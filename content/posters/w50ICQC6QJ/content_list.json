[{"type": "text", "text": "Discovery of the Hidden World with Large Language Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Chenxi Liu1,\u2217 Yongqiang Chen2,3,4,\u2217 Tongliang Liu5,2 ", "page_idx": 0}, {"type": "text", "text": "1TMLR Group, Hong Kong Baptist University 2Mohamed bin Zayed University of Artificial Intelligence {cscxliu,bhanml}@comp.hkbu.edu.hk {yqchen,jcheng}@cse.cuhk.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Mingming $\\mathbf{Gong^{6,2}}$ , James Cheng4, $\\mathbf{Bo}\\,\\mathbf{Han}^{1\\dagger}$ , Kun Zhang2,3 3Carnegie Mellon University 4The Chinese University of Hong Kong 5Sydney AI Centre, The University of Sydney 6The University of Melbourne tongliang.liu@sydney.edu.au mingming.gong@unimelb.edu.au kunz1@cmu.edu ", "page_idx": 0}, {"type": "text", "text": "https://causalcoat.github.io ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Revealing the underlying causal mechanisms in the real world is the key to the development of science. Despite the progress in the past decades, traditional causal discovery approaches (CDs) mainly rely on high-quality measured variables, usually given by human experts, to find causal relations. The lack of well-defined high-level variables in many real-world applications has already been a longstanding roadblock to a broader application of CDs. To this end, this paper presents Causal representatiOn AssistanT (COAT) that introduces large language models (LLMs) to bridge the gap. LLMs are trained on massive observations of the world and have demonstrated great capability in extracting key information from unstructured data. Therefore, it is natural to employ LLMs to assist with proposing useful high-level factors and crafting their measurements. Meanwhile, COAT also adopts CDs to find causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors. We show that LLMs and CDs are mutually beneficial and the constructed feedback provably also helps with the factor proposal. We construct and curate several synthetic and real-world benchmarks including analysis of human reviews and diagnosis of neuropathic and brain tumors, to comprehensively evaluate COAT. Extensive empirical results confirm the effectiveness and reliability of COAT with significant improvements. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Science originates along with identifying important variables and revealing their causal relations [1, 2]. Despite the progress in the past decades, existing causal discovery approaches (CDs) mainly rely on high-quality measured variables, which are usually given by human experts [3, 4, 5]. However, the desired variables and their measurements are usually unavailable in a wide range of real-world applications. For example, Amazon sellers who want to analyze the factors related to user ratings only have raw user reviews, which are written according to the underlying user preferences for certain product characteristics. Therefore, the lack of high-quality high-level variables has been a longstanding impediment to broader real-world applications of CDs or causality-inspired methods [6]. ", "page_idx": 0}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/1b854ec5d654e13a2983e561e7d0659aa4655de52d5cf73836a5d73a013dc3fd.jpg", "img_caption": ["Figure 1: Illustration of COAT framework to analyze the rating scores of AppleGastronome. COAT aims to uncover the underlying Markov Blanket with respect to the given ratings of the apples (i.e., factors that fti the preferences of gastronomes). COAT first (a) adopts an LLM to read, comprehend, and relate the rich knowledge about tasting the apples. The LLM needs to propose a series of candidate factors such as apple sizes and smells, along with some meta-information such as annotation guidelines. Based on the candidate factors, COAT then (b) prompts another LLM to annotate the unstructured review into structured data. (c) The CD algorithm then finds causal relations among the factors, and constructs feedback based on samples where the ratings can not be well explained by the existing factors. By looking into the new samples, the LLM is expected to associate more related knowledge to uncover more desired causal factors. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "The recently emerged Large Language Models (LLMs) [7, 8, 9, 10] offer a new opportunity to mitigate the gap [11]. Trained from massive observations of the world, LLMs demonstrate impressive capabilities in comprehending unstructured inputs, and leveraging the learned rich knowledge to resolve a variety of general tasks [12]. A surge of early tests demonstrates promising results that LLMs can effectively leverage the learned knowledge to answer commonsense causal questions [11, 13, 14]. Nevertheless, existing approaches mainly focus on incorporating LLMs as a straightforward reasoner with respect to the given causal variables. The reliability of LLMs in directly reasoning the true causal structure behind any specific data-generating process remains a debate [13, 15, 16, 17] due to a series of drawbacks of LLMs [18, 19, 20]. In addition, all of the existing combinations of LLMs and causal discovery have surprisingly overlooked the identifiability of causal structure, which plays an important role in classic causal discovery literature [3, 4, 5]. Hence, a challenging question comes: ", "page_idx": 1}, {"type": "text", "text": "How can LLMs reliably assist in revealing the causal mechanisms behind the real world? ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this work, we answer the question with a focus on local causal discovery with respect to a target variable that poses high value such as customer ratings and medical diagnosis, and introduce Causal representatiOn AssistanT (COAT). Specifically, given the target variable $Y$ , COAT aims to identify a Markov blanket to $Y$ from raw observation and also produce the theoretical-guaranteed causal structure. To achieve the goal, as illustrated in Fig. 1, COAT employs two mutually beneficial components: LLMs and CDs. Iteratively, at step (a), COAT leverages LLMs to look into a set of unstructured observations (e.g., customer comments) and propose potentially useful high-level factors. The proposed factors contain both the definition and the annotation criteria. Therefore, at step (b), another LLM is employed to give concrete values following the criteria. Then in step (c), CDs is used to reveal the structure among the identified factors. To ensure the reliability of the factor identification, COAT constructs feedback from the intermediate causal discovery results from step (c) to further inspire LLMs to improve further factors. The feedback includes sampling important observations that can not be well explained by the existing identified results. We show that the feedback provably helps with identifying the desired Markov Blanket and the structure (Proposition 2.2). We present a comprehensive analysis of COAT on both synthetic simulations and real-world case studies, ranging from analysis of human reviews to diagnosis of neuropathic and brain tumors (Sec. 4). Our contributions are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "\u2022 To the best of our knowledge, we are the first to leverage LLMs to propose high-level variables, thereby extending the scope of CDs to unstructured data (Sec. 2.1).   \n\u2022 We establish the first benchmarks with real-world data including AppleGastronome and Neuropathic to examine the unstructured causal discovery (Sec. 4).   \n\u2022 We propose the first framework COAT that combines the best of LLMs and CDs to find theoretically grounded causal results (Sec. 2.2), which are verified with extensive empirical studies (Sec. 4).   \n\u2022 Additionally, the analysis of COAT also derives the first metrics that measure the causal representation learning capabilities of various LLMs (Definition 2.3). ", "page_idx": 2}, {"type": "text", "text": "2 Representation Assistant for Causal Discovery ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we present the formulation of leveraging a language model to serve as a representation assistant for causal discovery on unstructured data. The representation assistant needs to extract useful factors that capture sufficient information for an interested target variable. ", "page_idx": 2}, {"type": "text", "text": "2.1 Problem Definition ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Data To begin with, we are given a target variable of interest $Y$ , e.g., stars rated by a customer or the tumor type of a patient. We treat $Y$ as a scalar random variable without loss of generality. The unstructured data, or raw observations, e.g., customer review of a certain product or images of tumors, are denoted as $\\mathbf{\\deltaX}$ . The dataset $\\mathcal{D}$ consists of $n$ paired samples $\\{(\\overline{{\\mathbf{x}_{i}}},y_{i})\\}_{i=1}^{n}$ that are independently drawn from the distribution over $(X,Y)$ . Note that the target variable $Y$ serves as a guider, and no prior assumption on the relations between $\\mathbf{\\deltaX}$ and $Y$ is assumed. ", "page_idx": 2}, {"type": "text", "text": "Objective We seek a mapping $h:X\\mapsto Z$ which elicits the structured representation $Z=h(X)$ such that $Y\\perp X\\mid Z$ . In other words, $_{z}$ serves as a Markov Blanket of $Y$ for the unstructured raw observations. Built upon the structure representation, then, downstream causal discovery methods can be applied on $Z\\cup\\{Y\\}$ . The revealed causal structure can provide insights about the target variable $Y$ [21, 22], such as what factors of the product would be most satisfactory to customers. Furthermore, the framework can be easily extended to discover a complete causal graph by shifting the target variable to the other identified factors or the other additionally available variables. Formal assumptions are discussed in Sec. 2.4. ", "page_idx": 2}, {"type": "text", "text": "LLM as a representation assistant We aim to make the most use of the rich knowledge of LLMs to assist in extracting the relevant information from the raw observations $\\mathbf{\\deltaX}$ . To this end, the mapping $h$ is decomposed as a collection of factors $\\mathcal{W}=\\left\\{\\pmb{w}_{1},\\pmb{w}_{2},...,\\pmb{w}_{k}\\right\\}$ , each of which is a function $w_{i}:X\\mapsto{\\mathcal{C}}$ that maps the raw observation $\\textbf{\\em x}$ to a predefined value space $\\mathcal{C}$ . In other words, the structured representation is composed of multiple factors: $h(\\pmb{X})=\\left(w_{1}\\left(\\pmb{X}\\right),w_{2}\\left(\\pmb{X}\\right),\\cdot\\cdot\\cdot\\mathbf{\\Phi},w_{k}\\left(\\pmb{X}\\right)\\right)$ . Throughout this work, for the notation of factors, we use the symbol $\\pmb{w}_{i}$ to denote the factor itself like sweetness, size, or scent, and $w_{i}(\\cdot)$ to denote the function that maps from raw observation space $\\mathcal{X}$ to the predefined value space $\\mathcal{C}$ . ", "page_idx": 2}, {"type": "text", "text": "Descriptions of the factors Without loss of generality, in this work, we consider the descriptions of the factors in natural language, which can be divided into two categories: i) Implicit factors, which need to be discovered and elaborated by LLMs. To obtain the values of the implicit factors, one could feed the factor descriptions and the unstructured input $\\pmb{x}_{i}$ to a suitable LLM for value annotation; For example, given a customer review on an apple $\\pmb{x}_{i}$ , a discovered implicit factor $\\mathcal{C}=\\{-1,0,1\\}$ : ${\\pmb w}_{1}({\\pmb x}_{i})\\,=\\,1$ could mean that the customer appreciates the sweetness of the apple; ${\\pmb w}_{1}({\\pmb x})\\,=\\,-1$ means that the customer is disappointed about the sweetness; ${\\pmb w}_{1}({\\pmb x})=0$ means the sweetness has not been mentioned. ii) Explicit factors such as heart rate, whose descriptions are already available. The measure of the explicit factors usually requires some external tools. ", "page_idx": 2}, {"type": "text", "text": "2.2 The COAT Framework ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We approach the aforementioned problem via a new framework called Causal representatiOn AssistanT (COAT) (Algorithm 1). COAT aims to extract useful factors through multiple rounds of iteration. We use the superscript $t$ to refer to the input and output of LLM at the $t$ -th round. We also denote the union of results from the first $t$ rounds using the superscript \u201c $\\mathrel{\\mathop{:}}\\leq t^{\\infty}$ . ", "page_idx": 2}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/e1d0a1c04b4a1f3017f54378e76f5ee5b795e71fad989dd57165ccb1a5b59c74.jpg", "img_caption": ["Figure 2: Illustration of the prompt template for factor proposal in COAT. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Factor proposal To induce useful highlevel factors from the rich world knowledge of LLMs, COAT employs a prompt $\\pmb{p}$ and a few samples $\\widehat{\\mathcal{D}}\\subseteq\\bar{\\mathcal{D}}$ . ", "page_idx": 3}, {"type": "text", "text": "Specifically, in Fig. 2, $\\pmb{p}$ contains three components: samples, instructions, and format control. To encourage LLM to focus on the information related to the target variable $Y$ , samples are grouped by the value of $Y$ . The instruction requires $\\Psi$ to give each proposed factor $\\pmb{w}_{i}$ a concrete description of the mapping $w_{i}(\\cdot)$ , like how to decide the factor values. In addition, the metadata about the task such as the task description and context can also be incorporated if available. The prompt $\\pmb{p}$ essentially imitates human experts [23] in selecting and ", "page_idx": 3}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/782009f70073c85f78dc1afdb5e2bb72ddf8cdf8065167720b22c36d32bbd9e4.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "defining high-level variables. The set of resulting factors in the $t$ -th round, defined with natural language by the LLM $\\Psi$ , is denoted as $\\mathcal{W}^{t}=\\bar{\\Psi}(\\bar{\\pmb{p^{t}}},\\widehat{\\mathcal{D}^{t}})$ . We merge them with factors proposed in the previous rounds to update the set of all factors $\\mathcal{W}^{\\leq t^{\\prime}}{=}\\mathcal{W}^{1}\\cup\\bar{\\dots}\\cdot\\cup\\mathcal{W}^{t}$ . ", "page_idx": 3}, {"type": "text", "text": "Factor parsing Once we obtain the candidate factors, we then collect the values of the factors from the unstructured observations. In prior works, they are usually collected from human experts according to the given factors [3]. To do so, another LLM $\\Psi_{s}$ is instructed to read the annotated guidelines of each variable $\\boldsymbol{w}_{i}$ and parse the unstructured observations into structured or tabular data: ", "page_idx": 3}, {"type": "equation", "text": "$$\nz_{i}:=\\big(w_{i}(x_{1}),\\cdot\\cdot\\cdot,w_{i}(x_{n})\\big),\\quad w_{i}(x):=\\Psi_{s}(\\pmb{x},w_{i},p_{p}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\pmb{p_{p}}$ refers to the additional instruction to prompt $\\Psi_{s}$ to parse the observed data, and $z_{i}$ refers to the parsed values for the corresponding factor $\\widehat{\\pmb{w}}_{i}$ . We define Z\u2264t := Concat $\\{z_{i}\\,\\mathrm{for}\\,{\\pmb w}_{i}\\in\\mathcal{W}^{\\leq t}\\}\\}$ . ", "page_idx": 3}, {"type": "text", "text": "When the data curation of the proposed factors requires additional domain-specific knowledge/skills (e.g., intervening on the external environments) that the LLMs do not acquire, we could fetch $z_{i}$ through some external process [24, 25]. For example, studying the causes of a disease requires annotating relevant symptoms from diagnosis records and conducting additional medical checks [26]. Our experiments show that COAT can effectively extract the hidden factors under both schemes. ", "page_idx": 3}, {"type": "text", "text": "Causal discovery With the given values $Z^{\\leq t}$ associated with the candidate factors $\\mathcal{W}^{\\leq t}$ , a CD algorithm $\\boldsymbol{\\mathcal{A}}$ (e.g., FCI [27]) is used to reason about the causal structure based on the parsed data: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{G}^{t}=\\mathcal{A}(Z^{\\leq t}\\cup\\{Y\\}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathcal{G}^{t}$ is the discovered causal structure. In general, the inputs in each round to $\\boldsymbol{\\mathcal{A}}$ may contain noises as well as latent confounders, any CDs with suitable theoretical assumptions could be used for $\\boldsymbol{\\mathcal{A}}$ . The noises injected through LLM-based parsing may be of independent interest to the literature of causal discovery [5, 28]. In this work, we demonstrate the idea of COAT via the FCI algorithm [4] as it is flexible with respect to different functional classes of the underlying generation process, allows for the existence of latent confounders [27], which aligns well with our objective. ", "page_idx": 4}, {"type": "text", "text": "Improving factor proposal with causal feedback LLMs require proper prompts to fully unlock their capabilities [29, 30, 31]. When it comes to factor proposing, it is also hard for LLMs to propose all factors at once. Nevertheless, from the causal discovery results, we could find useful information and thus provide feedback to further improve the factor proposal: ", "page_idx": 4}, {"type": "equation", "text": "$$\n(\\widehat{\\boldsymbol{D}}^{t+1},\\pmb{p}^{t+1})=\\mathcal{F}(\\mathcal{G}^{t},\\boldsymbol{\\mathcal{D}},\\pmb{p}^{t}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathcal{F}$ samples specific examples from $\\mathcal{D}$ and constructs new prompts according to the results of $\\boldsymbol{\\mathcal{A}}$ for the next round of factor proposal. For example, FCI is able to imply the existence of latent confounders, from which we could refine $\\textbf{\\emph{p}}$ to prompt $\\Psi$ to focus on the corresponding factors. ", "page_idx": 4}, {"type": "text", "text": "2.3 Causal Feedback ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let $X$ be the high-dimensional random variable for the raw data. After $t$ rounds, COAT identifies $h_{\\leq t}(X)$ as the Markov Blanket for $Y$ w.r.t. to $\\left\\{w_{i}(X)\\mid w_{i}\\in\\mathcal{W}^{\\leq t}\\right\\}$ . If $Y\\nmid\\!\\!X\\mid h_{\\leq t}(X).$ , which means it cannot serve as a Markov Blanket [32] for $Y$ w.r.t. $X$ , then there exists a potential factor $\\widehat{\\pmb{w}}:X\\mapsto\\mathcal{C}$ such that: ", "page_idx": 4}, {"type": "equation", "text": "$$\nH(Y|h_{\\leq t}(X))>H(Y|h_{\\leq t}(X),\\widehat{w}(X)),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $H(\\cdot)$ refers to the entropy. If the LLM $\\Psi$ can not find the desired $\\widehat{\\pmb w}$ , it means that $h_{\\leq t}(X)$ is already sufficient to separate $Y$ from $X$ . Therefore, for the next $(t+1)$ -th iteration with sample $\\widehat{\\mathcal{D}}^{t+1}$ , $\\Psi$ is expected to propose new factor $\\widehat{\\pmb{w}}$ tha t also satisfies the similar property: ", "page_idx": 4}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/895c771602eb537566b013547ff010d0271ab611bdd644fadf45f7a848e1bdb9.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Figure 3: Illustration of variables that could be discovered with COAT. Let $W\\in{\\mathfrak{h}}_{\\leq t}(X)$ be an identified variable, and assume there exists a latent variable $\\widehat{\\pmb w}$ to be discovered. When $\\widehat{\\pmb w}$ is the direct parent or child of $Y$ , finding hard-to-explain samples can help uncover it. When $\\widehat{\\pmb w}$ is the direct parent and also a child of $W$ , or the spouse of $Y$ with $W$ as the common child of $Y$ and $\\widehat{\\pmb{w}}$ , conditioning on $W$ facilitates the discovery of $\\widehat{\\pmb w}$ . ", "page_idx": 4}, {"type": "equation", "text": "$$\nH_{\\widehat{\\mathcal{D}}^{t+1}}(Y|h_{\\leq t}(X))-H_{\\widehat{\\mathcal{D}}^{t+1}}(Y|h_{\\leq t}(X),\\widehat{w}(X))>0,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $H_{\\widehat{D}^{t}}(\\cdot|\\cdot)$ refers to the conditional entropy measured on $\\widehat{\\mathcal{D}}^{t}$ . As shown in Fig. 3, finding factors sat isfying Eq. 4 progressively expands the discovered fac tors and pushes $h_{\\leq t}(X)$ to a valid Markov Blanket. Also, it implies conditioning on the identified factors would further strengthen the correlation between $\\widehat{w}$ and $Y$ . Therefore, to find the desired factor, we are motivated to select suitable $\\widehat{\\mathcal{D}}^{t+1}$ for the nex t  iteration such that $\\begin{array}{r}{\\widehat{\\mathcal{D}}^{t+1}=\\arg\\operatorname*{max}_{\\widehat{\\mathcal{D}}\\subseteq\\mathcal{D}}H_{\\widehat{\\mathcal{D}}}(Y|h_{\\leq t}(X))}\\end{array}$ , where $h_{\\leq t}(X)$ can not well explain $Y$ . This problem can be converted into a classification problem in which $\\widehat{\\mathcal{D}}^{*}$ are the samples that the fitted classifier yields a large prediction error. In our experiments,  we implement the classification via clustering with respect to $h_{\\leq t}(X)$ . The clustering elicits $C$ groups $\\widehat{\\cal D}_{c}:=\\{{\\pmb x}_{i}$ for $\\in\\mathcal{Z}_{c}\\}\\colon\\mathcal{T}_{1},\\cdot\\cdot\\cdot\\ ,\\mathcal{Z}_{C}=\\mathrm{K}\\mathrm{-Means}\\big(h_{\\leq t}(X)\\big)$ . We then take the group of samples with the largest conditional entropy to construct the feedback. ", "page_idx": 4}, {"type": "text", "text": "In practice, many factors, such as the LLM capabilities, data faithfulness, and prompt templates, could affect the satisfaction of Eq 5. Therefore, in the next section, we will establish a theoretical framework to discuss the influence of the factors above to the satisfaction of $\\operatorname{Eq}5$ . ", "page_idx": 4}, {"type": "text", "text": "2.4 Theoretical Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We then theoretically analyze some critical steps in COAT, including the feedback and identifiability. ", "page_idx": 4}, {"type": "text", "text": "Feedback analysis Given a new factor $\\pmb{w}_{k+1}$ , with the current representation as $h_{[k]}(X)\\;=\\;$ $\\left(\\pmb{w}_{1}\\left(X\\right),\\pmb{w}_{2}\\left(X\\right),\\cdot\\cdot\\cdot\\mathbf{\\Phi},\\pmb{w}_{k}\\left(X\\right)\\right)$ , and COAT tests: ", "page_idx": 5}, {"type": "equation", "text": "$$\nY\\nmid\\!\\!\\!\\!\\!\\slash\\ w_{k+1}(X)\\mid h_{[k]}(X).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "COAT also requires the following usual condition about distribution and causal graph: ", "page_idx": 5}, {"type": "text", "text": "Assumption 2.1 (Faithful and Markov conditions, adjusted from [33]). For any disjoint non-empty subsets $\\overset{\\cdot}{A},B,C\\subset\\mathcal{W}^{\\leq t}\\cup\\{Y\\}$ , $A$ and $B$ are $d$ -separated by $C$ on the causal graph iif $A\\perp B\\mid C$ on the factors\u2019 distribution. All conditional independencies are preserved after factor parsing. ", "page_idx": 5}, {"type": "text", "text": "The annotation from a poor model could introduce an additional \u201cerror term\u201d on the true factor values, disturbing the true distribution, as one can observe in Fig. 4(a) and 4(b). If Assumption 2.1 holds, the conditional mutual information between $Y$ and $X$ given the desired factors decreases: ", "page_idx": 5}, {"type": "text", "text": "Proposition 2.2. Under assumption 2.1, if condition $^{6}$ holds, then for Markov Blanket $S\\subseteq[k+1]$ of $Y$ , i.e., $Y\\perp h_{[k+1]\\backslash S}(X)\\mid h_{S}(X),$ , we have the following about conditional mutual information: ", "page_idx": 5}, {"type": "equation", "text": "$$\nI\\left(Y;X\\mid h_{S}(X)\\right)=I\\left(Y;X\\mid h_{[k+1]}(X)\\right)<I\\left(Y;X\\mid h_{[k]}(X)\\right)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Factor identification We provide an initial exploration under what conditions LLMs can identify target-related factors and how the ability of an LLM influences this procedure. ", "page_idx": 5}, {"type": "text", "text": "Definition 2.3 (Ability of LLMs). Given a suitable prompt about current factors and data, the LLM $\\Psi$ has non-zero probability $p_{\\Psi}>0$ to propose a new factor $\\pmb{w}_{k+1}$ that satisfies condition $^{6}$ and ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\frac{I\\left(Y;X\\mid h_{[k+1]}(X)\\right)}{I\\left(Y;X\\mid h_{[k]}(X)\\right)}<1-C_{\\Psi},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "for some positive constant $C_{\\Psi}$ whenever $I\\left(Y;X\\mid h_{[k]}(X)\\right)>0.$ . Note that $h_{[0]}(X)=\\phi$ , hence we also use $I\\left(Y;X\\mid h_{[0]}(X)\\right)$ to refer $I\\left(Y;X\\right)$ . We use $p$ instead of $p_{\\Psi}$ when the context is clear. ", "page_idx": 5}, {"type": "text", "text": "We further explain the intuition behind Def 2.3: the Perception Score $p$ captures the LLM\u2019s responsiveness to the given prompts and the feedback; the Capacity Score $C_{\\Psi}$ captures the quality of the factors proposed by the LLM. Empirically, the two scores are used to estimate the abilities of the predominant LLMs (Sec. 3.2). Theoretically, we use them to characterize the influence of prompt templates, the LLM responsiveness, and the quality of factors on the performance of COAT: ", "page_idx": 5}, {"type": "text", "text": "Proposition 2.4 (Characterization for Factor Identification Process). With assumption 2.1, for any small number $\\epsilon,\\delta\\in(0,\\frac{1}{2})$ , perception score $p>0$ , capacity score $C_{\\Psi}>0$ , with $t$ COAT rounds that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sqrt{t}>\\frac{|z_{\\delta}|\\sqrt{1-p}}{2\\sqrt{p}}\\left(1+\\sqrt{1+\\frac{4\\log\\epsilon}{z_{\\delta}^{2}(1-p)\\log\\left(1-C_{\\Psi}\\right)}}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $z_{\\delta}$ is the $\\delta$ -quantile of the standard normal distribution, we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(\\frac{I\\left(Y;X\\mid h_{\\leq t}(X)\\right)}{I\\left(Y;X\\right)}<\\epsilon\\right)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The proof is given in Appendix D.2. Prop. 2.4 gives a guarantee on identifying a Markov Blanket. Intuitively, Prop. 2.4 also characterizes the influence of prompt templates, the LLM responsiveness, and the quality of factors on the performance of COAT via the two proposed measures: $p$ and $C_{\\Psi}$ . When both of them are positive, COAT would converge exponentially: ", "page_idx": 5}, {"type": "text", "text": "Proposition 2.5 (Rate of Convergence). With assumption 2.1, for any small number \u03f5, $\\mathscr{S}\\in\\left(0,\\frac{1}{2}\\right)$ , perception score $p>0$ , capacity score $C_{\\Psi}>0$ , after $t$ COAT rounds, the following inequality holds with probability at least $1-\\delta$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n{\\frac{I(Y;X\\mid h_{\\leq t}(X))}{I(Y;X)}}\\leq\\left({\\frac{1}{1-C_{\\Psi}}}\\right)^{-t p-z_{\\delta}{\\sqrt{t p(1-p)}}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Causal structure identification It is clear that LLMs are not involved in the causal discovery process, which is mainly executed by causal discovery methods such as FCI. Therefore, the CD guarantees the identifiability of the final causal graph over the LLM-proposed factors. The concrete assumptions required for identifiability depend on the specific CD used in COAT. For instance, the FCI algorithm requires faithfulness of the data distribution with respect to the true causal graph [27]. In our experiments, we also verify that the structured data annotated by LLMs has a high accuracy and little noise, which is friendly to the CD assumption. In general, one could switch to another CD in COAT, while using different CDs may require different assumptions. For example, the LiNGAM algorithm requires the relations among variables to be linear and non-Gaussian models. Empirically, we find that COAT with LiNGAM works very well (Appendix F). ", "page_idx": 5}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/f7bd4ba80a2953f8bcfabf2ec57b0f7f6a171aa70504c99298f34f11c28a8d6e.jpg", "img_caption": ["Figure 4: Quantitative evaluation of the causal capabilities of LLMs in COAT. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "2.5 Practical Discussions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Prompt template The instruction following capability and the context window of LLMs may affect the satisfaction to the constraints of the prompt template. Including more data samples or background knowledge may improve the $p$ and $C_{\\Psi}$ , but it is more challenging for the LLM. ", "page_idx": 6}, {"type": "text", "text": "Modern causal discovery We use FCI in this paper in order to illustrate the idea. To attain identifiability better than the Markov equivalent class, one can choose more advanced Causal Discovery methods under different assumptions, see Appendix C if interested. ", "page_idx": 6}, {"type": "text", "text": "We also discuss some cases where we need to handle them properly in practice with LLMs. ", "page_idx": 6}, {"type": "text", "text": "Factor flitering LLMs may output several factors with similar semantics or exhibit multicollinearity in the annotated data, which will hinder the causal discovery process. To mitigate the issue, one could do factor flitering that adopts PCA or early conditional independence tests given the currently discovered variables in the Markov Blanket to detect and eliminate these variables. ", "page_idx": 6}, {"type": "text", "text": "Factor pool LLMs may discover useful factors in early rounds while being discarded. For example, the underlying spouse variables of the target label $y$ may be independent with $y$ without conditioning on their common children variables. To resolve the issue, we could introduce a factor pool that stores the candidate variables proposed in the past, and replay the variables that have not been passed by conditional independence tests with existing variables in the Markov Blanket for a double check. ", "page_idx": 6}, {"type": "text", "text": "3 Empirical Analysis of COAT ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate whether COAT can propose and identify a set of high-level factors belonging to the Markov Blanket of the target variable $Y$ . We construct the first benchmark, called AppleGastronome, to verify the effectiveness of COAT in finding useful causal information, and compare COAT to previous methods [11] that merely leverage LLMs to perform causal discovery. Specifically, we use AppleGastronome to examine the capabilities of 10 predominant LLMs including GPT 4o [34], Claude-3-Opus [35], LLaMA3-70b [36], and Mistral-Large [37] in realizing COAT. Due to the space limit, we report only the results of the popular LLMs and present full results in Appendix E.4. ", "page_idx": 6}, {"type": "text", "text": "3.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In AppleGastronome benchmark, we consider the target variable as a rating score of the apple by astronomers. We prepare different high-level factors: 3 parents of Y, one child of Y, and one spouse of Y. These factors form a Markov blanket of Y. In addition, we also prepared one disturbing factor related to Y but not a part of this blanket. A good method is expected to propose the five high-level factors (up to semantical meanings) and exclude the disturbing factor. ", "page_idx": 6}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/c89770b565f56be24f14b25678bca7980ba71449d37672ab778671ad4698fdc1.jpg", "img_caption": ["Figure 5: The discovered causal graphs in AppleGastronome. Compared to the ground truth results, directly adopting LLMs to reason the causal relations can easily elicit many false positive edges. In contrast, the relations recovered by COAT have a high precision and recall. The directed edge between \u201ctaste\u201d and \u201cjuiciness\u201d can not be recovered by COAT because of the limitations of FCI. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Benchmark construction Each apple has its own attributes, including size, smell, and taste (or sweetness). Each gastronomy pays unique attention to a subset of the above three attributes. They will write a review according to their preference and give the rating score. We generate the review using GPT 4 by feeding GPT 4 the preferences and the apple attributes. We generated 200 samples for LLMs\u2019 analysis and annotation. More details are left in Appendix E.1. ", "page_idx": 7}, {"type": "text", "text": "Baselines For factor proposal, we mainly employ two different uses of LLMs as the baselines: META is the zero-shot factor proposal given only the context to LLMs; and DATA additionally gives some samples of raw observations, which is an ablation of COAT without the feedback module, i.e., only one COAT round. For causal relation inference, we follow Kiciman et al. [11] that prompt LLMs to reason for the causal direction of each pair of the discovered variables by DATA. ", "page_idx": 7}, {"type": "text", "text": "Metrics We evaluate the ability on factor proposal based on three metrics: MB, NMB, and OT. MB means the desired factor forming the Markov Blanket of Y. NMB means the undesired factor relevant to data but not in MB. OT means the unexpected factors irrelevant to data. We also present the corresponding recall, precision, and F1 with respect to $\\mathrm{MB}(Y)$ . ", "page_idx": 7}, {"type": "text", "text": "3.2 Analysis with AppleGastronome Benchmark ", "text_level": 1, "page_idx": 7}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/f5c0db90f84745d3b735c59be4a22f62f89018ba31858a3445bff5309535c997.jpg", "table_caption": ["Table 1: Factor proposal results in Apple Gastronome benchmark (Full results in Appendix E.4). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Key findings Empirically, LLMs with CoT can be aware of high-level factors behind data (lower OT than META) but still struggle to distinguish the desired factors in Markov Blanket (higher NMB than COAT). COAT is more resistant to the \u201cdisturbing\u201d factor, which is supported by the lower NMB column. COAT filters out irrelevant factors from LLMs\u2019 prior knowledge that are not reflected by the data, which is ", "page_idx": 7}, {"type": "text", "text": "supported by the lower ${\\cal O}T$ column. COAT robustly encourages LLM to find more expected factors through the feedback, which is supported by the higher MB column. ", "page_idx": 7}, {"type": "text", "text": "Can LLMs be an effective factor proposer? As discussed in Sec. 2.4, there are two crucial abilities for LLMs in identifying potential high-level factors. The first one is to be aware of the existence of potential factors, and the second is to synthesize and describe these factors. Inspired by this observation, we propose two novel metrics to quantify LLMs\u2019 causal ability: a) Perception that quantifies the ratio of valid factors (satisfying Prop. 2.2) proposed by LLMs in each round; b) Capacity that measures the effective mutual information drop in Assumption 2.3. As shown in Fig. 4(c), LLMs differ largely on the perception score while comparably on the capacity score. ", "page_idx": 7}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/6d29912e3729f7f5c6b1a0d5a57812eadafc73f0a9f6295ed9be9ff3af76326a.jpg", "img_caption": ["Figure 6: The discovered causal graphs in Neuropathic. (c) shows the result based on directly prompting LLM to reason for the causal relations among all factors. Disconnected ones are dropped. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Can LLMs be an effective factor annotator? As shown in Fig. 4, both GPT 3.5 and GPT 4 annotate subjective attributes well. Regarding objective human preferences, the performances are still relatively high. Empirically, LLMs will not introduce new confounders, see Appendix E.3. ", "page_idx": 8}, {"type": "text", "text": "Can COAT reliably recover the causal relationships? We present quantitative and qualitative results in Table 3 (in Appendix E.1) and Fig. 5 (on page 8), respectively. Compared to directly adopting LLMs to reason the causal relations, COAT significantly boosts the causal relation recovery. Meanwhile, COAT maintains high performances based on various LLMs, which further demonstrates the effectiveness of the causal feedback in COAT to improve the robustness of this system. In fact, the causal feedback focuses on making maximal use of the rich knowledge of LLMs, and reducing the reliance on the reasoning capabilities of different LLMs, to assist with causal discovery. We provide the full results of 10 LLMs in Appendix E.3. ", "page_idx": 8}, {"type": "text", "text": "4 Empirical Study with Realistic Benchmarks ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "After examining the capabilities of COAT in AppleGastronome, we are further motivated to challenge COAT in a more complex setting from neuropathic panic diagnosis [26], brain tumor detection with MRI images [38], three-years news summary about one stock from the New York Times [39], and climatic reanalysis data with fine-grained time and space coverage [40]. We refer to Appendix H for a complete summary of all five benchmarks. ", "page_idx": 8}, {"type": "text", "text": "Table 2: Factor proposal results in Neuropathic. PA, AN, and OT refer to the parents, ancestors, and others, respectively. Accuracy and F1 measure the recovery of the causal ancestors. ", "page_idx": 8}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Benchmark construction In the Neuropathic benchmark, we convert the dataset into a clinical diagnosis task. In the original dataset, there are three levels of causal variables, including the symptom level, radiculopathy level, and the pathophysiology level. In the experiments, we mainly consider the target variable of right shoulder impingement. When generating the clinical diagnosis notes as $\\textbf{\\em x}$ using GPT 4, we avoid any mentioning of variables other than symptoms. We generated 100 samples for LLMs\u2019 analysis; since the number of possible factors is finite, we generate 1000 tabular data for CI tests. ", "page_idx": 8}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/8e3ae59a3d7b2650de149678781473fa5c4ae1e8b453af3b9a524d8a4458af08.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "As we intend to leverage the Neuropathic benchmark   \nto simulate the real-world diagnosis, after the factor proposal stage, we directly incorporate external tools to measure the values of the candidate factors. More details about the construction of the Neuropathic are given in Appendix E.6. ", "page_idx": 8}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/102075cf0697ebd7694de0c429d351040487119e6af70aad1f19bc5281216b8b.jpg", "img_caption": ["Figure 7: The final causal graph found by COAT in the ENSO case study "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Evaluation and baselines In Neuropathic, we adopt a similar evaluation protocol and the baselines as in AppleGastronome. Nevertheless, due to the faithfulness issue of the original dataset [26], for the evaluation of causal relation discovery, we mainly conduct a qualitative comparison between the ground truth that is faithful to the data, against the baselines and COAT. ", "page_idx": 9}, {"type": "text", "text": "4.2 Empirical Results on Neuropathic Benchmark ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Factor proposal The quantitative results on Neuropathic benchmark are given in Table 2. Similarly, we can find that COAT consistently outperforms all of the baselines regardless of which LLMs are incorporated. In particular, even with the weakest backbone model, i.e.,LLaMA2-7b, COAT can still effectively leverage the intrinsic rich knowledge and beat the baselines with more powerful LLMs. ", "page_idx": 9}, {"type": "text", "text": "Causal relation recovery Fig. 6(a) shows the causal graph obtained by FCI running on the original data, where we can find that several causal relations cannot hold on the data. As shown in Fig. 6, when using LLMs to perform the reasoning, LLMs cannot identify the faithfulness issues. In contrast, COAT can imply faithful causal insights. ", "page_idx": 9}, {"type": "text", "text": "4.3 More Real-world Results ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "El Ni\u02dcno\u2013Southern Oscillation (ENSO) case study El Ni\u02dcno-Southern Oscillation (ENSO) is a climatic phenomenon in the Pacific Ocean that influences global weather patterns profoundly. To understand its mechanism, we apply COAT on NOAA dataset [40]. There are 13 factors identified by COAT, and their instantaneous causal relations are visualized in Fig 7. The target variable is the future change in monthly SST in the Nino3 region, which could be an important indicator of ENSO events. Each factor is a time series about a certain climate measurement above a specific level averaged over a specific region. The paths about Sea level Pressure, Momentum Flux, and Cloud Cover matches the existing understanding from literature [41, 42, 43, 44]. It also suggests several inserting hypotheses that are less explored in literature, like the path from Soil Temperature in South American Coastal Region. We refer details in Appendix K. ", "page_idx": 9}, {"type": "text", "text": "More real-world empirical studies We also report concrete results on real-world problems involving MRI, time series, and NetCDF data in Appendix I, J, and K. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we proposed a new paradigm COAT to incorporate the rich knowledge of LLMs into the CD pipeline. We found that COAT effectively extends the scope of CDs to unstructured data by identifying useful high-level variables from raw observations for CD methods. COAT suggests a new pathway towards building a causal foundation model for discovery. We leave more detailed discussions about future studies in Appendix B. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We thank the reviewers for their valuable comments. This material is based upon work supported by NSF Award No. 2229881, AI Institute for Societal Decision Making (AI-SDM), the National Institutes of Health (NIH) under Contract R01HL159805, and grants from Salesforce, Apple Inc., Quris AI, and Florin Court Capital. CXL and BH were supported by NSFC General Program No. 62376235, Guangdong Basic and Applied Basic Research Foundation Nos. 2022A1515011652 and 2024A1515012399, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04, and HKBU CSD Departmental Incentive Scheme. MMG was partially supported by the following Australian Research Council projects: DE210101624 and DP240102088. JC was supported by CUHK direct grant 4055146. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Norwood Russell Hanson. Patterns of discovery : an inquiry into the conceptual foundations of science. Cambridge University Press, 1958. (Cited on page 1) ", "page_idx": 10}, {"type": "text", "text": "[2] Thomas S. Kuhn and David Hawkins. The structure of scientific revolutions. American Journal of Physics, 31:554\u2013555, 1963. (Cited on page 1)   \n[3] Peter Spirtes, Clark Glymour, and Richard Scheines. Causation, Prediction, and Search, Second Edition. Adaptive computation and machine learning. MIT Press, 2000. ISBN 978-0-262-19440-2. (Cited on pages 1, 2, 4, 21 and 22)   \n[4] Peter Spirtes, Clark Glymour, Richard Scheines, and Robert Tillman. Automated Search for Causal Relations: Theory and Practice, 2018. (Cited on pages 1, 2, 5, 21 and 22)   \n[5] Matthew J. Vowels, Necati Cihan Camgoz, and Richard Bowden. D\u2019ya like dags? a survey on structure learning and causal discovery. ACM Computing Survey, 55(4), 2022. ISSN 0360-0300. (Cited on pages 1, 2, 5, 21 and 22)   \n[6] Bernhard Scho\u00a8lkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, and Yoshua Bengio. Towards causal representation learning. arXiv preprint, arXiv:2102.11107, 2021. (Cited on pages 1, 21 and 22)   \n[7] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Advances in Neural Information Processing Systems, 2020. (Cited on pages 2, 21 and 22)   \n[8] OpenAI. Chatgpt. https://chat.openai.com/chat/, 2022. (Cited on pages 2, 21 and 22)   \n[9] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00b4ee Lacroix, Baptiste Rozi\\`ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aur\u00b4elien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. arXiv preprint, arXiv:2302.13971, 2023. (Cited on pages 2 and 21) ", "page_idx": 10}, {"type": "text", "text": "[10] OpenAI. Gpt-4 technical report, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 10}, {"type": "text", "text": "[11] Emre Kiciman, Robert Ness, Amit Sharma, and Chenhao Tan. Causal reasoning and large language models: Opening a new frontier for causality. arXiv preprint, arXiv:2305.00050, 2023. (Cited on pages 2, 7, 8, 21 and 22) ", "page_idx": 10}, {"type": "text", "text": "[12] Se\u00b4bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott M. Lundberg, Harsha Nori, Hamid Palangi, Marco Tu\u00b4lio Ribeiro, and Yi Zhang. Sparks of artificial general intelligence: Early experiments with GPT-4. arXiv preprint, arXiv:2303.12712, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 10}, {"type": "text", "text": "[13] Cheng Zhang, Stefan Bauer, Paul Bennett, Jiangfeng Gao, Wenbo Gong, Agrin Hilmkil, Joel Jennings, Chao Ma, Tom Minka, Nick Pawlowski, and James Vaughan. Understanding causality with large language models: Feasibility and opportunities. arXiv preprint, arXiv:2304.05524, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 11}, {"type": "text", "text": "[14] Ahmed Abdulaal, adamos hadjivasiliou, Nina Montana-Brown, Tiantian He, Ayodeji Ijishakin, Ivana Drobnjak, Daniel C. Castro, and Daniel C. Alexander. Causal modelling agents: Causal graph discovery through synergising metadata- and data-driven reasoning. In The Twelfth International Conference on Learning Representations, 2024. (Cited on pages 2, 21, 22 and 23) ", "page_idx": 11}, {"type": "text", "text": "[15] Matej Zec\u02c7evic\u00b4, Moritz Willig, Devendra Singh Dhami, and Kristian Kersting. Causal parrots: Large language models may talk causality but are not causal. Transactions on Machine Learning Research, 2023. ISSN 2835-8856. (Cited on pages 2, 21 and 22) ", "page_idx": 11}, {"type": "text", "text": "[16] Zhijing Jin, Yuen Chen, Felix Leeb, Luigi Gresele, Ojasv Kamal, Zhiheng LYU, Kevin Blin, Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, and Bernhard Scho\u00a8lkopf. CLadder: A benchmark to assess causal reasoning capabilities of language models. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 11}, {"type": "text", "text": "[17] Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, and Bernhard Sch\u00a8olkopf. Can large language models infer causation from correlation? arXiv preprint, arXiv:2306.05836, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 11}, {"type": "text", "text": "[18] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. Siren\u2019s song in the AI ocean: A survey on hallucination in large language models. arXiv preprint, arXiv:2309.01219, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 11}, {"type": "text", "text": "[19] Chenhang Cui, Yiyang Zhou, Xinyu Yang, Shirley Wu, Linjun Zhang, James Zou, and Huaxiu Yao. Holistic analysis of hallucination in gpt-4v(ision): Bias and interference challenges. arXiv preprint, arXiv:2311.03287, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 11}, {"type": "text", "text": "[20] Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. The reversal curse: Llms trained on \u201da is b\u201d fail to learn \u201db is a\u201d. arXiv preprint, arXiv:2309.12288, 2023. (Cited on pages 2, 21 and 22) ", "page_idx": 11}, {"type": "text", "text": "[21] Constantin F. Aliferis, Alexander Statnikov, Ioannis Tsamardinos, Subramani Mani, and Xenofon D. Koutsoukos. Local causal and markov blanket induction for causal discovery and feature selection for classification part i: Algorithms and empirical evaluation. Journal of Machine Learning Research, 11(7):171\u2013234, 2010. (Cited on page 3) ", "page_idx": 11}, {"type": "text", "text": "[22] Shantanu Gupta, David Childers, and Zachary Chase Lipton. Local causal discovery for estimating causal effects. In Conference on Causal Learning and Reasoning, volume 213, pages 408\u2013447, 2023. (Cited on page 3) ", "page_idx": 11}, {"type": "text", "text": "[23] Judea Pearl and Dana Mackenzie. The Book of Why: The New Science of Cause and Effect. Basic Books, Inc., USA, 1st edition, 2018. ISBN 046509760X. (Cited on pages 4 and 22) ", "page_idx": 11}, {"type": "text", "text": "[24] Timo Schick, Jane Dwivedi-Yu, Roberto Dess\u0131\\`, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint, arXiv:2302.04761, 2023. (Cited on page 4) ", "page_idx": 11}, {"type": "text", "text": "[25] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huan, and Tao Gui. The rise and potential of large language model based agents: A survey. arXiv preprint, arXiv:2309.07864, 2023. (Cited on page 4) ", "page_idx": 11}, {"type": "text", "text": "[26] Ruibo Tu, Kun Zhang, Bo C. Bertilson, Hedvig Kjellstr\u00a8om, and Cheng Zhang. Neuropathic pain diagnosis simulator for causal discovery algorithm evaluation. In Advances in Neural Information Processing Systems, pages 12773\u201312784, 2019. (Cited on pages 4, 9, 10 and 43) ", "page_idx": 11}, {"type": "text", "text": "[27] Peter Spirtes, Christopher Meek, and Thomas Richardson. Causal inference in the presence of latent variables and selection bias. In Uncertainty in Artificial Intelligence, page 499\u2013506, 1995. (Cited on pages 5, 7 and 22)   \n[28] Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on graphical models. Frontiers in Genetics, 10, 2019. (Cited on pages 5 and 22)   \n[29] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. (Cited on pages 5 and 22)   \n[30] Jiaxin Huang, Shixiang Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. Large language models can self-improve. In Conference on Empirical Methods in Natural Language Processing, pages 1051\u20131068, 2023. (Cited on page 5)   \n[31] Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. Reasoning with language model prompting: A survey. In Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), July 2023. (Cited on page 5)   \n[32] Judea Pearl. Probabilistic reasoning in intelligent systems - networks of plausible inference. In Morgan Kaufmann series in representation and reasoning, 1991. (Cited on page 5)   \n[33] Jonas Peters, Dominik Janzing, and Bernhard Schlkopf. Elements of Causal Inference: Foundations and Learning Algorithms. The MIT Press, 2017. ISBN 0262037319. (Cited on page 6)   \n[34] OpenAI. Hello, gpt-4o! https://openai.com/index/hello-gpt-4o/, 2024. Accessed: 2024-05-20. (Cited on page 7)   \n[35] Anthropic. Claude 3 family. https://www.anthropic.com/news/claude-3-family, 2024. Accessed: 2024-05-20. (Cited on page 7)   \n[36] Meta AI. Meta llama 3. https://ai.meta.com/blog/meta-llama-3/, 2024. Accessed: 2024-05-20. (Cited on page 7)   \n[37] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Le\u00b4lio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, The\u00b4ophile Gervet, Thibaut Lavril, Thomas Wang, Timothe\u00b4e Lacroix, and William El Sayed. Mixtral of experts. arXiv preprint, arXiv:2401.04088, 2024. (Cited on page 7)   \n[38] Sartaj Bhuvaji, Ankita Kadam, Prajakta Bhumkar, and Sameer Dedge. Brain tumor classification using deep learning algorithms. https://github.com/SartajBhuvaji/ Brain-Tumor-Classification-Using-Deep-Learning-Algorithms, 2024. Accessed: 2024-05-19. (Cited on pages 9 and 43)   \n[39] Bidec Innovations. Stock price and news related to it, 2023. URL https://www.kaggle. com/datasets/BidecInnovations/stock-price-and-news-realted-to-it. Accessed: 2023-10-01. (Cited on pages 9 and 43)   \n[40] Gilbert P Compo, Jeffrey S Whitaker, Prashant D Sardeshmukh, Nobuki Matsui, Robert J Allan, Xungang Yin, Byron E Gleason, Russell S Vose, Glenn Rutledge, Pierre Bessemoulin, et al. The twentieth century reanalysis project. Quarterly Journal of the Royal Meteorological Society, 137(654):1\u201328, 2011. (Cited on pages 9, 10, 43 and 49)   \n[41] Jakob Bjerknes. Atmospheric teleconnections from the equatorial pacific. Monthly weather review, 97(3):163\u2013172, 1969. (Cited on pages 10 and 51)   \n[42] Chunzai Wang. Enso, atlantic climate variability, and the walker and hadley circulations. In The Hadley circulation: Present, past and future, pages 173\u2013202. Springer, 2004. (Cited on pages 10 and 51)   \n[43] Yinge Liu, Ninglian Wang, Lingang Wang, Zhongming Guo, and Xiaobo Wu. Variation of cloud amount over china and the relationship with enso from 1951 to 2014. International Journal of Climatology, 36(8):2931\u20132941, 2016. (Cited on pages 10 and 51)   \n[44] Anoop Kumar Mishra. Investigating changes in cloud cover using the long-term record of precipitation extremes. Meteorological Applications, 26(1):108\u2013116, 2019. (Cited on pages 10 and 51)   \n[45] Peter Lee, Sebastien Bubeck, and Joseph Petro. Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine. New England Journal of Medicine, 388(13):1233\u20131239, 2023. (Cited on page 21)   \n[46] Ruibo Tu, Chao Ma, and Cheng Zhang. Causal-discovery performance of chatgpt in the context of neuropathic pain diagnosis. arXiv preprint, arXiv:2301.13819, 2023. (Cited on pages 21 and 23)   \n[47] Judea Pearl and James M. Robins. Causal diagrams for epidemiologic research. Epidemiology, 10 1:37\u201348, 1999. (Cited on page 22)   \n[48] Shohei Shimizu, Patrik O Hoyer, Aapo Hyv\u00a8arinen, Antti Kerminen, and Michael Jordan. A linear non-gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(10), 2006. (Cited on page 22)   \n[49] Kun Zhang and Aapo Hyvarinen. On the identifiability of the post-nonlinear causal model. arXiv preprint arXiv:1205.2599, 2012. (Cited on page 22)   \n[50] Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Scho\u00a8lkopf. Nonlinear causal discovery with additive noise models. Advances in neural information processing systems, 2008. (Cited on page 22)   \n[51] Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben Sanchez-Romero, Clark Glymour, and Bernhard Scho\u00a8lkopf. Causal discovery from heterogeneous/nonstationary data. Journal of Machine Learning Research, 21(89):1\u201353, 2020. (Cited on pages 22 and 50)   \n[52] Karren Yang, Abigail Katcoff, and Caroline Uhler. Characterizing and learning equivalence classes of causal DAGs under interventions. In International Conference on Machine Learning, pages 5541\u20135550, 2018. (Cited on page 22)   \n[53] Philippe Brouillard, S\u00b4ebastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien, and Alexandre Drouin. Differentiable causal discovery from interventional data. In Advances in Neural Information Processing Systems, pages 21865\u201321877, 2020. (Cited on page 22)   \n[54] Joris M. Mooij, Sara Magliacane, and Tom Claassen. Joint causal inference from multiple contexts. Journal of Machine Learning Research, 21(99):1\u2013108, 2020. (Cited on page 22)   \n[55] Ronan Perry, Julius von Ku\u00a8gelgen, and Bernhard Scho\u00a8lkopf. Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis. In Advances in Neural Information Processing Systems, pages 10904\u201310917, 2022. (Cited on page 22)   \n[56] Daniel Malinsky and Peter Spirtes. Learning the structure of a nonstationary vector autoregression. In International Conference on Artificial Intelligence and Statistics, pages 2986\u20132994, 2019. (Cited on page 22)   \n[57] Biwei Huang, Kun Zhang, Mingming Gong, and Clark Glymour. Causal discovery and forecasting in nonstationary environments with state-space models. In International Conference on Machine Learning, pages 2901\u20132910, 2019. (Cited on page 22)   \n[58] Chenxi Liu and Kun Kuang. Causal structure learning for latent intervened non-stationary data. In International Conference on Machine Learning, pages 21756\u201321777, 2023. (Cited on page 22)   \n[59] Zhengming Chen, Feng Xie, Jie Qiao, Zhifeng Hao, Kun Zhang, and Ruichu Cai. Identification of linear latent variable model with arbitrary distribution. In AAAI Conference on Artificial Intelligence, pages 6350\u20136357, 2022. (Cited on page 22)   \n[60] Anpeng Wu, Haoxuan Li, Kun Kuang, Zhang Keli, and Fei Wu. Learning causal relations from subsampled time series with two time-slices. In International Conference on Machine Learning, 2024. (Cited on page 22)   \n[61] Biwei Huang, Charles Jia Han Low, Feng Xie, Clark Glymour, and Kun Zhang. Latent hierarchical causal structure discovery with rank constraints. Advances in neural information processing systems, pages 5549\u20135561, 2022. (Cited on page 22)   \n[62] Xinshuai Dong, Biwei Huang, Ignavier Ng, Xiangchen Song, Yujia Zheng, Songyao Jin, Roberto Legaspi, Peter Spirtes, and Kun Zhang. A versatile causal discovery framework to allow causally-related hidden variables. arXiv preprint, arXiv:2312.11001, 2023. (Cited on page 22)   \n[63] Yibo Jiang and Bryon Aragam. Learning nonparametric latent causal graphs with unknown interventions. In Advances in Neural Information Processing Systems, volume 36, pages 60468\u201360513, 2023. (Cited on page 22)   \n[64] Xiu-Chuan Li, Kun Zhang, and Tongliang Liu. Causal structure recovery with latent variables under milder distributional and graphical assumptions. In International Conference on Learning Representations, 2024. (Cited on page 22)   \n[65] Aapo Hyvarinen, Hiroaki Sasaki, and Richard Turner. Nonlinear ica using auxiliary variables and generalized contrastive learning. In International Conference on Artificial Intelligence and Statistics, pages 859\u2013868, 2019. (Cited on page 22)   \n[66] Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoencoders and nonlinear ica: A unifying framework. In International Conference on Artificial Intelligence and Statistics, pages 2207\u20132217, 2020. (Cited on page 22)   \n[67] Francesco Locatello, Ben Poole, Gunnar Raetsch, Bernhard Sch\u00a8olkopf, Olivier Bachem, and Michael Tschannen. Weakly-supervised disentanglement without compromises. In International Conference on Machine Learning, pages 6348\u20136359, 2020. (Cited on page 22)   \n[68] David Klindt, Lukas Schott, Yash Sharma, Ivan Ustyuzhaninov, Wieland Brendel, Matthias Bethge, and Dylan Paiton. Towards nonlinear disentanglement in natural data with temporal sparse coding, 2021. (Cited on page 22)   \n[69] Sebastien Lachapelle, Pau Rodriguez, Yash Sharma, Katie E Everett, R\u00b4emi LE PRIOL, Alexandre Lacoste, and Simon Lacoste-Julien. Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ICA. In Conference on Causal Learning and Reasoning, pages 428\u2013484, 2022. (Cited on page 22)   \n[70] Kartik Ahuja, Jason S Hartford, and Yoshua Bengio. Weakly supervised representation learning with sparse perturbations. In Advances in Neural Information Processing Systems, pages 15516\u201315528, 2022. (Cited on page 22)   \n[71] Kartik Ahuja, Divyat Mahajan, Yixin Wang, and Yoshua Bengio. Interventional causal representation learning. In International conference on machine learning, pages 372\u2013407, 2023. (Cited on page 22)   \n[72] Jiaqi Zhang, Kristjan Greenewald, Chandler Squires, Akash Srivastava, Karthikeyan Shanmugam, and Caroline Uhler. Identifiability guarantees for causal disentanglement from soft interventions. Advances in Neural Information Processing Systems, 2024. (Cited on page 22)   \n[73] Julius von K\u00a8ugelgen, Michel Besserve, Liang Wendong, Luigi Gresele, Armin Keki\u00b4c, Elias Bareinboim, David Blei, and Bernhard Sch\u00a8olkopf. Nonparametric identifiability of causal representations from unknown interventions. In Advances in Neural Information Processing Systems, pages 48603\u201348638, 2023. (Cited on page 22)   \n[74] Chandler Squires, Anna Seigal, Salil S Bhate, and Caroline Uhler. Linear causal disentanglement via interventions. In International Conference on Machine Learning, pages 32540\u201332560, 2023. (Cited on page 22)   \n[75] Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam, Bernhard Scho\u00a8lkopf, and Pradeep Ravikumar. Learning linear causal representations from interventions under general nonlinear mixing. Advances in Neural Information Processing Systems, 2024. (Cited on page 22)   \n[76] Yongqiang Chen, Yonggang Zhang, Yatao Bian, Han Yang, Kaili Ma, Binghui Xie, Tongliang Liu, Bo Han, and James Cheng. Learning causally invariant representations for out-ofdistribution generalization on graphs. In Advances in Neural Information Processing Systems, 2022. (Cited on page 22)   \n[77] Yongqiang Chen, Yatao Bian, Kaiwen Zhou, Binghui Xie, Bo Han, and James Cheng. Does invariant graph learning via environment augmentation learn invariance? In Advances in Neural Information Processing Systems, 2023. (Cited on page 22)   \n[78] Yongqiang Chen, Yatao Bian, Bo Han, and James Cheng. Interpretable and generalizable graph learning via subgraph multilinear extension. In ICLR 2024 Workshop on Machine Learning for Genomics Explorations, 2024. (Cited on page 22)   \n[79] Yongqiang Chen, Kaiwen Zhou, Yatao Bian, Binghui Xie, Kaili Ma, Yonggang Zhang, Han Yang, Bo Han, and James Cheng. Pareto invariant risk minimization. arXiv preprint, arXiv:2206.07766, 2022. (Cited on page 22)   \n[80] Yongqiang Chen, Wei Huang, Kaiwen Zhou, Yatao Bian, Bo Han, and James Cheng. Understanding and improving feature learning for out-of-distribution generalization. In Advances in Neural Information Processing Systems, 2023. (Cited on page 22)   \n[81] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155, 2022. (Cited on page 22)   \n[82] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. arXiv preprint, arXiv:2110.14168, 2021. (Cited on page 22)   \n[83] Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Sean Welleck, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D. Hwang, Soumya Sanyal, Xiang Ren, Allyson Ettinger, Zaid Harchaoui, and Yejin Choi. Faith and fate: Limits of transformers on compositionality. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. (Cited on page 22)   \n[84] Bingbin Liu, Jordan T. Ash, Surbhi Goel, Akshay Krishnamurthy, and Cyril Zhang. Transformers learn shortcuts to automata. In The Eleventh International Conference on Learning Representations, 2023. (Cited on page 22)   \n[85] Xuan Li, Zhanke Zhou, Jianing Zhu, Jiangchao Yao, Tongliang Liu, and Bo Han. Deepinception: Hypnotize large language model to be jailbreaker, 2024. URL https://arxiv.org/ abs/2311.03191. (Cited on page 22)   \n[86] Zhanke Zhou, Rong Tao, Jianing Zhu, Yiwen Luo, Zengmao Wang, and Bo Han. Can large language models reason robustly with noisy rationales? In ICLR 2024 Workshop on Reliable and Responsible Foundation Models, 2024. (Cited on page 22)   \n[87] Brett Drury, Hugo Gonc\u00b8alo Oliveira, and Alneu de Andrade Lopes. A survey of the extraction and applications of causal relations. Natural Language Engineering, 28:361 \u2013 400, 2022. (Cited on page 22)   \n[88] Shaobo Cui, Zhijing Jin, Bernhard Sch\u00a8olkopf, and Boi Faltings. The odyssey of commonsense causality: From foundational benchmarks to cutting-edge reasoning. arXiv preprint arXiv:2406.19307, 2024. (Cited on page 22)   \n[89] Pedram Hosseini, David A Broniatowski, and Mona Diab. Predicting directionality in causal relations in text. arXiv preprint arXiv:2103.13606, 2021. (Cited on page 22)   \n[90] Lei Gao, Prafulla Kumar Choubey, and Ruihong Huang. Modeling document-level causal structures for event causal relation identification. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1808\u20131817, 2019. (Cited on page 22)   \n[91] Noah Weber, Rachel Rudinger, and Benjamin Van Durme. Causal inference of script knowledge. arXiv preprint arXiv:2004.01174, 2020. (Cited on page 22)   \n[92] Xiao Liu, Da Yin, Yansong Feng, Yuting Wu, and Dongyan Zhao. Everything has a cause: Leveraging causal inference in legal text analysis. arXiv preprint arXiv:2104.09420, 2021. (Cited on page 22)   \n[93] Andrew Kyle Lampinen, Stephanie C.Y. Chan, Ishita Dasgupta, Andrew Joo Hun Nam, and Jane X Wang. Passive learning of active causal strategies in agents and language models. In Advances in Neural Information Processing Systems, 2023. (Cited on page 22)   \n[94] Kristy Choi, Chris Cundy, Sanjari Srivastava, and Stefano Ermon. Lmpriors: Pre-trained language models as task-specific priors. arXiv preprint, arXiv:2210.12530, 2022. (Cited on pages 22 and 23)   \n[95] Stephanie Long, Alexandre Pich\u00b4e, Valentina Zantedeschi, Tibor Schuster, and Alexandre Drouin. Causal discovery with language models as imperfect experts. arXiv preprint, arXiv:2307.02390, 2023. (Cited on pages 22 and 23)   \n[96] Taiyu Ban, Lyuzhou Chen, Xiangyu Wang, and Huanhuan Chen. From query tools to causal architects: Harnessing large language models for advanced causal discovery from data. arXiv preprint, arXiv:2306.16902, 2023. (Cited on pages 22 and 23)   \n[97] Moritz Willig, Matej Zec\u02c7evic\u00b4, Devendra Singh Dhami, and Kristian Kersting. Can foundation models talk causality? In UAI 2022 Workshop on Causal Representation Learning, 2022. (Cited on page 22)   \n[98] Stephanie Long, Tibor Schuster, and Alexandre Piche\u00b4. Can large language models build causal graphs? arXiv preprint, arXiv:2303.05279, 2023. (Cited on page 22)   \n[99] Zhiheng LYU, Zhijing Jin, Rada Mihalcea, Mrinmaya Sachan, and Bernhard Scho\u00a8lkopf. Can large language models distinguish cause from effect? In UAI 2022 Workshop on Causal Representation Learning, 2022. (Cited on page 23)   \n[100] Yanming Zhang, Brette Fitzgibbon, Dino Garofolo, Akshith Kota, Eric Papenhausen, and Klaus Mueller. An explainable AI approach to large language model assisted causal model auditing and development. arXiv preprint, arXiv:2312.16211, 2023. (Cited on page 23)   \n[101] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36:46595\u2013 46623, 2023. (Cited on page 40)   \n[102] Daniel Lyndon, Joseph A Lansley, Jane Evanson, and Anant S Krishnan. Dural masses: meningiomas and their mimics. Insights into imaging, 10(1):11, 2019. (Cited on page 44)   \n[103] Nisreen Haydar, Khatoun Alyousef, Usama Alanan, Rana Issa, Fawaz Baddour, Zuheir AlShehabi, and Moatasem Hussein Al-Janabi. Role of magnetic resonance imaging (mri) in grading gliomas comparable with pathology: A cross-sectional study from syria. Annals of Medicine and Surgery, 82:104679, 2022. (Cited on page 44)   \n[104] Birkan Tunc\u00b8, David A Hormuth II, George Biros, and Thomas E Yankeelov. Modeling of glioma growth with mass effect by longitudinal magnetic resonance imaging. IEEE Transactions on Biomedical Engineering, 68(12):3713\u20133724, 2021. (Cited on page 44)   \n[105] J Watts, G Box, A Galvin, P Brotchie, N Trost, and T Sutherland. Magnetic resonance imaging of meningiomas: a pictorial review. Insights into imaging, 5:113\u2013122, 2014. (Cited on page 44)   \n[106] John Markoff. Competing as software goes to web. The New York Times, 2007. URL https://www.nytimes.com/2007/06/05/technology/05compute.html. Accessed: 2024- 03-14. (Cited on page 47)   \n[107] Fama Eugene. Efficient capital markets: A review of theory and empirical work. Journal of finance, 25:383\u2013417, 1970. (Cited on page 47)   \n[108] Jessica A Wachter. Can time-varying risk of rare disasters explain aggregate stock market volatility? The Journal of Finance, 68(3):987\u20131035, 2013. (Cited on page 47)   \n[109] Leland Bybee, Bryan T Kelly, Asaf Manela, and Dacheng Xiu. Business news and business cycles. Journal of Finance, Forthcoming, 2023. (Cited on page 47)   \n[110] Michael J McPhaden. Genesis and evolution of the 1997-98 el ni\u02dcno. Science, 283(5404): 950\u2013954, 1999. (Cited on pages 49 and 50)   \n[111] Chester F Ropelewski and Michael S Halpert. Global and regional scale precipitation patterns associated with the el nin\u02dco/southern oscillation. Monthly weather review, 115(8):1606\u20131626, 1987. (Cited on page 49)   \n[112] Wenju Cai, Simon Borlace, Matthieu Lengaigne, Peter Van Rensch, Mat Collins, Gabriel Vecchi, Axel Timmermann, Agus Santoso, Michael J McPhaden, Lixin Wu, et al. Increasing frequency of extreme el nin\u02dco events due to greenhouse warming. Nature climate change, 4(2): 111\u2013116, 2014. (Cited on page 49)   \n[113] Chunzai Wang, Clara Deser, Jin-Yi Yu, Pedro DiNezio, and Amy Clement. El ni\u02dcno and southern oscillation (enso): a review. Coral reefs of the eastern tropical Pacific: Persistence and loss in a dynamic environment, pages 85\u2013106, 2017. (Cited on page 49)   \n[114] Joris M Mooij, Sara Magliacane, and Tom Claassen. Joint causal inference from multiple contexts. Journal of Machine Learning Research, 21(99):1\u2013108, 2020. (Cited on page 50)   \n[115] Yi Ge Zhang, Mark Pagani, Jorijntje Henderiks, and Haojia Ren. A long history of equatorial deep-water upwelling in the pacific ocean. Earth and Planetary Science Letters, 467:1\u20139, 2017. ISSN 0012-821X. (Cited on page 50)   \n[116] J. Tarazona and W. Arntz. The Peruvian Coastal Upwelling System, pages 229\u2013244. Springer Berlin Heidelberg, 2001. (Cited on page 51) ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Appendix of COAT ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "A Table of Notations 20 ", "page_idx": 18}, {"type": "text", "text": "B Limitation and Future Opportunities 21 ", "page_idx": 18}, {"type": "text", "text": "C Related Work 22 ", "page_idx": 18}, {"type": "text", "text": "D Proofs for Theoretical Results 23   \nD.1 Proof for Proposition 2.2 23   \nD.2 Proof for Proposition 2.4 23   \nE More Details about Experiments 25   \nE.1 More Details on Constructing AppleGastronome 25   \nE.2 More Details on Prompts for AppleGastronome 25   \nE.3 More Details of Results on AppleGastronome 26   \nE.4 The Full Result on the Apple Gastronome Benchmark 29   \nE.5 Implementation of the FCI algorithm . . 29   \nE.6 More Details on Constructing Neuropathic . 37   \nE.7 More Details of Results on Neuropathic 37   \nE.8 Discussion on the time complexity . . 37   \nE.9 Resources . 38 ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "F COAT with Different Causal Discovery Algorithm 40 ", "page_idx": 18}, {"type": "text", "text": "G Ablation Study 40 ", "page_idx": 18}, {"type": "text", "text": "H Summary of Benchmark Data 43 ", "page_idx": 18}, {"type": "text", "text": "Case Study on Brain Tumor 43   \nI.1 The Brain Tumor Dataset 43   \nI.2 Result and Discussion . 44   \nCase Study on Stock News 45   \nJ.1 The Stock News Dataset 45   \nJ.2 Result and Discussion . 46   \nK Case Study on El Nin\u02dco\u2013Southern Oscillation (ENSO) 49   \nK.1 Setting and Data processing . . . 49   \nK.2 Causal Graph and Discussion 50 ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "L Broader Impacts 53 ", "page_idx": 18}, {"type": "text", "text": "A Table of Notations ", "text_level": 1, "page_idx": 19}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/501ae72489392e468149f2c8ea61be18cef836cfcd65bbb14d120a83d4726302.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/66c14515bca650f1853fce40ec532e22b0635b53e810a9f0549974557410391d.jpg", "img_caption": ["Figure 8: COAT combines both strengths of LLMs that learn the rich knowledge of the world, and causal discovery methods to uncover the hidden causal world. With the uncovered causal knowledge, COAT can empower broader applications of causal methods. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "B Limitation and Future Opportunities ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Future Opportunities Despite the progress in the past decades, existing causal discovery algorithms mainly rely on high-quality measured variables given by human experts [3, 4, 5]. However, the causal variables and their measurements are usually available in a wide range of real-world applications. For example, Amazon sellers who want to analyze the factors related to user ratings only have user reviews, generated by the underlying user preferences for certain product characteristics. Therefore, the lack of measured high-quality causal variables has been a major impediment to broader real-world applications of causal or causality-inspired methods [6]. ", "page_idx": 20}, {"type": "text", "text": "This work establishes and demonstrates a preliminary implementation of the system Causal representatiOn AssistanT (COAT). We present comprehensive evaluations of COAT and find plentiful evidence that the recent emergence of Large Language Models (LLMs) [7, 8, 9, 10] has a great potential to mitigate the gap. In particular, as shown in Fig. 8, we envision an entangled system towards causal foundation models, which consists of two mutually beneficial components: LLMs and causal discovery methods (CDs). On the one hand, LLMs that learn rich world knowledge about the world can assist with discovering high-level hidden variables from low-level observational data [12], or even certain commonsense causal knowledge [11, 13, 14]. On the other hand, it has also been found that the reliability of LLMs in the reasoning of causality remains a debate [13, 15, 16, 17], due to a series of drawbacks of LLMs [18, 19, 20], as well as the ethical considerations [45, 46]. Nevertheless, CDs can uncover the underlying causal relations between the discovered high-level variables with guarantees. More importantly, CDs can also provide feedback to improve the identification of the variables. The combination of LLMs and CDs iteratively improves the discovery of the hidden causal world, and hence opens up a broader adoption of various causal methods. ", "page_idx": 20}, {"type": "text", "text": "Limitations We would like to discuss some technical limitations of the current version of COAT. ", "page_idx": 20}, {"type": "text", "text": "\u2022 Multicollinearity. Sometimes, LLM may output factors with shared similar semantic meanings or overlapped factor-value criteria. The consequence of this phenomenon is that multicollinearity could occur in the resulting structured data, or the data matrix (each sample per row) would not be full column rank. This would hinder the conditional independent tests. In experiments, we adopt numerical methods like PCA to drop similar factors. More sophisticated methods could be investigated in the future. \u2022 Toward complete causal graph. In this work, we mainly focus on one single target variable and identify a set of factors to serve as a Markov blanket of this target variable. Indeed, one can explore a more complete causal graph by applying COAT procedures on those identified factors to acquire a more comprehensive causal graph. One may also introduce multiple target variables or let LLM define a suitable target variable (and also parse it out) from pure raw observations. These extensions are also important, and we leave it to future work. ", "page_idx": 20}, {"type": "text", "text": "\u2022 Faithfulness. The empirical distribution of the data reflects the actual data-generating process. \u2022 No selection bias. Otherwise, the condition of faithfulness would be violated. \u2022 Enough sample size. Our method involves statistical tests; the more, the better. ", "page_idx": 21}, {"type": "text", "text": "C Related Work ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Causal discovery aims to discover the unknown causal relations from the observational data [3, 4], which is critical to both real-world applications and scientific discoveries [23, 47]. We use FCI [27] in this paper just to illustrate the idea. To attain identifiability better than the Markov equivalent class, one can choose more advanced Causal Discovery methods under different assumptions, like constrained functional [48, 49, 50], multiple domain data [51, 52, 53, 54, 55], and non-stationary data [51, 56, 57, 58]. There are also some works aiming to address realistic challenges, like structure models with arbitrary distribution [59], subsampled time series [60], and latent hierarchical causal structure [61, 62, 63, 64]. Despite recent theoretical and empirical improvements [5, 28], most existing causal discovery approaches rely on well-structured data with human-crafted factors as inputs. They can easily suffer from the low quality of annotated data (e.g., latent confounders). ", "page_idx": 21}, {"type": "text", "text": "Causal representation learning aims to establish provable identifiability for latent high-level variables (like location and color of an object) from low-level observations such as images [6]. Such identification can be feasible with certain conditions, like auxiliary information [65, 66, 67], sparsity [68, 69, 70], or interventional data [71, 72, 73, 74, 75]. Recent works also generalize the causal representation learning to graph-structured data [76, 77, 78], and discuss the optimization challenges in realizing causal representation learning [79, 80]. In this work, we show that incorporating LLMs that learn world knowledge from massive training data could effectively relieve the need for artificial causal factor annotation. Meanwhile, COAT also opens up a new line to learn causal representations with rich pre-trained knowledge as well as feedback from causal discovery algorithms. ", "page_idx": 21}, {"type": "text", "text": "Reasoning with LLMs has achieved remarkable performance across a variety of tasks with few demonstrations of the samples [7, 8, 10, 81]. The strong capabilities of LLMs show that it is evident that LLMs could acquire and understand commonsense knowledge about the world [12]. The power of LLMs can be further unlocked with suitable context as inputs [29]. Nevertheless, LLMs have also been found to make mistakes in basic algorithmic reasoning [82, 83], easy to hallucinate nonfactual results [18], tend to learn shortcuts or dataset biases [19, 20, 84], vulnerable to adversarial jailbreaks or noisy interruptions [85, 86], and fall short in complex planning and reasoning tasks [12]. The drawbacks of LLMs render it risky to rely on the direct LLM reasoning results to derive any rigorous results. Therefore, we do not directly derive the results from LLMs. Rather, we merely leverage the learned world knowledge in LLMs to find useful causal factors by constructing proper instructions based on causal feedback. ", "page_idx": 21}, {"type": "text", "text": "Text mining of causal relations aims to analyze the causal relations implied by the semantics given a text [87, 88, 89]. In particular, some works focus on the identification of causal relations among events specified in documents [90, 91, 92]. Different from these tasks, where factors are entities or events described by text, in this work, COAT emphasizes crafting high-level factors that go beyond the unstructured data like text description and also establish identifiability on the Markov blanket for a given target variable. Note that the target variable is allowed to be not mentioned in the text or other unstructured data. Therefore, this work brings new scope and opportunities for these text-understanding tasks. ", "page_idx": 21}, {"type": "text", "text": "Causal learning with LLMs has received muchattention results from the community [11, 13]. Kiciman et al. [11] find that LLMs can recover the pairwise causal relations very well. Lampinen et al. [93] show that transformer-based agents can learn causal strategies passively if intervention is allowed during tests. Abdulaal et al. [14], Choi et al. [94], Long et al. [95], Ban et al. [96] propose to incorporate the causal discovery results by LLMs as a prior or constraint to improve the performance of data-driven causal discovery algorithms. However, Ze\u02c7cevi\u00b4c et al. [15], Willig et al. [97] find that LLMs can not understand causality but simply retell the causal knowledge contained in the training data. Zhang et al. [13], Jin et al. [16, 17] find that LLMs can hardly provide satisfactory answers for discovering new knowledge or decision-making tasks. Although Long et al. [98] find that LLMs can build causal graphs with 3-4 nodes, Tu et al. [46] find that the performance of LLMs in more complex causal discovery remains limited as LLMs can hardly understand new concepts and knowledge. The aforementioned debate implies the limitations in directly adopting the causal discovery results by LLMs, which motivates us to incorporate the existing causal discovery algorithms with rigorous guarantees instead of LLMs to learn the causal relations. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "LYU et al. [99] find that it is crucial to incorporate prompts aligned with the underlying causal story for LLMs to do pairwise causal relation inference. Zhang et al. [100] propose to leverage LLMs to audit causal discovery results in an explainable way. ", "page_idx": 22}, {"type": "text", "text": "The closest works to ours are Abdulaal et al. [14], Choi et al. [94], Long et al. [95], Ban et al. [96] which also incorporates LLMs into the pipeline of causal discovery. Nevertheless, all of the existing combinations of LLMs and causal discovery still focus on artificially curated structured data and rely on the capability of LLMs to infer causal relations, therefore, limited in both the reliability and the utility of LLMs in causal learning. ", "page_idx": 22}, {"type": "text", "text": "D Proofs for Theoretical Results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "D.1 Proof for Proposition 2.2 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proposition D.1 (Restatement of Proposition 2.2). Given the current representation as $h_{[k]}(X)=$ $\\left(\\pmb{w}_{1}\\left(X\\right),\\pmb{w}_{2}\\left(X\\right),\\cdot\\cdot\\cdot\\mathbf{\\Phi},\\pmb{w}_{k}\\left(X\\right)\\right)$ , and a new factor $w_{k+1}$ satisfying ", "page_idx": 22}, {"type": "equation", "text": "$$\nY\\nmid\\!\\!\\!\\!\\!\\slash\\ w_{k+1}(X)\\mid h_{[k]}(X),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "for Markov Blanket $S\\subseteq[k+1]$ of $Y$ , i.e., ", "page_idx": 22}, {"type": "equation", "text": "$$\nY\\perp h_{[k+1]\\backslash{\\cal{S}}}(X)\\mid h_{{\\cal{S}}}(X),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "we have the following result about conditional mutual information: ", "page_idx": 22}, {"type": "equation", "text": "$$\nI\\left(Y;X\\mid h_{S}(X)\\right)=I\\left(Y;X\\mid h_{[k+1]}(X)\\right)<I\\left(Y;X\\mid h_{[k]}(X)\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof for Prop. 2.2. From Eq. 12, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\nH(y\\mid h_{[k]}({\\pmb x});{\\pmb w}_{k+1}({\\pmb x}))<H(y\\mid h_{[k]}({\\pmb x}));\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "From Eq. 13, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\nH(y\\mid h_{S}({\\pmb x});h_{[k+1]\\backslash S}({\\pmb x}))=H(y\\mid h_{S}({\\pmb x})).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H(y\\mid h_{S}(\\pmb{x}))=H(y\\mid h_{S}(\\pmb{x}),h_{[k+1]\\setminus S}(\\pmb{x}))}\\\\ &{\\qquad\\qquad\\qquad=H(y\\mid h_{[k+1]}(\\pmb{x}))}\\\\ &{\\qquad\\qquad\\quad=H(y\\mid h_{[k]}(\\pmb{x}),\\pmb{w}_{k+1}(\\pmb{x}))}\\\\ &{\\qquad\\qquad\\quad<H(y\\mid h_{[k]}(\\pmb{x}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Also note that ", "page_idx": 22}, {"type": "equation", "text": "$$\nH(y\\mid h_{S}({\\pmb x}),{\\pmb x})=H(y\\mid{\\pmb x})=H(y\\mid h_{[k]}({\\pmb x}),{\\pmb x}),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "therefore: ", "page_idx": 22}, {"type": "equation", "text": "$$\nH(y\\mid h_{S}(x))-H(y\\mid h_{S}(x),x)<H(y\\mid h_{[k]}(x))-H(y\\mid h_{[k]}(x),x),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which is Eq. 14. ", "page_idx": 22}, {"type": "text", "text": "D.2 Proof for Proposition 2.4 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proposition D.2 (Restatement of Proposition 2.4). Given Assumption 2.3, for any small number $\\epsilon,\\delta\\stackrel{\\mathbf{\\textstyle~\\star~}}{\\in}(0,\\frac{1}{2})$ , with sufficiently $t$ rounds of COAT, i.e., ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sqrt{t}>\\frac{|z_{\\delta}|\\sqrt{1-p}}{2\\sqrt{p}}\\left(1+\\sqrt{1+\\frac{4\\log\\epsilon}{z_{\\delta}^{2}(1-p)\\log1-C_{\\Psi}}}\\right),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $z_{\\delta}$ is the $\\delta$ -quantile of the standard normal distribution, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(\\frac{I\\left(Y;X\\mid h_{\\leq t}(X)\\right)}{I\\left(Y;X\\right)}<\\epsilon\\right)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof for Prop. 2.4. Let $n_{s}$ be the number of rounds that LLM proposed at least one usable factor satisfying Assumption 2.3. Since $t$ is large, its Binomial distribution $\\mathrm{Binom}(t,p)$ can be approximated by Gaussian distribution $\\bar{\\mathcal{N}}\\left(t p,t p(1-\\bar{p})\\right)$ . To enforce ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\left(\\frac{I\\left(y;\\,x\\mid\\,h_{\\le t}(x)\\right)}{I\\left(y;\\,x\\right)}<\\epsilon\\right)\\ge\\operatorname*{Pr}\\left((1-C_{\\Psi})^{n_{s}}<\\epsilon\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\operatorname*{Pr}\\left(n_{s}>\\frac{\\log\\epsilon}{\\log\\left(1-C_{\\Psi}\\right)}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\operatorname*{Pr}\\left(\\frac{n_{s}-t p}{\\sqrt{t p(1-p)}}>\\frac{1}{\\sqrt{t p(1-p)}}\\left(\\frac{\\log\\epsilon}{\\log\\left(1-C_{\\Psi}\\right)}-t p\\right)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\ge1-\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{1}{\\sqrt{t p(1-p)}}\\left(\\frac{\\log\\epsilon}{\\log\\left(1-C_{\\Psi}\\right)}-t p\\right)<z_{\\delta}=-|z_{\\delta}|\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "with Gaussian distribution approximation. ", "page_idx": 23}, {"type": "text", "text": "Isolating $\\sqrt{t}>0$ from the above inequality, we would have the desired result. ", "page_idx": 23}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/d43231cf8347cdce07553943ba804372c775557d5ea1876e0a2fe07e1d6b2b53.jpg", "table_caption": ["Table 3: Causal relation extraction results in AppleGastronome. "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/956c965da4c968e2fed88fa921a8051209571a5c1fab96202efd7c4d536e379c.jpg", "table_caption": ["Table 4: Independence tests of the annotation noises with annotated features and other noises AppleGastronome. "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "E More Details about Experiments ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "E.1 More Details on Constructing AppleGastronome ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In the AppleGastronome benchmark, we consider the target variable as a rating score of the apple by several gastronomes. Each apple has its own attributes, including size, smell, and taste (or sweetness). Each gastronome has a unique preference for some attributes of the apple. They will give and rating as well as write a review according to the matchness of the apple with respect to their preference. We generate the review using GPT 4 by fetching GPT 4 the preferences and the apple attributes. ", "page_idx": 24}, {"type": "text", "text": "The prompts for generating the unstructured inputs are given in Fig. 9. The additional results on Relation Extraction are given in Table. 3. ", "page_idx": 24}, {"type": "text", "text": "Examples of AppleGastronome are given in Fig. 10. ", "page_idx": 24}, {"type": "text", "text": "E.2 More Details on Prompts for AppleGastronome ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The prompts for factor proposal are given in Fig. 11.   \nThe prompt for factor annotation is given in Fig. 12. ", "page_idx": 24}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/25e7d1b648990493a4365e53fee6a2e2496c324a803619a3829a411d75927237.jpg", "img_caption": ["Figure 9: Illustration of prompts for generating AppleGastronome. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/e9b6487999351240835322f843550895cbf4ce93ee0644a4ea5c313e6a857650.jpg", "img_caption": ["Figure 10: Illustration of examples in AppleGastronome. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "The prompts for constructing feedback are given in Fig. 13. ", "page_idx": 25}, {"type": "text", "text": "E.3 More Details of Results on AppleGastronome ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "The detailed causal graph results are given from Fig. 14 to Fig. 18.   \nIndependent tests about annotation on the Apple Gastronome benchmark are shown in Table 4. ", "page_idx": 25}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/b4e0407a82a09abe0926e91526e698427d2e9c7a7fafbb31d9d2558d682f7f85.jpg", "img_caption": ["Figure 11: Illustration of the prompt for factor proposal. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/fd1b689c308e3ca34dfa4fdf2dfd2dfa28cc9ee7454d28e6efba3df38244a901.jpg", "img_caption": ["Figure 12: Illustration of the prompt for factor annotation. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/df3c65590a782c3683657b75c55bdceda46dcd242e922bec8d7aceaca29d0c78.jpg", "img_caption": ["Figure 13: Illustration of the prompt for feedback. "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "E.4 The Full Result on the Apple Gastronome Benchmark ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Full Results on the Apple Gastronome Benchmark are shown in Table 5. ", "page_idx": 28}, {"type": "text", "text": "Full Results of Causal Metrics each Round of each LLM on Apple Gastronome Benchmark are shown in Table 6. ", "page_idx": 28}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/f5e3bc55a6d0ca8c58787c8c08eec5fde685039acc2c698d051cdefa53ac9a63.jpg", "table_caption": ["Table 5: Full Results on the Apple Gastronome Benchmark. "], "table_footnote": ["1DeepSeek-V2 is no more available when we add this baseline, therefore, we use DeepSeek-V2.5 instead. "], "page_idx": 28}, {"type": "text", "text": "E.5 Implementation of the FCI algorithm ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We use a third-party open-sourced Python library to perform the FCI algorithm: https://causallearn.readthedocs.io/en/latest/ ", "page_idx": 28}, {"type": "text", "text": "We set $\\alpha=0.05$ , and independence test method=\"fisherz\" hroughout all experiments.   \nOther parameters are kept as the default. ", "page_idx": 28}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/dd48a03df350bd928948b25c04df1eda243148cf8cde9039f34a755053bd4176.jpg", "table_caption": ["Table 6: Full Result of Causal Metrics each Round each LLM on Apple Gastronome Benchmark "], "table_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/62d539f692f622015324134f8991ac31af64d6ea98090f28c488284200ac0775.jpg", "img_caption": ["Figure 14: Ground truth and faithful (via FCI algorithm) causal graphs in AppleGastronome. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/5e5fc630c29e610b7acb33f0cf4e834adfe712e70a4a093876e72f2cc36c5073.jpg", "img_caption": ["Figure 15: Causal graphs with GPT 4 in AppleGastronome. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/b240559208cbff20948c2bc062597ad929811db9770ed391ed5a2ae82b1d8c92.jpg", "img_caption": ["Figure 16: Causal graphs with GPT 3.5 in AppleGastronome. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/dc04753fbaf5bc3dcba71fd1ee864bb87a24c7c21e31d1103f622baf3b116ffd.jpg", "img_caption": ["Figure 17: Causal graphs with Llama-2 in AppleGastronome. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/3f21f90acc90354770cfa736c63dbd2f0dfc82d178da5bc1564aba5c47b3ccba.jpg", "img_caption": ["Figure 18: Causal graphs with mistral Medium in AppleGastronome. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/dbdbed5ea1193c0180fd04ce547f441996b9137828d1547086e6191ff8e9cd46.jpg", "img_caption": ["Figure 19: Causal graphs with Claude-3-Opus in AppleGastronome. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/53d2a55247799c909eadbe5bc23eb52e20b9b078e6c1c1b230a1ea3477fc5daa.jpg", "img_caption": ["Figure 20: Causal graphs with DeepSeek-V2 in AppleGastronome. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/d377b410598856e0dd13f45ac6b856b821145fb4d7e471f7b4ebcc6e14ce5720.jpg", "img_caption": ["Figure 21: Causal graphs with Llama-3-70b in AppleGastronome. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/a7211d02a2ddae9fe39db0e6e29c52bae7e2b0881d434af7ebdcc8c2c0ee046b.jpg", "img_caption": ["Figure 22: Causal graphs with mistral-Large in AppleGastronome. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/62637d0fae15ded17f274f722a0d1ec59cf7c348bec26cac75d08753569c05cb.jpg", "img_caption": ["Figure 23: Causal graphs with qwen-1.5-110B in AppleGastronome. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/6d719f36bd72bbf7f666c166804230a0f5b724ab5ba1ca14234afb9bb2bb0747.jpg", "img_caption": ["Figure 24: Causal graphs with GPT-4o in AppleGastronome. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/0c481fa802a545d39bcc8fff57a6a1f47ebb862faf6096a7b48f14885bc26c14.jpg", "img_caption": ["Figure 25: Illustration of prompts for generating Neuropathic. "], "img_footnote": [], "page_idx": 36}, {"type": "text", "text": "In the Neuropathic benchmark, we convert the dataset into a clinical diagnosis task. In the original dataset, there are three levels of causal variables, including the symptom-level, radiculopathy-level and the pathophysiology-level. In experiments, we mainly consider the target variable of right shoulder impingement. When generating the clinical diagnosis notes as $\\textbf{\\em x}$ using GPT 4, we will avoid any mentioning of variables other than symptoms. ", "page_idx": 36}, {"type": "text", "text": "As we intend to leverage the Neuropathic benchmark to simulate the real-life diagnosis, after the factor proposal stage, we directly incorporate external experts that measure the values of the candidate factors. The prompts to generate the diagnosis records are given in Fig. 25. ", "page_idx": 36}, {"type": "text", "text": "Examples of Neuropathic are given in Fig. 26. ", "page_idx": 36}, {"type": "text", "text": "E.7 More Details of Results on Neuropathic ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "The detailed causal graph results are given from Fig. 27 to Fig. 31. ", "page_idx": 36}, {"type": "text", "text": "E.8 Discussion on the time complexity ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Assume there are m samples with n possible factors. ", "page_idx": 36}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/2bee7acd5877a2495f70321cab6e81e58993a069340bab121e8d398d3b9b9219.jpg", "img_caption": ["Figure 26: Illustration of examples in Neuropathic. "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/272e7c4b3bfd5e508837e5d2fea266daa2dd48f7562615b7c697dacc0c38f908.jpg", "img_caption": ["Figure 27: Ground truth and faithful (via FCI algorithm) causal graphs in Neuropathic. "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "For Factor Proposal: ", "page_idx": 37}, {"type": "text", "text": "META only needs to interact once with LLM, so it is O(1). DATA runs one single COAT round, so it is O(1). COAT interacts with LLMs multiple rounds. In each round, at least one new factor should be proposed; otherwise, the loop will stop. So it is ${\\mathrm{O}}({\\mathfrak{n}})$ For Factor Annotation: ", "page_idx": 37}, {"type": "text", "text": "META: Not applicable. DATA: At most n factors would be proposed in a single round. And each of them needs m times annotations by LLMs for all samples. So it is O(nm). COAT: At most n factors would be proposed during all rounds. And each of them needs m times annotations by LLMs for all samples. So it is ${\\mathrm{O}}({\\mathrm{nm}})$ . For Causal Discovery: ", "page_idx": 37}, {"type": "text", "text": "Pair-wise reasoning by LLMs: $\\mathrm{O}(n^{2})$ COAT: LLM is not involved. The computational cost of it depends on the numeric methods. The FCI algorithm used by COAT has a time complexity that goes exponentially with n. Learning the causal graph over a large number of nodes effectively is still an open problem in causal discovery literature. ", "page_idx": 37}, {"type": "text", "text": "E.9 Resources ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "We utilized a system comprising two Intel Xeon E5-2630v4 processors with 2.2GHz, two NVIDIA Tesla P40 GPUs, and $256\\,\\mathrm{GB}$ of memory. For conversations with large language models (LLMs), we leveraged the poe.com platform, while annotations were facilitated using the OpenAI API and the Mistral API. ", "page_idx": 37}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/a398bd305e989b19ee8714bce83543fc43783bd2ccb199eb3256a82803adda0c.jpg", "img_caption": ["(a) GPT 4 reasoning "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/48fbb23453ad4f000789a03d1c3574805bd3f8b0e9f8d416f5554f450cfdbcf7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "(b) GPT 4 COAT ", "page_idx": 38}, {"type": "text", "text": "Figure 28: Causal graphs with GPT 4 in Neuropathic. ", "page_idx": 38}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/869d817c1d34d8ce4673f17c609d0a3931dd48fa79b40e3ae52c22fc0b6f28db.jpg", "img_caption": ["(a) GPT 3.5 reasoning "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/7ee85cbdcf37154a3c8cc1fd8aae143e678c1b117af6dbfbef1bf83aabc533e7.jpg", "img_caption": ["Figure 29: Causal graphs with GPT 3.5 in Neuropathic. ", "(b) GPT 3.5 COAT "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/b7a4bde196a184b14945c323a6ed99614d1a5f05e546eb295c5ad851116c9b2a.jpg", "img_caption": ["(a) LLaMA-2-70b reasoning ", "(b) LLaMA-2-70b COAT "], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Figure 30: Causal graphs with LLaMA-2-70b in Neuropathic. ", "page_idx": 38}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/c1a5c23eeaaee5b114116a3fb70a7fc32972bd56836d8bf93f5578f21d7c6d28.jpg", "img_caption": ["(a) Mistral-Medium reasoning "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/cc8a6b976833765b4f2261b026247486c488b2ec1c229a5a998568840b3a3528.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "(b) Mistral-Medium COAT ", "page_idx": 38}, {"type": "text", "text": "Figure 31: Causal graphs with Mistral-Medium in Neuropathic. ", "page_idx": 38}, {"type": "text", "text": "F COAT with Different Causal Discovery Algorithm ", "text_level": 1, "page_idx": 39}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/b73ea8b56c4a6e149cb05902089d2bc91738720c88bec95e89ec7b8d3e37a1a0.jpg", "table_caption": ["Table 7: Causal discovery results in Neuropathic. PA, AN, and OT refer to the parents, ancestors, and others, respectively. Accuracy and F1 measure the recovery of the causal ancestors. "], "table_footnote": [], "page_idx": 39}, {"type": "text", "text": "G Ablation Study ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Group Size in Prompt. In the COAT prompt, several samples are given and grouped by the values of the target variable. The samples in each group are randomly selected to a fixed number (like 3 samples per group). Empirically, we keep it to be 3 throughout all experiments (sometimes smaller than 3 if samples are not enough). In practice, it is mainly constrained by the LLM\u2019s context length. ", "page_idx": 39}, {"type": "text", "text": "The Number of Clusters. When constructing feedback, we first use clustering to separate the dataset and then find the cluster where the target variable is not explained well by current factors (This is a heuristic for the problem in line 191). Empirically, we set the number of clusters to be one plus the number of current factors. ", "page_idx": 39}, {"type": "text", "text": "We conduct ablation studies of COAT with GPT-4 using different hyperparameters: ", "page_idx": 39}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/3fad9ef05080ab00e881a81e65a6ee29763de7bf83fffc95113d424346146946.jpg", "table_caption": ["Table 8: Results about Ablation Study on Hyperparameters. "], "table_footnote": [], "page_idx": 39}, {"type": "text", "text": "As shown in Table 8, one can observe that COAT is not sensitive to these hyperparameters and performs robustly well than the baselines under different hyperparameter setups. ", "page_idx": 39}, {"type": "text", "text": "Prompt Template. We conduct an ablation study with a different prompt template following [101]: ", "page_idx": 39}, {"type": "text", "text": "\u2022 We put the task description (also the format instructions) in the beginning [System] part, and we put samples in the last [Data] part of the prompt.   \n\u2022 The markdown grammar is replaced by blankets to represent headings, like [System] , [Data] , and [Groups with $\\mathsf{Y}\\!=\\!1\\,\\mathsf{J}$ ...   \n\u2022 3 COAT iterations are performed, which is aligned with the original experimental setup. ", "page_idx": 40}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/3c6d20d60f2550dc72f71a41e9034f5dff6729ecbb3b2f4e5f4eaf9e36725cd7.jpg", "table_caption": ["TABLE 9: COAT WITH CHANGED PROMPT TEMPLATE "], "table_footnote": [], "page_idx": 40}, {"type": "text", "text": "In Table 9, we observe that COAT is robust to the choice of templates, rejects unexpected factors (zero NMB and OT), and keeps a high precision. ", "page_idx": 40}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/bd908e85334151504d76de8fb7921e2135b8961ced25be6b67d312c1cd58617f.jpg", "img_caption": ["(a) Faithful ground truth "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/072f63dd33669c51b7016aa37a4eaaa9cce071806a713e438fbd207b10bbf522.jpg", "img_caption": ["(b) GPT-4 COAT with LiNGAM "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/0198316a144cbf7579e37d878bf714eb7a90639856ea4d23c6bed5372433670a.jpg", "img_caption": ["(c) GPT-3.5 COAT with LiNGAM "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/9c5e5513d9d6f63d448fa8eafa6fae0f2839df702e4ce6dbfdbbbfe46d5bb51c.jpg", "img_caption": ["(d) llama-2-70b COAT with LiNGAM "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/bf0bd0cbf0366fa612cc1a4ce5ab9b7fcbacfd4a09a5740d458ccbf8df8deaa4.jpg", "img_caption": ["(e) Mistral-med COAT with LiNGAM "], "img_footnote": [], "page_idx": 41}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/49934d22032d8c9235c0e104f7df4853be7036381350ab508aebcecd48981474.jpg", "table_caption": ["H Summary of Benchmark Data ", "Table 10: Summary of Benchmark Data "], "table_footnote": [], "page_idx": 42}, {"type": "text", "text": "I Case Study on Brain Tumor ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "In this section, we utilize the COAT to explore the image dataset. ", "page_idx": 42}, {"type": "text", "text": "I.1 The Brain Tumor Dataset ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Dataset Magnetic Resonance Imaging (MRI) is an important technique for detecting tumors in the human brain. The images are from an open Kaggle dataset (kaggle/brain-tumor-classification-mri) with an open-sourced project. [38]. Each sample is a scanning MRI of a human brain. In this case study, the interesting variable is the tumor type. We consider three types of MRI images: glioma, meningioma, and no tumor. We include 20 images for each category and the total sample size is 60. ", "page_idx": 42}, {"type": "text", "text": "Data Processing We use gpt-4-vision-preview to handle image samples. As the current gpt4 cannot process multiple images simultaneously, we concatenate samples from different categories into one picture, as shown in Fig. 33, and give instructions in the prompt to explain the format, as shown in Fig. 34. For each proposed factor, the LLMs would go through all 60 sample images individually to evaluate the factor value. ", "page_idx": 42}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/ac3bcaa490d8409db13f207c76e965b6c72d5abe172c2b0c1998ede9bd0f0dcc.jpg", "img_caption": ["Figure 33: The initial input to COAT in the Brain Tumor case study. Each row contains 5 samples randomly selected from one category (top-down: glioma, meningioma, and no tumor). "], "img_footnote": [], "page_idx": 43}, {"type": "text", "text": "Evaluation The ground truth is not directly available to this dataset. Therefore, each factor in the final result will be evaluated by searching the related literature and will be explained by human interpretation. ", "page_idx": 43}, {"type": "text", "text": "I.2 Result and Discussion ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Result interpretation As shown in Fig. 35, there are two visual factors that appeared in the final causal graph: contrast enhancement and mass effect. The first factor (contrast enhancement) is about whether the bright part is uniform or heterogeneous in the sample image. Another factor (mass effect) is about whether the tumor tissue has caused significant displacement of normal brain structures. One may refer to Fig. 36 to see detailed descriptions of these two factors. ", "page_idx": 43}, {"type": "text", "text": "Justification for the final factors We verify the proposed factors by the medical literature [102, 103, 104, 105], as shown Fig. 37. Note that these papers are searched according to keywords in factor descriptions and, therefore, can exclude some relevant studies. Therefore, the conclusions of this preliminary exploration should be considered a reference point for further in-depth validation by domain experts. ", "page_idx": 43}, {"type": "text", "text": "The factor description for contrast enhancement directly matches with the related paper (the first two papers displayed in Fig. 37). In addition, this can be visually checked in Fig. 33. Therefore, we believe it is a good factor. ", "page_idx": 43}, {"type": "text", "text": "The second factor, mass effect, may not directly match the papers. It is pointed out in the last two papers displayed in Fig. 37 that the two tumors have different axial locations and thus influence the magnitude of the displacement of tissues. Both the keywords \u201daxial location\u201d and \u201ddisplacement\u201d have occurred in its factor description. ", "page_idx": 43}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/30fc07f08c80e242c4d69a4b7dca8682af888f2f9e10c6c06d4124f3653d25d3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 44}, {"type": "text", "text": "Figure 34: Illustration of the prompt for the Brain Tumor case study. It contains instructions about understanding the combined input picture. ", "page_idx": 44}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/2002224ff76e4743e4fd7beb4fad17c3238d57c8deecae226e19bcf7e050418b.jpg", "img_caption": ["Figure 35: Final causal graph by COAT in the Brain Tumor case study. "], "img_footnote": [], "page_idx": 44}, {"type": "text", "text": "J Case Study on Stock News ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "In this section, we utilize COAT to explore time series data with text. ", "page_idx": 44}, {"type": "text", "text": "J.1 The Stock News Dataset ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Dataset The dataset consists of the stock value of Microsoft (MSFT) from 2006 to 2009 and its news summary (only include news in the New York Times). This is a subset of an open Kaggle dataset (kaggle/stock-price-and-news-realted-to-it). Each sample is one trading day with the company\u2019s close stock price and news. The target value is the future return rate, and we are curious about factors in the related news. We fed data during the first 200 trading days to COAT, and we used the following 400 trading days for evaluation. ", "page_idx": 44}, {"type": "text", "text": "Data processing The future return rate is calculated by close prices: ", "page_idx": 44}, {"type": "equation", "text": "$$\nr_{t}={\\frac{\\mathrm{close}_{t+4}}{\\mathrm{close}_{t}}}-1.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "The target value is a binary variable according to the return rate ", "page_idx": 44}, {"type": "equation", "text": "$$\nY_{t}=\\mathbf{1}_{r_{t}>0},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where ${\\mathbf{1}}_{A}$ is the indicator function. News fed to COAT are grouped according to the value of $Y_{t}$ . To keep the whole prompt within the context limit, only 3 samples would be randomly included in each group. ", "page_idx": 44}, {"type": "text", "text": "Factor processing Given one proposed factor, denote its annotated value at the $t$ -th trading day as $a_{t}\\in\\{-1,0,1\\}$ . Each factor is rolling averaged over the past $M$ days: ", "page_idx": 44}, {"type": "equation", "text": "$$\nS_{t}=\\frac{1}{M}\\sum_{t-M\\geq i\\geq t}a_{i}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/2bfbddf508fc8909688aeb075c1bb63a59cb4e42349cd2543aa643f55ca90ff6.jpg", "img_caption": [], "img_footnote": [], "page_idx": 45}, {"type": "text", "text": "Figure 36: Detailed descriptions of these two final factors in the Brain Tumor case study. These descriptions were also directly fed to LLMs for factor annotation on images. ", "page_idx": 45}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/7e5bd3aeb5d34bc3a3c46a1d8e294bafab69bdbf7aabd08aed4eb5aa8e653bbe.jpg", "img_caption": ["Figure 37: Medical literature about the brain tumor. Searched according to keywords in factor descriptions. "], "img_footnote": [], "page_idx": 45}, {"type": "text", "text": "Each variable, including return rate, is normalized by the rolling standard deviation over the past $M$ days: ", "page_idx": 45}, {"type": "equation", "text": "$$\nF_{t}=\\frac{1}{\\operatorname{Sd}\\left(\\left\\{S_{i}\\right\\}_{t-M\\geq i\\geq t}\\right)+1}S_{t}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "An example of a processed factor can be seen in Fig. 38. ", "page_idx": 45}, {"type": "text", "text": "J.2 Result and Discussion ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Result Causal Graph As shown in Fig. 39, four factors are identified in the final causal graph to form a Markov blanket of return rate: Product Focus, Legal and Regulatory Issues, Market Strategy, and Innovation and Technology Focus. One can refer to Fig. 40 for more detailed descriptions of these factors. One factor (Innovation and technology focus) is identified as a possible cause of the return rate; this matches the nature of the company\u2019s type and reflects people\u2019s expectation of the company to keep creating innovative computer software. It is also interesting to see that COAT captures the structure between factors and market strategy, where product focus and legal and regulatory issues are identified as potential causes. It also implies the existence of a latent confounder between market strategy and return rate that may not be significantly reflected in news text. ", "page_idx": 45}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/439c6c450851d27474bfef6577e0cb271476ceeac7cab8f02eba17cdecfea3ef.jpg", "img_caption": ["Figure 38: Example of one processed factors Innovation and Technology Focus during the first 200 trading days. The red star marks the highest value. In June 2007, there was a discussion about future competition in desktop operating systems and the trend towards web-based services [106]. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/c9d5424316ad6d9de3b6823b15d35b6485f940b1f4786d437574352fd3476154.jpg", "img_caption": ["Figure 39: The final causal graph by COAT in the Stock News case study "], "img_footnote": [], "page_idx": 46}, {"type": "text", "text": "Evaluation by Trading Strategies For each factor $\\{F_{t}\\}$ processed in Eq. 27, we establish a trading strategy on it to see the performance in the out-of-sample trading days. At each trading day $t$ , we fti the following model ", "page_idx": 46}, {"type": "equation", "text": "$$\nr_{t}=\\alpha+\\beta F_{t},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "using samples $\\{r_{i},F_{i}\\}_{t-200\\leq i<t}$ . Note that $r_{t}$ is the future return rate defined in Eq. 24 and is not available on this day. After the estimation, we make decision based on $\\hat{r}_{t}:=\\hat{\\alpha}+\\hat{\\beta}F_{t}$ . If $\\hat{r}_{t}>0$ , we go long with 1 unit capital, i.e., purchase that amount of stock, the gain would be gain would be $r\\times1$ units capital. If $\\hat{r}_{t}<0$ , we go short with 1 unit capital, i.e., borrow and sell that amount of stocks immediately and buy them back next time, the gain would be $-r\\times1$ units capital. ", "page_idx": 46}, {"type": "text", "text": "To align with the definition in Eq. 24, we make trading decisions every 4 trading day. We introduce an additional Buy and Hold baseline to always go long one unit capital. The trading evaluation is after the 200-th day and thus has no overlapping with data fed to COAT. ", "page_idx": 46}, {"type": "text", "text": "The cumulative return plot is shown in Fig. 41, and the metrics commonly used in economic literature [107, 108, 109] are shown in Table 11. One important metric to see a trading strategy\u2019s effectiveness is the sharp ratio: a measure of risk-adjusted return, showing the excess return (over the risk-free rate, we set it to be $2\\%$ ) per unit of standard deviation. A higher Sharpe ratio indicates better performance per unit of risk. We see that the Innovation and Technology Focus factor yields the highest sharp ratio and outperforms other non-causal factors. ", "page_idx": 46}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/ca0d5a0cdff35da7161f241a1e8ea2b876d0f44259bfe0c81bae32c3d21c3069.jpg", "img_caption": [], "img_footnote": [], "page_idx": 47}, {"type": "text", "text": "Figure 40: The detailed factor descriptions proposed by COAT in the Stock News case study ", "page_idx": 47}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/887cbb729dc1449bd9fa3a90ce2db0967a3d581e0adc48f9eefbc596b4b023fb.jpg", "img_caption": ["Figure 41: The out-of-sample cumulative return of trading strategies based on different factors in the Stock News case study "], "img_footnote": [], "page_idx": 47}, {"type": "table", "img_path": "w50ICQC6QJ/tmp/80fe754a3d4ff36f4180caa0ca3f8385df2bf90ec35f53d1e41c0d5967419fef.jpg", "table_caption": ["Table 11: Performance about trading strategy according to each factors "], "table_footnote": [], "page_idx": 47}, {"type": "text", "text": "K Case Study on El Ni\u02dcno\u2013Southern Oscillation (ENSO) ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "In this section, we use COAT to explore a scientific problem using open datasets in climate science.   \nThe case study shows its potential to handle more complex data formats when combined with tools. ", "page_idx": 48}, {"type": "text", "text": "The ENSO Background El Nin\u02dco-Southern Oscillation (ENSO) is an important phenomenon in the Pacific Ocean and is characterized by irregular fluctuations in sea surface temperatures[110]. ENSO consists of the warm phase (known as El Nin\u02dco) and the cold phase (known as La Nin\u02dca). It profoundly influences global weather patterns, including precipitation, storm development, and temperature anomalies [111]. The prediction of ENSO events involves the complex interplay between oceanic and atmospheric systems and, therefore, is still an open problem [112, 113]. ", "page_idx": 48}, {"type": "text", "text": "NOAA Dataset The NOAA 20th Century Reanalysis V3 dataset contains high-dimensional information about Earth\u2019s atmosphere with fine-grained time and space coverage from the 19th century to the early 21st century [40]. This dataset amalgamates many observational data and uses the ensemble fliter data assimilation method to reconstruct the historical state of the global atmosphere. The dataset includes a fine-grained spatial coverage with $360\\times181$ grids. We only use monthly data in this case study. ", "page_idx": 48}, {"type": "text", "text": "K.1 Setting and Data processing ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "The Target Variable Construction The focus of this study is the future change in monthly SST in the Nino3 region, which could be an important indicator of ENSO events. The target variable is manually crafted from the dataset using API and is visualized in Fig. 42, where the oscillation pattern can be seen. ", "page_idx": 48}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/23732b8998d991937074c4a4efe1f7f3ecd3724197db926fa94c02316e062dc6.jpg", "img_caption": ["Listing 1: Code to define the target variable in ENSO case study "], "img_footnote": [], "page_idx": 48}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/b2bae3b27415776ed51adce83f94338f0590681389c7416aecf637b7b7bf91ba.jpg", "img_caption": [], "img_footnote": [], "page_idx": 48}, {"type": "text", "text": "Figure 42: The visualization of the target variable defined in the ENSO case study. The oscillation pattern can be seen. ", "page_idx": 48}, {"type": "text", "text": "Prepare Tools for LLMs The dataset is in the NetCDF format (network Common Data Format), so it is not convenient to be directly fed to LLMs. We prepare a function Observation(measurement , level, region) to help define factors. For example, in Lst. 1, we define the target variable with the help of this function. The measurement specifies the climate variables like precipitation rate or temperature; the level specifies the vertical location, like surface or specific pressure level; the region is a rectangle about the area concerned. This function would output a single time series about the measurement on the specified level averaged within the specified region. Note that the target variable is the only factor defined by humans, all other factors are defined by code from LLMs. ", "page_idx": 48}, {"type": "text", "text": "", "page_idx": 49}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/864a6fa212b327efd4bc418f659864fc2bf92c2098416e08bbda8e81c975c27f.jpg", "img_caption": ["Listing 2: LLM can be prompted to propose factors using complex tools "], "img_footnote": [], "page_idx": 49}, {"type": "text", "text": "Feedback Construction The dataset is in a special format; we can only draw a tabular subset of data from it in this setting. Therefore, it is difficult to make groups on samples like what we did in the previous cases. Instead, we construct feedback with some summary information. As shown in Fig. 43, two types of information are included in the feedback: intermediate causal graph and OLS regression result of factors in the current estimation of a Markov blanket on the target variable. These two types of information can be drawn naturally from the COAT\u2019s intermediate results and are not complex, so LLMs can always access them and easily understand them. Intuitively, these factors would help LLMs better understand existing factors and propose further possible factors based on the provided dataset and its knowledge. ", "page_idx": 49}, {"type": "text", "text": "K.2 Causal Graph and Discussion ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Result Interpretation In this case study, we are treating non-stationary climate data, while assuming the causal structure is invariant. Under this assumption, the non-stationarity is actually helpful for causal structure learning [51, 114]. To this end, we utilize the CD-NOD algorithm [51] to fully utilize the changing causal modules for better identifiability. CD-NOD would first identify the non-stationary nodes, whose conditional distribution given the causal parents are changing with time, and then use them for better causal structure recovery. Four factors are identified to be non-stationary, as shown in Fig. 44. ", "page_idx": 49}, {"type": "text", "text": "We have adjusted the nodes\u2019 names, shapes, and colors for better visualization. There are 14 nodes in total, with 13 factors identified by COAT. Each factor is a time series about a certain climate measurement above a specific level averaged over a specific region. For simplicity, we only considered instantaneous causal relations among those time series. ", "page_idx": 49}, {"type": "text", "text": "There are three regions identified to be relevant to the ENSO phenomenon: ", "page_idx": 49}, {"type": "text", "text": "\u2022 Equatorial Pacific Region (Orange Nodes). This region (5N-5S, 120W-280W) is one of the most active places about ENSO. It becomes significantly warm during the El Nin\u02dco phase and becomes significantly cold during the La Ni\u02dcna phase [115].   \n\u2022 Nino3 Region (Blue Nodes). This region (5N-5S, 150W-90W) is one of the most classical regions to monitor the El Ni\u02dcno events by scientists. It is also used by humans to construct the target variables [110]. ", "page_idx": 49}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/54c966f30d38483dafebb355c9adefbf582284b919ed6100904642f0b8b2126f.jpg", "img_caption": ["Figure 43: The prompt with feedback based on previous loop in the ENSO case study "], "img_footnote": [], "page_idx": 50}, {"type": "text", "text": "\u2022 South American Coastal Region (Green Nodes). This region (0N-20S, 80W-60W) includes the Peruvian coastal up-welling system, and is noticed to be relevant to the ENSO cycle [116]. ", "page_idx": 50}, {"type": "text", "text": "Some insights are delivered by paths in the output causal graph: ", "page_idx": 50}, {"type": "text", "text": "\u2022 Sea level Pressure. This factor is about the sea-level pressure on the equatorial Pacific region. The pressure gradient would influence the movement of warm water, and thus influence the sea surface temperature (SST) change [41]. In addition, pressure can influence the water evaporation and thus regulate through the water circulation. This also matches another indirect path Sea level Pressure $\\rightarrow$ Sensible Heat Net Flux $\\rightarrow$ Volumetric Soil Moisture $\\rightarrow$ Cloud Cover $\\rightarrow S S\\mathrm{T}$ Change.   \n\u2022 Momentum Flux, V-compoent. This factor is about the vertical movement of air. It is crucial in driving atmospheric convection [41], and it is related to the Walker Circulation, which is an important component in the ENSO system[42]. Also, it could influence the change in sea level pressure and indirectly influence the SST change.   \n\u2022 Cloud Cover. The factor is the fraction of the sky covered by clouds in the NINO3 region. It could influence the SST Change through solar radiation as well as water circulation. It is confirmed to have a significant correlation [43] with ENSO events and plays an important role in the atmospheric circulation and hydrological cycle [44].   \n\u2022 Soil Temperature. This might be a novel hypothesis proposed by COAT, since we found no sufficient research to confirm this point to the best of our knowledge. This causal graph has also suggested two possible indirect mechanisms: (1) through Volumetric Soil Moisture and Cloud Cover; and (2) through Convective Precipitation Rate and Sea Level Pressure.   \nTherefore, this finding encourages more serious investigations of these hypotheses. ", "page_idx": 50}, {"type": "text", "text": "", "page_idx": 51}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/02bf92f247f55fb33bce080116375b073749c5aa101a494be353c217c0648e78.jpg", "img_caption": ["Figure 44: The final causal graph found by COAT in the ENSO case study "], "img_footnote": [], "page_idx": 51}, {"type": "text", "text": "Discussion on Additional assumption The constructed feedback contains the causal structure among existing factors and their OLS regression analysis on the target variable. By doing so, some additional assumptions are implicitly made. For example, it assumes a linear relation between factors and the target variables. More detailed theoretical analysis is out of the scope of this case study, and we left it for future work. ", "page_idx": 51}, {"type": "text", "text": "Discussion on Hallucination Although we have clarified how to use tools in prompts, LLM can sometimes propose unsupported data requests. For example, only certain pressure levels are supported in the dataset. To this end, we include a Python code in the prompt, as listed in Lst. 3. This function can check whether the LLM\u2019s request is supported. We ask LLM to run this function in its code interpreter to make sure the proposed factors are valid. ", "page_idx": 51}, {"type": "image", "img_path": "w50ICQC6QJ/tmp/70f9c6bacc524f78134180ed8606c700d1e9f02dccd81052648a20b0a53bcd04.jpg", "img_caption": ["Listing 3: LLM is required to use this function to overcome hallucination "], "img_footnote": [], "page_idx": 52}, {"type": "text", "text": "L Broader Impacts ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "This work focuses on fully leveraging the rich knowledge learned by LLMs during pre-training to facilitate causal discovery from unstructured data, with the hope of empowering broader applications and social benefits. Besides, this paper does not raise any ethical concerns. This study does not involve any human subjects, practices to data set releases, potentially harmful insights, methodologies and applications, potential confilcts of interest and sponsorship, discrimination/bias/fairness concerns, privacy and security issues, legal compliance, and research integrity issues. ", "page_idx": 52}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 53}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 53}, {"type": "text", "text": "Justification: See the end of the introduction part. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 53}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 53}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Justification: See Sec. 2.5 and Appendix B. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 53}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 53}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 53}, {"type": "text", "text": "Justification: see Appendix D. ", "page_idx": 54}, {"type": "text", "text": "Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 54}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 54}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 54}, {"type": "text", "text": "Justification: See Appendix E. Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 54}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 54}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Justification: https://causalcoat.github.io/ ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 55}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 55}, {"type": "text", "text": "Justification: See Sec. 3.1, Sec. 4.1 and Appendix E. Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 55}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Justification: Standard Deviations are included. ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 55}, {"type": "text", "text": "", "page_idx": 56}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 56}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 56}, {"type": "text", "text": "Justification: See Appendix E.9. ", "page_idx": 56}, {"type": "text", "text": "Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 56}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 56}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 56}, {"type": "text", "text": "Justification: Authors follow the NeurIPS Code of Ethics. ", "page_idx": 56}, {"type": "text", "text": "Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 56}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 56}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 56}, {"type": "text", "text": "Justification: See the Appendix L. ", "page_idx": 56}, {"type": "text", "text": "Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 56}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 57}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 57}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 57}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 57}, {"type": "text", "text": "Justification: No sensitive or risky content is included in this paper. ", "page_idx": 57}, {"type": "text", "text": "Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 57}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 57}, {"type": "text", "text": "Justification: See Appendix H. Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 57}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 57}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: See Appendix H. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 58}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 58}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 58}, {"type": "text", "text": "Justification: not involve crowdsourcing nor research with human subjects. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 58}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 58}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 58}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 58}]