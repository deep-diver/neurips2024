[{"figure_path": "RPM7STrnVz/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative Results of Video Generation with Compositional Prompts", "description": "This table presents a quantitative comparison of different text-to-video (T2V) models on video generation with compositional prompts.  The models are evaluated using three metrics: VBLIP-VQA, VUnidet, and CLIP-SIM.  VBLIP-VQA and VUnidet measure the accuracy and detail of the generated videos concerning the compositional aspects described in the prompts. CLIP-SIM measures the visual consistency of the generated video sequence.  The table shows that VideoTetris (Ours) achieves the highest scores across all three metrics, outperforming existing methods.", "section": "4.3 Video Generation with Compositional Prompts"}, {"figure_path": "RPM7STrnVz/tables/tables_8_1.jpg", "caption": "Table 2: Quantitative Results of Long Video Generation for Progressive Compositional Prompts", "description": "This table presents a quantitative comparison of three different methods for long video generation with progressive compositional prompts.  The methods compared are FreeNoise [10], StreamingT2V [11], and the authors' proposed VideoTetris. The metrics used for comparison are VBLIP-VQA, VUnidet, and CLIP-SIM.  Higher scores indicate better performance.", "section": "4.4 Long Video Generation for Progressive Compositional Prompts"}, {"figure_path": "RPM7STrnVz/tables/tables_8_2.jpg", "caption": "Table 3: Quantitative Comparison of Ablation Study.", "description": "This table presents a quantitative comparison of the ablation study conducted on VideoTetris.  It compares the performance of the full VideoTetris model against versions without the Reference Frame Attention component and against the baseline methods FreeNoise and Streaming T2V.  The metrics used for comparison are MAWE (Motion-Aware Weighted Error), CLIP (CLIPScore), AE (Attribute Error), and CLIP-SIM (CLIP Similarity). Lower MAWE and higher CLIP, AE, and CLIP-SIM scores indicate better performance.", "section": "4.5 Ablation Study"}, {"figure_path": "RPM7STrnVz/tables/tables_16_1.jpg", "caption": "Table 7: Ablation Studies for Spatio-Temporal Compositional Diffusion", "description": "This table presents the results of ablation studies conducted to evaluate the effectiveness of different components of the proposed Spatio-Temporal Compositional Diffusion method.  It compares the performance of the VideoTetris model with variations in the decomposition and composition methods, using metrics such as VBLIP-VQA, VUnidet, and CLIP-SIM.  The results highlight the importance of the proposed decomposition and composition strategies for achieving state-of-the-art performance in compositional video generation.", "section": "A.3 Ablations about Effect of Spatio-Temporal Compositionl Diffusion"}, {"figure_path": "RPM7STrnVz/tables/tables_17_1.jpg", "caption": "Table 8: Hyperparameters of VideoTetris", "description": "This table lists the hyperparameters used in the VideoTetris model.  It is divided into three sections: Dynamic-Aware Data Filtering, Diffusion Training, and Reference Frame Attention. Each section details specific parameters, such as thresholds for optical flow scores, the type of noise scheduler used during diffusion training, and the dimensions of convolutional layers within the reference frame attention module. These hyperparameters are crucial for controlling the behavior and performance of the VideoTetris model.", "section": "4 Experiments"}]