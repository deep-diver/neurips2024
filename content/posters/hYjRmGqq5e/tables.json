[{"figure_path": "hYjRmGqq5e/tables/tables_6_1.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the test returns achieved by the proposed A2PO method and several baseline algorithms across various Gym tasks in the D4RL benchmark.  The results represent the average normalized scores at the final training iteration, with \u00b1 indicating the standard deviation across five different random seeds.  The bolded values highlight the best-performing algorithm for each task.", "section": "5.2 Comparison on D4RL Benchmarks"}, {"figure_path": "hYjRmGqq5e/tables/tables_6_2.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the experimental results of the proposed A2PO algorithm and various baseline methods on the D4RL Gym tasks.  It shows the average test return (with standard deviation) achieved by each method across five random seeds. The best performing method for each task is highlighted in bold. The results are normalized scores from the final training iteration, illustrating the performance of each algorithm after training completion. ", "section": "5.2 Comparison on D4RL Benchmarks"}, {"figure_path": "hYjRmGqq5e/tables/tables_13_1.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the test returns achieved by the proposed A2PO method and several baseline methods on various Gym tasks within the D4RL benchmark.  The results are based on five random seeds, and the \u00b1 values represent one standard deviation of the performance across those seeds.  The performance is evaluated using the normalized score from the last training iteration. The best performance for each task is highlighted in bold.", "section": "5.2 Comparison on D4RL Benchmarks"}, {"figure_path": "hYjRmGqq5e/tables/tables_15_1.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the test returns achieved by the proposed A2PO method and several baseline algorithms across different Gym tasks within the D4RL benchmark.  The results are averaged across five random seeds, with \u00b1 representing the standard deviation.  The performance metric is the normalized score obtained at the final training iteration.  The best performing algorithm for each task is shown in bold.", "section": "5.2 Comparison on D4RL Benchmarks"}, {"figure_path": "hYjRmGqq5e/tables/tables_15_2.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the test returns of the proposed A2PO method and several baseline algorithms on four different Gym tasks from the D4RL benchmark.  The results are averaged over five random seeds, and the \u00b1 values represent the standard deviation. The performance metric is the normalized score at the final training iteration. The best performance for each task is highlighted in bold.", "section": "5.2 Comparison on D4RL Benchmarks"}, {"figure_path": "hYjRmGqq5e/tables/tables_16_1.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the test returns of the proposed A2PO algorithm and several baseline algorithms on various Gym tasks from the D4RL benchmark.  The results are averaged over 5 random seeds, and the \u00b1 values represent one standard deviation.  The performance metric used is the normalized score obtained at the final training iteration.  Bold numbers highlight the best performance for each task.", "section": "5.2 Comparison on D4RL Benchmarks"}, {"figure_path": "hYjRmGqq5e/tables/tables_17_1.jpg", "caption": "Table 7: Test returns of A2PO with CVAE policy or agent policy.", "description": "This table compares the performance of two policies: the CVAE policy and the agent policy, across various tasks and datasets.  The CVAE policy uses a Conditional Variational Auto-Encoder (CVAE) to generate actions, while the agent policy is learned by the Advantage-Aware Policy Optimization (A2PO) algorithm. The results show that the A2PO agent policy generally outperforms the CVAE policy, demonstrating the effectiveness of the A2PO algorithm in learning effective control policies.", "section": "5.3 Ablation Analysis"}, {"figure_path": "hYjRmGqq5e/tables/tables_18_1.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the test returns achieved by the proposed A2PO method and various baseline methods across different Gym tasks in the D4RL benchmark.  The results are averaged over 5 random seeds, and the \u00b1 values represent the standard deviation.  The performance metric is the normalized score obtained at the final training iteration.  Bold values highlight the best-performing method for each task.", "section": "5.2 Comparison on D4RL Benchmarks"}, {"figure_path": "hYjRmGqq5e/tables/tables_18_2.jpg", "caption": "Table 1: Test returns of our proposed A2PO and baselines on the Gym tasks. \u00b1 corresponds to one standard deviation of the performance on 5 random seeds. The performance is measured by the normalized scores at the last training iteration. Bold indicates the best performance in each task.", "description": "This table presents the test returns achieved by the proposed A2PO method and several baseline algorithms across different Gym tasks within the D4RL benchmark.  The results are averaged over five random seeds, with the \u00b1 values representing one standard deviation. The performance metric used is the normalized score at the final training iteration.  The best performance for each task is highlighted in bold.", "section": "5.2 Comparison on D4RL Benchmarks"}]