[{"figure_path": "3lQgEPRxeu/tables/tables_1_1.jpg", "caption": "Table 1: This table summarizes the different model-based and model-free state-of-the-art algorithms available in the literature for average reward CMDPs. We note that our proposed algorithm is the first to analyze the regret and constraint violation for average reward CMDP with general parameterization. Here, the parameter d refers to the dimension of the feature map for linear MDPs.", "description": "This table compares several state-of-the-art algorithms for solving infinite-horizon average reward constrained Markov Decision Processes (CMDPs).  It contrasts their regret (difference between the achieved and optimal average reward) and constraint violation, indicating whether the algorithms are model-free (meaning they do not require an explicit model of the environment) and the type of policy parameterization (tabular, linear, or general). The table highlights that the proposed algorithm in the paper is novel in its analysis of regret and constraint violation for average reward CMDPs with general policy parameterization, which is a more challenging problem setting.", "section": "1 Introduction"}]