{"references": [{"fullname_first_author": "Sanjeev Arora", "paper_title": "Implicit regularization in deep matrix factorization", "publication_date": "2019-12-01", "reason": "This paper is foundational for understanding the implicit regularization phenomenon in deep learning, which this paper builds on and extends to stochastic settings."}, {"fullname_first_author": "Qianxiao Li", "paper_title": "Stochastic modified equations and dynamics of stochastic gradient algorithms i: Mathematical foundations", "publication_date": "2019-07-01", "reason": "This paper provides the mathematical framework for analyzing SGD as a stochastic differential equation, which is crucial to the theoretical results in this paper."}, {"fullname_first_author": "Zhiyuan Li", "paper_title": "Reconciling modern deep learning with traditional optimization analyses: The intrinsic learning rate", "publication_date": "2020-12-01", "reason": "This paper offers a unique perspective on the learning rate in deep learning, which is closely related to the concept of noise equilibrium discussed in this paper."}, {"fullname_first_author": "Daniel Kunin", "paper_title": "Neural mechanics: Symmetry and broken conservation laws in deep learning dynamics", "publication_date": "2020-12-01", "reason": "This paper studies the role of symmetry and conservation laws in deep learning, setting the stage for the symmetry analysis in this paper."}, {"fullname_first_author": "Andrew M Saxe", "paper_title": "Exact solutions to the nonlinear dynamics of learning in deep linear networks", "publication_date": "2013-12-01", "reason": "This paper provides exact solutions to the dynamics of deep linear networks, which helps to validate the theoretical findings of this paper in a simplified setting."}]}