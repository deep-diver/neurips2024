[{"figure_path": "kCabCEhQWv/figures/figures_0_1.jpg", "caption": "Figure 1: Neural Isometries find latent spaces where complex transformations become tractable.", "description": "The figure illustrates the core idea of Neural Isometries.  It shows how complex transformations in the observation space (e.g., images) are mapped to a latent space where the relationships between transformed encodings become tractable, represented as isometries. The input is transformed by an unknown transformation 'T', which results in a transformed output T\u03c8. Both the original and transformed outputs are encoded, using Encoder E, into latent representations. The relationship between these latent representations in the latent space is an Isometry, a transformation preserving distances and angles. This isometry makes it significantly easier for subsequent equivariant neural networks to handle these latent representations. The figure highlights the key advantage of Neural Isometries: transforming complex observation space transformations into simpler, tractable isometries in a latent space.", "section": "1 Introduction"}, {"figure_path": "kCabCEhQWv/figures/figures_2_1.jpg", "caption": "Figure 2: Overview of Neural Isometries (NIso). NIso learn a latent space where transformations of observations manifest as isometries, achieved by regularizing the functional maps \u03c4 between latents to commute with a learned operator \u03a9, parameterized via its spectral decomposition into a mass matrix M, eigenfunctions \u03a6, and eigenvalues A (sec. 4.1). Given two observations \u03c8 and T\u03c8 related by some unknown transformation T (in this case, camera motion in a 3D scene), they are first encoded into latent functions E(\u03c8) and E(T\u03c8) and projected into the operator eigenbasis. An isometric functional map \u03c4\u03a9 is estimated between them, and used to map one to the other. Losses promote isometry-equivariance in the latent space, reconstruction of transformed latents, and distinct, low-multiplicity eigenvalues A, with the latter encouraging a diagonal as possible \u03c4\u03a9. An optional spectral dropout layer can be applied before the basis unprojection to encourage a physically meaningful ordering of the learned spectrum (sec. 4.2).", "description": "This figure illustrates the Neural Isometries (NIso) framework.  It shows how NIso learns a latent space where transformations in the input space (e.g., images) are represented as isometries (distance-preserving transformations) in the latent space.  The process involves encoding input observations into latent functions, projecting them into an eigenbasis defined by a learned operator, estimating an isometric functional map between them, and then reconstructing transformed observations.  Losses are used to enforce isometry equivariance in the latent space, accurate reconstruction of transformed data, and distinct eigenvalues of the learned operator to encourage a sparse, block diagonal isometric functional map.  An optional spectral dropout layer can improve the ordering of the eigenvalues.", "section": "Method Overview"}, {"figure_path": "kCabCEhQWv/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of Neural Isometries (NIso). NIso learn a latent space where transformations of observations manifest as isometries, achieved by regularizing the functional maps \u03c4 between latents to commute with a learned operator \u03a9, parameterized via its spectral decomposition into a mass matrix M, eigenfunctions \u03a6, and eigenvalues A (sec. 4.1). Given two observations \u03c8 and T\u03c8 related by some unknown transformation T (in this case, camera motion in a 3D scene), they are first encoded into latent functions E(\u03c8) and E(T\u03c8) and projected into the operator eigenbasis. An isometric functional map \u03c4\u03a9 is estimated between them, and used to map one to the other. Losses promote isometry-equivariance in the latent space, reconstruction of transformed latents, and distinct, low-multiplicity eigenvalues A, with the latter encouraging a diagonal as possible \u03c4\u03a9. An optional spectral dropout layer can be applied before the basis unprojection to encourage a physically meaningful ordering of the learned spectrum (sec. 4.2).", "description": "This figure illustrates the Neural Isometries (NIso) framework.  It shows how NIso learns a latent space where transformations in the observation space (e.g., images) become isometric transformations in the latent space. This is achieved by regularizing the functional maps between latent representations to commute with a learned operator. The figure details the process, from encoding observations to estimating isometric maps and applying losses to enforce equivariance and reconstruction.", "section": "Method Overview"}, {"figure_path": "kCabCEhQWv/figures/figures_5_1.jpg", "caption": "Figure 3: Approximating the Laplacian. Forced to map between shifted images on the torus (first row, left) and rotated images on the sphere (second row, left), NIso regress operators (center right) structurally similar to the toric and spherical Laplacian (right). Maps \u03c4\u03a9 between projected images are strongly diagonal (center left), with individual blocks (inset) preserving the subspaces spanned by eigenfunctions (center, first 64 shown) sharing nearly the same eigenvalues. These experiments result in the discovery of basis with the similar properties to the the toric and spherical harmonics. In particular, the estimated spherical \u03a4\u03a9 manifest exactly the same structure as the ground truth Wigner-D matrices corresponding to the rotation, with square blocks of size (2l + 1) \u00d7 (2l + 1) for the l-th distinct eigenvalue. Please zoom in to view structural details.", "description": "This figure shows the results of applying Neural Isometries (NIso) to learn representations of the Laplacian operator on the torus and sphere.  The left side displays input images (\u03c8 and T\u03c8) on the torus and sphere, respectively, undergoing shifts and rotations. The center shows the learned isometry (\u03c4\u03a9) in the latent space which maps between the encodings of these input images. A key observation is that \u03c4\u03a9 is nearly diagonal, with blocks preserving the subspaces spanned by the learned eigenfunctions (\u03a6). The right shows that NIso recovers operators structurally similar to the toric and spherical Laplacians, with the learned eigenfunctions demonstrating similar properties to toric and spherical harmonics.", "section": "4.3 A Simple Example: Approximating the Toric and Spherical Laplacians"}, {"figure_path": "kCabCEhQWv/figures/figures_7_1.jpg", "caption": "Figure 1: Neural Isometries find latent spaces where complex transformations become tractable.", "description": "This figure illustrates the core idea of Neural Isometries.  It shows how complex transformations in the original observation space (e.g., images) are mapped to a latent space where the relationships between transformed observations become simplified and tractable. This simplification is achieved by making the transformations in the latent space isometric, meaning they preserve distances and angles. The image depicts the transformation of input images through an encoder, creating isometrically related representations in a latent space, which then can be used by a generic equivariant neural network.", "section": "1 Introduction"}, {"figure_path": "kCabCEhQWv/figures/figures_7_2.jpg", "caption": "Figure 3: Approximating the Laplacian. Forced to map between shifted images on the torus (first row, left) and rotated images on the sphere (second row, left), NIso regress operators (center right) structurally similar to the toric and spherical Laplacian (right). Maps \u03c4\u03a9 between projected images are strongly diagonal (center left), with individual blocks (inset) preserving the subspaces spanned by eigenfunctions (center, first 64 shown) sharing nearly the same eigenvalues. These experiments result in the discovery of basis with the similar properties to the the toric and spherical harmonics. In particular, the estimated spherical \u03c4\u03a9 manifest exactly the same structure as the ground truth Wigner-D matrices corresponding to the rotation, with square blocks of size (2l + 1) \u00d7 (2l + 1) for the l-th distinct eigenvalue. Please zoom in to view structural details.", "description": "This figure shows the results of applying Neural Isometries (NIso) to learn operators on the torus and sphere.  The left side shows input images on the torus (top) and sphere (bottom), with their transformed versions underneath. NIso successfully regresses operators (center right) highly similar in structure to the Laplacian on each manifold, demonstrated by diagonal maps (center left) and eigenfunctions that closely resemble the toric and spherical harmonics.  The rightmost column shows ground truth Laplacian operators for comparison. The inset highlights the block-diagonal structure of the learned maps.", "section": "4.3 A Simple Example: Approximating the Toric and Spherical Laplacians"}, {"figure_path": "kCabCEhQWv/figures/figures_8_1.jpg", "caption": "Figure 2: Overview of Neural Isometries (NIso). NIso learn a latent space where transformations of observations manifest as isometries, achieved by regularizing the functional maps \u03c4 between latents to commute with a learned operator \u03a9, parameterized via its spectral decomposition into a mass matrix M, eigenfunctions \u03a6, and eigenvalues A (sec. 4.1). Given two observations \u03c8 and T\u03c8 related by some unknown transformation T (in this case, camera motion in a 3D scene), they are first encoded into latent functions E(\u03c8) and E(T\u03c8) and projected into the operator eigenbasis. An isometric functional map \u03c4\u03a9 is estimated between them, and used to map one to the other. Losses promote isometry-equivariance in the latent space, reconstruction of transformed latents, and distinct, low-multiplicity eigenvalues A, with the latter encouraging a diagonal as possible \u03c4\u03a9. An optional spectral dropout layer can be applied before the basis unprojection to encourage a physically meaningful ordering of the learned spectrum (sec. 4.2).", "description": "This figure illustrates the Neural Isometries (NIso) framework. It shows how NIso learns a latent space where geometric transformations in the input space (e.g., images) are represented as isometries (distance-preserving transformations) in the latent space.  The process involves encoding observations into latent functions, projecting them into an operator eigenbasis, estimating an isometric functional map between them, and using losses to ensure isometry equivariance, reconstruction accuracy, and distinct eigenvalues.", "section": "Method Overview"}, {"figure_path": "kCabCEhQWv/figures/figures_18_1.jpg", "caption": "Figure 4: Visualizing the Learned Eigenfunctions \u03a6 and Mass Matrices M. Visualizations of the eigenfunctions \u03a6 learned in each experiment are shown on the top row. Eigenfunctions are sorted by eigenvalue in ascending order along rows in C-style indexing. Here, experiments were performed without spectral dropout so the ordering is random. The elements of the learned diagonal mass matrices M are shown on the bottom row, in terms of the magnitude of the deviation from the mean value at each grid index in the latent space. White indicates little deviation from the mean, with green-blue indicating mass values above the mean and orange-red indicating mass values below. In the MNIST experiments (sec. 5.1), the distribution of mass appears to segment null space from the central region most often occupied by the digits. In the conformal shape classification experiments (sec. 5.2), the larger deviations from the mean values appear closer to the poles (the top-most and bottom-most rows of the spherical grid). For the pose estimation experiments (sec. 5.3), larger deviations appear at the boundaries, with the lower half of the grid having slightly higher values.", "description": "This figure visualizes the learned eigenfunctions (\u03a6) and mass matrices (M) from three different experiments: Homography MNIST, Conformal SHREC '11, and CO3D.  The top row shows the eigenfunctions, sorted by eigenvalue, while the bottom row displays the mass matrices, with color representing deviation from the mean mass value at each grid location. The visualization helps illustrate how the learned representations capture geometric information specific to each task.", "section": "Additional Results"}, {"figure_path": "kCabCEhQWv/figures/figures_19_1.jpg", "caption": "Figure 3: Approximating the Laplacian. Forced to map between shifted images on the torus (first row, left) and rotated images on the sphere (second row, left), NIso regress operators (center right) structurally similar to the toric and spherical Laplacian (right). Maps \u03c4\u03a9 between projected images are strongly diagonal (center left), with individual blocks (inset) preserving the subspaces spanned by eigenfunctions (center, first 64 shown) sharing nearly the same eigenvalues. These experiments result in the discovery of basis with the similar properties to the the toric and spherical harmonics. In particular, the estimated spherical \u03c4\u03a9 manifest exactly the same structure as the ground truth Wigner-D matrices corresponding to the rotation, with square blocks of size (2l + 1) \u00d7 (2l + 1) for the l-th distinct eigenvalue. Please zoom in to view structural details.", "description": "This figure demonstrates the ability of Neural Isometries to learn operators similar to the Laplacian on the torus and sphere. By inputting shifted images on the torus and rotated images on the sphere, the model regresses operators whose structure and eigenvalues closely match those of the toric and spherical Laplacians.  The diagonal structure of the maps (\u03c4\u03a9) highlights the preservation of subspaces spanned by eigenfunctions with similar eigenvalues, mirroring the properties of spherical harmonics.  The close match between the learned spherical \u03c4\u03a9 and the ground truth Wigner-D matrices further validates the model's accuracy.", "section": "4.3 A Simple Example: Approximating the Toric and Spherical Laplacians"}, {"figure_path": "kCabCEhQWv/figures/figures_20_1.jpg", "caption": "Figure 3: Approximating the Laplacian. Forced to map between shifted images on the torus (first row, left) and rotated images on the sphere (second row, left), NIso regress operators (center right) structurally similar to the toric and spherical Laplacian (right). Maps \u03c4\u03a9 between projected images are strongly diagonal (center left), with individual blocks (inset) preserving the subspaces spanned by eigenfunctions (center, first 64 shown) sharing nearly the same eigenvalues. These experiments result in the discovery of basis with the similar properties to the the toric and spherical harmonics. In particular, the estimated spherical \u03a4\u03a9 manifest exactly the same structure as the ground truth Wigner-D matrices corresponding to the rotation, with square blocks of size (2l + 1) \u00d7 (2l + 1) for the l-th distinct eigenvalue. Please zoom in to view structural details.", "description": "This figure shows the results of applying Neural Isometries (NIso) to learn representations of the Laplacian operator on the torus and sphere.  NIso is able to learn operators that closely resemble the ground truth Laplacian operators, demonstrating its ability to discover meaningful geometric structure in latent space. The diagonal structure of the learned isometries (\u03c4\u03a9) in the eigenbasis is highlighted, indicating the preservation of subspaces spanned by the eigenfunctions. The figure also illustrates the learned eigenfunctions for both the torus and sphere, showing a close resemblance to the expected toric and spherical harmonics. This figure demonstrates the effectiveness of NIso in discovering and representing complex geometric transformations in a tractable way.", "section": "4.3 A Simple Example: Approximating the Toric and Spherical Laplacians"}, {"figure_path": "kCabCEhQWv/figures/figures_21_1.jpg", "caption": "Figure 3: Approximating the Laplacian. Forced to map between shifted images on the torus (first row, left) and rotated images on the sphere (second row, left), NIso regress operators (center right) structurally similar to the toric and spherical Laplacian (right). Maps \u03c4\u03a9 between projected images are strongly diagonal (center left), with individual blocks (inset) preserving the subspaces spanned by eigenfunctions (center, first 64 shown) sharing nearly the same eigenvalues. These experiments result in the discovery of basis with the similar properties to the the toric and spherical harmonics. In particular, the estimated spherical \u03c4\u03a9 manifest exactly the same structure as the ground truth Wigner-D matrices corresponding to the rotation, with square blocks of size (2l + 1) \u00d7 (2l + 1) for the l-th distinct eigenvalue. Please zoom in to view structural details.", "description": "This figure shows the results of applying Neural Isometries (NIso) to learn operators on the torus and sphere.  The model successfully approximates the Laplacian operator on both manifolds, demonstrating that NIso can discover approximations of known operators.  The diagonal structure of the maps (\u03c4\u03a9) highlights the preservation of subspaces spanned by the learned eigenfunctions which share eigenvalues similar to spherical and toric harmonics.", "section": "4.3 A Simple Example: Approximating the Toric and Spherical Laplacians"}]