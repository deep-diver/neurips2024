{"references": [{"fullname_first_author": "Lukas Berglund", "paper_title": "The reversal curse: LLMs trained on \"a is b\" fail to learn \"b is a\"", "publication_date": "2023-09-27", "reason": "This paper introduces the \"reversal curse\" phenomenon, a key concept explored and expanded upon in the current research."}, {"fullname_first_author": "S\u00e9bastien Bubeck", "paper_title": "Sparks of artificial general intelligence: Early experiments with GPT-4", "publication_date": "2023-03-01", "reason": "This is a foundational paper providing early experimental results on GPT-4, which is highly relevant to the study of LLMs' generalization capabilities."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2021-05-03", "reason": "This paper introduces the MMLU benchmark, which is used in the current study to assess the broader impact of the observed phenomena on LLMs' overall performance."}, {"fullname_first_author": "Roger B. Grosse", "paper_title": "Studying large language model generalization with influence functions", "publication_date": "2023-08-01", "reason": "This paper uses influence functions to analyze LLMs' generalization, providing insights relevant to the understanding of the \"reversal curse\"."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-01", "reason": "This paper introduces Llama 2, a key LLM model used extensively in the experiments of the current study."}]}