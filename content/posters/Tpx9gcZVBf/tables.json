[{"figure_path": "Tpx9gcZVBf/tables/tables_4_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy results on ImageNet-C (with severity level 5) and ImageNet-Test datasets.  It shows the performance of different classifier models trained with various augmentation techniques. The augmentation techniques include AugMix (AM), DeepAugment (DA), AugMix+DeepAugment (DAM), and the proposed DiffAug method, either alone or in combination with the others. The evaluation is done using four modes: DDA (Diffusion-based test-time adaptation), DDA+Self-Ensemble (DDA+SE), DiffAug Ensemble (DE), and Default (without test-time augmentation). The average accuracy across all corruption types and evaluation modes is presented.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_5_1.jpg", "caption": "Table 2: Top-1 Accuracy (%) across different types of distribution shifts when additional high-quality synthetic data from Stable-Diffusion is available (denoted by +Synth). We show the net improvement obtained by DiffAug training and DiffAug-Ensemble (DE) inference. For reference, we also include the results for the corresponding ResNet50 models without extra synthetic data.", "description": "This table compares the top-1 accuracy of ResNet50 models trained with and without DiffAug and with and without additional synthetic data generated by Stable Diffusion. The accuracy is evaluated across various image corruption types (ImageNet-C), real-world corruptions (ImageNet-R), sketches (ImageNet-Sketch), and out-of-distribution examples (ImageNet-A, ImageNet-D, and ImageNet-S).  The table demonstrates DiffAug's effectiveness in improving robustness even when compared to models trained with additional synthetic data.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_5_2.jpg", "caption": "Table 3: AUROC on Imagenet Near-OOD Detection.", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) for different OOD detection algorithms on the ImageNet Near-OOD detection task.  The algorithms are AugMix (AM), AM+DiffAug, RN50, RN50+DiffAug.  The AUROC is a measure of the classifier's ability to distinguish between in-distribution and out-of-distribution samples. Higher AUROC values indicate better performance.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_7_1.jpg", "caption": "Table 4: Summary of Test Accuracies for CIFAR10 and Imagenet: each test example is diffused to a random uniformly sampled diffusion time. Both classifiers are shown the same diffused example.", "description": "This table summarizes the test accuracy results for CIFAR10 and ImageNet datasets. Two types of classifiers were used: Noisy Classifier and DA-Classifier. The Noisy Classifier uses only noisy inputs, while the DA-Classifier uses both noisy and denoised inputs. The results show that the DA-Classifier significantly outperforms the Noisy Classifier on both datasets, indicating the effectiveness of denoising-augmented training.", "section": "Experiments II: Classifier-Guided Diffusion"}, {"figure_path": "Tpx9gcZVBf/tables/tables_8_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy of different models trained with various data augmentation methods on ImageNet-C (a corrupted version of ImageNet with severity level 5) and ImageNet-Test.  The augmentation methods include AugMix (AM), DeepAugment (DA), AugMix+DeepAugment (DAM), and DiffAug (with and without combinations of the other methods). Evaluation modes include standard classification,  Diffusion-based test-time adaptation (DDA), DDA with self-ensembling (DDA-SE), and DiffAug Ensemble (DE). The average accuracy across all evaluation modes is also provided for each classifier.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_16_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the ImageNet-C (severity=5) and ImageNet-Test top-1 accuracy results for various classifier training methods.  It compares different augmentation strategies (AM, DA, DAM, and their combinations with DiffAug) and evaluation methods (DDA, DDA-SE, DE, and default).  The average accuracy across different evaluation types is also included for each classifier and augmentation strategy.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_17_1.jpg", "caption": "Table 7: Top-1 Accuracy (%) on Imagenet-S and Imagenet-R. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy results on ImageNet-S and ImageNet-R datasets.  It shows the performance of different classifier models trained with various augmentation techniques (including DiffAug) and evaluated under four different modes: DDA, DDA-SE, DE, and default.  The average accuracy across all modes and augmentation techniques is also provided for each classifier model (ResNet-50 and ViT-B/16). This helps in comparing the robustness of different augmentation methods and classifier models on these datasets representing covariate shifts.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_17_2.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy results on ImageNet-C (with severity level 5) and ImageNet-Test.  It summarizes the performance of different classifier models trained with various augmentation techniques, including DiffAug.  The table shows the accuracy for each model under different evaluation scenarios (Default, DDA, DDA-SE, and DE) and provides the average accuracy across these methods. The augmentation techniques used are AugMix (AM), DeepAugment (DA), DeepAugment+AugMix (DAM), and combinations with DiffAug.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_17_3.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the Top-1 accuracy results on ImageNet-C (with severity level 5) and ImageNet-Test datasets.  It compares the performance of different classifier models trained with various augmentation techniques, including DiffAug and combinations with AugMix and DeepAugment. The results are categorized by evaluation method (DDA, DDA-SE, DE, and Default) to show robustness across different scenarios.  The 'Avg' column provides an average across all augmentation methods for each evaluation type.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_17_4.jpg", "caption": "Table 10: DDA vs DE in terms of wallclock times: We use 40GB A40 GPU for determining the running time. For each method, we determine the maximum usable batch-size and report the average wallclock time for processing a single example.", "description": "This table compares the average wall-clock time taken by DDA and DE for processing one image.  The experiments used a 40GB A40 GPU. The maximum possible batch size was used for each method to obtain the reported average.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_18_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the ImageNet-C and ImageNet-Test top-1 accuracy for various classifier training methods and evaluation strategies (Default, DDA, DDA-SE, DE).  The training methods combine different data augmentation techniques (AM, DA, DAM, DiffAug).  The table shows how DiffAug improves the accuracy in multiple settings, and that the improvement is consistent across the different augmentation methods used.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_19_1.jpg", "caption": "Table 12: Evaluation of other sampling methods for DiffAug: We use \u2193 to denote lower performance due to the use of DPM-Solver instead of DDIM.", "description": "This table compares the performance of DiffAug using different sampling methods (DDIM and DPM-Solver) for generating augmentations.  The evaluation metric is top-1 accuracy on ImageNet-C (severity=5), and three different training methods are compared: AM (AugMix), AM+DiffAug/DDIM (AugMix with DiffAug using DDIM), and AM+DiffAug/DPM-Solver-2 (AugMix with DiffAug using DPM-Solver).  The results show that using DDIM generally results in higher accuracy than using DPM-Solver for DiffAug augmentations.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_19_2.jpg", "caption": "Table 13: Certified Accuracy for different l2 perturbation radius. As is standard in the literature, we consider \u03c3\u03b5 \u2208 {0.25, 0.5, 1.0} and select the best \u03c3\u03b5 for each l2 radius.", "description": "This table shows the certified accuracy for different l2 perturbation radius.  The authors selected the best noise scale (\u03c3) from a set of three (0.25, 0.5, 1.0) for each l2 radius to achieve the highest certified accuracy.  The results are presented for two models: ViT and ViT trained with DiffAug (ViT+DiffAug).", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_20_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the ImageNet-C and ImageNet-Test top-1 accuracy results for various classifier training methods.  The training methods combine different augmentation techniques (AugMix, DeepAugment, DiffAug) and evaluation methods (default, DDA, DDA-SE, DE).  The table shows how different augmentation strategies affect the robustness of the classifiers and their performance on clean and corrupted images.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_21_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy of different models trained with various data augmentation techniques on the ImageNet-C dataset (with severity level 5) and the standard ImageNet-Test dataset.  The augmentation techniques include AugMix (AM), DeepAugment (DA), AugMix+DeepAugment (DAM), and DiffAug, both independently and in combination with the others.  The evaluation modes are standard classification, using the DDA image adaptation method, using DDA with self-ensembling, and DiffAug Ensemble (DE).  The table shows the average accuracy across all these combinations for ResNet-50 and ViT models.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_21_2.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy results of different image classification models trained with various augmentation techniques on the ImageNet-C dataset (with a severity level of 5) and the standard ImageNet-Test dataset.  The augmentation techniques include AugMix, DeepAugment, and their combinations with DiffAug. The evaluation modes encompass standard classification, as well as robustness evaluations using DDA, DDA-SE, and DE methods.  The average accuracy across all models and evaluation methods is also provided for better comparison. ", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_21_3.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the ImageNet-C (severity=5) and ImageNet-Test top-1 accuracy for different classifier training methods.  It compares several augmentation techniques, including AugMix (AM), DeepAugment (DA), and their combination (DAM), with and without the proposed DiffAug method.  The evaluation includes standard classification accuracy, as well as robustness evaluation using three metrics: DDA (Diffusion-based test-time adaptation), DDA-SE (DDA with self-ensembling), and DE (DiffAug Ensemble).  The table shows the average accuracy across all corruption types for each classifier and augmentation strategy, allowing comparison of the relative impact of each augmentation method on the overall performance.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_21_4.jpg", "caption": "Table 15: AUROC and FPR@TPR95 (lower is better) on ImageNet Near-OOD Detection.", "description": "This table presents the results of ImageNet Near-OOD detection experiments using various training augmentation techniques.  The AUROC (Area Under the Receiver Operating Characteristic curve) and FPR@TPR95 (False Positive Rate at True Positive Rate of 95%) metrics are used to evaluate the out-of-distribution (OOD) detection performance of different models. The table compares the performance of models trained with different augmentations (AM, AM+DiffAug, RN50, RN50+DiffAug, DAM, DAM+DiffAug, DA, DA+DiffAug) across multiple OOD detection algorithms (ASH, MSP, ReAct, SCALE). The average performance across algorithms is also shown for each augmentation.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_22_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy results on ImageNet-C (with a severity of 5) and ImageNet-Test.  The results are broken down by different training augmentation methods (AM, DA, DAM, and their combinations with DiffAug), and by different evaluation methods (DDA, DDA-SE, DE, and the default method).  It shows the impact of DiffAug on classification accuracy across various robustness evaluation scenarios.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_22_2.jpg", "caption": "Table 7: Top-1 Accuracy (%) on Imagenet-S and Imagenet-R. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the ImageNet-S and ImageNet-R Top-1 accuracy for different training augmentation methods.  The results are broken down by evaluation method (DDA, DDA-SE, DE, Def.) to show the impact of different test-time augmentation strategies on model robustness across various datasets.  The average accuracy across all methods is also provided for each classifier.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_22_3.jpg", "caption": "Table 15: AUROC and FPR@TPR95 on ImageNet Near-OOD Detection.", "description": "This table presents the results of the ImageNet Near-OOD detection experiment.  It shows the Area Under the Receiver Operating Characteristic curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR@TPR95) for various OOD detection algorithms. The algorithms are evaluated using four different metrics: ASH, MSP, ReAct, and Scale. The table compares the performance of the models trained with AugMix (AM), AugMix combined with DiffAug (AM+DiffAug), AugMix combined with additional training (AM+Extra), AugMix combined with DiffAug using different time ranges (AM+DiffAug[0,500] and AM+DiffAug[500,999]). The average performance across all metrics is also presented for each model.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_25_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy results of different classifiers trained with various augmentation methods on the ImageNet-C dataset (with severity level 5) and the standard ImageNet-Test dataset.  It compares the performance using different test-time augmentation techniques (DDA, DDA-SE, DE, and default). The average accuracy across all methods is also provided for better comparison.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_29_1.jpg", "caption": "Table 1: Top-1 Accuracy (%) on Imagenet-C (severity=5) and Imagenet-Test. We summarize the results for each combination of Train-augmentations and evaluation modes. The average (avg) accuracies for each classifier and evaluation mode is shown.", "description": "This table presents the top-1 accuracy results of different image classification models trained with various data augmentation techniques on the ImageNet-C dataset (with a severity level of 5) and the standard ImageNet test set.  The augmentation techniques used include AugMix (AM), DeepAugment (DA), and a combination of both (DAM).  The models are evaluated using different robustness evaluation methods including the standard accuracy as well as  DDA, DDA-SE, and DE(DiffAug Ensemble). The table shows the average top-1 accuracy across all severities of the ImageNet-C dataset for better comparison.", "section": "Experiments I: Classifier Robustness"}, {"figure_path": "Tpx9gcZVBf/tables/tables_30_1.jpg", "caption": "Table 2: Top-1 Accuracy (%) across different types of distribution shifts when additional high-quality synthetic data from Stable-Diffusion is available (denoted by +Synth). We show the net improvement obtained by DiffAug training and DiffAug-Ensemble (DE) inference. For reference, we also include the results for the corresponding ResNet50 models without extra synthetic data.", "description": "This table compares the performance of ResNet50 models trained with and without extra synthetic data from Stable Diffusion, and with and without DiffAug, across multiple image classification benchmarks that evaluate robustness to different types of distribution shifts (ImageNet-C, ImageNet-R, ImageNet-S, ImageNet-Sketch, ImageNet-A, and ImageNet-D).  The \"DE\" column indicates the performance when using the DiffAug Ensemble method for test-time augmentation, which further improves robustness.", "section": "Experiments I: Classifier Robustness"}]