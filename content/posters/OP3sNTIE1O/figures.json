[{"figure_path": "OP3sNTIE1O/figures/figures_1_1.jpg", "caption": "Figure 1: Transforming unlabeled data using a diffusion model. Initially, the unlabeled data includes classes like trees, fish, and mountains, which are irrelevant to the labeled data's classes such as trucks, cars, and ships. The reverse process with class conditioning resolves this mismatch while preserving the diversity of the original unlabeled samples. More examples can be found in Appendix H.", "description": "This figure illustrates the process of transforming unlabeled data into labeled data using a diffusion model.  The process starts with noisy images from the unlabeled dataset, which may contain classes not present in the labeled data.  The diffusion model, conditioned on the desired class from the labeled data, then transforms these noisy images.  The resulting images retain the diversity from the unlabeled data while aligning their class labels with the labeled data.", "section": "Methodology"}, {"figure_path": "OP3sNTIE1O/figures/figures_4_1.jpg", "caption": "Figure 2: Schematic diagram of Discriminator-Weighted Diffusion (DWD). The conditional diffusion model is trained using both labeled and unlabeled data. The unlabeled data is utilized for unconditional training without class conditions. The pre-trained discriminator assigns weights to each unlabeled data sample to mitigate the potential negative impact of OOD samples.", "description": "This figure illustrates the architecture of the Discriminator-Weighted Diffusion (DWD) model.  It shows how both labeled and unlabeled data are used to train a conditional diffusion model. A discriminator is used to assign weights to the unlabeled data points, reducing the negative impact of out-of-distribution (OOD) samples during training. The final output is the DWD loss, used to optimize the model.", "section": "4 Methodology"}, {"figure_path": "OP3sNTIE1O/figures/figures_7_1.jpg", "caption": "Figure 3: Standard SSL performance with varying \u03b6.", "description": "This figure displays the performance of three standard semi-supervised learning (SSL) methods (MixMatch, FixMatch, and MPL) under varying levels of class distribution mismatch (\u03b6).  The x-axis represents the percentage of mismatch, and the y-axis shows the accuracy achieved by each method.  The black line represents the accuracy without the proposed data augmentation method (DWD-UT), while the blue line shows the accuracy with DWD-UT applied.  The figure demonstrates the robustness of SSL methods to class distribution mismatch when using DWD-UT, as the performance remains high even with significant mismatch.", "section": "5.2 DWD-UT: Unlabeled Dataset Transformation"}, {"figure_path": "OP3sNTIE1O/figures/figures_16_1.jpg", "caption": "Figure 1: Transforming unlabeled data using a diffusion model. Initially, the unlabeled data includes classes like trees, fish, and mountains, which are irrelevant to the labeled data's classes such as trucks, cars, and ships. The reverse process with class conditioning resolves this mismatch while preserving the diversity of the original unlabeled samples. More examples can be found in Appendix H.", "description": "This figure illustrates the process of transforming unlabeled data using a diffusion model.  The unlabeled data contains irrelevant classes (trees, fish, mountains), while the labeled data contains different classes (trucks, cars, ships). The diffusion model, through a reverse process with class conditioning, transforms the irrelevant unlabeled data into relevant data points, maintaining diversity within the original unlabeled data.", "section": "1 Introduction"}, {"figure_path": "OP3sNTIE1O/figures/figures_17_1.jpg", "caption": "Figure 5: Selected unlabeled samples based on discriminator's output on the SixAnimal (a, b) and ImageNet-30 (c, d).", "description": "This figure visualizes examples of unlabeled samples from the SixAnimal and ImageNet-30 datasets, categorized by their discriminator scores. High-score samples are those deemed relevant to the labeled data distribution, while low-score samples are considered irrelevant or out-of-distribution. The figure shows how the discriminator effectively identifies and separates relevant and irrelevant instances from the unlabeled data, which is crucial for the DWD method to enhance data augmentation quality.", "section": "G Images Corresponding to Discriminator's Output"}, {"figure_path": "OP3sNTIE1O/figures/figures_18_1.jpg", "caption": "Figure 1: Transforming unlabeled data using a diffusion model. Initially, the unlabeled data includes classes like trees, fish, and mountains, which are irrelevant to the labeled data's classes such as trucks, cars, and ships. The reverse process with class conditioning resolves this mismatch while preserving the diversity of the original unlabeled samples. More examples can be found in Appendix H.", "description": "This figure illustrates the process of transforming unlabeled data using a diffusion model.  The left side shows unlabeled images containing classes (trees, fish, mountains) not present in the labeled data (trucks, cars, ships). A noise process is applied, followed by a reverse diffusion process with class conditioning. The right side shows how the model transforms the irrelevant unlabeled images into relevant labeled images while maintaining the diversity of the original unlabeled samples.  The process is used to address class distribution mismatch in semi-supervised learning.", "section": "4 Methodology"}, {"figure_path": "OP3sNTIE1O/figures/figures_19_1.jpg", "caption": "Figure 7: Generated images from DPT and DWD. DPT sometimes generates incorrectly labeled samples (e.g., an image of a schooner, which is an OOD class, labeled as a mosque). Note that while DPT originally samples images from scratch, we applied our data generation algorithm to DPT for comparison.", "description": "The figure compares the image generation process of DPT and DWD methods using an example of a noisy tank image as input. DPT generates an image that is incorrectly labeled as a mosque, while DWD generates a correct mosque image. This demonstrates DWD's superiority in handling out-of-distribution (OOD) samples during image generation.", "section": "5.4 Comparison with Recent Diffusion-based Augmentation Approaches"}, {"figure_path": "OP3sNTIE1O/figures/figures_19_2.jpg", "caption": "Figure 8: Generated images from DA-Fusion. DA-Fusion only augments given labeled images with subtle visual details.", "description": "This figure shows the results of applying the DA-Fusion data augmentation method to a mosque image.  DA-Fusion, unlike the proposed DWD method, only generates subtle variations of the input image, maintaining the original image's content and style. It does not generate entirely new images from unlabeled data as DWD does, hence showing a limitation when there's a class distribution mismatch.", "section": "5.4 Comparison with Recent Diffusion-based Augmentation Approaches"}]