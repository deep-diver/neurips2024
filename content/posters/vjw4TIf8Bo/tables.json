[{"figure_path": "vjw4TIf8Bo/tables/tables_1_1.jpg", "caption": "Table 1: Structured output string format used in the literature. The examples come from CoNLL2003 dataset.", "description": "This table shows two common formats for representing the output of a named entity recognition (NER) system using large language models (LLMs).  The \"Augmented Language\" format incorporates the original input text along with the NER labels and mentions.  The \"Structured Annotation\" format uses a more concise, structured representation of the labels and mentions.  Examples are provided using the CoNLL2003 dataset.", "section": "1 Introduction"}, {"figure_path": "vjw4TIf8Bo/tables/tables_6_1.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency (in milliseconds) of the proposed PaDeLLM-NER model against several baseline methods across various English and Chinese NER datasets. The latency is a measure of how long it takes for the model to generate predictions.  The best and second-best performing models are highlighted in bold and underlined fonts, respectively.  This provides a direct comparison of the speed improvements achieved by the PaDeLLM-NER method.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_6_2.jpg", "caption": "Table 3: Comparison of prediction quality with recent SOTA models in zero-shot setting.", "description": "This table presents the comparison of prediction quality (using micro F1 score) of the proposed PaDeLLM-NER model against other state-of-the-art (SOTA) models in a zero-shot setting.  The comparison is done across various domains, such as AI, Literature, Music, Politics, Science, Movie, and Restaurant, demonstrating the model's performance in unseen domains without further training.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_7_1.jpg", "caption": "Table 4: Comparison of prediction quality with recent SOTA methods on English supervised datasets.", "description": "This table compares the prediction quality (micro F-score) of the proposed PaDeLLM-NER method against several state-of-the-art (SOTA) methods on three widely used English supervised named entity recognition (NER) datasets: CoNLL03, ACE05, and GENIA.  It showcases the performance of PaDeLLM-NER in a supervised setting, highlighting its ability to achieve competitive results compared to other advanced NER techniques.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_8_1.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency (in milliseconds) of the proposed PaDeLLM-NER model against several baseline methods across various English and Chinese NER datasets.  The latency represents the time taken for the models to generate predictions.  The best and second-best performing methods for each dataset are highlighted in bold and underscored font, respectively.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_15_1.jpg", "caption": "Table 6: Ablations on ignoring loss and de-duplication.", "description": "This table presents the ablation study results on the PaDeLLM-NER model. It shows the performance of the model with different components removed or modified. The variants are: (1) the base PaDeLLM-NER model, (2) PaDeLLM-NER with loss ignoring for text spans, (3) PaDeLLM-NER without de-duplication, and (4) PaDeLLM-NER with reversed de-duplication.  The results are presented as micro F1 scores for CoNLL03, ACE05, and GENIA datasets and a mean across these three datasets.  The table demonstrates the impact of each component on the overall model performance.", "section": "4 Experiments"}, {"figure_path": "vjw4TIf8Bo/tables/tables_15_2.jpg", "caption": "Table 7: Mentions appear under multiple labels in ground truth.", "description": "This table shows the number of mentions that appear under multiple labels in the ground truth data for different NER datasets.  The \"Ratio\" column represents the proportion of mentions with this characteristic relative to the total number of mentions in each dataset.  It demonstrates the infrequency of this phenomenon, supporting the claim that the de-duplication mechanism is not overly aggressive.", "section": "4 Experiments"}, {"figure_path": "vjw4TIf8Bo/tables/tables_16_1.jpg", "caption": "Table 8: Mentions appear under multiple labels in PaDeLLM prediction.", "description": "This table presents the number of mentions that appear under multiple labels in the PaDeLLM-NER model's predictions.  It provides a count for each dataset (ACE05, ConLL03, GENIA, Ecom, MSRA, Weibo, Youku, Resume) and calculates the ratio of these mentions to the total number of mentions. This data helps to assess the frequency of duplicate mention predictions and evaluate the effectiveness of the proposed de-duplication strategy.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_16_2.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency in milliseconds of PaDeLLM-NER against several baseline methods across various English and Chinese NER datasets.  The latency is a measure of how long it takes to process each input sentence.  It shows that PaDeLLM-NER significantly reduces inference time compared to the autoregressive baselines. The best and second-best performing methods are highlighted in bold and underlined fonts, respectively.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_16_3.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency in milliseconds of PaDeLLM-NER against several baseline methods across multiple English and Chinese datasets.  It highlights the significant speed improvements achieved by PaDeLLM-NER, indicating its efficiency in NER tasks. The best and second-best performing methods are clearly marked.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_16_4.jpg", "caption": "Table 4: Comparison of prediction quality with recent SOTA methods on English supervised datasets.", "description": "This table compares the performance of the proposed PaDeLLM-NER method against other state-of-the-art (SOTA) methods on several widely-used English supervised NER datasets.  It shows the micro F1-score, a common metric for NER, achieved by each method, enabling a direct comparison of prediction accuracy.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_17_1.jpg", "caption": "Table 12: Comparison of Latency and F-score between PaDeLLM and AutoRegAug under zero-shot scenarios.", "description": "This table compares the inference latency (in milliseconds) and prediction quality (F-score) of the PaDeLLM-NER model against the AutoRegAug baseline model in zero-shot settings across various domains including AI, Literature, Music, Politics, and Science.  It highlights the significant improvement in both latency and F-score achieved by PaDeLLM-NER compared to the traditional autoregressive approach.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_17_2.jpg", "caption": "Table 13: Ablations on model scaling up.", "description": "This table presents the results of ablations conducted on the model scaling. By increasing the model size from 7B to 13B, the performance on CONLL03 and GENIA datasets improved while showing a slight decrease on ACE05 dataset. The average performance shows a significant improvement from 85.06 to 85.45.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_18_1.jpg", "caption": "Table 14: Comparison of the number of generated tokens per sequence by PaDeLLM-NER with baseline methods.", "description": "This table compares the average number of generated tokens per sequence for the proposed PaDeLLM-NER model and several baseline methods across various English and Chinese NER datasets. It highlights the significant reduction in the number of tokens generated by PaDeLLM-NER compared to the autoregressive baselines, demonstrating its efficiency in terms of sequence length.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_18_2.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency (in milliseconds) of the PaDeLLM-NER model against several baseline methods across various English and Chinese NER datasets.  It highlights the significant speedup achieved by PaDeLLM-NER in comparison to traditional autoregressive approaches. The best and second-best performing methods are indicated using bold and underlined fonts, respectively.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_18_3.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency, in milliseconds, of the PaDeLLM-NER model against several baseline methods across various English and Chinese datasets.  It shows how much faster PaDeLLM-NER is compared to the other methods, highlighting its improved efficiency. The best and second-best performing methods are emphasized in bold and underlined font, respectively, for each dataset and are also used in other relevant tables of the paper.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_19_1.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency in milliseconds of the PaDeLLM-NER model against several baseline methods across multiple English and Chinese NER datasets.  It highlights the significant speed improvements achieved by PaDeLLM-NER.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/tables/tables_19_2.jpg", "caption": "Table 2: Comparison of inference latency (in milliseconds) between PaDeLLM-NER and baseline methods. Underscored font is the second-best method, while a bold font is the best method, also applied to subsequent tables.", "description": "This table compares the inference latency in milliseconds of the proposed PaDeLLM-NER method against several baseline methods across various English and Chinese NER datasets.  The latency reflects the time taken for the model to generate the output.  The best and second-best performing methods for each dataset are highlighted.", "section": "4.2 Main Results"}]