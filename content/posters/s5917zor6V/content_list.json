[{"type": "text", "text": "On the Curses of Future and History in Future-dependent Value Functions for OPE ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yuheng Zhang Nan Jiang University of Illinois Urbana-Champaign University of Illinois Urbana-Champaign yuhengz2@illinois.edu nanjiang@illinois.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study off-policy evaluation (OPE) in partially observable environments with complex observations, with the goal of developing estimators whose guarantee avoids exponential dependence on the horizon. While such estimators exist for MDPs and POMDPs can be converted to history-based MDPs, their estimation errors depend on the state-density ratio for MDPs which becomes history ratios after conversion, an exponential object. Recently, Uehara et al. [2022a] proposed future-dependent value functions as a promising framework to address this issue, where the guarantee for memoryless policies depends on the density ratio over the latent state space. However, it also depends on the boundedness of the futuredependent value function and other related quantities, which we show could be exponential-in-length and thus erasing the advantage of the method. In this paper, we discover novel coverage assumptions tailored to the structure of POMDPs, such as outcome coverage and belief coverage, which enable polynomial bounds on the aforementioned quantities. As a side product, our analyses also lead to the discovery of new algorithms with complementary properties. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction and Related Works ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Off-policy evaluation (OPE) is the problem of estimating the return of a new evaluation policy $\\pi_{e}$ based on historical data, which is typically collected using a different policy $\\pi_{b}$ (the behavior policy). OPE plays a central role in the pipeline of offilne reinforcement learning (RL), but is also notoriously difficult. Among the major approaches, importance sampling (IS) and its variants Precup et al. [2000], Jiang and Li [2016] provide unbiased and/or asymptotically correct estimation using the cumulative importance weights: given a trajectory of observations and actions $o_{1},a_{1},o_{2},a_{2},\\dots,o_{H},a_{H}$ , the cumulative importance weight is  hH=1\u03c0\u03c0be((aahh||oohh)), whose variance grows exponentially with the horizon, unless $\\pi_{b}$ and $\\pi_{e}$ are very close in their action distributions. In the language of offline RL theory [Chen and Jiang, 2019, Xie and Jiang, 2021, Yin and Wang, 2021], the boundedness of the cumulative importance weights is the coverage assumption required by IS, a very stringent one. ", "page_idx": 0}, {"type": "text", "text": "Alternatively, algorithms such as Fitted-Q Evaluation [FQE; Ernst et al., 2005, Munos and Szepesv\u00e1ri, 2008, Le et al., 2019] and Marginalized Importance Sampling [MIS; Liu et al., 2018, Xie et al., 2019, Nachum et al., 2019, Uehara et al., 2020] enjoy more favorable coverage assumptions, at the cost of function-approximation biases. Instead of requiring bounded cumulative importance weights, FQE and MIS only require that of the state-density ratios, which can be substantially smaller [Chen and Jiang, 2019, Xie and Jiang, 2021]. That is, when the environment satisfies the Markov assumption (namely $o_{h}$ is a state), the guarantees of FQE and MIS only depend on the range of $d_{h}^{\\pi_{e}}(o_{h})/d_{h}^{\\pi_{b}}(o_{h})$ , where $d_{h}^{\\pi_{e}}$ and $d_{h}^{\\pi_{b}}$ is the marginal distribution of $o_{h}$ under $\\pi_{e}$ and $\\pi_{b}$ , respectively. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we study the non-Markov setting, which is ubiquitous in real-world applications. Such environments are typically modeled as Partially Observable Markov Decision Processes (POMDPs) ", "page_idx": 0}, {"type": "text", "text": "Kaelbling et al. [1998]. Despite the more general formulation, one can reduce a POMDP to an MDP, making algorithms for MDPs applicable: we can simply define an equivalent MDP, with its state being the history of the original POMDP, $(o_{1},a_{1},\\ldots,o_{h})$ . Unfortunately, a close inspection reveals the problem: the state-density ratio after conversion is ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\frac{d_{h}^{\\pi_{e}}(o_{1},a_{1},\\ldots,o_{h})}{d_{h}^{\\pi_{b}}(o_{1},a_{1},\\ldots,o_{h})}=\\prod_{h^{\\prime}=1}^{h-1}\\frac{\\pi_{e}(a_{h^{\\prime}}|o_{h^{\\prime}})}{\\pi_{b}(a_{h^{\\prime}}|o_{h^{\\prime}})},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "which is exactly the cumulative importance weights in IS and thus also an exponential object! ", "page_idx": 1}, {"type": "text", "text": "To address this issue, Uehara et al. [2022a] recently proposed a promising framework called futuredependent value functions (or FDVF for short). Notably, their coverage assumption is the boundedness of density ratios between $\\pi_{e}$ and $\\pi_{b}$ over the latent state for memoryless policies. This is as if we were dealing directly with the latent MDP underlying the POMDP, a perhaps best possible scenario. Nevertheless, have we achieved exponential-free OPE in POMDPs? ", "page_idx": 1}, {"type": "text", "text": "The answer to this question turns out to be nontrivial. In addition to the latent-state coverage parameter, the guarantee in Uehara et al. [2022a] also depends on other quantities that are less interpretable. Among them, the boundedness of FDVF itself\u2014a concept central to this framework\u2014is unclear, and we show that a natural construction yields an upper bound that still scales with the cumulative importance weights, thus possibly erasing the superiority of the framework over IS or MDP-reduction. ", "page_idx": 1}, {"type": "text", "text": "In this work, we address these caveats by proposing novel coverage assumptions tailored to the structure of POMDPs, under which fully polynomial estimation guarantees can be established. More concretely, our contributions are: ", "page_idx": 1}, {"type": "text", "text": "1. For FDVFs, we show that a novel coverage concept called outcome coverage is sufficient for guaranteeing its boundedness (Section 4). Notably, outcome coverage concerns the overlap between $\\pi_{b}$ and $\\pi_{e}$ from the current time step onward, whereas all MDP coverage assumptions concern that before the current step.   \n2. With another novel concept called belief coverage (Section 5.1), we establish fully polynomial estimation guarantee for the algorithm in Uehara et al. [2022a]. The discovery of belief coverage also leads to a novel algorithm (Section 5.3) that is analogous to MIS for MDPs.   \n3. Despite the similarity to linear MDP coverage [Duan et al., 2020] due to the linear-algebraic structure, these POMDP coverage conditions also have their own unique properties due to the $L_{1}$ normalization of belief and outcome vectors. We present improved analyses that leverage such properties and avoid explicit dependence on the size of the latent state space (Section 4.2). ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "POMDP Setup. We consider a finite-horizon POMDP $\\begin{array}{r}{\\Big\\langle H,S=\\bigcup_{h=1}^{H}S_{h},\\mathcal{A},\\mathcal{O}=\\bigcup_{h=1}^{H}\\mathcal{O}_{h},R,\\mathbb{O},\\mathbb{T},d_{1}\\Big\\rangle,}\\end{array}$ where $H$ is the horizon, $\\ensuremath{\\mathcal{S}}_{h}$ is the latent state space at step $h$ with $|S_{h}|=S$ , $\\boldsymbol{\\mathcal{A}}$ is the action space with $|{\\mathcal{A}}|=A$ , $O_{h}$ is the observation space at step $h$ with $|\\mathcal{O}_{h}|=\\mathcal{O}$ , $R:\\mathcal{O}\\times\\mathcal{A}\\rightarrow[0,1]$ is the reward function, $\\mathbb{O}:\\mathcal{S}\\to\\Delta(\\mathcal{O})$ is the emission dynamics with $\\mathbb{O}(\\cdot|s_{h})$ supported on $O_{h}$ for $s_{h}\\in S_{h}$ , $\\mathbb{T}:S\\times A\\rightarrow\\Delta(S)$ is the dynamics $(\\mathbb{T}(\\cdot|s_{h},a_{h})$ is supported on $S_{h+1}$ ), and $d_{1}\\in\\Delta(S_{1})$ is the initial latent state distribution. For mathematical convenience we assume all the spaces are finite and discrete, but the cardinality of $O_{h},O$ , can be arbitrarily large. A trajectory (or episode) is sampled as $s_{1}\\sim d_{1}$ , then $o_{h}\\sim\\mathbb{O}(\\cdot|s_{h})$ , $r_{h}=R(o_{h},a_{h})$ , $s_{h+1}\\sim\\bar{\\mathbb{T}}(\\cdot|s_{h},\\bar{a_{h}})$ for $1\\leq h\\leq H$ , with $a_{1:H}$ decided by the decision-making agent, and the episode terminates after $a_{H}.~s_{1:H}$ are latent and not observable to the agent. ", "page_idx": 1}, {"type": "text", "text": "History-future Split. Given an episode $o_{1},a_{1},\\ldots,o_{H},a_{H}$ and a time step $h$ of interest, it will be convenient to rewrite the episode as ", "page_idx": 1}, {"type": "equation", "text": "$$\n(\\tau_{h}\\,,\\overbrace{o_{h}\\,,\\,a_{h}\\,,\\,f_{h+1}}^{f_{h}}).\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Here $\\begin{array}{r}{\\tau_{h}=\\left(o_{1},a_{1},\\dots.\\,o_{h-1},a_{h-1}\\right)\\in\\mathcal{H}_{h}:=\\prod_{h^{\\prime}=1}^{h-1}(\\mathcal{O}_{h}\\times\\mathcal{A})}\\end{array}$ denotes the historical observationaction sequence (or simply history) prior to  step $h$ , and $f_{h+1}\\ =\\ (o_{h+1},a_{h+1},\\ldots,o_{H},a_{H})\\ \\in$ $\\begin{array}{r}{\\mathcal{F}_{h+1}:=\\prod_{h^{\\prime}=h+1}^{H}(\\mathcal{O}_{h^{\\prime}}\\times\\mathcal{A})}\\end{array}$ denotes the future after step $h$ . This format will be convenient for reasoning about the system dynamics at step $h$ . We use $\\begin{array}{r}{\\mathcal{H}=\\bigcup_{h=1}^{H}\\mathcal{H}_{h}}\\end{array}$ to denote the entire history domain and use $\\begin{array}{r}{\\mathcal{F}=\\bigcup_{h=1}^{H}\\mathcal{F}_{h}}\\end{array}$ to denote the entire future domain. This way we can use stationary notation for functions  over $\\bar{\\boldsymbol{S}},\\boldsymbol{\\mathcal{O}},\\boldsymbol{\\mathcal{H}},\\boldsymbol{\\mathcal{F}}$ , where the time step can be identified from the function input (e.g., $R(o_{h},a_{h}))$ , and functions with time-step subscripts refer to their restriction to the $h$ -th step input space, often treated as a vector (e.g., $R_{h}\\'\\in\\mathbb{R}^{\\mathcal{O}_{h}\\times\\dot{\\mathcal{A}}})$ . ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Memoryless and History-dependent Policies. A policy $\\pi:\\bigcup_{h=1}^{H}(\\mathcal{H}_{h}\\times\\mathcal{O}_{h})\\to\\Delta(\\mathcal{A})$ specifies the action probability conditioned on the past observation-action sequence.1 In the main text, we will restrict ourselves to memory-less (or reactive) policies that only depends on the current observation $o_{h}$ ; extension to general policies is similar to Uehara et al. [2022a] and discussed in Appendix B.6. For any $\\pi$ , we use $\\mathrm{Pr}_{\\pi}$ and $\\mathbb{E}_{\\pi}$ for the probabilities and expectations under episodes generated by $\\pi$ , and define $J(\\pi)$ as the expected cumulative return: $\\begin{array}{r}{J(\\pi):=\\mathbb{E}_{\\pi}\\left[\\sum_{h=1}^{H}R(o_{h},a_{h})\\right]}\\end{array}$ . For memoryless $\\pi$ , we also define $V_{S}^{\\pi}(s_{h})$ as the latent state value function at $s_{h}\\colon V_{S}^{\\pi}(s_{h}):=\\mathbb{E}_{\\pi}\\left[\\sum_{h^{\\prime}=h}^{H}R(o_{h^{\\prime}},a_{h^{\\prime}})\\mid s_{h}\\right]\\in$ $[0,H]$ . $d^{\\pi}(s_{h})$ denotes the marginal distribution of $s_{h}$ under $\\pi$ . ", "page_idx": 2}, {"type": "text", "text": "Off-policy Evaluation. In OPE, the goal is to estimate $J(\\pi_{e})$ using $n$ data trajectories $\\mathcal{D}=$ $\\{(o_{1}^{(\\bar{i})},a_{1}^{(i)},r_{1}^{(i)},\\ldots,o_{H}^{(i)},a_{H}^{(i)},r_{H}^{(i)}):i\\in\\bar{[n]}\\}$ collected using $\\pi_{b}$ . We write $\\mathbb{E}_{\\mathcal{D}}[\\cdot]$ to denote empirical approximation of expectation using $\\mathcal{D}$ . Define the one-step action probability ratio $\\mu(o_{h},a_{h}):=$ $\\frac{\\pi_{e}\\left(a_{h}\\left|o_{h}\\right.\\right)}{\\pi_{b}\\left(a_{h}\\left|o_{h}\\right.\\right)}$ . We make the following assumption throughout: ", "page_idx": 2}, {"type": "text", "text": "Assumption 1 (Action coverage). We assume $\\pi_{b}(a_{h}|o_{h})$ is known and $\\operatorname*{max}_{h,o_{h},a_{h}}\\mu(o_{h},a_{h})\\leq C_{\\mu}$ . ", "page_idx": 2}, {"type": "text", "text": "This is a standard assumption in the OPE literature, and is needed by IS and value-based estimators that model state value functions [Jiang and Li, 2016, Liu et al., 2018]. ", "page_idx": 2}, {"type": "text", "text": "Belief and Outcome Matrices. We now introduce two matrices of central importance to our discussions. Given history $\\tau_{h}$ , we define $\\mathbf{b}(\\tau_{h})\\,\\in\\,\\mathbb{R}^{S}$ as its belief state vector where $\\mathbf{b}_{i}(\\tau_{h})\\,=$ $\\operatorname*{Pr}(s_{h}\\,=\\,i|\\tau_{h})$ . Then the belief matrix $\\dot{M_{\\mathcal{H},h}}\\,\\in\\,\\mathbb{R}^{S\\times\\mathcal{H}_{h}}$ is one where the column indexed by $\\tau_{h}\\in\\mathcal{H}_{h}$ is ${\\bf b}(\\tau_{h})$ . Similarly, for future $f_{h}$ , we define $\\mathbf{u}(f_{h})\\,\\in\\,\\mathbb{R}^{S}$ as its outcome vector where $[{\\bf u}(f_{h})]_{i}\\,=\\,\\mathrm{Pr}_{\\pi_{b}}(f_{h}|s_{h}\\,=\\,i)$ . The outcome matrix $\\boldsymbol{M}_{\\mathcal{F},h}\\,\\in\\,\\mathbb{R}^{S\\times\\mathcal{F}_{h}}$ is one where the column indexed by $f_{h}$ is ${\\bf u}(f_{h})$ . Unlike the belief matrix, the outcome matrix $M_{\\mathcal{F},h}$ is dependent on the behavior policy $\\pi_{b}$ , which is omitted in the notation. ", "page_idx": 2}, {"type": "text", "text": "For mathematical conveniences, we make the following assumptions throughout merely for simplifying presentations; they allow us to invert certain covariance matrices and avoid $0/0$ situations, which can be easily handled with extra care when the assumptions do not hold. ", "page_idx": 2}, {"type": "text", "text": "Assumption 2 (Invertibility). $\\forall h\\in[H]$ , $\\operatorname{1})\\operatorname{rank}(M_{\\mathcal{H},h})=\\operatorname{rank}(M_{\\mathcal{F},h})=S.$ (2) $\\forall f_{h}$ , $\\operatorname*{Pr}_{\\pi_{b}}(f_{h})>0;\\forall\\overset{\\cdot}{o}_{h},a_{h}$ , $R(o_{h},a_{h})>0$ . ", "page_idx": 2}, {"type": "text", "text": "Other Notation. Given a vector a, $\\|\\mathbf{a}\\|_{\\Sigma}:=\\sqrt{\\mathbf{a}^{\\top}\\Sigma\\mathbf{a}}$ , where $\\Sigma$ is a positive semi-definite (PSD) matrix. When $\\Sigma=\\mathrm{diag}(d)$ for a stochastic vector $d$ , this is the $d$ -weighted 2-norm of a, which we also write as $\\|\\mathbf{a}\\|_{2,d}$ . For a positive integer $\\mathbf{m}$ , we use $[m]$ to denote the set $\\{1,2,\\cdot\\cdot\\cdot,m\\}$ . For a matrix $M$ , we use $(M)_{i j}$ to denote the $i j$ entry of $M$ . ", "page_idx": 2}, {"type": "text", "text": "3 Future-dependent Value Functions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we provide a recap of FDVFs and translate the main result of Uehara et al. [2022a] into the finite-horizon setting, which is mathematically cleaner and more natural in many aspects; see Appendix B.2 for further discussion. ", "page_idx": 2}, {"type": "text", "text": "To illustrate the main idea behind FDVFs, recall that the tool that avoids the exponential weights in MDPs is to model the value functions. While we would like to apply the same idea to POMDPs, ", "page_idx": 2}, {"type": "text", "text": "history-dependent value functions lead to unfavorable coverage conditions (see Section 1). The only other known notion of value functions we are left with is that over the latent state space, $V_{S}^{\\pi_{e}}(s_{h})$ , which unfortunately is not accessible to the learner since it operates on unobservable latent states. ", "page_idx": 3}, {"type": "text", "text": "The central idea is to find observable proxies of $V_{S}^{\\pi_{e}}(s_{h})$ , which takes future as inputs: ", "page_idx": 3}, {"type": "text", "text": "Definition 3 (Future-dependent value functions [Uehara et al., 2022a]). A future-dependent value function $V_{\\mathcal{F}}\\,:\\,\\mathcal{F}\\,\\rightarrow\\,\\mathbb{R}$ , where $\\textstyle\\mathcal{F}:=\\bigcup_{h}\\mathcal{F}_{h}$ , is any function that satisfies the following: $\\forall s_{h}$ , $\\mathbb{E}_{\\pi_{b}}\\left[V_{\\mathcal{F}}(f_{h})\\mid s_{h}\\right]=V_{S}^{\\pi_{e}}(s_{h})$ . Equivale ntly, in matrix form, we have $\\forall h$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\nM_{\\mathcal{F},h}\\times V_{\\mathcal{F},h}=V_{S,h}^{\\pi_{e}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Recall our convention, that $V_{\\mathcal{F},h}\\in\\mathbb{R}^{|\\mathcal{F}_{h}|}$ is $V_{\\mathcal{F}}$ restricted to $\\mathcal{F}_{h}$ , and $V_{S,h}^{\\pi_{e}}$ is defined similarly. ", "page_idx": 3}, {"type": "text", "text": "A FDVF $V_{\\mathcal{F}}$ is a property of $\\pi_{e}$ , but also depends on $\\pi_{b}$ . As we will see later in Section 4, the boundedness of $V_{\\mathcal{F}}$ will depend on certain notion of coverage of $\\pi_{b}$ over $\\pi_{e}$ . As another important property, the FDVF $V_{\\mathcal{F}}$ is generally not unique even if we fix $\\pi_{e}$ and $\\pi_{b}$ , as Eq.(1) is generally an underdetermined linear system $(S\\ll|\\mathcal{F}_{h}|)$ and can yield many solutions. As we see below, it suffices to model any one of the solutions. Thus, from now on, when we talk about the boundedness of $V_{\\mathcal{F}}$ , we always consider the $V_{\\mathcal{F}}$ with the smallest range among all solutions. ", "page_idx": 3}, {"type": "text", "text": "Finite Sample Learning. Like in MDPs, to learn an approximate FDVF from data, we will minimize some form of estimated Bellman residuals (or errors). For that we need to first introduce the Bellman residual operators for FDVFs: ", "page_idx": 3}, {"type": "text", "text": "Definition 4 (Bellman residual operators). $\\forall V:\\mathcal{F}\\rightarrow\\mathbb{R}$ , the Bellman residual on state $s_{h}$ is:2 ", "page_idx": 3}, {"type": "equation", "text": "$$\n(\\mathcal{B}^{\\mathcal{S}}V)(s_{h}):=\\mathbb{E}_{a_{h+1:H}\\sim\\pi_{b}}[r_{h}+V(f_{h+1})\\mid s_{h}]-\\mathbb{E}_{\\pi_{b}}[V(f_{h})\\mid s_{h}].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Similarly, the Bellman residual onto the history $\\tau_{h}$ is: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h}):=\\mathbb{E}_{\\mathbf{\\Phi}_{a_{h+1}:H\\sim\\pi_{b}}}[r_{h}+V(f_{h+1})\\mid\\tau_{h}]-\\mathbb{E}_{\\pi_{b}}[V(f_{h})\\mid\\tau_{h}]=\\langle\\mathbf{b}(\\tau_{h}),\\mathcal{B}_{h}^{S}V\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The following lemma shows that, ideally, we would want to find $V$ with small $B^{S}V$ : ", "page_idx": 3}, {"type": "text", "text": "Lemma 1. For any $\\pi_{e},\\,\\pi_{b}$ , and $\\begin{array}{r}{V:\\mathcal{F}\\to\\mathbb{R},\\ J(\\pi_{e})-\\mathbb{E}_{\\pi_{b}}[V(f_{1})]=\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{e}}\\left[(\\mathcal{B}^{S}V)(s_{h})\\right].}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "See proof in Appendix C.1. As the lemma shows, any $V$ with small $B^{S}V$ (such as $V_{\\mathcal{F}}$ , since $\\beta^{S}\\bar{V}_{\\mathcal{F}}\\equiv0_{\\rightmoon}^{}$ ) can be used to estimate $J(\\pi_{e})$ via $\\mathbb{E}_{\\pi_{b}}[V(f_{1})]$ . But again, $B^{S}$ operates on $\\boldsymbol{S}$ which is unobserved, and we turn to its proxy $B^{\\mathcal{H}}$ , which are linear measures of $B^{S}$ (Eq.2). More concretely, Uehara et al. [2022a] proposed to estimate $\\mathbb{E}_{\\pi_{b}}[(B^{\\mathcal{H}}V)^{2}]$ using an additional helper class $\\Xi:\\mathcal{H}\\to\\mathbb{R}$ to handle the double-sampling issue [Antos et al., 2008, Dai et al., 2018]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat V=\\underset{V\\in\\mathcal V}{\\operatorname{argmin}}\\,\\underset{\\xi\\in\\Xi}{\\operatorname*{max}}\\sum_{h=1}^{H}\\mathcal L_{h}(V,\\xi),}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathcal{L}_{h}(V,\\xi)=\\mathbb{E}_{\\mathcal{D}}[\\{\\mu(a_{h},o_{h})(r_{h}+V(f_{h+1}))-V(f_{h})\\}\\xi(\\tau_{h})-0.5\\xi^{2}(\\tau_{h})]$ . Under the following assumptions, the estimator enjoys a finite-sample guarantee: ", "page_idx": 3}, {"type": "text", "text": "Assumption 5 (Realizability). Let $\\mathcal{V}\\subset(\\mathcal{F}\\rightarrow\\mathbb{R})$ be a finite function class. Assume $V_{\\mathcal{F}}\\in\\mathcal{V}$ for some $V_{\\mathcal{F}}$ satisfying Definition 3. ", "page_idx": 3}, {"type": "text", "text": "Assumption 6 (Bellman completeness). Let $\\Xi\\subset({\\mathcal{H}}\\rightarrow\\mathbb{R})$ be a finite function class. Assume $B^{\\mathcal{H}}V\\in\\Xi$ , $\\forall V\\in\\mathcal{V}$ . ", "page_idx": 3}, {"type": "text", "text": "Theorem 2. Under Assumptions 5 and $5,\\,w.p.\\geq1-\\delta,$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n|J(\\pi_{e})-\\mathbb{E}_{\\mathcal{D}}[\\widehat{V}(f_{1})]|\\leq c H\\operatorname*{max}\\{C\\nu+1,C\\Xi\\}\\cdot\\mathrm{IV}(\\mathcal{V})\\mathrm{Dr}_{\\mathcal{V}}[d^{\\pi_{e}},d^{\\pi_{b}}]\\sqrt{\\frac{C_{\\mu}\\log\\frac{|\\mathcal{V}||\\Xi|}{\\delta}}{n}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $c$ is an absolute constant,3 and $\\begin{array}{r}{C_{\\mathcal{V}}:=\\operatorname*{max}_{V\\in\\mathcal{V}}\\|V\\|_{\\infty},\\,C_{\\Xi}:=\\operatorname*{max}_{\\xi\\in\\Xi}\\|\\xi\\|_{\\infty},}\\end{array}$ ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{IV}(\\mathcal{V}):=\\operatorname*{max}_{h}\\operatorname*{sup}_{V\\in\\mathcal{V}}\\sqrt{\\frac{\\mathbb{E}_{\\pi_{b}}\\left[\\left(B^{S}V\\right)(s_{h})^{2}\\right]}{\\mathbb{E}_{\\pi_{b}}\\left[\\left(B^{\\mathcal{H}}V\\right)(\\tau_{h})^{2}\\right]}},\\quad\\mathrm{Dr}_{\\mathcal{V}}[d^{\\pi_{c}},d^{\\pi_{b}}]:=\\operatorname*{max}_{h}\\operatorname*{sup}_{V\\in\\mathcal{V}}\\sqrt{\\frac{\\mathbb{E}_{\\pi_{e}}\\left[\\left(B^{S}V\\right)(s_{h})^{2}\\right]}{\\mathbb{E}_{\\pi_{b}}\\left[\\left(B^{S}V\\right)(s_{h})^{2}\\right]}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "2We let $V(f_{H+1})\\equiv0$ for all $V$ to be considered, so that we do not need to handle the $H$ -th step separately.   \n3The value of $c$ can differ in each occurrence, and we reserve the symbol $c$ for such absolute constants. ", "page_idx": 3}, {"type": "text", "text": "See proof in Appendix C.2. Among the objects that appear in the bound, some are mundane and expected (e.g., horizon $H$ , the complexities of function classes log $|\\gamma||\\Xi|$ , etc.). We now focus on the important ones, which reveals the open questions we shall investigate next: ", "page_idx": 4}, {"type": "text", "text": "1. $\\mathrm{Dr}_{\\mathcal{V}}[d^{\\pi_{e}},d^{\\pi_{b}}]$ measures the coverage of $\\pi_{b}$ over $\\pi_{e}$ on the latent state space $\\boldsymbol{S}$ , as the expression inside square-root can be bounded by $\\mathrm{max}_{s_{h}}\\,d^{\\pi_{e}}(s_{h})/d^{\\pi_{b}}(s_{h})$ .   \n2. (Q1) $C_{\\mathcal{V}}$ is the range of the $\\nu$ class. Since $V_{\\mathcal{F}}\\in\\mathcal{V}$ (Assumption 5), $C_{\\mathcal{V}}\\geq\\|V_{\\mathcal{F}}\\|_{\\infty}$ . However, unlike the standard value functions in MDPs which have obviously bounded range $[0,H]$ (this also applies to $V_{S}^{\\pi_{e}}$ ), the range of $V_{\\mathcal{F}}$ is unclear. Similarly, since $\\Xi$ needs to capture $B^{\\mathcal{H}}V$ for $V\\in\\mathcal{V}$ , the boundedness of $\\Xi$ is also affected.   \n3. (Q2) $\\operatorname{IV}(\\mathcal{V})$ appears because we use $B^{\\mathcal{H}}V$ as a proxy for $B^{S}V$ , which is only a linear measure of the latter, $(\\bar{B}^{\\mathcal{H}}V)(\\tau_{h})\\,=\\,\\langle{\\bf b}(\\tau_{h}),B_{h}^{s}V\\rangle$ . $\\operatorname{IV}(\\mathcal{V})$ reflects the conversion ratio between them. Uehara et al. [2022a] pointed out that the value is finite if $M_{\\mathcal{H},h}$ has full-row rank $(S)$ , but a quantitative understanding is missing. ", "page_idx": 4}, {"type": "text", "text": "The rest of the paper proposes new coverage assumptions, analyses, and algorithms to answer the above questions, providing deeper understanding on the mathematical structure of OPE in POMDPs. ", "page_idx": 4}, {"type": "text", "text": "4 Boundedness of FDVFs ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We start with Q1: when are FDVFs bounded? Recall from Definition 3 that a FDVF at level $h$ , $V_{\\ensuremath{\\mathcal{F}},h}$ , is any function satisfying $M_{\\mathcal{F},h}\\times V_{\\mathcal{F},h}\\,=\\,V_{\\mathcal{S},h}^{\\pi_{e}}$ , where $M_{\\mathcal{F},h}$ is the outcome matrix with $(M_{{\\mathcal F},h})_{i,j}\\,=\\,\\operatorname*{Pr}_{\\pi_{b}}(f_{h}\\,=\\,j\\;\\mid\\,s_{h}\\,=\\,i)$ . Since the equation can have many solutions and we only need to find one of them, it suffices to provide an explicit construction of a $V_{\\mathcal{F},h}$ and show it is well bounded. Also note that the equations for different $h$ are independent of each other, so we can construct $V_{\\ensuremath{\\mathcal{F}},h}$ for each $h$ separately. ", "page_idx": 4}, {"type": "text", "text": "We first describe two natural constructions, both of which yield exponentially large upper bounds. ", "page_idx": 4}, {"type": "text", "text": "Importance Sampling Solution. Uehara et al. [2022a] provided a cruel bound on $\\|V_{\\mathcal{F}}\\|_{\\infty}$ which scales with $1/\\sigma_{\\operatorname*{min}}(M_{\\mathcal{F},h})$ , which we show shortly is an exponential-in-length quantity. However, it is not hard to notice that in certain benign cases, $V_{\\mathcal{F}}$ does not have to blow-up exponentially and has obviously bounded constructions. ", "page_idx": 4}, {"type": "text", "text": "As a warm-up, consider the on-policy case of $\\pi_{b}\\,=\\,\\pi_{e}$ , where a natural solution is $V_{\\mathcal{F}}(f_{h})\\;=$ $\\begin{array}{r}{R^{+}(f_{h}):=\\sum_{h^{\\prime}=h}^{H}R(o_{h^{\\prime}},a_{h^{\\prime}})}\\end{array}$ . Here $R^{+}(f_{h})$ simply adds up the Monte-Carlo rewards in future $f_{h}$ , which is bo unded in $[0,H]$ . The construction trivially satisfies $\\mathbb{E}_{\\pi_{b}}\\left[V_{\\mathcal{F}}(f_{h})\\mid s_{h}\\right]=V_{S}^{\\pi_{e}}(s_{h})$ when $\\pi_{b}=\\pi_{e}$ . In the more general setting of $\\pi_{b}\\neq\\pi_{e}$ , the hope is that $V_{\\mathcal{F}}$ can be still bounded up to some coverage condition that measures how $\\pi_{e}$ deviates from $\\pi_{b}$ . ", "page_idx": 4}, {"type": "text", "text": "Unfortunately, generalizing the above equation to the off-policy case raises issues: consider the solution VF(fh) = R+(fh) \u00b7  hH\u2032=h\u03c0\u03c0be((aahh\u2032\u2032||oohh\u2032\u2032)), whose correctness can be verified by importance sampling. Despite its validity, the construction involves cumulative action importance weights, which erases the superiority of the framework over IS as discussed in the introduction. ", "page_idx": 4}, {"type": "text", "text": "Pseudo-inverse Solution. Another direction is to simply treat Eq.(1) as a linear system. Given that the system is under-determined, we can use pseudo-inverse:4 $V_{\\mathcal{F},h}=M_{\\mathcal{F},h}^{\\top}\\left(M_{\\mathcal{F},h}M_{\\mathcal{F},h}^{\\top}\\right)^{-1}V_{S,h}^{\\pi_{e}}$ In this case, $\\|V_{\\mathcal{F}}\\|_{\\infty}$ can be bounded using $1/\\sigma_{\\operatorname*{min}}(M_{\\mathcal{F},h})$ , where $\\sigma_{\\mathrm{min}}$ denotes the smallest singular value. In fact, closely related quantities have appeared in the recent POMDP literature; for example, in the online setting, Liu et al. [2022a] used $\\sigma_{\\mathrm{min}}$ of an action-conditioned variant of $M_{\\mathcal{F},h}$ as a complexity parameter for online exploration in POMDPs. Unfortunately, these quantities suffer from scaling issues: $1/\\sigma_{\\operatorname*{min}}(M_{\\mathcal{F},h})$ is guaranteed to be misbehaved if the process is sufficiently stochastic. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\small^{f}\\mathrm{Pr}_{\\pi_{b}}}(f_{h}|_{s})\\leq\\frac{C_{s t o h}}{(O A)^{H-h+1}},\\forall f_{h},s_{h},\\,t h e n\\,\\sigma_{\\operatorname*{min}}(M_{\\mathcal{F},h})\\leq C_{s t o c h}\\sqrt{S}/(O A)^{\\frac{H-h+1}{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In this example, $C_{\\mathrm{stoch}}$ measures how the distribution of $f_{h}$ under $\\pi_{b}$ deviates multiplicatively from a uniform distribution over ${\\mathcal{F}}_{h}$ , and an even moderately stochastic $\\pi_{b}$ and emission process $\\mathbb{O}$ will lead to small $C_{\\mathrm{stoch}}$ , which implies an exponentially large $1/\\sigma_{\\mathrm{min}}(M_{\\mathcal{F},h})$ . ", "page_idx": 5}, {"type": "text", "text": "4.1 Minimum Weighted 2-Norm Solution and $L_{2}$ Outcome Coverage ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Pseudo-inverse finds the minimum $L_{2}$ norm solution. However, given that we are searching for solutions in $\\mathbb{R}^{\\mathcal{F}_{h}}$ which has an exponential dimensionality, the standard $L_{2}$ norm\u2014which treats all coordinates equally\u2014is not a particularly informative metric. Instead, we propose to minimize the weighted $L_{2}$ norm with a particular weighting scheme, which has also been used in HMMs [Mahajan et al., 2023] and enjoys benign properties. ", "page_idx": 5}, {"type": "text", "text": "We first define the diagonal weight matrix $Z_{h}:=\\mathrm{diag}(\\mathbf{1}_{S}^{\\top}M_{\\mathcal{F},h})$ , where $\\mathbf{1}_{S}\\in\\mathbb{R}^{S}=[1,\\cdots,1]^{\\top}$ is the all-one vector. Then, the solution that minimizes $\\Vert\\cdot\\Vert_{Z_{h}}$ is: ", "page_idx": 5}, {"type": "equation", "text": "$$\nV_{\\mathcal{F},h}=Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}V_{\\mathcal{S},h}^{\\pi_{e}},\\ \\ \\mathrm{where}\\ \\Sigma_{\\mathcal{F},h}:=M_{\\mathcal{F},h}Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\Sigma_{\\mathcal{F},h}\\in\\mathbb{R}^{S\\times S}$ plays an important role in this construction. Recall that its counterpart in the pseudoinverse solution, namely $M_{\\mathcal{F},h}M_{\\mathcal{F},h}^{\\top}$ , has scaling issues (Example 1), that even its largest eigenvalue can decay exponentially with $H-h+1$ . In contrast, $\\Sigma{\\mathcal{F}}{,h}$ is very well-behaved in its magnitude, as shown below. Furthermore, while $M_{\\mathcal{F},h}^{\\top}$ on the left is now multiplied by $Z_{h}^{-1}$ which can be exponentially large, $Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top}$ together is still well-behaved; see proof in Appendix D.2. ", "page_idx": 5}, {"type": "text", "text": "Proposition 3 (Properties of Eq.(4)). 1. $\\Sigma_{\\mathcal{F},h}$ is doubly-stochastic: that is, each row/column of $\\Sigma_{\\mathcal{F},h}$ is non-negative and sums up to 1. As a consequence, $\\sigma_{\\operatorname*{max}}(\\Sigma_{\\mathcal{F},h})=1$ . ", "page_idx": 5}, {"type": "text", "text": "2. Rows of $Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top}$ , i.e., $\\{\\mathbf{u}(f_{h})^{\\top}/Z(f_{h})\\,:\\,f_{h}\\,\\in\\,\\mathcal{F}_{h}\\}$ , are stochastic vectors, i.e., they are non-negative and the row sum is $1$ . ", "page_idx": 5}, {"type": "text", "text": "Therefore, it is promising to make the assumption that $\\sigma_{\\mathrm{min}}(\\Sigma_{\\mathcal{F},h})$ is bounded away from zero, which immediately leads to the boundedness of $V_{\\mathcal{F}}$ given that of $Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top}\\left([0,1]\\right)$ and $V_{S}^{\\pi_{e}}\\left([0,H]\\right)$ . However, we need to rule out the possibility that $\\Sigma_{\\mathcal{F},h}$ is always near-singular, and find natural examples that admit large $\\sigma_{\\mathrm{min}}(\\Sigma_{\\mathcal{F},h})$ , as given below. ", "page_idx": 5}, {"type": "text", "text": "Example 2. Suppose $f_{h}$ always reveals $s_{h}$ , in the sense that for any $j\\in\\mathcal{F}_{h}$ , $\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=j\\mid s_{h}=i)$ is only non-zero for a single $i\\in[S]$ , and zero for all other latent states. Then, $\\begin{array}{r}{\\Sigma_{\\mathcal{F},h}=\\mathbf{I},}\\end{array}$ , the identity matrix. Furthermore, $V_{\\mathcal{F}}$ from Eq.(4) satisfies $\\|V_{\\mathcal{F}}\\|_{\\infty}\\le H$ . See Appendix $D.3$ for details. ", "page_idx": 5}, {"type": "text", "text": "The example shows an ideal case where $\\sigma_{\\mathrm{min}}\\mathopen{}\\mathclose\\bgroup\\left(\\Sigma_{\\mathcal{F},h}\\aftergroup\\egroup\\right)\\,=\\,\\sigma_{\\mathrm{max}}\\mathopen{}\\mathclose\\bgroup\\left(\\Sigma_{\\mathcal{F},h}\\aftergroup\\egroup\\right)\\,=\\,1$ , when the future fully determines $s_{h}$ . This can happen when the last observation $O H$ reveals the identity of an earlier latent state $s_{h}$ . Note that in this case, $M_{\\mathcal{F},h}M_{\\mathcal{F},h}^{\\top}$ can still have poor scaling if the actions and observations between step $h$ and $H$ are sufficiently stochastic, which shows how the weighted 2-norm solution and analysis improve over the pseudo-inverse one. More generally, $\\Sigma{\\boldsymbol{\\mathcal{F}}}{,}h$ is the confusion matrix of making posterior predictions of $s_{h}$ from $f_{h}$ based on a uniform prior over $\\ensuremath{\\mathcal{S}}_{h}$ (see Appendix B.8 for how to incorporate different priors) with $\\bar{\\mathbf u}(f_{h})^{\\top}/Z(f_{h})$ being the posterior, and $\\sigma_{\\mathrm{min}}(\\Sigma_{\\mathcal{F},h})$ serves as a measure of how the distribution of future $f_{h}$ helps reveal the latent state $s_{h}$ . ", "page_idx": 5}, {"type": "text", "text": "We now break down the boundedness of Eq.(4) into more interpretable assumptions. ", "page_idx": 5}, {"type": "text", "text": "Assumption 7 (L2 outcome coverage). Assume for all h, \u2225V S\u03c0,eh\u22252\u03a3\u22121 \u2264CF,V .   \nAssumption 8 (\u03a3F,h regularity). Assume for any fh: \u2225u(fh)/Z(fh)\u22252\u03a3F\u2212,1h \u2264CF,U. ", "page_idx": 5}, {"type": "text", "text": "Proposition 4 (Boundedness of FDVF). Under Assumptions 7 and 8, $V_{\\mathcal{F}}$ in Eq.4 satisfies $\\|V_{\\mathcal{F}}\\|_{\\infty}\\leq$ $\\sqrt{C_{\\mathcal{F},2}}:=\\sqrt{C_{\\mathcal{F},V}C_{\\mathcal{F},U}}$ . Furthermore, when only Assumption 7 holds, $\\|V_{\\mathcal{F},h}\\|_{Z_{h}}\\le\\sqrt{C_{\\mathcal{F},V}},\\,\\forall h.$ . See proof in Appendix D.4. Assumption 7 requires that the weighted covariance matrix $\\Sigma{\\mathcal{F}}{,h}$ covers the direction of $V_{S,h}^{\\pi_{e}}$ well. As a sanity check, it is always bounded in the on-policy case: ", "page_idx": 5}, {"type": "text", "text": "Example 3. When $\\pi_{b}=\\pi_{e},\\,\\|V_{S,h}^{\\pi_{e}}\\|_{\\Sigma_{\\mathcal{F},h}^{-1}}\\le H\\sqrt{S}.$ . ", "page_idx": 5}, {"type": "text", "text": "Notably, mathematically similar coverage assumptions are also found in the linear MDP literature. For example, with state-action feature $\\phi_{h}$ for time step $h$ , a very tight coverage parameter for linear ", "page_idx": 5}, {"type": "text", "text": "MDPs is $\\|\\mathbb{E}_{\\pi_{e}}[\\phi_{h}]\\|_{\\mathbb{E}_{\\pi_{b}}[\\phi_{h}\\phi_{h}^{\\top}]^{-1}}^{2}$ [Zanette et al., 2021]. Despite the mathematically similarity, there are important high-level differences between these notions of coverage: ", "page_idx": 6}, {"type": "text", "text": "1. As mentioned earlier, MDP coverage is concerned with the dynamics before step $h$ , whereas our outcome coverage concerns that after $h$ . Relatedly, MDP coverage depends on the initial distribution (which our outcome coverage does not depend on), and our coverage depends on the reward function through $V_{\\mathcal{F}}$ (which MDP coverage does not explicitly depend on). In Section 5, we will discuss our other coverage assumption (belief coverage), which is more similar to the MDP coverage in that they are both concerned with the past. ", "page_idx": 6}, {"type": "text", "text": "2. The linear MDP coverage assumption is a refinement of state-density ratio using the knowledge of the function class [Chen and Jiang, 2019, Song et al., 2022]. In comparison, the linear structure of our outcome-coverage assumption comes directly from the internal structure of POMDPs. ", "page_idx": 6}, {"type": "text", "text": "4.2 Addressing $S$ dependence via $L_{1}/L_{\\infty}$ H\u00f6lder and $L_{\\infty}$ Outcome Coverage ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Example 3 shows that even in the on-policy case, $C_{\\mathcal{F},V}$ may depend on $S$ which makes the assumption only meaningful for finite and small $\\boldsymbol{S}$ . In fact, we showed earlier that $V_{\\mathcal{F}}=R^{+}$ is a natural and obvious $L_{\\infty}$ -bounded solution for $\\pi_{b}=\\pi_{e}$ , but this is not recovered by the construction in Eq. (4). We also need an additional regularity Assumption 8. ", "page_idx": 6}, {"type": "text", "text": "As it turns out, these undesired properties arise because $L_{2}$ H\u00f6lder\u2014which is natural for linear MDP settings mentioned above\u2014fails to leverage the $L_{1}$ normalization of $\\mathbf u(f_{h})^{\\top}/Z(f_{h})$ (Proposition 4, Claim 2) and is loose for POMDPs; see Appendix B.5 for further details. A better choice is $L_{1}/L_{\\infty}$ H\u00f6lder, motivating the $L_{\\infty}$ coverage assumption below, which requires a slightly different construction of $V_{\\mathcal{F}}$ . These definitions may seem mysterious or even counterintuitive; it will be easier to explain the intuitions when we get to their counterparts for belief coverage in Section 5.2. ", "page_idx": 6}, {"type": "text", "text": "Construction of $V_{\\mathcal{F}}$ Define $Z^{R}(f_{h}):=Z(f_{h})/R^{+}(f_{h})$ , and we use $Z^{R}$ to replace $Z$ in Eq.(4): ", "page_idx": 6}, {"type": "equation", "text": "$$\nV_{\\mathcal{F},h}=(Z_{h}^{R})^{-1}M_{\\mathcal{F},h}^{\\top}(\\Sigma_{\\mathcal{F},h}^{R})^{-1}V_{\\mathcal{S},h}^{\\pi_{e}},\\quad\\mathrm{where~}\\Sigma_{\\mathcal{F},h}^{R}:=M_{\\mathcal{F},h}(Z_{h}^{R})^{-1}M_{\\mathcal{F},h}^{\\top}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Assumption 9 $\\mathit{L}_{\\infty}$ outcome coverage). Assume for all $h$ , $\\|(\\Sigma_{\\mathcal{F},h}^{R})^{-1}V_{S}^{\\pi_{e}}\\|_{\\infty}\\leq C_{\\mathcal{F},\\infty}.$ ", "page_idx": 6}, {"type": "text", "text": "Lemma 5. Under Assumption 9, $\\|V_{\\mathcal{F}}\\|_{\\infty}\\le H C_{\\mathcal{F},\\infty}$ . See proof in Appendix E.7. ", "page_idx": 6}, {"type": "text", "text": "In Appendix B.5 we show that the construction shares similar properties to Eq.(4) in the scenario of Example 2. On the other hand, it has better scaling properties w.r.t. $S$ and does not additionally require a regularity assumption like Assumption 8. In the on-policy case, Eq.(5) exactly recovers $V_{\\mathcal{F}}=R^{+}$ , a property that Eq.(4) does not enjoy; see Appendix E.8 for details. ", "page_idx": 6}, {"type": "text", "text": "Example 4. W\u221ahen $\\pi_{e}~=~\\pi_{b}$ , $(\\Sigma_{\\mathcal{F},h}^{R})^{-1}V_{S}^{\\pi_{e}}\\ =\\ \\mathbf{1}$ , thus Assumption 9 holds with $C_{\\mathcal{F},\\infty}\\ =\\ 1$ $(c.f.\\;C_{{\\mathcal{F}},V}\\leq H{\\sqrt{S}}$ in Example 3). Furthermore, the construction in Eq.(5) is exactly $V_{\\mathcal{F}}=R^{+}$ . ", "page_idx": 6}, {"type": "text", "text": "5 Effective History Weights and A New Algorithm ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now turn to Q2 in Section 3, which asks for a quantitative understanding of the $\\mathbf{IV}(\\mathcal{V})$ term. Note that $\\mathbf{IV}(\\mathcal{V})$ and $\\operatorname{Dr}_{\\mathcal{V}}[d^{\\pi_{e}},d^{\\pi_{b}}]$ , taken together, are to address the conversion between: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{:minimize:}\\,\\,\\sqrt{\\mathbb{E}_{\\pi_{b}}[(B^{\\mathcal{H}}V)(\\tau_{h})^{2}]}\\,\\,\\,\\rightarrow\\,\\,\\,(\\mathrm{We~want~to~bound:})\\,\\,|\\mathbb{E}_{\\pi_{e}}[(B^{S}V)(s_{h})]|.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The two terms differ both in the policy $\\langle\\pi_{b}\\rightarrow\\pi_{e}\\rangle$ ) and the operator $(B^{\\mathcal{H}}\\to B^{S})$ ). While we could directly define a parameter by taking the worst-case (over $V\\in\\mathcal{V}$ ) ratio between the two expressions,5 the real question is to provide more intuitive understanding of when it can be bounded. ", "page_idx": 6}, {"type": "text", "text": "Towards this goal, Uehara et al. [2022a] split the above ratio into two terms, $\\operatorname{IV}(\\mathcal{V})$ and $\\mathrm{Dr}_{\\mathcal{V}}[d^{\\pi_{e}},d^{\\pi_{b}}]$ , which take care of the $B^{\\mathcal{H}}\\ \\to\\ \\bar{B}^{\\mathcal{S}}$ conversion (under $\\pi_{b}$ ) and $\\pi_{b}\\,\\rightarrow\\,\\pi_{e}$ conversion (under $B^{S}$ ), respectively. While this leads to an intuitive upper bound of the $\\pi_{b}\\rightarrow\\pi_{e}$ conversion parameter in terms of latent state coverage, the nature of the ${\\dot{B}}^{\\mathcal{H}}\\rightarrow B^{S}$ conversion, $\\mathbf{IV}(\\mathcal{V})$ , remains mysterious. ", "page_idx": 6}, {"type": "text", "text": "In this section, we take a different approach by directly providing an intuitive upper bound on both conversions altogether, under a novel belief coverage assumption. In Appendix E.4 we will also revisit the split into $\\mathrm{IV}(\\mathcal{V})$ and $\\operatorname{Dr}_{\\mathcal{V}}[d^{\\pi_{e}},d^{\\pi_{b}}]$ : in the absence of strong structures from $\\mathcal{V}$ , the boundedness of $\\operatorname{IV}(\\mathcal{V})$ turns out to require an even stronger version of belief coverage, rendering the split unnecessary. Furthermore, our approach also leads to a novel algorithm for estimating $\\bar{J}(\\pi_{e})$ that replaces Bellman-completeness (Assumption 6) with a weight-realizability assumption, similar to MIS estimators for MDPs [Liu et al., 2018, Uehara et al., 2020]. ", "page_idx": 7}, {"type": "text", "text": "5.1 Effective History Weights ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The key idea in this section is the notion of effective history weights, that perform the $\\pi_{b}\\rightarrow\\pi_{e}$ and $B^{\\mathcal{H}}\\rightarrow\\overline{{B^{s}}}$ conversions jointly. ", "page_idx": 7}, {"type": "text", "text": "Definition 10 (Effective history weights). An effective history weight function $w^{\\star}:\\mathcal{H}\\rightarrow\\mathbb{R}$ is any function that satisfies: $\\forall V\\in\\mathcal{V}$ , $h\\in[H]$ , ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\boldsymbol\\pi_{b}}[w^{\\star}(\\tau_{h})(\\beta^{\\mathcal{H}}V)(\\tau_{h})]=\\mathbb{E}_{\\boldsymbol\\pi_{e}}\\left[(\\beta^{\\mathcal{S}}V)(s_{h})\\right].\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "We first see that well-bounded $w^{\\star}$ immediately leads to a good conversion ratio for Eq.(6): ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\mathbb{E}_{\\pi_{e}}\\left[(B^{S}V)(s_{h})\\right]|=|\\mathbb{E}_{\\pi_{b}}[w^{\\star}(\\tau_{h})(B^{\\mathcal{H}}V)(\\tau_{h})]|\\le\\sqrt{\\mathbb{E}_{\\pi_{b}}[w^{\\star}(\\tau_{h})^{2}]\\mathbb{E}_{\\pi_{b}}[(B^{\\mathcal{H}}V)(\\tau)^{2}]},}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where the inequality follows from Cauchy-Schwartz for r.v.\u2019s. Hence, all we need is $\\|\\boldsymbol{w}^{\\star}\\|_{2,d_{h}^{\\pi_{b}}}:=$ $\\sqrt{\\mathbb{E}_{\\pi_{b}}[w^{\\star}(\\tau_{h})^{2}]}$ , the $\\pi_{b}$ -weighted 2-norm of $w^{\\star}$ , to be bounded, and we focus on this quantity next. Similar to Section 4, there may be multiple $w^{\\star}$ that satisfies the definition, and we only need to show the boundeness of any solution. Also similarly, the most obvious solution is w\u22c6(\u03c4h) = PPrr\u03c0\u03c0be((\u03c4\u03c4hh)) $\\begin{array}{r}{\\prod_{h^{\\prime}=1}^{h-1}\\frac{\\pi_{e}\\left(a_{h^{\\prime}}\\left|o_{h^{\\prime}}\\right.\\right)}{\\pi_{b}\\left(a_{h^{\\prime}}\\left|o_{h^{\\prime}}\\right.\\right)}}\\end{array}$ , ing that $\\mathbb{E}_{\\pi_{e}}\\left[(\\mathcal{B}^{S}V)(s_{h})\\right]=\\mathbb{E}_{\\pi_{e}}\\left[(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h})\\right]$ and importance weighting on $\\tau_{h}$ changes $\\mathbb{E}_{\\pi_{b}}$ to $\\mathbb{E}_{\\pi_{e}}$ . However, the use of cumulative importance weights is undesirable given its exponential nature, causing the history-version of \u201ccurse of horizon\u201d Liu et al. [2018]. ", "page_idx": 7}, {"type": "text", "text": "Construction by Belief Matching. We now show a better construction that is bounded under a natural belief coverage assumption. Note that Def 10 can be written as: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\boldsymbol\\pi_{b}}[w^{\\star}(\\tau_{h})\\langle\\mathbf{b}(\\tau_{h}),\\mathcal{B}_{h}^{S}V\\rangle]=\\mathbb{E}_{\\boldsymbol\\pi_{e}}\\left[\\langle\\mathbf{b}(\\tau_{h}),\\boldsymbol{B}_{h}^{S}V\\rangle\\right],\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $B_{h}^{S}V\\in\\mathbb{R}^{S}$ is the Bellman residual vector for $V$ on $\\ensuremath{\\mathcal{S}}_{h}$ . As a sufficient condition (which is also necessary when $\\nu$ lacks strong structures, i.e., $\\{B_{h}^{S}V:V\\in\\mathcal{V}\\}$ spans the entire $\\mathbb{R}^{S}$ ), we can find $w^{\\star}$ that satisfies: $\\mathbb{E}_{\\pi_{b}}[w^{\\star}(\\tau_{h})\\bar{\\mathbf{b}}(\\tau_{h})]=\\mathbb{E}_{\\pi_{e}}\\left[\\mathbf{b}(\\bar{\\tau}_{h})\\right]=:$ . This is related to the mean matching problem in the distribution shift literature [Gretton et al., 2009, Yu and Szepesv\u00e1ri, 2012], and a standard solution is [Bruns-Smith et al., 2023]: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\boldsymbol{w}^{\\star}(\\tau_{h})=\\mathbf{b}(\\tau_{h})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\begin{array}{r}{\\Sigma_{\\mathcal{H},h}:=\\sum_{\\tau_{h}}d^{\\pi_{b}}(\\tau_{h})\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}}\\end{array}$ , and $\\mathbf{b}_{h}^{\\pi_{e}}$ coincides with $\\left[d^{\\pi_{e}}(s_{h})\\right]_{s_{h}}$ . ", "page_idx": 7}, {"type": "text", "text": "The weighted 2-norm of this solution is immediately bounded under the following assumption. ", "page_idx": 7}, {"type": "text", "text": "Assumption 11 $L_{2}$ belief coverage). Assume $\\forall h$ , $\\|\\mathbf{b}_{h}^{\\pi_{e}}\\|_{\\Sigma_{\\mathcal{H},h}^{-1}}^{2}\\le C\\varkappa_{\\mathcal{H},2}$ . ", "page_idx": 7}, {"type": "text", "text": "Lemma 6. Under Assumption $_{l l}$ , $w^{\\star}$ in Eq. (8) satisfies \u2200h, $\\lVert\\boldsymbol{w}^{\\star}\\rVert_{2,d_{h}^{\\pi_{b}}}^{2}\\leq C_{\\mathcal{H},2}$ . See Appendix E.1. ", "page_idx": 7}, {"type": "text", "text": "Assumption 11 requires that the covariance matrix of belief states under $\\pi_{b}$ covers ${\\bf b}^{\\pi_{e}}$ , the average belief state under $\\pi_{e}$ . As before, we also check the on-policy case (see Appendix E.2): ", "page_idx": 7}, {"type": "text", "text": "Example 5. In the on-policy case $\\prime\\pi_{b}=\\pi_{e,}$ ), $C_{\\mathcal{H},2}\\leq1$ . ", "page_idx": 7}, {"type": "text", "text": "Algorithm Guarantee Now we have all the pieces to present a fully polynomial version of Theorem 2 under the proposed coverage assumptions. One subtlety is that the guarantee depends on $C_{\\mathcal{V}}:=\\operatorname*{max}_{V\\in\\mathcal{V}}\\|V\\|_{\\infty}$ , which is closely related to $\\|V_{\\mathcal{F}}\\|_{\\infty}$ since we require $V_{\\mathcal{F}}\\in\\mathcal{V}$ , but they are not equal since $\\mathcal{V}$ can include other functions with higher range. To highlight the dependence of $\\|V_{\\mathcal{F}}\\|_{\\infty}$ on the proposed coverage assumptions, we follow Xie and Jiang [2020] to assume that the range of the function classes is not much larger than that of the function it needs to capture. A similar assumption applies for bounding $C_{\\Xi}$ . The proof of the theorem is deferred to Appendix E.10. ", "page_idx": 7}, {"type": "text", "text": "Theorem 7. Consider the same setting as Theorem 2, and let Assumptions $_{l l}$ and 9 hold. For some absolute constant $c,$ further assume $\\bar{C}_{\\mathcal{V}}\\,\\leq\\,c\\|V_{\\mathcal{F}}\\|_{\\infty}$ for $V_{\\mathcal{F}}$ in $E q$ .(5) and $C_{\\Xi}\\,\\le\\,c(\\|V_{\\mathcal{F}}\\|_{\\infty}+1)$ . W.p. \u22651 \u2212\u03b4, |J(\u03c0e) \u2212ED[V  (f1)]| \u2264cH2(CF,\u221e+ 1) CH,2C\u00b5 long(|V||\u039e|/\u03b4). ", "page_idx": 8}, {"type": "text", "text": "In addition to $H$ and complexities of $\\vert\\nu\\vert$ and $|\\Xi|$ , the bound only depends on the intuitive coverage parameters: $C_{\\mu}$ (action coverage), $C_{\\mathcal{H},2}$ ( $L_{2}$ belief coverage), and $C_{\\mathcal{F},\\infty}$ ( $L_{\\infty}$ outcome coverage). ", "page_idx": 8}, {"type": "text", "text": "5.2 $L_{\\infty}$ Belief Coverage ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Assumption 11 enables bounded second moment of $w^{\\star}$ (Lemma 6) but does not control $\\|w^{\\star}\\|_{\\infty}$ , which we show will be useful for the new algorithm in Section 5.3. Here we present the $L_{\\infty}$ version of belief coverage that controls $\\|w^{\\star}\\|_{\\infty}$ , which also helps understand $L_{\\infty}$ outcome coverage given the symmetry between history and future. As alluded to in Section 4.2 and Appendix B.5, $L_{2}$ H\u00f6lder is inappropriate for controlling the infinity-norm since it does not leverage the $L_{1}$ normalization of vectors in POMDPs. Instead, we propose the following decomposition based on $L_{1}/L_{\\infty}$ H\u00f6lder: $|w^{\\star}(\\tau_{h})|\\leq\\|\\mathbf b(\\tau_{h})\\|_{1}\\|\\Sigma_{\\mathcal H,h}^{-1}\\mathbf b_{h}^{\\pi_{e}}\\|_{\\infty}=\\|\\Sigma_{\\mathcal H,h}^{-1}\\mathbf b_{h}^{\\pi_{e}}\\|_{\\infty}$ . This way, we can immediately bound $\\|w^{\\star}\\|_{\\infty}$ with the following assumption: ", "page_idx": 8}, {"type": "text", "text": "Assumption 12 ( $L_{\\infty}$ belief coverage). Assume $\\forall h$ , $\\|{\\Sigma_{\\mathcal{H},h}^{-1}}\\mathbf{b}_{h}^{\\pi_{e}}\\|_{\\infty}\\leq C_{\\mathcal{H},\\infty}$ . Then $\\|w^{\\star}\\|_{\\infty}\\leq C_{\\mathcal{H},\\infty}$ . ", "page_idx": 8}, {"type": "text", "text": "$\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}$ is the inverse of second moment (covariance) multiplying the first moment (expectation), raising the concern that the quantity may be poorly scaled: for example, given bounded (but otherwise arbitrary) random vector $X$ , $\\mathbb{E}[X\\dot{X}^{\\top}]^{\\underline{{\\bullet}}_{1}}\\mathbb{E}[\\dot{X}]$ can go to infinity if we rescale $X$ by a small constant. First note that such a pathology cannot happen here because the random vectors $(\\mathbf{b}(\\tau_{h}))$ are $L_{1}$ - normalized and cannot be arbitrarily rescaled. Below we use a few examples to show that $\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}$ is a very well-behaved quantity, and naturally generalize familiar concepts such as concentrability coefficient from MDPs [Munos, 2007, Chen and Jiang, 2019, Uehara et al., 2022a]. ", "page_idx": 8}, {"type": "text", "text": "We start by checking the on-policy case. Perhaps surprisingly, $\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}$ has an exact solution: ", "page_idx": 8}, {"type": "text", "text": "Example 6. When $\\pi_{e}=\\pi_{b}$ , $\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}=\\mathbf{1}$ , the all-one vector; see Appendix $E.5$ for the calculation.   \nConsequently, Assumption $^{12}$ is satisfied with $C_{\\mathcal{H},\\infty}=1$ . ", "page_idx": 8}, {"type": "text", "text": "The next scenario considers when ${\\bf b}(\\tau_{h})$ is always one-hot, i.e., histories reveal the latent state (this is analogous to Example 2. $L_{\\infty}$ coverage reduces to the familiar concentrability coefficient, the infinity-norm of density ratio as a standard coverage parameter: ", "page_idx": 8}, {"type": "text", "text": "Example 7. When ${\\bf b}(\\tau_{h})$ is always one-hot, $\\begin{array}{r}{\\|\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}\\|_{\\infty}=\\operatorname*{max}_{s_{h}}d^{\\pi_{e}}(s_{h})/d^{\\pi_{b}}\\big(s_{h}\\big).}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "We can also calculate $\\|\\mathbf b_{h}^{\\pi_{e}}\\|_{\\Sigma_{\\mathcal H,h}^{-1}}^{2}$ from Assumption 11, which equals $\\mathbb{E}_{\\pi_{b}}[(d^{\\pi_{e}}(s_{h})/d^{\\pi_{b}}(s_{h}))^{2}]$ in this \u201c1-hot belief\u201d scenario. Xie and Jiang [2020] show that this is tighter than $\\mathrm{max}_{s_{h}}\\,d^{\\pi_{e}}(s_{h})/d^{\\pi_{b}}(s_{h})$ , and this relation extends elegantly to general belief vectors in our setting: ", "page_idx": 8}, {"type": "text", "text": "Lemma 8. $\\|\\mathbf{b}_{h}^{\\pi_{e}}\\|_{\\Sigma_{\\mathcal{H},h}^{-1}}^{2}\\leq\\|\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}\\|_{\\infty}$ . See proof in Appendix E.6. ", "page_idx": 8}, {"type": "text", "text": "5.3 New Algorithm ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The discovery of effective history weights and its boundedness also lead to a new algorithm analogous to MIS methods for MDPs [Uehara et al., 2020]. The idea is that since Lemma 1 tells us to minimize $\\mathbb{E}_{\\pi_{e}}[(B^{S}V)(s_{h})]$ , which equals $\\mathbb{E}_{\\pi_{b}}[w^{\\star}(\\tau_{h})(B^{\\mathcal{H}}V)(\\tau_{h})]$ from Def 10, we can then use another function class $\\mathcal{W}\\subset(\\mathcal{H}\\rightarrow\\mathbb{R})$ to model $w^{\\star}$ , and approximately solve the following: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathop{\\mathrm{argmin}}_{V\\in\\mathcal{V}}\\operatorname*{max}_{w\\in\\mathcal{W}}\\sum_{h=1}^{H}|\\mathbb{E}_{\\pi_{b}}[w(\\tau_{h})(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h})]|,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "which minimizes an upper bound of $\\mathbb{E}_{\\pi_{b}}[w^{\\star}(\\tau_{h})(B^{\\mathcal{H}}V)(\\tau_{h})]$ as long as $w^{\\star}\\in\\mathcal{W}\\subset(\\mathcal{H}\\rightarrow\\mathbb{R})$ . Since there is no square inside the expectation, there is no double-sampling issue and we thus do not need the $\\Xi$ class and its Bellman-completeness assumption. The $h$ -th term of the loss can be estimated straightforwardly as ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}}\\left[w(\\tau_{h})\\left(\\mu(o_{h},a_{h}\\right)(r_{h}+V(f_{h+1}))-V(f_{h})\\right)\\right]\\left|.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "We now provide the sample-complexity analysis of the algorithm, using a more general analysis that allows for approximation errors in $\\nu$ and $\\mathcal{W}$ . ", "page_idx": 9}, {"type": "text", "text": "Assumption 13 (Approximate realizablity). Assume ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{V\\in\\mathcal{V}}{\\operatorname*{min}}\\underset{w\\in\\mathcal{W}}{\\operatorname*{max}}\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[w_{h}(\\tau_{h})\\cdot({\\beta}^{\\mathcal{H}}V)(\\tau_{h})\\right]\\right|\\le{\\epsilon}\\nu,}&{}\\\\ {\\underset{w\\in\\mathrm{sp}(\\mathcal{W})}{\\operatorname*{inf}}\\underset{V\\in\\mathcal{V}}{\\operatorname*{max}}\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[(w_{h}^{\\star}(\\tau_{h})-w_{h}(\\tau_{h}))\\cdot({\\beta}^{\\mathcal{H}}V)(\\tau_{h})\\right]\\right|\\quad}&{\\le{\\epsilon}\\nu.}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Instead of measuring how $\\mathcal{W}$ and $\\nu$ capture our specific constructions of $V_{\\mathcal{F}}$ and $w^{\\star}$ , the above approximation errors automatically allow all possible solutions by measuring the violation of the equations that define $V_{\\mathcal{F}}$ and $w^{\\star}$ . ", "page_idx": 9}, {"type": "text", "text": "We present the sample complexity bound of our algorithm as follows. Similar to Theorem 7, we assume that $C_{\\mathcal{V}}:=\\operatorname*{max}_{V\\in\\mathcal{V}}\\|V\\|_{\\infty}$ and $C_{\\mathcal{W}}:=\\operatorname*{max}_{h}\\operatorname*{sup}_{w\\in\\mathcal{W}}\\|w\\|_{\\infty}$ are not much larger than the corresponding norms of $V_{\\mathcal{F}}$ and $w^{\\star}$ , respectively. See the proof in Appendix E.11. ", "page_idx": 9}, {"type": "text", "text": "Theorem 9. Let $\\widehat V$ be the result of approximating Eq.9 with empirical estimation in Eq.(10). Assume that $C_{\\mathcal{V}}\\leq c\\|V_{\\mathcal{F}}\\|_{\\infty}$ for $V_{\\mathcal{F}}$ in Eq.(5), and $C_{\\mathcal{W}}\\leq c\\|w^{\\star}\\|_{\\infty}$ for $w^{\\star}$ in Eq.(8). Under Assumptions $^{12}$ , 9, and 1 $\\begin{array}{r}{\\begin{array}{r}{\\operatorname{\\langle}p_{\\cdot}\\geq1-\\delta,\\,\\Big|J(\\pi_{e})-\\mathbb{E}_{\\mathcal{D}}[\\widehat{V}(f_{1})]\\Big|\\leq\\epsilon\\nu+\\epsilon\\nu+c H^{2}C_{\\mathcal{H},\\infty}(C_{\\mathcal{F},\\infty}+1)\\sqrt{\\frac{C_{\\mu}\\log\\frac{|\\nu||W|}{\\delta}}{n}}.}\\end{array}}\\end{array}$ ", "page_idx": 9}, {"type": "text", "text": "As a remark, there is also a way to leverage the tighter $L_{2}$ belief coverage, despite that it does not guarantee bounded $\\|w^{\\star}\\|_{\\infty}$ and only $\\|\\boldsymbol{w^{\\star}}\\|_{2,d_{h}^{\\pi_{b}}}^{2}$ . In particular, if all functions in $\\mathcal{W}$ have bounded $\\|\\cdot\\|_{2,d_{h}^{\\pi_{b}}}^{2}$ , the estimator in Eq.(10) will have bounded 2nd moment on the data distribution. In this case, using Median-of-Means estimators [Lerasle, 2019, Chen, 2020] instead of plain averages for Eq.(10) will only pay for the 2nd moment and not the range. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The main text considers memoryless policies. Similar to Uehara et al. [2022a], we can extend to policies that depend on recent observations and actions (or memory). In fact, we provide a more general result in Appendix B.6 that handles recurrent policies that are finite state machines, which allows the policy to depend on long histories. However, the coverage coefficient will be diluted quickly when the memory contains rich information, which we call the curse of memory. We suspect that structural policies are needed to avoid the curse of memory and leave this to future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Nan Jiang acknowledges funding support from NSF IIS-2112471, NSF CAREER IIS-2141781, Google Scholar Award, and Sloan Fellowship. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Andr\u00e1s Antos, Csaba Szepesv\u00e1ri, and R\u00e9mi Munos. Learning near-optimal policies with Bellmanresidual minimization based fitted policy iteration and a single sample path. Machine Learning, 2008. ", "page_idx": 9}, {"type": "text", "text": "Kamyar Azizzadenesheli, Alessandro Lazaric, and Animashree Anandkumar. Reinforcement learning of pomdps using spectral methods. In Conference on Learning Theory, pages 193\u2013256. PMLR, 2016. ", "page_idx": 9}, {"type": "text", "text": "David Bruns-Smith, Oliver Dukes, Avi Feller, and Elizabeth L Ogburn. Augmented balancing weights as linear regression. arXiv preprint arXiv:2304.14545, 2023. ", "page_idx": 9}, {"type": "text", "text": "Fan Chen, Yu Bai, and Song Mei. Partially observable rl with b-stability: Unified structural condition and sharp sample-efficient algorithms. arXiv preprint arXiv:2209.14990, 2022. ", "page_idx": 9}, {"type": "text", "text": "Jinglin Chen and Nan Jiang. Information-theoretic considerations in batch reinforcement learning. In Proceedings of the 36th International Conference on Machine Learning, pages 1042\u20131051, 2019. ", "page_idx": 10}, {"type": "text", "text": "Yen-Chi Chen. A short note on the median-of-means estimator, 2020. ", "page_idx": 10}, {"type": "text", "text": "Bo Dai, Albert Shaw, Lihong Li, Lin Xiao, Niao He, Zhen Liu, Jianshu Chen, and Le Song. Sbeed: Convergent reinforcement learning with nonlinear function approximation. In International Conference on Machine Learning, pages 1133\u20131142, 2018.   \nSimon Du, Akshay Krishnamurthy, Nan Jiang, Alekh Agarwal, Miroslav Dudik, and John Langford. Provably efficient RL with Rich Observations via Latent State Decoding. In International Conference on Machine Learning, pages 1665\u20131674, 2019.   \nYaqi Duan, Zeyu Jia, and Mengdi Wang. Minimax-optimal off-policy evaluation with linear function approximation. In International Conference on Machine Learning, pages 2701\u20132709. PMLR, 2020.   \nMiroslav Dud\u00edk, John Langford, and Lihong Li. Doubly Robust Policy Evaluation and Learning. In Proceedings of the 28th International Conference on Machine Learning, pages 1097\u20131104, 2011.   \nYonathan Efroni, Chi Jin, Akshay Krishnamurthy, and Sobhan Miryoosef.i Provable reinforcement learning with a short-term memory. In International Conference on Machine Learning, pages 5832\u20135850. PMLR, 2022.   \nDamien Ernst, Pierre Geurts, and Louis Wehenkel. Tree-based batch mode reinforcement learning. Journal of Machine Learning Research, 6:503\u2013556, 2005.   \nBenjamin Eysenbach, Swapnil Asawa, Shreyas Chaudhari, Sergey Levine, and Ruslan Salakhutdinov. Off-dynamics reinforcement learning: Training for transfer with domain classifiers. arXiv preprint arXiv:2006.13916, 2020.   \nMehrdad Farajtabar, Yinlam Chow, and Mohammad Ghavamzadeh. More robust doubly robust offpolicy evaluation. In International Conference on Machine Learning, pages 1447\u20131456. PMLR, 2018.   \nArthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borgwardt, Bernhard Sch\u00f6lkopf, et al. Covariate shift by kernel mean matching. Dataset shift in machine learning, 3(4): 5, 2009.   \nHongyi Guo, Qi Cai, Yufeng Zhang, Zhuoran Yang, and Zhaoran Wang. Provably efficient offline reinforcement learning for partially observable markov decision processes. In International Conference on Machine Learning, pages 8016\u20138038. PMLR, 2022.   \nZhaohan Daniel Guo, Shayan Doroudi, and Emma Brunskill. A pac rl algorithm for episodic pomdps. In Artificial Intelligence and Statistics, pages 510\u2013518. PMLR, 2016.   \nMao Hong, Zhengling Qi, and Yanxun Xu. A policy gradient method for confounded pomdps. arXiv preprint arXiv:2305.17083, 2023.   \nYuchen Hu and Stefan Wager. Off-policy evaluation in partially observed markov decision processes under sequential ignorability. The Annals of Statistics, 51(4):1561\u20131585, 2023.   \nRuiquan Huang, Yingbin Liang, and Jing Yang. Provably efficient ucb-type algorithms for learning predictive state representations. arXiv preprint arXiv:2307.00405, 2023.   \nNan Jiang and Lihong Li. Doubly Robust Off-policy Value Evaluation for Reinforcement Learning. In Proceedings of the 33rd International Conference on Machine Learning, volume 48, pages 652\u2013661, 2016.   \nNan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Robert E. Schapire. Contextual Decision Processes with low Bellman rank are PAC-learnable. In Proceedings of the 34th International Conference on Machine Learning, volume 70, pages 1704\u20131713, 2017.   \nChi Jin, Sham Kakade, Akshay Krishnamurthy, and Qinghua Liu. Sample-efficient reinforcement learning of undercomplete pomdps. Advances in Neural Information Processing Systems, 33: 18530\u201318539, 2020.   \nLeslie Pack Kaelbling, Michael L Littman, and Anthony R Cassandra. Planning and acting in partially observable stochastic domains. Artificial intelligence, 101(1-2):99\u2013134, 1998.   \nNathan Kallus and Masatoshi Uehara. Double reinforcement learning for efficient off-policy evaluation in markov decision processes. Journal of Machine Learning Research, 21(167):1\u201363, 2020.   \nAkshay Krishnamurthy, Alekh Agarwal, and John Langford. PAC reinforcement learning with rich observations. In Advances in Neural Information Processing Systems, 2016.   \nJeongyeol Kwon, Yonathan Efroni, Constantine Caramanis, and Shie Mannor. Rl for latent mdps: Regret guarantees and a lower bound. Advances in Neural Information Processing Systems, 34: 24523\u201324534, 2021.   \nSahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, and Anima Anandkumar. Adaptive control and regret minimization in linear quadratic gaussian (lqg) setting. In 2021 American Control Conference (ACC), pages 2517\u20132522. IEEE, 2021.   \nHoang Le, Cameron Voloshin, and Yisong Yue. Batch policy learning under constraints. In International Conference on Machine Learning, pages 3703\u20133712, 2019.   \nMatthieu Lerasle. Lecture notes: Selected topics on robust statistical learning theory. arXiv preprint arXiv:1908.10761, 2019.   \nLihong Li, Wei Chu, John Langford, and Xuanhui Wang. Unbiased Offilne Evaluation of Contextualbandit-based News Article Recommendation Algorithms. In Proceedings of the 4th International Conference on Web Search and Data Mining, pages 297\u2013306, 2011.   \nQiang Liu, Lihong Li, Ziyang Tang, and Dengyong Zhou. Breaking the curse of horizon: Infinitehorizon off-policy estimation. In Advances in Neural Information Processing Systems, pages 5356\u20135366, 2018.   \nQinghua Liu, Alan Chung, Csaba Szepesv\u00e1ri, and Chi Jin. When is partially observable reinforcement learning not scary? In Conference on Learning Theory, pages 5175\u20135220. PMLR, 2022a.   \nQinghua Liu, Praneeth Netrapalli, Csaba Szepesvari, and Chi Jin. Optimistic mle\u2013a generic model-based algorithm for partially observable sequential decision making. arXiv preprint arXiv:2209.14997, 2022b.   \nMiao Lu, Yifei Min, Zhaoran Wang, and Zhuoran Yang. Pessimism in the face of confounders: Provably efficient offilne reinforcement learning in partially observable markov decision processes. arXiv preprint arXiv:2205.13589, 2022.   \nGaurav Mahajan, Sham Kakade, Akshay Krishnamurthy, and Cyril Zhang. Learning hidden markov models using conditional samples. In The Thirty Sixth Annual Conference on Learning Theory, pages 2014\u20132066. PMLR, 2023.   \nR\u00e9mi Munos. Performance bounds in l_p-norm for approximate value iteration. SIAM journal on control and optimization, 46(2):541\u2013561, 2007.   \nR\u00e9mi Munos and Csaba Szepesv\u00e1ri. Finite-time bounds for ftited value iteration. Journal of Machine Learning Research, 9(May):815\u2013857, 2008.   \nOfir Nachum, Yinlam Chow, Bo Dai, and Lihong Li. Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections. Advances in Neural Information Processing Systems, 32, 2019.   \nYash Nair and Nan Jiang. A spectral approach to off-policy evaluation for pomdps. arXiv preprint arXiv:2109.10502, 2021.   \nHongseok Namkoong, Ramtin Keramati, Steve Yadlowsky, and Emma Brunskill. Off-policy policy evaluation for sequential decisions under unobserved confounding. Advances in Neural Information Processing Systems, 33:18819\u201318831, 2020.   \nJuan C Perdomo, Akshay Krishnamurthy, Peter Bartlett, and Sham Kakade. A complete characterization of linear estimators for offline policy evaluation. Journal of Machine Learning Research, 24 (284):1\u201350, 2023.   \nDoina Precup, Richard S Sutton, and Satinder P Singh. Eligibility traces for off-policy policy evaluation. In Proceedings of the Seventeenth International Conference on Machine Learning, pages 759\u2013766, 2000.   \nChengchun Shi, Masatoshi Uehara, Jiawei Huang, and Nan Jiang. A minimax learning approach to offpolicy evaluation in confounded partially observable markov decision processes. In International Conference on Machine Learning, pages 20057\u201320094. PMLR, 2022.   \nMax Simchowitz, Karan Singh, and Elad Hazan. Improper learning for non-stochastic control. In Conference on Learning Theory, pages 3320\u20133436. PMLR, 2020.   \nYuda Song, Yifei Zhou, Ayush Sekhari, Drew Bagnell, Akshay Krishnamurthy, and Wen Sun. Hybrid rl: Using both offline and online data can make rl efficient. In The Eleventh International Conference on Learning Representations, 2022.   \nGuy Tennenholtz, Uri Shalit, and Shie Mannor. Off-policy evaluation in partially observable environments. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 10276\u201310283, 2020.   \nPhilip Thomas and Emma Brunskill. Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning. In Proceedings of the 33rd International Conference on Machine Learning, 2016.   \nMasatoshi Uehara, Jiawei Huang, and Nan Jiang. Minimax Weight and Q-Function Learning for Off-Policy Evaluation. In Proceedings of the 37th International Conference on Machine Learning, pages 1023\u20131032, 2020.   \nMasatoshi Uehara, Haruka Kiyohara, Andrew Bennett, Victor Chernozhukov, Nan Jiang, Nathan Kallus, Chengchun Shi, and Wen Sun. Future-dependent value-based off-policy evaluation in pomdps. arXiv preprint arXiv:2207.13081, 2022a.   \nMasatoshi Uehara, Ayush Sekhari, Jason D Lee, Nathan Kallus, and Wen Sun. Provably efficient reinforcement learning in partially observable dynamical systems. arXiv preprint arXiv:2206.12020, 2022b.   \nCameron Voloshin, Nan Jiang, and Yisong Yue. Minimax model learning. In International Conference on Artificial Intelligence and Statistics, pages 1612\u20131620. PMLR, 2021.   \nTengyang Xie and Nan Jiang. $\\mathrm{Q^{*}}$ approximation schemes for batch reinforcement learning: A theoretical comparison. In Conference on Uncertainty in Artificial Intelligence, pages 550\u2013559. PMLR, 2020.   \nTengyang Xie and Nan Jiang. Batch value-function approximation with only realizability. In International Conference on Machine Learning, pages 11404\u201311413. PMLR, 2021.   \nTengyang Xie, Yifei Ma, and Yu-Xiang Wang. Towards optimal off-policy evaluation for reinforcement learning with marginalized importance sampling. Advances in Neural Information Processing Systems, 32, 2019.   \nTengyang Xie, Ching-An Cheng, Nan Jiang, Paul Mineiro, and Alekh Agarwal. Bellman-consistent pessimism for offline reinforcement learning. arXiv preprint arXiv:2106.06926, 2021.   \nMing Yin and Yu-Xiang Wang. Towards instance-optimal offline reinforcement learning with pessimism. Advances in neural information processing systems, 34:4065\u20134078, 2021.   \nMing Yin, Yu Bai, and Yu-Xiang Wang. Near-optimal provable uniform convergence in offilne policy evaluation for reinforcement learning. In International Conference on Artificial Intelligence and Statistics, pages 1567\u20131575. PMLR, 2021.   \nYao-Liang Yu and Csaba Szepesv\u00e1ri. Analysis of kernel mean matching under covariate shift. In Proceedings of the 29th International Coference on International Conference on Machine Learning, pages 1147\u20131154, 2012.   \nAndrea Zanette, Martin J Wainwright, and Emma Brunskill. Provable beneftis of actor-critic methods for offilne reinforcement learning. Advances in neural information processing systems, 34:13626\u2013 13640, 2021.   \nWenhao Zhan, Masatoshi Uehara, Wen Sun, and Jason D Lee. Pac reinforcement learning for predictive state representations. arXiv preprint arXiv:2207.05738, 2022.   \nJunzhe Zhang and Elias Bareinboim. Markov decision processes with unobserved confounders: A causal approach. Purdue AI Lab, West Lafayette, IN, USA, Tech. Rep, 2016. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Related Literature ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "OPE in POMDPs. There is a line of research on OPE in confounded POMDPs [Zhang and Bareinboim, 2016, Namkoong et al., 2020, Nair and Jiang, 2021, Guo et al., 2022, Lu et al., 2022, Shi et al., 2022, Hong et al., 2023]. However, all these methods require the behavior policy to solely depend on the latent state. This assumption is inapplicable for our unconfounded POMDP setting, where the behavior policy depends on the observations. Hu and Wager [2023] studied the same unconfounded setting as ours. Nonetheless, their method uses multi-step importance sampling, leading to an undesirable exponential dependence on the horizon. The closest related work to our paper is [Uehara et al., 2022a], which we analyze in detail in Section 3. ", "page_idx": 14}, {"type": "text", "text": "Online Learning in POMDPs. There are many prior works studying online learning algorithms for sub-classes of POMDPs, including decodable POMDPs [Krishnamurthy et al., 2016, Jiang et al., 2017, Du et al., 2019, Efroni et al., 2022], Latent MDPs [Kwon et al., 2021] and linear quadratic Gaussian setting (LQG) [Lale et al., 2021, Simchowitz et al., 2020]. Recently, online learning algorithms with polynomial sample results have been proposed for both tabular POMDPs [Guo et al., 2016, Azizzadenesheli et al., 2016, Jin et al., 2020, Liu et al., 2022a] and POMDPs with general function approximation [Zhan et al., 2022, Liu et al., 2022b, Chen et al., 2022, Huang et al., 2023]. All of these approaches are model-based and require certain model assumptions. Uehara et al. [2022b] proposed a model-free online learning algorithm based on future-dependent value functions (FDVFs). However, their algorithm requires the boundness of FDVFs for all policies in the policy class, as well as a low-rank property of the Bellman loss, which limits the generality of the results. ", "page_idx": 14}, {"type": "text", "text": "OPE in MDPs. There has been a long history of studying OPE in MDPs, including importance sampling (IS) approaches [Precup et al., 2000, Li et al., 2011] and their doubly robust variants [Dud\u00edk et al., 2011, Jiang and Li, 2016, Thomas and Brunskill, 2016, Farajtabar et al., 2018], marginalized importance sampling (MIS) methods [Liu et al., 2018, Xie et al., 2019, Kallus and Uehara, 2020] and model-based estimators [Eysenbach et al., 2020, Yin et al., 2021, Voloshin et al., 2021]. As mentioned in Section 1, directly applying IS-based approaches for POMDPs will result in exponential variance. Meanwhile, MIS-based approaches do not apply to POMDPs since they require the environment to satisfy the Markov assumption. ", "page_idx": 14}, {"type": "text", "text": "B Discussions and Extensions ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Connection between Future-dependent Value Functions and Learnable Future-dependent Value Functions ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Uehara et al. [2022a] proposed a learnable version of future dependent value functions and focused on the learning of learnable FDVFs instead of the original FDVFs defined in Definition 3. In this subsection, we first introduce the definition of learnable FDVFs and then show that it is equivalent to FDVFs under a full-rank assumption. ", "page_idx": 14}, {"type": "text", "text": "Definition 14 (Learnable future-dependent value functions). A Learnable future-dependent value function $V_{\\mathcal{F}}^{L}:\\mathcal{F}\\rightarrow\\mathbb{R}$ is any function that satisfies the following: $\\forall\\tau_{h}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n(\\beta^{\\mathcal{H}}V_{\\mathcal{F}}^{L})(\\tau_{h})=0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For any FDVF $V_{\\mathcal{F}}$ , since $p s V_{\\mathcal{F}}\\equiv0$ , we have $\\forall\\tau_{h}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(B^{\\mathcal{H}}V_{\\mathcal{F}})(\\tau_{h})=\\mathbb{E}_{\\pi_{b}}[\\mu(o_{h},a_{h})\\{r_{h}+V_{\\mathcal{F}}(f_{h+1})\\}-V_{\\mathcal{F}}(f_{h})\\mid\\tau_{h}]}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\langle{\\bf b}(\\tau_{h}),B_{h}^{S}V_{\\mathcal{F}}\\rangle=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, all FDVFs are also learnbale FDVFs. On the other hand, for any learnbale FDVF $V_{\\mathcal{F}}^{L}$ , let $B_{h}^{\\mathcal{H}}V_{\\mathcal{F}}^{L}\\in\\mathbb{R}^{|\\mathcal{H}_{h}|}$ be the Bellman residual vector for $V_{\\mathcal{F}}^{L}$ on $\\mathcal{H}_{h}$ and $B_{h}^{S}V_{\\mathcal{F}}^{L}\\in\\mathbb{R}^{S}$ be the Bellman residual vector on $\\ensuremath{\\mathcal{S}}_{h}$ . With the help of $M_{\\mathcal{H},h}$ , we have the following relation between $B_{h}^{\\mathcal{H}}V_{\\mathcal{F}}^{L}$ and $B_{h}^{S}V_{\\mathcal{F}}^{L}$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\boldsymbol{\\mathcal{B}}_{h}^{\\mathcal{H}}\\boldsymbol{V}_{\\mathcal{F}}^{L}=\\big(\\boldsymbol{M}_{\\mathcal{H},h}\\big)^{\\top}\\boldsymbol{\\mathcal{B}}_{h}^{S}\\boldsymbol{V}_{\\mathcal{F}}^{L}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "When rank $\\operatorname{\\mathrm{\\Delta}}(M_{\\mathcal{H},h})\\;=\\;S$ , $B_{h}^{\\mathcal{H}}V_{\\mathcal{F}}^{L}\\:=\\:\\mathbf{0}$ if and only if $B_{h}^{S}V_{\\mathcal{F}}^{L}\\:=\\:\\mathbf{0}$ . Therefore, $V_{\\mathcal{F}}^{L}$ satisfies that $\\forall s_{h},(\\beta^{S}V_{\\mathcal{F}}^{L})(s_{h})=0$ , implying that $V_{\\mathcal{F}}^{L}$ is also a FDVF. Under the regular full rank assumption, the two definitions are actually equivalent. ", "page_idx": 14}, {"type": "text", "text": "B.2 Comparison between the Finite-horizon and the Discounted Formulations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The original results of Uehara et al. [2022a] were given in the infinite-horizon discounted setting. To describe their data collection assumption in simple terms, consider an infinite trajectory that enters the stationary configuration of $\\pi_{b}$ , and we pick a random time step and call it $t=0$ (which corresponds to a time step $h$ in our setting). Then, history (analogous to our $\\tau_{h}$ ) is $\\left(o_{\\left(-M_{F}\\right):\\left(-1\\right)},a_{\\left(-M_{F}\\right):\\left(-1\\right)}\\right)$ , and future is $\\left(o_{0:M_{H}},a_{0:M_{F}-1}\\right)$ . $M_{F}$ and $M_{H}$ are hyperparameters that determines the lengths, and should not be confused with our $M_{\\mathcal{F},h}$ and $M_{\\mathcal{H},h}$ matrices. Data points collected in this way form the \u201ctransition\u201d dataset. Separately, there is an \u201cinitial\u201d dataset of $\\left(o_{0:M_{F}-1},a_{0:M_{F}}\\right)$ tuples to represent the analogue of initial state distribution in MDPs. ", "page_idx": 15}, {"type": "text", "text": "Besides the fact that finite-horizon formulation better ftis real-world applications with episodic nature (e.g., a session in conversational system), there are mathematical reasons why the finite-horizon formulation is more natural: ", "page_idx": 15}, {"type": "text", "text": "1. Unlike the infinite-horizon setting, we do not need separate \u201ctrainsition\u201d and \u201cinitial\u201d datasets. The natural $H$ -step episode dataset plays both roles. We also do not need the stationarity assumption. 2. In the infinite-horizon, $M_{F}$ and $M_{H}$ are hyperparameters which do not have an obvious upper bound. The larger they are, it is easier to satisfy certain identification assumptions (such as full-rankness of the counterparts of our $M_{\\mathcal{H},h}$ and $M_{\\mathcal{F},h})$ . On the other hand, the \u201ccurses of future and horizon\u201d we identified in this work corresponds to exponential dependence on $M_{F}$ and $M_{H}$ , so there is a potential trade-off in the choice of $M_{F}$ and $M_{H}$ . In contrast, the future and the history have maximum lengths $(H-h$ and $h-1$ at time step $h$ ) in our setting. As we establish coverage assumptions that avoid potential exponential dependencies on these lengths, the trade-off in the choice of length is eliminated, so it is safe for us to always choose the maximum length, as we do in the paper. ", "page_idx": 15}, {"type": "text", "text": "B.3 Refined Coverage ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "As alluded to at the beginning of Section 5, we can tighten the definition of $L_{2}$ belief coverage by directly using the ratio: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{V\\in\\mathcal{V}}\\frac{|\\mathbb{E}_{\\pi_{e}}[(\\beta^{S}V)(s_{h})]|}{\\sqrt{\\mathbb{E}_{\\pi_{b}}[(\\beta^{\\mathcal{H}}V)(\\tau_{h})^{2}]}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which automatically leverages the structure of $\\mathcal{V}$ . For example, if $\\{B_{h}^{S}V:V\\in\\mathcal{V}\\}$ only occupies a low-dimensional subspace of $\\mathbb{R}^{S_{h}}$ (that is, there exists $\\phi:S_{h}\\,\\rightarrow\\,\\mathbb{R}^{d}$ such that $(\\boldsymbol{B}^{S}\\boldsymbol{V})(s_{h})\\,=$ $\\phi(s_{h})^{\\top}\\theta_{V})$ , then belief matching above Eq.(8) can be done in $\\mathbb{R}^{d}$ instead of $\\mathbb{R}^{S_{h}}$ . Other coverage definitions may be refined in similar manners. ", "page_idx": 15}, {"type": "text", "text": "B.4 Interpretation of Assumption 8 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To interpret Assumption 8, let $x\\,=\\,{\\mathbf{u}}(f_{h})/Z(f_{h})\\,\\in\\,\\Delta(S)$ , and assign a distribution over $x$ by sampling $f_{h}\\sim\\mathrm{diag}(Z_{h}/S)$ , then Assumption 8 becomes $x^{\\top}\\mathbb{E}_{Z_{h}/S}[x x^{\\top}]^{-1}x\\leq C_{\\mathcal{F},U}S$ for any $x$ with non-zero probability. This is a common regularity assumption [Duan et al., 2020, Perdomo et al., 2023], requiring that no $x$ points to a direction in $\\mathbb{R}^{S}$ alone without being joined by others from the distribution. While $1/\\sigma_{\\mathrm{min}}(\\Sigma_{\\mathcal{F},h})$ can bound this quantity, the other way around is not true, implying that Assumption 8 is weaker. ", "page_idx": 15}, {"type": "text", "text": "Example 8 (Bounded $C_{\\ensuremath{\\mathcal{F}},U}$ without bounded $1/\\sigma_{\\operatorname*{min}}(\\Sigma_{\\mathcal{F},h}))$ . Consider a distribution over $x$ where with 0.5 probability, $x=[1/2\\!+\\!\\epsilon,1/2\\!-\\!\\epsilon]^{\\top}$ , and with the other $0.5$ probability, $x=[1/2\\!-\\!\\epsilon,1/2\\!+\\!\\epsilon]^{\\top}$ . Then, as $\\epsilon\\to0$ , $1/\\sigma_{\\mathrm{min}}(\\Sigma_{\\mathcal{F},h})\\to\\infty$ , but $x^{\\top}\\mathbb{E}[x x^{\\top}]^{-1}x\\leq2$ . ", "page_idx": 15}, {"type": "text", "text": "B.5 Intuition for $L_{\\infty}$ Outcome Coverage ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Here we provide more details about the $L_{\\infty}$ outcome coverage in Section 4.2, which are omitted in the main text due to space limit. ", "page_idx": 15}, {"type": "text", "text": "Looseness of $L_{2}$ outcome coverage We start by examining the looseness of $L_{2}$ outcome coverage (Assumption 7), which will motivate the $L_{\\infty}$ version of outcome coverage. To develop intuitions, we ", "page_idx": 15}, {"type": "text", "text": "first examine the boundedness of Eq.(4) (the construction that leads to $L_{2}$ outcome coverage) in the setting of Example 2. In this example, $\\Sigma_{\\mathcal{F},h}=\\mathbf{I}.$ , and $\\|V_{\\mathcal{F}}\\|_{\\infty}\\leq H$ . According to the $L_{2}$ H\u00f6lder decomposition in Proposition 4, however, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|V_{\\mathcal{F}}\\|_{\\infty}\\leq\\operatorname*{max}_{f_{h}}\\|\\mathbf{u}(f_{h})/Z(f_{h})\\|_{2}\\|V_{\\mathcal{S}}^{\\pi_{e}}\\|_{2}\\leq H\\sqrt{S},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\|\\cdot\\|_{\\Sigma_{\\mathcal{F},h}^{-1}}$ is replaced by $\\|\\cdot\\|_{2}$ since $\\Sigma_{\\mathcal{F},h}=I$ . In contrast, the tight analysis is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|V_{\\mathcal{F}}\\|_{\\infty}\\leq\\operatorname*{max}_{f_{h}}\\|\\mathbf{u}(f_{h})/Z(f_{h})\\|_{1}\\|V_{\\mathcal{S}}^{\\pi_{e}}\\|_{\\infty}\\leq H.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The comparison clearly highlights that the looseness in $S$ comes from the fact that $L_{2}$ H\u00f6lder does not fully leverage the fact that $\\|\\mathbf{u}(f_{h})/Z(f_{h})\\|_{1}=1$ and loosely relaxing it to $\\|\\mathbf{u}(f_{h})/Z(f_{h})\\|_{2}\\le1$ . In contrast, our $L_{\\infty}$ coverage assumption allows for a more natural $L_{1}/L_{\\infty}$ H\u00f6lder to leverage the $L_{1}$ normalization of $\\mathbf{u}(f_{h})/Z(f_{h})$ . ", "page_idx": 16}, {"type": "text", "text": "$L_{\\infty}$ Outcome Coverage Similar to $L_{\\infty}$ belief coverage, we could define $L_{\\infty}$ outcome coverage simply as $\\|(\\Sigma_{\\mathcal{F},h})^{-1}\\tilde{V_{S}^{\\pi_{e}}}\\|_{\\infty}$ . The small caveat and inelegance is that it does not recover $V_{\\mathcal{F}}=\\bar{R}^{+}$ when $\\pi_{b}=\\pi_{e}$ . To address this, we leverage the lesson from belief coverage (Section 5.2): to obtain $C_{\\mathcal{H},\\infty}=1$ when $\\pi_{b}=\\pi_{e}$ , a key property is that $\\Sigma_{\\mathcal{H},h}$ (data covariance matrix) and $\\mathbf{b}_{h}^{\\pi_{b}}$ (the vector to be covered) are the covariance matrix and the mean vector w.r.t. the same distribution of belief vectors. In contrast, for the outcome coverage case, $V_{S}^{\\pi_{e}}$ depends on the reward function, but such information is missing in $\\Sigma_{\\mathcal{F},h}$ , which prevents a perfect cancellation in the on-policy case. ", "page_idx": 16}, {"type": "text", "text": "Therefore, we can adjust the definition of $\\Sigma{\\mathcal{F}}{,h}$ to mimic the situation of belief coverage. The first step is to find the counterpart of belief state which is $L_{1}$ -normalized. This obviously corresponds to $\\bar{Z}_{h}^{-1}M_{\\mathcal{F},h}^{\\top}$ , whose rows sum up to 1. Let $\\bar{\\mathbf{u}}(f_{h})\\;:=\\;\\mathbf{u}(f_{h})/Z(f_{h})\\;\\in\\;\\Delta(S_{h})$ , then $\\Sigma_{\\mathcal{F},h}\\;=\\;$ $\\boldsymbol{\\underbar{S}}\\cdot\\mathbb{E}_{Z_{h}/S}[\\bar{\\mathbf{u}}\\bar{\\mathbf{u}}^{\\top}]$ . Then, by incorporating reward information into $\\Sigma{\\boldsymbol{\\mathcal{F}}}{,}h$ , we arrive at the solution in Eq.(5). ", "page_idx": 16}, {"type": "text", "text": "Finally, we examine the setting of Example 2 and show that $V_{\\mathcal{F}}$ in Eq.(5) is similarly well-behaved as Eq.(4) in this scenario. ", "page_idx": 16}, {"type": "text", "text": "Example 9. In the same setting as Example 2, i.e., $f_{h}$ always reveals $s_{h}$ , we have $\\Sigma_{\\mathcal{F},h}^{R}=d i a g(V_{S_{h}}^{\\pi_{b}});$ and $\\begin{array}{r}{\\|(\\Sigma_{\\mathcal{F},h}^{R})^{-1}V_{\\mathcal{S}}^{\\pi_{e}}\\|_{\\infty}=\\operatorname*{max}_{s_{h}}V_{\\mathcal{S}}^{\\pi_{e}}(s_{h})/V_{\\mathcal{S}}^{\\pi_{b}}(s_{h}).}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "This example also closely resembles Example 7 for belief coverage. While $(\\Sigma_{\\mathcal{F},h}^{R})^{-1}$ may behave poorly if $V_{S}^{\\pi_{b}}(s_{h})$ is small, an easy fix is to simply add a constant to the reward function and shift its range to e.g., [1, 2], which ensures a small $C_{\\mathcal{F},\\infty}$ . ", "page_idx": 16}, {"type": "text", "text": "B.6 Extension to History-dependent Policies ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The main text assumes memoryless $\\pi_{b}$ and $\\pi_{e}$ . Similar to Uehara et al. [2022a], we can extend the approach to handle history-dependent policies (the changes to the proof are sketched below). Instead of rewriting the proof with these changes, we will provide a \u201cblack-box\u201d reduction that handles the extension more elegantly and allow for more general results than Uehara et al. [2022a]. ", "page_idx": 16}, {"type": "text", "text": "Memory-based Policies and Changes in the Proofs Define memory $m_{h}$ as a function of $\\tau_{h}$ (i.e., $m_{h}=m_{h}(\\tau_{h}))$ , and a memory-based policy can depend on $\\left(m_{h},o_{h}\\right)$ . Uehara et al. [2022a] allows for $\\begin{array}{r}{m_{h}\\,=\\,\\left(o_{h-M:h-1},a_{h-M:h-1}\\right)}\\end{array}$ for some fixed window $M$ in their analyses. If we let $m_{h}=(o_{1:h-1},a_{1:h-1})$ , we recover fully general history-dependent policies. ", "page_idx": 16}, {"type": "text", "text": "If we direct modify the proofs to accommodate this generalization (as done in Uehara et al. [2022a]), the required changes are: ", "page_idx": 16}, {"type": "text", "text": "\u2022 $V_{S}^{\\pi_{e}}$ and $V_{\\mathcal{F}}$ need to additionally depend on $m_{h}$ to be well defined. $V\\in\\mathcal{V}$ also generally depend on $m_{h}$ since we need realizability $V_{\\mathcal{F}}\\in\\mathcal{V}$ .   \n\u2022 $M_{\\mathcal{F},h}$ and $M_{\\mathcal{H},h}$ have rows indexed by $(s_{h},m_{h})$ instead of just $s_{h}$ . That is, we replace belief state with posterior over $(s_{h},m_{h})$ . Similarly, entries in $M_{\\mathcal{F},h}$ are now future probabilities conditioned on $(s_{h},m_{h})$ ", "page_idx": 16}, {"type": "text", "text": "However, if we consider latent state coverage, which is weaker than belief coverage that is really needed (Appendix E.3), we now require bounded dd\u03c0be((ssh,,mmh)). T his is generally exponential in the length of $m_{h}$ (e.g., if $M=h-1$ , the ratio is exactly the cumulative importance weight), preventing us from handling $\\pi_{b}$ and $\\pi_{e}$ with long-range history dependencies. ", "page_idx": 17}, {"type": "text", "text": "Reduction to Memoryless Case Instead of changing the proofs, we now describe an alternative approach that (1) produces results similar to Uehara et al. [2022a], and (2) handles more general recurrent policies that are finite-state-machines (FSMs), which subsume fully history-dependent policies (or policies that depend on a fixed-length window) as special cases. ", "page_idx": 17}, {"type": "text", "text": "Concretely, a policy with memory $m_{h}$ is said to be an FSM, if $m_{h+1}$ can be computed solely based on $m_{h},o_{h},a_{h}$ , without using other information in $\\tau_{h}$ . $\\begin{array}{r}{m_{h}=\\left(o_{h-M:h-1},a_{h-M:h-1}\\right)}\\end{array}$ satisfies this definition, as computing $m_{h+1}$ is simply dropping the oldest observation-action pair from $m_{h}$ and appending the newest one.6 Another example is belief update, where ${\\bf b}(\\tau_{h+1})$ can be computed from ${\\bf b}(\\tau_{h}),o_{h},a_{h}$ . ", "page_idx": 17}, {"type": "text", "text": "We assume that both $\\pi_{b}$ and $\\pi_{e}$ have the same memory; if they differ, we can simply concatenate their memories together. Then, handling memories in our analyses takes two steps: ", "page_idx": 17}, {"type": "text", "text": "1. We allow latent state transition to depend on $o_{h}$ , that is, $s_{h+1}\\sim\\mathbb{T}(\\cdot|s_{h},a_{h},o_{h})$ . This model has been considered by Jiang et al. [2017] to unify POMDPs and low-rank MDPs. Our analyses hold as-is without any changes. To provide some intuition: the key property that enables the analyses of FDVF is that $s_{h}$ is a bottleneck that separates histories from futures, which enables $(\\mathscr{B}^{\\mathcal{H}}\\dot{V})(\\tau_{h})=\\langle\\mathbf{b}(\\tau_{h}),\\mathscr{B}_{h}^{s}\\dot{V}\\rangle$ in Eq.(2). This property is intact with the additional dependence of $s_{h}$ on $o_{h-1}$ . ", "page_idx": 17}, {"type": "text", "text": "2. We provide a blackbox reduction from the memory-based case to the memoryless case. Define a new POMDP that is equivalent to the original one, where the latent state is $\\tilde{s}_{h}=(s_{h},m_{h})$ . The observation is $\\tilde{o}_{h}=(\\bar{o}_{h},m_{h})$ , which can be emitted from $\\tilde{s}_{h}$ since $\\tilde{s}_{h}$ contains $m_{h}$ . The latent state transition is $\\tilde{s}_{h+1}=(s_{h+1},m_{h+1})$ , where $s_{h+1}\\sim\\mathbb{T}(\\cdot|s_{h},a_{h},o_{h})$ , and $m_{h+1}$ is updated from $m_{h}$ (contained in $\\tilde{s}_{h}$ ), $a_{h}$ , and $o_{h}$ ; this is why we need $o_{h}$ to participate in latent transitions. Now it suffices to perform OPE in the new POMDP. Data from the original POMDP can be converted to that of the new POMDP with $\\tilde{o}_{h}=(o_{h},m_{h})$ . $\\pi_{b}$ and $\\pi_{e}$ only need to depend on $\\tilde{o}_{h}$ and become memoryless. ", "page_idx": 17}, {"type": "text", "text": "Given the reduction, if we design function classes that operate on the histories and futures of the new POMDP, the guarantees in the main text immediately hold. The final step is to translate the objects (e.g., futures and histories) and guarantees in the new POMDP back to the original POMDP for interpretability. Note that the history in the new POMDP is $\\tilde{\\tau}_{h}=\\left(\\tilde{o}_{1:h-1},a_{1:h-1}\\right)$ , which contains the same information as $\\tau_{h}$ , so functions in $\\Xi$ and $\\mathcal{W}$ can still operate on $\\tau_{h}$ . Similarly, $V\\in\\mathcal{V}$ now takes $(m_{h},f_{h})$ as input, which is consistent with Uehara et al. [2022a]. ", "page_idx": 17}, {"type": "text", "text": "When translating the assumptions back to the original POMDP, we can see that now the results can be well-behaved when $m_{h}$ is \u201csimple\u201d. For example, if $m_{h}$ takes values from a constant-sized space, $d^{\\pi_{e}}(s_{h},m_{h})/d^{\\pi_{b}}(s_{h},m_{h})$ (which lower-bounds belief coverage as discussed above) may not blow up exponentially, even though $m_{h}$ can hold information that is arbitrarily old (e.g., it remembers one bit of information from $h=1$ ). This is a scenario that cannot be handled by the formulation of Uehara et al. [2022a]. ", "page_idx": 17}, {"type": "text", "text": "However, the guarantee can still deteriorate when the policies maintain rich memories, even if these memories are highly structured, such as $m_{h}=\\mathbf{b}(\\tau_{h})$ . Under the mild assumption that all histories lead to distinct belief states ${\\bf b}(\\tau_{h})$ (they can be very close in $\\mathbb{R}^{S}$ and just need to be not exactly identical), the belief state in the new POMDP, $\\tilde{\\mathbf{b}}(\\tau_{h})$ , completely ignores the linear structure of $m_{h}$ and treats it in the same way as $m_{h}=\\tau_{h}$ ,7leading to an exponentially large belief coverage. How to handle policies that depend on rich but highly structured memories such as belief states is a major open problem. ", "page_idx": 17}, {"type": "text", "text": "B.7 Recovering MDP Algorithms and Analyses ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "One somewhat undesirable property of our algorithms and analyses is that they do not subsume MDP algorithms/analyses as a special case. MDPs can be viewed as POMDPs with identity emission, i.e., $o_{h}=s_{h}$ . In this case, algorithms considered in this paper are analogous to their MDP counterparts Uehara et al. [2020], except that the MDP algorithms require that all functions $V$ , $w$ , $\\xi$ to operate on the current state $s_{h}$ . In contrast, our FDVF operates on $f_{h}=(o_{h},a_{h},\\dots,o_{H},a_{H})$ which includes $o_{h}(=s_{h})$ . To recover the MDP algorithm as a special case, we can choose $\\mathcal{V}$ such that every $V\\in\\mathcal{V}$ only depends on $f_{h}$ through $o_{h}$ . However, $w$ and $\\xi$ operate on $\\tau_{h}=\\left(o_{1},a_{1},\\ldots,o_{h-1},a_{h-1}\\right)$ which does not contain $o_{h}$ . This makes subsuming the MDP case difficult. ", "page_idx": 18}, {"type": "text", "text": "Here we describe briefly how to overcome this issue by slightly modifying our analysis; the changes are somewhat similar to Appendix B.6. Instead of letting $\\tau_{h}=(o_{1},a_{1},\\dots,o_{h-1},a_{h-1})$ , we can define an alternative notion of history $\\tilde{\\tau}_{h}\\,=\\,(o_{1},a_{1},...\\,,o_{h})$ and replace $\\tau_{h}$ in the main text with $\\tilde{\\tau}_{h}$ . Algorithmically, we can immediately recover MDP algorithms by also restricting functions in $\\mathcal{W}$ and $\\mathcal{X}$ to only operate on $o_{h}$ . However, our analyses (which apply to general POMDPs) need to change accordingly, as replacing $\\tau_{h}$ with $\\tilde{\\tau}_{h}$ will break the key properties, such as $B^{\\mathcal{H}}V$ being linear in $B^{S}V$ . The problem is that in the definitions of $V_{S}^{\\pi_{e}}$ and $\\bar{\\mathcal{B}^{S}V}$ we want to marginalize out the randomness of $o_{h}$ given $s_{h}$ , which is in conflict with conditioning on $\\tilde{\\tau}_{h}$ that includes all the information of $o_{h}$ . To address this, we simply replace $s_{h}$ with $\\tilde{s}_{h}:=(s_{h},o_{h})$ in the definition of $V_{S}^{\\pi_{e}}$ , $B^{S}V$ , $M_{\\mathcal{H},h}$ , and $M_{\\mathcal{F},h}$ . That is, $V_{S}^{\\pi_{e}}$ is now a function of $\\tilde{s}_{h}$ and also depends on $o_{h}$ , ${\\bf b}(\\tau_{h})$ is the posterior distribution over $\\tilde{s}_{h}$ , and the entries of the outcome matrix $M_{\\mathcal{F},h}$ is $\\operatorname*{Pr}_{\\pi_{b}}(f_{h}|s_{h},o_{h})$ . This retains the key property that $B^{\\mathcal{H}}V$ is linear in $B^{S}V$ with $\\tilde{\\mathbf{b}}(\\tau_{h})$ as the coefficient. ", "page_idx": 18}, {"type": "text", "text": "When we specialize the guarantees of this modified analysis to the MDP setting, outcome coverage is always satisfied and we can always use the MDP\u2019s standard value function as $V_{\\mathcal{F}}$ . For belief coverage, note that $(\\beta^{\\mathcal{H}}V)(\\tau_{h})=(\\beta^{S}V)\\mathbf{\\dot{(}}s_{h},o_{h})$ , which is simply the standard definition of Bellman error in MDPs (since $s_{h}=o_{h}.$ ), which we denote as $(B V)(s_{h})$ . Plugging this into the refined coverage discussed in Appendix B.3, we recover the standard definition of coverage in the MDP setting, namely ", "page_idx": 18}, {"type": "text", "text": "B.8 Incorporating Different Latent-State Priors in $V_{\\mathcal{F}}$ ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In Section 4 we showed that $\\Sigma_{\\mathcal{F},h}$ , which is crucial to the construction in Eq.(4), can be viewed as the confusion matrix of making posterior predictions of $s_{h}$ from $f_{h}$ , using a uniform prior. The uniform prior corresponds to the all-one vector $\\mathbf{1}_{s}$ in the definition of $\\stackrel{\\cdot}{Z}_{h}:=\\mathrm{diag}(\\mathbf{1}_{S}^{\\top}{M}_{\\mathcal{F},h})$ , which naturally leads to the question of whether we can incorporate a different and perhaps more informative prior. ", "page_idx": 18}, {"type": "text", "text": "Let $\\mathbf{p}_{h}\\,\\in\\,\\Delta(S_{h})$ be the prior we would like to use instead of the uniform prior. An immediate idea is to define $Z_{h}^{\\mathbf{p}_{h}}\\,=\\,\\mathrm{diag}(\\mathbf{p}_{h}^{\\top}M_{\\mathcal{F},h})$ (possibly up to a $S$ scaling factor, as the uniform prior is $\\mathbf{p}_{\\mathrm{unif}}=[1/S,\\cdots\\,,1/S]^{\\top}$ and $\\mathbf{1}_{S}=S\\mathbf{p}_{\\mathrm{unif}})$ and directly plug it into the construction in Eq.(4). However, this breaks some of the key properties of the current construction of $\\Sigma{\\boldsymbol{\\mathcal{F}}}{,}h$ , such as $L_{1}$ normalization of rows of $Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top}$ . ", "page_idx": 18}, {"type": "text", "text": "To resolve this, the key is to realize that the rows of $Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top}$ are $L_{1}$ normalized because they can be viewed as posteriors over $\\ensuremath{\\mathcal{S}}_{h}$ . In comparison, if we examine the $(f_{h},s_{h})$ -th entry of $(Z_{h}^{\\mathbf{p}_{h}})^{-1}M_{\\mathcal{F},h}^{\\top}$ it is ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{\\operatorname*{Pr}_{\\pi_{b}}[f_{h}|s_{h}]}{\\sum_{s^{\\prime}\\in\\mathcal{S}_{h}}\\operatorname*{Pr}_{\\pi_{b}}[f_{h}|s^{\\prime}]\\mathbf{p}_{h}(s^{\\prime})},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "so clearly it is missing a $\\mathbf{p}_{h}(s_{h})$ term on the numerator to be a proper posterior. Inspired by this observation, we can see how to fix the construction now: recall that $V_{\\mathcal{F}}$ needs to satisfy $M_{\\mathcal{F},h}V_{\\mathcal{F},h}=$ $V_{S,h}^{\\pi_{e}}$ . If $\\mathbf{p}_{h}>0$ , then this is equivalent to ", "page_idx": 18}, {"type": "equation", "text": "$$\n(\\mathrm{diag}({\\mathbf p}_{h})M_{{\\mathcal F},h})V_{{\\mathcal F},h}=\\mathrm{diag}({\\mathbf p}_{h})V_{S,h}^{\\pi_{e}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then, the minimum $Z_{h}^{\\mathbf{p}_{h}}$ -weighted solution of this equation will provide the desired construction that preserves the $L_{1}$ normalization properties. ", "page_idx": 18}, {"type": "text", "text": "Which prior $\\mathbf{p}_{h}$ to use? For the initial time step $h=1$ , the initial latent-state distribution $d_{1}$ is the most natural candidate for the prior. If $d_{1}(s_{1})=0$ for some $s_{1}\\in S_{1}$ , incorporating $d_{1}$ as the prior will essentially treat $s_{1}$ as non-existent and ignore the outcome coverage of $\\pi_{b}$ over $\\pi_{e}$ from $s_{1}$ , which is reasonable because $s_{1}$ will not be activated by neither $\\pi_{e}$ and $\\pi_{b}$ . For $h>1$ , the answer is less clear, and natural candidates include ${\\bf p}_{h}=d_{h}^{\\pi_{b}}$ and $d_{h}^{\\pi_{e}}$ , or perhaps their probability mixture. For the example scenarios examined in the main text, these choices (or even a uniform prior) do not make significant differences, and we leave the investigation of which prior is the best to future work. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "C Proofs for Section 3 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "C.1 Proof of Lemma 1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The RHS of the lemma statement is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{e}}\\left[(B^{S}V)(s_{h})\\right]=\\sum_{h=1}^{H}\\mathbb{E}_{s_{h}\\sim d_{h}^{\\pi_{e}}}\\left[\\mathbb{E}_{a_{h+1:H}\\sim\\pi_{b}}[r_{h}+V(f_{h+1})\\mid s_{h}]-\\mathbb{E}_{\\pi_{b}}[V(f_{h})\\mid s_{h}]\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Now notice that the expected value of the $V(f_{h+1})$ term for $h$ is the same as that of the $V(f_{h})$ term for $h+1$ , since both can be written as $\\mathbb{E}_{s_{h+1}\\sim d_{h+1}^{\\pi_{e}}}[\\mathbb{E}_{\\pi_{b}}[V(f_{h+1})|s_{h+1}]]$ . After telescoping cancellations, what remains on the RHS is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\mathbb{E}_{s_{h}\\sim d_{h}^{\\pi_{e}}}\\left[\\mathbb{E}_{a_{h+1:H}\\sim\\pi_{b}}[r_{h}~|~s_{h}]\\right]-\\mathbb{E}_{s_{1}}[\\mathbb{E}_{\\pi_{b}}[V(f_{1})|s_{1}]]=J(\\pi_{e})-\\mathbb{E}_{\\pi_{b}}[V(f_{1})].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "C.2 Proof of Theorem 2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The proof follows similar idea from Uehara et al. [2022a]. Let $\\mathcal{G}_{h}V=\\mu(o_{h},a_{h})(r_{h}+V(f_{h+1}))\\mathrm{~-~}$ $V(f_{h})$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widehat{V}=\\underset{V\\in\\mathcal{V}}{\\operatorname{argmin}}\\,\\underset{\\xi\\in\\Xi}{\\operatorname*{max}}\\sum_{h=1}^{H}\\mathbb{E}_{\\mathcal{D}}\\left[(\\mathcal{G}_{h}V)^{2}-(\\mathcal{G}_{h}V-\\xi(\\tau_{h}))^{2}\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For any fixed $V$ , we define ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widehat{\\xi}_{V}=\\underset{\\xi\\in\\Xi}{\\operatorname{argmax}}-\\sum_{h=1}^{H}\\mathbb{E}_{\\mathcal{D}}\\left[\\left(\\mathcal{G}_{h}V-\\xi(\\tau_{h})\\right)^{2}\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Analysis of Inner Maximizer. We observe that for any $h\\in[H]$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\pi_{b}}\\left[(\\xi(\\tau_{h})-\\mathcal{G}_{h}V)^{2}-((B^{\\mathcal{H}}V)(\\tau_{h})-\\mathcal{G}_{h}V)^{2}\\right]=\\mathbb{E}_{\\pi_{b}}\\left[(\\xi(\\tau_{h})-(B^{\\mathcal{H}}V)(\\tau_{h}))^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Let $X_{h}=(\\xi(\\tau_{h})\\!-\\!\\mathcal G_{h}V)^{2}\\!-\\!((\\beta^{\\mathcal H}V)(\\tau_{h})\\!-\\!\\mathcal G_{h}V)^{2}$ and $\\begin{array}{r}{X=\\sum_{h=1}^{H}X_{h}}\\end{array}$ . Let $\\bar{C}=\\operatorname*{max}\\{1\\!+\\!C_{\\mathcal{V}},C_{\\Xi}\\}$ , since $C_{\\mu}\\geq1$ , we have $|\\xi(\\tau_{h})|\\leq\\bar{C},|\\mathcal{G}_{h}V|\\leq3C_{\\mu}\\bar{C}$ and $\\left|B^{\\mathcal{H}}V(\\tau_{h})\\right|\\leq3\\bar{C}$ . Therefore, we have $|X_{h}|\\leq40C_{\\mu}\\bar{C}^{2}$ and $|X|\\leq40H C_{\\mu}\\bar{C}^{2}$ . We observe that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{\\pi_{b}}[X_{h}^{2}]}\\\\ &{\\le\\mathbb{E}_{\\pi_{b}}\\left[((B^{\\mathcal{H}}V)(\\tau_{h})-\\xi(\\tau_{h}))^{2}\\left((B^{\\mathcal{H}}V)(\\tau_{h})+\\xi(\\tau_{h})-2\\mathcal{G}_{h}V\\right)^{2}\\right]}\\\\ &{\\le\\mathbb{E}_{\\pi_{b}}\\left[\\left((B^{\\mathcal{H}}V)(\\tau_{h})-\\xi(\\tau_{h})\\right)^{2}\\left(30\\bar{C}^{2}+12(\\mathcal{G}_{h}V)^{2}\\right)\\right]}\\\\ &{\\le\\mathbb{E}_{\\pi_{b}}\\left[\\left((B^{\\mathcal{H}}V)(\\tau_{h})-\\xi(\\tau_{h})\\right)^{2}\\left(54\\bar{C}^{2}+96\\bar{C}^{2}\\mu(o_{h},a_{h})^{2}\\right)\\right]}\\\\ &{\\le150\\bar{C}^{2}C_{\\mu}\\mathbb{E}_{\\pi_{b}}\\left[\\left((B^{\\mathcal{H}}V)(\\tau_{h})-\\xi(\\tau_{h})\\right)^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Hence, for the variance of $X$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}_{\\pi_{b}}[X]\\leq H\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[X_{h}^{2}\\right]}\\\\ &{\\qquad\\qquad\\leq150H\\bar{C}^{2}C_{\\mu}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[\\left((B^{\\mathcal{H}}V)(\\tau_{h})-\\xi(\\tau_{h})\\right)^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "From Bernstein\u2019s inequality, with probability at least $1-\\delta/2,\\forall V\\in\\mathcal{V},\\forall\\xi\\in\\Xi$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\displaystyle\\sum_{h=1}^{H}\\{\\mathbb E}_{\\mathcal{D}}-\\mathbb{E}_{\\pi_{b}}\\}[(\\xi(\\tau_{h})-\\mathcal{G}_{h}V)^{2}-((B^{\\mathcal{H}}V)(\\tau_{h})-\\mathcal{G}_{h}V)^{2}]\\right|}\\\\ &{\\le\\sqrt{\\displaystyle\\frac{150H\\bar{C}^{2}C_{\\mu}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}[((B^{\\mathcal{H}}V)(\\tau_{h})-\\xi(\\tau_{h}))^{2}]\\log(4|\\mathcal{V}||\\Xi|/\\delta)}{n}}+\\frac{40H\\bar{C}^{2}C_{\\mu}\\log(4|\\mathcal{V}||\\Xi|/\\delta}{n}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "From Bellman completeness assumption $B^{\\mathcal{H}}\\mathcal{V}\\subset\\Xi$ , we also have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\mathbb{E}_{\\mathcal{D}}[(\\widehat{\\xi}_{V}-\\mathcal{G}_{h}V)^{2}-((\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h})-\\mathcal{G}_{h}V)^{2}]\\leq0.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, we obtain that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~\\displaystyle\\sum_{k=1}^{H}\\mathbb{E}_{\\pi^{k}}[((B^{\\pi}V)(\\pi_{h})-\\widehat{\\xi}_{V}(\\pi_{h}))^{2}]}\\\\ &{=\\displaystyle\\sum_{k=1}^{H}\\mathbb{E}_{\\pi^{k}}[(\\widehat{\\xi}_{V}(\\pi_{h})-\\mathcal{G}_{h}V)^{2}-((B^{\\pi}V)(\\pi_{h})-\\mathcal{G}_{h}V)^{2}]}\\\\ &{\\le\\displaystyle\\left|\\frac{M}{N_{\\mathrm{in}}}\\mathbb{E}_{\\mathcal{D}}-\\mathbb{E}_{\\pi_{h}}[[\\widehat{\\xi}_{V}(\\pi_{h})-\\mathcal{G}_{h}V)^{2}-((B^{\\mathcal{H}}V)(\\pi_{h})-\\mathcal{G}_{h}V)^{2}]\\right|+\\displaystyle\\sum_{k=1}^{H}\\mathbb{E}_{\\mathcal{D}}[(\\widehat{\\xi}_{V}(\\pi_{h})-\\mathcal{G}_{h}V)^{2}-}\\\\ &{\\le\\displaystyle\\left|\\sum_{h=1}^{H}\\{\\mathbb{E}_{D}-\\mathbb{E}_{\\pi_{h}}\\}[(\\widehat{\\xi}_{V}(\\pi_{h})-\\mathcal{G}_{h}V)^{2}-((B^{\\mathcal{H}}V)(\\pi_{h})-\\mathcal{G}_{h}V)^{2}]\\right|}\\\\ &{\\le\\sqrt{\\frac{150H\\bar{C}^{2}C_{\\mu}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi}[((B^{\\pi}V)(\\pi_{h})-\\widehat{\\xi}_{V}(\\pi_{h}))^{2}]\\log(4|V|\\|\\Xi\\|/\\delta)}{n}}+\\frac{40H\\bar{C}^{2}C_{\\mu}\\log(4|V|\\|\\Xi\\|/\\mathcal{G}_{l})}{n}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The second inequality is from Equation (12) and the last inequality is from Equation (11). We then have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}[((B^{\\mathcal{H}}V)(\\tau_{h})-\\widehat{\\xi}_{V}(\\tau_{h}))^{2}]\\leq\\varepsilon_{\\mathrm{stat}},\\quad\\varepsilon_{\\mathrm{stat}}:=\\frac{225H\\bar{C}^{2}C_{\\mu}\\log(4|\\mathcal{V}||\\Xi|/\\delta)}{n}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Combining Equation (11) and Equation (13), we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left|\\sum_{h=1}^{H}\\{\\mathbb{E}_{\\mathcal{D}}-\\mathbb{E}_{\\pi_{b}}\\}[(\\widehat{\\xi}_{V}(\\tau_{h})-\\mathcal{G}_{h}V)^{2}-((\\beta^{\\mathcal{H}}V)(\\tau_{h})-\\mathcal{G}_{h}V)^{2}]\\right|\\leq\\varepsilon_{\\mathrm{stat}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Hence, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\left|\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\mathcal{D}}[(\\widehat{\\xi}_{V}(\\tau_{h})-\\mathcal{G}_{h}V)^{2}]-\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\mathcal{D}}[((B^{\\mathcal{H}}V)(\\tau_{h})-\\mathcal{G}_{h}V)^{2}]\\right|}\\\\ &{\\le\\displaystyle\\left|\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}[(\\widehat{\\xi}_{V}(\\tau_{h})-\\mathcal{G}_{h}V)^{2}]-\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}[((B^{\\mathcal{H}}V)(\\tau_{h})-\\mathcal{G}_{h}V)^{2}]\\right|+2\\varepsilon_{\\mathrm{stat}}}\\\\ &{=\\displaystyle\\left|\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}[((B^{\\mathcal{H}}V)(\\tau_{h})-\\widehat{\\xi}_{V}(\\tau_{h}))^{2}]\\right|+2\\varepsilon_{\\mathrm{stat}}\\le3\\varepsilon_{\\mathrm{stat}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The first inequality is from Equation (14) and the last step is from Equation (13). ", "page_idx": 20}, {"type": "text", "text": "Analysis of Outer Minimizer. For any future-dependent value function $V_{\\mathcal{F}}$ , from optimality of $\\widehat V$ and the convergence of inner maximizer, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\underset{-1}{\\overset{H}{\\sum}}\\mathbb{E}_{\\mathcal{D}}[(\\mathcal{G}_{h}{\\widehat{V}})^{2}-(\\mathcal{G}_{h}{\\widehat{V}}-((B^{\\mathcal{H}}{\\widehat{V}}))(\\tau_{h}))^{2}]\\leq\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}_{\\mathcal{D}}\\left[(\\mathcal{G}_{h}{\\widehat{V}})^{2}-(\\mathcal{G}_{h}{\\widehat{V}}-{\\widehat{\\xi}}_{\\widehat{V}})^{2}\\right]+3\\varepsilon_{\\mathrm{sut}}.}&{}&\\\\ &{\\leq\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}_{\\mathcal{D}}\\left[(\\mathcal{G}_{h}V_{\\mathcal{F}})^{2}-(\\mathcal{G}_{h}V_{\\mathcal{F}}-{\\widehat{\\xi}}_{\\widehat{V}_{\\mathcal{F}}})^{2}\\right]+3\\varepsilon_{\\mathrm{sut}}}&\\\\ &{\\leq\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}_{\\mathcal{D}}\\left[(\\mathcal{G}_{h}V_{\\mathcal{F}})^{2}-(\\mathcal{G}_{h}V_{\\mathcal{F}}-(B^{\\mathcal{H}}V_{\\mathcal{F}})(\\tau_{h}))^{2}\\right]+6\\varepsilon_{\\mathrm{sut}}}&\\\\ &{=6\\varepsilon_{\\mathrm{sut}}.}&{(15)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The last step is from that $(\\mathscr{B}^{\\mathcal{H}}V_{\\mathcal{F}})(\\tau_{h})=0$ . For any $\\tau_{h}$ , we observe that $\\forall V\\in\\mathcal{V}$ and $h\\in[H]$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{\\pi_{b}}[(\\mathcal{G}_{h}V)^{2}-(\\mathcal{G}_{h}V-(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h}))^{2}]}\\\\ &{=\\mathbb{E}_{\\pi_{b}}[-(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h})^{2}+2(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h})\\mathcal{G}_{h}V]}\\\\ &{=\\mathbb{E}_{\\pi_{b}}[(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h})^{2}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "For any fixed $V\\in\\mathcal{V}$ , let $Y_{h}\\,=\\,(\\mathcal{G}_{h}V)^{2}\\,-\\,(\\mathcal{G}_{h}V\\,-\\,(\\mathcal{B}^{\\mathcal{H}}V)(\\tau_{h}))^{2}$ and $\\begin{array}{r}{Y\\,=\\,\\sum_{h=1}^{H}Y_{h}}\\end{array}$ , we have $|Y_{h}|\\leq27\\bar{C}^{2}C_{\\mu}$ and $|Y|\\leq27H\\bar{C}^{2}C_{\\mu}$ . We observe that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[Y_{h}^{2}]=\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[(2\\mathcal{G}_{h}{V}-(\\beta^{\\mathcal{H}}{V})(\\tau_{h}))^{2}(\\beta^{\\mathcal{H}}{V})(\\tau_{h})^{2}]}\\\\ &{\\qquad\\qquad\\leq\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[(18\\bar{C}^{2}+4(\\mathcal{G}_{h}{V})^{2})(B^{\\mathcal{H}}{V})(\\tau_{h})^{2}]}\\\\ &{\\qquad\\qquad\\leq\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[(26\\bar{C}^{2}+32\\bar{C}^{2}\\mu(o_{h},a_{h})^{2})(B^{\\mathcal{H}}{V})(\\tau_{h})^{2}]}\\\\ &{\\qquad\\qquad\\leq58\\bar{C}^{2}C_{\\mu}\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[(B^{\\mathcal{H}}{V})(\\tau_{h})^{2}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then, for the variance of $Y$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\mathop{Var}}_{\\pi_{b}}[Y]\\leq\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[Y^{2}]}\\\\ &{\\phantom{\\mathrm{\\mathop{Var}}}\\leq H\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[Y_{h}^{2}]}\\\\ &{\\phantom{\\mathrm{\\mathop{Var}}}=58H\\bar{C}^{2}C_{\\mu}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[({\\boldsymbol{B}}^{\\mathcal{H}}V)(\\tau_{h})^{2}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "From Bernstein\u2019s inequality, with probability at least $1-\\delta/2,\\forall V\\in\\mathcal{V}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\vert\\sum_{h=1}^{H}(\\mathbb{E}_{\\mathcal{D}}-\\mathbb{E}_{\\pi_{b}})\\left[(\\mathcal{G}_{h}V)^{2}-(\\mathcal{G}_{h}V-(B^{\\mathcal{H}}V)(\\tau_{h}))^{2}\\right]\\right\\vert}\\\\ &{\\le\\sqrt{58H\\bar{C}^{2}C_{\\mu}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}[(B^{\\mathcal{H}}V)(\\tau_{h})^{2}]\\frac{\\log(4|\\mathcal{V}|/\\delta)}{n}}+\\frac{27H\\bar{C}^{2}C_{\\mu}\\log(4|\\mathcal{V}|/\\delta)}{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{n=1}^{H}\\mathbb{E}_{n_{b}}\\left[(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})^{2}\\right]=\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{n_{b}}[(\\mathcal{G}_{h}\\widehat{V})^{2}-(\\mathcal{G}_{h}\\widehat{V}-(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h}))^{2}]}\\\\ &{\\le\\displaystyle\\left\\lvert\\sum_{h=1}^{H}(\\mathbb{E}_{D}-\\mathbb{E}_{\\pi_{b}})[(\\mathcal{G}_{h}\\widehat{V})^{2}-(\\mathcal{G}_{h}\\widehat{V}-(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h}))^{2}]\\right\\rvert}\\\\ &{\\ +\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{D}\\left[(\\mathcal{G}_{h}\\widehat{V})^{2}-(\\mathcal{G}_{h}\\widehat{V}-(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h}))^{2}\\right]}\\\\ &{\\le\\sqrt{58H\\bar{C}^{2}C_{\\mu}\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})^{2}\\right]\\displaystyle\\frac{\\log(4|\\mathcal{V}|/\\delta)}{n}+\\frac{27H\\bar{C}^{2}C_{\\mu}\\log(4|\\mathcal{V}|)}{n}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Solving it and we get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})^{2}\\right]\\leq10\\varepsilon_{\\mathrm{stat}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We then invoke Lemma 1 and obtain that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{J(\\tau_{x})-\\mathbb{E}_{\\tau_{x}}|\\hat{V}(f(\\hat{\\mathbf{z}})|)\\Bigg|\\leq\\Bigg|\\displaystyle\\sum_{k=1}^{\\infty}\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\Big[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})})(s_{k})\\Big]\\Bigg|}&{}\\\\ &{\\leq\\sqrt{\\mu\\frac{B}{E_{\\tau}}\\!\\left(\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\left[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})})(s_{k})\\right]\\right)^{2}}}\\\\ &{\\leq\\sqrt{\\mu\\frac{B}{E_{\\tau}}\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\Big[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})}(s_{k}))^{2}\\Big]}}\\\\ &{\\leq\\sqrt{\\mu\\frac{B}{E_{\\tau}}\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\Big[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})}(\\Gamma_{1})^{2})\\cdot\\sqrt{\\frac{\\sum_{k=1}^{B}\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\Big[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})}(s_{k}))^{2}\\Big]}{\\sum_{k=1}^{B}\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\left[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})})(s_{k})\\right]^{2}}}}\\\\ &{\\leq\\sqrt{\\nu\\mu\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}}\\,\\sqrt{\\sum_{k=1}^{B}\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\Big[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})}(s_{k}))^{2}\\Big]}\\,\\cdot\\,\\sqrt{\\!\\sum_{k=1}^{B}\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\left[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})}(s_{k}))^{2}\\right]}}\\\\ &{\\leq\\sqrt{\\nu\\mu\\mathbb{E}_{\\tau_{x}\\sim\\sigma_{k}}\\Big[(B^{(\\hat{\\mathbf{z}}^{\\hat{\\tau}})}(\\Gamma_{1})^{2}\\mathbb{E}_{\\tau_{x}}\\Big|(B^{(\\hat \n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The proof is completed by using Hoeffding\u2019s inequality to bound $\\|\\mathbb{E}_{\\mathcal{D}}[\\widehat{V}(f_{1})]-\\mathbb{E}_{\\pi_{b}}[\\widehat{V}(f_{1})]|$ . \u53e3 ", "page_idx": 22}, {"type": "text", "text": "D Proofs for Section 4 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "D.1 Example 1 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We provide a brief justification of Example 1. When $\\begin{array}{r}{\\operatorname*{Pr}_{\\pi_{b}}(f_{h}|s_{h})\\le\\frac{C_{\\mathrm{stoch}}}{(O A)^{H-h+1}}}\\end{array}$ , for any ${\\bf u}(f_{h})$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\|\\mathbf{u}(f_{h})\\|_{2}\\leq\\frac{C_{\\mathrm{stoch}}\\sqrt{S}}{(O A)^{H-h+1}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, for any $\\mathbf{x}\\in\\mathbb{R}^{S}$ such that $\\|\\mathbf{x}\\|_{2}=1$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbf{x}^{\\top}(M_{\\mathcal{F},h}M_{\\mathcal{F},h}^{\\top})\\mathbf{x}\\leq\\sum_{f_{h}}\\|\\mathbf{x}\\|_{2}^{2}\\|\\mathbf{u}(f_{h})\\|_{2}^{2}=\\frac{C_{\\mathrm{stoch}}^{2}S}{(O A)^{H-h+1}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, $\\sigma_{\\operatorname*{min}}(M_{\\mathcal{F},h})\\leq\\sigma_{\\operatorname*{max}}(M_{\\mathcal{F},h})\\leq C_{\\mathrm{stoch}}\\sqrt{S}/(O A)^{(H-h+1)/2}.$ ", "page_idx": 23}, {"type": "text", "text": "D.2 Proof of Proposition 3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "For each entry in $\\Sigma{\\mathcal{F}}{,h}$ , we can write it as ", "page_idx": 23}, {"type": "equation", "text": "$$\n(\\Sigma_{\\mathcal{F},h})_{i j}=\\sum_{k}\\frac{\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=k\\mid s_{h}=i)\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=k\\mid s_{h}=j)}{\\sum_{i^{\\prime}}\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=k\\mid s_{h}=i^{\\prime})}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Since the probability is always non-negative, all the entries in $\\Sigma{\\boldsymbol{\\mathcal{F}}}{,}h$ is non-negative. For each row $i$ , we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sum_{j}(\\Sigma_{\\mathcal{F},h})_{i j}=\\displaystyle\\sum_{k}\\sum_{j}\\frac{\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=k\\mid s_{h}=i)\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=k\\mid s_{h}=j)}{\\sum_{i^{\\prime}}\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=k\\mid s_{h}=i^{\\prime})}}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{k}\\operatorname*{Pr}_{\\pi_{b}}(f_{h}=k\\mid s_{h}=i)=1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Similarly, for each column $j$ , we also have $\\begin{array}{r}{\\sum_{i}(\\Sigma_{\\mathcal{F},h})_{i j}\\,=\\,1}\\end{array}$ . Therefore, we prove that $\\Sigma{\\mathcal{F}}{,h}$ is doubly-stochastic and we know for a stochas tic matrix, the largest eigenvalue is 1. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "D.3 Example 2 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Due to the block structure of $M_{\\mathcal{F},h},\\Sigma_{\\mathcal{F},h}$ is clearly diagonal, and the $i$ -th diagonal entry is: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{j:\\mathrm{Pr}_{\\pi_{b}}[f_{h}=j|s_{h}=i]>0}\\frac{\\mathrm{Pr}_{\\pi_{b}}[f_{h}=j|s_{h}=i]^{2}}{\\sum_{i^{\\prime}}\\mathrm{Pr}_{\\pi_{b}}[f_{h}=j|s_{h}=i^{\\prime}]}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Due to the revealing property, the denominator is just ${\\mathrm{Pr}}_{\\pi_{b}}[f_{h}=j|s_{h}=i]$ , so the expression is just summing up ${\\mathrm{Pr}}_{\\pi_{b}}[f_{h}=j|s_{h}=i]$ over $j$ , which is 1. ", "page_idx": 23}, {"type": "text", "text": "D.4 Proof of Proposition 4 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "According to Equation (4), we have for any $f_{h}$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathcal{F}}(f_{h})=Z(f_{h})^{-1}\\mathbf{u}(f_{h})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}V_{S,h}^{\\pi_{e}}}\\\\ &{\\qquad\\quad\\leq\\sqrt{Z(f_{h})^{-1}\\mathbf{u}(f_{h})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}Z(f_{h})^{-1}\\mathbf{u}(f_{h})}\\sqrt{(V_{S,h}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}V_{S,h}^{\\pi_{e}}}}\\\\ &{\\qquad\\quad\\leq\\sqrt{C_{\\mathcal{F},U}C_{\\mathcal{F},V}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The last step is from Assumption 7 and Assumption 8. Therefore, $\\|V_{\\mathcal{F}}\\|_{\\infty}\\,\\leq\\,\\sqrt{C_{\\mathcal{F},U}C_{\\mathcal{F},V}}\\,=$ $\\sqrt{C\\!\\!\\!\\:_{\\!\\mathscr{F},2}}$ . Moreover, we observe that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|V_{\\mathcal{F},h}\\|_{Z_{h}}^{2}=\\displaystyle\\sum_{f_{h}}Z(f_{h})\\left(Z(f_{h})^{-1}\\mathbf{u}(f_{h})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}V_{\\mathcal{S}}^{\\pi_{e}}\\right)^{2}}\\\\ &{\\phantom{\\quad\\quad}=\\displaystyle\\sum_{f_{h}}Z(f_{h})^{-1}(V_{\\mathcal{S}}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}\\mathbf{u}(f_{h})\\mathbf{u}(f_{h})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}V_{\\mathcal{S}}^{\\pi_{e}}}\\\\ &{\\phantom{\\quad\\quad}=(V_{\\mathcal{S}}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}\\left(\\displaystyle\\sum_{f_{h}}Z(f_{h})^{-1}\\mathbf{u}(f_{h})\\mathbf{u}(f_{h})^{\\top}\\right)\\Sigma_{\\mathcal{F},h}^{-1}V_{\\mathcal{S}}^{\\pi_{e}}}\\\\ &{\\phantom{\\quad\\quad}=(V_{\\mathcal{S}}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}\\Sigma_{\\mathcal{F},h}\\Sigma_{\\mathcal{F},h}^{-1}V_{\\mathcal{S}}^{\\pi_{e}}\\leq C_{\\mathcal{F},V}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The last step is from Assumption 7. ", "page_idx": 23}, {"type": "text", "text": "D.5 Example 3 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We give the calculation for Example 3. When $\\pi_{e}=\\pi_{b}$ , $V_{S,h}^{\\pi_{e}}=M_{\\mathcal{F},h}R_{h}^{+}$ , so ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|V_{{\\cal S},h}^{\\pi_{e}}\\|_{\\Sigma_{\\gamma,h}^{-1}}^{2}=(R_{h}^{+})^{\\top}M_{\\mathcal{F},h}^{\\top}\\Sigma_{\\mathcal{F},h}^{-1}M_{\\mathcal{F},h}R_{h}^{+}}\\\\ &{=(R_{h}^{+})^{\\top}Z_{h}^{1/2}Z_{h}^{-1/2}M_{\\mathcal{F},h}^{\\top}(M_{\\mathcal{F},h}Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top})M_{\\mathcal{F},h}Z_{h}^{-1/2}Z_{h}^{1/2}R_{h}^{+}}\\\\ &{\\le(R_{h}^{+})^{\\top}Z_{h}^{1/2}Z_{h}^{1/2}R_{h}^{+},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the last step follows from the fact that $Z_{h}^{-1/2}M_{\\mathcal{F},h}^{\\top}(M_{\\mathcal{F},h}Z_{h}^{-1}M_{\\mathcal{F},h}^{\\top})M_{\\mathcal{F},h}Z_{h}^{-1/2}$ is a projection matrix ${\\cal P}^{2}={\\cal P},$ ) and is dominated by identity in eigenvalues $(P\\preceq I)$ . Now, recall that $Z_{h}/S$ is a proper distribution, so ", "page_idx": 24}, {"type": "equation", "text": "$$\n(R_{h}^{+})^{\\top}Z_{h}R_{h}^{+}=S\\cdot\\mathbb{E}_{Z_{h}/S}[(R_{h}^{+})^{2}]\\leq S H^{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "E Proofs for Section 5 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "E.1 Proof of Lemma 6 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We first verify that $w^{\\star}$ in Eq. (8) satisfies Eq. (7) as follows. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\pi_{b}}[w^{\\star}(\\tau_{h})\\mathbf{b}(\\tau_{h})]=\\displaystyle\\sum_{\\tau_{h}}d_{h}^{\\pi_{b}}(\\tau_{h})w^{\\star}(\\tau_{h})\\mathbf{b}(\\tau_{h})}\\\\ &{\\phantom{\\quad\\quad}=\\displaystyle\\sum_{\\tau_{h}}d_{h}^{\\pi_{b}}(\\tau_{h})\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}}\\\\ &{\\phantom{\\quad\\quad}=\\displaystyle\\left(\\sum_{\\tau_{h}}d_{h}^{\\pi_{b}}(\\tau_{h})\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}\\right)\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}}\\\\ &{\\phantom{\\quad\\quad}=\\mathbf{b}_{h}^{\\pi_{e}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We then show that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|w^{\\star}\\|_{2,d_{h}^{\\pi_{b}}}^{2}=\\displaystyle\\sum_{\\tau_{h}}d_{h}^{\\pi_{b}}(\\tau_{h})\\left\\{\\mathbf{b}(\\tau_{h})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}({\\mathbf{b}}_{h}^{\\pi_{c}})\\right\\}^{2}}\\\\ &{\\qquad\\qquad=({\\mathbf{b}}_{h}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}\\left(\\displaystyle\\sum_{\\tau_{h}}d_{h}^{\\pi_{b}}(\\tau_{h})\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}\\right)\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{c}}}\\\\ &{\\qquad=({\\mathbf{b}}_{h}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}\\Sigma_{\\mathcal{H},h}\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}}\\\\ &{\\qquad=({\\mathbf{b}}_{h}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}\\leq C_{\\mathcal{H},2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The last step follows from Assumption 11. ", "page_idx": 24}, {"type": "text", "text": "E.2 Example 5 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Consider the lemma: given vector $x$ and PD matrix $\\Sigma$ , if $\\Sigma\\,\\succeq\\,x x^{\\top}$ , then $x^{\\top}\\Sigma^{-1}x\\,\\leq\\,1$ . The calculation in the example directly follows from letting $x=\\mathbf{b}_{h}^{\\pi_{b}}$ , $\\Sigma=\\Sigma_{\\mathcal{H},h}$ , and the condition $\\Sigma\\succeq x x^{\\top}$ is satisfied due to Jensen\u2019s inequality. ", "page_idx": 24}, {"type": "text", "text": "To prove the lemma, note that $\\Sigma-x x^{\\top}$ is PSD, so ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{c}{(\\Sigma^{-1}x)^{\\top}(\\Sigma-x x^{\\top})(\\Sigma^{-1}x)\\geq0.}\\\\ {\\top\\Sigma^{-1}x\\geq x^{\\top}\\Sigma^{-1}x x^{\\top}\\Sigma^{-1}x,\\,\\mathrm{so}\\;x^{\\top}\\Sigma^{-1}x\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This implies ", "page_idx": 24}, {"type": "text", "text": "E.3 Comparison between belief coverage and latent state coverage ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Here we show that belief coverage is stronger than latent state coverage. More concretely, consider a standard measure of latent state coverage, the 2nd moment of state density ratio (c.f. discussion below Example 7): ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\boldsymbol\\pi_{b}}[(d^{\\pi_{e}}(s_{h})/d^{\\pi_{b}}(s_{h}))^{2}]=(\\mathbf{b}_{h}^{\\pi_{e}})^{\\top}\\mathrm{diag}(\\mathbb{E}_{\\boldsymbol\\pi_{b}}[\\mathbf{b}(\\tau_{h})])^{-1}\\mathbf{b}_{h}^{\\pi_{e}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "In comparison, our belief coverage parameter from Assumption 11 is ", "page_idx": 25}, {"type": "equation", "text": "$$\n(\\mathbf{b}_{h}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}=(\\mathbf{b}_{h}^{\\pi_{e}})^{\\top}\\mathbb{E}_{\\pi_{b}}[\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}]^{-1}\\mathbf{b}_{h}^{\\pi_{e}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To show the former is smaller than the latter, it suffices to show that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathrm{diag}(\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[\\mathbf{b}(\\tau_{h})])^{-1}\\preceq(\\mathbb{E}_{\\boldsymbol{\\pi}_{b}}[\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}])^{-1},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "which is implied by $\\mathrm{diag}(\\mathbb{E}_{\\pi_{b}}[\\mathbf{b}(\\tau_{h})])\\ \\succeq\\ \\mathbb{E}_{\\pi_{b}}[\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}]$ . It therefore suffices to show that $\\mathrm{diag}({\\mathbf b}(\\tau_{h}))\\succeq{\\mathbf b}(\\tau_{h}){\\mathbf b}(\\tau_{h})^{\\top}$ holds in a pointwise manner for all $\\tau_{h}$ . To show this, we temporarily let ${\\bf b}={\\bf b}(\\tau_{h})$ in the calculation: consider an arbitrary vector $\\boldsymbol{v}\\in\\mathbb{R}^{S}$ , then ", "page_idx": 25}, {"type": "equation", "text": "$$\nv^{\\top}(\\mathbf{diag}(\\mathbf{b})-\\mathbf{b}\\mathbf{b}^{\\top})v=\\mathbb{E}_{s\\sim\\mathbf{b}}[v(s)^{2}]-(\\mathbb{E}_{s\\sim\\mathbf{b}}[v(s)])^{2}\\geq0.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The last step is due to Jensen\u2019s inequality. ", "page_idx": 25}, {"type": "text", "text": "E.4 Comparison to $\\mathbf{IV}(\\mathcal{V})$ ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We now compare to the $\\mathrm{IV}(\\mathcal{V})$ and $\\mathbf{D}\\mathbf{r}_{\\mathcal{V}}$ terms in Theorem 2. Belief coverage is generally stronger than latent state coverage which corresponds to the $\\mathbf{D}\\mathbf{r}_{\\mathcal{V}}$ term (see Appendix E.3). That said, perhaps surprisingly, the remaining $\\operatorname{IV}(\\mathcal{V})$ term must scale with \u03c3min(1\u03a3H,h) under moderate assumptions. ", "page_idx": 25}, {"type": "text", "text": "Proposition 10. Suppose $\\mathbf{v}_{\\mathrm{min}}$ is the eigenvector corresponding to $\\sigma_{\\mathrm{min}}(\\Sigma_{\\mathcal{H},h})$ , the smallest eigenvalue for some $\\Sigma_{\\mathcal{H},h}$ . Then, if $c_{0}\\mathbf{v}_{\\operatorname*{min}}\\;\\in\\;{\\mathcal{B}}_{h}^{S}{\\mathcal{V}}\\;:=\\;\\{{\\mathcal{B}}_{h}^{S}V\\;:\\;V\\;\\in\\;{\\mathcal{V}}\\}$ for some non-zero $c_{0}$ , $\\begin{array}{r}{\\operatorname{IV}(\\mathcal{V})\\geq\\sqrt{\\frac{\\operatorname*{min}_{s_{h}}d^{\\pi_{b}}\\left(s_{h}\\right)}{\\sigma_{\\operatorname*{min}}\\left(\\Sigma_{\\mathcal{H},h}\\right)}}}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "The proposition states that as long as $\\operatorname*{min}_{s_{h}}\\,d^{\\pi_{b}}(s_{h})$ is bounded away from 0 (which is benign and helps bound the $\\operatorname{Dr}_{\\mathcal{V}}[d^{\\pi_{e}},d^{\\pi_{b}}]$ term) and $\\mathcal{V}$ is sufficiently rich that $B_{h}^{S}\\mathcal{V}$ includes a certain vector in $\\mathbb{R}^{S}$ , then boundedness of $\\mathbf{IV}(\\mathcal{V})$ requires bounded $1/\\sigma_{\\operatorname*{min}}(\\Sigma_{\\mathcal{H},h})$ , which is stronger than our belief coverage assumption. This renders the split between $\\operatorname{IV}(\\mathcal{V})$ and $\\operatorname{Dr}_{\\mathcal{V}}[d^{\\pi_{e}},d^{\\pi_{b}}]$ superficial and perhaps unnecessary. ", "page_idx": 25}, {"type": "text", "text": "Proof of Proposition $I O$ . Since $c_{0}\\mathbf{v}_{\\operatorname*{min}}\\in\\{B_{h}^{S}V:V\\in\\mathcal{V}\\}$ , there exists $V$ such that $B_{h}^{S}V=c_{0}\\mathbf{v}_{\\operatorname*{min}}$ . For such $V$ , we observe that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\boldsymbol\\pi_{b}}\\left[\\left(B^{\\mathcal{H}}V\\right)(\\tau_{h})^{2}\\right]=\\sum_{\\tau_{h}}d^{\\pi_{b}}(\\tau_{h})\\left\\langle\\mathbf{b}(\\tau_{h}),c_{0}\\mathbf{v}_{\\operatorname*{min}}\\right\\rangle^{2}=c_{0}^{2}\\mathbf{v}_{\\operatorname*{min}}^{\\top}\\Sigma_{\\mathcal{H},h}\\mathbf{v}_{\\operatorname*{min}}=\\sigma_{\\operatorname*{min}}(\\Sigma_{\\mathcal{H},h})c_{0}^{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\boldsymbol\\pi_{b}}\\left[\\left(\\mathcal{B}^{S}V\\right)(s_{h})^{2}\\right]\\ge\\operatorname*{min}_{s_{h}}d^{\\pi_{b}}(s_{h})\\cdot\\|c_{0}\\mathbf{v}_{\\operatorname*{min}}\\|_{2}^{2}=\\operatorname*{min}_{s_{h}}d^{\\pi_{b}}(s_{h})\\cdot c_{0}^{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Therefore ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sqrt{\\frac{\\mathbb{E}_{\\pi_{b}}\\left[\\left(\\mathcal{B}^{S}V\\right)\\left(s_{h}\\right)^{2}\\right]}{\\mathbb{E}_{\\pi_{b}}\\left[\\left(\\mathcal{B}^{\\mathcal{H}}V\\right)\\left(\\tau_{h}\\right)^{2}\\right]}}\\ge\\sqrt{\\frac{\\operatorname*{min}_{s_{h}}d^{\\pi_{b}}\\left(s_{h}\\right)\\cdot c_{0}^{2}}{\\sigma_{\\operatorname*{min}}\\left(\\Sigma_{\\mathcal{H},h}\\right)c_{0}^{2}}}=\\sqrt{\\frac{\\operatorname*{min}_{s_{h}}d^{\\pi_{b}}\\left(s_{h}\\right)}{\\sigma_{\\operatorname*{min}}\\left(\\Sigma_{\\mathcal{H},h}\\right)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "E.5 Example 6 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "It suffices to show ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Sigma_{\\mathcal{H},h}\\mathbf{1}=\\mathbb{E}_{\\pi_{b}}[\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}]\\mathbf{1}=\\mathbb{E}_{\\pi_{b}}[\\mathbf{b}(\\tau_{h})\\mathbf{b}(\\tau_{h})^{\\top}\\mathbf{1}]=\\mathbb{E}_{\\pi_{b}}[\\mathbf{b}(\\tau_{h})]=\\mathbf{b}_{h}^{\\pi_{b}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "E.6 Proof of Lemma 8 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "The key is to notice that $\\left(\\mathbf{b}_{h}^{\\pi_{e}}\\right)^{\\top}$ is non-negative, so ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\quad(\\mathbf{b}_{h}^{\\pi_{e}})^{\\top}\\Sigma_{\\mathcal{H},h}^{-1}\\mathbf{b}_{h}^{\\pi_{e}}\\leq(\\mathbf{b}_{h}^{\\pi_{e}})^{\\top}|\\Sigma_{\\mathcal{H},h}^{-1}(\\mathbf{b}_{h}^{\\pi_{e}})|}&{\\mathrm{(|\\beta|\\cdot|~is~pointwise~absolute~value)}}\\\\ &{\\leq(\\mathbf{b}_{h}^{\\pi_{e}})^{\\top}\\mathbf{1}\\cdot\\lVert\\Sigma_{\\mathcal{H},h}^{-1}(\\mathbf{b}_{h}^{\\pi_{e}})\\rVert_{\\infty}}&{(\\mathrm{using~the~non-negativity~of~}(\\mathbf{b}_{h}^{\\pi_{e}})^{\\top}\\mathbf{\\tau_{again}})}\\\\ &{=\\lVert\\Sigma_{\\mathcal{H},h}^{-1}(\\mathbf{b}_{h}^{\\pi_{e}})\\rVert_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "E.7 Proof of Lemma 5 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "According to Eq. (5), we use $L_{1}/L_{\\infty}$ H\u00f6lder\u2019s inequality and obtain that for any $f_{h}$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|V_{\\mathcal{F}}(f_{h})|\\leq\\left\\|\\frac{\\mathbf{u}(f_{h})}{Z^{R}(f_{h})}\\right\\|_{1}\\left\\|(\\Sigma_{\\mathcal{F},h}^{R})^{-1}V_{S}^{\\pi_{e}}\\right\\|_{\\infty}}\\\\ &{\\qquad\\quad=R^{+}(f_{h})\\left\\|\\frac{\\mathbf{u}(f_{h})}{Z(f_{h})}\\right\\|_{1}\\left\\|(\\Sigma_{\\mathcal{F},h}^{R})^{-1}V_{S}^{\\pi_{e}}\\right\\|_{\\infty}}\\\\ &{\\qquad\\quad\\leq R^{+}(f_{h})C_{\\mathcal{F},\\infty}}\\\\ &{\\qquad\\quad\\leq H C_{\\mathcal{F},\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The second inequality is from Assumption 9 and $\\frac{\\mathbf{u}(f_{h})}{Z(f_{h})}$ is a stochastic vector. The last step is from the boundedness of the reward. \u53e3 ", "page_idx": 26}, {"type": "text", "text": "E.8 Example 4 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We use $\\mathrm{diag(\\cdot)}$ both for creating a diagonal matrix with an input vector and for taking the diagonal vector out of a matrix. ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Sigma_{\\mathcal{F},h}^{R}\\mathbf{1}=M_{\\mathcal{F},h}(Z_{h}^{R})^{-1}M_{\\mathcal{F},h}^{\\top}\\mathbf{1}=M_{\\mathcal{F},h}(Z_{h}^{R})^{-1}\\mathrm{diag}(Z_{h})^{\\top}=M_{\\mathcal{F},h}R_{h}^{+}=V_{\\mathcal{S}}^{\\pi_{e}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "E.9 Example 9 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "The calculation is similar to that of Example 2 in Appendix D.3, except that the numerator has an extra $R^{+}(f_{h})$ . Therefore, when calculating the $i$ -th diagonal entry of \u03a3FR,h, the final sum is calculating the expectation of $R^{+}(f_{h})$ conditioned on $s_{h}=i$ under policy $\\pi_{b}$ , which is the definition of $V_{S}^{\\pi_{b}}(i)$ . ", "page_idx": 26}, {"type": "text", "text": "E.10 Proof of Theorem 7 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In the proof of Theorem 2, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\mathbb{E}_{\\boldsymbol\\pi_{b}}\\left[(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})^{2}\\right]\\leq10\\varepsilon_{\\mathrm{stat}},\\quad\\varepsilon_{\\mathrm{stat}}:=\\frac{225H\\bar{C}^{2}\\log(4|\\mathcal{V}||\\Xi|/\\delta)}{n}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We observe that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left|\\mathbb{E}_{\\boldsymbol\\pi_{e}}\\left[(B^{S}\\widehat{V})(s_{h})\\right]\\right|=\\left|\\mathbb{E}_{\\boldsymbol\\tau_{h}\\sim d_{h}^{\\pi_{e}}}\\mathbb{E}_{s_{h}\\sim\\mathbf{b}(\\tau_{h})}\\left[(B^{S}\\widehat{V})(s_{h})\\right]\\right|}&{}\\\\ {=\\left|\\mathbb{E}_{\\boldsymbol\\pi_{e}}\\left[(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|}&{}\\\\ {=\\left|\\mathbb{E}_{\\boldsymbol\\pi_{b}}\\left[w^{\\star}(\\tau_{h})(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|}&{}\\\\ {\\leq\\|{w^{\\star}}\\|_{2,d_{h}^{\\pi_{b}}}\\sqrt{\\mathbb{E}_{\\boldsymbol\\pi_{b}}\\left[(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})^{2}\\right]}}&{}\\\\ {\\leq\\sqrt{C_{\\mathcal{H},2}\\mathbb{E}_{\\boldsymbol\\pi_{b}}\\left[(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})^{2}\\right]}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The third equality is from Definition 10, the first inequality is from Cauchy-Schwarz inequality and the last inequality is from Lemma 6. Then, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\left\\vert\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{e}}\\left[(B^{S}\\widehat{V})(s_{h})\\right]\\right\\vert\\leq\\sqrt{H\\displaystyle\\sum_{h=1}^{H}\\left(\\mathbb{E}_{\\pi_{e}}\\left[(B^{S}\\widehat{V})(s_{h})\\right]\\right)^{2}}}&{}\\\\ {\\leq\\sqrt{10H C\\eta_{,2}\\varepsilon_{\\mathrm{stat}}}}&{}\\\\ {\\leq50H\\bar{C}\\sqrt{\\frac{C_{\\mathcal{H},2}C_{\\mu}\\log(4|\\mathcal{V}||\\Xi|/\\delta)}{n}}}&{}\\\\ {\\leq c H^{2}(C_{\\mathcal{F},\\infty}+1)\\sqrt{\\frac{C_{\\mathcal{H},2}C_{\\mu}\\log(4|\\mathcal{V}||\\Xi|/\\delta)}{n}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The last step is from Lemma 5, $C_{\\mathcal{V}}\\leq c\\|V_{\\mathcal{F}}\\|_{\\infty}$ and $C_{\\Xi}\\leq c(\\|V_{\\mathcal{F}}\\|_{\\infty}+1)$ . The proof is completed after invoking Lemma 1. \u53e3 ", "page_idx": 26}, {"type": "text", "text": "E.11 Proof of Theorem 9 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Finally, we prove Theorem 9. The proof uses the similar idea from Xie and Jiang [2020]. For any $V\\in\\mathcal{V}$ and $w\\in\\mathscr{W}$ , we define the population loss estimator $\\mathcal{L}_{d^{\\pi_{b}}}$ and the empirical loss estimator $\\mathcal{L}_{\\mathcal{D}}$ as follows ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{d^{\\pi_{b}}}(V,w):=\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[w(\\tau_{h})(B^{\\mathcal{H}}V)(\\tau_{h})\\right]}\\\\ &{\\quad\\mathcal{L}_{\\mathcal{D}}(V,w):=\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\mathcal{D}}\\left[w(\\tau_{h})\\left(\\mu(o_{h},a_{h}\\right)(r_{h}+V(f_{h+1}))-V(f_{h})\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We then invoke Lemma 1 and obtain that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left|J(\\pi_{e})-\\mathbb{E}_{\\pi_{b}}[\\widehat{V}(f_{1})]\\right|=\\left|\\sum_{h=1}^{H}\\mathbb{E}_{s_{h}\\sim d^{\\pi_{e}}}\\left[(\\beta^{S}\\widehat{V})(s_{h})\\right]\\right|.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We observe that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{s_{h}\\sim d^{\\pi_{e}}}\\left[(\\mathcal{B}^{S}\\widehat{V})(s_{h})\\right]=\\mathbb{E}_{\\tau_{h}\\sim d^{\\pi_{e}}}\\left[\\mathbb{E}_{s_{h}\\sim\\mathbf{b}(\\tau_{h})}\\left[(\\mathcal{B}^{S}\\widehat{V})(s_{h})\\right]\\right]}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\mathbb{E}_{\\tau_{h}\\sim d^{\\pi_{e}}}\\left[(\\mathcal{B}^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\mathbb{E}_{\\pi_{b}}\\left[w^{\\star}(\\tau_{h})(\\mathcal{B}^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the last step is from Definition 10. Therefore, our goal is to bound $\\begin{array}{r}{\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\boldsymbol\\pi_{b}}\\left[w^{\\star}(\\tau_{h})(\\bar{\\boldsymbol{B}^{\\mathcal{H}}}\\widehat{V})(\\tau_{h})\\right]\\right|=\\left|\\mathcal{L}_{d^{\\pi_{b}}}(\\widehat{V},w^{\\star})\\right|\\!.}\\end{array}$ . Let ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{w}:=\\underset{w\\in\\mathrm{sp}(\\mathcal{W})}{\\mathrm{argmin}}\\underset{V\\in\\mathcal{V}}{\\operatorname*{max}}\\left|\\sum_{h=1}^{H}{\\mathbb{E}}_{\\pi_{b}}\\left[(w^{\\star}(\\tau_{h})-w(\\tau_{h}))\\cdot(B^{\\mathcal{H}}V)(\\tau_{h})\\right]\\right|,}\\\\ &{\\widetilde{V}:=\\underset{V\\in\\mathcal{V}}{\\mathrm{argmin}}\\underset{w\\in\\mathrm{sp}(\\mathcal{W})}{\\operatorname*{sup}}\\left|\\sum_{h=1}^{H}{\\mathbb{E}}_{\\pi_{b}}\\left[w(\\tau_{h})\\cdot(B^{\\mathcal{H}}V)(\\tau_{h})\\right]\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then, we subtract the approximation error of $\\widehat{w}$ from our objective, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[w^{\\star}(\\tau_{h})(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\Bigg|=}&{\\displaystyle\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[(w^{\\star}(\\tau_{h})-\\widehat{w}(\\tau_{h}))\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]+\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[\\widehat{w}(\\tau_{h})\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|}\\\\ &{\\displaystyle\\leq\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[(w^{\\star}(\\tau_{h})-\\widehat{w}(\\tau_{h}))\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|+\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[\\widehat{w}(\\tau_{h})\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|}\\\\ &{\\displaystyle\\leq\\epsilon_{W}+\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[\\widehat{w}(\\tau_{h})\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Next, we consider the approximation error of $\\widetilde{V}$ and obtain that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[\\widehat{w}(\\tau_{h})\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\Bigg|=\\epsilon\\nu+\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[\\widehat{w}(\\tau_{h})\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|-\\operatorname*{sup}_{w\\in\\mathrm{sp}(\\mathcal{W})}\\left|\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[w(\\tau_{h})\\cdot(B^{\\mathcal{H}}\\widehat{V})(\\tau_{h})\\right]\\right|,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We then connect $\\mathcal{L}_{d^{\\pi_{b}}}(V,w)$ with $\\mathcal{L}_{\\mathcal{D}}(V,w)$ as follows, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{h}}\\left[\\widehat{w}(\\gamma_{h})\\cdot(B^{\\#}\\widehat{V})(\\tau_{h})\\right]\\right|-\\displaystyle\\operatorname*{sup}_{w\\in\\Theta(N)}\\left|\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{h}}\\left[w(\\tau_{h})\\cdot(B^{\\#}\\widehat{V})(\\tau_{h})\\right]\\right|}\\\\ &{\\leq\\displaystyle}\\\\ &{\\displaystyle=\\operatorname*{sup}_{w\\in\\mathrm{sp}(W)}\\left|\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{h}}\\left[w(\\tau_{h})\\cdot(B^{\\#}\\widehat{V})(\\tau_{h})\\right]\\right|-\\displaystyle\\operatorname*{sup}_{w\\in\\mathrm{sp}(W)}\\left|\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{h}}\\left[w(\\tau_{h})\\cdot(B^{\\#}\\widehat{V})(\\tau_{h})\\right]\\right|}\\\\ &{=\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}(\\bar{V})}\\left|\\angle{a}^{\\nu_{h}}(\\bar{V},w)\\right|-\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}(\\bar{V},w)}\\left|\\displaystyle\\sum_{h=1}^{H}w_{\\tau}\\widehat{V}_{\\tau}w\\right|}\\\\ &{=\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}(\\bar{V},w)}\\left|-\\displaystyle\\sum_{w\\in\\mathrm{sp}(\\bar{V},w)}\\left|\\displaystyle\\sum_{\\bar{C}>(\\bar{V})}\\left|+\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}}\\left|\\mathcal{L}_{D}(\\bar{V},w)\\right|-\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}}\\left|\\mathcal{L}_{d^{\\#}\\nu}\\left(\\tilde{V},w\\right)\\right|}\\\\ &{\\le\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}(\\bar{V},w)}\\left|-\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}(\\bar{V},w)}\\left|\\displaystyle\\sum_{w\\in\\mathrm{sp}(\\bar{V},w)}\\right|+\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}(\\bar{V},w)}\\left|-\\operatorname*{max}_{w\\in\\mathrm{sp}}\\left|\\mathcal{L}_{d^{\\#}\\nu}\\left(\\tilde{V},w\\right)\\right|}\\\\ &{\\le\\displaystyle\\operatorname*{max}_{w\\in\\mathrm{sp}(\\bar{V},w)}\\left|-\\alpha_{P}(\\bar{V\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The first equality is from that $\\begin{array}{r}{\\operatorname*{sup}_{w\\in\\operatorname{sp}(\\mathcal{W})}|f(\\cdot)|=\\operatorname*{max}_{w\\in\\mathcal{W}}|f(\\cdot)|}\\end{array}$ for any linear function $f(\\cdot)$ . The second inequality is from the optimality of $\\widehat V$ . ", "page_idx": 28}, {"type": "text", "text": "For any fixed $V,w$ , let random variable $\\begin{array}{r}{X\\,=\\,\\sum_{h=1}^{H}w(\\tau_{h})\\,(\\mu(o_{h},a_{h})(r_{h}+V(f_{h}))-V(f_{h+1}))}\\end{array}$ , $\\mathbb{E}_{\\pi_{b}}[X]=\\mathcal{L}_{d^{\\pi_{b}}}(V,w)$ . Recall that $C_{\\mathcal{V}}:=\\operatorname*{max}_{V\\in\\mathcal{V}}\\|V\\|_{\\infty}$ and $C_{\\mathcal{W}}:=\\operatorname*{max}_{h}\\operatorname*{sup}_{w\\in\\mathcal{W}}\\|w\\|_{\\infty}$ . For $|X|$ , we have $|X|\\leq2H C_{\\mu}(1+C_{\\nu})C_{\\mathcal{W}}$ . For the variance, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathrm{Var}_{\\pi_{b}}[X]}\\\\ &{\\le H\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[w(\\tau_{h})^{2}(\\mu(o_{h},a_{h})(r_{h}+V(f_{h+1}))-V(f_{h}))^{2}\\right]}\\\\ &{\\le H\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{b}}\\left[w(\\tau_{h})^{2}\\left(2C_{V}^{2}+2(1+C_{V})^{2}\\mu(o_{h},a_{h})^{2}\\right)\\right]}\\\\ &{\\le4H^{2}(1+C_{V})^{2}C_{\\mu}C_{\\mathcal{W}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "From Bernstein\u2019s inequality, with probability at least $1-\\delta$ , we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n|\\mathcal{L}_{d^{\\pi_{b}}}(V,w)-\\mathcal{L}_{\\mathcal{D}}(V,w)|\\leq2H(1+C_{\\mathcal{V}})C_{\\mathcal{W}}\\sqrt{\\frac{C_{\\mu}\\log\\frac{2}{\\delta}}{n}}+\\frac{2H(1+C_{\\mathcal{V}})C_{\\mathcal{W}}C_{\\mu}\\log\\frac{2}{\\delta}}{n}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Taking the union bound and we obtain ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{w\\in\\mathcal{W}}{\\operatorname*{max}}\\left|\\mathcal{L}_{d^{\\pi_{b}}}(\\widehat{V},w)-\\mathcal{L}_{\\mathcal{D}}(\\widehat{V},w)\\right|+\\underset{w\\in\\mathcal{W}}{\\operatorname*{max}}\\left|\\mathcal{L}_{d^{\\pi_{b}}}(\\widetilde{V},w)-\\mathcal{L}_{\\mathcal{D}}(\\widetilde{V},w)\\right|}\\\\ &{\\leq4H(1+C_{\\mathcal{V}})C_{\\mathcal{W}}\\sqrt{\\frac{C_{\\mu}\\log\\frac{2|\\mathcal{V}||\\mathcal{W}|}{\\delta}}{n}}+\\frac{4H(1+C_{\\mathcal{V}})C_{\\mathcal{W}}C_{\\mu}\\log\\frac{2|\\mathcal{V}||\\mathcal{W}|}{\\delta}}{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "According to Lemma 5, Assumption 12, $C_{\\mathcal{V}}\\leq c\\|V_{\\mathcal{F}}\\|_{\\infty}$ and $C_{\\mathcal{W}}\\leq c\\|w^{\\star}\\|_{\\infty}$ , we further have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\small J(\\pi_{e})-\\mathbb{E}_{\\pi_{b}}[\\widehat{V}(f_{1})]\\Big|\\leq\\epsilon_{V}+\\epsilon_{W}+c H^{2}C_{\\mathcal{H},\\infty}(C_{\\mathcal{F},\\infty}+1)\\sqrt{\\frac{C_{\\mu}\\log\\frac{2|\\mathcal{V}||\\mathcal{W}|}{\\delta}}{n}}+\\frac{c H^{2}C_{\\mathcal{H},\\infty}(C_{\\mathcal{F},\\infty}+C_{\\mathcal{H},\\infty})}{n}\\sqrt{\\frac{C_{\\mu}\\log\\frac{2|\\mathcal{V}||\\mathcal{W}|}{\\delta}}{n}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The proof is completed by using Hoeffding\u2019s inequality to bound $|\\mathbb{E}_{\\mathcal{D}}[\\widehat{V}(f_{1})]-\\mathbb{E}_{\\pi_{b}}[\\widehat{V}(f_{1})]|$ . ", "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: We discuss the limitations in Section 6. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide the full set of assumptions in the main text and a complete proof in the appendix. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: No experiments. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: No experiments. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: No experiments. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: No experiments. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: No experiments. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We conform with the NeurIPS Code of Ethics. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper presents work whose goal is to advance the field of learning theory and has no societal impact. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 33}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 34}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}]