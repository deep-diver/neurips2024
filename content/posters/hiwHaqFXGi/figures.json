[{"figure_path": "hiwHaqFXGi/figures/figures_1_1.jpg", "caption": "Figure 1: The number of latent factors is set to 4. In Fig. 1(a), the probabilities of nodes belonging to different latent groups are similar, resulting in nodes of the same type being incorrectly assigned to different factors. In contrast, Fig. 1(b) shows that the probabilities of node-factor affiliation are more discriminative, correctly categorizing nodes of the same type into the same latent group.", "description": "This figure compares two approaches to latent factor learning in the context of graph masked autoencoders (GMAEs).  (a) shows the results of applying traditional methods to GMAEs. The probabilities of nodes belonging to different latent factors are similar, leading to misclassification. (b) shows the improved results achieved by the proposed DiGGR method.  The probabilities are more discriminative, correctly assigning nodes of the same type to the same latent factor, thus improving the disentanglement of learned representations.", "section": "1 Introduction"}, {"figure_path": "hiwHaqFXGi/figures/figures_3_1.jpg", "caption": "Figure 2: The overview of proposed DiGGR's computation graph. The input data successively passes three modules described in Sections 3.2 and 3.3: Latent Factor Learning, Graph Factorization, and Disentangled Graph Mask Autoencoder. Graph information will be first processed through Latent Factor Learning and Graph Factorization, the former processed the input graph to get the latent factor z; the latter performs graph factorization via z, such that in each factorized subgraph, nodes exchange more information with intensively interacted neighbors. Hence, during the disentangled graph masking phase, we will individually mask each factorized subgraph to enhance the disentanglement of the obtained node representations.", "description": "This figure illustrates the architecture of the DiGGR model.  The input graph is first processed by a Latent Factor Learning module to extract latent factors (z). Then, a Graph Factorization module uses these factors to decompose the graph into factor-specific subgraphs.  These subgraphs are then fed into a Disentangled Graph Mask Autoencoder, where random masking is applied to each subgraph individually to improve the disentanglement of the learned representations. The masked subgraphs are processed by separate Graph Masked Autoencoders and then reconstructed, creating a final representation of the graph.", "section": "3 Proposed Method"}, {"figure_path": "hiwHaqFXGi/figures/figures_8_1.jpg", "caption": "Figure 3: T-SNE visualization of MUTAG dataset, where z is the latent factor, H is the learned node representation used for downstream tasks.", "description": "This figure visualizes the results of t-SNE dimensionality reduction applied to the MUTAG dataset.  The left panel (a) shows the latent factors (z) colored by node label, demonstrating the learned clustering based on node attributes before the masking process. The central panel (b) shows the learned node representations (H) after the disentangled masking and reconstruction process, colored by the assigned latent factor.  The visualization aims to illustrate the disentanglement of features achieved by the DiGGR model, showcasing how different latent factors capture distinct aspects of node characteristics.", "section": "4.3 Exploratory Studies"}, {"figure_path": "hiwHaqFXGi/figures/figures_12_1.jpg", "caption": "Figure 5: Performance of the task under different choices of latent factor number K, where the horizontal axis represents the change in K and the vertical axis is accuracy.", "description": "This figure shows the performance of node classification tasks on four different datasets (Cora, MUTAG, Citeseer, IMDB-B) with varying numbers of latent factors (K).  The x-axis represents the number of latent factors (K), while the y-axis shows the accuracy achieved.  The results indicate that an optimal number of latent factors exists for each dataset; increasing or decreasing the number beyond the optimal value decreases performance.  This suggests that a balance is needed between the complexity of the model and its ability to capture the underlying structure of the data.", "section": "A.1 Ablation Study"}, {"figure_path": "hiwHaqFXGi/figures/figures_14_1.jpg", "caption": "Figure 3: T-SNE visualization of MUTAG dataset, where z is the latent factor, H is the learned node representation used for downstream tasks.", "description": "This figure shows the t-SNE visualization of the MUTAG dataset, used to reduce the dimensionality of the data for better visualization.  It displays two subfigures:\n\n(a) shows the visualization of the latent factor (z), where each node is colored according to its node label. This demonstrates the ability of the latent factor to capture meaningful node information even without explicit label supervision.\n\n(b) shows the visualization of the learned node representation (H) used for classification, where each node is colored according to its assigned latent factor. This subfigure illustrates the disentanglement achieved by the model, as nodes belonging to the same latent factor tend to cluster together, highlighting the efficacy of DiGGR in separating node features based on their latent factors.", "section": "4.3 Exploratory Studies"}]