[{"figure_path": "HfztZgwpxI/tables/tables_2_1.jpg", "caption": "Table 1: Summary of the datasets and their properties. * in the #FoV refers to the possible presence of hidden factors.", "description": "This table summarizes the properties of several datasets used in the paper's experiments.  For each dataset, it indicates whether it contains real or synthetic images, whether it involves 3D or 2D objects, the presence of occlusions, the number of factors of variation (FoVs), whether the FoVs are independent, and whether there is complete annotation of the factors. It also specifies the resolution and the number of images in each dataset. The asterisk (*) next to #FoV denotes the possibility of hidden factors.", "section": "3.2 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_5_1.jpg", "caption": "Table 1: Summary of the datasets and their properties. * in the #FoV refers to the possible presence of hidden factors.", "description": "This table summarizes the characteristics of eight datasets used in the paper's experiments.  For each dataset, it indicates whether it contains real or synthetic images (Real), whether the images are 3D or 2D (3D), whether occlusions are present (Occlusions), the number of factors of variation (FoV), whether the FoVs are independent, if complete annotations are available, the resolution of images, and the number of images in the dataset.  The asterisk (*) in the #FoV column indicates the potential presence of hidden or unannotated factors.  This table is crucial for understanding the diversity and complexity of the data used in evaluating the proposed disentangled representation transfer methodology.", "section": "3.2 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative analysis of transferring disentangled representations within the dSprites family of datasets.  It shows the average classification accuracy (using Gradient Boosted Trees) before and after fine-tuning, comparing performance using the full representation versus a pruned representation (selected based on the OMES metric). The table also includes measures of disentanglement (MES, OS, DCI, MIG).", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_7_2.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative analysis of transferring disentangled representations within the dSprites family of datasets.  It shows the average classification accuracy (using Gradient Boosted Trees) for various factors of variation (FoVs), both before and after applying a dimensionality reduction technique guided by the OMES metric (Pruned). The results are broken down by source and target datasets, showcasing the impact of the transfer on different aspects of disentanglement.  Finally, it includes a comparison using disentanglement metrics like MES, OS, DCI, and MIG to evaluate the overall quality of the disentangled representations after transfer.", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_8_1.jpg", "caption": "Table 4: Target dataset: Coil100 and variants (see Table 2).", "description": "This table presents the results of transferring disentangled representations from different source datasets to the Coil-100 dataset and its variants. It shows the average classification accuracy for different factors of variation (FoVs), along with disentanglement metrics (Modularity and Compactness) before and after fine-tuning.  The \"Pruned\" column indicates whether only the most relevant dimension according to the OMES metric was used for classification.  It helps to understand the performance of the transfer learning and the preservation of disentanglement properties in the target domain.", "section": "3.3 Experimental analysis"}, {"figure_path": "HfztZgwpxI/tables/tables_8_2.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative evaluation of transferring disentangled representations within the dSprites family of datasets.  It shows the average classification accuracy using Gradient Boosted Trees (GBT) for various source-target dataset pairs, both with the full representation and a \"pruned\" representation (using only the most informative dimension).  Disentanglement is evaluated using MES, OS, DCI, and MIG metrics.", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_15_1.jpg", "caption": "Table 6: Summary of different metrics for disentanglement learning. L and K are the numbers of latent variables and ground truth factors, respectively.", "description": "This table compares various metrics used for evaluating disentanglement in representation learning.  It shows whether each metric is based on intervention, information theory, or prediction; the type of classifier (if any) used; the number of classifiers; and the disentanglement property (modularity or compactness) measured by each metric. The table provides a useful overview of the existing approaches to evaluating disentanglement, highlighting their strengths and weaknesses.", "section": "2 Evaluating the quality of disentanglement"}, {"figure_path": "HfztZgwpxI/tables/tables_22_1.jpg", "caption": "Table 6: Summary of different metrics for disentanglement learning. L and K are the numbers of latent variables and ground truth factors, respectively.", "description": "This table summarizes several metrics used to evaluate disentanglement in representation learning.  It compares various approaches based on whether they are intervention-based, information-based, or predictor-based. The table also specifies the classifier used (if any), the number of classifiers, and the disentanglement property each metric measures (Modularity, Compactness, or Explicitness).  This allows for a comparison of different methods and their strengths in evaluating specific aspects of disentanglement.", "section": "2 Evaluating the quality of disentanglement"}, {"figure_path": "HfztZgwpxI/tables/tables_23_1.jpg", "caption": "Table 9: Transfer from Shapes3D (Source) to Isaac3D (Target). Average classification accuracy over the 20 models of the GBT classifier, before and after fine-tuning (see Table 2).", "description": "This table presents the average classification accuracy of a Gradient Boosted Trees (GBT) classifier on the Isaac3D dataset.  The classifier is trained using the disentangled representations learned from the Shapes3D dataset.  The table shows the performance both before and after fine-tuning the model on the Isaac3D dataset.  The results are broken down by individual Factors of Variation (FoVs) in the Isaac3D dataset, and also shows an overall accuracy across all FoVs.  The 'Pruned' row indicates whether a single dimension (the one with strongest OMES score for the FoV) was used in the classification or the entire representation was used.", "section": "3.3 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_23_2.jpg", "caption": "Table 10: Transfer from Shapes3D (Source) to Isaac3D (Target). The Compactness and Modularity scores of the same models of Table 9.", "description": "This table shows the compactness and modularity scores for the same models used in Table 9.  The compactness and modularity are evaluated using the OMES metric (both OS and MES components) and also using DCI and MIG metrics. The results show the values before and after fine-tuning, indicating the impact of the fine-tuning process on these two important properties of disentangled representations.", "section": "3.3 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_26_1.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative evaluation of how well disentangled representations transfer between different datasets in the dSprites family.  It shows the average classification accuracy (using Gradient Boosted Trees) for various factors of variation (FoVs), both using the full representation and a pruned version (selected using the OMES metric). It also compares disentanglement using different metrics (MES, OS, DCI, MIG). The source and target datasets are specified, and the improvements from fine-tuning are indicated.", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_26_2.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative evaluation of the transfer learning experiments using the dSprites dataset family. It shows the average classification accuracy obtained by using Gradient Boosted Trees (GBT) on both the full and pruned (one-dimensional) representations.  The table compares results for different Source and Target datasets, indicating which FoVs (Factors of Variation) were used. The final columns provide a comparison of various disentanglement metrics (including the proposed OMES metric).", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_26_3.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative evaluation of transferring disentangled representations using the dSprites dataset family.  It shows the average classification accuracy (using Gradient Boosted Trees) on various target datasets, comparing results obtained using the full representation versus a pruned (single-dimension) representation.  The table also includes a comparison of disentanglement metrics (MES, OS, DCI, MIG) to assess the quality of the transferred representation.  The source dataset varies across different rows, while the target datasets (and the use of the pruned representation) are systematically varied to explore the impact of this transfer.", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_27_1.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative analysis of transferred disentangled models using the dSprites family of datasets.  It shows the average classification accuracy (using Gradient Boosted Trees) for different Source and Target datasets, both with the full representation and a pruned representation (using only the most relevant dimension as determined by OMES).  The table compares the performance before and after fine-tuning, and also includes a comparison of disentanglement metrics like MES (Multiple Encoding Score), OS (Overlap Score), DCI (Disentanglement), and MIG (Mutual Information Gap).", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_27_2.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative analysis of transferring disentangled representations within the dSprites family of datasets.  It shows the average classification accuracy (using Gradient Boosted Trees) on different factors of variation (FoVs), both using the full representation and a pruned representation (selected using the OMES metric).  The table also includes disentanglement scores (MES, OS, DCI, MIG) to evaluate the quality of the transferred representation.  The comparison is made for various source-target dataset pairs, allowing assessment of transfer performance across different levels of similarity between the source and target data.", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_27_3.jpg", "caption": "Table 1: Summary of the datasets and their properties. * in the #FoV refers to the possible presence of hidden factors.", "description": "This table summarizes the characteristics of several datasets used in the paper's experiments.  It lists whether each dataset is real or synthetic, if it contains 3D information or occlusions, the number of factors of variation (#FoV) it contains, whether these factors are independent or correlated, if complete annotations are available for all FoVs, and the resolution and number of images in each dataset. The asterisk (*) next to #FoV indicates that hidden factors might exist in that dataset.", "section": "3.2 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_28_1.jpg", "caption": "Table 1: Summary of the datasets and their properties. * in the #FoV refers to the possible presence of hidden factors.", "description": "This table summarizes the characteristics of several datasets used in the paper's experiments.  It shows whether each dataset is real or synthetic, if it involves 3D data or occlusions, the number of factors of variation (FoVs), whether the FoVs are independent, if complete annotations are available, the image resolution, and the total number of images. The asterisk (*) indicates that there might be hidden factors in the dataset.", "section": "3.2 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_28_2.jpg", "caption": "Table 1: Summary of the datasets and their properties. * in the #FoV refers to the possible presence of hidden factors.", "description": "This table summarizes the characteristics of several datasets used in the paper's experiments.  For each dataset, it indicates whether it consists of real or synthetic images, if it includes 3D information, if occlusions are present, the number of factors of variation (FoVs), whether the FoVs are independent, whether complete annotations are available, the image resolution, and the number of images.", "section": "3.2 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_28_3.jpg", "caption": "Table 1: Summary of the datasets and their properties. * in the #FoV refers to the possible presence of hidden factors.", "description": "This table summarizes the characteristics of several datasets used in the paper's experiments.  It shows whether each dataset is real or synthetic, whether it involves 3D objects or occlusions, the number of factors of variation (#FoV), whether the factors are independent, whether there is complete annotation of the FoVs, the image resolution, and the number of images. The asterisk (*) next to the #FoV indicates the potential presence of hidden factors.  The table helps to understand the diversity of data used in evaluating the proposed method for transferring disentangled representations, highlighting the differences in complexity and supervision.", "section": "3.2 Datasets"}, {"figure_path": "HfztZgwpxI/tables/tables_29_1.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative evaluation of transferred disentangled models, focusing on the dSprites family of datasets.  It shows the average classification accuracy achieved using Gradient Boosted Trees (GBT) on both the full and pruned latent representations. The table compares results across different source and target datasets, analyzing the impact of transferring a disentangled representation from one dataset to another.  The final columns provide a comparison using different disentanglement metrics (MES, OS, DCI, MIG).", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_29_2.jpg", "caption": "Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.", "description": "This table presents a quantitative evaluation of transferring disentangled models within the dSprites family of datasets.  It shows the average classification accuracy using Gradient Boosted Trees (GBTs) on both the full and pruned representations (where the representation is reduced to only the most informative dimension for each factor of variation). The results are presented for various Source-Target dataset pairs, illustrating how well disentanglement transfers in different scenarios.  It also includes a comparison of disentanglement metrics like MES (Multiple Encoding Score), OS (Overlap Score), DCI (Disentanglement), and MIG (Mutual Information Gap) to assess the quality of the transferred representations.", "section": "3 Transferring disentangled representations"}, {"figure_path": "HfztZgwpxI/tables/tables_29_3.jpg", "caption": "Table 1: Summary of the datasets and their properties. * in the #FoV refers to the possible presence of hidden factors.", "description": "This table summarizes the characteristics of several datasets used in the paper's experiments.  It shows whether each dataset is real or synthetic, whether it includes 3D information or occlusions, the number of factors of variation (#FoV), whether the factors are independent, whether complete annotations are available, the resolution of the images, and the number of images in each dataset.  The asterisk (*) indicates that the dataset may have hidden factors not explicitly identified.", "section": "3.2 Datasets"}]