[{"figure_path": "RPChapuXlC/tables/tables_3_1.jpg", "caption": "Table 1: Performance under different harmful ratios. The fine-tuning dataset is SST-2 and the base model is a Llama2-7B. The switching step is K\u2081 = K2 = 500. SFT is standard supervised fine-tuning. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the results of the Bi-State Optimization (BSO) method and the standard Supervised Fine-Tuning (SFT) method on the SST-2 dataset using a Llama2-7B model. The harmful ratio is varied from 0% to 40%, while the alignment and fine-tuning steps are kept constant at 500 each. The table compares the harmful score and fine-tuning accuracy of both methods under different levels of harmful data contamination.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_4_1.jpg", "caption": "Table 1: Performance under different harmful ratios. The fine-tuning dataset is SST-2 and the base model is a Llama2-7B. The switching step is K\u2081 = K2 = 500. SFT is standard supervised fine-tuning. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the performance of the Bi-State Optimization (BSO) method and the standard Supervised Fine-Tuning (SFT) method under different harmful ratios. The harmful ratio represents the percentage of harmful data mixed with the fine-tuning data.  The table shows the harmful score and finetune accuracy for both methods across various harmful ratios.  A lower harmful score is better, while a higher finetune accuracy is better.  The experiment uses the SST-2 dataset and Llama2-7B model, with the number of alignment and fine-tuning steps being equal and set at 500 for both BSO and SFT.", "section": "Bi-State optimization mitigates harmful fine-tuning"}, {"figure_path": "RPChapuXlC/tables/tables_4_2.jpg", "caption": "Table 2: Performance under different steps allocation on two states. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the results of the Bi-State Optimization (BSO) method with varying step allocations between the alignment and fine-tuning states.  It shows how the harmful score changes as the proportion of steps dedicated to the alignment state decreases. The results demonstrate a significant increase in the harmful score as fewer steps are allocated to the alignment state, highlighting the importance of sufficient alignment optimization. This indicates the convergence instability experienced when alignment steps invested are too few.", "section": "Asymmetrical computing degrades alignment performance"}, {"figure_path": "RPChapuXlC/tables/tables_5_1.jpg", "caption": "Table 1: Performance under different harmful ratios. The fine-tuning dataset is SST-2 and the base model is a Llama2-7B. The switching step is K\u2081 = K2 = 500. SFT is standard supervised fine-tuning. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the performance of the Bi-State Optimization (BSO) method compared to standard supervised fine-tuning (SFT) under different harmful ratios in the fine-tuning dataset.  It shows the harmful score and fine-tuning accuracy for both methods across various percentages of harmful data (p=0.05, 0.1, 0.2, 0.3, 0.4). The results demonstrate BSO's effectiveness in mitigating the harmful effects of the harmful data, while maintaining a comparable level of accuracy.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_6_1.jpg", "caption": "Table 1: Performance under different harmful ratios. The fine-tuning dataset is SST-2 and the base model is a Llama2-7B. The switching step is K\u2081 = K2 = 500. SFT is standard supervised fine-tuning. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the performance of the Bi-State Optimization (BSO) method compared to standard supervised fine-tuning (SFT) under various harmful data ratios (0%, 5%, 10%, 20%, 30%, 40%).  It shows the harmful score (lower is better) and finetune accuracy (higher is better) for both methods across different harmful data ratios. The experiment uses the SST-2 dataset and a Llama2-7B model.  The equal number of steps (500) are used for both alignment and fine-tuning states.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_6_2.jpg", "caption": "Table 3: Performance under different harmful ratio in the default setting.", "description": "This table presents the performance of different methods (NA-SFT, SFT, EWC, Vaccine-SFT, Vlguard, BSO, Lisa) under varying harmful ratios (clean, p=0.05, p=0.1, p=0.2, p=0.3) with a fixed sample number of 5000.  The results show the harmful score (lower is better) and finetune accuracy (higher is better) for each method and harmful ratio. This demonstrates the effectiveness of each method at mitigating the negative impact of harmful data on model performance.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_7_1.jpg", "caption": "Table 5: Performance of models trained on different models over GSM8K as fine-tuning task.", "description": "This table presents the results of harmful score and fine-tune accuracy using three different pre-trained language models (Opt-2.7B, Llama2-7B, Mistral-7B) on the GSM8K dataset.  It compares several methods: NA-SFT (no alignment, standard fine-tuning), SFT (standard fine-tuning with alignment), Vaccine-SFT (alignment stage modification with standard fine-tuning), Vlguard (alignment with modified fine-tuning), BSO (Bi-State Optimization), and Lisa (Lazy Safety Alignment).  The lower the harmful score, the better the model's performance against harmful data.  The higher the fine-tune accuracy, the better the model performs on the intended task. The average across all three models shows that Lisa shows the best results. ", "section": "5 Experiments"}, {"figure_path": "RPChapuXlC/tables/tables_7_2.jpg", "caption": "Table 6: Performance of models trained on different fine-tuning datasets with Mistral-7B.", "description": "This table presents the performance of different models (NA-SFT, SFT, Vaccine-SFT, Vlguard, BSO, Lisa) on four different downstream fine-tuning datasets (SST2, AGNEWS, GSM8K, AlpacaEval) using the Mistral-7B model.  The metrics shown are Harmful Score (HS) and Finetune Accuracy (FA). Lower HS indicates better performance against harmful fine-tuning attacks, while higher FA shows better accuracy on the main task.  The table aims to demonstrate the generalization performance of the proposed Lisa method across different datasets and its effectiveness compared to baseline methods in mitigating harmful fine-tuning.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_7_3.jpg", "caption": "Table 1: Performance under different harmful ratios. The fine-tuning dataset is SST-2 and the base model is a Llama2-7B. The switching step is K\u2081 = K2 = 500. SFT is standard supervised fine-tuning. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the performance of the Bi-State Optimization (BSO) method and the standard Supervised Fine-Tuning (SFT) method under various harmful ratios (0%, 5%, 10%, 20%, 30%, 40%). The harmful score and finetune accuracy are reported for each method and harmful ratio.  The results demonstrate the effectiveness of BSO in mitigating the negative impact of harmful data on model performance. The experiment used the SST-2 dataset for fine-tuning and a Llama2-7B model as the base model.  The number of optimization steps for both the alignment and fine-tuning stages was set to 500.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_7_4.jpg", "caption": "Table 7: System Evaluation.", "description": "This table presents the performance comparison of different methods (SFT, VlGuard, BSO, Lisa) in terms of clock time and memory usage.  It shows the computational cost and memory footprint associated with each approach during the experiments.  The values are likely measured in seconds for clock time and gigabytes for memory.", "section": "5 Experiments"}, {"figure_path": "RPChapuXlC/tables/tables_8_1.jpg", "caption": "Table 8: Under default setting, the impact of step allocation on two states.", "description": "This table shows the impact of different step allocations between alignment and fine-tuning states on the performance of the Lisa model. It demonstrates the trade-off between harmful score mitigation and fine-tuning accuracy, revealing that a balanced allocation leads to better results. The table also demonstrates that when too many steps are invested in finetuning, the model accuracy decreases while the harmful score increases. When too many steps are invested in alignment, the model achieves a low harmful score but low accuracy.", "section": "5.4 Hyper-parameters Analysis and Ablation Study"}, {"figure_path": "RPChapuXlC/tables/tables_8_2.jpg", "caption": "Table 9: The impact of intensity of proximal term.", "description": "This table shows the performance of Lisa model with different proximal penalty (intensity) values. The harmful score and finetune accuracy are reported for each intensity value. It demonstrates how the proximal term affects the trade-off between safety and accuracy. A larger intensity generally reduces the harmful score, but may slightly decrease the finetune accuracy. ", "section": "5.4 Hyper-parameters Analysis and Ablation Study"}, {"figure_path": "RPChapuXlC/tables/tables_8_3.jpg", "caption": "Table 1: Performance under different harmful ratios. The fine-tuning dataset is SST-2 and the base model is a Llama2-7B. The switching step is K\u2081 = K2 = 500. SFT is standard supervised fine-tuning. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the performance of the Bi-State Optimization (BSO) method compared to standard supervised fine-tuning (SFT) under different harmful ratios in the fine-tuning dataset.  It shows the harmful score and fine-tune accuracy for both methods across varying percentages of harmful data mixed with the clean data. The results demonstrate BSO's effectiveness in mitigating the negative impact of harmful data.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_9_1.jpg", "caption": "Table 3: Performance under different harmful ratio in the default setting.", "description": "This table presents the performance of different methods (NA-SFT, SFT, EWC, Vaccine-SFT, Vlguard, BSO, Lisa) under various harmful ratios (clean, p=0.05, p=0.1, p=0.2, p=0.3) in the default setting.  It shows the harmful score (lower is better) and finetune accuracy (higher is better) for each method and harmful ratio.  This helps assess the effectiveness of each method in mitigating the impact of harmful data during fine-tuning. The default setting includes using the Llama2-7B model and SST-2 dataset.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_9_2.jpg", "caption": "Table 12: Performance comparison when combined with data filtration (with BeaverTails moderation).", "description": "This table compares the performance of different methods when combined with data filtration using the BeaverTails moderation model.  It shows the harmful score and finetune accuracy for various poison ratios (p=0.1, p=0.2, p=0.5, p=0.8, p=1) for four methods: SFT (no filter), Lisa (no filter), Filter+SFT, and Filter+Lisa. The results demonstrate the effectiveness of combining data filtration with the Lisa method in reducing the harmful score while maintaining acceptable finetune accuracy.", "section": "5.5 Alternative Design"}, {"figure_path": "RPChapuXlC/tables/tables_18_1.jpg", "caption": "Table 13: Performance under different harmful ratio in the default setting.", "description": "This table shows how different mitigation strategies perform given different harmful ratios in the default setting.  The fine-tuning sample number is fixed at 5000.  It compares the performance of several methods (SFT, Vaccine-SFT, Lisa) across various harmful ratios (p=0.1, p=0.3, p=0.5, p=0.7, p=0.9, p=1), evaluating both harmful score and finetune accuracy. The table demonstrates the robustness of Lisa to different levels of harmful data contamination.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_19_1.jpg", "caption": "Table 14: Harmonic mean when combined with data filtration (with BeaverTails moderation).", "description": "This table presents the harmonic mean of harmful score and finetune accuracy for different methods under various harmful ratios (0.1, 0.2, 0.5, 0.8, 1), with and without data filtration.  The harmonic mean combines the two metrics to provide a more holistic evaluation of performance. It compares standard fine-tuning (SFT), Lisa (without filtration), Filter+SFT (data filtration followed by SFT), and Filter+Lisa (data filtration followed by Lisa). The results show that Filter+Lisa generally outperforms other methods, demonstrating the effectiveness of combining data filtration and the proximal term in Lisa.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_19_2.jpg", "caption": "Table 15: Performance evaluation with Bi-directional Anchoring (He et al., 2024).", "description": "This table presents the results of an experiment evaluating the robustness of different methods against a Bi-directional Anchoring attack.  The attack aims to select the most harmful data from a benign dataset to use for fine-tuning. The table shows the harmful score (a measure of the model's tendency to generate harmful outputs) before and after fine-tuning for three methods: SFT (standard supervised fine-tuning), Vaccine-SFT (an alignment-stage solution), and Lisa (the proposed method). The results demonstrate that Lisa exhibits more robustness compared to SFT and Vaccine-SFT against this specific attack, showing little change in its harmful score.", "section": "5.2 Main Results"}, {"figure_path": "RPChapuXlC/tables/tables_20_1.jpg", "caption": "Table 1: Performance under different harmful ratios. The fine-tuning dataset is SST-2 and the base model is a Llama2-7B. The switching step is K\u2081 = K2 = 500. SFT is standard supervised fine-tuning. Other settings are the default setting specified in Section 5.1.", "description": "This table presents the performance of the Bi-State Optimization (BSO) method compared to the standard Supervised Fine-Tuning (SFT) method under different harmful ratios (percentage of harmful data in the fine-tuning dataset).  It shows harmful scores and fine-tuning accuracy for both methods with varying harmful data proportions (0%, 5%, 10%, 20%, 30%, 40%). The goal is to demonstrate BSO's effectiveness in mitigating the negative impact of harmful data on model performance.", "section": "5.2 Main Results"}]