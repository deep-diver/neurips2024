[{"figure_path": "sy2SmstDOB/figures/figures_0_1.jpg", "caption": "Figure 1: Generated samples with 20 steps inference from stable-diffusion-xl-base-1.0 optimized by Unified Feedback Learning (UniFL). The last three images of the third row are generated with 4 steps.", "description": "This figure shows several images generated by the UniFL model.  The images demonstrate the model's ability to generate high-quality images in various styles.  The caption indicates that the first two rows of images were generated using 20 inference steps, while the last three images in the bottom row used only 4 steps, highlighting the model's efficiency.", "section": "Abstract"}, {"figure_path": "sy2SmstDOB/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of UniFL. We leverage a unified feedback learning framework to enhance the model performance and inference speed comprehensively. The training process of UniFL is divided into two stages, the first stage aims to improve visual quality and aesthetics, and the second stage speeds up model inference.", "description": "This figure shows the overview of the UniFL framework, which is divided into two stages. Stage 1 focuses on performance enhancement by improving visual quality and aesthetics using perceptual feedback learning and decoupled feedback learning. Stage 2 focuses on inference acceleration using adversarial feedback learning and decoupled feedback learning. The figure illustrates the flow of data and the interaction between different components of the framework.", "section": "4 UniFL: Unified Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_6_1.jpg", "caption": "Figure 2: Overview of UniFL. We leverage a unified feedback learning framework to enhance the model performance and inference speed comprehensively. The training process of UniFL is divided into two stages, the first stage aims to improve visual quality and aesthetics, and the second stage speeds up model inference.", "description": "This figure provides a visual overview of the UniFL framework, illustrating its two-stage training process.  The first stage focuses on enhancing visual quality and aesthetic appeal through perceptual and decoupled feedback learning. The second stage accelerates inference speed via adversarial feedback learning. The diagram shows the flow of data and the interactions between the different components of the model.", "section": "4 UniFL: Unified Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_6_2.jpg", "caption": "Figure 4: Qualitive comparison of the generation results of different methods based on SDXL.", "description": "This figure shows a qualitative comparison of image generation results from different methods, all based on the SDXL model.  The top row shows images generated from the prompt \"A high-contrast photo of a panda riding a horse. The panda is wearing a wizard hat and is reading a book.\"  The bottom row shows images generated from the prompt \"A bloody mary cocktail.\"  The columns show the results from SDXL base model, SDXL with DPO, SDXL with ImageReward, SDXL with UniFL, SDXL with LCM (4 steps), SDXL with Turbo (4 steps), and SDXL with UniFL (4 steps). This allows for visual comparison of the image quality and stylistic differences produced by each method and the impact of using fewer inference steps with UniFL.", "section": "5.2 Main Results"}, {"figure_path": "sy2SmstDOB/figures/figures_7_1.jpg", "caption": "Figure 5: (a) Illustration of PeFL with instance segmentation model (SOLO). (b) Visualization of the effect of PeFL on structure optimization.", "description": "This figure shows the results of using perceptual feedback learning (PeFL) with the SOLO instance segmentation model to improve the structure of generated images.  (a) illustrates the process of PeFL, showing the ground truth image, the ground truth segmentation mask, the predicted segmentation mask, and the generated image with improved structure. (b) visually demonstrates the positive effects of PeFL on structure optimization, highlighting improved structural accuracy.", "section": "4.1 Perceptual Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_7_2.jpg", "caption": "Figure 6: (a) Design components ablation of UniFL. (b) Visualization of decoupled and non-decoupled aesthetic feedback learning results.", "description": "This figure presents the ablation study of UniFL, showing the impact of each component on the model's performance.  (a) shows a bar chart illustrating the preference rates for UniFL with different components removed (adversarial feedback learning, perceptual feedback learning, decoupled feedback learning, and active prompt selection).  (b) provides a visual comparison of image generation results with and without decoupled aesthetic feedback learning, highlighting the improved aesthetic appeal achieved through decoupling.", "section": "5.3 Ablation Study"}, {"figure_path": "sy2SmstDOB/figures/figures_8_1.jpg", "caption": "Figure 7: Analysis on the ad. Left: reward scores distribution on 5k validation preference image pairs with our final chosen values highlighted. Right: ablation on the ad on color and detail reward.", "description": "This figure shows the distribution of reward scores for different aesthetic aspects (color, detail, layout, lighting) obtained from 5,000 validation preference image pairs.  The left side displays histograms showing the distribution of reward scores for each aspect, with the optimal hinge coefficient (ad) values highlighted. The right side shows an ablation study on the effect of varying the hinge coefficient (ad) for color and detail, demonstrating how different ad values influence the generated images. The images illustrate how the choice of ad impacts the color and detail aspects of the generation.", "section": "5.3 Ablation Study"}, {"figure_path": "sy2SmstDOB/figures/figures_8_2.jpg", "caption": "Figure 8: Incorporating the style and structure optimization objectives simultaneously with PeFL results in no effectiveness degeneration of each other.", "description": "This figure shows the results of applying style and structure optimization objectives simultaneously using the perceptual feedback learning (PeFL) method.  The left side demonstrates the results for the prompt \"a strong American cowboy with dark skin stands in front of a chair.\"  It illustrates that adding style optimization on top of structure optimization doesn't negatively impact the structure; instead, both are improved.  The right side shows the same for the prompt \"a baby Swan, graffiti.\"  This shows that PeFL can effectively incorporate multiple visual aspects and improve both simultaneously without negative interference.", "section": "4.2 Decoupled Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_9_1.jpg", "caption": "Figure 2: Overview of UniFL. We leverage a unified feedback learning framework to enhance the\nmodel performance and inference speed comprehensively. The training process of UniFL is divided\ninto two stages, the first stage aims to improve visual quality and aesthetics, and the second stage\nspeeds up model inference.", "description": "This figure shows the overall architecture of UniFL, a unified framework that enhances latent diffusion models.  It's divided into two stages: Stage 1 focuses on improving visual quality and aesthetics through perceptual and decoupled feedback learning. Stage 2 focuses on accelerating inference speed using adversarial feedback learning. The figure illustrates the flow of data and the interaction between different components within the framework.", "section": "4 UniFL: Unified Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_9_2.jpg", "caption": "Figure 10: Ablation on different inference steps of UniFL.", "description": "This figure shows the results of an ablation study on the number of inference steps used by UniFL.  The top row shows images generated using 25 steps with the SDXL model and then using UniFL with 8, 4, 2, and 1 steps, respectively. The same process is repeated for the LCM and SDXL-Turbo models in the subsequent rows. The goal is to demonstrate how the quality of the generated images changes as the number of steps decreases, highlighting the effectiveness of UniFL in generating high-quality images even with a significantly reduced number of steps.", "section": "5 Experiments"}, {"figure_path": "sy2SmstDOB/figures/figures_14_1.jpg", "caption": "Figure 11: Style optimization of PeFL on SD1.5 and SDXL.", "description": "This figure shows a comparison of style optimization using PeFL on two different diffusion models, Stable Diffusion 1.5 (SD1.5) and Stable Diffusion XL (SDXL).  The images demonstrate the improved style generation achieved by incorporating PeFL. Each row represents a different artistic style (impasto, oil painting, frescos, Victorian) applied to a prompt (family portrait, tree, girl, woman in a dress). The leftmost column shows the results from the base model, the middle shows results with pre-trained style, and the rightmost shows results using PeFL for style optimization.  The aim is to show that PeFL significantly enhances style consistency and accuracy compared to just using pre-trained styles.", "section": "A.1 Additional Examples of PeFL"}, {"figure_path": "sy2SmstDOB/figures/figures_14_2.jpg", "caption": "Figure 2: Overview of UniFL. We leverage a unified feedback learning framework to enhance the model performance and inference speed comprehensively. The training process of UniFL is divided into two stages, the first stage aims to improve visual quality and aesthetics, and the second stage speeds up model inference.", "description": "This figure provides a visual overview of the UniFL framework, highlighting its two-stage training process. Stage 1 focuses on enhancing visual quality and aesthetics using perceptual and decoupled feedback learning. Stage 2 concentrates on accelerating inference speed through adversarial feedback learning.  The diagram showcases the interplay between the latent diffusion model (LDM), various feedback modules (PeFL, Decoupled Feedback Learning, Adversarial Feedback Learning), and the optimization process, demonstrating a unified approach to improving various aspects of the LDM.", "section": "4 UniFL: Unified Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_15_1.jpg", "caption": "Figure 5: (a) Illustration of PeFL with instance segmentation model (SOLO). (b) Visualization of the effect of PeFL on structure optimization.", "description": "This figure demonstrates the Perceptual Feedback Learning (PeFL) method. Subfigure (a) shows the process of PeFL using the SOLO instance segmentation model. It takes an image and its corresponding ground truth segmentation mask as input. The model predicts the segmentation mask for the generated image and calculates the loss between the predicted mask and the ground truth mask. Subfigure (b) visualizes the results of PeFL on structure optimization, showing how it improves the structure of the generated image by comparing images generated with and without PeFL.  The examples show improvements in object structure details.", "section": "4.1 Perceptual Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_16_1.jpg", "caption": "Figure 3: User study about UniFL and other methods with 10 users on the generation of 500 prompts in generation quality (left) and inference acceleration (right).", "description": "This figure presents the results of a user study comparing UniFL with other methods in terms of generation quality and inference speed.  Ten users evaluated 500 image prompts generated by UniFL and competing methods. The left side shows the user preference for generation quality (good, same, bad), while the right side displays user preference for inference speed (fast, same, slow).  The bar charts visually represent the percentage of users who preferred each method in each category, providing a clear comparison of UniFL's performance against other models.", "section": "5 Experiments"}, {"figure_path": "sy2SmstDOB/figures/figures_16_2.jpg", "caption": "Figure 14: Generalization of PeFL with SOLO. The generation of the concepts not included in COCO (e.g., ostrich, robot, cones) is also improved after PeFL optimization.", "description": "This figure demonstrates the generalization ability of the Perceptual Feedback Learning (PeFL) method.  Even though PeFL uses a model trained on the COCO dataset (which has a limited set of concepts), the improved image generation is not limited to those concepts.  The examples shown illustrate that the method also improves generation of images with concepts not present in the COCO dataset, such as ostriches, robots, and traffic cones. This shows that the method is not overly reliant on the training data and can generalize to a broader range of subjects.", "section": "5.3 Ablation Study"}, {"figure_path": "sy2SmstDOB/figures/figures_17_1.jpg", "caption": "Figure 2: Overview of UniFL. We leverage a unified feedback learning framework to enhance the model performance and inference speed comprehensively. The training process of UniFL is divided into two stages, the first stage aims to improve visual quality and aesthetics, and the second stage speeds up model inference.", "description": "This figure shows the overall architecture of UniFL, a unified feedback learning framework for enhancing latent diffusion models.  UniFL is a two-stage process. Stage 1 focuses on improving visual quality and aesthetics using perceptual, decoupled aesthetic, and active prompt selection feedback learning. Stage 2 accelerates inference speed using adversarial feedback learning. The diagram illustrates the flow of data and the interaction between the different components of the model.", "section": "4 UniFL: Unified Feedback Learning"}, {"figure_path": "sy2SmstDOB/figures/figures_19_1.jpg", "caption": "Figure 1: Generated samples with 20 steps inference from stable-diffusion-xl-base-1.0 optimized by Unified Feedback Learning (UniFL). The last three images of the third row are generated with 4 steps.", "description": "This figure shows images generated using the UniFL method.  The top two rows demonstrate images generated with a 20-step inference process, while the bottom row highlights images generated with a faster 4-step process, showcasing the inference speedup achieved by UniFL.", "section": "Abstract"}, {"figure_path": "sy2SmstDOB/figures/figures_19_2.jpg", "caption": "Figure 17: Both SD1.5 and SDXL still keep high adaptation ability after being enhanced by the UniFL, even after being accelerated and inference with fewer denoising steps.", "description": "This figure shows the results of applying UniFL to both Stable Diffusion 1.5 and SDXL, demonstrating their ability to adapt to different styles even when using fewer denoising steps.  The images showcase the successful application of UniFL with various LoRA (Low-Rank Adaptation) models for different artistic styles like Anime Lineart, Pixel Art XL, and others, and also its integration with ControlNet for more sophisticated image manipulations.", "section": "5 Experiments"}, {"figure_path": "sy2SmstDOB/figures/figures_20_1.jpg", "caption": "Figure 4: Qualitive comparison of the generation results of different methods based on SDXL.", "description": "This figure shows a qualitative comparison of image generation results from different methods using the Stable Diffusion XL model.  Each row presents the same text prompt and shows the generated images from the base SDXL model and several other methods including DPO, ImageReward, LCM, SDXL Turbo, and UniFL. This allows for visual comparison of image quality and style across different models and inference steps.  The examples chosen highlight the strengths and weaknesses of each approach in terms of visual detail, coherence, and artistic style.", "section": "5.2 Main Results"}]