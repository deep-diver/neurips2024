{"references": [{"fullname_first_author": "Andrychowicz", "paper_title": "Hindsight experience replay", "publication_date": "2017-00-00", "reason": "This paper introduces the concept of hindsight experience replay, a core technique used in goal-conditioned reinforcement learning, which is the focus of the current paper."}, {"fullname_first_author": "Ecoffet", "paper_title": "Go-Explore: a new approach for hard-exploration problems", "publication_date": "2019-00-00", "reason": "This paper introduces the Go-Explore algorithm, a key method for exploration in reinforcement learning that the current paper builds upon and improves."}, {"fullname_first_author": "Hafner", "paper_title": "Dream to control: Learning behaviors by latent imagination", "publication_date": "2019-00-00", "reason": "This paper introduces the Dreamer model, a model-based reinforcement learning framework that is used as a foundation for the current paper's approach."}, {"fullname_first_author": "Pitis", "paper_title": "Maximum entropy gain exploration for long horizon multi-goal reinforcement learning", "publication_date": "2020-00-00", "reason": "This paper introduces MEGA, a key exploration algorithm which the current paper compares against and improves upon."}, {"fullname_first_author": "Hu", "paper_title": "Planning goals for exploration", "publication_date": "2023-00-00", "reason": "This paper introduces PEG, another recent and relevant exploration algorithm which is compared against the proposed algorithm in the current paper."}]}