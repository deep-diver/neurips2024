[{"type": "text", "text": "Solving Inverse Problems via Diffusion Optimal Control ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Henry Li \u2217 Yale University henry.li@yale.edu ", "page_idx": 0}, {"type": "text", "text": "Marcus Pereira Bosch Center for Artificial Intelligence marcus.pereira@us.bosch.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Existing approaches to diffusion-based inverse problem solvers frame the signal recovery task as a probabilistic sampling episode, where the solution is drawn from the desired posterior distribution. This framework suffers from several critical drawbacks, including the intractability of the conditional likelihood function, strict dependence on the score network approximation, and poor $\\mathbf{x}_{\\mathrm{0}}$ prediction quality. We demonstrate that these limitations can be sidestepped by reframing the generative process as a discrete optimal control episode. We derive a diffusion-based optimal controller inspired by the iterative Linear Quadratic Regulator (iLQR) algorithm. This framework is fully general and able to handle any differentiable forward measurement operator, including super-resolution, inpainting, Gaussian deblurring, nonlinear deblurring, and even highly nonlinear neural classifiers. Furthermore, we show that the idealized posterior sampling equation can be recovered as a special case of our algorithm. We then evaluate our method against a selection of neural inverse problem solvers, and establish a new baseline in image reconstruction with inverse problems. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Diffusion models Song and Ermon [2019], Ho et al. [2020] have been shown to be remarkably adept at conditional generation tasks Dhariwal and Nichol [2021], Ho and Salimans [2022], in part due to their iterative sampling algorithm, which allows the dynamics of an uncontrolled prior score function $\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x})$ to be directed towards an arbitrary posterior distribution by introducing an additive guidance term u. When this guidance term is the conditional score $\\nabla_{\\mathbf x}\\log p_{t}(\\mathbf y|\\mathbf x)$ , the resulting sample is provably drawn from the desired conditional distribution $p(\\mathbf{x}|\\mathbf{y})$ Song et al. [2020a]. ", "page_idx": 0}, {"type": "text", "text": "A central obstacle to this framework is the general difficulty of obtaining the conditional score function $\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{t})$ due to its dependence on the noisy diffusion variate $\\mathbf{x}_{t}$ rather than just the final sample $\\mathbf{x}_{\\mathrm{0}}$ Chung et al. [2023a]. In large-scale conditional generation tasks such as class- or text-conditional sampling the computational overhead of training a time-dependent conditional score function from scratch is deemed acceptable, and is indeed the approach taken by Rombach et al. [2022], Saharia et al. [2022], and many others. However, this solution is not acceptable in inverse problems where the goal is to design a generalized solver that will work in a zero-shot capacity for an arbitrary forward model. ", "page_idx": 0}, {"type": "text", "text": "This bottleneck has spawned a flurry of recent research dedicated to approximating the conditional score $\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{t}\\big)$ as a simple function of the noiseless likelihood $\\log p(\\mathbf{y}|\\mathbf{x}_{0})$ Choi et al. [2021], Chung et al. [2022], Rout et al. [2024], Chung et al. [2023a], Kawar et al. [2022], Chung et al. [2023b]. However, as we will demonstrate in this work, these approximations impose a significant cost to the performance of the resulting algorithm. ", "page_idx": 0}, {"type": "image", "img_path": "wqLC4G1GN3/tmp/4d649b3a225d42e2ee47525e2b37dc1d1a3aa7638836a78eb5cf37101018c22c.jpg", "img_caption": ["Figure 1: Conceptual illustration comparing a probabilistic posterior sampler to our proposed optimal control-based sampler. In a probabilistic sampler, the model relies on an approximation $\\tilde{\\mathbf{x}}_{0}\\approx\\mathbf{x}_{0}$ to guide each step (left). We are able to compute $\\mathbf{x}_{\\mathrm{0}}$ exactly on each step, resulting in much higher quality gradients $\\nabla\\log p(\\mathbf{y}|\\tilde{\\mathbf{x}}_{0})$ and an improved trajectory update (right). "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "To address these issues, we propose a novel framework built from optimal control theory where such approximations are no longer necessary. By framing the reverse diffusion process as an optimal control episode, we are able to detach the inverse problem solver from the strict requirements of the conditional sampling equation given by Song et al. [2020a], while still leveraging the exceptionally powerful prior of the unconditional diffusion process. Moreover, we find that the desired score function directly arises as the Jacobian of the value function. ", "page_idx": 1}, {"type": "text", "text": "We summarize our contributions as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We present diffusion optimal control, a framework for solving inverse problems via the lens of optimal control theory, using pretrained unconditional off-the-shelf diffusion models.   \n\u2022 We show that this perspective overcomes many core obstacles present in existing diffusionbased inverse problem solvers. In particular, the idealized posterior sampling score Song et al. [2020b] \u2014 approximated by existing methods \u2014 can be recovered exactly as a specific case of our method.   \n\u2022 We showcase the advantages of our model empirically with quantitative experiments and qualitative examples, and demonstrate state-of-the-art performance on the FFHQ $256\\times256$ dataset. ", "page_idx": 1}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Notation We use lowercase letters for denoting scalars $a\\in\\mathbb R$ , lowercase bold letters for vectors $\\mathbf{a}\\in\\mathbb{R}^{n}$ and uppercase bold letters for matrices $\\mathbf{A}\\,\\in\\,\\mathbb{R}^{m\\times n}$ . Subscripts indicate Jacobians and Hessians of scalar functions, e.g. $l_{\\mathbf{x}}\\,\\in\\,\\mathbb{R}^{n}$ and $l_{\\mathbf{x}\\mathbf{x}}\\,\\in\\,\\mathbb{R}^{n\\times n}$ for $l(\\mathbf{x})\\,:\\,\\mathbb{R}^{n}\\,\\rightarrow\\,\\mathbb{R}$ , respectively. We overload notation for time-dependent variables, where subscripts imply dependence rather than derivatives w.r.t. time, e.g., ${\\mathbf x}_{t}\\,=\\,{\\mathbf x}(t)$ . Furthermore, $V(\\mathbf{x}_{t})$ and $Q(\\mathbf{x}_{t},\\mathbf{u}_{t})$ are scalar functions despite being uppercase, in line with existing optimal control literature Betts [1998]. ", "page_idx": 1}, {"type": "text", "text": "2.1 Diffusion Models ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The diffusion modeling literature uses the following reverse-time It\u00f6 SDE to generate samples Song et al. [2020b], ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}_{t}=\\big[\\mathbf{f}(\\mathbf{x}_{t})-g(t)^{2}\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{x}_{t})\\big]\\mathrm{d}t+g(t)\\mathrm{d}\\mathbf{w}_{t},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\mathbf{x}_{t}\\in\\mathbb{R}^{n}$ is the state vector, $\\mathbf{f}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{n}$ and $g:\\mathbb{R}\\rightarrow\\mathbb{R}$ are drift and diffusion terms that can take different functional forms (e.g., Variance-Preserving SDEs (VPSDEs) and Variance-Exploding SDEs (VESDEs) in Song et al. [2020b]), $\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{x}_{t})$ is the score-function and $\\mathbf{w}_{t}\\,\\in\\,\\mathbb{R}^{n}$ is a vector of mutually independent Brownian motions. The above SDE has an associated ODE called the ", "page_idx": 1}, {"type": "image", "img_path": "wqLC4G1GN3/tmp/a008c94ca3d52fcb2586b0c92a2914757f0f300656633edfe9ef4f8a1fb54538.jpg", "img_caption": ["Figure 2: Predicted $\\mathbf{x}_{\\mathrm{0}}$ used in a probabilistic framework (above) compared to ours (below) for a general diffusion trajectory. The full forward rollout in our proposed framework allows for the predicted $\\mathbf{x}_{\\mathrm{0}}$ (and therefore $\\nabla_{\\mathbf{x}_{t}}\\log p(\\mathbf{y}|\\mathbf{x}_{0}))$ ) to be efficiently computed for all $t=0,\\dots,T$ . "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "probability-flow (PF) ODE given by ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}_{t}=\\mathrm{d}\\mathbf{x}_{t}+\\big[\\mathbf{f}(\\mathbf{x}_{t})-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{x}_{t})\\big]\\mathrm{d}t,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with the same marginals $p_{t}(\\mathbf{x}_{t})$ as the SDE, which allow for likelihood computation [Song et al., 2020b, Li et al., 2024]. All practical implementations of diffusion samplers require a timediscretization of the PF-ODE. One such discretization is the well-known Euler-discretization which gives, ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t-1}=\\mathbf{x}_{t}-\\left[\\mathbf{f}(\\mathbf{x}_{t})-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}_{t})\\right]\\Delta t\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where, $\\Delta t$ is the length of the discretization interval and we have reversed the time evolution by changing the sign of the drift. We are not restricted to only using the Euler-discretization and any high-order discretization techniques can also be employed. More concisely, we have, ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t-1}=\\mathbf{h}(\\mathbf{x}_{t}),\\;\\;\\mathrm{where}\\;\\mathbf{h}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{n}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "which describes the general non-linear dynamics of the corresponding discrete-time diffusion sampler. ", "page_idx": 2}, {"type": "text", "text": "2.2 Posterior Sampling for Inverse Problems ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Inverse problems are a general class of problems where an unknown signal is reconstructed from observations obtained by a forward measurement process Ongie et al. [2020]. The forward process is usually lossy, resulting in an ill-posed signal recovery task where a unique solution does not exist. The forward model can generally be written as ", "page_idx": 2}, {"type": "equation", "text": "$$\ny=A(\\mathbf{x}_{0})+\\eta,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathcal{A}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{d}$ is the forward operator, $y\\in\\mathbb{R}^{d}$ the measured signal, $\\mathbf{x}_{0}\\in\\mathbb{R}^{n}$ the unknown signal to be recovered, and $\\boldsymbol\\eta\\sim\\mathcal{N}(0,\\bar{\\sigma}\\mathbf{I}_{d})$ the noise (with variance $\\sigma^{2}$ ) in the measurement process. Given the forward model Eq. (5) and a measurement $\\mathbf{y}$ , sampling from the posterior distribution $p_{\\theta}(\\mathbf{x}|\\mathbf{y})$ can then be performed by solving the corresponding conditional It\u00f6 SDE ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}=[\\mathbf{f}(\\mathbf{x})-g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}|\\mathbf{y})]\\mathrm{d}t+g(t)\\mathrm{d}\\mathbf{w},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where, invoking Bayes rule, ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf x}\\log p_{t}(\\mathbf x|\\mathbf y)=\\nabla_{\\mathbf x}\\log p_{t}(\\mathbf x)+\\nabla_{\\mathbf x}\\log p_{t}(\\mathbf y|\\mathbf x).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "As with the unconditional dynamics, Eq. (6) has a corresponding ODE ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}=[\\mathbf{f}(\\mathbf{x})-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}|\\mathbf{y})]\\mathrm{d}t,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "which has an approximate solution obtained by the Euler discretization ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t-1}=\\mathbf{x}_{t}+[f(\\mathbf{x}_{t})-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{x}_{t}|\\mathbf{y})]\\Delta t.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "image", "img_path": "wqLC4G1GN3/tmp/238babd86f2bc640220868fc1e783bd15693d527f6bd03dcd6833db9e9278003.jpg", "img_caption": ["Figure 3: Inverse problem solution as a function of total diffusion timesteps $T$ for the $4\\times$ super-resolution task. Compared to DPS (top row), our method (bottom row) produces solutions that are higher quality, in greater agreement with the inverse problem contraint $\\mathbf{\\mathcal{A}}\\mathbf{x}=\\mathbf{y}$ , and more stable across $T$ . "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "2.3 Optimal Control ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Optimal control is the structured and principled approach to the guidance of dynamical systems over time. Many methods have been developed in the optimal control literature and are popularly referred to as trajectory optimization algorithms Betts [1998]. Perhaps the most well-known is the Iterative Linear Quadratic Regulator (iLQR) algorithm which uses a first-order approximation of the dynamics and second-order approximations of the value-function Li and Todorov [2004]. ", "page_idx": 3}, {"type": "text", "text": "Formally, let us define an arbitrary user-defined global cost function ", "page_idx": 3}, {"type": "equation", "text": "$$\nJ_{T}=\\sum_{t=T}^{1}\\ell_{t}(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})+\\ell_{0}(\\mathbf{x}_{0}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "composed of a sum over scalar-valued running and terminal cost functions $\\ell_{t}$ and $\\ell_{0}$ . Optimal control theory dictates that the value function $V(\\mathbf{x}_{t},\\,t):=\\operatorname*{min}_{\\{\\mathbf{u}_{n}\\}_{n=t}^{n=1}}J_{t}$ satisfies the following recursive relation also known as Bellman\u2019s Principle of Optimality ", "page_idx": 3}, {"type": "equation", "text": "$$\nV(\\mathbf x_{t},\\,t)=\\operatorname*{min}_{\\mathbf u_{t}}\\Big[\\ell_{t}(\\mathbf x_{t},\\,{\\mathbf u}_{t})+V({\\mathbf x}_{t-1},\\,t-1)\\Big].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The iLQR algorithm centers around approximating the state-action value function, ", "page_idx": 3}, {"type": "equation", "text": "$$\nQ(\\mathbf{x}_{t},\\,\\mathbf{u}_{t}):=\\ell_{t}(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})+V(\\mathbf{x}_{t-1},\\,t-1),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "from which the value function can be recovered as $\\begin{array}{r}{V(\\mathbf{x}_{t},\\,t)=\\operatorname*{min}_{\\mathbf{u}_{t}}Q(\\mathbf{x}_{t},\\,\\mathbf{u}_{t}).}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Then given a state transition function $\\mathbf x_{t}=\\mathbf h(\\mathbf x_{t+1},\\mathbf u_{t+1})$ where we crucially note that we have defined time to flow backwards from $t=T,\\dots,0$ , the iLQR algorithm has feedforward and feedback gains ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\bf k}=-Q_{{\\bf u}{\\bf u}}^{-1}Q_{{\\bf u}}\\quad\\quad\\mathrm{and}\\quad\\quad{\\bf K}=-Q_{{\\bf u}{\\bf u}}^{-1}Q_{{\\bf u x}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The update equations can be written as ", "page_idx": 3}, {"type": "equation", "text": "$$\nV_{\\mathbf{x}}=Q_{\\mathbf{x}}-\\mathbf{K}^{T}Q_{\\mathbf{uu}}\\mathbf{k}\\qquad{\\mathrm{and}}\\qquad V_{\\mathbf{xx}}=Q_{\\mathbf{xx}}-\\mathbf{K}^{T}Q_{\\mathbf{uu}}\\mathbf{K}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Given the feedforward and feedback gains $\\{(\\mathbf{K}_{t},\\mathbf{k}_{t})\\}_{t=0}^{T}$ and $\\bar{\\bf x}_{0}:={\\bf x}_{0}$ , we can recursively obtain the locally optimal control at time $t$ as a function of the present states $\\mathbf{x}_{t}$ and controls $\\mathbf{u}_{t}$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\mathbf{x}}_{t}=\\mathbf{h}(\\bar{\\mathbf{x}}_{t+1},\\mathbf{u}_{t+1}^{*}),}\\\\ &{\\mathbf{u}_{t}^{*}=\\mathbf{u}_{t}+\\lambda\\mathbf{k}+\\mathbf{K}(\\bar{\\mathbf{x}}_{t}-\\mathbf{x}_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "For a more detailed treatment of iLQR as well as a derivation of the equations, please see Appendix B. ", "page_idx": 3}, {"type": "text", "text": "3 Diffusion Optimal Control ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We motivate our framework by observing that the reverse diffusion process Eq. (1) is an uncontrolled non-linear dynamical system that evolves from some initial state (at time $t=T$ ) to some terminal state (at time $t=0$ ). By injecting control vectors $\\mathbf{u}_{t}$ into this system we can influence its behavior and hence its terminal state (i.e., the generated data) to sample from a desired $p(\\mathbf{x}|\\mathbf{y})$ . There are two obvious ways to inject control into this process: ", "page_idx": 3}, {"type": "text", "text": "Algorithm 1 Diffusion Optimal Control ", "page_idx": 4}, {"type": "text", "text": "Input: $\\lambda,T,\\mathbf{y},\\mathbf{x}_{T}$   \nInitialize $\\mathbf{u}_{t},\\mathbf{k}_{t},\\mathbf{K}_{t}$ as 0 for $t=1\\ldots T$ , $\\{\\mathbf{x}_{t}^{\\prime}\\}_{t=0}^{T}$ as uncontrolled dynamics   \nfor iter $=1$ to num_iters do $V_{\\mathbf{x}},V_{\\mathbf{x}\\mathbf{x}}\\gets\\nabla_{\\mathbf{x}_{0}}\\log p(\\mathbf{y}|\\mathbf{x}_{0}),\\nabla_{\\mathbf{x}_{0}}^{2}\\log p(\\mathbf{y}|\\mathbf{x}_{0})$ \u25b7Initialize derivatives of $V(\\mathbf{x}_{t},t)$ for $t=1$ to $T$ do Compute $\\mathbf{k}_{t},\\mathbf{K}_{t},V_{\\mathbf{x}},V_{\\mathbf{xx}}$ \u25b7See Eqs. (13), (14) end for for $t=T$ to 1 do $\\begin{array}{r l}&{\\mathbf{x}_{t-1}\\leftarrow h(\\mathbf{x}_{t},\\lambda\\mathbf{k}_{t}+\\mathbf{K}_{t}(\\mathbf{x}_{t}-\\mathbf{x}_{t}^{\\prime}))}\\\\ &{\\mathbf{x}_{t}^{\\prime}\\leftarrow\\mathbf{x}_{t}}\\end{array}$ \u25b7Update $\\mathbf{x}_{t-1}$ with new $\\mathbf{u}_{t}$ end for   \nend for ", "page_idx": 4}, {"type": "text", "text": "1. In input perturbation control, we apply the $\\mathbf{u}_{t}$ before the diffusion step: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t-1}=(\\mathbf{x}_{t}+\\mathbf{u}_{t})-\\left[\\mathbf{f}(\\mathbf{x}_{t}+\\mathbf{u}_{t})-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}_{t}+\\mathbf{u}_{t})\\right]\\Delta t.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "2. In output perturbation control, $\\mathbf{u}_{t}$ is applied after the diffusion step: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t-1}=\\mathbf{x}_{t}-\\big[\\mathbf{f}(\\mathbf{x}_{t})-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}_{t})\\big]\\Delta t+\\mathbf{u}_{t}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Observe that iLQR is formulated for general discrete-time dynamic processes. When applied specifically to the reverse diffusion dynamics of diffusion models, we are able to make several simplifications. First, we assume that we do not have access to any guidance except at time $t=0$ \u2014 i.e., $\\boldsymbol{\\ell}_{t}(\\mathbf{x}_{t},\\mathbf{u}_{t})$ does not depend on $\\mathbf{x}_{t}$ . ", "page_idx": 4}, {"type": "text", "text": "In the case of input perturbation control, we observe from Eq. (17) that $\\mathbf{h}_{\\mathbf{x}}=\\mathbf{h}_{\\mathbf{u}}$ , whereas output perturbation control implies that $\\mathbf{h}_{\\mathbf{u}}=\\mathbf{I}$ , resulting in the left and right equations, respectively: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{Q_{\\mathbf{x}}=\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime}}&{\\quad}&{Q_{\\mathbf{x}}=\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime}}\\\\ {Q_{\\mathbf{u}}=\\ell_{\\mathbf{u}}+\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime}}&{\\quad}&{Q_{\\mathbf{u}}=\\ell_{\\mathbf{u}}+V_{\\mathbf{x}}^{\\prime}}\\\\ {Q_{\\mathbf{xx}}=\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}}&{\\quad}&{Q_{\\mathbf{xx}}=\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}}\\\\ {Q_{\\mathbf{ux}}=Q_{\\mathbf{xu}}=\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}}&{\\quad}&{Q_{\\mathbf{ux}}=Q_{\\mathbf{xu}}^{T}=V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}}\\\\ {Q_{\\mathbf{uu}}=\\ell_{\\mathbf{uu}}+\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}}&{\\quad}&{Q_{\\mathbf{uu}}=\\ell_{\\mathbf{uu}}+V_{\\mathbf{xx}}^{\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The derivatives of $V$ can then be backpropagated using the following equations: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathbf x}=Q_{\\mathbf x}-\\mathbf K^{T}Q_{\\mathbf u\\mathbf u}\\mathbf k=Q_{\\mathbf x\\mathbf x}-\\mathbf K^{T}Q_{\\mathbf u\\mathbf u}\\mathbf K}\\\\ &{\\qquad=Q_{\\mathbf x}+Q_{\\mathbf u\\mathbf x}^{T}Q_{\\mathbf u\\mathbf u}^{-1}Q_{\\mathbf u}}\\\\ &{V_{\\mathbf x\\mathbf x}=Q_{\\mathbf x\\mathbf x}-\\mathbf K^{T}Q_{\\mathbf u\\mathbf u}\\mathbf K}\\\\ &{\\qquad=Q_{\\mathbf x\\mathbf x}-Q_{\\mathbf u\\mathbf x}^{T}Q_{\\mathbf u\\mathbf u}^{-1}Q_{\\mathbf u\\mathbf x}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In high dimensional systems such as Eq. 3, matrices may be singular. Therefore, a Tikhonov regularized variant of iLQR is often employed, where matrix inverses are regularized by a diagonal matrix $\\alpha\\mathbf{I}$ Tassa et al. [2014]. ", "page_idx": 4}, {"type": "text", "text": "3.1 High Dimensional Control ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Compared to the dynamics in traditional application areas of optimal control, those we consider in Eqs. (17- 18) are much higher dimensional in the state $\\mathbf{x}$ and control u variates. Therefore, iLQR faces several unique computational bottlenecks when applied to such control problems. ", "page_idx": 4}, {"type": "text", "text": "In particular, the Jacobian matrices $\\mathbf{h}_{\\mathbf{x}},\\mathbf{h}_{\\mathbf{u}}$ and the second-order derivative matrices $V_{\\mathbf{x}\\mathbf{x}},Q_{\\mathbf{x}\\mathbf{x}},Q_{\\mathbf{u}\\mathbf{x}},Q_{\\mathbf{x}\\mathbf{u}}$ , and $Q_{\\bf u u}$ are particularly expensive to compute, store, and perform downstream operations against. For example, in a three-channel $256\\times256$ image, these matrices naively contain $(256\\times256^{-}\\times3)^{2}\\approx39B$ parameters. ", "page_idx": 4}, {"type": "image", "img_path": "wqLC4G1GN3/tmp/48933be56127426a44019c8b92eba27c80a189a99aa867643a8a26c46596283a.jpg", "img_caption": ["Figure 4: Examples from inverse problem tasks on FFHQ $256\\times256$ . From left to right each column contains ground truth, measurement, Diffusion Posterior Sampling (DPS), and ours. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "In Appendix D.1 we propose and analyze three modifications to the standard iLQR algorithm: randomized low rank approximations, matrix-free evaluations, and action updates via an adaptive optimizer, that significantly reduce runtime and memory constraints while introducing minimal deterioration to performance on inverse problem solving tasks. ", "page_idx": 5}, {"type": "text", "text": "4 Improved Posterior Sampling ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We demonstrate that our optimal control-based sampler overcomes several practical obstacles that plague existing diffusion-based methods for inverse problem solvers. ", "page_idx": 5}, {"type": "text", "text": "Brittleness to Discretization In a probabilistic framework, solutions to inverse problems incur a discretization error from the numerical solution of Eq. (8) that decays poorly with the total diffusion steps $T$ of the diffusion process. While much research has been conducted on the acceleration of unconditional diffusion processes Song et al. [2020a], Jolicoeur-Martineau et al. [2021], Karras et al. [2022], Meng et al. [2023], sample quality appears to decay much more aggressively in diffusion-based inverse problem solvers (Figure 3). ", "page_idx": 5}, {"type": "text", "text": "We theorize that this is due to two reasons: 1) the posterior sampler Eq. (9) is only correct in the limit of infinitely small time steps, and 2) the quality of the approximated conditional score term $\\nabla_{\\mathbf{x}}\\log p(\\mathbf{y}|\\mathbf{x}_{t})$ decays quickly with time (Figure 2), and so fewer timesteps lead to fewer chances at low $t$ to correct errors made at high $t$ . On the other hand, since optimal control directly casts the discretized process as an end-to-end control episode, it produces a feasible solution for any number of discretization steps $T$ . ", "page_idx": 5}, {"type": "text", "text": "Intractability of $\\nabla_{{\\bf x}_{t}}\\log p({\\bf y}|{\\bf x}_{t})$ When the forward model $\\boldsymbol{\\mathcal{A}}$ is known and $\\eta$ comes from a simple distribution, the conditional likelihood $p(\\mathbf{y}|\\mathbf{x}_{t})$ can be derived in closed form for $t=0$ . On the other hand, the dependence of $y$ on $\\mathbf{x}_{t}$ for $t>0$ is generally not known without explicitly computing $\\mathbf{x}_{\\mathrm{0}}$ , which requires sampling from the diffusion process. Ultimately, obtaining the conditional score term $\\nabla_{{\\mathbf x}_{t}}\\log\\bar{p({\\mathbf y}|{\\mathbf x}_{t})}$ is a highly nontrivial task Song et al. [2020b]. ", "page_idx": 5}, {"type": "text", "text": "To sidestep this issue, many works Meng and Kabashima [2022], Song et al. [2022], Chung et al. [2023a] factorize this term as the integral ", "page_idx": 5}, {"type": "equation", "text": "$$\np(\\mathbf{y}\\vert\\mathbf{x}_{t})=\\int p(\\mathbf{y}\\vert\\mathbf{x}_{0})p(\\mathbf{x}_{0}\\vert\\mathbf{x}_{t})d\\mathbf{x}_{0}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and then apply a series of approximations to recover a computationally feasible estimate of the conditional score. First, the marginal $p(\\mathbf{x}_{0}|\\mathbf{x}_{t})$ is replaced by the marginal conditioned on $\\mathbf{x}_{\\mathrm{0}}$ , i.e. ", "page_idx": 5}, {"type": "text", "text": "$p(\\mathbf{x}_{0}|\\mathbf{x}_{t},\\mathbf{x}_{0})=\\mathcal{N}(\\mathbf{x}_{0},\\sigma^{2}\\mathbf{I})$ Kim and Ye [2021]. Next, the $\\mathbf{x}_{\\mathrm{0}}$ -centered marginal is replaced by the posterior mean $\\mathbb{E}[{\\bf x}_{0}|{\\bf x}_{t}]$ given by Tweedie\u2019s formula Efron [2011]. Finally, the true score is replaced by the learned score network. ", "page_idx": 6}, {"type": "text", "text": "While these approximations are necessary in a probabilistic framework, we show that they are not required in our method. Intuitively, this is because the linear quadratic regulator backpropagates the control cost $\\log p(\\mathbf{y}|\\mathbf{x})$ through a forward trajectory rollout, which naturally computes the true conditional score at each time $t$ . Moreover, our model always estimates $\\mathbf{x}_{0}|\\mathbf{x}_{t}$ exactly (up to the discretization error induced by solving Eq. 3), rather than forming an approximation $\\hat{\\mathbf{x}}_{0}\\approx\\mathbf{x}_{0}$ (Figure 2). We formalize this observation with the following statement. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.1. Let Eq. 3 be the discretized sampling equation for the diffusion model with output perturbation mode control (Eq. 18). Moreover, let the terminal cost ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\ell_{0}(\\mathbf{x}_{0})=-\\log p(\\mathbf{y}|\\mathbf{x}_{0})\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "be twice-differentiable and the running costs ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\ell_{t}(\\mathbf{x}_{t},\\mathbf{u}_{t})=0.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Then the iterative linear quadratic regulator with Tikhonov regularizer \u03b1 produces the control ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t}=\\alpha\\nabla_{\\mathbf{x}_{t}}\\log p(\\mathbf{y}|\\mathbf{x}_{0}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In other words, by framing the inverse problem as an unconditional diffusion process with controls $\\mathbf{u}_{t}$ , our proposed method produces controls that coincide precisely with the desired conditional scores $\\nabla_{\\mathbf{x}_{t}}\\log\\bar{p}(\\mathbf{\\bar{y}}|\\mathbf{x}_{0})$ . ", "page_idx": 6}, {"type": "text", "text": "Let us further assume that $\\log p(\\mathbf{y}|\\mathbf{x}_{t})=\\log p(\\mathbf{y}|\\mathbf{x}_{0})$ , i.e., $\\mathbf{x}_{t}$ contains no additional information about $y$ than $\\mathbf{x}_{\\mathrm{0}}$ . This assumption results in the posterior mean approximation in Chung et al. [2023a] under stochastic dynamics (Eq. 1), where we additionally obtain exact computation of $\\mathbf{x}_{\\mathrm{0}}$ , rather than $\\hat{\\mathbf{x}}_{0}\\approx\\mathbf{x}_{0}$ via Tweedie\u2019s formula Kim and Ye [2021]. Under the deterministic ODE dynamics (Eq. 2), we recover the true posterior sampler under appropriate choice of Tikhonov regularization constant \u03b1. ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.2. Under the deterministic sampler with output perturbation mode control, $\\begin{array}{r}{\\alpha=\\frac{1}{g(t)^{2}\\Delta t}}\\end{array}$ recovers posterior sampling (Eq. 9). ", "page_idx": 6}, {"type": "text", "text": "We demonstrate a similar result with input mode perturbation. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.3. Let Eq. 3 be the discretized sampling equation for the diffusion model with input perturbation mode control (Eq. 17). Moreover, let ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\ell_{0}(\\mathbf{x}_{0})=\\log p(\\mathbf{y}|\\mathbf{x}_{0}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "and the running costs ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\ell_{t}(\\mathbf{x}_{t},\\mathbf{u}_{t})=0.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Then the iterative linear quadratic regulator with Tikhonov regularizer $\\begin{array}{r}{\\alpha=\\frac{1}{g(t)^{2}\\Delta t}}\\end{array}$ g(t)12\u2206t produces the dynamical sytem ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde\\mathbf{x}_{t}=\\widetilde\\mathbf{x}_{t}+[f(\\widetilde\\mathbf{x}_{t})-\\displaystyle\\frac{1}{2}g(t)^{2}(\\nabla_{\\mathbf{x}}\\log p_{t}(\\widetilde\\mathbf{x}_{t})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{t}))]\\Delta t,}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\widetilde{\\mathbf{x}}_{t}:=\\mathbf{x}_{t}+\\mathbf{u}_{t}$ . ", "page_idx": 6}, {"type": "text", "text": "Observe that Eq. (32) can be understood as a predictor-corrector sampling method, where the predictor produces an unconditional reverse diffusion update and the corrector produces a conditional correction step on the intermediary variable $\\mathbf{x}_{t}=\\tilde{\\mathbf{x}}_{t}-\\mathbf{u}_{t}$ . ", "page_idx": 6}, {"type": "text", "text": "Ultimately, these results demonstrate that our proposed method is able to recover the idealized sampling procedure under mild assumptions on the diffusion optimal control algorithm. ", "page_idx": 6}, {"type": "table", "img_path": "wqLC4G1GN3/tmp/b4edf1e3eae0969340b5bfe8f5379a3f0a31ffac492d5395bebe1f7286842751.jpg", "table_caption": [], "table_footnote": ["Table 1: Quantitative evaluation (FID, LPIPS) of model performance on inverse problems on the FFHQ 256x256-1K dataset. "], "page_idx": 7}, {"type": "text", "text": "Dependence on the Approximate Score While our theoretical results require that the learned score function $s_{\\theta}(\\mathbf{x}_{t},t)$ approximates the true data score $\\log p_{t}(\\mathbf{x}_{t},t)$ , we emphasize that the performance of our method does not necessitate this condition. In fact, we find that reconstruction performance is theoretically and empirically robust to the accuracy of the approximated prior score $s_{\\theta}(\\mathbf{x}_{t},t)\\approx$ $\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{x}_{t})$ or conditional score $\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{0})\\approx\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{t})$ terms. This is because the optimal control-based solution is formulated for the optimization of generalized dynamical systems, and thus agnostic to the diffusion sampling process. ", "page_idx": 7}, {"type": "text", "text": "Certainly, improved approximation of the score terms result in a better-informed prior and usually higher sample quality. However, we demonstrate that our sampler produces remarkably reasonable solutions even in the case of randomly initialized diffusion models. Conversely, probabilistic posterior samplers can only sample from $p(\\mathbf{y}|\\mathbf{x}_{0})$ when the terms composing the posterior sampling equation (Eq. (8)) are well approximated (Figure 6). Modeling errors can occur even in foundation models. For example, this scenario may arise in models trained on regions where there are underrepresented examples in the data. When these arise from existing social or ethical biases, they can further perpetuate or amplify biases to the resulting model if left unaddressedBolukbasi et al. [2016], Birhane et al. [2021], Srivastava et al. [2022]. ", "page_idx": 7}, {"type": "text", "text": "There exist several methods that seek to alleviate the errors incurred by Tweedie\u2019s formula (being a mean approximation of the diffusion process), including Song et al. [2024] which imposes a hard data consistency optimization loop at various points in the diffusion process, and Rout et al. [2023] which includes a stochastic averaging loop in each step of the diffusion process. However, these methods still rely on Tweedie\u2019s formula for the error reduction scheme, which assumes access to a ground truth score function. Ultimately, the aforementioned problems in the present section are exacerbated in existing samplers, and relatively less consequential in our solver. ", "page_idx": 7}, {"type": "text", "text": "5 Related Work ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The recent success of diffusion models in image generation Song and Ermon [2019], Ho et al. [2020], Song et al. [2020b], Rombach et al. [2022] has spawned a surge of research in deep learning-based solvers to inverse problems. Song et al. [2020b] demonstrated a strategy for provably sampling from the solution set $p(\\mathbf{x}|\\mathbf{y})$ of a general inverse problem $\\mathbf{y}=A(\\mathbf{x})$ using only an unconditional prior score model $\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x})$ and a forward probabilistic model lo $\\operatorname{g}p(\\mathbf{y}|\\mathbf{x}_{t})$ . However, a crucial problem arises in the intractability of forward probabilistic model, which depends on the noisy $\\mathbf{x}_{t}$ rather than the final $\\mathbf{x}_{\\mathrm{0}}$ . This has resulted in a series of approximation algorithms Choi et al. [2021], Kawar et al. [2022], Chung et al. [2022, 2023a,b], Kawar et al. [2023] for the true conditional diffusion dynamics. ", "page_idx": 7}, {"type": "text", "text": "Topics in control theory have been applied to deep learning Liu et al. [2020], Pereira et al. [2020] as well as diffusion modeling Berner et al. [2022]. Optimal control can also be connected to diffusion processes via forward-backward SDEs Chen et al. [2021]. However, these ideas have not been applied to guided conditional diffusion processes solely at inference time, nor for guided conditional sampling. Our proposed optimal control-based algorithm is, to our knowledge, the first such framework for deep inverse problem solvers. ", "page_idx": 7}, {"type": "image", "img_path": "wqLC4G1GN3/tmp/878b0b77ebf7ecec55b28c4fa18bf9ce665c6226fffe6d6b6e0958dd99fd5841.jpg", "img_caption": ["Figure 5: Examples from the classconditional inverse problem. DPS (left) is compared against ours (right). Each row is a different target MNIST class. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "wqLC4G1GN3/tmp/dbb5b5936edabfa7d17799e34398c16cb0248b466fee5b98d33dc420f1d87106.jpg", "img_caption": ["Figure 6: Robustness to approximation quality of the score function. We consider the $4\\times$ super-resolution task with a randomly initialized diffusion model. Since the reverse diffusion process is no longer well approximated, DPS cannot produce a feasible solution, while our method still can. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Following previous work Chung et al. [2023a], Meng and Kabashima [2022], Kawar et al. [2022], we consider five inverse problems. 1) In $4\\times$ image super-resolution, we use the bicubic downsampling operator. 2) In randomized inpainting, we uniformly omit $92\\%$ of all pixels (across all channels). 3) In box inpainting, we mask out a $128\\times128$ block uniformly sampled from a 16 pixel margin from each side of the image, as in Chung et al. [2022]. 4) In Gaussian deblurring, we use a kernel of size $61\\times61$ and standard deviation 3.0. In motion deblurring, we generate images according to a library2of point spread functions with kernel size $61\\times61$ and intensity 0.5. Following the experimental design in Chung et al. [2023a], we apply Gaussian noise with standard deviation 0.05 to all measurements of the forward model. ", "page_idx": 8}, {"type": "text", "text": "We compare against a generalized diffusion inverse sampler (Score-SDE) proposed in Song et al. [2020b], Diffusion Posterior Sampling (DPS) Chung et al. [2023a], Denoising Diffusion Restoration Models Kawar et al. [2022], Manifold Constrained Gradients (MCG) Chung et al. [2022], as well as two recent latent diffusion-based methods Fabian et al. [2023] (Flash-Diffusion3) and Rout et al. [2024] (PSLD). For non-diffusion baselines, we compare against Plug-and-Play Alternating Direction Method of Multipliers (PnP-ADMM) with neural proximal maps Chan et al. [2016], Zhang et al. [2017], and a total-variation based alternating direction method of multipliers (TV-ADMM) baseline proposed in Chung et al. [2023a]. ", "page_idx": 8}, {"type": "text", "text": "We validate our results on the high resolution human face dataset FFHQ $256\\times256$ Karras et al. [2019]. Several methods are model agnostic (DPS, DDRM, MCG, and thus evaluated with the same pre-trained diffusion models. To fairly compare between all models, all methods use the model weights from Chung et al. [2023a], which are trained on 49K FFHQ images, with 1K images left as a held-out set for evaluation. We compare our algorithm against competing frameworks on these last 1K images. We report our results on FFHQ $256\\times256$ in Table 1, and demonstrate improvements on all tasks against previous methods. Finally, we demonstrate the performance of our algorithm on the nonlinear inverse problem of class-conditional generation. Namely, let $\\mathbf{\\mathcal{A}(x)}=\\mathsf{c l a s s i f i e r}(\\mathbf{x})$ and $p(\\mathbf{y}\\vert\\mathbf{x})$ be its associated probability. We compare our method to DPS on the inverse task of generating an MNIST digit given a label y. Compared to images generated by DPS, images from our method exhibit more pronounced class alignment and higher overall sample quality (Figure 5). ", "page_idx": 8}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper we presented a novel perspective on tackling inverse problems with diffusion models \u2013 framing the discretized reverse diffusion process as a discrete time optimal control episode. We demonstrate that this framework alleviates several core problems in probabilistic solvers: its dependence on the approximation quality of the underlying terms in the diffusion process, its sensitivity to the temporal discretization scheme, its inherent inaccuracy due to the intractability of the conditional score function. We also show that the diffusion posterior sampler can be seen as a specific case of our optimal control-based sampler. Finally, leveraging the improvements granted by our solver, we validate the performance of our algorithm on several inverse problem tasks across several datasets, and demonstrate highly competitive results. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Julius Berner, Lorenz Richter, and Karen Ullrich. An optimal control perspective on diffusion-based generative modeling. arXiv preprint arXiv:2211.01364, 2022.   \nJohn T Betts. Survey of numerical methods for trajectory optimization. Journal of guidance, control, and dynamics, 21(2):193\u2013207, 1998.   \nAbeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. Multimodal datasets: misogyny, pornography, and malignant stereotypes. arXiv preprint arXiv:2110.01963, 2021.   \nTolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. Man is to computer programmer as woman is to homemaker? debiasing word embeddings. Advances in neural information processing systems, 29, 2016.   \nStanley H Chan, Xiran Wang, and Omar A Elgendy. Plug-and-play admm for image restoration: Fixed-point convergence and applications. IEEE Transactions on Computational Imaging, 3(1): 84\u201398, 2016.   \nTianrong Chen, Guan-Horng Liu, and Evangelos A Theodorou. Likelihood training of schr\\\" odinger bridge using forward-backward sdes theory. arXiv preprint arXiv:2110.11291, 2021.   \nJooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon. Ilvr: Conditioning method for denoising diffusion probabilistic models. arXiv preprint arXiv:2108.02938, 2021.   \nHyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving diffusion models for inverse problems using manifold constraints. Advances in Neural Information Processing Systems, 35:25683\u201325696, 2022.   \nHyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L Klasky, and Jong Chul Ye. Diffusion posterior sampling for general noisy inverse problems. International Conference on Learning Representations, 2023a.   \nHyungjin Chung, Jeongsol Kim, and Jong Chul Ye. Direct diffusion bridge using data consistency for inverse problems. arXiv preprint arXiv:2305.19809, 2023b.   \nPrafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in neural information processing systems, 34:8780\u20138794, 2021.   \nBradley Efron. Tweedie\u2019s formula and selection bias. Journal of the American Statistical Association, 106(496):1602\u20131614, 2011.   \nZalan Fabian, Berk Tinaz, and Mahdi Soltanolkotabi. Adapt and diffuse: Sample-adaptive reconstruction via latent diffusion models. arXiv preprint arXiv:2309.06642, 2023.   \nNathan Halko, Per-Gunnar Martinsson, and Joel A Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. SIAM review, 53(2): 217\u2013288, 2011.   \nJonathan Ho and Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022.   \nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840\u20136851, 2020.   \nMatthew D Houghton, Alexander B Oshin, Michael J Acheson, Evangelos A Theodorou, and Irene M Gregory. Path planning: Differential dynamic programming and model predictive path integral control on vtol aircraft. In AIAA SCITECH 2022 Forum, page 0624, 2022.   \nDavid H Jacobson. New second-order and first-order algorithms for determining optimal control: A differential dynamic programming approach. Journal of Optimization Theory and Applications, 2: 411\u2013440, 1968.   \nAlexia Jolicoeur-Martineau, Ke Li, R\u00e9mi Pich\u00e9-Taillefer, Tal Kachman, and Ioannis Mitliagkas. Gotta go fast when generating data with score-based models. arXiv preprint arXiv:2105.14080, 2021.   \nTero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4401\u20134410, 2019.   \nTero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusionbased generative models. Advances in Neural Information Processing Systems, 35:26565\u201326577, 2022.   \nBahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. Denoising diffusion restoration models. Advances in Neural Information Processing Systems, 35:23593\u201323606, 2022.   \nBahjat Kawar, Noam Elata, Tomer Michaeli, and Michael Elad. Gsure-based diffusion model training with corrupted data. arXiv preprint arXiv:2305.13128, 2023.   \nKwanyoung Kim and Jong Chul Ye. Noise2score: tweedie\u2019s approach to self-supervised image denoising without clean images. Advances in Neural Information Processing Systems, 34:864\u2013874, 2021.   \nDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \nDana A Knoll and David E Keyes. Jacobian-free newton\u2013krylov methods: a survey of approaches and applications. Journal of Computational Physics, 193(2):357\u2013397, 2004.   \nHenry Li, Ronen Basri, and Yuval Kluger. Likelihood training of cascaded diffusion models via hierarchical volume-preserving maps. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id $\\equiv$ sojpn00o8z.   \nWeiwei Li and Emanuel Todorov. Iterative linear quadratic regulator design for nonlinear biological movement systems. In First International Conference on Informatics in Control, Automation and Robotics, volume 2, pages 222\u2013229. SciTePress, 2004.   \nGuan-Horng Liu, Tianrong Chen, and Evangelos A Theodorou. Ddpnopt: Differential dynamic programming neural optimizer. arXiv preprint arXiv:2002.08809, 2020.   \nChenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans. On distillation of guided diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14297\u201314306, 2023.   \nXiangming Meng and Yoshiyuki Kabashima. Diffusion model based posterior sampling for noisy linear inverse problems. arXiv preprint arXiv:2211.12343, 2022.   \nGregory Ongie, Ajil Jalal, Christopher A Metzler, Richard G Baraniuk, Alexandros G Dimakis, and Rebecca Willett. Deep learning techniques for inverse problems in imaging. IEEE Journal on Selected Areas in Information Theory, 1(1):39\u201356, 2020.   \nSamet Oymak, Zalan Fabian, Mingchen Li, and Mahdi Soltanolkotabi. Generalization guarantees for neural networks via harnessing the low-rank structure of the jacobian. arXiv preprint arXiv:1906.05392, 2019.   \nMarcus Pereira, Ziyi Wang, Tianrong Chen, Emily Reed, and Evangelos Theodorou. Feynman-kac neural network architectures for stochastic control using second-order fbsde theory. In Learning for Dynamics and Control, pages 728\u2013738. PMLR, 2020.   \nKaare Brandt Petersen, Michael Syskind Pedersen, et al. The matrix cookbook. Technical University of Denmark, 7(15):510, 2008.   \nRobin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. Highresolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684\u201310695, 2022.   \nLitu Rout, Yujia Chen, Abhishek Kumar, Constantine Caramanis, Sanjay Shakkottai, and Wen-Sheng Chu. Beyond first-order tweedie: Solving inverse problems using latent diffusion. arXiv preprint arXiv:2312.00852, 2023.   \nLitu Rout, Negin Raoof, Giannis Daras, Constantine Caramanis, Alex Dimakis, and Sanjay Shakkottai. Solving linear inverse problems provably via posterior sampling with latent diffusion models. Advances in Neural Information Processing Systems, 36, 2024.   \nLevent Sagun, Utku Evci, V Ugur Guney, Yann Dauphin, and Leon Bottou. Empirical analysis of the hessian of over-parametrized neural networks. arXiv preprint arXiv:1706.04454, 2017.   \nChitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Information Processing Systems, 35:36479\u201336494, 2022.   \nTomohiro Sasaki, Koki Ho, and E Glenn Lightsey. Nonlinear spacecraft formation flying using constrained differential dynamic programming. In Proceedings of AAS/AIAA Astrodynamics Specialist Conference, 2022.   \nBowen Song, Soo Min Kwon, Zecheng Zhang, Xinyu Hu, Qing Qu, and Liyue Shen. Solving inverse problems with latent diffusion models via hard data consistency. arXiv preprint arXiv:2307.08123, 2024.   \nJiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020a.   \nJiaming Song, Arash Vahdat, Morteza Mardani, and Jan Kautz. Pseudoinverse-guided diffusion models for inverse problems. In International Conference on Learning Representations, 2022.   \nYang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32, 2019.   \nYang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020b.   \nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.   \nYuval Tassa, Tom Erez, and William Smart. Receding horizon differential dynamic programming. Advances in neural information processing systems, 20, 2007.   \nYuval Tassa, Nicolas Mansard, and Emo Todorov. Control-limited differential dynamic programming. In 2014 IEEE International Conference on Robotics and Automation (ICRA), pages 1168\u20131175. IEEE, 2014.   \nEmanuel Todorov and Weiwei Li. A generalized iterative lqg method for locally-optimal feedback control of constrained nonlinear stochastic systems. In Proceedings of the 2005, American Control Conference, 2005., pages 300\u2013306. IEEE, 2005.   \nKai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang. Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising. IEEE transactions on image processing, 26(7): 3142\u20133155, 2017. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 12}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "Justification: We demonstrate our results through rigorous analysis of our algorithm and extensive experiments on multiple inverse problem settings over several datasets. ", "page_idx": 12}, {"type": "text", "text": "Guidelines: ", "page_idx": 12}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 12}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "Justification: Yes, the paper discusses the runtime cost of the work, and provides an equivalent budget analysis, where it still demonstrates competitive performance on each benchmark. ", "page_idx": 12}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 12}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "Justification: The paper provides full proofs for all theory in the appendix. ", "page_idx": 12}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 12}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "Justification: The paper discloses all hyperparameters and implementation details in the appendix. ", "page_idx": 12}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 12}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "Justification: The paper provides open access to the data, which is publicly available. The authors will release code upon acceptance. ", "page_idx": 12}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 12}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "Justification: The paper provides all details in the appendix. ", "page_idx": 12}, {"type": "text", "text": "7. Experiment Statistical Significance ", "page_idx": 12}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 13}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 13}, {"type": "text", "text": "Justification: Experiments for other works do not provide error bars, therefore error bars would not benefit the analysis in this paper. ", "page_idx": 13}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: Experiments can be run on any GPU A4000 or later. ", "page_idx": 13}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We confirm to the NeurIPS Code of Ethics in every respect. ", "page_idx": 13}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: The paper discusses this in the appendix. ", "page_idx": 13}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 13}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 13}, {"type": "text", "text": "Justification: The results in this paper paper do not have high risk for misuse. ", "page_idx": 13}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We credit all creators and original owners of assets. ", "page_idx": 13}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 13}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 13}, {"type": "text", "text": "Justification: No new assets are introduced. ", "page_idx": 13}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 13}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 13}, {"type": "text", "text": "Justification: No research is performed with human subjects. ", "page_idx": 13}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 13}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 14}, {"type": "text", "text": "Answer: [NA] Justification: No research is performed with human subjects. ", "page_idx": 14}, {"type": "text", "text": "A Impact Statement ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "This paper builds on a large body of existing work and presents an improved technique for solving generic nonlinear inverse problems, which can be seen as a generalization of guided diffusion modeling. Controlling the diffusion process in a generative model has many societal applications, and thus a broad range of downstream impacts. We believe that understanding the capabilities and limitations of such models in a public forum and open community is essential for practical and responsible integration of these technologies with society. However, the ideas presented in this work, as well as any other work in this field, must be deployed with caution to the inherent dangers of these technologies. ", "page_idx": 15}, {"type": "text", "text": "B Deriving the Iterative Linear Quadratic Regulator (iLQR) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Differential Dynamic Programming (DDP) is a very popular trajectory optimization algorithm that has a rich history of theoretical results Jacobson [1968] as well as successful practical applications in robotics Tassa et al. [2007, 2014], aerospace Houghton et al. [2022], Sasaki et al. [2022] and biomechanics Todorov and Li [2005]. It falls under the class of indirect methods for trajectory optimization, wherein Bellman\u2019s principle of optimality defines the so-called optimal value-function which in turn can be used to determine the optimal control. This is in contrast to so-called direct methods which cast the problem at hand into a nonlinear constrained optimization problem. ", "page_idx": 15}, {"type": "text", "text": "To formulate an optimal control algorithm we first define the state transition function of a dynamical system as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t-1}=\\mathbf{h}(\\mathbf{x}_{t},\\,\\mathbf{u}_{t}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The next ingredient that we need for our optimal control approach is a cost function $J(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})\\in\\mathbb{R}$ . This is used to define a performance criterion that iLQR can optimize with respect to the set of controls $\\{{\\mathbf{u}}_{t}\\}_{t=T}^{t=1}$ (i.e., the control trajectory going backwards from time $t\\,=\\,T$ to $t\\,=\\,1$ ). The cost-function is defined as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nJ_{T}=\\sum_{t=T}^{1}\\ell_{t}(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})+\\ell_{0}(\\mathbf{x}_{0}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where, $\\ell_{t}$ and $\\ell_{0}$ are scalar-valued functions which are commonly referred to as the running costfunction and the terminal cost-function respectively. ", "page_idx": 15}, {"type": "text", "text": "To obtain the sequence of optimal controls, we employ the dynamic programming principle. To do so, we first introduce the notion of the Value-function defined as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nV(\\mathbf x_{t},\\,t)=\\operatorname*{min}_{\\{\\mathbf u_{n}\\}_{n=t}^{n=1}}J_{t}=\\operatorname*{min}_{\\{\\mathbf u_{n}\\}_{n=t}^{n=1}}\\big[\\sum_{n=t}^{1}\\ell_{n}(\\mathbf x_{n},\\,\\mathbf u_{n})+\\ell_{0}(\\mathbf x_{0})\\big]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Intuitively, the Value-function resembles the optimal cost-to-go starting from time step $t$ and state $\\mathbf{x}_{t}$ until the end of the time horizon (i.e., $t=0$ ). Using this definition, one can easily derive the following recursive relation also known as Bellman\u2019s Principle of Optimality: ", "page_idx": 15}, {"type": "equation", "text": "$$\nV(\\mathbf x_{t},\\,t)=\\operatorname*{min}_{\\mathbf u_{t}}\\Big[\\ell_{t}(\\mathbf x_{t},\\,\\mathbf u_{t})+V(\\mathbf x_{t-1},\\,t-1)\\Big].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A often useful defintion used in the derivation of the iLQR Riccati equations is that of the State-Action Value-Function $Q(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})$ given by, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{Q}(\\mathbf{x}_{t},\\,{\\mathbf{u}}_{t})={\\ell}_{t}(\\mathbf{x}_{t},\\,{\\mathbf{u}}_{t})+V(\\mathbf{x}_{t-1},\\,t-1)}\\\\ {\\mathrm{Therefore},V(\\mathbf{x}_{t},\\,t)=\\underset{\\mathbf{u}_{t}}{\\mathrm{min}}\\,Q(\\mathbf{x}_{t},\\,{\\mathbf{u}}_{t})}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A sketch of the derivation of the Riccati equations is as follows: we take second-order Taylor expansions of both $Q(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})$ and $V(\\mathbf{x}_{t},\\,t)$ around nominal state and action trajectories of $\\{\\bar{\\mathbf{x}}_{t}\\}_{t=T}^{t=0}$ and $\\{\\bar{\\mathbf{u}}_{t}\\}_{t=T}^{t=1}$ respectively. Next, we substitute these into Eq.(37) and equate the first- and second", "page_idx": 15}, {"type": "text", "text": "order terms to yield the following relations between the derivatives of $Q,\\,\\ell$ and $V$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q_{\\mathbf{x}}=\\ell_{\\mathbf{x}}+\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime}}\\\\ &{Q_{\\mathbf{u}}=\\ell_{\\mathbf{u}}+\\mathbf{h}_{\\mathbf{u}}^{T}V_{\\mathbf{x}}^{\\prime}}\\\\ &{Q_{\\mathbf{xx}}=\\ell_{\\mathbf{xx}}+\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}}\\\\ &{Q_{\\mathbf{xu}}=\\ell_{\\mathbf{xu}}+\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{u}}}\\\\ &{Q_{\\mathbf{ux}}=\\ell_{\\mathbf{ux}}+\\mathbf{h}_{\\mathbf{u}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}}\\\\ &{Q_{\\mathbf{uu}}=\\ell_{\\mathbf{uu}}+\\mathbf{h}_{\\mathbf{u}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{u}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathbf{h}_{\\mathbf{x}_{t}}$ and $\\mathbf{h}_{\\mathbf{u}_{t}}$ are the Jacobians of the dynamics function $\\mathbf{h}(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})$ , evaluated at time step $t$ , w.r.t the state and the control vectors respectively. For ease of notation, we have dropped the subscript $t$ and therefore all derivatives above should be considered to be evaluated at time step $t$ , while we use $V_{\\mathbf{x}}^{\\prime}$ and $V_{\\mathbf{x}\\mathbf{x}}^{\\prime}$ above to indicate the gradient and hessian of the Value-function evaluated at the next time step (i.e., at time step $t-1)$ ). ", "page_idx": 16}, {"type": "text", "text": "Next, we substitute for the second-order approximation of $Q(\\mathbf{x}_{t},\\,\\mathbf{u}_{t})$ into Eq. (38) and note that $\\mathbf{u}_{t}$ can be written in terms of the nominal control as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t}=\\bar{\\mathbf{u}}_{t}+\\delta\\mathbf{u}_{t}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This results in a quadratic objective w.r.t $\\delta\\mathbf{u}_{t}$ and the minimization in Eq. (38) can be performed exactly resulting in the following optimal perturbation from the nominal control trajectory: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\delta\\mathbf{u}_{t}^{*}=\\mathbf{k}_{t}+\\mathbf{K}_{t}\\delta\\mathbf{x}_{t}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where, the feedforward and feedback gains are given by the following expressions: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\bf k}=-Q_{\\bf u u}^{-1}Q_{\\bf u}}\\\\ {{\\bf K}=-Q_{\\bf u u}^{-1}Q_{\\bf u x}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Finally, by substituting for the optimal $\\delta\\mathbf{u}_{t}^{*}$ back into Eq.(38), we can drop the min operator and equate the first- and second-order terms on both sides. This results the following Riccati equations: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathbf{x}}=Q_{\\mathbf{x}}-\\mathbf{K}^{T}Q_{\\mathbf{uu}}\\mathbf{k}}\\\\ &{V_{\\mathbf{xx}}=Q_{\\mathbf{xx}}-\\mathbf{K}^{T}Q_{\\mathbf{uu}}\\mathbf{K}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This concludes the sketch derivation of the Riccati equations. The algorithm roughly proceeds as follows: ", "page_idx": 16}, {"type": "text", "text": "1. We start with an initial guess of the the nominal control trajectory $\\{\\bar{\\mathbf{u}}_{t}\\}_{t=T}^{1}$ and generate the corresponding nominal state trajectory $\\{\\bar{\\mathbf{x}}_{t}\\}_{t=T}^{0}$ using $\\mathbf x_{t}=\\mathbf h(\\mathbf x_{t+1},\\dot{\\mathbf u}_{t+1})$ .   \n2. By noticing from Eq. (35) that $V(\\mathbf{x}_{0},\\,0)=\\ell(\\mathbf{x}_{0})$ we can obtain expressions for $V_{\\mathbf{x}}$ and $V_{\\mathbf{xx}}$ evaluated at $\\bar{\\bf x}_{0}$ .   \n3. Next, we compute the derivatives of $Q$ given by equations. (39)-(44) using $\\{\\bar{\\mathbf{u}}_{t}\\}_{t=T}^{1}$ and {\u00afxt}t1=T .   \n4. Using the derivatives of $Q$ , we can compute the feedforward and feedback gains using equations (46)-(47).   \n5. Finally, using the Riccati equations (48)-(49), we can propagate both $V_{\\mathbf{x}}$ and $V_{\\mathbf{xx}}$ one step backwards in time.   \n6. We then repeat the steps 3, 4 and 5 until we backpropagate the derivatives of $V$ to time step $t=T$ .   \n7. This completes one iteration of iLQR. At the end of each iteration the gains are used to produce the updated nominal control trajectory as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{u}}_{t}^{*}=\\bar{\\mathbf{u}}_{t}+\\alpha\\mathbf{k}+\\mathbf{K}(\\bar{\\mathbf{x}}_{t}-\\mathbf{x}_{t})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where, $\\mathbf{x}_{t}$ is the state obtained by unrolling the dynamics subject to the updated controls: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbf x_{t}=\\mathbf h(\\mathbf x_{t+1},\\bar{\\mathbf u}_{t+1}^{*}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "8. The new nominal control trajectory $\\bar{\\mathbf{u}}_{t}^{*}$ is used to produce a new nominal state trajectory $\\bar{\\mathbf{x}}_{t}^{*}$ and the algorithm is repeated from step 2 onwards until convergence or a fixed number of iterations. ", "page_idx": 16}, {"type": "text", "text": "C Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Theorem 4.1. Let Eq. 3 be the discretized sampling equation for the diffusion model with output perturbation mode control (Eq. 18). Moreover, let the terminal cost ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{0}(\\mathbf{x}_{0})=-\\log p(\\mathbf{y}|\\mathbf{x}_{0})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "be twice-differentiable and the running costs ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{t}(\\mathbf{x}_{t},\\mathbf{u}_{t})=0.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then the iterative linear quadratic regulator with Tikhonov regularizer \u03b1 produces the control ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t}=\\alpha\\nabla_{\\mathbf{x}_{t}}\\log p(\\mathbf{y}|\\mathbf{x}_{0}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. We demonstrate the result via induction for $t=1,\\dots,T$ . ", "page_idx": 17}, {"type": "text", "text": "Since we assume that $\\ell_{\\mathbf{uu}}=\\mathbf{0}$ , $V_{\\mathbf{xx}}$ vanishes: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathbf{x}\\mathbf{x}}=Q_{\\mathbf{x}\\mathbf{x}}-Q_{\\mathbf{u}\\mathbf{x}}^{T}Q_{\\mathbf{u}\\mathbf{u}}^{-1}Q_{\\mathbf{u}\\mathbf{x}}}\\\\ &{\\qquad=h_{\\mathbf{x}}^{T}V_{\\mathbf{x}\\mathbf{x}}^{\\prime}h_{\\mathbf{x}}-h_{\\mathbf{x}}^{T}V_{\\mathbf{x}\\mathbf{x}}^{\\prime}(V_{\\mathbf{x}\\mathbf{x}}^{\\prime})^{-1}V_{\\mathbf{x}\\mathbf{x}}^{\\prime}h_{\\mathbf{x}}}\\\\ &{\\qquad=\\mathbf{0}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Similarly, $V_{\\mathbf{x}}$ also greatly simplifies as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathbf x}=Q_{\\mathbf x}+Q_{\\mathbf u\\mathbf x}^{T}Q_{\\mathbf u\\mathbf u}^{-1}Q_{\\mathbf u}}\\\\ &{\\quad\\quad=h_{\\mathbf x}^{T}V_{\\mathbf x}^{\\prime}+h_{\\mathbf x}^{T}V_{\\mathbf x\\mathbf x}^{\\prime}(V_{\\mathbf x\\mathbf x}^{\\prime})^{-1}V_{\\mathbf x}^{\\prime}}\\\\ &{\\quad\\quad=h_{\\mathbf x}^{T}V_{\\mathbf x}^{\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Turning to the Tikhonov regularized feedforward term, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{k}=-Q_{\\mathbf{u}\\mathbf{u}}^{-1}Q_{\\mathbf{u}}}\\\\ &{\\quad=-(h_{\\mathbf{x}}^{T}\\underbrace{V_{\\mathbf{xx}}}_{\\mathbf{0}}h_{\\mathbf{x}}+\\alpha\\mathbf{I})^{-1}Q_{\\mathbf{u}}}\\\\ &{\\quad=-(\\mathbf{0}+\\alpha\\mathbf{I})^{-1}Q_{\\mathbf{u}}}\\\\ &{\\quad=-\\frac{1}{\\alpha}V_{\\mathbf{x}}^{\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Finally, the feedback term disappears due to the vanishing $V_{\\mathbf{xx}}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\bf K}=-Q_{\\bf u u}^{-1}Q_{\\bf u x}}\\\\ {={\\bf0}.\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Explicitly denoting the dependence of $V_{\\mathbf{x}}$ and $V_{\\mathbf{x}}^{\\prime}$ on $t$ , we can rewrite Eq. 56 as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathbf{x}}^{(t)}=h_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{(t-1)}}\\\\ &{\\quad\\quad\\quad=\\frac{\\partial\\mathbf{x}_{t-1}}{\\partial\\mathbf{x}_{t}}\\frac{\\partial}{\\partial\\mathbf{x}_{t-1}}V.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Combining this observation with the fact that $\\ell_{0}=-\\log p(\\mathbf{y}|\\mathbf{x}_{0})$ , we can conclude that ", "page_idx": 17}, {"type": "equation", "text": "$$\nV_{\\mathbf{x}}^{(t)}=-\\nabla_{\\mathbf{x}_{t}}\\log p(\\mathbf{y}|\\mathbf{x}_{0}),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathbf{x}_{\\mathrm{0}}$ depends on $\\mathbf{x}_{t}$ via the state transition function $\\mathbf{h}$ (Eq. 18). Therefore, we have that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\bf k}=-\\frac{1}{\\alpha}V_{\\bf x}^{\\prime}}\\ ~}\\\\ {~~~=\\frac{1}{\\alpha}\\nabla_{\\bf x}_{t}\\log p({\\bf y}|{\\bf x}_{0})}\\\\ {{\\displaystyle{\\bf K}=0}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Finally, given our action update (Eq. 15), we can conclude our desired result ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t}={\\frac{1}{\\alpha}}\\nabla_{\\mathbf{x}_{t}}\\log p(\\mathbf{y}|\\mathbf{x}_{0}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Lemma C.1. Under the deterministic sampler with output perturbation mode control, \u03b1 =g(t)12\u2206t recovers posterior sampling (Eq. 9). ", "page_idx": 18}, {"type": "text", "text": "Proof. Substituting in $\\begin{array}{r}{\\alpha=\\frac{1}{g(t)^{2}\\Delta t}}\\end{array}$ to Eq. 29, we observe that Eq. 18 can now be written as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t-1}=[f(\\mathbf{x}_{t})-\\frac{1}{2}g(t)^{2}(\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{x}_{t})+\\nabla_{\\mathbf{x}_{t}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{0}))]\\Delta t.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Under the determinstic sampler, we can conclude that $\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{0})=\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{t})$ , since each $\\mathbf{x}_{t}$ has a unique path through the sample space. Therefore, we conclude that Eq. 65 resembles the ideal posterior sampler equation 9. We conclude our proof. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Theorem 4.3. Let Eq. 3 be the discretized sampling equation for the diffusion model with input perturbation mode control (Eq. 17). Moreover, let ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\ell_{0}(\\mathbf{x}_{0})=\\log p(\\mathbf{y}|\\mathbf{x}_{0}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and the running costs ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\ell_{t}(\\mathbf{x}_{t},\\mathbf{u}_{t})=0.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then the iterative linear quadratic regulator with Tikhonov regularizer $\\begin{array}{r}{\\alpha=\\frac{1}{g(t)^{2}\\Delta t}}\\end{array}$ g(t)2\u2206t produces the dynamical sytem ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde\\mathbf{x}_{t}=\\widetilde\\mathbf{x}_{t}+[f(\\widetilde\\mathbf{x}_{t})-\\displaystyle\\frac{1}{2}g(t)^{2}(\\nabla_{\\mathbf{x}}\\log p_{t}(\\widetilde\\mathbf{x}_{t})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{t}))]\\Delta t,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\widetilde{\\mathbf{x}}_{t}:=\\mathbf{x}_{t}+\\mathbf{u}_{t}$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. We similarly demonstrate the result via induction for $t=1,\\dots,T$ . ", "page_idx": 18}, {"type": "text", "text": "Again, assuming that $\\ell_{\\mathbf{uu}}=0$ , $V_{\\mathbf{xx}}$ vanishes: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\mathbf{x}\\mathbf{x}}=Q_{\\mathbf{x}\\mathbf{x}}-Q_{\\mathbf{u}\\mathbf{x}}^{T}Q_{\\mathbf{u}\\mathbf{u}}^{-1}Q_{\\mathbf{u}\\mathbf{x}}}\\\\ &{\\qquad=Q_{\\mathbf{x}\\mathbf{x}}-Q_{\\mathbf{x}\\mathbf{x}}(\\underbrace{\\ell_{\\mathbf{u}\\mathbf{u}}}_{=\\mathbf{0}}+Q_{\\mathbf{x}\\mathbf{x}})^{-1}Q_{\\mathbf{x}\\mathbf{x}}}\\\\ &{\\qquad\\qquad=\\mathbf{0},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "whereas $V_{\\mathbf{x}}$ greatly simplifies as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V_{\\mathbf{x}}=Q_{\\mathbf{x}}+Q_{\\mathbf{ux}}^{T}Q_{\\mathbf{uu}}^{-1}Q_{\\mathbf{u}}}\\\\ {=h_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime}.\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Turning to the feedforward and feedback terms, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{k}=-Q_{\\mathbf{u}\\mathbf{u}}^{-1}Q_{\\mathbf{u}}}\\\\ &{\\quad=-(h_{\\mathbf{x}}^{T}\\underbrace{V_{\\mathbf{xx}}}_{\\mathbf{0}}h_{\\mathbf{x}}+\\alpha\\mathbf{I})^{-1}Q_{\\mathbf{u}}}\\\\ &{\\quad=-(\\mathbf{0}+\\alpha\\mathbf{I})^{-1}Q_{\\mathbf{u}}}\\\\ &{\\quad=-\\frac{1}{\\alpha}h_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\bf K}=-Q_{\\bf u u}^{-1}Q_{\\bf u x}}\\\\ {={\\bf0}.\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We observe that ", "page_idx": 18}, {"type": "equation", "text": "$$\nV_{\\mathbf{x}}^{(t)}=-\\frac{1}{\\alpha}h_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{(t-1)}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "table", "img_path": "wqLC4G1GN3/tmp/e9fe10d937115453d3fe7b6ad141dddd5ddb7f6184d05748c7d24fa258d4de6f.jpg", "table_caption": [], "table_footnote": ["Table 2: Hyperparameters for FFHQ experiments. "], "page_idx": 19}, {"type": "text", "text": "Therefore, noting that $V_{\\mathbf{x}}^{(0)}=\\log p(\\mathbf{y}|\\mathbf{x}_{0})$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbf{k}=-V_{\\mathbf{x}}^{(t)}}\\\\ {\\displaystyle\\quad=-\\frac{1}{\\alpha}(h_{\\mathbf{x}}^{(t)})^{T}V_{\\mathbf{x}}^{(t-1)}}\\\\ {\\displaystyle\\quad=-\\frac{1}{\\alpha}\\nabla_{\\mathbf{x}_{t}}\\log p(\\mathbf{y}|\\mathbf{x}_{0})}\\\\ {\\displaystyle\\quad=-\\frac{1}{\\alpha}\\nabla_{\\mathbf{x}_{t}}\\log p(\\mathbf{y}|\\mathbf{x}_{0}(\\mathbf{x}_{t})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Applying the feedforward terms to the diffusion sampling process, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\bf x}_{t-1}=({\\bf x}_{t}+{\\bf u}_{t})+[f({\\bf x}_{t}+{\\bf u}_{t})}\\ ~}\\\\ {{\\displaystyle~~~~~~~~~~~-\\frac{1}{2}g(t)^{2}\\nabla_{\\bf x}\\log p_{t}({\\bf x}_{t}+{\\bf u}_{t})]\\Delta t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We define the intermediary variable ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widetilde{\\mathbf{x}}_{t}=\\mathbf{x}_{t}+\\mathbf{u}_{t},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which has dynamics ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widetilde{\\mathbf{x}}_{t}=\\widetilde{\\mathbf{x}}_{t}+[f(\\widetilde{\\mathbf{x}}_{t})-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\widetilde{\\mathbf{x}}_{t})]\\Delta t+\\mathbf{u}_{t}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We now can see that, letting $\\alpha=\\Delta t g(t)^{2}$ , we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widetilde{\\mathbf{x}}_{t}=\\widetilde{\\mathbf{x}}_{t}+[f(\\widetilde{\\mathbf{x}}_{t})-\\frac{1}{2}g(t)^{2}(\\nabla_{\\mathbf{x}}\\log p_{t}(\\widetilde{\\mathbf{x}}_{t})+\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{y}|\\mathbf{x}_{0}))]\\Delta t.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "D Implementation ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For all experiments, we use publicly available datasets and pre-trained model weights. For the FFHQ $256\\times256$ experiments, we use the last 1K images of the dataset for evaluation. For MNIST, we do not use images directly in the inverse classification task. The images were only used for training the pretrained diffusion model. ", "page_idx": 19}, {"type": "text", "text": "For models, we used the pretrained weights from Chung et al. [2023a] for FFHQ $256\\times256$ tasks, and the Hugging Face 1aurent/mnist-28 diffusion model for MNIST experiments. No further training is performed on any models. Further hyperparameters can be found in Table 2. For the classifier $p(\\mathbf{y}\\vert\\mathbf{x})$ in MNIST class-guided classification, we use a simple convolutional neural network with two convolutional layers and two MLP layers, trained on the entire MNIST dataset. ", "page_idx": 19}, {"type": "text", "text": "D.1 High Dimensional Control ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "To speed up our proposed method, we leverage the following three modifications to the standard iLQR algorithm. ", "page_idx": 19}, {"type": "table", "img_path": "wqLC4G1GN3/tmp/ec8fcde2451cd698edd8b8cbdaee6a8d2cd7368625018ba182a3995d64979a40.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "wqLC4G1GN3/tmp/b2dd966c7a6b4a3a3caa3d7998c25e208068289f6ba98970089951635f62da5f.jpg", "table_caption": ["Table 3: Quantitative evaluation (PSNR, SSIM, MSE) of performance on inverse problems on the FFHQ 256x256-1K dataset. ", "Table 4: Ablative study on the effect of rank in the low rank and matrix-free approximations on performance (LPIPS, PSNR, SSIM, NMSE) of our proposed model on the FFHQ 256x256-1K dataset dataset. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Randomized Low-Rank Approximation The first and second order terms in Eqs. (19-25) are corresponding Taylor expansions of deep neural functions. Even with the use of automatic differentiation libraries, the formation of these matrices is incredibly expensive, requiring at least $\\dim(\\mathbf{x})$ backpropagation passes (where $\\mathrm{dim}(\\mathbf{x})\\approx39B$ in some experiments). To reduce the cost of computing these matrices, we utilize their known low rank structure Sagun et al. [2017], Oymak et al. [2019]. ", "page_idx": 20}, {"type": "text", "text": "Leveraging advanced techniques in randomized numerical linear algebra, we estimate Eqs. (19-25) using randomized SVD Halko et al. [2011]. For any matrix $\\mathbf{A}\\in\\bar{\\mathbb{R}^{m\\times n}}$ this is a four step process. 1) We sample a random matrix $\\boldsymbol\\Omega\\sim\\mathcal{N}(\\mathbf0,\\mathbf I_{n\\times k})$ . 2) We obtain $\\mathbf{A}\\Omega=\\mathbf{Y}\\in\\mathbb{R}^{m\\times k}$ . 3) We form a basis over the columns of $\\mathbf{Y}$ , e.g. by taking the $\\mathbf{Q}$ matrix in a QR factorization $\\mathbf{QR}=\\mathbf{Y}$ . 4) We approximate $\\mathbf{A}\\approx\\mathbf{Q}^{T}\\mathbf{Q}\\mathbf{A}$ . ", "page_idx": 20}, {"type": "text", "text": "Notably, we observe that when A is a Jacobian (or Hessian) matrix, it can be approximated purely through Jacobian-vector and vector-Jacobian (Hessian-vector and vector-Hessian, resp.) products \u2014 without ever materializing A itself. Moreover, a key result in randomized linear algebra is that this algorithm can approximate A up to accuracy $\\mathcal{O}(m n k\\sigma_{k+1})$ (Theorem 1.1 in Halko et al. [2011]). Notably, if A has low rank structure where $\\exists k$ such that the $k+1$ th singular value $\\sigma_{k+1}=0$ , then the approximation is exact. ", "page_idx": 20}, {"type": "table", "img_path": "wqLC4G1GN3/tmp/471eca878a5fbd005a74c85121582ea384e9b4555690b4bdf453e0b936aa7b6b.jpg", "table_caption": ["Matrix-Free Evaluation Inspired by matrix-free techniques in numerical optimization Knoll and Keyes [2004], we demonstrate a strategy for forming the action update (15) without materializing the costly $\\dim(\\mathbf{x})\\times\\dim(\\mathbf{x})$ matrices in the iLQR algorithm (19-25), which we shall denote as an "], "table_footnote": ["Table 5: Ablative study on the effect of the Tikhonov regularization coefficient $\\alpha$ on performance (LPIPS, PSNR, SSIM, NMSE) of our proposed model on the FFHQ 256x256-1K dataset dataset. No results are reported for $\\alpha=0$ , as the algorithm encountered numerical precision errors during matrix inversion. "], "page_idx": 20}, {"type": "table", "img_path": "wqLC4G1GN3/tmp/2283b4bc38e617afff5e60d95b809d469f6cea66d6aafe7651a11c597d632b53.jpg", "table_caption": [], "table_footnote": ["Table 6: Ablative study on the effect of $T$ on performance (LPIPS, PSNR, SSIM, NMSE) of our proposed model on the FFHQ $256\\mathrm{x256-1K}$ dataset dataset. "], "page_idx": 21}, {"type": "text", "text": "indexed set of matrices $\\{\\mathbf{A}_{i}\\}$ . We do this by forming projections of each $\\mathbf{A}_{i}$ against a corresponding set of $\\dim(\\mathbf{x})\\times\\ell$ column-orthogonal matrices $\\{\\mathbf{Q}_{i}\\}$ , which we denote as $\\mathbf{\\check{B}}_{i}:=\\mathbf{Q}_{i}^{T}\\mathbf{A}_{i}$ . These matrices can then be stored at reduced cost as $(\\mathbf{Q}_{i},\\mathbf{B}_{i})$ pairs. ", "page_idx": 21}, {"type": "text", "text": "Matrix multiplications between any $\\mathbf{A}_{i}\\mathbf{A}_{j}$ can then be approximated up to rank $\\ell$ with respect to the projected matrix, $\\mathbf{Q}_{i}\\mathbf{A}_{i,\\mathbf{Q}_{i}}$ , i.e. ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{A}_{i}\\mathbf{A}_{j}\\approx\\mathbf{Q}_{i}\\mathbf{B}_{i}\\mathbf{Q}_{j}^{T}\\mathbf{B}_{j}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "However, to prevent materialization of the full size of any matrices, we drop the leading $\\mathbf{Q}_{i}$ , obtaining a new projected-matrix pair $(\\bf{Q}_{k},\\bf{B}_{k})$ , where $\\mathbf{Q_{k}}=\\mathbf{Q}_{i}$ . ", "page_idx": 21}, {"type": "text", "text": "Adam Optimizer Finally, we precondition gradients via the Adam optimizer Kingma and Ba [2014] before applying the feedback gains, rather than applying a backtracking line search Tassa et al. [2014], resulting in the action update ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{u}_{t}=\\mathbf{P}\\mathbf{k}_{t}+\\mathbf{K}_{t}(\\mathbf{x}_{t}-\\mathbf{x}_{t}^{\\prime}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\mathbf{P}$ is the preconditioning matrix produced by the Adam optimizer. This reduces the overall runtime of the algorithm while still accounting for second-order information that respects the nonlinearity of the optimization landscape. ", "page_idx": 21}, {"type": "text", "text": "D.2 Computational Complexity Analysis ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Incorporating all three modifications, we can provide a realistic runtime and space complexity analysis of our presented algorithm with respect to the rank $k$ , the data dimension $d$ , diffusion steps $m$ , and number of iLQR iterations $n$ . ", "page_idx": 21}, {"type": "text", "text": "Combining both the low rank and matrix-free approximations, we obtain the updated equations for input mode perturbation (where projection matrices are written as $\\mathbf{P}$ to avoid overloading the $Q$ function notation): ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q_{\\mathbf{x}}=\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime}}\\\\ &{\\qquad\\qquad\\qquad Q_{\\mathbf{u}}=\\ell_{\\mathbf{u}}+\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{x}}^{\\prime}}\\\\ &{\\mathbf{P}Q_{\\mathbf{xx}}\\mathbf{P}^{T}=\\mathbf{P}Q_{\\mathbf{ux}}\\mathbf{P}^{T}=\\mathbf{P}Q_{\\mathbf{xu}}\\mathbf{P}^{T}=\\mathbf{P}\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}\\mathbf{P}^{T}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\quad\\mathbf{P}Q_{\\mathbf{uu}}\\mathbf{P}^{T}=\\mathbf{P}\\ell_{\\mathbf{uu}}\\mathbf{P}^{T}+\\mathbf{P}\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}\\mathbf{P}^{T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "To simplify notation, each projection matrix $\\mathbf{P}$ is the same \u2014 in reality, this need not be the case. Note that $\\mathbf{Q}_{x}$ and $\\mathbf{Q}_{u}$ are simply of size $d$ and therefore image-sized. For all our datasets, these each take $0.2\\,\\mathrm{MB}$ to store and are therefore negligible, and we do not project these variables. When $\\ell_{\\mathbf{uu}}$ is diagonal (as it is in our case), we can obtain the projected inverse for $Q_{\\bf u u}$ as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{P}Q_{\\mathbf{uu}}^{-1}\\mathbf{P}^{T}=\\mathbf{P}\\ell_{\\mathbf{uu}}^{-1}\\mathbf{P}^{T}+\\mathbf{P}\\ell_{\\mathbf{uu}}^{-1}\\mathbf{P}^{T}(\\mathbf{C}^{-1}+\\mathbf{P}^{T}\\ell_{\\mathbf{uu}}^{-1}\\mathbf{P})^{-1}\\mathbf{P}\\ell_{\\mathbf{uu}}^{-1}\\mathbf{P}^{T}\\qquad{\\mathrm{where~}}\\mathbf{C}=\\mathbf{P}\\mathbf{h}_{\\mathbf{x}}^{T}V_{\\mathbf{xx}}^{\\prime}\\mathbf{h}_{\\mathbf{x}}\\mathbf{P}\\,.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "via a direct application of the Woodbury matrix inversion formula Petersen et al. [2008], which has cost $O(k^{3}+\\dot{k}d^{2})$ . Finally, we compute the projected updates $V_{\\mathbf{x}\\mathbf{x}},\\mathbf{K}$ as well as the full-precision ", "page_idx": 21}, {"type": "text", "text": "$V_{\\mathbf{x}},\\mathbf{k}$ terms via ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbf k=-\\mathbf P^{T}\\mathbf P Q_{\\mathbf u\\mathbf u}^{-1}\\mathbf P^{T}\\mathbf P Q_{\\mathbf u}}\\\\ &{\\quad\\quad\\quad V_{\\mathbf x}=Q_{\\mathbf x}-\\mathbf P^{T}\\mathbf P\\mathbf K^{T}\\mathbf P^{T}\\mathbf P Q_{\\mathbf u\\mathbf u}\\mathbf P^{T}\\mathbf P\\mathbf k}\\\\ &{\\quad\\mathbf P\\mathbf K\\mathbf P^{T}=-\\mathbf P Q_{\\mathbf u\\mathbf u}^{-1}\\mathbf P^{T}\\mathbf P Q_{\\mathbf u\\mathbf x}\\mathbf P^{T}}\\\\ &{\\mathbf P V_{\\mathbf x\\mathbf x}\\mathbf P^{T}=\\mathbf P Q_{\\mathbf x\\mathbf x}\\mathbf P^{T}-\\mathbf P\\mathbf K^{T}\\mathbf P^{T}\\mathbf P Q_{\\mathbf u\\mathbf u}\\mathbf P^{T}\\mathbf P\\mathbf K\\mathbf P^{T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Where applicable, we leverage vector-Jacobian products from standard automatic differentiation libraries (e.g. torch.func.vjp) which have runtime complexity $O(1)$ . Computing the $V_{\\mathbf{x}},V_{\\mathbf{x}\\mathbf{x}},\\mathbf{k},\\mathbf{K}$ terms in Eqs. (46)-(49) costs $\\mathbf{\\dot{O}}(k^{3}+k d^{2})$ FLOPs in terms of matrix multiplications (dominated by the matrix inverse of $k\\times k$ matrix $\\mathbf{q}^{T}Q_{\\mathbf{uu}}\\mathbf{q})$ . Crucially, it incurs $O(k)$ neural function evaluations (NFEs), which dominates the runtime of the algorithm. Since this computation is performed for each diffusion step and iLQR iteration, the total runtime complexity of our algorithm is $\\mathcal{O}(n m(k^{3}+k d^{2}))$ matrix multiplication FLOPs and $\\mathcal{O}(n m k)$ NFEs, with $O(\\dot{m}k^{2}+d)$ space complexity. In terms of time complexity, the NFEs are the dominating cost, accounting for $97\\%$ of computation time. ", "page_idx": 22}, {"type": "text", "text": "D.3 Sensitivity to Hyperparameters ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In Tables 4, 5, 6, we investigate the effect of the rank of the low rank approximation and matrix-free projections, the Tikhonov regularization coefficient $\\alpha$ , and the diffusion time $T$ on the performance of our method on the FFHQ $256\\mathrm{x256}$ dataset. We evaluate performance on the super-resolution and random inpainting tasks, with the same setup as in Section 6. ", "page_idx": 22}, {"type": "text", "text": "Low-Rank and Matrix-Free Rank From Table 4, it is clear that there is a significant performance gain from even a rank one approximation of the first- and second-order matrices. The gains from subsequent increases in the rank approximation diminish quickly. This is because increasing the rank of the approximation only improves the approximation of the second-order terms. The first order $V_{\\mathbf{x}},Q_{\\mathbf{x}},Q_{\\mathbf{u}}$ terms are always modeled exactly in $\\mathcal{O}(1)$ time per iteration due to their amenability to vector-Jacobian products. From Theorems 4.1-4.3 we see that even when the second order terms are zero (i.e., the result of assumption $\\ell_{t}=0$ ), we exactly recover the true posterior sampler. Therefore, the second-order terms are less important, though still useful for imposing a quadratic trust-region regularization to the algorithm. Therefore, we ultimately choose $k=1$ for three reasons: ", "page_idx": 22}, {"type": "text", "text": "1. the rank only affects the quadratic approximation of the iLQR algorithm (and does not affect our theoretical results in Theorems 4.1-4.3)   \n2. $k=1$ already allows second-order propagation of the quadratic trust-region regularization, and   \n3. subsequent increases in $k$ have a minimal effect on the performance of the algorithm. ", "page_idx": 22}, {"type": "text", "text": "Tikhonov Regularizer Table 5 demonstrates that our algorithm is relatively robust to the Tikhonov regularization parameter, except when $\\alpha\\,=\\,0$ . Under this condition, any ill-conditioning of $Q_{\\bf u u}$ results in division by zero errors, resulting in the failure of the algorithm. Therefore, we simply choose to let $\\alpha=1e-4$ , since the effect of Tikhonov regularizer is minimal. ", "page_idx": 22}, {"type": "text", "text": "Diffusion Steps Finally, we observe in Table 6 that increasing the diffusion time results in higher quality samples \u2014 though at the cost of increased computation time. Therefore, choice of $T$ requires balancing computational cost and sample quality, and is ultimately highly user-dependent. When the computational and latency budget is relatively high, large $T$ can be used to improve sample quality. Conversely, when this budget is low, we find that even $T=20$ provides reasonable samples. ", "page_idx": 22}]