{"references": [{"fullname_first_author": "David Silver", "paper_title": "Mastering the game of Go without human knowledge", "publication_date": "2017-01-01", "reason": "This paper is foundational to the concept of decision-time search (DTS), a key component of the proposed OMIS model."}, {"fullname_first_author": "Ilya Sutskever", "paper_title": "Sequence to Sequence Learning with Neural Networks", "publication_date": "2014-01-01", "reason": "This paper introduces the fundamental architecture of sequence-to-sequence learning using neural networks, which is crucial to the OMIS model's Transformer-based design."}, {"fullname_first_author": "Yan Duan", "paper_title": "RL2: Fast reinforcement learning via slow reinforcement learning", "publication_date": "2016-11-16", "reason": "This paper introduces the concept of in-context learning, a core element of the OMIS approach that facilitates efficient opponent modeling."}, {"fullname_first_author": "Aditya Grover", "paper_title": "Learning policy representations in multiagent systems", "publication_date": "2018-07-01", "reason": "This paper lays groundwork on representation learning for opponent modeling, which OMIS improves by combining in-context learning and decision-time search."}, {"fullname_first_author": "He He", "paper_title": "Opponent modeling in deep reinforcement learning", "publication_date": "2016-07-01", "reason": "This paper is among the first to integrate deep learning techniques into opponent modeling, providing a foundation upon which OMIS builds and improves upon."}]}