{"references": [{"fullname_first_author": "Agarwal", "paper_title": "Flambe: Structural complexity and representation learning of low rank mdps", "publication_date": "2020-00-00", "reason": "This paper introduces the Flambe algorithm for low-rank MDPs, which is a foundational work that many of the other cited papers build upon."}, {"fullname_first_author": "Zhao", "paper_title": "Learning adversarial low-rank markov decision processes with unknown transition and full-information feedback", "publication_date": "2024-00-00", "reason": "This is the only prior work that studies adversarial low-rank MDPs with full information, which is a closely related setting to the setting studied in this paper."}, {"fullname_first_author": "Mhammedi", "paper_title": "Efficient model-free exploration in low-rank mdps", "publication_date": "2024-00-00", "reason": "This paper provides the first model-free and oracle-efficient algorithms for reward-free exploration in low-rank MDPs, which are used as subroutines in this paper's algorithms."}, {"fullname_first_author": "Cheng", "paper_title": "Improved sample complexity for reward-free reinforcement learning under low-rank mdps", "publication_date": "2023-00-00", "reason": "This paper significantly improves the sample complexity bounds for reward-free exploration in low-rank MDPs, which are used as subroutines in this paper's algorithms."}, {"fullname_first_author": "Jin", "paper_title": "Provably efficient reinforcement learning with linear function approximation", "publication_date": "2020-00-00", "reason": "This paper provides a foundational result for reinforcement learning with linear function approximation, which is used as a comparison point in this paper."}]}