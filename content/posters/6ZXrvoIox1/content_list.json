[{"type": "text", "text": "Beating Adversarial Low-Rank MDPs with Unknown Transition and Bandit Feedback ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Haolin Liu\\* University of Virginia srs8rh@virginia.edu ", "page_idx": 0}, {"type": "text", "text": "Zakaria Mhammedi\\* Google Research mhammedi@google.com ", "page_idx": 0}, {"type": "text", "text": "Chen-Yu Wei\\* University of Virginia chenyu.wei@virginia.edu ", "page_idx": 0}, {"type": "text", "text": "Julian Zimmert\\* Google Research zimmert@google.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider regret minimization in low-rank MDPs with fixed transition and adversarial losses. Previous work has investigated this problem under either fullinformation loss feedback with unknown transitions (Zhao et al., 2024), or bandit loss feedback with known transition (Foster et al., 2022). First, we improve the $\\mathrm{poly}(d,A,H)T^{5/6}$ regret bound of Zhao et al. (2024) to $\\mathrm{poly}(d,A,H)T^{2/3}$ for the full-information unknown transition setting, where $d$ is the rank of the transitions, $A$ is the number of actions, $H$ is the horizon length, and $T$ is the number of episodes. Next, we initiate the study on the setting with bandit loss feedback and unknown transitions. Assuming that the loss has a linear structure, we propose both model-based and model-free algorithms achieving poly $(d,A,H)T^{2/3}$ regret, though they are computationally inefficient. We also propose oracle-effcient modelfree algorithms with p $\\mathrm{{\\oly}}(d,A,H)T^{4/5}$ regret. We show that the linear structure is necessary for the bandit case\u2014without structure on the reward function, the regret has to scale polynomially with the number of states. This is contrary to the full-information case (Zhao et al., 2024), where the regret can be independent of the number of states even for unstructured reward function. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study online reinforcement learning (RL) in low-rank Markov Decision Processes (MDPs). Lowrank MDPs is a class of MDPs where the transition probability can be decomposed as an inner product between two low-dimensional features, i.e., $P(x^{\\bar{\\prime}}\\,|\\,x,a)=\\bar{\\phi}^{\\star}(x,a)^{\\intercal}\\mu^{\\star}(\\bar{x^{\\prime}})$ , where $P(x^{\\prime}\\,|\\,\\bar{x},a)$ is the probability of transitioning to state $x^{\\prime}$ when the learner takes action $a$ onstate $x$ , and $\\phi^{\\star}$ \uff0c $\\mu^{\\star}$ are two feature mappings. The ground truth features $\\phi^{\\star}$ and $\\mu^{\\star}$ are unknown to the learner. This setting has recently caught theoretical attention due to its simplicity and expressiveness (Agarwal et al., 2020; Uehara et al., 2021; Zhang et al., $2022\\mathbf{a}$ ; Cheng et al., 2023; Modi et al., 2024; Zhang et al., 2022b; Mhammedi et al., 2024a; Huang et al., 2023). In particular, since the learner does not know the features, it is necessary for the learner to perform feature learning (or representation learning) to approximate them. This allows low-rank MDPs to model the additional difficulty not present in traditional linear function approximation schemes where the features are given, such as in linear MDPs (Jin et al., 2020b) and in linear mixture MDPs (Ayoub et al., 2020). Since feature learning is an indispensable part of modern deep RL pipelines, low-rank MDP is a model that is closer to practice than traditional linear function approximation. ", "page_idx": 0}, {"type": "table", "img_path": "6ZXrvoIox1/tmp/66c54ffd8ac97f10523d9d05c4ced0a4e8270e8fab8456a9bf07037cbfb91661.jpg", "table_caption": ["Table 1: Comparison of adversarial low-rank MDP algorithms. $\\scriptscriptstyle\\mathcal{O}$ here hides factors of order $\\mathrm{poly}(d,|\\mathcal{A}|,\\log{T},\\log{|\\Phi||}\\Upsilon{|})$ . fAlgorithm 5 assumes access to $\\phi(x,a)$ for any $(\\phi,x,a)\\in\\Phi\\times\\mathcal{X}\\times\\mathcal{A}$ while other algorithms only require access to $\\phi(x,a)$ for any $(\\phi,a)\\in\\Phi\\times A$ on visited $x$ "], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "Most prior theoretical work on low-rank MDPs focuses on reward-free learning; this is a setting where instead of focusing on a particular reward function, the goal is to learn a model for the transitions (or, in the model-free setting, a small set of policies with good state cover), that enables policy optimization for any downstream reward functions. While this is a reasonable setup in some cases, in other applications, the learner can only obtain loss information from interactions with the environment, and only observes the loss on the state-actions that have been visited (i.e., bandit feedback). This introduces additional challenges to the learner. ", "page_idx": 1}, {"type": "text", "text": "Furthermore, in many online learning scenarios, the loss function may change over time, reflecting the non-stationary nature of the environment or task switches (Padakandla et al., 2020). This could be modeled by the adversarial MDP setting, where the loss function changes arbitrarily from one episode to the next, and the changes might even depend on the behavior of the learner. This setting is also extensively studied, but mostly restricted to tabular MDPs (Rosenberg and Mansour, 2019; Jin et al., 2020a; Shani et al., 2020; Luo et al., 2021) or traditional linear function approximation schemes (Cai et al., 2020; Lu0 et al., 2021; He et al., 2022; Zha0 et al., 2022; Sherman et al., 2023b; Dai et al., 2023; Liu et al., 2023). The work by Zha0 et al. (2024) initiated the study on adversarial MDPs in low-rank MDPs, but their work is restricted to full-information loss feedback. ", "page_idx": 1}, {"type": "text", "text": "When feature learning, bandit feedback, and adversarial losses are combined, the problem becomes highly challenging, and to the best of our knowledge their are no provably efficient algorithms to tackle this setting. In this work, we provide the first result for this combination. We hope that our result would bring new ideas to RL in practice, where all three elements are usually present simultaneously. We give several main results, targeting at either tighter regret (i.e., the performance gap between the optimal policy and the learner) or computational efficiency, as summarized in Table 1. Below we give a brief introduction for each of them. A more thorough related work review is in AppendixA. ", "page_idx": 1}, {"type": "text", "text": "$T^{2/3}$ -regret algorithm under full-information feedback (Algorithm 1). This setting is studied by the only prior work in adversarial low-rank MDPs (Zhao et al., 2024), and we greatly improve their $T^{5/6}$ regret bound to $T^{2/3}$ . Our algorithm begins with a model-based initial exploration phase to estimate the transition. It then performs policy optimization where the critic is the $Q$ value induced by the estimated transition and the full information loss. $T^{2/3}$ -regret model-based/model-free inefficient algorithm under bandit feedback (Algorithm 2, Algorithm 5). Algorithm 2 starts with a model-based initial exploration phase to learn an estimated transition, and then runs exponential weights over policy space for regret minimization in the second phase. To tackle bandit feedback, we construct a novel loss estimator that leverages the structure of low-rank MDP to perform accurate off-policy evaluation. Algorithm 5 starts with a different exploration phase, where it calls Vox (Mhammedi et al., 2023) to learn a policy cover; VoX is a model-free, reward-free exploration algorithm. After this initial exploratory phase, the algorithm also applies exponential weights and utilizes the same loss estimator as in Algorithm 2. However, due to its model-free nature, certain components of the estimator cannot be directly accessed and must be derived through specific optimizations. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "$T^{4/5}$ -regret model-free oracle-effcient algorithm under bandit feedback (Algorithm 3,Algo rithm 4). Algorithm 3 also starts with the model-free exploration algorithm Vox (Mhammedi et al., 2023) to learn a policy cover. After that, the algorithm operates in epochs; during epoch $k$ the algorithm commits to a fixed mixture of policies. This mixture consists of certain exploratory policies (based on the policy cover from the initial phase) and a policy computed using an online learning algorithm based on estimated $Q$ -functions from previous epochs (these serve as loss functions). Algorithm 4 deals with the much more challenging setting of an adaptive adversary with bandit feedback. Here, we make the additional assumption that the loss feature, which may be different from the feature of the low-rank decomposition, is given. The algorithm is similar to Algorithm 3 with key differences outlined in Section 4.3. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We study the episodic online reinforcement learning setting with horizon $H$ . We consider an MDP $\\mathcal{M}=(\\dot{\\mathcal{X}},\\mathcal{A},\\bar{P_{1:H}^{\\star}})$ where $\\mathcal{X}$ represents a countable (possibly infinite) state space2, $\\boldsymbol{\\mathcal{A}}$ is a finite action space, and $P_{h}^{\\star}:\\mathcal{X}\\times\\mathcal{A}\\to\\Delta(\\mathcal{X})$ denotes the transition kernel from layer $h$ to $h+1$ .We assume that the initial state $x_{1}\\in\\mathcal{X}$ is fixed for simplicity without loss of generality. For any policy $\\pi:{\\mathcal{X}}\\mapsto\\Delta(A)$ and arbitrary set of transition kernels $\\{\\stackrel{.}{P}_{h}\\}_{h\\in[H]}$ , we let $\\overline{{\\mathbb{P}}}^{P,\\pi}$ denote the law over $(x_{1},\\pmb{a}_{1},\\hdots,\\pmb{x}_{H},\\pmb{a}_{H})$ induced by the process of setting $\\pmb{x}_{1}=\\pmb{x}_{1}$ , sampling $\\begin{array}{r}{\\pmb{a}_{1}\\sim\\pi_{1}\\big(\\cdot\\mid\\pmb{x}_{1}\\big)}\\end{array}$ , then for $h=2,\\dots,H,\\pmb{x}_{h}\\sim P_{h-1}(\\cdot\\,|\\,\\pmb{x}_{h-1},\\pmb{a}_{h-1})$ and $\\begin{array}{r}{\\pmb{a}_{h}\\sim\\pi_{h}\\big(\\cdot\\,\\big|\\,\\pmb{x}_{h}\\big)}\\end{array}$ . We let $\\mathbb{E}^{P,\\pi}$ denote the corresponding expectations. Further, we let $d_{h}^{P,\\pi}(x):=\\mathbb{P}^{P,\\pi}[{\\pmb x}_{h}\\,=\\,x]$ denote the occupancy of $x\\in\\mathscr{X}$ . We also let $d_{h}^{P,\\pi}(x,a):=\\mathbb{P}^{P,\\pi}[{\\pmb x}_{h}=x,\\pmb{a}_{h}=a]$ Further, we let $\\mathbb{E}^{\\pi}\\,=\\,\\mathbb{E}^{P^{\\star},\\pi}$ \uff0c $\\mathbb{P}^{\\pi}=\\mathbb{P}^{P^{\\star},\\pi}$ , and $d_{h}^{\\pi}=d_{h}^{P^{\\star},\\pi}$ We use $\\pi\\circ_{h}\\pi^{\\prime}$ to denote a policy that follows $\\pi_{k}\\big(\\cdot\\big|\\cdot\\big)$ for $k<h$ and $\\pi_{k}^{\\prime}(\\cdot\\mid\\cdot)$ for $k\\geq h$ . Similarly, $\\pi\\circ_{h}\\pi^{\\prime}\\circ_{h^{\\prime}}\\pi^{\\prime\\prime}$ denotes a policy that follows $\\pi_{k}$ for $k<h$ \uff0c $\\pi_{k}^{\\prime}$ for $h\\le k<\\mathrm{\\bar{\\,}h^{\\prime}}$ and $\\pi_{k}^{\\prime\\prime}$ for $k>h^{\\prime}$ ", "page_idx": 2}, {"type": "text", "text": "We consider a learner interacting with the MDP $\\mathcal{M}$ for $T$ episodes with adversarial loss functions. Before the game starts, anoblivious adversary chooses the loss functions for all episodes $(\\ell_{1:H}^{t}:$ $\\mathcal{X}\\times\\mathcal{A}\\rightarrow[0,1])_{t=1}^{T}$ For each episode $t\\in[T]$ , the learner starts at state ${\\boldsymbol{x}}_{1}^{t}=\\boldsymbol{x}_{1}$ , then for each step $h\\in[H]$ within episode $t$ , the learner observes state ${\\pmb x}_{h}^{t}\\in\\mathcal X_{h}$ , chooses an action $\\pmb{a}_{h}^{t}\\in\\mathcal{A}$ , then suffers loss $\\ell_{h}^{t}(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t})$ . The state ${\\pmb x}_{h+1}^{t}$ at the next step is drawn from transition $P_{h}^{\\star}(\\cdot\\mid\\mathbf{x}_{h}^{t},\\mathbf{a}_{h}^{t})$ We consider banditfeedback seting where the learner could only observe the losses $\\ell_{1}^{t}\\big(\\pmb{x}_{1}^{t},\\pmb{a}_{1}^{t}\\big),\\dots,\\ell_{H}^{t}\\big(\\pmb{x}_{H}^{t},\\pmb{a}_{H}^{t}\\big)$ at the visited state-action pairs. ", "page_idx": 2}, {"type": "text", "text": "We let $\\Pi:=\\{\\pi:\\mathcal{X}\\rightarrow\\Delta(A)\\}$ denote the set of Markovian policies. For policy $\\pi\\in\\Pi$ ,loss $\\ell$ and transition kernels $P_{1:H}$ wedenoteby $Q_{h}^{P,\\pi}(\\cdot,\\cdot;\\ell)$ the state-action alue function (a.k.a. $Q$ function) at step $h\\in[H]$ with respect to the transitions $P_{1:H}$ and loss $\\ell$ ; that is ", "page_idx": 2}, {"type": "equation", "text": "$$\nQ_{h}^{P,\\pi}(x,a;\\ell):=\\mathbb{E}^{P,\\pi}\\left[\\sum_{s=h}^{H}\\ell_{s}(x_{s}^{t},a_{s}^{t})\\mid x_{h}=x,\\pmb{a}_{h}=a\\right],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "for all $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$ We let $V_{h}^{P,\\pi}(x;\\ell):=\\operatorname*{max}_{a\\in\\mathcal{A}}Q_{h}^{P,\\pi}(x,a;\\ell)$ be the corresponding state value function at layer $h$ . Further, we write $Q_{h}^{\\pi}(\\cdot,\\cdot;\\ell):=Q_{h}^{P^{\\star},\\pi}(\\cdot,\\cdot;\\ell)$ and $V_{h}^{\\pi}(\\cdot;\\ell):=V^{P^{\\star},\\pi}(\\cdot;\\ell)$ ", "page_idx": 2}, {"type": "text", "text": "For all of our algorithms except for Algorithm 4, we aim to construct (possibly randomized) policies $\\{\\pi^{t}\\}_{t\\in[T]}$ that ensure a sublinear pseudo-regret with respect to the best-fixed policy; that is, ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}:=\\operatorname*{min}_{\\pi\\in\\Pi}\\mathrm{Reg}_{T}(\\pi)\\quad\\mathrm{where}\\quad\\mathrm{Reg}_{T}(\\pi):=\\mathbb{E}\\left[\\sum_{t=1}^{T}V_{1}^{\\pi^{t}}(x_{1};\\ell^{t})-\\sum_{t=1}^{T}V_{1}^{\\pi}(x_{1};\\ell^{t})\\right].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "ForAlgorithm 4, we bound the standard regret ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{Reg}}}_{T}:=\\sum_{t=1}^{T}V_{1}^{\\pi^{t}}\\big(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\big)-\\operatorname*{min}_{\\pi\\in\\Pi}\\sum_{t=1}^{T}V_{1}^{\\pi}\\big(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\big)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with high probability. This allows it to handle adaptive adversary. ", "page_idx": 3}, {"type": "text", "text": "Throughout, we will assume that the MDP $\\mathcal{M}$ is low-rank with unknown feature maps $\\phi_{h}^{\\star}$ and $\\mu_{h}^{\\star}$ ", "page_idx": 3}, {"type": "text", "text": "Assumption 2.1 (Low-Rank MDP). There exist (unknown) features maps $\\phi_{1:H}^{\\star}:\\mathcal{X}\\times\\mathcal{A}\\rightarrow\\mathbb{R}^{d}$ and $\\mu_{1:H}^{\\star}:\\mathcal{X}\\rightarrow\\mathbb{R}^{d}$ suchthatfor all $h\\in[H-1]$ and $(x,a,x^{\\prime})\\in\\mathcal{X}\\times\\mathcal{A}\\times\\mathcal{X}$ ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{P}[{\\pmb x}_{h+1}=x^{\\prime}\\mid{\\pmb x}_{h}=x,{\\pmb a}_{h}=a]=\\phi_{h}^{\\star}(x,a)^{\\top}\\mu_{h+1}^{\\star}(x^{\\prime}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Furthermore, for all $h\\in[H],$ . the feature maps $\\mu_{h}^{\\star}$ and $\\phi_{h}^{\\star}$ are such that $\\operatorname*{sup}_{(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\|\\phi_{h}^{\\star}(x,a)\\|\\leq1$ and $\\begin{array}{r}{\\|\\textstyle\\sum_{x\\in{\\mathcal{X}}}g(x)\\cdot\\mu_{h}^{\\star}(x)\\|\\leq\\sqrt{d},}\\end{array}$ for all $g:\\mathcal{X}\\rightarrow[0,1]$ ", "page_idx": 3}, {"type": "text", "text": "Loss function under bandit feedback. For bandit feedback setting, we make the following additional linear assumption on the losses; in the sequel, we will argue that this is necessary to avoid a sample complexity scaling with the number of states. This linear loss assumption also appears in Ren et al. (2022); Zhang et al. (2022a) for stochastic low-rank MDPs. Note that for the full-information feedback setting, such an assumption is not required. ", "page_idx": 3}, {"type": "text", "text": "Assumption 2.2 (Loss Representation). For any $t\\in[T]$ and layer $h$ there is a vector $g_{h}^{t}\\in\\ensuremath{\\mathbb{B}}_{d}(1)$ such that the loss $\\ell_{h}^{t}(x,a)$ at round $t$ satisfies: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall(x,a)\\in\\mathcal{X}\\times\\mathcal{A},\\quad\\ell_{h}^{t}(x,a)=\\phi_{h}^{\\star}(x,a)^{\\top}g_{h}^{t}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We note that there is no loss of generality in assuming that the losses are expressed using the same features $\\phi_{1:H}^{\\star}$ as the low-rank structure in (4). This is because if the losses have different features, we can simply combine these features with the low-rank features, and redefine $\\phi^{\\star}$ accordingly. For the bulk of ouresults (and as sted in the prequel, we willassume that the loses $\\{\\ell_{h}^{t}(\\cdot,\\cdot)\\}_{h\\in[H],t\\in[T]}$ (or equivalently $\\{g_{h}^{t}\\}_{h\\in[H],t\\in[T]}$ under Assumption 2.2) are chosen by an aversary before the start of the game (i.e. oblvious adversary). In Section 4.3, we will present a model-free, oracle-efficient algorithm for an adaptive adversary. ", "page_idx": 3}, {"type": "text", "text": "Function approximation.  So far, Assumption 2.1 and Assumption 2.2 are in line with assumptions made in the linear MDP setting (Jin et al., 2020b). However, unlike in linear MDPs, we do not assume that the feature maps $\\phi_{1:H}^{\\star}$ are known. To facilitate representation learning and ultimately a sublinear regret, we need to make realizability assumptions. In particular, in the model-free setting, we assume we have a function class $\\Phi$ that contains the true features $\\phi_{1:H}^{\\star}$ . In the model-based setting,. we additionally assume access to a function clas $\\Upsilon$ that contains the feature maps $\\mu_{1:H}^{\\star}{}^{3}$ . We will formalize these assumptions in their corresponding sections in the sequel. ", "page_idx": 3}, {"type": "text", "text": "Other notation. For $\\psi:\\Pi\\to\\mathbb{R}^{d}$ , we define ${\\tt J o h n}(\\psi,\\Pi)$ as a distribution $\\mu\\in\\Delta(\\Pi)$ such that $\\|\\psi(\\pi)\\|_{G^{-1}}^{2}\\leq\\,d$ for all $\\pi\\,\\in\\,\\Pi$ ,where $\\begin{array}{r}{G\\,=\\,\\sum_{\\pi\\in\\Pi}\\mu(\\pi)\\cdot\\psi(\\pi)\\psi(\\pi)^{\\intercal}}\\end{array}$ . This is the standard John's exploration or $G$ -optimal design, which always exists. ", "page_idx": 3}, {"type": "text", "text": "3  Model-based Algorithms for Adversarial Low-rank MDPs ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we discuss adversarial low-rank MDPs under model-based assumption. The modelbased assumption is formalized in the Assumption 3.1 below. This assumption is standard which also appears in prior works on model-based learning in low-rank MDPs (Agarwal et al., 2020; Uehara et al., 2021; Zhang et al., 2022a; Cheng et al., 2023; Zha0 et al., 2024). ", "page_idx": 3}, {"type": "text", "text": "Assumption 3.1 (Model-based assumption). The learner has access to two model spaces $\\Phi$ and $\\Upsilon$ such that $\\phi^{\\star}\\,\\in\\,\\Phi$ and $\\mu^{\\star}\\,\\in\\,\\Upsilon$ .Moreover, for any $\\phi\\,\\in\\,\\Phi$ $\\mu\\,\\in\\,\\Upsilon$ ,and $h\\,\\in\\,[2\\ldots H]$ , we have $\\mathrm{sup}_{(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\left\\|\\phi_{h-1}(x,a)\\right\\|\\leq1,$ $\\textstyle\\sum_{x^{\\prime}\\in{\\mathcal{X}}}\\phi_{h-1}(x,a)^{\\top}\\mu_{h}(x^{\\prime})=1$ and $\\begin{array}{r}{\\|\\sum_{x\\in\\mathcal{X}}g(x)\\cdot\\mu_{h}(x)\\|\\leq\\sqrt{d},}\\end{array}$ for all $g:\\mathcal{X}\\to[0,1]$ ", "page_idx": 3}, {"type": "text", "text": "3.1 Adversarial Low-rank MDPs with Full Information ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We first discuss learning adversarial low-rank MDPs with full information and model-based assumption. This setting aligns with Zhao et al. (2024), and our Algorithm 1 successfully improves their regret from $T^{5/6}$ to $T^{2/3}$ ", "page_idx": 3}, {"type": "text", "text": "1: Let $\\begin{array}{r}{\\eta=\\frac{1}{H\\sqrt{T}}}\\end{array}$ \uff0c $\\epsilon=\\left(H d^{2}|A|(d^{2}+|A|)\\right)^{\\frac{1}{3}}T^{-\\frac{1}{3}}$ and $T_{0}=\\widetilde{\\mathcal{O}}\\big(\\epsilon^{-2}H^{3}d^{2}|\\pmb{A}|(d^{2}+|\\pmb{A}|)\\big)$ Let $\\pi^{1}$ be a uniform policy.   \n2: Run (Cheng et al., 2023, Algorithm 1) for $T_{0}$ episodes and get outputs $\\hat{\\phi}\\in\\Phi,\\hat{\\mu}\\in\\Upsilon$   \n3: Define transitions $\\widehat{P}_{1:H-1}$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\widehat{P}_{h}(x^{\\prime}\\,|\\,x,a)=\\widehat{\\phi}_{h}(x,a)^{\\top}\\widehat{\\mu}_{h+1}(x^{\\prime}),\\quad\\forall(x,a,x^{\\prime})\\in\\mathcal{X}\\times\\mathcal{A}\\times\\mathcal{X}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "4: for $t=T_{0}+1,T_{0}+2,\\ldots,T$ do ", "page_idx": 4}, {"type": "text", "text": "5: Execute policy $\\pi^{t}$ and observe trajectory $(x_{1:H},a_{1:H})$ and full information loss $\\ell^{t}$   \n6: Update policy for all $h\\in[H]$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\pi_{h}^{t+1}(a\\,|\\,x)\\propto\\exp\\left(-\\eta\\sum_{i=1}^{t}\\widehat{Q}_{h}^{i}(x,a)\\right)\\mathrm{~where~}\\widehat{Q}_{h}^{t}(x,a)=Q_{h}^{\\widehat{P},\\pi^{t}}(x,a;\\ell^{t}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "7: end for ", "page_idx": 4}, {"type": "text", "text": "As argued in Zhao et al. (2024), the challenge of learning adversarial low-rank MDPs lies in the need for balancing exploration and exploitation both in representation learning and policy optimization over adversarial losses. To tackle this doubled exploration and exploitation challenge, the algorithm of Zhao et al. (2024) performs simultaneous representation learning and policy optimization. With a closer look at their analysis, we find that there is a drawback of this approach: because their algorithm handles the two tasks at the same time, it spends less exploration for representation learning in the early phase of the algorithm. This results in larger error in the estimated Q-values (i.e., critic) fed to policy optimization, and worsens the overall regret. ", "page_idx": 4}, {"type": "text", "text": "To address this issue, we design Algorithm 1 as a simple two-phase algorithm that separates representation learning and policy optimization. In the first phase, following Cheng et al. (2023), we perform optimal reward-free exploration for low-rank MDPs to estimate the transition. The resulted estimator, $\\bar{\\widehat{P}}$ , is able to accurately approximate the true transition and give accurate $\\mathrm{^Q}$ value estimators for any policy. The more accurate $Q\\cdot$ -estimator allows for more effective policy optimization in the second phase. Theorem 3.1 shows the guarantee of Algorithm 1 where $\\widetilde O$ hides logarithmic factors of $d,H,T,|\\Phi||\\Upsilon|$ ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.1. Algorithm 1 ensures $\\mathrm{Reg}_{T}\\leq\\widetilde{\\mathcal{O}}\\,\\Big(H^{3}\\left(d^{2}+|{\\cal A}|\\right)T^{\\frac{2}{3}}\\Big).$ ", "page_idx": 4}, {"type": "text", "text": "The proof for Theorem 3.1 is given in Appendix B. Zhao et al. (2024) also constructs a lower bound $\\Omega\\left(H{\\sqrt{d|A|T}}\\right)$ for this settings. Thus,the poly $\\left(\\left\\vert\\mathcal{A}\\right\\vert\\right)$ -dependence is unavoidable. ", "page_idx": 4}, {"type": "text", "text": "3.2 Model-Based, Computationally Inefficient Algorithm for Bandit Feedback ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, following Assumption 3.1, we introduce the first (model-based) algorithm (Algorithm 2) for adversarial low-rank MDPs with bandit feedback and sublinear regret. Compared with linear MDPs, the key challenge for more general low-rank MDPs is to construct a proper loss estimator. For linear MDP, since the feature is known, the loss estimator closely resembles that of linear bandits. However, low-rank MDPs lack such structural simplicity, making standard loss estimators invalid. To overcome this challenge, we propose a new loss estimator that works for any loss function based on off-policy evaluation and the low-rank structure of transition. In this section, $\\widetilde O$ hides logarithmic factors of $d,H,T,|\\Phi||\\Upsilon|$ ", "page_idx": 4}, {"type": "text", "text": "In Algorithm 2, we first conduct an initial representation learning phase to establish accurate transition estimator $\\widehat{P}$ and its corresponding features $\\hat{\\phi}$ and $\\hat{\\mu}$ based on reward-free exploration algorithms in Cheng et al. (2023). Then, in the second phase, we use exponential weights to maintain a distribution over the policy space $\\Pi^{\\prime}$ where we mix a uniform policy with $\\Pi$ to enhance exploration. At every round $t$ , a behavior policy $\\pi^{t}$ is chosen from the current policy distribution, and we use the data collected by $\\pi^{t}$ to estimate the value for every $\\pi\\in\\Pi^{\\prime}$ . The success of such off-policy evaluation is based on the following observations of low-rank MDP. Using the low-rank transition structure, for $h\\geq2$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\forall\\pi\\in\\Pi,\\quad d_{h}^{\\pi}(x)=\\phi_{h-1}^{\\star}(\\pi)^{\\top}\\mu_{h}^{\\star}(x),\\quad\\mathrm{where}\\quad\\phi_{h-1}^{\\star}(\\pi):=\\mathbb{E}^{\\pi}\\big[\\phi_{h-1}^{\\star}(x_{h-1},a_{h-1})\\big].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Input: A policy class $\\Pi$ ", "page_idx": 5}, {"type": "text", "text": "1: Set $\\epsilon=T^{-{\\frac{1}{3}}}$ \uff0c $\\gamma=T^{-\\frac{1}{3}}$ \uff0c $\\beta=T^{-\\frac{1}{3}}$ \uff0c $\\eta=(4H d|A|)^{-1}T^{-\\frac{2}{3}}$ , and $T_{0}=\\widetilde{\\mathcal{O}}\\big(\\epsilon^{-2}H^{3}d^{2}|A|(d^{2}+|A|)\\big)$   \n2: Run (Cheng et al., 2023, Algorithm 1) for $T_{0}$ episodes and get outputs $\\hat{\\phi}\\in\\Phi,\\hat{\\mu}\\in\\Upsilon$   \n3: Define transitions $\\widehat{P}_{1:H-1}$ as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widehat{P}_{h}(x^{\\prime}\\,|\\,x,a)=\\widehat{\\phi}_{h}(x,a)^{\\top}\\widehat{\\mu}_{h+1}(x^{\\prime}),\\quad\\forall(x,a,x^{\\prime})\\in\\mathcal{X}\\times\\mathcal{A}\\times\\mathcal{X}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "4: For all $h\\in[H-1]$ define $\\begin{array}{r}{\\hat{\\phi}_{h}(\\pi)=\\sum_{(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\hat{d}_{h}^{\\pi}(x,a)\\cdot\\hat{\\phi}_{h}(x,a)}\\end{array}$ , where $\\hat{d}_{h}^{\\pi}:=d_{h}^{\\widehat{P},\\pi}$   \n5: Define the policy space $\\Pi^{\\prime}=\\left\\{\\pi^{\\prime}:\\;\\exists\\pi\\in\\Pi\\right\\}$ \uff0c $\\pi_{h}^{\\prime}(\\cdot\\mid x)=(1-\\beta)\\pi_{h}(\\cdot\\mid x)+\\beta/\\vert A\\vert,\\,\\,\\,\\forall x,h\\}.$   \n6: for $t=T_{0}+1$ $T_{0}+2,\\ldots,T$ do   \n7: Define $\\begin{array}{r}{p^{t}(\\pi)\\propto\\exp\\left(-\\eta\\sum_{i=1}^{t-1}\\left(\\hat{\\ell}^{i}(\\pi)-b^{i}(\\pi)\\right)\\right)}\\end{array}$ , for all $\\pi\\in\\Pi^{\\prime}$   \n8: Let $\\begin{array}{r}{\\rho^{t}(\\pi)=(1-\\gamma)p^{t}(\\pi)+\\frac{\\gamma}{H-1}\\sum_{h=1}^{H-1}J_{h}}\\end{array}$ ,where $J_{h}=\\mathsf{J o h n}\\big(\\hat{\\phi}_{h}\\big(\\cdot\\big),\\Pi^{\\prime}\\big)$ -/ John as in s 2   \n9: Execute policy $\\pi^{t}\\sim\\rho^{t}$ and observe trajectory $(\\pmb{x}_{1:H}^{t},\\pmb{a}_{1:H}^{t})$ and losses $\\pmb{\\ell}_{h}^{t}=\\ell_{h}^{t}(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t})$   \n10: Define $\\begin{array}{r}{\\Sigma_{h}^{t}=\\sum_{\\pi\\in\\Pi^{\\prime}}\\rho^{t}(\\pi)\\cdot\\hat{\\phi}_{h}(\\pi)\\hat{\\phi}_{h}(\\pi)^{\\top},b^{t}(\\pi)=\\sqrt{d}H\\epsilon\\cdot\\sum_{h=1}^{H-1}\\|\\hat{\\phi}_{h}(\\pi)\\|_{(\\Sigma_{h}^{t})^{-1}}}\\end{array}$ and ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{\\ell}^{t}(\\pi)=\\frac{\\pi_{1}(a_{1}^{t}\\mid x_{1}^{t})}{\\pi_{1}^{t}(a_{1}^{t}\\mid x_{1}^{t})}\\ell_{1}^{t}+\\sum_{h=2}^{H}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\frac{\\pi_{h}(a_{h}^{t}\\mid x_{h}^{t})}{\\pi_{h}^{t}(a_{h}^{t}\\mid x_{h}^{t})}\\ell_{h}^{t}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "11: end for ", "page_idx": 5}, {"type": "text", "text": "Thus, using the definition of the $V$ -function from Section 2, we have for any loss function $\\ell$ and $\\pi$ ", "page_idx": 5}, {"type": "equation", "text": "$$\nV_{1}^{\\pi}(x_{1};\\ell)-\\mathbb{E}\\!\\left[\\ell_{1}(x_{1},a_{1})\\right]=\\sum_{h=2}^{H}\\sum_{(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\phi_{h-1}^{\\star}(\\pi)^{\\top}\\mu_{h}^{\\star}(x)\\pi_{h}(a\\mid x)\\cdot\\ell_{h}(x,a).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Letting $\\Lambda_{h}^{t}:=\\,(\\mathbb{E}_{\\pmb{\\pi}^{t}\\sim p^{t}}\\left[\\phi_{h}^{\\star}(\\pmb{\\pi}^{t})\\phi_{h}^{\\star}(\\pmb{\\pi}^{t})^{\\top}\\right])^{-1}$ and ingnoring the loss term $\\mathbb{E}[\\ell_{1}(x_{1},\\pmb{a}_{1})]$ from the first step (this term can easily be treated as in a bandit setting with $H=1$ ), we have for all $\\pi\\in\\Pi^{\\prime}$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\gamma_{1}^{\\pi}(x_{1};\\ell)=\\mathbb{E}_{\\pi^{t}\\sim p^{t}}\\left[\\displaystyle\\sum_{h=2}^{H}\\sum_{(x,a)\\in\\mathcal{X}\\times A}\\phi_{h-1}^{\\star}(\\pi)^{\\top}\\Lambda_{h-1}^{t}\\phi_{h-1}^{\\star}(\\pi^{t})\\phi_{h-1}^{\\star}(\\pi^{t})^{\\top}\\mu_{h}^{\\star}(x)\\pi_{h}(a\\mid x)\\cdot\\ell_{h}(x,a)\\right],}\\\\ &{\\quad\\quad\\quad=\\mathbb{E}_{\\pi^{t}\\sim p^{t}}\\left[\\displaystyle\\sum_{h=2}^{H}\\sum_{x,a}\\phi_{h-1}^{\\star}(\\pi)^{\\top}\\Lambda_{h-1}^{t}\\phi_{h-1}^{\\star}(\\pi^{t})\\cdot d_{h}^{\\pi^{t}}(x)\\pi_{h}^{t}(a\\mid x)\\frac{\\pi_{h}(a\\mid x)}{\\pi_{h}^{t}(a\\mid x)}\\cdot\\ell_{h}(x,a)\\right],}\\\\ &{\\quad\\quad\\quad=\\mathbb{E}_{\\pi^{t}\\sim p^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\displaystyle\\sum_{h=2}^{H}\\phi_{h-1}^{\\star}(\\pi)^{\\top}\\Lambda_{h-1}^{t}\\phi_{h-1}^{\\star}(\\pi^{t})\\cdot\\frac{\\pi_{h}(a_{h}\\mid x_{h})}{\\pi_{h}^{t}(a_{h}\\mid x_{h})}\\cdot\\ell_{h}(x_{h},a_{h})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Thus, for all $\\ell$ and $\\pi$ $\\begin{array}{r}{\\sum_{h=2}^{H}\\phi_{h-1}^{\\star}(\\pi)^{\\top}\\Lambda_{h-1}^{t}\\phi_{h-1}^{\\star}(\\pi^{t})\\cdot\\pi_{h}(a_{h}\\mid x_{h})\\pi_{h}^{t}(a_{h}\\mid x_{h})^{-1}\\cdot\\ell_{h}(x_{h},a_{h})}\\end{array}$ for $\\pi^{t}\\,\\sim\\,p^{t}$ and $({\\bf x}_{h},{\\bf a}_{h})\\;\\sim\\;d_{h}^{\\pi^{t}}$ is an unbiased estimator of $V_{1}^{\\pi}(x_{1},\\ell)$ . However, $\\phi_{h-1}^{\\star}(\\pi)$ is not accessible because both the true feature $\\phi^{\\star}$ and occupancy $d^{\\pi}$ for the true transition are unknown. Thus, our estimator incorporates the learned feature $\\bar{\\hat{\\phi}}$ and the occupancy of $\\widehat{P}$ instead as shown in Line 4 and Line 10. Utilizing estimated features and transition could introduce additional bias but the initial representation learning already ensures such bias is small enough to tackle. We compensate for the bias by incorporating an exploration bonus $b^{t}(\\pi)$ in exponential weights. To further encourage exploration, we additionally perform John's exploration together with exponential weights when selecting behavior policies. The main guarantee of Algorithm 2 is given in Theorem 3.2. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.2. Algorithm 2 achieves ${\\mathrm{Reg}}_{T}(\\pi)\\leq\\widetilde{\\mathcal{O}}\\left(d^{2}H^{3}|A|(d^{2}+|A|)T^{2/3}\\log|\\Pi|\\right)f o r\\,a n y$ $\\pi\\in\\Pi$ ", "page_idx": 5}, {"type": "text", "text": "Note that the guarantee in Theorem 3.2 only holds for policy $\\pi\\in\\Pi$ . To ensure our regret bound is meaningful, at least a near-optimal policy should be contained in the given policy set $\\Pi$ . In general, the size of such a policy set would grow exponentially with the number of states (e.g. covering of all Markovian policies), making the regret have polynomial dependence on the number of states. In Theorem 3.3, we show that even for low-rank MDPs, if the loss function lacks structure, the regret cannot avoid polynomial dependence on the number of states. The detailed construction for this lower-bound is given in Appendix H. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.3. There exists a low-rank MDP with $|{\\mathcal{X}}|$ States, $|{\\mathcal{A}}|$ actions and sufciently large $T$ With unstructured losses such that any agent suffers at least regret of $\\Omega({\\sqrt{|{\\mathcal{X}}||A|T}})$ ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.3 shows that under bandit feedback, in general, we could not gain too much from low-rank transition structure compared with tabular MDPs. This contrasts with the $\\Omega({\\sqrt{\\left|A\\right|}}T)$ lowerbound in the full information settings (Zhao et al. (2024). To get rid of any dependence on the number of states, we additionally introduce Assumption 2.2 to impose linear structure on the loss function. Unlike linear MDPs that require the loss feature to be known, our algorithm can even handle linear loss with unknown feature, since our Algorithm 2 never explicitly uses the loss feature. The linear structure is only used to control the size of the candidate policy class in the analysis (i.e., making $\\log\\left|\\Pi\\right|$ irrelevant to the number of states). Specifically, when both loss and transition are linear, the Q-function is also linear, making it sufficient to consider the following linear policy space: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Pi_{\\mathrm{lin}}=\\left\\{\\pi:\\mathcal{X}\\to A\\;\\Big|\\;\\pi_{h}(a\\,|\\,x)=\\mathbb{I}\\Big\\{a=\\underset{a\\in\\mathcal{A}}{\\mathrm{argmin}}\\,\\phi_{h}(x,a)^{\\top}\\theta_{h}\\Big\\},\\;h\\in[H],\\;\\|\\theta_{h}\\|_{2}\\leq\\sqrt{d}H T,\\;\\phi\\in\\Phi\\right\\}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The $\\textstyle{\\frac{1}{T}}$ -coverof $\\Pi_{\\mathrm{lin}}$ Oonlyhavesize $|\\Phi|\\cdot T^{\\mathcal{O}(d)}$ following standard arguments (e.g, Exercise 27.6 of Lattimore and Szepesvari (2020)) and if we feed it into Algorithm 2, our regret could avoid dependece on the size of state space as shown in Corollary 3.1. ", "page_idx": 6}, {"type": "text", "text": "Corollary 3.1. If the loss function satisfies Assumption 2.2, applying Algorithm 2 with II as the $\\textstyle{\\frac{1}{T}}$ -coverof $\\Pi_{\\mathrm{in}}$ ensures $\\mathrm{Reg}_{T}\\leq{\\widetilde{\\mathcal{O}}}\\left(d^{3}H^{3}|A|(d^{2}+|{\\dot{A}}|)T^{2/3}\\right)$ ", "page_idx": 6}, {"type": "text", "text": "4  Model-free Algorithms for Adversarial Low-rank MDPs ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we consider the model-free setting, where we only assume access to a feature class $\\Phi$ that contains the true feature map $\\phi^{\\star}$ ", "page_idx": 6}, {"type": "text", "text": "Assumption 4.1 (Model-free realizability). The learner has access to a function class $\\Phi$ suchthat ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\phi^{\\star}\\in\\Phi\\qquad a n d\\qquad\\operatorname*{sup}_{\\phi\\in\\Phi\\;(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\left\\|\\phi(x,a)\\right\\|\\leq1.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This is a standard assumption in the context of model-free RL (Modi et al., 2024; Zhang et al., 2022b; Mhammedi et al., 2024a). We note that having access to the function class $\\Phi$ alone (instead of both $\\Phi$ and $\\Upsilon$ as in Assumption 3.1) is not sufficient to model the transition probabilities (unlike in the model-based case). This makes the model-free setting much more challenging; in fact, until the recent work by Mhammedi et al. (2023) there were no model-free, oracle-efficient algorithms for this setting that do not require any additional structural assumptions on the MDP. ", "page_idx": 6}, {"type": "text", "text": "4.1 Model-free, Inefficient Algorithm for Bandit Feedback ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Our first algorithm follows the same structure as Algorithm 2 but incorporates a model-free initial exploration phase introduced by Mhammedi et al. (2023). Unlike the model-based exploration phase, which directly provides an estimated transition, the model-free exploration phase outputs a policy cover. This policy cover can be combined with the optimization in Algorithm 1 of Liu et al. (2023) to solve the expected feature $\\hat{\\phi}$ , which is then used in the loss estimator in Line 10 of Algorithm 2. The algorithm, summarized in Algorithm 5, is inefficient but achieves $T^{2/3}$ regret. More details and proofs can be found in Appendix D. ", "page_idx": 6}, {"type": "text", "text": "4.2 Model-free, Oracle Efficient Algorithm for Bandit Feedback (Oblivious Adversary) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now descibe the key component of our efficient model-free algorithm (Algorithm 3). ", "page_idx": 6}, {"type": "text", "text": "Exploration phase and policy cover. Similar to algorithms in the previous section, Algorithm 3 begins with a reward-free exploratorion phase; Line 2 of Algorithm 3. However, unlike in the previous sections where the role of this exploration phase was to learn a model for the transition probabilities, here the goal is to compute a, so called, policy cover which is a small set of policies that can be used to effectively explore the state space. ", "page_idx": 6}, {"type": "text", "text": "Definition 4.1 (Approximate policy cover). For $\\alpha,\\varepsilon\\in(0,1]$ and $h\\in[H]$ a subset $\\Psi\\subseteq\\Pi$ is an $(\\alpha,\\varepsilon)$ -policycoverfor layerh $i f$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi\\in\\Psi}d_{h}^{\\pi}(x)\\geq\\alpha\\cdot\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi}d_{h}^{\\pi^{\\prime}}(x),\\ \\ \\ f o r\\,a l l\\,x\\in\\mathcal{X}\\,s u c h\\,t h a t\\,\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi}d_{h}^{\\pi^{\\prime}}(x)\\geq\\varepsilon\\cdot\\|\\mu_{h}^{\\star}(x)\\|.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Input: Number of rounds $T$ , feature class $\\Phi$ , confidence parameter $\\delta\\in(0,1)$   \n1: Set $\\varepsilon\\gets T^{-1/3}$ \uff0c $N_{\\mathrm{reg}}\\leftarrow T^{2/3}$ $\\nu\\leftarrow N_{\\mathrm{reg}}^{-1/2}$ and $T_{0}\\gets\\varepsilon^{-2}A d^{13}H^{6}\\log(\\Phi/\\delta)$   \n2: Get $\\Psi_{1:H}^{\\mathrm{cov}}\\leftarrow\\nabla\\mathsf{o X}(\\Phi,\\varepsilon,\\delta)$ .// Compute policy cover with VoX (Mhammedi et al., 2023).   \n3: for $k=1,\\ldots,(T-T_{0})/N_{\\mathrm{reg}}\\;\\mathbf{do}$   \n4: Define $\\begin{array}{r}{\\widehat{\\pi}_{h}^{(k)}(a\\mid x)\\propto\\exp\\left(-\\eta\\sum_{s<k}\\widehat{Q}_{h}^{(s)}(x,a)\\right)}\\end{array}$ 00 $h\\in[H]$   \n5: for $t=T_{0}+\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+1$ $T_{0}+k\\cdot N_{\\mathrm{reg}}$ do   \n6: Sample variables $\\zeta^{t}\\sim\\operatorname{Ber}(\\nu),h^{t}\\sim\\operatorname{unif}\\left([H]\\right)$ , and $\\pi^{t}\\sim\\operatorname{unif}\\left(\\Psi_{h^{t}}^{\\mathsf{c o v}}\\right)$   \n7: Set $\\widehat{\\boldsymbol{\\pi}}^{t}=\\mathbb{I}\\big\\{\\zeta^{t}=0\\big\\}\\cdot\\widehat{\\boldsymbol{\\pi}}^{(k)}+\\mathbb{I}\\big\\{\\zeta^{t}=1\\big\\}\\cdot\\boldsymbol{\\pi}^{t}\\circ_{h^{t}}\\pi_{\\mathrm{unif}}\\circ_{h^{t}+1}\\widehat{\\boldsymbol{\\pi}}^{(k)}.$   \n8: Execute $\\widehat{\\pi}^{t}$ , and observe trajectory $(x_{1}^{t},\\pmb{a}_{1}^{t},\\ldots,\\pmb{x}_{H}^{t},\\pmb{a}_{H}^{t})$   \n9: For $h\\in[H]$ , observe loss $\\pmb{\\ell}_{h}^{t}:=\\ell_{h}^{t}(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t})$ ", "page_idx": 7}, {"type": "text", "text": "10: end for ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "11: For $h\\in[H]$ and $\\mathcal{Z}^{(k)}=\\left\\{T_{0}+\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+1,\\,\\,.\\,.\\,.\\,,\\,\\,T_{0}+k\\cdot N_{\\mathrm{reg}}\\right\\}$ compute $\\big(\\hat{\\phi}_{h}^{(k)},\\hat{\\theta}_{h}^{(k)}\\big)$$(\\hat{\\phi}_{h}^{(k)},\\hat{\\theta}_{h}^{(k)})\\gets\\operatorname*{argmin}_{(\\phi,\\theta)\\in\\Phi\\times\\mathbb{B}_{d}(H\\sqrt{d})}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\left(\\phi_{h}(x_{h}^{t},a_{h}^{t})^{\\top}\\theta-\\sum_{s=h}^{H}\\ell_{s}^{t}\\right)^{2}\\cdot\\mathbb{I}\\{\\zeta^{t}=0\\mathrm{~or~}h^{t}\\leq h\\}.$ (9)12: Set $\\widehat{Q}_{h}^{(k)}(x,a)=\\hat{\\phi}_{h}^{(k)}(x,a)^{\\top}\\hat{\\theta}_{h}^{(k)}$ , for all $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$", "page_idx": 7}, {"type": "text", "text": "13: end for ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In Line 2, Algorithm 3 calls $\\mathtt{V o X}$ (Mhammedi et al., 2023), a reward-free and model-free exploration algorithm to compute $(1/(8A d),\\varepsilon)$ -policy covers $\\Psi_{1}^{\\mathrm{cov}},\\dots,\\Psi_{H}^{\\mathrm{cov}}$ for layers $1,\\dots,H$ , respectively, with $|\\Psi_{h}|=d$ for all $h\\in[H]$ . This call to $\\mathtt{V o X}$ requires ${\\cal O}(1/\\varepsilon^{2})$ episodes; see the guarantee of $\\mathtt{V o X}$ in Lemma G.1. After this initial phase, the algorithm operates in epochs, each consisting of $N_{\\mathrm{reg}}\\in\\mathbb{N}$ episodes, where in each epoch $\\bar{k}\\in[K]$ , the algorithm commits to executing policies sampled from a fixed policy distribution $\\rho^{(k)}\\in\\Delta(\\Pi)$ with support on the policy covers $\\Psi_{1:H}^{\\mathrm{cov}}$ and a policy $\\widehat{\\pi}^{(k)}$ specified by an online learning algorithm. Next, we describe in more detail how $\\rho^{(k)}$ is constructed and motivatethe elementsof is construction starting with the oline learming plicies $\\{\\widehat{\\pi}^{(k)}\\}_{k\\in[K]}$ ", "page_idx": 7}, {"type": "text", "text": "Onlinelearning policies. Givn estt $\\{\\widehat{Q}_{1:H}^{(s)}\\}_{s<k}$ of the average $Q$ functions ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\left\\{\\frac{1}{N_{\\mathrm{reg}}}\\sum_{t\\mathrm{\\scriptsize~in}\\,\\mathrm{epoch}\\;s}Q_{1:H}^{\\widehat\\pi^{(s)}}\\left(\\cdot,\\cdot;\\ell^{t}\\right)\\right\\}_{s<k}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "from the previous epoch (we will describe how these estimates are computed in the sequel), Algorithm 3 computes policy $\\widehat{\\pi}^{(k)}$ for epoch $k$ accordingto ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widehat{\\pi}_{h}^{(k)}(a\\mid x)\\propto\\exp{\\left(-\\eta\\sum_{s<k}\\widehat Q_{h}^{(s)}(x,a)\\right)},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "for all $h\\in[H]$ .Givenastate $x\\in\\mathscr{X}$ , such exponential weight update ensures a sublinear regret   \nWith respect to the sequence of loss functions given by $\\{\\pi(\\cdot\\mid x)\\mapsto\\sum_{h\\in[H]}{\\widehat Q}_{h\\;.\\;}^{(k)}(x,\\pi_{h}(\\cdot\\mid x))\\}_{k\\in[K]}$   \nThanks to the performance difference lemma, and as shown in Luo et al. (2021), a sublinear regret   \nwith respect to these \"surrogate\" loss functions translates into a sublinear regret in the low-rank MDP $\\{\\widehat{Q}_{1:H}^{(k)}\\}_{k\\in[K]}$ $Q$ $Q$   \nthe following bias term ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}^{\\pi}\\left[\\operatorname*{max}_{a\\in A}\\left(\\frac{1}{N_{\\mathrm{reg}}}\\sum_{\\substack{t\\mathrm{~in~epoch}\\,k}}Q_{h}^{\\widehat{\\pi}^{(k)}}(\\pmb{x}_{h},a;\\ell^{t})-\\widehat{Q}_{h}^{(k)}(\\pmb{x}_{h},a)\\right)^{2}\\right]\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "is small for all $h\\in[H],k\\in[K]$ , and $\\pi\\in\\Pi$ ", "page_idx": 7}, {"type": "text", "text": "$Q$ -function estimates.  Thanks to the low-rank MDP structure and the linear loss representation assumption (Assumption 2.2), the avegare $Q$ -functions in (11) are linear in the feature maps $\\phi^{\\star}$ Thus, using the function class $\\Phi$ in Assumption 2.1 we can estimate these average $Q$ -functions by regressing the sum of losses $\\textstyle\\sum_{s=h}^{H}\\ell_{s}^{t}$ onto $(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t})$ for $t$ in the $k$ th epoch (as in (9). However, naively doing this using only trajectories generated by $\\widehat{\\pi}^{(k)}$ would only ensure that the bias term in (13) is small for $\\pi=\\widehat{\\pi}^{(\\bar{k})}$ . To ensure that it is small for ll possible policies $\\pi$ 's, we need to estimate the $Q$ -functions on the trajectories of policies that are guaranteed to have good state coverage; this is where we use the policy cover from the initial phase. ", "page_idx": 8}, {"type": "text", "text": "Mixture of policies.At episode $t$ in each epoch $k\\in[K]$ , we execute policy ${\\widehat{\\pi}}^{t}$ sampled from $\\rho^{(k)}$ \uff0c where $\\rho^{(k)}$ is the distribution of the random policy: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{I}\\{\\boldsymbol{\\zeta}^{t}=0\\}\\cdot\\widehat{\\boldsymbol{\\pi}}^{(k)}+\\mathbb{I}\\{\\boldsymbol{\\zeta}^{t}=1\\}\\cdot\\boldsymbol{\\pi}^{t}\\circ_{h^{t}}\\pi_{\\mathrm{unif}}\\circ_{h^{t}+1}\\widehat{\\boldsymbol{\\pi}}^{(k)},\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "with $\\zeta^{t}\\sim\\operatorname{Ber}(\\nu)$ \uff0c $h^{t}\\sim\\tt u n i f}\\left([H]\\right)$ , and $\\pi^{t}\\sim\\operatorname{unif}\\left(\\Psi_{h^{t}}^{\\mathsf{c o v}}\\right)$ . In words, at the start of each episode of any epoch $k$ ,we execute $\\widehat{\\pi}^{(k)}$ (see (12)) with probability $1-\\nu$ ; and with probability $\\nu$ , we execute a policy in $\\Psi_{1:H}^{\\mathrm{cov}}$ selected uniformly at random. As explained in the previous paragraph,this ensures a small bias forall choices of $\\pi$ in13thanksthpolicycoverpropertyf $\\Psi_{1:H}^{\\mathrm{cov}}$ We now state the guarantee of Algorithm 3. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.1. Let $\\delta~\\in~(0,1)$ be given and supposeAssumption 2.1 and Assumption 2.2hold. This, for $T\\ =\\ \\mathrm{poly}(A,d,{\\cal H},\\log(|\\Phi|/\\delta))$ sufficiently large, Algorithm $^3$ guarantees $\\mathrm{Reg}_{T}\\ \\leq$ $\\mathrm{poly}(A,d,H,\\log(|\\Phi|/\\delta))\\cdot T^{4/5}$ regret against an oblivious adversary. ", "page_idx": 8}, {"type": "text", "text": "The proof is in Appendix E. Note that the $T$ -dependence in this regret even outperforms that of the previous best bound by Zhao et al. (2024) (see Table 1). Compared to their algorithm, Algorithm 3 is model-free and only requires bandit feedback. This makes the result in Theorem 4.1 rather surprising. ", "page_idx": 8}, {"type": "text", "text": "4.3  Model-free, Oracle Effcient Algorithm (Adaptive Adversary) ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we present a variant of Algorithm 3 (Algorithm 4) that guarantees a sublinear regret against an adaptive adversary. Given the difficulty of this setting, we make the additional assumption that the algorithm has access to the loss feature $\\phi^{\\mathrm{loss}}$ , which may be different than the low-rank MDP feature $\\phi^{\\star}$ (unlike in Assumption 2.2). ", "page_idx": 8}, {"type": "text", "text": "Assumption 4.2 (Loss Representation). There is a (known) feature map $\\phi^{\\mathrm{loss}}$ satisfying $\\mathrm{sup}_{h\\in[H],(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\left\\|\\phi_{h}^{\\mathrm{loss}}(x,a)\\right\\|\\,\\leq\\,1$ and such thatforanyround $h\\,\\in\\,[H],\\,\\,t\\,\\in\\,[T].$ and history $\\mathcal{H}^{t-1}=\\big(x_{1:H}^{1:t-1},a_{1:H}^{1:t-1}\\big)$ $t$ satisfes ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\forall(x,a)\\in\\mathcal{X}\\times\\mathcal{A},\\quad\\ell_{h}\\big(x,a;\\mathcal{H}^{t-1}\\big)=\\phi_{h}^{\\mathrm{loss}}\\big(x,a\\big)^{\\top}g_{h}^{t},\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "for some $g_{h}^{t}\\in\\ensuremath{\\mathbb{B}}_{d}(1)$ ", "page_idx": 8}, {"type": "text", "text": "Note that Assumption 4.2 asserts that the loss at round $t$ depends only on the history $\\mathcal{H}^{t-1}$ and the current state action pair. Before moving forward, we introduce some additional notation we will use throughout this section. ", "page_idx": 8}, {"type": "text", "text": "Additional notation. For any two feature maps $\\phi,\\psi:\\mathcal{X}\\times\\mathcal{A}\\rightarrow\\mathbb{R}^{d}$ we denoteby $\\left[\\phi,\\psi\\right]:\\mathcal{X}\\times\\mathcal{A}\\rightarrow$ $\\mathbb{R}^{2d}$ the vertical concatenation of the two feature maps. For any $h\\in[H],\\mathit{t}\\in[T]$ , policy $\\pi\\in\\Pi$ , and history $\\mathcal{H}^{t-1}=\\big(x_{1:H}^{1:t-1},a_{1:H}^{1:t-1}\\big)$ we denoeby $Q_{h}^{\\pi}(\\cdot,\\cdot;\\mathcal{H}^{t-1})$ $Q$ functionat layer $h$ corresponding to rollout policy $\\pi$ ; that is, ", "page_idx": 8}, {"type": "equation", "text": "$$\nQ_{h}^{\\pi}(x,a;\\mathcal{H}^{t-1}):=\\mathbb{E}^{\\pi}\\left[\\sum_{s=h}^{H}\\ell_{s}(x_{s},a_{s};\\mathcal{H}^{t-1})\\mid x_{h}=x,\\pmb{a}_{h}=a\\right].\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Finally, we let $\\begin{array}{r}{V_{h}^{\\pi}(x;\\mathcal{H}^{t-1}):=\\operatorname*{max}_{a\\in\\mathcal{A}}Q_{h}^{\\pi}(x,a;\\mathcal{H}^{t-1})}\\end{array}$ denote the corresponding $V$ -function. ", "page_idx": 8}, {"type": "text", "text": "Algorithm 4 is similar to Algorithm 3 with the following key differences; after computing a policy cover, the algorithm calls RepLearn (a representation learning algorithm initially introduced by Modi et al. (2024) and subsequently refined by Mhammedi et al. (2023) to compute a feature map $\\phi^{\\mathrm{rep}}$ . Then, for every $h\\in[H]$ , the algorithm computes a spanner; a set of policies $\\Psi_{h}^{\\mathrm{span}}=$ $\\{\\pi_{h,1},\\ldots,\\pi_{h,2d}\\}$ that act as an approximate spanner for the set $\\{\\mathbb{E}^{\\pi}[\\phi_{h}^{\\mathrm{rep}}({\\pmb x}_{h},{\\pmb a}_{h}),\\phi_{h}^{\\mathrm{loss}}({\\pmb x}_{h},{\\pmb a}_{h})]:$ $\\pi\\in\\Pi\\}\\subseteq\\mathbb{R}^{2d}$ , where we use $[\\cdot,\\cdot]$ to denote the vertical concatenation of vectors. These spanner policies are then used as the exploratory policies after the initial phase; that is, at episode $t$ in each epoch $k\\in[K]$ , we execute policy. $\\pi^{(k)}$ sampled from $\\rho^{(k)}$ , where $\\bar{\\rho}^{(k)}$ is set to be the distribution of the random policy: $\\mathbb{I}\\big\\{\\zeta^{t}=0\\big\\}\\cdot\\widehat{\\pi}^{(k)}+\\mathbb{I}\\big\\{\\zeta^{t}=1\\big\\}\\cdot\\pi^{t}\\circ_{h^{t}+1}\\widehat{\\pi}^{(k)}$ , with $\\zeta^{t}\\sim\\mathrm{Ber}(\\nu)$ \uff0c $h^{t}\\sim\\tt u n i f}\\left([H]\\right)$ \uff0c and $\\pi^{t}\\sim\\operatorname{unif}\\left(\\Psi_{h^{t}}^{\\mathrm{span}}\\right)$ . Here, the main difference to Algorithm 3 (see also (47) is that we use $\\pi^{t}\\,\\sim\\,\\operatorname{unif}\\left(\\Psi_{h^{t}}^{\\mathrm{span}}\\right)$ $\\pi^{t}\\,\\sim\\,\\mathrm{unif}\\,\\big(\\Psi_{h^{t}}^{\\mathrm{cov}}\\big)$ least squares regression due to the lack of permutation invariance of state-action pairs across episodes within an epoch. Estimating the Q-functions is thus more complex, and we approach it in expectation over roll-ins using policies in $\\Psi^{\\mathbf{span}}$ , the \u201cin-expectation\u201d\u2019 estimation task is in a sense easier. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "We now state the guarantee of Algorithm 4. ", "page_idx": 9}, {"type": "text", "text": "Theorem 4.2. Let $\\delta\\in(0,1)$ be given and suppose that Assumption 2.1 and Assumption 4.2 hold. Then,for $T=\\mathrm{poly}(A,d,H,\\mathrm{log}(|\\Phi|/\\delta))$ sufficiently large, Algorithm 4 guarantees with probability atleast $1-\\delta$ ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\sum_{t\\in[T]}V_{h}^{\\pi^{t}}(x_{1};\\mathcal{H}^{t-1})-\\operatorname*{min}_{\\pi\\in\\Pi}\\sum_{t\\in[T]}V_{h}^{\\pi}(x_{1};\\mathcal{H}^{t-1})\\le\\mathrm{poly}(A,d,H,\\log(|\\Phi|/\\delta))\\cdot T^{4/5},\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where $\\pi^{t}$ is the policy that Algorithm $^{4}$ executes at episode $t\\in[T]$ ", "page_idx": 9}, {"type": "text", "text": "Algorithm 4 Oracle Efficient Algorithm for Adversarial Low-Rank MDPs (Adaptive Adversary).   \nInput: Number of rounds $T$ , feature class $\\Phi$ , loss feature $\\phi^{\\mathrm{loss}}$ , confidence parameter $\\delta\\in(0,1)$   \n1: Set $\\varepsilon\\gets T^{-1/3}$ \uff0c1 $N_{\\mathrm{reg}}\\leftarrow T^{2/3}$ $\\nu\\leftarrow N_{\\mathrm{reg}}^{-1/4}$ and $\\alpha\\leftarrow(8A d)^{-1}$ $T_{\\mathrm{cov}}\\leftarrow\\varepsilon^{-2}A d^{13}H^{6}\\log(\\Phi/\\delta)$   \n2: Set $T_{\\mathrm{rep}}\\gets\\alpha^{-1}\\varepsilon^{-2}A H\\log(|\\Phi|/\\delta)$ $T_{\\mathrm{span}}\\gets\\alpha^{-2}\\varepsilon^{-2}A\\log(d H|\\Phi|\\varepsilon^{-1}\\delta^{-1})$ \uff0c   \n3: Define $\\begin{array}{r}{\\mathcal{F}_{h}=\\big\\{(\\boldsymbol{x},\\boldsymbol{a})\\mapsto\\operatorname*{max}_{a\\in\\mathcal{A}}\\bar{\\phi}_{h}(\\boldsymbol{x},\\boldsymbol{a})^{\\top}\\bar{\\theta}\\,\\,\\big|\\,\\bar{\\phi}_{h}=[\\phi_{h}^{\\mathrm{loss}},\\phi_{h}],\\phi\\in\\Phi,\\bar{\\theta}\\in\\mathbb{B}_{2d}(1)\\big\\},}\\end{array}$ $\\forall h\\in[H]$   \n4: Get $\\Psi_{1:H}^{\\mathrm{cov}}\\leftarrow\\nabla\\mathsf{o X}(\\Phi,\\varepsilon,\\delta/4)$   \n5: Get $\\phi_{h}^{\\mathrm{rep}}\\gets\\mathsf{R e p L e a r n}(h,\\mathcal{F}_{h+1},\\Phi,\\mathrm{unif}\\,(\\Psi_{h}^{\\mathrm{cov}}),T_{\\mathrm{rep}}).$ for all $h\\in[H-1]$ .// RepLearn as in   \nMhammedi et al.(2023)   \n6: For ll $h\\in[H]$ set $\\bar{\\phi}_{h}^{\\mathrm{rep}}\\leftarrow[\\phi_{h}^{\\mathrm{loss}},\\phi_{h}^{\\mathrm{rep}}]\\in\\mathbb{R}^{2d}$   \n7: For $h\\in[H]$ set $\\Psi_{h}^{\\mathrm{span}}\\gets\\mathtt{S p a n n e r}(h,\\Phi,\\Psi_{1:h}^{\\mathrm{cov}},\\bar{\\phi}_{h}^{\\mathrm{rep}},T_{\\mathrm{span}})$ // Algorithm 7   \n8: Set $T_{0}\\gets T_{\\mathrm{cov}}+T_{\\mathrm{rep}}+T_{\\mathrm{span}}$   \n9: for $k=1,\\ldots,(T-T_{0})/N_{\\mathrm{reg}}\\;\\mathbf{do}$   \n10: Define $\\begin{array}{r}{\\widehat{\\pi}_{h}^{(k)}(a\\mid x)\\propto\\exp\\left(-\\eta\\sum_{s<k}\\widehat{Q}_{h}^{(s)}(x,a)\\right)}\\end{array}$ for $h\\in[H]$   \n11: for $t=T_{0}+\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+1$ $T_{0}+k\\cdot N_{\\mathrm{reg}}$ do   \n12: Define the random varables $\\zeta^{t}\\sim\\operatorname{Ber}(\\nu),h^{t}\\sim\\operatorname{unif}\\left([H]\\right)$ and $\\pi^{t}\\sim\\operatorname{unif}\\left(\\Psi_{h^{t}}^{\\mathrm{span}}\\right)$   \n13: Set $\\widehat{\\pmb{\\pi}}^{t}=\\mathbb{I}\\big\\{\\pmb{\\zeta}^{t}=0\\big\\}\\cdot\\widehat{\\pmb{\\pi}}^{(k)}+\\mathbb{I}\\big\\{\\pmb{\\zeta}^{t}=1\\big\\}\\cdot\\pmb{\\pi}^{t}\\circ\\mathsf{o}_{h^{t}+1}\\,\\widehat{\\pmb{\\pi}}^{(k)}$   \n14: Execute \u03c0', and observe trajectory (\u221e, a,. $(x_{1}^{t},\\pmb{a}_{1}^{t},\\ldots,\\pmb{x}_{H}^{t},\\pmb{a}_{H}^{t})$   \n15: For $h\\in[H]$ observe los $\\ell_{h}^{t}:=\\ell_{h}\\big(\\mathbf x_{h}^{t},\\mathbf a_{h}^{t};\\mathcal{H}^{t-1}\\big)$ ,Where $\\pmb{\\mathscr{H}}^{t-1}:=\\big(\\pmb{x}_{1:H}^{1:t-1},\\pmb{a}_{1:H}^{1:t-1}\\big)$   \n16: end for   \n17: For $h\\in[H]$ and $\\mathcal{Z}^{(k)}=\\left\\{T_{0}+\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+1,\\,\\,...\\,,\\,\\,T_{0}+k\\cdot N_{\\mathrm{reg}}\\right\\}$ , compute $\\hat{\\theta}_{h}^{(k)}$ such that   \n$\\hat{\\theta}_{h}^{(k)}\\gets\\operatorname*{argmin}_{\\theta\\in\\mathbb{B}_{2d}(4H d^{2})}\\sum_{\\pi\\in\\Psi_{h}^{\\mathrm{span}}}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{I}\\big\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\big\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(\\mathbf{x}_{h}^{t},a_{h}^{t})^{\\top}\\theta-\\sum_{s=h}^{H}\\ell_{s}^{t}\\right)\\right|$ (18)   \n18:Set $\\widehat{Q}_{h}^{(k)}(x,a)=\\bar{\\phi}_{h}^{\\mathrm{rep}}(x,a)^{\\top}\\hat{\\theta}_{h}^{(k)}$ , for all $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$ ", "page_idx": 9}, {"type": "text", "text": "19: end for ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we focus on learning low-rank MDPs with unknown transitions and adversarial losses. For the full-information setting, we improve upon previous regret bounds. More importantly, we initiate the study of the challenging bandit feedback setting, developing various algorithms that achieve sublinear regret under different assumptions. However, the optimal $\\sqrt{T}$ regret remains out of reach due to the limitations of our two-phase design. An interesting direction for future work is to perform on-the-fly representation learning to adapt to adversarial losses and achieve optimal regret. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Abbeel, P. and Ng, A. Y. (2005). Exploration and apprenticeship learning in reinforcement learning. In Proceedings of the 22nd international conference on Machine learning, pages 1-8. ", "page_idx": 10}, {"type": "text", "text": "Agarwal, A., Kakade, S., Krishnamurthy, A., and Sun, W. (2020). Flambe: Structural complexity and representation learning of low rank mdps. Advances in neural information processing systems, 33:20095-20107.   \nAyoub, A., Jia, Z, Szepesvari, C., Wang, M., and Yang, L. (2020). Model-based reinforcement learning with value-targeted regression. In International Conference on Machine Learning, pages 463-474. PMLR.   \nCai, Q., Yang, Z.,Jin, C., and Wang, Z. (2020). Provably efcint exloration in policy optimization. In International Conference on Machine Learning, pages 1283-1294. PMLR.   \nChen, F., Mei, S., and Bai, Y. (2022a). Unified algorithms for rl with decision-estimation coefficients: No-regret, pac, and reward-free learning. arXiv preprint arXiv:2209.11745.   \nChen, J., Modi, A., Krishnamurthy, A., Jiang, N., and Agarwal, A. (2022b). On the statistical effciency of reward-free exploration in non-linear rl. Advances in Neural InformationProcessing Systems, 35:20960-20973.   \nChen, L. and Luo, H. (2021). Finding the stochastic shortest path with low regret: The adversarial cost and unknown transition case. In International Conference on Machine Learning, pages 1651-1660. PMLR.   \nCheng, Y., Huang, R., Yang, J., and Liang, Y. (2023). Improved sample complexity for reward-free reinforcement learning under low-rank mdps. arXiv preprint arXiv:2303.10859.   \nDai, Y., Luo, H., and Chen, L. (2022). Follow-the-perturbed-leader for adversarial markov decision processes with bandit feedback. Advances in Neural Information Processing Systems, 35:11437- 11449.   \nDai, Y., Luo, H., Wei, C.-Y., and Zimmert, J. (2023). Refined regret for adversarial mdps with linear function approximation. In International Conference on Machine Learning, pages 6726-6759. PMLR.   \nDann, C., Wei, C.-Y., and Zimmert, J. (2023). Best of both worlds policy optimization. In International Conference on Machine Learning.   \nDu, S., Kakade, S., Lee, J., Lovett, S., Mahajan, G., Sun, W., and Wang, R. (2021). Bilinear classes: A structural framework for provable generalization in rl. In International Conference on Machine Learning, pages 2826-2836. PMLR.   \nFoster, D. J., Kakade, S.M, Qian, J., and Rakhlin,A.(2021). The statistical complexity of interactive decision making. arXiv preprint arXiv:2112.13487.   \nFoster, D. J., Rakhlin, A., Sekhari, A., and Sridharan, K. (2022). On the complexity of adversarial decision making. Advances in Neural Information Processing Systems, 35:35404-35417.   \nHe, J., Zhou, D, and Gu, Q. (2022). Near-optimal policy optimization algorithms for learning adversarialinearmixturemdps. In International Conference onArifcial Intelligenceand Statistic, pages 4259-4280. PMLR.   \nHuang, A., Chen, J., and Jiang, N. (2023). Reinforcement learning in low-rank mdps with density features. In International Conference on Machine Learning, pages 13710-13752. PMLR.   \nJiang, N., Krishnamurthy, A., Agarwal, A., Langford, J, and Schapire, R. E. (2017). Contextual decision processes with low bellman rank are pac-learnable. In International Conference on Machine Learning, pages 1704-1713. PMLR.   \nJin, C., Jin, T, Luo, H., Sra, S., and Yu, T. (2020a). Learning adversarial markov decision processes with bandit feedback and unknown transition. In International Conference on Machine Learning, pages 4860-4869. PMLR.   \nJin, C., Liu, Q., and Miryoosefi, S. (2021a). Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms. Advances in neural information processing systems, 34:13406-13418.   \nJin, C., Yang, Z., Wang, Z., and Jordan, M. 1. (2020b). Provably efficient reinforcement learning with linear function approximation. In Conference on Learning Theory, pages 2137-2143. PMLR.   \nJin, T., Huang, L., and Luo, H. (202ib). The best of both worlds: stochastic and adversarial episodic mdps with unknown transition. Advances in Neural Information Processing Systems, 34:20491-20502.   \nKakade, S. and Langford, J. (2002). Approximately optimal approximate reinforcement learning. In Proceedings of the Nineteenth International Conference on Machine Learning, pages 267-274.   \nKong, F., Zhang, X., Wang, B., and Li, S. (2023). Improved regret bounds for linear adversarial mdps via linear optimization. arXiv preprint arXiv:2302.06834.   \nLattimore, T. and Szepesvari, C. (2020). Bandit algorithms. Cambridge University Press.   \nLee, C.-W., Luo, H, Wei, C.-Y., and Zhang, M. (2020). Bias no more: high-probability datadependent regret bounds for adversarial bandits and mdps. In Advances in Neural Information Processing Systems.   \nLiu, H., Wei, C.-Y, and Zimmert, J. (2023). Towards optimal regret in adversarial linear mdps with bandit feedback. arXiv preprint arXiv:2310.11550.   \nLuo, H., Wei, C.-Y., and Lee, C.-W. (2021). Policy optimization in adversarial mdps: Improved exploration via dilated bonuses. Advances in Neural Information Processing Systems, 34:22931- 22942.   \nMhammedi, Z., Block, A., Foster, D. J., and Rakhlin, A. (2023). Efficient model-free exploration in low-rank mdps. arXiv preprint arXiv:2307.03997.   \nMhammedi, Z., Block, A., Foster, D. J., and Rakhlin, A. (2024a). Efficient model-free exploration in low-rank mdps. Advances in Neural Information Processing Systems, 36.   \nMhammedi, Z., Foster, D. J., and Rakhlin, A. (2024b). The power of resets in online reinforcement learning. arXiv preprint arXiv:2404.15417.   \nModi, A., Chen, J., Krishnamurthy, A., Jiang, N, and Agarwal, A. (2024). Model-free representation learning and exploration in low-rank mdps. Journal of Machine Learning Research, 25(6):1-76.   \nPadakandla, S., KJ, P, and Bhatnagar, S. (2020), Reinforcement learning algorithm for non-stationary environments. Applied Intelligence, 50(11):3590-3606.   \nRen, T., Zhang, T., Szepesvari, C., and Dai, B. (2022). A free lunch from the noise: Provable and practicalexploration for representation learning. In Uncertainty in Artificial Intelligence, pages 1686-1696. PMLR.   \nRosenberg, A. and Mansour, Y. (2019). Online stochastic shortest path with bandit feedback and unknown transition function. Advances in Neural Information Processing Systems, 32.   \nShani, L., Efroni, Y., Rosenberg, A., and Mannor, S. (2020). Optimistic policy optimization with bandit feedback. In International Conference on Machine Learning, pages 8604-8613. PMLR.   \nSherman, U., Cohen, A., Koren, T., and Mansour, Y. (2023a). Rate-optimal policy optimization for linear markov decision processes. arXiv preprint arXiv:2308.14642.   \nSherman, U., Koren, T., and Mansour, Y. (2023b). Improved regret for efficient online reinforcement learning with linear function approximation. In International Conference on Machine Learning.   \nUehara, M., Zhang, X., and Sun, W. (2021). Representation learning for online and offine rl in low-rank mdps. arXiv preprint arXiv:2110.04652.   \nXie, T., Foster, D. J., Bai, Y, Jiang, N., and Kakade, S. M. (2022). The role of coverage in online reinforcement learning. arXiv preprint arXiv:2210.04157.   \nZhang, T., Ren, T., Yang, M., Gonzalez, J., Schuurmans, D., and Dai, B. (2022a). Making linear mdps practical via contrastive representation learning. In International Conference on Machine Learning, pages 26447-26466. PMLR.   \nZhang, X., Song, Y., Uehara, M., Wang, M., Agarwal, A., and Sun, W. (2022b). Effcient reinforcement learning in block mdps: A model-free representation learning approach. In International Conference on Machine Learning, pages 26517-26547. PMLR.   \nZhao, C., Yang, R., Wang, B., and Li, S. (2022). Learning adversarial linear mixture markov decision processes with bandit feedback and unknown transition. In The Eleventh International Conference onLearningRepresentations.   \nZhao, C., Yang, R., Wang, B., Zhang, X., and Li, S. (2024). Learning adversarial low-rank markov decision processes with unknown transition and full-information feedback. Advances in Neural Information Processing Systems, 36.   \nZhong, H., Xiong, W., Zheng, S., Wang, L., Wang, Z., Yang, Z., and Zhang, T. (2022). Gec: A unified framework for interactive decision making in mdp, pomdp, and beyond. arXiv preprint arXiv:2211.01962. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendices ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A Related Work 15 ", "page_idx": 13}, {"type": "text", "text": "B Proof of Theorem 3.1 (Model-Based, Full Information) 16 ", "page_idx": 13}, {"type": "text", "text": "C Proof of Theorem 3.2 (Model-Based, Bandit Feedback) 17 ", "page_idx": 13}, {"type": "text", "text": "D  More Details of Ineffcient Model-Free Algorithm in Section 4.1 23 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "D.1 Algorithm Description 23   \nD.2  Analysis of Occupancy Estimation from Algorithm 6 24   \nD.3 Regret Analysis . . . 27 ", "page_idx": 13}, {"type": "text", "text": "E Proof of Theorem 4.1 (Model-Free, Banfit Feedback) 32 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "E.1  Bounding the Regret Term 32   \nE.2 Bounding the Bias Term . . : 33   \nE.3  Bounding the Regression Error 34   \nE.4 Putting It All Together . ... . .36 ", "page_idx": 13}, {"type": "text", "text": "F Proof of Theorem 4.2 (Model-Free, Bandit Feedback, Adaptive Adversary) 37 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "F.1 Bounding the Regret Term . . - 37   \nF.2 Bounding the Bias Term . . . . 38   \nF.3 Bound the Regression Error . . . 39   \nF.4 Putting It All Together . . . . 40   \nF.5 Spanner Guarantee . . . 40   \nF.6  Representation $^+$ Spanner 42   \nF.7 Martingal Concentration 42 ", "page_idx": 13}, {"type": "text", "text": "G Policy Cover and Representation Learning Algorithms 44 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "G.1  Policy Cover . 44   \nG.2 Representation Learning . . 44 ", "page_idx": 13}, {"type": "text", "text": "H  Lower Bound for Bandit feedback with Unstructured Losses 46 ", "page_idx": 13}, {"type": "text", "text": "1 Helper Results 46 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "1.1 Martingale Concentration and Regression Results 47   \n1.2 Online Learning . . . 48   \n1.3 Reinforcement Learning . . 48 ", "page_idx": 13}, {"type": "text", "text": "A Related Work ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Learning low-rank MDPs in the stochastic setting.  In the absent of adversarial losses, several general learning frameworks have been developed for super classes of low-rank MDPs which offer tight sample complexity for either reward-based (Jiang et al., 2017; Jin et al., 2021a; Du et al., 2021; Foster et al., 2021; Zhong et al., 2022) or reward-free (Chen et al., 2022b,a; Xie et al., 2022) settings. However, these algorithms require solving non-convex optimization problems on non-convex version spaces, making them computationally inefficiency. Oracle-efficient algorithms for low-rank MDPs are first obtained by Agarwal et al. (2020) using a model-based approach, and the sample complexity bound has been largely improved in subsequent works (Uehara et al., 2021; Zhang et al., 2022a; Cheng et al., 2023). The model-based approach, however, necessitates the function class to accurately model the transition, which is a strong requirement. To relax it, Modi et al. (2024); Zhang et al. (2022b) developed oracle-efficient model-free algorithms, but both of them require additional assumptions on the MDP structure. Recently, Mhammedi et al. (2024a) proposed a satisfactory model-free algorithm that removes all these assumptions. Our work leverages their techniques to tackle the more challenging adversarial seting. ", "page_idx": 14}, {"type": "text", "text": "Learning adversarial MDPs.  Learning adversarial tabular MDPs under bandit feedback and unknown transition has been extensively studied (Rosenberg and Mansour, 2019; Jin et al., 2020a; Lee et al., 2020; Jin et al., 2021b; Shani et al., 2020; Chen and Luo, 2021; Luo et al., 2021; Dai et al., 2022; Dann et al., 2023). This line of work has demonstrated not only $\\sqrt{T}$ regret boundsbut also several data-dependent bounds. ", "page_idx": 14}, {"type": "text", "text": "For adversarial MDPs with a large state space which necessitates the use of function approximation, if the transition is known, Foster et al. (2022) shows that adversarial setting is as easy as the stochastic setting even under general function approximation. For full-information loss feedback with unknown transition, $\\sqrt{T}$ bound is derived for both linear mixture MDPs (Cai et al., 2020; He et al., 2022) and linear MDPs (Sherman et al., 2023a). For more challenging low-rank MDPs with unknown features, the best result only achieves $T^{5/6}$ regret (Zhao et al., 2024). ", "page_idx": 14}, {"type": "text", "text": "For function approximation with bandit feedback and unknown transition, Zhao et al. (2022) provides $\\sqrt{T}$ bound for linear mixture MDPs, but their regret has polynomial dependence on the size of the state space due to the lack of structure on the loss function. For linear MDPs, a series of recent work has made significant progress in improving the regret bound (Luo et al., 2021; Dai et al., 2023; Sherman et al., 2023b; Kong et al., 2023; Liu et al., 2023). The state-of-the-art result by Liu et al. (2023) gives an inefficient algorithm with $\\sqrt{T}$ regret and an efficient algorithm with $T^{3/4}$ regret. These regret bounds for linear MDPs do not depend on the state space size because of the linear loss assumption. We show in Appendix H that cross-state structure on the losses is necessary for low-rank MDPs with bandit feedback to achieve regret bound that do not scale with the number of states. ", "page_idx": 14}, {"type": "text", "text": "B Proof of Theorem 3.1 (Model-Based, Full Information) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Theorem B.1 (Theorem 3 in Cheng et al. (2023). With probability $1-\\delta$ for anypolicy $\\pi$ and layer $h$ Algorithm $^{\\,l}$ in Cheng et al. (2023) outputs transition $\\widehat{P}_{1:H}$ and features $\\hat{\\phi}_{h},\\,\\hat{\\mu}_{h}$ such that $\\widehat{P_{h}}(x^{\\prime}\\,|\\,x,\\bar{a})=\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\mu}_{h+1}(x^{\\prime})$ and ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}^{\\pi}\\left[\\|\\widehat{P}_{h}\\left(\\cdot\\,\\vert\\,\\pmb{x}_{h},\\pmb{a}_{h}\\right)-P_{h}^{\\star}\\left(\\cdot\\,\\vert\\,\\pmb{x}_{h},\\pmb{a}_{h}\\right)\\|_{1}\\right]\\le\\epsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "$\\begin{array}{r}{\\mathcal{O}\\Big(\\frac{H^{3}d^{2}|A|(d^{2}+|A|)}{\\epsilon^{2}}\\log^{2}{(T d H|\\Phi||\\Upsilon|)}\\Big).}\\end{array}$ ", "page_idx": 15}, {"type": "text", "text": "Define $\\widehat{V}_{1}^{\\pi}(x_{1};\\ell)$ as the value function of policy $\\pi$ under transition $\\{\\widehat{P}_{h}\\}_{h=1}^{H}$ and loss $\\ell$ We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathrm{Reg}_{T}\\bigl(\\pi^{\\star}\\bigr)=\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\pi^{t}}\\bigl(x_{1};\\ell^{t}\\bigr)-\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\pi^{\\star}}\\bigl(x_{1};\\ell^{t}\\bigr)}}\\\\ &{=\\displaystyle\\sum_{t=1}^{T}\\Bigl({V_{1}^{\\pi^{t}}\\bigl(x_{1};\\ell^{t}\\bigr)-\\widehat V_{1}^{\\pi^{t}}\\bigl(x_{1};\\ell^{t}\\bigr)}\\Bigr)+\\displaystyle\\sum_{t=1}^{T}\\Bigl(\\widehat V_{1}^{\\pi^{\\star}}\\bigl(x_{1};\\ell^{t}\\bigr)-{V_{1}^{\\pi^{\\star}}\\bigl(x_{1};\\ell^{t}\\bigr)}\\Bigr)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n+\\sum_{t=1}^{T}\\left(\\widehat{V}_{1}^{\\pi^{t}}(x_{1};\\ell^{t})-\\widehat{V}_{1}^{\\pi^{\\star}}(x_{1};\\ell^{t})\\right)+\\mathcal{O}\\left(\\frac{H^{3}d^{2}|A|(d^{2}+|A|)}{\\epsilon^{2}}\\log^{2}\\left(T d H|\\Phi||\\Upsilon|\\right)\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Bounding the bias term.  By Theorem B.1 and Lemma I.6, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbf{Bias1}+\\mathbf{Bias2}\\leq2H^{2}\\epsilon T.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Bounding the FTRL term. Since $\\begin{array}{r}{\\eta=\\frac{1}{H\\sqrt{T}}}\\end{array}$ HT, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{FTRL}\\leq\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}^{\\hat{P},\\pi^{\\star}}\\left[\\left\\langle\\widehat{Q}_{h}^{t}(x_{h},\\cdot),\\pi_{h}^{t}(\\cdot\\mid x_{h})-\\pi_{h}^{\\star}(\\cdot\\mid x_{h})\\right\\rangle\\right]}\\\\ &{\\qquad\\leq\\displaystyle\\frac{H\\log\\left|\\mathcal{A}\\right|}{\\eta}+\\eta\\displaystyle\\sum_{h=1}^{H}\\sum_{t=1}^{T}\\mathbb{E}^{\\hat{P},\\pi^{\\star}\\ o_{h}\\pi^{t}}\\left[\\left(\\widehat{Q}_{h}^{t}(x_{h},a_{h})\\right)^{2}\\right],}\\\\ &{\\qquad\\leq\\displaystyle\\frac{H\\log\\left|\\mathcal{A}\\right|}{\\eta}+2H^{3}\\eta T}\\\\ &{\\qquad=\\mathcal{O}\\left(H^{2}\\sqrt{T}\\log\\left|\\mathcal{A}\\right|\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n(\\widehat{Q}_{h}^{t}(x_{h},\\pmb{a}_{h})\\leq H)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Thus, by setting $\\epsilon=\\left(H d^{2}|A|(d^{2}+|A|)\\right)^{\\frac{1}{3}}T^{-\\frac{1}{3}}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}_{T}\\leq\\mathcal{O}\\left(\\frac{H^{3}d^{2}\\lvert A\\rvert\\left(d^{2}+\\lvert A\\rvert\\right)}{\\epsilon^{2}}\\log^{2}\\left(T d H\\lvert\\Phi\\rvert\\lvert\\Upsilon\\rvert\\right)+2H^{2}\\epsilon T+H^{2}\\sqrt{T}\\log\\left\\lvert A\\rvert\\right)}\\\\ &{\\qquad\\leq\\mathcal{O}\\left(H^{3}\\left(d^{2}+\\lvert A\\rvert\\right)T^{\\frac{2}{3}}\\log\\left(\\lvert A\\rvert+d H\\lvert\\Phi\\rvert\\lvert\\Upsilon\\rvert T\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "CProof of Theorem 3.2 (Model-Based, Bandit Feedback) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Lemma C.1. With $\\widehat{P}_{1:H}$ as in Theorem B.1, we have for any $h\\in[H]$ and any policy $\\pi$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{x\\in\\mathcal{X}}\\left|\\hat{d}_{h}^{\\pi}(x)-d_{h}^{\\pi}(x)\\right|\\leq\\sum_{i=1}^{h-1}\\mathbb{E}^{\\pi}\\left[\\|\\widehat{P}_{i}(\\cdot\\,|\\,x_{i},a_{i})-P_{i}(\\cdot\\,|\\,x_{i},a_{i})\\|_{1}\\right]\\leq(h-1)\\cdot\\epsilon.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\hat{d}_{h}^{\\pi}:=d_{h}^{\\widehat{P},\\pi}$ ", "page_idx": 16}, {"type": "text", "text": "Proof. We prove the claim by induction. When $h=1$ , given that the $\\|d_{1}^{\\pi}-\\hat{d}_{1}^{\\pi}\\|_{1}=0$ .Assume ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{x\\in\\mathcal{X}}\\left|\\hat{d}_{h}^{\\pi}(x)-d_{h}^{\\pi}(x)\\right|\\leq\\sum_{i=1}^{h-1}\\mathbb{E}^{\\pi}\\left[\\|\\widehat{P}_{i}(\\cdot\\,|\\;x_{i},a_{i})-P_{i}(\\cdot\\,|\\;x_{i},a_{i})\\|_{1}\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\sum_{k\\geq1}^{n}\\bigg|\\hat{l}_{k+1}^{(n)}(x)-d_{n+1}^{(\\varepsilon)}(x)\\bigg|}\\\\ &{\\cdots\\sum_{k\\geq1}^{n}\\sum_{i=1}^{n}\\bigg|\\frac{l_{n}^{(n)}}{\\varepsilon_{i}(x)}(x)_{i}(a\\,|\\,x)\\cdot\\widehat{R_{h}}(x^{\\prime}|,a)-d_{n}^{\\infty}(x)\\pi_{h}(a\\,|\\,x)\\cdot P_{h}^{\\ast}(x^{\\prime}|x,a)\\bigg|,}\\\\ &{\\cdots\\sum_{k\\geq1}^{n}\\sum_{i=1}^{n}\\varepsilon_{i}(x)_{i}(a\\,|\\,x)\\cdot\\widehat{R_{h}}(x^{\\prime}|x,a)-d_{n}^{\\infty}(x)\\pi_{h}(a\\,|\\,x)\\cdot\\widehat{P_{h}}(x^{\\prime}|x,a)\\bigg|}\\\\ &{\\cdots\\sum_{k\\geq1}^{n}\\sum_{i=1}^{n}\\bigg|\\frac{l_{n}^{(n)}}{\\varepsilon_{i}(x)}\\pi_{h}(a\\,|\\,x)\\cdot\\widehat{P_{h}}_{h}(x^{\\prime}|x,a)-d_{n}^{\\infty}(x)\\pi_{h}(a\\,|\\,x)\\cdot\\widehat{P_{h}}_{h}(x^{\\prime}|x,a)\\bigg|}\\\\ &{\\quad+\\sum_{k\\geq1}^{n}\\sum_{i=1}^{n}\\varepsilon_{i}(x)_{i}\\quad|a_{k}^{\\infty}(x)\\pi_{h}(a\\,|\\,x)\\cdot\\widehat{P_{h}}_{h}(x^{\\prime}|x,a)-d_{n}^{\\infty}(x)\\pi_{h}(a\\,|\\,x)\\cdot P_{h}^{\\ast}(x^{\\prime}|x,a)\\bigg|,}\\\\ &{\\lesssim\\sum_{k\\geq1}^{n}\\sum_{i=1}^{n}\\ \\sum_{i=1}^{n}\\sigma_{h}(a\\,|\\,x)\\pi_{h}(a\\,|\\,x)\\cdot|\\widehat{i}_{h}(x^{\\prime}|x,a)-d_{n}^{\\infty}(x)|}\\\\ &{\\quad+\\sum_{k\\geq1}^{n}\\sum_{i=1}^{n}\\varepsilon_{i}(x)_{i}\\quad|\\widehat{i}_{h}(x^{\\prime}|x,a)|}\\\\ &{\\quad+\\sum_{k\\geq1}^{n}\\sum_{i=1}^{n}\\widehat{\\pi}_{h}^{(\\varepsilon) \n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last step follows by the induction hypothesis. The second inequality of Lemma C.1 directly comes from Theorem B.1. \u25a0 ", "page_idx": 16}, {"type": "text", "text": "Our candidate policy space $\\Pi^{\\prime}$ has a $\\beta$ mixture of the random policy. For any deterministic policy $\\pi_{0}^{\\star}$ \uff0c define policy $\\pi^{\\star}$ such that for any state $x\\in\\mathscr{X}$ , we have $\\begin{array}{r}{\\pi^{\\star}\\big(\\cdot\\;\\big|\\;x\\big)=\\big(1-\\beta\\big)\\pi_{0}^{\\star}\\big(\\cdot\\;\\big|\\;x\\big)+\\frac{\\beta}{|A|}}\\end{array}$ . We have $\\pi^{\\star}\\in\\Pi^{\\prime}$ Defne $\\widehat{V}_{1}^{\\pi}(x_{1};\\ell)$ as the value funtion of policy $\\pi$ under transion $\\{\\widehat{P}_{h}\\}_{h=1}^{H}$ and loss $\\ell$ \uff0c For any policy $\\pi_{0}^{\\star}$ . we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\sf R e g}_{T}(\\pi_{0}^{*})}\\\\ &{={\\mathbb E}\\left[\\displaystyle\\sum_{t=1}^{T}\\underline{{r}}^{t}\\varrho^{t}(\\pi)V_{1}^{\\pi}({x}_{1};\\ell^{t})-V_{1}^{\\pi_{0}^{*}}({x}_{1};\\ell^{t})\\right]+\\mathcal O\\left(\\displaystyle\\frac{H^{3}d^{2}\\lvert A\\rvert(d^{2}+\\lvert A\\rvert)}{\\epsilon^{2}}\\log^{2}\\left(T d H\\lvert\\Phi\\rvert\\right\\rvert{\\mathbb{T}}\\rvert\\right)\\right),}\\\\ &{={\\mathbb E}\\left[\\displaystyle\\sum_{t=1}^{T}\\underline{{\\gamma}}^{t}\\varrho^{t}(\\pi)V_{1}^{\\pi}({x}_{1};\\ell^{t})-V_{1}^{\\pi^{*}}({x}_{1};\\ell^{t})\\right]+\\mathcal O\\left(\\frac{H^{3}d^{2}\\lvert A\\rvert(d^{2}+\\lvert A\\rvert)}{\\epsilon^{2}}\\log^{2}\\left(T d H\\lvert\\Phi\\rvert\\right\\rvert{\\mathbb{T}}\\rvert\\right)\\right)}\\\\ &{\\qquad+\\underbrace{{\\mathbb E}\\left[\\displaystyle\\sum_{t=1}^{T}\\frac{\\gamma}{\\pi}\\left(\\rho^{t}(\\pi)-p^{t}(\\pi)\\right)V_{1}^{\\pi}({x}_{1};\\ell^{t})\\right]}_{{\\mathbb E}\\mathrm{rere}1}+\\underbrace{{\\mathbb E}\\left[\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\pi^{*}}({x}_{1};\\ell^{t})-V_{1}^{\\pi_{0}^{*}}({x}_{1};\\ell^{t})\\right]}_{{\\mathbb E}\\mathrm{rere}2},}\\\\ &{={\\mathbb E}\\left[\\displaystyle\\sum_{t=1}^{T}\\sum p^{t}(\\pi)\\left(V_{1}^{\\pi}({x}_{1};\\ell^{t})-\\widehat{V}_{1}^{\\pi}({x}_{1};\\ell^{t})\\right)\\right]+{\\mathbb E}\\left[\\displaystyle\\sum_{t=1}^{T}\\widehat{V}_{1}^{\\pi^{*}}({x}_{1};\\ell^{t})-V_{1}^{\\pi^{*}}({x}_{1};\\ell^{t})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{+\\underbrace{\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{\\pi}p^{t}(\\pi)\\widehat{V}_{1}^{\\pi}(\\mathbf{\\boldsymbol{x}}_{1};\\mathcal{\\ell}^{t})-\\widehat{V}_{1}^{\\pi^{\\star}}(\\mathbf{\\boldsymbol{x}}_{1};\\mathcal{\\ell}^{t})\\right]}_{\\mathbf{EXP}}+\\mathbf{Error1}+\\mathbf{Error2}}\\\\ &{+\\underbrace{\\mathcal{O}\\left(\\frac{H^{3}d^{2}|A|(d^{2}+|A|)}{\\epsilon^{2}}\\log^{2}\\left(T d H|\\Phi||\\Upsilon|\\right)\\right)}_{\\epsilon^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Recall that $J~=~\\mathrm{John}\\{{\\hat{\\phi}}_{h}(\\pi)\\}_{\\pi\\in\\Pi^{\\prime},h\\in[H]}~\\in~\\Delta(\\Pi^{\\prime}\\times H)$ . and we have $\\rho^{t}(\\pi)~=~(1-\\gamma)p^{t}(\\pi)~+$ $\\begin{array}{r}{\\gamma\\sum_{h=1}^{H}J(\\pi,h)}\\end{array}$ where $p^{t}(\\pi)$ is defined in Line 7 of Algorithm 2. ", "page_idx": 17}, {"type": "text", "text": "Lemma C.2. We have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{Error1}+\\mathbf{Error2}\\leq H\\gamma T+2H^{2}\\beta T.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{Error1}=\\displaystyle\\gamma\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\sum_{\\pi}\\left(\\displaystyle\\sum_{h=1}^{H}J(\\pi,h)-p^{t}(\\pi)\\right)\\cdot V_{1}^{\\pi}(\\pmb{x}_{1};\\ell^{t})\\right]\\leq H\\gamma T.}\\\\ &{\\mathbf{Error2}=\\displaystyle\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star}}\\left[\\displaystyle\\sum_{a\\in\\mathcal{A}}\\left|\\pi_{0}^{\\star}(a\\mid\\pmb{x}_{h})-\\pi^{\\star}(a\\mid\\pmb{x}_{h})\\right|\\cdot Q_{h}^{\\pi_{0}^{\\star}}(\\pmb{x}_{h},a;\\ell^{t})\\right]\\leq2H^{2}\\beta T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last step follows by Lemma I.7. ", "page_idx": 17}, {"type": "text", "text": "Lemma C.3. We have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{Bias1}+\\mathbf{Bias2}\\leq H^{2}T\\epsilon.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. This is a direct result combing Theorem B.1 and Lemma I.6. ", "page_idx": 17}, {"type": "text", "text": "For $(x_{1:H},a_{1:H})\\in\\mathcal{X}^{H}\\times\\mathcal{A}^{H}$ and $\\pi\\in\\Pi^{\\prime}$ where $\\Pi^{\\prime}$ defined in Line 5 in Algorithm 2 is the mix of a given policy class $\\Pi$ and a uniform policy, and is also the policy class we play with. Recall that the loss estimator ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},a_{1:H}):=\\displaystyle\\frac{\\pi_{1}(a_{1}\\mid x_{1})}{\\pi_{1}^{t}(a_{1}\\mid x_{1})}\\ell_{1}^{t}(x_{1},a_{1})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\sum_{h=2}^{H}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\frac{\\pi_{h}(a_{h}\\mid x_{h})}{\\pi_{h}^{t}(a_{h}\\mid x_{h})}\\ell_{h}^{t}(x_{h},a_{h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "defined in Line 10 of Algorithm 2. ", "page_idx": 17}, {"type": "text", "text": "Lemma C.4. For any episode $t\\in[T]$ for any policy $\\pi$ we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\widehat{V}_{1}^{\\pi}(x_{1};\\ell^{t})\\leq\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\widehat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},\\boldsymbol{a}_{1:H})\\right]+\\sqrt{d}H\\epsilon\\sum_{h=2}^{H}\\left\\|\\widehat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}},}\\\\ {\\displaystyle\\widehat{V}_{1}^{\\pi}(x_{1};\\ell^{t})\\geq\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\widehat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},\\boldsymbol{a}_{1:H})\\right]-\\sqrt{d}H\\epsilon\\sum_{h=2}^{H}\\left\\|\\widehat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. First, from the definition in Line 4 of Algorithm 2, for any $x\\in\\mathscr{X}$ with $h\\geq2$ wehave ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\hat{d}_{h}^{\\pi}(x)=\\sum_{x^{\\prime},a^{\\prime}}\\hat{d}_{h-1}^{\\pi}(x^{\\prime},a^{\\prime})\\cdot\\widehat{P}_{h-1}(x\\mid x^{\\prime},a^{\\prime})=\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\hat{\\mu}_{h}(x)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\begin{array}{r}{\\hat{\\phi}_{h-1}\\!\\left(\\pi\\right)=\\sum_{x^{\\prime},a^{\\prime}}\\hat{d}_{h-1}^{\\pi}(x^{\\prime},a^{\\prime})\\hat{\\phi}_{h-1}(x^{\\prime},a^{\\prime})}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "We now prove the first inequality: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\widehat{V}_{1}^{\\pi}(x_{1};\\ell^{t})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{=\\displaystyle\\sum_{h=1}^{H}\\sum_{x_{h}\\in\\mathcal{X}}\\sum_{a_{h}\\in\\mathcal{A}}{\\hat{d}}_{h}^{\\pi}(x_{h})\\pi_{h}(a_{h}\\mid x_{h})\\cdot\\ell_{h}^{t}(x_{h},a_{h}),}}\\\\ {{=\\displaystyle\\sum_{a_{1}\\in\\mathcal{A}}\\pi_{1}(a_{1}\\mid x_{1})\\cdot\\ell_{1}^{t}(x_{1},a_{1})+\\sum_{h=2}^{H}\\sum_{x_{h}\\in\\mathcal{X}}\\sum_{a_{h}\\in\\mathcal{A}}{\\hat{\\phi}}_{h-1}(\\pi)^{\\top}{\\hat{\\mu}}_{h}(x_{h})\\pi_{h}(a_{h}\\mid x_{h})\\cdot\\ell_{h}^{t}(x_{h},a_{h})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Remain ", "page_idx": 18}, {"type": "text", "text": "Through importance sampling, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbf{First}=\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[{\\frac{\\pi_{1}(a_{1}\\mid x_{1})}{\\pi_{1}^{t}(a_{1}\\mid x_{1})}}\\cdot\\ell_{1}^{t}(x_{1},a_{1})\\right].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We now bound the remaining term in (42) Since $\\begin{array}{r}{\\Sigma_{h-1}^{t}=\\mathbb{E}_{\\pmb{\\pi}^{t}\\sim\\rho^{t}}\\left[\\hat{\\phi}_{h-1}(\\pmb{\\pi}^{t})\\hat{\\phi}_{h-1}(\\pmb{\\pi}^{t})^{\\top}\\right]}\\end{array}$ wehave ", "page_idx": 18}, {"type": "text", "text": "Remain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\displaystyle\\frac{H}{h^{2}}\\sum_{n\\neq\\sigma}\\sum_{k\\neq\\sigma_{n}\\neq k,\\sigma_{n}\\neq k}\\hat{Q}_{h-1}(\\pi)^{\\top}\\left(\\sum_{h=1}^{t}\\right)^{-1}\\mathbb{E}_{\\pi^{+}\\sigma^{\\prime}}\\left[\\hat{g}_{h-1}(\\pi^{t})\\hat{\\phi}_{h-1}(\\pi^{t})^{\\top}\\right]\\hat{\\mu}_{h}(x_{h})\\pi_{h}(a_{h}|\\pi_{h})\\epsilon_{h}^{\\prime}(x_{h},a_{h})\\,,}\\\\ &{=\\displaystyle\\mathbb{E}_{\\pi^{+}\\sigma^{\\prime}}\\left[\\sum_{h=2}^{H}\\sum_{\\kappa\\neq\\sigma_{n}\\neq k}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\sum_{h=1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\frac{\\hat{\\phi}_{h-1}(\\pi^{t})^{\\top}\\hat{\\tau}_{h}(x_{h})}{\\hat{d}_{h}^{+}(\\pi_{h})}\\pi_{h}(a_{h}|\\pi_{h})\\epsilon_{h}^{\\prime}(x_{h},a_{h})\\right]\\,,}\\\\ &{=\\displaystyle\\mathbb{E}_{\\pi^{+}\\sigma^{\\prime}}\\left[\\sum_{h=2}^{H}\\sum_{\\sigma\\neq\\kappa,\\sigma_{n}\\neq k}\\hat{Q}_{h-1}(\\pi)^{\\top}\\left(\\sum_{h=1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\hat{d}_{h}^{\\pi^{+}}(x_{h})\\pi_{h}(a_{h}|\\pi_{h})\\epsilon_{h}^{\\prime}(x_{h},a_{h})\\right]\\,,}\\\\ &{=\\displaystyle\\mathbb{E}_{\\pi^{+}\\sigma^{\\prime}}\\left[\\sum_{h=2}^{H}\\sum_{\\sigma\\neq\\sigma_{n}\\neq\\sigma_{n}}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\sum_{h=1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})d_{h}^{\\pi^{+}}(x_{h})\\pi_{h}(a_{h}|\\pi_{h})\\epsilon_{h}^{\\prime}(x_{h},a_{h})\\right]}\\\\ &{\\phantom{=\\;}+ \n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\left[\\displaystyle\\sum_{h=2}^{H}\\sum_{x_{h}\\in\\mathcal{X}}\\sum_{a_{h}\\in\\mathcal{A}}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})d_{h}^{\\pi^{t}}(x_{h},a_{h})\\frac{\\pi_{h}\\left(a_{h}\\mid x_{h}\\right)}{\\pi_{h}^{t}\\left(a_{h}\\mid x_{h}\\right)}\\ell_{h}^{t}(x_{h},a_{h})\\right]}\\\\ &{\\qquad+\\displaystyle\\sum_{h=2}^{H}\\left\\|\\hat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}}\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\left[\\left\\|\\hat{\\phi}_{h-1}(\\pi^{t})\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}}\\right]\\sum_{x_{h}\\in\\mathcal{X}}\\left|\\hat{d}_{h}^{\\pi^{t}}(x_{h})-d_{h}^{\\pi^{t}}(x_{h})\\right|,}\\\\ &{\\leq\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\displaystyle\\sum_{h=2}^{H}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\frac{\\pi_{h}\\left(a_{h}\\mid x_{h}\\right)}{\\pi_{h}^{t}\\left(a_{h}\\mid x_{h}\\right)}\\ell_{h}^{t}(x_{h},a_{h})\\right]}\\\\ &{\\qquad+\\sqrt{d}H\\epsilon\\displaystyle\\sum_{h=2}^{H}\\left\\|\\hat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where (25) follows by Cauchy-Schwarz, and the last inequality uses Lemma C.1. Adding up First and Remain, and using the defintion of $\\hat{\\ell}$ in (22) implies the first inequality of the lemma. ", "page_idx": 18}, {"type": "text", "text": "The second inequality follows the same procedure except for applying Cauchy-Schwarz inequality in the opposite direction in Eq. (24). \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Lemma C.5. 1f ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\quad\\langle\\frac{2|{\\cal A}|H d}{\\beta\\gamma}+d H^{2}\\frac{\\epsilon}{\\sqrt{\\gamma}}\\rangle^{-1},\\,t h e n}\\\\ &{\\quad\\quad\\mathbf{EXP}\\leq\\frac{\\log|\\Pi|}{\\eta}+\\frac{6d\\eta H^{2}|{\\cal A}|T}{\\beta}+4\\eta d^{2}H^{4}\\epsilon^{2}T+4d H^{2}\\epsilon T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where EXP is as in (21). ", "page_idx": 18}, {"type": "text", "text": "Proof ReallinLn 10of Agort2 $\\begin{array}{r}{b^{t}(\\pi):=\\sqrt{d}H\\epsilon\\sum_{h=2}^{H}\\left\\lVert\\widehat{\\phi}_{h-1}(\\pi)\\right\\rVert_{\\left(\\Sigma_{h-1}^{t}\\right)^{-1}}}\\end{array}$ for all $\\pi\\in\\Pi^{\\prime}$ By Lemma C.4, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbf{EXP}=\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{\\pi}p^{t}(\\pi)\\widehat{V}_{1}^{\\pi}\\big(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\big)-\\widehat{V}_{1}^{\\pi^{\\star}}\\big(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\big)\\right]\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad_{1}\\leq\\sum_{n\\leq t}\\gamma^{\\varepsilon}\\left(\\tau\\right)_{n\\leq t},\\quad_{2}\\leq\\varepsilon\\left(\\tau\\right)_{n\\leq t},\\quad_{3}\\leq\\varepsilon\\left(\\tau\\right)_{n\\leq t},}\\\\ &{\\quad+\\sqrt{\\varepsilon\\left(\\left(\\tau\\right)_{n\\leq t}^{\\varepsilon}\\right)}\\frac{\\varepsilon\\left(\\tau\\right)_{n\\leq t}}{\\varepsilon^{\\varepsilon}}\\left(\\tau\\right)_{n\\leq t},\\quad_{1\\leq t}\\leq\\varepsilon\\left(\\tau\\right)_{n\\leq t},}\\\\ &{\\quad+\\sqrt{\\varepsilon\\left(\\tau\\right)_{n\\leq t}^{\\varepsilon}}\\left(\\tau\\right)_{n\\leq t}^{\\varepsilon}\\left(\\tau\\right)_{n\\leq t},\\quad_{3}<\\varepsilon\\left(\\tau\\right)_{n\\leq t},}\\\\ &{\\quad+\\sum_{n\\leq t}\\gamma^{\\varepsilon}\\left(\\tau\\right)_{n\\leq t},\\quad_{2}\\leq\\varepsilon^{\\varepsilon}\\left(\\tau\\right)_{n\\leq t},\\quad_{3}\\leq\\varepsilon\\left(\\tau\\right)_{n\\leq t}}\\\\ &{\\quad-\\frac{\\varepsilon}{\\sqrt{\\varepsilon}\\left(\\tau\\right)_{n\\leq t}}\\left(\\tau\\right)_{n\\leq t}^{\\varepsilon}\\left(\\tau\\right)_{n\\leq t},\\quad_{4}>\\varepsilon\\left(\\tau\\right)}\\\\ &{\\quad-\\frac{\\varepsilon}{\\sqrt{\\varepsilon}\\left(\\tau\\right)_{n\\leq t}}\\left(\\tau\\right)_{n\\leq t}^{\\varepsilon}\\left(\\tau\\right)_{n\\leq t},\\quad_{1\\leq t}\\leq\\varepsilon\\left(\\tau\\right)_{n\\leq t}^{\\varepsilon}\\left(\\tau\\right)_{n\\leq t},\\quad_{2}\\leq\\varepsilon\\left(\\tau\\right)_{n\\leq t}}\\\\ &{\\quad+\\frac{\\varepsilon}{\\sqrt{\\varepsilon}\\left(t\\right)_{n\\leq t}}\\left(\\tau\\right)_{n\\leq t}-\\frac{\\varepsilon}{\\sqrt{\\varepsilon}\\left(t\\right)_{n\\leq t}}\\left(\\tau\\right)_{n\\leq t}^{\\varepsilon}\\sqrt{\\varepsilon\\left(t\\right)_{n\\leq t}^{\\varepsilon}}\\left(\\tau\\right)_{n\\leq t}+\\varepsilon\\left(\\tau\\right)_{n\\leq t}}\\\\ &{\\quad+\\sqrt{\\varepsilon\\left(t\\right)_{n\\leq t}^{\\varepsilon}}\\frac{\\varepsilon\\left(\\tau\\right)_{n\\leq t}}{\\varepsilon^{\\varepsilon}}\\left(\\tau\\right)_{n\\leq t},\\quad_{1\\leq t}\\leq\\varepsilon\\left(\\tau\\right)_{n\\leq t},}\\\\ &{\\quad-\\frac{\\varepsilon}{\\sqrt{\\varepsilon}\\left(t\\right)_{n\\leq t}}\\left(\\tau\\right)_{n\\leq t},\\quad_{2}\\leq\\varepsilon\\left(\\tau\\right) \n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{FTRL}:=\\displaystyle\\sum_{t=1}^{T}\\sum_{\\pi}p^{t}(\\pi)\\cdot\\left(\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},\\pmb{a}_{1:H})\\right]-b^{t}(\\pi)\\right)}\\\\ &{\\qquad\\qquad-\\displaystyle\\sum_{t=1}^{T}\\left(\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\hat{\\ell}^{t}(\\pi^{\\star};\\pi^{t},x_{1:H},\\pmb{a}_{1:H})\\right]-b^{t}(\\pi^{\\star})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We nowbound the FTRL term.Since $\\rho^{t}(\\pi)\\ =\\ (1\\,-\\,\\gamma)p^{t}(\\pi)\\,+\\,\\gamma\\,\\sum_{h=1}^{H}\\,J(\\pi,h)$ . define $\\textstyle\\sum_{J}\\;=$ $\\begin{array}{r l}{\\sum_{\\pi\\in\\Pi}\\sum_{h=1}^{H}J(\\pi,h)\\hat{\\phi}_{h}(\\pi)\\hat{\\phi}_{h}(\\pi)^{\\intercal}}&{{}}\\end{array}$ . Note that for any $t\\in[T]$ and $h\\in[H]$ , we have $\\Sigma_{h}^{t}\\succeq\\gamma\\Sigma_{J}$ ", "page_idx": 19}, {"type": "text", "text": "By the triangle inequality, we have for any $\\pi,\\pi^{t}$ and $\\left(x_{1:H},a_{1:H}\\right)$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},a_{1:H})\\right|\\leq\\displaystyle\\left|\\frac{\\pi_{1}(a_{1}\\mid x_{1})}{\\pi_{1}^{t}(a_{1}\\mid x_{1})}\\cdot\\ell_{1}^{t}(x_{1},a_{1})\\right|}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\sum_{h=2}^{H}\\left|\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\frac{\\pi_{h}(a_{h}\\mid x_{h})}{\\pi_{h}^{t}(a_{h}\\mid x_{h})}\\ell_{h}^{t}(x_{h},a_{h})\\right|,}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{|A|}{\\beta}+\\frac{|A|}{\\beta}\\displaystyle\\sum_{h=2}^{H}\\left|\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\right|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "$\\beta$ -mixure of uniform policy) ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\frac{|{\\cal A}|}{\\beta}+\\frac{|{\\cal A}|}{\\beta\\gamma}\\sum_{h=2}^{H}\\left\\|\\hat{\\phi}_{h-1}(\\pi)\\right\\|_{\\Sigma_{J}^{-1}}\\left\\|\\hat{\\phi}_{h-1}(\\pi^{t})\\right\\|_{\\Sigma_{J}^{-1}},}\\\\ &{\\leq\\displaystyle\\frac{|{\\cal A}|}{\\beta}+\\frac{|{\\cal A}|H d}{\\beta\\gamma},}\\\\ &{\\leq\\displaystyle\\frac{2|{\\cal A}|H d}{\\beta\\gamma},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left|b^{t}(\\pi)\\right|=\\left|\\sqrt{d}H\\epsilon\\sum_{h=2}^{H}\\left\\|\\hat{\\phi}_{h-1}(\\pi)\\right\\|_{\\left(\\Sigma_{h-1}^{t}\\right)^{-1}}\\right|\\leq d H^{2}\\frac{\\epsilon}{\\sqrt{\\gamma}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "To ensure $\\eta\\left|\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},a_{1:H})-b^{t}(\\pi)\\right|\\leq1$ $\\begin{array}{r}{\\eta\\le\\left(\\frac{2|\\mathcal{A}|H d}{\\beta\\gamma}+d H^{2}\\frac{\\epsilon}{\\sqrt{\\gamma}}\\right)^{-1}}\\end{array}$ Under this constraint, from Lemma 1.5, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{FTRL}\\leq\\frac{\\log|\\Pi|}{\\eta}+2\\eta\\sum_{t=1}^{T}\\sum_{\\pi\\in\\Pi^{\\prime}}p^{t}(\\pi)\\cdot\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\hat{\\ell}^{t}(\\pi;\\pi^{t},\\pmb{x}_{1:H},\\pmb{a}_{1:H})^{2}\\right]\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "For any $t\\in[T]$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\tau\\in\\Pi^{\\prime}}p^{t}(\\pi)\\cdot\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},a_{1:H})^{2}\\right]}\\\\ &{\\le H\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\frac{\\pi_{1}(a_{1}\\mid x_{1})^{2}}{\\pi_{1}^{t}(a_{1}\\mid x_{1})^{2}}\\ell_{1}^{t}(x_{1},a_{1})^{2}\\right]}\\\\ &{\\displaystyle\\ \\ +H\\sum_{h=2}^{H}\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\sum_{\\pi\\in\\Pi^{\\prime}}p^{t}(\\pi)\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\hat{\\phi}_{h-1}(\\pi^{t})^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi)\\frac{\\pi_{h}(a_{h})}{\\pi_{h}^{t}(a_{h})}+\\mathcal{O}_{h-1}(\\pi^{t})^{2}\\right]}\\\\ &{\\le\\displaystyle\\frac{H|A|}{\\beta}+2H\\sum_{h=2}^{H}\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\mathrm{Tr}\\left(\\hat{\\phi}_{h-1}(\\pi^{t})\\hat{\\phi}_{h-1}(\\pi^{t})^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\right)\\sum_{a\\in A}\\frac{\\pi_{h}(a\\mid x_{h})^{2}}{\\pi_{h}^{t}(a\\mid x_{h})}\\ell_{h}^{t}(x_{h},a)^{2}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where (29) follows by the fact that $\\begin{array}{r}{p^{t}(\\pi)\\leq\\frac{1}{1-\\gamma}\\rho^{t}(\\pi)}\\end{array}$ and $\\begin{array}{r}{\\frac{1}{1-\\gamma}\\leq2}\\end{array}$ . Thus, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{Stability-1}=2\\eta\\sum_{\\pi\\in\\Pi^{\\prime}}p^{t}(\\pi)\\cdot\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},a_{1:H})^{2}\\right]\\le\\frac{6d\\eta H^{2}|A|T}{\\beta}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Moreover, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\mathrm{Stability-2}=2\\eta\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{\\tau\\in\\Pi^{\\prime}}p^{t}(\\pi)b^{t}(\\pi)^{2}\\right]},}\\\\ {~~}\\\\ {{\\displaystyle~=2\\eta d H^{3}\\epsilon^{2}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{h=2}^{H}\\sum_{\\pi\\in\\Pi^{\\prime}}p^{t}(\\pi)\\left\\|\\hat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}}^{2}\\right]},}\\\\ {~~}\\\\ {{\\displaystyle~~\\leq4\\eta d H^{3}\\epsilon^{2}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{h=1}^{H-1}\\sum_{\\tau\\in\\Pi^{\\prime}}\\rho^{t}(\\pi)\\left\\|\\hat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}}^{2}\\right]},}\\\\ {~~}\\\\ {{\\displaystyle~~\\leq4\\eta d^{2}H^{4}\\epsilon^{2}T.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Combing Lema C.2, Lemma C.3 and Lemma C5, $\\begin{array}{r}{\\eta\\le\\left(\\frac{2|A|H d}{\\beta\\gamma}+d H^{2}\\frac{\\epsilon}{\\sqrt{\\gamma}}\\right)^{-1}}\\end{array}$ ,we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n{\\mathrm{Reg}}_{T}(\\pi_{0}^{\\star})\\leq H\\gamma T+2H^{2}\\beta T+H^{2}T\\epsilon+\\frac{\\log|\\Pi|}{\\eta}+\\frac{6d\\eta H^{2}|\\mathcal{A}|T}{\\beta}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\displaystyle{+\\,4\\eta d^{2}H^{4}\\epsilon^{2}T+4d H^{2}\\epsilon T+\\mathcal{O}\\left(\\frac{H^{3}d^{2}|A|(d^{2}+|A|)}{\\epsilon^{2}}\\log^{2}\\left(T d H|\\Phi||\\Upsilon|\\right)\\right).}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "By seting $\\begin{array}{r}{\\epsilon=T^{-\\frac{1}{3}},\\gamma=T^{-\\frac{1}{3}},\\beta=T^{-\\frac{1}{3}},\\eta=\\frac{1}{4H d|A|}T^{-\\frac{2}{3}}}\\end{array}$ we have for any $\\pi_{0}^{\\star}\\in\\Pi$ \uff0c $\\mathrm{Reg}_{T}(\\pi_{0}^{\\star})\\leq\\mathcal{O}\\left(d^{2}H^{3}|A|(d^{2}+|A|)T^{\\frac23}\\log|\\Pi|\\log^{2}\\left(T d H|\\Phi||\\Upsilon|\\right)\\right).$ ", "page_idx": 21}, {"type": "text", "text": "D  More Details of Inefficient Model-Free Algorithm in Section 4.1 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "D.1  Algorithm Description ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we give a more detailed introduction of the algorithm mentioned in Section 4.1. This algorithm is model-free and achieves $T^{\\frac{2}{3}}$ regret, but it is computationally inefficient. We consider the low-rank MDPs with linear losses that satisfies Assumption 2.1 and Assumption 2.2. ", "page_idx": 22}, {"type": "text", "text": "Let $\\mathcal{C}\\left(S,\\epsilon^{\\prime}\\right)$ be $\\epsilon^{\\prime}$ -net ofspace $S$ . We define necessary policy and function classes in Definition D.1. ", "page_idx": 22}, {"type": "text", "text": "Definition D.1. We define linear policy class and its discretization as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Pi_{\\mathrm{lin}}=\\Bigg\\{\\pi:\\mathcal{X}\\rightarrow\\Delta(\\mathcal{A})\\Bigm|\\pi_{h}(a\\mid x)=\\mathbb{I}\\Big\\{a=\\underset{a\\in\\mathcal{A}}{\\mathrm{argmin}}\\,\\phi_{h}(x,a)^{\\top}\\theta_{h}\\Big\\},\\ h\\in\\big[H\\big],\\ \\theta_{h}\\in\\mathbb{B}_{d}\\Bigm(\\sqrt{d}H T\\Big),\\ \\phi\\in\\mathbb{C}\\Bigg\\}}\\\\ &{\\big(\\epsilon^{\\prime}\\big)=\\Bigg\\{\\pi:\\mathcal{X}\\rightarrow\\Delta(\\mathcal{A})\\Bigm|\\pi_{h}(a\\mid x)=\\mathbb{I}\\Big\\{a=\\underset{a\\in\\mathcal{A}}{\\mathrm{argmin}}\\,\\phi_{h}(x,a)^{\\top}\\theta_{h}\\Big\\},\\ h\\in\\big[H\\big],\\ \\theta_{h}\\in\\mathcal{C}\\Big(\\mathbb{B}_{d}\\Big(\\sqrt{d}H T\\Big),\\epsilon^{\\prime}\\big)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Define corresponding function class as follows ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{F}^{\\pi}=\\left\\{\\int f:\\mathcal{X}\\to[-1,1]\\~\\middle|~f(x)=\\sum_{a}\\pi(a|x)\\phi(x,a)^{\\top}\\theta,~f o r~\\theta\\in\\mathbb{B}^{d}(\\sqrt{d})~a n d~\\phi\\in\\Phi\\right\\}}\\\\ &{\\quad\\mathcal{F}=\\left\\{f:\\mathcal{X}\\to[-1,1]~\\middle|~f\\in\\bigcup_{\\pi\\in\\Pi_{\\mathrm{in}}}\\mathcal{F}^{\\pi}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Our main algorithm is given in Algorithm 5, which shares the same structure as Algorithm 2, but with a different initial phase to learn expected feature estimator $\\begin{array}{r}{\\hat{\\phi}_{h}(\\pi)=\\sum_{(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\hat{d}_{h}^{\\pi}(x)\\pi(a|x)\\hat{\\phi}_{h}(x,a)}\\end{array}$ to approximate $\\begin{array}{r}{\\phi_{h}^{\\star}(\\pi)=\\sum_{(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}d_{h}^{\\pi}(x)\\pi(a|x)\\phi_{h}^{\\star}(x,a)}\\end{array}$ for every $h\\in[H]$ . In Algorithm 2, under Assumption 3.1, it is feasible to use established model-based approach to learn an accurate estimated transition $\\widehat{P}$ together with itsfeature $\\hat{\\phi}$ The occupancy estimator $\\hat{d}_{1:H}^{\\pi}$ is induced by $\\widehat{P}$ which also enjoy small errors. However, when we move to model-free settings with Assumption 4.1, there is no existing approach that could guarantee a good estimation for $\\hat{d}_{h}^{\\pi}(x)$ and $\\hat{\\phi}$ ", "page_idx": 22}, {"type": "text", "text": "To tackle this challenge, we first call Vox (Mhammedi et al., 2023) to construct a policy cover $\\Psi_{1:H}^{\\mathrm{cov}}$ and then playeverypolicyin $\\Psi_{1:H}^{\\mathrm{cov}}$ for $n$ episdeslldqlyd are fed into Algorithm 6 to jointly solve estimated occupancy $\\hat{d}_{1:H}^{\\pi}$ and feature $\\hat{\\phi}_{1:H}$ Algorithm 6 is similar to (Liu et al., 2023, Algorithm 1), which is used to estimate occupancy on the fly for linear MDP. In Algorithm 6, given a target policy $\\pi$ we jointly solve $\\widehat{\\phi}_{1:H}\\,\\in\\,\\Phi$ \uff0c $\\hat{d}_{1:H}^{\\pi}\\,\\in\\,[0,1]^{|\\mathcal{X}|}$ and $(\\hat{\\xi}_{1:H,f})_{f\\in\\mathcal{F}^{\\pi}}\\subset\\mathbb{B}^{d}\\left(\\sqrt{d}\\right)$ that satisfies four constrains, where $\\hat{\\xi}_{h,f}$ is the estimation of $\\xi_{h,f}^{\\star}:=$ $\\begin{array}{r}{\\sum_{x^{\\prime}\\in\\mathcal{X}}\\mu_{h+1}^{\\star}(x^{\\prime})f(x^{\\prime})}\\end{array}$ The first constraint Eq. (30) ensures the estimated occupancy $\\hat{d}_{1:H}^{\\pi}$ are valid distrbutions. The second constrant Eq. (31) enforces the estimated values to follow the dynamic programming relationship between the occupancy of layer $h$ and layer $h\\!+\\!1$ , which helps to control the propagation of estimation errors across layers through the bias of $\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}$ . The third constrain Eq. (32) and fourth constrain Eq. (33) are then used to bound the estimated bias of $\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}$ by utlizing thedata colleted from policiesin policy covers $\\Psi_{1:H}^{\\mathrm{cov}}$ NotethaalingE3q access to the whole state space, which is an additional assumption not needed in previous algorithms. The gurantee of Algorithm 5 is given in Theorem D.1, where the $\\widetilde O$ hides the logarithmic dependence on $d,H,|A|,T$ ", "page_idx": 22}, {"type": "text", "text": "Theorem D.1. Algorithm 5 ensures $\\mathrm{Reg}_{T}\\leq\\widetilde O\\\\Big(d^{8}H^{6}|A|T^{\\frac{2}{3}}\\log(|\\Phi|))\\Big).$ ", "page_idx": 22}, {"type": "text", "text": "Input: Policy class $\\textstyle\\Pi=\\prod_{\\operatorname*{lin}}^{\\operatorname{cov}}\\left({\\frac{1}{T}}\\right)$   \n1: Set $\\epsilon=18^{-1}d^{\\frac{5}{2}}T^{-\\frac{1}{3}}$ $\\begin{array}{r}{,\\gamma=T^{-\\frac{\\star}{3}},\\beta=T^{-\\frac{1}{3}},\\eta=(4H d|A|)^{-1}T^{-\\frac{2}{3}},n=11250d^{\\frac{5}{2}}|A|T^{\\frac{2}{3}}\\log\\frac{3d n H T|\\Phi|}{\\delta}}\\end{array}$ and $T_{0}=\\widetilde{\\cal O}\\left(\\epsilon^{-2}|A|d^{13}H^{6}\\log(|\\Phi|/\\delta))\\right)$   \n2: Get $\\Psi_{1:H}^{\\mathrm{cov}}\\leftarrow\\nabla\\mathsf{o X}(\\Phi,\\varepsilon,\\delta)$ using $T_{0}$ episodes. $\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}$ $n$ $\\left(\\mathcal{D}_{h}^{\\pi^{\\prime}}\\right)_{h\\in[H]}$ where $\\mathcal{D}_{h}^{\\pi^{\\prime}}$ consists of tuples $(x,a,x^{\\prime})$ such that $(x,a)\\sim d_{h}^{\\pi^{\\prime}}$ and $x^{\\prime}\\sim P^{\\star}(\\cdot\\mid x,a)$   \n4:Define the policy space $\\Pi^{\\prime}=\\left\\{\\pi^{\\prime}:\\;\\exists\\pi\\in\\Pi\\right.$ \uff0c $\\pi_{h}^{\\prime}\\(\\cdot\\mid x)=(1-\\beta)\\pi_{h}(\\cdot\\mid x)+\\beta/\\vert A\\vert,\\;\\;\\forall x,h\\}.$ $\\hat{\\phi}_{h}(\\cdot)\\gets\\mathrm{EOM-PC}\\left(\\Pi^{\\prime},\\left(\\mathcal{D}_{h}^{\\pi^{\\prime}}\\right)_{h\\in[H],\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}}\\right)$ from Algorithm 6.   \n6: for $t=T_{0}+1$ \uff0c $T_{0}+2,\\ldots,T$ do   \n7: Define $p^{t}(\\pi)\\propto\\exp\\left(-\\eta\\sum_{i=1}^{t-1}\\left(\\hat{\\ell}^{i}(\\pi)-b^{i}(\\pi)\\right)\\right)$ , for all $\\pi\\in\\Pi^{\\prime}$   \n8: Let $\\begin{array}{r}{\\rho^{t}(\\pi)=(1-\\gamma)p^{t}(\\pi)+\\frac{\\gamma}{H-1}\\sum_{h=1}^{H-1}J_{h}}\\end{array}$ ,where $J_{h}=\\mathsf{J o h n}\\big(\\hat{\\phi}_{h}\\big(\\cdot\\big),\\Pi^{\\prime}\\big)$ -/ John as in 2   \n9: Execute policy $\\pi^{t}\\sim\\rho^{t}$ and observe trajectory $(\\pmb{x}_{1:H}^{t},\\pmb{a}_{1:H}^{t})$ and losses $\\pmb{\\ell}_{h}^{t}=\\ell_{h}^{t}(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t})$   \n10: Define $\\begin{array}{r}{\\Sigma_{h}^{t}=\\sum_{\\pi\\in\\Pi^{\\prime}}\\rho^{t}(\\pi)\\cdot\\hat{\\phi}_{h}(\\pi)\\hat{\\phi}_{h}(\\pi)^{\\intercal}}\\end{array}$ $\\begin{array}{r}{b^{t}(\\pi)=d^{\\frac{11}{2}}H T^{-\\frac{1}{3}}\\cdot\\sum_{h=1}^{H-1}\\|\\widehat{\\phi}_{h}(\\pi)\\|_{(\\Sigma_{h}^{t})^{-1}}}\\end{array}$ , and ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\hat{\\ell}^{t}(\\pi)=\\frac{\\pi_{1}(a_{1}^{t}\\mid x_{1}^{t})}{\\pi_{1}^{t}(a_{1}^{t}\\mid x_{1}^{t})}\\ell_{1}^{t}+\\sum_{h=2}^{H}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\left(\\Sigma_{h-1}^{t}\\right)^{-1}\\hat{\\phi}_{h-1}(\\pi^{t})\\frac{\\pi_{h}(a_{h}^{t}\\mid x_{h}^{t})}{\\pi_{h}^{t}(a_{h}^{t}\\mid x_{h}^{t})}\\ell_{h}^{t}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "11: end for ", "page_idx": 23}, {"type": "text", "text": "$\\begin{array}{r}{\\mathbf{Algorithm\\6\\EOM-PC}\\Big(\\Pi,\\Big(\\mathcal{D}_{h}^{\\pi^{\\prime}}\\Big)_{h\\in[H],\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}}\\Big)}\\end{array}$ (Estimate Occupancy Measure with Policy Cover) ", "page_idx": 23}, {"type": "text", "text": "Input: The policy class $\\Pi$ datasets $\\left(\\mathcal{D}_{h}^{\\pi^{\\prime}}\\right)_{h\\in[H]}$ forevery $\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}$   \nJointly find $\\hat{\\phi}_{h}\\in\\Phi$ $(\\hat{d}_{h}^{\\pi})_{\\pi\\in\\Pi}\\in[0,1]^{|\\mathcal{X}|}$ , and $\\left(\\hat{\\xi}_{h,f}\\right)_{f\\in\\mathcal{F}}\\subset\\mathbb{B}^{d}\\left(\\sqrt{d}\\right)$ for any $h\\in[H]$ such that for all $\\pi\\in\\Pi$ \uff0c ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{x\\in\\mathcal{X}}\\hat{d}_{h}^{\\pi}(x)=1,\\qquad\\forall h\\in[H]\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{x^{\\prime}\\in\\mathcal{X}}\\hat{d}_{h+1}^{\\pi}(x^{\\prime})f(x^{\\prime})=\\sum_{x\\in\\mathcal{X}}\\sum_{a\\in\\mathcal{A}}\\hat{d}_{h}^{\\pi}(x)\\pi(a|x)\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f},\\qquad\\forall f\\in\\mathcal{F},h\\in[H]\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}-\\displaystyle\\operatorname*{min}_{(\\phi,\\xi)\\in\\Phi\\times\\mathbb{B}_{d}(\\sqrt{d})}\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\phi(x,a)^{\\top}\\xi\\right)^{2}}&{{}}\\\\ {\\displaystyle\\leq132d^{\\frac{3}{2}}\\log(3d n H T|\\Phi|/\\delta),\\quad}&{{}\\forall\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}},\\,\\,f\\in\\mathcal{F},h\\in[H]}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\boldsymbol{x},\\boldsymbol{a}}\\left|\\hat{\\phi}_{h}(\\boldsymbol{x},\\boldsymbol{a})^{\\top}\\hat{\\xi}_{h,f}\\right|\\leq1\\qquad\\forall f\\in\\mathcal{F},h\\in[H]\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Output: $\\begin{array}{r}{\\hat{\\phi}_{h}:\\Pi\\to\\mathbb{R}^{d},\\hat{\\phi}_{h}(\\pi)=\\sum_{(x,a)\\in\\mathcal{X}\\times\\mathcal{A}}\\hat{d}_{h}^{\\pi}(x)\\pi(a|x)\\hat{\\phi}_{h}(x,a),\\forall h\\in[H].}\\end{array}$ ", "page_idx": 23}, {"type": "text", "text": "D.2 Analysis of Occupancy Estimation from Algorithm 6 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Lemma D.1. With probability 1 - 8, $\\phi_{1:H}^{\\star},(d_{1:H}^{\\pi})_{\\pi\\in\\Pi^{\\prime}}$ and $\\begin{array}{r}{\\xi_{h,f}^{\\star}\\;:=\\;\\sum_{x^{\\prime}\\in\\mathcal{X}}\\mu_{h+1}^{\\star}(x^{\\prime})f(x^{\\prime}),\\forall f\\;\\in}\\end{array}$ $\\mathcal{F},\\forall h\\in[H]$ is a solution to Algorithm 6. ", "page_idx": 23}, {"type": "text", "text": "Proof. Since for any policy $\\pi$ and any $h\\in[H],\\textstyle\\sum_{x\\in\\mathcal{X}}d_{h}^{\\pi}(x)=1$ , Eq. (30) holds. For any policy $\\pi$ any $f\\in\\mathcal{F}^{\\pi}$ and any $h\\in[H]$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\sum_{x^{\\prime}\\in\\mathcal{X}}d_{h+1}^{\\pi}(x^{\\prime})f(x^{\\prime})=\\sum_{x^{\\prime}\\in\\mathcal{X}}\\sum_{x\\in\\mathcal{X}}\\sum_{a\\in\\mathcal{A}}d_{h}^{\\pi}(x)\\pi(a|x)P_{h}^{\\star}(x^{\\prime}\\,|\\,x,a)f(x^{\\prime})}}\\\\ {{\\displaystyle=\\sum_{x\\in\\mathcal{X}_{h}}\\sum_{a\\in\\mathcal{A}}d_{h}^{\\pi}(x)\\pi(a|x)\\phi_{h}^{\\star}(x,a)^{\\top}\\sum_{x^{\\prime}\\in\\mathcal{X}_{h+1}}\\mu_{h+1}^{\\star}(x^{\\prime})f(x^{\\prime})}}\\\\ {{\\displaystyle=\\sum_{x\\in\\mathcal{X}_{h}}\\sum_{a\\in\\mathcal{A}}d_{h}^{\\pi}(x)\\pi(a|x)\\xi_{h,f}^{\\star}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, Eq. (31) holds. From Exercise 27.6 of Lattimore and Szepesvari (2020), the $\\epsilon$ -net of $\\mathbb{B}_{d}(R)$ is $\\left(\\frac{3R}{\\epsilon}\\right)^{d}$ Thus. $\\begin{array}{r}{\\big|\\Pi^{\\prime}\\big|=\\Big|\\Pi_{\\mathrm{lin}}^{\\mathrm{cov}}\\big(\\frac{1}{T}\\big)\\Big|=\\big|\\Phi\\big|\\left(3\\sqrt{d}H T^{2}\\right)^{d}}\\end{array}$ . We also have $\\left|{\\mathcal{C}}\\left(\\mathbb{B}_{d}({\\sqrt{d}}),{\\frac{1}{T}}\\right)\\right|=\\left(3{\\sqrt{d}}T\\right)^{d}$ and for any policy $\\pi,\\left|{\\mathcal{C}}\\left({\\mathcal{F}}^{\\pi},{\\frac{1}{T}}\\right)\\right|=\\left|\\Phi\\right|\\left(3{\\sqrt{d}}T\\right)^{d}$ . To consider all possible instances, define ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{N}_{T}:=|\\Pi^{\\prime}|\\left|\\mathcal{C}\\left(\\mathbb{B}_{d}(\\sqrt{d}),\\epsilon\\right)\\right||\\mathcal{C}\\left(\\mathcal{F}^{\\pi},\\epsilon\\right)||\\Psi_{1:H}^{\\mathrm{cov}}|\\,|\\Phi|H\\leq d H^{2}|\\Phi|^{3}\\left(3\\sqrt{d}H T^{2}\\right)^{3d}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, by union bound, with probability of ${1\\!-\\!\\delta}$ for every $\\pi\\in\\Pi^{\\prime}$ , every $\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}$ , every $f\\in\\mathcal{C}\\left(\\mathcal{F}^{\\pi},\\epsilon\\right)$ every $\\xi\\in{\\mathcal{C}}\\left(\\mathbb{B}_{d}(\\sqrt{d}),\\epsilon\\right)$ , every $\\phi\\in\\Phi$ and every $h\\in[H]$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}{\\sum}\\left(f(x^{\\prime})-\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}\\right)^{2}-\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}{\\sum}\\left(f(x^{\\prime})-\\phi(x,a)^{\\top}\\xi\\right)^{2}}\\\\ &{=-2\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}{\\sum}\\left(f(x^{\\prime})-\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}\\right)\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\phi(x,a)^{\\top}\\xi\\right)}\\\\ &{\\qquad-\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}{\\sum}\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\phi(x,a)^{\\top}\\xi\\right)^{2}}\\\\ &{=-2\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}{\\sum}\\left(f(x^{\\prime})-\\mathbb{E}_{x^{\\prime}\\sim P^{*}}(\\cdot|x,a)[f(x^{\\prime})]\\right)\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\phi(x,a)^{\\top}\\xi\\right)}\\\\ &{\\qquad-\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}{\\sum}\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\phi(x,a)^{\\top}\\xi\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Bounding the distance through $\\textstyle{\\frac{1}{T}}$ -net, we havewith probability of $1-\\delta$ , for every $\\pi\\in\\Pi^{\\prime}$ , every $\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}$ , every $f\\in\\mathcal{F}^{\\pi}$ , every $\\xi\\in\\mathbb{B}_{d}(\\sqrt{d})$ , every $\\phi\\in\\Phi$ and every $h\\in[H]$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{^7\\in{\\mathcal D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}\\right)^{2}-\\displaystyle\\sum_{x,a,x^{\\prime}\\in{\\mathcal D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\phi(x,a)^{\\top}\\xi\\right)^{2}\\le120d^{\\frac{3}{2}}\\log\\frac{3d H T|\\Phi|}{\\delta\\epsilon}+\\frac{12\\sqrt{d}n}{T}}\\\\ &{\\quad+O(\\ensuremath{\\epsilon^{2}})=1.}\\\\ &{\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\le132d^{\\frac{3}{2}}\\log\\frac{3d n H T|\\Phi|}{\\delta}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, Eq. (32) also holds. Finally, for all $x,a$ ,wehave ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\left\\vert\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}\\right\\vert=\\left\\vert\\sum_{x^{\\prime}\\in\\mathcal{X}}\\phi_{h}^{\\star}(x,a)^{\\top}\\mu_{h+1}^{\\star}(x^{\\prime})f(x^{\\prime})\\right\\vert=\\left\\vert\\sum_{x^{\\prime}\\in\\mathcal{X}}P^{\\star}\\left(x^{\\prime}\\ \\left\\vert\\ x,a\\right)f(x^{\\prime})\\right\\vert\\leq1.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, $\\phi_{h}^{\\star},d_{h}^{\\pi}$ , and $\\begin{array}{r}{\\xi_{h,f}^{\\star}:=\\sum_{x^{\\prime}\\in\\mathcal{X}}\\mu_{h+1}^{\\star}(x^{\\prime})f(x^{\\prime}),\\forall f\\in\\mathcal{F}^{\\pi},h\\in[H]}\\end{array}$ satisfy all Eq. (30) - Eq (33) and is a solution to Algorithm 6. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "Lemma D.2. With probability $1-\\delta_{i}$ for all $f\\in\\mathcal F$ any solution $\\hat{d}^{\\pi}$ from Algorithm 6 for any $\\pi\\in\\Pi^{\\prime}$ satisfies ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\left|\\sum_{x}(\\hat{d}_{h}^{\\pi}(x)-d_{h}^{\\pi}(x))f(x)\\right|\\le d^{5}H T^{-\\frac{1}{3}}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "For every solution $\\hat{\\phi}_{1:H},\\hat{\\xi}_{1:H,f\\in\\mathcal{F}^{\\pi}},\\big(\\hat{d}_{1:H}^{\\pi}\\big)_{\\pi\\in\\Pi^{\\prime}}$ of Algorithm 6, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}-\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}\\right)^{2}}\\\\ &{=\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}-\\operatorname*{min}_{(\\phi,\\xi)}\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\phi(x,a)^{\\top}\\xi\\right)^{2}}\\\\ &{\\displaystyle\\qquad+\\operatorname*{min}_{(\\phi,\\xi)}\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\phi(x,a)^{\\top}\\xi\\right)^{2}-\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}}\\left(f(x^{\\prime})-\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "equation", "text": "$$\n\\leq132d^{\\frac{3}{2}}\\log\\frac{3d n H T|\\Phi|}{\\delta}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the last step comes from the constrain Eq. (32). On the other hand ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\begin{array}{r l}&{2\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\left(f(x^{\\prime})-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}-2\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\left(f(x^{\\prime})-\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}\\right)^{2}}\\\\ &{=4\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\left(f(x^{\\prime})-\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}\\right)\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)}\\\\ &{\\phantom{\\begin{array}{r l}&{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\\\ &{+2\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}}\\end{array}}}\\\\ &{\\begin{array}{r l}&{\\displaystyle=4\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\left(f(x^{\\prime})-\\mathbb{E}_{x^{\\prime}\\sim P^{*}(\\cdot|x,a)}[f(x^{\\prime})]\\right)\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}}\\\\ &{\\phantom{\\begin{array}{r l}&{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\\\ &{+2\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h}^{\\prime}}\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}}\\end{array}}}\\end{array}}\\\\ &{\\begin{array}{r l}&{\\displaystyle=4\\displaystyle\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h \n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Combing Eq. (34) and Eq. (35), we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\quad\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h^{\\prime}}^{*}}{\\sum}\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}}\\\\ &{\\leq-4\\sum_{x,a,x^{\\prime}\\in\\mathcal{D}_{h^{\\prime}}^{*}}\\left(f(x^{\\prime})-\\mathbb{E}_{x^{\\prime}\\sim P^{*}(\\cdot|x,a)}[f(x^{\\prime})]\\right)\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)}\\\\ &{\\quad\\quad\\times\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h^{\\prime}}^{*}}{\\sum}\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}}\\\\ &{\\quad\\quad\\quad\\times\\underset{x,a,x^{\\prime}\\in\\mathcal{D}_{h^{\\prime}}^{*}}{\\sum}\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}^{*}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}}\\\\ &{\\quad\\quad\\quad+264d^{\\frac{3}{2}}\\log\\frac{3d n H T[\\Phi]}{\\delta}}\\\\ &{\\leq288d^{\\frac{3}{2}}\\log\\frac{3d n H T[\\Phi]}{\\delta}}&{\\mathrm{(Lemma~L2~wit)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since for every data tuple $(x,a,x^{\\prime})\\in\\mathcal{D}_{h}^{\\pi^{\\prime}}$ \uff0c $(x,a)\\sim d_{h}^{\\pi^{\\prime}}$ independently, by Lemma I.3, for every $\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}$ wehave ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\tau^{\\prime}\\left[\\left(\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}\\right]\\leq\\frac{2}{n}\\sum_{x,a\\in\\mathcal{D}_{h}^{\\tau^{\\prime}}}\\left(\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}+\\frac{24d\\log\\left(\\frac{6\\sqrt{\\pi}}{h}\\xi_{h,f}^{\\star}-\\xi_{h,f}\\right)}{n}\\xi_{h,f}^{\\star}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "equation", "text": "$$\n\\leq\\frac{600d^{\\frac{3}{2}}}{n}\\log\\frac{3d n H T|\\Phi|}{\\delta}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "This implies there exists a representation $\\hat{\\phi}_{1:H}(x,a)$ such that for every $f\\in\\mathcal F$ and any $h\\in[H]$ , there exists $\\hat{\\xi}_{h,f}$ such that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi^{\\prime}\\in\\Psi_{1:H}^{\\mathrm{cov}}}\\mathbb{E}^{\\pi^{\\prime}}\\left[\\left(\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)^{2}\\right]\\leq\\frac{600d^{\\frac{3}{2}}}{n}\\log\\frac{3d n H T|\\Phi|}{\\delta}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Eq. (36) matches Eq. (99) with a different error bound on the right hand. From Lemma G.1, we have $\\Psi_{h}^{\\mathrm{cov}}$ isa $(\\textstyle{\\frac{1}{8A d}},\\varepsilon)$ policycover forlayer $h$ follwingtherest o thepro in LemaG.2,forevery $\\pi$ and every $\\bar{f}\\in\\mathcal{F},h\\in[H]$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left|\\mathbb{E}^{\\pi}\\left[\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right]\\right|\\leq\\frac{75d^{\\frac{5}{4}}}{\\sqrt{n}}\\sqrt{|A|\\log\\frac{3d n H T|\\Phi|}{\\delta}}+9d^{\\frac{5}{2}}\\epsilon.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The $d^{\\frac{5}{2}}$ in the second term of Eq. (37) improves the $d^{\\frac{7}{2}}$ term in Eq. (98) because $\\hat{\\xi}_{h,f}\\in\\mathbb{B}_{d}(\\sqrt{d})$ rather than $\\mathbb{B}_{d}(d^{\\frac{3}{2}})$ . Putting the choice $n=11250d^{\\frac{5}{2}}|A|T^{\\frac{2}{3}}\\log{\\frac{3d n H T|\\Phi|}{\\delta}}$ 3dnHTI\u03a6 and e = T-3 into Eq. (37), we have for every $\\pi$ and every $f\\in\\mathcal{F},h\\in[H]$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\mathbb{E}^{\\pi}\\left[\\phi_{h}^{\\star}(x,a)^{\\top}\\xi_{h,f}^{\\star}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right]\\right|\\leq d^{5}T^{-\\frac{1}{3}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Utilizing above results, for every $\\pi$ , every $f\\in\\mathcal F$ and any $h\\in[H-1]$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{x}(\\hat{d}_{h+1}^{x}(x)-d_{h+1}^{x}(x))f(x)\\Bigg|}\\\\ &{=\\left|\\sum_{x,a}\\hat{d}_{h}^{x}(x)\\pi_{h}(a\\,|\\,x)\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}-\\sum_{x,a}d_{h}^{x}(x)\\pi(a\\,|\\,x)\\phi_{h}^{*}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right|}\\\\ &{\\le\\displaystyle\\left|\\sum_{x,a}d_{h}^{x}(x)\\pi_{h}(a\\,|\\,x)\\left(\\phi_{h}^{*}(x,a)^{\\top}\\xi_{h,f}-\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}\\right)\\right|}\\\\ &{\\displaystyle\\ \\ \\ \\ +\\left|\\sum_{x}\\left(\\hat{d}_{h}^{x}(x)-d_{h}^{x}(x)\\right)\\underbrace{\\sum_{a}\\pi_{h}(a\\,|\\,x)\\hat{\\phi}_{h}(x,a)^{\\top}\\hat{\\xi}_{h,f}}_{\\leqslant x}\\right|}\\\\ &{\\le d^{5}T^{-\\frac{1}{3}}+\\left|\\sum_{x}\\left(\\hat{d}_{h}^{x}(x)-d_{h}^{x}(x)\\right)f^{\\prime}(x)\\right|}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where in the last step, we define $\\begin{array}{r}{f^{\\prime}(x)\\;=\\;\\sum_{a}\\pi_{h}(a|x)\\hat{\\phi}_{h}(x,a)^{\\intercal}\\hat{\\xi}_{h,f}\\;\\in\\;\\mathcal{F}}\\end{array}$ . This allow us to use recursion to finish the proof. ", "page_idx": 26}, {"type": "text", "text": "D.3  Regret Analysis ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We begin by proving Lemma D.3, showing that the policy class $\\Pi_{\\mathrm{lin}}^{\\mathrm{cov}}(\\epsilon^{\\prime})$ suffces to approximate all policies with small error. ", "page_idx": 26}, {"type": "text", "text": "Lemma D.3. For any policy $\\pi$ , there exists a policy $\\pi^{\\prime}\\in\\Pi_{\\mathrm{lin}}^{\\mathrm{cov}}\\big(\\epsilon^{\\prime}\\big)$ such that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}V_{1}^{\\pi^{\\prime}}\\big(x_{1};\\ell^{t}\\big)-\\sum_{t=1}^{T}V_{1}^{\\pi}\\big(x_{1};\\ell^{t}\\big)\\leq H\\epsilon^{\\prime}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. Let $\\theta_{h}^{t,\\pi}\\in\\mathbb{B}_{d}(H\\sqrt{d})$ be such that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\forall(x,a)\\in\\mathcal{X}\\times\\mathcal{A},\\quad Q_{h}^{\\pi}(x,a;\\ell^{t})=\\phi_{h}^{\\star}(x,a)^{\\top}\\theta_{h}^{\\pi,t}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Such a $\\theta_{h}^{\\pi,t}$ is guaranteed to exist by the low-rank MDP structure (Assumption 2.1) and Assumption2Frevery $h\\in[H]$ sice $\\begin{array}{r}{\\sum_{t=1}^{T}\\theta_{h}^{\\pi,t}\\in\\mathbb{B}_{d}(\\sqrt{d}H T)}\\end{array}$ wedfine $\\theta_{h}^{\\prime}\\in\\mathcal{C}\\left(\\mathbb{B}_{d}\\left(\\sqrt{d}H T\\right),\\epsilon^{\\prime}\\right)$ such that $\\|\\theta_{h}^{\\prime}-\\textstyle\\sum_{t=1}^{T}\\theta_{h}^{\\pi,t}\\|_{2}\\leq\\epsilon^{\\prime}$ , and let $\\pi_{h}(a\\mid x)=\\mathbb{I}\\big\\{a=\\operatorname{argmin}_{a\\in\\mathcal{A}}\\phi_{h}^{\\star}(x,a)^{\\top}\\theta_{h}^{\\prime}\\big\\}$ for every $h\\in[H]$ Wehave $\\pi^{\\prime}\\in\\Pi_{\\mathrm{lin}}^{\\mathrm{cov}}\\big(\\epsilon^{\\prime}\\big)$ . From Lemma I.7, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{=1}^{T}{V_{1}^{\\pi^{\\prime}}(x_{1};\\ell^{t})-\\sum_{t=1}^{T}V_{1}^{\\pi}(x_{1};\\ell^{t})}}\\\\ &{\\displaystyle=\\sum_{t=1}^{T}\\sum_{h=1}^{H}\\mathbb{E}_{x\\sim d_{h}^{\\pi^{\\prime}}}\\Bigg[\\sum_{a\\in A}\\left(\\pi_{h}^{\\prime}(a|x)-\\pi_{h}(a|x)\\right)Q_{h}^{\\pi}(x,a;\\ell^{t})\\Bigg]}\\\\ &{\\displaystyle=\\sum_{h=1}^{H}\\mathbb{E}_{x\\sim d_{h}^{\\pi^{\\prime}}}\\Bigg[\\sum_{a\\in A}\\left(\\pi^{\\prime}(a|x)-\\pi(a|x)\\right)\\phi_{h}^{*}(x,a)^{\\top}\\sum_{t=1}^{T}\\theta_{h}^{\\pi,t}\\Bigg]}\\\\ &{\\displaystyle=\\sum_{h=1}^{H}\\mathbb{E}_{x\\sim d_{h}^{\\pi^{\\prime}}}\\Bigg[\\sum_{a\\in A}\\left(\\pi_{h}^{\\prime}(a|x)-\\pi_{h}(a|x)\\right)\\phi_{h}^{*}(x,a)^{\\top}\\theta_{h}^{\\pi^{\\prime}}\\Bigg]+\\sum_{h=1}^{H}\\mathbb{E}_{x\\sim d_{h}^{\\pi^{\\prime}}}\\Bigg[\\sum_{a\\in A}\\left(\\pi_{h}^{\\prime}(a|x)-\\pi_{h}(a|x)\\right)\\phi_{h}^{*}(x,a)}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "<HE' ", "page_idx": 27}, {"type": "text", "text": "where the last inequality comes from the fact that $\\pi_{h}(a\\mid x)=\\mathbb{I}\\big\\{a=\\operatorname{argmin}_{a\\in{\\cal A}}\\phi_{h}^{\\star}(x,a)^{\\top}\\theta_{h}^{\\prime}\\big\\}$ and $\\begin{array}{r}{\\|\\theta_{h}^{\\prime}-\\sum_{t=1}^{T}\\theta_{h}^{\\pi,t}\\|_{2}\\le\\epsilon^{\\prime}}\\end{array}$ for every $h\\in[H]$ \u53e3 ", "page_idx": 27}, {"type": "text", "text": "From Lemma D.3, for any policy $\\pi_{1}^{\\star}$ , there exists a policy $\\pi_{0}^{\\star}\\in\\Pi_{\\mathrm{lin}}^{\\mathrm{cov}}\\big(\\frac{1}{T}\\big)$ such that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{Reg}_{T}\\bigl(\\boldsymbol{\\pi}_{1}^{\\star}\\bigr)=\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\boldsymbol{\\pi}^{t}}\\bigl(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\bigr)-\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\boldsymbol{\\pi}_{1}^{\\star}}\\bigl(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\bigr)\\right]}}\\\\ &{}&{\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\boldsymbol{\\pi}^{t}}\\bigl(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\bigr)-\\displaystyle\\sum_{t=1}^{T}V_{1}^{\\boldsymbol{\\pi}_{0}^{\\star}}\\bigl(\\boldsymbol{x}_{1};\\boldsymbol{\\ell}^{t}\\bigr)\\right]+1}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Our candidate policy space $\\Pi^{\\prime}$ has a $\\beta$ mixture of the random policy. For any policy $\\pi_{0}^{\\star}\\in\\Pi_{\\mathrm{lin}}^{\\mathrm{cov}}\\big(\\frac{1}{T}\\big)$ \uff0c define policy $\\pi^{\\star}$ such that for any state $x\\in\\mathscr{X}$ , we have $\\begin{array}{r}{\\pi^{\\star}\\big(\\cdot\\mid x\\big)=\\big(1-\\beta\\big)\\pi_{0}^{\\star}\\big(\\cdot\\mid x\\big)+\\frac{\\beta}{\\vert A\\vert}}\\end{array}$ We have $\\pi^{\\star}\\in\\Pi^{\\prime}$ . Define ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\widehat{V}_{1}^{\\pi}(x_{1};\\ell)=\\sum_{h=1}^{H}\\sum_{x_{h}\\in\\mathcal{X}}\\sum_{a_{h}\\in\\mathcal{A}}\\hat{d}_{h}^{\\pi}(x_{h})\\pi_{h}(a_{h}\\mid x_{h})\\cdot\\ell_{h}^{t}(x_{h},a_{h})\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Utilizing Eq. (39) and the decomposition in Eq. (21), together with the fact that $|\\Psi_{h}^{\\mathrm{cov}}|\\leq d$ from Lemma G.1, we have for any policy $\\pi_{1}^{\\star}$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}_{T}(\\pi_{1}^{\\star})}\\\\ &{\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\sum_{\\pi}p^{t}(\\pi)\\left(V_{1}^{\\pi}(x_{1};\\ell^{t})-\\widehat{V}_{1}^{\\pi}(x_{1};\\ell^{t})\\right)\\right]+\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\widehat{V}_{1}^{\\pi^{\\star}}\\big(x_{1};\\ell^{t}\\big)-{V}_{1}^{\\pi^{\\star}}\\big(x_{1};\\ell^{t}\\big)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\underbrace{\\mathbb{E}\\left[\\sum_{t=1}^{T}\\underset{\\pi}{\\sum}p^{t}(\\pi)\\left(V_{1}^{\\pi}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})-\\widehat{V}_{1}^{\\pi}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})\\right)\\right]}_{\\mathrm{Riast}}+\\underbrace{\\mathbb{E}\\left[\\sum_{t=1}^{T}\\widehat{V}_{1}^{\\pi^{\\star}}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})-V_{1}^{\\pi^{\\star}}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})\\right]}_{\\mathrm{Rias2}}}\\\\ &{\\ \\ +\\underbrace{\\mathbb{E}\\left[\\underset{t=1}{\\sum}\\underset{\\pi}{\\sum}p^{t}(\\pi)\\widehat{V}_{1}^{\\pi}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})-\\widehat{V}_{1}^{\\pi^{\\star}}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})\\right]}_{\\mathrm{EXP}}+\\underbrace{\\mathbb{E}\\left[\\underset{t=1}{\\sum}\\underset{\\pi}{\\sum}\\left(\\rho^{t}(\\pi)-p^{t}(\\pi)\\right)V_{1}^{\\pi}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})\\right]}_{\\mathrm{Error1}}}\\\\ &{\\ \\ +\\underbrace{\\mathbb{E}\\left[\\underset{t=1}{\\sum}\\underset{V_{1}^{\\pi^{\\star}}}{\\sum}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})-V_{1}^{\\pi_{0}^{\\star}}(\\mathbf{\\boldsymbol{x}}_{1};\\ell^{t})\\right]}_{\\mathrm{EAP}}+\\widetilde{O}\\left(\\epsilon^{-2}|A|d^{13}H^{6}\\log(|\\Phi|/\\delta))\\right)+d H n}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Following Lemma C.2, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\nE r r o r I+E r r o r2\\leq H\\gamma T+2H^{2}\\beta T\\leq3H^{2}T^{\\frac{2}{3}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Lemma D.4. ", "text_level": 1, "page_idx": 28}, {"type": "equation", "text": "$$\nB i a s I+B i a s2\\leq2d^{5}H^{2}T^{\\frac{2}{3}}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. For any policy $\\pi$ and any $t\\in[T]$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|V_{1}^{\\pi}(x_{1};\\ell^{t})-\\widehat V_{1}^{\\pi}(x_{1};\\ell^{t})\\right|=\\displaystyle\\sum_{h=1}^{H}\\sum_{x_{h}\\in\\mathcal X}\\left|d_{h}^{\\pi}(x_{h})-\\hat{d}_{h}^{\\pi}(x_{h})\\right|\\sum_{a_{h}\\in\\mathcal A}\\pi_{h}(a_{h}\\mid x_{h})\\cdot\\ell_{h}^{t}(x_{h},a_{h})}\\\\ {\\le d^{5}H^{2}T^{-\\frac13}\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\ (\\mathrm{Lemma~})}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Thus, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{Bias1}\\leq d^{5}H^{2}T^{\\frac{2}{3}}\\qquad\\mathrm{and}\\qquad\\mathbf{Bias2}\\leq d^{5}H^{2}T^{\\frac{2}{3}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We now prove a modle-free counterpart of Lemma C.4 in Lemma D.5. ", "page_idx": 28}, {"type": "text", "text": "Lemma D.5. For any episode $t\\in[T]$ for any policy $\\pi$ we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{V}_{1}^{\\pi}(x_{1};\\ell^{t})\\leq\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\widehat{\\ell}^{t}(\\pi;\\pi^{t},{\\pmb x}_{1:H},{\\pmb a}_{1:H})\\right]+d^{\\frac{11}{2}}H T^{-\\frac{1}{3}}\\displaystyle\\sum_{h=2}^{H}\\left\\|\\widehat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}},}\\\\ &{\\widehat{V}_{1}^{\\pi}(x_{1};\\ell^{t})\\geq\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\widehat{\\ell}^{t}(\\pi;\\pi^{t},{\\pmb x}_{1:H},{\\pmb a}_{1:H})\\right]-d^{\\frac{11}{2}}H T^{-\\frac{1}{3}}\\displaystyle\\sum_{h=2}^{H}\\left\\|\\widehat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We now prove the first inequality: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{V}_{1}^{\\pi}(x_{1};\\ell^{t})}\\\\ &{\\ =\\displaystyle{\\sum_{h=1}^{H}\\sum_{x_{h}\\in\\mathcal{X}}\\sum_{a_{h}\\in\\mathcal{A}}\\hat{d}_{h}^{\\pi}(x_{h})\\pi_{h}(a_{h}\\mid x_{h})\\cdot\\ell_{h}^{t}(x_{h},a_{h})},}\\\\ &{\\ =\\displaystyle{\\sum_{a_{1}\\in\\mathcal{A}}\\pi_{1}(a_{1}\\mid x_{1})\\cdot\\ell_{1}^{t}(x_{1},a_{1})+\\sum_{h=2}^{H}\\sum_{x_{h}\\in\\mathcal{X}}\\sum_{a_{h}\\in\\mathcal{A}}\\hat{d}_{h}^{\\pi}(x_{h})\\pi_{h}(a_{h}\\mid x_{h})\\phi_{h}(x_{h},a_{h})^{\\top}g_{h}^{t}(x_{h})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Through importance sampling, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbf{First}=\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[{\\frac{\\pi_{1}(a_{1}\\mid x_{1})}{\\pi_{1}^{t}(a_{1}\\mid x_{1})}}\\cdot\\ell_{1}^{t}(x_{1},a_{1})\\right].\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We now bound the remaining term in (42) Since $\\begin{array}{r}{\\Sigma_{h-1}^{t}=\\mathbb{E}_{\\pmb{\\pi}^{t}\\sim\\rho^{t}}\\left[\\hat{\\phi}_{h-1}(\\pmb{\\pi}^{t})\\hat{\\phi}_{h-1}(\\pmb{\\pi}^{t})^{\\top}\\right]}\\end{array}$ wehave ", "page_idx": 28}, {"type": "text", "text": "Remain ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle=\\sum_{h=2}^{H}\\sum_{x_{h}\\in\\mathcal{X}}\\hat{d}_{h}^{\\pi}(x_{h})\\sum_{\\substack{u_{h}\\in\\mathcal{A}}}\\pi_{h}(a_{h}\\ |\\ x_{h})\\phi_{h}(x_{h},a_{h})^{\\top}g_{h}^{t},}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle=\\sum_{h=2}^{H}\\sum_{x_{h-1}\\in\\mathcal{X}_{h-1}}\\sum_{h=h-1}^{\\infty}\\hat{d}_{h-1}^{\\pi}(x)\\pi_{h-1}(a_{h-1}|x_{h-1})\\hat{\\phi}(x_{h-1},a_{h-1})^{\\top}\\hat{\\xi}_{h-1,f}}}\\\\ {{\\displaystyle=\\sum_{h=2}^{H}\\hat{\\phi}_{h-1}(\\pi)^{\\top}\\hat{\\xi}_{h-1,f}}}\\\\ {{\\displaystyle=\\sum_{h=2}^{H}\\hat{\\phi}_{h-1}(\\pi)^{\\top}(\\Sigma_{h-1}^{t})^{-1}\\mathbb{E}_{\\pi^{t-\\rho^{t}}}[\\hat{\\phi}_{h-1}(\\pi^{t})\\hat{\\phi}_{h-1}(\\pi^{t})^{\\top}]\\hat{\\xi}_{h-1,f}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "$\\begin{array}{r l}&{\\mathbf{S}:=-\\mathbb{E}_{\\mathbf{x}^{\\star}}\\left[\\sum_{k=0}^{\\infty}\\phi_{k+1}^{(1)}(\\mathbf{Y}_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(1)},\\phi_{k+1}^{(2)}(\\mathbf{Y}_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(1)}))\\in\\mathbb{Z}_{0}^{1}\\times\\mathbb{Z}_{1}\\right]}\\\\ &{\\quad\\times\\sum_{k=0}^{\\infty}\\left[\\sum_{k=1}^{\\infty}\\phi_{k+1}^{(1)}(Y_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(1)},\\phi_{k+1}^{(2)}(\\mathbf{Y}_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(2)},\\mathbf{Z}_{0}^{(2)},\\mathbf{Z}_{1}^{(1)}(\\mathbf{Y}_{k-1}^{(1)},\\phi_{k+1}^{(2)}(\\mathbf{Y}_{k-1}^{(1)},\\phi_{k+1}^{(2)}))\\tilde{\\xi}_{k}\\right]}\\\\ &{\\quad\\times\\sum_{k=0}^{\\infty}\\left[\\sum_{k=1}^{\\infty}\\phi_{k+1}^{(1)}(\\mathbf{Y}_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(1)})\\phi_{k+1}^{(2)}(\\mathbf{W}_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(1)},\\phi_{k+1}^{(2)}(\\mathbf{Z}_{0}^{(1)})\\right]}\\\\ &{\\quad\\times\\sum_{k=0}^{\\infty}\\left[\\sum_{k=1}^{\\infty}\\phi_{k+1}^{(1)}(\\mathbf{Y}_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(1)},\\phi_{k+1}^{(2)}(\\mathbf{W}_{k-1}^{(1)},\\mathbf{Y}_{k-1}^{(1)},\\phi_{k+1}^{(2)}(\\mathbf{Z}_{0}^{(1)}))\\right]}\\\\ &{\\quad\\times\\sum_{k=0}^{\\infty}\\left[\\sum_{k=0}^{\\infty}\\phi_{k+1}^{(1)}(\\mathbf{Y}_{k-1}^{(1)},\\$ 1,f )Tgh (43)   \n\u2264E\u03c0t\\~p E\u03c0   \nLh=2 \u03c0(a|h)   \n+dHT-/h-1(m)(x-)1,; H   \nh=2 ", "page_idx": 29}, {"type": "text", "text": "Adding up First and Remain, and using the defintion of $\\hat{\\ell}$ in (22) implies the first inequality of the lemma. ", "page_idx": 29}, {"type": "text", "text": "The second inequality follows the same procedure except for applying Cauchy-Schwarz inequality in the opposite direction in Eq. (43). \u53e3 ", "page_idx": 29}, {"type": "text", "text": "Given Lemma D.5, we could follow the same procedure in Lemma C.5 except replacing the factor of bonus $b^{t}(\\pi)$ from $\\sqrt{d}H\\epsilon$ $d^{\\frac{11}{2}}H T^{-{\\frac{1}{3}}}$ . This leads to the following changes. Firstly, by a similar argument as Eq. (27), we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n{\\bf E X P}={\\bf F T R L}+4d^{6}H^{2}T^{\\frac{2}{3}}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{FTRL}:=\\displaystyle\\sum_{t=1}^{T}\\sum_{\\pi}p^{t}(\\pi)\\cdot\\left(\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},\\pmb{a}_{1:H})\\right]-b^{t}(\\pi)\\right)}\\\\ &{\\qquad\\qquad-\\displaystyle\\sum_{t=1}^{T}\\left(\\mathbb{E}_{\\pi^{t}\\sim\\rho^{t}}\\mathbb{E}^{\\pi^{t}}\\left[\\hat{\\ell}^{t}(\\pi^{\\star};\\pi^{t},x_{1:H},\\pmb{a}_{1:H})\\right]-b^{t}(\\pi^{\\star})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Secondly, now we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\left|b^{t}(\\pi)\\right|=\\left|d^{\\frac{11}{2}}H T^{-\\frac{1}{3}}\\sum_{h=2}^{H}\\left\\|\\hat{\\phi}_{h-1}(\\pi)\\right\\|_{(\\Sigma_{h-1}^{t})^{-1}}\\right|\\leq d^{6}H^{2}\\frac{T^{-\\frac{1}{3}}}{\\sqrt{\\gamma}}=d^{6}H^{2}T^{-\\frac{1}{6}}.\\eqno(\\gamma=T^{-\\frac{1}{3}})\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "To ensure $\\eta\\left|\\hat{\\ell}^{t}(\\pi;\\pi^{t},x_{1:H},a_{1:H})-b^{t}(\\pi)\\right|\\;\\leq\\;1$ , it suffices to set $\\begin{array}{r l r}{\\eta\\!\\!\\!\\!/\\ \\ \\le\\ }&{\\!\\!\\!\\!\\!{\\left(\\frac{2|{\\cal A}|H d}{\\beta\\gamma}+d^{6}H^{2}{\\cal T}^{-\\frac{1}{6}}\\right)}^{-1}\\ =}\\end{array}$ $\\left(2|A|H d T^{\\frac{2}{3}}+d^{6}H^{2}T^{-\\frac{1}{6}}\\right)^{-1}$ from $\\beta=\\gamma=T^{-{\\frac{1}{3}}}$ . Thus our choice $\\eta=(4H d|A|)^{-1}T^{-\\frac{2}{3}}$ satisfies the condition if we assume $T\\geq d^{6}H^{2}$ . Moreover, now we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{Stability-2}\\,\\,2\\eta\\mathbb{E}\\left[\\sum_{t=1}^{T}\\underline{{\\gamma}}^{t}(\\pi)b^{t}(\\pi)^{2}\\right],}}\\\\ &{}&{=2\\eta d^{11}H^{3}T^{-\\frac{2}{3}}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{s=2}^{H}\\sum_{\\tau\\in\\mathbb{T}^{\\prime}}^{t}\\boldsymbol{p}^{t}(\\pi)\\left\\lVert\\hat{\\phi}_{h-1}(\\pi)\\right\\rVert_{(\\Sigma_{h-1}^{t})^{-1}}^{2}\\right],\\quad}\\\\ &{}&{\\le4\\eta d^{11}H^{3}T^{-\\frac{2}{3}}\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T-1}\\sum_{h=1}^{H-1}\\sum_{\\tau\\in\\mathbb{T}^{\\prime}}^{t}\\boldsymbol{\\rho}^{t}(\\pi)\\left\\lVert\\hat{\\phi}_{h-1}(\\pi)\\right\\rVert_{(\\Sigma_{h-1}^{t})^{-1}}^{2}\\right],\\quad}\\\\ &{}&{\\le4\\eta d^{11}H^{4}T^{\\frac{1}{3}}}\\\\ &{}&{\\le d^{10}H^{3}T^{-\\frac{1}{3}}}\\\\ &{}&{\\le d^{4}H T^{3}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Putting these two changes back to the proof into Lemma C.5, given $\\eta=(4H d|A|)^{-1}T^{-\\frac{2}{3}}$ wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{\\mathbf{EXP}={\\frac{\\log\\left|\\Pi_{\\mathrm{lin}}^{\\mathrm{cov}}\\left({\\frac{1}{T}}\\right)\\right|}{\\eta}}+{\\frac{6d\\eta H^{2}|A|T}{\\beta}}+4\\eta d^{2}H^{4}\\epsilon^{2}T+d^{4}H T^{\\frac{2}{3}}+4d^{6}H^{2}T^{\\frac{2}{3}}}\\\\ &{\\qquad={\\widetilde{\\mathcal{O}}}\\left(d^{6}|A|H^{2}T^{\\frac{2}{3}}\\log(|\\Phi|)\\right)}\\end{array}}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Putting Eq. (41), Lemma D.4, Eq. (44) into Eq. (40) together with $\\epsilon=18^{-1}d^{\\frac{5}{2}}T^{-\\frac{1}{3}}$ ,wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}\\leq\\widetilde O\\left(d^{8}H^{6}|A|T^{\\frac{2}{3}}\\log(|\\Phi|))\\right)\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "E Proof of Theorem 4.1 (Model-Free, Banfit Feedback) ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We start by introducting some notation. We let $\\mathcal{I}^{(k)}$ denote the rounds in the $k$ -th epoch: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathcal{Z}^{(k)}:=\\{T_{0}+\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+1,\\,\\,.\\,.\\,.\\,,\\,\\,T_{0}+k\\cdot N_{\\mathrm{reg}}\\},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $T_{0}$ is as in Line 1 of Algorithm 3. Throughout the analysis, we condition on the event ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathcal{E}:=\\mathcal{E}^{\\mathrm{cov}},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\mathcal{E}^{\\mathrm{cov}}$ is as in Lemma G.1. Further, for any $k\\in[K]$ , let $\\rho^{(k)}$ be the distribution of the random policy: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathbb{I}\\big\\{\\boldsymbol{\\zeta}=\\boldsymbol{0}\\big\\}\\cdot\\widehat{\\boldsymbol{\\pi}}^{(k)}+\\mathbb{I}\\big\\{\\boldsymbol{\\zeta}=\\boldsymbol{1}\\big\\}\\cdot\\boldsymbol{\\pi}\\circ_{h}\\pi_{\\mathrm{unif}}\\circ_{h+1}\\widehat{\\boldsymbol{\\pi}}^{(k)},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "with ${\\mathsf{\\boldsymbol{\\zeta}}}\\sim\\operatorname{Ber}(\\nu),h\\sim\\operatorname{unif}\\left([H]\\right)$ , and $\\pi\\sim\\operatorname{unif}\\left(\\Psi_{h}^{\\mathsf{c o v}}\\right)$ ", "page_idx": 31}, {"type": "text", "text": "We start our analysis by applying the performance difference lemma. ", "page_idx": 31}, {"type": "text", "text": "Applying the performance difference lemma. For any $k\\in[K],t\\in{\\mathcal{L}}^{(k)}$ , and $\\rho^{(k)}$ as just defined, wehave ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\pi_{t}\\sim\\rho^{(k)}}\\mathbb{E}\\left[V_{\\pi}^{(1)}(x_{1};\\ell^{t})\\right]-V_{\\pi}^{(k)}(x_{1};\\ell^{t})}\\\\ &{=(1-\\nu)\\cdot\\left(V_{\\pi}^{(k)}(x_{1};\\ell^{t})-V_{\\pi}^{\\pi^{(k)}}(x_{1};\\ell^{t})\\right)}\\\\ &{\\phantom{=}+\\frac{\\nu}{H}\\int_{M_{\\cal M}}\\prod_{\\ell=\\pi_{k}^{(\\ell)}}^{\\pi^{(k)}}\\exp\\left(V_{\\pi^{(k)}}^{\\pi^{(k)}}(x_{1};\\ell^{t})-V_{\\pi}^{\\pi^{(k)}}(x_{1};\\ell^{t})\\right),}\\\\ &{\\le(1-\\nu)\\cdot\\frac{\\nu}{L}\\mathbb{E}^{\\pi^{(k)}}\\left[\\sum_{k=1}^{\\infty}\\left(\\overline{{\\pi}}_{k}^{(k)}(a\\,|\\,x_{h})-\\pi_{k}^{(k)}(a\\,|\\,x_{h})\\right)\\cdot Q_{h}^{\\pi^{(k)}}(x_{h},a;\\ell^{t})\\right]+H\\nu,}\\\\ &{=(1-\\nu)\\cdot\\frac{\\nu}{L}\\mathbb{E}^{\\pi^{(k)}}\\left[\\sum_{k=1}^{\\infty}\\left(\\overline{{\\pi}}_{k}^{(k)}(a\\,|\\,x_{h})-\\pi_{k}^{(k)}(a\\,|\\,x_{h})\\right)\\cdot\\widehat{Q}_{h}^{(k)}(x_{h},a)\\right]+H\\nu}\\\\ &{\\phantom{=}+(1-\\nu)\\cdot\\frac{\\nu}{L}\\mathbb{E}^{\\pi^{(k)}}\\left[\\sum_{\\alpha\\in{\\pi_{k}^{(\\ell)}}}^{\\pi^{(k)}}\\widehat{\\pi}_{k}^{(k)}(a\\,|\\,x_{h})\\cdot\\left(Q_{h}^{\\pi^{(k)}}(x_{h},a;\\ell^{t})-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\right)\\right]}\\\\ &{\\phantom{=}+(1-\\nu)\\cdot\\frac{\\nu}{L}\\mathbb{E}^{\\pi^{(k)}}\\left[\\sum_{\\alpha}\\overline{{\\pi}}_{k}^{(k)}(a\\,|\\,x_{h})\\cdot\\left(\\widehat{Q\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Thus, by the triangle inequality, we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\left(\\mathbb{E}_{\\pi\\sim\\rho^{(k)}}\\mathbb{E}\\left[V_{1}^{\\pi}(x_{1};\\ell^{t})\\right]-V_{1}^{\\pi^{\\star}}(x_{1};\\ell^{t})\\right)}\\\\ &{\\leq\\left(1-\\nu\\right)\\cdot\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star}}\\left[\\displaystyle\\sum_{a\\in\\mathcal{A}}\\left(\\widehat{\\pi}_{h}^{(k)}(a\\mid x_{h})-\\pi_{h}^{\\star}(a\\mid x_{h})\\right)\\cdot\\widehat{Q}_{h}^{(k)}(x_{h},a)\\right]+H N_{\\mathrm{reg}}\\nu,}\\\\ &{\\displaystyle\\ \\ +\\left.2(1-\\nu)\\cdot\\displaystyle\\sum_{h=1}^{H}\\operatorname*{max}_{\\pi^{\\prime}\\in\\Pi}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{\\star}}\\left[\\displaystyle\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\left(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a)-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\right)\\right]\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We start by bound the first term in the right-hand side of (48) (the regret term). ", "page_idx": 31}, {"type": "text", "text": "E.1 Bounding the Regret Term ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Fix $h\\in[H]$ and define $\\tilde{\\pi}_{h}^{\\star}(\\cdot\\mid x):=(1-\\gamma/T)\\cdot\\pi_{h}^{\\star}(\\cdot\\mid x)+\\gamma\\pi_{\\mathrm{unif}}\\left(\\cdot\\mid x\\right)/T$ for all $x$ where $\\gamma$ is as in Algrithm 3. we have that $|\\widehat{Q}_{h}^{(k)}(x,a)|=|\\widehat{\\phi}_{h}^{(k)}(x,a)^{\\top}\\widehat{\\theta}_{h}^{(k)}|\\leq H\\sqrt{d}$ (sine $\\hat{\\theta}_{h}^{(k)}\\in\\mathbb{B}_{d}(H\\sqrt{d})$ and (x,a)\u2264 1) By applying Lemma 15, we have that for any n aa and $x\\in\\mathscr{X}$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k\\in[K]}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{a\\in A}\\left(\\widehat{\\pi}_{h}^{(k)}(a\\mid x)-\\pi_{h}^{\\star}(a\\mid x)\\right)\\cdot\\widehat{Q}_{h}^{(k)}(x,a)}\\\\ &{\\leq\\displaystyle\\sum_{k\\in[K]}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{a\\in A}\\left(\\widehat{\\pi}_{h}^{(k)}(a\\mid x)-\\tilde{\\pi}_{h}^{\\star}(a\\mid x)\\right)\\cdot\\widehat{Q}_{h}^{(k)}(x,a)+H\\gamma,}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\frac{N_{\\mathrm{reg}}\\log(T/\\gamma)}{\\eta}+\\eta\\sum_{k=1}^{K}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{a\\in A}\\widehat\\pi_{h}^{(k)}(a\\mid x)\\cdot\\widehat Q_{h}^{(k)}(x,a)^{2}+H\\gamma,}\\\\ &{\\leq\\displaystyle\\frac{N_{\\mathrm{reg}}\\log(T/\\gamma)}{\\eta}+H^{2}d\\eta T+H\\gamma,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "E.2  Bounding the Bias Term ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Fix epoch $k\\in[K]$ , round $t\\in\\mathcal{T}^{(k)}$ , layer $h\\in[2\\ldots H]$ , and $\\pi^{\\prime}\\in\\Pi$ . Further, let ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathcal{X}_{h,\\varepsilon}:=\\left\\{x\\in\\mathcal{X}:\\operatorname*{max}_{\\pi\\in\\Pi}d_{h}^{\\pi}(x)\\geq\\varepsilon\\cdot\\|\\mu_{h}^{\\star}(x)\\|\\right\\}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "be the set of $\\varepsilon$ -reachable states. With this notation, we now bound the bias term in (48); we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\vert\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\ell^{t})-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big)\\right]\\right\\vert}\\\\ &{\\le\\displaystyle\\left\\vert\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\mathbb{I}\\{\\mathbf{\\Phi}(x_{h}\\notin\\mathcal{X}_{h,\\varepsilon})\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\ell^{t})-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big)\\right]\\right\\vert}\\\\ &{\\quad+\\displaystyle\\left\\vert\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\mathbb{I}\\{\\mathbf{\\Phi}(x_{h}\\in\\mathcal{X}_{h,\\varepsilon})\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\ell^{t})-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big)\\right]\\right\\vert,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "and so by Lemma I.1, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\left\\vert\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\mathbb{I}\\{\\mathbf{x}_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\left(Q_{h}^{\\widehat{\\pi}^{(k)}}(\\mathbf{x}_{h},a;\\ell^{\\prime})-\\widehat{Q}_{h}^{(k)}(\\mathbf{x}_{h},a)\\right)\\right]\\right\\vert+2N_{\\mathrm{reg}}H d^{2}\\varepsilon,}\\\\ &{=N_{\\mathrm{reg}}\\cdot\\left\\vert\\mathbb{E}^{\\pi^{*}}\\left[\\mathbb{I}\\{\\mathbf{x}_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\displaystyle\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\left(\\displaystyle\\frac{1}{N_{\\mathrm{reg}}}\\sum_{t\\in\\mathbb{Z}^{(k)}}Q_{h}^{\\widehat{\\pi}^{(k)}}(\\mathbf{x}_{h},a;\\ell^{\\prime})-\\widehat{Q}_{h}^{(k)}(\\mathbf{x}_{h},a)\\right)\\right]\\right\\vert+2N_{\\mathrm{reg}}H d^{2}\\varepsilon}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Thus, by letting ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\overline{{Q}}_{h}^{\\widehat{\\pi}^{(k)}}(\\cdot,\\cdot):=\\frac{1}{N_{\\mathrm{reg}}}\\sum_{t\\in\\mathbb{Z}^{(k)}}Q_{h}^{\\widehat{\\pi}^{(k)}}(\\cdot,\\cdot;\\ell^{t}),\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "and using Jensen's inequality (twice), we get ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{t\\in T^{\\mathbb{S}}}{\\sum}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a^{\\#}}\\!\\!\\!\\!\\!\\!\\!\\sum_{h}\\!\\!\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(Q_{h}^{\\pi^{*}(h)}(x_{h},a;\\ell^{t})-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big)\\Big]\\right]}\\\\ &{\\leq N_{\\mathrm{reg}}\\cdot\\mathbb{E}^{\\pi^{*}}\\left[\\mathbb{I}\\{\\left\\{x_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\right\\}\\underset{a\\in A}{\\sum}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big|\\overline{{Q}}_{h}^{\\pi^{*}}(x_{h},a)-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big|\\right]+2N_{\\mathrm{reg}}H d^{2}\\varepsilon,}\\\\ &{\\leq N_{\\mathrm{reg}}\\cdot\\sqrt{\\mathbb{E}^{\\pi^{*}}\\left[\\mathbb{I}\\{x_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\underset{a\\in A}{\\sum}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(\\overline{{Q}}_{h}^{\\pi^{*}(k)}(x_{h},a)-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big)^{2}\\Big]+2N_{\\mathrm{reg}}H d^{2}\\varepsilon,}\\\\ &{\\leq N_{\\mathrm{reg}}\\cdot\\sqrt{\\mathbb{E}^{\\pi^{*}}\\left[\\mathbb{I}\\{x_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\cdot\\underset{a\\in A}{\\operatorname*{max}}\\left(\\overline{{Q}}_{h}^{\\pi^{*}(k)}(x_{h},a)-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\right)^{2}\\right]+2N_{\\mathrm{reg}}H d^{2}\\varepsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "and now by the fact that $\\Psi_{h}^{\\mathrm{cov}}$ is an $(\\frac{1}{8A d},\\varepsilon)$ policy cover for layer $h$ (see Lemma G.1 and Defintion 4.1): ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq N_{\\mathrm{reg}}\\cdot\\sqrt{8A d\\underset{\\pi\\in\\Psi_{h}^{\\mathrm{ax}}}{\\operatorname*{max}}\\mathbb{E}^{\\pi}\\bigg[\\mathbb{I}\\{\\mathbf{x}_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\cdot\\underset{a\\in A}{\\operatorname*{max}}\\left(\\overline{{Q}}_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a)-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\right)^{2}\\bigg]}+2N_{\\mathrm{reg}}H d^{2}\\varepsilon,}\\\\ &{\\leq N_{\\mathrm{reg}}\\cdot\\sqrt{8A^{2}d\\underset{\\pi\\in\\Psi_{h}^{\\mathrm{cov}}}{\\sum}\\mathbb{E}^{\\pi_{\\mathrm{oh}}\\pi_{\\mathrm{unit}}}\\left[\\left(\\overline{{Q}}_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a_{h})-\\widehat{Q}_{h}^{(k)}(x_{h},a_{h})\\right)^{2}\\right]}+2N_{\\mathrm{reg}}H d^{2}\\varepsilon.\\qquad\\quad(52M)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Next, we bound the regression error term in the right-hand side of (52) ", "page_idx": 32}, {"type": "text", "text": "E.3  Bounding the Regression Error ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Lemma E.1. Let $\\delta\\in(0,1)$ and $\\nu\\in(0,1/4)$ be given. There is an event $\\mathcal{E}^{\\mathrm{reg}}$ of probability at least $1-2\\delta$ under which ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\sum_{\\pi\\in\\Psi_{h}}\\mathbb{E}^{\\pi\\circ_{h}\\pi_{\\mathrm{unif}}}\\left[\\left(\\widehat{\\phi}_{h}^{(k)}(\\mathbf{x}_{h},a_{h})^{\\top}\\widehat{\\theta}_{h}^{(k)}-\\overline{{Q}}_{h}^{\\widehat{\\pi}^{(k)}}(\\mathbf{x}_{h},a_{h})\\right)^{2}\\right]\\leq\\varepsilon_{\\mathrm{reg}}^{2}:=\\frac{40H^{3}d\\log(2|\\mathcal{F}|/\\delta)}{\\nu N_{\\mathrm{reg}}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. Fix $\\delta\\in(0,1),h\\in[H]$ and $k\\in[K]$ , and let $(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t},\\pmb{\\zeta}^{t},\\pmb{h}^{t})$ be as in Algorithm 3. With this, define ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{I_{h}^{t}:=\\mathbb{I}\\{\\boldsymbol{\\zeta}^{t}=0\\;\\mathrm{or}\\;h^{t}\\leq h\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "and note that $(\\mathbf{x}_{h}^{t},\\mathbf{a}_{h}^{t},I_{h}^{t})_{t\\in\\mathcal{T}^{(k)}}$ are identically and independently distributed. Further, for $t\\in\\mathcal{T}^{(k)}$ and $\\pi\\in\\Pi$ let $\\theta_{h}^{t,\\pi}\\in\\mathbb{B}_{d}(H\\sqrt{d})$ be such that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\forall(x,a)\\in\\mathcal{X}\\times\\mathcal{A},\\quad Q_{h}^{\\pi}(x,a;\\ell^{t})=\\phi_{h}^{\\star}(x,a)^{\\top}\\theta_{h}^{\\pi,t}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Such a $\\theta_{h}^{\\pi,t}$ is guaranteed to exist by the low-rank MDP structure (Assumption 2.1) and Assumption 2.2. With this, note that for $\\overline{{Q}}_{h}^{\\widehat{\\pi}^{(k)}}$ as in (51), we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\overline{{Q}}_{h}^{\\widehat{\\pi}^{(k)}}(x,a)=\\phi_{h}^{\\star}(x,a)^{\\top}\\theta_{h}^{(k)},\\quad\\mathrm{where}\\quad\\theta_{h}^{(k)}:=\\frac{1}{N_{\\mathrm{reg}}}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\theta_{h}^{\\widehat{\\pi}^{(k)},t}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "For the rest of this proof, we let $\\mathcal{F}$ be the function class ", "page_idx": 33}, {"type": "equation", "text": "$$\n{\\mathcal{F}}:=\\{f:(x,a)\\mapsto\\phi_{h}(x,a)^{\\top}\\theta\\mid\\theta\\in{\\mathcal{C}}\\cup\\{\\theta_{h}^{(k)}\\},\\phi\\in\\Phi\\},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $\\mathcal{C}$ is a minimal $(N_{\\mathrm{reg}})^{-1}$ -cover of $\\mathbb{B}(H{\\sqrt{d}})$ in $\\|\\cdot\\|$ distance. Further, for $\\tau\\in\\mathcal{T}^{(k)}$ we let ", "page_idx": 33}, {"type": "equation", "text": "$$\nz_{h}^{\\tau}:=\\sum_{l=h}^{H}\\ell_{l}^{\\tau}(x_{l}^{\\tau},\\pmb{a}_{l}^{\\tau});\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n\\pmb{\\mathscr{E}}_{h}^{\\tau}:=\\sum_{l=h}^{H}\\ell_{l}^{\\tau}\\big(\\pmb{x}_{l}^{\\tau},\\pmb{a}_{l}^{\\tau}\\big)-\\frac{1}{N_{\\mathrm{reg}}}\\sum_{t\\in\\mathbb{Z}^{(k)}}Q_{h}^{\\widehat{\\pi}^{(k)}}\\big(\\pmb{x}_{h}^{\\tau},\\pmb{a}_{h}^{\\tau};\\ell^{t}\\big);\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "and ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\widehat{L}(f):=\\sum_{t\\in\\mathcal{Z}^{(k)}}\\pmb{I}_{h}^{t}\\cdot\\big(f(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t})-\\pmb{z}_{h}^{t}\\big)^{2},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "for $f\\in\\mathcal F$ Finally,let $f_{\\star}(x,a):=\\phi_{h}^{\\star}(x,a)^{\\intercal}\\theta_{h}^{(k)}$ ,where $\\theta_{h}^{(k)}$ is as in (5) and $\\widehat{f}(x,a):=\\widehat{Q}_{h}^{(k)}(x,a)$ With this, note that $f_{\\star}$ and $\\hat{f}$ satisfy $f_{\\star}({\\pmb x}_{h}^{t},{\\pmb a}_{h}^{t})=z_{h}^{t}-{\\pmb\\varepsilon}_{h}^{t}$ and $\\hat{f}\\in\\mathrm{argmin}_{f\\in\\mathcal{F}}\\widehat{L}(f)$ ", "page_idx": 33}, {"type": "text", "text": "Now, since $\\hat{f}\\in\\mathrm{argmin}_{f\\in\\mathcal{F}}\\,\\widehat{L}(f)$ , we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n0\\geq\\widehat{L}\\big(\\widehat{f}\\big)-\\widehat{L}\\big(f_{\\star}\\big)=\\nabla\\widehat{L}\\big(f_{\\star}\\big)\\big[\\widehat{f}-f_{\\star}\\big]+\\|\\widehat{f}-f_{\\star}\\|^{2},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $\\nabla$ denotes directional derivative and ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\big\\|\\hat{f}-f_{\\star}\\big\\|^{2}:=\\sum_{t\\in\\mathbb{Z}^{(k)}}{\\pmb I}_{h}^{t}\\cdot\\big(\\hat{f}({\\pmb x}_{h}^{t},{\\pmb a}_{h}^{t})-f_{\\star}({\\pmb x}_{h}^{t},{\\pmb a}_{h}^{t})\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Rearranging (58) and using that $f_{\\star}({\\pmb x}_{h}^{t},{\\pmb a}_{h}^{t})=z_{h}^{t}-{\\pmb\\varepsilon}_{h}^{t}$ , we get that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\hat{f}-f_{\\star}\\right\\|^{2}\\leq-\\nabla\\widehat{L}\\big(f_{\\star}\\big)\\big[\\hat{f}-f_{\\star}\\big],}\\\\ &{\\qquad\\qquad=2\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}I_{h}^{t}\\cdot\\big(z_{h}^{t}-f_{\\star}\\big(x_{h}^{t},a_{h}^{t}\\big)\\big)\\big(\\hat{f}\\big(x_{h}^{t},a_{h}^{t}\\big)-f_{\\star}\\big(x_{h}^{t},a_{h}^{t}\\big)\\big),}\\\\ &{\\qquad\\qquad=2\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}I_{h}^{t}\\cdot\\varepsilon_{h}^{t}\\cdot\\big(\\hat{f}\\big(x_{h}^{t},a_{h}^{t}\\big)-f_{\\star}\\big(x_{h}^{t},a_{h}^{t}\\big)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We now bound the right-hand side of (59). For any $h\\in[H],k\\in[K]$ and any $\\hat{f},f_{\\star}\\in\\mathcal{F}$ we apply Lemma I.2 with ", "page_idx": 33}, {"type": "text", "text": "$\\widetilde{\\pmb{\\updelta}}^{i}=\\sigma\\big(\\{(\\pmb{x}_{h}^{j},\\pmb{a}_{h}^{j},\\pmb{\\varepsilon}_{h}^{j},\\pmb{\\zeta}^{j}):j\\leq t_{i}\\}\\big)$ where $t_{i}:=\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+i$ ", "page_idx": 34}, {"type": "text", "text": "\u00b7 The random variable $\\pmb{w}^{i}$ set as the difference ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\pmb{w}^{i}=\\mathbb{I}\\big\\{\\zeta^{t_{i}}=0\\;\\mathrm{or}\\;h^{t_{i}}\\leq h\\big\\}\\cdot\\pmb{\\varepsilon}_{h}^{t_{i}}\\cdot\\big(\\hat{f}\\big(\\pmb{x}_{h}^{t_{i}},\\pmb{a}_{h}^{t_{i}}\\big)-f_{\\star}\\big(\\pmb{x}_{h}^{t_{i}},\\pmb{a}_{h}^{t_{i}}\\big)\\big)}\\\\ &{\\qquad-\\mathbb{E}\\left[\\mathbb{I}\\big\\{\\zeta^{t_{i}}=0\\;\\mathrm{or}\\;h^{t_{i}}\\leq h\\big\\}\\cdot\\pmb{\\varepsilon}_{h}^{t_{i}}\\cdot\\big(\\hat{f}\\big(\\pmb{x}_{h}^{t_{i}},\\pmb{a}_{h}^{t_{i}}\\big)-f_{\\star}\\big(\\pmb{x}_{h}^{t_{i}},\\pmb{a}_{h}^{t_{i}}\\big)\\big)\\mid\\mathfrak{F}^{i-1}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $t_{i}:=\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+i$ ", "page_idx": 34}, {"type": "text", "text": "$n=N_{\\mathrm{reg}}=|{\\mathcal{L}}^{(k)}|.$ $R=4H^{2}$ ; and $\\lambda=1/(16H^{2});$ ", "page_idx": 34}, {"type": "text", "text": "to get that there is an event $\\mathcal{E}$ of porbability at least $1-\\delta$ under which ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\ell\\in\\mathbb{Z}^{(k)}}{\\sum}\\,H_{\\mathrm{i}}^{t}\\cdot\\ell_{h}^{t}\\cdot(\\hat{f}(x_{h}^{t},a_{h}^{t})-f_{*}(x_{h}^{t},a_{h}^{t}))}\\\\ &{\\leq\\underset{\\ell\\in\\mathbb{Z}^{(k)}}{\\sum}\\mathbb{E}_{t}[I_{h}^{t}\\cdot\\varepsilon_{h}^{t}\\cdot(\\hat{f}(x_{h}^{t},a_{h}^{t})-f_{*}(x_{h}^{t},a_{h}^{t}))]}\\\\ &{\\quad+\\frac{1}{8H^{2}}\\sum_{\\ell\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}[I_{h}^{t}\\cdot(\\varepsilon_{h}^{t})^{2}\\cdot(\\hat{f}(x_{h}^{t},a_{h}^{t})-f_{*}(x_{h}^{t},a_{h}^{t}))^{2}]+16H^{2}\\log(|\\mathcal{F}|/\\delta),}\\\\ &{\\leq\\underset{t\\in\\mathbb{Z}^{(k)}}{\\sum}\\mathbb{E}_{t}[I_{h}^{t}\\cdot\\varepsilon_{h}^{t}\\cdot(\\hat{f}(x_{h}^{t},a_{h}^{t})-f_{*}(x_{h}^{t},a_{h}^{t}))]}\\\\ &{\\quad+\\frac{1}{4}\\underset{t\\in\\mathbb{Z}^{(k)}}{\\sum}\\mathbb{E}_{t}[I_{h}^{t}\\cdot(\\hat{f}(x_{h}^{t},a_{h}^{t})-f_{*}(x_{h}^{t},a_{h}^{t}))^{2}]+16H^{2}\\log(|\\mathcal{F}|/\\delta),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $\\mathbb{E}_{t}[\\cdot]$ is defined as $\\mathbb{E}\\left[\\cdot\\,|\\,\\mathfrak{F}^{t-1}\\right]$ and the last step uses that $|\\varepsilon_{h}^{t}|\\leq2H$ , for all $t\\in\\mathcal{T}^{(k)}$ . For the rest of the proof, we condition on $\\mathcal{E}$ and to simplify notation let ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\pmb{\\Delta}_{h}^{t}:=\\hat{f}(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t})-f_{\\star}(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t}).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Using the expression of $\\varepsilon_{h}^{t}$ in (56), we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}[I_{h}^{t}\\cdot\\varepsilon_{h}^{t}\\cdot\\Delta_{h}^{t}]}\\\\ &{=\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot\\left(\\sum_{l=h}^{H}\\ell_{l}^{t}(\\mathbf{x}_{l}^{t},a_{l}^{t})-\\frac{1}{N_{\\mathrm{reg}}}\\sum_{\\tau\\in\\mathbb{Z}^{(k)}}Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h}^{t},a_{h}^{t};\\ell^{\\tau})\\right)\\cdot\\Delta_{h}^{t}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Now, since $\\pmb{I}_{h}^{t}=\\mathbb{I}\\{\\pmb{\\zeta}^{t}=0$ or $h^{t}\\leq h\\}$ , we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{E}_{t}\\left[\\sum_{l=h}^{H}\\ell_{l}^{t}(\\pmb{x}_{l}^{t},\\pmb{a}_{l}^{t})\\mid\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t},\\pmb{I}_{h}^{t}=1\\right]=Q_{h}^{\\widehat{\\pi}^{(k)}}(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t};\\ell^{t}).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Plugging this into (62) and using the law of total expectation, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}[I_{h}^{t}\\cdot\\varepsilon_{h}^{t}\\cdot\\Delta_{h}^{t}]}\\\\ &{=\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot\\left(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h}^{t},a_{h}^{t};\\ell^{t})-\\frac{1}{N_{\\mathrm{reg}}}\\sum_{\\tau\\in\\mathbb{Z}^{(k)}}Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h}^{t},a_{h}^{t};\\ell^{\\tau})\\right)\\cdot\\Delta_{h}^{t}\\right],}\\\\ &{=\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h}^{t},a_{h}^{t};\\ell^{t})\\cdot\\Delta_{h}^{t}\\right]-\\frac{1}{N_{\\mathrm{reg}}}\\sum_{\\tau\\in\\mathbb{Z}^{(k)}}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h}^{t},a_{h}^{t};\\ell^{\\tau})\\cdot\\Delta_{h}^{t}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "On the other hand, since $(\\mathbf{x}_{h}^{t},\\mathbf{a}_{h}^{t},I_{h}^{t})_{t\\in\\mathcal{T}^{(k)}}$ are i.i.d. and $\\ell^{t}$ is chosen by an oblivious adversary, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\forall t\\in\\mathbb{Z}^{(k)},\\quad\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h}^{t},a_{h}^{t};\\ell^{t})\\cdot\\Delta_{h}^{t}\\right]=\\frac{1}{N_{\\mathrm{reg}}}\\sum_{\\tau\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{\\tau}\\left[I_{h}^{\\tau}\\cdot Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h}^{\\tau},a_{h}^{\\tau};\\ell^{t})\\cdot\\Delta_{h}^{\\tau}\\right].\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Plugging this into (63) shows that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{t\\in\\mathcal{Z}^{(k)}}\\mathbb{E}_{t}\\big[\\pmb{I}_{h}^{t}\\cdot\\pmb{\\varepsilon}_{h}^{t}\\cdot\\pmb{\\Delta}_{h}^{t}\\big]=0.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Combining this with (60) and (59), we get that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}I_{h}^{t}\\cdot\\big(\\hat{f}\\big(x_{h}^{t},a_{h}^{t}\\big)-f_{\\star}\\big(x_{h}^{t},a_{h}^{t}\\big)\\big)^{2}\\leq\\frac{1}{4}\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}\\big[I_{h}^{t}\\cdot\\big(\\hat{f}\\big(x_{h}^{t},a_{h}^{t}\\big)-f_{\\star}\\big(x_{h}^{t},a_{h}^{t}\\big)\\big)^{2}\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+16H^{2}\\log(|\\mathcal{F}|/\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Now, since $(\\mathbf{x}_{h}^{t},\\mathbf{a}_{h}^{t},I_{h}^{t})_{t\\in\\mathcal{T}^{(k)}}$ are i.i.d., we have by Lemma I.3 that there is an event ${\\mathcal{E}}^{\\prime}$ of probability at least $1-\\delta$ under which we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot\\big(\\hat{f}(\\mathbf{x}_{h}^{t},a_{h}^{t})-f_{\\star}(\\mathbf{x}_{h}^{t},a_{h}^{t})\\big)^{2}\\right]\\leq2\\sum_{t\\in\\mathbb{Z}^{(k)}}I_{h}^{t}\\cdot\\big(\\hat{f}(\\mathbf{x}_{h}^{t},a_{h}^{t})-f_{\\star}(\\mathbf{x}_{h}^{t},a_{h}^{t})\\big)^{2}}\\\\ &{\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+8H^{2}\\log(2|\\mathcal{F}|/\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Combining this with (65) and rearranging, we get that under $\\mathcal{E}^{\\mathrm{reg}}:=\\mathcal{E}\\cap\\mathcal{E}^{\\prime}$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\frac{1}{N_{\\mathrm{reg}}}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot(\\hat{f}(\\mathbf{x}_{h}^{t},\\boldsymbol{a}_{h}^{t})-f_{\\star}(\\boldsymbol{x}_{h}^{t},\\boldsymbol{a}_{h}^{t}))^{2}\\right]\\leq\\frac{40H^{2}\\log(2|\\mathcal{F}|/\\delta)}{N_{\\mathrm{reg}}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "On the other hand, we have that for all $t\\in\\mathcal{T}^{(k)}$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{t}\\left[I_{h}^{t}\\cdot(\\hat{f}(\\mathbf{x}_{h}^{t},\\mathbf{a}_{h}^{t})-f_{\\star}(\\mathbf{x}_{h}^{t},\\mathbf{a}_{h}^{t}))^{2}\\right]\\geq\\mathbb{E}_{t}\\left[\\mathbb{I}\\{\\zeta^{t}=1,h^{t}=h\\}\\cdot(\\hat{f}({x}_{h}^{t},\\mathbf{a}_{h}^{t})-f_{\\star}({x}_{h}^{t},\\mathbf{a}_{h}^{t}))^{2}\\right],}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\frac{\\nu}{H d}\\displaystyle\\sum_{\\pi\\in\\Psi_{h}}\\mathbb{E}^{\\pi\\circ_{h}\\pi_{\\operatorname*{mit}}}\\left[(\\hat{f}({x}_{h}^{t},\\mathbf{a}_{h}^{t})-f_{\\star}({x}_{h}^{t},\\mathbf{a}_{h}^{t}))^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Plugging this into (67) and using the expressions of $\\hat{f}$ and $f_{\\star}$ ,we get ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{\\pi\\in\\Psi_{h}}\\mathbb{E}^{\\pi\\circ_{h}\\pi_{\\mathrm{unif}}}\\left[\\left(\\widehat{\\phi}_{h}^{(k)}(\\mathbf{x}_{h},a_{h})^{\\top}\\widehat{\\theta}_{h}^{(k)}-\\overline{{Q}}_{h}^{\\widehat{\\pi}^{(k)}}(\\mathbf{x}_{h},a_{h})\\right)^{2}\\right]\\leq\\frac{40H^{3}d\\log(2|\\mathcal{F}|/\\delta)}{\\nu N_{\\mathrm{reg}}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "E.4  Putting It All Together ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "By combining (48), (52), (53), and (49), we have that under the event $\\mathcal{E}:=\\mathcal{E}^{\\mathrm{cov}}\\cap\\mathcal{E}^{\\mathrm{reg}}$ (where $\\mathcal{E}^{\\mathrm{cov}}$ and $\\mathcal{E}^{\\mathrm{reg}}$ are as in Lemma G.1 and Lemma E.1, respectively): ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}_{T}=H T_{0}+\\displaystyle\\sum_{k\\in[K]}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\left(\\mathbb{E}_{\\pi\\sim\\rho^{(k)}}\\mathbb{E}\\left[V_{1}^{\\pi}(x_{1};\\ell^{t})\\right]-V_{1}^{\\pi^{\\star}}(x_{1};\\ell^{t})\\right),}\\\\ &{\\qquad\\qquad\\leq H T_{0}+H T\\nu+T\\cdot\\sqrt{8A^{2}d\\cdot\\varepsilon_{\\mathrm{reg}}^{2}}+\\frac{N_{\\mathrm{reg}}\\log(T/\\gamma)}{\\eta}+H^{2}d\\eta T+H\\gamma.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Thus, plugging in the expression of $T_{0}$ from Algorithm 3, and ignoring polynormal factors $d,A,\\dot{H_{\\parallel}},\\mathrm{log}\\(|\\Phi|\\varepsilon^{-1}\\delta^{-1})$ ,weget that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}_{T}<\\frac{1}{\\varepsilon^{2}}+T\\varepsilon+T\\nu+N_{\\mathrm{reg}}\\cdot\\sqrt{8A^{2}d\\cdot\\varepsilon_{\\mathrm{reg}}^{2}}+2N_{\\mathrm{reg}}H d\\varepsilon+\\frac{N_{\\mathrm{reg}}}{\\eta}+\\eta T,}\\\\ &{\\qquad<T^{2/3}+\\nu T+T\\cdot\\sqrt{8A^{2}d\\cdot\\varepsilon_{\\mathrm{reg}}^{2}}+\\sqrt{T N_{\\mathrm{reg}}},\\quad\\mathrm{(by~setting~}\\varepsilon=T^{-1/3}\\mathrm{~and~}\\eta=\\left(N_{\\mathrm{reg}}/T\\right)^{1/2})}\\\\ &{\\qquad=T^{2/3}+\\nu T+T\\cdot\\sqrt{\\frac{1}{\\nu N_{\\mathrm{reg}}}}+\\sqrt{T N_{\\mathrm{reg}}},\\quad\\mathrm{(used~the~cxpression~of~}\\varepsilon_{\\mathrm{reg}}^{2}\\mathrm{~in~(53))}}\\\\ &{\\qquad<T^{2/3}+\\nu T+\\sqrt{T}\\cdot\\left(\\frac{T}{\\nu}\\right)^{1/4},\\quad\\mathrm{(by~setting~}N_{\\mathrm{reg}}=\\left(T/\\nu\\right)^{1/2})}\\\\ &{\\qquad<T^{4/5}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the last step follows by setting v = T-1/5. ", "page_idx": 35}, {"type": "text", "text": "F Proof of Theorem 4.2 (Model-Free, Bandit Feedback, Adaptive Adversary) ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "We let $\\mathcal{I}^{(k)}$ denote the rounds in the $k$ th epoch: ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathcal{Z}^{(k)}:=\\{T_{0}+\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+1,\\,\\,.\\,.\\,.\\,,\\,\\,T_{0}+k\\cdot N_{\\mathrm{reg}}\\},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $T_{0}$ is as in Line 8 of Algorithm 4. Throughout the analysis, we condition on the event ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{E}:=\\mathcal{E}^{\\mathrm{cov}}\\cap\\mathcal{E}^{\\mathrm{rep+span}}\\cap\\mathcal{E}^{\\mathrm{freed}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $\\mathcal{E}^{\\mathrm{cov}}$ $,\\mathcal{E}^{\\mathrm{rep+span}}$ ,and $\\mathcal{E}^{\\mathrm{freed}}$ are as in Lemma G.1, Corollary F.1, and Lemma FE.3, respectively.   \nWe start our analysis by applying the performance difference lemma. ", "page_idx": 36}, {"type": "text", "text": "Applying the performance difference lemma. For any $k\\,\\in\\,[K],\\,t\\,\\in\\,{\\mathcal{Z}}^{(k)}$ , and let $\\rho^{(k)}$ be the distribution of the random policy: ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathbb{I}\\{\\boldsymbol{\\zeta}^{t}=0\\}\\cdot\\widehat{\\boldsymbol{\\pi}}^{(k)}+\\mathbb{I}\\{\\boldsymbol{\\zeta}^{t}=1\\}\\cdot\\boldsymbol{\\pi}^{t}\\circ_{h^{t}+1}\\widehat{\\boldsymbol{\\pi}}^{(k)},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "with $\\zeta^{t}\\sim\\operatorname{Ber}(\\nu),h^{t}\\sim\\operatorname{unif}\\left([H]\\right)$ , and $\\pi^{t}\\sim\\operatorname{unif}\\left(\\Psi_{h^{t}}^{\\mathrm{span}}\\right)$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{n\\sim\\rho^{(k)}}\\mathbb{E}\\left[V_{1}^{\\pi}(x_{1};\\mathcal{H}^{-1})\\right]-V_{1}^{\\pi^{*}}(x_{1};\\mathcal{H}^{-1})}\\\\ &{=(1-\\nu)\\cdot\\left(V_{1}^{\\pi^{*}(k)}(x_{1};\\mathcal{H}^{-1})-V_{1}^{\\pi^{*}}(x_{1};\\mathcal{H}^{-1})\\right)}\\\\ &{\\quad+\\frac{\\nu}{H}\\int_{M_{\\cal M}}\\sum_{i=1}^{\\infty}{\\left(V_{1}^{\\pi(k)}\\alpha_{i}\\right)^{\\alpha_{i}}{\\left(x_{1};\\mathcal{H}^{-1}\\right)}-V_{1}^{\\pi^{*}}(x_{1};\\mathcal{H}^{-1})}\\Big)\\,,}\\\\ &{=(1-\\nu)\\cdot\\frac{1}{L^{\\pi}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{i=k}^{\\infty}{\\left(\\overline{{\\alpha}}_{i}^{k}(A)\\left(x_{1}\\right)-\\pi_{k}^{*}(\\alpha\\left[x_{1}\\right)\\right)\\right)\\cdot Q_{\\Lambda}^{0(k)}\\left(x_{1},\\alpha;\\mathcal{H}^{-1}\\right)\\mid\\mathcal{H}^{\\pi^{*}-1}}\\right]+H N_{\\mathrm{reg}}\\nu,}\\\\ &{=(1-\\nu)\\cdot\\frac{1}{L^{\\pi}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{i=k}^{\\infty}{\\left(\\overline{{\\alpha}}_{i}^{k}(A)\\left(x_{1}\\right)-\\pi_{k}^{*}(\\alpha\\left[x_{1}\\right)\\right)\\cdot\\widehat{Q}_{\\Lambda}^{0(k)}\\left(x_{1},\\alpha\\right)\\mid\\mathcal{H}^{\\pi^{*}}\\right]}+H N_{\\mathrm{reg}}\\nu}\\\\ &{\\quad+(1-\\nu)\\cdot\\frac{\\nu}{L^{\\pi}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{i=k}^{\\infty}{\\left(\\overline{{\\alpha}}_{i}^{k}\\right)\\left(\\alpha\\left[x_{1}\\right)-\\left(\\overline{{\\alpha}}_{i}^{k}\\right)\\left(\\alpha_{1},\\alpha;\\mathcal{H}^{-1}\\right)-\\widehat{Q}_{\\Lambda}^{(k)}\\left(x_{1},\\alpha\\right)\\right)\\mid\\mathcal{H \n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Thus, by the triangle inequality, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\in\\mathbb{Z}^{(k)}}\\left(\\mathbb{E}_{\\pi\\sim\\rho^{(k)}}\\mathbb{E}\\left[V_{1}^{\\pi}(x_{1};\\mathcal{H}^{t-1})\\right]-V_{1}^{\\pi^{*}}(x_{1};\\mathcal{H}^{t-1})\\right)}\\\\ &{\\le\\left(1-\\nu\\right)\\cdot\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a\\in\\mathcal{A}}\\left(\\widehat{\\pi}_{h}^{(k)}(a\\mid x_{h})-\\pi_{h}^{*}(a\\mid x_{h})\\right)\\cdot\\widehat{Q}_{h}^{(k)}(x_{h},a)\\mid\\mathcal{H}^{t-1}\\right]+H N_{\\mathrm{reg}}\\nu}\\\\ &{\\quad+\\displaystyle2(1-\\nu)\\cdot\\displaystyle\\sum_{h=1}^{H}\\operatorname*{max}_{\\pi^{\\prime}\\in\\mathbb{Z}^{(k)}}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\left(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\mathcal{H}^{t-1})-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\right)\\mid\\mathcal{H}^{t-1}\\right]\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "We start by bounding the first term on the right-hand side of (74) (the regret term). ", "page_idx": 36}, {"type": "text", "text": "F.1 Bounding the Regret Term ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Fix $h\\in[H]$ and define $\\tilde{\\pi}_{h}^{\\star}(\\cdot\\mid x):=(1-\\gamma/T)\\cdot\\pi_{h}^{\\star}(\\cdot\\mid x)+\\gamma\\pi_{\\mathrm{unif}}\\left(\\cdot\\mid x\\right)/T$ for all $x$ , where $\\gamma$ is as in Algoritm .We hav that $\\big|\\widehat{Q}_{h}^{(k)}(x,a)\\big|=\\big|\\bar{\\phi}_{h}^{\\mathrm{rep}}(x,a)^{\\top}\\hat{\\theta}_{h}^{(k)}\\big|\\leq8H d^{2}$ (sine $\\hat{\\theta}_{h}^{(k)}\\in\\mathbb{B}_{2d}(4H d^{2})$ and $\\|\\bar{\\phi}_{h}^{\\mathrm{rep}}(x,a)\\|\\leq\\|\\phi_{h}^{\\mathrm{loss}}(x,a)\\|+\\|\\phi_{h}^{\\mathrm{rep}}(x,a)\\|\\leq2)$ .By applying 15, we have that for any $\\begin{array}{r}{\\eta\\leq\\frac{1}{8H d^{2}}}\\end{array}$ and $x\\in\\mathscr{X}$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k\\in[K]}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{a\\in A}\\left(\\widehat{\\pi}_{h}^{(k)}(a\\mid x)-\\pi_{h}^{\\star}(a\\mid x)\\right)\\cdot\\widehat{Q}_{h}^{(k)}(x,a)}\\\\ &{\\leq\\displaystyle\\sum_{k\\in[K]}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{a\\in A}\\left(\\widehat{\\pi}_{h}^{(k)}(a\\mid x)-\\tilde{\\pi}_{h}^{\\star}(a\\mid x)\\right)\\cdot\\widehat{Q}_{h}^{(k)}(x,a)+H\\gamma,}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\frac{N_{\\mathrm{reg}}\\log(T/\\gamma)}{\\eta}+\\eta\\sum_{k=1}^{K}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\sum_{a\\in A}\\widehat\\pi_{h}^{(k)}(a\\mid x)\\cdot\\widehat Q_{h}^{(k)}(x,a)^{2}+H\\gamma,}\\\\ &{\\leq\\displaystyle\\frac{N_{\\mathrm{reg}}\\log(T/\\gamma)}{\\eta}+64H^{2}d^{4}\\eta T+H\\gamma,}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "F.2  Bounding the Bias Term ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "To bound the bias term (second term in (74)), we make use of the following result. ", "page_idx": 37}, {"type": "text", "text": "Lemma F.1. For $t\\,\\in\\,[T],\\,\\,h\\,\\in\\,[H],$ and $\\pi\\,\\in\\,\\Pi$ there exists $\\bar{\\theta}_{h}^{t,\\pi}\\,\\in\\,\\mathbb{B}_{2d}(H\\sqrt{d})$ such that for all $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$ and history $\\mathcal{H}^{t-1}=\\big(x_{1:H}^{1:t-1},a_{1:H}^{1:t-1}\\big)$ \uff0c ", "page_idx": 37}, {"type": "equation", "text": "$$\nQ_{h}^{\\pi}(x,a;\\mathcal{H}^{t-1})=\\bar{\\phi}_{h}^{\\star}(x,a)^{\\top}\\bar{\\theta}_{h}^{t,\\pi},\\quad w h e r e\\quad\\bar{\\phi}_{h}^{\\star}:=\\left[\\phi^{\\mathrm{loss}},\\phi^{\\star}\\right]\\in\\mathbb{R}^{2d}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Proof. Fix $t\\,\\in\\,[T],\\,h\\,\\in\\,[H]$ . and $\\pi\\,\\in\\,\\Pi$ . By the low-rank MDP structure and the normalizing assumption on $\\mu_{h}^{\\star}$ in Assumption 2.1, there exists $w_{h+1}^{t,\\pi}\\in\\mathbb{B}_{d}((H-s)\\sqrt{d})$ such that for all $(x,a)\\in$ X\u00d7Aand history Ht-1 = (l,al), ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{E}^{\\pi}\\left[\\sum_{s=h+1}^{H}\\ell_{s}(\\pmb{x}_{s},\\pmb{a}_{s};\\mathcal{H}^{t-1})\\mid\\pmb{x}_{h}=x,\\pmb{a}_{h}=a\\right]=\\phi_{h}^{\\star}(x,a)^{\\top}w_{h+1}^{t,\\pi}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Now.with $g_{h}^{t}$ as in ssumption 4.2, (15)and (7) imples that $\\bar{\\theta}_{h}^{t,\\pi}:=[g_{h}^{t},w_{h+1}^{t,\\pi}]\\in\\mathbb{R}^{2d}$ (where $[\\cdot,\\cdot]$ denotes the vertical stacking of vectors) satisfies the desired property. ", "page_idx": 37}, {"type": "text", "text": "Fix epoch $k\\,\\in\\,[K]$ , round $t\\in\\mathcal{T}^{(k)}$ , layer $h\\,\\in\\,[2\\ldots H]$ , and $\\pi^{\\prime}\\in\\Pi$ . By Lemma F.1, there exists $\\overline{{\\pmb{\\theta}}}_{h}^{t,\\widehat{\\pi}^{(k)}}\\in\\mathbb{B}_{2d}(H d^{1/2})$ such that for all $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$ ", "page_idx": 37}, {"type": "equation", "text": "$$\nQ_{h+1}^{\\widehat{\\pi}^{(k)}}(x,a;\\pmb{\\mathscr{H}}^{t-1})=\\bar{\\phi}_{h+1}^{\\star}(x,a)^{\\top}\\bar{\\pmb{\\theta}}_{h+1}^{t,\\widehat{\\pi}^{(k)}}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "With this, let whti $\\pmb{w}_{h+1}^{t,\\widehat{\\pi}^{(k)}}\\qquad\\in\\qquad\\mathbb{B}_{d}(3H d^{2})$ be\u3000as\u3000in\u3000Corollary\u3000F.l\u3000with $\\begin{array}{r l r}{f(x)}&{{}:=}&{}\\end{array}$ $\\begin{array}{r}{\\frac{1}{H d^{1/2}}\\operatorname*{max}_{a\\in\\mathcal{A}}\\bar{\\phi}_{h+1}^{\\star}(x,a)^{\\intercal}\\bar{\\theta}_{h+1}^{t,\\widehat{\\pi}^{({k})}}}\\end{array}$ ; note that this function belongs to the function class $\\mathcal{F}_{h+1}$ in Algorithm 4. With this, we define ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{\\pmb{\\vartheta}}_{h}^{t,\\widehat{\\pi}^{(k)}}:=\\left[\\pmb{g}_{h}^{t},\\pmb{w}_{h+1}^{t,\\widehat{\\pi}^{(k)}}\\right]\\in\\mathbb{B}_{2d}\\big(4H d^{2}\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $\\pmb{g}_{h}^{t}\\in\\mathbb{B}_{d}(1)$ is such that $\\ell_{h}(x,a;\\pmb{\\mathscr{H}}^{t-1})=\\phi_{h}^{\\mathrm{loss}}(x,a)^{\\top}\\pmb{g}_{h}^{t}$ ", "page_idx": 37}, {"type": "text", "text": "With this notation, we now bound the bias term in Eq. (74): we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Bigg|\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\mathcal{H}^{t-1})-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big)\\mid\\mathcal{H}^{t-1}\\right]\\Bigg|}\\\\ &{\\le\\displaystyle\\Bigg|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(\\bar{\\phi}_{h}^{\\scriptscriptstyle(\\mathrm{rep}}(x_{h},a)^{\\top}\\bar{\\vartheta}_{h}^{t,\\widehat{\\pi}^{(k)}}-\\widehat{Q}_{h}^{(k)}(x_{h},a)\\Big)\\mid\\mathcal{H}^{t-1}\\right]\\Bigg|}\\\\ &{\\quad+\\displaystyle\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\Big(Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\mathcal{H}^{t-1})-\\bar{\\phi}_{h}^{\\scriptscriptstyle{\\mathrm{rep}}}(x_{h},a)^{\\top}\\bar{\\vartheta}_{h}^{t,\\widehat{\\pi}^{(k)}}\\Big)\\mid\\mathcal{H}^{t-1}\\right]\\right|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "and by Corollary F.1 (in particular (92)) ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\leq\\left\\vert\\sum_{t\\in\\mathcal{T}^{(k)}}\\mathbb{E}^{\\pi^{*}}\\left[\\sum_{a\\in\\mathcal{A}}\\pi_{h}^{\\prime}(a\\mid x_{h})\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a)^{\\top}\\bar{\\vartheta}_{h}^{t,\\widehat{\\pi}^{(k)}}-\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a)^{\\top}\\hat{\\theta}_{h}^{(k)}\\right)\\mid\\mathcal{H}^{t-1}\\right]\\right\\vert+N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{rep}},\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "and by Corollary F.1 again (in particular (93) and the triangle inequality ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq2\\displaystyle\\sum_{\\pi\\in\\Psi_{h}^{\\mathrm{span}}}\\left|\\sum_{t\\in\\overline{{T}}^{(k)}}\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}\\bar{\\vartheta}_{h}^{t,\\bar{\\pi}^{(k)}}-\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}\\hat{\\theta}_{h}^{(k)}\\mid\\mathcal{H}^{t-1}\\right]\\right|+N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{span}}+N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{rep}}}\\\\ &{\\le2\\displaystyle\\sum_{\\pi\\in\\Psi_{h}^{\\mathrm{span}}}\\left|\\sum_{t\\in\\overline{{T}}^{(k)}}\\mathbb{E}^{\\pi}\\left[Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\mathcal{H}^{t-1})-\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}\\hat{\\theta}_{h}^{(k)}\\mid\\mathcal{H}^{t-1}\\right]\\right|+N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{span}}+N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{rep}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad+\\displaystyle\\operatorname{\\sum_{\\pi\\in\\mathbb{V}_{h}^{\\mathrm{span}}}}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}\\bar{\\vartheta}_{h}^{t,\\widehat{\\pi}^{(k)}}-Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\mathcal{H}^{t-1})\\;|\\;\\mathcal{H}^{t-1}\\right]\\right|,\\quad\\mathrm{(triangle~inequality~)}}\\\\ &{\\leq\\displaystyle\\sum_{\\pi\\in\\mathbb{V}_{h}^{\\mathrm{span}}}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi}\\left[Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\mathcal{H}^{t-1})-\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}\\widehat{\\theta}_{h}^{(k)}\\;|\\;\\mathcal{H}^{t-1}\\right]\\right|+N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{span}}+3d N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{ref}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the last inequality follows by Corollary F.1 (in particular (92)) ", "page_idx": 38}, {"type": "text", "text": "Next, we bound the estimation error term in the right-hand side of (79). ", "page_idx": 38}, {"type": "text", "text": "F.3 Bound the Regression Error ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "By Lemma F3 (Freedman's inequality), we have that for al $\\pi\\in\\Psi_{h}^{\\mathrm{span}}$ and $\\bar{\\theta}\\in\\mathbb{B}_{2d}(4H d^{2})$ ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{freed}}\\geq\\displaystyle\\left\\vert\\sum_{t\\in\\cal Z^{(k)}}\\mathbb{I}\\big\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\big\\}\\cdot\\bigg(\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h}^{t},a_{h}^{t})^{\\top}\\bar{\\theta}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t}\\bigg)\\right.}\\\\ &{\\qquad\\qquad\\qquad\\left.-\\displaystyle\\sum_{t\\in\\cal Z^{(k)}}\\mathbb{E}\\left[\\mathbb{I}\\big\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\big\\}\\cdot\\bigg(\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h}^{t},a_{h}^{t})^{\\top}\\bar{\\theta}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t}\\bigg)\\mid\\mathcal{H}^{t-1}\\right]\\right\\vert.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "On the other hand, we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}\\left[\\mathbb{I}\\big\\{h^{t}=h,\\pmb{\\pi}^{t}=\\pi,\\zeta^{t}=1\\big\\}\\cdot\\Bigg(\\bar{\\phi}_{h}^{\\mathrm{rep}}\\big(\\pmb{x}_{h}^{t},\\pmb{a}_{h}^{t}\\big)^{\\top}\\bar{\\theta}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t}\\Bigg)\\mid\\mathcal{H}^{t-1}\\right]}\\\\ &{\\displaystyle=\\frac{\\nu}{H d}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi^{\\circ_{h+1}}\\widehat{\\pi}^{(k)}}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}\\big(\\pmb{x}_{h},\\pmb{a}_{h}\\big)^{\\top}\\bar{\\theta}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t}\\mid\\mathcal{H}^{t-1}\\right],}\\\\ &{\\displaystyle=\\frac{\\nu}{H d}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}\\big(\\pmb{x}_{h},\\pmb{a}_{h}\\big)^{\\top}\\bar{\\theta}-Q_{h}^{\\widehat{\\pi}^{(k)}}\\big(\\pmb{x}_{h},a;\\mathcal{H}^{t-1}\\big)\\mid\\mathcal{H}^{t-1}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Now, by Corollary F.1 (in particular (92)) and the triangle inequality, we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{rep}}\\geq\\Bigg|\\sum_{t\\in\\mathbb{Z}^{\\backslash}}\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}({x}_{h},a_{h})^{\\top}\\bar{\\theta}-Q_{h}^{\\bar{\\pi}^{(k)}}({x}_{h},a;\\mathcal{H}^{t-1})\\mid\\mathcal{H}^{t-1}\\right]}\\\\ &{\\qquad\\qquad-\\underset{t\\in\\mathbb{Z}^{\\backslash}}{\\sum}\\,\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}({x}_{h},a_{h})^{\\top}\\bar{\\theta}-\\bar{\\phi}_{h}^{\\mathrm{rep}}({x}_{h},a_{h})^{\\top}\\bar{\\vartheta}_{h}^{t,\\bar{\\pi}^{(k)}}\\mid\\mathcal{H}^{t-1}\\right]\\Bigg|,}\\\\ &{\\qquad=\\Bigg|\\underset{t\\in\\mathbb{Z}^{\\backslash}}{\\sum}\\,\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}({x}_{h},a_{h})^{\\top}\\bar{\\theta}-Q_{h}^{\\bar{\\pi}^{(k)}}({x}_{h},a;\\mathcal{H}^{t-1})\\mid\\mathcal{H}^{t-1}\\right]}\\\\ &{\\qquad\\qquad-\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}({x}_{h},a_{h})^{\\top}\\right]\\left(N_{\\mathrm{reg}}\\cdot\\bar{\\theta}-\\underset{t\\in\\mathbb{Z}^{\\backslash}}{\\sum}\\,\\bar{\\vartheta}_{h}^{t,\\bar{\\pi}^{(k)}}\\right)\\Bigg|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Thus, by combining (80), (81), and (82), we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\pi\\in\\mathbb{V}_{h}^{\\Psi_{\\mathrm{sh}}^{\\mathrm{t}}}}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{I}\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h}^{t},a_{h}^{t})^{\\top}\\bar{\\theta}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t}\\right)\\right|}\\\\ &{\\le d N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{freed}}+\\frac{\\nu N_{\\mathrm{reg}}\\varepsilon_{\\mathrm{rep}}}{H}+\\frac{\\nu}{H\\bar{d}}\\displaystyle\\sum_{\\pi\\in\\Psi_{h}^{\\Psi_{\\mathrm{sh}}^{\\mathrm{sp}}}}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}\\right]\\left(N_{\\mathrm{reg}}\\cdot\\bar{\\theta}-\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\bar{\\vartheta}_{h}^{t,\\widehat{\\pi}^{(k)}}\\right)\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Using that $\\hat{\\theta}_{h}^{(k)}$ is the minimizer over $\\mathbb{B}_{2d}\\!\\left(4H d^{2}\\right)$ f evaltedto $d N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{freed}}+\\frac{\\nu N_{\\mathrm{reg}}\\varepsilon_{\\mathrm{rep}}}{H}$ vNregerep with \u03b8 = With $\\begin{array}{r}{\\overline{{\\theta}}=\\frac{1}{N_{\\mathrm{reg}}}\\sum_{t\\in{\\mathcal{T}}^{(k)}}\\bar{\\pmb{\\vartheta}}_{h}^{t,\\widehat{\\pi}^{(k)}}\\in\\mathbb{B}_{2d}(4H d^{2})}\\end{array}$ , we have that $\\sum_{\\substack{\\in\\Psi_{h}^{\\mathrm{span}}}}\\left|\\sum_{t\\in\\mathbb{Z}^{(k)}}\\|\\big\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\big\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(\\mathbf{x}_{h}^{t},a_{h}^{t})^{\\top}\\hat{\\theta}_{h}^{(k)}-\\sum_{s=h}^{H}\\ell_{s}^{t}\\right)\\right|\\leq d N_{\\mathrm{reg}}\\cdot\\varepsilon_{\\mathrm{freed}}+\\frac{\\nu N_{\\mathrm{reg}}\\varepsilon_{\\mathrm{rep}}}{H}.$ ", "page_idx": 38}, {"type": "text", "text": "Now, combinin his with 80)and (81)with $\\bar{\\theta}=\\hat{\\theta}_{k}^{(k)}$ , we get that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\lefteqn{\\sum_{\\pi\\in\\mathbb{V}_{h}^{\\ast\\mathrm{pan}}}\\left\\vert\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}^{\\pi}\\left[\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}\\hat{\\theta}_{h}^{(k)}-Q_{h}^{\\widehat{\\pi}^{(k)}}(x_{h},a;\\mathcal{H}^{t-1})\\mid\\mathcal{H}^{t-1}\\right]\\right\\vert}}\\\\ &{}&{\\le\\frac{H d^{2}N_{\\mathrm{reg}}\\varepsilon_{\\mathrm{freed}}}{\\nu}+\\frac{H d}{\\nu}\\sum_{\\pi\\in\\mathbb{V}_{h}^{\\ast\\mathrm{pan}}}\\left\\vert\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{I}\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h}^{t},a_{h}^{t})^{\\top}\\hat{\\theta}_{h}^{(k)}-\\sum_{s=h}^{H}\\varepsilon_{s}^{t}\\right)\\right\\vert,}\\\\ &{}&{\\le\\frac{2H d^{2}N_{\\mathrm{reg}}\\varepsilon_{\\mathrm{freed}}}{\\nu}+d N_{\\mathrm{reg}}\\varepsilon_{\\mathrm{rep}}.\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\left(83\\pi\\sqrt{\\lambda^{\\prime}\\nu^{t}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "F.4 Putting It All Together ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "By combining (74), (79), (83), and (75), we have that under the event $\\mathcal{E}$ in (72): ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}_{T}=H T_{0}+\\displaystyle\\sum_{k\\in[K]}\\sum_{t\\in\\mathbb{Z}^{(k)}}\\left(\\mathbb{E}_{\\pi\\sim\\rho^{(k)}}\\mathbb{E}\\left[V_{1}^{\\pi}(x_{1};\\mathcal{H}^{t-1})\\right]-V_{1}^{\\pi^{\\star}}(x_{1};\\mathcal{H}^{t-1})\\right),}\\\\ &{\\qquad\\qquad\\le H T_{0}+H T\\nu+T\\cdot\\varepsilon_{\\mathrm{span}}+3d T\\cdot\\varepsilon_{\\mathrm{rep}}+\\frac{2H d^{2}T\\varepsilon_{\\mathrm{freed}}}{\\nu}}\\\\ &{\\qquad\\qquad+\\,d T\\varepsilon_{\\mathrm{rep}}+\\frac{N_{\\mathrm{reg}}\\log(T/\\gamma)}{\\eta}+64H^{2}d^{4}\\eta T+H\\gamma.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Thus, plugging in the expression of $T_{0}$ $\\varepsilon_{\\mathrm{freed}}$ ,and $(\\varepsilon_{\\mathrm{span}},\\varepsilon_{\\mathrm{rep}})$ from Algorithm 4, Lemma F.3, and Corollary F.1, respectively, and ignoring polynormal factors $\\bar{d},A,H,\\mathrm{log}(|\\Phi|\\varepsilon^{-1}\\delta^{-1})$ ,we get that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}_{T}<\\frac{1}{\\varepsilon^{2}}+T\\varepsilon+T\\nu+\\frac{T}{\\nu}\\sqrt{\\frac{\\nu}{N_{\\mathrm{reg}}}}+\\frac{N_{\\mathrm{reg}}}{\\eta}+\\eta T,}\\\\ &{\\qquad<T^{2/3}+T N_{\\mathrm{reg}}^{-1/3}+\\sqrt{T N_{\\mathrm{reg}}},\\quad\\mathrm{(by~setting~}\\varepsilon=T^{-1/3},\\,\\eta=\\bigl(N_{\\mathrm{reg}}/T\\bigr)^{1/2},\\,\\nu=N_{\\mathrm{reg}}^{-1/3}\\bigr)}\\\\ &{\\qquad<T^{4/5}\\quad(N_{\\mathrm{reg}}=T^{3/5}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the last step follows by setting $N_{\\mathrm{reg}}=T^{2/3}$ ", "page_idx": 39}, {"type": "text", "text": "F.5 Spanner Guarantee ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Algorithm 7 Spanner: Computing an Approximate Spanner. ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Require: Layer $h$ , feature classes $\\Phi$ , policy covers $\\Psi_{1:H}$ , feature map $\\bar{\\phi}:\\mathcal{X}\\times\\mathcal{A}\\rightarrow\\mathbb{R}^{2d}$ ,#of episodes $n$   \n1: Define ${\\mathcal{G}}=\\{g:(x,a)\\mapsto\\phi(x,a)^{\\top}w\\mid\\phi\\in\\Phi,w\\in\\mathbb{B}_{d}(2{\\sqrt{d}})\\}.$   \n2: For $\\theta\\in\\mathbb{R}^{2d}$ and $(x,a)\\in\\mathcal{X}\\times\\mathcal{A}$ define ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{t}(x,a;\\theta):=\\left\\{\\begin{array}{l l}{\\bar{\\phi}_{h}(x,a)^{\\top}\\theta,}&{\\mathrm{for}\\;t=h,}\\\\ {0,}&{\\mathrm{otherwise}}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "3: Set $\\mathcal{G}_{h}=\\{(x,a)\\mapsto\\bar{\\phi}_{h}(x,a)^{\\intercal}\\theta:\\theta\\in\\mathbb{B}_{2d}(1)\\}$ , and for $t\\in[h-1]$ , set $\\mathcal{G}_{t}=\\mathcal{G}$   \n4: For each $t\\in[h]$ ,set $P_{t}=\\mathrm{unif}\\left(\\Psi_{t}\\right)$   \n5: For $\\theta\\in\\mathbb{R}^{2d}$ , define LinOpt $:(\\theta)=\\mathtt{P S D P}\\big(h,r_{1:h}(\\cdot,\\cdot;\\theta),\\mathcal{G}_{1:h},P_{1:h},n\\big)\\in\\Pi.$ //PSDP as in Mhammedi et al. (2023).   \n6: For $\\theta\\in\\mathbb{R}^{2d}$ and $\\pi\\in\\Pi$ , define $\\mathtt{L i n E s t}(\\pi)=\\mathtt{E s t V e c}(h,\\bar{\\phi}_{h},\\pi,n)$ . // EstVec as in Mhammedi et al.(2023).   \n7: Set $\\begin{array}{r}{\\pi_{1:2d}=\\mathtt{R o b u s t S p a n n e r}\\left(\\mathtt{L i n O p t}(\\cdot),\\mathtt{L i n E s t}(\\cdot),2,\\sqrt{\\frac{A d^{2}\\log(n d H|\\Phi|/\\delta)}{\\alpha n}}\\right).}\\end{array}$ RobustSpanner as in Mhammedi et al.(2023).   \n8: Return: Policy cover $\\{\\pi_{1},...,\\pi_{2d}\\}$ ", "page_idx": 39}, {"type": "text", "text": "Lemma F.2 (Spanner Guarantee). Let $\\varepsilon,\\alpha,\\delta\\,\\in\\,(0,1),\\ h\\,\\in\\,[H],\\ n\\,\\geq\\,1,$ and $\\bar{\\phi}_{h}:\\mathcal{X}\\times\\mathcal{A}\\to\\mathbb{R}^{2d}$ be given. Suppose that Assumption 2.1 and Assumption 4.1 hold, and let $\\Psi_{1:h}$ be such that for all $\\bar{s}\\,\\in\\,[h]$ \uff0c $\\Psi_{s}$ is an $(\\alpha,\\varepsilon)$ -poliy coverforlayers with $\\left|\\Psi_{s}\\right|\\;=\\;2d$ Then, the output $\\Psi_{h}^{\\mathrm{spain}}\\;=$ ", "page_idx": 39}, {"type": "text", "text": "Spanner $(h,\\Phi,\\Psi_{1:h},\\bar{\\phi}_{h},n)$ (Algorithm 7) is such that $|\\Psi_{h}^{\\mathrm{span}}|\\,=\\,2d$ and, with probability at least $1-\\delta$ for all $\\pi^{\\prime}\\in\\Pi$ there xist $\\left\\{\\beta_{\\pi}\\in\\left[-2,2\\right]:\\pi\\in\\Psi_{h}^{\\mathrm{span}}\\right\\}$ span} such that hu\u00e4 ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\left\\|\\mathbb{E}^{\\pi^{\\prime}}[\\bar{\\phi}_{h}(x_{h},a_{h})]-\\sum_{\\pi\\in\\Psi_{h}^{\\mathrm{span}}}\\beta_{\\pi}\\cdot\\mathbb{E}^{\\pi}[\\bar{\\phi}_{h}(x_{h},a_{h})]\\right\\|\\leq\\varepsilon_{\\mathrm{span}}(n,\\alpha,\\delta),\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\varepsilon_{\\mathrm{span}}(n,\\alpha,\\delta):=c H^{2}d\\sqrt{\\frac{d A\\cdot(d\\log(2n\\sqrt{d}H)+\\log(n|\\Phi|/\\delta))}{\\alpha n}}+H^{2}d^{5/2}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where $c>0$ is a large enough absolute constant. Furthermore, the number of episodes $T_{\\mathrm{span}}(n)$ used by the call to Spanner is at most ${\\widetilde{O}}(H^{2}d^{2}n)$ ", "page_idx": 40}, {"type": "text", "text": "Proof. To derive the desired bound, we will use the generic guarantee of RobustSpanner from (Mhammedi et al., 2023, Proposition E.1). To invoke this result, we first need to derive guarantees for the optimization and estimation subroutines LinOpt and LinEst withn the Spanner algorithm (Algorithm 7). In particular, we need to show that there is some $\\varepsilon^{\\prime}\\in(0,1)$ such that (with high probability) for any $\\bar{\\theta}\\in\\mathbb{R}^{2d}\\setminus\\{0\\}$ and $\\pi\\in\\Pi$ the outputs $\\hat{\\pi}_{\\bar{\\theta}}:=\\tt L i n O p t}(\\bar{\\theta}/\\|\\bar{\\theta}\\|)$ and $\\hat{\\phi}^{\\pi}:=\\mathtt{L i n E s t}(\\pi)$ satisfy ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\Sigma}\\bar{\\theta}^{\\top}\\mathbb{E}^{\\pi}[\\bar{\\phi}_{h}(x_{h},a_{h})]\\leq\\bar{\\theta}^{\\top}\\mathbb{E}^{\\hat{\\pi}_{\\theta}}[\\bar{\\phi}_{h}(x_{h},a_{h})]+\\varepsilon^{\\prime}\\cdot\\|\\bar{\\theta}\\|\\quad\\mathrm{~and~}\\quad\\|\\hat{\\phi}^{\\pi}-\\mathbb{E}^{\\pi}[\\bar{\\phi}_{h}(x_{h},a_{h})]\\|\\leq\\varepsilon^{\\prime}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "With this, we can apply (Mhammedi et al., 2023, Proposition E.1) to get that the output ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\pi_{1:2d}=\\mathsf{R o b u s t S p a n n e r}(\\mathtt{L i n O p t}(\\cdot),\\mathtt{L i n E s t}(\\cdot),2,\\varepsilon)\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "for $\\varepsilon\\le2\\varepsilon^{\\prime}$ is such that for all $\\pi\\in\\Pi$ , there exist $\\beta_{1},\\dots,\\beta_{d}\\in[-2,2]$ satisfying ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\left\\|\\mathbb{E}^{\\pi}[\\bar{\\phi}_{h}(\\pmb{x}_{h},\\pmb{a}_{h})]-\\sum_{i=1}^{d}\\beta_{i}\\cdot\\mathbb{E}^{\\pi_{i}}[\\bar{\\phi}_{h}(\\pmb{x}_{h},\\pmb{a}_{h})]\\right\\|\\leq6d\\varepsilon^{\\prime}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Since LinOpt is based on PSDP as in Line 5 of Algorithm 7 and $\\Psi_{1},\\ldots,\\Psi_{h}$ are $(\\alpha,\\varepsilon)$ -policy covers for layers 1 to $h$ , respectively, (Mhammedi et al., 2023, Corollary H.1) implies that there is an event $\\mathcal{E}^{\\mathtt{P S D P}}$ ofprobability atleast $1-\\delta/2$ under which for any $\\bar{\\theta}\\in\\mathbb{R}^{d}\\setminus\\{0\\}$ , the output $\\hat{\\pi}_{\\bar{\\theta}}=\\mathtt{L i n O p t}(\\bar{\\theta})$ satisfies ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\pi\\in\\Pi}{\\operatorname*{sup}}\\bar{\\theta}^{\\top}\\mathbb{E}^{\\pi}\\big[\\bar{\\phi}_{h}(\\pmb{x}_{h},\\pmb{a}_{h})\\big]\\leq\\bar{\\theta}^{\\top}\\mathbb{E}^{\\hat{\\pi}_{\\theta}}[\\bar{\\phi}_{h}(\\pmb{x}_{h},\\pmb{a}_{h})]}\\\\ &{\\quad+\\left\\|\\bar{\\theta}\\right\\|\\cdot\\left(c H^{2}\\sqrt{\\frac{d A\\cdot\\big(d\\log(2n\\sqrt{d}H)+\\log(n|\\Phi|/\\delta)\\big)}{\\alpha n}}+H^{2}d^{3/2}\\varepsilon\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "for a large enough absolute constant $c>0$ . On the other hand, since LinEst is based on EstVec as in Line 6, (Mhammedi et al., 2023, Lemma G.3) implies that there is an event $\\mathcal{E}^{\\mathrm{EstVec}}$ of probability at least $1-\\delta/2$ under which for all $\\pi\\in\\Pi$ , the output $\\hat{\\phi}^{\\pi}:=\\mathtt{L i n E s t}(\\pi)$ satisfies ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\|\\hat{\\phi}^{\\pi}-\\mathbb{E}^{\\pi}[\\bar{\\phi}_{h}({\\pmb x}_{h},{\\pmb a}_{h})]\\|\\leq c\\cdot\\sqrt{\\frac{\\log(2/\\delta)}{n}},\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "for alarge enough absolute constant $c>0$ . Therefore, under $\\mathcal{E}^{\\mathtt{P S D P}}\\cap\\mathcal{E}^{\\mathtt{E s t V e c}}$ , LinOpt and LinEst satisfy (90) with ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\varepsilon^{\\prime}:=c H^{2}{\\sqrt{\\frac{d A\\cdot(d\\log(2n{\\sqrt{d}}H)+\\log(n|\\Phi|/\\delta))}{\\alpha n}}}+H^{2}d^{3/2}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Therefore, by (Mhammedi et al., 2023, Proposition) and the fact that $\\begin{array}{r}{d\\sqrt{\\frac{A\\log(n d H|\\Phi|/\\delta)}{\\alpha n}}\\leq\\varepsilon^{\\prime}}\\end{array}$ the output ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\pi_{1:2d}=\\mathsf{R o b u s t S p a n n e r}\\left(\\mathtt{L i n O p t}(\\cdot),\\mathtt{L i n E s t}(\\cdot),2,d\\sqrt{\\frac{A\\log(n d H|\\Phi|/\\delta)}{\\alpha n}}\\right)\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "is such that for all $\\pi\\in\\Pi$ , there exist $\\beta_{1},\\dots,\\beta_{2d}\\in[-2,2]$ satisfying ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\left\\|\\mathbb{E}^{\\pi}[\\bar{\\phi}_{h}(x_{h},\\pmb{a}_{h})]-\\sum_{i=1}^{2d}\\beta_{i}\\cdot\\mathbb{E}^{\\pi_{i}}[\\bar{\\phi}_{h}(\\pmb{x}_{h},\\pmb{a}_{h})]\\right\\|\\leq\\varepsilon_{\\mathrm{span}}(n,\\alpha,\\delta),\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where $\\varepsilon_{\\mathrm{span}}(n,\\alpha,\\delta)$ is as in (89). ", "page_idx": 40}, {"type": "text", "text": "Bounding the number of episodes _ By (Mhammedi et al., 2023, Proposition E.1), RobustSpanner calls LinOpt and LinEst as most $\\widetilde{O}(\\dot{d}^{2})$ times. Each call to LinOpt [resp. LinEst] requires $H^{2}n$ episodes. This implies the desired bound on the number of iterations. \u53e3 ", "page_idx": 41}, {"type": "text", "text": "F.6  Representation $^+$ Spanner ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Corollary F.1. Let e,8 \u2208 (0., 1), r:H, \uff0c $\\Psi_{h}^{\\mathrm{span}}$ $h\\,\\in\\,[H]$$\\phi_{h}^{\\mathrm{rep}}\\in\\Phi$ $|\\Psi_{h}^{\\mathrm{span}}|=2d$ $\\mathcal{E}^{\\mathrm{rep+span}}$ $1-3\\delta/4$$h\\in[H]$", "page_idx": 41}, {"type": "equation", "text": "$$\n\\forall\\pi\\in\\Pi,\\quad\\left|\\mathbb{E}^{\\pi}\\left[\\phi_{h}^{\\mathrm{rep}}(x_{h},\\pmb{a}_{h})^{\\top}\\pmb{w}_{h+1}^{f}-\\mathbb{E}[f(\\pmb{x}_{h+1})\\mid\\pmb{x}_{h},\\pmb{a}_{h}]\\right]\\right|\\leq\\varepsilon_{\\mathrm{rep}}:=10d^{7/2}\\varepsilon;\n$$", "text_format": "latex", "page_idx": 41}, {"type": "equation", "text": "$$\n\\left\\|\\mathbb{E}^{\\pi^{\\prime}}[\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})]-\\sum_{\\pi\\in\\Psi_{h}^{\\mathrm{span}}}\\beta_{\\pi}\\cdot\\mathbb{E}^{\\pi}[\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h},a_{h})]\\right\\|\\leq\\varepsilon_{\\mathrm{span}}:=2H^{2}d^{5/2}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Proof. From Algorithm 4, we have ", "page_idx": 41}, {"type": "text", "text": "$\\mathrm{\\Delta_{h}^{v e p}=R e p L e a r n}(h,\\mathcal{F}_{h+1},\\Phi,\\operatorname{unif}(\\Psi_{h}^{\\mathrm{cov}}),T_{\\mathrm{rep}})\\quad\\mathrm{\\and}\\quad\\Psi_{h}^{\\mathrm{span}}=\\mathrm{Spanner}(h,\\Phi,\\Psi_{1:h}^{\\mathrm{cov}},\\bar{\\phi}_{h}^{\\mathrm{rep}},T_{\\mathrm{span}}),$ where ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\Psi_{1:H}^{\\mathrm{cov}}=\\mathsf{V o X}\\big(\\Phi,\\varepsilon,\\delta/4\\big),\\qquad T_{\\mathrm{rep}}:=\\frac{A H\\log\\big(|\\Phi|/\\delta\\big)}{\\alpha\\varepsilon^{2}},\\qquad T_{\\mathrm{span}}=\\frac{A\\log(d H|\\Phi|\\varepsilon^{-1}\\delta^{-1})}{\\alpha\\varepsilon^{2}},\\qquad T_{\\mathrm{span}}=\\frac{A H\\log\\big(d H|\\Phi|\\varepsilon^{-1}\\delta^{-1}\\big)}{\\alpha\\varepsilon^{2}},\\qquad T_{\\mathrm{span}}=\\frac{\\varepsilon^{2}}{\\alpha\\varepsilon^{2}}.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "and $\\begin{array}{r}{\\alpha:=\\frac{1}{8A d}}\\end{array}$ By Lemma G.1 there i an event $\\mathcal{E}^{\\mathrm{cov}}$ of probability a last $1-\\delta/4$ under which, for all $h\\in[H],\\Psi_{h}^{\\mathrm{cov}}$ isan $(\\alpha,\\varepsilon)$ -policy cover for layer $h$ with $|\\Psi_{h}^{\\mathrm{cov}}|=d$ In what follows, we condion on $\\mathcal{E}^{\\mathrm{cov}}$ . By Lemma G.2 and Lemma F.2, there are events $\\mathcal{E}^{\\mathrm{rep}}$ and $\\mathcal{E}^{\\mathrm{span}}$ of probability at least $1-\\delta/4$ each such that under $\\mathcal{E}^{\\mathrm{rep}}\\cap\\mathcal{E}^{\\mathrm{span}}$ (92) and (93) hold; this follows from (98) and (88) and the choices of $T_{\\mathrm{rep}}$ and $T_{\\mathrm{span}}$ in (94). Finally, by the union bound, we have $\\mathbb{P}\\big[\\mathcal{E}^{\\mathrm{cov}}\\cap\\mathcal{E}^{\\mathrm{rep}}\\cap\\mathcal{E}^{\\mathrm{span}}\\big]\\ge1-\\delta$ which completes the proof. \u53e3 ", "page_idx": 41}, {"type": "text", "text": "F.7  Martingal Concentration ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Lemma E3. Let $K$ $,\\,N_{\\mathrm{reg}},\\,\\bar{\\phi}_{1:H}^{\\mathrm{rep}}$ and $\\mathcal{I}^{(k)}$ be as in Algorithm 4 for $k\\in[K]$ There is an event $\\mathcal{E}$ freed of probability at least $1-\\delta/4$ under which for all $\\bar{\\theta}\\in\\mathbb{B}_{2d}(4H d^{2}),\\,h\\in[H],\\,k\\in[K],$ and $\\pi\\in\\Psi_{h}^{\\mathrm{span}}$ ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{\\nabla_{\\mathrm{reg}}}\\left|\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{I}\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h}^{t},a_{h}^{t})^{\\top}\\bar{\\theta}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t}\\right)\\right.}\\\\ &{-\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}\\left[\\mathbb{I}\\{h^{t}=h,\\pi^{t}=\\pi,\\zeta^{t}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(x_{h}^{t},a_{h}^{t})^{\\top}\\bar{\\theta}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t}\\right)|\\cdot\\mathcal{H}^{t-1}\\right]\\right|\\leq\\varepsilon_{\\mathrm{freed}}:=4H d^{2}\\sqrt{\\frac{\\nu\\log(\\sigma)}{1+\\sqrt{\\pi}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where the random variables $h^{t},\\zeta^{t},\\pi^{t}$ ,and $\\pmb{\\mathcal{H}}^{t-1}$ are as in Algorithm 7. ", "page_idx": 41}, {"type": "text", "text": "Proof. Fix $\\bar{\\theta}\\,\\in\\,\\mathbb{B}_{2d}\\bigl(4d^{2}\\bigr),\\:h\\,\\in\\,[H],\\:k\\,\\in\\,[K]$ , and $\\pi\\in\\Psi_{h}^{\\mathrm{span}}$ .We apply Lemma I2 (Freedman's inequality) with ", "page_idx": 41}, {"type": "text", "text": "$R=4H d^{2}$   \n\u00b7 n= Nreg;   \n\u00b7 The random variable $\\pmb{w}^{i}$ set as the difference $\\begin{array}{r l}&{{\\pmb w}^{i}:=\\mathbb{I}\\{{\\pmb h}^{t_{i}}=h,{\\pmb\\pi}^{t_{i}}={\\pmb\\pi},\\zeta^{t_{i}}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}({\\pmb x}_{h}^{t_{i}},{\\pmb a}_{h}^{t_{i}})^{\\top}\\bar{{\\pmb\\theta}}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t_{i}}\\right)}\\\\ &{~~~~~~-\\mathbb{E}\\left[\\mathbb{I}\\{{\\pmb h}^{t_{i}}=h,{\\pmb\\pi}^{t_{i}}={\\pmb\\pi},\\zeta^{t_{i}}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}({\\pmb x}_{h}^{t_{i}},{\\pmb a}_{h}^{t_{i}})^{\\top}\\bar{{\\pmb\\theta}}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t_{i}}\\right)|\\,\\mathcal{H}^{t-1}\\right],}\\end{array}$ where $t_{i}:=\\left(k-1\\right)\\cdot N_{\\mathrm{reg}}+i$ .\uff0c ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{n}=\\displaystyle\\sum_{i=1}^{N_{\\mathrm{reg}}}\\mathbb{E}\\left[(\\pmb{w}^{i})^{2}\\mid\\widetilde{\\mathbf{g}}^{i-1}\\right]\\leq\\displaystyle\\sum_{i=1}^{N_{\\mathrm{reg}}}\\mathbb{E}\\left[\\mathbb{I}\\{h^{t_{i}}=h,\\pi^{t_{i}}=\\pi,\\zeta^{t_{i}}=1\\}\\cdot\\left(\\overline{{\\phi}}_{h}^{\\mathrm{rep}}(x_{h}^{t_{i}},a_{h}^{t_{i}})^{\\top}\\overline{{\\theta}}-\\displaystyle\\sum_{s=h}^{H}\\ell_{s}^{t_{i}}\\right)^{2}\\mid\\widetilde{\\mathbf{g}}^{i}\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\left.\\leq8H d^{3}\\nu N_{\\mathrm{reg}};}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bullet\\,\\,\\lambda=H^{-1}\\,\\bigg(\\frac{d^{2}\\nu N_{\\mathrm{reg}}}{\\log(K H N_{\\mathrm{reg}}/\\delta)}\\bigg)^{-1/2};}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "$\\mathcal{E}_{h,k,\\pi}^{\\mathrm{freed}}(\\bar{\\theta})$ $1-(N_{\\mathrm{reg}})^{-d}H^{-1}K^{-1}d^{-1}\\delta/8$ ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{N_{\\mathrm{reg}}}\\displaystyle\\left\\lvert\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{I}\\{\\boldsymbol{h}^{t}=\\boldsymbol{h},\\boldsymbol{\\pi}^{t}=\\boldsymbol{\\pi},\\boldsymbol{\\zeta}^{t}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(\\boldsymbol{x}_{h}^{t},\\boldsymbol{a}_{h}^{t})^{\\top}\\bar{\\boldsymbol{\\theta}}-\\displaystyle\\sum_{s=h}^{H}\\boldsymbol{\\ell}_{s}^{t}\\right)}\\\\ &{\\qquad-\\displaystyle\\sum_{t\\in\\mathbb{Z}^{(k)}}\\mathbb{E}\\left[\\mathbb{I}\\{\\boldsymbol{h}^{t}=\\boldsymbol{h},\\boldsymbol{\\pi}^{t}=\\boldsymbol{\\pi},\\boldsymbol{\\zeta}^{t}=1\\}\\cdot\\left(\\bar{\\phi}_{h}^{\\mathrm{rep}}(\\boldsymbol{x}_{h}^{t},\\boldsymbol{a}_{h}^{t})^{\\top}\\bar{\\boldsymbol{\\theta}}-\\displaystyle\\sum_{s=h}^{H}\\boldsymbol{\\ell}_{s}^{t}\\right)\\big|\\,\\mathcal{H}^{t-1}\\right]\\Big\\rvert}\\\\ &{\\leq4H d^{2}\\sqrt{\\frac{\\nu\\log\\left(d K H N_{\\mathrm{reg}}/\\delta\\right)}{N_{\\mathrm{reg}}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Let $\\mathcal{C}$ be a minimal $(d H N_{\\mathrm{reg}})^{-1}$ -cover of $\\mathbb{B}_{2d}(4H d^{2})$ with respect to the $\\|\\cdot\\|$ distance. Under the event ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\mathcal{E}^{\\mathrm{freed}}:=\\bigcap_{h\\in[H],k\\in[K],\\pi\\in\\Psi_{h}^{\\mathrm{span}},\\bar{\\theta}\\in\\mathbb{B}_{2d}(4H d^{2})}\\mathcal{E}_{h,k,\\pi}^{\\mathrm{freed}}(\\bar{\\theta}),\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Eq. (96) holds for all $h\\in[H],k\\in[K]$ and $\\bar{\\theta}\\in\\mathbb{B}_{2d}\\big(4H d^{2}\\big)$ up to an additive $O(1/N_{\\mathrm{reg}})$ error. By the union bound, we have $\\mathbb{P}[\\mathcal{E}^{\\mathrm{freed}}]\\ge1-\\delta/4$ which completes the proof. \u53e3 ", "page_idx": 42}, {"type": "text", "text": "G  Policy Cover and Representation Learning Algorithms ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "In this section, we present guarantees for VoX, RepLearn, and RobustSpanner which we need in the analysis of our oracle efficient algorithm. The results are based on (Mhammedi et al., 2023). ", "page_idx": 43}, {"type": "text", "text": "G.1  Policy Cover ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "The following result is a restatement of (Mhammedi et al., 2023, Theorem 12). ", "page_idx": 43}, {"type": "text", "text": "Lemma G.1 (VoX Guarantee). Let $\\varepsilon,\\delta\\in(0,1)$ be given. Suppose Assumption 2.1 and Assumption 4.1   \nhold.Then, there is an event $\\mathcal{E}^{\\mathrm{cov}}$ of probability at least $1-\\delta$ under which the output $\\Psi_{1:H}^{\\mathrm{cov}}\\;=\\;$   \n$\\operatorname{VoX}(\\Phi,\\varepsilon,\\delta)$ is such that for all $h\\in[H]$ \u00b7 $\\Psi_{h}^{\\mathrm{cov}}$ isa $(\\textstyle{\\frac{1}{8A d}},\\varepsilon)$ -policy cover for layer $h$ $|\\Psi_{h}^{\\mathrm{cov}}|\\leq d.$ ", "page_idx": 43}, {"type": "text", "text": "Furthermore, the number of episodes $T_{\\mathrm{cov}}(\\varepsilon)$ used by the call to Vox is bounded by $\\widetilde{O}(A d^{13}H^{6}\\log(\\Phi/\\delta))/\\varepsilon^{2}$ ", "page_idx": 43}, {"type": "text", "text": "G.2  Representation Learning ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Lemma G.2 (Representation Learning Guarantee). Let $\\varepsilon,\\alpha,\\delta\\in(0,1)$ $h\\in[H-1]$ and $n\\geq1$ be given and define the function class ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\mathcal{F}_{h+1}:=\\left\\{f:(x,a)\\mapsto\\operatorname*{max}_{a\\in A}\\bar{\\phi}_{h+1}(x,a)^{\\top}\\bar{\\theta}\\,\\,|\\,\\,\\bar{\\phi}_{h+1}=[\\phi_{h+1}^{\\mathrm{loss}},\\phi_{h+1}],\\phi\\in\\Phi,\\bar{\\theta}\\in\\mathbb{B}_{2d}(1)\\right\\}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Further,let $\\Psi$ be an $(\\alpha,\\varepsilon)$ -policycover for layer $h$ with $|\\Psi|\\ \\ =\\ d_{\\mathrm{:}}$ and supposeAssumption 2.1 and Assumption 4.1 hold. Then, with probability at least $1\\,-\\,\\delta$ . the output $\\bar{\\phi}_{h}^{\\mathrm{rep}}\\;\\;{=}\\;\\;$ RepLearn $(h,\\mathcal{F}_{h+1},\\Phi,\\operatorname{unif}(\\Psi),n)$ is such that for all $f\\,\\in\\,{\\mathcal{F}}_{h+1}$ there exists $w_{h+1}^{f}\\in\\mathbb{B}_{d}(3d^{3/2})$ such that: ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\forall\\pi\\in\\Pi,\\quad\\left|\\mathbb{E}^{\\pi}\\left[\\phi_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}w_{h+1}^{f}-\\mathbb{E}[f(x_{h+1})\\mid x_{h},a_{h}]\\right]\\right|\\leq c\\cdot\\sqrt{\\frac{A H d^{5}\\log(|\\Phi|/\\delta)}{\\alpha n}}+9d^{7/2}\\varepsilon,\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where $c>0$ is a large enough absolute constant. Furthermore, the number of episodes $T_{\\mathrm{rep}}(\\varepsilon)$ used by the call to RepLearn is equal to $n$ ", "page_idx": 43}, {"type": "text", "text": "Proof. By (Mhammedi et al., 2023, Theorem F.1) and the assumption that $|\\Psi|=d$ , there is an event $\\mathcal{E}$ of probability at least $1-\\delta/2$ under which $\\phi_{h}^{\\mathrm{rep}}$ satisies: ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{f\\in\\mathcal{F}_{h+1}}\\operatorname*{inf}_{w\\in\\mathbb{B}_{d}(3d^{3/2})}\\operatorname*{max}_{\\pi^{\\prime}\\in\\Psi}\\mathbb{E}^{\\pi^{\\prime}}\\left[\\big(\\phi_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}w-\\mathbb{E}[f(x_{h+1})\\mid x_{h},a_{h}]\\big)^{2}\\right]\\leq c\\cdot\\frac{A d^{5}\\log(|\\Phi|/\\delta)}{n},\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where $c$ is a large enough absolute constant. We use this to show (98). In what follows, we condition on $\\mathcal{E}$ Fix $\\pi\\in\\Pi$ and $f\\in\\mathcal G$ and let $w_{h+1}^{f}$ be the vector $w\\in\\mathbb{B}_{d}(3d^{3/2})$ achieving the infimum in (99) for the given choice of $f$ Let $\\chi_{h,\\varepsilon}$ be the set of $\\varepsilon$ -reachable states at layer $h$ as defined in (50). With this this, we have for all $h\\in[H]$ \uff0c ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\vert\\mathbb{E}^{\\pi}\\left[\\phi_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}w_{h+1}^{f}-\\mathbb{E}[f({x}_{h+1})\\mid x_{h},a_{h}]\\right]\\right\\vert}\\\\ &{\\le\\left\\vert\\mathbb{E}^{\\pi}\\left[\\mathbb{I}\\{x_{h}\\notin\\chi_{h,\\varepsilon}\\}\\cdot(\\phi_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}w_{h+1}^{f}-\\mathbb{E}[f({x}_{h+1})\\mid x_{h},a_{h}])\\right]\\right\\vert}\\\\ &{\\quad+\\left\\vert\\mathbb{E}^{\\pi}\\left[\\mathbb{I}\\{x_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\cdot(\\phi_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}w_{h+1}^{f}-\\mathbb{E}[f({x}_{h+1})\\mid x_{h},a_{h}])^{2}\\right]\\right\\vert,}\\\\ &{\\le\\left\\vert\\mathbb{E}^{\\pi}\\left[\\mathbb{I}\\{x_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\cdot(\\phi_{h}^{\\mathrm{rep}}(x_{h},a_{h})^{\\top}w_{h+1}^{f}-\\mathbb{E}[f({x}_{h+1})\\mid x_{h},a_{h}])\\right]\\right\\vert+9d^{7/2}\\varepsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where the last inequality follows by Lemma I.1. ", "page_idx": 43}, {"type": "text", "text": "We now bound the first term on the right-hand side of (100). By Jensen's inequality, we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\mathbb{E}^{\\pi}\\left[\\mathbb{I}\\{\\pmb{x}_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\cdot(\\phi_{h}^{\\mathrm{rep}}(\\pmb{x}_{h},\\pmb{a}_{h})^{\\top}\\pmb{w}_{h+1}^{f}-\\mathbb{E}[f(\\pmb{x}_{h+1})\\mid\\pmb{x}_{h},\\pmb{a}_{h}])\\right]\\right|}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "equation", "text": "$$\n\\leq\\sqrt{\\mathbb{E}^{\\pi}\\left[\\mathbb{I}\\{\\mathbf{x}_{h}\\in\\mathcal{X}_{h,\\varepsilon}\\}\\cdot(\\phi_{h}^{\\mathrm{rep}}(\\mathbf{x}_{h},\\mathbf{a}_{h})^{\\top}w_{h+1}^{f}-\\mathbb{E}\\big[f(x_{h+1})\\mid x_{h},a_{h}\\big])^{2}\\right]},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "and so using that $\\Psi$ is a $(\\alpha,\\varepsilon^{\\prime})$ -policy cover (see Definition 4.1), we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\le\\sqrt{\\alpha^{-1}\\cdot\\underset{\\pi^{\\prime}\\in\\Psi}{\\operatorname*{max}}\\mathbb{E}^{\\pi^{\\prime}}\\left[(\\phi_{h}^{\\mathrm{rep}}(x_{h},\\pmb{a}_{h})^{\\top}w_{h+1}^{f}-\\mathbb{E}[f(\\pmb{x}_{h+1})\\mid\\pmb{x}_{h},\\pmb{a}_{h}])^{2}\\right]},}\\\\ &{\\le\\sqrt{c\\cdot\\frac{A H d^{5}\\log(|\\Phi|/\\delta)}{\\alpha n}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where the last step follows by (99). Combining this with (100) yields (98). ", "page_idx": 44}, {"type": "text", "text": "HLower Bound for Bandit feedback with Unstructured Losses ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "In full-information, one does not require any structure on the losses. We show that this is not the case for the bandit case via a lower bound depending polynomially on the number of states. This lower bound implies that the low-rank transition structure with unstructured losses does not give any significant improvements over the tabular setting. ", "page_idx": 45}, {"type": "text", "text": "Theorem H.1. There exists a low-rank MDP with $S$ states, $A$ actions and sufficiently large time step $T$ with unstructured losses such that any agent suffers at least regret of $\\Omega({\\sqrt{S A T}})$ ", "page_idx": 45}, {"type": "text", "text": "Proof. We assume $4S<{\\sqrt{T}}$ .The construction is an $H\\,=\\,1$ (i.e. contextual bandit) MDP with uniform initial distribution over states. Each state is a copy of an $A$ -armed bandit problem with Bernoulli losses with mean $\\frac{1}{2}$ , and one randomly chosen optimal arm with mean $\\begin{array}{r}{\\frac{1}{2}-\\dot{\\Delta}}\\end{array}$ . Following the standard lower bound construction for bandits (Lattimore and Szepesvari, 2020), there exists $\\Delta=\\Theta(1/\\sqrt{T A S})$ such that the the regret of playing any individual bandit problem for $N\\leq2T/S$ rounds is lower bounded by $\\Omega(N\\Delta)$ . Let denote $N(s)$ the number of time the agent receives the initial state $s$ , then any agent suffers a regret lower bound in our MDP of ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\Omega\\left(\\sum_{s=1}^{S}\\mathbb{E}[\\operatorname*{min}\\{N(s),2T/S\\}]\\right)\\,.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "$N(s)$ is the sum of $T$ Bernoulli random ariables with mean $1/S$ . We have by Hoeffding's inequality ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{P}[N(s)>T/S+x]\\le\\exp(-2x^{2}/T)\\,.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "This allows to upper bound the tail ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{E}[N(s)\\mathbb{I}(N(s)>2T/S)]\\le\\displaystyle\\int_{T/S}^{\\infty}x(2x/T\\exp(-2x^{2}/T))\\,d x}&{}&\\\\ {\\le\\displaystyle\\int_{T/S}^{\\infty}4\\exp(x/\\sqrt{T}-2x^{2}/T)\\,d x}&{\\quad(\\frac{1}{2}(x/\\sqrt{T})^{2}<\\exp(x/\\sqrt{T}))}\\\\ &{\\le\\displaystyle\\int_{T/S}^{\\infty}4\\exp(-x/\\sqrt{T})\\,d x}&{(x\\ge T/S>4\\sqrt{T})}\\\\ &{=4\\sqrt{T}\\exp(-\\sqrt{T}/S)\\le4\\sqrt{T}\\exp(-4)\\le T/(2S)\\,.}&\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Hence $\\mathbb{E}[\\operatorname*{min}\\{N(s),2T/S\\}]=T/S-\\mathbb{E}[N(s)\\mathbb{I}(N(s)>2T/S)]\\ge T/(2S)$ and the regret in the MDP is lower bounded by $\\Omega\\left({\\sqrt{T S A}}\\right)$ \u53e3 ", "page_idx": 45}, {"type": "text", "text": "Helper Results ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Lemma I.1. Let $\\varepsilon,B>0$ and $h\\in[2\\ldots H]$ be given. For any function $f:\\mathcal{X}\\rightarrow[-B,B]$ and $\\pi\\in\\Pi$ we have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{E}^{\\pi}[\\mathbb{I}\\left\\{\\pmb{x}_{h}\\notin\\mathcal{X}_{h,\\varepsilon}\\right\\}\\cdot f(\\pmb{x}_{h})]\\leq B\\sqrt{d}\\varepsilon,\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathcal{X}_{h,\\varepsilon}:=\\left\\{x\\in\\mathcal{X}:\\operatorname*{max}_{\\pi\\in\\Pi}d_{h}^{\\pi}(x)\\geq\\varepsilon\\cdot\\|\\mu_{h}^{\\star}(x)\\|\\right\\},\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "denotes the set of states that are $\\varepsilon$ -reachableat layer $h$ ", "page_idx": 45}, {"type": "text", "text": "Proof. Fix $f:\\mathcal{X}\\rightarrow[-B,B]$ and $\\pi\\in\\Pi$ . Using the definition of $\\chi_{h,\\varepsilon}$ in (102), we have that $x\\notin\\mathcal{X}_{h,\\varepsilon}$ only if $d_{h}^{\\pi}(x)<\\varepsilon\\|\\mu_{h}^{\\bar{\\star}}(x)\\|$ . Using this, we have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}^{\\pi}[\\mathbb{I}\\left\\{\\pmb{x}_{h}\\notin\\mathcal{X}_{h,\\varepsilon}\\right\\}\\cdot f(\\pmb{x}_{h})]\\leq\\displaystyle\\sum_{x\\in\\mathcal{X}}\\mathbb{I}\\left\\{x\\notin\\mathcal{X}_{h,\\varepsilon}\\right\\}\\cdot d_{h}^{\\pi}(x)\\cdot f(x),}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq B\\varepsilon\\displaystyle\\sum_{x\\in\\mathcal{X}}\\|\\mu_{h}^{\\star}(x)\\|,}\\\\ &{\\qquad\\qquad\\qquad\\leq B d^{3/2}\\varepsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where the last step follows by the normalizing assumption on $\\mu^{\\star}$ (see Assumption 2.1) and (Mhammedi et al., 2023, Lemma I.3). \u53e3 ", "page_idx": 45}, {"type": "text", "text": "1.1 Martingale Concentration and Regression Results ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Lemma I.2. Let $R>0$ be given and let $w^{1},\\ldots w^{n}$ bea sequence of real-valuedrandomvariables adapted tofiltration $\\mathfrak{F}^{1},\\cdots,\\mathfrak{F}^{n}$ Assumethatforall $i\\in[n]$ $w^{i}\\leq\\dot{R}$ and $\\mathbb{E}[{\\pmb w}^{i}\\mid\\mathfrak{F}^{i-1}]=0$ Define $\\begin{array}{r}{S_{n}:=\\,\\sum_{i=1}^{n}w^{i}}\\end{array}$ and $\\begin{array}{r}{V_{n}\\;:=\\;\\sum_{i=1}^{n}\\mathbb{E}[({\\pmb w}^{i})^{2}\\;|\\;\\mathfrak{F}^{i-1}]}\\end{array}$ . Then, for any $\\delta\\,\\in\\,(0,1)$ and $\\lambda\\,\\in\\,\\left[0,1/R\\right]$ with probability at least $1-\\delta$ \uff0c ", "page_idx": 46}, {"type": "equation", "text": "$$\nS_{n}\\leq\\lambda V_{n}+\\ln(1/\\delta)/\\lambda.\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "We now state two helpful results from Mhammedi et al. (2024b) without a proof. ", "page_idx": 46}, {"type": "text", "text": "Lemma I.3. Let $B>0$ and $n\\in\\mathbb{N}$ be given. abstract set. Further, let $\\mathcal{Q}\\subseteq\\{g:\\mathcal{X}\\times\\mathcal{A}\\to[0,B]\\}$ be $a$ finite function class and $(\\pmb{x}^{1},\\pmb{a}^{1},\\pmb{\\varepsilon}^{1}),\\pmb{\\cdot}\\cdot\\cdot,(\\pmb{x}^{n},\\pmb{a}^{n},\\pmb{\\varepsilon}^{n})$ be a sequence of i.i.d. random variables in $\\mathcal{X}\\times\\mathcal{A}\\times\\mathbb{R}$ .Then, for any $\\delta\\in(0,1)$ ,with probability at least $1-\\delta$ , we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\forall g\\in\\mathcal{Q},\\quad\\frac{1}{2}\\|g\\|^{2}-2B^{2}\\log(2|\\mathcal{Q}|/\\delta)\\leq\\|g\\|_{n}^{2}\\leq2\\|g\\|^{2}+2B^{2}\\log(2|\\mathcal{Q}|/\\delta),\n$$", "text_format": "latex", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|g\\|^{2}:=\\sum_{i\\in[n]}\\mathbb{E}[g({\\pmb x}^{i},{\\pmb a}^{i})^{2}\\mid\\mathfrak{F}^{i-1}]\\;a n d\\;\\|g\\|_{n}^{2}:=\\sum_{i=1}^{n}g({\\pmb x}^{i},{\\pmb a}^{i})^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Lemma I.4 (Generic regression guarantee). Let $B>0,\\,n\\in\\mathbb{N}$ and $f_{\\star}:\\mathcal{X}\\times\\mathcal{A}\\rightarrow[0,B]$ be given. Further, let $\\mathcal{F}\\subseteq\\{f:\\mathcal{X}\\stackrel{\\cdot}{\\times}\\mathcal{A}\\rightarrow[0,^{\\cdot}B]\\}$ be a finite function class and $(\\pmb{x}^{1},\\pmb{a}^{1},\\pmb{\\varepsilon}^{1}),\\dots,(\\pmb{x}^{n},\\pmb{a}^{n},\\pmb{\\varepsilon}^{n})$ be a sequence of i.i.d. random variables in $\\mathcal{X}\\times\\mathcal{A}\\times\\mathbb{R}$ Suppose that ", "page_idx": 46}, {"type": "text", "text": "$f_{\\star}\\in{\\mathcal{F}}_{:}$   \n$z^{i}=f_{\\star}\\big({\\pmb x}^{i},{\\pmb a}^{i}\\big)+\\varepsilon^{i}+{\\pmb b}^{i},$ for all $i\\in[n]$ $b^{1},\\ldots,b^{n}\\in\\mathbb{R}$ (not necessarily i.i.d.); $\\boldsymbol{\\varepsilon}^{i}\\in[-B,B]$ for all $i\\in[n]$ :and   \n$\\mathbb{E}[\\pmb{\\varepsilon}^{i}\\mid\\pmb{x}^{i},\\pmb{a}^{i}]=0.$ ", "page_idx": 46}, {"type": "text", "text": "Then, for $\\hat{f}\\in\\operatorname{argmin}_{f\\in\\mathcal{F}}\\sum_{i=1}^{n}(f(\\pmb{x}^{i},\\pmb{a}^{i})-z^{i})^{2}$ and any $\\delta\\in(0,1)$ with probabiliy at last $1-\\delta/2$ ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\|\\hat{f}-f_{\\star}\\|_{n}^{2}\\le8B^{2}\\log(2|\\mathcal{F}|/\\delta)+8\\sum_{i=1}^{n}(b^{i})^{2},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $\\textstyle\\|{\\hat{f}}-f_{\\star}\\|_{n}^{2}:=\\sum_{i=1}^{n}({\\hat{f}}(\\pmb{x}^{i},\\pmb{a}^{i})-f^{\\star}(\\pmb{x}^{i},\\pmb{a}^{i}))^{2}.$ ", "page_idx": 46}, {"type": "text", "text": "Proof. Fix $\\delta\\;\\in\\;(0,1)$ and let $\\begin{array}{r}{\\widehat{L}_{n}(f)\\;:=\\;\\sum_{i=1}^{n}(f(\\pmb{x}^{i},\\pmb{a}^{i})-\\pmb{z}^{i})^{2}}\\end{array}$ , for $f\\,\\in\\,{\\mathcal{F}}$ , and note that since $\\hat{f}\\in\\mathrm{argmin}_{f\\in\\mathcal{F}}\\,\\widehat{L}_{n}(f)$ , we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n0\\geq\\widehat{L}_{n}(\\widehat{f})-\\widehat{L}_{n}(f_{\\star})=\\nabla\\widehat{L}_{n}(f_{\\star})[\\widehat{f}-f_{\\star}]+\\|\\widehat{f}-f_{\\star}\\|_{n}^{2},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $\\nabla$ denotes directional derivative. Rearranging, we get that ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\hat{f}-f_{\\star}\\|_{n}^{2}\\le-2\\nabla\\hat{L}_{n}(f_{\\star})[\\hat{f}-f_{\\star}]-\\|\\hat{f}-f_{\\star}\\|_{n}^{2},}\\\\ &{\\qquad\\qquad=4\\displaystyle\\sum_{i=1}^{n}(z^{i}-f_{\\star}(x^{i},a^{i}))(\\hat{f}(x^{i},a^{i})-f_{\\star}(x^{i},a^{i}))-\\|\\hat{f}-f_{\\star}\\|_{n}^{2},}\\\\ &{\\qquad\\qquad=4\\displaystyle\\sum_{i=1}^{n}(\\varepsilon^{i}+b^{i})(\\hat{f}(x^{i},a^{i})-f_{\\star}(x^{i},a^{i}))-\\|\\hat{f}-f_{\\star}\\|_{n}^{2},}\\\\ &{\\qquad\\qquad=4\\displaystyle\\sum_{i=1}^{n}\\varepsilon^{i}\\cdot(\\hat{f}(x^{i},a^{i})-f_{\\star}(x^{i},a^{i}))-\\|\\hat{f}-f_{\\star}\\|_{n}^{2}+4\\displaystyle\\sum_{i=1}^{n}b^{i}\\cdot(\\hat{f}(x^{i},a^{i})-f_{\\star}(x^{i},a^{i})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\leq4\\sum_{i=1}^{n}\\varepsilon^{i}\\cdot(\\hat{f}(\\pmb{x}^{i},\\pmb{a}^{i})-f_{\\star}(\\pmb{x}^{i},\\pmb{a}^{i}))-\\|\\hat{f}-f_{\\star}\\|_{n}^{2}+4\\sum_{i=1}^{n}(b^{i})^{2}+\\displaystyle\\frac{1}{2}\\sum_{i=1}^{n}(\\hat{f}(\\pmb{x}^{i},\\pmb{a}^{i})-f_{\\star}(\\pmb{x}^{i},\\pmb{a}^{i}))^{2}}\\\\ {\\displaystyle=4\\sum_{i=1}^{n}\\varepsilon^{i}\\cdot(\\hat{f}(\\pmb{x}^{i},\\pmb{a}^{i})-f_{\\star}(\\pmb{x}^{i},\\pmb{a}^{i}))-\\|\\hat{f}-f_{\\star}\\|_{n}^{2}+4\\sum_{i=1}^{n}(b^{i})^{2}+\\displaystyle\\frac{1}{2}\\|\\hat{f}-f_{\\star}\\|_{n}^{2}.}&{(109)}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Thus, rearranging, we get ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\Vert\\hat{f}-f_{\\star}\\Vert_{n}^{2}\\le8\\sum_{i=1}^{n}\\varepsilon^{i}\\cdot\\big(\\hat{f}(\\pmb{x}^{i},\\pmb{a}^{i})-f_{\\star}(\\pmb{x}^{i},\\pmb{a}^{i})\\big)-2\\Vert\\hat{f}-f_{\\star}\\Vert_{n}^{2}+8\\sum_{i=1}^{n}(b^{i})^{2}.\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "We now bound the first term on the right-hand side of (110). For this, we apply Lemma I.2 with $\\pmb{w}^{i}=\\pmb{\\varepsilon}^{i}\\cdot(\\hat{f}(\\pmb{x}^{i},\\pmb{a}^{i})-f_{\\star}(\\pmb{x}^{i},\\pmb{a}^{i}))$ $R=B^{2}$ $\\lambda=1/(8B^{2})$ ,and $\\mathfrak{F}^{i}=\\mathcal{O}$ and use ", "page_idx": 47}, {"type": "text", "text": "1. the union bound over $f\\in\\mathcal F$ ; and   \n2. the facts that $\\mathbb{E}[\\pmb{\\varepsilon}^{i}\\mid\\pmb{x}^{i},\\pmb{a}^{i}]=0$ ", "page_idx": 47}, {"type": "text", "text": "to get that with probability at least $1-\\delta/2$ ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}\\varepsilon^{i}\\cdot(\\hat{f}(\\pmb{x}^{i},\\pmb{a}^{i})-f_{\\star}(\\pmb{x}^{i},\\pmb{a}^{i}))\\leq\\frac{1}{4}\\|\\hat{f}-f_{\\star}\\|_{n}^{2}+B^{2}\\log(2|\\mathcal{F}|/\\delta).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Combining this with (110), we get that with probability at least $1-\\delta/2$ ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\|\\hat{f}-f_{\\star}\\|_{n}^{2}\\le8B^{2}\\log(2|\\mathcal{F}|/\\delta)+8\\sum_{i=1}^{n}(b^{i})^{2}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "This completes the proof. ", "page_idx": 47}, {"type": "text", "text": "1.2  Online Learning ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "The following is the standard guarantee of exponential weights (e.g. Lemma F.4 of Sherman et al.   \n(2023b)). ", "page_idx": 47}, {"type": "text", "text": "Lemma I.5 (Exponential Weights). Given a sequence of loss functions $\\{g^{t}\\}_{t=1}^{T}$ over a decision set II, $\\{p^{t}\\}_{t=1}^{T}$ is a distribution sequence with $p^{t}\\in\\Delta\\left(\\Pi\\right)$ $\\forall t\\in[T]$ suchthat ", "page_idx": 47}, {"type": "equation", "text": "$$\np^{t+1}(\\pi)\\propto\\exp\\left(-\\eta\\sum_{t=1}^{T}g^{t}(\\pi)\\right).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "f $p^{1}$ is a uniform distribution over $|\\Pi|$ and $\\eta g^{t}(\\pi)\\geq-1$ for all $t\\in[T]$ and $\\pi\\in\\Pi.$ Then ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{p\\in\\Delta(\\Pi)}\\left\\{\\sum_{t=1}^{T}\\left\\langle g^{t},p^{t}-p\\right\\rangle\\right\\}\\leq\\frac{\\log(|\\Pi|)}{\\eta}+\\eta\\sum_{t=1}^{T}\\sum_{\\pi\\in\\Pi}p^{t}(\\pi)g^{t}(\\pi)^{2}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "1.3  Reinforcement Learning ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "The following is standard simulation lemma which is first proposed by Abbeel and $\\mathrm{Ng}$ (2005). ", "page_idx": 47}, {"type": "text", "text": "Lemma I.6 (Simulation Lemma). For two finite-horizon MDPs $\\widehat{M}\\ =\\ \\{\\chi,\\mathcal{A},\\ell,\\{\\widehat{P}_{h}\\}_{h=1}^{H}\\}$ and $M=\\{\\mathcal{X},\\mathcal{A},\\ell,\\{P_{h}\\}_{h=1}^{H}\\}$ With horizon $H$ and $\\|\\ell\\|_{\\infty}\\leq1$ Let thecorrespondingvaluefunctionbe $\\widehat{V}_{h}^{\\pi}(x;\\ell)$ and $V_{h}^{\\pi}(x;\\ell)$ for step $h\\in[H]$ Foranypolicy $\\pi:{\\mathcal{X}}\\rightarrow\\Delta(A)$ we have ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\left|\\widehat{V}_{1}^{\\pi}(x_{1};\\ell)-V_{1}^{\\pi}(x_{1};\\ell)\\right|\\leq H\\sum_{h=1}^{H}\\mathbb{E}_{x,a\\sim d_{h}^{\\pi}}\\left[\\left\\|\\widehat{P}_{h}\\left(\\cdot\\,\\middle\\vert\\;x,a\\right)-P_{h}\\left(\\cdot\\,\\middle\\vert\\;x,a\\right)\\right\\|_{1}\\right].\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "The following is the standard performance difference lemma which is first proposed by Kakade and Langford (2002). ", "page_idx": 47}, {"type": "text", "text": "Lemma L7 Performance Diffrence Lmma). Fora fnite-horizonMDPs $M=\\{\\boldsymbol{\\mathcal{X}},\\boldsymbol{\\mathcal{A}},\\boldsymbol{\\ell},\\{P_{h}\\}_{h=1}^{H}\\}$ starting at $x_{1}$ ,and two policies $\\pi,\\pi^{\\prime}:\\mathcal{X}\\to\\Delta(\\mathcal{A})$ wehave ", "page_idx": 47}, {"type": "equation", "text": "$$\nV_{1}^{\\pi^{\\prime}}(x_{1};\\ell)-V_{1}^{\\pi}(x_{1};\\ell)=\\sum_{h=1}^{H}\\mathbb{E}_{x\\sim d_{h}^{\\pi}}\\left[\\sum_{a\\in A}\\left(\\pi_{h}^{\\prime}(a|x)-\\pi_{h}(a|x)\\right)Q_{h}^{\\pi^{\\prime}}(x,a;\\ell)\\right]\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 48}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 You should answer [Yes] , [No] , or [NA] .   \n\u00b7 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u00b7 Please provide a short (1-2 sentence) justification right after your answer (even for NA). ", "page_idx": 48}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with thepaper. ", "page_idx": 48}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g.,\"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 48}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] . ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Justification: The main claims made in the abstract and introductio accurately reflect the paper's contributions and scope. The claims are validated by detailed proofs. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 48}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 48}, {"type": "text", "text": "Justification: The paper discuss the limitations of the work in the discussion section. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper. ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should refect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 49}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] . ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Justification: The paper provides detailed assumptions and proofs. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 49}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 49}, {"type": "text", "text": "Justification: This is a theoretical paper. Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. ", "page_idx": 50}, {"type": "text", "text": "\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 50}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 50}, {"type": "text", "text": "", "page_idx": 51}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 51}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 51}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 51}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 51}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 52}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 52}, {"type": "text", "text": "Justification: This paper does not include experiments ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 52}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 52}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 52}, {"type": "text", "text": "Justification: The research conducted in the paper conforms, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 52}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 52}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 52}, {"type": "text", "text": "Justification: This is a theoretical work. There is no societal impact of the work performed. ", "page_idx": 52}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 52}, {"type": "text", "text": "\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 53}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 53}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 53}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 53}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 53}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 53}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 53}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 54}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 54}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 54}, {"type": "text", "text": "Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 54}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 54}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 54}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 54}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 54}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 54}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution. ", "page_idx": 54}, {"type": "text", "text": "\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 55}]