[{"figure_path": "muYhNDlxWc/figures/figures_1_1.jpg", "caption": "Figure 1: Non-invertible generative models (a), e.g., CVAE, GAN, and diffusions, lack the invertibility for probability density estimation. Flow-based methods (b) are invertible while, sampling from the symmetric standard Gaussian, undermines the diversity and controllability of generation. Our proposed Mixed Gaussian flow (c) maps from a mixed Gaussian prior instead. Summarizing distributions from data and controllable edits, it achieves better diversity and controllability for trajectory prediction.", "description": "This figure compares three different generative models for trajectory prediction. (a) shows a non-invertible model which cannot estimate probability density. (b) shows a flow-based model that uses a standard Gaussian prior, which limits diversity and controllability. (c) shows the proposed Mixed Gaussian Flow (MGF), which uses a mixed Gaussian prior to improve diversity and controllability.", "section": "3 Method"}, {"figure_path": "muYhNDlxWc/figures/figures_3_1.jpg", "caption": "Figure 2: The illustration of our proposed Mixed Gaussian Flow (MGF). During training, we construct a mixed Gaussian prior by statistics from the training set. During sampling, the initial noise samples are from the constructed mixed Gaussian prior. MGF keeps a tractable prior distribution and an invertible inference process while the novel mixed Gaussian prior provides more diversity and controllability to the generation outcomes.", "description": "This figure illustrates the Mixed Gaussian Flow (MGF) model.  The left side shows the process of constructing the mixed Gaussian prior. The training data is preprocessed, clustered into groups representing different motion patterns, and used to fit a mixture of Gaussian distributions, creating a multi-modal prior that reflects the diversity of movements in the training data. The right side shows the flow prediction process, where the history encoder takes historical trajectory observations as input. This information is used, along with a sample from the mixed Gaussian prior, by the flow model (a series of CIF layers). This model transforms the sample into a prediction of future trajectories. The model architecture enables both diversity of predictions (from the mixed Gaussian prior) and controllability (due to the prior's parametric nature and invertible inference).", "section": "3 Method"}, {"figure_path": "muYhNDlxWc/figures/figures_5_1.jpg", "caption": "Figure 2: The illustration of our proposed Mixed Gaussian Flow (MGF). During training, we construct a mixed Gaussian prior by statistics from the training set. During sampling, the initial noise samples are from the constructed mixed Gaussian prior. MGF keeps a tractable prior distribution and an invertible inference process while the novel mixed Gaussian prior provides more diversity and controllability to the generation outcomes.", "description": "This figure illustrates the Mixed Gaussian Flow (MGF) model architecture.  During training, the model learns a mixed Gaussian prior distribution from the training data by clustering trajectory patterns. This prior represents the diverse movement patterns of agents. During inference, samples are drawn from this mixed Gaussian prior, and then passed through a normalizing flow model. The normalizing flow model maps the samples from the simple mixed Gaussian prior to the complex distribution of possible future trajectories. The invertibility of the normalizing flow allows for probability density estimation, making the model more controllable. The model incorporates history information through an encoder. The overall design allows for diverse and controllable trajectory generation, improving the quality of probabilistic trajectory prediction.", "section": "3 Method"}, {"figure_path": "muYhNDlxWc/figures/figures_8_1.jpg", "caption": "Figure 4: MGF predictions on ETH dataset. The color of trajectories corresponds to the cluster in the mixed Gaussian prior, from which the sample belongs to.", "description": "This figure demonstrates the diversity of trajectory predictions generated by the Mixed Gaussian Flow (MGF) model on the ETH dataset.  Each set of predictions originates from a specific past trajectory (black dotted line) and its corresponding ground truth future trajectory (black solid line with stars). The various colored lines represent the different predicted trajectories generated by MGF. The color of a prediction corresponds to the cluster in the mixed Gaussian prior from which its initial noise sample was drawn. The figure visually shows that MGF produces diverse predictions based on the clusters within the mixed Gaussian prior, covering various possible future trajectories.", "section": "4.3 Diverse Generation"}, {"figure_path": "muYhNDlxWc/figures/figures_17_1.jpg", "caption": "Figure 6: By adding augmented data along with their corresponding clusters into the construction of the mixed Gaussian prior, we could manipulate the generation patterns as we desire. For example, we could inject some under-represented trajectory patterns. Then the model can generate corner cases that existing models fail to generate in a reasonable probability. We selected three examples from the UNIV dataset, namely sharp left/right turns and U-turns. The left column shows the predictions from FlowChain, while the middle column shows the predictions of MGF with augmented priors", "description": "This figure demonstrates how data augmentation affects trajectory prediction.  The leftmost column shows predictions using the FlowChain model, showing limited diversity and accuracy for complex trajectories. The middle column presents results from the Augmented-MGF model, which utilizes a mixed Gaussian prior generated from augmented data. This approach significantly improves prediction diversity and accuracy for difficult scenarios.  The rightmost column illustrates how adding clusters of augmented data helps generate more diverse and accurate predictions, especially for complex maneuvers like U-turns and sharp turns. Each row represents a different scenario.  The numerical values under each column indicate ADE/FDE scores.", "section": "4.3 Diverse Generation"}]