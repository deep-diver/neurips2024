[{"figure_path": "TZ5k9IYBBf/figures/figures_0_1.jpg", "caption": "Figure 1: Our primary analysis in this work is ablating the deep feature extractor (bottom center) by replacing it with a random projection (top center) to isolate the effect of online continual representation learning in the deep network. RanDumb (top) maps raw pixels to a high-dimensional space using random Fourier projections (4), then decorrelates the features using the Mahalanobis distance [43] and classifies based on the nearest class mean. We demonstrate that random projections not only match but consistently outperform continually learned representations, highlighting the low quality of the learned representations.", "description": "This figure compares a standard deep learning model for continual learning with RanDumb, a novel approach proposed in the paper. The standard model consists of a deep convolutional neural network that learns representations and classifiers simultaneously.  In contrast, RanDumb uses a fixed, random transformation to project the input pixels into a high-dimensional space. It then decorrelates the features and uses a simple nearest class mean classifier. The figure highlights the surprising finding that the simple RanDumb model outperforms the complex deep learning model, suggesting that continually learning representations may not be as effective as previously thought.", "section": "Abstract"}, {"figure_path": "TZ5k9IYBBf/figures/figures_2_1.jpg", "caption": "Figure 2: RanDumb projects the datapoints to a high-dimensional space to create a clearer separation between classes. Subsequently, it corrects the anisotropy across feature dimensions, scaling them to be unit variance each. This allows cosine similarity to accurately separates classes. The figure is adapted from [48].", "description": "This figure shows how RanDumb improves class separation.  It starts with data points in a low-dimensional space where classes overlap (Input).  RanDumb projects these points into a high-dimensional space using a random projection, resulting in better separation (Embed). Then, it decorrelates the features by scaling each dimension to have unit variance (Decorrelate), which further enhances the separation of classes, enabling more accurate classification using simple nearest class mean methods (Output). The 3D view provides a visual representation of the data in both the original and transformed spaces, illustrating how the process improves class separability. ", "section": "2 RanDumb: Mechanism & Intuitions"}, {"figure_path": "TZ5k9IYBBf/figures/figures_7_1.jpg", "caption": "Figure 1: Our primary analysis in this work is ablating the deep feature extractor (bottom center) by replacing it with a random projection (top center) to isolate the effect of online continual representation learning in the deep network. RanDumb (top) maps raw pixels to a high-dimensional space using random Fourier projections (4), then decorrelates the features using the Mahalanobis distance [43] and classifies based on the nearest class mean. We demonstrate that random projections not only match but consistently outperform continually learned representations, highlighting the low quality of the learned representations.", "description": "This figure illustrates the core concept of the RanDumb method and compares it to traditional online continual learning methods.  It shows how RanDumb replaces a deep feature extractor with a random projection, which projects raw image pixels into a high-dimensional space using random Fourier projections. Then, it decorrelates the features and classifies based on the nearest class mean. The figure highlights that this simple method surprisingly outperforms the continually learned representations of deep networks.", "section": "Abstract"}, {"figure_path": "TZ5k9IYBBf/figures/figures_8_1.jpg", "caption": "Figure 1: Our primary analysis in this work is ablating the deep feature extractor (bottom center) by replacing it with a random projection (top center) to isolate the effect of online continual representation learning in the deep network. RanDumb (top) maps raw pixels to a high-dimensional space using random Fourier projections (4), then decorrelates the features using the Mahalanobis distance [43] and classifies based on the nearest class mean. We demonstrate that random projections not only match but consistently outperform continually learned representations, highlighting the low quality of the learned representations.", "description": "This figure compares a standard deep learning architecture with RanDumb.  The standard architecture uses a deep feature extractor to learn representations and a classifier to learn the model.  RanDumb replaces the deep feature extractor with a random projection, highlighting that the representation learned by the deep feature extractor is not superior to a simple random projection.  The comparison demonstrates that random projection outperforms standard continual learning approaches.", "section": "Abstract"}]