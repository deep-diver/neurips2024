[{"figure_path": "zBG7WogAvm/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of BED workflows. (a) Traditional BED, which iterates between optimizing designs, running experiments, and updating the model via Bayesian inference. (b) Amortized BED, which uses a policy network for rapid experimental design generation. (c) Our decision-aware amortized BED integrates decision utility in training to facilitate downstream decision-making.", "description": "This figure compares three Bayesian Experimental Design (BED) workflows: Traditional BED, Amortized BED, and the authors' proposed Decision-aware Amortized BED.  Traditional BED involves iterative optimization, experimentation, and Bayesian inference. Amortized BED streamlines this with a policy network for quick design generation.  The authors' approach further improves upon Amortized BED by integrating downstream decision utility into the training process, leading to more effective decision-making.", "section": "1 Introduction"}, {"figure_path": "zBG7WogAvm/figures/figures_5_1.jpg", "caption": "Figure 2: Illustration of TNDP. (a) An overview of TNDP architecture with input consisting of 2 observed design-outcome pairs from D(c), 2 designs from D(P) for prediction, and 2 candidate designs from D(q) for query. (b) The corresponding attention mask. The colored squares indicate that the elements on the left can attend to the elements on the top in the self-attention layer of ftfm.", "description": "This figure illustrates the architecture of the Transformer Neural Decision Process (TNDP).  Panel (a) shows a high-level overview of the model's components: a data embedding block, a transformer block, a prediction head, and a query head.  The different input sets (context, prediction, and query) are highlighted, along with the global information. Panel (b) depicts the attention mask used within the transformer block, showing which parts of the input can attend to each other during processing. The colors in the mask indicate the permitted connections within the self-attention mechanism.", "section": "4.1 Transformer Neural Decision Processes"}, {"figure_path": "zBG7WogAvm/figures/figures_7_1.jpg", "caption": "Figure 3: Results of synthetic regression and decision-aware active learning. (a) The top figure represents the true function and the initial known points. The red line indicates the location of x*. The blue star marks the next query point, sampled from the policy\u2019s predicted distribution shown in the bottom figure. (b) Mean and standard error of the proportion of correct decisions on 100 test points w.r.t. the acquisition steps. Our TNDP significantly outperforms other methods.", "description": "This figure shows the results of two experiments: 1D synthetic regression and decision-aware active learning.  The top panel (a) illustrates the 1D synthetic regression. It shows the true underlying function (black line), the initial known data points (magenta crosses), the target point (red dashed line), and the next point selected for querying by the model (blue star). The bottom panel displays the probability distribution over the next point to be queried, with the highest probability density around the target point. The second panel (b) displays the results of the decision-aware active learning. It shows that the proposed TNDP method outperforms other algorithms in terms of decision accuracy over 100 test points.", "section": "6 Experiments"}, {"figure_path": "zBG7WogAvm/figures/figures_7_2.jpg", "caption": "Figure 3: Results of synthetic regression and decision-aware active learning. (a) The top figure represents the true function and the initial known points. The red line indicates the location of x*. The blue star marks the next query point, sampled from the policy\u2019s predicted distribution shown in the bottom figure. (b) Mean and standard error of the proportion of correct decisions on 100 test points w.r.t. the acquisition steps. Our TNDP significantly outperforms other methods.", "description": "This figure shows the results of two experiments: 1D synthetic regression and decision-aware active learning.  The synthetic regression experiment (a) illustrates how the model selects informative query points to approximate an unknown function, showing the true function, initial data points, and the next query point selected by the model. The decision-aware active learning experiment (b) compares the performance of TNDP to other methods on a 100-point test set across different acquisition steps, demonstrating TNDP's superior performance in making accurate decisions.", "section": "6 Experiments"}, {"figure_path": "zBG7WogAvm/figures/figures_8_1.jpg", "caption": "Figure 4: Results on Top-k HPO task. For each meta-dataset, we calculated the average utility across all available test sets. The error bars represent the standard deviation over five runs. TNDP consistently achieved the best performance in terms of utility.", "description": "The figure shows the results of the Top-k hyperparameter optimization (HPO) experiments.  Four different meta-datasets (ranger, rpart, svm, xgboost) are used, with the average utility across all test sets being calculated for each. Error bars represent the standard deviation across five runs. The results demonstrate that TNDP consistently outperforms other methods in terms of utility.", "section": "6.3 Top-k hyperparameter optimization"}, {"figure_path": "zBG7WogAvm/figures/figures_16_1.jpg", "caption": "Figure 3: Results of synthetic regression and decision-aware active learning. (a) The top figure represents the true function and the initial known points. The red line indicates the location of x*. The blue star marks the next query point, sampled from the policy\u2019s predicted distribution shown in the bottom figure. (b) Mean and standard error of the proportion of correct decisions on 100 test points w.r.t. the acquisition steps. Our TNDP significantly outperforms other methods.", "description": "This figure shows the results of two experiments: 1D synthetic regression and decision-aware active learning. The synthetic regression experiment demonstrates how the TNDP model selects informative query points to accurately predict the value at a target point. The decision-aware active learning experiment compares the performance of the TNDP model against other methods in a classification task, highlighting its superior performance in terms of the proportion of correct decisions.", "section": "6 Experiments"}, {"figure_path": "zBG7WogAvm/figures/figures_18_1.jpg", "caption": "Figure A2: Results of retrosynthesis planning experiment. The utility is the sum of the quality scores of top-k routes and is calculated with 50 molecules. Our TNDP outperforms the random search baseline.", "description": "This figure shows the results of a retrosynthesis planning experiment.  The task was to identify the top-k synthetic routes for a novel molecule using a decision-aware amortized Bayesian experimental design framework called TNDP.  The results compare the TNDP approach to a random search baseline, showing that TNDP achieved significantly higher utility (sum of quality scores for the top-k routes) across 10 design steps. The error bars represent standard deviation across 50 test molecules. This demonstrates the effectiveness of TNDP in guiding the design process toward better decision-making outcomes.", "section": "G.3 Additional experiment on retrosynthesis planning"}]