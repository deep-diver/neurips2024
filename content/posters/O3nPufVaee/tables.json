[{"figure_path": "O3nPufVaee/tables/tables_4_1.jpg", "caption": "Table 1: PSNR(dB)/SSIM results on SIDD benchmark, DND benchmark and NIND dataset. We report the official results from the benchmarks' websites whenever possible. The results of Zhou et al.are quoted from [27]. The results of Noise2Void and Noise2Self are quoted from [45]. The results of DnCNN and Laine et al.are obtained by code re-running. Bold denotes the best results in clean-image-free methods.", "description": "This table presents a comparison of the performance of various image denoising methods on three benchmark datasets: SIDD, DND, and NIND.  The methods are categorized into supervised, unsupervised, zero-shot, and self-supervised approaches.  The table shows PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index) scores for each method and dataset. The best performing methods that do not use clean images are highlighted in bold.", "section": "4.2 Performance Evaluation on Real-world Denoising"}, {"figure_path": "O3nPufVaee/tables/tables_7_1.jpg", "caption": "Table 1: PSNR(dB)/SSIM results on SIDD benchmark, DND benchmark and NIND dataset. We report the official results from the benchmarks' websites whenever possible. The results of Zhou et al.are quoted from [27]. The results of Noise2Void and Noise2Self are quoted from [45]. The results of DnCNN and Laine et al.are obtained by code re-running. Bold denotes the best results in clean-image-free methods.", "description": "This table presents a comparison of the performance of various image denoising methods on three benchmark datasets: SIDD, DND, and NIND.  The methods are categorized into several groups based on their training approach (supervised with synthetic or real pairs, unsupervised, zero-shot, and self-supervised) and whether they require clean images during training.  The performance is measured using PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index). The table highlights the best-performing methods that do not use clean images during training, demonstrating the effectiveness of self-supervised approaches.", "section": "4.2 Performance Evaluation on Real-world Denoising"}, {"figure_path": "O3nPufVaee/tables/tables_7_2.jpg", "caption": "Table 2: Computational complexity comparison in terms of model size and inference time.", "description": "This table compares the computational complexity of different self-supervised denoising methods in terms of model size (number of parameters) and inference time for a 256x256 image.  It shows that SelfFormer-F has a smaller model size and significantly faster inference time compared to other transformer-based methods (LG-BPN and SS-BSN). It also shows that SelfFormer-F is comparable to the best-performing CNN-based method (PUCA) in terms of performance while being much faster.", "section": "4 Experiments"}, {"figure_path": "O3nPufVaee/tables/tables_9_1.jpg", "caption": "Table 3: PSNR(dB)/SSIM results of ablation studies on SIDD-Validation.", "description": "This table presents the results of ablation studies conducted on the SIDD-Validation dataset to evaluate the impact of different components of the proposed SelfFormer model.  The base model's performance is compared against versions where key components like Directional Self-Attention (DSA), Channel Attention (CA), and the Siamese architecture are removed or replaced.  This allows for assessing the individual contribution of each part to the overall denoising performance.", "section": "4.3 Ablation Studies"}, {"figure_path": "O3nPufVaee/tables/tables_9_2.jpg", "caption": "Table 4: Results with varying grid sizes and loss function weights on SIDD-Validation", "description": "This table presents the ablation study results on the SIDD-Validation dataset.  It shows the impact of varying the grid size used in the directional self-attention (DSA) and grid self-attention (Grid SA) modules, and the impact of varying the loss function weight (lambda) in the overall loss function (Ltotal = Lself + lambda*Lmutual).  The results demonstrate how different grid sizes and loss weights affect the model's performance measured by PSNR and SSIM.", "section": "4 Experiments"}, {"figure_path": "O3nPufVaee/tables/tables_15_1.jpg", "caption": "Table A1: Quantitative results of self-supervised methods on SIDD-Validation.", "description": "This table presents a comparison of the performance of various self-supervised image denoising methods on the SIDD-Validation dataset.  The metrics used for comparison are PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index).  The methods compared include Noise2Void (N2V), Recorrupted2Recorrupted (R2R), CVF-SID, AP-BSN, LG-BPN, SASL, PUCA, C-BSN, and the proposed SelfFormer method.  Higher PSNR and SSIM values indicate better denoising performance.", "section": "A.2 Additional Results"}, {"figure_path": "O3nPufVaee/tables/tables_15_2.jpg", "caption": "Table 2: Computational complexity comparison in terms of model size and inference time.", "description": "This table presents a comparison of the computational complexity among different image denoising methods.  It specifically contrasts the model size (number of parameters) and inference time for a 256x256 image across various CNN-based and transformer-based approaches.  This allows for a quantitative assessment of the efficiency and resource requirements of each method.", "section": "4 Experiments"}]