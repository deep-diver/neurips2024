[{"figure_path": "Nmmiyjw7Xg/figures/figures_7_1.jpg", "caption": "Figure 1: Top: Marginal error vs. iteration number for different algorithms on three datasets. Bottom: Marginal error vs. run time. The cost matrix is based on the l\u2081-distance, and \u03b7 = 0.01.", "description": "This figure compares the performance of five different algorithms (BCD, APDAGD, Dual L-BFGS, Newton, and SSNS) for solving entropic-regularized optimal transport problems on three benchmark datasets: MNIST, Fashion-MNIST, and ImageNet.  The top row shows the convergence of the algorithms in terms of marginal error against the number of iterations. The bottom row shows the same convergence, but instead plots the marginal error against the runtime. The cost matrix is based on the l1-distance, and the regularization parameter is set to \u03b7 = 0.01. The figure demonstrates that the second-order methods (Newton and SSNS) converge faster than first-order methods (BCD and APDAGD), and the SSNS algorithm is more computationally efficient than the Newton method due to its sparsification scheme.", "section": "5 Numerical Experiments"}, {"figure_path": "Nmmiyjw7Xg/figures/figures_8_1.jpg", "caption": "Figure 1: Top: Marginal error vs. iteration number for different algorithms on three datasets. Bottom: Marginal error vs. run time. The cost matrix is based on the l\u2081-distance, and \u03b7 = 0.01.", "description": "This figure compares the performance of several optimization algorithms (BCD, APDAGD, Dual L-BFGS, Newton, and SSNS) on three benchmark datasets (MNIST, FashionMNIST, and ImageNet).  The top row shows the marginal error over the number of iterations, while the bottom row presents the marginal error against run time. The cost matrix is calculated using the l\u2081-distance, and the regularization parameter \u03b7 is set to 0.01. The results demonstrate that second-order methods (Newton and SSNS) achieve faster convergence than first-order and quasi-Newton methods.", "section": "5 Numerical Experiments"}, {"figure_path": "Nmmiyjw7Xg/figures/figures_9_1.jpg", "caption": "Figure 1: Top: Marginal error vs. iteration number for different algorithms on three datasets. Bottom: Marginal error vs. run time. The cost matrix is based on the l\u2081-distance, and \u03b7 = 0.01.", "description": "This figure compares the performance of several optimal transport (OT) algorithms across three datasets: MNIST, FashionMNIST, and ImageNet.  The top row shows the log10 of the marginal error plotted against the number of iterations for each algorithm. The bottom row shows the same log10 marginal error plotted against the runtime in seconds.  The cost matrix used is based on the l1-distance, and the regularization parameter (\u03b7) is set to 0.01.  Algorithms compared include BCD (Sinkhorn), APDAGD, Dual L-BFGS, Newton, and the proposed SSNS method. The results demonstrate that the second-order methods (Newton and SSNS) converge significantly faster in terms of iterations, but that SSNS has a runtime advantage over the standard Newton method due to its use of sparse matrices.", "section": "Numerical Experiments"}, {"figure_path": "Nmmiyjw7Xg/figures/figures_9_2.jpg", "caption": "Figure 1: Top: Marginal error vs. iteration number for different algorithms on three datasets. Bottom: Marginal error vs. run time. The cost matrix is based on the l\u2081-distance, and \u03b7 = 0.01.", "description": "This figure compares the performance of five different algorithms for solving entropic-regularized optimal transport (OT) problems on three benchmark datasets: MNIST, Fashion-MNIST, and ImageNet.  The top row shows the log10 of the marginal error plotted against the number of iterations for each algorithm.  The bottom row shows the same log10 marginal error, but plotted against the run time in seconds. The cost matrix used is based on the l\u2081-distance, and the regularization parameter \u03b7 is set to 0.01.  The algorithms compared are BCD (Sinkhorn), APDAGD, dual L-BFGS, Newton, and the authors' proposed SSNS algorithm. The figure demonstrates that SSNS converges significantly faster than first-order methods while offering competitive run time compared to the vanilla Newton method. ", "section": "5 Numerical Experiments"}, {"figure_path": "Nmmiyjw7Xg/figures/figures_13_1.jpg", "caption": "Figure 1: Top: Marginal error vs. iteration number for different algorithms on three datasets. Bottom: Marginal error vs. run time. The cost matrix is based on the l\u2081-distance, and \u03b7 = 0.01.", "description": "This figure compares the performance of five different algorithms (BCD, APDAGD, Dual L-BFGS, Newton, and SSNS) for solving entropic-regularized optimal transport problems on three datasets (MNIST, Fashion-MNIST, and ImageNet).  The top row shows the logarithmic marginal error against the iteration number, while the bottom row displays the logarithmic marginal error against the runtime in seconds.  The cost matrix is computed using the l\u2081-distance, and the regularization parameter \u03b7 is set to 0.01.  The results demonstrate that second-order methods (Newton and SSNS) converge much faster than first-order methods but that the SSNS method is superior in runtime performance due to its efficient sparsification techniques.", "section": "5 Numerical Experiments"}, {"figure_path": "Nmmiyjw7Xg/figures/figures_14_1.jpg", "caption": "Figure 1: Top: Marginal error vs. iteration number for different algorithms on three datasets. Bottom: Marginal error vs. run time. The cost matrix is based on the l\u2081-distance, and \u03b7 = 0.01.", "description": "This figure compares the performance of several optimization algorithms (BCD, APDAGD, Dual L-BFGS, Newton, and SSNS) for solving entropic-regularized optimal transport problems. The top row shows the convergence behavior in terms of marginal error against the number of iterations, while the bottom row shows the run time performance. The cost matrix is based on the l1-distance, and the regularization parameter is set to \u03b7 = 0.01. The datasets used are MNIST, FashionMNIST, and ImageNet.", "section": "5 Numerical Experiments"}, {"figure_path": "Nmmiyjw7Xg/figures/figures_14_2.jpg", "caption": "Figure 2: Top: Marginal error vs. iteration number for different algorithms on three datasets. Bottom: Marginal error vs. run time. The cost matrix is based on the l\u2081-distance, and \u03b7 = 0.001.", "description": "This figure compares the performance of five different algorithms (BCD, APDAGD, Dual L-BFGS, Newton, and SSNS) for solving entropic-regularized optimal transport problems on three datasets (MNIST, FashionMNIST, and ImageNet).  The top row shows the marginal error plotted against the iteration number, while the bottom row shows the marginal error against the run time. The cost matrix is based on the l\u2081-distance, and the regularization parameter \u03b7 is set to 0.001.  The results demonstrate the superior performance of SSNS, especially in terms of run time.", "section": "Numerical Experiments"}]