[{"figure_path": "wlcm21C4nk/tables/tables_7_1.jpg", "caption": "Table 1: Performance on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS. Results are averaged over three runs of experiments, except for single crop evaluations on ImageNet. Models marked with (*) employ scaled weight standardization, adapting to normalizer-free architectures.", "description": "This table presents a comparison of the proposed rate-based backpropagation method with other state-of-the-art SNN training methods across four benchmark datasets: CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS.  The results show the top-1 accuracy achieved by each method on various network architectures with different numbers of timesteps.  It highlights the comparable or superior performance of the proposed method while using less computational resources.", "section": "5 Experiments"}, {"figure_path": "wlcm21C4nk/tables/tables_8_1.jpg", "caption": "Table 1: Performance on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS. Results are averaged over three runs of experiments, except for single crop evaluations on ImageNet. Models marked with (*) employ scaled weight standardization, adapting to normalizer-free architectures.", "description": "This table presents a comparison of the proposed rate-based backpropagation method against several state-of-the-art SNN training methods across four benchmark datasets: CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS.  The table shows the top-1 accuracy achieved by each method on each dataset, along with the model architecture and number of timesteps used. Note that some methods use scaled weight standardization (*).", "section": "5 Experiments"}, {"figure_path": "wlcm21C4nk/tables/tables_19_1.jpg", "caption": "Table 1: Performance on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS. Results are averaged over three runs of experiments, except for single crop evaluations on ImageNet. Models marked with (*) employ scaled weight standardization, adapting to normalizer-free architectures.", "description": "This table compares the performance of the proposed rate-based backpropagation method against several state-of-the-art SNN training methods across four benchmark datasets: CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS.  The table shows the top-1 accuracy achieved by each method using different network architectures (ResNet-18, ResNet-19, VGG-11) and various numbers of timesteps. It highlights the comparable or superior performance of the proposed method.", "section": "5 Experiments"}, {"figure_path": "wlcm21C4nk/tables/tables_20_1.jpg", "caption": "Table 1: Performance on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS. Results are averaged over three runs of experiments, except for single crop evaluations on ImageNet. Models marked with (*) employ scaled weight standardization, adapting to normalizer-free architectures.", "description": "This table presents the classification accuracy results of different deep spiking neural network (SNN) training methods on four benchmark datasets: CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS.  The table compares the performance of the proposed rate-based backpropagation methods ('rates' and 'ratem') against several state-of-the-art SNN training techniques, including BPTT (standard and modified versions), OTTT, SLTT, and OS. The results show the top-1 accuracy achieved by each method on each dataset.  Note that some methods use scaled weight standardization (*) to adapt to normalizer-free architectures.", "section": "5 Experiments"}, {"figure_path": "wlcm21C4nk/tables/tables_21_1.jpg", "caption": "Table 1: Performance on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS. Results are averaged over three runs of experiments, except for single crop evaluations on ImageNet. Models marked with (*) employ scaled weight standardization, adapting to normalizer-free architectures.", "description": "This table presents a comparison of the Top-1 accuracy achieved by different SNN training methods (including the proposed rate-based backpropagation) on four benchmark datasets: CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS.  The results are averaged across three independent runs for most experiments, except for ImageNet (single crop). Some models use scaled weight standardization to work with normalizer-free architectures. The table allows readers to compare the performance of the proposed method against state-of-the-art SNN training techniques.", "section": "5 Experiments"}, {"figure_path": "wlcm21C4nk/tables/tables_22_1.jpg", "caption": "Table 1: Performance on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS. Results are averaged over three runs of experiments, except for single crop evaluations on ImageNet. Models marked with (*) employ scaled weight standardization, adapting to normalizer-free architectures.", "description": "This table presents the top-1 accuracy results achieved by different SNN training methods (including the proposed rate-based backpropagation) on four benchmark datasets: CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS.  It compares the performance of the proposed method to several state-of-the-art efficient training techniques and the standard BPTT training method on various network architectures. Note that some models use scaled weight standardization.", "section": "5 Experiments"}]