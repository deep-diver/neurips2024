[{"figure_path": "rafVvthuxD/figures/figures_2_1.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = g\u03b8(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of the MCMC correction on generated images. The left columns show the initial generated images from the student model, while the right columns show the images after 300 steps of MCMC sampling.  Subfigure (a) demonstrates the correction on ImageNet images; (b) shows the correction in the Stable Diffusion embedding space; and (c) shows the decoded images from (b) in the image space. The results highlight how MCMC sampling improves image quality and disentangles objects.", "section": "3.2 Reparametrized sampling and noise cancellation"}, {"figure_path": "rafVvthuxD/figures/figures_4_1.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = g\u03b8(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of the MCMC correction process on image generation.  The left side shows images generated before correction (x = g\u03b8(z)), while the right side depicts the same images after 300 steps of MCMC sampling, which corrects off-manifold artifacts and improves image quality. The comparison highlights the correction process on ImageNet and in the Stable Diffusion embedding space. The improved clarity and disentanglement of objects (like cats and a sofa) in the corrected images are clearly visible.", "section": "Method"}, {"figure_path": "rafVvthuxD/figures/figures_6_1.jpg", "caption": "Figure 3: (a)(b) Gradient norms and FIDs for complete noise cancellation, last-step noise cancellation and no noise cancellation. (c) (d) FIDs and Recalls of EMD with different numbers of Langevin steps.", "description": "This figure shows the effects of noise cancellation and the number of Langevin steps on the performance of the EM distillation method. (a) compares the gradient norms during training with different noise cancellation strategies. (b) shows the FID scores for the same strategies. (c) and (d) show the FID and Recall scores, respectively, as a function of the number of Langevin steps used.", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_8_1.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by the one-step generator model trained on the ImageNet dataset. The model is trained in a class-conditional manner, meaning it is trained to generate images belonging to specific classes.  The figure displays multiple generated images for different classes (multi-class) and showcases examples from single classes to demonstrate that the model can capture a variety of modes (different features and styles within a class) and avoid mode collapse (where the model only produces a limited range of similar outputs).", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_8_2.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator trained using the proposed EM distillation method. The model was trained on the ImageNet dataset, conditioned on different classes.  The images demonstrate the model's ability to generate high-quality images that capture diverse characteristics of the object classes. The single-class samples (c) are particularly important to show that the model captures various modes within each class rather than concentrating on just one typical representation. ", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_17_1.jpg", "caption": "Figure 6: Initial denoiser generation with different \u03bb*.", "description": "This figure shows the initial denoiser generation at the 0th training iteration for different values of \u03bb*.  When \u03bb* = 0, the generated images are pure Gaussian noise. As \u03bb* decreases to -6 and then -10, the generated images become progressively more structured and less noisy, demonstrating the effect of the hyperparameter \u03bb* on the initial state of the generation process.  This hyperparameter is used in the EM Distillation method.", "section": "3.2 Reparametrized sampling and noise cancellation"}, {"figure_path": "rafVvthuxD/figures/figures_18_1.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator trained using the proposed EM Distillation method on the ImageNet dataset.  The images are organized into three sections: (a) multi-class ImageNet 64x64, (b) multi-class ImageNet 128x128, and (c) single-class ImageNet 128x128. The single-class section (c) specifically demonstrates that the model can generate diverse samples within a single class, showcasing its ability to capture the distribution effectively. The images illustrate the quality and diversity of images generated by the one-step model, highlighting the efficacy of the proposed approach.", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_18_2.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator model trained using the EM Distillation method.  The model was trained on the ImageNet dataset, with separate sections for multi-class and single-class generation. The single-class section is intended to highlight that the model avoids mode collapse and can generate diverse samples within a single class.", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_18_3.jpg", "caption": "Figure 7: Additional qualitative results for ImageNet", "description": "This figure shows additional samples generated by the EMD model on ImageNet 64x64 and ImageNet 128x128 datasets.  The samples demonstrate the model's ability to generate diverse and high-quality images, showcasing its performance in various classes and scenarios.  The single-class images (c) highlight the model's ability to generate good mode coverage, which addresses a common limitation of mode-seeking divergence found in some one-step generation methods. This emphasizes the capability of EMD in capturing the full distribution of the data.", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_19_1.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = go(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of MCMC correction on generated images using EM distillation. The left column displays samples generated before correction (x = g\u03b8(z)), while the right shows results after 300 MCMC steps jointly on data (x) and latent variables (z).  Subfigure (a) illustrates ImageNet corrections, highlighting improvements in off-manifold samples.  (b) shows the correction in the Stable Diffusion embedding space and (c) the decoded image space, emphasizing the disentanglement of image features and improved sharpness.", "section": "3 Method"}, {"figure_path": "rafVvthuxD/figures/figures_20_1.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = go(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of the MCMC correction process on image generation. The left columns of (a) and (b) show images generated by the student model before MCMC correction, while the right columns show the images after 300 MCMC steps jointly sampling data and latent variables. (a) demonstrates the correction on ImageNet, showing that the off-manifold images are corrected. (b) shows the correction in the Stable Diffusion v1.5 embedding space, which are decoded to the image space in (c). The disentanglement of objects and improved sharpness highlight the effectiveness of MCMC correction.", "section": "3 Method"}, {"figure_path": "rafVvthuxD/figures/figures_21_1.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = g\u03b8(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of the MCMC correction method used in the paper. The left columns display images generated directly by the model (x = g\u03b8(z)).  After 300 MCMC steps jointly sampling x and z, the right columns show the improved, corrected images.  Subfigure (a) demonstrates the correction on ImageNet, showing how off-manifold images are brought onto the data manifold.  Subfigure (b) presents the correction within the embedding space of Stable Diffusion v1.5, and (c) shows the corresponding decoded images.  The result highlights improved image quality (e.g. sharpness of sofa) and disentanglement (e.g., improved distinction between cat and sofa).", "section": "3.2 Reparametrized sampling and noise cancellation"}, {"figure_path": "rafVvthuxD/figures/figures_22_1.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = g\u03b8(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of the MCMC correction process in the paper's EM Distillation method.  The left columns of (a) and (b) display images generated by the student model before MCMC correction, showing artifacts or deviations from the target distribution. After 300 MCMC steps, the images (right columns) show improved quality, demonstrating the correction's ability to refine the samples and align them more closely with the teacher model's distribution.", "section": "3 Method"}, {"figure_path": "rafVvthuxD/figures/figures_23_1.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator trained using the proposed EM Distillation method.  The model was trained on ImageNet, using a class-conditional approach. The figure displays image samples from multiple classes to illustrate the model's ability to generate diverse images.  A separate set of single-class samples is also shown to demonstrate the model's ability to capture the distinct modes within each class.", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_23_2.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator model trained using the EM Distillation method. The model was trained on the ImageNet dataset.  The top row shows multi-class samples, demonstrating the model's ability to generate diverse images from various classes.  The bottom row shows single-class samples from the same model, highlighting its capacity to generate high-quality images consistent within each specific class, emphasizing the quality and mode coverage achieved by the model.", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_23_3.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator trained using the EM distillation method on the ImageNet dataset.  The top row displays multi-class samples (multiple classes of images from the ImageNet dataset). The bottom row focuses on single-class samples to highlight the model's ability to generate diverse images within a specific class.  This visually demonstrates that the model successfully captures the distribution of the dataset and does not suffer from mode collapse (where it only produces images of a few specific types).", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_23_4.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = go(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of the MCMC correction process in the EM Distillation method.  It compares samples before and after 300 steps of MCMC sampling. Subfigure (a) demonstrates the correction of off-manifold images from ImageNet. Subfigure (b) shows the correction in the embedding space of Stable Diffusion v1.5, and subfigure (c) displays the decoded images.  The improved disentanglement and sharpness in the corrected images highlight the effectiveness of the method.", "section": "3.2 Reparametrized sampling and noise cancellation"}, {"figure_path": "rafVvthuxD/figures/figures_24_1.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator trained using the EM distillation method proposed in the paper. The model was trained on the ImageNet dataset, and the images are organized into three subfigures (a,b,c). (a) shows samples from the multi-class ImageNet 64x64 dataset, (b) shows samples from the multi-class ImageNet 128x128 dataset, and (c) shows samples from the single-class ImageNet 128x128 dataset. The single-class samples are used to demonstrate that the model is able to generate diverse samples that are not simply repetitions of a single mode. The figure provides visual evidence of the strong performance of the proposed EM distillation method for generating high-quality, diverse samples.", "section": "5.1 ImageNet"}, {"figure_path": "rafVvthuxD/figures/figures_24_2.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = go(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure shows the effect of MCMC correction on generated images.  The left columns display initial samples from the student generator, while the right columns show the improved samples after 300 steps of MCMC sampling, jointly optimizing for both data and latent variables. The improvement is visible across different scenarios, including ImageNet and Stable Diffusion. The correction leads to sharper images and better disentanglement of features.", "section": "3 Method"}, {"figure_path": "rafVvthuxD/figures/figures_24_3.jpg", "caption": "Figure 1: Before and after MCMC correction. In (a)(b), the left columns are x = g\u03b8(z), the right columns are updated x after 300 steps of MCMC sampling jointly on x and z. (a) illustrates the effect of correction in ImageNet. Note that the off-manifold images are corrected. (b) illustrates the correction in the embedding space of Stable Diffusion v1.5, which are decoded to image space in (c). Note the disentanglement of the cats and sharpness of the sofa. Zoom in for better viewing.", "description": "This figure demonstrates the effect of the MCMC correction process on generated images.  The left columns show initial images generated by the student model (x = g\u03b8(z)), while the right columns show the images after 300 MCMC steps which jointly correct the data (x) and latent (z) variables.  The top row shows results from the ImageNet dataset, highlighting how the correction pulls off-manifold images back onto the data manifold.  The second and third rows depict the correction process within the embedding and image spaces of Stable Diffusion v1.5 respectively, showcasing improvements in detail (e.g., sharpness and disentanglement of objects).", "section": "3.2 Reparametrized sampling and noise cancellation"}, {"figure_path": "rafVvthuxD/figures/figures_24_4.jpg", "caption": "Figure 4: ImageNet samples from the distilled 1-step generator. Models are trained class-conditionally with all classes. We provide single-class samples in (c) to demonstrate good mode coverage.", "description": "This figure shows samples generated by a one-step generator trained using the EM distillation method on the ImageNet dataset.  The models were trained using class-conditional generation, meaning that each model was trained to generate images from a specific class. The figure showcases the quality and diversity of the generated images, with a subfigure (c) specifically highlighting the model's ability to generate diverse examples within a single class.", "section": "5.1 ImageNet"}]