{"references": [{"fullname_first_author": "L. Chizat", "paper_title": "Implicit bias of gradient descent for wide two-layer neural networks trained with the logistic loss", "publication_date": "2020-00-00", "reason": "This paper is foundational in establishing the implicit bias of gradient descent in neural networks, which is a core concept in understanding the paper's analysis of adversarial robustness."}, {"fullname_first_author": "S. Bubeck", "paper_title": "A single gradient step finds adversarial examples on random two-layers neural networks", "publication_date": "2021-00-00", "reason": "This paper provides crucial theoretical analysis of adversarial examples in shallow neural networks, directly relevant to the paper's focus on the interaction of layers in relation to adversarial robustness."}, {"fullname_first_author": "A. Daniely", "paper_title": "Most relu networks suffer from l2 adversarial perturbations", "publication_date": "2020-00-00", "reason": "This paper addresses the vulnerability of ReLU networks to adversarial attacks, forming a critical base for understanding the limitations and challenges in achieving adversarial robustness, aligning with the core topic of the paper."}, {"fullname_first_author": "E. Dohmatob", "paper_title": "On the (non-) robustness of two-layer neural networks in different learning regimes", "publication_date": "2022-00-00", "reason": "This paper investigates the robustness of two-layer neural networks, offering insights into the factors affecting adversarial robustness, which the main paper extends to multilayer networks."}, {"fullname_first_author": "S. Frei", "paper_title": "The double-edged sword of implicit bias: Generalization vs. robustness in relu networks", "publication_date": "2023-00-00", "reason": "This paper directly addresses the trade-off between generalization and adversarial robustness, a central theme explored and expanded upon by the main paper in the context of multilayer network interactions."}]}