[{"type": "text", "text": "FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Evelyn Ma, Chao Pan, Rasoul Etesami, Han Zhao, Olgica Milenkovic ", "page_idx": 0}, {"type": "text", "text": "University of Illinois Urbana-Champaign {pingm, chaopan2, etesami1, hanzhao, milenkov}@illinois.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The performance of Transfer Learning (TL) significantly depends on effective pretraining, which not only requires extensive amounts of data but also substantial computational resources. As a result, in practice, it is challenging to successfully perform TL at the level of individual model developers. Federated Learning (FL) addresses these challenges by enabling collaborations among individual clients through an indirect expansion of the available dataset, distribution of the computational across different clients, and privacy-preserving communication mechanisms. Despite several attempts to design effective transferable FL approaches, several important issues remain unsolved. First, existing methods primarily focus on optimizing transferability within local client domains, thereby ignoring transferability across clients. Second, most approaches focus on analyzing indirect transferability metrics, which does not allow for accurate assessment of the final target loss and the degree of transferability. To address these issues, we introduce two important FL features into the model. The first boosts transferability via an exchange protocol between the clients and the server that includes information about cross-client Jacobian (gradient) norms. The second feature promotes an increase of the average of the Jacobians of the clients at the server side, which is subsequently used as a local regularizer that reduces the cross-client Jacobian variance. A rigorous analysis of our transferable federated algorithm, termed FedGTST (Federated Global Transferability via Statistics Tuning), reveals that increasing the averaged Jacobian norm across clients and reducing the Jacobian variance ensures tight control of the target loss. This insight leads to an upper bound on the target loss of transferable FL regarding the source loss and source-target domain discrepancy. Empirically, experiments on public benchmarks show that FedGTST significantly outperforms other baselines, such as FedSR. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Transfer Learning (TL) has received significant interest in the machine learning community due to its ability to extract representative features from source tasks and use them to improve the generalization capability on related target domain problems [48, 52]. In addition to boosting the performance of a target domain model, TL also reduces the computational cost of fine-tuning the target domain model. Nevertheless, effective source pretraining in TL is practically challenging for individual model developers because it requires access to large datasets as well as significant computational resources [35]. To resolve this problem, one can leverage Federated Learning (FL), which refers to decentralized learning protocols used in mobile and IoT devices [18]. FL not only increases access to multiple datasets in a decentralized manner and alleviates the computational burden of individual clients, but it also protects the privacy of local data [32]. As a result, a number of recent works have outlined methods for transferable FL, including FedADG (Federated Adversarial Domain Generalization) [55], FedCDG (Federated Contrastive Domain Generalization) [53], FedSR (Federated Simple Representations) [34], FedIIR (Federated Implicit Invariant Relationships) [12], FedCCST (Federated Cross-Client Style Transfer) [4], FedMM (Federated Adversarial Domain Adaptation) [42] and StableFDG (Stable Federated Domain Generalization) [36]. Despite the promising preliminary findings provided by the techniques above, several combinations of important issues remain unsolved across the spectrum of methods. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "For privacy leakage, the limitations of existing methods include: 1. FedADG forces each client source domain to align its representation distribution with that of the target domain, and therefore violates data privacy because source domains are given access to the target domain in order to perform the alignment; 2. FedCCST boosts global transferability by increasing local diversity to avoid local overfitting. It therefore requires clients to share their local representations with each other and this information is subsequently used for local data augmentation. This is a direct violation of FL privacy constraints; 3. StableFDG expands local data diversity by sharing style statistics (i.e., representations, including means and variances). This clearly leads to the leakage of local privacy-sensitive information. ", "page_idx": 1}, {"type": "text", "text": "For local overfitting, the shortcomings of a group of the methods above are as follows: 1. FedSR learns a simple representation through regularization during local training, by exploiting the similarity between the representation and the data, given the labels. However, since the regularized local training relies completely on local structures (i.e., local models, representations, labels, data), it leads to overfitting of local distributions, and thus has limited capability to learn cross-client invariant features, which is key for global transferability; 2. FedCDG uses a contrastive local regularizer on representations generated by various samples within the same class. This leads to overfitting in the local domain since no cross-client information is exploited. ", "page_idx": 1}, {"type": "text", "text": "For communication complexity, we observe that: 1. FedIIR is suboptimal. Although it mitigates the problem of privacy violation and avoids local overfitting by adding a local regularizer capturing the distance between the local gradient and the global gradient, it requires communicating gradients between the clients and the server and therefore doubles the communication cost compared to baselines (additionally, FedIIR performs well for a large number of clients, but offers average performance when this number is small); 2. Similar communication complexity problems are faced by FedCCST and StableFDG, which rely on communicating styles (i.e., representations); 3. FedMM requires significant communication overhead for adaptation using distribution-matching techniques [58], which involves solving an intractable non-convex-non-concave optimization problem [56]. ", "page_idx": 1}, {"type": "text", "text": "Finally, prior works mostly lack explicit theoretical analyses of global transferability: they do not tend to quantify the performance/loss of the pretrained model fine-tuned on the target domain. ", "page_idx": 1}, {"type": "text", "text": "In summary, perhaps the most important unresolved problem with known transferable FL models (with the exception of FedIIR) is that they use centralized TL approaches during local training, and do not fully exploit features specific to federated learning (for details, see also the discussion in Section 2). ", "page_idx": 1}, {"type": "text", "text": "Our contributions. We describe what is, to the best of our knowledge, the first approach to federated transfer learning termed Federated Global Transferability via Statistics Tuning (FedGTST) that simultaneously alleviates the above issues faced by existing methods. Our main contributions can be summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "1. We use a new regularizer that encodes cross-client statistics and forces the local training process to tune the global statistics in a \u201cdirection\u201d that improves global transferability rather than just local transferability. This is achieved through subtractions of global norms of Jacobians (gradients) communicated by the server.   \n2. We suggest to only communicate scalars, more precisely, Jacobian norms, which introduces a negligible communication overhead in the overall model exchange protocol.   \n3. We ensure that our communication schemes do not allow uncontrolled access to data and thereby ensure data privacy.   \n4. We rigorously prove that even though only small discrepancies among local gradients may exist upon regularization, transferability can be low as regularization can impede the growth of the gradient norm. To boost the Jacobian norm, we implement specialized protocols at both the client and server levels. Finally, we establish relevant bounds on the transferability loss for this setting. ", "page_idx": 1}, {"type": "text", "text": "The main technical insights provided by our analysis are as follows. Two FL-specific factors, a small cross-client Jacobian variance and larger cross-client Jacobian norm are indicative of good transferability. These factors are direct performance indicators, unlike indirect factors (e.g., feature invariance) which only suggest improved transferability. Our findings are based on the first direct measure of transferability, which equals the loss on the target domain incurred by the pretrained federated model. The FL-specific factors govern the bounds on the loss and therefore allow one to control them for better transferability. We validate these findings through extensive experiments which show that FedGTST outperforms methods such as FedSR and FedIIR by as much as $10\\%$ . ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "FL is a machine learning paradigm in which multiple entities collaborate to train a global model without sharing their local data (see [15] for a comprehensive review). FL has gained significant attention due to its potential to address privacy concerns while enabling large-scale collaborative learning [44]. Relevant to this work, [32] proposed the Federated Averaging (FedAvg) algorithm, which aggregates model updates from multiple client devices to train a global model. Another relevant line of work [51] introduced FedProx, a federated optimization algorithm that incorporates proximal terms to handle non-iid data distributions. FL methods nevertheless still face several challenges. One challenge is dealing with highly heterogeneous local datasets [26] , for which the recent work FedImpro[46] proposed leveraging aggregated feature distributions to address client drift. Another challenge is the communication overhead incurred during the aggregation of model updates [2]. Minimizing communication costs while ensuring convergence and data privacy remain active topics of research in FL. Also, many FL solutions primarily emphasize performance in the client domain without considering the performance of the model on unseen domains. ", "page_idx": 2}, {"type": "text", "text": "TL is a powerful machine learning technique that allows models to leverage knowledge gained from one task to improve performance on another related task [35]. TL has been widely adopted in various domains such as computer vision, natural language processing, and speech recognition, where labeled data may be scarce or expensive to acquire [47, 48]. A common approach in TL involves fine-tuning a pre-trained model on a target task using a small amount of labeled data, which often leads to improved generalization and faster convergence compared to training from scratch [52]. Recent works in TL have focused on developing more effective algorithms, such as domain adaptation methods that address the discrepancy between the source and target domains [11]. Additionally, TL techniques have been used to handle tasks with limited amounts of labeled data through techniques like semi-supervised and self-supervised learning [40]. TL still faces challenges such as negative transfer, where information from the source task actually degrades performance on the target task; and, it requires careful selecting of appropriate pretrained models and transfer strategies for specific tasks and domains [35]. Current TL methods often require that one entity possesses knowledge of all data, violating the privacy requirements of FL. Moreover, we comment on Gradient Matching in TL in Appendix I.1 ", "page_idx": 2}, {"type": "text", "text": "Transferable Federated Learning (TFL) is an emerging research area at the intersection of FL and TL. One of earliest contributions to the field, FedADG [55], encourages the transferablity of FL through adversarial local training. However, the work does not provide theoretical guarantees, and existing studies [50] indicate that adversarial robustness does not necessarily lead to better transferability. Other methods, such as FedSR [34] and FedCDG [53], enhance transferability by adapting standard representation learning from a single-agent to a federated setting; they do not incorporate FL-specific features (i.e., instructions provided by the server, cross-client model properties etc). Note that although FedSR has successfully included centralized invariant feature learning into FL, it uses centralized methods locally and then shares information with the global model, and thereby does not fully exploiting FL capabilities. Thus, using FedSR, each client can learn very different representations that are hard to aggregate at the central server. More precisely, FedSR does not communicating information that can help improve the transferability of the global model. Among all the previously discussed methods (FedADG, FedCDG, FedSR, FedIIR, FedCCST, and StableFDG), FedIIR is the closest to our approach and may be seen as a special case of our method which has better performance, smaller communication complexity and comes with provable global transferability guarantees. Furthermore, we discuss the distinctions and connections between TFL and Generalization of FL, a topic potentially relevant to TFL, in Appendix I.2. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "General Supervised Learning Settings. We denote the data space by $\\mathcal{X}$ , the feature space by $\\mathcal{Z}$ , and the label space by $\\boldsymbol{\\wp}$ . A model $h:\\mathcal{X}\\to\\mathcal{Y}$ typically takes the form $h=g\\circ f$ , where $f:\\mathcal{X}\\to\\mathcal{Z}$ is a feature extractor and $g:\\mathcal{Z}\\to\\mathcal{Y}$ is a classifier. Denote the function class for the entire model, the feature extractor and the classifier by $\\mathcal{H},\\mathcal{F},\\mathcal{G}$ , respectively, so that $h\\in\\mathcal{H},f\\in\\mathcal{F},g\\in\\mathcal{G}$ . Denote the weights of model $\\psi\\,\\in\\,\\{f,g,h\\}$ as $w_{\\psi}$ . Given a loss function $l:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\mathbb{R}$ and a domain distribution $\\mathcal{D}$ over $\\mathcal X\\times\\mathcal X$ , the population loss $L_{\\mathcal{D}}(h)$ is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}}(h):=\\mathbb{E}_{(x,y)\\sim\\mathcal{D}}\\emph{l}(h(x),y)\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "General Framework of TFL. In TL, the two typical learning phases are: a) pretraining on the source domain; and, b) finetuning on the target domain. In the context of TFL, pretraining is conducted via FL over source (local) domains, while the global model is trained and then finetuned on the target domain during the second phase. In both phases, supervised learning is performed with full access to the labels. More details are provided next. ", "page_idx": 3}, {"type": "text", "text": "Pretraining Phase in TFL: FL on Source (Local) Domains. The source domain is a composition of the agents\u2019 local domains, $\\{\\mathcal{D}^{(k)}\\}$ , with $k\\in[K]$ denoting the client index and $K$ representing the total number of clients. The source loss is defined as the standard federated loss on the source domains. ", "page_idx": 3}, {"type": "equation", "text": "$$\nL_{s r c}(g\\circ f):=\\frac{1}{K}\\sum_{k=1}^{K}L_{\\mathcal{D}^{(k)}}(g\\circ f).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Let $h^{*}=g^{*}\\circ f^{*}$ be an optimal global solution for the objective (2). In $\\mathrm{FL}$ approaches, the problem solution is the result of the central server\u2019s aggregation of local models into a global one. We denote the local solutions involved in creating the optimal global solution $\\psi^{*}$ $\\rangle^{*}\\,\\,(\\psi\\in\\{f,g,h\\})$ by $\\{\\psi^{*(k)}\\}$ ; through averaging aggregation, we obtain the optimal global weights $\\begin{array}{r}{w_{\\psi}^{*}=\\frac{1}{K}\\sum_{k}w_{\\psi}^{*(k)}}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Finetuning Phase in TFL: Supervised Finetuning on the Target Domain. Upon obtaining the optimal pretrained global solution $h^{*}=g^{*}\\circ f^{*}$ , the pretrained feature extractor $f^{*}$ is fixed and applied to the target domain $\\mathcal{D}_{T}$ . The target loss is defined as the loss on the target domain $\\mathcal{D}_{T}$ , i.e., ", "page_idx": 3}, {"type": "equation", "text": "$$\nL_{t g t}(g\\circ f^{*}):=L_{\\mathcal{D}_{T}}(g\\circ f^{*}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Through finetuning, a new classifier $g_{T}^{*}:=\\arg\\operatorname*{inf}_{g\\in\\mathcal{G}}L_{t g t}(g\\circ f^{*})$ is determined by minimizing the target objective (3). ", "page_idx": 3}, {"type": "text", "text": "Transferability Assessment. With a slight abuse of notation, we define the optimal target loss as ", "page_idx": 3}, {"type": "equation", "text": "$$\nL_{t g t}^{*}:=L_{t g t}(g_{T}^{*}\\circ f^{*}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We formally define the measure of transferability of $T F L$ as the optimal target loss $L_{t a t}^{*}$ , as it directly reflects the performance of a transferable model on the target domain. A smaller Lt\u2217gt, or a tighter bound on it, indicates better transferability. ", "page_idx": 3}, {"type": "text", "text": "4 Theoretical Bounds on the Target Loss ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "4.1 A General Bound Based on Discrepancy/Divergence ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We start with Definitions 1 and 2 borrowed from existing TL studies that characterize the domain discrepancy, and then propose a new domain divergence tailored to Transferable FL (TFL), including the cross-client discrepancy in Definition 2 and the source-target discrepancy in Definition 3. ", "page_idx": 3}, {"type": "text", "text": "Definition 1 ( ${\\mathcal{G}},{\\mathcal{F}}$ -discrepancy [50]). Given a classifier class $\\mathcal{G}$ , a feature extractor class $\\mathcal{F}$ , the source domain $\\mathcal{D}_{S}$ and the target domain $\\mathcal{D}_{T}$ , with a slight abuse of notation, the $(\\mathcal{G},\\mathcal{F})$ -discrepancy is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\nd_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S},\\mathcal{D}_{T}):=\\operatorname*{sup}_{f\\in\\mathcal{F}}\\left|\\operatorname*{inf}_{g\\in\\mathcal{G}}L_{\\mathcal{D}^{(k)}}(g\\circ f)-\\operatorname*{inf}_{g\\in\\mathcal{G}}L_{\\mathcal{D}_{T}}(g\\circ f)\\right|.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Remark. The ${\\mathcal{G}},{\\mathcal{F}}$ -discrepancy has also been used in the analysis of domain adaptation [50]. ", "page_idx": 3}, {"type": "text", "text": "We next adapt the $\\mathcal{H}$ -discrepancy to measure the cross-client domain discrepancy in transferable FL (Definition 2), and tailor the ${\\mathcal{G}},{\\mathcal{F}}$ -discrepancy (Definition 1) to measure the source\u2013target discrepancy in TFL (Definition 3). ", "page_idx": 3}, {"type": "text", "text": "Definition 2 (Cross-Client Divengence for TFL). Given a model class $\\mathcal{H}$ and federated local domains ${\\mathcal{D}_{S}^{f e d}=\\{\\mathcal{D}^{(k)}\\}_{k\\in[K]}}$ , with $d\\varkappa(\\cdot,\\cdot)$ defined as Definition 5, the intra-client discrepancy is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\overline{{{d}}}_{\\mathcal{H}}(\\mathcal{D}_{S}^{f e d}):=\\frac{1}{K(K-1)}\\sum_{k_{1}\\neq k_{2}}d_{\\mathcal{H}}\\left(\\mathcal{D}_{S}^{(k_{1})},\\mathcal{D}_{S}^{(k_{2})}\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that $\\overline{{d}}_{\\mathcal{H}}(\\mathcal{D}_{S})$ equals the average of $\\mathcal{H}$ -discrepancies over all local domain pairs and therefore measures the intra-discrepancy on the non-iid distributed source domains. When source domains are iid across clients, we have $\\overline{{d}}_{\\mathcal{H}}(\\mathcal{D}_{S})=0$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 3 (Source-Target Discrepancy for TFL). Given a classifier class $\\mathcal{G}$ , a feature extractor class $\\mathcal{F}$ , federated local domains $\\mathcal{D}_{S}^{f e d}=\\{\\mathcal{D}^{(k)}\\}_{k\\in[K]}$ , and the target domain $\\mathcal{D}_{T}$ , with slight abuse of notation, the federated $(\\mathcal{G},\\mathcal{F})$ -discrepancy is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\nd_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}):=\\frac{1}{K}\\sum_{k\\in[K]}d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}^{(k)},\\mathcal{D}_{T}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Based on the two TFL-specific domain discrepancy definitions (i.e., Definition 2 and 3), we derive a general bound on the TFL loss in Theorem 1. The TFL-specific source-target discrepancy (Definition 3) is further used in Theorem 2 which presents a bound on the target loss using cross-client statistics. For our theoretical analyses, we need the following common assumptions. ", "page_idx": 4}, {"type": "text", "text": "Assumption 4.1 (Convexity and Smoothness). We assume that the loss function $l$ satisfies two conditions: (1) l is convex w.r.t. $w_{h}$ ; (2) l is Lipschitz smooth for $w_{h}$ with a constant $\\alpha>0$ . ", "page_idx": 4}, {"type": "text", "text": "Remark. Assumption 4.1 is easy to meet in practice, and it arises in many linear models (linear regression, SVM etc). ", "page_idx": 4}, {"type": "text", "text": "Theorem 1 (Bound Based on TFL-specific Domain Discrepancy). Under Assumptions 4.1 (Convexity and Smoothness), the optimal target loss is bounded as ", "page_idx": 4}, {"type": "equation", "text": "$$\nL_{t g t}^{*}\\leq\\frac{1}{K}\\sum_{k=1}^{K}\\Big[L_{\\mathcal{D}^{(k)}}\\left(h^{*(k)}\\right)\\Big]+\\overline{{d}}_{\\mathcal{H}}(\\mathcal{D}_{S}^{f e d})+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $h^{*(k)}$ denotes the optimal local model of client $k$ (see Section 3). ", "page_idx": 4}, {"type": "text", "text": "Semantic Interpretation. In Theorem 1 , the optimal target loss $L_{t g t}^{*}$ is bounded by the sum of three terms on the RHS of Equation 7: (1) the averaged optimal local loss $\\begin{array}{r}{\\frac{1}{K}\\sum_{k=1}^{K}\\left[L_{{\\mathcal{D}}^{(k)}}\\left(h^{*(k)}\\right)\\right]}\\end{array}$ ; (2) the intra-discrepancy of the source domain $\\overline{{d}}_{\\mathcal{H}}(\\mathcal{D}_{S}^{f e d})$ ; (3) the discrepancy between the source and target domains, $d\\mathcal{G},\\!\\mathcal{F}\\big(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}\\big)$ . Therefore, the bound on the optimal target loss can be tightened by making the optimal source loss smaller, and by lowering the intra-source and source-target discrepancy. The later two terms can be controlled through regularization as detailed below. ", "page_idx": 4}, {"type": "text", "text": "Tightening the Bound via Regularization over ${\\mathcal F}.$ . Given two feature extractor function classes ${\\mathcal{F}}_{1}$ and ${\\mathcal{F}}_{2}$ , if $\\mathcal{F}_{1}\\subset\\mathcal{F}_{2}$ , we have $\\mathscr{H}_{1}\\,\\subset\\,\\mathscr{H}_{2}$ where $\\mathcal{H}_{1}\\,=\\,\\mathcal{G}\\,\\times\\,\\mathcal{F}_{1}$ and $\\mathcal{H}_{2}\\,=\\,\\mathcal{G}\\,\\times\\,\\mathcal{F}_{2}$ . From Definition 2 and 3, it is straightforward to see that $\\overline{{d}}_{\\mathcal{H}_{1}}(\\mathcal{D}_{S}^{f e d})\\leq\\overline{{d}}_{\\mathcal{H}_{2}}(\\mathcal{D}_{S}^{f e d})$ and $d_{\\mathcal{G},\\mathcal{F}_{1}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T})\\leq$ $d\\mathcal{G},\\mathcal{F}_{2}\\big(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}\\big)$ . This indicates that any general regularizer on $\\mathcal{F}$ can lead to a decrease in the latter two terms of the RHS of Theorem 1. However, shrinking the expressive power of $\\mathcal{F}$ will inevitably increase the optimal source loss, which is the first term on the RHS of the expression in Theorem 1. Therefore, using general regularization, one has to trade-off the optimal source loss, TFL-specific cross-client discrepancy, and TFL-specific source-target discrepancy. ", "page_idx": 4}, {"type": "text", "text": "Based on Theorem 1 and the follow-up discussion, we aim to answer the question: how should one design a practical regularizer that can inherently tighten our bound on TFL? We give an answer to this question in Section 4.2. There, Theorem 2 shows that a transferability-boosting pretraining regularization should decrease the cross-client Jacobian variance while at the same time increase the cross-client averaged Jacobian norm. ", "page_idx": 4}, {"type": "text", "text": "4.2 Practical Bounds Based on Cross-Client Statistics ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The goal of $\\mathrm{FL}$ is to estimate the optimal solution $f^{*}$ by updating the global model through multiple federated rounds 1. Denote the total number of rounds by $P$ and the output global model after round $P$ by $f_{P}$ . Denote the target loss under $f_{P}$ instead of $f^{*}$ as $\\widehat{L}_{t g t}^{*}$ (which is an estimate of $L_{t g t.}^{*}$ ). At the end of local training during any round $p\\leq P$ , let $h_{p}^{(k)}$ with weight $w_{p}^{(k)}$ represent the model of client , and let $h_{p}$ with weight $w_{p}$ represent the global model. Denote the Jacobian (gradient) of the loss w.r.t the model weights at domain $k$ as $J^{(k)}(w)=\\mathbb{E}_{\\mathcal{D}_{S}^{(k)}}\\nabla_{w_{h}}l(h(x),y)|_{w_{h}=w}.$ ", "page_idx": 5}, {"type": "text", "text": "Throughout the remainder of the manuscript, we use $J_{p}^{(k)}$ as shorthand for $J^{(k)}\\left(w_{p}\\right)$ . Furthermore, we denote the learning rate of agent $k$ at round $p$ by $\\lambda_{p}^{(k)}$ . We make a single-step local update assumption (Assumption 4.2) and use the definitions for cross-client statistics (Definition 4) to derive bounds exploiting the cross-client statistics from Lemma 4.1 and Theorem 2). ", "page_idx": 5}, {"type": "text", "text": "Assumption 4.2 (Single-Step Local Update). During local training, all clients perform one step of gradient descent $(G D)$ to update their model for transmission, = wp \u2212\u03bb(pk+)1 \u00b7 J(k)(wp). This is a common assumption in the FL literature $[30,32]$ . 2 ", "page_idx": 5}, {"type": "text", "text": "Definition 4 (Cross-Client Statistics). At federated round $p$ , given $K$ clients with local Jacobians $\\{J_{p}^{(k)}\\}_{k\\in[K]}$ , pwecet idveefliyn,e  atshe cross-client averaged Jacobian norm $\\|J_{p}\\|_{2}$ and the cross-client Jacobian ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|J_{p}\\|_{2}=\\left\\|\\frac{1}{K}\\sum_{k}J_{p}^{(k)}\\right\\|_{2},\\;\\;\\mathrm{and}\\;\\;\\sigma_{p}^{2}=\\frac{1}{K}\\sum_{k}\\left\\|J_{p}^{(k)}\\right\\|_{2}^{2}-\\left\\|\\frac{1}{K}\\sum_{k}J_{p}^{(k)}\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that we assumed the loss function to have a $\\alpha$ -Lipschitz continuous gradient. When the gradient is large, $\\alpha$ is also large, and to make $\\beta_{1}(\\lambda)\\geq0$ , $\\lambda$ has to be close to 0. In this case, the absolute value of the second term can be small and that of the third term can be large. ", "page_idx": 5}, {"type": "text", "text": "Lemma 4.1 (Loss Bound Using Cross-Client Statistics). Under Assumptions 4.2 and 4.1, and the cross-client statistics defined in Definition 4, after $P$ rounds of federated pretraining one has ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widehat{L}_{t g t}^{*}\\leq L_{s r c}\\left(h_{0}\\right)-\\sum_{p=0}^{P-1}\\beta_{1}(\\lambda_{p+1})\\|J_{p}\\|_{2}^{2}+\\sum_{p=0}^{P-1}\\beta_{2}(\\lambda_{p+1})\\sigma_{p}^{2}+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $h_{0}$ is the initial global model and $\\begin{array}{r}{\\beta_{2}(\\lambda)=\\frac{\\alpha\\lambda^{2}}{2}}\\end{array}$ , $\\beta_{1}(\\lambda)=\\lambda-\\beta_{2}(\\lambda)$ . ", "page_idx": 5}, {"type": "text", "text": "Note that during the training process, a large Jacobian norm can promote transferability (the Jacobian is expected to be small at the end of training). ", "page_idx": 5}, {"type": "text", "text": "Interpretation of Key Terms. Lemma 4.1 shows that the target loss of the finetuned pretrained model (LHS) is bounded by a sum (RHS) involving four key terms: 1) $L_{s r c}(h_{0})$ , the initial source loss; 2) $\\|J_{p}\\|_{2}$ , the cross-client averaged Jacobian norm; 3) $\\bar{\\sigma}_{p}^{2}$ , the cross-client Jacobian variance; 4) $d\\mathcal{G},\\!\\mathcal{F}\\big(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}\\big)$ , the TFL-specific source-target domain divergence. Since $L_{s r c}(h_{0})$ is fixed throughout the pretraining process, and dG,F(DfSed, DT ) can be reduced using general regularization, we focus on analyzing the two tunable cross-client statistics, $\\|J_{p}\\|_{2}$ and $\\sigma_{p}^{2}$ . ", "page_idx": 5}, {"type": "text", "text": "Influence of the Cross-Client Statistics on the Bound. We note that during pretraining, both the coefficients $\\beta_{1}(\\lambda_{p+1})$ and $\\beta_{2}(\\lambda_{p+1})$ have to be positive (see how to ensure these constraints in Appendix D). Therefore, a larger $\\|J_{p}\\|_{2}$ and a smaller $\\sigma_{p}^{2}$ tighten the upper bound, indicate a lower target loss, and thus suggest better model transferability. ", "page_idx": 5}, {"type": "text", "text": "Coefficients Quadratic w.r.t. the Learning Rates. Lemma 4.1 involves coefficients $\\beta_{1}(\\lambda)$ and $\\beta_{2}(\\lambda)$ that are quadratic in the learning rate $\\lambda$ ; thus, we can further tighten the bound by optimizing the learning rates across different rounds (Assumption 4.3). The tightened bound is given in Theorem 2. ", "page_idx": 5}, {"type": "text", "text": "Assumption 4.3 (Optimal Learning Rates Across Rounds). In each round $p$ $2\\leq p\\leq P_{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!}$ ), we use an optimal learning rate for local training $\\begin{array}{r}{\\lambda_{p}^{*}=\\frac{K\\cdot\\|J_{p-1}\\|_{2}^{2}}{\\alpha\\cdot\\sum_{k}\\|J_{p-1}^{(k)}\\|_{2}^{2}}}\\end{array}$ . $A$ similar analysis and assumptions on optimal learning rate has also been used in [7, 10, 13, 30, 49]. ", "page_idx": 6}, {"type": "text", "text": "Theorem 2 (Tightened Bound Based on Cross-Client Statistics). By optimizing the bound in Lemma 4.1 with respect to the learning rates $\\lambda$ as governed by Assumption 4.3, and under Assumption 4.1 (Convexity and Smoothness), the estimated optimal target loss is bounded as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widehat{L}_{t g t}^{*}\\leq L_{s r c}\\left(h_{0}\\right)-\\sum_{p=0}^{P-1}\\frac{2\\|J_{p}\\|_{2}^{2}}{\\alpha(1+\\sigma_{p}^{2}\\|J_{p}\\|_{2}^{-2})}+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Semantic Interpretation. Theorem 2 indicates that by optimizing the learning rates at each round, the bound for $\\widehat{L}_{t g t}^{*}$ can be made smaller through 1) a smaller source loss $L_{s r c}(h_{0})$ ; 2) a larger cross-client average Jacobian norm $\\|J_{p}\\|_{2};3)$ a smaller cross-client Jacobian variance $\\sigma_{p}^{2}$ , and 4) a smaller source-target domain divergence $d\\mathcal{G},\\!\\mathcal{F}\\big(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}\\big)$ . These are consistent with Lemma 4.1. ", "page_idx": 6}, {"type": "text", "text": "Intuitive Explanation. (a) Increasing the Cross-Client Averaged Jacobian Norm $\\|J_{p}\\|$ . In early training, it is crucial to avoid a small $J_{p}$ , as it can \u201ctrap\u201d clients in local minima or cause overfitting of local distributions. Note that increasing $J_{p}$ will not induce an excessively large second term (i.e., a term that $\\rightarrow\\infty$ ) in Theorem 2, as increments are constrained through the Lipschitz condition $\\|J_{1}-J_{2}\\|\\le\\alpha\\|x_{1}-x_{2}\\|$ . In the final stages of training, $\\|J_{p}\\|$ naturally decreases due to convergence. (b) Decreasing the Cross-Client Jacobian Variance $\\sigma_{p}$ . A small $\\sigma_{p}$ promotes domain similarity, preventing local overfitting and enhancing global model transferability. (c) Trade-Off Between Increasing $\\|J_{p}\\|$ and Decreasing $\\sigma_{p}$ . A larger $\\|J_{p}\\|$ induces more substantial local updates but can increase variance $\\sigma_{p+1}$ . Thus, Theorem 2 underscores balancing this trade-off: enlarging $\\|J_{p}\\|$ while maintaining a small $\\sigma_{p}$ . ", "page_idx": 6}, {"type": "text", "text": "Challenges in Regularization of the Jacobians. Certain regularization of the Jacobians can induce local Jacobian alignment and reduce $\\sigma_{p}^{2}$ (e.g., the regularization of the alignment between local gradients and the global gradient proposed in FedIIR [12]). However, local regularization can naturally impede the growth of local Jacobian norms $\\{J_{p}^{(k)}\\}_{k\\in[K]}$ and subsequently prevent $\\|J_{p}\\|_{2}$ from increasing. Thus, such prior regularization may not necessarily improve transferability. As an example, consider the extreme case where $\\sigma_{p}^{2}=0$ . Then, the bound in Theorem 2 takes the form $\\begin{array}{r}{\\widehat{L}_{t g t}^{*}\\leq L_{s r c}\\left(h_{0}\\right)-\\sum_{p=0}^{P-1}\\frac{2}{\\alpha}\\|J_{p}\\|_{2}^{2}+d_{\\mathcal{G},\\mathcal{F}}(\\dot{\\mathcal{D}}_{S}^{f e d},\\mathcal{D}_{T})}\\end{array}$ , where a small $\\|J_{p}\\|_{2}$ can severely degrade the bound. This indicates that boosting transferability by prior regularization, such as controlling $\\sigma_{p}^{2}$ itself, has limitations, and tuning $\\|J_{p}\\|$ during the pretraining stage is of crucial importance. We provide a solution to this problem in Section 5. ", "page_idx": 6}, {"type": "text", "text": "5 Our Algorithm ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Algorithmic Solution for the Theoretical Challenges. From Lemma 4.1 and Theorem 2, we can see that certain round-wise FL-specific statistics, the cross-client averaged Jacobian norm $\\|J_{p}\\|_{2}$ and cross-client Jacobian variance $\\sigma_{p}^{2}$ control the bound on the target loss. The challenge is that, while $\\sigma_{p}^{2}$ can be reduced using straightforward techniques (i.e., such as gradient alignment from FedIIR [12]), such techniques unavoidably prevent $J_{p}$ from increasing properly. We therefore propose our FedGTST approach which reduces $\\sigma_{p}^{2}$ while enlarging $\\|J_{p}\\|_{2}$ . A round-wise description of FedGTST is given in Algorithm 5. ", "page_idx": 6}, {"type": "text", "text": "Tuning the Cross-Client Jacobian Variance $\\sigma_{p}^{2}$ . The cross-client Jacobian variance is controlled via regularization at the local client level (Line 5 of Algorithm 5). The local clients, upon receiving a guide norm $\\gamma$ from the server (explanation deferred to subsequent sections), implement a regularized local training protocol. While client $k$ during standard local training uses the objective $\\bar{L}_{\\ensuremath{\\mathcal{D}}^{(k)}}(h)$ , during regularized local training he/she/they use ", "page_idx": 6}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}_{S}^{(k)}}\\left(h\\right)+\\xi\\cdot\\left(\\|J^{(k)}(h)\\|_{2}-\\gamma\\right)^{2}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "instead, where $\\xi$ is the penalty coefficient for the regularization term. This type of regularization intuitively aligns each local Jacobian norm $\\|J^{(k)}\\|$ with the guide norm $\\gamma$ , which results in a $\\sigma_{J}^{2}$ that is smaller than that of standard FL (i.e., FedAVG). ", "page_idx": 6}, {"type": "text", "text": "1: Randomly select a set $\\phi\\subset[K]$ for regular training.   \n2: while $k\\leq K$ , Client $k$ should do   \n3: Receive the guide norm $\\gamma_{p-1}$ and global model $h_{p-1}$ from the server.   \n4: Initialize the local model to $h_{p-1}$ .   \n5: Update the local model to $h_{p}^{(k)}$ by training with $L_{\\mathcal{D}_{\\mathrm{c}}^{(k)}}\\left(h\\right)+\\xi\\cdot\\left(\\|J^{(k)}(h)\\|_{2}-\\gamma\\right)^{2}\\!.$   \n6: Calculate the surrogate Jacobian norm \u03b3p(k) $\\gamma_{p}^{(k)}=\\gamma_{p}^{r e g,(k)}=\\|J_{p}^{(k)}\\|_{2}$ .   \n7: if $k\\in\\phi$ then   \n8: Train with $L_{\\mathcal{D}^{(k)}}(h)$ to obtain Jacobian norm $\\gamma_{p}^{s t d,(k)}$   \n9: Update the surrogate Jacobian norm \u03b3p(k $\\gamma_{p}^{(k)}=\\operatorname*{max}\\left(\\gamma_{p}^{r e g,(k)},\\gamma_{p}^{s t d,(k)}\\right)$   \n1101:: eTnradn isfmit the model $h_{p}^{(k)}$ and norm $\\gamma_{p}^{(k)}$ to the server.   \n12: end while   \n13: The server aggregates the client models into a global model $h_{p}$ and sets the guide norm to   \n14: The server broadcasts \u03b3p = maxk(\u03b3p(k )). $h_{p}$ and $\\gamma_{p}$ to all clients. ", "page_idx": 7}, {"type": "text", "text": "Tuning the Cross-Client Averaged Jacobian Norm $\\|J_{p}\\|_{2}$ . The cross-client averaged Jacobian norm can be increased via an exchange protocol that includes: 1) clients calculating surrogate norms for transmission; 2) the server computing and broadcasting a guide norm; 3) clients performing local alignment using the guide norm. ", "page_idx": 7}, {"type": "text", "text": "Surrogate Norms. A decrease in the local Jacobian norm $\\|J^{(k)}\\|$ prevents the cross-client averaged Jacobian norm $\\|J\\|$ from growing. We mitigate such a decrease by forcing a small portion of the clients to implement both regularized training and standard training (Line 1), to generate a pair of Jacobian norms $\\gamma^{r e g,(k)}$ and $\\bar{\\gamma^{s t d,(k)}}$ . The client than chooses the larger norm, $\\gamma^{(k)}\\bar{=}\\,m a x(\\bar{\\gamma^{r e g,(k)}},\\gamma^{s t d,(k)})$ as a surrogate norm for transmission (Lines 6 to 10). ", "page_idx": 7}, {"type": "text", "text": "Server Guide Norm. The clients send their local Jacobian norms $\\gamma^{(k)}:=\\|J^{(k)}\\|_{2}$ to the server, and the server broadcasts the largest norm received as its guide norm $\\gamma:=\\operatorname*{max}_{k}\\gamma^{(k)}$ (Line 13). ", "page_idx": 7}, {"type": "text", "text": "Local alignment. The local regularizer from Equation (10) reduces the variance, but can also force an increase of the averaged Jacobian norm. It forces all local Jacobian norms to align with the guide norm $\\gamma$ (Line 5). Since $\\gamma$ has been boosted both at the clients\u2019 and server levels, the alignment leads to larger local Jacobian norms. ", "page_idx": 7}, {"type": "text", "text": "Communication Cost. Most TFL methods, as already described, require large communication overheads between the clients and the server. For example, FedIIR requires exchanging Jacobians, which have the same dimension as the model weights; FedGTST only requires exchanging norms. ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "6.1 Experimental Setting ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Transfer tasks. We investigate three transfer tasks utilizing fully-annotated data: a) MNIST [9] to MNIST-M [11], b) CIFAR-10 [19] to SVHN [33], and c) cross-domain transfer in DomainNet [37]. All transfer tasks have been used as benchmarks in existing TL research [3, 8, 11, 22, 28, 50] (also, see Appendix G). Moreover, DomainNet is a standard large-scale dataset for TFL studies, also used by FedSR. ", "page_idx": 7}, {"type": "text", "text": "Non-iid Distributed Source (Local) Domains. The pretraining phase is conducted via FL on source (local) domains. Marginal distribution shift is an important phenomenon in FL [27] since the access to classes (or categories) is not the same for all participating entities. However, some federated datasets tested by existing transferable FL methods do not reflect marginal distribution shifts when constructing source local domains (i.e., in the Rotated-MNIST benchmark in FedSR[34], all clients have access to all classes). To address this issue, we employ the following methods for constructing non-iid local domains: ", "page_idx": 7}, {"type": "text", "text": "\u2022 For MNIST or CIFAR-10, unless otherwise specified, we follow the approach in [27] and let each client have access to only a subset of the categories. The category selection rule and data sampling method is described in Appendix H. Besides, we run additional experiments for Dirichlet sampling, a method commonly used in FL [1, 20, 23, 24, 29, 45, 46, 54]. \u2022 For DomainNet, which compromises six distinct domains, we follow the leave-one-out strategy used in FedSR: one domain is designated as the target domain, while the remaining five domains serve as source domains, with each assigned to an individual client. ", "page_idx": 8}, {"type": "text", "text": "Federated System Size. Large system sizes are inherent to FL systems, where the number of clients can be as large as 100 [25, 27]. In such a case, it is more challenging for the global model to achieve good performance. However, existing TFL methods typically use a very small number of domains $\\leq5$ for FedSR and StableFDG). In contrast, we allow the system size to cover a broad range of values, including 10 (small), 50 (medium), and 100 (large) clients. ", "page_idx": 8}, {"type": "text", "text": "Evaluation matrix and backbones. We measure domain transferability via $a c c_{t g t}$ , the accuracy of a pretrained model finetuned on the target domain. For backbone selection, we use both LeNet [21] and ResNet18[14] to represent different levels of backbone complexity. ", "page_idx": 8}, {"type": "text", "text": "Baselines. We consider the following TFL algorithms as our main baselines: FedAVG, FedSR, and FedIIR. Furthermore, we also compare our findings to Scaffold [16], an advanced FL approach used to address data heterogeneity. We do not report results for FedADG, FedCDG, FedGTST, and StableFDG since they do not ensure privacy and/or underperform compared to the main baseline. ", "page_idx": 8}, {"type": "text", "text": "Settings for Pretraining (FL on source local domains). 1) Local epochs. To conform with our theoretical assumptions, unless specified otherwise, we set the local epoch of each client to 1. We also investigate the system performance with 10 local epochs in Appendix C. 2) Number of participants per round. We allow $\\bar{5}0\\%$ of the clients to participate in each round (e.g., if $K\\,=\\,50$ , there are 25 participants per round). 3) Number of clients performing standard local training. To boost the Jacobian norm, a subset of clients conducts standard local training (we set the subset size to $10\\%$ of the total number of clients). ", "page_idx": 8}, {"type": "text", "text": "Additional Settings. Unless specified otherwise, for local training on the source datasets we use the Adam [17] optimizer with coefficients $(\\beta_{1},\\beta_{2})=(0.9,0.999)$ (note that these $\\beta$ values are not to be confused with the coefficients from our theoretical analysis). Our initial learning rate equals 0.01 and then decays by a factor of $10\\;\\mathrm{per}\\;50$ rounds, with an early stop trigger of 10 rounds. We apply the standard cross-entropy loss. We also set the pretraining batch size to 256 for MNIST $\\rightarrow$ MNIST-M and to 128 for CIFAR $10\\rightarrow\\mathrm{SVHN}$ . For both tasks, we use a finetuned learning rate 0.005, with weight decay 0.0001. All results reported in Section 6.2 are averaged over three runs. ", "page_idx": 8}, {"type": "text", "text": "6.2 Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Table 1: Target accuracy $(\\%)$ of the finetuned model pretrained on a small number of clients $\\kappa=10$ ). FedGTST outperforms other methods across both tasks and both backbones; for the example MNIST to MNIST-M with a LeNet backbone, FedGTST outperforms FedIIR and FedSR by around $4\\%$ . ", "page_idx": 8}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/79a2bce4b5bfc9f7c3459570444feb32971198a56d8244db654cdf3e17b7c8df.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Transferability results. FedGTST exhibits significantly improved transfer performance when compared to baselines across a range of tasks, system sizes, and backbone architectures. For the example of CIFAR $10{\\rightarrow}\\mathrm{SVHN}$ with 100 clients and a LeNet backbone, FedGTST outperforms FedIIR by $7.6\\%$ and FedSR by $9.8\\%$ . The results for a small, medium and large federated system ( $K=10$ , $K=50$ and $K=100,$ ) are reported in Tables 1, 2 and 3, respectively. ", "page_idx": 8}, {"type": "text", "text": "Discussion. Besides the significant performance gain of FedGTST over baseline methods, we also observe that 1) for transfer tasks in which the backbone and method are fixed, transferability generally decreases with the system size. Importantly, FedGTST improves the baselines more significantly ", "page_idx": 8}, {"type": "text", "text": "Table 2: Target accuracy $(\\%)$ of the finetuned model pretrained on a medium number of clients $[K=50]$ ). FedGSTS outperforms other methods across both tasks and both backbones; for both the examples of MNIST $\\rightarrow$ MNIST-M and CIFAR $\\mathrm{10{\\rightarrow}S V H N}$ with a ResNet18 backbone, FedGTST outperforms FedIIR and FedSR by around $5\\%$ . ", "page_idx": 9}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/7c1ebd13f00de475d86c540e2b71b7b310061acbd2a048c00c309f6a433e012a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/d13ea0c83bf3647ec6415ec7722e7b1a5aff5bf7f66fd1fb96dafc9caae918a3.jpg", "table_caption": ["Table 3: Target accuracy $(\\%)$ of the finetuned model pretrained on a large number of clients $\\(K\\;=\\;100)$ ). FedGTST outperforms other methods across both tasks and for both backbones; for CIFAR $10{\\rightarrow}\\mathrm{SVHN}$ with a ResNet18 and LeNet backbone, FedGTST outperforms FedIIR and FedSR by $7\\%$ . "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "for large system sizes; 2) when the system size, transfer task and the method are fixed, the more \u201dcomplex\u201d the backbone (ResNet18 vs LeNet), the better the transferability. ", "page_idx": 9}, {"type": "text", "text": "Additional results. We defer reporting and discussing additional results in Appendix C, which include (a) an investigation on hyper-parameter sensitivity the convergence speed, and cross-client statistics, (b) results regarding DomainNet, Dirichlet Sampling, and Scaffold. ", "page_idx": 9}, {"type": "text", "text": "7 Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Increased Local Computational Cost. While FedGTST only induces a negligible communication overhead among clients and the server, we note that at the level of a small subset of clients we need to conduct both regularized training and standard training to boost $\\|J_{p}\\|_{2}$ . This increases the local computational burden but to a very small extent. Nevertheless, in future works, we will explore algorithms with lower local computational costs. ", "page_idx": 9}, {"type": "text", "text": "Potentially Loose Bounds. Although existing studies have added to our understanding of transferable federated learning, our work is the first to derive a bound on a direct measure of transferability (the target loss). We believe that the bound can be tightened. ", "page_idx": 9}, {"type": "text", "text": "8 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We introduced FedGTST, a federated learning algorithm aimed at enhancing global transferability. Inspired by theoretical insights, FedGTST integrates cross-client information on averaged Jacobian norms and Jacobian variance. Our work addresses key challenges in existing methods, such as privacy violations and an overemphasis on local transferability. Experimental results demonstrate significant performance improvements over baseline models. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the Air Force Office of Scientific Research under award number FA9550- 23-1-0107, the NSF CAREER Award under Grant No. EPCN-1944403 as well as the NSF Awards CCF 1956384 and 2402815, and SVCF CZI 2022-249120. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Durmus Alp Emre Acar, Yue Zhao, Ramon Matas Navarro, Matthew Mattina, Paul N Whatmough, and Venkatesh Saligrama. Federated learning based on dynamic regularization. In International Conference on Learning Representations (ICLR), 2021. URL https://openreview.net/forum?id=B7v4QMR6Z9w.   \n[2] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, David Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Kone\u02c7cn\\`y, Stefano Mazzocchi, H Brendan McMahan, et al. Towards federated learning at scale: System design. arXiv preprint arXiv:1902.01046, 2019.   \n[3] Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan. Domain separation networks. Advances in neural information processing systems, 29, 2016.   \n[4] Junming Chen, Meirui Jiang, Qi Dou, and Qifeng Chen. Federated domain generalization for image recognition via cross-client style transfer. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 361\u2013370, 2023.   \n[5] Corinna Cortes and Mehryar Mohri. Domain adaptation and sample bias correction theory and algorithm for regression. Theoretical Computer Science, 519:103\u2013126, 2014. ISSN 0304-3975. doi: https://doi.org/10.1016/j.tcs.2013.09.027. URL https://www.sciencedirect.com/ science/article/pii/S0304397513007184. Algorithmic Learning Theory.   \n[6] Corinna Cortes, Mehryar Mohri, and Andr\u00e9s Munoz Medina. Adaptation based on generalized discrepancy. Journal of Machine Learning Research, 20(1):1\u201330, 2019.   \n[7] Laizhong Cui, Xiaoxin Su, Yipeng Zhou, and Jiangchuan Liu. Optimal rate adaption in federated learning with compressed communications. In IEEE INFOCOM 2022-IEEE Conference on Computer Communications, pages 1459\u20131468. IEEE, 2022.   \n[8] Bharath Bhushan Damodaran, Benjamin Kellenberger, R\u00e9mi Flamary, Devis Tuia, and Nicolas Courty. Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. In Proceedings of the European conference on computer vision (ECCV), pages 447\u2013463, 2018.   \n[9] Li Deng. The mnist database of handwritten digit images for machine learning research. IEEE Signal Processing Magazine, 29(6):141\u2013142, 2012.   \n[10] Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive personalized federated learning. arXiv preprint arXiv:2003.13461, 2020.   \n[11] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario March, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of machine learning research, 17(59):1\u201335, 2016.   \n[12] Yaming Guo, Kai Guo, Xiaofeng Cao, Tieru Wu, and Yi Chang. Out-of-distribution generalization of federated learning via implicit invariant relationships. In International Conference on Machine Learning, pages 11905\u201311933. PMLR, 2023.   \n[13] Farzin Haddadpour and Mehrdad Mahdavi. On the convergence of local descent methods in federated learning. arXiv preprint arXiv:1910.14425, 2019.   \n[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \n[15] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjuneta Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.   \n[16] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 5132\u20135143. PMLR, 2020.   \n[17] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[18] Jakub Kone\u02c7cn\u00fd, H Brendan McMahan, Daniel Ramage, Peter Richt\u00e1rik, Ananda Theertha Suresh, et al. Federated optimization: Distributed optimization beyond the datacenter. arXiv preprint arXiv:1511.03575, 2016.   \n[19] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[20] Fan Lai, Yinwei Dai, Sanjay Singapuram, Jiachen Liu, Xiangfeng Zhu, Harsha Madhyastha, and Mosharaf Chowdhury. Fedscale: Benchmarking model and system performance of federated learning at scale. In International Conference on Machine Learning (ICML), 2022. URL https://proceedings.mlr.press/v162/lai22a.html.   \n[21] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998. doi: 10.1109/5.726791.   \n[22] Seunghun Lee, Sunghyun Cho, and Sunghoon Im. Dranet: Disentangling representation and adaptation networks for unsupervised cross-domain adaptation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 15252\u201315261, 2021.   \n[23] Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 10713\u201310722, 2021. doi: 10.1109/CVPR46437. 2021.01057. URL https://openaccess.thecvf.com/content/CVPR2021/papers/Li_ Model-Contrastive_Federated_Learning_CVPR_2021_paper.pdf.   \n[24] Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In CVPR, pages 10713\u201310722, 2021. doi: 10.1109/CVPR46437.2021. 01057. URL https://openaccess.thecvf.com/content/CVPR2021/papers/Li_ Model-Contrastive_Federated_Learning_CVPR_2021_paper.pdf.   \n[25] Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 10713\u201310722, June 2021.   \n[26] Tianqing Li, Anup Sahu, Ameet S Talwalkar, and Virginia Smith. Federated learning: Challenges, methods, and future directions. IEEE Signal Processing Magazine, 37(3):50\u201360, 2020.   \n[27] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of fedavg on non-iid data. arXiv preprint arXiv:1907.02189, 2019.   \n[28] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In International conference on machine learning, pages 97\u2013105. PMLR, 2015.   \n[29] Mi Luo, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, and Jiashi Feng. No fear of heterogeneity: Classifier calibration for federated learning with non-iid data. In Advances in Neural Information Processing Systems, volume 34, pages 6072\u20136084, 2021.   \n[30] Evelyn Ma, Praneet Rathi, and S Rasoul Etesami. Local environment poisoning attacks on federated reinforcement learning. arXiv preprint arXiv:2303.02725, 2023.   \n[31] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and algorithms. arXiv preprint arXiv:0902.3430, 2009.   \n[32] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR, 2017.   \n[33] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011.   \n[34] A Tuan Nguyen, Philip Torr, and Ser Nam Lim. Fedsr: A simple and effective domain generalization method for federated learning. Advances in Neural Information Processing Systems, 35:38831\u201338843, 2022.   \n[35] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering, 22(10):1345\u20131359, 2010.   \n[36] Jungwuk Park, Dong-Jun Han, Jinho Kim, Shiqiang Wang, Christopher Brinton, and Jaekyun Moon. Stablefdg: Style and attention based learning for federated domain generalization. Advances in Neural Information Processing Systems, 36, 2024.   \n[37] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In Proceedings of the IEEE International Conference on Computer Vision, pages 1406\u20131415, 2019.   \n[38] Mohammad Pezeshki, Chengxu Le Lan, Thibaut Durand, Guillaume Lajoie, Simon LacosteJulien, Aaron Courville, and David Lopez-Paz. Understanding hessian alignment for domain generalization. arXiv preprint arXiv:2308.11778, 2023.   \n[39] Alexandre Rame, Corentin Dancette, and Matthieu Cord. Fishr: Invariant gradient variances for out-of-distribution generalization. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 18347\u201318377. PMLR, 17\u201323 Jul 2022. URL https://proceedings.mlr.press/ v162/rame22a.html.   \n[40] Sebastian Ruder, Ivan Vulic, and Anders S\u00f8gaard. A survey of cross-lingual word embedding models. Journal of Artificial Intelligence Research, 65:569\u2013631, 2019.   \n[41] Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. Do adversarially robust imagenet models transfer better? Advances in Neural Information Processing Systems, 33, 2020. URL https://par.nsf.gov/biblio/10283431.   \n[42] Yan Shen, Jian Du, Han Zhao, Zhanghexuan Ji, Chunwei Ma, and Mingchen Gao. Fedmm: A communication efficient solver for federated adversarial domain adaptation. In Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems, pages 1808\u20131816, 2023.   \n[43] Yuge Shi, Jeffrey Seely, Philip H. S. Torr, Siddharth Narayanaswamy, Awni Y. Hannun, Nicolas Usunier, and Gabriel Synnaeve. Gradient matching for domain generalization. In International Conference on Learning Representations (ICLR), 2022. URL https://openreview.net/ forum?id=_7w5JXy8VJM.   \n[44] Virginia Smith. Federated learning: strategies for improving communication efficiency. IEEE Signal Processing Magazine, 34(6):36\u201343, 2017.   \n[45] Zhenheng Tang, Yonggang Zhang, Shaohuai Shi, Xin He, Bo Han, and Xiaowen Chu. Virtual homogeneity learning: Defending against data heterogeneity in federated learning. arXiv preprint arXiv:2206.02465, 2022.   \n[46] Zhenheng Tang, Yonggang Zhang, Shaohuai Shi, Xinmei Tian, Tongliang Liu, Bo Han, and Xiaowen Chu. Fedimpro: Measuring and improving client update in federated learning. In The Twelfth International Conference on Learning Representations (ICLR), Vienna, Austria, May 7-11 2024. OpenReview.net.   \n[47] Lisa Torrey and Jude Shavlik. Transfer learning. In Handbook of research on machine learning applications and trends: algorithms, methods, and techniques, pages 242\u2013264. IGI global, 2010.   \n[48] Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. A survey of transfer learning. Journal of Big data, 3(1):1\u201340, 2016.   \n[49] Xidong Wu, Feihu Huang, Zhengmian Hu, and Heng Huang. Faster adaptive federated learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 10379\u2013 10387, 2023.   \n[50] Xiaojun Xu, Jacky Y Zhang, Evelyn Ma, Hyun Ho Son, Sanmi Koyejo, and Bo Li. Adversarially robust models may not transfer better: Sufficient conditions for domain transferability from the view of regularization. In International Conference on Machine Learning, pages 24770\u201324802. PMLR, 2022.   \n[51] Qiang Yang, Yang Liu, Tianjian Chen, Yu Tong, et al. Federated optimization: Distributed optimization beyond the datacenter. IEEE Signal Processing Magazine, 36(4):49\u201359, 2019.   \n[52] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable are features in deep neural networks? Advances in Neural Information Processing Systems, 27, 2014.   \n[53] Xinhui Yu, Dan Wang, Martin McKeown, and Z Jane Wang. Contrastive-enhanced domain generalization with federated learning. IEEE Transactions on Artificial Intelligence, 2023.   \n[54] Jie Zhang, Chen Chen, Bo Li, Lingjuan Lyu, Shuang Wu, Shouhong Ding, Chunhua Shen, and Chao Wu. DENSE: Data-free one-shot federated learning. In Advances in Neural Information Processing Systems, volume 35, pages 19112\u2013 19126, 2022. URL https://papers.nips.cc/paper_files/paper/2022/hash/ 868f2266086530b2c71006ea1908b14a-Abstract-Conference.html.   \n[55] Liling Zhang, Xinyu Lei, Yichun Shi, Hongyu Huang, and Chao Chen. Federated learning with domain generalization. arXiv preprint arXiv:2111.10487, 2021.   \n[56] Han Zhao, Shanghang Zhang, Guanhang Wu, Jos\u00e9 MF Moura, Joao P Costeira, and Geoffrey J Gordon. Adversarial multiple source domain adaptation. In Advances in Neural Information Processing Systems, pages 8568\u20138579, 2018.   \n[57] Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant representations for domain adaptation. In International conference on machine learning, pages 7523\u20137532. PMLR, 2019.   \n[58] Han Zhao, Chen Dan, Bryon Aragam, Tommi S Jaakkola, Geoffrey J Gordon, and Pradeep Ravikumar. Fundamental limits and tradeoffs in invariant representation learning. The Journal of Machine Learning Research, 23(1):15356\u201315404, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Additional preliminaries ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Definition 5 ( $\\mathcal{H}$ -discrepancy [6, 57]). Given a model function class $\\mathcal{H}$ and two data distributions $\\mathcal{D}_{S}$ , $\\mathcal{D}_{T}$ , the $\\mathcal{H}$ -discrepancy between $\\cal{D}_{S},\\cal{D}_{T}$ is defined as ", "page_idx": 14}, {"type": "equation", "text": "$$\nd_{\\mathcal{H}}(\\mathcal{D}_{S},\\mathcal{D}_{T}):=\\operatorname*{sup}_{h\\in\\mathcal{H}}|L_{\\mathcal{D}_{S}}(h)-L_{\\mathcal{D}_{T}}(h)|.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Remark. This type of discrepancy, as well as the related $\\mathcal{H}$ -divergence, have been frequently used in the analysis of domain adaptation [5, 31, 57], and we follow this trend. ", "page_idx": 14}, {"type": "text", "text": "B Proof of our bounds ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lemma B.1 (Theorem 2.5 in [50]). Suppose we perform pretraining on the source domain $\\mathcal{D}_{S}$ to obtain $f$ and $g$ at the server, and fine-tune the model on the target domain $\\mathcal{D}_{T}$ to obtain a new classifier $g_{T}$ . We then have ", "page_idx": 14}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}_{T}}(g_{T}^{*}\\circ f^{*})\\leq L_{s r c}(g^{*}\\circ f^{*})+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S},\\mathcal{D}_{T}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Equation (12) shows that the transfer loss can be upper bounded by the sum of the loss on the source domain and the divergence between two domains. ", "page_idx": 14}, {"type": "text", "text": "Lemma B.2. With Assumption 4.1 (Convexity and Smoothness) and Definition 2 (Cross-Client Divergence), we have ", "page_idx": 14}, {"type": "equation", "text": "$$\nL_{s r c}(h^{*})\\leq\\frac{1}{K}\\sum_{k=1}^{K}\\left[L_{\\mathcal{D}^{(k)}}\\left(h^{*(k)}\\right)\\right]+\\overline{{d}}_{\\mathcal{H}}(\\mathcal{D}_{S}^{f e d}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. The loss function $l$ is assumed to be convex w.r.t. the parameters of the model $h$ , where t, erwsh aerree n aonted $w_{h}$ .n dBs afsoerd t hoen  wtheei gahgtsg rfeogr agtlioobna rl umleo idne l catniod nt h3a,t  fwoer  lhoacvael $w_{h}\\ =$ $\\bar{\\mathit{\\Sigma}}_{K}^{\\bar{\\mathit{1}}}\\bar{\\mathit{\\Sigma}}_{k}^{\\bar{\\mathit{1}}}\\mathit{w}_{h}^{(k)}$ $w_{h}$ $w_{h}^{(k)}$ $h$ $h^{(k)}$ , respectively. We therefore have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{L_{n+1}(k^{n})=\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}L_{n+1}(k^{n})}&{}\\\\ {=}&{\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\mathbb{E}_{n}\\{R(k,\\pi_{k}^{n}),\\,y\\}}\\\\ &{=\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\mathbb{E}_{n}\\{R(k^{n},\\frac{1}{K}\\log|\\alpha_{k}|)\\}}\\\\ &{\\overset{(a)}{=}\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\sum_{k\\ge1}\\mathbb{E}_{n}\\{R(k,\\frac{1}{K}\\log|\\alpha_{k}^{n}),\\,y\\}}\\\\ &{=\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}L_{n+1}\\left(k^{n}(k^{n})\\right)}\\\\ &{\\overset{(b)}{=}\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\sum_{l\\ge0}\\left(k^{n+1}\\right)+d_{n}\\left(\\eta^{(k+1)},\\,y^{(k+)}\\right)\\Big]}\\\\ &{=\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}L_{n+1}\\left(k^{n+1}\\right)+\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}d_{n}\\left(P^{(k+1)},\\,y^{(k+)}\\right)}\\\\ &{\\leq\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}L_{n+1}\\left(N^{(k+1)}\\right)+\\frac{1}{\\sqrt{K}}\\displaystyle\\sum_{k=1}^{K}\\Big(\\lambda_{n}\\left(P^{(k+1)},\\,y^{(k+)}\\right)}\\\\ &{\\leq\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}L_{n+1}\\left(N^{(k+1)}\\right)+\\lambda_{n}(P^{(k)},\\,y^{(k)})}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\begin{array}{r}{\\frac{1}{K^{2}}\\sum_{k_{1},k_{2}}d\\varkappa\\left(\\mathcal{D}^{(k_{1})},\\mathcal{D}^{(k_{2})}\\right)\\leq\\frac{1}{K(K-1)}\\sum_{k_{1}\\neq k_{2}}d\\varkappa\\left(\\mathcal{D}^{(k_{1})},\\mathcal{D}^{(k_{2})}\\right)=\\overline{{d}}_{\\mathcal{H}}(\\mathcal{D}_{S})}\\end{array}$ as in Definition 2. Here $(a)$ follows from the convexity assumption for $l$ w.r.t the parameters, while $(b)$ follows ", "page_idx": 14}, {"type": "text", "text": "from Lemma B.1 based on the argument below: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{{\\mathcal D}^{(k_{1})}}\\left(h^{*(k_{2})}\\right)=L_{{\\mathcal D}^{(k_{1})}}\\left(h^{*(k_{2})}\\right)-L_{{\\mathcal D}^{(k_{2})}}\\left(h^{*(k_{2})}\\right)+L_{{\\mathcal D}^{(k_{2})}}\\left(h^{*(k_{2})}\\right)}\\\\ &{\\phantom{{=}}\\leq\\left|L_{{\\mathcal D}^{(k_{1})}}\\left(h^{*(k_{2})}\\right)-L_{{\\mathcal D}^{(k_{2})}}\\left(h^{*(k_{2})}\\right)\\right|+L_{{\\mathcal D}^{(k_{2})}}\\left(h^{*(k_{2})}\\right)}\\\\ &{\\phantom{{=}}\\leq d_{\\mathcal{H}}\\left({\\mathcal D}^{(k_{1})},{\\mathcal D}^{(k_{2})}\\right)+L_{{\\mathcal D}^{(k_{2})}}\\left(h^{*(k_{2})}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Theorem 3 (Theorem 1). Under Assumptions 4.1 (Convexity and Smoothness), the optimal target loss is bounded by ", "page_idx": 15}, {"type": "equation", "text": "$$\nL_{t g t}^{*}\\leq\\frac{1}{K}\\sum_{k=1}^{K}\\Big[L_{\\mathcal{D}^{(k)}}\\left(h^{*(k)}\\right)\\Big]+\\overline{{d}}_{\\mathcal{H}}(\\mathcal{D}_{S}^{f e d})+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $h^{*(k)}$ denotes the optimal local model of client $k$ (see Section 3). ", "page_idx": 15}, {"type": "text", "text": "Proof. Since ", "page_idx": 15}, {"type": "equation", "text": "$$\nL_{t g t}^{*}=L_{\\mathcal{D}_{T}}\\left(g_{T}^{*}\\circ f^{*}\\right)\\leq L_{\\mathcal{D}^{(k)}}\\left(g^{*}\\circ f^{*}\\right)+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}^{(k)},\\mathcal{D}_{T}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{t g t}^{*}\\leq\\displaystyle\\frac{1}{K}\\sum_{k}\\Big[L_{{\\mathcal{D}}^{(k)}}\\left(g^{*}\\circ f^{*}\\right)+d_{{\\mathcal{G}},{\\mathcal{F}}}({\\mathcal{D}}^{(k)},{\\mathcal{D}}_{T})\\Big]}\\\\ &{\\qquad=L_{s r c}(h^{*})+d_{{\\mathcal{G}},{\\mathcal{F}}}({\\mathcal{D}}_{S}^{f e d},{\\mathcal{D}}_{T}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Using Lemma B.2, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{t g t}^{*}\\leq L_{s r c}(h^{*})+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T})}\\\\ &{\\qquad\\leq\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\left[L_{\\mathcal{D}^{(k)}}\\left(h^{*(k)}\\right)\\right]+\\overline{d}_{\\mathcal{H}}(\\mathcal{D}_{S}^{f e d})+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma B.3 (Bound on round-wise source loss). Suppose the learning rates of all clients at round $p$ are the same, i.e., $\\lambda_{p}^{(k)}=\\lambda_{p},\\forall k\\in[K],p\\in[P].$ . Under Assumptions 4.2 and 4.1, we have that ", "page_idx": 15}, {"type": "equation", "text": "$$\nL_{s r c}\\left(h_{p+1}\\right)\\le L_{s r c}\\left(h_{p}\\right)-\\beta_{1}(\\lambda_{p+1})\\|J_{p}\\|_{2}^{2}+\\beta_{2}(\\lambda_{p+1})\\sigma_{p}^{2}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\begin{array}{r}{J_{p}=\\frac{1}{K}\\sum_{k}J_{p}^{(k)},\\,\\sigma_{p}^{2}=\\frac{1}{K}\\sum_{k}\\left\\|J_{p}^{(k)}\\right\\|_{2}^{2}-\\left\\|\\frac{1}{K}\\sum_{k}J_{p}^{(k)}\\right\\|_{2}^{2},a n d\\,\\beta_{1}(\\lambda)=\\lambda-\\beta_{2}(\\lambda),\\,\\beta_{2}(\\lambda)=\\beta_{1}(\\lambda),\\,\\beta_{2}(\\lambda)=\\lambda-\\beta_{1}(\\lambda).}\\end{array}$ $\\frac{\\alpha\\lambda^{2}}{2}$ ", "page_idx": 15}, {"type": "text", "text": "Proof. Following the same proof idea as for Lemma B.2, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nL_{s r c}\\left(h_{p+1}\\right)\\leq\\frac{1}{K^{2}}\\sum_{k_{1},k_{2}}L_{\\mathcal{D}^{(k_{1})}}\\left(h_{p+1}^{(k_{2})}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By definition, we also have ", "page_idx": 15}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}^{(k_{1})}}\\left(\\boldsymbol{h}_{p+1}^{(k_{2})}\\right)=\\mathbb{E}_{\\mathcal{D}^{(k_{1})}}l\\left(h\\left(\\boldsymbol{x},\\boldsymbol{w}_{p+1}^{(k_{2})}\\right),\\boldsymbol{y}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "From the update rule of GD, we can write ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{l\\left(h\\left(x,w_{p+1}^{(k_{2})}\\right),y\\right)=l\\left(h\\left(x,w_{p}-\\lambda_{p+1}\\cdot\\left[\\nabla_{w_{h}}L_{\\mathcal{D}^{(k_{2})}}\\left(h\\right)\\bigg|_{w_{h}=w_{p}}\\right]\\right),y\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=l\\left(h\\left(x,w_{p}-\\lambda_{p+1}\\cdot\\left[\\nabla_{w}\\mathbb{E}_{\\mathcal{D}^{(k_{2})}}l\\left(h(x_{i},w),y_{i}\\right)\\bigg|_{w=w_{p}}\\right]\\right),y\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=l\\left(h\\left(x,w_{p}-\\lambda_{p+1}\\cdot J_{p}^{(k_{2})}\\right),y\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In (18), $\\left({x_{i},y_{i}}\\right)$ are sampled from $\\mathcal{D}^{(k_{2})}$ , and not to be confused with $(x,y)$ sampled from $\\mathcal{D}^{(k_{1})}$ . ", "page_idx": 16}, {"type": "text", "text": "Define $\\Delta:=-\\lambda_{p+1}\\cdot J_{p}^{(k_{2})}$ , we can upper bound the loss in (19) by ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{l\\left(h\\left(x,w_{p+1}^{\\left(k_{2}\\right)}\\right),y\\right)=l\\left(h\\left(x,w_{p}+\\Delta\\right),y\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq l\\left(h\\left(x,w_{p}\\right),y\\right)+\\left[\\nabla_{w}l\\left(h\\left(x,w\\right),y\\right)\\big|_{w=w_{p}}\\right]^{\\top}\\cdot\\Delta+\\frac{\\alpha}{2}\\Delta^{\\top}\\Delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The inequality holds since $l$ is assumed to have $\\alpha$ -Lipschitz continuous gradient. Combining (17) and (20), we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal L}_{\\mathcal{D}^{\\left(k_{1}\\right)}}\\left(h_{p+1}^{\\left(k_{2}\\right)}\\right)\\leq\\mathbb{E}_{\\mathcal{D}^{\\left(k_{1}\\right)}}\\left[l\\left(h\\left(x,w_{p}\\right),y\\right)+\\left[\\nabla_{w}l\\left(h\\left(x,w\\right),y\\right)\\big|_{w=w_{p}}\\right]^{\\top}\\cdot\\Delta+\\frac{\\alpha}{2}\\Delta^{\\top}\\Delta\\right]}}\\\\ {{\\displaystyle={\\cal L}_{\\mathcal{D}^{\\left(k_{1}\\right)}}\\left(h_{p}\\right)+\\left[J_{p}^{\\left(k_{1}\\right)}\\right]^{\\top}\\cdot\\Delta+\\frac{\\alpha}{2}\\Delta^{\\top}\\Delta}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Next, by (16) and (21), we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{s r c}\\left(h_{p+1}\\right)\\leq\\displaystyle\\frac{1}{K^{2}}\\sum_{k_{1},k_{2}}L_{D^{\\left(k_{1}\\right)}}\\left(h_{p+1}^{\\left(k_{2}\\right)}\\right)}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{1}{K^{2}}\\sum_{k_{1},k_{2}}\\left[L_{D^{\\left(k_{1}\\right)}}\\left(h_{p}\\right)+\\left[J_{p}^{\\left(k_{1}\\right)}\\right]^{\\top}\\cdot\\Delta+\\frac{\\alpha}{2}\\Delta^{\\top}\\Delta\\right]}\\\\ &{\\qquad=\\displaystyle\\frac{1}{K^{2}}\\sum_{k_{1},k_{2}}\\left[L_{D^{\\left(k_{1}\\right)}}\\left(h_{p}\\right)-\\lambda_{p+1}\\cdot\\left[J_{p}^{\\left(k_{1}\\right)}\\right]^{\\top}\\cdot J_{p}^{\\left(k_{2}\\right)}\\right.}\\\\ &{\\qquad\\left.\\qquad+\\frac{\\alpha}{2}\\cdot\\left(\\lambda_{p+1}\\right)^{2}\\cdot\\left\\Vert J_{p}^{\\left(k_{2}\\right)}\\right\\Vert_{2}^{2}\\right]}\\\\ &{\\qquad=L_{s r c}\\left(h_{p}\\right)-\\lambda_{p+1}\\|J_{p}\\|_{2}^{2}+\\displaystyle\\frac{\\alpha}{2K}\\cdot\\left(\\lambda_{p+1}\\right)^{2}\\cdot\\sum_{k_{2}}\\left\\|J_{p}^{\\left(k_{2}\\right)}\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The last equality follows from the definition of $J_{p}$ . ", "page_idx": 16}, {"type": "text", "text": "Define $\\begin{array}{r}{\\sigma_{p}^{2}:=\\frac{1}{K}\\sum_{k=1}^{K}\\left|\\left|J_{p}^{(k)}\\right|\\right|_{2}^{2}-\\left|\\left|J_{p}\\right|\\right|_{2}^{2}}\\end{array}$ . Then, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{s r c}\\left(h_{p+1}\\right)\\leq L_{s r c}\\left(h_{p}\\right)-\\lambda_{p+1}\\|J_{p}\\|_{2}^{2}+\\displaystyle\\frac{\\alpha}{2}\\cdot(\\lambda_{p+1})^{2}\\cdot\\left(\\sigma_{p}^{2}+\\|J_{p}\\|_{2}^{2}\\right)}\\\\ &{\\qquad\\qquad=L_{s r c}\\left(h_{p}\\right)-\\left(\\lambda_{p+1}-\\displaystyle\\frac{\\alpha\\cdot(\\lambda_{p+1})^{2}}{2}\\right)\\|J_{p}\\|_{2}^{2}+\\displaystyle\\frac{\\alpha\\cdot(\\lambda_{p+1})^{2}}{2}\\sigma_{p}^{2}}\\\\ &{\\qquad\\qquad=L_{s r c}\\left(h_{p}\\right)-\\beta_{1}(\\lambda_{p+1})\\|J_{p}\\|_{2}^{2}+\\beta_{2}(\\lambda_{p+1})\\sigma_{p}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which completes the proof. ", "page_idx": 16}, {"type": "text", "text": "Lemma B.4 (Lemma 4.1). Under Assumptions 4.2 and 4.1, and the cross-client statistics defined in Definition 4, after $P$ rounds of federated pretraining one has ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\widehat{L}_{t g t}^{*}\\leq L_{s r c}\\left(h_{0}\\right)-\\sum_{p=0}^{P-1}\\beta_{1}(\\lambda_{p+1})\\|J_{p}\\|_{2}^{2}+\\sum_{p=0}^{P-1}\\beta_{2}(\\lambda_{p+1})\\sigma_{p}^{2}+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $h_{0}$ is the initial global model and $\\begin{array}{r}{\\beta_{2}(\\lambda)=\\frac{\\alpha\\lambda^{2}}{2}}\\end{array}$ , $\\beta_{1}(\\lambda)=\\lambda-\\beta_{2}(\\lambda)$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. From Lemma B.3, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{\\cal L}_{s r c}\\left(h_{P}\\right)\\leq{\\cal L}_{s r c}\\left(h_{P-1}\\right)-\\beta_{1}(\\lambda_{P})\\|J_{p-1}\\|_{2}^{2}+\\beta_{2}(\\lambda_{P})\\sigma_{P-1}^{2}}\\\\ {\\displaystyle\\leq{\\cal L}_{s r c}\\left(h_{0}\\right)-\\sum_{p=0}^{P-1}\\beta_{1}(\\lambda_{p+1})\\|J_{p}\\|_{2}^{2}+\\displaystyle\\sum_{p=0}^{P-1}\\beta_{2}(\\lambda_{p+1})\\sigma_{p}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Following the same proof as the one outlined for Theorem 1, we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\nL_{t g t}(h_{P})\\leq L_{s r c}(h_{P})+d_{\\mathcal{G},\\mathcal{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{L}_{t g t}^{*}=L_{t g t}(h_{P})\\leq L_{s r c}(h_{P})+d_{\\mathscr{G},\\mathscr{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq L_{s r c}(h_{0})-\\displaystyle\\sum_{p=0}^{P-1}\\beta_{1}(\\lambda_{p+1})\\|J_{p}\\|_{2}^{2}+\\displaystyle\\sum_{p=0}^{P-1}\\beta_{2}(\\lambda_{p+1})\\sigma_{p}^{2}+d_{\\mathscr{G},\\mathscr{F}}(\\mathcal{D}_{S}^{f e d},\\mathcal{D}_{T}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "C Additional Experimental Results ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Computing resources. We used an NVIDIA GeForce RTX 3090 Ti GPU with a memory of 24247MiB. One run of experimental evaluation takes approximately 6 hours for CIFAR $.10\\rightarrow\\mathrm{SVHN}$ for the small client setting. ", "page_idx": 17}, {"type": "text", "text": "Fraction of Clients Participating in FL Rounds. Besides the results generated using $20\\%$ of the participating clients reported in the main text, we also report the results pertaining to $10\\%$ and $100\\%$ participating clients in Table 4. A larger fraction of participants helps with improving transferability, i.e., as expected, $100\\%$ participation outperforms the setting with $\\bar{10\\%}$ participation. However, we note that for $20\\%$ of participating clients we already reach a performance comparable to that involving $100\\%$ of the participants. ", "page_idx": 17}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/c4a971c288595b8082370198a23d8424d95bf45c5ecd7deeea32b14839a7b4c5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Convergence Results. Convergence results are plotted in Figure 1. We observe that a model pretrained via FedGTST not only offers better transferability than baselines, but also tends to converge faster during the finetuning stage (i.e., the green lines in all plots always converge faster than the grey dashed lines). ", "page_idx": 17}, {"type": "text", "text": "Local Epochs. Besides the results for single local client epochs presented in main text, here we also report the results for multiple local epochs in Table 5. A smaller number of local epochs tends to improve transferability more than a larger number of epochs, which is consistent with the intuition that FL pretraining can avoids local overfitting when using fewer epochs. ", "page_idx": 17}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/309a20adb4d4fa82a12a87b31849dd5236db0cea389285578746b7756a396709.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Table 5: Transferability v.s. local number of epochs. We report results for CIFAR10 $\\rightarrow$ SVHN with the LeNet backbone, for $10\\%$ of participating clients and $K=100$ . ", "page_idx": 17}, {"type": "text", "text": "Cross-Client Statistics. We plot the cross-client averaged Jacobian norm $\\|J_{p}\\|_{2}$ and the cross-client Jacobian variance $\\sigma_{p}^{2}$ in Figure 2. The observation is that FedGTST leads to a significantly larger $\\|J_{p}\\|_{2}$ and a significantly smaller $\\sigma_{p}^{2}$ compared to FedAVG. A more detailed explanation of the findings (i.e., the reason for truncating the ${\\bf X}$ -axis in the left plot, the FedGTST coefficient selection approach and faster convergence results in the right plot) is available in the caption of Figure 2. ", "page_idx": 17}, {"type": "text", "text": "Additional Dataset: DomainNet. Following FedSR, we apply a leave-one-out strategy, where one domain is treated as the target domain and the other five are source domains, allocated to five ", "page_idx": 17}, {"type": "image", "img_path": "QXkFC7D6p4/tmp/53954523ac55ea69f0f3e87993c0394d46f9b967bfa808427ba2da3fc96cdd66.jpg", "img_caption": ["Figure 1: Visualization of Convergence Results. We use CIFAR $10\\rightarrow\\mathrm{SVHN}$ with $K=100$ as an example. The top two plots correspond to a fraction of $10\\%$ of participating clients, while the bottom two plots correspond to $100\\%$ participation. We report the training and test accuracy along with finetuned epochs for both settings. The grey dashed lines represent FedAVG, where the coefficient for the regularizer term is set to 0. Other lines represent FedGTST with tuned coefficients. "], "img_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/0107abb7cf2bd61a128f5bc7c216422fc7a763c363512b99c2036397ce66982c.jpg", "table_caption": ["individual clients. Results are reported in Table 6, where the target domains listed are: C (Clipart), I (Infograph), P (Painting), Q (Quickdraw), R (Real), and S (Sketch). "], "table_footnote": ["Table 6: Comparison of different federated models on intra-domain transfer tasks of DomainNet. FedGTST consistently outperforms the other methods. "], "page_idx": 18}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/040f0d61df03c42b1f7e8df292010eb86da67981e9ef669b0dea95e31126ea4a.jpg", "table_caption": ["Additional Baseline: Scaffold. FedGTST consistently outperforms Scaffold, as presented in Table 7 and 8. ", "Table 7: Comparison between Scaffold and FedGTST. Number of clients is 10. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Dirichlet Sampling. We set the concentration parameter to 0.5 and the number of parties to 10 by default. The results in Table 9 and 10 indicate that FedGTST still outperforms others when individual domains are constructed via Dirichlet sampling. ", "page_idx": 18}, {"type": "image", "img_path": "QXkFC7D6p4/tmp/a254e2895ced1642ca578edb24bdc2c40e92b23a828e6446e4ff4549427d79cd.jpg", "img_caption": ["Figure 2: Cross-client statistics tuning via FedGTST. We use CIFAR1 $\\scriptstyle0\\to\\mathrm{SVHN}$ with $K=100$ as an example. The left plot reports the global Jacobian (gradient) norm versus the index of the federated round. The grey dashed line represents FedAVG, while other lines correspond to FedGTST with different coefficients. We truncate the plot to only capture the results of the first 100 rounds, since at the end of training the gradient norm should drop to a value close to 0 due to convergence, and we are only interested in observing the behaviour of Jacobian norms during relative early pretraining stages. We select the best-performing setup from the left plot (the red line with coefficient $1e-3)$ , and then in the right plot, compare its variance during a federated round with that of FedAVG. The blue line represents FedAVG and the yellow line corresponds to FedGTST. The yellow line terminated earlier since all experiments are averaged over 3 runs and aligned with the run that converges the fastest. "], "img_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/94abf222e78b312719f90706bdfd6947e534b9e39def596a7efd84d735b40aaa.jpg", "table_caption": [], "table_footnote": ["Table 8: Comparison between Scaffold and FedGTST. Number of clients is 100. "], "page_idx": 19}, {"type": "text", "text": "D Discussion of the Positivity of Coefficients Requirement for Cross-Client Statistics ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Lemma D.1 (Bound on round-wise source loss). Suppose the learning rates of all clients at round $p$ are the same: $\\lambda_{p}^{(k)}=\\lambda_{p},\\forall k\\in[K],p\\in[P]$ . When Assumption 4.2 and 4.1 hold, we have that ", "page_idx": 19}, {"type": "equation", "text": "$$\nL_{s r c}\\left(h_{p+1}\\right)\\leq L_{s r c}\\left(h_{p}\\right)-\\beta_{1}(\\lambda_{p+1})\\|J_{p}\\|_{2}^{2}+\\beta_{2}(\\lambda_{p+1})\\sigma_{p}^{2}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\cdot J_{p}=\\frac{1}{K}\\sum_{k}J_{p}^{(k)},\\,\\sigma_{p}^{2}=\\frac{1}{K}\\sum_{k}\\left\\|J_{p}^{(k)}\\right\\|_{2}^{2}-\\left\\|\\frac{1}{K}\\sum_{k}J_{p}^{(k)}\\right\\|_{2}^{2},a n d\\,\\beta_{1}(\\lambda)=\\lambda-\\beta_{2}(\\lambda),\\,\\beta_{2}(\\lambda)=\\frac{\\lambda-1}{K}\\sum_{k}J_{p}^{(k)},\\,\\beta_{1}(\\lambda)=\\lambda-\\beta_{1}(\\lambda).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Remark. Lemma D.1 provides an upper bound of current-round cross-client loss (the proof is given in Appendix B), indicating that a smaller current-round cross-client loss (LHS) may be influenced by factors such as a small last-round cross-client loss, a large cross-client average Jacobian norm, and a small cross-client Jacobian variance (RHS). More precisely, the LHS is the cross-client current-round loss, which is upper bounded by three terms on the RHS, ", "page_idx": 19}, {"type": "text", "text": "1) The Loss Term: Lsrc h(p0) is the last-round cross-client loss.   \n2) The Variance Term: $\\sigma_{p}^{2}$ measuring the variance of local gradients across all nodes.   \n3) The Norm Term: $\\|J_{p}\\|_{2}^{2}$ measures the squared cross-client average Jacobian norm. ", "page_idx": 19}, {"type": "text", "text": "Positivity of the Coefficients. It is straightforward to see that \u03b22(\u03bbp+1) = \u03b1(\u03bbp2+1)2, the coefficient in front of $\\sigma_{p}^{2}$ , is always positive. Therefore, we focus on $\\beta_{2}(\\lambda_{p+1})$ , the coefficient in front of $\\|J_{p}\\|_{2}$ . Denote the RHS of Equation 25 by $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , so that $L_{s r c}(h_{p+1})\\leq B$ . To allow such a bound to be used as an indicator that the source loss is decreasing with the number of training rounds, we require $\\begin{array}{r}{\\beta\\leq L_{s r c}(h_{p})}\\end{array}$ , since only in this way can the bound give $L_{s r c}(h_{p+1})\\leq B\\leq L_{s r c}(h_{p})$ . Thus, we require $\\beta_{1}(\\bar{\\lambda_{p+1}})$ to be positive, since otherwise $\\begin{array}{r}{\\beta\\leq L_{s r c}(h_{p})}\\end{array}$ cannot be meet. We describe in what follows that a positive $\\beta_{1}(\\lambda_{p+1})$ is indeed possible in practice. ", "page_idx": 19}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/925c7274a548617aa0ead9469a0fbc0370e11a5eb6d45454c3ca1e60e78285d9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/d20605a5741ac1bfd31719df14d2781523ee70054a78dfd5923cc6044bb98e2e.jpg", "table_caption": ["Table 9: Comparison of target accuracy $\\%$ ) across different methods on MNIST $\\rightarrow$ MNIST-M and CIFAR10 $\\mapsto$ SVHN tasks. 10 individual domains are constructed by Dirichlet sampling. ", "Table 10: Comparison of target accuracy $(\\%)$ across different methods on MNIST $\\rightarrow$ MNIST-M and CIFAR $10{\\rightarrow}\\mathrm{SVHN}$ tasks. 100 individual domains are constructed by Dirichlet sampling. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "Realistic scenarios in which $\\beta_{1}(\\lambda_{p+1})\\,>\\,0$ . To require $\\beta_{1}(\\lambda_{p+1})\\,>\\,0$ is equivalent to require $\\begin{array}{r}{\\lambda_{p+1}<\\ \\frac{2}{\\alpha_{\\star}}}\\end{array}$ . This requirement can be easily met since for any model of a known mathematical form based on a second-order differentiable loss, we can easily get the lower bound for $\\alpha$ once we observed all training data. Using linear regression as an example, where $l(x,y;w)=(w x-y)^{2}$ , we have $\\begin{array}{r}{\\frac{d^{2}l}{d w^{2}}=2x}\\end{array}$ , therefore, in this case we can simply control $\\begin{array}{r}{\\lambda_{p+1}\\leq\\frac{1}{\\operatorname*{max}_{x\\in\\mathcal{X}}\\|x\\|}}\\end{array}$ maxx\u2208X \u2225x\u2225to approximately guarantee $\\begin{array}{r}{\\lambda_{p+1}<\\frac{2}{\\alpha}}\\end{array}$ . This then ensures $\\beta_{1}(\\lambda_{p+1})>0$ . ", "page_idx": 20}, {"type": "text", "text": "E Optimal Learning Rate ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Choosing the Optimal Learning Rate. Lemma B.3 shows that the upper bound of federated loss at round $p$ is a quadratic function w.r.t the learning rate $\\lambda_{p}$ . Therefore, a good learning rate at each round needs to be chosen to minimize the upper bound. For simplicity of notation, we use $B_{p+1}(\\lambda_{p+1})$ as a shorthand for the upper bound shown in (15). ", "page_idx": 20}, {"type": "text", "text": "The following two observations are in place for $B_{p+1}(\\lambda_{p+1})$ : ", "page_idx": 20}, {"type": "text", "text": "\u2022 When 0 < \u03bbp+1 < $\\begin{array}{r}{0\\ <\\ \\lambda_{p+1}\\ <\\ \\frac{2K\\cdot\\|J_{p}\\|_{2}^{2}}{\\alpha\\cdot\\sum_{k}\\|J_{p}^{(k)}\\|_{2}^{2}}\\ \\leq\\ \\frac{2}{\\alpha}}\\end{array}$ , it holds that $L_{s r c}\\left(h_{p+1}^{(0)}\\right)\\;\\leq\\;B_{p+1}(\\lambda_{p+1})\\;<$ $L_{s r c}\\left(h_{p}^{(0)}\\right)$ , indicating that the federated loss is decreasing with the number of rounds. \u2022 By minimizing $B_{p+1}(\\lambda_{p+1})$ w.r.t. $\\lambda_{p+1}$ , we have $\\lambda_{p+1}^{*}=\\frac{K\\cdot\\|J_{p}\\|_{2}^{2}}{\\alpha\\cdot\\sum_{k}\\|J_{p}^{(k)}\\|_{2}^{2}},\\quad B_{p+1}(\\lambda_{p+1}^{*})=L_{s r c}\\left(h_{p}^{(0)}\\right)-\\frac{K\\cdot\\|J_{p}\\|_{2}^{4}}{2\\alpha\\cdot\\sum_{k}\\|J_{p}^{(k)}\\|_{2}^{2}}.$ ", "page_idx": 20}, {"type": "text", "text": "F Stochastic Gradient Descend ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Assumption 4.2 on one step of gradient descent can be extended to stochastic learning with batch sampling. The additional randomness in sampling would require incorporating the variance of batch sampling into the generalization bound. This variance term, being independent of the algorithm design, was omitted in our theoretical analysis. ", "page_idx": 20}, {"type": "text", "text": "G Dataset Description ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "MNIST comprises $60,000\\;28\\times28$ grayscale images of handwritten digits (0 through 9); MNIST-M is created by combining MNIST digits with the patches randomly extracted from color photos of BSDS500 as their background, containing 59, 001 training images. The CIFAR-10 dataset consists of $60,000\\;32\\times32$ colour images from 10 classes. SVHN contains 73, 257 $32\\times32$ colored digits obtained from house numbers in Google Street View images. ", "page_idx": 21}, {"type": "text", "text": "H Non-iid FL Models ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "For the source domains MNIST and CIFAR-10, we only allow each local client to have access to two out of ten classes (e.g., for the digit dataset (0-9), one client may only have access to say digits 3 and 6). We let each client randomly chooses their labels and samples following a uniform distribution. See the example in Fig. 3 ", "page_idx": 21}, {"type": "table", "img_path": "QXkFC7D6p4/tmp/47cfcd3a0abf0f81b604ccaaccb1a49f431d291895a410b011d470b8530eb378.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "I Additional Related Work ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "I.1 Gradient Matching in Transfer Learning ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Discussion. Gradient matching in transfer learning focuses on aligning gradients between source and target domains to facilitate better domain adaptation. Shi et al. [43] demonstrate that matching gradients across domains enhances domain generalization by making the learned representations more resilient to domain shifts. Extending this idea, Rame et al. [39] introduce the concept of invariant gradient variances, which helps maintain generalization performance even for out-of-distribution settings. The work in Pezeshki et al. [38] further highlights the impact of Hessian alignment, showing that aligning the Hessians of the source and target domains can significantly boost generalization in gradient-based methods. ", "page_idx": 21}, {"type": "text", "text": "Challenges. Applying gradient alignment techniques directly to FL presents several challenges: (1) Privacy leakage\u2014these methods can potentially compromise data privacy by necessitating access to the target domain from source domains; (2) Local overftiting\u2014clients train their models on local data, which can lead to overftiting within their specific domains, reducing the global model\u2019s generalization capabilities. ", "page_idx": 21}, {"type": "text", "text": "Our contribution. To address the issues described above, we propose communication schemes that ensure data privacy by preventing unrestricted access to client data. Furthermore, our approach promotes global transferability by focusing on improving generalization across all clients rather than solely enhancing local domain performance. ", "page_idx": 21}, {"type": "text", "text": "I.2 Distinctions and Connections between Generalization and Transferability in FL ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Both approaches address the challenge of non-iid data, and improving transferability may potentially enhance generalization across diverse local domains. However, they employ distinct models and evaluation datasets: (a) Generalization of $\\mathrm{FL}$ targets performance on heterogeneous source testing datasets, while transferable FL aims for strong performance on a target dataset that may significantly differ from source training datasets. (b) Heterogeneous FL utilizes the pretrained model for evaluation, whereas Transferable FL assesses the finetuned model. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "The methodologies also diverge. Although reducing cross-client variance is linked to better generalization, our method distinguishes itself from traditional heterogeneous FL by enforcing a large average Jacobian norm $|J_{p}|$ in the early stages. While a larger $|J_{p}|$ may hinder generalization due to increased local updates and model variance, it enhances transferability by preventing premature local convergence. ", "page_idx": 22}, {"type": "text", "text": "Additionally, adversarially robust models offer an example where improving transferability may come at the expense of generalization. As shown in [41], adversarially robust models tend to have better transferability. However, since these models are designed to perform well against adversarial examples or perturbations, they do not necessarily exhibit lower generalization error on clean test data. In this scenario, transferability can be unrelated to or even conflict with generalization. ", "page_idx": 22}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The abstract and introduction reflect the facts that 1) we theoretically established that certain cross-client statistics can boost transferability of federated learning, and that 2) based on our theoretical findings, we proposed a novel transferable federated learning method which significantly outperforms baselines. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We discuss the limitations of our work in a separate section, Limitations. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We provided necessary assumptions need for our theoretical analysis in the main text but deferred the proofs to the Appendix due to space limitations. We nevertheless discussed the intuition behind our findings in the main text. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The datasets are existing open-source benchmarks, and we have included our code in the Supplementary materials document. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The datasets are existing open-source benchmarks, and we have attached our code in a Supplementary materials document. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Details of the experimental work are discussed in the Experimental Setting in the Experiments section. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Our experimental results are test accuracies, and we reported the standard deviations. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 25}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Sufficient information about the compute resources (type of compute workers, memory, time of execution) is provided in the Experiments section. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The research conducted to produce the paper conformed, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: There is neither a negative or positive societal impact of the work performed. It still may have a technological and academic impact based on its results and findings. There should be no problems with the proper use of the pertinent methods/software. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper poses no risk in this domain. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The original papers that produced the dataset used in our studies are properly cited. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper will not lead to the release of new assets. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 28}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]