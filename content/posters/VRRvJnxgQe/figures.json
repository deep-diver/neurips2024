[{"figure_path": "VRRvJnxgQe/figures/figures_3_1.jpg", "caption": "Figure 1: We leverage the zero-shot ability of MLLM to examine whether an example pair is noisy. To identify the potential noise, NoiseGPT first perturbs a given example x and produces a set of augmented versions z via using a novel token-wise Mixture-of-Feature (MoF) technique. Then by comparing the Softmax probabilities q\u03b8 between x and z, we can calculate an In-Context Discrepancy (ICD) measure to further decide the authenticity of the given label \u1ef9.", "description": "This figure illustrates the NoiseGPT framework for label noise detection and rectification.  It shows how the model uses a Multimodal Large Language Model (MLLM) and a classifier in conjunction with a novel token-wise Mixture-of-Feature (MoF) technique to determine if an image-label pair is noisy.  The process involves perturbing the input image, generating augmented versions, and comparing the MLLM's softmax probabilities to calculate an In-Context Discrepancy (ICD) measure, which helps to identify noisy labels.", "section": "3 Methodology"}, {"figure_path": "VRRvJnxgQe/figures/figures_3_2.jpg", "caption": "Figure 2: We demonstrate the distinctive curvatures of clean and noisy examples through an experiment. Ten perturbed exemplars are generated for a clean and a noisy sample from CIFAR-100 respectively. The MLLM output Softmax probability qo (\u1ef9) of perturbed clean exemplars xclean ~ p(\u00b7) (left) reside within a convex region on the curvature; While those of noisy exemplars xnoisy ~ p(\u00b7) (right) tend to cluster around the original point, posing lower or higher probability.", "description": "This figure shows the probability curvature of clean and noisy samples.  The left panel shows the smooth, convex curvature of clean samples under perturbation, while the right panel illustrates the fluctuating, non-convex curvature of noisy samples. This difference in curvature is the basis for NoiseGPT's noise detection method.", "section": "3.1 Noise Detection"}, {"figure_path": "VRRvJnxgQe/figures/figures_4_1.jpg", "caption": "Figure 3: We conduct validation experiments on six noisy datasets using ICD score, namely CIFAR-10 Sym. 50%,, CIFAR-100 Sym. 50%, CIFAR-10N with worse labels, CIFAR-100N with noisy labels, Webvision Sym. 40%, ISLVRC12 Sym. 40%,. We collect scores of 10,000 clean samples and 10,000 noisy samples from each dataset, and each sample is augmented by 10 perturbed exemplars with a MoF weight of 0.5.", "description": "The figure shows the distribution of ICD scores for clean and noisy samples from six different datasets under perturbation.  It visually demonstrates the effectiveness of the In-Context Discrepancy (ICD) measure in distinguishing between clean and noisy data based on the probability curvature effect. Higher ICD scores are associated with clean samples and lower scores with noisy samples.", "section": "3.1 Noise Detection"}, {"figure_path": "VRRvJnxgQe/figures/figures_6_1.jpg", "caption": "Figure 4: The noise detection ROC curves.", "description": "This ROC curve figure visualizes the performance of NoiseGPT's noise detection capabilities across six different noisy datasets: CIFAR-10N Aggregate, CIFAR-10N Rand1, CIFAR-10N Worst, CIFAR-100N Noisy, Webvision Sym. 40%, and ILSVRC12 Sym. 40%.  The x-axis represents the false positive rate (FPR), and the y-axis represents the true positive rate (TPR). Each line corresponds to a specific dataset, showing the trade-off between correctly identifying noisy samples (TPR) and incorrectly labeling clean samples as noisy (FPR). A curve closer to the top-left corner indicates better performance, with an area under the curve (AUROC) score approaching 1. The dashed line represents a random classifier with an AUROC of 0.5.", "section": "4.2 Performance analysis"}, {"figure_path": "VRRvJnxgQe/figures/figures_8_1.jpg", "caption": "Figure 5: Trend of performance under changing perturbation number.", "description": "This figure shows the trend of noise rectification performance under a changing hyperparameter (number of perturbations) for CIFAR-10 and CIFAR-100 datasets with 80% symmetric noise.  It demonstrates that increasing the number of perturbations initially improves accuracy but eventually plateaus, indicating a point of diminishing returns. The optimal number of perturbations balances computational cost and performance gains.", "section": "4.4 Sensitivity study"}, {"figure_path": "VRRvJnxgQe/figures/figures_9_1.jpg", "caption": "Figure 6: Output possibility curvatures of clean and noisy examples under different perturbation strength.", "description": "This figure shows the probability curvature for both clean and noisy examples under different perturbation strengths. The x-axis represents the perturbation strength (MoF weight w), while the y-axis represents the output probability.  The curves demonstrate that clean examples exhibit a smooth, predictable curvature, while noisy examples show a fluctuating, less consistent pattern. This difference in curvature is a key observation that underpins NoiseGPT's ability to distinguish between clean and noisy samples.", "section": "4.5 Ablation study"}, {"figure_path": "VRRvJnxgQe/figures/figures_9_2.jpg", "caption": "Figure 7: Clean categories that are easier to be mistaken as noisy.", "description": "This figure shows the average ICD scores for clean categories that are frequently misclassified as noisy by the NoiseGPT model.  The lower the ICD score, the more likely a clean category is to be misidentified. This visualization helps to understand the inherent biases within the model's noise detection process, specifically highlighting categories where the probability curvature effect is less pronounced.", "section": "4.5 Ablation study"}, {"figure_path": "VRRvJnxgQe/figures/figures_16_1.jpg", "caption": "Figure 4: The noise detection ROC curves.", "description": "This ROC curve graph shows the performance of NoiseGPT's noise detection capabilities across various noisy datasets.  Each curve represents a different dataset (CIFAR-10 with symmetric noise at different levels, CIFAR-10 with asymmetric noise, and CIFAR-100 with symmetric noise at different levels). The x-axis represents the false positive rate (FPR), and the y-axis represents the true positive rate (TPR). The closer a curve is to the top-left corner, the better the model's performance at distinguishing between clean and noisy samples. The dashed line represents the performance of a random classifier (AUROC = 0.5).", "section": "4.2 Performance analysis"}, {"figure_path": "VRRvJnxgQe/figures/figures_17_1.jpg", "caption": "Figure 9: Noisy categories that are easier to be mistaken as clean.", "description": "This figure shows the average ICD scores for noisy categories in four datasets: CIFAR-10, CIFAR-100, Webvision, and ILSVRC12.  The higher the score, the more likely a noisy example from that category is to be mistaken as clean by the NoiseGPT model.  It highlights the detection biases of NoiseGPT, showing that some noisy categories are more easily misclassified as clean than others.", "section": "4.5 Ablation study"}]