[{"figure_path": "VRRvJnxgQe/tables/tables_6_1.jpg", "caption": "Table 1: Noise detection and rectification performance.", "description": "This table presents the performance of the NoiseGPT model in detecting and rectifying noisy labels.  It shows the Area Under the Receiver Operating Characteristic curve (AUROC) score, which measures the model's ability to distinguish between clean and noisy samples, and the rectification accuracy, which indicates the percentage of noisy labels that were correctly identified and corrected. The table includes results for several datasets with varying levels of noise, demonstrating the model's effectiveness across different scenarios.", "section": "4.2 Performance analysis"}, {"figure_path": "VRRvJnxgQe/tables/tables_7_1.jpg", "caption": "Table 2: Detection performance comparison.", "description": "This table compares the detection performance of NoiseGPT with two baseline methods, DivideMix and Proto-Mix, using precision, recall, and F1-score as evaluation metrics. The results are based on the CIFAR-10 dataset with 80% symmetric noise. NoiseGPT outperforms both baselines in all three metrics, demonstrating its superior ability to detect noisy labels.", "section": "4.3 Quantitative comparison"}, {"figure_path": "VRRvJnxgQe/tables/tables_7_2.jpg", "caption": "Table 3: Noise rectification results.", "description": "This table shows the noise reduction effects of NoiseGPT on CIFAR-10 and CIFAR-100 datasets with varying levels of symmetric and asymmetric noise.  The improvement is substantial, particularly for CIFAR-10 datasets with high noise rates.  The last row indicates the number of clean examples remaining after NoiseGPT's rectification process.", "section": "4.3 Quantitative comparison"}, {"figure_path": "VRRvJnxgQe/tables/tables_7_3.jpg", "caption": "Table 5: Classification on Webvision.", "description": "This table presents the classification accuracy results on the Webvision dataset for various methods.  It shows a comparison of different techniques, highlighting the improvement achieved by integrating NoiseGPT with DivideMix, resulting in the highest accuracy of 78.10%.", "section": "4.3 Quantitative comparison"}, {"figure_path": "VRRvJnxgQe/tables/tables_8_1.jpg", "caption": "Table 4: Classification accuracy comparisons.", "description": "This table presents a comparison of classification accuracy achieved by various methods on CIFAR-10 and CIFAR-100 datasets with different noise levels (symmetric and asymmetric).  It compares the performance of NoiseGPT integrated with other methods (NoiseGPT+M-correction and NoiseGPT+Pro-Mix) against baseline methods like Cross-Entropy, F-correction, Co-teaching+, Mixup, P-correction, Meta-Learning, M-correction, and Pro-Mix.  The results show the impact of NoiseGPT on improving the classification accuracy in the presence of label noise.", "section": "4.3 Quantitative comparison"}, {"figure_path": "VRRvJnxgQe/tables/tables_15_1.jpg", "caption": "Table 6: NoiseGPT hyperparameters.", "description": "This table lists the hyperparameters used in the NoiseGPT experiments.  These parameters control various aspects of the model's operation, including the mixing of features (MoF weight), the number of examples used for each class, the number of perturbations applied to each query, the threshold used for noise detection, and the number of candidate labels considered during label rectification.", "section": "4.1 Experiments setup"}, {"figure_path": "VRRvJnxgQe/tables/tables_15_2.jpg", "caption": "Table 7: Runtime of NoiseGPT.", "description": "This table shows the runtime in hours for NoiseGPT's noise detection and rectification experiments on CIFAR-10 and CIFAR-100 datasets.  Different noise types (symmetric and asymmetric) and levels (20%, 50%, 80%, 90%, and 40%) are considered. The table highlights the computational cost associated with different noise conditions and dataset sizes.", "section": "4.1 Experiments setup"}, {"figure_path": "VRRvJnxgQe/tables/tables_15_3.jpg", "caption": "Table 8: Noise rectification results of CIFAR-N datasets.", "description": "This table presents the noise reduction results achieved by NoiseGPT on CIFAR-10N and CIFAR-100N datasets. It shows the initial noise rate (before NoiseGPT), the noise rate after applying NoiseGPT, and the number of clean samples remaining after the noise reduction process for different noise types (Aggregate, Rand1, Worst for CIFAR-10N, and Noisy for CIFAR-100N).", "section": "4.3 Quantitative comparison"}, {"figure_path": "VRRvJnxgQe/tables/tables_15_4.jpg", "caption": "Table 9: Classification accuracy on CIFAR-N datasets.", "description": "This table presents the classification accuracy results on CIFAR-10N and CIFAR-100N datasets. It compares the performance of two classic noisy label learning methods (M-correction and ProtoMix) with and without the integration of NoiseGPT, demonstrating the effectiveness of NoiseGPT in improving classification accuracy when dealing with noisy labels.", "section": "4.3 Quantitative comparison"}, {"figure_path": "VRRvJnxgQe/tables/tables_16_1.jpg", "caption": "Table 10: NoiseGPT performance on CIFAR datasets.", "description": "This table presents the performance of NoiseGPT on CIFAR-10 and CIFAR-100 datasets with various symmetric and asymmetric noise levels.  For each dataset and noise type, it shows the Area Under the Receiver Operating Characteristic curve (AUROC) score for noise detection and the correction accuracy for label rectification.  Higher AUROC values indicate better noise detection, and higher correction accuracy signifies more effective label rectification.", "section": "4.2 Performance analysis"}, {"figure_path": "VRRvJnxgQe/tables/tables_16_2.jpg", "caption": "Table 11: Comparison of detection bias.", "description": "This table compares the detection biases of NoiseGPT and Proto-Mix*.  It presents the average ICD scores for clean classes that are frequently mistaken as noisy, across 10 different classes, calculated for both methods. The variance (Var) column highlights a key finding: NoiseGPT exhibits significantly lower variance in ICD scores across different classes compared to Proto-Mix*, indicating a more balanced and less biased noise detection process.  In other words, NoiseGPT is less likely to misidentify certain classes as noisy disproportionately compared to the baseline method.", "section": "4.5 Ablation study"}]