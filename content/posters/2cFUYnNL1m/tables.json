[{"figure_path": "2cFUYnNL1m/tables/tables_6_1.jpg", "caption": "Table 1: Accuracy (%) on Huffpost and Arxiv. The best and second best results in the incremental setup are bolded and underlined, respectively. (Huffpost: K = 3, Axriv: K = 7)", "description": "This table presents the accuracy results of different domain generalization methods on the Huffpost and Arxiv datasets.  The results are broken down by whether the method used incremental training, access to multiple domains, and the accuracy on the next unseen domain (DT+1), average accuracy over unseen domains, and worst accuracy over unseen domains.  The best and second-best performing methods in the incremental setting are highlighted.", "section": "5.1 Experimental Setup"}, {"figure_path": "2cFUYnNL1m/tables/tables_7_1.jpg", "caption": "Table 2: Accuracy (%) on Yearbook, RMNIST and fMoW. The best and second best results in the incremental setup are bolded and underlined. (Yearbook: K = 5, RMNIST: K = 3, fMoW: K = 3)", "description": "This table presents the accuracy results of different domain generalization methods on three image datasets: Yearbook, RMNIST, and fMoW.  It compares the performance of these methods in both incremental and non-incremental training settings, showing the average and worst accuracy across out-of-distribution (OOD) test domains. The best and second-best performing methods for each dataset and setting are highlighted.  The table helps illustrate the effectiveness of incremental learning and the relative performance of various approaches.", "section": "5.2 Main Results"}, {"figure_path": "2cFUYnNL1m/tables/tables_7_2.jpg", "caption": "Table 3: (a): Error rate (%) on 2-Moons and ONP (K = 1). (b): Ablation study on RMNIST.", "description": "Table 3 presents the results of two experiments. In (a), the error rates of different methods on the 2-Moons and ONP datasets are reported. In (b), an ablation study on RMNIST is conducted, analyzing the impact of different components of W-Diff on its performance.", "section": "5. Experiments"}, {"figure_path": "2cFUYnNL1m/tables/tables_9_1.jpg", "caption": "Table 4: Accuracy (%) of W-Diff on RMNIST dataset using different conditions. (K = 3)", "description": "This table presents the accuracy results of the W-Diff model on the RMNIST dataset under different conditions.  Two conditions are tested: using the reference point and prototype matrix, and using a scaled reference point and prototype matrix. The accuracy is evaluated for the immediate next domain (D<sup>T+1</sup>) and the average and worst accuracy over multiple unseen future domains (OOD avg. and OOD worst). The results show that using a scaled reference point slightly improves the overall performance.", "section": "5.3 Analytical Experiments"}, {"figure_path": "2cFUYnNL1m/tables/tables_9_2.jpg", "caption": "Table 5: Accuracy (%) of W-Diff on fMoW dataset with different backbones. (K = 3)", "description": "This table shows the accuracy of the W-Diff model on the fMoW dataset using different DenseNet backbones.  It presents the accuracy on the first unseen target domain (DT+1) and the average and worst accuracy across all unseen target domains (OOD avg. and OOD worst). The number of parameters for each backbone is also included to illustrate the trade-off between model complexity and performance.", "section": "Results with Larger Backbones"}, {"figure_path": "2cFUYnNL1m/tables/tables_13_1.jpg", "caption": "Table 1: Accuracy (%) on Huffpost and Arxiv. The best and second best results in the incremental setup are bolded and underlined, respectively. (Huffpost: K = 3, Axriv: K = 7)", "description": "This table presents the accuracy results of various domain generalization methods on the Huffpost and Arxiv datasets.  It compares the performance of these methods in both an offline setting (where all domains are available for training) and an incremental setting (where domains arrive sequentially).  The best and second-best results in the incremental setting are highlighted, providing a clear comparison of performance across different approaches under varying data availability scenarios.  K represents the number of target domains.", "section": "5.1 Experimental Setup"}, {"figure_path": "2cFUYnNL1m/tables/tables_14_1.jpg", "caption": "Table 1: Accuracy (%) on Huffpost and Arxiv. The best and second best results in the incremental setup are bolded and underlined, respectively. (Huffpost: K = 3, Axriv: K = 7)", "description": "This table shows the accuracy of different domain generalization methods on the Huffpost and Arxiv datasets.  The results are broken down by whether the methods were trained incrementally and whether they had access to multiple domains.  The best and second-best results for incremental training are highlighted. The number of target domains (K) is also specified for each dataset.", "section": "5.1 Experimental Setup"}, {"figure_path": "2cFUYnNL1m/tables/tables_15_1.jpg", "caption": "Table 1: Accuracy (%) on Huffpost and Arxiv. The best and second best results in the incremental setup are bolded and underlined, respectively. (Huffpost: K = 3, Axriv: K = 7)", "description": "This table presents the accuracy results of several domain generalization methods on the Huffpost and Arxiv datasets.  The results are categorized by whether the methods allow for access to multiple domains simultaneously or only allow access to sequentially arriving domains. For each method, average and worst-case accuracy across out-of-distribution (OOD) target domains are shown.  The best-performing methods in the incremental setup (meaning only sequentially arriving domains are considered) are highlighted.", "section": "5.1 Experimental Setup"}, {"figure_path": "2cFUYnNL1m/tables/tables_17_1.jpg", "caption": "Table 7: Configuration of the U-Net Ee on different datasets with hybrid conditioning way.", "description": "This table details the hyperparameters used for the U-Net architecture of the conditional diffusion model (Ee).  The table breaks down the configurations based on the specific dataset used, including input shape, diffusion steps, noise schedule, channel settings, depth, attention resolutions, head channels, and transformer depth. It also lists the batch size, learning rate, and optimizer used for training the model for each dataset.  These settings were optimized for each dataset separately to improve the quality of the generated model weights.", "section": "D.2 Network Details"}, {"figure_path": "2cFUYnNL1m/tables/tables_17_2.jpg", "caption": "Table 8: Training details on different datasets.", "description": "This table lists the hyperparameters used for training the task model and conditional diffusion model on eight different datasets.  The hyperparameters include batch size, number of epochs, warm-up hyperparameter, inner iterations for diffusion model training, optimizer, learning rate, loss tradeoff hyperparameter, maximum length of the reference point queue, maximum length of the anchor and prototype queues, and number of generated residual classifier weights.", "section": "Experimental Setup"}, {"figure_path": "2cFUYnNL1m/tables/tables_18_1.jpg", "caption": "Table 9: Memory cost and inference time of diffusion model on different datasets", "description": "This table shows the memory cost (in MB) and inference time (in seconds) required for the conditional diffusion model to generate 32 residual classifier weights within a batch, using a denoising step of 1000.  The results are broken down for different datasets: Yearbook, RMNIST, fMoW, Huffpost, Arxiv, 2-Moons, and ONP.", "section": "E More Results"}]