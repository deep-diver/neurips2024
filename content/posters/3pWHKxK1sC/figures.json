[{"figure_path": "3pWHKxK1sC/figures/figures_2_1.jpg", "caption": "Figure 1: Schematic visualization of the automatic sensitive attribute selection carried out by our Adaptively Fair Conformal Prediction (AFCP) method. This method is designed to find the attribute corresponding to the group most negatively affected by algorithmic bias, on a case-by-case basis.", "description": "The figure shows a schematic of the proposed Adaptively Fair Conformal Prediction (AFCP) method.  AFCP automatically selects a sensitive attribute (e.g., race, gender, age) based on the input test point and the calibration data. The choice of attribute is guided by an analysis of potential model bias, aiming to identify groups most affected by algorithmic unfairness.  Based on this selected attribute (or no attribute if no significant bias is detected), AFCP generates conformal prediction sets.  The example shows three test cases where different attributes were selected, each resulting in prediction sets calibrated to provide valid coverage for the corresponding identified group.", "section": "1 Introduction"}, {"figure_path": "3pWHKxK1sC/figures/figures_3_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by three different methods: marginal, AFCP, and exhaustive.  The marginal method produces prediction sets that have good coverage on average, but poor coverage for certain subgroups, leading to invalid coverage for some individuals.  The exhaustive method guarantees fair coverage across all subgroups, but at the cost of significantly larger and less informative prediction sets. The AFCP method offers a balance between informativeness and fairness, producing smaller prediction sets that still have approximately valid and efficient coverage for all subgroups, by carefully selecting the relevant features to focus on.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_7_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "This figure compares the performance of four conformal prediction methods (AFCP, AFCP1, Marginal, Partial, and Exhaustive) on a synthetic medical diagnosis task. The x-axis represents the total number of training and calibration data points. The y-axis shows three different metrics: coverage for the \"Blue\" group (a minority group with higher algorithmic bias), average coverage across all groups, and the average size of the prediction sets. The results demonstrate that the AFCP method effectively balances efficiency and fairness, achieving good coverage while producing relatively small prediction sets, especially compared to the exhaustive method which tends to be overly conservative.  The marginal method, while efficient, fails to accurately represent uncertainty for the \"Blue\" group, demonstrating the value of the AFCP approach in addressing algorithmic bias.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_7_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "This figure compares prediction sets created by four different methods for two example patients from a group negatively affected by algorithm bias.  The methods are: Marginal, Exhaustive, and the authors' proposed AFCP.  The Marginal method produces small, efficient prediction sets, but these fail to cover the true label for the two patients. The Exhaustive method produces prediction sets that correctly cover the true label, but these sets are too large to be informative. The authors' AFCP method produces prediction sets that are both efficient and cover the true label.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_8_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by different methods for individuals in groups negatively impacted by algorithmic bias.  The methods compared are: Marginal (standard conformal prediction), Exhaustive (conformal prediction with all sensitive attributes protected), and the authors' proposed method, AFCP (Adaptively Fair Conformal Prediction).  AFCP attempts to find a balance between ensuring fair coverage and producing informative predictions (small set sizes).  The example shows that for two patients in a group with significant bias, standard marginal prediction sets fail to cover the true label, exhaustive equalized coverage sets are too large to be informative, and AFCP generates prediction sets that are both fair and efficient.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_27_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure compares the performance of different conformal prediction methods on synthetic medical diagnosis data.  The x-axis shows the sample size (total number of training and calibration data points), while the y-axis shows three metrics: Coverage for the Blue group, Average Coverage (overall), and Average Size of prediction sets.  The results show that AFCP offers a good compromise between efficiency (smaller prediction set sizes) and fairness (good coverage, especially for the group with algorithmic bias).", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_27_2.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure displays the performance of four different conformal prediction methods on synthetic medical diagnosis data.  The methods are compared in terms of coverage, average set size, and coverage for a specific group (Blue) known to be affected by algorithmic bias. AFCP, the proposed method, aims to balance efficiency (small set sizes) and fairness (equal coverage across groups). The results demonstrate that AFCP achieves better coverage for the Blue group while maintaining reasonably small set sizes compared to methods focused solely on equalized coverage (Exhaustive) which produced overly large sets.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_27_3.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure shows the performance comparison of different conformal prediction methods on synthetic medical diagnosis data. The methods are AFCP, AFCP1, Marginal, Partial, and Exhaustive.  The x-axis represents the sample size, and the y-axis shows the coverage for the Blue group, average coverage, and average set size. AFCP consistently achieves valid coverage and smaller prediction set sizes compared to the others, especially the Exhaustive method, showing its efficiency in mitigating algorithmic bias.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_30_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure compares the performance of different methods for constructing prediction sets on synthetic medical diagnosis data.  The x-axis represents the sample size, while the y-axis shows three different metrics: coverage for the Blue group (a group experiencing algorithmic bias), average coverage across all groups, and average prediction set size.  The results demonstrate that the proposed AFCP method produces more informative predictions (smaller set size) and effectively mitigates algorithmic bias by improving the coverage, especially for the disadvantaged Blue group.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_30_2.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "This figure shows the performance comparison of four conformal prediction methods on a synthetic medical diagnosis task with varying dataset sizes.  The methods compared are the proposed AFCP method, a simplified version (AFCP1), a marginal benchmark (ignoring fairness), a partial equalized benchmark (considering each sensitive attribute individually), and an exhaustive equalized benchmark (considering all sensitive attributes simultaneously).  The results demonstrate that the proposed AFCP methods achieve a balance between the marginal method (more efficient predictions, but potentially unfair) and the exhaustive method (fair, but less efficient predictions). AFCP achieves better performance than the others in mitigating bias while maintaining efficiency for moderate and larger dataset sizes.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_31_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure displays the performance comparison of several conformal prediction methods in a synthetic medical diagnosis task.  It illustrates how the proposed AFCP method outperforms other methods (marginal, exhaustive, and partial equalized coverage) by providing more informative predictions (smaller prediction set size) while effectively mitigating algorithmic bias and achieving higher conditional coverage. The results are presented as functions of the sample size (x-axis) and for each method (different colored lines) for three different metrics: conditional coverage for the minority class (Blue group), overall average coverage, and prediction set size. Error bars represent 2 standard errors.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_31_2.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure displays the performance of different conformal prediction methods on a synthetic medical diagnosis task.  The x-axis represents the sample size used for training and calibration. The y-axis shows three different metrics: coverage for a specific group (Blue), average coverage across all groups, and the average prediction set size. The results indicate that the proposed method (AFCP) achieves a good balance between efficiency (smaller prediction sets) and fairness (higher conditional coverage, especially for the disadvantaged group).  Comparison is made against marginal coverage, exhaustive equalized coverage, and a partial equalized coverage benchmark.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_34_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by different methods for individuals in groups disproportionately affected by algorithmic bias.  The Marginal method produces small prediction sets but fails to cover the true label in several cases, indicating undercoverage. The Exhaustive method guarantees equalized coverage across all groups, but at the cost of significantly larger prediction sets, reducing their informativeness.  In contrast, the proposed AFCP method identifies the groups most affected by bias and generates prediction sets that are both informative (small sizes) and well-calibrated (valid coverage) within those groups.", "section": "1 Introduction"}, {"figure_path": "3pWHKxK1sC/figures/figures_34_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "This figure compares prediction sets generated by different methods for patients in groups negatively affected by algorithmic bias.  The marginal method produces small prediction sets but suffers from low coverage for specific groups.  The exhaustive method provides valid coverage for all groups but produces overly conservative (large) prediction sets. The partial method attempts a compromise, but it's still too conservative. The AFCP method (developed by the authors) is shown to provide prediction sets that achieve a balance between efficiency (small sets) and fairness (valid coverage for affected groups) by dynamically selecting the appropriate sensitive attribute.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_35_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by four different methods for two example patients from a group negatively affected by algorithmic bias.  The methods are Marginal (only considers overall accuracy), Exhaustive (equalizes coverage across all sensitive attributes), Partial (equalizes coverage for each individual sensitive attribute), and AFCP (adaptively selects the most relevant sensitive attribute to equalize coverage).  The figure highlights that the Marginal approach results in prediction sets that fail to cover the true label for the biased group, while the Exhaustive method yields sets that are too large and uninformative. The Partial method is an improvement, but AFCP offers the best compromise:  accurate and informative prediction sets.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_35_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "This figure compares prediction sets generated by four different methods for two example patients.  The methods are: Marginal (ignores group fairness), Exhaustive (ensures equal coverage across all subgroups, potentially producing very large sets), Partial (a compromise between the previous two), and AFCP (the authors' method, which aims for equal coverage but only where the model shows bias). The figure illustrates that the marginal method fails to accurately reflect uncertainty for patients in biased subgroups. The exhaustive method is overly cautious and uninformative. AFCP, by contrast, produces relatively small and accurate prediction sets, striking a balance between efficiency and fairness.", "section": "1 Introduction"}, {"figure_path": "3pWHKxK1sC/figures/figures_35_3.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares the prediction sets generated by different methods for patients in groups disproportionately affected by algorithmic bias.  It shows that the marginal method produces sets that are too small and fail to cover the true label for biased groups, leading to invalid coverage. The exhaustive method, aiming for equalized coverage across all sensitive attributes, produces sets that are too large and uninformative.  In contrast, the proposed AFCP method dynamically selects the relevant sensitive attribute, creating prediction sets that are well-calibrated for the biased group while maintaining informativeness (smaller set size).", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_39_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by four methods: Marginal, Exhaustive, Partial and the proposed AFCP method. For two example patients from a group negatively affected by algorithm bias, Marginal prediction sets fail to cover the true label.  Exhaustive prediction sets are too conservative to be informative. The AFCP method generates efficient and fair prediction sets by using an automatically identified sensitive attribute to calibrate prediction sets only for groups actually affected by algorithmic bias, achieving a balance between accuracy and fairness.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_39_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "This figure compares the prediction sets generated by different methods for patients in groups negatively impacted by algorithmic bias.  The methods are:\n\n1. **Marginal:**  Prediction sets with only marginal coverage guarantees (i.e., overall coverage, but not necessarily equal coverage across all subgroups).\n2. **AFCP:** The authors' proposed method (Adaptively Fair Conformal Prediction), which aims for valid coverage conditional on an adaptively chosen sensitive attribute.  The attribute is selected based on which group is most negatively affected by bias.\n3. **Exhaustive:** Prediction sets that guarantee equal coverage across all subgroups defined by all sensitive attributes. This often leads to overly large, uninformative prediction sets.\n\nThe figure showcases that marginal prediction sets fail to cover the true labels for some patients in the biased group, while the exhaustive method's prediction sets are too broad. The authors' AFCP method, however, aims to strike a balance between efficiency and fairness, achieving valid coverage within the biased group with more manageable prediction set sizes.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_40_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "This figure shows the results of a comparison of several methods for constructing prediction sets on synthetic medical diagnosis data. The x-axis represents the sample size used for training and calibration, and the y-axis shows various metrics including conditional coverage, average coverage, and average set size. The key finding is that the proposed AFCP method produces smaller prediction sets while maintaining good conditional coverage, which is particularly important for mitigating algorithmic bias.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_40_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by four different methods for two example patients from a group negatively impacted by algorithmic bias. The methods compared are:\n\n1. **Marginal**: Prediction sets with marginal coverage only (no fairness considerations).\n2. **Exhaustive**: Prediction sets that guarantee valid coverage across all sensitive attributes (most conservative, potentially uninformative).\n3. **Partial**: Prediction sets that guarantee valid coverage across each sensitive attribute individually (less conservative than exhaustive, still potentially uninformative).\n4. **AFCP (Adaptively Fair Conformal Prediction)**: The authors' proposed method, which aims to provide a practical compromise between efficiency and fairness by adaptively choosing the most relevant sensitive attribute for equalized coverage. \n\nFor each method, prediction sets are shown for two patients (one for asthma, the other for stroke). Note that only the AFCP method provides prediction sets that are both informative and demonstrate valid coverage for the negatively impacted group.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_40_3.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by four different methods: Marginal, Exhaustive, Partial, and AFCP for two patients from groups negatively affected by algorithm bias. The Marginal method produces small prediction sets but exhibits invalid coverage. Conversely, the Exhaustive method produces valid coverage but the sets are too large to be informative. The Partial method shows a compromise between Marginal and Exhaustive, but it is still conservative. The AFCP method provides well-calibrated and efficient prediction sets.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_40_4.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "This figure compares prediction sets generated by four different methods for two example patients from a group negatively impacted by algorithmic bias.  The methods compared are:\n\n1. **Marginal:** Prediction sets with only marginal coverage guarantees.\n2. **AFCP:**  Prediction sets from the authors' proposed method (Adaptively Fair Conformal Prediction), which guarantees coverage conditional on the most biased group, dynamically identified by the algorithm.\n3. **Exhaustive:** Prediction sets using all sensitive attributes to ensure equalized coverage across all groups (very conservative).\n4. **Partial:** Prediction sets obtained by taking the union of those generated using each sensitive attribute separately (less conservative than exhaustive, but still less informative than AFCP).\n\nThe figure shows that for the two example patients, the marginal method fails to cover the true label, while the exhaustive method is overly conservative. AFCP strikes a balance, providing well-calibrated prediction sets while effectively mitigating the algorithmic bias for the most sensitive group.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_44_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure shows the performance comparison of different conformal prediction methods on a synthetic medical diagnosis task, varying the sample size used for training and calibration.  The key metric is conditional coverage (accuracy of predictions within specific groups) and average prediction set size (informativeness).  AFCP demonstrates improved conditional coverage for a group disproportionately affected by algorithmic bias, achieving this with smaller prediction sets than other methods.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_44_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "This figure compares prediction sets generated by four different methods for two example patients from a group negatively affected by algorithmic bias.  The methods compared are Marginal, Exhaustive, Partial, and the proposed AFCP method. The figure highlights how the Marginal method fails to provide valid coverage while the Exhaustive method produces overly conservative predictions.  The AFCP method, in contrast, provides informative predictions that are well-calibrated for the group by accounting for algorithmic bias.", "section": "1 Introduction"}, {"figure_path": "3pWHKxK1sC/figures/figures_45_1.jpg", "caption": "Figure 4: Selection frequency of different attributes using our AFCP method and its variation, AFCP1, in the experiments of Figure 3. As the sample size increases, AFCP becomes more consistent in selecting the most relevant attribute, Color.", "description": "This figure shows how often each sensitive attribute is selected by the AFCP and AFCP1 methods as the sample size increases.  AFCP1 always selects an attribute regardless of a statistical test for bias, while AFCP only selects if bias is detected.  As the sample size grows, AFCP becomes more reliable at selecting the attribute showing the greatest bias (Color).", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_46_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by four different methods for two example patients from a group negatively impacted by algorithmic bias.  The methods are: Marginal (only considers overall average coverage), Exhaustive (guarantees equal coverage across all sensitive attributes), Partial (guarantees equal coverage for each sensitive attribute individually), and AFCP (the proposed method that adaptively selects the most relevant sensitive attribute for equalized coverage).  The figure shows that Marginal fails to accurately reflect the uncertainty for the biased group, Exhaustive produces overly large and uninformative prediction sets, and Partial is less informative than AFCP. AFCP strikes a balance between accuracy and fairness, producing more useful predictions.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_46_2.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "This figure compares the performance of different conformal prediction methods on synthetic medical diagnosis data.  The x-axis represents the sample size used for training and calibration, and the y-axis shows three different metrics: conditional coverage for the 'Blue' group (a group designed to have algorithmic bias), average coverage across all groups, and the average size of the prediction sets.  AFCP consistently achieves higher conditional coverage for the biased group compared to other methods (Marginal, Exhaustive, Partial) while maintaining relatively small prediction set sizes, demonstrating its effectiveness in mitigating bias. Error bars indicate 2 standard deviations.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_47_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure compares the performance of different conformal prediction methods on synthetic medical diagnosis data.  It shows how prediction set size and coverage vary with the total number of training and calibration data points. The proposed AFCP method outperforms other methods in terms of providing smaller (more informative) prediction sets while maintaining or improving coverage, especially for the group most affected by algorithmic bias.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_47_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by different methods for individuals from groups negatively impacted by algorithmic bias.  The methods compared include Marginal (only considering overall accuracy), Exhaustive (considering all sensitive attributes for equalized coverage, which can be overly conservative), and the proposed AFCP method.  AFCP adaptively selects a sensitive attribute to focus on, leading to prediction sets that provide a balance between accuracy and fairness by equalizing coverage for only the groups truly needing it.  The examples shown highlight that AFCP avoids both the undercoverage issues of the Marginal method and the overly conservative predictions of the Exhaustive method, providing more informative results.", "section": "1 Introduction"}, {"figure_path": "3pWHKxK1sC/figures/figures_47_3.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "This figure compares the performance of several conformal prediction set construction methods on a synthetic medical diagnosis dataset. The x-axis shows the total sample size used for training and calibration.  The y-axis displays three metrics: coverage for the 'Blue' group, average coverage across all groups, and average set size.  The results show that the AFCP method achieves good coverage while maintaining relatively small prediction set sizes, outperforming other methods, especially in mitigating algorithmic bias affecting the 'Blue' group. Error bars represent two standard errors.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_49_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by several methods for two example patients from a group negatively affected by algorithmic bias.  The \"Marginal\" method produces small prediction sets but with invalid coverage for the biased group. The \"Exhaustive\" method guarantees valid coverage but results in overly large, uninformative sets.  The proposed \"AFCP\" method provides prediction sets that are both efficient and fair, achieving valid coverage for the biased group without being overly conservative.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_50_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by four different methods for patients in groups disproportionately affected by algorithmic bias.  The methods are: Marginal, Exhaustive, Partial, and AFCP (the authors' proposed method).  The example shows that the Marginal method fails to cover the true label for two example patients. The Exhaustive method produces valid but overly conservative prediction sets.  The Partial method offers an improvement over Marginal but is still relatively large.  The authors' AFCP method provides informative and well-calibrated prediction sets conditional on the automatically selected sensitive attribute.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_50_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "This figure compares the prediction sets generated by four different methods for two example patients from a group negatively impacted by algorithmic bias. The methods compared are: Marginal (baseline), Exhaustive (ensures equalized coverage across all sensitive attributes, which can be too conservative), Partial (ensures equalized coverage for each sensitive attribute individually, but might not be sufficient), and AFCP (the proposed method, which adaptively selects the most critical attribute for equalized coverage). The figure shows that the Marginal method fails to cover the true label for both patients, Exhaustive generates overly conservative sets, and Partial provides improvements but is still not optimal. AFCP effectively balances efficiency and fairness, generating informative and well-calibrated prediction sets.", "section": "1 Introduction"}, {"figure_path": "3pWHKxK1sC/figures/figures_50_3.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure shows the performance of different conformal prediction methods on synthetic medical diagnosis data.  The x-axis represents the sample size (total number of training and calibration data points), and the y-axis shows different metrics: coverage for the Blue group, average coverage across all groups, and average set size.  The results show that the proposed AFCP method provides prediction sets with smaller average size and better coverage, especially for the underrepresented Blue group, compared to standard marginal conformal prediction, exhaustive equalized coverage, and partial equalized coverage.  Error bars represent 2 standard errors, indicating the variability in the results.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_51_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by different methods for individuals in groups disproportionately affected by algorithmic bias.  The methods shown are:\n\n* **Marginal:** Standard conformal prediction sets with marginal coverage guarantees.\n* **AFCP:** Adaptive Fair Conformal Prediction, the authors' proposed method, which selects a sensitive attribute to equalize coverage within subgroups and provides more informative prediction sets.\n* **Exhaustive:** Conformal prediction sets with exhaustive equalized coverage, which guarantee valid coverage for all possible combinations of sensitive attributes. These sets tend to be overly conservative, leading to less informative predictions.\n\nThe figure highlights that standard marginal methods can fail to cover the true label for individuals in biased groups.  The exhaustive method provides valid coverage but generates overly large prediction sets that are not useful. The authors' AFCP method is designed to provide a balance between the two approaches, offering valid coverage and informative prediction sets.  The example showcases the superior performance of AFCP in addressing biases.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_52_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by four different methods for two example patients from a group negatively affected by algorithmic bias. The methods compared are: Marginal (no bias correction), Exhaustive (bias correction for all sensitive attributes), Partial (bias correction for each sensitive attribute separately), and AFCP (adaptive bias correction for the most relevant attribute). For both patients, the Marginal method fails to cover the true label, indicating bias, while the Exhaustive method produces overly conservative sets. The Partial method is better, but still not as informative as the AFCP method, which produces appropriately sized and well-calibrated prediction sets.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_52_2.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by different methods for individuals from groups disproportionately affected by algorithmic bias.  The methods compared are: Marginal (standard conformal prediction), Exhaustive (equalized coverage across all sensitive attributes), and AFCP (the proposed method).  The figure shows that Marginal prediction sets fail to cover the true label for two example patients from a disadvantaged group.  Exhaustive prediction sets achieve fair coverage but are too conservative, leading to uninformative predictions.  The AFCP method provides a more practical solution with both efficient and fair prediction sets.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_53_1.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure shows the performance comparison of different conformal prediction methods on a synthetic medical diagnosis task.  The x-axis represents the total sample size used for training and calibration. The y-axis shows three different metrics: coverage for the group with algorithmic bias (Color=Blue), average coverage across all groups, and the average size of prediction sets.  The results demonstrate that the proposed AFCP method provides a good balance between efficiency and fairness. It offers informative predictions (smaller set sizes) while achieving valid coverage for groups affected by algorithmic bias, unlike the marginal method which undercovers, and the exhaustive method that is too conservative. AFCP1, a variation always selecting an attribute, exhibits slightly more robust performance at smaller sample sizes.", "section": "3 Numerical Experiments"}, {"figure_path": "3pWHKxK1sC/figures/figures_55_1.jpg", "caption": "Figure 2: Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.", "description": "The figure compares prediction sets generated by different methods for individuals in groups disproportionately affected by algorithmic bias.  It highlights three methods: Marginal (ignoring fairness), Exhaustive (guaranteeing equalized coverage across all groups but potentially inefficient and uninformative), and the proposed Adaptive Fair Conformal Prediction (AFCP) method. AFCP adaptively selects the most relevant sensitive attribute to address bias. The figure shows that, for certain patients, the marginal method produces prediction sets that do not achieve proper coverage, exhaustive methods produce large, uninformative sets, and only AFCP achieves good coverage within the affected group while maintaining efficiency.", "section": "1.3 Preview of Our Contributions: Adaptive Equalized Coverage"}, {"figure_path": "3pWHKxK1sC/figures/figures_55_2.jpg", "caption": "Figure 3: Performance of conformal prediction sets constructed by different methods on synthetic medical diagnosis data, as a function of the total number of training and calibration data points. Our method (AFCP) leads to more informative prediction sets (smaller average size) with more effective mitigation of algorithmic bias (higher conditional coverage). The error bars indicate 2 standard errors.", "description": "The figure shows the performance comparison of different conformal prediction methods on a synthetic medical diagnosis task. The x-axis represents the sample size, and the y-axis shows three metrics: coverage for the \"Blue\" group (a specific group that suffers from algorithmic bias), average coverage across all groups, and average prediction set size.  The results demonstrate that AFCP achieves a good balance between efficiency (smaller prediction sets) and fairness (higher coverage for the minority group), outperforming other methods.", "section": "3 Numerical Experiments"}]