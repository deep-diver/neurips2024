[{"figure_path": "h2e4G2YiwR/figures/figures_1_1.jpg", "caption": "Figure 1: Qualitative comparisons of TwinAct with other methods. TwinAct preserves the identity consistency of actors while allowing customized actions to be accurately generalized across different actors by effectively decoupling actions and actors.", "description": "This figure shows a qualitative comparison of TwinAct against other methods for generating customized action images.  Each row represents a different action (e.g., three-point landing), and each column represents a different method.  The results demonstrate that TwinAct is superior at maintaining the visual identity of the actors while also accurately generating the specified actions, even across different actors. Other methods struggle to separate the actor from the action, leading to inconsistencies and less accurate results.", "section": "1 Introduction"}, {"figure_path": "h2e4G2YiwR/figures/figures_3_1.jpg", "caption": "Figure 2: The construction of Common Action Space.", "description": "This figure illustrates the process of constructing a Common Action Space for representing actions.  It starts with filtering actions that are known to a Text-Guided Diffusion Model (TGDM) from those unknown to the model.  Action phrases are generated using GPT-4 and then tokenized and embedded.  These embeddings undergo Principal Component Analysis (PCA) to create the common action space.  Finally, action adjustment and composition are shown, indicating how customized actions can be built as combinations of basic actions within the common action space.", "section": "3 Methods"}, {"figure_path": "h2e4G2YiwR/figures/figures_4_1.jpg", "caption": "Figure 3: The overview of the proposed TwinAct. We optimize the coefficients of the action bases to avoid encoding the action-irrelevant features. After training, we combine the learned coefficients and shared action base to generate images with the customized action.", "description": "This figure shows a schematic overview of the TwinAct model architecture.  The process begins with a user-provided image and text prompt. The prompt is tokenized and processed by a text transformer.  An action encoder extracts action features from the input image. These features are used by an MLP to adjust weights for a set of action bases in a common action space.  The weighted action bases are used to modulate the coefficients of the LoRA layers within the text-to-image decoder.  The decoder generates a denoised image, and the action similarity loss refines the generated image based on the action similarity between the generated image and the input image.  The final output is a generated image with a customized action, while minimizing the inclusion of action-irrelevant features.", "section": "3 Methods"}, {"figure_path": "h2e4G2YiwR/figures/figures_6_1.jpg", "caption": "Figure 4: The results of customized action generation with TwinAct. TwinAct generates images of different actors performing customized actions such as celebrities and animals, and maintains the consistency of the action and identity of the subject.", "description": "This figure showcases the results of the TwinAct model in generating images with customized actions performed by various subjects, including celebrities and animals.  The key takeaway is the model's ability to maintain both the fidelity of the customized action and the identity consistency of the actor, even when the actor is different across images.  The results demonstrate the model's flexibility and robustness in handling diverse contexts and subjects.", "section": "4 Experiment"}, {"figure_path": "h2e4G2YiwR/figures/figures_7_1.jpg", "caption": "Figure 4: The results of customized action generation with TwinAct. TwinAct generates images of different actors performing customized actions such as celebrities and animals, and maintains the consistency of the action and identity of the subject.", "description": "This figure showcases the results of the TwinAct model in generating images of various actors performing customized actions.  The model successfully generates images where actors (celebrities, animals) perform actions specified by user input. Importantly, it demonstrates the model's ability to maintain consistency in the action's performance across different actors while preserving the actor's identity. This highlights the model's capability to decouple actions and actors effectively.", "section": "4 Experiment"}, {"figure_path": "h2e4G2YiwR/figures/figures_8_1.jpg", "caption": "Figure 3: The overview of the proposed TwinAct. We optimize the coefficients of the action bases to avoid encoding the action-irrelevant features. After training, we combine the learned coefficients and shared action base to generate images with the customized action.", "description": "This figure shows a schematic overview of the TwinAct model.  It illustrates the process of generating customized action images, starting with a textual prompt (V*) and exemplar images. TwinAct uses a multi-layer perceptron (MLP) to optimize the coefficients of action bases within a common action space. These optimized coefficients and the action bases are then combined to generate images of the customized action, minimizing action-irrelevant details. The model incorporates both reconstruction loss and action similarity loss during training to improve accuracy and generalization.", "section": "3 Methods"}, {"figure_path": "h2e4G2YiwR/figures/figures_13_1.jpg", "caption": "Figure 8: Comparing the results generated by TwinAct and fine-grained textual descriptions. The results show that customized actions are difficult to describe and that existing text-to-image generation models do not accurately follow textual instructions even when fine-grained textual descriptions are provided.", "description": "This figure compares the results of generating customized action images using TwinAct and Stable Diffusion. It demonstrates that even when using very detailed textual descriptions, Stable Diffusion struggles to accurately generate the intended actions, while TwinAct is successful. This highlights TwinAct's ability to understand and generate accurate action images despite limitations in textual description.", "section": "4.2 Qualitative Comparison"}, {"figure_path": "h2e4G2YiwR/figures/figures_13_2.jpg", "caption": "Figure 9: Comparison of results generated by TwinAct and sketch-based generation models. The results show that it is difficult for the user to provide a suitable sketch for generating customized action images. The results generated with skeleton images show it is difficult to capture the details of the action such as fingers, while the results generated with line images are limited in generalization, especially when it involves animals.", "description": "This figure compares the image generation results of TwinAct against sketch-based methods like ControlNet.  The comparison highlights that using sketches as input for generating customized actions is challenging. ControlNet struggles to capture fine details (like fingers) when using skeleton-style input sketches, while using line-style sketches limits the diversity and generalization of generated images, especially when the actions involve animals. TwinAct, in contrast, generates images with better detail and broader applicability.", "section": "4.2 Qualitative Comparison"}, {"figure_path": "h2e4G2YiwR/figures/figures_14_1.jpg", "caption": "Figure 10: Comparing the results of generating customized actors to perform customized actions generated by TwinAct and other methods. TwinAct can better maintain the identity consistency of the subject in the generated image, and the fidelity of the action.", "description": "This figure compares the performance of TwinAct against other methods for generating images of customized actors performing customized actions.  The results show that TwinAct excels at maintaining both the identity of the actor and the accuracy of the action in the generated image, unlike the other methods which struggle to balance these aspects.", "section": "4.2 Qualitative Comparison"}, {"figure_path": "h2e4G2YiwR/figures/figures_16_1.jpg", "caption": "Figure 4: The results of customized action generation with TwinAct. TwinAct generates images of different actors performing customized actions such as celebrities and animals, and maintains the consistency of the action and identity of the subject.", "description": "This figure shows example results from the TwinAct model.  It demonstrates the model's ability to generate images of various actors (celebrities, animals) performing a customized action while preserving both the action's characteristics and the actor's identity.  The top row shows the example action image used as input; subsequent rows showcase the generated images with various actors executing that same action.", "section": "4 Experiment"}]