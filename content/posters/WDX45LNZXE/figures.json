[{"figure_path": "WDX45LNZXE/figures/figures_2_1.jpg", "caption": "Figure 1: Illustration of data distribution in Assumption 1 on S\u00b2 and the corresponding ground-truth division of S\u00b2 generated by one-nearest neighbor. (1) In the left panel, the red and blue points correspond to the xi with y = 1 and \u22121 for i \u2208 [N], respectively, with N = 500. (2) In the right panel, the color of every point on the sphere is the same as its closest neighbor in {xi}i\u2208[N]. The sphere is thus split into divisions by the one-nearest-neighbor decision rule.", "description": "This figure illustrates the data distribution used in the paper's theoretical analysis. The left panel shows sampled points on a 2D sphere, colored red or blue based on their label (y = 1 or y = -1).  The right panel shows the same sphere, but now colored according to the one-nearest-neighbor (1-NN) prediction rule.  Each point's color represents the label of its nearest neighbor among the sampled points, demonstrating how the 1-NN rule partitions the sphere.", "section": "Preliminaries"}, {"figure_path": "WDX45LNZXE/figures/figures_3_1.jpg", "caption": "Figure 2: Heatmap and landscape of loss function of single layer transformer when learning from one-nearest neighbor. The loss is defined in Eq. (2.5), generated by sampling 100 training sequences according to Assumption 1, with d = N = 4. We parametrize W as diag{\u00a71,..., \u00a71, 0, \u00a72}.", "description": "The figure visualizes the loss landscape of a single-layer transformer trained to perform one-nearest neighbor classification.  It displays both a heatmap and a 3D surface plot showing how the loss function varies with two parameters, \u00a71 and \u00a72, which represent weights in the transformer's attention layer.  The training data is generated according to Assumption 1 with d=N=4, implying data points on a 3D sphere (d-1 dimensions) and a sample size of 4. The highly non-convex and irregular nature of the loss landscape is clearly demonstrated, making the optimization problem challenging.", "section": "2.2 One-Layer Softmax Attention Transformers"}, {"figure_path": "WDX45LNZXE/figures/figures_8_1.jpg", "caption": "Figure 3: Prediction error for single softmax attention layer as a function of gradient iteration number. (1) The left panel shows the convergence of loss function during the training process. (2) The right pannel shows the MSE between the trained model and a 1-NN predictor on a well-separated testing dataset under distribution shift, as we discuss in Section 5. Curves and error bars in both panels are computed as twice the standard deviation based on 10 independent trials.", "description": "This figure shows the training and testing results of a single-layer transformer trained on a one-nearest neighbor task.  The left panel displays the training loss convergence for different dataset sizes and input dimensions, demonstrating successful minimization of the loss function despite its non-convex nature. The right panel illustrates the model's performance on a testing dataset with a different distribution than the training data.  Despite the distribution shift, the model exhibits low mean squared error (MSE), closely matching the performance of a one-nearest neighbor classifier.", "section": "Numerical Results"}]