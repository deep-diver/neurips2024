[{"figure_path": "f8MrWxlnRz/tables/tables_7_1.jpg", "caption": "Table 1: Detection performance comparison on all three datasets along with their challenging subsets", "description": "This table presents a quantitative comparison of the proposed AIRS model against several state-of-the-art (SOTA) object detection models on three benchmark datasets: MS COCO, Pascal VOC 2012, and Google Open Images V4.  For each dataset, results are shown for the standard evaluation split, as well as a specifically created \"challenging subset\" designed to evaluate performance on more difficult images with complex scenes and numerous small objects. The metrics used for comparison include Average Precision (AP), as well as AP for small, medium, and large objects (APS, APM, APL, respectively), and AP on the challenging subset (APCH).", "section": "4 Quantitative Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_7_2.jpg", "caption": "Table 1: Detection performance comparison on all three datasets along with their challenging subsets", "description": "This table presents a quantitative comparison of the proposed AIRS model against various state-of-the-art (SOTA) object detection models on three benchmark datasets: MS COCO, Pascal VOC 2012, and Google Open Images V4.  For each dataset, the performance is evaluated using Average Precision (AP), broken down by object size (APS for small objects, APM for medium, APL for large) and also on a challenging subset of images (APCH) designed to evaluate performance in complex scenes.  The table allows for a direct comparison of the proposed method against both one-stage and two-stage detectors, highlighting its strengths and potential weaknesses across different scenarios.", "section": "4 Quantitative Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_7_3.jpg", "caption": "Table 3: Inference speed comparison", "description": "This table compares the inference speed and the number of parameters of different models.  It shows that AIRS, despite being a novel object detection method using reinforcement learning, achieves comparable inference speed to other state-of-the-art (SOTA) one-stage and two-stage object detectors.", "section": "4 Experiments"}, {"figure_path": "f8MrWxlnRz/tables/tables_7_4.jpg", "caption": "Table 4: RL baseline comparison", "description": "This table compares the performance of the proposed AIRS model against other existing RL-based object detection methods.  The mAP (mean Average Precision) metric is used to evaluate the performance of each model.  AIRS significantly outperforms the other methods.", "section": "4 Experiments"}, {"figure_path": "f8MrWxlnRz/tables/tables_8_1.jpg", "caption": "Table 5: Ablation study on model design choices", "description": "This ablation study analyzes the impact of different model design choices, including positive anchor criterion choices and the epistemic uncertainty design in evidential Q-learning, on the object detection performance. The results show that DIoU is the most effective positive anchor criterion and that the epistemic uncertainty significantly improves detection performance.", "section": "4.5 Ablation Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_14_1.jpg", "caption": "Table 1: Detection performance comparison on all three datasets along with their challenging subsets", "description": "This table presents a comparison of the proposed AIRS model's object detection performance against various state-of-the-art (SOTA) methods across three benchmark datasets: MS COCO, Pascal VOC 2012, and Open Images V4.  For each dataset, the performance is evaluated using Average Precision (AP), and further broken down into AP for small, medium, and large objects (APS, APM, APL).  Additionally, a challenging subset ('CH') of images from each dataset is used for evaluation to highlight the model's robustness in handling complex scenes.  The results demonstrate AIRS's superior performance, particularly in detecting small objects and in challenging scenarios.", "section": "4 Quantitative Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_23_1.jpg", "caption": "Table 1: Detection performance comparison on all three datasets along with their challenging subsets", "description": "This table presents a quantitative comparison of the proposed AIRS model against several state-of-the-art (SOTA) object detection methods across three benchmark datasets: MS COCO, Pascal VOC 2012, and Google Open Images V4.  For each dataset, the performance is evaluated using Average Precision (AP), and broken down further into AP for small, medium, and large objects (APS, APM, APL).  Additionally, a challenging subset ('CH') of images is used for evaluation, focusing on more complex scenarios with smaller objects, object overlaps, and dense object arrangements. The results highlight the superior performance of AIRS, especially in the challenging subsets and small objects.", "section": "4 Quantitative Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_23_2.jpg", "caption": "Table 1: Detection performance comparison on all three datasets along with their challenging subsets", "description": "This table presents a comparison of the object detection performance of the proposed AIRS model against several state-of-the-art (SOTA) methods across three benchmark datasets: MS COCO, Pascal VOC 2012, and Google Open Images V4.  For each dataset, the table includes results for the standard evaluation split and a challenging subset designed to evaluate the models' robustness on more complex scenes. The performance metrics reported are Average Precision (AP), and its breakdown into AP for small (APS), medium (APM), and large (APL) objects and AP for the challenging subset (APCH).", "section": "4 Quantitative Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_23_3.jpg", "caption": "Table 9: AP performance of AIRS on the aerial parking lot dataset [16] and newly created MSCOCO challenging subset, both containing a large number of cluttered small objects in one image, besides few medium or large objects.", "description": "This table presents a comparison of the Average Precision (AP) metric for GFocal and AIRS on two challenging datasets: an aerial parking lot dataset and a newly created subset of the MS COCO dataset.  Both datasets are characterized by a high density of small, cluttered objects, making object detection particularly difficult.  The AP, AP<sup>S</sup>, AP<sup>M</sup>, and AP<sup>L</sup> columns represent the overall average precision and average precision for small, medium, and large objects, respectively.  The results demonstrate AIRS's improved performance, especially on these challenging datasets.", "section": "4.3 Quantitative Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_24_1.jpg", "caption": "Table 10: Ablation on RL masks trained on Different Detector Backbones", "description": "This table presents the ablation study results focusing on the impact of different base detectors on the performance of RL masks.  It compares the Average Precision (AP), Average Precision for small objects (APS), Average Precision for medium objects (APM), Average Precision for large objects (APL), and Average Precision on a challenging subset (APCH) across three different one-stage detectors (RetinaNet, FCOS, ATSS). For each detector, it shows the results without RL augmentation, with RL augmentation trained on its own FPN, and with RL masks transferred from another detector. The results indicate the effectiveness of RL masks in enhancing the performance across all detectors and datasets.", "section": "4.5 Ablation Study"}, {"figure_path": "f8MrWxlnRz/tables/tables_24_2.jpg", "caption": "Table 1: Detection performance comparison on all three datasets along with their challenging subsets", "description": "This table presents a quantitative comparison of the proposed AIRS model against several state-of-the-art (SOTA) object detection methods across three benchmark datasets: MS COCO, Pascal VOC 2012, and Google Open Images V4.  For each dataset, performance is evaluated using Average Precision (AP), and broken down further by object size (small, medium, large) and a challenging subset of images.  The challenging subset contains images with complex scenes, significant object occlusion, and a higher proportion of smaller objects, designed to assess the models' robustness in more difficult scenarios.", "section": "4 Quantitative Study"}]