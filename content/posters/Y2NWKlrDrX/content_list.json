[{"type": "text", "text": "Conformal Inverse Optimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Bo Lin Erick Delage Timothy C. Y. Chan University of Toronto HEC Montr\u00e9al University of Toronto blin@mie.utoronto.ca Mila \u2013 Qu\u00e9bec AI Institute Vector Institute erick.delage@hec.ca tcychan@mie.utoronto.ca ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Inverse optimization has been increasingly used to estimate unknown parameters in an optimization model based on decision data. We show that such a point estimation is insufficient in a prescriptive setting where the estimated parameters are used to prescribe new decisions. The prescribed decisions may be of low-quality and misaligned with human intuition and thus are unlikely to be adopted. To tackle this challenge, we propose conformal inverse optimization, which seeks to learn an uncertainty set for the unknown parameters and then solve a robust optimization model to prescribe new decisions. Under mild assumptions, we show that our method enjoys provable guarantees on solution quality, as evaluated using both the ground-truth parameters and the decision maker\u2019s perception of the unknown parameters. Our method demonstrates strong empirical performance compared to classic inverse optimization. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Inverse optimization (IO) is a supervised learning approach that fits parameters in an optimization model to decision data. The ftited optimization model can then be used to prescribe future decisions. Such problems naturally arise in AI applications where human preferences are not explicitly given, and instead need to be inferred from historical decisions. For this pipeline to succeed in practice, the prescribed decision should not only be of high quality but also align with human intuition (i.e., perceived to be of high-quality). The latter encourages algorithm adoption (Chen et al., 2023; Donahue et al., 2023), which is critical in many real-world settings (Liu et al., 2023; Sun et al., 2022). ", "page_idx": 0}, {"type": "text", "text": "As an example, rideshare platforms, e.g., Uber and Lyft, provide a shortest-path to the driver at the start of a trip based on real-time traffic data (Nguyen, 2015). The driver then relies on her perception of the road network formed through past experience to evaluate the path. The driver may deviate from the suggested path if it is perceived to be low-quality. Although seasoned drivers are often capable of identifying a better path due to their tacit knowledge of the road network (Merch\u00e1n et al., 2022), such deviations impose operational challenges as it may cause rider safety concerns and affect downstream decisions, such as arrival time estimation, trip pricing, and rider-driver matching (Hu et al., 2022). Therefore, the platform may be interested in leveraging historical paths taken by drivers to suggest high-quality paths for future trips, as evaluated using both the travel time and the driver\u2019s perception. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we first show that the classic IO pipeline may generate decisions that are low-quality and misaligned with human intuition. We next propose conformal IO, which first learns an uncertainty set from decision data and then solves a robust optimization model with the learned uncertainty set to prescribe decisions. Finally, we show that the proposed approach has provable guarantees on the actual and perceived solution quality. Our contributions are as follows. ", "page_idx": 0}, {"type": "text", "text": "New framework. We propose a new IO pipeline that integrates i) a novel method to learn uncertainty sets from decision data and ii) a robust optimization model for decision recommendation. ", "page_idx": 0}, {"type": "text", "text": "Theoretical guarantees. We prove that, with high probability, the learned uncertainty set contains parameters that make future observed decisions optimal. This coverage guarantee leads to bounds on the optimality gap of the decisions from conformal IO, as evaluated using the ground-truth parameters and the decision maker\u2019s (DM\u2019s) perceived parameters. ", "page_idx": 1}, {"type": "text", "text": "Performance. Through experiments, we demonstrate strong empirical performance of conformal IO compared to classic IO and provide insights into modeling choices. ", "page_idx": 1}, {"type": "text", "text": "2 Literature Review ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Inverse optimization. IO is a method to estimate unknown parameters in an optimization problem based on decision data (Ahuja and Orlin, 2001; Chan et al., 2014; Chan and Kaw, 2020). Early IO papers focus on deterministic settings where the observed decisions are assumed to be optimal to the specified optimization model. Recently, IO has been extended to stochastic settings where the observed decisions are subject to errors and bounded rationality. Progress has been made to provide estimators that are consistent (Aswani et al., 2018; Dong et al., 2018), tractable (Chan et al., 2019; Tan et al., 2020), and robust to data corruption (Mohajerin Esfahani et al., 2018). Our paper is in the stochastic stream. Unlike existing methods that provide a point estimation of the unknown parameters, we learn an uncertainty set that can be used in a robust optimization model. ", "page_idx": 1}, {"type": "text", "text": "Data-driven uncertainty set construction. Recently, data have become a critical ingredient to design the structure (Delage and Ye, 2010; Mohajerin Esfahani et al., 2018; Gao and Kleywegt, 2023) and calibrate the size (Chenreddy et al., 2022; Sun et al., 2023) of an uncertainty set. Our paper is related to the work of Sun et al. (2023) who first use an ML model to predict the unknown parameters and then calibrate an uncertainty set around the prediction. However, this approach does not apply in our setting as it requires observations of the unknown parameters, which we do not have access to. Our paper presents the first method to calibrating uncertainty sets using decision data. ", "page_idx": 1}, {"type": "text", "text": "Estimate, then optimize. Conformal IO belongs to a family of data-driven optimization methods called \u201cestimate, then optimize\u201d (Elmachtoub et al., 2023). Recent research suggests that even small estimation errors may be amplified in the optimization step, resulting in significant decision errors. This issue can be mitigated by training the estimation model with decision-aware losses (Wilder et al., 2019; Mandi et al., 2022) and robustifying the optimization model (Chan et al., 2023a). We take a similar approach as the second stream, yet deviate from them by i) utilizing decision data instead of observations of the unknown parameters, and ii) focusing on both the ground-truth and perceived solution quality, the latter of which has not been studied in this stream of literature. ", "page_idx": 1}, {"type": "text", "text": "Preference learning. Preference learning has been studied in the context of reinforcement learning and has recently attracted significant attention due to its application in AI alignment (Ji et al., 2023). Existing methods focus on learning a reward function/decision policy that is maximally consistent with expert decision trajectories $\\mathrm{Ng}$ and Russell, 2000; Wu et al., 2024) or labeled preferences in the form of pair-wise comparison/ranking (Wirth et al., 2017; Christiano et al., 2017; Rafailov et al., 2024). We enrich this stream of literature in two ways. First, we leverage unlabeled decision data that are not state-action trajectories, but solutions to an optimization model. Second, instead of learning a policy that imitates expert behaviors, we aim to extract common wisdom from decision data crowd-sourced from DMs who are not necessarily experts to encourage algorithm adoption. ", "page_idx": 1}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section, we first present the problem setup (Section 3.1) and then describe the challenges with the classic IO pipeline (Section 3.2). Finally, we provide intuition on why robustifying the IO pipeline would help (Section 3.3). ", "page_idx": 1}, {"type": "text", "text": "3.1 Problem Setup ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Data generation. Consider a forward optimization problem ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbf{FO}(\\theta,\\mathbf{u}):{\\underset{\\mathbf{x}\\in{\\mathcal{X}}(\\mathbf{u})}{\\mathrm{minimize~}}}f(\\theta,\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\mathbf{x}\\in\\mathbb{R}^{n}$ is the decision vector whose feasible region $\\chi_{\\bf{(u)}}$ is non-empty and is parameterized by exogenous parameters $\\mathbf{u}\\in\\mathbb{R}^{m}$ , $\\pmb{\\theta}\\in\\mathbb{R}^{d}$ is a parameter vector, and $f:\\mathbb{R}^{n\\times d}\\rightarrow\\mathbb{R}$ is the objective function. Suppose $\\mathbf{u}$ is distributed according to $\\mathbb{P}_{\\mathbf{u}}$ supported on $\\boldsymbol{\\mathcal{U}}$ . There exists a ground-truth parameter vector $\\pmb{\\theta}^{*}$ that is unknown to the DM. Instead, the DM obtains a decision $\\hat{\\bf x}$ by solving $\\bar{\\mathbf{FO}}(\\hat{\\pmb{\\theta}},\\mathbf{u})$ where $\\hat{\\pmb{\\theta}}$ is a noisy perception of $\\pmb{\\theta}^{*}$ . We assume that, while the distribution $\\mathbb{P}_{\\pmb{\\theta}}$ of $\\hat{\\pmb\\theta}$ is unknown, it is supported on a known bounded set $\\Theta\\subset\\mathbb{R}^{d}$ and that $\\pmb{\\theta}^{*}\\in\\Theta$ . Let $\\mathbb{P}_{(\\theta,\\mathbf{u})}$ denote the joint distribution of $\\hat{\\pmb\\theta}$ and $\\mathbf{u}$ , $\\tilde{\\mathbf{x}}:\\Theta\\times\\mathcal{U}\\rightarrow\\mathbb{R}^{n}$ be an oracle that returns an optimal solution to FO drawn uniformly at random from $\\chi^{\\mathrm{OPT}}(\\pmb{\\theta},\\mathbf{u}):=\\mathrm{argmin}\\,\\{f(\\pmb{\\theta},\\mathbf{x})\\,|\\,\\mathbf{x}\\in\\mathcal{X}(\\mathbf{u})\\}.$ . ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Objective function. We focus on cases where $f$ is linear in $\\pmb{\\theta}$ and convex in $\\mathbf{x}$ , i.e., $f(\\pmb\\theta,\\mathbf x)\\;=$ $\\textstyle\\sum_{i\\in[d]}\\theta_{i}f_{i}(\\mathbf{x})$ where $f_{i}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$ are convex basis functions. This generalizes the linear objective $f(\\pmb\\theta,\\mathbf{\\dot{x}})\\,=\\,\\theta^{\\intercal}\\mathbf{x}.$ . Moreover, FO with this objective function can be treated as a multi-objective optimization model, which has been used to model routing preferences (R\u00f6nnqvist et al., 2017), radiation therapy planning (Chan et al., 2014), and portfolio optimization (Dong and Zeng, 2021). In this setting, the optimal solution to $\\mathbf{FO}$ is invariant to the scale of $\\pmb{\\theta}$ , i.e., if $\\bar{\\mathbf{x}}\\in\\mathcal{X}^{\\mathrm{OPT}}(\\pmb{\\theta},\\mathbf{u})$ , then $\\mathbf{x}\\in\\mathcal{X}^{\\mathrm{OPT}}(\\beta\\pmb{\\theta},\\mathbf{u})$ for any $\\beta\\in\\mathbb{R}_{+}$ . So, we set $\\Theta=\\left\\{\\pmb{\\theta}\\in\\mathbb{R}^{d}\\,\\vert\\,\\Vert\\pmb{\\theta}\\Vert_{2}=1\\right\\}$ without loss of generality. ", "page_idx": 2}, {"type": "text", "text": "Learning task. Given a dataset of $N$ decision-exogenous parameter pairs $\\boldsymbol{\\mathcal{D}}=\\left\\{\\hat{\\mathbf{x}}_{k},\\mathbf{u}_{k}\\right\\}_{k=1}^{N}$ , we are interested in finding a decision policy $\\bar{\\mathbf{x}}:\\mathcal{U}\\rightarrow\\mathbb{R}^{n}$ to suggest decisions for future u. We require $\\bar{\\mathbf{x}}(\\mathbf{u})\\in\\mathcal{X}(\\mathbf{u})$ for any $\\mathbf{u}\\in\\mathcal{U}$ . As discussed later, $\\bar{\\bf x}({\\bf u})$ is usually generated by solving an optimization model that may have multiple optimal solutions. So we consider randomized policies (e.g., uniformly sample from a set of optimal solutions). This is nonrestrictive because a deterministic policy can be recovered from a randomized policy that samples the deterministic solution with probability one. ", "page_idx": 2}, {"type": "text", "text": "As a running example, FOP may represent a shortest path problem, where $\\mathbf{u}_{k}$ specifies the origin and destination of a trip, $\\pmb{\\theta}^{*}$ indicates the ground-truth travel times on each road segment, while $\\mathbf{\\bar{\\theta}}_{k}$ is a driver\u2019s perception of $\\pmb{\\theta}^{*}$ (i.e., perceived travel times). Decision $\\mathbf{x}_{k}$ corresponds to a path taken by a driver based on her perceived travel times. Given a set of historical trips $\\{\\mathbf{u}_{k},\\hat{\\mathbf{x}}_{k}\\}_{k\\in[N]}$ , our goal is to derive a routing policy $\\bar{\\bf x}$ that can provide path recommendations for future origin-destination pairs. ", "page_idx": 2}, {"type": "text", "text": "3.1.1 Assumptions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Assumption 1 (I.I.D. Samples). The dataset $\\mathcal{D}$ is generated using $\\hat{\\mathbf{x}}_{k}:=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}}_{k},\\mathbf{u}_{k})$ where $(\\hat{\\pmb\\theta}_{k},\\mathbf u_{k})$ are i.i.d. samples from $\\mathbb{P}_{(\\theta,\\mathbf{u})}$ for all $k\\in[N]$ . ", "page_idx": 2}, {"type": "text", "text": "Assumption 2 (Bounded Inverse Feasible Set). There exists a constant $\\eta\\in\\mathbb{R}_{+}$ such that, for any $\\theta,\\theta^{\\prime}\\in\\mathbf{\\bar{\\Theta}}^{\\mathrm{OPT}}\\left(\\hat{\\mathbf{x}},\\mathbf{u}\\right)$ , for some $\\hat{\\mathbf{x}}\\in\\mathcal{X}(\\mathbf{u})$ and $\\mathbf{u}\\in\\mathcal{U}$ , we have $\\lVert\\pmb{\\theta}-\\pmb{\\theta}^{\\prime}\\rVert_{2}\\leq\\eta,$ where ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Theta^{\\mathrm{OPT}}(\\mathbf{x},\\mathbf{u}):=\\left\\{\\pmb{\\theta}\\in\\mathbb{R}^{d}\\,\\vert\\,\\mathbf{x}\\in\\mathcal{X}^{\\mathrm{OPT}}(\\pmb{\\theta},\\mathbf{u}),\\Vert\\pmb{\\theta}\\Vert_{2}=1\\right\\}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Assumption 3 (Bounded Divergence). There exists a constant $\\sigma\\in\\mathbb{R}_{+}$ such that $\\lVert\\mathbb{E}(\\hat{\\pmb{\\theta}})-\\pmb{\\theta}^{*}\\rVert_{2}\\leq\\sigma$ . ", "page_idx": 2}, {"type": "text", "text": "Assumption 1 is standard in the ML and IO literature. Assumption 2 is mild because $\\Theta^{\\mathrm{OPT}}\\left(\\hat{\\mathbf{x}},\\mathbf{u}\\right)$ is by definition bounded and is usually much smaller than $\\Theta$ . Assumption 3 states that the $l_{2}$ distance between the expected perceived parameters and the ground-truth parameters is upper bounded. It is reasonable in many real-world settings. For example, a driver\u2019s perceived travel cost $({\\hat{\\pmb\\theta}})$ should not be too different from the travel time $(\\pmb\\theta^{*})$ as the latter is an important factor that drivers consider. ", "page_idx": 2}, {"type": "text", "text": "3.1.2 Evaluation Metrics ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Definition 1. The actual optimality gap $(A O G)$ of a decision policy \u00afx is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{AOG}(\\bar{\\mathbf{x}}):=\\mathbb{E}\\left[f\\left(\\pmb{\\theta}^{*},\\bar{\\mathbf{x}}(\\mathbf{u})\\right)-f\\left(\\pmb{\\theta}^{*},\\tilde{\\mathbf{x}}(\\pmb{\\theta}^{*},\\mathbf{u})\\right)\\right]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the expectation is taken over the joint distribution of the random variable u and the decision sampled using the possibly randomized policy $\\bar{\\bf x}$ . ", "page_idx": 2}, {"type": "text", "text": "Definition 2. The perceived optimality gap $(P O G)$ of a decision policy \u00afx is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname{POG}({\\bar{\\mathbf{x}}}):=\\mathbb{E}\\left[f\\left({\\hat{\\pmb{\\theta}}},{\\bar{\\mathbf{x}}}(\\mathbf{u})\\right)-f\\left({\\hat{\\pmb{\\theta}}},{\\tilde{\\mathbf{x}}}\\left({\\hat{\\pmb{\\theta}}},\\mathbf{u}\\right)\\right)\\right].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the expectation is taken with respect to the randomness in $\\boldsymbol{\\hat{\\theta}},\\,\\mathbf{u},$ , and possibly \u00afx. ", "page_idx": 2}, {"type": "text", "text": "AOG is an objective performance measure. Achieving a low AOG means that $\\bar{\\bf x}$ can generate highquality decisions. In contrast, POG is a subjective measure that depends on the DM\u2019s perception of the problem. Achieving a low POG is critical to mitigate algorithm aversion (Burton et al., 2020). ", "page_idx": 2}, {"type": "text", "text": "3.2 An Inverse Optimization Pipeline ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Finding $\\bar{\\bf x}$ is challenging for three reasons. First, unlike many ML tasks where the prediction target is unconstrained, we require $\\bar{\\bf x}({\\bf u})$ to be feasible to FO which may involve a large number of constraints. Supervised learning approaches that predict $\\hat{\\bf x}$ based on u can often fail as they typically do not provide feasibility guarantees. An optimization module is often needed to recover feasibility or produce feasible solutions based on $\\mathbf{u}$ and some estimated $\\bar{\\pmb\\theta}$ . Second, we do not directly observe $\\pmb{\\theta}^{*}$ or $\\hat{\\pmb{\\theta}}$ , which precludes using classic ML techniques to estimate them. Finally, AOG and POG may not necessarily align with each other, so we are essentially dealing with a bi-objective problem. ", "page_idx": 3}, {"type": "image", "img_path": "Y2NWKlrDrX/tmp/86fe42bd3cd170565d17af716eca0d4e3e4cd20022f32fd9fd9e5a510849cdc1.jpg", "img_caption": ["Figure 1: Classic and conformal IO pipelines. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "In light of the first two challenges, a classic IO pipeline (visualized in Figure 1) has been proposed to first obtain a point estimation $\\bar{\\pmb\\theta}$ of the unknown parameters and then employ a policy $\\bar{\\bf x}_{\\mathrm{IO}}({\\bf u}):=$ $\\tilde{\\mathbf{x}}(\\bar{\\pmb{\\theta}},\\mathbf{u})$ to prescribe decisions for any $\\mathbf{u}\\in\\mathcal{U}$ (R\u00f6nnqvist et al., 2017; Babier et al., 2020). Specifically, we can estimate the parameters by solving the following inverse optimization problem ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\bf I O}({\\mathcal{D}}):\\operatorname*{minimize}_{\\theta\\in\\Theta}\\frac{1}{N}\\sum_{k\\in[N]}\\ell\\left(\\hat{\\bf x}_{k},\\chi^{\\mathrm{OPT}}(\\theta,{\\bf u}_{k})\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\ell$ is a non-negative loss function that returns 0 when $\\hat{\\mathbf{x}}_{k}\\in\\mathcal{X}^{\\mathrm{OPT}}(\\pmb{\\theta},\\mathbf{u}_{k})$ . For instance, the following loss function is commonly used in the literature. ", "page_idx": 3}, {"type": "text", "text": "Definition 3. The sub-optimality loss of $\\pmb{\\theta}$ is given by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell_{S}\\left(\\hat{\\mathbf{x}},\\chi^{O P T}(\\pmb{\\theta},\\mathbf{u})\\right):=\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{X}(\\mathbf{u})}f(\\pmb{\\theta},\\hat{\\mathbf{x}})-f(\\pmb{\\theta},\\mathbf{x}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The sub-optimality loss penalizes the optimality gap achieved by the observed decision under the estimated parameters. As remarked by Mohajerin Esfahani et al. (2018), this loss function has better computational properties than its alternatives as it is convex in the unknown parameters. In fact, when the dataset $\\mathcal{D}$ is large in size and the unknown parameters $\\pmb{\\theta}$ are high-dimensional, the sub-optimality loss is usually the only loss function that leads to a tractable inverse problem, although it does not enjoy properties such as statistical consistency (see Chan et al. (2023b) for detailed discussions). While such a trade-off is acceptable in some applications, we suggest that it is undesirable in our setting because the resulting policy can achieve arbitrarily large AOG and POG. To see this, consider the following example that satisfies Assumptions 1\u20133. This example is visualized in Figure 2. ", "page_idx": 3}, {"type": "text", "text": "Example 1. Let $\\mathbf{FO}(\\theta,u)$ be the following problem ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}{{\\mathrm{minimize}}}&{\\theta_{1}x_{1}+\\theta_{2}x_{2}}\\\\ {{\\mathrm{subject~to}}}&{x_{1}+u x_{2}\\geq u}\\\\ &{0\\leq x_{1}\\leq u}\\\\ &{0\\leq x_{2}\\leq2.}\\end{array}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Let the ground-truth $\\pmb{\\theta}^{*}=(\\cos(\\pi/4),\\sin(\\pi/4))$ and $\\mathcal{U}=\\{u\\}$ where $u>1$ is a real constant. We are given a dataset $=\\left\\{\\hat{\\mathbf{x}}_{k},u\\right\\}_{k=1}^{N}\\,w h e r e\\;\\hat{\\mathbf{x}}_{k}\\,=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}}_{k},u)$ with $\\hat{\\pmb{\\theta}}_{k}$ uniformly and independently drawn from $\\Theta=\\{(\\cos\\delta,\\,\\sin\\delta)\\,|\\,\\ddot{\\delta}\\in(0,\\pi/2)\\}$ for all $k\\in[N]$ . ", "page_idx": 3}, {"type": "text", "text": "Lemma 1. In Example $^{\\,l}$ , let $\\bar{\\pmb{\\theta}}_{N}$ denote an optimal solution to $\\mathbf{IO}(\\mathcal{D})$ with \u221athe sub-optimality loss (6), we have $\\mathbb{P}\\left(\\bar{\\pmb{\\theta}}_{N}=\\pmb{\\theta}_{u}\\right)\\rightarrow1$ as $N\\rightarrow\\infty$ , where $\\pmb{\\theta}_{u}:=\\left(1/\\sqrt{1+u^{2}},u/\\sqrt{1+u^{2}}\\right)$ . ", "page_idx": 3}, {"type": "image", "img_path": "Y2NWKlrDrX/tmp/5e047524762b3663bf44714f3386cdc8d612965ec77962f3986e6db29704de2e.jpg", "img_caption": ["Figure 2: Illustration of Example 1. The gray areas are the feasible region $\\chi_{(u)}$ . The black arrows are the ground-truth parameter $\\pmb{\\theta}^{*}$ . The gray arrows are the extreme rays of $\\Theta$ . The blue and green arrows are the point estimation $\\bar{\\pmb\\theta}$ . The green area is the uncertainty set $\\dot{\\mathcal{C}}(\\bar{\\pmb{\\theta}},\\alpha)$ . The black circles are the optimal solution to ${\\bf F O}(\\pmb{\\theta}^{*},u)$ . The blue and green circles are the suggested decisions. Note that \u00afxIO may suggest any decisions on the facet of $x_{1}+u x_{2}\\geq u$ , which are omitted for clarity. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Lemma 1 shows that, when using $\\mathbf{IO}(\\mathcal{D})$ with the sub-optimality loss to estimate the unknown parameter in Example 1, the probability of the estimated parameter being $\\theta_{u}$ converges to one asymptotically. This implies that asymptotically we are almost certain that $\\bar{\\mathbf{x}}_{\\mathrm{IO}}(u)=\\tilde{\\mathbf{x}}(\\pmb{\\theta}_{u},u)$ , i.e. the policy that samples uniformly from the facet corresponding to the constraint $x_{1}+u x_{2}\\geq u$ . As a result, $\\bar{\\bf x}_{\\mathrm{IO}}$ can achieve arbitrarily large AOG and POG when $u$ is set to a large enough value. ", "page_idx": 4}, {"type": "text", "text": "Proposition 1. In Example 1, let $\\bar{\\mathbf{x}}_{\\mathrm{IO}}(u)=\\tilde{\\mathbf{x}}(\\pmb{\\theta}_{u},u)$ . For any $v\\in\\mathbb{R}_{+}$ there exists some $\\bar{u}>1$ such that $\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})>v$ and $\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})>v$ for any $u>\\bar{u}$ . ", "page_idx": 4}, {"type": "text", "text": "3.3 Robustifying the Inverse Optimization Pipeline ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "A natural idea to improve the AOG and POG of $\\bar{\\bf x}$ is to robustify the decision pipeline. Specifically, instead of solving FO with some estimated parameters $\\bar{\\pmb\\theta}$ , we solve the following robust forward optimization problem with an uncertainty set around $\\bar{\\pmb\\theta}$ to prescribe decisions (final steps in Figure 1). ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname{RFO}\\left({\\mathcal C}({\\bar{\\theta}},\\alpha),\\mathbf{u}\\right):{\\underset{\\mathbf{x}\\in{\\mathcal X}(\\mathbf{u})}{\\operatorname{minimize~maximize}}}\\ f(\\theta,\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathcal{C}$ is an uncertainty set with $\\bar{\\pmb\\theta}$ being its center and $_{\\alpha}$ representing parameters that control its shape/size. Given the support set $\\Theta$ defined in Section 3.1, we focus on the following uncertainty set. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha):=\\left\\{\\pmb{\\theta}\\in\\mathbb{R}^{d}\\,\\vert\\,\\Vert\\pmb{\\theta}\\Vert_{2}=1,\\,\\pmb{\\theta}^{\\intercal}\\bar{\\pmb{\\theta}}\\geq\\cos\\alpha\\right\\}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\alpha\\in(0,\\pi]$ represents the max angle between $\\bar{\\pmb\\theta}$ and any vector in the uncertainty set. ", "page_idx": 4}, {"type": "text", "text": "Remark 1. An alternative approach to robustify the IO pipeline is to replace IO with a distributionally robust IO for parameter estimation (Mohajerin Esfahani et al., 2018). However, this approach would not help as $\\theta_{u}$ is still optimal to the distributionally robust $I O$ in Example 1. So, the AOG and POG can still be arbitrarily large. See Appendix A.3 for complete statement and discussions. ", "page_idx": 4}, {"type": "text", "text": "Now, in Example 1, we analyze the performance of a policy that utilizes RFO to prescribe decisions. Lemma 2. In Example 1, let $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(u)$ be an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}}_{N},\\alpha),u)$ where $\\bar{\\pmb{\\theta}}_{N}$ is an optimal solution to $\\mathbf{IO}(\\mathcal{D})$ with the sub-optima\u221ality loss (6). When $\\alpha\\,\\in\\,(0,\\pi/2)$ , we have $\\mathbb{P}\\left[\\mathrm{AOG}(\\mathbf{x}_{\\mathrm{CIO}})=0\\right]\\rightarrow1$ and $\\mathbb{P}$ $[\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})<\\pi/2\\sqrt{2}]\\to1$ as $N\\rightarrow\\infty$ . ", "page_idx": 4}, {"type": "text", "text": "Lemmas 2 shows that, when using RFO to prescribe new decisions, the probability of achieving upper-bounded AOG and POG converges to one as $N$ goes to infinity, as long as $\\alpha\\in(0,\\pi/2)$ . These bounds are independent of $u$ , in contrast to the AOG and POG of classic IO that can be arbitrarily large as $u$ changes (Proposition 1). However, the performance of this approach still depends on the choice of $\\alpha$ , which is non-trivial when FO is more complex than a two-dimensional linear program. We address this problem next. ", "page_idx": 4}, {"type": "text", "text": "4 Conformal Inverse Optimization ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we present a principled approach to learn uncertainty sets that lead to provable performance guarantees. As presented later, the learned uncertainty set contains parameters that make the next DM\u2019s decision optimal with a specified probability. We call this approach conformal IO due to its connection to conformal prediction (Vovk et al., 2005), which aims to predict a set that contains the next prediction target with a specified probability. Our approach first converts each context-decision observation $({\\bf u}_{k},\\hat{\\bf x}_{k})$ to a parameter set $\\Theta^{\\mathrm{OPT}}(\\mathbf{u}_{k},\\,\\hat{\\mathbf{x}}_{k})$ that contains all the parameters that explain $\\hat{\\mathbf{x}}_{k}$ under $\\mathbf{u}_{k}$ . We then adapt conformal prediction to produce a set that has $\\gamma$ probability of containing at least one member of the next sampled $\\boldsymbol{\\Theta}^{\\mathrm{opT}}(\\mathbf{\\bar{u}},\\hat{\\mathbf{x}})$ . Note that if $\\Theta^{\\mathrm{OPT}}(\\mathbf{u},\\hat{\\mathbf{x}})$ is a singleton almost surely, the approach is equivalent to applying conformal prediction to $\\theta_{k}$ directly. As illustrated in Figure 1, there are three training steps in conformal IO: i) data split, ii) point estimation, and iii) uncertainty set calibration. We present these steps in Section 4.1 and analyze the properties of conformal IO in Section 4.2. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "4.1 Learning an Uncertainty Set ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Data split. We first split the dataset $\\mathcal{D}$ into training and validation sets, namely $\\ensuremath{\\mathcal{D}}_{\\mathrm{train}}$ and $\\mathcal{D}_{\\mathrm{val}}$ . Let $\\kappa_{\\mathrm{train}}$ and $\\kappa_{\\mathrm{val}}$ index $\\mathcal{D}_{\\mathrm{train}}$ and $\\mathcal{D}_{\\mathrm{val}}$ , respectively, while $N_{\\mathrm{train}}=|\\mathcal{D}_{\\mathrm{train}}|$ and $N_{\\mathrm{val}}=|D_{\\mathrm{val}}|$ . ", "page_idx": 5}, {"type": "text", "text": "Point estimation. Given a training set $\\mathcal{D}_{\\mathrm{train}}$ , we apply data-driven IO techniques to obtain a point estimation $\\bar{\\pmb\\theta}$ of the unknown parameters. The most straightforward way is to solve $\\mathbf{IO}(\\mathcal{D}_{\\mathrm{train}})$ with any loss function. Alternatively, one may consider using end-to-end learning and optimization methods that do not require observations of the parameter vectors, e.g., the one proposed by Berthet et al. (2020). The point estimation can also come from other sources, e.g., from an ML model that predicts the parameters. Our calibration method is independent of the point estimation method. ", "page_idx": 5}, {"type": "text", "text": "Uncertainty set calibration. Given a point estimation $\\bar{\\pmb\\theta}$ , we calibrate an uncertainty set that, with a specified probability, contains parameters that make the next observed decision optimal. This property is critical for the results in Section 4.2 to hold. While we can naively achieve this by setting $\\alpha=\\pi$ , the resulting RFO may generate overly conservative decisions. Hence, we are interested in learning the smallest uncertainty set that satisfies this condition. We solve the following calibration problem ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbf{CP}(\\bar{\\theta},\\mathcal{D}_{\\mathrm{val}},\\gamma):\\underset{\\alpha,\\{\\theta_{k}\\}_{k\\in\\mathcal{K}_{\\mathrm{val}}}}{\\mathrm{minimize}}}&{\\alpha}\\\\ {\\mathrm{subject~to}}&{\\hat{\\mathbf{x}}_{k}\\in\\mathcal{X}^{\\mathrm{OPT}}(\\pmb{\\theta}_{k},\\mathbf{u}_{k}),\\ \\forall k\\in\\mathcal{K}_{\\mathrm{val}}}\\\\ &{\\displaystyle\\sum_{k\\in\\mathcal{K}_{\\mathrm{val}}}\\mathbb{1}\\left[\\theta_{k}\\in\\mathcal{C}(\\bar{\\theta},\\alpha)\\right]\\geq\\gamma(\\mathcal{N}_{\\mathrm{val}}+1)}\\\\ &{\\|\\theta_{k}\\|_{2}=1,\\ \\forall k\\in\\mathcal{K}_{\\mathrm{val}}}\\\\ &{0\\leq\\alpha\\leq\\pi,}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where decision $\\alpha$ controls the size of the uncertainty set, $\\theta_{k}$ represent a possible parameter vector associated with data point $k\\in\\mathcal{K}_{\\mathrm{val}}$ , $\\gamma\\in[0,1]$ is a DM-specified confidence level. Constraints (10b) ensure that $\\theta_{k}$ can make the decision $\\hat{\\mathbf{x}}_{k}$ optimal for $k\\in\\mathcal{K}_{\\mathrm{val}}$ . Constraint (10c) ensures that at least $\\gamma(N_{\\mathrm{val}}+1)$ of the decisions in $\\mathcal{D}_{\\mathrm{val}}$ can find a vector in $\\mathcal{C}$ that makes it optimal. Constraints (10d) ensure that the parameter vectors are on the unit sphere as defined in Equation (9). ", "page_idx": 5}, {"type": "text", "text": "Remark 2 (Optimality Conditions). The specific form of Constraints (10b) depends on the structure of FO. For example, when FO is a linear program, Constraints (10b) can be replaced with the dual feasibility and strong duality constraints. When the FO is a general convex optimization problem, we can use the KKT conditions. For non-convex forward problems, we can replace Constraints (10b) with $f(\\pmb{\\theta}_{k},\\hat{\\mathbf{x}}_{k})\\leq f(\\pmb{\\theta}_{k},\\mathbf{x})$ for all $\\mathbf{x}\\in\\mathcal{X}(\\mathbf{u})$ , which can be generated in a cutting-plane fashion. ", "page_idx": 5}, {"type": "text", "text": "Remark 3 (Feasibility). For CP to be feasible, we require, for each observed decision, there exists a $\\theta\\in\\Theta$ that make it optimal. This condition holds for a range of problems, e.g., routing problems and the knapsack problem, even if the DM is subject to bounded rationality, i.e., the DM settles for suboptimal solutions due to cognitive/computational limitations. For problems where this condition is violated, we may pre-process $\\mathcal{D}_{\\nu a l}$ to project $\\hat{\\bf x}$ to a point in $\\chi_{\\bf{(u)}}$ such that the condition is satisfied. ", "page_idx": 5}, {"type": "text", "text": "Solving CP is hard. First, CP is non-convex due to Constraints (10d). Second, Constraints (10b) involve the optimality conditions of $N_{\\mathrm{val}}$ problems, so the size of $\\mathbf{CP}$ grows quickly as $N_{\\mathrm{val}}$ increases. Nevertheless, considering a large $\\mathcal{D}_{\\mathrm{val}}$ is critical to ensure desirable properties of the learned uncertainty set (Section 4.2). Below we introduce a decomposition method to solve CP efficiently. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. Let $\\mathcal{D}_{\\mathrm{val}}$ be a dataset, $\\gamma~\\in~[0,1]$ , $\\bar{\\pmb{\\theta}}~\\in~\\mathbb{R}^{d}$ , $\\tau~=~\\lceil\\gamma(N_{\\mathrm{val}}+1)\\rceil$ and $\\Gamma_{\\tau}$ be an operator that returns the $\\tau^{\\mathrm{th}}$ largest value in a set. The optimal solution to $\\mathbf{CP}(\\bar{\\pmb\\theta},\\mathcal{D}_{\\mathrm{val}},\\gamma)$ is $\\alpha_{\\gamma}:=\\operatorname{arccos}\\left(\\Gamma_{\\tau}\\left(\\{c_{k}\\}_{k\\in K_{v a l}}\\right)\\right)$ with $c_{k}:=\\operatorname*{max}_{\\pmb{\\theta}_{k}}\\left\\{\\pmb{\\theta}_{k}^{\\intercal}\\bar{\\pmb{\\theta}}\\,\\Big|\\,\\hat{\\mathbf{x}}_{k}^{}\\in\\mathcal{X}^{\\mathrm{OPT}}(\\pmb{\\theta}_{k},\\mathbf{u}_{k})\\right.$ , $\\lVert\\pmb{\\theta}_{k}\\rVert_{2}=1\\}$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 1 states that we can solve CP by first solving $N_{\\mathrm{val}}$ optimization problems whose size is independent of $N_{\\mathrm{val}}$ and then find a quantile in a set of $N_{\\mathrm{val}}$ elements. The first step is parallelizable and the second step can be done in $\\bar{O}\\left(N_{\\mathrm{val}}\\log(\\tau)\\right)$ time. Since the problem required for evaluating $c_{k}$ is a maximization problem, we can replace the constraint $\\lVert\\pmb{\\theta}_{k}\\rVert_{2}=1$ with $\\lVert\\pmb{\\theta}_{k}\\rVert_{2}\\leq1$ if $\\bar{\\pmb{\\theta}}\\in\\mathbb{R}_{+}^{d}$ , so this problem is convex when the forward problem is a linear program. ", "page_idx": 6}, {"type": "text", "text": "4.2 Properties of Conformal IO ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Theorem 2 (Uncertainty Set Validity). Let $\\mathcal{D}_{\\mathrm{val}}$ be a dataset that satisfies Assumption $^{\\,l}$ , $({\\hat{\\pmb{\\theta}}},\\mathbf{u})$ be $a$ new i.i.d. sample from $\\mathbb{P}_{(\\theta,\\mathbf{u})}$ , $\\hat{\\mathbf{x}}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},\\mathbf{u})$ , $\\hat{\\Theta}:=\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}},\\mathbf{u})$ , and $\\alpha_{\\gamma}$ be an optimal solution to $\\mathbf{CP}(\\bar{\\pmb\\theta},\\mathcal{D}_{\\mathrm{val}},\\gamma)$ where $\\bar{\\pmb{\\theta}}\\in\\mathbb{R}^{d}$ . We have, for any $\\gamma\\in[0,N_{\\nu a l}/(N_{\\nu a l}+1)]$ , that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\hat{\\Theta}\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{\\gamma})\\neq\\varnothing\\right)\\ge\\gamma.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "For any $\\gamma\\in[0,1]$ , with probability at least $1-1/N_{\\mathrm{val}},$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\bigg|\\mathbb{P}\\left(\\hat{\\Theta}\\cap\\mathcal{C}(\\bar{\\theta},\\alpha_{\\gamma})\\neq\\varnothing\\right)-\\gamma\\bigg|\\leq\\epsilon(N_{v a l}):=\\sqrt{\\frac{8\\log(N_{v a l}+1)+2\\log N_{v a l}}{N_{v a l}}}+\\frac{2}{N_{v a l}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 2 states that our learned uncertainty set is conservatively valid and asymptotically exact (Vovk et al., 2005). More specifically, first, our method will produce a set that contains a $\\pmb{\\theta}$ that makes the next DM\u2019s decision optimal no less than $\\gamma$ of the time that it is used (conservatively valid). The probability in Inequality (11) is with respect to the joint distribution over $\\mathcal{D}_{\\mathrm{val}}$ and the new sample. Second, once the set is given, we have high confidence that, the probability of the next DM\u2019s decision being covered is within $\\epsilon(N_{\\mathrm{val}})$ from $\\gamma$ . The probability in Inequality (12) is with respect to the new sample, while the high confidence is with respect to the draw of the validation data set. Overall, we have the almost sure convergence of $\\mathbb{P}(\\hat{\\pmb{\\Theta}}\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{\\gamma})\\neq\\alpha)$ to $\\gamma$ as $N$ goes to infinity. Finally, we note that in many practical applications, the number of decision observations $N$ can be quite large. For example, in our motivating example, rideshare platforms observe millions of trips on a daily basis, providing ample data for both point estimation and uncertainty set calibration in our pipeline. ", "page_idx": 6}, {"type": "text", "text": "Now, we relate the validity results to the performance of conformal IO. The following Lemma is an immediate result of the objective function $f$ being linear in $\\pmb{\\theta}$ . ", "page_idx": 6}, {"type": "text", "text": "Lemma 3. For any $\\hat{\\mathbf{x}}\\in\\tilde{\\mathbf{x}}\\left(\\hat{\\pmb{\\theta}},\\mathbf{u}\\right)$ and $\\left({\\hat{\\theta}},\\mathbf{u}\\right)\\in\\Theta\\times\\mathcal{U},$ , there exists a constant $\\nu\\left(\\hat{\\mathbf{x}}\\right)\\in\\mathbb{R}_{+}$ such that, for any ${\\boldsymbol{\\theta}},{\\boldsymbol{\\theta}}^{\\prime}\\in\\Theta$ , we have $f\\left(\\pmb{\\theta},\\hat{\\mathbf{x}}\\right)-f\\left(\\pmb{\\theta}^{\\prime},\\hat{\\mathbf{x}}\\right)\\leq\\nu\\left(\\hat{\\mathbf{x}}\\right)\\|\\pmb{\\theta}-\\pmb{\\theta}^{\\prime}\\|_{2}$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 3 (POG Bound). Let $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})$ be an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ for any $\\mathbf{u}\\in\\mathcal{U}$ , where $\\bar{\\pmb{\\theta}}\\in\\mathbb{R}^{d}$ and $\\alpha_{1}$ are chosen such that, for a new sample $(\\pmb\\theta^{\\prime},\\mathbf u^{\\prime})$ from $\\mathbb{P}_{(\\theta,\\mathbf{u})}$ and $\\mathbf{x}^{\\prime}=\\tilde{\\mathbf{x}}(\\pmb{\\theta}^{\\prime},\\mathbf{u}^{\\prime})$ , $\\mathbb{P}\\left(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})\\cap\\Theta^{\\mathrm{OPT}}(\\mathbf{u}^{\\prime},\\mathbf{x}^{\\prime})\\neq\\varnothing\\right)=1.$ If Assumptions 2\u20133 hold, then ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})\\leq(\\eta-2\\cos2\\alpha_{1}+2)\\mu+\\eta\\mu_{\\mathrm{CIO}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "and ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})\\leq(2-2\\cos2\\alpha_{1}+\\eta+\\sigma)\\mu^{*}+(\\eta+\\sigma)\\mu_{\\mathrm{CIO}},}\\\\ {\\cdot(\\hat{\\pmb{\\theta}},\\mathbf{u}))],\\,\\mu_{\\mathrm{CIO}}:=\\mathbb{E}(\\nu[\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})]),\\,a n d\\,\\mu^{*}:=\\mathbb{E}\\,(\\nu[\\tilde{\\mathbf{x}}(\\pmb{\\theta}^{*},\\mathbf{u})]).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 3 states that, when $\\mathcal{C}(\\bar{\\pmb\\theta},\\alpha)$ contains a $\\pmb{\\theta}$ that makes the next DM\u2019s decision optimal almost surely, conformal IO achieves upper-bounded POG and AOG. While we can meet this condition by using a large $\\alpha$ , the bounds would be large as they increase as $\\alpha$ increases, reflecting that the decisions may be overly conservative. Instead, we can use CP to obtain a $\\alpha$ that achieves close-to- $100\\%$ coverage and possibly add a small $\\Delta_{\\alpha}\\in\\mathbb{R}_{+}$ as extra protection. Moreover, we show in Section 5 that, when using $\\gamma<100\\%$ , conformal IO still demonstrates favorable performance compared to classic IO. Our bounds have problem-specific constants. To demonstrate tightness, we present their numerical values in Example 1 with $\\alpha=\\pi/4$ (Table 1). They closely follow the performance of conformal IO, which outperforms classic IO by a large margin. ", "page_idx": 6}, {"type": "table", "img_path": "Y2NWKlrDrX/tmp/1f2900f7aca8078139fa2db7f98021495397943a9a6940a4499a524bc6195da2.jpg", "table_caption": ["Table 1: Performance profile of classic and conformal IO in Example 1. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "5 Numerical Studies ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Data generation. We consider two forward problems: The shortest path problem (linear program, $d=120$ ) and knapsack problem (integer program, $d=10$ ). See Appendix C.2 for their formulations. We use synthetic instances, which is a common practice as there is no well established IO benchmark (Tan et al., 2020; Dong et al., 2018). For both problems, we randomly generate a ground-truth parameters $\\pmb{\\theta}^{*}$ and a dataset of $N=1000$ DMs. For each DM $k\\in[N]$ , we generate her perceived parameters as $\\hat{\\theta}_{k}^{i}=(\\theta_{k}^{i*}*p_{k}^{i}+\\epsilon_{k}^{i})^{+}+\\epsilon_{0}$ for $i\\in[d]$ where $p_{k}^{i}$ is uniformly drawn from $[1/2,2]$ , $\\epsilon_{k}^{i}$ is drawn from a normal distribution with mean 0 and standard deviation 1, and $\\epsilon_{0}=0.1$ . For the shortest path problem, parameters $\\mathbf{u}_{k}$ represent a random origin-destination pair on the network. For the knapsack problem, $\\mathbf{u}_{k}$ correspond to the weights of different items and the DM\u2019s budget. The item weight $\\bar{w^{i}}$ for $i\\in[d]$ are uniformly drawn from [1, 10] and are shared among DMs. For each DM $k\\in[N]$ , we generate a budget $u_{k}\\overset{\\cdot}{=}q_{k}\\sum_{i}w^{i}$ where $q_{k}$ is uniformly drawn from $[1/5,5]$ . ", "page_idx": 7}, {"type": "text", "text": "Experiment design. Conformal IO is compatible with any approach that can provide a point estimation of unknown parameters using decision data (Step 2 in Section 4.1). To the best of our knowledge, i) IO with the sub-optimality loss and ii) the PFYL approach from Berthet et al. (2020) are the only two methods that can perform this task at scale. We thus implement conformal IO with these two methods. They also serve as our baselines. We call both i) and ii) classic IO to emphasize that they rely on a point estimation for decision prescription, although PFYL is not an IO approach. See Appendix C for implementation details. In all experiments, conformal IO uses the training set for point estimation and the validation set for calibration, while classic IO uses the union of the training and validation sets for point estimation. So, they have access to the same amount of data and are evaluated on the same test set. Unless otherwise noted, experiments are based on a 60/20/20 train-validation-test split and are repeated 10 times with different random seeds. ", "page_idx": 7}, {"type": "text", "text": "Uncertainty validity. To verify Theorem 2, we empirically evaluate the out-of-sample coverage achieved by our uncertainty set under different target levels $\\gamma$ and sample sizes $N_{\\mathrm{val}}$ . The point estimation is generated by IO with the sub-optimality loss. As shown in Figure 3, when the validation set is small ( $/N_{\\mathrm{val}}\\,=\\,10)$ ), we always achieve the specified target but $\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{\\gamma})$ tends to over-cover (conservatively valid). When using larger validation sets $(N_{\\mathrm{val}}\\in\\{100,200\\})$ , our coverage level gets closer to the specified $\\gamma$ (asymptotic exact). These empirical findings echo our theoretical analysis. ", "page_idx": 7}, {"type": "image", "img_path": "Y2NWKlrDrX/tmp/b03ec42ec2fb561c7641fc53afebf58b784ec3ea37d16856e29f35b4f1dac113.jpg", "img_caption": ["Figure 3: Empirical coverage achieved by the learned uncertainty set (error bar $=$ range). "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "The value of robustness. As shown in Figure 4, solving RFO with an uncertainty set learned by conformal IO leads to decisions of lower AOG and POG, compared to solving FO with a point estimation from classic IO. On average, when varying $\\gamma$ , our approach improves AOG by $20.1\u201330.4\\%$ and POG by $15.0\u201323.2\\%$ for the shortest path problem, and improves AOG by $40.3\u201357.0\\%$ and POG by $13.5{-}20.1\\%$ for the knapsack problem. The improvement is orthogonal to the point estimation method. Our decisions are of higher quality and better align with human intuition than classic IO. Finally, the performance of conformal IO generally improves as the quality of the point estimate increases (see Appendix D for details). Therefore, even though the conformal IO pipeline is robust to estimation errors, using the best available point estimation method is still recommended. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "image", "img_path": "Y2NWKlrDrX/tmp/2a9c03ec4793e480f145df491a76663ab8b7cc2a8a3ca805a4a0b19e3beee715.jpg", "img_caption": ["Figure 4: Performance profile of classic (blue) and conformal IO (green). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Computational efficiency. As shown in Table 2, conformal IO and classic IO require similar training times. When FO is an integer program (knapsack), the training of conformal IO is even faster because it replaces a relatively large inverse integer program (associated with $\\mathcal{D}_{\\mathrm{train}}\\cup\\mathcal{D}_{\\mathrm{val}})$ ), which is notoriously difficult to solve (Bodur et al., 2022), with a smaller inverse integer program (associated with $\\ensuremath{\\mathcal{D}_{\\mathrm{train}}}^{}$ ) and a set of small calibration problems that are parallelizable (Theorem 1). At the prediction time, our method achieves lower AOG and POG at the cost of solving a more challenging RFO. Nevertheless, the solution time of RFO is within one second in our instances. ", "page_idx": 8}, {"type": "table", "img_path": "Y2NWKlrDrX/tmp/93650e317169295b5342e9b2553bd7930c19309b61ec2d1f2f45752da25efbce.jpg", "table_caption": ["Table 2: Average (std) computational time of classic and conformal IO in seconds. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Important hyper-parameters. Finally, we provide empirical evidence that sheds light on the choice of two important hyper-parameters in conformal IO: i) confidence level $\\gamma$ , and ii) train-validation split ratio. Regarding $\\gamma$ , as shown in Figure 4, the performance of conformal IO improves quickly as $\\gamma$ increases from 0 to $50\\%$ and remains stable and even worsens slightly after that. Hence, it is possible to improve the performance of conformal IO by carefully tuning $\\gamma$ using cross-validation. However, this requires an additional validation dataset. If such a dataset is unavailable, setting $\\gamma$ to a relatively large value (e.g., 0.99) usually yields decent performance, which aligns with our theoretical analysis. Regarding train-validation split ratio, intuitively, both the estimation and calibration can benefti from more data. However, when the dataset is small, we need to strike a balance between these two steps aiming to achieve lower AOG and POG. We implement conformal IO for the shortest path problem under different dataset sizes $(N_{\\mathrm{train}}+N_{\\mathrm{val}})$ and train-validation split ratios $(N_{\\mathrm{val}}/(N_{\\mathrm{train}}+N_{\\mathrm{val}}))$ . As shown in Figure 5, when the dataset is small, there is no benefti of using conformal IO because we do not have enough data to obtain good point estimation and uncertainty set simultaneously. However, the performance of classic IO quickly plateaus as the dataset grows. When given a mid- or large-sized dataset, we can generally benefit from putting more data in $\\mathcal{D}_{\\mathrm{val}}$ , echoing our theoretical analysis. ", "page_idx": 8}, {"type": "image", "img_path": "Y2NWKlrDrX/tmp/4c1c1876defc0fab34c7e355c2a05202c355917690b127b8a410839b74b8a256.jpg", "img_caption": ["Figure 5: Percentage reduction in AOG and POG when using the conformal IO vs classic IO. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we propose conformal IO, a novel IO pipeline to recommend high-quality decisions that align with human intuition. We present the first approach to learning uncertainty sets from decision data, which is then utilized in a robust optimization model to prescribe new decisions. We prove that conformal IO achieves bounded optimality gaps, as measured by the ground-truth parameters and the DM\u2019s perceived parameters. We demonstrate the strong empirical performance of conformal IO via extensive numerical studies. Finally, we highlight several challenges that underscore future research directions. First, we focus on objectives that are linear in the unknown parameters. While such objectives are ubiquitous in practice, it is of interest to extend our results for general convex objectives. Second, the robust forward problem, while leading to better decisions, is computationally more costly than the forward problem. Future research can be done to accelerate its solution process. Finally, while Conformal IO consistently outperforms classic IO when the point estimation methods are fixed, our computational experiments suggest that its performance hinges on the quality of the point estimate. Future research could explore point estimation methods that directly optimize the performance of the downstream robust optimization model. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The authors are grateful to the anonymous reviewers for their valuable feedback and insightful comments. Erick Delage was partially supported by the Canadian Natural Sciences and Engineering Research Council [Grant RGPIN-2022-05261] and by the Canada Research Chair program [950- 230057]. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Ahuja, R. K. and Orlin, J. B. (2001). Inverse optimization. Operations Research, 49(5):771\u2013783. ", "page_idx": 9}, {"type": "text", "text": "Aswani, A., Shen, Z.-J., and Siddiq, A. (2018). Inverse optimization with noisy data. Operations Research, 66(3):870\u2013892.   \nBabier, A., Mahmood, R., McNiven, A. L., Diamant, A., and Chan, T. C. (2020). Knowledge-based automated planning with three-dimensional generative adversarial networks. Medical Physics, 47(2):297\u2013306.   \nBerthet, Q., Blondel, M., Teboul, O., Cuturi, M., Vert, J.-P., and Bach, F. (2020). Learning with differentiable pertubed optimizers. In Advances in Neural Information Processing Systems, volume 33, pages 9508\u20139519.   \nBodur, M., Chan, T. C., and Zhu, I. Y. (2022). Inverse mixed integer optimization: Polyhedral insights and trust region methods. INFORMS Journal on Computing, 34(3):1471\u20131488.   \nBurton, J. W., Stein, M.-K., and Jensen, T. B. (2020). A systematic review of algorithm aversion in augmented decision making. Journal of Behavioral Decision Making, 33(2):220\u2013239.   \nChan, T. C. Y., Craig, T., Lee, T., and Sharpe, M. B. (2014). Generalized inverse multiobjective optimization with application to cancer therapy. Operations Research, 62(3):680\u2013695.   \nChan, T. C. Y. and Kaw, N. (2020). Inverse optimization for the recovery of constraint parameters. European Journal of Operational Research, 282(2):415\u2013427.   \nChan, T. C. Y., Lee, T., and Terekhov, D. (2019). Inverse optimization: Closed-form solutions, geometry, and goodness of fit. Management Science, 65(3):1115\u20131135.   \nChan, T. C. Y., Mahmood, R., O\u2019Connor, D. L., Stone, D., Unger, S., Wong, R. K., and Zhu, I. Y. (2023a). Got (optimal) milk? pooling donations in human milk banks with machine learning and optimization. Manufacturing & Service Operations Management, 0(0).   \nChan, T. C. Y., Mahmood, R., and Zhu, I. Y. (2023b). Inverse optimization: Theory and applications. Operations Research, 0(0).   \nChen, V., Liao, Q. V., Wortman Vaughan, J., and Bansal, G. (2023). Understanding the role of human intuition on reliance in human-AI decision-making with explanations. In Proceedings of the ACM on Human-Computer Interaction, volume 7, pages 1\u201332.   \nChenreddy, A. R., Bandi, N., and Delage, E. (2022). Data-driven conditional robust optimization. In Advances in Neural Information Processing Systems, volume 35, pages 9525\u20139537.   \nChristiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., and Amodei, D. (2017). Deep reinforcement learning from human preferences. In Advances in neural information processing systems, volume 30.   \nDelage, E. and Ye, Y. (2010). Distributionally robust optimization under moment uncertainty with application to data-driven problems. Operations Research, 58(3):595\u2013612.   \nDonahue, K., Kollias, K., and Gollapudi, S. (2023). When are two lists better than one?: Beneftis and harms in joint decision-making. arXiv preprint arXiv:2308.11721.   \nDong, C., Chen, Y., and Zeng, B. (2018). Generalized inverse optimization through online learning. In Advances in Neural Information Processing Systems, volume 31.   \nDong, C. and Zeng, B. (2021). Wasserstein distributionally robust inverse multiobjective optimization. In Proceedings of the AAAI Conference on Artificial Intelligence, number 7 in 35, pages 5914\u2013 5921.   \nElmachtoub, A. N., Lam, H., Zhang, H., and Zhao, Y. (2023). Estimate-then-optimize versus integrated-estimation-optimization: A stochastic dominance perspective. arXiv preprint arXiv:2304.06833.   \nGao, R. and Kleywegt, A. (2023). Distributionally robust stochastic optimization with wasserstein distance. Mathematics of Operations Research, 48(2):603\u2013655.   \nHu, X., Cirit, O., Binaykiya, T., and Hora, R. (2022). DeepETA: How uber predicts arrival times using deep learning. Uber Engineering Blog. Available at https://www.uber.com/en-CA/blog/deepetahow-uber-predicts-arrival-times/. Accessed: 2024-01-19.   \nJi, J., Qiu, T., Chen, B., Zhang, B., Lou, H., Wang, K., Duan, Y., He, Z., Zhou, J., Zhang, Z., et al. (2023). AI alignment: A comprehensive survey. arXiv preprint arXiv:2310.19852.   \nLiu, M., Tang, X., Xia, S., Zhang, S., Zhu, Y., and Meng, Q. (2023). Algorithm aversion: Evidence from ridesharing drivers. Management Science, 0(0).   \nMandi, J., Bucarey, V., Tchomba, M. M. K., and Guns, T. (2022). Decision-focused learning: through the lens of learning to rank. In International Conference on Machine Learning, pages 14935\u201314947. PMLR.   \nMerch\u00e1n, D., Arora, J., Pachon, J., Konduri, K., Winkenbach, M., Parks, S., and Noszek, J. (2022). 2021 Amazon last mile routing research challenge: Data set. Transportation Science, 0(0).   \nMohajerin Esfahani, P., Shafieezadeh-Abadeh, S., Hanasusanto, G. A., and Kuhn, D. (2018). Datadriven inverse optimization with imperfect information. Mathematical Programming, 167:191\u2013 234.   \nMohri, M., Rostamizadeh, A., and Talwalkar, A. (2018). Foundations of machine learning. MIT press.   \nNg, A. Y. and Russell, S. J. (2000). Algorithms for inverse reinforcement learning. In Proceedings of the Seventeenth International Conference on Machine Learning, page 663\u2013670.   \nNguyen, T. (2015). ETA phone home: How uber engineers an efficient route. Uber Engineering Blog. Available at https://www.uber.com/en-CA/blog/engineering-routing-engine/. Accessed: 2024-01-19.   \nRafailov, R., Sharma, A., Mitchell, E., Manning, C. D., Ermon, S., and Finn, C. (2024). Direct preference optimization: Your language model is secretly a reward model. Advances in Neural Information Processing Systems, 36.   \nR\u00f6nnqvist, M., Svenson, G., Flisberg, P., and J\u00f6nsson, L.-E. (2017). Calibrated route finder: Improving the safety, environmental consciousness, and cost effectiveness of truck routing in sweden. Interfaces, 47(5):372\u2013395.   \nShafer, G. and Vovk, V. (2008). A tutorial on conformal prediction. Journal of Machine Learning Research, 9(3).   \nSun, C., Liu, L., and Li, X. (2023). Predict-then-calibrate: A new perspective of robust contextual LP. In Advances in Neural Information Processing Systems.   \nSun, J., Zhang, D. J., Hu, H., and Van Mieghem, J. A. (2022). Predicting human discretion to adjust algorithmic prescription: A large-scale field experiment in warehouse operations. Management Science, 68(2):846\u2013865.   \nTan, Y., Terekhov, D., and Delong, A. (2020). Learning linear programs from optimal decisions. In Advances in Neural Information Processing Systems, volume 33, pages 19738\u201319749.   \nTang, B. and Khalil, E. B. (2022). Pyepo: A pytorch-based end-to-end predict-then-optimize library for linear and integer programming. arXiv preprint arXiv:2206.14234.   \nVovk, V., Gammerman, A., and Shafer, G. (2005). Algorithmic learning in a random world, volume 29. Springer.   \nWainwright, M. J. (2019). High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cambridge University Press.   \nWilder, B., Dilkina, B., and Tambe, M. (2019). Melding the data-decisions pipeline: Decision-focused learning for combinatorial optimization. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 1658\u20131665.   \nWirth, C., Akrour, R., Neumann, G., and F\u00fcrnkranz, J. (2017). A survey of preference-based reinforcement learning methods. Journal of Machine Learning Research, 18(136):1\u201346.   \nWu, F., Ke, J., and Wu, A. (2024). Inverse reinforcement learning with the average reward criterion. In Advances in Neural Information Processing Systems, volume 36. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Omitted Statements and Proofs in Section 3 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Poof of Lemma 1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof. We first show that $\\hat{\\mathbf{x}}\\,\\in\\,\\{(0,1),(u,0)\\}$ almost surely. Let $\\delta_{u}:=\\operatorname{arccos}\\left({1}/{\\sqrt{1+u^{2}}}\\right)$ , so $\\cos\\delta_{u}\\;=\\;1/\\sqrt{1+u^{2}}$ and $\\sin\\delta_{u}\\;=\\;u/\\sqrt{1+u^{2}}$ . It is easy to verify that, when $\\widehat{\\pmb{\\theta}}_{k}\\;\\in\\;\\Theta_{1}\\;:=\\;$ $\\{(\\cos\\delta,\\sin\\delta)\\,|\\,\\delta\\,\\in\\,(0,\\delta_{u}]\\},$ , we have $\\widehat{\\mathbf{x}}_{k}\\,=\\,\\widetilde{\\mathbf{x}}(\\widehat{\\pmb{\\theta}}_{k},u)\\,=\\,(0,1)$ almost surely; When $\\widehat{\\pmb{\\theta}}_{k}\\,\\in\\,\\Theta_{2}:=$ $\\{(\\cos\\delta,\\sin\\delta)\\,|\\,\\delta\\in(\\delta_{u},\\pi/2)\\}$ , we have $\\hat{\\mathbf{x}}_{k}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}}_{k},u)=(u,0)$ almost surely. Since $\\hat{\\theta}_{k}$ is uniformly distributed in $\\ensuremath{\\hat{\\pmb{\\theta}}}\\in\\Theta=\\Theta_{1}\\cup\\Theta_{2}$ , the distribution of $\\hat{\\mathbf{x}}_{k}$ is ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\hat{\\mathbf{x}}_{k}=\\left\\{\\begin{array}{r l}&{(0,1),\\;\\mathrm{w.p.}\\;2\\delta_{u}/\\pi}\\\\ &{(u,0),\\;\\mathrm{w.p.}\\;(\\pi-2\\delta_{u})/\\pi.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Given a sample set $\\mathcal{D}=\\left\\{\\mathbf{u}_{k},\\hat{\\mathbf{x}}_{k}\\right\\}_{k\\in[N]}$ , let $N_{1}$ and $N_{2}$ , respectively, denote the numbers of $(0,1)$ and $(u,0)$ in $\\mathcal{D}$ . We next show that when $N_{1}>0$ and $N_{2}>0$ , $\\theta_{u}$ is the unique optimal solution to $\\mathbf{IO}(\\dot{\\mathcal{D}})$ . Specifically, in Example 1, $\\mathbf{IO}(\\mathcal{D})$ is presented as follows. ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\bar{\\pmb\\theta}_{N}:=\\underset{\\pmb\\theta\\in\\Theta}{\\mathrm{argmin}}\\quad\\frac{N_{1}}{N}l_{1}(\\pmb\\theta)+\\frac{N_{2}}{N}l_{2}(\\pmb\\theta)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where ", "page_idx": 12}, {"type": "text", "text": "and ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{l_{1}(\\pmb\\theta)=\\left\\{0,\\begin{array}{l l}&{\\mathrm{~if~}\\pmb\\theta\\in\\Theta_{1},}\\\\ {\\qquad}&{\\mathrm{~if~}\\pmb\\theta\\in\\Theta_{2},}\\end{array}\\right.}\\\\ &{l_{2}(\\pmb\\theta)=\\left\\{\\begin{array}{l l}{u\\theta_{1}-\\theta_{2},}&{\\mathrm{~if~}\\pmb\\theta\\in\\Theta_{1},}\\\\ {0,}&{\\mathrm{~if~}\\pmb\\theta\\in\\Theta_{2}.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "A simple calculation gives that when $N_{1}>0$ and $N_{2}>0$ , the minimum is 0 which occurs uniquely at $\\pmb{\\theta}=(\\cos\\delta_{u},\\sin\\delta_{u})$ ; When $N_{2}=0$ , the minimum is 0 which occurs when $\\theta\\in\\Theta_{1}$ ; When $N_{1}=0$ , the minimum is 0 which occurs when $\\pmb{\\theta}\\in\\Theta_{2}$ . Therefore, we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{P}(N_{1}N_{2}>0)\\le\\mathbb{P}\\left(\\bar{\\theta}_{N}=(\\cos\\delta_{u},\\sin\\delta_{u})\\right)\\le1.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Given the probability distribution given in Equation (15) and that $\\mathcal{D}$ is generated using i.i.d. samples from $\\mathbb{P}_{\\theta}$ , we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{P}(N_{1}N_{2}>0)=1-\\left(\\frac{2\\delta_{u}}{\\pi}\\right)^{N}-\\left(1-\\frac{2\\delta_{u}}{\\pi}\\right)^{N},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "which converges to 1 as $N$ goes to infinity. Therefore, we conclude that $\\mathbb{P}(\\bar{\\pmb{\\theta}}_{N}=(\\cos\\delta_{u},\\sin\\delta_{u}))$ converges to 1 as $N$ goes to infinity. ", "page_idx": 12}, {"type": "text", "text": "A.2 Proof of Proposition 1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof. We first consider the AOG and POG of the decision policy $\\bar{\\mathbf{x}}_{\\mathrm{IO}}(u):=\\tilde{\\mathbf{x}}(\\pmb{\\theta}_{u},u)$ separately in the following two lemmas. ", "page_idx": 12}, {"type": "text", "text": "Lemma 4. In Example 1, let $\\bar{\\mathbf{x}}_{\\mathrm{IO}}(u)=\\tilde{\\mathbf{x}}(\\pmb{\\theta}_{u},u)$ . For any $v\\in\\mathbb{R}_{+}$ there exists some $\\bar{u}>1$ such that $\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})>v$ for any $u>\\bar{u}_{A O G}$ . ", "page_idx": 12}, {"type": "text", "text": "Proof. According to the definition of $\\tilde{\\bf x}$ , we know that $\\bar{\\mathbf{x}}_{\\mathrm{IO}}(u)$ is uniformly drawn from ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\chi^{\\mathrm{OPT}}(\\theta_{u},u)=\\left\\{\\left(\\frac{u t}{\\sqrt{u^{2}+1}},1-\\frac{t}{\\sqrt{u^{2}+1}}\\right)\\bigg|\\in\\left[0,\\sqrt{u^{2}+1}\\right]\\right\\}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since the gr\u221aound-truth $\\pmb{\\theta}^{*}=(\\cos(\\pi/4),\\sin(\\pi/4))$ , the true optimal solution is $\\mathbf{x}^{*}=(0,1)$ with $\\tilde{f}(\\theta^{*},u)=\\sqrt{2}/2$ . Hence, we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})=\\int_{0}^{\\sqrt{u^{2}+1}}\\frac{\\sqrt{2}}{2\\sqrt{u^{2}+1}}\\left(1-\\frac{t}{\\sqrt{u^{2}+1}}+\\frac{u t}{\\sqrt{u^{2}+1}}\\right)d t-\\frac{\\sqrt{2}}{2}=\\frac{\\sqrt{2}(u-1)}{4}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Therefore, for any $v\\,\\in\\,\\mathbb{R}_{+}$ , there exists $\\bar{u}_{\\mathrm{AOG}}\\,=\\,2\\sqrt{2}v\\,+1$ such that $\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})\\,>\\,v$ for any $u>\\bar{u}_{\\mathrm{AOG}}$ . ", "page_idx": 12}, {"type": "text", "text": "Lemma 5. In Example $^{\\,l}$ , let $\\bar{\\mathbf{x}}_{\\mathrm{IO}}(u)=\\tilde{\\mathbf{x}}(\\pmb{\\theta}_{u},u)$ . for any $v\\in\\mathbb{R}_{+}$ there exists some $\\bar{u}_{P O G}>1$ such that $\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})>v$ for any $u>\\bar{u}_{P O G}$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. According to the definition of $\\tilde{\\bf x}$ , $\\bar{\\bf x}_{\\mathrm{IO}}(u)$ is uniformly drawn from ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\chi^{\\mathrm{OPT}}(\\theta_{u},u)=\\left\\{\\left(\\frac{u t}{\\sqrt{u^{2}+1}},1-\\frac{t}{\\sqrt{u^{2}+1}}\\right)\\bigg|\\in\\left[0,\\sqrt{u^{2}+1}\\right]\\right\\}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "It is easy to verify that, when $\\widehat{\\pmb{\\theta}}\\in\\Theta_{1}:=\\{(\\cos\\delta,\\sin\\delta)\\,|\\,\\delta\\in(0,\\delta_{u}]\\}$ , we have $\\hat{\\mathbf{x}}_{k}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},u)=(0,1)$ with ${\\tilde{f}}({\\hat{\\pmb{\\theta}}},u)\\;=\\;{\\hat{\\theta}}_{2}$ almost surely; When $\\widehat{\\pmb{\\theta}}\\;\\in\\;\\Theta_{2}\\;:=\\;\\left\\{(\\cos\\delta,\\sin\\delta)\\;|\\;\\delta\\;\\in\\;(\\delta_{u},\\pi/2\\right\\}$ , we have $\\hat{\\mathbf{x}}_{k}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},u)=(u,0)$ with ${\\tilde{f}}({\\hat{\\pmb{\\theta}}},u)=u{\\hat{\\theta}}_{1}$ almost surely. Since the optimal solution drawn from $\\mathcal{X}^{\\mathrm{OPT}}(\\pmb{\\theta}_{u},u)$ is independent of the DM\u2019s perception $\\hat{\\pmb\\theta}$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\gamma_{\\mathrm{OG}}({\\bf\\bar{x}}_{\\mathrm{lo}})=\\int_{0}^{\\delta_{\\mathrm{s}}}\\int_{0}^{\\sqrt{u^{2}+1}}\\frac{1}{\\sqrt{u^{2}+1}}\\left[\\frac{u t}{\\sqrt{u^{2}+1}}\\cos\\delta+\\left(1-\\frac{t}{\\sqrt{u^{2}+1}}\\right)\\sin\\delta-\\sin\\delta\\right]d t\\,d\\delta}\\ ~}\\\\ {{\\displaystyle~~~~~~+\\int_{\\delta_{u}}^{\\pi/2}\\int_{0}^{\\sqrt{u^{2}+1}}\\frac{1}{\\sqrt{u^{2}+1}}\\left[\\frac{u t}{\\sqrt{u^{2}+1}}\\cos\\delta+\\left(1-\\frac{t}{\\sqrt{u^{2}+1}}\\right)\\sin\\delta-u\\cos\\delta\\right]d t\\,d\\delta}\\ ~}\\\\ {{\\displaystyle~~~~~~=\\frac{1}{2}\\int_{0}^{\\delta_{u}}\\left(u\\cos\\delta-\\sin\\delta\\right)d\\delta+\\frac{1}{2}\\int_{\\delta_{u}}^{\\pi/2}(-u\\cos\\delta+\\sin\\delta)\\,d\\delta}\\ ~}\\\\ {{\\displaystyle~~~~~=\\sqrt{1+u^{2}}-\\frac{u+1}{2}.}}\\\\ {{\\displaystyle~~~~~~>\\frac{u-1}{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The inequality holds because ${\\sqrt{1+u^{2}}}\\,>\\,u$ . Therefore, we have, for any $v\\,\\in\\,\\mathbb{R}_{+}$ , there exists $\\bar{u}_{\\mathrm{POG}}=2v+1$ such that $\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})>v$ for any $u>\\bar{u}_{\\mathrm{POG}}$ . \u53e3 ", "page_idx": 13}, {"type": "text", "text": "Ba\u221ased on Lemmas 4 and 5, we conclude that for any $v\\in\\mathbb{R}_{+}$ , there exists $\\bar{u}=\\operatorname*{max}\\{\\bar{u}_{\\mathrm{AOG}},\\bar{u}_{\\mathrm{POG}}\\}=$ $2\\sqrt{2}v+1$ such that $\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})>v$ and $\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{IO}})>v$ for any $u>\\bar{u}$ . \u53e3 ", "page_idx": 13}, {"type": "text", "text": "A.3 Robustifying the Inverse Problem ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "An alternative approach to robustify the classic IO pipeline is to solve a distributionally robust inverse optimization problem. Specifically, consider the following loss function proposed by Mohajerin Esfahani et al. (2018). ", "page_idx": 13}, {"type": "text", "text": "Definition 4. The distributionally robust sub-optimality loss of $\\pmb{\\theta}$ is given by ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\ell_{D R-S}\\left(\\pmb{\\theta}\\right):=\\operatorname*{sup}_{\\mathbb{Q}\\in\\mathfrak{B}_{r}^{p}\\left(\\hat{\\mathbb{P}}_{\\mathbf{u},\\hat{\\mathbf{x}}}\\right)}\\rho^{\\mathbb{Q}}\\left[\\ell_{S}\\left(\\hat{\\mathbf{x}},\\mathcal{X}^{O P T}(\\pmb{\\theta},\\mathbf{u})\\right)\\right]\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\hat{\\mathbb{P}}_{\\mathbf{u},\\hat{\\mathbf{x}}}$ is the sample distribution of $\\mathcal{D}$ , $\\mathfrak{B}_{r}^{p}(\\hat{\\mathbb{P}}_{\\mathbf{u},\\hat{\\mathbf{x}}})$ is a $p$ -Wasserstain ball of radius r centered at $\\hat{\\mathbb P}_{\\mathbf{u},\\hat{\\mathbf{x}}}$ , and $\\rho^{\\mathbb{Q}}$ is a risk measure, e.g., the value at risk. ", "page_idx": 13}, {"type": "text", "text": "The distributionally robust inverse optimization problem is ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbf{DRIO}(\\mathcal{D}):\\underset{\\theta\\in\\Theta}{\\mathrm{minimize}}\\quad\\ell_{\\mathrm{DR-S}}(\\pmb{\\theta}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "As shown by Mohajerin Esfahani et al. (2018), the estimated parameters from DRIO achieve bounded out-of-sample sub-optimality loss with a high probability. However, this does not imply bounded AOG and POG for the decision policy. ", "page_idx": 13}, {"type": "text", "text": "Lemma 6. In Example 1, $\\theta_{u}$ is an optimal solution to DRIO $(\\mathcal{D})$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. As shown in the proof of Lemma 7, when $\\alpha\\in(0,\\pi/2)$ , the RFO $(\\mathcal{C}(\\theta_{u},\\alpha),u)$ has a unique optimal solution $(0,1)$ . So $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(u)=(0,1)$ almost surely, when $\\bar{\\pmb{\\theta}}_{N}=\\dot{\\pmb{\\theta}}_{u}$ and $\\alpha\\in(0,\\pi/2)$ . It is easy to verify that, when $\\widehat{\\pmb{\\theta}}\\in\\Theta_{1}:=\\{(\\cos\\delta,\\sin\\delta)\\,|\\,\\delta\\in\\,(0,\\delta_{u}]\\}$ , we have $\\hat{\\mathbf{x}}_{k}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},u)=(0,1)$ ", "page_idx": 13}, {"type": "text", "text": "almost surely; When $\\hat{\\pmb{\\theta}}\\in\\Theta_{2}:=\\{(\\cos\\delta,\\sin\\delta)\\,|\\,\\delta\\in\\,(\\delta_{u},\\pi/2)\\}$ , we have $\\hat{\\mathbf{x}}_{k}\\,=\\hat{\\mathbf{x}}(\\hat{\\pmb{\\theta}},u)=(u,0)$ almost surely. Hence, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})=\\int_{0}^{\\delta_{u}}\\frac{\\pi}{2}\\times0\\,d\\delta+\\int_{\\delta_{u}}^{\\pi/2}\\frac{\\pi}{2}\\times\\sin\\delta\\,d\\delta=-\\frac{\\pi}{2}\\cos\\delta\\Big|_{\\delta_{u}}^{\\pi/2}=\\frac{\\pi}{2\\sqrt{1+u^{2}}}<\\frac{\\pi}{2\\sqrt{2}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The inequality holds because $u>1$ . ", "page_idx": 14}, {"type": "text", "text": "According to Lemma 1, we know that $\\mathbb{P}(\\bar{\\pmb{\\theta}}_{N}=\\pmb{\\theta}_{u})\\rightarrow\\mathbb{1}$ as $N\\rightarrow\\infty$ . So we conclude that, when $\\alpha\\in(0,\\pi/2)$ , we have $\\mathbb{P}\\left[\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})<\\pi/2\\sqrt{2}\\right]\\to1$ as $N\\rightarrow\\infty$ . \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Lemma 6 shows that, in Example 1, the estimated parameter from $\\mathbf{DRIO}(\\mathcal{D})$ may still be $\\theta_{u}$ . Hence, the decision policy is identical to $\\bar{\\bf x}_{\\mathrm{IO}}$ whose AOG and POG can be unbounded. The fundamental reason behind these negative results is the misalignment between the sub-optimality loss and the evaluation metrics. Achieving a low sub-optimality loss means that the suggested and observed decisions are of similar quality as evaluated using the estimated parameters. However, this does not speak to the similarity between these two decisions with respect to the DM\u2019s perceived parameters (POG) or the ground-truth parameters (AOG). Therefore, the out-of-sample guarantees on the suboptimality loss do not translate into bounded AOG or POG. ", "page_idx": 14}, {"type": "text", "text": "A.4 Proof of Lemma 2 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We consider the AOG and POG of conformal IO separately in the following two lemmas. ", "page_idx": 14}, {"type": "text", "text": "Lemma 7. In Example 1, let $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(u)$ be an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}}_{N},\\alpha),u)$ where $\\bar{\\pmb\\theta}_{N}$ is an optimal solution to $\\mathbf{IO}(\\mathcal{D})$ with the sub-optimality loss (6). When $\\alpha\\,\\in\\,(0,\\pi/2)$ , we have $\\mathbb{P}\\left[\\mathrm{AOG}(\\mathbf{x}_{\\mathrm{CIO}})=0\\right]\\rightarrow1$ as $N\\rightarrow\\infty$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. We first show that when $\\bar{\\pmb{\\theta}}=\\pmb{\\theta}_{u}$ and $\\alpha\\in(0,\\pi/2)$ , RFO $(\\mathcal C(\\bar{\\pmb\\theta},\\alpha),u)$ has a unique optimal solution $(0,1)$ . Let ${\\bf x}_{1}=(0,1)$ , $\\mathbf{x}_{2}=(0,2)$ , $\\mathbf{x}_{3}=(u,0)$ and $\\mathbf{x}_{4}=(u,2)$ denote the four extreme points of the feasible region $\\chi_{(u)}$ , respectively, and ", "page_idx": 14}, {"type": "equation", "text": "$$\nR(\\mathbf{x}):=\\operatorname*{max}_{\\theta\\in{\\mathcal{C}}(\\theta_{u},\\alpha)}\\theta_{1}x_{1}+\\theta_{2}x_{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since FO is a linear program, it suffices to show that, when $\\alpha\\;\\;\\in\\;\\;(0,\\pi/2)$ , $R(\\mathbf{x}_{1})\\quad<$ $\\operatorname*{min}\\{R(\\mathbf{x}_{2}),R(\\mathbf{x}_{3}),R(\\bar{\\mathbf{x}_{4}})\\}$ because, if there exists an optimal solution that is not an extreme point, then there must exist another extreme point $\\mathbf{x}_{i}$ such that $R(\\mathbf{x}_{1})=R(\\mathbf{x}_{i})$ where $i\\neq1$ . Next, we compare $R(\\mathbf{x}_{1})$ with $R(\\mathbf{x}_{2}),R(\\mathbf{x}_{3})$ , and $R(\\mathbf{x}_{4})$ . ", "page_idx": 14}, {"type": "text", "text": "It is easy to verify that ", "page_idx": 14}, {"type": "equation", "text": "$$\nR(\\mathbf{x}_{1})=\\left\\{\\!\\!\\begin{array}{l l}{\\sin(\\delta_{u}+\\alpha),}&{\\mathrm{~if~}\\alpha\\in(0,\\pi/2-\\delta_{u}],}\\\\ {1,}&{\\mathrm{~if~}\\alpha\\in(\\pi/2-\\delta_{u},\\pi/2).}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For $\\mathbf{x}_{2}$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\nR(\\mathbf{x}_{2})=\\binom{2\\sin(\\delta_{u}+\\alpha),\\quad\\mathrm{if}\\;\\alpha\\in(0,\\pi/2-\\delta_{u}],}{2,\\quad\\quad\\quad}\\mathrm{if}\\;\\alpha\\in(\\pi/2-\\delta_{u},\\pi/2).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, we have $R(\\mathbf{x}_{1})<R(\\mathbf{x}_{2})$ when $\\alpha\\in(0,\\pi/2)$ . ", "page_idx": 14}, {"type": "text", "text": "For $\\mathbf{x}_{3}$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\nR(\\mathbf{x}_{3})=\\left\\{u\\cos(\\delta_{u}-\\alpha),\\quad\\mathrm{if}\\,\\alpha\\in(0,\\delta_{u}],\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $u>1$ , we have $\\pi/2-\\delta_{u}<\\pi/4<\\delta_{u}<\\pi/2$ . We will show that $R(\\mathbf{x}_{1})<R(\\mathbf{x}_{3})$ when $\\alpha$ is in $(0,\\pi/2-\\delta_{u})$ , $[\\pi/2-\\delta_{u},\\delta_{u})$ , and $[\\delta_{u},\\pi/2)$ . When $\\alpha\\in(0,\\pi/2-\\delta_{u})$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}{H(\\mathbf{x}_{1})=\\sin(\\delta_{u}+\\alpha)}\\\\ &{=\\sin\\delta_{u}\\cos\\alpha+\\cos\\delta_{u}\\sin\\alpha}\\\\ &{={\\cfrac{u}{\\sqrt{1+u^{2}}}}\\cos\\alpha+{\\cfrac{1}{\\sqrt{1+u^{2}}}}\\sin\\alpha}\\\\ &{\\prec{\\cfrac{u}{\\sqrt{1+u^{2}}}}\\cos\\alpha+{\\cfrac{u^{2}}{\\sqrt{1+u^{2}}}}\\sin\\alpha}\\\\ &{=u\\left({\\cfrac{1}{\\sqrt{1+u^{2}}}}\\cos\\alpha+{\\cfrac{u}{\\sqrt{1+u^{2}}}}\\sin\\alpha\\right)}\\\\ &{=u\\left(\\cos\\delta_{u}\\cos\\alpha+\\sin\\delta_{u}\\sin\\alpha\\right)}\\\\ &{=u\\cos(\\delta_{u}-\\alpha)}\\\\ &{=R(\\mathbf{x}_{3}).}\\end{array}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The second line holds due to the sum of angles identity. The third line holds due to the definition of $\\delta_{u}$ . The fourth line holds because $u>1$ . The fifth line is obtained by simple manipulation. The sixth line holds due to the definition of $\\delta_{u}$ . The seventh line holds due to the sum of angles identity. ", "page_idx": 15}, {"type": "text", "text": "When $\\alpha\\in[\\pi/2-\\delta_{u},\\delta_{u})$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle R({\\bf x}_{1})=1}\\\\ {\\displaystyle<1+\\frac{u-1}{u^{2}+1}}\\\\ {\\displaystyle=\\frac{u}{\\sqrt{u^{2}+1}}\\frac{1}{\\sqrt{u^{2}+1}}+\\frac{u^{2}}{\\sqrt{u^{2}+1}}\\frac{1}{\\sqrt{u^{2}+1}}}\\\\ {\\displaystyle=u\\cos\\delta_{u}\\frac{1}{\\sqrt{u^{2}+1}}+u\\sin\\delta_{u}\\frac{1}{\\sqrt{u^{2}+1}}}\\\\ {\\displaystyle<u\\cos\\delta_{u}\\cos\\alpha+u\\sin\\delta_{u}\\sin\\alpha}\\\\ {\\displaystyle=u\\cos(\\delta_{u}-\\alpha)}\\\\ {\\displaystyle=R({\\bf x}_{3}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The second line holds because $u>1$ . The third line is obtained through simple manipulation. The forth line holds due to the definition of $\\delta_{u}$ . For the fifth line, we know that $\\alpha\\in[\\pi/2-\\delta_{u},\\delta_{u})\\subseteq$ $[\\pi/4-\\pi/2]$ where $\\cos\\alpha$ is strictl\u221ay decreasing in $\\alpha$ and where $\\sin\\alpha$ is strictly increasi\u221ang in $\\alpha$ . Therefore, $\\cos\\alpha\\,<\\,\\cos\\delta_{u}\\,=\\,1/\\sqrt{u^{2}+1}$ and $\\sin\\alpha\\,\\leq\\,\\sin(\\pi/2\\,-\\,\\delta_{u})\\,=\\,\\cos\\delta_{u}\\,=\\,1/\\sqrt{u^{2}+1}$ . Hence, the fifth line holds. The sixth line holds due to the sum of angles identity. ", "page_idx": 15}, {"type": "text", "text": "When $\\alpha\\in[\\delta_{u},\\pi/2)$ , we have $R(\\mathbf{x}_{1})=1<u=R(\\mathbf{x}_{3})$ . ", "page_idx": 15}, {"type": "text", "text": "Hence, $R(\\mathbf{x}_{1})<R(\\mathbf{x}_{3})$ when $\\alpha\\in(0,\\pi/2)$ . ", "page_idx": 15}, {"type": "text", "text": "For $\\mathbf{x}_{4}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nR(\\mathbf{x}_{4})=\\operatorname*{max}_{\\delta\\in\\mathcal{C}(\\delta_{u},\\alpha)}u\\cos\\delta+2\\sin\\delta.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let $\\delta_{1}^{*}$ denote the optimal solution to the maximization problem for calculating $R(\\mathbf{x}_{1})$ . It is easy to verify that $\\delta_{1}^{*}\\in(0,\\bar{\\pi}/2)$ when $\\alpha\\in(0,\\pi/2)$ . So cos $\\delta_{1}^{*}>0$ and $\\sin\\delta_{1}^{*}>0$ . Hence, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nR(\\mathbf{x}_{4})=\\operatorname*{max}_{\\delta\\in\\mathcal{C}(\\delta_{u},\\alpha)}u\\cos\\delta+2\\sin\\delta\\geq u\\cos\\delta_{1}^{*}+2\\sin\\delta_{1}^{*}>\\sin\\delta_{1}^{*}=R(\\mathbf{x}_{1}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The first inequality holds because ${\\delta}_{1}^{*}$ may not be the maximizer of the problem associated with $\\mathbf{x}_{4}$ The second inequality holds because $u>1$ , $\\cos\\delta_{1}^{*}>0$ , and $\\sin\\delta_{1}^{*}>0$ . ", "page_idx": 15}, {"type": "text", "text": "Hence, when $\\alpha\\in(0,\\pi/2)$ , RFO $(\\mathcal{C}(\\delta_{u},\\alpha),u)$ has a unique optimal solution $\\mathbf{x}_{1}$ , so $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(u)=(0,1)$ almost surely. Given that $(0,1)$ is also the optimal solution to ${\\bf F O}(\\delta^{*},u)$ , we have $\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})=0$ when $\\bar{\\pmb{\\theta}}_{N}\\,=\\,\\pmb{\\theta}_{u}$ and $\\alpha\\,\\in\\,(0,\\pi/2)$ . According to Lemma 1, we know that $\\mathbb{P}(\\bar{\\pmb{\\theta}}_{N}=\\pmb{\\theta}_{u})\\rightarrow1$ as $N\\rightarrow\\infty$ . So we conclude that, when $\\alpha\\in(0,\\pi/2)$ , we have $\\mathbb{P}\\left[\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})=0\\right]\\rightarrow1$ as $N\\rightarrow\\infty$ . ", "page_idx": 15}, {"type": "text", "text": "Lemma 8. In Example 1, let $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(u)$ be an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}}_{N},\\alpha),u)$ where $\\bar{\\pmb\\theta}_{N}$ is an optimal solution t\u221ao $\\mathbf{IO}(\\mathcal{D})$ with the sub-optimality loss (6). When $\\alpha\\,\\in\\,(0,\\pi/2)$ , we have $\\mathbb{P}\\left[\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})<\\pi/2\\sqrt{2}\\right]\\to1$ as $N\\rightarrow\\infty$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. As shown in the proof of Lemma 7, when $\\alpha\\in(0,\\pi/2)$ , the RFO $(\\mathcal{C}(\\theta_{u},\\alpha),u)$ has a unique optimal solution $(0,1)$ . So $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(u)=(0,1)$ almost surely, when $\\bar{\\pmb{\\theta}}_{N}=\\dot{\\pmb{\\theta}}_{u}$ and $\\dot{\\alpha}\\in(0,\\pi/2)$ . It is easy to verify that, when $\\widehat{\\pmb{\\theta}}\\in\\Theta_{1}:=\\{(\\cos\\delta,\\sin\\delta)\\,|\\,\\delta\\in\\,(0,\\delta_{u}]\\}$ , we have $\\hat{\\mathbf{x}}_{k}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},u)=(0,1)$ almost surely; When $\\hat{\\pmb{\\theta}}\\in\\Theta_{2}:=\\{(\\cos\\delta,\\sin\\delta)\\,|\\,\\delta\\in\\,(\\delta_{u},\\pi/2)\\}$ , we have $\\hat{\\mathbf{x}}_{k}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},u)=(u,0)$ almost surely. Hence, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})=\\int_{0}^{\\delta_{u}}\\frac{\\pi}{2}\\times0\\,d\\delta+\\int_{\\delta_{u}}^{\\pi/2}\\frac{\\pi}{2}\\times\\sin\\delta\\,d\\delta=-\\frac{\\pi}{2}\\cos\\delta\\Big|_{\\delta_{u}}^{\\pi/2}=\\frac{\\pi}{2\\sqrt{1+u^{2}}}<\\frac{\\pi}{2\\sqrt{2}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The inequality holds because $u>1$ . ", "page_idx": 16}, {"type": "text", "text": "According to Lemma 1, we know that $\\mathbb{P}(\\bar{\\pmb{\\theta}}_{N}=\\pmb{\\theta}_{u})\\rightarrow\\mathbb{1}$ as $N\\rightarrow\\infty$ . So we conclude that, when $\\alpha\\in(0,\\pi/2)$ , we have $\\mathbb{P}\\left[\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})<\\pi/2\\sqrt{2}\\right]\\to1$ as $N\\rightarrow\\infty$ . \u53e3 ", "page_idx": 16}, {"type": "text", "text": "B Proof of Statements in Section 4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "B.1 Definitions ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Definition 5 (Empirical Rademacher Complexity). Let $\\mathcal{F}$ be a class of functions mapping from $\\mathcal{Z}=\\{Z_{1},Z_{2},...\\,,Z_{m}\\}$ to $[a,b]$ and $\\mathcal{D}$ be a fixed sample of size $N$ with elements in $\\mathcal{Z}$ , then the empirical Rademacher Complexity of $\\mathcal{F}$ with respect to the sample $\\mathcal{D}$ is defined as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\Re}_{\\mathcal{D}}(\\mathcal{F}):=\\mathbb{E}_{\\pmb{\\sigma}}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\frac{1}{N}\\sum_{i\\in[N]}\\sigma_{i}f(Z_{i})\\right]\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\pmb{\\sigma}=(\\sigma_{1},\\sigma_{2},\\ldots,\\sigma_{N})^{\\intercal}$ with $\\sigma_{i}$ \u2019s being independent uniform random variables taking values in $\\{-1,1\\}$ . ", "page_idx": 16}, {"type": "text", "text": "Definition 6 (Rademacher Complexity). Let $\\mathbb{P}$ denote the distribution according to which samples are drawn. For any integer $N\\geq1$ , the Rademacher complexity of a function class $\\mathcal{F}$ is the expectation of the empirical Rademacher complexity over the samples of size $N$ drawn from $\\mathbb{P}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathfrak{R}_{N}(\\mathcal{F}):=\\mathbb{E}_{\\mathcal{D}\\sim\\mathbb{P}^{N}}\\left[\\hat{\\mathfrak{R}}_{\\mathcal{D}}(\\mathcal{F})\\right]\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Definition 7 (Growth Function). Let $\\mathcal{H}$ be a class of functions that take values in $\\{-1,1\\}$ . The growth function $\\Pi_{\\mathcal{H}}:\\mathbb{N}\\rightarrow\\mathbb{N}$ for $\\mathcal{H}$ is defined as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Pi_{\\mathcal{H}}(N):=\\operatorname*{max}_{(Z_{1},Z_{2},\\ldots,Z_{N})\\in\\mathcal{Z}^{N}}\\left|\\left\\{(h(Z_{1}),h(Z_{2}),\\ldots,h(Z_{N}))\\:|\\:h\\in\\mathcal{H}\\right\\}\\right|\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which measures the maximum number of distinct ways in which $N$ data points in $\\mathcal{Z}$ can be classified using the function class $\\mathcal{H}$ . ", "page_idx": 16}, {"type": "text", "text": "B.2 Useful Lemmas ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Lemma 9 (Corollary 3.1 in Mohri et al. (2018)). Let $\\mathcal{H}$ be a class of functions taking values in $\\{1,-1\\}$ , then, for any integer $N\\geq1$ , the following holds ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Re_{N}(\\mathcal{H})\\leq\\sqrt{\\frac{2\\log\\Pi_{\\mathcal{H}}(N)}{N}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Lemma 10 (Theorem 4.10 in Wainwright (2019)). For any $b$ -uniformly bounded class of functions $\\mathcal{F}$ , any positive integer $N\\geq1$ , and any scalar $\\delta\\geq0$ , with probability at least $1-\\exp\\left(-\\dot{N}\\delta^{2}/(2b^{2})\\right)$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{f\\in\\mathcal{F}}\\left|\\frac{1}{N}\\sum_{i\\in[N]}f(X_{i})-\\mathbb{E}\\left[f(X_{i})\\right]\\right|\\leq2\\Re_{N}(\\mathcal{F})+\\delta\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\Re({\\mathcal{F}})$ denotes the Rademacher complexity of the function class $\\mathcal{F}$ . ", "page_idx": 16}, {"type": "text", "text": "B.3 Proof of Theorem 1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. We first present the extensive formulation of Problem (10). For convenience, we define $\\hat{\\Theta}_{k}\\,:=\\,\\Theta^{\\mathrm{OPT}}(\\bar{\\mathbf{u}_{k}},\\hat{\\mathbf{x}}_{k})$ for any $k~\\in~[N]$ . When $\\alpha\\,\\in\\,[0,\\pi]$ , $\\cos\\alpha$ is a strictly decreasing in $\\alpha$ Therefore, minimizing $\\alpha$ is equivalent to maximizing the value of $\\cos\\alpha$ . We can replace the decision variable $\\alpha$ in Problem (10) with a new decision variable $c:=\\cos\\alpha$ with an additional constraint $t$ with $-1\\le c\\le1$ . In addition, we introduce a new set of decision variables $y_{k}\\in\\{0,1\\}$ that indicate if $\\hat{\\Theta}_{k}$ intersects with the learned uncertainty set $(=1)$ ) or not $(=0)$ ) for any $k\\in\\mathcal{K}_{\\mathrm{val}}$ . Problem (10) can be presented as follows. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{c,\\{\\theta_{k}\\}_{k\\in\\mathcal{K}_{\\mathrm{st}}},\\{y,\\mathbf{k}\\}_{k\\in\\mathcal{K}_{\\mathrm{st}}}}{\\mathrm{maximize}}}&{c}\\\\ {\\mathrm{subject{\\_}}}&{\\hat{\\mathbf{x}}_{k}\\in\\mathcal{X}^{\\mathrm{oPT}}(\\theta_{k},\\mathbf{u}_{k}),\\quad\\forall k\\in\\mathcal{K}_{\\mathrm{val}}}\\\\ &{\\theta_{k}^{\\top}\\bar{\\theta}\\geq c+2(y_{k}-1),\\quad\\forall k\\in\\mathcal{K}_{\\mathrm{val}}}\\\\ &{\\displaystyle\\sum_{k\\in\\mathcal{K}_{\\mathrm{st}}}y_{k}\\geq\\left\\lceil\\gamma(N_{\\mathrm{val}}+1)\\right\\rceil}\\\\ &{\\|\\theta_{k}\\|_{2}=1,\\quad\\forall k\\in\\mathcal{K}_{\\mathrm{val}}}\\\\ &{\\mathrm{\\quad}-1\\leq c\\leq1}\\\\ &{y_{k}\\in\\{0,1\\},\\quad\\forall k\\in\\mathcal{K}_{\\mathrm{val}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Constraints (39b) ensure that $\\theta_{k}$ is a member of $\\hat{\\Theta}_{k}$ for any $k\\,\\in\\,\\kappa_{\\mathrm{val}}$ . Constraints (39c) decide if $\\theta_{k}$ should be taken into account when calculating the maximal cosine value $c$ based on if $\\hat{\\Theta}_{k}$ intersects with $\\mathcal{C}$ . Constraint (39d) ensures that $\\mathcal{C}$ intersects with at least $\\lceil\\gamma(N_{\\mathrm{val}}+1)\\rceil$ inverse feasible sets. Constraint (39e) enforces $\\theta_{k}$ to be on the unit sphere as defined in Equation (9). Constraints (39f)\u2013(39g) specify the ranges of the decision variables. ", "page_idx": 17}, {"type": "text", "text": "Observing that the objective of Problem (39) is to maximize $c$ and that decision variables $\\pmb{\\theta}_{k}$ of different data points only interact in Constraints $(39\\mathrm{c})$ . We can re-write Problem (39) as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{\\boldmath~\\sject~to~}}&{c\\leq c_{k}-2(y_{k}-1),\\quad\\forall k\\in\\mathcal{K}_{\\mathrm{val}}}\\\\ &{\\displaystyle\\sum_{k\\in\\mathcal{K}_{\\mathrm{val}}}y_{k}\\geq\\lceil\\gamma(N_{\\mathrm{val}}+1)\\rceil}\\\\ &{\\displaystyle-1\\leq c\\leq1}\\\\ &{y_{k}\\in\\{0,1\\},\\quad\\forall k\\in\\mathcal{K}_{\\mathrm{val}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{c_{k}:=\\underset{\\theta_{k}}{\\mathrm{maximize}}}&{\\theta_{k}^{\\top}\\bar{\\theta}}\\\\ {\\mathrm{subject~to}}&{\\hat{\\mathbf{x}}_{k}\\in\\mathcal{X}^{\\mathrm{oPT}}(\\pmb\\theta_{k},\\mathbf{u}_{k})}\\\\ &{\\|\\pmb\\theta_{k}\\|_{2}\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that we replace Constraints (39e) with Constraints (41c) because the objective of Problem (41) is to maximize the inner product of $\\theta_{k}$ and $\\bar{\\pmb\\theta}$ , so the maximum only occurs when $\\|\\pmb{\\theta}_{k}\\|_{2}\\,=\\,1$ . We further observe that the optimal solution to Problem (40a) is to set $y_{k}=1$ for all $k$ such that $c_{k}\\geq\\Gamma_{\\tau}\\left(\\left\\{c_{k}\\right\\}_{k\\in\\mathcal{K}_{\\mathrm{val}}}\\right)$ and $y_{k}=0$ otherwise. Therefore, the optimal objective value of Problem (40a) is $c=\\Gamma_{\\tau}\\left(\\{c_{k}\\}_{k\\in\\mathcal{K}_{\\mathrm{val}}}\\right)$ corresponding to $\\alpha_{\\gamma}=\\operatorname{arccos}\\Gamma_{\\tau}\\left(\\{c_{k}\\}_{k\\in K_{\\mathrm{val}}}\\right)$ . ", "page_idx": 17}, {"type": "text", "text": "B.4 Proof of Lemma 3 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. Proof. For any fixed $\\mathbf{x}$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f\\left(\\pmb{\\theta},\\hat{\\mathbf{x}}\\right)-f\\left(\\pmb{\\theta}^{\\prime},\\hat{\\mathbf{x}}\\right)=\\displaystyle\\sum_{i\\in[d]}\\left(\\theta_{i}-\\theta_{i}^{\\prime}\\right)f_{i}\\left(\\hat{\\mathbf{x}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\sqrt{\\displaystyle\\sum_{i\\in[d]}f_{i}^{2}(\\hat{\\mathbf{x}})}\\sqrt{\\displaystyle\\sum_{i\\in[d]}(\\theta_{i}-\\theta_{i}^{\\prime})^{2}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\nu(\\hat{\\mathbf{x}})\\|\\theta-\\theta^{\\prime}\\|_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\begin{array}{r}{\\nu(\\hat{\\mathbf{x}}):=\\sqrt{\\sum_{i\\in[d]}f_{i}^{2}(\\hat{\\mathbf{x}})}}\\end{array}$ . The inequality follows the Cauchy-Schwartz inequality. ", "page_idx": 18}, {"type": "text", "text": "B.5 Proof of Theorem 2 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. We first prove the learned uncertainty set is conservatively valid. Following the conformal prediction language used by Vovk et al. (2005), we define a conformality measure of each data point,i.e. an observed decision and exogenous parameter pair, $A_{\\bar{\\theta}}:\\mathbb{R}^{n}\\times\\mathcal{U}\\rightarrow\\mathbb{R}_{+}$ as follows ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u}):=\\underset{\\theta}{\\mathrm{maximize}}}&{\\theta^{\\top}\\bar{\\theta}}\\\\ {\\mathrm{subject\\to}}&{\\theta\\in\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}},\\mathbf{u})}\\\\ &{\\lVert\\theta\\rVert_{2}\\le1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We note that $c_{k}\\;=\\;A_{\\bar{\\theta}}(\\hat{\\bf x}_{k},{\\bf u}_{k})$ for any $k\\,\\in\\,\\mathcal{K}_{\\mathrm{val}}$ where $c_{k}$ is defined in Theorem 1. Let $\\tau=$ $\\lceil\\gamma(N_{\\mathrm{val}}+1)\\rceil$ , and $\\bar{\\mathcal{A}}:=\\,\\,\\{A_{\\bar{\\theta}}(\\hat{\\mathbf{x}}_{k},\\mathbf{u}_{k})\\}_{k\\in K_{\\mathrm{val}}}$ , or equivalently, $\\mathcal{A}\\;:=\\;\\{c_{k}\\}_{k\\in\\mathcal{K}_{\\mathrm{val}}}$ . Due to the definition of ${\\mathcal{C}}\\left({\\bar{\\pmb\\theta}},\\alpha\\right)$ and that $\\alpha$ is chosen such that $\\cos\\alpha\\,=\\,\\Gamma^{\\tau}(A)$ , the event $\\hat{\\mathbf{\\rho}}^{\\mathrm{c}}\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}},\\mathbf{u})\\cap$ $c(\\bar{\\pmb{\\theta}},\\alpha)\\neq\\alpha^{,*}$ is equivalent to ${}^{\\ast}A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})\\geq\\Gamma^{\\tau}(A)^{,*}$ , so ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}},\\mathbf{u})\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha)\\neq\\varnothing\\right)=\\mathbb{P}\\left(A_{\\bar{\\pmb{\\theta}}}(\\hat{\\mathbf{x}},\\mathbf{u})\\geq\\Gamma^{\\tau}(\\mathcal{A})\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Assumption 1 implies that the dataset ${\\mathcal{D}}^{\\prime}\\,=\\,{\\mathcal{D}}_{\\mathrm{val}}\\cup\\{({\\hat{\\mathbf{x}}},\\mathbf{u})\\}$ is exchangeable, i.e. the ordering of the data points in $\\mathcal{D}^{\\prime}$ does not affect its joint probability distribution (Shafer and Vovk, 2008). Therefore, the rank (from high to low) of $A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})$ in $A^{\\prime}:={\\dot{A}}\\cup\\{A_{\\bar{\\theta}}({\\hat{\\mathbf{x}}},\\mathbf{u})\\}$ is uniformly distributed in $\\{1,2,\\ldots,N_{\\mathrm{val}}+1\\}$ . So, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\gamma\\leq\\mathbb{P}\\left\\{A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})\\geq\\Gamma^{\\tau}(A^{\\prime})\\right\\}}\\\\ &{\\quad=1-\\mathbb{P}\\left\\{A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})<\\Gamma^{\\tau}(A^{\\prime})\\right\\}}\\\\ &{\\quad=1-\\mathbb{P}\\left\\{A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})<\\Gamma^{\\tau}(A)\\right\\}}\\\\ &{\\quad=\\mathbb{P}\\left\\{A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})\\geq\\Gamma^{\\tau}(A)\\right\\}}\\\\ &{\\quad=\\mathbb{P}\\left\\{\\\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}},\\mathbf{u})\\cap\\mathcal{C}(\\bar{\\theta},\\alpha)\\neq\\emptyset\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The first line holds due to the definition of $\\tau$ . We obtain the second line by taking the complement of the event in the first line (inside the probability). The third line holds because $A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})$ can never be strictly smaller than itself, so any elements in $\\mathcal{A^{\\prime}}$ that are strictly smaller than $A_{\\bar{\\theta}}(\\hat{\\mathbf{x}},\\mathbf{u})$ are in $\\boldsymbol{\\mathcal{A}}$ . Note that this line holds only when $\\tau\\leq N_{\\mathrm{val}}$ , which occurs when $\\gamma\\leq N_{\\mathrm{val}}/(N_{\\mathrm{val}}+1)$ , because $\\boldsymbol{\\mathcal{A}}$ only has $N_{\\mathrm{val}}$ elements. We obtain the third line by taking the complement of the event in the second line (inside the probability). The last line holds due to Equation (43). We note that all the probabilities are over the joint distribution of $\\mathcal{D}_{\\mathrm{val}}$ and the new sample, i.e. $\\mathcal{D}^{\\prime}$ . ", "page_idx": 18}, {"type": "text", "text": "We next prove that the learned uncertainty set is asymptotically exact. Let $\\boldsymbol{z}_{k}:=\\left(\\mathbf{u}_{k},\\hat{\\mathbf{x}}_{k}\\right)$ , ${\\mathcal{Z}}:=$ $\\{z_{k}\\}_{k\\in K_{\\mathrm{val}}}$ . We define a function class ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{H}=\\left\\{h(z,\\alpha)=\\mathbb{1}\\left[\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}},\\mathbf{u})\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha)\\right]\\mid\\alpha\\in(0,\\pi)\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $\\Pi_{\\mathcal{H}}$ denote the growth function of $\\mathcal{H}$ as defined in Definition 7. It is easy to verify that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Pi_{\\mathcal{H}}(N_{\\mathrm{val}})=N_{\\mathrm{val}}+1\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "because the value of $h(z,\\alpha)$ is monotonically increasing in $\\alpha$ for any fixed $z\\in{\\mathcal{Z}}$ , so changing the value of $\\alpha$ can only leads to $N_{\\mathrm{val}}+1$ different outcomes for a fixed dataset $\\mathcal{Z}$ . ", "page_idx": 18}, {"type": "text", "text": "Therefore, according to Lemma 9, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Re_{N_{\\mathrm{val}}}(\\mathcal{H})\\leq\\sqrt{\\frac{2\\log(N_{\\mathrm{val}}+1)}{N_{\\mathrm{val}}}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\Re_{N_{\\mathrm{val}}}(\\mathcal{H})$ denotes the Rademacher complexity of $\\mathcal{H}$ when sample size is $N_{\\mathrm{val}}$ , as defined in Definition 6. ", "page_idx": 18}, {"type": "text", "text": "We know that the value of $\\alpha$ is chosen such that it is the smallest value that satisfies ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{N_{\\mathrm{val}}}\\sum_{k\\in K_{\\mathrm{val}}}h(z_{k},\\alpha)=\\frac{1}{N_{\\mathrm{val}}}\\sum_{{k\\in K_{\\mathrm{val}}}}\\mathbb{1}\\left[\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}}_{k},\\mathbf{u}_{k})\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha)\\right]=\\frac{\\lceil\\gamma(N_{\\mathrm{val}}+1)\\rceil}{N_{\\mathrm{val}}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "so we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\gamma\\leq\\frac{1}{N_{\\mathrm{val}}}\\sum_{k\\in K_{\\mathrm{val}}}h(z_{k},\\alpha)\\leq\\gamma+\\frac{2}{N_{\\mathrm{val}}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The second inequality holds because ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\gamma(N_{\\mathrm{val}}+1)]}{N_{\\mathrm{val}}}=\\frac{\\lfloor\\gamma N_{\\mathrm{val}}\\rfloor+\\left\\lceil\\gamma N_{\\mathrm{val}}-\\lfloor\\gamma N_{\\mathrm{val}}\\rfloor+\\gamma\\right\\rceil}{N_{\\mathrm{val}}}\\le\\frac{\\gamma N_{\\mathrm{val}}+\\left\\lceil\\gamma N_{\\mathrm{val}}-\\lfloor\\gamma N_{\\mathrm{val}}\\rfloor+\\gamma\\right\\rceil}{N_{\\mathrm{val}}}\\le\\gamma+\\frac{2}{N_{\\mathrm{val}}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since $\\mathcal{D}_{\\mathrm{val}}$ is i.i.d. sampled, for any fixed $\\alpha$ , $\\begin{array}{r}{\\sum_{k\\in{\\cal K}_{\\mathrm{val}}}h(z_{k},\\alpha)/N_{\\mathrm{val}}}\\end{array}$ provides a sample average approximation to $\\mathbb{E}\\left[h(z,\\alpha)\\right]$ , which can be interpreted as $\\mathbb{P}\\left(\\Theta^{\\mathrm{OPT}}(\\hat{\\mathbf{x}},\\mathbf{u})\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha)\\right)$ for any new sample $({\\hat{\\pmb{\\theta}}},\\mathbf{u})$ from $\\mathbb{P}_{\\hat{\\pmb{\\theta}},{\\bf u}}$ and $\\hat{\\mathbf{x}}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},\\mathbf{u})$ . ", "page_idx": 19}, {"type": "text", "text": "By applying Lemma 10, we have, with probability at least $\\delta=1-1/N_{\\mathrm{val}}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left|\\frac{1}{N_{\\mathrm{val}}}\\sum_{k\\in K_{\\mathrm{val}}}h(z_{k},\\alpha)-\\mathbb{E}\\left[h(z,\\alpha)\\right]\\right|\\leq2\\Re_{N_{\\mathrm{val}}}(\\mathcal{H})+\\sqrt{\\frac{2\\log N_{\\mathrm{val}}}{N_{\\mathrm{val}}}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By combing (46)\u2013(50), we have, with probability at least $1-1/N_{\\mathrm{val}}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left|\\mathbb{P}\\left(\\Theta^{\\mathrm{opr}}(\\hat{\\mathbf{x}},\\mathbf{u})\\cap\\mathcal{C}(\\bar{\\theta},\\alpha)\\right)-\\gamma\\right|\\le\\sqrt{\\frac{8\\log(N_{\\mathrm{val}}+1)+2\\log N_{\\mathrm{val}}}{N_{\\mathrm{val}}}}+\\frac{2}{N_{\\mathrm{val}}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "B.6 Proof of Theorem 3 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We bound the AOG and POG of conformal IO separately in the following two propositions. ", "page_idx": 19}, {"type": "text", "text": "Proposition 2 (Conformal IO Achieves Bounded POG). L $e t\\;\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})$ be an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ for any $\\mathbf{u}\\in\\mathcal{U}$ , where $\\bar{\\pmb{\\theta}}\\in\\mathbb{R}^{d}$ and $\\alpha_{1}$ are chosen such that, for a new sample $(\\pmb\\theta^{\\prime},\\mathbf u^{\\prime})$ from $\\mathbb{P}_{(\\theta,\\mathbf{u})}$ and $\\mathbf{x}^{\\prime}=\\tilde{\\mathbf{x}}(\\pmb{\\theta}^{\\prime},\\mathbf{u}^{\\prime})$ , $\\mathbb{P}\\left(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})\\cap\\Theta^{\\mathrm{OPT}}(\\mathbf{u}^{\\prime},\\mathbf{x}^{\\prime})\\neq\\varnothing\\right)=1.$ . If Assumptions 2\u20133 hold, then ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})\\leq(\\eta-2\\cos2\\alpha_{1}+2)\\mu+\\eta\\mu_{\\mathrm{CIO}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\mu:=\\mathbb{E}[\\nu(\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},\\mathbf{u}))]$ and $\\mu_{\\mathrm{CIO}}:=\\mathbb{E}(\\nu[\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})])$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. We first bound the perceived optimality gap of a sampled DM. Let $({\\hat{\\pmb{\\theta}}},\\mathbf{u})$ be a sample from $\\mathbb{P}_{(\\pmb{\\theta},\\mathbf{u})},\\,\\hat{\\mathbf{x}}=\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},\\mathbf{u}),\\,\\hat{\\pmb{\\theta}}_{\\mathrm{CIO}}(\\mathbf{u})$ denote the optimal solution to the inner maximization problem in RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ when the outer decision variable is set to $\\hat{\\bf x}$ , $\\bar{\\theta}_{\\mathrm{CIO}}(\\mathbf{u})$ denote the optimal solution to the inner maximization problem in RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ when the outer decision variable is set to $\\bar{\\bf x}_{\\mathrm{CIO}}({\\bf u})$ , If $\\Theta^{\\mathrm{OPT}}\\left(\\hat{\\mathbf{x}},\\mathbf{u}\\right)\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})\\neq\\emptyset$ , let $\\tilde{\\pmb{\\theta}}$ be an element of $\\Theta^{\\mathrm{OPT}}\\left(\\hat{\\mathbf{x}},\\mathbf{u}\\right)\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad f\\left(\\hat{\\theta},\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)-f\\left(\\hat{\\theta},\\hat{\\mathbf{x}}\\right)}\\\\ &{\\leq f\\left(\\hat{\\theta},\\bar{\\kappa}_{\\mathrm{CO}}(\\mathbf{u})\\right)-f\\left(\\hat{\\theta},\\hat{\\mathbf{x}}\\right)+\\left[\\nu(\\hat{\\mathbf{x}})+\\nu\\left(\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)\\right]\\left\\Vert\\hat{\\theta}-\\bar{\\theta}\\right\\Vert_{2}}\\\\ &{\\leq f\\left(\\hat{\\theta},\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)-f\\left(\\hat{\\theta},\\hat{\\mathbf{x}}\\right)+\\eta\\left[\\nu(\\hat{\\mathbf{x}})+\\nu\\left(\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)\\right]}\\\\ &{\\leq f\\left(\\bar{\\theta}_{\\mathrm{CC}}(\\mathbf{u}),\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)-f\\left(\\hat{\\theta},\\hat{\\mathbf{x}}\\right)+\\eta\\left[\\nu(\\hat{\\mathbf{x}})+\\nu\\left(\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)\\right]}\\\\ &{\\leq f\\left(\\hat{\\theta}_{\\mathrm{CC}}(\\mathbf{u}),\\hat{\\mathbf{x}}\\right)-f\\left(\\hat{\\theta},\\hat{\\mathbf{x}}\\right)+\\eta\\left[\\nu(\\hat{\\mathbf{x}})+\\nu\\left(\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)\\right]}\\\\ &{\\leq\\nu(\\hat{\\mathbf{x}})\\left\\Vert\\hat{\\theta}_{\\mathrm{CIO}}(\\mathbf{u})-\\hat{\\theta}\\right\\Vert_{2}+\\eta\\left[\\nu(\\hat{\\mathbf{x}})+\\nu\\left(\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)\\right]}\\\\ &{\\leq2\\nu(\\hat{\\mathbf{x}})(1-\\cos2\\alpha_{1})+\\eta\\left(\\nu(\\hat{\\mathbf{x}})+\\nu\\left(\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right)\\right]}\\\\ &{=\\nu(\\hat{\\mathbf{x}})(\\eta-2\\cos2\\alpha_{1}+2)+\\eta\\left[\\bar{\\kappa}_{\\mathrm{CIO}}(\\mathbf{u})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The first line holds due to Lemma 3. The second line holds due to assumption 2. The third line holds due to the definition of $\\bar{\\theta}_{\\mathrm{CIO}}(u)$ . The fourth line holds because $\\left(\\Bar{\\mathbf{x}}_{\\mathrm{CIO}}\\,\\Bar{(}\\mathbf{u}),\\Bar{\\theta}_{\\mathrm{CIO}}(\\mathbf{u})\\right)$ is an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ . The fifth line holds due to Lemma 3. The sixth line holds because both $\\hat{\\pmb{\\theta}}_{\\mathrm{CIO}}(\\mathbf{u})$ and $\\tilde{\\pmb{\\theta}}$ are in $\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})$ so the angle between them is no larger than $2\\alpha_{1}$ . Since both $\\hat{\\pmb{\\theta}}_{\\mathrm{CIO}}(\\mathbf{u})$ and $\\tilde{\\pmb{\\theta}}$ are on the unit sphere, the $L_{2}$ distance between them are bounded by $2(1-\\cos2\\alpha_{1})$ . ", "page_idx": 20}, {"type": "text", "text": "Since $\\alpha_{1}$ is chosen such that $\\mathbb{P}\\left(\\pmb{\\Theta}^{\\mathrm{OPT}}\\left(\\hat{\\mathbf{x}},\\mathbf{u}\\right)\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})\\right)=1$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{POG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})=\\mathbb{E}\\left[f\\left(\\hat{\\pmb{\\theta}},\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})\\right)-f\\left(\\hat{\\pmb{\\theta}},\\hat{\\mathbf{x}}\\right)\\right]}\\\\ &{\\qquad\\qquad\\leq\\mathbb{E}\\left\\{\\nu(\\hat{\\mathbf{x}})(\\eta-2\\cos2\\alpha_{1}+2)+\\eta\\nu\\left[\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})\\right]\\right\\}}\\\\ &{\\qquad\\qquad=\\mu(\\eta-2\\cos2\\alpha_{1}+2)+\\eta\\mu_{\\mathrm{CIO}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\boldsymbol{\\mu}:=\\mathbb{E}\\left[\\boldsymbol{\\nu}(\\hat{\\mathbf{x}})\\right]$ and $\\mu_{\\mathrm{CIO}}:=\\mathbb{E}\\left(\\nu\\left[\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})\\right]\\right)$ . ", "page_idx": 20}, {"type": "text", "text": "Proposition 3 (Conformal IO Achieves Bounded AOG). Let $\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})$ be an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ for any $\\mathbf{u}\\in\\mathcal{U}$ , where $\\bar{\\pmb{\\theta}}\\in\\mathbb{R}^{d}$ and $\\alpha_{1}$ are chosen such that, for a new sample $(\\pmb\\theta^{\\prime},\\mathbf u^{\\prime})$ from $\\mathbb{P}_{(\\theta,\\mathbf{u})}$ and $\\mathbf{x}^{\\prime}=\\tilde{\\mathbf{x}}(\\pmb{\\theta}^{\\prime},\\mathbf{u}^{\\prime})$ , $\\mathbb{P}\\left(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})\\cap\\Theta^{\\mathrm{OPT}}(\\mathbf{u}^{\\prime},\\mathbf{x}^{\\prime})\\neq\\varnothing\\right)=1.$ . If Assumptions 2\u20133 hold, then ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})\\leq(2-2\\cos2\\alpha_{1}+\\eta+\\sigma)\\mu^{*}+(\\eta+\\sigma)\\mu_{\\mathrm{CIO}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\mu^{\\ast}:=\\mathbb{E}\\left(\\nu[\\tilde{\\mathbf{x}}(\\pmb{\\theta}^{\\ast},\\mathbf{u})]\\right)$ . ", "page_idx": 20}, {"type": "text", "text": "Proof. We first derive an upper bound on the optimality gap of the suggested decision $\\bar{\\bf x}_{\\mathrm{CIO}}({\\bf u})$ as evaluated using $\\pmb{\\theta}^{*}$ for any $\\mathbf{u}\\in\\mathcal{U}$ . Let $({\\hat{\\pmb{\\theta}}},\\mathbf{u})$ be a sample from $\\mathbb{P}_{(\\theta,\\mathbf{u})}$ , $\\hat{\\mathbf{x}}\\,=\\,\\tilde{\\mathbf{x}}(\\hat{\\pmb{\\theta}},\\mathbf{u})$ , and $\\tilde{\\pmb{\\theta}}$ be an element of $\\Theta^{\\mathrm{OPT}}\\left(\\hat{\\mathbf{x}},\\mathbf{u}\\right)\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})$ , which is non-empty almost surely because $\\alpha_{1}$ is chosen such that $\\mathbb{P}\\left(\\Theta^{\\mathrm{OPT}}\\left(\\hat{\\mathbf{x}},\\mathbf{u}\\right)\\cap\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1})\\right)=1$ . Let $\\bar{\\pmb{\\theta}}_{\\mathrm{CIO}}(\\mathbf{u})$ denote the optimal solution to the inner maximization problem in RFO $(\\mathcal{C}(\\bar{\\theta},\\dot{\\alpha}_{1}),\\mathbf{u})$ when the outer decision variable is set to $\\bar{\\bf x}_{\\mathrm{CIO}}({\\bf u})$ . For any $\\mathbf{u}\\in\\mathcal{U}$ , let $\\mathbf{x}^{*}(\\mathbf{u}):=\\tilde{\\mathbf{x}}(\\pmb{\\theta}^{*},\\mathbf{u})$ and $\\boldsymbol{\\theta}_{\\mathrm{CIO}}^{*}(\\mathbf{u})$ denote the optimal solution to the inner maximization problem in RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ when the outer decision variable is set to $\\mathbf{x}^{*}(\\mathbf{u})$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad I(\\theta^{*},\\chi_{\\mathbf{x}(0)}(u))-I(\\theta^{*},\\mathbf{x}^{*}(u))}\\\\ &{\\leq f\\left(\\overline{{\\nu}}(\\delta),\\chi_{\\mathbf{x}(0)}(u)\\right)-f\\left(\\overline{{\\nu}}(\\delta),x^{*}(u)\\right)+\\left(\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left[\\kappa^{*}(u)\\right]\\right)\\|\\theta^{*}-\\mathbb{E}(\\theta)}\\\\ &{\\leq f\\left(\\overline{{\\nu}}(\\delta),\\chi_{\\mathbf{x}(0)}(u)\\right)-f\\left(\\overline{{\\nu}}(\\delta),x^{*}(u)\\right)+\\sigma\\left(\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left[\\kappa^{*}(u)\\right]\\right)}\\\\ &{=\\mathbb{E}\\left[f\\left(\\delta,\\chi_{\\mathbf{x}(0)}(u)\\right)-f\\left(\\overline{{\\nu}},\\delta,x^{*}(u)\\right)\\right]+\\sigma\\left(\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left[\\kappa^{*}(u)\\right]\\right)}\\\\ &{\\leq\\mathbb{E}\\left[f\\left(\\delta,\\chi_{\\mathbf{x}(0)}(u)\\right)-f\\left(\\overline{{\\nu}},\\delta,x^{*}(u)\\right)+\\left(\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]\\right)}\\\\ &{\\quad+\\sigma\\left(\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left[\\kappa^{*}(u)\\right]\\right)}\\\\ &{\\leq\\mathbb{E}\\left[f\\left(\\delta,\\chi_{\\mathbf{x}(0)}(u)\\right)-f\\left(\\overline{{\\nu}},\\delta,x^{*}(u)\\right)+\\left(\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left[\\kappa\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]\\right)\\right.}\\\\ &{\\quad+\\sigma\\left.\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left(\\kappa^{*}(u)\\right)}\\\\ &{\\leq\\mathbb{E}\\left[f\\left(\\delta,\\chi_{\\mathbf{x}(0)}(u)\\right)-f\\left(\\overline{{\\nu}},\\kappa^{*}(u)\\right)\\right]+\\left(\\eta+\\sigma\\right)\\left(\\nu\\left[\\kappa_{\\mathbf{x}(0)}(u)\\right]+\\nu\\left(\\kappa^{*}(u)\\right)\\right)}\\\\ & \n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The first line holds because of Lemma 3. The second line holds due to Assumption 3. The third line holds because $f$ is linear in $\\pmb{\\theta}$ . The expectation is taken over $\\mathbb{P}_{\\pmb{\\theta}}$ . The fourth line holds due to Lemma ", "page_idx": 20}, {"type": "text", "text": "3. The fifth line holds due to Assumption 2. The sixth line holds because of the definition of $\\bar{\\theta}_{\\mathrm{CIO}}(\\mathbf{u})$ . The seventh line holds because $\\bar{(\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u}),\\bar{\\theta}_{\\mathrm{CIO}}(\\mathbf{u}))}$ is an optimal solution to RFO $(\\mathcal{C}(\\bar{\\pmb{\\theta}},\\alpha_{1}),\\mathbf{u})$ . The eigth line holds due to Lemma 3. The ninth line holds since both $\\boldsymbol{\\theta}_{\\mathrm{CIO}}^{*}(\\mathbf{u})$ and $\\tilde{\\pmb{\\theta}}$ are on the unit sphere and the angle between them is no greater than $2\\alpha_{1}$ , then the $L_{2}$ distance between them is upper bounded by $2(1-\\cos2\\alpha_{1})$ . ", "page_idx": 21}, {"type": "text", "text": "Next, we bound the AOG of $\\bar{\\bf x}_{\\mathrm{CIO}}$ . We have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{AOG}(\\bar{\\mathbf{x}}_{\\mathrm{CIO}})=\\mathbb{E}\\left[f\\left(\\theta^{*},\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})\\right)-f\\left(\\theta^{*},\\mathbf{x}^{*}(\\mathbf{u})\\right)\\right]}\\\\ &{\\qquad\\qquad\\leq\\mathbb{E}\\left[(2-2\\cos2\\alpha_{1}+\\eta+\\sigma)\\nu\\left(\\mathbf{x}^{*}(\\mathbf{u})\\right)+(\\eta+\\sigma)\\nu\\left[\\bar{\\mathbf{x}}_{\\mathrm{CIO}}(\\mathbf{u})\\right]\\right]}\\\\ &{\\qquad\\qquad=(2-2\\cos2\\alpha_{1}+\\eta+\\sigma)\\mu^{*}+(\\eta+\\sigma)\\mu_{\\mathrm{CIO}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\mu^{*}:=\\mathbb{E}\\left(\\nu[\\mathbf{x}^{*}(\\mathbf{u})]\\right)$ . ", "page_idx": 21}, {"type": "text", "text": "C Numerical Experiment Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "C.1 Computational Setup ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "All the algorithms are implemented and test using Python 3.9.1 on a MacBook Pro with an Apple M1 Pro processor and 16 GB of RAM. Optimization models are implemented with Gurobi 9.5.2. ", "page_idx": 21}, {"type": "text", "text": "C.2 Forward Problems ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "C.2.1 Shortest-path ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We consider the shortest path problem on a $5\\!\\times\\!5$ grid network $G(\\mathcal{N},\\mathcal{E})$ where $\\mathcal{N}$ and $\\mathcal{E}$ indicate the node and edge sets, respectively. Let $\\mathcal{E}^{+}(i)$ and $\\bar{\\mathcal{E}}^{-}(i)$ denote the sets of edges that enter and leave node $i\\in\\mathcal{N}$ , respectively. Let $u^{o}$ and $u^{d}$ denote the origin and destination of the trip, respectively. We define $x_{i j}\\in\\mathcal{E}$ as binary decision variables that take 1 if road $(i,j)$ is traversed for any $(i,j)\\in\\dot{\\mathcal{E}}$ . The shortest path problem is presented as follows. ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathbf{x}}{\\mathrm{minimize}}}&{\\displaystyle\\sum_{(i,j)\\in\\mathcal{E}}\\theta_{i j}x_{i j}}\\\\ {\\mathrm{subject~to}}&{\\displaystyle\\sum_{(j,i)\\in\\mathcal{E}^{+}(i)}x_{j i}-\\sum_{(i,j)\\in\\mathcal{E}^{-}(i)}x_{i j}=\\left\\{\\!\\!\\!\\begin{array}{l l}{1,}&{\\mathrm{~if~}i=u^{d}}\\\\ {-1,}&{\\mathrm{~if~}i=o^{d}}\\end{array}\\!\\!\\right.,\\quad\\forall i\\in\\mathcal{N}}\\\\ &{x_{i j}\\in\\{0,1\\},\\quad(i,j)\\in\\mathcal{E}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The objective function minimizes the total travel cost. The first set of constraints are the flowbalancing constraints that make sure we can find a path from $u_{o}$ to $u_{d}$ . The second set of constraints specify the range of our decision variables. Note that the constriant matrix is totally unimodular, so we can replace the binary constraints with $0\\leq x_{i j}\\leq1$ for any $(i,j)\\in\\mathcal{E}$ when implementing this model. ", "page_idx": 21}, {"type": "text", "text": "C.2.2 Knapsack ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We consider a knapsack problem of $d=10$ items. We define binary decision variables $x_{i}$ that indicate if item $i\\in[d]$ is selected $(=1)$ ) or not $(=0)$ ). The knapsack problem is presented as follows. ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathbf{x}}{\\mathrm{maximize}}}&{\\displaystyle\\sum_{i\\in[d]}\\theta_{i}x_{i}}\\\\ {\\mathrm{subject~to}}&{\\displaystyle\\sum_{i\\in[d]}w_{i}x_{i}\\leq u}\\\\ &{x_{i}\\in\\{0,1\\},\\forall i\\in[d]}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The objective maximizes the total value of the selected items. The first constraint enforces a total budget for item selection. The second set of constraints specify the range of our decision variables. ", "page_idx": 21}, {"type": "text", "text": "C.3 Obtaining a Point Estimation ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We consider two methods to obtain point estimations of the unknown parameters. They are i) datadriven inverse optimization with the sub-optimality loss and ii) the gradient-based method proposed by Berthet et al. (2020). We implement the method from Berthet et al. (2020) with the package provided by Tang and Khalil (2022). Hyper-parameters are tuned using a separate validation set of 200 decision data points. Batch size is set to 64. We use the Adam optimizer with an initial learning rate of 0.1. We train the model for 20 epochs. ", "page_idx": 22}, {"type": "text", "text": "We present the implementation details of the data-driven inverse optimization method next. We consider solving ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\underset{\\theta\\in\\mathbb{R}^{|\\mathcal{E}|},\\epsilon\\in\\mathbb{R}_{+}^{n_{\\mathrm{tain}}}}{\\mathrm{minimize}}}&{\\displaystyle\\frac{1}{N_{\\mathrm{train}}}\\sum_{k\\in\\mathcal{K}_{\\mathrm{train}}}l_{k}}\\\\ {\\mathrm{subject~to}}&{l_{k}\\geq\\theta^{\\top}\\hat{\\mathbf{x}}_{k}-\\theta^{\\top}\\mathbf{x},\\quad\\forall\\mathbf{x}\\in\\mathcal{X}_{k},\\ k\\in\\mathcal{K}_{\\mathrm{train}}}\\\\ &{\\|\\theta-\\mathbf{1}\\|_{1}\\leq\\displaystyle\\frac{|\\mathcal{E}|}{4}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This problem is initialized without Constraints (56b), which were added iteratively using a cuttingplane method. Specifically, in each iteration, after solving Problem (56), let $\\pmb{\\theta}^{\\prime}$ and $\\bar{\\{l_{k}^{\\prime}\\}}_{k\\in K_{\\mathrm{train}}}$ be the optimal solution. For each data point $k\\in\\mathcal{K}_{\\mathrm{train}}$ , we solve the following sub-problem ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{minimize}\\quad\\theta^{\\prime\\top}\\mathbf{x}_{k}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let $\\mathbf{x}_{k}^{\\prime}$ be the optimal solution to the sub-problem. If $l_{k}^{\\prime}<\\theta^{\\prime\\intercal}\\hat{\\mathbf{x}}_{k}-\\theta^{\\prime\\intercal}\\mathbf{x}_{k}^{\\prime}$ , we add the following cut to Problem (56) ", "page_idx": 22}, {"type": "equation", "text": "$$\nl_{k}\\geq\\theta^{\\top}\\hat{\\mathbf x}_{k}-\\theta^{\\top}\\mathbf x_{k}^{\\prime}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We keep running this procedure until no cut is added to the master Problem (56). ", "page_idx": 22}, {"type": "text", "text": "C.4 Solving the Calibration Problem ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "C.4.1 Shortest Path ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "For each data point in the validation set, we calculate the value of $c_{k}$ by solving the following problem ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{maximize}_{\\boldsymbol{\\theta}\\in\\mathbb{R}^{|\\mathcal{E}|},\\mathbf{w}\\in\\mathbb{R}^{\\mathcal{N}},\\mathbf{v}\\in\\mathbb{R}_{+}^{|\\mathcal{E}|}}}&{\\displaystyle\\bar{\\theta}^{\\top}\\boldsymbol{\\theta}}\\\\ {\\mathrm{subject~to}}&{w_{d_{k}}-w_{o_{k}}-\\displaystyle\\sum_{(i,j)\\in\\mathcal{E}}v_{i j}=\\pmb{\\theta}^{\\top}\\hat{\\mathbf{x}}_{k}}\\\\ &{w_{j}-w_{i}-v_{i j}\\leq c_{i j},\\quad\\forall(i,j)\\in\\mathcal{E}}\\\\ &{\\|\\boldsymbol{\\theta}\\|_{2}\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\textbf{w}\\in\\mathbb{R}^{N}$ and $\\mathbf{v}\\,\\in\\,\\mathbb{R}_{+}^{|\\mathcal{E}|}$ , respectively, denote the dual variables associated with the flowbalancing constraints and the capacity constraints in the primal problem. The first constraint enforces strong duality. The second set of constraints are the dual feasibility constraints. The last constraint ensures the optimal solution is on the unit sphere. Note that we do not need to enforce $\\lVert\\pmb\\theta\\rVert_{2}=1$ because this is a maximization problem. ", "page_idx": 22}, {"type": "text", "text": "C.4.2 Knapsack ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "For each data point in the validation set, we calculate the value of $c_{k}$ by solving the following calibration problem ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\theta\\in\\mathbb{R}^{d}}{\\mathrm{maximize}}}&{\\bar{\\theta}^{\\top}\\theta}\\\\ {\\mathrm{subject\\to}}&{\\theta^{\\top}\\hat{\\mathbf{x}}_{k}\\geq\\theta^{\\top}\\mathbf{x},\\quad\\forall\\mathbf{x}\\in\\mathcal{X}(\\mathbf{u}_{k})}\\\\ &{\\|\\theta\\|_{2}\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We initialize this problem without Constraints (60b). In each iteration, after solving the calibration problem, let $\\theta^{\\prime}$ denote the optimal solution. We solve ${\\bf F O}(\\pmb\\theta^{\\prime},{\\bf u}_{k})$ and let $\\mathbf{x}^{\\prime}$ denote the optimal solution. If $\\pmb{\\theta}^{\\prime\\intercal}\\mathbf{x}^{\\prime}>\\pmb{\\theta}^{\\prime\\intercal}\\hat{\\mathbf{x}}_{k}$ , we then add the corresponding cut to the model. We keep running this process until no cut is added. ", "page_idx": 23}, {"type": "text", "text": "C.5 Solving the Robust Forward Problem ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Let $\\alpha=\\cos^{-1}\\big(\\Gamma_{k}\\big(\\{c_{k}\\}_{k\\in\\mathcal{K}_{\\mathrm{val}}}\\big)\\big)$ . We next solve the following robust model to recommend a new decision to prescribe a decision given a $u\\in\\mathcal{U}$ . ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathbf{x}\\in\\mathcal{X}(\\mathbf{u})}{\\mathrm{minimize~maximize}}}&{\\theta^{\\top}\\mathbf{x}}\\\\ {\\mathrm{subject~to}}&{\\bar{\\theta}^{\\top}\\theta\\geq\\cos(\\alpha)}\\\\ &{\\|\\theta\\|_{2}\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We initialize this problem as follows. ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{x}\\in\\mathcal{X}(\\mathbf{u}),\\Omega\\in\\mathbb{R}_{+}}{\\mathrm{minimize}}\\,\\!\\!\\!\\Omega}\\\\ &{\\quad\\quad\\mathrm{subject\\,to}\\quad\\pmb{\\theta}^{\\intercal}\\mathbf{x}\\leq\\Omega,\\quad\\forall\\pmb{\\theta}\\in\\tilde{\\Theta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We initialize $\\tilde{\\Theta}=\\mathcal{D}$ . We first solve Problem (62), let $\\mathbf{x}^{\\prime}$ and $\\Omega^{\\prime}$ denote the optimal solution. Then we solve the following sub-problem ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\theta\\in\\mathbb{R}^{|\\mathcal{E}|}}{\\mathrm{maximize}}}&{\\theta^{\\top}\\mathbf{x}^{\\prime}}\\\\ {\\mathrm{subject\\,to}}&{\\bar{\\theta}^{\\top}\\theta\\geq\\cos(\\alpha)}\\\\ &{\\|\\theta\\|_{2}\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let $\\pmb{\\theta}^{\\prime}$ denote the optimal solution to the sub-problem. If $\\theta^{\\top}\\mathbf{x}^{\\prime}>\\Omega^{\\prime}$ , then we add $\\pmb{\\theta}^{\\prime}$ to $\\tilde{\\Theta}$ and re-solve Problem (62). We keep running this procedure until no new solution is added to \u0398\u02dc. ", "page_idx": 23}, {"type": "text", "text": "D Additional Computational Results ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section, we conduct additional computational experiments to assess how point estimate quality affects the performance of the Conformal IO pipeline. Specifically, we focus on the knapsack problem, where we randomly generate point estimates with an angular deviation $\\delta$ from the groundtruth parameter $\\pmb{\\theta}^{*}$ , with $\\delta$ serving as a proxy for point estimate quality. We then apply our calibration method to the point estimate and subsequently use the robust forward problem to generate decision recommendations. We vary the value of $\\delta$ and report the average (std) out-of-sample AOG and POG achieved by our pipeline in Table 3. ", "page_idx": 23}, {"type": "table", "img_path": "Y2NWKlrDrX/tmp/73500bbfa14ea313aa2c930a2483ccd2afbec5a3f16c75cfd6c4cebd15735298.jpg", "table_caption": ["Table 3: Mean (std) AOG and POG by conformal IO when varying point estimate quality. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "In general, conformal IO beneftis from more accurate point estimates (i.e., when $\\delta$ is small). However, the trend is not always strictly monotonic. For instance, as $\\delta$ increases from 0 to $\\pi/10$ , the POG initially decreases before rising again. While beyond the scope of this work, exploring point estimation methods that optimize for the performance of the downstream robust optimization could be a valuable direction for future research. ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: Theoretical results are proved in Sections 3 and Section 4 (complete proofs are in the appendix). These results are verified numerically in Section 5. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: Limitations and future research directions are discussed in Section 6. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: Assumptions are stated and justified in Section 3.1.1. Proofs are in the appendix. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Experiment details are well documented in the paper. We also open source our implementation at https://anonymous.4open.science/r/ConformalIO-B776. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 25}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Data and source code available at https://anonymous.4open.science/ r/ConformalIO-B776. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Yes, this information is documented in Section 5. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We report error bars/standard errors for all experimental results in Section 4. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: This information is disclosed in Appendix C. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We have reviewed the NeurIPS Code and Ethics and confirm that our paper conform with it. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. \u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. ", "page_idx": 27}, {"type": "text", "text": "\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This is a theoretical/methodological paper that presents foundational research in optimization. We do not see a direct path to any negative societal impact. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: This is a theoretical/methodological paper that presents foundational research in optimization. It does not involve any high-risk data/model. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We properly cite code/papers on which our research is built on. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our code and data along with documentations are available at https:// anonymous.4open.science/r/ConformalIO-B776. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]