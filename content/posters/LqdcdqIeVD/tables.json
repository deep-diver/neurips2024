[{"figure_path": "LqdcdqIeVD/tables/tables_6_1.jpg", "caption": "Table 1: Quantative results of semantic segmentation on the SemanticKITTI [1] test set. Bold results are the best in each block of methods.", "description": "This table presents a quantitative comparison of different semantic segmentation methods on the SemanticKITTI test set.  The methods are categorized into three groups: Point-Based, 3D Voxel-Based, and 2D Projection-Based.  For each method, the mean Intersection over Union (mIoU) is reported for 19 semantic classes. The best performing method in each category is highlighted in bold. This allows for a direct comparison of the performance of various approaches across different methodological categories.", "section": "4 Experiments"}, {"figure_path": "LqdcdqIeVD/tables/tables_6_2.jpg", "caption": "Table 2: Quantative results of semantic segmentation on the nuScenes [27] validation set. Bold results are the best in each block of methods.", "description": "This table presents the quantitative results of semantic segmentation on the nuScenes validation set.  The results are broken down by category (barrier, bicycle, bus, car, construction, motorcycle, pedestrian, traffic cone, trailer, truck, driveable surface, other flat, sidewalk, terrain, manmade, vegetation) and show the mean Intersection over Union (mIoU) achieved by different methods.  The methods are categorized into Point-Based, 3D Voxel Based, and 2D Projection Based approaches.  Bold numbers indicate the best performance within each method category.", "section": "4 Experiments"}, {"figure_path": "LqdcdqIeVD/tables/tables_8_1.jpg", "caption": "Table 3: Results of ablation studies on the SemanticKITTI validation set.", "description": "This table presents the ablation study results performed on the SemanticKITTI validation set to analyze the effect of each proposed module in SFCNet. The baseline model uses conventional spherical projection and stride-based sampling.  The table shows the mIoU achieved with different combinations of modules: only baseline, with SFC (Spherical Frustum Sparse Convolution), with F2PS (Frustum Farthest Point Sampling), and with both SFC and F2PS. The results demonstrate the contribution of each module to the overall performance improvement.", "section": "4.5 Ablation Study"}, {"figure_path": "LqdcdqIeVD/tables/tables_8_2.jpg", "caption": "Table 4: The performance comparison between the restoring-based methods and SFCNet on the SemanticKITTI validation set.", "description": "This table compares the mean Intersection over Union (mIoU) scores achieved by SFCNet and two other methods that aim to restore complete semantic predictions from partial ones (KNN-based Post-processing and KPConv Refinement) on the SemanticKITTI validation set.  It highlights SFCNet's superior performance by directly preserving the complete geometric structure during the projection process, avoiding the need for post-processing restoration steps.", "section": "4.6 Comparision with Restoring-Based Methods"}, {"figure_path": "LqdcdqIeVD/tables/tables_14_1.jpg", "caption": "Table 5: The Detailed Hyperparameters of the Components and Modules in SFCNet. Component shows the names of components in SFCNet. Module Type shows the types of basic modules used in the components. Kernel Size shows the convolution kernel size of Spherical Frustum sparse Convolutions (SFCs) used in the modules. In the column of Stride, [1, 1] strides mean the SFC treats all the points as the center points, while [2,2] strides show the strides used in Frustum Farthest Point Sampling (F2PS). The column of Upsampling Rate shows the upsampling rate used in the upsampling SFCs. Number of Modules shows the number of composed modules used in corresponding components. Width shows the output channel dimensions of the modules. In addition, in the column of Width, C means the channel dimensions of the extracted point features, which is 128 for the SemanticKITTI dataset and 256 for the nuScenes dataset. n means the number of semantic classes, which is 19 for the SemanticKITTI dataset and 16 for the nuScenes dataset.", "description": "This table details the hyperparameters used in the different components and modules of the SFCNet architecture.  It specifies kernel sizes, strides, upsampling rates, the number of modules, and output channel dimensions for each component, differentiating between the SemanticKITTI and nuScenes datasets.", "section": "3 SFCNet"}, {"figure_path": "LqdcdqIeVD/tables/tables_15_1.jpg", "caption": "Table 6: The statistics of each input data category on SemanticKITTI dataset.", "description": "This table shows the mean and standard deviation of the input features (x, y, z coordinates, range, and intensity) for each data category in the SemanticKITTI dataset.  These statistics are used for data normalization during the training process of the SFCNet model. The normalization involves subtracting the mean and dividing by the standard deviation for each feature to ensure that the features have zero mean and unit variance.", "section": "4.2 Implementation Details"}, {"figure_path": "LqdcdqIeVD/tables/tables_17_1.jpg", "caption": "Table 7: Efficiency comparison. The inference time of a single LiDAR scan, the processed point number, and the normalized time, the inference time per thousand points, are evaluated on the SemanticKITTI validation set with a single Geforce RTX 4090Ti GPU.", "description": "This table compares the inference time and efficiency of different semantic segmentation methods on the SemanticKITTI dataset.  The inference time is measured for a single LiDAR scan, and the normalized time represents the inference time per 1000 points. The results show the efficiency of SFCNet compared to other methods.", "section": "4.3 Quantative Results"}, {"figure_path": "LqdcdqIeVD/tables/tables_17_2.jpg", "caption": "Table 8: The quantitative results of different resolutions used in the baseline model with KNN-based post-processing [13] on the SemanticKITTI validation set.", "description": "This table presents the results of an ablation study on the baseline model (using conventional spherical projection and stride-based sampling) with different resolutions of the projected range image (64 \u00d7 1800, 64 \u00d7 2048, 64 \u00d7 4096).  The results show the number of points preserved at each resolution, and the corresponding mIoU on the SemanticKITTI validation set.  The study aims to investigate the effect of resolution on the model's performance, particularly in relation to information loss caused by dropping points during the projection.", "section": "4.3 Quantative Results"}, {"figure_path": "LqdcdqIeVD/tables/tables_18_1.jpg", "caption": "Table 9: Ablation study on the stride sizes of the Frustum Farthest Point Sampling in the downsampling layers on the SemanticKITTI validation set.", "description": "This table presents the results of an ablation study conducted on the SemanticKITTI validation set to assess the impact of different stride sizes used in the Frustum Farthest Point Sampling (F2PS) method on the performance of the model. The study varied the stride sizes in the horizontal and vertical directions during downsampling in three layers of the network. The results show that a stride size of (2,2) yields the best performance, suggesting a balance between downsampling rate and information preservation is crucial for optimal results.", "section": "4.5 Ablation Study"}, {"figure_path": "LqdcdqIeVD/tables/tables_18_2.jpg", "caption": "Table 10: Ablation study on the maximal number of points in spherical frustums on the SemanticKITTI validation set.", "description": "This table shows the results of an ablation study conducted on the SemanticKITTI validation set to analyze the impact of the maximum number of points allowed within each spherical frustum on the model's performance.  The model's mean Intersection over Union (mIoU) is evaluated for three scenarios:  allowing a maximum of 2 points, 4 points, and an unlimited number of points per frustum.  The results demonstrate how increasing the maximum number of points improves performance. The unlimited point scenario represents the full SFCNet model.", "section": "4.5 Ablation Study"}, {"figure_path": "LqdcdqIeVD/tables/tables_19_1.jpg", "caption": "Table 11: Ablation study on the configuration of the hash table for the spherical frustum structure on the SemanticKITTI validation set.", "description": "This table presents the ablation study on the number of hash functions used in the hash table for the spherical frustum structure.  It shows that the performance (mIoU) remains relatively consistent across different numbers of hash functions, suggesting that the model is robust to this hyperparameter. The slight variations in inference time are likely due to minor differences in the hash table lookup process.", "section": "4.5 Ablation Study"}, {"figure_path": "LqdcdqIeVD/tables/tables_20_1.jpg", "caption": "Table 12: Quantative comparison of semantic segmentation between baseline model and SFCNet for the small object categories on SemanticKITTI validation sets. Bold results are the best in each column. The performance improvement of each category is highlighted in green.", "description": "This table presents a quantitative comparison of semantic segmentation performance between the baseline model (with KNN-based post-processing) and the proposed SFCNet.  The comparison focuses specifically on small object categories within the SemanticKITTI validation set.  The table shows the mean Intersection over Union (mIoU) for each small object category and highlights the performance improvement achieved by SFCNet compared to the baseline.  Higher mIoU values indicate better segmentation accuracy.", "section": "4. Experiments"}, {"figure_path": "LqdcdqIeVD/tables/tables_20_2.jpg", "caption": "Table 13: Quantative comparison of semantic segmentation between baseline model and SFCNet for the small object categories on the nuScenes validation sets. Bold results are the best in each column. The performance improvement of each category is highlighted in green.", "description": "This table compares the performance of the baseline model with KNN-based post-processing and the proposed SFCNet on the nuScenes validation dataset.  The comparison focuses specifically on four small object categories: bicycle, motorcycle, pedestrian, and traffic-cone.  The mIoU (mean Intersection over Union) scores are provided for each category and method.  Green numbers indicate the improvement achieved by SFCNet over the baseline approach.", "section": "4.3 Quantative Results"}]