[{"type": "text", "text": "Tri-Level Navigator: LLM-Empowered Tri-Level Learning for Time Series OOD Generalization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Chengtao Jian Tongji University, Shanghai, China jct@tongji.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Kai Yang\u2217 Tongji University, Shanghai, China kaiyang@tongji.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Yang Jiao Tongji University, Shanghai, China yangjiao@tongji.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Out-of-Distribution (OOD) generalization in machine learning is a burgeoning area of study. Its primary goal is to enhance the adaptability and resilience of machine learning models when faced with new, unseen, and potentially adversarial data that significantly diverges from their original training datasets. In this paper, we investigate time series OOD generalization via pre-trained Large Language Models (LLMs). We first propose a novel Tri-level learning framework for Time Series OOD generalization, termed TTSO, which considers both sample-level and group-level uncertainties. This formula offers a fresh theoretic perspective for formulating and analyzing OOD generalization problem. In addition, we provide a theoretical analysis to justify this method is well motivated. We then develop a stratified localization algorithm tailored for this tri-level optimization problem, theoretically demonstrating the guaranteed convergence of the proposed algorithm. Our analysis also reveals that the iteration complexity to obtain an $\\epsilon_{}$ -stationary point is bounded by $\\mathcal{O}\\big(\\frac{1}{\\epsilon^{2}}\\big)$ . Extensive experiments on real-world datasets have been conducted to elucidate the effectiveness of the proposed method. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In machine learning, a common challenge arises when the distributions of training and test sets differ significantly [Qui\u00f1onero-Candela et al., 2009]. This mismatch demands that models, trained on specific distribution data, should generalize well on unseen distribution data, known as OOD generalization [Shen et al., 2021, Zhou et al., 2022]. Despite a vast amount of research on the OOD generalization [Zhang et al., 2017, Sagawa et al., 2019, Huang et al., 2020, Arjovsky et al., 2019], the field of OOD generalization in time series is relatively limited and presents more significant challenges. This is primarily due to the inherent temporal dependencies and dynamic changes characteristic of time series data [Hamilton, 2020]. Therefore, a critical aspect of improving time series OOD generalization is to learn robust representations that remain stable despite shifts in distributions. ", "page_idx": 0}, {"type": "text", "text": "Recently, the field of machine learning has witnessed remarkable advancements in pre-trained foundation models, with notable examples including Large Language Models (LLMs) such as GPT [Radford et al., 2018], LLaMA [Touvron et al., 2023] and CLIP [Radford et al., 2021]. These models have been instrumental in capturing and leveraging complex patterns across various domains. In addition, using foundation models, especially LLMs, in processing non-linguistic data, e.g., time series is increasingly drawing attention. By fine-tuning only a few handful of parameters, these models show remarkable versatility in diverse data formats ranging from audio [Ghosal et al., 2023], image [Lu et al., 2021] and time series [Chang et al., 2023, Jin et al., 2023]. Studies indicate that LLMs, as part of the broader foundation model spectrum, demonstrate sophisticated reasoning and strong pattern recognition capabilities [Wang et al., 2023, Chu et al., 2023], fundamentally acting as pattern machines [Mirchandani et al., 2023]. Moreover, LLMs have been shown to be effective in transfer learning across various modalities, due to their data-independent self-attention mechanism [Zhou et al., 2023]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Additionally, recent advancements in vision-language foundation models have shown promising developments in OOD generalization [Zheng et al., 2022], yet the exploration in time series remains underdeveloped. The potential of using foundational models is highlighted by the study in Liu et al. [2023a], Hendrycks et al. [2020], which suggests that pre-trained transformers can improve OOD robustness. Despite existing efforts, the limited exploration of foundational model applications in time series OOD generalization suggests an emerging field. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we propose a Tri-level learning framework for Time Series OOD generalization, named TTSO. Unlike conventional OOD generalization methods that focus solely on group-level [Jiao et al., 2022a, Huang et al., 2020] or sample-level uncertainties [Zhang et al., 2017, Zhou et al., 2021, Han et al., 2024], our framework uniquely addresses both by combing a minimization problem for optimal model parameter learning, a maximization problem for dynamically data re-grouping, and another maximization problem for data augmentation under a tri-level framework. To tackle this tri-level problem, we propose a stratified localization algorithm via cutting planes. Leveraging the advanced representation learning capabilities of LLMs, we adapt this tri-level learning framework for fine-tuning LLMs. ", "page_idx": 1}, {"type": "text", "text": "Our contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Tri-level Learning Framework. In contrast to most existing works in OOD generalization, which primarily focus on either group-level or sample-level uncertainties, TTSO uniquely integrates both aspects under a tri-level learning framework. Specially, this comprehensive framework emphasizes the interdependent relationship between problems of each level, advancing beyond the typical single or bi-level methodologies in OOD generalization. Moreover, a theoretical framework based on Vapnik-Chervonenkis dimension has been developed to rigorously analyze and elucidate the generalization properties of TTSO. We then leverage this tri-level framework to fine-tune LLMs, achieving an maximum $4.9\\%$ improvement in performance on time series classification in OOD scenarios. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Stratified Localization Algorithm. To tackle the aforementioned tri-level optimization problem, we develop a stratified localization method using cutting planes. Unlike traditional gradient-based methods, TTSO removes the necessity of computing the hypergradient for the outer optimization problem. This computation is typically very challenging and computationally intensive due to the nested structure of the tri-level optimization problem. Furthermore, the decomposable nature of cutting planes offers a promising avenue for enabling distributed implementations of TTSO, thereby potentially enhancing scalability and computational efficiency. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Iteration Complexity Analysis. To validate the effectiveness of our method, we conducted a thorough theoretical analysis of the algorithm. We theoretically derive that the iteration complexity of the proposed algorithm for achieving an $\\epsilon_{\\mathrm{:}}$ -stationary point is bounded by $\\begin{array}{r}{\\mathcal{O}\\left(\\frac{\\mathfrak{j}}{\\epsilon^{2}}\\right)}\\end{array}$ . ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section, we provide an overview of the foundational concepts and methodologies related to our research, including OOD Generalization and the LLM in time series. ", "page_idx": 1}, {"type": "text", "text": "OOD Generalization. OOD Generalization research focuses on improving the model\u2019s ability to generalize when there is a difference in distribution between the training and test data, and has been widely studied in the fields of Computer Vision (CV) [Recht et al., 2019, Salman et al., 2021] and Natural Language Processing (NLP) [Tu et al., 2020, Schneider et al., 2020]. Existing works for out-of-distribution (OOD) generalization are diverse and can generally be categorized into approaches that consider sample-level [Zhang et al., 2017, Zhou et al., 2021] or group-level [Sagawa et al., 2019, ", "page_idx": 1}, {"type": "text", "text": "Huang et al., 2020] uncertainty. However, the exploration of OOD generalization specially for time series remains relatively underdeveloped. A recent study [Lu et al., 2023] introduced \u2019Diversify\u2019, an innovative approach that models time series data from the perspective of distribution and obtain superior performance. In our work, we consider both sample-level and group-level uncertainties and formulate them as a tri-level optimization problem. ", "page_idx": 2}, {"type": "text", "text": "LLM in Time Series. The integration of LLMs in time series analysis is a rapidly evolving field, drawing significant interest due to their superior pattern recognition and reasoning abilities [Wang et al., 2023, Chu et al., 2023]. A recent example is Time-LLM [Jin et al., 2023], which introduces an innovative method by reprogramming time series and incorporating linguistic prompts, effectively activating the extensive capabilities of LLM. In addition, the OFA framework [Zhou et al., 2023], utilizing the frozen pretrained transformer framework, validates the ersatility and effectiveness of pre-trained models in time series analysis. Another innovative approach is PromptCast [Xue and Salim, 2023], which employs a prompt-based learning method, transforming numerical input and output data into prompts for effective forecasting in zero-shot settings. The TEMPO [Cao et al., 2023] adapts to changes in time series distribution by decomposing time series and adding different prompts for each component and obtain competitive performance in time series forecasting. In specialized domains like traffic [Xue et al., 2022], finance [Zhang et al., 2023] and healthcare [Liu et al., 2023b], LLMs have also shown unique advantages. In this work, we aim to enhance OOD robusness for time series by fine-tuning LLMs with TTSO. ", "page_idx": 2}, {"type": "text", "text": "3 Problem Formulation and Algorithm ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Notations. $\\mathcal{X}$ and $\\boldsymbol{\\wp}$ represent the input and target spaces of samples, respectively. The predictor $f_{\\varphi}=h_{\\omega}\\circ r_{\\theta}$ consists of the representation function $r_{\\theta}(\\cdot)$ with parameter $\\pmb{\\theta}$ and the classifier $h_{\\omega}$ with parameter $\\omega$ . The function $f_{\\varphi}:\\mathcal{X}\\to\\mathcal{Y}$ maps time series $X\\in{\\mathcal{X}}$ to $Y\\in\\mathcal{Y}$ , where $\\boldsymbol{X}\\in\\mathbb{R}^{T\\times F}$ and $Y\\in\\mathbb{R}_{+}$ , with $T$ as the time series length and $F$ as the feature dimensions. The multivariate time series $\\mathbf{\\deltaX}$ , composed of $F$ univariate time series each with $T$ observations, is sampled i.i.d. from distribution $\\mathbb{P}$ and represented as $\\pmb{X}=[\\pmb{x}_{1},\\pmb{x}_{2},\\dots,\\pmb{x}_{F}]$ , where $\\pmb{x}_{i}=[x_{v_{1}},x_{v_{2}},\\ldots,x_{T}]$ for $i=1,\\dots,F$ . Assume source domain distributions are $\\mathbb{P}_{S_{i}}$ for $i\\,\\in\\,\\{1,2,\\dots,K\\}$ and the target domain distribution is $\\mathbb{P}_{\\mathrm{T}}$ . The source domain data $\\mathcal{D}_{S_{i}}$ is sampled i.i.d. from $\\mathbb{P}_{S_{i}}$ , and the target domain data $\\mathcal{D}_{T}$ is sampled i.i.d. from $\\mathbb{P}_{\\mathrm{T}}$ . ", "page_idx": 2}, {"type": "text", "text": "3.1 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given a training dataset $\\mathcal{D}_{\\mathrm{train}}\\,=\\,\\{(X_{i},Y_{i})\\}_{i=1}^{N}$ sampled from the distribution $\\mathbb{P}_{\\operatorname{train}}(X,Y)$ . In supervised learning, the goal is to learn an optimal predictor on such that $f_{\\varphi^{*}}$ generalizes well on a test dataset $\\ensuremath{\\mathcal{D}}_{\\mathrm{test}}$ sampled from the distribution $\\mathbb{P}_{\\mathrm{test}}(X,Y)$ . In self-supervised contrastive learning, for a given time series $\\mathbf{\\deltaX}$ , we generate two augmented views, $X_{a_{1}}$ and $X_{a_{2}}$ , using augmentation methods $a_{1}$ , $,a_{2}\\in A$ . These augmentations produce the time series representations $\\bar{R_{1}}=r_{\\theta}\\left(a_{1}(\\pmb{X})\\right)\\in\\mathbb{R}^{T\\times M}$ and $\\pmb{R}_{2}=r_{\\theta}\\left(\\breve{a}_{2}(\\pmb{X})\\right)\\in\\mathbb{R}^{\\dot{T}\\times M}$ , through the representation function $r_{\\theta}$ . The objective of contrastive learning is to minimize the distance between positive pairs $(R_{1},R_{2})$ while maximizing the distance between positive and negative pairs. The general formula for contrastive loss, as detailed in Zhao et al. [2022], is formulated as follows ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\ell_{\\mathrm{con}}\\,=\\ell_{\\mathrm{align}}\\,(r_{\\theta};\\mathbb{P},\\pi)+\\lambda\\ell_{\\mathrm{reg}}\\,(r_{\\theta};\\mathbb{P},\\pi).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The first term aims to minimize the distance between positive pairs in the latent space, while the second term served as a regularizer prevents representation collapse. To evaluate the performance of the model, a classifier $h_{\\omega}$ is trained using the representation function $x_{\\theta^{*}}$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{h_{\\omega^{*}}=\\arg\\operatorname*{min}_{h_{\\omega}}\\;\\mathbb{E}_{(\\mathbf{X},Y)\\sim\\mathbb{P}_{\\operatorname*{train}}}\\ell_{\\operatorname*{sup}}\\left(h_{\\omega}\\circ r_{\\theta^{*}}(X),Y\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the representation function $r_{\\theta^{\\ast}}(\\cdot)$ is optimized via the supervised loss in Eq. (2). The classification is performed using $f_{\\varphi^{*}}=h_{\\omega^{*}}\\circ r_{\\theta^{*}}$ . However, the discrepancy between the training distribution $\\mathbb{P}_{\\operatorname{train}}(X,Y)$ and the test distribution $\\mathbb{P}_{\\mathrm{test}}(X,Y)$ poses a challenge for generalizing $f_{\\varphi^{*}}$ to test data. Directly optimizing $\\ell_{\\mathrm{sup}}\\left(f_{\\varphi}(X),Y\\right)$ may lead to overftiting, compromising performance on unseen data. To mitigate this issue, invariant representation learning [Arjovsky et al., 2019] is employed to handle distribution shifts by learning robust invariant representations across diverse distributions. To achieve this, we begin with the following assumption. ", "page_idx": 2}, {"type": "text", "text": "Assumption 1 (Invariant Assumption [Zhao et al., 2022]). Considering $K$ different environments (domains) $\\mathcal{E}$ , there exists a random variable $\\psi(X)$ such that for any $e,e^{\\prime}\\in\\mathrm{supp}(\\mathcal{E})$ , it holds that $\\operatorname{P}\\left(Y\\mid\\psi\\left(\\mathbf{X}_{e}\\right)\\right)=\\operatorname{P}\\left(Y\\mid\\psi\\left(X_{e^{\\prime}}\\right)\\right)$ . ", "page_idx": 3}, {"type": "text", "text": "This assumption implies that for time series $\\mathbf{\\deltaX}$ observed in different environments, invariant rationales exist and their relationship with the corresponding labels remains stable. This stability ensures that predictions remain consistent across various environments, relying on these rationales. Assuming $\\psi(\\cdot)$ represents the representation function $r_{\\theta}(\\cdot)$ parameterized by $\\theta$ , then it follows that ", "page_idx": 3}, {"type": "equation", "text": "$$\nr_{\\theta^{*}}(X_{e})=r_{\\theta^{*}}(X_{e^{\\prime}})=\\psi(X).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In contrastive representation learning, where labels are not available, the theoretical analysis of the downstream performance is challenging. To address this, research [Zhao et al., 2022] bridges this gap by connects contrastive loss to downstream risks, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{R}(h_{\\omega}\\circ r_{\\theta};\\mathbb{P}_{\\pi})\\!\\le\\!c\\|h_{\\omega}\\|\\sqrt{K\\sigma}(\\ell_{\\mathrm{align}}(r_{\\theta};\\mathbb{P},\\pi))^{\\frac14}+\\|h_{\\omega}\\|\\tau(\\sigma,\\delta)\\!+\\!\\sum_{k}\\!\\mathbb{P}_{\\pi}(C_{k})\\|e_{k}\\!-\\!h_{\\omega}\\circ\\mu_{k}(r_{\\theta};\\mathbb{P}_{\\pi})\\|\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $c$ is a positive constant, $\\tau(\\sigma,\\delta)$ refers to a set of constants determined by the $(\\sigma,\\delta)$ - augmentation, and $C_{k}$ corresponds to the sample set for class $k$ . The first term is optimized during contrastive pre-training. The second term depends on data augmentations $(\\sigma,\\delta)$ . The third term, related to the linear layer $h_{\\omega}$ , is optimized in downstream tasks. As shown by Eq. (4), contrastive learning on distribution $\\mathbb{P}$ with augmentation function $\\pi$ essentially optimizes the upper bound of the supervised risk. ", "page_idx": 3}, {"type": "text", "text": "Each environment $\\mathcal{E}$ corresponds to a domain distribution $\\mathbb{P}_{S_{i}}$ . To learn an invariant representation over the domain set $\\mathcal{P}$ , we first provide a mathematical definition of invariant risk minimization. ", "page_idx": 3}, {"type": "text", "text": "Definition 1 (Invariant Risk Minimization [Arjovsky et al., 2019]). If there exists a classifier $h_{0}$ that is optimal for all domains in $\\mathcal{P}$ , i.e., $h_{0}\\in\\mathrm{argmin}_{h}\\,\\mathcal{R}\\left(h\\circ r_{\\theta};\\mathbb{P}_{S_{i}}\\right),\\forall\\mathbb{P}_{S_{i}}\\in\\mathcal{P}_{i}$ , then the representation function $r_{\\theta}$ elicits an invariant predictor $h_{0}\\circ r_{\\theta}$ across the domain set $\\mathcal{P}$ . ", "page_idx": 3}, {"type": "text", "text": "This definition is equivalent to learning features that have a stable association with the target variable, which has been theoretically and empirically proven to improve the transferability of supervised learning across different distributions [Arjovsky et al., 2019, Zhao et al., 2022]. ", "page_idx": 3}, {"type": "text", "text": "3.2 A Tri-level Learning Framework ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To address OOD challenges, GroupDRO [Sagawa et al., 2019] propose a mimax formulation to minimizes the maximum domain supervised loss to enhance robustness against unseen data. According to Eq. (4), contrastive learning optimizes the upper bound of supervised risk. Thus, we extend GroupDRO by replacing the supervised loss with a self-supervised contrastive loss, aiming to learn invariant representations. We further impose constraints on the group distribution $\\pmb q$ to mitigate the risk of overfitting to specific domains. This results in a bi-level optimization problem ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\pmb{\\theta},\\pmb{q}}{\\mathrm{min}}}&{\\sum_{i=1}^{K}q_{i}\\ell_{\\mathrm{con}}(r_{\\theta};\\mathcal{D}_{S_{i}},\\pi)}\\\\ {\\mathrm{s.t.}}&{\\pmb{q}=\\arg\\operatorname*{max}\\sum_{i=1}^{K}q_{i}^{\\prime}\\ell_{\\mathrm{con}}(r_{\\theta};\\mathcal{D}_{S_{i}},\\pi)}\\\\ &{\\mathrm{s.t.}\\;d(\\pmb{p},\\pmb{q}^{\\prime})\\leq\\tau,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $d\\left(\\cdot,\\cdot\\right)$ denotes a distribution distance metric, such as KL divergence, Wasserstein distance, or Euclidean distance, $\\Delta^{K}$ is a probability simplex, and $\\tau$ is a constant. Following previous work [Qian et al., 2019], we adopt the Euclidean distance due to its strong convexity, which reults in faster convergence [Rakhlin et al., 2012]. The outer optimization seeks the best parameters across all domains to optimize overall performance, while the inner optimization, representing the group-level uncertainty, optimizes the worst-case distribution to enhance representation robustness. ", "page_idx": 3}, {"type": "text", "text": "Definition 2 (Augmentation Robust Alignment Loss [Zhao et al., 2022]). For any two augmentation methods $a,a^{\\prime}\\in A$ , the robust alignment loss is defined as follows ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\ell_{\\mathrm{ar}}(r_{\\theta};\\mathbb{P}):=\\mathbb{E}_{{X}\\sim\\mathbb{P}}\\operatorname*{sup}_{(a,a^{\\prime})\\in{A}}\\left\\|r_{\\theta}(a(X))-r_{\\theta}\\left(a^{\\prime}(X)\\right)\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Theorem 1 (Upper Bound of Risk Gap Between Augmented Domains [Shen et al., 2021]). For any two augmentation methods $a,a^{\\prime}\\in A$ , representation function $r_{\\theta}$ and classifier $h_{\\omega}$ , we have ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{sup}_{a,a^{\\prime}\\in A}\\|\\mathcal{R}\\left(h_{\\omega}\\circ r_{\\theta};\\mathbb{P}_{a}\\right)-\\mathcal{R}\\left(h_{\\omega}\\circ r_{\\theta};\\mathbb{P}_{a^{\\prime}}\\right)\\|\\leq c\\|h_{\\omega}\\|\\ell_{a r}\\left(r_{\\theta};\\mathbb{P}_{t r a i n}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "image", "img_path": "a6HzEu4Kpo/tmp/6d426c5ced30de0a67f096ae06526528343adcaca7ccfacb5ab4127c7a016cbc.jpg", "img_caption": ["Figure 1: The depiction of sample-level, group-level, and combined uncertainties. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Fix $r_{\\theta}$ , let $h_{a}=\\arg\\operatorname*{min}_{h_{\\omega}}\\mathcal{R}\\left(h_{\\omega}\\circ r;\\mathbb{P}_{t r a i n}\\right)$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\mathcal{R}\\left(h_{a}\\circ r_{\\theta};\\mathbb{P}_{a^{\\prime}}\\right)-\\mathcal{R}\\left(h_{a^{\\prime}}\\circ r_{\\theta};\\mathbb{P}_{a^{\\prime}}\\right)\\right\\|\\leq2c\\left(\\left\\|h_{a}\\right\\|+\\left\\|h_{a^{\\prime}}\\right\\|\\right)\\ell_{a r}\\left(r_{\\theta};\\mathbb{P}_{t r a i n}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Theorem 1 states that minimizing $\\ell_{\\mathrm{ar}}\\left(r_{\\theta};\\mathbb{P}_{\\mathrm{train}}\\right)$ makes the optimal predictor more consistent across different augmentation domains, i.e., minimize $\\ell_{\\mathrm{ar}}(r_{\\theta};\\mathbb{P}_{\\mathrm{train}})$ can enhance the invariance of the learned representation. Nonetheless, evaluating $\\ell_{\\mathrm{ar}}\\left(r;\\mathbb{P}_{\\mathrm{train}}\\right)$ involves a supremum operator, and the large set $\\boldsymbol{\\mathcal{A}}$ makes accurate computation infeasible. Therefore, we propose an approximation for $\\ell_{\\mathrm{ar}}\\left(r_{\\theta};\\mathbb{P}_{\\mathrm{train}}\\right)$ . We start with the following reasonable assumption. ", "page_idx": 4}, {"type": "text", "text": "Assumption 2. For any pair of augmentation methods $a,a^{\\prime}\\in A,$ , they can be viewed as introducing specific perturbations $\\delta$ to the sample $\\mathbf{\\deltaX}$ , i.e., $a({\\pmb X})={\\pmb X}+\\delta_{a},a^{\\prime}({\\pmb X})={\\pmb X}+\\delta_{a^{\\prime}}$ . ", "page_idx": 4}, {"type": "text", "text": "Suppose $\\delta_{a}$ and $\\delta_{a^{\\prime}}$ are sampled from $\\mathbb{P}_{\\mathrm{perb}}$ , representing the distribution of perturbations induced by augmentation techniques. We adopt a Gaussian Mixture Model (GMM) [Jiao et al., 2022b] to accurately characterize the uncertain perturbation distribution. Thus, the distribution of $\\delta$ is given by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{p(\\delta;\\pi,\\mu,\\sigma)=\\sum_{m=1}^{M}\\pi_{m}\\mathcal{N}\\left(\\delta;\\mu_{m},\\sigma_{m}^{2}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "pwrheesrsie $\\pi_{m}$ orr wceaing hbte  owf rtihttee $m^{t h}$ $\\textstyle\\sum_{m=1}^{M}\\pi_{m}=1$ .e qTuheen telxy-, on f  \u2113ar (r\u03b8; Ptrain) n as sup\u03b4\u223cp(\u03b4;\u03c0,\u00b5,\u03c3) $\\begin{array}{r}{\\operatorname*{sup}_{\\delta\\sim p(\\delta;\\pi,\\mu,\\sigma)}\\sum_{i=1}^{K}q_{i}\\ell_{\\mathrm{align}}(\\pmb{\\theta},\\dot{\\delta};\\mathcal{D}_{S_{i}})}\\end{array}$ we can further extend problem (5) to the following tri-level optimization problem. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\theta,q,\\delta}{\\mathrm{min}}}&{\\sum_{i=1}^{K}q_{i}\\ell_{\\mathrm{con}}\\left(\\theta,\\delta;\\mathcal{D}_{S_{i}}\\right)}\\\\ {\\mathrm{s.t.}}&{q=\\underset{q^{\\prime}\\in\\Delta^{K}}{\\mathrm{arg}\\,\\mathrm{max}}\\sum_{i=1}^{K}q_{i}^{\\prime}\\ell_{\\mathrm{con}}\\left(\\theta,\\delta;\\mathcal{D}_{S_{i}}\\right)}\\\\ &{\\mathrm{s.t.}\\;d(p,q^{\\prime})\\leq\\tau}\\\\ &{\\qquad\\delta=\\underset{\\delta^{\\prime}\\sim p(\\delta^{\\prime}\\pi,\\mu,\\sigma)}{\\mathrm{arg}\\,\\mathrm{max}}\\sum_{i=1}^{K}q_{i}^{\\prime}\\ell_{\\mathrm{align}}(\\theta,\\delta^{\\prime};\\mathcal{D}_{S_{i}})}\\\\ &{\\qquad\\mathrm{s.t.}\\;||\\mu|\\leq C_{1},||\\sigma||\\leq C_{2},\\sum_{m=1}^{M}\\pi_{m}=1,\\pi_{m}\\geq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $C_{1}$ and $C_{2}$ are constants. The third-level optimization addresses sample-level uncertainties by maximizing the alignment loss under the worst-case perturbation distribution. Figure 1 illustrates these concepts, showing how group-level and sample-level optimizations interact within the tri-level framework. To theoretically justify our approach in Eq. (10), we present the following theorem. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2 (Upper Bound on Target Error). Given the previous setup, let $\\mathcal{H}$ be a hypothesis space of Vapnik-Chervonenkis (VC) Dimension $d$ and $\\begin{array}{r}{h_{T}^{*}~=~\\operatorname*{min}_{h\\in\\mathcal{H}}\\epsilon_{T}(h)}\\end{array}$ . Let $\\mathcal{P}_{\\alpha}\\ =$ $\\textstyle\\left\\{\\mathbb{P}_{\\alpha}\\mid\\mathbb{P}_{\\alpha}=\\sum_{i}\\alpha_{i}\\mathbb{P}_{S_{i}}\\right.$ , $\\textstyle\\sum_{i}\\alpha_{i}=1$ , $\\alpha_{i}\\geq0\\ \\}$ . If $\\hat{h}\\,\\in\\,\\mathcal{H}$ is the empirical minimizer on $\\mathbb{P}_{\\alpha}$ , then for any $\\delta$ and $\\mathbb{P}_{C}\\in\\mathcal{P}_{\\alpha}$ , with probability at least $1-\\delta$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\epsilon_{T}(\\widehat{h})\\leq3\\epsilon_{T}\\left(h_{T}^{*}\\right)+\\lambda+d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{C},\\mathbb{P}_{T}\\right)+\\operatorname*{max}_{i,j}{d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}}\\right)}+C(\\delta,m,d),}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\begin{array}{r}{\\lambda=2\\sum_{i=1}^{K}\\alpha_{i}\\epsilon_{S_{i}}(h^{*})}\\end{array}$ and $C(\\delta,m,d)$ is a statistical term. $d\\varkappa_{\\mathcal{H}\\Delta\\mathcal{H}}(\\cdot,\\cdot)$ is a metric function which measu res differences in distribution [Ben-David et al., 2010]. $\\epsilon_{S_{i}}(h)$ and is the source error and the target error. ", "page_idx": 4}, {"type": "text", "text": "Discussion: Theorem 2 provides a theoretical framework for estimating performance on a new target distribution. The TTSO framework in Eq. (10) focuses on minimizing the terms $d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{\\mathrm{C}},\\mathbb{P}_{\\mathrm{T}}\\right)$ and $\\operatorname*{max}_{i,j}d_{\\mathcal{H}\\Delta\\mathcal{H}}(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}})$ , thereby giving a tighter bound of target error to improve generalization ability. Proof of Theorem 2 and further discussion of our motivation are in Appendix A.2. ", "page_idx": 4}, {"type": "text", "text": "Input: Training datasets $\\{\\mathcal{D}_{S_{i}}\\}$ , learning rates $\\eta_{\\theta},\\eta_{q},\\eta_{\\delta}$ , number of iterations $T$ .   \nOutput: Optimized parameters $\\pmb{\\theta}^{*}$   \n1: Initialize parameters $\\theta,q,\\delta$ and initial set of cutting planes $S^{0}$ .   \n2: for $t=0$ to $T-1$ do   \n3: Update variable $\\pmb{\\theta}^{(t+1)}$ , $\\pmb q^{(t+1)}$ and $\\pmb{\\delta}^{(t+1)}$ according to Eq. (19), (20) and (21)   \n4: if t mod $\\mathbf k==0$ then   \n5: if $h(\\pmb{\\theta}^{(t+1)},\\pmb{q}^{(t+1)},\\pmb{\\delta}^{(t+1)})>\\varepsilon$ then   \n6: Add new cutting planes to set $S^{t+1}$ according to Eq. (1)   \n7: end if   \n8: end if   \n9: end for   \n10: return \u03b8(T ) ", "page_idx": 5}, {"type": "text", "text": "However, solving the constrained tri-level optimization is extremely challenging. In the next subsection, we introduce a stratified localization algorithm to address this problem effectively. ", "page_idx": 5}, {"type": "text", "text": "3.3 Stratified Localization Algorithm ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Due to the hierarchical structure of the tri-level problem, we develop a stratified version of the localization method [Boyd and Vandenberghe, 2007, Jiao et al., 2023] to tackle the problem presented in Eq. (10). First, we use exterior penalty method to reformulate the third level problem, the resulting problem is ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\pmb{\\theta},\\pmb{q},\\pmb{\\delta}}{\\operatorname*{min}}}&{\\sum_{i=1}^{K}q_{i}\\ell_{\\mathrm{con}}\\left(\\pmb{\\theta},\\pmb{\\delta};\\mathcal{D}_{S_{i}}\\right)}\\\\ {\\mathrm{s.t.}}&{\\pmb{q}=\\arg\\operatorname*{max}\\sum_{i=1}^{K}q_{i}^{\\prime}\\ell_{\\mathrm{con}}\\left(\\pmb{\\theta},\\pmb{\\delta};\\mathcal{D}_{S_{i}}\\right)}\\\\ &{\\mathrm{s.t.}\\;d\\left(\\pmb{p},\\pmb{q}^{\\prime}\\right)\\leq\\tau}\\\\ &{\\qquad\\delta=\\underset{\\pmb{\\delta}^{\\prime}\\sim p(\\pmb{\\delta}^{\\prime};\\pi,\\pmb{\\mu},\\pmb{\\sigma})}{\\arg\\operatorname*{max}}\\sum_{i=1}^{K}q_{i}^{\\prime}\\ell_{\\mathrm{align}}\\left(\\pmb{\\theta},\\pmb{\\delta}^{\\prime};\\mathcal{D}_{S_{i}}\\right)-P_{3},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $P_{3}$ is a penalty term defined as $P_{3}=\\rho_{1}(\\operatorname*{max}(0,\\|\\pmb\\mu\\|-C_{1}))^{2}+\\rho_{2}(\\operatorname*{max}(0,\\|\\pmb\\sigma\\|-C_{2}))^{2}+$ $\\begin{array}{r}{\\rho_{3}(\\sum_{m=1}^{M}\\pi_{m}-1)^{2}+\\rho_{4}(\\operatorname*{max}(0,-\\pi_{m}))^{2}}\\end{array}$ , and $\\rho_{i}$ are penalty coefficients. ", "page_idx": 5}, {"type": "text", "text": "Given that the third-level optimization is a constraint for the second-level optimization, we employ $T_{3}$ steps of gradient ascent to approximate the third-level problem. This technique is commonly used in previous bi-level optimization studies [Ji et al., 2021]. By defining $f_{3}(\\dot{\\theta},q^{\\prime},\\delta^{\\prime})=$ $\\begin{array}{r}{\\sum_{i=1}^{K}q_{i}^{\\prime}(\\ell_{\\mathrm{align}}\\left(\\pmb{\\theta},\\pmb{\\delta}^{\\prime};\\mathcal{D}_{S_{i}}\\right)-P_{3}}\\end{array}$ and using the exterior penalty method, the resulting optimization problem can be expressed as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\underset{\\theta,q,\\delta}{\\mathrm{min}}}&{\\sum_{i=1}^{K}q_{i}\\ell_{\\mathrm{con}}\\left(\\theta,\\delta;\\mathcal{D}_{S_{i}}\\right)}&\\\\ {\\mathrm{s.t.}\\quad\\,\\,q=\\underset{q^{\\prime}\\in\\Delta^{K}}{\\mathrm{arg}\\,\\mathrm{max}}\\sum_{i=1}^{K}q_{i}^{\\prime}\\ell_{\\mathrm{con}}\\left(\\theta,\\delta;\\mathcal{D}_{S_{i}}\\right)-P_{2},}&\\\\ &{}&\\\\ {:\\lambda_{1}(\\sum_{i=1}^{K}q_{i}-1)^{2}\\!+\\!\\sum_{i=1}^{K}\\lambda_{2}\\operatorname*{max}(0,-q_{i})\\!+\\!\\lambda_{3}\\|\\delta\\!-\\!\\delta^{(0)}\\!-\\!\\sum_{i=0}^{T_{3}-1}\\eta_{\\delta}\\nabla_{\\delta^{\\prime}}f_{3}(\\theta,q^{\\prime},\\delta^{\\prime})\\|^{2}.}&\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Likewise, we perform $T_{2}$ steps of gradient ascent to replace the second level optimization problem. With the definition of $\\begin{array}{r}{f_{2}(\\pmb{\\theta},\\pmb{q}^{\\prime},\\pmb{\\delta})=\\sum_{i=1}^{K}q_{i}^{\\prime}\\ell_{\\mathrm{con~}}(\\pmb{\\theta},\\pmb{\\delta};\\mathcal{D}_{S_{i}}^{t r})\\!-\\!P_{2},\\varphi(\\pmb{\\theta},\\pmb{\\delta})=\\arg\\operatorname*{max}_{\\pmb{q}^{\\prime}}f_{2}(\\pmb{\\theta},\\pmb{q}^{\\prime},\\pmb{\\delta})}\\end{array}$ and $h(\\pmb{\\theta},\\pmb{q},\\pmb{\\delta})=\\|\\pmb{q}-\\varphi(\\pmb{\\theta},\\pmb{\\delta})\\|$ , Eq. (13) can be reformulated as follows ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\theta,q,\\delta}{\\operatorname*{min}}}&{\\sum_{i=1}^{K}q_{i}\\ell_{\\mathrm{con}}\\left(\\theta,\\delta;\\mathcal{D}_{S_{i}}\\right)}\\\\ {\\mathrm{s.t.}\\;}&{h(\\theta,q,\\delta)=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\begin{array}{r}{f_{1}\\left(\\pmb{\\theta},\\pmb{q},\\pmb{\\delta}\\right)=\\sum_{i=1}^{K}q_{i}\\ell_{\\mathrm{align}}\\,\\left(\\pmb{\\theta},\\pmb{\\delta};\\mathcal{D}_{S_{i}}\\right)}\\end{array}$ . Considering the approximations of $\\pmb q$ and $\\delta$ , the above problem can be relaxed as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\theta,q,\\delta}{\\operatorname*{min}}}&{{}\\,\\,f_{1}\\left(\\theta,q,\\delta\\right)}\\\\ {\\mathrm{s.t.}}&{{}\\,\\,h(\\theta,q,\\delta)\\leq\\varepsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\varepsilon>0$ is a constant. Inspired by the polyhedral approximation method [B\u00fcrger et al., 2013], we utilize cutting planes to approximate the feasible region with respect to $h(\\pmb\\theta,\\pmb q,\\delta)\\leq\\varepsilon$ . In the ", "page_idx": 5}, {"type": "text", "text": "$(t+1)^{t h}$ iteration, the set of cutting planes, denoted as $S^{t}$ , is defined as follows ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{S^{t}=\\{\\pmb{a}_{i}^{\\top}\\pmb{\\theta}+b_{i}^{\\top}\\pmb{q}+c_{i}^{\\top}\\pmb{\\delta}+d_{i}\\leq0,i=1,\\cdots,|S^{t}|\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\pmb{a}_{i}\\in\\mathbb{R}^{N},\\pmb{b}_{i}\\in\\mathbb{R}^{M},\\pmb{c}_{i}\\in\\mathbb{R}^{H},d_{i}\\in\\mathbb{R}^{1}$ , and $|\\mathcal S^{t}|$ represents the number of cutting planes in $S^{t}$ . Then Eq. (15) can be expressed as the following approximation problem ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\boldsymbol{\\theta},\\boldsymbol{q},\\delta}{\\operatorname*{min}}}&{f_{1}\\left(\\boldsymbol{\\theta},\\boldsymbol{q},\\delta\\right)}\\\\ {\\mathrm{s.t.}}&{a_{i}^{\\top}\\boldsymbol{\\theta}+b_{i}^{\\top}\\boldsymbol{q}+c_{i}^{\\top}\\delta+d_{i}\\leq0,\\quad i=1,\\cdots,|S^{t}|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The penalty function with respect to Eq. (17) can be described as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F\\left(\\pmb{\\theta},\\pmb{q},\\pmb{\\delta}\\right)=f_{1}\\left(\\pmb{\\theta},\\pmb{q},\\pmb{\\delta}\\right)+\\sum_{i}\\lambda_{i}\\operatorname*{max}(0,\\pmb{a}_{i}^{\\top}\\pmb{\\theta}+\\pmb{b}_{i}^{\\top}\\pmb{q}+\\pmb{c}_{i}^{\\top}\\pmb{\\delta}+d_{i})^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In $(t+1)^{t h}$ iteration, the variables are updated as follows ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\theta}^{t+1}=\\pmb{\\theta}^{t}-\\eta_{\\theta}\\nabla_{\\theta}F(\\pmb{\\theta}^{t},\\pmb{q}^{t},\\pmb{\\delta}^{t}),}\\\\ {\\pmb{q}^{t+1}=\\pmb{q}^{t}-\\eta_{q}\\nabla_{q}F(\\pmb{\\theta}^{t},\\pmb{q}^{t},\\pmb{\\delta}^{t}),}\\\\ {\\pmb{\\delta}^{t+1}=\\pmb{\\delta}^{t}-\\eta_{\\delta}\\nabla_{\\delta}F(\\pmb{\\theta}^{t},\\pmb{q}^{t},\\pmb{\\delta}^{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Throughout the iteration process, the set of cutting planes $S^{t}$ is updated every $k$ iterations for a tighter and more accurate polyhedral approximation. Before adding new cutting planes, we first check whether $(\\pmb{\\theta}^{t+1},\\pmb{q}^{t+\\Bar{1}},\\pmb{\\delta}^{t+1})$ is a solution for Eq. (15). If it is not a feasible solution to Eq. (15), i.e., $h(\\pmb\\theta,\\pmb q,\\delta)>\\varepsilon$ , new cutting planes are added to $S^{t}$ based on Theorem 3 and Proposition 1. Algorithm 1 provides details of the proposed method. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3. Let $T_{2}=1$ . If a first-order Taylor expansion is applied to the function $f_{2}(\\pmb\\theta,\\pmb q,\\delta)$ at the point $({\\overline{{\\theta}}},{\\overline{{\\delta}}})$ , it follows that the function $h\\left(\\theta,q,\\delta\\right)$ is convex with respect to $(\\theta,q,\\delta)$ . The detailed proof can be found in Appendix A.3. ", "page_idx": 6}, {"type": "text", "text": "Proposition 1. Given the convexity of the function $h(\\pmb\\theta,\\pmb q,\\delta),$ , a new cutting plane is generated when the condition $h(\\pmb\\theta,\\pmb q,\\delta)>\\varepsilon$ is not met. This cutting plane is formally expressed as ", "page_idx": 6}, {"type": "equation", "text": "$$\nh(\\theta^{t+1},q^{t+1},\\delta^{t+1})+\\left[\\begin{array}{l}{\\nabla_{\\theta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\\\ {\\nabla_{q}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\\\ {\\nabla_{\\delta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\end{array}\\right]^{\\top}\\left[\\begin{array}{l}{\\theta-\\theta^{t+1}}\\\\ {q-q^{t+1}}\\\\ {\\delta-\\delta^{t+1}}\\end{array}\\right]\\leq\\varepsilon.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "For the detailed derivation and proof of Proposition 1, please see Appendix A.1. ", "page_idx": 6}, {"type": "text", "text": "3.4 TTSO for Fine-tuning LLMs ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "LLMs have garnered considerable attention in time series applications [Jin et al., 2023, Zhou et al., 2023]. The emergent abilities of LLMs, especially in OOD scenarios, largely depends on the robustness of their representations[Wang et al., 2023, Chu et al., 2023]. This section connects the established theoretical foundation with the practical application of fine-tuning LLMs for time series OOD generalization. We adapt TTSO framework for fine-tuning LLMs to enhance the performance in time series OOD generalization. Our proposed method involves a dual-stage fine-tuning method tailored for time series. The main process of fine-tuning are described below. ", "page_idx": 6}, {"type": "text", "text": "Time Series Pre-processing. Preprocessing starts with an input projection layer to bridge the gap in dimensions between raw time series data and the LLM\u2019s native embedding dimension. This step is crucial for the LLM\u2019s effective integration of time series. Following this, positional encoding is applied to preserve the sequential integrity of the time series. ", "page_idx": 6}, {"type": "text", "text": "Dual-stage Fine-tuning Method. In the first stage, we employ TTSO framework to fine-tune LLMs, in line with the previously mentioned tri-level optimization framework as illustrate in Eq. (10). We adopt the contrastive loss function designed for time series from Yue et al. [2022]. In the second stage, the learned weights of the LLM, including the projection layer, are transferred to the downstream fine-tuning stage for time series classification. To retain the knowledge learned by the LLM from the corpus, we follow Chang et al. [2023], Zhou et al. [2023] by fixing the weights of the fully connected and attention layers, using Layer Normalization Tuning [Lu et al., 2022a] to adjust only the layer normalization parameters, making the affine transformation trainable. ", "page_idx": 6}, {"type": "text", "text": "Constrained Optimization for Fine-Tuning. Research [Wortsman et al., 2022] indicates that adopting radical strategies for fine-tuning models, such as larger learning rates, can reduce out-ofdistribution robustness. Unconstrained optimization of model parameters during fine-tuning can lead to knowledge forgetting issues and decrease the model\u2019s generalization ability, as mentioned in Xuhong et al. [2018]. Therefore, during fine-tuning for downstream tasks, we impose constraints on the parameters, following Xuhong et al. [2018], resulting in the following optimization problem ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\theta}{\\operatorname*{min}}}&{\\ \\ell_{c l s}\\left(r_{\\theta}\\circ h_{\\omega};\\mathcal{D}\\right)}\\\\ {\\mathrm{s.t.}}&{\\ \\|\\theta-\\pmb{\\theta}_{0}\\|\\leq\\gamma,}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\pmb\\theta_{0}$ and $\\pmb{\\theta}$ respectively denote the weights from the first and second fine-tuning phases of the LLMs. More details of fine-tuning LLMs can be found in appendix D. ", "page_idx": 7}, {"type": "text", "text": "4 Convergence Analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Assumption 3 (Lipschitz Continuity of Gradient). Assume that the gradient of the function $F$ is Lipschitz continuous, i.e., for any $\\mathbf{\\nabla}x,y_{\\mathrm{~\\,~}}$ , there exists $L>0$ such that: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\left\\|\\nabla F(\\pmb{x})-\\nabla F(\\pmb{y})\\right\\|\\leq L\\left\\|\\pmb{x}-\\pmb{y}\\right\\|.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Assumption 4 (Unbiasedness and Variance Bound of Stochastic Gradients). Assume for the stochastic gradients $g_{\\theta},g_{q},g_{\\delta}$ , the following conditions are satisfied ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\zeta_{j}^{t}}\\big[g_{\\theta}(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t})-\\nabla_{\\theta}F(\\theta^{t},q^{t},\\delta^{t})\\big]=0,}\\\\ &{\\mathbb{E}_{\\zeta_{j}^{t}}\\big[g_{q}(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t})-\\nabla_{q}F(\\theta^{t},q^{t},\\delta^{t})\\big]=0,}\\\\ &{\\mathbb{E}_{\\zeta_{j}^{t}}\\big[g_{\\delta}(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t})-\\nabla_{\\delta}F(\\theta^{t},q^{t},\\delta^{t})\\big]=0,}\\\\ &{\\mathbb{E}_{\\zeta_{j}^{t}}\\big[\\|g_{\\theta}(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t})-\\nabla_{\\theta}F(\\theta^{t},q^{t},\\delta^{t})\\|^{2}\\big]\\leq\\sigma_{1}^{2},}\\\\ &{\\mathbb{E}_{\\zeta_{j}^{t}}\\big[\\|g_{q}(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t})-\\nabla_{q}F(\\theta^{t},q^{t},\\delta^{t})\\|^{2}\\big]\\leq\\sigma_{2}^{2},}\\\\ &{\\mathbb{E}_{\\zeta_{j}^{t}}\\big[\\|g_{\\delta}(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t})-\\nabla_{\\delta}F(\\theta^{t},q^{t},\\delta^{t})\\|^{2}\\big]\\leq\\sigma_{3}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\mathbb{E}_{\\zeta_{j}^{t}}[\\cdot]$ denotes the expectation over the $\\zeta_{j}^{t}$ . ", "page_idx": 7}, {"type": "text", "text": "Assumption 5 (Bounded Gradient). Assume that the gradient of the function $F$ is bounded, i.e., $\\begin{array}{r}{\\forall t,\\|\\nabla_{\\theta}^{\\star}F(\\theta^{t},q^{i},\\delta^{t})\\|^{2}\\leq\\alpha_{1}^{2},\\|\\nabla_{q}F(\\theta^{t},q^{t},\\delta^{t})\\|^{2}\\leq\\alpha_{2}^{2},\\|\\nabla_{\\delta}F(\\theta^{\\dot{t}},q^{t},\\overleftarrow{\\delta^{t}})\\|^{2}\\leq\\alpha_{3}^{2}}\\end{array}$ . ", "page_idx": 7}, {"type": "text", "text": "Definition 3 ( $\\epsilon$ -Stationary Point). Following Xu et al. $[2023]$ , Jiao et al. [2024], a point $(\\theta,q,\\delta)$ is considered an $\\epsilon$ -stationary point (where $\\epsilon>0$ ) of a differentiable function $F$ if the sum of squares of its gradients on these variables satisfies $\\lVert\\nabla G^{t}\\rVert\\leq\\epsilon.$ . Let $T(\\epsilon)$ be the index of the first iteration that satisfies $\\|\\nabla G^{t}\\|\\leq\\epsilon,$ , i.e., $T(\\epsilon)=\\operatorname*{min}\\{t\\mid\\|\\nabla G^{t}\\|\\leq\\epsilon,t>t_{1}\\}$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 4 (Convergence Guarantee). With the continuous addition of cutting planes, the optimal objective value of the approximated problem, delineated in Eq. $(I7)$ , is guaranteed to converge monotonically. For further details, see the proof of Theorem $^{4}$ in appendix A.4. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5 (Convergence Rate). Under the assumptions 3, 4, and 5, by setting the step-sizes as \u03b7\u03b8 = \u03b7q = \u03b7\u03b4 =\u221aT1\u2212t1 and the batch size as $B$ , for $a$ given $\\epsilon$ , it follows that ", "page_idx": 7}, {"type": "equation", "text": "$$\nT(\\epsilon)\\sim\\mathcal{O}\\left(t_{1}+\\frac{L^{2}(m(\\alpha_{1}^{2}+\\alpha_{2}^{2}+\\alpha_{3}^{2})+\\sigma_{1}^{2}+\\sigma_{2}^{2}+\\sigma_{3}^{2})^{2}}{4m^{2}(\\epsilon-F(\\theta^{T_{1}},q^{T_{1}},\\delta^{T_{1}})+F^{*})^{2}}\\right),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $F^{*}$ represents the lower bound of $F$ . The proof of Theorem 5 is detailed in appendix A.5. ", "page_idx": 7}, {"type": "text", "text": "5 Experiment ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "To evaluate the proposed TTSO framework, we conduct experiments on 6 real-world time series datasets using the leave-one-domain-out setting, including HHAR [Blunck et al., 2015], PAMAP [Reiss, 2012], WESAD [Philip Schmidt et al., 2018], SWELL [Koldijk et al., 2014], USC-HAD[Zhang and Sawchuk, 2012] and DSADS [Barshan and Altun, 2013]. We compare with baseline method ERM [Vapnik, 1991] and 8 general OOD generalization methods: IRM [Arjovsky et al., 2019], GroupDRO [Sagawa et al., 2019], ANDMask [Parascandolo et al., 2020], RSC [Huang et al., 2020], Mixup [Zhang et al., 2017], VERx [Krueger et al., 2021], DIFEX[Lu et al., 2022b]. And we further compare with 2 recent strong approach in time series: AdaRNN[Du et al., 2021] and GILE [Qian et al., 2021]. We also include DIVERSIFY[Lu et al., 2023], DFDG[Zhang et al., 2021], and CCDG[Ragab et al., 2022], three methods specifically designed for time series OOD generalization. To guarantee a fair comparison, we implement all methods using the same backbone architecture (except AdaRNN and GILE), TCN [Bai et al., 2018], a model widely used in time series analysis. In addition, we fine-tune the pre-trained Large Language Model, GPT2[Radford et al., 2018], within our TTSO framework to harness its sophisticated representation learning capabilities. Detailed information regarding datasets, domain setting, data pre-processing, network architecture and hyperparameters are provided in Appendix B.1, B.2, B.3 and C. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5.1 Main Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We report the average results over 3 runs for each dataset, along with the standard deviation. The results for the HHAR, PAMAP, and WESAD datasets are shown in Tables 1, where our method outperforms the second-best baseline by $2.8\\%$ , $4.8\\%$ , and $4.9\\%$ respectively. Additional results are provided in Appendix E.1 (Table 4). These results demonstrate the superiority and effectiveness of the TTSO framework, as it accounts for both sample-level and group-level uncertainties, which optimizes the upper bound in Theorem 2. ", "page_idx": 8}, {"type": "text", "text": "Compared to traditional methods like ERM, IRM, and GroupDRO, both TTSO and TTSO\u2217show more consistent and generally superior performance in OOD generalization, highlighting the advantages of a tri-level learning framework. The TTSO method, which incorporates LLM fine-tuning, consistently outperforms other approaches, demonstrating the effectiveness of LLM with TTSO fine-tuning in enhancing OOD generalization for time series. Concurrently, the TTSO method, even without LLM fine-tuning, shows strong generalization performance, especially on the HHAR dataset where it closely matches $\\mathrm{{TSO}^{*}}$ results. This indicates that the TTSO framework is highly effective in generalizing across different scenarios, even in the absence of LLM. ", "page_idx": 8}, {"type": "table", "img_path": "a6HzEu4Kpo/tmp/69eb2f3bb9baf2f3d02b170375001e57f08783c7bb1a4f968d65376770a79f4c.jpg", "table_caption": ["Table 1: Classification accuracy $(\\%)$ on HHAR, PAMAP, and WESAD datasets. Bold indicates the best, underline the second-best performance. Standard deviation is shown in the lower right corner. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.2 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This ablation study is conducted to further understand the impact of our TTSO framework\u2019s fine-tuning on model performance. We compare four distinct variants: a pretrained GPT2 fine-tuned with TTSO $(\\mathrm{TTSO}^{++}$ ), a pretrained GPT2 without TTSO fine-tuning $(\\mathrm{TTSO}^{+-})$ ), a randomly initialized GPT2 fine-tuned with TTSO $(\\mathrm{TTSO^{-+}})$ ), and a randomly initialized GPT2 without TTSO finetuning $(\\mathrm{TTSO}^{--})$ ). This comparison helps in quantifying the effectiveness of the TTSO fine-tuning strategy in enhancing the model\u2019s OOD generalization capabilities. ", "page_idx": 8}, {"type": "text", "text": "The ablation results are presented in Figure 2. From this results, we can see that: (a) $\\mathrm{TTSO^{++}}$ demonstrates the best performance in all scenarios, further validating that the combination of a pre-trained GPT2 model with TTSO fine-tuning can significantly improve the model\u2019s OOD generalization capabilities. (b) Although $\\mathrm{TTSO^{+-}}$ does not employ TTSO fine-tuning, it still exhibits relatively good performance. This suggests that the pre-trained GPT2 model has an intrinsic capacity for OOD generalization, consistent with previous empirical studies [Zheng et al., 2022, Hendrycks et al., 2020]. (c) Compared to $\\mathrm{TTSO}^{--}$ , $\\mathrm{\\dot{T}}\\mathrm{T}\\mathrm{SO}^{-+}$ applies TTSO to fine-tune on a randomly initialized GPT2, TTSO $^{++}$ achieves improved performance. ", "page_idx": 8}, {"type": "image", "img_path": "a6HzEu4Kpo/tmp/18b002640aa6b3d73c6bd8b808728785726809ef248bbca111c179a7607f355b.jpg", "img_caption": ["Figure 2: Ablation study of TTSO\u2217 "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "This demonstrates that even in the absence of a pre-trained model, TTSO fine-tuning can effectively enhance the model\u2019s OOD generalization capabilities, though not as significantly as that with a pre-trained GPT2. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Existing OOD generalization methods mainly focus on sample-level uncertainties or group-level uncertainties, often overlooking the interplay between these two aspects. In light of this, we propose the TTSO framework to integrate both sample-level and group-level uncertainties within a unified tri-level learning approach, thereby enhancing the model\u2019s robustness and adaptability in facing diverse and unforeseen distribution shifts. In addition, this innovative framework introduces a fresh perspective for the development and analysis of the Out-of-Distribution (OOD) generalization problem. Based on this formulation, we develop a stratified localization algorithm for the tri-level optimization problem and provide theoretical analysis regarding the iteration complexity of the proposed algorithm. Comprehensive studies have been carried out to assess the performance of the proposed algorithm and substantiate the theoretic claims. It is seen that TTSO with LLM can considerably improves the performance of time series OOD generalization. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported in part by the National Natural Science Foundation of China under Grant 12371519 and 61771013; in part by Asiainfo Technologies; in part by the Fundamental Research Funds for the Central Universities of China; and in part by the Fundamental Research Funds of Shanghai Jiading District. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.   \nShaojie Bai, J Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271, 2018.   \nBillur Barshan and Kerem Altun. Daily and Sports Activities. UCI Machine Learning Repository, 2013. DOI: https://doi.org/10.24432/C5C59F.   \nShai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79:151\u2013175, 2010.   \nHenrik Blunck, Sourav Bhattacharya, Thor Prentow, Mikkel Kjrgaard, and Anind Dey. Heterogeneity activity recognition. UCI Machine Learning Repository, 2015. DOI: https://doi.org/10.24432/C5689X.   \nStephen Boyd and Lieven Vandenberghe. Localization and cutting-plane methods. From Stanford EE 364b lecture notes, 386, 2007.   \nStephen P Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.   \nMathias B\u00fcrger, Giuseppe Notarstefano, and Frank Allg\u00f6wer. A polyhedral approximation framework for convex and robust distributed optimization. IEEE Transactions on Automatic Control, 59(2): 384\u2013395, 2013.   \nDefu Cao, Furong Jia, Sercan O Arik, Tomas Pfister, Yixiang Zheng, Wen Ye, and Yan Liu. Tempo: Prompt-based generative pre-trained transformer for time series forecasting. arXiv preprint arXiv:2310.04948, 2023.   \nChing Chang, Wen-Chih Peng, and Tien-Fu Chen. llm4ts: Two-stage fine-tuning for time-series forecasting with pre-trained llms. arXiv preprint arXiv:2308.08469, 2023. ", "page_idx": 9}, {"type": "text", "text": "Zhixuan Chu, Hongyan Hao, Xin Ouyang, Simeng Wang, Yan Wang, Yue Shen, Jinjie Gu, Qing Cui, Longfei Li, Siqiao Xue, et al. Leveraging large language models for pre-trained recommender systems. arXiv preprint arXiv:2308.10837, 2023. ", "page_idx": 10}, {"type": "text", "text": "Lucas Deecke, Timothy Hospedales, and Hakan Bilen. Visual representation learning over latent domains. In International Conference on Learning Representations, 2021. ", "page_idx": 10}, {"type": "text", "text": "Yuntao Du, Jindong Wang, Wenjie Feng, Sinno Pan, Tao Qin, Renjun Xu, and Chongjun Wang. Adarnn: Adaptive learning and forecasting of time series. In Proceedings of the 30th ACM international conference on information & knowledge management, pages 402\u2013411, 2021. ", "page_idx": 10}, {"type": "text", "text": "Deepanway Ghosal, Navonil Majumder, Ambuj Mehrish, and Soujanya Poria. Text-to-audio generation using instruction-tuned llm and latent diffusion model. arXiv preprint arXiv:2304.13731, 2023. ", "page_idx": 10}, {"type": "text", "text": "James D Hamilton. Time series analysis. Princeton university press, 2020.   \nPengchao Han, Xingyan Shi, and Jianwei Huang. Fedal: Black-box federated knowledge distillation enabled by adversarial learning. IEEE Journal on Selected Areas in Communications, 2024.   \nDan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam Dziedzic, Rishabh Krishnan, and Dawn Song. Pretrained transformers improve out-of-distribution robustness. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2744\u20132751, 2020.   \nZeyi Huang, Haohan Wang, Eric P Xing, and Dong Huang. Self-challenging improves cross-domain generalization. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part II 16, pages 124\u2013140. Springer, 2020.   \nKaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Convergence analysis and enhanced design. In International conference on machine learning, pages 4882\u20134892. PMLR, 2021.   \nYang Jiao, Kai Yang, and Dongjin Song. Distributed distributionally robust optimization with non-convex objectives. Advances in neural information processing systems, 35:7987\u20137999, 2022a.   \nYang Jiao, Kai Yang, Dongjing Song, and Dacheng Tao. Timeautoad: Autonomous anomaly detection with self-supervised contrastive loss for multivariate time series. IEEE Transactions on Network Science and Engineering, 9(3):1604\u20131619, 2022b.   \nYang Jiao, Kai Yang, Tiancheng Wu, Dongjin Song, and Chengtao Jian. Asynchronous distributed bilevel optimization. In The Eleventh International Conference on Learning Representations, 2023.   \nYang Jiao, Kai Yang, Tiancheng Wu, Chengtao Jian, and Jianwei Huang. Provably convergent federated trilevel learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 12928\u201312937, 2024.   \nMing Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, et al. Time-llm: Time series forecasting by reprogramming large language models. arXiv preprint arXiv:2310.01728, 2023.   \nSaskia Koldijk, Maya Sappelli, Suzan Verberne, Mark A Neerincx, and Wessel Kraaij. The swell knowledge work dataset for stress and user modeling research. In Proceedings of the 16th international conference on multimodal interaction, pages 291\u2013298, 2014.   \nDavid Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In International Conference on Machine Learning, pages 5815\u20135826. PMLR, 2021.   \nBo Liu, Liming Zhan, Zexin Lu, Yujie Feng, Lei Xue, and Xiao-Ming Wu. How good are large language models at out-of-distribution detection? arXiv preprint arXiv:2308.10261, 2023a.   \nXin Liu, Daniel McDuff, Geza Kovacs, Isaac Galatzer-Levy, Jacob Sunshine, Jiening Zhan, MingZher Poh, Shun Liao, Paolo Di Achille, and Shwetak Patel. Large language models are few-shot health learners. arXiv preprint arXiv:2305.15525, 2023b.   \nKevin Lu, Aditya Grover, Pieter Abbeel, and Igor Mordatch. Pretrained transformers as universal computation engines. arXiv preprint arXiv:2103.05247, 1, 2021.   \nKevin Lu, Aditya Grover, Pieter Abbeel, and Igor Mordatch. Frozen pretrained transformers as universal computation engines. In Proceedings of the AAAI conference on artificial intelligence, volume 36, pages 7628\u20137636, 2022a.   \nWang Lu, Jindong Wang, Haoliang Li, Yiqiang Chen, and Xing Xie. Domain-invariant feature exploration for domain generalization. arXiv preprint arXiv:2207.12020, 2022b.   \nWang Lu, Jindong Wang, Xinwei Sun, Yiqiang Chen, and Xing Xie. Out-of-distribution representation learning for time series classification. In International Conference on Learning Representations, 2023.   \nSuvir Mirchandani, Fei Xia, Pete Florence, Brian Ichter, Danny Driess, Montserrat Gonzalez Arenas, Kanishka Rao, Dorsa Sadigh, and Andy Zeng. Large language models as general pattern machines. arXiv preprint arXiv:2307.04721, 2023.   \nGiambattista Parascandolo, Alexander Neitz, ANTONIO ORVIETO, Luigi Gresele, and Bernhard Sch\u00f6lkopf. Learning explanations that are hard to vary. In International Conference on Learning Representations, 2020.   \nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019.   \nA Philip Schmidt, R Duerichen Reiss, and Introducing WESAD Kristof Van Laerhoven. A multimodal dataset for wearable stress and affect detection. In Proceedings of the International Conference on Multimodal Interaction, 2018.   \nHangwei Qian, Sinno Jialin Pan, and Chunyan Miao. Latent independent excitation for generalizable sensor-based cross-person activity recognition. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 11921\u201311929, 2021.   \nQi Qian, Shenghuo Zhu, Jiasheng Tang, Rong Jin, Baigui Sun, and Hao Li. Robust optimization over multiple domains. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 4739\u20134746, 2019.   \nJoaquin Qui\u00f1onero-Candela, Masashi Sugiyama, Neil D. Lawrence, and Anton Schwaighofer. Dataset shift in machine learning. MIT Press, 2009.   \nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. OpenAI Blog, 2018.   \nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748\u20138763. PMLR, 2021.   \nMohamed Ragab, Zhenghua Chen, Wenyu Zhang, Emadeldeen Eldele, Min Wu, Chee-Keong Kwoh, and Xiaoli Li. Conditional contrastive domain generalization for fault diagnosis. IEEE Transactions on Instrumentation and Measurement, 71:1\u201312, 2022. doi: 10.1109/TIM.2022.3154000.   \nAlexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Making gradient descent optimal for strongly convex stochastic optimization. In International Conference on Machine Learning, pages 1571\u20131578, 2012.   \nBenjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize to imagenet? In International conference on machine learning, pages 5389\u20135400. PMLR, 2019.   \nAttila Reiss. PAMAP2 physical activity monitoring. UCI Machine Learning Repository, 2012. DOI: https://doi.org/10.24432/C5NW2H.   \nShiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks. In International Conference on Learning Representations, 2019.   \nHadi Salman, Andrew Ilyas, Logan Engstrom, Sai Vemprala, Aleksander Madry, and Ashish Kapoor. Unadversarial examples: Designing objects for robust vision. Advances in Neural Information Processing Systems, 34:15270\u201315284, 2021.   \nSteffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in Neural Information Processing Systems, 33:11539\u201311551, 2020.   \nZheyan Shen, Jiashuo Liu, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, and Peng Cui. Towards out-of-distribution generalization: A survey. arXiv preprint arXiv:2108.13624, 2021.   \nQingyu Tan, Ruidan He, Lidong Bing, and Hwee Tou Ng. Domain generalization for text classification with memory-based supervised contrastive learning. In Proceedings of the 29th International Conference on Computational Linguistics, pages 6916\u20136926, 2022.   \nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.   \nLifu Tu, Garima Lalwani, Spandana Gella, and He He. An empirical study on robustness to spurious correlations using pre-trained language models. Transactions of the Association for Computational Linguistics, 8:621\u2013633, 2020.   \nVladimir Vapnik. Principles of risk minimization for learning theory. Advances in Neural Information Processing Systems, 4, 1991.   \nYan Wang, Zhixuan Chu, Xin Ouyang, Simeng Wang, Hongyan Hao, Yue Shen, Jinjie Gu, Siqiao Xue, James Y Zhang, Qing Cui, et al. Enhancing recommender systems with large language model reasoning graphs. arXiv preprint arXiv:2308.10835, 2023.   \nMitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, et al. Robust fine-tuning of zero-shot models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7959\u20137971, 2022.   \nZi Xu, Huiling Zhang, Yang Xu, and Guanghui Lan. A unified single-loop alternating gradient projection algorithm for nonconvex\u2013concave and convex\u2013nonconcave minimax problems. Mathematical Programming, 201(1):635\u2013706, 2023.   \nHao Xue and Flora D Salim. Promptcast: A new prompt-based learning paradigm for time series forecasting. IEEE Transactions on Knowledge and Data Engineering, 2023.   \nHao Xue, Bhanu Prakash Voutharoja, and Flora D Salim. Leveraging language foundation models for human mobility forecasting. In Proceedings of the 30th International Conference on Advances in Geographic Information Systems, pages 1\u20139, 2022.   \nLI Xuhong, Yves Grandvalet, and Franck Davoine. Explicit inductive bias for transfer learning with convolutional networks. In International Conference on Machine Learning, pages 2825\u20132834. PMLR, 2018.   \nZhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong, and Bixiong Xu. Ts2vec: Towards universal representation of time series. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 8980\u20138987, 2022.   \nBoyu Zhang, Hongyang Yang, and Xiao-Yang Liu. Instruct-fingpt: Financial sentiment analysis by instruction tuning of general-purpose large language models. arXiv preprint arXiv:2306.12659, 2023.   \nHongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.   \nMi Zhang and Alexander A. Sawchuk. Usc-had: A daily activity dataset for ubiquitous activity recognition using wearable sensors. In ACM International Conference on Ubiquitous Computing (Ubicomp) Workshop on Situation, Activity and Goal Awareness (SAGAware), Pittsburgh, Pennsylvania, USA, September 2012.   \nWenyu Zhang, Mohamed Ragab, and Ramon Sagarna. Robust domain-free domain generalization with class-aware alignment. In ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 2870\u20132874, 2021. doi: 10.1109/ICASSP39728. 2021.9413872.   \nXuyang Zhao, Tianqi Du, Yisen Wang, Jun Yao, and Weiran Huang. Arcl: Enhancing contrastive learning with augmentation-robust representations. In International Conference on Learning Representations, 2022.   \nZangwei Zheng, Xiangyu Yue, Kai Wang, and Yang You. Prompt vision transformer for domain generalization. arXiv preprint arXiv:2208.08914, 2022.   \nKaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Domain generalization with mixstyle. In International Conference on Learning Representations, 2021.   \nKaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain generalization: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.   \nTian Zhou, Peisong Niu, Xue Wang, Liang Sun, and Rong Jin. One ftis all: Power general time series analysis by pretrained lm. arXiv preprint arXiv:2302.11939, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A Theoretical Proofs and Discussion ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Proof of Proposition 1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Since $h(\\pmb\\theta,\\pmb q,\\delta)$ is a convex function, we have that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{h(\\theta,q,\\delta)\\geq h(\\theta^{t+1},q^{t+1},\\delta^{t+1})+\\left[\\begin{array}{l}{\\nabla_{\\theta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\\\ {\\nabla_{q}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\\\ {\\nabla_{\\delta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\end{array}\\right]^{\\top}\\left[\\begin{array}{l}{\\theta-\\theta^{t+1}}\\\\ {q-q^{t+1}}\\\\ {\\delta-\\delta^{t+1}}\\end{array}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "According to theorem 3, combine with Eq. (15) and Eq. (27), the new cutting plane will be generated as ", "page_idx": 14}, {"type": "equation", "text": "$$\nh(\\theta^{t+1},q^{t+1},\\delta^{t+1})+\\left[\\begin{array}{l}{\\nabla_{\\theta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\\\ {\\nabla_{q}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\\\ {\\nabla_{\\delta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})}\\end{array}\\right]^{\\top}\\left[\\begin{array}{l}{\\theta-\\theta^{t+1}}\\\\ {q-q^{t+1}}\\\\ {\\delta-\\delta^{t+1}}\\end{array}\\right]\\leq\\varepsilon.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "From the inequalities, we can derive the coefficients $\\mathbf{\\Delta}_{a_{i},}b_{i},c_{i}$ and $d_{i}$ as follows ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{\\Phi}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\mathbf{a}_{i}=\\nabla_{\\theta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1}),}\\\\ &{\\mathbf{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!b}_{i}=\\nabla_{q}h(\\theta^{t+1},q^{t+1},\\delta^{t+1}),}\\\\ &{\\mathbf{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!c}_{i}=\\nabla_{\\delta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1}),}\\\\ &{d_{i}=h(\\theta^{t+1},q^{t+1},\\delta^{t+1})-\\nabla_{\\theta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})^{\\top}\\theta^{t+1}}\\\\ &{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!-\\nabla_{q}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})^{\\top}q^{t+1}-\\nabla_{\\delta}h(\\theta^{t+1},q^{t+1},\\delta^{t+1})^{\\top}\\delta^{t+1}-\\varepsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 14}, {"type": "text", "text": "A.2 Proof of Theorem 2 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.2.1 Background ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For a sample distribution $\\mathbb{P}_{S}$ on inputs space $\\mathcal{X}$ with a binary labeling function $f$ and a hypothesis $h$ , the error (or risk) is defined as follows ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\epsilon_{S}(h,f)=\\mathrm{E}_{{\\pmb x}\\sim\\mathbb{P}_{S}}[|h({\\pmb x})-f({\\pmb x})|].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For simplicity, we use the shorthand $\\epsilon_{S}(h)=\\epsilon_{S}(h,f_{S})$ for source risk and $\\epsilon_{T}(h)=\\epsilon_{T}(h,f_{D})$ for target risk, where $f_{S}$ and $f_{D}$ represent the labeling function of source and target domain, respectively. To bound the target error, following Ben-David et al. [2010], we define the $\\mathcal{H}$ -divergence. Given source distribution $\\mathbb{P}_{S}$ and target distribution $\\mathbb{P}_{T}$ over input space $\\mathcal{X}$ , let $\\mathcal{H}$ be a hypothesis class on $\\mathcal{X}$ . The $\\mathcal{H}$ -divergence between $\\mathbb{P}_{S}$ and $\\mathbb{P}_{T}$ is ", "page_idx": 14}, {"type": "equation", "text": "$$\nd_{\\mathcal{H}}\\left(\\mathbb{P}_{S},\\mathbb{P}_{T}\\right)=2\\operatorname*{sup}_{h\\in\\mathcal{H}}\\left|\\operatorname*{Pr}_{\\mathbb{P}_{S}}[I(h)]-\\operatorname*{Pr}_{\\mathbb{P}_{T}}[I(h)]\\right|,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $I_{h}=\\{{\\pmb x}\\in\\mathcal{X}:h({\\boldsymbol x})=1,h\\in\\mathcal{H}\\}$ . In addition, for a hypothesis space $\\mathcal{H}$ , the symmetric difference hypothesis space $d_{\\mathcal{H}\\Delta\\mathcal{H}}$ is the set of hypotheses. And the $d_{\\mathcal{H}\\Delta\\mathcal{H}}$ in [Ben-David et al., 2010] is defined as ", "page_idx": 14}, {"type": "equation", "text": "$$\nd_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S},\\mathbb{P}_{T}\\right)=2\\operatorname*{sup}_{h,h^{\\prime}\\in\\mathcal{H}}\\left|\\operatorname*{Pr}_{{\\mathbf x}\\sim\\mathbb{P}_{S}}\\left[h({\\pmb x})\\neq h^{\\prime}({\\pmb x})\\right]-\\operatorname*{Pr}_{{\\mathbf x}\\sim\\mathbb{P}_{T}}\\left[h({\\pmb x})\\neq h^{\\prime}({\\pmb x})\\right]\\right|.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Theorem 6. (Modified from Theorem $^{4}$ in [Ben-David et al., 2010]) Let $\\mathcal{H}$ be a hypothesis space of $V C$ dimension $d.$ . For each $i\\in\\{1,\\ldots,K\\}.$ , let $\\mathcal{D}_{S_{i}}$ be a labeled sample of size $\\beta_{i}m$ drawn from $\\mathbb{P}_{S_{i}}$ and labeled according to function $f_{S_{i}}$ . If $\\hat{h}\\in\\mathcal{H}$ is the empirical minimizer of $\\hat{\\epsilon}_{\\alpha}(h)$ for a fixed weight vector $_{\\alpha}$ on these samples and $\\begin{array}{r}{h_{T}^{*}=\\operatorname*{min}_{h\\in\\mathcal{H}}\\epsilon_{T}(h)}\\end{array}$ is the target error minimizer, then for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\epsilon_{T}(\\hat{h})\\leq\\epsilon_{T}\\left(h_{T}^{*}\\right)+\\sum_{i=1}^{N}\\alpha_{i}\\left(2\\lambda_{i}+d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{T}\\right)\\right)+2\\sqrt{\\left(\\sum_{i=1}^{N}\\frac{\\alpha_{i}^{2}}{\\beta_{i}}\\right)\\left(\\frac{d\\log\\left(2m\\right)-\\log\\left(\\delta\\right)}{2m}\\right)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\begin{array}{r}{\\lambda_{i}=\\operatorname*{min}_{h\\in\\mathcal{H}}\\left\\{\\epsilon_{T}(h)+\\epsilon_{S_{i}}(h)\\right\\}}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "A.2.2 Proof ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "According to the definition of $d_{\\mathcal{H}\\Delta\\mathcal{H}}$ in Eq. (32), we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{T}\\right)=2\\underset{h,h^{\\prime}\\in\\mathcal{H}}{\\operatorname*{sup}}\\left|\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{S_{i}}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]-\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{T}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]\\right|}\\\\ &{\\qquad\\qquad\\qquad=2\\underset{h,h^{\\prime}\\in\\mathcal{H}}{\\operatorname*{sup}}\\left|\\left(\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{S_{i}}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]-\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{T}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]\\right)\\right.}\\\\ &{\\qquad\\qquad\\qquad\\left.+\\left(\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{C}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]-\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{T}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]\\right)\\right|}\\\\ &{\\qquad\\qquad\\leq2\\underset{h,h^{\\prime}\\in\\mathcal{H}}{\\operatorname*{sup}}\\left|\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{S_{i}}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]-\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{C}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]\\right|}\\\\ &{\\qquad\\qquad+2\\underset{h,h^{\\prime}\\in\\mathcal{H}}{\\operatorname*{sup}}\\left|\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{C}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]-\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathbb{P}_{T}}\\left[h(\\mathbf{x})\\neq h^{\\prime}(\\mathbf{x})\\right]\\right|}\\\\ &{\\qquad\\qquad\\qquad\\left.h,h^{\\prime}\\in\\mathcal{H}\\right.}\\\\ &{\\qquad=d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{C}\\right)+d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{C},\\mathbb{P}_{T}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $\\begin{array}{r}{\\mathcal{P}_{\\alpha}=\\{\\mathbb{P}_{\\alpha}\\ |\\ \\mathbb{P}_{\\alpha}=\\sum_{i}\\alpha_{i}\\mathbb{P}_{S_{i}}}\\end{array}$ , $\\begin{array}{r}{\\sum_{i}\\alpha_{i}=1,\\;\\alpha_{i}\\geq0\\;\\forall i\\}}\\end{array}$ and $\\mathbb{P}_{C}\\in\\mathcal{P}_{\\alpha}$ , we can obtain that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{C}\\right)=d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\sum_{j}\\alpha_{j}\\mathbb{P}_{S_{j}}\\right)}\\\\ &{\\phantom{\\leq}=d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\sum_{j}\\alpha_{j}\\mathbb{P}_{S_{i}},\\sum_{j}\\alpha_{j}\\mathbb{P}_{S_{j}}\\right)}\\\\ &{\\phantom{\\leq}\\leq\\sum_{j}\\alpha_{j}d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}}\\right)}\\\\ &{\\phantom{\\leq}=d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}}\\right)}\\\\ &{\\phantom{\\leq}\\underset{i,j}{\\leq}\\underset{i,j}{\\operatorname*{max}}\\,d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Combine with Eq. (34) and 35, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nd_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{T}\\right)\\leq\\operatorname*{max}_{i,j}{d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}}\\right)}+d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{C},\\mathbb{P}_{T}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Substitute Eq. (36) into Eq. (33), we obtain that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\epsilon_{T}(\\hat{h})\\leq\\epsilon_{T}\\left(h_{T}^{*}\\right)+\\sum_{i=1}^{N}\\alpha_{j}\\left(2\\lambda_{i}+\\underset{i,j}{\\operatorname*{max}}\\,d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}}\\right)+d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{C},\\mathbb{P}_{T}\\right)\\right)}\\\\ &{\\quad\\quad\\quad+\\,2\\sqrt{\\left(\\sum_{i=1}^{N}\\frac{\\alpha_{i}^{2}}{\\beta_{i}}\\right)\\left(\\frac{d\\log\\left(2m\\right)-\\log\\left(\\delta\\right)}{2m}\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $\\begin{array}{r}{;\\lambda_{i}=\\operatorname*{min}_{h\\in\\mathcal{H}}\\left\\{\\epsilon_{T}(h)+\\epsilon_{S_{i}}(h)\\right\\}=\\epsilon_{T}(h^{*})+\\epsilon_{S_{i}}(h^{*}),}\\end{array}$ , by setting $\\begin{array}{r}{\\lambda=2\\sum_{i=1}^{N}\\alpha_{i}\\epsilon_{S_{i}}(h^{*})}\\end{array}$ and $\\begin{array}{r}{C(\\delta,m,d)=2\\sqrt{\\left(\\sum_{i=1}^{N}\\frac{\\alpha_{i}^{2}}{\\beta_{i}}\\right)\\left(\\frac{d\\log(2m)-\\log(\\delta)}{2m}\\right)}}\\end{array}$ yields the proof. ", "page_idx": 15}, {"type": "text", "text": "A.2.3 Discussion ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Theorem 2 provides a theoretical framework for estimating performance on a new target distribution. $\\begin{array}{r}{\\lambda=2\\sum_{j=1}^{N}\\alpha_{i}\\epsilon_{S_{i}}(\\bar{h})}\\end{array}$ $\\epsilon_{T}(h_{T}^{*})$ aggregates the combined error over all source $h_{T}^{*}$ eighted by $\\alpha_{i}$ $d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{\\mathbf{C}},\\mathbb{P}_{\\mathrm{T}}\\right)$ distributional discrepancy between a composite source distribution and the target distribution. The fourth term, $\\operatorname*{max}_{i,j}\\bar{d}_{\\mathcal{H}\\Delta\\mathcal{H}}(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}})$ , quantifies the maximum discrepancy between any two source distributions. The last term, $C(\\delta,m,d)$ , is a statistical term which depends on the confidence level $\\delta$ , sample size $m$ , and VC dimension $d$ . ", "page_idx": 15}, {"type": "text", "text": "The tri-level learning framework proposed in Eq. (10) aims to minimize the third term, $d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{\\mathrm{C}},\\mathbb{P}_{\\mathrm{T}}\\right)$ , and the fourth term, $\\operatorname*{max}_{i,j}d\\varkappa_{\\Delta\\mathcal{H}}(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}})$ . These two terms correspond to the group-level and sample-level uncertainties, respectively. Below, we discuss how these two terms align with the motivation for our tri-level optimization. ", "page_idx": 15}, {"type": "text", "text": "For the term $d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{\\mathbf{C}},\\mathbb{P}_{\\mathrm{T}}\\right)$ , the goal of time series OOD generalization is to learn a model that generalizes well to unseen domain distributions, which makes direct optimization infeasible due to the unavailability of target dataset. To minimize this discrepancy, we can only enlarge the set $\\mathcal{P}_{C}$ . Specifically, we manipulate $\\delta$ -perturbations applied to individual samples in the third level of our tri-level learning framework. By optimizing these perturbations, we explore a broader range of variations within each source domain, which potentially minimizes the term $d_{\\mathcal{H}\\Delta\\mathcal{H}}\\left(\\mathbb{P}_{\\mathbf{C}},\\mathbb{P}_{\\mathrm{T}}\\right)$ , enhancing the robustness of learned representations. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "For the term $\\operatorname*{max}_{i,j}d_{\\mathcal{H}\\Delta\\mathcal{H}}(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}})$ , the second-level optimization in our tri-level framework adjusts the weights $\\alpha_{i}$ that define the mixture of source distributions $\\mathbb{P}_{\\mathrm{C}}$ . By dynamically modifying these weights based on the \u2018worst-case\u2019 distribution, we minimize the term $\\operatorname*{max}_{i,j}d_{\\mathcal{H}\\Delta\\mathcal{H}}(\\mathbb{P}_{S_{i}},\\mathbb{P}_{S_{j}})$ . ", "page_idx": 16}, {"type": "text", "text": "Our approach not only enhances representation invariance across diverse domains but also improves the model\u2019s resilience against variations within individual samples. The effectiveness of this tri-level framework is rooted in the interdependence between the problems at each level; adjustments in one level influence the conditions and outcomes of the others. This demonstrates the necessity of our tri-level learning optimization, as it requires a coordinated strategy that simultaneously considers sample-level, group-level, and parameter-level dynamics. ", "page_idx": 16}, {"type": "text", "text": "A.3 Proof of Theorem 3 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "First, the first-order Taylor expansion of $f_{2}(\\pmb\\theta,\\pmb q,\\delta)$ at the point $({\\overline{{\\theta}}},{\\overline{{\\delta}}})$ is obtained as follows ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{f}_{2}(\\theta,q^{\\prime},\\delta)=f_{2}(\\overline{{\\theta}},q^{\\prime},\\overline{{\\delta}})+\\nabla_{\\theta}f_{2}(\\overline{{\\theta}},q^{\\prime},\\overline{{\\delta}})^{T}(\\theta-\\overline{{\\theta}})+\\nabla_{\\delta}f_{2}(\\overline{{\\delta}},q^{\\prime},\\overline{{\\delta}})^{T}(\\delta-\\overline{{\\delta}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since $T_{2}=1$ , therefore, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\varphi(\\pmb{\\theta},\\pmb{\\delta})=\\pmb{q}_{0}^{\\prime}-\\eta_{q}\\nabla_{q^{\\prime}}\\tilde{f}_{2}\\left(\\pmb{\\theta},\\pmb{q}^{\\prime},\\pmb{\\delta}\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Combine with Eq. (38) and (39), we can obtain that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varphi(\\pmb{\\theta},\\pmb{\\delta})=q_{0}^{\\prime}-\\eta_{q}\\nabla_{q^{\\prime}}\\Big(f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})+\\nabla_{\\theta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})(\\pmb{\\theta}-\\overline{{\\theta}})+\\nabla_{\\delta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})(\\pmb{\\delta}-\\overline{{\\delta}})\\Big)}\\\\ &{\\qquad\\qquad=q_{0}^{\\prime}-\\eta_{q}\\nabla_{q^{\\prime}}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})-\\eta_{q}\\nabla_{q^{\\prime}}\\nabla_{\\theta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})\\pmb{\\theta}+\\nabla_{q^{\\prime}}\\nabla_{\\theta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})\\overline{{\\theta}}}\\\\ &{\\qquad\\qquad-\\nabla_{q^{\\prime}}\\nabla_{\\delta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})\\delta+\\nabla_{q^{\\prime}}\\nabla_{\\delta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})\\overline{{\\delta}}}\\\\ &{\\qquad\\qquad=-\\eta_{q}\\nabla_{q^{\\prime}}\\nabla_{\\theta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})\\theta-\\nabla_{q^{\\prime}}\\nabla_{\\delta}f_{2}(\\overline{{\\theta}},\\pmb{q}^{\\prime},\\overline{{\\delta}})\\delta+C,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $C=q_{0}^{\\prime}-\\eta_{q}\\nabla_{q^{\\prime}}f_{2}(\\overline{{\\theta}},q^{\\prime},\\overline{{\\delta}})+\\nabla_{q^{\\prime}}\\nabla_{\\theta}f_{2}(\\overline{{\\theta}},q^{\\prime},\\overline{{\\delta}})\\overline{{\\theta}}+\\nabla_{q^{\\prime}}\\nabla_{\\delta}f_{2}(\\overline{{\\theta}},q^{\\prime},\\overline{{\\delta}})\\overline{{\\delta}}$ is an affine function. Therefore, $\\varphi(\\pmb\\theta,\\pmb\\delta)$ is a convex function. According to preserve convexity[Boyd and Vandenberghe, 2004], $h(\\pmb{\\theta},\\pmb{q},\\pmb{\\delta})=\\|\\pmb{q}-\\phi(\\pmb{\\theta},\\pmb{\\delta})\\|$ is convexity, which concludes the proof of theorem 3. ", "page_idx": 16}, {"type": "text", "text": "A.4 Proof of Theorem 4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Assume that in the $t^{\\mathrm{th}}$ iteration, a new cutting plane is added, and the selected point $(\\pmb{\\theta}^{t+1},\\pmb{q}^{t+1},\\pmb{\\delta}^{t+1})$ always lies within the region $\\mathcal{R}_{t}^{c}$ formed by the cutting plane set $\\mathcal{C}^{t}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{R}_{0}^{c}\\supseteq\\mathcal{R}_{1}^{c}\\supseteq\\cdots\\supseteq\\mathcal{R}_{t}^{c}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $\\mathcal{H}^{t}$ denote the feasible region of problem in Eq. (17) at the $t^{\\mathrm{th}}$ iteration, and $\\mathcal{R}$ represent the feasible region of problem in Eq. (15), then it follows that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{H}^{0}\\supseteq\\cdot\\cdot\\cdot\\supseteq\\mathcal{H}^{t}\\supseteq\\mathcal{H}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $F(\\pmb\\theta^{t},\\pmb q^{t},\\pmb\\delta^{t})$ denote the optimal value of problem in Eq. (17) at the $t^{\\mathrm{th}}$ iteration, and $f_{1}^{*}$ represent the optimal value of the problem Eq. (15). Based on equation (42), we can obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\nF\\left(\\pmb\\theta^{0},\\pmb q^{0},\\pmb\\delta^{0}\\right)\\leq F\\left(\\pmb\\theta^{t},\\pmb q^{t},\\pmb\\delta^{t}\\right)\\leq\\cdot\\cdot\\cdot\\leq F^{*}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "It\u2019s seen that the sequence $\\left\\{{\\cal F}(\\pmb\\theta^{t},\\pmb q^{t},\\pmb\\delta^{t})\\right\\}$ is monotonically increasing. As $T_{1}\\rightarrow\\infty$ , $f_{1}$ monotonically converges to a certain fixed value. It is worth mentioning that $h(\\pmb{\\theta},\\pmb{q},\\pmb{\\delta})=\\|\\pmb{q}-\\phi(\\pmb{\\theta},\\pmb{\\delta})\\|$ is a convex function. Since the sublevel set of a convex function is convex, the feasible region of problem in Eq. (17) is convexity. This implies that the iterative procedure, by continuously adding a cutting plane, is progressively converging to the optimal value $f_{1}^{*}$ of the problem as referenced in Eq. (15). ", "page_idx": 16}, {"type": "text", "text": "A.5 Proof of Theorem 5 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "To begin with, we introduce a fundamental lemma that is pivotal for the subsequent analysis. ", "page_idx": 16}, {"type": "text", "text": "Lemma 1. For $\\begin{array}{r}{\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right),\\frac{1}{m}\\sum_{j=1}^{m}g_{q}(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}),\\frac{1}{m}\\sum_{j=1}^{m}g_{\\delta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\!,}\\end{array}$ they are unbiased and bounded, that is, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right]=\\nabla_{\\theta}f_{1}\\left(\\theta^{t},q^{t},\\delta^{t}\\right),}\\\\ &{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right\\|^{2}\\right]\\leq\\alpha_{1}^{2}+\\frac{\\sigma_{1}^{2}}{m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\frac{1}{m}\\sum_{j=1}^{m}g_{q}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right]=\\nabla_{q}f_{1}\\left(\\theta^{t},q^{t},\\delta^{t}\\right),}\\\\ &{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}g_{q}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right\\|^{2}\\right]\\leq\\alpha_{2}^{2}+\\frac{\\sigma_{2}^{2}}{m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\frac{1}{m}\\sum_{j=1}^{m}g_{\\delta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right]=\\nabla_{\\delta}f_{1}\\left(\\theta^{t},q^{t},\\delta^{t}\\right),}\\\\ &{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}g_{\\delta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right\\|^{2}\\right]\\leq\\alpha_{3}^{2}+\\frac{\\sigma_{3}^{2}}{m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Here, $\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}[\\cdot]$ denotes the expectation with respect to a set of variables $\\{\\zeta_{1}^{t},\\cdot\\cdot\\cdot,\\zeta_{m}^{t}\\}$ . ", "page_idx": 17}, {"type": "text", "text": "A.5.1 Proof of Lemma 1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Taking the variable $\\pmb{\\theta}$ as an example, according to Assumption 4, for all $i=1,\\cdots,n$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right]=\\frac{1}{m}\\sum_{j=1}^{m}\\mathbb{E}_{\\zeta_{j}^{t}}\\left[g_{\\theta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right]=\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Based on Assumption 5, the variance of $\\nabla_{\\boldsymbol{\\theta}}F(\\boldsymbol{\\theta}^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t})$ is bounded, from which we can deduce ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\left\\{\\zeta_{j}^{t}\\right\\}}\\left[\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)\\right]}\\\\ &{=\\mathbb{E}_{\\left\\{\\zeta_{j}\\right\\}}\\left[\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},q^{t},\\delta^{t};\\zeta_{j}^{t}\\right)-\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\|^{2}\\right]+\\left\\|\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\|^{2}}\\\\ &{=\\frac{\\sum_{j=1}^{m}\\mathbb{E}_{\\zeta_{j}}\\left[\\left\\|g_{\\theta}\\left(\\theta,q,\\delta;\\zeta_{j}\\right)-\\nabla_{\\theta}F\\left(\\theta,q,\\delta\\right)\\right\\|^{2}\\right]}{m^{2}}+\\alpha_{1}^{2}}\\\\ &{\\le\\frac{\\sigma_{1}^{2}}{m}+\\alpha_{1}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The proofs of Eq. (45) and Eq. (46) follow a similar logic. Thus, we complete the proof of Lemma 1. Combine with lemma 1, we now proceed to derive Theorem 5. Under Assumption 3 that the gradient of $F$ is Lipschitz continuous, for $t>t_{1}$ , it follows that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{F}\\left(\\theta^{t+1},\\boldsymbol{q}^{t+1},\\boldsymbol{\\delta}^{t+1}\\right)}\\\\ &{\\le\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right)+\\left\\langle\\nabla_{\\theta}\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right),\\theta^{t+1}-\\theta^{t}\\right\\rangle+\\left\\langle\\nabla_{\\theta}\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right),\\boldsymbol{q}^{t+1}-\\theta^{t}\\right\\rangle}\\\\ &{\\quad+\\left\\langle\\nabla_{\\theta}\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right),\\theta^{t+1}-\\delta^{t}\\right\\rangle+\\frac{L}{2}\\left(\\left\\|\\theta^{t+1}-\\theta^{t}\\right\\|^{2}+\\left\\|\\theta^{t+1}-\\theta^{t}\\right\\|^{2}+\\left\\|\\tilde{\\theta}^{t+1}-\\theta^{t}\\right\\|^{2}\\right)}\\\\ &{=\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right)-\\eta_{\\theta}\\left\\langle\\nabla_{\\theta}\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right),\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t};\\boldsymbol{\\zeta}_{j}^{t}\\right)\\right\\rangle}\\\\ &{\\quad-\\eta_{\\theta}\\left\\langle\\nabla_{\\theta}\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right),\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t};\\boldsymbol{\\zeta}_{j}^{t}\\right)\\right\\rangle}\\\\ &{\\quad-\\eta_{\\theta}\\left\\langle\\nabla_{\\theta}\\boldsymbol{F}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t}\\right),\\frac{1}{m}\\sum_{j=1}^{m}g_{\\theta}\\left(\\theta^{t},\\boldsymbol{q}^{t},\\boldsymbol{\\delta}^{t};\\boldsymbol{\\zeta}_{j}^{t}\\right)\\right\\rangle}\\\\ &{\\quad+\\frac{L(\\eta)^{2}}{2}\\left\\|\\frac{1}{m}\\sum_{j=1}^ \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Taking the expectation of both sides of Equation (49) with respect to $\\{\\zeta_{1}^{t},\\cdot\\cdot\\cdot,\\zeta_{m}^{t}\\}$ , we can obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\{\\xi_{|\\xi|}^{\\tau}\\}\\left[F^{(\\tau^{*},\\tau^{*},\\tau^{*},\\sigma^{*},\\tau^{*})}\\right]}\\\\ &{\\le F\\left(\\theta^{*},q^{*},\\xi^{*}\\right)-\\eta\\mathbb{E}\\{\\xi_{|\\xi|}^{\\tau}\\}\\left\\langle\\nabla e^{\\mathcal{L}_{\\xi}}F^{(\\theta^{*},\\tau^{*},\\delta^{*})},\\frac{1}{m}\\sum_{j=1}^{m}\\beta(e^{\\mathcal{L}_{j}},q^{*};\\xi_{j}^{*})\\right\\rangle}\\\\ &{\\quad-\\eta_{|\\xi|}\\mathbb{E}\\{\\sqrt{\\eta_{\\xi}}F^{(\\theta^{*},\\tau^{*},\\delta^{*})},\\frac{1}{m}\\sum_{j=1}^{m}\\beta(e^{\\mathcal{L}_{j}},q^{*};\\xi_{j}^{*})\\}}\\\\ &{\\quad-\\eta\\mathbb{E}\\{\\xi_{|\\xi|}^{\\tau}\\}\\left\\langle\\nabla e^{\\mathcal{L}_{\\xi}}F^{(\\theta^{*},\\tau^{*},\\delta^{*})},\\frac{1}{m}\\sum_{j=1}^{m}\\beta(e^{\\mathcal{L}_{j}},q^{*};\\xi_{j}^{*})\\right\\rangle}\\\\ &{\\quad+\\frac{L(n)^{2}}{2m}\\mathbb{E}_{\\{\\xi_{|\\xi|}^{\\tau}\\}}\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}\\beta(e^{\\mathcal{L}_{j}},q^{*};\\xi_{j}^{*})\\right\\|^{2}}\\\\ &{\\quad+\\frac{L(n)^{2}}{2m}\\mathbb{E}_{\\{\\xi_{|\\xi|}^{\\tau}\\}}\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}\\beta(e^{\\mathcal{L}_{j}},q^{*};\\xi_{j}^{*})\\right\\|^{2}}\\\\ &{\\quad+\\frac{L(n)^{2}}{2}\\mathbb{E}_{\\{\\xi_{|\\xi|}^{\\tau}\\}}\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}\\beta(e^{\\mathcal{L}_{j}},\\theta^{*};\\xi_{j}^{*})\\right\\|^{2}}\\\\ &{\\overset{(c)}{\\le}F^{(\\theta)}\\frac{2}{2}\\mathbb{E}_{\\{\\xi \n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The inequality (i) is based on lemma 1. Taking the total expectation of both sides of Eq. (50), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[F\\left(\\theta^{t+1},q^{t+1},\\delta^{t+1}\\right)\\right]}\\\\ &{\\leq\\mathbb{E}\\left[F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right]-\\eta_{\\theta}\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]-\\eta_{q}\\mathbb{E}\\left[\\left\\Vert\\nabla_{q}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]}\\\\ &{\\quad-\\eta_{\\delta}\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\delta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]+\\frac{L\\left(\\eta_{\\theta}\\right)^{2}}{2}\\left(\\alpha_{1}^{2}+\\frac{\\sigma^{2}}{m}\\right)+\\frac{L\\left(\\eta_{q}\\right)^{2}}{2}\\left(\\alpha_{2}^{2}+\\frac{\\sigma^{2}}{m}\\right)}\\\\ &{\\quad+\\frac{L\\left(\\eta_{\\delta}\\right)^{2}}{2}\\left(\\alpha_{3}^{2}+\\frac{\\sigma^{2}}{m}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\mathbb{E}[\\cdot]$ denotes the expectation over all terms. Summing Eq. (51) from $t=t_{1}$ to $t=T_{1}-1$ , we obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[F\\left(\\theta^{T_{1}},q^{T_{1}},\\delta^{T_{1}}\\right)\\right]}\\\\ &{\\le\\mathbb{E}\\left[F\\left(\\theta^{t_{1}},q^{t_{1}},\\delta^{t_{1}^{\\prime}}\\right)\\right]-\\eta_{\\theta}\\sum_{t=t_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]-\\eta_{\\theta}\\sum_{t=T_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\Vert\\nabla_{q}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]}\\\\ &{\\quad-\\eta_{\\delta}\\sum_{t=t_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]+\\sum_{t=t_{1}}^{T_{1}-1}\\frac{L\\left(\\eta_{\\theta}\\right)^{2}}{2}\\left(\\alpha_{1}^{2}+\\frac{\\sigma_{1}^{2}}{m}\\right)}\\\\ &{\\quad+\\sum_{t=t_{1}}^{T_{1}-1}\\frac{L\\left(\\eta_{\\theta}\\right)^{2}}{2}\\left(\\alpha_{2}^{2}+\\frac{\\sigma_{2}^{2}}{m}\\right)+\\sum_{t=t_{1}}^{T_{1}-1}\\frac{L\\left(\\eta_{\\theta}\\right)^{2}}{2}\\left(\\alpha_{3}^{2}+\\frac{\\sigma_{3}^{2}}{m}\\right)}\\\\ &{=\\mathbb{E}\\left[F\\left(\\theta^{t_{1}},q^{t_{1}},\\delta^{t}\\right)\\right]-\\eta_{\\theta}\\sum_{t=t_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]-\\eta_{\\theta}\\sum_{t=T_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\Vert\\nabla_{q}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]}\\\\ &{\\quad-\\eta_{\\delta}\\sum_{t=t_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\theta}F\\left(\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $\\begin{array}{r}{\\eta_{\\theta}=\\eta_{q}=\\eta_{\\delta}=\\frac{1}{\\sqrt{T_{1}-t_{1}}}}\\end{array}$ , Combining with Eq. (52), we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sum_{t=t_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\Vert\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right.\\ \\ +\\left\\Vert\\nabla_{q}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}+\\left\\Vert\\nabla_{\\delta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\Vert^{2}\\right]}\\\\ &{\\leq F\\left(\\theta^{T_{1}},q^{T_{1}},\\delta^{T_{1}}\\right)-F^{*}+\\frac{L}{2}(T_{1}-t_{1})^{-\\frac{1}{2}}\\sum_{t=t_{1}}^{T_{1}-1}\\sum_{i=1}^{3}\\alpha_{i}^{2}}\\\\ &{\\quad+\\frac{L}{2m}(T_{1}-t_{1})^{-\\frac{1}{2}}\\sum_{t=t_{1}}^{T_{1}-1}\\sum_{i=1}^{3}\\sigma_{i}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Combining the definition of $\\epsilon$ -stationary point described in Definition (3) with Eq. (53), we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sum_{t=t_{1}}^{T_{1}-1}\\mathbb{E}\\left[\\left\\|\\nabla_{\\theta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\|^{2}+\\left\\|\\nabla_{q}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\|^{2}+\\left\\|\\nabla_{\\delta}F\\left(\\theta^{t},q^{t},\\delta^{t}\\right)\\right\\|^{2}\\right]}\\\\ &{\\leq F\\left(\\theta^{T_{1}},q^{T_{1}},\\delta^{T_{1}}\\right)-f_{1}^{*}+\\frac{L}{2}(T_{1}(\\epsilon)-t_{1})^{-\\frac{1}{2}}\\sum_{t=t_{1}}^{T_{1}-1}\\sum_{i=1}^{3}\\alpha_{i}^{2}}\\\\ &{\\quad+\\frac{L}{2m}(T_{1}(\\epsilon)-t_{1})^{-\\frac{1}{2}}\\sum_{t=t_{1}}^{T_{1}-1}\\sum_{i=1}^{3}\\sigma_{i}^{2}}\\\\ &{\\leq\\epsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "that is, ", "page_idx": 19}, {"type": "equation", "text": "$$\nT_{1}(\\epsilon)\\sim t_{1}+\\frac{L^{2}(m(\\alpha_{1}^{2}+\\alpha_{2}^{2}+\\alpha_{3}^{2})+\\sigma_{1}^{2}+\\sigma_{2}^{2}+\\sigma_{3}^{2})^{2}}{4m^{2}(\\epsilon-F(\\pmb{\\theta}^{T_{1}},\\pmb{q}^{T_{1}},\\pmb{\\delta}^{T_{1}})+\\pmb{F}^{*})^{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "According to Eq. (55), we can obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\nT_{1}(\\epsilon)\\sim\\frac{1}{\\epsilon^{2}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Hence, it can be concluded that there exists a $T_{1}(\\epsilon)$ such that $\\left\\|\\nabla G^{t}\\right\\|=\\mathbb{E}\\left[\\left\\|\\nabla_{\\theta}F\\left(\\theta^{t},\\pmb{q}^{t},\\delta^{t}\\right)\\right\\|^{2}+$ $\\left\\|\\nabla_{q}F\\left(\\pmb{\\theta}^{t},\\pmb{q}^{t},\\pmb{\\delta}^{t}\\right)\\right\\|^{2}+\\left\\|\\nabla_{\\delta}F\\left(\\pmb{\\theta}^{t},\\pmb{q}^{t},\\pmb{\\delta}^{t}\\right)\\right\\|^{2}\\right]\\leq\\epsilon$ , which concludes the proof of Theorem 5. ", "page_idx": 19}, {"type": "text", "text": "B Datasets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "B.1 Datasets Information ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "HHAR[Blunck et al., 2015] collected activity data from 9 subjects engaging in 6 activities, using smartphones that capture 3D accelerometer data from various positions. PAMAP[Reiss, 2012] encompasses 18 physical activities data from 9 subjects, recorded using wearable sensors monitoring physiological and movement metrics. WESAD[Philip Schmidt et al., 2018] focuses on stress and affective state detection from 15 subjects, employing wearable sensors for ECG, EMG, respiration, and temperature under varied conditions. SWELL[Koldijk et al., 2014] recorded stress responses in a work environment from 25 participants using ECG, EDA, and heart rate sensors during typical office tasks under stressors. USC-HAD[Zhang and Sawchuk, 2012] comprises detailed motion and orientation data from 14 subjects performing various activities, captured via a MotionNode device with high sampling rate. DSADS[Barshan and Altun, 2013] consists of 19 activities recorded from 8 subjects at Bilkent University, using body-worn sensors on torso and limbs, with data segmented for detailed analysis. Table 2 shows the information of the 6 datasets we used in our experiments. ", "page_idx": 19}, {"type": "table", "img_path": "a6HzEu4Kpo/tmp/daa2ee93d64ff6b0c356fbad3d388cc2a71f72f757051a984a5024feb8822218.jpg", "table_caption": ["Table 2: Dataset information. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "B.2 Domain Setting ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The domain setting is summarized in Table 3. This setting is done to balance the number of samples and classed across different domains. ", "page_idx": 19}, {"type": "text", "text": "B.3 Data pre-processing ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For all datasets, we configure the window size as 128 and the step size as 64, resulting in a $50\\%$ overlap between two adjacent time series samples. Each sample is standardized using the formula $\\begin{array}{r}{\\tilde{x}=\\frac{x-\\mu}{\\sigma}}\\end{array}$ , where $\\mu$ and $\\sigma$ represent the mean and standard deviation of the dataset, respectively. It\u2019s ", "page_idx": 19}, {"type": "table", "img_path": "a6HzEu4Kpo/tmp/cbb35dc78437f2159531c4647e253fc983dcc5a278ac1e2f609a62c4cc90ddf6.jpg", "table_caption": ["Table 3: Domain setting for HHAR, PAMAP and WESAD dataset. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "important to note that the $\\mu$ and $\\sigma$ used here is specific to each domain, rather than the entire dataset.   \nThis approach is intended to maximize the distinction between data from different domains. ", "page_idx": 20}, {"type": "text", "text": "C Network Architecture and Hyperparameters ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Our baseline experiments were conducted using a network architecture consisting of 10-layers dilated convolutions network. The dilation rate for each layer is set to $2^{k}$ , where $k$ is the layer number. We used the same kernel size of 3 across all layers. Optimization was performed using the Adam optimizer with a weight decay of $3\\times10^{-4}$ . For all baseline experiments, we set the batch size to 256 and the learning rate to 0.002. The training was set to run for a maximum of 50 epochs. All the methods are implemented with PyTorch[Paszke et al., 2019] version 1.7.1 on an NVIDIA GeForce RTX 4090 graphics card. ", "page_idx": 20}, {"type": "text", "text": "In the TTSO fine-tuning experiments, we employed GPT-2 as the language model. Fine-tuning was performed in two stage: In the first stage, the learning rate for the large model was $1\\times10^{-4}$ , and for the input embedding, it was set at 0.001. In the second phase, we adjusted the learning rate for the large model to $5\\times\\bar{1}0^{-5}$ , aiming to further refine the model\u2019s performance. During the evaluation phase, we froze the parameters of the language model, only fine-tuning the classifier with a learning rate of 0.003 to adapt to the specific classification tasks. The batch size was consistently set at 16 for all experimental stages. ", "page_idx": 20}, {"type": "text", "text": "D Details of Fine-tuning ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The structure of LLM Fine-tuning with TTSO is illustrated in figure 3a and 3b. The primary components involved are as follows: ", "page_idx": 20}, {"type": "image", "img_path": "a6HzEu4Kpo/tmp/6400bc5eebc367a060e5e642d2061ed05d16524fcd96e64aa05a6d7317880bf7.jpg", "img_caption": ["(a) First Stage: Alignment Fine-tuning (b) Second Stage: Downstream Fine-tuning "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 3: Structure of LLM Fine-tuning with TTSO, illustrating the two-phase approach starting with alignment fine-tuning followed by downstream fine-tuning, adapted specifically for time series out-of-distribution generalization tasks. ", "page_idx": 20}, {"type": "text", "text": "Input Embedding: The first is the input embedding, where raw time series is transformed into embedding space that is amenable for processing by the language model. In our experiments, the input embedding is a linear layer. As shown in Figure 3, the time series (indicated by the dashed box below the waveform) is combined with positional encoding to form the input representation. ", "page_idx": 20}, {"type": "text", "text": "Language Model: This is the core part of the model, typically comprising multiple pretrained transformer encoder. This model is used for processing the input embeddings and producing advanced feature representations for subsequent classification tasks. Note that, to retain the intrinsic information of the language model, only the parameters of layer normalization can be tuned. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Classifier: In the second stage of fine-tuning, the classifier tailors the language model to the specific time series classification task. It takes the advanced feature representations from the language model and fine-tunes the model for downstream tasks. We use a linear layer for the classifier, with cross entropy as the supervised loss. ", "page_idx": 21}, {"type": "text", "text": "Contrastive Loss: A contrastive loss function is employed to enhance the discriminative of the representations in the first stage of the fine-tuning process. This loss function aims to ensure that the representations of similar time series samples are brought closer together in the representations space, while representations of dissimilar samples are pushed apart. Specifically, during this stage, the contrastive loss acts as a guiding signal for the language model, encouraging it to learn representations that effectively capture the underlying patterns and distinctions within the time series data, thereby adapting the language model to time series data more effectively. ", "page_idx": 21}, {"type": "text", "text": "E More Experiments ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "E.1 Additional Datasets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We conducte on more datasets to demonstrate the superior performance of our framework. The results is summarized in Table 4. ", "page_idx": 21}, {"type": "table", "img_path": "a6HzEu4Kpo/tmp/d031086bbc691df9db3f50c5b786a5c4c67e1a290e9d956ecc83119baf0eaa7c.jpg", "table_caption": ["Table 4: Classification accuracy $(\\%)$ on SWELL, USC-HAD and DSADS datasets. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "E.2 Illustration of Sample-level and Group-level Uncertainties ", "text_level": 1, "page_idx": 21}, {"type": "image", "img_path": "a6HzEu4Kpo/tmp/37d45694b40d3717538a901d83e0120e650649954a5a952b5645b6914a42340d.jpg", "img_caption": ["Figure 4: Sample-Level Uncertainty: Each line represents a window of time series data with the same label. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "To illustrate the concepts of sample-level and group-level uncertainties, we use the $\\mathbf{X}$ -axis values from accelerometer data collected by the \u2018samsungold_1\u2019 device from four users in the HHAR dataset. ", "page_idx": 21}, {"type": "text", "text": "In Figure 4, sample-level uncertainty is shown by plotting time series data from a specific label (e.g., \u2019walking\u2019), where each line represents a different time window. The variations among these lines illustrate the inherent noise, which represents sample-level uncertainty. ", "page_idx": 21}, {"type": "image", "img_path": "a6HzEu4Kpo/tmp/630fc80dc93f38d686565b934f9c7583ace5eef00fb022245a98fd630e79827f.jpg", "img_caption": ["Figure 5: Group-Level Uncertainty: Histogram of $\\mathbf{\\Psi}_{\\mathbf{X}},$ axis values, with each color representing a different group. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 5 demonstrates the group-level uncertainty by displaying the distribution of $\\mathbf{X}$ -axis values from the accelerometer across different groups (users). Each color represents a distinct group, and each group\u2019s unique characteristics contribute to the overall group-level uncertainty. ", "page_idx": 22}, {"type": "text", "text": "E.3 Ablation Study on LLM Architectures and Parameter Configurations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "To further investigate the impact of various architectures and parameter settings of LLMs, we conducted additional ablation experiments that focused on different LLM architectures and parameter sizes (e.g., base model and large model). These experiments included encoder-only models (e.g., BERT), decoder-only models (e.g., GPT-2), and encoder-decoder models (e.g., BART) to determine which configurations yield the greatest beneftis during fine-tuning. The results are summarized in the table 5. ", "page_idx": 22}, {"type": "table", "img_path": "a6HzEu4Kpo/tmp/8b681b175ccff100a32cbf53fcb09a594a142f1bd9a87995a6a71259f502936c.jpg", "table_caption": ["Table 5: Performance comparison of different LLM architectures and parameter sizes across datasets. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "The results indicate that decoder-only architectures, specifically the GPT-2 base model in this experiments, achieve the best performance. However, increasing the number of parameters in all three architectures leads to a significant drop in performance across 3 architectures for time series OOD generalization. ", "page_idx": 22}, {"type": "image", "img_path": "a6HzEu4Kpo/tmp/6b8c5e1df9739ba8fad5d339b81b94399d648199644350a8a550a8989f4ed055.jpg", "img_caption": ["Figure 6: The effect of varying the number of Transformer layers (k) on average accuracy for OOD generalization across HHAR, PAMAP, and WESAD datasets. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "To further explore how the number of parameters affects performance, we conducted experiments using GPT-2 models with varying numbers of Transformer layers on 3 datasets to evaluate their OOD generalization performance. For these experiments, we utilized $20\\%$ of each dataset. As shown in Figure 3 (in the attached PDF), the results demonstrate that optimal OOD generalization performance is achieved with a configuration of 8 Transformer layers. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "Based on this findings, we incorporate this optimal layer configuration with TTSO framework, yielding improved results as detailed in the table 6. ", "page_idx": 23}, {"type": "text", "text": "Table 6: Performance improvements on different domains for HHAR, PAMAP, and WESAD datasets. ", "page_idx": 23}, {"type": "table", "img_path": "a6HzEu4Kpo/tmp/988b5303bf0a6f0bf9492f7699631d65e04c275ff6d156104e2251e2df76d0e9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "F Limitation ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "TTSO is a general framework for learning invariant representations across diverse domain distributions, currently discussed only for time series classification. This framework could be further enhanced by extending it to more time series OOD tasks, such as time series forecasting and anomaly detection. Additionally, distribution shifts occur not only in time series but also in other machine learning domains like images [Deecke et al., 2021] and text [Tan et al., 2022]. Applying our approach to these domains could further improve performance. ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: In the abstract and introduction, we clearly state the main contributions of our work. The tri-level learning framework, stratified localization algorithm and iteration complexity analysis is in Section 3.2, 3.3 and 4. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The limitations of this work can be found in Appendix F. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper. \u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. ", "page_idx": 23}, {"type": "text", "text": "\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: In this paper, all theoretical results are accompanied by a full set of assumptions and complete proofs. These are clearly stated and numbered within the main text and are cross-referenced appropriately. Detailed proofs for major theorems are provided in the Appendix. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our paper provides detailed descriptions of the experimental setup. Detailed information regarding datasets, domain setting, data pre-processing, network architecture and hyperparameters can be found in Appendix B.1, B.2, B.3 and C. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: While the data used in our study is publicly available, we are currently unable to provide open access to the code. However, we have included detailed descriptions of the data access, preprocessing steps, model architecture, and experimental setup in the paper and Appendix. These details should be sufficient for others to reproduce the experimental results. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Our paper provides detailed descriptions of the experimental details. Detailed information regarding datasets, domain setting, data pre-processing, network architecture and hyperparameters can be found in Appendix B.1, B.2, B.3 and C. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We report the mean accuracy and standard deviation across three runs with different random seeds. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We provide the type of compute workers (GPU) in the Appendix C Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. ", "page_idx": 26}, {"type": "text", "text": "\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Our research adheres to all guidelines outlined in the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper poses no such risks. ", "page_idx": 27}, {"type": "text", "text": "\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing experiments or research with human subjects. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing experiments or research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]