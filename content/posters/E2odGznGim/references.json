{"references": [{"fullname_first_author": "Tianyu Gu", "paper_title": "Badnets: Evaluating backdooring attacks on deep neural networks", "publication_date": "2019-07-01", "reason": "This paper is foundational in the field of backdoor attacks, introducing the BadNets attack and significantly influencing subsequent research."}, {"fullname_first_author": "Xinyun Chen", "paper_title": "Targeted backdoor attacks on deep learning systems using data poisoning", "publication_date": "2017-12-01", "reason": "This paper is highly influential for its early introduction of targeted backdoor attacks through data poisoning, a common and impactful attack method."}, {"fullname_first_author": "Yige Li", "paper_title": "Neural attention distillation: Erasing backdoor triggers from deep neural networks", "publication_date": "2021-01-01", "reason": "This work proposes a defense mechanism against backdoor attacks and is frequently cited as a significant contribution to backdoor defense techniques."}, {"fullname_first_author": "Bolun Wang", "paper_title": "Neural cleanse: Identifying and mitigating backdoor attacks in neural networks", "publication_date": "2019-05-01", "reason": "This paper presents a notable defense strategy against backdoor attacks and its technique has influenced the design of subsequent defense methods."}, {"fullname_first_author": "Baoyuan Wu", "paper_title": "Backdoorbench: A comprehensive benchmark of backdoor learning", "publication_date": "2022-01-01", "reason": "This paper offers a standard benchmark dataset and evaluation metrics, providing a crucial resource for comparing various backdoor attacks and defenses, thereby significantly shaping the field."}]}