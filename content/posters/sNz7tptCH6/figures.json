[{"figure_path": "sNz7tptCH6/figures/figures_2_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure shows the overall framework of the proposed Adaptive Token Tuning (ATT) attack method.  The process starts with a clean image and its corresponding ground-truth label.  A self-paced patch out strategy is used to dynamically discard patches in the adversarial perturbation. The adaptive variance reduced token gradient method then adjusts the token gradients within and across the ViT layers, mitigating overfitting and improving transferability. This gradient correction involves re-scaling the largest token gradient(s) and applying a hybrid token gradient truncation method to weaken the attention mechanism. The process culminates in the generation of adversarial examples.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_9_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure shows a flowchart summarizing the Adaptive Token Tuning (ATT) attack method.  The method comprises three main strategies: adaptive variance reduced token gradient, self-paced patch out, and truncated attention layers.  Adaptive variance reduction corrects the gradient variance across layers to produce more transferable adversarial examples. Self-paced patch out enhances the diversity of input tokens by discarding patches based on feature importance in a self-paced manner. Truncated attention layers mitigate overfitting by weakening the attention mechanism in deep layers of the Vision Transformer (ViT). The figure visually depicts the interaction and flow of information between these strategies during the attack process.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_16_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure shows a detailed flowchart of the Adaptive Token Tuning (ATT) attack method proposed in the paper.  It illustrates the three main optimization strategies used: adaptive gradient re-scaling, self-paced patch out, and hybrid token gradient truncation. Each strategy is visually represented, highlighting the interactions and flow of information between different components. The figure is crucial in understanding how the method boosts the transferability of adversarial attacks on Vision Transformers.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_16_2.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure shows a schematic of the Adaptive Token Tuning (ATT) attack method proposed in the paper.  It illustrates the three main components of the ATT attack: Self-Paced Patch Out, Adaptive Variance Reduced Token Gradient, and Truncated Attention Layers.  Self-Paced Patch Out uses feature importance to selectively discard perturbation patches, improving diversity and efficiency.  Adaptive Variance Reduced Token Gradient re-scales token gradients to reduce variance across layers, enhancing transferability. Finally, Truncated Attention Layers mitigate overfitting by weakening the attention mechanism in deeper layers. The figure visually represents the interactions and flow of information between these components during the adversarial attack process.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_18_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure presents a flowchart illustrating the Adaptive Token Tuning (ATT) attack method.  The method comprises three main strategies: adaptive variance reduced token gradient, self-paced patch out, and hybrid token gradient truncation.  The adaptive variance reduced token gradient strategy aims to reduce the gradient variance across different layers of the Vision Transformer (ViT) model while preserving crucial feature information.  The self-paced patch out strategy leverages feature importance to dynamically control the number of discarded patches.  Finally, the hybrid token gradient truncation strategy weakens the effect of the attention mechanism.  The flowchart shows the interplay of these three strategies during the attack process.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_19_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure shows the overall framework of the proposed Adaptive Token Tuning (ATT) attack method.  It illustrates three optimization strategies: adaptive gradient rescaling to reduce variance, self-paced patch out to enhance input diversity, and hybrid token gradient truncation to weaken the attention mechanism.  The figure visually represents the flow of the attack process, highlighting the interaction between these strategies and their impact on improving the transferability of adversarial attacks on Vision Transformers (ViTs).", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_19_2.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure illustrates the Adaptive Token Tuning (ATT) attack method proposed in the paper. It shows three main components: Adaptive Variance Reduced Token Gradient, Self-Paced Patch Out, and Truncated Attention Layers. The Adaptive Variance Reduced Token Gradient component aims to reduce the overall variance of token gradients, improving the stability and transferability of the attack. The Self-Paced Patch Out component enhances the diversity of input tokens by selectively discarding patches based on feature importance. The Truncated Attention Layers component weakens the effectiveness of the attention mechanism to mitigate overfitting. The figure visually represents the flow of information and the interactions between these components during the attack process.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_20_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure presents a flowchart that illustrates the framework of the proposed Adaptive Token Tuning (ATT) attack method.  It shows three main components working together: 1) Self-Paced Patch Out, which selectively discards less important patches during the adversarial perturbation process; 2) Adaptive Variance Reduced Token Gradient, which adjusts the gradient variance to avoid overfitting and improve transferability; and 3) Truncated Attention Layers, which reduces the influence of the attention mechanism in deeper layers of the Vision Transformer (ViT). The combination of these strategies is intended to boost the effectiveness of adversarial attacks against ViTs.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_22_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure shows a schematic of the proposed Adaptive Token Tuning (ATT) attack method.  The method consists of three optimization strategies: adaptive gradient rescaling to reduce token gradient variance, self-paced patch-out to improve input diversity, and hybrid token gradient truncation to weaken the attention mechanism. The figure highlights the interactions between these strategies and the overall workflow of the attack.", "section": "3 Methodology"}, {"figure_path": "sNz7tptCH6/figures/figures_23_1.jpg", "caption": "Figure 1: The overall framework of our Adaptive Token Tuning (ATT) attack method.", "description": "This figure shows the overall framework of the proposed Adaptive Token Tuning (ATT) attack method.  The framework consists of three main components: Self-Paced Patch Out, Adaptive Variance Reduced Token Gradient, and Truncated Attention Layers.  Self-Paced Patch Out uses a self-paced learning strategy to discard patches from the input image, improving input diversity. Adaptive Variance Reduced Token Gradient adjusts token gradients by reducing their variance, preventing overfitting and leading to more stable optimization. Finally, Truncated Attention Layers mitigate the effect of the attention mechanism in deep ViT layers, further improving transferability.  The figure illustrates the interactions between these components, showing the flow of information during the attack process.", "section": "3 Methodology"}]