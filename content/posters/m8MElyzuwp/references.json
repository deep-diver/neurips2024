{"references": [{"fullname_first_author": "Francisco M Castro", "paper_title": "End-to-end incremental learning", "publication_date": "2018-00-00", "reason": "This paper is foundational for dataset condensation methods, particularly in the context of incremental learning, which the current paper builds upon."}, {"fullname_first_author": "George Cazenavette", "paper_title": "Dataset distillation by matching training trajectories", "publication_date": "2022-00-00", "reason": "This paper is highly relevant as it directly addresses dataset condensation by focusing on matching training trajectories, a technique that is conceptually similar to the current paper's approach."}, {"fullname_first_author": "Akshay Chawla", "paper_title": "Data-free knowledge distillation for object detection", "publication_date": "2021-00-00", "reason": "This is highly relevant as it focuses on data-free knowledge distillation for object detection, a technique which is closely related to the current paper's core idea of efficient dataset condensation for this task."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-00-00", "reason": "This paper is important due to its significant impact on the field of image recognition, providing a foundational model (the vision transformer) that the current paper is relevant to."}, {"fullname_first_author": "Mark Everingham", "paper_title": "The pascal visual object classes challenge: A retrospective", "publication_date": "2015-00-00", "reason": "This paper is crucial as it introduces the widely used Pascal VOC dataset, a benchmark dataset used in the current paper to demonstrate the efficacy of the proposed method."}]}