[{"figure_path": "5lLb7aXRN9/tables/tables_7_1.jpg", "caption": "Table 1: Test accuracy on MNIST dataset", "description": "This table presents the test accuracy results of different models on the MNIST handwritten digit classification task.  The models compared include Stabilized Supralinear Networks (SSNs) with different configurations (50:50 and 80:20 representing the ratio of excitatory to inhibitory neurons), a Multilayer Perceptron (MLP), and the proposed Oscillatory Recurrent Gated Neural Integrator Circuits (ORGANICs) model with different configurations and a two-layer version.  The table demonstrates that ORGANICs achieves comparable or superior performance to the other models on this task.", "section": "6.1 Static input classification task"}, {"figure_path": "5lLb7aXRN9/tables/tables_8_1.jpg", "caption": "Table 2: Test accuracy on sequential pixel-by-pixel MNIST and permuted MNIST", "description": "This table compares the performance of ORGANICs against other RNN models on two sequential MNIST tasks: the standard sequential MNIST (sMNIST) and the permuted sequential MNIST (psMNIST).  The sMNIST task involves classifying MNIST digits from their pixels presented sequentially in scanline order.  psMNIST adds a further challenge by randomly permuting the pixel order before presentation. The table shows the test accuracy, the number of hidden units, and the number of parameters for each model.  ORGANICs achieves performance comparable to LSTMs on sMNIST and only slightly lower on psMNIST, even without using ad-hoc techniques like gradient clipping.", "section": "6 Experiments"}, {"figure_path": "5lLb7aXRN9/tables/tables_32_1.jpg", "caption": "Table 4: ORGANICs parametrization for static MNIST classification", "description": "This table details the parameterization used for the ORGANICs model in the static MNIST classification task.  It specifies whether each parameter (Wzx, Wbx, Wr, W, bo, \u03c3) is learned during training or fixed, its shape (dimensions), and its initialization method.  The parameters represent different aspects of the model, including input weights, recurrent weights, normalization weights, input gains, and normalization constants.", "section": "6.1 Static input classification task"}, {"figure_path": "5lLb7aXRN9/tables/tables_33_1.jpg", "caption": "Table 4: ORGANICs parametrization for static MNIST classification", "description": "This table lists the parameters used in the ORGANICs model for static MNIST classification, their shapes, whether they are learned during training, and their initialization methods.  The parameters include weight matrices for input (Wzx, Wbx), recurrent connections (Wby, Wba), input gain modulation (Wbox, Wboy, Wboa), the recurrent weight matrix (Wr), normalization weights (W), and the parameters \u03c3 for divisive normalization.  The initialization methods include kaiming uniform and identity matrix.", "section": "6.1 Static input classification task"}, {"figure_path": "5lLb7aXRN9/tables/tables_33_2.jpg", "caption": "Table 7: Hyperparameters", "description": "This table shows the hyperparameters used for training the ORGANICs model on the static and sequential MNIST image classification tasks. For the static MNIST task, there was no step size for the learning rate scheduler. In contrast, for the sequential MNIST task, the step size for the learning rate scheduler was set to 30 epochs and the gamma to 0.8.", "section": "6 Experiments"}]