[{"figure_path": "jfE7XCE89y/figures/figures_2_1.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates the FuseMoE architecture for handling FlexiModal data.  It shows how modality-specific encoders process various data types (vital signs, ECG, clinical notes, chest X-rays),  handling missing data and irregular sampling. A multi-time attention mechanism addresses temporal irregularities. The core is the MoE Fusion Layer, routing data to expert MLPs based on a gating function, producing fused embeddings for downstream tasks.", "section": "FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_3_1.jpg", "caption": "Figure 2: We present three exemplary designs of the Top-K router for effective multimodal fusion, considering an input scenario with three modalities: Time-Series (TS), Text (TXT), and images (IMG). (a) The joint router design utilizes a concatenated embedding of all modalities, directing this combined input to selected experts. (b) In the modality-specific router design, each modality's embedding is independently assigned to a shared pool of experts. (c) The third design variant also uses modality-specific routers but assigns each modality's embedding to separate pools of experts, each pool uniquely tailored to process a specific modality type.", "description": "This figure illustrates three different architectures for the Top-K router in a multimodal fusion model.  The designs explore different strategies for combining and routing modalities to expert networks.  (a) shows a joint router approach, where a single router processes the concatenated embeddings of all modalities. (b) shows a per-modality router, where separate routers process each modality's embedding individually and share a common pool of experts.  (c) demonstrates disjoint experts and routers, where separate routers route each modality to unique and separate pools of experts.", "section": "2.3 MoE Fusion Layer"}, {"figure_path": "jfE7XCE89y/figures/figures_6_1.jpg", "caption": "Figure 3: Log-log scaled plots illustrating simulation results under the exact-specified (left) and the over-specified settings (right). The orange curves depict the mean discrepancy between the MLE \u011cn and the true mixing measure G*, accompanied by error bars signifying two empirical standard deviations. Additionally, the gray dash-dotted line represents the least-squares fitted linear regression line for these data points. Finally, the loss functions D\u2081 and D2 are defined in equations equation 9 and equation 7, respectively. See Appendix I for the experimental details.", "description": "This figure shows the results of simulation experiments to compare the convergence rates of maximum likelihood estimation (MLE) under the Laplace gating and the Softmax gating in Gaussian Mixture of Experts model.  The left panel shows the results under the exact-specified setting where the number of experts is known, while the right panel shows the results under the over-specified setting where the number of experts is unknown. The plots show the mean discrepancy between the MLE and the true mixing measure, along with error bars representing the empirical standard deviations. The gray dash-dotted lines represent the least-squares fitted linear regression line for the data. The convergence rates are indicated in the legend. Appendix I provides additional details about the experimental setup.", "section": "Theoretical Contribution"}, {"figure_path": "jfE7XCE89y/figures/figures_6_2.jpg", "caption": "Figure 3: Log-log scaled plots illustrating simulation results under the exact-specified (left) and the over-specified settings (right). The orange curves depict the mean discrepancy between the MLE \u011cn and the true mixing measure G*, accompanied by error bars signifying two empirical standard deviations. Additionally, the gray dash-dotted line represents the least-squares fitted linear regression line for these data points. Finally, the loss functions D\u2081 and D2 are defined in equations equation 9 and equation 7, respectively. See Appendix I for the experimental details.", "description": "This figure shows the results of simulation experiments comparing the maximum likelihood estimation (MLE) under the Laplace gating and Softmax gating in the mixture-of-experts (MoE) model. The left panel shows the results under the exact-specified setting (when the true number of experts is known), while the right panel shows the results under the over-specified setting (when the true number of experts is unknown). The orange curves represent the mean discrepancy between the MLE and the true mixing measure, with error bars showing the two empirical standard deviations. The gray dash-dotted lines show the least-squares fitted linear regressions. The loss functions D1 and D2 are defined in equations (7) and (9), respectively.", "section": "Theoretical Contribution"}, {"figure_path": "jfE7XCE89y/figures/figures_7_1.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates how FuseMoE handles Fleximodal data, characterized by a variable number of modalities and irregular sampling patterns.  It shows how modality-specific encoders process different data types (vital signs, ECG, clinical notes, etc.), with a multi-time attention mechanism addressing temporal irregularities. A gating function in the MoE Fusion Layer routes the data to appropriate experts for processing, ultimately generating fused embeddings for downstream tasks.", "section": "2 FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_20_1.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates how FuseMoE handles FlexiModal data, which is characterized by multiple modalities (vital signs, ECG, clinical notes, etc.), temporal irregularity, and missing data.  FuseMoE first encodes each modality separately, uses multi-time attention to handle the irregular time series, and then employs a mixture-of-experts (MoE) fusion layer with a novel gating function to combine the information from all modalities, creating a final embedding for downstream tasks.", "section": "FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_24_1.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates the FuseMoE architecture and how it handles FlexiModal data, which is characterized by multiple modalities (vital signs, ECG, clinical notes, chest X-rays), irregular sampling, and missing data. FuseMoE leverages modality-specific encoders and a multi-time attention mechanism to manage irregular temporal dynamics and missingness.  The core of the model is the MoE Fusion Layer, routing data to specialized experts (MLPs) based on a learned gating function, producing fused embeddings for downstream tasks.", "section": "2 FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_28_1.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates FuseMoE's ability to handle FlexiModal data, which is characterized by diverse modalities, irregular sampling, and missingness.  It shows the process of encoding different modalities using modality-specific encoders, handling temporal irregularities with a multi-time attention mechanism, and integrating them in the MoE fusion layer.  The gating function routes the data to relevant experts for processing, producing fused embeddings for downstream tasks.", "section": "FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_28_2.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates the FuseMoE architecture and its ability to handle FlexiModal data (data with variable numbers of modalities, missing data, and irregular sampling).  It shows how modality-specific encoders process different input types (vital signs, ECG, clinical notes, etc.), which are then integrated via a multi-time attention mechanism to account for irregular sampling patterns. Finally, a MoE fusion layer, guided by a novel gating function, combines the processed inputs into a fused embedding for downstream tasks.", "section": "FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_29_1.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates the FuseMoE architecture and how it handles FlexiModal data (data with multiple modalities, irregular sampling, and missing values).  It shows how modality-specific encoders process different data types, a multi-time attention mechanism addresses temporal irregularities, and a Mixture-of-Experts (MoE) layer with a novel gating function fuses the information for prediction.", "section": "FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_29_2.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates FuseMoE's architecture and how it handles FlexiModal data (data with multiple modalities, missing values, and irregular sampling).  Modality-specific encoders process different data types, a multi-time attention mechanism addresses temporal irregularities, and a Mixture-of-Experts (MoE) fusion layer routes data to specialized experts based on input characteristics.  The final embeddings are then used for prediction.", "section": "FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_29_3.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates the FuseMoE architecture and how it handles FlexiModal data, which is characterized by various modalities (vital signs, ECG, clinical notes, chest X-rays), temporal irregularity, and missing data.  The architecture uses modality-specific encoders, followed by a multi-time attention mechanism and the core MoE fusion layer with a sparse gating mechanism to route inputs to the appropriate experts before producing fused embeddings.", "section": "2 FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_30_1.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates the FuseMoE architecture and its ability to handle FlexiModal data (data with varying numbers of modalities, missing data, and irregular sampling).  It shows how modality-specific encoders process different data types, a multi-time attention mechanism addresses temporal irregularities, and a MoE fusion layer routes data to expert MLPs for weighted fusion and final embedding.", "section": "2 FuseMoE: Enhance Predictive Performance for FlexiModal Data"}, {"figure_path": "jfE7XCE89y/figures/figures_30_2.jpg", "caption": "Figure 1: An example of addressing the challenge of FlexiModal Data: patients in ICUs often have extensive and irregular health status measurements over time; patients with milder conditions only require monitoring across fewer categories. FuseMoE is adept at handling inputs featuring any combination of modalities, including those with missing elements. It starts by encoding inputs using modality-specific feature extractors, followed by employing a multi-time attention mechanism [82] to address temporal irregularities. The core of FuseMoE lies the MoE Fusion Layer, where a routing mechanism is trained to categorize multimodal inputs and direct them to the appropriate combinations of MLPs. The outputs from these MLPs are weighted through a gating function, resulting in fused embeddings, which are subsequently utilized for further processing.", "description": "This figure illustrates the FuseMoE architecture and its ability to handle FlexiModal data, which is characterized by multiple modalities, temporal irregularity, and missing data. The architecture consists of modality-specific encoders, a multi-time attention mechanism, a MoE fusion layer, and a final prediction layer.", "section": "2 FuseMoE: Enhance Predictive Performance for FlexiModal Data"}]