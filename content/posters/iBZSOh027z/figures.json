[{"figure_path": "iBZSOh027z/figures/figures_3_1.jpg", "caption": "Figure 1: The motivation for SNAPS. (a) The trend of Coverage and Size as the number of nodes with the same label as the ego node increases. (b) The average of node feature cosine similarity between same or different labels. (c) The number statistics of nodes with the same label and with different labels as the ego node with increasing k that denotes k-NN with feature similarity.", "description": "This figure demonstrates the impact of aggregating non-conformity scores from similar nodes on the efficiency of conformal prediction sets.  Panel (a) shows that increasing the number of nodes with the same label as the target node reduces the prediction set size while maintaining coverage. Panel (b) shows that nodes with the same label tend to have higher feature similarity.  Panel (c) visually confirms the effectiveness of using k-NN based on feature similarity for selecting similar nodes.", "section": "3 Motivation and Methodology"}, {"figure_path": "iBZSOh027z/figures/figures_4_1.jpg", "caption": "Figure 2: The overall framework of SNAPS. (1) Basic non-conformity score function. We first use basic non-conformity score functions, e.g., APS, to convert node embeddings into non-conformity scores. (2) SNAPS function (our method). We then aggregate basic non-conformity scores of k-NN with feature similarity and one-hop structural neighbors to correct the non-conformity scores of nodes. (3) Conformal Prediction. Finally, we use conformal prediction to generate prediction sets, significantly reducing their size compared to the basic score functions.", "description": "This figure illustrates the three main steps of the Similarity-Navigated Adaptive Prediction Sets (SNAPS) algorithm.  First, a basic non-conformity score (e.g., Adaptive Prediction Sets or APS) is calculated from node embeddings generated by a Graph Neural Network (GNN). Second, the SNAPS function refines these scores by aggregating scores from k-nearest neighbors (based on feature similarity) and one-hop neighbors. Finally, conformal prediction uses these corrected scores to produce smaller, more efficient prediction sets.", "section": "3.2 Similarity-Navigated Adaptive Prediction Sets"}, {"figure_path": "iBZSOh027z/figures/figures_7_1.jpg", "caption": "Figure 1: The motivation for SNAPS. (a) The trend of Coverage and Size as the number of nodes with the same label as the ego node increases. (b) The average of node feature cosine similarity between same or different labels. (c) The number statistics of nodes with the same label and with different labels as the ego node with increasing k that denotes k-NN with feature similarity.", "description": "This figure presents empirical evidence supporting the core idea of SNAPS. Subfigure (a) shows that increasing the number of nodes with the same label as the ego node improves the efficiency (Size) of conformal prediction sets without compromising the coverage guarantee. Subfigure (b) demonstrates that nodes with the same label tend to have higher feature similarity. Subfigure (c) shows the distribution of nodes with the same/different labels within the k-nearest neighbors based on feature similarity, reinforcing the effectiveness of using feature similarity to identify similar nodes.", "section": "3 Motivation and Methodology"}, {"figure_path": "iBZSOh027z/figures/figures_8_1.jpg", "caption": "Figure 1: The motivation for SNAPS. (a) The trend of Coverage and Size as the number of nodes with the same label as the ego node increases. (b) The average of node feature cosine similarity between same or different labels. (c) The number statistics of nodes with the same label and with different labels as the ego node with increasing k that denotes k-NN with feature similarity.", "description": "This figure empirically shows the impact of aggregating non-conformity scores from nodes with the same label as the ego node on the efficiency and coverage of conformal prediction sets.  Panel (a) demonstrates that increasing the number of nodes with the same label reduces the average prediction set size while maintaining coverage. Panel (b) visually shows that nodes with the same label tend to have higher feature similarity than nodes with different labels. Panel (c) provides further evidence that selecting k-nearest neighbors based on feature similarity effectively identifies more nodes with the same label.", "section": "3 Motivation and Methodology"}, {"figure_path": "iBZSOh027z/figures/figures_17_1.jpg", "caption": "Figure 1: The motivation for SNAPS. (a) The trend of Coverage and Size as the number of nodes with the same label as the ego node increases. (b) The average of node feature cosine similarity between same or different labels. (c) The number statistics of nodes with the same label and with different labels as the ego node with increasing k that denotes k-NN with feature similarity.", "description": "This figure demonstrates the impact of aggregating non-conformity scores from similar nodes on the efficiency and coverage of conformal prediction.  Panel (a) shows that increasing the number of nodes with the same label as the target node reduces the average prediction set size while maintaining coverage. Panel (b) shows that nodes with the same label tend to have higher feature similarity. Panel (c) visually represents the number of similar nodes (k-NN) with the same label and different labels compared to the target node, further supporting the motivation for the SNAPS algorithm.", "section": "3 Motivation and Methodology"}, {"figure_path": "iBZSOh027z/figures/figures_20_1.jpg", "caption": "Figure 1: The motivation for SNAPS. (a) The trend of Coverage and Size as the number of nodes with the same label as the ego node increases. (b) The average of node feature cosine similarity between same or different labels. (c) The number statistics of nodes with the same label and with different labels as the ego node with increasing k that denotes k-NN with feature similarity.", "description": "This figure demonstrates the motivation behind the Similarity-Navigated Adaptive Prediction Sets (SNAPS) algorithm. Subfigure (a) shows how increasing the number of nodes with the same label as the ego node improves the efficiency of conformal prediction by reducing the size of prediction sets while maintaining coverage. Subfigure (b) illustrates the feature similarity between nodes with the same and different labels, highlighting the rationale for using similarity to select nodes. Subfigure (c) provides statistics on the number of nodes with the same and different labels within a k-nearest neighbor graph, showcasing that similarity can indeed help in identifying nodes with the same label.", "section": "3 Motivation and Methodology"}, {"figure_path": "iBZSOh027z/figures/figures_20_2.jpg", "caption": "Figure 1: The motivation for SNAPS. (a) The trend of Coverage and Size as the number of nodes with the same label as the ego node increases. (b) The average of node feature cosine similarity between same or different labels. (c) The number statistics of nodes with the same label and with different labels as the ego node with increasing k that denotes k-NN with feature similarity.", "description": "This figure presents empirical evidence supporting the core idea of SNAPS, which leverages the information from nodes with the same label as the ego node to improve prediction efficiency.  Panel (a) shows that increasing the number of nodes with the same label reduces the size of the prediction sets while maintaining coverage. Panel (b) shows the feature similarity is higher between nodes with the same label.  Panel (c) demonstrates that using k-NN based on feature similarity effectively selects more nodes with the same label as k increases.", "section": "3 Motivation and Methodology"}]