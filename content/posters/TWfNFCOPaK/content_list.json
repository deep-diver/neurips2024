[{"type": "text", "text": "Probabilistic and Differentiable Wireless Simulation with Geometric Transformers ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Modelling the propagation of electromagnetic signals is critical for designing mod  \n2 ern communication systems. While there are precise simulators based on ray trac  \n3 ing, they do not lend themselves to solving inverse problems or the integration in   \n4 an automated design loop. We propose to address these challenges through differ  \n5 entiable neural surrogates that exploit the geometric aspects of the problem. We   \n6 first introduce the Wireless Geometric Algebra Transformer (Wi-GATr), a generic   \n7 backbone architecture for simulating wireless propagation in a 3D environment. It   \n8 uses versatile representations based on geometric algebra and is equivariant with   \n9 respect to E(3), the symmetry group of the underlying physics. Second, we study   \n10 two algorithmic approaches to signal prediction and inverse problems based on   \n1 differentiable predictive modelling and diffusion models. We show how these let   \n12 us predict received power, localize transmitters, and reconstruct the 3D environ  \n13 ment from the received signal. Finally, we introduce two large, geometry-focused   \n14 datasets of wireless signal propagation in indoor scenes. In experiments, we show   \n15 that our geometry-forward approach achieves higher-fidelity predictions with less   \n16 data than various baselines. ", "page_idx": 0}, {"type": "text", "text": "1 7 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "18 Modern communication is wireless: more and more, we communicate via electromagnetic waves   \n19 through the antennas of various devices, leading to progress in and adoption of mobile phones, auto  \n20 motive, AR/VR, and IoT technologies [12, 16]. All these innovations build upon electromagnetic   \n21 wave propagation. Therefore, modelling and understanding wave propagation in space is a core re  \n22 search area in wireless communication, and remains crucial as we are moving toward new generations   \n23 of more efficient and spatially-aware wireless technologies.   \n24 Wireless signal propagation follows Maxwell\u2019s equations of electromagnetism and is often accurately   \n25 modelled by state-of-the-art ray-tracing simulation software. However, these simulators take substan  \n26 tial time to evaluate for each scene, cannot be fine-tuned on measurements, and are (usually [29]) not   \n27 differentiable. This limits their usefulness for solving inverse problems.   \n28 In contrast, neural models of signal propagation can be evaluated cheaply, can be trained on real   \n29 measurements in addition to simulation, and are differentiable and thus well-suited for solving   \n30 inverse problems. Several such approaches have been proposed recently, often using image-based   \n31 representations of the inputs and outputs and off-the-shelf vision architectures [6, 23, 34, 35, 44, 46,   \n32 51, 52]. However, wireless surrogate modelling faces various challenges. Realistic training data   \n33 is often scarce, requiring surrogate models to be data efficient. Wireless environments can consist   \n34 of complex meshes. Finally, input and output data consist of a variety of data types, including the   \n35 shape of extended 3D objects, point coordinates and spatial orientation of antennas, and information   \n36 associated with the transmitted signal.   \n37 In this work, we present a new approach to modelling wireless signal propagation. It is grounded in   \n38 the observation that wireless propagation is inherently a geometric problem: a directional signal is   \n39 transmitted by an oriented transmitting antenna, the signal interacts with surfaces in the environment,   \n40 and the signal eventually impinges an oriented receiving antenna. We argue that it is critical for   \n41 neural surrogates to model and flexibly represent geometric aspects (e. g. orientations, shapes) in   \n42 the propagation environment. We therefore develop surrogate models based on flexible geometric   \n43 representation and strong geometric inductive biases.   \n44 We first propose the Wireless Geometric Algebra Transformer (Wi-GATr), a backbone architecture for   \n45 wireless signal propagation problems. A key component is a new tokenizer for the diverse, geometric   \n46 data of wireless scenes. The tokens are processed with a Geometric Algebra Transformer (GATr)   \n47 network [9]. This architecture is equivariant with respect to the symmetries of wireless channel   \n48 modelling, but maintains the scalability of a transformer architecture.   \n49 Second, we study Wi-GATr models as differentiable, predictive surrogates for the simulator (see   \n50 Fig. 1a). Here the network predicts observables such as the received power as a function of transmitter   \n51 position, receiver position, and 3D environment. We show how this enables forward modelling, and   \n52 in addition, inverse problem solving due to Wi-GATr\u2019s differentiability.   \n53 Next, we propose an alternative, more versatile probabilistic approach to prediction and inference   \n54 tasks: training Wi-GATr diffusion models (Fig. 1b) on the joint distribution of transmitter, receiver,   \n55 channel information, and 3D environment. At test time, the model can be flexibly conditioned on any   \n56 available information to predict the received power, localize a transmitter or receiver (Fig. 1c), or   \neven reconstruct the (full or partial) 3D geometry from the wireless signal (Fig. 1d).   \n58 To enable machine learning development for wireless problems, we finally introduce two new datasets,   \n59 Wi3R and WiPTR. Each dataset consists of thousands of indoor scenes of varying complexity and   \n60 include all the geometric information that characterizes a wireless scene.   \n61 Finally, we demonstrate the predictive and the probabilistic models on these datasets. Our experi  \n62 ments show that the Wi-GATr approach gives us a higher-fidelity predictions than various baselines,   \n63 generalizes robustly to unseen settings, and requires up to 20 times less data for the same perfor  \n64 mance than a transformer baseline. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/0fbb767e4b08260511339a7b10b66634a4a5ee18f57e133cc43ca6b3846d65cd.jpg", "img_caption": ["Figure 1: Geometric surrogates for modelling wireless signal propagation. (a): Predictive modelling of channels from 3D geometry, transmitter, and receiver properties. Wi-GATr is a fast and differentiable surrogate for ray tracers. (b): A probabilistic approach with diffusion models lets us reconstruct 3D environments (c) and antenna positions (d) from the wireless signal. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "65 2 Background and related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "66 Wireless signal propagation. How do wireless signals propagate from a transmitting antenna   \n67 (Tx) to a receiver antenna (Rx) in a (static) 3D environment? While the system is fundamentally   \n68 described by Maxwell\u2019s equations, for many realistic problems the ray approximation of geometric   \n69 optics suffices [31]. It approximates the solution to Maxwell\u2019s equations as a sum of planar waves   \n70 propagating in all directions from Tx. Each planar wave is represented as a ray, characterized by   \n71 various attributes (e. g., power, phase, delay) since transmission. As a ray reaches an object\u2014that is,   \n72 it intersects with its mesh\u2014the interaction is modelled as reflection, refraction, or diffraction. During   \n73 such interactions, the power, phase, polarization, and propagation direction of the wave can change in   \n74 complex, material-dependent ways. In addition, new rays can emanate from the point of interaction.   \n75 After multiple interactions, the rays eventually reach the receiving antenna. The Tx and Rx are then   \n76 linked by a connected path $p$ of multiple rays. The effects on the received signal are described by the   \n77 channel impulse response (CIR) $\\begin{array}{r}{h(\\tau)=\\dot{\\sum_{p}}\\,a_{p}\\delta(\\tau-\\tau_{p})}\\end{array}$ , where $a_{p}\\in\\mathbb{C}$ is the complex gain and $\\tau_{p}$   \n78 the delay of the incoming rays [53].   \n79 Maxwell\u2019s equations and in extension ray propagation are highly symmetric. The received signal does   \n80 not change under rotations, translations, and reflections of the whole scene, as well as the exchange   \n81 of transmitter and receiver. The latter property is known as reciprocity [37].   \n82 Wireless simulators. Wireless propagation models play a key role in design and evaluation of   \n83 communication systems, for instance by characterizing the gain of competitive designs in realistic   \n84 settings or by optimizing systems performance as in base station placement for maximal coverage.   \n85 Statistical approaches [2] represent propagation as a generative model where the parameters of a   \n86 probabilistic model are fitted to measurements. On the other hand, wireless ray-tracing approaches   \n87 [1, 5, 29] are increasingly popular due to their high accuracy and because they do not require   \n88 expensive field measurement collection campaigns.   \n89 Neural wireless simulations. Both statistical and ray-tracing simulation techniques are accompanied   \n90 by their own shortcomings, subsequently mitigated by their neural counterparts. Neural surrogates for   \n91 statistical models [19, 40, 42, 56] reduce the amount and cost of measurements required. Neural ray   \n92 tracers [29, 41, 58] address the non-differentiability of simulators using a NeRF-like strategy [38] by   \n93 parameterizing the scene using a spatial MLP and rendering wireless signals using classic ray-tracing   \n94 or volumetric techniques. While these techniques are faster than professional ray tracers, they are   \n95 similarly bottlenecked by expensive bookkeeping and rendering steps (involving thousands of forward   \n96 passes). In contrast, we propose a framework to simulate wireless signals with a single forward pass   \n97 through a geometric transformer that is both sample-efficient and generalizes to novel scenes.   \n98 Geometric deep learning. The growing field of geometric deep learning [11] aims to incorporate   \n99 structural properties of a problem into neural network architectures and algorithms. A central concept   \n100 is equivariance to symmetry groups [15]: a network $f(x)$ is equivariant with respect to a group   \n101 $G$ if its outputs transform consistently with any symmetry transformation $g\\,\\in\\,G$ of the inputs,   \n102 $f(g\\cdot x)=g\\cdot f(x)$ , where $\\cdot$ denotes the group action. Of particular interest to us is the Euclidean   \n103 group $\\mathrm{E}(3)$ of isometries of 3D space, that is, transformations that leave Euclidean distances invariant.   \n104 This group includes spatial translations, rotations, reflections, and their combinations. As we argued   \n105 above, the physics of wireless signal propagation are invariant under this group.   \n106 GATr. The Geometric Algebra Transformer (GATr) [9] is an $\\mathrm{E}(3)$ -equivariant architecture for geo  \n107 metric problems. Among equivariant architectures, it stands out in two ways. First, it uses geometric   \n108 (or Clifford) algebras [14, 22] as representations. For a rigorous introduction to these algebras, we   \n109 refer the reader to Dorst [20]. From a practical machine learning perspective, these algebras define   \n110 embeddings for various geometric primitices like 3D points, planes, or E(3) transformations. We   \n111 will show that this representation is particularly well-suited for wireless channel modelling. Second,   \n112 GATr is a transformer architecture [54]. It computes the interactions between multiple tokens through   \n113 scaled dot-product attention. With efficient backends like FlashAttention [17], the architecture is scal  \n114 able to large systems, without any restrictions on the sparsity of interactions like in message-passing   \n115 networks.   \n116 Diffusion models. Diffusion models [25, 48, 50] are a class of generative models that iteratively   \n117 invert a noising process. They have become the de-facto standard in image and video generation   \n118 [26, 45]. Recently, they have also shown to yield promising results in the generation of spatial   \n119 and sequential data, such as in planning [30] and puzzle solving [28]. Aside from their generative   \n120 modelling capabilities, diffusion models provide a flexible way for solving inverse problems [13, 36]   \n21 through multiplication with an appropriate likelihood term [48]. Furthermore, by combining an   \n122 invariant prior distribution with an equivariant denoising network, one obtains equivariant diffusion   \n123 models [33]. These yield a sampling distribution that assigns equal probability to all symmetry   \n124 transformations of an object, which can improve performance and data efficiency in symmetry   \n125 problems like molecule generation [27] and planning [10]. We will demonstrate similar benefits in   \n126 modelling wireless signal propagation. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "127 3 The Wireless Geometric Algebra Transformer (Wi-GATr) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "128 3.1 Problem formulation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "129 Our goal is to model the interplay between 3D environments, transmitting and receiving antennas, and   \n130 the resulting transmitted wireless signals. More precisely, we consider wireless scenes consisting of:   \n131 \u2022 The 3D geometry $F$ of the environment. We specify it through a triangular mesh with a discrete   \n132 material class associated with each mesh face.   \n133 \u2022 A set of transmitting antennas $t_{i}$ for $i=1,\\dots,n_{t}$ . Each $t_{i}$ is characterized by a 3D position,   \n134 an orientation, and any antenna characteristics. We will often focus on the case of a single $\\mathbf{T}\\mathbf{X}$   \n135 and then omit the index $i$ .   \n136 \u2022 Analogously, a set of receiving antennas $r_{i}$ for $i=1,\\dots,n_{r}$ .   \n137 \u2022 The channel or signal $h_{i j}$ between each transmitter $i$ and each receiver $j$ , which can be any   \n138 observable function of the CIR. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "139 In this setting, we consider various downstream tasks: ", "page_idx": 3}, {"type": "text", "text": "140 \u2022 Signal prediction is about predicting the signal received at a single antenna from a single   \n141 receiver, $p(h|F,t,r)$ with $n_{t}=n_{r}=1$ . This is exactly the task that ray-tracing simulators   \n142 solve. Often, the signal is modelled deterministically as a function $h(F,t,r)$ .   \n143 \u2022 Receiver localization: inferring the position and properties of a receiving antenna from one or   \n144 multiple transmitters, $r\\sim p(r|\\tilde{F},\\{t_{i}\\},\\{h_{i}\\})$ , with $n_{r}=1$ .   \n145 \u2022 Geometry reconstruction or sensing: reconstructing a 3D environment partially, inferring   \n146 $p(F_{u}|F_{k},t,r,h)$ , where $F_{u}$ and $F_{k}$ are the unknown and known subsets of $F$ , respectively.   \n147 The latter two problems are examples of inverse problems, as they invert the graphical model that   \n148 simulators are designed for. They are not straightforward to solve with the simulators directly, but we   \n149 will show how neural surrogates trained on simulator data can solve them. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "150 3.2 Backbone ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "151 Core to our approach to this family of inference problems is the Wireless Geometric Algebra   \n152 Transformer (Wi-GATr) backbone. It consists of a novel tokenizer and a network architecture.   \n153 Wireless GA tokenizer. The tokenizer takes as input some subset of the information characterizing   \n154 a wireless scene and outputs a sequence of tokens that can be processed by the network. A key   \n155 challenge in the neural modelling of wireless problems is the diversity of types of data involved. As   \n156 we argued above, a wireless scene consists of the 3D environment mesh $F$ , which features three  \n157 dimensional objects such as buildings and trees, antennas $t$ and $r$ characterized through a point  \n158 like position, an antenna orientation, and additional information about the antenna type, and the   \n159 characteristics of the channel $h$ .   \n160 To support all of these data types, we propose a new tokenizer that outputs a sequence of geometric   \n161 algebra (GA) tokens. Each token consists of a number of elements (channels) of the projective   \n162 geometric algebra $\\mathbb{G}_{3,0,1}$ in addition to the usual unstructured scalar channels. We define the GA   \n163 precisely in Appendix A. Its main characteristics are that each element is a 16-dimensional vector   \n164 and can represent various geometric primitives: 3D points including an absolute position, lines,   \n165 planes, and so on. This richly structured space is ideally suited to represent the different elements   \n166 encountered in a wireless problem. Our tokenization scheme is specified in Tbl. 1.   \n167 Network. After tokenizing, we process the input data with a Geometric Algebra Transformer   \n168 (GATr) [9]. This architecture naturally operates on our $\\mathbb{G}_{3,0,1}$ parameterization of the scene. It is   \n169 equivariant with respect to permutations of the input tokens as well as $\\mathrm{E}(3)$ , the symmetry group   \n170 of translations, rotations, and reflections. These are exactly the symmetries of wireless signal   \n171 propagation, with one exception: wireless signals have an additional reciprocity symmetry that   \n172 specifies that the signal is invariant under an role exchange between transmitter and receiver. We will   \n173 later show how we can incentivize this additional symmetry property through data augmentation.1   \n174 Finally, because GATr is a transformer, it can process sequences of variable lengths and scales well   \n175 to systems with many tokens. Both properties are crucial for complex wireless scenes, which can in   \n176 particular involve a larger number of mesh faces. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "table", "img_path": "TWfNFCOPaK/tmp/c5bb3886b8bcc473ac185f0e94efbdde6fac778d910fd42a120a40c64715eec6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "177 3.3 Predictive modelling ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "178 The Wi-GATr backbone can be used either in a predictive or probabilistic ansatz. We begin with the   \n179 predictive modelling of the measured channel information as a function of the complete 3D envi  \n180 ronment and the information characterizing the transmitter and receiver, $h_{\\theta}(F,t,r)$ . This regression   \n181 model is trained in a supervised way on simulated or measured wireless scenes.   \n182 Forward prediction. The network thus learns a differentiable, deterministic surrogate for the   \n183 simulator model $h_{\\mathrm{sim}}(F,t,r)$ . At test time, we can use the network instead of a simulator to predict   \n184 the signals in unseen, novel scenes. Compared to a simulator based on ray tracing, it has three   \n185 advantages: it can be evaluated in microseconds rather than seconds or minutes, it can be finetuned   \n186 on real measurements, and it is differentiable.   \n187 Inverse problems. This differentiability makes such a surrogate model well-suited to solve   \n188 inverse problems. For instance, we can use it for receiver localization. Given a 3D environment $F$ ,   \n189 transmitters $\\{t_{i}\\}$ , and corresponding signals $\\{h_{i}\\}$ , we can find the most likely receiver position and   \n190 orientation as $\\begin{array}{r}{\\hat{r}=\\arg\\operatorname*{min}_{r}\\bar{\\sum}_{i}\\|h_{\\theta}\\bar{(F,\\bar{t}_{i},r)}\\bar{-}h\\|^{2}}\\end{array}$ . The minimization can be performed numerically   \n191 through gradient descent, thanks to the differentiability of the Wi-GATr surrogate. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "192 3.4 Probabilistic modelling ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "193 While a predictive model of the signal can serve as a powerful neural simulator, it has two shortcom  \n194 ings. Solving an inverse problem through gradient descent requires a sizable computational cost for   \n195 every problem instance. Moreover, predictive models are deterministic and do not allow us to model   \n196 stochastic forward processes or express the inherent uncertainty in inverse problems.   \n197 Equivariant diffusion model. To overcome this, we draw inspiration from the inverse problem   \n198 solving capabilities of diffusion models using guidance [13]. In this case, we formulate the learning   \n199 problem as a generative modelling task of the joint distribution $p_{\\theta}(F,t,r,h)$ between 3D environment   \n200 mesh $F$ , transmitter $t$ , receiver $r$ , and channel $h$ , for a single transmitter-receiver pair. Concretely,   \n201 we follow the DDPM framework and use a Wi-GATr model as score estimator (denoising network).   \n202 By using an invariant base density and an equivariant denoising network, we define an invariant   \n203 generative model. See Appendix B for a detailed description of our diffusion model and the discussion   \n204 of some subtleties in equivariant generative modelling.   \n205 Unifying forward prediction and inverse problems as conditional sampling. A diffusion model   \n206 trained to learn the joint density $p_{\\theta}(F,t,r,h)$ does not only allow us to generate unconditional   \n207 samples of wireless scenes, but also lets us sample from various conditionals: given a partial wireless   \n208 scene, we can fill in the remaining details, in analogy to how diffusion models for images allow for   \n209 inpainting. To achieve this, we use the conditional sampling algorithm proposed by Sohl-Dickstein   \n210 et al. [48]: at each step of the sampling loop, we fix the conditioning variables to their known values   \n211 before feeding them into the denoising network.   \n212 This algorithm lets us solve signal prediction (sampling from $p_{\\theta}(h|F,t,r))$ , receiver localization   \n213 (from $\\bar{p_{\\theta}}(r|F,t,h))$ , geometry reconstruction (from $p_{\\theta}(F_{u}|F_{k},t,r,h))$ , or any other inference task   \n214 in wireless scenes. We thus unify \u201cforward\u201d and \u201cinverse\u201d modelling in a single algorithm. Each   \n215 approach is probabilistic, enabling us to model uncertainties. This is important for inverse problems,   \n216 where measurements often underspecify the solutions.   \n217 In principle, the unconditional diffusion objective should suffice to enable test-time conditional   \n218 sampling. In practice, we find that we can improve the conditional sampling performance with two   \n219 modifications. First, we combine training on the unconditional diffusion objective with conditional   \n220 diffusion objectives. For the latter, we randomly select tokens to condition on and evaluate the   \n221 diffusion loss only on the remaining tokens. Second, we provide the conditioning mask as an   \n222 additional input to the denoising model. See Appendix B for details. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/ebfc683a75a7beb81ae61e719661d46fd29fb9738c60802bb0945fa206fab2af.jpg", "img_caption": ["Figure 2: Qualitative signal prediction results. We show a single floor plan from the WiPTR test set. The black lines indicate the walls and doors, the colors show the received power as a function of the transmitter location (brighter colours mean a stronger signal). The transmitting antenna is shown as a black cross. The $z$ coordinates of transmitter and receiver are all fixed to the same height. We compare the ground-truth predictions (top left) to the predictions from different predictive models, each trained on only 100 WiPTR floor plans. Wi-GATr is able to generalize to this unseen floor plan even with such a small training set. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "223 4 New datasets ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "224 While several datasets of wireless simulations and measurements exist [3, 4, 41, 57], they either do   \n225 not include geometric information, are not diverse, are at a small scale, or the signal predictions are   \n226 not realistic. To facilitate the development of machine learning methods with a focus on geometry,   \n227 we generate two new datasets of simulated wireless scenes.2 Both feature indoor scenes and channel   \n228 information generated with a state-of-the-art ray-tracing simulator [1] at a frequency of $3.5\\:\\mathrm{GHz}$ .   \n229 They provide detailed characteristics for each path between Tx and Rx, such as gain, delay, angle   \n230 of departure and arrival at Tx/Rx, and the electric field at the receiver itself, which allows users to   \n231 compute various quantities of interest themselves. See Appendix C for more details.   \n232 Wi3R dataset. Our first dataset focuses on simplicity: each of 5000 floor plans has the same size and   \n233 number of rooms, and all walls have the same material across layouts. They differ only in their layouts,   \n234 which we take from Wi3Rooms [41], Tx positions, and Rx positions. In Appendix C we define training,   \n235 validation, and test splits as well as an out-of-distribution set to test the robustness of different models.   \n236 WiPTR dataset. Next, we generate a more varied, realistic dataset based on the floor layouts in   \n237 the ProcTHOR-10k dataset for embodied AI research [18]. We extract the 3D mesh information   \n238 including walls, windows, doors, and door frames and assign 6 different dielectric materials for   \n239 different groups of objects. Our dataset consists of $12\\mathbf{k}$ different floor layouts, split into training,   \n240 test, validation, and OOD sets as described in Appendix C. Not only does WiPTR stand out among   \n241 wireless datasets in terms of its level of detail and scale, but because it is based on ProcTHOR- $10\\mathtt{k}$ , it   \n242 is also suited for the integration with embodied AI research. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "table", "img_path": "TWfNFCOPaK/tmp/5a376c10648592dcb0459ce0db9465c7ad7e2c07edd90029fbad4977fe6c321f.jpg", "table_caption": ["Table 2: Signal prediction results. We show the mean absolute error on the received power in dBm (lower is better, best in bold). Top: In-distribution performance. Middle: Generalization under symmetry transformations. Bottom: Generalization to out-of-distribution settings. In almost all settings, Wi-GATr is the highest-fidelity surrogate model. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "243 5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "244 5.1 Predictive modelling ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "245 We focus on the prediction of the time-averaged non-coherent received power $\\begin{array}{r}{h\\;=\\;\\sum_{p}|a_{p}|^{2}}\\end{array}$ ,   \n246 disregarding delay or directional information that may be available in real measurements. We train   \n247 predictive surrogates $h_{\\theta}(F,t,r)$ that predict the power as a function of the $\\mathrm{T}\\ensuremath{\\mathbf{{x}}}$ position and orientation   \n248 $t$ , Rx position and orientation $r$ , and 3D environment mesh $F$ , on both the $\\mathtt{W i3R}$ and WiPTR datasets.   \n249 All models are trained with reciprocity augmentation, i. e., randomly filpping Tx and Rx labels during   \n250 training. This improves data efficiency slightly, especially for the transformer baseline.   \n251 In addition to our Wi-GATr model, described in Sec. 3, we train several baselines. The first is a   \n252 vanilla transformer [54], based on the same inputs and tokenization of the wireless scene, but without   \n253 the geometric inductive biases. Next, we compare to the $\\mathrm{E}(3)$ -equivariant SEGNN [8], though we   \n254 were only able to fit this model into memory for the Wi3R dataset. In addition, we train a PLViT   \n255 model, a state-of-the-art neural surrogate for wireless scenes [24] that represent wireless scenes   \n256 as an image centered around the $\\mathrm{T}\\mathbf{x}$ position. Finally, we attempt to compare Wi-GATr also to   \n257 WiNeRT [41], a neural ray tracer. However, this architecture, which was developed to be trained   \n258 on several measurements on the same floor plan, was not able to achieve useful predictions on our   \n259 diverse datasets with their focus on generalization across floor plans. Our experiment setup and the   \n260 baselines are described in detail in Appendix D.   \n261 Signal prediction. In Fig. 2 we illustrate the prediction task on a WiPTR floor plan. We show signal   \n262 predictions for the simulator as well as for surrogate models trained on only 100 floor plans. Despite   \n263 this floor plan not being part of the training set, Wi-GATr is able to capture the propagation pattern   \n264 well, while the transformer and ViT show memorization artifacts.   \n265 In Tbl. 2 we compare surrogate models trained on the full Wi3R and WiPTR datasets. Both when   \n266 interpolating Rx positions on the training floor plans as well as when evaluating on new scenes   \n267 unseen during training, Wi-GATr offers the highest-fidelity approximation of the simulator. Wi-GATr   \n268 as well as the equivariant baselines are by construction robust to symmetry transformations, while   \n269 the performance of a vanilla transformer degrades substantially. All methods but SEGNN struggle   \n270 to generalize to an OOD setting on the Wi3R dataset. This is not surprising given that the training   \n271 samples are so similar to each other. On the more diverse WiPTR dataset, Wi-GATr is almost perfectly   \n272 robust under domain shift.   \n273 Data efficiency. Next, we study the data efficiency of the different surrogates in Fig. 3. Wi-GATr is   \n274 more data-efficient than any other method with the exception of the E(3)-equivariant SEGNN, which   \n275 performs similarly well for a small number of training samples. This confirms that equivariance is a   \n276 useful inductive bias when data is scarce. But Wi-GATr scales better than SEGNN to larger number   \n277 of samples, showing that our architecture combines the small-data advantages of strong inductive   \n278 biases with the large-data advantages of a transformer architecture.   \n279 Inference speed. One of the advantages of neural surrogates is their test-time speed. Both Wi-GATr   \n280 and a transformer are over a factor of 20 faster than the ground-truth ray tracer (see Appendix D).   \n281 Receiver localization. Next, we show how differentiable surrogates let us solve inverse problems,   \n282 focusing on the problem of receiver localization. We infer the Rx position with the predictive   \n283 surrogate models by optimizing through the neural surrogate of the simulator as discussed in Sec. 3.3.   \n284 The performance of our surrogate models is shown in Fig. 4 and Appendix D.3 The two neural   \n285 surrogates achieve a similar performance when only one or two transmitters are available, a setting in   \n286 which the receiver position is highly ambiguous. With more measurements, Wi-GATr lets us localize   \n287 the transmitter more precisely. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/7af0705c285502b0fd356ed3adfbc44b12a8b61ac63466b9e4c88bab3e4980a2.jpg", "img_caption": ["Figure 3: Signal prediction. We show the mean absolute error on the received power as a function of the training data on Wi3R (left) and WiPTR (right). Wi-GATr outperforms the transformer and PLViT baselines at any amount of training data, and scales better to large data or many tokens than SEGNN. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/2d1627dad66ea32f4b937bfcb6dd7aa17d4defcfc8ba73f54fcc1a02960d40f2.jpg", "img_caption": ["Figure 4: Rx localization error, as a function of the number of Tx. Lines and error band show mean and its standard error over 240 measurements. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "288 5.2 Probabilistic modelling ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "289 Next, we experiment with our probabilistic approach. We train diffusion models on the Wi3R dataset.   \n290 In addition to a Wi-GATr model, we study a transformer baseline, as well as a transformer trained on   \n291 the same data augmented with random rotations. Both models are trained with the DDPM pipeline   \n292 with 1000 denoising steps and samples from with the DDIM solver [49]. Our setup is described in   \n293 detail in Appendix D.   \n294 Signal prediction, receiver localization, and geometry reconstruction as conditional sampling.   \n295 In our probabilistic approach, signal prediction, receiver localization, and geometry reconstruction   \n296 are all instances of sampling from conditional densities: $h\\sim p_{\\theta}(h|F,t,r)$ , $r\\sim\\dot{p_{\\theta}}(r|F,t,h)$ , and   \n297 $F_{u}\\,\\sim\\,p_{\\theta}(F_{u}|F_{k},t,r,h)$ , respectively. We qualitatively show results for this approach in Figs. 1   \n298 and 5. All of these predictions are probabilistic, which allows our model to express uncertainty in   \n299 ambiguous inference tasks. When inferring Rx positions from a single measurement, the model learns   \n300 multimodal densities, as shown in the middle of Fig. 5. When reconstructing geometry, the model   \n301 will sample diverse floor plans as long as they are consistent with the transmitted signal, see the right   \n302 panel of Fig. 5. Additional results on signal and geometry prediction are given in Appendix D.2.   \n303 We quantitatively evaluate these mod  \n304 els through the variational lower bound   \n305 on the log likelihood of test data under   \n306 the model. To further analyze the ef  \n307 fects of equivariance, we test the model   \n308 both on canonicalized scenes, in which   \n309 all walls are aligned with the $x$ and $y$   \n310 axis, and scenes that are arbitrarily ro  \n311 tated. The results in Tbl. 3 show that   \n312 Wi-GATr outperforms the transformer   \n313 baseline across all three tasks, even in   \n314 the canonicalized setting or when the   \n315 transformer is trained with data augmen  \n316 tation. The gains of Wi-GATr are partic  \n317 ularly clear on the signal prediction and   \n318 receiver localization problems. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/d6bf07e7893a4c92369c7527ed82395ebfc342f16e5d7403e03c3f0a94b28191.jpg", "img_caption": ["Figure 5: Probabilistic modelling. We formulate various tasks as sampling from the unconditional or conditional densities of a single diffusion model. (a): Unconditional sampling of wireless scenes $p(F,t,r,h)$ . (b): Receiver localization as conditional sampling from $p(r|F,t,h)$ for two different values of $h$ and $r$ . (c): Geometry reconstruction as conditional sampling from $p(F_{u}|F_{k},t,r,h)$ for two different values of $h$ , keeping $t,r.$ , $F_{k}$ fixed. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "table", "img_path": "TWfNFCOPaK/tmp/91a2e0ecc2b0e52f5c45f6e861475f77bc1209f6eafc3ee0fdfc0bdb7839f189.jpg", "table_caption": ["Table 3: Probabilistic modelling results. We show variational upper bounds on the negative log likelihood for different conditional inference tasks (lower is better, best in bold). "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "319 6 Discussion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "320 Wireless signal transmission through electromagnetic wave propagation is an inherently geometric and   \n321 symmetric problem. We developed a class of neural surrogates grounded in geometric representations   \n322 and strong inductive biases. They are based on our new Wi-GATr backbone architecture, consisting   \n323 of a new tokenization scheme for wireless scenes together with an E(3)-equivariant transformer   \n324 architecture. The proposed backbone is applied in two ways to wireless tasks: first, as a differentiable   \n325 \u201cforward\u201d prediction model that maps the features to the signals; second, as a probabilistic diffusion   \n326 model that captures the joint and conditional distributions of features and channels. We employed   \n327 these designs in experiments on received power prediction, receiver localization, and geometry   \n328 reconstruction, where our Wi-GATr models enabled precise predictions, outperforming various   \n329 baselines.   \n330 Our analysis is in many ways a first step. The range of materials in our datasets is limited and we only   \n331 experimented with measurements of the non-coherent total received power, which is a stable signal,   \n332 but offers less spatial information than measurements of the time delay or angular information. More   \n333 importantly, we only considered idealized inference tasks. For instance, our receiver localization   \n334 problem assumed perfect knowledge of the room geometry and materials.   \n335 Nevertheless, we hope that we were able to highlight the benefits of a geometric treatment of wave   \n336 propagation modelling. Augmenting or replacing the image-based or general-purpose representations   \n337 and architectures prevalent in wireless modelling with geometric approaches has the potential of   \n338 improving data efficiency, performance, and robustness. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "339 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "340 [1] Remcom Wireless InSite\u00ae. https://www.remcom.com/wireless-insite-propagation  \n341 software. [Accessed 10-05-2024]. (Cited on pages 3 and 6)   \n342 [2] 3GPP TR 38.901. Study on channel model for frequencies from 0.5 to 100 ghz. Standard, 3GPP,   \n343 Valbonne, FR, March 2022. (Cited on page 3)   \n344 [3] A. Alkhateeb. DeepMIMO: A generic deep learning dataset for millimeter wave and massive   \n345 MIMO applications. In ITA, 2019. (Cited on page 6)   \n346 [4] Ahmed Alkhateeb, Gouranga Charan, Tawfik Osman, Andrew Hredzak, Joao Morais, Umut   \n347 Demirhan, and Nikhil Srinivas. Deepsense 6g: A large-scale real-world multi-modal sensing   \n348 and communication dataset. IEEE Communications Magazine, 2023. (Cited on page 6)   \n349 [5] Nicolas Amiot, Mohamed Laaraiedh, and Bernard Uguen. Pylayers: An open source dynamic   \n350 simulator for indoor propagation and localization. In ICC, 2013. (Cited on page 3)   \n351 [6] Stefanos Bakirtzis, Kehai Qiu, Jie Zhang, and Ian Wassell. DeepRay: Deep Learning Meets   \n352 Ray-Tracing. In EuCAP, 2022. (Cited on page 1)   \n353 [7] Johannes Brandstetter, Rianne van den Berg, Max Welling, and Jayesh K Gupta. Clifford neural   \n354 layers for PDE modeling. arXiv:2209.04934, 2022. (Cited on page 8)   \n355 [8] Johannes Brandstetter, Rob Hesselink, Elise van der Pol, Erik J Bekkers, and Max Welling.   \n356 Geometric and physical quantities improve E(3) equivariant message passing. In ICLR, 2022.   \n357 (Cited on pages 7 and 21)   \n358 [9] Johann Brehmer, Pim de Haan, S\u00f6nke Behrends, and Taco Cohen. Geometric Algebra Trans  \n359 former. In NeurIPS, 2023. (Cited on pages 2, 3, 5, 19, and 20)   \n360 [10] Johann Brehmer, Joey Bose, Pim De Haan, and Taco S Cohen. Edgi: Equivariant diffusion for   \n361 planning with embodied agents. NeurIPS, 2024. (Cited on page 3)   \n362 [11] Michael M Bronstein, Joan Bruna, Taco Cohen, and Petar Velic\u02c7kovic\u00b4. Geometric deep learning:   \n363 Grids, groups, graphs, geodesics, and gauges. 2021. (Cited on page 3)   \n364 [12] Wanshi Chen, Peter Gaal, Juan Montojo, and Haris Zisimopoulos. Fundamentals of 5G   \n365 communications: connectivity for enhanced mobile broadband and beyond. McGraw-Hill, New   \n366 York, 2021. (Cited on page 1)   \n367 [13] Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L Klasky, and Jong Chul Ye.   \n368 Diffusion posterior sampling for general noisy inverse problems. arXiv:2209.14687, 2022.   \n369 (Cited on pages 3 and 5)   \n370 [14] William Kingdon Clifford. Applications of Grassmann\u2019s Extensive Algebra. Amer. J. Math., 1   \n371 (4):350\u2013358, 1878. (Cited on page 3)   \n372 [15] Taco Cohen. Equivariant Convolutional Networks. PhD thesis, University of Amsterdam, 2021.   \n373 (Cited on page 3)   \n374 [16] Erik Dahlman, Stefan Parkvall, and Johan Skold. 5G NR: The Next Generation Wireless Access   \n375 Technology. Elsevier Science, October 2020. (Cited on page 1)   \n376 [17] Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher R\u00e9. FlashAttention: Fast and   \n377 memory-efficient exact attention with IO-awareness. NeurIPS, 2022. (Cited on page 3)   \n378 [18] Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana Ehsani, Winson   \n379 Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, and Roozbeh Mottaghi. ProcTHOR: Large  \n380 Scale Embodied AI Using Procedural Generation. In NeurIPS, 2022. (Cited on pages 7 and 20)   \n381 [19] Sebastian D\u00f6rner, Marcus Henninger, Sebastian Cammerer, and Stephan ten Brink. Wgan-based   \n382 autoencoder training over-the-air. In SPAWC, 2020. (Cited on page 3)   \n383 [20] Leo Dorst. A guided tour to the plane-based geometric algebra pga. 2020. URL https:   \n384 //geometricalgebra.org/downloads/PGA4CS.pdf. (Cited on pages 3 and 19)   \n385 [21] Yilun Du, Conor Durkan, Robin Strudel, Joshua B Tenenbaum, Sander Dieleman, Rob Fergus,   \n386 Jascha Sohl-Dickstein, Arnaud Doucet, and Will Sussman Grathwohl. Reduce, reuse, recycle:   \n387 Compositional generation with energy-based diffusion models and mcmc. In ICML, 2023.   \n388 (Cited on page 23)   \n389 [22] Hermann Grassmann. Die lineale Ausdehnungslehre. Otto Wigand, Leipzig, 1844. (Cited on   \n390 page 3)   \n391 [23] Ankit Gupta, Jinfeng Du, Dmitry Chizhik, Reinaldo A Valenzuela, and Mathini Sellathurai. Ma  \n392 chine learning-based urban canyon path loss prediction using 28 ghz manhattan measurements.   \n393 IEEE Transactions on Antennas and Propagation, 2022. (Cited on page 1)   \n394 [24] Thomas M Hehn, Tribhuvanesh Orekondy, Ori Shental, Arash Behboodi, Juan Bucheli, Akash   \n395 Doshi, June Namgoong, Taesang Yoo, Ashwin Sampath, and Joseph B Soriaga. Transformer  \n396 based neural surrogate for link-level path loss prediction from variable-sized maps. In IEEE   \n397 Globecom, 2023. (Cited on pages 7, 8, and 21)   \n398 [25] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. NeurIPS,   \n399 2020. (Cited on pages 3 and 19)   \n400 [26] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko,   \n401 Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. Imagen video: High   \n402 definition video generation with diffusion models. arXiv:2210.02303, 2022. (Cited on page 3)   \n403 [27] Emiel Hoogeboom, V\u0131ctor Garcia Satorras, Cl\u00e9ment Vignac, and Max Welling. Equivariant   \n404 diffusion for molecule generation in 3d. In ICML, 2022. (Cited on pages 3 and 20)   \n405 [28] Sepidehsadat Sepid Hossieni, Mohammad Amin Shabani, Saghar Irandoust, and Yasutaka   \n406 Furukawa. Puzzlefusion: Unleashing the power of diffusion models for spatial puzzle solving.   \n407 NeurIPS, 2024. (Cited on page 3)   \n408 [29] Jakob Hoydis, Sebastian Cammerer, Fay\u00e7al Ait Aoudia, Avinash Vem, Nikolaus Binder,   \n409 Guillermo Marcus, and Alexander Keller. Sionna: An open-source library for next-generation   \n410 physical layer research. arXiv, 2022. (Cited on pages 1 and 3)   \n411 [30] Michael Janner, Yilun Du, Joshua B Tenenbaum, and Sergey Levine. Planning with diffusion   \n412 for flexible behavior synthesis. arXiv:2205.09991, 2022. (Cited on page 3)   \n413 [31] Joseph B Keller. Geometrical theory of diffraction. J. Opt. Soc. Am., JOSA. (Cited on page 2)   \n414 [32] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. ICLR, 2014. (Cited on   \n415 page 19)   \n416 [33] Jonas K\u00f6hler, Leon Klein, and Frank No\u00e9. Equivariant flows: exact likelihood generative   \n417 learning for symmetric densities. In ICML, 2020. (Cited on pages 3 and 20)   \n418 [34] JunG-Yong Lee, Min Young Kang, and Seong-Cheol Kim. Path Loss Exponent Prediction for   \n419 Outdoor Millimeter Wave Channels through Deep Learning. In WCNC, 2019. (Cited on page 1)   \n420 [35] Ron Levie, \u00c7a\u02d8gkan Yapar, Gitta Kutyniok, and Giuseppe Caire. Radiounet: Fast radio map   \n421 estimation with convolutional neural networks. IEEE TWC, 2021. (Cited on page 1)   \n422 [36] Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc   \n423 Van Gool. Repaint: Inpainting using denoising diffusion probabilistic models. In CVPR, 2022.   \n424 (Cited on page 3)   \n425 [37] T L Marzetta and B M Hochwald. Fast transfer of channel state information in wireless systems.   \n426 IEEE Transactions on Signal Processing, 2006. (Cited on page 3)   \n427 [38] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi,   \n428 and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. In ECCV,   \n429 2020. (Cited on page 3)   \n430 [39] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic   \n431 models. In ICML, 2021. (Cited on page 23)   \n432 [40] Tribhuvanesh Orekondy, Arash Behboodi, and Joseph B Soriaga. Mimo-gan: Generative mimo   \n433 channel modeling. In ICC, 2022. (Cited on page 3)   \n434 [41] Tribhuvanesh Orekondy, Pratik Kumar, Shreya Kadambi, Hao Ye, Joseph Soriaga, and Arash   \n435 Behboodi. Winert: Towards neural ray tracing for wireless channel modelling and differentiable   \n436 simulations. In ICLR, 2022. (Cited on pages 3, 6, 7, and 20)   \n437 [42] Timothy J O\u2019Shea, Tamoghna Roy, and Nathan West. Approximating the void: Learning   \n438 stochastic channel models from observation with variational generative adversarial networks. In   \n439 ICNC, 2019. (Cited on page 3)   \n440 [43] William Peebles and Saining Xie. Scalable diffusion models with transformers.   \n441 arXiv:2212.09748, 2022. (Cited on pages 20 and 23)   \n442 [44] Kehai Qiu, Stefanos Bakirtzis, Hui Song, Jie Zhang, and Ian Wassell. Pseudo Ray-Tracing: Deep   \n443 Leaning Assisted Outdoor mm-Wave Path Loss Prediction. IEEE Wireless Communications   \n444 Letters, 2022. (Cited on page 1)   \n445 [45] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text  \n446 conditional image generation with clip latents. arXiv:2204.06125, 1(2):3, 2022. (Cited on page 3)   \n447 [46] Vishnu V Ratnam, Hao Chen, Sameer Pawar, Bingwen Zhang, Charlie Jianzhong Zhang, Young  \n448 Jin Kim, Soonyoung Lee, Minsung Cho, and Sung-Rok Yoon. Fadenet: Deep learning-based   \n449 mm-wave large-scale channel fading prediction and its applications. IEEE Access, 2020. (Cited   \n450 on page 1)   \n451 [47] David Ruhe, Jayesh K Gupta, Steven de Keninck, Max Welling, and Johannes Brandstetter.   \n452 Geometric clifford algebra networks. In ICLR, 2023. (Cited on page 19)   \n453 [48] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsuper  \n454 vised learning using nonequilibrium thermodynamics. In ICML, 2015. (Cited on pages 3 and 6)   \n455 [49] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. ICLR,   \n456 2021. (Cited on page 8)   \n457 [50] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and   \n458 Ben Poole. Score-based generative modeling through stochastic differential equations. ICLR,   \n459 2021. (Cited on pages 3 and 19)   \n460 [51] Marco Sousa, Pedro Vieira, Maria Paula Queluz, and Ant\u00f3nio Rodrigues. An Ubiquitous 2.6   \n461 GHz Radio Propagation Model for Wireless Networks using Self-Supervised Learning from   \n462 Satellite Images. IEEE Access, 2022. (Cited on page 1)   \n463 [52] Yu Tian, Shuai Yuan, Weisheng Chen, and Naijin Liu. Transformer based radio map prediction   \n464 model for dense urban environments. In ISAPE, 2021. (Cited on page 1)   \n465 [53] David Tse and Pramod Viswanath. Fundamentals of wireless communication. Cambridge   \n466 university press, 2005. (Cited on page 3)   \n467 [54] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,   \n468 \u0141ukasz Kaiser, and Illia Polosukhin. Attention Is All You Need. NeurIPS, 2017. (Cited on   \n469 pages 3 and 7)   \n470 [55] Pascal Vincent. A Connection Between Score Matching and Denoising Autoencoders. Neural   \n471 computation, 23(7):1661\u20131674, 2011. (Cited on page 19)   \n472 [56] Hao Ye, Geoffrey Ye Li, Biing-Hwang Fred Juang, and Kathiravetpillai Sivanesan. Channel   \n473 Agnostic End-to-End Learning Based Communication Systems with Conditional GAN. In   \n474 IEEE Globecom Workshops, 2018. (Cited on page 3)   \n475 [57] Lihao Zhang, Haijian Sun, Jin Sun, and Rose Qingyang Hu. WiSegRT: Dataset for Site-specific   \n476 Indoor Radio Propagation Modeling with 3D Segmentation and Differentiable Ray-Tracing.   \n477 arXiv:2312.11245, 2023. (Cited on page 6)   \n478 [58] Xiaopeng Zhao, Zhenlin An, Qingrui Pan, and Lei Yang. NeRF2: Neural Radio-Frequency   \n479 Radiance Fields. In ACM MobiCom, 2023. (Cited on page 3) ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "480 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "1. Claims Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? Answer: [Yes] Justification: Our methods are explained in Sec. 3, the datasets in Sec. 4, and the experiments in Sec. 5. Guidelines: \u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper. \u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. \u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 12}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Justification: We discuss the main limitations of our work in Sec. 6 and throughout the paper.   \nGuidelines: \u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper. \u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. \u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. \u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. \u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. \u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 12}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and   \na complete (and correct) proof?   \nAnswer: [NA]   \nJustification: Our paper does not include theoretical results.   \nGuidelines: \u2022 The answer NA means that the paper does not include theoretical results. \u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems. ", "page_idx": 12}, {"type": "text", "text": "\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. \u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 13}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?   \nAnswer: [Yes]   \nJustification: See Appendix D.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "538   \n539   \n540   \n541   \n542   \n543   \n544   \n545   \n546   \n547   \n548   \n549   \n550   \n551   \n552   \n553   \n554   \n555   \n556   \n557   \n558   \n559   \n560   \n561   \n562   \n563   \n564   \n565   \n566   \n567   \n568   \n569   \n570   \n571   \n572   \n573   \n574   \n575   \n576   \n577   \n578   \n579   \n580   \n581   \n582   \n583   \n584   \n585   \n586   \n587   \n588   \n589   \n590   \n591   \n592   \n593   \n594   \n595   \n596 ", "page_idx": 13}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 13}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that paper does not include experiments requiring code. \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. \u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). \u2022 The instructions should contain the exact command and environment needed to run ", "page_idx": 13}, {"type": "text", "text": "to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 14}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [No]   \nJustification: In the main paper, we provide all experimental details we have found to be relevant to comprehend our results and support our claims. All other details are either found in the appendices or are included in the data and code release that is being prepared. Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 14}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate   \ninformation about the statistical significance of the experiments?   \nAnswer: [No] ", "page_idx": 14}, {"type": "text", "text": "597   \n598   \n599   \n600   \n601   \n602   \n603   \n604   \n605   \n606   \n607   \n608   \n609   \n610   \n611   \n612   \n613   \n614   \n615   \n616   \n617   \n618   \n619   \n620   \n621   \n622   \n623   \n624   \n625   \n626   \n627   \n628   \n629   \n630   \n631   \n632   \n633   \n634   \n635   \n636   \n637   \n638   \n639   \n640   \n641   \n642   \n643   \n644   \n645   \n646   \n647   \n648   \n649   \n650   \n651   \n652   \n653   \n654   \n655 ", "page_idx": 14}, {"type": "text", "text": "Justification: We provide an estimate of epistemic uncertainties for some of our experiments. Due to compute restrictions, we were not able to provide meaningful estimates of epistemic uncertainties for the other experiments yet.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?   \nAnswer: [No]   \nJustification: Our models and experiments are all at at a sufficiently small scale that they can be run on a single GPU and a few days. ", "page_idx": 14}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not include experiments. \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. \u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. \u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 15}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the   \nNeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \nAnswer: [Yes]   \nJustification: We conform in every aspect with the Code of Ethics.   \nGuidelines: \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. \u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 15}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative   \nsocietal impacts of the work performed?   \nAnswer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. \u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. \u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. \u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 15}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 15}, {"type": "text", "text": "Answer: [NA]   \nJustification: We do not anticipate such a risk.   \nGuidelines: \u2022 The answer NA means that the paper poses no such risks. \u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?   \nAnswer: [Yes]   \nJustification: All external assets are cited properly. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset. \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. \u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. \u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. \u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 16}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation   \nprovided alongside the assets?   \nAnswer: [No]   \nJustification: We are preparing the release of our datasets and their documentation.   \nGuidelines: \u2022 The answer NA means that the paper does not release new assets. \u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. \u2022 The paper should discuss whether and how consent was obtained from people whose asset is used. \u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 16}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 16}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 16}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 16}, {"type": "text", "text": "74 Question: Does the paper describe potential risks incurred by study participants, whether   \n75 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n76 approvals (or an equivalent approval/review based on the requirements of your country or   \n7 institution) were obtained?   \n78 Answer: [NA]   \n79 Justification: The paper does not involve crowdsourcing nor research with human subjects.   \n80 Guidelines:   \n81 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research   \n82 with human subjects.   \n83 \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent)   \n84 may be required for any human subjects research. If you obtained IRB approval, you   \n85 should clearly state this in the paper.   \n86 \u2022 We recognize that the procedures for this may vary significantly between institutions   \n87 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n88 guidelines for their institution.   \n89 \u2022 For initial submissions, do not include any information that would break anonymity   \n90 (if applicable), such as the institution conducting the review. ", "page_idx": 17}, {"type": "text", "text": "791 A Geometric algebra ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "792 As representation, Wi-GATr uses the projective geometric algebra $\\mathbb{G}_{3,0,1}$ . Here we summarize key   \n793 aspects of this algebra and define the canonical embedding of geometric primitives in it. For a precise   \n794 definition and pedagogical introduction, we refer the reader to Dorst [20].   \n795 Geometric algebra. A geometric algebra $\\mathbb{G}_{p,q,r}$ consists of a vector space together with a bilinear   \n796 operation, the geometric product, that maps two elements of the vector space to another element of   \n797 the vector space.   \n798 The elements of the vector space are known as multivectors. Their space is constructed by extending   \n799 a base vector space $\\mathbb{R}^{d}$ to lower orders (scalars) and higher-orders (bi-vectors, tri-vectors, . .. ). The   \n800 algebra combines all of these orders (or grades) in one $2^{d}$ -dimensional vector space. From a basis   \n801 for the base space, for instance $(e_{1},e_{2},e_{3})$ , one can construct a basis for the multivector space. A   \n802 multivector expressed in that basis then reads, for instance for $d=3$ , $x=x_{\\emptyset}+x_{1}e_{1}+x_{2}e_{2}+x_{3}e_{3}+$   \n803 $x_{12}e_{1}e_{2}+x_{13}e_{1}e_{3}+x_{23}e_{2}e_{3}+x_{123}e_{1}e_{2}e_{3}.$ .   \n804 The geometric product is fully defined by bilinearity, associativity, and the condition that the geometric   \n805 product of a vector with itself is equal to its norm. The geometric product generally maps between   \n806 different grades. For instance, the geometric product of two vectors will consist of a scalar, the inner   \n807 product between the vectors, and a bivector, which is related to the cross-product of $\\mathbb{R}^{3}$ . In particular,   \n808 the conventional basis elements of grade $k>1$ are constructed as the geometric product of the vector   \n809 basis elements $e_{i}$ . For instance, $e_{12}\\,=\\,e_{1}e_{2}$ is a basis bivector. From the defining properties of   \n810 the geometric products it follows that the geometric product between orthogonal basis elements is   \n811 antisymmetric, $e_{i}e_{j}=-e_{j}e_{i}$ . Thus, for a $d_{\\cdot}$ -dimensional basis space, there are $\\binom{d}{k}$ independent basis   \n812 elements at grade $k$ .   \n813 Projective geometric algebra. To represent three-dimensional objects including absolute positions,   \n814 we use a geometric algebra based on a base space with $d=4$ , adding a homogeneous coordinate   \n815 to the 3D space.4 We use a basis $(e_{0},e_{1},e_{2},e_{3})$ with a metric such that $e_{0}^{2}\\,=\\,0$ and $e_{i}^{2}\\,=\\,1$ for   \n816 $i\\,=\\,1,2,3$ . The multivector space is thus $2^{4}\\,=\\,16$ -dimensional. This algebra is known as the   \n817 projective geometric algebra $\\mathbb{G}_{3,0,1}$ .   \n818 Canonical embedding of geometric primitives. In $\\mathbb{G}_{3,0,1}$ , we can represent geometric primitives   \n819 as follows:   \n820 \u2022 Scalars (data that do not transform under translation, rotations, and reflections) are represented   \n821 as the scalars of the multivectors (grade $k=0$ ).   \n822 \u2022 Oriented planes are represented as vectors ( $k=1$ ), encoding the plane normal as well as the   \n823 distance from the origin.   \n824 \u2022 Lines or directions are represented as bivectors $\\mathit{\\Delta}k=2$ ), encoding the direction as well as the   \n825 shift from the origin.   \n826 \u2022 Points or positions are represented as trivectors $\\mathit{\\Delta}k=3$ ). ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "827 For more details, we refer the reader to Tbl. 1 in Brehmer et al. [9], or to Dorst [20]. ", "page_idx": 18}, {"type": "text", "text": "828 B Probabilistic model ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "829 Formally, we employ the standard DDPM framework [50] to train a latent variable model   \n830 $\\begin{array}{r}{p_{\\theta}(\\mathbf{x}_{0})\\ =\\ \\int p_{\\theta}(\\bar{\\mathbf{x}_{0:T}})d_{\\mathbf{x}_{1:T}}}\\end{array}$ , where $\\mathbf{x}_{0}\\;=\\;[r s r p,\\mathbf{tx},\\mathbf{rx},\\mathbf{mesh}]$ denotes the joint vector of vari  \n831 ables following the dataset distribution $p_{d a t a}(\\mathbf{x}_{0})$ . In DDPM, the latent variables $\\mathbf{x}_{1:T}$ are   \n832 noisy ve\u221arsions of the original data, defined by a discrete forward noise process $q(\\mathbf{x}_{t}|\\mathbf{x}_{t-1})\\;=\\;$   \n833 $\\mathcal{N}\\left(\\mathbf{x}_{t};\\sqrt{1-\\beta_{t}}\\mathbf{x}_{t-1},\\beta_{t}\\mathbf{I}\\right)$ and $\\beta_{i}\\,>\\,0$ . We approximate the reverse distribution $q(\\mathbf{x}_{t-1}\\mathbf{x}_{t})$ with   \n834 $\\begin{array}{r}{p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t})=\\sum_{\\hat{\\mathbf{x}}_{0}}q(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\hat{\\mathbf{x}}_{0})p_{\\theta}(\\hat{\\mathbf{x}}_{0}|\\mathbf{x}_{t},t)}\\end{array}$ , where $q(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0})$ is a normal distribution with   \n835 closed-form par ameters [25]. The forward and backward distributions $q$ and $p$ form a variational auto  \n836 encoder [32] which can be trained with a variational lower bound loss. Using the above parametriza  \n837 tion of $p_{\\theta}(\\mathbf{x}_{t-1}\\vert\\mathbf{x}_{t})$ , however, allows for a simple approximation of this lower bound by training on   \n838 an MSE objective $\\mathcal{L}=\\mathbb{E}_{\\mathbf{x}_{t},\\mathbf{x}_{0}}\\left[||f_{\\theta}(\\mathbf{x}_{t},t)-\\mathbf{x}_{0}||^{2}\\right]$ which resembles denoising score matching [55].   \n839 To parametrize $p_{\\theta}(\\hat{\\mathbf{x}}_{0}|\\mathbf{x}_{t},t)$ , we pass the raw representation of $\\mathbf{x}_{t}$ through the wireless GA tokenizer   \n840 of Wi-GATr and, additionally, we embed the scalar $t$ through a learned timestep embedding [43]. The   \n841 embedded timesteps can then be concatenated along the scalar channels in the GA representation in   \n842 a straightforward manner. Similar to GATr [9], the neural network outputs a prediction in the GA   \n843 representation, which is subsequently converted to the original latent space. Note that this possibly   \n844 simplifies the learning problem, as the GA representation is inherently higher dimensional than our   \n845 diffusion space with the same dimensionality as $\\mathbf{x}_{\\mathrm{0}}$ .   \n846 Equivariant generative modelling. A diffusion model with an invariant base density and an   \n847 equivariant denoising network defines an invariant density, but equivariant generative modelling has   \n848 some subtleties [33]. Because the group of translations is not compact, we cannot define a translation  \n849 invariant base density. Previous works have circumvented this issue by performing diffusion in the   \n850 zero center of gravity subspace of euclidean space [27]. However, we found that directly providing   \n851 the origin as an additional input to the denoising network also resulted in good performance, at the   \n852 cost of full E(3) equivariance. We also choose to generate samples in the convention where the $z$ -   \n853 axis represents the direction of gravity and positive $z$ is \u201cup\u201d; we therefore provide this direction of   \n854 gravity as an additional input to our network.   \n855 Masking strategies. To improve the performance of conditional sampling, we randomly sample   \n856 conditioning masks during training which act as an input to the model, as well as a mask on   \n857 the loss terms. Namely, we sample masks from a discrete distribution with probabilities $p=$   \n858 $(0.2,0.3,0.2,0.3)$ corresponding to masks for unconditional, signal, receiver and mesh prediction   \n859 respectively. If we denote this distribution over masks as $p(m)$ , the modified loss function then   \n860 reads as $\\mathcal{L}=\\mathbb{E}_{\\mathbf{m}\\sim p(\\mathbf{m}),\\mathbf{x}_{t},\\mathbf{x}_{0}}\\left[||\\mathbf{m}\\odot f_{\\theta}(\\mathbf{x}_{t}^{\\mathbf{m}},t,\\mathbf{m})-\\mathbf{m}\\odot\\mathbf{x}_{0}||^{2}\\right]$ , where $\\mathbf{x}_{t}^{\\mathbf{m}}$ is equal to $\\mathbf{x}_{\\mathrm{0}}$ along   \n861 the masked tokens according to $\\mathbf{m}$ . ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "862 C Datasets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "863 Table 4 summarizes major characteristics of the two datasets. In the following we explain more   \n864 details on data splits and generation.   \n865 Wi3R dataset. Based on the layouts of the Wi3Rooms dataset by Orekondy et al. [41], we run   \n866 simulations for 5000 floor layouts that are split into training (4500), validation (250), and test (250).   \n867 These validation and test splits thus represent generalization across unseen layouts, transmitter, and   \n868 receiver locations. From the training set, we keep $10\\,\\mathrm{Rx}$ locations as additional test set to evaluate   \n869 generalization only across unseen $\\mathbf{R}\\mathbf{x}$ locations. To evaluate the generalization performance, we also   \n870 introduce an out-of-distribution (OOD) set that features four rooms in each of the 250 floor layouts.   \n871 In all layouts, the interior walls are made of brick while exterior walls are made of concrete. The The   \n872 Tx and Rx locations are sampled uniformly within the bounds of the floor layouts $\\mathrm{10m}\\times\\mathrm{5m}\\times3\\mathrm{m})$ .   \n873 WiPTR dataset. Based on the floor layouts in the ProcTHOR-10k dataset for embodied AI re  \n874 search [18], we extract the 3D mesh information including walls, windows, doors, and door frames.   \n875 The layouts comprise between 1 to 10 rooms and can cover up to $600\\;\\mathrm{{m}^{2}}$ . We assign 6 different   \n876 dielectric materials for different groups of objects (see Tbl. 5). The 3D Tx and $\\mathbf{R}\\mathbf{x}$ locations are ran  \n877 domly sampled within the bounds of the layout. The training data comprises 10k floor layouts, while   \n878 test and validation sets each contain 1k unseen layouts, Tx, and Rx locations. Again, we introduce an   \n879 OOD validation set with 5 layouts where we manually remove parts of the walls such that two rooms   \n880 become connected. While the multi-modality in combination with the ProcTHOR dataset enables   \n881 further research for joint sensing and communication in wireless, our dataset set is also, to the best of   \n882 our knowledge, the first large-scale 3D wireless indoor datasets suitable for embodied AI research. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "883 D Experiments ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "884 D.1 Predictive modelling ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "885 Models. We use an Wi-GATr model that is 32 blocks deep and 16 multivector channels in addition   \n886 to 32 additional scalar channels wide. We use 8 attention heads and multi-query attention. Overall,   \n887 the model has $1.6\\cdot10^{7}$ parameters. These settings were selected by comparing five differently sized   \n888 networks on an earlier version of the Wi3R dataset, though somewhat smaller and bigger networks ", "page_idx": 19}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/6c22a2f986142b409427ac677c0c3b7fc22da81bac4627c5680f77e0ccfe1a10.jpg", "img_caption": ["Figure 6: Rx localization error, as a function of the number of Tx. Lines and error band show mean and its standard error over 240 measurements. "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "889 achieved a similar performance. ", "page_idx": 20}, {"type": "text", "text": "890 Our Transformer model has the same width (translating to 288 channels) and depth as the Wi-GATr   \n891 model, totalling $16.7\\cdot10^{6}$ parameters. These hyperparameters were independently selected by   \n892 comparing five differently sized networks on an earlier version of the Wi3R dataset.   \n893 For SEGNN, we use representations of up to max $\\ell_{\\mathrm{max}}=3$ , 8 layers, and 128 hidden features. The model   \n894 has $2.6\\cdot10^{5}$ parameters. We selected these parameters in a scan over all three parameters, within the   \n895 ranges used in Brandstetter et al. [8].   \n896 The PLViT model is based on the approach introduced by Hehn et al. [24]. We employ the same   \n897 centering and rotation strategy as in the original approach around the Tx. Further, we extend the   \n898 original approach to 3 dimensions by providing the difference in $z$ -direction concatenated with the   \n899 2D $x{-}y$ -distance as one token. Since training from scratch resulted in poor performance, we finetuned   \n900 a ViT-B-16 model pretrained on ImageNet and keeping only the red channel. This resulted in a model   \n901 with $85.4\\cdot10^{7}$ parameters and also required us to use a fixed image size for each dataset that ensures   \n902 the entire floor layout is visible in the image data.   \n903 Optimization. All models are trained on the mean squared error between the model output and   \n904 the total received power in dBm. We use a batch size of 64 (unless for SEGNN, where we use a   \n905 smaller batch size due to memory limitations), the Adam optimizer, an initial learning rate of $10^{-3}$ ,   \n906 and a cosine annealing scheduler. Models are trained for $\\dot{5}\\cdot10^{5}$ steps on the Wi3R dataset and for   \n907 $2\\cdot10^{5}$ steps on the WiPTR dataset.   \n908 Inference speed. To quantify the trade-off between inference speed and accuracy of signal prediction,   \n909 we compare the ray tracing simulation with our machine learning approaches. For this purpose, we   \n910 evaluate the methods on a single room of the validation set with 2 different $\\mathbf{T}\\mathbf{X}$ locations and two   \n911 equidistant grids at $z\\in\\{2.3,0.3\\}$ with each $1637\\;\\mathrm{Rx}$ locations. Figure 7 summarizes the average   \n912 inference times per link with the corresponding standard deviation. While Wireless InSite $(6/3/1$ ,   \n913 i.e., 6 reflections/3 transmissions/1 diffraction) represents our method that was used to generate the   \n914 ground truth data, it is also by far the slowest approach. Note that we only measure the inference   \n915 speed of Wireless InSite for each Tx individually without the preprocessing of the geometry. By   \n916 reducing the complexity, e.g., reducing the number of allowed reflections or transmissions, of the ray   \n917 tracing simulation the inference time can be reduced significantly. For example, the configuration   \n918 $3/2/1$ shows a significant increase in inference speed, but at the same time we can already see that the   \n919 simulation results do not match the ground truth anymore. This effect is even more pronounced for the   \n920 case of Wireless InSite $3/1/1$ . Our machine learning solutions outperform all tested configurations of   \n921 Wireless InSite in terms of inference speed, while at the same time keeping competitive performance   \n922 in terms of prediction accuracy (MAE) compared to the data generation simulation itself in a simpler   \n923 configuration setting.   \n924 In addition, the differentiability of ML approches enables them to solve inverse problems and such   \n925 as finetuning to real-world measurement data. Finetuning, often referred to as calibration, remains   \n926 challenging for simulation software and will likely lead to increased MAE as the ground truth is not   \n927 given by Wireless InSite itself anymore. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "table", "img_path": "TWfNFCOPaK/tmp/ff20645e1bacd77468220bba7b85600e0d185281d1ed7f27387e9a0643b536de.jpg", "table_caption": ["Table 4: Dataset details and simulation settings for dataset generation. "], "table_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/2ce083f34a11d037c400988ae84947705ffcce58603d472f935485a0a35f1f28.jpg", "img_caption": ["Figure 7: Inference wall time vs signal prediction error per $\\mathrm{Tx}/\\mathrm{Rx}$ prediction on the first room of the WiPTR validation set. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "928 D.2 Probabilistic modelling ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "929 Experiment setup. For all conditional samples involving $p(F_{u}|F_{k},t,r,h)$ , we always choose   \n930 to set $F_{k}$ to be the floor and ceiling mesh faces only and $F_{u}$ to be the remaining geometry. This   \n931 amounts to completely predicting the exterior walls, as well as the separating walls/doors of the three   \n932 rooms, whereas the conditioning on $F_{k}$ acts only as a mean to break equivariance. Since $F$ is always   \n933 canonicalized in the non-augmented training dataset, this allows for direct comparison of variational   \n934 lower bounds in Tbl. 3 with the non-equivariant transformer baseline.   \n935 Models. For both Wi-GATr and the transformer baseline, we follow similar architecture choices as   \n936 for the predictive models, using an equal amount of attention layers. To make the models timestep  \n937 dependent, we additionally employ a standard learnable timestep embedding commonly used in ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "table", "img_path": "TWfNFCOPaK/tmp/c045e02e72af3c7303a246696a6f27c14e49f41fbef45f4d67e0ca64f03eb529.jpg", "table_caption": ["Table 5: Dielectric material properties of objects in WiPTR. "], "table_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/1154307a6240f5ea2e370efa622a683a22a408195a3048fd2d0c5525e8ac9269.jpg", "img_caption": ["Figure 8: Mean absolute errors of received power as a function of number of training rooms for conditional diffusion model samples. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "938 diffusion transformers [43] and concatenate it to the scalar channel dimension. ", "page_idx": 22}, {"type": "text", "text": "939 Optimization. We use the Adam optimizer with a learning rate of $10^{-3}$ for the Wi-GATr models.   \n940 The transformer models required a smaller learning rate for training stability, and thus we chose   \n941 $3\\cdot10^{-4}$ . In both cases, we linearly anneal the learning rate and train for $7\\cdot10^{5}$ steps with a batchsize   \n942 of 64 and gradient norm clipping set to 100.   \n943 Evaluation. We use the DDIM sampler using 100 timesteps for visualizations in Fig. 5 and   \n944 for the error analysis in Fig. 8. To evaluate the variational lower bound in Tbl. 3, we fol  \n945 low [39] and evaluate $L_{v l b}\\;:=\\;L_{0}\\,+\\,L_{1}\\,+\\,.\\,.\\,L_{T}$ , where $L_{0}\\ :=\\ -\\log p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{1}),$ $L_{t-1}~:=$   \n946 $D_{K L}(q(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0})||p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t}))$ and $L_{T}\\,:=\\,D_{K L}\\big(q(\\mathbf{x}_{T}|\\mathbf{x}_{0}),p(\\mathbf{x}_{t})\\big)$ . To be precise, for each   \n947 sample $\\mathbf{x}_{\\mathrm{0}}$ on the test set, we get a single sample $\\mathbf{x}_{t}$ from $q$ and evaluate $L_{v l b}$ accordingly. Table 3   \n948 reports the mean of all $L_{v l b}$ evaluations over the test set.   \n949 Additional results. Fig. 8, shows the quality of samples from $p_{\\theta}(h|F,t,r)$ as a function of the   \n950 amount of available training data, where we average over 3 samples for each conditioning input. It   \n951 is worth noting that diffusion samples have a slightly higher error than the predictive models. This   \n952 shows that the joint probabilistic modelling of the whole scene is a more challenging learning task   \n953 than a deterministic forward model.   \n954 To further evaluate the quality of generated rooms, we analyze how often the model generates walls   \n955 between the receiver and transmitter, compared to the ground truth. Precisely, we plot the distribution   \n956 of received power versus the distance of transmitter and receiver in Fig. 9 and color each point   \n957 according to a line of sight test. We can see that, overall, Wi-GATr has an intersection error of 0.26,   \n958 meaning that in $26\\%$ of the generated geometries, line of sight was occluded, while the true geometry   \n959 did not block line of sight between receiver and transmitter. This confirms that the diffusion model   \n960 correctly correlates the received power and receiver/transmitter positions with physically plausible   \n961 geometries. While an error of $26\\bar{\\%}$ is non-negligible, we note that this task involves generating the   \n962 whole geometry given only a single measurement of received power, making the problem heavily   \n963 underspecified. Techniques such as compositional sampling [21] could overcome this limitation by   \n964 allowing to condition on multiple receiver and received power measurements. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "965 E Discussion ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "966 Progress in wireless channel modelling is likely to lead to societal impact. Not all of it is positive.   \n967 The ability to reconstruct details about the propagation environment may have privacy implications.   \n968 Wireless networks are ubiquitous and could quite literally allow to see through walls. At the same time,   \n969 we believe that progress in the development of wireless channel models may help to reduce radiation   \n970 exposure and power consumption of wireless communication systems, and generally contribute to   \n971 better and more accessible means of communication. ", "page_idx": 22}, {"type": "image", "img_path": "TWfNFCOPaK/tmp/b67fcad40422809fed2c8f9b4a811f12d0cf15d4bd7d8ee1545bbfa36fd65e1c.jpg", "img_caption": ["Figure 9: A scatter plot of normalized received power versus normalized distance between receiver and transmitter. Each point is colored depending on having line of sight between the receiver and transmitter given the room geometry. Left: The geometry used for calculating line of sight is given by conditional diffusion samples using Wi-GATr. Middle: The geometry used for calculating line of sight is given by transformer samples. Right: The geometry used for calculating line of sight is taken from the test data distribution. "], "img_footnote": [], "page_idx": 23}]