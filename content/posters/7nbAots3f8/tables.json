[{"figure_path": "7nbAots3f8/tables/tables_5_1.jpg", "caption": "Table 1: Qualitative comparison of different UDF learning methods. \"Normal\" indicates whether the method requires point cloud normals during learning. \"Feature Type\" refers to whether the information required during training is global or local. \u201cNoise\" and \"Outlier\u201d indicate whether the method can handle the presence of noise and outliers in point clouds.", "description": "This table compares different UDF learning methods based on several characteristics, including the type of input required (dense or sparse point clouds), whether or not normal information is needed, the type of learning (supervised or unsupervised), the type of features used (local or global), and the methods' robustness to noise and outliers.", "section": "4.1 Experiment setup"}, {"figure_path": "7nbAots3f8/tables/tables_6_1.jpg", "caption": "Table 2: Quantitative evaluation of UDF learning methods (CD score is multiplied by 100).", "description": "This table presents a quantitative comparison of different UDF learning methods across various datasets, including the ShapeNetCars and DeepFashion3D datasets.  The metrics used for comparison are Chamfer Distance (CD) and F1-score (at thresholds of 0.005 and 0.01). The results are shown for both clean data, noisy data (with added Gaussian noise), and data with outliers. This table allows for a direct comparison of the performance of the proposed method against state-of-the-art baselines under different data conditions.", "section": "4.2 Experimental results"}]