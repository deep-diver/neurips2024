{"references": [{"fullname_first_author": "Ilyas", "paper_title": "Datamodels: A framework for understanding and improving in-context learning", "publication_date": "2023-05-16", "reason": "This paper introduces datamodels, a framework for understanding and improving in-context learning, which is directly relevant to the core methodology of CONTEXTCITE."}, {"fullname_first_author": "Menick", "paper_title": "CiteQ: Teaching Language Models to Generate Citations", "publication_date": "2022-07-11", "reason": "CiteQ is a seminal work that explores teaching language models to generate citations, providing a critical comparison point for CONTEXTCITE's contributive attribution approach."}, {"fullname_first_author": "Lundberg", "paper_title": "A unified approach to interpreting model predictions", "publication_date": "2017-06-01", "reason": "This paper introduces SHAP values, a theoretically grounded method for explaining model predictions, providing a valuable conceptual framework for evaluating CONTEXTCITE's attribution scores."}, {"fullname_first_author": "Ribeiro", "paper_title": "Anchors: High-Precision Model-Agnostic Explanations", "publication_date": "2018-07-16", "reason": "Anchors provide a method for high-precision model-agnostic explanations, offering a comparison point to CONTEXTCITE's approach to context attribution."}, {"fullname_first_author": "Park", "paper_title": "Data Shapley: Equitable Valuation of Data in Machine Learning", "publication_date": "2022-05-01", "reason": "This paper develops the linear datamodeling score (LDS), a key metric used to evaluate and benchmark CONTEXTCITE's effectiveness."}]}