[{"figure_path": "YxyYTcv3hp/tables/tables_3_1.jpg", "caption": "Table 1: The accuracy of Dt for each unlearning method across different unlearning scenarios.", "description": "This table presents the accuracy results on the test dataset (Dt) for different unlearning methods and various unlearning scenarios. The unlearning scenarios include removing sensitive features (e.g., mouth from CelebA, marital status from Adult, pregnancies from Diabetes), backdoor features (pixel-pattern in CIFAR-10, CIFAR-20, CIFAR-100, ImageNet), and biased features (color in CMNIST and mouth in CelebA). The methods compared are Baseline (original model), Retrain (model retrained without the unlearned features), Fine-tune (model fine-tuned on the remaining data), FedCDP [65], FedRecovery [61], and the proposed Ferrari method.  The accuracy metric assesses how well each method preserves the model's performance on the test dataset after unlearning.", "section": "5.2 Utility Guarantee"}, {"figure_path": "YxyYTcv3hp/tables/tables_6_1.jpg", "caption": "Table 1: The accuracy of Dt for each unlearning method across different unlearning scenarios.", "description": "This table presents the accuracy results on the test dataset (Dt) for various feature unlearning methods across different scenarios.  The scenarios include sensitive feature unlearning (removing sensitive features like 'mouth' from CelebA dataset), backdoor feature unlearning (removing backdoor triggers introduced during training), and biased feature unlearning (mitigating biases towards specific features in datasets). The methods compared are Baseline (original model), Retrain (model retrained without the target features), Fine-tune (model fine-tuned on the remaining dataset), FedCDP (Federated Unlearning via Class-discriminative Pruning), FedRecovery (Federated Unlearning using historical gradient information), and Ferrari (the proposed method). The table shows that Ferrari generally achieves higher accuracy compared to the other methods across various scenarios, suggesting its effectiveness in feature unlearning.", "section": "5 Experimental Results"}, {"figure_path": "YxyYTcv3hp/tables/tables_6_2.jpg", "caption": "Table 2: Feature sensitivity for each unlearning method across sensitive feature unlearning scenario.", "description": "This table presents the feature sensitivity results for different unlearning methods on sensitive features. Lower feature sensitivity indicates better unlearning performance.  The methods compared include Baseline (original model), Retrain (model retrained without sensitive features), Fine-tune (model fine-tuned without sensitive features), FedCDP, FedRecovery, and the proposed Ferrari method.  The results are shown for four different datasets and sensitive features.", "section": "5.3 Sensitive Feature Unlearning"}, {"figure_path": "YxyYTcv3hp/tables/tables_7_1.jpg", "caption": "Table 3: The ASR of MIA for each unlearning method across sensitive feature unlearning scenario.", "description": "This table presents the Attack Success Rate (ASR) achieved by a Model Inversion Attack (MIA) for different feature unlearning methods across various sensitive feature datasets.  It compares the performance of the proposed Ferrari method against baselines (Baseline, Retrain, Fine-tune, FedCDP, FedRecovery). Lower ASR values indicate better protection of sensitive features.", "section": "5.3 Sensitive Feature Unlearning"}, {"figure_path": "YxyYTcv3hp/tables/tables_8_1.jpg", "caption": "Table 1: The accuracy of Dt for each unlearning method across different unlearning scenarios.", "description": "This table presents the accuracy results on the test dataset (Dt) for different unlearning methods across various scenarios (Sensitive, Backdoor, and Biased feature unlearning).  Each row represents a different unlearning scenario and dataset, while each column shows the performance of various methods: Baseline (original model), Retrain (model retrained without the unlearned feature), Fine-tune (model fine-tuned on the remaining data), FedCDP, FedRecovery, and Ferrari (the proposed method). The accuracy values are expressed as percentages with standard deviations. This table helps to evaluate the effectiveness of different methods in preserving model utility during the feature unlearning process.", "section": "5 Experimental Results"}]