{"references": [{"fullname_first_author": "Abbassi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-01-01", "reason": "This paper provides improved algorithms for linear stochastic bandits, which are foundational to the understanding of linear contextual bandits and their application in reinforcement learning."}, {"fullname_first_author": "Jin", "paper_title": "Provably efficient reinforcement learning with linear function approximation", "publication_date": "2020-01-01", "reason": "This paper establishes provably efficient reinforcement learning algorithms with linear function approximation, providing a theoretical foundation for the work in this paper."}, {"fullname_first_author": "He", "paper_title": "Logarithmic regret for reinforcement learning with linear function approximation", "publication_date": "2021-01-01", "reason": "This paper provides logarithmic regret bounds for reinforcement learning with linear function approximation, representing state-of-the-art results before the current paper's contribution."}, {"fullname_first_author": "Papini", "paper_title": "Reinforcement learning in linear MDPs: Constant regret and representation selection", "publication_date": "2021-01-01", "reason": "This paper explores constant regret bounds in linear Markov Decision Processes, directly addressing the central problem tackled in the current paper."}, {"fullname_first_author": "Zhang", "paper_title": "On the interplay between misspecification and sub-optimality gap: From linear contextual bandits to linear MDPs", "publication_date": "2023-01-01", "reason": "This paper analyzes the impact of model misspecification on the regret bounds for reinforcement learning, providing crucial context for the current paper's investigation of misspecified linear MDPs."}]}