{"references": [{"fullname_first_author": "Katherine Crowson", "paper_title": "VQGAN-CLIP: Open domain image generation and editing with natural language guidance", "publication_date": "2022-00-00", "reason": "This paper introduces VQGAN-CLIP, a foundational model for text-to-image generation that significantly influenced the design and methodology of Fantasy."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper details Stable Diffusion, a highly influential diffusion model that serves as a key benchmark and comparison point for Fantasy's performance."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a crucial text encoder widely used in text-to-image models and directly compared to Fantasy's LLM-based approach."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "Muse: Text-to-image generation via masked generative transformers", "publication_date": "2023-00-00", "reason": "Muse, similar to Fantasy, uses a transformer-based masked image modeling approach for text-to-image generation, making it a relevant comparison model and source of related techniques."}, {"fullname_first_author": "Alex Nichol", "paper_title": "GLIDE: Towards photorealistic image generation and editing with text-guided diffusion models", "publication_date": "2021-00-00", "reason": "GLIDE is another significant diffusion-based text-to-image model that establishes a strong baseline for performance and provides a contrast to Fantasy's transformer-based architecture."}]}