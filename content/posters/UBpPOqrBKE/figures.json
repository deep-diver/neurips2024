[{"figure_path": "UBpPOqrBKE/figures/figures_1_1.jpg", "caption": "Figure 1: (a) In order to obtain accurate recommendations in the Books domain, we aim to exploit user preferences (i.e., knowledge of external domains should be fully utilized, e.g. Movie, Toys, and Games domains). However, with the influence of lossy privacy-preserving techniques, the results of the transfer could be negative (e.g., the Music domain with low-quality data). (b) There is a diminishing marginal effect on the growth rate of the model performance with pure positive knowledge, while NT accumulates with an increasing number of source domains. Consequently, the performance of existing methods declines and is worse than that of a single domain model.", "description": "This figure illustrates the challenges in broader-source cross-domain recommendation (BS-CDR). Subfigure (a) shows how BS-CDR aims to leverage user preferences from multiple source domains (Movies, Toys, Games, Music, Clothing, Sports, and Phone) to improve recommendation accuracy in the target domain (Books). However, privacy-preserving techniques can lead to low-quality data in some source domains, resulting in negative knowledge transfer. Subfigure (b) shows that as the number of source domains increases, the positive effect of knowledge transfer diminishes, while the negative impact from low-quality data accumulates, leading to overall performance degradation. ", "section": "1 Introduction"}, {"figure_path": "UBpPOqrBKE/figures/figures_1_2.jpg", "caption": "Figure 1: (a) In order to obtain accurate recommendations in the Books domain, we aim to exploit user preferences (i.e., knowledge of external domains should be fully utilized, e.g. Movie, Toys, and Games domains). However, with the influence of lossy privacy-preserving techniques, the results of the transfer could be negative (e.g., the Music domain with low-quality data). (b) There is a diminishing marginal effect on the growth rate of the model performance with pure positive knowledge, while NT accumulates with an increasing number of source domains. Consequently, the performance of existing methods declines and is worse than that of a single domain model.", "description": "This figure illustrates the challenges in broader source cross-domain recommendation (BS-CDR).  (a) shows how incorporating knowledge from multiple source domains can lead to negative transfer if privacy-preserving methods result in low-quality data. (b) shows that while positive knowledge transfer initially improves performance, the accumulation of negative transfer from multiple domains eventually reduces performance below that of a single-domain model.", "section": "1 Introduction"}, {"figure_path": "UBpPOqrBKE/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of FedGCDR. It consists of two key modules and follows a HVH pipeline: (1) Source Domain Training (Horizontal FL): 1 Each source domain maintains its graph attention network (GAT)-based federated model. (2) Positive Knowledge Transfer Module (Vertical FL): 2 Source domain embeddings are extracted from GAT layers and perturbed with Gaussian noise. 3 The multilayer perceptron aligns the feature space of source domain embeddings and target domain embeddings. (3) Positive Knowledge Activation Module (Horizontal FL): \u2463 Local graph is expanded with source domain embeddings. 5 Enhanced federated training of the target domain is achieved through the expanded graph. \u2465 The target domain maintains its GAT-based federated model. The target domain freezes the GAT layer and fine tunes the model.", "description": "This figure illustrates the FedGCDR framework, detailing its three stages: horizontal source domain training, vertical positive knowledge transfer, and horizontal positive knowledge activation.  Each stage utilizes federated learning and graph attention networks (GATs).  The positive knowledge transfer module uses differential privacy for security. The positive knowledge activation module filters out negative knowledge and improves model accuracy by expanding the target domain graph. ", "section": "3.2 Framework of FedGCDR"}, {"figure_path": "UBpPOqrBKE/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of target domain graph expansion. The virtual users are constructed with the source domain embeddings from the Movie domain and the Music domain. The attentions generated by social links to the virtual user can be regarded as the domain attentions.", "description": "This figure illustrates how the target domain's graph is expanded by incorporating virtual users and virtual social links.  The virtual users represent the same real user from different source domains (Movie and Music in this example).  These links create domain-specific attentions, allowing the model to focus on the most relevant source domain knowledge for better recommendation accuracy in the target domain.", "section": "3.2.3 Positive knowledge activation module"}, {"figure_path": "UBpPOqrBKE/figures/figures_8_1.jpg", "caption": "Figure 4: Illustrations of negative transfer on HR@5 and NDCG@5. Metric values lower than single-domain (dotted line and red area) mean severe negative soft transfer. The figure on HR@10 and NDCG@10 is shown in Appendix D.1.", "description": "This figure shows the negative transfer effect on HR@5 and NDCG@5, comparing the performance of FedGCDR with baselines across different numbers of domains in the Amazon dataset.  The red shaded area highlights cases where multi-domain models perform worse than single-domain models, illustrating the negative impact of transferring knowledge from less relevant domains. The HR@10 and NDCG@10 results, showing similar trends, are provided in the appendix.", "section": "4.2 Recommendation performance"}, {"figure_path": "UBpPOqrBKE/figures/figures_8_2.jpg", "caption": "Figure 5: Ablation study on Amazon-16@CDs and Amazon-16@Books.", "description": "This ablation study on Amazon-16 datasets (CDs and Books as target domains) compares the performance of FedGCDR with two variants: FedGCDR-M (missing the attention graph expansion and target domain fine-tuning) and FedGCDR-T (missing the feature mapping). The results demonstrate the importance of both the positive knowledge transfer module and the positive knowledge activation module in achieving superior recommendation performance (HR@5, HR@10, NDCG@5, NDCG@10).", "section": "4.3 Ablation study"}, {"figure_path": "UBpPOqrBKE/figures/figures_16_1.jpg", "caption": "Figure 4: Illustrations of negative transfer in HR@5 and NDCG@5. Metric values lower than single-domain (dotted line and red area) mean severe negative soft transfer. The figure on HR@10 and NDCG@10 is shown in Appendix D.1.", "description": "This figure shows the performance of different models on two metrics (HR@5 and NDCG@5) across three different datasets (Amazon-4, Amazon-8, and Amazon-16) for two target domains (Books and CDs).  The dotted black line represents the performance of a single-domain model (without cross-domain transfer), serving as a baseline. The red shaded area highlights cases where the multi-domain models perform worse than the single-domain baseline, indicating negative transfer. The chart visually demonstrates the impact of the number of source domains on the effectiveness of cross-domain recommendation, illustrating how the accumulation of negative knowledge from multiple sources can harm the model's performance.", "section": "4.2 Recommendation performance"}, {"figure_path": "UBpPOqrBKE/figures/figures_17_1.jpg", "caption": "Figure 7: The effect of \u03b5 in DP on model performance.", "description": "This figure shows the impact of the privacy budget (\u03b5) on the model's performance in terms of HR@5, HR@10, NDCG@5, and NDCG@10.  The x-axis represents the privacy budget (\u03b5), and the y-axis represents the performance metrics.  The results demonstrate a trade-off between privacy and accuracy; as \u03b5 decreases (stronger privacy), performance diminishes. This indicates that the level of noise added to protect privacy affects the model's ability to learn accurate recommendations.", "section": "4.3 Ablation study"}]