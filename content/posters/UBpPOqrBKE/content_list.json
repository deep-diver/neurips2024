[{"type": "text", "text": "Federated Graph Learning for Cross-Domain Recommendation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ziqi Yang1,2, Zhaopeng Peng1,2, Zihui Wang1,2, Jianzhong $\\mathbf{Qi}^{3}$ , Chaochao Chen4, Weike $\\mathbf{Pan}^{5}$ , Chenglu Wen1,2, Cheng Wang1,2, Xiaoliang Fan1,2\u2217 ", "page_idx": 0}, {"type": "text", "text": "1Fujian Key Laboratory of Sensing and Computing for Smart Cities, Xiamen University, China 2Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University, China 3School of Computing and Information Systems, The University of Melbourne, Australia 4College of Computer Science and Technology, Zhejiang University Hangzhou, China   \n5College of Computer Science and Software Engineering, Shenzhen University Shenzhen, China {yangziqi,pengzhaopeng,wangziwei}@stu.xmu.edu.cn {clwen,cwang,fanxiaoliang}@xmu.edu.cn jianzhong.qi@unimelb.edu.au, zjuccc@zju.edu.cn, panweike@szu.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Cross-domain recommendation (CDR) offers a promising solution to the data sparsity problem by enabling knowledge transfer across source and target domains. However, many recent CDR models overlook crucial issues such as privacy as well as the risk of negative transfer (which negatively impact model performance), especially in multi-domain settings. To address these challenges, we propose FedGCDR, a novel federated graph learning framework that securely and effectively leverages positive knowledge from multiple source domains. First, we design a positive knowledge transfer module that ensures privacy during inter-domain knowledge transmission. This module employs differential privacy-based knowledge extraction combined with a feature mapping mechanism, transforming source domain embeddings from federated graph attention networks into reliable domain knowledge. Second, we design a knowledge activation module to fliter out potential harmful or conflicting knowledge from source domains, addressing the issues of negative transfer. This module enhances target domain training by expanding the graph of the target domain to generate reliable domain attentions and fine-tunes the target model for improved negative knowledge flitering and more accurate predictions. We conduct extensive experiments on 16 popular domains of the Amazon dataset, demonstrating that FedGCDR significantly outperforms state-of-the-art methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Cross-domain recommendation (CDR) has emerged as an effective solution for mitigating data sparsity in recommender systems [1, 2, 3, 4, 5]. CDR operates by integrating auxiliary information from source domains, thereby enhancing recommendation relevance in the target domain. Recently, to address data privacy constrains, many privacy-preserving CDR frameworks have been proposed [6, 7, 8, 9], which achieve strong performance under the assumptions of data sparsity and a dual-domain model (i.e., typically involving a single source domain and a single target domain.). ", "page_idx": 0}, {"type": "text", "text": "In this paper, we focus on a more generic scenario of Broader-Source Cross-Domain Recommendation (BS-CDR), which integrates knowledge from more than two source domains while ", "page_idx": 0}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/26080384d2d006e004b7086b5279190c3d5eab924b6c113decf4eec51889ab7e.jpg", "img_caption": ["(a) The BS-CDR scenario. "], "img_footnote": [], "page_idx": 1}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/ad6ea3e2d50dfdc4313e8e2fc77226cab4de068386701b115d21ee51368e588e.jpg", "img_caption": ["(b) The performance affected by the number of domains "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: (a) In order to obtain accurate recommendations in the Books domain, we aim to exploit user preferences (i.e., knowledge of external domains should be fully utilized, e.g. Movie, Toys, and Games domains). However, with the influence of lossy privacy-preserving techniques, the results of the transfer could be negative (e.g., the Music domain with low-quality data). (b) There is a diminishing marginal effect on the growth rate of the model performance with pure positive knowledge, while NT accumulates with an increasing number of source domains. Consequently, the performance of existing methods declines and is worse than that of a single domain model. ", "page_idx": 1}, {"type": "text", "text": "preserving privacy. Given the diverse nature of user preferences, it is essential to gain a more holistic understanding of user interests by incorporating user behaviors from diversified domains [10, 11]. For example, in Figure 1a, a user who enjoys certain types of books might also enjoy movies, toys, and games in similar genres. However, incorporating more domains while preserving privacy poses challenges to counteract negative transfer (NT), which is a phenomenon of transferring knowledge from a source domain that negatively impacts the recommender model performance in the target domain [12]. Suppose the Books domain in Figure 1a is the target domain. The Clothing domain is causing NT, because of the domain discrepancy. While the Music domain is supposed to transfer positive knowledge, it might also lead to NT because of lossy privacy-preserving techniques applied to broader source domains. As a result, the influx of negative knowledge accumulated from source domains will poison the model performance of the target domain in BS-CDR scenarios. ", "page_idx": 1}, {"type": "text", "text": "To mitigate the NT issue, attention mechanisms have been widely leveraged, either in an explicit (e.g., determine domain attentions by predefined domain features [13, 14]) or implicit manner (e.g., employ hyper-parameters [7, 15]). Several other studies [16, 17, 18], ensure positive transfer by passing only domain-shared features. However, existing methods cannot be directly applied to BS-CDR due to two major challenges. First, inadequate privacy preservation (CH1). Both intra-domain and inter-domain privacy must be carefully considered in BS-CDR. As depicted in Figure 1a, BS-CDR relies on extensive knowledge transfer, risking simultaneous privacy leakages across broader source domains (inter-domain privacy) [9, 19, 20, 21]. Additionally, concerns over centralized data storage may prevent users from sharing sensitive rating data (intra-domain privacy). Second, accumulative negative transfer (CH2). Adjusting attention-related hyper-parameters for a large number of source domains in BS-CDR scenarios is extremely difficult, as well as predefined or domain-shared features cannot accommodate complex domain diversities. In addition, the use of various lossy privacypreserving techniques can further degrade the quality of transferred knowledge, complicating the achievement of positive transfer. Consequently, the impact of NT can inevitably intensify with an increasing number of source domains [2] and the performance of CDR models can decline to levels lower than those of single-domain models, as shown in Figure 1b. ", "page_idx": 1}, {"type": "text", "text": "To address the challenges of privacy (CH1) and NT (CH2) in BS-CDR, we propose Federated Graph learning for Cross-Domain Recommendation (FedGCDR). It follows a horizontal-verticalhorizontal pipeline [6] and consists of two key modules. First, the positive knowledge transfer module aims to safeguard inter-domain privacy and mitigate potential NT before transfer. This module adopts differential privacy (DP) [22] with a theoretical guarantee and aligns the feature spaces to facilitate positive knowledge transfer. Second, the positive knowledge activation module is engaged to further alleviate NT. Specifically, it expands the local graph of the target domain by incorporating virtual social links, enabling the generation of domain attentions. Additionally, it performs target model fine-tuning to optimize the broader-source CDR. Extensive experiments on 16 popular domains from the Amazon benchmarks demonstrate that FedGCDR outperforms all baseline methods in terms of recommendation accuracy. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Our contributions are summarized as follows: ", "page_idx": 2}, {"type": "text", "text": "\u2022 We introduce FedGCDR, a novel federated graph learning framework for CDR that provides high-quality BS-CDR recommendations while safeguarding both user privacy and domain confidentiality;   \n\u2022 We propose two key model, i.e., the positive knowledge transfer module and the positive knowledge activation module. The first transfer module ensure privacy and positive knowledge flows via privacy-preserving knowledge extraction and feature mapping. The second activation module filter harmful information via graph expansion, target domain training and target model fine-tuning;   \n\u2022 We conduct extensive experiments on 16 domains of the Amazon datasets that confirm the effectiveness of FedGCDR in terms of recommendation accuracy. ", "page_idx": 2}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Cross-domain recommendation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "CDR utilizes auxiliary information from external domains to alleviate the data sparsity problem and effectively improve recommendation quality. Li et al. [23] enrich domain knowledge by transferring user-item rating patterns from source domains to target domains. Man et al. [15] and Elkahky et al. [24] augment entities\u2019 embeddings in the target domain by employing a linear or multilayer perceptron (MLP)-based nonlinear mapping function across domains. Liu et al. [25] address the review-based non-overlapped recommendation problem by attribution alignment. Zhao et al.[18] improve the recommendation quality of multi-sparse-domains by mining domain-invariant preferences. Liu et al. [26] achieve knowledge transfer without overlapping users by mining joint preferences. Chen et al. [19] and Liu et al. [27] avoid intermediate result privacy leakage during cross-domain knowledge transfer by employing DP. In these works, the NT problem is often ignored because most of them assume a carefully selected dual-domain scenarios or limited multi-domain scenarios where NT is not evident. We aim to solve the NT problem in complex BS-CDR scenarios. ", "page_idx": 2}, {"type": "text", "text": "2.2 Federated recommendation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Recently, FL [28, 29, 30, 31, 32] has been widely adopted to tackle the privacy issue in recommender system. Chai et al. [33] adopts FL to classic matrix factorization algorithm and utilize homomorphic encryption to avoid the potential threat of privacy disclosure. Later, Wu et al. [34] explores the application of federated graph neural networks (GNN) models to improve the recommendation quality and ensure user privacy. To utilize sensitive social information, Liu et al. [8] adopts local differential privacy (LDP) and negative sampling. More recent studies use VFL to protect company\u2019s privacy in recommender system. Mai et al. [35] utilizes random projection and ternary quantization to ensure privacy preservation in VFL. In CDR, Chen et al. [9] designs a dual-target VFL CDR model with orthogonal mapping matrix and LDP for organizations\u2019 privacy preservation. Liu et al. [36] designs a graph convolutional networks (GCN)-based federated framework to learn user preference distributions for more accurate recommendations. To ensure user privacy in CDR, Liu et al. [6] utilizes a VAE-based federated model to mine user preference with data stored locally. Wu et al. [7] designs a personal module and a transfer module to provide personalized recommendation while preserving user privacy. These existing works, especially federated CDR frameworks, consider only one type of privacy (intra- or inter-domain). We aim to provide both intra-domain and inter-domain privacy. ", "page_idx": 2}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/861702eb0be0abede1480ad06337c017b9116f8afbd0e38f1897cbf6a068125e.jpg", "img_caption": ["Figure 2: An overview of FedGCDR. It consists of two key modules and follows a HVH pipeline: (1) Source Domain Training (Horizontal FL): $\\Phi$ Each source domain maintains its graph attention network (GAT)-based federated model. (2) Positive Knowledge Transfer Module (Vertical FL): $\\textcircled{2}$ Source domain embeddings are extracted from GAT layers and perturbed with Gaussian noise. $\\circledast$ The multilayer perceptron aligns the feature space of source domain embeddings and target domain embeddings. (3) Positive Knowledge Activation Module (Horizontal FL): $\\textcircled{4}$ Local graph is expanded with source domain embeddings. $\\mathfrak{H}$ Enhanced federated training of the target domain is achieved through the expanded graph. $\\circled{6}$ The target domain maintains its GAT-based federated model. $\\oslash$ The target domain freezes the GAT layer and fine tunes the model. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "3.1 Problem definition ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We consider $M$ $(M\\!>\\!3)$ domains participating in the CDR process. The domains are divided into M-1 source domains $\\mathring{D}^{S_{1}},\\mathcal{D}^{S_{2}},...,\\mathcal{D}^{S_{M-1}}$ and one target domain $\\mathcal{D}^{T}$ . Each domain is assigned a domain server to conduct intra-domain model training. $\\boldsymbol{\\mathcal{U}}$ is the user set across all the domains, $\\mathcal{U}=\\mathcal{U}_{1}\\bigcup\\mathcal{U}_{2}\\bigcup\\ldots\\bigcup\\mathcal{U}_{M}$ , where $u_{i}$ denotes the user set of domain $i$ . We assume that users partially overlap between do mains. Each user is treated as an individual client. User space refers to the virtual space in the user\u2019s device containing domain models distributed from each domain server. Meanwhile, $\\nu_{i}$ is the item set of domain $i$ . Let $\\mathbf{\\dot{R}}^{i}\\in\\mathbb{R}^{|\\mathcal{U}_{i}|\\times|\\mathcal{V}_{i}|}$ be the observed rating matrix of the $i$ -th domain. We consider top- $\\mathbf{\\nabla}\\cdot\\mathbf{K}$ recommendation, i.e., we learn a function to estimate the scores of unobserved entries in the rating matrix, which are later used for item ranking and recommendations. Our goal is to achieve highly accurate recommendations in the target domain. ", "page_idx": 3}, {"type": "text", "text": "3.2 Framework of FedGCDR ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "3.2.1 Overview ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The overall framework of FedGCDR is shown in Figure 2. FedGCDR follows a Horizontal-VerticalHorizontal (HVH) pipeline and its two horizontal FL stages ensure the intra-domain privacy privacy. Our two key modules focus on the vertical stage and the second horizontal stage: (1) The positive knowledge transfer module preserves the inter-domain privacy by DP and alleviates NT by feature mapping. (2) The positive knowledge activation module filters out potential harmful or conflicting knowledge from the source domains. Specifically, we expand the local graph of the target domain by virtual social links, such that the target domain graph attention network (GAT) model could generate reliable domain attention based on the expanded graph. After target domain GAT model training, we further mitigate NT by adopting a fine-tuning stage. ", "page_idx": 3}, {"type": "text", "text": "Horizontal-Vertical-Horizontal pipeline The HVH pipeline contains three stages with switching federated settings. The first horizontal stage refers to the source domain training in which source domain servers individually interacts with its domain users (clients). The private rating information is stored within each client, while the clients exchange model and gradients to train a domain-specific global model. The next two stages correspond to our two key modules (vertical positive knowledge transfer module and horizontal positive knowledge activation module), which we will cover in detail in the following subsections. It\u2019s important to note that the vertical positive knowledge transfer module is completely computed in each client\u2019s user space (their personal devices), thus reducing communication overheads. This is because the needed source domain knowledge can be extracted from local source models on each client which are distributed during the first horizontal source domain training stage. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Following the HVH pipeline, we achieve: (1) Privacy enhancement. The two horizontal stages can provide intra-domain privacy preservation, while we further ensure inter-domain privacy by applying DP to the vertical stage. In the mean time, servers are not involved in the knowledge transfer process (i.e., the positive knowledge transfer module), making them unaware of user interactions in other source domains. (2) Communication efficiency. Cross-domain knowledge transfer does not require additional communication overhead. ", "page_idx": 4}, {"type": "text", "text": "Intra-domain GAT-based federated model We adopt a GAT-based [37, 38, 39] federated framework as the underlying model for our intra-domain recommender system. The horizontal paradigm avoids centralized storage of user ratings to ensure intra-domain privacy (CH1). In the initial step, each user and item is offered an ID embedding of size $d$ , denoted by ${\\bf e}_{u}^{0}$ , ${\\bf e}_{v}^{0}\\in\\mathbb{R}^{d}$ respectively. The embedding is passed through $L$ message propagation layers [40, 41, 42]. For the $l$ -th layer: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{e}_{u}^{l+1}=\\sigma(\\mathbf{W}^{l}(a_{u u}^{l}\\mathbf{e}_{u}^{l}+\\sum_{v\\in N_{u}}a_{u v}^{l}\\mathbf{e}_{v}^{l})),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $N_{u}$ is the neighbor set of $u$ , $\\mathbf{W}^{l}$ is a learnable weight matrix, $a_{u u}^{l}$ and $a_{u v}^{l}$ are the importance coefficients computed by the attention mechanism: ", "page_idx": 4}, {"type": "equation", "text": "$$\na_{u v}^{l}=\\frac{e x p(L e a k y R e L U(\\alpha(\\mathbf{W}\\mathbf{e}_{u}^{l}||\\mathbf{W}\\mathbf{e}_{v}^{l}))}{\\sum_{v^{\\prime}\\in N_{u}\\bigcup u}e x p(L e a k y R e L U(\\alpha[\\mathbf{W}\\mathbf{e}_{u}^{l}||\\mathbf{W}\\mathbf{e}_{v^{\\prime}}^{l}])},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\alpha$ is the weight vector. Inspired by LightGCN [43], we discard feature transformation and nonlinear activation for better model efficiency and learning effectiveness: ", "page_idx": 4}, {"type": "equation", "text": "$$\ne_{u}^{l+1}=a_{u u}^{l}{\\bf e}_{u}^{l}+\\sum_{v\\in N_{u}}a_{u v}^{l}{\\bf e}_{v}^{l},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "equation", "text": "$$\na_{u v}=\\frac{e x p(\\alpha(\\mathbf{e}_{u}^{l}||\\mathbf{e}_{v}^{l}))}{\\sum_{v^{\\prime}\\in N_{u}\\bigcup u}e x p(\\alpha(\\mathbf{e}_{u}^{l}||\\mathbf{e}_{v^{\\prime}}^{l})}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In each source domain, the domain server and corresponding users collaboratively train a GAT-based federated model. The training process follows the horizontal federated learning (HFL) paradigm in which only the model and gradients are exchanged considering intra-domain privacy. We will not detail the horizontal federation model (e.g., further privacy guarantee and more high-order information) as it is a well established FL model and not our novel contribution. This model can be replaced by other GAT-based $\\mathrm{FL}$ models [34, 44] as well. ", "page_idx": 4}, {"type": "text", "text": "3.2.2 Positive knowledge transfer module ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "After the source domain training, we obtain a series of source models in individual client\u2019s user space. Our positive knowledge transfer module then prepares positive knowledge to be transferred from each source domains $\\bar{\\mathcal{D}}^{S}$ to the target domain $\\mathcal{D}^{\\tilde{T}}$ , while protecting inter-domain privacy (CH1). Specifically, suppose a individual user (client) $u$ and a source domain $\\mathcal{D}^{S_{i}}$ , we transfer the user $u$ \u2019s embedding matrix $\\mathbf{X}_{S_{i}}\\in\\mathbb{R}^{L\\times d}$ . Take the row $l$ of the matrix (i.e., $\\mathbf{x}_{S_{i}}^{l}$ ) as an example, it is the user $u$ \u2019s embedding output by the $l$ -th message propagation layer $(e_{u}^{l})$ . In an ideal scenario (i.e., we transfer totally positive knowledge without taking inter-domain privacy into account) [6], embedding matrices from different source domains can be directly used to enhance target domain local training in client $u$ . By utilizing the source domain embeddings, $u$ \u2019s final target domain embedding ${\\bf e}_{T}^{l}$ of layer $l$ is: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{e}_{T}^{l}=f_{T}(\\mathbf{x}_{T}^{l},\\mathbf{x}_{S_{1}}^{l},...,\\mathbf{x}_{S_{M-1}}^{l}),\\quad l\\in[1,L]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $f_{T}(\\cdot)$ is the function that the target domain aggregates the knowledge of the source domains and we will give its final expression in Subsection 3.2.3. In this process, the transfer of knowledge between domains takes place entirely in the user $u$ \u2019s local space. Such a fully localized mode of knowledge transfer avoiding the additional communication overhead and potential privacy issues [6]. However, this direct embeddings transfer does not meet the privacy and NT constrains in BS-CDR scenarios. ", "page_idx": 4}, {"type": "text", "text": "Privacy-preserving knowledge extraction In existing CDR frameworks, the user or item embedding was shared as knowledge [9, 15, 6], which neglects inter-domain privacy. In a GNN-based approach, such direct transfers are subject to privacy attacks. Each message propagation layer can be viewed as a function with user and item embeddings as input. An attacker can easily obtain the user\u2019s private rating matrix based on these embeddings. We apply DP to the source domain embeddings $\\mathbf{x}_{S_{i}}$ [22, 45] to safeguard inter-domain privacy. ", "page_idx": 5}, {"type": "text", "text": "THEOREM 1. By perturbing the source domain embeddings with Gaussian noise, the reconstructed data of the ideal attack deviates from the real data and prevents a perfect reconstruction. ", "page_idx": 5}, {"type": "text", "text": "In FedGCDR, we adopt the Gaussian mechanism to the source domain embedding $\\mathbf{x}_{S_{i}}$ to obtain $\\hat{\\mathbf{x}}_{S_{i}}$ for knowledge transfer. Detailed privacy analysis is included in Appendix A. ", "page_idx": 5}, {"type": "text", "text": "Feature mapping User features could represent personal preferences and are influenced by domain features. The discrepancy of domains leads to the heterogeneity of feature space between domains which means that source domain embeddings cannot be utilized directly by the target domain. Man et al. [15] show that there exists an underlying mapping relationship between the latent user matrix of different domains, which can be captured by a mapping function. In order to alleviate NT, we adopt a series of MLP to explore mapping functions for each source domain. Adding Gaussian noise and feature mapping, Equation (5) becomes: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{e}_{T}^{l}=f_{T}(\\mathbf{x}_{T}^{l},M L P_{1}(\\hat{\\mathbf{x}}_{S_{1}}^{l}),...,M L P_{M-1}(\\hat{\\mathbf{x}}_{S_{M-1}}^{l})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "To learn more effective mapping function, we adopt a mapping loss term: ", "page_idx": 5}, {"type": "equation", "text": "$$\nl_{m}=\\sum_{i=1}^{M-1}\\sum_{l=1}^{L}\\vert\\vert\\mathbf{x}_{T}^{l}-M L P_{i}(\\hat{\\mathbf{x}}_{S_{i}}^{l})\\vert\\vert^{2},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "3.2.3 Positive knowledge activation module ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "After the aforementioned operations, the target domain obtains a list of source domain matrices $\\hat{\\mathbf{X}}_{S_{1}},\\hat{\\mathbf{X}}_{S_{2}},...,\\hat{\\mathbf{X}}_{S_{M-1}}$ . The row of the matrices represent $M L P_{i}(\\hat{\\mathbf{x}}_{S_{i}}^{l})$ . It is worth noting that for source domains where a user has no rating, $\\hat{\\mathbf{X}}_{S_{i}}$ is a Gaussian noise matrix and our motivation is: (1) no rating may also suggest a preference; (2) this is beneficial for enhancing the model\u2019s capability to fliter noise and identify NT. With the knowledge from the source domains, the positive knowledge activation module is to alleviate NT after the knowledge transfer (CH2). Although we have aligned the feature space in the previous module, the Gaussian noise that has been fed to the target domain with source domain embedding matrices leads to potential NT. How to utilize the transferred knowledge remains a great challenge. ", "page_idx": 5}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/b83929832f9b639fbbcff4d070528a73bd7b7c3ca120895bdcbed3a1d7e86205.jpg", "img_caption": ["Figure 3: Illustration of target domain graph expansion. The virtual users are constructed with the source domain embeddings from the Movie domain and the Music domain. The attentions generated by social links to the virtual user can be regarded as the domain attentions. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Graph expansion and target domain training To alleviate NT, common approaches are to generate domain attention by predefined domain features [13, 46, 47] or to control the transfer ratio of source domains by hyper-parameters [7]. These methods are only applicable to a limited number of domains and have excessive human intervention. In FedGCDR, we take an attention-based approach. First, we expand $u$ \u2019s (Mary\u2019s) local graph of the target domain as shown in Figure 3. ", "page_idx": 5}, {"type": "text", "text": "For the source domain embedding matrices $\\hat{\\mathbf{X}}_{S_{1}},\\hat{\\mathbf{X}}_{S_{2}},...,\\hat{\\mathbf{X}}_{S_{M-1}}$ , we represent them as $M-1$ virtual users.Since the virtual users constructed from source domain embeddings represent the same individual $u$ , they share correlated preferences, with their features (i.e., embeddings) characterizing $u$ \u2019s preferences. Inspired by social recommendation [48, 49, 50], we consider that there is a implicit social relationship between virtual users and the actual user $u$ , because of the correlation in their preferences. Then, we build virtual social links between them to expand the original target domain graph. Second, by incorporating this expanded graph into target domain training, the GAT model generates corresponding attention coefficients for the virtual users, which can be interpreted as domain-specific attentions. Leveraging the domain attention coefficients, the target domain can focus on domains that transfer positive knowledge and we can finally give $f_{T}(\\cdot)$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\nf_{T}(x_{T}^{l},M L P_{1}(\\hat{\\mathbf{x}}_{S_{1}}^{l}),...,M L P_{M-1}(\\hat{\\mathbf{x}}_{S_{M-1}}^{l}))=a_{u u}^{l}\\mathbf{x}_{T}^{l}+\\sum_{v\\in N_{u}}a_{u v}^{l}\\mathbf{e}_{v}^{l}+\\sum_{i=1}^{M-1}a_{i}^{l}M L P_{i}(\\hat{\\mathbf{x}}_{S_{i}}^{l}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $a_{i}^{l}$ is the domain attention of source domain $i$ generated by the $l$ -th layer. Beside, we introduce a social regularization term to strengthen the virtual social links: ", "page_idx": 6}, {"type": "equation", "text": "$$\nl_{s}=\\sum_{l=1}^{L}\\parallel\\mathbf{x}_{T}^{l}-\\frac{\\sum_{i=1}^{M-1}S i m(\\mathbf{x}_{T}^{l},\\hat{\\mathbf{x}}_{S_{i}}^{l})\\times\\hat{\\mathbf{x}}_{S_{i}}^{l}}{\\sum_{i=1}^{M-1}S i m(\\mathbf{x}_{T}^{l},\\hat{\\mathbf{x}}_{S_{i}}^{l})}\\parallel^{2},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Since we do not have direct access to the rating matrix of each source domain, the function $S i m(\\cdot)$ calculates the cosine similarity [48]. ", "page_idx": 6}, {"type": "text", "text": "Through the graph expansion, we achieve: (1) dynamic domain attentions that focus on positive source domain knowledge to alleviate NT; (2) attention generation by GAT, eliminating the need for additional interventions such as hyper-parameter tuning or feature engineering. ", "page_idx": 6}, {"type": "text", "text": "For top- $k$ recommendation, we adopt a widely-used inner product model to estimate the value of target domain rating $\\mathbf{R}_{u v}^{T}$ , which is the interaction probability between a pair of user $u$ and item $v$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mathbf{R}}_{u v}^{T}=S i g m o i d(\\mathbf{e}_{T}^{u}\\cdot\\mathbf{e}_{T}^{v}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where ${\\bf e}_{T}^{u}$ and ${\\bf e}_{T}^{v}$ are the final user and item embeddings output by GAT. Our objective function consists of three terms as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n{\\cal L}_{G A T}=B C E L o s s(\\hat{{\\bf R}}_{u v}^{T},{\\bf R}_{u v}^{T})+\\frac{\\alpha}{2}l_{m}+\\frac{\\beta}{2}l_{s},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\alpha$ and $\\beta$ are hyper-parameters, and $B C E L o s s(\\cdot)$ is the binary cross-entropy loss [51]. The target domain federated GAT training with the expanded graph following the HFL paradigm. ", "page_idx": 6}, {"type": "text", "text": "Target model fine-tuning After target domain training with the expanded graph, the target domain GAT model assimilates knowledge from the source domains. However, NT may still be unavoidable, potentially leading to the accumulation of negative knowledge in the target domain. An example of this is the Gaussian noise matrices transferred from source domains where the user has no interactions. On the basis of this consideration, we adopt an additional fine-tuning stage: First, we freeze the message propagation layer of GAT to isolate the influence of source domains preventing Gaussian noise from permeating through the transfer process. Second, we directly train the well-informed embeddings generated by the target domain GAT. These steps adapt the learned external knowledge for predicting the target domain ratings. In this process, we use the loss of prediction in Equation (11) as the object function: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{f t}=B C E L o s s(\\hat{\\mathbf{R}}_{u v}^{T},\\mathbf{R}_{u v}^{T}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We provide a computational analysis and a communication analysis of FedGCDR in Appendix B. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Experimental setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets We study the effectiveness of FedGCDR with 16 popular domains on a real-world dataset Amazon [52]. To study the impact of the number of domains on model performance, we divide these domains into three subsets containing 4, 8, and 16 domains respectively and denote them as Amazon-4, Amazon-8, and Amazon-16 respectively. The statistics of sub-datasets are shown in Table 1. We fliter the original data in different ways, and more details are given in Appendix C.1. In our experiments, Books and CDs are selected as the target domains. For the ratings in each domain, we first convert them to implicit data, where entries corresponding to existing user-item interactions are marked as 1 and others are marked as 0. ", "page_idx": 6}, {"type": "table", "img_path": "UBpPOqrBKE/tmp/f085fb0938c7aeddefa2e5e94b91af29f0c0b15058fdaea2b102c9b1b1bbb42e.jpg", "table_caption": ["Table 1: Statistics on the Amazon Dataset. (min-median-max) values are provided for $|U_{d}|$ , $|I_{d}|$ and $|R_{d}|$ . "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Baselines We compare FedGCDR with the following state-of-the-art models: (1) FedGNN [34] is an attempt to adopt FL graph learning to recommender systems. Its recommendation performance could represent the data quality of the target domain and reflect negative transfer. In Tables 2 and 3, in order to distinguish FedGNN from the CDR baselines, we denote it by Single Domain. (2) EMCDR [15] is a conventional embedding-mapping CDR framework. We adjust it to the HFL framework following [6]. (3) PriCDR [19] is a privacy-preserving CDR framework, which adopted DP on the rating matrices rating matrix to ensure privacy. (4) FedCT [6] is a VAE-based federated framework that is the first attempt to protect intra-domain privacy in cross-domain recommendations. (5) FedCDR [7] is a dual-target federated CDR framework, where the user embeddings are transferred as knowledge to enhance the other domain\u2019s model training. To adapt to the BS-CDR scenarios, we modify FedCDR by applying embedding averaging when receiving source domain embeddings. ", "page_idx": 7}, {"type": "text", "text": "We provide implement details in Appendix C.2. ", "page_idx": 7}, {"type": "text", "text": "4.2 Recommendation performance ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We report the model performance results in Tables 2 and 3. Single domain shows that the Book domain has better single-domain recommendation accuracy than the Music domain, which represents higher data quality and quantity. Under BS-CDR settings, FedGCDR outperforms all CDR baselines on all three sub-datasets, which confirms the effectiveness of the proposed model on real-world data. ", "page_idx": 7}, {"type": "text", "text": "To further study our model capacity in alleviating negative transfer, we first define two types of negative transfer: (1) Soft Negative Transfer (SNT), where recommender models\u2019 performance under the multi-domain setting is worse than that under the single-domain setting. This means that the knowledge from source domains poisoning the target domain\u2019s model training. (2) Hard Negative Transfer (HNT), where recommended performance of a large number of source domains is lower than that of a small number of source domains. This means that the newly added domains are not conducive to the training of the target domain or conflict with the already added source domain. ", "page_idx": 7}, {"type": "text", "text": "Taking the Books domain as the target domain, EMCDR, PriCDR, FedCT and FedCDR both have serious negative transfer problems and lower performance on the three data subsets. From the SNT perspective, their performances is much worse than that of Single Domain as shown in Figure 4. From the HNT perspective, their performances under 16-domain settings is worse than that under the 8-domain and 4-domain settings, which suggests it is not appropriate to recklessly transfer knowledge to a well-informed domain. Our FedGCDR model successfully alleviates NT with consistently best and stable performance results. For the CDs domain, the performance of the CDR models greatly improves with less NT in Figure 4.From the SNT perspective, information-poor domains have a lower probability of negative transfer, as they are inherently less well-trained. From the HNT perspective, on the Amazon-8 dataset, the performance of all models declines, which we attribute to the strong negative knowledge introduced by the four additional domains compared to the Amazon-4 dataset. On the Amazon-16 dataset, all methods achieve best performance which indicates more knowledge from the source domains can improve the model performance in the CDs domain. Overall, the capability of EMCDR, PriCDR and FedCDR to alleviate negative transfer is much higher than that ", "page_idx": 7}, {"type": "text", "text": "Table 2: The recommendation performance on Amazon $@$ Books. Single Domain represents FedGNN and its performance is exactly the same on three sub-datasets. FedGCDR-DP is a complete implementation of our method while FedGCDR does not incorporate Gaussian noise. (The best result for the same setting is marked in bold and the second best is underlined. These notes are the same to others.) ", "page_idx": 8}, {"type": "table", "img_path": "UBpPOqrBKE/tmp/e0e036949950b7d6b03fd3e74156facb3a166dbbf7863228f8b5cd6cfca91969.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "UBpPOqrBKE/tmp/c3480dcc3b3235f06e64333a0afda07a74174b08c13a6f8de36e1a02ae365dae.jpg", "table_caption": ["Table 3: The recommendation performance on Amazon@CDs. "], "table_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/2d218bcb2b52fa863fc004454dec2db56eeaf86ff2f6674115c6a24264f1ed22.jpg", "img_caption": ["Figure 4: Illustrations of negative transfer on $\\operatorname{HR}\\!\\left(\\varpi5\\right)$ and $\\operatorname{NDCG}\\!\\left(\\alpha\\!\\left|\\right.\\right)$ . Metric values lower than single-domain (dotted line and red area) mean severe negative soft negative transfer. The figure on HR $@10$ and NDCG $@10$ is shown in Appendix D.1. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/4ea5e3977403b227db05db1a24067b45d2955be31a21dc5e3a6ecb7dd74cb581.jpg", "img_caption": ["Figure 5: Ablation study on Amazon- $16\\@$ CDs and Amazon- $16\\@$ Books. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "of FedCT. This is because the proportion of target domain features in the final feature is guaranteed by tuning hyper-parameters to control the transfer ratio of the source domain. Meanwhile, FedGCDR avoids this kind of human involvement and maintains performance optimality on three sub-datasets. In conclusion, our experiments show the superiority of FedCDR in recommendation performance and the effectiveness of alleviating NT. ", "page_idx": 8}, {"type": "text", "text": "4.3 Ablation study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To study the contribution of each module of FedGCDR, we implement two model variants, FedGCDR-M and FedGCDR-T. FedGCDR-T transfers the source domain embeddings without mapping. FedGCDR-M replaces the attention graph expansion with the average sum of source domain embeddings and omits the fine-tuning stage. We experiment with Books and CDs as target domains on the Amazon-16 dataset. The experimental results are shown in Figure 5. We make the following observations: (1) The two variants perform differently on different target domains. On the Books domain, FedGCDR-T performs better than FedGCDR-M, which indicates that for domains with higher data quality, preventing the transfer of negative knowledge from other domains is more important than mapping this knowledge better (in other words, the quality of external information holds greater significance than its quantity), and the Positive Knowledge Activation module meets the requirements of such domains. On the CDs domain, FedGCDR-M performs better than FedGCDRT, which indicates that for domains that are deficient in information, mapping knowledge correctly is more important than preventing inter-domain negative knowledge (in other words, the quantity of external information holds greater significance than its quality), and the Positive Knowledge Transfer module meets these requirements. (2) Compared to FedGCDR, the absence of either module can cause a significant drop in performance. This indicates that in cross-domain recommendation, we should not only focus on transferring positive knowledge, but also control the spread of negative knowledge to the target domain, especially when a large number of domains. ", "page_idx": 8}, {"type": "table", "img_path": "UBpPOqrBKE/tmp/61f1d4c505a3b786eace40967f69bca1176afcf3453e5e4a0b96180c44794807.jpg", "table_caption": ["Table 4: Dual-domain CDR performance. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "4.4 Dual-domain scenario ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "According to the experimental results shown in Table 5, our FedGCDR achieved the best experimental metrics in both knowledge transfer directions. This shows that our approach is also suitable for dual-domain scenarios where users full-overlap and have only a single source domain and a single target domain. ", "page_idx": 9}, {"type": "text", "text": "We provide experimental results on privacy budget in Appendix D.2. ", "page_idx": 9}, {"type": "text", "text": "5 Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our experiments were conducted on 16 domains of the Amazon dataset. While this extensive dataset covers broader source domains, relying on a single dataset may limit the generalizability of our model to data from other sources. Our approach uses overlapping users as a cross-domain bridge. Indeed, there are no widely-recognized cross-domain recommendation datasets with more than three domains, aside from the Amazon dataset. Despite this limitation, we firmly believe that the significant improvements in privacy preservation and model performance demonstrated by FedGCDR underscore its superiority. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We proposed FedGCDR, a federated graph learning framework designed for BS-CDR. FedGCDR addresses the critical challenge of privacy preservation and negative transfer by employing a positive knowledge transfer module and a positive knowledge activation module. Our privacy-preserving method achieves best recommendation quality results on 16 domains of the Amazon dataset. In the future, we aim to extend FedGCDR to improve the recommendation performance of both the target and the source domains. ", "page_idx": 9}, {"type": "text", "text": "7 Acknowledgment ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The research was supported by Natural Science Foundation of China (62272403). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Weiming Liu, Jiajie Su, Chaochao Chen, and Xiaolin Zheng. Leveraging distribution alignment via stein path for cross-domain cold-start recommendation. Advances in Neural Information Processing Systems, 34:19223\u201319234, 2021.   \n[2] Tianzi Zang, Yanmin Zhu, Haobing Liu, Ruohan Zhang, and Jiadi Yu. A survey on crossdomain recommendation: taxonomies, methods, and future directions. ACM Transactions on Information Systems, 41(2):1\u201339, 2022. [3] Feng Zhu, Yan Wang, Chaochao Chen, Jun Zhou, Longfei Li, and Guanfeng Liu. Cross-domain recommendation: challenges, progress, and prospects. arXiv preprint arXiv:2103.01696, 2021. [4] Meng Liu, Jianjun Li, Guohui Li, and Peng Pan. Cross domain recommendation via bidirectional transfer graph collaborative filtering networks. In Proceedings of the 29th ACM international conference on information & knowledge management, pages 885\u2013894, 2020. [5] Jiangxia Cao, Jiawei Sheng, Xin Cong, Tingwen Liu, and Bin Wang. Cross-domain recommendation to cold-start users via variational information bottleneck. In 2022 IEEE 38th International Conference on Data Engineering, pages 2209\u20132223. IEEE, 2022. [6] Shuchang Liu, Shuyuan Xu, Wenhui Yu, Zuohui Fu, Yongfeng Zhang, and Amelie Marian. Fedct: Federated collaborative transfer for recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 716\u2013725, 2021.   \n[7] Wu Meihan, Li Li, Chang Tao, Eric Rigall, Wang Xiaodong, and Xu Cheng-Zhong. Fedcdr: federated cross-domain recommendation for privacy-preserving rating prediction. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, pages 2179\u20132188, 2022.   \n[8] Zhiwei Liu, Liangwei Yang, Ziwei Fan, Hao Peng, and Philip S Yu. Federated social recommendation with graph neural network. ACM Transactions on Intelligent Systems and Technology (TIST), 13(4):1\u201324, 2022.   \n[9] Gaode Chen, Xinghua Zhang, Yijun Su, Yantong Lai, Ji Xiang, Junbo Zhang, and Yu Zheng. Win-win: a privacy-preserving federated framework for dual-target cross-domain recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 4149\u20134156, 2023.   \n[10] Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. A survey of transfer learning. Journal of Big Data, 3:1\u201340, 2016.   \n[11] Nidhi Agarwal, Akanksha Sondhi, Khyati Chopra, and Ghanapriya Singh. Transfer learning: Survey and classification. Smart Innovations in Communication and Computational Sciences 2020, pages 145\u2013155, 2021.   \n[12] Wen Zhang, Lingfei Deng, Lei Zhang, and Dongrui Wu. A survey on negative transfer. IEEE/CAA Journal of Automatica Sinica, 10(2):305\u2013329, 2022.   \n[13] Hongwei Zhang, Xiangwei Kong, and Yujia Zhang. Selective knowledge transfer for crossdomain collaborative recommendation. IEEE Access, 9:48039\u201348051, 2021.   \n[14] Xu Yu, Dingjia Zhan, Lei Liu, Hongwu Lv, Lingwei Xu, and Junwei Du. A privacy-preserving cross-domain healthcare wearables recommendation algorithm based on domain-dependent and domain-independent feature fusion. IEEE Journal of Biomedical and Health Informatics, 26(5):1928\u20131936, 2021.   \n[15] Tong Man, Huawei Shen, Xiaolong Jin, and Xueqi Cheng. Cross-domain recommendation: An embedding and mapping approach. In IJCAI, volume 17, pages 2464\u20132470, 2017.   \n[16] Zhen Liu, Jingyu Tian, Lingxi Zhao, and Yanling Zhang. Attentive-feature transfer based on mapping for cross-domain recommendation. In 2020 International Conference on Data Mining Workshops (ICDMW), pages 151\u2013158. IEEE, 2020.   \n[17] Huan Yan, Xiangning Chen, Chen Gao, Yong Li, and Depeng Jin. Deepapf: Deep attentive probabilistic factorization for multi-site video recommendation. TC, 2(130):17\u2013883, 2019.   \n[18] Xiaoyun Zhao, Ning Yang, and Philip S Yu. Multi-sparse-domain collaborative recommendation via enhanced comprehensive aspect preference learning. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining, pages 1452\u20131460, 2022.   \n[19] Chaochao Chen, Huiwen Wu, Jiajie Su, Lingjuan Lyu, Xiaolin Zheng, and Li Wang. Differential private knowledge transfer for privacy-preserving cross-domain recommendation. In Proceedings of the ACM Web Conference 2022, pages 1455\u20131465, 2022.   \n[20] Xinting Liao, Weiming Liu, Xiaolin Zheng, Binhui Yao, and Chaochao Chen. Ppgencdr: A stable and robust framework for privacy-preserving cross-domain recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 4453\u20134461, 2023.   \n[21] Zhongxuan Han, Xiaolin Zheng, Chaochao Chen, Wenjie Cheng, and Yang Yao. Intra and inter domain hypergraph convolutional network for cross-domain recommendation. In Proceedings of the ACM Web Conference 2023, pages 449\u2013459, 2023.   \n[22] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014.   \n[23] Bin Li, Qiang Yang, and Xiangyang Xue. Can movies and books collaborate? cross-domain collaborative flitering for sparsity reduction. In Twenty-First International Joint Conference on Artificial Intelligence, 2009.   \n[24] Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. A multi-view deep learning approach for cross domain user modeling in recommendation systems. In Proceedings of the 24th International Conference on World Wide Web, pages 278\u2013288, 2015.   \n[25] Weiming Liu, Xiaolin Zheng, Mengling Hu, and Chaochao Chen. Collaborative filtering with attribution alignment for review-based non-overlapped cross domain recommendation. In Proceedings of the ACM Web Conference 2022, pages 1181\u20131190, 2022.   \n[26] Weiming Liu, Chaochao Chen, Xinting Liao, Mengling Hu, Yanchao Tan, Fan Wang, Xiaolin Zheng, and Yew Soon Ong. Learning accurate and bidirectional transformation via dynamic embedding transportation for cross-domain recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, number 8, pages 8815\u20138823, 2024.   \n[27] Weiming Liu, Xiaolin Zheng, Chaochao Chen, Mengling Hu, Xinting Liao, Fan Wang, Yanchao Tan, Dan Meng, and Jun Wang. Differentially private sparse mapping for privacy-preserving cross domain recommendation. In Proceedings of the 31st ACM International Conference on Multimedia, pages 6243\u20136252, 2023.   \n[28] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pages 1273\u20131282. PMLR, 2017.   \n[29] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International Conference on Machine Learning, pages 5132\u20135143. PMLR, 2020.   \n[30] Zheng Wang, Xiaoliang Fan, Jianzhong Qi, Chenglu Wen, Cheng Wang, and Rongshan Yu. Federated learning with fair averaging. In Zhi-Hua Zhou, editor, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pages 1615\u20131623. International Joint Conferences on Artificial Intelligence Organization, 8 2021. Main Track.   \n[31] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. Proceedings of Machine Learning and Systems, 2:429\u2013450, 2020.   \n[32] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems in federated learning. Foundations and trends\u00ae in machine learning, 14(1\u20132):1\u2013210, 2021.   \n[33] Di Chai, Leye Wang, Kai Chen, and Qiang Yang. Secure federated matrix factorization. IEEE Intelligent Systems, 36(5):11\u201320, 2020.   \n[34] Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, and Xing Xie. Fedgnn: Federated graph neural network for privacy-preserving recommendation. arXiv preprint arXiv:2102.04925, 2021.   \n[35] Peihua Mai and Yan Pang. Vertical federated graph neural network for recommender system. In International Conference on Machine Learning, pages 23516\u201323535. PMLR, 2023.   \n[36] Weiming Liu, Chaochao Chen, Xinting Liao, Mengling Hu, Jianwei Yin, Yanchao Tan, and Longfei Zheng. Federated probabilistic preference distribution modelling with compactness co-clustering for privacy-preserving multi-domain recommendation. In Proceedings of the 32rd International Joint Conference on Artificial Intelligence, pages 2206\u20132214, 2023.   \n[37] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4\u201324, 2020.   \n[38] Petar Velic\u02c7kovic\u00b4, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.   \n[39] Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. Graph neural networks in recommender systems: a survey. ACM Computing Surveys, 55(5):1\u201337, 2022.   \n[40] Chen Gao, Xiang Wang, Xiangnan He, and Yong Li. Graph neural networks for recommender system. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining, pages 1623\u20131625, 2022.   \n[41] Teng Xiao, Zhengyu Chen, Donglin Wang, and Suhang Wang. Learning how to propagate messages in graph neural networks. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 1894\u20131903, 2021.   \n[42] Yifei Zhang, Hao Zhu, Zixing Song, Piotr Koniusz, Irwin King, et al. Mitigating the popularity bias of graph collaborative filtering: A dimensional collapse perspective. Advances in Neural Information Processing Systems, 36:67533\u201367550, 2023.   \n[43] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. Lightgcn: Simplifying and powering graph convolution network for recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, pages 639\u2013648, 2020.   \n[44] Chuhan Wu, Fangzhao Wu, Lingjuan Lyu, Tao Qi, Yongfeng Huang, and Xing Xie. A federated graph neural network framework for privacy-preserving personalization. Nature Communications, 13(1):3091, 2022.   \n[45] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308\u2013318, 2016.   \n[46] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Sch\u00f6lkopf, and Alexander Smola. A kernel two-sample test. The Journal of Machine Learning Research, 13(1):723\u2013773, 2012.   \n[47] Zirui Wang and Jaime Carbonell. Towards more reliable transfer learning. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10\u201314, 2018, Proceedings, Part II 18, pages 794\u2013810. Springer, 2019.   \n[48] Hao Ma, Dengyong Zhou, Chao Liu, Michael R Lyu, and Irwin King. Recommender systems with social regularization. In Proceedings of the fourth ACM International Conference on Web Search and Data Mining, pages 287\u2013296, 2011.   \n[49] Chaochao Chen, Liang Li, Bingzhe Wu, Cheng Hong, Li Wang, and Jun Zhou. Secure social recommendation based on secret sharing. arXiv preprint arXiv:2002.02088, 2020.   \n[50] Suman Deb Roy, Tao Mei, Wenjun Zeng, and Shipeng Li. Socialtransfer: cross-domain transfer learning from social streams for media applications. In Proceedings of the 20th ACM international conference on Multimedia, pages 649\u2013658, 2012.   \n[51] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. Neural collaborative flitering. In Proceedings of the 26th International Conference on World Wide Web, pages 173\u2013182, 2017.   \n[52] Jianmo Ni, Jiacheng Li, and Julian McAuley. Justifying recommendations using distantlylabeled reviews and fine-grained aspects. In Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 188\u2013197, 2019.   \n[53] Shuowei Cai and Hao Liu. Hstf:l A heterogeneous federated learning framework for misaligned spatiotemporal forecasting. arXiv preprint arXiv:2409.18482, 2024.   \n[54] Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, and Beng Chin Ooi. Feature inference attack on model predictions in vertical federated learning. In 2021 IEEE 37th International Conference on Data Engineering, pages 181\u2013192. IEEE, 2021.   \n[55] Kalervo J\u00e4rvelin and Jaana Kek\u00e4l\u00e4inen. Cumulated gain-based evaluation of ir techniques. ACM Transactions on Information Systems, 20(4):422\u2013446, 2002. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Privacy analysis ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Due to the algorithmic nature of GNN, the source domain embeddings we pass are a function result on the user embeddings and item embeddings. This means that in the event of a successful inference attack, our user item interaction matrix is exposed to the threat of privacy disclosure. We apply differential privacy (DP) to further safeguard embeddings, following the approach of Cai et al.[53]. ", "page_idx": 14}, {"type": "text", "text": "Threat model In this paper, we assume the threat model to be semi-honest (honest-but-curious). Under this threat model, the participants adhere strictly to the FL protocol for collaborative model training. However, they are interested in the sensitive rating data and may attempt to extract as much information as possible from the transferred embeddings. Specifically, these semi-honest parties, i.e. the target domain, may employ inference attacks [54] on the embeddings to reconstruct or infer sensitive user-item interaction matrix of other domains. ", "page_idx": 14}, {"type": "text", "text": "DEFINITION 1 (THE GAUSSIAN MECHANISM). Given a function $f:D\\rightarrow\\mathbb{R}^{d}$ over a dataset $D$ , the Gaussian mechanism is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nF_{G}(x,f(\\cdot),\\epsilon)=f(x)+(r_{1},...r_{k}),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ri is the random noise drawn from N \u223c(0, \u03c32\u22062f 2) and \u03c3 = 2ln(\u03f51.25/\u03b4). In FedGCDR, the intra-domain GAT-based federated model is considered as the function $f(\\bar{\\cdot})$ . ", "page_idx": 14}, {"type": "text", "text": "THEOREM 2. The Gaussian mechanism defined in Definition $^{\\,l}$ preserves $(\\epsilon,\\delta)$ -DP for each publication step $I22J.$ . ", "page_idx": 14}, {"type": "text", "text": "First, we give the definition of the inverse function: ", "page_idx": 14}, {"type": "text", "text": "DEFINITION 2 (INVERSE FUNCTION). Given a function $f:D\\rightarrow\\mathbb{R}^{d}$ over a dataset $D$ , the inverse function $f^{-1}$ is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\nf^{-1}=a r g m i n_{g}\\sum_{i\\in u\\bigcup v}\\|\\;\\mathbf{e}_{i}-g(f(\\mathbf{e}_{u},\\mathbf{e}_{v}))\\;\\|_{2},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\bf e}_{u},{\\bf e}_{v}=E m b e d d i n g(x),x\\in D.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For the target domain, the embeddings received form source domains can be regarded as the functional result of their models. Let the function be $f(\\cdot,\\cdot)$ and the input $e_{u},e_{v}$ is the user embedding and item embedding respectively. The embeddings is the output $f(e_{u},e_{v})$ . The target domain attempts to find a inference attack function $I(\\cdot)$ which is as close to the inverse function as possible. ", "page_idx": 14}, {"type": "text", "text": "DEFINITION 3 (PRIVACY LEAKAGE). Given a function $f:E\\rightarrow\\mathbb{R}^{d}$ over a Embedding set $E$ and an inference function $I$ , the privacy leakage $\\Lambda$ is defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Lambda=\\frac{1}{1+\\frac{1}{|U|}\\sum L e a k_{u}+\\frac{1}{|V|}\\sum L e a k_{v}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\mathit{L e a k}_{u}=\\lVert\\mathbf{\\deltae}_{i}-I_{u}(f(\\mathbf{e}_{u},\\mathbf{e}_{v}))\\rVert_{2},i\\in U},}\\\\ {{\\displaystyle\\mathit{L e a k}_{v}=\\lVert\\mathbf{\\deltae}_{j}-I_{v}(f(\\mathbf{e}_{u},\\mathbf{e}_{v}))\\rVert_{2},j\\in V.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "$\\parallel e-I(f(e_{u},e_{v}))$ $\\Vert_{2}$ reflects the closeness of the reconstructed input to the true input. Therefore, privacy leakage (PLeak) $\\Lambda$ is able to reflect privacy leakage of FedGCDR with the inference function $I(\\cdot)$ . PLeak equal to 1 means a perfect reconstruction, and being close to zero means a bad reconstruction. DP on the embeddings further ensures that attackers cannot perfectly reconstruct the raw data. ", "page_idx": 14}, {"type": "text", "text": "THEOREM 2. If PLeak equals to $^{\\,I}$ with the inference function $I(\\cdot)$ , the function $f(\\cdot,\\cdot)$ is bijection. ", "page_idx": 14}, {"type": "text", "text": "Proof. If the function $f(\\cdot,\\cdot)$ is not bijection, there are $i,j\\in D$ and $i\\neq j$ , but $f(\\mathbf{e}_{u}^{i},\\mathbf{e}_{v}^{i})=f(\\mathbf{e}_{u}^{j},\\mathbf{e}_{v}^{j})$ and $\\check{I}(f(\\mathbf{e}_{u}^{i},\\mathbf{e}_{v}^{i}))$ and $\\bar{I}(f(\\mathbf{e}_{u}^{j},\\mathbf{e}_{v}^{j}))$ . This is a contradiction as the perfect reconstruction requires both $\\mathbf{e}_{u}^{i},\\mathbf{e}_{v}^{i}=\\bar{I}(f(\\mathbf{\\bar{e}}_{u}^{i},\\mathbf{e}_{v}^{i}))$ and $\\mathbf{e}_{u}^{j},\\mathbf{e}_{v}^{j}=I(f(\\mathbf{e}_{u}^{j},\\mathbf{e}_{v}^{j}))$ to achieve $\\Lambda=1$ . Therefore, the function $f(\\cdot,\\cdot)$ must be is bijection. ", "page_idx": 14}, {"type": "text", "text": "THEOREM 3. Given the lipschiz constant $L$ of the function $f$ at $x\\in D$ with the noise generated by Gaussian mechanism $\\mathcal{N}$ on embeddings. If $f(\\mathbf{e}_{u},\\mathbf{e}_{v})+\\mathcal{N}\\in f$ , the distance between $x$ to the reconstructed data of the attack $I(\\cdot)$ which achieves $\\Lambda=1$ is bounded by $\\frac{|\\mathcal{N}|}{L}$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. By Theorem 2, we have for $x\\in D$ and $v\\,\\in\\,f,I(f(\\mathbf{e}_{u},\\mathbf{e}_{v}))=(\\mathbf{e}_{u},\\mathbf{e}_{v})$ and $f(I(v))=v$ , From the Lipschitz continuous, ", "page_idx": 15}, {"type": "equation", "text": "$$\n|e-I(f(\\mathbf{e}_{u},\\mathbf{e}_{v})+\\mathcal{N})|\\ge\\frac{|f(\\mathbf{e}_{u},\\mathbf{e}_{v})-(f(\\mathbf{e}_{u},\\mathbf{e}_{v})+\\mathcal{N})|}{L}=\\frac{|\\mathcal{N}|}{L}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, by perturbing the source domain embedding with Gaussian mechanism, the reconstructed data of the ideal attack deviates from the real data and prevents a perfect reconstruction $(i.e.,\\Lambda=1)$ . ", "page_idx": 15}, {"type": "text", "text": "B Cost analysis ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Due to the complexity of the FedGCDR pipeline, we perform a theoretical analysis of the computational and communication cost of FedGCDR accordance with the HVH pipeline including horizontal source domain training, vertical positive knowledge transfer module and horizontal positive knowledge activation module. ", "page_idx": 15}, {"type": "text", "text": "B.1 Computational cost ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Given a GAT model, let $V$ be the number of nodes, $E$ be the number of edges, and $F$ the embedding size. The computational cost of one propagation layer of classic GAT framework is $O(V F F^{\\prime}+E F^{\\bar{\\prime}})$ [38]. In the horizontal source domain training, our model is a simplified GAT variants which discard feature transformation and non-linear activation. For a $N^{K}$ layer model, the simplified computational cost is $O(N^{K}E F)$ . In the vertical positive knowledge transfer module, space mapping is carried by a $N^{m}$ layers\u2019 MLP with computational cost $O(N^{m}F^{2})$ . In the horizontal positive knowledge activation module, the first part is the simplified GAT model and the second part is the fine-tuning model with computational cost ${\\cal O}(F^{2})$ . In conclusion, for the FedCDR framework with $N^{\\mathcal{D}}$ domains, $T^{G}$ GAT-based federated model training epochs, and $T^{F}$ fine-tuning epochs, the total computational cost is $O(T^{G}(N^{\\cal D}N^{K}E F+N^{m}F^{2})\\stackrel{\\leftarrow}{+}\\dot{T}^{F}F^{2}))$ . Cause $N^{m}F^{2}\\overset{\\mathcal{=}}{\\ll}N^{\\mathcal{D}}N^{K}E F$ , we get the final computational cost $O(T^{G}N^{D}N^{K}E\\dot{F}+T^{F}F^{2})\\sp{\\dagger}$ ). ", "page_idx": 15}, {"type": "text", "text": "B.2 Communication cost ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In FedGCDR, the global model and item embeddings are held by the domain server. Let $I$ be the number of items and $F$ be the embedding size. The space complexity of global model and item embeddings are ${\\cal O}(F)$ and $O(I F)$ respectively. In the horizontal source domain training, the domain server distributes the global model and item embeddings and get the gradient with the same size. The communication cost is $O(F+I F)$ . In the vertical positive knowledge transfer module, the $N^{m}$ layers\u2019 MLP and its gradients are transmitted with the communication cost $O(N^{m}F^{2})$ . In the horizontal positive knowledge activation module, the target domain additionally perform a fine-tuning stage with communication cost $O(I F)$ . In conclusion, for the FedCDR framework with $N^{u}$ users, $T^{\\check{G}}$ federated model training epochs, and $T^{F}$ fine-tuning epochs, the total communication cost is $O(T^{G}N^{u}(N^{m}F^{2}{+}F{+}I F\\bar{)}{+}\\dot{T}^{F}N^{u}I F)$ . Cause $N^{m}F^{\\tilde{2}}{+\\dot{F}}\\ll I F$ , we get ${\\cal O}(N^{u}I F(T^{G}\\!+\\!T^{F}))$ . According to the expression, the communication cost of our FedGCDR is basically equivalent to the cost of two HFL progress. The cost is reduced because knowledge transfer totally takes place in user space, thus avoiding large-scale information exchange. ", "page_idx": 15}, {"type": "text", "text": "C Experimental details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "C.1 Dataset details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The Amazon dataset we used is the 2018 version and can be easily accessed in https://cseweb. ucsd.edu/\\~jmcauley/datasets/amazon_v2/. The basis of our domain selection strategy is the amount of data before performing data filtering. Thus, we sorted the domains contained in the Amazon dataset based on the amount of data in descending order and selected the top 16 domains. Similarly, the Amazon-4 and Amazon-8 datasets were selected accordingly. The only exception is that we prioritized the Movie domain, which has a relatively small amount of source data, based on popularity. In addition to multi-domain experiments, we randomly selected 2500 overlapping users in the Books domain and CDs domain to construct the dataset Amazon-Dual, so as to validate the performance of our FedGCDR in the conventional dual-domain scenarios where users full-overlap. The processing details are shown in Table 5. The bottleneck time of FedGCDR is the federated-GAT training time in each domain, and we also show it in Table 5. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "table", "img_path": "UBpPOqrBKE/tmp/5d2a4c27917d53edddbb1419163ca9aa2f5c5f386540d408ba2ac4c8229b23f7.jpg", "table_caption": ["Table 5: Processing details on Amazon Dataset. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "C.2 Implement details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We provide the implemented details of our proposed model and baselines. We set batch size $=256$ and latent $\\mathrm{dim}=8$ for all domains. The number of propagation layer of GAT-base federated model is set to 2. The MLP has two hidden layers with $\\mathrm{size}{=}\\{16,4\\}$ .Considering the trade-off between recommendation performance and privacy preservation, we set $\\epsilon$ to 8 and $\\sigma$ to $10^{-5}$ . We set $\\scriptstyle\\alpha=0.01$ and $\\beta{=}0.01$ which are the two hyper-parameters of the objective function $L_{G A T}(\\cdot)$ . When training our models, we choose Adam as the optimizer, and set the learning rate to 0.01 both in GAT-based federated model training and the fine-tuning stage. To evaluate the recommendation performance, we use the leave-one-out method which is widely used in recommender systems [51]. Specifically, we held out the latest interaction as the test set and utilized the remaining data for training. Then, we follow the common strategy which randomly samples 99 negative items that are not interacted with by the user for the rank list generation of the test set. We consider the top- $k$ recommendation task as the main experiment so we choose metrics including Hit Ratio $(\\mathrm{HR})@\\mathrm{K}$ score and the Normalized Discounted Cumulative Gain $(\\mathrm{NDCG})\\mathbb{G}\\mathrm{K}$ [55] of the top-K ranked items with $K{=}5$ , 10. We conduct the experiments on three groups of random seeds and report the average results. We conduct all the experiments on NVIDIA 3090 GPUs. ", "page_idx": 16}, {"type": "text", "text": "D Additional experimental results ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "D.1 Neagtive transfer on HR $@$ 10 and NDCG@10. ", "text_level": 1, "page_idx": 16}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/0e083a1221e7953fe53abc3017fdb37e1f541d84097cf1a35ebd462bc914ca24.jpg", "img_caption": ["Figure 6: Illustrations of negative transfer on HR $@10$ and NDCG@10 "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "For $\\mathrm{HR}@10$ and $\\operatorname{NDCG}@10$ in Figure 6, our method and baselines show similar trends to the previous $\\operatorname{HR}(\\mathcal{O}5$ and $\\mathrm{NDCG}@5.$ . Compared to Figure 6, the slight difference is that FedCT\u2019s $\\operatorname{HR}\\mathcal{O}\\,10$ ", "page_idx": 16}, {"type": "text", "text": "performance is better on Amazon- ${\\mathit{8@C D s}}$ than on Amazon- ${\\mathcal{A}}@\\mathrm{CDs}$ . We believe that the reason is the poor performance of FedCT on Amzon- ${4@}$ CDs lowers the threshold for negative transfer of the newly added source domain. ", "page_idx": 17}, {"type": "text", "text": "D.2 Privacy budget ", "text_level": 1, "page_idx": 17}, {"type": "image", "img_path": "UBpPOqrBKE/tmp/e39f1a76e7c0bf95215fcae2bbeed06372a56294e2c226f446a3402398ab38e2.jpg", "img_caption": ["Figure 7: The effect of $\\epsilon$ in DP on model performance. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "To study the effects of privacy budget $\\epsilon$ on the model performance, we vary the privacy budget $\\epsilon=\\{4,8,16,32,64\\}$ to affect the $\\sigma$ . We experimented on the Amazon-16 with CDs as the target domain and fix $\\delta~=~10\\{-5~\\$ . We report the results Figure 7. From that we can observe that the model\u2019s performance decreases as $\\epsilon$ decreases.The degradation in model performance suggests that our approach struggles to counteract the effects of high-intensity noise in a large number of domains, but the model performance is not completely destroyed by Gaussian noise. Thus, there is a trade-off between accuracy and privacy, where a smaller $\\epsilon$ value adds more noise to embeddings for stronger privacy preservation but leads to more prediction error. Therefore, to balance the data privacy preservation capacity and the model performance, we set it as $\\epsilon=8$ . ", "page_idx": 17}, {"type": "text", "text": "E Broader impacts ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Our proposed FedGCDR is tailored for BS-CDR, focusing on the privacy and negative transfer problems. CDR is widely uesd, while BS-CDR is generic and close to the reality. Our approach can better mine user preferences and effectively protect privacy. On the one hand, users will benefti from more accurate recommendations and thus have a better experience in shopping, watching movies, etc. On the other hand, various economic entities can gain more profits. ", "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We have claimed the contributions and scope in lines 5-7 and 69-75. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: We have discussed the limitations in lines 318-325. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 18}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We have given the full set of assumptions and proof in Appendices A and B. Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We have provided experimental setup in section 4 and more experimental details in Appendix C. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We provide the code in supplemental material. For datasets, we provide the data processing code and the public benchmark is easy to access via the link in code file. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We have provided implement details in Appendix C.2 which contains data splits, hyper-parameters, type of optimizer, etc. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: Our reported results are averaged over 3 runs with different random seeds. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We have provided information the computer resources in Appendices C. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 21}, {"type": "text", "text": "Answer: answerYes ", "page_idx": 21}, {"type": "text", "text": "Justification: We have fully reviewed the NeurIPS Code of Ethics. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 21}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: We have discussed social impacts in Appendix E. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: Our method well-address the privacy issure and poses no such risks. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We have cited the original paper and proviced necessary information in the line 246 and Appendix C.1. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 22}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: We totally use public benchmarks. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}]