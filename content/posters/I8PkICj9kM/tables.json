[{"figure_path": "I8PkICj9kM/tables/tables_6_1.jpg", "caption": "Table 1: Zero-shot FID comparison with different score distillation methods. We report FID scores of text-to-image generation using 5K captions randomly sampled from the COCO dataset. The best score distillation result is indicated in bold, while the second best is underlined.", "description": "This table compares the performance of several score distillation methods for text-to-image generation.  The FID (Fr\u00e9chet Inception Distance) and CLIP FID scores are reported, which are lower is better, measuring the quality of generated images compared to real images.  The time taken per sample generation is also provided for each method.  The table highlights the best-performing method in bold and the second-best in underlined font.", "section": "4 Experiments"}, {"figure_path": "I8PkICj9kM/tables/tables_7_1.jpg", "caption": "Table 1: Zero-shot FID comparison with different score distillation methods. We report FID scores of text-to-image generation using 5K captions randomly sampled from the COCO dataset. The best score distillation result is indicated in bold, while the second best is underlined.", "description": "This table compares the Fr\u00e9chet Inception Distance (FID) scores and CLIP FID scores of different score distillation methods for zero-shot text-to-image generation.  Lower FID scores indicate better image quality. The results are based on 5,000 captions from the COCO dataset.  The table also shows the time taken per sample generation for each method.  It highlights the best performing method in bold and the second-best method in underlined font.", "section": "4 Experiments"}, {"figure_path": "I8PkICj9kM/tables/tables_9_1.jpg", "caption": "Table 1: Zero-shot FID comparison with different score distillation methods. We report FID scores of text-to-image generation using 5K captions randomly sampled from the COCO dataset. The best score distillation result is indicated in bold, while the second best is underlined.", "description": "This table presents a comparison of different score distillation methods for text-to-image generation, evaluated using the Fr\u00e9chet Inception Distance (FID) score.  The methods are compared on their ability to generate high-quality images from text prompts,  using a zero-shot setting where the models have not been specifically trained on the COCO dataset. The table shows the FID scores, CLIP FID scores (another metric for image quality), and the time required per sample for each method. The best performing methods are highlighted.", "section": "4 Experiments"}]