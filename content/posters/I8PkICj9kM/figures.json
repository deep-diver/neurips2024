[{"figure_path": "I8PkICj9kM/figures/figures_2_1.jpg", "caption": "Figure 1: Optimization with diffusion models as approximation of a Schr\u00f6dinger Bridge Problem (SBP). (a) We propose to formulate optimization with diffusion models as bridging the distribution of the current optimized image xe to the target distribution under a dual-bridge framework (a). Current methods can be interpreted as approximating the optimal transport ESBP between these distributions via the difference between projections of a noised image xe,t onto the two distributions. This analysis reveals two sources of error: (1) these gradients are linear approximations of the optimal path, as illustrated in (a), and (2) the source distribution used for computing this approximation (e.g., the unconditional distribution in SDS [48]) may not be aligned with the current distribution, illustrated in (b).", "description": "This figure illustrates the core idea of the paper: viewing score distillation sampling (SDS) methods as approximating the solution to a Schr\u00f6dinger Bridge problem.  Panel (a) shows how SDS methods try to bridge the gap between a source distribution (e.g., noisy or corrupted images) and a target distribution (natural images) by iteratively moving points in the source distribution closer to the target. However, the figure points out two key limitations of this approach: the linear approximation of the optimal transport path and an inaccurate estimate of the source distribution.  Panel (b) focuses on the second limitation \u2013 the mismatch between the assumed source distribution and the actual distribution of the current optimized images, highlighting another potential source of error in standard SDS methods.", "section": "3 Method"}, {"figure_path": "I8PkICj9kM/figures/figures_4_1.jpg", "caption": "Figure 1: Optimization with diffusion models as approximation of a Schr\u00f6dinger Bridge Problem (SBP). (a) We propose to formulate optimization with diffusion models as bridging the distribution of the current optimized image xe to the target distribution under a dual-bridge framework (a). Current methods can be interpreted as approximating the optimal transport ESBP between these distributions via the difference between projections of a noised image xe,t onto the two distributions. This analysis reveals two sources of error: (1) these gradients are linear approximations of the optimal path, as illustrated in (a), and (2) the source distribution used for computing this approximation (e.g., the unconditional distribution in SDS [48]) may not be aligned with the current distribution, illustrated in (b).", "description": "This figure illustrates the proposed framework for understanding score distillation optimization using diffusion models.  Panel (a) shows the optimization process as a bridge between the current image distribution and the target distribution, highlighting the approximation inherent in existing methods. Panel (b) emphasizes the source distribution mismatch error. This helps to visualize the core idea of the paper, which is to reformulate optimization with diffusion models as a Schr\u00f6dinger Bridge Problem to explain existing methods and motivate a new, improved one.", "section": "3 Method"}, {"figure_path": "I8PkICj9kM/figures/figures_6_1.jpg", "caption": "Figure 3: Text-to-image generation results with COCO Captions. We compare different score distillation methods for generating images with COCO captions by optimizing a randomly initialized image. DDIM sampling indicates the lower bound that the diffusion model can achieve. VSD [70] and our method generate the least color artifacts while ours is more efficient than VSD.", "description": "This figure compares different score distillation methods (DDIM Sampling, SDS, NFSD, CSD, VSD, and the proposed method) for text-to-image generation using COCO captions.  Each method starts with a randomly initialized image and optimizes it to match the caption.  The results demonstrate the effectiveness of the proposed method in generating high-quality images with fewer color artifacts compared to other baselines, especially VSD, while also being computationally more efficient.", "section": "4.1 Zero-Shot Text-to-Image Generation with Score Distillation"}, {"figure_path": "I8PkICj9kM/figures/figures_7_1.jpg", "caption": "Figure 4: Text-guided NeRF optimization with different score distillation methods. We make a fair comparison of SDS and VSD for text-to-3D generation. For each generation, we show three uniformly sampled views. SDS results like the cottage and pepper mill still suffer from over-saturation problems, while ours and VSD can produce realistic details, color, and texture.", "description": "This figure compares the results of text-guided NeRF optimization using different score distillation methods: SDS, VSD, and the proposed method. Three uniformly sampled views are shown for each generated 3D object. The results show that the proposed method and VSD produce more realistic details, colors, and textures compared to SDS, which exhibits over-saturation artifacts.", "section": "4.2 Text-guided NeRF Optimization"}, {"figure_path": "I8PkICj9kM/figures/figures_8_1.jpg", "caption": "Figure 5: Painting-to-Real comparison. We compare our gradient in optimization to image restoration and image-conditional generation baselines. While SDEdit produces convincing textures, it is difficult to find a strength value that balances structure and quality. Other baselines fail to reproduce natural image quality, while our method produces the best combination of quality and faithfulness.", "description": "This figure compares several methods for enhancing the realism of paintings by optimizing them using different approaches.  The methods include a simple plug-and-play method, score distillation sampling (SDS), SDEdit (with a specific strength setting), CycleGAN, and the proposed method from the paper.  The results demonstrate that the proposed method outperforms others in maintaining faithfulness to the original painting while significantly increasing realism.", "section": "4.3 Painting-to-Real"}, {"figure_path": "I8PkICj9kM/figures/figures_9_1.jpg", "caption": "Figure 5: Painting-to-Real comparison. We compare our gradient in optimization to image restoration and image-conditional generation baselines. While SDEdit produces convincing textures, it is difficult to find a strength value that balances structure and quality. Other baselines fail to reproduce natural image quality, while our method produces the best combination of quality and faithfulness.", "description": "This figure compares the results of painting-to-real image generation using different methods: the proposed method, SDEdit (with different strength values), Plug-and-Play, and CycleGAN.  The results show that the proposed method achieves a better balance between structure and quality compared to other methods.  SDEdit shows promising results, but struggles to find the optimal strength parameter balance, while the other methods fail to achieve natural image quality.", "section": "4.3 Painting-to-Real"}, {"figure_path": "I8PkICj9kM/figures/figures_15_1.jpg", "caption": "Figure A1: 3D sketch-to-real. We introduce a conditional generation task in 3D where a coarse human-drawn mesh is optimized into a high-quality mesh. While SDS and our gradient both adhere to the prompt and shape conditions, our method produces higher fidelity colors and texture.", "description": "This figure shows a comparison of 3D sketch-to-real generation using two different methods: the proposed method and the SDS baseline. The input is a coarse 3D sketch of a flower. The proposed method generates a high-quality 3D model of a flower with realistic colors and textures, while the SDS baseline generates a lower-quality model with less detail and less realistic colors.", "section": "B More Visual Results"}, {"figure_path": "I8PkICj9kM/figures/figures_16_1.jpg", "caption": "Figure A2: Diffusion illusions. We generate overlaid optic illusions with SDS and our method. While SDS suffers from color artifacts, our methods produce more details and proper color.", "description": "This figure compares the results of generating overlaid optical illusions using two different methods: Score Distillation Sampling (SDS) and the proposed method from the paper.  The top row shows the base and rotator images used for both methods. The bottom rows illustrate the generated illusions at 0\u00b0, 90\u00b0, 180\u00b0, and 270\u00b0 rotations, respectively, for each method. The results demonstrate that the proposed method produces significantly improved color accuracy, realism and detail compared to SDS, which suffers from color artifacts.", "section": "B More Visual Results"}, {"figure_path": "I8PkICj9kM/figures/figures_16_2.jpg", "caption": "Figure 3: Text-to-image generation results with COCO Captions. We compare different score distillation methods for generating images with COCO captions by optimizing a randomly initialized image. DDIM sampling indicates the lower bound that the diffusion model can achieve. VSD [70] and our method generate the least color artifacts while ours is more efficient than VSD.", "description": "This figure compares the results of different score distillation methods for text-to-image generation using COCO captions.  Each method starts with a randomly initialized image and refines it using the respective method.  DDIM sampling serves as a baseline representing the lower bound on image quality achievable by the diffusion model itself. The figure highlights that both VSD (Variational Score Distillation) and the proposed method in the paper yield images with fewer color artifacts than other methods, but that the proposed method achieves better efficiency.", "section": "4 Experiments"}, {"figure_path": "I8PkICj9kM/figures/figures_17_1.jpg", "caption": "Figure A4: Comparison with more text-to-3D baselines. We apply our two-stage optimization as a drop-in replacement of SDS in Fantasia3D [9], Magic3D [35] and CSD [76] for texture refinement. We notice that this change greatly improves details and visual quality and reduces SDS artifacts.", "description": "This figure compares the results of applying the proposed two-stage optimization method (replacing SDS) within three different text-to-3D generation baselines: Fantasia3D, Magic3D, and CSD. The improvements in detail, visual quality, and reduction of SDS artifacts are highlighted.", "section": "B More Visual Results"}, {"figure_path": "I8PkICj9kM/figures/figures_17_2.jpg", "caption": "Figure A5: Ablation study of negative prompts. We compare SDS results with those from the two-stage optimization (bridge) using our negative prompts and five sets of negative prompts generated by GPT (GPT 1 is the first set, GPT 2 second, GPT 3 third, etc.). All negative prompts produce similar results and outperform the SDS baseline.", "description": "This figure shows the results of an ablation study on the impact of different negative prompts in the two-stage optimization method.  It compares the results of using the authors' proposed negative prompts against five alternative sets generated using GPT-4.  The goal was to determine if the choice of negative prompt significantly affected the results. The results show that all negative prompts produce similar improvements, outperforming the original Score Distillation Sampling (SDS) baseline.", "section": "B More Visual Results"}, {"figure_path": "I8PkICj9kM/figures/figures_18_1.jpg", "caption": "Figure A6: Ablation study of our method without stage 1. We show directly optimizing with Ysrc from the start can undermine the quality of the geometry and produce unnecessary content.", "description": "This figure shows an ablation study comparing three different optimization approaches: (a) using only the second stage of the proposed method (SDS + Stage 2 source prompt), (b) using only the first stage (SDS), and (c) using both stages (Ours). The results demonstrate that starting the optimization directly with the second stage's source prompt (Ysrc) can negatively impact the quality of the generated geometry, leading to unnatural or undesirable elements.  In contrast, using both stages of the proposed method produces significantly better results in terms of geometric accuracy and overall coherence.", "section": "B More Visual Results"}, {"figure_path": "I8PkICj9kM/figures/figures_19_1.jpg", "caption": "Figure 3: Text-to-image generation results with COCO Captions. We compare different score distillation methods for generating images with COCO captions by optimizing a randomly initialized image. DDIM sampling indicates the lower bound that the diffusion model can achieve. VSD [70] and our method generate the least color artifacts while ours is more efficient than VSD.", "description": "This figure compares several score distillation methods for text-to-image generation using COCO captions.  Each method starts with a randomly initialized image and iteratively refines it using the respective method's gradient.  The results showcase the visual quality and presence of artifacts (e.g., color distortions) for each method.  The figure highlights that VSD and the proposed method produce images with the fewest artifacts, while the proposed method is more computationally efficient.", "section": "4.1 Zero-Shot Text-to-Image Generation with Score Distillation"}]