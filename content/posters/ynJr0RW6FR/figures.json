[{"figure_path": "ynJr0RW6FR/figures/figures_1_1.jpg", "caption": "Figure 1: Given a pretrained 3DGS model of the target scene and its paired style reference, ReGS enables real-time stylized view synthesis (at 134 FPS) with high-fidelity texture well-aligned with the reference. In contrast, only optimizing the appearance of 3DGS (denoted as Naive 3DGS), as previous methods [8, 9, 3, 10, 6] do, fails to capture many texture details in the reference. We tackle the challenges in high-fidelity appearance editing with a texture-guided control mechanism that is significantly more effective than the default density control [11] in addressing texture underfitting. Side-by-side comparisons with default density control can be found in Figure 5.", "description": "This figure compares the results of ReGS with a naive approach for reference-based scene stylization using 3D Gaussian Splatting.  ReGS demonstrates its ability to generate high-fidelity, real-time stylized views by effectively addressing texture underfitting, resulting in more detailed and accurate texture matching compared to simply optimizing the appearance.", "section": "1 Introduction"}, {"figure_path": "ynJr0RW6FR/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of ReGS. (a) The proposed method starts with a pretrained content 3DGS of the target scene, and (b) outputs a stylized 3DGS that follows the reference. (c) We propose Texture-Guided Gaussian Control that can progressively resolve texture underfitting by automatically locating responsible Gaussians and adjusting local geometry layout for fitting high-frequency textures. (d) Once training is done, our method enables real-time stylized scene navigation.", "description": "This figure shows the process of ReGS. First, a pretrained 3D Gaussian splatting (3DGS) model of the target scene is used as input (a). Then, the stylized 3DGS model is obtained by applying Texture-Guided Gaussian Control to resolve texture underfitting and adjust local Gaussian geometry (b, c). Finally, real-time stylized scene navigation is enabled by rendering the stylized 3DGS model (d).", "section": "3 Method"}, {"figure_path": "ynJr0RW6FR/figures/figures_4_1.jpg", "caption": "Figure 3: Examples of (a) rendered depth maps using Eq.3 and (b) synthesized stylized pseudo views.", "description": "This figure shows examples of rendered depth maps and synthesized stylized pseudo views.  The depth maps (a) are created using equation 3 from the paper, representing the depth information of the scene. These depth maps are then used to generate stylized pseudo views (b) through a depth-based warping technique, creating views that are consistent with the reference style image but from slightly different viewpoints. These pseudo views provide additional training supervision during the stylization process, helping to ensure view consistency in the final stylized output.", "section": "3 Method"}, {"figure_path": "ynJr0RW6FR/figures/figures_6_1.jpg", "caption": "Figure 4: Ablation study on different components of ReGS. (a) Optimizing only the appearance of a 3DGS model cannot reproduce texture details. (b) Removing depth regularization causes Gaussians to float out from the surface and distort the origin geometry. (c) Without pseudo-view supervision, results lack view consistency. (d) Our full model produces the best results that faithfully respect the texture in the reference.", "description": "This ablation study shows the importance of each component in ReGS.  (a) demonstrates that simply adjusting appearance is insufficient for high-fidelity texture reproduction. (b) shows how depth regularization prevents geometric distortions. (c) highlights the need for pseudo-view supervision to maintain view consistency. (d) showcases the superior results of the complete ReGS model.", "section": "4 Ablation Study"}, {"figure_path": "ynJr0RW6FR/figures/figures_7_1.jpg", "caption": "Figure 5: Effectiveness of Texture-Guided Control. We conduct controlled experiments by limiting the number of newly densified Gaussians throughout optimization. The pretrained model contains 0.3M Gaussians. The proposed texture-guided control can more faithfully reproduce the target texture details with a small number of Gaussians added (0.05M). The default strategy struggles to capture high-frequency details, even with a large number of Gaussians added (0.25M).", "description": "This figure compares the results of using the proposed texture-guided control method versus the default density control method in 3D Gaussian Splatting for scene stylization.  By limiting the number of new Gaussians added during optimization, the experiment shows that the texture-guided approach can achieve significantly better results in capturing fine details, even with a much smaller number of additional Gaussians. The default approach struggles to capture high-frequency texture details, even when a larger number of Gaussians is added.", "section": "4 Experiments"}, {"figure_path": "ynJr0RW6FR/figures/figures_8_1.jpg", "caption": "Figure 6: Visual comparisons with state-of-the-art methods. Paired reference and content view are shown on the left. Our method produces visual-compelling results that precisely follow the texture of the given reference, including the challenging high-frequency details such as the leaf in the second example. Baseline methods [10, 8, 4] either lack semantic consistency or produce artifacts.", "description": "This figure compares the results of ReGS against three state-of-the-art methods (ARF, Ref-NPR, and SNeRF) on three different scenes.  Each row shows a scene with its reference image and the results from each method. ReGS demonstrates a superior capability to accurately reproduce the textures from the reference image, especially high-frequency details that other methods struggle to capture. The other methods either miss crucial texture details or introduce visual inconsistencies.", "section": "4.3 Compare with State-of-the-art Methods"}, {"figure_path": "ynJr0RW6FR/figures/figures_9_1.jpg", "caption": "Figure 7: Application: appearance editing. Given a pretrained 3DGS model, our method allows users to make 3D appearance editing with ease by drawing on a 2D rendered view. Unlike NeRFs [14], just optimizing the appearance of a 3DGS model cannot robustly handle user edits.", "description": "This figure demonstrates the application of ReGS for appearance editing.  A pre-trained 3D Gaussian Splatting (3DGS) model is used as a starting point. The user can directly edit the appearance of the scene by drawing on a 2D rendering.  The key takeaway is that ReGS can seamlessly integrate these edits back into the 3D model, unlike methods that only optimize appearance, which struggle to handle user edits effectively, especially on surfaces with high detail.", "section": "5 Application: Appearance Editing"}, {"figure_path": "ynJr0RW6FR/figures/figures_15_1.jpg", "caption": "Figure 8: Additional ablation study on structured densification. Structured densification allows ReGS to create dense set of tiny Gaussians for representing high-frequency details. This enables our method to quickly infill the most of textures with a small amount of Gaussians tiny created ((a)). In contrast, the default strategy fails to express many details even with a large amount of Gaussians added ((d)).", "description": "This figure shows an ablation study comparing the proposed structured densification method with the default method. The structured densification method is shown to effectively capture high-frequency details with fewer Gaussians, while the default method struggles to do so even with a large number of Gaussians.", "section": "C Additional Ablation Study"}, {"figure_path": "ynJr0RW6FR/figures/figures_16_1.jpg", "caption": "Figure 9: Ablation study on Texture Guidance (i.e., color-gradient guidance). Replacing texture guidance with positional-gradient guidance (bottom) fails to capture texture details.", "description": "This ablation study compares the performance of ReGS using color-gradient guidance versus positional-gradient guidance.  The results show that using color gradients to guide the texture-based control mechanism is crucial for capturing high-frequency texture details.  In contrast, positional gradients are insufficient for accurately reproducing fine details of the reference texture.", "section": "4.2 Ablation Study"}, {"figure_path": "ynJr0RW6FR/figures/figures_16_2.jpg", "caption": "Figure 10: Ablation study on the number of Gaussians for each responsible Gaussian to be split. Small number cannot capture full details. Performance becomes saturated as the number grows.", "description": "This ablation study explores the impact of varying the number of new Gaussians generated when splitting a responsible Gaussian during the texture-guided control process. The results demonstrate that using a small number of Gaussians fails to capture fine details, while increasing the number beyond a certain point yields diminishing returns, indicating saturation in performance improvement. The optimal balance is found at a specific number of new Gaussians, demonstrating that the proposed structured densification strategy effectively enhances high-frequency texture representation without unnecessary computational overhead.", "section": "4.2 Ablation Study"}, {"figure_path": "ynJr0RW6FR/figures/figures_16_3.jpg", "caption": "Figure 4: Ablation study on different components of ReGS. (a) Optimizing only the appearance of a 3DGS model cannot reproduce texture details. (b) Removing depth regularization causes Gaussians to float out from the surface and distort the origin geometry. (c) Without pseudo-view supervision, results lack view consistency. (d) Our full model produces the best results that faithfully respect the texture in the reference.", "description": "This ablation study demonstrates the importance of each component in the ReGS model.  (a) shows that only optimizing appearance leads to a lack of fine texture detail. (b) illustrates that the depth regularization is crucial for maintaining the correct geometry.  (c) highlights the necessity of pseudo-view supervision for view consistency. Finally, (d) showcases the superior performance of the complete ReGS model, accurately reproducing the reference texture.", "section": "4 Ablation Study"}, {"figure_path": "ynJr0RW6FR/figures/figures_17_1.jpg", "caption": "Figure 2: An overview of ReGS. (a) The proposed method starts with a pretrained content 3DGS of the target scene, and (b) outputs a stylized 3DGS that follows the reference. (c) We propose Texture-Guided Gaussian Control that can progressively resolve texture underfitting by automatically locating responsible Gaussians and adjusting local geometry layout for fitting high-frequency textures. (d) Once training is done, our method enables real-time stylized scene navigation.", "description": "This figure provides a visual overview of the ReGS method.  It shows the process, starting with a pretrained 3D Gaussian Splatting (3DGS) model of the target scene and a style reference image.  The core of the method, Texture-Guided Gaussian Control, is highlighted, showing how it addresses texture underfitting by adjusting the geometry and arrangement of Gaussians. The final result is real-time stylized scene navigation.", "section": "3 Method"}, {"figure_path": "ynJr0RW6FR/figures/figures_18_1.jpg", "caption": "Figure 6: Visual comparisons with state-of-the-art methods. Paired reference and content view are shown on the left. Our method produces visual-compelling results that precisely follow the texture of the given reference, including the challenging high-frequency details such as the leaf in the second example. Baseline methods [10, 8, 4] either lack semantic consistency or produce artifacts.", "description": "This figure compares the results of ReGS against three other state-of-the-art methods for reference-based 3D scene stylization: ARF, SNeRF, and Ref-NPR.  Each row shows a different scene with its reference image on the far left.  The following columns show the results from each method, highlighting the superior detail and accuracy of ReGS, especially regarding high-frequency textures. ARF and SNeRF often fail to achieve the level of detail or semantic consistency as ReGS, while Ref-NPR produces some artifacts.", "section": "4 Experiments"}, {"figure_path": "ynJr0RW6FR/figures/figures_19_1.jpg", "caption": "Figure 15: More visual comparison results with Ref-NPR [10]. Our method faithfully reproduce the texture in reference image. In contrast, Ref-NPR [10] produces images with lower quality.", "description": "This figure compares the results of the proposed method, ReGS, against Ref-NPR, another reference-based stylization method.  It shows three different scenes: microphones, drums, and flowers. For each scene, the content view, reference image, Ref-NPR results, and ReGS results are presented. The results illustrate that ReGS better reproduces the texture of the reference image compared to Ref-NPR, which shows some artifacts.", "section": "4.3 Compare with State-of-the-art Methods"}]