[{"figure_path": "y9sHKrdnRt/figures/figures_2_1.jpg", "caption": "Figure 1: (a) Mutual information of different methods between generated masked patches and unmasked patches. We generate masked noisy patches from unmasked noisy patches and calculate mutual information I(Xunmasked, Xmasked) under various noise scales. The \u2018vanilla clean images\u2019 and \u2018vanilla noisy images\u2019 denote the real clean/noisy images, which are the upper bound of the mutual information. The other lines are computed with the generated images by three strategies. (b) Mask graph [46] in different reconstruction targets. The left yellow ellipse denotes unmasked patches and the right green one denotes masked patches. The black arrow denotes the positive pairs to pull in.", "description": "This figure demonstrates the impact of noise variance on the mutual information between unmasked and masked patches for different methods.  Subfigure (a) shows that as noise variance increases, the mutual information in noisy patches generated by MDT [13] and MaskDiT [48] decreases sharply, while mutual information in vanilla noisy images decreases slowly. This suggests insufficient contextual information exploitation in noisy-to-noisy mask reconstruction. Subfigure (b) illustrates the mask graph [46] concept, highlighting the difference in reconstruction targets between clean patches and noisy patches.", "section": "3.2 Contextual Information in Noisy Patches Reconstruction"}, {"figure_path": "y9sHKrdnRt/figures/figures_5_1.jpg", "caption": "Figure 2: Framework of the proposed MC-DiT. (a) Pre-training. MC-DiT introduces unmasked clean patches and learns sufficient contextual information by reconstructing unmasked clean patches from masked clean patches. Two complementary EMA branches are developed to avoid model collapse. (b) Finetuning. MC-DiT is trained with unmasked patches for denoising.", "description": "This figure illustrates the architecture of the proposed MC-DiT model for image generation.  Panel (a) shows the pre-training stage, where the model learns contextual information by reconstructing unmasked clean image patches from masked clean patches.  This process is enhanced by two parallel branches (EMA branches) to mitigate model collapse. Panel (b) depicts the fine-tuning stage, where the pre-trained model is further trained on unmasked patches to improve its performance in denoising and image generation.", "section": "3 Proposed Method"}, {"figure_path": "y9sHKrdnRt/figures/figures_8_1.jpg", "caption": "Figure 3: Training loss and FID for DiT-B/2, MaskDit-B/2, and MC-DiT-B/2 during training.", "description": "This figure shows two sub-figures: (a) Training loss and (b) FID (Fr\u00e9chet Inception Distance) scores.  Both sub-figures plot the training curves of three different models: DiT-B/2, MaskDiT-B/2, and MC-DiT-B/2.  Sub-figure (a) illustrates the training loss over iterations, indicating that MC-DiT-B/2 converges faster than the other two.  Sub-figure (b) displays the FID scores during training, which represent the quality of the generated images. Lower FID scores are better, and this sub-figure demonstrates that MC-DiT-B/2 achieves significantly lower FID scores, indicating better image quality, after around 100k iterations.", "section": "4 Experiments"}, {"figure_path": "y9sHKrdnRt/figures/figures_8_2.jpg", "caption": "Figure 4: Comparison of 256 \u00d7 256 images generated by MDT, MaskDiT and MC-DiT. Various details are strange in images generated by MDT and MaskDiT.", "description": "This figure is a comparison of images generated by three different methods: MDT, MaskDiT, and MC-DiT. Each column represents a different method. Each row contains four images generated using the same method. The images show that the MC-DiT method generates more realistic and coherent images compared to MDT and MaskDiT. The images generated by MDT and MaskDiT often have strange or unnatural details.", "section": "4.2 Experimental Results"}, {"figure_path": "y9sHKrdnRt/figures/figures_9_1.jpg", "caption": "Figure 5: Ablation study of mask ratio.", "description": "The figure shows the impact of varying mask ratios on the FID score.  A mask ratio of 0.5 shows the lowest FID score, indicating an optimal balance between masked and unmasked patches for training the model.  Increasing or decreasing the mask ratio from this optimum leads to a higher FID score and therefore poorer image generation quality.", "section": "3.3 Contextual Enhancement with Masked Clean Patches"}, {"figure_path": "y9sHKrdnRt/figures/figures_16_1.jpg", "caption": "Figure 6: Feature visualization of MaskDiT and MC-DiT at different noise variance. Better viewed by zoom in.", "description": "This figure visualizes the attention maps of MaskDiT and MC-DiT at different noise variances.  The left side shows MC-DiT, and the right side shows MaskDiT.  Three noise levels are shown (variance of 0.9, 0.5, and 0.1). A lower noise variance means that less noise has been added.  The bottom row displays the original clean image patches that the noisy patches are trying to reconstruct.  The purpose is to demonstrate the difference in feature extraction between the two methods at varying noise levels, showing that MC-DiT is better at extracting relevant features even in the presence of high noise.", "section": "3.2 Contextual Information in Noisy Patches Reconstruction"}, {"figure_path": "y9sHKrdnRt/figures/figures_17_1.jpg", "caption": "Figure 6: Feature visualization of MaskDiT and MC-DiT at different noise variance. Better viewed by zoom in.", "description": "This figure visualizes the attention maps of MaskDiT and MC-DiT at different noise variance levels using the CIFAR-10 dataset.  The visualization shows that as noise variance increases (moving from right to left), MaskDiT's attention maps become increasingly noisy and less focused, while MC-DiT maintains a more coherent and focused attention even at higher noise levels. This demonstrates MC-DiT's improved ability to extract contextual information from noisy images compared to MaskDiT.", "section": "A.3 Supplementary Experiments"}, {"figure_path": "y9sHKrdnRt/figures/figures_18_1.jpg", "caption": "Figure 8: Visualization of 512 \u00d7 512 images generated by our MC-DiT", "description": "This figure showcases a 4x4 grid of 16 images generated by the MC-DiT model at a resolution of 512x512 pixels. Each image depicts a different object, showcasing the model's ability to generate diverse and detailed images of various subjects, including animals, objects, and insects.", "section": "A.4 Generated Samples"}]