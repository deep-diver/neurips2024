{"importance": "This paper is important because it proposes a novel solution to the crucial problem of LLM copyright protection.  **It introduces HuRef, a human-readable fingerprint that uniquely identifies the base model of LLMs without revealing sensitive parameters or interfering with training.** This addresses a significant challenge in the field and opens new avenues for research in model provenance and copyright enforcement.  The use of zero-knowledge proofs enhances trustworthiness and practicality.", "summary": "HuRef: Generate unique, human-readable fingerprints for LLMs to protect copyright without exposing model parameters or impeding training.", "takeaways": ["HuRef generates unique fingerprints for LLMs.", "The method is robust to various training methods.", "Zero-knowledge proof ensures fingerprint authenticity."], "tldr": "Large Language Models (LLMs) are computationally expensive to train and their copyright protection is a growing concern.  Existing methods are limited by their inability to uniquely identify the base model, especially after further fine-tuning or modifications.  Additionally, many methods either expose sensitive model parameters or interfere with the model's training process.  This creates challenges in practically protecting LLM copyrights.\nHuRef, a novel method, addresses these limitations by generating human-readable fingerprints based on stable internal model properties. This is achieved without exposing parameters or hindering training.  **The system uses three invariant terms that uniquely identify an LLM's base model, mapping them to a natural image for easy verification.**  Furthermore, **zero-knowledge proofs ensure the authenticity and integrity of these fingerprints.** HuRef provides a practical and trustworthy method for LLM copyright protection.", "affiliation": "Shanghai Jiao Tong University", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "RlZgnEZsOH/podcast.wav"}