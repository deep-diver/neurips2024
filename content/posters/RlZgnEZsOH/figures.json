[{"figure_path": "RlZgnEZsOH/figures/figures_1_1.jpg", "caption": "Figure 1: An illustrative framework for LLM protection with fingerprints. The LLM manufacturers compute invariant terms internally and feed them into the fingerprinting model (FPM\u00b2) to generate a fingerprint image. This image is then released to the public along with zero-knowledge proofs (\u03c0\u2081), allowing for intuitive identification of shared base models through the fingerprint images. We also provide a limited one-to-one quantitative comparison scheme (ICS & \u03c02) as a complement. Zero-Knowledge Proof guarantees the reliability of the fingerprints and comparison results, without interfering with LLM training or revealing model parameters to the public.", "description": "This figure illustrates the proposed framework for protecting LLMs using fingerprints.  LLM manufacturers compute invariant terms from their models' parameters, which are then fed into a fingerprinting model (FPM). The FPM generates a fingerprint image, which along with zero-knowledge proofs, is released publicly.  This allows anyone to easily compare fingerprint images to identify LLMs sharing a common base model.  A secondary, limited one-to-one comparison scheme is also included to provide further verification. The zero-knowledge proof ensures the integrity of the fingerprints and comparisons without revealing sensitive model information.", "section": "1 Introduction"}, {"figure_path": "RlZgnEZsOH/figures/figures_2_1.jpg", "caption": "Figure 2: The model's performance quickly deteriorates as the PCS decreases.", "description": "This figure shows the relationship between the cosine similarity of model parameters (PCS) and the model's performance. As the cosine similarity decreases (meaning the model parameters' direction deviates further from that of the base model), the model's performance drops significantly, demonstrating the necessity of preserving the base model's parameter vector direction to maintain performance. The performance is measured on a set of standard benchmarks.", "section": "3.1 Using Vector Direction of LLM Parameters to Identify the Base Model"}, {"figure_path": "RlZgnEZsOH/figures/figures_3_1.jpg", "caption": "Figure 3: Transformer layer", "description": "This figure shows a detailed diagram of a single Transformer layer.  It illustrates the flow of information, highlighting the key components: Attention, Add & Norm, and Feed Forward.  The arrows indicate the direction of data processing within the layer, starting with the input hidden state (Hn) and culminating in the output hidden state (Hn+1).  The different colors represent different sub-layers or modules within the Transformer block, visually separating the attention mechanism, the feed-forward network, and the layer normalization steps. This visualization is crucial for understanding the mathematical operations described in section 3.2 of the paper, especially when analyzing potential attacks that rearrange model weights.", "section": "3.2 Deriving the Invariant Terms"}, {"figure_path": "RlZgnEZsOH/figures/figures_5_1.jpg", "caption": "Figure 4: The training and inference of our fingerprinting model.", "description": "This figure illustrates the training and inference processes of the fingerprinting model. During training, the model learns a mapping between the invariant terms extracted from LLMs and their corresponding Gaussian vectors using a contrastive learning approach with a GAN for Gaussian distribution. In the inference stage, the trained encoder maps invariant terms from LLMs to Gaussian vectors, and a GAN-based image generator converts the vectors into human-readable fingerprint images.", "section": "4 Mapping the Invariant Terms to Image and Publish it through ZKP"}, {"figure_path": "RlZgnEZsOH/figures/figures_8_1.jpg", "caption": "Figure 5: Fingerprints of 7 different base models (in the first row) and their corresponding offspring models (the lower two rows) are presented. The base model's name is omitted in the offspring models.", "description": "This figure shows the fingerprints generated by HuRef for seven different base LLMs and their offspring models.  The top row displays the fingerprints of the base models (Falcon-40B, LLaMA2-13B, MPT-30B, LLaMA2-7B, Qwen-7B, Baichuan-13B, InternLM-7B), while the bottom two rows showcase the fingerprints of their corresponding offspring models, created through various training techniques such as Instruction fine-tuning (Instruct), supervised fine-tuning (SFT), and reinforcement learning from human feedback (RLHF). The figure visually demonstrates HuRef's ability to distinguish between base models and their derivatives, even after undergoing significant training modifications.", "section": "5.1.2 Low ICS between 28 Independently Trained LLMs"}, {"figure_path": "RlZgnEZsOH/figures/figures_18_1.jpg", "caption": "Figure 6: Flowchart for using commitment to defend against substitution attacks.", "description": "The flowchart illustrates the process of using cryptographic commitments to protect against substitution attacks in the context of LLM fingerprinting.  The LLM manufacturer computes a commitment using the model's parameters, a random value (r), and an input (X). This commitment (cm) is publicly published along with the fingerprint image.  A verification process then involves checking the consistency of the commitment with the fingerprint.  The process involves the generation of a zero-knowledge proof (\u03c0\u2081) to ensure the fingerprint was honestly generated from the claimed model and a proof (\u03c0inf) that verifies the consistency of the commitment with the output.", "section": "4 Zero-knowledge Proof for Fingerprints"}, {"figure_path": "RlZgnEZsOH/figures/figures_21_1.jpg", "caption": "Figure 1: An illustrative framework for LLM protection with fingerprints. The LLM manufacturers compute invariant terms internally and feed them into the fingerprinting model (FPM\u00b2) to generate a fingerprint image. This image is then released to the public along with zero-knowledge proofs (\u03c0\u2081), allowing for intuitive identification of shared base models through the fingerprint images. We also provide a limited one-to-one quantitative comparison scheme (ICS & \u03c02) as a complement. Zero-Knowledge Proof guarantees the reliability of the fingerprints and comparison results, without interfering with LLM training or revealing model parameters to the public.", "description": "This figure illustrates the framework for protecting LLMs using fingerprints.  LLM manufacturers compute invariant terms internally and use a fingerprinting model to create a fingerprint image. This image and zero-knowledge proofs are publicly released, enabling identification of models with shared base models. A quantitative comparison scheme is included as a complement, and the zero-knowledge proofs ensure the reliability of the fingerprints without revealing model parameters.", "section": "1 Introduction"}, {"figure_path": "RlZgnEZsOH/figures/figures_21_2.jpg", "caption": "Figure 8: Fingerprints of LLaMA-7B and its offspring models.", "description": "This figure visually shows the fingerprints generated by the HuRef model for LLaMA-7B and ten of its offspring models.  Each fingerprint is a StyleGAN2-generated image that uniquely identifies the base model. The visual similarity between the fingerprints of the base model and its offspring models demonstrates the effectiveness of the HuRef method in preserving model identity even after fine-tuning or continued pretraining. The differences in appearance between the fingerprints of different base models highlight the unique identity assigned by HuRef.", "section": "5.1.1 High ICS between Base LLMs and Their Offspring Models"}, {"figure_path": "RlZgnEZsOH/figures/figures_21_3.jpg", "caption": "Figure 5: Fingerprints of 7 different base models (in the first row) and their corresponding offspring models (the lower two rows) are presented. The base model's name is omitted in the offspring models.", "description": "This figure shows the fingerprints generated by the HuRef model for 7 base LLMs and their offspring models. Each fingerprint is a StyleGAN2-generated image representing the invariant terms derived from the LLM parameters. The figure demonstrates that offspring models have very similar fingerprints to their base models, while independently trained models have distinct fingerprints.  The top row shows fingerprints of the base models and the two bottom rows show the fingerprints of their offspring models. Base model names are not displayed for offspring models.", "section": "5.1.2 Low ICS between 28 Independently Trained LLMs"}, {"figure_path": "RlZgnEZsOH/figures/figures_23_1.jpg", "caption": "Figure 10: Fingerprints of 28 independently trained LLMs.", "description": "This figure shows the fingerprints generated by the HuRef model for 28 independently trained LLMs. Each fingerprint is a StyleGAN2-generated image that uniquely identifies the base model of the corresponding LLM. The diversity of the fingerprints highlights the ability of HuRef to distinguish between different LLMs, even those trained independently.", "section": "5.1.2 Low ICS between 28 Independently Trained LLMs"}, {"figure_path": "RlZgnEZsOH/figures/figures_24_1.jpg", "caption": "Figure 1: An illustrative framework for LLM protection with fingerprints. The LLM manufacturers compute invariant terms internally and feed them into the fingerprinting model (FPM\u00b2) to generate a fingerprint image. This image is then released to the public along with zero-knowledge proofs (\u03c0\u2081), allowing for intuitive identification of shared base models through the fingerprint images. We also provide a limited one-to-one quantitative comparison scheme (ICS & \u03c02) as a complement. Zero-Knowledge Proof guarantees the reliability of the fingerprints and comparison results, without interfering with LLM training or revealing model parameters to the public.", "description": "This figure illustrates the process of using HuRef for LLM copyright protection. LLM manufacturers calculate invariant terms from their model's parameters, use a fingerprinting model to generate a fingerprint image from those terms, and then publish the image along with zero-knowledge proofs. This allows others to verify that different LLMs share the same base model by comparing their fingerprint images.  A quantitative comparison scheme is also included as a secondary verification method.", "section": "1 Introduction"}, {"figure_path": "RlZgnEZsOH/figures/figures_24_2.jpg", "caption": "Figure 11: An illustration of a question in the human subject study. Participants were presented with the fingerprint of OPT-IML-30B (finetuned from OPT-30B) and asked to select the most similar image from the fingerprints of 18 distinct base models. Correct responses were counted only when participants precisely selected OPT-30B's fingerprint.", "description": "This figure shows a sample question from a human subject study designed to evaluate the effectiveness of the proposed method for identifying base LLMs from their offspring models using generated fingerprints.  Participants were given an offspring model's fingerprint (OPT-IML-30B in this example) and asked to choose the most similar fingerprint from a selection of 18 base model fingerprints.  Correct identification required an exact match to the base model of the offspring model (OPT-30B).", "section": "I Human Subject Study"}]