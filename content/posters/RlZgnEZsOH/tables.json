[{"figure_path": "RlZgnEZsOH/tables/tables_7_1.jpg", "caption": "Table 2: The ICS between offspring models and their corresponding base model.", "description": "This table displays the Invariant Terms' Cosine Similarity (ICS) scores between various offspring LLMs and their corresponding base models.  The offspring models were derived from seven base models: Falcon-40B, LLaMA2-13B, MPT-30B, LLaMA2-7B, Qwen-7B, Baichuan-13B, and InternLM-7B. For each base model, two offspring models are included, representing different training paradigms or modifications. The high ICS scores indicate that the parameter vector direction of the base model remains largely stable across various offspring models, despite subsequent training steps.", "section": "5.1 Effectiveness and Robustness of Invariant Terms"}, {"figure_path": "RlZgnEZsOH/tables/tables_7_2.jpg", "caption": "Table 1: The cosine similarities of model parameters (PCS) and Figure 2: The model's performance quickly deteriorates as the PCS decreases.", "description": "This table presents the cosine similarity scores of model parameters (PCS) and invariant terms (ICS) between various LLMs with respect to the LLaMA-7B base model.  It demonstrates the high cosine similarity between models that share a common base model, regardless of subsequent training steps, and the sharp decrease in performance when the parameter vector direction deviates from that of the base model.", "section": "3.1 Using Vector Direction of LLM Parameters to Identify the Base Model"}, {"figure_path": "RlZgnEZsOH/tables/tables_8_1.jpg", "caption": "Table 4: Different methods' FSR on various LLaMA's offspring models. IF1 and IF2 represent two different experimental settings of IF, with the former using all parameters and the latter only using the embedding parameter. Abbreviations are consistent with Table 3.", "description": "This table compares the Fingerprint Success Rate (FSR) of different methods for identifying the base model of LLaMA offspring models.  The methods compared include Trap, IF (with two variations: IF1 using all parameters and IF2 using only embedding parameters), and the proposed HuRef method. The table shows that HuRef achieves a perfect FSR of 100%, significantly outperforming Trap and IF.", "section": "5.1.4 Comparing to Latest Fingerprinting Methods"}, {"figure_path": "RlZgnEZsOH/tables/tables_17_1.jpg", "caption": "Table 5: Detailed zero-shot performance on multiple standard benchmarks of the original LLaMA, Alpaca, and the tuning model at different LA (PCS) values.", "description": "This table presents the results of a zero-shot experiment conducted on several standard benchmarks using three different models: the original LLaMA model, the Alpaca model, and a fine-tuned model. The Alpaca model is a fine-tuned version of the LLaMA model. The fine-tuned model was trained with an additional term (LA) in the loss function which minimized the cosine similarity to the original LLaMA model's parameters. The cosine similarity acts as an indicator of how close the model parameters are to those of the base model.  The table shows the performance of each model on various tasks, indicating how changes to the model's parameter direction due to fine-tuning affect its overall performance.", "section": "3.1 Using Vector Direction of LLM Parameters to Identify the Base Model"}, {"figure_path": "RlZgnEZsOH/tables/tables_17_2.jpg", "caption": "Table 1: The cosine similarities of model parameters (PCS) and Figure 2: The model's performance quickly deteriorates as the PCS decreases.", "description": "This table displays the cosine similarity of model parameters (PCS) and invariant terms (ICS) between various LLMs and the LLaMA-7B base model.  The PCS measures the similarity of the raw model parameters, while the ICS reflects the similarity of the derived invariant terms, which are more robust to attacks.  The table demonstrates that the PCS values are very high for models that are derived from LLaMA-7B, while the ICS is much lower for independently-trained models. The accompanying figure shows the relationship between model performance and PCS, revealing a sharp decline in performance when PCS decreases. This suggests the importance of the invariant terms in identifying the base model.", "section": "3.1 Using Vector Direction of LLM Parameters to Identify the Base Model"}, {"figure_path": "RlZgnEZsOH/tables/tables_21_1.jpg", "caption": "Table 8: ICS values between GPT-NeoX models with different global seeds.", "description": "This table presents the cosine similarities (ICS) of invariant terms between four GPT-NeoX-350M models. Each model was trained independently from scratch using different global random seeds, while sharing the same architecture, training data, computational resources, and hyperparameters.  The high diagonal values (close to 100) represent the high similarity of a model's invariant terms to itself. The low off-diagonal values (close to 2) indicate the low similarity between models trained with different seeds. This demonstrates that even subtle differences in initial conditions lead to distinct parameter vector directions after pretraining.", "section": "5.1.1 High ICS between Base LLMs and Their Offspring Models"}, {"figure_path": "RlZgnEZsOH/tables/tables_21_2.jpg", "caption": "Table 1: The cosine similarities of model parameters (PCS) and Figure 2: The model's performance quickly deteriorates as the PCS decreases.", "description": "This table shows the cosine similarity of model parameters (PCS) and invariant terms (ICS) between various LLMs with respect to the LLaMA-7B base model.  The PCS values show how similar the overall parameter vectors are between different models. A high PCS suggests that two LLMs might share a common base model. The ICS values indicate the similarity of invariant terms extracted from the models, which are robust to attacks that rearrange model weights. Figure 2 visually shows the correlation between the model's performance and PCS. As the PCS decreases, the performance quickly deteriorates, showcasing the importance of the parameter vector direction in identifying the base model.", "section": "3.1 Using Vector Direction of LLM Parameters to Identify the Base Model"}, {"figure_path": "RlZgnEZsOH/tables/tables_22_1.jpg", "caption": "Table 1: The cosine similarities of model parameters (PCS) and Figure 2: The model's performance quickly deteriorates as the PCS decreases.", "description": "This table displays the cosine similarity scores of model parameters (PCS) and invariant terms (ICS) for various LLMs compared to the LLaMA-7B base model.  It shows that LLMs derived from LLaMA-7B exhibit high cosine similarity scores, indicating preservation of the base model's parameter vector direction, even after substantial fine-tuning or continued pretraining.  The figure demonstrates the correlation between PCS and model performance, showing that performance drops significantly when the parameter vector direction differs substantially from the base model.", "section": "3.1 Using Vector Direction of LLM Parameters to Identify the Base Model"}]