[{"figure_path": "X3oeoyJlMw/tables/tables_3_1.jpg", "caption": "Table 1: Performance of ensembling heuristics.", "description": "This table presents the performance comparison of several methods for link prediction on the Citeseer and ogbl-collab datasets.  It shows the performance of individual heuristics (Common Neighbors, Shortest Path, Katz, and Feature Similarity), and their ensemble using a simple MLP.  It also includes the performance of several GNN4LP models for context and comparison. The results highlight that combining multiple heuristics can improve performance but that GNN4LP models generally perform better than simple heuristic combinations.", "section": "3 Preliminary"}, {"figure_path": "X3oeoyJlMw/tables/tables_7_1.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table presents the main results of the link prediction experiments conducted on eight benchmark datasets.  The results are shown in terms of Mean Reciprocal Rank (MRR) and Hits@K (where K varies based on the dataset).  It compares the performance of Link-MoE against several baseline methods, including heuristic methods, embedding methods, Graph Neural Networks (GNNs), and other state-of-the-art GNN4LP methods. The table highlights the top three performing methods for each dataset and metric and indicates which methods were used as experts within the Link-MoE model.  It also notes that due to out-of-memory (OOM) errors, NBFNet and PEG were not used as experts on the larger OGB datasets.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_13_1.jpg", "caption": "Table 3: Statistics of datasets. The split ratio is for train/validation/test.", "description": "This table presents the key statistics for eight datasets used in the paper's experiments, including the number of nodes, edges, and the mean node degree. It also specifies the train/validation/test split ratio used for each dataset.  The datasets represent a mix of homophilic and heterophilic graph types to ensure a comprehensive evaluation of the proposed method.", "section": "5.1 Experimental Settings"}, {"figure_path": "X3oeoyJlMw/tables/tables_14_1.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table shows the main results of the link prediction task on eight benchmark datasets, including three citation networks (Cora, Citeseer, Pubmed) and five OGB datasets.  It compares the performance of the proposed Link-MoE model against various baselines, including heuristic methods, embedding methods, GNNs, and other GNN4LP methods. The table reports the Mean Reciprocal Rank (MRR) and Hits@K metrics.  Results are highlighted to show the top three performers for each dataset. Note that NBFNet and PEG are excluded from OGB datasets due to memory issues.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_16_1.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table presents the main results of the link prediction task on several datasets, comparing the performance of Link-MoE against various baseline methods, including heuristics, embedding methods, GNNs, and other GNN4LP models.  The table highlights the top three performers for each metric and dataset, indicating Link-MoE's superior performance.  The use of * indicates which models were used as experts within the Link-MoE model.  It also notes that NBFNet and PEG were excluded from OGB datasets due to memory limitations.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_17_1.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table presents the main results of the link prediction experiments conducted on eight datasets (Cora, Citeseer, Pubmed, ogbl-collab, ogbl-ppa, ogbl-citation2, Chameleon, and Squirrel).  It compares the performance of Link-MoE against various baseline methods, including heuristic approaches, embedding methods, Graph Neural Networks (GNNs), and state-of-the-art GNN4LP models. The table shows the Mean Reciprocal Rank (MRR) for smaller datasets and Hits@K for larger datasets.  The best performing models are highlighted for each dataset and metric.  It's worth noting that NBFNet and PEG were excluded from the OGB dataset experiments due to out-of-memory (OOM) issues.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_17_2.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table presents the main results of the link prediction experiments conducted on various datasets (Cora, Citeseer, Pubmed, ogbl-collab, ogbl-ppa, ogbl-citation2).  It compares the performance of the proposed Link-MoE model against several baseline methods, including heuristic methods, embedding methods, various GNNs, and other GNN4LP models. The table highlights the top three performing methods for each dataset and metric (MRR and Hits@K).  The results demonstrate Link-MoE's superior performance compared to other methods and emphasize the impact of utilizing a mixture of experts (MoE) approach.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_18_1.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table presents the main results of the link prediction experiments conducted on various datasets (Cora, Citeseer, Pubmed, ogbl-collab, ogbl-ppa, and ogbl-citation2).  It compares the performance of Link-MoE against several baseline methods, including heuristic methods, embedding methods, GNNs, and other GNN4LP models. The results are reported as mean and standard deviation over 10 runs for each method and dataset.  The best performing models for each metric are highlighted.  NBFNet and PEG were not included in the OGB dataset experiments due to out-of-memory errors.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_18_2.jpg", "caption": "Table 9: Results for using Top-K experts or a few experts on ogbl-collab and Pubmed.", "description": "This table presents the results of experiments conducted on the ogbl-collab and Pubmed datasets using different numbers of experts in the Link-MoE model.  The results show Hits@50 for ogbl-collab and MRR for Pubmed. The \"Best Expert\" row indicates the performance of the single best-performing expert model. The rows \"Top-3 Experts\", \"3 Experts\", \"4 Experts\", and \"All Experts\" show the performance when using the top 3, a selected 3, a selected 4, and all experts, respectively. The comparison shows the improvement in performance gained by using multiple experts with Link-MoE compared to individual best experts.", "section": "D Results for Top-K Experts and a few Experts"}, {"figure_path": "X3oeoyJlMw/tables/tables_18_3.jpg", "caption": "Table 10: Results on heterophilic datasets. The metric is MRR.", "description": "This table presents the Mean Reciprocal Rank (MRR) achieved by different link prediction models on two heterophilic graph datasets: Chameleon and Squirrel.  The results show the performance of various baselines (Node2Vec, MLP, GCN, BUDDY, Neo-GNN, NCN, NCNC) and the proposed Link-MoE model.  The MRR metric is a ranking metric commonly used in link prediction to measure the quality of the predicted rankings.", "section": "F Results for Heterophilic Datasets"}, {"figure_path": "X3oeoyJlMw/tables/tables_20_1.jpg", "caption": "Table 12: Results for ensemble baselines on ogbl-collab and Pubmed.", "description": "This table compares the performance of Link-MoE against two ensemble baselines (Mean-Ensemble and Global-Ensemble) and two other ensemble methods from existing literature on the ogbl-collab and Pubmed datasets.  The results highlight that Link-MoE significantly outperforms these ensemble approaches, emphasizing the advantage of its dynamic gating mechanism which assigns weights to each expert model based on specific node pairs.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_20_2.jpg", "caption": "Table 13: Results for different gating inputs on ogbl-collab and Pubmed.", "description": "This table compares the performance of Link-MoE with different gating inputs on the ogbl-collab and Pubmed datasets.  It shows the results for using only node features in the gating mechanism (Traditional Gating),  using both node features and expert model predictions (With Experts as Input), and the full Link-MoE model.  The results demonstrate the effectiveness of the designed gating model.", "section": "I Results for Different Gating Input"}, {"figure_path": "X3oeoyJlMw/tables/tables_21_1.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table presents the main results of the link prediction experiments conducted on several benchmark datasets (Cora, Citeseer, Pubmed, ogbl-collab, ogbl-ppa, ogbl-citation2).  It compares the performance of Link-MoE against various baseline methods, including heuristic approaches, embedding methods, GNNs, and other GNN4LP models.  The results are reported as Mean Reciprocal Rank (MRR) and Hits@K (where K varies by dataset).  Significant improvements achieved by Link-MoE are highlighted.", "section": "5.2 Main Results"}, {"figure_path": "X3oeoyJlMw/tables/tables_21_2.jpg", "caption": "Table 2: Main results on link prediction (%). Highlighted are the results ranked first, second, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.", "description": "This table presents the main results of the link prediction experiments conducted on various datasets.  It compares the performance of the proposed Link-MoE model against several baseline methods, including heuristic methods, embedding methods, GNNs, and other GNN4LP models.  The results are presented in terms of Mean Reciprocal Rank (MRR) and Hits@K metrics.  The table highlights the top three performing models for each dataset and indicates which models were used as experts within the Link-MoE framework. It also notes that due to out-of-memory (OOM) errors, NBFNet and PEG were not included as experts in the experiments using OGB datasets.", "section": "5.2 Main Results"}]