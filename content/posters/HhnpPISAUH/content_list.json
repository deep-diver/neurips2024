[{"type": "text", "text": "Heterogeneity-Guided Client Sampling: Towards Fast and Efficient Non-IID Federated Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Huancheng Chen University of Texas at Austin huanchengch@utexas.edu ", "page_idx": 0}, {"type": "text", "text": "Haris Vikalo University of Texas at Austin hvikalo@ece.utexas.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Statistical heterogeneity of data present at client devices in a federated learning (FL) system renders the training of a global model in such systems difficult. Particularly challenging are the settings where due to communication resource constraints only a small fraction of clients can participate in any given round of FL. Recent approaches to training a global model in FL systems with non-IID data have focused on developing client selection methods that aim to sample clients with more informative updates of the model. However, existing client selection techniques either introduce significant computation overhead or perform well only in the scenarios where clients have data with similar heterogeneity proflies. In this paper, we propose HiCS-FL (Federated Learning via Hierarchical Clustered Sampling), a novel client selection method in which the server estimates statistical heterogeneity of a client\u2019s data using the client\u2019s update of the network\u2019s output layer and relies on this information to cluster and sample the clients. We analyze the ability of the proposed techniques to compare heterogeneity of different datasets, and characterize convergence of the training process that deploys the introduced client selection method. Extensive experimental results demonstrate that in non-IID settings HiCS-FL achieves faster convergence than state-of-the-art FL client selection schemes. Notably, HiCS-FL drastically reduces computation cost compared to existing selection schemes and is adaptable to different heterogeneity scenarios. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The federated learning (FL) framework enables privacy-preserving collaborative training of machine learning (ML) models across a number of devices (clients) by avoiding the need to collect private data stored at those devices. The participating clients typically experience both the system as well as statistical heterogeneity [18]. The former describes settings where client devices have varying degree of computational resources, communication bandwidth and fault tolerance, while the latter refers to the fact that the data owned by the clients may be drawn from different distributions. In this paper, we focus on FL under statistical heterogeneity and leave studies of system heterogeneity to future work. ", "page_idx": 0}, {"type": "text", "text": "An early FL method, FedAvg [21], performs well in the settings where the devices train on independent and identically distributed (IID) data. However, compared to the IID scenario, training on non-IID data is detrimental to the convergence speed, variance and accuracy of the learned model. This has motivated numerous studies aiming to reduce the variance and improve convergence of FL on non-IID data [6, 9, 14, 17, 19, 30]. ", "page_idx": 0}, {"type": "text", "text": "On another note, constraints on communication resources and therefore on the number of clients that may participate in training additionally complicate implementation of FL schemes. It would be particularly unrealistic to require regular contributions to training from all the clients in a largescale cross-device FL system. Instead, only a fraction of clients participate in any given training round; unfortunately, this further aggravates detrimental effects of statistical heterogeneity. Selecting informative clients in non-IID FL settings is an open problem that has received considerable attention from the research community [8, 11, 12]. Since privacy concerns typically prohibit clients from sharing their local data label distributions, existing studies focus on estimating informativeness of a client\u2019s update by analyzing the update itself. This motivated a family of methods that rely on the norms of local updates to assign probabilities of sampling the clients [7, 23]. Aiming to enable efficient use of the available communication and computation resources, another set of methods groups clients with similar data distributions into clusters based on the similarity between clients\u2019 model updates [2, 11]. Across the board, the existing methods still struggle to deliver desired performance in an efficient manner and cannot distinguish clients with balanced data from the clients with imbalanced data. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this paper, we consider training a neural network model for classification tasks via federated learning and propose a novel adaptive clustering-based sampling method for identifying and selecting informative clients. The method, referred to as Federated Learning via Hierarchical Clustered Sampling (HiCS-FL), relies on the updates of the (fully connected) output layer in the network to determine how diverse is the clients\u2019 data and, based on that, decide which clients to sample. In particular, HiCS-FL enables heterogeneity-guided client selection by utilizing general properties of the gradients of the output layer to distinguish between clients with balanced from those with imbalanced data. Unlike the Clustered Sampling strategies [11] where the clusters of clients are sampled uniformly, HiCS-FL allocates different probabilities (importance) to the clusters according to their average estimated data heterogeneity. Numerous experiments conducted on vision datasets FMNIST, CIFAR10, Mini-ImageNet and a NLP dataset THUC news demonstrate that HiCS-FL achieves significantly faster training convergence and lower variance than the competing methods. Finally, we conduct convergence analysis of HiCS-FL and discuss implications of the results. ", "page_idx": 1}, {"type": "text", "text": "In summary, the contributions of the paper include: (1) Analytical characterization of the correlation between local updates of the output layer and the FL clients\u2019 data label distribution, along with an efficient method for estimating data heterogeneity; (2) a novel clustering-based algorithm for heterogeneity-guided client selection; (3) extensive simulation results demonstrating HiCS-FL provides significant improvement in terms of convergence speed and variance over competing approaches; and (4) theoretical analysis of the proposed schemes. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Assume the cross-device federated learning setting with $N$ clients, where client $k$ owns private local dataset $B_{k}$ with $|\\boldsymbol{\\beta}_{k}|$ samples. The plain vanilla FL considers the objective ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}F(\\theta)\\triangleq\\sum_{k=1}^{N}p_{k}F_{k}(\\theta),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\theta$ denotes parameters of the global model, $F_{k}(\\theta)$ is the loss (empirical risk) of model $\\theta$ on $\\boldsymbol{{\\beta}}_{k}$ , and $p_{k}$ denotes the weight assigned to client $k$ , $\\begin{array}{r}{\\sum_{k=1}^{N}p_{k}=1}\\end{array}$ . In FedAvg, the weights are set to $\\begin{array}{r}{p_{k}=\\left|\\mathcal{B}_{k}\\right|/\\sum_{i=1}^{N}\\left|\\mathcal{B}_{i}\\right|}\\end{array}$ . In training round $t$ , the server collects clients\u2019 model updates $\\theta_{k}^{t}$ formed by training on l ocal data and aggregates them to update global model as $\\begin{array}{r}{\\theta^{t+1}=\\sum_{k=1}^{N}p_{k}\\ddot{\\theta_{k}}}\\end{array}$ . ", "page_idx": 1}, {"type": "text", "text": "When an $\\mathrm{FL}$ system operates under resource constraints, typically only $K\\ll N$ clients are selected to participate in any given round of training; denote the set of clients selected in round $t$ by $S^{t}$ . In departure from FedAvg, FedProx [19] proposes an alternative strategy for sampling clients based on a multinomial distribution where the probability of selecting a client is proportional to the size of its local dataset; the global model is then formed as the average of the collected local models $\\begin{array}{r}{\\theta^{t+1}=\\frac{1}{K}\\sum_{k\\in S_{.}^{t}}\\bar{\\theta}_{k}^{t}}\\end{array}$ .h Te hoins es aobmtpailinnegd  sbtry attheeg yf rias muenwbioarsk ewd istihn fcuel lt hclei ethnte  puaprdtiactiepda tgiloonb aasl  Emqo.d1.el is on ", "page_idx": 1}, {"type": "text", "text": "AFL [12] is the first study to utilize local validation loss as a value function for computing client sampling probabilities; Power-of-Choice [8] takes a step further to propose a greedy approach to sampling clients with the largest local loss. Both of these methods require all clients to compute the local validation loss, which is often unrealistic. To address this problem, FedCor [28] models the local loss by a Gaussian Process (GP), estimates the GP parameters from experiments, and uses the GP model to predict clients\u2019 local losses without requiring them to perform validation. In [7], Optimal Client Sampling scheme aiming to minimize the variance of local updates by assigning sampling probabilities proportional to the Euclidean norm of the updates is proposed. The study in [23] models the progression of model\u2019s weights by an Ornstein-Uhlenbeck process and proposes a strategy, optimal under that assumption, for selecting clients with significant weight updates. ", "page_idx": 1}, {"type": "text", "text": "The clustering-based sampling method proposed in [11] uses cosine similarity [24] to group together clients with similar local updates, and proceeds to sample one client per cluster in attempt to avoid redundant gradient information. DivFL [2] follows the same principle of identifying representative clients but does so by constructing a submodular set and greedily selecting diverse clients. Both of these techniques are computationally expensive due to the high dimension of the gradients that they need to process. ", "page_idx": 2}, {"type": "text", "text": "In general, the overviewed methods either: (1) select diverse clients to reduce redundant information; or (2) select clients with a perceived significant contributions to the global model (high loss, large update or low class-imbalance). Efficient and effective client selection in FL remains an open challenge, motivating the heterogeneity-guided adaptive client selection method presented next. ", "page_idx": 2}, {"type": "text", "text": "3 HiCS-FL: Federated Learning via Hierarchical Clustered Sampling ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Existing client sampling methods including Clustered Sampling [11] and DivFL [2] aim to select clients such that the resulting model update is an unbiased estimate of the true update (i.e., the update in the case of full client participation) while minimizing the variance ", "page_idx": 2}, {"type": "image", "img_path": "HhnpPISAUH/tmp/37c8c12df0be5345fc6070ffe893bca6fcf343546f1dbd9244b543ee3bb7ae52.jpg", "img_caption": ["Figure 1: The last two network layers. "], "img_footnote": [], "page_idx": 2}, {"type": "equation", "text": "$$\n\\left\\|\\frac{1}{N}\\sum_{k=1}^{N}\\nabla F_{k}(\\theta^{t})-\\frac{1}{K}\\sum_{k\\in S^{t}}\\nabla F_{k}(\\theta^{t})\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Clustered Sampling, for instance, groups $N$ clients into $K$ clusters based on representative gradients [24], and randomly selects one client from each cluster to contribute to the global model update. Such an approach unfortunately fails to differentiate between model updates formed on data with balanced and those formed on data with imbalanced label distributions \u2013 indeed, in either case the updates are treated as being equally important. However, a number of studies in centralized learning has shown that class-imbalanced datasets have significant detrimental effect on the performance of learning classification tasks [3, 4, 26]. This intuition carries over to the FL settings where one expects the updates from clients training on relatively more balanced local data to have a more beneficial impact on the performance of the system. The Federated Learning via Hierarchical Clustered Sampling (HiCS-FL) framework described in this section adapts to the clients\u2019 data heterogeneity in the following way: if the levels of heterogeneity (as quantified by the entropy of data label distribution) vary from one cluster to another, HiCS-FL is more likely to sample clusters containing clients with more balanced data; if the clients grouped in different clusters have similar heterogeneity levels, HiCS-FL is more likely to select diverse clients (i.e., sample uniformly across clusters, thus reducing to the conventional clustered sampling strategy). ", "page_idx": 2}, {"type": "text", "text": "3.1 Class-imbalance Causes Objective Drift ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A number of studies explored detrimental effects of non-IID training data on the performance of a global model learned via FedAvg. An example is SCAFFOLD [14] which demonstrates objective drift in non-IID FL manifested through large differences between local models $\\theta_{k}^{*}$ trained on substantially different data distributions. The drift is due to FedAvg updating the global model in the direction of the weighted average of local optimal models, which is not necessarily leading towards the optimal global model $\\theta^{*}$ . The optimal model $\\theta^{*}$ , in principle obtained by solving optimization in Eq. 1, achieves minimal empirical error on the data with uniform label distribution and is intuitively closer to the local optimal models trained on balanced data. Recent work [36] empirically verified this conjecture through extensive experiments. Let $\\nabla F(\\theta^{t})$ denote the gradient of $F(\\theta^{t})$ given the global model $\\theta^{t}$ at round $t$ ; the difference between $\\nabla F(\\theta^{t})$ and the local gradient $\\nabla F_{k}(\\theta^{t})$ computed on client $k$ \u2019s data is typically assumed to be bounded [7, 11, 31]. To proceed, we formalize the assumption about the relationship between gradients and data label distributions. ", "page_idx": 2}, {"type": "text", "text": "Assumption 3.1 (Bounded Dissimilarity.) Gradient $\\nabla F_{k}(\\theta^{t})$ of the $k$ -th local model at global round $t$ is such that ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\nabla F_{k}(\\theta^{t})-\\nabla F(\\theta^{t})\\right\\|^{2}\\leq\\kappa-\\rho e^{\\beta\\left(H(\\mathcal{D}^{(k)})-H(\\mathcal{D}_{0})\\right)}=\\sigma_{k}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathcal{D}^{(k)}$ is the data label distribution of client $k$ , $\\mathcal{D}_{0}$ denotes uniform distribution, $H(\\cdot)$ is Shannon\u2019s entropy of a stochastic vector, and $\\beta>0,\\kappa>\\rho>0$ . ", "page_idx": 2}, {"type": "text", "text": "(T3h) et oa $\\sigma_{m}^{2}\\,=\\,\\operatorname*{max}_{k}\\sigma_{k}^{2}$ .o nIlnyt ueitnicvoeluyn,t iefr etdh ei nd laittae rlaatbuerle  idsi srtericbouvteiroend  obf yc slieettnitn $k$ tihs e hriigghhlty- hiamnbda sliadnec eodf (i.e., $H(\\mathcal{D}^{(k)})$ is small), the local gradient $\\nabla F_{k}(\\theta^{t})$ may significantly differ from the global gradient $\\nabla F(\\theta^{t})$ (as reflected by the bound above). Analytically, connecting the gradients to the local data label distributions allows one to characterize the effects of client selection on the variance and the rate of convergence. The results of extensive experiments that empirically verify the above assumption are reported in Appendix A.2. ", "page_idx": 3}, {"type": "text", "text": "3.2 Estimating Client\u2019s Data Heterogeneity ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "If the server were given access to clients\u2019 data label distributions, selecting clients would be relatively straightforward [32]. However, privacy concerns typically discourage clients from sharing such information. Previous studies have explored the use of multi-arm bandits for inferring clients\u2019 data heterogeneity from local model parameters, or have utilized a validation dataset at the server to accomplish the same [27, 34, 36]. In this section, we demonstrate how to efficiently and accurately estimate data heterogeneity using local updates of the output layer of a neural network in a classification task. Figure 1 illustrates the last two layers in a typical neural network. The prediction $\\mathbf{q}\\in\\mathbb{R}^{C}$ is computed by forming a weighted average of signals $\\mathbf{z}\\in\\mathbb{R}^{L}$ utilizing the weight matrix $\\mathbf{W}\\in\\mathbb{R}^{C\\times L}$ and bias $\\mathbf{b}\\in\\mathbb{R}^{C}$ . ", "page_idx": 3}, {"type": "text", "text": "3.2.1 Local updates of the output layer ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "An empirical investigation of the gradients of the output layer\u2019s weights while training with FedAvg using mini-batch stochastic gradient descent (SGD) as an optimizer is reported in [5, 29]. There, the focus is on detecting the presence of specific labels in a batch rather than on exploring the effects of class imbalance on the local update. To pursue the latter, we focus on the correlation between local updates of the output layer\u2019s bias and the client\u2019s data label distribution; we start by analyzing the training via FedAvg that employs SGD and then extend the results to other FL algorithms that utilize optimizers beyond SGD. We assume that the model is trained by minimizing the cross-entropy (CE) loss over one-hot labels \u2013 a widely used multi-class classification framework. The gradient is computed by averaging contributions of the samples in mini-batches, i.e., $\\nabla_{\\mathbf{b}}\\mathcal{L}_{\\mathbf{c}\\mathbf{e}}=$ $\\begin{array}{r}{\\frac{1}{B l}\\overset{\\cdot}{\\sum_{j=1}^{l}}\\sum_{n=1}^{B}\\nabla_{\\mathbf{b}}\\overset{\\cdot}{\\mathcal{L}_{\\mathbf{ce}}^{(j,n)}}\\overset{\\cdot}{\\left(\\mathbf{x}^{(j,n)},\\overset{\\cdot}{y}^{(j,\\bar{n})}\\right)}}\\end{array}$ , where $B$ denotes the batch size, $l$ is the number of minibatches, $\\mathbf{x}^{(j,n)}$ is the $n$ -th point in the $j$ -th mini-batch and $y^{(j,n)}\\in[C]$ is its label. The contribution of $\\mathbf{x}^{(j,n)}$ to the $i$ -th component of the gradient of the output layer\u2019s bias $\\mathbf{b}$ can be found as (details provided in Appendix A.3) ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\nabla_{b_{i}}\\mathcal{L}_{\\mathbf{c}\\mathbf{e}}^{(j,n)}(\\mathbf{x}^{(j,n)},y^{(j,n)})=\\mathbb{I}\\{i=y^{(j,n)}\\}\\frac{-\\sum_{c\\neq i}\\exp(q_{c}^{(j,n)})}{\\sum_{c=1}^{C}\\exp(q_{c}^{(j,n)})}+\\mathbb{I}\\{i\\neq y^{(j,n)}\\}\\frac{\\exp(q_{i}^{(j,n)})}{\\sum_{c=1}^{C}\\exp(q_{c}^{(j,n)})},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbb{I}\\{\\cdot\\}$ is an indicator, $\\mathbf{q}^{(j,n)}\\,=\\,\\mathbf{W}\\cdot\\mathbf{z}^{(j,n)}+\\mathbf{b}$ is the output logit for signals $\\mathbf{z}^{(j,n)}\\,\\in\\,\\mathbb{\\vec{R}}^{L}$ corresponding to training point $(\\mathbf{x}^{(j,n)},y^{(j,n)})$ (see Fig. 1), and where $C$ denotes the number of classes. We make the following observations: (1) the sign of $y^{(j,n)}$ -th component of $\\nabla_{\\mathbf{b}}\\mathcal{L}_{\\mathbf{ce}}^{(j,n)}$ is opposite of the sign of other components; and (2) the $y^{(j,n)}$ -th component of $\\nabla_{\\mathbf{b}}\\mathcal{L}_{\\mathbf{ce}}^{(j,n)}$ is equal in magnitude to all the other components combined. Note that the above two observations are standard for neural networks using CE loss for supervised multi-class classification tasks. ", "page_idx": 3}, {"type": "text", "text": "In each global round $t$ of FedAvg, the selected client $k$ starts from the global model $\\theta^{t}$ and proceeds to compute local update in $R$ local epochs employing an SGD optimizer with learning rate $\\eta$ . According to Eq. 4, the $i$ -th component of local update $\\bar{\\Delta}\\mathbf{b}^{(k)}$ is computed as ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\Delta}b_{i}^{(k)}=-\\frac{\\eta}{B l}\\sum_{j=1}^{l}\\sum_{n=1}^{B}\\sum_{r=1}^{R}\\nabla_{b_{i}}\\mathcal{L}_{\\mathbf{ce}}^{(j,n,r)},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\nabla_{b_{i}}\\mathcal{L}_{\\mathbf{c}\\mathbf{e}}^{(j,n,r)}$ denotes the gradient of bias at local epoch $r$ . Note that the local update of client $k$ $\\Delta\\mathbf{b}^{(k)}$ , is dependent on the label distribution of client $k$ \u2019s data, $\\mathcal{D}^{(k)}=[D_{1}^{(k)},\\cdot\\cdot\\cdot,D_{C}^{(k)}]^{T}$ and the label-specific components of $\\mathbf{q}^{(j,n)}$ which change during training. We proceed by relating expected local updates to the label distributions; for convenience, we first introduce the following definition. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.2 Let $B^{-i}$ be the subset of local data $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ that excludes points with label i. Let $\\mathbf{s}^{-i}(\\mathbf{x})\\in$ $[0,1]^{C}$ be the softmax output of a trained neural network for a training point $(\\mathbf{x},y)\\in B^{-i}$ . The $i$ -th component of $s^{-i}(\\mathbf{x})$ , $s_{i}^{-i}(\\mathbf{x})$ , indicates the level of confidence in (erroneously) classifying $\\boldsymbol{x}$ as having label i. For convenience, we define $\\begin{array}{r}{\\mathcal{E}_{i}=\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{B}^{-i}}\\left[\\mathbf{s}_{i}^{-i}(\\mathbf{x})\\right],\\forall i\\in[C]}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "In an untrained/initialized neural network where classifier makes random predictions, $\\mathcal{E}_{i}=1/C$ ; as training proceeds, $\\mathcal{E}_{i}$ decreases. By taking expectation and simplifying, we obtain (details provided in Appendix A.4) ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]=\\eta R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where ${D}_{i}^{(k)}$ denotes the true fraction of samples with label $i$ in client $k$ \u2019s data, $\\textstyle\\sum_{i=1}^{C}D_{i}^{(k)}=1$ ", "page_idx": 4}, {"type": "text", "text": "3.2.2 Estimating local data heterogeneity ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We quantify the heterogeneity of clients\u2019 data by an entropy-like measure defined below. Let $\\mathcal{D}^{(k)}$ denote the label distribution of client $k$ \u2019s data; its entropy is defined as $H(\\mathcal{D}^{(k)})\\;\\;\\triangleq$ $\\begin{array}{r}{-\\sum_{i=1}^{C}D_{i}^{(k)}\\ln D_{i}^{(k)}\\le\\ln C}\\end{array}$ . Recall that more balanced data results in higher entropy, and that $H(\\mathcal{D}^{(k)})$ takes the maximal value when $\\mathcal{D}^{(k)}$ is uniform. The server does not know $\\mathcal{D}^{(k)}$ and therefore cannot compute $H(\\mathcal{D}^{(k)})$ directly. We define ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{H}(\\mathcal{D}^{(k)})\\triangleq H(\\mathrm{softmax}(\\Delta\\mathbf{b}^{(k)},T)),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "here $T$ is a scaling hyper-parameter (so-called temperature). Note that even though we can compute $\\hat{H}(\\mathcal{D}^{(k)})$ to characterize heterogeneity, ${D}_{i}^{(k)}$ and $\\mathcal{E}_{i}$ remain unknown to the server (details in A.5). ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.3 Consider an $F L$ system in which clients collaboratively train a model for a classification task over $C$ classes. Let $\\mathcal{D}^{(u)}$ and $\\mathcal{D}^{(k)}$ denote data label distributions of an arbitrary pair of clients u and $k$ , respectively. Moreover, let $U$ denote the uniform distribution, and let $\\eta$ and $R$ be the learning rate and the number of local epochs, respectively. Then ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\hat{H}(\\mathcal{D}^{(u)})-\\hat{H}(\\mathcal{D}^{(k)})\\right]\\geq\\frac{1}{2}\\left(\\frac{\\eta R}{C T}\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right)^{2}\\left\\|\\mathcal{D}^{(k)}-\\mathbf{U}\\right\\|_{2}^{2}-\\frac{\\eta R}{T}\\left\\|\\mathcal{D}^{(u)}-\\mathbf{U}\\right\\|_{\\infty}-\\mathcal{C}\\delta,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathcal{C}=\\frac{\\eta R(\\eta R+C^{2}T\\ln C)}{C^{2}T^{2}}}\\end{array}$ and $\\begin{array}{r}{\\delta=\\operatorname*{max}_{i}\\Big|\\frac{\\sum_{c=1}^{C}\\mathcal{E}_{c}}{C}-\\mathcal{E}_{i}\\Big|.}\\end{array}$ . The proof is provided in Appendix A.6. ", "page_idx": 4}, {"type": "text", "text": "As an illustration, consider the scenario where client $u$ has a balanced dataset while the dataset of client $k$ is imbalanced; then $\\|\\mathcal{D}^{(k)}-\\mathbf{U}\\|_{2}^{2}$ is relatively large compared to $\\|\\mathcal{D}^{(u)}-\\mathbf{U}\\|_{\\infty}$ . The bound in (8) also depends on $\\delta$ , which is reflective of how misleading on average can a class be; small $\\delta$ suggests that no class is universally misleading. As shown in Appendix A.4, during training $\\delta$ gradually decreases to 0 as $\\textstyle\\sum_{i=1}^{C}{\\mathcal{E}}_{i}$ decreases to 0. ", "page_idx": 4}, {"type": "text", "text": "3.2.3 Generalizing beyond FedAvg and SGD ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The proposed method for estimating clients\u2019 data heterogeneity relies on the properties of the gradient for the cross-entropy loss objective discussed in Section 3.2.1. However, for FL algorithms other than FedAvg, such as FedProx [19], FedDyn [1] and Moon [16], which add regularization to combat overfitting, the aforementioned properties may not hold. Moreover, optimization algorithms using second-order momentum such as Adam [15] deploy update rules different from SGD, making the local updates no longer proportional to the gradients. Nevertheless, HiCS-FL remains capable of distinguishing between clients with imbalanced and balanced data, which will be demonstrated in our experiments. Further theoretical discussion of various FL algorithms with optimizers beyond SGD are in appendix A.8 and A.9. ", "page_idx": 4}, {"type": "text", "text": "3.3 Heterogeneity-guided Clustering ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Clustered Sampling [11] uses cosine similarity [24] between gradients to quantify proximity between clients\u2019 data distributions and subsequently group them into clusters. However, cosine similarity cannot help distinguish between clients with balanced and those with imbalanced datasets. Motivated by this observation, we introduce a new distance measure that incorporates estimates of data heterogeneity $\\hat{H}(\\mathcal{D}^{(k)})$ . In particular, the proposed measure of distance between clients $u$ and $k$ that we use to form clusters is defined as ", "page_idx": 4}, {"type": "table", "img_path": "HhnpPISAUH/tmp/e33bc302ef0fcb6b3e29c5d0ca85eb5f610185580df0f0827c5d99a1d5e4024d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{Distance}(u,k)=\\operatorname{arc}\\cos\\left(\\frac{\\Delta\\mathbf{b}^{(u)}\\cdot\\Delta\\mathbf{b}^{(k)}}{|\\Delta\\mathbf{b}^{(u)}|\\cdot|\\Delta\\mathbf{b}^{(k)}|}\\right)+\\lambda\\left|\\hat{H}(\\mathcal{D}^{(u)})-\\hat{H}(\\mathcal{D}^{(k)})\\right|,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the first term is akin to the cosine similarity used by CS with the major difference that we compute it using only the updates of the bias in the output layer, which is much more efficient than using the weights of the entire network; $\\lambda$ is a pre-defined hyper-parameter (set to 10 in all our experiments). For large $\\lambda$ , the second term dominates when there are clients with different levels of statistical heterogeneity; this allows emergence of clusters that group together clients with balanced datasets. The second term is small when clients have data with similar levels of statistical heterogeneity; in that case, the distance measure reduces to the conventional cosine similarity. ", "page_idx": 5}, {"type": "text", "text": "3.4 Hierarchical Clustered Sampling ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To select $K$ out of $N$ clients in an $\\mathrm{FL}$ system, we first organize the clients into $M\\geq K$ groups via the proposed Hierarchical Clustered Sampling (HiCS) technique. In particular, during the first $\\lceil N/K\\rceil$ training rounds the server randomly (without replacement) selects clients and collects from them local updates of $\\Delta\\mathbf{b}^{(k)}$ ; the server then estimates ${\\hat{H}}^{t}({\\mathcal{D}}^{(k)})$ for each selected client $k$ and clusters the clients using the distance measure defined in Eq. 9. Let $G_{1}^{t},\\dots,G_{M}^{t}$ denote the resulting $M$ clusters at global round $t$ , and let $\\begin{array}{r}{\\bar{H}_{m}^{t}\\,=\\,\\frac{1}{|G_{m}|}\\sum_{k\\in G_{m}}\\hat{H}^{t}(\\mathcal{D}^{(k)})}\\end{array}$ characterize the average heterogeneity of clients in cluster $m$ , $m\\in[M]$ . Having computed ${\\bar{H}}_{m}^{t}$ , HiCS selects a cluster according to the probability vector $\\pi^{t}$ , and then from the selected cluster selects a client according to the probability vector $\\tilde{\\mathbf{p}}_{m}^{t}$ . The two probability vectors $\\pi^{t}$ and $\\tilde{\\mathbf{p}}_{m}^{t}$ are defined as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pi^{t}=\\left[\\frac{\\exp(\\gamma^{t}\\bar{H}_{1}^{t})}{\\sum_{m=1}^{M}\\exp(\\gamma^{t}\\bar{H}_{m}^{t})},\\ldots,\\frac{\\exp(\\gamma^{t}\\bar{H}_{M}^{t})}{\\sum_{m=1}^{M}\\exp(\\gamma^{t}\\bar{H}_{m}^{t})}\\right],\\boldsymbol{\\tilde{p}}_{m}^{t}=\\left[\\frac{p_{k_{1}}}{\\sum_{k\\in G_{m}}p_{k}},\\ldots,\\frac{p_{k_{|G_{m}|}}}{\\sum_{k\\in G_{m}}p_{k}}\\right],\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $k_{1},\\hdots,k_{|G_{m}|}$ are the indices of clients in cluster $G_{m}$ , $\\textstyle\\gamma^{t}=\\gamma^{0}(1-{\\frac{t}{\\tau}})$ denotes an annealing hyper-parameter, and $\\tau$ is the number of global rounds. The annealing parameter is scheduled such that at first it promotes sampling clients with balanced data, thus accelerating and stabilizing the convergence of the global model. To avoid overfitting potentially caused by repeatedly selecting a small subset of clients, the annealing parameter is gradually reduced to $\\gamma^{t}\\approx\\bar{0}$ , when the server samples the clusters uniformly. The described procedure is formalized as Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "3.5 Convergence Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Adopting the standard assumptions of smoothness, unbiased gradients and bounded variance [7], the following theorem holds for FedAvg with SGD optimizer. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.4 Assume $F_{k}(\\cdot)$ is $L$ -smooth for all $k\\,\\in\\,[N]$ . Let $\\theta^{t}$ denote parameters of the global model and let $F(\\cdot)$ be defined as in Eq. 1. Furthermore, assume the stochastic gradient estimator $g_{k}(\\theta^{t})$ is unbiased and the variance is bounded such that $\\Im\\left\\lvert|g_{k}(\\theta^{t})-\\nabla F_{k}(\\theta^{t})|\\right\\rvert^{2}\\leq\\sigma^{2}$ . Let $\\eta$ and $R$ be the learning rate and the number of local epochs, respectively. If the learning rate is such that \u03b7 \u22648L1R, R \u22652, then ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{t\\in[T]}\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}\\leq\\frac{1}{\\mathcal{T}}\\left(\\frac{F(\\theta^{0})-F(\\theta^{*})}{A_{1}}+A_{2}\\sum_{t=0}^{T-1}\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}\\right)+\\Phi,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $A_{1},A_{2}$ , $\\Phi$ are positive constants, and $\\omega_{k}^{t}$ is the probability of sampling client $k$ at round $t$ . ", "page_idx": 6}, {"type": "text", "text": "Note that only the second term in the parenthesis on the right-hand side of the bound in Theorem 3.4 is related to the sampling method $\\Pi$ . Under Assumption 3.1, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}\\leq\\kappa-\\sum_{k=1}^{N}\\omega_{k}^{t}\\frac{\\exp\\big(\\beta H(\\mathcal{D}^{(k)})\\big)}{\\exp\\big(\\beta H(\\mathcal{D}_{0})\\big)}\\rho=\\kappa-\\mathcal{H}_{\\Pi}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "If the server samples clients with weights proportional to $p_{k}$ , the statistical heterogeneity of the entire FL system may be characterized by imbalanced data, $\\mathcal{H}_{\\mathbf{S}}$ is small and thus random sampling leads to unsatisfactory convergence rate (as $\\begin{array}{r}{\\mathcal{H}\\mathbf{s}=\\sum_{k=1}^{N}p_{k}\\frac{\\exp(\\beta(H(\\mathcal{D}^{(k)}))}{\\exp(\\beta(H(\\mathcal{D}_{0}))}\\rho}\\end{array}$ . If all clients have classindicated by Theorem 3.4). On the other hand, since the clients sharing a cluster have similar data entropy, the proposed HiCS-FL leads to $\\begin{array}{r}{\\omega_{k}^{t}=\\frac{p_{k}\\exp(\\gamma^{t}\\hat{H}^{t}(\\mathcal{D}^{(k)}))}{\\sum_{j=1}^{N}p_{j}\\exp(\\gamma^{t}\\hat{H}^{t}(\\mathcal{D}^{(j)}))}}\\end{array}$ . When training starts, $\\mathcal{H}_{\\Pi}$ is large because the server tends to sample clients with higher $p_{k}\\exp(\\gamma^{t}H(\\mathcal{D}^{(k)}))$ ; as $\\gamma^{t}$ decreases, $\\mathcal{H}_{\\Pi}$ eventually approaches $\\mathcal{H}_{\\mathbf{S}}$ . Further details and the proof of the theorem are in Appendix A.7. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Setup. We evaluate the proposed HiCS-FL algorithm on four benchmark datasets (FMNIST, CIFAR10, Mini-ImageNet and THUC news) using different model architectures. We use four baselines: random sampling, pow-d [8], clustered sampling (CS) [11], DivFL [2] and FedCor [28]. To generate non-IID data partitions, we follow the strategy in [35], utilizing Dirichlet distribution with different concentration parameters $\\alpha$ which controls the level of heterogeneity (smaller $\\alpha$ leads to generating less balanced data). In a departure from previous works we utilize several different $\\alpha$ to generate data partitions for a single experiment, leading to a realistic scenario of varied data heterogeneity across different clients. To quantify the performance of the tested methods, we use two metrics: (1) average training loss, and (2) test accuracy of the learned global model. For better visualization, data points in the results are smoothened by a Savitzky\u2013Golay fliter with window length 13 and the polynomial order set to 3. Further details of the experimental setting and a visualization of data partitions are in Appendix A.1 and A.10. ", "page_idx": 6}, {"type": "text", "text": "4.1 Comparison on Test Accuracy and Training Loss ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "FMNIST. We run FedAvg with SGD to train a global model which has CNN architecture in an FL system with 50 clients, where $10\\%$ of clients are selected to participate in each round of training. The data partitions are generated using one of 3 sets of the concentration parameter $\\alpha$ values: (1) $\\{0.001,0.002,0.005,0.01,0.5\\}$ ; (2) $\\{0.001,0.002,0.005,0.01,0.2\\}$ ; (3) $\\{0.001\\}$ . These are used to generate clients\u2019 data so as to emulate the following scenarios: (1) $80\\%$ of clients have severely imbalanced data while the remaining $20\\%$ have balanced data; (2) $80\\%$ clients have severely imbalanced data while the remaining $20\\%$ have mildly imbalanced data; (3) all clients have severely imbalanced data. Note that $\\mathcal{H}_{\\mathbf{M}}$ monotonically decreases as we go through settings (1) to (3). For a fair comparison, pow-d and DivFL are deployed with their ideal settings where the server requires all clients to precompute in each round a metric that is then used for client selection. Figure 2 shows that HiCS-FL outperforms other methods across different settings, exhibiting the fastest convergence rates and the least amount of variance. Particularly significant is the acceleration of convergence in setting (1) where $20\\%$ of the participating clients have balanced data. Figure 3 shows that HiCS-FL is helping achieve significant reduction of training variations (as expected, see Section 3.5) as evident by a smooth loss trajectory. ", "page_idx": 6}, {"type": "image", "img_path": "HhnpPISAUH/tmp/fc0bfc86803820b1fddff5d935e66160debe98020bfb7b5a298404e43867798c.jpg", "img_caption": ["Figure 2: Test accuracy for the global model on 3 groups of data partitions of FMNIST and CIFAR10. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "HhnpPISAUH/tmp/56e00f573cda6fa13cef885e93d80204b3a30d2ac8ca4a481799b322bf7c96e2.jpg", "img_caption": ["Figure 3: Training loss of HiCS-FL compared to four baselines for setting (1) on the three datasets. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "CIFAR10. Here we compare the performance of HiCS-FL to FedProx [19] running CNN model with Adam optimizer on the task of training an FL system with 50 clients, where $20\\bar{\\%}$ of clients are selected to participate in each training round. Similar to the experiments on FMNIST, 3 sets of the concentration parameter $\\alpha$ are considered: (1) $\\{0.001,0.01,0.\\dot{1},0.5,1\\}$ ; (2) $\\{0.001,\\,0.002,\\,0.005$ , 0.01, 0.5}; (3) $\\{0.001,0.002,0.005,0.01,0.1\\}$ . The interpretation of the scenarios emulated by these setting is as same as in the FMNIST experiments. Figure 2 demonstrates improvement of HiCS-FL over all the other methods. HiCS-FL exhibits particularly significant improvements in settings (2) and (3), where $80\\%$ of the clients with extremely imbalanced data benefit from $20\\%$ of the clients with either balanced or mildly imbalanced data. The advantage of HiCS-FL in setting (1) where all clients have relatively high data heterogeneity is relatively modest (see Fig.2.(d)) because the system\u2019s $\\mathcal{H}_{\\mathbf{S}}$ is relatively large (see discussion in Section 3.5). ", "page_idx": 7}, {"type": "text", "text": "Mini-ImageNet. As in the Mini-ImageNet experiments, we compare HiCS-FL to FedProx running ResNet18 with Adam optimizer but now consider training of an FL system with 100 clients, where $20\\%$ of the clients are selected to participate in each round of training. We consider two settings of the concentration parameter $\\alpha$ : (1) $\\left\\lbrace0.\\dot{0}01,0.01,0.1,0.5,1\\right\\rbrace$ and (2) $\\{0.001,0.005,0.01,0.1,\\bar{1}\\}$ . Setting (1) emulates the scenario where clients have a range of heterogeneity proflies, from extremely imbalanced, through mildly imbalanced, to balanced, while setting (2) corresponds to the scenario where $80\\%$ of the clients have extremely imbalanced data while the remaining $20\\%$ have balanced data. The system\u2019s $\\mathcal{H}_{\\mathbf{S}}^{(1)}$ for setting (1) is larger than H(S2)for setting (2), which is reflected in a more significant improvements achieved by HiCS-FL in the latter setting, as shown in Figure 4. ", "page_idx": 7}, {"type": "text", "text": "THUC news. To evaluate our method on data from a different domain, we conduct experiments involving text classification on the THUC news dataset in Chinese language (10 labels). Similar to the aforementioned experiments, we allocate data to 50 clients by emulating heterogeneous data distributions scenarios with parameter $\\alpha$ set to: (1) {0.001, 0.01, 0.1, 0.2,1}; (2) $\\left\\{0.001,0.002,0.01,0.1,0.5\\right\\}$ ; and (3) {0.001, 0.002, 0.005, 0.01, 0.1}. We trained TextRNNs [20] with BiLSTM architecture as the classifiers using Adam optimizer. The test accuracy of the global model trained with different schemes for 100 global rounds, reported in Table 1, show that our method outperforms baselines in all the settings, demonstrating efficacy of our proposed algorithm in a simple NLP task. ", "page_idx": 7}, {"type": "table", "img_path": "HhnpPISAUH/tmp/76d43bbe8b0e0bed4b029a03a1067885522ab80e2accb10bf2207078184cc36f.jpg", "table_caption": ["Table 1: Test accuracy $(\\%)$ for the global model on 3 groups of data partitions of THUC news dataset. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "HhnpPISAUH/tmp/cb7c874bbac694f856524ebfdc77f1f8a159625b5d79eb7791c95c85cd9c8bad.jpg", "table_caption": ["Table 2: The number of communication rounds needed to reach a certain test accuracy in the experiments on FMNIST, CIFAR10, Mini-ImageNet and THUC News. All results are for the concentration parameter setting (2). "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.2 Accelerating the Training Convergence ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section we report the communication costs required to achieve convergence when using HiCS-FL, and compare those results with the competing schemes. For brevity, we select one result from each experiment conducted on the considered four datasets, and display them in Table 2. As can be seen from the table, HiCS-FL significantly reduces the number of communication rounds needed to reach target test accuracy. On FMNIST, HiCS-FL needs 60 rounds to reach test accuracy 0.75, achieving it 2.5 times faster than the random sampling scheme. On CIFAR10, HiCS-FL requires only 123 rounds to reach 0.6 test accuracy, which is 7.3 times faster than random sampling. Significant speedup appears on THUC dataset, in which HiCS-FL only needs 27 rounds to achieve 0.8 test accuracy, 3.1 times faster than the baseline. Acceleration on Mini-ImageNet is relatively modest but HiCS-FL still outperforms other methods, and does so up to 2.2 times faster than random sampling. ", "page_idx": 8}, {"type": "image", "img_path": "HhnpPISAUH/tmp/a1ee7c73c729f5fb6f9f2eecb0cd63825720b22b779caea56070b8bd48e40fa9.jpg", "img_caption": ["Figure 4: MiniImageNet acc. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 2 also shows that HiCS-FL provides the reported improvements without introducing major computational and communication overhead. The only additional computation is due to estimating data heterogeneity and performing clustering utilizing bias updates, which scales with the total number of classes but does not increase with the size of the neural network model $|\\theta^{t}|$ . Remarkably, HiCS-FL outperforms pow-d, Clustered Sampling, DivFL and FedCor in terms of convergence speed, variance and test accuracy while requiring significantly less computations. More details are provided in Appendix A.11. ", "page_idx": 8}, {"type": "text", "text": "4.3 Number of Clustering Groups ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "As discussed at the end of Section 3.3, the distance function in Equation 9 can be reduced to the conventional cosine similarity when clients exhibit similar levels of statistical heterogeneity, despite potential differences in data distribution. Under these circumstances, our HiCS-FL method can recover the performance of the previously established CS approach [11]. While CS suggests that the number of clusters $M$ should be greater than or equal to the number of selected clients $K$ , our HiCS-FL does not require $M\\,>\\,K$ but adheres to the CS settings to ensure a fair comparison. To elucidate the impact of the number of clusters, we conducted supplementary experiments with ", "page_idx": 8}, {"type": "table", "img_path": "HhnpPISAUH/tmp/d857c84051a962f2b37096d61229391e694fda6033efbe3ed059c47845333161.jpg", "table_caption": ["Table 3: Additional experimental results (accuracy in $\\%$ ) on HiCS with the number of clusters $M\\leq K$ , where $K$ is the number of selected clients each global round. "], "table_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "HhnpPISAUH/tmp/b96562ea0010e54a13e303af25d06523e79c6a58adae2a0bd12cd490a2104ec2.jpg", "table_caption": ["Table 4: In experiments on CIFAR10, only 20 out of 50 clients are available in the beginning; additional 10 clients join each 100 global rounds. The initial 20 clients leave the system after 400 global rounds. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "HiCS-FL using varying numbers of clusters $M$ and compared these results to those obtained with $M=K$ as presented in the paper. The results of those experiments can be found in Table. 3. As shown there, HiCS-FL can perform well with smaller $M<K$ as long as $M$ is not too small, such as $M=3$ . ", "page_idx": 9}, {"type": "text", "text": "4.4 Dynamic Availability of Clients ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The purpose of the warm-up phase $(t<\\lceil N/K\\rceil)$ shown in Alg. 1 is to collect updates of the output layer from all the available clients in the system in order to facilitate clustering. Although we conduct all the experiments in the setting where clients have fixed availability, our HiCS-FL does not assume all the clients are available in the warm-up phase and can be adapted to more practical scenarios where clients have dynamic availability. ", "page_idx": 9}, {"type": "text", "text": "In such a scenario, the warm-up phase can be implemented by the available clients at the beginning of training. The proposed HiCS-FL is then implemented only among the available clients; the available clients with more balanced data are preferred. When new clients join the system at the global round $t$ , the server can obtain the information of availability and selects these new clients at round $t+1$ to approximate their data heterogeneity. To provide more insights, we conduct additional experiments on CIFAR10 dataset; the results are reported in Table. 4. As can be seen there, HiCS-FL outperforms baselines that consider clients\u2019 availability. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we studied federated learning systems where clients that own non-IID data collaboratively train a global model; the system operates under communication constraints and thus only a fraction of clients participates in any given round of training. We developed HiCS-FL, a hierarchical clustered sampling method which estimates clients\u2019 data heterogeneity and uses this information to cluster and select clients to participate in training. We analyzed the performance of the proposed heterogeneity estimation method, and the convergence of training a FL system that deploys HiCS-FL. Extensive benchmarking experiments on four datasets demonstrated significant benefits of the proposed method, including improvement in convergence speed, variance and test accuracy, accomplished with only a minor computational overhead. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was funded in part by the NSF grant 2148224. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Durmus Alp Emre Acar, Yue Zhao, Ramon Matas Navarro, Matthew Mattina, Paul N Whatmough, and Venkatesh Saligrama. 2021. Federated learning based on dynamic regularization. arXiv preprint arXiv:2111.04263. [2] Ravikumar Balakrishnan, Tian Li, Tianyi Zhou, Nageen Himayat, Virginia Smith, and Jeff Bilmes. 2022. Diverse client selection for federated learning via submodular maximization. In International Conference on Learning Representations. [3] Mateusz Buda, Atsuto Maki, and Maciej A Mazurowski. 2018. A systematic study of the class imbalance problem in convolutional neural networks. Neural networks, 106:249\u2013259. [4] Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. 2002. Smote: synthetic minority over-sampling technique. Journal of artificial intelligence research, 16:321\u2013357. [5] Huancheng Chen and Haris Vikalo. 2024. Recovering labels from local updates in federated learning. arXiv preprint arXiv:2405.00955. [6] Huancheng Chen, Chaining Wang, and Haris Vikalo. 2023. The best of both worlds: Accurate global and personalized models through federated learning with data-free hyper-knowledge distillation. In The Eleventh International Conference on Learning Representations. [7] Wenlin Chen, Samuel Horvath, and Peter Richtarik. 2020. Optimal client sampling for federated learning. arXiv preprint arXiv:2010.13723.   \n[8] Yae Jee Cho, Jianyu Wang, and Gauri Joshi. 2020. Client selection in federated learning: Convergence analysis and power-of-choice selection strategies. arXiv preprint arXiv:2010.01243.   \n[9] Liam Collins, Hamed Hassani, Aryan Mokhtari, and Sanjay Shakkottai. 2021. Exploiting shared representations for personalized federated learning. In International Conference on Machine Learning, pages 2089\u20132099. PMLR.   \n[10] Sever S Dragomir, Marcel L Scholz, and Jadranka Sunde. 2000. Some upper bounds for relative entropy and applications. Computers & Mathematics with Applications, 39(9-10):91\u2013100.   \n[11] Yann Fraboni, Richard Vidal, Laetitia Kameni, and Marco Lorenzi. 2021. Clustered sampling: Lowvariance and improved representativity for clients selection in federated learning. In International Conference on Machine Learning, pages 3407\u20133416. PMLR.   \n[12] Jack Goetz, Kshitiz Malik, Duc Bui, Seungwhan Moon, Honglei Liu, and Anuj Kumar. 2019. Active federated learning. arXiv preprint arXiv:1909.12641.   \n[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778.   \n[14] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. 2020. Scaffold: Stochastic controlled averaging for federated learning. In International Conference on Machine Learning, pages 5132\u20135143. PMLR.   \n[15] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.   \n[16] Qinbin Li, Bingsheng He, and Dawn Song. 2021. Model-contrastive federated learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10713\u201310722.   \n[17] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. 2021. Ditto: Fair and robust federated learning through personalization. In International Conference on Machine Learning, pages 6357\u20136368. PMLR.   \n[18] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. 2020. Federated learning: Challenges, methods, and future directions. IEEE signal processing magazine, 37(3):50\u201360.   \n[19] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. 2020. Federated optimization in heterogeneous networks. Proceedings of Machine Learning and Systems, 2:429\u2013450.   \n[20] Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Recurrent neural network for text classification with multi-task learning. arXiv preprint arXiv:1605.05101.   \n[21] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. 2017. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR.   \n[22] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32.   \n[23] Monica Ribero and Haris Vikalo. 2020. Communication-efficient federated learning via optimal client sampling. arXiv preprint arXiv:2007.15197.   \n[24] Felix Sattler, Klaus-Robert M\u00fcller, and Wojciech Samek. 2020. Clustered federated learning: Modelagnostic distributed multitask optimization under privacy constraints. IEEE transactions on neural networks and learning systems, 32(8):3710\u20133722.   \n[25] Ronald W Schafer. 2011. What is a savitzky-golay fliter?[lecture notes]. IEEE Signal processing magazine, 28(4):111\u2013117.   \n[26] Li Shen, Zhouchen Lin, and Qingming Huang. 2016. Relay backpropagation for effective learning of deep convolutional neural networks. In Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11\u201314, 2016, Proceedings, Part VII 14, pages 467\u2013482. Springer.   \n[27] Fang Shi, Weiwei Lin, Lisheng Fan, Xiazhi Lai, and Xiumin Wang. 2023. Efficient client selection based on contextual combinatorial multi-arm bandits. IEEE Transactions on Wireless Communications.   \n[28] Minxue Tang, Xuefei Ning, Yitu Wang, Jingwei Sun, Yu Wang, Hai Li, and Yiran Chen. 2022. Fedcor: Correlation-based active client selection strategy for heterogeneous federated learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10102\u201310111.   \n[29] Aidmar Wainakh, Fabrizio Ventola, Till M\u00fc\u00dfig, Jens Keim, Carlos Garcia Cordero, Ephraim Zimmer, Tim Grube, Kristian Kersting, and Max M\u00fchlh\u00e4user. 2021. User label leakage from gradients in federated learning. arXiv preprint arXiv:2105.09369.   \n[30] Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khazaeni. 2020. Federated learning with matched averaging. arXiv preprint arXiv:2002.06440.   \n[31] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. 2020. Tackling the objective inconsistency problem in heterogeneous federated optimization. Advances in neural information processing systems, 33:7611\u20137623.   \n[32] Joel Wolfrath, Nikhil Sreekumar, Dhruv Kumar, Yuanli Wang, and Abhishek Chandra. 2022. Haccs: Heterogeneity-aware clustered client selection for accelerated federated learning. In 2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS), pages 985\u2013995. IEEE.   \n[33] Haibo Yang, Minghong Fang, and Jia Liu. 2021. Achieving linear speedup with partial worker participation in non-iid federated learning. arXiv preprint arXiv:2101.11203.   \n[34] Miao Yang, Ximin Wang, Hongbin Zhu, Haifeng Wang, and Hua Qian. 2021. Federated learning with class imbalance reduction. In 2021 29th European Signal Processing Conference (EUSIPCO), pages 2174\u20132178. IEEE.   \n[35] Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia Hoang, and Yasaman Khazaeni. 2019. Bayesian nonparametric federated learning of neural networks. In International conference on machine learning, pages 7252\u20137261. PMLR.   \n[36] Jianyi Zhang, Ang Li, Minxue Tang, Jingwei Sun, Xiang Chen, Fan Zhang, Changyou Chen, Yiran Chen, and Hai Li. 2022. Fed-cbs: A heterogeneity-aware client sampling mechanism for federated learning via class-imbalance reduction. arXiv preprint arXiv:2209.15245. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Details of the Experiments ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1.1 General Settings ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The experimental results were obtained using Pytorch [22]. In the experiments involving FMNIST, each client used a CNN-based classifier with two $5\\times5$ -convolutional layers and two $2\\times2$ -maxpooling layers (with a stride of 2), followed by a fully-connected layer. In the experiments involving CIFAR10, each client used a CNN-based classifier with three $3{\\times}3.$ -convolutional layers and two $2\\!\\times\\!2$ -maxpooling layers (with a stride of 2), followed by two fully-connected layers; dimension of the hidden layer was 64. In the experiments involving Mini-ImageNet and THUC news, each client fine-tuned a pretrained ResNet18 [13] and learned a TextRNNs [20], respectively. The optimizers used for model training in the experiments on FMNIST and CIFAR10/Mini-ImageNet/THUC news were the mini-batch stochastic gradient descent (SGD) and Adam [15], respectively. The learning rate was initially set to 0.001 and then decreased every 10 iterations, with a decay factor 0.5. The number of global communication rounds was set to 200, 500, 100 and 100 for the experiments on FMNIST, CIFAR10, Mini-ImageNet and THUC news, respectively. In all the experiments, the number of local epochs $R$ was set to 2 and the size of a mini-batch was set to 64. The sampling rate (fraction of the clients participating in a training round) was set to 0.1 for the experiments on FMNIST/THUC news, and to 0.2 for the experiments on CIFAR10/Mini-ImageNet. For the sake of visualization, data points in the presented graphs were smoothened by a Savitzky\u2013Golay filter [25] with window length 13 and the polynomial order set to 3. ", "page_idx": 12}, {"type": "text", "text": "A.1.2 Hyper-parameters ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In all experiments, the hyper-parameter $\\mu$ of the regularization term in FedProx [19] was set to 0.1. In the Power-of-Choice (pow-d) [8] selection strategy, $d$ was set to the total number of clients: 50 in the experiments on FMNIST, CIFAR10 and THUC news, 100 in the experiments on Mini-ImageNet. When running DivFL [2], we used the ideal setting where 1-step gradients were requested from all client in each round (regardless of their participation status), similar to the Power-of-Choice settings. For FedCor [28], we followed all settings in the paper and set the annealing coefficient $\\beta$ controlling the sampling strategy to 0.9 as suggested in the paper. For HiCS-FL (our method), the scaling parameter $T$ (temperature) used in data heterogeneity estimation was set to 0.0025 in the experiments on FMNIST and to 0.0015 in the experiments on CIFAR10/Mini-ImageNet. In all experiments, parameter $\\lambda$ which multiplies the difference between clients\u2019 estimated data heterogeneity (used in clustering) was set to 10. In all experiments, the number of clusters $m$ was for convenience set to be equal to the number of selected clients $K$ . The coefficient $\\gamma^{0}$ was set to 4 in the experiments on FMNIST and CIFAR10 while set to 2 in the experiments on Mini-ImageNet. To group clients, both Clustered Sampling [11] and HiCS-FL (our method) utilized an off-the-shelf clustering algorithm performing hierarchical clustering with Ward\u2019s Method. ", "page_idx": 12}, {"type": "text", "text": "A.2 Empirical Validation of Assumption 3.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "To illustrate and empirically validate Assumption 3.1, we conducted extensive experiments on FMNIST and CIFAR10 with the same model mentioned in Section A.1. In particular, we varied $\\alpha$ over 250 values in the interval [0.01, 50] to generate data partitions allocated to 250 clients; entropy of the generated label distributions ranged from 0 to $\\ln10$ (maximum). In these experiments, we allowed all clients to participate in each of 500 training rounds. To facilitate the desired study, in addition to these 250 clients we also simulated a super-client which owns a data set aggregating the data from all the clients (the set of labels in the aggregated dataset is uniformly distributed). In each round, clients start from the initialized global model and compute local gradients on their datasets; the super-client does the same on the aggregated dataset. The server computes and records squared Euclidean norm of the difference between the local gradients and the \u201ctrue\" gradient (i.e., the super-client\u2019s gradient). In each round, the difference between the local gradient and the true gradient changes in a pattern similar to what is stated in Assumption 3.1. As an illustration, we plot all such gradient differences computed during the entire training process of a client. Specifically, the server computes the difference between local gradient and the true gradient in each round of training, obtaining $250\\times500=12500$ data points that correspond to 250 data partitions. For better visualization, we merged adjacent points. ", "page_idx": 12}, {"type": "text", "text": "The results obtained by following these steps in experiments on FMNIST and CIFAR10 are shown in Figure 5. For a more informative visualization, the horizontal coordinate of a point in the scatter plot is $H(\\mathcal{D}^{(k)})$ , while the vertical coordinate is $\\left\\|\\eta_{t}\\nabla F_{k}({\\boldsymbol{\\theta}}^{t})-\\eta_{t}\\nabla F({\\boldsymbol{\\theta}}^{t})\\right\\|^{2}$ . The dashed lines correspond to the curves $y=-\\exp(\\beta\\left[x-H(\\mathcal{D}_{0})\\right])\\rho+\\kappa$ that envelop the majority of the generated points. In the case of FMNIST, the blue dashed line is parametrized by $\\beta=1.0$ , $\\rho=0.13$ , and $\\kappa=0.14$ while the green dashed line is parametrized by $\\beta=1.5$ , $\\rho=0.025$ , and $\\kappa=0.022$ ; these two lines envelop $95\\%$ of the generated points. In the case of CIFAR10, the blue dashed line is parametrized by $\\beta=2.0$ , $\\rho=0.30$ , and $\\kappa=0.36$ while the green dashed line is parametrized by $\\beta=1.8$ , $\\rho=0.15$ , and $\\kappa\\,=\\,0.20$ ; as in the other plot, these two lines envelop $95\\%$ of the generated points. As the plots indicate, the difference between the local gradient and the true gradient increases as $H(\\mathcal{D}^{(k)})$ decreases, implying that the local gradient computed by a client with more balanced data is closer to the true gradient. ", "page_idx": 13}, {"type": "image", "img_path": "HhnpPISAUH/tmp/4e6c6f32ed2f4cd8474c28244d442135028a4f8187a56d6e81d5bca9f93782fd.jpg", "img_caption": [], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "Figure 5: Visualization of the difference between local gradients and the global gradient (evaluated if all the data is centrally collected). ", "page_idx": 13}, {"type": "text", "text": "A.3 Gradient of the output (fully connected) layer\u2019s bias ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Given a batch of samples $(\\mathbf{x}^{(j,n)},y^{(j,n)})$ , the cross-entropy loss is readily computed as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathbf{CE}}=-\\frac{1}{B l}\\sum_{j=1}^{l}\\sum_{n=1}^{B}\\log\\frac{\\exp\\left(q_{y^{(j,n)}}^{(j,n)}\\right)}{\\sum_{c=1}^{C}\\exp\\left(q_{c}^{(j,n)}\\right)}=\\frac{1}{B l}\\sum_{j=1}^{l}\\sum_{n=1}^{B}\\mathcal{L}_{\\mathbf{CE}}^{(j,n)},\\quad y^{(j,n)}\\in[C]\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\nq_{c}^{(j,n)}=\\sum_{d=1}^{L}w_{d,c}z_{d}^{(j,n)}+b_{c},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $B$ is the batchsize; $l$ is the number of mini-batches; $C$ is the number of classes; $d$ is the dimension of the hidden space; zd $z_{d}^{(j,n)}$ denotes the $d$ -th feature in the hidden space given sample $\\mathbf{x}^{(j,n)}$ in the $j$ -th batch; $w_{d,c}$ and $b_{c}$ denote the weight of $z_{d}^{(j,n)}$ and the bias for the neuron that outputs the probability of the class $c$ , respectively; and $q_{c}^{(j,n)}$ is the corresponding output logit on class $c$ . The gradient of the bias $b_{i}$ given sample $\\mathbf{x}^{(j,n)}$ can be computed by the chain rule as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\mathbf{CE}}^{(j,n)}}{\\partial b_{i}}=-\\frac{\\partial\\mathcal{L}_{\\mathbf{CE}}^{(j,n)}}{\\partial Q}\\cdot\\frac{\\partial Q}{\\partial q_{i}^{(j,n)}}\\cdot\\frac{\\partial q_{i}^{(j,n)}}{\\partial b_{i}},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where ", "page_idx": 13}, {"type": "equation", "text": "$$\nQ=\\frac{\\exp\\Big(q_{y^{(j,n)}}^{(j,n)}\\Big)}{\\sum_{c=1}^{C}\\exp\\Big(q_{c}^{(j,n)}\\Big)}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Then ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\bf C E}^{(j,n)}}{\\partial Q}=\\frac{1}{Q},\\quad\\frac{\\partial q_{i}^{(j,n)}}{\\partial b_{i}}=1.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "If i = y(j,n), ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\partial Q}{\\partial q_{i}^{(j,n)}}=\\frac{\\exp\\left(q_{y^{(j,n)}}^{(j,n)}\\right)\\left(\\sum_{c=1}^{C}\\exp\\left(q_{c}^{(j,n)}\\right)\\right)-\\exp\\left(q_{y^{(j,n)}}^{(j,n)}\\right)^{2}}{\\left(\\sum_{c=1}^{C}\\exp\\left(q_{c}^{(j,n)}\\right)\\right)^{2}}=\\frac{Q\\sum_{c\\neq y^{(j,n)}}\\exp\\left(q_{c}^{(j,n)}\\right)}{\\sum_{c=1}^{C}\\exp\\left(q_{c}^{(j,n)}\\right)}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "If $i\\neq y^{(j,n)}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\partial Q}{\\partial q_{i}^{(j,n)}}=-\\frac{\\exp\\left(q_{y^{(j,n)}}^{(j,n)}\\right)\\exp\\left(q_{i}^{(j,n)}\\right)}{\\left(\\sum_{c=1}^{C}\\exp\\left(q_{c}^{(j,n)}\\right)\\right)^{2}}=-\\frac{Q\\exp\\left(q_{i}^{(j,n)}\\right)}{\\sum_{c=1}^{C}\\exp\\left(q_{c}^{(j,n)}\\right)}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "By plugging Eq. 18 and 19 in Eq. 15, we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\partial C_{\\mathbf{CE}}^{(j,n)}}{\\partial b_{i}}=-\\frac{\\sum_{c\\neq y}(j,n)\\,\\exp\\Big(q_{c}^{(j,n)}\\Big)}{\\sum_{c=1}^{C}\\exp\\Big(q_{c}^{(j,n)}\\Big)},\\;\\mathrm{if~}i=y^{(j,n)};\\frac{\\partial C_{\\mathbf{CE}}^{(j,n)}}{\\partial b_{i}}=\\frac{\\exp\\Big(q_{i}^{(j,n)}\\Big)}{\\sum_{c=1}^{C}\\exp\\Big(q_{c}^{(j,n)}\\Big)},\\;\\mathrm{if~}i\\neq y^{(j,n)}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.4 Expectation of the local update $\\Delta\\mathbf{b}^{(k)}$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "By combining Eq. 4 and 5 and taking expectation, we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\Delta_{t}^{\\alpha}\\right]=-}&{-\\frac{\\eta}{\\sqrt{\\alpha}}\\frac{\\displaystyle\\sum_{t=1}^{T-\\delta}\\sum_{s=1}^{t-\\delta}\\mathbb{E}\\left[\\nabla_{s}G_{s}(\\cdot,t^{\\delta,s})\\right]}{\\displaystyle\\sum_{t=1}^{T-\\delta}\\sum_{s=1}^{t-\\delta}\\sum_{s=1}^{t-\\delta}\\mathbb{E}\\left[\\nabla_{s}G_{s}^{(\\delta,s)\\nu}\\right]}}\\\\ &{=\\eta\\frac{\\displaystyle\\sum_{t=1}^{T-\\delta}\\mathbb{E}\\left((-\\eta^{\\alpha})^{\\alpha}|\\mathbb{A}|^{\\alpha}\\left[\\sigma^{\\alpha}\\right]^{\\beta}\\right)\\mathbb{E}\\frac{1}{\\displaystyle\\sum_{t=1}^{T-\\delta}\\sum_{s=1}^{t-\\delta}\\exp(\\theta^{\\alpha}|^{\\beta-s})}}{\\displaystyle\\sum_{t=1}^{T-\\delta}\\sum_{s=1}^{t-\\delta}\\exp(\\theta^{\\alpha}|^{\\beta-s})}}\\\\ &{\\quad-\\eta\\frac{\\displaystyle\\sum_{t=1}^{T-\\delta}\\mathbb{E}\\left(\\eta^{\\alpha}|^{\\beta}|^{\\alpha}|^{\\beta}|^{\\alpha}|^{\\beta}|^{\\beta}|^{\\alpha}|^{\\beta}\\right)\\mathbb{E}\\frac{1}{\\displaystyle\\sum_{t=1}^{T-\\delta}\\sum_{s=1}^{t-\\delta}\\exp(\\theta^{\\alpha}|^{\\beta-s})}}{\\displaystyle\\sum_{t=1}^{T-\\delta}\\sum_{s=1}^{t-\\delta}\\sum_{s=1}^{t-\\delta}\\exp(\\theta^{\\alpha}|^{\\beta-s})}}\\\\ &{\\quad=\\eta\\frac{\\displaystyle\\sum_{t=1}^{T-\\delta}\\mathbb{E}\\left[\\nabla_{s}G_{s}^{(\\delta,s)\\nu}\\right]\\mathbb{E}_{\\alpha\\times\\alpha^{\\beta-s}}\\left[\\sum_{t=1}^{t-\\delta}\\exp(\\theta^{\\alpha}|^{\\beta-s})\\right]}{\\displaystyle\\sum_{t=1}^{T-\\delta}\\sum_{s=1}^{t-\\delta}\\exp(\\theta^{\\alpha}|^{\\beta-s})}}\\\\ &{\\quad-\\eta\\frac{\\displaystyle\\sum_{t=1}^{T-\\delta}(1-\\delta_{t}^{\\alpha})^{\\alpha}\\mathbb{E}_{\\alpha\\times\\alpha^{\\beta-s}}\\left[\\sum_{t=1}^{t-\\delta}\\exp( \n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Note that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{C}\\mathcal{E}_{i}=\\displaystyle\\sum_{i=1}^{C}\\mathbb{E}_{(\\mathbf{x},\\mathbf{y})\\sim\\boldsymbol{B}^{-i}}\\left[\\mathbf{s}_{i}^{-i}(\\mathbf{x})\\right]}\\\\ {\\displaystyle}&{=\\mathbb{E}\\left[\\sum_{i=1}^{C}\\frac{1}{C-1}\\sum_{c\\neq i}\\frac{1}{B D_{c}^{(i)}}\\sum_{j=1}^{L}\\sum_{n=1}^{B}\\mathbb{I}\\{y^{(j,n)}-c\\}\\frac{\\exp(q_{i}^{(j,n)})}{\\sum_{c=1}^{C}\\exp(q_{c}^{(j,n)})}\\right]}\\\\ &{=\\displaystyle\\frac{1}{C-1}\\sum_{i=1}^{C}\\frac{1}{B D_{i}^{(i)}}\\sum_{j=1}^{l}\\sum_{n=1}^{B}\\mathbb{P}\\{y^{(j,n)}=i\\}\\frac{\\sum_{c\\neq i}\\exp(q_{c}^{(j,n)})}{\\sum_{c=1}^{C}\\exp(q_{c}^{(j,n)})}}\\\\ &{=-\\displaystyle\\frac{C}{C-1}\\frac{1}{B I}\\sum_{j=1}^{l}\\sum_{n=1}^{B}\\frac{\\exp(q_{y^{(j,n)}}^{(j,n)})}{\\sum_{c=1}^{C}\\exp(q_{c}^{(j,n)})}+\\frac{C}{C-1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A comparison to $\\mathcal{L}_{\\bf C E}$ in Eq. 13 reveals that as $\\mathcal{L}_{\\bf C E}$ decreases during training, so does $\\textstyle\\sum_{i=1}^{C}{\\mathcal{E}}_{i}$ . Given an untrained/initialized neural network model, $\\mathcal{E}_{i}^{0}\\,=\\,1/C$ for $\\forall i\\in[C]$ , i.e., $\\textstyle\\sum_{i=1}^{C}\\mathcal{E}_{i}^{0}\\;=$ $\\begin{array}{r}{-\\frac{1}{C-1}+\\frac{C}{C-1}=1}\\end{array}$ . At global round $T$ , if $\\mathcal{L}_{\\mathbf{CE}}^{*}=0$ , then $\\begin{array}{r}{\\sum_{i=1}^{C}\\mathcal{E}_{i}^{T}=-\\frac{C}{C-1}+\\frac{C}{C-1}=0}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "A.5 Privacy of $\\mathcal{D}^{(k)}$ ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "According to Eq. 6, the server is able to obtain $C$ linear equations from each client, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]=\\eta R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),\\mathrm{for}\\,\\forall i\\in[C],\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{C}D_{i}^{(k)}=1,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $C$ denotes the number of classes. Suppose $\\mathbb{E}[\\Delta b_{i}^{(k)}]$ are known by the server. Then ${D}_{i}^{(k)}$ , the variables in the aforementioned equations, cannot be determined uniquely since there are $C$ variables and $C+1$ equations. Therefore, the server is unable to infer clients\u2019 true data label distribution and the privacy of $\\mathcal{D}^{(k)}$ is protected. ", "page_idx": 15}, {"type": "text", "text": "A.6 Proof of Theorem 3.3 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In Section A.3 we derived an expression for the gradient of the bias in the output layer given a single sample $(\\mathbf{x}^{(j,n)},y)$ in the mini-batch. It is worthwhile making the following two observations: ", "page_idx": 15}, {"type": "text", "text": "\u2022 the sign of the $y^{(j,n)}$ -th component of $\\nabla_{\\mathbf{b}}\\mathcal{L}_{\\mathbf{C}\\mathbf{E}}^{(j,n)}(\\mathbf{x}^{(j,n)},y^{(j,n)})$ is opposite of the sign of the other components; and   \n\u2022 the $y^{(j,n)}$ -th component of $\\nabla_{\\mathbf{b}}\\mathcal{L}_{\\mathbf{C}\\mathbf{E}}^{(j,n)}(\\mathbf{x}^{(j,n)},y^{(j,n)})$ is equal in magnitude to all other components combined. ", "page_idx": 15}, {"type": "text", "text": "Proof: Let $\\Delta\\mathbf{b}^{(k)}=[\\Delta b_{1}^{(k)},\\ldots,\\Delta b_{C}^{(k)}]$ denote the local update (made by client $k$ ) of the bias in the output layer of the neural network model, and let $\\mathcal{D}^{(k)}=[D_{1}^{(k)},\\ldots,D_{C}^{(k)}]$ be the (unknown) true data label distribution, $\\textstyle\\sum_{i=1}^{C}D_{i}^{(k)}=1$ . Assuming the learning rate $\\eta$ and $R$ local epochs, the expectation of the local update of $\\Delta\\mathbf{b}^{(k)}$ is ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]=\\eta R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Data heterogeneity can be captured via entropy, $\\begin{array}{r}{H(\\mathcal{D}^{(k)})=-\\sum_{c=1}^{C}D_{i}^{(k)}\\ln D_{i}^{(k)}}\\end{array}$ , where higher $H(\\mathcal{D}^{(k)})$ indicates that client $k$ has more balanced data. However, since we do not have access to ", "page_idx": 15}, {"type": "text", "text": "the client\u2019s data distribution, we instead define and use as a measure of heterogeneity $\\hat{H}(\\mathcal{D}^{(k)})\\triangleq$ $H(\\operatorname{softmax}(\\Delta\\mathbf{b}^{(k)},T))$ , where ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{softmax}(\\Delta\\mathbf{b}^{(k)},T)_{i}=\\frac{\\exp(\\Delta b_{i}^{(k)}/T)}{\\sum_{c=1}^{C}\\exp(\\Delta b_{c}^{(k)}/T)},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and where $T$ denotes the temperature of the softmax operator. Suppose there are two clients, $u$ and $k$ , with class-balanced and class-imbalanced data; let $\\mathcal{D}^{(\\bar{u})}$ and $\\mathcal{D}^{(k)}$ denote their data label distributions, respectively, while $\\hat{\\mathcal{D}}^{(u)}$ and $\\hat{\\mathcal{D}}^{(k)}$ are computed by softmax $(\\Delta\\mathbf{b}^{(u)},T)$ and softmax $(\\Delta\\mathbf{b}^{(k)},T)$ . Without a loss of generality, we can re-parameterize $\\hat{\\mathcal D}^{(u)}$ as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{D}}^{(u)}=\\epsilon\\mathbf{U}+\\sum_{i=1}^{C}\\epsilon_{i}\\mathbf{Z}_{i},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathbf{U}=[\\textstyle{\\frac{1}{C}},\\dots,{\\frac{1}{C}}]$ denotes uniform distribution; $i$ -th component of $\\mathbf{Z}_{i}$ is 1 while the remaining components are 0; $\\epsilon$ and $\\epsilon_{i}$ are all non-negative such that $\\begin{array}{r}{\\epsilon+\\sum_{i=1}^{C}\\epsilon_{i}\\,=\\,1}\\end{array}$ . We can always set $\\mathrm{min}_{j}\\,\\epsilon_{j}=0$ ; otherwise, let $\\epsilon^{'}=\\epsilon+\\operatorname*{min}_{j}\\epsilon_{j}$ and $\\epsilon_{i}^{'}=\\epsilon_{i}-\\operatorname*{min}_{j}\\epsilon_{j}$ , $\\forall i\\in[C]$ ; $\\epsilon$ quantifies how close is $\\hat{\\mathcal{D}}^{(u)}$ to U. Due to the concavity of entropy, ", "page_idx": 16}, {"type": "equation", "text": "$$\nH(\\hat{\\mathcal{D}}^{(u)})\\geq\\epsilon H(\\mathbf{U})+\\sum_{i=1}^{C}\\epsilon_{i}H(\\mathbf{Z}_{i})=\\epsilon\\ln C.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We will find the following lemma useful. ", "page_idx": 16}, {"type": "text", "text": "Lemma A.1 For two probability vectors $\\pmb{p}$ and $\\pmb q$ with dimension $C_{v}$ , the Kullback\u2013Leibler divergence between p and $\\pmb q$ satisfies ", "page_idx": 16}, {"type": "equation", "text": "$$\nK L D(\\pmb{p}||\\pmb{q})\\geq\\frac12\\left\\|\\pmb{\\mathbf{p}}-\\pmb{\\mathbf{q}}\\right\\|_{1}^{2},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\begin{array}{r}{\\|\\mathbf{p}-\\mathbf{q}\\|_{1}=\\sum_{i=1}^{C}|p_{i}-q_{i}|}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "For the proof of the lemma, please see [10]. Applying it, we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbf{KLD}(\\hat{\\mathcal{D}}^{(k)}||\\mathbf{U})=H(\\mathbf{U})-H(\\hat{\\mathcal{D}}^{(k)})\\geq\\frac{1}{2}\\left\\|\\hat{\\mathcal{D}}^{(k)}-\\mathbf{U}\\right\\|_{1}^{2}\\geq\\frac{1}{2}\\left\\|\\hat{\\mathcal{D}}^{(k)}-\\mathbf{U}\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Combining Eq. 28 and Eq. 30, we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\nH(\\hat{\\mathcal{D}}^{(u)})-H(\\hat{\\mathcal{D}}^{(k)})\\geq(\\epsilon-1)\\ln C+\\frac{1}{2}\\left\\|\\hat{\\mathcal{D}}^{(k)}-\\mathbf{U}\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By taking expectations of both sides, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[H(\\hat{\\mathcal{D}}^{(u)})-H(\\hat{\\mathcal{D}}^{(k)})\\right]\\geq\\left(\\mathbb{E}[\\epsilon]-1\\right)\\ln C+\\frac{1}{2}\\mathbb{E}\\left[\\left\\|\\hat{\\mathcal{D}}^{(k)}-\\mathbf{U}\\right\\|_{2}^{2}\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since $\\left\\|\\hat{\\mathcal{D}}^{(k)}-\\mathbf{U}\\right\\|_{2}^{2}$ is convex (composition of the Euclidean norm and softmax), according to Jensen\u2019s inequality ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[H(\\hat{\\mathcal{D}}^{(u)})-H(\\hat{\\mathcal{D}}^{(k)})\\right]\\geq(\\mathbb{E}[\\epsilon]-1)\\ln C+\\frac{1}{2}\\left\\|\\hat{\\mathcal{D}}^{(k)}(\\mathbb{E}[\\Delta\\mathbf{b}^{(k)}])-\\mathbf{U}\\right\\|_{2}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{D}}^{(k)}(\\mathbb{E}[\\Delta\\mathbf{b}^{(k)}])_{i}=\\frac{\\exp\\left(\\eta R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)/T\\right)}{\\sum_{j}^{C}\\exp\\left(\\eta R\\left(D_{j}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{j}\\right)/T\\right)}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Selecting $T$ such that $\\begin{array}{r}{\\eta R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)/T}\\end{array}$ is sufficiently small and applying the first-order Taylor\u2019s expansion of $e^{x}$ around $0$ , we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{j}^{C}\\exp\\left(\\eta R\\left(D_{j}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{j}\\right)/T\\right)=\\sum_{j}^{C}1+\\eta R\\sum_{j}^{C}\\left(D_{j}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{j}\\right)/T=C,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\textstyle\\sum_{j=1}^{C}D_{j}^{(k)}=1$ . This leads to a simplified $\\hat{\\mathcal{D}}^{(k)}(\\mathbb{E}[\\Delta\\mathbf{b}^{(k)}])$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{D}}^{(k)}(\\mathbb{E}[\\Delta\\mathbf{b}^{(k)}])_{i}=\\frac{1+\\eta R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)/T}{C}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Substituting Eq. 36 for the second term on the right-hand side of ineq. 33 leads to ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left\\|\\hat{D}^{(k)}(\\mathbb{E}[\\Delta\\mathbf{b}^{(k)}])-\\mathbf{U}\\right\\|_{2}^{2}=\\left(\\frac{\\eta R}{C T}\\right)^{2}\\sum_{i=1}^{C}\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Now, consider ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{D}}^{(u)}-\\mathbf{U}=(\\epsilon-1)\\mathbf{U}+\\sum_{i=1}^{C}\\epsilon_{i}\\mathbf{Z}_{i}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Taking expectations of both sides, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[(\\epsilon-1)\\mathbf{U}+\\sum_{i=1}^{C}\\epsilon_{i}\\mathbf{Z}_{i}\\right]=\\mathbb{E}\\left[\\hat{\\mathcal{D}}^{(u)}-\\mathbf{U}\\right]\\geq\\hat{\\mathcal{D}}^{(u)}(\\mathbb{E}[\\Delta\\mathbf{b}^{(u)}])-\\mathbf{U}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The above inequality holds component-wise, so for the $j$ -component $(\\epsilon_{j}=0$ ) ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\frac{1}{C}(\\epsilon-1)+\\epsilon_{j}]=\\mathbb{E}[\\frac{1}{C}(\\epsilon-1)]\\ge\\hat{\\mathcal{D}}^{(u)}(\\mathbb{E}[\\Delta\\mathbf{b}^{(u)}])_{j}-\\mathbf{U}_{i}=\\frac{\\eta R\\left(D_{j}^{(u)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{j}\\right)}{C T}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\epsilon]-1\\ge\\frac{\\eta R\\left(D_{j}^{(u)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{j}\\right)}{T}\\ge\\operatorname*{min}_{i}\\frac{\\eta R\\left(D_{i}^{(u)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)}{T}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Taking absolute value of both sides yields ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left|\\mathbb{E}[\\epsilon]-1\\right|\\leq\\frac{\\eta R}{T}\\operatorname*{max}_{i}\\left|D_{i}^{(u)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right|=\\frac{\\eta R}{T}\\operatorname*{max}_{i}\\left|(D_{i}^{(u)}-\\frac{1}{C})\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}+\\frac{1}{C}\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right|.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "By applying the triangle inequality we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n|\\mathbb{E}[\\epsilon]-1|\\leq\\frac{\\eta R}{T}\\operatorname*{max}_{i}\\bigg|D_{i}^{(u)}-\\frac{1}{C}\\bigg|\\sum_{c=1}^{C}\\mathcal{E}_{c}+\\frac{\\eta R}{T}\\operatorname*{max}_{i}\\bigg|\\frac{1}{C}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\bigg|\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $\\begin{array}{r}{\\delta=\\operatorname*{max}_{i}\\left|\\frac{1}{C}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right|}\\end{array}$ . Since $\\begin{array}{r}{\\sum_{c=1}^{C}\\mathcal{E}_{c}\\leq C\\frac{1}{C}=1}\\end{array}$ , it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\n|\\mathbb{E}[\\epsilon]-1|\\leq\\frac{\\eta R}{T}\\operatorname*{max}_{i}\\left|D_{i}^{(u)}-\\frac{1}{C}\\right|+\\frac{\\eta R}{T}\\delta.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Furthermore, since $\\mathbb{E}[\\epsilon]-1<0$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\epsilon]-1\\ge-\\frac{\\eta R}{T}\\operatorname*{max}_{i}\\left|D_{i}^{(u)}-\\frac{1}{C}\\right|-\\frac{\\eta R}{T}\\delta.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)^{2}=\\left((D_{i}^{(k)}-\\displaystyle\\frac{1}{C})\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}+\\displaystyle\\frac{1}{C}\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right)^{2}}&{}\\\\ {=\\left((D_{i}^{(k)}-\\displaystyle\\frac{1}{C})\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right)^{2}+\\left(\\displaystyle\\frac{1}{C}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)^{2}}&{}\\\\ {+\\displaystyle2\\left(\\displaystyle\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right)\\left(D_{i}^{(k)}-\\displaystyle\\frac{1}{C}\\right)\\left(\\frac{1}{C}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)}&{}\\\\ {\\displaystyle}&{\\geq\\left((D_{i}^{(k)}-\\displaystyle\\frac{1}{C})\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right)^{2}+2\\left(\\displaystyle\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right)\\left(D_{i}^{(k)}-\\displaystyle\\frac{1}{C}\\right)\\left(\\frac{1}{C}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{\\mathrm{c}}{\\mathrm{c}t}\\bigg(U_{1}^{n}\\frac{\\sqrt{\\varepsilon}}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon}-\\varepsilon_{1}\\frac{\\varepsilon}{2}\\bigg)^{2}\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\right)_{2}^{2}\\C_{1}\\left(U_{1}^{n}-\\frac{1}{\\varepsilon}\\right)^{2}}\\\\ &{\\quad+2\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\frac{\\varepsilon}{\\varepsilon}\\right)_{2}^{2}\\sum_{k=1}^{n}\\left(D_{1}^{n}-\\frac{1}{\\varepsilon}\\right)^{2}\\bigg(\\frac{1}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon}-\\varepsilon_{1}\\bigg)}\\\\ &{\\quad-\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\right)_{2}^{2}\\frac{\\mathrm{c}}{\\mathrm{c}t}\\bigg(U_{1}^{n}-\\frac{1}{\\varepsilon}\\bigg)^{2}}\\\\ &{\\quad+2\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\right)_{2}^{2}\\frac{\\mathrm{c}}{\\mathrm{c}t}\\bigg(U_{1}^{n}-\\frac{1}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon}-\\frac{1}{\\varepsilon_{1}\\sqrt{2}}\\frac{\\varepsilon}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon}-\\frac{\\varepsilon_{2}}{\\varepsilon_{2}}-D_{2}^{n}{n}\\varepsilon_{1}\\bigg)}\\\\ &{\\quad-\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\right)_{2}^{2}\\frac{\\mathrm{c}}{\\mathrm{c}t}\\left(U_{1}^{n}-\\frac{1}{\\varepsilon}\\right)^{2}}\\\\ &{\\quad+2\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\right)_{2}^{2}\\frac{\\mathrm{c}}{\\mathrm{c}t}\\left(U_{1}^{n}-\\frac{1}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon}-\\frac{1}{\\varepsilon_{2}\\sqrt{\\varepsilon}}\\frac{\\varepsilon}{\\varepsilon}-\\frac{\\varepsilon}{\\varepsilon_{1}\\sqrt{2}}\\frac{\\varepsilon}{\\varepsilon}\\right)}\\\\ &{\\quad+2\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\right)_{2}^{2}\\frac{\\mathrm{c}}{\\mathrm{c}t}\\left(U_{1}^{n}-\\frac{1}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon}\\right)^{2}+2\\left(\\frac{S}{\\sqrt{\\varepsilon}}\\right)_{2}^{2}\\left(\\frac{1}{\\varepsilon}\\frac{\\varepsilon}{\\varepsilon \n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Substituting the above expression in Eq. 33, we obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[H(\\hat{\\mathcal{D}}^{(u)})-H(\\hat{\\mathcal{D}}^{(k)})\\right]\\geq-\\frac{\\eta R\\ln C}{T}\\operatorname*{max}_{j}\\left|D_{j}^{(u)}-\\frac{1}{C}\\right|-\\frac{\\eta R\\ln C}{T}\\delta}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\left.\\frac{1}{2}\\left(\\frac{\\eta R}{C T}\\right)^{2}\\left(\\underset{c=1}{\\overset{C}{\\sum}}\\mathcal{E}_{c}\\right)^{2}\\underset{i=1}{\\overset{C}{\\sum}}\\left(D_{i}^{(k)}-\\frac{1}{C}\\right)^{2}-\\left(\\frac{\\eta R}{C T}\\right)^{2}\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and, therefore, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[H(\\hat{\\mathcal{D}}^{(u)})-H(\\hat{\\mathcal{D}}^{(k)})\\right]\\geq\\frac{1}{2}\\left(\\frac{\\eta R}{C T}\\sum_{c=1}^{C}\\mathcal{E}_{c}\\right)^{2}\\left\\|\\mathcal{D}^{(k)}-\\mathbf{U}\\right\\|_{2}^{2}-\\frac{\\eta R\\ln C}{T}\\left\\|\\mathcal{D}^{(u)}-\\mathbf{U}\\right\\|_{\\infty}-C\\delta,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where C = \u03b7R(\u03b7R+C2T ln C). ", "page_idx": 18}, {"type": "text", "text": "A.7 Convergence Analysis ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Here we present the convergence analysis of an $\\mathrm{FL}$ system deploying FedAvg with SGD wherein only a small fraction of clients participates in any given round of training. Recall that the objective function that comes up when training a neural network model is generally non-convex; we make the standard assumptions of smoothness, unbiased gradient estimate, and bounded variance. ", "page_idx": 18}, {"type": "text", "text": "Assumption A.2 (Smoothness) Each local objective function $F_{k}(\\cdot)$ is $L$ -smooth, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\nabla F_{k}({\\theta}_{k}^{t+1})-\\nabla F_{k}({\\theta}_{k}^{t})\\right\\rVert_{2}\\leq L\\left\\lVert{\\theta}_{k}^{t+1}-{\\theta}_{k}^{t}\\right\\rVert_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Assumption A.3 (Gradient oracle) The stochastic gradient estimator $g_{k}(\\theta_{k}^{t,r})=\\nabla F_{k}(\\theta_{k}^{t,r})+\\zeta_{k}^{t,r}$ for each global round $t$ and local epoch $r$ is such that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\zeta_{k}^{t,r}]=0\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\zeta_{k}^{t,r}\\right\\Vert^{2}|\\theta_{k}^{t,r}\\right]\\leq\\sigma^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "With these three assumptions in place, we provide the proof of Theorem 3.4 stated in the main paper. The proof relies on the technique previously used in [7, 33], where the sampling method is unbiased and thus $\\begin{array}{r}{\\mathbb{E}\\left[\\frac{1}{K}\\sum_{k\\in\\mathcal{S}^{t}}\\sum_{r=1}^{\\bar{R}}\\stackrel{}{g_{k}}(\\theta_{k}^{t,r})\\right]^{\\cdot}=\\,\\sum_{k=1}^{N}\\sum_{r=1}^{R}p_{k}\\nabla F_{k}(\\theta_{k}^{t,r})}\\end{array}$ . We provide a generalization that holds for any sampling strategy, resulting in $\\begin{array}{r l}&{\\mathbb{E}\\left[\\frac{1}{K}\\sum_{k\\in\\mathcal{S}^{t}}\\sum_{r=1}^{R}g_{k}(\\theta_{k}^{t,r})\\right]\\,=\\,}\\end{array}$ $\\begin{array}{r}{\\sum_{k=1}^{N}\\sum_{r=1}^{R}\\omega_{k}^{t}\\nabla F_{k}(\\theta_{k}^{t,r})}\\end{array}$ , where $\\omega_{k}^{t}$ denotes the probability of sampling client $k$ in round $t$ under sampling strategy $\\Pi$ . Note that $\\textstyle\\sum_{k=1}^{N}\\omega_{k}^{t}=1$ . We assume that all clients deploy the same number of local epochs $R$ and use learnin g rate $\\eta$ at round $t$ . ", "page_idx": 19}, {"type": "text", "text": "A.7.1 key lemma ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Lemma A.4 (Lemma 2 in [33]) Instate Assumptions 3.1, A.2 and A.3. For any step size $\\eta$ such that \u03b7 \u2264 8L1R, for any client k it holds that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\left\\Vert\\theta_{k}^{t,r}-\\theta^{t}\\right\\Vert^{2}\\right]\\leq5R\\eta^{2}(\\sigma^{2}+6R\\sigma_{k}^{2})+30R^{2}\\eta^{2}\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof of Lemma A.4: For any client $k\\in[N]$ and $r\\in[R]$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{E\\left[\\big\\lVert\\theta_{t}^{\\prime\\prime}-\\theta^{\\prime}\\big\\rVert^{2}\\right]=\\mathbb{E}\\left[\\big\\lVert\\theta_{t}^{\\prime\\prime\\prime}-\\theta^{\\prime}-\\eta\\theta_{\\mathrm{B}}(\\theta_{t}^{\\prime\\prime\\prime}-\\theta^{\\prime})\\big\\rVert^{2}\\right]}\\\\ &{=\\mathbb{E}\\big[(\\theta_{t}^{\\prime\\prime\\prime}-\\theta^{\\prime}-\\eta\\theta(\\theta_{\\mathrm{B}}^{\\prime\\prime\\prime}-\\theta^{\\prime}))-\\nabla E_{t}(\\theta_{t}^{\\prime\\prime\\prime}-\\theta^{\\prime})+\\nabla E_{\\mathrm{B}}(\\theta_{t}^{\\prime}-1)}\\\\ &{\\qquad-\\nabla E_{\\mathrm{B}}(\\theta^{\\prime})+\\nabla E_{\\mathrm{B}}(\\theta^{\\prime})-\\nabla E(\\theta^{\\prime})+\\nabla E(\\theta^{\\prime})\\big]\\big]^{2}}\\\\ &{\\le\\Big(1+\\frac{2}{\\eta\\theta_{\\mathrm{B}}}\\Big)\\le\\Big[\\theta_{t}^{\\prime}\\theta^{\\prime\\prime}-\\theta^{\\prime}\\Big]+\\eta^{2}\\theta\\le\\Big[\\theta_{\\mathrm{B}}(\\theta^{\\prime\\prime}-\\theta^{\\prime})-\\nabla E_{\\mathrm{B}}(\\theta_{t}^{\\prime\\prime}-1)\\Big]^{2}}\\\\ &{\\quad+6B\\eta^{2}\\mathbb{E}\\left[\\nabla E_{\\mathrm{B}}(\\theta^{\\prime\\prime\\prime}-\\theta^{\\prime})-\\nabla E_{\\mathrm{B}}(\\theta^{\\prime})\\right]^{2}+6B\\eta^{2}\\mathbb{E}\\left[\\theta_{\\mathrm{B}}(\\nabla F_{\\mathrm{B}}(\\theta^{\\prime\\prime})-\\nabla F(\\theta^{\\prime})\\right]^{2}}\\\\ &{\\quad+6B\\eta^{2}\\mathbb{E}\\left[\\nabla E_{\\mathrm{B}}(\\theta^{\\prime\\prime\\prime})\\right]^{2}}\\\\ &{\\le\\Big(1+\\frac{2}{\\eta\\theta_{\\mathrm{B}}}\\Big)\\mathbb{E}\\Big[\\theta_{t}^{\\prime\\prime\\prime}-\\theta^{\\prime}\\Big]+\\eta^{2}\\theta^{2}+6B\\eta^{2}2\\mathbb{E}\\left[\\theta_{t}^{\\prime\\prime\\prime}-\\theta^{\\prime}\\right]^{2}}\\\\ &{\\quad+6B\\eta^{2}\\sigma_{\\mathrm{B}}^{2}+6B\\eta^{2}\\mathbb{E}\\left[\\nabla F(\\theta^{\\prime\\prime})\\right]^{2} \n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Unrolling the recursion yields ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\Vert\\theta_{k}^{t,r}-\\theta^{t}\\right\\Vert^{2}\\right]\\leq\\displaystyle\\sum_{r=1}^{R}\\left(1+\\displaystyle\\frac{1}{R-1}\\right)^{r-1}\\left(\\eta^{2}\\sigma^{2}+6R\\eta^{2}\\sigma_{k}^{2}+6R\\eta^{2}\\mathbb{E}\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(R-1\\right)\\left[\\left(1+\\displaystyle\\frac{1}{R-1}\\right)^{R}-1\\right]\\left(\\eta^{2}\\sigma^{2}+6R\\eta^{2}\\sigma_{k}^{2}+6R\\eta^{2}\\mathbb{E}\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq5R\\eta^{2}\\left(\\sigma^{2}+6R\\sigma_{k}^{2}\\right)+30R^{2}\\eta^{2}\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "A.7.2 Proof of Theorem 3.4 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The model update at global round $t$ is formed as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\theta^{t+1}=\\theta^{t}-\\eta\\frac{1}{K}\\sum_{k\\in{\\bf S}^{t}}\\sum_{r=1}^{R}g_{k}(\\theta_{k}^{t,r}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\theta^{t+1}$ and $\\theta^{t}$ denote parameters of the global model at rounds $t+1$ and $t$ , respectively, and $\\theta_{k}^{t,r}$ denotes parameters of the local model of client $k$ after $r$ local training epochs. Let ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Delta^{t}\\triangleq\\frac{1}{K}\\sum_{k\\in\\mathbf{S}^{t}}\\sum_{r=1}^{R}g_{k}(\\boldsymbol{\\theta}_{k}^{t,r}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Taking the expectations (conditioned on $\\theta^{t}$ ) of both sides, we obtain ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[F(\\theta^{t+1})\\right]=\\mathbb{E}\\left[F(\\theta^{t}-\\eta\\Delta^{t})\\right]}\\\\ &{\\overset{(a)}{\\leq}F(\\theta^{t})-\\eta\\left\\langle\\nabla F(\\theta^{t}),\\mathbb{E}\\left[\\Delta^{t}\\right]\\right\\rangle+\\frac{L}{2}\\eta^{2}\\mathbb{E}\\left[\\left\\Vert\\Delta^{t}\\right\\Vert^{2}\\right]}\\\\ &{=F(\\theta^{t})+\\eta\\left\\langle\\nabla F(\\theta^{t}),\\mathbb{E}\\left[R\\nabla F(\\theta^{t})-R\\nabla F(\\theta^{t})-\\Delta^{t}\\right]\\right\\rangle+\\frac{L}{2}\\eta^{2}\\mathbb{E}\\left[\\left\\Vert\\Delta^{t}\\right\\Vert^{2}\\right]}\\\\ &{=F(\\theta^{t})-R\\eta\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}+\\eta\\underbrace{\\langle\\nabla F(\\theta^{t}),\\mathbb{E}\\left[R\\nabla F(\\theta^{t})-\\Delta^{t}\\right]\\rangle}_{A_{1}}+\\frac{L}{2}\\eta^{2}\\underbrace{\\mathbb{E}\\left[\\left\\Vert\\Delta^{t}\\right\\Vert^{2}\\right]}_{A_{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Inequality (a) in the expression above holds due to the smoothness of $F(\\cdot)$ (see Assumption A.2). Note that the term $A_{1}$ can be bounded as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbf{\\Phi}_{1}=}&{(\\nabla F(\\theta),\\mathbb{E}[\\mathcal{H}(F^{T}(\\theta)-\\Delta)])}\\\\ {=}&{\\left\\langle\\nabla F(\\theta^{T}(\\theta),\\bigg[\\Bigg|\\nabla F(\\theta^{T})-\\frac{\\theta}{\\Delta}\\nabla F_{\\theta}(\\theta^{T})\\Bigg|\\right\\rangle)}\\\\ &{=\\left\\langle\\nabla F(\\theta^{T}),\\mathbb{E}[\\mathcal{H}(F^{T}(\\theta^{T}))-\\displaystyle\\sum_{t=1}^{N}\\sum_{u=1}^{d}\\nabla F_{\\theta}(\\theta^{T})\\right\\rangle}\\\\ &{=\\sum_{t=1}^{\\infty}\\sqrt{\\operatorname*{def}\\left\\langle\\nabla F(\\theta^{T}),\\frac{1}{\\sqrt{t}}\\mathbb{E}\\left[\\mathbb{E}\\left(\\nabla F_{u}(\\theta^{T})-\\nabla F(\\theta^{T})\\right)\\right]\\right\\rangle}}\\\\ &{=\\sum_{t=1}^{\\infty}\\sqrt{\\operatorname*{def}\\left\\langle\\nabla F(\\theta^{T})-\\frac{1}{\\sqrt{t}}\\mathbb{E}\\left[\\mathbb{E}\\left(\\nabla F_{u}(\\theta^{T})-\\nabla F(\\theta^{T})\\right)\\right]\\right\\rangle}}\\\\ &{\\overset{(a)}{=}\\frac{\\theta}{2}\\left\\|\\nabla F(\\theta^{T})\\right\\|^{2}+\\frac{1}{2N}\\sum_{t=1}^{N}\\sum_{u=1}^{d}\\left\\|\\frac{\\nabla F_{u}(\\theta^{T})}{\\sqrt{t}}(\\nabla F_{u}(\\theta^{T})-\\nabla F(\\theta^{T}))\\right\\|^{2}-\\frac{1}{2N}\\frac{N}{L_{1}\\times1}\\|\\nabla F_{u}(\\theta^{T})\\|}\\\\ &{\\overset{(b)}{=}\\frac{\\theta}{2}\\left\\|\\nabla F(\\theta^{T})\\right\\|^{2}+\\frac{1}{N}\\sum_{t=1}^{N}\\alpha^{2}\\left\\|\\frac{\\nabla F_{u}(\\theta^{T})}{\\sqrt{t}}(\\nabla F_{u}(\\theta^{T})-\\nabla F(\\theta^{T}))\\right\\|^{2}}\\\\ &{\\quad+\\frac{1}{N}\\frac{N}{L_{1}\\times1}\\|\\frac{N}{N}\\|\\nabla F_{u}(\\theta^{T})-\\nabla F(\\theta^{T})\\|^{2}-\\frac{1}{2N}\\frac{N}{L_{1}\\times1}\\leq\\mathbb{E}\\left\\|\\frac{N}{L_{2}}\\right\\|\\nabla F_{u}(\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\stackrel{(d)}{\\leq}\\frac{R}{2}\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}+L^{2}\\sum_{k=1}^{N}\\omega_{k}^{t}\\sum_{r=1}^{R}\\mathbb{E}\\left\\|\\theta_{k}^{t,r}-\\theta^{t}\\right\\|^{2}+R\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}-\\frac{1}{2R}\\sum_{k=1}^{N}\\omega_{k}^{t}\\mathbb{E}\\left\\|\\sum_{r=1}^{R}\\nabla F(\\theta^{r})\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where equality (a) follows from $\\begin{array}{r}{\\langle\\mathbf{x},\\mathbf{y}\\rangle\\,=\\,\\frac{1}{2}\\left(\\left\\|\\mathbf{x}\\right\\|^{2}+\\left\\|\\mathbf{y}\\right\\|^{2}-\\left\\|\\mathbf{x}-\\mathbf{y}\\right\\|^{2}\\right)}\\end{array}$ , inequality (b) is due to $\\left\\|\\mathbf{x}+\\mathbf{y}\\right\\|^{2}\\;\\leq\\;2\\left\\|\\mathbf{x}\\right\\|^{2}+2\\left\\|\\mathbf{y}\\right\\|^{2}$ , inequality (c) holds because $\\begin{array}{r}{\\left\\|\\sum_{i=1}^{n}\\mathbf{z}_{i}\\right\\|^{2}\\leq\\ n\\sum_{i=1}^{n}\\left\\|\\mathbf{z}_{i}\\right\\|^{2}}\\end{array}$ , and inequality (d) follows from Assumptions 3.1 and A.2. By selecting $\\begin{array}{r}{\\eta<\\frac{1}{8L R}}\\end{array}$ and  applying Lemma A.4 we obtain ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A_{1}\\leq\\displaystyle\\frac{R}{2}\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}+L^{2}\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\displaystyle\\sum_{r=1}^{R}\\left[5R\\eta^{2}\\big(\\sigma^{2}+6R\\sigma_{k}^{2}\\big)+30R^{2}\\eta^{2}\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}\\right]}\\\\ &{\\qquad+R\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}-\\displaystyle\\frac{1}{2R}\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\mathbb{E}\\left\\|\\displaystyle\\sum_{r=1}^{R}\\nabla F_{k}(\\theta_{k}^{t,r})\\right\\|^{2}}\\\\ &{\\displaystyle=\\left(\\frac{R}{2}+30L^{2}R^{3}\\eta^{2}\\right)\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}+5L^{2}R^{2}\\eta^{2}\\sigma^{2}+30L^{2}R^{3}\\eta^{2}\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}}\\\\ &{\\qquad+R\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}-\\displaystyle\\frac{1}{2R}\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\mathbb{E}\\left\\|\\displaystyle\\sum_{r=1}^{R}\\nabla F_{k}(\\theta_{k}^{t,r})\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Furthermore, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A_{2}=\\mathbb{E}\\left[\\left\\lVert\\frac{1}{K}\\sum_{k\\in\\mathcal{S}_{t}^{t}\\setminus\\mathcal{H}}\\beta_{k}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})\\right\\rVert^{2}\\right]}\\\\ &{\\quad=\\mathbb{E}\\left[\\left\\lVert\\frac{N}{K-1}\\frac{\\mathbb{E}(k\\in\\mathcal{S})}{K}\\sum_{i=1}^{K}\\beta_{i}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})\\right\\rVert^{2}\\right]}\\\\ &{\\quad=\\mathbb{E}\\left[\\left\\lVert\\frac{N}{K-1}\\frac{\\mathbb{E}(k\\in\\mathcal{S})}{K}\\sum_{q=1}^{K}\\beta_{i}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})-\\nabla F_{k}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})+\\nabla F_{k}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})\\right\\rVert^{2}\\right]}\\\\ &{\\quad\\stackrel{(a)}{=}\\mathbb{E}\\left[\\left\\lVert\\frac{N}{K-1}\\frac{\\mathbb{E}(k\\in\\mathcal{S})}{K}\\sum_{q=1}^{K}\\beta_{i}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})-\\nabla F_{k}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})\\right\\rVert^{2}\\right]+\\mathbb{E}\\left[\\left\\lvert\\frac{N}{K-1}\\frac{\\mathbb{E}(k\\in\\mathcal{S})}{K}\\sum_{\\tau=1}^{K}\\nabla F_{k}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon}})\\right\\rvert^{2}\\right]}\\\\ &{\\stackrel{(b)}{\\leq}\\mathbb{E}\\left[\\sum_{i=1}^{K}\\frac{\\mathbb{E}(k\\in\\mathcal{S})}{K}\\sum_{q=1}^{K}\\left\\lVert\\alpha_{i}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})-\\nabla F_{k}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})\\right\\rVert^{2}\\right]+\\mathbb{E}\\left[\\sum_{i=1}^{K}\\frac{\\mathbb{E}(k\\in\\mathcal{S})}{K}\\left\\lVert\\frac{N}{K-1}F_{k}(\\theta_{k^{\\prime}}^{\\varepsilon^{\\varepsilon^{\\varepsilon}}})\\right\\rVert^{2}\\right]}\\\\ &{\\stackrel \n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where equation (a) holds because $\\mathbb{E}\\left[g_{k}({\\boldsymbol{\\theta}}_{k}^{t,r})-\\nabla F_{k}({\\boldsymbol{\\theta}}_{k}^{t,r})\\right]\\,=\\,0$ , inequality (b) stems from the Jensen\u2019s inequality, and inequality (c) is due to Assumption A.3. ", "page_idx": 21}, {"type": "text", "text": "Substituting inequalities (61) and (62) into inequality (59) yields ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[F(\\theta^{t+1})\\right]\\leq F(\\theta^{t})-R\\eta\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}+\\eta\\underbrace{\\langle\\nabla F(\\theta^{t}),\\mathbb{E}\\left[R\\nabla F(\\theta^{t})-\\Delta^{t}\\right]\\rangle}_{A_{1}}+\\frac{L}{2}\\eta^{2}\\underbrace{\\mathbb{E}\\left[\\left\\Vert\\Delta^{t}\\right\\Vert^{2}\\right]}_{A_{2}}}\\\\ &{\\qquad\\leq F(\\theta^{t})-R\\eta\\left(\\frac{1}{2}-30L^{2}R^{2}\\eta^{2}\\right)\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}+\\left(5L^{2}R^{2}\\eta^{3}+\\frac{L R}{2}\\eta^{2}\\right)\\sigma^{2}}\\\\ &{\\qquad+\\left(30L^{2}R^{3}\\eta^{3}+R\\eta\\right)\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}+\\left(\\frac{L}{2}\\eta^{2}-\\frac{\\eta}{2R}\\right)\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\mathbb{E}\\left\\Vert\\displaystyle\\sum_{r=1}^{R}\\nabla F_{k}(\\theta_{k}^{t,r})\\right\\Vert^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If $\\begin{array}{r}{\\eta<\\frac{1}{8L R}}\\end{array}$ , it must be that $\\textstyle{\\frac{1}{2}}-30L^{2}R^{2}\\eta^{2}>0$ and $\\begin{array}{r}{\\frac{L}{2}\\eta^{2}-\\frac{\\eta}{2R}<0}\\end{array}$ , leading to ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[F(\\theta^{t+1})\\right]\\leq F(\\theta^{t})-R\\eta\\left(\\frac{1}{2}-30L^{2}R^{2}\\eta^{2}\\right)\\left\\Vert\\nabla F(\\theta^{t})\\right\\Vert^{2}}\\\\ &{\\qquad\\qquad+\\left(5L^{2}R^{2}\\eta^{3}+\\frac{L R}{2}\\eta^{2}\\right)\\sigma^{2}+\\left(30L^{2}R^{3}\\eta^{3}+R\\eta\\right)\\displaystyle\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By rearranging and summing from $t=0$ to $t=\\tau-1$ we obtain ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[F(\\theta^{T})\\right]-F(\\theta^{0})\\leq-R\\eta\\left(\\frac{1}{2}-30L^{2}R^{2}\\eta^{2}\\right)\\overset{T-1}{\\underset{t=0}{\\prod}}\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad+\\left(5L^{2}R^{2}\\eta^{3}+\\frac{L R}{2}\\eta^{2}\\right)7\\sigma^{2}+\\left(30L^{2}R^{3}\\eta^{3}+R\\eta\\right)\\overset{T-1}{\\underset{t=0}{\\sum}}\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq-R\\eta\\left(\\frac{1}{2}-30L^{2}R^{2}\\eta^{2}\\right)T\\underset{t\\in[\\mathcal{T}]}{\\operatorname*{min}}\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad+\\left(5L^{2}R^{2}\\eta^{3}+\\frac{L R}{2}\\eta^{2}\\right)T\\sigma^{2}+\\left(30L^{2}R^{3}\\eta^{3}+R\\eta\\right)\\overset{T-1}{\\underset{t=0}{\\sum}}\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let $\\theta^{*}$ denote the optimal model\u2019s parameters, i.e., $F({\\boldsymbol{\\theta}}^{*})\\leq F({\\boldsymbol{\\theta}}^{t})\\forall t\\in[T]$ . Then ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{t\\in[T]}\\left\\|\\nabla F(\\theta^{t})\\right\\|^{2}\\leq\\frac{1}{\\mathcal{T}}\\left(\\frac{F(\\theta^{0})-F(\\theta^{*})}{A_{1}}+A_{2}\\sum_{t=0}^{T-1}\\sum_{k=1}^{N}\\omega_{k}^{t}\\sigma_{k}^{2}\\right)+\\Phi,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathcal{A}_{1}=R\\eta\\left(\\frac{1}{2}-30L^{2}R^{2}\\eta^{2}\\right)\\!,\\mathcal{A}_{2}=\\frac{60L^{2}R^{3}\\eta^{3}+2R\\eta}{R\\eta\\left(1-60L^{2}R^{2}\\eta^{2}\\right)}}\\end{array}$ and \u03a6 = $\\begin{array}{r}{\\Phi=\\frac{\\left(10L^{2}R\\eta^{2}+L\\eta\\right)\\sigma^{2}}{1-60L^{2}R^{2}\\eta^{2}}}\\end{array}$ ", "page_idx": 22}, {"type": "text", "text": "A.8 Regularization Terms in the Objective Function ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The proposed method for estimating clients\u2019 data heterogeneity relies on the properties of gradient computed for the cross-entropy loss objective. However, the method also applies to the FL algorithms other than FedAvg, in particular those that add a regularization term to combat overftiting, including FedProx [19], FedDyn[1] and Moon [16]. In the following discussion, we demonstrate that HiCS-FL remains capable of distinguishing between clients with imbalanced and balanced data when using these other FL algorithms. ", "page_idx": 22}, {"type": "text", "text": "A.8.1 FedProx ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The objective function used by FedProx [19] is ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{prox}}^{r}=\\mathcal{L}_{\\bf C E}^{r}+\\frac{\\mu}{2}\\left\\Vert\\theta_{k}^{t,r}-\\theta^{t}\\right\\Vert^{2},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\theta_{k}^{t,r}$ is the vector of client $k$ \u2019s local model parameters in the $r$ -th local epoch at global round $t$ . Therefore, contribution of sample $(\\mathbf{x}^{(j,n)},y^{(j,n)})$ to the gradient of $\\mathcal{L}_{\\mathrm{prox}}$ in local epoch $r$ is ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\mathrm{prox}}^{(j,n,r)}}{\\partial b_{i}}=\\frac{\\partial\\mathcal{L}_{\\mathbf{CE}}^{(j,n,r)}}{\\partial b_{i}}+\\mu\\left(b_{i}^{t,r}-b_{i}^{t}\\right),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\mathbf{b}^{t,r}=[b_{1}^{t,r},\\ldots,b_{C}^{t,r}]$ denotes parameters of bias in the output layer of the local model, and $\\mathbf{b}^{t}=[b_{1}^{t},\\cdot\\cdot\\cdot,\\bar{b}_{C}^{t}]$ denotes parameters of the global model at round $t$ . We assume the model is trained by SGD as the optimizer, and hence ", "page_idx": 22}, {"type": "equation", "text": "$$\nb_{i}^{t,r}-b_{i}^{t}=b_{i}^{t,r-1}-\\eta_{t}\\frac{\\partial\\mathcal{L}_{\\mathrm{prox}}^{(j,n,r-1)}}{\\partial b_{i}}-b_{i}^{t}=-\\eta_{t}\\frac{\\partial\\mathcal{L}_{\\mathrm{CE}}^{(j,n,r-1)}}{\\partial b_{i}}+(1-\\eta_{t}\\mu)(b_{i}^{t,r-1}-b_{i}^{t}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{b_{i}^{t,r}-b_{i}^{t}=-\\eta_{t}\\displaystyle\\sum_{s=1}^{r-1}(1-\\eta_{t}\\mu)^{r-1-s}\\frac{\\partial\\mathcal{L}_{\\mathbf{CE}}^{(j,n,s)}}{\\partial b_{i}}+(1-\\eta_{t}\\mu)^{r-1}(b_{i}^{t}-b_{i}^{t})}\\\\ &{\\qquad=-\\eta_{t}\\displaystyle\\sum_{s=1}^{r-1}(1-\\eta_{t}\\mu)^{r-1-s}\\frac{\\partial\\mathcal{L}_{\\mathbf{CE}}^{(j,n,s)}}{\\partial b_{i}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and thus ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\mathrm{prox}}^{(j,n,r)}}{\\partial b_{i}}=\\frac{\\partial\\mathcal{L}_{\\mathrm{CE}}^{(j,n,r)}}{\\partial b_{i}}-\\eta_{t}\\mu\\sum_{s=1}^{r-1}(1-\\eta_{t}\\mu)^{r-1-s}\\frac{\\partial\\mathcal{L}_{\\mathrm{CE}}^{(j,n,s)}}{\\partial b_{i}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Taking expectation of both sides yields ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\frac{1}{\\beta l}\\displaystyle\\sum_{j=1}^{l}\\displaystyle\\sum_{n=1}^{B}\\sum_{r=1}^{R}\\mathbb{E}\\left[\\frac{\\partial\\mathcal{L}_{p00}^{(j,n,r)}}{\\partial b_{i}}\\right]=\\left(-\\mathbb{E}[\\mathbb{E}\\{i=y^{(j,n)}\\}]\\displaystyle\\sum_{c\\neq i}\\mathcal{E}_{c}+\\mathbb{E}[\\mathbb{E}(i\\neq y^{(j,n)})]\\mathcal{E}_{i}\\right)}\\\\ &{\\phantom{\\frac{1}{\\beta}\\displaystyle\\sum_{r=1}^{R}}\\left(1-\\eta_{t}\\mu\\displaystyle\\sum_{s=1}^{r-1}(1-\\eta_{t}\\mu)^{r-1-s}\\right)}\\\\ &{=\\displaystyle\\sum_{r=1}^{R}\\left(-D_{i}^{(k)}\\sum_{c\\neq i}\\mathcal{E}_{c}+(1-D_{i}^{(k)})\\mathcal{E}_{i}\\right)\\left(1-\\eta_{t}\\mu\\displaystyle\\frac{1-\\left(1-\\eta_{t}\\mu\\right)^{r-1}}{\\eta_{t}\\mu}\\right)}\\\\ &{=\\displaystyle\\sum_{r=1}^{R}c^{r}\\left(-D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}+\\mathcal{E}_{i}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $c^{r}=(1-\\eta_{t}\\mu)^{r-1}>0$ provided $\\eta_{t}$ and $\\mu$ are sufficiently small. Therefore, the expectation of the local update of bias in the output layer satisfies ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]=C\\eta_{t}\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\begin{array}{r}{C=\\sum_{r=1}^{R}c^{r}}\\end{array}$ . Eq. (73) is similar to the expression for the expectation of the local updates of bias when a pplying FedAvg presented in the main paper; clearly, the analysis of HiCS-FL done in the context of FedAvg extends to FedProx. ", "page_idx": 23}, {"type": "text", "text": "A.8.2 FedDyn ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "For FedDyn [1], the objective function in local epoch $r$ at global round $t$ is ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{dyn}}^{t,r}=\\mathcal{L}_{\\bf C E}^{t,r}-\\left\\langle\\nabla\\mathcal{L}_{\\mathrm{dyn}}^{t-1,R},\\theta_{k}^{t,r}\\right\\rangle+\\frac{\\mu}{2}\\left\\Vert\\theta_{k}^{t,r}-\\theta^{t}\\right\\Vert^{2},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $R$ denotes the total number of local epochs. The first order condition for local optima implies ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla\\mathcal{L}_{\\mathrm{dyn}}^{t,r}-\\nabla\\mathcal{L}_{\\mathrm{dyn}}^{t-1,R}+\\mu(\\boldsymbol{\\theta}_{k}^{t,r}-\\boldsymbol{\\theta}^{t})=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and, therefore, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{\\partial C_{\\theta,n}^{\\varepsilon,w}}{\\partial h_{0}}}&{=\\frac{\\partial C_{\\theta,n}^{\\varepsilon,w,1}}{\\partial h_{1}}-\\mu\\left({b}_{i}^{\\varepsilon,r}-{b}_{i}^{\\varepsilon}\\right)}\\\\ &{=\\frac{\\partial C_{\\theta,n}^{\\varepsilon,w,2}}{\\partial h_{1}}-\\mu\\left({b}_{i}^{\\varepsilon-1,R}-{b}_{i}^{\\varepsilon-1}\\right)-\\mu\\left({b}_{i}^{\\varepsilon,r}-{b}_{i}^{\\varepsilon}\\right)}\\\\ &{=-\\mu\\displaystyle\\sum_{r=1}^{r-1}\\left({b}_{i}^{r,R}-{b}_{i}^{r}\\right)-\\mu\\left({b}_{i}^{\\varepsilon,r}-{b}_{i}^{\\varepsilon}\\right)}\\\\ &{=-\\mu\\displaystyle\\sum_{r=1}^{r-1}\\Delta_{i}^{N_{i}^{r}}-\\mu\\left({b}_{i}^{\\varepsilon,r}-{b}_{i}^{\\varepsilon}\\right)}\\\\ &{=-\\mu\\displaystyle\\sum_{r=1}^{r-1}\\Delta_{i}^{N_{i}^{r}}-\\mu\\left(-\\eta\\frac{\\partial C_{\\varepsilon,n}^{\\varepsilon,r-1}}{\\partial h_{1}}+\\frac{\\mu^{1-\\varepsilon-1}}{h_{1}}-{b}_{i}^{\\varepsilon}\\right)}\\\\ &{=-\\mu\\displaystyle\\sum_{m=1}^{r-1}\\Delta_{i}^{N_{i}^{r}}+\\mu\\left(-\\eta\\frac{\\partial C_{\\varepsilon,n}^{\\varepsilon,m-1}}{\\partial h_{1}}+\\frac{\\mu^{1-\\varepsilon-1}}{h_{1}}-{b}_{i}^{\\varepsilon}\\right)}\\\\ &{=-\\mu\\displaystyle\\sum_{m=1}^{r-1}\\Delta_{i}^{N_{i}^{r}}+\\mu\\eta_{n}\\left(\\displaystyle\\sum_{s=1}^{r-1}\\frac{\\partial C_{\\varepsilon,n}^{\\varepsilon,m}}{\\partial h_{1}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\mathbf{b}^{t,r}=[b_{1}^{t,r},\\ldots,b_{C}^{t,r}]$ denotes the bias parameters in the output layer of the local model at local epoch $r$ , and where $\\mathbf{\\widetilde{\\Delta}}\\mathbf{b}^{\\intercal}=[\\Delta b_{1}^{\\intercal},\\dots,\\Delta b_{C}^{\\intercal}]$ is the local update of the bias at round $\\tau$ . Since ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\mathrm{dyn}}^{t,1}}{\\partial b_{i}}=-\\mu\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "it holds that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\mathrm{dyn}}^{t,2}}{\\partial b_{i}}=-\\mu\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}+\\mu\\eta_{t}\\left(-\\mu\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}\\right)=-\\mu(1+\\mu\\eta_{t})\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\Phi\\mathrm{pn}}^{t,3}}{\\partial b_{i}}=-\\mu\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}+\\mu\\eta_{t}\\left(-\\mu\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}-(\\mu+\\mu^{2}\\eta_{t})\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}\\right)=-\\mu(1+\\mu\\eta_{t})^{2}\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By induction, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\mathrm{dyn}}^{t,r}}{\\partial b_{i}}=-\\mu(1+\\mu\\eta_{t})^{r-1}\\sum_{\\tau=1}^{t-1}\\Delta b_{i}^{\\tau}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, the expectation of the local update of bias in the output layer at round $t$ can be computed as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\Delta b_{i}^{(k),t}\\right]=\\displaystyle\\sum_{r=1}^{R}(1+\\mu\\eta_{t})^{r-1}\\mu\\eta_{t}\\displaystyle\\sum_{\\tau=1}^{t-1}\\mathbb{E}\\left[\\Delta b_{i}^{(k),\\tau}\\right]}\\\\ &{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~=\\left((1+\\mu\\eta_{t})^{R}-1\\right)\\displaystyle\\sum_{\\tau=1}^{t-1}\\mathbb{E}\\left[\\Delta b_{i}^{(k),\\tau}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since the objective function of $\\mathbb{E}\\left[\\Delta b_{i}^{(k),1}\\right]$ coincides with that of FedAvg, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k),1}\\right]=\\eta_{1}R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\eta_{1}$ is the learning rate at global round $t=1$ . Then, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathbb{E}\\left[\\Delta b_{i}^{(k),2}\\right]=\\eta_{1}R\\left((1+\\mu\\eta_{2})^{R}-1\\right)\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)}\\\\ {=a_{1}a_{2}\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $a_{1}=\\eta_{1}R$ and $a_{2}=(1+\\mu\\eta_{2})^{R}-1$ . Furthermore, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k),3}\\right]=a_{1}a_{3}(1+a_{2})\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k),4}\\right]=a_{1}a_{4}(1+a_{2}+a_{3}+a_{2}a_{3})\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k),5}\\right]=a_{1}a_{5}(1+a_{2}+a_{3}+a_{4}+a_{2}a_{3}+a_{3}a_{4}+a_{2}a_{3}a_{4})\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By induction, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left[\\Delta b_{i}^{(k),t}\\right]=\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)a_{1}a_{t}\\cdot\\left(1+\\sum_{i=0}^{t-3}\\sum_{\\tau=2}^{t-1}\\mathbb{I}(\\tau+i<t)\\prod_{i=\\tau}^{\\tau+i}a_{s}\\right)}\\\\ {\\displaystyle=a\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $a_{t}\\,=\\,(1+\\mu\\eta_{t})^{R}-1$ and $\\begin{array}{r}{a\\,=\\,a_{1}a_{t}\\,\\Big(1+\\sum_{i=0}^{t-3}\\sum_{\\tau=2}^{t-1}\\mathbb{I}(\\tau+i<t)\\prod_{i=\\tau}^{\\tau+i}a_{s}\\Big)\\,>\\,0}\\end{array}$ . After comparing Eq. (89) with its counterpart in the case of FedAvg, we conclude that the previously presented analysis of HiCS-FL extends to FedDyn. ", "page_idx": 25}, {"type": "text", "text": "A.8.3 Model-Contrastive Federated Learning (Moon) ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Moon [16] relies on the objective function with a contrastive term ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{moon}}=\\frac{1}{B l}\\sum_{j=1}^{l}\\sum_{n=1}^{B}\\mathcal{L}_{\\mathbf{CE}}^{(j,n)}-\\mu\\log\\frac{\\exp(\\sin(\\mathbf{z}^{(j,n)},\\mathbf{z}_{\\mathbf{glob}}^{(j,n)})/T)}{\\exp(\\sin(\\mathbf{z}^{(j,n)},\\mathbf{z}_{\\mathbf{glob}}^{(j,n)})/T)+\\exp(\\sin(\\mathbf{z}^{(j,n)},\\mathbf{z}_{\\mathbf{pev}}^{(j,n)})/T)},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\mathbf{z}^{(j,n)}$ denotes the output of the feature extractor of the local model $\\theta_{k}^{t}$ , $\\mathbf{z}_{\\mathrm{glob}}^{(j,n)}$ is the output of the feature extractor of the global model $\\theta^{t}$ , and $\\mathbf{z}_{\\mathrm{prev}}^{(j,n)}$ is the output of the feature extractor of the local model in the previous round $\\theta_{k}^{t-1}$ . Since the contrastive term does not depend on the parameters of bias in the output layer, it holds that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}_{\\mathrm{moon}}^{(j,n)}}{\\partial b_{i}}=\\frac{\\partial\\mathcal{L}_{\\mathbf{CE}}^{(j,n)}}{\\partial b_{i}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since the expectation of the local updates of bias in the output layer coincides with the one in case of FedAvg, previously presented analysis of HiCS-FL extends to Moon. ", "page_idx": 25}, {"type": "text", "text": "A.9 Optimization Algorithms Beyond SGD ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Optimizers beyond SGD utilize different model update rules which in principle may lead to different properties of the local update of the bias in the output layer. However, for several variants of SGD, the properties of the local update of the bias remain such that our presented analysis still applies. ", "page_idx": 25}, {"type": "text", "text": "A.9.1 SGD with momentum ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In each local epoch $r$ , SGD with momentum updates the model according to ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{m}_{k}^{t,r}=\\mu\\boldsymbol{m}_{k}^{t,r-1}+(1-\\mu)\\nabla{\\mathcal{L}}_{\\mathbf{C}\\mathbf{E}}^{t,r},}\\\\ &{\\qquad\\qquad\\boldsymbol{g}_{k}^{t,r}=\\boldsymbol{m}_{k}^{t,r},}\\\\ &{\\qquad\\quad\\theta_{k}^{t,r}=\\theta_{k}^{t,r-1}-\\eta_{t}\\boldsymbol{g}_{k}^{t,r},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where mtk,rdenotes the momentum in the r-th local epoch, \u00b5 is the weight for the momentum, and $m_{k}^{t,1}=\\ddot{\\nabla}\\mathcal{L}_{\\mathbf{CE}}^{t,1}$ . Then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\Delta\\theta_{k}^{t}=-\\eta_{t}\\sum_{r=1}^{R}g_{k}^{t,r},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where ", "page_idx": 26}, {"type": "equation", "text": "$$\nm_{k}^{t,1}=\\nabla\\mathcal{L}_{\\mathbf{CE}}^{t,1},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\nm_{k}^{t,2}=\\mu\\nabla\\mathcal{L}_{\\mathbf{C}\\mathbf{E}}^{t,1}+(1-\\mu)\\nabla\\mathcal{L}_{\\mathbf{C}\\mathbf{E}}^{t,2},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Therefore, ", "page_idx": 26}, {"type": "equation", "text": "$$\nm_{k}^{t,r}=\\mu^{r-1}\\nabla\\mathcal{L}_{\\mathbf{CE}}^{t,1}+\\left(1-\\mu\\right)\\sum_{\\tau=2}^{r}\\mu^{r-\\tau}\\nabla\\mathcal{L}_{\\mathbf{CE}}^{t,\\tau}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and thus we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\Delta\\theta_{k}^{t}=-\\eta_{t}\\left(\\sum_{r=2}^{R}\\left(\\mu^{r-1}\\nabla{\\mathcal{L}}_{\\mathrm{CE}}^{t,1}+(1-\\mu)\\sum_{\\tau=2}^{r}\\mu^{r-\\tau}\\nabla{\\mathcal{L}}_{\\mathrm{CE}}^{t,\\tau}\\right)+\\nabla{\\mathcal{L}}_{\\mathrm{CE}}^{t,1}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Similar to the discussion in the previous section, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]=\\eta_{t}\\left(\\displaystyle\\sum_{r=2}^{R}\\left(\\mu^{r-1}+(1-\\mu)\\displaystyle\\sum_{\\tau=2}^{r}\\mu^{r-\\tau}\\right)+1\\right)\\left(D_{i}^{(k)}\\displaystyle\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)}\\\\ &{\\qquad\\qquad=a\\left(D_{i}^{(k)}\\displaystyle\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\begin{array}{r}{a\\,=\\,\\eta_{t}\\left(\\sum_{r=2}^{R}\\left(\\mu^{r-1}+(1-\\mu)\\sum_{\\tau=2}^{r}\\mu^{r-\\tau}\\right)+1\\right)\\,>\\,0}\\end{array}$ . Similar result is obtained when SGD applies Nesterov acceleration as long as the optimizers are not using second-order momentum. ", "page_idx": 26}, {"type": "text", "text": "A.9.2 Adam Optimizer ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Recall that the two observations regarding the gradient of $\\mathcal{L}_{\\bf C E}$ still hold when training the model with an adaptive optimizer such as Adam [15]. However, Adam updates the model differently from SGD. In particular, each entry of the gradient has an adaptive learning rate tied to its magnitude. With an SGD optimizer, the magnitude of the $i$ -th entry of the local update of bias $\\Delta\\mathbf{b}^{(k)}$ is approximately proportional to the fraction of the samples with label $i$ , ${D}_{i}^{(k)}$ (if $\\mathcal{E}_{i}$ is small), ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]=\\eta_{t}R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "However, this observation does not hold when using the Adam optimizer for the local update because each entry has a different learning rate $\\eta_{t,i}$ and thus ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]=\\eta_{t,i}R\\left(D_{i}^{(k)}\\sum_{c=1}^{C}\\mathcal{E}_{c}-\\mathcal{E}_{i}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Although the magnitude of $\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]$ is no longer approximately proportional to ${D}_{i}^{(k)}$ , we can utilize the sign of $\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]$ , i.e., ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathrm{if}\\;D_{i}^{(k)}\\gg D_{j}^{(k)},\\mathrm{then}\\;\\mathbb{P}\\left(\\mathbb{E}\\left[\\Delta b_{i}^{(k)}\\right]>0\\right)\\gg\\mathbb{P}\\left(\\mathbb{E}\\left[\\Delta b_{j}^{(k)}\\right]>0\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Suppose client $k$ has highly imbalanced data, i.e., $H(\\mathcal{D}^{(k)})$ is small. Then the maximal component $\\operatorname*{max}_{i}D_{i}^{(k)}$ is much larger than the other components; in fact, it is likely to have only one positive component in the local update of bias $\\Delta\\mathbf{b}^{(k)}$ . On the contrary, suppose client $u$ has balanced data and thus $H(\\mathcal{D}^{(u)})$ is large. The maximal component $\\operatorname*{max}_{i}\\bar{D_{i}^{(u)}}$ is then very close to the other components, and it is likely to observe larger number of positive components in the local update of $\\Delta\\mathbf{b}^{(u)}$ . While characterizing $\\mathbb{P}(\\mathbb{E}[\\Delta b_{i}^{(k)}]\\bar{>}0)$ appears challenging, we can empirically infer that client $u$ with more balanced data has a local update of bias $\\Delta\\mathbf{b}^{(u)}$ with more positive components. With ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{H}(\\mathcal{D}^{(u)})\\triangleq H(\\mathrm{softmax}(\\Delta\\mathbf{b}^{(u)},T)),}\\\\ &{}\\\\ &{\\hat{H}(\\mathcal{D}^{(k)})\\triangleq H(\\mathrm{softmax}(\\Delta\\mathbf{b}^{(k)},T)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "$\\hat{H}(\\mathcal{D}^{(u)})$ is more likely to be larger than $\\hat{H}(\\mathcal{D}^{(k)})$ . The examples of estimated entropy when utilizing Adam as the optimizer are provided in Section. A.12. ", "page_idx": 27}, {"type": "text", "text": "A.10 Visualization of Data Partitions ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "To generate non-IID data partitions we follow the strategy in [35], utilizing Dirichlet distribution with different concentration parameters $\\alpha$ to control the heterogeneity levels. In particular, the number of samples with label $i$ owned by client $k$ is set t o XjNi=(k1) XNi(ij),where Xi(1), . . . , Xi(N)are drawn from $\\operatorname{Dir}(\\alpha)$ and $N_{i}$ denotes the total number of samples with label $i$ in the overall dataset. For the setting with multiple $\\alpha$ , we divide the overall training set into $|\\alpha|$ equal parts and generate data partitions according to the method above. Figures 6 and 7 illustrate the class distribution of local clients by displaying the number of samples with different labels; colors distinguish between magnitudes \u2013 the darker the color, the more samples are in the class. ", "page_idx": 27}, {"type": "image", "img_path": "HhnpPISAUH/tmp/fe8cb98e1a1699a60bad3289c2f084ad8b067bea1e79006216db405e4acdc937.jpg", "img_caption": ["Figure 6: Results on CIFAR10. Training data is split into 50 partitions according to a Dirichlet distribution (50 clients). The concentration parameter is as follows: (1) $\\alpha\\in\\{0.001,0.01,0.1,0.5,1.0\\}$ ; (2) $\\alpha\\in\\{0.001,0.002,0.005,0.01,0.5\\}$ ; (3) $\\alpha\\in\\{0.001,0.002,0.005,\\dot{0}.01,0.1\\}$ . The figures (a), (b) and (c) correspond to settings (1), (2) and (3), respectively. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "HhnpPISAUH/tmp/8d29d9eedd8ff2b2c6f78b36dd5da64e56ffc819d622c04d024e839253a2f0bf.jpg", "img_caption": ["Figure 7: Results on Mini-ImageNet. Training data is split into 100 partitions according to Dirichlet distribution (100 clients). The concentration parameter is varied as follows: (1) $\\alpha\\ \\in$ $\\left\\lbrace0.001,0.01,0.1,0.5,1.0\\right\\rbrace$ ; (2) $\\alpha\\,\\in\\,\\{0.001,0.005,0.01,0.1,1.0\\}$ . The figures (a) and (b) correspond to settings (1) and (2), respectively. "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Table 5: The columns \u201cExtra Computation\u201d and \u201cExtra Communication\u201d denote the computation and communication complexity of additional operations in each sampling scheme compared to random sampling. ", "page_idx": 28}, {"type": "table", "img_path": "HhnpPISAUH/tmp/8304e7fc71607eabec18a34e12df07d61bc03e866089bccbb45a7565b35f3ceb.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "A.11 Computational and Communication Complexity ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We compare the communication and computational costs of HiCS-FL with those of the competing methods, including Power of Choice (pow-d) [8], Clustered Sampling [11] and DivFL [2], and map them against random sampling, as shown in Table. 5. In its ideal setting, pow-d selects $K$ clients with the largest local validation loss among all $N$ clients. To compute the local validation loss at the beginning of a global training round $t$ , the server must send the global model to all clients. Compared to the random sampling strategy where the global model is sent to only $K$ clients, pow-d must transmit additional $(N-K)|\\theta^{t}|$ model parameters. Moreover, pow-d requires all clients to compute validation loss of the global model $\\theta^{t}$ on local datasets, which incurs additional $\\mathcal{O}(N|\\theta^{t}|)$ computations. While communication requirements of Clustered Sampling do not exceed those of random sampling, the server must run a clustering algorithm on the local updates of dimension $|\\theta^{t}|$ (the same as gradients). DivFL relies on maximizing a submodular function to select the most diverse clients based on all clients\u2019 gradients, leading to a transmission overhead and additional computation involving $|\\theta^{t}|$ -dimensional gradients. In our experiments, DivFL has consistently required the longest training time and memory usage due to its dependence on the submodularity maximizer. FedCor [28] cliams that only partial clients participating in the global update after warm-up stage but still needs all clients to perform inference for computing validation loss in the warm-up stage. Our proposed method, HiCS-FL, does not require any additional transmission of model parameters; furthermore, in HiCS-FL the server clusters clients based on their local updates of the bias in the output layer, which is low-dimensional and model-agnostic. Overall, HiCS-FL requires negligible computational overhead to significantly improve the performance of non-iid Federated Learning. ", "page_idx": 28}, {"type": "text", "text": "A.12 Examples of Estimated Entropy ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "To further illustrate the proposed framework, here we show a comparison between the estimated entropy of data label distribution and the true entropy. Specifically, Figures 8 and 9 show that the entropy estimated by the proposed method is close to the true entropy; the experiments were conducted on FMNIST and Mini-ImageNet, using SGD and Adam as optimizers, respectively. As stated in Theorem 3.3, the clients with larger true entropy are likely to have lager estimated entropy. In case where the model is trained with Adam, estimated entropy of data label distribution is not as accurate as in the case of using SGD. Figures 10 and 11 compare the performance of estimating entropy with SGD and Adam optimizers for the same setting of $\\alpha$ . Notably, as shown in the figures, the method is capable of distinguishing clients with extremely imbalanced data from those with balanced data. ", "page_idx": 28}, {"type": "image", "img_path": "HhnpPISAUH/tmp/2f73389aa8c2b37df289a31030fc66903bea001cf4ad9fd91fb2dabdb5db3532.jpg", "img_caption": [], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "Figure 8: The estimated entropy of data label distribution in experiments on FMNIST with SGD as the optimizer. The parameter $\\alpha$ for the two figures: (a) $\\alpha\\,\\in\\,\\{0.01,0.02,0.05,0.1,0.2\\}$ ; (b) $\\alpha\\in\\{0.001,0.002,0.005,0.01,0.5\\}$ ", "page_idx": 29}, {"type": "image", "img_path": "HhnpPISAUH/tmp/459d1a2652d1b2587fc8deb75039ed975fb62bb0f961a140c1753fd8fbbaa83e.jpg", "img_caption": ["Figure 9: The estimated entropy of data label distribution in experiments on Mini-ImageNet with Adam as the optimizer. The parameter $\\alpha$ for the two figures: (a) $\\bar{\\alpha}\\in\\{0.001,0.01,0.1,0.\\bar{5},1.0\\}$ ; (b) $\\alpha\\in\\{0.001,0.\\dot{0}05,0.01,0.\\dot{1},1.0\\}$ . "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "HhnpPISAUH/tmp/5bfc701d0eaf5cdfd8023cabfd1bb209af144e3c8c329069e311f27fe4581b51.jpg", "img_caption": ["Figure 10: The estimated entropy of data label distribution in experiments on CIFAR10 with $\\alpha\\in$ $\\left\\lbrace0.001,0.01,0.1,0.5,1.0\\right\\rbrace$ . (a) The result of the experiments using SGD as the optimizer. (b) The result of the experiments using Adam as the optimizer. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "HhnpPISAUH/tmp/f01882c76676ee215faad863ef3f7c609670859fd9e0175abd654736004cd78c.jpg", "img_caption": ["Figure 11: The estimated entropy of data label distribution in experiments on CIFAR10 with $\\alpha\\in$ {0.001, 0.002, 0.005, 0.01, 0.5}. (a) The result of the experiments using SGD as the optimizer. (b) The result of the experiments using Adam as the optimizer. "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 32}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] Justification: [NA] Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 33}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of exNoecution) needed to reproduce the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [No] Justification: [NA] Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 34}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 35}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 35}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 35}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 36}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 36}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 36}]