[{"figure_path": "HhnpPISAUH/figures/figures_2_1.jpg", "caption": "Figure 1: The last two network layers.", "description": "This figure shows the architecture of the last two layers of a neural network used in the HiCS-FL algorithm. The input is a vector z \u2208 R<sup>L</sup> representing the signals from the previous layers. These signals are then multiplied by a weight matrix W \u2208 R<sup>C\u00d7L</sup>, and a bias vector b \u2208 R<sup>C</sup> is added. The result is a vector q \u2208 R<sup>C</sup> representing the prediction, where each element corresponds to the logit for a class. Finally, this prediction is compared to a one-hot label representing the true class.", "section": "3 HiCS-FL: Federated Learning via Hierarchical Clustered Sampling"}, {"figure_path": "HhnpPISAUH/figures/figures_7_1.jpg", "caption": "Figure 2: Test accuracy for the global model on 3 groups of data partitions of FMNIST and CIFAR10.", "description": "This figure shows the test accuracy of the global model trained using different client selection schemes (random sampling, pow-d, clustered sampling, DivFL, FedCor, and HiCS-FL) across three different data heterogeneity settings for FMNIST and CIFAR10 datasets.  Each setting represents a different level of data imbalance across the clients. The results demonstrate the performance of HiCS-FL in comparison to other state-of-the-art methods.", "section": "4 Experiments"}, {"figure_path": "HhnpPISAUH/figures/figures_7_2.jpg", "caption": "Figure 3: Training loss of HiCS-FL compared to four baselines for setting (1) on the three datasets.", "description": "The figure shows the average training loss for all clients across different global training rounds for three benchmark datasets: FMNIST, CIFAR10, and Mini-ImageNet. The performance of HiCS-FL is compared against four baseline methods: random sampling, pow-d, Clustered Sampling, and FedCor. The results are presented for the data partition setting (1), where 80% of the clients have severely imbalanced data while the remaining 20% have balanced data. In all three datasets, HiCS-FL demonstrates significantly faster convergence with lower variance than the other methods.", "section": "4 Experiments"}, {"figure_path": "HhnpPISAUH/figures/figures_8_1.jpg", "caption": "Figure 2: Test accuracy for the global model on 3 groups of data partitions of FMNIST and CIFAR10.", "description": "This figure compares the test accuracy of different client selection methods across three different data heterogeneity settings for the FMNIST and CIFAR10 datasets.  Setting (1) represents a scenario where 80% of clients have severely imbalanced data while the remaining 20% have balanced data. Setting (2) has 80% of clients with severely imbalanced data and 20% with mildly imbalanced data. Finally, setting (3) has all clients with severely imbalanced data.  The plot shows the test accuracy over a certain number of global rounds for each method: Random Sampling, pow-d, Clustered Sampling, DivFL (ideal), FedCor, and HiCS-FL.  The results highlight HiCS-FL's superior performance, particularly in settings with a mix of balanced and imbalanced data, demonstrating its effectiveness in non-IID federated learning scenarios.", "section": "4.1 Comparison on Test Accuracy and Training Loss"}, {"figure_path": "HhnpPISAUH/figures/figures_13_1.jpg", "caption": "Figure 5: Visualization of the difference between local gradients and the global gradient (evaluated if all the data is centrally collected).", "description": "This figure shows the empirical validation of Assumption 3.1, which bounds the dissimilarity between local and global gradients based on data heterogeneity.  The plots visualize the relationship between the Shannon entropy of the client's data label distribution (H(D(k)) on the x-axis) and the squared Euclidean norm of the difference between the local gradient and the true global gradient (on the y-axis) for FMNIST and CIFAR10 datasets. The dashed lines represent negative exponential functions fitted to the data points, demonstrating that the difference between local and global gradients increases as the data label distribution becomes more imbalanced (i.e., H(D(k)) decreases). This visually confirms Assumption 3.1, supporting the theoretical analysis of HiCS-FL.", "section": "3.2 Estimating Client's Data Heterogeneity"}, {"figure_path": "HhnpPISAUH/figures/figures_27_1.jpg", "caption": "Figure 6: Results on CIFAR10. Training data is split into 50 partitions according to a Dirichlet distribution (50 clients). The concentration parameter \u03b1 is as follows: (1) \u03b1 \u2208 {0.001, 0.01, 0.1, 0.5, 1.0}; (2) \u03b1 \u2208 {0.001, 0.002, 0.005, 0.01, 0.5}; (3) \u03b1 \u2208 {0.001, 0.002, 0.005, 0.01, 0.1}. The figures (a), (b) and (c) correspond to settings (1), (2) and (3), respectively.", "description": "This figure shows the data distribution across 50 clients in CIFAR10 for three different levels of heterogeneity. Each subfigure represents a different setting of the concentration parameter \u03b1 in the Dirichlet distribution used to generate non-IID data. Each cell in the heatmap represents the number of samples of a certain class owned by a specific client. The color intensity indicates the number of samples; darker colors represent more samples.", "section": "4 Experiments"}, {"figure_path": "HhnpPISAUH/figures/figures_27_2.jpg", "caption": "Figure 6: Results on CIFAR10. Training data is split into 50 partitions according to a Dirichlet distribution (50 clients). The concentration parameter \u03b1 is as follows: (1) \u03b1 \u2208 {0.001, 0.01, 0.1, 0.5, 1.0}; (2) \u03b1 \u2208 {0.001, 0.002, 0.005, 0.01, 0.5}; (3) \u03b1 \u2208 {0.001, 0.002, 0.005, 0.01, 0.1}. The figures (a), (b) and (c) correspond to settings (1), (2) and (3), respectively.", "description": "This figure shows the class distribution of training data across 50 clients in CIFAR10 dataset under three different settings of data heterogeneity controlled by Dirichlet distribution concentration parameter \u03b1. Each subfigure shows a heatmap where rows represent clients, columns represent classes, and color intensity represents the number of samples in each class per client. The three settings represent different levels of data heterogeneity; from most heterogeneous (a) to least heterogeneous (c).", "section": "4 Experiments"}, {"figure_path": "HhnpPISAUH/figures/figures_29_1.jpg", "caption": "Figure 8: The estimated entropy of data label distribution in experiments on FMNIST with SGD as the optimizer. The parameter \u03b1 for the two figures: (a) \u03b1 \u2208 {0.01,0.02, 0.05, 0.1, 0.2}; (b) \u03b1 \u2208 {0.001,0.002, 0.005, 0.01, 0.5}", "description": "This figure shows the estimated entropy of data label distribution in experiments on the FMNIST dataset using SGD optimizer. It compares the estimated entropy (red line) against the true entropy (blue line) for two different settings of the concentration parameter \u03b1.  The concentration parameter \u03b1 controls the level of data heterogeneity; smaller \u03b1 leads to more imbalanced data distributions.  The plot visually demonstrates the relationship between the estimated entropy and the true entropy for various data distributions, providing empirical support for the accuracy of the proposed heterogeneity estimation method within the HiCS-FL framework. ", "section": "A.12 Examples of Estimated Entropy"}, {"figure_path": "HhnpPISAUH/figures/figures_29_2.jpg", "caption": "Figure 2: Test accuracy for the global model on 3 groups of data partitions of FMNIST and CIFAR10.", "description": "This figure compares the test accuracy of different federated learning client selection methods across three different data heterogeneity scenarios for the FMNIST and CIFAR10 datasets.  The x-axis represents the number of global training rounds, and the y-axis represents the test accuracy of the global model.  Each line represents a different client selection method (Random Sampling, pow-d, Clustered Sampling, DivFL, FedCor, and HiCS-FL). The three subfigures (a), (b), and (c) correspond to different data heterogeneity levels in FMNIST, while (d), (e), and (f) correspond to those in CIFAR10.  HiCS-FL consistently outperforms other methods, achieving faster convergence and lower variance, particularly in scenarios with a mixture of balanced and highly imbalanced data among clients.", "section": "4.1 Comparison on Test Accuracy and Training Loss"}, {"figure_path": "HhnpPISAUH/figures/figures_29_3.jpg", "caption": "Figure 2: Test accuracy for the global model on 3 groups of data partitions of FMNIST and CIFAR10.", "description": "The figure shows the test accuracy for the global model trained with different schemes for three different data partition settings of FMNIST and CIFAR10 datasets. Each setting represents a different level of data heterogeneity among the clients, ranging from severely imbalanced data to balanced data. The results demonstrate the performance of HiCS-FL in comparison with other state-of-the-art client selection methods. HiCS-FL outperforms other methods across different settings, exhibiting the fastest convergence rates and the least amount of variance, particularly significant when there is a mix of balanced and imbalanced data among clients.", "section": "4 Experiments"}, {"figure_path": "HhnpPISAUH/figures/figures_30_1.jpg", "caption": "Figure 11: The estimated entropy of data label distribution in experiments on CIFAR10 with \u03b1 \u2208 {0.001, 0.002, 0.005, 0.01, 0.5}. (a) The result of the experiments using SGD as the optimizer. (b) The result of the experiments using Adam as the optimizer.", "description": "This figure compares the estimated entropy of data label distribution with the true entropy for two different optimizers (SGD and Adam) on the CIFAR10 dataset. The data is partitioned using a Dirichlet distribution with concentration parameter \u03b1 = [0.001, 0.002, 0.005, 0.01, 0.5]. The x-axis represents the client index, and the y-axis represents the entropy. The red line shows the estimated entropy, and the blue line shows the true entropy.", "section": "A.12 Examples of Estimated Entropy"}]