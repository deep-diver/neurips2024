[{"figure_path": "gBOQ0ACqoO/tables/tables_7_1.jpg", "caption": "Table 1: Comparisons with the state of the art on the nuScenes validation and test sets. FPS is measured on a 3090 GPU by default, and * denotes the inference speed on an A100 GPU referred from the original paper. Note that all results are obtained without any model ensemble or test time augmentation.", "description": "This table compares the proposed DH-Fusion method with other state-of-the-art methods on the nuScenes dataset for 3D object detection.  It shows the performance (NDS and mAP) and inference speed (FPS) of various methods categorized by the type of 2D backbone used (ResNet50, SwinTiny, Others).  The table highlights that DH-Fusion achieves higher accuracy and faster inference speed compared to existing methods.", "section": "4.2 Comparison to the State of the Art"}, {"figure_path": "gBOQ0ACqoO/tables/tables_7_2.jpg", "caption": "Table 2: Robustness experiments on nuScenes-C. Numbers are NDS / mAP.", "description": "This table presents the results of robustness experiments conducted on the nuScenes-C dataset, which includes various corruptions such as weather, sensor, motion, object, and alignment issues. The table shows the performance of different methods, including the proposed DH-Fusion-light method, under different corruption conditions. The performance is evaluated using two metrics: NDS (nuScenes Detection Score) and mAP (mean Average Precision).  The results demonstrate the robustness of DH-Fusion-light compared to other state-of-the-art methods.", "section": "4.3 Robustness to Corruptions"}, {"figure_path": "gBOQ0ACqoO/tables/tables_20_1.jpg", "caption": "Table 6: Comparisons on nuScenes validation set for 3D multi-object tracking.", "description": "This table presents the results of 3D multi-object tracking experiments on the nuScenes validation set.  It compares the performance of different methods, including TransFusion, BEVFusion, ObjectFusion, and the authors' DH-Fusion-light method, in terms of AMOTA (Average Multi-Object Tracking Accuracy), AMOTP (Average Multi-Object Tracking Precision), and IDS (Identity Switches).  Higher AMOTA and lower AMOTP and IDS indicate better tracking performance.  The table highlights that DH-Fusion-light achieves the best performance among all methods.", "section": "A.2.1 3D Multi-Object Tracking Experiments"}, {"figure_path": "gBOQ0ACqoO/tables/tables_20_2.jpg", "caption": "Table 7: Comparisons on nuScenes validation set at different depths. The numbers are mAP.", "description": "This table presents the mean Average Precision (mAP) achieved by different methods at various depth ranges: Near (0-20m), Middle (20-30m), and Far (>30m).  It shows a comparison of the performance of TransFusion-L, BEVFusion, ObjectFusion, and the proposed DH-Fusion-light method. The results highlight the improved performance of DH-Fusion-light, particularly at longer ranges.", "section": "4.2 Comparison to the State of the Art"}, {"figure_path": "gBOQ0ACqoO/tables/tables_21_1.jpg", "caption": "Table 8: Comparisons for each corruption level on the nuScenes-C. Corruptions exist in both modalities by default. (L) means that only the point cloud modality has corruptions, and (C) means that only the image modality has corruptions. Numbers are NDS / MAP.", "description": "This table presents a detailed breakdown of the performance of different models (FUTR3D, TransFusion, BEVFusion, and DH-Fusion) on the nuScenes-C dataset, which includes various types of data corruptions. The results are categorized by corruption type (Weather, Sensor, Motion, Object, Alignment) and severity.  Each corruption type is further divided into sub-categories such as snow, rain, fog, and specific sensor corruptions.  The table shows NDS and mAP scores for each model and corruption scenario. (L) and (C) indicate if the corruption only affects LiDAR or camera data, respectively.  This allows for a nuanced comparison of the model's robustness under diverse conditions.", "section": "4.3 Robustness to Corruptions"}]