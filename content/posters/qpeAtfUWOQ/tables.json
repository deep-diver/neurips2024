[{"figure_path": "qpeAtfUWOQ/tables/tables_8_1.jpg", "caption": "Table 1: The depth uncertainty estimation performance on the LF dataset, quantified by the AUSE with MAE error.", "description": "This table presents a quantitative evaluation of depth uncertainty estimation methods on the LF dataset.  The Area Under Sparsification Error (AUSE) metric, combined with Mean Absolute Error (MAE), assesses the alignment between predicted uncertainty and actual error. Lower AUSE values indicate better calibration between predicted uncertainty and the ground truth MAE.", "section": "4.2 Uncertainty Estimation Quality Evaluation"}, {"figure_path": "qpeAtfUWOQ/tables/tables_8_2.jpg", "caption": "Table 2: The performance of novel view rendering and uncertainty estimation on rendered images within the LF and LLFF dataset.", "description": "This table presents a quantitative comparison of the proposed multi-scale variational inference method against several baseline methods for view synthesis and uncertainty estimation.  The metrics used include PSNR, SSIM, and LPIPS to evaluate the quality of synthesized novel views, and AUSE and NLL to assess the accuracy and reliability of uncertainty estimations. The results are shown separately for the LF and LLFF datasets, providing a comprehensive evaluation of the method's performance across different scenes and datasets.", "section": "4.2 Uncertainty Estimation Quality Evaluation"}, {"figure_path": "qpeAtfUWOQ/tables/tables_15_1.jpg", "caption": "Table 3: Inference time for variants of our method and the ensemble method.", "description": "This table presents the inference time in seconds for different variants of the proposed multi-scale variational inference method and compares it against the ensemble method.  The variants differ in the number of parameters being offset: \n - `Ours_{full}` offsets all parameters (position, scale, color, opacity)\n - `Ours_{p,S,c}` offsets position, scale, and color\n - `Ours_{p,S,\u03b1}` offsets position, scale, and opacity. The results demonstrate the efficiency gains achieved by the proposed offset table technique in reducing the inference time compared to the ensemble method.", "section": "4.2 Uncertainty Estimation Quality Evaluation"}, {"figure_path": "qpeAtfUWOQ/tables/tables_16_1.jpg", "caption": "Table 4: The experiment on active learning with our uncertainty estimation.", "description": "This table presents the results of an active learning experiment using the proposed uncertainty estimation method.  It compares the performance of view synthesis (measured by PSNR, SSIM, and LPIPS) between randomly selecting training images and using the uncertainty map to guide the selection of the most informative images.  The results show that using the proposed uncertainty-guided active learning approach improves the quality of view synthesis compared to random selection.", "section": "4.2 Uncertainty Estimation Quality Evaluation"}, {"figure_path": "qpeAtfUWOQ/tables/tables_16_2.jpg", "caption": "Table 5: Ablation study on the number of spawned Gaussians.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of varying the number of spawned Gaussians (K) on the performance of the proposed multi-scale variational inference framework.  The study varied K across three values (1, 5, and 10), assessing the impact on PSNR, SSIM, LPIPS, AUSE, and NLL.  The results show that increasing the number of spawned Gaussians generally improves the quality of uncertainty estimation and view synthesis, highlighting the benefit of a diverse parameter sample space.", "section": "4.2 Uncertainty Estimation Quality Evaluation"}]