[{"figure_path": "qpeAtfUWOQ/figures/figures_1_1.jpg", "caption": "Figure 1: The results of cleaning up an unbounded scene reconstructed with 3DGS using our uncertainty estimation. We remove the Gaussians with large parameter uncertainty, the majority of which are under-reconstructed background. The desk at the center of the scene remains complete even after removing 90% of the Gaussians.", "description": "This figure shows the results of applying the proposed uncertainty estimation method to remove noisy Gaussians from a 3D scene reconstructed using 3D Gaussian Splatting (3DGS).  By removing Gaussians with high parameter uncertainty (mostly background elements), the model retains a high-fidelity representation of the main object (a desk) even after removing a large percentage of the total Gaussians (up to 90%). This demonstrates the effectiveness of the method in enhancing scene quality by eliminating noise.", "section": "1 Introduction"}, {"figure_path": "qpeAtfUWOQ/figures/figures_2_1.jpg", "caption": "Figure 2: The comparison between our multi-scale variational inference and other methods. (a) Laplace's Approximation fits posterior with normal distribution where the mean equals maximum a posteriori solution \u03b8MAP and precision equals fisher information I(\u03b8). (b) The ensemble method learns multiple models simultaneously to form the model space samples. (c) Our method builds a multi-scale representation of the scene, where inference is done by sampling the offset distribution and forming finer Gaussians.", "description": "This figure compares three different methods for approximating Bayesian inference in the context of scene representation.  (a) Laplace's Approximation uses a single Gaussian to represent the posterior distribution. (b) Ensemble methods use multiple models to generate a set of samples that cover the posterior distribution. (c) The proposed multi-scale variational inference method leverages explicit scale information in the 3D Gaussian Splatting parameters to efficiently generate diverse samples from the posterior distribution by constructing multi-scale Gaussians. This allows for more efficient and accurate uncertainty estimation.", "section": "Related Work"}, {"figure_path": "qpeAtfUWOQ/figures/figures_3_1.jpg", "caption": "Figure 3: The pipeline of our variational multi-scale representation. We spawn base Gaussians, which are the major components in the scene, into multi-scale finer Gaussians. We learn an offset table to perform the spawn operation by offsetting a subset of attributes. The offset table is learned with variational inference with multi-scale prior. The predictive and parameter uncertainty can be inferred from the variational parameters stored in the table.", "description": "This figure illustrates the proposed variational multi-scale representation for 3D Gaussian Splatting. It shows how base Gaussians (major scene components) are spawned into multi-scale finer Gaussians. An offset table, learned through variational inference with a multi-scale prior, efficiently controls this spawning process by offsetting a subset of Gaussian attributes.  This allows for efficient uncertainty quantification by inferring predictive and parameter uncertainty from the learned offset table.", "section": "3 Proposed Method"}, {"figure_path": "qpeAtfUWOQ/figures/figures_7_1.jpg", "caption": "Figure 4: The visualization of predicted uncertainty map of novel view renderings. Our method demonstrates the best alignment of the uncertainty map with the error map.", "description": "This figure compares the predicted uncertainty maps of novel view renderings generated by four different methods: Ensemble, Bayes' Ray, CF-NeRF, and the proposed method.  Each method's uncertainty map is displayed alongside the corresponding error map (difference between prediction and ground truth).  The figure visually demonstrates that the proposed method's uncertainty map most accurately reflects the areas of high error in the rendered image, indicating a superior alignment between estimated uncertainty and actual rendering errors.", "section": "4.2 Uncertainty Estimation Quality Evaluation"}, {"figure_path": "qpeAtfUWOQ/figures/figures_9_1.jpg", "caption": "Figure 5: The results of noisy Gaussian removal on Mip-NeRF 360 scenes. By gradually deleting the Gaussians with large posterior uncertainty, our method removes the blurred floaters. The object of interest remains complete after the clean-up.", "description": "This figure visualizes the results of removing noisy Gaussians from scenes in the Mip-NeRF 360 dataset. By progressively removing Gaussians with high posterior uncertainty (those contributing least to the scene), the algorithm effectively cleans up the reconstructed scene, reducing noise and floaters. The removal process is shown in three stages: 50% Gaussians, 30% Gaussians.  The zoomed-in details emphasize that the main objects of interest remain intact and high-quality, despite the significant reduction of Gaussians.", "section": "4.4 Removing Noisy Floaters with Posterior Uncertainty"}, {"figure_path": "qpeAtfUWOQ/figures/figures_15_1.jpg", "caption": "Figure 6: The Cumulative Distribution Function (CDF) of opacity offset prior.", "description": "This figure shows the cumulative distribution function (CDF) of the prior distribution for the opacity offset (\u03c7a).  The prior is designed to encourage small perturbations to the opacity during variational inference. The CDF demonstrates a high probability of the offset being close to 1, indicating a preference for small increases in opacity. The sigmoid function used to map a normally distributed variable \u03b7 to \u03c7a contributes to the shape of this CDF, ensuring numerical stability during optimization.", "section": "B Prior Distribution of Opacity Offset"}, {"figure_path": "qpeAtfUWOQ/figures/figures_17_1.jpg", "caption": "Figure 7: Addtional visualization results.", "description": "This figure shows additional qualitative results of the proposed method on the LLFF dataset. For each scene (Room, Horns, Trex), the ground truth images, rendered images from novel viewpoints, the error maps (difference between the ground truth and rendered images), and the predicted uncertainty maps are shown. The error maps and uncertainty maps are aligned, showing that the uncertainty estimates capture the error well. ", "section": "F Addtional Visualization"}]