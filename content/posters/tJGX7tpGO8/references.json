{"references": [{"fullname_first_author": "Huihui Liu", "paper_title": "Overcoming catastrophic forgetting in graph neural networks", "publication_date": "2021-00-00", "reason": "This paper is foundational for the current work, focusing on overcoming catastrophic forgetting in graph neural networks, a key challenge addressed in the current research."}, {"fullname_first_author": "Xikun Zhang", "paper_title": "Hierarchical prototype networks for continual graph representation learning", "publication_date": "2023-00-00", "reason": "This work explores continual graph representation learning, a directly related area, proposing hierarchical prototype networks to address the problem."}, {"fullname_first_author": "Matthias De Lange", "paper_title": "A continual learning survey: Defying forgetting in classification tasks", "publication_date": "2022-00-00", "reason": "This survey provides a broad overview of continual learning, offering context and background for the current research within the wider field."}, {"fullname_first_author": "Fan Zhou", "paper_title": "Overcoming catastrophic forgetting in graph neural networks with experience replay", "publication_date": "2021-00-00", "reason": "This paper introduces the experience replay method for graph neural networks, a technique directly relevant to and used in the current research."}, {"fullname_first_author": "Xikun Zhang", "paper_title": "Sparsified subgraph memory for continual graph representation learning", "publication_date": "2022-00-00", "reason": "This paper proposes a technique called Sparsified Subgraph Memory, which is directly relevant to and compared against the current research."}]}