{"references": [{"fullname_first_author": "Satinder P Singh", "paper_title": "Learning without state-estimation in partially observable markovian decision processes", "publication_date": "1994", "reason": "This paper lays the groundwork for understanding the challenges of learning in partially observable environments, a key context for the current research on balancing context length and mixing times."}, {"fullname_first_author": "Michael Kearns", "paper_title": "Efficient reinforcement learning in factored mdps", "publication_date": "1999", "reason": "This paper presents early work on addressing the computational challenges of reinforcement learning in high-dimensional state spaces, which is relevant to the current work's focus on managing the computational cost of increasing context length."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018", "reason": "This is a foundational textbook in reinforcement learning, providing the essential background and context for understanding the core concepts and challenges addressed in the current research."}, {"fullname_first_author": "Lili Chen", "paper_title": "Decision transformer: Reinforcement learning via sequence modeling", "publication_date": "2021", "reason": "This paper introduces the Decision Transformer architecture, a key method used in the empirical evaluation of the current research, highlighting the connection between sequence modeling and reinforcement learning."}, {"fullname_first_author": "Matthew Riemer", "paper_title": "Continual learning in environments with polynomial mixing times", "publication_date": "2022", "reason": "This paper establishes the concept of mixing time in reinforcement learning, providing a critical theoretical framework for analyzing the trade-offs between context length and mixing time in the current research."}]}