[{"figure_path": "TrN5TcWY87/figures/figures_1_1.jpg", "caption": "Figure 1: Misalignment problem. In LBO, a latent vector z can be associated with two function values y and y' due to the reconstruction error of the VAE, i.e., x \u2260 x'. (a) In Encoder triplet (x, z, y), latent vector z is associated with f(x), where x is the original input to the encoder, i.e., z = q(x). (b) In Decoder triplet (x', z, y'), z is associated with y' = f(x'), which is the objective function value of reconstructed input value x' using the decoder, i.e., x' = p\u03b8(z). The discrepancy between y and y' hinders learning the accurate surrogate model g. We name this the \u2018misalignment problem\u2019.", "description": "This figure illustrates the misalignment problem in Latent Bayesian Optimization (LBO). Due to the reconstruction error of the Variational Autoencoder (VAE), a single latent vector z can be mapped to two different input values (x and x') resulting in two different objective function values (y and y'). This discrepancy makes it difficult to accurately learn a surrogate model of the objective function in the latent space, hindering the optimization process. The figure shows both the encoder and decoder triplets, highlighting the difference between the original input x and its reconstruction x'.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_3_1.jpg", "caption": "Figure 2: Comparison of solutions to the misalignment problem. (a) Some works [13, 14] solve the misalignment problem by the recentering technique that generates the aligned triplet (x', z, y'). However, it requests additional oracle calls as y' = f(x') is unevaluated, and does not fully use the evaluated function value y = f(x). (b) The inversion method (ours) aims to find zinv that generates the evaluated data x to get the aligned triplet (x, zinv, y) without any additional oracle calls.", "description": "This figure compares two methods for addressing the misalignment problem in Latent Bayesian Optimization (LBO).  The misalignment problem arises because the reconstruction error of the Variational AutoEncoder (VAE) means one latent vector z can be associated with multiple objective function values. (a) shows the \"recentering\" method, which generates a new input x' from the latent vector z, evaluates f(x'), and uses (x', z, f(x')) as a training triplet. This requires additional function evaluations. (b) shows the proposed \"inversion\" method, which finds a latent vector zinv that perfectly reconstructs a given input x, resulting in the aligned triplet (x, zinv, f(x)) without extra evaluations.  The inversion method efficiently addresses the misalignment problem by leveraging the pre-trained decoder to directly find the corresponding latent code.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_3_2.jpg", "caption": "Figure 3: (Left) The number of oracle calls to evaluate the queries selected by the acquisition function (blue) and during the recentering (Red). (Right) The number of objective function evaluation that updates the best score.", "description": "This figure compares two methods for solving the misalignment problem in Latent Bayesian Optimization: recentering and inversion. The left panel shows the number of oracle calls required for query selection using the acquisition function and for generating aligned triplets using the recentering technique.  The recentering technique requires significantly more oracle calls.  The right panel displays the number of objective function evaluations resulting in improved best scores for each approach. The inversion method (not shown in this figure) offers an advantage by not needing extra oracle calls to update the VAE.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_6_1.jpg", "caption": "Figure 4: Optimization results on Guacamol benchmark tasks. The lines and ranges indicate the average and standard error of ten runs under the same settings. A higher score is a better score.", "description": "This figure visualizes the performance comparison of different Bayesian Optimization methods on seven Guacamol benchmark tasks.  The x-axis represents the number of oracle calls (the number of times the expensive black-box objective function is evaluated), while the y-axis shows the best objective function value achieved.  Each line represents the average performance of ten independent runs for a particular method, and the shaded area indicates the standard error. The graph helps readers understand the relative effectiveness of each method in optimizing molecule design by showing which methods converge faster to better solutions given a limited evaluation budget.", "section": "5 Experiments"}, {"figure_path": "TrN5TcWY87/figures/figures_7_1.jpg", "caption": "Figure 5: Optimization results on various tasks and settings. Note that: (a) A lower score is a better score. (b) A higher score is a better score.", "description": "This figure presents the results of the proposed method InvBO against several baselines on three different tasks: DRD3, arithmetic expression, and Guacamol.  The results are displayed for both small and large budget settings.  In the DRD3 and arithmetic expression tasks, a lower score indicates better performance, while the Guacamol tasks use a higher score for better performance. The figure shows that InvBO consistently outperforms other LBO methods across all tasks and budget settings.", "section": "5 Experiments"}, {"figure_path": "TrN5TcWY87/figures/figures_7_2.jpg", "caption": "Figure 2: Comparison of solutions to the misalignment problem. (a) Some works [13, 14] solve the misalignment problem by the recentering technique that generates the aligned triplet (x', z, y'). However, it requests additional oracle calls as y' = f(x') is unevaluated, and does not fully use the evaluated function value y = f(x). (b) The inversion method (ours) aims to find ziny that generates the evaluated data x to get the aligned triplet (x, Zinv, y) without any additional oracle calls.", "description": "This figure compares two different approaches to handle the misalignment problem in Latent Bayesian Optimization (LBO). The misalignment problem arises from the reconstruction error of the variational autoencoder (VAE) used in LBO, where a single latent vector z can be associated with multiple different objective function values.  (a) shows the \"recentering\" technique used in previous LBO methods. This technique generates an aligned triplet (x', z, y') by finding a new input x' that produces the same latent vector z and objective function value y. However, this requires additional evaluations of the objective function, making it inefficient. (b) presents the proposed \"inversion\" method, which finds a latent vector zinv that perfectly reconstructs the original input x, forming an aligned triplet (x, zinv, y) without any extra function evaluations.  The inversion method addresses the inefficiency of the recentering technique.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_8_1.jpg", "caption": "Figure 2: Comparison of solutions to the misalignment problem. (a) Some works [13, 14] solve the misalignment problem by the recentering technique that generates the aligned triplet (x', z, y'). However, it requests additional oracle calls as y' = f(x') is unevaluated, and does not fully use the evaluated function value y = f(x). (b) The inversion method (ours) aims to find ziny that generates the evaluated data x to get the aligned triplet (x, Zinv, y) without any additional oracle calls.", "description": "This figure compares two approaches to address the misalignment problem in Latent Bayesian Optimization (LBO).  The \"Recentering\" method (a) generates an aligned triplet (x', z, y') by reconstructing the input x and evaluating the objective function f(x') at the reconstructed point x', but this requires additional function evaluations. In contrast, the proposed \"Inversion\" method (b) finds the latent code ziny that perfectly reconstructs the original input x, resulting in an aligned triplet (x, zinv, y) without extra function evaluations. The inversion method leverages pre-trained decoder to avoid additional computational cost.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_8_2.jpg", "caption": "Figure 2: Comparison of solutions to the misalignment problem. (a) Some works [13, 14] solve the misalignment problem by the recentering technique that generates the aligned triplet (x', z, y'). However, it requests additional oracle calls as y' = f(x') is unevaluated, and does not fully use the evaluated function value y = f(x). (b) The inversion method (ours) aims to find ziny that generates the evaluated data x to get the aligned triplet (x, Zinv, y) without any additional oracle calls.", "description": "This figure compares two methods for addressing the misalignment problem in Latent Bayesian Optimization (LBO). The recentering technique (a) generates aligned triplets by using the decoder to produce a reconstructed input, then evaluating it with the objective function.  This requires extra function evaluations. In contrast, the proposed inversion method (b) finds the latent code that perfectly reconstructs the original input, requiring no extra function evaluations. The inversion method aims to directly generate an aligned triplet (x, z, y) using the pre-trained decoder.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_8_3.jpg", "caption": "Figure 12: Dissimilarity between x\u00b2 and po (z\u00b2) with and without inversion on med2 and valt tasks. The measurement of dissimilarity is the normalized Levenshtein distance between the SELFIES token. (x-axis: number of iterations, y-axis: normalized Levenshtein distance.)", "description": "This figure empirically demonstrates the effectiveness of the inversion method by comparing the dissimilarity between the input data x and the reconstructed data po(z) with and without the inversion method. The inversion method aims to find a latent code z that perfectly reconstructs the input data x, thereby minimizing the dissimilarity between x and po(z). This figure shows that the inversion method consistently achieves zero dissimilarity, indicating that it generates perfectly aligned data. In contrast, the method without inversion results in significantly higher dissimilarity, indicating the generation of misaligned data.  This visualization highlights the necessity of the inversion method for improving the accuracy of latent Bayesian optimization.", "section": "Analysis on Misalignment Problem and Inversion"}, {"figure_path": "TrN5TcWY87/figures/figures_13_1.jpg", "caption": "Figure 12: Dissimilarity between x\u00b2 and po (z\u00b2) with and without inversion on med2 and valt tasks. The measurement of dissimilarity is the normalized Levenshtein distance between the SELFIES token. (x-axis: number of iterations, y-axis: normalized Levenshtein distance.)", "description": "The figure shows the dissimilarity between the input data and the reconstructed data from the decoder with and without inversion method. The normalized Levenshtein distance is used as a measurement for the dissimilarity. The results demonstrate that using inversion method leads to better reconstruction (lower dissimilarity), while without inversion, the reconstruction is worse (higher dissimilarity).", "section": "Analysis on Misalignment Problem and Inversion"}, {"figure_path": "TrN5TcWY87/figures/figures_14_1.jpg", "caption": "Figure 12: Dissimilarity between x\u00b2 and p\u0473(z\u00b2) with and without inversion on med2 and valt tasks. The measurement of dissimilarity is the normalized Levenshtein distance between the SELFIES token. (x-axis: number of iterations, y-axis: normalized Levenshtein distance.)", "description": "This figure compares the dissimilarity between the original input x and the reconstructed output p\u0473(z) with and without using the inversion method proposed in the paper.  The dissimilarity is measured using the normalized Levenshtein distance on SELFIES tokens. The results show that the inversion method effectively reduces the dissimilarity to near zero, indicating the generation of aligned data, while the method without inversion shows significantly higher dissimilarity, implying misaligned data.", "section": "C Dissimilarity in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_14_2.jpg", "caption": "Figure 13: Optimization results of TuRBO and applying PAS to TuRBO on the synthetic Ackley function with 40 dimensions. The lines and ranges indicate the mean and a standard deviation of ten runs with different seeds.", "description": "This figure compares the performance of the TuRBO algorithm with and without the potential-aware anchor selection (PAS) method on the 40-dimensional Ackley function.  The results show the best score achieved over a series of iterations (number of oracle calls). Error bars represent the standard deviation across ten different runs, highlighting the algorithm's robustness and performance consistency. The plot demonstrates that incorporating PAS into TuRBO improves optimization performance, achieving a better best score with fewer oracle calls.", "section": "D Applying PAS to TuRBO on standard BO benchmark"}, {"figure_path": "TrN5TcWY87/figures/figures_15_1.jpg", "caption": "Figure 4: Optimization results on Guacamol benchmark tasks. The lines and ranges indicate the average and standard error of ten runs under the same settings. A higher score is a better score.", "description": "This figure presents the performance comparison of various Bayesian Optimization methods on seven Guacamol benchmark tasks.  The x-axis represents the number of oracle calls (function evaluations), and the y-axis represents the best objective function score achieved. Each line represents the average performance across ten independent runs, with shaded areas showing the standard error.  The figure illustrates how the proposed InvBO method improves the performance of different baseline methods (TURBO-L, LOL-BO, and CoBO) across various oracle call budgets, consistently achieving higher scores.", "section": "5 Experiments"}, {"figure_path": "TrN5TcWY87/figures/figures_17_1.jpg", "caption": "Figure 4: Optimization results on Guacamol benchmark tasks. The lines and ranges indicate the average and standard error of ten runs under the same settings. A higher score is a better score.", "description": "This figure compares the performance of different Bayesian Optimization methods on seven Guacamol benchmark tasks, each with varying numbers of oracle calls (100, 300, and 500).  The lines represent the average best score achieved by each method, while the shaded areas show the standard error across ten independent runs.  The results illustrate the effectiveness of the proposed InvBO method in improving the performance of various LBO baselines.  Higher scores indicate better results in terms of optimizing molecule properties.", "section": "5.1 Tasks"}, {"figure_path": "TrN5TcWY87/figures/figures_18_1.jpg", "caption": "Figure 2: Comparison of solutions to the misalignment problem. (a) Some works [13, 14] solve the misalignment problem by the recentering technique that generates the aligned triplet (x', z, y'). However, it requests additional oracle calls as y' = f(x') is unevaluated, and does not fully use the evaluated function value y = f(x). (b) The inversion method (ours) aims to find ziny that generates the evaluated data x to get the aligned triplet (x, Zinv, y) without any additional oracle calls.", "description": "This figure compares two methods for addressing the misalignment problem in Latent Bayesian Optimization (LBO). The misalignment problem arises because the reconstruction error of the variational autoencoder (VAE) can lead to a single latent vector z being associated with multiple different function values.  (a) shows the recentering technique, a prior approach that generates an aligned triplet by making additional oracle calls to obtain the function value for the reconstructed input. (b) illustrates the proposed inversion method, which directly finds a latent code that perfectly reconstructs the given input, thus generating an aligned triplet without extra oracle calls. The inversion method is more efficient, avoiding the need for additional function evaluations.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}, {"figure_path": "TrN5TcWY87/figures/figures_18_2.jpg", "caption": "Figure 2: Comparison of solutions to the misalignment problem. (a) Some works [13, 14] solve the misalignment problem by the recentering technique that generates the aligned triplet (x', z, y'). However, it requests additional oracle calls as y' = f(x') is unevaluated, and does not fully use the evaluated function value y = f(x). (b) The inversion method (ours) aims to find ziny that generates the evaluated data x to get the aligned triplet (x, Zinv, y) without any additional oracle calls.", "description": "This figure compares two methods for addressing the misalignment problem in Latent Bayesian Optimization (LBO).  The \"Recentering\" method (a) generates an aligned triplet by reconstructing the input data using the decoder and evaluating the objective function, but requires extra function evaluations. The proposed \"Inversion\" method (b) efficiently finds the latent code that reconstructs the original data, avoiding extra function calls.", "section": "4.1 Misalignment in Latent Bayesian Optimization"}]