[{"figure_path": "lvS2b8CjG5/tables/tables_5_1.jpg", "caption": "Table 1: Datasets for pretraining and downstream tasks", "description": "This table lists the datasets used in the EEGPT paper.  It's divided into two sections: 'pretraining Datasets' and 'Downstream Datasets'. For each dataset, it provides the paradigm (type of brain activity being measured, e.g., motor imagery, emotion), the number of subjects, and the number of target classes in the data. The pretraining datasets were used to train the EEGPT model, while the downstream datasets were used to evaluate its performance on various tasks.", "section": "3.1 Datasets and Data Processing"}, {"figure_path": "lvS2b8CjG5/tables/tables_6_1.jpg", "caption": "Table 2: The results of different methods on TUAB.", "description": "This table presents the results of various methods on the TUAB dataset for abnormal EEG detection.  It compares the Balanced Accuracy (BAC) and Area Under the Receiver Operating Characteristic Curve (AUROC) achieved by several models including SPaRCNet, ContraWR, CNN-T, FFCL, ST-T, BIOT, Ours-Tiny (a smaller version of the proposed EEGPT model), and Ours (the full EEGPT model). The table shows the model size (in millions of parameters) and the performance metrics for each model. This allows for a comparison of performance across different model architectures and sizes.", "section": "3.3 Downstream Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_7_1.jpg", "caption": "Table 3: The results of different methods on TUEV.", "description": "This table presents a comparison of the performance of various methods on the TUEV dataset, including the balanced accuracy, weighted F1 score, and Cohen's kappa.  The methods compared include SPaRCNet, ContraWR, CNN-T, FFCL, ST-T, BIOT, Ours-Tiny, and Ours.  The model sizes are also provided for each method.", "section": "3.3 Downstream Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_7_2.jpg", "caption": "Table 4: The results of universal EEG models on various datasets.", "description": "This table presents the performance of EEGPT and several other models (BENDR, BIOT, LaBraM) on various downstream tasks, including BCIC-2A, BCIC-2B, Sleep-EDFx, KaggleERN, and PhysioP300.  Each row represents a different dataset, while the columns show the model used and its performance metrics: Balanced Accuracy, Cohen's Kappa, and Weighted F1 or AUROC (area under the receiver operating characteristic curve).  The results illustrate EEGPT's ability to achieve state-of-the-art performance across multiple EEG paradigms and datasets.", "section": "3.3 Downstream Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_8_1.jpg", "caption": "Table 7: The results of the ablation study for pretraining methods.", "description": "This table presents the results of an ablation study on the EEGPT model's pretraining methods. Four variants are compared: A (without spatio-temporal representation alignment loss), B (without Layer Normalization), C (without skip connection), and D (with all components).  The table shows the Balanced Accuracy (BAC) on the BCIC-2A dataset, the Area Under the Receiver Operating Characteristic curve (AUROC) on the BCIC-2B dataset, and the AUROC on the KaggleERN dataset for each variant.  The results demonstrate the impact of each component on the model's performance on different downstream tasks.", "section": "A.2 Ablation study for pretraining methods"}, {"figure_path": "lvS2b8CjG5/tables/tables_8_2.jpg", "caption": "Table 6: The results of pretrained models.", "description": "This table presents the results of eight different variations of the EEGPT model trained with different hyperparameters.  The variations differ in embedding dimension (de), the number of layers in the encoder, predictor, and reconstructor, and the number of summary tokens (S). The table shows the total number of parameters in each model variant, the alignment loss (LA), the reconstruction loss (LR), and the balanced accuracy achieved on the BCIC-2A dataset.  The results demonstrate how different hyperparameter settings impact model performance.", "section": "3.5 Pretrain Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_13_1.jpg", "caption": "Table 7: The results of the ablation study for pretraining methods.", "description": "This table presents the ablation study results for the pretraining methods used in the EEGPT model.  It shows the balanced accuracy (BAC) on the BCIC-2A dataset, the area under the receiver operating characteristic curve (AUROC) on the BCIC-2B and KaggleERN datasets for four different model variants.  Variant A excludes the spatio-temporal representation alignment loss (LA). Variant B excludes layer normalization (LN). Variant C excludes the skip connection. Variant D includes all components. The results demonstrate the importance of each component in achieving high performance.", "section": "A.2 Ablation study for pretraining methods"}, {"figure_path": "lvS2b8CjG5/tables/tables_14_1.jpg", "caption": "Table 8: The results of the ablation study for fine-tuning methods.", "description": "This table presents the ablation study results focusing on fine-tuning methods. It compares four model variants (A, B, C, and D) with different configurations regarding adaptive spatial filters (ASF) and linear probing (L-P). The performance is evaluated across three datasets: BCIC-2A (Balanced Accuracy), BCIC-2B (AUROC), and KaggleERN (AUROC). Variant D, which uses both adaptive spatial filters and linear probing, shows the best performance across all three datasets.", "section": "3.3 Downstream Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_15_1.jpg", "caption": "Table 2: The results of different methods on TUAB.", "description": "This table presents the results of different methods on the TUAB dataset for comparing the performance of EEGPT with other state-of-the-art models.  It lists various models, their sizes, balanced accuracy, and AUROC scores, highlighting the performance of EEGPT in comparison.", "section": "3.3 Downstream Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_16_1.jpg", "caption": "Table 3: The results of different methods on TUEV.", "description": "This table presents the results of different methods on the TUEV dataset for evaluating the performance of EEGPT and other models in terms of Balanced Accuracy, Weighted F1, and Cohen's Kappa.  It compares EEGPT (both the large and a smaller \"tiny\" version) against several other state-of-the-art methods (BIOT, ST-T, FFCL, CNN-T, ContraWR, and SPaRCNet). The table allows for a direct comparison of EEGPT's performance relative to other approaches on the same dataset. The model sizes are also listed to show the relationship between model complexity and performance.", "section": "3.3 Downstream Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_16_2.jpg", "caption": "Table 11: The results of different methods on TUAB.", "description": "This table presents the results of three different models on the TUAB dataset. The models compared are BIOT [15], Ours (no pretrained), and Ours. The \"Ours (no pretrained)\" model represents the model without using pretrained parameters.  The metrics used for evaluation are Balanced Accuracy and AUROC.  The table shows that the pretrained \"Ours\" model significantly outperforms the model without pretrained weights, and performs comparably to the BIOT model.", "section": "A.7 Ablation study of self-supervised learning on TUAB"}, {"figure_path": "lvS2b8CjG5/tables/tables_20_1.jpg", "caption": "Table 12: Model design for TUAB dataset.", "description": "This table shows the detailed architecture of the model used for the TUAB dataset.  It specifies the input size, the operators used (convolutional layers, batch normalization, GELU activation, dropout, the EEGPT encoder, flattening, and a linear layer), and hyperparameters such as kernel size, stride, groups, and padding for each layer.  This architecture is designed for processing the TUAB EEG data and extracting relevant features for classification.", "section": "3.3 Downstream Experiment Results"}, {"figure_path": "lvS2b8CjG5/tables/tables_20_2.jpg", "caption": "Table 13: Model design for TUEV dataset.", "description": "This table details the architecture of the model used for the TUEV dataset. It breaks down the input size, operators (layers) used, kernel size, stride, number of groups, and padding for each layer.  It provides a specific configuration for processing EEG data within the context of the TUEV dataset.", "section": "3.1 Datasets and Data Processing"}]