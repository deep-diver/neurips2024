[{"figure_path": "cEtExbAKYV/tables/tables_7_1.jpg", "caption": "Table 1: Quantization results of SD v1.5 and SDXL-Turbo on MS-COCO and SDprompts.", "description": "This table presents the results of applying different quantization methods (Naive PTQ, PTQD, and StepbaQ) to two different diffusion models, Stable Diffusion v1.5 and SDXL-Turbo.  The models are quantized using two different bit-width settings (W8A8 and W4A8), and their performance is evaluated on two datasets, MS-COCO and SDprompts, using FID and CLIP scores. This allows for a comparison of the effectiveness of the different quantization methods in maintaining the quality of the generated images after quantization.", "section": "5 Experiment"}, {"figure_path": "cEtExbAKYV/tables/tables_8_1.jpg", "caption": "Table 2: Ablation Study of SD v1.5 on MS-COCO and SDprompts under W8A8 setting.", "description": "This table presents the results of an ablation study conducted on the Stable Diffusion v1.5 model using the W8A8 quantization setting. The study investigates the impact of different components of the proposed StepbaQ method on the model's performance, as measured by FID and CLIP scores on the MS-COCO and SDprompts datasets.  The components are Temporal Information Alignment (TIA), Latent Adjustment (LA), Step Size Adaptation (SSA), and Error Accumulation (ACC).  Each row represents a different combination of these components, showing the effect of including or excluding each one on the final FID and CLIP scores.", "section": "5.1 Improvement upon Off-the-Shelf Tool"}, {"figure_path": "cEtExbAKYV/tables/tables_8_2.jpg", "caption": "Table 1: Quantization results of SD v1.5 and SDXL-Turbo on MS-COCO and SDprompts.", "description": "This table presents the results of applying different quantization methods (Naive PTQ, PTQD, and StepbaQ) to two different Stable Diffusion models (SD v1.5 and SDXL-Turbo) under two different quantization settings (W8A8 and W4A8).  The performance is measured using FID (Fr\u00e9chet Inception Distance) and CLIP (Contrastive Language-Image Pre-training) scores on two datasets: MS-COCO and SDprompts. Lower FID indicates better image quality and higher CLIP score indicates better alignment between the generated images and their text prompts.", "section": "5 Experiment"}, {"figure_path": "cEtExbAKYV/tables/tables_13_1.jpg", "caption": "Table 4: The kurtosis and skewness of the quantization errors collected under W8A8 setting.", "description": "This table presents the kurtosis and skewness of the quantization errors for three different diffusion models (SDv1.4, SDv1.5, and SDXL-Turbo) under the W8A8 quantization setting.  Kurtosis measures the \"tailedness\" of the distribution, while skewness measures its asymmetry.  These statistics provide insights into the shape of the quantization error distribution and how it deviates from a normal distribution.", "section": "A Analysis of Quantization Error"}]