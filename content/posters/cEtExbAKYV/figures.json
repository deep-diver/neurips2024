[{"figure_path": "cEtExbAKYV/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of the denoising process of StepbaQ and existing methods. Figure (a) shows the original denoising process. Figure (b) demonstrates the negative impact of quantization error without changing the step size, leading to significant accumulation error. Figure (c), on the other hand, illustrates how StepbaQ treats the quantization error as a stepback in the denoising process and adopts corrected steps with a larger step size to eliminate cumulative quantization error.", "description": "This figure illustrates the denoising process in three scenarios:\n(a) A floating-point (FP) model showing the ideal, error-free process.\n(b) A quantized (Q) model without StepbaQ correction shows how quantization errors accumulate and distort the sampling trajectory.\n(c) A quantized (Q) model with StepbaQ demonstrates the method's correction mechanism that reduces the effect of accumulated error by adjusting the sampling steps.", "section": "4 Method"}, {"figure_path": "cEtExbAKYV/figures/figures_5_1.jpg", "caption": "Figure 1: Overview of the denoising process of StepbaQ and existing methods. Figure (a) shows the original denoising process. Figure (b) demonstrates the negative impact of quantization error without changing the step size, leading to significant accumulation error. Figure (c), on the other hand, illustrates how StepbaQ treats the quantization error as a stepback in the denoising process and adopts corrected steps with a larger step size to eliminate cumulative quantization error.", "description": "This figure compares three denoising processes: (a) the original floating point process, (b) a quantized process without StepbaQ showing error accumulation, and (c) a quantized process with StepbaQ which corrects the sampling trajectory.  StepbaQ addresses quantization error by treating it as a 'stepback' and correcting the sampling trajectory with larger steps to mitigate accumulated error.", "section": "Method"}, {"figure_path": "cEtExbAKYV/figures/figures_6_1.jpg", "caption": "Figure 2: SNR curve of diffusion process. The quantization error decreases the SNR, which could be regarded as a stepback. To address this issue, StepbaQ takes a larger step to reach the scheduled SNR.", "description": "The figure shows the signal-to-noise ratio (SNR) curve for a diffusion process.  The blue curve represents the ideal SNR. The black dots and arrows indicate how quantization error reduces SNR and how StepbaQ compensates by taking a larger step to reach the intended SNR, addressing the \"stepback\" effect of quantization error.", "section": "5 Experiment"}, {"figure_path": "cEtExbAKYV/figures/figures_6_2.jpg", "caption": "Figure 3: Magnitude of stepback for SD v1.5 on the SD-prompts dataset under W8A8 setting. Most sampling step corrections occur at the last few steps of sampling, showing the importance of these steps. Since StepbaQ considers the error accumulation, it performs corrections more frequently than StepbaQ w/o ACC.", "description": "This figure shows a bar chart illustrating the magnitude of stepback (the difference between the corrected step and the original step) for each sampling step when using the StepbaQ method on the Stable Diffusion v1.5 model with the W8A8 quantization setting.  The chart compares StepbaQ's corrections to a version of the algorithm without error accumulation consideration. It highlights that most corrections happen in the later sampling steps, implying that accumulated quantization error significantly affects the final sample quality.  StepbaQ's approach, which accounts for error accumulation, makes corrections more frequently than the algorithm without this feature.", "section": "5 Experiment"}, {"figure_path": "cEtExbAKYV/figures/figures_13_1.jpg", "caption": "Figure 4: The distribution of quantization errors collected under W8A8 setting.", "description": "This figure displays the distribution of quantization errors observed for three different diffusion models (SDv1.4, SDv1.5, and SDXL-Turbo) under the W8A8 quantization setting. Each subfigure shows a histogram representing the frequency of different quantization error values for a given model. The distributions generally exhibit a bell shape, centered around zero, indicating that the mean quantization error is close to zero.  However, there are differences in the spread or variance of the distributions, suggesting that some models may be more sensitive to quantization than others.  This visual representation supports the paper's analysis of the quantization error and its assumption that this error follows a Gaussian distribution, though with potentially fatter tails than a purely Gaussian distribution.", "section": "A Analysis of Quantization Error"}, {"figure_path": "cEtExbAKYV/figures/figures_14_1.jpg", "caption": "Figure 5: The distribution of quantization error collected from W4A8 SDXL-Turbo on SDprompts dataset, outliers are clipped by Tukey\u2019s fence with k set as 1.7.", "description": "The figure shows the distribution of quantization errors obtained from the SDXL-Turbo model under the W4A8 setting using the SDprompts dataset.  To mitigate the impact of outliers, the data has been pre-processed using Tukey's fence with a k-value of 1.7, which helps remove extreme values and provide a clearer view of the distribution's central tendency and spread. This visualization helps confirm assumptions made in the paper about the distribution of quantization errors.", "section": "C Extending StepbaQ to SDXL-Turbo"}, {"figure_path": "cEtExbAKYV/figures/figures_16_1.jpg", "caption": "Figure 6: Qualitative results of SD v1.5 on SDprompts under W8A8 setting.", "description": "This figure displays a qualitative comparison of images generated by the Stable Diffusion v1.5 model under different quantization methods.  The first column shows images generated using the full-precision (FP) model, while subsequent columns illustrate results using Naive PTQ, PTQD, and StepbaQ. Each row presents a different image prompt or subject. The goal is to visually compare the quality of images generated under each method.  The figure aims to visually demonstrate that StepbaQ provides a better preservation of image quality when comparing to other quantization methods, especially with regards to visual artifacts.", "section": "D Qualitative Results"}, {"figure_path": "cEtExbAKYV/figures/figures_17_1.jpg", "caption": "Figure 7: Qualitative results of SDXL-Turbo on SDprompts under W4A8 setting.", "description": "This figure displays qualitative results of the SDXL-Turbo model on the SDprompts dataset under the W4A8 quantization setting.  It compares the image generation quality of the floating-point model (FP) against those generated by the Naive PTQ, PTQD, and StepbaQ methods.  Each row presents a different prompt, with four columns showing the results of each method.  The purpose is to visually demonstrate how StepbaQ improves the generation quality of quantized diffusion models compared to other methods, particularly highlighting the mitigation of visual artifacts resulting from quantization errors.", "section": "D Qualitative Results"}, {"figure_path": "cEtExbAKYV/figures/figures_18_1.jpg", "caption": "Figure 8: Qualitative results of SD v1.4 on SDprompts under W4A8 setting.", "description": "This figure displays the qualitative comparison of images generated by different methods on the SDprompts dataset under W4A8 setting. It compares the original floating-point model (FP) with results from Q-Diffusion, PTQD, TFMQ, and StepbaQ, showcasing the visual differences between different quantization methods and their impacts on image quality. StepbaQ shows the best visual quality, closely matching the floating-point model.", "section": "5 Experiment"}]