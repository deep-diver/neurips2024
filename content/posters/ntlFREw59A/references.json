{"references": [{"fullname_first_author": "Rombach, R.", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces Stable Diffusion, a foundational model for high-resolution image generation, which is directly built upon in the current work."}, {"fullname_first_author": "Kulal, S.", "paper_title": "Putting people in their place: Affordance-aware human insertion into scenes", "publication_date": "2023-06-01", "reason": "This paper provides the large-scale dataset used to train the proposed ActAnywhere model, representing a crucial element for successful model development."}, {"fullname_first_author": "Guo, Y.", "paper_title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning", "publication_date": "2023-07-01", "reason": "AnimateDiff serves as the architectural basis for the video diffusion model in this paper, offering essential temporal modeling components."}, {"fullname_first_author": "Radford, A.", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, provides a crucial component for conditioning the background generation on image features, directly impacting the model's performance."}, {"fullname_first_author": "Ho, J.", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the fundamental theory of diffusion models, which underpins the core methodology employed in ActAnywhere for video generation."}]}