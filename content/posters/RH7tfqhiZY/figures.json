[{"figure_path": "RH7tfqhiZY/figures/figures_1_1.jpg", "caption": "Figure 1: Creating unreal creatures. Our method generates imaginary creatures based on an artist's creative control. We show that these creatures cannot be generated faithfully only based on text. Each row depicts a 3D animal generated by HiFA, MVDream, and YOUDREAM (left to right) using the prompt mentioned below the row. We present 3D pose controls used to create these in the Sec. F (results best viewed zoomed in).", "description": "This figure showcases the results of three different text-to-3D generation methods (HiFA, MVDream, and the authors' YOUDREAM) on generating imaginary creatures.  The prompts used for generation are provided below each row of images.  The results demonstrate that YOUDREAM can generate more anatomically consistent and high-quality results, as compared to the existing baselines.  The 3D poses used as input for YOUDREAM are detailed in Section F.", "section": "1 Introduction"}, {"figure_path": "RH7tfqhiZY/figures/figures_1_2.jpg", "caption": "Figure 1: Creating unreal creatures. Our method generates imaginary creatures based on an artist's creative control. We show that these creatures cannot be generated faithfully only based on text. Each row depicts a 3D animal generated by HiFA, MVDream, and YOUDREAM (left to right) using the prompt mentioned below the row. We present 3D pose controls used to create these in the Sec. F (results best viewed zoomed in).", "description": "This figure compares the 3D animal generation results of three different methods: HiFA, MVDream, and the authors' proposed method, YOUDREAM.  For each of several prompts describing fantastical creatures (e.g., a llama with octopus tentacles), the figure shows the 3D models generated by each method.  The results highlight YOUDREAM's ability to generate higher-quality, more anatomically consistent models, especially when compared to methods relying solely on text-based input. The 3D pose controls used by YOUDREAM are referenced, indicating the method's ability to achieve fine-grained control over the generated animal's anatomy.", "section": "1 Introduction"}, {"figure_path": "RH7tfqhiZY/figures/figures_1_3.jpg", "caption": "Figure 1: Creating unreal creatures. Our method generates imaginary creatures based on an artist's creative control. We show that these creatures cannot be generated faithfully only based on text. Each row depicts a 3D animal generated by HiFA, MVDream, and YOUDREAM (left to right) using the prompt mentioned below the row. We present 3D pose controls used to create these in the Sec. F (results best viewed zoomed in).", "description": "This figure showcases the results of three different text-to-3D animal generation methods: HiFA, MVDream, and the authors' proposed method, YOUDREAM.  Each row shows the same prompt given to all three methods, demonstrating that YOUDREAM, guided by both text and 3D pose, produces more realistic and creative results than the other methods which rely solely on text input.  The differences highlight YOUDREAM's ability to generate even unreal animals with complex anatomies.", "section": "1 Introduction"}, {"figure_path": "RH7tfqhiZY/figures/figures_4_1.jpg", "caption": "Figure 2: Automatic pipeline for 3D animal generation. Given the name of an animal and textual pose description, we utilize a multi-agent LLM to generate a 3D pose ($) supported by a small library of animal names paired with 3D poses. With the obtained 3D pose, we train a NeRF to generate the 3D animal guided by a diffusion model controlled by 2D views (\u00f8proj) of \u0444.", "description": "This figure illustrates the automatic pipeline for generating 3D animals using YOUDREAM. It starts with a user providing the name and pose description of the desired animal. A multi-agent large language model (LLM) then generates a 3D pose based on a library of existing animal poses. This 3D pose is used to generate 2D views via viewpoint sampling. These views are then fed into a ControlNet-guided diffusion model, which produces the final 3D animal model using NeRF rendering.  The pipeline is fully automated, requiring minimal human intervention.", "section": "3 Method"}, {"figure_path": "RH7tfqhiZY/figures/figures_5_1.jpg", "caption": "Figure 3: Qualitative examples of pose editing using multi-agent LLM setup. For each example, the green box denotes the desired animal, while the blue box is the animal retrieved from the 3D pose library by Finder LLM (\u03c0F). We show the pose modification performed by the joint effort of Observer (\u03c0\u03bf) and Modifier (\u03c0\u039c) for three instances.", "description": "This figure shows examples of how the multi-agent LLM system modifies 3D poses of animals.  The system consists of three agents: Finder, Observer, and Modifier. The Finder selects an initial pose from a library based on the requested animal. The Observer analyzes the differences between the initial pose and the desired pose (described in text), suggesting necessary adjustments.  Finally, the Modifier applies those adjustments to the initial pose to generate a modified pose representing the desired animal in the specified pose. The figure visually demonstrates this process for three different animals: crocodile, spoonbill, and giraffe. Each example shows the desired animal, the initial pose selected by the Finder, and the final modified pose generated by the system.", "section": "3.2 3D Pose Generation aided by Multi-agent LLM"}, {"figure_path": "RH7tfqhiZY/figures/figures_6_1.jpg", "caption": "Figure 4: Comparison on generating animals observed in nature. We compare with baselines which use T2I diffusion (with official open-source code) for the automatic generation of text-to-3D animals. Unlike the baselines, our method produces high-quality anatomically consistent animals.", "description": "This figure compares the performance of YOUDREAM against three baseline methods (HIFA, Fantasia3D, and 3DFuse) on generating common animals from text descriptions.  The results show that YOUDREAM outperforms the baselines in terms of generating high-quality, anatomically consistent 3D animal models. While the baselines show inconsistencies in anatomy and geometry, YOUDREAM generates more realistic and accurate results.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_7_1.jpg", "caption": "Figure 1: Creating unreal creatures. Our method generates imaginary creatures based on an artist's creative control. We show that these creatures cannot be generated faithfully only based on text. Each row depicts a 3D animal generated by HiFA, MVDream, and YOUDREAM (left to right) using the prompt mentioned below the row. We present 3D pose controls used to create these in the Sec. F (results best viewed zoomed in).", "description": "This figure compares the 3D animal generation results of three different methods: HiFA, MVDream, and the authors' proposed method, YOUDREAM.  Each row shows the results for a different animal prompt, demonstrating the ability of YOUDREAM to generate more realistic and imaginative creatures compared to the other two methods. The figure highlights the importance of using 3D pose control for generating high-quality, anatomically consistent animals.", "section": "1 Introduction"}, {"figure_path": "RH7tfqhiZY/figures/figures_8_1.jpg", "caption": "Figure 6: Ablation over the effect of initial shape and pose control. The initial shape helps in producing clean geometry, while the pose control helps to maintain 3D consistency.", "description": "This figure shows an ablation study on the effects of using an initial shape and pose control in the YOUDREAM model.  It demonstrates the impact of each component on the quality of the generated 3D animal models. The results indicate that both initial shape and pose control are beneficial, with pose control being particularly important for maintaining 3D consistency across multiple views.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_8_2.jpg", "caption": "Figure 7: Ablation over scheduling techniques. Using either guidance or control scaling produces unnatural color, using neither produces artifacts such as grass at feet owing to lower diversity of ControlNet compared to Stable Diffusion.", "description": "This ablation study demonstrates the impact of different scheduling techniques on the quality of generated images.  The results indicate that using only guidance scaling or only control scaling leads to unnatural color artifacts in the generated images. The use of neither scaling technique results in artifacts, such as grass appearing at the feet of the elephant, likely due to the lower diversity of the ControlNet compared to the Stable Diffusion model used.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_13_1.jpg", "caption": "Figure 8: Results on compositional and style prompts. We show our method performs well while generating animals with style alterations or object interactions.", "description": "This figure demonstrates the versatility of the YOUDREAM model by showcasing its ability to generate images of animals with various styles and compositional elements.  The top row shows the input prompts. The subsequent rows illustrate variations in the generated images based on different styles and compositions, all while maintaining a good level of detail and realism. This highlights the model's ability to incorporate diverse artistic directions, not solely relying on a single, literal interpretation of the text prompt.", "section": "A More Results"}, {"figure_path": "RH7tfqhiZY/figures/figures_13_2.jpg", "caption": "Figure 9: Pose generation using single LLM vs our multi-agent LLM setup. For \"Hippo\", \"Greater Flamingo\", and \"Horse\", we show a 2D view of the 3D pose generated by a single LLM compared to our multi-agent setup.", "description": "This figure compares the performance of a single Large Language Model (LLM) against a multi-agent LLM system for generating 3D animal poses.  The comparison is shown for three different animals: a hippopotamus, a greater flamingo, and a horse. For each animal, the figure displays the 2D projection of the 3D pose generated by both methods. The visual difference highlights the improved pose generation quality achieved through the multi-agent approach.", "section": "Method"}, {"figure_path": "RH7tfqhiZY/figures/figures_14_1.jpg", "caption": "Figure 10: Comparison with OpenPose ControlNet for generating animals. OpenPose ControlNet produces the animal in the prompt for \u201cHorse\u201d and \u201cBaboon\u201d, but either does not follow control or makes unnatural anatomy. For \u201cGazelle\u201d a meaningless image is produced.", "description": "This figure compares the performance of YOUDREAM's TetraPose ControlNet against OpenPose ControlNet for generating images of animals.  It shows that, unlike YOUDREAM, the OpenPose ControlNet either fails to follow the provided pose control or generates images with unnatural anatomical features.  The example images provided are of a gazelle, a horse, and a baboon.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_14_2.jpg", "caption": "Figure 1: Creating unreal creatures. Our method generates imaginary creatures based on an artist's creative control. We show that these creatures cannot be generated faithfully only based on text. Each row depicts a 3D animal generated by HiFA, MVDream, and YOUDREAM (left to right) using the prompt mentioned below the row. We present 3D pose controls used to create these in the Sec. F (results best viewed zoomed in).", "description": "This figure compares the results of three different text-to-3D animal generation methods: HiFA, MVDream, and the authors' proposed method, YOUDREAM.  Each row shows the generated 3D models for a different animal based on a textual description provided as a prompt.  The purpose is to demonstrate that YOUDREAM, which incorporates 3D pose controls, can generate more imaginative and anatomically consistent results, especially compared to methods that rely solely on text prompts.", "section": "1 Introduction"}, {"figure_path": "RH7tfqhiZY/figures/figures_15_1.jpg", "caption": "Figure 12: Variation with seed. Our method is robust across seeds and generates slightly different faces and stripes for various seeds.", "description": "This figure demonstrates the robustness of the YOUDREAM model to different random seeds.  Four different images of a tiger are shown, each generated using a different random seed. While the overall pose and general characteristics of the tiger remain consistent, minor variations appear in details like the exact pattern and coloring of its stripes, and the expression on its face. This illustrates that YOUDREAM produces similar but not identical results when provided with different random seeds, thereby showcasing its stability while preserving creative diversity.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_15_2.jpg", "caption": "Figure 13: Comparison of various scheduling techniques. Using cosine strategy for both produces oversaturation, while using cosine strategy for guidance scheduling and linear for control scheduling produces oversmooth textures at the legs. Results of using both linear scheduling is closest to our strategy, but is lesser textured (notice feet and ears).", "description": "This figure compares different scheduling strategies for guidance and control in the training process of the proposed model.  The results suggest that using a cosine schedule for both guidance and control leads to oversaturation, while a cosine schedule for guidance and a linear schedule for control results in over-smoothed textures. The best results are obtained using a linear schedule for both.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_16_1.jpg", "caption": "Figure 14: Effect of using LRGB. Not using LRGB results is hollow geometry and flickering. The chin of the tiger appears and disappears based on view, a view where the chin has disappeared has been chosen.", "description": "This figure demonstrates the impact of using the LRGB loss function in the YOUDREAM model. The left panels show results without LRGB, exhibiting hollow geometry and flickering artifacts, especially noticeable in the elephant's trunk and tiger's chin.  The right panels present results with LRGB, showing improved geometry and reduced flickering.  The highlighted regions show the areas where the artifacts are most apparent.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_16_2.jpg", "caption": "Figure 15: More Comparison with MVDream. We compare our method with MVDream for simple prompts. MVDream results are clearly missing the texture of the scaly body of the pangolin, while their giraffe has a toy-like geometry and hence unnatural. In contrast YOUDREAM produces very realistic results.", "description": "The figure compares the results of the proposed method, YOUDREAM, and the baseline method, MVDream, in generating images of a pangolin and a giraffe.  The comparison highlights YOUDREAM's superior ability to generate more realistic and texturally accurate animal models compared to MVDream.", "section": "Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_17_1.jpg", "caption": "Figure 16: Comparison with 3DFauna. Our method produces more detailed geometry compared to the baseline.", "description": "This figure compares the 3D animal generation results of the proposed YOUDREAM method and the baseline method 3DFauna.  The top row shows an input image of an elephant and a tiger for the 3DFauna method, and the corresponding generated 3D models. The bottom row shows the input pose (a skeleton) for the YOUDREAM method, and the generated 3D models for the elephant and tiger.  The comparison highlights that YOUDREAM produces 3D models with significantly more detailed geometry compared to 3DFauna.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_17_2.jpg", "caption": "Figure 17: Comparison with additional prior art methods. Even though LucidDreamer performs better than Stable Dreamfusion and ProlificDreamer, it shows the same failures as discussed in the main paper.", "description": "This figure compares YOUDREAM against several other text-to-3D generation methods (Stable Dreamfusion, ProlificDreamer, and LucidDreamer). It demonstrates that YOUDREAM produces superior results in terms of image quality and adherence to the text prompt. The comparison is performed by showing the front and side views of two different animals generated using each method. The two animals are an elephant and a llama with octopus tentacles.", "section": "4 Experiments"}, {"figure_path": "RH7tfqhiZY/figures/figures_18_1.jpg", "caption": "Figure 18: Generating more OOD assets through automatic pipeline. Using our multi-agent LLM setup we first generate the 3D poses of \u201cclownfish\u201d and \u201cfour-legged tarantula\u201d. We then use the produced 3D poses to guide our 3D generation. We observe that the multi-agent LLM pose editor chooses \u201cRoseate Spoonbill\u201d as the base 3D pose to be modified into \u201cClownfish\u201d, and \u201cGerman Shepherd\u201d is chosen for modifying to \u201cfour-legged tarantula\u201d.", "description": "This figure shows the results of generating out-of-distribution (OOD) assets using the proposed automatic pipeline.  The pipeline uses a multi-agent large language model (LLM) to generate 3D poses for animals not included in the initial training data.  The figure demonstrates how the LLM selects an existing animal pose as a starting point and modifies it to create the desired OOD animal. Specifically, it shows that a roseate spoonbill pose is used as a basis for generating the clownfish pose, and a German shepherd pose is used to generate the four-legged tarantula pose.  The resulting 3D models are then generated using these modified poses.", "section": "3 Method"}, {"figure_path": "RH7tfqhiZY/figures/figures_18_2.jpg", "caption": "Figure 19: Increasing NeRF dimensions. On increasing each NeRF dimension by 2x we generate a sharper and cleaner 3D asset for the prompt \"a tiger\" without any change in hyperparameters.", "description": "This figure demonstrates the impact of increasing the resolution of the Neural Radiance Field (NeRF) used in the 3D animal generation process. By doubling the dimensions of the NeRF (from 128x128x128 to 256x256x256), a significant improvement in the sharpness and detail of the generated 3D tiger model is observed. This suggests that higher-resolution NeRFs can lead to more realistic and visually appealing 3D animal models, even without adjusting other hyperparameters.", "section": "E Scaling to higher dimension NeRF"}, {"figure_path": "RH7tfqhiZY/figures/figures_19_1.jpg", "caption": "Figure 1: Creating unreal creatures. Our method generates imaginary creatures based on an artist's creative control. We show that these creatures cannot be generated faithfully only based on text. Each row depicts a 3D animal generated by HiFA, MVDream, and YOUDREAM (left to right) using the prompt mentioned below the row. We present 3D pose controls used to create these in the Sec. F (results best viewed zoomed in).", "description": "This figure compares the results of generating imaginary creatures using three different methods: HiFA, MVDream, and the authors' proposed method, YOUDREAM.  The input for each method is a text prompt describing an unusual creature (e.g., a llama with an octopus body).  The figure shows that YOUDREAM is superior in generating high-quality, anatomically consistent results that are more closely aligned with the user's creative intent compared to the other methods. The 3D pose controls utilized by YOUDREAM for the creation of these images are further explained in section F of the paper. ", "section": "1 Introduction"}, {"figure_path": "RH7tfqhiZY/figures/figures_21_1.jpg", "caption": "Figure 1: Creating unreal creatures. Our method generates imaginary creatures based on an artist's creative control. We show that these creatures cannot be generated faithfully only based on text. Each row depicts a 3D animal generated by HiFA, MVDream, and YOUDREAM (left to right) using the prompt mentioned below the row. We present 3D pose controls used to create these in the Sec. F (results best viewed zoomed in).", "description": "This figure demonstrates the ability of the YOUDREAM model to generate imaginary creatures based on artistic text prompts and 3D pose controls.  It compares the results of YOUDREAM to those of two other methods, HiFA and MVDream, highlighting YOUDREAM's superior ability to generate anatomically consistent and visually compelling results, especially for unreal creatures that are difficult to describe solely through text. The 3D pose controls, detailed in section F of the paper, provide a crucial element of artistic control for YOUDREAM.", "section": "1 Introduction"}, {"figure_path": "RH7tfqhiZY/figures/figures_22_1.jpg", "caption": "Figure 3: Qualitative examples of pose editing using multi-agent LLM setup. For each example, the green box denotes the desired animal, while the blue box is the animal retrieved from the 3D pose library by Finder LLM (\u03c0F). We show the pose modification performed by the joint effort of Observer (\u03c0\u03bf) and Modifier (\u03c0\u039c) for three instances.", "description": "This figure shows examples of how the multi-agent large language model (LLM) system modifies 3D poses of animals.  The system consists of three agents: a Finder, an Observer, and a Modifier. The Finder selects a base animal pose from a library that's similar to the target animal. The Observer then analyzes the differences between the base pose and the desired animal and pose, generating instructions for the Modifier. Finally, the Modifier adjusts the base pose to match the target animal and pose. The figure showcases this process for several animals, illustrating the system's ability to generate realistic and diverse poses.", "section": "3 Method"}, {"figure_path": "RH7tfqhiZY/figures/figures_23_1.jpg", "caption": "Figure 12: Variation with seed. Our method is robust across seeds and generates slightly different faces and stripes for various seeds.", "description": "This figure demonstrates the robustness of the YOUDREAM model to different random seeds.  Four different images of a tiger are shown, each generated with a different random seed. While the overall pose and structure of the tiger remain consistent, subtle variations in the details, such as the stripes and facial features, are observed. This highlights the ability of YOUDREAM to consistently generate high-quality results even when dealing with stochastic components of the model.", "section": "4 Experiments"}]