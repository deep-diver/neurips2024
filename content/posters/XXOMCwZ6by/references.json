{"references": [{"fullname_first_author": "Bowen Baker", "paper_title": "Video pretraining (VPT): Learning to act by watching unlabeled online videos", "publication_date": "2022-12-01", "reason": "This paper introduces VPT, a foundational model for training embodied agents by learning from unlabeled online videos, which is directly relevant to the Optimus-1 agent's training methodology."}, {"fullname_first_author": "Linxi Fan", "paper_title": "Minedojo: Building open-ended embodied agents with internet-scale knowledge", "publication_date": "2022-12-01", "reason": "This paper introduces MineDojo, a large-scale dataset of Minecraft demonstrations used for training embodied agents, which is the primary environment used in evaluating the Optimus-1 agent."}, {"fullname_first_author": "William H Guss", "paper_title": "Minerl: A large-scale dataset of minecraft demonstrations", "publication_date": "2019-07-01", "reason": "This paper introduces MineRL, a large-scale dataset of Minecraft demonstrations, providing a benchmark for training and evaluating the capabilities of Minecraft agents, crucial for the performance analysis of Optimus-1."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces a method for learning transferable visual models from natural language supervision, which is fundamental to the multimodal capabilities of Optimus-1."}, {"fullname_first_author": "Zihao Wang", "paper_title": "Jarvis-1: Open-world multi-task agents with memory-augmented multimodal language models", "publication_date": "2023-11-01", "reason": "This paper introduces Jarvis-1, an agent with a memory-augmented multimodal language model architecture, which is directly compared to and improved upon by the proposed Optimus-1 agent."}]}