[{"figure_path": "ziYC4FHRNr/figures/figures_3_1.jpg", "caption": "Figure 1: The maximum entrywise error against rank for low-rank approximations of kernel matrices constructed from a collection of datasets. The kernel matrices are constructed using Mat\u00e9rn kernels with a range of smoothness parameters, each of which is represented by a line in each plot. Details of the experiment are provided in Section 5.", "description": "The figure shows the maximum entrywise error for low-rank approximations of kernel matrices for six datasets (GMM, Abalone, Wine Quality, MNIST, 20 Newsgroups, Zebrafish).  Each dataset uses Mat\u00e9rn kernels with varying smoothness parameters (v = 1/2, 3/2, 5/2, \u221e).  The x-axis represents the rank of the approximation, and the y-axis represents the maximum entrywise error. The plots illustrate how the maximum entrywise error decreases as the rank increases, with smoother kernels exhibiting faster decay rates.  The high-dimensional datasets (20 Newsgroups and Zebrafish) show slower decay compared to the low-dimensional datasets.", "section": "5 Experiments"}, {"figure_path": "ziYC4FHRNr/figures/figures_7_1.jpg", "caption": "Figure 1: The maximum entrywise error against rank for low-rank approximations of kernel matrices constructed from a collection of datasets. The kernel matrices are constructed using Mat\u00e9rn kernels with a range of smoothness parameters, each of which is represented by a line in each plot. Details of the experiment are provided in Section 5.", "description": "This figure shows the maximum entrywise error for low-rank approximations of kernel matrices for six datasets. Each dataset is represented in a separate subplot, and the different lines in each plot represent the use of different Mat\u00e9rn kernels with varying smoothness parameters (v = 1/2, 3/2, 5/2, \u221e). The x-axis shows the rank of the approximation, and the y-axis shows the maximum entrywise error.  The figure demonstrates how the maximum entrywise error decreases as the rank increases, and how this decay varies depending on the kernel smoothness and the dataset.  Section 5 of the paper provides additional details about the experiments.", "section": "5 Experiments"}, {"figure_path": "ziYC4FHRNr/figures/figures_24_1.jpg", "caption": "Figure 2: The Frobenius-norm error against rank for low-rank approximations of kernel matrices constructed from a collection of datasets. The kernel matrices are constructed using Mat\u00e9rn kernels with a range of smoothness parameters, each of which is represented by a line in each plot. Details of the experiment are provided in Section 5.", "description": "This figure compares the Frobenius norm error for different low-rank approximations of kernel matrices constructed from various datasets (GMM, Abalone, Wine Quality, MNIST, 20 Newsgroups, Zebrafish). Each dataset uses a Mat\u00e9rn kernel with varying smoothness parameters (v = 1/2, 3/2, 5/2, \u221e). The x-axis represents the rank of the approximation, and the y-axis represents the Frobenius norm error. The plot shows how the error decreases as the rank increases, with the smoother kernels (larger v) showing faster convergence.", "section": "5.2 Interpretation of the results"}]