[{"figure_path": "OrtN9hPP7V/figures/figures_3_1.jpg", "caption": "Figure 1: Generator G loss for different objectives over training. Regardless of which objective is used, training diverges with only R\u2081 and succeeded with both R\u2081 and R2. Convergence failure with only R\u2081 was noted by Lee et al. [42].", "description": "This figure shows the generator loss curves during training for four different GAN loss functions on the StackedMNIST dataset.  The four loss functions are combinations of the RpGAN (relativistic pairing GAN) loss and the R1 and R2 gradient penalties. The graph demonstrates that using only R1 leads to training instability and divergence in all cases, while the addition of R2 provides stability and convergence for both RpGAN and standard GAN losses. This highlights the importance of R2 as a regularizer for stable GAN training.", "section": "2.3 Training Dynamics of RpGAN"}, {"figure_path": "OrtN9hPP7V/figures/figures_3_2.jpg", "caption": "Figure 1: Generator G loss for different objectives over training. Regardless of which objective is used, training diverges with only R\u2081 and succeeded with both R\u2081 and R2. Convergence failure with only R\u2081 was noted by Lee et al. [42].", "description": "This figure shows the training curves for the generator (G) loss using different loss functions on the StackedMNIST dataset. The x-axis represents the wall time, and the y-axis shows the generator's loss.  The plot compares four different loss functions: RpGAN + R1 + R2, GAN + R1 + R2, RpGAN + R1, and GAN + R1. It demonstrates that using both R1 and R2 regularization is crucial for preventing divergence and ensuring convergence during training, unlike using only R1, which leads to training failure.  The results highlight the importance of the proposed regularized relativistic GAN loss for stable training.", "section": "2.3 Training Dynamics of RpGAN"}, {"figure_path": "OrtN9hPP7V/figures/figures_5_1.jpg", "caption": "Architecture comparison. For image generation, G and D are often both deep ConvNets with either partially or fully symmetric architectures. (a) StyleGAN2 [31] G uses a network to map noise vector z to an intermediate style space W. We use a traditional generator as style mapping is not necessary for a minimal working model. (b) StyleGAN2's building blocks have intricate layers but are themselves simple, with a ConvNet architecture from 2015 [38, 73, 16]. ResNet's identity mapping principle is also violated in the discriminator. (c) We remove tricks and modernize the architecture. Our design have clean layers with a more powerful ConvNet architecture. Figure 2", "description": "This figure compares the architectures of StyleGAN2 and the proposed R3GAN model.  It highlights key differences, showing how R3GAN simplifies the StyleGAN2 architecture by removing unnecessary components while adopting modern convolutional network designs for improved performance and stability.  The figure visually depicts the building blocks of each architecture and emphasizes the streamlined design of R3GAN.", "section": "A Roadmap to a New Baseline R3GAN"}, {"figure_path": "OrtN9hPP7V/figures/figures_7_1.jpg", "caption": "Figure 3: Millions of parameters vs. FID-50K (log scale) on CIFAR-10. Lower is better.", "description": "This figure compares the performance of various GAN and diffusion models on the CIFAR-10 dataset in terms of FID score and the number of parameters (in millions).  It shows that the proposed model (Ours-Config E) achieves a lower FID score with a significantly smaller number of parameters compared to other state-of-the-art models, demonstrating its efficiency and effectiveness.", "section": "4.5 FID - CIFAR-10 [37]"}, {"figure_path": "OrtN9hPP7V/figures/figures_9_1.jpg", "caption": "Figure 4: Qualitative examples of sample generation from our Config E on FFHQ-256.", "description": "This figure shows several qualitative examples of images generated by the R3GAN model (Config E) on the FFHQ-256 dataset.  The images are arranged in a grid to showcase the model's ability to generate diverse and realistic-looking faces. The high quality of the generated faces demonstrates the effectiveness of the proposed model and its ability to overcome issues often associated with GAN training, such as mode collapse and lack of diversity.", "section": "Qualitative Results"}, {"figure_path": "OrtN9hPP7V/figures/figures_25_1.jpg", "caption": "Figure 5: Qualitative examples of sample generation from our Config E on Stacked-MNIST.", "description": "This figure shows samples generated by the R3GAN model (Config E) on the Stacked-MNIST dataset.  Stacked-MNIST is a challenging dataset consisting of 1000 uniformly distributed modes, making it a good test of a GAN's ability to avoid mode collapse and generate diverse samples. The samples shown in the figure illustrate the variety of digits generated by the R3GAN model, demonstrating its capability to capture the different styles and variations present in the dataset. The color scheme used in the samples likely highlights aspects of the generated images, potentially indicating different features or aspects of the underlying digit representation learned by the GAN.", "section": "F Qualitative Results"}, {"figure_path": "OrtN9hPP7V/figures/figures_26_1.jpg", "caption": "Figure 4: Qualitative examples of sample generation from our Config E on FFHQ-256.", "description": "This figure shows a grid of 64 images generated by the R3GAN model (Config E) trained on the FFHQ-256 dataset.  The images are high-quality and diverse, demonstrating the model's ability to generate realistic and varied facial images. The caption is quite short, so this description provides more detail. This figure supports the paper's claim of achieving state-of-the-art image generation quality using a simple and modern GAN architecture.", "section": "Qualitative Results"}, {"figure_path": "OrtN9hPP7V/figures/figures_27_1.jpg", "caption": "Figure 4: Qualitative examples of sample generation from our Config E on FFHQ-256.", "description": "This figure shows several qualitative examples of images generated by the R3GAN model (Config E) on the FFHQ-256 dataset.  The images are arranged in a grid to showcase the diversity and quality of the generated faces.  The quality and diversity of the generated images demonstrate the effectiveness of the proposed method in generating high-quality and realistic images.", "section": "4 Experiments Details"}, {"figure_path": "OrtN9hPP7V/figures/figures_28_1.jpg", "caption": "Figure 9: Qualitative examples of sample generation from our Config E on ImageNet-32.", "description": "This figure shows a qualitative evaluation of the ImageNet-32 dataset generated samples using the R3GAN model's Config E.  It provides a visual representation of the model's ability to generate diverse and realistic images from the ImageNet-32 dataset.  The image is a grid of many small images, each representing a different sample generated by the model. The quality and diversity of these samples are indicative of the overall performance of the R3GAN model.", "section": "F Qualitative Results"}, {"figure_path": "OrtN9hPP7V/figures/figures_29_1.jpg", "caption": "Figure 9: Qualitative examples of sample generation from our Config E on ImageNet-32.", "description": "This figure shows a grid of 256 images generated by the R3GAN model (Config E) on the ImageNet-32 dataset.  Each image is 32x32 pixels and represents a sample from the model's learned distribution.  The variety and quality of the generated images illustrate the model's ability to produce realistic and diverse samples of various animals and objects from the ImageNet dataset. The image quality is high, demonstrating the effectiveness of the proposed R3GAN architecture and training approach.", "section": "F Qualitative Results"}, {"figure_path": "OrtN9hPP7V/figures/figures_30_1.jpg", "caption": "Figure 9: Qualitative examples of sample generation from our Config E on ImageNet-32.", "description": "This figure shows a grid of 256 images generated by the R3GAN model (Config E) on the ImageNet-32 dataset.  Each image is 32x32 pixels and represents a sample from the model's learned distribution of images. The diversity and quality of the generated images provide a visual assessment of the model's performance.  The caption is short, so this description expands on the figure's purpose and content.", "section": "F Qualitative Results"}, {"figure_path": "OrtN9hPP7V/figures/figures_31_1.jpg", "caption": "Figure 1: Generator G loss for different objectives over training. Regardless of which objective is used, training diverges with only R\u2081 and succeeded with both R\u2081 and R2. Convergence failure with only R\u2081 was noted by Lee et al. [42].", "description": "The figure shows the generator loss curves for different GAN training objectives on the StackedMNIST dataset.  The objectives compared include the standard GAN loss, the RpGAN loss, and variations with and without R1 and R2 gradient penalties.  The key observation is that only the combination of RpGAN and both R1 and R2 penalties produces stable training that avoids divergence and mode dropping.  The result highlights the importance of the proposed regularized relativistic GAN loss for stability and achieving full mode coverage.", "section": "2.3 Training Dynamics of RpGAN"}, {"figure_path": "OrtN9hPP7V/figures/figures_31_2.jpg", "caption": "Figure 1: Generator G loss for different objectives over training. Regardless of which objective is used, training diverges with only R\u2081 and succeeded with both R\u2081 and R2. Convergence failure with only R\u2081 was noted by Lee et al. [42].", "description": "The figure shows the training curves of the generator's loss for different GAN objectives on the StackedMNIST dataset.  The plot demonstrates that using only the R1 regularization results in training divergence for both the standard GAN loss and the RpGAN loss. However, when both R1 and R2 regularizations are used, stable training and convergence are achieved for both losses. This highlights the importance of using both regularizations for training stability in GANs.", "section": "2.3 Training Dynamics of RpGAN"}, {"figure_path": "OrtN9hPP7V/figures/figures_31_3.jpg", "caption": "Figure 1: Generator G loss for different objectives over training. Regardless of which objective is used, training diverges with only R\u2081 and succeeded with both R\u2081 and R2. Convergence failure with only R\u2081 was noted by Lee et al. [42].", "description": "This figure shows the training curves for the generator (G) loss using different loss functions on the StackedMNIST dataset.  The x-axis represents the training time (wall time), and the y-axis represents the generator loss.  The plot demonstrates that using RpGAN + R1 regularization (orange line) leads to stable training with relatively low loss. Conversely, GAN + R1 (blue line) results in unstable training, with the loss diverging after a certain number of training steps. This highlights the importance of including both R1 and R2 regularizations for stable GAN training.", "section": "2.3 Training Dynamics of RpGAN"}, {"figure_path": "OrtN9hPP7V/figures/figures_31_4.jpg", "caption": "Figure 1: Generator G loss for different objectives over training. Regardless of which objective is used, training diverges with only R\u2081 and succeeded with both R\u2081 and R2. Convergence failure with only R\u2081 was noted by Lee et al. [42].", "description": "This figure shows the training curves for the generator (G) loss using different objective functions in a GAN setting.  It demonstrates the impact of regularization terms (R1 and R2) on training stability.  Using only R1 leads to divergence (the loss explodes), whereas the combination of R1 and R2 ensures stable training and convergence.  The results support the claim that RpGAN with both R1 and R2 regularization is necessary for stable GAN training.", "section": "2.3 Training Dynamics of RpGAN"}, {"figure_path": "OrtN9hPP7V/figures/figures_31_5.jpg", "caption": "Figure 1: Generator G loss for different objectives over training. Regardless of which objective is used, training diverges with only R\u2081 and succeeded with both R\u2081 and R2. Convergence failure with only R\u2081 was noted by Lee et al. [42].", "description": "This figure shows the training curves of the generator (G) loss for different GAN objective functions on the StackedMNIST dataset.  The x-axis represents training time, and the y-axis represents the generator loss.  The different lines represent different objective functions: RpGAN (relativistic pairing GAN) with and without R1 and R2 regularization, as well as the standard GAN loss with and without R1 and R2 regularization. The plot demonstrates that using only R1 regularization leads to training divergence for both RpGAN and the standard GAN loss, while the inclusion of both R1 and R2 regularization ensures stable convergence for both.", "section": "2.3 Training Dynamics of RpGAN"}]