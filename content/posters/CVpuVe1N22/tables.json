[{"figure_path": "CVpuVe1N22/tables/tables_7_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs.  The table compares the performance of different methods, including Direct Prompting and Uncertainty of Thoughts (UoT), in terms of Success Rate (SR), the average length of successful conversations (MSC), and the average length of all conversations (MCL). Higher SR indicates better performance. Lower MSC and MCL values indicate higher efficiency. The results are shown separately for both Open Set and Closed Set settings.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_9_1.jpg", "caption": "Table 2: Average success rates for 20Q, MD, and TB at comparable efficiency, measured by GPT-4 token use. k is sampling count, D is tree depth.", "description": "This table presents a comparison of the success rates achieved by different methods (CoT-SC, Orig-ToT, Adapt-ToT, Pruned UoT, and UoT) on three tasks: 20 Questions (20Q), Medical Diagnosis (MD), and Troubleshooting (TB).  The key aspect of the comparison is that it's done at \"comparable efficiency,\" meaning the methods were run with a similar number of GPT-4 tokens used.  The table shows that the UoT method, even in a pruned version, generally outperforms the other methods across all three tasks, particularly when the computational cost is considered.  The parameters k (sampling count) and D (tree depth) help explain the differences in computation for the different methods.", "section": "3.3 Comparing Model Performance at Equal Computational Efficiency"}, {"figure_path": "CVpuVe1N22/tables/tables_14_1.jpg", "caption": "Table 3: Performance(Successful Rate) comparison of different reward methods based on GPT-3.5", "description": "This table compares the performance (measured by successful rate) of different reward calculation methods: Vanilla Expected Information Gain (IG), Logarithmic Transformation Scaling (LTS), Sigmoid Transformation Scaling (STS), Piecewise Function Scaling (PFS), and Uncertainty-based Reward (UR). The comparison is performed using GPT-3.5 across five datasets: 20Q-BIG-bench, Common, DX, MedDG, and FloDial.  The results show the successful rates for each method on each dataset, illustrating the impact of different reward scaling techniques on the model's performance.", "section": "3.3.2 Effectiveness of Uncertainty Rewards"}, {"figure_path": "CVpuVe1N22/tables/tables_15_1.jpg", "caption": "Table 2: Average success rates for 20Q, MD, and TB at comparable efficiency, measured by GPT-4 token use. k is sampling count, D is tree depth.", "description": "This table compares the average success rates of different methods (CoT-SC, Original-ToT, Adapted-ToT, Pruned UoT, and UoT) across three tasks (20 Questions, Medical Diagnosis, and Troubleshooting) while controlling for computational efficiency.  The efficiency is measured by the number of GPT-4 tokens used.  The table shows that UoT consistently outperforms other methods even when the computational cost is kept similar, demonstrating its superior efficiency and effectiveness.", "section": "3.3.1 Comparing Model Performance at Equal Computational Efficiency"}, {"figure_path": "CVpuVe1N22/tables/tables_15_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods (Direct Prompting, UoT, etc.).  It compares the success rate (SR), mean conversation length in successful cases (MSC), and mean conversation length (MCL) across these different scenarios and models.  The metrics provide insights into both the effectiveness and efficiency of information-seeking strategies for LLMs in various scenarios.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_16_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods.  The metrics evaluated are Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).  The table helps to compare the performance of different models and methods across the three tasks, showing success rates, efficiency, and effectiveness.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_17_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using several LLMs.  It compares the performance of the proposed Uncertainty of Thoughts (UoT) method against several baselines (Direct Prompting, Planning Prompting, Chain of Thought, etc.).  The table shows the Success Rate (percentage of successful task completions), Mean Conversation Length in Successful Cases (average number of turns in successful conversations), and Mean Conversation Length (average number of turns across all conversations, regardless of success). Lower MCL values indicate greater efficiency.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_17_2.jpg", "caption": "Table 8: Llama 3 Comparison of DP and UoT on Success Rates (SR)", "description": "This table presents the results of a t-test comparing the success rates of Direct Prompting (DP) and Uncertainty of Thoughts (UoT) methods using the Llama 3 LLM across five different datasets.  The p-values indicate the statistical significance of the difference in success rates between the two methods for each dataset.  All p-values are below 0.05, indicating statistically significant differences in favor of UoT across all datasets.", "section": "3.3 Analysis"}, {"figure_path": "CVpuVe1N22/tables/tables_20_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) across multiple LLMs.  It compares the performance of the proposed Uncertainty of Thoughts (UoT) method against several baselines. The metrics used for evaluation are Success Rate (SR), which indicates the percentage of successful task completions; Mean Conversation Length in Successful Cases (MSC), representing the average number of turns needed for successful tasks; and Mean Conversation Length (MCL), showing the average number of turns for all tasks, regardless of success or failure. The table allows for a comparison of UoT's effectiveness in different scenarios and its overall improvement over the baselines.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_20_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods.  It compares the Success Rate (SR), the average conversation length in successful cases (MSC), and the average conversation length overall (MCL) for each scenario and model.  Lower MCL values are better, indicating greater efficiency. This allows for a comparison of the effectiveness and efficiency of different methods and models across different task types.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_20_3.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of experiments conducted across three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs.  It compares the performance of the proposed UoT method against several baselines.  The metrics used are Success Rate (SR), reflecting the percentage of tasks successfully completed; Mean Conversation Length in Successful Cases (MSC), showing the average number of turns taken in successful conversations; and Mean Conversation Length (MCL), representing the average number of turns across all conversations (both successful and unsuccessful).  The table provides a detailed breakdown of the results, showing the performance of different LLMs in open and closed set scenarios for each task.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_21_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods (Direct Prompting, UoT, etc.).  It compares the success rates, average conversation lengths for successful attempts, and overall average conversation lengths across these scenarios and models, illustrating the effectiveness of the UoT method in improving performance.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_21_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods (Direct Prompting, UoT, and other baselines). It compares three key metrics: Success Rate (the percentage of successful task completions), Mean Conversation Length in Successful Cases (the average number of turns taken to complete the task successfully), and Mean Conversation Length (the average number of turns taken in all cases, including unsuccessful ones). The table allows for a comprehensive comparison of the effectiveness and efficiency of different methods in each scenario across multiple LLMs.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_22_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the performance of different LLMs across three tasks: 20 Questions, Medical Diagnosis, and Troubleshooting.  For each task and LLM, it shows the Success Rate (percentage of successful task completions), Mean Conversation Length in Successful Cases (average number of turns in successful conversations), and the overall Mean Conversation Length (average number of turns across all conversations, including unsuccessful ones).  The table allows comparison between different LLMs and evaluation of the effectiveness of UoT in improving efficiency and success rate.  Open set (OS) and closed set (CS) results are reported for each task, showing performance with and without prior knowledge of the solution space.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_22_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) across five different LLMs (Llama-3-70B-Instruct, Mistral-Large, Gemini-1.5-Pro, Claude-3-Opus, and GPT-4). For each scenario and LLM, it shows the success rate (SR), mean conversation length in successful cases (MSC), and mean conversation length (MCL).  The table allows comparison of the performance of different LLMs and the effectiveness of the UoT method (Uncertainty of Thoughts) in various scenarios.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_22_3.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of experiments conducted across three scenarios: 20 Questions, Medical Diagnosis, and Troubleshooting.  For each scenario, the table shows the success rate (percentage of tasks successfully completed), the mean conversation length in successful cases (average number of turns in successful conversations), and the mean conversation length across all cases (average number of turns, regardless of success).  Results are presented for different language models (LLMs) and methods (Direct Prompting, UoT, and various baselines).", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_23_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) across various LLMs.  It compares the performance of direct prompting (DP) and the proposed Uncertainty of Thoughts (UoT) method in both open-set (OS) and closed-set (CS) settings.  For each scenario and LLM, the table shows the Success Rate (percentage of successful task completions), Mean Conversation Length in Successful Cases (average number of turns in successful conversations), and Mean Conversation Length (average number of turns across all conversations, regardless of success). This allows for a comprehensive comparison of UoT's effectiveness across different tasks and models in terms of both efficiency and success rate.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_23_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using different LLMs and methods. For each scenario, it displays the Success Rate (percentage of successful task completions), Mean Conversation Length in Successful Cases (average number of turns in successful conversations), and Mean Conversation Length (average number of turns in all conversations, both successful and unsuccessful).  This data allows for a comparison of the effectiveness and efficiency of different approaches across various LLMs.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_24_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods.  It compares the success rate (SR), mean conversation length in successful cases (MSC), and mean conversation length (MCL) across different models and conditions (open-set and closed-set). The table allows for a comparison of the effectiveness and efficiency of different approaches.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_24_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) across multiple LLMs.  For each scenario and LLM, it shows the Success Rate (percentage of successful task completions), Mean Conversation Length in Successful Cases (average number of turns in successful conversations), and the Mean Conversation Length (average number of turns across all conversations, including unsuccessful ones).  This allows for a comparison of the effectiveness and efficiency of different LLMs and methods in various interactive tasks.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_24_3.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods.  It compares the success rate (SR), mean conversation length in successful cases (MSC), and mean conversation length (MCL) for each scenario and model. The models tested include Llama-3-70B-Instruct, Mistral-Large, Gemini-1.5-Pro, Claude-3-Opus, and GPT-4, with baselines including Direct Prompting (DP), Planning Prompting (PP), Chain-of-Thought (CoT), CoT-SC, Reflexion, ToT, and Adapted-ToT.  The results demonstrate the performance of the proposed UoT method across different scenarios and models, highlighting its improvement over existing baselines in terms of success rate and efficiency.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_26_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) across multiple LLMs.  For each scenario and model, it shows the Success Rate (SR, the percentage of successfully completed tasks), Mean Conversation Length in Successful Cases (MSC, the average number of turns in successful conversations), and the Mean Conversation Length (MCL, the average number of turns in all conversations, both successful and unsuccessful).  It compares the performance of the proposed Uncertainty of Thoughts (UoT) method with several baseline methods (Direct Prompting, Planning Prompting, etc.). The table helps to illustrate the effectiveness of the UoT method in improving both task success rate and efficiency.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_26_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods (Direct Prompting, UoT, and others). It compares the success rate (SR), mean conversation length in successful cases (MSC), and mean conversation length (MCL) across these scenarios and methods to evaluate the performance of the Uncertainty of Thoughts (UoT) model.  The table shows how the UoT model improves the success rate and efficiency of LLMs in different tasks by reducing the number of questions needed to complete the tasks.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_26_3.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using several large language models (LLMs).  For each scenario and LLM, the table shows the success rate (SR), the mean conversation length in successful cases (MSC), and the mean conversation length across all cases (MCL).  The results allow comparison of performance across different tasks and LLMs.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_27_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) across multiple LLMs.  It compares the performance of the proposed UoT method to various baselines (DP, PP, CoT, CoT-SC, Reflexion, Original-ToT, Adapted-ToT) by measuring three key metrics: Success Rate (SR), representing the percentage of successfully completed tasks; Mean Conversation Length in Successful Cases (MSC), indicating the average number of turns required for successful task completion; and Mean Conversation Length (MCL), showing the average number of turns across both successful and unsuccessful attempts.  The table allows for a comprehensive comparison of UoT's effectiveness in terms of both accuracy (SR) and efficiency (MSC and MCL) across different models and tasks.", "section": "3. Experiments"}, {"figure_path": "CVpuVe1N22/tables/tables_27_2.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods (Direct Prompting, UoT, and others).  It compares the success rate (SR) of each method, the mean conversation length in successful cases (MSC), and the mean conversation length overall (MCL).  Lower MCL values indicate higher efficiency.", "section": "3.2 Performance"}, {"figure_path": "CVpuVe1N22/tables/tables_27_3.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods, including Direct Prompting (DP) and Uncertainty of Thoughts (UoT).  The metrics used to evaluate performance are Success Rate (SR), which represents the percentage of successfully completed tasks; Mean Conversation Length in Successful Cases (MSC), indicating the average number of turns required to complete a successful task; and Mean Conversation Length (MCL), showing the average number of turns across all tasks, regardless of success or failure.  The table allows for a comparison of the performance and efficiency of the UoT method across different LLMs and scenarios compared to the baseline DP method.", "section": "3.1 Experimental Setup"}, {"figure_path": "CVpuVe1N22/tables/tables_28_1.jpg", "caption": "Table 1: Results from three different scenarios, assessing Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL).", "description": "This table presents the results of three different scenarios (20 Questions, Medical Diagnosis, and Troubleshooting) using various LLMs and methods.  It compares the Success Rate (SR), Mean Conversation Length in Successful Cases (MSC), and Mean Conversation Length (MCL) for each scenario and model to demonstrate the effectiveness of the Uncertainty of Thoughts (UoT) method.  The table allows for comparison of UoT against various baseline methods and different LLMs. Lower MCL values indicate greater efficiency.", "section": "3.2 Performance"}]