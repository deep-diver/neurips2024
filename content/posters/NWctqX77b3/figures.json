[{"figure_path": "NWctqX77b3/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of the proposed compression architecture.", "description": "This figure illustrates the MeLLoC framework's architecture. It starts with the original data which undergoes a local mechanism analysis represented by solving the equation K<sub>c</sub>u<sub>in</sub> = b<sub>ubd,f</sub>.  The results are then separated into boundary data (u<sub>bd</sub>) and source term (f).  A precision control step optimizes these components before encoding and decoding, which ultimately leads to reconstructed data that closely matches the original data. The figure visually showcases the key stages of the compression process: learning a local mechanism from data, separating boundary and source term, utilizing precision control and applying encoding and decoding.", "section": "3 Methodology"}, {"figure_path": "NWctqX77b3/figures/figures_3_1.jpg", "caption": "Figure 2: Local representation notations.", "description": "This figure illustrates the local representation of the difference operator used in the MeLLoC framework. (a) shows the coefficient template, a 9-point stencil that captures the spatial relationships between data points. (b) shows how this local representation translates to intra-predictions within the grid. (c) provides examples of coefficient templates for different types of partial differential equations (PDEs) such as elliptic, hyperbolic, and parabolic.", "section": "Methodology"}, {"figure_path": "NWctqX77b3/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of precision control.", "description": "This figure illustrates the concept of precision control in the MeLLoC framework. It shows how the precision of the data (u) and the source term (f) are related.  (a) shows the relationship between the number of significant digits in the data and the total number of decimal places, highlighting that the source term (f) has a lower precision than the original data (u), which is crucial for compression. (b) illustrates three scenarios that demonstrate the trade-off between the number of significant digits and the magnitude of the values in the source term. Case I shows a scenario with high precision digits, resulting in a larger magnitude for the source term. Case II shows a scenario where the source term has a large absolute value despite having fewer significant digits. Case III represents the optimal scenario, where a balance is achieved between the magnitude and the number of significant digits in the source term.", "section": "3.4 Precision Control"}, {"figure_path": "NWctqX77b3/figures/figures_6_1.jpg", "caption": "Figure 4: Schematic representation of periodic continuation.", "description": "This figure illustrates the periodic continuation used in the Fast Fourier-based Solver method.  The data points are extended periodically beyond the original boundaries to create a larger grid.  This allows for the application of the efficient Fast Fourier Transform (FFT) for solving the system of equations (1), which significantly accelerates the computation during both compression and decompression. The blue dots represent the original data, and the green and orange dots represent the periodically extended data.", "section": "3.5 Fast Fourier-based Solver"}, {"figure_path": "NWctqX77b3/figures/figures_8_1.jpg", "caption": "Figure 5: Demo of the proposed scheme on CESM-ATM and Hurricane datasets.", "description": "This figure demonstrates the effectiveness of the proposed compression method on two real-world datasets: CESM-ATM and Hurricane.  It shows visualizations of the original data and the corresponding source term after applying the compression technique. The visualizations reveal a significant reduction in the range of values and complexity in the source term compared to the original data, indicating a successful compression process. The small range of values and simpler structure in the source term imply that it is much more compressible than the original data, which is consistent with the main idea of the paper.  The low reconstruction errors (10\u207b\u00b9\u00b9 for CESM-ATM and 10\u207b\u00b9\u00b2 for Hurricane) further validate the accuracy of the method, demonstrating that it preserves the necessary numerical precision for scientific computations.", "section": "5.1 Compression and Reconstruction"}, {"figure_path": "NWctqX77b3/figures/figures_8_2.jpg", "caption": "Figure 6: Frequency distribution plots of data before and after compression.", "description": "This figure displays the frequency distribution of the data before and after applying the compression method.  The left two histograms show the distribution of the original CESM-ATM and Hurricane datasets. The right two histograms show the distribution of the corresponding source terms after compression.  The use of logarithmic scales highlights the effect of the compression on reducing the range and variability of the data values, leading to a better compression rate.", "section": "5.2 Frequency Distribution Analysis"}, {"figure_path": "NWctqX77b3/figures/figures_9_1.jpg", "caption": "Figure 7: Performance Metrics Across File Sizes.", "description": "This figure shows the scalability performance of the MeLLoC compression method across varying file sizes.  The orange line represents the compression ratio, which shows a slight decrease as the file size increases, indicating consistent performance even with larger datasets.  The blue and green dashed lines represent the compression and decompression speeds, respectively, both remaining relatively stable across the tested file sizes.  Compression speed consistently outperforms decompression speed, maintaining an efficient compression process.", "section": "5.4 Scalability Performance Analysis"}]