{"references": [{"fullname_first_author": "Yasin Abbasi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-01-01", "reason": "This paper provides foundational algorithms for linear stochastic bandits, which are crucial for understanding and improving upon the techniques used in this work on reinforcement learning with function approximation."}, {"fullname_first_author": "Marc Abeille", "paper_title": "Instance-wise minimax-optimal algorithms for logistic bandits", "publication_date": "2021-01-01", "reason": "This paper establishes important results in the field of logistic bandits, which are closely related to the multinomial logit models studied in this paper and serves as a foundation for improving the regret bound for MNL MDPs."}, {"fullname_first_author": "Alex Ayoub", "paper_title": "Model-based reinforcement learning with value-targeted regression", "publication_date": "2020-01-01", "reason": "This paper provides significant advancements in model-based reinforcement learning, particularly the value-targeted regression method, which is highly relevant to the techniques and analysis in this paper on improving computational and statistical efficiency."}, {"fullname_first_author": "Francis Bach", "paper_title": "Self-concordant analysis for logistic regression", "publication_date": "2010-01-01", "reason": "This paper introduces the concept of self-concordant analysis for logistic regression, a key technique used in analyzing the efficiency and convergence rate of the online Newton step algorithm used in this paper."}, {"fullname_first_author": "Stephen Boyd", "paper_title": "Convex optimization", "publication_date": "2004-01-01", "reason": "This book provides a comprehensive overview of convex optimization, a fundamental tool used in various aspects of this paper, including the development of efficient algorithms for MNL function approximation and the theoretical analysis of the regret bounds."}]}