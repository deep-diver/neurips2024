{"references": [{"fullname_first_author": "Chuan Guo", "paper_title": "On calibration of modern neural networks", "publication_date": "2017-08-06", "reason": "This paper is foundational for the topic of calibration in neural networks, which is central to the current paper's focus on improving confidence calibration in both in-distribution and out-of-distribution settings."}, {"fullname_first_author": "Matthias Hein", "paper_title": "Why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem", "publication_date": "2019-06-01", "reason": "This paper directly addresses the issue of overconfidence in deep neural networks, which is a key problem that the proposed approach aims to solve by modifying the network's internal representation."}, {"fullname_first_author": "Shiyu Liang", "paper_title": "Enhancing the reliability of out-of-distribution image detection in neural networks", "publication_date": "2017-06-01", "reason": "This paper tackles the problem of out-of-distribution detection, another crucial aspect of the research. It is directly relevant as the current paper seeks to improve calibration not only for in-distribution data but also for out-of-distribution data."}, {"fullname_first_author": "Jie Ren", "paper_title": "Likelihood ratios for out-of-distribution detection", "publication_date": "2019-01-01", "reason": "This paper introduces the concept of likelihood ratios for out-of-distribution detection, which is relevant to the methods explored for OOD calibration in the present work."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Deep anomaly detection with outlier exposure", "publication_date": "2018-12-01", "reason": "This paper focuses on deep anomaly detection, closely related to OOD detection, a problem that the current paper addresses by improving overall confidence calibration."}]}