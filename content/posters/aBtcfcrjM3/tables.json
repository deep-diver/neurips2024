[{"figure_path": "aBtcfcrjM3/tables/tables_5_1.jpg", "caption": "Table 1: Comparison of the best-performing compression rates for different methods on the CIFAR10 benchmark with Alexnet, VGG16, and ResNet18. For each column, we report first and second best results.", "description": "This table compares the performance of different model compression techniques on three different convolutional neural network architectures (Alexnet, VGG16, ResNet18) using the CIFAR10 dataset.  The techniques include the proposed TDLRT method, along with several baseline methods involving matrix and tensor factorizations (CP, Tucker, Tensor Train, etc.), and pruning methods (SNIP, IMP, GraSP). For each architecture, the table shows the test accuracy and compression rate achieved by the best and second-best performing methods in each category.", "section": "4.1 Compression Performance"}, {"figure_path": "aBtcfcrjM3/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of the best-performing compression rates for different methods on the CIFAR10 benchmark with Alexnet, VGG16, and ResNet18. For each column, we report first and second best results.", "description": "This table compares the best compression rate achieved by different model compression methods on three different CNN architectures (Alexnet, VGG16, and ResNet18) using the CIFAR10 dataset.  The compression rate is calculated as 1 - c/f, where c is the number of convolutional parameters in the compressed model and f is the number of convolutional parameters in the full model.  The table shows that TDLRT (the proposed method) achieves the highest compression rates with comparable accuracy to the other methods.  Different baseline methods include direct training of low-rank matrix and tensor factorizations, and pruning techniques based on weight sparsification.", "section": "4.1 Compression Performance"}, {"figure_path": "aBtcfcrjM3/tables/tables_9_1.jpg", "caption": "Table 2: Fine-tuning performance metrics on Deberta V3 Glue benchmark (left) and on Stable diffusion Dreambooth (right).", "description": "This table compares the performance of the proposed TDLRT method against LoRA for fine-tuning pre-trained models on two different tasks: the GLUE benchmark (a natural language understanding benchmark) and Stable Diffusion Dreambooth (an image generation model).  It shows the loss and the number of parameters for different rank settings for both LoRA and the proposed method.  The results demonstrate the comparable performance of TDLRT to LoRA while achieving better compression.", "section": "4.4 Fine-tuning with LoRA-like low-rank adapters"}, {"figure_path": "aBtcfcrjM3/tables/tables_16_1.jpg", "caption": "Table 3: Tiny-imagenet benchmark with ResNet18. TDLRT outperforms standard Tucker factorization in terms of the compression-to-accuracy ratio.", "description": "This table presents the results of the ResNet18 model trained on the Tiny-Imagenet dataset, comparing the performance of TDLRT with different compression rates (controlled by the parameter \u03c4) against a standard Tucker factorization baseline. It shows that TDLRT achieves a higher compression rate while maintaining a competitive test accuracy, demonstrating its effectiveness in model compression.", "section": "4.1 Compression Performance"}, {"figure_path": "aBtcfcrjM3/tables/tables_17_1.jpg", "caption": "Table 4: Reproduction of the results of Alexnet on Cifar10. The ranks reported refer to the Tucker ranks of each convolutional layer.", "description": "This table compares the test accuracy and Tucker ranks of each convolutional layer for Alexnet trained on Cifar10 dataset, using both the baseline (full model) and TDLRT approaches with different compression rates (\u03c4).  The Tucker ranks show the compression achieved by the TDLRT method on each layer.", "section": "4. Experiments"}]