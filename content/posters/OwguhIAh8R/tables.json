[{"figure_path": "OwguhIAh8R/tables/tables_7_1.jpg", "caption": "Table 1: Summary of dataset statistics.", "description": "This table summarizes the statistics of five benchmark datasets used in the paper's experiments.  Each dataset is characterized by the number of node types, the total number of nodes, the number of edges, the number of features per node, and the number of labels associated with each node.  The datasets represent diverse domains and characteristics, enabling a comprehensive evaluation of the proposed HGDL method.", "section": "6 Experiments"}, {"figure_path": "OwguhIAh8R/tables/tables_7_2.jpg", "caption": "Table 2: Mean \u00b1 standard deviation results of seven models on five datasets. Best results are bold, and \u2191 (or\u2193) indicates the higher (or lower) the better. Results are taken from 5 repeats. The win/tie/loss counts are suggested by the paired t-test at 90% confidence level.", "description": "This table presents the performance comparison of seven different models on five graph datasets using six evaluation metrics. The models include baselines and variants of the proposed HGDL model. Each metric measures the discrepancy between predicted and true label distributions. The best-performing model for each metric is highlighted in bold. Win/Tie/Lose counts indicate the number of times each model outperforms, ties, or underperforms HGDL, based on paired t-tests at a 90% confidence level.  This provides insights into the effectiveness of HGDL compared to other state-of-the-art methods for heterogeneous graph label distribution learning.", "section": "6 Experiments"}, {"figure_path": "OwguhIAh8R/tables/tables_14_1.jpg", "caption": "Table 3: Benchmark dataset data statistics", "description": "This table presents the statistics of five benchmark datasets used in the paper's experiments. For each dataset, it lists the number of node types and the count of nodes for each type, the number of features for each node, the edge types and their counts, and the number of labels.", "section": "6 Experiments"}, {"figure_path": "OwguhIAh8R/tables/tables_14_2.jpg", "caption": "Table 4: Meta-paths and label semantics of the benchmark datasets", "description": "This table summarizes the meta-paths used for each dataset (DRUG, ACM, DBLP, YELP, URBAN) and provides a description of the label semantics for each dataset.  Meta-paths represent the different paths through the heterogeneous graph used to generate homogeneous subgraphs for the learning process. The label semantics describe the meaning and interpretation of the labels used in each dataset.", "section": "Supplement B: Experiments and Datasets"}, {"figure_path": "OwguhIAh8R/tables/tables_15_1.jpg", "caption": "Table 5: Examples of drug name, ID, and drug in SMILES notation (SMILES: Simplified Molecular Input Line Entry System)", "description": "This table shows three examples of drug names, their corresponding Drug IDs, and their chemical structures represented using SMILES notation.  SMILES is a simplified way to represent molecular structures as strings, which can be easily processed by computers. This is useful for machine learning models that use molecular information as input.", "section": "6.1 Experiment Setup"}, {"figure_path": "OwguhIAh8R/tables/tables_15_2.jpg", "caption": "Table 6: DRUG label semantics", "description": "This table shows the semantic meanings of the labels used in the DRUG dataset.  Each label represents a category of diseases from the Medical Subject Headings (MeSH) database, which is a comprehensive controlled vocabulary of medical terms. The table provides a mapping between the numerical label identifiers (C01-G07) and the corresponding MeSH categories, clarifying the meaning and nature of the labels used to describe the relationship between drugs and diseases.", "section": "6.1 Experiment Setup"}, {"figure_path": "OwguhIAh8R/tables/tables_15_3.jpg", "caption": "Table 7: DBLP dataset average label distributions (mean\u00b1Std) for all nodes w.r.t. different classes.", "description": "This table shows the average label distributions for each node in the DBLP dataset.  Each node's label is represented as a probability distribution across four classes. The average distribution is calculated by grouping nodes with the same dominant class (the class with the highest probability). Standard deviations show the spread of distributions within each group.  Lower diagonal values indicate more spread-out class probabilities.", "section": "6.1 Experiment Setup"}, {"figure_path": "OwguhIAh8R/tables/tables_16_1.jpg", "caption": "Table 2: Mean \u00b1 standard deviation results of seven models on five datasets. Best results are bold, and \u2191 (or\u2193) indicates the higher (or lower) the better. Results are taken from 5 repeats. The win/tie/loss counts are suggested by the paired t-test at 90% confidence level.", "description": "This table presents the performance comparison of seven models (GCNKL, HANKL, SeHGNNKL, HGDL, HGDL-transformer, HGDL-TH, and HGDLED) across five benchmark datasets (DRUG, ACM, DBLP, YELP, and URBAN).  The performance is evaluated using six metrics (COD, CAD, CHD, CLD, IND, and KL) that measure the discrepancy between predicted and true label distributions.  The best results for each metric and dataset are highlighted in bold, indicating which model performed best.  The win/tie/loss counts show the statistical significance of the differences, obtained through paired t-tests at 90% confidence.", "section": "6.2 Results"}, {"figure_path": "OwguhIAh8R/tables/tables_17_1.jpg", "caption": "Table 2: Mean \u00b1 standard deviation results of seven models on five datasets. Best results are bold, and \u2191 (or\u2193) indicates the higher (or lower) the better. Results are taken from 5 repeats. The win/tie/loss counts are suggested by the paired t-test at 90% confidence level.", "description": "This table presents the performance comparison results of seven models on five different datasets.  Each model's performance is measured using six evaluation metrics: Cosine Distance (COD), Canberra Distance (CAD), Chebyshev Distance (CHD), Clark Distance (CLD), Intersection Score (IND), and Kullback-Leibler Divergence (KL).  The best performance for each metric is highlighted in bold.  Win/tie/loss counts indicate the number of times each model outperformed, tied, or underperformed the HGDL model across all metrics and datasets.", "section": "6 Experiments"}, {"figure_path": "OwguhIAh8R/tables/tables_17_2.jpg", "caption": "Table 2: Mean \u00b1 standard deviation results of seven models on five datasets. Best results are bold, and \u2191 (or \u2193) indicates the higher (or lower) the better. Results are taken from 5 repeats. The win/tie/loss counts are suggested by the paired t-test at 90% confidence level.", "description": "This table presents the performance comparison of seven different models (including the proposed HGDL model and its variants) on five different datasets.  The performance is evaluated using six different metrics: Cosine Distance (COD), Canberra Distance (CAD), Chebyshev Distance (CHD), Clark Distance (CLD), Intersection Score (IND), and Kullback-Leibler Divergence (KL).  Lower values are better for COD, CAD, CHD, and CLD, while higher values are better for IND and KL. The win/tie/loss counts represent how many times each model outperformed, tied with, or underperformed the proposed HGDL model at a 90% confidence level based on a paired t-test.", "section": "6 Experiments"}, {"figure_path": "OwguhIAh8R/tables/tables_20_1.jpg", "caption": "Table 2: Mean \u00b1 standard deviation results of seven models on five datasets. Best results are bold, and \u2191 (or\u2193) indicates the higher (or lower) the better. Results are taken from 5 repeats. The win/tie/loss counts are suggested by the paired t-test at 90% confidence level.", "description": "This table presents the performance comparison of seven different models (GCNKL, HANKL, SeHGNNKL, GLDL, HINormer, HGDL, and its variants) on five benchmark datasets (DRUG, ACM, DBLP, YELP, and URBAN) using six evaluation metrics (COD, CAD, CHD, CLD, IND, and KL). The best performance for each metric and dataset is highlighted in bold. The win/tie/loss counts indicate the statistical significance of the performance differences between HGDL and other models.", "section": "6.2 Results"}, {"figure_path": "OwguhIAh8R/tables/tables_31_1.jpg", "caption": "Table 1: Summary of dataset statistics.", "description": "This table presents the statistics of five benchmark datasets used in the paper. For each dataset, it shows the number of node types, the total number of nodes, the number of edges, the number of features per node, and the number of labels. These datasets cover various domains including biomedicine, scholarly network, business network, and urban planning.", "section": "6 Experiments"}]