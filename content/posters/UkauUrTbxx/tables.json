[{"figure_path": "UkauUrTbxx/tables/tables_5_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of the proposed ProTransformer against several baseline methods (ALBERT, DistilBERT, RoBERTa, BERT) and defense mechanisms (FreeLB, PGD, MixADA, TA-VAT, AT) under various text attack methods (TextFooler, TextBugger, DeepWordBug, PWWS). The table showcases the clean accuracy, accuracy under attack, and attack success rate for each model and attack combination, highlighting the effectiveness of ProTransformer in improving robustness against adversarial attacks.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_6_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), RoBERTa, Pro-RoBERTa (MCP), BERT, and Pro-BERT with various loss functions and combined with Adversarial Training) across four different attack methods (TextFooler, TextBugger, DeepWordBug, PWWS). For each model and attack, the table shows the clean accuracy (Clean%), the accuracy under attack (AUA%), and the attack success rate (ASR%).  The results highlight the effectiveness of the proposed ProTransformer in improving the robustness of various transformer models against different attacks.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_7_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models under various text-based adversarial attacks (TextFooler, TextBugger, DeepWordBug, PWWS) and defense methods.  The table shows the clean accuracy, accuracy under attack (AUA%), attack success rate (ASR%), and the number of queries for each model.  The results highlight the effectiveness of the proposed ProTransformer in improving robustness against these attacks, especially when combined with adversarial training.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_9_1.jpg", "caption": "Table 3: Adversarial robustness under PGD.", "description": "This table shows the adversarial robustness of various vision transformer models (DeiT, ConViT, BeiT, Swin, ViT) and the proposed Pro-ViT model under the Projected Gradient Descent (PGD) attack.  The results are presented as the accuracy under attack (%) at different perturbation budgets (1/255, 4/255, 8/255). The clean accuracy is also included as a baseline.", "section": "5.1 Image Classification"}, {"figure_path": "UkauUrTbxx/tables/tables_9_2.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), ROBERTa, Pro-ROBERTa (MCP), BERT, and several defense baselines (FreeLB, PGD, MixADA, TA-VAT, AT, Pro-BERT (l1), Pro-BERT (Huber), and Pro-BERT (MCP), Pro-BERT (MCP) + AT)) under various classic text-based attacks (TextFooler, TextBugger, DeepWordBug, and PWWS). The metrics used for evaluation include Clean Accuracy, Accuracy under Attack (AUA), and Attack Success Rate (ASR).  The table showcases the improvement in robustness achieved by the proposed ProTransformer (Pro- versions of the models) compared to standard models and existing defense methods.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_16_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted using the AGNEWS dataset.  It compares the performance of various models, including ALBERT, DistilBERT, RoBERTa, and BERT, both with and without the ProTransformer (using different penalty functions). It also compares these models to several baseline defense methods, such as FreeLB, PGD, MixADA, TA-VAT, and Adversarial Training (AT). The performance is measured under various text attack methods: TextFooler, TextBugger, DeepWordBug, and PWWS.  The metrics displayed for each model and attack include clean accuracy, accuracy under attack, and attack success rate.  This allows for a comprehensive comparison of the robustness of different models and defense strategies.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_26_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments using the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), RoBERTa, Pro-RoBERTa (MCP), BERT, BERT + FreeLB, BERT + PGD, BERT + MixADA, BERT + TA-VAT, BERT + AT, Pro-BERT (l1), Pro-BERT (Huber), Pro-BERT (MCP), and Pro-BERT (MCP) + AT) under various classic text attacks (TextFooler, TextBugger, DeepWordBug, PWWS). The metrics used are Clean Accuracy (Clean%), Accuracy under Attack (AUA%), and Attack Success Rate (ASR%). The results showcase the effectiveness of the proposed ProTransformer in improving the robustness of transformer models.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_27_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments performed on the AGNEWS dataset.  It compares the performance of various models (ALBERT, Pro-ALBERT, DistilBERT, Pro-DistilBERT, RoBERTa, Pro-RoBERTa, BERT, and Pro-BERT) under different classic text attacks (TextFooler, TextBugger, DeepWordBug, PWWS).  The table also includes results for several defense baselines (FreeLB, PGD, MixADA, TA-VAT, AT) and shows the clean accuracy for each model.  The metrics used are clean accuracy, accuracy under attack (AUA), and attack success rate (ASR).  The goal is to demonstrate the effectiveness of the proposed ProTransformer in improving the robustness of transformer-based models against adversarial attacks.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_27_2.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification on the AGNEWS dataset.  It compares the performance of several models (ALBERT, DistilBERT, RoBERTa, and BERT) with and without the proposed ProTransformer, under various classic text attacks (TextFooler, TextBugger, DeepWordBug, and PWWS).  The table shows clean accuracy, accuracy under attack, and attack success rate for each model and attack, allowing for a comprehensive comparison of the robustness improvements achieved by ProTransformer.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_27_3.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments using the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), RoBERTa, Pro-RoBERTa (MCP), BERT, and Pro-BERT (MCP)) under various classic text attacks (TextFooler, TextBugger, DeepWordBug, PWWS).  The results show the clean accuracy (Clean%), accuracy under attack (AUA%), and attack success rate (ASR%).  It also includes results for several defense baselines (FreeLB, PGD, MixADA, TA-VAT, AT, Pro-BERT (l1), Pro-BERT (Huber)) for comparison.  The table demonstrates the effectiveness of the proposed ProTransformer (using the MCP penalty) in improving the robustness of different transformer models.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_28_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), RoBERTa, Pro-RoBERTa (MCP), BERT, and various defense methods (FreeLB, PGD, MixADA, TA-VAT, AT) against several text attack methods (TextFooler, TextBugger, DeepWordBug, PWWS).  The metrics used are clean accuracy, accuracy under attack, and attack success rate.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_29_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification on the AGNEWS dataset.  It compares the performance of several models (ALBERT, DistilBERT, RoBERTa, and BERT) with and without the proposed ProTransformer under various text-based adversarial attacks (TextFooler, TextBugger, DeepWordBug, and PWWS).  It also includes the performance of several existing defense methods for comparison.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_29_2.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models (ALBERT, DistilBERT, RoBERTa, BERT) against various text-based adversarial attacks (TextFooler, TextBugger, DeepWordBug, PWWS). The table also shows the performance of the proposed ProTransformer method and several defense baselines (FreeLB, PGD-Adv, MixADA, TA-VAT, Adversarial Training) to highlight the effectiveness of ProTransformer in improving model robustness against adversarial attacks.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_29_3.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models, including the baseline ALBERT, DistilBERT, RoBERTa, and BERT models, and their corresponding ProTransformer versions enhanced with the MCP penalty. The models' performance is evaluated under various text-based attacks (TextFooler, TextBugger, DeepWordBug, PWWS) and defense baselines (FreeLB, PGD, MixADA, TA-VAT, Adversarial Training).  The metrics used are Clean accuracy (Clean%), Accuracy under Attack (AUA%), and Attack Success Rate (ASR%). This allows for a comprehensive comparison of the proposed ProTransformer's robustness against different attacks and in comparison to other defense mechanisms.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_30_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification on the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), ROBERTA, Pro-ROBERTa (MCP), BERT, and several defense baselines (FreeLB, PGD, MixADA, TA-VAT, AT)) under different text-based adversarial attacks (TextFooler, TextBugger, DeepWordBug, PWWS).  The metrics shown are clean accuracy, accuracy under attack (AUA), and attack success rate (ASR).  It demonstrates the effectiveness of ProTransformer (MCP) in enhancing the robustness of transformer models against these attacks, showing improvements in AUA and reductions in ASR compared to baselines, both independently and when combined with adversarial training.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_31_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments using the AGNEWS dataset.  It compares the performance of several models, including vanilla transformers (ALBERT, DistilBERT, RoBERTa, BERT) and their ProTransformer counterparts, under various classic text attacks.  The performance metrics include clean accuracy, accuracy under attack, and attack success rate.  The table also provides a comparison with several existing defense methods (FreeLB, PGD, MixADA, TA-VAT, and AT). This allows for a comprehensive evaluation of ProTransformer's robustness and effectiveness against adversarial attacks.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_32_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted using the AGNEWS dataset.  It compares the performance (clean accuracy, accuracy under attack, and attack success rate) of several models, including ALBERT, DistilBERT, RoBERTa, and BERT, both with and without the ProTransformer (with MCP penalty).  It also includes results from several baseline defense methods: FreeLB, PGD, MixADA, TA-VAT, and Adversarial Training (AT). The goal is to demonstrate the effectiveness and generalizability of ProTransformer in enhancing the robustness of different transformer architectures against various adversarial attacks.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_33_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of a topic classification experiment using the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), RoBERTa, Pro-RoBERTa (MCP), BERT, and Pro-BERT (with various loss functions and including adversarial training)) under various classic text attacks (TextFooler, TextBugger, DeepWordBug, PWWS).  The table shows the clean accuracy, accuracy under attack, and attack success rate for each model and attack method, demonstrating the effectiveness of the proposed ProTransformer in improving model robustness.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_34_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification on the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), RoBERTa, Pro-RoBERTa (MCP), BERT, and Pro-BERT (with various penalty functions) under different text attack methods (TextFooler, TextBugger, DeepWordBug, PWWS). The metrics used are clean accuracy, accuracy under attack, and attack success rate.  It allows for a comparison of the vanilla transformer models against ProTransformer models and various other defense baselines.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_35_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification on the AGNEWS dataset using various models and attack methods. It compares the clean accuracy, accuracy under attack (AUA), and attack success rate (ASR) for different models, including ALBERT, DistilBERT, RoBERTa, BERT, and their ProTransformer counterparts using MCP and Huber losses.  Several defense baselines like FreeLB, PGD, MixADA, TA-VAT, and AT are included for comparison, allowing for a comprehensive assessment of the ProTransformer's effectiveness.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_36_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several transformer models (ALBERT, DistilBERT, RoBERTa, and BERT) with and without the ProTransformer enhancement.  The comparison is made across four different types of classic text attacks (TextFooler, TextBugger, DeepWordBug, and PWWS). For each model and attack, the table shows the clean accuracy (Clean%), accuracy under attack (AUA%), and attack success rate (ASR%). Several defense baselines (FreeLB, PGD, MixADA, TA-VAT, and Adversarial Training) are also included for comparison.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_37_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models, including the proposed ProTransformer, under various classic text-based adversarial attacks (TextFooler, TextBugger, DeepWordBug, PWWS). The table shows the clean accuracy, accuracy under attack, and attack success rate for each model and attack. It also includes results for several defense baselines for comparison.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_41_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AG's News dataset.  The performance of several models (ALBERT, DistilBERT, RoBERTa, BERT) is evaluated under various classic text attacks (TextFooler, TextBugger, DeepWordBug, PWWS). For each model and attack, the clean accuracy, accuracy under attack (AUA%), and attack success rate (ASR%) are reported.  Additionally, the performance of several defense baselines (FreeLB, PGD-Adv, MixADA, TA-VAT, Adversarial Training) are provided for comparison, along with the proposed ProTransformer using different penalties (L1, Huber, MCP).", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_41_2.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification on the AGNEWS dataset using different models and attack methods.  It compares the performance of several models (ALBERT, DistilBERT, RoBERTa, BERT) against various text attacks (TextFooler, TextBugger, DeepWordBug, PWWS).  It also shows the performance improvement achieved by the proposed ProTransformer, with and without additional adversarial training,  and compares it to several existing defense methods (FreeLB, PGD, MixADA, TA-VAT, AT). The metrics used are Clean Accuracy (Clean%), Accuracy Under Attack (AUA%), and Attack Success Rate (ASR%).", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_41_3.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments using the AGNEWS dataset.  It compares the performance of several models (ALBERT, DistilBERT, RoBERTa, BERT) against various classic text attacks (TextFooler, TextBugger, DeepWordBug, PWWS). For each model and attack, the table shows the clean accuracy (Clean%), accuracy under attack (AUA%), and attack success rate (ASR%). It also includes results from several defense baselines (FreeLB, PGD, MixADA, TA-VAT, AT) and ProTransformer models, illustrating the improvements in robustness achieved by the proposed ProTransformer.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_42_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models: ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), RoBERTa, Pro-RoBERTa (MCP), BERT, and Pro-BERT (with different penalty functions and with/without adversarial training).  The performance is evaluated under different classic text attacks (TextFooler, TextBugger, DeepWordBug, PWWS). For each model and attack, the clean accuracy (Clean%), accuracy under attack (AUA%), and attack success rate (ASR%) are reported.  This allows for a comparison of the baseline model's robustness versus the improvements achieved by the proposed ProTransformer with different configurations.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_43_1.jpg", "caption": "Table 3: Adversarial robustness under PGD.", "description": "This table presents the results of adversarial robustness experiments conducted on various vision transformers (ViT, BeiT, ConViT, DeiT, and Swin) using the Projected Gradient Descent (PGD) attack method on the CIFAR-10 dataset.  The table shows the clean accuracy (0 budget) and the accuracy under attack at different perturbation budgets (1/255, 4/255, 8/255).  The performance of Pro-ViT (the proposed method) is compared against the baseline models, demonstrating its improved robustness against adversarial attacks.", "section": "5.1 Image Classification"}, {"figure_path": "UkauUrTbxx/tables/tables_43_2.jpg", "caption": "Table 3: Adversarial robustness under PGD.", "description": "This table presents the results of adversarial robustness experiments under the Projected Gradient Descent (PGD) attack.  The experiments were conducted on the CIFAR-10 dataset using several vision transformer models: ViT, DeiT, ConViT, BeiT, and Swin. The table shows the clean accuracy and the accuracy under attack for different perturbation budgets (1/255, 4/255, 8/255).  The results demonstrate the effectiveness of Pro-ViT in improving the robustness of the vision transformer models against adversarial attacks.", "section": "5.1 Image Classification"}, {"figure_path": "UkauUrTbxx/tables/tables_43_3.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of a topic classification experiment using the AGNEWS dataset.  It compares the performance of several models (ALBERT, Pro-ALBERT (MCP), DistilBERT, Pro-DistilBERT (MCP), ROBERTa, Pro-ROBERTa (MCP), BERT, and Pro-BERT with different loss functions and combined with adversarial training) under four different classic text attack methods (TextFooler, TextBugger, DeepWordBug, PWWS). The metrics presented are Clean Accuracy (Clean%), Accuracy Under Attack (AUA%), and Attack Success Rate (ASR%). The results highlight how ProTransformer consistently enhances robustness compared to the base models and other defense methods.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_44_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset.  It compares the performance of several models, including ALBERT, DistilBERT, RoBERTa, and BERT, both with and without the ProTransformer (using different penalty functions).  The table shows clean accuracy, accuracy under attack, and attack success rate (ASR) across four different classic text attacks: TextFooler, TextBugger, DeepWordBug, and PWWS.  It also includes results for several defense baselines for comparison. The results demonstrate the effectiveness of ProTransformer in improving the robustness of different transformer architectures under various text attacks.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_45_1.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments using the AGNEWS dataset.  It compares the performance of several models, including ALBERT, DistilBERT, RoBERTa, and BERT, both with and without the proposed ProTransformer. The results are shown for different attack methods (TextFooler, TextBugger, DeepWordBug, PWWS), indicating the clean accuracy, accuracy under attack (AUA), and attack success rate (ASR).  It also includes the results of other defense methods for comparison.", "section": "4.2.1 Adversarial Robustness"}, {"figure_path": "UkauUrTbxx/tables/tables_45_2.jpg", "caption": "Table 1: The results of topic classification on AGNEWS.", "description": "This table presents the results of topic classification experiments conducted on the AGNEWS dataset using various models.  It compares the performance of the proposed ProTransformer method against several baseline methods across different attack scenarios (TextFooler, TextBugger, DeepWordBug, PWWS). The table shows the clean accuracy, accuracy under attack, and attack success rate for each model and attack.  This allows for a comparison of the robustness of different models and the effectiveness of the proposed ProTransformer in improving model resilience to adversarial attacks.", "section": "4.2.1 Adversarial Robustness"}]