[{"figure_path": "klsyhjLlX5/tables/tables_2_1.jpg", "caption": "Table 1: In the table above, T is the number of rounds of online learning, Tg is the number of rounds for a particular group g, H is the hypothesis class, G is the collection of groups, and \u03c3 is the smoothness parameter defined in Definition 4.1. d is an upper bound on the VC dimension of H. In our \u03c3-smooth result in the fifth row, d is also an upper bound on the VC dimension of a possibly infinite collection of groups, G. In the \u03b3-approximable setting of the sixth row, N is the number of perturbations.", "description": "This table summarizes the regret bounds, computational complexity, and oracle efficiency of various online multi-group learning algorithms, including existing algorithms from the literature and the proposed algorithms from this paper.  It compares the algorithms across different settings: adversarial, \u03c3-smooth, and transductive. The table highlights the oracle efficiency of the proposed algorithms in both the hypothesis class H and the collection of groups G.", "section": "1.2 Related Work"}]