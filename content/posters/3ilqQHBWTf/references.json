{"references": [{"fullname_first_author": "Max Bain", "paper_title": "Frozen in time: A joint video and image encoder for end-to-end retrieval", "publication_date": "2021-10-01", "reason": "This paper is a foundational work for text-to-video generation, providing a strong image encoder which LaSe-E2V adapts to improve video reconstruction from event data."}, {"fullname_first_author": "Christian Brandli", "paper_title": "A 240\u00d7180 130 dB 3 \u03bcs latency global shutter spatiotemporal vision sensor", "publication_date": "2014-10-01", "reason": "This paper introduces the DAVIS sensor, a key technology enabling high dynamic range (HDR) and high temporal resolution video capture, which is a major focus for E2V research."}, {"fullname_first_author": "Yu-Hui Chen", "paper_title": "Speed is all you need: On-device acceleration of large diffusion models via GPU-aware optimizations", "publication_date": "2023-06-01", "reason": "This paper presents efficient GPU optimizations for diffusion models, which LaSe-E2V leverages to achieve real-time video generation from event data."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPM), the foundation for the text-conditional diffusion models used by LaSe-E2V for video generation."}, {"fullname_first_author": "Alex Nichol", "paper_title": "Glide: Towards photorealistic image generation and editing with text-guided diffusion models", "publication_date": "2021-12-01", "reason": "This paper introduces Glide, a text-guided diffusion model, which LaSe-E2V adapts to achieve semantic-aware high-quality video reconstruction."}]}