[{"type": "text", "text": "Multi-Armed Bandits with Network Interference ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Lorenzo Masoero ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Abhineet Agarwal Department of Statistics UC Berkeley aa3797@berkeley.edu ", "page_idx": 0}, {"type": "text", "text": "Anish Agarwal   \nDepartment of IEOR   \nColumbia University   \naa5194@columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Amazon masoerl@amazon.com\u2217 ", "page_idx": 0}, {"type": "text", "text": "Justin Whitehouse Computer Science Department Carnegie Mellon University jwhiteho@andrew.cmu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online experimentation with interference is a common challenge in modern applications such as e-commerce and adaptive clinical trials in medicine. For example, in online marketplaces, the revenue of a good depends on discounts applied to competing goods. Statistical inference with interference is widely studied in the offline setting, but far less is known about how to adaptively assign treatments to minimize regret. We address this gap by studying a multi-armed bandit (MAB) problem where a learner (e-commerce platform) sequentially assigns one of possible $\\boldsymbol{\\mathcal{A}}$ actions (discounts) to $N$ units (goods) over $T$ rounds to minimize regret (maximize revenue). Unlike traditional MAB problems, the reward of each unit depends on the treatments assigned to other units, i.e., there is interference across the underlying network of units. With $\\boldsymbol{\\mathcal{A}}$ actions and $N$ units, minimizing regret is combinatorially difficult since the action space grows as $\\mathcal{A}^{N}$ . To overcome this issue, we study a sparse network interference model, where the reward of a unit is only affected by the treatments assigned to $s$ neighboring units. We use tools from discrete Fourier analysis to develop a sparse linear representation of the unit-specific reward $r_{n}:[A]^{N}\\overset{\\cdot}{\\rightarrow}\\mathbb{R}$ , and propose simple, linear regression-based algorithms to minimize regret. Importantly, our algorithms achieve provably low regret both when the learner observes the interference neighborhood for all units and when it is unknown. This significantly generalizes other works on this topic which impose strict conditions on the strength of interference on a known network, and also compare regret to a markedly weaker optimal action. Empirically, we corroborate our theoretical findings via numerical simulations. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online experimentation is an indispensable tool for modern decision-makers in settings ranging from e-commerce marketplaces [Li et al., 2016] to adaptive clinical trials in medicine [Durand et al., 2018]. Despite the wide-spread use of online experimentation to assign treatments to units (e.g., individuals, subgroups, or goods), a significant challenge in these settings is that outcomes of one unit are often affected by treatments assigned to other units. That is, there is interference across the underlying network of units. For example, in e-commerce, the revenue for a given good depends on discounts applied to related or competing goods. In medicine, an individual\u2019s risk of disease depends not only on their own vaccination status but also on that of others in their network. ", "page_idx": 0}, {"type": "image", "img_path": "ZxZOvVOiiL/tmp/b34667b4e6a6538bc3ac90f324108946f478823618d52ccfc9bf217aa1a0fb56.jpg", "img_caption": ["Figure 1: A visual representation of sparse network interference. In this toy example, we have $N=9$ units, and visualize the interference pattern. For unit 2 (orange), its outcomes are affected by the treatments of its neighbours (blue) $\\mathcal{N}(2)=\\{1,\\bar{2},3,6,7\\}$ . "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Network interference often invalidates standard tools and algorithms for the design and analysis of experiments. While there has been significant work done to develop tools for statistical inference in the offline setting (see Section 2), this problem has mostly been unaddressed in the online learning setting. In this paper, we address this gap by studying the multi-armed bandit (MAB) problem with network interference. We consider the setting where a learner (online marketplace) assigns one of possible ${\\mathcal{A}}\\in\\mathbb{N}$ actions (varying discounts) to $N$ units (goods) over $T$ rounds to minimize average regret. In our setting, the reward of a unit $n\\in[N]:=\\{1,\\dots,N\\}$ depends on the actions assigned to other units.2 With $N$ units and $\\boldsymbol{\\mathcal{A}}$ actions, achieving low regret is difficult since there are $\\boldsymbol{A^{N}}$ possible treatment assignments. Naively applying typical MAB methods such a\u221as the upper confidence bound (UCB) algorithm [Auer et al., 2002] leads to regret that scales as $O(\\sqrt{\\mathcal{A}^{N}T})$ , which can be prohibitively large due to the exponential \u221adependence on $N$ . Further, without any assumptions on the interference pattern, regret scaling as $\\widetilde\\Omega(\\sqrt{A^{N}T})$ is unavoidable due to lower bounds from the MAB literature [Lattimore and Szepesv\u00e1ri, 2020]. ", "page_idx": 1}, {"type": "text", "text": "To overcome this issue, we consider a natural and widely-studied model of sparse network interference, where the reward $r_{n}:[A]^{N}\\to\\mathbb{R}$ for unit $n$ is affected by the treatment assignment of at most $s$ other units, i.e., neighbours. See Figure 1 for a visualization. Under this model, we provide algorithms that provably achieve low regret both when the learner observes the network (i.e., the learner knows the $s$ neighbors for all units $n$ ), and when it is unknown. Our results allow for more general interference patterns and define regret with respect to a significantly stronger comparator policy than existing results in the literature. ", "page_idx": 1}, {"type": "text", "text": "Contributions. ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "(i) For each unit $n\\,\\in\\,[N]$ , we use the Fourier analysis of discrete functions to re-express its reward $r_{n}:[A]^{N}:\\rightarrow\\mathbb{R}$ as a linear function in the Fourier basis with coefficients $\\pmb{\\theta}_{n}\\in\\mathbb{R}^{A^{N}}$ . We show sparse network interference implies $\\theta_{n}$ is $A^{s}$ sparse for all $n\\in[N]$ . This sparse linear representation motivates a simple \u2018explore-then-commit\u2019 style algorithm that uniformly explores actions, then fits a linear model to estimate unit-specific rewards (i.e., $\\pmb{\\theta}_{n_{\\alpha}}$ ). (ii) With known interference (i.e., the learner knows the $s$ neighbors for all $n\\in[N],$ ), our algorithm exploits this knowledge to estimate $r_{n}$ by performing ordinary least squares (OLS) locally (i.e., per unit) on the Fourier basis elements where $\\pmb{\\theta}_{n}$ is non-zero. Our analysis establishes regret $\\tilde{O}((A^{s}T)^{2/3})$ for this algorithm. (iii) With unknown interference, we use the Lasso instead of OLS locally which adapts to sparsity of $\\pmb{\\theta}_{n}$ and establish regret $\\tilde{O}(N^{1/3}(A^{s}T)^{2/3})$ . We argue this $T^{2/3}$ scaling cannot be improved. (iv) Numerical simulations with network interference show our method outperforms baselines. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Causal inference and bandits with interference. The problem of learning causal effects in the presence of cross-unit interference has received significant study from the causal inference community (see [Bajari et al., 2023] for a thorough overview). Cross-unit interference violates basic assumptions for causal identifiability, invalidating standard designs and analyses.3As a result, authors have developed methodologies for estimating causal effects under several models of interference such as intra-group interference [Hudgens and Halloran, 2008, Rosenbaum, 2007], interference neighborhoods [Gao and Ding, 2023, Ugander et al., 2013, Bhattacharya et al., 2020, Yu et al., 2022, Cen et al., 2022], in bipartite graphs representative of modern online markets [Pouget-Abadie et al., 2019, Bajari et al., 2021, 2023], in panel data settings [Agarwal et al., 2022] as well as under a general model of interference, generally encoded via \u201cexposure mappings\u201d [Aronow, 2012, Aronow and Samii, 2017]. Despite this large literature, there is much less work on learning with interference in online settings. Jia et al. [2024] take an important step towards addressing this gap by studying MABs with network interference, but assume a known, grid-like interference pattern, where the strength of the interference decays as the $\\ell_{1}$ distance between units grows. Moreover, their focus \u2013 unlike ours \u2013 is on establishing regret rates with respect to the best constant policy, i.e. the best policy that assigns each unit the same treatment. We also note that the authors consider a setting more closely aligned with the adversarial bandit literature, whereas the results in this paper are closer to those in the stochastic bandit literature. See Section 3 for a detailed description of these differences. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Bandits with high-dimensional action spaces. In MAB problems, regret is typically lower bounded by $\\widetilde{\\Omega}(\\sqrt{\\#\\mathrm{Actions}\\cdot T})$ , where $\\#\\mathrm{Actions}=A^{N}$ in our setting. Typically, this curse of dimensionality is addressed by sparsity constraints on the rewards, where only a small fraction of actions have non-zero rewards [Kwon et al., 2017, Abbasi-Yadkori et al., 2012, Hao et al., 2020]. Particularly relevant to this paper is the work of Hao et al. [2020] who consider sparse linear bandits. The authors utilize a \u201cexplore-then-commit\u201d style algorithm to uniformly explore actions before using the Lasso to estimate the sparse linear parameter. We utilize a similar algorithm but allow for arbitrary interaction between neighboring units, instead using discrete Fourier analysis to linearly represent rewards [Negahban and Shah, 2012, O\u2019Donnell, 2014, Agarwal et al., 2023]. This is similar to kernel bandits [Srinivas et al., 2009, Chowdhury and Gopalan, 2017, Whitehouse et al., 2024], which assume there exists a feature map such that the rewards can be linearly represented (non-sparsely) in a high-dimensional reproducing kernel Hilbert space. Also related are stochastic combinatorial bandits [Chen et al., 2013, Cesa-Bianchi and Lugosi, 2012], in which the action space is assumed to be a subset of $\\{0,1\\}^{N}$ but rewards are typically inherently assumed to be linear in treatment assignments. That is, these works typically assume the reward $r=\\langle\\theta,\\mathbf{a}\\rangle$ for $\\mathbf{a}\\in\\{0,1\\}^{N}$ , with valid actions a often having at most $s$ non-zero components. Our work (with ${\\mathcal{A}}=2$ ), considers an arbitrary function $r:\\{0,1\\}^{\\ensuremath{N}}\\to\\ensuremath{\\mathbb{R}}$ , but explicitly constructs a feature map via discrete Fourier analysis such that rewards can be represented linearly. ", "page_idx": 2}, {"type": "text", "text": "3 Model & Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we first describe the problem setting, and our notion of regret. Then, we introduce the requisite background on discrete Fourier analysis that we will use to motivate our algorithm and theoretical analysis. Last, we introduce the model that we study in this paper. Throughout this paper, we use boldface to represent vectors and matrices. ", "page_idx": 2}, {"type": "text", "text": "3.1 Problem Set-up ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We consider an agent that sequentially interacts with an environment consisting of $N$ individual units over a series of $T$ rounds. We index units $n\\in[N]$ , and rounds $t\\in[T]$ . At each time step $t$ , the agent simultaneously administers each unit $n$ action (or treatment) $a\\in[A]$ . Let $a_{n t}$ denote the treatment received by unit $n$ at time step $t$ , and let $\\mathbf{a}_{t}=(a_{1t},\\dots,a_{N t})\\in[\\dot{A}]^{N}$ denote the entire treatment vector. Each unit $n$ possesses an unknown reward mapping $r_{n}:[\\dot{A}]^{N}\\rightarrow[0,1]$ . Note that we allow the reward for a given unit $n$ to depend on the treatments assigned to all other units, i.e., we allow for cross-unit interference. After assigning a treatment to all units in round $t$ , the agent then observes the noisy reward for unit $n$ as $R_{n t}=r_{n}(\\mathbf{a}_{t})+\\epsilon_{n t}$ . Denote the vector of observed rewards as $\\mathbf{R}_{t}:=\\left(R_{1t}\\,.\\,.\\,.\\,R_{N t}\\right)$ . We assume the following standard condition on the noise $\\epsilon_{n t}$ . ", "page_idx": 2}, {"type": "text", "text": "Assumption 1. $(\\epsilon_{n t}:n\\in[N],t\\in[T])$ is a collection of mutually independent $^{\\,l}$ -sub-Gaussian random variables. ", "page_idx": 2}, {"type": "text", "text": "Regret. To measure the performance of the learning agent, we define the average reward function $\\bar{r}:[A]^{N}\\rightarrow[0,1]$ by $\\begin{array}{r}{\\bar{r}(\\mathbf{a})=\\frac{1}{N}\\sum_{n=1}^{N}r_{n}(\\mathbf{a})}\\end{array}$ . Then, for a sequence of (potentially random) treatment assignments $\\mathbf{a}_{1}\\ldots\\mathbf{a}_{T}$ , the regret at the horizon time $T$ is defined as the quantity ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}=\\sum_{t=1}^{T}\\bar{r}(\\mathbf{a}^{*})-\\sum_{t=1}^{T}\\bar{r}(\\mathbf{a}_{t}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbf{a}^{*}\\in\\arg\\operatorname*{max}_{\\mathbf{a}\\in[A]^{N}}\\bar{r}(\\mathbf{a}).$ . In Sections 4 and 5, we provide and analyse algorithms that achieve small regret with high probability. ", "page_idx": 3}, {"type": "text", "text": "Comparison to other works. Previous works studying network bandits such as Jia et al. [2024] measure regret with respect to the best constant action $\\mathbf{a}^{\\prime}\\;:=\\;\\arg\\operatorname*{max}_{a\\in[A]}\\bar{r}(a\\mathbf{1})$ where $\\textbf{1}\\in$ $\\mathbb{R}^{N}$ denotes the all 1 vector of dimension $N$ . We compare regret to the optimal action ${\\mathbf{a}}^{*}\\ \\in$ ar $\\mathrm{\\max}_{\\mathbf{a}\\in[A]^{N}}\\,\\bar{r}(\\mathbf{a}$ $\\bar{r}(\\mathbf{a})$ , which is combinatorially more difficult to minimize since the policy space is exponentially larger $\\boldsymbol{A}^{N}$ vs $\\mathcal{A}$ ). Our setup is also different than the traditional MAB setting since the agent in this problem does not observe a single scalar reward, but one for each unit (similar to semi-bandit feedback in the combinatorial bandits literature [Cesa-Bianchi and Lugosi, 2012]). As we show later, this crucially allows us to exploit local, unit-specific information that allow for better regret rates. ", "page_idx": 3}, {"type": "text", "text": "3.2 Background on Discrete Fourier Analysis ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we provide background on discrete Fourier analysis, which we heavily employ in both our algorithm and analysis. Specifically, these Fourier-analytic tools provide a linear representation of the discrete unit-specific rewards $r_{n}\\colon[A]^{N}\\to[0,1]$ , which will allow us to leverage well-studied linear bandit algorithms. For the rest of paper, assume $\\boldsymbol{\\mathcal{A}}$ is a power of 2. If instead, if $\\bar{2^{\\ell}}<\\mathcal{A}<2^{\\ell+1}$ for some $\\ell\\geq0$ , we can redundantly encode actions to obtain $A^{\\prime}=2^{\\ell+1}$ total treatments. As seen later, this encoding does not affect the overall regret. ", "page_idx": 3}, {"type": "text", "text": "Boolean encoding of action space. Since by assumption $\\boldsymbol{\\mathcal{A}}$ is a power of 2, every action $a\\quad\\in\\ [A]$ can be uniquely represented as a binary number using $\\log_{2}(A)$ bits. Explicitly, let $\\tilde{\\mathbf{v}}(a)\\,=\\,\\bigl(\\bar{v}_{1}(a),\\ldots\\tilde{v}_{\\log_{2}(A)}(a)\\bigr)\\,\\in\\,\\{0,1\\}^{\\log_{2}(A)}$ denote this vectorized binary representation. For ease of analysis, we use the Boolean representation instead $\\mathbf{v}(a)\\,=\\,2\\tilde{\\mathbf{v}}(a)\\,-\\,1\\,\\in\\,\\{-1,1\\}^{\\log_{2}A}$ . For a $\\in[\\mathcal{A}]^{N}$ , define $\\mathbf{v}(\\mathbf{a})=(\\mathbf{v}(a_{1}),\\ldots,\\mathbf{v}(a_{N}))\\in\\{-1,1\\}^{N\\log_{2}(A)}$ . Note each action $\\mathbf{a}\\in[A]^{N}$ corresponds to a unique Boolean vector $\\mathbf{v}(\\mathbf{a})$ . ", "page_idx": 3}, {"type": "text", "text": "Boolean representation of discrete functions. Let $\\mathcal{F}\\,=\\,\\{\\boldsymbol{f}\\,:\\,[\\mathcal{A}]^{N}\\,\\rightarrow\\,\\mathbb{R}\\}$ and ${\\mathcal F}_{\\mathrm{Bool}}\\;=\\;\\{\\tilde{f}\\;:$ $\\{-1,1\\}^{N\\log_{2}(A)}\\ \\to\\ \\mathbb{R}\\}$ be the collection of all real-values functions defined on the set $[A]^{N}$ and $\\{-1,1\\}^{N\\log_{2}(A)}$ respectively. Since every $\\mathbf{a}\\in[A]^{N}$ has a uniquely Boolean representation $\\mathbf{v}(\\mathbf{a})\\in\\{-1,1\\}^{N\\log_{2}(A)}$ , the set of functions $\\mathcal{F}$ can be naturally identified within ${\\mathcal{F}}_{\\mathrm{Bool}}$ . Specifically, any $f\\in\\mathcal F$ can be identified with the function $\\tilde{f}\\in\\mathcal{F}_{\\mathrm{Bool}}$ by $f(\\cdot)=\\tilde{f}(\\mathbf{v}(\\cdot))$ . ", "page_idx": 3}, {"type": "text", "text": "Fourier series of Boolean functions. This identification is key for our use since the space of Boolean functions admits a number of attractive properties. ", "page_idx": 3}, {"type": "text", "text": "$(I)$ Hilbert space. ${\\mathcal{F}}_{\\mathrm{Bool}}$ forms a Hilbert space defined by the following inner product: for any $h,g\\in{\\mathcal{F}}_{\\mathrm{Bool}}$ , $\\begin{array}{r}{\\langle h,g\\rangle_{B}=\\mathcal{A}^{-N}\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}}\\stackrel{*}{\\log_{2}}(A)\\,h(\\mathbf{x})g(\\mathbf{x})}\\end{array}$ . This inner product induces the norm $\\begin{array}{r}{\\langle h,h\\rangle_{B}\\;:=\\;\\|h\\|_{B}^{2}=A^{-N}\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{p}}\\dot{h}^{2}(\\mathbf{x}).}\\end{array}$ .   \n(2) Simple orthonormal basis. For each subset $S\\subset[N\\log_{2}(A)]$ , define a basis function $\\chi_{S}(\\mathbf{x})=$ $\\textstyle\\prod_{i\\in S}x_{i}$ where $x_{i}$ is the $i^{\\mathrm{th}}$ coefficient of $\\textbf{x}\\in\\,\\,\\{-1,1\\}^{N\\log_{2}(A)}$ . One can verify that for any $S\\ \\tilde{\\subset}\\ [N\\log_{2}(A)]$ , $\\|\\chi_{S}\\|_{B}\\,=\\,1$ , and that $\\langle\\chi_{S},\\chi_{S^{\\prime}}\\rangle_{B}\\,=\\,0$ for any $S^{\\prime}\\neq S$ . Since $|\\{\\chi_{S}\\,:\\,S\\,\\subset$ $[N\\log_{2}(A)]\\}|=A^{N}$ , the functions $\\chi_{S}$ are an orthonormal basis of ${\\mathcal{F}}_{\\mathrm{bool}}$ . We refer to $\\chi_{S}$ as the Fourier character for the subset $S$ .   \n(3) Linear Fourier expansion of ${\\mathcal{F}}_{B o o l}$ . Any $h\\in\\mathcal{F}_{\\mathrm{bool}}$ can be expanded via the following Fourier decomposition: $\\begin{array}{r}{h(\\mathbf{x})=\\sum_{S\\subset[N\\log_{2}(A)]}\\theta_{S}\\chi_{S}(\\mathbf{x})}\\end{array}$ , where the Fourier coefficient $\\theta_{S}$ is given by $\\theta_{S}=$ $\\langle h,\\chi_{S}\\rangle_{B}$ . For $h\\in\\mathcal{F}_{\\mathrm{Bool}}$ , we refer to $\\mathring{\\theta_{h}}=(\\theta_{S}:S\\subset[N\\log_{2}(A)])\\in\\mathbb{R}^{{A}^{N}}$ as the vector of Fourier coefficients associated with it. For $\\mathbf{x}\\in\\{-1,1\\}^{N\\log_{2}(A)}$ , let $\\chi(\\mathbf{x})=(\\chi_{S}(\\mathbf{x}):S\\in[N\\log_{2}(A))])\\in\\mathcal{$ ", "page_idx": 3}, {"type": "text", "text": "$\\{-1,1\\}^{A^{N}}$ be the vector of associated Fourier character outputs. For $\\mathbf{a}\\in[A]^{N}$ , abbreviate $\\chi_{S}(\\mathbf{v}(\\mathbf{a}))$ and $x(\\mathbf{v}(\\mathbf{a}))$ as $\\chi_{S}(\\mathbf{a})$ and $x(\\mathbf{a})$ respectively. ", "page_idx": 4}, {"type": "text", "text": "3.3 Model: Sparse Network Interference ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The unit-specific reward function $r_{n}:[A]^{N}\\to\\mathbb{R}$ can be equivalently viewed as a real-valued Boolean function over the hypercube $\\{-1,1\\}^{N\\log_{2}(A)}$ . That is, $r_{n}$ takes as input a vector of actions $\\mathbf{a}\\in[A]^{N}$ , converts it to a Boolean vector $\\mathbf{v}(\\mathbf{a})\\,\\in\\,\\{-1,1\\}^{N\\log_{2}(A)}$ , and outputs a reward $r_{n}(\\mathbf{a})$ . From the discussion in Section 3.2, we can represent unit $n$ \u2019s reward as $\\begin{array}{r}{r_{n}(\\mathbf{a})\\stackrel{{}}{=}\\sum_{S\\subset[N\\log_{2}(A)]}\\dot{\\theta_{n,S}}\\chi_{S}(\\mathbf{a})=}\\end{array}$ $\\left<\\pmb{\\theta}_{n},\\pmb{\\chi}(\\mathbf{a})\\right>$ , where $\\pmb{\\theta}_{n}=(\\theta_{n,S}:S\\subseteq N\\log_{2}(A))\\in\\mathbb{R}^{\\mathcal{A}^{N}}$ is a vector of Fourier coefficients. ", "page_idx": 4}, {"type": "text", "text": "Without any assumptions on the nature of the interference pattern, achieving low regret is impossible since it requires estimating $\\mathcal{A}^{N}$ Fourier coefficients per unit. To overcome this fundamental challenge, we impose a natural structure on the interference pattern which assumes that the reward $r_{n}$ only depends on the the treatment assignment of a subset of $s$ units. This assumption is often observed in practice, e.g., the revenue of a good does not depend on discounts applied to all other goods, but only those applied to similar or related ones. ", "page_idx": 4}, {"type": "text", "text": "Assumption 2. (Sparse Network Interference) For any unit $n\\in[N]$ , there exists a neighborhood $\\mathcal{N}(n)\\subset[N]$ of size $|{\\mathcal{N}}(n)|\\leq s$ such that $r_{n}(\\mathbf{a})=r_{n}(\\mathbf{b})$ for all $\\dot{\\mathbf{a}},\\dot{\\mathbf{b}}\\in\\{-1,1\\}^{N\\log_{2}\\mathcal{A}}$ satisfying $(a_{m}:m\\,\\Bar{\\in}\\,\\Bar{N}(n))=(b_{m}:m\\in N(n))$ . ", "page_idx": 4}, {"type": "text", "text": "We typically assume that $n\\in\\mathcal{N}(n)$ , i.e. unit $n$ \u2019s reward depends on its own treatment. This model allows for completely arbitrary interference between these $s$ units, generalizing the results of Jia et al. [2024] who allow for interaction between all $N$ units but assume the strength of interference decays with a particular notion of distance between units. Next, we show using our Fourier analytic tools, that Assumption 2 implies that the reward can be re-expressed as a sparse linear model. We prove the following in Appendix A. ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.1. Let Assumption 2 hold. Then, for any unit $n$ , and action a $\\mathbf{\\Psi}_{1}\\in[\\mathcal{A}]^{N}$ , we have the following representation of the reward $r_{n}(\\mathbf{a})=\\langle\\pmb{\\theta}_{n},x(\\mathbf{a})\\rangle$ , where $\\|\\pmb{\\theta}_{n}\\|_{0}\\leq\\mathcal{A}^{s}$ .4 ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.1 shows sparse network interference implies $\\pmb{\\theta}_{n}$ is $A^{s}$ sparse with non-zero coordinates corresponding to the interactions of treatments between units in ${\\mathcal{N}}(n)$ . Indeed, the Boolean encoding $\\mathbf{v}(a)$ can be represented as blocks of $\\log_{2}(A)$ dimensional Boolean vectors: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{v}(\\mathbf{a})=(\\underbrace{\\mathbf{v}(\\mathbf{a})_{1:\\mathrm{log}_{2}(A)}}_{\\mathrm{Unit~1:~treatment}},\\ldots,\\underbrace{\\mathbf{v}(\\mathbf{a})_{(i-1)\\log_{2}(A)+1:i\\log_{2}(A)}}_{\\mathrm{Unit~1:~treament}},\\ldots,\\underbrace{\\mathbf{v}(\\mathbf{a})_{(N-1)\\log_{2}(A)+1:N\\log_{2}(A)}}_{\\mathrm{Unit~{N\\setminus~ureatment}}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Unit $n$ \u2019s reward depends on a small collection of these blocks, those indexed by its neighbors. Define ", "page_idx": 4}, {"type": "equation", "text": "$$\nB(n):={\\Bigl\\{}i\\in[N\\log_{2}(A)]:i\\in[(m-1)\\log_{2}(A)+1:m\\log_{2}(A)]{\\mathrm{~for~some~}}m\\in N(n){\\Bigr\\}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "$B(n)$ contains the indices of $\\mathbf{v}(a)$ corresponding to treatments of units $m\\in\\mathcal{N}(n)$ and the non-zero entries of $\\pmb{\\theta}_{n}$ are indexed by subsets $S\\subset B(n)$ . E.g., consider $N=3$ , ${\\mathcal{A}}=2$ , with $\\mathcal{N}(1)=\\{1,2\\}$ . Then $B(1)=\\{1,2\\}$ and $S\\subset\\mathcal{B}(n)=\\{\\emptyset,\\{1\\},\\{2\\},\\{1,2\\}\\}$ , where $\\varnothing$ is the empty set. ", "page_idx": 4}, {"type": "text", "text": "Graphical interpretation. Assumption 2 can be interpreted graphically as follows. Let $\\mathcal{G}=([N],\\mathcal{E})$ denote a directed graph over the $N$ units, where $\\mathcal{E}\\subseteq[N]\\times[N]$ denotes the edges of $\\mathcal{G}$ . For unit $n$ , we add to the edge set $\\mathcal{E}$ a directed edge $(n,m)$ for each $m\\in{\\mathcal{N}}(n)$ , thus justifying calling ${\\mathcal{N}}(n)$ the neighborhood of $n$ . That is, unit $n$ \u2019s reward is affected by the treatment of another unit $m$ only if there is a directed edge from $n$ to $m$ . See Figure 1 for an example of a network graph $\\mathcal{G}$ . ", "page_idx": 4}, {"type": "text", "text": "4 Network Multi-Armed Bandits with Known Interference ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now present our algorithms and regret bounds when the interference pattern is known, i.e. the learner observes $\\mathcal{G}$ and knows $\\mathcal{N}(n)$ for each unit $n$ . The unknown case is analysed in Section 5. Assuming knowledge of $\\mathcal{G}$ is reasonable in e-commerce, where the platform (learner) assigning discounts (treatments) to goods (units) understands the underlying similarity between goods. ", "page_idx": 4}, {"type": "text", "text": "Our algorithm requires the following additional notation: for $\\mathbf{a}\\in[A]^{N}$ , let $\\chi^{\\mathbf{a}}(\\mathcal{B}_{n})=(\\chi_{S}(\\mathbf{a}):S\\subset$ $B(n))\\in\\{-1,1\\}^{\\mathcal{A}^{s}}$ , where $\\chi_{S}(\\mathbf{a})$ are the Fourier characteristics corresponding to subsets of $B(n)$ . Further, let $\\mathcal{U}([\\bar{A}]^{N})$ denote the uniform discrete distribution on the action space $[A]^{N}$ . ", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 Network Explore-Then-Commit with Known Interference ", "text_level": 1, "page_idx": 5}, {"type": "table", "img_path": "ZxZOvVOiiL/tmp/c4ed35603ac563759c98eb229eff70f2165997a91c540970f7f0dff234294b12.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Algorithm 1 is a \u201cexplore-then-commit\u201d style which operates in two phases. First, the learner assigns units treatments uniformly at random for $E$ rounds, and observes rewards for each unit. In the second phase, the algorithm performs least squares regressions of the observed rewards against $x^{\\mathbf{a}}(B_{n})$ for each unit $n$ . This is because when $\\mathcal{G}$ is known, the learner knows the positions of the non-zero elements of $\\pmb{\\theta}_{n}$ which are precisely the subsets of $B(n)$ , Once the estimates $\\widehat{\\pmb{\\theta}}_{n}$ are obtained for each unit, they are aggregated to estimate the average reward for each action $\\mathbf{a}\\in[A]^{N}$ . In the remaining $T-E$ rounds, the learner greedily plays the action with the highest estimated average reward. ", "page_idx": 5}, {"type": "text", "text": "Determining exploration length $E$ . Theoretically, we detail the length of $E$ below to achieve low regret in Theorem 4.1. Practically, the learner can continue to explore and assess the error of the learnt $\\widehat{\\pmb{\\theta}}_{n}$ via cross-validation (CV). Once the CV error for all units falls below a (user-specified) thresh old, commit to the action with highest average reward. We use this approach for selecting $E$ in our simulations in Section 6. ", "page_idx": 5}, {"type": "text", "text": "4.1 Regret Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Here, we establish high-probability regret bounds of Algorithm 1 using $O(\\cdot)$ notation. We prove the following in Appendix B. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4.1. Suppose Assumptions $^{\\,l}$ and 2 hold. For $T=\\Omega\\left(A^{2s}[\\log(2N/\\delta)+s\\log(A)]\\right)$ and any failure probability \u03b4 \u2208(0, 1), Algorithm 1 run with E := (TAs)2/3  log N\u03b4 + s log (A) 1/3 satisfies ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}=O\\left(\\left[s\\log(A/\\delta)\\right]^{1/3}(T A^{s})^{2/3}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "with probability at least $1-\\delta$ . ", "page_idx": 5}, {"type": "text", "text": "Establishing Theorem 4.1 requires trading-off the exploration time $E$ to accurately estimate $\\pmb{\\theta}_{n}$ with the exploitation time. It also requires $T$ to be large enough such that we can accurately estimate $\\pmb{\\theta}_{n}$ . Next, we compare regret of Algorithm 1 to other methods, ignoring any dependencies on logarithmic factors to ease the discussion. ", "page_idx": 5}, {"type": "text", "text": "Comparison to other approaches. ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "(a) Na\u00efve MAB learner. A na\u00efve learner who treats the entire \u221anetwork of units as a single multiarmed bandit system with $\\mathcal{A}^{N}$ actions will obtain regret $\\widetilde{\\cal O}(\\sqrt{T A^{N}})$ . For sparse networks with $s\\ll N$ and $T\\ll A^{N}$ , our regret bound is significantly tighter. ", "page_idx": 5}, {"type": "text", "text": "(b) Global estimation. An alternate algorithm would be to estimate Fourier coefficients $\\pmb\\theta:=$ $1/N\\sum_{i=1}^{N}\\pmb{\\theta}_{n}$ of $\\bar{r}$ directly rather than estimate each $\\pmb{\\theta}_{n}$ (i.e., $r_{n}$ ) individually. That is, perform the least squares regression by compressing the observed, unit-specific rewards into $\\overline{{R}}_{t}\\,:=$ $\\begin{array}{r}{N^{-1}\\sum_{n=1}^{N}R_{t n}}\\end{array}$ . An analysis similar to the one presented in Appendix B would yield rate of $\\widetilde{\\cal O}(s^{1/3}(T N{\\cal A}^{s})^{2/3})$ , which suffers an additional $N^{2/3}$ cost as compared to Theorem 4.1. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "(c) Jia et al. $[2024]$ . Comparing regret to this work is difficult because they assume decaying interference strength on a grid-like network structure and establish regret only with respect to the best constant action, i.e., $\\mathbf{a}^{\\prime}:=\\arg\\operatorname*{max}_{a\\in[A]}\\bar{r}(a\\mathbf{1})$ . We also note that the framework of Jia et al. [2024] is closer to that of adversarial bandits, whereas our framework is closer to that of stochastic bandits. ", "page_idx": 6}, {"type": "text", "text": "5 Network Multi-Armed Bandits with Unknown Interference ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Next, we consider the case in which the underlying network $\\mathcal{G}$ governing interference is not known. We present Algorithm 2, which extends Algorithm 1 to account for the fact that the learner does not observe the network graph $\\mathcal{G}$ and thus does not know ${\\mathcal{N}}(n)$ for all $n$ . Unknown network interference is common in medical trials, e.g., vaccine roll-outs where an individual\u2019s social network (i.e., $\\mathcal{G}$ ) is unavailable to the learner. ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 Network Explore-Then-Commit with Unknown Interference ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "1: Input: Time horizon $T$ , exploration steps $E$ , regularization parameter $\\lambda>0$   \n2: Sample $\\mathbf{a}_{1},\\ldots,\\mathbf{a}_{E}\\sim_{\\mathrm{i.i.d.}}\\mathcal{U}\\left([A]^{N}\\right)$   \n3: Observe reward vectors $\\mathbf{R}_{t}=\\left(R_{1t},\\cdot\\cdot\\cdot,R_{N t}\\right)$ for $t\\in[E]$ , where $R_{n t}=\\langle\\pmb{\\theta}_{n},\\pmb{\\chi}(\\mathbf{a}_{t})\\rangle+\\epsilon_{n t}$ .   \n4: Let $\\mathbf{X}=(\\chi(\\mathbf{a}_{i}):i\\in[E])\\in\\{-1,1\\}^{E\\times A^{N}}$   \n5: for $n\\in[N]$ do   \n6: Let $\\mathbf{Y}_{n}:=(R_{n1},...,R_{n E})$ .   \n7: Set $\\begin{array}{r}{\\widehat{\\pmb{\\theta}}_{n}:=\\arg\\operatorname*{min}_{\\pmb{\\theta}\\in\\mathbb{R}^{A^{N}}}\\left\\{\\frac{1}{2E}\\|\\mathbf{X}\\pmb{\\theta}-\\mathbf{Y}_{n}\\|_{2}^{2}+\\lambda\\|\\pmb{\\theta}\\|_{1}\\right\\}}\\end{array}$   \n8: Set $\\begin{array}{r}{\\widehat{\\pmb{\\theta}}:=N^{-1}\\sum_{n=1}^{N}\\widehat{\\pmb{\\theta}}_{n}}\\end{array}$ .R   \n9: Play $\\widehat{\\mathbf{a}}:=\\arg\\operatorname*{max}_{\\mathbf{a}\\in[A]^{N}}\\langle\\widehat{\\pmb{\\theta}},\\chi(\\mathbf{a})\\rangle$ for the $T-E$ remaining rounds. ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 is similar to Algorithm 1, but differs in how it learns $\\pmb{\\theta}_{n}$ . Since $\\mathcal{G}$ is unknown, the learner cannot identify the Fourier characteristics which correspond to the non-zero elements of $\\pmb{\\theta}_{n}$ . Therefore, we regress against the entire Fourier characteristic $x(\\mathbf{a})$ , using Lasso instead of ordinary least squares to adapt to the underlying sparsity of $\\pmb{\\theta}_{n}$ . A similar CV approach, as discussed after Algorithm 1, can be used to determine both the exploration length $E$ , and regularization parameter $\\lambda$ . ", "page_idx": 6}, {"type": "text", "text": "Low-order interactions. When $\\mathcal{A}^{N}$ is very large, the computational cost of running the Lasso can be large. Further, if the underlying network is indeed believed to be sparse, one can regress against all characteristics $\\chi_{S}$ where $|S|\\leq d$ . A similar approach is explored in $\\mathrm{Yu}$ et al. [2022]. In practice, one can choose degree $d$ via CV. ", "page_idx": 6}, {"type": "text", "text": "Partially observed network graph $\\mathcal{G}$ . In many settings, network interference graphs $\\mathcal{G}$ are partially observed. For example, on e-commerce platforms, interference patterns between established classes of goods is well-understood, but might be less so for newer products. Our framework can naturally be adapted to this setting by running Algorithm 1 on the observed portion of $\\mathcal{G}$ , and Algorithm 2 on the unobserved graph. Specifically, if $\\bar{N}(n)$ is observed for unit $n$ , replace the Lasso in line 7 of Algorithm 2 with OLS (i.e., line 8) in Algorithm 1. ", "page_idx": 6}, {"type": "text", "text": "5.1 Regret Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now establish high-probability bounds on the regret for Algorithm 2 in Theorem 5.1. We prove the following in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5.1. Suppose Assumptions $^{\\,l}$ and 2 hold, and assume $T=\\Omega(A^{2s}\\left[\\log(N/\\delta)+N\\log(A)\\right])$ . Then, with failure probability $\\delta{\\mathrm{~\\rightleftarrow~}}\\left(0,1\\right)$ , Algorithm 2 run with $\\lambda~=~4\\sqrt{{\\cal E}^{-1}\\log(2{\\cal A}^{N})}~+$ $\\begin{array}{r}{4\\sqrt{E^{-1}\\log\\left(\\frac{2N}{\\delta}\\right)}}\\end{array}$ where $\\begin{array}{r}{E:=(T\\mathcal{A}^{s})^{2/3}\\left[\\log\\left(\\frac{N}{\\delta}\\right)+N\\log(\\mathcal{A})\\right]^{1/3}}\\end{array}$ satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}=O\\left(\\left[N\\log(A/\\delta)\\right]^{1/3}(T\\mathcal{A}^{s})^{2/3}\\right)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We note the regret bound requires the horizon $T$ to be sufficiently large in order to learn the network graph $\\mathcal{G}$ \u2014 a necessary detail in order to ensure Lasso convergence. This is because the proof of Theorem 5.1 requires establishing that the matrix of Fourier coefficients for the sampled actions (i.e., design matrix $\\mathbf{X}$ ) satisfies the the necessary regularity conditions to learn $\\pmb{\\theta}_{n}$ accurately. Specifically, we show that $\\mathbf{X}$ is incoherent, i.e., approximately orthogonal, with high probability. See Appendix $\\mathbf{C}$ for a formal definition of incoherence, and Rigollet and H\u00fctter [2023], Wainwright [2019] for a detailed study of the Lasso. ", "page_idx": 7}, {"type": "text", "text": "Comparison to other approaches. Algorithm 2 achieves the same dependence in $A,s,T$ as in the known interference case, but pays a factor of $N^{1/3}$ as compared to $s^{1/{\\bar{3}}}$ . This additional cost which is logarithmic in the ambient dimension $\\mathcal{A}^{N}$ is typical in spar\u221ase online learning. This regret rate is still significantly lower than na\u00efve approaches that scale as $O(\\sqrt{\\mathcal{A}^{N}T})$ when one assumes $T$ is much smaller then $\\dot{\\mathcal{A}^{N}}$ . Further, as argued before, estimating per-unit rewards (i.e., $\\pmb{\\theta}_{n}$ ) results in lower regret as compared to directly estimating $\\bar{r}$ by a factor of $\\bar{N}^{2/3}$ . ", "page_idx": 7}, {"type": "text", "text": "Dependence on horizon $T$ . Generally, the dependence on $T$ cannot be improved. Hao et al. [2020] lower bound regret for sparse linear bandits as $\\widetilde\\Omega((\\mathrm{sparsity}\\!\\cdot\\!T)^{2/3})$ , i.e., $\\widetilde\\Omega((A^{s}\\cdot T)^{2/3})$ in our setting. They show improved dependence on $T$ can only be achieved under stronger assumptions on the size of non-zero coefficients of $\\theta_{n}$ . ", "page_idx": 7}, {"type": "text", "text": "6 Simulations ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we perform simulations to empirically validate our algorithms and theoretical findings. We compare Algorithms 1 and 2 to UCB. We could not compare to Jia et al. [2024] since we did not find a public implementation. For our Algorithms, we choose all hyper-parameters via 3-fold CV, and use the scikit-learn implementation of the Lasso. Code for our methods and experiments can be found at https://github.com/aagarwal1996/NetworkMAB. Our experimental setup and results are described below. ", "page_idx": 7}, {"type": "text", "text": "Data Generating Process. We generate interference patterns with varying number of units $N\\in$ $\\{5,\\ldots,10\\}$ , and ${\\mathcal{A}}=2$ . For each $N$ , we use $s=4$ . We generate rewards $r_{n}=\\langle\\pmb{\\theta}_{n},\\pmb{\\chi}(\\mathbf{a})\\rangle$ , where the non-zero elements of $\\pmb{\\theta}_{n}$ (i.e., $\\theta_{n,S}$ for $S\\subset B_{n},$ ) are drawn uniform from [0, 1]. We normalize rewards so that they are contained in $[0,1]$ , and add 1 sub-gaussian noise to sampled rewards. We measure regret as we vary $T$ , and set a max horizon of $T_{\\mathrm{max}}=10\\cdot2^{N}$ for each $N$ . Classical MAB algorithms need the horizon $T$ to satisfy $T>2^{N}$ since they first explore by pulling all $2^{N}$ arms. We emphasize that these time horizons scaling as $T=C\\cdot\\dot{A}^{N}$ are often unreasonable in practice, as even for ${\\mathcal{A}}=2$ and $N=100$ there would already be $\\approx1.27\\mathrm{e^{30}}$ actions to explore. We include such large time horizons for the sake of making a complete comparison. Our methods circumvent the need for exponentially large exploration times by effectively exploiting sparsity. ", "page_idx": 7}, {"type": "text", "text": "Results. We plot the regret at the maximum horizon time as a function of $N$ , and the cumulative regret as we vary $T$ for $N=13$ in Figure 2 below. Our results are averaged over 5 repetitions, with shaded regions representing 1 standard deviation measured across repetitions. Algorithms 1 and 2 are denoted by Network MAB (Known) and Network MAB (Unknown) respectively. We discuss both sets of plot separately below. ", "page_idx": 7}, {"type": "text", "text": "Regret Scaling with $N$ . We plot the cumulative regret when $T=T_{\\mathrm{max}}$ for $N=9$ in Figure 2 (a). Classical MAB algorithms such as UCB see an exponential growth in the regret as $N$ increases. Both Algorithm 1 and Algorithm 2 have much milder scaling with $N$ . Algorithm 1 uses $\\mathcal{G}$ to reduce the ambient dimension of the regression, hence suffering less dependence on $N$ as compared to Algorithm 2. ", "page_idx": 7}, {"type": "text", "text": "Regret Scaling with $T$ . We plot the cumulative regret for $N=9$ in Figure 2 (b). Despite the poorer scaling of our regret bounds with $T$ , our algorithms lead to significantly better regret than UCB which takes a large horizon to converge. Algorithm 1 is able to end its exploration phase earlier than algorithm 2 since it does not need additional samples to learn the sparsity unlike the Lasso. ", "page_idx": 7}, {"type": "image", "img_path": "ZxZOvVOiiL/tmp/91b45bf087720e6adf5e0d74ac00c5a435c6069ab6b0fe475a4857e809c74a42.jpg", "img_caption": ["Figure 2: We simulate rewards via a sparse network interference pattern, and plot the cumulative regret as a function of $N$ and $T$ . Our Network MAB algorithms out-perform UCB, irrespective of knowledge of $\\mathcal{G}$ , and does not suffer exponential dependence in number of units $N$ . The results also confirm our theoretical results that knowledge of $\\mathcal{G}$ leads Algorithm 1 to have milder dependence in $N$ and better regret than Algorithm 2. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "ZxZOvVOiiL/tmp/fefc729c9bf442cb3d3d7d17a215ab5c63dca5e13a2894a97dc6a716b1a6796f.jpg", "img_caption": ["(b) Cumulative regret scaling vs horizon $T$ . "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This paper introduces a framework for regret minimization in MABs with network interference, a ubiquitous problem in practice. We study this problem under a natural sparsity assumption on the interference pattern and provide simple algorithms both when the network graph is known and unknown. Our analysis establishes low regret for these algorithms and numerical simulations corroborate our theoretical findings. The results in this paper also significantly generalize previous works on MABs with network interference by allowing for arbitrary and unknown (neighbourhood) interference, as well as comparing to a combinatorially more difficult optimal policy. This paper also suggests future directions for research such as designing algorithms that achieve better dependence on $T$ in the known graph setting. Establishing lower bounds to understand optimal algorithms will also be valuable future work. Further extensions could also include considering interference in contextual bandits or reinforcement learning problems. We also hope this work serves as a bridge between online learning and discrete Fourier analysis. ", "page_idx": 8}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Online-to-confidence-set conversions and application to sparse stochastic bandits. In Artificial Intelligence and Statistics, pages 1\u20139. PMLR, 2012. ", "page_idx": 8}, {"type": "text", "text": "Abhineet Agarwal, Anish Agarwal, and Suhas Vijaykumar. Synthetic combinations: A causal inference framework for combinatorial interventions. Advances in Neural Information Processing Systems, 36:19195\u201319216, 2023. ", "page_idx": 8}, {"type": "text", "text": "Anish Agarwal, Sarah H Cen, Devavrat Shah, and Christina Lee Yu. Network synthetic interventions: A causal framework for panel data under network interference. arXiv preprint arXiv:2210.11355, 2022. ", "page_idx": 8}, {"type": "text", "text": "Peter M Aronow. A general method for detecting interference between units in randomized experiments. Sociological Methods & Research, 41(1):3\u201316, 2012. ", "page_idx": 8}, {"type": "text", "text": "Peter M. Aronow and Cyrus Samii. Estimating average causal effects under general interference, with application to a social network experiment. The Annals of Applied Statistics, 11(4):1912 \u2013 1947, 2017. doi: 10.1214/16-AOAS1005. URL https://doi.org/10.1214/16-AOAS1005. ", "page_idx": 8}, {"type": "text", "text": "Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47:235\u2013256, 2002. ", "page_idx": 8}, {"type": "text", "text": "Patrick Bajari, Brian Burdick, Guido W Imbens, Lorenzo Masoero, James McQueen, Thomas Richardson, and Ido M Rosen. Multiple randomization designs. arXiv preprint arXiv:2112.13495, 2021. ", "page_idx": 8}, {"type": "text", "text": "Patrick Bajari, Brian Burdick, Guido W Imbens, Lorenzo Masoero, James McQueen, Thomas S Richardson, and Ido M Rosen. Experimental design in marketplaces. Statistical Science, 38(3): 458\u2013476, 2023.   \nRohit Bhattacharya, Daniel Malinsky, and Ilya Shpitser. Causal inference under interference and network uncertainty. In Uncertainty in Artificial Intelligence, pages 1028\u20131038. PMLR, 2020.   \nSarah Huiyi Cen, Anish Agarwal, Christina Yu, and Devavrat Shah. A causal inference framework for network interference with panel data. In NeurIPS 2022 Workshop on Causality for Real-world Impact, 2022.   \nNicolo Cesa-Bianchi and G\u00e1bor Lugosi. Combinatorial bandits. Journal of Computer and System Sciences, 78(5):1404\u20131422, 2012.   \nWei Chen, Yajun Wang, and Yang Yuan. Combinatorial multi-armed bandit: General framework and applications. In International conference on machine learning, pages 151\u2013159. PMLR, 2013.   \nSayak Ray Chowdhury and Aditya Gopalan. On kernelized multi-armed bandits. In International Conference on Machine Learning, pages 844\u2013853. PMLR, 2017.   \nAudrey Durand, Charis Achilleos, Demetris Iacovides, Katerina Strati, Georgios D Mitsis, and Joelle Pineau. Contextual bandits for adapting treatment in a mouse model of de novo carcinogenesis. In Machine Learning for Healthcare Conference, pages 67\u201382. PMLR, 2018.   \nMengsi Gao and Peng Ding. Causal inference in network experiments: regression-based analysis and design-based properties, 2023.   \nBotao Hao, Tor Lattimore, and Mengdi Wang. High-dimensional sparse linear bandits. Advances in Neural Information Processing Systems, 33:10753\u201310763, 2020.   \nMichael G Hudgens and M Elizabeth Halloran. Toward causal inference with interference. Journal of the American Statistical Association, 103(482):832\u2013842, 2008.   \nSu Jia, Peter Frazier, and Nathan Kallus. Multi-armed bandits with interference. arXiv preprint arXiv:2402.01845, 2024.   \nJoon Kwon, Vianney Perchet, and Claire Vernade. Sparse stochastic bandits. arXiv preprint arXiv:1706.01383, 2017.   \nTor Lattimore and Csaba Szepesv\u00e1ri. Bandit algorithms. Cambridge University Press, 2020.   \nShuai Li, Alexandros Karatzoglou, and Claudio Gentile. Collaborative filtering bandits. In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 539\u2013548, 2016.   \nSahand Negahban and Devavrat Shah. Learning sparse boolean polynomials. In 2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 2032\u20132036. IEEE, 2012.   \nRyan O\u2019Donnell. Analysis of boolean functions. Cambridge University Press, 2014.   \nJean Pouget-Abadie, Kevin Aydin, Warren Schudy, Kay Brodersen, and Vahab Mirrokni. Variance reduction in bipartite experiments through correlation clustering. Advances in Neural Information Processing Systems, 32, 2019.   \nPhilippe Rigollet and Jan-Christian H\u00fctter. High-dimensional statistics. arXiv preprint arXiv:2310.19244, 2023.   \nPaul R Rosenbaum. Interference between units in randomized experiments. Journal of the American Statistical Association, 102(477):191\u2013200, 2007.   \nDonald B Rubin. Bayesian inference for causal effects: The role of randomization. The Annals of statistics, pages 34\u201358, 1978.   \nNiranjan Srinivas, Andreas Krause, Sham M Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. arXiv preprint arXiv:0912.3995, 2009.   \nJohan Ugander, Brian Karrer, Lars Backstrom, and Jon Kleinberg. Graph cluster randomization: Network exposure to multiple universes. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 329\u2013337, 2013.   \nRoman Vershynin. High-dimensional probability: An introduction with applications in data science, volume 47. Cambridge university press, 2018.   \nMartin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cambridge university press, 2019.   \nJustin Whitehouse, Aaditya Ramdas, and Steven Z Wu. On the sublinear regret of GP-UCB. Advances in Neural Information Processing Systems, 36, 2024.   \nChristina Lee Yu, Edoardo M Airoldi, Christian Borgs, and Jennifer T Chayes. Estimating the total treatment effect in randomized experiments with unknown network structure. Proceedings of the National Academy of Sciences, 119(44):e2208975119, 2022. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "A Proof of Proposition 3.1 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "By the discussion in Section 3, recall that for any action $\\mathbf{a}\\in[A]^{N}$ and unit $n$ , the reward can be expressed as $r_{n}=\\langle\\pmb{\\theta}_{n},\\pmb{\\chi}(\\mathbf{a})\\rangle$ . To establish the proof, it suffices to show that for any $S\\subset[N\\log_{2}(A)]$ satisfying $S\\setminus B(n)\\neq\\emptyset$ , $\\langle\\chi_{S},r_{n}\\rangle_{B}=0$ . Let $i\\in S\\setminus B(n)$ be an arbitrary index, then, we have, ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle x,x,r_{n}\\rangle_{B}=\\mathcal{A}^{-N}\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}\\times\\mathbb{R}_{n}\\in\\mathbb{Z}\\backslash\\mathbf{X}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\\\ &{=\\mathcal{A}^{-N}\\left\\{\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}\\times\\mathbb{R}_{n}\\in\\mathbb{Z}\\backslash\\mathbf{X}}(\\mathbf{x})\\chi_{S}(\\mathbf{x})+\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}\\times\\mathbb{R}_{n}\\in\\mathbb{Z}\\backslash\\mathbf{X}}\\right\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\mathcal{E}(\\mathbf{1}_{2}^{-1}\\mathbf{1}_{S}^{-1})}\\\\ &{=\\mathcal{A}^{-N}\\left\\{\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}\\times\\mathbb{R}_{n}\\in\\mathbb{Z}\\backslash\\mathbf{X}}\\mathbb{r}_{S\\backslash\\mathbf{X}}(\\mathbf{x})\\chi_{S\\backslash\\mathbf{Y}}(\\mathbf{x})+\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}\\times\\mathbb{R}_{n}\\in\\mathbb{Z}\\backslash\\mathbf{X}}\\mathbb{r}_{S\\backslash\\mathbf{Y}}(\\mathbf{x})\\right\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\mathcal{E}(\\mathbf{1}_{2}^{-1}\\mathbf{1}_{S}^{-1})}\\\\ &{=\\mathcal{A}^{-N}\\left\\{\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}\\times\\mathbb{R}_{n}\\in\\mathbb{Z}\\backslash\\mathbf{X}}(\\mathbf{x})\\chi_{S\\backslash\\mathbf{Y}}(\\mathbf{i})(\\mathbf{x})-\\sum_{\\mathbf{x}\\in\\{-1,1\\}^{N}\\times\\mathbb{R}_{n}\\in\\mathbb{Z}\\backslash\\mathbf{X}}\\mathbb{r}_{S\\backslash\\mathbf{Y}}(\\mathbf{x})\\right\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\mathbb{C}(\\mathbf{1}_{2}^{-1},\\mathbf{x})=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "where the final equality follows from the fact that, by Assumption 2, $r_{n}(\\mathbf{x})=r_{n}(\\mathbf{x}^{\\prime})$ when $\\mathbf{x}$ and $\\mathbf{x}^{\\prime}$ differ only in positions indexed by $i\\not\\in\\mathcal{B}(n)$ . Thus, the only subsets $S\\subset[N\\log_{2}(A)]$ where we can have $\\langle r_{n},\\chi_{S}\\rangle_{B}\\neq0$ are those satisfying $S\\subset B(n)$ , which proves the desired result. ", "page_idx": 11}, {"type": "text", "text": "B Proofs for for Known Interference ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "In this section, we prove Theorem 4.1. We establish helper lemmas before proving Theorem 4.1. ", "page_idx": 11}, {"type": "text", "text": "B.1 Helper Lemmas ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Recall the following notation before establishing our results. We defined $B(n):=\\{i\\in[N\\log_{2}(A)]:$ $i\\,\\in\\,[(m\\,-\\,1)\\,\\mathrm{log}_{2}^{\\phantom{\\,}}(A)\\,+\\,1\\,:\\,m\\,\\mathrm{log}_{2}(A)]$ for $\\bar{m}\\,\\in\\,\\mathcal{N}(n)\\}$ as the set of indices of the treatment vector $\\mathbf{v}(a)\\in\\{-1,1\\}^{N\\log_{2}(A)}$ belonging to neighbors $m\\in\\mathcal{N}(n)$ . Additionally, ${\\bf X}_{n}=({\\boldsymbol{\\chi}}^{\\mathbf{a}_{i}}({\\boldsymbol{B}}_{n}):$ $i\\,\\in\\,[E])\\,\\in\\,\\{-1,1\\}^{E\\times A^{s}}$ , where $\\chi^{\\mathbf{a}}({\\mathcal{B}}_{n})\\,=\\,(\\chi_{S}(\\mathbf{a})\\,:\\,S\\,\\subset\\,{\\mathcal{B}}(n))\\,\\in\\,\\{-1,1\\}^{\\mathcal{A}^{s}}$ . For a matrix $\\mathbf{A}\\in\\mathbb{R}^{N\\times d}$ , let $\\sigma_{\\mathrm{min}}(\\mathbf{A})$ denote its minimum singular value. To proceed, we quote the following theorem. ", "page_idx": 11}, {"type": "text", "text": "Lemma B.1 (Theorem 5.41 in Vershynin [2018]). Let $\\textbf{A}\\in\\,\\mathbb{R}^{N\\times d}$ such that its rows $\\mathbf{A}_{i}$ are independent isotropic random vectors in $\\mathbb{R}^{d}$ . If $\\|\\mathbf{A}_{i}\\|_{2}\\leq\\sqrt{m}$ almost surely for all $i\\in[N]$ , then, with probability at least $1-\\delta$ , one has ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\sigma_{\\mathrm{min}}(\\mathbf{A})\\geq\\sqrt{N}-\\sqrt{c m\\log(2d/\\delta)}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "for universal constant $c>0$ . ", "page_idx": 11}, {"type": "text", "text": "Lemma B.2 (Minimum Eigenvalue of Fourier Characteristics). There exists a positive constant $C_{4}>0$ such that if $E\\ge C_{4}A^{s}\\log(2{\\cal A}^{s}/\\delta)$ , then, ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\sigma_{\\mathrm{min}}\\left(\\frac{\\mathbf{X}_{n}^{T}\\mathbf{X}_{n}}{E}\\right)\\geq\\frac{1}{2},\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "with probability at least $1-\\delta$ . ", "page_idx": 11}, {"type": "text", "text": "Proof. We begin by showing the conditions for Lemma B.1 are satisfied. First, we prove $\\mathbf{X}_{n}$ is isotropic, i.e., $\\vec{\\mathbb{E}}[\\pmb{\\chi}^{\\mathbf{a}}(\\mathcal{B}_{n})\\,\\bar{(\\pmb{\\chi}^{\\mathbf{a}}(\\mathcal{B}_{n}))}^{T}]\\,=\\,\\mathbf{I}_{\\mathcal{A}^{s}}$ , where the expectation is taken over uniformly ", "page_idx": 11}, {"type": "text", "text": "sampling actions a uniformly and random from $[A]^{N}$ . This follows since for any two subsets $S,\\dot{S^{\\prime}}\\subset\\bar{[N\\log_{2}(A)]}$ , ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}[\\chi_{S}(\\mathbf{a})\\chi_{S^{\\prime}}(\\mathbf{a})]=\\frac{1}{\\mathcal{A}^{N}}\\sum_{\\mathbf{a}\\in\\mathcal{A}^{N}}\\chi_{S}(\\mathbf{a})\\chi_{S^{\\prime}}(\\mathbf{a})}}\\\\ &{}&{=\\langle\\chi_{S},\\chi_{S^{\\prime}}\\rangle_{B}=\\mathbb{1}[S=S^{\\prime}]}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since, $\\chi^{\\mathbf{a}}(B_{n})\\in\\{-1,1\\}^{\\mathcal{A}^{s}}$ for all actions $\\mathbf{a}\\in[A]^{N}$ , $\\|\\pmb{\\chi}^{\\mathbf{a}}(\\pmb{B}_{n})\\|_{2}\\leq\\sqrt{\\pmb{A}^{s}}$ . Hence, by Lemma B.1, $\\sigma_{\\mathrm{min}}(\\mathbf{X}_{n})\\geq{\\sqrt{E}}-{\\sqrt{c\\log(2{A^{s}}/\\delta){A^{s}}}}$ . Next, using the fact that $\\sigma_{\\mathrm{min}}({\\bf X}_{n}^{T}{\\bf X}_{n})=\\sigma_{\\mathrm{min}}^{2}({\\bf X}_{n})$ , we get that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sigma_{\\mathrm{min}}\\left(\\frac{\\mathbf{X}_{n}^{T}\\mathbf{X}_{n}}{E}\\right)\\geq\\frac{E-2\\sqrt{c E\\mathcal{A}^{s}\\log(2\\mathcal{A}^{s}/\\delta)}}{E}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Finally, plugging in $A^{s}\\log(2\\mathcal{A}^{s}/\\delta)\\leq E/C$ for an appropriate $C$ gives us the claimed result. ", "page_idx": 12}, {"type": "text", "text": "We quote the following theorem regarding the $\\Vert\\cdot\\Vert_{2}$ error of $\\widehat{\\pmb{\\theta}}_{n}$ ", "page_idx": 12}, {"type": "text", "text": "Lemma B.3. [Theorem 2.2 in Rigollet and H\u00fctter [2023]] Assume that $\\mathbf{Y}=\\mathbf{X}\\pmb{\\theta}^{*}+\\epsilon,$ , where \u03f5 is 1 sub-Gaussian, where $\\mathbf{X}\\in\\mathbb{R}^{E\\times\\tilde{d}}$ . If $d\\leq E$ , and covariance matrix $\\pmb{\\Sigma}_{X}=(\\mathbf{X}^{T}\\mathbf{X})/E$ has rank $d_{\\cdot}$ , then we have with probability at least $1-\\delta$ , ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\|\\mathbf{X}\\pmb{\\theta}^{*}-\\mathbf{X}\\widehat{\\pmb{\\theta}}\\|_{2}\\leq C_{1}\\sqrt{\\frac{d+\\log(1/\\delta)}{E}},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\begin{array}{r}{\\widehat{\\pmb{\\theta}}=\\arg\\operatorname*{min}_{\\pmb{\\theta}\\in\\mathbb{R}^{d}}\\|\\mathbf{Y}-\\mathbf{X}\\pmb{\\theta}\\|_{2}^{2}}\\end{array}$ is the least squares estimator, and $C_{1}>0$ is a positive universal constant. ", "page_idx": 12}, {"type": "text", "text": "While the above lemma bounds the mean-squared error the least-squares estimate, in our applications we can about bounding the $\\ell_{2}$ distance between $\\theta^{*}$ and $\\widehat{\\pmb{\\theta}}$ . Simple rearrangement on the above implies that, with probability at least $1-\\delta$ , we actually have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\|\\theta^{*}-\\widehat\\theta\\|_{2}\\leq C_{1}\\sqrt{\\frac{d+\\log(1/\\delta)}{E\\cdot\\sigma_{\\operatorname*{min}}(\\Sigma_{X})}}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "If, in particular, $\\sigma_{\\mathrm{min}}\\left(\\frac{\\mathbf{x}^{\\top}\\mathbf{x}}{E}\\right)\\geq1/2$ , the above can be simplified to ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\|\\theta^{*}-\\widehat{\\theta}\\|_{2}\\leq C_{2}\\sqrt{\\frac{d+\\log(1/\\delta)}{E}}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "with probability at least $1-\\delta$ for some new, appropriate universal constant $C_{2}>0$ . ", "page_idx": 12}, {"type": "text", "text": "B.2 Proof of Theorem 4.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof. Recall the notation $\\begin{array}{r}{\\widehat{\\pmb{\\theta}}=N^{-1}\\sum_{n=1}^{N}\\widehat{\\pmb{\\theta}}_{n}}\\end{array}$ , and $\\widehat{\\mathbf{a}}=\\arg\\operatorname*{max}_{\\mathbf{a}\\in[A]^{N}}\\langle\\widehat{\\pmb{\\theta}},\\chi(\\mathbf{a})\\rangle$ . The average reward ${\\overline{{r}}}({\\widehat{\\mathbf{a}}})$ can be bounded using the definiti on of $\\widehat{\\mathbf{a}}$ and Holder\u2019s inequality as follows, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\gamma(\\mathbf{a}^{*})-\\bar{r}(\\widehat{\\mathbf{a}})=\\langle\\theta,x(\\mathbf{a}^{*})-x(\\widehat{\\mathbf{a}})\\rangle}&{}\\\\ {=\\langle\\theta-\\widehat{\\theta},X(\\mathbf{a}^{*})-X(\\widehat{\\mathbf{a}})\\rangle+\\underbrace{\\langle\\widehat{\\theta},X(\\mathbf{a}^{*})-X(\\widehat{\\mathbf{a}})\\rangle}_{\\le0}}\\\\ {\\ }&{\\ }\\\\ {\\le\\langle\\theta-\\widehat{\\theta},X(\\mathbf{a}^{*})-X(\\widehat{\\mathbf{a}})\\rangle}\\\\ {\\ }&{=\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}\\theta_{n}-\\widehat{\\theta}_{n},X(\\mathbf{a}^{*})-X(\\widehat{\\mathbf{a}})\\rangle}\\\\ {\\ }&{=\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}(\\theta_{n}-\\widehat{\\theta}_{n},X^{\\mathbf{a}^{*}}(B_{n})-X^{\\widehat{\\mathbf{a}}}(B_{n}))}\\\\ {\\ }&{\\leq\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}|\\theta_{n}-\\widehat{\\theta}_{n}|_{2}|\\mathbf{1}\\chi^{\\mathbf{a}^{*}}(B_{n})-X^{\\widehat{\\mathbf{a}}}(B_{n})|_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Using $\\|\\pmb{\\chi}^{\\mathbf{a}}(\\pmb{\\mathcal{B}}_{n})\\|_{2}\\leq\\sqrt{\\pmb{\\mathcal{A}}^{s}}$ then gives us ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\overline{r}(\\mathbf{a}^{*})-\\overline{r}(\\widehat{\\mathbf{a}})\\leq\\frac{\\sqrt{\\mathcal{A}^{s}}}{N}\\sum_{i=1}^{N}\\|\\pmb\\theta_{n}-\\widehat{\\pmb\\theta}_{n}\\|_{2}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Next, define \u201cgood\u201d events for any unit $n\\in[N]$ as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\widetilde{x}_{n1}:=\\left\\{\\sigma_{\\operatorname*{min}}\\left(\\frac{\\mathbf{X}_{n}^{T}\\mathbf{X}_{n}}{E}\\right)\\geq\\frac{1}{2}\\right\\}\\mathrm{~and~}\\,G_{n2}:=\\left\\{\\|\\widehat{\\theta}_{n}-\\theta_{n}\\|_{2}\\leq C_{2}\\sqrt{E^{-1}\\left[A^{s}+\\log\\left(\\frac{4N A^{s}}{\\delta}\\right)\\right]}\\right\\}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\begin{array}{r l r}{C_{2}}&{{}>}&{0}\\end{array}$ is as stated above. Notice that there exists a sufficiently large universal constant $C_{3}\\mathrm{~\\ensuremath~{~>~}~0~}$ , such that $T\\ \\ \\geq\\ \\ C_{3}\\left(A^{2s}[\\log(2N/\\delta)+s\\log(A)]\\right)$ implies ${\\cal E}\\quad=$ $\\begin{array}{r}{(T\\mathcal{A}^{s})^{2/3}\\left[\\log\\left(\\frac{N}{\\delta}\\right)+s\\log\\left(\\mathcal{A}\\right)\\right]^{1/3}\\;\\geq\\;C_{4}\\mathcal{A}^{s}\\log(4N\\mathcal{A}^{s}/\\delta)}\\end{array}$ . Hence, for any given $\\boldsymbol n\\,\\in\\,[N]$ , we have via Lemma B.2 that $\\mathcal{G}_{n1}$ holds with probability $1\\,-\\,\\textstyle{\\frac{\\delta}{2N}}$ Conditioned on $\\mathcal{G}_{n1}$ , we get that $\\begin{array}{r}{\\mathbb{P}(\\mathcal{G}_{n2}|\\mathcal{G}_{1})\\geq1-\\frac{\\delta}{2N}}\\end{array}$ . Summarizing, we get that for any $n\\in[N]$ , the following holds ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\|\\widehat{\\theta}_{n}-\\theta_{n}\\|_{2}\\le C_{2}\\sqrt{E^{-1}\\left[A^{s}+\\log\\left(\\frac{4N{A^{s}}}{\\delta}\\right)\\right]}\\le C_{5}\\sqrt{E^{-1}{A^{s}}\\log\\left(\\frac{4N{A^{s}}}{\\delta}\\right)},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "with probability at least $\\begin{array}{r}{\\left(1-\\frac{\\delta}{2N}\\right)^{2}\\ge1-\\delta/N}\\end{array}$ , where $C_{5}>0$ is an appropriate constant. Taking a union bound over all $N$ units, and then substituting into (2) gives us ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\overline{{r}}(\\mathbf{a}^{*})-\\overline{{r}}(\\widehat{\\mathbf{a}})\\leq C_{5}A^{s}\\sqrt{E^{-1}\\log\\left(\\frac{4N\\mathcal{A}^{s}}{\\delta}\\right)}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Finally, using this, the cumulative regret can be upper bounded with probability $1-\\delta$ as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathrm{Reg}_{T}=\\sum_{t=1}^{T}\\left(\\bar{r}(\\mathbf{a}^{*})-\\bar{r}(\\hat{\\mathbf{a}})\\right)}\\\\ {\\displaystyle\\qquad=\\sum_{t=1}^{E}\\left(\\bar{r}(\\mathbf{a}^{*})-\\bar{r}(\\hat{\\mathbf{a}})\\right)+\\sum_{t=E+1}^{T}\\left(\\bar{r}(\\mathbf{a}^{*})-\\bar{r}(\\hat{\\mathbf{a}})\\right)}\\\\ {\\displaystyle\\qquad\\leq E+C_{5}T\\mathcal{A}^{s}\\sqrt{E^{-1}\\log\\left(\\frac{4N\\mathcal{A}^{s}}{\\delta}\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Substituting $E$ as in the theorem statement completes the proof. ", "page_idx": 13}, {"type": "text", "text": "C Proofs for Unknown Interference ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this appendix, we prove Theorem 5.1. Our proof requires the following lemmas. ", "page_idx": 13}, {"type": "text", "text": "C.1 Helper Lemmas for Theorem 5.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The first lemma we prove details the (high-probability) incoherence guarantees of the uniformly random design matrix under the Fourier basis. Recall the following notation before stating and proving our results. We denote $E$ as our exploration length, and $x(\\mathbf{a}_{t})$ as the Fourier characteristic associated with action $\\mathbf{a}_{t}\\in[A]^{N}$ . Let $\\mathbf{X}=(\\chi(\\mathbf{a}_{t}):t\\in[E])\\in\\{-1,1\\}^{E\\times{A}^{N}}$ Additionally, we require the following definition of incoherence. ", "page_idx": 13}, {"type": "text", "text": "Definition C.1. We say a matrix $\\mathbf{A}\\in\\mathbb{R}^{E\\times d}$ is $s$ -incoherent if $\\begin{array}{r}{\\|\\mathbf{A}^{\\top}\\mathbf{A}-\\mathbf{I}_{d}\\|_{\\infty}\\leq\\frac{1}{32s}}\\end{array}$ , where $\\mathbf{I}_{d}$ is the identity matrix of dimension $d$ . ", "page_idx": 13}, {"type": "text", "text": "Lemma C.2 (Incoherence of Fourier Characteristics). For $E~\\ge~1$ , suppose $\\mathbf{a}_{1},\\ldots,\\mathbf{a}_{E}$ ii\u223cd $\\mathcal{U}(\\{-1,+1\\}^{N\\log_{2}(A)})$ . Then, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left\\|\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}-I_{A^{N}}\\right\\|_{\\infty}\\leq\\sqrt{\\frac{2\\log\\left(\\frac{2A^{2N}}{\\delta}\\right)}{E}}\\right)\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\|\\mathbf{A}\\|_{\\infty}\\ =\\ \\operatorname*{max}_{i,j}\\|\\mathbf{A}_{i,j}\\|$ denotes the maximum coordinates of a matrix. Thus, if $\\textit{E}\\geq$ $4096.4^{2s}$ $\\begin{array}{r}{\\left[\\log\\left(\\frac{2}{\\delta}\\right)+2N\\log\\left(A\\right)\\right]}\\end{array}$ , $\\mathbf{X}$ is $A^{s}$ -incoherent with probability at least $1-\\delta$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. Recall that, for any $\\mathbf{a}\\in[A]^{N}$ $[A]^{N},\\chi(\\mathbf{a}):=(\\chi_{S_{1}}(\\mathbf{a}),\\dots,\\chi_{S_{\\mathcal{A}^{N}}}(\\mathbf{a}))$ , where $S_{1},\\ldots,S_{A^{N}}$ is some fixed enumeration of subsets $S\\subset[N\\log_{2}(A)]$ . Thus, each entry of $(\\mathbf{X}^{\\top}\\mathbf{X})/E$ can be viewed as being indexed by subsets $S,S^{\\prime}\\subset[\\dot{N}\\log_{2}(\\bar{A})]$ . ", "page_idx": 14}, {"type": "text", "text": "To establish (C.2), we first examine diagonal elements of $(\\mathbf{X}^{\\top}\\mathbf{X})/E$ . For $S\\subset[N\\log_{2}(A)]$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left(\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}\\right)_{S,S}=\\frac{1}{E}\\left(\\sum_{t=1}^{E}\\chi(\\mathbf{a}_{t})(\\chi(\\mathbf{a}_{t}))^{\\top}\\right)_{S,S}=\\frac{1}{E}\\sum_{t=1}^{E}\\chi_{S}(\\mathbf{a}_{t})\\chi_{S}(\\mathbf{a}_{t})=1,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the last equality follows from the fact that $(\\chi_{S}(\\mathbf{a}_{t}))^{2}=1$ . ", "page_idx": 14}, {"type": "text", "text": "Next, we consider off-diagonal elements, and bound their magnitude. Before doing so, we require the following. For subsets $S,S^{\\prime}\\subset[N\\log_{2}(A)]$ , let $S\\Delta S^{\\prime}$ denote the symmetric difference of two subsets. For any two subsets $S,S^{\\prime}\\subset[N\\log_{2}(A)]$ , the product of their Fourier characteristics is, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\chi_{S}(\\mathbf{a}_{t})\\chi_{S^{\\prime}}(\\mathbf{a}_{t})=\\left(\\prod_{i\\in S}\\mathbf{v}(\\mathbf{a}_{t})_{i}\\right)\\left(\\prod_{i^{\\prime}\\in S^{\\prime}}\\mathbf{v}(\\mathbf{a}_{t})_{i^{\\prime}}\\right)=\\prod_{i\\in S\\Delta S^{\\prime}}\\mathbf{v}(\\mathbf{a}_{t})_{i}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Using this, for any distinct subsets $S,S^{\\prime}$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left(\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}\\right)_{S,S^{\\prime}}=\\frac{1}{E}\\sum_{t=1}^{E}\\chi_{S}(\\mathbf{a}_{t})\\chi_{S^{\\prime}}(\\mathbf{a}_{t})=\\frac{1}{E}\\sum_{t=1}^{E}\\prod_{i\\in S\\Delta S^{\\prime}}\\mathbf{v}(\\mathbf{a}_{t})_{i}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $S\\neq S^{\\prime}$ , and $\\mathbf{a}_{t}\\sim\\mathcal{U}(\\{-1,1\\}^{N\\log_{2}(A)})$ , the set of random variables $\\{\\mathbf{v}(\\mathbf{a}_{t})_{i}:i\\in S\\Delta S^{\\prime}\\}$ are independent Rademacher random variables. Applying Hoeffding\u2019s inequality for $\\epsilon>0$ gives us ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left(\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}\\right)_{S,S^{\\prime}}\\geq\\epsilon\\right)\\leq2\\exp\\left(-\\frac{E\\epsilon^{2}}{2}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Applying the inequality above and taking a union bound over all $A^{2N}$ elements of $(\\mathbf{X}^{\\top}\\mathbf{X})/E$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{max}_{S,S^{\\prime}\\subset[N\\log_{2}(A)]}\\left(\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}\\right)_{S,S^{\\prime}}\\geq\\epsilon\\right)\\leq2A^{2N}\\exp\\left(-\\frac{E\\epsilon^{2}}{2}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Choosing $\\begin{array}{r}{\\epsilon=\\sqrt{2E^{-1}\\log\\left(\\frac{2.4^{2N}}{\\delta}\\right)}}\\end{array}$ yields, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{max}_{\\substack{S,S^{\\prime}\\subset[N\\log_{2}(A)]}}\\left(\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}\\right)_{S,S^{\\prime}}\\geq\\sqrt{\\frac{2\\log\\left(\\frac{2A^{2N}}{\\delta}\\right)}{E}}\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To complete the proof, observe that (3) implies that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\|\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}-I_{A^{N}}\\right\\|_{\\infty}=\\operatorname*{max}_{\\substack{S,S^{\\prime}\\subset[N\\log_{2}(A)]}}\\left(\\frac{\\mathbf{X}^{\\top}\\mathbf{X}}{E}\\right)_{S,S^{\\prime}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Substituting this observation into (4) above completes the proof. ", "page_idx": 14}, {"type": "text", "text": "In addition to the above lemma, we leverage the following Lasso convergence result. We state a version that can be found in the book on high-dimensional probability due to Rigollet and H\u00fctter [2023]. ", "page_idx": 14}, {"type": "text", "text": "Lemma C.3 (Theorem 2.18 in [Rigollet and H\u00fctter, 2023] ). Suppose that $\\mathbf{Y}=\\mathbf{X}\\theta^{*}+\\epsilon$ , where $\\mathbf{X\\in}$ $\\mathbb{R}^{E\\times d}$ , $\\pmb{\\theta}^{*}\\in\\mathbb{R}^{d}$ is $s$ -sparse, and $\\epsilon$ has independent $^{\\,l}$ -sub-Gaussian coordinates. Further, suppose XT\u22a4Xis s-incoherent. Then, for any \u03b4 \u2208(0, 1) and for \u03bb = 4 E\u22121 log(2d) + 4 E\u22121 log(\u03b4\u22121), we have, with probability at least $1-\\delta$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\theta^{*}-\\widehat{\\theta}\\|_{2}\\le C\\sqrt{s E^{-1}\\log\\left(\\frac{2d}{\\delta}\\right)}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\widehat{\\pmb{\\theta}}$ denotes the solution to the Lasso and $C>0$ is some absolute constant. ", "page_idx": 15}, {"type": "text", "text": "Using standard arguments (see the proof of Theorem 2.18 in Rigollet and H\u00fctter [2023] or the statement of Theorem 7.3 in Wainwright [2019]), it can be further deduced that $\\lVert{\\pmb\\theta}^{*}-\\widehat{{\\pmb\\theta}}\\rVert_{1}\\leq$ $4{\\sqrt{s}}\\|\\pmb{\\theta}^{*}-{\\widehat{\\pmb{\\theta}}}\\|_{2}$ , so we actually have that, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\theta^{*}-\\widehat{\\theta}\\|_{1}\\leq C s\\sqrt{E^{-1}\\log\\left(\\frac{2d}{\\delta}\\right)},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $C>0$ is again some absolute constant. ", "page_idx": 15}, {"type": "text", "text": "C.2 Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof. Define $\\begin{array}{r c l}{{\\pmb{\\theta}}}&{{=}}&{{N^{-1}\\sum_{n=1}^{N}{\\pmb{\\theta}}_{n}}}\\end{array}$ . Recall the notation $\\widehat{\\pmb{\\theta}}~~=~~N^{-1}\\sum_{n=1}^{N}\\widehat{\\pmb{\\theta}}_{n}$ , and $\\widehat{\\textbf{a}}=$ arg $\\operatorname*{max}_{\\mathbf{a}\\in[A]^{N}}\\langle\\widehat{\\pmb{\\theta}},\\chi(\\mathbf{a})\\rangle$ . For any round $t\\in\\{E+1,\\ldots,T\\}$ , we greedily play th e action $\\widehat{\\mathbf{a}}$ . The average reward $\\overline{r}(\\widehat{\\mathbf a})$ can be bounded using the definition of $\\widehat{\\mathbf{a}}$ and Holder\u2019s inequality as follows, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{r}}(\\mathbf{a}^{*})-\\overline{{r}}(\\widehat{\\mathbf{a}})=\\langle\\theta,\\chi(\\mathbf{a}^{*})-\\chi(\\widehat{\\mathbf{a}})\\rangle}\\\\ &{\\qquad\\qquad=\\langle\\theta-\\widehat{\\theta},\\chi(\\mathbf{a}^{*})-\\chi(\\widehat{\\mathbf{a}})\\rangle+\\underbrace{\\langle\\widehat{\\theta},\\chi(\\mathbf{a}^{*})-\\chi(\\widehat{\\mathbf{a}})\\rangle}_{\\le0}}\\\\ &{\\qquad\\quad\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ }\\\\ &{\\leq\\langle\\theta-\\widehat{\\theta},\\chi(\\mathbf{a}^{*})-\\chi(\\widehat{\\mathbf{a}})\\rangle}\\\\ &{\\leq\\|\\theta-\\widehat{\\theta}\\|_{1}\\|\\chi(\\mathbf{a}^{*})-\\chi(\\widehat{\\mathbf{a}})\\|_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Next, substituting the definition of $\\theta,\\widehat{\\theta},\\,\\|\\chi(\\mathbf{a})\\|_{\\infty}=1$ , and using the triangle inequality into the equation above gives us, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{r}(\\mathbf{a}^{*})-\\bar{r}(\\widehat{\\mathbf{a}})\\leq2\\|\\theta-\\widehat{\\theta}\\|_{1}\\leq2\\left\\|\\displaystyle\\frac{1}{N}\\sum_{n=1}^{N}\\Big(\\theta_{n}-\\widehat{\\theta}_{n}\\Big)\\right\\|_{1}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{2}{N}\\sum_{n=1}^{N}\\left\\|\\theta_{n}-\\widehat{\\theta}_{n}\\right\\|_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let us define the \u201cgood\u201d events by ", "page_idx": 15}, {"type": "equation", "text": "$$\n=\\left\\{\\mathbf{X}{\\mathrm{~is~}}A^{s}{\\mathrm{-incoherent}}\\right\\}\\quad{\\mathrm{and}}\\quad G_{2}:=\\left\\{\\forall n\\in[N],\\|{\\widehat{\\pmb{\\theta}}}_{n}-\\pmb{\\theta}_{n}\\|_{1}\\leq C A^{s}{\\sqrt{E^{-1}\\log\\left({\\frac{4N A^{N}}{\\delta}}\\right)}}\\right\\}\n$$$G_{1}:=\\{\\mathbf{X}$ ", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $C>0$ is the constant following the discussion of Lemma C.3. Let us define the global \u201cgood\u201d event by $G:=G_{1}\\cap G_{2}$ . We show $\\mathbb{P}(G)\\geq1-\\delta$ . ", "page_idx": 15}, {"type": "text", "text": "First, there is a universal constant $C^{\\prime}>0$ such that $E\\geq4096{\\cal A}^{2s}\\left[\\log(4/\\delta)+2N\\log({\\cal A})\\right]$ when $T\\geq C^{\\prime}A^{2s}[\\log(N/\\delta)\\!+\\!N\\log(A)]$ . Thus, by Lemma C.2, we know the matrix $\\mathbf{X}$ with $\\boldsymbol{\\chi}^{\\mathbf{a}_{1}},\\dots,\\boldsymbol{\\chi}^{\\mathbf{a}_{E}}$ as its rows is $A^{s}$ -incoherent least $\\bar{1}-\\frac\\delta2$ , i.e. $\\begin{array}{r}{\\mathbb{P}(G_{1})\\ge1-\\frac{\\delta}{2}}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "Next, conditioning on $G_{1}$ and applying Lemma C.3 alongside a union bound over the $N$ units yields ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Vert\\widehat{\\pmb{\\theta}}_{n}-\\pmb{\\theta}_{n}\\Vert_{1}\\leq C\\pmb{\\mathcal{A}}^{s}\\sqrt{E^{-1}\\log\\left(\\frac{4N\\pmb{\\mathcal{A}}^{N}}{\\delta}\\right)},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for all $n\\in[N]$ with probability at least $\\textstyle1-{\\frac{\\delta}{2}}$ , i.e. $\\mathbb{P}(G_{2}\\mid G_{1})\\geq1-{\\frac{\\delta}{2}}$ . Thus, in total, we have $\\mathbb{P}(G)=\\mathbb{P}(G_{1})\\mathbb{P}(G_{2}\\mid G_{1})\\geq(1-\\delta/2)^{2}\\geq1-\\delta$ . We assume we are operating on the good event $G$ going forward. ", "page_idx": 16}, {"type": "text", "text": "Plugging the per-unit $\\ell_{1}$ norms into (5), the cumulative regret can be upper bounded with probability $1-\\delta$ as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathrm{Reg}_{T}=\\sum_{t=1}^{T}\\big(\\bar{r}(\\mathbf a^{*})-\\bar{r}(\\hat{\\mathbf a})\\big)}}\\\\ &{=\\sum_{t=1}^{E}\\big(\\bar{r}(\\mathbf a^{*})-\\bar{r}(\\hat{\\mathbf a})\\big)+\\sum_{t=E+1}^{T}\\big(\\bar{r}(\\mathbf a^{*})-\\bar{r}(\\hat{\\mathbf a})\\big)}\\\\ &{\\le E+\\frac{2T}{N}\\left(\\displaystyle\\sum_{n=1}^{N}\\Big\\lVert\\theta_{n}-\\hat{\\theta}_{n}\\Big\\rVert_{1}\\right)}\\\\ &{\\le E+2C T\\cdot A^{s}\\sqrt{E^{-1}\\log\\left(\\frac{4N A^{N}}{\\delta}\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Clearly, we should select $E$ to roughly balance terms (up to multiplicative constants). In particular, using the choice of $E$ as ", "page_idx": 16}, {"type": "equation", "text": "$$\nE:=(T\\mathcal{A}^{s})^{2/3}\\left[\\log\\left(\\frac{N}{\\delta}\\right)+N\\log(A)\\right]^{1/3}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and substituting $E$ into (6) gives us ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{T}\\leq O\\left((N\\log(A N/\\delta))^{1/3}(T\\mathcal{A}^{s})^{2/3}\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "with probability at least $1-\\delta$ , precisely the claimed result. ", "page_idx": 16}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: in the abstract/introduction, we claim that we contribute (a) a framework for studying bandits with sparse interference, (b) algorithms for obtaining low regret under this framework, and (c) simulations to empirically back up our theoretical findings. We present these, respectively, in Section 3, Sections 4 and 5, and Section 6 of our paper. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 17}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: We discuss many shortcomings of our contributions. For instance, we note that in the known interference setting, our main algorithm obtains a dependence on the time horizon that grows as $T^{2/3}$ , whereas one would ideally hope for $T^{1/2}$ dependence. We also address computational aspects of the Lasso in Section 5, providing heuristic approaches for speedup. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 17}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We detail all of our assumptions either in Section 3 or in the statements of theorems. We also provide full, rigorous proof of our results in the appendices. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 18}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We fully describe our theoretical framework, and painstakingly detail all algorithms, including how to choose free parameters. In our experimentation section, we provide full details on our setup. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 18}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We have attached our code as a supplement so it is viewable by reviewers. We have redacted written where the link to the repo will be included upon acceptance. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 19}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We fully describe our simulations in Section 6 in our work. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 19}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We provide error bars for our simulation results and we describe the methodology by which we produce our error bars. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 20}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [No] ", "page_idx": 20}, {"type": "text", "text": "Justification: Our experiments are extremely lightweight and can be run on any modern laptop. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We have read the code of ethics and have found no violations in our work. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: There are no negative societal impacts of our work. We have mentioned as positive societal impacts applicability of our results to tasks such as medical trials. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 21}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: We do not produce any models or release any data that may be misused. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: We do not use existing assets in our work. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 21}, {"type": "text", "text": "\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 22}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: We do not introduce any new assets in our work. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 22}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: We do not use crowdsourcing nor do we conduct research with human subjects. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 22}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: Same as the justification for the above bullet point. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}]