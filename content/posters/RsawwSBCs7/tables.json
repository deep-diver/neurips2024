[{"figure_path": "RsawwSBCs7/tables/tables_2_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models (ViT-B/16 for images and BERT for text).  It compares the accuracy of three methods:  Zero-shot, Prior Matching (a baseline method), and OTTER (the proposed method). The true label distribution was used as the label distribution specification for OTTER.  The table shows that OTTER significantly outperforms both Zero-shot and Prior Matching across a wide range of datasets, achieving an average improvement of 4.9% for image classification and 15.5% for text classification.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_6_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models (ViT-B/16 for images and BERT for text).  The performance of OTTER is compared against a baseline method (Prior Matching) across various datasets.  The numbers in parentheses show standard deviations.  The table highlights that OTTER consistently outperforms the baseline, improving accuracy by an average of 4.9% for image classification and 15.5% for text classification.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_8_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models (ViT-B/16 for images and BERT for text).  It compares the performance of three methods: Zero-shot (baseline), Prior Matching (a competing method), and OTTER (the proposed method).  The results show OTTER significantly outperforms the other methods, demonstrating substantial improvements in accuracy across a range of datasets.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_8_2.jpg", "caption": "Table 3: Accuracy (%) with hierarchical OTTER (H-OTTER). (H-OTTER) yields additional improvements over OTTER, up to 5.1%, using the hierarchy information of labels.", "description": "This table presents the results of using hierarchical OTTER (H-OTTER) on image classification tasks using the CLIP model.  It shows that incorporating class hierarchy information can improve the accuracy of the zero-shot model.  The improvements range up to 5.1% compared to the standard OTTER approach.  Different CLIP model versions (RN50, RN101, and various ViT models) were tested.  The accuracy and standard deviation are shown for each model.", "section": "5.4 Zero-shot prediction improvement with class hierarchy"}, {"figure_path": "RsawwSBCs7/tables/tables_9_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the accuracy results of zero-shot image classification using ViT-B/16 and text classification using BERT.  The results compare the performance of three methods: zero-shot classification (baseline), Prior Matching, and the proposed OTTER method.  The true label distribution was used for the label distribution specification. The table shows accuracy improvements across different datasets for OTTER, significantly outperforming Prior Matching in most cases.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_9_2.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models, ViT-B/16 for images and BERT for text.  It compares the accuracy of three methods: zero-shot prediction (baseline), Prior Matching, and the proposed OTTER method.  The results show significant improvements in accuracy using OTTER across a wide variety of datasets, surpassing prior matching in nearly every case, and demonstrating the effectiveness of the method in addressing label distribution mismatch.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_15_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models, ViT-B/16 and BERT respectively.  The accuracy of both Prior Matching and OTTER are shown for each dataset.  The results highlight that OTTER consistently outperforms Prior Matching, achieving a significant accuracy improvement on average. The use of the true label distribution as a specification for the label distribution is also noted. Standard deviation for Prior Matching is reported over 10 different samplings of validation sets.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_23_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models, ViT-B/16 for images and BERT for text.  It compares the accuracy of three methods: a standard zero-shot approach, Prior Matching (PM), and the proposed OTTER method. The true label distribution was used as the label distribution specification for OTTER.  The results show that OTTER significantly outperforms both the standard zero-shot approach and Prior Matching, achieving an average accuracy increase of 4.9% for image classification and 15.5% for text classification.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_24_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the accuracy of zero-shot image and text classification using different models (ViT-B/16 for images and BERT for text).  It compares the performance of three methods: standard zero-shot classification, Prior Matching (a baseline method), and OTTER (the proposed method). The results show that OTTER significantly improves accuracy over both the standard zero-shot method and the baseline, particularly in text classification.  The table highlights OTTER's effectiveness across a wide range of datasets.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_25_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models (ViT-B/16 for images and BERT for text).  It compares the accuracy of three methods: a standard zero-shot approach, a prior matching baseline, and the proposed OTTER method. The results show that OTTER significantly outperforms both the zero-shot baseline and the prior matching method across a wide range of datasets. The table also includes standard deviations for the prior matching results.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_25_2.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models, ViT-B/16 for images and BERT for text.  It compares the performance of three methods: a zero-shot baseline, a prior matching method, and the proposed OTTER method.  The results show OTTER significantly outperforms the other methods across most datasets, indicating its effectiveness in improving zero-shot accuracy.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_27_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models: ViT-B/16 for images and BERT for text.  The accuracy of the OTTER method is compared against a baseline method (Prior Matching) across various datasets. The results show significant improvement by OTTER over the baseline, especially in text classification, while using the true label distribution for the label distribution specification.  Parenthetical values for Prior Matching reflect the standard deviation based on 10 different validation set samplings.", "section": "5.1 Real Data Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_27_2.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models, ViT-B/16 for images and BERT for text.  It compares the accuracy of three methods: Zero-shot (baseline), Prior Matching, and the proposed OTTER method.  The results show that OTTER significantly improves the accuracy compared to the baseline and often outperforms Prior Matching, highlighting the effectiveness of OTTER in addressing label distribution mismatch in zero-shot scenarios. The use of the true label distribution as a specification is also noted.  Standard deviations are reported for Prior Matching, reflecting multiple validation set samplings.", "section": "5 Experiments"}, {"figure_path": "RsawwSBCs7/tables/tables_28_1.jpg", "caption": "Table 13: Class balance estimation error with BBSE in Section 5.3. We report the mean of 10 different random samplings of the validation set. Lower is better.", "description": "This table presents the total variation distance between the true label distribution and estimations using BBSE (Black Box Shift Estimation) with zero-shot prediction scores and linear probing prediction scores.  It shows how well BBSE estimates the true class balance for different datasets. Lower values indicate better estimation accuracy.", "section": "5.3 Few-shot adaptation with label distribution estimation"}, {"figure_path": "RsawwSBCs7/tables/tables_30_1.jpg", "caption": "Table 1: Accuracy (%) in zero-shot image classification (ViT-B/16) and text classification (BERT). We use the true label distribution as the label distribution specification. The numbers in parenthesis of Prior Matching represent the standard deviation of 10 different samplings of the validation set. OTTER produces improvements nearly across-the-board, with an average lift 4.9% in image classification and 15.5% in text classification, outperforming a powerful baseline, prior matching in almost all cases.", "description": "This table presents the results of zero-shot image and text classification experiments using two different models (ViT-B/16 for images and BERT for text).  It compares the accuracy of OTTER against a baseline method (Prior Matching) across various datasets.  The results demonstrate OTTER's significant improvement in accuracy, especially compared to the baseline.", "section": "5.1 Real Data Experiments"}]