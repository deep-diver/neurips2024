[{"figure_path": "7UenF4kx4j/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of SMART. Left: Given EHR data with missingness, we randomly mask them on the existing observations and conduct reconstruction in the latent space. The reconstruction targets are generated by EMA updated parameters. Right: We illustrate the detailed architecture of the input encoder and the MART block. The input encoder embeds each variable (which can also be referred to as a biomarker) and missing mask into a separate hidden space. The MART block employs various techniques to capture feature interactions in both the temporal and variable dimensions while further encoding missing information.", "description": "This figure illustrates the SMART model's architecture and training process. The left side shows the pre-training stage, where the model learns to reconstruct missing data in the latent space using a self-supervised approach.  The right side details the model's architecture, focusing on the input encoder and MART block, which handle temporal and variable interactions while encoding missingness.  The MART block utilizes attention mechanisms to learn relationships between variables and time points.", "section": "3 Methodology"}, {"figure_path": "7UenF4kx4j/figures/figures_8_1.jpg", "caption": "Figure 2: Performance on different observed ratio of EHR.", "description": "This figure shows the performance (AUPRC) of different models on three datasets (Cardiology, Sepsis, and In-hospital Mortality) under various observed rates of EHR data ranging from 10% to 100%.  The x-axis represents the observed rate, while the y-axis represents the AUPRC. Each line represents a different model, allowing for a comparison of their robustness to missing data.  The figure demonstrates how well the model generalizes in the presence of varying degrees of missing data.  The results show SMART's superior performance compared to the other models, especially when the observed rate is low.", "section": "4.2.3 Effect of Missingness"}, {"figure_path": "7UenF4kx4j/figures/figures_8_2.jpg", "caption": "Figure 1: Overview of SMART. Left: Given EHR data with missingness, we randomly mask them on the existing observations and conduct reconstruction in the latent space. The reconstruction targets are generated by EMA updated parameters. Right: We illustrate the detailed architecture of the input encoder and the MART block. The input encoder embeds each variable (which can also be referred to as a biomarker) and missing mask into a separate hidden space. The MART block employs various techniques to capture feature interactions in both the temporal and variable dimensions while further encoding missing information.", "description": "This figure provides a comprehensive overview of the SMART model, showcasing its two-stage training process (pre-training and fine-tuning). The left side illustrates the self-supervised pre-training stage, where the model learns to reconstruct missing data representations in the latent space.  The right side details the architecture of the input encoder and the core MART block, highlighting how it handles temporal and variable interactions, along with missing information. The figure uses a visual representation to clearly depict the information flow and key components of the SMART model.", "section": "3 Methodology"}]