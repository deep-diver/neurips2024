{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a vision-language model that is foundational to the current work's approach and is used extensively throughout the paper's methodology."}, {"fullname_first_author": "Chao Jia", "paper_title": "Scaling up visual and vision-language representation learning with noisy text supervision", "publication_date": "2021-07-01", "reason": "This paper is highly relevant due to its focus on scaling up visual-language representation learning, a key element of the proposed OV-OAD model."}, {"fullname_first_author": "Haroon Idrees", "paper_title": "The THUMOS challenge on action recognition for videos \"in the wild\"", "publication_date": "2017-01-01", "reason": "This paper introduces the THUMOS challenge dataset, a benchmark dataset that is extensively used for evaluating the proposed model's performance."}, {"fullname_first_author": "Dima Damen", "paper_title": "Rescaling egocentric vision: Collection, pipeline and challenges for epic-kitchens-100", "publication_date": "2022-01-01", "reason": "This paper presents the EPIC-KITCHENS-100 dataset, another benchmark dataset used in the paper's evaluation, showcasing the model's capabilities on a diverse dataset."}, {"fullname_first_author": "Roeland De Geest", "paper_title": "Online action detection", "publication_date": "2016-10-11", "reason": "This paper introduces the concept of online action detection, which is directly addressed by the proposed OV-OAD model and forms the core task being tackled."}]}