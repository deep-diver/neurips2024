[{"figure_path": "vjsd8Bcipv/tables/tables_1_1.jpg", "caption": "Table 2: Last epoch test accuracies (%) of different methods on CIFAR-10/100 symmetric and asymmetric noise. The results \"mean\u00b1std\" are reported over 3 random runs and the top-2 best results are boldfaced.", "description": "This table presents the test accuracy results for various methods (CE, FL, GCE, NLNL, SCE, NCE+MAE, NCE+RCE, NFL+RCE, NCE+AUL, NCE+AGCE, NCE+AEL, LDR-KL, CE+LC, CE+MAE, FLE+MAE) on CIFAR-10 and CIFAR-100 datasets under different symmetric and asymmetric noise rates (0, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8).  The results are averaged over three random runs, and the top two best results are highlighted in bold.", "section": "4.1 Evaluation on Benchmark Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_4_1.jpg", "caption": "Table 1: All-k consistency between different loss functions.", "description": "This table summarizes the All-k consistency property of various loss functions.  All-k consistency is a stronger property than standard consistency, indicating the loss function's ability to achieve Bayes optimal top-k error for any k.  A checkmark (\u2713) indicates All-k consistency, while an X indicates a lack thereof.", "section": "3.2 Consistency"}, {"figure_path": "vjsd8Bcipv/tables/tables_6_1.jpg", "caption": "Table 2: Last epoch test accuracies (%) of different methods on CIFAR-10/100 symmetric and asymmetric noise. The results \"mean\u00b1std\" are reported over 3 random runs and the top-2 best results are boldfaced.", "description": "This table presents the test accuracies achieved by various methods on the CIFAR-10 and CIFAR-100 datasets under different symmetric and asymmetric noise conditions.  The results, averaged over three random runs and reported as mean \u00b1 standard deviation, show the performance of various loss functions in handling noisy labels.  The top two best performing methods for each condition are highlighted in bold.", "section": "4.1 Evaluation on Benchmark Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_7_1.jpg", "caption": "Table 3: Ablation experiments on CIFAR-100. The results \"mean\u00b1std\" are reported over 3 random runs and the best results are boldfaced. If m = 0, CE+MAE equals CE+MAE.", "description": "This table presents the results of ablation experiments conducted on the CIFAR-100 dataset to analyze the impact of the hyperparameter 'm' in the CE+MAE loss function.  The table compares the performance of CE+MAE with different values of 'm' (including m=0, which is equivalent to the standard CE+MAE) across various noise levels (clean, symmetric noise rates of 0.4 and 0.8, and asymmetric noise rate of 0.4). The best performance for each noise level is highlighted in bold.  The results show how the choice of 'm' affects the trade-off between robustness to noise and the ability to fit clean data.", "section": "4.1 Evaluation on Benchmark Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_8_1.jpg", "caption": "Table 2: Last epoch test accuracies (%) of different methods on CIFAR-10/100 symmetric and asymmetric noise. The results \"mean\u00b1std\" are reported over 3 random runs and the top-2 best results are boldfaced.", "description": "This table presents the test accuracies achieved by various methods on CIFAR-10 and CIFAR-100 datasets under different symmetric and asymmetric noise conditions.  The results, averaged over three random runs, show the performance of different loss functions in handling label noise. The top two best-performing methods in each scenario are highlighted in bold.", "section": "4.1 Evaluation on Benchmark Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_8_2.jpg", "caption": "Table 2: Last epoch test accuracies (%) of different methods on CIFAR-10/100 symmetric and asymmetric noise. The results \"mean\u00b1std\" are reported over 3 random runs and the top-2 best results are boldfaced.", "description": "This table shows the test accuracy of various methods on CIFAR-10 and CIFAR-100 datasets under different symmetric and asymmetric noise conditions.  The results are averaged over three independent runs, with standard deviations reported. The two highest-performing methods for each scenario are highlighted in bold.", "section": "4.1 Evaluation on Benchmark Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_13_1.jpg", "caption": "Table 2: Last epoch test accuracies (%) of different methods on CIFAR-10/100 symmetric and asymmetric noise. The results \"mean\u00b1std\" are reported over 3 random runs and the top-2 best results are boldfaced.", "description": "This table presents the test accuracy results achieved by various methods on CIFAR-10 and CIFAR-100 datasets under different symmetric and asymmetric noise conditions.  The results, expressed as mean \u00b1 standard deviation, were obtained across three independent runs.  The top two best-performing methods for each noise level are highlighted in bold.", "section": "4.1 Evaluation on Benchmark Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_17_1.jpg", "caption": "Table 2: Last epoch test accuracies (%) of different methods on CIFAR-10/100 symmetric and asymmetric noise. The results \"mean\u00b1std\" are reported over 3 random runs and the top-2 best results are boldfaced.", "description": "This table presents the test accuracies achieved by various methods (including the proposed method) on CIFAR-10 and CIFAR-100 datasets under different symmetric and asymmetric noise conditions.  The results are averaged over three random runs, and the top two best performing methods are highlighted in bold for each scenario.", "section": "4.1 Evaluation on Benchmark Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_19_1.jpg", "caption": "Table 4: Best epoch test accuracies (%) of different methods on CIFAR-N datasets. We compare methods without and with semi-supervised learning (SSL) and sample selection. The results \\\"mean\u00b1std\\\" are reported over 5 random runs and the best results are boldfaced.", "description": "This table compares the performance of various methods on CIFAR-10N and CIFAR-100N datasets, which are datasets with human-annotated noisy labels.  It shows the test accuracy of methods both with and without semi-supervised learning (SSL) and sample selection techniques. The best performing methods are highlighted in bold. The results are averaged over 5 runs, with the standard deviation reported.", "section": "4.2 Evaluation on Human-Annotated Datasets"}, {"figure_path": "vjsd8Bcipv/tables/tables_19_2.jpg", "caption": "Table 8: Last epoch test accuracies (%) on CIFAR-10/100 instance-dependent noise (IDN). The results \"mean\u00b1std\" are reported over 3 random runs and the best results are boldfaced.", "description": "This table presents the last epoch test accuracies of different methods on CIFAR-10 and CIFAR-100 datasets with instance-dependent noise.  The results are averaged over three random runs, and the standard deviation is reported. The best results in each setting are highlighted in bold.", "section": "4.1 Evaluation on Benchmark Datasets"}]