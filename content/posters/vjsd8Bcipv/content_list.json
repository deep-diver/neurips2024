[{"type": "text", "text": "\u03f5-Softmax: Approximating One-Hot Vectors for Mitigating Label Noise ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jialiang Wang1\u2217 Xiong Zhou1\u2217 Deming Zhai1 Junjun Jiang1 Xiangyang Ji2 Xianming Liu1\u2020 ", "page_idx": 0}, {"type": "text", "text": "Faculty of Computing, Harbin Institute of Technology 2Department of Automation, Tsinghua University cswjl@stu.hit.edu.cn, cszx@hit.edu.cn, csxm@hit.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Noisy labels pose a common challenge for training accurate deep neural networks. To mitigate label noise, prior studies have proposed various robust loss functions to achieve noise tolerance in the presence of label noise, particularly symmetric losses. However, they usually suffer from the underfitting issue due to the overly strict symmetric condition. In this work, we propose a simple yet effective approach for relaxing the symmetric condition, namely $\\epsilon$ -softmax, which simply modifies the outputs of the softmax layer to approximate one-hot vectors with a controllable error $\\epsilon$ . Essentially, $\\epsilon$ -softmax not only acts as an alternative for the softmax layer, but also implicitly plays the crucial role in modifying the loss function. We prove theoretically that $\\epsilon$ -softmax can achieve noise-tolerant learning with controllable excess risk bound for almost any loss function. Recognizing that $\\epsilon$ -softmaxenhanced losses may slightly reduce fitting ability on clean datasets, we further incorporate them with one symmetric loss, thereby achieving a better trade-off between robustness and effective learning. Extensive experiments demonstrate the superiority of our method in mitigating synthetic and real-world label noise. The code is available at https://github.com/cswjl/eps-softmax. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In recent years, deep neural networks (DNNs) have achieved remarkable advancements across various machine learning tasks [1, 2]. Despite its significant success, the prevalence of noisy labels in realworld datasets is a pervasive issue, often stemming from human bias or a lack of relevant professional knowledge [2]. The application of supervised learning methods directly to data with noisy labels consistently results in a decline in model performance [3]. Moreover, the ability to generalize from weak learners plays a pivotal role in the alignment of large language models [4]. Consequently, the pursuit of noise-tolerant learning has emerged as a compelling and significant challenge within the domain of weakly supervised learning, garnering increased attention in recent years [5, 6, 7, 8]. ", "page_idx": 0}, {"type": "text", "text": "The literature presents several strategies for remedying this issue, with the design of robust loss functions standing out as a particularly popular approach due to its simplicity and broad applicability. Some previous works [9, 10, 5] theoretically proved that a loss function is noise-tolerant to label noise under mild conditions if it is symmetric: ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}L(f(\\mathbf{x}),k)=C,\\quad\\forall\\mathbf{x}\\in\\mathcal{X},\\forall f\\in\\mathcal{H}\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $k\\in[K]$ is the label corresponding to each class, $C$ is a constant, and $\\mathcal{H}$ is the hypothesis class. Furthermore, Asymmetric Loss Functions (ALFs) [7] are proposed as an extension of symmetric losses, which are designed for clean-label-dominant noise. However, both symmetric and asymmetric losses, such as Mean Absolute Error (MAE) [5] and Asymmetric Unhinged Loss (AUL) [7], encounter the underfitting problem and prove challenging to optimize [5, 6, 7]. The fitting ability of existing symmetric loss functions is constrained by the overly strict symmetric condition in Equation 1.1 [7]. Some approaches aim to improve the classical symmetric loss MAE by incorporating the robustness of the MAE and the rapid convergence of the Cross Entropy (CE). Examples include Generalized Cross Entropy (GCE) [11], Symmetric Cross Entropy (SCE) [12], and Jensen-Shannon Divergence Loss (JS) [13]. However, these loss functions often mechanically select an intermediate value between the derivatives of CE and MAE, essentially representing a trade-off between fitting ability and robustness. This prompts a crucial question: How can we simultaneously achieve both robustness and effective learning? ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Zhou et al. [14] proposed an alternative approach to achieve the symmetric condition, diverging from the development of a new robust loss function. By restricting the hypothesis class $\\mathcal{H}$ , which restricts the outputs of the prediction function $f$ to one-hot vectors, any loss function can inherently become symmetric, i.e., kK=1 L $\\begin{array}{r}{\\sum_{k=1}^{K}L(f(\\mathbf x),k)=C,\\forall\\mathbf x\\in\\mathcal X,\\forall L\\in\\mathcal L}\\end{array}$ . However, a notable challenge arises from the fact that directly mapping outputs to one-hot vectors constitutes a non-differentiable operation. Accordingly, the crux of the matter lies in formulating an effective method to constrain the outputs to one-hot vectors. Previous attempts, such as temperature-dependent softmax [14], sparseness constraint [15], sparse regularization [14], and variance enlargement [16], have aimed to approximate one-hot vectors through the application of regularization methods. Nevertheless, these methods lack predictability, fail to achieve a quantitative approximation to one-hot vectors, and exhibit limited effectiveness, particularly at higher noise rates. Up to this point, a reliable approach for rigorously enforcing one-hot vector outputs remains elusive. Addressing this gap continues to pose a significant challenge in realizing the symmetric condition. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we present a simple yet effective and theoretically sound approach for approximating outputs to one-hot vectors, which we term $\\epsilon$ -softmax. This method serves as a valuable alternative to the conventional softmax function in mitigating label noise. The distinctive attribute of $\\epsilon$ -softmax lies in its guarantee to possess a controllable approximation error $\\epsilon$ to one-hot vectors, thus achieving perfect constraint for the hypothesis class. This approach is universally applicable across diverse models and loss functions, as it only needs to implement a simple layer resembling softmax. Specifically, the process of applying our $\\epsilon$ -softmax is outlined as follows: ", "page_idx": 1}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/a5b192d287a92e735777dec01ce315e9e95df00d81a0687911e811cc7b8ca8ba.jpg", "table_caption": [], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "Herein, $\\mathbf{p}(\\cdot|\\mathbf{x})$ represents the prediction probabilities, $p_{k}$ denotes the $k$ -th element of the vector $\\mathbf{p}(\\cdot|\\mathbf{x})$ , and $h(\\mathbf{x})$ denotes the logits. Step 1 obtains the original predictions by the softmax function. Step 2 involves a hyperparameter $m\\,\\geq\\,0$ to amplify the maximum term in the predictions with a controllable approximation error to one-hot vectors. Step 3 performs a normalization to make predictions sum to one, which also reduces the values of non-maximum terms. ", "page_idx": 1}, {"type": "text", "text": "The above description underscores that $\\epsilon_{}$ -softmax as a plug-and-play module applicable to any classifier incorporating a softmax layer. Through the adjustment of the parameter $m$ , our approach allows for the quantitative approximation of output to one-hot vectors, and thus owns the ability for mitigating label noise in classification. The main contributions of our work are highlighted as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a simple yet effective scheme, $\\epsilon$ -softmax, for mitigating label noise. This scheme operates as a plug-and-play module, seamlessly integrating with any classifier that incorporates a softmax layer through just two additional lines of code. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We offer rigorous theoretical analyses, which indicate that $\\epsilon$ -softmax is capable of controllably approximating one-hot vectors. Consequently, $\\epsilon$ -softmax-enhanced loss functions can achieve noise-tolerant learning and Bayes optimal top- $k$ error. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We develop practical loss functions that enhance noise-tolerant learning. These include integration with MAE, achieving a better trade-off between robustness and effective learning. Extensive experimental results demonstrate the superiority of our method. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Problem Formulation. In a typical supervised classification scenario, let $\\mathcal{X}\\subset\\mathbb{R}^{d}$ represent the $d$ -dimensional input space, and $\\mathcal{\\bar{D}}=[K]^{*}=\\{1,2,...,K\\}$ is the label space, where $K$ is the number of classes. We are provided with a labeled dataset $S=\\{(\\mathbf{x}_{n},y_{n})\\}_{n=1}^{N}$ , where each $\\left(\\mathbf{x}_{n},y_{n}\\right)$ is drawn $i.i.d.$ from an underlying distribution $\\mathcal{D}$ over $\\mathcal X\\times\\mathcal X$ . The classifier $f$ is a mapping from the sample space to the label space, the prediction label ${\\hat{y}}=\\arg\\operatorname*{max}_{k}f(\\mathbf{x})_{k}$ . Here, the prediction function $f:\\mathcal{X}\\rightarrow\\Delta_{K}$ estimates the probability $\\mathbf{p}(\\cdot|\\mathbf{x})$ , and $\\Delta_{K}=\\{\\mathbf{u}\\in[0,1]^{K}:\\mathbf{1}^{\\top}\\mathbf{u}=1\\}$ represents the probability simplex. Typically, the function $f$ is expressed as $f=\\mathbf{softmax}\\circ h$ , where $h$ denotes the logits input to the softmax layer. In the context of deep learning, $h$ is commonly a neural network. The objective or loss function is defined as a measure of distance $L\\,:\\,\\Delta_{K}\\,\\times\\,\\Delta_{K}\\,\\rightarrow\\,\\mathbb{R}$ . For a classification problem, the loss function is characterized by $L(\\mathbf{u},\\mathbf{e}_{y})$ , where ${\\bf e}_{y}$ represents the one-hot vector with its $y$ -th element set to 1. In this study, we consider the loss functional $\\mathcal{L}$ , where $\\forall L\\in{\\mathcal{L}}$ , $\\begin{array}{r}{L(\\mathbf{u},\\mathbf{v})=\\sum_{k=1}^{K}\\ell(u_{k},v_{k})}\\end{array}$ with a basic loss function $\\ell$ . For brevity, we slightly abuse notation by defining $L(\\mathbf{u},k)=L(\\mathbf{u},\\mathbf{e}_{k})$ . ", "page_idx": 2}, {"type": "text", "text": "Label Noise Model. In the context of learning with noisy labels, the accessible training set is the noisy counterpart $\\tilde{S}\\,=\\,\\{({\\bf x}_{n},\\tilde{y}_{n})\\}_{n=1}^{N}$ rather than the clean set $\\boldsymbol{S}$ . We characterize the noise corruption process as the flipping of the clean label of $\\mathbf{x}$ into its noisy version $\\tilde{y}$ with a probability denoted as $\\eta_{\\mathbf{x},\\tilde{y}}\\,=\\,p(\\tilde{y}|\\mathbf{x},y)$ . $\\begin{array}{r}{\\eta_{\\mathbf{x}}^{-}=\\sum_{k\\neq y}\\eta_{\\mathbf{x},k}}\\end{array}$ denotes the noise rate for $\\mathbf{x}$ . Our focus is on two prevalent types of label noise [6, 7] : ", "page_idx": 2}, {"type": "text", "text": "\u2013 Symmetric or uniform noise: $\\eta_{\\mathbf{x},y}=1-\\eta$ and $\\begin{array}{r}{\\eta_{\\mathbf{x},k\\neq y}=\\frac{\\eta}{K-1}}\\end{array}$ , \u2013 Asymmetric or class-conditional noise: $\\eta_{\\mathbf{x},y}=1-\\eta_{y}$ and $\\begin{array}{r}{\\sum_{k\\neq y}\\eta_{\\mathbf{x},k}=\\eta_{y}}\\end{array}$ , where $\\eta_{\\bf x}=\\eta$ for symmetric noise, $\\eta_{\\mathbf{x}}=\\eta_{y}$ denotes the noise rate for the $y$ -th class, and $\\eta_{\\mathbf{x},i}$ is not necessarily equal to $\\eta_{\\mathbf{x},j}$ , $i\\neq j$ for asymmetric noise. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "We also empirically consider learning with human-annotated noisy labels. ", "page_idx": 2}, {"type": "text", "text": "Expected Risk and Noise Tolerance. In learning with clean labels, given a loss function $L\\,\\in\\,{\\mathcal{L}}$ and a prediction function $f$ , the expected risk with respect to $f$ is defined as: $\\mathcal{R}_{L}(f)\\;=$ $\\mathbb{E}_{(\\mathbf{x},y)\\sim\\mathcal{D}}[L(\\hat{f(\\mathbf{x})},y)]$ . The objective is to learn an optimal classifier $f^{*}$ that minimizes the expected risk, i.e., $f^{*}\\in\\arg\\operatorname*{min}_{f\\in\\mathcal{F}}\\mathcal{R}_{L}(f)$ . ", "page_idx": 2}, {"type": "text", "text": "In the case of learning with noisy labels, the corresponding noisy expected risk with respect to $f$ is defined as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{R}_{L}^{\\eta}(f)=\\mathbb{E}_{\\mathcal{D}}\\big[(1-\\eta_{\\mathbf{x}})L(f(\\mathbf{x}),y)+\\sum_{k\\neq y}\\eta_{\\mathbf{x},k}L(f(\\mathbf{x}),k)\\big],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "wDhNeNres . $\\begin{array}{r}{\\sum_{k\\neq y}\\eta_{\\mathbf{x},k}L(f(\\mathbf{x}),k)}\\end{array}$ is the noisy part that usually poses challenges in training accurate ", "page_idx": 2}, {"type": "text", "text": "A loss function $L$ is claimed to be noise-tolerant if the global minimizer $f_{\\eta}^{*}$ of $\\mathcal{R}_{L}^{\\eta}(f)$ also minimizes $\\mathcal{R}_{L}(f)$ , that is, $f_{\\eta}^{*}\\in\\arg\\operatorname*{min}_{f}\\mathcal{R}_{L}(f)$ . ", "page_idx": 2}, {"type": "text", "text": "All- $k$ Consistency. Consistency is an important property of a loss function. A standard consistency is for achieving Bayes optimal top-1 error. We consider much stronger consistency for achieving Bayes optimal top- ${\\cdot k}$ error for any $k\\in[K]$ . To this end, we introduce some definitions about top- $k$ consistency [17, 8]. ", "page_idx": 2}, {"type": "text", "text": "For any vector $\\textbf{f}\\in\\mathbb{R}^{K}$ , we let $r_{k}(\\mathbf{f})$ denote a top- $k$ selector that selects the $k$ indices of the largest entries of f by breaking ties arbitrarily. Given a data $\\left(\\mathbf{x},y\\right)$ , its top- $k$ error is defined as $\\mathrm{err}_{k}(f,\\mathbf{x},y)=\\mathbb{I}(y\\notin r_{k}(f(\\mathbf{x})))$ . The goal of a classification algorithm under the top- $k$ error metric is to learn a predictor $f$ that minimizes the $\\mathrm{err}_{k}$ expected risk: $\\begin{array}{r}{\\bar{\\mathcal{R}}_{\\mathrm{err}_{k}}(f)=\\mathbb{E}_{(\\mathbf{x},y)\\sim\\bar{\\mathcal{D}}}[\\mathrm{err}_{k}(f,\\mathbf{x},y)]}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "For a fixed $\\textit{k}\\in\\ [K]$ , a loss function $L$ is top- $k$ consistent if for any sequence of measurable functions $f:\\mathcal{X}\\rightarrow\\Delta_{K}$ , we have the global minimizer $f^{*}$ of $\\mathcal{R}_{L}(f)$ also minimizes $\\mathcal{R}_{\\mathrm{err}_{k}}(f)$ , that is, $f^{*}\\in\\arg\\operatorname*{min}_{f}\\mathcal{R}_{\\mathrm{err}_{k}}(f)$ . If the above holds for all $k\\in[K]$ , it is referred to as All- $k$ consistency. ", "page_idx": 2}, {"type": "text", "text": "3 Methodology and Theoretical Investigation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The symmetry condition in Equation 1.1, theoretically ensures that a symmetric loss function can be noise-tolerant [5]. Existing methods primarily focus on designing new loss functions. Those derived based on this design principle exhibit drawbacks, such as being challenging to optimize [5, 6] and prone to encounter the gradient explosion problem [7]. In this work, we take an alternative approach by proposing to constrain the hypothesis class $\\mathcal{H}$ such that any loss functions will be approximately symmetric thereby rendering them robust to label noise. ", "page_idx": 3}, {"type": "text", "text": "3.1 Robustness ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We introduce $\\epsilon$ -softmax to make the output $f(\\mathbf{x})$ approximate one-hot vectors. The implementation of $\\epsilon$ -softmax is easy to follow, as outlined in the gray box of the Introduction Section 1, requiring just two additional lines of code alongside the standard softmax layer. This underscores that $\\epsilon$ - softmax is a plug-and-play module applicable to any classifier that incorporates a softmax layer. In this following, we investigate in theory how $\\epsilon$ -softmax realizes the controllable approximation of outputs to one-hot vectors, thereby enhancing the noise tolerance of any loss function. ", "page_idx": 3}, {"type": "text", "text": "Approximating One-Hot Vectors. We first introduce the concept of $\\epsilon$ -relaxation for a hypothesis class and then prove $\\epsilon$ -softmax can strictly approximate outputs to one-hot vectors with a controllable error. ", "page_idx": 3}, {"type": "text", "text": "Definition 1 $\\epsilon$ -relaxation). Given a fixed vector v and its permutation set $\\mathcal{P}_{\\mathbf{v}}^{1}$ , the $\\epsilon$ -relaxation of $\\mathcal{P}_{\\mathbf{v}}$ is defined as the hypothesis class $\\mathcal{H}_{\\mathbf{v},\\epsilon},$ , in which any hypothesis $f\\in\\mathcal{H}_{\\mathbf{v},\\epsilon}$ outputs vectors in the $\\epsilon$ -ball of $\\mathcal{P}_{\\mathbf{v}}$ , i.e., $\\mathcal{H}_{\\mathbf{v},\\epsilon}=\\{f:\\operatorname*{min}_{\\mathbf{u}\\in\\mathcal{P}_{\\mathbf{v}}}$ $\\|f(\\mathbf{x})-\\mathbf{u}\\|_{2}\\leq\\epsilon,\\forall\\mathbf{x}\\}$ . ", "page_idx": 3}, {"type": "text", "text": "Without loss of generality, we consider $\\mathbf{v}$ as a one-hot vector, which is common in machine learning, to facilitate the implementation and analysis. We then denote the permutation set of the one-hot vector as $\\mathcal{P}_{\\mathbf{e}_{1}}$ , where all elements are also one-hot vectors. In accordance with Definition 1, we can further derive that: ", "page_idx": 3}, {"type": "text", "text": "Lemma 1. $\\epsilon$ -softmax can achieve $\\epsilon$ -relaxation for one-hot vectors: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{\\mathbf{u}\\in\\mathcal{P}_{\\mathbf{e}_{1}}}{\\operatorname*{min}}\\|f(\\mathbf{x})-\\mathbf{u}\\|_{2}\\le\\epsilon=\\frac{\\sqrt{1-1/K}}{m+1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $f(\\mathbf{x})=\\epsilon{\\mathbf{-softmax}}\\circ h(\\mathbf{x}).$ . ", "page_idx": 3}, {"type": "text", "text": "Lemma 1 suggests that $\\epsilon$ -softmax effectively enables $f_{\\epsilon}(\\mathbf{x})$ to approximate one-hot vectors with a controllable error $\\frac{\\sqrt{1-1/K}}{m+1}$ ", "page_idx": 3}, {"type": "text", "text": "Robustness Guarantee. We then establish theoretical guarantees for the robustness in mitigating label noise, where the constrained hypothesis class $\\mathcal{H}_{\\mathbf{e}_{1},\\epsilon}$ is considered. ", "page_idx": 3}, {"type": "text", "text": "Zhou et al. [14] established the excess risk bound [18] under symmetric noise, which holds when outputs fall within an $\\epsilon_{}$ -relaxation of a permutation set. We prove a more comprehensive conclusion by considering asymmetric noise, of which symmetric noise is a special case. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1 (Excess Risk Bound under Asymmetric Noise). In a multi-class classification problem, if the loss function $L\\in{\\mathcal{L}}$ satisfies $\\begin{array}{r}{|\\sum_{k=1}^{K}(L(\\mathbf{u}_{1},k)-L(\\mathbf{u}_{2},k))|\\leq\\delta}\\end{array}$ when $\\|\\mathbf{u}_{1}-\\mathbf{u}_{2}\\|_{2}\\leq\\epsilon,$ , and $\\delta\\rightarrow0$ as $\\epsilon\\rightarrow0$ , then for asymmet ric label noise $\\eta_{\\mathbf{x},k}<\\left(1-\\eta_{y}\\right),\\forall k\\neq y$ , if $\\mathcal{R}_{L}(f^{*})=0$ , the excess risk bound for $f\\in\\mathcal{H}_{\\mathbf{v},\\epsilon}$ can be expressed as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{R}_{L}(f_{\\eta}^{*})\\leq2\\delta+\\frac{2c\\delta}{a},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $c=\\mathbb{E}_{\\mathcal{D}}\\left(1-\\eta_{y}\\right)$ , $\\begin{array}{r}{a\\mathrm{~=~}\\operatorname*{min}_{\\mathbf{x},k}(1-\\eta_{y}-\\eta_{\\mathbf{x},k}),}\\end{array}$ , $f_{\\eta}^{*}$ and $f^{*}$ denote the global minimum of $\\mathcal{R}_{L}^{\\eta}(f)$ and $\\mathcal{R}_{L}(f)$ , respectively. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1 demonstrate that under mild conditions for symmetric and asymmetric label noise, any loss function can be made noise-tolerant when the function $f(\\mathbf{x})$ increasingly approximates a permutation set $\\mathcal{P}_{\\mathbf{v}}$ (i.e., $\\delta\\rightarrow0$ as $\\epsilon\\rightarrow0$ ). ", "page_idx": 3}, {"type": "text", "text": "$\\epsilon$ -Softmax-Enhanced Loss Functions. Lemma 1 enable $f(\\mathbf{x})=\\epsilon{\\mathbf{-softmax}}\\circ h(\\mathbf{x})$ in closely approximating a one-hot vector, aligns with the principle outlined in Theorem 1 within the framework of the hypothesis class $\\mathcal{H}_{\\mathbf{e}_{1},\\epsilon}$ . Hence, $\\epsilon$ -softmax progressively enhances the noise tolerance of any loss function as the hyperparameter $m$ approaches infinity $\\left(\\epsilon\\rightarrow0\\right)$ as $m\\rightarrow\\infty$ and the discrepancy $\\delta\\rightarrow0$ ). ", "page_idx": 4}, {"type": "text", "text": "In this paper we consider CE loss and Focal loss (FL) [19]. We combine them with $\\epsilon_{}$ -softmax, denoted as $\\mathrm{CE}_{\\epsilon}$ and $\\mathrm{FL_{\\epsilon}}$ . $\\epsilon$ -softmax approach is effective in adapting them to become more resilient to noise, ensuring better performance in the presence of label noise. ", "page_idx": 4}, {"type": "text", "text": "3.2 Consistency ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Fundamentally, $\\epsilon$ -softmax not only acts as an alternative for the softmax layer, but also plays the crucial role in modifying the loss function. Consistency is an important property of a loss function. A standard consistency is for achieving Bayes optimal top-1 error. We show much stronger consistency for achieving Bayes optimal top- $k$ error for any $k\\,\\in\\,[K]$ of the CE loss when combined with $\\epsilon$ - softmax. To establish the All- $k$ consistency, we first introduce some existing results of sufficient condition of top- ${\\cdot k}$ consistency by top- $k$ calibration [17, 8]. ", "page_idx": 4}, {"type": "text", "text": "Let $P_{k}(\\mathbf{f},\\mathbf{q})$ denote that f is top- $k$ preserving with respect to the underlying label distribution $\\mathbf{q}$ , i.e., if for all $l\\in[K],q_{l}>q_{[k+1]}\\Rightarrow f_{l}>f_{[k+1]}$ , and $q_{l}<q_{[k]}\\Rightarrow f_{l}<f_{[k]}$ . Here, $q_{[k]}$ denotes he $k$ -th greatest entry of q. For example, if $\\mathbf{q}=[0.2,0.4,0.4]$ ], then $q_{[1]}=0.4,q_{[2]}=0.4,q_{[3]}=0.2$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 2 (All- $k$ calibrated). For a fixed $k\\in[K]$ , a loss function $L$ is called top- $k$ calibrated if for all $\\mathbf{q}\\in\\Delta_{K}$ it holds that: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{f\\in\\mathbb{R}^{K}:\\neg P_{k}(f,\\mathbf{q})}\\mathcal{R}_{L}(f)>\\operatorname*{inf}_{f\\in\\mathbb{R}^{K}}R_{L}(f).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "A loss function is called All- $k$ calibrated if the loss function $L$ is top- $k$ calibrated for all $k\\in[K]$ . ", "page_idx": 4}, {"type": "text", "text": "Yang and Koyejo [17] demonstrate that suppose $L$ is a nonnegative top- $k$ calibrated loss function, then $L$ is top- $k$ consistent. Furthermore, Zhu et al. [8] show that if $f^{\\ast}=\\arg\\operatorname*{min}_{f}R_{L}(f)$ is rank preserving with respect to $\\mathbf{q}$ , then $L$ is All- $k$ calibrated. f is called rank preserving w.r.t q, i.e., if for any pair $q_{i}<q_{j}$ it holds that $f_{i}<f_{j}$ . ", "page_idx": 4}, {"type": "text", "text": "Then we establish comprehensive All- $k$ consistency for $\\mathrm{CE}_{\\epsilon}$ as follows: ", "page_idx": 4}, {"type": "text", "text": "Lemma 2. For one-hot label ${\\bf e}_{y}$ , $C E_{\\epsilon}$ is All- $k$ calibrated and All- $k$ consistency. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2. For any label $\\mathbf{q}\\in\\Delta_{K}$ , let $y=\\arg\\operatorname*{max}_{k\\in[K]}q_{k}$ and $t=\\arg\\operatorname*{max}_{k\\in[K]}p_{k}\\;,\\,i f t=y$ and $\\begin{array}{r}{q_{y}-\\operatorname*{max}_{k\\neq y}q_{k}>\\frac{m}{m+1}}\\end{array}$ mm+1, CE\u03f5 is All-k calibrated and All-k consistency. ", "page_idx": 4}, {"type": "text", "text": "Lemma 2 and Theorem 2 mean that $\\mathrm{CE}_{\\epsilon}$ performs well not only on the top-1 prediction, but also on the top- $k$ predictions for any $k\\in[K]$ . We show the All- $k$ consistency property of different losses in Table 1, the consistency of other losses refer to [8]. ", "page_idx": 4}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/8cee547926e2c213779ff92cd69c0a0978db4cde9f11f03c20b0eab966b3b556.jpg", "table_caption": ["Table 1: All- $k$ consistency between different loss functions. "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.3 Gradient Analysis of $\\epsilon$ -Softmax. ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To provide a comprehensive understanding of $\\epsilon_{\\mathrm{:}}$ -softmax in mitigating label noise, we further analyze the gradient of the CE loss when combined with $\\epsilon$ -softmax. The gradient of $L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),y)$ with respect to the model $h(\\mathbf{x})$ can be derived as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),y)}{\\partial h(\\mathbf{x})}=\\left\\{\\begin{array}{l l}{-\\frac{1}{p_{y}+m}\\cdot\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})},}&{t=y}\\\\ {-\\frac{1}{p_{y}}\\cdot\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})},}&{t\\neq y}\\end{array},\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $f=\\epsilon$ -softmax $\\circ h$ , $,\\mathbf{p}(\\mathbf{x})=\\mathbf{softmax}(h(\\mathbf{x}))$ denotes the probabilities by standard softmax, and $t=\\arg\\operatorname*{max}_{k\\in[K]}p_{k}$ is the class with the largest value in prediction probabilities. ", "page_idx": 4}, {"type": "text", "text": "Remark. The gradient in Equation 3.4 shows that $\\mathrm{CE}_{\\epsilon}$ will be equivalent to the standard CE if the maximum prediction is not the target class (i.e., $t\\neq y$ ), in which the division of $m+1$ in probabilities is omitted due to the partial deviation. Conversely, when the prediction class $t$ matches the target class $y$ , the gradient undergoes dynamic scaling by $\\frac{p_{y}}{p_{y}+m}$ . This scaling results in smaller gradients, akin to a form of soft early-stopping [20], which facilitates the mitigation of overfitting to noisy labels. Such a characteristic enables Deep Neural Networks (DNNs) to efficiently fit clean samples in the early phases of training [21, 20], while simultaneously preventing the overfitting of noisy labels in the later stages of the training process. As illustrated in Figure 1(b), $\\mathrm{CE}_{\\epsilon}$ achieves a stable test accuracy curve, even in the challenging scenario with 0.8 symmetric label noise, without overfitting to noisy labels. On the contrary, CE with the standard softmax tends to rapidly overfit to noisy labels after the early phase of training, leading to poor performance. ", "page_idx": 4}, {"type": "image", "img_path": "vjsd8Bcipv/tmp/08b60552ff10d5ab0bbf3808bd679005c7d8fa6e5be74fdee5b5a3bf2bde195f.jpg", "img_caption": ["Figure 1: Test accuracies on CIFAR-10 under symmetric noise with different $m$ , where the red box represents the zoomed-in accuracies of the last 20 epochs. (a) and (b) illustrate $\\mathrm{CE_{\\epsilon}}$ with 0 (clean) and 0.8 noise rates, respectively. (c) and (d) illustrate $\\mathrm{CE_{\\epsilon}+M A E}$ $\\alpha=0.01$ , $\\beta=5$ ) similarly. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "3.4 Better Trade-off between Robustness and Effective Learning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "It can be noted that the incorporation of $\\epsilon$ -softmax somewhat sacrifices the fitting ability of the CE loss on clean datasets, as shown in Figure 1(a). Therefore, we need to enhance the fitting ability using additional techniques. Inspired by the Active Passive Loss [6], we propose to accommodate with the symmetric loss MAE. For instance, we formulate the combination of $\\mathrm{CE_{\\epsilon}}$ and MAE (a.k.a., $\\mathrm{CE_{\\epsilon}+M A E}$ ) as follows ", "page_idx": 5}, {"type": "equation", "text": "$$\nL_{\\mathrm{CE_{\\epsilon}+M A E}}=\\alpha\\cdot L_{\\mathrm{CE_{\\epsilon}}}+\\beta\\cdot L_{\\mathrm{MAE}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "ditto for $\\mathrm{FL_{\\epsilon}+M A E}$ . ", "page_idx": 5}, {"type": "text", "text": "Lemma 3. For any loss function $L_{\\epsilon}$ with $\\epsilon$ -softmax and symmetric loss function Lsymmetric defined in Equation 1.1, the excess risk bound of $\\alpha\\cdot L_{\\epsilon}+\\beta\\cdot L_{s y m m e t r i c}$ is equivalent to that of $\\alpha\\cdot L_{\\epsilon}$ . ", "page_idx": 5}, {"type": "text", "text": "Lemma 3 suggests that the $\\epsilon$ -softmax-enhanced loss function $L_{\\epsilon}$ can be seamlessly integrated with any symmetric loss function while not modifying the inherent robustness. As can be noticed in Figure 1(c) and Figure 1(d), $\\mathrm{CE_{\\epsilon}+M A E}$ not only depicts strong fitting capabilities but also achieves better noise tolerance. More interestingly, the test accuracy on clean datasets obtained by $\\mathrm{CE_{\\epsilon}+M A E}$ even exceeds that of the standard CE loss. ", "page_idx": 5}, {"type": "text", "text": "Strict Convexity of $\\mathbf{C}\\mathbf{E}_{\\epsilon}{+}\\mathbf{M}\\mathbf{A}\\mathbf{E}$ . To elaborate on how the combination of $\\mathrm{CE_{\\epsilon}}$ and MAE can overcome the underfitting issue, we conduct an in-depth analysis from the optimization perspective. When the prediction $t=y$ , the gradients of $\\mathrm{CE}_{\\epsilon}$ , CE and MAE w.r.t. $p_{y}\\in(0,1]$ , are $\\textstyle-{\\frac{1}{p_{y}+m}},-{\\frac{1}{p_{y}}}$ and $-2$ , respectively. As can be seen, CE and $\\mathrm{CE}_{\\epsilon}$ are strictly convex, while MAE exhibits linearity. Moreover, CE has stronger convexity compared to $\\mathrm{CE_{\\epsilon}}$ (specifically, the gradient of CE changes more rapidly as $1/p_{y}^{2}>1/(\\bar{p_{y}}+m)^{2})$ , rendering CE more susceptible to overfitting noisy labels while $\\mathrm{CE_{\\epsilon}}$ suffering from underfitting for large $m$ , as illustrated in Figure 1(a) and Figure 1(b). Conversely, owing to the linearity, MAE treats every sample equally, making it robust to label noise but leading to more training time for convergence [11]. Hence, the combination of $\\mathrm{CE}_{\\epsilon}$ and MAE, which notably forms a strictly convex function (where the convexity can be controlled by $m$ ), can provide better trade-off between robustness and effective learning. ", "page_idx": 5}, {"type": "text", "text": "Association with APL. Additionally, our proposed $\\mathrm{CE_{\\epsilon}+M A E}$ coincides with the concept of active and passive losses in [6]. Specifically, for a loss function denoted as $L(f(\\mathbf{x}),y)=\\ell_{1}(\\dot{f}(\\mathbf{x}),y)\\,+$ $\\begin{array}{r}{\\sum_{k\\neq y}\\ell_{2}(f(\\mathbf{x}),k),}\\end{array}$ , $L$ is active if $\\ell_{2}(f(\\mathbf{x}),k)=0$ for any $k\\neq y$ , and $L$ is passive if $\\ell_{2}(f(\\mathbf{x}),k)\\neq0$ for some $k\\neq y$ . Active losses only explicitly maximize the target probability $f(\\mathbf{x})_{y}$ , while passive losses also explicitly minimize non-target probabilities $\\{f(\\mathbf{x})_{k}\\}_{k\\neq y}$ . For example, CE is an active loss, while MAE is passive. Based on these two loss terms, Ma et al. [6] proposed to combine a robust active loss and a robust passive loss into an \u201cActive Passive Loss\u201d (APL) framework for improving ", "page_idx": 5}, {"type": "text", "text": "Table 2: Last epoch test accuracies $(\\%)$ of different methods on CIFAR-10/100 symmetric and asymmetric noise. The results \"mean\u00b1std\" are reported over 3 random runs and the top-2 best results are boldfaced. ", "page_idx": 6}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/a2c0a7bd126a1ca5f1df19278dd44a21b417c6379592b71815c05530663b93f8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "sufficient learning with underfitting losses. Note that $\\mathrm{CE}_{\\epsilon}$ is also active, thus $\\mathrm{CE_{\\epsilon}+M A E}$ coincides with the APL framework and further mitigates the underfitting issue. ", "page_idx": 6}, {"type": "text", "text": "To further validate $\\mathrm{CE_{\\epsilon}+M A E}$ , we incorporate it with sample selection, pseudo-label prediction [22], and MixUp [23], culminating in a semi-supervised learning algorithm we term ${\\cal{C}}\\mathrm{E}_{\\epsilon}{+}\\mathrm{MAE}$ (Semi). The algorithm details can be found in the Appendix C. In our experiments, we use $\"C_{\\mathrm{E}_{\\epsilon}+\\mathrm{MAE}}$ (Semi)\" to ensure a fair comparison with other hybrid methods with sample selection and semi-supervised learning (SSL). No additional techniques are utilized for $\"\\mathrm{CE}_{\\epsilon}{+}\\mathrm{MAE}\"$ . ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we conduct extensive experiments to validate the superiority of $\\epsilon_{}$ -softmax in mitigating label noise. Complete experimental setting and results can be found in the Appendix D and E. ", "page_idx": 6}, {"type": "text", "text": "4.1 Evaluation on Benchmark Datasets ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate our proposed methods on benchmark datasets CIFAR-10 / CIFAR-100 [24] with synthetic label noise, following [6, 7]. ", "page_idx": 6}, {"type": "text", "text": "Baselines. We consider several baseline methods for comparison, including Standard CE and FL [19]; MAE; GCE [11]; NLNL [25]; SCE [12]; APL [6], including NCE $\\cdot+.$ MAE, NCE+RCE, and NFL $^{,+}$ RCE; AFLs [7], including NCE $^+$ AEL, NCE $+.$ AGCE, and NCE $+.$ AUL; LDR-KL [8]; and LogitClip [26], including CE+LC. ", "page_idx": 6}, {"type": "text", "text": "Table 3: Ablation experiments on CIFAR-100. The results \"mean $\\pm$ std\" are reported over 3 random runs and the best results are boldfaced. If $m=0$ , ${\\cal{C}}\\mathrm{{E}_{\\epsilon}+\\mathrm{{MAE}}}$ equals $\\scriptstyle\\mathrm{CE+MAE}$ . ", "page_idx": 7}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/7f0cb0f8f04a0de43a66bc54d9a3da4e9478e0ee91e771243de5e16636729a71.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "vjsd8Bcipv/tmp/ef67e1e6525146b947ee8900c96dd2b207f6863492f01efa1c56f68ed907763c.jpg", "img_caption": ["Figure 2: Visualizations of learned representations on CIFAR-10 with symmetric label noise. The x-axis and y-axis represent the first and second dimensions of the 2D embeddings, respectively. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Results. Table 2 presents the test accuracy of various loss functions under symmetric and asymmetric label noise. As can be seen, our proposed $\\epsilon$ -softmax-enhanced loss functions, $\\mathrm{CE_{\\epsilon}+M A E}$ and $\\mathrm{FL_{\\epsilon}+M A E}$ , demonstrate remarkable performance, ranking among the top-2 in most cases across both datasets. These methods consistently outperform others such as GCE, SCE, NLNL, $\\scriptstyle\\mathrm{NCE+MAE}$ and LDR-KL, regardless of the noise rates. In scenarios of clean labels, $\\mathrm{CE_{\\epsilon}+M A E}$ and $\\mathrm{FL_{\\epsilon}+M A E}$ also exhibit strong fitting abilities, outperforming $\\mathrm{NCE+RCE}$ and $\\scriptstyle\\mathrm{NCE+AGCE}$ . In particular, on CIFAR-100 with 0.4 asymmetric noise, most robust loss functions have no effect, but our methods achieve over $48\\%$ accuracy, significantly outperforming all other methods. These findings underscore the robustness and effectiveness of $\\epsilon_{}$ -softmax-enhanced loss functions, delivering their excellent performance in various noise scenarios. ", "page_idx": 7}, {"type": "text", "text": "Ablation Experiments. We perform detailed ablation experiments to further explore the role of each component and hyperparameter $m$ in our $\\mathrm{CE_{\\epsilon}+M A E}$ , experimental results are shown in Table 3. We can observe that CE will severely fit the noise label, and the symmetric loss MAE is difficult to optimize. $\\scriptstyle\\mathrm{CE+MAE}$ (i.e., $m=0$ ) is a trade-off between robustness and fitting ability, increasing noise tolerance at the cost of reducing fitting ability on clean labels, consistent with previous works [11, 12, 13]. In particular, our $\\mathrm{CE_{\\epsilon}+M A E}$ shows remarkable properties. As the parameter $m$ experiences a moderate increase, $\\mathrm{CE_{\\epsilon}+M A E}$ not only achieves noise tolerance for symmetric and asymmetric noise, but also achieves effective learning for the clean scenario. Additionally, the experimental results suggest that strict constraints are better suited for symmetric noise, while looser constraints are more effective for asymmetric noise. ", "page_idx": 7}, {"type": "text", "text": "Visualization. We conduct a further analysis to compare the effectiveness of $\\mathrm{CE_{\\epsilon}+M A E}$ and traditional CE in learning representations. We train models with different label noise and use the trained models to extract feature representations of the test set by t-SNE [27]. The visualizations for CIFAR-10 symmetric noise are depicted in Figure 2. Notably, the embeddings generated by CE show evident overfitting to label noise, as seen in the blending of embeddings from distinct classes. In sharp contrast, embeddings from the $\\mathrm{CE_{\\epsilon}+M A E}$ method consistently form clear, well-separated clusters, demonstrating its superior ability to learn robust and distinct representations under noisy label conditions. ", "page_idx": 7}, {"type": "text", "text": "4.2 Evaluation on Human-Annotated Datasets ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We further conduct comparison studies on human-annotated datasets CIFAR-10N/CIFAR-100N [28], following the experiment setting in [28]. ", "page_idx": 7}, {"type": "text", "text": "Table 4: Best epoch test accuracies $(\\%)$ of different methods on CIFAR-N datasets. We compare methods without and with semi-supervised learning (SSL) and sample selection. The results \"mean\u00b1std\" are reported over 5 random runs and the best results are boldfaced. ", "page_idx": 8}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/83448d30dc32952468c7a322335f31e019e6dd4aeed2ba18d39c204b82408b6b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/d3814624e1625eaa1ecd00004a3fb40dfa7498d0d0635c73e5abc96d95b4eceb.jpg", "table_caption": ["Table 5: Last epoch accuracies $(\\%)$ on the WebVision and ILSVRC12 validation sets and the Clothing1M test set. The best results are boldfaced. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Baselines. For a fair comparison, we divide the baselines into those without and those with semisupervised learning (SSL) and sample selection: ", "page_idx": 8}, {"type": "text", "text": "\u2013 Without SSL: Standard loss CE, Forward T [29], GCE [11], T-Revision [30], Peer Loss [31], F-Div [32], Negative-LS [33], VolMinNet [34], and AGCE [35]. ", "page_idx": 8}, {"type": "text", "text": "\u2013 With SSL: Co-teaching+ [36], JoCoR [37], $\\mathrm{ELR+}$ [38], DivideMix [39], CORES\\* [40], CAL [41], PES (Semi) [20], $\\mathrm{SOP+}$ [42], and Proto-semi [43]. ", "page_idx": 8}, {"type": "text", "text": "Results. Table 4 reports the test accuracy results of each method on the human-annotated datasets. The results show that the proposed $\\mathrm{CE_{\\epsilon}+M A E}$ and ${\\cal{C}}\\mathrm{{E}_{\\epsilon}+\\mathrm{{MAE}}}$ (Semi) provide significant improvements in handling human-annotated label noise, especially at high noise rates. Among the methods without SSL, $\\mathrm{CE_{\\epsilon}+M A E}$ stands out on the CIFAR-100N \"Noisy\" case as the only method to exceed $61\\%$ accuracy. Within the methods with SSL, ${\\cal{C}}\\mathrm{{E}_{\\epsilon}+\\mathrm{{MAE}}}$ (Semi) shows a pronounced superiority in all scenarios, especially in the most difficult CIFAR-10N \"Worst\" case and CIFAR-100N \"Noisy\" case. In the CIFAR-10N \"Worst\" case, $\\mathrm{CE_{\\epsilon}+M A E}$ (Semi) achieves an impressive accuracy rate of over $95\\%$ , significantly outperforming competing methods. These results underscore the effectiveness of the $\\epsilon$ -softmax-enhanced loss function in counteracting label noise for human-annotated scenarios. ", "page_idx": 8}, {"type": "text", "text": "4.3 Evaluation on the Real-World Datasets ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We perform experiments on massively real-world noisy datasets, including WebVision [44], ILSVRC12 (ImageNet) [45] and Clothing1M [46], following the experiment setting in [7]. ", "page_idx": 8}, {"type": "text", "text": "Results. In Table 5, we showcase the accuracies achieved on WebVision, ILSVRC12 and Clothing1M by various leading methods. Notably, our $\\mathrm{CE_{\\epsilon}+M A E}$ method outshines others, achieving the highest results on all real-world datasets. It surpasses CE by approximately $5.5\\%$ on WebVision and $6.5\\%$ on ILSVRC12. For Clothing1M, we finetune a pretrained ResNet-50, so the differences between the methods are relatively small, but our method still achieves the best accuracy. These results underline the robustness and efficacy of the $\\epsilon$ -softmax-enhanced loss function in real-world scenarios. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we introduced $\\epsilon$ -softmax, a simple yet effective and theoretically sound scheme for noise-tolerant learning. Our method is not only easy to implement but also can be seamlessly integrated with any softmax-based DNNs, requiring just two additional lines of code. Our rigorous and comprehensive theoretical analysis reveals that $\\epsilon$ -softmax effectively alleviates the common issue of overfitting to noisy labels. Furthermore, we propose to incorporate $\\epsilon$ -softmax-enhanced loss functions with MAE, achieving better trade-off between effective learning and robustness. Extensive experimental results demonstrate the superior performance of our method in mitigating label noise. ", "page_idx": 9}, {"type": "text", "text": "Broader Impacts ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work has the potential to advance the development of machine learning methods that can be deployed in contexts where it is costly to gather accurate annotations. This is an important issue in applications such as medicine, where machine learning has great potential societal impact. This work will not have negative social impacts. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by National Natural Science Foundation of China under Grants 92270116, 62071155 and 632B2031, and in part by the Fundamental Research Funds for the Central Universities (Grant No. HIT.DZJJ.2023075). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436\u2013444, 2015.   \n[2] Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, Ivor W Tsang, James T Kwok, and Masashi Sugiyama. A survey of label-noise representation learning: Past, present and future. arXiv preprint arXiv:2011.04406, 2020.   \n[3] Devansh Arpit, Stanis\u0142aw Jastrz\u02dbebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. A closer look at memorization in deep networks. In International conference on machine learning, pages 233\u2013242. PMLR, 2017.   \n[4] Collin Burns, Pavel Izmailov, Jan Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, Adrien Ecoffet, Manas Joglekar, Jan Leike, et al. Weak-to-strong generalization: Eliciting strong capabilities with weak supervision. arXiv preprint arXiv:2312.09390, 2023.   \n[5] Aritra Ghosh, Himanshu Kumar, and P Shanti Sastry. Robust loss functions under label noise for deep neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 31, 2017.   \n[6] Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, and James Bailey. Normalized loss functions for deep learning with noisy labels. In International conference on machine learning, pages 6543\u20136553. PMLR, 2020.   \n[7] Xiong Zhou, Xianming Liu, Junjun Jiang, Xin Gao, and Xiangyang Ji. Asymmetric loss functions for learning with noisy labels. In International conference on machine learning, pages 12846\u201312856. PMLR, 2021.   \n[8] Dixian Zhu, Yiming Ying, and Tianbao Yang. Label distributionally robust losses for multi-class classification: Consistency, robustness and adaptivity. In International Conference on Machine Learning, pages 43289\u201343325. PMLR, 2023.   \n[9] Naresh Manwani and PS Sastry. Noise tolerance under risk minimization. IEEE transactions on cybernetics, 43(3):1146\u20131151, 2013.   \n[10] Brendan Van Rooyen, Aditya Menon, and Robert C Williamson. Learning with symmetric label noise: The importance of being unhinged. Advances in neural information processing systems, 28, 2015.   \n[11] Zhilu Zhang and Mert Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. Advances in neural information processing systems, 31, 2018.   \n[12] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross entropy for robust learning with noisy labels. In Proceedings of the IEEE/CVF international conference on computer vision, pages 322\u2013330, 2019.   \n[13] Erik Englesson and Hossein Azizpour. Generalized jensen-shannon divergence loss for learning with noisy labels. Advances in Neural Information Processing Systems, 34:30284\u201330297, 2021.   \n[14] Xiong Zhou, Xianming Liu, Chenyang Wang, Deming Zhai, Junjun Jiang, and Xiangyang Ji. Learning with noisy labels via sparse regularization. In Proceedings of the IEEE/CVF international conference on computer vision, pages 72\u201381, 2021.   \n[15] Patrik O Hoyer. Non-negative matrix factorization with sparseness constraints. Journal of machine learning research, 5(9), 2004.   \n[16] Xiong Zhou, Xianming Liu, Hao Yu, Jialiang Wang, Zeke Xie, Junjun Jiang, and Xiangyang Ji. Variance-enlarged poisson learning for graph-based semi-supervised learning with extremely sparse labeled data. In The Twelfth International Conference on Learning Representations, pages 1\u201319, 2024.   \n[17] Forest Yang and Sanmi Koyejo. On the consistency of top-k surrogate losses. In International Conference on Machine Learning, pages 10727\u201310735. PMLR, 2020.   \n[18] Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. Journal of the American Statistical Association, 101(473):138\u2013156, 2006.   \n[19] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision, pages 2980\u20132988, 2017.   \n[20] Yingbin Bai, Erkun Yang, Bo Han, Yanhua Yang, Jiatong Li, Yinian Mao, Gang Niu, and Tongliang Liu. Understanding and improving early stopping for learning with noisy labels. Advances in Neural Information Processing Systems, 34:24392\u201324403, 2021.   \n[21] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. Advances in neural information processing systems, 31, 2018.   \n[22] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semisupervised learning with consistency and confidence. Advances in neural information processing systems, 33:596\u2013608, 2020.   \n[23] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. In International Conference on Learning Representations, 2018.   \n[24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[25] Youngdong Kim, Junho Yim, Juseung Yun, and Junmo Kim. Nlnl: Negative learning for noisy labels. In Proceedings of the IEEE/CVF international conference on computer vision, pages 101\u2013110, 2019.   \n[26] Hongxin Wei, Huiping Zhuang, Renchunzi Xie, Lei Feng, Gang Niu, Bo An, and Yixuan Li. Mitigating memorization of noisy labels by clipping the model prediction. In International Conference on Machine Learning, pages 36868\u201336886. PMLR, 2023.   \n[27] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008.   \n[28] Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu. Learning with noisy labels revisited: A study using real-world human annotations. In International Conference on Learning Representations, 2021.   \n[29] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1944\u20131952, 2017.   \n[30] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi Sugiyama. Are anchor points really indispensable in label-noise learning? Advances in neural information processing systems, 32, 2019.   \n[31] Yang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing noise rates. In International conference on machine learning, pages 6226\u20136236. PMLR, 2020.   \n[32] Jiaheng Wei and Yang Liu. When optimizing f-divergence is robust with label noise. In International Conference on Learning Representations, 2021.   \n[33] Jiaheng Wei, Hangyu Liu, Tongliang Liu, Gang Niu, Masashi Sugiyama, and Yang Liu. To smooth or not? when label smoothing meets noisy labels. In International Conference on Machine Learning, pages 23589\u201323614. PMLR, 2022.   \n[34] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. Provably end-to-end label-noise learning without anchor points. In International conference on machine learning, pages 6403\u20136413. PMLR, 2021.   \n[35] Xiong Zhou, Xianming Liu, Deming Zhai, Junjun Jiang, and Xiangyang Ji. Asymmetric loss functions for noise-tolerant learning: Theory and applications. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.   \n[36] Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama. How does disagreement help generalization against label corruption? In International Conference on Machine Learning, pages 7164\u20137173. PMLR, 2019.   \n[37] Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo An. Combating noisy labels by agreement: A joint training method with co-regularization. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 13726\u201313735, 2020.   \n[38] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Earlylearning regularization prevents memorization of noisy labels. Advances in neural information processing systems, 33:20331\u201320342, 2020.   \n[39] Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020.   \n[40] Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu. Learning with instance-dependent label noise: A sample sieve approach. In International Conference on Learning Representations, 2021.   \n[41] Zhaowei Zhu, Tongliang Liu, and Yang Liu. A second-order approach to learning with instancedependent label noise. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10113\u201310123, 2021.   \n[42] Sheng Liu, Zhihui Zhu, Qing Qu, and Chong You. Robust training under label noise by overparameterization. In International Conference on Machine Learning, pages 14153\u201314172. PMLR, 2022.   \n[43] Renyu Zhu, Haoyu Liu, Runze Wu, Minmin Lin, Tangjie Lv, Changjie Fan, and Haobo Wang. Rethinking noisy label learning in real-world annotation scenarios from the noise-type perspective. arXiv preprint arXiv:2307.16889, 2023.   \n[44] Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database: Visual learning and understanding from web data. arXiv preprint arXiv:1708.02862, 2017.   \n[45] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A largescale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 248\u2013255, 2009. doi: 10.1109/CVPR.2009.5206848.   \n[46] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy labeled data for image classification. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2691\u20132699, 2015.   \n[47] Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. Randaugment: Practical automated data augmentation with a reduced search space. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops, pages 702\u2013703, 2020.   \n[48] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent label noise. Advances in Neural Information Processing Systems, 33:7597\u20137610, 2020. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Limitation and Discussion ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The limitation of $\\epsilon$ -softmax is that it may slightly reduce fitting ability on clean case. Therefore, we propose to combine the $\\epsilon$ -softmax-enhanced loss with the symmetric loss MAE. Consequently, our practical loss functions utilized for noise-tolerant learning exhibit a hybrid form similar to GCE and SCE, but their meanings are significantly different. ", "page_idx": 13}, {"type": "text", "text": "Comparing with GCE and SCE. GCE is a hybrid of CE and MAE var the negative Box-Cox transformation [11]. SCE combines CE with Reverse CE (RCE), where the RCE component actually acts as a scaled version of the MAE. This relationship is unveiled through the following derivation, adapted from Section 4.3 in SCE [12]: $\\begin{array}{r}{L_{\\mathrm{RCE}}=-\\sum_{k=1}^{K}p(k\\mid\\mathbf{x})\\log q(k\\mid\\mathbf{x})=-p(y\\mid\\mathbf{x})\\log1-}\\end{array}$ $\\begin{array}{r}{\\sum_{k\\neq y}p(k\\mid\\mathbf{x})A=-A\\sum_{k\\neq y}p(k\\mid\\mathbf{x})=-A(1-p(y\\mid\\mathbf{x}))=-\\frac{A}{2}L_{\\mathrm{MAE}}}\\end{array}$ . Consequently, SCE essentially translates to $\\scriptstyle\\mathrm{CE+MAE}$ . Hence, GCE and SCE increases the fitting ability but reduces the robustness because of the CE term. Conversely, our $\\mathrm{CE}_{\\epsilon}$ is inherently robust. The combination of $\\mathrm{CE}_{\\epsilon}$ and MAE does not reduce the robustness, as demonstrated by Lemma 3, and also improves the fitting ability. We perform further experiments cimparing with GCE and $\\scriptstyle\\mathrm{CE+MAE}$ (SCE), the results can be seen in Table 6. Our $\\mathrm{CE_{\\epsilon}+M A E}$ obtains obviously the best results at all noise rates, significantly outperforming GCE and $\\scriptstyle\\mathrm{CE+MAE}$ (SCE). ", "page_idx": 13}, {"type": "text", "text": "Meanwhile, we further compare our $\\epsilon$ -softmax with temperature-dependent softmax. ", "page_idx": 13}, {"type": "text", "text": "Comparing with Temperature-Dependent Softmax. softmax( $\\big[\\frac{h(x)}{\\tau}\\big]$ , where $\\tau$ is the temperature parameter, is a useful technique for making outputs sparse [14]. Compared to our $\\epsilon_{}$ -softmax, temperature-dependent softmax does not achieve a quantitative approximation to a one-hot vector for each output, and therefore cannot achieve a controllable excess risk bound. We also perform further experiments cimparing with temperature-dependent softmax. For simplicity, we refer to CE with temperature-dependent softmax as $\\mathrm{CE}_{\\tau}$ , the results can be seen in Table 6. Our $\\mathrm{CE_{\\epsilon}+M A E}$ obtains obviously the best results at all noise rates, significantly outperforming temperature-dependent softmax. ", "page_idx": 13}, {"type": "text", "text": "Table 6: Last epoch test accuracies $(\\%)$ of ablation and comparetion experiments on CIFAR-100. The results \"mean $\\pm$ std\" are reported over 3 random runs. The best results are boldfaced and the best results of each method are underlined. If $m=0$ , $\\mathrm{CE_{\\epsilon}+M A E}$ equals $\\scriptstyle\\mathrm{CE+MAE}$ . ", "page_idx": 13}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/783ab1b6efae5ae8d0459fe8eebaf31e4a0b48618f1e3b3d600338835af66d66.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "B Proof of Theorems ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Lemma 1. $\\epsilon$ -softmax can achieve \u03f5-relaxation for one-hot vectors: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{\\mathbf{u}\\in\\mathcal{P}_{\\mathbf{e}_{1}}}{\\operatorname*{min}}\\|f(\\mathbf{x})-\\mathbf{u}\\|_{2}\\le\\epsilon=\\frac{\\sqrt{1-1/K}}{m+1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $f(\\mathbf{x})=\\epsilon$ -softmax $\\u>h(\\mathbf{x})$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{u\\in\\mathcal{P}_{\\mathbf{e}_{1}}}{\\mathrm{min}}\\,\\|f(\\mathbf{x})-\\mathbf{u}\\|_{2}=\\frac{\\sqrt{1-2p_{t}+\\sum_{k=1}^{K}p_{k}^{2}}}{m+1}}\\\\ &{\\phantom{\\frac{1}{\\mathrm{min}}\\,\\|f(\\mathbf{x})-\\mathbf{u}\\|_{2}}=\\frac{\\sqrt{1-p_{t}-\\sum_{k=1}^{K}p_{k}(p_{t}-p_{k})}}{m+1}}\\\\ &{\\phantom{\\frac{1}{\\mathrm{min}}\\,\\|f(\\mathbf{x})-\\mathbf{u}\\|_{2}}\\leq\\frac{\\sqrt{1-1/K}}{m+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Theorem 1 (Excess Risk Bound under Asymmetric Noise). In a multi-class classification problem, if the loss function $L\\in{\\mathcal{L}}$ satisfies $\\begin{array}{r}{|\\sum_{k=1}^{K}(L(\\mathbf{u}_{1},k)-L(\\mathbf{u}_{2},k))|\\leq\\delta}\\end{array}$ when $\\|\\mathbf{u}_{1}-\\mathbf{u}_{2}\\|_{2}\\leq\\epsilon,$ , and $\\delta\\rightarrow0$ as $\\epsilon\\rightarrow0$ , then for asymmet ric label noise $\\eta_{\\mathbf{x},k}\\,<\\,(1-\\eta_{y})\\,,\\forall k\\,\\neq\\,y,$ , if $\\mathcal{R}_{L}(f^{*})\\,=\\,0$ , the excess risk bound for $f\\in\\mathcal{H}_{\\mathbf{v},\\epsilon}$ can be expressed as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{R}_{L}(f_{\\eta}^{*})\\leq2\\delta+\\frac{2c\\delta}{a},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $c=\\mathbb{E}_{\\mathcal{D}}\\left(1-\\eta_{y}\\right)$ , $\\begin{array}{r}{a\\mathrm{~=~}\\operatorname*{min}_{\\mathbf{x},k}(1-\\eta_{y}\\mathrm{~-~}\\eta_{\\mathbf{x},k})}\\end{array}$ , $f_{\\eta}^{*}$ and $f^{*}$ denote the global minimum of $\\mathcal{R}_{L}^{\\eta}(f)$ and $\\mathcal{R}_{L}(f)$ , respectively. ", "page_idx": 14}, {"type": "text", "text": "Proof. ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle R_{L}^{\\eta}(f)=\\mathbb{E}_{\\mathcal{D}}\\left[(1-\\eta_{y})\\,L(f({\\bf x}),y)\\right]+\\mathbb{E}_{\\mathcal{D}}\\left[\\sum_{k\\neq j}\\eta_{\\bf x}{\\bf}_{k}L(f({\\bf x}),k)\\right]}}\\\\ {\\ \\ \\ \\ \\ \\ \\leq\\mathbb{E}_{\\mathcal{D}}\\left[(1-\\eta_{y})\\left(C+\\delta-\\sum_{k\\neq j}L(f({\\bf x}),k)\\right)\\right]+\\mathbb{E}_{\\mathcal{D}}\\left[\\sum_{k\\neq j}\\eta_{\\bf x}{\\bf}_{k}L(f({\\bf x}),k)\\right]}\\\\ {\\ \\ \\ \\ =(C+\\delta)\\mathbb{E}_{\\mathcal{D}}(1-\\eta_{y})-\\mathbb{E}_{\\mathcal{D}}\\left[\\sum_{k\\neq j}(1-\\eta_{y}-\\eta_{\\bf x,k})L(f({\\bf x}),k)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\begin{array}{r}{C=\\sum_{k=1}^{K}L(\\mathbf{v},k)}\\end{array}$ , ditto ", "page_idx": 14}, {"type": "equation", "text": "$$\nR_{L}^{\\eta}(f)\\geq(C-\\delta)\\mathbb{E}_{\\mathcal{D}}(1-\\eta_{y})-\\mathbb{E}_{\\mathcal{D}}\\left[\\sum_{k\\neq y}(1-\\eta_{y}-\\eta_{\\mathbf{x},k})L(f(\\mathbf{x}),k)\\right]\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "hence, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(R_{L}^{\\eta}\\left(f^{*}\\right)-R_{L}^{\\eta}(f_{\\eta}^{*})\\right)\\le2\\delta\\mathbb{E}_{\\mathcal{D}}(1-\\eta_{y})+}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\mathbb{E}_{\\mathcal{D}}\\displaystyle\\sum_{k\\ne y}(1-\\eta_{y}-\\eta_{\\mathbf{x},k})\\left[L(f_{\\eta}^{*}(\\mathbf{x}),k)-L\\left(f^{*}(\\mathbf{x}),k\\right)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "According to the assumption $R_{L}(f^{*})=0$ , we have $L(f^{*}(\\mathbf{x}),y)=0$ then $\\begin{array}{r}{L(f^{*}(\\mathbf{x}),k)=\\frac{C}{k-1}}\\end{array}$ where $k\\neq y$ . Since $L(f_{\\eta}^{*}(\\mathbf{x}),k)-L(f^{*}(\\mathbf{x}),k)\\leq0$ where $k\\neq y$ , the second term on the right of the inequality is a non-positive value. And $R_{L}^{\\eta}\\left(f^{*}\\right)-R_{L}^{\\eta}(f_{\\eta}^{*})\\geq0$ . So we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\mathbb{E}_{\\mathcal{D}}\\displaystyle\\sum_{k\\neq y}(1-\\eta_{y}-\\eta_{\\mathbf{x},k})\\left(L(f_{\\eta}^{*}(\\mathbf{x}),k)-L(f^{*}(\\mathbf{x}),k)\\right)\\right|\\leq2c\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $c=\\mathbb{E}_{\\mathcal{D}}\\left(1-\\eta_{y}\\right)$ . ", "page_idx": 14}, {"type": "text", "text": "Let $\\begin{array}{r}{a=\\operatorname*{min}_{\\mathbf{x},k}(1-\\eta_{y}-\\eta_{\\mathbf{x},k})}\\end{array}$ , we have $\\begin{array}{r}{\\left|\\mathbb{E}_{\\mathcal{D}}\\sum_{k\\neq y}\\big(L(f_{\\eta}^{*}(\\mathbf{x}),k)-L(f^{*}(\\mathbf{x}),k)\\big)\\right|\\leq\\frac{2c\\delta}{a}}\\end{array}$ . Note that $f_{\\eta}^{*},f^{*}\\in\\mathcal{H}_{\\mathbf{v},\\epsilon}$ means that $|\\sum_{k}\\left(L(f_{\\eta}^{*}(\\mathbf{x}),k)-L(f^{*}(\\mathbf{x}),k)\\right)|\\leq2\\delta$ , then we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left|\\mathbb{E}_{\\mathcal{D}}\\left(L(f_{\\eta}^{*}(\\mathbf{x}),y)-L(f^{*}(\\mathbf{x}),y)\\right)\\right|\\leq2\\delta+\\frac{2c\\delta}{a},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "that is, $\\begin{array}{r}{\\mathcal{R}_{L}(f_{\\eta}^{*})\\leq\\mathcal{R}_{L}(f^{*})+2\\delta+\\frac{2c\\delta}{a}=2\\delta+\\frac{2c\\delta}{a}.}\\end{array}$ ", "page_idx": 15}, {"type": "text", "text": "Lemma 2. For one-hot label ${\\bf e}_{y}$ , $C E_{\\epsilon}$ is All- $k$ calibrated and All- $k$ consistency. ", "page_idx": 15}, {"type": "text", "text": "Proof. Here $f=\\epsilon$ -softmax $\\circ h$ , $\\mathbf{p}(\\cdot|\\mathbf{x})=\\mathbf{softmax}(h(\\mathbf{x}))$ denotes the probabilities by standard softmax, $p_{k}\\,\\in\\,(0,1]$ and $t\\,=\\,\\arg\\operatorname*{max}_{k\\in[K]}p_{k}$ is the class with the largest value in prediction probabilities. ", "page_idx": 15}, {"type": "text", "text": "if t = y: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),y)}{\\partial h(y|\\mathbf{x})}=\\frac{\\partial-\\log\\frac{p_{y}+m}{m+1}}{\\partial p_{y}}\\cdot\\frac{\\partial p_{y}}{\\partial h(y|\\mathbf{x})}=-\\frac{1}{m+1}\\cdot\\frac{m+1}{p_{y}+m}\\cdot\\frac{\\partial p_{y}}{\\partial h(y|\\mathbf{x})}}\\\\ &{\\quad\\quad\\quad\\quad\\quad=-\\frac{1}{p_{y}+m}\\cdot\\frac{\\partial p_{y}}{\\partial h(y|\\mathbf{x})}=-\\frac{p_{y}}{p_{y}+m}(1-p_{y}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By the first-order optimality condition \u2202LCE\u2202\u03f5h((fx()x),y) = 0, we have: py = 1. Hence, for any k \u0338= y, we have ek = 0 < ey and pk < py. ", "page_idx": 15}, {"type": "text", "text": "if $t\\neq y$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),y)}{\\partial h(y|\\mathbf{x})}=\\frac{\\partial-\\log\\frac{p_{y}}{m+1}}{\\partial p_{y}}\\cdot\\frac{\\partial p_{y}}{\\partial h(y|\\mathbf{x})}=-\\frac{1}{m+1}\\cdot\\frac{m+1}{p_{y}}\\cdot\\frac{\\partial p_{y}}{\\partial h(y|\\mathbf{x})}}\\\\ &{\\quad\\quad\\quad\\quad\\quad=-\\frac{1}{p_{y}}\\cdot\\frac{\\partial p_{y}}{\\partial h(y|\\mathbf{x})}=-(1-p_{y}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By the first-order optimality condition \u2202LCE\u2202\u03f5h((fx()x),y) = 0, we have: py = 1. Hence, for any k \u0338= y, we have $e_{k}=0<e_{y}$ and $p_{k}<p_{y}$ . ", "page_idx": 15}, {"type": "text", "text": "Hence, $\\mathrm{CE}_{\\epsilon}$ is All- $k$ calibrated. Since $\\mathrm{CE}_{\\epsilon}$ is nonnegative, so $\\mathrm{CE}_{\\epsilon}$ is All- $k$ consistency. ", "page_idx": 15}, {"type": "text", "text": "Theorem 2. For any label $\\mathbf{q}\\in\\Delta_{K}$ , let $y=\\arg\\operatorname*{max}_{k\\in[K]}q_{k}$ and $t=\\arg\\operatorname*{max}_{k\\in[K]}p_{k}\\;,\\,i f t=y$ and $\\begin{array}{r}{q_{y}-\\operatorname*{max}_{k\\neq y}q_{k}>\\frac{m}{m+1}}\\end{array}$ , $C E_{\\epsilon}$ is All- $k$ calibrated and All- $k$ consistency. ", "page_idx": 15}, {"type": "text", "text": "Proof. For $\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),\\mathbf{q})}{\\partial h(y|\\mathbf{x})}$ , we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),\\mathbf{q})}{\\partial h(y|\\mathbf{x})}=-q_{t}\\frac{m+1}{p_{t}+m}\\cdot\\frac{1}{m+1}\\cdot\\frac{\\partial p_{t}}{\\partial h(t|\\mathbf{x})}-\\sum_{k\\neq t}q_{k}\\frac{1}{p_{k}}\\cdot\\frac{\\partial p_{k}}{\\partial h(t|\\mathbf{x})}}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad=-q_{t}\\frac{1}{p_{t}+m}p_{t}(1-p_{t})-\\sum_{k\\neq t}q_{k}\\frac{1}{p_{k}}(-p_{k}p_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By the first-order optimality condition \u2202LCE\u03f5(f(x),q)= 0, we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{q_{t}\\cfrac{1}{p_{t}+m}p_{t}(1-p_{t})=\\displaystyle\\sum_{k\\neq t}q_{k}p_{t}}\\\\ {\\Rightarrow}&{q_{t}\\cfrac{1}{p_{t}+m}(1-p_{t})=1-q_{t}}\\\\ {\\Rightarrow}&{p_{t}=q_{t}(1+m)-m}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since, $\\begin{array}{r}{\\frac{m}{m+1}<q_{t}\\leq1}\\end{array}$ , we can get $0<p_{t}\\le1$ . ", "page_idx": 15}, {"type": "text", "text": "For $\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),\\mathbf{q})}{\\partial h(j\\neq y|\\mathbf{x})}$ , we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),\\mathbf{q})}{\\partial h(j\\neq y|\\mathbf{x})}=-q_{t}\\frac{1}{p_{t}+m}\\cdot\\frac{\\partial p_{t}}{\\partial h(j|\\mathbf{x})}-\\displaystyle\\sum_{k\\neq t,j}q_{k}\\frac{1}{p_{k}}\\cdot\\frac{\\partial p_{k}}{\\partial h(j|\\mathbf{x})}-q_{j}\\frac{1}{p_{j}}\\cdot\\frac{\\partial p_{j}}{\\partial h(j|\\mathbf{x})}}\\\\ {\\displaystyle=-q_{t}\\frac{1}{p_{t}+m}(-p_{j}p_{t})-\\displaystyle\\sum_{k\\neq t,j}q_{k}\\frac{q}{p_{k}}(-p_{j}p_{k})+q_{j}(p_{j}-1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By the first-order optimality condition $\\begin{array}{r}{\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),\\mathbf{q})}{\\partial h(j\\neq y|\\mathbf{x})}=0}\\end{array}$ = 0, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{q_{t}{\\frac{p_{j}p_{t}}{p_{t}+m}}+\\sum_{k\\neq t,j}q_{k}p_{j}+q_{j}p_{j}=q_{j}}\\\\ {\\Rightarrow}&{p_{j}={\\frac{q_{j}}{{\\frac{q_{t}p_{t}}{p_{t}+m}}+\\sum_{k\\neq t,j}q_{k}+q_{j}}}={\\frac{q_{j}}{{\\frac{q_{t}p_{t}}{p_{t}+m}}+1-q_{t}}}}\\end{array}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Substituting $p_{t}=q_{t}(1+m)-m$ , we can get $p_{j}=q_{j}(m+1)$ . Since $q_{t}>\\frac{m}{m+1}$ , so $\\begin{array}{r}{q_{j}<\\frac{1}{m+1}}\\end{array}$ and . ", "page_idx": 16}, {"type": "text", "text": "For $i,j~\\neq~t$ , if $q_{i}\\ <\\ q_{j}$ , we have $p_{i}~<~p_{j}$ . Consider $q_{k\\neq t}$ and $q_{t}$ , because of the condition qy \u2212qk\u0338=y>mm+1 , we have qk < qt, qt \u2212qk = qt(1 + m) \u2212m \u2212qk(m + 1) > 0. ", "page_idx": 16}, {"type": "text", "text": "Hence, $\\mathrm{CE_{\\epsilon}}$ is All- $k$ calibrated. Since $\\mathrm{CE_{\\epsilon}}$ is nonnegative, so $\\mathrm{CE}_{\\epsilon}$ is All- $k$ consistency. ", "page_idx": 16}, {"type": "text", "text": "The gradient of $\\mathbf{CE}_{\\epsilon}$ . ", "text_level": 1, "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),y)}{\\partial h(\\mathbf{x})}=\\left\\{\\begin{array}{l l}{-\\frac{1}{p_{y}+m}\\cdot\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})},}&{t=y}\\\\ {-\\frac{1}{p_{y}}\\cdot\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})},}&{t\\neq y}\\end{array},\\right.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $f=\\epsilon$ -softmax $\\circ h$ , $\\mathbf{p}(\\mathbf{x})=\\mathbf{softmax}(h(\\mathbf{x}))$ denotes the probabilities by standard softmax, and $t=\\arg\\operatorname*{max}_{k\\in[K]}p_{k}$ is the class with the largest value in prediction probabilities. ", "page_idx": 16}, {"type": "text", "text": "Proof. The proof is similar to Theorem 2. ", "page_idx": 16}, {"type": "text", "text": "if t = y: ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{{\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),y)}{\\partial h(\\mathbf{x})}}={\\frac{\\partial-\\log{\\frac{p_{y}+m}{m+1}}}{\\partial p_{y}}}\\cdot{\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})}}=-{\\frac{1}{m+1}}\\cdot{\\frac{m+1}{p_{y}+m}}\\cdot{\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})}}}\\\\ &{\\qquad\\qquad\\qquad=-{\\cfrac{1}{p_{y}+m}}\\cdot{\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})}}.}\\end{array}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "if $t\\neq y$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{{\\frac{\\partial L_{\\mathrm{CE}_{\\epsilon}}(f(\\mathbf{x}),y)}{\\partial h(\\mathbf{x})}}={\\frac{\\partial-\\log{\\frac{p_{y}}{m+1}}}{\\partial p_{y}}}\\cdot{\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})}}=-{\\frac{1}{m+1}}\\cdot{\\frac{m+1}{p_{y}}}\\cdot{\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})}}}\\\\ &{\\qquad\\qquad\\qquad=-{\\frac{1}{p_{y}}}\\cdot{\\frac{\\partial p_{y}}{\\partial h(\\mathbf{x})}}.}\\end{array}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Lemma 3. For any loss function $L_{\\epsilon}$ with $\\epsilon$ -softmax and symmetric loss function Lsymmetric defined in Equation 1.1, the excess risk bound of $\\alpha\\cdot L_{\\epsilon}+\\beta\\cdot L_{s y m m e t r i c}$ is equivalent to that of $\\alpha\\cdot L_{\\epsilon}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. For $\\mathbf{u}_{1},\\mathbf{u}_{2}\\in\\mathcal{H}_{\\mathbf{v},\\epsilon}$ and ${\\bf u}_{3},{\\bf u}_{4}\\in\\Delta_{K}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{\\displaystyle|\\sum_{k=1}^{K}(\\alpha\\cdot L_{\\epsilon}({\\bf u}_{1},k)+\\beta\\cdot L_{\\mathrm{symmetric}}({\\bf u}_{3},k))-\\sum_{k=1}^{K}(\\alpha\\cdot L_{\\epsilon}({\\bf u}_{2},k)+\\beta\\cdot L_{\\mathrm{symmetric}}({\\bf u}_{4},k))\\left[\\begin{array}{c}{\\displaystyle|}\\\\ {\\displaystyle|}\\\\ {\\displaystyle|=|\\sum_{k=1}^{K}\\alpha\\cdot L_{\\epsilon}({\\bf u}_{1},k)-\\sum_{k=1}^{K}\\alpha\\cdot L_{\\epsilon}({\\bf u}_{2},k)+0\\right|}\\\\ {\\displaystyle=\\alpha\\cdot|\\sum_{k=1}^{K}\\cdot L_{\\epsilon}({\\bf u}_{1},k)-\\sum_{k=1}^{K}\\cdot L_{\\epsilon}({\\bf u}_{2},k)|}\\\\ {\\displaystyle<\\alpha\\cdot\\delta}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/4803ac0365c9d75e05eb6d1afd8cc901a45b30ef3e6daf983dbd9317394e1a7c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "For sample selection: We simply select $k$ samples from each class with the least loss as clean samples. For CIFAR-10N, we set $k=2500$ for \u201cWorst\u201d case and 3500 for others. For CIFAR-100N, we set $k\\,=\\,250$ for \u201cNoisy\u201d case and 350 for others. In practice, if $k\\,>\\,|\\mathrm{sample\\_num}|$ , we set $k=|\\mathrm{sample\\_num}|-20$ . ", "page_idx": 17}, {"type": "text", "text": "For pseudo-label prediction: In the actual training, we do the pseudo-label prediction using two standard augment versions from the sample. We add the probabilities and divide by 2 to make the pseudo-label prediction. At the same time, we set the threshold $\\sigma=0.2$ and discard the samples whose prediction probability is less than the threshold. ", "page_idx": 17}, {"type": "text", "text": "For the Augment to $\\mathcal{D}_{u}$ , we employ RandAugment [47]. We set the trade-off parameter $\\lambda$ to grow linearly from 0 to 1 over 200 epochs. The MixUp parameter $\\alpha$ is set to 0.75 for epochs less than 100, and adjusted to 4 for epochs greater than 100. $\\mathrm{CE}_{\\epsilon}+\\mathrm{MAE}\\,m=1e4,\\alpha=0.5,\\beta=1\\,\\mathrm{i}$ s the same as the CIFAR-N experiment for the robust learning stage and $m=10,\\alpha=1,\\beta=1$ for the semi-supervised learning stage. In $\\mathrm{CE_{\\epsilon}+M A E}$ (Semi), we ensemble the outputs of two networks during inference and exchange the samples selected by the two networks during training, as is customary for methods that train two networks simultaneously [21, 36, 39, 38]. ", "page_idx": 17}, {"type": "text", "text": "D Experiments ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "D.1 Evaluation on Benchmark Datasets ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Noise Generation. We follow the approach of previous studies [6, 7] to experiment with two types of synthetic label noise: symmetric (uniform) noise and asymmetric (class-conditional) noise. In the case of symmetric label noise, we intentionally corrupt the training labels by randomly flipping labels within each class to incorrect labels in other classes. As for asymmetric label noise, we flip the labels within a specific sets of classes: For CIFAR-10, the flips occur from TRUCK $\\rightarrow$ AUTOMOBILE, BIRD $\\rightarrow$ AIRPLANE, DEER $\\rightarrow\\mathrm{HORSE}$ , and $\\mathrm{CAT}\\leftrightarrow\\mathrm{DOG}$ . For CIFAR-100, the 100 classes are grouped into 20 super-classes, each containing 5 sub-classes, and we flip the labels within the same super-class into the next. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Experimental Setting. We follow the same experimental settings in [6, 7]: An 8-layer CNN is used for CIFAR-10 and a ResNet-34 for CIFAR-100. The networks are trained for 120 and 200 epochs for CIFAR-10 and CIFAR-100 with batch size 128. We use the SGD optimizer with momentum 0.9 and cosine learning rate annealing. The weight decay is set to $1\\times10^{-4}$ and $1\\times10^{-5}$ for CIFAR-10 and CIFAR-100. The initial learning rate is set to 0.01 for CIFAR-10 and 0.1 for CIFAR-100. Clipping the gradient norm to 5.0 and the minimum allowable value for log to $1\\times10^{-8}$ . Typical data augmentations including random shift and horizontal flip are applied to CIFAR-10; random shift, horizontal flip and random rotation are applied to CIFAR-100. ", "page_idx": 18}, {"type": "text", "text": "Parameters Setting. We set the parameter settings which match their original papers for all baseline methods [6, 7]. Specifically, for $\\mathrm{FL}$ , we set $\\gamma=0.5$ . For GCE, we set $q=0.7$ for CIFAR-10, and $q=$ [0.5, 0.5, 0.7, 0.7, 0.9] for CIFAR-100 clean and symmetric noise $(\\eta\\in[0,0.2,0.4,0.6,0.8])$ , $q=0.7$ asymmetric noise. For SCE, we set $A=-4$ , $\\alpha=0.1$ , $\\beta=1$ for CIFAR-10, and $\\alpha=6$ , $\\beta=0.1$ for CIFAR-100. For APL $(\\mathrm{NCE+MAE}$ , $\\mathrm{NCE+RCE}$ and $\\mathrm{NFL+RCE}$ ), we set $\\alpha=1,\\beta=1$ for CIFAR-10, and $\\alpha\\,=\\,10$ , $\\beta\\,=\\,0.1$ for CIFAR-100. For $\\mathrm{NCE+AUL}$ , we set $a\\,=\\,6.3,q\\,=\\,1.5,\\alpha\\,=\\,1,\\beta\\,=\\,4$ for CIFAR-10, and $a\\,=\\,6,q\\,=\\,3,\\alpha\\,=\\,10,\\beta\\,=\\,0.015$ for CIFAR-100. For $\\scriptstyle\\mathrm{NCE+AGCE}$ , we set $a=6,q=1.5,\\alpha=1,\\beta=4$ for CIFAR-10, and $a=1.8,q=3,\\alpha=10,\\beta=0.1$ for CIFAR-100. Fo $\\cdot\\,\\mathrm{NCE}{+}\\mathrm{AEL}$ , we set $a\\,=\\,5,\\alpha\\,=\\,1,\\beta\\,=\\,4$ for CIFAR-10, and $a\\,=\\,1.5,\\alpha\\,=\\,10,\\beta\\,=\\,0.1$ for CIFAR-100. For $\\mathrm{CE+LC}$ , we set $\\delta\\,=\\,[1,1,1,1.5,1.5]$ for CIFAR-10 clean and symmetric noise $(\\eta~\\in~[0,0.2,0.4,0.6,0.8])$ and $\\delta~=~2.5$ for CIFAR-10 asymmetric noise. We set $\\delta~=~2.5$ for CIFAR-100 asymmetric noise and $\\delta=0.5$ for others. For LDR-KL, We set $\\lambda=10$ for CIFAR-10 and 1 for CIFAR-100. For our $\\mathrm{CE_{\\epsilon}+M A E}$ , we set $\\beta\\,=\\,5,m\\,=\\,1e5,\\alpha\\,=\\,0.01$ for CIFAR-10 symmetric, and $m=1e3$ , $\\alpha=0.02$ for asymmetric. For CIFAR-100, we set $\\beta=1$ , $m=1e4$ and $\\alpha=[0.1,0.05,0.03,0.0125,0.0075]$ for clean and symmetric noise $(\\eta\\in[0,0.2,0.4,0.6,0.8])$ , and $m=1e2$ , $\\alpha=[0.015,0.007,0.005,0.004]$ for asymmetric noise $\\mathit{\\check{\\Psi}}\\left[\\eta\\in\\left[0.1,0.2,0.3,0.4\\right]\\right)$ . For our $\\mathrm{FL_{\\epsilon}+M A E}$ , we set $\\gamma=0.1$ and others are same as $\\mathrm{CE_{\\epsilon}+M A E}$ . For NLNL, we use the results in [7] directly. ", "page_idx": 18}, {"type": "text", "text": "D.2 Evaluation on Human-Annotated Datasets ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Experimental Setting. We follow the experimental settings in [28]: Train a Resnet-34 using SGD for 100 epochs with initial learning rate 0.1, momentum 0.9, and weight decay 0.0005. Set the learning rate decay 0.1 at 60 epochs. Standard data augmentation including random shift and horizontal flip are applied. Best epoch test accuracies are compared. The results of the comparison methods are taken directly from [28] and the original papers [35, 43]. ", "page_idx": 18}, {"type": "text", "text": "Parameters Setting. For our ${\\cal{C}}\\mathrm{{E}_{\\epsilon}+\\mathrm{{MAE}}}$ , we set $m=1e4,\\alpha=0.5,\\beta=1$ for CIFAR-10N/100N.   \n${\\cal{C}}\\mathrm{{E}_{\\epsilon}+\\mathrm{{MAE}}}$ (Semi) has been covered in detail in the previous section C. ", "page_idx": 18}, {"type": "text", "text": "D.3 Evaluation on Real-World Dataset WebVision ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Experimental Setting. For WebVision, the training details follow [7]: We use the mini WebVision setting [6, 7] and train a ResNet-50 using SGD for 250 epochs with initial learning rate 0.4, nesterov momentum 0.9 and weight decay $3\\times10^{\\bar{-5}}$ and batch size 256. The learning rate is multiplied by 0.97 after each epoch of training. All the images are resized to $224\\times224$ . Typical data augmentations including random width/height shift, color jittering, and horizontal flip are applied. We train the model on Webvision and evaluate the trained model on the same 50 concepts on the corresponding WebVision and ILSVRC12 validation sets. ", "page_idx": 18}, {"type": "text", "text": "For Clothing1M, we use ResNet-50 pre-trained on ImageNet similar to [46]. All the images are resized to $224\\times224$ . We use SGD with a momentum of 0.9, a weight decay of $1\\times10^{-3}$ , and batch size of 256. We train the network for 10 epochs with a learning rate of $5\\times10^{-3}$ and a decay of 0.1 at 5 epochs. Typical data augmentations including random shift and horizontal flip are applied. ", "page_idx": 18}, {"type": "text", "text": "Parameters Setting. We set the best parameter settings which match their original papers for all baseline methods [6, 7]. Specifically, for GCE, we set $q=0.7$ for WebVision and 0.6 for Clothing1M. ", "page_idx": 18}, {"type": "text", "text": "For SCE, we set $A=-4$ , $\\alpha=10$ , $\\beta=1$ . For $\\mathrm{NCE+RCE}$ , we set $\\alpha=50,\\beta=0.1$ for WebVision and $\\alpha=10,\\beta=1$ for Clothing1M. For AGCE, we set $a\\mathrm{~=~}1e\\mathrm{~-~}5,q\\mathrm{~=~}0.5$ . For $\\scriptstyle\\mathrm{NCE+AGCE}$ , we set $a=2.5,q=3,\\alpha=50,\\beta=0.1$ . For LDR-KL, we set $\\lambda=1$ . For our ${\\cal{C}}\\mathrm{{E}_{\\epsilon}+\\mathrm{{MAE}}}$ , we set $m=1e3,\\alpha=0.015,\\beta=0.3$ for WebVison and $\\alpha=0.012,\\beta=0.1$ for Clothing1M. ", "page_idx": 19}, {"type": "text", "text": "E More Experimental Results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Visualization. We show more visualizations of learned representations in Figure 3. ", "page_idx": 19}, {"type": "text", "text": "Detailed Experimental Results of $\\mathbf{C}\\mathbf{E}_{\\epsilon}{+}\\mathbf{M}\\mathbf{A}\\mathbf{E}$ (Semi) The more detailed results are reported in Table 7. ", "page_idx": 19}, {"type": "text", "text": "Instance-Dependent Noise. We follow the method in PDN [48] to generate instance-dependent noise. The experimental setting is the same as CIFAR-10/CIFAR-100. For $\\mathrm{CE_{\\epsilon}+M A E}$ on CIFAR-10, we set $\\alpha=0.045,\\beta=10$ , $m=1e5$ . For CIFAR-100, we use the same parameters as symmetric noise. The results are reported in Table 8. ", "page_idx": 19}, {"type": "image", "img_path": "vjsd8Bcipv/tmp/b57cb5f990831dcb49d78c17daafb9220981555af00f547b307fd35bb0bbbae9.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Figure 3: Visualizations of learned representations on CIFAR-10 with different symmetric label noise $\\bar{(\\eta^{-})}\\in[0,0.2,0.4,0.6])$ . The ${\\bf X}$ -axis and y-axis represent the first and second dimensions of the 2D embeddings, respectively. ", "page_idx": 19}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/1841c603c19ddbe9983e07bf9ffbc1db6e2ca1889ddde84567a08d3454722182.jpg", "table_caption": ["Table 7: Last and best epoch test accuracies $(\\%)$ of ${\\cal{C}}\\mathrm{{E}_{\\epsilon}+\\mathrm{{MAE}}}$ (Semi) on CIFAR-N datasets. The results \"mean\u00b1std\" are reported over 5 random runs. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Table 8: Last epoch test accuracies $(\\%)$ on CIFAR-10/100 instance-dependent noise (IDN). The results \"mean\u00b1std\" are reported over 3 random runs and the best results are boldfaced. ", "page_idx": 19}, {"type": "table", "img_path": "vjsd8Bcipv/tmp/13c7e56eeae3aaea9405588c2f5d51b864ec2be44cad03764af97c9dcba8c850.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. Specifically, we provide a simple yet effective method for mitigating label noise with elaborated descriptions and theoretical results. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 20}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: We have discussed the limitations of the work in the Appendix A. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 20}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We provide the full set of assumptions in the main paper and all proofs in Appendix B. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 21}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We describe the experiment details in the Appendix D and submit the code for reproducibility in the supplementary materials. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 21}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We have submitted the code for with sufficient instructions to faithfully reproduce the main experimental results. And the datasets are obtained from open source. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 22}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We have specified all the training and test details in Appendix D. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 22}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: For all experiments, we include error bars for added clarity. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provide the information in the experiment details. All experiments are implemented by PyTorch and are conducted on NVIDIA GeForce RTX 4090. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 23}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We promise that the research conducted in the paper conforms, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 23}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We have discussed broader impact of this work. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 23}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 24}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: We do not use pretrained language models, image generators, etc. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 24}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The existing asserts in this paper are properly credited an are the license and terms of use explicitly mentioned and properly respected with appropriate citations. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: We do not introduce any new assets. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 25}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 25}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}]