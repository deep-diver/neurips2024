[{"figure_path": "IdIVfzjPK4/tables/tables_7_1.jpg", "caption": "Table 1: Anomaly detection performance in terms of AUROC (in percent, mean\u00b1std). Highlighted are the results ranked first, second, and third. \"Rank\" indicates the average ranking over 8 datasets.", "description": "This table presents the AUROC (Area Under the Receiver Operating Characteristic curve) scores for various graph anomaly detection methods across eight benchmark datasets.  The AUROC is a common metric for evaluating the performance of binary classification models, where higher values indicate better performance.  The table compares supervised and unsupervised pre-trained models, both with and without fine-tuning, highlighting the performance of the proposed ARC method.  The mean and standard deviation are provided for each method on each dataset. The average ranking across all datasets is also provided, offering a summary of each method's overall performance.", "section": "5.2 Experimental Results"}, {"figure_path": "IdIVfzjPK4/tables/tables_8_1.jpg", "caption": "Table 1: Anomaly detection performance in terms of AUROC (in percent, mean\u00b1std). Highlighted are the results ranked first, second, and third. \"Rank\" indicates the average ranking over 8 datasets.", "description": "This table presents a comparison of the anomaly detection performance of different methods (including ARC and baselines) across eight datasets using the AUROC metric.  The AUROC scores (Area Under the Receiver Operating Characteristic curve) represent the model's ability to distinguish between normal and anomalous nodes.  Higher AUROC scores indicate better performance.  The table includes mean and standard deviation scores across multiple trials, and highlights the top three performing methods for each dataset to help make comparisons easier.", "section": "5.2 Experimental Results"}, {"figure_path": "IdIVfzjPK4/tables/tables_21_1.jpg", "caption": "Table 1: Anomaly detection performance in terms of AUROC (in percent, mean\u00b1std). Highlighted are the results ranked first, second, and third. \"Rank\" indicates the average ranking over 8 datasets.", "description": "This table presents the AUROC (Area Under the Receiver Operating Characteristic curve) scores for various graph anomaly detection methods across eight datasets.  The AUROC is a common metric for evaluating the performance of binary classifiers (in this case, classifying nodes as anomalous or normal).  The table compares several supervised and unsupervised methods, with and without pre-training and fine-tuning.  The mean and standard deviation of AUROC are reported for each method across multiple trials, providing a measure of performance stability and variability.  The \"Rank\" column gives the average rank across all datasets, helping to summarize the overall performance of each method.", "section": "5.2 Experimental Results"}, {"figure_path": "IdIVfzjPK4/tables/tables_21_2.jpg", "caption": "Table 1: Anomaly detection performance in terms of AUROC (in percent, mean\u00b1std). Highlighted are the results ranked first, second, and third. \"Rank\" indicates the average ranking over 8 datasets.", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) scores for various graph anomaly detection methods across eight datasets.  The methods are categorized as supervised (with pre-training only or with pre-training and fine-tuning) and unsupervised (with pre-training only or with pre-training and fine-tuning).  For each method and dataset, the mean AUROC and standard deviation are reported. The best three performing methods for each dataset are highlighted. An average ranking of the methods across all datasets is also provided.", "section": "5.2 Experimental Results"}, {"figure_path": "IdIVfzjPK4/tables/tables_23_1.jpg", "caption": "Table 1: Anomaly detection performance in terms of AUROC (in percent, mean\u00b1std). Highlighted are the results ranked first, second, and third. \"Rank\" indicates the average ranking over 8 datasets.", "description": "This table presents the results of anomaly detection experiments using various methods (GCN, GAT, BGNN, BWGNN, GHRN, DOMINANT, COLA, HCM-A, TAM, and ARC).  The performance is measured by the Area Under the Receiver Operating Characteristic curve (AUROC), showing the mean and standard deviation across multiple trials.  The table is split into supervised and unsupervised sections, further subdivided by pre-training only and pre-training and fine-tuning.  The best-performing three methods for each dataset are highlighted.  The \"Rank\" column provides the average ranking of each method across all eight datasets.", "section": "5.2 Experimental Results"}, {"figure_path": "IdIVfzjPK4/tables/tables_24_1.jpg", "caption": "Table 1: Anomaly detection performance in terms of AUROC (in percent, mean\u00b1std). Highlighted are the results ranked first, second, and third. \"Rank\" indicates the average ranking over 8 datasets.", "description": "This table presents the performance of various graph anomaly detection methods (including the proposed ARC method) across eight datasets in terms of Area Under the Receiver Operating Characteristic curve (AUROC).  The results are presented as mean \u00b1 standard deviation (std) based on 5 trials, and the average ranking across all datasets is provided.  Highlighting indicates the top three performing methods for each dataset. The methods are categorized into supervised (with pre-training and pre-training with fine-tuning) and unsupervised (with pre-training only and pre-training plus fine-tuning) groups to show the various training settings.", "section": "5.2 Experimental Results"}, {"figure_path": "IdIVfzjPK4/tables/tables_25_1.jpg", "caption": "Table 1: Anomaly detection performance in terms of AUROC (in percent, mean\u00b1std). Highlighted are the results ranked first, second, and third. \"Rank\" indicates the average ranking over 8 datasets.", "description": "This table presents the AUROC (Area Under the Receiver Operating Characteristic curve) scores for various graph anomaly detection methods across eight different datasets.  The AUROC metric measures the performance of a classifier.  Higher AUROC indicates better performance. The table compares the performance of ARC (the proposed method) against several baselines, including both supervised and unsupervised methods with and without pre-training and fine-tuning. The mean and standard deviation of AUROC are presented for each method on each dataset. The \"Rank\" column provides an average rank of each method across the eight datasets.", "section": "5 Experimental Results"}]