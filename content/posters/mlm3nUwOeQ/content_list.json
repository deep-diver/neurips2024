[{"type": "text", "text": "Tight Rates for Bandit Control Beyond Quadratics ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Y. Jennifer Sun Princeton University ys7849@princeton.edu ", "page_idx": 0}, {"type": "text", "text": "Zhou Lu Princeton University zhoul@princeton.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Unlike classical control theory, such as Linear Quadratic Control (LQC), real-world control problems are highly complex. These problems often involve adversarial perturbations, bandit feedback models, and non-quadratic, adversarially chosen cost functions. A fundamental yet unresolved question is whether optimal regret can be achieved for these general control problems. The standard approach to addressing this problem involves a reduction to bandit convex optimization with memory. In the bandit setting, constructing a gradient estimator with low variance is challenging due to the memory structure and non-quadratic loss functions. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we provide an affirmative answ\u221aer to this question. Our main contribution is an algorithm that achieves an $\\tilde{O}(\\sqrt{T})$ optimal regret for bandit nonstochastic control with strongly-convex and smooth cost functions in the presence of adversarial perturbations, improving the previously known $\\tilde{O}(T^{2/3})$ regret bound from (Cassel and Koren, 2020). Our algorithm overcomes the memory issue by reducing the problem to Bandit Convex Optimization (BCO) without memory and addresses general strongly-convex costs using recent advancements in BCO from (Suggala et al., 2024). Along the way, we develop an improved algorithm for BCO with memory, which may be of independent interest. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Optimal control lies at the heart of engineering and operations research, with applications ranging from launching spacecraft to stabilizing economies. The theory of optimal control is a well-established field with a rich history, dating back to 1868 when James Clerk Maxwell analyzed governors, and flourishing in the mid-20th century with the development of dynamic programming by (Bellman, 1954) and the Kalman filter by (Kalman, 1960). ", "page_idx": 0}, {"type": "text", "text": "Classic optimal control theory studies the problem where a controller interacts with an environment, according to a (partially observable) linear time-invariant (LTI) dynamical system: ", "page_idx": 0}, {"type": "equation", "text": "$$\nx_{t+1}=A x_{t}+B u_{t}+w_{t},\\quad y_{t}=C x_{t}+e_{t},\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $A,B,C$ are the dynamics governing the system, $x_{t},u_{t},y_{t},w_{t},e_{t}$ represent the system state, control input, observation, perturbation, and observation noise at time $t$ , respectively. At each time $t$ , the controller observes $y_{t}$ and chooses a control $u_{t}$ , incurring a cost $c_{t}(y_{t},u_{t})$ based on the current observation and control. The system then evolves according to Eq. (1) to reach the next state $x_{t+1}$ . ", "page_idx": 0}, {"type": "text", "text": "The theory of optimal control (e.g., LQC) typically relies on three key assumptions on the setting: the perturbation $w_{t}$ is stochastic, the cost function $c_{t}$ is quadratic and known in advance, and the function $c_{t}$ is observable to the controller. The linear-quadratic regulator (LQR) (Kalman et al., 1960) provides a closed-form optimal solution under these conditions, representing a pinnacle of classical control theory. ", "page_idx": 0}, {"type": "text", "text": "However, these assumptions are often too idealistic for practical scenarios. In real-world control problems, the perturbations can be adversarial, the feedback model can be bandit, and the cost function can be non-quadratic. This is evident in applications such as autonomous vehicle navigation, advertisement placement, and traffic signal control. This discrepancy between theory and practice raises a fundamental question for developing a more general control theory: ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Can we devise algorithms with provable guarantees for LTI control problems with adversarial perturbations, bandit feedback models, and non-quadratic cost? ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Recent research in online non-stochastic control (see (Hazan and Singh, 2022) for a survey) aims to address this broader goal by relaxing two of the standard assumptions: (1) the cost $c_{t}$ can be time-varying, non-quadratic convex functions unknown to the controller; (2) the perturbation $w_{t}$ and the observation noise $e_{t}$ can be adversarially chosen. ", "page_idx": 1}, {"type": "text", "text": "The natural performance metric in this context is regret, defined as the excess cost incurred by the controller compared to the best control policy in a benchmark policy class $\\Pi$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{T}^{\\Pi}(\\mathrm{contro11er})=\\sum_{t=1}^{T}c_{t}\\bigl(y_{t},u_{t}\\bigr)-\\operatorname*{min}_{\\pi\\in\\Pi}\\sum_{t=1}^{T}c_{t}\\bigl(y_{t}^{\\pi},u_{t}^{\\pi}\\bigr),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $(y_{t},u_{t})$ is the observation-control pair reached by executing the controller\u221a at time $t$ , and $(y_{t}^{\\pi},u_{t}^{\\pi})$ is the observation-control pair under the policy $\\pi$ at time $t$ . An optimal $\\tilde{O}(\\sqrt{T})$ regret was obtained by (Agarwal et al., 2019a) with the Gradient Perturbation Controller (GPC) algorithm. ", "page_idx": 1}, {"type": "text", "text": "Several works in online control have made further progress towards the general question. (Cassel and Koren, 2020; Sun et al., 2024) obtained optimal regret under bandit feedback for strongly convex and smooth cost when the perturbation $w_{t}$ and observation noise $e_{t}$ are semi-adversarial (i.e. they contain an additive stochastic component that admits covariance matrices with least singular value bounded from below). (Cassel and Koren, 2020) also showed a sub-optimal $\\tilde{O}(T^{2/3})$ regret bound for fully adversarial perturbations. More recently, the advancement of (Suggala et al., 2024) showed for the first time that an optimal regret of $\\tilde{O}(\\sqrt{T})$ is achievable for strongly convex and smooth quadratic costs in the presence of adversarial perturbations and observation noises. ", "page_idx": 1}, {"type": "text", "text": "Still, no previous work has simultaneously addressed all three challenges with an optimal regret guarantee, which was left as an open problem by (Suggala et al., 2024). The main challenge lies in how to construct a low-variance gradient estimator under bandit feedback, with the memory structure and non-quadratic cost. Due to the $\\Omega(T^{2/3})$ regret lower bound for general BCO with memory by (Suggala et al., 2024), exploiting the special affine memory structure in control problems is crucial to achieving optimal regret for general convex cost. ", "page_idx": 1}, {"type": "text", "text": "In this work, we provide the first affirmative answer to th\u221ais general question by devising an algorithm that handles all three challenges with an optimal $\\tilde{O}(\\sqrt{T})$ regret bound. Our approach involves reducing the problem to no-memory BCO, which circumvents the high-dimensional estimator issue for non-quadratic costs. We then leverage a special curvature structure of the loss function induced by general strongly convex and smooth costs to obtain the optimal regret guarantee. Our result serves as a preliminary step toward fully solving the general control problem. ", "page_idx": 1}, {"type": "text", "text": "1.1 Technical Overview ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Several previous works have addressed the bandit non-stochastic control problem, but none achieved optimal regret across all three generalities due to the following technical challenges: ", "page_idx": 1}, {"type": "text", "text": "1. The necessity of curvature: The first work tackling the bandit non-stochastic control problem was (Cassel and Koren, 2020), which achieved an $\\tilde{O}(T^{2/3})$ regret bound for smooth convex cost. However, such sub-optimality is arguably inevitable due to the $\\tilde{\\Omega}(T^{2/3})$ regret lower bound for BCO-M with smooth convex 1 cost (Suggala et al., 2024): all existing results on bandit non-stochastic control relies on reduction to BCO-M! Indeed, the algorithm of (Cassel and Koren, 2020) is based on online gradient descent (OGD) and ignores the geometry of cost. This is the reason why we introduce the assumption on strong convexity.   \n2. Strong convexity is not enough: Does strong convexity alone become an easy remedy to the control problem? Unfortunately, even if we assume the cost functions $c_{t}$ in the control ", "page_idx": 1}, {"type": "table", "img_path": "mlm3nUwOeQ/tmp/b9c48c3c7b675f9242d5949d4209a20bc75b0cd4cce9489551eadc1e6f41fb0b.jpg", "table_caption": [], "table_footnote": ["Table 1: Comparison of results. This work is the first to address all three generalities with an $\\tilde{O}(\\sqrt{T})$ optimal regret: (Agarwal et al., 2019a) addressed perturbation $^+$ loss, (Cassel and Koren, 2020) addressed feedback $+\\ {\\mathrm{loss}}$ , (Suggala et al., 2024) addressed perturbation $^+$ feedback. (Cassel and Koren, 2020) also obtained a sub-optimal $\\tilde{O}(T^{2/3})$ regret for perturbation $^+$ feedback $^+$ loss. "], "page_idx": 2}, {"type": "text", "text": "problem are strongly-convex, the induced loss functions in the BCO-M problem are not necessarily strongly-convex! It was observed by (Suggala et al., 2024) that the induced loss functions satisfy a property called $\\kappa$ -convexity, allowing for low-variance estimation of Hessian matrices, which is a key ingredient in Newton-based second-order update to exploit the curvature. ", "page_idx": 2}, {"type": "text", "text": "3. Going beyond quadratic: However, finding a low-biased first-order estimation of gradients remains a challenge for BCO-M, because the nice property on the unit sphere domain $\\mathbb{S}_{d-1}:=\\{x\\in\\mathbb{R}^{d}\\prime|\\ \\|x\\|_{2}=1\\}$ of the exploration term is not preserved under Cartesian product: $\\mathbb{S}_{d-1}\\times\\mathbb{S}_{d-1}\\neq\\mathbb{S}_{d\\times d-1}$ . To handle this issue, (Suggala et al., 2024) relies on the quadratic cost assumption which admits an unbiased estimator of the divergence of the induced loss function. It\u2019s unclear how to handle general $\\kappa$ -convex smooth cost in BCO-M. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Similar to its full-information counterpart, we reduce the bandit non-stochastic control problem to bandit convex optimization with memory (BCO-M). To overcome these challenges, we further reduce the BCO-M problem to a no-memory BCO problem following (Cassel and Koren, 2020), to avoid the issue on the Cartesian product of ${\\mathbb S}_{d-1}$ . This allows for the use of a Newton-based BCO-M algorithm similar to (Suggala et al., 2024), which can handle general $\\kappa$ -convex smooth cost because the exploration domain is now ${\\mathbb S}_{d-1}$ . Besides this new approach, our method also includes novel algorithmic components and analysis. ", "page_idx": 2}, {"type": "text", "text": "1.2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Optimal control theory (Bellman, 1954) concerns finding a control for a dynamical system such that some objective function is optimized. The basic form of optimal control is linear quadratic control (Kalman, 1960), in which a quadratic function is minimized in a linear first-order dynamical system with stochastic noise, whose solution is given by LQR. ", "page_idx": 2}, {"type": "text", "text": "Online non-stochastic control generalizes classic optimal control by considering adversarial perturbation and cost, with the metric of regret to compete with the best fixed policy in some benchmark class. The first work (Agarwal et al., 2019a) obtained an optimal regret bound for general convex cost by reduction to online convex optimization with memory (Anava et al., 2015), under stability assumptions on the system. For the line of works on the full information feedback setting, see (Hazan and Singh, 2022) for a survey. ", "page_idx": 2}, {"type": "text", "text": "Online non-stochastic control with bandit feedback were first considered by (Cassel and Koren, 2020; Gradu et al., 2020). Under a smoothness assumption on cost functions, the two works showed an $\\tilde{O}(T^{2/3})$ and $\\tilde{O}(T^{3/4})$ regret bound respectively. W\u221ahen the cost functions are additionally stronglyconvex quadratics, (Sun et al., 2024) obtained an $\\tilde{O}(\\sqrt{T})$ regret, under semi-adversarial perturbations. (Yan et al., 2024) showed sublinear regret for cost functions with heterogeneous curvatures under the same semi-adversarial perturbations. This restriction on perturbation was later removed by (Suggala et al., 2024) which achieved the same regret for adversarial perturbations. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Recent advancements on BCO (Lattimore and Gy\u00f6rgy, 2023; Suggala et al., 2021; Lattimore, 2024) considered Newton step updates to achieve improved regret bounds. In particular, (Suggala et al., 2024) also showed an $\\bar{\\Omega}(T^{\\bar{2}/3})$ lower bound for bandit quadratic optimization with memory (BQO-M) without strong convexity. When making use of the affine memory structure, (Suggala et al., 2024) obtained an $\\bar{\\tilde{O}}(\\sqrt{T})$ regret bound for BQO-M. ", "page_idx": 3}, {"type": "text", "text": "2 Preliminary ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "2.1 Online non-stochastic control with bandit feedback ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Consider the linear dynamical system in Eq. (1). At time $t\\in\\mathbb{N}$ , the learner receives observation $y_{t}$ and outputs control $u_{t}$ , to which the learner receives a scalar instantaneous cost $c_{t}(y_{t},u_{t})$ depending on both the current observation and the control, and no other information about $c_{t}$ is available. The perturbation $w_{t}$ and observation noise $e_{t}$ can be adversarially chosen. The learner\u2019s goal is to minimize regret over a fixed time horizon $T\\in\\mathbb N$ defined in Eq. (2). ", "page_idx": 3}, {"type": "text", "text": "Throughout this paper, all cost functions we consider are assumed to be twice continuously differentiable. Consistent with past literature (Sun et al., 2024; Suggala et al., 2024), we make the following assumptions on the cost functions. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1 (Cost curvature and regularity). Let $d_{y},d_{u}\\in\\mathbb{N}$ denote the dimensions of observation and control, respectively. The control cost function $\\bar{c_{t}}:\\mathbb{R}^{d_{y}}\\times\\mathbb{R}^{d_{u}}\\rightarrow\\mathbb{R}_{+}$ satisfies that ", "page_idx": 3}, {"type": "text", "text": "1. (Curvature) $c_{t}$ is $\\alpha_{c}$ -strongly convex and $\\beta_{c}$ -smooth over some compact set $\\mathcal{V}\\times\\mathcal{U}\\subset\\mathbb{R}^{d_{\\mathcal{Y}}}\\times$ $\\mathbb{R}^{d_{u}}$ for some $\\alpha_{c},\\beta_{c}>0,$ , i.e., $\\begin{array}{r}{\\nabla c_{t}(x_{2})^{\\top}(x_{1}-x_{2})+\\frac{\\beta_{c}}{2}\\|x_{1}-x_{2}\\|_{2}^{2}\\geq c_{t}(x_{1})-c_{t}(x_{2})\\geq}\\end{array}$ $\\begin{array}{r}{\\nabla c_{t}(x_{2})^{\\top}(x_{1}-x_{2})+\\frac{\\alpha_{c}}{2}\\|x_{1}-x_{2}\\|_{2}^{2}.}\\end{array}$ for any $x_{1},x_{2}\\in\\mathcal{Y}\\times\\mathcal{U}$ .   \n2. (Gradient bounds) There exists some $G_{c}>0$ such that the gradients satisfy $\\|\\nabla c_{t}(y,u)\\|_{2}\\leq$ $G_{c}\\|(y,u)\\|_{2}$ for any $y\\in\\mathcal{Y},u\\in\\mathcal{U}$ . ", "page_idx": 3}, {"type": "text", "text": "We also make stability assumption on the LDS in Eq. (1) as well as norm bound on the perturbation and noise. These assumptions are standard in literature (e.g. (Hazan and Singh, 2022)) and necessary for deriving meaningful regret guarantees. ", "page_idx": 3}, {"type": "text", "text": "Assumption 2 (Strong stabilizability and bounded dynamics). $(A,B,C)$ that governs the LDS in Eq. (1) satisfies that max $\\{\\|A\\|_{\\mathrm{op}},\\|B\\|_{\\mathrm{op}},\\|C\\|_{\\mathrm{op}}\\}\\le\\dot{\\kappa}_{s y s}$ for some positive constant $\\kappa_{s y s}$ . There exists $K\\in\\mathbb{R}^{d_{u}\\times d_{y}}$ s.t. $A+B K C=H L^{-1}H$ for some $H\\succ0$ and $\\operatorname*{max}\\{\\|K\\|_{2},\\|H\\|_{2},\\|H^{-1}\\|_{2}\\}\\leq\\kappa,$ , $\\|L\\|_{2}\\leq1-\\gamma$ for some $\\kappa>0$ , $0<\\gamma\\leq1$ . Such $K$ is called $a$ $(\\kappa,\\gamma)$ -stabilizing linear controller for the $L D S$ . ", "page_idx": 3}, {"type": "text", "text": "Assumption 3 (Bounded perturbation and noise). The perturbation and observation noise sequences satisfy the norm bound $\\begin{array}{r}{\\operatorname*{max}_{t\\in[T]}\\left\\{\\operatorname*{max}\\{\\|w_{t}\\|_{2},\\|e_{t}\\|_{2}\\}\\right\\}\\leq R_{w,e}}\\end{array}$ for some $R_{w,e}>0$ . ", "page_idx": 3}, {"type": "text", "text": "We assume the adversary chooses the cost functions and noise sequences in an oblivious way, i.e.   \nthey are chosen independently of the learner\u2019s decisions. ", "page_idx": 3}, {"type": "text", "text": "Assumption 4 (Oblivious adversary). The sequence of cost functions $\\{c_{t}\\}_{t=1}^{T}$ and the noise sequences $\\{w_{t}\\}_{t=1}^{T}$ , $\\{e_{t}\\}_{t=1}^{T}$ are chosen by an oblivious adversary and does not depend on the control played by the learner. ", "page_idx": 3}, {"type": "text", "text": "For partially observable systems, the standard comparator class in literature (Simchowitz et al., 2020) is the class of Disturbance Response Controllers (DRC). Essentially, this class considers controllers that choose linear combinations of past signals and observations. The signals are simply the would-be observations had a stabilizing controller $K$ been used from the beginning of the time. Formally, the class of DRC is given by the following definition: ", "page_idx": 3}, {"type": "text", "text": "Definition 1 (DRC). (1) A disturbance response controller (DRC) is a policy $\\pi_{M}$ parametrized by $m\\in\\mathbb{N}$ matrices $M=M^{[0:m-1]}$ in $\\mathbb{R}^{d_{u}\\times d_{y}}$ such that the control at time $t$ according to $\\pi_{M}$ is ", "page_idx": 3}, {"type": "equation", "text": "$$\nu_{t}(\\pi_{M})=K y_{t}+\\sum_{j=0}^{m-1}M^{[j]}y_{t-j}(K),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $K$ is a $(\\kappa,\\gamma)$ -stabilizing linear controller, and $y_{t}^{K}$ is the would-be observation had the linear policy $K$ been carried out from the beginning of the time. ", "page_idx": 4}, {"type": "text", "text": "(2) A DRC policy class $\\mathcal{M}(\\boldsymbol{m},R_{\\mathcal{M}})$ , parameterized by $m\\,\\in\\,\\mathbb{N},R_{\\mathcal{M}}\\,>\\,0$ , is the set of all DRC controller of length $m$ and obeys the norm bound $\\begin{array}{r}{\\|M\\|_{\\ell_{1},\\mathrm{op}}:=\\sum_{j=0}^{m-1}\\|M^{[j]}\\|_{\\mathrm{op}}\\leq R_{\\mathcal{M}}}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "A DRC policy always produces controls that ensure the system remains state bounded, the DRC class is expressive enough to approximate the class of linear policies of past observations (see Theorem 1 in (Simchowitz et al., 2020)). ", "page_idx": 4}, {"type": "text", "text": "2.2 Bandit convex optimization with memory (BCO-M) ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We start with the general protocol of bandit convex optimization with memory (BCO-M). In the (improper) BCO-M problem, at each time $t$ , the learner is asked to output a decision $z_{t}\\in\\mathbb{R}^{d}$ , to which a scalar loss $f_{t}(z_{t-m+1:t})$ , depending on the learner\u2019s most recent $m\\in\\mathbb{N}$ decisions is revealed. Given a convex compact set $\\kappa\\subset\\mathbb{R}^{d}$ as the domain of comparators, the regret is measured on the best single point $z\\in\\kappa$ over a time horizon of $T\\in\\mathbb N$ , formally given by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{T}^{K}=\\operatorname*{max}_{z\\in K}\\;\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-f_{t}(z,\\cdot\\cdot\\cdot\\,,z)\\right].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In non-stochastic control, the learner\u2019s past decisions affect future states through an affine structure, therefore we are interested in BCO-M problems with such structure. This leads to the following structural assumption on the induced loss function with memory. We will show in Lemma 9 that the bandit control problems with the standard regularity conditions satisfy Assumption 5. ", "page_idx": 4}, {"type": "text", "text": "Assumption 5 (Affine memory structure). At time $t\\in\\mathbb{N}_{;}$ , the loss function with memory length $m$ takes the form of $f_{t}:(\\mathbb{R}^{d})^{m}\\overset{\\cdot}{\\to}\\mathbb{R}_{+}$ given by the following structure ", "page_idx": 4}, {"type": "equation", "text": "$$\nf_{t}(z_{t-m+1:t})=\\ell_{t}\\left(B_{t}+\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}z_{t-i}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "with parameters $B_{t}\\,\\in\\,\\mathbb{R}^{n}$ , $Y_{t-i}\\,\\in\\,\\mathbb{R}^{p\\times d}$ , and $G\\,=\\,G^{[0:m-1]}$ $a$ sequence of m matrices where $G^{[i]}\\ \\in\\ \\mathbb{R}^{n\\times p}$ for some $n,p\\;\\in\\;\\mathbb{N}$ . 2 We denote $\\begin{array}{r}{G_{t}\\ =\\ \\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}\\ \\in\\ \\mathbb{R}^{n\\times d}}\\end{array}$ , and $H_{t}\\ =$ $G_{t}^{\\top}G_{t}\\ \\in\\ \\mathbb{R}^{d\\times d}$ . There exists some $R_{H}~>~0$ such that $\\operatorname*{max}\\{1,\\|G_{t}\\|_{2},\\|Y_{t}\\|_{2},\\|H_{t}\\|_{2}\\}\\;\\leq\\;R_{H}$ . In addition, we assume that $G$ satisfies positive convolution invertibility-modulus, i.e. $\\kappa(G)\\,=$ $\\begin{array}{r}{\\operatorname*{inf}_{\\sum_{n\\geq0}\\|u_{n}\\|_{2}^{2}=1}\\sum_{n\\geq0}\\|\\sum_{i=0}^{n}G^{[i]}u_{n-i}\\|_{2}^{2}=\\Omega(1).}\\end{array}$ . We assume that the learner receives $H_{t}$ every step after they incurred the loss. ", "page_idx": 4}, {"type": "text", "text": "We make two standard curvature and regularity assumptions on each of the instantaneous loss $f_{t}$ , that $f_{t}$ is strongly-convex and smooth, with its subgradient norm bounded by some constants, following the previous work of Suggala et al. (2024). ", "page_idx": 4}, {"type": "text", "text": "Assumption 6 (Curvature). Consider a loss function $f_{t}$ satisfying Assumption $^{5}$ and the set ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{Z}_{t}=\\left\\{B_{t}+\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}z_{t-i}:z_{t-m+1},\\ldots,z_{t}\\in K+\\mathbb{B}_{d}\\right\\}\\subset\\mathbb{R}^{n},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $B_{t},G,Y_{t-m+1:t}$ are the parameters, and $\\ell_{t}:\\mathbb{R}^{n}\\to\\mathbb{R}_{+}$ is the function associated with $f_{t}$ in Assumption 5. We assume that $\\ell_{t}$ is $\\alpha_{f}$ -strongly-convex and $\\beta_{f}$ -smooth, i.e. $\\alpha_{f}I_{n}\\preceq\\nabla^{2}\\ell_{t}(z)\\preceq\\bar{\\beta}_{f}I_{n},$ , over $\\mathcal{Z}_{t}$ , with $0<\\alpha_{f}\\le1\\le\\beta_{f}$ here 3. ", "page_idx": 4}, {"type": "text", "text": "Assumption 7 (Regularity). For $d\\in\\mathbb{N}$ , denote $\\mathbb{B}_{d}:=\\{x\\in\\mathbb{R}^{d}\\ |\\ \\|x\\|_{2}\\leq1\\}$ as the unit ball in $\\mathbb{R}^{d}$ . We assume that at time $t_{\\perp}$ , the with-memory loss function $f_{t}:(\\mathbb{R}^{d})^{m}\\to\\mathbb{R}_{+}$ with memory parameter $m\\in\\mathbb{N}$ obeys the following gradient bounds over $K+\\mathbb{B}_{d}:=\\{x+y\\ |\\ x\\in K,y\\in\\mathbb{B}_{d}\\}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\|\\nabla f_{t}(z_{1},\\ldots,z_{m})\\|_{2}\\le G_{f},\\ \\ \\forall z_{1},\\ldots,z_{m}\\in K+\\mathbb{B}_{d}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Additionally, we assume that $\\kappa$ has Euclidean diameter $D>0$ . ", "page_idx": 4}, {"type": "text", "text": "We consider an oblivious adversary model, given by Assumption 8. ", "page_idx": 5}, {"type": "text", "text": "Assumption 8 (Oblivious adversary). For a BCO-M instance, we assume that the adversary is oblivious. In particular, let $z_{t}$ denote the algorithm\u2019s decision at time $t_{\\perp}$ , then the loss function $f_{t}$ chosen by the adversary does not depend on $z_{1:t}$ . ", "page_idx": 5}, {"type": "text", "text": "In the definition of regret in BCO-M, we compare the cumulative loss of any algorithm with the best fixed comparator $z\\in\\kappa$ , evaluated on the induced unary form $f_{t}(z,\\dots,z)$ of the loss $f_{t}$ . Formally, we have the following definition ", "page_idx": 5}, {"type": "text", "text": "Definition 2 (Induced unary form). $\\forall t\\in\\mathbb{N}$ , let $\\bar{f}_{t}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}_{+}$ denote the induced unary form of the loss $f_{t}$ , given by $\\bar{f}_{t}(z)=\\bar{f}_{t}(z,\\dots,z)$ . Then, for $f_{t}$ satisfying Assumption 5, $\\bar{f}_{t}$ admits the structure $\\begin{array}{r}{\\bar{f}_{t}(z)=\\ell_{t}\\left(B_{t}+\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}z\\right)}\\end{array}$ . ", "page_idx": 5}, {"type": "text", "text": "We note that for $f_{t}$ satisfying Assumption 6, the induced unary form in Definition 2 satisfies a special curvature called $\\kappa$ -convexity introduced in (Suggala et al., 2024). To avoid confusion with the notations with the bound on the dynamics (Assumption 2), we will call it $\\kappa_{0}$ -convexity henceforth. ", "page_idx": 5}, {"type": "text", "text": "Definition 3 ( $\\lvert\\kappa_{0}$ -convexity, (Suggala et al., 2024)). A function $f:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ is called $\\kappa_{0}$ -convex over a domain $\\boldsymbol{\\kappa}\\subseteq\\mathbb{R}^{d}$ if and only if the following holds: $f$ is convex and twice continuously differentiable, and moreover $\\exists c,C>0$ and a PSD matrix $0\\preceq H\\preceq I$ s.t. the Hessian of $f$ at any $z\\in\\kappa$ satisfies ", "page_idx": 5}, {"type": "equation", "text": "$$\nc H\\preceq\\nabla^{2}f(z)\\preceq C H,\\ \\ \\frac{C}{c}\\leq\\kappa_{0}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The benefit that the loss function exhibits an affine memory dependence is that its induced unary form satisfies $\\kappa_{0}$ convexity for some $\\kappa_{0}>0$ , summarized the following observation. ", "page_idx": 5}, {"type": "text", "text": "Observation 4 $\\scriptstyle\\kappa_{0}$ -convexity and gradient bound of the unary loss.). Consider $f_{t}:(\\mathbb{R}^{d})^{m}\\to\\mathbb{R}_{+}$ satisfying Assumption 5, Assumption 6, and Assumption 7. Then, the induced unary form $\\bar{f}_{t}:\\mathbb{R}^{d}\\to$ $\\mathbb{R}_{+}$ in Definition 2 satisfies the following two properties: ", "page_idx": 5}, {"type": "text", "text": "Proof of Observation 4. By our assumption on the affine structure of $f_{t}$ in Assumption 5, $\\forall z\\in\\mathbb{R}^{d}$ , $\\nabla^{2}\\bar{f}_{t}(\\bar{z^{\\big}})=G_{t}^{\\top}\\nabla^{2}\\ell_{t}(B_{t}+\\dot{G}_{t}z)G_{t}$ . $\\kappa_{0}$ -convexity follows from the curvature assumption in Assumption \u221a6. For any $z_{1},z_{2}\\in\\mathbb{R}^{d}$ , we have that $|{\\bar{f}}_{t}(z_{1})-{\\bar{f}}_{t}(z_{2})|\\leq G_{f}\\|(z_{1},\\cdot\\cdot\\cdot\\,,z_{1})-{\\bar{(z_{2},\\cdot\\cdot\\cdot\\,,z_{2})}}\\|_{2}=$ $G_{f}\\sqrt{m}\\|z_{1}-z_{2}\\|_{2}$ . \u53e3 ", "page_idx": 5}, {"type": "text", "text": "2.3 Notations ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For a positive semidefinite square matrix $H\\,\\succeq\\,0\\,\\in\\,\\mathbb{R}^{d\\times d}$ , define the norm $\\Vert\\cdot\\Vert_{H}$ on $\\mathbb{R}^{d}$ so that $\\|v\\|_{H}^{2}=v^{\\top}H v$ . We write $c_{t}$ to denote the cost function of the control problem, and $f_{t}$ to denote the loss function for BCO with memory. For two sets $A,B,A+B=\\{\\bar{a}+b:a\\in A,b\\in B\\}$ . For a set $S$ , $|S|$ denotes the cardinality of $S$ . We use $\\mathbb{B}_{d},\\mathbb{S}_{d-1}$ to denote the unit ball and unit sphere in $\\mathbb{R}^{d}$ , respectively. For $n$ vectors $v_{1},\\ldots,v_{n}\\in\\mathbb{R}^{d}$ , we slightly abuse notation and shorthand as $v_{1:n}$ to denote the concatenated vector $(v_{1},\\ldots,v_{n})\\in\\mathbb{R}^{n d}$ . ", "page_idx": 5}, {"type": "text", "text": "3 Improved Bandit Convex Optimization with Memory ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we introduce an improved algorithm for the bandit convex optimization with memory problem. Our algorithm incorporates the occasional update idea from (Cassel and Koren, 2020) and the \u221aNewton-based update for $\\kappa_{0}$ -convex functions from (Suggala et al., 2024), achieving an optimal $\\tilde{O}(\\sqrt{T})$ regret bound, improving the previously best known $\\tilde{O}(T^{2/3})$ result from (Cassel and Koren, 2020). Besides the advancement on BCO-M, this result is the key component of our main result in control. First, we define the BCO-M instance. ", "page_idx": 5}, {"type": "text", "text": "Definition 5 (BCO-M instance). Given $d~\\in~\\mathbb{N}$ , a BCO-M instance is parametrized by ${\\cal O}\\ =$ $\\{\\mathcal{K},m,\\{f_{t}\\}_{t\\ge m,t\\in\\mathbb{N}}\\}$ , where $\\kappa\\subset\\mathbb{R}^{d}$ is a convex compact set; $m$ is the memory length; $f_{t}~:$ ${K^{m}}\\to\\mathbb{R}_{+}$ measures the instantaneous loss at time $t$ . Given any bandit online learning with memory algorithm $\\overset{\\cdot}{\\mathcal{A}}^{B}$ , the regret of $\\boldsymbol{A}^{B}$ on $\\scriptscriptstyle\\mathcal{O}$ w.r.t. $z\\in\\kappa$ is given by ", "page_idx": 6}, {"type": "equation", "text": "$$\n{\\mathrm{Regret}}_{T}^{A^{B},z}(\\mathcal{O})=\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $z_{t}=z_{t}^{A^{B}}$ is the decision according to $A^{B}$ at time $t$ . We say a BCO-M instance $\\scriptscriptstyle\\mathcal{O}$ is affine and $(\\alpha,\\beta,G,D)$ -well-conditioned if $\\scriptscriptstyle\\mathcal{O}$ satisfies Assumption 5, Assumption 6 with $\\alpha_{f}=\\alpha,\\beta_{f}=\\beta$ , Assumption 7 with $G_{f}=G,D_{f}=D$ , and the adversary model satisfies Assumption 8. ", "page_idx": 6}, {"type": "text", "text": "3.1 BCO-M algorithm ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We describe Algorithm 1 that runs bandit convex optimization for any BCO-M instance ${\\mathcal{O}}\\,=$ $\\{\\mathcal{K},m,\\{f_{t}\\}_{t\\ge m,t\\in\\mathbb{N}}\\}$ . On a high level, our algorithm employs the occasional update idea from (Cassel and Koren, 2020). The decisions are updated at most once every $m$ steps, ensured by the condition $b_{t}\\prod_{i=1}^{m-1}(1-b_{t-i})=1$ (line 8 in Algorithm 1), where $b_{t}$ is the Bernoulli random variable (partially) deciding whether the algorithm will make an update at the current time step. We write $o$ as the original ideal prediction, $v$ as the random perturbation vector, and $z$ is the actual prediction (as the perturbed $o$ ) of the algorithm. ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1 Improved Bandit Convex Optimization with Affine Memory ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Input: convex compact set $\\kappa\\subset\\mathbb{R}^{d}$ , step size $\\eta>0$ , memory parameter $m$ , curvature parameter $\\alpha$ ,   \ntime horizon $T$ .   \n1: Initialize: $o_{1}=\\cdots=o_{m}\\in\\mathcal{K},\\tilde{g}_{0:m-1}=\\mathbf{0}_{d},\\hat{A}_{0:m-1}=I,$ , $\\tau=1$ .   \n2: Sample $v_{t}\\sim S_{d-1}$ i.i.d. uniformly at random for $t=1,\\dots,m$ .   \n3: Set $z_{t}=o_{t}+\\hat{A}_{t-1}^{-\\frac{1}{2}}v_{t}$ , $t=1,\\dots,m$ .   \n4: Draw $\\begin{array}{r}{b_{t}\\sim\\operatorname{Ber}\\left(\\frac{1}{m}\\right)}\\end{array}$ , $t=1,\\dots,m$ .   \n5: for $t=m,\\ldots,T$ do   \n6: Play $z_{t}$ , observe $f_{t}(z_{t-m+1:t})$ , receive $H_{t}=G_{t}^{\\top}G_{t}$ .   \n7: Draw $\\begin{array}{r}{b_{t}\\sim\\mathrm{Ber}\\left(\\frac{1}{m}\\right)}\\end{array}$ .   \n8: if $\\begin{array}{r}{b_{t}\\prod_{i=1}^{m-1}(1-b_{t-i})=1}\\end{array}$ then   \n9: Let $s_{\\tau}=t$ .   \n10: Update $\\begin{array}{r}{\\hat{A}_{t}=\\hat{A}_{t-1}+\\frac{\\eta\\alpha}{2}H_{t}}\\end{array}$ .   \n11: Create gradient estimate: $\\tilde{g}_{t}=d f_{t}\\big(z_{t-m+1:t}\\big)\\hat{A}_{t-1}^{\\frac{1}{2}}v_{t}\\in\\mathbb{R}^{d}.$   \n12: Update $\\begin{array}{r}{o_{t+1}=\\prod_{\\kappa}^{\\hat{A}_{s_{\\tau-1}}}\\Big[o_{t}-\\eta\\hat{A}_{s_{\\tau-1}}^{-1}\\tilde{g}_{s_{\\tau-1}}\\Big],}\\end{array}$ .   \n13: Sample $v_{t+1}\\sim S_{d-1}$ uniformly at random, independent of previous steps.   \n14: Set $z_{t+1}=o_{t+1}+\\hat{A}_{t}^{-\\frac{1}{2}}v_{t+1}$ .   \n15: $\\tau\\gets\\tau+1$ .   \n16: else   \n17: Set $o_{t+1}=o_{t},v_{t+1}=v_{t},z_{t+1}=z_{t},\\hat{A}_{t}=\\hat{A}_{t-1},\\tilde{g}_{t}=\\tilde{g}_{t-1}.$   \n18: end if ", "page_idx": 6}, {"type": "text", "text": "19: end for ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Such occasional update essentially reduces the BCO-M problem to a new no-memory BCO problem, whose equivalence will be shown later (see Appendix A.2). Consistent with the notation used in (Cassel and Koren, 2020), we denote the following set ", "page_idx": 6}, {"type": "equation", "text": "$$\nS:=\\{t\\in[T]:z_{t+1}\\neq z_{t}\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "to be the set of time steps where the algorithm updates its decision. We readily have $\\left\\vert S\\right\\vert\\,\\leq\\,{\\frac{T}{m}}$ . Moreover, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\nf_{t}(z_{t-m+1:t})=\\bar{f}_{t}(z_{t-m+1})=\\bar{f}_{t}(z_{t}),\\;\\;\\forall t\\in S,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "since $t\\in S$ implies $b_{t-m+1}=\\cdot\\cdot\\cdot=b_{t-1}=0$ . Thus, whenever Algorithm 1 updates, it effectively updates with function value $\\bar{f}_{t}(\\boldsymbol{z}_{t})$ . ", "page_idx": 7}, {"type": "text", "text": "The occasional update alone only gives a sub-optimal $\\tilde{O}(T^{2/3})$ regret as shown in (Cassel and Koren, 2020). To achieve the optimal $\\tilde{O}(\\sqrt{T})$ regret, we use a Newton-based update to exploit the $\\kappa_{0}$ -convexity of general strongly-convex smooth functions, recently introduced by (Suggala et al., 2024). ", "page_idx": 7}, {"type": "text", "text": "For this improvement we require the knowledge of a Hessian estimator $H_{t}$ as in Assumption Assumption 5. This doesn\u2019t hold in BCO in general, but we will show in the next section that the control problem indeed satisfies this assumption: thanks to $\\kappa_{0}$ -convexity, in the control problem $H_{t}$ can be constructed from the knowledge of system, instead of knowledge of loss which would typically incur a huge variance term. ", "page_idx": 7}, {"type": "text", "text": "The regret guarantee of Algorithm 1 is given by the following theorem. ", "page_idx": 7}, {"type": "text", "text": "Theorem 6 (BCO-M regret guarantee). Given an $(\\alpha,\\beta,G,D)$ -well-conditioned BCO-M instance $\\mathcal{O}=\\{K,m,\\{f_{t}\\}_{t\\geq m,t\\in\\mathbb{N}}\\}$ with $m\\,=\\,\\mathrm{poly}(\\log T)$ and $G,D=\\tilde{O}(1)$ (Definition 5), let $(\\kappa,\\eta=$ $\\Theta(1/\\sqrt{T}),m,\\alpha,T)$ be the input to Algorithm $^{\\,l}$ . Algorithm $^{\\,I}$ guarantees that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{z\\in K}\\,\\mathbb{E}\\left[R e g r e t_{T}^{A l g o r i t h m\\ 1,z}(\\mathcal{O})\\right]\\leq\\tilde{O}\\left(\\frac{\\beta}{\\alpha}G D\\sqrt{T}\\right),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\tilde{O}(\\cdot)$ hides all universal constants and logarithmic dependence in $T$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 6 is the first algorithm to achieve the optimal $\\tilde{O}(\\sqrt{T})$ regret bound for the BCO-M problem with general smooth convex loss. Compared with the $\\tilde{O}(T^{2/3})$ bound from (Cassel and Koren, 2020), our improvement exploits the new a\u221assumptions on the strong convexity of loss and the affine structure of memory. We notice that the $\\tilde{O}(\\sqrt{T})$ regret bound of (Suggala et al., 2024) requires the additional quadratic loss assumption and uses the special structure of quadratic functions to construct low-biased gradient estimators for the unary form of losses. Algorithm 1 and its guarantee in Theorem 6 thus improve upon both of these previous results. The proof of Theorem 6 is lengthy, therefore we leave it to the appendix and include a sketch here. ", "page_idx": 7}, {"type": "text", "text": "3.2 Proof Sketch ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The theorem is proven via reduction to a no-memory BCO algorithm with Newton-based updates. ", "page_idx": 7}, {"type": "text", "text": "Step 1: regret of the base algorithm. We devise a new BCO algorithm with two new ingredients different from standard algorithms. First, our algorithm adopts Newton-based updates which require estimating Hessians. In Assumption 5 we assume \"free\" access to a Hessian estimator $H_{t}$ , which holds in the control setting by utilizing the $\\kappa_{0}$ -convexity property. ", "page_idx": 7}, {"type": "text", "text": "Second, we incorporate a new delay mechanism to decorrelate neighboring iterates such that $o_{t}$ is independent of recent perturbation vectors, which plays a crucial role in bo\u221aunding the expectation of moving cost. Our base BCO algorithm is then shown to have an $\\tilde{O}(\\sqrt{T})$ regret bound (see Lemma 11). ", "page_idx": 7}, {"type": "text", "text": "Step 2: reduction to the base algorithm. We show that the regret of Algorithm 1 can be controlled by the regret of the base algorithm plus a moving cost term. By the design of Algorithm 1, it updates a univariate loss function at most once every $m$ steps. If all the $z_{t}$ across these $m$ steps are the same, Regret(Algorithm 1) will be exactly the same as $m\\times\\mathbf{R}$ egret(base algorithm). When $z_{t}$ are different, we suffer an additional moving cost E $\\begin{array}{r}{\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})\\right]}\\end{array}$ , which can be bounded by the assumption on the gradient of $f\\overline{{t}}$ if $z_{t}$ changes slowly. ", "page_idx": 7}, {"type": "text", "text": "Step 3: bounding the moving cost. We partition the moving cost $f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})$ into three terms ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\underbrace{f_{t}(z_{t-m+1:t})-f_{t}(o_{t-m+1:t})}_{(a)}+\\underbrace{f_{t}(o_{t-m+1:t})-\\bar{f}_{t}(o_{t-m+1})}_{(b)}+\\underbrace{\\bar{f}_{t}(o_{t-m+1})-\\bar{f}_{t}(z_{t-m+1})}_{(c)}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Here, (a), (c) can be seen as perturbation loss suffered by the algorithm during exploration. (b) is the moving cost determined by the stability of the algorithm\u2019s neighboring iterates. ", "page_idx": 8}, {"type": "text", "text": "For the three terms in the above equation, (c) is bounded by Jensen\u2019s inequality using the convexity of the unary form of loss. We bound (a) using the curvature assumptions and the affine memory structure of $f_{t}$ , where we also make use of the delayed updates to decorrelate neighboring iterates for technical reasons. (b) is bounded by the Lipschitzness of $f_{t}$ and the distance between neighboring iterates. Theorem 6 is reached by putting the three steps together. ", "page_idx": 8}, {"type": "text", "text": "4 Optimal Regret for Bandit Non-stochastic Control ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we show how to achieve optimal regret for the bandit non-stochastic control problem with a partially observable LTI dynamical system as described in Eq. (1) for strongly-convex smooth loss, by a reduction to the BCO-M algorithm (Algorithm 1) we devise in the previous section. Previously, the best known regret bound for this problem was $\\tilde{O}(T^{2/3})$ from (Cassel and Koren, 2020), which is also rooted in a reduction to BCO-M. We use a similar reduction, obtaining a better bound thanks to the improved regret bound of BCO-M (Theorem 6). We first give the formal definition of the control problem. ", "page_idx": 8}, {"type": "text", "text": "Definition 7 (Bandit non-stochastic control). A bandit non-stochastic control problem of a partially observable LDS is parametrized by a tuple $\\begin{array}{r}{\\mathcal{L}=(A,B,C,x_{1},(w_{t})_{t\\in\\mathbb{N}},(e_{t})_{t\\in\\mathbb{N}},(c_{t})_{t\\in\\mathbb{N}},\\Pi).}\\end{array}$ , where $A,B,C$ and $(w_{t})_{t\\in\\mathbb{N}}$ , $(e_{t})_{t\\in\\mathbb{N}}$ are the dynamics and perturbations in the LDS (Eq. (1)) with initial state $x_{1}$ (we assume $x_{1}{=}0$ without loss of generality henceforth); $c_{t}$ measures the instantaneous cost at time $t$ ; $\\Pi$ is the comparator control policy class. Given any bandit non-stochastic control algorithm $\\boldsymbol{\\mathcal{A}}$ , the regret of $\\mathcal{A}^{\\mathrm{NC}}$ on $\\mathcal{L}$ over a time horizon $T\\in\\mathbb N$ is given by ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{T}^{A^{\\mathrm{NC}}}(\\mathcal{L},\\Pi)=\\sum_{t=1}^{T}c_{t}(y_{t}^{A^{\\mathrm{NC}}},u_{t}^{{A^{\\mathrm{NC}}}})-\\operatorname*{min}_{\\pi\\in\\Pi}\\sum_{t=1}^{T}c_{t}(y_{t}^{\\pi},u_{t}^{\\pi}),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where (ytANC, u $(y_{t\\dots\\alpha}^{{A^{\\mathrm{NC}}}},u_{t}^{{A^{\\mathrm{NC}}}}),(y_{t}^{\\pi},u_{t}^{\\pi})$ are the observation, control pair at time $t$ following the trajectory of $\\mathcal{A}^{\\mathrm{NC}}$ and $\\pi$ , respectively. We say that a bandit non-stochastic control problem $\\mathcal{L}$ is $(\\alpha,\\beta,G,\\kappa_{\\mathbf{sys}},\\kappa,\\gamma,R_{\\mathbf{w},\\mathbf{e}},\\gamma,\\mathcal{U})$ -well-conditioned if $\\mathcal{L}$ and $\\Pi$ satisfy Assumption 1 with $\\alpha_{c}=$ $\\alpha,\\beta_{c}\\,=\\,\\beta,G_{c}\\,=\\,G$ over some centered bounded convex domain $\\mathcal{V}\\times\\mathcal{U}\\subset\\mathbb{R}^{d_{\\mathcal{Y}}+d_{u}}$ , Assumption 2 with $\\kappa_{\\mathbf{sys}},\\kappa,\\gamma$ , Assumption 3 with $R_{\\mathbf{w},\\mathbf{e}}$ , and Assumption 4. ", "page_idx": 8}, {"type": "text", "text": "The reduction from partially observable bandit non-stochastic control to BCO-M consists of two main steps. The first step is to construct the would-be signal $y_{t}(K)$ from the observation $y_{t}$ , where $y_{t}(K)$ is used for updating but not directly observed by the controller. $y_{t}(K)$ is computed by using the Markov operator of the LDS (Simchowitz et al., 2020). The second step is a standard black-box reduction from control to BCO-M, which uses the strong stability of the system. Reduction is formalized in the following definition. ", "page_idx": 8}, {"type": "text", "text": "Definition 8 (Approximation). A bandit non-stochastic control instance (Definition 7) $\\mathcal{L}$ with some convex comparator class $\\Pi$ over a time horizon $T\\in\\mathbb N$ is said to be $\\varepsilon$ -approximated ( $\\varepsilon>0,$ ) by a BCO-M instance (Definition 5) $\\scriptscriptstyle\\mathcal{O}$ with domain $\\kappa=\\Pi$ , if the existence of a BCO-M algorithm $\\bar{\\boldsymbol{A}}^{B}$ implies the existence of a bandit non-stochastic control algorithm $\\mathcal{A}^{\\mathrm{NC}}$ satisfying ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[{\\mathrm{Regret}}_{T}^{A^{\\mathrm{NC}},K}(\\mathcal{L},\\Pi)\\right]\\leq\\mathbb{E}\\left[{\\mathrm{Regret}}_{T}^{A^{B},K}(\\mathcal{O})\\right]+\\varepsilon T.}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "The formal guarantee of the reduction is given below. ", "page_idx": 8}, {"type": "text", "text": "Lemma 9 (Control reduction). Every instance of $(\\alpha_{c},\\beta_{c},G_{c},\\kappa_{s y s},\\kappa,\\gamma,R_{\\mathbf{w},\\mathbf{e}},\\mathcal{V},\\mathcal{U})$ -well  \nconditioned bandit non-stochastic control problem $\\mathcal{L}$ over the ball $\\mathcal{V}\\times\\mathcal{U}\\subset\\mathbb{R}^{d_{\\mathcal{Y}}+d_{u}}$ of radius   \n$R^{\\,4}$ with comparator class $\\Pi\\,=\\,\\mathcal{M}(m,R_{\\mathcal{M}})$ (Definition $^{\\,l}$ ) is $2G_{f}D m T^{-1}$ -approximated by $a$   \n$(\\alpha_{f},\\beta_{f},G_{f},D)$ -well-conditioned BCO-M instance $\\scriptscriptstyle\\mathcal{O}$ with $\\alpha_{f}=\\alpha_{c},~~\\beta_{f}=\\beta_{c},~~D=\\sqrt{m\\operatorname*{max}\\{d_{u},d_{y}\\}}R_{M},~~G_{f}=\\frac{4096\\sqrt{m}G_{c}R_{w,e}^{2}R_{M}^{2}d_{x}^{2.5}\\kappa^{3}\\kappa_{s y s}^{8}}{\\gamma^{5}},$   \nprovided that $m=\\Theta(\\log T/\\log(1/(1-\\gamma)))$ ). 4See Appendix B, $\\begin{array}{r}{R=R_{w,e}\\left(1+\\frac{\\sqrt{d_{x}}\\kappa_{\\mathrm{sys}}}{\\gamma}\\right)\\left(\\sqrt{1+\\kappa^{2}}+R_{M}\\left(1+\\frac{\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sys}}^{2}}{\\gamma}\\right)\\right)=O(1).}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "Lemma 9 implies that every well-conditioned bandit non-stochastic control problem can be reduced to a well-conditioned BCO-M instance, whose parameters are polynomial in those of the control problem. As a result, any regret bound for BCO-M will directly transfer to the control problem (at the expense of polynomial dependence on th\u221ae system parameters). In particular, combining Theorem 6 and Lemma 9, we obtain an optimal $\\tilde{O}(\\sqrt{T})$ regret bound for the bandit non-stochastic control with strongly-convex smooth cost. ", "page_idx": 9}, {"type": "text", "text": "Theorem 10 (Bandit non-stochastic control regret guarantee). Given an $(\\alpha,\\beta,G,\\kappa_{s y s},\\kappa,\\gamma,R_{\\mathbf{w},\\mathbf{e}},\\gamma,\\mathcal{U})$ -well-conditioned bandit non-stochastic control instance $\\mathcal{L}$ over the ball $R\\mathbb{B}_{d_{y}+d_{u}}\\subset\\mathbb{R}^{d_{y}+d_{u}}$ for the same $R$ as in Lemma 9, with $G,\\kappa_{s y s},\\kappa,\\gamma,R_{\\mathbf{w},\\mathbf{e}},d_{x},d_{y},d_{u}=\\tilde{O}(1)^{5}$ , let $(\\Pi,\\kappa,\\eta,m,T,G,K,\\alpha)$ be the input to Algorithm 2 with $m\\:=\\:\\mathrm{poly}(\\log T)$ . Algorithm 2 guarantees that ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{z\\in K}\\mathbb{E}\\left[R e g r e t_{T}^{A l g o r i t h m\\ 2,z}(\\mathcal{O})\\right]\\leq\\tilde{O}\\left(\\frac{\\beta}{\\alpha}\\sqrt{T}\\right),\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where $\\tilde{O}(\\cdot)$ hides all universal constants and logarithmic dependence in $T$ . ", "page_idx": 9}, {"type": "text", "text": "Theorem 10 strictly improves Theorem 8 of (Cassel and Koren, 2020) and Theorem 5 of (Suggala et al., 2024), in the sense that our result achieves the optimal regret with fewer assumptions: all three results achieve the same ${\\tilde{O}}\\left({\\frac{\\beta}{\\alpha}}{\\sqrt{T}}\\right)$ regret bound, however (Cassel and Koren, 2020) requires the additional assumption that perturbations are stochastic, while (Suggala et al., 2024) requires the additional assumption that costs are quadratic. ", "page_idx": 9}, {"type": "text", "text": "Algorithm 2 Improved Bandit Non-stochastic Control ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Input: Step size $\\eta>0$ , memory parameter $m$ , DRC policy class $\\mathcal{M}(\\boldsymbol{m},R_{\\mathcal{M}})$ , time horizon $T$ , system dynamics, $(\\kappa,\\gamma)$ -strongly stabilizing linear policy $K$ , strong convexity parameter $\\alpha>0$ .   \n1: Let $\\boldsymbol{A}^{\\mathrm{B}}$ be an instance of Algorithm 1 with inputs $\\langle\\mathcal{K}=\\mathcal{M}(m,R_{\\mathcal{M}}),\\eta,m,\\alpha,T\\rangle$ .   \n2: Initialize: M 1[j] ${\\cal M}_{1}^{[j]}\\,=\\,\\cdot\\,\\cdot\\,=\\,{\\cal M}_{m}^{[j]}\\,=\\,0_{d_{u}\\,\\times\\,d_{y}}$ , $\\forall j\\in[m]$ . ${\\tilde{g}}_{0}\\,=\\,\\cdot\\,\\cdot\\,=\\,{\\tilde{g}}_{m-1}\\,=\\,0_{m d_{u}d_{y}}$ , $\\hat{A}_{0}\\,=$ A\u02c6m\u22121 = mImdudy\u00d7mdudy.   \n3: Initialize $\\boldsymbol{A}^{\\mathrm{B}}$ for $t=1,\\cdot\\cdot\\cdot,m-1$ (lines 1-4 in Algorithm 1).   \n4: Sample $\\xi_{t}\\sim S^{m d_{u}d_{y}-\\dot{1}}$ i.i.d. uniformly at random for $t=1,\\dots,m$ .   \n5: Play control $u_{t}=K y_{t}$ , incur cost $c_{t}(y_{t},u_{t})$ for $t\\in[m]$ .   \n6: for $t=m,\\ldots,T$ do   \n7: Play control $\\begin{array}{r}{u_{t}^{M_{t}}=K y_{t}+\\sum_{j=0}^{m-1}M_{t}^{[j]}y_{t-j}(K)}\\end{array}$ , incur cost $c_{t}(y_{t},u_{t})$ .   \n8: Let $f_{t}:(\\mathcal{M}(m,R_{\\mathcal{M}}))^{m}\\to\\bar{\\mathbb{R}}$ be the induced with-memory loss function via reduction in Lemma 9 and $H_{t}$ be the associated Hessian estimator in Assumption 5.   \n9: Update $M_{t+1}\\gets A^{\\mathrm{B}}(M_{t},\\{f_{s}\\}_{s=m}^{t},\\{H_{s}\\}_{s=m}^{t})$ . ", "page_idx": 9}, {"type": "text", "text": "10: end for ", "page_idx": 9}, {"type": "text", "text": "", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we devise an algorithm with an $\\tilde{O}(\\sqrt{T})$ regret bound for the bandit non-stochastic control problem with adversarial strongly-convex smooth cost functions. This is the first result with optimal regret that simultaneously breaks the three assumptions of LQC (1) stochastic perturbation (2) full-information feedback (3) quadratic cost. Our control algorithm is built upon an improved algorithm for BCO-M, which may be of independent interest. ", "page_idx": 9}, {"type": "text", "text": "As a preliminary step to address the question of a general control theory for LTI, our result comes with limitations and potential future research directions. Currently, the improvement over the $\\tilde{O}(T^{2/3}$ regret by (Cassel and Koren, 2020) is made under the a\u221additional assumption of strong convexity. It\u2019s unclear whether this assumption is necessary for an $\\tilde{O}(\\sqrt{T})$ regret, we leave determining the minimal assumption on the cost functions for optimal regret as an open question. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Agarwal, N., Bullins, B., Hazan, E., Kakade, S., and Singh, K. (2019a). Online control with adversarial disturbances. In International Conference on Machine Learning, pages 111\u2013119. PMLR.   \nAgarwal, N., Hazan, E., and Singh, K. (2019b). Logarithmic regret for online control. Advances in Neural Information Processing Systems, 32.   \nAnava, O., Hazan, E., and Mannor, S. (2015). Online learning for adversaries with memory: price of past mistakes. Advances in Neural Information Processing Systems, 28.   \nBellman, R. (1954). The theory of dynamic programming. Bulletin of the American Mathematical Society, 60(6):503\u2013515.   \nCassel, A. and Koren, T. (2020). Bandit linear control. Advances in Neural Information Processing Systems, 33:8872\u20138882.   \nGradu, P., Hallman, J., and Hazan, E. (2020). Non-stochastic control with bandit feedback. Advances in Neural Information Processing Systems, 33:10764\u201310774.   \nHazan, E., Agarwal, A., and Kale, S. (2007). Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2):169\u2013192.   \nHazan, E. and Singh, K. (2022). Introduction to online non-stochastic control. arXiv preprint arXiv:2211.09619.   \nKalman, R. E. (1960). A new approach to linear filtering and prediction problems.   \nKalman, R. E. et al. (1960). Contributions to the theory of optimal control. Bol. soc. mat. mexicana, 5(2):102\u2013119.   \nLattimore, T. (2024). Bandit convex optimisation. arXiv preprint arXiv:2402.06535.   \nLattimore, T. and Gy\u00f6rgy, A. (2023). A second-order method for stochastic bandit convex optimisation. In The Thirty Sixth Annual Conference on Learning Theory, pages 2067\u20132094. PMLR.   \nSimchowitz, M. (2020). Making non-stochastic control (almost) as easy as stochastic. Advances in Neural Information Processing Systems, 33:18318\u201318329.   \nSimchowitz, M., Singh, K., and Hazan, E. (2020). Improper learning for non-stochastic control. In Conference on Learning Theory, pages 3320\u20133436. PMLR.   \nSuggala, A., Sun, Y. J., Netrapalli, P., and Hazan, E. (2024). Second order methods for bandit optimization and control. arXiv preprint arXiv:2402.08929.   \nSuggala, A. S., Ravikumar, P., and Netrapalli, P. (2021). Efficient bandit convex optimization: Beyond linear losses. In Conference on Learning Theory, pages 4008\u20134067. PMLR.   \nSun, Y. J., Newman, S., and Hazan, E. (2024). Optimal rates for bandit non-stochastic control. Advances in Neural Information Processing Systems, 36.   \nYan, Y.-H., Wang, J., and Zhao, P. (2024). Handling heterogeneous curvatures in bandit lqr control. In Forty-first International Conference on Machine Learning. ", "page_idx": 10}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "1.1 Technical Overview 2   \n1.2 Related Work 3 ", "page_idx": 11}, {"type": "text", "text": "2 Preliminary 4 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "2.1 Online non-stochastic control with bandit feedback 4   \n2.2 Bandit convex optimization with memory (BCO-M) . . . 5   \n2.3 Notations 6 ", "page_idx": 11}, {"type": "text", "text": "3 Improved Bandit Convex Optimization with Memory 6 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "3.1 BCO-M algorithm .   \n3.2 Proof Sketch . 8 ", "page_idx": 11}, {"type": "text", "text": "4 Optimal Regret for Bandit Non-stochastic Control 9 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "5 Conclusion 10 ", "page_idx": 11}, {"type": "text", "text": "A Proof of Theorem 6 13 ", "page_idx": 11}, {"type": "text", "text": "A.1 Base No-Memory BCO Algorithm and Guarantees 13   \nA.2 Reduction . 15   \nA.3 Bounding Moving Cost . . . 16   \nA.4 Proof of Theorem 6 . 20 ", "page_idx": 11}, {"type": "text", "text": "B Proof of Lemma 9 21 ", "page_idx": 11}, {"type": "text", "text": "A Proof of Theorem 6 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The proof is reduction-based. It consists of three parts ", "page_idx": 12}, {"type": "text", "text": "1. We first consider an algorithm for the no-memory BCO problem, which uses Newton-based updates and a novel delay mechanism. This algorithm will serve as the base algorithm. 2. We then show that the regret of our main algorithm 1 can be bounded by the regret of the base algorithm plus a moving cost, via an improved analysis on $\\kappa_{0}$ -convexity. 3. Finally, we bound the moving cost and then put every pieces together. ", "page_idx": 12}, {"type": "text", "text": "A.1 Base No-Memory BCO Algorithm and Guarantees ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In this section, we prove Lemma 11, which establishes the regret guarantee for the base algorithm used by Algorithm 1. The base no-memory algorithm is a variant of the Newton-based (improper) BCO algorithm considered in Algorithm 1 of (Suggala et al., 2024). The main differences are: ", "page_idx": 12}, {"type": "text", "text": "1. Algorithm 1 in (Suggala et al., 2024) constructs Hessian estimators from the bandit feedback. Algorithm 3 doesn\u2019t require Hessian estimators, since the $H_{t}$ determining $\\kappa_{0}$ -convexity is given by the system instead of loss in bandit control problems, and thus it\u2019s computable by the learner given the system parameters. 2. Algorithm 3 introduces an additional delay mechanism (specified by the delay parameter $d_{0}\\in\\mathbb{N}$ ) to decorrelate neighboring iterates, a necessary ingredient to later analysis. ", "page_idx": 12}, {"type": "text", "text": "Algorithm 3 Simple BCO-with-delay ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Input: convex compact set K \u2282R , step size $\\eta>0$ , delay parameter $d_{0}\\in\\mathbb{N}$ , curvature parameter $\\alpha>0$ , time horizon $T\\in\\mathbb N$ . ", "page_idx": 12}, {"type": "text", "text": "1: Initialize: $o_{1}\\in\\mathcal{K},\\hat{A}_{0}=I_{d\\times d}.~\\hat{A}_{t}=0_{d\\times d},\\forall t<0.~\\tilde{g}_{t}=0,\\forall t\\leq0.$   \n2: Sample $v_{1}\\sim S_{d-1}$ uniformly at random. Set $z_{1}=o_{1}+\\hat{A}_{0}^{-\\,\\frac{1}{2}}v_{1}.$   \n3: for $t=1,\\dots,T$ do   \n4: Play $z_{t}$ , observe $\\bar{f}_{t}(\\boldsymbol{z}_{t})$ , receive $H_{t}$ .   \n5: Update $\\begin{array}{r}{\\hat{A}_{t}=\\hat{A}_{t-1}+\\frac{\\eta\\alpha}{2}H_{t}}\\end{array}$ .   \n6: Create gradient estimate: $\\tilde{g}_{t}=d\\bar{f}_{t}(z_{t})\\hat{A}_{t-1}^{\\frac{1}{2}}v_{t}\\in\\mathbb{R}^{d}$ .   \n7: Update $\\begin{array}{r}{o_{t+1}=\\prod_{K}^{\\hat{A}_{t-d_{0}+1}}\\left[o_{t}-\\eta\\hat{A}_{t-d_{0}+1}^{-1}\\tilde{g}_{t-d_{0}+1}\\right]}\\end{array}$ .   \n8: Sample $v_{t+1}\\sim S_{d-1}$ uniformly at random, independent of previous steps.   \n9: Set $z_{t+1}=o_{t+1}+\\hat{A}_{t}^{-\\frac{1}{2}}v_{t+1}$ . ", "page_idx": 12}, {"type": "text", "text": "10: end for ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Lemma 11 (Base BCO regret guarantee). Suppose that the sequence of loss functions $\\{\\bar{f}_{t}\\}_{t=1}^{T}$ and the convex compact set $\\kappa$ satisfy the conditions in Assumption 7, Assumption ${\\boldsymbol\\beta}$ , and the properties in Observation 4, and $\\operatorname*{max}\\{1,\\|H_{t}\\|_{2}\\}\\leq R_{H},\\forall t$ . With $\\alpha=\\alpha_{f}$ in the first condition in Observation 4, $(\\eta,d_{0})$ satisfying $d_{0}\\leq2/(\\eta\\alpha R_{H})$ , Algorithm 3 run with inputs $(\\kappa,\\eta,d_{0},\\alpha,T)$ satisfies the following regret guarantee: $\\forall o\\in K$ , $\\mathbb{E}\\left[\\sum_{t=1}^{T}\\bar{f}_{t}(z_{t})-\\bar{f}_{t}(o)\\right]\\leq\\frac{2\\beta d}{\\eta\\alpha}\\log(\\eta R_{H}T+1)+2d_{0}G D+\\frac{D^{2}d_{0}R_{H}}{2\\eta}+3\\eta d_{0}d^{2}G^{2}D^{2}R_{H}T.$ In particular, by choosing $\\eta=\\Theta(1/{\\sqrt{T}})$ and $d_{0}=\\tilde{\\Theta}(1)$ , the above regret is of order ${\\tilde{O}}\\left({\\frac{\\beta}{\\alpha}}{\\sqrt{T}}\\right)$ . ", "page_idx": 12}, {"type": "text", "text": "Proof of Lemma $_{l l}$ . First, note that by the condition on $\\eta$ and $d_{0}$ , we have that $\\hat{A}_{t}\\preceq2\\hat{A}_{t-i},\\forall i\\leq d_{0}$ . To see this, it is equivalent to proving any PSD matrix $H$ with $\\lambda_{\\operatorname*{max}}(H)\\leq1$ satisfies that $H\\preceq I$ , which follows from the fact that $x^{\\top}(I-H)x\\geq\\|x\\|_{2}^{2}-\\lambda_{m a x}\\|x\\|_{2}^{2}\\geq0,\\forall x$ . ", "page_idx": 12}, {"type": "text", "text": "By the convexity and curvature assumption on $\\bar{f}_{t}$ described by the conditions in Observation 4, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\bar{f}_{t}(z_{t})-\\bar{f}_{t}(o_{t})\\right]\\leq\\sum_{t=1}^{T}\\mathbb{E}[\\nabla\\bar{f}_{t}(o_{t})^{\\top}\\hat{A}_{t-1}^{-\\frac{1}{2}}v_{t}]+\\frac{\\beta}{2}\\sum_{t=1}^{T}\\mathbb{E}[v_{t}^{\\top}\\hat{A}_{t-1}^{-\\frac{1}{2}}H_{t}\\hat{A}_{t-1}^{-\\frac{1}{2}}v_{t}],\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the first-order term equals 0 since $v_{t}$ is drawn independently of $o_{t},\\bar{f}_{t},\\hat{A}_{t-1}$ , and $\\mathbb{E}[v_{t}]=0$ . We can further bound the second order term by ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\bar{f}_{t}(z_{t})-\\bar{f}_{t}(o_{t})\\right]\\leq\\frac{\\beta}{2}\\sum_{t=1}^{T}\\mathbb{E}[\\hat{A}_{t-1}^{-1}\\cdot H_{t}]\\leq\\frac{2\\beta}{\\eta\\alpha_{f}}\\sum_{t=1}^{T}\\mathbb{E}[\\hat{A}_{t}^{-1}\\cdot(\\hat{A}_{t}-\\hat{A}_{t-1})],\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the first step follows from $\\mathbb{E}[v^{\\top}A v|A]=A\\cdot\\mathbb{E}[v v^{\\top}]$ and the cyclic property of trace, and the last step follows from the definition of $\\hat{A}_{t}$ , the stability condition that $\\hat{A}_{t}\\preceq2\\hat{A}_{t-1}$ , and $\\alpha=\\alpha_{f}$ . Using standard inequalities on log determinant in Newton step analysis (Hazan et al., 2007), we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\bar{f}_{t}(z_{t})-\\bar{f}_{t}(o_{t})\\right]\\leq\\frac{2\\beta}{\\eta\\alpha_{f}}\\log\\frac{\\operatorname*{det}(\\hat{A}_{T})}{\\operatorname*{det}(\\hat{A}_{0})}\\leq\\frac{2\\beta d}{\\eta\\alpha_{f}}\\log\\left(\\frac{\\eta\\alpha_{f}R_{H}T}{2}+1\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Moreover, the curvature assumption on $\\bar{f}_{t}$ also implies ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\bar{f}_{t}(o_{t})-\\bar{f}_{t}(o)\\right]\\leq\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[\\nabla\\bar{f}_{t}(o_{t})^{\\top}(o_{t}-o)]-\\displaystyle\\frac{\\alpha_{f}}{2}\\sum_{t=1}^{T}\\mathbb{E}[\\|o_{t}-o\\|_{H_{t}}^{2}]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[\\tilde{g}_{t}^{\\top}(o_{t}-o)]-\\displaystyle\\frac{\\alpha_{f}}{2}\\sum_{t=1}^{T}\\mathbb{E}[\\|o_{t}-o\\|_{H_{t}}^{2}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the second step follows from $\\mathbb{E}[\\tilde{g}_{t}\\mid o_{t}]=\\nabla\\bar{f}_{t}(o_{t})$ by Stoke\u2019s theorem. By the projection step in Line 7 of Algorithm 3, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\Vert o_{t}-o\\Vert_{\\mathring{A}_{t-d_{0}}}^{2}}\\\\ &{\\le\\Vert o_{t-1}-o-\\eta\\hat{A}_{t-d_{0}}^{-1}\\tilde{g}_{t-d_{0}}\\Vert_{\\mathring{A}_{t-d_{0}}}^{2}}\\\\ &{=\\Vert o_{t-1}-o\\Vert_{\\mathring{A}_{t-d_{0}-1}}^{2}+\\frac{1}{2}\\Vert o_{t-1}-o\\Vert_{\\eta\\alpha_{f}H_{t-d_{0}}}^{2}-2\\eta\\tilde{g}_{t-d_{0}}^{\\top}(o_{t-1}-o)+\\eta^{2}\\Vert\\tilde{g}_{t-d_{0}}\\Vert_{\\mathring{A}_{t-d_{0}}^{-1}}^{2}}\\\\ &{\\le\\Vert o_{t-1}-o\\Vert_{\\mathring{A}_{t-d_{0}-1}}^{2}+\\Vert o_{t-d_{0}}-o\\Vert_{\\eta\\alpha_{f}H_{t-d_{0}}}^{2}+\\Vert o_{t-d_{0}}-o_{t-1}\\Vert_{\\eta\\alpha_{f}H_{t-d_{0}}}^{2}-2\\eta\\tilde{g}_{t-d_{0}}^{\\top}(o_{t-d_{0}}-o)}\\\\ &{\\quad+\\,2\\eta\\tilde{g}_{t-d_{0}}^{\\top}(o_{t-d_{0}}-o_{t-1})+\\eta^{2}\\Vert\\tilde{g}_{t-d_{0}}\\Vert_{\\mathring{A}_{t-d_{0}}^{-1}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the last inequality follows from that $\\forall H\\succeq0$ , $\\|x+y\\|_{H}^{2}\\leq2(\\|x\\|_{H}^{2}+\\|y\\|_{H}^{2}).$ . ", "page_idx": 13}, {"type": "text", "text": "Rearranging, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{g}_{t-d_{0}}^{\\top}(o_{t-d_{0}}-o)-\\frac{\\alpha_{f}}{2}\\|o_{t-d_{0}}-o\\|_{H_{t-d_{0}}}^{2}}\\\\ &{\\leq\\frac{\\|o_{t-1}-o\\|_{\\tilde{A}_{t-d_{0}-1}}^{2}-\\|o_{t}-o\\|_{\\tilde{A}_{t-d_{0}}}^{2}}{2\\eta}+\\frac{\\alpha_{f}}{2}\\|o_{t-d_{0}}-o_{t-1}\\|_{H_{t-d_{0}}}^{2}+\\tilde{g}_{t-d_{0}}^{\\top}(o_{t-d_{0}}-o_{t-1})+\\frac{\\eta}{2}\\|\\tilde{g}_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Note that $\\forall t$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r}{\\|\\tilde{g}_{t}\\|_{\\hat{A}_{t}^{-1}}^{2}\\leq(d G D)^{2}v_{t}^{\\top}\\hat{A}_{t-1}^{\\frac{1}{2}}\\hat{A}_{t}^{-1}\\hat{A}_{t-1}^{\\frac{1}{2}}v_{t}\\leq(d G D)^{2},}\\\\ {\\|o_{t}-o_{t-1}\\|_{2}\\leq\\|o_{t}-o_{t-1}\\|_{\\hat{A}_{t-d_{0}}}\\leq\\eta\\|\\tilde{g}_{t-d_{0}}\\|_{\\hat{A}_{t-d_{0}}^{-1}}\\leq\\eta d G D,}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the second inequality in the second bound follows from the update rule in Line 7 of Algorithm 3, which gives \u2225ot \u2212ot\u22121\u22252A\u02c6t\u2212d $\\begin{array}{r}{\\left\\|o_{t}-o_{t-1}\\right\\|_{\\hat{A}_{t-d_{0}}}^{2}\\leq\\left\\|\\eta\\hat{A}_{t-d_{0}}^{-1}\\tilde{g}_{t-d_{0}}\\right\\|_{\\hat{A}_{t-d_{0}}}^{2}=\\eta^{2}\\left\\|\\tilde{g_{t-d_{0}}}\\right\\|_{\\hat{A}_{t-d_{0}}^{-1}}^{2}}\\end{array}$ . Thus, we can further bound ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\alpha_{f}}{2}\\Vert o_{t-d_{0}}-o_{t-1}\\Vert_{H_{t-d_{0}}}^{2}\\le\\frac{\\alpha_{f}R_{H}d_{0}}{2}\\sum_{i=0}^{d_{0}}\\Vert o_{t-d_{0}+i}-o_{t-d_{0}+i+1}\\Vert_{2}^{2}\\le\\frac{\\eta^{2}\\alpha_{f}d_{0}d^{2}G^{2}D^{2}R_{H}}{2},}\\\\ &{\\qquad\\tilde{g}_{t-d_{0}}^{\\top}(o_{t-d_{0}}-o_{t-1})\\le\\Vert\\tilde{g}_{t-d_{0}}\\Vert_{\\tilde{A}_{t-d_{0}}^{-1}}\\Vert o_{t-d_{0}}-o_{t-1}\\Vert_{\\tilde{A}_{t-d_{0}}}\\le2\\eta d_{0}d^{2}G^{2}D^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Combining both and using that $\\hat{A}_{t}\\preceq2\\hat{A}_{t-i},\\forall i\\leq d_{0}$ , we have that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=0}^{T-d_{0}}\\tilde{g}_{t}^{\\top}(o_{t}-o)-\\frac{\\alpha_{f}}{2}\\|o_{t}-o\\|_{H_{t}}^{2}}\\\\ &{=\\displaystyle\\sum_{t=2d_{0}}^{T}\\tilde{g}_{t-d_{0}}^{\\top}(o_{t-d_{0}}-o)-\\frac{\\alpha_{f}}{2}\\|o_{t-d_{0}}-o\\|_{H_{t-d_{0}}}^{2}}\\\\ &{\\le\\displaystyle\\frac{1}{2\\eta}\\|o_{2d_{0}-1}-o\\|_{\\tilde{A}_{d_{0}-1}}^{2}+\\eta T\\left(\\frac{\\alpha_{f}d_{0}d^{2}G^{2}D^{2}R_{H}}{2}+2d_{0}d^{2}G^{2}D^{2}+\\frac{d^{2}G^{2}D^{2}}{2}\\right)}\\\\ &{\\le\\displaystyle\\frac{D^{2}d_{0}R_{H}}{2\\eta}+3\\eta d_{0}d^{2}G^{2}D^{2}R_{H}T.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "As a result, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\bar{f}_{t}(o_{t})-\\bar{f}_{t}(o)\\right]\\leq2d_{0}G D+\\frac{D^{2}d_{0}R_{H}}{2\\eta}+3\\eta d_{0}d^{2}G^{2}D^{2}R_{H}T.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Combining, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\bar{f}_{t}(z_{t})-\\bar{f}_{t}(o)\\right]\\leq\\frac{2\\beta d}{\\eta\\alpha}\\log(\\eta R_{H}T+1)+2d_{0}G D+\\frac{D^{2}d_{0}R_{H}}{2\\eta}+3\\eta d_{0}d^{2}G^{2}D^{2}R_{H}T.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.2 Reduction ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we prove Lemma 12, which states that the regret of BCO-M algorithm (Algorithm 1) can be related to the regret guarantee of the base no-memory BCO algorithm (Algorithm 3). ", "page_idx": 14}, {"type": "text", "text": "We follow the proof idea of (Cassel and Koren, 2020). In the previous section we have proved an $\\tilde{O}(\\sqrt{T})$ regret bound for a \u201cno-memory\u201d base BCO algorithm. Our main Algorithm 1, however, has memory dependence. When $z_{t}$ is changing slowly, Algorithm 1 is approximately a \u201cno-memory\u201d algorithm, and we can do the following reduction: if all the $z_{t}$ across these steps are the same, Regret(Algorithm 1) will be exactly the same as $m\\times\\mathbf{R}$ egret(base algorithm). ", "page_idx": 14}, {"type": "text", "text": "In this part, we show that when $z_{t}$ are different, we only suffer an additional moving cost ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})\\right],\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which we will bound in Appendix A.3. ", "page_idx": 14}, {"type": "text", "text": "Lemma 12 (Lemma 11, (Cassel and Koren, 2020)). Let $(\\kappa,\\eta,m,T)$ be the input for Algorithm 1. Suppose that the loss functions $\\{f_{t}\\}_{t=m}^{T}$ and the convex compact set $\\kappa$ satisfy Assumption 5, Assumption $6$ , Assumption 7, and Assumption 8. Then, the regret of Algorithm $^{\\,I}$ with respect to any $o\\in\\kappa$ is upper bounded by ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\uptau\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(o)\\right]\\leq3m\\cdot R_{A l g o r i t h m\\;3}\\left(\\frac{T}{m}\\right)+\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})\\right],\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $R_{A l g o r i t h m\\ 3}\\left({\\frac{T}{m}}\\right)$ is the regret upper bound obtained in Lemma $_{l l}$ with time horizon $\\textstyle{\\frac{T}{m}}$ and $d_{0}=2$ . ", "page_idx": 14}, {"type": "text", "text": "Proof of Lemma $^{12}$ . First, note that by assumption, the conditions in Lemma 11 are satisfied for the induced unary forms $\\{\\bar{f}_{t}\\}_{t=m}^{T}$ . The argument follows by reducing Algorithm 1 to Algorithm 3. ", "page_idx": 14}, {"type": "text", "text": "Denote $\\begin{array}{r}{\\chi_{t}=b_{t}\\prod_{i=1}^{m-1}(1-b_{t-i})}\\end{array}$ as the indicator of whether the algorithm gets updated during round $t$ . Recall the definition of $S=\\{t\\in[T]:\\chi_{t}=1\\}$ in Eq. (4). The algorithm updates during round $t$ if $t\\in S$ . For any $t\\in S$ , we have that $\\chi_{t-1}=\\cdot\\cdot:=\\chi_{t-m+1}=0$ . Therefore, we have $z_{t-m+1}=\\cdot\\cdot\\cdot=$ $z_{t}$ by design of Algorithm 1. Thus, we have that $f_{t}(z_{t-m+1:t})=\\bar{f}_{t}(z_{t-m+1})=\\bar{f}_{t}(z_{t})$ . Therefore, constrained to the time steps $t\\in S$ , Algorithm 1 is essentially running Algorithm 3 with a delay parameter $d_{0}=2$ (since in Line 12 of Algorithm 1, we update with the gradient information at time $s_{\\tau-1}$ during round $t$ ). Note that since $\\begin{array}{r}{|\\breve{S|}\\leq\\frac{T}{m}}\\end{array}$ (Algorithm 1 updates at most once every $m$ steps), we have that $\\forall o\\in K$ , ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{b_{1:T},\\{v_{t}\\}_{t\\in S}}\\left[\\sum_{t\\in S}\\bar{f}_{t}(z_{t})-\\sum_{t\\in S}\\bar{f}_{t}(o)\\right]\\le\\mathbb{E}_{b_{1:T}}\\left[R_{A l g o r i t h m~3}(|S|)\\right]\\le R_{A l g o r i t h m~3}\\left(\\frac{T}{m}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "It is left to relate the quantity on the left hand side of the above expression to the regret of Algorithm 1. Since $\\chi_{t}\\overset{D}{=}\\chi_{m}$ (the two random variables equal in distribution), $\\forall t$ , we have $\\mathbb{E}[\\chi_{t}]=\\mathbb{E}[\\chi_{m}]$ . For any fixed $o\\in\\kappa$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{b_{1:T},v_{1:T}}\\left[\\sum_{t\\in S}\\bar{f}_{t}(o)\\right]=\\mathbb{E}_{b_{1:T},v_{1:T}}\\left[\\sum_{t=1}^{T}\\bar{f}_{t}(o)\\cdot\\chi_{t}\\right]=\\mathbb{E}[\\chi_{m}]\\cdot\\mathbb{E}\\left[\\sum_{t=m}^{T}\\bar{f}_{t}(o)\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For $t\\,\\in\\,\\mathbb{N}$ , denote $\\mathcal{F}_{t}$ to be the $\\sigma$ -algebra generated by the randomness of Algorithm 1 through sampling $b_{s},v_{s}$ up to time $t$ , i.e. $\\vec{\\mathcal{F}_{t}^{\\bar{}}}=\\,\\sigma(\\bar{\\{b_{s},v_{s}\\}}_{s=1}^{t})$ . Since $z_{t}\\,=\\,z_{t-m+1}$ whenever $\\chi_{t}\\,=\\,1$ , $b_{t-m+1:t}$ are drawn independently of $z_{t-m+1}$ and $\\chi_{t}$ is independent of $\\mathcal{F}_{t-m}$ by definition of $\\chi_{t}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}_{b_{1:T},v_{1:T}}\\left[\\sum_{t\\in S}\\bar{f}_{t}(z_{t})\\right]=\\mathbb{E}_{b_{1:T},v_{1:T}}\\left[\\sum_{t=m}^{T}\\bar{f}_{t}(z_{t-m+1})\\cdot\\chi_{t}\\right]}}\\\\ &{=\\mathbb{E}_{b_{1:T},v_{1:T}}\\left[\\sum_{t=m}^{T}\\bar{f}_{t}(z_{t-m+1})\\cdot\\chi_{t}\\mid\\mathcal{F}_{t-m},v_{t-m+1}\\right]}\\\\ &{=\\mathbb{E}[\\chi_{m}]\\cdot\\mathbb{E}\\left[\\displaystyle\\sum_{t=m}^{T}\\bar{f}_{t}(z_{t-m+1})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Together, Eq. (7) and Eq. (8) give that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{\\mathbb{I}}_{b_{1:T},\\{v_{t}\\}_{t\\in S}}\\left[\\sum_{t\\in S}\\bar{f}_{t}(z_{t})-\\sum_{t\\in S}\\bar{f}_{t}(o)\\right]=\\mathbb{E}[\\chi_{m}]\\cdot\\mathbb{E}\\left[\\sum_{t=m}^{T}\\bar{f}_{t}(z_{t-m+1})-\\bar{f}_{t}(o)\\right]\\leq\\mathbb{E}[\\chi_{m}]\\cdot R_{A l g o r i t h}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, we have that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(o)\\right]=\\mathbb{E}\\left[\\sum_{t=m}^{T}\\bar{f}_{t}(z_{t-m+1})-\\bar{f}_{t}(o)\\right]+\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1:t})\\right]}}\\\\ &{}&{\\leq(\\mathbb{E}[\\chi_{m}])^{-1}R_{A l g o r i t h m~3}\\left(\\frac{T}{m}\\right)+\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1:t})\\right]}\\\\ &{}&{\\leq3m\\cdot R_{A l g o r i t h m~3}\\left(\\frac{T}{m}\\right)+\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the last inequality follows from ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\chi_{m}]=\\mathbb{E}[b_{m}]\\,\\prod_{i=1}^{m-1}\\mathbb{E}[1-b_{i}]=\\frac{1}{m}\\left(1-\\frac{1}{m}\\right)^{m-1}\\geq\\frac{1}{e m}>\\frac{1}{3m}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A.3 Bounding Moving Cost ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Lemma 11 and Lemma 12 almost give the regret guarantee in Theorem 6. We are left with bounding the moving cost term in Lemma 12 ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "(Cassel and Koren, 2020) bounded each of the summands by $\\mathbb{E}[\\delta_{t}+\\nu_{t}]$ , where $\\delta_{t}=\\|o_{t+1}-o_{t}\\|_{2}$ , and $\\nu_{t}=\\|z_{t}-o_{t}\\|_{2}$ . Making use of the $\\kappa_{0}$ -convexity induced by the affine memory structure of non-stochastic control problems, we can establish a tighter bound that is necessary to obtain optimal regret in Theorem 6. ", "page_idx": 16}, {"type": "text", "text": "Lemma 13 (Moving cost). Let $(\\kappa,\\eta,m,T)$ be the input for Algorithm 1. Suppose that the loss functions $\\{f_{t}\\}_{t=m}^{T}$ and the convex compact set $\\kappa$ satisfy Assumption 5, Assumption 6, Assumption 7, and Assumption 8. Suppose $m\\le2/(\\eta\\alpha R_{H})$ . Then, the iterates output by Algorithm 1 satisfy ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\Sigma}\\left[\\displaystyle\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})\\right]\\leq\\frac{12m^{4}\\beta R_{H}d\\cdot\\operatorname*{max}\\{2,\\eta\\alpha R_{H}\\sqrt{T}\\}}{\\eta\\alpha\\kappa(G)}\\log(\\eta\\alpha R_{H}+1)+\\frac{10m^{4}\\beta R_{H}d\\cdot\\mathbb{H}^{2}}{\\rho_{t}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\left.m^{2}\\beta d R_{H}^{3}\\sqrt{T}+\\eta d G D^{2}\\beta T.\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In particular, with $\\eta=\\Theta({\\sqrt{T}})$ , $m=\\mathrm{poly}(\\log T)$ and $\\kappa(G)=\\Omega(1)$ by Assumption 5, we have that the above bound is of order $\\tilde{O}(\\sqrt{T})$ . ", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma $^{l3}$ . We can decompose the moving cost into three terms: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\underbrace{\\boldsymbol{\\mathbb{\\Sigma}}\\left[\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-f_{t}(o_{t-m+1:t})\\right]}_{(a)}+\\underbrace{\\mathbb{E}\\left[\\sum_{t=m}^{T}f_{t}(o_{t-m+1:t})-\\bar{f}_{t}(o_{t-m+1})\\right]}_{(b)}+\\underbrace{\\mathbb{E}\\left[\\sum_{t=m}^{T}\\bar{f}_{t}(o_{t-m+1:t})-f_{t}(o_{t-m+1:t})\\right]}_{(c)},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and we will bound each of the terms separately. In particular, $(a),(c)$ can be seen as perturbation loss suffered by the algorithm during exploration. $(b)$ is the moving cost determined by the stability of the algorithm\u2019s neighboring iterates. We start with establishing bounds on $(a),(c)$ . ", "page_idx": 16}, {"type": "text", "text": "Perturbation loss. As before, we denote $\\mathcal{F}_{t}=\\sigma(\\{b_{s},v_{s}\\}_{s=1}^{t})$ to be the $\\sigma$ -algebra generated by the randomness of Algorithm 1 through sampling $b_{s},v_{s}$ up to time $t$ . First, $(c)\\leq0$ by Jensen\u2019s inequality for conditional expectations. In particular, recall that $\\chi_{t}=b_{t}\\Pi_{i=1}^{m-1}(1-b_{t-i})$ denotes whether the decision is updated at time $t$ . For every $t\\in\\mathbb{N}$ , denote as $T(t):=\\operatorname*{max}\\{s<t\\mid\\chi_{s}=1\\}$ the last time that the algorithm updates its decision. It naturally holds that ${o_{t}}={o_{T(t)+1}}$ , $v_{t}=v_{T(t)+1}$ by design of Algorithm 1. Therefore, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\bar{f}_{t}(o_{t-m+1})-\\bar{f}_{t}(z_{t-m+1})]=\\mathbb{E}[\\bar{f}_{t}(o_{T(t-m+1)+1})-\\bar{f}_{t}(z_{T(t-m+1)+1})]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}[\\bar{f}_{t}(o_{T(t-m+1)+1})-\\bar{f}_{t}(o_{T(t-m+1)}+\\hat{A}_{t-m}^{-\\frac{1}{2}}v_{T(t-m+1)+1})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By the sampling rule in Line 13 of Algorithm 1, if the algorithm updates its decision at time $t$ $(\\chi_{t}=1)$ , then $v_{t+1}$ is independent drawn from previous steps. On the other hand, $o_{t+1}$ is measurable w.r.t. $\\mathcal{F}_{t}$ . Therefore, we have by Jensen\u2019s inequality for conditional expectations that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}[\\bar{f}_{t}(o_{T(t-m+1)+1})-\\bar{f}_{t}(o_{T(t-m+1)+1}+\\hat{A}_{t-m}^{-\\frac{1}{2}}v_{T(t-m+1)+1})]}\\\\ &{=\\mathbb{E}[\\bar{f}_{t}(o_{T(t-m+1)+1})-\\mathbb{E}[\\bar{f}_{t}(o_{T(t-m+1)+1}+\\hat{A}_{t-m}^{-\\frac{1}{2}}v_{T(t-m+1)+1})\\mid\\mathcal{F}_{T(t-m+1)}]]}\\\\ &{\\leq\\mathbb{E}[\\bar{f}_{t}(o_{T(t-m+1)+1})-\\bar{f}_{t}(\\mathbb{E}[o_{T(t-m+1)+1}+\\hat{A}_{t-m}^{-\\frac{1}{2}}v_{T(t-m+1)+1}\\mid\\mathcal{F}_{T(t-m+1)}])]}\\\\ &{=\\mathbb{E}[\\bar{f}_{t}(o_{T(t-m+1)})-\\bar{f}_{t}(o_{T(t-m+1)})]}\\\\ &{=0}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Summing up over $t$ , we get that $(c)\\leq0$ . We move on to bound $(a)$ . We start with a (conditional) independence argument. ", "page_idx": 16}, {"type": "text", "text": "Independence argument. Fix $t$ . Denote $t_{1}=T(t)$ to be the most recent time when the algorithm makes an update. Additionally, denote $t_{2}=T(T(t))$ to be the second most recent time when the algorithm makes an update. We already have $o_{t}=o_{t_{1}+1}$ . By the delayed update rule in Line 12 of Algorithm 1, we have that $O_{t_{1}+1}$ is updated with $o_{t_{1}}=o_{t_{2}+1}$ and gradient information $\\tilde{g}_{t_{2}}$ and thus is ${\\mathcal{F}}_{t_{2}}$ -measurable. On the other hand, consider the sequence of random vectors $v_{t-m+1},\\ldots,v_{t}$ . We have that $v_{s}=v_{T(s)+1}$ for every $t-m+1\\leq s\\leq t$ . Since the algorithm updates at most once every $m$ steps, we have that $T(s)\\geq t_{2}$ for all $t-m+1\\leq s\\leq t$ . Therefore, $v_{t-m+1},\\ldots,v_{t}$ is independent of ${\\mathcal{F}}_{t_{2}}$ . This observation de-correlates $o_{t}$ with $v_{t-m+1},\\ldots,v_{t}$ conditioning on ${\\mathcal{F}}_{t_{2}}$ . ", "page_idx": 16}, {"type": "text", "text": "For notation simplicity, for matrices $A_{1},\\dots,A_{n}\\in\\mathbb{R}^{d\\times d}$ and vectors $v_{1},\\ldots,v_{n}\\in\\mathbb{R}^{d}$ , we slightly abuse notation and denote as $A_{1:n}v_{1:n}=(A_{1}v_{1},\\ldots,A_{n}v_{n})\\in\\mathbb{R}^{n d}$ to be the concatenated matrixvector product of the two sequences. ", "page_idx": 17}, {"type": "text", "text": "We apply Taylor\u2019s theorem to the function $f_{t}$ and obtain that ", "page_idx": 17}, {"type": "equation", "text": "$$\na)=\\sum_{t=m}^{T}\\mathbb{E}\\left[\\nabla f_{t}(o_{t-m+1:t})^{\\top}{\\hat{A}}_{t-m:t-1}^{-\\frac{1}{2}}v_{t-m+1:t}+\\frac{1}{2}v_{t-m+1:t}^{\\top}{\\hat{A}}_{t-m:t-1}^{-\\frac{1}{2}}\\nabla^{2}f_{t}(q_{t-m+1:t}){\\hat{A}}_{t-m:t-1}^{-\\frac{1}{2}}v_{t-m+1:t}\\right]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $q_{t-m+1:t}$ is some point that lies on the line segment connecting $O_{t-m+1:t}$ and $z_{t-m+1:t}$ . By the conditional independence argument, we have that the first order term vanishes: let $t_{2}=T(T(t))$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\nabla f_{t}(o_{t-m+1:t})^{\\top}\\hat{A}_{t-m:t-1}^{-\\frac{1}{2}}v_{t-m+1:t}\\right]=\\mathbb{E}\\left[\\mathbb{E}\\left[\\nabla f_{t}(o_{t-m+1:t})^{\\top}\\hat{A}_{t-m:t-1}^{-\\frac{1}{2}}v_{t-m+1:t}\\mid\\mathcal{F}_{t_{2}}\\right]\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}\\left[\\nabla f_{t}(o_{t-m+1:t})^{\\top}\\hat{A}_{t-m:t-1}^{-\\frac{1}{2}}\\mathbb{E}\\left[v_{t-m+1:t}\\mid\\mathcal{F}_{t_{2}}\\right]\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The above sum thus reduces to the sum of second-order terms: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{2}\\displaystyle\\sum_{t=m}^{T}\\mathbb{E}\\left[\\widehat{v}_{t-m+1+\\lambda}^{\\top}\\widehat{A}_{t-m+1}^{-\\lambda}\\widehat{v}^{2}f_{t}(q_{t-m+1+\\lambda})\\widehat{A}_{t-m-t}^{-\\frac{1}{2}}v_{t-m+1+\\lambda}t\\right]}\\\\ &{\\leq\\frac{1}{2}\\displaystyle\\sum_{t=m}^{T}\\mathbb{E}\\left[\\left(\\widehat{A}_{t-m}^{-\\frac{1}{2}}v_{t-m+1,\\cdots},\\widehat{A}_{t-m}^{-\\frac{1}{2}}v_{t}\\right)^{\\top}\\widehat{\\nabla}^{2}f_{t}(q_{t-m+1+\\lambda})(\\widehat{A}_{t-m}^{-\\frac{1}{2}}v_{t-m+1},\\ldots,\\widehat{A}_{t-m}^{-\\frac{1}{2}}v_{t})\\right],}\\\\ &{\\leq\\frac{1}{2}\\displaystyle\\sum_{t=m}^{T}\\mathbb{E}\\left[\\operatorname*{sum}_{t\\in\\mathbb{R}^{-\\frac{1}{2}}\\mathbb{H}_{t}^{2}\\lambda}\\operatorname*{max}_{t=0}^{T}\\left[\\begin{array}{c c c c}{\\widehat{A}_{t-m}^{-\\frac{1}{2}}}&{0}&{\\cdots}&{0}\\\\ {0}&{\\widehat{A}_{t-m}^{-\\frac{1}{2}}}&{\\cdots}&{0}\\\\ {0}&{0}&{\\cdots}&{\\widehat{A}_{t-m}^{-\\frac{1}{2}}}\\end{array}\\right]\\nabla^{2}f_{t}(q_{t-m+1+\\lambda})\\left[\\begin{array}{c c c c}{\\widehat{A}_{t-m}^{-\\frac{1}{2}}}&{0}&{\\cdots}&{0}\\\\ {0}&{\\widehat{A}_{t-m}^{-\\frac{1}{2}}}&{\\cdots}&{0}\\\\ {0}&{0}&{\\cdots}&{\\widehat{A}_{t-m}^{-\\frac{1}{2}}}\\end{array}\\right]}\\\\ &{\\leq\\frac{m^{2}}{2}\\displaystyle\\sum_{t=m}^{T}\\mathbb{E}\\left[\\nabla^{2}f_{t}(q_{t-m+1+\\lambda})\\cdot\\left[\\begin{array}{c c c c}{\\widehat{A}_{t-m}^{-1}}&{0}&{\\cdots}&{0}\\\\ {0}&{\\widehat{A}_{t-m}^{- \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first inequality follows from $\\hat{A}_{s}\\preceq\\hat{A}_{t}$ for all $s<t$ ; the second inequality follows from taking maximum over all concatenated unit vectors in $\\mathbb{R}^{d}$ ; the third inequality follows from the inequality between trace and spectral norm. ", "page_idx": 17}, {"type": "text", "text": "From this point on, the bound follows almost identically to the proof of Proposition 21 in (Suggala et al., 2024). We will reiterate the proof in a concise manner for completeness. ", "page_idx": 17}, {"type": "text", "text": "Note that by the assumption of affine memory structure (Assumption 5), we can write the following expression for the Hessian matrix of $f_{t}$ evaluated at $q_{t-m+1:t}$ as the following: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla^{2}f_{t}(q_{t-m+1:t})=\\left[\\!\\!\\begin{array}{c c c}{W_{t-m+1}^{\\top}\\nabla^{2}\\ell_{t}(q)W_{t-m+1}}&{\\ldots}&{W_{t-m+1}^{\\top}\\nabla^{2}\\ell_{t}(q)W_{t}}\\\\ {\\ldots}&{\\ldots}&{\\ldots}\\\\ {W_{t}^{\\top}\\nabla^{2}\\ell_{t}(q)W_{t-m+1}}&{\\ldots}&{W_{t}^{\\top}\\nabla^{2}\\ell_{t}(q)W_{t}}\\end{array}\\!\\!\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\begin{array}{r}{q\\,=\\,B_{t}+\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}q_{t-i}}\\end{array}$ , and $W_{t-m+i}\\,=\\,G^{[m-i]}Y_{t-m+i}$ , $\\forall1\\,\\leq\\,i\\,\\leq\\,m$ . By the curvature assumpti on on $\\ell_{t}$ (Assumption 6), we can further bound the sum of diagonal blocks by ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{m}[\\nabla^{2}f_{t}(q_{t-m+1:t})]_{i i}\\preceq\\beta\\displaystyle\\sum_{i=1}^{m}W_{t-m+i}^{\\top}W_{t-m+i}}&{}\\\\ {\\displaystyle}&{=\\beta\\displaystyle\\sum_{i=1}^{m}Y_{t-m+i}^{\\top}(G^{[m-i]})^{\\top}G^{[m-i]}Y_{t-m+i}}\\\\ &{\\preceq\\beta R_{H}\\displaystyle\\sum_{i=1}^{m}Y_{t-m+i}^{\\top}Y_{t-m+i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{m^{2}}{2}\\displaystyle\\sum_{t=m}^{T}\\mathbb{E}\\left[\\widehat{A}_{t-m}^{-1}\\cdot\\sum_{i=1}^{m}[\\nabla^{2}f_{t}(q_{t-m+1:t})]_{i i}\\right]\\leq\\frac{m^{2}\\beta R_{H}}{2}\\displaystyle\\sum_{t=m}^{T}\\mathbb{E}\\left[\\widehat{A}_{t-m}^{-1}\\cdot\\left(\\displaystyle\\sum_{s=t-m+1}^{t}Y_{s}^{\\top}Y_{s}\\right)\\right]}\\\\ {\\leq m^{2}\\beta R_{H}\\displaystyle\\sum_{t=m}^{T}\\mathbb{E}\\left[\\widehat{A}_{t}^{-1}\\cdot\\left(\\displaystyle\\sum_{s=t-m+1}^{t}Y_{s}^{\\top}Y_{s}\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Consider $\\gamma=\\lfloor{\\sqrt{T}}\\rfloor$ and endpoints $k_{j}=\\gamma(j-1)+m$ for $j=1,\\dots,J$ , and $\\begin{array}{r}{J=\\bigl\\lfloor\\frac{T-m}{\\gamma}\\bigr\\rfloor}\\end{array}$ . Using the fact that $\\operatorname{Trace}(A C)\\leq\\operatorname{Trace}(B C)$ for any PSD matrices $A,B,C$ with $A\\preceq B$ , we can further decompose and bound the sum in the above expression by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle{l R}_{H}\\sum_{t=m}^{T}\\hat{A}_{t}^{-1}\\cdot\\left(\\sum_{s=t-m+1}^{t}Y_{s}^{\\top}Y_{s}\\right)\\leq m^{2}\\beta R_{H}\\sum_{j=1}^{J}\\hat{A}_{k_{j}}^{-1}\\cdot\\left(\\sum_{t=k_{j}}^{k_{j+1}-1}\\sum_{s=t-m+1}^{t}Y_{s}^{\\top}Y_{s}\\right)+m^{2}\\beta\\gamma d R_{H}^{3}}\\\\ &{\\leq m^{3}\\beta R_{H}\\sum_{j=1}^{J}\\hat{A}_{k_{j}}^{-1}\\cdot\\left(\\sum_{t=k_{j}-m+1}^{k_{j+1}-1}Y_{t}^{\\top}Y_{t}\\right)+m^{2}\\beta\\gamma d R_{H}^{3}}\\\\ &{\\leq\\frac{2m^{3}\\beta R_{H}}{K(G)}\\sum_{j=1}^{J}\\hat{A}_{k_{j}}^{-1}\\cdot\\left(5m R_{H}^{2}I+\\sum_{t=k_{j}}^{k_{j+1}-1}H_{t}\\right)+m^{2}\\beta\\gamma d R_{H}^{3}}\\\\ &{=\\frac{2m^{3}\\beta R_{H}}{K(G)}\\sum_{j=1}^{J}\\hat{A}_{k_{j}}^{-1}\\cdot\\left(\\sum_{t=k_{j}}^{k_{j+1}-1}H_{t}\\right)+\\frac{10m^{4}\\beta R_{H}^{3}d\\sqrt{T}}{\\kappa(G)}+m^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the first inequality follows by applying the radius bounds on $Y_{t}$ for the last $T-J\\gamma$ terms and using the fact that $\\mathring{\\hat{A}}_{s}\\preceq\\hat{A}_{t}$ for any $s<t$ ; the last inequality follows by applying Proposition 4.8 in (Simchowitz, 2020). Therefore, it suffices to bound the sum in the first term in expectation. First, recall that $\\forall t$ , $\\chi_{t}=b_{t}\\Pi_{i=1}^{m-1}(1-b_{i})$ denotes whether Algorithm 1 updates during round $t$ , and $S=\\{m\\leq t\\leq T:\\dot{\\chi}_{t}=1\\}$ denotes the set of all rounds where Algorithm 1 updates. To bound the following, we make use of the facts that (1) $H_{t}$ is oblivious, and $(2)\\,\\chi_{t}$ is independent of $\\hat{A}_{k}^{-1}$ for any $k\\leq t-m$ . Then, we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\sum_{t\\in[k_{j},k_{j+1-1}]\\cap\\hat{\\cal S}_{k}}\\hat{A}_{k_{j}-m}^{-1}\\cdot H_{t}\\right]=\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\sum_{t=k_{j}}^{k_{j+1}-1}\\hat{A}_{k_{j}-m}^{-1}\\cdot H_{t}\\cdot\\chi_{t}\\right]}&{}\\\\ {=\\displaystyle\\sum_{j=1}^{J}\\sum_{t=k_{j}}^{k_{j+1}-1}\\mathbb{E}[\\hat{A}_{k_{j}-m}^{-1}\\cdot H_{t}]\\cdot\\mathbb{E}[\\chi_{t}]}&{}\\\\ {=\\mathbb{E}[\\chi_{m}]\\cdot\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\sum_{t=k_{j}}^{k_{j+1}-1}\\hat{A}_{k_{j}-m}^{-1}\\cdot H_{t}\\right]}&{}\\\\ {\\geq\\mathbb{E}[\\chi_{m}]\\cdot\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\sum_{t=k_{j}}^{k_{j+1}-1}\\hat{A}_{k_{j}}^{-1}\\cdot H_{t}\\right].}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Using this and that $\\hat{A}_{t}\\preceq2\\hat{A}_{t-m}$ , we have that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\sum_{t=k_{j}}^{k_{j+1}-1}\\hat{A}_{k_{j}}^{-1},\\ H_{k_{j}}^{-1}\\right]}&{\\leq2\\mathbb{E}\\langle x_{1}\\rangle^{-1}\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\sum_{\\ell_{j},k_{j},i_{\\ell}+1\\ell_{j}}\\hat{A}_{k_{j}}^{-1},H_{k_{j}}^{-1}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\frac{6m}{\\eta\\alpha}\\cdot\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\hat{A}_{k_{j}}^{-1}\\cdot(\\hat{A}_{k_{j+1}-1}-\\hat{A}_{k_{j-1}})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\eta\\alpha}\\\\ &{\\leq\\frac{6m\\cdot\\operatorname*{max}\\{2,\\eta{\\alpha}R\\}\\eta}{\\eta\\alpha}\\cdot\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\hat{A}_{k_{j+1}-1}^{-1}\\cdot(\\hat{A}_{k_{j+1}-1}-\\hat{A}_{k_{j}-1})\\right]}\\\\ &{\\leq\\frac{6m\\cdot\\operatorname*{max}\\{2,\\eta{\\alpha}R\\}\\eta}{\\eta\\alpha}\\cdot\\mathbb{E}\\left[\\displaystyle\\sum_{j=1}^{J}\\log\\left(\\frac{\\operatorname*{det}(\\hat{A}_{k_{j+1}-1})}{d\\mathrm{ex}(\\hat{A}_{k_{j}-1})}\\right)\\right]}\\\\ &{\\leq\\frac{6m\\cdot\\operatorname*{max}\\{2,\\eta{\\alpha}R\\}\\eta}{\\eta\\alpha}\\cdot\\mathbb{E}[\\log\\mathrm{d}\\epsilon(\\hat{A}_{k_{j}})}\\\\ &{\\leq\\frac{6m\\cdot\\operatorname*{max}\\{2,\\eta{\\alpha}R\\}\\eta}{\\eta\\alpha}],\\ \\mathrm{g}[\\mathrm{or}\\,\\ell(R_{j}+1),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the first inequality follows from $\\hat{A}_{k_{j+1}-1}\\preceq\\operatorname*{max}\\{2,\\eta\\alpha R_{H}\\gamma\\}\\hat{A}_{k_{j}}$ , and rest follows from the standard inequalities used in Newton-step analysis (Hazan et al., 2007). ", "page_idx": 19}, {"type": "text", "text": "Combining all the bounds, we have that ", "page_idx": 19}, {"type": "equation", "text": "$$\n(a)\\leq\\frac{12m^{4}\\beta R_{H}d\\cdot\\operatorname*{max}\\{2,\\eta\\alpha R_{H}\\sqrt{T}\\}}{\\eta\\alpha\\kappa(G)}\\log(\\eta\\alpha R_{H}+1)+\\frac{10m^{4}\\beta R_{H}^{3}d\\sqrt{T}}{\\kappa(G)}+m^{2}\\beta d R_{H}^{3}\\sqrt{T}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Movement cost. By design, the algorithm updates at most once in every $m$ iterations. Therefore, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\big(o_{t-m+1},\\ldots,o_{t}\\big)-\\big(o_{t-m+1},\\ldots,o_{t-m+1}\\big)\\|_{2}\\le s,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $s$ is the Euclidean distance between neighboring iterates in Algorithm 3. By analysis in Lemma 11, we have $s\\leq\\eta d G D$ . By Lipschitz assumption on $f_{t}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n(b)\\leq\\eta d G D^{2}\\beta T.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Combining, we have that the total moving cost is bounded by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{\\Sigma}\\left[\\displaystyle\\sum_{t=m}^{T}f_{t}(z_{t-m+1:t})-\\bar{f}_{t}(z_{t-m+1})\\right]\\leq\\frac{12m^{4}\\beta R_{H}d\\cdot\\operatorname*{max}\\{2,\\eta\\alpha R_{H}\\sqrt{T}\\}}{\\eta\\alpha\\kappa(G)}\\log(\\eta\\alpha R_{H}+1)+\\frac{10m^{4}\\beta R_{H}d\\cdot\\mathbb{H}^{2}}{\\rho}}\\\\ {+m^{2}\\beta d R_{H}^{3}\\sqrt{T}+\\eta d G D^{2}\\beta T.\\eqnoindent}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "A.4 Proof of Theorem 6 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Combining result from Lemma 11, Lemma 12, and Lemma 13, we have the regret of Algorithm 1 w.r.t. to any $z\\in\\kappa$ is bounded by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathrm{Regret}_{T}(z)]\\leq3m\\left(\\frac{2\\beta d}{\\eta\\alpha}\\log(\\eta R_{H}T+1)+2d_{0}(G D)+\\frac{D^{2}d_{0}R_{H}}{2\\eta}+3\\eta d_{0}d^{2}(G D)^{2}R_{H}T\\right)}\\\\ &{\\phantom{=\\;}+\\frac{12m^{4}\\beta R_{H}d\\cdot\\operatorname*{max}\\{2,\\eta\\alpha R_{H}\\sqrt{T}\\}}{\\eta\\alpha\\kappa(G)}\\log(\\eta R_{H}T+1)+\\frac{10m^{4}\\beta R_{H}^{3}d\\sqrt{T}}{\\kappa(G)}}\\\\ &{\\phantom{=\\;}+m^{2}\\beta d R_{H}^{3}\\sqrt{T}+\\eta d G\\beta D^{2}T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and by choosing $\\begin{array}{r}{\\eta=\\Theta\\left(\\frac{1}{\\alpha\\sqrt{T}}\\right)}\\end{array}$ , we have the regret above is bounded by $\\begin{array}{r}{\\tilde{O}\\left(\\frac{\\beta}{\\alpha}G D\\sqrt{T}\\right)}\\end{array}$ . ", "page_idx": 19}, {"type": "text", "text": "B Proof of Lemma 9 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we prove Lemma 9. We begin by defining the Markov operator (Simchowitz et al., 2020). ", "page_idx": 20}, {"type": "text", "text": "Definition 14 (Markov operator). Given a partially observable LDS instance parametrized by dynamics $\\begin{array}{r}{A\\in\\mathbb{R}^{d_{x}\\times\\hat{d}_{x}},B\\in\\mathbb{R}^{\\dot{d}_{x}\\times d_{u}},\\overbrace{C}\\in\\mathbb{R}^{d_{y}\\times\\dot{d}_{x}}}\\end{array}$ satisfying Assumption 2 with $(\\kappa,\\gamma)$ -strongly stabilizing $K$ , define the Markov operator to be a sequence of matrices $G=\\{G^{[i]}\\}_{i\\geq0}$ such that $G^{0}=[0;I_{d_{u}}]$ and $\\forall i>0$ , $G^{[i]}$ is given by ", "page_idx": 20}, {"type": "equation", "text": "$$\nG^{[i]}=\\left[\\!\\!\\begin{array}{c c c}{C}\\\\ {K C}\\end{array}\\!\\!\\right](A+B K C)^{i-1}B\\in\\mathbb{R}^{(d_{y}+d_{u})\\times d_{u}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The next observation (Observation 15) relates $y_{t}(K)$ , the signals used by the DRC policies (Definition 1), to the observations and controls along the learner\u2019s trajectory. This justifies the accessibility of the signals. ", "page_idx": 20}, {"type": "text", "text": "Observation 15. Given a partially observable LDS instance with $(\\kappa,\\gamma)$ -strongly stabilizing $K$ , let $G$ be the Markov operator in Definition 14. For $t,m\\,\\in\\,\\mathbb{N},$ , let $M_{1},\\ldots,M_{t-1}\\,\\in\\,\\mathbb{R}^{m\\times d_{u}\\times d_{y}}$ be $(t-1)$ DRC matrices (Definition $^{\\,l}$ ). Let $(y_{t},u_{t})$ be the observation-control pair reached by playing $M_{1},\\ldots,M_{t-1}$ for time step $t=1,\\ldots,t-1$ . Let $u_{t}(K)$ be the control at time $t$ by executing the linear policy $K$ , i.e. $y_{t}(K)=K u_{t}(K),$ , and $y_{t}(K)$ be the would-be observation had $K$ been executed from the beginning of the time. Then, $(y_{t},u_{t})$ and $(y_{t}(K),u_{t}(K))$ can be related by the following equality: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left[\\!\\!\\begin{array}{c}{{y_{t}}}\\\\ {{u_{t}}}\\end{array}\\!\\!\\right]=\\left[\\!\\!\\begin{array}{c}{{y_{t}(K)}}\\\\ {{K y_{t}(K)}}\\end{array}\\!\\!\\right]+\\sum_{i=1}^{t}G^{[i]}\\left(\\sum_{j=0}^{m-1}M_{t-i}^{[j]}y_{t-i-j}(K)\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In particular, Eq. (9) implies that $y_{t}(K)$ can be computed by the learner through access to the Markov operator $G$ and the observations along the learner\u2019s own trajectory. ", "page_idx": 20}, {"type": "text", "text": "With Eq. (9), we are almost ready to reduce the control instance to the BCO-M problem. One delicate detail is that the BCO-M problem is defined for vector-valued decisions, and the the space $\\mathcal{M}(\\boldsymbol{m},R_{\\mathcal{M}})$ is a space of sequences of matrices. For clarity of presentation, we define the following embedding operators. ", "page_idx": 20}, {"type": "text", "text": "Definition 16 (Embedding operators). For $m,d_{y},d_{u}\\in\\mathbb{N}$ , denote $d=m d_{y}d_{u}$ . The embedding operator $\\mathfrak{e}\\,:\\,(\\mathbb{R}^{(d_{u}\\times d_{y})})^{m}\\,\\to\\,\\mathbb{R}^{d}$ is the natural embedding of a DRC controller $M\\,=\\,M^{[0:m-1]}$ (Definition 1) in $\\mathbb{R}^{d}$ . In particular, $\\forall k\\in[m-1],i\\in[d_{u}],j\\in[d_{y}]$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\langle e_{k d_{u}d_{y}+(i-1)d_{y}+j},\\mathfrak{e}(M)\\rangle=M_{i j}^{[k]}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Let $\\mathfrak{e}_{y}:(\\mathbb{R}^{d_{y}})^{m}\\to\\mathbb{R}^{d_{u}\\times d}$ be given by $\\forall y_{t-m+1},\\ldots,y_{t}\\in\\mathbb{R}^{d_{y}},\\forall i\\in[d_{u}],k\\in[m],$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathfrak{e}_{y}(y_{t-m+1:t})]_{i,j+1:j+d_{y}}=y_{t-k+1},\\ \\ \\mathrm{if}\\ \\ j=(k-1)d_{u}d_{y}+(i-1)d_{y}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof of Lemma 9. Let $\\begin{array}{r}{B_{t}\\;=\\;(y_{t}(K),K y_{t}(K))\\,+\\,\\sum_{i=m}^{t}G^{[i]}Y_{t-i}\\mathfrak{e}(M_{t-i})\\;\\in\\;\\mathbb{R}^{d_{u}+d_{y}},\\;\\forall t}\\end{array}$ . Let $Y_{t}=\\mathfrak{e}_{y}(y_{t-m+1:t}(K))$ . Then, by Eq. (9), we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nc_{t}(y_{t},u_{t})=c_{t}\\left(B_{t}+\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}\\mathfrak{e}(M_{t-i})\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We can\u2019t directly define our $f_{t}$ as this function because the $\\begin{array}{r}{\\sum_{i=m}^{t}G^{[i]}Y_{t-i}\\mathfrak{e}(M_{t-i})}\\end{array}$ term in $B_{t}$ depends on historical steps, which will lead to an unbounded m emory. ", "page_idx": 20}, {"type": "text", "text": "To this end, we define ", "page_idx": 20}, {"type": "equation", "text": "$$\nc_{t}\\left((y_{t}(K),K y_{t}(K))+\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}\\mathfrak{e}(M_{t-i})\\right)=:f_{t}(\\mathfrak{e}(M_{t-m+1}),\\ldots,\\mathfrak{e}(M_{t})),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "which is independent of $M_{t-m+1:t}$ , and $Y_{t}$ is independent of $M_{1:T}$ . Note that by the loss function with memory has an affine memory structure. Moreover, $G^{[i]}$ and $Y_{t-i}$ are computable by the learner given system parameters. By the choice of $m=\\Theta(\\log T)$ , the Lipschitzness of $c_{t}$ , and the norm-decaying property of $G^{[i]}$ due to the stability of the system, we can bound the distance ", "page_idx": 21}, {"type": "equation", "text": "$$\n|c_{t}(y_{t},u_{t})-f_{t}(\\mathfrak{e}(M_{t-m+1}),\\dots,\\mathfrak{e}(M_{t}))|=O\\left(\\frac{1}{\\mathrm{poly}(T)}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "In particular, we can choose $m$ such that this term is $O\\left({\\frac{1}{T^{2}}}\\right)$ , then any regret bound on $f_{t}$ in the BCO-M setting directly transfers to the same regret bound on $c_{t}$ in the control setting, at a negligible $o(1)$ cost which will be subsumed by the approximation error term. ", "page_idx": 21}, {"type": "text", "text": "We are left with two steps to conclude this lemma. First, we need to show that $f_{t}$ indeed satisfies the conditions in Definition 5 and specify the constants. Next, because $f_{t}$ is not equal to $c_{t}$ while we only have access to $c_{t}$ , the gradient estimator for $f_{t}$ constructed from $c_{t}$ is biased. We need to bound this error and show that it has negligible impact on the regret bound. ", "page_idx": 21}, {"type": "text", "text": "Step 1: We denote the unary form to be $\\bar{f}_{t}$ as in Definition 2 . Let $\\begin{array}{r l}{\\mathcal{O}}&{{}=}\\end{array}$ $\\{\\bar{\\mathcal{M}}(m,R_{\\mathcal{M}}),m,\\{f_{t}\\}_{t\\geq m,t\\in\\mathbb{N}}\\}$ be the associated BCO-M instance (Definition 5). ", "page_idx": 21}, {"type": "text", "text": "By construction, $f_{t}$ satisfies Assumption 8 and Assumption 5 other than the assumption on positive convolution invertibility-modulus if the truncated vector $\\scriptstyle(y_{t}(K),K y_{t}(K))+\\sum_{i=0}^{m-1}{\\bar{G}}^{[i]}Y_{t-i}{\\bar{\\mathfrak{e}}}(M_{t-i})$ always lives in the $R\\mathbb{B}_{d_{y}+d_{u}}$ and the matrix parameters are bounded. For the positive convolution invertibility-modulus, Lemma 3.1 in (Simchowitz, 2020) proves that the $G^{[0]},\\dots,G^{[m-1]}$ induced by the Markov operator in Definition 14 satisfies the positive convolution invertibility-modulus, i.e. $\\kappa(G)=\\Omega(1)$ . By assumption on $c_{t}$ , the curvature assumption in Assumption 6 is also satisfied. It is left to check the diameter bounds in Assumption 5 and Assumption 7. ", "page_idx": 21}, {"type": "text", "text": "First, we establish a diameter bound on our learning comparator set $\\boldsymbol{K}=\\mathcal{M}(\\boldsymbol{m},R_{\\mathcal{M}})$ . ", "page_idx": 21}, {"type": "text", "text": "Diameter bound on $\\;K=\\mathcal{M}(\\boldsymbol{m},R_{\\mathcal{M}})$ . The diameter of the set $\\mathcal{M}(\\boldsymbol{m},R_{\\mathcal{M}})$ is given by ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\substack{d_{1},M_{2}\\in\\mathcal{M}(m,R_{M})}}{\\operatorname*{max}}\\|\\mathfrak{e}(M_{1})-\\mathfrak{e}(M_{2})\\|_{2}\\leq\\sqrt{m}\\underset{M_{1},M_{2}\\in\\mathcal{M}(m,R_{M})}{\\operatorname*{max}}\\underset{0\\leq j\\leq m-1}{\\operatorname*{max}}\\|M_{1}^{[j]}-M_{2}^{[j]}\\|_{F}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\sqrt{m\\operatorname*{max}\\{d_{u},d_{y}\\}}\\underset{M_{1},M_{2}\\in\\mathcal{M}(m,R_{M})}{\\operatorname*{max}}\\underset{0\\leq j\\leq m-1}{\\operatorname*{max}}\\|M_{1}^{[j]}-M_{2}^{[j]}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\sqrt{m\\operatorname*{max}\\{d_{u},d_{y}\\}}R_{M}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Algorithm 2 essentially calls the improper BCO-M algorithm in Algorithm 1. With the diameter bound on $\\mathcal{M}(\\boldsymbol{m},R_{\\mathcal{M}})$ , we know that the matrices governing the controls picked by Algorithm 2 during each round lives in the set $\\mathcal{M}(m,R_{\\mathcal{M}}+m)$ . For simplicity, we may assume that $R_{{\\mathcal{M}}}\\geq m$ and thus the decisions made by Algorithm 2 live in $\\mathcal{M}(m,2\\bar{R}_{\\mathcal{M}})$ . ", "page_idx": 21}, {"type": "text", "text": "Now, we are ready to prove the gradient bound on $f_{t}$ and the bounds on the observation-control pairs produced by Algorithm 2. ", "page_idx": 21}, {"type": "text", "text": "Gradient bound of $f_{t}$ . First, we bound the sum of op\u221aerator norms for\u221a the Markov operator. By Assumption 2 and the fact that $\\forall M\\in\\mathbb{R}^{n\\times n}$ , $\\|M\\|_{\\mathrm{op}}\\leq\\bar{\\sqrt{n}}\\|M\\|_{\\mathrm{max}}\\leq\\sqrt{n}\\|M\\|_{2}$ , we have that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=0}^{\\infty}\\|G^{[i]}\\|_{\\mathrm{op}}\\leq1+\\displaystyle\\sum_{i=1}^{\\infty}\\sqrt{\\|C(A+B K C)^{i-1}B\\|_{\\mathrm{op}}^{2}+\\|K C(A+B K C)^{i-1}B\\|_{\\mathrm{op}}^{2}}}\\\\ &{\\leq1+\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sps}}^{2}\\displaystyle\\sum_{i=1}^{\\infty}\\|H L^{i-1}H^{-1}\\|_{2}}\\\\ &{\\leq1+\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sps}}^{2}\\displaystyle\\sum_{i=0}^{\\infty}(1-\\gamma)^{i}}\\\\ &{=1+\\displaystyle\\frac{\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sps}}^{2}}{\\gamma}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The signals $y_{t}(K)$ has the following norm bound: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{t\\in[T]}{\\operatorname*{max}}\\,\\|y_{t}(K)\\|_{2}=\\underset{t\\in[T]}{\\operatorname*{max}}\\,\\Bigg\\|C\\underset{i=0}{\\overset{t-1}{\\sum}}(A+B K C)^{i}w_{t-i}+e_{t}\\Bigg\\|_{2}}\\\\ &{\\qquad\\qquad\\leq R_{w,e}\\left(1+\\sqrt{d_{x}}\\kappa_{\\mathbf{sys}}\\underset{i=1}{\\overset{\\infty}{\\sum}}\\,\\|H L^{i-1}H^{-1}\\|_{2}\\right)}\\\\ &{\\qquad\\qquad\\leq R_{w,e}\\left(1+\\frac{\\sqrt{d_{x}}\\kappa_{\\mathbf{sys}}}{\\gamma}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By the unfolding of $(y_{t},u_{t})$ in Eq. (9), the observation and control pair $(y_{t},u_{t})$ has the following norm bound: $\\forall t$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|(y_{t},u_{t})\\|_{2}\\leq\\|(y_{t}(K),K y_{t}(K))\\|_{2}+\\left\\|\\displaystyle\\sum_{i=1}^{t}G^{[i]}\\left(\\displaystyle\\sum_{j=0}^{m-1}M_{t-i}^{[j]}y_{t-i-j}(K)\\right)\\right\\|_{2}}\\\\ &{\\qquad\\qquad\\leq R_{w,e}\\left(1+\\displaystyle\\frac{\\sqrt{d_{x}}\\kappa_{\\mathrm{sys}}}{\\gamma}\\right)\\left(\\sqrt{1+\\kappa^{2}}+2R_{M}\\left\\|\\displaystyle\\sum_{i=0}^{\\infty}G^{[i]}\\right\\|_{\\mathrm{op}}\\right)}\\\\ &{\\qquad\\qquad\\leq R_{w,e}\\left(1+\\displaystyle\\frac{\\sqrt{d_{x}}\\kappa_{\\mathrm{sys}}}{\\gamma}\\right)\\left(\\sqrt{1+\\kappa^{2}}+2R_{M}\\left(1+\\displaystyle\\frac{\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sys}}^{2}}{\\gamma}\\right)\\right)=:R.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The above bound holds similarly for the truncated $\\begin{array}{r l r}{(\\hat{y}_{t},\\hat{u}_{t})}&{{}:=}&{(y_{t}(K),K y_{t}(K))\\;\\;+}\\end{array}$ $\\begin{array}{r}{\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}\\mathfrak{e}(M_{t-i})}\\end{array}$ in Eq. (10), which shows that $(\\hat{y}_{t},\\hat{u}_{t})\\in R\\mathbb{B}_{d_{y}+d_{u}}$ . This also completes ", "page_idx": 22}, {"type": "text", "text": "By assumption, $c_{t}$ obeys the Lipschitz bounds ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\|\\nabla c_{t}(y,u)\\|_{2}\\leq G_{c}\\|(y,u)\\|_{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The gradient bound on $f_{t}$ is given by ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|\\nabla f_{t}(\\mathbf{(}\\mathbf{e}(M_{t-m+1}),\\ldots,\\mathbf{\\Lambda},\\mathbf{e}(M_{t}))\\|_{2}}\\\\ &{=\\left\\|((G^{[m-1]}Y_{t-m+1})^{\\top}\\nabla c_{t}(\\hat{y}_{t},\\hat{u}_{t}),\\ldots,(G^{[0]}Y_{t})^{\\top}\\nabla c_{t}(\\hat{y}_{t},\\hat{u}_{t})\\right\\|_{2}}\\\\ &{\\leq\\sqrt{m}\\left(1+\\frac{\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sys}}^{2}}{\\gamma}\\right)G_{c}R_{w,e}^{2}\\left(1+\\frac{\\sqrt{d_{x}}\\kappa_{\\mathrm{sys}}}{\\gamma}\\right)^{2}\\left(\\sqrt{1+\\kappa^{2}}+2R_{M}\\left(1+\\frac{\\sqrt{d_{x}(1+\\kappa^{2})}}{\\gamma}\\right)\\right)}\\\\ &{\\leq\\frac{4096\\sqrt{m}G_{c}R_{w,e}^{2}R_{M}^{2}d_{x}^{2.5}\\kappa^{3}\\kappa_{\\mathrm{sys}}^{8}}{\\gamma^{5}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Step 2: Clearly the gradient estimator obtained for $f_{t}$ is biased. We denote this error as $a_{t}$ which has a norm bound $\\begin{array}{r}{\\|a_{t}\\|_{2}=O(\\frac{1}{T})}\\end{array}$ with the same reasoning on bounding $\\left|c_{t}-f_{t}\\right|$ . Now, we only need to show that Algorithm 1 can tolerate such perturbation with no loss in regret. ", "page_idx": 22}, {"type": "text", "text": "It\u2019s known that the OGD algorithm can tolerate per-round adaptive gradient perturbation with norm bounded by $O(\\frac{1}{T})$ , with no cost in regret. We will prove a similar argument for Algorithm 3. Suppose in line 6, the unbiased gradient estimator $\\tilde{g}_{t}$ is replaced by a biased estimator $\\hat{g}_{t}=\\tilde{g}_{t}+a_{t}$ , then we want to extend the regret bound for Algorithm 3 in Lemma 11 in this setting with an additional term depending on the sum of magnitude of $a_{t}$ . The analysis in the proof of Lemma 11 remains unchanged except when we bound the regret for the sequence $\\{o_{t}\\}_{t=1}^{T}$ in Eq. (6), the inequality becomes ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\bar{f}_{t}(o_{t})-\\bar{f}_{t}(o)\\right]\\leq\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[\\nabla\\bar{f}_{t}(o_{t})^{\\top}(o_{t}-o)]-\\displaystyle\\frac{\\alpha_{f}}{2}\\sum_{t=1}^{T}\\mathbb{E}[\\|o_{t}-o\\|_{H_{t}}^{2}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[\\hat{g}_{t}^{\\top}(o_{t}-o)]-\\displaystyle\\sum_{t=1}^{T}\\mathbb{E}[a_{t}^{\\top}(o_{t}-o)]-\\displaystyle\\frac{\\alpha_{f}}{2}\\sum_{t=1}^{T}\\mathbb{E}[\\|o_{t}-o\\|_{H_{t}}^{2}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The rest of proof after Eq. (6) is indentical, except that we replace each appearance of $\\tilde{g}_{t}$ by ${\\hat{g}}_{t}$ . ", "page_idx": 23}, {"type": "text", "text": "Therefore, the regret incurred by using $\\hat{g}_{t}$ instead of $\\tilde{g}_{t}$ as the gradient estimator is bounded by the regret upper bound in Lemma 11 and the additional term $\\begin{array}{r}{\\sum_{t=1}^{\\bar{T}}\\mathbb{E}[a_{t}^{\\top}(o_{t}-o)]\\leq a D T}\\end{array}$ , where $a=\\operatorname*{max}_{t\\in[T]}\\|a_{t}\\|_{2}$ . Since $\\textstyle a=O({\\frac{1}{T}})$ , the additional regret is bounded by $O(1)$ . ", "page_idx": 23}, {"type": "text", "text": "Concluding the lemma: Denote ", "text_level": 1, "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha_{f}=\\alpha_{c},~~\\beta_{f}=\\beta_{c},~~D=\\sqrt{m\\operatorname*{max}\\{d_{u},d_{y}\\}}R_{\\mathcal{M}},}\\\\ &{G_{f}=\\frac{4096\\sqrt{m}G_{c}R_{w,e}^{2}R_{\\mathcal{M}}^{2}d_{x}^{2.5}\\kappa^{3}\\kappa_{\\mathbf{sys}}^{8}}{\\gamma^{5}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We have that by Assumption 4 that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathbf{Regrt}_{T}^{k,w}(\\mathcal{L})\\right]}\\\\ &{=\\underset{M\\in\\mathbb{M}(\\mathcal{M},n,H_{\\delta})}{\\operatorname*{max}}\\mathbb{E}\\left[\\sum_{t=1}^{T}c_{\\iota}(y_{t}(M_{1:t-1}),u_{t}(M_{1:t-1}))-c_{\\iota}(y_{t}(M),u_{t}(M))\\right]}\\\\ &{\\le G_{J}D m+\\mathbb{E}\\left[\\sum_{t=0}^{T}f_{\\iota}(\\varepsilon(M_{t-n+1}),\\dots,\\varepsilon(M_{t}))-\\bar{f}_{\\iota}(\\varepsilon(M))\\right]}\\\\ &{\\quad+\\mathbb{E}\\left[\\sum_{t=0}^{T}\\bar{f}_{\\iota}(\\epsilon(M))-c_{\\iota}(y_{t}(M),u_{t}(M))\\right]}\\\\ &{=\\mathbb{E}\\left[\\sum_{t=0}^{T}c_{\\iota}\\left(B_{t}+\\sum_{i=0}^{-1}G^{(i)}Y_{t-i}(\\varepsilon(M))\\right)-c_{\\iota}\\left((y_{i}(K),K y_{t}(K))+\\sum_{i=0}^{t}G^{(i)}Y_{t-i}(\\varepsilon(M))\\right)\\right]}\\\\ &{\\quad+\\mathbb{E}\\left[\\sum_{t=0}^{T}f_{\\iota}(\\epsilon(M_{t-n+1}),\\dots,\\epsilon(M_{t}))-\\bar{f}_{\\iota}(\\epsilon(M))\\right]+G_{J}D m,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\c_{t}\\left(B_{t}+\\sum_{i=0}^{m-1}G^{[i]}Y_{t-i}\\mathfrak{e}(M))\\right)-c_{t}\\left((y_{t}(K),K y_{t}(K))+\\sum_{i=0}^{t}G^{[i]}Y_{t-i}\\mathfrak{e}(M)\\right)}\\\\ &{\\leq G_{c}\\left\\|\\sum_{i=m}^{t}G^{[i]}Y_{t-i}\\mathfrak{e}(M)\\right\\|_{2}\\leq G_{c}\\displaystyle\\sum_{i=m}^{t}\\|G^{[i]}\\|_{\\infty}\\|Y_{t-i}\\|_{F}\\|M\\|_{F}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Recall that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\ \\|M\\|_{F}^{2}=\\displaystyle\\sum_{j=0}^{m-1}\\|M^{[j]}\\|_{F}^{2}\\leq\\operatorname*{max}\\{d_{u},d_{y}\\}\\displaystyle\\sum_{j=0}^{m-1}\\|M^{[j]}\\|_{\\mathrm{op}}^{2}\\leq m\\operatorname*{max}\\{d_{u},d_{y}\\}R_{M}^{2},}\\\\ &{\\displaystyle\\operatorname*{max}_{t\\in[T]}\\|Y_{t}\\|_{2}=\\sqrt{m d_{y}d_{u}^{2}}\\cdot\\operatorname*{max}_{t\\in[T]}\\|y_{t}(K)\\|_{2}\\leq\\sqrt{m d_{y}d_{u}^{2}}\\cdot R_{w,e}\\left(1+\\displaystyle\\frac{\\sqrt{d_{x}}\\kappa_{\\mathrm{sys}}}{\\gamma}\\right),}\\\\ &{\\displaystyle\\sum_{i=m}^{\\infty}\\|G^{[i]}\\|_{\\mathrm{op}}\\leq\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sys}}^{2}\\sum_{i=m}^{\\infty}(1-\\gamma)^{i}\\leq\\frac{\\sqrt{d_{x}(1+\\kappa^{2})}\\kappa_{\\mathrm{sys}}^{2}(1-\\gamma)^{m}}{\\gamma}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We have for $m=\\Theta\\left(\\log T/\\log(1/(1-\\gamma))\\right)$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{G_{c}\\displaystyle\\sum_{i=m}^{t}\\|G^{[i]}\\|_{\\mathrm{op}}\\|Y_{t-i}\\|_{F}\\|M\\|_{F}\\leq\\frac{4G_{c}m d_{y}d_{u}^{2}d_{x}(1+\\kappa^{2})\\kappa_{\\mathrm{sys}}^{4}R_{M}(1-\\gamma)^{m}}{\\gamma^{2}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\frac{G_{c}m d_{y}d_{u}^{2}d_{x}\\kappa^{2}\\kappa_{\\mathrm{sys}}^{4}R_{M}}{\\gamma^{2}T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Combining, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[{\\mathrm{Regret}}_{T}^{A^{\\mathrm{NC}}}(\\mathcal{L})\\right]\\leq\\mathbb{E}\\left[{\\mathrm{Regret}}_{T}^{A^{\\mathrm{B}}}(\\mathcal{O})\\right]+\\frac{G_{c}m d_{y}d_{u}^{2}d_{x}\\kappa^{2}\\kappa_{\\mathrm{sys}}^{4}R_{M}}{\\gamma^{2}}+G_{f}D m}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\mathbb{E}\\left[{\\mathrm{Regret}}_{T}^{A^{\\mathrm{B}}}(\\mathcal{O})\\right]+2G_{f}D m,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "which concludes the claim that $\\mathcal{O}\\:2G_{f}D m T^{-1}$ -approximates $\\mathcal{L}$ . ", "page_idx": 24}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: we make sure all the claims are accurate. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 25}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: we discuss the limitations and future directions for improvement in the Discussion section. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: we provide the full set of assumptions for all theoretical results. We provide a complete (and correct) proof to for all theoretical results, among which the simpler ones are left to the appendix. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 26}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: the paper does not include experiments. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: paper does not include experiments requiring code. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: the paper does not include experiments. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: the paper does not include experiments. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: the paper does not include experiments. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: we carefully follow the NeurIPS Code of Ethics. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: there is no societal impact of the work performed. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: the paper poses no such risks. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: the paper does not use existing assets. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 29}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: the paper does not release new assets. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]