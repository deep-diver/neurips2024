---
title: "Tight Rates for Bandit Control Beyond Quadratics"
summary: "This paper presents an algorithm achieving √ï(‚àöT) optimal regret for bandit non-stochastic control with strongly-convex and smooth cost functions, overcoming prior limitations of suboptimal bounds."
categories: ["AI Generated", ]
tags: ["AI Theory", "Optimization", "üè¢ Princeton University",]
showSummary: true
date: 2024-09-26
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} mlm3nUwOeQ {{< /keyword >}}
{{< keyword icon="writer" >}} Y. Jennifer Sun et el. {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://openreview.net/forum?id=mlm3nUwOeQ" target="_blank" >}}
‚Üó arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/mlm3nUwOeQ" target="_blank" >}}
‚Üó Hugging Face
{{< /button >}}{{< button href="https://huggingface.co/spaces/huggingface/paper-central?tab=tab-chat-with-paper&paper_id=mlm3nUwOeQ&paper_from=neurips" target="_blank" >}}
‚Üó Chat
{{< /button >}}




<audio controls>
    <source src="https://ai-paper-reviewer.com/mlm3nUwOeQ/podcast.wav" type="audio/wav">
    Your browser does not support the audio element.
</audio>


### TL;DR


{{< lead >}}

Classical optimal control theory relies on simplifying assumptions (linearity, quadratic costs, stochasticity) rarely seen in real-world scenarios. This often leads to algorithms performing poorly on real problems. The paper focuses on solving the challenging  **bandit non-stochastic control problem**, which involves adversarial perturbations, non-quadratic cost functions and bandit feedback mechanisms (i.e. limited information about the system's response to actions).  Existing solutions often suffer from suboptimal regret bounds. 

This paper introduces a novel algorithm that significantly improves upon the state-of-the-art. By cleverly **reducing the problem to a no-memory bandit convex optimization (BCO)** and employing a novel Newton-based update, the authors achieve an optimal √ï(‚àöT) regret bound for strongly convex and smooth cost functions. This algorithm effectively addresses the challenges of high-dimensional gradient estimation and the complexity introduced by memory.  The **result is a significant contribution** to the field, providing a more practical and efficient approach to solving general control problems.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} Achieved √ï(‚àöT) optimal regret for bandit non-stochastic control, improving previous suboptimal bounds. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} Developed a novel algorithm that handles adversarial perturbations, bandit feedback models, and non-quadratic cost functions. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} Reduced the complex control problem to a no-memory bandit convex optimization problem, simplifying analysis and algorithm design. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
This paper is crucial because **it addresses a significant gap in optimal control theory**, moving beyond restrictive assumptions like quadratic cost functions and stochastic perturbations.  Its results provide **new avenues for developing more robust and efficient algorithms** for real-world applications. The optimal regret bound achieved is a major step toward solving general control problems. The new algorithm and its analysis are valuable contributions to the field.

------
#### Visual Insights





![](https://ai-paper-reviewer.com/mlm3nUwOeQ/tables_2_1.jpg)

> üîº This table compares the results of this paper with previous works on online non-stochastic control.  It shows the achieved regret bound, the type of perturbation (adversarial, stochastic, semi-adversarial), the feedback model (full or bandit), and the type of loss function used (convex, strongly-convex, smooth, quadratic). The table highlights that this paper is the first to achieve an optimal regret bound of √ï(‚àöT) while addressing all three challenges: adversarial perturbations, bandit feedback, and strongly-convex smooth loss functions.
> <details>
> <summary>read the caption</summary>
> Table 1: Comparison of results. This work is the first to address all three generalities with an √ï(‚àöT) optimal regret: (Agarwal et al., 2019a) addressed perturbation + loss, (Cassel and Koren, 2020) addressed feedback + loss, (Suggala et al., 2024) addressed perturbation + feedback. (Cassel and Koren, 2020) also obtained a sub-optimal √ï(T¬≤/¬≥) regret for perturbation + feedback + loss.
> </details>





### Full paper

{{< gallery >}}
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/mlm3nUwOeQ/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}