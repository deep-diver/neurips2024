[{"figure_path": "PK8xOCBQRO/figures/figures_8_1.jpg", "caption": "Figure 1: Comparison of algorithms on three source-target pairs (n = 2000, nq = 500). Each row corresponds to a different source/target pair (P, Q). For a fixed row, the upper triangular part on columns 2, 3, 4 corresponds a Q for a different algorithm. The upper triangular part of column 1 shows the true P. The lower triangular part of columns 1, 2, 3, and 4 is identical for a fixed row, and shows the true Q. In each heatmap, the lower triangle is the target Q. Algorithm 2 performs best when (P, Q) are SBMs (top), while Algorithm 1 is better for smooth graphons (2nd and 3rd rows).", "description": "This figure compares the performance of three algorithms (Algorithm 1, Algorithm 2, and Oracle with p=0.1) on three different source-target pairs of networks.  Each row represents a different pair, with the true source network (P) shown in the upper left triangle of the first column. The heatmaps compare the true target matrix (Q) (lower left triangle) to the estimated target matrices produced by the three algorithms (upper right triangle). The figure demonstrates that Algorithm 2 is most accurate when both the source and target networks are stochastic block models (SBMs), while Algorithm 1 performs better for smooth graphons.", "section": "4 Experiments"}, {"figure_path": "PK8xOCBQRO/figures/figures_9_1.jpg", "caption": "Figure 2: Results of network estimation on real-world data. Shaded regions denote [1, 99] percentile outcomes from 50 trials. Left half: Estimating metabolic network of iJN1463 (Pseudomonas putida) with source iWFL1372 (Escherichia coli W) leftmost, and source iPC815 (Yersinia pestis) second-left. Right half: Using source data from days 1 \u2013 80 of EMAIL-EU to estimate target days 81 \u2013 160 (third-left) and target days 561 \u2013 640 (rightmost). Note that we use smaller values of p for the Oracle in EMAIL-EU.", "description": "This figure compares the performance of the proposed algorithms (Algorithm 1 and Algorithm 2) and the oracle method on real-world datasets. The left half shows the results for metabolic networks, where the target network is the metabolic network of Pseudomonas putida, and the source networks are the metabolic networks of Escherichia coli and Yersinia pestis. The right half shows the results for email networks, where the target networks are the email interaction networks from different time periods, and the source network is the email interaction network from an earlier period. The shaded regions show the 98% confidence intervals for the mean-squared error (MSE) of the different methods.", "section": "Experiments"}, {"figure_path": "PK8xOCBQRO/figures/figures_28_1.jpg", "caption": "Figure 3: Testing parameters of Algorithm 1 (Transfer for Latent Variable Models). For most parameter settings, our method is better than the baseline and worse than the Oracle. Left: Testing H\u00f6lder-smoothness of fQ with n = 200, nQ = 25, d = 1. All methods improve as \u03b2 \u2192 1. Here fP(x,y) = x+y2, fQ(x,y) = x+y2 with \u03b1 = 0.01 and \u03b2 varying. Middle: Testing number of observed target nodes nQ with n = 200, d = 1. Here fP(x,y) = x+y2, fQ(x,y) = x+y2 with \u03b1 = 0.01, \u03b2 = 0.1. Note that the oracle does not depend on nQ because it observes the full adjacency matrix AQ \u2208 {0,1}n\u00d7n. Right: Testing dimension d of latent positions x1,...,xn \u2208 [0,1]d (i.i.d. Lebesgue) with n = 200, nQ = 25. Here fP(x,y) = exp(\u2212\u03b4||x\u2212y||2) and fQ(x,y) = exp(\u2212|x1\u2212y1|). Points are the median MSE across 50 trials, with with [5, 95] percentile outcomes shaded.", "description": "This figure presents the results of testing Algorithm 1's performance under varying parameters for latent variable models. The left panel shows the impact of smoothness (\u03b2) on the mean squared error (MSE). The middle panel illustrates the effect of the number of observed target nodes (nQ) on the MSE. The right panel examines the influence of latent space dimensionality (d) on the MSE.  For most parameter settings, Algorithm 1 outperforms the baseline but underperforms the oracle, demonstrating its effectiveness in transfer learning.", "section": "Experiments"}, {"figure_path": "PK8xOCBQRO/figures/figures_29_1.jpg", "caption": "Figure 4: Testing parameters of Algorithm 2 (Transfer for SBMs). For most parameter settings, our method is better than the baseline and worse than the Oracle. Left: n = 200, kp = 12, kq = 6. Note that the oracle does not depend on no because it observes the full adjacency matrix Aq \u2208 {0,1}n\u00d7n. Right: n = 200, nq = 25, kp = 2kQ. For both experiments, the intra-community edge probabilities are 0.2, 0.9 for P, Q respectively, while the inter-community edge probabilities are 0.1, 0.8 respectively. Points are the median MSE across 50 trials, with with [5, 95] percentile outcomes shaded.", "description": "This figure displays the results of testing Algorithm 2's performance on Stochastic Block Models (SBMs).  The left panel shows how the mean squared error (MSE) changes with varying numbers of observed target nodes (nq), while the right panel shows the impact of varying the number of communities (kq) in the target model. In both cases, the performance of Algorithm 2 is compared to an oracle and a baseline method. The shaded areas represent the 5th to 95th percentile range of MSE across 50 trials, demonstrating the variability of the results.", "section": "4 Experiments"}, {"figure_path": "PK8xOCBQRO/figures/figures_30_1.jpg", "caption": "Figure 1: Comparison of algorithms on three source-target pairs (n = 2000, nq = 500). Each row corresponds to a different source/target pair (P, Q). For a fixed row, the upper triangular part on columns 2, 3, 4 corresponds a Q for a different algorithm. The upper triangular part of column 1 shows the true P. The lower triangular part of columns 1, 2, 3, and 4 is identical for a fixed row, and shows the true Q. In each heatmap, the lower triangle is the target Q. Algorithm 2 performs best when (P, Q) are SBMs (top), while Algorithm 1 is better for smooth graphons (2nd and 3rd rows).", "description": "This figure compares the performance of three algorithms (Algorithm 1, Algorithm 2, and Oracle) on three different source-target pairs of networks.  Each row represents a different pair, and the heatmaps show the estimated probability matrices (Q) produced by each algorithm compared to the true probability matrices (P and Q).  The results show that Algorithm 2 is most effective for Stochastic Block Models, while Algorithm 1 performs better for smooth graphons. The Oracle method, which has access to complete target data, performs well in all cases.", "section": "4 Experiments"}, {"figure_path": "PK8xOCBQRO/figures/figures_30_2.jpg", "caption": "Figure 1: Comparison of algorithms on three source-target pairs (n = 2000, nq = 500). Each row corresponds to a different source/target pair (P, Q). For a fixed row, the upper triangular part on columns 2, 3, 4 corresponds a Q for a different algorithm. The upper triangular part of column 1 shows the true P. The lower triangular part of columns 1, 2, 3, and 4 is identical for a fixed row, and shows the true Q. In each heatmap, the lower triangle is the target Q. Algorithm 2 performs best when (P, Q) are SBMs (top), while Algorithm 1 is better for smooth graphons (2nd and 3rd rows).", "description": "The figure compares three algorithms (Algorithm 1, Algorithm 2, and Oracle) for estimating the target network Q using transfer learning from a source network P. It shows heatmaps representing the estimated and true probability matrices for three different source-target pairs. Algorithm 2 performs best on stochastic block models, whereas Algorithm 1 is superior for smooth graphons. The Oracle algorithm serves as a performance benchmark.", "section": "4 Experiments"}, {"figure_path": "PK8xOCBQRO/figures/figures_30_3.jpg", "caption": "Figure 1: Comparison of algorithms on three source-target pairs (n = 2000, nq = 500). Each row corresponds to a different source/target pair (P, Q). For a fixed row, the upper triangular part on columns 2, 3, 4 corresponds a Q for a different algorithm. The upper triangular part of column 1 shows the true P. The lower triangular part of columns 1, 2, 3, and 4 is identical for a fixed row, and shows the true Q. In each heatmap, the lower triangle is the target Q. Algorithm 2 performs best when (P, Q) are SBMs (top), while Algorithm 1 is better for smooth graphons (2nd and 3rd rows).", "description": "This figure compares the performance of three algorithms (Algorithm 1, Algorithm 2, and Oracle) on three different source-target network pairs with varying network structures (Stochastic Block Model, Smooth Graphons). It visually demonstrates the accuracy of each algorithm in reconstructing the target network (Q) using limited target data and complete source data (P). The heatmaps represent the adjacency matrices of the true networks and the estimated networks, illustrating the differences between them.", "section": "Experiments"}, {"figure_path": "PK8xOCBQRO/figures/figures_31_1.jpg", "caption": "Figure 1: Comparison of algorithms on three source-target pairs (n = 2000, nq = 500). Each row corresponds to a different source/target pair (P, Q). For a fixed row, the upper triangular part on columns 2, 3, 4 corresponds a Q for a different algorithm. The upper triangular part of column 1 shows the true P. The lower triangular part of columns 1, 2, 3, and 4 is identical for a fixed row, and shows the true Q. In each heatmap, the lower triangle is the target Q. Algorithm 2 performs best when (P, Q) are SBMs (top), while Algorithm 1 is better for smooth graphons (2nd and 3rd rows).", "description": "This figure compares the performance of three different algorithms (Algorithm 1, Algorithm 2, and Oracle) in estimating the target network Q from the source network P and limited target data. It presents the results for three different pairs of source and target networks which have different characteristics (Stochastic Block Models, smooth graphons). Each heatmap visualization shows the true P and Q for each network pair and the estimated Q for the three algorithms.  The results suggest that Algorithm 2 is superior when the networks are Stochastic Block Models, while Algorithm 1 performs better for smooth graphons.", "section": "4 Experiments"}]