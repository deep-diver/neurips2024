[{"figure_path": "4OJdZhcwBb/tables/tables_12_1.jpg", "caption": "Table 1: This table reports counts of hyperparameters (excluding those relating to neural network architecture) from a sampling of prominent algorithms proposed over the last decade. When possible, we tried to use hyperparameter tables listed in the original papers. Otherwise, we used documentation from popular implementations. The comments column contains links to sources used.", "description": "This table presents the number of hyperparameters for various reinforcement learning algorithms proposed over the last decade.  It categorizes algorithms by type (value-based, policy-gradient, model-based), indicating the year of proposal and the count of hyperparameters.  The 'Comments' column provides further details on the hyperparameter counts, referencing sources such as original papers or popular implementations.", "section": "B Proliferation of Hyperparameters"}, {"figure_path": "4OJdZhcwBb/tables/tables_13_1.jpg", "caption": "Table 2: The subsets of hyperparameters that were found to be most impactful to tune per environment as measured when creating Figure 6.", "description": "This table shows, for each algorithm variant, the subsets of hyperparameters that, when tuned, resulted in the most significant performance improvement. The table is organized by the size of the subset (1, 2, or 3 hyperparameters).  For example, for the PPO algorithm, tuning only the \u03bb hyperparameter (Size 1) provided the most benefit.  In contrast, for the Advantage percentile scaling variant, tuning the \u03b1w hyperparameter alone (Size 1) was most impactful, but adding \u03bb and \u03b1\u03b8 yielded further improvements (Size 3). This highlights the differing relative importance of hyperparameters across various algorithm implementations.", "section": "4.3 Sensitivity Experiment with PPO variants"}, {"figure_path": "4OJdZhcwBb/tables/tables_14_1.jpg", "caption": "Table 3: This table reports means and standard deviations across seeds of the average return observed during learning for a subset of the different hyperparameter settings, algorithm variants, and environments.", "description": "This table presents the mean and standard deviation of returns for various PPO algorithm variants across different environments and hyperparameter settings.  The results show the average performance achieved by each algorithm variant under different conditions, providing insights into their relative effectiveness and sensitivity to hyperparameter tuning across various environments.", "section": "4.3 Sensitivity Experiment with PPO variants"}]