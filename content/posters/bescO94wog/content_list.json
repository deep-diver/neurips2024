[{"type": "text", "text": "Partially Observable Cost-Aware Active-Learning with Large Language Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Nicol\u00e1s Astorga, Tennison Liu, Nabeel Seedat & Mihaela van der Schaar DAMTP, University of Cambridge Cambridge, UK nja46@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Conducting experiments and collecting data for machine learning models is a complex and expensive endeavor, particularly when confronted with limited information. Typically, extensive experiments to obtain features and labels come with a significant acquisition cost, making it impractical to carry out all of them. Therefore, it becomes crucial to strategically determine what to acquire to maximize the predictive performance while minimizing costs. To perform this task, existing data acquisition methods assume the availability of an initial dataset that is both fully-observed and labeled, crucially overlooking the partial observability of features characteristic of many real-world scenarios. In response to this challenge, we present Partially Observable Cost-Aware Active-Learning (POCA), a new learning approach aimed at improving model generalization in data-scarce and data-costly scenarios through label and/or feature acquisition. Introducing $\\mu\\mathrm{POCA}$ as an instantiation, we maximize the uncertainty reduction in the predictive model when obtaining labels and features, considering associated costs. $\\mu\\mathrm{POCA}$ enhance traditional Active Learning metrics based solely on the observed features by generating the unobserved features through Generative Surrogate Models, particularly Large Language Models (LLMs). We empirically validate $\\mu\\mathrm{POCA}$ across diverse tabular datasets, varying data availability, acquisition costs, and LLMs. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In real-world machine learning (ML) applications, fully-observed, pristine training data is an exception rather than the norm. This challenge is especially evident during the initial stages of model development when training data is limited and varies in its informativeness across samples [1\u20133]. At this stage, obtaining additional data is crucial for improving model generalization but is fraught with challenges [4\u20136]. In particular, acquiring new data can be costly, often resulting in only essential features and labels being collected, leading to partially observed features in training data. Therefore, it\u2019s vital that acquisition is efficient, yet it remains unclear which features and labels from each instance will ultimately prove essential. Furthermore, data sources themselves can also be partially observed, with different features available across samples, further complicating the acquisition process. These challenges emphasize the importance of a new problem we call Partially Observable Cost-Aware Active-Learning (POCA) illustrated in Figure 1. Before its formalization in Section 2, we provide an intuitive overview: ", "page_idx": 0}, {"type": "text", "text": "Addressing the POCA problem is vital when building systems with partial observation or relevant features are yet to be defined, particularly in fields like customer churn, monitoring, healthcare, and finance (see Appendix A). For example, developing a churn customer prediction system might start with some basic client information, such as demographics and income. However, to build such a system, additional features may be needed, which could be gathered through further customer interactions or surveys. At the outset, it\u2019s uncertain which specific features will prove essential, and acquiring additional information and relevant labels (e.g., churn events) necessary to refine the ML system involves costs related to money, time, or risks limiting the data acquisition in practice. From a practical perspective, we envision POCA to be useful in applications or fields where missing features exist, and also data acquisition techniques like Active Learning (AL) are necessary. Applications from different fields dealing with missing features and/or applying AL can be found in Table 2. ", "page_idx": 1}, {"type": "text", "text": "Related work. The most related data acquisition technique is AL [7\u201310]. AL centers around enhancing model generalization through the acquisition of only additional labels. It operates under the assumption of having access to an initial small, fully observed training set (referred to as the historical labeled set) and seeks to acquire additional labels for samples from an unlabeled dataset (referred to as the pool set). This set is assumed to be fully observed in features, missing only labels. The distinctions between POCA and AL are illustrated in Figure 1. Tangentially, Active Feature Acquisition (AFA) methods [11\u2013 13] have been proposed to enhance the prediction of individual samples at test time\u2014where the sample is partially observed. Like AL, it assumes a fully-observed historical labeled set, on ", "page_idx": 1}, {"type": "image", "img_path": "bescO94wog/tmp/0ee79ee054345157d6fc188978df8d29805730d0cfba8680ebaa5ca4e48939ab.jpg", "img_caption": ["Figure 1: Overview of data acquisition methods. POCA acquires features and/or labels from a partially-observed pool incorporating them into a partially-observed training set. In contrast, AL targets label acquisition assuming a fully-observed pool set and training set. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "which a model has already been trained. Given the trained model, the task then becomes identifying the most relevant unobserved features to acquire for partially observed instances at test time. We emphasize that AFA\u2019s primary focus is on optimizing feature acquisition for individual test samples, differing from our broader goal of data collection to enhance model training. ", "page_idx": 1}, {"type": "text", "text": "Towards an Instantiation of POCA. Given this problem definition, it is natural to wonder whether traditional AL metrics can be employed straightforwardly in the POCA setting. These metrics are usually derived from a predictive model that typically operates with fixed-size inputs. Consequently, predictions on partially observed instances can adversely affect the accuracy of AL metric estimations, leading to acquiring poor quality samples [14]. To overcome this challenge, we incorporate Generative Surrogate Models (GSM) to impute missing features in partially observed inputs, facilitating a more precise estimation of AL metrics. The effectiveness of GSM hinges on its ability to discern feature interrelations from available but unlabeled data. This task is particularly challenging due to the varying degrees of missingness in the instances and the constraints of limited sample sizes. To address these complexities, we employ Large Language Models (LLMs) to instantiate GSMs, utilizing their generation ability based on arbitrary conditioning and strong sample efficiency, allowing robust imputations to support the estimation of AL metrics under partial observability [15\u201317] ", "page_idx": 1}, {"type": "text", "text": "Uncertainty POCA. We term this instantiation uncertainty POCA $\\mathbf{\\Psi}_{\\mathcal{\\mu}}\\mathbf{P}\\mathrm{OCA})$ , due to its connection with Bayesian Experimental Design [18\u201322], and its application in Bayesian Active Learning (BAL)[7, 23] and Bayesian Optimization (BO)[24\u201326]. From a Bayesian perspective, $\\mu\\mathrm{POCA}$ maximizes the expected information gain or also known as expected uncertainty reduction, in the model\u2019s hypothesis resulting from an experiment. More specifically, $\\mu\\mathrm{POCA}$ extends the concepts of expected information gain in the model\u2019s parameters (EIG) and expected predictive information gain (EPIG) to partially observed scenarios, introducing PO-EIG and PO-EPIG, respectively [7, 27, 28]. Here, these methodologies maximize the expected uncertainty reduction when acquiring labels and a subset of features. Since the impact of unacquired features cannot be directly assessed, GSMs facilitate the computation of these metrics. ", "page_idx": 1}, {"type": "text", "text": "In summary, we make the following contributions: ", "page_idx": 1}, {"type": "text", "text": "$\\textcircled{\\scriptsize{1}}$ We address the unexplored challenge of costly data acquisition to enhance model generalization in partially observed scenarios. This leads us to introduce and formalize POCA, a novel ML paradigm for the acquisition of features and/or labels in the partially observed setting. ", "page_idx": 2}, {"type": "text", "text": "$\\circleddash$ We propose $\\mu\\mathrm{POCA}$ , a cost-aware Bayesian instantiation of POCA that maximizes the uncertainty reduction when acquiring data. $\\mu\\mathrm{POCA}$ extends traditional AL metrics by imputing partially observed instances using GSMs. We theoretically show that the uncertainty reduction is larger than using vanilla AL metrics. ", "page_idx": 2}, {"type": "text", "text": "$\\circled{3}$ We propose the use of LLMs as a specific instance of GSMs, designed to address challenges in partially observed scenarios, including data efficiency, arbitrary information conditioning, and handling both categorical and numerical feature values. ", "page_idx": 2}, {"type": "text", "text": "$\\textcircled{4}$ We empirically demonstrate $\\mu\\mathrm{POCA}$ outperforms standard active learning on a variety of partially observability scenarios spanning datasets, sample availability, and acquisition metrics\u2014 highlighting the usefulness and applicability of $\\mu\\mathrm{POCA}$ . ", "page_idx": 2}, {"type": "text", "text": "2 POCA: Partially Observable Cost-Aware Active-Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Preliminaries. Partially Observable Cost-Aware Active-Learning is a data acquisition problem that focuses on improving the predictive performance of $p_{\\phi}(y|x)$ in the supervised setting, with $\\phi$ the models we can employ. We denote $x\\in\\mathscr{x}$ and $y\\in\\mathcal{V}$ as instances of observed features and target, alongside the respective random variables (RV) $\\mathbf{\\deltaX}$ and $Y$ . Bold variables, expressed as $\\pmb{x}=\\{x_{j}\\}_{j=1}^{\\overline{{J}}}$ , represent a set of variables, in this case, features indexed by $j\\in[J]=\\{1,\\dots,J\\}$ , where the bold form of $j$ indicates a set of sub-indices $^j$ . The sample index $i\\,\\in\\,[I]\\,=\\,\\{1,\\dots,I\\}$ , representing possible indexes in the pool set, is omitted when unnecessary, i.e., $x_{i,j}\\equiv x_{j}$ . We denote $\\pmb{x_{o}}$ as the observed features with $o\\subseteq[J]$ .1 In the general case, we assume that each feature $x_{i,j}$ considered for acquisition and the output of interest $y_{i}$ have associated acquisition costs $c_{i,j}$ and $c_{i,J+1}$ . Here, $c_{i,j}$ represents the total cost of acquiring the variables indexed by $^j$ for instance $i$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "POCA ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In the context of partially observed data, our focus is on efficiently gathering features and/or labels to optimize a utility function, $U_{t}(\\cdot)$ subject to an acquisition constraint $r_{t}(\\cdot)$ at iteration $t$ . $U_{t}(\\cdot)$ quantifies the trade-off between the costs of data acquisition and the increased generalization capabilities of the model $\\phi$ , estimated from the available information $\\pmb{x_{o}}$ and the hypothetical acquisition of a specific set of features and/or labels. We formulate the optimization of this utility as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n(i,j)^{*}=\\arg\\operatorname*{max}_{i\\in[I],j\\subseteq[J+1]}U_{t}(i,j),\\;\\mathrm{s.t.}\\;r_{t}(i,j).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "$U_{t}(\\cdot)$ is broadly defined, potentially estimated as result of using Bayesian techniques [18, 23, 27], frequentist techniques [29\u201331], RL techniques [32, 33], or can even be subjectively defined through human desires. Note, optimizing $U_{t}(\\cdot)$ involves an iterative process of $\\textcircled{1}$ selecting the instance and variables $(i,j)^{*}$ to acquire (features and/or labels); $\\circledcirc$ adding these variables into the training set; $\\circled{3}$ updating the model $\\phi$ using the updated training set. In a more general case, this could also encompass batch acquisition [34, 35] by using $\\pmb{i}$ instead of $i$ . Note that Eq. (1) represents the most general form of POCA, supporting model generalization when only features are acquired, as in semi-supervised or self-supervised learning. Our specific $\\mu\\mathrm{POCA}$ instantiation (Section 2.1) focuses on the supervised case, where selected features and labels are acquired. ", "page_idx": 2}, {"type": "text", "text": "Common modalities for POCA. We anticipate that most applications of POCA will center on the tabular domain (see Table 2). However, it could also find valuable uses in fields like medical and satellite imaging, where noise-induced occlusion is common. In these cases, determining when a sample requires additional information (features) is essential for enhancing prediction accuracy and model training. Likewise, interactive robots that learn through vision may benefit from this approach, as they need to discern which scenarios (samples) merit interaction to effectively learn the relationship between features (objects) and labels (task to solve). ", "page_idx": 2}, {"type": "text", "text": "2.1 $\\mu\\mathbf{P}\\mathbf{O}\\mathbf{C}\\mathbf{A}$ : A Bayesian implementation of POCA ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Although several techniques can be used to implement POCA, we opt for a Bayesian approach due to its widespread success in data acquisition literature. Building on the foundational principles of Bayesian Experimental Design [18, 23, 27], which provides a comprehensive framework for integrating various sources of information [36, 37], we introduce an instantiation of POCA within a Bayesian framework. This new approach, termed uncertainty POCA or $\\mu\\mathrm{POCA}$ , leverages information theory [38] to recast Eq. (1) as a cost-aware uncertainty reduction problem [27, 39]. The core of $\\mu\\mathrm{POCA}$ is centered on reducing uncertainty through a class of models that are exclusively trained using supervised learning, focusing on feature and label acquisition in partially observed scenarios. Here, we denote $\\hat{\\mu}_{i,j}$ as the uncertainty reduction for acquiring the label and features $^j$ for sample $i$ , which varies based on the approximation or method used. ", "page_idx": 3}, {"type": "text", "text": "$\\mu\\mathbf{P}\\mathbf{O}\\mathbf{C}\\mathbf{A}$ ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We reformulate the optimization problem (1) by substituting $U_{t}$ with a utility function $\\tilde{U}$ . This function $\\tilde{U}$ is designed to capture the trade-off between uncertainty reduction, $\\hat{\\mu}_{i,j}$ , and the acquisition costs associated with features and labels, represented by $\\bar{c}_{i,j}$ . The new objective can be expressed as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n(i,j)^{*}=\\underset{i\\in[I],j\\subseteq[J]}{\\arg\\operatorname*{max}}\\ \\tilde{U}\\big(\\hat{\\mu}_{i,j},\\bar{c}_{i,j}\\big),\\quad\\mathrm{s.t.}\\ r(i,j),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "here $\\bar{c}_{i,j}=c_{i,j}+c_{i,J+1}$ . In our research, we explore one specific instantiation, among potentially infinite options, denoted by $\\tilde{U}_{i,j}=\\hat{\\mu}_{i,j}$ and $r(i,j)=\\bar{c}_{i,j}<c,$ , respectively, with $c$ indicating the iteration\u2019s budget.2 ", "page_idx": 3}, {"type": "text", "text": "How to obtain this uncertainty? We aim to minimize epistemic uncertainty [40, 41] by acquiring data, decreasing the predictive uncertainty produced by the possible hypothesis explaining the data. We work within the supervised model framework, hence we represent hypotheses as distributions over parameters. Our approach assumes the predictive model $p_{\\phi}(y|x^{\\prime})$ can be expressed as: ", "page_idx": 3}, {"type": "equation", "text": "$$\np_{\\phi}(y|x^{\\prime})=\\mathbb{E}_{p_{\\phi}(\\omega)}[p_{\\phi}(y|x^{\\prime},\\omega)],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\omega\\in\\mathcal W$ is an instance of the parameter space and $\\Omega$ its associated RV. Here, $\\phi$ specifies the model choice, defining the functional form of $\\begin{array}{r}{\\bar{p}_{\\phi}(\\omega)=p(\\omega|D)}\\end{array}$ , the posterior given the observed training set $\\mathcal{D}$ , and the posterior predictive distribution $p_{\\phi}(y|x^{\\prime})$ , marginalized over $\\omega$ . Here, $\\pmb{x}^{\\prime}$ represents a partially observed input, so estimating $p_{\\phi}(y|x^{\\prime})$ must be adaptable to varying lengths of $\\mathbf{\\boldsymbol{x}}^{\\prime}$ . To achieve this flexibility, models capable of handling variable-length inputs (such as Transformers) or, more broadly, marginalization techniques introduced in Section 3.2 can be employed. ", "page_idx": 3}, {"type": "text", "text": "This formulation is general, encompassing Bayesian models, neural networks with certain stochastic parameters [42, 43], and ensemble models [44, 45]. It also applies to Gaussian processes [46] when the posterior $p(\\omega|\\mathcal{D})$ is interpreted as a distribution over functions. ", "page_idx": 3}, {"type": "text", "text": "3 Method: Optimizing \u00b5POCA ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The challenge in optimizing $\\mu\\mathrm{POCA}$ is in developing an uncertainty reduction metric, $\\hat{\\mu}_{i,j}$ , that accurately represents the decrease in uncertainty when acquiring a subset of features $^j$ for instance $i$ , which has not been thoroughly investigated in the Bayesian literature. To address this, let\u2019s first provide some key background information. For data acquisition in ML, the primary focus has been on maximizing the expected uncertainty reduction, also known as expected information gain, when acquiring data [27]. This concept can be mathematically defined as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{I}(A,B):=\\mathrm{H}(A)-\\mathrm{H}(A|B),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\operatorname{H}(A)$ quantifies the uncertainty (entropy) about $A$ , and $\\mathrm{H}(A|B)$ represents the uncertainty of $A$ after observing $B$ (in expectation). Existing AL approaches that utilize the expected reduction of uncertainty are summarized in Table 1. These methods maximize the uncertainty reduction of $\\operatorname{I}({\\mathcal{G}},Y|\\circ)$ when $Y$ is observed. ", "page_idx": 3}, {"type": "text", "text": "Here, we use $\\mathcal{G}$ to represent any random variable aligned with the generalization capabilities of the model and  any arbitrary conditioning. In the Appendix, for completeness, we derive the estimation for these acquisition metrics. ", "page_idx": 4}, {"type": "table", "img_path": "bescO94wog/tmp/97df19f4c1a86513160d033d84bbddec51f5c3fe40d29971733b396e817769cd.jpg", "table_caption": ["Table 1: AL metrics with form of $\\operatorname{I}({\\mathcal{G}},Y|\\circ)$ . "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.1 Metrics for uncertainty reduction in partially observed scenarios ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Challenges in designing $\\hat{\\mu}_{i,j}$ . In real-world scenarios, the challenge is estimating uncertainty reduction based solely on accessible data $\\pmb{x}_{o}$ . Traditional AL acquisition metrics, denoted as $\\mu_{\\phi}(\\pmb{x}_{o})$ , estimate uncertainty scores assuming $\\mathbf{\\boldsymbol{x}}_{o}\\equiv\\mathbf{\\boldsymbol{x}}$ . However, in partially observed scenarios where only a subset of inputs, $\\mathbf{\\boldsymbol{x}}_{o}\\subseteq\\mathbf{\\boldsymbol{x}}$ , is available, the observed features may lack sufficient informativeness for precise $y$ estimates and reliable uncertainty scores $\\mu_{\\phi}({\\pmb x}_{o})$ . ", "page_idx": 4}, {"type": "text", "text": "Generative Surrogate Model (GSM) to estimate metrics. A more accurate estimate of current metrics can be achieved using the aforementioned AL metrics by imputing the potential missing features in expectation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mu_{\\phi,\\theta}^{j}(\\mathbf{x}_{o}):=\\mathbb{E}_{\\tilde{\\mathbf{x}}_{j}}[\\mu_{\\phi}(\\mathbf{x}_{o}\\cup\\tilde{\\mathbf{x}}_{j})].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, the samples $\\Tilde{\\pmb{x}}_{j}$ are obtained with a GSM denoted as $p_{\\theta}(\\mathbf{\\bar{x}}_{j}|\\mathbf{x}_{o})$ , which sample possible unobserved features $\\pmb{x}_{j}$ based on the observed $\\pmb{x}_{o}$ . It\u2019s worth noting that training $p_{\\theta}(x_{j}|\\mathbf{\\boldsymbol{x}}_{o})$ could be done leveraging unlabeled data. In Figure 2, we illustrate the acquisition process of $\\mu\\mathrm{POCA}$ using GSMs. ", "page_idx": 4}, {"type": "text", "text": "Why generative imputation can help Active Learning? In Bayesian active learning, acquisition is closely linked to the concept of uncertainty reduction. To identify which features need to be acquired, it is essential to estimate the possible unobserved values. If these values lie in areas of high uncertainty within the hypothesis space, acquiring these features is beneficial, as it will help reduce this uncertainty. Conversely, if the possible values for certain unobserved features show little or no impact on uncertainty, then acquiring these features may not be necessary. Notably, deterministic imputation cannot achieve this, as the lack of variability prevents assessment of its effect on uncertainty within the hypothesis space. This concept is illustrated in Figure 11 from Appendix H. ", "page_idx": 4}, {"type": "image", "img_path": "bescO94wog/tmp/ebad8ef5beaf39e8518001f1371b20da76dde7ccb93fce954413b6163b04306a.jpg", "img_caption": ["Figure 2: $\\mu\\mathrm{POCA}$ leverages GSMs trained on unlabeled data for imputing missing features. The imputed observations are used as an input for the predictive model, whose outputs are used to compute the acquisition metric. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Are we doing better? We demonstrate the theoretical value of this approach for a family of acquisition metrics presented in Table 1, delving into their impact on the optimization process. These propositions convey the intuitive idea that acquiring more information, in this case, features, leads to a higher reduction in uncertainty for the predictive model (proofs can be found in Appendix B). ", "page_idx": 4}, {"type": "text", "text": "Proposition 1. Let $\\mu({\\pmb x}_{o})$ be an acquisition metric that can be written as $\\operatorname{I}({\\mathcal{G}},Y|\\circ)$ , with $\\mathcal{G}$ and \u2022 representing the same variables observed in traditional $A L$ (Table $^{\\,l}$ ), and with $Y$ , $X_{j}$ as previously defined. If $\\mathcal{G}\\perp\\!\\!\\!\\perp X_{j}|$ , the following equality holds: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname{I}({\\mathcal{G}},(Y,X_{j})|\\,\\,)=\\mathbb{E}_{{\\pmb{x}}_{j}}\\operatorname{I}({\\mathcal{G}},Y|{\\pmb{x}}_{j},\\,\\circ\\,)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Corollary 1. Under the assumptions of Proposition $^{\\,l}$ , the subsequent inequality is established: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{\\boldsymbol{x}}_{j}}\\mathrm{I}(\\mathcal{G},Y|\\mathbf{\\boldsymbol{x}}_{j},\\mathbb{\\mathbf{\\xi}})\\geq\\mathrm{I}(\\mathcal{G},Y|\\mathbb{\\boldsymbol{\\circ}})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Equality is attained when $\\mathcal{G}\\perp\\!\\!\\!\\!\\perp X_{j}|Y,$ . ", "page_idx": 4}, {"type": "text", "text": "$\\mathtt{a}$ Proposition 1 states that the uncertainty reduction of $\\mathcal{G}$ (e.g., the random variable of the parameters, $\\Omega$ ) by knowing $Y$ and $X_{j}$ is equivalent to the expected uncertainty reduction achieved by knowing $Y$ while conditioning on unobserved variables $\\pmb{x}_{j}$ . This is convenient as the conditioning on $\\pmb{x}_{j}$ can be computed using Monte-Carlo approximation [48]. ", "page_idx": 4}, {"type": "text", "text": "$\\mathtt{a}$ Corollary 1 implies that acquiring both labels and features results in greater uncertainty reduction compared to acquiring only labels, the objective maximized in traditional AL (Table 1). The uncertainty reduction is equivalent when, given \u2022 and $Y$ , the unobserved features $X_{j}$ don\u2019t have any impact in generalization $\\mathcal{G}$ . ", "page_idx": 5}, {"type": "text", "text": "Note that the independence assumption of Proposition 1 is valid in the supervised models we consider. In essence, this is because acquiring features without labels do not aid parameter updates and in consequence generalization improvements. The foundation of this assumption lies in the predictive mapping process from $X\\rightarrow Y\\leftarrow\\Omega$ , rather than in the data itself. Appendix B provides a more detailed explanation of this independence assumption\u2019s validity. Additionally, empirical evidence supporting the validity of Corollary 1 and, by extension, Proposition 1, is shown in Appendix K. ", "page_idx": 5}, {"type": "text", "text": "Equations (6) and (7) always apply to the true random variable of unobserved features or any of its approximations. However, the terms in Eq. (6) reflect the uncertainty reduction of obtaining the actual features when the approximated distribution of the GSM accurately reflects the distribution of the true random variable. We empirically investigate this approximation and its practical utility. ", "page_idx": 5}, {"type": "text", "text": "PO Active learning metrics. Building on Proposition 1 and Corollary 1, we extend BALD and EPIG as $\\blacktriangleright$ Partially Observable Expected Information Gain (PO-EIG): $\\mathbb{E}_{\\mathbf{x}_{j}}\\mathrm{I}\\big(\\Omega,Y|x_{j},x_{o},D\\big)$ and $\\blacktriangleright$ Partially Observable Expected Predictive Information Gain (PO-EPIG): $\\mathbb{E}_{{\\pmb x}_{j}}\\mathrm{I}({\\pmb Y}^{e v a l},{\\boldsymbol Y}|{\\pmb x}_{j},{\\pmb x}_{o},{\\pmb X}^{e v a l},\\mathcal{D})$ . Corollary 1 states that these metrics provide a higher uncertainty reduction than their vanilla counterparts. We use Monte-Carlo for estimation (see Appendix C). ", "page_idx": 5}, {"type": "text", "text": "3.2 Predictive models in the PO setting ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our derivations are based on a distribution perspective, considering different numbers of conditioned variables. For instance, when calculating PO-EIG, expressed as $\\mathbb{E}_{\\mathbf{x}_{j}}\\mathrm{I}\\big(\\Omega,Y|x_{j},x_{o},D\\big)$ , it is necessary to compute the distribution $p_{\\phi}(y|\\pmb{x}_{o},\\pmb{x}_{j})$ . Here, $\\pmb{x}_{o}$ could vary in length from one instance to another and $\\boldsymbol{x}_{j}$ varies based on the number of features considered for computing the uncertainty reduction metric. In practical terms, this means that the predictive model, attempting to approximate this distribution, must effectively handle inputs with varying variables and lengths. ", "page_idx": 5}, {"type": "text", "text": "To address this challenge, we employ GSMs to impute the missing information to enable predictive models that expect fixed-size inputs. This imputation is separated in two different steps (1) conditioning and (2) marginalization. Essentially, when evaluating the uncertainty reduction of an unobserved subset of features $\\boldsymbol{x}_{j}$ considered for acquisition, we condition on this subset $\\pmb{x}_{j}$ and $x_{o}$ (the observed features), marginalizing over the remaining subset of unobserved features $\\pmb{x}_{j^{\\prime}}$ (where $x_{j}\\cup x_{j^{\\prime}}$ is the set of all unobserved features). This approximation process is mathematically formalized as follows, with supplementary visual aids provided in Figure 8 of Appendix C.3: ", "page_idx": 5}, {"type": "equation", "text": "$$\np_{\\phi}(y|x_{o},x_{j})=\\int p_{\\phi}(y|x_{o},x_{j},x_{j^{\\prime}})p_{\\theta}(x_{j^{\\prime}}|x_{o},x_{j})=\\mathbb{E}_{p_{\\theta}(x_{j^{\\prime}}|x_{o},x_{j})}[p_{\\phi}(y|x)],\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here the predictive model simulates the behavior, wherein the predictive model only has access to $\\pmb{x}_{o}$ and $\\pmb{x}_{j}$ but it is computed using a model as it would have all the features. The marginalization step is essential for accurate metric estimation in the pool set and can also be applied during training. However, to reduce costs, we use GSM to impute features not acquired in the training set. ", "page_idx": 5}, {"type": "text", "text": "3.3 Efficient computation of utility function, Eq. (2) ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our goal is to maximize $\\tilde{U}_{i,j}(\\cdot)~\\equiv~\\tilde{U}(\\hat{\\mu}_{i,j},\\bar{c}_{i,j}),$ , which incorporates the uncertainty reduction $\\hat{\\mu}_{i,j}$ . It is crucial to recognize that $\\hat{\\mu}_{i,j}$ could encompass all possible combinations of unobserved features. However, computing $\\hat{\\mu}_{i,j}$ for every possible combination of $(i,j)$ is impractical, since it is of order ${\\mathcal{O}}(2^{J})$ . To overcome this challenge, we propose estimating the uncertainty reduction for all unobserved features and subsequently excluding the less relevant ones, i.e. those contributing minimally to uncertainty reduction. This ensures that we always retain the most relevant features until the constraint $r$ in Eq. (2) is satisfied, in order ${\\mathcal O}(J^{2})$ . The acquisition process is summarized in Algorithm 1, with feature selection steps highlighted in teal. Appendix C.3 provides details on an efficient approach to computing the marginalization step necessary for estimating $\\hat{\\mu}_{i,j}$ . This efficiency can be further improved by selecting the most informative samples, followed by the application of Algorithm 1 (see Appendix D). For a comprehensive overview, including cost analyses, and details on GSM training and sampling, refer to Appendix D. ", "page_idx": 5}, {"type": "table", "img_path": "bescO94wog/tmp/b1cbaaa8036960195ffcd1451c7b122b3f812e2d8b5a9ee4b5e8a8cd21d5f596.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "3.4 Large Language Models as Generative Surrogate Models ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "LLMs as GSMs. For the scenarios outlined in POCA, we specify the following desiderata for GSMs: (P1) generative capability, (P2) ability to learn from partially observed data, (P3) sample efficiency, and (P4) seamless integration of mixed-type variables. We argue that LLMs are well-suited to meet these criteria due to their $\\blacktriangleright$ generative capabilities and flexibility in training under $\\blacktriangleright$ arbitrary conditioning contexts [49\u201351]. Moreover, recent research highlights their exceptional performance in $\\blacktriangleright$ few-shot settings [52, 53] and their generative capabilities applied to $\\blacktriangleright$ tabular data comprising mixed-type attributes [51]. These strengths provide strong justification for focusing our research on LLMs as GSMs. However, any imputation method that fulfills these criteria may also serve as a suitable GSM, as further discussed in Appendix G. ", "page_idx": 6}, {"type": "text", "text": "We use LLMs as GSMs leveraging the unlabelled information via Supervised Fine-Tuning (SFT). When working with tabular data, we serialize rows of the data, thereby converting it to natural language. For example, a set of features is serialized as \u201cAge is 25, Gender is Female, ..., Blood pressure is $\\it0.57^{\\,\\circ}$ . The LLM is then used to predict unobserved features based on available information. To achieve this, we utilize SFT on the LLM with the available observed features. The training data can encompass all unlabeled data, including historical and pool set data. The process entails generating random masks to form an input, $m\\odot\\mathbf{x}_{o}$ , and an output, $\\left(1-m\\right)\\odot{\\pmb x}_{o}$ , for SFT across all available data. This empowers the LLM to predict missing information by leveraging various combinations of observed features.3 For more details, refer to Appendix F.2. ", "page_idx": 6}, {"type": "text", "text": "Analysis of GSMs. The effectiveness of $\\mu\\mathrm{POCA}$ in partially observed settings is closely tied to the GSM\u2019s ability to approximate the distribution of unobserved features. Two primary factors influence the accuracy of this approximation: (1) the approximation capacity of the GSM and (2) intrinsic characteristics of the dataset. A detailed examination of these factors is provided in Appendix J. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate $\\mu\\mathrm{POCA}$ across three dimensions 4: First, in the case that all features are acquired, we demonstrate that $\\mu\\mathrm{POCA}$ acquisition metrics are more informative in selecting instances with informative features than AL metrics. Second, we present a synthetic experiment accompanied by theoretical insights. Finally, we explore scenarios with budget constraints demonstrating that $\\mu\\mathrm{POCA}$ on more challenging scenarios. ", "page_idx": 6}, {"type": "text", "text": "Comparing $\\mu\\mathrm{POCA}$ with the current AL models is complex, as the latter are designed for fixed-size inputs. To address this challenge, we developed Scenario 1 (see visual aid in Appendix H). This scenario involves dividing each instance in the pool set into the same observed and unobserved feature sets. We specifically select half of the features to remain unobserved, chosen by their high relevance to the predictive task as identified by a preliminary RF. It is important to note that while $\\mu\\mathrm{POCA}$ methods can handle any form of missing data, Scenario 1 ensures a fair comparison by allowing AL models to operate without any modification, which could bias our evaluation. This scenario presumes the availability of a historical unlabeled dataset for training the GSM, using instances that include data on unobserved features. In practical applications, the pool set can often serve as the training set itself, representing a more realistic scenario we may encounter. We refer to this setting as Scenario 2. Results for this scenario are presented in Appendix I, where GSM is trained on partially observed data, while vanilla AL employs deterministic imputation to manage this case. ", "page_idx": 6}, {"type": "text", "text": "We select Magic, Adult, Housing, Cardio, and Banking tabular datasets based on their use in AL [28], tabular generation [49, 51], LLM-based classification [54], and relation with potential real-world applications (Appendix A). These datasets have diverse characteristics: sample size, number of features, number of categorical, and numerical variables. We prioritize datasets with over 1000 samples to guarantee sufficient samples for the pool set. We showcase results using a RF trained with 100 estimators. We start training with two fully observed samples per class, conduct 150 acquisition cycles, repeat each experiment over 60 seeds, and display a $95\\%$ confidence interval. We train Mistral7B-Instruct- $\\cdot\\mathrm{v}0.3$ using 8 Monte-Carlo samples for generative imputation. ", "page_idx": 6}, {"type": "image", "img_path": "bescO94wog/tmp/e04003d6afb2b0d6901501ca358d966b5abb079520801fecfd883458472d6c7d.jpg", "img_caption": ["Figure 3: PO-EIG and PO-EPIG computed across diverse datasets - showing they either outperform or match their fully observed counterpart in terms of predictive performance "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4.1 Need for POCA: Shortfalls of Active Learning ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Objective. To assess the need for more generalized methodologies such as $\\mu\\mathrm{POCA}$ , we analyze the performance of PO-EIG, a partially observed extension of BALD (EIG)\u2014the most widely used metric in active learning literature. Additionally, we incorporate EPIG into the study, a recently developed active learning metric within the 1 family. According to our theoretical framework (see Corollary 1), PO-metrics outperforms their vanilla counterparts in terms of uncertainty reduction. Our goal is to examine whether this uncertainty reduction leads to improved downstream performance when all features are acquired based on the same information, $\\pmb{x_{o}}$ , or, in other words, if the selected instances possess features that are more relevant. ", "page_idx": 7}, {"type": "text", "text": "Setup. To ensure a fair comparison, we evaluated $P O$ -metrics and Vanilla-metrics under Scenario 1, using Random and Oracle as reference baselines. Here, Oracle represents the Vanilla-metrics acquisition metric, but with access to all features. Ideally, when GSM functions optimally, the performance of PO-EIG should align with that of Oracle. ", "page_idx": 7}, {"type": "text", "text": "Analysis. The first thing to note is that EIG metrics computed with partially observed features can be significantly worse than simple baselines like random as shown in Magic dataset from Figure 3) (top). Figure 3 (top) demonstrates that PO-EIG generally either outperforms or worst case matches their fully observable counterparts BALD across all datasets. A similar behavior is observed for PO-EPIG, which generally outperforms their vanilla metric counterpart. This suggests that an increase in uncertainty reduction translates into an increase in downstream performance. While PO-EIG and PO-EPIG metrics consistently outperform baselines, they occasionally fall short of oracle performance, notably in the Housing datasets. This may stem from two factors: Firstly, the GSM has poor prediction performance on the unobserved data due to insufficient data or model capacity. Secondly, even with adequate capacity and data, weak correlation between unobserved data and the target hinders the acquisition process. We study these factors in Appendix J. We note that it is non-trivial to quantify the GSM\u2019s capability or correlations of unobserved data to the target. Thus, the practical implication is that both $P O$ -metrics should be preferred in PO settings, providing a performance boost or at least matching their vanilla counterparts. Additionally, in Appendix I.1, we include other relevant Active Learning metrics that, while not fitting into the family of studied metrics, also demonstrate performance gains with the proposed framework. ", "page_idx": 7}, {"type": "text", "text": "First, AL metrics computed on partially observed features can dramatically fail for selecting relevant instances. Second, PO-EIG and PO-EPIG generally outperform or match fully observed counterparts. ", "page_idx": 7}, {"type": "text", "text": "4.2 Theoretical insights ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Objective. We investigate the implications of our theoretical findings (Eq. (7)) on the acquisition process; determining whether a weak correlation between unobserved features and the target, results in a small gap between PO-EIG and BALD. We also explore how correlation affects performance. ", "page_idx": 8}, {"type": "text", "text": "Setup: We create an intuitive synthetic 2D experimental setup (Figure 4) with a variable target. The target is determined linearly with varying slopes, leading to different correlations with the features. Our chosen features\u2014 $X_{1}$ , $X_{2}$ , and $X_{3}$ \u2014represent data along the ${\\bf X}$ -axis, y-axis, and a Gaussian category, respectively. Introducing the Gaussian category injects stochasticity into the marginalization process, ensuring non-trivial solutions. The observed feature is $X_{1}$ , with possible acquisition of $X_{2}$ , $X_{3}$ . We examine three scenarios: 1) Low $\\operatorname{Corr}(X_{2},Y)$ , where the class depends solely on $X_{1}$ due to vertical slope; 2) High $\\operatorname{Corr}(X_{2},Y)$ , where the class depends solely on $X_{2}$ , rendering $X_{1}$ irrelevant; and 3) Mid. $\\operatorname{Corr}(X_{2},Y)$ , where $X_{1}$ has some impact. Note, we evaluate acquisition metrics and performance until the convergence of the oracle (BALD with all features) ", "page_idx": 8}, {"type": "text", "text": "Analysis. Figure 5A empirically validates that PO-EIG is always equal to or greater than BALD, consistent with our theoretical insights (Eq. (7)). Figure 5B illustrates the evolution of the metric gap between PO-EIG and BALD under varying correlations between $X_{2,3}$ and $Y$ . In low correlation scenarios (orange line), the gap diminishes towards the acquisition\u2019s end, aligning with Corollary 1 where both metrics should converge when $\\mathcal{G}\\perp\\mathbf{X}_{2,3}|x_{1},$ , i.e., when the unobserved features don\u2019t impact generalization. Initially, the gap exists as the model learns from data the redundancy of unobserved features. The same figure shows larger correlation leads to a wider gap, observed most notably in the large correlation scenario (purple) and moderately in the medium correlation scenario (teal). Figure 5 shows that, generally, the degree of problem correlation provides a proxy correlation with acquisition performance. For example, the purple line exhibits the largest difference between BALD and EIG. Particularly in low correlation scenarios, the performance difference between PO-EIG and BALD is negligible across the acquisition (orange line). ", "page_idx": 8}, {"type": "image", "img_path": "bescO94wog/tmp/d2a4ee5177f8ab033fe3df81efc824867b2e158f1deabdc1bd68dbef2b89704d.jpg", "img_caption": ["Figure 5: Comparing PO-EIG and BALD. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.3 Cost-aware active learning ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Objective: We evaluate the performance of $\\mu\\mathrm{POCA}$ (specifically PO-EIG) under budget-constrained feature acquisition, aiming to determine if acquiring only a subset of features, denoted as $^j$ , offers an advantageous trade-off in performance. This selective acquisition approach enables acquiring a larger number of instances within the same budget. Furthermore, we aim to show that imputation alone cannot fully replace the need for direct data acquisition. ", "page_idx": 8}, {"type": "text", "text": "Setup. We use the Magic dataset as a case study to examine the impact of cost constraints on predictive performance and the feature acquisition process. To facilitate this assessment, we introduce costs associated with both features and labels. For simplicity and visualization clarity, we assume the cost of an instance to be 1, representing the sum of the costs for all features and the label, with each feature assigned an equal cost. This setup allows us to analyze four distinct approaches: (1) the Vanilla acquisition metric (EIG), (2) PO-EIG, (3) PO-EIG with a maximum feature acquisition limit of $60\\%$ , and (4) PO-EIG with unrestricted feature acquisition. We evaluate the performance of these approaches in three ways: by accuracy based on acquired instances (Figure 6, left), by performance relative to the budget utilized (assuming no label costs) (Figure 6, middle), and by performance with varying label costs under a fixed total budget of 50 (Figure 6, right). ", "page_idx": 8}, {"type": "text", "text": "Analysis. Figure 6 (left) illustrates that acquiring fewer features generally results in decreased performance; however, it still outperforms the EIG baseline. While limited feature acquisition impacts performance, it allows for a more efficient budget allocation across instances, enabling the acquisition of a larger instance pool. This trend is visible in Figure 6 (middle), where performance is plotted against the total budget spent, assuming no label cost. Here, methods focusing on selective feature acquisition excel, as they gather more overall information through increased instance count and key features. ", "page_idx": 8}, {"type": "image", "img_path": "bescO94wog/tmp/5deb80dee19b9b7f9045758e7a34eb7fc8fba5302f35f41a71e6d323b97bed27.jpg", "img_caption": ["Figure 6: Left: Accuracy vs. number of instances acquired. Middle: Accuracy vs. budget without considering label costs. Right: Accuracy vs. budget with varying label costs. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Figure 6 (right) demonstrates that the optimal PO-EIG method depends on feature acquisition cost: when cost is heavily weighted toward feature acquisition (right histogram), the best method is POEIG with $20\\%$ of features acquired, whereas a $50\\%$ label cost favors PO-EIG with $60\\%$ feature acquisition. While these findings might suggest that acquiring fewer features and imputing the rest is optimal for maximizing instances, this approach may introduce noise into the training set, potentially biasing the model. To explore this, we analyze model performance at different levels of feature acquisition in Figure 7, with varying levels of pool data, using the full pool set for training (excluding non-acquired features). As shown on the y-axis, acquiring more features enhances performance. When the budget is unlimited, acquiring all available data is preferable; however, in practice, this may not be feasible, making POCA approaches advantageous. ", "page_idx": 9}, {"type": "image", "img_path": "bescO94wog/tmp/0e96408ee87708c2f4241db03e958d6b44e227e677b3083a830dec6da1c5e9fa.jpg", "img_caption": ["Figure 7: Acquiring vs imputing. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "$\\heartsuit$ First, $\\mu\\mathrm{POCA}$ metrics (PO-EIG) can be more cost-effective than common active learning metrics. Second, imputation is useful for missing data but shouldn\u2019t replace data acquisition. ", "page_idx": 9}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We introduce and formalize POCA a data acquisition framework, addressing the vital but underexplored challenge of partially observed settings. Through $\\mu\\mathrm{POCA}$ , a practical implementation of this framework, we demonstrate the feasibility of acquiring unobserved features and labels based on those partially observed features, using more generalized AL utility metrics \u2014 computed by estimating features generated using an LLM-based GSM. Our results over various scenarios are substantially more effective than alternatives \u2014 of substantial value for data acquisition in cost-restrictive environments. We hope the POCA framework and our subsequent findings will spur additional work to advance data acquisition in partially observed settings. ", "page_idx": 9}, {"type": "text", "text": "Limitations. Our work focuses on the values of features, providing a general framework where restrictions are the main source of constraints in terms of acquisition. However, we do not assess how these restrictions are selected, which could be a promising area for future research. We also note that we use LLMs in the context of data acquisition. Like any GSM, LLMs can indeed exhibit biases that affect the acquisition process. In this study, we did not consider this issue, and it represents an interesting avenue for future work. If necessary, current debiasing techniques can be applied. ", "page_idx": 9}, {"type": "text", "text": "Practical consideration and future work. (1) In the PO setting with data \u201cmissingness,\u201d GSM imputation is essential for acquisition. Future work could quantify uncertainty [43, 55] to assess GSM efficacy. (2) LLM capability also impacts acquisition; while we use a 7B-parameter model, larger models could further enhance performance, though this is beyond our current scope. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We thank the anonymous NeurIPS reviewers, members of the van der Schaar lab, and Andrew Rashbass for insightful comments and suggestions. NA thanks W.D. Armstrong Trust for sponsorship and support. TL thanks AstraZeneca for support. NS thanks the Cystic Fibrosis Trust. This work was supported by Microsoft\u2019s Accelerate Foundation Models Academic Research initiative. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Leslie Pack Kaelbling Kenji Kawaguchi and Yoshua Bengio. Generalization in deep learning. In Mathematics of Deep Learning, Cambridge University Press, to appear. Prepint avaliable as: MIT-CSAIL-TR-2018-014, Massachusetts Institute of Technology, 2018.   \n[2] Shuo Yang, Zeke Xie, Hanyu Peng, Min Xu, Mingming Sun, and Ping Li. Dataset pruning: Reducing training data by examining generalization influence. arXiv preprint arXiv:2205.09329, 2022.   \n[3] Nabeel Seedat, Fergus Imrie, and Mihaela van der Schaar. Navigating data-centric artificial intelligence with DC-Check: Advances, challenges, and opportunities. IEEE Transactions on Artificial Intelligence, 2023.   \n[4] Yuji Roh, Geon Heo, and Steven Euijong Whang. A survey on data collection for machine learning: a big data-ai integration perspective. IEEE Transactions on Knowledge and Data Engineering, 33(4):1328\u20131347, 2019.   \n[5] Steven Euijong Whang, Yuji Roh, Hwanjun Song, and Jae-Gil Lee. Data collection and quality challenges in deep learning: A data-centric ai perspective. The VLDB Journal, 32(4):791\u2013813, 2023.   \n[6] Lea Goetz, Nabeel Seedat, Robert Vandersluis, and Mihaela van der Schaar. Generalization\u2014a key challenge for responsible ai in patient-facing clinical applications. npj Digital Medicine, 7(1):126, 2024.   \n[7] Neil Houlsby, Ferenc Husz\u00e1r, Zoubin Ghahramani, and M\u00e1t\u00e9 Lengyel. Bayesian active learning for classification and preference learning. arXiv preprint arXiv:1112.5745, 2011.   \n[8] Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep Bayesian active learning with image data. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pages 1183\u20131192. PMLR, 06\u201311 Aug 2017.   \n[9] Yanyao Shen, Hyokun Yun, Zachary C Lipton, Yakov Kronrod, and Animashree Anandkumar. Deep active learning for named entity recognition. arXiv preprint arXiv:1707.05928, 2017.   \n[10] Dana Angluin. Queries and concept learning. Machine learning, 2:319\u2013342, 1988.   \n[11] Hajin Shim, Sung Ju Hwang, and Eunho Yang. Joint active feature acquisition and classification with variable-size set encoding. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.   \n[12] Yang Li and Junier Oliva. Active feature acquisition with generative surrogate models. In International Conference on Machine Learning, pages 6450\u20136459. PMLR, 2021.   \n[13] Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Sebastian Nowozin, and Cheng Zhang. Eddi: Efficient dynamic discovery of high-value information with partial vae. arXiv preprint arXiv:1809.11142, 2018.   \n[14] Siddharth Karamcheti, Ranjay Krishna, Li Fei-Fei, and Christopher D Manning. Mind your outliers! investigating the negative impact of outliers on active learning for visual question answering. arXiv preprint arXiv:2107.02331, 2021.   \n[15] Robin Jaulmes, Joelle Pineau, and Doina Precup. Active learning in partially observable markov decision processes. In Jo\u00e3o Gama, Rui Camacho, Pavel B. Brazdil, Al\u00edpio M\u00e1rio Jorge, and Lu\u00eds Torgo, editors, Machine Learning: ECML 2005, pages 601\u2013608, Berlin, Heidelberg, 2005. Springer Berlin Heidelberg.   \n[16] Massih R. Amini, Nicolas Usunier, and Cyril Goutte. Learning from multiple partially observed views - an application to multilingual text categorization. In Y. Bengio, D. Schuurmans, J. Lafferty, C. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems, volume 22. Curran Associates, Inc., 2009.   \n[17] Merlijn Krale. Active Measuring in Uncertain Environments. PhD thesis, 2023.   \n[18] Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: a review. Statistical Science, 1995.   \n[19] Tom Rainforth, Adam Foster, Desi R Ivanova, and Freddie Bickford Smith. Modern bayesian experimental design. arXiv preprint arXiv:2302.14545, 2023.   \n[20] Adam Foster, Desi R Ivanova, Ilyas Malik, and Tom Rainforth. Deep adaptive design: Amortizing sequential bayesian experimental design. In International Conference on Machine Learning, pages 3384\u20133395. PMLR, 2021.   \n[21] Anthony Atkinson, Alexander Donev, and Ray Tobias. Optimum Experimental Designs, with SAS. Oxford University Press, 2007.   \n[22] P. Sebastiani and H. P. Wynn. Maximum entropy sampling and optimal Bayesian experimental design. Journal of the Royal Statistical Society Series B, 62(1):145\u2013157, 2000.   \n[23] David JC MacKay. Information-based objective functions for active data selection. Neural computation, 4(4):590\u2013604, 1992.   \n[24] Tennison Liu, Nicol\u00e1s Astorga, Nabeel Seedat, and Mihaela van der Schaar. Large language models to enhance bayesian optimization. In The Twelfth International Conference on Learning Representations, 2024.   \n[25] Philipp Hennig and Christian J Schuler. Entropy search for information-efficient global optimization. Journal of Machine Learning Research, 13(6), 2012.   \n[26] Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Matthew W Hoffman, and Zoubin Ghahramani. Predictive entropy search for efficient global optimization of black-box functions. Advances in neural information processing systems, 27, 2014.   \n[27] Dennis V Lindley. On a measure of the information provided by an experiment. Annals of Mathematical Statistics, 1956.   \n[28] Freddie Bickford Smith, Andreas Kirsch, Sebastian Farquhar, Yarin Gal, Adam Foster, and Tom Rainforth. Prediction-oriented Bayesian active learning. International Conference on Artificial Intelligence and Statistics, 2023.   \n[29] Anthony Atkinson, Alexander Donev, and Randall Tobias. Optimum Experimental Designs, with SAS. 05 2007.   \n[30] R. A. Fisher. Design of experiments. British Medical Journal, 1(3923):554, Mar 1936. Letter.   \n[31] Thomas P. Ryan and J. P. Morgan. Modern experimental design. Journal of Statistical Theory and Practice, 1(3-4):501\u2013506, 2007.   \n[32] Meng Fang, Yuan Li, and Trevor Cohn. Learning how to active learn: A deep reinforcement learning approach. arXiv preprint arXiv:1708.02383, 2017.   \n[33] Arkady Epshteyn, Adam Vogel, and Gerald DeJong. Active reinforcement learning. In Proceedings of the 25th international conference on Machine learning, pages 296\u2013303, 2008.   \n[34] Andreas Kirsch, Joost van Amersfoort, and Yarin Gal. Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning, 2019.   \n[35] Andreas Kirsch, Sebastian Farquhar, Parmida Atighehchian, Andrew Jesson, Frederic Branchaud-Charron, and Yarin Gal. Stochastic batch acquisition for deep active learning. arXiv preprint arXiv:2106.12059, 2021.   \n[36] Andreas Kirsch and Yarin Gal. Unifying approaches in active learning and active sampling via fisher information and information-theoretic quantities. Transactions on Machine Learning Research, 2022. Expert Certification.   \n[37] Andreas Kirsch and Yarin Gal. A practical & unified notation for information-theoretic quantities in ml. arXiv preprint arXiv:2106.12062, 2021.   \n[38] A mathematical theory of communication. The Bell system technical journal, 27(3):379\u2013423, 1948.   \n[39] Jose M. Bernardo. Expected Information as Expected Utility. The Annals of Statistics, 7(3):686 \u2013 690, 1979.   \n[40] Lewis Smith and Yarin Gal. Understanding measures of uncertainty for adversarial example detection. arXiv preprint arXiv:1803.08533, 2018.   \n[41] Vu-Linh Nguyen, Mohammad Hossein Shaker, and Eyke H\u00fcllermeier. How to measure uncertainty in uncertainty sampling for active learning. Machine Learning, 111(1):89\u2013122, 2022.   \n[42] Mrinank Sharma, Sebastian Farquhar, Eric Nalisnick, and Tom Rainforth. Do bayesian neural networks need to be fully stochastic? In Francisco Ruiz, Jennifer Dy, and Jan-Willem van de Meent, editors, Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, volume 206 of Proceedings of Machine Learning Research, pages 7694\u20137722. PMLR, 25\u201327 Apr 2023.   \n[43] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pages 1050\u20131059. PMLR, 2016.   \n[44] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in neural information processing systems, 30, 2017.   \n[45] Thomas G. Dietterich. Ensemble methods in machine learning. In International Workshop on Multiple Classifier Systems, 2000.   \n[46] Carl Edward Rasmussen et al. Gaussian processes for machine learning, volume 1. Springer.   \n[47] Andreas Kirsch, Tom Rainforth, and Yarin Gal. Test distribution-aware active learning: A principled approach against distribution shift and outliers, 2021.   \n[48] Tom Rainforth, Rob Cornish, Hongseok Yang, Andrew Warrington, and Frank Wood. On nesting Monte Carlo estimators. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 4267\u20134276. PMLR, 10\u201315 Jul 2018.   \n[49] Vadim Borisov, Kathrin Sessler, Tobias Leemann, Martin Pawelczyk, and Gjergji Kasneci. Language models are realistic tabular data generators. In The Eleventh International Conference on Learning Representations, 2022.   \n[50] Aivin V Solatorio and Olivier Dupriez. Realtabformer: Generating realistic relational and tabular data using transformers. arXiv preprint arXiv:2302.02041, 2023.   \n[51] Nabeel Seedat, Nicolas Huynh, Boris van Breugel, and Mihaela van der Schaar. Curated llm: Synergy of llms and data curation for tabular augmentation in low-data regimes. In Forty-first International Conference on Machine Learning, 2024.   \n[52] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.   \n[53] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge. Nature, pages 1\u20139, 2023.   \n[54] Stefan Hegselmann, Alejandro Buendia, Hunter Lang, Monica Agrawal, Xiaoyi Jiang, and David Sontag. Tabllm: Few-shot classification of tabular data with large language models. In International Conference on Artificial Intelligence and Statistics, pages 5549\u20135581. PMLR, 2023.   \n[55] Boris van Breugel, Zhaozhi Qian, and Mihaela van der Schaar. Synthetic data, real errors: how (not) to publish and use synthetic data. arXiv preprint arXiv:2305.09235, 2023.   \n[56] Bing Zhu, Yin Pan, and Zihan Gao. Application of active learning for churn prediction with class imbalance. ICMLT \u201918, page 89\u201393, New York, NY, USA, 2018. Association for Computing Machinery.   \n[57] M. A. R. Khalid, M. A. H. Farquad, and V. Kamakshi Prasad. Data classification using active learning based data modification: An application to churn prediction. In 2017 International Conference on Current Trends in Computer, Electrical, Electronics and Communication (CTCEEC), pages 529\u2013533, 2017.   \n[58] Youngjung Suh. Machine learning based customer churn prediction in home appliance rental business. Journal of Big Data, 10(1):41, 2023.   \n[59] Elizabeth Barnes, Richard Meyer, Bob McClelland, Hildegard Wieseholfer, and Mike Worsam. Marketing: An Active Learning Approach. Wiley\u2013Blackwell, paperback edition, April 1997.   \n[60] Toshiki Ueda and Hiroshi Ban. Active learning on digital marketing for advertising a university museum exhibition. Procedia Computer Science, 126:2097\u20132106, 2018. Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia.   \n[61] V. Anand and Varsha Mamidi. Multiple imputation of missing data in marketing. In 2020 International Conference on Data Analytics for Business and Industry: Way Towards a Sustainable Economy (ICDABI), pages 1\u20136, 2020.   \n[62] Mariusz Grabowski. Handling missing values in marketing research using som. In Daniel Baier and Klaus-Dieter Wernecke, editors, Innovations in Classification, Data Science, and Information Systems, pages 322\u2013329, Berlin, Heidelberg, 2005. Springer Berlin Heidelberg.   \n[63] J. Wu and X. Zhang. Credit risk assessment: An active learning approach. 01 2010.   \n[64] Yue Zhao, Yong C. Cao, Xiu Q. Pan, Yong Lu, and Xiao N. Xu. A telecom clients\u2019 credit risk rating model based on active learning. In 2008 IEEE International Conference on Automation and Logistics, pages 2590\u20132593, 2008.   \n[65] Jill Hussey. Understanding Business and Finance: An Active Learning Approach. Letts Educational, 6 1991. Paperback edition.   \n[66] Ronghao Tong. An active learning application on loan default prediction: based on forest classifier model. In Xiaoli Li, editor, Third International Conference on Artificial Intelligence and Computer Engineering (ICAICE 2022), volume 12610 of Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series, page 126104W, April 2023.   \n[67] Feng Zhao, Yan Lu, Xinning Li, Lina Wang, Yingjie Song, Deming Fan, Caiming Zhang, and Xiaobo Chen. Multiple imputation method of missing credit risk assessment data based on generative adversarial networks. Applied Soft Computing, 126:109273, 2022.   \n[68] Jomark Noriega, Luis Rivera, and Jose Herrera. Machine learning for credit risk prediction: A systematic literature review, 08 2023.   \n[69] R. Florez-Lopez. Effects of missing data in credit risk scoring. a comparative analysis of methods to achieve robustness in the absence of sufficient data. The Journal of the Operational Research Society, 61(3):486\u2013501, 2010.   \n[70] I. M. El-Hasnony, O. M. Elzeki, A. Alshehri, and H. Salem. Multi-label active learning-based machine learning model for heart disease prediction. Sensors, 22(3):1184, 2022.   \n[71] Zoe Fowler, Kiran Premdat Kokilepersaud, Mohit Prabhushankar, and Ghassan Alregib. Clinical trial active learning. In Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics, BCB \u201923, New York, NY, USA, 2023. Association for Computing Machinery.   \n[72] JJ Teijema, L Hofstee, M Brouwer, J de Bruin, G Ferdinands, J de Boer, P Vizan, S van den Brand, C Bockting, R van de Schoot, and A Bagheri. Active learning-based systematic reviewing using switching classification models: the case of the onset, maintenance, and relapse of depressive disorders. Frontiers in Research Metrics and Analytics, 8:1178181, 2023.   \n[73] Angona Biswas, Md Abdullah Nasim, Md Ali, Ismail Hossain, Md Azim Ullah, and Sajedul Talukder. Active learning on medical image, 06 2023.   \n[74] Samuel Budd, Emma C. Robinson, and Bernhard Kainz. A survey on active learning and human-in-the-loop deep learning for medical image analysis. Medical Image Analysis, 71:102062, 2021.   \n[75] Xing Wu, Cheng Chen, Mingyu Zhong, Jianjia Wang, and Jun Shi. Covid-al: The diagnosis of covid-19 with deep active learning. Medical Image Analysis, 68:101913, 2021.   \n[76] A. Fong, J.L. Howe, K.T. Adams, and R.M. Ratwani. Using active learning to identify health information technology related patient safety events. Applied Clinical Informatics, 8(1):35\u201346, 2017.   \n[77] S. Nijman, A.M. Leeuwenberg, I. Beekers, I. Verkouter, J. Jacobs, M.L. Bots, F.W. Asselbergs, K. Moons, and T. Debray. Missing data is poorly handled and reported in prediction model studies using machine learning: a literature review. Journal of Clinical Epidemiology, 142:218\u2013 229, February 2022. Epub 2021 Nov 16.   \n[78] Yuan Luo. Evaluating the state of the art in missing data imputation for clinical data. Briefings in Bioinformatics, 23(1):bbab489, 12 2021.   \n[79] Sebastien Haneuse, David Arterburn, and Michael J. Daniels. Assessing Missing Data Assumptions in EHR-Based Studies: A Complex and Underappreciated Task. JAMA Network Open, 4(2):e210184\u2013e210184, 02 2021.   \n[80] Rolf H. H. Groenwold. Informative missingness in electronic health record systems: the curse of knowing. Diagnostic and Prognostic Research, 4(1):8, 2020.   \n[81] Catarina Pinto, Juliana Faria, and Luis Macedo. An active learning-based medical diagnosis system. In Goreti Marreiros, Bruno Martins, Ana Paiva, Bernardete Ribeiro, and Alberto Sardinha, editors, Progress in Artificial Intelligence, pages 207\u2013218, Cham, 2022. Springer International Publishing.   \n[82] A Kulkarni, J Terpenny, and V Prabhu. Leveraging active learning for failure mode acquisition. Sensors, 23(5):2818, 2023.   \n[83] Jonathan Sadeghi, Romain Mueller, and John Redford. An active learning reliability method for systems with partially defined performance functions. 12 2022.   \n[84] Cao Tong, Jian Wang, Jinguo Liu, and A. M. Bastos Pereira. A kriging-based active learning algorithm for mechanical reliability analysis with time-consuming and nonlinear response. Mathematical Problems in Engineering, 2019:7672623, 2019.   \n[85] Jo\u017ee M. Ro\u017eanec, Elena Trajkova, Paulien Dam, Bla\u017e Fortuna, and Dunja Mladenic\u00b4. Streaming machine learning and online active learning for automated visual inspection.\\*\\*this work was supported by the slovenian research agency and the european union\u2019s horizon 2020 program project star under grant agreement number h2020-956573. IFAC-PapersOnLine, 55(2):277\u2013 282, 2022. 14th IFAC Workshop on Intelligent Manufacturing Systems IMS 2022.   \n[86] Rong Zhu, Yuan Chen, Weiwen Peng, and Zhi-Sheng Ye. Bayesian deep-learning for rul prediction: An active learning perspective. Reliability Engineering & System Safety, 228:108758, 2022.   \n[87] Long Wang, Chen Wenbai, Liu Chang, Chen Weizhao, Liu Huixiang, Chen Qili, and Wu Peiliang. A prediction method for the rul of equipment for missing data. Complexity, 2021:2122655, 2021.   \n[88] Kai Zhang and Ruonan Liu. Lstm-based multi-task method for remaining useful life prediction under corrupted sensor data. Machines, 11(3), 2023.   \n[89] Shengfei Zhang, Tianmei Li, Xiaosheng Si, Changhua Hu, Hao Zhang, and Yuzhe Ma. A new missing data generation method based on an improved dcgan with application to rul prediction. In 2021 CAA Symposium on Fault Detection, Supervision, and Safety for Technical Processes (SAFEPROCESS), pages 1\u20136, 2021.   \n[90] Mehdi Elahi, Francesco Ricci, and Neil Rubens. Active learning in collaborative filtering recommender systems. In Martin Hepp and Yigal Hoffner, editors, E-Commerce and Web Technologies, pages 113\u2013124, Cham, 2014. Springer International Publishing.   \n[91] Mehdi Elahi, Francesco Ricci, and Neil Rubens. A survey of active learning in collaborative filtering recommender systems. Computer Science Review, 20:29\u201350, 2016.   \n[92] Neil Rubens, Mehdi Elahi, Masashi Sugiyama, and Dain Kaplan. Active Learning in Recommender Systems, pages 809\u2013846. 02 2016.   \n[93] Xiangyu Zhao, Zhendong Niu, Kaiyi Wang, Ke Niu, Zhongqiang Liu, and Jean-Charles Beugnot. Improving top-n recommendation performance using missing data. Mathematical Problems in Engineering, 2015:380472, 2015.   \n[94] Benjamin Marlin, Richard Zemel, Sam Roweis, and Malcolm Slaney. Recommender systems, missing data and statistical model estimation. pages 2686\u20132691, 01 2011.   \n[95] H Chen and J Wang. Active learning for efficient soil monitoring in large terrain with heterogeneous sensor network. Sensors, 23(5):2365, 2023.   \n[96] Yifan Zhang and Peter J. Thorburn. Handling missing data in near real-time environmental monitoring: A system and a review of selected methods. Future Generation Computer Systems, 128:63\u201372, 2022.   \n[97] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3):107\u2013115, 2021.   \n[98] John R Zech, Marcus A Badgeley, Manway Liu, Anthony B Costa, Joseph J Titano, and Eric Karl Oermann. Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study. PLoS medicine, 15(11):e1002683, 2018.   \n[99] R. Bock. MAGIC Gamma Telescope. UCI Machine Learning Repository, 2007. DOI: https://doi.org/10.24432/C52C8B.   \n[100] Barry Becker and Ronny Kohavi. Adult. UCI Machine Learning Repository, 1996. DOI: https://doi.org/10.24432/C5XW20.   \n[101] Cardiovascular-disease dataset. Kaggle: https://www.kaggle.com/datasets/colewelkins/cardiovascul disease, September 2023.   \n[102] Rita P. Moro, S. and P. Cortez. Bank Marketing. UCI Machine Learning Repository, 2012. DOI: https://doi.org/10.24432/C5K306.   \n[103] Jinsung Yoon, James Jordon, and Mihaela Schaar. Gain: Missing data imputation using generative adversarial nets. In International conference on machine learning, pages 5689\u2013 5698. PMLR, 2018.   \n[104] Steven Cheng-Xian Li, Bo Jiang, and Benjamin Marlin. Misgan: Learning from incomplete data with generative adversarial networks. arXiv preprint arXiv:1902.09599, 2019.   \n[105] Seongwook Yoon and Sanghoon Sull. Gamin: Generative adversarial multiple imputation network for highly missing data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8456\u20138464, 2020.   \n[106] Alfredo Nazabal, Pablo M Olmos, Zoubin Ghahramani, and Isabel Valera. Handling incomplete heterogeneous data using vaes. Pattern Recognition, 107:107501, 2020.   \n[107] Oleg Ivanov, Michael Figurnov, and Dmitry Vetrov. Variational autoencoder with arbitrary conditioning. arXiv preprint arXiv:1806.02382, 2018.   \n[108] Trevor W Richardson, Wencheng Wu, Lei Lin, Beilei Xu, and Edgar A Bernal. Mcflow: Monte carlo flow models for data imputation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14205\u201314214, 2020.   \n[109] Pierre-Alexandre Mattei and Jes Frellsen. Miwae: Deep generative modelling and imputation of incomplete data sets. In International Conference on Machine Learning, pages 4413\u20134423. PMLR, 2019.   \n[110] S. J\u00e4ger, A. Allhorn, and F. Bie\u00dfmann. A benchmark for data imputation methods. Frontiers in Big Data, 4:693674, 2021.   \n[111] Daniel J Stekhoven and Peter B\u00fchlmann. Missforest\u2014non-parametric missing value imputation for mixed-type data. Bioinformatics, 28(1):112\u2013118, 2012.   \n[112] Esther-Lydia Silva-Ram\u00edrez, Rafael Pino-Mej\u00edas, Manuel L\u00f3pez-Coello, and Mar\u00eda-Dolores Cubiles-de-la Vega. Missing value imputation on missing completely at random data using multilayer perceptrons. Neural Networks, 24(1):121\u2013129, 2011.   \n[113] Euredit. Interim report on evaluation criteria for statistical editing and imputation, 2005.   \n[114] Jaap Brand. Development, implementation and evaluation of multiple imputation strategies for the statistical analysis of incomplete data sets. PhD thesis, 1999.   \n[115] David Heckerman, David Maxwell Chickering, Christopher Meek, Robert Rounthwaite, and Carl Kadie. Dependency networks for inference, collaborative flitering, and data visualization. Journal of Machine Learning Research, 1(Oct):49\u201375, 2000.   \n[116] Trivellore E Raghunathan, James M Lepkowski, John Van Hoewyk, Peter Solenberger, et al. A multivariate technique for multiply imputing missing values using a sequence of regression models. Survey Methodology, 27(1):85\u201396, 2001.   \n[117] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers. arXiv preprint arXiv:2309.03409, 2023.   \n[118] Tom B Brown. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020.   \n[119] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824\u201324837, 2022.   \n[120] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In International conference on machine learning, pages 9118\u20139147. PMLR, 2022.   \n[121] Zirui Zhao, Wee Sun Lee, and David Hsu. Large language models as commonsense knowledge for large-scale task planning. Advances in Neural Information Processing Systems, 36, 2024.   \n[122] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu. Reasoning with language model is planning with world model. In The 2023 Conference on Empirical Methods in Natural Language Processing, 2023.   \n[123] Max Ruiz Luyten and Mihaela van der Schaar. A theoretical design of concept sets: improving the predictability of concept bottleneck models. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024.   \n[124] Aditya Taparia, Som Sagar, and Ransalu Senanayake. Explainable concept generation through vision-language preference learning. arXiv preprint arXiv:2408.13438, 2024.   \n[125] Boyi Li, Yue Wang, Jiageng Mao, Boris Ivanovic, Sushant Veer, Karen Leung, and Marco Pavone. Driving everywhere with large language model policy adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14948\u201314957, 2024.   \n[126] Tsung-Han Wu, Long Lian, Joseph E Gonzalez, Boyi Li, and Trevor Darrell. Self-correcting llm-controlled diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6327\u20136336, 2024.   \n[127] Paulius Rauba, Nabeel Seedat, Krzysztof Kacprzyk, and Mihaela van der Schaar. Self-healing machine learning: A framework for autonomous adaptation in real-world environments. In The Thirty-Eighth Annual Conference on Neural Information Processing Systems, 2024.   \n[128] Samuel Holt, Tennison Liu, and Mihaela van der Schaar. Automatically learning hybrid digital twins of dynamical systems. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024.   \n[129] Hanqing Yang, Marie Siew, and Carlee Joe-Wong. An llm-based digital twin for optimizing human-in-the loop systems. arXiv preprint arXiv:2403.16809, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Appendix: POCA: Partially Observable Cost-Aware Active-Learning with Large Language Models. ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "A Appendix A: Real-World Use Cases ", "page_idx": 18}, {"type": "text", "text": "Table 2: Real-world use-cases of POCA. We outline real-world scenarios where the POCA framework can have an impact. For each problem domain, we describe partially observable features, labels, and the underlying predictive task. We categorize references into three types: A) where active learning is employed, B) where predictive modelling is performed in the presence of partially observed features, and C) active learning is applied to partially observed settings (with data pre-processing to handle missing features). The symbol $\\blacktriangleright$ stands for acquisition costs. ", "page_idx": 18}, {"type": "table", "img_path": "bescO94wog/tmp/d4b24548a58f52f39a4a7900406e620b09f7eab0f58e3b6f6043a8681c7c77b5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Table 2 illustrates that active learning is extensively utilized in a variety of real-world application scenarios. Furthermore, it is not uncommon in these contexts to encounter situations with incomplete data, which can harm generalization [2, 6, 97, 98] capabilities of downstream models. The breadth of related work covers diverse sectors including customer churn prediction, marketing research, healthcare diagnostics, and predictive maintenance. While active learning is adept at selectively querying labels in scenarios where data is fully observed, its application in the context of missing data is less clear. The challenge is compounded by the fact that, in similar problem settings, it is not always guaranteed that features will be fully observed. This reality underscores the need for alternative machine learning techniques to address such challenges. Our proposed approach, POCA, offers a novel solution for applying active learning in scenarios with partially observed data, taking into account realistic cost constraints. ", "page_idx": 18}, {"type": "text", "text": "B Appendix B: Acquisition metrics for partially observed scenarios. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proposition 1. Let $\\mu({\\pmb x}_{o})$ be an acquisition metric that can be written as $\\operatorname{I}({\\mathcal{G}},Y|\\circ)$ , with $\\mathcal{G}$ and \u2022 representing the same variables observed in traditional AL (Table 1), and with $Y$ , $X_{j}$ as previously defined. If $\\mathcal{G}\\perp\\!\\!\\!\\perp X_{j}|$ , the following equality holds: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname{I}({\\mathcal{G}},(Y,X_{j})|\\,\\circ\\,)=\\mathbb{E}_{{\\pmb{x}}_{j}}\\operatorname{I}({\\mathcal{G}},Y|{\\pmb{x}}_{j},\\,\\circ\\,)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof: We can decompose the left part of Eq. (9) as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname{I}({\\mathcal{G}},(Y,X_{j})|\\,\\,)=\\operatorname{I}({\\mathcal{G}},X_{j}|\\,\\circ)+\\operatorname{I}({\\mathcal{G}},Y|X_{j},\\,\\circ)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Using $\\mathcal{G}\\perp X_{j}|\\;\\longrightarrow\\;\\mathrm{I}(\\mathcal{G},X_{j}|\\;)=0,$ , the first term on the right of Eq. (10) cancels, obtaining $\\operatorname{I}({\\mathcal{G}},(Y,X_{j})|\\;)=\\operatorname{I}({\\mathcal{G}},Y|X_{j},\\;)=\\mathbb{E}_{{\\boldsymbol x}_{j}}\\operatorname{I}({\\mathcal{G}},Y|{\\boldsymbol x}_{j},\\;)$ concluding the proof. ", "page_idx": 19}, {"type": "text", "text": "Corollary 1. Under the assumptions of Proposition $^{\\,l}$ , the subsequent equivalent inequality is established: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{\\boldsymbol{x}}_{j}}\\mathrm{I}(\\mathcal{G},Y|\\mathbf{\\boldsymbol{x}}_{j},\\mathbb{\\boldsymbol{\\circ}})\\geq\\mathrm{I}(\\mathcal{G},Y|\\mathbb{\\boldsymbol{\\circ}})\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Equality is attained when $\\mathcal{G}\\perp\\!\\!\\!\\!\\perp X_{j}|Y,$ . ", "page_idx": 19}, {"type": "text", "text": "Proof: Symmetrically as before we can decompose the left part of Eq. (9) as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname{I}({\\mathcal{G}},(Y,X_{j})|\\circ)=\\operatorname{I}({\\mathcal{G}},Y|\\circ)+\\operatorname{I}({\\mathcal{G}},X_{j}|Y,\\circ)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Using proposition (1), we obtain: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\pmb{x}_{j}}\\mathrm{I}(\\mathcal{G},Y|\\pmb{x}_{j},\\circ)=\\mathrm{I}(\\mathcal{G},Y|\\circ)+\\mathrm{I}(\\mathcal{G},X_{j}|Y,\\circ)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Clearly the equality is obtained when $\\mathcal{G}\\perp\\!\\!\\!\\!\\perp X_{j}|Y,$ since the mutual information is zero. When taking $\\operatorname{I}({\\mathcal{G}},X_{j}|Y,\\cdot)\\geq0$ we obtain: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{{\\pmb{x}}_{j}}\\mathrm{I}({\\mathcal{G}},Y|{\\pmb{x}}_{j},\\circ)\\geq\\mathrm{I}({\\mathcal{G}},Y|\\circ),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "concluding the proof. ", "page_idx": 19}, {"type": "text", "text": "Observation: Note that, the independence assumption $\\mathcal{G}\\perp\\!\\!\\!\\perp X_{j}|$ always hold for the class of supervised learning models we consider. $\\mathcal{G}$ is a random variable representing the generalization capabilities of the model $\\omega\\in\\mathcal W$ , with random variable $\\Omega$ . This random variable is subject to model training $\\boldsymbol{\\mathcal{A}}$ , which can be written as the mapping between the training set $\\mathcal{D}$ and hyperparameters $h\\in\\mathcal H$ to the output $\\omega$ , i.e., $A:D\\times\\mathcal{H}\\to\\mathcal{W}$ . Additionally, the model prediction is a mapping $\\mathcal{P}$ between the model $\\omega$ and the input $x\\in X$ to the output $Y$ , i.e., $\\mathcal{P}:\\mathcal{W}\\times\\mathcal{X}\\to\\mathcal{Y}$ . ", "page_idx": 19}, {"type": "text", "text": "It is crucial to acknowledge that the \u201cworld generator\u201d influences $\\mathcal{D}$ , $X$ , and $Y$ , but does not directly affect $\\Omega$ . Given that $\\mathcal{D}$ is observable, any connection through this path is cut. The sole connection of $\\Omega$ to $X$ and $Y$ is through the mapping $\\mathcal{P}$ , which establishes a causal structure: $\\Omega\\rightarrow Y\\leftarrow X$ According to this structure, $\\Omega$ and $X$ are generally independent unless $Y$ is observed, leading to a dependence due to $\\mathcal{P}$ creating a configuration known as an \u201cimmorality\u201d among these variables. This explains why $\\mathcal{G}\\perp\\!\\!\\!\\perp X_{j}|$ holds; however, this independence may not persist in scenarios where $\\mathcal{G}\\perp\\bar{\\boldsymbol{X_{j}}}|\\circ,\\boldsymbol{Y}$ . ", "page_idx": 19}, {"type": "text", "text": "In the context of our work the input $X$ can be decomposed in $X=x_{o},X_{j}$ the observed part of the random variable and the unobserved part of the random variable. Consequently, $X_{j}$ follows the same independency assumptions of $X$ . ", "page_idx": 19}, {"type": "text", "text": "C Appendix C: Monte-Carlo Estimates ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In our study, we evaluate BALD and EPIG, along with their partially observed counterparts, POEIG and PO-EPIG. For completness, we show the estimatation the vanilla metrics, and later their corresponding partially observed extensions. ", "page_idx": 20}, {"type": "text", "text": "C.1 PO-EIG and BALD ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We follow a similar notation to [28]. For categorical variables, BALD can be decomposed as: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\mathrm{I}(\\Omega,Y|x_{o},\\mathcal{D})=\\mathrm{H}(y|x_{o},\\mathcal{D})-\\mathrm{H}(y|x_{o},\\Omega,\\mathcal{D})}\\\\ {\\displaystyle=\\mathbb{E}_{p_{\\phi}(\\omega)}\\left[\\mathbb{E}_{p_{\\phi}(y|x)}[\\log p_{\\phi}(y|x)]+\\mathbb{E}_{p_{\\phi}(y|x,\\omega)}[\\log p_{\\phi}(y|x,\\omega)]\\right]}&{{\\scriptstyle(1)}}\\\\ {\\displaystyle\\approx-\\sum_{y\\in\\mathcal{Y}}\\hat{p}_{\\phi}(y|x_{o})\\log\\hat{p}_{\\phi}(y|x_{o})+\\frac{1}{K}\\sum_{k=1}^{K}\\sum_{y\\in\\mathcal{Y}}p_{\\phi}(y|x_{o},\\omega_{k})\\log p_{\\phi}(y|x_{o},\\omega_{k}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $K$ represent the total number of parameter samples $\\omega_{k}\\sim p_{\\phi}(\\omega)$ from the posterior distribution given $\\mathcal{D}$ . Here, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\hat{p}_{\\phi}(y|\\pmb{x}_{o})=\\frac{1}{K}\\sum_{k=1}^{K}p_{\\phi}(y|\\pmb{x}_{o},\\omega_{k}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "PO-EIG extends this formulation to include missing features as conditioning samples $\\tilde{\\pmb{x}}_{j}$ from the GSM, accommodating partially observed settings. To illustrate, let\u2019s first consider the case where the metric is conditioned over all unobserved features, i.e., $j^{\\prime}=\\emptyset$ , which correspond to results of Figure 3. Following a similar decomposition, we can approximate $\\mathbb{E}_{\\tilde{\\mathbf{x}}_{j}}\\mathrm{I}(\\Omega,Y|x_{o},\\bar{\\mathcal{D}},\\tilde{\\mathbf{x}}_{j})$ as: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\tilde{x}_{j}}\\mathrm{I}(\\Omega,Y|x_{o},\\mathcal{D},\\tilde{x}_{j})\\approx\\displaystyle\\sum_{l=1}^{L}\\Bigg[-\\displaystyle\\sum_{y\\in\\mathcal{Y}}\\hat{p}_{\\phi}(y|x^{l})\\log\\hat{p}_{\\phi}(y|x^{l})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\sum_{y\\in\\mathcal{Y}}p_{\\phi}(y|x^{l},\\omega_{k})\\log p_{\\phi}(y|x^{l},\\omega_{k})\\Bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "here $L$ represent the total number of Monte-Carlo samples from the GSM, with $\\tilde{\\pmb{x}}_{j}^{l}$ one possible sample. Here, ", "page_idx": 20}, {"type": "equation", "text": "$$\np_{\\phi}(y|\\mathbf{x}^{l})=p_{\\phi}(y|\\underbrace{x_{o},\\tilde{\\mathbf{x}}_{j}^{l}}_{x})\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\hat{p}_{\\phi}(y|\\pmb{x}^{l})=\\frac{1}{K}\\sum_{k=1}^{K}p_{\\phi}(y|\\pmb{x}^{l},\\omega_{k}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "What happen when $^j$ doesn\u2019t consider all unobserved features?. This scenario is useful when we want to asses the impact acquiring of subset of the unobserved features. Utilizing a smart notation, this approximation can be stated identically as Equation (19), but the estimation of the predictive distribution changes slightly: ", "page_idx": 20}, {"type": "equation", "text": "$$\np_{\\phi}(y|x^{l},w_{k})=\\sum_{p=1}^{P}p_{\\phi}(y|\\underbrace{x_{o},x_{j}^{l},x_{j^{\\prime}}^{p}}_{x},w_{k}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "here, $P$ are a total of new MC samples from the GSM. This marginalization trick is necessary to deal with model that expect fixed size inputs. ", "page_idx": 20}, {"type": "text", "text": "C.2 PO-EPIG and EPIG ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "For PO-EPIG and EPIG, we replace the sub-index eval by $^*$ . Similar to before, for categorical variables, EPIG can be decomposed as: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{I}(Y_{*},Y|x_{o},X_{*},\\mathcal{D})=\\mathbb{E}_{x_{*}}[\\mathrm{I}(Y_{*},Y|x_{o},x_{*},\\mathcal{D})]}\\\\ &{\\phantom{\\mathrm{I}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!=\\mathbb{E}_{x_{*}}[\\mathrm{KL}(p_{\\phi}(y_{*},y|x_{o},x_{*})||p_{\\phi}(y_{*}|x_{*})p_{\\phi}(y|x_{o})]}\\\\ &{\\phantom{\\mathrm{I}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\approx\\frac{1}{M}\\sum_{m=1}^{M}\\sum_{y\\in\\mathcal{Y}_{\\mathcal{Y}_{*}}}\\sum_{\\hat{p}_{\\phi}(y,y_{*}|x_{o},x_{*}^{m})}\\log\\frac{\\hat{p}_{\\phi}(y,y_{*}|x_{o},x_{*}^{m})}{\\hat{p}_{\\phi}(y|x_{o})\\hat{p}_{\\phi}(y_{*}|x_{*}^{m})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "here, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\hat{p}_{\\phi}(y,y_{*}|x_{o},x_{*}^{m})=\\frac{1}{K}\\sum_{k=1}^{K}p_{\\phi}(y|x_{o},\\omega_{k})p_{\\phi}(y_{*}|x_{*}^{m},\\omega_{k}),}}\\\\ {{\\displaystyle\\hat{p}_{\\phi}(y|x_{o})=\\sum_{k=1}^{K}p_{\\phi}(y|x_{o},\\omega_{k}),}}\\\\ {{\\displaystyle\\hat{p}_{\\phi}(y_{*}|x_{*}^{m})=\\sum_{k=1}^{K}p_{\\phi}(y_{*}|x_{*}^{m},\\omega_{k})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Similarly as before, PO-EPIG extends this formulation to include missing features when conditioning on samples $\\tilde{\\pmb{x}}_{j}$ from the GSM. We now derive the estimation of this metric when estimating PO-EPIG when considering all the unobserved features $^j$ . We can decompose $\\mathbb{E}_{\\tilde{\\mathbf{x}}_{j}}\\mathrm{I}(Y_{*},Y|\\mathbf{x}_{o},X_{*},\\mathcal{D},\\tilde{\\mathbf{x}}_{j})$ as: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\tilde{\\alpha}_{j}}\\mathrm{I}\\big(Y_{*},Y\\mid x_{o},X_{*},\\mathcal{D},\\tilde{x}_{j}\\big)\\approx\\sum_{l=1}^{L}\\Bigg[\\frac{1}{M}\\sum_{m=1}^{M}\\sum_{y\\in\\mathcal{Y}}\\sum_{y_{*}\\in\\mathcal{Y}_{*}}\\hat{p}_{\\phi}\\big(y,y_{*}\\mid x^{l},x_{**}^{m}\\big)}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\times\\log\\frac{\\hat{p}_{\\phi}\\big(y,y_{*}\\mid x^{l},x_{**}^{m}\\big)}{\\hat{p}_{\\phi}\\big(y\\mid x^{l}\\big)\\,\\hat{p}_{\\phi}\\big(y_{*}\\mid x_{**}^{m}\\big)}\\Bigg],\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{\\displaystyle\\hat{p}_{\\phi}(y,y_{*}|x^{l},x_{*}^{m})=\\frac{1}{K}\\sum_{k=1}^{K}p_{\\phi}(y|\\underbrace{x_{o},\\tilde{x}_{j}^{l}}_{x},\\omega_{k})p_{\\phi}(y_{*}|x_{*}^{m},\\omega_{k}),}\\\\ {\\displaystyle\\hat{p}_{\\phi}(y|x^{l})=\\sum_{k=1}^{K}p_{\\phi}(y|\\underbrace{x_{o},\\tilde{x}_{j}^{l}}_{x},\\omega_{k}),}\\\\ {\\displaystyle\\hat{p}_{\\phi}(y_{*}|x_{*}^{m})=\\sum_{k=1}^{K}\\sum_{h=1}^{H}p_{\\phi}(y_{*}|x_{*}^{m},x_{j}^{h},\\omega_{k}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Note that the marginalization step of the \u201cevaluation set\u201d is also necessary since we also assume it to be partially observed. Here, $\\pmb{x}_{j}^{h}$ are Monte-Carlo samples necessary make the predictive model receive fixed inputs. While expensive, PO-EPIG can also compute metrics when only a subset of features is estimated to be acquired. The trick is similar to PO-EIG, being necessary a marginalization across the $j^{\\prime}$ for the the predictive mode receive fixed-size inputs (as (22)). ", "page_idx": 21}, {"type": "text", "text": "C.3 Illustration of efficient MC estimation ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "As outlined in the earlier sections, we approximate the PO-metrics through the techniques of conditioning and marginalization. Figure 8 provides a visual representation of this approximation. ", "page_idx": 22}, {"type": "text", "text": "In Eq. (8), for efficient computation in the marginalization of $j^{\\prime}$ , we substitute $p_{\\theta}(x_{j^{\\prime}}|\\pmb{x}_{o},\\pmb{x}_{j})$ with $p_{\\theta}(x_{j^{\\prime}}|\\mathbf{\\emx}_{o})$ , using the same samples used to compute the uncertainty reduction across all unobserved features. This approximation does not significantly compromise precision, as we exclude the least relevant feature sequentially. Consequently, the samples used to marginalize an \u201cirrelevant\u201d feature remain minimally impacted by the overall sampling strategy. ", "page_idx": 22}, {"type": "image", "img_path": "bescO94wog/tmp/2451f4134b748f060decb7cfc09513169e86621a37f73955957593f84e3df1d7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 8: Illustrative diagram demonstrating the application of conditioning and marginalization techniques in the estimation of PO-metrics for an arbitrary instance. ", "page_idx": 22}, {"type": "table", "img_path": "bescO94wog/tmp/35e1f907e935e2ae40524cc6ebea5be73d18590dc3c79008871206b40b01394a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "We assume that GSMs will be trained using available unlabeled data, which may be either fully observed (if a bank of fully observed unlabeled data is available) or partially observed (using the pool set itself), respectively. This assumption enables us to train the GSM and generate imputed values for the pool set before the acquisition process begins. The complete acquisition is detailed in Algorithm 2. ", "page_idx": 23}, {"type": "text", "text": "We define the generation cost as $C_{g}$ and the downstream cost as $C_{d}$ . Algorithm 2 indicates that the sampling cost for GSMs is $\\mathcal{O}(I\\cdot J^{'}\\cdot S\\cdot C_{g})$ , where $I$ is the number of instances, $J$ is the number of features, and $S$ represents the number of Monte Carlo samples. The inference cost of the downstream model is $\\mathcal{O}(I\\cdot J\\cdot S\\cdot C_{d})$ . ", "page_idx": 23}, {"type": "text", "text": "The cost of acquiring a subset of features depends on the restriction $r(i,j)$ , which is bounded by $J$ (the case where $J$ features are discarded for acquisition). The cost for acquiring a subset of features for a single instance is ${\\mathcal{O}}(J^{2}\\cdot S\\cdot C_{d})$ using Algorithm 1. To reduce this overhead, we first select the most informative instance (assuming all features are acquired) in $\\mathcal{O}(I\\cdot J\\cdot S\\cdot C_{d})$ (L7 in Algorithm 2), and then select the subset of features to acquire using Algorithm 1 (10 in our case) in order $\\mathcal{O}(J^{2}\\cdot R\\cdot S\\cdot C_{d})$ . This analysis shows that the most critical factor is the number of features $J$ , as it affects both sampling and the downstream model (quadratically in this case). ", "page_idx": 23}, {"type": "text", "text": "Another consideration is when the available data is insufficient for a reliable GSM. In this case, any additional features acquired during the acquisition process can be used to update the GSM weights periodically, which increases the costs. ", "page_idx": 23}, {"type": "text", "text": "E Datasets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Datasets were constructed such the number of pool samples were numerous enough to determine the impact of the acquisition performance any confounding effect. The distribution of pool set were selected maintaining the distribution of the original dataset similar to previous work [28]. The \u201cevaluation distribution\u201d in EPIG is follows the same distribution of pool set. As mentioned in the main text, we maintain a small unlabeled historical set for GSM training allowing fair comparison with Active Learning. For large datasets like Adult and Housing we limit their maximum original data size avoiding unnecessary costs in Monte-Carlo sample generation. The test set is defined as the $30\\,\\%$ of the intial dataset. ", "page_idx": 24}, {"type": "text", "text": "\u2022 Magic [99]: Original data size of 19020 samples. Historical set of 1000 samples. Pool set distribution; Class0: 4980 samples. Class1: 2700   \n\u2022 Adult [100]. Original data size of 19020 samples (after cut). Historical set of 1000 samples. Pool set distribution; Class0: 5760 samples. Class1: 1920.   \n\u2022 Housing. Original data size of 19020 samples (after cut). Historical dataset of 1000 samples. Pool set distribution; Class0: 3840, Class1: 3840.   \n\u2022 Cardio [101]. Original data size of 100k samples. Historical dataset of 1000 samples. Pool set distribution; Class0: 3000, Class1: 3000.   \n\u2022 Banking [102] Original data size of 45211 samples. Historical dataset of 400 samples. Pool set distribution; Class0: 2000, Class1: 500. ", "page_idx": 24}, {"type": "text", "text": "We did slight modification in datasets allowing LLM better comprehension. For Magic, we didn\u2019t include fConc1 since its name similarity with fConc. For CMC dataset, we change categorical values 0 and 1 to the categories that were represented on metadata. For example, in column \u201cStandard-ofliving_index\u201d instead of using 0,1, 2, 3 we use Low, Medium-Low, Medium-High, and High. ", "page_idx": 24}, {"type": "text", "text": "With this adjustment the final columns of these datasets are: ", "page_idx": 24}, {"type": "text", "text": "\u2022 Magic. 9 numerical columns: fLength, fWidth, fSize, fConc, fAsym, fM3Long\u2019, fM3Trans, fAlpha, fDist.   \n\u2022 Adult. 8 categorical columns: workclass, education, marital-status, occupation, relationship, race, sex, native-country. 6 numerical columns: age, fnlwgt, education-num, capital-gain, capital-loss, hours-per-week.   \n\u2022 Housing. 8 numerical columns: MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude.   \n\u2022 Cardio. 10 numerical columns: ID, age, age_years, height, weight, ap_hi, ap_lo, bmi. 7 categorical variables: gender, cholesterol, gluc, smoke, alco, active, bp_category_encoded.   \n\u2022 Bank. 2 numerical columns: age, balance. 6 categorical variables: job, marital, education, contact, day_of_week, default. ", "page_idx": 24}, {"type": "text", "text": "For model training, we use one hot encoding for categorical variables. ", "page_idx": 24}, {"type": "text", "text": "F Large Language Models, training and evaluation ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We analyzed primarily one open-source Mistral7B-Instruct-v0.3 with more in Section J. Preliminary findings show that instruct LLMs generally outperformed their non-instruct counterparts. In what follows, we give component used and a general overview of the prompts used: ", "page_idx": 24}, {"type": "text", "text": "\u2022 Input: The input is the tabular information provided to the LLM. Here, it is in the form of \u201c{feature A: value A, feature B: value $B$ , feature C: value $C$ }\u201d, for possible features and values.   \n\u2022 Query: The query represents the information requested by the LLM to generate a response. It should only include the attribute names, formatted as follows: \u201c{feature D: [Mask], feature E: [Mask], feature F: [Mask]\u201d. ", "page_idx": 24}, {"type": "text", "text": "\u2022 Response: The input is the tabular information provided to the LLM. Here, it is in the form of only values: \u201c{feature D: value $D$ , feature E: value $E$ , feature $F$ : value $F\\}^{\\bullet}$ . ", "page_idx": 25}, {"type": "text", "text": "The specific prompts were adjusted to specific LLM format. ", "page_idx": 25}, {"type": "text", "text": "F.1 Mistral7B-Instruct-v0.3 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Training time: approximately 1-2 hours ", "page_idx": 25}, {"type": "text", "text": "{\\*\\*Input, \\*\\*Query} ###Response: {\\*\\*Input, \\*\\*Response}   \nTest time: The total number of generated samples varies depending on the dataset, with processing   \ntimes ranging from 3 to 8 hours.   \n{\\*\\*Input, \\*\\*Query} ###Response:   \nHere as some samples and the respones On Magic:   \n{fAsym: -90.6431, fM3Trans: -10.169, fDist: 250.51, fConc: 0.1637, fAlpha: [Mask], fM3Long: [Mask], fSize: [Mask], fWidth: [Mask], fLength: [Mask]} ###Response: {fAsym: -90.6431, fM3Trans: -10.169, fDist: 250.51, fConc: 0.1637, fAlpha: 1.719, fM3Long: -33.7346, fSize:   \n3.3316, fWidth: 28.4232, fLength: 69.8763}   \n{fConc: 0.3174, fM3Trans: -4.5924, fAsym: -28.5264, fDist: 150.686, fSize: [Mask], fM3Long: [Mask], fWidth: [Mask], fAlpha: [Mask], fLength: [Mask]} ###Response: {fConc: 0.3174, fM3Trans: -4.5924, fAsym: -28.5264, fDist: 150.686, fSize: 2.6819, fM3Long: -21.4579, fWidth: 16.6296, fAlpha: 18.3037, fLength: 27.3688} {fM3Trans: -19.0262, fDist: 294.682, fConc: 0.1546, fAsym: -137.729, fAlpha: [Mask], fLength: [Mask], fWidth: [Mask], fM3Long: [Mask], fSize: [Mask]} ###Response: {fM3Trans: -19.0262, fDist: 294.682, fConc: 0.1546, fAsym: -137.729, fAlpha: 0.294, fLength: 124.816, fWidth: 38.3973, fM3Long: -71.1274, fSize: 3.3655} {fM3Trans: -11.0238, fDist: 85.2971, fConc: 0.1765, fAsym: 32.2464, fWidth: [Mask], fM3Long: [Mask], fAlpha: [Mask], fLength: [Mask], fSize: [Mask]} ###Response: {fM3Trans: -11.0238,   \nfDist: 85.2971, fConc: 0.1765, fAsym: 32.2464, fWidth: 27.559, fM3Long: -51.3547, fAlpha: 21.297, fLength: 56.6845, fSize: 3.3454} ", "page_idx": 25}, {"type": "text", "text": "F.2 Masking ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We tested two masking strategies. First, when we had access to all the historical data, particularly when comparing against traditional AL in the main text. Second, when certain features might be missing, as encountered in Appendix I. In the first scenario, we randomly masked some observed information, always ensuring at least two features as input to prevent overly complex tasks for the LLM. In the second scenario, due to the partial observability of data, some features could be less observed than others, leading to varying degrees of missingness. ", "page_idx": 25}, {"type": "text", "text": "F.3 Training specification ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We train the models using QLoRA using 4 bit quantization, $r=32$ , lora_alpha $=64$ , for 10000 steps, with 2 samples per batch size, and a learning rate of 7.5e-5. ", "page_idx": 25}, {"type": "text", "text": "G Generative Surrogate Models ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In this section, we outline the core desiderata for Generative Surrogate Models to be used within the $\\mu\\mathrm{POCA}$ framework and compares related imputation methods against the desiderata. ", "page_idx": 26}, {"type": "text", "text": "\u2022 [P1] Generative capability: The model must model a non-deterministic distribution over the unobserved features to effectively identify and prioritize the most relevant features. To exemplify, we consider $x_{j^{*}}$ as the subset of current features under review for acquisition, and $\\mathbf{\\boldsymbol{x}}_{j^{\\prime}}$ as the features already excluded from acquisition. PO-EIG\u2019s acquisition metric strategically selects the feature, $\\boldsymbol{v}^{*}$ , that maximizes uncertainty reduction among all possible features, $v$ , considered for exclusion from the set $j^{*}$ . This effectively minimizes information loss. Formally, this is expressed as: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\boldsymbol{v}^{*}=\\underset{\\boldsymbol{v}\\in\\boldsymbol{j}^{*}}{\\arg\\operatorname*{max}}\\,\\mathbb{E}_{\\tilde{\\alpha}_{\\boldsymbol{j}\\setminus\\boldsymbol{v}}}\\mathrm{I}(\\Omega,Y|\\tilde{\\boldsymbol{x}}_{\\boldsymbol{j}\\setminus\\boldsymbol{v}},\\mathbf{x}_{o},T).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "In contrast, employing a deterministic GSM modifies the acquisition strategy for imputed features $\\bar{\\pmb{x}}$ , simplifying to: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v^{*}=\\underset{v\\in\\mathcal{j}^{*}}{\\arg\\operatorname*{max}}\\,\\mathrm{I}\\big(\\Omega,Y|\\bar{\\pmb{x}}_{j\\setminus v},\\pmb{x}_{o},\\mathcal{D}\\big).}\\\\ &{\\qquad=\\underset{v\\in\\mathcal{j}^{*}}{\\arg\\operatorname*{max}}\\,\\mathrm{I}\\big(\\Omega,Y|\\bar{\\pmb{x}},\\pmb{x}_{o},\\mathcal{D}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The second equality arises from the fact that we are limited to a single value due to estimated conditioning and marginalization. Consequently, any permutation of conditioning sets $^j$ and marginalization sets $j^{\\prime}$ will lead to the same metric for a deterministic GSM. (34) explicitly demonstrates that employing deterministic GSM results in an acquisition metric independent of $v$ , the feature under consideration for exclusion through a greedy approach. In conclusion, the GSM should model a stochastic distribution for acquisition purposes. ", "page_idx": 26}, {"type": "text", "text": "\u2022 [P2] Learning on partially observed data: The GSM must learn from partially observed training data, where different instances will have varying observed features. ", "page_idx": 26}, {"type": "text", "text": "[P3] Sample-efficiency: Given the potential scarcity and variability of feature observability of training data, the GSM must efficiently learn from limited samples with different observed features. ", "page_idx": 26}, {"type": "text", "text": "\u2022 [P4] Supports mixed-type variables: To support a broad range of data types, the GSM should enable generative modelling across both continuous and discrete variables. ", "page_idx": 26}, {"type": "table", "img_path": "bescO94wog/tmp/1523c2961d6b74f154d0ef886ec60023d10a87ec5f7cc92ad54bc839e2791f92.jpg", "table_caption": ["Table 3: Overview of imputation methods. Comparison based on key desiderata of a GSM. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Flexibility of Large Language Models. We believe that Large Language Models hold significant potential as sample-efficient methods for feature estimation. Although LLMs are not specifically pretrained for tabular data estimation, their general capabilities have demonstrated effectiveness across various domains. These general abilities have been successfully applied in optimization [24, 117], reasoning [118, 119], planning [120\u2013122], concepts [123, 124], autonomous adaptation [125\u2013127], digital twin construction [128, 129], and as tabular data generators [49]. They have also shown promise as few-shot tabular learners in supervised settings [52, 53]. The application of LLMs in the intersection of tabular data tasks, particularly in the last two contexts, provides direct evidence of their viability in this area and to be used as GSMs in the context of data acquisition. ", "page_idx": 26}, {"type": "text", "text": "H Comparing with Active Learning ", "text_level": 1, "page_idx": 27}, {"type": "image", "img_path": "bescO94wog/tmp/370be2abc283440d6894271c6e55ea2d44992b2b6fda28ae60d8171e90bd236d.jpg", "img_caption": ["Figure 9: Scenario 1. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "bescO94wog/tmp/5a28b9e7e140e63e5951c81eb3f9aa47146434a5bb6211fbc3bf96aa30585ed1.jpg", "img_caption": ["Figure 10: Scenario 2. "], "img_footnote": [": Labels acquired : Features acquired :Features imputed "], "page_idx": 27}, {"type": "text", "text": "We used Scenario 1 as indicated in the main text. Another scenario where traditional active learning metrics can be applied is Scenario 2, which utilizes conventional imputation methods. The results for this scenario are shown in Figure 12 when all features are acquired for the Active Learning metric. As discussed in the main paper deterministic imputation does not allowed for the acquisition of subset of features, which is illustrated in Figure 11. ", "page_idx": 27}, {"type": "image", "img_path": "bescO94wog/tmp/55b76aae4f34e5b32e796b02750f1df86500f64963a7446da9c6dc276a6ccde8.jpg", "img_caption": ["Figure 11: Figure (a) shows the distribution of $X_{2}$ and $X_{3}$ conditioned on $x_{1}$ . With estimates of $X_{2}$ and $X_{3}$ , $\\mu\\mathrm{POCA}$ can identify the relevant feature $(X_{2})$ and the relevant region. In contrast, AL metrics might use deterministic imputation (green), which does not reveal feature relevance or area of importance under partial observability. This is because a point estimate can not explore the $X_{2}$ , $X_{3}$ and how their variability affects the outcome. "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "I Additional Results ", "text_level": 1, "page_idx": 28}, {"type": "image", "img_path": "bescO94wog/tmp/c9655a6054e528a7f594725d6de61796f88f0699c9add8b6cc5f952c836a00fe.jpg", "img_caption": [], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "Figure 12 illustrates that Mistral-Instruct-v0.3 trained LLMs solely on the Pool dataset, introducing a different scenario than the discussed in the main text. In this setup, only three features are consistently observed in the pool set, while others may be absent with uniform of probability. While the effectiveness of LLMs would depend on case-by case scenarios. In this demonstration, we underscore their viability and potential as Generative Surrogate Models (GSMs). ", "page_idx": 28}, {"type": "text", "text": "I.1 Varying uncertainty metrics ", "text_level": 1, "page_idx": 28}, {"type": "image", "img_path": "bescO94wog/tmp/76783748c8722c37f72d20a91c085b1ab6e17179906499401b2428cc4cd00462.jpg", "img_caption": ["Figure 13: Partially observed active learning metrics and their fully observed counterparts. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "J Analysis of GSM ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "The performance of $\\mu\\mathrm{POCA}$ in partially observed settings fundamentally depends on how well the GSM approximates the distribution of the unobserved features. There are two key factors that affect the quality of this estimation: ", "page_idx": 29}, {"type": "text", "text": "\u2022 GSM\u2019s approximation power: Referring to the model\u2019s capacity to accurately model the unobserved features. \u2022 Intrinsic characteristics of the dataset: Referring to inherent correlations between observed and unobserved features. Indeed, lower correlations are more challenging. ", "page_idx": 29}, {"type": "text", "text": "In what follows, we investigate each factor in turn, [G1] studying the impact of different GSMs and [G2] investigating different dataset characteristics. This approach aims to delineate the conditions under which $\\mu\\mathrm{POCA}$ is expected to excel. ", "page_idx": 29}, {"type": "text", "text": "[G1] GSM impact on acquisition performance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Setup. We evaluated various LLMs (including Mistral-7B-Instruct-v0.3, Gemma2, and Llama-3.1) as GSMs to assess how model quality affects acquisition performance. ", "page_idx": 29}, {"type": "text", "text": "Analysis. Figure 14 demonstrates that GSM quality significantly influences acquisition results. Notably, Mistral-7B consistently outperforms the alternative GSMs, with one exception in the housing dataset. Interestingly, Gemma 2 performs well on this benchmark, highlighting this intermodel variability. The Cardio dataset further highlights these differences, with Mistral-7B performing significantly better than the other models. ", "page_idx": 29}, {"type": "text", "text": "Takeaway. These findings underscore the critical role of GSM quality in acquisition performance. ", "page_idx": 29}, {"type": "image", "img_path": "bescO94wog/tmp/b77af66b9a0bdfb7f8c23db23f1093074c1c638178626f5da84a97e89b8ab345.jpg", "img_caption": ["Figure 14: Varying LLMs with Mistral7B-Instruct v0.3 based on EIG acquisition metric. "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "[G2] Performance across varying data characteristics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Setup. Next, we turn our attention to investigating how the data distribution affects acquisition performance. We are particularly interested in analyzing the effect of the correlation between unobserved features $X_{u n o b s}$ and observed features $X_{o b s}$ on acquisition performance. ", "page_idx": 30}, {"type": "text", "text": "To demonstrate this, we examine a scenario where (1) $X_{u n o b s}$ correlates with the outcome, while (2) observed features do not. In this context, the GSM becomes crucial for downstream performance, as $X_{o b s}$ alone provides insufficient information to predict outcomes accurately. As such, the GSM must effectively model the relationship between $X_{o b s}$ and $X_{u n o b s}$ to acquire missing features critical for predicting the outcome. ", "page_idx": 30}, {"type": "text", "text": "We model both $X_{o b s}$ and $X_{u n o b s}$ as two-dimensional random Gaussian variables centered at zero and establish a specific controllable correlation between them through $\\rho$ : ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\Sigma=\\left[\\!\\!\\begin{array}{c c}{I_{2}}&{\\rho_{X_{o b s}X_{u n o b s}}I_{2}}\\\\ {\\rho_{X_{o b s}X_{u n o b s}}I_{2}}&{I_{2}}\\end{array}\\!\\!\\right]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The label $Y$ is then constructed to be independent of $X_{o b s}$ using the orthogonalization: ", "page_idx": 30}, {"type": "equation", "text": "$$\nX_{\\mathrm{orthogonal}}=X_{u n o b s}-X_{o b s}(X_{o b s}^{T}X_{o b s})^{-1}X_{o b s}^{T}X_{u n o b s}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "which we use to construct the label using ", "page_idx": 30}, {"type": "equation", "text": "$$\n{\\mathrm{logits}}={\\frac{1}{1+e^{-\\sum X_{\\mathrm{orthogonal}}}}},\\quad C=\\mathbf{1}_{\\mathrm{logits}>0}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Analysis. Figure 15a illustrates how varying $\\rho$ between $X_{o b s}$ and $X_{u n o b s}$ empirically affects variable correlation, $c$ , validating our synthetic experiment design. Figure 15b analyzes EIG (traditional active learning without GSM) and PO-EIG with varying $\\rho$ . We note that when the correlation between $X_{o b s}$ and $X_{u n o b s}$ is low, GSMs provide no performance benefits. However, as correlation increases, the performance gains of PO-EIG over EIG expand significantly, confirming our hypothesis. ", "page_idx": 30}, {"type": "image", "img_path": "bescO94wog/tmp/febdbfec9e198472db1d3ec1f00a898dd552738191a06aa4bfc1be7b4c79273b.jpg", "img_caption": ["(a) Correlations between $X_{\\mathrm{obs}}$ and $Y$ , and between $X_{\\mathrm{unobs}}$ and $Y$ is roughly unaffected across different vaues of $\\rho$ . "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "bescO94wog/tmp/fced488fd236b0bf15edd387fba767ccce13ca5d656e3caacc290a8e5c4e56ee.jpg", "img_caption": ["(b) Performance of EIG Across Datasets with Varying Correlations Between Observed Features $(X_{o b s})$ and Unobserved Features $\\left(X_{u n o b s}\\right)$ . Observation: As correlation increases, the performance gains of PO-EIG (using GSM) over BALD (traditional AL) becomes more notable. "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "Figure 15: Synthetic experiments. Figure (a) visualizes the characteristics of the synthetic data with different values of $\\rho$ , while Figure (b) demonstrates the performance of EIG (BALD) and PO-EIG as the degree of correlation between observed and unobserved features varies. ", "page_idx": 30}, {"type": "text", "text": "K PO-EIG vs BALD ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Figure 16 illustrates the comparison of uncertainty reduction between PO-EIG and BALD (EIG) at iteration 50 of training with seed zero. It is evident that PO-EIG consistently achieves equal or greater uncertainty reduction than EIG. This empirical observation supports the validity of Corollary 1, and consequently, substantiates the assumption made in Proposition 6. ", "page_idx": 31}, {"type": "image", "img_path": "bescO94wog/tmp/dbcbb1af3611532e7e30a02a036da0cd14f9695ed4799b9e9055460e609368f3.jpg", "img_caption": ["Figure 16: PO-EIG vs BALD metrics on various scenarios at iteration 50. "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The abstract and introduction accurately reflects the claims made in the paper. We formalize the POCA problem and provide an instantiation of POCA which we validate empirically. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. \u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 32}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: Section 5 discusses possible limitations with mitigation strategies. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 32}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We provide all assumptions for proofs in Sections 2 and 3. We also provide additional details in Appendix B and C. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 33}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: Experimental details are provided in Section 4, with further details in Appendix D and E. The implementation of our instantiation closely follows Section 3. Code can be found at: https://github.com/ADDUSER/POCA or https://github.com/ vanderschaarlab/POCA ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 33}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 34}, {"type": "text", "text": "Answer: [No] ", "page_idx": 34}, {"type": "text", "text": "Justification: Besides the descriptions in Sec 4, we also provide details about the algorithms and data in Appendix D and E. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 34}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: All the details on data, training, prompts etc for the experiments are provided in Appendix D and E. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 34}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Error bars $95\\%$ confidence interval) are included as relevant over 15 seeds for the experiments. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 34}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 35}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The compute details on the experiments are provided in Appendix E. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 35}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We have read the code of ethics do not violate any of the dimensions. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 35}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We highlight broader impacts in Section 1 and 5 of the paper, as well as, Appendix A \u2014 discussing both positive impacts and possible negative impacts (e.g. biases). Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 35}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 36}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: Not applicable \u2014 our paper presents a process for data acquisition \u2014 which does not fall into this category. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 36}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Appendix D provides details and/or citations for all the open source data assets used in the paper. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: The paper does not produce new assets such as datasets, but uses existing datasets. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 37}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: We do not have crowdsourcing experiments or research with humans. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 37}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: We do not have crowdsourcing experiments or research with humans that would need an IRB. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 37}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 38}]