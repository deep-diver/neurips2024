[{"figure_path": "nRp0XhTf61/tables/tables_5_1.jpg", "caption": "Table 2: Supervised Fine-Tuning Datasets. We collect data from diverse sources to empower the model with different capabilities. The image resolution is also different for different tasks.", "description": "This table lists the datasets used for supervised fine-tuning of the InternLM-XComposer2-4KHD model.  It breaks down the datasets by task (e.g., Captioning, General QA, Science QA, etc.) and shows the resolution setting used for each task's training data.  The table highlights the model's versatility and ability to handle different types of visual and textual information.", "section": "3 Method"}, {"figure_path": "nRp0XhTf61/tables/tables_6_1.jpg", "caption": "Table 4: Comparison with open-source SOTA methods. IXC2-4KHD outperforms competitors in most benchmarks. The best results are bold and the second-best results are underlined.", "description": "This table compares the performance of InternLM-XComposer2-4KHD (IXC2-4KHD) against other state-of-the-art (SOTA) open-source Large Vision-Language Models (LVLMs) across sixteen benchmark datasets.  The benchmarks cover diverse tasks, including document visual question answering, chart question answering, and image-based reasoning. The table highlights IXC2-4KHD's superior performance by showing that it achieves the best scores (in bold) on most benchmarks and second-best scores (underlined) on the others. The model sizes are also compared to showcase the efficiency of IXC2-4KHD.", "section": "4.1 LVLM Benchmark results"}, {"figure_path": "nRp0XhTf61/tables/tables_7_1.jpg", "caption": "Table 5: High-resolution Evaluation. IntenrLM-XComposer2-4KHD has the largest input resolution and outperforms open-source LVLMs which are specifically tuned for document understanding.", "description": "This table presents a comparison of InternLM-XComposer2-4KHD against other open-source Large Vision-Language Models (LVLMs) on high-resolution benchmarks focusing on document understanding tasks.  It shows that InternLM-XComposer2-4KHD achieves superior performance with the largest input resolution (3840x1600 pixels) compared to other models, highlighting its ability to handle high-resolution images effectively.", "section": "4.1 LVLM Benchmark results"}, {"figure_path": "nRp0XhTf61/tables/tables_8_1.jpg", "caption": "Table 7: (a) Influence of Indicator '\\n' in the Image Features. '\\n' helps LVLM understand structural images when the input resolution is dynamic and large. (b) Ablation on Token Merging Operation. Both the simple concatenation operation and the C-Abstractor works well.", "description": "This table presents the ablation study of two key components in InternLM-XComposer2-4KHD: the newline token ('\\n') as an indicator for image features and the token merging operation.  Part (a) compares the performance of the model with and without the newline token for different image resolutions (HD9 and 4KHD).  The results show that the newline token significantly improves performance when dealing with high resolutions, suggesting its crucial role in helping the model understand the 2D structure of images with dynamic and large patch layouts. Part (b) evaluates three different token merging strategies: Re-Sampler, C-Abstractor, and Concat.  The results indicate that both the concatenation and C-Abstractor methods achieve comparable performance, demonstrating the effectiveness of these approaches in balancing efficiency and performance.", "section": "4.3 High-Resolution Strategy Ablation"}, {"figure_path": "nRp0XhTf61/tables/tables_8_2.jpg", "caption": "Table 8: Influence of Global-View in the Input. Global-view is critical for most benchmarks.", "description": "This table presents the ablation study on the global view's impact. It compares the performance of the model with and without the global view across several benchmarks.  The results demonstrate the importance of the global view for overall performance, particularly highlighting its contribution to the accuracy on most benchmarks.", "section": "4.3 High-Resolution Strategy Ablation"}, {"figure_path": "nRp0XhTf61/tables/tables_8_3.jpg", "caption": "Table 9: Strategy-Level comparison between LLaVA-Next and our IXC2-4KHD. Our strategy reaches better performance under a similar image token number constrain.", "description": "This table compares the performance of the InternLM-XComposer2-4KHD model (IXC-4KHD) with LLaVA-Next, another state-of-the-art model, across multiple benchmarks.  It highlights the superior performance of IXC-4KHD while maintaining a similar number of image tokens as LLaVA-Next. This demonstrates the effectiveness of the IXC-4KHD model's high-resolution strategy.", "section": "4.3 High-Resolution Strategy Ablation"}, {"figure_path": "nRp0XhTf61/tables/tables_9_1.jpg", "caption": "Table 10: Inference Efficieny Analysis. The image token number mainly inference the prefix speed, and their difference in the decoding part is neglectable.", "description": "This table presents an efficiency analysis of the InternLM-XComposer2-4KHD model's inference process, focusing on the time required for prefix encoding and per-token decoding.  The results show that the prefix encoding time scales linearly with the number of image tokens, while the per-token decoding speed remains relatively constant regardless of the input size.  The overall inference time for generating 2048 new tokens is nearly identical across different input resolutions (HD9, HD16, HD25), indicating that the model's efficiency is acceptable even with high-resolution images.", "section": "4 Experiments"}]