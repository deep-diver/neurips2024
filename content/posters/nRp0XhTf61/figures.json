[{"figure_path": "nRp0XhTf61/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Overview of InternLM-XComposer2-4KHD (IXC-4KHD) performance on benchmarks with different resolutions. Our model based on InternLM2-7B (91) matches or even surpasses GPT-4V (74) and Gemini Pro (90) in 10 of the 16 benchmarks. (b) Image resolution statistic of 16 benchmarks. We report the minimum (Min), median, and maximum (Max) image area (resolution). Both the inter-/intra-benchmark resolution diversity are large, and we sort them by the maximum resolution.", "description": "This figure presents a comparison of the InternLM-XComposer2-4KHD model's performance against GPT-4V and Gemini Pro across 16 benchmarks, showcasing its superior performance in 10 out of the 16 benchmarks.  The figure also shows the image resolutions used in each benchmark, demonstrating a wide range of resolutions handled by the InternLM-XComposer2-4KHD model.", "section": "1 Introduction"}, {"figure_path": "nRp0XhTf61/figures/figures_2_1.jpg", "caption": "Figure 1: (a) Overview of InternLM-XComposer2-4KHD (IXC-4KHD) performance on benchmarks with different resolutions. Our model based on InternLM2-7B (91) matches or even surpasses GPT-4V (74) and Gemini Pro (90) in 10 of the 16 benchmarks. (b) Image resolution statistic of 16 benchmarks. We report the minimum (Min), median, and maximum (Max) image area (resolution). Both the inter-/intra-benchmark resolution diversity are large, and we sort them by the maximum resolution.", "description": "This figure presents a comparison of InternLM-XComposer2-4KHD's performance against state-of-the-art models on 16 benchmark datasets.  Subfigure (a) is a radar chart visualizing the model's performance across these benchmarks, showing that it surpasses or matches GPT-4V and Gemini Pro on 10 out of 16 tasks.  Subfigure (b) provides a statistical overview of the image resolutions within these benchmarks, indicating a wide range of resolutions used in the datasets, emphasizing the model's capability to handle diverse input image resolutions.", "section": "1 Introduction"}, {"figure_path": "nRp0XhTf61/figures/figures_4_1.jpg", "caption": "Figure 3: The framework of InternLM-XComposer2-4KHD. Our model processes the high-resolution image with a Dynamic Image Partition strategy and concatenates the image tokens with text tokens as LLM input.", "description": "The figure illustrates the architecture of InternLM-XComposer2-4KHD, a large vision-language model designed to handle high-resolution images.  It shows how the model processes high-resolution images by dynamically partitioning them into smaller patches.  These patches are then encoded and merged with text tokens before being fed into a large language model (LLM) for processing. The diagram highlights the \"Dynamic Image Configuration\" step which automatically adjusts the number and layout of patches based on the input image's aspect ratio and resolution, maintaining training image aspect ratios and varying patch counts and layouts.", "section": "3 Method"}, {"figure_path": "nRp0XhTf61/figures/figures_7_1.jpg", "caption": "Figure 1: (a) Overview of InternLM-XComposer2-4KHD (IXC-4KHD) performance on benchmarks with different resolutions. Our model based on InternLM2-7B (91) matches or even surpasses GPT-4V (74) and Gemini Pro (90) in 10 of the 16 benchmarks. (b) Image resolution statistic of 16 benchmarks. We report the minimum (Min), median, and maximum (Max) image area (resolution). Both the inter-/intra-benchmark resolution diversity are large, and we sort them by the maximum resolution.", "description": "This figure shows a comparison of InternLM-XComposer2-4KHD's performance against other models (GPT-4V and Gemini Pro) across 16 benchmarks with varying resolutions.  The left panel (a) is a radar chart illustrating the model's performance relative to the others; the right panel (b) shows the distribution of image resolutions across the benchmarks, categorized by minimum, median, and maximum values.", "section": "1 Introduction"}, {"figure_path": "nRp0XhTf61/figures/figures_16_1.jpg", "caption": "Figure 5: Chat with InternLM-XComposer2-4KHD.", "description": "This figure shows two example interactions with the InternLM-XComposer2-4KHD model.  The first example shows a question about contact tracing, with the model providing a detailed explanation based on an infographic image showing the contact tracing process. The second example shows the model describing a Venn diagram on the topic of healthy eating habits.", "section": "A More examples chat with our InternLM-XComposer2-4KHD"}, {"figure_path": "nRp0XhTf61/figures/figures_17_1.jpg", "caption": "Figure 3: The framework of InternLM-XComposer2-4KHD. Our model processes the high-resolution image with a Dynamic Image Partition strategy and concatenates the image tokens with text tokens as LLM input.", "description": "This figure illustrates the InternLM-XComposer2-4KHD model's architecture.  It showcases how high-resolution images are processed using a dynamic image partition strategy.  The image is divided into patches, and features are extracted from each patch. These features are then merged with text tokens and fed into a large language model (LLM) for processing. A key aspect shown is the dynamic configuration of patches based on the input image's resolution and aspect ratio. The global view, which provides a macro-level image understanding, is also included in the input.", "section": "3 Method"}, {"figure_path": "nRp0XhTf61/figures/figures_17_2.jpg", "caption": "Figure 1: (a) Overview of InternLM-XComposer2-4KHD (IXC-4KHD) performance on benchmarks with different resolutions. Our model based on InternLM2-7B (91) matches or even surpasses GPT-4V (74) and Gemini Pro (90) in 10 of the 16 benchmarks. (b) Image resolution statistic of 16 benchmarks. We report the minimum (Min), median, and maximum (Max) image area (resolution). Both the inter-/intra-benchmark resolution diversity are large, and we sort them by the maximum resolution.", "description": "This figure shows a comparison of the InternLM-XComposer2-4KHD model's performance against other models (GPT-4V and Gemini Pro) across 16 benchmarks with varying image resolutions.  Part (a) is a radar chart illustrating the model's performance relative to others. Part (b) provides a table summarizing the minimum, median, and maximum image resolutions across these benchmarks, highlighting the wide range of image sizes handled by InternLM-XComposer2-4KHD and the other models. The results demonstrate InternLM-XComposer2-4KHD's competitive performance and ability to handle a broad range of high resolutions.", "section": "1 Introduction"}, {"figure_path": "nRp0XhTf61/figures/figures_18_1.jpg", "caption": "Figure 3: The framework of InternLM-XComposer2-4KHD. Our model processes the high-resolution image with a Dynamic Image Partition strategy and concatenates the image tokens with text tokens as LLM input.", "description": "This figure illustrates the architecture of InternLM-XComposer2-4KHD, a large vision-language model designed to handle high-resolution images.  The model uses a dynamic image partition strategy, dividing high-resolution images into smaller patches based on their aspect ratio, before processing them with a vision transformer (ViT). These image tokens are then concatenated with text tokens and fed into a large language model (LLM) for processing. This approach enables the model to understand fine details in high-resolution images. The dynamic patch configuration ensures efficient handling of various image sizes and aspect ratios.", "section": "3 Method"}]