{"references": [{"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-06", "reason": "This paper is foundational to the concept of in-context learning (ICL), a core concept that the current paper builds upon and improves."}, {"fullname_first_author": "Jason Wei", "paper_title": "Emergent abilities of large language models", "publication_date": "2022-06-07", "reason": "This paper explores the emergent capabilities of LLMs, which provides theoretical support for why leveraging a smaller model to improve LVLMs might be effective."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "This paper introduces Flamingo, one of the LVLMs used in the experiments of the current paper, making it directly relevant to the empirical results."}, {"fullname_first_author": "Hugo Lauren\u00e7on", "paper_title": "Obelics: An open web-scale filtered dataset of interleaved image-text documents", "publication_date": "2023-12-01", "reason": "This paper introduces the IDEFICS dataset used in the experiments, providing the contextual data for the current paper's empirical results."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "CLIP, introduced in this paper, is a crucial component of the Lever-LM model architecture, providing the multimodal embedding used in the experiments."}]}