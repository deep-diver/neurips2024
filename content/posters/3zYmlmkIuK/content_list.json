[{"type": "text", "text": "Asynchronous Multi-Agent Reinforcement Learning with General Function Approximation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 We study multi-agent reinforcement learning (RL) where agents cooperate through   \n2 asynchronous communications with a central server to learn a shared environ  \n3 ment. Our first focus is on the case of multi-agent contextual bandits with general   \n4 function approximation, for which we introduce the Async-NLin-UCB algorithm.   \n5 This algorithm is proven to achieve a regret of $\\widetilde{O}(\\sqrt{T\\dim_{E}(\\mathcal{F})\\log N(\\mathcal{F})})$ and a   \n6 communication complexity of ${\\widetilde{O}}(M^{2}\\dim_{E}({\\mathcal{F}}))$ , where $M$ is the total number of   \n7 agents and $T$ is the number of rounds, while $\\dim_{E}({\\mathcal{F}})$ and $N({\\mathcal{F}})$ are the Eluder   \n8 dimension and the covering number of function space $\\mathcal{F}$ respectively. We then   \n9 progress to the more intricate setting of multi-agent RL with general function ap  \n10 proximation, and present the Async-NLSVI-UCB algorithm. This algorithm enjoys   \n11 a regret of $\\widetilde{O}(H^{2}\\sqrt{K\\dim_{E}(\\mathcal{F})\\log N(\\mathcal{F})})$ and a communication complexity of   \n12 $\\widetilde{O}(H M^{2}\\dim_{E}(\\mathcal{F}))$ , where $H$ is the horizon length and $K$ the number of episodes.   \n13 Our findings showcase the provable efficiency of both algorithms for collaborative   \n14 learning within nonlinear environments and minimal communication overhead. ", "page_idx": 0}, {"type": "text", "text": "15 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "16 Multi-agent reinforcement learning (RL) is an important paradigm in RL, and has been successfully   \n17 applied to real-world tasks such as robotics [Williams et al., 2016, Liu et al., 2019, Ding et al., 2020,   \n18 Liu et al., 2020, Na et al., 2022], games [Vinyals et al., 2017, Berner et al., 2019, Jaderberg et al.,   \n19 2019, Ye et al., 2020], and control systems [Bazzan, 2009, Yu et al., 2014, 2020, Min et al., 2022, Xu   \n20 et al., 2023]. By learning cooperatively, agents benefit from sharing learning experiences, enabling   \n21 them to collectively enhance their decision-making capabilities. This collaborative process is usually   \n22 accomplished through the utilization of a central server, whose task is to aggregate local data and   \n23 deliver feedback for the agents.   \n24 There has been an excellent line of work establishing provably efficient algorithms for multi-agent   \n25 bandits and RL. However, most existing works are restricted to the synchronous setting, where com  \n26 munications between all agents and the server must happen simultaneously. This is impractical since   \n27 in many scenarios the availability of agents may vary and be unpredictable. Ideally, communication   \n28 should be allowed to happen asynchronously to offer the agents more flexibility. He et al. [2022] and   \n29 Min et al. [2023] studied this setting respectively for linear contextual bandits and linear Markov   \n30 Decision Processes (MDPs), both of which assumes linearity in the environment, and introduced   \n31 algorithms with low regret and communication cost. Yet the linear function class is quite limited, and   \n32 does not encompass practical reinforcement learning scenarios where nonlinearity is prevalent.   \n33 To address the aforementioned drawback, in this work, we tackle environments with general function   \n34 approximation, broadening the applicability of the algorithm to more realistic and complex scenarios.   \n35 We first delve into multi-agent contextual bandits with general function approximation, where multiple   \n36 agents interact with homogeneous environments in parallel to solve a common objective. Notably,   \n37 the communication protocol is designed to be flexible and asynchronous, allowing agents to initiate   \n38 communication with the server and acquire new policy functions whenever the need arises. The   \n39 primary objective is to minimize total regret while reducing communication cost as much as possible.   \nSubmitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.   \n40 We propose an algorithm Async-NLin-UCB, which adapts a fully asynchronous communication   \n41 protocol, and leverages various methods for tackling nonlinear function approximation. Despite the   \n42 flexibility of communication, our algorithm performs almost as well as a single agent, in terms of a   \n43 regret that is mostly independent of the number of agents and a low communication cost.   \n44 We then progress to multi-agent RL with general function approximation under similar requirements   \n45 and objectives. We propose an algorithm named Async-NLSVI-UCB based on Least-Squares Value   \n46 Iteration (LSVI) to learn the underlying Markov decision processes (MDPs), which demonstrates   \n47 similar advantages with provably low regret and communication cost.   \n48 Our main contributions are summarized in the following:   \n49 \u2022 For asynchronous multi-agent nonlinear contextual bandits, we propose the algorithm   \n50 Async-NLin-UCB, which enjoys an $\\widetilde{O}(\\sqrt{T\\dim_{E}(\\mathcal{F})\\log N(\\mathcal{F})}\\,+\\,\\dim_{E}(\\mathcal{F}))$ regret and an   \n51 ${\\widetilde{O}}(M^{2}\\dim_{E}({\\mathcal{F}}))$ communication complexity, where $\\dim_{E}({\\mathcal{F}})$ and $N({\\mathcal{F}})$ are respectively the   \n52 Eluder dimension and the covering number of function space $\\mathcal{F}$ .   \n53 \u2022 For asynchronous multi-agent nonlinear MDPs, we propose the algorithm Async-NLSVI-UCB,   \n54 which enjoys an $\\widetilde{\\cal O}(H^{2}\\sqrt{K\\dim_{E}(\\mathcal{F})\\log N(\\mathcal{F})}+H^{2}\\dim_{E}(\\mathcal{F}))$ regret and a communication   \n55 complexity of $\\widetilde{O}(H M^{2}\\dim_{E}(\\mathcal{F}))$ .   \n\u2022 At the core of our algorithm, we design a communication criterion in order to tackles the challenges   \n57 posed by both asynchronous communication and the nonlinearity of function approximation. To   \n58 guarantee a low communication cost, we propose a low switching communication criterion that   \n59 allows the agent to trigger communication rounds.   \n60 \u2022 We carefully design our download content from server to local agents, which consist only of   \n61 decision and bonus functions, with no mention of any specific historical data. This effectively   \n62 protects user data against exposure by disallowing local users from obtaining the data of others.   \n63 Notation. We use lower case letters to denote scalars. We denote by $[n]$ the set $\\{1,\\ldots,n\\}$ . For   \n64 two positive sequences $\\left\\{a_{n}\\right\\}$ and $\\{b_{n}\\}$ with $n=1,2,\\ldots$ , we write $a_{n}\\,{\\overset{\\cdot}{=}}\\,O(b_{n})$ if there exists an   \n65 absolute constant $C>0$ such that $a_{n}\\leq C b_{n}$ holds for all $n\\geq1$ . We use $\\widetilde O(\\cdot)$ to further hide the   \n66 polylogarithmic factors. For two non-negative integers $a,b$ satisfying $a<b$ and a sequence $\\left\\{s_{i}\\right\\}$   \n67 indexed by integers $i$ , we use $s_{[a:b]}$ to denote the subsequence $\\{s_{a},s_{a+1},\\cdot\\cdot\\cdot\\,,s_{b}\\}$ . ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "68 2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "69 2.1 Multi-Agent Bandits ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "70 First, there is a multitude of previous work on distributed or federated multi-armed bandits and   \n71 stochastic linear bandits [Liu and Zhao, 2010, Szorenyi et al., 2013, Landgren et al., 2016, Chakraborty   \n72 et al., 2017, Landgren et al., 2018, Mart\u00ednez-Rubio et al., 2019, Sankararaman et al., 2019, Wang et al.,   \n73 2020a,c, Zhu et al., 2021, Huang et al., 2021]. For the more realistic setting of contextual bandits, most   \n74 previous work are within the scope of linear contextual bandits with synchronized communication.   \n75 Korda et al. [2016] introduced two novel distributed confidence ball (DCB) algorithms for linear   \n76 bandit problems in peer-to-peer networks. Wang et al. [2020c] considered both P2P and star-shaped   \n77 communication, achieving near-optimal regret and low communication cost that is largely independent   \n78 of the time horizon in their algorithm DisLinUCB. Dubey and Pentland [2020] proposed FedUCB,   \n79 an algorithm focusing on differential-privacy.   \n80 Li and Wang [2022] first considered an asynchronous communication protocol and proposed the   \n81 algorithm Async-LinUCB with near-optimal regret, yet the algorithm contains a download step   \n82 for all agents triggered by the central server. Their results are flexible and contains a parameter to   \n83 control the trade-off between regret and communication cost. He et al. [2022] improved the setting   \n84 to a fully asyn\u221achronous communication, proposing the algorithm FedLinUCB with near-optimal   \n85 regret of $\\widetilde{O}(d\\sqrt{T})$ and low communication cost of $\\widetilde{O}(d m^{2})$ , comparable to the benchmark in single  \n86 agent con textual linear bandits [Abbasi-Yadkori et  al., 2011]. We consider the same communication   \n87 protocol in our results. A summary of these results along with ours can be found in the first four rows   \n88 of Table 1. ", "page_idx": 1}, {"type": "text", "text": "89 2.2 Multi-Agent RL ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "90 Multi-agent reinforcement learning is decidedly more challenging than contextual bandits. There is   \n91 also a vast literature on this setting, with many works discussing different aspects of multi-agent RL   \n92 than ours. For example, there are works focusing on convergence guarantees [Zhang et al., 2018b,a,   \n93 Wai et al., 2018], non-stationary or heterogeneous environments [Lowe et al., 2017, Yu et al., 2021,   \n94 Dubey and Pentland, 2021, Kuba et al., 2022, Liu et al., 2022, Jin et al., 2022], and deep federated RL   \n95 [Clemente et al., 2017, Espeholt et al., 2018, Horgan et al., 2018, Nair et al., 2015, Zhuo et al., 2019],   \n96 to name a few. We refer to a recent survey on federated reinforcement learning Qi et al. [2021] for a   \n97 more comprehensive summary.   \n98 Narrowing it down to multi-agent RL with function approximation, the benc\u221ahmark is the LSVI-UCB   \n99 algorithm in the single-agent setting [Jin et al., 2020], with an $\\widetilde{\\cal O}(d^{3/2}H^{2}\\sqrt{K})$ regret. Dubey and   \n100 Pentland [2021] proposed CoopLSVI for multi-agent linear M DPs, whi\u221ach requires a synchronized   \n101 communication through central server, and proves a regret of $\\widetilde{\\cal O}(d^{3/2}H^{2}\\sqrt{M K})$ . They also extended   \n102 their result to the heterogeneous setting. Min et al. [2023] considered the fully asynchronous setting   \n103 and introduced the Async-Coop-LSVI-UCB algorithm, with a $\\widetilde{\\cal O}(d^{3/2}H^{2}\\sqrt{K})$ regret not dependent   \n104 on the number of agents $M$ , as well as a low communication c ost. A summary of these results along   \n105 with ours can be found in the last three rows of Table 1. ", "page_idx": 1}, {"type": "table", "img_path": "3zYmlmkIuK/tmp/152dc7e0ac519ed32cd6a4518539d6d64a3e8f65c6477bde6f81dcea4de55b0e.jpg", "table_caption": [], "table_footnote": ["Table 1: Comparison of our result against baseline methods for multi-agent contextual bandits and MDPs. Note that the first four rows are for contextual bandits, and the last three are for reinforcement learning. Only our algorithms are in the general function approximation setting. We abbreviate $\\dim_{E}=\\dim_{E}({\\mathcal{F}})$ and $N=N({\\mathcal{F}})$ , and hide logarithmic factors. For algorithms with synchronized communication, each communication round actually corresponds to $M$ rounds in asynchronous settings, which explains the extra $M$ terms. "], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "106 2.3 General function approximation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "107 Reinforcement learning with general function approximation extends the well-studied case of linear   \n108 MDPs to more general classes of MDPs, and has gained a lot of traction in recent years [Wang et al.,   \n109 2020b, Jin et al., 2021, Foster et al., 2023, Du et al., 2021, Agarwal and Zhang, 2022, Agarwal   \n110 et al., 2023]. Previous works focus on different measures of complexity for the function classes, for   \n111 example the Bellman rank proposed by Jiang et al. [2017], the Bellman Eluder dimension introduced   \n112 in Jin et al. [2021], the Decision-Estimation Coefficient in Foster et al. [2023], and generalized Eluder   \n113 dimension in Agarwal et al. [2023]. Our work considers the Eluder dimension with the introduction   \n114 of uncertainty estimators $D^{2}$ , which has been widely utilized to establish results in RL with general   \n115 function approximation [Agarwal et al., 2023, Zhao et al., 2023, Ye et al., 2023, Di et al., 2023]. ", "page_idx": 2}, {"type": "text", "text": "116 3 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "117 In this section, we introduce the formal definition of both multi-agent nonlinear contextual bandits   \n118 and MDPs and some related concepts, and discuss the asynchronous communication protocol. ", "page_idx": 2}, {"type": "text", "text": "119 3.1 Multi-Agent Contextual Bandits with General Function Approximation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "120 We assume a global action set $\\boldsymbol{\\mathcal{A}}$ that is known to all agents. At each round $t\\in[T]$ , a single arbitrary   \n121 agent $m_{t}\\in[M]$ is chosen to participate. The agent receives a contextual decision set $A_{t}\\subseteq A$ and   \n122 chooses from the set an action $a_{t}\\in\\mathcal A_{t}$ to perform, and subsequently receives a random reward $r_{t}$ . ", "page_idx": 2}, {"type": "text", "text": "123 The assumption of general function approximation is that the reward is generated according to ", "page_idx": 3}, {"type": "equation", "text": "$$\nr_{t}=f^{*}(a_{t})+\\eta_{t},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "124 where $f^{*}$ is the ground truth objective function, and $\\eta_{t}$ is a random noise variable. We assume the   \n125 the objective function lies within a known function class $\\mathcal{F}$ . In addition, we also make the following   \n126 assumptions regarding the function class and noise variables, which are standard assumptions for   \n127 contextual bandits [Abbasi-Yadkori et al., 2011, He et al., 2022]:   \n128 Assumption 3.1. Suppose the following conditions hold for the contextual bandits environment:   \n129 \u2022 For any $f\\in\\mathcal F$ and $a\\in{\\mathcal{A}}$ , $|f(a)|\\leq1$ ; ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "130 \u2022 $\\eta_{t}$ is $R$ -sub-Gaussian conditioned on data history: $\\begin{array}{r}{\\mathbb{E}\\big[e^{\\lambda\\eta_{t}}\\big|a_{1:t},m_{1:t},r_{1:t-1}\\big]\\leq\\exp(R^{2}\\lambda^{2}/2),\\forall\\lambda.}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "131 Learning Objective. The primary goal of contextual bandits is to minimize the cumulative regret ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Reg}(T)=\\sum_{t=1}^{T}[f^{*}(a_{t})-\\operatorname*{max}_{a\\in A_{t}}f^{*}(a)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "132 Notice that this summation is across all time steps does not depend on agent participation order,   \n133 as should be the case for the resulting regret bound. To achieve this goal, agents are allowed to   \n134 communicate with the server to upload their interaction history and update their policy. The secondary   \n135 learning objective is to reduce communication overhead. We will explain the communication protocol   \n136 further in Section 3.4. ", "page_idx": 3}, {"type": "text", "text": "137 3.2 Multi-Agent Episodic MDPs with General Function Approximation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "138 We consider episodic MDPs, which are a classic family of models in reinforcement learning [Sutton   \n139 and Barto, 2018]. It is characterized by the following elements, which we assume to be homogeneous   \n114401 faucrnocstiso anlsl $\\bar{\\mathbb{P}^{\\big}}=\\ \\{\\mathbb{P}_{h}(\\cdot|\\cdot,\\cdot)\\}_{h=1}^{H}$ $\\boldsymbol{S}$ ,n da nr eawctairodn  fsupnacctei $\\boldsymbol{\\mathcal{A}}$ ,s $\\{r_{h}(\\cdot,\\cdot)\\}_{h=1}^{H})$ n.g tShi $H$ ,l atrr atnos itthioe n bparnodbita bcialistey,   \n142 for each episode $k\\,=\\,1,\\cdots\\,,K$ , a single agent $m\\,=\\,m_{k}$ is chosen to participate. An episode   \n143 $k$ begins with an initial state $s_{1}^{k}$ , which is drawn from an unknown fixed distribution. Then for   \n144 steps $h\\,=\\,1,\\cdot\\cdot\\cdot\\,,H$ , the participating agent $m$ selects an action $a_{h}^{k}$ based on the observed state   \n145 $s_{h}^{k}$ . After each action, the agent receives a reward = rh(skh, akh), where rh : S \u00d7 A \u2192R is the   \n146 reward function at step $h$ . Here for the sake of convenience, we assume the reward function to be   \n147 deterministic, but it is not difficult to generalize our result to stochastic rewards. We also assume   \n148 $r_{h}(s,a)\\in[0,1]$ for all $(s,a)\\in S\\times{\\mathcal{A}}$ without loss of generality. The environment then transitions   \n149 to the next state according to $s_{h+1}^{k}\\sim\\mathbb{P}_{h}(\\cdot|s_{h}^{k},a_{h}^{k})$ , where $\\mathbb{P}_{h}$ is the transition probability at step $h$   \n150 The episode terminates when $r_{H}$ is observed.   \n115512 be described by a set of decision functions The strategy an agent employs to interact with the environment is called the agent\u2019s policy, which can , where $\\pi_{h}:{\\mathcal{S}}\\rightarrow A$ is the decision function ", "page_idx": 3}, {"type": "text", "text": "$\\pi=\\{\\pi_{h}\\}_{h=1}^{H}$ 153 at level , mapping the current state to an action to select. ", "page_idx": 3}, {"type": "text", "text": "154 Value Functions. For any policy $\\pi=\\{\\pi_{h}\\}$ , we define $Q$ -value functions and $V$ -value functions: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\cal Q}_{h}^{\\pi}(s_{h},a_{h}):=\\mathbb{E}\\!\\left[\\sum_{h^{\\prime}=h}^{H}\\!r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})\\bigg|s_{h},a_{h}\\right],\\quad V_{h}^{\\pi}(s_{h}):=\\mathbb{E}\\!\\left[\\sum_{h^{\\prime}=h}^{H}\\!r_{h^{\\prime}}(s_{h^{\\prime}},a_{h^{\\prime}})\\bigg|s_{h}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the expectation is taken over the trajectory $\\left(\\boldsymbol{s}_{1},\\boldsymbol{a}_{1},\\cdot\\cdot\\cdot\\,,\\boldsymbol{s}_{h},\\boldsymbol{a}_{h}\\right)$ , determined by the transition probability functions $\\mathbb{P}$ and policy $\\pi$ . The optimal strategy $\\pi^{*}$ is the maximizer of the value functions: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi^{*}:=\\operatorname{argmax}_{\\pi}V_{1}^{\\pi}(s_{1}),\\forall s_{1}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "155 We also have optimal value functions $Q_{h}^{*}:=Q_{h}^{\\pi^{*}}$ and $V_{h}^{*}:=V_{h}^{\\pi^{*}}$ , which satisfy Bellman equations ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{h}^{*}(s_{h},a_{h})=r_{h}(s_{h},a_{h})+\\mathbb{E}\\bigl[V_{h+1}^{*}(s_{h+1})\\bigl|s_{h},a_{h}\\bigr],\\quad V_{h}^{*}(s_{h})=\\operatorname*{max}_{a\\in\\mathcal{A}}Q_{h}^{*}(s_{h},a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Fwuhinccht icoonn tAaipnp rreoaxl ivmalautei ofnu.nctiWoen sa pwpitrho xdiommaatien $Q$ e.  fOunnec tbiaosnisc  awsitshu mfupnticotino ins  ctlhaast $\\{\\mathcal{F}_{h}\\}_{h=1}^{H}$ ${\\mathcal{S}}\\times{\\mathcal{A}}$ $Q_{h}^{*}\\in\\mathcal{F}_{h}$ all steps $h\\in[H]$ . Now with the convention that functions at level $H+1$ are uniformly zero, i.e., $f_{H+1}=0$ , we define the Bellman operator $\\mathcal{T}_{h}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n(\\mathcal{T}_{h}f_{h+1})(s_{h},a_{h}):=\\mathbb{E}\\bigl[r_{h}(s_{h},a_{h})+f_{h+1}(s_{h+1})\\bigl|s_{h},a_{h}\\bigr],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "156 and we expect $\\mathcal{T}_{h}$ to map any function in ${\\mathcal{F}}_{h+1}$ to a function in $\\mathcal{F}_{h}$ , i.e., $T_{h}\\mathcal{F}_{h+1}\\subseteq\\mathcal{F}_{h}$ . This is   \n157 called the completeness assumption, which is a fundamental assumption in RL with general function   \n158 approximation [Wang et al., 2020b, Jin et al., 2021]. ", "page_idx": 3}, {"type": "text", "text": "Learning Objective. The primary goal in multi-agent MDPs is to minimize the cumulative regret over $K$ episodes ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Reg}(K)=\\sum_{k=1}^{K}\\bigl[V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi_{m,k}}(s_{1}^{k})\\bigr],}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "159 where $\\pi_{m,k}$ is the policy of agent $m=m_{k}$ at round $k$ , while the secondary objective is to minimize   \n160 the communication cost. ", "page_idx": 4}, {"type": "text", "text": "161 3.3 Eluder Dimension and Covering Number ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "162 To measure the complexity of the learning objective, Russo and Van Roy [2013] first proposed the   \n163 concept of Eluder dimension, which we define below.   \n164 Definition 3.2 ( $\\mathbf{\\sigma}_{\\epsilon}$ -dependence). For a function class $\\mathcal{F}$ on domain $\\mathcal{D}$ , a point $z\\in\\mathcal{D}$ is $\\epsilon$ -dependent   \n165 on $\\mathcal{Z}\\subseteq\\mathcal{D}$ if, for any $f_{1},f_{2}\\,\\in{\\mathcal{F}}$ satisfying $\\begin{array}{r}{\\sqrt{\\sum_{z^{\\prime}\\in\\mathcal{Z}}\\left(f_{1}(z^{\\prime})-f_{2}(z^{\\prime})\\right)^{2}}\\le\\epsilon.}\\end{array}$ , it must hold that   \n166 $|f_{1}(z)-f_{2}(z)|\\le\\epsilon$ . Accordingly, $z$ is $\\epsilon$ -independent of $\\mathcal{Z}$ if it is not $\\epsilon$ -dependent on $\\mathcal{Z}$ .   \n167 Definition 3.3 (Eluder dimension). The $\\epsilon$ -Eluder dimension $\\mathrm{dim}_{E}(\\mathcal{F},\\epsilon)$ is the length of the longest   \n168 sequence of elements in $\\mathcal{D}$ satisfying that, for some $\\epsilon_{0}>\\epsilon$ , each element is $\\epsilon_{0}$ -independent of the set   \n169 consisting of its predecessors.   \n170 It has been demonstrated that the Eluder dimension roughly corresponds to regular dimension   \n171 concepts in linear and quadratic cases [Russo and Van Roy, 2013], and that the Eluder family is   \n172 strictly larger than the generalized linear class [Li et al., 2022]. Note that our Eluder definition can be   \n173 applied to either the contextual bandit case with $\\mathcal{D}=\\mathcal{A}$ or the MDPs case with $\\mathcal{D}=\\mathcal{S}\\times\\mathcal{A}$ .   \n174 We also introduce covering number for function classes [Wainwright, 2019] in the following:   \n175 Definition 3.4 (Covering number). An $\\epsilon$ -cover of $\\mathcal{F}$ is any subset $\\mathcal{F}_{\\epsilon}\\subseteq\\mathcal{F}$ such that for any $f\\in\\mathcal F$ ,   \n176 there exists $f^{\\prime}\\in\\mathcal{F}_{\\epsilon}$ that $\\|f-f^{\\prime}\\|_{\\infty}\\leq\\epsilon$ . The covering number of $\\mathcal{F}$ , denoted by $N(\\mathcal{F},\\epsilon)$ , is the   \n177 minimal cardinality of its $\\epsilon$ -cover. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "178 3.4 Communication Protocol ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "179 We consider a star-shaped communication model [He et al., 2022, Min et al., 2023], where the agents   \n180 communicate through a central server to collaborate. To ensure asynchronous communication, we   \n181 mandate that all communications must be initiated by a participating agent. Specifically, at the end of   \n182 a time step / episode, the agent will decide whether or not to trigger a communication round. If so,   \n183 the agent uploads its local data history and receives some global data for future decision making. The   \n184 communication cost is the total number of communication rounds initiated by the agents.   \n185 One variability is the form of global data that the communicating agent downloads from server. It   \n186 may be tempting to have the server send all its stored trajectories to the agent for future decision   \n187 making, but this will unnecessarily expose other agents\u2019 data to the current participating agent. We   \n188 will come back to this issue and our solution in Section 4.2. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "189 4 Multi-Agent Contextual Bandits ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "190 In this section, we introduce the Asynchronous Nonlinear UCB (Async-NLin-UCB) algorithm   \n191 designed for multi-agent contextual bandits with general function approximation, and provide a   \n192 theoretical result for its regret and communication cost. ", "page_idx": 4}, {"type": "text", "text": "193 4.1 Algorithm: Async-NLin-UCB ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "194 Algorithm 1 takes as input the total number of time steps $T$ , regularization parameter $\\lambda$ , communica  \n195 tion parameter $\\alpha$ and exploration radii $\\{\\beta_{t}\\}_{t=1}^{T}$ .   \n196 In the algorithm, there are some variables that go through different versions as $t$ progresses through   \n197 $1,\\cdots,T$ . For clarity, here we give them an extra subscript $t$ to denote the version of that variable   \n198 before (not included) the least squares calculation on Line 12 at round $t$ .   \n199 Throughout the learning process, the server maintains a global history set $Z_{t}^{\\mathrm{ser}}$ that stores action  \n200 reward pairs $(a,r)\\in\\mathcal{A}\\times[0,1]$ , initialized on Line 2 and updated only during communication rounds.   \n201 Each local agent $m$ maintains a decision function $f_{m,t}$ for taking action, a bonus function $b_{m,t}$ for   \n202 checking communication criterion, and a local data history set $Z_{m,t}^{\\mathrm{loc}}$ , all initialized on Line 3. Each   \n203 step of Algorithm 1 contains two parts: local exploration and server updates.   \n204 Part I: Local Exploration. At step $t$ a single agent $m=m_{t}$ is active (Line 5). It receives a decision   \n205 set, finds the greedy action according to its decision function $f_{m,t}$ , receives a reward, and updates its ", "page_idx": 4}, {"type": "text", "text": "206 local dataset $Z_{m,t}^{\\mathrm{loc}}$ (Lines 5 - 7). ", "page_idx": 4}, {"type": "text", "text": "1: Input: total number of rounds $T$ , parameters $\\lambda,\\alpha,\\beta_{t}$ for $t=1,\\dots,T$ .   \n2: Server init: Set $Z^{\\mathrm{ser}}=\\emptyset$ .   \n3: Local init: For all $m\\in[M]$ , set $f_{m}=1$ , $b_{m}=B_{A}(\\emptyset,\\mathcal{F};\\lambda,\\beta_{0})$ and $Z_{m}^{\\mathrm{loc}}=\\emptyset$ .   \n4: for $t=1,\\dots,T$ do   \n5: Agent $m=m_{t}\\in[M]$ is active.   \n6: Receive decision set $A_{t}\\subseteq A$ and take action $a_{t}\\in\\operatorname{argmax}_{a\\in D_{t}}f_{m}(a)$ and receive reward $r_{t}$ .   \n7: Update local history $Z_{m}^{\\mathrm{loc}}=Z_{m}^{\\mathrm{loc}}\\cup\\{(a_{t},r_{t})\\}$ .   \n8: if switch condition (4) is met then   \n9: Send new data $Z_{m}^{\\mathrm{loc}}$ to server.   \n10: on server:   \n11: Update $Z^{\\mathrm{ser}}=Z^{\\mathrm{ser}}\\cup Z_{m}^{\\mathrm{loc}}$ .   \n12: Calculate $\\widehat{f}$ according to (5) and the bonus function $b=\\mathcal{B}_{A}(Z^{\\mathrm{ser}},\\mathcal{F};\\lambda,\\beta_{t})$ .   \n13: Send $\\widehat{f}+b$ and $b$ to agent $m$ .   \n14: end of s erver   \n15: Agent $m$ receives decision and bonus functions $f_{m}=\\widehat{f}+b,b_{m}=b.$ , then set $Z_{m}^{\\mathrm{loc}}=\\emptyset$ .   \n16: end if   \n17: end for ", "page_idx": 5}, {"type": "text", "text": "207 After exploration, the agent checks if the switch condition is true using its bonus function: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sum_{(a,r)\\in Z_{m,t}^{\\mathrm{loc}}}b_{m,t}^{2}(a)/\\big(\\beta_{t^{\\prime}}^{2}+\\lambda\\big)\\ge\\alpha,}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "208 where $t^{\\prime}$ is the last time step when agent $m$ communicated with the server. If so, the agent initiates a   \n209 communication round and uploads its local data (Line 9), prompting the server to begin global policy   \n210 updates. We will discuss the reasons behind this switch condition in Section 4.2.   \n211 Part II: Server Updates. After receiving a new local data history from an agent, the server merges   \n212 the data into its global dataset $Z_{t}^{\\mathrm{ser}}$ (Line 11), and calculate a function $\\widehat{f}_{t+1}\\in\\mathcal{F}$ which minimizes   \n213 the sum of squares error according to the current dataset $Z_{t}^{\\mathrm{ser}}$ (Line 12): ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{f}_{t+1}=\\operatorname*{argmin}_{f\\in\\mathcal{F}}\\sum_{(a,r)\\in Z_{t}^{\\operatorname*{ser}}}\\bigl(f(a)-r\\bigr)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "214 The next step is to obtain a bonus function $b_{t+1}$ from the oracle $B_{A}$ from Definition 4.1 (Line ??).   \n215 We discuss the specifics of this construction in detail up next in Section 4.2. Finally, the server sends   \n216 the optimistic value function $\\widehat{f}_{t+1}+b_{t+1}$ and the bonus function $b_{t+1}$ back to agent $m$ for future   \n217 exploration and updates; agent $m$ also resets its local data history to an empty set (Lines 13 and 15). ", "page_idx": 5}, {"type": "text", "text": "218 4.2 Uncertainty Estimators and Bonus Functions ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "219 In this section, we introduce uncertainty estimators and bonus functions, and give a detailed explana  \n220 tion for our communication criterion (4). Most of these apply to the MDPs setting as well.   \n221 Uncertainty Estimators. First we define the uncertainty estimator of new data $a$ against data history   \n222 $Z$ , which is considered in many works on bandits and RL with general function approximation   \n223 [Gentile et al., 2022, Agarwal et al., 2023]: ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{D_{\\lambda,\\mathcal{F}}(a;Z)=\\operatorname*{sup}_{f_{1},f_{2}\\in\\mathcal{F}}|f_{1}(a)-f_{2}(a)|/\\sqrt{\\lambda+\\sum_{(a^{\\prime},r)\\in Z}|f_{1}(a^{\\prime})-f_{2}(a^{\\prime})|^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "224 here $\\lambda$ is the regularization parameter, $\\mathcal{F}$ is a function class. Intuitively, the uncertainty estimator   \n225 measures the difference between functions on new data $a$ against the difference on historical data $Z$   \n226 Switch Condition Based On Uncertainty Estimators. The determinant-based criterion is a   \n227 common technique used in contextual bandits and RL with linear function approximation to reduce   \n228 policy switching or communication cost [Abbasi-Yadkori et al., 2011]. For nonlinear function   \n229 approximation, one can use uncertainty estimators to formulate a new form of switch condition: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sum_{(a,r)\\in Z_{t}^{\\mathrm{new}}}D_{\\lambda,\\mathcal{F}}^{2}(a;Z_{t}^{\\mathrm{old}})\\geq\\alpha.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "230 where we use $Z_{t}^{\\mathrm{new}}$ and $Z_{t}^{\\mathrm{old}}$ to denote newly accumulated data and old historical data. This criterion   \n231 has a similar function as the determinant-based criterion in linear settings. Parameter $\\alpha$ controls   \n232 communication frequency: smaller $\\alpha$ indicates more frequent communication, more accurate decision   \n233 functions and smaller regret, thus implying a trade-off between regret and communication cost.   \n234 Bonus Function Oracle. Next, we introduce bonus functions obtained through oracles that   \n235 approximate the uncertainty estimators.   \n236 Definition 4.1 (Bonus Function Oracle $\\scriptstyle B_{D}$ ). Given domain $\\mathcal{D}$ , the oracle $B_{\\cal D}(Z,{\\mathcal F};\\lambda,\\beta)$ takes the   \n237 following as inputs: a dataset $Z$ consisting of a series of data points $(z,e)$ , where $z\\in\\mathcal{D}$ and $e$ is some   \n238 additional data content; function class $\\mathcal{F}$ with functions $f:\\mathcal{D}\\to\\mathbb{R}_{\\geq0}$ ; regularization parameter $\\lambda$   \n239 and exploration radius $\\beta$ . It returns a function $b\\in\\mathcal{W}_{\\mathcal{D}}:\\mathcal{D}\\to\\mathbb{R}_{\\geq0}$ satisfying for any $z\\in\\mathcal{D}$ that ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{b(z)\\geq\\operatorname*{max}\\Big\\{\\big|f_{1}(z)-f_{2}(z)\\big|:f_{1},f_{2}\\in\\mathcal{F},\\sum_{(z,e)\\in\\cal Z}\\big(f_{1}(z)-f_{2}(z)\\big)^{2}\\leq\\beta^{2}\\Big\\};}\\\\ &{D_{\\lambda,\\mathcal{F}}(z;\\cal{Z})\\leq b(z)/\\sqrt{\\beta^{2}+\\lambda}\\leq C_{8}D_{\\lambda,\\mathcal{F}}(z;\\cal{Z}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "242 where $C_{B}$ is an absolute constant. ", "page_idx": 6}, {"type": "text", "text": "243 Remark 4.2. Similar bonus function oracles have been proposed in previous works (Definition 3   \n244 in Agarwal et al. [2023]). The accessibility of these oracles is also supported by previous works   \n245 that proposed methods to compute bonus functions [Kong et al., 2023, Wang et al., 2020b]. In this   \n246 definition, we leave the domain and data format to be variable so the oracle can be applied to both   \n247 contextual bandits and MDPs. For bandits, the domain is $\\boldsymbol{\\mathcal{A}}$ , and the data format has $z=a$ and $e=r$ .   \n248 The first property of the bonus function guarantees the optimism of decision functions $\\widehat{f}_{t+1}+b_{t+1}$   \n249 (see Lemma 6.1 for MDPs or Lemma A.2 for bandits), while the second property links bonuses to   \n250 uncertainty estimators.   \n251 Switch Condition Based On Bonus Functions. If we try to adapt the switch condition (7) in our   \n252 setting, a local agent will require access to historical data $Z_{t}^{\\mathrm{old}}$ to calculate uncertainty estimators   \n253 $D_{\\lambda,\\mathcal{F}}^{2}\\bar{(}a;Z_{t}^{\\mathrm{old}})$ . For multi-agent learning, this dataset consists of the collective data from all agents,   \n254 and giving local agent access is a clear violation of data privacy. Our solution is to let local agents   \n255 download bonus functions and set communication criterion to (4), using bonus functions instead of   \n256 uncertainty estimators.   \n257 Decision Functions Based On Bonus Functions. Another benefti of introducing the bonus function   \n258 is evident from our exploration method in line 6. A common practice for nonlinear RL algorithms is   \n259 to construct confidence sets of functions during policy update, and find the optimal function within the   \n260 confidence sets during exploration [Agarwal et al., 2023, Ye et al., 2023]. However, in a multi-agent   \n261 setting, this would involve the download of confidence sets, which is impractical due to the complex   \n262 nature of function classes. With the bonus function, local agents need only download the decision   \n263 function from the server for future exploration, which for contextual bandits is simply $\\widehat{f}_{t+1}+b_{t+1}$ . ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "264 4.3 Theoretical Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "265 Our main results for Algorithm 1 are summarized in the following theorem, which provides a regret   \n266 upper bound and communication complexity order.   \n267 Theorem 4.3\u221a. By taking\u221a $\\gamma\\,=\\,O(1/T)$ , $\\beta_{t}\\,=\\,C_{\\beta,1}\\bigl(\\sqrt{\\lambda}+R C(M,\\alpha)\\log(3M N(\\mathcal{F},\\gamma)/\\delta)\\bigr)$ and   \n268 $C(M,\\alpha)=\\sqrt{1+M\\alpha}\\big(\\sqrt{1+M\\alpha}+M\\sqrt{\\alpha}\\big)$ , the regret of Algorithm $^{\\,I}$ within $T$ rounds is ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\nO\\Big(\\sqrt{T}\\widetilde{\\beta}_{1}\\sqrt{(1+M\\alpha)\\dim_{E}}\\log(T/\\operatorname*{min}\\{1,\\lambda\\})+(1+M\\alpha)\\dim_{E}\\log^{2}(T/\\operatorname*{min}\\{1,\\lambda\\})\\Big),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "269 where we abbreviate $\\dim_{E}:=\\dim_{E}({\\mathcal{F}},\\lambda/T).$ ; the total communication complexity is ", "page_idx": 6}, {"type": "equation", "text": "$$\nO\\Big((1+M\\alpha)^{2}/\\alpha\\dim_{E}\\log^{2}(T/\\operatorname*{min}\\{1,\\lambda\\})\\Big)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "270 Remark 4.4. When reduced to linear contextual bandits, where $\\dim_{E}({\\mathcal F},\\lambda/T)\\ =\\ {\\widetilde O}(d)$ and   \n271 $\\log N(\\mathcal{F},\\gamma)=\\widetilde{O}(d)$ , our result on regret correspond exactly to Theorem 5.1 of He et al. [2022],   \n272 except for an extra $1+M\\alpha$ term in the communication cost, an unimportant term when taking   \n273 $\\alpha=1/M^{2}$ that comes from the complication of communication cost analysis in nonlinear settings. ", "page_idx": 6}, {"type": "text", "text": "274 5 Multi-Agent Reinforcement Learning ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "275 In this section, we introduce the Asynchronous Nonlinear Least Squares Value Iteration UCB   \n276 (Async-NLin-UCB) algorithm for multi-agent MDPs with general function approximation, and a   \n277 corresponding theoretical result. ", "page_idx": 6}, {"type": "text", "text": "278 5.1 Algorithm: Async-NLSVI-UCB ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "279 To better represent the elements in the datasets, we sometimes use $o_{h}$ to represent the tuple   \n280 $(s_{h},a_{h},r_{h},s_{h+1})$ and $z_{h}$ to represent $(s_{h},a_{h})$ when there is no confusion. Similar to the ban  \n281 dit case, we give some variables an extra subscript $k$ here for clarity, which denotes the version of the   \n282 variable before (not included) Line 14 at episode $k$ .   \n1: Input: total number of rounds $K$ , parameters $\\lambda$ , $\\alpha$ , $\\beta_{k,h}$ for $k=[K]$ and $h\\in[H]$   \n2: Server init: Set $Z_{h}^{\\mathrm{ser}}=\\mathcal{D}$ for all $h\\in[H]$ .   \n3: Local init: $\\forall m\\in[M]$ and $h\\in[H]$ , set $Q_{m,h}=1$ , $b_{m,h}=\\mathcal{B}(\\emptyset,\\mathcal{F}_{h};\\lambda,\\beta_{0,h}),\\,Z_{m,h}^{\\mathrm{loc}}=\\emptyset.$ .   \n4: for $k=1,\\ldots,K$ do   \n5: Agent $m=m_{k}\\in[M]$ is active and receives initial state $s_{1}^{k}\\in\\mathcal{S}$ .   \n67:: forT $h=1,\\ldots,H$ $a_{h}^{k}=\\operatorname{argmax}_{a\\in\\mathcal{A}}Q_{m,h}(s_{h}^{k},a)$ , receive reward $r_{h}^{k}$ and next state $s_{h+1}^{k}$ .   \n8: Update $Z_{m,h}^{\\mathrm{loc}}=Z_{m,h}^{\\mathrm{loc}}\\cup\\{(s_{h}^{k},a_{h}^{k},r_{h}^{k},s_{h+1}^{k})\\}$ .   \n9: end for   \n10: if switch condition (8) is met then   \n11: Send new data $\\{Z_{m,h}^{\\mathrm{loc}}\\}_{h\\in[H]}$ to server.   \n1123:: on Useprdvaeter : $Z_{h}^{\\mathrm{ser}}=Z_{h}^{\\mathrm{ser}}\\cup Z_{m,h}^{\\mathrm{loc}}$ .   \n14: Initialize $Q_{H+1}=V_{H+1}=0$ .   \n15: for $h=H,H-1,\\cdots\\,,1$ do   \n16: Calculate $\\widehat{f_{h}}$ according to (9) and bonus function $b_{h}=\\mathcal{B}_{S\\times A}(Z_{h}^{\\mathrm{ser}},\\mathcal{F}_{h};\\lambda,\\beta_{k,h})$ .   \n17: Calculate $Q_{h}$ and $V_{h}$ according to (11).   \n18: end for   \n19: Send {Qh}hH=1 and {bh}hH=1 to agent m.   \n20:   \n21: Agent $m$ receives $Q_{m,h}=Q_{h}$ , $b_{m,h}=b_{h}$ and resets $Z_{m,h}^{\\mathrm{loc}}=\\emptyset$ for all $h\\in[H]$ .   \n22: end if   \n23: end for   \n283 The server maintains global historical datasets $Z_{k,h}^{\\mathrm{ser}}$ containing sequences of tuples $\\left(s_{h},a_{h},r_{h},s_{h+1}\\right)$ ,   \n284 initialized in Line 2. Each local agent $m$ maintains optimistic value functions $\\{Q_{m,k,h}\\}_{h=1}^{H}$ , bonus   \n285 functions $\\{b_{m,k,h}\\}_{h=1}^{H}$ , and local datasets $\\{Z_{m,k,h}^{\\mathrm{loc}}\\}_{h=1}^{H}$ , all initialized in Line 3.   \n286 Each episode $k$ of Algorithm 2 also consists of the two parts local exploration and server updates.   \n287 Part I: Local Exploration. At step $k$ an agent $m\\;=\\;m_{k}$ is active (Line 5). It interacts with   \n228889 ,c uwtihnigc ht hise  tghreene dstyo rpeodl iicnyt oa tchceo rldoicnagl  thios $\\{Q_{m,k,h}\\}_{h=1}^{H}$ ,s n (gl ian etrs a6j e-c t9o)r.y   \n$\\{(s_{h}^{k},a_{h}^{k},r_{h}^{k},s_{h+1}^{k})\\}_{h=1}^{H}$   \n290 After exploration, the agent checks for the following switch condition: there exists $h\\in[H]$ so that ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sum_{o_{h}\\in Z_{m,k,h}^{\\mathrm{loc}}}b_{m,k,h}^{2}(s_{h},a_{h})/\\big(\\beta_{k^{\\prime},h}^{2}+\\lambda\\big)\\ge\\alpha,}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "291 where $k^{\\prime}$ is the last communication round for $m$ . If so, the agent triggers communication (Line 11).   \n292 Part II: Server Updates. After receiving new data, the server merges it with its global datasets $Z_{k,h}^{\\mathrm{ser}}$   \n293 (Line 13) and calculates value function estimates $\\{Q_{k+1,h}\\}_{h=1}^{H}$ and $\\{V_{k+1,h}\\}_{h=1}^{H}$ using LSVI.   \n294 Suppose we already have $Q.$ - and $V$ -value function estimates $Q_{k+1,h+1}$ and $V_{k+1,h+1}$ at level $h+1$ .   \n295 We solve the least squares problem for $\\widehat{f}_{h}$ to minimize the Bellman error (Line 16): ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{f}_{k+1,h}=\\operatorname*{argmin}_{f_{h}\\in\\mathcal{F}_{h}}\\sum_{o_{h}\\in Z_{k,h}^{\\mathrm{sc}}}\\big(f_{h}(z_{h})-r_{h}-V_{k+1,h+1}(s_{h+1})\\big)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "296 We now also define the uncertainty estimator of a new pair of data $z=(s,a)$ against data history $Z$   \n297 with normalization parameter $\\lambda$ and function class $\\mathcal{F}$ as ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{D_{\\lambda,\\mathcal{F}}(z;Z)=\\operatorname*{sup}_{f_{1},f_{2}\\in\\mathcal{F}}|f_{1}(z)-f_{2}(z)|/\\sqrt{\\lambda+\\sum_{\\sigma^{\\prime}\\in Z}|f_{1}(z^{\\prime})-f_{2}(z^{\\prime})|^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "298 Similar to the bandits setting, the uncertainty can be approximated with the bonus function acquired   \n299 from an oracle $B_{S\\times A}$ in Definition 4.1. In this case, the domain $\\mathcal{D}=\\mathcal{S}\\times\\mathcal{A}$ , and the data format   \n300 corresponds to $z=(s,a)$ and $e=\\left(\\boldsymbol{r},\\boldsymbol{s}^{\\prime}\\right)$ . Despite these definitions not depending on the step $h$ , we   \n301 expect the parameters $z,Z,{\\mathcal{F}}$ to always come from same step $h$ . Finally, we allow the bonus function   \n302 classes $\\mathcal{W}_{h}=\\mathcal{W}_{h,S\\times A}$ to vary between different levels.   \n303 After calling oracle for $b_{k+1,h}$ (Line 16), we can obtain value function estimates (Line 17): ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{k+1,h}(s,a)=\\widehat{f}_{k+1,h}(s,a)+b_{k+1,h}(s,a),\\quad V_{k+1,h}(s)=\\operatorname*{sup}_{a\\in\\mathcal{A}}Q_{k+1,h}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "304 Iterating through $\\textit{h}=\\textit{H},\\cdot\\cdot\\cdot,1$ , the server calculates a set of updated $Q$ -value functions   \n305 {Qk+1,h}hH=1 and bonus functions $\\{b_{k+1,h}\\}_{h=1}^{H}$ , and send them back to agent $m$ for future ex  \n306 ploration and updates (lines 19 and 21). ", "page_idx": 7}, {"type": "text", "text": "307 5.2 Theoretical Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "308 We summarize the regret and communication cost of Algorithm 2 in the following theorem: ", "page_idx": 8}, {"type": "text", "text": "309 Theorem 5.1. Taking $\\gamma=O(1/H K)$ , $\\beta_{h,k}=C_{\\beta,2}\\Bigl[\\sqrt{\\lambda}+H C(M,\\alpha)\\sqrt{\\log(3H M N(\\gamma)/\\delta)}\\Bigr]$ and   \n310 $\\begin{array}{r}{N(\\gamma):=\\operatorname*{max}_{h}N(\\mathcal{F}_{h},\\gamma)N(\\mathcal{F}_{h+1},\\gamma)N(\\mathcal{W}_{h+1},\\gamma}\\end{array}$ ), the regret within $K$ rounds is bounded by ${\\cal O}\\Big(H\\widetilde{\\beta}_{2}\\sqrt{(1+M\\alpha)\\dim_{E}K}\\log(K/\\operatorname*{min}\\{1,\\lambda\\})+H^{2}(1+M\\alpha)\\dim_{E}\\log^{2}(K/\\operatorname*{min}\\{1,\\lambda\\})\\Big).$ where we abbreviate $\\dim_{E}:=\\dim_{E}(\\mathcal{F},\\lambda/K)$ ; the total communication complexity is ", "page_idx": 8}, {"type": "text", "text": "$O\\big(H(1+M\\alpha)^{2}\\alpha\\dim_{E}(\\mathcal{F},\\lambda/K)\\log^{2}(K/\\operatorname*{min}\\{1,\\lambda\\})\\big).$ . ", "page_idx": 8}, {"type": "text", "text": "311 Remark 5.2. This result when reduced to linear MDPs correspond well to Theorem 5.1 in Min   \n312 et al. [2023]. Taking $\\alpha=1/M^{2}$ , we get a regret of $\\widetilde{\\cal O}\\big(H^{2}\\sqrt{K\\dim_{E}\\log N}+H^{2}\\dim_{E}\\big)$ and a   \n313 communication cost of $\\widetilde{\\cal O}\\big(H M^{2}\\,\\mathrm{dim}_{E}\\,\\big)$ , where $N=\\operatorname*{max}_{h}\\{N(\\mathcal{F}_{h},\\gamma),N(\\mathcal{W}_{h},\\gamma)\\}$ . ", "page_idx": 8}, {"type": "text", "text": "314 6 Proof Sketch ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "315 In this section, we provide an outline for the proof of Theorem 5.1, while a more detailed proof can   \n316 be found in Appendix B, and the full versions of the following lemmas are in Appendix B.1. ", "page_idx": 8}, {"type": "text", "text": "317 6.1 Regret Upper Bound ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "318 For the regret upper bound, the first lemma establishes optimism of value function estimates. ", "page_idx": 8}, {"type": "text", "text": "319 Lemma 6.1. Taking $\\beta_{k,h}$ as in Theorem 5.1, with probability at least $1-\\delta,$ , for all $k$ , $z\\in{\\mathcal{S}}\\times{\\mathcal{A}}$ and   \n320 $h\\in[H],|\\mathcal{T}_{h}Q_{k+1,h+1}(z)-\\widehat{f}_{k+1,h}(z)|\\leq b_{k+1,h}(z).$   \n321 This allows us to decompose regret into a sum of bonuses: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathrm{Reg}(K)=\\sum_{k=1}^{K}\\bigl[V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi_{m,k}}(s_{1}^{k})\\bigr]}\\\\ &{\\leq\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi_{m,k}}\\bigl[Q_{m,k,h}-\\mathcal{T}_{h}Q_{m,k,h+1}\\bigr](s_{h}^{k},a_{h}^{k})\\leq\\sum_{k=1}^{K}\\!\\sum_{h=1}^{H}\\!2b_{m,k,h}\\bigl(s_{h}^{k},a_{h}^{k}\\bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "322 The sum of bonuses is equal to the sum of uncertainty up to a constant, which we bound in the   \n323 following lemma corresponding to the elliptical potential lemma [Abbasi-Yadkori et al., 2011]. ", "page_idx": 8}, {"type": "text", "text": "$Z_{k,h}^{a l l}=\\{o_{h}^{k^{\\prime}}\\}_{k^{\\prime}\\in[k]}$ $h\\in[H]$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sum_{k=1}^{K}D_{\\lambda,\\mathcal{F}}^{2}(z_{h}^{k};Z_{k-1,h}^{a l l})=O\\big(\\dim_{E}(\\mathcal{F},\\lambda/K)\\log^{2}(K/\\operatorname*{min}\\{1,\\lambda\\})\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "325 Careful examination exposes a problem: the uncertainty $D_{\\lambda,\\mathcal{F}}(z;Z_{k,h}^{\\mathrm{ser}})$ corresponding to bonuses are   \n326 based on server data $Z_{k,h}^{\\mathrm{ser}}$ instead of universal data $Z_{k,h}^{\\mathrm{all}}$ . The next lemma bridges this gap:   \n327 Lemma 6.3. For any $z\\in S\\times A,\\,k\\in[K],\\,h\\in[H],\\,D_{\\lambda,\\mathcal{F}}^{2}(z;Z_{k,h}^{s e r})\\leq(1+M\\alpha)D_{\\lambda,\\mathcal{F}}^{2}(z;Z_{k,h}^{a l l}).$   \n328 With these, we can deduce the regret bound from (12). ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "329 6.2 Communication Cost ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "330 For communication cost, we employ an epoch segmentation scheme, which defines $N$ epochs   \n331 segmented by episodes $\\{k_{i}\\}_{i=1}^{N}$ , with $k_{i}$ being the smallest episode satisfying ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sum_{o_{h}\\in Z_{k_{i},h}^{\\mathrm{ser}}\\setminus Z_{k_{i-1},h}^{\\mathrm{ser}}}\\sum_{h=1}^{H}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h};Z_{k_{i-1},h}^{\\mathrm{ser}}\\big)\\ge1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "332 This is a generalization of epoch segmentation based on doubling determinants in linear settings, yet   \n333 the lack of determinant in the nonlinear case dramatically increases its complexity. Intuitively, switch   \n334 condition (8) suggests an agent must gather a substantial amount of data to trigger communication,   \n335 yet a careful analysis according to (13) yields a maximum of $M+C/\\alpha$ communication rounds within   \n336 one epoch. With this we only need an upper bound for the number of epochs $N$ . This is derived by   \n337 summing (13) over all epochs, then using Lemma 6.1 and Lemma 6.3 to bound the left hand side. ", "page_idx": 8}, {"type": "text", "text": "338 7 Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "339 We propose the algorithms Async-NLin-UCB and Async-NLSVI-UCB to tackle multi-agent nonlinear   \n340 contextual bandits and MDPs with asynchronous communication. We prove that our algorithms enjoy   \n341 low regret and communication cost, which are comparable to previous results.   \n342 Our algorithms employ a communication criterion that allows the agents to trigger communication   \n343 rounds, effectively controlling communication cost while promoting the asynchronous protocol.   \n344 Moreover, we carefully design the contents of server download to guard against data exposure. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "345 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "346 Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits.   \n347 Advances in neural information processing systems, 24:2312\u20132320, 2011.   \n348 Alekh Agarwal and Tong Zhang. Model-based RL with optimistic posterior sampling: Structural conditions   \n349 and sample complexity. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors,   \n350 Advances in Neural Information Processing Systems, 2022.   \n351 Alekh Agarwal, Yujia Jin, and Tong Zhang. Voql: Towards optimal regret in model-free rl with nonlinear function   \n352 approximation. In Gergely Neu and Lorenzo Rosasco, editors, Proceedings of Thirty Sixth Conference on   \n353 Learning Theory, volume 195 of Proceedings of Machine Learning Research, pages 987\u20131063. PMLR, 12\u201315   \n354 Jul 2023.   \n355 Ana LC Bazzan. Opportunities for multiagent systems and multiagent reinforcement learning in traffic control.   \n356 Autonomous Agents and Multi-Agent Systems, 18(3):342\u2013375, 2009.   \n357 Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemys\u0142aw D\u02dbebiak, Christy Dennison,   \n358 David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, Rafal J\u00f3zefowicz, Scott Gray, Catherine Olsson,   \n359 Jakub Pachocki, Michael Petrov, Henrique P. d. O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter,   \n360 Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan Zhang. Dota 2 with large   \n361 scale deep reinforcement learning. arXiv preprint arXiv:1912.06680, 2019.   \n362 Mithun Chakraborty, Kee Yuan Peh Chua, Sanmay Das, and Brendan Juba. Coordinated versus decentralized   \n363 exploration in multi-agent multi-armed bandits. In IJCAI, 2017.   \n364 Alfredo V Clemente, Humberto N Castej\u00f3n, and Arjun Chandra. Efficient parallel methods for deep reinforce  \n365 ment learning. arXiv preprint arXiv:1705.04862, 2017.   \n366 Qiwei Di, Heyang Zhao, Jiafan He, and Quanquan Gu. Pessimistic nonlinear least-squares value iteration for   \n367 offline reinforcement learning. arXiv preprint arXiv:2310.01380, 2023.   \n368 Guohui Ding, Joewie J Koh, Kelly Merckaert, Bram Vanderborght, Marco M Nicotra, Christoffer Heckman,   \n369 Alessandro Roncone, and Lijun Chen. Distributed reinforcement learning for cooperative multi-robot object   \n370 manipulation. In Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent   \n371 Systems, pages 1831\u20131833, 2020.   \n372 Simon Du, Sham Kakade, Jason Lee, Shachar Lovett, Gaurav Mahajan, Wen Sun, and Ruosong Wang. Bilinear   \n373 classes: A structural framework for provable generalization in rl. In Marina Meila and Tong Zhang, editors,   \n374 Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of   \n375 Machine Learning Research, pages 2826\u20132836. PMLR, 18\u201324 Jul 2021.   \n376 Abhimanyu Dubey and Alex Pentland. Provably efficient cooperative multi-agent reinforcement learning with   \n377 function approximation. arXiv preprint arXiv:2103.04972, 2021.   \n378 Abhimanyu Dubey and AlexSandy\u2019 Pentland. Differentially-private federated linear bandits. Advances in Neural   \n379 Information Processing Systems, 33:6003\u20136014, 2020.   \n380 Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Vlad Mnih, Tom Ward, Yotam Doron, Vlad   \n381 Firoiu, Tim Harley, Iain Dunning, et al. Impala: Scalable distributed deep-rl with importance weighted   \n382 actor-learner architectures. In International conference on machine learning, pages 1407\u20131416. PMLR, 2018.   \n383 Dylan J. Foster, Sham M. Kakade, Jian Qian, and Alexander Rakhlin. The statistical complexity of interactive   \n384 decision making, 2023.   \n385 Claudio Gentile, Zhilei Wang, and Tong Zhang. Fast rates in pool-based batch active learning, 2022.   \n386 Jiafan He, Tianhao Wang, Yifei Min, and Quanquan Gu. A simple and provably efficient algorithm for   \n387 asynchronous federated contextual linear bandits. In Advances in Neural Information Processing Systems,   \n388 2022.   \n389 Dan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo Hessel, Hado van Hasselt, and David   \n390 Silver. Distributed prioritized experience replay. In International Conference on Learning Representations,   \n391 2018.   \n392 Ruiquan Huang, Weiqiang Wu, Jing Yang, and Cong Shen. Federated linear contextual bandits. In A. Beygelz  \n393 imer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing   \n394 Systems, 2021.   \n395 Max Jaderberg, Wojciech M Czarnecki, Iain Dunning, Luke Marris, Guy Lever, Antonio Garcia Castaneda,   \n396 Charles Beattie, Neil C Rabinowitz, Ari S Morcos, Avraham Ruderman, et al. Human-level performance in   \n397 3d multiplayer games with population-based reinforcement learning. Science, 364(6443):859\u2013865, 2019.   \n398 Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Robert E. Schapire. Contextual decision   \n399 processes with low Bellman rank are PAC-learnable. In Doina Precup and Yee Whye Teh, editors, Proceedings   \n400 of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning   \n401 Research, pages 1704\u20131713. PMLR, 06\u201311 Aug 2017.   \n402 Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael I Jordan. Provably efficient reinforcement learning with   \n403 linear function approximation. In Conference on Learning Theory, pages 2137\u20132143. PMLR, 2020.   \n404 Chi Jin, Qinghua Liu, and Sobhan Miryoosef.i Bellman eluder dimension: New rich classes of RL problems,   \n405 and sample-efficient algorithms. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors,   \n406 Advances in Neural Information Processing Systems, 2021.   \n407 Hao Jin, Yang Peng, Wenhao Yang, Shusen Wang, and Zhihua Zhang. Federated reinforcement learning with   \n408 environment heterogeneity. In International Conference on Artificial Intelligence and Statistics, pages 18\u201337.   \n409 PMLR, 2022.   \n410 Dingwen Kong, Ruslan Salakhutdinov, Ruosong Wang, and Lin F. Yang. Online sub-sampling for reinforcement   \n411 learning with general function approximation, 2023.   \n412 Nathan Korda, Bal\u00e1zs Sz\u00f6r\u00e9nyi, and Shuai Li. Distributed clustering of linear bandits in peer to peer networks.   \n413 In Proceedings of the 33rd International Conference on International Conference on Machine Learning -   \n414 Volume 48, ICML\u201916, page 1301\u20131309. JMLR.org, 2016.   \n415 Jakub Grudzien Kuba, Ruiqing Chen, Muning Wen, Ying Wen, Fanglei Sun, Jun Wang, and Yaodong Yang. Trust   \n416 region policy optimisation in multi-agent reinforcement learning. In International Conference on Learning   \n417 Representations, 2022.   \n418 Peter Landgren, Vaibhav Srivastava, and Naomi Ehrich Leonard. On distributed cooperative decision-making in   \n419 multiarmed bandits. In 2016 European Control Conference (ECC), pages 243\u2013248, 2016.   \n420 Peter Landgren, Vaibhav Srivastava, and Naomi Ehrich Leonard. Social imitation in cooperative multiarmed   \n421 bandits: Partition-based algorithms with strictly local information. In 2018 IEEE Conference on Decision and   \n422 Control (CDC), 2018.   \n423 Chuanhao Li and Hongning Wang. Asynchronous upper confidence bound algorithms for federated linear   \n424 bandits. In International Conference on Artificial Intelligence and Statistics, pages 6529\u20136553. PMLR, 2022.   \n425 Gene Li, Pritish Kamath, Dylan J Foster, and Nati Srebro. Understanding the eluder dimension. In S. Koyejo,   \n426 S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information   \n427 Processing Systems, volume 35, pages 23737\u201323750. Curran Associates, Inc., 2022.   \n428 Boyi Liu, Lujia Wang, and Ming Liu. Lifelong federated reinforcement learning: a learning architecture for   \n429 navigation in cloud robotic systems. IEEE Robotics and Automation Letters, 4(4):4555\u20134562, 2019.   \n430 Dianbo Liu, Vedant Shah, Oussama Boussif, Cristian Meo, Anirudh Goyal, Tianmin Shu, Michael Mozer,   \n431 Nicolas Heess, and Yoshua Bengio. Stateful active facilitator: Coordination and environmental heterogeneity   \n432 in cooperative multi-agent reinforcement learning. arXiv preprint arXiv:2210.03022, 2022.   \n433 Dongfang Liu, Yiming Cui, Zhiwen Cao, and Yingjie Chen. Indoor navigation for mobile agents: A multimodal   \n434 vision fusion model. In 2020 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138. IEEE,   \n435 2020.   \n436 Keqin Liu and Qing Zhao. Distributed learning in multi-armed bandit with multiple players. IEEE Transactions   \n437 on Signal Processing, 58(11):5667\u20135681, 2010. doi: 10.1109/TSP.2010.2062509.   \n438 Ryan Lowe, Yi I Wu, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and Igor Mordatch. Multi-agent actor-critic   \n439 for mixed cooperative-competitive environments. Advances in neural information processing systems, 30,   \n440 2017.   \n441 David Mart\u00ednez-Rubio, Varun Kanade, and Patrick Rebeschini. Decentralized cooperative stochastic bandits.   \n442 In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in   \n443 Neural Information Processing Systems. Curran Associates, Inc., 2019.   \n444 Yifei Min, Tianhao Wang, Ruitu Xu, Zhaoran Wang, Michael Jordan, and Zhuoran Yang. Learn to match with no   \n445 regret: Reinforcement learning in markov matching markets. In Advances in Neural Information Processing   \n446 Systems, 2022.   \n447 Yifei Min, Jiafan He, Tianhao Wang, and Quanquan Gu. Cooperative multi-agent reinforcement learning:   \n448 Asynchronous communication and linear function approximation. In Andreas Krause, Emma Brunskill,   \n449 Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th   \n450 International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research,   \n451 pages 24785\u201324811. PMLR, 23\u201329 Jul 2023.   \n452 Seongin Na, Tom\u00e1\u0161 Rou\u02c7cek, Ji\u02c7r\u00ed Ulrich, Jan Pikman, Tom\u00e1\u0161 Krajn\u00edk, Barry Lennox, and Farshad Arvin.   \n453 Federated reinforcement learning for collective navigation of robotic swarms, 2022.   \n454 Arun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas Alcicek, Rory Fearon, Alessandro De Maria, Vedavyas   \n455 Panneershelvam, Mustafa Suleyman, Charles Beattie, Stig Petersen, et al. Massively parallel methods for   \n456 deep reinforcement learning. arXiv preprint arXiv:1507.04296, 2015.   \n457 Jiaju Qi, Qihao Zhou, Lei Lei, and Kan Zheng. Federated reinforcement learning: techniques, applications, and   \n458 open challenges. arXiv preprint arXiv:2108.11887, 2021.   \n459 Daniel Russo and Benjamin Van Roy. Eluder dimension and the sample complexity of optimistic exploration.   \n460 In C.J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural   \n461 Information Processing Systems, volume 26. Curran Associates, Inc., 2013.   \n462 Abishek Sankararaman, Ayalvadi Ganesh, and Sanjay Shakkottai. Social learning in multi agent multi armed   \n463 bandits. Proc. ACM Meas. Anal. Comput. Syst., 3(3), 2019.   \n464 Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.   \n465 Balazs Szorenyi, Robert Busa-Fekete, Istvan Hegedus, Robert Ormandi, Mark Jelasity, and Balazs Kegl. Gossip  \n466 based distributed stochastic bandit algorithms. In Proceedings of the 30th International Conference on   \n467 Machine Learning, 2013.   \n468 Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo,   \n469 Alireza Makhzani, Heinrich K\u00fcttler, John Agapiou, Julian Schrittwieser, et al. Starcraft ii: A new challenge   \n470 for reinforcement learning. arXiv preprint arXiv:1708.04782, 2017.   \n471 Hoi-To Wai, Zhuoran Yang, Zhaoran Wang, and Mingyi Hong. Multi-agent reinforcement learning via double   \n472 averaging primal-dual optimization. Advances in Neural Information Processing Systems, 31, 2018.   \n473 Martin Wainwright. High-Dimensional Statistics: A Non-Asymptotic Viewpoint. 02 2019. ISBN 9781108498029.   \n474 Po-An Wang, Alexandre Proutiere, Kaito Ariu, Yassir Jedra, and Alessio Russo. Optimal algorithms for   \n475 multiplayer multi-armed bandits. In Silvia Chiappa and Roberto Calandra, editors, Proceedings of the Twenty   \n476 Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine   \n477 Learning Research, pages 4120\u20134129. PMLR, 26\u201328 Aug 2020a.   \n478 Ruosong Wang, Russ R Salakhutdinov, and Lin Yang. Reinforcement learning with general value function   \n479 approximation: Provably efficient approach via bounded eluder dimension. In H. Larochelle, M. Ranzato,   \n480 R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33,   \n481 pages 6123\u20136135. Curran Associates, Inc., 2020b.   \n482 Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, and Liwei Wang. Distributed bandit learning: Near-optimal regret   \n483 with efficient communication. In International Conference on Learning Representations, 2020c.   \n484 Grady Williams, Paul Drews, Brian Goldfain, James M Rehg, and Evangelos A Theodorou. Aggressive   \n485 driving with model predictive path integral control. In 2016 IEEE International Conference on Robotics and   \n486 Automation (ICRA), pages 1433\u20131440. IEEE, 2016.   \n487 Ruitu Xu, Yifei Min, Tianhao Wang, Michael I Jordan, Zhaoran Wang, and Zhuoran Yang. Finding regular  \n488 ized competitive equilibria of heterogeneous agent macroeconomic models via reinforcement learning. In   \n489 International Conference on Artificial Intelligence and Statistics, pages 375\u2013407. PMLR, 2023.   \n490 Chenlu Ye, Wei Xiong, Quanquan Gu, and Tong Zhang. Corruption-robust algorithms with uncertainty   \n491 weighting for nonlinear contextual bandits and Markov decision processes. In Andreas Krause, Emma   \n492 Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of   \n493 the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning   \n494 Research, pages 39834\u201339863. PMLR, 23\u201329 Jul 2023.   \n495 Deheng Ye, Guibin Chen, Wen Zhang, Sheng Chen, Bo Yuan, Bo Liu, Jia Chen, Zhao Liu, Fuhao Qiu, Hongsheng   \n496 Yu, et al. Towards playing full moba games with deep reinforcement learning. Advances in Neural Information   \n497 Processing Systems, 33:621\u2013632, 2020.   \n498 Chao Yu, Akash Velu, Eugene Vinitsky, Yu Wang, Alexandre Bayen, and Yi Wu. The surprising effectiveness of   \n499 ppo in cooperative, multi-agent games. arXiv preprint arXiv:2103.01955, 2021.   \n500 Shuai Yu, Xu Chen, Zhi Zhou, Xiaowen Gong, and Di Wu. When deep reinforcement learning meets federated   \n501 learning: Intelligent multitimescale resource management for multiaccess edge computing in $5\\mathrm{g}$ ultradense   \n502 network. IEEE Internet of Things Journal, 8(4):2238\u20132251, 2020.   \n503 Tao Yu, HZ Wang, Bin Zhou, Ka Wing Chan, and J Tang. Multi-agent correlated equilibrium q (\u03bb) learning for   \n504 coordinated smart generation control of interconnected power grids. IEEE transactions on power systems, 30   \n505 (4):1669\u20131679, 2014.   \n506 Kaiqing Zhang, Zhuoran Yang, and Tamer Basar. Networked multi-agent reinforcement learning in continuous   \n507 spaces. In 2018 IEEE conference on decision and control (CDC), pages 2771\u20132776. IEEE, 2018a.   \n508 Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Basar. Fully decentralized multi-agent   \n509 reinforcement learning with networked agents. In International Conference on Machine Learning, pages   \n510 5872\u20135881. PMLR, 2018b.   \n511 Heyang Zhao, Jiafan He, and Quanquan Gu. A nearly optimal and low-switching algorithm for reinforcement   \n512 learning with general function approximation, 2023.   \n513 Zhaowei Zhu, Jingxuan Zhu, Ji Liu, and Yang Liu. Federated bandit: A gossiping approach. Proc. ACM Meas.   \n514 Anal. Comput. Syst., 5(1), 2021.   \n515 Hankz Hankui Zhuo, Wenfeng Feng, Yufeng Lin, Qian Xu, and Qiang Yang. Federated deep reinforcement   \n516 learning. arXiv preprint arXiv:1901.08277, 2019. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "517 Impact Statement ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "518 Our work has the potential to enhance cooperative learning systems across diverse fields. By   \n519 introducing algorithms that enable efficient collaboration among agents with minimal communication   \n520 overhead, our research paves the way for advancements in distributed systems, including robotics,   \n521 traffic management, and distributed sensor networks. This could lead to more adaptive, efficient,   \n522 and scalable systems capable of tackling complex problems in dynamic environments, ultimately   \n523 contributing to technological progress and societal well-being.   \n524 As far as we can tell, there is hardly any negative social impact from our work, mainly because we do   \n525 not include experiments apart from our theoretical analysis. ", "page_idx": 13}, {"type": "text", "text": "526 A The Bandit Case: Proof of Theorem 4.3 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Before we begin the analysis of Algorithm 1, we reiterate and add some notations for clarity and convenience. Define the data collected by agent $m$ that has already been uploaded to the server by round $t$ as $Z_{m,t}^{\\mathrm{up}}$ , and the universal data at round $t$ as $Z_{t}^{\\mathrm{all}}$ . Apart from these we also have from the algorithm the datasets $Z_{m,t}^{\\mathrm{loc}}$ and $Z_{t}^{\\mathrm{ser}}$ . It is not difficult to check that they satisfy the following relation: ", "page_idx": 14}, {"type": "equation", "text": "$$\nZ_{t}^{\\mathrm{all}}=\\bigcup_{m=1}^{M}\\big(Z_{m,t}^{\\mathrm{up}}\\cup Z_{m,t}^{\\mathrm{loc}}\\big).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Furthermore, when $t$ is not a communication round, we also have ", "page_idx": 14}, {"type": "equation", "text": "$$\nZ_{t}^{\\mathrm{ser}}=\\bigcup_{m=1}^{M}Z_{m,t}^{\\mathrm{up}},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and when it is a communication round that ", "page_idx": 14}, {"type": "equation", "text": "$$\nZ_{t}^{\\mathrm{ser}}=\\biggl[\\bigcup_{m=1}^{M}Z_{m,t}^{\\mathrm{up}}\\biggr]\\cup Z_{m_{t},t}^{\\mathrm{loc}},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "527 which will be useful in our proof of Lemma A.1 and B.1 in Section C.1. ", "page_idx": 14}, {"type": "text", "text": "528 Next, we assume that at rounds $0=t_{0}<t_{1}<\\dots<t_{L}<t_{L+1}=T+1$ , the participating agent   \n529 communicates with the server, where $t_{0}$ and $t_{K+1}$ are dummy rounds. The subscripts will be denoted   \n530 as $l=1,\\cdots\\,,L$ in the future.   \n531 We now describe a participant reordering trick for our asynchronous multi-agent setting, which we will   \n532 use multiple times in the proof. The basic idea is that, as long as the communication order remains the   \n533 same, and for any given agent, the number of rounds between two consecutive communication rounds   \n534 remains the same, one can switch the episodes around and change the order of agent participation to   \n535 a certain degree. For example, we may assume that $m_{t}=m_{t_{l}}$ for all $t\\in(t_{l-1},t_{l}]$ by reordering the   \n536 participants, which means all participation of any given agent happens immediately before a certain   \n537 communication round; as another example, we may assume $m_{t}=m_{t_{l-1}}$ for all $t\\in[t_{l-1},t_{l})$ , which   \n538 means all participation happen immediately after communication rounds. It should be noted that one   \n539 needs to be careful when utilizing this argument, since switching the participation order changes the   \n540 values of $t_{l}$ and many associated elements, so applying this trick twice in succession would lead to   \n541 contradictions. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "For a dataset $Z$ , we define the $Z$ -norm on function set $\\mathcal{F}$ as $\\begin{array}{r}{\\|f\\|_{Z}^{2}:=\\sum_{(a,r)\\in Z}f^{2}(a)}\\end{array}$ for any $f\\in\\mathcal F$ . Then we have the shortened notation ", "page_idx": 14}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}}(a;Z)=\\operatorname*{sup}_{f_{1},f_{2}\\in\\mathcal{F}}\\frac{|f_{1}(a)-f_{2}(a)|}{\\sqrt{\\lambda+\\|f_{1}-f_{2}\\|_{Z}^{2}}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "542 Finally, we define the confidence set of functions at round $t+1$ as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal F_{t+1}=\\bigg\\{f\\in\\mathcal F:\\sum_{(a,r)\\in Z_{t}^{\\mathrm{ser}}}\\big(f(a)-\\widehat f_{t+1}(a)\\big)^{2}\\leq\\beta_{t}^{2}\\bigg\\},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "543 which is a common construction in reinforcement learning. ", "page_idx": 14}, {"type": "text", "text": "544 A.1 Auxiliary Lemmas ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "545 In this section we present some auxiliary lemmas that will be used in the proof of Theorem 4.3. Note   \n546 these lemmas correspond well to the lemmas presented in 6, only that these are for the contextual   \n547 bandit case. The proofs for these lemmas can be found in Section C. ", "page_idx": 14}, {"type": "text", "text": "Lemma A.1. For any $t\\in[T]$ , $m\\in[M]$ and $f_{1},f_{2}\\in{\\mathcal{F}}$ , as long as agent m does not communicate with the server at time step $t_{\\perp}$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\lambda+\\sum_{m^{\\prime}\\in[M]}\\|f_{1}-f_{2}\\|_{Z_{m^{\\prime},t}^{u p}}^{2}\\geq\\frac{1}{\\alpha}\\|f_{1}-f_{2}\\|_{Z_{m,t}^{l_{o c}}}^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Furthermore, for any $t\\in[T]$ and $f_{1},f_{2}\\in{\\mathcal{F}}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\lambda+\\|f_{1}-f_{2}\\|_{Z_{t}^{s e r}}^{2}\\geq\\frac{1}{1+M\\alpha}\\big(\\lambda+\\|f_{1}-f_{2}\\|_{Z_{t}^{a l l}}^{2}\\big),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and as a corollary, for any $a\\in{\\mathcal{A}}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}}^{2}(a;Z_{t}^{s e r})\\le(1+M\\alpha)D_{\\lambda,\\mathcal{F}}^{2}(a;Z_{t}^{a l l})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "548 This lemma describes the discrepancy between different datasets. Crucially, it provides a worst case   \n549 ratio between uncertainty measured on the server dataset and universal dataset. This is an important   \n550 tool for bridging between the different uncertainty estimators in the following proofs. The proof can   \n551 be found in Section C.1. ", "page_idx": 15}, {"type": "text", "text": "Lemma A.2. By taking $\\gamma=O(1/T)$ and ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\beta_{t}=\\widetilde{\\beta}_{1}:=C_{\\beta,1}\\big[\\sqrt{\\lambda}+\\sqrt{(\\gamma^{2}+\\gamma R)T}+R C(M,\\alpha)\\log(3M N(\\mathcal{F},\\gamma)/\\delta)\\big],\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "552 with $C_{\\beta,1}=6$ , where $C(M,\\alpha):=\\sqrt{1+M\\alpha}+M\\sqrt{\\alpha}$ , we have $f^{*}\\in\\mathcal{F}_{t+1}$ for all $t\\in\\{t_{l}\\}_{l=1}^{L}$ with   \n553 probability at least $1-\\delta$ . As a corollary, we also have $|f_{*}(a)-\\widehat{f}_{t+1}(a)|\\leq b_{t+1}(a).$ for any $a\\in\\mathcal{A}_{t}$   \n554 and $t\\in\\{t_{l}\\}_{l=1}^{L}$ .   \n555 This is the central optimism lemma present in all provably efficient reinforcement learning literature.   \n556 It states that the confidence function set contains the ground truth function $f^{*}$ with high probability,   \n557 and in our case, that the decision function $\\widehat{f}_{t}+b_{t}$ is optimistic. With this, we define the good event   \n558 $\\mathcal{E}_{T}=\\{f^{*}\\in\\mathcal{F}_{t+1},\\forall t\\in\\{t_{l}\\}_{l=1}^{L}\\}$ . Then a ccording to A.2, $\\mathbb{P}(\\mathcal{E}_{T})\\geq1-\\delta$ . The proof can be found   \n559 in Section C.2. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Lemma A.3. The sum of squared uncertainty estimators of new data over all historical data can be bounded as follows with some absolute constant $C_{D}$ : ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t-1}^{a l l})\\leq C_{D}\\dim_{E}(\\mathcal{F},\\lambda/T)\\log^{2}(T/\\operatorname*{min}\\{1,\\lambda\\})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "560 This lemma corresponds to the elliptical potential argument from the linear setting [Abbasi-Yadkori   \n561 et al., 2011]. In the nonlinear setting, this lemma essentially reveals the relationship between the sum   \n562 of Eluder-like confidence quantities and the Eluder dimension. The proof can be found in Section   \n563 C.3. ", "page_idx": 15}, {"type": "text", "text": "564 A.2 The Epoch Segmentation Scheme ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "565 In this section, we introduce an epoch segmentation scheme, which is needed for both the regret and   \n566 communication cost proofs presented in the next two sections. It is a generalization of the epoch   \n567 segmentation scheme based on doubling determinant in the linear bandits / MDPs setting [He et al.,   \n568 2022, Min et al., 2023], but the lack of a Gram matrix (used for linear regression) in the nonlinear   \n569 case complicates matters significantly. ", "page_idx": 15}, {"type": "text", "text": "We segment the entire run of $t=1,\\cdot\\cdot\\cdot,T$ into $N$ epochs as follows. Define iteratively $0=l_{0}<$ $l_{1}<\\cdots<l_{N}\\leq L$ as ", "page_idx": 15}, {"type": "equation", "text": "$$\nl_{i}=\\operatorname*{min}\\bigg\\{l>l_{i-1}:\\sum_{l^{\\prime}=l_{i-1}+1}^{l}\\sum_{(a,r)\\in Z_{m,t_{l^{\\prime}}}^{\\mathrm{loc}}}D_{\\lambda,\\mathcal{F}}^{2}(a;Z_{t_{l_{i-1}}}^{\\mathrm{ser}})\\geq1\\bigg\\},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "570 where for a given $l^{\\prime}$ in the summation, $m=m_{t_{l^{\\prime}}}$ is the participating agent at $t_{l^{\\prime}}$ . In the iterative   \n571 process, if the above minimum does not exist, simply define $N=i-1$ and end the process there.   \n572 Correspondingly, the $i$ -th epoch is defined by the time steps $[t_{l_{i-1}},t_{l_{i}})$ .   \n573 The following sections will make use of this epoch scheme as befti their needs, but here we shall give   \n574 an upper bound for the total number of epochs $N$ . Based on the definition of $l_{i}$ , we have for any ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "575 $l_{i-1}\\leq l<l_{i}$ that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{1\\geq\\underset{t=\\ensuremath{\\tau_{i-1}}+1}{\\sum}\\sum_{\\substack{(a,r)\\in\\ensuremath{\\mathbb{Z}}_{m_{t}}^{\\infty},\\,t;r}}D_{\\lambda,r}^{2}(a;\\ensuremath{\\mathbb{Z}}_{t_{i-1}}^{\\infty})}\\\\ &{=\\underset{t=\\ensuremath{\\tau_{i-1}}+1}{\\sum}\\sum_{\\substack{(a,r)\\in\\ensuremath{\\mathbb{Z}}_{t_{i}^{\\infty}}^{\\infty},\\,t;r}}\\underset{f_{i}\\geq\\ensuremath{\\mathbb{Z}}^{\\infty}}{\\operatorname*{sup}}\\frac{\\bigl[f_{1}(a)-f_{2}(a)\\bigr]^{2}}{\\lambda+\\|f_{1}-f_{2}\\|_{\\ensuremath{\\mathbb{Z}}_{t_{i-1}}^{\\infty}}^{2}}}\\\\ &{\\geq\\underset{f_{1},f_{2}\\in\\ensuremath{\\mathbb{Z}}^{\\infty}}{\\operatorname*{sup}}\\frac{\\sum_{(a,r)\\in\\ensuremath{\\mathbb{Z}}_{t_{i}^{\\infty}}^{\\infty},\\,t;r_{i-1}^{\\infty}}\\bigl[f_{1}(a)-f_{2}(a)\\bigr]^{2}}{\\lambda+\\|f_{1}-f_{2}\\|_{\\ensuremath{\\mathbb{Z}}_{t_{i-1}}^{\\infty}}^{2}}}\\\\ &{=\\underset{f_{1},f_{2}\\in\\ensuremath{\\mathbb{Z}}^{\\infty}}{\\operatorname*{sup}}\\frac{\\lambda+\\|f_{1}-f_{2}\\|_{\\ensuremath{\\mathbb{Z}}_{t_{i}^{\\infty}}^{2}}^{2}}{\\lambda+\\|f_{1}-f_{2}\\|_{\\ensuremath{\\mathbb{Z}}_{t_{i-1}}^{\\infty}}^{2}}-1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "576 which gives $\\lambda+\\|f_{1}-f_{2}\\|_{Z_{t_{l}}^{\\mathrm{ser}}}^{2}\\leq2\\big(\\lambda+\\|f_{1}-f_{2}\\|_{Z_{t_{l}}^{\\mathrm{ser}}}^{2}\\big)$ for any $f_{1},f_{2}\\in{\\mathcal{F}}$ . Then we have ", "page_idx": 16}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}}^{2}(a;Z_{t_{l_{i-1}}}^{\\mathrm{ser}})\\leq2D_{\\lambda,\\mathcal{F}}^{2}(a;Z_{t_{l}}^{\\mathrm{ser}})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "577 for any $a$ , and so ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{1\\leq\\underset{(a,r)\\in\\mathbb{Z}_{t_{l_{i}}^{\\pi^{\\varepsilon}}}^{\\infty}\\backslash\\mathbb{Z}_{t_{l_{i-1}}}^{\\infty}}{\\sum}D_{\\lambda,\\mathcal{F}}^{2}(a;\\mathcal{Z}_{t_{l_{i-1}}}^{\\mathrm{ser}})}\\\\ &{\\quad=\\underset{l=l_{i-1}+1}{\\overset{l_{i}}{\\sum}}\\underset{(a,r)\\in\\mathbb{Z}_{t_{l}^{\\pi}}^{\\infty}\\backslash\\mathbb{Z}_{t_{l-1}}^{\\infty}}{\\sum}D_{\\lambda,\\mathcal{F}}^{2}(a;\\mathcal{Z}_{t_{l_{i-1}}}^{\\mathrm{ser}})}\\\\ &{\\quad\\leq2\\underset{l=l_{i-1}+1}{\\overset{l_{i}}{\\sum}}\\underset{(a,r)\\in\\mathbb{Z}_{t_{l}^{\\pi}}^{\\infty}\\backslash\\mathbb{Z}_{t_{l-1}}^{\\infty}}{\\sum}D_{\\lambda,\\mathcal{F}}^{2}(a;\\mathcal{Z}_{t_{l-1}}^{\\mathrm{ser}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "578 and summing over $i=1,\\cdot\\cdot\\cdot,N-1$ that: ", "page_idx": 16}, {"type": "equation", "text": "$$\nN-1\\leq2\\sum_{l=1}^{L}\\sum_{(a,r)\\in\\cal Z_{t_{l}}^{\\mathrm{ser}}\\backslash{Z_{t_{l-1}}^{\\mathrm{ser}}}}D_{\\lambda,\\mathcal{F}}^{2}(a;\\cal Z_{t_{l-1}}^{\\mathrm{ser}}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "579 If we apply the participant reordering trick and let $m_{t}=m_{t_{l}}$ for all $t\\in(t_{l-1},t_{l}]$ and $l\\in[L]$ , we get   \n580 $Z_{t_{l}}^{\\mathrm{ser}}\\backslash Z_{t_{l-1}}^{\\mathrm{ser}}=\\{(a_{t},r_{t})\\}_{t=t_{l-1}+1}^{t_{l}}$ , and so applying Lemma A.1 and Lemma A.3, we get ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{N-1\\leq2\\displaystyle\\sum_{l=1}^{L}\\displaystyle\\sum_{t=t_{l-1}+1}^{t_{l}}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t_{l-1}}^{\\mathrm{ser}})}\\\\ &{\\qquad\\le2(1+M\\alpha)\\displaystyle\\sum_{l=1}^{L}\\displaystyle\\sum_{t=t_{l-1}+1}^{t_{l}}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t-1}^{\\mathrm{al}})}\\\\ &{\\qquad\\le2(1+M\\alpha)\\displaystyle\\sum_{t=1}^{T}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t-1}^{\\mathrm{al}})}\\\\ &{\\qquad\\le C(1+M\\alpha)\\displaystyle\\operatorname*{dim}_{t=1}^{\\mathbf{\\alpha}}(\\mathcal{F},\\lambda/T)\\log(T/\\lambda)\\log T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "581 which gives the order of total number of epochs: ", "page_idx": 16}, {"type": "equation", "text": "$$\nN=O\\bigg((1+M\\alpha)\\,\\mathrm{dim}_{E}(\\mathcal{F},\\lambda/T)\\log^{2}(T/\\operatorname*{min}\\{1,\\lambda\\})\\bigg).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "582 Notice that the participant reordering trick is only used to bound the number of epochs, which itself   \n583 does not depend on the specific order of participation. This is crucial since it suggests this reordering   \n584 does not change anything essential, and is in fact not necessary for the proof - it just made the proof   \n585 easier to read. Therefore we can still reorder participants as we see fit in other parts of our proof. ", "page_idx": 16}, {"type": "text", "text": "586 A.3 Proof of Regret Upper Bound ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "587 Now we are ready to prove the first part of Theorem 4.3 concerning the regret upper bound. We   \n588 begin by applying the participation reordering trick to assume, without loss of generality, that the   \n589 same agent is active within the rounds $[t_{l},t_{l+1}-1]$ , i.e. $m_{t_{l}}=m_{t_{l}+1}=\\cdot\\cdot\\cdot=m_{t_{l+1}-1}$ . Under this   \n590 assumption, we have $t_{1}=1$ .   \n591 Let $a_{t}^{*}:=\\operatorname*{argmax}_{a\\in D_{t}}f_{*}(a)$ be the best arm at time $t$ . Then by Lemma A.2, $f_{*}(a_{t}^{*})\\leq\\,\\widehat{(f_{m_{t},t}}+$   \n592 $b_{m_{t},t}\\big)(a_{t}^{*})\\leq\\big(\\widehat{f}_{m_{t},t}+b_{m_{t},t}\\big)\\big(a_{t}\\big)$ , where the second inequality is due to the choice of $a_{t}$ at round $t$ .   \n593 Hence we get ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathrm{Reg}(T)=\\sum_{t=1}^{T}\\left[f_{*}(a_{t}^{*})-f_{*}(a_{t})\\right]}\\quad}&{}\\\\ &{\\leq\\operatorname*{min}\\left\\{\\sum_{t=1}^{T}\\left(\\widehat{f}_{m_{t},t}+b_{m_{t},t}-f^{*}\\right)(a_{t}),4\\right\\}}\\\\ &{\\leq\\displaystyle\\sum_{t=1}^{T}\\operatorname*{min}\\{2b_{m_{t},t}(a_{t}),4\\}}\\\\ &{=2\\sum_{t=1}^{L}\\sum_{t=t+1}^{t_{t+1}-1}b_{t_{t}}(a_{t})+2\\sum_{t=1}^{L}\\operatorname*{min}\\{b_{m_{t},t}(a_{t}),2\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "594 where the first inequality is due to $\\vert f\\vert\\le1$ from Assumption 3.1, and the second inequality again   \n595 uses Lemma A.2. We first bound the second term here using the epoch scheme in Section A.2. We   \n596 start by converting the bonus term to uncertainty: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{b_{m_{t_{l}},t_{l}}(a_{t_{l}})=b_{t_{l-1}}(a_{t_{l}})}\\\\ &{\\qquad\\qquad\\qquad\\leq C_{\\mathcal{B}}\\sqrt{\\beta_{t_{l}-1}^{2}+\\lambda}\\cdot D_{\\lambda,\\mathcal{F}}(a_{t_{l}};Z_{t_{l-1}}^{\\mathrm{ser}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "597 Now consider the episodes in an epoch $i$ , specifically $\\{t_{l_{i-1}},t_{l_{i-1}+1},\\cdot\\cdot\\cdot\\;,t_{l_{i}}\\}$ . For any $l_{i-1}<l<l_{i}$ ,   \n598 since $Z_{t_{l_{i-1}}}^{\\mathrm{ser}}\\subseteq Z_{t_{l-1}}^{\\mathrm{ser}}$ , we can deduce that ", "page_idx": 17}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}}^{2}(z_{t_{l}};Z_{t_{l-1}}^{\\mathrm{ser}})\\leq D_{\\lambda,\\mathcal{F}}^{2}(z_{t_{l}};Z_{t_{l_{i-1}}}^{\\mathrm{ser}})\\leq2D_{\\lambda,\\mathcal{F}}^{2}(z_{t_{l}};Z_{t_{l}}^{\\mathrm{ser}}),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "599 where the second inequality is borrowed from (15) from Section A.2. Therefore continuing from   \n600 (18), ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{l=1}^{L}\\operatorname*{min}\\{b_{m_{t_{l}},t_{l}}(z_{t_{l}}),2\\}\\leq\\sum_{l\\not\\in\\{l_{i}\\}_{i=1}^{N}}\\left[\\sqrt{2}C_{B}\\sqrt{\\beta_{t_{l}-1}^{2}+\\lambda}\\cdot D_{\\lambda,\\mathcal{F}}(z_{t_{l}};Z_{t_{l}}^{\\mathrm{ser}})\\right]+\\sum_{i=1}^{N}2}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\leq\\sqrt{2}C_{B}\\sum_{l=1}^{L}D_{\\lambda,\\mathcal{F}}(z_{t_{l}};Z_{t_{l}}^{\\mathrm{ser}})\\sqrt{\\beta_{h}^{2}+\\lambda}+2N.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "601 Now combine this result with the first term in (17) and use again (18), we get ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{2\\mathrm{ceg}(T)\\leq2C_{B}\\sum_{l=1}^{L}\\sum_{t=t_{l}+1}^{t_{l+1}-1}D_{\\lambda,\\mathcal{F}}(a_{t};Z_{t_{l}}^{\\mathrm{ser}})\\sqrt{\\beta_{t_{l}}^{2}+\\lambda}+2\\sqrt{2}C_{B}\\sum_{l=1}^{L}D_{\\lambda,\\mathcal{F}}(z_{t_{l}};Z_{t_{l}}^{\\mathrm{ser}})\\sqrt{\\beta_{h}^{2}+\\lambda}+4N}}\\\\ &{}&{\\leq2\\sqrt{2}C_{B}\\sum_{l=1}^{L}\\sum_{t=t_{l}}^{t_{l+1}-1}D_{\\lambda,\\mathcal{F}}(a_{t};Z_{t_{l}}^{\\mathrm{ser}})\\sqrt{\\beta_{t_{l}}^{2}+\\lambda}+4N}\\\\ &{}&{\\leq2\\sqrt{2}C_{B}\\Bigg[\\displaystyle\\sum_{l=1}^{L}\\sum_{t=t_{l}}^{t_{l+1}-1}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t_{l}}^{\\mathrm{ser}})\\Bigg]^{1/2}\\Bigg[\\displaystyle\\sum_{t=1}^{T}\\big(\\widetilde{\\beta}_{1}^{2}+\\lambda\\big)\\Bigg]^{1/2}+4N}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\widetilde{\\beta}_{1}=C_{\\beta}\\bigg[\\sqrt{\\lambda}+R C(M,\\alpha)\\sqrt{\\log(3N()M/\\delta)}\\bigg].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "602 According to Lemma A.1 and Lemma A.3, the term ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{l=1}^{L}\\sum_{t=t_{l}}^{t_{l+1}-1}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t_{l}}^{\\mathrm{ser}})\\leq(1+M\\alpha)\\displaystyle\\sum_{l=1}^{L}\\sum_{t=t_{l}}^{t_{l+1}-1}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t-1}^{\\mathrm{all}})}&\\\\ &{\\qquad\\qquad\\qquad\\qquad=(1+M\\alpha)\\displaystyle\\sum_{t=1}^{T}D_{\\lambda,\\mathcal{F}}^{2}(a_{t};Z_{t-1}^{\\mathrm{all}})}\\\\ &{\\qquad\\qquad\\qquad\\leq C(1+M\\alpha)\\displaystyle\\operatorname*{dim}_{E}(\\mathcal{F},\\lambda/T)\\log^{2}\\big(T/\\operatorname*{min}\\{1,\\lambda\\}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "603 combining this with (16), we get ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}(T)\\leq C\\left[(1+M\\alpha)\\dim_{E}(\\mathcal{F},\\lambda/T)\\log^{2}\\left(T/\\operatorname*{min}\\{1,\\lambda\\}\\right)\\right]^{1/2}\\Bigg[\\underset{t=1}{\\overset{T}{\\sum}}(\\beta_{t}^{2}+\\lambda)\\Bigg]^{1/2}+4N}\\\\ &{\\qquad\\quad=O\\Bigg(\\sqrt{T}\\widetilde{\\beta}_{1}\\sqrt{(1+M\\alpha)\\dim_{E}(\\mathcal{F},\\lambda/T)}\\log(T/\\operatorname*{min}\\{1,\\lambda\\})}\\\\ &{\\qquad\\quad\\,+\\left(1+M\\alpha\\right)\\dim_{E}(\\mathcal{F},\\lambda/T)\\log^{2}(T/\\operatorname*{min}\\{1,\\lambda\\})\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "604 A.4 Proof of Communication Cost ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "605 In this section we prove the second part of Theorem 4.3, by calculating the communication com  \n606 plexity. First, for each communication round $t_{l}$ , assume the last time before $t_{l}$ when the agent $m_{t_{l}}$   \n607 communicated with the server was $t_{l^{\\prime}}$ , then ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{(a,r)\\in{\\cal Z}_{m,t_{l}}^{\\mathrm{loc}}}D_{\\lambda,{\\mathcal F}}^{2}(a;{\\cal Z}_{m,t_{l}}^{\\mathrm{up}})\\geq\\sum_{(a,r)\\in{\\cal Z}_{m,t_{l}}^{\\mathrm{loc}}}\\frac{\\left[b_{t_{l^{\\prime}}}(a)/C\\right]^{2}}{\\beta_{t_{l^{\\prime}}}^{2}+\\lambda}\\geq\\frac{\\alpha}{C^{2}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "608 Now employing the epoch segmentation scheme from section A.2, for the $i$ -th epoch consisting of   \n609 the time steps $[t_{l_{i-1}},t_{l_{i}})$ , we have the inequality ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{1\\geq\\displaystyle\\sum_{l=l_{i-1}+1}^{l_{i}-1}\\sum_{\\substack{(a,r)\\in\\ensuremath{\\mathbb{Z}}_{m,t_{l}}^{\\mathrm{loc}}}}D_{\\lambda,\\mathcal{F}}^{2}\\big(a;Z_{t_{l_{i-1}}}^{\\mathrm{ser}}\\big)}\\\\ &{\\geq\\displaystyle\\sum_{l=l_{i-1}+1}^{l_{i}-1}\\sum_{\\substack{(a,r)\\in\\ensuremath{\\mathbb{Z}}_{m,t_{l}}^{\\mathrm{loc}}}}D_{\\lambda,\\mathcal{F}}^{2}\\big(a;Z_{m,t_{l}}^{\\mathrm{up}}\\cup Z_{t_{l_{i-1}}}^{\\mathrm{ser}}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For $m\\in[M]$ , assume the agent $m$ communicated with the server a total of $n_{m}$ times within $[t_{l_{i-1}},t_{l_{i}})$ . Then except for the first of these communication rounds, for each $l\\in[l_{i-1}+1,l_{i}-1]$ with $m_{t_{l}}=m$ , there exists $l^{\\prime}\\in[l_{i-1},l)$ with $m_{t_{l^{\\prime}}}=m$ , thus we have $Z_{m,t_{l}}^{\\mathfrak{u p}}\\supset Z_{m,t_{l^{\\prime}}+1}^{\\mathfrak{u p}}=Z_{t_{l^{\\prime}}}^{\\mathrm{ser}}\\supset Z_{t_{l_{i-1}}}^{\\mathrm{ser}}$ . With this we have the corresponding term ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{(a,r)\\in{\\cal Z}_{m,t_{l}}^{\\mathrm{loc}}}D_{\\lambda,{\\mathcal{F}}}^{2}(a;{\\cal Z}_{m,t_{l}}^{\\mathrm{up}}\\cup{\\cal Z}_{t_{l_{i-1}}}^{\\mathrm{ser}})=\\sum_{(a,r)\\in{\\cal Z}_{m,t_{l}}^{\\mathrm{loc}}}D_{\\lambda,{\\mathcal{F}}}^{2}(a;{\\cal Z}_{m,t_{l}}^{\\mathrm{up}})\\geq\\frac{\\alpha}{C_{B}^{2}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "610 therefore ", "page_idx": 18}, {"type": "equation", "text": "$$\n1\\geq\\sum_{m=1}^{M}(n_{m}-1)\\cdot{\\frac{\\alpha}{4C^{2}}}\\Rightarrow\\sum_{m=1}^{M}n_{m}\\leq M+{\\frac{C_{B}^{2}}{\\alpha}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Notice that $\\begin{array}{r}{\\sum_{m=1}^{M}n_{m}=l_{i}-l_{i-1}}\\end{array}$ is the number of communication rounds within $[t_{l_{i-1}},t_{l_{i}})$ , hence summing over $i$ the total number of communication rounds is upper bounded by $N(M+C_{B}^{2}/\\alpha)$ . Combine this with (16), we have the total number of communication rounds throughout the algorithm is ", "page_idx": 18}, {"type": "equation", "text": "$$\nO\\bigg(\\frac{(1+M\\alpha)^{2}}{\\alpha}\\dim_{E}(\\mathcal{F},\\lambda/T)\\log^{2}\\big(T/\\operatorname*{min}\\{1,\\lambda\\}\\big)\\bigg).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "611 B The MDPs Case: Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "612 Similar to the bandit case, we define $Z_{m,k,h}^{\\mathrm{loc}},Z_{m,k,h}^{\\mathrm{up}},Z_{k,h}^{\\mathrm{ser}}$ , and $Z_{k,h}^{\\mathrm{all}}$ to be the local, uploaded, server   \n613 and universal data, with corresponding subscripts of agent $m\\in[M]$ , episode $k\\in[K],h\\in[H]$ .   \n614 Suppose at rounds $0=k_{0}<k_{1}<\\dots<k_{L}<k_{L+1}=T+1$ , the participating agent communicates   \n615 with the server, where $k_{0}$ and $k_{L+1}$ are dummy rounds. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "For a dataset $Z_{h}$ in the MDPs setting, we again define the $Z_{h}$ -norm on function set ${\\mathcal{F}}_{h}$ as $\\|f\\|_{Z}^{2}:=$ $\\sum_{o_{h}\\in Z}f_{.}^{2}(z_{h})$ for any $f\\in\\mathcal F$ . As a reminder, the tuples $o_{h}=(s_{h},a_{h},r_{h},s_{h+1})$ and $z_{h}=(s_{h},a_{h})$ Then we have the shortened notation ", "page_idx": 19}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}_{h}}(z_{h};Z_{h})=\\operatorname*{sup}_{f_{1},f_{2}\\in\\mathcal{F}_{h}}\\frac{\\lvert f_{1}(z_{h})-f_{2}(z_{h})\\rvert}{\\sqrt{\\lambda+\\lVert f_{1}-f_{2}\\rVert_{Z_{h}}^{2}}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "616 Finally, we define the confidence set of functions at round $k+1$ and step $h$ as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal{F}_{k+1,h}=\\bigg\\{f\\in\\mathcal{F}_{h}:\\sum_{o_{h}\\in Z_{k,h}^{\\mathrm{sr}}}\\big(f(z_{h})-\\widehat{f}_{k+1,h}(z_{h})\\big)^{2}\\leq(\\beta_{k,h})^{2}\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "617 B.1 Auxiliary Lemmas ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "618 In this section we present some auxiliary lemmas that will be used in the proof of Theorem 5.1. These   \n619 lemmas are generalizations / restatements to the lemmas presented in 6, and their detailed proofs can   \n620 be found in Section C. ", "page_idx": 19}, {"type": "text", "text": "Lemma B.1 (Restatement of Lemma 6.3). For any $\\xi\\in[K],\\,m\\in[M],\\,h\\in[H]$ and $f_{1},f_{2}\\in{\\mathcal{F}}$ , as long as agent m does not communicate with the server at episode $k$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\lambda+\\sum_{m^{\\prime}\\in[M]}\\|f_{1}-f_{2}\\|_{Z_{m^{\\prime},k,h}^{u p}}^{2}\\geq\\frac{1}{\\alpha}\\|f_{1}-f_{2}\\|_{Z_{m,k,h}^{l o c}}^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Furthermore, we have for any $k\\in[K]$ and $f_{1},f_{2}\\in{\\mathcal{F}}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k,h}^{s e r}}^{2}\\geq\\frac{1}{1+M\\alpha}\\big(\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k,h}^{a l l}}^{2}\\big),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and as a corollary, for any $z=(s,a)\\in S\\times A$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}}^{2}(z;Z_{k,h}^{s e r})\\le(1+M\\alpha)D_{\\lambda,\\mathcal{F}}^{2}(z;Z_{k,h}^{a l l})\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "621 Similar to Lemma A.1, this lemma provides a worst case ratio between uncertainty measured on the   \n622 server dataset and universal dataset. The proof can be found in Section C.1. ", "page_idx": 19}, {"type": "text", "text": "623 Lemma B.2 (Restatement of Lemma 6.1). By taking $\\gamma=1/(C_{\\gamma}K H)$ with $C_{\\gamma}\\geq20$ , as well as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\beta_{k,h}=\\widetilde{\\beta}_{2}:=C_{\\beta,2}\\bigg[\\sqrt{\\lambda}+H C(M,\\alpha)\\sqrt{\\log(3H M N_{h}(\\gamma)/\\delta)}\\bigg],\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "624 with $C_{\\beta,2}=12$ for all $k\\in[K]$ and $h\\in[H].$ , where $N_{h}(\\gamma)=N(\\mathcal{F}_{h},\\gamma)\\cdot N(\\mathcal{F}_{h+1},\\gamma)\\cdot N(\\mathcal{W}_{h+1},\\gamma)$ ,   \n625 we have with probability at least $1\\!-\\!\\delta$ that $\\tau_{h}Q_{k+1,h+1}\\in\\mathcal{F}_{k+1,h}.$ for all $k\\in\\{k_{l}\\}_{l=1}^{L}$ with probability   \n626 at least $1-\\delta$ . As a corollary, we also have $\\vert\\mathcal{T}_{h}Q_{k+1,h+1}(s,a)-\\widehat{f}_{k+1,h}(s,a)\\vert\\leq b_{k+1,h}(s,a)\\,f$ or   \n627 any $(s,a)\\in\\mathcal{S}\\times\\mathcal{A},\\,k\\in\\{k_{l}\\}_{l=1}^{L}$ and $h\\in[H]$ .   \n628 This is the central optimism lemma. It states that the Bellman operator of $Q$ -value function at level   \n629 $h+1$ is within the confidences set at level $h$ . The conclusion immediately gives the optimism   \n630 inequality $\\tau_{h}Q_{k+1,h+1}(s,a)\\,\\leq\\,Q_{k+1,h}(s,a)$ , which we will use at the start of the regret upper   \n631 bound prove. The proof of the lemma can be found in Section C.2.   \n632 With this, we define the good event $\\mathcal{E}_{T}=\\{\\mathcal{T}_{h}Q_{k+1,h+1}\\in\\mathcal{F}_{k+1,h},\\forall k\\in\\{k_{l}\\}_{l=1}^{L},h\\in[H]\\}$ . Then   \n633 according to Lemma B.2, $\\mathbb{P}(\\mathcal{E}_{T})\\geq1-\\delta$ . ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Lemma B.3. For some absolute constant $C_{D}$ , the following holds for all level $h\\in[H]$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}D_{\\lambda,\\mathcal{F}}^{2}(z_{h}^{k};Z_{k-1,h}^{a l l})\\leq C_{D}\\dim_{E}(\\mathcal{F},\\lambda/T)\\log^{2}(T/\\operatorname*{min}\\{1,\\lambda\\})\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "634 This lemma is essentially the same as Lemma A.3. It reveals the relationship between the sum of   \n635 Eluder-like confidence quantities and the Eluder dimension. The proof can be found in Section C.3. ", "page_idx": 19}, {"type": "text", "text": "636 B.2 The Epoch Segmentation Scheme ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "637 In this section, we introduce the epoch segmentation scheme for MDPs, which is again needed for   \n638 both the regret and communication cost proofs presented in the next two sections. All of this is   \n639 quite similar to the bandit case in Section A.2, but the introduction of multiple levels $h\\in[H]$ does   \n640 complicate things a bit. ", "page_idx": 20}, {"type": "text", "text": "We segment the entire run of episodes $k=1,\\cdots\\,,K$ into $N$ epochs as follows. Define iteratively $0=l_{0}<l_{1}<\\cdot\\cdot<l_{N}\\leq L$ as ", "page_idx": 20}, {"type": "equation", "text": "$$\nl_{i}=\\operatorname*{min}\\bigg\\{l>l_{i-1}:\\sum_{l^{\\prime}=l_{i-1}+1}^{l}\\sum_{h=1}^{H}\\sum_{o_{h}\\in Z_{m,k_{l^{\\prime}},h}^{\\mathrm{loc}}}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h};Z_{k_{l_{i-1}},h}^{\\mathrm{ser}})\\geq1\\bigg\\},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "641 where for a given $l^{\\prime}$ in the summation, $m=m_{k_{l^{\\prime}}}$ is the participating agent at $k_{l^{\\prime}}$ . In the iterative   \n642 process, if the above minimum does not exist, simply define $N=i-1$ and end the process there.   \n643 Correspondingly, the $i$ -th epoch is defined by the episodes $[k_{l_{i-1}},k_{l_{i}})$ .   \n644 The following sections will make use of this epoch scheme as befti their needs, but here we shall give   \n645 an upper bound for the total number of epochs $N$ . Based on the definition of $l_{i}$ , we have for any   \n646 $l_{i-1}\\leq l<l_{i}$ that ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{1\\geq\\displaystyle\\sum_{t=\\bar{t}_{i-1}+1}^{l}\\displaystyle\\sum_{h=1}^{H}\\sum_{o_{h}\\in\\mathbb{Z}_{m_{k}}^{m_{l}},\\Lambda_{k}^{-1}}D_{\\lambda,F}^{2}(z_{h};Z_{k-1}^{\\operatorname{sur}},h)}\\\\ &{\\quad=\\displaystyle\\sum_{t=\\bar{t}_{i-1}+1}^{l}\\sum_{h=1}^{H}\\sum_{o_{h}\\in\\mathbb{Z}_{k_{\\bar{t}}^{m_{l}},\\Lambda}^{-1},\\mathbb{Z}_{u_{t}^{m}-1}^{m},\\bar{h},I,J\\in\\mathbb{Z}^{m}}\\displaystyle\\frac{[f_{1}(z_{h})-f_{2}(z_{h})]^{2}}{\\lambda+\\|f_{1}-f_{2}\\|\\frac{2}{\\mathcal{Z}_{\\bar{t}_{i-1},h}^{2}}}}\\\\ &{\\geq\\displaystyle\\sum_{h=1}^{H}\\displaystyle\\sum_{t,j\\in\\mathbb{Z}_{h}}\\displaystyle\\sum_{h=1}^{\\sum_{a_{h}}\\xi_{\\bar{t}_{i-1}}^{\\sum_{h}},\\mathbb{Z}_{\\bar{t}_{i-1},h}^{m_{l}}}\\displaystyle\\bar{f}_{1}(z_{h})-f_{2}(z_{h})\\|^{2}}\\\\ &{=\\displaystyle\\sum_{h=1}^{H}\\left[\\sum_{h,j\\in\\mathbb{Z}_{h}}\\frac{\\lambda+\\|f_{1}-f_{2}\\|\\frac{2}{\\mathcal{Z}_{\\bar{t}_{i-1},h}^{m}}}{\\lambda+\\|f_{1}-f_{2}\\|\\frac{2}{\\mathcal{Z}_{\\bar{t}_{i-1},h}^{m}}}-1\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "647 which gives $\\lambda+\\Vert f_{1}-f_{2}\\Vert_{Z_{k_{l},h}^{\\mathrm{ser}}}^{2}\\leq2\\bigl(\\lambda+\\Vert f_{1}-f_{2}\\Vert_{Z_{k_{l_{i-1}},h}^{\\mathrm{ser}}}^{2}\\bigr)$ for any $h\\in[H]$ and $f_{1},f_{2}\\in\\mathcal{F}_{h}$ . Then   \n648 we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}}^{2}(z_{h};Z_{k_{l_{i-1}},h}^{\\mathrm{ser}})\\le2D_{\\lambda,\\mathcal{F}}^{2}(z_{h};Z_{k_{l},h}^{\\mathrm{ser}})\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "649 for any $h\\in[H]$ and $z_{h}\\in{\\mathcal{S}}\\times{\\mathcal{A}}$ , and so ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{1\\leq\\displaystyle\\sum_{l=l_{i-1}+1}^{l_{i}}\\sum_{h=1}^{H}\\sum_{o_{h}\\in Z_{m,k_{l},h}^{\\mathrm{loc}}}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h};Z_{k_{l_{i-1}},h}^{\\mathrm{ser}})}\\\\ &{\\quad\\leq2\\displaystyle\\sum_{l=l_{i-1}+1}^{l_{i}}\\sum_{h=1}^{H}\\sum_{o_{h}\\in Z_{k_{l},h}^{\\mathrm{ser}}\\setminus X}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h};Z_{k_{l-1},h}^{\\mathrm{ser}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "650 and summing over $i=1,\\cdot\\cdot\\cdot,N-1$ that: ", "page_idx": 20}, {"type": "equation", "text": "$$\nN-1\\leq2\\sum_{h=1}^{H}\\sum_{l=1}^{L}\\sum_{o_{h}\\in Z_{k_{l},h}^{\\mathrm{ser}}\\backslash Z_{k_{l-1},h}^{\\mathrm{ser}}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h};Z_{k_{l-1},h}^{\\mathrm{ser}}\\big).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "651 If we apply the participant reordering trick and let $m_{k}=m_{k_{l}}$ for all $k\\in(k_{l-1},k_{l}]$ and $l\\in[L]$ , we   \n652 get $Z_{k_{l},h}^{\\mathrm{ser}}\\backslash Z_{k_{l-1},h}^{\\mathrm{ser}}=\\{o_{h}^{k}\\}_{k=k_{l-1}+1}^{k_{l}}$ , and so applying Lemma 6.3 and Lemma 6.2, we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle N-1\\leq2\\sum_{h=1}^{H}\\sum_{l=1}^{L}\\sum_{k=k_{l-1}+1}^{k_{l}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h}^{k};Z_{k_{l-1},h}^{\\mathrm{ser}}\\big)}\\\\ {\\displaystyle\\leq2(1+M\\alpha)\\sum_{h=1}^{H}\\sum_{l=1}^{L}\\sum_{k=k_{l-1}+1}^{k_{l}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h}^{k};Z_{k-1,h}^{\\mathrm{all}}\\big)}\\\\ {\\displaystyle\\leq2(1+M\\alpha)\\sum_{h=1}^{H}\\sum_{k=1}^{K}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h}^{k};Z_{k-1,h}^{\\mathrm{all}}\\big)}\\\\ {\\displaystyle\\leq C H(1+M\\alpha)\\operatorname*{dim}_{k=1}(\\mathcal{F},\\lambda/T)\\log(T/\\lambda)\\log T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "653 which gives the order of total number of epochs: ", "page_idx": 21}, {"type": "equation", "text": "$$\nN=O\\bigg(H(1+M\\alpha)\\dim_{E}(\\mathcal{F},\\lambda/T)\\log^{2}(T/\\operatorname*{min}\\{1,\\lambda\\})\\bigg).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "654 B.3 Proof of Regret Upper Bound ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "655 In this section, we prove the first half of Theorem 5.1, which gives an upper bound for the cumulative   \n656 regret of Algorithm 2.   \n657 Using the participant reordering trick, assume without loss of generality that the same agent is active   \n658 within the rounds $[k_{l},k_{l+1}-1]$ , i.e. $m_{k_{l}}=m_{k_{l}+1}=\\cdot\\cdot\\cdot=m_{k_{l+1}-1}$ . Under this assumption, we   \n659 have $k_{1}=1$ . ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "We first prove via induction that $Q_{h}^{*}\\le Q_{m,k,h}$ for any $m\\in[M],k\\in[K]$ and $h\\in[H\\!+\\!1]$ . This holds true for $h=H+1$ trivially since both value functions at $H+1$ are uniformly 0. Suppose we already have $Q_{h+1}^{*}\\leq Q_{m,k,h+1}$ , we have from Lemma B.2 that for the last communication round $k^{\\prime}$ for agent $m$ , the server functions satisfy $\\mathcal{T}_{h}Q_{k^{\\prime}+1,h+1}(s,a)\\leq\\widehat{f}_{k^{\\prime}+1,h}(s,a)+b_{k^{\\prime}+1,h}(s,a)=Q_{k^{\\prime}+1,h}(s,a)$ Couple this with the fact that $Q_{m,k,h}=Q_{k^{\\prime}+1,h}$ , we can prove that ", "page_idx": 21}, {"type": "equation", "text": "$$\nQ_{h}^{*}=\\mathcal{T}_{h}Q_{h+1}^{*}\\leq\\mathcal{T}_{h}Q_{m,k,h+1}\\leq Q_{m,k,h},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "660 which finishes the induction process. ", "page_idx": 21}, {"type": "text", "text": "661 Now let $a_{h}^{k*}:=\\operatorname*{argmax}_{a\\in\\mathcal{A}}Q_{h}^{*}(s_{h}^{k},a)$ be the best action at time $t$ , then $V_{h}^{*}(s_{h}^{k})=Q_{h}^{*}(s_{h}^{k},a_{h}^{k*})\\leq$   \n662 $Q_{m,k,h}{(s_{h}^{k},a_{h}^{k*})}\\leq Q_{m,k,h}{(s_{h}^{k},a_{h}^{k})}$ , where the second inequality is due to the choice of $a_{h}^{k}$ at round   \n663 $k$ . Hence we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Reg}(K)=\\displaystyle\\sum_{k=1}^{K}\\Big[V_{1}^{*}(x_{1}^{k})-V_{1}^{*\\,n}(s_{1}^{k})\\Big]}\\\\ &{\\qquad\\qquad\\le\\displaystyle\\sum_{k=1}^{K}\\mathrm{min}\\left\\{V_{m,k,1}(s_{1}^{k})-V_{1}^{*\\,n}(s_{1}^{k}),2H\\right\\}}\\\\ &{\\qquad=\\displaystyle\\sum_{k=1}^{K}\\displaystyle\\sum_{i=1}^{n}\\mathrm{min}\\left\\{\\mathbb{E}_{n}\\left[Q_{m,k,1}(s_{h}^{k},a_{h}^{k})-\\mathbb{T}_{\\mathbb{H}}Q_{m,k,1+1}(s_{h}^{k},a_{h}^{k})\\right],2\\right\\}}\\\\ &{\\qquad=\\displaystyle\\sum_{k=1}^{K}\\displaystyle\\sum_{i=1}^{n}\\mathrm{min}\\left\\{\\mathbb{E}_{n}\\left[\\widehat{f}_{n+1,k}(s_{h}^{k},a_{h}^{k})+b_{\\mathbb{H}+1,k}(s_{h}^{k},a_{h}^{k})-\\mathbb{T}_{\\mathbb{H}}Q_{m,k,1+1}(s_{h}^{k},a_{h}^{k})\\right],2\\right\\}}\\\\ &{\\qquad\\le\\displaystyle\\sum_{k=1}^{K}\\displaystyle\\sum_{i=1}^{n}\\mathrm{min}\\left\\{2b_{\\mathbb{H}-h}(s_{h}^{k},a_{h}^{k}),2\\right\\}}\\\\ &{\\qquad=\\displaystyle\\sum_{j=1}^{K}\\displaystyle\\sum_{k=1}^{n}b_{\\mathbb{H}+1,k}(s_{h}^{k})=2\\displaystyle\\sum_{i=1}^{K}\\sum_{j=1}^{n}\\mathrm{min}\\left\\{b_{m,k,h}(s_{h}^{k},1),1\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "664 where the second equality uses the Value-decomposition Lemma from Jiang et al. [2017], the second   \n665 inequality uses again Lemma B.2, and from the third inequality onward we let $k^{\\prime}$ be the last time   \n666 agent $m$ communicated with the server.   \n667 We now bound the second term here using the epoch scheme in Section B.2. We start by converting   \n668 the bonus term to uncertainty: ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{b_{m_{k_{l}},k_{l},h}(z_{h}^{k_{l}})=b_{k_{l-1},h}(z_{h}^{k_{l}})}\\\\ &{\\qquad\\qquad\\qquad\\leq C_{8}\\sqrt{\\beta_{k_{l}-1,h}^{2}+\\lambda}\\cdot D_{\\lambda,\\mathcal{F}_{h}}(z_{h}^{k_{l}};Z_{k_{l-1},h}^{\\mathrm{ser}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "669 Now consider the episodes in an epoch $i$ , specifically $\\{k_{l_{i-1}},k_{l_{i-1}+1},\\cdot\\cdot\\cdot,k_{l_{i}}\\}$ . For any $l_{i-1}<l<l_{i}$ ,   \n670 since $Z_{k_{l_{i-1}},h}^{\\mathrm{ser}}\\subseteq Z_{k_{l-1},h}^{\\mathrm{ser}}$ , we can deduce that ", "page_idx": 22}, {"type": "equation", "text": "$$\nD_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k_{l}};Z_{k_{l-1},h}^{\\mathrm{ser}})\\le D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k_{l}};Z_{k_{l_{i-1}},h}^{\\mathrm{ser}})\\le2D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k_{l}};Z_{k_{l},h}^{\\mathrm{ser}}),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "671 where the second inequality is borrowed from (21) from Section B.2. Therefore continuing from   \n672 (24), ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i=1}^{L}\\sum_{h=1}^{H}\\operatorname*{min}\\{b_{m_{k_{l}},k_{l},h}(z_{h}^{k_{l}}),1\\}\\leq\\displaystyle\\sum_{l\\not\\in\\{l_{i}\\}_{i=1}^{N}}\\sum_{h=1}^{H}\\left[\\sqrt{2}C_{B}\\sqrt{\\beta_{k_{l}-1,h}^{2}+\\lambda}\\cdot D_{\\lambda,\\mathcal{F}_{h}}(z_{h}^{k_{l}};Z_{k_{l},h}^{\\mathrm{ser}})\\right]+\\sum_{i=1}^{N}\\sum_{h=1}^{H}}\\\\ &{\\leq\\sqrt{2}C_{B}\\displaystyle\\sum_{l=1}^{L}\\sum_{h=1}^{H}D_{\\lambda,\\mathcal{F}_{h}}(z_{h}^{k_{l}};Z_{k_{l},h}^{\\mathrm{ser}})\\sqrt{\\beta_{h}^{2}+\\lambda}+N H.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "673 Now combine this result with the first term in (23) and use again (24), we get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{seg}(K)\\le C_{B}\\sum_{l=1}^{L}\\sum_{k=l+1}^{k_{l+1}-1}\\sum_{h=1}^{H}\\left[D_{\\lambda,\\mathcal{F}_{h}}(z_{h}^{k};Z_{k,h}^{\\mathrm{srr}})\\sqrt{\\beta_{h}^{2}+\\lambda}\\right]+\\sqrt{2}C_{B}\\sum_{l=1}^{L}\\sum_{h=1}^{H}\\left[D_{\\lambda,\\mathcal{F}_{h}}(z_{h}^{k_{l}};Z_{k,h}^{\\mathrm{srr}})\\sqrt{\\beta_{h}^{2}+\\lambda}\\right]}}\\\\ &{}&{\\le\\sqrt{2}C_{B}\\sum_{l=1}^{L}\\ \\sum_{k=k_{l}}^{L}\\ \\displaystyle\\sum_{h=1}^{H}\\left[D_{\\lambda,\\mathcal{F}_{h}}(z_{h}^{k};Z_{k,h}^{\\mathrm{srr}})\\sqrt{\\beta_{h}^{2}+\\lambda}\\right]+N H}\\\\ &{}&{\\le\\sqrt{2}C_{B}\\left[\\displaystyle\\sum_{l=1}^{L}\\ \\sum_{k=k_{l}}^{k_{l+1}-1}\\sum_{h=1}^{H}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{k,h}^{\\mathrm{srr}})\\right]^{1/2}\\left[\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\big(\\beta_{h}^{2}+\\lambda\\big)\\right]^{1/2}+N H.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "674 According to Lemma 6.3 and Lemma 6.2, the term ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{l=1}^{L}\\sum_{k=k_{l}}^{k_{l+1}-1}\\sum_{h=1}^{H}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{k_{l},h}^{\\mathrm{ser}})\\le(1+M\\alpha)\\sum_{l=1}^{L}\\sum_{k=k_{l}}^{k_{l+1}-1}\\sum_{h=1}^{H}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{k-1,h}^{\\mathrm{all}})}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\le(1+M\\alpha)\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{k-1,h}^{\\mathrm{all}})}\\\\ &{\\qquad\\qquad\\qquad\\le H(1+M\\alpha)\\operatorname*{dim}_{E}(\\mathcal{F},\\lambda/T)\\log(T/\\lambda)\\log T.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "675 Now with $\\gamma=O(1/K H)$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\lambda_{h}=O(1)\\beta_{h+1}+C_{\\beta}\\bigg[\\sqrt{\\lambda}+H\\bigg(\\sqrt{(1+M\\alpha)\\log(3H N_{h}(\\gamma)/\\delta)}+M\\sqrt{\\alpha\\log(3H M N_{h}(\\gamma)/\\delta)}\\bigg)\\bigg]\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "676 therefore, with $C(M,\\alpha)=\\sqrt{1+M\\alpha}+M\\sqrt{\\alpha}$ and the upper bound for number of epochs $N$ in   \n677 (22), we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{l=1}^{L}\\sum_{k=k_{l}+1}^{k_{l+1}-1}\\sum_{h=1}^{H}b_{k_{l},h}(z_{h}^{k})}\\\\ &{\\le O\\bigg(\\big[H(1+M\\alpha)\\dim_{E}(\\mathcal{F},\\lambda/K)\\log^{2}(K/\\operatorname*{min}\\{1,\\lambda\\})\\big]^{1/2}\\bigg[K\\displaystyle\\sum_{h=1}^{H}(\\beta_{h}^{2}+\\lambda)\\bigg]^{1/2}+H N\\bigg)}\\\\ &{=O\\bigg(H\\sqrt{K}\\tilde{\\beta}_{2}\\sqrt{(1+M\\alpha)\\dim_{E}(\\mathcal{F},\\lambda/K)}\\log(K/\\operatorname*{min}\\{1,\\lambda\\})}\\\\ &{\\qquad+\\ H^{2}(1+M\\alpha)\\dim_{E}(\\mathcal{F},\\lambda/K)\\log^{2}(K/\\operatorname*{min}\\{1,\\lambda\\})\\bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "678 where $\\widetilde{\\beta}_{2}=C_{\\beta,2}\\bigg[\\sqrt{\\lambda}+H C(M,\\alpha)\\log\\big(H M N(\\mathcal{F},\\gamma)N(\\mathcal{W},\\gamma)/\\delta\\big)\\bigg]$ is the choice of $\\beta_{k,h}$ in the   \n679 algorithm. ", "page_idx": 23}, {"type": "text", "text": "680 B.4 Proof of Communication Cost ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "681 Next up, we calculate the communication complexity of Algorithm 2 and prove the second half of   \n682 Theorem 5.1. For each communication round $k_{l}$ , assume the last time before $k_{l}$ when the agent   \n683 $m\\,=\\,m_{k_{l}}$ communicated with the server was $k_{l^{\\prime}}$ , then by the communication rule there exists   \n684 $h_{l}\\in[H]$ such that $\\begin{array}{r}{\\sum_{o_{h_{l}}\\in Z_{m,k_{l},h_{l}}^{\\mathrm{loc}}}b_{k_{l^{\\prime}},h_{l}}^{2}(z_{h_{l}})/(\\beta_{k_{l^{\\prime}},h_{l}}^{2}+\\lambda)^{\\ast}\\geq\\alpha,}\\end{array}$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{o_{h_{l}}\\in Z_{m,k_{l},h_{l}}^{\\mathrm{loc}}}D_{\\lambda,\\mathcal{F}_{h_{l}}}^{2}(z_{h_{l}};Z_{m,k_{l},h_{l}}^{\\mathrm{up}})\\ge\\sum_{o_{h_{l}}\\in Z_{m,k_{l},h_{l}}^{\\mathrm{loc}}}\\frac{\\left[b_{k_{l^{\\prime}},h_{l}}(z_{h_{l}})/C\\right]^{2}}{\\beta_{k_{l^{\\prime}},h_{l}}^{2}+\\lambda}\\ge\\frac{\\alpha}{C^{2}},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "685 Next we will make use of the epoch segmentation scheme in Section B.2. For the $i$ -th epoch consisting   \n686 of the time steps $[k_{l_{i-1}},k_{l_{i}})$ , we have the inequality ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{1\\geq\\displaystyle\\sum_{l=l_{i-1}+1}^{l_{i}-1}\\sum_{h=1}^{H}\\sum_{o_{h}\\in\\ensuremath{\\mathbb{Z}}_{m,k_{l},h}^{\\mathrm{loc}}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h};\\ensuremath{\\boldsymbol{Z}}_{k_{l_{i-1}},h}^{\\mathrm{ser}}\\big)}\\\\ &{\\geq\\displaystyle\\sum_{l=l_{i-1}+1}^{l_{i}-1}\\sum_{h=1}^{H}\\sum_{o_{h}\\in\\ensuremath{\\mathbb{Z}}_{m,k_{l},h}^{\\mathrm{loc}}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h};\\ensuremath{\\boldsymbol{Z}}_{m,k_{l},h}^{\\mathrm{up}}\\cup\\ensuremath{\\boldsymbol{Z}}_{k_{l_{i-1}},h}^{\\mathrm{ser}}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For $m\\:\\in\\:[M]$ , assume the agent $m$ communicated with the server a total of $n_{m}$ times within $[k_{l_{i-1}},k_{l_{i}})$ $m_{k_{l}}=m$ e, nt heexrcee eptx ifsotrs $l^{\\prime}\\in[l_{i-1},l)$ eswei tcho $m_{k_{l^{\\prime}}}=m$ ,o tnh ruosu nwdes ,h faovre $Z_{m,k_{l},h}^{\\mathrm{up}}\\supset Z_{m,k_{l^{\\prime}}+1,h}^{\\mathrm{up}}=$ $l\\in[l_{i-1}+1,l_{i}-1]$ $Z_{k_{l^{\\prime}},h}^{\\mathrm{ser}}\\supset Z_{k_{l_{i-1}},h}^{\\mathrm{ser}}$ Zskelr ,h for all h \u2208[H]. With this we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{h=1}^{H}\\sum_{o_{h}\\in\\mathbb{Z}_{m,k_{l},h}^{\\mathrm{loc}}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\left(z_{h};Z_{m,k_{l},h}^{\\mathrm{up}}\\cup Z_{k_{l_{i-1}},h}^{\\mathrm{ser}}\\right)=\\sum_{h=1}^{H}\\sum_{o_{h}\\in Z_{m,k_{l},h}^{\\mathrm{lec}}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\left(z_{h};Z_{m,k_{l},h}^{\\mathrm{up}}\\right)\\geq\\frac{\\alpha}{4C^{2}},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "687 therefore ", "page_idx": 23}, {"type": "equation", "text": "$$\n1\\geq\\sum_{m=1}^{M}(n_{m}-1)\\cdot{\\frac{\\alpha}{4C^{2}}}\\Rightarrow\\sum_{m=1}^{M}n_{m}\\leq M+{\\frac{4C^{2}}{\\alpha}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Notice that $\\begin{array}{r}{\\sum_{m=1}^{M}n_{m}=l_{i}-l_{i-1}}\\end{array}$ is the number of communication rounds within $[k_{l_{i-1}},k_{l_{i}})$ , hence summing over $i$ the total number of communication rounds is upper bounded by $N(M+4C^{2}/\\alpha)$ . Combine this with the result in (22), we have the total number of communication rounds throughout the algorithm is ", "page_idx": 23}, {"type": "equation", "text": "$$\nO\\bigg(H\\frac{(1+M\\alpha)^{2}}{\\alpha}\\dim_{E}(\\mathcal{F},\\lambda/K)\\log^{2}(K/\\operatorname*{min}\\{1,\\lambda\\})\\bigg).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "688 C Proof of Auxiliary Lemmas ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "689 In this section we prove all the auxiliary lemmas in Section A.1 and Section $B.1$ . Note that some of   \n690 these lemmas are very similar in nature, for which we will only give the proof for the version for the   \n691 MDPs case, and briefly remark on the version for the bandit case. ", "page_idx": 23}, {"type": "text", "text": "692 C.1 Proof of Lemma A.1 and Lemma B.1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "693 Here we prove Lemma B.1 in detail. The proof for Lemma A.1 is very similar, and so we will only   \n694 give a short remark on how to apply this to the bandit case.   \n695 Proof of Lemma B.1. First, for an episode $\\textit{k}\\in\\ [K]$ and agent $m\\:\\in\\:[M]$ such that $m$ does not   \n696 communicate with the server at episode $k$ (either $m$ is not participating or $k$ is not a communication ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "697 round), from the communication criterion we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha\\geq\\displaystyle\\sum_{o_{h}\\in\\mathbb Z_{m,k}^{\\infty},h_{k}^{\\infty},h_{k}^{\\infty}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\beta_{h,h}^{2}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\sum_{\\substack{j,h,h}\\in\\mathbf{\\lambda}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\beta_{h,h}^{2}h_{\\overline{{\\lambda}},h_{h}^{\\infty},h}(a)}\\\\ &{~\\geq\\displaystyle\\sum_{o_{h}\\in\\mathbb Z_{m,k}^{\\infty},h_{k}^{\\infty},h_{k}^{\\infty}}D_{\\lambda,\\overline{{\\lambda}}_{\\mathcal{X}_{h}}}^{2}(z_{h};Z_{k}^{\\infty},h)}\\\\ &{=\\displaystyle\\sum_{o_{h}\\in\\mathbb Z_{m,k}^{\\infty},h_{k}^{\\infty},h_{l}^{\\infty}\\in\\mathbb F_{h}}\\displaystyle\\operatorname*{sup}_{\\lambda\\in\\mathbb Z_{h}}\\displaystyle\\frac{|f_{1}(z_{h})-f_{2}(z_{h})|^{2}}{\\lambda+|f_{1}-f_{2}|\\left|Z_{k^{\\infty},h}^{\\infty}\\right.}}\\\\ &{\\geq\\displaystyle\\sum_{f_{1},f_{2}\\in\\mathbb F_{h}}\\displaystyle\\frac{|f_{1}-f_{2}||_{Z_{m,k}^{\\infty},h_{k}}^{2}}{\\lambda+|f_{1}-f_{2}||_{Z_{m,k}^{\\infty},h}^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "$k^{\\prime}$ .  fOorb saegrveinnt g $m$ .a t $f_{1},f_{2}\\;\\in\\;\\mathcal{F}_{h}$ s, $\\begin{array}{r}{(1/\\alpha)\\|f_{1}-f_{2}\\|_{Z_{m,k,h}^{\\mathrm{loc}}}^{2}\\leq\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k^{\\prime},h}^{\\mathrm{ser}}}^{2}}\\end{array}$ $\\begin{array}{r}{Z_{k^{\\prime},h}^{\\mathrm{ser}}\\subset Z_{k,h}^{\\mathrm{ser}}=\\bigcup_{m^{\\prime}=1}^{M}Z_{m^{\\prime},k,h}^{\\mathrm{up}}}\\end{array}$ the first conclusion that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{1}{\\alpha}\\|f_{1}-f_{2}\\|_{Z_{m,k,h}^{\\mathrm{loc}}}^{2}\\leq\\lambda+\\sum_{m^{\\prime}=1}^{M}\\|f_{1}-f_{2}\\|_{Z_{m^{\\prime},k,h}^{\\mathrm{up}}}^{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "698 Second, for any $f_{1},f_{2}\\in\\mathcal{F}_{h}$ , from the above conclusion we have for any $k\\in[K]\\backslash\\{k_{l}\\}_{l=1}^{L}$ that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k,h}^{\\mathrm{sr}}}^{2}=\\lambda+\\sum_{m=1}^{M}\\|f_{1}-f_{2}\\|_{Z_{m,k,h}^{\\mathrm{sp}}}^{2}}}\\\\ &{}&{\\geq\\displaystyle\\frac{1}{M\\alpha}\\sum_{m=1}^{M}\\|f_{1}-f_{2}\\|_{Z_{m,k,h}^{\\mathrm{tx}}}^{2}}\\\\ &{}&{=\\displaystyle\\frac{1}{M\\alpha}\\|f_{1}-f_{2}\\|_{Z_{k,h}^{\\mathrm{sq}}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "699 and when $k=k_{l}$ for some $l\\in[L]$ , we have alternatively ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\lambda+\\|f_{1}-f_{2}\\|_{Z_{w,h}^{w}}^{2}=\\lambda+\\displaystyle\\sum_{m^{\\prime}\\neq m_{t}}\\|f_{1}-f_{2}\\|_{Z_{m^{\\prime},h,h}^{w}}^{2}+\\|f_{1}-f_{2}\\|_{Z_{m_{t},k,h}^{w}}^{2}\\cup Z_{m_{k},k,h}^{w}}\\\\ {\\displaystyle\\geq\\lambda+\\displaystyle\\sum_{m=1}^{M}\\|f_{1}-f_{2}\\|_{Z_{m,h,h}^{w}}^{2}}\\\\ {\\displaystyle\\geq\\frac{1}{(M-1)\\alpha}\\displaystyle\\sum_{m^{\\prime}\\neq m_{k}}\\|f_{1}-f_{2}\\|_{Z_{m^{\\prime},k,h}^{w}}^{2}}\\\\ {\\displaystyle}&{\\geq\\frac{1}{M\\alpha}\\|f_{1}-f_{2}\\|_{Z_{k,h}^{w}}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Either way, we can deduce for any $k\\in[K]$ that ", "page_idx": 24}, {"type": "equation", "text": "$$\n(1+M\\alpha)\\big(\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k,h}^{\\mathrm{ser}}}^{2}\\big)\\geq\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k,h}^{\\mathrm{all}}}^{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "700 Finally, from the above we immediately have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{\\boldsymbol{\\lambda},\\mathcal{F}}^{2}(z_{h};Z_{k,h}^{\\mathrm{ser}})=\\underset{f_{1},f_{2}\\in\\mathcal{F}_{h}}{\\operatorname*{sup}}\\frac{[f_{1}(z_{h})-f_{2}(z_{h})]^{2}}{\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k,h}^{\\mathrm{ser}}}^{2}}}\\\\ &{\\qquad\\qquad\\qquad\\leq(1+M\\alpha)\\underset{f_{1},f_{2}\\in\\mathcal{F}}{\\operatorname*{sup}}\\frac{[f_{1}(z_{h})-f_{2}(z_{h})]^{2}}{\\lambda+\\|f_{1}-f_{2}\\|_{Z_{k,h}^{\\mathrm{sql}}}^{2}}}\\\\ &{\\qquad\\qquad=(1+M\\alpha)D_{\\boldsymbol{\\lambda},\\mathcal{F}}^{2}(a;Z_{k,h}^{\\mathrm{all}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "702 Remark C.1. Notice that this prove does not depend on the multi-level structure of episodic MDPs,   \n703 but is a direct result of the communication criterion and protocol. This means the proof can be   \n704 converted to the bandit case of Lemma A.1 without any essential changes: simply change episode $k$   \n705 into time step $t$ , disregard all mentions of level $h$ , and consider $z=a$ instead of $z=(s,a)$ . ", "page_idx": 25}, {"type": "text", "text": "706 C.2 Proof of Lemma A.2 and Lemma B.2 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "707 We begin with the proof of Lemma A.2, which is an almost direct application of Lemma D.3. ", "page_idx": 25}, {"type": "text", "text": "Proof of Lemma A.2. We invoke Lemma D.3 with $\\epsilon_{0}=0$ , then with probability at least $1-\\delta$ , for all t \u2208{tl}lL=1, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{a,r\\right)\\in Z_{\\tau}^{\\kappa}}\\left(\\widehat{f}_{t+1}(a)-f^{*}(a)\\right)^{2}\\leq C_{\\mathrm{ERM}}\\bigg[\\lambda+\\gamma^{2}T+\\gamma T R+R^{2}(1+M\\alpha)\\log(3N/\\delta)+R^{2}M^{2}\\alpha\\log(3N M/\\delta)\\bigg]\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "708 if we let $\\begin{array}{r l r}{\\gamma}&{{}=}&{O(1/T)}\\end{array}$ be sufficiently small and take $\\begin{array}{r l r}{\\widetilde{\\beta}_{1}}&{{}=}&{C_{\\beta,1}\\bigg[\\sqrt{\\lambda}\\ \\ +}\\end{array}$   \n709 $R C(M,\\alpha)\\log(3M N(\\mathcal{F},\\gamma)/\\delta)\\bigg]$ with $C_{\\beta,1}~=~\\sqrt{C_{\\mathrm{ERM}}}~=~6$ . Thus taking $\\beta_{t}~=~\\widetilde{\\beta}_{1}$ , accord  \n710 ing to the definition of $\\mathcal{F}_{t+1}$ , this directly implies $f^{*}\\in\\mathcal{F}_{t+1}$ . With this, since the bonus function satisfy ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "equation", "text": "$$\nb_{t+1}(a)\\geq|f_{1}(a)-f_{2}(a)|,\\quad\\forall f_{1},f_{2}\\in\\mathcal{F}\\quad\\mathrm{s.t.}\\quad\\sum_{(a,r)\\in\\ensuremath{Z^{\\mathrm{sr}}}}\\left(f_{1}(a)-f_{2}(a)\\right)^{2}\\leq\\beta_{t}^{2},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "711 which is based on the first property of the bonus oracle in Definition 4.1, by taking $f_{1}=\\widehat{f}_{t+1}$ and   \n712 $f_{2}=f^{*}$ we get for any $a\\in{\\mathcal{A}}$ that $b_{t+1}(a)\\geq|f_{*}(a)-\\widehat{f}_{t+1}(a)|$ , which finishes the proof. \u53e3   \n713 Next we prove Lemma B.2, which is more challenging and requires an analysis on the least squares   \n714 value iteration method.   \n715 Proof of Lemma B.2. Take $\\mathcal{F}_{h+1,\\gamma}$ as a $\\gamma$ -cover of $\\mathcal{F}_{h+1}$ , and $\\mathcal{W}_{h+1,\\gamma}$ as a $\\gamma$ -cover of $\\mathcal{W}_{h+1}$ . Select   \n716 $\\bar{f}_{k+1,h+1}\\in\\mathcal{F}_{h+1,\\gamma}\\oplus\\mathcal{W}_{h+1,\\gamma}$ so that $\\|Q_{k+1,h+1}-\\bar{f}_{k+1,h+1}\\|_{\\infty}\\leq\\bar{\\epsilon}:=(1+\\beta_{k+1,h+1}$ 1)\u03b3. For   \n717 $o_{h}\\,=\\,\\left(s_{h},a_{h},r_{h},s_{h+1}\\right)$ , define the corresponding $y_{h}\\,=\\,r_{h}\\,+\\,V_{k+1,h+1}\\bigl(s_{h+1}\\bigr)$ and $\\bar{y}_{h}~=~r_{h}+$   \n718 $\\mathrm{sup}_{a\\in\\mathcal{A}}\\,\\bar{f}_{k+1,h+1}(s_{h+1},a)$ . Let ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "equation", "text": "$$\n\\widetilde{f}_{k+1,h}=\\underset{f_{h}\\in\\mathcal{F}_{h}}{\\mathrm{argmin}}\\,\\sum_{o_{h}\\in Z_{k,h}^{\\mathrm{ser}}}\\big(f_{h}(s_{h},a_{h})-\\bar{y}_{h}\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "719 Then we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left(\\sum_{o_{h}\\in\\mathbb{Z}_{k,h}^{\\times}}\\left(\\widehat{f}_{k+1,h}(s_{h},a_{h})-\\bar{y}_{h}\\right)^{2}\\right)^{1/2}}\\leq\\bigg(\\sum_{o_{h}\\in\\mathbb{Z}_{k,h}^{\\times}}\\left(\\widehat{f}_{k+1,h}(s_{h},a_{h})-y_{h}\\right)^{2}\\bigg)^{1/2}+\\bar{\\epsilon}\\sqrt{k}}\\\\ &{}&{\\leq\\bigg(\\displaystyle\\sum_{o_{h}\\in\\mathbb{Z}_{k,h}^{\\times}}\\left(\\widetilde{f}_{k+1,h}(s_{h},a_{h})-y_{h}\\right)^{2}\\bigg)^{1/2}+\\bar{\\epsilon}\\sqrt{k}}\\\\ &{}&{\\leq\\bigg(\\displaystyle\\sum_{o_{h}\\in\\mathbb{Z}_{k,h}^{\\times}}\\left(\\widetilde{f}_{k+1,h}(s_{h},a_{h})-\\bar{y}_{h}\\right)^{2}\\bigg)^{1/2}+2\\bar{\\epsilon}\\sqrt{k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "720 Now notice that $\\mathbb{E}\\bar{y}_{h}\\,=\\,\\mathcal{T}_{h}\\bar{f}_{k+1,h}\\big(\\boldsymbol{s}_{h},\\boldsymbol{a}_{h}\\big)$ , and the difference $\\bar{y}_{h}-\\mathcal{T}_{h}\\bar{f}_{k+1,h}(s_{h},a_{h})$ is bounded   \n721 in $[-H,H]$ , hence we may apply Lemma D.3 with $f^{*}={\\cal T}_{h}\\bar{f}_{k+1,h}$ , $r_{t}\\,=\\,\\bar{y}_{h}$ , $R\\,=\\,H$ , $\\epsilon_{0}\\,=\\,2\\bar{\\epsilon}$   \n722 and $\\delta=\\delta/3H N(\\mathcal{F}_{h+1},\\gamma)\\cdot N(\\mathcal{W}_{h+1},\\gamma)$ , taking a union bound over $\\bar{f}\\in\\mathcal{F}_{h+1,\\gamma}\\oplus\\mathcal{W}_{h+1,\\gamma}$ and ", "page_idx": 25}, {"type": "text", "text": "723 $h\\in[H]$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\bigg(\\displaystyle\\sum_{o_{h}\\in\\mathbb{Z}_{k,h}^{\\times}}\\big(\\widehat f_{k+1,h}(s_{h},a_{h})-7h Q_{k+1,h+1}(s_{h},a_{h})\\big)^{2}\\bigg)^{1/2}}\\\\ &{\\le\\bigg(\\displaystyle\\sum_{o_{h}\\in\\mathbb{Z}_{k,h}^{\\times}}\\big(\\widehat f_{k+1,h}(s_{h},a_{h})-7h\\widehat f_{k+1,h+1}(s_{h},a_{h})\\big)^{2}\\bigg)^{1/2}+\\gamma\\sqrt{k}}\\\\ &{\\le\\sqrt{C_{\\mathrm{ERM}}}\\sqrt{\\lambda+(\\gamma+2\\bar{\\epsilon})^{2}K+(\\gamma+2\\bar{\\epsilon})K H+H^{2}(1+M\\alpha)\\log(3H N_{h}(\\gamma)/\\delta)+H^{2}M^{2}\\alpha\\log(3H M\\gamma)/\\delta)}}\\\\ &{\\le\\sqrt{C_{\\mathrm{ERM}}}\\bigg[\\sqrt{\\lambda}+\\gamma(3+2\\beta_{k+1,h+1})\\sqrt{K}+\\sqrt{\\gamma(3+2\\beta_{k+1,h+1})K H}+H C(M,\\alpha)\\sqrt{\\log(3H M N_{h}(\\gamma)/\\delta)}\\bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $N_{h}(\\gamma)=N(\\mathcal{F}_{h},\\gamma)\\cdot N(\\mathcal{F}_{h+1},\\gamma)\\cdot N(\\mathcal{W}_{h+1},\\gamma)$ . By taking $\\gamma=1/(C_{\\gamma}K H)$ with sufficiently large absolute constant $C_{\\gamma}$ (for example, $C_{\\gamma}=20$ ), the second and third terms within the bracket above are both less than $(\\mathrm{i}/2)\\beta_{k+1,h+1}$ , and hence we can easily prove via induction on $h$ that the above is no greater than ${\\widetilde{\\beta}}_{2}$ , where ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\widetilde{\\beta}_{2}=C_{\\beta,2}\\bigg[\\sqrt{\\lambda}+H C(M,\\alpha)\\sqrt{\\log(3H M N(\\gamma)/\\delta)}\\bigg]\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "724 with $C_{\\beta,2}=2\\sqrt{C_{\\mathrm{ERM}}}=12$ and $N(\\gamma)=\\operatorname*{max}_{h\\in[H]}N_{h}(\\gamma)$ . ", "page_idx": 26}, {"type": "text", "text": "725 ", "page_idx": 26}, {"type": "text", "text": "726 C.3 Proof of Lemma A.3 and Lemma B.3 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "727 In this section we prove Lemma B.3 in detail. The proof for Lemma A.3 is very similar, and so we   \n728 will again only give a short remark on how to apply this to the bandit case. ", "page_idx": 26}, {"type": "text", "text": "729 Proof of Lemma B.3. We fix the level $h\\in[H]$ throughout the proof. For an index set $K_{0}\\subseteq[K]$ , we   \n730 denote $\\mathcal{Z}(K_{0}):=\\{z_{h}^{k}:k\\in K_{0}\\}$ . First, let $n=\\lceil\\log(K/\\lambda)/\\log2\\rceil$ , and we divide the set of episodes $\\boldsymbol{\\kappa}=[K]$ into $n+1$ disjoint episode sets as follows. For any $1\\leq l\\leq L$ and $k_{l}\\leq k<k_{l+1}$ , let ", "page_idx": 26}, {"type": "equation", "text": "$$\n(\\bar{f}_{k,1},\\bar{f}_{k,2})=\\underset{f_{1},f_{2}\\in\\mathcal{F}_{h}}{\\operatorname{argmax}}\\,\\frac{\\left(f_{1}(z_{h}^{k})-f_{2}(z_{h}^{k})\\right)^{2}}{\\lambda+\\Vert f_{1}-f_{2}\\Vert_{Z_{h,k-1}^{\\mathrm{all}}}^{2}},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "731 and define $L_{k}:S\\times A\\to\\mathbb{R}$ as $L_{k}(z)=\\left(\\bar{f}_{k,1}(z)-\\bar{f}_{k,2}(z)\\right)^{2}$ . Now we define $\\begin{array}{r}{\\mathcal{K}^{\\iota}:=\\left\\{k\\in\\mathcal{K}:\\right.}\\end{array}$   \n732 $L_{k}(z_{h}^{k})\\in(2^{-\\iota-1},2^{-\\iota}]\\}$ for $\\iota\\in\\{0,1,\\cdot\\cdot\\cdot\\,,n-1\\}$ and $\\mathcal{K}^{n}:=\\{k\\in\\mathcal{K}:L_{k}(z_{h}^{k})\\in[0,2^{-n}]\\}$ . We   \n733 note that for $k\\in\\kappa^{n}$ , $L_{k}(z_{h}^{k})\\le\\lambda/K$ .   \n734 Now define the mapping $\\tau:[K]\\rightarrow[K]$ , such that for any $k\\in[K],\\tau(k)$ is the last episode when   \n735 agent $m_{k}$ communicated with the server (not including $k$ ). We will bound $\\begin{array}{r}{\\sum_{k\\in\\mathcal{K}^{\\iota}}D_{\\lambda,\\mathcal{F}_{h}}^{2}\\big(z_{h}^{k};Z_{h,k-1}^{\\mathrm{all}}\\big)}\\end{array}$   \n736 for $\\iota\\in\\{0,\\cdots\\,,n-1\\}$ .   \n737 For a fixed $\\iota\\leq n-1$ , we now decompose $\\begin{array}{r}{\\mathcal{K}^{\\iota}=\\bigcup_{j=1}^{n^{\\iota}+1}\\mathcal{K}_{j}^{\\iota}}\\end{array}$ , where $n^{\\iota}=\\left\\lceil|K^{\\iota}|/\\dim_{E}(\\mathcal{F}_{h},2^{-\\iota-1})\\right\\rceil$ .   \n738 We start off each set $\\kappa_{j}^{\\iota}=\\emptyset$ , and fill them up gradually by iterating through $k\\,\\in\\,\\kappa^{\\iota}$ one by one   \n739 in increasing order to decide which subset $\\kappa_{j}^{\\iota}$ should $k$ belong to. Specifically, we define $j(k)$ to   \n740 be the smallest index $j<n^{\\iota}$ such that is $z_{h}^{k}$ is $2^{-(\\iota+1)/2}$ -independent of $\\mathcal{Z}(K_{j}^{\\iota})$ , and assign $k$ to   \n741 the set $K_{j(k)}^{\\iota}$ . If such a $j$ does not exist, we simply let $j(k)=n^{\\iota}+1$ assign $k$ to $K_{n^{\\iota}+1}^{\\iota}$ . Finally   \n74 2 after the assignment process, we define $K_{j,k}^{\\iota}\\,=\\,K_{j}^{\\iota}\\cap[k]$ for any $k\\ \\in\\ [K]$ . Then we have the   \n743 elements added into $\\kappa_{j(k)-1,k}^{\\iota}$ form a sequence where each data corresponding to a new member   \n744 is $2^{-(\\iota+1)/2}$ -independent of the old members, and so there are no more than $\\mathrm{dim}_{E}({\\mathcal{F}}_{h},2^{-\\iota-1})$   \n745 members within each of them. Moreover, for all $k\\in\\kappa^{\\iota}$ that $z_{h}^{k}$ is $2^{-(\\iota+1)/2}$ -dependent on each of   \n746 Z(K\u03b91,k), \u00b7 \u00b7 \u00b7 , Z(K\u03b9j(k)\u22121,k). ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "Now for any $k\\in\\kappa^{\\iota}$ by the definition of $\\kappa^{\\iota}$ , we have $\\left(\\bar{f}_{k,1}(z_{h}^{k})\\!-\\!\\bar{f}_{k,2}(z_{h}^{k})\\right)^{2}\\geq2^{-\\iota-1}$ . This combined with the $2^{-\\iota-1}$ -dependencies imply that for each $j^{\\prime}=1,\\cdots\\,,j(k)\\!-\\!1,\\|\\bar{f}_{k,1}\\!-\\!\\bar{f}_{k,2}\\|_{\\mathcal{Z}(\\mathcal{K}_{j^{\\prime},k}^{\\iota})}^{2}\\geq2^{-\\iota-1}$ . ", "page_idx": 26}, {"type": "text", "text": "Notice that $\\mathcal{Z}(K_{j^{\\prime},k}^{\\iota})\\subset Z_{h,k-1}^{\\mathrm{all}}$ for any $j^{\\prime}\\in[j(k)-1]$ , and that $\\mathcal{Z}(K_{j^{\\prime},k}^{\\iota})$ for $j^{\\prime}\\in[j(k)-1]$ are disjoint, therefore ", "page_idx": 27}, {"type": "equation", "text": "$$\n(j(k)-1)2^{-\\iota-1}\\le\\sum_{j^{\\prime}=1}^{j(k)-1}\\|\\bar{f}_{k,1}-\\bar{f}_{k,2}\\|_{\\mathcal{Z}(\\mathcal{K}_{j^{\\prime},k}^{\\iota})}^{2}\\le\\|\\bar{f}_{k,1}-\\bar{f}_{k,2}\\|_{Z_{h,k-1}^{\\mathrm{all}}}^{2}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "747 It follows that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{h,k-1}^{\\mathrm{all}})=\\frac{\\big(\\bar{f}_{k,1}(z_{h}^{k})-\\bar{f}_{k,2}(z_{h}^{k})\\big)^{2}}{\\lambda+\\|\\bar{f}_{k,1}-\\bar{f}_{k,2}\\|_{Z_{h,k-1}^{\\mathrm{all}}}^{2}}}}\\\\ &{\\leq\\frac{2^{-\\iota}}{\\lambda+(j(k)-1)2^{-\\iota-1}}}\\\\ &{=\\frac{2}{(j(k)-1)+2^{\\iota+1}\\lambda},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "748 where the first inequality uses the definition of $\\kappa^{\\iota}$ . Summing over $k\\in\\kappa^{\\iota}$ , we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{\\in\\mathcal{K}^{\\varepsilon}}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{h,k-1}^{\\mathrm{all}})=\\sum_{j=1}^{n^{\\varepsilon}+1}\\sum_{k\\in\\mathcal{K}_{j}^{\\varepsilon}}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{h,k-1}^{\\mathrm{all}})}}\\\\ &{\\leq\\displaystyle\\sum_{j=1}^{n^{\\varepsilon}}\\frac{2\\big|K_{j}^{\\varepsilon}\\big|}{(j-1)+2^{\\varepsilon+1}\\lambda}+\\frac{2\\big|K_{n^{\\varepsilon}+1}^{\\varepsilon}\\big|}{n^{\\varepsilon}+2^{\\varepsilon+1}\\lambda}}\\\\ &{\\leq\\frac{2\\dim_{E}\\left(\\mathcal{F}_{h},2^{-\\varepsilon-1}\\right)}{2^{\\varepsilon+1}\\lambda}+\\displaystyle\\sum_{j=2}^{n^{\\varepsilon}}\\frac{2\\dim_{E}\\left(\\mathcal{F}_{h},2^{-\\varepsilon-1}\\right)}{j-1}+2\\big|K^{\\varepsilon}\\big|\\cdot\\frac{\\dim_{E}\\left(\\mathcal{F}_{h},2^{-\\varepsilon}\\right)}{\\big|K^{\\varepsilon}\\big|}}\\\\ &{\\leq\\dim_{E}(\\mathcal{F}_{h},2^{-\\varepsilon-1})\\big(2\\log n^{\\varepsilon}+4+1/(2^{\\varepsilon}\\lambda)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "749 where we used the relation $|K_{j}^{\\iota}|\\leq\\mathrm{dim}_{E}(\\mathcal{F}_{h},2^{-\\iota-1})$ and the definition of $n^{\\iota}$ in the second inequality.   \n750 Additionally, for $\\iota=n$ we also have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{k\\in K^{n}}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{h,k-1}^{\\mathrm{all}})\\leq\\sum_{k\\in K^{n}}\\frac{L_{k}(z_{h}^{k})}{\\lambda}\\leq|K^{n}|\\cdot\\frac{\\lambda/K}{\\lambda}\\leq1,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "751 and so finally we sum over $\\iota=0,\\cdots\\,,n$ to get ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k=1}^{K}D_{\\lambda,\\mathcal{F}_{h}}^{2}(z_{h}^{k};Z_{h,k-1}^{\\mathrm{all}})\\le\\displaystyle\\sum_{\\iota=0}^{n-1}\\dim_{E}(\\mathcal{F}_{h},2^{-\\iota-1})\\big(2\\log n^{\\iota}+4+1/(2^{\\iota}\\lambda)\\big)+1}&{}\\\\ {\\le n\\dim_{E}(\\mathcal{F}_{h},2^{-n})\\big(2\\log K+4+1/\\lambda\\big)+1}&{}\\\\ {\\le C\\dim_{E}(\\mathcal{F}_{h},\\lambda/K)\\log(K/\\operatorname*{min}\\{1,\\lambda\\}),}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "752 where the final step makes the assumption that $\\lambda={\\cal O}(1/\\log K)$ , in which case it holds with some   \n753 absolute constant $C_{D}$ . \u53e3   \n754 Remark C.2. Again, this prove does not depend on the multi-level structure of episodic MDPs. In   \n755 fact, it only relies on the Eluder dimensionality of ${\\mathcal{F}}_{h}$ . This means the proof can be converted to the   \n756 bandit case of Lemma A.3 without any essential changes: simply change episode $k$ into time step $t$ ,   \n757 disregard all mentions of level $h$ , and consider $z=a$ instead of $z=(s,a)$ . ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "758 D Technical Lemmas ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "759 In this section, we provide a technical concentration lemma that serves as the core of our results. For   \n760 one, this lemma is based on the following concentration inequality:   \n761 Lemma D.1. For a sequence of random variables $\\{Z_{t}\\}_{t\\in\\mathbb{N}}$ adapted to the filtration $\\{S_{t}\\}_{t\\in\\mathbb{N}}$ and   \n762 function $f\\in{\\mathcal{F}}$ , for any $\\lambda>0$ , with probability at least $1-\\delta_{i}$ , for all $t\\in\\mathbb{N}$ , we have ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "equation", "text": "$$\n-\\frac{1}{\\lambda}\\sum_{s=1}^{t}\\log\\mathbb{E}\\big[\\exp[-\\lambda f(Z_{s})]\\big|S_{s-1}\\big]-\\sum_{s=1}^{t}f(Z_{s})\\leq\\frac{1}{\\lambda\\delta}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "763 The proof for this lemma can be found under Lemma 4 of Russo and Van Roy [2013]. Apart from   \n764 this, we need yet another basic concentration lemma: ", "page_idx": 28}, {"type": "text", "text": "Lemma D.2. Suppose $\\{\\eta_{t}\\}_{t=1}^{T}$ is a sequence of conditional $R$ -sub-Gaussian random variables satisfying ${\\mathbb E}\\big[e^{\\mu\\eta_{t}}\\big|\\mathcal H_{t-1}\\big]\\;\\le\\;\\exp\\big(R^{2}\\mu^{2}/2\\big)$ , where $\\mathcal{H}_{t-1}$ denotes all history before time $t$ , with probability $\\bar{1}-\\delta$ , we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\eta_{t}^{2}\\leq2T\\sigma^{2}+3\\sigma^{2}\\log(1/\\delta).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "765 A proof of this lemma can be found under Lemma G.2 of Ye et al. [2023]. With this, we can prove   \n766 the following lemma characterizing the accuracy of least squares solution. Even though we need   \n767 this lemma for both bandit and RL settings, we will follow the notations presented in multi-agent   \n768 contextual bandits. Detailed explanation of how this translates to multi-agent MDPs can be found in   \n769 Section C.2. ", "page_idx": 28}, {"type": "text", "text": "Lemma D.3. Suppose we have a sequence of inputs $\\{(a_{t},r_{t})\\}_{t=1}^{T}$ that follow the rule $r_{t}=f^{*}(a_{t}){+}\\eta_{t}$ for some ground truth $f^{*}\\in\\mathcal{F}$ , with $\\eta_{t}$ being conditionally $R$ -sub-Gaussian: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[e^{\\mu\\eta_{t}}\\big|a_{1:t},r_{1:t-1}\\big]\\leq\\exp(R^{2}\\mu^{2}/2),\\forall\\mu\\in\\mathbb{R}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "770 We also have server datasets $Z_{t}^{s e r}$ at different time steps, collected following the communication   \n771 protocol in our settings. Note that strictly speaking, the conditions under which $\\eta_{t}$ is sub-Gaussian   \n772 should also include the former participants $m_{1:t}$ , but we will omit this dependency for convenience.   \n773 Consider $\\widehat{f}_{t+1}^{s e r}$ , the approximate ERM solution to the least squares problem: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\bigg(\\sum_{(a,r)\\in Z_{t}^{\\times r}}\\left(\\widehat{f}_{t+1}^{s e r}(a)-r\\right)^{2}\\bigg)^{1/2}\\leq\\operatorname*{min}_{f\\in\\mathcal{F}_{t}}\\bigg(\\sum_{(a,r)\\in Z_{t}^{\\times r}}\\left(f(a)-r\\right)^{2}\\bigg)^{1/2}+\\epsilon_{0}\\sqrt{t},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "774 Then abbreviating $N=N(\\mathcal{F},\\gamma)$ and taking $C_{E R M}=36$ , with probability at least $1-\\delta$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{a,r)\\in Z_{t}^{\\kappa r}}\\left(\\widehat{f}_{t+1}^{s e r}(a)-f^{*}(a)\\right)^{2}\\leq C_{E R M}\\Big[\\lambda+(\\gamma+\\epsilon_{0})^{2}T+(\\gamma+\\epsilon_{0})T R+R^{2}(1+M\\alpha)\\log(3N/\\delta)+(\\gamma+\\epsilon_{0})T R\\Big]\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof of Lemma $D.3$ . Let $\\mathcal{F}_{\\gamma}$ be a $\\gamma$ -cover of the function class $\\mathcal{F}$ with respect to the infinity norm $\\|\\cdot\\|_{\\infty}$ . For $f\\in\\mathcal F$ and $(a_{t},r_{t})$ for some $t\\in[T]$ , let ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\phi(f,a_{t},r_{t})=-(f(a_{t})-r_{t})^{2}+(f^{*}(a_{t})-r_{t})^{2},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "775 Since $r_{t}=f^{*}(a_{t})+\\eta_{t}$ , we can write $\\phi(f,a_{t},r_{t})$ as ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\phi(f,a_{t},r_{t})=-\\big(f(a_{t})-f^{*}(a_{t})+\\eta_{t}\\big)^{2}+\\eta_{t}^{2}}}\\\\ {{=-2\\big(f(a_{t})-f^{*}(a_{t})\\big)\\eta_{t}-\\big(f(a_{t})-f^{*}(a_{t})\\big)^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "776 Since $\\eta_{t}$ is $R$ -sub-Gaussian conditional on $Z_{t-1}^{\\mathrm{all}},a_{t}$ , we have for any positive parameter $\\mu$ that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\mathbb{E}\\big[\\exp(\\mu\\phi(f,a_{t},r_{t}))\\big|Z_{t-1}^{\\mathrm{all}},a_{t}\\big]\\leq2\\mu^{2}R^{2}(f(a_{t})-f^{*}(a_{t}))^{2}-\\mu(f(a_{t})-f^{*}(a_{t}))^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=(2\\mu^{2}R^{2}-\\mu)(f(a_{t})-f^{*}(a_{t}))^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "777 Using Lemma D.1, we have with probability at least $1-\\delta/3$ , for all $f\\in\\mathcal F_{\\gamma}$ and $t\\in[T]$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mu_{\\mathrm{all}}\\sum_{(a,r)\\in{\\cal Z}_{t}^{\\mathrm{all}}}\\phi(f,a,r)\\le(2\\mu_{\\mathrm{all}}^{2}R^{2}-\\mu_{\\mathrm{all}})\\sum_{(a,r)\\in{\\cal Z}_{t}^{\\mathrm{all}}}(f(a)-f^{*}(a))^{2}+\\log(3N/\\delta),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "778 where $\\mu_{\\mathrm{all}}>0$ is a parameter we will determine later. ", "page_idx": 28}, {"type": "text", "text": "779 On the other hand, if we consider any local agent $m$ , when $m_{t}=m$ , we have $\\eta_{t}$ is $R$ -sub-Gaussian   \n780 conditional on $Z_{m,t-1}^{\\mathrm{up}}\\cup Z_{m,t-1}^{\\mathrm{loc}}$ and $a_{t}$ , i.e. all the data agent $m$ has received from the environment   \n781 up to this point. Thus we have for any $\\mu>0$ that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\mathbb{E}\\big[\\exp(-\\mu\\phi(f,a_{t},r_{t}))\\big|Z_{m,t-1}^{\\mathrm{up}}\\cup Z_{m,t-1}^{\\mathrm{loc}},a_{t}\\big]\\leq2\\mu^{2}R^{2}(f(a_{t})-f^{*}(a_{t}))^{2}+\\mu(f(a_{t})-f^{*}(a_{t}))^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=(2\\mu^{2}R^{2}+\\mu)(f(a_{t})-f^{*}(a_{t}))^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "782 Then again using Lemma D.1 and taking summation on $Z_{m,t}^{\\mathrm{loc}}$ , with probability at least $1-\\delta/3$ , the   \n783 following holds for any $m\\in[M]$ : ", "page_idx": 29}, {"type": "equation", "text": "$$\n-\\mu_{\\mathrm{loc}}\\sum_{(a,r)\\in\\cal Z_{m,t}^{\\mathrm{loc}}}\\phi(f,a,r)\\le(2\\mu_{\\mathrm{loc}}^{2}R^{2}+\\mu_{\\mathrm{loc}})\\sum_{(a,r)\\in\\cal Z_{m,t}^{\\mathrm{loc}}}(f(a)-f^{*}(a))^{2}+\\log(3N M/\\delta),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "784 where $\\mu_{\\mathrm{loc}}>0$ is a parameter we will determine later. ", "page_idx": 29}, {"type": "text", "text": "785 Taking the summation of (27) for all $m\\in[M]$ and combining (26), while observing that $Z_{t}^{\\mathrm{ser}}=$   \n786 $\\textstyle Z_{t}^{\\mathrm{all}}\\backslash\\bigcup_{m=1}^{M}Z_{m,t}^{\\mathrm{loc}}$ , we get ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{(a,r)\\in{\\ensuremath{\\mathbb Z}}_{t}^{\\infty}}\\phi(f,a,r)=\\sum_{(a,r)\\in{\\ensuremath{\\mathbb Z}}_{t}^{\\infty}}\\phi(f,a,r)-\\sum_{m=1}^{M}\\sum_{(a,r)\\in{\\ensuremath{\\mathbb Z}}_{m,t}^{\\infty}}\\phi(f,a,r)}}\\\\ &{}&{\\leq(2\\mu_{\\mathrm{all}}R^{2}-1)\\displaystyle\\sum_{(a,r)\\in{\\ensuremath{\\mathbb Z}}_{t}^{\\infty}}(f(a)-f^{*}(a))^{2}+\\displaystyle\\frac{1}{\\mu_{\\mathrm{all}}}\\log(3N/\\delta)}\\\\ &{}&{\\quad\\quad+\\,(2\\mu_{\\mathrm{isc}}R^{2}+1)\\displaystyle\\sum_{m=1}^{M}\\sum_{(a,r)\\in{\\ensuremath{\\mathbb Z}}_{m,t}^{\\infty}}(f(a)-f^{*}(a))^{2}+\\displaystyle\\frac{1}{\\mu_{\\mathrm{isc}}}M\\log(3N M/\\delta)}\\\\ &{}&{=2R^{2}(\\mu_{\\mathrm{all}}+\\mu_{\\mathrm{isc}})\\|f-f^{*}\\|_{2\\mu_{\\mathrm{al}}}^{2}-(2\\mu_{\\mathrm{le}}R^{2}+1)\\|f-f^{*}\\|_{Z_{t}^{\\infty}}^{2}}\\\\ &{}&{\\quad\\quad+\\,\\displaystyle\\frac{1}{\\mu_{\\mathrm{all}}}\\log(3N/\\delta)+\\displaystyle\\frac{1}{\\mu_{\\mathrm{all}}}M\\log(3N M/\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "787 From Lemma A.1, we have $\\lambda+\\|f-f^{*}\\|_{Z_{t}^{\\mathrm{al}}}^{2}\\leq(1{+}M\\alpha)\\big(\\lambda{+}\\|f-f^{*}\\|_{Z_{t}^{\\mathrm{sr}}}^{2}\\big)\\Leftrightarrow\\|f-f^{*}\\|_{Z_{t}^{\\mathrm{al}}}^{2}\\leq M\\alpha\\lambda+$   \n788 $(1+M\\alpha)\\|f-f^{*}\\|_{Z_{t}^{\\mathrm{ser}}}^{2}$ . Plugging this inequality into the above and letting $\\mu_{\\mathrm{all}}=1/8R^{2}(1+M\\alpha)$   \n789 and $\\mu_{\\mathrm{loc}}=1/8R^{2}M\\dot{\\alpha}$ , we get ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{a,r)\\in\\mathbb{Z}_{t}^{\\times}}\\phi(f,a,r)\\leq2R^{2}(\\mu_{\\mathrm{all}}+\\mu_{\\mathrm{loc}})M\\alpha\\lambda-\\left(1-2M\\alpha\\mu_{\\mathrm{loc}}R^{2}-2(1+M\\alpha)\\mu_{\\mathrm{all}}R^{2}\\right)\\|f-f^{*}\\|_{\\mathbb{Z}_{t}^{\\times}}^{2}}&{}\\\\ {\\displaystyle}&{\\qquad+\\displaystyle\\frac{1}{\\mu_{\\mathrm{all}}}\\log(3N/\\delta)+\\displaystyle\\frac{1}{\\mu_{\\mathrm{loc}}}M\\log(3N M/\\delta)}\\\\ {\\leq-\\displaystyle\\frac{1}{2}\\|f-f^{*}\\|_{Z_{t}^{\\times\\tau}}^{2}+\\displaystyle\\frac{1}{2}\\lambda+8R^{2}(1+M\\alpha)\\log(3N/\\delta)+8R^{2}M^{2}\\alpha\\log(3N M/\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "790 Now for $\\widehat{f}_{t+1}^{\\mathrm{ser}}$ , there exists $\\widetilde{f}\\in\\mathcal{F}_{\\gamma}$ such that $\\|\\widetilde{f}-\\widehat{f}_{t+1}^{\\mathrm{ser}}\\|_{\\infty}\\le\\gamma$ . Using Lemma D.2, this gives us the   \n791 followin g with probability  at least $1-\\delta/3$ : ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{-\\displaystyle\\sum_{(a,r)\\in\\mathbb{Z}_{t}^{m}}\\phi(\\widetilde{f},a,r)=\\displaystyle\\sum_{(a,r)\\in\\mathbb{Z}_{t}^{m}}\\left[\\left(\\widetilde{f}(a)-r\\right)^{2}-\\left(f^{*}(a)-r\\right)^{2}\\right]}\\\\ &{\\leq\\left(\\displaystyle\\sqrt{\\sum_{(a,r)\\in\\mathbb{Z}_{t}^{m}}\\left(\\widehat{f}_{t+1}^{a r}(a)-r\\right)^{2}}+\\sqrt{t\\gamma^{2}}\\right)^{2}-\\displaystyle\\sum_{(a,r)\\in\\mathbb{Z}_{t}^{m}}\\left(f^{*}(a)-r\\right)^{2}}\\\\ &{\\leq\\left(\\displaystyle\\sqrt{\\sum_{(a,r)\\in\\mathbb{Z}_{t}^{m}}\\left(f^{*}(a)-r\\right)^{2}}+\\sqrt{t}(\\gamma+\\epsilon_{0})\\right)^{2}-\\displaystyle\\sum_{(a,r)\\in\\mathbb{Z}_{t}^{m}}\\left(f^{*}(a)-r\\right)^{2}}\\\\ &{=(\\gamma+\\epsilon_{0})^{2}t+2(\\gamma+\\epsilon_{0})\\sqrt{t}\\left(\\displaystyle\\sum_{s=1}^{t}\\eta_{s}^{2}\\right)^{1/2}}\\\\ &{\\leq(\\gamma+\\epsilon_{0})^{2}t+2(\\gamma+\\epsilon_{0})\\sqrt{2T^{2}R^{2}+3T R^{2}\\log(3/\\delta)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "792 where we used the basic inequality $\\sqrt{\\sum(a+b)^{2}}\\leq\\sqrt{\\sum a^{2}}+\\sqrt{\\sum b^{2}}$ in the first inequality and   \n793 used the property of $\\widehat{f}_{t+1}^{\\mathrm{ser}}$ in the second inequality. Finally, taking a union bound and combining this ", "page_idx": 29}, {"type": "text", "text": "794 with (28), we have with probability at least $1-\\delta$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{(a,r)\\in\\mathbb{Z}_{\\neq}^{\\times}}{\\sum}\\big(\\widehat f_{t+1}^{\\times\\mathrm{or}}(a)-f^{*}(a)\\big)^{2}}\\\\ &{\\leq2\\gamma^{2}t+2\\,\\underset{(a,r)\\in\\mathbb{Z}_{\\neq}^{\\times}}{\\sum}\\big(\\widetilde f(a)-f^{*}(a)\\big)^{2}}\\\\ &{\\leq2\\gamma^{2}t-2\\,\\underset{(a,r)\\in\\mathbb{Z}_{\\neq}^{\\times}}{\\sum}\\phi(\\widetilde f,a,r)+\\lambda+32R^{2}(1+M\\alpha)\\log(3N/\\delta)+32R^{2}M^{2}\\alpha\\log(3N M/\\delta)}\\\\ &{\\leq2\\gamma^{2}T+2(\\gamma+\\epsilon_{0})^{2}T+4(\\gamma+\\epsilon_{0})\\sqrt{2T^{2}R^{2}+3T R^{2}\\log(3/\\delta)}+\\lambda+32R^{2}(1+M\\alpha)\\log(3N/\\delta)\\,.}\\\\ &{\\leq C_{\\mathrm{ERM}}\\bigg[\\lambda+(\\gamma+\\epsilon_{0})^{2}T+(\\gamma+\\epsilon_{0})T R+R^{2}(1+M\\alpha)\\log(3N/\\delta)+R^{2}M^{2}\\alpha\\log(3N M/\\delta)\\bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "795 where the first inequality uses again $\\|\\widetilde{f}-\\widehat{f}_{t+1}^{\\mathrm{ser}}\\|_{\\infty}\\le\\gamma$ , and it can be verified that the last inequality   \n796 holds when $C_{\\mathrm{ERM}}\\geq36$ . ", "page_idx": 30}, {"type": "text", "text": "797 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "01 Answer: [Yes]   \n02 Justification: We accurately summarize our contribution and main results in the abstract,   \n03 and elaborate further on motivation and main techniques in our introduction.   \n04 Guidelines:   \n05 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n06 made in the paper.   \n07 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n08 contributions made in the paper and important assumptions and limitations. A No or   \n09 NA answer to this question will not be perceived well by the reviewers.   \n10 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n11 much the results can be expected to generalize to other settings.   \n12 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n13 are not attained by the paper. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: All assumptions made for our theoretical analysis are present and stated clearly within the main paragraphs of our paper. Discussions on the applicability of these assumptions are also included. ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes]   \nJustification: All assumptions are listed in the main paper, while a very detailed and sound proof is displayed in the appendices. ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results. \u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems. \u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. \u2022 Inversely, any informal proof provided in the core of the paper should be complemented 2 by formal proofs provided in appendix or supplemental material. \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 32}, {"type": "text", "text": "864 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "865 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n866 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n867 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 32}, {"type": "text", "text": "Justification: Our theoretical paper does not present any experimental results. ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "902 5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "903 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n904 tions to faithfully reproduce the main experimental results, as described in supplemental   \n905 material?   \n906 Answer: [NA]   \n907 Justification: Our theoretical paper does not present any experimental results.   \n908 Guidelines:   \n909 \u2022 The answer NA means that paper does not include experiments requiring code.   \n910 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n911 public/guides/CodeSubmissionPolicy) for more details.   \n912 \u2022 While we encourage the release of code and data, we understand that this might not be   \n913 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n914 including code, unless this is central to the contribution (e.g., for a new open-source   \n915 benchmark).   \n916 \u2022 The instructions should contain the exact command and environment needed to run to   \n917 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n918 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n919 \u2022 The authors should provide instructions on data access and preparation, including how   \n920 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n921 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n922 proposed method and baselines. If only a subset of experiments are reproducible, they   \n923 should state which ones are omitted from the script and why.   \n924 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n925 versions (if applicable).   \n926 \u2022 Providing as much information as possible in supplemental material (appended to the   \n927 paper) is recommended, but including URLs to data and code is permitted.   \n928 6. Experimental Setting/Details   \n929 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n930 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n931 results?   \n932 Answer: [NA]   \n933 Justification: Our theoretical paper does not present any experimental results.   \n934 Guidelines:   \n935 \u2022 The answer NA means that the paper does not include experiments.   \n936 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n937 that is necessary to appreciate the results and make sense of them.   \n938 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n939 material.   \n940 7. Experiment Statistical Significance   \n941 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n942 information about the statistical significance of the experiments?   \n943 Answer: [NA]   \n944 Justification: Our theoretical paper does not present any experimental results.   \n945 Guidelines:   \n946 \u2022 The answer NA means that the paper does not include experiments.   \n947 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n948 dence intervals, or statistical significance tests, at least for the experiments that support   \n949 the main claims of the paper.   \n950 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n951 example, train/test split, initialization, random drawing of some parameter, or overall   \n952 run with given experimental conditions).   \n953 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n954 call to a library function, bootstrap, etc.) ", "page_idx": 33}, {"type": "text", "text": "\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 34}, {"type": "text", "text": "966 8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "967 Question: For each experiment, does the paper provide sufficient information on the com  \n968 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n969 the experiments?   \n970 Answer: [NA]   \n971 Justification: Our theoretical paper does not present any experimental results.   \n972 Guidelines: ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Justification: We have thoroughly reviewed the NeurIPS Code of Ethics, and believe our work conforms fully the the Code. ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "993 10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "994 Question: Does the paper discuss both potential positive societal impacts and negative   \n995 societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "997 Justification: See Impact Statement before appendices   \n998 Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. ", "page_idx": 34}, {"type": "text", "text": "1006 \u2022 The conference expects that many papers will be foundational research and not tied   \n1007 to particular applications, let alone deployments. However, if there is a direct path to   \n1008 any negative applications, the authors should point it out. For example, it is legitimate   \n1009 to point out that an improvement in the quality of generative models could be used to   \n1010 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n1011 that a generic algorithm for optimizing neural networks could enable people to train   \n1012 models that generate Deepfakes faster.   \n1013 \u2022 The authors should consider possible harms that could arise when the technology is   \n1014 being used as intended and functioning correctly, harms that could arise when the   \n1015 technology is being used as intended but gives incorrect results, and harms following   \n1016 from (intentional or unintentional) misuse of the technology.   \n1017 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n1018 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n1019 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n1020 feedback over time, improving the efficiency and accessibility of ML).   \n1021 11. Safeguards   \n1022 Question: Does the paper describe safeguards that have been put in place for responsible   \n1023 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n1024 image generators, or scraped datasets)?   \n1025 Answer: [NA]   \n1026 Justification: Our theoretical paper does not present any experimental results, and thus does   \n1027 not feature such data and models.   \n1028 Guidelines:   \n1029 \u2022 The answer NA means that the paper poses no such risks.   \n1030 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n1031 necessary safeguards to allow for controlled use of the model, for example by requiring   \n1032 that users adhere to usage guidelines or restrictions to access the model or implementing   \n1033 safety filters.   \n1034 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n1035 should describe how they avoided releasing unsafe images.   \n1036 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n1037 not require this, but we encourage authors to take this into account and make a best   \n1038 faith effort.   \n1039 12. Licenses for existing assets   \n1040 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n1041 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n1042 properly respected?   \n1043 Answer: [NA]   \n1044 Justification: Our paper does not include any such assets.   \n1045 Guidelines:   \n1046 \u2022 The answer NA means that the paper does not use existing assets.   \n1047 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n1048 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n1049 URL.   \n1050 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n1051 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n1052 service of that source should be provided.   \n1053 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n1054 package should be provided. For popular datasets, paperswithcode.com/datasets   \n1055 has curated licenses for some datasets. Their licensing guide can help determine the   \n1056 license of a dataset.   \n1057 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n1058 the derived asset (if it has changed) should be provided.   \n1059 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n1060 the asset\u2019s creators.   \n1061 13. New Assets   \n1062 Question: Are new assets introduced in the paper well documented and is the documentation   \n1063 provided alongside the assets?   \n1064 Answer: [NA]   \n1065 Justification: Our theoretical paper does not introduce any new assets.   \n1066 Guidelines:   \n1067 \u2022 The answer NA means that the paper does not release new assets.   \n1068 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n1069 submissions via structured templates. This includes details about training, license,   \n1070 limitations, etc.   \n1071 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n1072 asset is used.   \n1073 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n1074 create an anonymized URL or include an anonymized zip file.   \n1075 14. Crowdsourcing and Research with Human Subjects   \n1076 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n1077 include the full text of instructions given to participants and screenshots, if applicable, as   \n1078 well as details about compensation (if any)?   \n1079 Answer: [NA]   \n1080 Justification: Our theoretical paper does not present any experimental results.   \n1081 Guidelines:   \n1082 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n1083 human subjects.   \n1084 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n1085 tion of the paper involves human subjects, then as much detail as possible should be   \n1086 included in the main paper.   \n1087 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n1088 or other labor should be paid at least the minimum wage in the country of the data   \n1089 collector.   \n1090 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n1091 Subjects   \n1092 Question: Does the paper describe potential risks incurred by study participants, whether   \n1093 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n1094 approvals (or an equivalent approval/review based on the requirements of your country or   \n1095 institution) were obtained?   \n1096 Answer: [NA]   \n1097 Justification: Our theoretical paper does not present any experimental results.   \n1098 Guidelines:   \n1099 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n1100 human subjects.   \n1101 \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent)   \n1102 may be required for any human subjects research. If you obtained IRB approval, you   \n1103 should clearly state this in the paper.   \n1104 \u2022 We recognize that the procedures for this may vary significantly between institutions   \n1105 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n1106 guidelines for their institution.   \n1107 \u2022 For initial submissions, do not include any information that would break anonymity (if   \n1108 applicable), such as the institution conducting the review. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}]