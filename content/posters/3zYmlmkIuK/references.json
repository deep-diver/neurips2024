{"references": [{"fullname_first_author": "Yasin Abbasi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-01-01", "reason": "This paper provides foundational algorithms for linear stochastic bandits, which are crucial for understanding and extending to the multi-agent and nonlinear settings explored in the current paper."}, {"fullname_first_author": "Alekh Agarwal", "paper_title": "Model-based RL with optimistic posterior sampling: Structural conditions and sample complexity", "publication_date": "2022-01-01", "reason": "This work establishes theoretical foundations for model-based reinforcement learning with general function approximation, a key component of the algorithms presented in the current paper."}, {"fullname_first_author": "Alekh Agarwal", "paper_title": "Voql: Towards optimal regret in model-free rl with nonlinear function approximation", "publication_date": "2023-07-12", "reason": "This very recent paper introduces a novel algorithm for model-free reinforcement learning with nonlinear function approximation, which is highly relevant to the multi-agent RL setting considered in this work."}, {"fullname_first_author": "Chi Jin", "paper_title": "Provably efficient reinforcement learning with linear function approximation", "publication_date": "2020-01-01", "reason": "This paper presents a foundational algorithm for reinforcement learning with linear function approximation, setting a benchmark for efficiency that is relevant to the multi-agent setting and compared against in this paper."}, {"fullname_first_author": "Chi Jin", "paper_title": "Bellman eluder dimension: New rich classes of RL problems, and sample-efficient algorithms", "publication_date": "2021-01-01", "reason": "This paper significantly expands the theoretical understanding of reinforcement learning with general function approximation by introducing the concept of Eluder dimension, a key complexity measure used in this work."}]}