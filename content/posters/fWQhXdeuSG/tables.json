[{"figure_path": "fWQhXdeuSG/tables/tables_5_1.jpg", "caption": "Table 1: Detailed parameter settings for all baselines.", "description": "This table lists the detailed parameter settings used for all baseline algorithms in the experiments, including CMA-ES, L-SHADE, ES, DE, LGA, and LES.  It provides specific values for hyperparameters, initial values, and settings crucial for the reproducibility of the experimental results.  Note that for some algorithms (CMA-ES and L-SHADE), parameters were automatically adjusted, while others (LGA and LES) utilized parameters provided by the authors.  For algorithms where grid search was used to determine parameters, the search ranges and steps are specified.", "section": "4 Experiments"}, {"figure_path": "fWQhXdeuSG/tables/tables_18_1.jpg", "caption": "Table 1: Detailed parameter settings for all baselines.", "description": "This table lists the detailed parameter settings used for the different baseline algorithms compared in the paper's experiments.  It includes settings for CMA-ES, LSHADE, ES, DE, LGA, and LES,  showing the specific values used for each algorithm's hyperparameters.  These parameters were either automatically adjusted, set to optimal values from previous literature, or tuned using a grid search.  The table helps ensure reproducibility by clearly documenting the parameters used in each experiment.", "section": "4 Experiments"}, {"figure_path": "fWQhXdeuSG/tables/tables_18_2.jpg", "caption": "Table 2: POM parameters of different architectures and architecture settings.", "description": "This table shows the different hyperparameter settings used for the various model sizes of POM.  It details the number of parameters, the dimension of the Multi-head Self-Attention (MSA) module's input (dm), and the dimension of the Feedforward Network (FFN) module's input (dc). These parameters are crucial for understanding the model's complexity and performance across different scales.", "section": "3 Pretrained Optimization Model"}, {"figure_path": "fWQhXdeuSG/tables/tables_19_1.jpg", "caption": "Table 3: Additional Training Functions. Zi = Xi - Wi.", "description": "This table lists eight additional training functions (TF1-TF8) used in the paper's experiments.  Each function includes a mathematical formula defining it, along with a specification of the range of its input variable 'x' and a parameter '\u03c9'. These functions represent a diverse set of mathematical landscapes, designed to challenge and enhance the robustness of the POM algorithm during its training phase. The diversity in the functions' characteristics, including modality (unimodal versus multimodal), separability, and the presence of asymmetry, helps to ensure that the trained POM model generalizes effectively to a wide variety of unseen optimization problems.", "section": "3.4 Tasks, Loss Function & MetaGBT"}, {"figure_path": "fWQhXdeuSG/tables/tables_19_2.jpg", "caption": "Table 4: BBOB RESULT. POM is trained on TF1-TF5 with d=10. The best results are indicated in bold, and the suboptimal results are underlined.", "description": "This table presents the results of the BBOB (Black-box Optimization Benchmark) experiments.  POM (Pretrained Optimization Model) was trained using functions TF1-TF5 with a dimensionality (d) of 10. The table compares the performance of POM against several other optimization algorithms (ES, DE, CMA-ES, LSHADE, LES, and LGA) across 24 different BBOB test functions. The best performance for each function is highlighted in bold, and the near-best results are underlined.  This allows for a direct comparison of POM's performance on these standard benchmarks against state-of-the-art and classic algorithms.", "section": "F.1 BBOB Test"}, {"figure_path": "fWQhXdeuSG/tables/tables_20_1.jpg", "caption": "Table 5: Additional Experimental results on BBOB (d = 100). The best results are indicated in bold, and the suboptimal results are underlined.", "description": "This table presents the results of additional experiments conducted on the BBOB benchmark with a dimensionality of 100.  It compares the performance of POM against several other algorithms (ES, DE, CMA-ES, LSHADE, LES, and LGA) across 24 different functions (F1-F24).  The best result for each function is highlighted in bold, and near-optimal results are underlined. This demonstrates the performance of POM in handling situations where the optimal solution of the function is slightly perturbed. The table provides a quantitative comparison to assess the algorithm's robustness and generalisation ability.", "section": "F.2 BBOB Test With Optimal Solution Disturbed"}, {"figure_path": "fWQhXdeuSG/tables/tables_21_1.jpg", "caption": "Table 6: Additional Experimental results on BBOB (d = 500). The best results are indicated in bold, and the suboptimal results are underlined.", "description": "This table presents the results of additional experiments conducted on the BBOB benchmark with a dimensionality of 500.  The table compares the performance of POM against several other algorithms (ES, DE, CMA-ES, LSHADE, LES, and LGA) across 24 different BBOB functions. The best result for each function is highlighted in bold, while suboptimal results are underlined. This data allows for a detailed comparison of POM's performance relative to state-of-the-art methods in high-dimensional optimization problems.", "section": "4.2 Results"}, {"figure_path": "fWQhXdeuSG/tables/tables_25_1.jpg", "caption": "Table 7: Results of ablation experiments. The best results are indicated in bold, and the suboptimal results are underlined. Here d = 30.", "description": "This table presents the results of an ablation study conducted to evaluate the contribution of each module (LMM, LCM, SM, and Mask) in the POM architecture.  The results show the optimal value (smaller is better) of the objective function achieved by POM and its variants on 24 benchmark functions from the BBOB suite.  By removing one module at a time, the impact of each component on the overall performance is assessed, allowing for a quantitative analysis of their relative importance in the proposed optimization strategy.", "section": "4.3 Analysis"}, {"figure_path": "fWQhXdeuSG/tables/tables_25_2.jpg", "caption": "Table 4: BBOB RESULT. POM is trained on TF1-TF5 with d=10. The best results are indicated in bold, and the suboptimal results are underlined.", "description": "This table presents the results of the proposed Pretrained Optimization Model (POM) on the Black-Box Optimization Benchmark (BBOB).  POM was trained using functions TF1-TF5 with a dimension of 10 (d=10).  The table shows the performance of POM across various BBOB functions (F1-F24), comparing it against other state-of-the-art algorithms. The best results for each function are highlighted in bold, and suboptimal results are underlined. This allows for a direct comparison of POM's performance relative to existing methods for different BBOB functions.", "section": "F.1 BBOB Test"}, {"figure_path": "fWQhXdeuSG/tables/tables_32_1.jpg", "caption": "Table 9: Results of POMs of different sizes on BBOB tests (d = 100). The best results are indicated in bold, and the suboptimal results are underlined.", "description": "This table presents the results of POMs with different sizes (VS, S, M, L, VL, XL) tested on the BBOB benchmark functions with a dimensionality of 100. The best results for each function (F1-F24) are shown in bold, and the suboptimal results are underlined, allowing for a comparison of the algorithm's performance at different scales.  Each result represents the mean (mean) and standard deviation (std) of the optimal values achieved.", "section": "4.2 Results"}]