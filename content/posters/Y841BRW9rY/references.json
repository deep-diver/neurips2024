{"references": [{"fullname_first_author": "Patrick Lewis", "paper_title": "Retrieval-augmented generation for knowledge-intensive NLP tasks", "publication_date": "2020-12-01", "reason": "This paper introduces Retrieval-Augmented Generation (RAG), a core mechanism used by many LLM agents, making it foundational to the paper's study of backdoor attacks targeting RAG-based agents."}, {"fullname_first_author": "Kelvin Guu", "paper_title": "Retrieval augmented language model pre-training", "publication_date": "2020-06-01", "reason": "This paper presents a significant advancement in RAG methods, improving the effectiveness of retrieval mechanisms used by LLM agents, hence directly relevant to the paper's exploration of vulnerabilities in those improved mechanisms."}, {"fullname_first_author": "Zhen Xiang", "paper_title": "BadChain: Backdoor chain-of-thought prompting for large language models", "publication_date": "2024-01-01", "reason": "This paper is highly relevant as it investigates a type of backdoor attack on LLMs and serves as a comparative baseline for the novel attack method proposed in the current research."}, {"fullname_first_author": "Vladimir Karpukhin", "paper_title": "Dense passage retrieval for open-domain question answering", "publication_date": "2020-04-01", "reason": "This paper introduces a widely used dense retrieval technique for RAG, making it highly relevant to the paper's focus on attacking RAG systems used by LLMs."}, {"fullname_first_author": "Zexuan Zhong", "paper_title": "Poisoning retrieval corpora by injecting adversarial passages", "publication_date": "2023-10-01", "reason": "This paper is highly relevant as it explores a form of poisoning attack used as a comparative baseline method for the novel attack technique proposed in the current research."}]}