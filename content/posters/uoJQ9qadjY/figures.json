[{"figure_path": "uoJQ9qadjY/figures/figures_1_1.jpg", "caption": "Figure 1: Complex VQA scenarios (CLEVR-Humans [35], GQA [29], CLEVRER-Humans[51]), AGQA[20] and STAR[79]) wherein combination of iterative (step-by-step) computation (blue phrases) and parallel computation (orange phrases) can be beneficial for reasoning.", "description": "This figure shows five example complex visual question answering (VQA) scenarios. Each scenario is accompanied by a question that requires compositional multi-step reasoning. The questions are color-coded to highlight the parts that are best addressed by iterative reasoning (blue) and parallel reasoning (orange). The scenarios include images and videos with different levels of complexity, demonstrating the benefits of combining iterative and parallel approaches for VQA.", "section": "1 Introduction"}, {"figure_path": "uoJQ9qadjY/figures/figures_2_1.jpg", "caption": "Figure 2: IPRM's computation flow diagram. First, a new set of N-parallel latent operations Zop are retrieved from language features XL conditioned on prior operation states Mop. Then, visual features Xy are queried conditioned on both Zop and prior result states results Mres, to form the new results Zres. Finally, both Zres and Zop are passed to the Operation Composition Unit (see 2.3 the output of which becomes the new memory state M.", "description": "This figure shows the computation flow diagram of the Iterative and Parallel Reasoning Mechanism (IPRM).  The process starts with language and visual inputs.  The IPRM first forms a new set of parallel latent operations based on the prior operation states and language features. Then, it executes these operations in parallel using the visual features, prior result states, and newly formed operations. Finally, it integrates these operations and results using an operation composition unit to update the memory state. This iterative process repeats for T reasoning steps.", "section": "2 Iterative and Parallel Reasoning Mechanism"}, {"figure_path": "uoJQ9qadjY/figures/figures_4_1.jpg", "caption": "Figure 2: IPRM's computation flow diagram. First, a new set of N-parallel latent operations Zop are retrieved from language features XL conditioned on prior operation states Mop. Then, visual features Xy are queried conditioned on both Zop and prior result states results Mres, to form the new results Zres. Finally, both Zres and Zop are passed to the Operation Composition Unit (see 2.3 the output of which becomes the new memory state M.", "description": "The figure illustrates the computation flow of the Iterative and Parallel Reasoning Mechanism (IPRM). It shows how IPRM iteratively processes visual and language information to generate a reasoning result. At each iteration, it performs three steps: (1) operation formation: retrieves new parallel latent operations from language features based on prior operation states; (2) operation execution: retrieves visual information based on latent operations and prior results, and (3) operation composition: integrates the new operations and their results with previous memory states to update memory. The process repeats until the final reasoning result is obtained.", "section": "2 Iterative and Parallel Reasoning Mechanism"}, {"figure_path": "uoJQ9qadjY/figures/figures_6_1.jpg", "caption": "Figure 4: Acc. of IPRM (blue) across program lengths for CLEVR (left) and STAR (right). IPRM has significantly higher accs. at longer program lengths.", "description": "This figure shows the performance of the Iterative and Parallel Reasoning Mechanism (IPRM) model compared to two baseline models (Concat-Att and Cross-Att) on the CLEVR and STAR datasets.  The x-axis represents the length of the functional program, which is a measure of the complexity of the reasoning task. The y-axis represents the accuracy of the models. The figure demonstrates that IPRM achieves significantly higher accuracy than the baseline models, especially on more complex reasoning tasks (longer functional programs). This highlights IPRM's ability to handle multi-step reasoning.", "section": "3.2 Compositional Image Reasoning (CLEVR-Humans, CLEVR-CoGen and GQA)"}, {"figure_path": "uoJQ9qadjY/figures/figures_6_2.jpg", "caption": "Figure 5: IPRM performance on CLEVR-Humans at different training data ratios of Cross- and Concat-Att.", "description": "This figure shows the performance of the IPRM model (Iterative and Parallel Reasoning Mechanism) on the CLEVR-Humans dataset, comparing it against two baselines: Concat-Att and Cross-Att. The x-axis represents the ratio of training data used, and the y-axis shows the validation accuracy. The figure demonstrates that IPRM achieves higher validation accuracy with less training data compared to both baselines, highlighting its sample efficiency. The figure also includes the performance of MDETR and MAC for comparison.", "section": "3.2 Compositional Image Reasoning (CLEVR-Humans, CLEVR-CoGen and GQA)"}, {"figure_path": "uoJQ9qadjY/figures/figures_7_1.jpg", "caption": "Figure 6: IPRM Model ablations in order: (i) Impact of number of parallel operations (Nop) VS computation steps (T). (ii) Impact of Operation Composition Block (OPC). (iii): Impact of reduction ratio (r) and (iv) memory window length (W).", "description": "This figure shows the ablation study of IPRM model by varying different hyperparameters. The impact of changing the number of parallel operations and computation steps is shown in the first subplot. The second subplot shows the impact of using or not using the operation composition block. The third and fourth subplots show the impact of reduction ratio and memory window length respectively.", "section": "3.3 Model ablations and reasoning visualization"}, {"figure_path": "uoJQ9qadjY/figures/figures_8_1.jpg", "caption": "Figure 1: Complex VQA scenarios (CLEVR-Humans [35], GQA [29], CLEVRER-Humans[51]), AGQA[20] and STAR[79]) wherein combination of iterative (step-by-step) computation (blue phrases) and parallel computation (orange phrases) can be beneficial for reasoning.", "description": "This figure shows examples of complex Visual Question Answering (VQA) scenarios where a combination of iterative and parallel computation is beneficial.  The examples highlight tasks requiring multi-step reasoning, such as determining the color of an object based on its relative position to other objects, or counting the maximum occurrence of a shape.", "section": "1 Introduction"}, {"figure_path": "uoJQ9qadjY/figures/figures_20_1.jpg", "caption": "Figure 7: Condensed reasoning visualization of IPRM. In the top two examples, IPRM correctly utilizes both parallel and iterative computation to arrive at the correct answer. The bottom left example shows IPRM's cumulative lang. and visual attentions when solving a real-world GQA example. The bottom right example, shows an error case where IPRM seems to misunderstand question and outputs wrong ans. with less relevant attentions. See appendix for further reasoning visualizations and error cases, and supplemental for further CLIP integrated visualizations on GQA examples.", "description": "This figure shows four examples of how IPRM's internal computations are visualized across reasoning steps.  The top two examples illustrate correct reasoning using both iterative and parallel computation. The bottom left shows a correct answer on a real-world GQA example, highlighting the attention weights. The bottom right shows an error, indicating that IPRM may have misinterpreted the question.", "section": "3.3 Model ablations and reasoning visualization"}, {"figure_path": "uoJQ9qadjY/figures/figures_21_1.jpg", "caption": "Figure 9: In this example, IPRM predicts the correct answer and its visual attention trace provides evidence of correct intermediate reasoning. In penultimate reasoning step, IPRM correctly localizes the gray object with maximum occuring shape (cylinder) and in the final step, the parallel operations attend to both the cyan cube and the brown cylinder closest to previously identified gray cylinder.", "description": "This figure visualizes the intermediate reasoning steps of the Iterative and Parallel Reasoning Mechanism (IPRM) model for a specific question.  The top shows the original image and question. The middle shows the language attention weights. The bottom shows the visual attention weights across parallel operations and reasoning computation steps. The visualization demonstrates how IPRM uses both iterative and parallel computation to correctly identify and locate the relevant object for the question.", "section": "3.3 Model ablations and reasoning visualization"}, {"figure_path": "uoJQ9qadjY/figures/figures_22_1.jpg", "caption": "Figure 10: Example where IPRM outputs incorrect answer and the intermediate reasoning appears faulty possibly due to lack of understanding what a \"primary color is\". The pair of blue (a primary color) cubes in this case should have been identified but are not visually attended in any of the operations across reasoning steps).", "description": "This figure shows an example where the Iterative and Parallel Reasoning Mechanism (IPRM) model incorrectly answers a question. The visualization shows that the model did not correctly identify the \"primary color\" mentioned in the question. The pair of blue cubes, which are a primary color, were not attended to by the model's operations. This suggests a potential failure in understanding the concept of \"primary colors\", which is a crucial element in correctly answering the question.", "section": "3.3 Model ablations and reasoning visualization"}, {"figure_path": "uoJQ9qadjY/figures/figures_23_1.jpg", "caption": "Figure 1: Complex VQA scenarios (CLEVR-Humans [35], GQA [29], CLEVRER-Humans[51]), AGQA[20] and STAR[79]) wherein combination of iterative (step-by-step) computation (blue phrases) and parallel computation (orange phrases) can be beneficial for reasoning.", "description": "This figure showcases several complex visual question answering (VQA) scenarios where a combination of iterative and parallel reasoning is beneficial.  The examples highlight tasks requiring multi-step reasoning, such as determining the color of an object based on its relative position to other objects, or identifying the maximum occurring shape among a set of objects.  The blue phrases represent steps that benefit from iterative (step-by-step) processing, while the orange phrases illustrate those that can be efficiently computed in parallel.", "section": "1 Introduction"}, {"figure_path": "uoJQ9qadjY/figures/figures_24_1.jpg", "caption": "Figure 2: IPRM's computation flow diagram. First, a new set of N-parallel latent operations Zop are retrieved from language features XL conditioned on prior operation states Mop. Then, visual features Xy are queried conditioned on both Zop and prior result states results Mres, to form the new results Zres. Finally, both Zres and Zop are passed to the Operation Composition Unit (see 2.3 the output of which becomes the new memory state M.", "description": "This figure shows the computation flow diagram of the Iterative and Parallel Reasoning Mechanism (IPRM).  It details the three main steps: Operation Formation, Operation Execution, and Operation Composition.  Operation Formation retrieves relevant information from language features conditioned on previous operation states. Operation Execution retrieves visual information based on newly formed operations and previous results. Operation Composition integrates new and previous operations to form the new memory state. This process repeats iteratively for a fixed number of steps, with the final output being a 'reasoning result'.", "section": "2 Iterative and Parallel Reasoning Mechanism"}, {"figure_path": "uoJQ9qadjY/figures/figures_25_1.jpg", "caption": "Figure 2: IPRM's computation flow diagram. First, a new set of N-parallel latent operations Zop are retrieved from language features XL conditioned on prior operation states Mop. Then, visual features Xy are queried conditioned on both Zop and prior result states results Mres, to form the new results Zres. Finally, both Zres and Zop are passed to the Operation Composition Unit (see 2.3 the output of which becomes the new memory state M. across reasoning steps, which helps better interpret what operations it was doing and accordingly where it was looking visually when processing a complex reasoning scenario.", "description": "The figure illustrates the computation flow of the Iterative and Parallel Reasoning Mechanism (IPRM). It shows how IPRM iteratively processes information from language and visual features by forming parallel latent operations and results and composing them into a new memory state.  This process repeats across multiple reasoning steps, facilitating both parallel and iterative computations. The figure helps visualize the internal operations and reasoning steps of IPRM.", "section": "2 Iterative and Parallel Reasoning Mechanism"}, {"figure_path": "uoJQ9qadjY/figures/figures_26_1.jpg", "caption": "Figure 2: IPRM's computation flow diagram. First, a new set of N-parallel latent operations Zop are retrieved from language features XL conditioned on prior operation states Mop. Then, visual features Xy are queried conditioned on both Zop and prior result states results Mres, to form the new results Zres. Finally, both Zres and Zop are passed to the Operation Composition Unit (see 2.3 the output of which becomes the new memory state M.", "description": "This figure illustrates the computation flow of the Iterative and Parallel Reasoning Mechanism (IPRM).  It shows how IPRM iteratively processes information in three main steps: Operation Formation, Operation Execution, and Operation Composition. In the Operation Formation step, new parallel operations are generated from language features, conditioned on the previous memory state. The Operation Execution step retrieves visual information relevant to these new operations, also conditioned on previous results. Finally, the Operation Composition unit combines the results of the parallel operations and updates the memory state for the next iteration.", "section": "2 Iterative and Parallel Reasoning Mechanism"}]