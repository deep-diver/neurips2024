[{"figure_path": "ccQ4fmwLDb/figures/figures_1_1.jpg", "caption": "Figure 1: Schematic description of DDIM (left) and BELM (right). DDIM uses xi and \u03b5\u03b8 (\u03a7\u03af,\u03af) to calculate xi-1 based on a linear relation between xi, xi\u22121 and \u025b\u04e9(xi, i) (represented by the blue line). However, DDIM inversion uses xi\u22121 and \u025b\u0259 (xi\u22121, i \u2212 1) to calculate x\u2081 based on a different linear relation represented by the red line. This mismatch leads to the inexact inversion of DDIM. In contrast, BELM seeks to establish a linear relation between xi\u22121, Xi, Xi+1 and \u025b\u04e9(xi, i) (represented by the green line). BELM and its inversion are derived from this unitary relation, which facilitates the exact inversion. Specifically, BELM uses the linear combination of xi, xi+1 and \u025b\u03b8(xi, i) to calculate xi-1, and the BELM inversion uses the linear combination of xi\u22121, xi and \u025b\u03b8(xi, i) to calculate xi+1. The bidirectional explicit constraint means this linear relation does not include the derivatives at the bidirectional endpoint, that is, \u025b\u04e9 (xi\u22121, i \u2212 1) and \u025bo (xi+1, i + 1).", "description": "This figure compares the DDIM and BELM methods for diffusion model inversion.  DDIM uses a linear relationship between current and previous states and noise prediction, but the inversion uses a different relationship, leading to inexact inversion. BELM, however, uses a single, bidirectional linear relationship to define both forward and inverse processes, thus achieving exact inversion. This figure highlights the key difference between the approaches: the bidirectional explicit constraint in BELM ensures mathematical exactness.", "section": "2.3 Intuitive Exact Inversion Samplers of Diffusion Models"}, {"figure_path": "ccQ4fmwLDb/figures/figures_7_1.jpg", "caption": "Figure 2: Examples of editing results using O-BELM on both synthesized and real images. We showcase the diverse editing capabilities of O-BELM across a range of tasks, including human face modifications, content change, entity addition and global style transfer. The exact inversion property of O-BELM enables large-scale image alterations while preserving auxiliary details (background in first row, hairstyle in second row, traffic sign in third row, tree and crop in fourth row, composition in last row). Its stability and accuracy further ensure the high quality of the resulting images.", "description": "This figure shows various image editing results using the O-BELM model.  It demonstrates the model's ability to perform large-scale edits while preserving fine details, showcasing its accuracy and stability.", "section": "5 Experiments"}, {"figure_path": "ccQ4fmwLDb/figures/figures_8_1.jpg", "caption": "Figure 3: Comparison of editing results from different samplers under 50 steps. DDIM leads to inconsistencies (highlighted by the red rectangle), and the EDICT and BDIA samplers may introduce unrealistically low-quality sections (highlighted by the yellow rectangle). Our O-BELM sampler ensures consistency and demonstrates high-quality results.", "description": "This figure compares image editing results from four different diffusion models: DDIM, EDICT, BDIA, and the authors' proposed O-BELM.  It highlights the superior quality and consistency of O-BELM compared to the others, showcasing how O-BELM avoids inconsistencies and low-quality artifacts.", "section": "5 Experiments"}, {"figure_path": "ccQ4fmwLDb/figures/figures_17_1.jpg", "caption": "Figure 2: Examples of editing results using O-BELM on both synthesized and real images. We showcase the diverse editing capabilities of O-BELM across a range of tasks, including human face modifications, content change, entity addition and global style transfer. The exact inversion property of O-BELM enables large-scale image alterations while preserving auxiliary details (background in first row, hairstyle in second row, traffic sign in third row, tree and crop in fourth row, composition in last row). Its stability and accuracy further ensure the high quality of the resulting images.", "description": "This figure demonstrates the image editing capabilities of the O-BELM model.  It shows several examples of image editing tasks, including face modifications, content changes, and style transfers applied to both synthetic and real images. The results highlight O-BELM's ability to perform large-scale edits while maintaining fine details and demonstrating high-quality results. The caption emphasizes that the exact inversion property of O-BELM is key to achieving these results.", "section": "5 Experiments"}, {"figure_path": "ccQ4fmwLDb/figures/figures_27_1.jpg", "caption": "Figure 4: Results of image reconstruction and MSE error using DDIM and exact inversion samplers under 50 steps. The red rectangle point out the inconsistent part in the reconstructed images of DDIM.", "description": "This figure shows the results of image reconstruction using DDIM and three exact inversion samplers (EDICT, BDIA, and O-BELM) with 50 steps.  The original images are shown alongside their reconstructions using each method.  A key observation is that DDIM produces noticeably inconsistent reconstructions, highlighted by red rectangles, whereas the exact inversion methods achieve much more accurate reconstructions.", "section": "C.1 Image Reconstruction"}, {"figure_path": "ccQ4fmwLDb/figures/figures_29_1.jpg", "caption": "Figure 5: (a) uncurated CIFAR10 samples with BELM, steps = 100 (b) uncurated CelebA-HQ samples with BELM, steps = 100", "description": "This figure shows the image reconstruction results using the O-BELM sampler on the CIFAR10 and CelebA-HQ datasets.  The left panel (a) displays 256 images from the CIFAR10 dataset reconstructed using O-BELM with 100 steps, while the right panel (b) shows 64 images from the CelebA-HQ dataset, also reconstructed using O-BELM with 100 steps.  The figure visually demonstrates the high-quality sampling capabilities of the O-BELM method. ", "section": "C Experiments Details and Extra Results"}, {"figure_path": "ccQ4fmwLDb/figures/figures_30_1.jpg", "caption": "Figure 2: Examples of editing results using O-BELM on both synthesized and real images. We showcase the diverse editing capabilities of O-BELM across a range of tasks, including human face modifications, content change, entity addition and global style transfer. The exact inversion property of O-BELM enables large-scale image alterations while preserving auxiliary details (background in first row, hairstyle in second row, traffic sign in third row, tree and crop in fourth row, composition in last row). Its stability and accuracy further ensure the high quality of the resulting images.", "description": "This figure shows various image editing results obtained using the Optimal BELM (O-BELM) method.  It highlights O-BELM's ability to perform large-scale edits while preserving fine details and maintaining high image quality. Examples include face modifications, object addition, and style transfers.", "section": "5 Experiments"}, {"figure_path": "ccQ4fmwLDb/figures/figures_31_1.jpg", "caption": "Figure 2: Examples of editing results using O-BELM on both synthesized and real images. We showcase the diverse editing capabilities of O-BELM across a range of tasks, including human face modifications, content change, entity addition and global style transfer. The exact inversion property of O-BELM enables large-scale image alterations while preserving auxiliary details (background in first row, hairstyle in second row, traffic sign in third row, tree and crop in fourth row, composition in last row). Its stability and accuracy further ensure the high quality of the resulting images.", "description": "This figure shows several examples of image editing results using the O-BELM model. The examples illustrate the model's ability to perform a variety of edits, including changing facial features, adding or removing objects, and changing the overall style of the image.  The caption highlights that O-BELM's exact inversion property allows for large-scale edits while preserving fine details, and its stability ensures high-quality results.", "section": "5 Experiments"}, {"figure_path": "ccQ4fmwLDb/figures/figures_32_1.jpg", "caption": "Figure 8: Comparison of ControlNet-based editing results of different samplers. DDIM leads to inconsistencies (red rectangle), and the EDICT and BDIA samplers introduce low-quality sections (yellow rectangle). Our O-BELM sampler ensures consistency and demonstrates high-quality results, even in such large scale editing and still preserve features from original images (face in the first example and clothing in the second example).", "description": "This figure compares the performance of O-BELM, DDIM, EDICT, and BDIA on ControlNet-based image editing tasks using Canny edge detection and depth maps. The results show that O-BELM produces high-quality results that preserve original image features while the other methods suffer from inconsistencies or low-quality areas.", "section": "5.4 Training-free Image Editing"}, {"figure_path": "ccQ4fmwLDb/figures/figures_32_2.jpg", "caption": "Figure 2: Examples of editing results using O-BELM on both synthesized and real images. We showcase the diverse editing capabilities of O-BELM across a range of tasks, including human face modifications, content change, entity addition and global style transfer. The exact inversion property of O-BELM enables large-scale image alterations while preserving auxiliary details (background in first row, hairstyle in second row, traffic sign in third row, tree and crop in fourth row, composition in last row). Its stability and accuracy further ensure the high quality of the resulting images.", "description": "This figure shows several examples of image editing using the O-BELM method.  The examples demonstrate the ability of O-BELM to perform large-scale edits while preserving fine details and achieving high-quality results.  Different types of edits are shown, such as changing facial features, adding or removing objects, and changing the overall style of the image.", "section": "5 Experiments"}, {"figure_path": "ccQ4fmwLDb/figures/figures_33_1.jpg", "caption": "Figure 10: Image editing example for EDICT and BDIA with different hyperparameters, carried out over 200 steps. We observe that even within the interval advised in the original paper, the editing result may still diverge.", "description": "This figure shows the results of image editing experiments using EDICT and BDIA with varying hyperparameters. The results demonstrate that even within the recommended hyperparameter ranges, the editing results can be highly sensitive to the specific hyperparameters used, and in some cases, the results can diverge.  This highlights the instability and lack of robustness of these methods in image editing tasks.", "section": "Experiments"}]