{"importance": "This paper is crucial because **it challenges the common practice of solely relying on accuracy metrics to evaluate compressed LLMs**.  It highlights the limitations of accuracy in revealing significant behavioral changes in compressed models, a problem previously overlooked.  The proposed alternative metrics, % flips and KL-Divergence, provide more comprehensive insights for researchers, ultimately improving the reliability and effectiveness of model compression techniques.  This work also opens up **new avenues for research in evaluating free-form text generation models** and model compression in general, areas of growing importance in the field.", "summary": "LLM compression accuracy hides crucial behavioral changes;  use % flips and KL-divergence for better evaluation.", "takeaways": ["Accuracy alone is insufficient for evaluating compressed LLMs; significant changes can occur even with similar accuracy scores.", "% flips, a new metric, effectively captures the divergence in model behavior between the baseline and compressed models.", "KL-Divergence and % flips are well-correlated and serve as valuable alternative metrics to accuracy for evaluating compression techniques."], "tldr": "Large Language Models (LLMs) are expensive to run, so researchers are always looking for ways to compress them to make them smaller and faster. Traditionally, researchers have relied on accuracy metrics such as how well a compressed model performs on a benchmark, to measure how well the compression works. This paper shows that relying only on accuracy is not sufficient. Even when accuracy changes are small, the compressed model may change its answers surprisingly often, even when the overall accuracy on a benchmark does not change much. This unexpected behavior is called \"flips\". The authors propose to use two other metrics to evaluate model compression: percent flips and KL-divergence. They show that these metrics correlate highly with each other and with how well the compressed model performs on a multi-turn dialogue task, which demonstrates a more realistic use case for LLMs. \nThe paper's main contribution is showing that **accuracy alone is not enough to evaluate LLM compression**. It introduces new metrics, % flips and KL-divergence, and demonstrates their usefulness in evaluating the quality of compression techniques. The authors argue that % flips is especially valuable because it is an intuitive measure of how different a compressed model is from the original model and it is as easy to compute as accuracy.  This is important because it helps to ensure that the compressed models are truly comparable to the original models, something that is not always clear when just looking at accuracy.", "affiliation": "Microsoft Research", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "QVG7j29Sta/podcast.wav"}