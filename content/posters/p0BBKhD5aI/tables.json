[{"figure_path": "p0BBKhD5aI/tables/tables_3_1.jpg", "caption": "Table 1: The learning rates which should be applied to obtain the correct scale of updates for SGD or Adam optimizers. In addition, the weight variance and multiplier for the first layer may need to be rescaled (relative to eq (5)) with width/depth depending on the parameterization and optimizer.", "description": "This table shows how to scale the learning rate for both SGD and Adam optimizers to maintain the correct scale of updates to the weights and variables when using the parameterizations described in the paper.  It also indicates how the variance and multipliers for the first layer should be rescaled, depending on the chosen optimizer and parameterization.", "section": "2 Parameterizations with Feature Learning Limits"}, {"figure_path": "p0BBKhD5aI/tables/tables_20_1.jpg", "caption": "Table 1: The learning rates which should be applied to obtain the correct scale of updates for SGD or Adam optimizers. In addition, the weight variance and multiplier for the first layer may need to be rescaled (relative to eq (5)) with width/depth depending on the parameterization and optimizer.", "description": "This table presents the learning rate scaling for SGD and Adam optimizers to maintain consistent feature updates across different model sizes (N, H, L).  It also shows the necessary rescaling of the first layer's weights and multipliers, dependent on the optimizer and parameterization.", "section": "2 Parameterizations with Feature Learning Limits"}, {"figure_path": "p0BBKhD5aI/tables/tables_22_1.jpg", "caption": "Table 3: Two interesting choices of scaling for the attention layer exponent \u03b1<sub>A</sub> which give approximately constant updates to the attention matrices A<sub>h</sub>. The \u03bcP scaling \u03b1<sub>A</sub> = 1 causes the entries of the key/query vector entries to move non-negligibly but causes all heads to be identical (and all A = 0) at initialization. Scaling instead with \u03b1<sub>A</sub> = \u00bd causes the A variables to be random but still non-negligibly updated under training.", "description": "This table shows two different ways to scale the attention layer exponent (\u03b1<sub>A</sub>) to achieve approximately constant updates to the attention matrices (A<sub>h</sub>) during training.  The first uses the mean-field parameterization (\u03bcP) with \u03b1<sub>A</sub> = 1. This method, while resulting in non-negligible updates, causes all attention heads to behave identically and results in zero attention matrices (A<sub>h</sub>) at initialization. The second approach uses \u03b1<sub>A</sub> = \u00bd, which produces random, but non-negligible attention matrix updates.", "section": "C.4 What Counts as Feature Learning for Attention Layers?"}]