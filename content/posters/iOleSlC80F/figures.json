[{"figure_path": "iOleSlC80F/figures/figures_2_1.jpg", "caption": "Figure 1: The overview of the proposed 3DET-Mamba. The point clouds are first patched and fed into the Inner Mamba block to learn fine-grained local features, which are then sent to the Dual Mamba block to extract global representations. These encoded scene information and box queries go through the decoder, which includes Query-aware Mamba blocks and MLPs to generate the final bounding boxes. We employ the bipartite graph to match the predicted boxes with the ground truth and use a set loss for end-to-end optimization. Color is utilized only for visualization purposes.", "description": "The figure shows an overview of the 3DET-Mamba architecture, a novel end-to-end 3D object detection model based on the state space model (SSM).  Point clouds are divided into patches, processed by an Inner Mamba block to extract local features, and then further processed by a Dual Mamba block to capture global scene context.  These features and object queries are fed into a decoder comprised of Query-aware Mamba blocks and Multi-Layer Perceptrons (MLPs) to generate final bounding boxes. A bipartite matching scheme refines the output.", "section": "3 Method"}, {"figure_path": "iOleSlC80F/figures/figures_4_1.jpg", "caption": "Figure 2: Architecture of our scene feature aggregator that employs a novel local-to-global scanning mechanism. The raw point clouds are first sampled and patched using FPS and KNN. Within each patch, points are ranked by their distance from the patch center. The Inner Mamba block then scans these ranked points to extract local geometric features. Subsequently, patches are treated as tokens and serialized in two manners before being fed into the Dual Mamba block. This step scans all tokens, extracting comprehensive scene contexts.", "description": "This figure illustrates the scene feature aggregator which is a core component of the 3DET-Mamba model. It shows how the model extracts both local and global features from point cloud data. The process begins with sampling and grouping the points into patches, then using the Inner Mamba block to extract local features from each patch.  These local features are then processed by the Dual Mamba block, which models both the spatial distribution and continuity of the point cloud to capture global context.", "section": "3.3 Scene Feature Aggregator"}, {"figure_path": "iOleSlC80F/figures/figures_5_1.jpg", "caption": "Figure 3: Query-aware Mamba block.", "description": "The Query-aware Mamba block takes box queries and scene context as input, extracting tasked-related features from the scene context guided by the learnable queries. Each query sequence Fq is fed into a standard Mamba block to model the dependencies between queries. Meanwhile, scene features undergo the same process as the query sequence. Then, by multiplying the scene features with query embeddings, scene contexts are integrated into the query embeddings, and the updated queries are then passed through multiple MLP layers.", "section": "3.4 Decoder"}, {"figure_path": "iOleSlC80F/figures/figures_5_2.jpg", "caption": "Figure 1: The overview of the proposed 3DET-Mamba. The point clouds are first patched and fed into the Inner Mamba block to learn fine-grained local features, which are then sent to the Dual Mamba block to extract global representations. These encoded scene information and box queries go through the decoder, which includes Query-aware Mamba blocks and MLPs to generate the final bounding boxes. We employ the bipartite graph to match the predicted boxes with the ground truth and use a set loss for end-to-end optimization. Color is utilized only for visualization purposes.", "description": "This figure shows the overall architecture of the 3DET-Mamba model.  Point clouds are initially divided into patches. These patches are processed by the Inner Mamba block to extract local features, which are then fed into the Dual Mamba block for global context extraction. This combined information and learned bounding box queries are then passed to a decoder (with Query-aware Mamba blocks and MLPs) to predict the final bounding boxes for objects.  A bipartite graph matching is then used for evaluating performance, using a set loss for the end-to-end training.", "section": "3 Method"}, {"figure_path": "iOleSlC80F/figures/figures_8_1.jpg", "caption": "Figure 4: Visualization of detection results. 3DET-Mamba is able to generate tight bounding boxes for objects of interest in these complex and diverse scenes.", "description": "This figure shows a qualitative comparison of the 3DET-Mamba model's performance on several indoor scenes.  Each row represents a different scene, from left to right. The \"Input\" row displays the original point cloud input data.  The \"Our\" row shows the 3D bounding boxes predicted by the 3DET-Mamba model.  Finally, the \"GT\" row displays the ground truth bounding boxes for comparison. The orange boxes represent the model's predictions, while the green boxes represent the ground truth.  The figure illustrates the model's ability to accurately detect and localize objects within cluttered and complex environments.", "section": "4.4 Qualitative Results"}]