[{"figure_path": "nxL7eazKBI/figures/figures_2_1.jpg", "caption": "Figure 1: Disassembling process at the l-th layer of a CNN model, where the red solid line represents the contribution aggregation process, and the black dashed line represents the contribution allocation process.", "description": "This figure illustrates the process of disassembling a Convolutional Neural Network (CNN) at a specific layer (the l-th layer). The red lines show how contributions from input feature maps are aggregated to hidden feature maps via convolution filters.  The black dashed lines illustrate how these contributions are then allocated to various hidden feature maps through different convolution kernels.  This process helps in identifying the parameters most relevant to a specific task within the CNN.", "section": "3 Model Disassembling"}, {"figure_path": "nxL7eazKBI/figures/figures_5_1.jpg", "caption": "Figure 2: Assembling process at the l-th layer of CNN models: (a) and (b) represent two distinct disassembled models, respectively; (c) illustrates the assembled model.", "description": "This figure illustrates the process of assembling CNN models layer by layer.  Panels (a) and (b) show two different disassembled models, each with a different number of kernels in their filters. Panel (c) demonstrates how these models are combined using the alignment padding strategy, where empty kernels are added to ensure that all filters in the assembled model have a uniform number of kernels, ensuring a standardized structure for further processing.", "section": "4 Model Assembling"}, {"figure_path": "nxL7eazKBI/figures/figures_8_1.jpg", "caption": "Figure 3: Accuracy curve (a), FLOPs ratio curve (b), and model parameter size ratio curve (c) for the disassembled model, varying with hyperparameters in the fully connected layers (\u03b1f, \u03b2f) and convolutional layers (\u03b1c, \u03b2c).", "description": "This figure shows the impact of hyperparameters \u03b1 and \u03b2 on the performance of the disassembled model.  The hyperparameters \u03b1 and \u03b2 control the threshold for determining which parameters are most relevant to a given task.  The plots show that as the hyperparameter values increase, the accuracy decreases, while the FLOPs and parameter size also decrease. The effect of changing \u03b1 and \u03b2 is more pronounced in the convolutional layers compared to the fully connected layers.", "section": "5.4 Ablation Study"}, {"figure_path": "nxL7eazKBI/figures/figures_13_1.jpg", "caption": "Figure 1: Disassembling process at the l-th layer of a CNN model, where the red solid line represents the contribution aggregation process, and the black dashed line represents the contribution allocation process.", "description": "This figure illustrates the process of disassembling a Convolutional Neural Network (CNN) at a given layer (l).  The red lines show how the contributions from input feature maps are aggregated to produce hidden feature maps.  The black dashed lines show how those contributions are allocated to different convolutional kernels in that layer. This process is a key part of the Model Disassembling and Assembling (MDA) method, which aims to extract task-aware components from a trained CNN.", "section": "3 Model Disassembling"}, {"figure_path": "nxL7eazKBI/figures/figures_14_1.jpg", "caption": "Figure 6: Visualization of the soft relative contribution r(1) (as defined in Eqn.(8)) in the 13-th convolutional layer of the VGG-16 model trained on the CIFAR-10 dataset. Subfigure (a) depicts different input samples belonging to the same category, while subfigure (b) showcases input samples from different categories. Bright and dark colors respectively represent large and small values of relative contribution.", "description": "This figure visualizes the relative contribution of input features to the output of the 13th convolutional layer in a VGG-16 model trained on CIFAR-10.  (a) shows that inputs from the same category have similar contribution patterns. (b) demonstrates that inputs from different categories have distinct contribution patterns, highlighting the task-specific nature of these contributions.", "section": "3.2 Component Locating Technique"}, {"figure_path": "nxL7eazKBI/figures/figures_14_2.jpg", "caption": "Figure 2: Assembling process at the l-th layer of CNN models: (a) and (b) represent two distinct disassembled models, respectively; (c) illustrates the assembled model.", "description": "This figure illustrates the process of assembling CNN models layer by layer.  It shows how disassembled models (a and b), each with a different number of filters (kernels), are combined.  The alignment padding strategy is used to make the number of kernels uniform in the combined layer (c), ensuring compatibility during assembly.  The process involves padding empty kernels to each filter to ensure that all filters in a given layer have the same number of kernels.", "section": "4 Model Assembling"}, {"figure_path": "nxL7eazKBI/figures/figures_17_1.jpg", "caption": "Figure 8: Decision routes of the categories \u2018dog\u2019 and \u2018automobile\u2019 in the LeNet-5 model on the CIFAR-10 dataset, where the channels of the \u2018dog\u2019 and \u2018automobile\u2019 in layer 1 are the same, while in later layers, such as layer 2, 3, 4, and 5, they are totally different.", "description": "This figure visualizes the decision routes for the categories \"dog\" and \"automobile\" within the LeNet-5 model trained on the CIFAR-10 dataset.  It demonstrates how the pathways of activation through the network differ significantly between these two categories, even though they share some common channels in the initial layers.  The differences in pathways highlight how the model distinguishes between these categories by processing different features at different stages of the network.", "section": "H.1 Model Decision Route Visualization"}, {"figure_path": "nxL7eazKBI/figures/figures_19_1.jpg", "caption": "Figure 9: Visualization of the soft relative contribution  (as defined in Eqn.(8)) for input samples from different categories in layer 13 of VGG-16 on different datasets.", "description": "This figure visualizes the soft relative contribution for input samples from various categories in layer 13 of the VGG-16 model, trained on different datasets (MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet). Each row represents a different dataset, and the columns represent different categories within that dataset. The color intensity represents the magnitude of the soft relative contribution, with brighter colors indicating higher contribution values.  The visualization helps illustrate the varying levels of contribution different input features make towards the classification of distinct categories in different datasets, offering insight into how different datasets affect feature relevance in different layers of the CNN model.", "section": "More Visualization of Relative Contribution (\u00a7B)"}, {"figure_path": "nxL7eazKBI/figures/figures_19_2.jpg", "caption": "Figure 10: Visualization of the soft relative contribution r(1)q,p (as defined in Eqn.(8)) for input samples from different categories in layer 52 of ResNet-50 on different datasets.", "description": "This figure visualizes the soft relative contribution of input features to different categories in layer 52 of a ResNet50 model trained on several datasets (MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, Tiny-ImageNet). Each row represents a different dataset, and each column represents a different category within that dataset.  The color intensity reflects the magnitude of the contribution, with brighter colors indicating stronger contributions.", "section": "More Visualization of Relative Contribution (\u00a7B)"}, {"figure_path": "nxL7eazKBI/figures/figures_20_1.jpg", "caption": "Figure 11: Visualization of the soft relative contribution  (as defined in Eqn.(8)) for input samples from different categories in layer 66 of GoogleNet on different datasets.", "description": "This figure visualizes the soft relative contribution for input samples from different categories in layer 66 of the GoogleNet model, trained on various datasets.  Each row represents a different dataset (MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, Tiny-ImageNet), and within each row, different color intensities represent the relative contribution of different channels to the classification of a specific category. Darker colors represent smaller contributions, while brighter colors represent larger contributions. This visualization helps illustrate how different channels contribute differently across different datasets and categories.", "section": "More Visualization of Relative Contribution (\u00a7B)"}, {"figure_path": "nxL7eazKBI/figures/figures_21_1.jpg", "caption": "Figure 1: Disassembling process at the l-th layer of a CNN model, where the red solid line represents the contribution aggregation process, and the black dashed line represents the contribution allocation process.", "description": "This figure illustrates the process of disassembling a CNN model at a particular layer (l).  The red lines show how the contributions from input feature maps are aggregated to the hidden feature maps using a convolutional filter.  The black dashed lines demonstrate how these aggregated contributions are then allocated to the different hidden feature maps. This process is crucial for identifying the components of the CNN model that are most relevant to specific tasks.", "section": "3 Model Disassembling"}]