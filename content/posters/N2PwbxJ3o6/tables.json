[{"figure_path": "N2PwbxJ3o6/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of our method with previous in-context learning methods.", "description": "This table compares the performance of the proposed method (Partial2Global) against several existing in-context learning methods across three different tasks: foreground segmentation, single object detection, and image colorization.  The metrics used for evaluation are mean Intersection over Union (mIoU) for segmentation and detection, and Mean Squared Error (MSE) for colorization.  The table shows the performance of each method on four folds of data, along with an average. The results indicate that Partial2Global consistently outperforms other methods, achieving state-of-the-art results.", "section": "4.2 Main results"}, {"figure_path": "N2PwbxJ3o6/tables/tables_8_1.jpg", "caption": "Table 2: Ablation study among different variants of our method.", "description": "This table presents the ablation study results comparing different variations of the proposed method.  It compares the performance of three models: Rank-10 Naive (using a rank-10 model directly for selection), Rank-10 Aggr (using a rank-10 model with the consistency-aware aggregator), and Rank-{5,10} Aggr (the full model using both rank-5 and rank-10 models with the aggregator). The results are shown in terms of mean Intersection over Union (mIoU) for foreground segmentation and single object detection tasks.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_9_1.jpg", "caption": "Table 3: Ablation study among different backbones of our method.", "description": "This table presents the results of an ablation study comparing the performance of the proposed method using different backbone networks (CLIP, DINOv1, and DINOv2) for foreground segmentation and object detection tasks.  Two strategies are compared: a \"Naive\" approach using the ranking predictions directly and an \"Aggr.\" approach that incorporates a consistency-aware ranking aggregator.  The table shows the mIoU for segmentation and object detection across four folds and an average across all folds for each backbone and strategy.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_9_2.jpg", "caption": "Table 2: Ablation study among different variants of our method.", "description": "This table presents the ablation study comparing different variants of the proposed method.  It shows the performance (Seg. mIoU and Det. mIoU) of four models: SupPR (baseline), Rank-10 Naive (using a rank-10 model without aggregation), Rank-10 Aggr (using a rank-10 model with the consistency-aware aggregator), and Rank-{5,10} Aggr (the full model using both rank-5 and rank-10 models with aggregation). The results demonstrate the effectiveness of the proposed list-wise ranker and consistency-aware ranking aggregator in improving the overall performance.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_13_1.jpg", "caption": "Table 5: Cross-fold performance of our method on segmentation task.", "description": "This table presents the results of a cross-validation experiment evaluating the transferability of the proposed method for image segmentation.  The model trained on one fold of the dataset is tested on the remaining three folds. Each cell shows the mean Intersection over Union (mIoU) achieved on the target fold using the model trained on the source fold.  The diagonal elements represent the performance of the model on the training fold (i.e., no transfer learning).  The values show that while performance is reduced in cross-fold scenarios, the model trained with the proposed method generally exhibits better performance than competitors.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_13_2.jpg", "caption": "Table 6: Cross-fold performance of SupPR on segmentation task.", "description": "This table presents the results of a cross-validation experiment evaluating the performance of the SupPR model on the foreground segmentation task.  The model was trained on one fold of the Pascal-5i dataset and tested on the remaining folds.  The table shows the mean Intersection over Union (mIoU) achieved by SupPR on each test fold, when trained on each of the source folds. This demonstrates the model's generalizability and robustness across different training sets within the same dataset.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_13_3.jpg", "caption": "Table 7: Inference speed with different alternative set size.", "description": "This table shows the inference time for each query with different alternative set sizes (25, 50, and 100).  The inference time includes feature extraction, sub-sequence ranking with the list-wise ranker, and ranking aggregation.  The time increases with the size of the alternative set, as expected.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_13_4.jpg", "caption": "Table 1: Comparison of our method with previous in-context learning methods.", "description": "This table compares the performance of the proposed method (Ours) against several other methods for visual in-context learning on three tasks: foreground segmentation, single object detection, and colorization.  The performance metrics used are mean Intersection over Union (mIoU) for segmentation and detection, and Mean Squared Error (MSE) for colorization.  Results are shown for multiple folds of the dataset to provide a more robust evaluation.  The table shows the performance of methods both with and without a voting strategy to combine predictions. It highlights the improvements achieved by the proposed method in all tasks and with both strategies.", "section": "4.2 Main results"}, {"figure_path": "N2PwbxJ3o6/tables/tables_14_1.jpg", "caption": "Table 9: Ablation study for hyper-parameters.", "description": "This table presents the results of an ablation study on the hyperparameters delta (margin) and tau (temperature) used in the NeuralNDCG loss function.  It shows the Mean Squared Error (MSE) achieved for different values of these hyperparameters in a colorization task.  The results demonstrate the impact of these hyperparameters on model performance and help to determine optimal settings.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_14_2.jpg", "caption": "Table 10: Ablation study for different alternative set sizes.", "description": "This table shows the results of an ablation study conducted to evaluate the impact of varying the size of the alternative set on the performance of the proposed method.  The model was tested on all folds of the segmentation task with three different sizes of the alternative sets: 25, 50 (the main setting in the paper), and 100. The results demonstrate the robustness of the method to the size of the alternative set.", "section": "4.3 Model analysis"}, {"figure_path": "N2PwbxJ3o6/tables/tables_14_3.jpg", "caption": "Table 11: Ablation study for loss terms.", "description": "This table shows the result of ablation study on the effectiveness of different terms in the proposed loss function for the colorization task. The results indicate that all three loss terms contribute to the final performance, with Lsort playing the most important role.", "section": "4.3 Model analysis"}]