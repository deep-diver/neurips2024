[{"figure_path": "ZizwgYErtQ/figures/figures_3_1.jpg", "caption": "Figure 1: The Contextual Active Model Selection (CAMS) algorithm", "description": "This figure presents the CAMS algorithm, which consists of two main procedures: SETRATE and RECOMMEND.  SETRATE determines the learning rate for updating the probability distribution over policies, considering both stochastic and adversarial settings. RECOMMEND selects the model for prediction, using a weighted majority strategy for stochastic cases and random sampling for adversarial ones.  The algorithm dynamically queries labels based on model disagreement, balancing exploration and exploitation.", "section": "4 Contextual Active Model Selection"}, {"figure_path": "ZizwgYErtQ/figures/figures_6_1.jpg", "caption": "Figure 2: Main results. Comparison of CAMS with 7 baselines across 4 diverse benchmarks in terms of cost effectiveness. We plot the cumulative loss as we increase the query cost for a fixed number of rounds T and maximal query cost B (from left to right: T = 10000, 3000, 80, 4000, and B = 1200, 2000, 80, 2000). CAMS outperforms all baselines. Algorithms: 4 contextual {Oracle, CQBC, CIWAL, CAMS} and 4 non-contextual baselines {RS, QBC, IWAL, MP} are included (see Section ). 90% confident interval are indicated in shades.", "description": "The figure compares the performance of CAMS with seven other baseline methods across four different benchmark datasets. Each subplot displays the cumulative loss (y-axis) against the query cost (x-axis). The results demonstrate that CAMS consistently outperforms the baselines across all four datasets, showcasing its superior cost-effectiveness in active model selection.", "section": "6 Experiments"}, {"figure_path": "ZizwgYErtQ/figures/figures_7_1.jpg", "caption": "Figure 3: Ablation studies. (a) Comparing three query strategies {CAMS, variance-based, random} under same model selection policy. (b) Comparing the increasing rate of CAMS' query cost over other baselines. (c) Comparing CAMS with MP in context-free environment. (d) Evaluating the performance of CAMS under a pure adversarial setting. (e) Large dataset (COVTYPE). (f,g) Adjustable query probability. (h) CAMS vs best policy (HIV).", "description": "This figure presents ablation studies on the proposed CAMS algorithm.  Panel (a) compares different query strategies (CAMS, variance-based, random) while keeping the model selection strategy fixed. Panel (b) shows the query cost increase rate for CAMS versus other baselines.  Panels (c) and (d) evaluate CAMS performance in context-free and pure adversarial settings respectively. Panel (e) displays results for a larger dataset (COVTYPE). Panels (f) and (g) show results when adjusting query probabilities for VERTEBRAL and HIV datasets respectively. Finally, panel (h) shows a comparison between CAMS and the best policy for the HIV dataset.", "section": "6 Experiments"}, {"figure_path": "ZizwgYErtQ/figures/figures_29_1.jpg", "caption": "Figure 4: Comparing CAMS with 7 baselines on CovType in terms of relative cumulative loss, query complexity, and cost effectiveness. CAMS outperforms all baselines. (Left) Performance measured by relative cumulative loss (i.e., loss against the best classifier) under a fixed query cost B (where B = 1000). (Middle) Number of queries and (Right) Performance of cumulative loss by increasing the query cost, for a fixed number of rounds T (where T = 100,000) and maximal query cost B (where B = 5000). Algorithms: 4 contextual {Oracle, CQBC, CIWAL, CAMS} and 4 non-contextual baselines {RS, QBC, IWAL, MP} are included (see Section 6.1). 90% confident intervals are indicated in shades.", "description": "This figure compares the performance of CAMS against seven baseline algorithms on the CovType dataset in terms of relative cumulative loss, the number of queries needed, and cost-effectiveness.  The left panel shows the relative cumulative loss (loss compared to the best classifier) under a fixed query budget. The middle panel displays the cumulative number of queries, and the right panel illustrates the cumulative loss as the query cost increases.  CAMS consistently outperforms all baselines across all three metrics.", "section": "6 Experiments"}, {"figure_path": "ZizwgYErtQ/figures/figures_29_2.jpg", "caption": "Figure 5: Ablation study of three query strategies (entropy, variance, random) for 4 diverse benchmarks based on the same model recommendation strategy. Under the same query cost constraint, CAMS's entropy-based strategy exceeds the performance of the other two strategies on non-binary benchmarks in terms of query cost and cumulative lost. 90% confident intervals are indicated in shades.", "description": "This figure compares three different query strategies (entropy, variance, and random) used in the CAMS algorithm.  The experiment is conducted on four diverse benchmark datasets (CIFAR10, DRIFT, VERTEBRAL, and HIV). The results show that the entropy-based query strategy used in CAMS significantly outperforms the variance and random strategies in terms of both query cost and cumulative loss, particularly for datasets with non-binary classification tasks. The use of 90% confidence intervals helps to quantify the reliability of the results and provides a visual representation of the uncertainty associated with each data point.", "section": "6.2 Ablation studies"}, {"figure_path": "ZizwgYErtQ/figures/figures_30_1.jpg", "caption": "Figure 6: Comparing CAMS with every single policy (only plotted top performance policies in Figure). CAMS could approach the best expert and exceed all others with limited queries. In particular, on VERTEBRAL and HIV Benchmarks, CAMS outperforms the best expert. 90% confident intervals are indicated in shades.", "description": "This figure compares the performance of CAMS against all individual policies (showing only the top performers for clarity) across four datasets: CIFAR10, DRIFT, VERTEBRAL, and HIV.  The results demonstrate that CAMS consistently achieves a cumulative loss comparable to or even better than the best performing individual policy, while often requiring significantly fewer queries.  It's particularly notable that CAMS outperforms the best policy in the VERTEBRAL and HIV datasets.", "section": "G.3 Comparing CAMS with each individual expert"}, {"figure_path": "ZizwgYErtQ/figures/figures_30_2.jpg", "caption": "Figure 2: Main results. Comparison of CAMS with 7 baselines across 4 diverse benchmarks in terms of cost effectiveness. We plot the cumulative loss as we increase the query cost for a fixed number of rounds T and maximal query cost B (from left to right: T = 10000, 3000, 80, 4000, and B = 1200, 2000, 80, 2000). CAMS outperforms all baselines. Algorithms: 4 contextual {Oracle, CQBC, CIWAL, CAMS} and 4 non-contextual baselines {RS, QBC, IWAL, MP} are included (see Section). 90% confident interval are indicated in shades.", "description": "The figure compares the performance of CAMS against 7 other algorithms (4 contextual and 3 non-contextual) on four different benchmark datasets.  The x-axis represents the query cost (number of labels requested), and the y-axis represents the cumulative loss.  The plots show that CAMS consistently outperforms the other algorithms in terms of cost-effectiveness, achieving a lower cumulative loss for the same query cost.", "section": "6 Experiments"}, {"figure_path": "ZizwgYErtQ/figures/figures_30_3.jpg", "caption": "Figure 8: Evaluating the robustness of CAMS compared to the conventional learning from experts' advice (CAMS-conventional) in a complete malicious and random policies environment. When no good policy is available, CAMS could recover from malicious advice and successfully approach the performance of the best classifier. In contrast, the conventional approach will be trapped in malicious advice. 90% confident intervals are indicated in shades.", "description": "This figure compares the performance of CAMS and a conventional approach in an adversarial environment with only malicious and random policies.  The results show that CAMS is robust, adapting to the situation and approaching the performance of the best classifier. In contrast, the conventional approach is trapped and its performance suffers.  The experiment is conducted on four datasets.", "section": "G.5 Robustness against malicious experts in adversarial environments"}, {"figure_path": "ZizwgYErtQ/figures/figures_31_1.jpg", "caption": "Figure 9: Comparing CAMS, CAMS-MAX and CAMS-RANDOM-POLICY with top policies and classifiers in the VERTEBRA and HIV benchmarks. They outperform all the malicious/random policies. Moreover, CAMS and CAMS-MAX outperform the best classifier. Finally, only CAMS even exceeds the best policy (Oracle) in both benchmarks and continues approaching the hypothetical, optimal policy (0 cumulative loss). 90% confident intervals are indicated in shades.", "description": "This figure compares the performance of three variants of CAMS (CAMS, CAMS-MAX, and CAMS-random-policy) against top-performing policies and classifiers on two benchmark datasets (VERTEBRAL and HIV).  The results show that all three CAMS variants outperform policies that provide malicious or random advice.  Interestingly, both CAMS and CAMS-MAX surpass the performance of the single best classifier. Most notably, CAMS achieves even better performance than the best policy (Oracle), consistently moving toward the hypothetical optimal solution of zero cumulative loss.", "section": "G.6 Outperformance over the best policy/expert"}, {"figure_path": "ZizwgYErtQ/figures/figures_32_1.jpg", "caption": "Figure 1: The Contextual Active Model Selection (CAMS) algorithm", "description": "The figure shows the pseudocode of the CAMS algorithm, which consists of two main procedures: SETRATE and RECOMMEND.  SETRATE determines the learning rate based on whether the setting is stochastic or adversarial. RECOMMEND selects the model to use for prediction, again using different methods depending on the setting. The algorithm incorporates an adaptive query strategy to strategically request labels to minimize cost.", "section": "4 Contextual Active Model Selection"}, {"figure_path": "ZizwgYErtQ/figures/figures_32_2.jpg", "caption": "Figure 1: The Contextual Active Model Selection (CAMS) algorithm", "description": "The figure shows the pseudocode for the CAMS algorithm, which consists of two main procedures: SETRATE and RECOMMEND.  SETRATE determines the learning rate and query probability based on whether the setting is stochastic or adversarial. RECOMMEND selects a model based on the current context and the probability distribution over policies. The algorithm iteratively receives data points, makes predictions, and decides whether to query the true label based on a calculated uncertainty metric. The process updates model loss and policy probabilities to refine future decisions.", "section": "4 Contextual Active Model Selection"}, {"figure_path": "ZizwgYErtQ/figures/figures_33_1.jpg", "caption": "Figure 2: Main results. Comparison of CAMS with 7 baselines across 4 diverse benchmarks in terms of cost effectiveness. We plot the cumulative loss as we increase the query cost for a fixed number of rounds T and maximal query cost B (from left to right: T = 10000, 3000, 80, 4000, and B = 1200, 2000, 80, 2000). CAMS outperforms all baselines. Algorithms: 4 contextual {Oracle, CQBC, CIWAL, CAMS} and 4 non-contextual baselines {RS, QBC, IWAL, MP} are included (see Section). 90% confident interval are indicated in shades.", "description": "The figure compares the performance of CAMS against seven other baseline methods on four different benchmark datasets. The x-axis represents the query cost (number of labels requested), and the y-axis shows the cumulative loss. The results show that CAMS consistently outperforms all other methods across all four datasets.", "section": "6 Experiments"}, {"figure_path": "ZizwgYErtQ/figures/figures_34_1.jpg", "caption": "Figure 2: Main results. Comparison of CAMS with 7 baselines across 4 diverse benchmarks in terms of cost effectiveness. We plot the cumulative loss as we increase the query cost for a fixed number of rounds T and maximal query cost B (from left to right: T = 10000, 3000, 80, 4000, and B = 1200, 2000, 80, 2000). CAMS outperforms all baselines. Algorithms: 4 contextual {Oracle, CQBC, CIWAL, CAMS} and 4 non-contextual baselines {RS, QBC, IWAL, MP} are included (see Section ). 90% confident interval are indicated in shades.", "description": "The figure compares the performance of CAMS against seven baseline methods across four different benchmark datasets.  The x-axis represents the query cost (number of labels requested), and the y-axis represents the cumulative loss.  Each subplot corresponds to a different dataset. The results show that CAMS consistently outperforms all the baselines in terms of cost-effectiveness, achieving a lower cumulative loss for the same query cost.", "section": "6 Experiments"}, {"figure_path": "ZizwgYErtQ/figures/figures_35_1.jpg", "caption": "Figure 14: Comparing CAMS (in red) with CAMS-nonactive (in blue) on 4 diverse benchmarks in terms of query complexity, and cost effectiveness. CAMS outperforms or performs equally well to CAMS-nonactive with much less queried labels for all benchmarks. (Top) Number of queries and (Bottom) Performance of cumulative loss by increasing the query cost, for a fixed number of rounds T (where T = 5000, 3000, 80, 4000 from left to right) and maximal query cost B (where B = T = 5000, 3000, 80, 4000 from left to right). 90% confident interval are indicated in shades.", "description": "This figure compares the performance of CAMS and a non-active variant (CAMS-nonactive) across four benchmark datasets. CAMS-nonactive queries labels for every incoming data point. The figure shows that CAMS performs equally well or better than CAMS-nonactive, even though it queries significantly less data. The upper plots show the number of queries over rounds, while the lower plots show the cumulative loss with respect to the query cost.", "section": "G.12 Ablation study on the active query strategy"}, {"figure_path": "ZizwgYErtQ/figures/figures_35_2.jpg", "caption": "Figure 15: Comparing CAMS with 7 baselines on 4 diverse benchmarks in terms of loss trajectory. CAMS outperforms all baselines. Performance measured by relative cumulative loss (i.e., loss against the best classifier) under a fixed query cost B (where B = 200, 400, 30, 400 from left to right). Algorithms: 4 contextual {Oracle, CQBC, CIWAL, CAMS} and 4 non-contextual baselines {RS, QBC, IWAL, MP} are included (see Section ). 90% confident interval are indicated in shades.", "description": "This figure compares the performance of CAMS against 7 other baseline methods (4 contextual and 3 non-contextual) across 4 different benchmark datasets (CIFAR10, DRIFT, VERTEBRAL, HIV). The performance is measured by relative cumulative loss, which represents the difference between the cumulative loss of each method and the cumulative loss of the best classifier.  The figure shows that CAMS consistently outperforms all other methods across all datasets, achieving negative relative cumulative loss in many cases. This indicates that CAMS not only learns effectively but also surpasses the performance of simply selecting the best classifier.", "section": "6 Experiments"}, {"figure_path": "ZizwgYErtQ/figures/figures_36_1.jpg", "caption": "Figure 16: Comparison of CAMS with 7 baselines on IMAGENET benchmark in terms of cost effectiveness. We plot the cumulative loss as we increase the query cost for a fixed number of rounds T and maximal query cost B (T = 3000, and B = 2500). CAMS outperforms all baselines. Algorithms: 4 contextual {Oracle, CQBC, CIWAL, CAMS} and 4 non-contextual baselines {RS, QBC, IWAL, MP} are included. 90% confident interval are indicated in shades.", "description": "This figure compares the performance of CAMS against seven baseline methods on the ImageNet dataset.  The x-axis represents the query cost (number of labels requested), and the y-axis shows the cumulative loss. The plot demonstrates that CAMS achieves the lowest cumulative loss compared to all other methods, both contextual and non-contextual, for a fixed number of rounds and a maximum query cost.", "section": "H Experiments on ImageNet"}]