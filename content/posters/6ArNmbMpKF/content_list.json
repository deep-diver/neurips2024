[{"type": "text", "text": "Noisy Dual Mirror Descent: A Near Optimal Algorithm for Jointly-DP Convex Resource Allocation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Du Chen\u2217 Geoffrey A. Chua Nanyang Business School, Nanyang Technological University, Singapore, 639798 chen1443@e.ntu.edu.sg, gbachua@ntu.edu.sg ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study convex resource allocation problems with $m$ hard constraints under $(\\varepsilon,\\delta)$ - joint differential privacy (Joint-DP or JDP) in an offilne setting. To approximately solve the problem, we propose a generic algorithm called Noisy Dual Mirror Descent. The algorithm applies noisy Mirror Descent to a dual problem from relaxing the hard constraints for private shadow prices, and then uses the shadow prices to coordinate allocations in the primal problem. Leveraging w\u221aeak duality theory, we show that the optimality gap is u\u221apper bounded by O( m ln\u03b5 (1/\u03b4)) strong duality holds, both preceding results can be\u03b5 improved to $\\tilde{\\mathcal{O}}(\\frac{\\sqrt{\\ln\\left(1/\\delta\\right)}}{\\varepsilon})$ by existing works. To complement our results under strong duality, we derive a minimax lower bound $\\Omega\\left({\\frac{m}{\\varepsilon}}\\right)$ for any JDP algorithm outputting feasible allocations. The lower bound matches our upper bounds up to some logarithmic factors for $\\varepsilon\\geq\\operatorname*{max}\\{1,1/(n\\gamma)\\}$ , where $n\\gamma$ is the available resource level. Numerical studies further confirm the effectiveness of our algorithm. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The resource allocation problem is a classic optimization problem and has many applications in machine learning, such as Internet advertising and personalized recommendation, among many others. The problem is typically modeled as a utility maximization problem, where the central decision maker has to properly allocate $m$ types of limited resources to $n$ agents in order to maximize the total utility of all agents. Each agent\u2019s data $z_{i}:=(u_{i}(\\cdot),\\mathbf{a}_{i}(\\cdot),\\mathcal{X}_{i})$ consists of three elements: (i) a utility function $u_{i}:\\mathbb{R}_{+}^{s}\\rightarrow\\mathbb{R}_{+}$ that maps an allocation $\\pmb{x}_{i}$ to a utility scalar; (ii) a consumption function $\\pmb{a}_{i}:\\mathbb{R}_{+}^{s}\\rightarrow\\mathbb{R}_{+}^{m}$ that maps an allocation $\\pmb{x}_{i}$ to a consumption vector; and (iii) a feasible set $\\mathcal{X}_{i}\\subseteq\\mathbb{R}_{+}^{s}$ that may capture the agent\u2019s special requirements. With a dataset $\\mathcal{D}:=\\{z_{i}\\}_{i=1}^{n}$ of $n$ agents, the problem is modeled as ", "page_idx": 0}, {"type": "text", "text": "(Resource Allocation Problem) ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{\\{\\pmb{x}_{i}\\}_{i=1}^{n}}}&{\\sum_{i=1}^{n}u_{i}(\\pmb{x}_{i})}\\\\ {\\mathrm{s.t.~}}&{\\displaystyle\\sum_{i=1}^{n}a_{i}(\\pmb{x}_{i})\\leq n\\gamma\\pmb{b};}\\\\ &{\\displaystyle\\pmb{x}_{i}\\in\\mathcal{X}_{i},\\quad\\forall i=1,2,\\ldots,n,}\\end{array}\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $n\\gamma b>0$ is the available level of $m$ types of resources. Evidently, the goal in (1) is to find the best allocation $\\pmb{x}_{i}$ for each agent subject to resource-coupling constraints (2) and to a personal requirement constraint (3). When $u_{i}(\\cdot)$ is concave, and $a_{i}(\\cdot)$ , $\\mathcal{X}_{i}$ are both convex, the problem reduces to a convex constrained problem that has been widely studied in optimization literature. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "However, an emerging issue in allocation problems is data privacy. Because constraint (2) couples agents, the allocation decision to one agent would affect the allocation to another agent. When a group of agents collude, they can infer other agents\u2019 data by analyzing their received allocations. For example, when allocating limited budgets among education agencies to support students in poverty, a simple rule is to allocate budgets proportional to the number of students in poverty [SLWA22]. Agencies who notice a change in received funding may infer the financial status of students in other agencies. Realizing this potential leakage of its students\u2019 financial status, an agency may misreport the number of its students in poverty, compromising the original intention of the financial support. ", "page_idx": 1}, {"type": "text", "text": "To overcome privacy concerns in such cases, joint differential privacy (Joint-DP or JDP, for short), which is a relaxation of differential privacy (DP), has been adopted. It is found that JDP is more suitable than DP for the considered allocation problems $[\\mathrm{HHR}^{+}14]$ . Essentially, JDP ensures agent $i$ \u2019s data cannot be accurately inferred by a group of collusive agents without $i$ . It guarantees that the allocations received by the collusive agents are insensitive to agent $i$ \u2019s data. Considering that the allocation decision $\\pmb{x}_{i}$ is usually private to agent $i$ herself, the privacy guarantee by JDP is hence meaningful and sufficiently strong. The most handy way to achieve JDP is by the well-known Billboard Lemma $[\\mathrm{HHR}^{+}1\\dot{4}]$ : publish a DP public signal on a billboard accessible to all agents, and compute the allocation for agent $i$ based on the DP public signal and agent $i$ \u2019s own data only; then the final allocations $(x_{1},\\ldots,x_{n})$ satisfy JDP. The Billboard Lemma has wide applications, ranging from convex optimization $[\\mathrm{HHR}^{+}14$ , HHRW16, HZ18], to multi-armed bandits [SS18, $\\mathrm{HLL}^{+}22\\bar{]}$ , to reinforcement learning [VBKW20]. We also use it for privacy analysis. For clarification purposes, we highlight that, in problem (1), dataset $\\{z_{i}\\}_{i=1}^{n}:=\\{(u_{i}(\\cdot),\\pmb{a}_{i}(\\cdot),\\mathcal{X}_{i})\\}_{i=1}^{n}$ is the private information to protect; resource level $n\\gamma b$ is treated as public information. ", "page_idx": 1}, {"type": "text", "text": "While important and fundamental, resource allocation problems under JDP are far from being well understood, in terms of both algorithm design and theoretical analysis. For algorithm design, most existing works adopt a \u201cdual decomposition\u201d idea [HHRW16, HZ18], which dualizes the coupling constraint (2) and iteratively seeks private minimizers of a dual problem to coordinate the allocation process in the primal problem. However, the primal-dual relationship and the geometric structure of the dual space are not well exploited, leaving substantial room for improvement. In terms of theoretical analysis, both privacy accounting and optimality analysis are short of modern standard. For privacy accounting, existing works [HHRW16, HZ18, HZ19] all use Advanced Composition, which suggests an unnecessarily large noise to be injected, significantly hindering algorithm practicability. For optimality analysis, [HHRW16] fails to take full advantage of strong assumptions made, and the analysis by [HZ18] is specific to linear packing problems. More importantly, there is no formal understanding of the fundamental trade-off between privacy and optimality in resource allocation problems under JDP, i.e. minimax lower bounds. Motivated by these gaps in the literature, we focus our study on the following three questions. ", "page_idx": 1}, {"type": "text", "text": "1. Can we design a generic algorithm for resource allocation problem (1), and provide better privacy and optimality analysis? 2. Can we better utilize the primal-dual relationship to improve performance? 3. Is our algorithm (near) optimal? What is the minimax lower bound? ", "page_idx": 1}, {"type": "text", "text": "Our contributions First, we propose a generic algorithm Noisy Dual Mirror Descent, which follows a similar dual decomposition idea. We tighten the privacy analysis through R\u00e9nyi DP, and analyze performance (both optimality and constraint violations) by better utilizing the primal-dual relationship. Second, for many cases where strong duality holds, we further improve performance by leveraging on the $\\ell_{1}$ geometry of the dual space. Last, we complement previous analysis with a matching minimax lower bound for $\\varepsilon\\,\\geq\\,\\operatorname*{max}\\{1,1/(n\\gamma)\\}$ , suggesting near optimality of our algorithm. We further conduct numerical experiments to show the effectiveness of our proposed algorithm. Table 1 summarizes our contributions and compares them with results in the literature. ", "page_idx": 1}, {"type": "text", "text": "Our interpretation of algorithm performance Because the algorithms considered may output infeasible solutions, when assessing their performance, we should take into account both suboptimality in utility and constraint violations, i.e., the last two columns in Table 1. We therefore treat the sum of them as the ultimate performance. This idea admits a social welfare interpretation: when the central decision maker (e.g., a government) desires to implement an infeasible allocation, she may purchase additional resources from an emergency supplier to make the allocation feasible. Then, the total loss in social welfare is the sum of (i) the loss in utility of agents and (ii) the decision maker\u2019s expenditure on extra resources. If we only look at suboptimality, we may mistakenly conclude that the gap could be arbitrarily small. Following our interpretation of performance, our proposed algorithm is near optimal. ", "page_idx": 1}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/6eb8005d1de72a0dbaed61b9de609b09da8635bd876d894f02c82a8fab0fb608.jpg", "table_caption": ["Table 1: Comparison of various works on resource allocation problems under $(\\varepsilon,\\delta)$ -JDP. "], "table_footnote": ["Notes. All results in the table are stated for $\\varepsilon\\,\\leq\\,\\ln\\left({1}/{\\delta}\\right)$ for conciseness; $_m$ , $n,T$ are the number of constraints, agents, and iterations, respectively. Tilde symbol $\\widetilde O$ hides poly-log factors in $_m$ ; for results in [HHRW16, HZ18], $\\widetilde O$ additionally hides poly-log terms in $_n$ and $_T$ . LB=lower bound, UB=upper bound, w.h.p=with high probability. \u2021 The algorithm in [HHRW16] can be practically applied to general convex problems. But one supporting Lemma (Theorem 2.1) they used to derive analytical results is only valid for linear problems with solutions in probability simplex. \u00a7 An lower bound $\\widetilde{\\Omega}(\\frac{\\sqrt{m}}{\\varepsilon})$ can be derived from [HZ18, Theorem 1.2]. But their original statement is for the minimal supply, not for suboptimality as we considered.  The lower bound is for algorithms outputting feasible allocations, while upper bounds are achieved by algorithms that may output infeasible allocations. So, the lower bound could be higher. The lower bound holds only for $\\varepsilon\\ge\\operatorname*{max}\\{1,1/(n\\gamma)\\}$ where $\\gamma\\in(0,1)$ . "], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Related work JDP was initially proposed by [KPRU14] as a relaxation of differential privacy [DR14], which better ftis the nature of privacy issues in zero-sum games, such as allocation problems $[\\mathrm{HHR}^{+}14$ , CKRW15]. Following this stream, the most relevant works to ours are [HHRW16, HZ18], both of which designed their algorithms with a dual decomposition idea. [HHRW16] proposed the first generic method, dual gradient descent, for solving allocation problems. For the special case of linear packing problem, [HZ18] designed a dual multiplicative weight update algorithm, and extended it to online setting. [GU22] further provides an economic interpretation of payoff sharing. Our work is also closely related to Mirror Descent (MD) [NY83], a generalization of projected gradient descent to non-Euclidean settings. Its private version, Noisy MD, has recently found many applications in non-Euclidean DP stochastic convex optimization [AFKT21, BGN21] and saddle-point problems [GGP24]. We further apply Noisy MD to JDP resource allocation problems. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Definition 2.1 (Differential privacy, [DR14]). A mechanism ${\\mathcal{M}}:{\\mathcal{Z}}^{n}\\to{\\mathcal{P}}$ is $(\\varepsilon,\\delta)$ -differentially private $i f,$ , for any pair of neighboring datasets $\\mathcal{D}\\sim\\mathcal{D}^{\\prime}$ that differ in one data point, and for any subset of output ${\\mathcal{S}}\\subseteq{\\mathcal{P}}$ , we have $\\mathbb{P}\\left[\\mathcal{\\bar{M}}(\\mathcal{D})\\in\\mathcal{S}\\right]\\leq e^{\\varepsilon}\\cdot\\mathbb{P}\\left[\\mathcal{M}(\\mathcal{D}^{\\prime})\\in\\mathcal{S}\\right]+\\delta.$ . ", "page_idx": 2}, {"type": "text", "text": "Throughout the work, we use the subscript $-i$ to indicates variables without agent $i$ . For example, $\\mathcal{X}_{-i}\\,:=\\,\\mathcal{X}_{1}\\,\\times\\,\\cdot\\,\\cdot\\,\\mathcal{X}_{i-1}\\,\\times\\,\\mathcal{X}_{i+1}\\,\\cdot\\,\\cdot\\,\\times\\,\\mathcal{X}_{n}$ is a feasible space without $i$ , and $\\mathcal{M}(\\mathcal{D})_{-i}\\;:=$ $(\\bar{\\mathcal{M}}(\\mathcal{D})_{1},\\ldots,\\mathcal{M}(\\mathcal{D})_{i-1},\\mathcal{M}(\\mathcal{D})_{i+1},\\ldots,\\mathcal{M}(\\mathcal{D})_{n})$ is the view from other agents without $i$ . ", "page_idx": 2}, {"type": "text", "text": "Definition 2.2 (Joint differential privacy, [KPRU14]). A mechanism $\\mathcal{M}:\\mathcal{Z}^{n}\\rightarrow\\mathcal{X}^{n}$ is $(\\varepsilon,\\delta)$ -jointly differentially private if for any pair of neighboring datasets $\\mathcal{D}\\sim\\mathcal{D}^{\\prime}$ that differ in datapoint $i\\in[n]$ , and for any subset of outputs $S\\subseteq\\mathcal{X}_{-i}$ , we have $\\mathbb{P}\\left[\\mathcal{M}(\\mathcal{D})_{-i}\\in S\\right]\\leq e^{\\varepsilon}\\cdot\\mathbb{P}\\left[\\mathcal{M}(\\mathcal{D}^{\\prime})_{-i}\\in S\\right]+\\delta$ . ", "page_idx": 2}, {"type": "text", "text": "Lemma 2.3 (Billboard Lemma, $[\\mathrm{HHR}^{+}14]\\rangle$ ). Suppose ${\\mathcal{M}}:{\\mathcal{Z}}^{n}\\to{\\mathcal{P}}$ is $(\\varepsilon,\\delta)$ -DP. For any given function $f:\\mathcal{Z}\\times\\mathcal{P}\\rightarrow\\mathcal{X}$ , denote the output of $f$ on individual $i$ \u2019s data as $f_{i}:=\\bar{f}\\!\\left(z_{i},\\mathcal{M}(\\mathcal{D})\\right)$ . Then, $(f_{1},\\ldots,f_{n})$ is $(\\varepsilon,\\delta)$ -JDP. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.4 ( $\\alpha$ -strong convexity). Let $\\alpha\\,>\\,0$ . Function $\\ell:\\mathbb{R}^{m}\\to\\mathbb{R}$ is said to be $\\alpha$ -strongly convex w.r.t. $\\left\\|\\cdot\\right\\|_{p}$ over set $\\begin{array}{r}{\\mathcal{W},\\,i f\\ell(\\pmb{x})\\geq\\ell(\\pmb{y})+\\langle\\nabla\\ell(\\pmb{y}),\\pmb{x}-\\pmb{y}\\rangle+\\frac{\\alpha}{2}\\left\\|\\pmb{x}-\\pmb{y}\\right\\|_{p}^{2},\\forall\\pmb{x},\\pmb{y}\\in\\mathcal{W}.}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Primal problem in a condensed form Let $\\pmb{x}:=(\\pmb{x}_{1},\\ldots,\\pmb{x}_{n})$ be the collection of allocations. For a given dataset $\\mathcal{D}$ , let $\\begin{array}{r}{\\mathsf{F}({\\pmb x})\\,:=\\,\\sum_{i=1}^{n}u_{i}({\\pmb x}_{i})}\\end{array}$ be the total utility when allocation is $\\textbf{\\em x}$ . Let $\\begin{array}{r}{{\\pmb a}({\\pmb x}):=\\sum_{i=1}^{n}{\\pmb a}_{i}({\\pmb x}_{i})}\\end{array}$ be the total co nsumed resource, and let $\\mathcal{X}:=\\mathcal{X}_{1}\\times\\cdot\\cdot\\cdot\\times\\mathcal{X}_{n}$ be the feasible region.  Then, the resource allocation problem (1), referred to as \u201cprimal problem\u201d later, can be written in a condensed form: ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\mathrm{(Primal~Problem)}}\\qquad\\operatorname*{max}_{x\\in{\\mathcal{X}}}\\left\\{\\mathsf{F}({\\pmb x}):a({\\pmb x})\\leq n\\gamma{\\pmb b}\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The optimal allocation is denoted as $\\pmb{x}^{*}:=\\arg\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}}\\{\\mathsf{F}(\\pmb{x}):\\pmb{a}(\\pmb{x})\\leq{n}\\gamma\\pmb{b}\\}.$ ", "page_idx": 3}, {"type": "text", "text": "Dual problem By dualizing the coupling constraint with shadow prices $\\mathbf{\\nabla}p\\geq\\mathbf{0}$ , we get a Lagrangian function $\\scriptstyle\\operatorname*{min}_{\\mathbf{p}\\geq\\mathbf{0}}\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{X}}$ $\\{{\\bar{\\mathsf{F}}}(\\pmb{x})+{\\bar{\\langle}}\\pmb{p},{\\bar{n^{\\gamma}}}\\pmb{b}-\\pmb{a}(\\pmb{x})\\rangle\\}$ . Thus, the Lagrangian dual problem is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}{\\mathrm{(Dual\\,Problem)}}&{{}}&{\\underset{p\\geq0}{\\mathrm{min}}\\;\\mathsf{D}(p),}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathsf{D}(p):=\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}}\\left\\{\\mathsf{F}(\\pmb{x})+\\left\\langle\\pmb{p},n\\gamma b-\\pmb{a}(\\pmb{x})\\right\\rangle\\right\\}}\\end{array}$ . It is easy to see that, given $\\pmb{p}\\geq\\mathbf{0}$ , the dual problem is decomposable across agents, i.e., $\\begin{array}{r}{\\mathsf{D}(\\pmb{p})=\\sum_{i=1}^{n}\\operatorname*{max}_{\\pmb{x}_{i}\\in\\mathcal{X}_{i}}\\left\\{u_{i}(\\pmb{x})+\\langle\\pmb{p},\\gamma\\pmb{b}-\\pmb{a}_{i}(\\pmb{x}_{i})\\rangle\\right\\}}\\end{array}$ . Let us denote the dual problem\u2019s minimizer by $p^{*}:=\\arg\\operatorname*{min}_{p\\geq0}\\mathsf{D}(p)$ . ", "page_idx": 3}, {"type": "text", "text": "When there are multiple $x^{*}$ and $\\pmb{p}^{*}$ , we can break ties arbitrarily. Let $\\left\\|\\cdot\\right\\|_{p}$ denote the $p$ -norm of a vector, and let $[n]:=\\{1,\\ldots,n\\}$ be a running set. We impose some assumptions on dataset $\\mathcal{D}$ to make both primal and dual problems interesting. ", "page_idx": 3}, {"type": "text", "text": "Assumption 2.5 (Interesting instances). For a dataset $\\mathcal{D}:=\\{(u_{i}(\\cdot),\\mathbf{a}_{i}(\\cdot),\\mathcal{X}_{i})\\}_{i=1}^{n}$ , we assume ", "page_idx": 3}, {"type": "text", "text": "1. Convexity: for each $i\\in[n]$ , utility function $u_{i}$ is concave on $\\mathcal{X}_{i}$ , consumption function $\\pmb{a}_{i}$ is convex on $\\mathcal{X}_{i}$ , and $\\mathcal{X}_{i}$ is a convex set;   \n2. Boundedness: \u2203 $\\bar{u}>0$ and bounded $b>0$ with $\\|\\pmb{b}\\|_{2}\\leq B$ such that $u_{i}(\\pmb{x}_{i})\\in[0,\\overline{{u}}]$ and ${\\pmb{a}}_{i}({\\pmb{x}}_{i})\\in[{\\bf0},{\\pmb{b}}],\\,\\forall{\\pmb{x}}_{i}\\in\\mathcal{X}_{i},i\\in[n]$ . Specially, $i f\\mathbf{0}\\in\\mathcal{X}_{i}$ , then $u_{i}(\\mathbf{0})=0$ and $\\mathbf{\\boldsymbol{a}}_{i}(\\mathbf{\\boldsymbol{0}})=\\mathbf{\\boldsymbol{0}}$ ;   \n3. Limited resource: the constant $\\gamma$ in (4) is assumed to be in the interval $(0,1)$ . The primal problem (4) is feasible, and optimal $x^{*}$ is attainable. Under $x^{*}$ , at least one of m constraints in (4) is binding. Moreover, the optimal shadow prices $\\pmb{p}^{*}$ to dual problem (5) are not all zeros, i.e., $\\lVert\\pmb{p}^{*}\\rVert_{1}\\neq0$ ;   \n4. Compulsory request allowed: request $i$ can be compulsory in the sense that $\\mathcal{X}_{i}\\geqslant{\\bf0}$ , only if $\\begin{array}{r}{\\operatorname*{max}_{\\pmb{x}_{i}\\in\\mathcal{X}_{i}}\\left\\{u_{i}(\\pmb{x}_{i})+\\langle\\pmb{p}^{*},-\\pmb{a}_{i}(\\pmb{x}_{i})\\rangle\\right\\}\\geq0.}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "These assumptions are very mild. The first assumption restricts our attention to convex problems. The second one assumes both utility and consumption functions are non-negative and bounded from above, and are both zeros if no resource is allocated. The third one assumes the non-private problem is indeed resource-constrained and not ill-posed. The constant $\\gamma$ controls available resource levels, and $n\\gamma$ means the number of agents whose requests can be fully fulfilled. In practice, usually $\\gamma\\geq1/n$ . The fourth one allows agents to propose compulsory requests with minimal requirements strictly greater than 0, as long as allocating resource to the agent is beneficial. Our assumptions are weaker than those in the literature [HZ18, BLM20, BLM23] by allowing compulsory requests. ", "page_idx": 3}, {"type": "text", "text": "3 The algorithm and analysis ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our algorithm is a private version of Mirror Descent applied to the dual problem (5). Mirror Descent (MD) [NY83] is a generalization of Projected Gradient Descent (Proj-GD) that can better cater to the geometry of the problem at hand by the proper choice of a strongly convex potential function $\\Phi:\\bar{\\mathcal{W}}\\to\\mathbb{R}^{\\dot{+}}$ . The potential function chosen should meet some conditions below. ", "page_idx": 3}, {"type": "text", "text": "Condition 3.1 (Potential Functions). The potential function $\\Phi:\\mathcal{W}\\to\\mathbb{R}_{+}$ chosen should be (i) differentiable on $i n t(\\mathcal{W})$ , i.e., the interior of its domain $\\boldsymbol{\\mathcal{W}}\\subseteq\\mathbb{R}^{m}$ ; and (ii) $\\alpha$ -strongly convex with respect to $\\left\\|\\cdot\\right\\|_{p}$ on $\\mathcal{W}$ . For a given $\\Phi$ , let $B_{\\Phi}(\\pmb{x},\\pmb{y}):=\\,\\Phi(\\pmb{x})-\\Phi(\\pmb{y})-\\langle\\nabla\\Phi(\\pmb{y}),\\pmb{x}-\\pmb{y}\\rangle$ be the Bregman divergence between $x\\in\\mathcal{W},y\\in i n t(\\mathcal{W})$ . ", "page_idx": 4}, {"type": "text", "text": "With the primal problem (4) and dual problem (5) in mind, and a well-chosen potential function, we are ready to present the algorithm, Noisy Dual Mirror Descent. The algorithm is an iterative ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 Noisy Dual Mirror Descent for Resource Allocation Problems, $\\boldsymbol{\\mathcal{A}}$ Parameters: privacy parameters $(\\varepsilon,\\delta)$ , variance $\\sigma^{2}$ ; stepsizes $\\{\\eta^{(t)}\\}_{t=1}^{T}$ ; potential function $\\Phi(\\cdot):$   \n$\\mathcal{W}\\to\\mathbb{R}_{+}$ that is $\\alpha$ -strongly convex with respect to $\\ell_{p}$ -norm; conjugate index $q$ s.t. $1/q+1/p=1$ ,   \nnumber of iterations $T$ , feasible region of shadow prices $\\mathcal{P}:=\\mathbb{R}_{+}^{m}$ . 1: Set initial point $p^{(1)}\\in\\mathcal{P}\\cap\\mathrm{int}(\\mathcal{W})$ 2: for $t=1$ to $T$ do   \n3: Get intermediate allocation decision $\\pmb{x}^{(t)}\\gets\\arg\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}}\\mathsf{F}(\\pmb{x})+\\left\\langle\\pmb{p}^{(t)},\\gamma n\\pmb{b}-\\pmb{a}(\\pmb{x})\\right\\rangle$   \n4: Draw a noise vector $\\mathbf{n}^{(t)}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}I_{m\\times m})$ 5: Update private shadow prices according to Noisy Mirror Descent: $\\begin{array}{r}{\\boldsymbol{p}^{(t+1)}\\xleftarrow{\\arg\\operatorname*{min}}_{\\boldsymbol{p}\\in\\mathcal{P}\\cap\\mathcal{W}}\\left\\{\\boldsymbol{\\eta}^{(t)}\\cdot\\left\\langle\\mathbf{g}^{(t)}+\\mathbf{n}^{(t)},\\boldsymbol{p}\\right\\rangle+B_{\\Phi}(\\boldsymbol{p},\\boldsymbol{p}^{(t)})\\right\\},}\\end{array}$ (6) where $\\mathbf{g}^{(t)}:=n\\gamma\\pmb{b}-\\pmb{a}(\\pmb{x}^{(t)})$   \n6: Final allocation decision $\\begin{array}{r}{\\pmb{x}^{A}:=(\\pmb{x}_{1}^{A},\\pmb{\\dots},\\pmb{x}_{n}^{A})\\leftarrow\\frac{1}{T}\\sum_{t=1}^{T}\\pmb{x}^{(t)}}\\end{array}$   \n7: Output $\\pmb{x}_{i}^{A}$ to agent $i$ , for all $i\\in[n]$ ", "page_idx": 4}, {"type": "text", "text": "algorithm, and in each iteration, we first calculate allocation decisions based on current shadow prices $\\pmb{p}^{(t)}$ , i.e. Step 3. Then, we update the shadow prices by Noisy Mirror Descent update rule (6). The gradient $\\mathbf{g}^{(t)}$ used is exactly the gradient of the dual problem $\\mathsf{D}(\\pmb{p}^{(t)})$ according to Danskin\u2019s theorem. After $T$ iterations, we output the averaging allocations across all iterations. In other words, we basically apply Noisy Mirror Descent to solve the dual problem, and use the sequence of shadow prices to coordinate allocations in the primal problem. Intuitively, the shadow prices are implicitly pricing each resource to ensure that limited resources are allocated to agents most in need. ", "page_idx": 4}, {"type": "text", "text": "Recall the Billboard Lemma, if we can privatize the entire sequence of shadow prices in a DP manner, then the final allocation decisions will be JDP. Compared to existing works invoking Advanced Composition, we provide a tighter privacy accounting through R\u00e9nyi DP. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.2 (JDP Guarantee). Given $\\varepsilon>0,\\delta\\in(0,1)$ and $T\\geq1$ , if noise variance $\\sigma^{2}=T\\cdot c_{\\varepsilon,\\delta}$ with $\\begin{array}{r}{c_{\\varepsilon,\\delta}:=\\left\\|b\\right\\|_{2}^{2}\\cdot\\left(\\frac{2\\ln\\left(1/\\delta\\right)}{\\varepsilon^{2}}+\\frac{1}{\\varepsilon}\\right)}\\end{array}$ , then Algorithm $1\\,A$ is $(\\varepsilon,\\delta)$ -JDP. ", "page_idx": 4}, {"type": "text", "text": "To better align with expressions in DP literature, we can assume $\\varepsilon\\le\\ln\\left({1}/{\\delta}\\right)$ . Then, the magnitude of $c_{\\varepsilon,\\delta}$ becomes $\\frac{\\ln{(1/\\delta)}}{\\varepsilon^{2}}$ , a magnitude of Gaussian Mechanism that frequently appears in DP literature. Moreover, the privacy analysis via R\u00e9nyi DP significantly lowers the variance level. For example, when $\\varepsilon=1$ , $\\delta=10^{-3}$ , and $\\left\\|\\pmb{b}\\right\\|_{2}^{2}=1$ , the variance indicated by Theorem 3.2 is $14.8T$ , compared to approximately $121.6T$ by [HHRW16, Theorem 3.2], [HZ18, Lemma 3.1]. ", "page_idx": 4}, {"type": "text", "text": "3.1 Performance upper bounds ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now move on to analyze the utility optimality gap $\\mathsf{F}(\\pmb{x}^{*})-\\mathbb{E}_{\\mathcal{A}}\\left[\\mathsf{F}(\\pmb{x}^{\\mathcal{A}})\\right]$ . The following weak duality lemma bridges the primal and dual problems. ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.3 (Weak duality). For any $\\pmb{p}\\geq\\mathbf{0}$ , the objective value of dual problem (5) is always greater than or equal to that of primal problem (4), i.e., $\\mathsf{D}(\\pmb{p})\\geq\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}}$ $\\{\\mathsf{F}(\\pmb{x}):\\pmb{a}(\\pmb{x})\\leq n\\gamma\\pmb{b}\\}$ , $\\forall p\\geq\\mathbf{0}$ . ", "page_idx": 4}, {"type": "text", "text": "An immediate result of weak duality is $\\mathsf{D}(\\pmb{p}^{(t)})\\geq\\mathsf{F}(\\pmb{x}^{\\ast}),\\forall t$ . Hence, applying weak duality and Jensen\u2019s inequality, the optimality gap $\\mathsf{F}(\\pmb{x}^{\\bar{*}})-\\mathsf{F}(\\pmb{x}^{A})$ can be upper bounded as follows, provided ", "page_idx": 4}, {"type": "text", "text": "the randomness dice of $\\boldsymbol{\\mathcal{A}}$ is fixed, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{}^{*}({\\pmb x}^{*})-{}\\mathbb{F}({\\pmb x}^{A})\\leq\\frac{1}{T}\\sum_{t=1}^{T}\\left({\\sf D}({\\pmb p}^{(t)})-{}\\mathbb{F}({\\pmb x}^{(t)})\\right)=\\frac{1}{T}\\sum_{t=1}^{T}\\left<{\\pmb p}^{(t)},n\\gamma b-{\\pmb a}({\\pmb x}^{(t)})\\right>}}\\\\ {{\\displaystyle{}=\\frac{1}{T}\\sum_{t=1}^{T}\\left<{\\pmb p}^{(t)},{\\pmb\\mathbf g}^{(t)}+\\mathbf n^{(t)}\\right>-\\frac{1}{T}\\sum_{t=1}^{T}\\left<{\\pmb p}^{(t)},\\mathbf n^{(t)}\\right>,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the first equality is by definition of the dual problem, and the second equality is by definition of gradient $\\mathbf{g}^{(t)}$ . Taking expectation with respect to $\\boldsymbol{\\mathcal{A}}$ removes the subtrahend, since $\\dot{\\mathbf{n}}^{(t)}$ is independent of $\\pmb{p}^{(t)}$ and zero-mean, which gives $\\begin{array}{r}{\\mathsf{F}({\\pmb x}^{*})-\\mathbb{E}_{{\\pmb A}}\\left[\\mathsf{F}({\\pmb x}^{{\\cal A}})\\right]\\le\\mathbb{E}_{{\\pmb A}}\\left[\\frac{1}{T}\\sum_{t=1}^{T}\\left\\langle{\\pmb p}^{(t)},{\\mathbf{g}}^{(t)}+\\mathbf{n}^{(t)}\\right\\rangle\\right]}\\end{array}$ . The inner term is closely related to stationarity gap [GL13, $\\mathrm{ABG}^{+}23]$ in nonconvex optimization. It is well-known that Proj-GD guarantees a small stationarity gap in both non-private $[\\mathbf{J}\\mathbf{N}\\mathbf{G}^{+}21]$ and private $[\\mathrm{ABG}^{+}23]$ cases. Not surprisingly, MD can also achieve a small stationarity gap. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.4 (Cumulative stationarity gap of MD). Suppose stepsizes $\\eta^{(t)}=\\eta$ in MD update rule (6) are the same for all $t\\in[T]$ , and let $\\{\\widetilde{\\mathbf{g}}^{(t)}\\}_{t=1}^{T}$ be gradients used for update. Then the cumulative stationarity gap $\\begin{array}{r}{\\sum_{t=1}^{T}\\left\\langle\\pmb{p}^{(t)}-\\pmb{p},\\widetilde{\\mathbf{g}}^{(t)}\\right\\rangle.}\\end{array}$ for any anchor point $\\pmb{p}\\in\\mathcal{P}\\cap\\mathcal{W}$ is upper bounded as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left\\langle p^{(t)}-p,\\widetilde{\\mathbf{g}}^{(t)}\\right\\rangle\\leq\\frac{\\eta\\sum_{t=1}^{T}\\left\\Vert\\widetilde{\\mathbf{g}}^{(t)}\\right\\Vert_{q}^{2}}{2\\alpha}+\\frac{B_{\\Phi}(p,p^{(1)})}{\\eta},\\quad\\forall p\\in\\mathcal{P}\\cap\\mathcal{W}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "With Lemma 3.4 and proper stepsizes, we can control the optimality gap. Denote $\\bar{\\gamma}:=\\operatorname*{max}\\{\\gamma,1\\!-\\!\\gamma\\}$ , $G:=\\left.\\bar{\\gamma}^{2}n^{2}\\left\\Vert\\pmb{b}\\right\\Vert_{q}^{2}.$ , and let $z\\sim\\mathcal{N}(\\mathbf{0},I_{m\\times m})$ be a standard Gaussian random vector. For a given potential function $\\Phi$ and an initial point $\\pmb{p}^{(1)}$ , denote $C_{\\Phi}(\\pmb{p}^{(1)}):=\\sqrt{B_{\\Phi}(\\mathbf{0},\\pmb{p}^{(1)})/\\alpha}$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.5 (Utility guarantee). Set stepsizes $\\begin{array}{r}{\\eta^{(t)}\\;=\\;\\sqrt{\\frac{\\alpha B_{\\Phi}(\\mathbf{0},p^{(1)})}{T\\cdot(G+\\sigma^{2}\\mathbb{E}[\\|z\\|_{q}^{2}])}},\\forall t\\;\\in\\;[T]}\\end{array}$ . Suppose potential function\u2019s domain includes 0, i.e., $\\textbf{0}\\in\\mathcal{W}$ . Then running algorithm $\\boldsymbol{\\mathcal{A}}$ with iterations T \u2265 c\u03b5,\u03b4\u00b7E[\u2225z\u2225q2] and $\\sigma^{2}$ chosen in Theorem 3.2 yields ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{F}(\\pmb{x}^{*})-\\mathbb{E}_{\\pmb{A}}\\left[\\mathsf{F}(\\pmb{x}^{\\pmb{A}})\\right]\\leq4C_{\\Phi}(\\pmb{p}^{(1)})\\sqrt{\\mathbb{E}\\left[\\|\\pmb{z}\\|_{q}^{2}\\right]}\\cdot\\sqrt{c_{\\varepsilon,\\delta}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "An instantiation of the utility guarantee is by $\\begin{array}{r}{\\Phi(\\cdot)=\\frac{1}{2}\\left\\|\\cdot\\right\\|_{2}^{2}}\\end{array}$ , which is 1-strongly convex w.r.t. $\\ell_{2}$ -norm on $\\mathbb{R}^{m}$ . Then, the upper bound in (7) becomes $2\\sqrt{2m}\\left\\|\\pmb{p}^{(1)}\\right\\|_{2}\\cdot\\sqrt{c_{\\varepsilon,\\delta}}$ , which depends on the choice of initial point $\\pmb{p}^{(1)}$ . It seems the bound can be arbitrarily small if $\\pmb{p}^{(1)}$ is close to 0. But in fact, the theorem itself does not reflect the whole picture, since $x^{\\tilde{A}}$ could be infeasible. Therefore, we have to further examine $\\boldsymbol{\\mathcal{A}}$ \u2019s feasibility guarantee. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.6 (Feasibility guarantee). Given allocation decision $x^{A}$ , denote the violation levels as $v^{A}:=(\\mathbf{a}(\\mathbf{x}^{A})-n\\gamma b)^{\\dagger}$ , where positive part operator $(\\cdot)^{+}$ applies element-wisely. In addition to Condition 3.1, additionally assume the domain $\\mathcal{W}$ of potential function $\\Phi$ contains 2 $\\|\\pmb{p}^{*}\\|_{1}\\pmb{e}_{j},\\forall j\\in$ $[m]$ . Then, running algorithm $\\boldsymbol{\\mathcal{A}}$ with the same setting as in Theorem 3.5 yields ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}\\left[\\left\\|v^{A}\\right\\|_{\\infty}\\right]\\leq\\left(\\frac{2\\sqrt{\\mathbb{E}\\left[\\left\\|z\\right\\|_{q}^{2}\\right]}\\cdot C_{\\Phi,1}(p^{(1)})}{\\sqrt{\\alpha}\\cdot\\left\\|p^{*}\\right\\|_{1}}+2\\sqrt{2\\ln m}\\right)\\cdot\\sqrt{c_{\\varepsilon,\\delta}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\Sigma}_{\\mathbb{C}\\Phi,1}(p^{(1)})=\\frac{B_{\\Phi}(\\mathbf{0},p^{(1)})+\\operatorname*{max}_{e\\in E_{1}}B_{\\Phi}(2\\|p^{*}\\|_{1}e,p^{(1)})}{\\sqrt{B_{\\Phi}(\\mathbf{0},p^{(1)})}},s e t\\;E_{1}:=\\{e\\in\\{0,1\\}^{m}:(\\mathbf{1},e)\\leq1\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The proof idea is to sandwich the cumulative stationarity gap $\\begin{array}{r}{\\sum_{t=1}^{T}\\left\\langle p^{(t)}-p,\\widetilde{\\mathbf{g}}^{(t)}\\right\\rangle}\\end{array}$ at a properly chosen anchor point $\\pmb{p}:=\\,2\\,\\|\\pmb{p}^{*}\\|_{1}\\,\\pmb{e}_{j^{A}}\\,\\in\\,\\mathcal{P}\\cap\\mathcal{W}$ (the constant 2 is chosen arbitrarily, it can be any value strictly greater than 1), and then comparing the upper bound and lower bound in the sandwich inequality gives the desired result. The base vector $e_{j^{A}}$ with a single 1 on $j^{\\mathcal{A}}$ -th position indicates which constraint $j^{\\mathcal{A}}\\in[m]$ is most severely violated. One may notice that the anchor point $p:=2\\left\\|p^{*}\\right\\|_{1}e_{j}{\\boldsymbol{A}}$ needs to be in $\\mathcal{P}\\cap\\mathcal{W}$ , which implicitly imposes one additional condition on the domain $\\mathcal{W}$ of potential function $\\Phi$ . While the capability of computationally calculating $\\|\\pmb{p}^{*}\\|_{1}$ is not needed for deriving (8), on a practical note, we may need to adjust $\\mathcal{W}$ accordingly so that $\\mathcal{W}$ contains all possible anchor points $2\\,\\|\\pmb{\\dot{p}}^{*}\\|_{1}\\,\\pmb{e}_{j^{\\mathcal{A}}},\\forall j^{\\mathcal{A}}$ almost surely. When doing so, we should be very careful because $\\pmb{p}^{*}$ depends on dataset $\\mathcal{D}$ and thus, such an adjustment may leak privacy. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Again, one may think $\\begin{array}{r}{\\Phi(\\cdot)\\,=\\,\\frac{1}{2}\\left\\|\\cdot\\right\\|_{2}^{2}}\\end{array}$ is the ideal potential function, because its domain $\\boldsymbol{\\mathcal{W}}=\\mathbb{R}^{m}$ contains all anchor points of interest, does not depend on $\\pmb{p}^{*}$ , and therefore no privacy leakage risk. As shown in the first row of Table 2, the guarantees under squared $\\ell_{2}$ are only comparable to, not better than, those in the literature summarized in Table 1. Nevertheless, being comparable is already a significant improvement because our results are derived from weak duality only, whereas existing works all assume strong duality. Moreover, since anchor points $p=2\\,\\|p^{*}\\|_{1}\\,e_{j^{A}}$ are related to $\\ell_{1}$ norm of $\\pmb{p}^{*}$ , if we can find a data-independent upper bound for the value of $\\left\\|p^{*}\\right\\|_{1}^{\\;-}$ , we might be able to adjust $\\mathcal{W}$ accordingly without privacy concerns and may further improve performance. We do so in the next subsection. ", "page_idx": 6}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/b377035714c39e3e55048757aac4fdcf8ae730d1dd206d1f9e6c6796924d7230.jpg", "table_caption": ["Table 2: Examples of theoretical guarantees under specific choices of hyperparameters. "], "table_footnote": ["Notes. Results for squared $\\ell_{2}$ (negative entropy) are from Section 3.1 (Section 3.2). Strong duality is necessary for theoretical guarantees by (parameterized) negative entropy. Abbreviations in column titles: cvx. $,=$ onvexity, init.pt.=initial point, opt.gap $=$ optimality gap, contrs.viol. $=c$ constraint violations. The (scaled) simplex set $\\Delta_{K}(b)$ with radius $K$ is defined as $\\Delta_{K}(\\pmb{b})\\;:=\\;\\{\\pmb{p}\\;\\geq\\;\\mathbf{0}\\;:\\;\\langle\\pmb{b},\\pmb{p}\\rangle\\;\\leq\\;K\\}$ ; the standard simplex is $\\Delta_{K}:=\\Delta_{K}({\\bf1})$ . $^\\dagger$ Squared $\\ell_{2}$ function is strongly convex on whole space $\\mathbb{R}^{m}$ , while negative entropy functions only on their respective domains. Results in the first and second rows are highlighted as the main contributions in Table 1. "], "page_idx": 6}, {"type": "text", "text": "3.2 Improvements by strong duality ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Indeed, there exists space for improvement, if we assume strong duality holds. ", "page_idx": 6}, {"type": "text", "text": "Assumption 3.7 (Strong duality holds). Strong duality between primal problem (4) and dual problem (5) holds, i.e., $\\mathsf{F}(\\pmb{x}^{*})=\\mathsf{D}(\\pmb{p}^{*})$ , where $x^{*}$ and $\\pmb{p}^{*}$ are optimal solutions to (4) and (5), respectively. ", "page_idx": 6}, {"type": "text", "text": "While weak duality always holds, strong duality does not universally hold. However, there are many applications where strong duality naturally holds. For example, when the dualized constraint $a(x)\\leq\\bar{n}\\gamma b$ is linear in $\\textbf{\\em x}$ , strong duality holds. If the constraint is not linear, one can check strong duality by Slater\u2019s condition, which essentially says that if the primal problem (4) has strictly feasible solutions, then strong duality holds. The strong duality assumption here is also very mild, and all examples previously considered in the literature satisfy strong duality, for example [HHRW16, Section 4] and [HZ18]. However, these works fail to take full advantage of strong duality. We flil the gap by noticing that strong duality actually restricts $\\pmb{p}^{*}$ to an $\\ell_{1}$ space. ", "page_idx": 6}, {"type": "text", "text": "Lemma 3.8 (Strong duality implies bounded $\\pmb{p}^{*}$ ). Let $p^{*}:={\\mathrm{~arg~min}}_{p\\geq0}\\,\\mathsf{D}(p)$ . Then, under assumptions 2.5 and 3.7, we have $\\begin{array}{r}{\\langle\\boldsymbol{b},\\boldsymbol{p}^{*}\\rangle\\leq\\frac{\\bar{\\boldsymbol{u}}}{\\gamma}}\\end{array}$ and $\\langle\\mathbf{1},p^{*}\\rangle\\leq\\frac{\\bar{u}}{\\gamma b}$ with $\\begin{array}{r}{\\underline{{b}}:=\\operatorname*{min}_{j}\\{b_{j}\\}}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "The above lemma indicates that $\\pmb{p}^{*}$ lies in the interior of a scaled simplex, suggesting the best choice of potential function could be the negative entropy function, which better ftis the $\\ell_{1}$ geometry. However, negative entropy $\\begin{array}{r}{\\Phi({\\pmb w})=\\sum_{j=1}^{m}{\\bar{w}}_{j}\\ln w_{j}}\\end{array}$ is widely known to be 1-strongly convex only on the probability simplex $\\Delta_{1}:=\\{\\pmb{w}>\\mathbf{0}:\\langle\\mathbf{1},\\pmb{w}\\rangle=1\\}$ . To tailor it for our studied problem, we parameterize the negative entropy $\\begin{array}{r}{\\Phi({\\boldsymbol w};{\\boldsymbol\\theta}):=\\sum_{j=1}^{m}(\\theta_{j}{\\boldsymbol w}_{j})\\ln\\left(\\theta_{j}{\\boldsymbol w}_{j}\\right)}\\end{array}$ with $\\mathbf{\\theta}_{\\theta}>\\mathbf{0}$ , and show that it is also strongly convex in a scaled simplex. ", "page_idx": 6}, {"type": "text", "text": "Lemma 3.9 (Strong convexity of parameterized negative entropy). Let the parameterized negative entropy $\\begin{array}{r}{\\Phi(\\boldsymbol{w};\\boldsymbol{\\theta}):=\\sum_{j=1}^{m}(\\partial_{j}\\boldsymbol{w}_{j})\\ln\\left(\\theta_{j}\\boldsymbol{w}_{j}\\right)}\\end{array}$ be defined on $\\mathbb{R}_{+}^{m}$ , where we define $\\begin{array}{r}{\\frac{0}{0}=0}\\end{array}$ and $0\\ln0=0$ by continuity. Then $\\Phi(\\boldsymbol{w};\\boldsymbol{\\theta})$ is $(\\operatorname*{min}_{j}\\{\\theta_{j}\\})^{2}/K$ -strongly convex in w w.r.t. $\\left\\Vert\\cdot\\right\\Vert_{1}$ in a scaled simplex $\\Delta_{K}^{\\mathrm{int}}(\\pmb\\theta):=\\left\\{\\pmb w>\\mathbf0:\\left\\langle\\pmb\\theta,\\pmb w\\right\\rangle\\le K\\right\\}$ . ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "It is immediate to see that if we set ${\\pmb\\theta}={\\bf1}$ and $K=1$ , then Lemma 3.9 recovers the well-known result that negative entropy is 1-strongly convex. For our studied problem, we can let the negative entropy be parameterized by $^{b}$ , and use $\\begin{array}{r}{\\Phi(\\boldsymbol{w};\\boldsymbol{b})=\\sum_{j=1}^{m}(b_{j}{w_{j}})\\ln\\left(b_{j}{w_{j}}\\right)}\\end{array}$ for the Mirror Descent update step (6). This does not compromise privacy, since $^{b}$ is a universal upper bound and is not associated with any specific agent. Now, we are ready to improve the algorithm\u2019s performance. ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.10 (Improved utility $\\&$ feasibility guarantees). Let $\\bar{b}:=\\,\\operatorname*{max}_{j}\\{b_{j}\\}$ , $\\underline{{b}}:=\\operatorname*{min}_{j}\\{b_{j}\\}$ . Under assumptions 2.5 and 3.7, running algorithm 1 $\\boldsymbol{\\mathcal{A}}$ with parameterized negative entropy $\\Phi(w;b)$ with radius $K:=2\\bar{u}/\\gamma,\\,p_{j}^{(1)}=K/(m b_{j}),\\forall j\\in[m]$ , and same $T$ , $\\sigma^{2}$ as in Theorem 3.5 yields ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{(u t i l i t y\\ g u a r a n t e e)}&{\\ F({\\pmb x}^{*})-\\mathbb{E}_{{\\pmb A}}\\left[\\mathsf{F}({\\pmb x}^{{\\pmb A}})\\right]\\leq\\frac{8\\sqrt{2}\\bar{\\pi}\\cdot\\sqrt{\\ln\\left(2m\\right)}}{\\gamma\\underline{{b}}}\\cdot\\sqrt{c_{\\varepsilon,{\\pmb\\delta}}};}\\\\ {e a s i b i l i t y\\ g u a r a n t e e)}&{\\qquad\\mathbb{E}_{{\\pmb A}}\\left[\\|{\\pmb v}^{{\\pmb A}}\\|_{\\infty}\\right]\\leq\\frac{4\\bar{u}\\sqrt{2\\ln\\left(2m\\right)}\\cdot\\left[2+\\bar{b}\\cdot\\left(\\ln\\left(m\\bar{b}\\right)-1\\right)^{+}\\right]}{\\gamma\\underline{{b}}\\cdot\\|{\\pmb p}^{*}\\|_{1}}\\cdot\\sqrt{c_{\\varepsilon,{\\pmb\\delta}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Com\u221apared to the results in Theorems 3.5 and 3.6 where both dependencies on number of constraints are $\\sqrt{m}$ , the results here have better dependencies of $\\ln m$ . Moreover, following our interpretation of algorithm performance as discussed in the Introduction, Theorem 3.10 implies that the algorithm\u2019s ultimate performance is $\\widetilde{\\mathcal{O}}\\left(\\sqrt{c_{\\varepsilon,\\delta}}\\right)+m\\cdot\\widetilde{\\mathcal{O}}\\left(\\sqrt{c_{\\varepsilon,\\delta}}\\right)=\\widetilde{\\mathcal{O}}\\left(m\\sqrt{c_{\\varepsilon,\\delta}}\\right)$ . The additional $m$ factor comes from $m$ constraints, sin ce the feasibility g uarantee in T heorem 3.10 is for any single constraint. ", "page_idx": 7}, {"type": "text", "text": "4 The lower bound ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Some post-processing lemmas for JDP are necessary to prove the lower bound. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.1 (Self post-processing for JDP). Let ${\\mathcal{M}}\\ :\\ {\\mathcal{Z}}^{n}\\ \\to\\ {\\mathcal{X}}^{n}$ be an $(\\varepsilon,\\delta)$ -JDP mechanism and denote its output by ${\\mathcal M}({\\mathcal D})\\;:=\\;({\\mathcal M}({\\mathcal D})_{1},...\\,,{\\mathcal M}({\\mathcal D})_{n})$ . Let $f\\;:\\;\\mathcal{X}\\;\\times\\;\\mathcal{Z}\\;\\rightarrow\\;\\mathcal{Y}$ be an arbitrary (randomized) function that can be applied element-wisely to M\u2019s output. Then, $\\big(f(M(\\mathcal{D})_{1},z_{1}),\\dots,f(\\mathcal{M}(\\mathcal{D})_{n},z_{n})\\big)$ is $(\\varepsilon,\\delta)$ -JDP. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.2 (Post-processing for JDP). Let $\\mathcal{M}:\\mathcal{Z}^{n}\\rightarrow\\mathcal{X}^{n}$ be an $(\\varepsilon,\\delta)$ -JDP mechanism and denote its output by $\\mathcal{M}(\\bar{\\mathcal{D}}):=(\\bar{\\mathcal{M}}(\\mathcal{D})_{1},\\ldots,\\mathcal{M}(\\mathcal{D})_{n})$ . Let $f:\\mathcal{X}^{n-1}\\to\\mathcal{Y}$ be an arbitrary (randomized) function that can be applied to any collection of $n-1$ elements of $\\mathcal{M}$ \u2019s output. Then, for any $k\\in[n]$ , $f(\\mathcal{M}(\\mathcal{D})_{-k})$ and $f(\\bar{\\mathcal{M}}(\\mathcal{D}^{\\prime})_{-k})$ are $(\\varepsilon,\\delta)$ -indistinguishable.2 ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.1 confirms that processing each JDP output with the agent\u2019s own data preserves JDP. Lemma 4.2 says applying any operation to $n-1$ elements of two $n$ -length JDP outputs obtained from a pair of neighboring datasets will be indistinguishable. ", "page_idx": 7}, {"type": "text", "text": "To see how these two lemmas help, we consider the allocations $\\pmb{x}^{A}:=(\\pmb{x}_{1}^{A},\\pmb{\\ldots},\\pmb{x}_{n}^{A})$ outputted by a JDP algorithm $A:{\\mathcal{Z}}^{n}\\rightarrow{\\mathcal{X}}^{n}$ . By Lemma 4.1, their consumptions $({\\pmb a}_{1}({\\bar{\\pmb x_{1}^{A}}}),\\dots,{\\bar{\\pmb a}}_{n}({\\pmb x}_{n}^{A}))$ are also JDP. Furthermore, for any collusive group without agent $k$ , their total consumption $\\textstyle\\sum_{i\\neq k}^{\\cdot\\tilde{n}^{\\prime}}{\\pmb{a}}_{i}({\\pmb{x}}_{i}^{A})$ should be insensitive to agent $k$ \u2019s allocation by Lemma 4.2. To ensure insensitivity, intuitively but informally, any algorithm $\\boldsymbol{\\mathcal{A}}$ outputting feasible allocations should reserve some resource exclusively for agent $k$ . But the reserved resource is wasted in some scenarios, which leads to the lower bound. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.3 (Minimax lower bound). For $\\varepsilon\\,\\geq\\,\\operatorname*{max}\\{1,1/(n\\gamma)\\},0\\,<\\,\\delta\\,\\leq\\,1/2,$ , there exists $a$ dataset $\\mathcal{D}$ satisfying assumptions 2.5 and 3.7 such that any $(\\varepsilon,\\delta)$ -JDP algorithm $\\boldsymbol{\\mathcal{A}}$ outputting feasible allocations will lead to a utility loss at least $m/(4\\varepsilon)$ . Therefore, the minimax lower bound is ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\substack{A\\,i s\\,(\\varepsilon,\\delta)\\subset J D P}}\\operatorname*{sup}_{\\mathcal{D}}\\left\\{\\mathsf{F}(x^{*}(\\mathcal{D}))-\\mathbb{E}_{A}\\left[\\mathsf{F}(x^{A}(\\mathcal{D}))\\right]\\right\\}\\geq\\frac{m}{4\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The lower bound here nearly matches upper bounds given by Theorem 3.10 up to some logarithmic factors in $m$ and $1/\\delta$ . Therefore, Noisy Dual Mirror Descent is near optimal, under our interpretation of algorithm performance. However, the result is limited to $\\varepsilon\\geq\\operatorname*{max}\\{1,1/(n\\gamma)\\}$ , and it is interesting to derive lower bounds for other $\\varepsilon$ . We provide a promising direction in the Appendix, which involves a lower bounding optimization problem with hockey-stick divergence constraints. We conjecture that couplings and divergences employed by [BBG18] are promising tools for this purpose. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5 Numerical experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "5.1 Workforce scheduling ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Workforce scheduling is about establishing a shift schedule for a given period to maximize workers\u2019 total preference while meeting worker availability and shift coverage requirements. Workers\u2019 preference and availability are private data to protect. We consider a simple case of scheduling $n=7$ workers for $m=14$ days with data publicly available [Opt24]. In this case, (i) each worker has preferences $c_{i}\\in\\mathbb{Z}_{+}^{m}$ , and utility function is $u_{i}({\\pmb x}_{i})=\\langle{\\pmb c}_{i},{\\pmb x}_{i}\\rangle$ ; (ii) shift requirement $r_{j}\\in\\mathbb{Z}_{+}$ is imposed on each day $j\\in[m]$ , i.e., the number of workers needed for day $j$ , which couples all workers; and (iii) workers\u2019 availability and shift limits described by a polyhedral set $\\mathcal{X}_{i}:=\\{\\bar{\\mathbf{x}}_{i}\\in[0,1]^{m}:l_{i}\\leq\\langle\\mathbf{1},\\mathbf{x}_{i}\\rangle\\leq u_{i}\\}$ . The problem is modeled as max $\\begin{array}{r}{\\{\\sum_{i=1}^{n}\\left\\langle\\bar{c}_{i},\\bar{\\mathbf{x}}_{i}\\right\\rangle:\\sum_{i}x_{i}=r;x_{i}\\in\\dot{\\mathcal{X}_{i}},\\forall i\\}}\\end{array}$ . While this is a small case, it is suitable for visualizing decisions and understanding the impact of JDP. Moreover, since the optimal non-private $\\pmb{p}^{*}=[0,3,1,0,2,0,0,4,3,2,3,0,0,0]$ is a sparse vector, one can expect MD equipped with negative entropy to perform better. ", "page_idx": 8}, {"type": "text", "text": "Figure 1 shows the final decisions under various $\\varepsilon$ , where the rightmost is the optimal non-private decision where a value of 1 means arranging the person to that day. Private decisions are fractional ", "page_idx": 8}, {"type": "image", "img_path": "6ArNmbMpKF/tmp/4b1bf69d3dc6b556d86ff4de68d4f79170c0eb0a0ba571f27856087741cf4e8a.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 1: 7-person, 14-day rosters under various $\\varepsilon$ . Algorithms parameters: potential function is negative entropy parameterized by $\\pmb{b}=\\pmb{1}$ ; $K=1.1\\bar{u}/(\\gamma\\underline{{b}})$ , $\\delta=.01$ , $T=10^{4}$ . Other settings follow Theorem 3.10. Results reported are averages of 50 runs. Strong duality holds due to linearity. ", "page_idx": 8}, {"type": "text", "text": "and can be interpreted as probabilities. It is not hard to see that private decisions are in a similar pattern to non-private decisions, and many private decisions are exactly the same as their optimal non-private counterpart. Moreover, private decisions different from their non-private counterpart converge gradually as $\\varepsilon\\rightarrow\\infty$ , see for example, the decision of (Day1, Marisa), (Day2, Marisa), and (Day4, Vincent). Optimality gaps and constraint violations are shown in Figure 2 (left panel). For all curves, the lower the better. It is clear that our algorithms have significantly smaller optimality gaps at slightly higher constraint violations. ", "page_idx": 8}, {"type": "image", "img_path": "6ArNmbMpKF/tmp/eaa5c616862f49bfd5711ef0d52af07abd146131cd57a7a45c20fd248fdd666f.jpg", "img_caption": ["Figure 2: $\\varepsilon$ v.s.optimality gaps & constraint violations. More discussions in Appendix C. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "One may notice that the constant of $K$ is 1.1 rather than 2 suggested by Theorem 3.10. This is the consequence of parameter tuning, and we show its impact in Figure 2 (right panel). Comparing the two plots in Figure 2, it is obvious that larger K_constant leads to conservative decisions: fewer constraint violations but higher optimality gaps. Moreover, when K_constant is 2, our algorithms achieve lower optimality gaps at the same level of constraint violations. ", "page_idx": 9}, {"type": "text", "text": "5.2 Assignment problem ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We next consider three large-scale assignment problems with $(m,n)=(8,\\,800)$ , (15, 1500), (30, 3000), aiming to maximize aggregated utility by assigning at most one unit to each agent. The problem is modeled as max $\\begin{array}{r}{\\{\\bar{\\sum_{i=1}^{n}}\\left\\langle c_{i},\\mathbf{x}_{i}\\right\\rangle:\\sum_{i}I_{m\\times n}\\mathbf{\\bar{x}}_{i}\\stackrel{}{\\leq}n\\gamma\\mathbf{1};\\mathbf{x}_{i}\\in\\mathcal{X}_{i},\\forall i\\}}\\end{array}$ with $\\mathcal{X}_{i}:=\\{\\pmb{\\mathscr{x}}_{i}\\in$ $[0,1]^{n}:\\langle\\mathbf{1},\\mathbf{x}_{i}\\rangle\\leq1\\}$ being a unit simplex and $\\bar{I_{m\\times n}}:=[I_{m},\\cdot\\cdot\\cdot,I_{m}]$ being a consumption matrix concatenated from $n/m$ identity matrices. Raw data of $c_{i}$ are available at [Bea04]. In this assignment problem, $p^{*}>0$ is strictly non-zero. We run experiments and report results in Table 3. ", "page_idx": 9}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/01b7634ce9c04d355613557f9b12146a4485dea00f85025d7ae6ccea0bba60bd.jpg", "table_caption": ["Table 3: Algorithm performance, mean $\\pm$ sd "], "table_footnote": ["Notes. Parameters for our algorithms: $K\\,=\\,1.1\\bar{u}/(\\gamma\\underline{{b}})$ , $\\delta\\;=\\;.01$ , $T\\;=\\;10^{4}$ . Other settings follow Theorem 3.10. MD_l2 and MD_ne mean that potential function is squared $\\ell_{2}$ and negative entropy, respectively. For three cases $n\\:=\\:800$ , 1500, 3000, we set resource level $\\gamma=0.1$ , 0.05, 0.02, respectively. For all values in the table, the lower the better. Bold=better. More results are deferred to Appendix C. "], "page_idx": 9}, {"type": "text", "text": "From the table, we observe $\\mathrm{MD}\\_{12}$ has lower gaps and reasonable constraint violations for small $\\varepsilon$ ;   \nand MD_ne almost dominates others for large $\\varepsilon$ . Both our algorithms outperform existing methods. ", "page_idx": 9}, {"type": "text", "text": "6 Discussion and conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Limitation of our work. One significant limitation is the restriction of $\\varepsilon\\geq\\operatorname*{max}\\{1,1/(n\\gamma)\\}$ to make the lower bound hold. However, we identify a promising direction to overcome this limitation in Appendix B.4. Once the limitation is overcame, the analysis may further uncover lower bounds on online cases [SS18], a long-standing open question in private online optimization $[\\mathrm{CDE^{+}24}]$ . ", "page_idx": 9}, {"type": "text", "text": "In this work, we considered convex resource allocation problems under joint differential privacy. To solve the problem approximately, we proposed an algorithm Noisy Dual Mirror Descent, which privatizes dual variables of hard constraints, and then uses private dual variables to coordinate allocations. A significant merit of the algorithm is its ability to better leverage the geometric structure of the dual space; thus, it is provably near optimal for a large range of privacy parameters. There are many interesting directions for future study. For example, getting rid of the limitation discussed previously is a fruitful endeavour. Identifying a proper DP manner to tune the constant of $K$ is of more practical interest. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We sincerely thank the anonymous Area Chair and reviewers for their valuable feedback that significantly improved this work. This research is supported by the Ministry of Education, Singapore, under its MOE AcRF Tier 1 (RG117/23). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "$[\\mathrm{ABG}^{+}23]$ Raman Arora, Raef Bassily, Tom\u00e1s Gonz\u00e1lez, Crist\u00f3bal A Guzm\u00e1n, Michael Menart, and Enayat Ullah. Faster rates of convergence to stationary points in differentially private optimization. In International Conference on Machine Learning, pages 1060\u20131092. PMLR, 2023. 6   \n[AFKT21] Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021. 3 [BBG18] Borja Balle, Gilles Barthe, and Marco Gaboardi. Privacy amplification by subsampling: Tight analyses via couplings and divergences. Advances in neural information processing systems, 31, 2018. 9, 23 [Bea04] J E Beasley. Or-library, assignment problem. http://people.brunel.ac.uk/\\~mastjjb/jeb/ orlib/assigninfo.html, 2004. Accessed: 2024-May-3. 10 [Bec17] Amir Beck. First-order methods in optimization. SIAM, 2017. 14 [BGN21] Raef Bassily, Crist\u00f3bal Guzm\u00e1n, and Anupama Nandi. Non-euclidean differentially private stochastic convex optimization. In Conference on Learning Theory, pages 474\u2013499. PMLR, 2021. 3 [BLM20] Santiago Balseiro, Haihao Lu, and Vahab Mirrokni. Dual mirror descent for online allocation problems. In International Conference on Machine Learning, pages 613\u2013628. PMLR, 2020. 4 [BLM23] Santiago R Balseiro, Haihao Lu, and Vahab Mirrokni. The best of many worlds: Dual mirror descent for online allocation problems. Operations Research, 71(1):101\u2013119, 2023. 4, 18   \n$[\\mathrm{CDE^{+}}24]$ Rachel Cummings, Damien Desfontaines, David Evans, Roxana Geambasu, Yangsibo Huang, Matthew Jagielski, Peter Kairouz, Gautam Kamath, Sewoong Oh, Olga Ohrimenko, et al. Advancing differential privacy: Where we are now and future directions for real-world deployment. 2024. 10   \n[CKRW15] Rachel Cummings, Michael Kearns, Aaron Roth, and Zhiwei Steven Wu. Privacy and truthful equilibrium selection for aggregative games. In Web and Internet Economics: 11th International Conference, WINE 2015, Amsterdam, The Netherlands, December 9-12, 2015, Proceedings 11, pages 286\u2013299. Springer, 2015. 3 [DR14] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014. 3 [GGP24] Tom\u00e1s Gonz\u00e1lez, Crist\u00f3bal Guzm\u00e1n, and Courtney Paquette. Mirror descent algorithms with nearly dimension-independent rates for differentially-private stochastic saddle-point problems. arXiv preprint arXiv:2403.02912, 2024. 3 [GL13] Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic programming. SIAM journal on optimization, 23(4):2341\u20132368, 2013. 6 [GU22] George Gilliam and Nelson A Uhan. Computing payoff allocations in the approximate core of linear programming games in a privacy-preserving manner. Operations Research Letters, 50(1):64\u201371, 2022. 3   \n$[\\mathrm{HHR}^{+}14]$ Justin Hsu, Zhiyi Huang, Aaron Roth, Tim Roughgarden, and Zhiwei Steven Wu. Private matchings and allocations. In Proceedings of the forty-sixth annual ACM symposium on Theory of computing, pages 21\u201330, 2014. 2, 3, 4   \n[HHRW16] Justin Hsu, Zhiyi Huang, Aaron Roth, and Zhiwei Steven Wu. Jointly private convex programming. In Proceedings of the twenty-seventh annual ACM-SIAM symposium on Discrete algorithms, pages 580\u2013599. SIAM, 2016. 2, 3, 5, 7, 10, 24, 25, 26   \n$[\\mathrm{HLL}^{+}22]$ Yuxuan Han, Zhicong Liang, Zhipeng Liang, Yang Wang, Yuan Yao, and Jiheng Zhang. Private streaming sco in lp geometry with applications in high dimensional online decision making. In International Conference on Machine Learning, pages 8249\u20138279. PMLR, 2022. 2 [HZ18] Zhiyi Huang and Xue Zhu. Near optimal jointly private packing algorithms via dual multiplicative weight update. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 343\u2013357. SIAM, 2018. 2, 3, 4, 5, 7 [HZ19] Zhiyi Huang and Xue Zhu. Scalable and jointly differentially private packing. In 46th International Colloquium on Automata, Languages, and Programming (ICALP 2019). Schloss-Dagstuhl-Leibniz Zentrum f\u00fcr Informatik, 2019. 2   \n$[\\mathbf{J}\\mathbf{N}\\mathbf{G}^{+}21]$ Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. On nonconvex optimization for machine learning: Gradients, stochasticity, and saddle points. Journal of the ACM (JACM), 68(2):1\u201329, 2021. 6   \n[KPRU14] Michael Kearns, Mallesh Pai, Aaron Roth, and Jonathan Ullman. Mechanism design in large games: Incentives and privacy. In Proceedings of the 5th conference on Innovations in theoretical computer science, pages 403\u2013410, 2014. 3 [Mir17] Ilya Mironov. R\u00e9nyi differential privacy. In 2017 IEEE 30th computer security foundations symposium (CSF), pages 263\u2013275. IEEE, 2017. 13 [NY83] Arkadij Semenovi\u02c7c Nemirovskij and David Borisovich Yudin. Problem complexity and method efficiency in optimization. 1983. 3, 4 [Opt24] Gurobi Optimization. Workforce scheduling. https:// gurobi-optimization-gurobi-optimods.readthedocs-hosted.com/en/latest/ mods/workforce.html, 2024. Accessed: 2024-April-30. 9   \n[SLWA22] Ryan Steed, Terrance Liu, Zhiwei Steven Wu, and Alessandro Acquisti. Policy impacts of statistical uncertainty and privacy. Science, 377(6609):928\u2013931, 2022. 2 [SS18] Roshan Shariff and Or Sheffet. Differentially private contextual linear bandits. Advances in Neural Information Processing Systems, 31, 2018. 2, 10   \n[VBKW20] Giuseppe Vietri, Borja Balle, Akshay Krishnamurthy, and Steven Wu. Private reinforcement learning with pac and regret guarantees. In International Conference on Machine Learning, pages ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Proofs for Section 3 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof. Since each individual\u2019s allocation $\\pmb{x}_{i}^{A}$ depends on all shadow prices $(p^{(1)},\\ldots,p^{(T)})$ on the training trajectory and the individual\u2019s own data, by Billboard Lemma 2.3, it suffices to verify the whole sequence $(p^{(1)},\\ldots,p^{(T)})$ is $(\\varepsilon,\\delta)$ -DP. We characterize the DP guarantee through R\u00e9nyi Differential Privacy [Mir17]. Below are some useful lemmas on R\u00e9nyi DP. ", "page_idx": 12}, {"type": "text", "text": "Definition A.1 ( $\\left(\\alpha,\\varepsilon\\right)$ -R\u00e9nyi Differential Privacy, [Mir17]). Let ${\\mathcal{M}}:{\\mathcal{D}}\\rightarrow{\\mathcal{P}}$ be a randomized mechanism. For any neighboring datasets $\\mathcal{D}\\sim\\mathcal{D}^{\\prime}$ , let P, $\\mathbb{P}^{\\prime}$ be the distribution of $\\mathcal{M}(\\mathcal{D})$ and $\\mathcal{M}(\\mathcal{D}^{\\prime})$ , respectively. Then, $\\mathcal{M}$ is said to be $\\varepsilon$ -R\u00e9nyi differentially private of order $\\alpha$ , or $(\\alpha,\\varepsilon)$ -RDP for short, if it holds that ", "page_idx": 12}, {"type": "equation", "text": "$$\nD_{\\alpha}({\\mathbb P}\\,\\,|\\,|\\,{\\mathbb P}^{\\prime})\\leq\\varepsilon,\\quad\\forall\\mathcal{D}\\sim\\mathcal{D}^{\\prime},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\begin{array}{r}{D_{\\alpha}(\\mathbb{P}\\mid\\mid\\mathbb{Q}):=\\frac{1}{\\alpha-1}\\ln\\left(\\mathbb{E}_{\\mathbb{Q}}\\left[\\left(\\frac{\\mathbb{P}(x)}{\\mathbb{Q}(x)}\\right)^{\\alpha}\\right]\\right)}\\end{array}$ is the R\u00e9nyi divergence between $\\mathbb{P}$ and $\\mathbb{Q}$ ", "page_idx": 12}, {"type": "text", "text": "Lemma A.2 (Gaussian Mechanism is RDP, Proposition 7 in [Mir17]). Let $f:{\\mathcal{D}}\\rightarrow{\\mathcal{Z}}$ be a vectorvalued function whose global sensitivity is $\\begin{array}{r}{G S:=\\operatorname*{sup}_{\\mathcal D\\sim\\mathcal D^{\\prime}}\\|f(\\mathcal D)-f(\\mathcal D^{\\prime})\\|_{2}}\\end{array}$ , then the Gaussian Mechanism $\\mathcal{M}(\\mathcal{D}):=f(\\mathcal{D})+\\mathcal{N}(\\mathbf{0},\\sigma^{2}I)$ is $\\textstyle(\\alpha,{\\frac{\\alpha\\cdot G S^{2}}{2\\sigma^{2}}})$ -RDP, for any $\\alpha>1$ . ", "page_idx": 12}, {"type": "text", "text": "Lemma A.3 (Composition for RDP, Proposition 1 in [Mir17]). Let $\\mathcal{M}_{1}:\\,\\mathcal{D}\\,\\rightarrow\\,\\mathcal{P}_{1}$ be $(\\alpha,\\varepsilon_{1})$ - RDP and $\\mathcal{M}_{2}\\,:\\,\\mathcal{D}\\,\\times\\,\\mathcal{P}_{1}\\,\\rightarrow\\,\\mathcal{P}_{2}$ be $\\left(\\alpha,\\varepsilon_{2}\\right)$ -RDP. Let $X\\;:=\\;\\mathcal{M}_{1}(\\mathcal{D})$ be the output of $\\mathcal{M}_{1}$ and $Y:=\\mathcal{M}_{2}(\\mathcal{D},X)$ be the output of $\\mathcal{M}_{2}$ , then the adaptive composition $(X,Y)$ satisfies $(\\alpha,\\varepsilon_{1}+\\varepsilon_{2})$ - RDP. ", "page_idx": 12}, {"type": "text", "text": "Lemma A.4 (From RDP to DP, Proposition 3 in [Mir17]). If $\\mathcal{M}$ is an $(\\alpha,\\varepsilon)$ -RDP mechanism, it also satisfies ln \u03b1(1\u2212/1\u03b4 ), \u03b4)-DP, for any \u03b4 \u2208(0, 1). ", "page_idx": 12}, {"type": "text", "text": "For iteration $t$ , we notice that data only plays a role in the gradient $\\mathbf{g}(\\pmb{p}^{(t)};\\mathcal{D}):=n\\gamma b\\!-\\!a(\\pmb{x}(\\pmb{p}^{(t)};\\mathcal{D}))$ through intermediate allocation decision $\\begin{array}{r}{\\pmb{x}(\\pmb{p}^{(t)};\\mathcal{D})\\,:=\\,\\arg\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}}\\mathsf{F}(\\pmb{x})-\\left<\\pmb{p}^{(t)},\\pmb{a}(\\pmb{x})\\right>}\\end{array}$ . It is immediate to show that the Global Sensitivity of gradient function is ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathrm{GS}=\\operatorname*{sup}_{p,\\mathcal{D}\\sim\\mathcal{D}^{\\prime}}\\|\\mathbf{g}(p;\\mathcal{D})-\\mathbf{g}(p;\\mathcal{D}^{\\prime})\\|_{2}=\\operatorname*{sup}_{p;z_{i}\\sim z_{i}^{\\prime}}\\|a_{i}(x_{i}(p;z_{i}))-a_{i}^{\\prime}(x_{i}(p;z_{i}^{\\prime}))\\|_{2}\\le\\|b\\|_{2}\\,,\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where the last inequality is by our assumption that serving one individual consumes at most $^{b}$ resource (see assumption 2.5). Then, injecting a zero-mean Gaussian noise $\\mathbf{n}^{(t)}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}I)$ into gradients $\\mathbf{g}^{(t)}:=\\mathbf{g}(\\boldsymbol{p}^{(t)};\\mathcal{D})$ can guarantee $\\left(\\boldsymbol{\\alpha},\\frac{\\boldsymbol{\\alpha}\\cdot\\lVert\\boldsymbol{b}\\rVert_{2}^{2}}{2\\sigma^{2}}\\right)$ -RDP by Lemma A.2. ", "page_idx": 12}, {"type": "text", "text": "Moreover, the algorithm comprises $T$ iterations, and each iteration takes as input the shadow price in previous iteration; therefore, $T$ -fold iterations form a sequential composition. Applying Composition Lemma A.3, we immediately conclude that $(\\mathbf{g}^{(1)}+\\mathbf{n}^{(1)},\\ldots,\\mathbf{g}^{(T)}+\\mathbf{n}^{(T)})$ satisfies $\\big(\\boldsymbol{\\alpha},\\frac{T\\boldsymbol{\\alpha}\\cdot\\lVert\\boldsymbol{b}\\rVert_{2}^{2}}{2\\sigma_{.}^{2}}\\big)$ - RDP. As the noisy mirror descent update step in Eq.(6) is merely post-processing after obtaining $(\\mathbf{g}^{(1)}+\\mathbf{n}^{(1)},\\ldots,\\mathbf{g}^{(T)}+\\mathbf{n}^{(T)})$ , the sequence $(p^{(1)},\\ldots,p^{(T)})$ is thus also $\\begin{array}{r}{(\\alpha,\\frac{T\\alpha\\cdot\\|\\pmb{b}\\|_{2}^{2}}{2\\sigma^{2}})}\\end{array}$ -RDP. Lastly, by Lem .4, $\\displaystyle(\\alpha,\\,\\frac{T\\alpha\\cdot\\|b\\|_{2}^{2}}{2\\sigma^{2}})$ -RDP implies $\\begin{array}{r}{(\\frac{T\\alpha\\cdot\\|\\pmb{b}\\|_{2}^{2}}{2\\sigma^{2}}+\\frac{\\ln{(1/\\delta)}}{\\alpha-1},\\delta)}\\end{array}$ )-DP $\\forall\\delta\\in(0,1)$ . Thus, for a given $(\\varepsilon,\\delta)$ , if we assign privacy budget in the following way: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\frac{T\\alpha\\|\\pmb{b}\\|_{2}^{2}}{2\\sigma^{2}}=\\varepsilon/2;}\\\\ {\\frac{\\ln{(1/\\delta)}}{\\alpha-1}=\\varepsilon/2,}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "we can get ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sigma^{2}=T\\left\\|\\pmb{b}\\right\\|_{2}^{2}\\cdot\\left(\\frac{2\\ln\\left(1/\\delta\\right)}{\\varepsilon^{2}}+\\frac{1}{\\varepsilon}\\right),\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "which is the desired variance level. ", "page_idx": 12}, {"type": "text", "text": "A.2 Proof of Lemma 3.4 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. For any gradient $\\widetilde{\\mathbf{g}}^{(t)}$ used for the mirror descent update step Eq.(6), shadow prices $\\pmb{p}^{(t)}$ , and updated shadow pric e s $\\pmb{p}^{(t+1)}$ , there exists an inequality linking them together (Lemma 9.13, [Bec17]): ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\left\\langle\\widetilde{\\mathbf{g}}^{(t)},p^{(t)}-\\mathbf{p}\\right\\rangle\\le\\frac{\\eta^{(t)}\\left\\Vert\\widetilde{\\mathbf{g}}^{(t)}\\right\\Vert_{q}^{2}}{2\\alpha}+\\frac{1}{\\eta^{(t)}}\\left\\{B_{\\Phi}(\\pmb{p},p^{(t)})-B_{\\Phi}(\\pmb{p},p^{(t+1)})\\right\\},\\quad\\forall t,\\quad\\forall p\\in\\mathcal{P}\\cap\\mathcal{W}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Summing up the above inequality in a telescoping way over $t=1,\\dots,T$ gives ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\left<\\widetilde{\\mathbf{g}}^{(t)},p^{(t)}-p\\right>\\leq\\frac{\\sum_{t=1}^{T}\\eta^{(t)}\\left\\|\\widetilde{\\mathbf{g}}^{(t)}\\right\\|_{q}^{2}}{2\\alpha}+\\frac{B_{\\Phi}(p,p^{(1)})}{\\eta^{(1)}}-\\frac{B_{\\Phi}(p,p^{(T+1)})}{\\eta^{(T)}}}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\qquad+\\sum_{t=1}^{T-1}\\left(\\frac{1}{\\eta^{(t+1)}}-\\frac{1}{\\eta^{(t)}}\\right)B_{\\Phi}(p,p^{(t+1)}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "When stepsizes $\\eta^{(t)}=\\eta$ are the same for all $t$ , the inequality becomes ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left<\\widetilde{\\mathbf{g}}^{(t)},\\pmb{p}^{(t)}-\\pmb{p}\\right>\\leq\\frac{\\eta\\sum_{t=1}^{T}\\left\\|\\widetilde{\\mathbf{g}}^{(t)}\\right\\|_{q}^{2}}{2\\alpha}+\\frac{B_{\\Phi}(\\pmb{p},\\pmb{p}^{(1)})}{\\eta}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "A.3 Proof of Theorem 3.5 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. Let us first fix a sequence of noises $\\{{\\bf n}^{(t)}\\}_{t=1}^{T}$ . Recall that the final allocation decision $x^{A}$ is the average over all decisions along the trajectory and the objective function is concave; therefore, by Jensen\u2019s inequality, $\\begin{array}{r}{\\mathsf{F}({\\pmb x}^{A})\\geq\\frac{1}{T}\\overleftarrow{\\sum_{t=1}^{T}\\bar{\\mathsf{F}}}({\\pmb x}^{(t)})}\\end{array}$ . Moreover, by weak duality, $\\mathsf{F}(\\pmb{x}^{*})\\leq\\mathsf{D}(\\pmb{p}^{(t)}),\\forall t$ . With the above results, the optimality gap $\\mathsf{F}(\\pmb{x}^{*})-\\mathsf{F}(\\pmb{x}^{A})$ can be upper controlled as: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\bf\\ddot{\\Phi}}({\\bf x}^{*})-{\\bf F}({\\bf x}^{A})\\leq\\frac{1}{T}\\sum_{t=1}^{T}\\left[{\\sf D}({p^{(t)}})-{\\sf F}({\\bf x}^{(t)})\\right]\\ ~}}\\\\ {{\\\\displaystyle=\\frac{1}{T}\\sum_{t=1}^{T}\\left[{\\sf F}({\\bf x}^{(t)})+\\left<{p^{(t)}},{\\bf g}^{(t)}\\right>-{\\sf F}({\\bf x}^{(t)})\\right]\\ ~~~~~~({\\bf b y}~d e f i n i t i o n~o f~d u a l~p r o b l e m~D)}}\\\\ {{\\displaystyle=\\frac{1}{T}\\sum_{t=1}^{T}\\left<\\widetilde{\\bf g}^{(t)},{p^{(t)}}-{\\bf0}\\right>-\\frac{1}{T}\\sum_{t=1}^{T}\\left<{\\bf n}^{(t)},{p^{(t)}}\\right>.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Taking expectation with respect to noises $\\{{\\bf n}^{(t)}\\}_{t=1}^{T}$ on both sides, we can remove the second term on the right hand side in preceding inequality, because $\\mathbf{n}^{(t)}$ is zero-mean and is independent of $\\pmb{p}^{(t)}$ . This leads to ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathsf{F}(\\pmb{x}^{*})-\\mathbb{E}_{\\pmb{A}}\\left[\\mathsf{F}(\\pmb{x}^{\\pmb{A}})\\right]\\leq\\frac{1}{T}\\cdot\\mathbb{E}_{\\pmb{A}}\\left[\\sum_{t=1}^{T}\\left<\\widetilde{\\mathbf{g}}^{(t)},\\pmb{p}^{(t)}-\\mathbf{0}\\right>\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The inner summation can be upper bounded by applying Lemma 3.4 with $\\mathbfit{p}=\\mathbf{0}$ and $\\eta^{(t)}=\\eta>0,\\forall t$ ; we therefore obtain ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathsf{F}({\\pmb x}^{*})-\\mathbb{E}_{\\mathcal{A}}\\left[\\mathsf{F}({\\pmb x}^{\\mathcal{A}})\\right]\\leq\\mathbb{E}_{\\mathcal{A}}\\left[\\frac{\\eta\\sum_{t=1}^{T}\\left\\|\\widetilde{\\mathbf{g}}^{(t)}\\right\\|_{q}^{2}}{2\\alpha T}+\\frac{1}{\\eta T}B_{\\Phi}(\\pmb{0},{p}^{(1)})\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Here are some helpful inequalities: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\widetilde{\\mathbf{g}}^{(t)}\\right\\|_{q}^{2}=\\left\\|\\mathbf{g}^{(t)}+\\mathbf{n}^{(t)}\\right\\|_{q}^{2}\\leq2\\left\\|\\mathbf{g}^{(t)}\\right\\|_{q}^{2}+2\\left\\|\\mathbf{n}^{(t)}\\right\\|_{q}^{2};}\\\\ &{\\left\\|\\mathbf{g}^{(t)}\\right\\|_{q}=\\left\\|\\gamma n b-a(x^{(t)})\\right\\|_{q}\\leq\\bar{\\gamma}n\\left\\|b\\right\\|_{q}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Denote $G:=\\left.\\bar{\\gamma}^{2}n^{2}\\,\\|\\pmb{b}\\right\\vert_{q}^{2}$ , and $\\begin{array}{r}{G_{A}:=\\frac{1}{T}\\sum_{t=1}^{T}\\left\\|\\mathbf{n}^{(t)}\\right\\|_{q}^{2}}\\end{array}$ . Using above helpful inequalities, we can upper bound $\\begin{array}{r}{{\\frac{1}{T}}\\sum_{t=1}^{T}\\left\\lVert\\widetilde{\\mathbf{g}}^{(t)}\\right\\rVert_{q}^{2}}\\end{array}$ as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{1}{T}\\sum_{t=1}^{T}\\left\\lVert\\widetilde{\\mathbf{g}}^{(t)}\\right\\rVert_{q}^{2}\\leq2G+2G_{\\mathcal{A}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Plugging (11) back into (10), we further reach an upper bound: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathsf{F}(\\pmb{x}^{*})-\\mathbb{E}_{A}\\left[\\mathsf{F}(\\pmb{x}^{A})\\right]\\leq\\frac{\\eta\\cdot\\left(G+\\mathbb{E}_{A}\\left[G_{A}\\right]\\right)}{\\alpha}+\\frac{1}{\\eta T}B_{\\Phi}\\big(\\pmb{0},\\pmb{p}^{(1)}\\big).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Because $\\begin{array}{r}{G_{A}=\\frac{1}{T}\\sum_{t=1}^{T}\\left\\|\\mathbf{n}^{(t)}\\right\\|_{q}^{2}}\\end{array}$ and $\\mathbf{n}^{(t)}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}I_{m\\times m})$ with $\\sigma^{2}=T c_{\\varepsilon,\\delta},\\forall t$ , direct calculation gives $\\mathbb{E}_{A}\\left[G_{A}\\right]=\\sigma^{2}\\mathbb{E}\\left[\\left\\lVert\\boldsymbol{z}\\right\\rVert_{q}^{2}\\right]$ with $z\\sim\\mathcal{N}(0,I_{m\\times m})$ being a standard Gaussian random vector. Therefore, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathsf{F}(\\pmb{x}^{*})-\\mathbb{E}_{A}\\left[\\mathsf{F}(\\pmb{x}^{A})\\right]\\leq\\frac{\\eta\\cdot\\left(G+\\sigma^{2}\\mathbb{E}\\left[\\left\\|\\pmb{z}\\right\\|_{q}^{2}\\right]\\right)}{\\alpha}+\\frac{1}{\\eta T}B_{\\Phi}(\\pmb{0},\\pmb{p}^{(1)}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Let C\u03a6(p(1)) := B\u03a6(0, p(1))/\u03b1. Then, plugging in the stepsize \u03b7 = $\\begin{array}{r}{\\eta=\\sqrt{\\frac{\\alpha B_{\\Phi}(\\mathbf{0},\\pmb{p}^{(1)})}{T\\cdot(G+\\sigma^{2}\\mathbb{E}[\\|\\pmb{z}\\|_{q}^{2}])}}}\\end{array}$ leads to ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathsf{F}(\\pmb{x}^{*})-\\mathbb{E}_{A}\\left[\\mathsf{F}(\\pmb{x}^{A})\\right]\\leq2\\sqrt{\\frac{\\left(G+\\sigma^{2}\\mathbb{E}\\left[\\left\\|\\pmb{z}\\right\\|_{q}^{2}\\right]\\right)\\cdot B_{\\Phi}(\\mathbf{0},\\pmb{p}^{(1)})}{\\alpha T}}\\qquad}\\\\ {\\leq2C_{\\Phi}(\\pmb{p}^{(1)})\\cdot\\left(\\frac{\\sqrt{G}}{\\sqrt{T}}+\\sqrt{c_{\\varepsilon,\\delta}}\\cdot\\sqrt{\\mathbb{E}\\left[\\left\\|\\pmb{z}\\right\\|_{q}^{2}\\right]}\\right)\\cdot\\quad(\\mathsf{b y}\\ \\sigma^{2}=T c_{\\varepsilon,\\delta})\\,}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Lastly, if we run sufficiently many iterations T \u2265 c\u03b5,\u03b4\u00b7EG[\u2225z\u2225q2], we get the stated result in the theorem. ", "page_idx": 14}, {"type": "text", "text": "A.4 Proof of Theorem 3.6 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof. We first briefly introduce the idea for the proof. We will find a lower bound and an upper bound for the cumulative stationarity gap t=1 g( $\\sum_{t=1}^{T}\\left\\langle\\widetilde{\\mathbf{g}}^{(t)},\\pmb{p}^{(t)}-\\pmb{p}\\right\\rangle$ in Lemma 3.4. With a properly chosen $\\pmb{p}\\in\\mathbb{R}_{+}^{m}\\cap\\mathcal{W}$ as a bridge, comparin g these t wo bounds leads to the desired conclusion. ", "page_idx": 14}, {"type": "text", "text": "For a given final allocation decision $x^{A}$ , we denote the resource underage level by ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{v^{A}:=\\left(a(x^{A})-n\\gamma b\\right)^{+},}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the positive part operator $(\\cdot)^{+}$ applies element-wise. It is self-evident that $v^{A}\\geq0$ by definition, and $\\pmb{v}^{A}=\\mathbf{\\dot{0}}$ implies no constraint violation. Let $j^{A}:=\\arg\\operatorname*{max}_{j\\in[m]\\cup\\{0\\}}\\{u_{j}^{A}\\}$ be the index of the most-severely violated constraint. Specially, if $j^{\\mathcal{A}}=0$ , then we know $\\pmb{v}^{A}=\\mathbf{0}$ , and we are done. Otherwise, we let $e_{j^{A}}$ be an indicator vector with 1 on its $(j^{\\mathcal{A}})$ \u2019s position and 0 on others. ", "page_idx": 14}, {"type": "text", "text": "Choose $\\pmb{p}:=\\,C\\pmb{e}_{j}\\pmb{\\mathscr{s}}\\,\\in\\,\\mathbb{R}_{+}^{m}\\cap\\mathcal{W}$ with a constant $C$ to be determined later, we reformulate the cumulative stationarity gap $\\begin{array}{r}{\\sum_{t=1}^{T}\\left\\langle\\widetilde{\\mathbf{g}}^{(t)},\\mathbf{p}^{(t)}-C e_{j^{A}}\\right\\rangle}\\end{array}$ into ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left<\\widetilde{\\mathbf{g}}^{(t)},\\boldsymbol{p}^{(t)}-C e_{j}\\boldsymbol{\\mathcal{A}}\\right>=\\underbrace{\\sum_{t=1}^{T}\\left<\\mathbf{g}^{(t)},\\boldsymbol{p}^{(t)}\\right>}_{(*)}+\\underbrace{\\sum_{t=1}^{T}\\left<\\mathbf{g}^{(t)},-C e_{j}\\boldsymbol{\\mathcal{A}}\\right>}_{(**)}+\\underbrace{\\sum_{t=1}^{T}\\left<\\mathbf{n}^{(t)},\\boldsymbol{p}^{(t)}-C e_{j}\\boldsymbol{\\mathcal{A}}\\right>}_{(***)},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and control the three terms one by one. ", "page_idx": 14}, {"type": "text", "text": "$(\\ast)$ : First, rewrite $(*)$ into a function of dual form: ", "page_idx": 15}, {"type": "equation", "text": "$$\n*)=\\sum_{t=1}^{T}\\left\\{\\Big[\\mathsf{F}(\\mathbf{x}^{(t)})+\\Big\\langle p^{(t)},\\mathbf{g}^{(t)}\\Big\\rangle\\Big]-\\mathsf{F}(\\mathbf{x}^{(t)})\\Big\\}=\\sum_{t=1}^{T}\\Big[\\mathsf{D}(p^{(t)})-\\mathsf{F}(\\mathbf{x}^{(t)})\\Big]\\geq T\\cdot\\big[\\mathsf{D}(p^{*})-\\mathsf{F}(\\mathbf{x}^{(t)})\\big]\\right\\},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the last inequality is from $\\mathsf{D}(\\pmb{p}^{(t)})\\geq\\mathsf{D}(\\pmb{p}^{*})$ and applying Jensen\u2019s inequality to $\\mathsf{F}(\\cdot)$ . Next, we turn to control $\\mathsf{\\bar{F}}(x^{\\mathcal{A}})$ . We observe that if more resource $\\stackrel{\\cdot}{\\mathbf{\\nabla}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\$ becomes available for the original allocation problem, then $x^{A}$ will be a feasible allocation. Hence, we can upper bound the value of $\\mathsf{F}(\\pmb{x}^{A})$ with another problem having more resources. Denote the set of feasible allocations when $^{b}$ resource available by $\\mathcal{X}(b):=\\{x:=(x_{1},\\ldots,x_{n})\\in\\otimes_{i=1}^{n}\\mathcal{X}_{i}:a(x)\\leq b\\}$ . We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathsf{F}({\\boldsymbol{x}}^{A})\\le\\operatorname*{max}_{\\boldsymbol{x}\\in\\mathcal{X}(n\\gamma b+{\\boldsymbol{v}}^{A})}\\mathsf{F}({\\boldsymbol{x}})}&{\\quad}&{({\\boldsymbol{x}}^{A}\\mathrm{~is~feasible})}\\\\ {\\le\\operatorname*{max}_{\\boldsymbol{x}\\in\\mathcal{Q}_{i=1}^{n}\\mathcal{X}_{i}}\\left\\{\\mathsf{F}({\\boldsymbol{x}})+\\left\\langle{\\boldsymbol{p}},{\\boldsymbol{n}}\\gamma b+{\\boldsymbol{v}}^{A}-{\\boldsymbol{a}}({\\boldsymbol{x}})\\right\\rangle\\right\\}}&{\\quad(\\mathrm{weak~duality,~}\\forall{\\boldsymbol{p}}\\in\\mathcal{P})}\\\\ &{=\\mathsf{D}({\\boldsymbol{p}})+\\left\\langle{\\boldsymbol{p}},{\\boldsymbol{v}}^{A}\\right\\rangle.}&{\\quad}&{(\\mathrm{dual~form})}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let $\\pmb{p}$ in (14) be $\\pmb{p}:=\\pmb{p}^{*}$ , and plug (14) back into (13), we obtain ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left(\\ast\\right)\\geq-T\\cdot\\left\\langle p^{*},v^{A}\\right\\rangle\\geq-T\\left\\|v^{A}\\right\\|_{\\infty}\\cdot\\left\\|p^{*}\\right\\|_{1}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "$(\\ast\\ast)$ : The second term $(**)$ helps characterize constraint violations: ", "page_idx": 15}, {"type": "text", "text": "(by assumption $a(\\cdot)$ is convex) ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left(\\ast\\ast\\right)=C\\displaystyle\\sum_{t=1}^{T}\\left\\langle-\\mathbf{g}^{(t)},e_{j}\\boldsymbol{A}\\right\\rangle=C T\\cdot\\left\\langle\\cfrac{1}{T}\\sum_{t=1}^{T}a(\\boldsymbol{x}^{(t)})-n\\gamma b,e_{j}\\boldsymbol{A}\\right\\rangle}&{}\\\\ {\\displaystyle\\geq C T\\cdot\\left\\langle a(\\boldsymbol{x}^{A})-n\\gamma b,e_{j}\\boldsymbol{A}\\right\\rangle}&{}\\\\ {\\displaystyle=C T\\left\\lVert\\boldsymbol{v}^{A}\\right\\rVert_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "$(\\ast\\ast\\ast)$ : The third term $(***)$ involves zero-mean Gaussian noise vectors $\\{\\mathbf{n}^{(t)}\\}_{t}$ that are independent of $\\pmb{p}^{(t)}$ . While $e_{j^{A}}$ is dependent on noise vectors, the dependence is not a big issue here, since $e_{j^{A}}\\;\\in\\;E_{1}\\;:=\\;\\{e\\;\\;\\bar{\\in}\\;\\;\\{0,1\\}^{m}\\;:\\;\\langle e,1\\rangle\\;=\\;1\\}$ , and the Gaussian Complexity $\\mathcal{G}(E_{1}):=\\mathbb{E}_{z\\sim\\mathcal{N}(\\mathbf{0},I_{m\\times m})}\\left[\\operatorname*{sup}_{e\\in E_{1}}\\left\\langle e,z\\right\\rangle\\right]$ of the set $E_{1}$ can be well controlled: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{G}(E_{1})=\\mathbb{E}_{z\\sim\\mathcal{N}(0,I_{m\\times m})}\\left[\\operatorname*{max}\\{z_{1},\\dots,z_{m}\\}\\right]\\leq\\sqrt{2\\ln m}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, the term $\\left(***\\right)$ admits a lower bound in expectation w.r.t. $\\boldsymbol{\\mathcal{A}}$ as shown below: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left(\\ast\\ast\\ast\\right)\\right]=0-C\\cdot\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left\\langle\\displaystyle\\sum_{t=1}^{T}\\mathbf{n}^{(t)},e_{j}\\boldsymbol{A}\\right\\rangle\\right]\\geq-C\\cdot\\mathbb{E}_{\\boldsymbol{A}}\\left[\\displaystyle\\operatorname*{sup}_{e\\in E_{1}}\\left\\langle\\displaystyle\\sum_{t=1}^{T}\\mathbf{n}^{(t)},e\\right\\rangle\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=-C\\sqrt{T}\\sigma\\cdot\\mathcal{G}(E_{1})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\geq-C\\sqrt{T}\\sigma\\cdot\\sqrt{2\\ln m}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=-C T\\cdot\\sqrt{c_{\\varepsilon,\\delta}\\cdot2\\ln m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Finally, replacing three terms back and taking expectation w.r.t. $\\boldsymbol{\\mathcal{A}}$ , we obtain a lower bound on the cumulative stationarity gap: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}\\left[\\sum_{t=1}^{T}\\left\\langle\\widetilde{\\mathbf{g}}^{(t)},p^{(t)}-C e_{j}\\boldsymbol{\\lambda}\\right\\rangle\\right]\\geq T\\mathbb{E}_{A}\\left[\\left\\|\\pmb{v}^{A}\\right\\|_{\\infty}\\right]\\cdot(C-\\left\\|p^{*}\\right\\|_{1})-C T\\cdot\\sqrt{c_{\\varepsilon,\\delta}\\cdot2\\ln m}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Now, we turn to another side and bound the cumulative stationarity gap from above. Suppose we can choose a proper $C>0$ such that $C e_{j^{A}}\\in\\mathbb{R}_{+}^{m}\\cap\\mathcal{W}$ almost surely, the expected cumulative stationarity gap thus can be bounded from above by employing Lemma 3.4: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}\\left[\\sum_{t=1}^{T}\\left\\langle\\widetilde{\\mathbf{g}}^{(t)},p^{(t)}-C e_{j^{A}}\\right\\rangle\\right]\\le\\mathbb{E}_{A}\\left[\\frac{\\eta\\sum_{t=1}^{T}\\left\\lVert\\widetilde{\\mathbf{g}}^{(t)}\\right\\rVert_{q}^{2}}{2\\alpha}+\\frac{1}{\\eta}B_{\\Phi}(C e_{j^{A}},p^{(1)})\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Similarly, denote $G:=\\left.\\bar{\\gamma}^{2}n^{2}\\,\\|\\pmb{b}\\right\\vert_{q}^{2}$ and $\\begin{array}{r}{G_{\\mathcal{A}}\\::=\\:\\sum_{t=1}^{T}\\left\\|\\mathbf{n}^{(t)}\\right\\|_{q}^{2}/T}\\end{array}$ . Then $\\begin{array}{r}{\\mathbb{E}_{\\mathcal{A}}\\left[\\sum_{t=1}^{T}\\left\\|\\widetilde{\\mathbf{g}}^{(t)}\\right\\|_{q}^{2}\\right]\\leq}\\end{array}$ $2T\\cdot\\left(G+\\sigma^{2}\\mathbb{E}\\left[\\left\\|z\\right\\|_{q}^{2}\\right]\\right)$ with $_{z}$ being a standard Gaussian vector. Plugging these values back, we get ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\boldsymbol{A}}\\left[\\sum_{t=1}^{T}\\left\\langle\\widetilde{\\mathbf{g}}^{(t)},p^{(t)}-C e_{j^{\\boldsymbol{A}}}\\right\\rangle\\right]\\leq\\frac{\\eta T\\cdot\\left(G+\\sigma^{2}\\mathbb{E}\\left[\\left\\Vert\\boldsymbol{z}\\right\\Vert_{q}^{2}\\right]\\right)}{\\alpha}+\\frac{1}{\\eta}\\mathbb{E}_{\\boldsymbol{A}}\\left[B_{\\Phi}(C e_{j^{\\boldsymbol{A}}},p^{(1)})\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Lastly, using stepsize \u03b7 = T \u00b7(G+\u03a6\u03c32E[\u2225z\u2225q2]) results in ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\zeta_{\\mathcal{A}}\\left[\\displaystyle\\sum_{t=1}^{T}\\Big\\langle\\mathbf{g}^{(t)},p^{(t)}-C e_{j^{\\mathcal{A}}}\\Big\\rangle\\right]\\leq\\sqrt{\\frac{T\\cdot\\left(G+\\sigma^{2}\\mathbb{E}[\\|z\\|_{q}^{2}]\\right)}{\\alpha}}\\cdot\\frac{B_{\\Phi}(\\mathbf{0},p^{(1)})+\\mathbb{E}_{\\mathcal{A}}\\left[B_{\\Phi}(C e_{j^{\\mathcal{A}}},p^{(1)})\\right]}{\\sqrt{B_{\\Phi}(\\mathbf{0},p^{(1)})}}}\\\\ {\\leq\\sqrt{\\frac{T\\cdot\\left(G+\\sigma^{2}\\mathbb{E}[\\|z\\|_{q}^{2}]\\right)}{\\alpha}}\\cdot\\underbrace{\\frac{B_{\\Phi}(\\mathbf{0},p^{(1)})+\\operatorname*{max}_{e\\in E_{1}}B_{\\Phi}(C e,p^{(1)})}{\\sqrt{B_{\\Phi}(\\mathbf{0},p^{(1)})}}}_{=:C_{\\Phi,1}(p^{(1)})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Comparing the lower bound (15) with the upper bound (16) and using $\\sigma^{2}=T c_{\\varepsilon,\\delta}$ , we immediately obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{T}_{\\mathbf{\\mathcal{A}}}\\left[\\left\\|v^{A}\\right\\|_{\\infty}\\right](C-\\left\\|p^{*}\\right\\|_{1})-C T\\sqrt{c_{\\varepsilon,\\delta}\\cdot2\\ln m}\\leq\\frac{C_{\\Phi,1}(p^{(1)})}{\\sqrt{\\alpha}}\\cdot\\left(\\sqrt{T G}+T\\sqrt{c_{\\varepsilon,\\delta}}\\cdot\\sqrt{\\mathbb{E}\\left[\\left\\|z\\right\\|_{q}^{2}\\right]}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Rearranging the above inequality yields (assume $C>\\|\\pmb{p}^{*}\\|_{1})$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}\\left[\\left\\lVert\\boldsymbol{v}^{A}\\right\\rVert_{\\infty}\\right]\\le\\frac{C_{\\Phi,1}(p^{(1)})}{\\sqrt{\\alpha}\\cdot(C-\\left\\lVert\\boldsymbol{p}^{*}\\right\\rVert_{1})}\\cdot\\left(\\sqrt{\\frac{G}{T}}+\\sqrt{c_{\\varepsilon,\\delta}}\\cdot\\sqrt{\\mathbb{E}\\left[\\left\\lVert\\boldsymbol{z}\\right\\rVert_{q}^{2}\\right]}\\right)+\\frac{C\\sqrt{2\\ln m}}{C-\\left\\lVert\\boldsymbol{p}^{*}\\right\\rVert_{1}}\\cdot\\sqrt{c_{\\varepsilon,\\delta}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "When c\u03b5,\u03b4\u00b7EG[\u2225z\u2225q2], (17) implies ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}\\left[\\left\\|v^{A}\\right\\|_{\\infty}\\right]\\leq\\left(\\frac{2\\sqrt{\\mathbb{E}[\\left\\|z\\right\\|_{q}^{2}]}\\cdot C_{\\Phi,1}(p^{(1)})}{\\sqrt{\\alpha}\\cdot(C-\\left\\|p^{*}\\right\\|_{1})}+\\frac{C\\sqrt{2\\ln m}}{C-\\left\\|p^{*}\\right\\|_{1}}\\right)\\cdot\\sqrt{c_{\\varepsilon,\\delta}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The inequality (18) gives an upper bound on the expected maximal constraint violation. ", "page_idx": 16}, {"type": "text", "text": "However, the above analysis holds only when constant $C$ satisfies (i) $C>\\|p^{*}\\|_{1}$ and (ii) $C e_{j^{A}}\\in$ $\\mathbb{R}_{+}^{m}\\cap\\mathcal{W}$ for any $j^{\\mathcal{A}}\\in[m]$ . To this end, we can simply let $C=2\\left\\|p^{*}\\right\\|_{1}$ , and replacing $C$ with $2\\left\\|p^{*}\\right\\|_{1}$ gives the desired result: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}\\left[\\left\\|v^{A}\\right\\|_{\\infty}\\right]\\leq\\left(\\frac{2\\sqrt{\\mathbb{E}\\left[\\left\\|z\\right\\|_{q}^{2}\\right]}\\cdot C_{\\Phi,1}(p^{(1)})}{\\sqrt{\\alpha}\\cdot\\left\\|p^{*}\\right\\|_{1}}+2\\sqrt{2\\ln m}\\right)\\cdot\\sqrt{c_{\\varepsilon,\\delta}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "A.5 Proof of Lemma 3.8 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof. For any agent $i$ , the objective value of its individual dual problem is always positive, i.e., $\\begin{array}{r}{\\operatorname*{max}_{{\\pmb x}_{i}\\in\\mathcal{X}_{i}}\\left\\{{\\boldsymbol u}_{i}({\\pmb x}_{i})-\\langle{\\pmb p}^{*},{\\pmb a}_{i}({\\pmb\\dot{\\pmb x}}_{i})\\rangle\\right\\}\\geq0}\\end{array}$ by Assumption 2.5 part 4. With this inequality, we are ready to show bounded shadow prices: ", "page_idx": 16}, {"type": "equation", "text": "$$\nn\\gamma\\left\\langle b,p^{*}\\right\\rangle+0\\leq\\left\\langle n\\gamma b,p^{*}\\right\\rangle+\\operatorname*{max}_{x\\in\\mathcal{X}}\\left\\{\\mathsf{F}(x)-\\left\\langle p^{*},a(x)\\right\\rangle\\right\\}=\\underbrace{\\mathsf{D}(p^{*})=\\mathsf{F}(x^{*})}_{\\mathrm{(by~strong~duality)}}\\leq n\\overline{{u}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Dividing both sides by $n\\gamma$ results in $\\langle{\\pmb b},{\\pmb p}^{*}\\rangle\\leq\\frac{\\bar{\\b u}}{\\gamma}$ ", "page_idx": 17}, {"type": "text", "text": "Similarly, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{n\\gamma\\left\\langle\\mathbf{1},p^{*}\\right\\rangle\\leq\\frac{\\left\\langle n\\gamma b,\\,\\pmb{p}^{*}\\right\\rangle+0}{\\operatorname*{min}_{j}b_{j}}\\leq\\frac{\\left\\langle n\\gamma b,\\,\\pmb{p}^{*}\\right\\rangle+\\operatorname*{max}_{\\pmb{x}\\in\\mathcal{X}}\\left\\{\\mathsf{F}(\\pmb{x})-\\left\\langle p^{*},a(\\pmb{x})\\right\\rangle\\right\\}}{\\operatorname*{min}_{j}b_{j}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\underbrace{\\frac{\\mathsf{D}(\\pmb{p}^{*})}{\\operatorname*{min}_{j}b_{j}}}_{\\operatorname*{min}_{j}b_{j}}=\\frac{\\mathsf{F}(\\pmb{x}^{*})}{\\operatorname*{min}_{j}b_{j}}\\leq\\frac{n\\bar{u}}{\\operatorname*{min}_{j}b_{j}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which implies \u27e81, p\u2217\u27e9\u2264 \u03b3 miunj bj . ", "page_idx": 17}, {"type": "text", "text": "A.6 Proof of Lemma 3.9 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. By the definition of strong convexity, it suffices to show ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\langle\\nabla\\Phi(p;\\theta)-\\nabla\\Phi(q;\\theta),p-q\\rangle\\geq\\frac{(\\operatorname*{min}_{j}\\{\\theta_{j}\\})^{2}}{K}\\left\\|p-q\\right\\|_{1}^{2},\\quad\\forall p,q\\in\\Delta_{K}^{\\mathrm{int}}(\\theta).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "According to the definition of parameterized negative entropy function, its gradient is $\\nabla\\Phi(p;\\pmb\\theta)_{j}=$ $\\theta_{j}\\ln\\left(p_{j}\\theta_{j}\\right)+\\theta_{j},\\forall j\\ \\in\\ [m]$ . By the well celebrated Hermite\u2013Hadamard inequality $\\textstyle f({\\frac{a+b}{2}})\\;\\leq$ $\\textstyle{\\frac{1}{b-a}}\\int_{a}^{b}f(x)\\,d x$ , if we use convex function $\\begin{array}{r}{f(t)=\\frac{1}{t},\\forall t>0}\\end{array}$ , we immediately have $\\begin{array}{r}{\\frac{2}{a+b}\\leq\\frac{\\ln b-\\ln a}{b-a}}\\end{array}$ which implies ", "page_idx": 17}, {"type": "equation", "text": "$$\n(\\ln b-\\ln a)\\cdot(b-a)\\geq{\\frac{2(b-a)^{2}}{b+a}},\\quad\\forall a,b\\geq0,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the case $a=0$ or $b=0$ , or both are obtained by continuity and the conventions that $\\begin{array}{r}{\\frac{0}{0}=0}\\end{array}$ and $0\\ln0=0$ . If we set $b=p_{j}\\theta_{j}$ and $a=q_{j}\\theta_{j}$ for (21), we can get ", "page_idx": 17}, {"type": "equation", "text": "$$\n(\\ln{(p_{j}\\theta_{j})}-\\ln{(q_{j}\\theta_{j})})\\cdot\\theta_{j}(p_{j}-q_{j})\\geq\\frac{2\\theta_{j}(p_{j}-q_{j})^{2}}{p_{j}+q_{j}},\\quad\\forall j\\in[m].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Summing over $j\\in[m]$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{LHS\\,of\\,}(20)=\\sum_{j=1}^{m}\\left(\\ln\\left(p_{j}\\theta_{j}\\right)-\\ln\\left(q_{j}\\theta_{j}\\right)\\right)\\cdot\\theta_{j}(p_{j}-q_{j})\\ge\\sum_{j=1}^{m}\\frac{2\\theta_{j}(p_{j}-q_{j})^{2}}{p_{j}+q_{j}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "It remains to further lower bound the summation on the r.h.s. We follow the proof idea of Lemma 2 in [BLM23] to complete our proof: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{j=1}^{m}\\frac{2\\theta_{j}(p_{j}-q_{j})^{2}}{p_{j}+q_{j}}=2\\left<\\theta,p+q\\right>\\cdot\\displaystyle\\sum_{j=1}^{m}\\frac{\\theta_{j}(p_{j}+q_{j})}{(\\theta,p+q)}\\cdot\\left.\\frac{\\left|p_{j}-q_{j}\\right|^{2}}{(p_{j}+q_{j})^{2}}\\right.}&{}\\\\ {\\displaystyle}&{\\ge2\\left<\\theta,p+q\\right>\\cdot\\left(\\displaystyle\\sum_{j=1}^{m}\\frac{\\theta_{j}(p_{j}+q_{j})}{(\\theta,p+q)}\\cdot\\frac{\\left|p_{j}-q_{j}\\right|}{p_{j}+q_{j}}\\right)^{2}}\\\\ &{=\\displaystyle\\frac{2}{(\\theta,p+q)}\\cdot\\left(\\displaystyle\\sum_{j=1}^{m}\\theta_{j}\\left|p_{j}-q_{j}\\right|\\right)^{2}}\\\\ &{\\ge\\displaystyle\\frac{1}{K}\\cdot\\left(\\displaystyle\\sum_{j=1}^{m}\\theta_{j}\\left|p_{j}-q_{j}\\right|\\right)^{2}}\\\\ &{\\ge\\displaystyle\\frac{(\\operatorname*{min}_{j}\\{\\theta\\})^{2}}{2}\\cdot\\left|[p-q]\\right|_{1}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "A.7 Proof of Theorem 3.10 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. The proof follows the general proof of Theorem 3.5 and 3.6 for any potential function $\\Phi$ . It remains to properly modify results for the $\\Phi$ chosen. When the potential function is the parameterized negative entropy $\\begin{array}{r}{\\dot{\\Phi}:=\\Phi(\\pmb{w};\\pmb{b})=\\sum_{j=1}^{m}w_{j}b_{j}\\ln\\left(w_{j}b_{j}\\right)}\\end{array}$ defined on $\\Delta_{K}^{\\mathrm{int}}(\\pmb{b}):=\\{\\pmb{w}>\\bar{\\mathbf{0}}:\\langle\\pmb{b},\\pmb{w}\\rangle\\leq$ $K\\}$ with $\\begin{array}{r}{K=\\frac{2\\bar{u}}{\\gamma}}\\end{array}$ , the conjugate index $q=\\infty$ , strong convexity parameter $\\alpha=\\underline{{b}}^{2}/K$ . Moreover, direct calculation gives the Bregman divergence $B_{\\Phi}(\\mathbf{0},p^{(1)})\\,=\\,\\bigl\\langle b,p^{(1)}\\bigr\\rangle$ . Because we choose $p_{j}^{(1)}=K/(m b_{j}),\\forall j\\in[m]$ , we thus have $B_{\\Phi}(\\mathbf{0},p^{(1)})=K$ . ", "page_idx": 18}, {"type": "text", "text": "Utility Guarantee: It is evident that $C_{\\Phi}({\\pmb p}^{(1)})\\,:=\\,\\sqrt{B_{\\Phi}({\\pmb0},{\\pmb p}^{(1)})/\\alpha}\\,=\\,\\sqrt{K/({\\underline{{b}}}^{2}/K)}\\,=\\,K/{\\underline{{b}}}.$ Therefore, the utility upper bound (7) becomes ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{F}({\\boldsymbol x}^{*})-\\mathbb{E}_{{\\boldsymbol A}}\\left[\\mathsf{F}({\\boldsymbol x}^{{\\boldsymbol A}})\\right]=4C_{\\Phi}(p^{(1)})\\cdot\\sqrt{\\mathbb{E}\\left[\\left\\|{\\boldsymbol z}\\right\\|_{\\infty}^{2}\\right]}\\cdot\\sqrt{c_{\\varepsilon,{\\boldsymbol\\delta}}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\le4\\frac{K}{\\underline{{b}}}\\cdot\\sqrt{2\\ln\\left(2m\\right)}\\cdot\\sqrt{c_{\\varepsilon,{\\boldsymbol\\delta}}}=\\frac{8\\sqrt{2}\\bar{\\boldsymbol{u}}\\cdot\\sqrt{\\ln\\left(2m\\right)}}{\\gamma\\underline{{b}}}\\cdot\\sqrt{c_{\\varepsilon,{\\boldsymbol\\delta}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Feasibility Guarantee: We can work from (19) and first figure out $C_{\\Phi,1}(p^{(1)})$ . Direct calculation gives $B_{\\Phi}(C e_{j},p^{(1)})=B_{\\Phi}(\\mathbf{0},p^{(1)})+C b_{j}\\cdot\\left(\\ln(C/p_{j}^{(1)})-1\\right),\\forall j\\in[m]$ . Plugging $C=2\\left\\|p^{*}\\right\\|_{1}$ , we can upper bound $C_{\\Phi,1}(\\pmb{p}^{(1)})$ as: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\widetilde{\\gamma}_{\\Phi,1}(p^{(1)}):=\\frac{B_{\\Phi}(\\pmb{0},p^{(1)})+\\operatorname*{max}_{j}B_{\\Phi}\\left(C e_{j},p^{(1)}\\right)}{\\sqrt{B_{\\Phi}(\\pmb{0},p^{(1)})}}}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =2\\sqrt{K}+\\frac{2\\|p^{*}\\|_{1}\\operatorname*{max}_{j}\\,\\left\\{b_{j}\\cdot\\left(\\ln\\left(\\frac{2\\|p^{*}\\|_{1}m b_{j}}{K}\\right)-1\\right),0\\right\\}}{\\sqrt{K}}}&{(\\mathrm{since}\\,p_{j}^{(1)}=K/(m b_{j}))}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\leq2\\sqrt{K}+\\sqrt{K}\\cdot\\operatorname*{max}_{j}\\,\\{b_{j}\\cdot\\left(\\ln\\left(m b_{j}\\right)-1\\right),0\\}}&{(K\\geq2\\,\\|p^{*}\\|_{1},\\mathrm{Lemma\\,3.8})}\\\\ &{\\leq2\\sqrt{K}+\\sqrt{K}\\bar{b}\\cdot(\\ln\\left(m\\bar{b}\\right)-1)^{+}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Substitute $C_{\\Phi,1}(p^{(1)})$ back into (19) with $\\begin{array}{r}{K=\\frac{2\\overline{{u}}}{\\gamma}}\\end{array}$ , we get ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}\\left[\\left\\Vert v^{A}\\right\\Vert_{\\infty}\\right]\\le\\frac{4\\bar{u}\\sqrt{2\\ln\\left(2m\\right)}\\cdot\\left[2+\\bar{b}\\cdot(\\ln\\left(m\\bar{b}\\right)-1)^{+}\\right]}{\\gamma\\underline{{b}}\\cdot\\left\\Vert p^{*}\\right\\Vert_{1}}\\cdot\\sqrt{c_{\\varepsilon,\\delta}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "B Proofs for Section 4 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "B.1 Proof of self post-processing Lemma 4.1 for JDP ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. The proof is for a deterministic function $f$ . The result on randomized functions follows immediately as any randomized mapping can be decomposed into a convex combination of deterministic functions. The proof here largely follows the same idea for the proof of Billboard Lemma. For any $x\\in\\mathcal{X}^{n}$ , let $f(x_{-k},{\\mathcal D}_{-k}):=(f(x_{1},z_{1}),\\dots,f(x_{k-1},z_{k-1}),f(x_{k+1},z_{k+1}),\\dots,f(x_{n},z_{n}),f(x_{k+1},z_{k+1}),\\dots,f(x_{n},z_{n})))$ )). For any subset $S\\subseteq\\mathcal{V}^{n-1}$ , let $f^{-1}(S;\\mathcal{D}_{-k}):=\\left\\{x_{-k}\\in\\mathcal{X}^{n-1}:f(x_{-k},\\mathcal{D}_{-k})\\in S\\right\\}$ be the preimage of $\\boldsymbol{S}$ with respect to the mapping $\\pmb{f}(\\cdot,\\mathscr{D}_{-k})$ . Then, we can show that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\operatorname*{Pr}\\left[f(\\mathcal{M}(\\mathcal{D})_{-k},\\mathcal{D}_{-k})\\in\\mathcal{S}\\right]=\\operatorname*{Pr}\\left[\\mathcal{M}(\\mathcal{D})_{-k}\\in f^{-1}(\\mathcal{S};\\mathcal{D}_{-k})\\right]}&{}\\\\ {\\leq e^{\\varepsilon}\\cdot\\operatorname*{Pr}\\left[\\mathcal{M}(\\mathcal{D}^{\\prime})_{-k}\\in f^{-1}(\\mathcal{S};\\mathcal{D}_{-k})\\right]+\\delta}&{(\\mathcal{M}(\\cdot)\\operatorname*{is}{(\\varepsilon,\\delta)}\\mathrm{-}\\mathrm{JDP})}\\\\ {=e^{\\varepsilon}\\cdot\\operatorname*{Pr}\\left[f(\\mathcal{M}(\\mathcal{D}^{\\prime})_{-k},\\mathcal{D}_{-k})\\in\\mathcal{S}\\right]+\\delta}&{}\\\\ {=e^{\\varepsilon}\\cdot\\operatorname*{Pr}\\left[f(\\mathcal{M}(\\mathcal{D}^{\\prime})_{-k},\\mathcal{D}_{-k}^{\\prime})\\in\\mathcal{S}\\right]+\\delta,}&{(\\mathcal{D}_{-k}=\\mathcal{D}_{-k}^{\\prime})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which confirms JDP guarantee after self post-processing. ", "page_idx": 18}, {"type": "text", "text": "B.2 Proof of post-processing Lemma 4.2 for JDP ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. Similarly, the proof is for a deterministic function $f$ . Let $f^{-1}(S)$ be the preimage of $\\boldsymbol{S}$ . For any ${\\mathcal{S}}\\subseteq{\\mathcal{V}}$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\operatorname*{Pr}\\left[f(\\mathcal{M}(\\mathcal{D})_{-k})\\in S\\right]=\\operatorname*{Pr}\\left[\\mathcal{M}(\\mathcal{D})_{-k}\\in f^{-1}(S)\\right]}&{}\\\\ {\\leq e^{\\varepsilon}\\cdot\\operatorname*{Pr}\\left[\\mathcal{M}(\\mathcal{D}^{\\prime})_{-k}\\in f^{-1}(S)\\right]+\\delta}&{\\qquad(\\mathcal{M}(\\cdot)\\mathrm{~is~}(\\varepsilon,\\delta)\\mathrm{-}\\mathrm{JDP})}\\\\ {=e^{\\varepsilon}\\cdot\\operatorname*{Pr}\\left[f(\\mathcal{M}(\\mathcal{D}^{\\prime})_{-k})\\in S\\right]+\\delta.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "B.3 Proof of Theorem 4.3 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The proof consists of several steps: (i) construct a \u201chard\u201d distribution of datasets; (ii) identify necessary conditions on the JDP algorithm $\\boldsymbol{\\mathcal{A}}$ with the help of Lemma 4.1 and 4.2; (iii) reformulate the minimax lower bound into a better form that aligns these necessary conditions; (iv) combine all steps together. Without loss of generality, we assume $\\pmb{b}=\\pmb{1}$ . ", "page_idx": 19}, {"type": "text", "text": "Step 1: Construct a \u201chard\u201d distribution of datasets. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Let $\\operatorname{Id}(\\cdot)$ be the identity function, and let 1 and 0 be vectors of 1\u2019s and $0$ \u2019s whose lengths are $m$ . Define three types of requests: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{z:=({\\mathbf x}\\mapsto\\langle\\mathbf{1},{\\mathbf x}\\rangle\\,,\\;\\mathrm{Id}(\\cdot),\\;\\{\\mathbf{1}{x}:x\\in[0,1]\\});}\\\\ &{z^{1}:=({\\mathbf x}\\mapsto\\langle\\mathbf{1},{\\mathbf x}\\rangle\\,,\\;\\mathrm{Id}(\\cdot),\\;\\{\\mathbf{1}{x}:x=\\operatorname*{min}\\{1,n\\gamma\\}\\});}\\\\ &{z^{0}:=({\\mathbf x}\\mapsto\\langle\\mathbf{1},{\\mathbf x}\\rangle\\,,\\;\\mathrm{Id}(\\cdot),\\;\\{\\mathbf{1}{x}:x=0\\}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "All three types of requests are the same in their utility and consumption functions, both taking linear forms. It is also easy to verify that all three types of requests satisfy Assumptions 2.5 (part 1 and 2). In what follows, we construct datasets that satisfy Assumption 2.5 (part 3 and 4) and Assumption 3.7 as well. ", "page_idx": 19}, {"type": "text", "text": "Based on these requests, we construct a pair of neighboring datasets that differ in agent $n$ only: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal{D}_{0}:=(\\underbrace{z,\\ldots,z}_{n-1\\;\\mathrm{requests}}\\;z^{0});\\qquad\\mathcal{D}_{1}:=(\\underbrace{z,\\ldots,z}_{n-1\\;\\mathrm{requests}}\\;z^{1}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "It is easy to verify that part 3 of Assumption 2.5 is also met, i.e., the primal problem is always feasible, and the optimal shadow price is $\\pmb{p}^{*}=\\mathbf{1}$ , which are non-zeros. The result $\\pmb{p}^{*}=\\mathbf{1}$ is by noticing that one unit increase in available resource will increase the objective value of the primal problem by 1. Since $\\pmb{p}^{*}=\\mathbf{1}$ , it immediate to see that part 4 of Assumption 2.5 also holds, because now the function $u_{i}(\\pmb{x}_{i})+\\langle\\pmb{p}^{*},-\\pmb{a}_{i}(\\pmb{x}_{i})\\rangle$ becomes $\\langle\\mathbf{1},\\pmb{x}_{i}\\rangle+\\langle\\mathbf{1},-\\pmb{x}_{i}\\rangle$ , which is always non-negative for any $\\mathbf{\\mathcal{x}}_{i}\\in\\mathcal{X}_{i}$ . Moreover, the constraint to be dualized is a linear constraint; thus Assumption 3.7 strong duality holds. ", "page_idx": 19}, {"type": "text", "text": "Lastly, let dataset $\\mathcal{D}$ be drawn from $\\mathrm{Unif}\\{\\ensuremath{D_{0}},\\ensuremath{D_{1}}\\}$ , i.e. uniformly distributed over these two datasets. ", "page_idx": 19}, {"type": "text", "text": "Step 2: Identify necessary conditions on JDP algorithm $\\boldsymbol{\\mathcal{A}}$ ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Let ${\\pmb x}^{A}({\\mathcal D})\\;:=\\;({\\pmb x}_{1}^{A}({\\mathcal D}),\\ldots,{\\pmb x}_{n}^{A}({\\mathcal D}))$ be the output of $(\\varepsilon,\\delta)$ -JDP algorithm $\\boldsymbol{\\mathcal{A}}$ . The self postprocessing Lemma 4.1 says that if we process each $\\pmb{x}_{i}^{A}$ with $i$ \u2019s own data, the resulting output is still JDP. That implies $(\\mathrm{Id}(\\pmb{x}_{1}^{A}),\\dots,\\mathrm{Id}(\\pmb{x}_{n}^{A}))$ should also be $(\\varepsilon,\\delta)$ -JDP. Moreover, the postprocessing Lemma 4.2 indicates that the aggregated consumption, excluding agent $n$ \u2019s, should be indistinguishable even if agent $n$ \u2019s data is changed, i.e., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[\\sum_{i\\neq n}\\mathrm{Id}(x_{i}^{A}(\\mathcal{D}))\\in\\mathcal{S}\\right]\\leq e^{\\varepsilon}\\mathrm{Pr}\\left[\\sum_{i\\neq n}\\mathrm{Id}(x_{i}^{A}(\\mathcal{D}^{\\prime}))\\in\\mathcal{S}\\right]+\\delta,\\quad\\forall S\\subseteq[\\mathbf{0},n\\gamma\\mathbf{1}].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Instantiating the above inequality with $\\mathcal{D}\\;=\\;\\mathcal{D}_{0}$ , $\\mathcal{D}^{\\prime}\\;=\\;\\mathcal{D}_{1}$ , and $S\\,=\\,\\left(n\\gamma{\\bf1}\\,-\\,c{\\bf1},n\\gamma{\\bf1}\\right]$ with $c:=\\operatorname*{min}\\{1,n\\gamma\\}$ leads to ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{0})\\in(n\\gamma\\mathbf{1}-c\\mathbf{1},n\\gamma\\mathbf{1}\\right]\\right]\\leq e^{\\varepsilon}\\mathrm{Pr}\\left[\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{1})\\in(n\\gamma\\mathbf{1}-c\\mathbf{1},n\\gamma\\mathbf{1}\\right]\\right]+\\delta.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We can simplify the preceding inequality by changing decision variables from bold format $\\pmb{x}_{i}$ to normal format $x_{i}$ , because by construction of requests $z,z^{1},z^{0}$ , each decision vector $\\mathbf{x}_{i}:=\\mathbf{1}x_{i}$ is fully determined by a single scalar $x_{i}$ . This leads to the following equivalent inequality, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{Pr}\\left[\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{0})\\in(n\\gamma-c,n\\gamma]\\right]\\leq e^{\\varepsilon}\\mathrm{Pr}\\left[\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{1})\\in(n\\gamma-c,n\\gamma]\\right]+\\delta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Moreover, when dataset is $\\mathcal{D}_{1}$ , agent $n$ should always be assigned $c$ unit, forcing resource available for others to be at most $n\\gamma-c$ . Thus, if $\\boldsymbol{\\mathcal{A}}$ is an $(\\varepsilon,\\delta)$ -JDP algorithm outputting a feasible allocation with probability 1, then $\\begin{array}{r}{\\sum_{i\\neq n}x_{i}^{\\mathcal{A}}(\\mathcal{D}_{1})\\leq n\\gamma-\\dot{c}}\\end{array}$ w.p. 1, and (23) becomes: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{0})\\in(n\\gamma-c,n\\gamma]\\right]\\leq e^{\\varepsilon}\\cdot0+\\delta=\\delta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, we get a necessary condition (24) for any $\\boldsymbol{\\mathcal{A}}$ being $(\\varepsilon,\\delta)$ -JDP: when dataset is $\\mathcal{D}_{0}$ , Algorithm $\\boldsymbol{\\mathcal{A}}$ should not assign many resources to other agents, and only with a small probability $\\delta$ , other agents can get at least $n\\gamma-c$ resources. ", "page_idx": 20}, {"type": "text", "text": "Step 3: Reformulate the minimax bound ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Let $\\Delta\\in[0,n\\gamma]$ be a constant to be determined later, and let $S_{\\Delta}^{+}:=(n\\gamma-\\Delta,n\\gamma]$ , $S_{\\Delta}^{-}:=[0,n\\gamma-\\Delta]$ be two disjoint regions partitioning the interval $[0,n\\gamma]$ . Let $\\mathcal{T}\\in\\{0,1\\}^{m}$ be an indicator so that 1 in $j$ \u2019s position implies $(\\textstyle\\sum_{i=1}^{n}\\mathbf{x}_{i}^{A})_{j}\\,\\in\\,S_{\\Delta}^{+}$ ; otherwise, in $S_{\\Delta}^{-}$ . Let event $E_{\\mathcal{T}}:=\\left\\{(\\pmb{x}_{1},\\pmb{\\dots},\\pmb{x}_{n}):\\right.$ $\\mathbb{1}\\,\\big\\{(\\sum_{i=1}^{n}\\pmb{x}_{i})_{j}\\in S_{\\Delta}^{+}\\big\\}=\\mathbb{Z}_{j},\\forall\\dot{\\pmb{j}}\\in[m]\\big\\}.$ . With these notations and the law of total probability, we first rewrite the expression of Algorithm $\\boldsymbol{\\mathcal{A}}$ \u2019s utility when dataset is $\\mathcal{D}_{0}$ as: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\boldsymbol{A}}\\left[\\mathbb{F}(\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0}))\\right]=\\displaystyle\\sum_{\\boldsymbol{\\tau}\\in\\{0,1\\}^{m}}\\mathbb{E}_{\\boldsymbol{A}}\\left[\\sum_{i=1}^{n}\\left\\langle\\mathbf{1},\\boldsymbol{x}_{i}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\right\\rangle\\;\\middle|\\;\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\mathbb{Z}}\\right]\\cdot\\operatorname*{Pr}\\left[\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\mathbb{Z}}\\right]}\\\\ &{\\qquad=\\displaystyle\\sum_{\\boldsymbol{\\tau}\\in\\{0,1\\}^{m}}\\mathbb{E}_{\\boldsymbol{A}}\\left[\\sum_{i=1}^{n}\\sum_{j=1}^{m}\\left(\\boldsymbol{x}_{i}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\right)_{j}\\;\\middle|\\;\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\mathbb{Z}}\\right]\\cdot\\operatorname*{Pr}\\left[\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\mathbb{Z}}\\right]}\\\\ &{\\qquad=\\displaystyle\\sum_{\\boldsymbol{\\tau}\\in\\{0,1\\}^{m}}\\mathbb{E}_{\\boldsymbol{A}}\\left[\\sum_{j=1}^{m}\\left(\\sum_{i=1}^{n}\\boldsymbol{x}_{i}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\right)_{j}\\;\\middle|\\;\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\mathbb{Z}}\\right]\\cdot\\operatorname*{Pr}\\left[\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\mathbb{Z}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We observe that when event $E_{\\mathbb{Z}}$ happens, the resource consumed $\\textstyle\\left(\\sum_{i=1}^{n}\\pmb{x}_{i}^{\\mathcal{A}}(D_{0})\\right)_{j}$ is no more than either $n\\gamma-\\Delta$ or $n\\gamma$ , depending on $\\mathcal{T}_{j}$ . Hence, we can reach an upper bound expressed by $\\mathcal{T}_{j}$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left.\\left[\\boldsymbol{X}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\right]\\right]\\leq\\underset{\\mathcal{Z}\\in\\{0,1\\}^{1}}{\\sum}\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left.\\left[\\mathcal{D}_{0}\\right]\\left[\\left.\\left[\\mathcal{T}_{j}-\\Delta\\right)\\right]\\left\\{\\boldsymbol{Z}_{j}=0\\right\\}+n{\\gamma}\\right]\\left\\{\\boldsymbol{Z}_{j}=1\\right\\}\\right|\\,\\,E_{\\boldsymbol{Z}}\\right]\\cdot\\mathbf{Pr}\\left[\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\right.}\\\\ &{=\\underset{\\mathcal{Z}\\in\\{0,1\\}^{1}}{\\sum}\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left.\\left[m_{\\mathcal{T}}\\right.-\\left.\\frac{m}{\\gamma-1}\\Delta\\boldsymbol{1}\\left\\{\\boldsymbol{Z}_{j}=0\\right\\}\\right.\\right]E_{\\boldsymbol{Z}}\\right]\\cdot\\mathbf{Pr}\\left[\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\boldsymbol{Z}}\\right]}\\\\ &{=m n\\gamma-\\Delta\\underset{j=1}{\\overset{m}{\\sum}}\\underset{\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left.\\left[\\boldsymbol{Z}_{j}\\right]\\right]^{1}}{\\sum}\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left.\\left[\\boldsymbol{Z}_{j}=0\\right]\\right.\\right]E_{\\boldsymbol{Z}}\\right]\\operatorname*{Pr}\\left[\\boldsymbol{x}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\in E_{\\boldsymbol{Z}}\\right]}\\\\ &{=m n\\gamma-\\Delta\\underset{j=1}{\\overset{m}{\\sum}}\\mathbb{E}_{\\boldsymbol{A}}\\left[\\left.\\left[\\boldsymbol{Z}_{j}=0\\right]\\right]}\\\\ &{=m n\\gamma-\\Delta\\underset{j=1}{\\overset{m}{\\sum}}\\mathbf{Pr}\\left[\\left(\\underset{i=1}{\\overset{n}{\\sum}}\\boldsymbol{x}_{i}^{\\boldsymbol{A}}(\\mathcal{D}_{0})\\right)_{j}\\in S_{\\boldsymbol{A}}^{\\infty}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Due to the construction of $\\mathcal{D}_{0}$ that $\\pmb{x}_{i}^{A}:=\\mathbf{1}x_{i}^{A}$ , the probability terms in the preceding inequality should be the same among all $j=1,\\dots,m$ ; thus, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{A}}\\left[\\mathsf{F}({\\boldsymbol{x}}^{A}({\\mathcal{D}}_{0}))\\right]\\leq m n\\gamma-m\\Delta\\cdot\\operatorname*{Pr}\\left[\\sum_{i=1}^{n}x_{i}^{A}({\\mathcal{D}}_{0})\\in S_{\\Delta}^{-}\\right].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Moreover, with $\\mathcal{D}_{0}$ , the allocation to agent $n$ should be $x_{n}^{A}({\\mathcal{D}}_{0})\\,=\\,0$ , modifying the preceding inequality into ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{A}}\\left[\\mathsf{F}({\\boldsymbol{x}}^{A}({\\mathcal{D}}_{0}))\\right]\\leq m n{\\boldsymbol{\\gamma}}-m\\Delta\\cdot\\mathrm{Pr}\\left[\\sum_{i\\neq n}x_{i}^{A}({\\mathcal{D}}_{0})\\in S_{\\Delta}^{-}\\right].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We note that with either dataset $\\mathcal{D}_{0}$ or $\\mathcal{D}_{1}$ , the optimal utility obtained in the non-private setting is always mn\u03b3, i.e., $\\mathsf{F}(\\pmb{x}^{*}(\\mathcal{D}_{0}))\\,=\\,\\mathsf{F}(\\pmb{x}^{*}(\\mathcal{D}_{1}))\\,=\\,m n\\gamma$ . As a result, the minimax regret is lower bounded as follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{inf}_{\\varepsilon,\\delta\\to\\operatorname{IDP}}\\underset{\\mathcal{D}}{\\operatorname*{sup}}\\left\\{\\mathsf{F}(\\mathbf{x}^{*}(\\mathcal{D}))-\\mathbb{E}_{{\\cal A}}\\left[\\mathsf{F}(\\mathbf{x}^{\\mathcal{A}}(\\mathcal{D}))\\right]\\right\\}\\geq\\underset{A\\mathrm{is}\\;(\\varepsilon,\\delta)\\cdot\\operatorname*{IDP}}{\\operatorname*{inf}}\\mathbb{E}_{\\mathcal{D}\\sim\\operatorname{Unif}\\{\\mathcal{D}_{0},\\mathcal{D}_{1}\\}}\\left[\\mathsf{F}(\\mathbf{x}^{*}(\\mathcal{D}))-\\mathbb{E}_{{\\cal A}}\\left[\\mathsf{F}(\\mathbf{x}^{\\mathcal{A}}(\\mathcal{D}))\\right]\\right],}\\\\ {\\geq\\frac{1}{2}\\cdot\\underset{A\\mathrm{is}\\;(\\varepsilon,\\delta)\\cdot\\operatorname*{IDP}}{\\operatorname*{inf}}\\;\\Bigg\\{m n\\gamma-\\Bigg(m n\\gamma-m\\Delta\\cdot\\operatorname*{Pr}\\left[\\sum_{i\\neq n}w_{i}^{*}(\\mathcal{D})-\\mathbb{E}_{\\delta}\\right]\\Bigg)\\Bigg\\}\\;\\Bigg|_{\\varepsilon=n}}\\\\ {=\\frac{m\\Delta}{2}\\cdot\\underset{A\\mathrm{is}\\;(\\varepsilon,\\delta)\\cdot\\operatorname*{IDP}}{\\operatorname*{inf}}\\operatorname*{Pr}\\left[\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{0})\\in[0,n\\gamma-\\Delta]\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second inequality is by considering $\\mathcal{D}_{0}$ and plugging in (25). ", "page_idx": 21}, {"type": "text", "text": "Step 4: Combine all together ", "text_level": 1, "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\left[\\displaystyle\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{0})\\in[0,n\\gamma-1/\\varepsilon]\\right]\\geq\\operatorname*{Pr}\\left[\\displaystyle\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{0})\\in[0,n\\gamma-c]\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=1-\\operatorname*{Pr}\\left[\\displaystyle\\sum_{i\\neq n}x_{i}^{A}(\\mathcal{D}_{0})\\in(n\\gamma-c,n\\gamma]\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\geq1-\\delta\\geq\\frac12.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Plugging the preceding inequality back into (26) immediately leads to ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\substack{A\\,\\mathrm{is}\\,\\left(\\varepsilon,\\delta\\right)-\\mathrm{JDP}\\,\\mathrm{~\\tiny~\\mathscr~D~}}}\\operatorname*{sup}_{\\mathcal{D}}\\left\\{\\mathsf{F}(x^{*}(\\mathcal{D}))-\\mathbb{E}_{A}\\left[\\mathsf{F}(x^{A}(\\mathcal{D}))\\right]\\right\\}\\geq\\frac{m}{4\\varepsilon},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "which completes the proof. ", "page_idx": 21}, {"type": "text", "text": "B.4 Discussion on lower bounds for general $\\varepsilon$ ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The lower bound in Theorem 4.3 only holds for $\\varepsilon\\geq\\operatorname*{max}\\{1,1/(n\\gamma)\\}$ . Intuitively, this is because we only use feasibility of $\\boldsymbol{\\mathcal{A}}$ to prove the lower bound: \u201cwe reserve some resource exclusively for agent $k$ .\u201d The optimality condition of $\\boldsymbol{\\mathcal{A}}$ in the minimax expression $\\operatorname{inf}_{A}\\operatorname{sup}_{D}$ is not used. Noticing this oversight, we provide a lower bounding problem that fills this gap. ", "page_idx": 21}, {"type": "text", "text": "We start with expressing DP in terms of hockey-stick divergence. Suppose $\\mu$ and $\\mu^{\\prime}$ are two probability measures that are absolutely continuous with respect to each other. Let $H_{e^{\\varepsilon}}(X,Y):=$ $\\begin{array}{r}{\\int_{z\\in\\mathcal{Z}}\\left(\\frac{d\\mu}{d\\mu^{\\prime}}(z)-e^{\\varepsilon}\\right)^{+}d\\mu^{\\prime}(z)}\\end{array}$ be the hockey-stick divergence between two random variables $X,Y$ . ", "page_idx": 21}, {"type": "text", "text": "Let $\\mathcal{M}$ be an $(\\varepsilon,\\delta)$ -DP mechanism, and let $\\mathcal{M}(\\mathcal{D})_{-k}:=\\Pi_{-k}\\mathcal{M}(\\mathcal{D})$ be the random vector of $n-1$ elements projected to others than agent $k$ . Here are some relationships among indistinguishability, DP, and JDP. ", "page_idx": 22}, {"type": "text", "text": "\u2022 $(\\varepsilon,\\delta)$ -indistinguishability: if $H_{e^{\\varepsilon}}(X,Y)\\leq\\delta$ , then $X$ is said to be $(\\varepsilon,\\delta)$ -indistinguishable from $Y$ ;   \n\u2022 $(\\varepsilon,\\delta)$ -DP: for a mechanism $\\mathcal{M}$ , if $\\begin{array}{r}{\\operatorname*{sup}_{\\mathcal{D}\\sim\\mathcal{D}^{\\prime}}H_{e^{\\varepsilon}}(\\mathcal{M}(\\mathcal{D}),\\mathcal{M}(\\mathcal{D}^{\\prime}))\\leq\\delta}\\end{array}$ , we say $\\mathcal{M}$ is $(\\varepsilon,\\delta)$ - DP [BBG18];   \n\u2022 $(\\varepsilon,\\delta)$ -JDP: for a mechanism $\\mathcal{M}$ , if $\\begin{array}{r}{\\operatorname*{sup}_{\\mathcal{D}\\sim\\mathcal{D}^{\\prime},k}H_{e^{\\varepsilon}}(\\mathcal{M}(\\mathcal{D})_{-k},\\mathcal{M}(\\mathcal{D}^{\\prime})_{-k})\\leq\\delta,}\\end{array}$ we say $\\mathcal{M}$ is $(\\varepsilon,\\delta)$ -JDP. ", "page_idx": 22}, {"type": "text", "text": "It is self-evident from these relationships that DP requires indistinguishability between outputs for any pair of neighboring datasets, while JDP requires indistinguishability between projected outputs without agent $k$ for any pair of neighboring datasets. ", "page_idx": 22}, {"type": "text", "text": "To obtain another lower bound exploiting optimality of $\\boldsymbol{\\mathcal{A}}$ , we can follow the idea and notation in the proof of Theorem 4.3, but consider different neighboring datasets: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{D}^{1-}:=(z^{0},\\underbrace{z,\\dots,z}_{\\mathrm{n-l~requests}}),\\quad\\mathcal{D}^{1+}:=(z^{1},\\underbrace{z,\\dots,z}_{\\mathrm{n-l~requests}}),\\quad\\mathcal{D}^{1+,2+}:=(z^{1},z^{1},\\underbrace{z,\\dots,z}_{\\mathrm{n-2~requests}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "It is obvious $D^{1-}\\sim\\mathcal{D}^{1+}$ , and $D^{1+}\\sim\\mathcal{D}^{1+,2+}$ are pairs of neighboring datasets. Let $S_{-k}(\\mathbf{x}^{A}):=$ $\\textstyle\\sum_{i\\neq k}{\\pmb{x}}_{i}^{A}$ be the total consumption excluding agent $k$ . By the definition of $(\\varepsilon,\\delta)$ -JDP, any JDP algorithm $\\boldsymbol{\\mathcal{A}}$ should satisfy following necessary constraints: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{H_{e^{\\varepsilon}}(S_{-1}(x^{A}(\\mathcal{D}^{1-})),S_{-1}(x^{A}(\\mathcal{D}^{1+})))\\leq\\delta;}\\\\ {H_{e^{\\varepsilon}}(S_{-1}(x^{A}(\\mathcal{D}^{1+})),S_{-1}(x^{A}(\\mathcal{D}^{1+,2+})))\\leq\\delta;}\\\\ {H_{e^{\\varepsilon}}(S_{-2}(x^{A}(\\mathcal{D}^{1+,2+})),S_{-2}(x^{A}(\\mathcal{D}^{1+})))\\leq\\delta;}\\\\ {H_{e^{\\varepsilon}}(S_{-2}(x^{A}(\\mathcal{D}^{1+})),S_{-2}(x^{A}(\\mathcal{D}^{1-})))\\leq\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The variable $\\pmb{x}^{A}(\\mathcal{D}^{1+,2+})$ in both constraints (28) and (29) should be the same, and thus links both constraints. Moreover, the variable $x^{A}({\\mathcal{D}}^{1-})$ in constraints (27) and (30) are the same. Therefore, the four constraints form a loop restricting each other. ", "page_idx": 22}, {"type": "text", "text": "The four constraints (27)-(30) are necessary conditions for any JDP algorithm. Furthermore, the dataset $\\mathcal{D}^{1-}$ here is essentially the same as $\\mathcal{D}_{0}$ in the proof of Theorem 4.3; thus all analysis for $\\mathcal{D}_{0}$ can be borrowed. Consequently, following the same analysis for (26), we get a lower bound expressed by an inf problem: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\varepsilon,\\delta\\to\\infty}\\operatorname*{sup}_{\\mathcal{D}}\\left\\{\\mathsf{F}(x^{*}(\\mathcal{D}))-\\mathbb{E}_{\\mathcal{A}}\\left[\\mathsf{F}(x^{A}(\\mathcal{D}))\\right]\\right\\}\\geq\\frac{m}{2\\varepsilon}\\cdot\\operatorname*{inf}_{A\\ s.t.\\left(2^{\\gamma}\\right)\\cdot(30)}\\operatorname*{Pr}\\left[S_{-1}(x^{A}(\\mathcal{D}^{1-}))\\in[0,n\\gamma-\\frac{1}{\\varepsilon}]\\right]\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We believe analyzing the inf problem with tools in [BBG18], such as couplings, is promising. After this base case, one can easily extend the set of constraints (27)-(30) to take account of more loops. ", "page_idx": 22}, {"type": "text", "text": "C Additional results of numerical experiments ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "All experiments were run on a PC with an AMD 3700X CPU, 16GB memory; no GPU was used. The algorithm was implemented in Python 3.11, and optimization was solved by scipy.optimize.minimize method. Source code is available in supplementary materials. Datasets are publicly available as discussed in the main text. ", "page_idx": 22}, {"type": "text", "text": "C.1 Workforce scheduling ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "When running the algorithm, the only parameter different from Theorem 3.10 is $K:=1.1\\bar{u}/(\\gamma\\underline{{b}})$ , where Theorem 3.10 suggests $K:=2\\bar{u}/(\\gamma\\underline{{b}})$ . The constant factor is modified from 2 to 1.1, as a result of hyperparameter tuning. We discuss the tuning and its impact later. ", "page_idx": 22}, {"type": "text", "text": "We first report optimality gaps in Table 4. It is clear that our algorithm, equipped with either potential functions, always outperform the existing method. However, the performance of \u201c $\\mathcal{A}$ w. neg.entr\u201d seems independent of $\\varepsilon$ and the performance of [HHRW16] seems worse when $\\varepsilon$ increases, both of which are strange. The observations here are because the optimality gap itself does not reflect the whole picture, for example, constraint violations are not reflected. We thus report constraint violations in Table 5 below. It should be clear from Table 5 that constraint violations are reduced when $\\varepsilon$ increases, which indicates that our algorithm can maintain a good optimality performance while better reducing constraint violations. While [HHRW16] has the lowest constraint violations, our algorithms\u2019 constraint violations are only slightly worse. ", "page_idx": 22}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/e74bfec80ca012622b5093ebaebe6ee868f31ffea8833ecbdf00a6f75f795443.jpg", "table_caption": ["Table 4: Optimality gap $(\\mathsf{F}(\\pmb{x}^{*})-\\mathsf{F}(\\pmb{x}^{A}))/\\mathsf{F}(\\pmb{x}^{*})\\times100\\%$ . mean\u00b1sd "], "table_footnote": ["Notes. We run our algorithm $\\mathcal{A}$ Noisy Dual MD with two potential functions: negative entropy (abbr. ne) and squared $\\ell_{2}$ -norm function (abbr. $\\ell_{2}$ ). Settings are the same as in Figure 1. bold $\\equiv$ better "], "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/a44bdb27ac29538156017c4163dbdf22796bbcbdb10784bb75b4f394323e5afa.jpg", "table_caption": ["Table 5: Constraint violations, mean\u00b1sd. Settings are the same as in Figure 1 "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/d29ba11ff992d3ff10ba85570ef5e1d3bcd35e6e31e806d830d842c363c430c5.jpg", "table_caption": ["Runtime For this workforce scheduling problem, the runtime of our algorithm varies from potential function to potential function, see Table 6. ", "Table 6: Mean runtime (in seconds) per thousand iterations "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Impact of \u201cK_constant\u201d From our experiments, we found that the constant factor of $K$ significantly impacts algorithms\u2019 performance. To avoid confusion, we want to point out that the algorithm by [HHRW16] set K_constant to be 2, a fixed value. But for all results in Appendix here, we let their K_constant change as well, in order to gain more understandings of its impact. We find that, when the constant is close to 1, the final allocations are more likely to achieve a smaller optimality gap, but violate constraints more severely. On the other side, when the constant increases, the final allocations will violate fewer constraints, but end with a larger optimality gap. In other words, the constant of $K$ trade-offs between optimality and constraint violations. To see the trade-off more clearly, we draw Figure 3. The ${\\bf X}$ -axis represents the constant of $K$ , the left y-axis is optimality gap, and the right y-axis is total constraint violation; and for all curves, the lower the better. It is evident that when K_constant is small, we get smaller gaps but higher constraint violations. Additionally, when $\\varepsilon$ takes large values (say, $\\varepsilon=5,10)$ ), constraint violations of all algorithm are at almost the same levels, but our algorithms have better optimality performance. One may notice that when K_constant $^{=1}$ , the optimality gap is negative, which means $\\mathsf{F}(\\pmb{x}^{A})\\geq\\mathsf{F}(\\pmb{x}^{*})$ . Considering $x^{A}$ may violate some constraints, this phenomenon is possible. ", "page_idx": 23}, {"type": "image", "img_path": "6ArNmbMpKF/tmp/bbb3c4a4c103249083ca86e35134b1e5689e4bf5847e78190308c1fc897c7ab2.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 3: K_constant v.s. optimality & constraint violations. Settings are the same as in Figure 1 except K_constant. Shadow areas and error bars indicate $95\\%$ confidence interval. ", "page_idx": 24}, {"type": "text", "text": "C.2 Assignment Problems ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We repeat Table 3 below for discussion convenience. When reading the table, we should keep in mind that optimality gaps should be understood together with constraint violations. Some observations from the table are: ", "page_idx": 24}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/52de9cc36f698abdebc4513ebc15ac245ea4907ac5b1548484cfb0f87ffecce1.jpg", "table_caption": ["Table 7: Algorithm performance, mean $\\pm\\mathrm{sd}$ (this table is a copy of Table 3) "], "table_footnote": ["Notes. Algorithm parameters: $K=1.1\\bar{u}/(\\gamma\\underline{{{b}}}),\\delta=.01,T=10^{4}$ . Other settings follow Theorem 3.10. MD_l2 and MD_ne means potential function is squared $\\ell_{2}$ and negative entropy, respectively. For three cases $n\\,=\\,800$ , 1500, 3000, we set resource level $\\gamma\\,=\\,0.1$ , 0.05, 0.02, respectively. For all values in the table, the lower the better. Bold=better. "], "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "1. When $\\varepsilon$ is small $(\\varepsilon=1,2)$ ), while [HHRW16] achieves the lowest optimality gaps in most instances, it achieves them at severe constraint violations, which might be not acceptable in practice. In contrast, our algorithms have reasonably satisfying optimality performances and much smaller constraint violations.   \n2. When $\\varepsilon$ gradually grows, our algorithms have a clear pattern of convergence, i.e., smaller optimality gap and fewer constraint violations; but the pattern for [HHRW16] is not clear enough. We conjecture that this is because of high-variance noises injected.   \n3. If constraint violation matters, MD_ne is most preferred. ", "page_idx": 24}, {"type": "text", "text": "Runtime Runtimes are reported in Table 8. Compared to existing methods, our algorithms do not observe a significant increase in runtime. Moreover, as we set $T=10^{4}$ , we can in fact complete training within one hour, even for the largest case with $n=3000$ . ", "page_idx": 24}, {"type": "text", "text": "Dual convergence Figure 4 shows the progress of dual variables convergence. The y-axis is the gap between dual variables by our algorithms and the optimal dual variables, while $\\mathbf{X}$ -axis is the training progress. Shadow areas indicate standard deviations. It is evident that when $\\varepsilon$ is larger, dual variables converge faster to optimal values, and stay around the optimal values in remaining iterations. When $\\varepsilon$ is small, say $\\varepsilon=1$ , dual variables still show a converging tendency. Moreover, dual variables by MD_ne converge much faster, which further justifies its better performance observed earlier. ", "page_idx": 24}, {"type": "table", "img_path": "6ArNmbMpKF/tmp/e7659cef02542a2a3474e82b3428172e325701a78c2ca4f87664dc30a3bcc379.jpg", "table_caption": ["Table 8: Runtimes per thousand iterations, in seconds "], "table_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "6ArNmbMpKF/tmp/39f1fb64d7999d672911c38013198b7252962ddf54322d2cb26aad4015878ae1.jpg", "img_caption": ["Figure 4: (prefix averaging) dual variables converge. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: Theoretical results claimed in the abstract and introduction are summarized in Table 1, wherein cross-references are provided to point to specific theorems and sections. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We discussed limitations in Section 6 with a paragraph starting with Limitation of our work. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: For assumptions applied to most theorems in this paper, we give a summary in Assumption 2.5. For theorems needing more assumptions (or specific parameters), we clearly stated these assumptions. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: In the main text, we disclosed dataset source, hyperparameter values used for experiments, and algorithms. For the sake of limited space of the main text, we deferred more implementation details to Appendix C, such as PC specs, coding language, environments, and etc. Moreover, we also provide source code in supplementary material. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in ", "page_idx": 27}, {"type": "text", "text": "some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: Datasets used for experiments are publicly available. We pointed to these data website with proper hyperlinks and references in the main text, see Section Numerical experiments. Also, source code is released as part of supplementary material of this submission. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: In our case, experiment settings/details are mainly about algorithm hyperparameters. We clearly state them in captions of corresponding figures. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: In all figures and tables, indications of statistical significance, such as standard deviations and confidence intervals, are properly reported. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide computer resource information in Appendix C at the very beginning. Also, runtimes are reported for each experiment in Appendix C. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We have reviewed the NeurIPS Code of Ethics thoroughly. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This is a theory paper. It is hard to judge its societal impact. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: Not applicable, as our work is a theory paper. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Our work is a theory paper. And experiments do not need existing assets. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 30}, {"type": "text", "text": "\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Not applicable to our theory paper. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our work does not involve crowdsourcing nor human subjects. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our work does not involve crowdsourcing nor human subjects. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 31}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 32}]