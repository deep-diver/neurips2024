[{"figure_path": "Cx2O6Xz03H/tables/tables_4_1.jpg", "caption": "Table 1: We start with a baseline (Row 1) without using self-attention, temporal-attention, and cost-volume, and add each component from TAPTR in turn to show their impact on in-domain and out-of-domain datasets. The addition of self-attention and temporal attention leads to a significant improvement on both the in-domain and out-of-domain datasets. However, the addition of cost-volume only leads to a significant improvement on the out-of-domain dataset but a negative impact on the in-domain dataset, showing that the importance of cost-volume mainly comes from its ability to mitigate the domain gap. Note that the in-domain evaluation set is created by rendering additional 150 videos using the same setting as the training set.", "description": "This table presents an ablation study on the components of TAPTR (self-attention, temporal attention, and cost volume) to analyze their individual contributions to the model's performance on in-domain and out-of-domain datasets. It shows that self-attention and temporal attention significantly improve performance in both domains, while the cost volume's impact is more nuanced, improving out-of-domain results but negatively affecting in-domain performance, suggesting its primary role in domain generalization.", "section": "3.2 Analysis of Cost Volume Aggregation in TAPTR Decoder"}, {"figure_path": "Cx2O6Xz03H/tables/tables_6_1.jpg", "caption": "Table 2: Comparison of TAPTRv2 with prior methods. Note that, LocoTrack and BootsTAP\u2020 are concurrent works, and BootsTAP introduces extra 15M video clips for training.", "description": "This table compares the performance of TAPTRv2 against several state-of-the-art methods on three benchmark datasets: DAVIS, DAVIS-S, and Kinetics.  The metrics used for comparison are Average Jaccard (AJ), Average Precision at different thresholds (< \u03b4\u03b1\u03c5\u03b1), and Occlusion Accuracy (OA).  It highlights TAPTRv2's superior performance, particularly noting that BootsTAP+, a concurrent work, uses a significantly larger training dataset (15M extra video clips).", "section": "4 Experiments"}, {"figure_path": "Cx2O6Xz03H/tables/tables_7_1.jpg", "caption": "Table 3: Ablation on each key design of the attention-based position updating. \u201cPos.\u201d is short for \"Position\", and \"A. W.\" for \"Attention Weights.", "description": "This table presents the ablation study on the key designs of the attention-based position update. It shows the impact of using key-aware attention, position update, disentangling attention weights, and supervision on the performance (AJ, <binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>avg, OA). Each row represents a different combination of these design choices, allowing for an analysis of their individual contributions to the overall performance.", "section": "4.4 Ablation Studies and Analysis"}, {"figure_path": "Cx2O6Xz03H/tables/tables_8_1.jpg", "caption": "Table 3: Ablation on each key design of the attention-based position updating. \u201cPos.\u201d is short for \"Position\", and \"A. W.\" for \"Attention Weights.", "description": "This table presents the ablation study results on the key designs of the attention-based position update mechanism in TAPTRv2. It shows the impact of key-aware attention, position update, disentangled attention weights, and supervision on the model's performance. Each row represents a different configuration, indicating whether a specific design element was included or excluded. The results are measured in terms of Average Jaccard (AJ), average precision at different thresholds (< \u03b4xavg), and Occlusion Accuracy (OA), demonstrating the contribution of each component to the overall performance improvement.", "section": "4.4 Ablation Studies and Analysis"}, {"figure_path": "Cx2O6Xz03H/tables/tables_13_1.jpg", "caption": "Table 5: Comparison of resource requirements between TAPTR and TAPTRv2. We evaluate TAPTR and TAPTRv2 on A100 GPU (80G), and the computational cost (GFLOPS) is calculated following detectron2.", "description": "This table presents a comparison of the computational resource requirements between TAPTR and TAPTRv2.  The comparison is made for two scenarios: tracking 800 points and tracking 5000 points.  The metrics shown are frames per second (FPS), GFLOPS (floating-point operations per second), and the number of parameters (#Param) used by each model. The results demonstrate the improved efficiency of TAPTRv2, especially when tracking a large number of points.", "section": "4.4 Ablation Studies and Analysis"}]