[{"figure_path": "H3at5y8VFW/figures/figures_1_1.jpg", "caption": "Figure 1: The Self-Retrieval framework consists of three key components: (1) corpus indexing through self-supervised learning, (2) passage generation via constrained decoding, (3) passage ranking using self-assessment scoring.", "description": "This figure illustrates the Self-Retrieval framework, which is an end-to-end information retrieval architecture.  It consists of three main stages: indexing, retrieval, and reranking.  The indexing stage uses self-supervised learning to embed the corpus into the LLM. The retrieval stage uses constrained decoding to generate relevant passages from the corpus based on a given query. The reranking stage uses self-assessment scoring to evaluate the relevance of the retrieved passages, allowing for more precise ranking. The figure visually represents the flow of data through each component.", "section": "3 Self-Retrieval"}, {"figure_path": "H3at5y8VFW/figures/figures_8_1.jpg", "caption": "Figure 2: Impact of model capacity on Self-Retrieval performance.", "description": "This figure shows the performance of Self-Retrieval using different sizes of language models (StableLM, Llama2, and Qwen-1.5) on the NQ dataset.  The x-axis represents the number of parameters in the model, while the y-axis shows the Hits@1 and Hits@5 metrics.  It demonstrates that larger models generally lead to improved performance in Self-Retrieval, showcasing the scaling benefits of the architecture.", "section": "4.4 Detailed Analysis"}, {"figure_path": "H3at5y8VFW/figures/figures_8_2.jpg", "caption": "Figure 3: Reranking performance comparison when processing top-100 passages.", "description": "This figure compares the reranking performance of three methods: the original retriever's ranking, the ranking after applying the BGE-reranker, and the ranking produced by Self-Retrieval.  The x-axis shows the different retriever models used (DPR-FT, SEAL, and GritLM). The y-axis represents the MRR@5 (Mean Reciprocal Rank at 5) score, indicating the effectiveness of reranking.  The chart visually demonstrates the improvement in ranking achieved by both the BGE-reranker and, more significantly, by Self-Retrieval, across all three retriever models.", "section": "4.2 Main Results"}, {"figure_path": "H3at5y8VFW/figures/figures_8_3.jpg", "caption": "Figure 4: Scalability analysis of retrieval performance for Self-Retrieval and BGE-FT across varying corpus sizes.", "description": "This figure shows the scalability of Self-Retrieval and BGE-FT (a strong baseline) on two different datasets (NQ and TriviaQA) as the number of documents increases from 10k to 200k.  It demonstrates how the retrieval performance (Hits@1 and Hits@5) changes with increasing corpus size for both models. The results indicate the robustness of Self-Retrieval even when dealing with significantly larger corpora.", "section": "4.4 Detailed Analysis"}]