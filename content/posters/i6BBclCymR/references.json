{"references": [{"fullname_first_author": "B. Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces NeRF, a foundational work in novel view synthesis that uses neural networks to represent 3D scenes as continuous radiance fields, forming the basis for many subsequent improvements."}, {"fullname_first_author": "B. Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces 3D Gaussian Splatting, a significant advancement in view synthesis that combines the speed of explicit 3D representations with the realism of implicit methods."}, {"fullname_first_author": "M. Niemeyer", "paper_title": "Regnerf: Regularizing neural radiance fields for view synthesis from sparse inputs", "publication_date": "2022-00-00", "reason": "This paper addresses the challenge of novel view synthesis from sparse views by introducing regularization techniques to improve the stability and quality of the results."}, {"fullname_first_author": "J. Yang", "paper_title": "Freenerf: Improving few-shot neural rendering with free frequency regularization", "publication_date": "2023-00-00", "reason": "This paper introduces FreeNeRF, which further enhances sparse view synthesis by using free frequency regularization to prevent overfitting and improve generalization."}, {"fullname_first_author": "J. Li", "paper_title": "DNGaussian: Optimizing sparse-view 3D Gaussian radiance fields with global-local depth normalization", "publication_date": "2024-00-00", "reason": "This paper presents DNGaussian, which improves upon 3D Gaussian Splatting by adding depth regularization to further enhance performance in sparse-view scenarios."}]}