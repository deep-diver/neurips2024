[{"type": "text", "text": "Cross-Modality Perturbation Synergy Attack for Person Re-identification ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yunpeng Gong1, Zhun Zhong2, Yansong ${\\boldsymbol{\\mathrm{Qu}}}^{1}$ , Zhiming Luo1, Rongrong $\\mathrm{{Ji^{1}}}$ , and Min Jiang\\* ", "page_idx": 0}, {"type": "text", "text": "1School of Informatics, Xiamen University 2School of Computer Science and Information Engineering, Hefei University of Technology ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In recent years, there has been significant research focusing on addressing security concerns in single-modal person re-identification (ReID) systems that are based on RGB images. However, the safety of cross-modality scenarios, which are more commonly encountered in practical applications involving images captured by infrared cameras, has not received adequate attention. The main challenge in cross-modality ReID lies in effectively dealing with visual differences between different modalities. For instance, infrared images are typically grayscale, unlike visible images that contain color information. Existing attack methods have primarily focused on the characteristics of the visible image modality, overlooking the features of other modalities and the variations in data distribution among different modalities. This oversight can potentially undermine the effectiveness of these methods in image retrieval across diverse modalities. This study represents the first exploration into the security of cross-modality ReID models and proposes a universal perturbation attack specifically designed for cross-modality ReID. This attack optimizes perturbations by leveraging gradients from diverse modality data, thereby disrupting the discriminator and reinforcing the differences between modalities. We conducted experiments on three widely used cross-modality datasets, namely RegDB, SYSU, and LLCM. The results not only demonstrate the effectiveness of our method but also provide insights for future improvements in the robustness of cross-modality ReID systems. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "With the rapid advancement of surveillance technology, person re-identification (ReID) [1\u20134] has emerged as a pivotal component in the realm of security, garnering escalating attention. ReID constitutes a fundamental task in computer vision [5, 6], aiming to precisely identify the same individual across diverse locations and time points by analyzing pedestrian images captured through surveillance cameras [7]. The challenges inherent in this task encompass factors such as changes in viewpoint, lighting conditions [8, 9], occlusion [10, 11], and pose variations, culminating in significant appearance variations of the same individual across distinct camera views [12]. ", "page_idx": 0}, {"type": "text", "text": "In traditional ReID, where samples are image-based, the conventional methodology centers on matching visible to visible (RGB to RGB) data. However, when dealing with diverse scenarios and conditions, especially involving multiple image modalities such as RGB and infrared images, the system needs to intricately handle the differences in images from different modalities [15\u201317]. This is essential to ensure that the system exhibits better robustness across different modalities. Hence, cross-modality ReID is considered more challenging due to the need for addressing these modality differences [18, 19]. ", "page_idx": 0}, {"type": "image", "img_path": "LONd7ACEjy/tmp/b482a781ec9b692e675054ddea59f5923cc49bafab4a723b01af5d3652adac95.jpg", "img_caption": ["Figure 1: Comparison between traditional and proposed methods: Fig.(a) illustrates traditional attack methods (e.g., FGSM [13], PGD [14]), which are primarily designed for single-modal tasks and lack mechanisms to associate multiple modalities, making them ineffective in simultaneously misleading retrieval results across different modalities. Fig.(b) illustrates the proposed method, which employs an intrinsic mechanism to effectively associate different modalities, thereby misleading retrieval results across multiple modalities simultaneously. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Cross-modal ReID [20, 21, 18, 22] plays a crucial role in significantly expanding the applicability of traditional ReID methods, focusing on addressing complex matching issues between different image modalities. In practical surveillance systems, the simultaneous use of multiple sensors, such as RGB cameras and infrared cameras, is a common scenario. This task requires innovative solutions to effectively bridge the differences between various modalities, ensuring robust and accurate reidentification of pedestrians in heterogeneous sensor outputs. ", "page_idx": 1}, {"type": "text", "text": "Currently, most research on the security of ReID focuses on single-modality systems based on RGB images [23\u201328], while the security of cross-modality ReID systems has received insufficient attention. The challenge in cross-modality attacks arises from significant visual differences among different modality inputs, requiring attackers to effectively capture shared features from each modality for perturbation implementation. However, as shown in Fig. 1, existing attack methods in crossmodal scenarios require optimizing perturbations separately for each modality, lacking an intrinsic mechanism to capture shared knowledge between different modalities, which limits the success rate of the attacks. To address this issue, we propose a synergistic optimization method combined with triplet loss, utilizing information from different modalities to optimize the universal perturbation. This method pushes the features of different samples into a common sub-region that affects the model\u2019s accuracy, as shown in Fig. 2. ", "page_idx": 1}, {"type": "text", "text": "Specifically, we propose the Cross-Modality Perturbation Synergy (CMPS) method, a universal perturbation approach designed specifically for cross-modality ReID systems. This method simultaneously leverages gradient information from multiple modalities to jointly optimize universal perturbations across visible and infrared images. CMPS incorporates cross-modality triplet loss to ensure feature consistency across different modalities, enhancing the generality of the perturbation. During the synergistic optimization process, CMPS iteratively updates gradients from various modalities within a unified optimization framework, effectively capturing and utilizing shared features across modalities. To further reduce visual differences between modalities, we introduce cross-modality attack augmentation, converting images into grayscale to standardize their visual representation and facilitate the learning of modality-agnostic perturbations. As a result, these universal perturbations push the features of different samples toward a common region in the feature space, significantly diminishing the model\u2019s ability to accurately distinguish identities in cross-modality scenarios, thereby successfully deceiving the model. ", "page_idx": 1}, {"type": "image", "img_path": "LONd7ACEjy/tmp/27e81524bf1a48eeafcb6bd77795cf342a31dfca8ec5f494329d46190dec1e5f.jpg", "img_caption": ["Figure 2: Illustration of the CMPS attack framework. We generate homogeneous grayscale images through random grayscale transformations to reduce the differences between modalities, aiding in the learning of a universal perturbation. The process is as follows: first, the gradient from one modality is used to optimize the universal perturbation, which is then applied to another modality\u2019s images to generate adversarial samples for attacks. The new modality\u2019s gradient is then used to further optimize the perturbation and attack the next modality. By aggregating feature gradients from different modalities, we iteratively learn a universal perturbation, pushing samples toward a common region in the manifold. The manifold is represented as a sphere, with identical shapes but different colors representing the same person\u2019s features across modalities. This method captures shared knowledge between modalities, enabling more effective learning of cross-modal universal perturbations. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "In our experiments on widely utilized cross-modality ReID datasets, including RegDB [29], SYSU [30] and LLCM [21], we not only showcase the effectiveness of our proposed method but also provide insights for fortifying the robustness of cross-modality ReID systems in the future. This research contributes by bridging gaps in current studies and introducing novel perspectives to study the security challenges in cross-modality ReID systems. ", "page_idx": 2}, {"type": "text", "text": "The main contributions of our work can be summarized as: ", "page_idx": 2}, {"type": "text", "text": "\u2022 To the best of our knowledge, our work is the first to investigate vulnerabilities in cross-modality ReID models. By explicitly incorporating cross-modality constraints into the synergistic optimization process, we enhance the universality of the learned cross-modality perturbations. Additionally, we provide mathematical analysis to demonstrate the superiority of our proposed method over traditional approaches. ", "page_idx": 2}, {"type": "text", "text": "\u2022 We propose a cross-modality attack augmentation method, utilizing random grayscale transformations to narrow the gap between different modalities, aiding our cross-modality perturbation synergy attack in better capturing shared features across modalities. ", "page_idx": 2}, {"type": "text", "text": "\u2022 Extensive experiments conducted on three widely used cross-modality ReID benchmarks demonstrate the effectiveness of our proposed cross-modality attack. Our method exhibits good transferability even when attacking different models. The code will be available at https://github.com/ finger-monkey/cmps__attack. ", "page_idx": 2}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Adversarial Attack. Adversarial attacks are a technique involving the clever design of small input perturbations with the aim of deceiving machine learning models, leading them to produce misleading outputs. This form of attack is not confined to the image domain but extends to models in various fields, including speech [31] and text [32\u201334]. Typically, the goal of adversarial attacks is to tweak input data in a way that causes the model to make erroneous predictions when handling these subtly modified samples [13, 35\u201337]. In the early stages of research, adversarial attacks had to be customized for each specific sample. However, with the evolution of related studies, universal perturbation [38] attacks were introduced, aiming to find perturbations effective across multiple samples rather than tailored to individual instances. Research on universal perturbation attacks seeks to expose vulnerabilities in models, prompting designers to enhance their robustness to withstand a broader range of adversarial challenges. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Adversarial Attacks in ReID. Some ReID attack methods have been proposed, with current research predominantly focusing on RGB-RGB matching. These methods mainly include: Metric-FGSM [26] extends some techniques, inspired by classification attacks, into a category known as metric attacks. These encompass Fast Gradient Sign Method (FGSM) [13], Iterative FGSM (IFGSM), and Momentum IFGSM (MIFGSM) [39]. The Furthest-Negative Attack (FNA) [27] integrates hard sample mining [40] and triple loss to employ pushing and pulling guides. These guides guide image features towards the least similar cluster while moving away from other similar features. Deep Mis-Ranking (DMR) [28] utilizes a multi-stage network architecture to pyramidally extract features at different levels, aiming to derive general and transferable features for adversarial perturbations. Gong et al. [25] proposed a local transformation attack (LTA) method specifically aimed at attacking color features without requiring additional reference images, and discussed effective defense strategies against current ReID attacks. The Opposite-direction Feature Attack (ODFA) [23] exploits featurelevel adversarial gradients to generate examples that guide features in the opposite direction with an artificial guide. Yang et al. [24] introduced a combined attack named $\\mathrm{Col.+Del.}$ ., which integrates UAP-Retrieval [41] with color space perturbations [42]. While this method also explores universal perturbations in ReID, its generality is limited due to the inability to leverage color information in cross-modality problems and the lack of a mechanism for associating different modality information. In contrast to the aforementioned approaches, our focus lies on addressing cross-modality challenges. ", "page_idx": 3}, {"type": "text", "text": "Algorithm 1 Procedure of CMPS attack ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "1: Input: Visible images $I_{R G B}$ and infrared (or thermal) images $I_{i r}$ from dataset $S$ , cross-modality   \nReID model $f$ trained on $S$ , adversarial bound $\\epsilon$ , momentum value $\\theta$ , iteration step size $\\alpha$ ,   \niteration epoch iter_epoch.   \n2: Output: Cross-modality universal perturbation $\\eta$ .   \n3: Initialize $\\eta$ with random noise $\\eta\\leftarrow R a n d(0,1)$ , $\\Delta^{0}=0$ .   \n4: for $i$ in iter_epoch do   \n5: repeat   \n6: Sample a mini-batch of visible images $I_{R G B}$ and infrared (or thermal) images $I_{i r}$ with $n$   \nsamples   \n7: I\u02c6RGB \u2190IRGB + \u03b7   \n8: Use infrared images to compute the triplet loss $L_{R G B}$ for visible images (Eq. 4)   \n9: Compute gradient $\\Delta_{R G B}$ of $L_{R G B}$ w.r.t. $\\eta$ :   \n10: $\\begin{array}{r}{\\Delta_{R G B}\\leftarrow\\theta\\cdot\\Delta^{i-1}+\\frac{\\partial L_{R G B}}{\\partial\\eta}}\\end{array}$   \n11: Update perturbation $\\eta$ :   \n12: $\\begin{array}{r l}&{\\dot{\\eta}\\Bigl\\{-\\cosh(\\eta+\\alpha\\cdot\\mathrm{sign}(\\Delta_{R G B}),-\\epsilon,\\epsilon)}\\\\ &{\\dot{I}_{i r}\\gets I_{i r}+\\eta}\\end{array}$   \n13:   \n14: Use visible images to compute the triplet loss $L_{i r}$ for infrared images (Eq. 7)   \n15: Compute gradient $\\Delta_{i r}$ of $L_{i r}$ w.r.t. $\\eta$ :   \n16: $\\begin{array}{r}{\\Delta^{i}\\leftarrow\\theta\\cdot\\Delta_{R G B}+\\frac{\\partial L_{i r}}{\\partial\\eta}}\\end{array}$   \n17: Update perturbation $\\eta$ :   \n18: $\\eta\\leftarrow\\mathrm{clip}(\\eta+\\alpha\\cdot\\mathrm{sign}(\\Delta^{i}),-\\epsilon,\\epsilon)$   \n19: until all mini-batches are processed   \n20: end for   \n21: return $\\eta$ ", "page_idx": 3}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we introduce a universal perturbation designed for cross-modality attacks, referred to as the Cross-Modality Perturbation Synergy (CMPS) attack. Considering the significant differences between different modalities, we propose a attack augmentation method to bridge the gap between modalities, aiding in enhancing the perturbation\u2019s universality across different modalities. Our objective in addressing this problem is to find a universal adversarial perturbation, denoted as $\\eta$ , capable of misleading the retrieval ranking results of cross-modality ReID models. The adversarial operation involves adding $\\eta$ to a query image $I$ . The perturbed query image, denoted as $I_{a d v}=I+\\eta$ , is then used to retrieve from the gallery and deceive the cross-modality ReID model $f$ . The algorithm is summarized in Alg. 1. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "3.1 Overall Framework ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In Fig. 2, we illustrate the overall framework of the proposed CMPS attack. During the training phase, we optimize $\\eta$ using our cross-modality attack augmentation method, which leverages images from different modalities to bridge their inherent differences and enhance cross-modality universality. In the attack phase, the optimized $\\eta$ deceives reID models, leading to inaccurate ranking lists. Section 3.2 outlines the framework and overall optimization objective, providing a macro-level overview. Section 3.4 delves into the specific process of perturbation optimization across different modalities. ", "page_idx": 4}, {"type": "text", "text": "3.2 Optimizing Loss Functions for Attacking ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our study aims to deceive cross-modality ReID models using a universal perturbation. We have specifically designed a triplet loss tailored for our proposed attack method, which can correlate different modalities and influence the distance relationships between images from different modalities. ", "page_idx": 4}, {"type": "text", "text": "We follow the approach of [41] to optimize the perturbation using cluster centroids. This method directly impacts the similarity between pedestrian identities in the ReID model\u2019s feature space (rather than the similarity between individual samples), making it more effective. Subsequently, leveraging the acquired cluster centroids, we apply our triplet loss to distort the pairwise relations between pedestrian identities. This process can be represented as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L=\\operatorname*{max}\\left[\\left(\\|C_{g}^{n}-f_{R G B}^{a d v}\\|_{2}-\\|C_{i r}^{p}-f_{R G B}^{a d v}\\|_{2}+\\rho\\right),0\\right]}\\\\ &{\\ \\ +\\operatorname*{max}\\left[\\left(\\|C_{i r}^{n}-f_{g}^{a d v}\\|_{2}-\\|C_{R G B}^{p}-f_{g}^{a d v}\\|_{2}+\\rho\\right),0\\right]}\\\\ &{\\ \\ +\\operatorname*{max}\\left[\\left(\\|C_{R G B}^{n}-f_{i r}^{a d v}\\|_{2}-\\|C_{g}^{p}-f_{i r}^{a d v}\\|_{2}+\\rho\\right),0\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As shown in Fig. 3, the loss function mentioned above fully leverages the triplet-wise relationships across different modality. Through this loss, we are able to pull the negative samples of each modality closer to the adversarial samples and push the positive samples of each modality away from the adversarial samples. Here, $C_{R G B}^{\\bar{p}}$ and $C_{R G B}^{n}$ represent the cluster centroids of the positive samples to push and negative samples to pull, respectively, in the original visible (RGB) image feature space of the training data. Similar definitions apply to other modalities. f RadGvB, f gad , and $f_{i r}^{a d v}$ denote the perturbed features of the disturbed image in the visible, grayscale, and infrared (or thermal) modalities, respectively. ", "page_idx": 4}, {"type": "text", "text": "3.3 Cross-Modality Attack Augmentation Method ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Intuitively, as illustrated in Fig. 4, maximizing the overlap of common factors across different modalities facilitates the capture of shared features by the learned perturbation. Grayscale images, being inherently homogeneous, serve as effective mediators between diverse modalities. Consequently, we introduce random grayscale transformations into adversarial attack methods, referred to as CrossModality Attack Augmentation. This approach guides cross-modality perturbations by leveraging homogeneous grayscale images sourced from diverse modalities. The primary objective is to explore the underlying structural relationships across heterogeneous modalities. ", "page_idx": 4}, {"type": "text", "text": "The process of grayscale transformation can be represented as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nt(R,G,B)=0.299R+0.587G+0.114B,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The function $\\mathrm{t}(\\cdot)$ represents the grayscale transformation using ITU-R BT.601-7 standard weights, combining the RGB channels of each pixel into a single grayscale channel. From this, we construct a 3-channel grayscale image $x_{g}$ by replicating the grayscale channel: ", "page_idx": 4}, {"type": "equation", "text": "$$\nx_{g}=[t(R,G,B),t(R,G,B),t(R,G,B)].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "image", "img_path": "LONd7ACEjy/tmp/1680c3c8d8f1174ed917029a5549400cc8fab94bd75c0e949416e7c915e495b9.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 3: Schematic illustration of triplet Figure 4: Cross-modality attack augmentation: relationship-guided universal perturbation bridging gap between visible and non-visible learning for cross-modality ReID. (infrared) modalities with grayscale. ", "page_idx": 5}, {"type": "text", "text": "3.4 Cross-Modality Perturbation Synergy Attack ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To synergistically utilize gradient information from diverse modalities for perturbation optimization, narrow the gap between different modalities to better capture shared knowledge, we adopt the following training process to generate a universal perturbation: ", "page_idx": 5}, {"type": "text", "text": "(1) Learning the visible modality. For a given batch of visible images with $n$ samples, we extract and perturb their features using the cross-modality ReID model. We update the temporary perturbation $\\eta$ iteratively using Momentum-Inertia Stochastic Gradient Descent (MI-SGD), expressed as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{R G B}(f_{R G B}^{a d v},\\eta)=\\operatorname*{max}\\left[(\\|C_{g}^{n}-f_{R G B}^{a d v}\\|_{2}}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ -\\ \\|C_{i r}^{p}-f_{R G B}^{a d v}\\|_{2}+\\rho)\\,,0\\right],}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\Delta_{R G B}=\\theta\\Delta_{i r}^{\\prime}+\\frac{\\nabla_{\\eta}L_{R G B}}{\\|\\nabla_{\\eta}L_{R G B}\\|_{1}},}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\eta=\\mathrm{clip}(\\eta+\\alpha\\cdot\\mathrm{sign}(\\Delta_{R G B}),-\\varepsilon,\\varepsilon).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, $\\theta$ represents the momentum value (set as $\\theta=1$ ), and $\\Delta_{i r}^{\\prime}$ is derived from the previous iteration. The iteration step size is denoted by $\\alpha$ (set as $\\alpha={\\frac{\\epsilon}{12}}$ ), where $\\epsilon$ is the adversarial bound $\\epsilon=8$ , unless otherwise specified). We set the margin $\\rho=0.5$ in our triplet loss. ", "page_idx": 5}, {"type": "text", "text": "(2) Learning the grayscale modality. This part is executed through data augmentation. It is not considered as a separate module and is therefore not explicitly listed in Alg. 1. Specifically, during the perturbation learning process, we randomly transform visible or infrared (or thermal) images into homogeneous grayscale images, participating in the iterative optimization of adversarial perturbations. It is employed to bridge the gap between different modalities, thereby improving the universality of the perturbation across diverse modalities. In order to investigate the impact of different grayscale conversion probabilities on attack performance, we conducted a series of ablation experiments. For details, please refer to Fig. 5 in supplementary material. ", "page_idx": 5}, {"type": "text", "text": "(3) Learning the infrared (or thermal) modality. This step is similar to (1). We utilize the infrared (or thermal) images to learn the perturbation $\\eta$ with the our loss functions: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{i r}(f_{i r}^{a d v},\\eta)=\\operatorname*{max}\\left[\\left(\\|C_{R G B}^{n}-f_{i r}^{a d v}\\|_{2}\\right.\\right.}\\\\ &{\\left.\\left.~~~~~~~~~~~~~-\\|C_{g}^{p}-f_{i r}^{a d v}\\|_{2}+\\rho\\right),0\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Delta_{i r}=\\theta\\Delta_{R G B}+\\frac{\\nabla_{\\eta}L_{i r}}{\\|\\nabla_{\\eta}L_{i r}\\|_{1}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, $\\Delta_{R G B}$ derived from step (1). The main difference compared to the previous step lies in the perturbation applied to the input and the gradients related to momentum. ", "page_idx": 6}, {"type": "text", "text": "Theoretical Analysis. In traditional optimization, optimizing for one modality can render the perturbation suboptimal for the other, leading to a bias toward a single modality. In contrast, the proposed aggregated optimization method jointly optimizes both modalities, ultimately identifying a universal perturbation that enhances cross-modality attack performance. In the supplementary material 7, we provide a mathematical analysis demonstrating the effectiveness of this method compared to traditional attack methods that lack intrinsic correlations between different modalities. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we compare our approach with several methods, including traditional classification attack methods FGSM [13] and PGD [14], traditional metric attack methods like Metric-FGSM [26], as well as state-of-the-art ReID attack methods such as LTA [25] \\*, ODFA[23] and Col. $^+$ Del.[24]. ", "page_idx": 6}, {"type": "text", "text": "Datasets. We evaluate our proposed method on two commonly used cross-modality ReID datasets: SYSU-MM01 [30], RegDB [29] and LLCM [21]. SYSU-MM01 is a large-scale dataset with 395 training identities, captured by 6 cameras (4 RGB, 2 near-infrared) on the SYSU campus. It comprises 22,258 visible and 11,909 near-infrared images. The testing set consists of 95 identities with two evaluation settings. The query sets include 3803 images from two IR cameras. We conduct ten trials following established methods [43] and report the average retrieval performance. Please refer to [30] for the evaluation protocol. RegDB [29] is a smaller-scale dataset with 412 identities, each having ten visible and ten thermal images. we randomly select 206 identities (2,060 images) for training and use the remaining 206 identities (2,060 images) for testing. LLCM is a dataset designed specifically for cross-modality ReID in low-light environments. Compared to other datasets, its diverse scenarios and low-light conditions present greater challenges for attackers. This complexity and uncertainty make adversarial attacks more difficult to execute. We assess our model in two retrieval scenarios: visible-thermal and thermal-visible performance. ", "page_idx": 6}, {"type": "text", "text": "Evaluation Metrics. Following existing works [44], we employ Rank-k precision and Cumulative Matching Characteristics (CMC) and mean Average Precision (mAP) as evaluation metrics. Rank-1 represents the average accuracy of the top-ranked result corresponding to each cross-modality query image. mAP represents the mean average accuracy, where the query results are sorted based on similarity, and the closer the correct result is to the top of the list, the higher the precision. Please note that, for adversarial attacks, a lower accuracy indicates a more successful attack. ", "page_idx": 6}, {"type": "text", "text": "4.1 Performance on Cross-Modality ReID ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We used AGW [18] and DDAG [22] as baseline models for testing on the RegDB and SYSU cross-modality ReID datasets. AGW (Attention Generalized mean pooling with Weighted triplet loss) enhances the learning capability of crucial features by integrating non-local attention blocks, learnable GeM pooling, and weighted regularization triplet loss. DDAG (Dynamic Dual-Attentive Aggregation) improves feature learning by combining intra-modality weighted-part attention and cross-modality graph structured attention, considering both part-level and cross-modal contextual cues. Additionally, we use DEEN [21] (Diverse Embedding Expansion Network) as baseline models for testing on the LLCM [21] cross-modality ReID datasets. The core idea of DEEN is to enhance the feature representation capability by introducing a diversity embedding mechanism. The network expands the embedding space, allowing features from visible and infrared images to align better in a high-dimensional space, thereby improving the accuracy of cross-modality matching. ", "page_idx": 6}, {"type": "text", "text": "The experiments encompass two scenarios: 1) Perturbing visible images (query) to disrupt the retrieval of infrared or thermal non-visible images (gallery). This is denoted as \"Visible to Infrared\" in Tab.1 and \"Visible to Thermal\" in Tab.2. 2) Perturbing infrared or thermal non-visible images (query) to interfere with the retrieval of visible images (gallery). This is indicated as \"Infrared to Visible\" in Tab.1 and \"Thermal to Visible\" in Tab.2. ", "page_idx": 6}, {"type": "table", "img_path": "LONd7ACEjy/tmp/e3be4429ba8fdec704b0351f7e2f36e95b41b1653a65b6015bba7d94d3c1ed74.jpg", "table_caption": ["Table 1: Results for attacking cross-modality ReID systems on the SYSU [30] dataset. It reports on visible images querying infrared images and vice versa. Rank at $r$ accuracy $(\\%)$ and mAP $(\\%)$ are reported. For the \"Visible to Infrared\" scenario, we used the all-search mode. For the \"Infrared to Visible\" scenario, we used the indoor-search mode. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "LONd7ACEjy/tmp/e7d58d6538eb695ecd1dcd146430a4275718d882d81f6bac38b72fe5b750d6c8.jpg", "table_caption": ["Table 2: Results for attacking cross-modality ReID systems on the RegDB [29] dataset. It reports on visible images querying thermal images and vice versa. Rank at $r$ accuracy $(\\%)$ and mAP $(\\%)$ are reported. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "From Tab.1, it can be seen that the proposed method reduces the rank-1 accuracy to below $2\\%$ in both the \u2019Visible to Infrared\u2019 and \u2019Infrared to Visible\u2019 cases. Similarly, from Tab.2, the rank-1 accuracy drops below $3\\%$ in both the \u2019Visible to Thermal\u2019 and \u2019Thermal to Visible\u2019 scenarios. In contrast, traditional metric-based attacks, such as Metric-FGSM (M-FGSM)[26], LTA [25] and ODFA[23], lead to attacked models with significantly higher rank-1 accuracy, whereas traditional classification attacks (such as FGSM [13] and PGD [14]) perform even worse, with rank-1 accuracy remaining over $60\\%$ . This is because ReID relies on metric learning for feature matching rather than category classification, requiring attacks specifically tailored for metric learning. These results indicate that, compared to traditional methods that optimize perturbations separately for each modality without considering the inherent correlations between different modalities, our proposed approach demonstrates significant attacking effectiveness across different modalities. ", "page_idx": 7}, {"type": "text", "text": "Comparison with State-of-the-Art. Col. $+\\mathrm{Del}.$ ., as a universal perturbation method, was fairly compared by first optimizing with one modality\u2019s dataset and then fine-tuning with the other modality. Since universal perturbations capture shared patterns across the entire data distribution, $\\mathrm{Col.+Del}$ . is capable of achieving some level of attack effectiveness in cross-modality scenarios. However, by comparing Tab.1, Tab.2, and Tab.3, we observe that although $\\mathrm{Col.+Del}$ . performs better than other methods, its effectiveness is still noticeably limited due to the lack of intrinsic correlation mechanisms between modalities. Moreover, as shown in Fig.6, our method outperforms $\\mathrm{Col.+Del}$ . in transfer attacks across different baselines in cross-modality ReID. The conclusions from these experiments are as follows: 1) In cross-modality attacks, $\\mathrm{Col.+Del}$ . demonstrates the feasibility of universal perturbations. However, its performance is limited by its failure to account for modality differences and inherent correlations. 2) Our method better bridges the gap between different modalities, more effectively capturing shared features across them. ", "page_idx": 7}, {"type": "table", "img_path": "LONd7ACEjy/tmp/56812abe49651750f88cfc44f417ddac49513c97bd905a30d9b07cc1f84d3c52.jpg", "table_caption": ["Table 3: Results for attacking cross-modality ReID systems on the LLCM [21] dataset. It reports on visible images querying thermal images and vice versa. Rank at $r$ accuracy $(\\%)$ and mAP $(\\%)$ are reported. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.2 Transferability of CMPS ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "From Fig.6 in supplemental material, the results of the proposed method\u2019s transfer attacks on two baseline models, AGW and DDAG, can be observed. For example, on the SYSU dataset, the original attack result of the proposed method on DDAG is $\\mathrm{mAP=}1.84\\%$ (refer to Tab. 1). When the perturbation is transferred from AGW to DDAG, the attack result becomes $\\scriptstyle\\mathrm{mAP}=3.41\\%$ . This indicates that the proposed attack method exhibits good generalization across different models, and thus, the attack performance does not degrade significantly. This consistent result is observed on both the RegDB and SYSU datasets. Similarly, in Fig.7 of the supplemental material, we evaluate the cross-dataset transferability of perturbations in comparison with Col. $+\\mathrm{Del}$ . The results demonstrate a significant advantage of our method. Additionally, we conducted adversarial transferability experiments on IDE [45], PCB [46], and ResNet18 [47]. The rank-1 transfer attack success rates are presented in Tab.4. It can be observed that our method consistently achieves higher transfer attack success rates across all model combinations compared to $\\mathrm{Col.+Del.}$ ., indicating that our method demonstrates stronger robustness in generating more universal adversarial perturbations. ", "page_idx": 8}, {"type": "table", "img_path": "LONd7ACEjy/tmp/b10ec1bd4fd62035144b7cc7a72c1d53924fd1076a53b93a1aade483a4aaf6a0.jpg", "table_caption": ["Table 4: Comparison of transfer attack success rates between our method and $\\mathrm{Col.+Del}$ . across models, with higher values indicating better transferability. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.3 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Our method is implemented based on UAP-Retrieval [41]. To validate the effectiveness of the proposed method, we conducted experiments by adding augmentation (Cross-Modality Attack Augmentation) and CMPS to the baseline. Results with AGW baseline model are reported in Tab. 5. The No.1 line represents the UAP-Retrieval algorithm. In the table, \u2019Aug\u2019 indicates the use of the Cross-Modality Attack Augmentation proposed in this paper. ", "page_idx": 8}, {"type": "text", "text": "The effectiveness of CMPS. Comparing No.1 with No.3 and No.4, we observe the following: 1) The direct use of UAP-Retrievals yields limited performance. 2) Training with the CMPS strategy proposed in this paper consistently improves the performance of attack results and the universality of learned perturbations. ", "page_idx": 8}, {"type": "table", "img_path": "LONd7ACEjy/tmp/0c764a8d8ddfae4ada273ce6ad7a89ed1eb008b670e15d5b4edb452c90375c63.jpg", "table_caption": ["Table 5: Ablation studies on the AGW baseline. \u2019Aug\u2019 denotes the cross-modality attack augmentation method proposed in this paper. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "The effectiveness of augmentation method. Our approach includes cross-modality attack augmentation. Comparing results of No.1, No.2, and No.4 shows its benefits. For example, on the RegDB dataset, augmentation (No.2) reduces mAP from $6.87\\%$ to $5.11\\%$ , $1.76\\%$ lower than without augmentation $(\\mathrm{No.1})$ . Similarly, with CMPS, mAP drops from $3.98\\%$ to $3.46\\%$ (No.4), a $0.52\\%$ decrease compared to No.3. These findings suggest that using appropriate augmentation enhances cross-modality ReID adversarial attacks\u2019 universality. If not specified, our experiments default to using CMPS augmentation. Fig. 5 in the supplementary materials displays the experimental results of our augmentation performed at different probabilities. It can be observed that when the probability value is around $20\\%$ , it achieves optimal effectiveness in assisting the attack. If not specified, a probability value of $20\\%$ for augmentation is used by default in experiments. ", "page_idx": 9}, {"type": "text", "text": "Impact of adversarial boundary size. We conducted an ablation study on different adversarial boundary sizes (\u03f5), as shown in the supplementary material 6. In practical applications, $\\epsilon$ is typically kept moderate to balance perturbation visibility and attack effectiveness. To maintain consistency with previous work [24], we set $\\epsilon=8$ for comparison unless otherwise specified. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this study, we have proposed a cross-modality attack method known as Cross-Modality Perturbation Synergy (CMPS) attack, aimed at evaluating the security of cross-modality ReID systems. The core idea behind the CMPS attack is to capture shared knowledge between visible and non-visible images to optimize perturbations. Additionally, we proposed a Cross-Modality Attack Augmentation method, utilizing grayscale images to bridge the gap between different modalities, further enhancing the attack performance. Through experiments conducted on the RegDB, SYSU and LLCM datasets, we demonstrated the effectiveness of the proposed method while also revealing the limitations of traditional attack approaches. The primary objective of this study has been to assess the security of cross-modality ReID systems. In future research, on the one hand, we will continue to improve the transferability of cross-modality attacks across different datasets and models; on the other hand, we plan to develop robust ReID methods specifically tailored for cross-modality attacks, aimed at defending against adversarial samples. This study not only contributes to advancing the understanding of the security of cross-modality ReID systems but also provides strong motivation for ensuring the reliability and security of these systems in real-world applications. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgment ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported in part by the National Natural Science Foundation of China under Grant No.62276222 and the Public Technology Service Platform Project of Xiamen City, Grant No.3502Z20231043. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Bin Yang, Jun Chen, and Mang Ye. Shallow-deep collaborative learning for unsupervised visible-infrared person re-identification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16870\u201316879, 2024.   \n[2] Jialong Zuo, Hanyu Zhou, Ying Nie, Feng Zhang, Tianyu Guo, Nong Sang, Yunhe Wang, and Changxin Gao. Ufinebench: Towards text-based person retrieval with ultra-fine granularity. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22010\u201322019, 2024.   \n[3] Yunpeng Gong, Jiaquan Li, Lifei Chen, and Min Jiang. Exploring color invariance through image-level ensemble learning. arXiv preprint arXiv:2401.10512, 2024.   \n[4] Jiangming Shi, Yachao Zhang, Xiangbo Yin, Yuan Xie, Zhizhong Zhang, Jianping Fan, Zhongchao Shi, and Yanyun Qu. Dual pseudo-labels interactive self-training for semi-supervised visible-infrared person re-identification. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 11218\u201311228, 2023.   \n[5] Yiwei Ma, Jiayi Ji, Xiaoshuai Sun, Yiyi Zhou, and Rongrong Ji. Towards local visual modeling for image captioning. Pattern Recognition, 138:109420, 2023.   \n[6] Changli Wu, Yiwei Ma, Qi Chen, Haowei Wang, Gen Luo, Jiayi Ji, and Xiaoshuai Sun. 3d-stmn: Dependency-driven superpoint-text matching network for end-to-end 3d referring expression segmentation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 5940\u20135948, 2024.   \n[7] Zhun Zhong, Liang Zheng, Zhiming Luo, Shaozi Li, and Yi Yang. Learning to adapt invariance in memory for person re-identification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(8):2723\u20132738, 2021.   \n[8] Yunpeng Gong, Yongjie Hou, Chuangliang Zhang, and Min Jiang. Beyond augmentation: Empowering model robustness under extreme capture environments. In 2024 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138. IEEE, 2024.   \n[9] Yunpeng Gong, Liqing Huang, and Lifei Chen. Eliminate deviation with deviation for data augmentation and a general multi-modal data learning method. arXiv preprint arXiv:2101.08533, 2021.   \n[10] Lei Tan, Pingyang Dai, Rongrong Ji, and Yongjian Wu. Dynamic prototype mask for occluded person re-identification. In Proceedings of the 30th ACM international conference on multimedia, pages 531\u2013540, 2022.   \n[11] Lei Tan, Jiaer Xia, Wenfeng Liu, Pingyang Dai, Yongjian Wu, and Liujuan Cao. Occluded person re-identification via saliency-guided patch transfer. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 5070\u20135078, 2024.   \n[12] Zhun Zhong, Liang Zheng, Zhedong Zheng, Shaozi Li, and Yi Yang. Camera style adaptation for person re-identification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.   \n[13] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In 3rd International Conference on Learning Representations, ICLR 2015, 2015.   \n[14] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In International Conference on Learning Representations, 2018.   \n[15] Yukang Zhang, Yan Yan, Jie Li, and Hanzi Wang. Mrcn: A novel modality restitution and compensation network for visible-infrared person re-identification. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 3498\u20133506, 2023.   \n[16] Jiangming Shi, Xiangbo Yin, Zhizhong Zhang, Yachao and Zhang, Yuan Xie, and Yanyun Qu. Learning commonality, divergence and variety for unsupervised visible-infrared person re-identification. arXiv preprint arXiv:2402.19026v2 , 2024.   \n[17] Bin Yang, Jun Chen, and Mang Ye. Towards grand unified representation learning for unsupervised visible-infrared person re-identification. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 11069\u201311079, October 2023.   \n[18] Mang Ye, Jianbing Shen, Gaojie Lin, Tao Xiang, Ling Shao, and Steven CH Hoi. Deep learning for person re-identification: A survey and outlook. IEEE transactions on pattern analysis and machine intelligence, 44(6):2872\u20132893, 2022.   \n[19] Xiangbo Yin, Jiangming Shi, Yachao Zhang, Yang Lu, Zhizhong Zhang, Yuan Xie, and Yanyun Qu. Robust pseudo-label learning with neighbor relation for unsupervised visible-infrared person re-identification. arXiv preprint arXiv:2405.05613, 2024.   \n[20] Jiangming Shi, Yachao Zhang, Xiangbo Yin, Yuan Xie, Zhizhong Zhang, Jianping Fan, Zhongchao Shi, and Yanyun Qu. Dual pseudo-labels interactive self-training for semi-supervised visible-infrared person re-identification. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 11218\u201311228, 2023.   \n[21] Yukang Zhang and Hanzi Wang. Diverse embedding expansion network and low-light crossmodality benchmark for visible-infrared person re-identification. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 2153\u20132162, 2023.   \n[22] Mang Ye, Jianbing Shen, David J. Crandall, Ling Shao, and Jiebo Luo. Dynamic dual-attentive aggregation learning for visible-infrared person re-identification. In European Conference on Computer Vision (ECCV), 2020.   \n[23] Zhedong Zheng, Liang Zheng, Yi Yang, and Fei Wu. U-turn: Crafting adversarial queries with opposite-direction features. International Journal of Computer Vision, 131(4):835\u2013854, 2023.   \n[24] Fengxiang Yang, Juanjuan Weng, Zhun Zhong, Hong Liu, Zheng Wang, Zhiming Luo, Donglin Cao, Shaozi Li, Shin\u2019ichi Satoh, and Nicu Sebe. Towards robust person re-identification by defending against universal attackers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(4):5218\u20135235, 2023.   \n[25] Yunpeng Gong, Liqing Huang, and Lifei Chen. Person re-identification method based on color attack and joint defence. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4313\u20134322, 2022.   \n[26] Song Bai, Yingwei Li, Yuyin Zhou, Qizhu Li, and Philip HS Torr. Adversarial metric attack and defense for person re-identification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(6):2119\u20132126, 2020.   \n[27] Quentin Bouniot, Romaric Audigier, and Angelique Loesch. Vulnerability of person reidentification models to metric adversarial attacks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2020.   \n[28] Hongjun Wang, Guangrun Wang, Ya Li, Dongyu Zhang, and Liang Lin. Transferable, controllable, and inconspicuous adversarial attacks on person re-identification with deep mis-ranking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 342\u2013351, 2020.   \n[29] Dat Tien Nguyen, Hyung Gil Hong, Ki Wan Kim, and Kang Ryoung Park. Person recognition system based on a combination of body images from visible light and thermal cameras. Sensors, 17(3):605, 2017.   \n[30] Ancong Wu, Wei-Shi Zheng, Hong-Xing Yu, Shaogang Gong, and Jianhuang Lai. Rgb-infrared cross-modality person re-identification. In Proceedings of the IEEE international conference on computer vision, pages 5380\u20135389, 2017.   \n[31] Wenqi Wang, Run Wang, Lina Wang, Zhibo Wang, and Aoshuang Ye. Towards a robust deep neural network against adversarial texts: A survey. IEEE Transactions on Knowledge and Data Engineering, 35:3159\u20133179, 2023.   \n[32] Qian Wang, Baolin Zheng, Qi Li, Chao Shen, and Zhongjie Ba. Towards query-efficient adversarial attacks against automatic speech recognition systems. IEEE Transactions on Information Forensics and Security, 16:896\u2013908, 2021.   \n[33] Yiwei Ma, Guohai Xu, Xiaoshuai Sun, Ming Yan, Ji Zhang, and Rongrong Ji. X-clip: End-toend multi-grained contrastive learning for video-text retrieval. In Proceedings of the 30th ACM International Conference on Multimedia, pages 638\u2013647, 2022.   \n[34] Mingrui Wu, Xinyue Cai, Jiayi Ji, Jiale Li, Oucheng Huang, Gen Luo, Hao Fei, Xiaoshuai Sun, and Rongrong Ji. Controlmllm: Training-free visual prompt learning for multimodal large language models. arXiv preprint arXiv:2407.21534, 2024.   \n[35] Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017 ieee symposium on security and privacy (sp), pages 39\u201357. Ieee, 2017.   \n[36] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and accurate method to fool deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2574\u20132582, 2016.   \n[37] Yunpeng Gong, Yongjie Hou, Zhenzhong Wang, Zexin Lin, and Min Jiang. Adversarial learning for neural pde solvers with sparse data. arXiv preprint arXiv:2409.02431, 2024.   \n[38] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. Universal adversarial perturbations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.   \n[39] Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial attacks with momentum. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 9185\u20139193, 2018.   \n[40] Alexander Hermans, Lucas Beyer, and Bastian Leibe. In defense of the triplet loss for person re-identification. arXiv preprint arXiv:1703.07737, 2017.   \n[41] Jie Li, Rongrong Ji, Hong Liu, Xiaopeng Hong, Yue Gao, and Qi Tian. Universal perturbation attack against image retrieval. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4899\u20134908, 2019.   \n[42] Cassidy Laidlaw and Soheil Feizi. Functional adversarial attacks. Advances in neural information processing systems, 32, 2019.   \n[43] Zhixiang Wang, Zheng Wang, Yinqiang Zheng, Yung-Yu Chuang, and Shin\u2019ichi Satoh. Learning to reduce dual-level discrepancy for infrared-visible person re-identification. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 618\u2013626, 2019.   \n[44] Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, and Qi Tian. Scalable person re-identification: A benchmark. In Proceedings of the IEEE international conference on computer vision, pages 1116\u20131124, 2015.   \n[45] Liang Zheng, Yi Yang, and Alexander G Hauptmann. Person re-identification: Past, present and future. arXiv preprint arXiv:1610.02984, 2016.   \n[46] Yifan Sun, Liang Zheng, Yi Yang, Qi Tian, and Shengjin Wang. Beyond part models: Person retrieval with refined part pooling (and a strong convolutional baseline). In Proceedings of the European conference on computer vision (ECCV), pages 480\u2013496, 2018.   \n[47] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11\u201314, 2016, Proceedings, Part IV 14, pages 630\u2013645. Springer, 2016. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Supplemental Material ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "1 Introduction 1 ", "page_idx": 13}, {"type": "text", "text": "2 Related Works 3 ", "page_idx": 13}, {"type": "text", "text": "3 Methodology 4 ", "page_idx": 13}, {"type": "text", "text": "3.1 Overall Framework 5   \n3.2 Optimizing Loss Functions for Attacking 5   \n3.3 Cross-Modality Attack Augmentation Method 5   \n3.4 Cross-Modality Perturbation Synergy Attack 6 ", "page_idx": 13}, {"type": "text", "text": "4 Experiments ", "page_idx": 13}, {"type": "text", "text": "4.1 Performance on Cross-Modality ReID 7   \n4.2 Transferability of CMPS 9   \n4.3 Ablation Study 9 ", "page_idx": 13}, {"type": "text", "text": "5 Conclusion 10 ", "page_idx": 13}, {"type": "text", "text": "6 Supplemental Experiments 15 ", "page_idx": 13}, {"type": "text", "text": "7 Proof of Method Superioritys 17 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "7.1 Definition of Cross-Modality Triplet Loss 17   \n7.2 Proof of Aggregated Optimization Superiority . . . . 17   \n7.2.1 Stepwise Optimization Method 18   \n7.2.2 Aggregated Optimization Method 18   \n7.3 Generalization Error Analysis . . 18   \n8 Discussion 20   \n8.1 Ethical Considerations 20   \n8.2 Limitations and Future Work 20 ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "6 Supplemental Experiments ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Our experiments were conducted using three RTX 2080 Ti GPUs, each with 11GB of memory. ", "page_idx": 14}, {"type": "image", "img_path": "LONd7ACEjy/tmp/1d4b51f2204c7fdee568eb96dd30c9c46b4dd45bf21192463ce17fd2d8bd8e9e.jpg", "img_caption": ["Figure 5: The impact of different grayscale transformation probabilities on attack performance. Lower evaluation metrics indicate higher attack success rates. The experimental results are derived from experiments on the RegDB dataset using AGW as the baseline model for testing. "], "img_footnote": [], "page_idx": 14}, {"type": "image", "img_path": "LONd7ACEjy/tmp/bda8eef50ec2fa696965bf30b8215d0f1249e25a99cdc1ec365426adf4d7235b.jpg", "img_caption": ["Figure 6: Transferability experiments of the proposed method across different models on the RegDB dataset (visible to thermal). Transferability experiments of the proposed method across different models on the SYSU dataset (visible to Infrared). "], "img_footnote": [], "page_idx": 14}, {"type": "image", "img_path": "LONd7ACEjy/tmp/0b050032641586ef6f23b235086bca4eb1c8fbefa7335c9326fa0b1e8cbf8966.jpg", "img_caption": ["Figure 7: Comparison of Transferability Between Different Methods on Two Cross-Modal Datasets SYSU and RegDB. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Table 6: Using the AGW baseline on the RegDB dataset, we conduct an ablation study to evaluate the impact of the adversarial boundary $\\epsilon$ on the effectiveness of the proposed CMPS attack (rank-1 accuracy). ", "page_idx": 15}, {"type": "table", "img_path": "LONd7ACEjy/tmp/c5b0fee046a9345b9b488a4d8419bea7e7c64437b17534146e0b746f9bba241c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "7 Proof of Method Superioritys ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We design a cross-modality triplet loss to simultaneously optimize two modalities, which effectively captures common features between different modalities and enhances the cross-modality adaptability of universal perturbations. ", "page_idx": 16}, {"type": "text", "text": "7.1 Definition of Cross-Modality Triplet Loss ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The cross-modality triplet loss aims to optimize the model by adjusting the distance relationships among triplet samples (anchor, positive, negative) so that samples of the same identity are closer, while samples of different identities are farther apart. Specifically, given samples $(x_{\\mathrm{A}},x_{\\mathrm{P}},x_{\\mathrm{N}})$ , where: ", "page_idx": 16}, {"type": "text", "text": "\u2022 $x_{\\mathrm{A}}$ is the anchor sample, \u2022 $x_{\\mathrm{P}}$ is the positive sample with the same identity as the anchor (from a different modality), \u2022 $x_{\\mathrm{{N}}}$ is the negative sample with a different identity from the anchor. ", "page_idx": 16}, {"type": "text", "text": "The triplet loss function is defined as: ", "page_idx": 16}, {"type": "equation", "text": "$$\nL_{\\mathrm{triplet}}=\\operatorname*{max}\\left(0,D(f(x_{\\mathrm{A}}),f(x_{\\mathrm{P}})\\right)-D(f(x_{\\mathrm{A}}),f(x_{\\mathrm{N}}))+\\alpha\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $D(\\cdot,\\cdot)$ denotes the distance metric (e.g., Euclidean distance), and $\\alpha$ is a margin hyperparameter. Mathematically, given the cross-modality triplet loss: ", "page_idx": 16}, {"type": "equation", "text": "$$\nL_{\\mathrm{triplet}}=\\mathrm{max}\\left(\\left(\\Vert C_{g}^{n}-f_{R G B}^{a d v}\\Vert_{2}-\\Vert C_{i r}^{p}-f_{R G B}^{a d v}\\Vert_{2}+\\rho\\right),0\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We can view it as part of the sum of the loss functions for two modalities: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{A}(\\eta)=\\lVert C_{g}^{n}-f_{R G B}^{a d v}\\rVert_{2}}\\\\ {\\mathcal{L}_{B}(\\eta)=\\lVert C_{i r}^{p}-f_{R G B}^{a d v}\\rVert_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Thus, the overall optimization objective can be expressed as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\eta_{\\mathrm{agg}}^{*}=\\arg\\operatorname*{min}_{\\eta}\\left(\\mathcal{L}_{A}(\\eta)+\\mathcal{L}_{B}(\\eta)+\\rho\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This form effectively aggregates the losses of different modalities, thereby optimizing the loss functions of different modalities simultaneously, achieving joint optimization of cross-modality data. This approach trains universal perturbations with better generalization capabilities than methods that consider only single-modality information. ", "page_idx": 16}, {"type": "text", "text": "7.2 Proof of Aggregated Optimization Superiority ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Assume we have data from two modalities: modality A and modality B. Let $\\mathcal{L}_{A}(\\eta)$ and $\\mathcal{L}_{B}(\\eta)$ be the loss functions on modality A and modality B, respectively. The objective of single-modality training is: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\eta}\\mathcal{L}_{A}(\\eta)+\\mathcal{L}_{B}(\\eta)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The stepwise optimization method first optimizes $\\mathcal{L}_{A}(\\eta)$ and then optimizes $\\mathcal{L}_{B}(\\eta)$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\eta^{*}=\\arg\\operatorname*{min}_{\\eta}\\mathcal{L}_{A}(\\eta)\\rightarrow\\eta^{**}=\\arg\\operatorname*{min}_{\\eta}\\mathcal{L}_{B}(\\eta^{*})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The aggregated optimization of the two loss functions is: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\eta_{\\mathrm{agg}}^{*}=\\arg\\operatorname*{min}_{\\eta}\\left(\\mathcal{L}_{A}(\\eta)+\\mathcal{L}_{B}(\\eta)\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Using the gradient aggregation method, it can be expressed as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\nabla_{\\eta}\\mathcal{L}_{\\mathrm{agg}}=\\nabla_{\\eta}\\left(\\mathcal{L}_{A}(\\eta)+\\mathcal{L}_{B}(\\eta)\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Next, we consider the different optimization paths of the two methods. ", "page_idx": 16}, {"type": "text", "text": "7.2.1 Stepwise Optimization Method ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The stepwise optimization method first optimizes the loss function of modality A and then the loss function of modality B. Assume the update rule at iteration $k$ is: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\eta^{(k+1)}=\\eta^{(k)}-\\alpha\\nabla_{\\eta}\\mathcal{L}_{A}(\\eta^{(k)})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "After optimizing the loss function of modality A, the loss function of modality $\\mathbf{B}$ is optimized: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\eta^{(k+1)}=\\eta^{(k)}-\\alpha\\nabla_{\\eta}\\mathcal{L}_{B}(\\eta^{(k)})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since the two optimization processes are separate, this may result in $\\eta$ being optimal for modality A but not necessarily for modality B. ", "page_idx": 17}, {"type": "text", "text": "7.2.2 Aggregated Optimization Method ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The aggregated optimization method considers the losses of both modalities in each iteration. Assume the update rule at iteration $k$ is: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\eta^{(k+1)}=\\eta^{(k)}-\\alpha\\left(\\nabla_{\\eta}\\mathcal{L}_{A}(\\eta^{(k)})+\\nabla_{\\eta}\\mathcal{L}_{B}(\\eta^{(k)})\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In this way, each update considers the losses of both modalities, ensuring that $\\eta$ approaches the optimal solution for both modalities. ", "page_idx": 17}, {"type": "text", "text": "To further prove that the aggregated optimization method can find a better perturbation $\\eta$ , we can analyze the existence and uniqueness of the optimal solution. ", "page_idx": 17}, {"type": "text", "text": "Assume $\\mathcal{L}_{A}(\\eta)$ and $\\mathcal{L}_{B}(\\eta)$ are continuously differentiable and convex loss functions. According to convex optimization theory, the optimal solutions of the loss functions exist and are unique. ", "page_idx": 17}, {"type": "text", "text": "The optimal solution of the stepwise optimization method is: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\eta_{\\mathrm{step}}^{*}=\\arg\\operatorname*{min}_{\\eta}\\left(\\mathcal{L}_{A}(\\eta)+\\mathcal{L}_{B}(\\eta^{*})\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\eta^{*}$ is the optimal solution of $\\mathcal{L}_{A}(\\eta)$ . ", "page_idx": 17}, {"type": "text", "text": "The optimal solution of the aggregated optimization method is: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\eta_{\\mathrm{agg}}^{\\ast}=\\arg\\operatorname*{min}_{\\eta}\\left(\\mathcal{L}_{A}(\\eta)+\\mathcal{L}_{B}(\\eta)\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since $\\eta_{\\mathrm{step}}^{*}$ is not necessarily globally optimal for modality B, and $\\eta_{\\mathrm{agg}}^{*}$ is the global optimal solution considering both modalities, we can derive: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{L}_{A}(\\eta_{\\mathrm{agg}}^{*})+\\mathcal{L}_{B}(\\eta_{\\mathrm{agg}}^{*})\\leq\\mathcal{L}_{A}(\\eta_{\\mathrm{step}}^{*})+\\mathcal{L}_{B}(\\eta_{\\mathrm{step}}^{*})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "7.3 Generalization Error Analysis ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Generalization error measures the model\u2019s performance on unseen data. We can further prove the superiority of aggregated training through generalization error analysis. ", "page_idx": 17}, {"type": "text", "text": "Let $\\mathcal{L}_{\\mathrm{train}}$ and $\\mathscr{L}_{\\mathrm{test}}$ be the losses on the training and test sets, respectively. The generalization error is defined as: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}=\\mathcal{L}_{\\mathrm{test}}(\\eta)-\\mathcal{L}_{\\mathrm{train}}(\\eta)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The upper bound of the generalization error can be expressed using measures such as Rademacher complexity or VC dimension. For machine learning models, the lower the model complexity, the smaller the generalization error. Simultaneously optimizing the losses for multiple tasks (modalities) can reduce overftiting to a single task (modality), as the model needs to perform well on multiple tasks (modalities) simultaneously. This effectively introduces an implicit regularization effect, reducing the model complexity. Therefore, compared to the stepwise optimization method, the aggregated optimization method can effectively reduce the complexity of the perturbation model. The lower the model complexity, the smaller the generalization error. ", "page_idx": 17}, {"type": "text", "text": "The Rademacher complexity measures the complexity of a class of models on a given sample set. For a function $h$ in the hypothesis space $\\mathcal{H}$ , the empirical Rademacher complexity on $n$ samples is defined as: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{R}}_{n}(\\mathcal{H})=\\mathbb{E}_{\\sigma}\\left[\\operatorname*{sup}_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^{n}\\sigma_{i}h(x_{i})\\right]\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\sigma_{i}$ are Rademacher random variables, taking values $\\pm1$ with equal probability. ", "page_idx": 18}, {"type": "text", "text": "The impact of modality aggregation on complexity: ", "page_idx": 18}, {"type": "text", "text": "Assume $\\mathcal{H}_{\\mathrm{A}}$ and $\\mathcal{H}_{\\mathrm{B}}$ are the hypothesis spaces of modality A and modality $\\mathbf{B}$ , respectively. The stepwise optimization method first optimizes $\\mathcal{H}_{\\mathrm{A}}$ and then $\\mathcal{H}_{\\mathrm{B}}$ . Its empirical Rademacher complexity can be expressed as: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{\\hat{R}}_{n}(\\mathcal{H}_{\\mathrm{step}})=\\mathcal{\\hat{R}}_{n}(\\mathcal{H}_{\\mathrm{A}})+\\mathcal{\\hat{R}}_{n}(\\mathcal{H}_{\\mathrm{B}})\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The aggregated optimization method optimizes $\\mathcal{H}_{\\mathrm{A}}\\cup\\mathcal{H}_{\\mathrm{B}}$ simultaneously. Its empirical Rademacher complexity is: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mathcal{R}}_{n}(\\mathcal{H}_{\\mathrm{agg}})=\\hat{\\mathcal{R}}_{n}(\\mathcal{H}_{\\mathrm{A}}\\cup\\mathcal{H}_{\\mathrm{B}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "According to the properties of Rademacher complexity, the complexity of $\\mathcal{H}_{\\mathrm{A}}\\cup\\mathcal{H}_{\\mathrm{B}}$ is usually less than or equal to the sum of the complexities of $\\mathcal{H}_{\\mathrm{A}}$ and $\\mathcal{H}_{\\mathrm{B}}$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{R}}_{n}(\\mathcal{H}_{\\mathrm{agg}})\\leq\\hat{\\mathcal{R}}_{n}(\\mathcal{H}_{\\mathrm{A}})+\\hat{\\mathcal{R}}_{n}(\\mathcal{H}_{\\mathrm{B}})\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Generalization error upper bound derivation: ", "page_idx": 18}, {"type": "text", "text": "Using Rademacher complexity, we can derive the upper bound of the generalization error. For the loss function $\\mathcal{L}$ and hypothesis space $\\mathcal{H}$ , the upper bound of the generalization error is: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen}}\\leq2\\hat{\\mathcal{R}}_{n}(\\mathcal{L}\\circ\\mathcal{H})+\\mathcal{O}\\left(\\frac{1}{\\sqrt{n}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\mathcal{L}\\circ\\mathcal{H}$ denotes the composition of the loss function with the hypothesis space. ", "page_idx": 18}, {"type": "text", "text": "The upper bound of the generalization error for the stepwise optimization method is: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen,\\,step}}\\leq2\\left(\\hat{\\mathcal{R}}_{n}(\\mathcal{L}\\circ\\mathcal{H}_{\\mathrm{A}})+\\hat{\\mathcal{R}}_{n}(\\mathcal{L}\\circ\\mathcal{H}_{\\mathrm{B}})\\right)+\\mathcal{O}\\left(\\frac{1}{\\sqrt{n}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The upper bound of the generalization error for the aggregated optimization method is: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen,\\,agg}}\\leq2\\hat{\\mathcal{R}}_{n}(\\mathcal{L}\\circ(\\mathcal{H}_{\\mathrm{A}}\\cup\\mathcal{H}_{\\mathrm{B}}))+\\mathcal{O}\\left(\\frac{1}{\\sqrt{n}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mathcal{R}}_{n}(\\mathcal{L}\\circ(\\mathcal{H}_{\\mathrm{A}}\\cup\\mathcal{H}_{\\mathrm{B}}))\\leq\\hat{\\mathcal{R}}_{n}(\\mathcal{L}\\circ\\mathcal{H}_{\\mathrm{A}})+\\hat{\\mathcal{R}}_{n}(\\mathcal{L}\\circ\\mathcal{H}_{\\mathrm{B}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{gen,\\,agg}}\\leq\\mathcal{E}_{\\mathrm{gen,\\,step}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This indicates that the aggregated optimization method has a lower upper bound on the generalization error compared to the stepwise optimization method. ", "page_idx": 18}, {"type": "text", "text": "8 Discussion ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "8.1 Ethical Considerations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this study, we introduce a novel cross-modal adversarial attack method known as Cross-Modality Perturbation Synergy (CMPS). This research offers a new perspective on understanding and enhancing the security of cross-modal ReID systems by leveraging shared features across different modalities to optimize perturbations. However, this approach also raises a series of ethical and safety concerns regarding the potential negative impacts of adversarial attack techniques. The CMPS method, like other adversarial technologies, can be maliciously exploited, posing a serious threat to public safety. ", "page_idx": 19}, {"type": "text", "text": "However, we recognize the positive value of adversarial attack research. It reveals vulnerabilities in existing systems, prompting academia and industry to make in-depth improvements to the robustness of machine learning models. The positive impact of this study lies in its potential to combine adversarial training with the attack methods presented to enhance system security and bring positive social impacts. Therefore, we emphasize the importance of conducting adversarial attack research within an ethical framework and encourage further development of defensive technologies to build a safer and more reliable technological environment. ", "page_idx": 19}, {"type": "text", "text": "8.2 Limitations and Future Work ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Here, we need to acknowledge the limitations of the proposed method and identify potential directions for future research. Firstly, current attack techniques primarily focus on gradient-based perturbation optimization for given datasets. However, in real-world scenarios, the modalities encountered are often unknown and not limited to RGB, infrared, and thermal imaging. Moreover, effectively transferring perturbations to different and unknown modalities presents a significant research challenge. ", "page_idx": 19}, {"type": "text", "text": "When dealing with various models and modalities, gradient-based methods face several challenges. Firstly, these methods are prone to \"catastrophic forgetting,\" where learning new information can lead to the loss of previously learned knowledge, affecting the effectiveness of perturbations. Secondly, the inconsistency of gradient information across multiple models and modalities can negatively impact the stability and generalizability of the method. Therefore, future research should explore more robust algorithms that can effectively operate in complex environments involving multiple modalities and models, thereby enhancing the applicability and transferability of attacks. ", "page_idx": 19}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction accurately reffect the paper\u2019s contributions and scope. We have clearly stated our novel methodology and its implications in the abstract and introduction, and these are further elaborated upon and validated in the main body of the paper ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 20}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: Please refer to the final section of the supplementary materials. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 20}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We have conducted a theoretical analysis of the effectiveness of the proposed method. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 21}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: To ensure full disclosure of all necessary information to reproduce the main experimental results of the paper, we have provided the experimental setup within the paper and included pseudocode in the supplementary materials. Additionally, as a key contribution, we have conducted a comprehensive theoretical analysis of the proposed method. We will provide the source code for the reviewers\u2019 examination. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in ", "page_idx": 21}, {"type": "text", "text": "some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 22}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 22}, {"type": "text", "text": "Answer: [No] ", "page_idx": 22}, {"type": "text", "text": "Justification:Given the rapid pace of technological advancement, our field requires careful dissemination of our methods to ensure the integrity and competitiveness of our ongoing research. Additionally, due to ethical and security considerations, we currently prefer not to publicly release our code. However, we will provide the code for reviewers\u2019 examination and release the source code when the time is right. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 22}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We have mentioned this in our paper. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 22}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification:In our main performance comparison experiments, the results are reported as the mean $\\pm$ standard deviation. \u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 22}, {"type": "text", "text": "\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 23}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provide the GPU type used in our paper, and the computation time is given in the ablation experiments. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 23}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our research adheres to the NeurIPS Code of Ethics in all respects. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 23}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our research may have potential negative social impacts. One possible solution is to enhance model security by improving defenses against the proposed attacks through adversarial training.Our research may have potential negative social impacts. One possible solution is to enhance model security by improving defenses against the proposed attacks through adversarial training. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 24}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: Our intention in proposing adversarial attack techniques is to study model security. The safeguard involves enhancing model security by improving defenses against the proposed attacks through adversarial training. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 24}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We used open datasets and correctly referenced the papers. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 25}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: Given the rapid pace of technological development, our field requires careful dissemination of our methods to ensure the integrity and competitiveness of our ongoing research. Therefore, we do not currently plan to publicly release our code. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 25}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 25}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 26}]