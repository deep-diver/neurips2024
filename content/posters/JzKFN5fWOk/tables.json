[{"figure_path": "JzKFN5fWOk/tables/tables_5_1.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents the performance comparison of five different parameterizations of the D-CPT Law across six domains (general and five domain-specific ones).  The performance is measured using Huber loss (lower is better) and R-squared (higher is better) for both the general and domain-specific datasets. The number of fitting parameters for each parameterization is also listed.  Appendix J contains more detailed results for each domain.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_6_1.jpg", "caption": "Table 2: Model Size Generalizability", "description": "This table presents the results of a 3-fold cross-validation experiment to evaluate the model size generalizability of the D-CPT Law.  It shows the Huber loss and R-squared values for the general and domain-specific corpora across different model sizes (0.5B, 1.8B, and 4B parameters) and across different parameterizations of the D-CPT Law (L1-L5).  Lower Huber loss and higher R-squared values indicate better generalizability.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_6_2.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents the Huber loss and R-squared values for five different parameterizations of the D-CPT Law across six domains (general and five downstream domains). Lower Huber loss and higher R-squared indicate better model performance.  The table shows the average performance across all domains, with more detailed results available in Appendix J.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_6_3.jpg", "caption": "Table 4: Mixture ratio Generalizability.", "description": "This table presents the results of mixture ratio generalizability experiments.  It compares five different parameterizations (L1-L5) of the D-CPT Law across six domains (general and five downstream domains).  For each parameterization and domain, it shows the Huber loss and R-squared values, indicating the quality of the model's fit to the experimental data points at different mixture ratios. Lower Huber loss and higher R-squared values signify better model performance and generalizability.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_7_1.jpg", "caption": "Table 5: The real Lg and Ld with respect to ra in usage 1 setting", "description": "This table shows the real general-corpus validation loss (Lg) and domain-corpus validation loss (Ld) for different domain-corpus mixture ratios (rd).  The highlighted row indicates the optimal mixture ratio (rd = 0.924) that minimizes the domain-specific loss while keeping the general loss within an acceptable threshold (3% increase from the initial general loss). This demonstrates the effectiveness of the D-CPT Law in identifying the optimal ratio for a desired trade-off between general and domain-specific performance.", "section": "4.3 Usages of D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_8_1.jpg", "caption": "Table 6: The real domain-corpus validation loss with respect to ra when Da is fixed with 5B.", "description": "This table shows the real domain-corpus validation loss (Ld) for different values of the domain-corpus mixture ratio (rd) when the domain-specific dataset size (Da) is fixed at 5B.  It demonstrates the relationship between the mixture ratio and the loss, highlighting the optimal mixture ratio that minimizes the loss.", "section": "4.4 Cross-Domain D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_8_2.jpg", "caption": "Table 8: Domain generalizability", "description": "This table shows the performance of four different representations of the Domain-Specific Learnable Coefficient (DLC) in a cross-domain setting.  The goal is to determine which representation best predicts the performance of unseen domains using data from only a subset of domains.  The table reports Huber loss and R-squared values for both general and domain-specific settings, indicating the accuracy of the prediction. Lower Huber loss and higher R-squared values suggest better performance. ", "section": "4.4 Cross-Domain D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_8_3.jpg", "caption": "Table 7: The performance of 4 representations under effectiveness setting.", "description": "This table presents the performance of four different representations (K1, K2, K3, K4) of the Domain-Specific Learnable Coefficient (DLC) in terms of Huber loss and R-squared values.  Lower Huber loss and higher R-squared values indicate better model performance. The table also shows the number of fitting parameters and the accessibility of each representation.  The results are used to determine which representation of K is the most suitable for the Cross-Domain D-CPT Law.", "section": "4.4 Cross-Domain D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_14_1.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents the Huber loss and R-squared values for five different parameterizations of the D-CPT law across six domains (general and five downstream domains).  Lower Huber loss and higher R-squared indicate better model performance. The table summarizes the results, with full details in Appendix J.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_14_2.jpg", "caption": "Table 10: The fitting performance of two laws on code-corpus with 1:1 mixture ratio.", "description": "This table compares the fitting performance of two scaling laws, OpenAI Scaling Law and Chinchilla Scaling Law, on a code corpus dataset using a 1:1 mixture ratio.  The comparison is based on Huber loss (lower is better) and R-squared (higher is better) values for both general and domain-specific data. The results show that the Chinchilla Scaling Law exhibits significantly better fitting performance than the OpenAI Scaling Law in this specific experimental setup.", "section": "E.3 Details behind D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_20_1.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents a comparison of five different parameterizations of the D-CPT Law, denoted as L1 through L5.  The comparison is based on two key metrics: Huber loss (lower is better) and R-squared (higher is better).  The results are shown separately for general domains (G) and downstream domains (D), which represent performance on general language tasks and domain-specific tasks, respectively.  The table highlights the best-performing parameterization (L3) based on the lowest Huber loss and the highest R-squared values across both general and downstream domains. The full details for each domain are available in Appendix J.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_20_2.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents the results of five different parameterizations of the D-CPT Law across six downstream domains (Code, Math, Law, Chemistry, Music, Medical). The performance is evaluated using Huber loss and R-squared (R2). \"G\" represents the general domain, and \"D\" represents the downstream domains. Lower Huber loss and higher R2 indicate better performance. The table shows the average performance across all six domains, with details for each domain provided in Appendix J.  This table is crucial in the paper because it helps to justify the choice of the best parameterization (L3) for the D-CPT Law.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_22_1.jpg", "caption": "Table 13: Domain-corpus validation loss with respect to various model sizes and dataset sizes while keeping the same compute budget.", "description": "This table presents the results of an experiment where the compute budget was fixed, and the domain-corpus validation loss (Ld) was measured for different model sizes (N) and dataset sizes (D).  The results show how the loss changes as the model and dataset sizes are varied while maintaining a constant compute budget. The highlighted row indicates the optimal setting found through the experiment.", "section": "4.3 Usages of D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_23_1.jpg", "caption": "Table 14: The fitting performance of different sampling methods.", "description": "This table compares the performance of four different sampling methods for collecting data points to fit the D-CPT Law. The methods vary in density (dense, sparse, sectional) and use an exponential decay function.  The table shows Huber loss, R-squared, and resource consumption (evaluation and storage) for each method,  across the general and domain-specific data. Method M4, using an exponential decay function, seems to provide the best balance between accuracy and resource consumption.", "section": "I.1 Fitting Efficiency"}, {"figure_path": "JzKFN5fWOk/tables/tables_26_1.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents the Huber loss and R-squared values for five different parameterizations of the D-CPT Law across six domains (General, Code, Math, Law, Music, Chemistry, Medical). Lower Huber loss and higher R-squared indicate better fitting performance. The table helps in selecting the best parameterization for the D-CPT Law by comparing their performance across different domains.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_26_2.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table compares the performance of five different parameterizations of the D-CPT Law across six downstream domains (Code, Math, Law, Music, Chemistry, and Medical).  The \"G\" column represents the performance on the general corpus and the \"D\" column shows the performance on the domain-specific corpus.  It uses Huber loss (lower is better) and R-squared (higher is better) as evaluation metrics. The table highlights the trade-off between fitting performance and the number of parameters used in the models. Appendix J provides more detailed results for each domain.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_26_3.jpg", "caption": "Table 17: Supplementary Table of Table 2. Huber loss of 5 parameterizations across 6 domains, each unit displays the average value of 3-fold cross-validation.", "description": "This table presents the Huber loss, a robust loss function, for five different parameterizations of the D-CPT Law across six domains (Code, Math, Law, Music, Chemistry, Medical).  Each value represents the average Huber loss calculated using 3-fold cross-validation, offering a more robust estimate of performance than a single run.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_26_4.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents the average Huber loss and R-squared values across six domains (Code, Math, Law, Music, Chemistry, and Medical) for five different parameterizations (L1-L5) of the D-CPT Law.  Lower Huber loss and higher R-squared values indicate better model performance.  The 'G' and 'D' columns represent general and domain-specific metrics, respectively.  Appendix J contains detailed results for each domain.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_26_5.jpg", "caption": "Table 11: Mean performance across L3, L6, and L7 over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains.", "description": "This table compares the performance of three different parameterizations (L3, L6, and L7) of the D-CPT Law across six downstream domains.  For each parameterization and domain, it shows the Huber loss and R-squared values for both general and domain-specific validation sets.  Lower Huber loss and higher R-squared indicate better performance.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_27_1.jpg", "caption": "Table 11: Mean performance across L3, L6, and L7 over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains.", "description": "This table compares the performance of three different parameterizations (L3, L6, and L7) of the D-CPT Law across six downstream domains (Code, Math, Law, Music, Chemistry, and Medical).  For each parameterization and domain, it shows the Huber loss and R-squared values for both general and domain-specific corpora.  Lower Huber loss and higher R-squared indicate better fitting performance.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_27_2.jpg", "caption": "Table 11: Mean performance across L3, L6, and L7 over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains.", "description": "This table presents a comparison of the performance (Huber loss and R-squared) of three different parameterizations (L3, L6, and L7) of the D-CPT Law across six downstream domains (Code, Math, Law, Music, Chemistry, and Medical).  'G' represents the general domain and 'D' represents the domain-specific results for each parameterization. The table helps to evaluate which parameterization is most effective by comparing their Huber loss and R-squared values across both general and domain-specific datasets.", "section": "4.2 D-CPT Law"}, {"figure_path": "JzKFN5fWOk/tables/tables_27_3.jpg", "caption": "Table 1: Mean performance across five parameterizations over six domains. \u201cG\u201d and \u201cD\u201d denote general and downstream domains. Detailed results on all domains are shown in Appendix J.", "description": "This table presents the Huber loss and R-squared values for five different parameterizations of the D-CPT Law across six domains (general and five specific domains).  Lower Huber loss and higher R-squared indicate better fitting performance.  The table allows comparison of different parameterizations to determine which best fits the D-CPT Law model and provides a summary of performance across various domains. Details for each domain are available in Appendix J.", "section": "4.2 D-CPT Law"}]