[{"figure_path": "DG2f1rVEM5/tables/tables_1_1.jpg", "caption": "Table 1: Comparison with previous 3D representations with respect to spatial structure, explicitness, real-time rendering capability, and relative parameter count (Rel. Parameters) for representations of comparable quality.", "description": "This table compares several existing 3D representations against the proposed GaussianCube method.  The comparison focuses on four key aspects: spatial structure (whether the representation is organized in a structured grid or is unstructured), explicitness (whether the representation is directly defined or requires an implicit feature decoder), real-time rendering capability, and the relative number of parameters required to achieve comparable quality.  GaussianCube excels in all aspects except for the number of parameters, which is significantly lower (1.0x) than existing methods.", "section": "1 Introduction"}, {"figure_path": "DG2f1rVEM5/tables/tables_6_1.jpg", "caption": "Table 3: Quantitative results of unconditional generation on ShapeNet Car and Chair [9] and class-conditioned generation on OmniObject3D [64].", "description": "This table presents a quantitative comparison of the proposed GaussianCube method against existing state-of-the-art methods on three datasets: ShapeNet Car, ShapeNet Chair, and OmniObject3D.  For each dataset, the table shows the Fr\u00e9chet Inception Distance (FID) and Kernel Inception Distance (KID) scores, which are common metrics to evaluate the quality of generated 3D models. Lower FID and KID scores indicate better-quality generated models. The results demonstrate the superior performance of GaussianCube in generating high-fidelity 3D objects compared to the other methods.", "section": "4 Experiments"}, {"figure_path": "DG2f1rVEM5/tables/tables_7_1.jpg", "caption": "Table 4: Quantitative results of digital avatar creation conditioned on single portrait image.", "description": "This table presents a quantitative comparison of different methods for generating 3D digital avatars based on a single input portrait image. The metrics used for comparison include PSNR, LPIPS, SSIM, CSIM, FID-5K, and KID-5K.  These metrics evaluate the quality of the generated avatars in terms of peak signal-to-noise ratio, learned perceptual image patch similarity, structural similarity index, cosine similarity of identity embedding, Fr\u00e9chet inception distance and kernel inception distance, respectively. The results show that the proposed GaussianCube method significantly outperforms the other methods in terms of both visual quality and identity preservation. ", "section": "4. Experiments"}, {"figure_path": "DG2f1rVEM5/tables/tables_16_1.jpg", "caption": "Table 2: Comparison with prior 3D representations of spatial structure, fitting quality, relative fitting speed (Rel. Speed) and parameter sizes on ShapeNet Car. * denotes that the implicit feature decoder is shared across different objects. All methods are evaluated at 30K iterations.", "description": "This table compares the proposed GaussianCube method with several other 3D representations in terms of spatial structure, fitting quality (PSNR, LPIPS, SSIM), relative fitting speed, and the number of parameters.  It highlights GaussianCube's superior performance and efficiency, particularly when compared to methods using a shared implicit feature decoder.", "section": "4 Experiments"}, {"figure_path": "DG2f1rVEM5/tables/tables_16_2.jpg", "caption": "Table 2: Comparison with prior 3D representations of spatial structure, fitting quality, relative fitting speed (Rel. Speed) and parameter sizes on ShapeNet Car. * denotes that the implicit feature decoder is shared across different objects. All methods are evaluated at 30K iterations.", "description": "This table compares GaussianCube with other 3D representations in terms of spatial structure, fitting quality (PSNR, LPIPS, SSIM), relative fitting speed, and the number of parameters.  It highlights GaussianCube's superior performance and efficiency, especially when compared to methods using shared implicit feature decoders.", "section": "4 Experiments"}, {"figure_path": "DG2f1rVEM5/tables/tables_17_1.jpg", "caption": "Table 2: Comparison with prior 3D representations of spatial structure, fitting quality, relative fitting speed (Rel. Speed) and parameter sizes on ShapeNet Car. * denotes that the implicit feature decoder is shared across different objects. All methods are evaluated at 30K iterations.", "description": "This table compares the proposed GaussianCube method with other 3D representations in terms of spatial structure, fitting quality (PSNR, LPIPS, SSIM), relative speed, and the number of parameters used.  It highlights GaussianCube's superior performance and efficiency, especially when compared to methods using shared implicit feature decoders.", "section": "4 Experiments"}, {"figure_path": "DG2f1rVEM5/tables/tables_17_2.jpg", "caption": "Table 2: Comparison with prior 3D representations of spatial structure, fitting quality, relative fitting speed (Rel. Speed) and parameter sizes on ShapeNet Car. * denotes that the implicit feature decoder is shared across different objects. All methods are evaluated at 30K iterations.", "description": "This table compares GaussianCube against other 3D representations on the ShapeNet Car dataset.  It shows the spatial structure, fitting quality (PSNR, LPIPS, SSIM), relative fitting speed, and the number of parameters for each method.  It highlights that GaussianCube achieves comparable or better quality with significantly fewer parameters, especially when compared to methods using a shared implicit feature decoder.", "section": "4 Experiments"}]