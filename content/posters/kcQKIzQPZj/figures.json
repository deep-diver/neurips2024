[{"figure_path": "kcQKIzQPZj/figures/figures_0_1.jpg", "caption": "Figure 1: Given an input image, the user draws a mask specifying the editable region and clicks dragging points (handle points (red) and target points (blue)). Our LucidDrag considers the ill-posed nature of drag-based editing and can produce diverse results (the first row). Besides, it achieves outstanding performance in editing accuracy and image fidelity (the second row).", "description": "This figure demonstrates the capabilities of LucidDrag in handling drag-based image editing.  The top row shows diverse results generated from the same input image and user-defined drag points, highlighting LucidDrag's ability to handle the ill-posed nature of this task (multiple valid results). The bottom row showcases LucidDrag's strong performance in terms of both accuracy (how closely the editing matches the user's intent) and image fidelity (preserving the quality and realism of the image).", "section": "Abstract"}, {"figure_path": "kcQKIzQPZj/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of LucidDrag. LucidDrag comprises two main components: an intention reasoner and a collaborative guidance sampling mechanism. Intention Reasoner leverages an LVLM and an LLM to reason N possible semantic intentions. Collaborative Guidance Sampling facilitates semantic-aware editing by collaborating editing guidance with semantic guidance and quality guidance.", "description": "LucidDrag's architecture is composed of two main parts: an intention reasoner and a collaborative guidance sampling mechanism.  The intention reasoner uses an LVLM and an LLM to identify potential semantic intentions from user input (image, caption, and drag points).  The collaborative guidance sampling mechanism combines editing, semantic, and quality guidance to produce semantically-aware and high-quality image edits.  The figure visually represents the information flow between these components and the editing process.", "section": "3 Method"}, {"figure_path": "kcQKIzQPZj/figures/figures_6_1.jpg", "caption": "Figure 3: LucidDrag allows generating diverse results conforming to the intention.", "description": "This figure demonstrates the ability of LucidDrag to generate diverse results that align with the user's intentions, even when those intentions are ambiguous.  Multiple examples are shown, each beginning with a source image and a user-specified editing task (indicated by drag points and text prompts).  The results showcase the variety of outputs generated by LucidDrag for the same input, highlighting the model's ability to handle the ill-posed nature of drag-based editing.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/figures/figures_6_2.jpg", "caption": "Figure 3: LucidDrag allows generating diverse results conforming to the intention.", "description": "This figure showcases the diversity and semantic awareness of LucidDrag.  Given various input images and user-specified drag points, LucidDrag generates multiple diverse results, each adhering to the implied semantic intent.  It highlights the model's ability to interpret the user's intention and produce results that accurately reflect that intention, even when multiple valid interpretations exist. The images demonstrate differences in how animals and objects are modified based on subtle changes in the dragging points and the source/target prompts determined by the intention reasoner.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/figures/figures_7_1.jpg", "caption": "Figure 4: Qualitative comparison between our LucidDrag and other methods in object moving.", "description": "This figure shows a qualitative comparison of object-moving results between LucidDrag and other methods (DragDiffusion and DiffEditor).  Each row presents a different image editing task where an object is moved from one location to another within the image using the various methods. The comparisons highlight LucidDrag's superior performance in generating images with higher fidelity and more precisely placed objects, while the other methods may struggle with positional accuracy or introduce unwanted artifacts.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/figures/figures_8_1.jpg", "caption": "Figure 5: Visualization of ablation study.", "description": "This figure shows the ablation study results for LucidDrag, comparing the full model against versions without the intention reasoner and without quality guidance.  The top row demonstrates the impact on a bicycle image, highlighting how the absence of these components leads to distortions and artifacts. The bottom row shows the effect on a spinning top image, illustrating the loss of detail and fidelity caused by removing quality guidance and the intention reasoner.  The results show the importance of both components in achieving high-quality and semantically consistent image editing.", "section": "4.3 Ablation Study"}, {"figure_path": "kcQKIzQPZj/figures/figures_15_1.jpg", "caption": "Figure 3: LucidDrag allows generating diverse results conforming to the intention.", "description": "This figure shows several examples of diverse results generated by LucidDrag for different image editing tasks.  Each row represents a single task, starting with a source image and a user-specified drag interaction (shown as blue and red points). LucidDrag then generates multiple possible output images, all consistent with the user's intended semantic changes. The results demonstrate LucidDrag's ability to handle the inherently ill-posed nature of drag-based editing, producing diverse and semantically meaningful outputs while maintaining image fidelity.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/figures/figures_16_1.jpg", "caption": "Figure 7: LucidDrag allows generating diverse results.", "description": "This figure shows several examples of diverse editing results generated by LucidDrag for different prompts.  Each row presents a series of images resulting from applying different editing strategies to the same source image. This demonstrates LucidDrag's ability to produce a variety of semantically coherent outputs for a single input, highlighting its capacity to handle the ill-posed nature of drag-based editing.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/figures/figures_17_1.jpg", "caption": "Figure 8: Analysis of confidence probabilities. A higher confidence probability indicates that the intention of the output is more reasonable, leading to better editing results.", "description": "This figure shows four different outputs from the LLM-driven reasoner module, each with a different confidence score. The input is a picture of a pineapple with drag points indicating a desired change in size. Output 1, with the highest confidence score, correctly interprets the intention and generates an image reflecting a change in size (shorter).  Outputs 2, 3, and 4 have lower confidence scores and produce less accurate results, either failing to accurately change the size or interpreting the request incorrectly.", "section": "A.5 More Analysis"}, {"figure_path": "kcQKIzQPZj/figures/figures_17_2.jpg", "caption": "Figure 9: Visualization of the quality guidance and editing guidance.", "description": "This figure visualizes the evolution of gradient maps during the drag-based editing process at different time steps. The top row shows gradient maps generated by the editing guidance (gedit), while the bottom row displays those from the quality guidance (gquality).  The visualization demonstrates a gradual convergence as sampling progresses.  The activation range of the gradient maps narrows, focusing progressively towards the editing areas.", "section": "3.2 Collaborative Guidance Sampling"}, {"figure_path": "kcQKIzQPZj/figures/figures_17_3.jpg", "caption": "Figure 10: Analysis of the quality guidance weight.", "description": "This figure shows the effect of changing the weight of the quality guidance (Wquality) on the image editing results.  As Wquality increases, the importance of maintaining high image quality is emphasized. However, there is a trade-off; overly high weights can lead to overly constrained editing, potentially sacrificing the desired changes in the image. The default setting of 1e-3 is shown to provide a balance between quality and editing fidelity.", "section": "4.3 Ablation Study"}, {"figure_path": "kcQKIzQPZj/figures/figures_18_1.jpg", "caption": "Figure 3: LucidDrag allows generating diverse results conforming to the intention.", "description": "This figure shows several examples of diverse results generated by LucidDrag for different image editing tasks. Each example includes the source image, the user's edits (including source and target prompts), and the results generated by LucidDrag.  The results demonstrate the model's ability to produce multiple plausible outcomes for a given input, highlighting its capacity for handling the inherent ambiguity in drag-based editing.", "section": "4.2 Comparisons"}]