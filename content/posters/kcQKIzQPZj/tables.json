[{"figure_path": "kcQKIzQPZj/tables/tables_7_1.jpg", "caption": "Table 1: Comparisons of content dragging on DragBench.", "description": "This table presents a quantitative comparison of different drag-based image editing methods on the DragBench benchmark dataset.  It shows the Mean Distance and GScore for each method.  Mean Distance measures the average distance between the dragged content and the target location, indicating the accuracy of the dragging process (lower is better). GScore is a human-aligned image quality assessment metric (higher is better).  The results demonstrate the superior performance of LucidDrag in both dragging accuracy and image quality compared to other state-of-the-art methods.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/tables/tables_8_1.jpg", "caption": "Table 2: Comparisons of object moving.", "description": "This table presents a quantitative comparison of the object moving task, comparing the performance of LucidDrag against DragonDiffusion and DiffEditor.  The metrics used are CLIP-score (higher is better, indicating better alignment between the edited image and the target description) and LMM-score (higher is better, representing a human-aligned assessment of overall image quality).  LucidDrag shows improved performance across both metrics.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/tables/tables_8_2.jpg", "caption": "Table 3: Quantitative result of ablation study.", "description": "This table presents the quantitative results of the ablation study conducted on the LucidDrag model. It compares the performance of the full implementation of LucidDrag with two ablated versions: one without the intention reasoner and another without the quality guidance.  The metrics used for comparison are Mean Distance and GScore. Lower Mean Distance indicates better dragging precision, while a higher GScore indicates better image quality. The results show that both the intention reasoner and quality guidance contribute significantly to the overall performance of the model.", "section": "4.3 Ablation Study"}, {"figure_path": "kcQKIzQPZj/tables/tables_14_1.jpg", "caption": "Table 4: Comparisons of Dragging Accuracy (Mean Distance) on DragBench (\u2193).", "description": "This table presents a detailed comparison of the dragging accuracy of different methods across various categories in the DragBench dataset.  The \"Mean Distance\" metric is used to evaluate the accuracy of moving contents to target points. Lower values indicate better performance. The table includes results for different categories of images in the DragBench dataset, including Artworks, Landscape, City, Countryside, Animals, Head, Upper body, Full body, Interior, and Other. This allows for a comprehensive assessment of the methods' performance across different image types and editing scenarios. The table shows that the proposed LucidDrag method achieves the lowest mean distance in almost every category.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/tables/tables_14_2.jpg", "caption": "Table 5: Comparisons of Image Fidelity (GScore) on DragBench (\u2191).", "description": "This table presents a detailed comparison of image quality using the GScore metric across different categories within the DragBench dataset.  It compares the performance of LucidDrag against several other drag-based editing methods.  Higher GScore indicates better perceived image quality. The results show that LucidDrag achieves a higher average GScore than other methods, demonstrating superior image fidelity in drag-based editing.", "section": "4.2 Comparisons"}, {"figure_path": "kcQKIzQPZj/tables/tables_16_1.jpg", "caption": "Table 6: Results with different LVLMs and LLMs", "description": "This table presents the results of experiments conducted to analyze the performance of different Large Vision-Language Models (LVLMs) and Large Language Models (LLMs) used in the Intention Reasoner module of the LucidDrag model.  The models tested are Ferret and Osprey for LVLMs, and Vicuna, Llama 3, and GPT3.5 for LLMs. The table shows the Mean Distance and GScore for each combination of LVLMs and LLMs.  The combination Osprey + GPT3.5 represents the default setting for the paper.  It demonstrates that all combinations surpass the experiment without an Intention Reasoner, indicating the reliability and effectiveness of using both LVLMs and LLMs in this application.", "section": "A.5 More Analysis"}, {"figure_path": "kcQKIzQPZj/tables/tables_18_1.jpg", "caption": "Table 7: Efficiency of different methods.", "description": "This table compares the inference time and memory usage of LucidDrag against four other drag-based image editing methods: DragDiffusion, FreeDrag, DragonDiffusion, and DiffEditor. The results show that LucidDrag has a relatively fast inference time and comparable memory requirements to the other methods.", "section": "4.1 Implementation Details"}]