[{"figure_path": "AvWB40qXZh/figures/figures_1_1.jpg", "caption": "Figure 1: The core idea of NeuMA: Learning to correct existing expert knowledge on object motions by fitting a neural material adaptor to ground-truth visual observations.", "description": "The figure illustrates the core concept of NeuMA.  It shows how NeuMA integrates existing expert-designed physical models (e.g., Neo-Hookean elasticity, von Mises plasticity) with a learned neural adaptor. This adaptor corrects the expert models to better match actual intrinsic dynamics observed from visual data. The process involves a GAP (Grounding Adaptor Paradigm) which bridges expert knowledge with observations to generate grounded dynamics.", "section": "1 Introduction"}, {"figure_path": "AvWB40qXZh/figures/figures_2_1.jpg", "caption": "Figure 2: The pipeline of NeuMA for visual grounding. During Stage I, we first reconstruct the 3D Gaussian kernels of the foreground object using masked multi-view images. Then, we uniformly sample the initial physical particles from the object volume and bind them to the reconstructed Gaussian kernels. In Stage II, we integrate the neural material adaptor into the PDE-based simulation framework to estimate the actual dynamics. In Stage III, we deform the Gaussian kernels according to the binding relationship (pre-computed in Stage I) and then render 2D images. The neural material adaptor is trained end-to-end using the difference between the rendered and observed images.", "description": "This figure shows the pipeline of NeuMA, which consists of three stages: Initial State Acquisition, Physics Simulation, and Dynamic Scene Rendering.  In the first stage, 3D Gaussian kernels are reconstructed from multi-view images, and particles are sampled and bound to these kernels. The second stage involves physics simulation using the Neural Material Adaptor (NeuMA) which combines physical laws and learned corrections to estimate dynamics. Finally, the third stage renders 2D images by deforming the Gaussian kernels based on the simulation results, allowing for end-to-end training with pixel supervision.", "section": "3 Method"}, {"figure_path": "AvWB40qXZh/figures/figures_6_1.jpg", "caption": "Figure 3: Comparison in object dynamics grounding over the entire simulation sequence.", "description": "This figure compares the performance of different methods (NCLaw, NeuMA, NeuMA with particle supervision, NeuMA without binding, and NeuMA without the correction term) for object dynamics grounding across the entire simulation sequence.  Each subplot represents a different dynamic scene (BouncyBall, JellyDuck, RubberPawn, ClayCat, SandFish, HoneyBottle). The y-axis shows the Chamfer distance, a measure of the difference between the predicted and ground-truth particle positions, and the x-axis represents the time step. This visualization provides a detailed comparison of the methods' ability to accurately track object motion over time in various dynamic settings.", "section": "4.2 Performance on Object Dynamics Grounding"}, {"figure_path": "AvWB40qXZh/figures/figures_6_2.jpg", "caption": "Figure 4: Quantitative comparison in dynamic scene rendering.", "description": "This figure presents a quantitative comparison of dynamic scene rendering performance using different metrics (PSNR, SSIM, LPIPS) for various methods: PAC-NeRF, NCLaw+R, NeuMA, and its ablation variants (NeuMA w/o \u0394\u039c\u03b8, NeuMA w/ P.S., NeuMA w/o Bind).  The bar chart visualizes the performance across six different dynamic scenes: BouncyBall, JellyDuck, RubberPawn, ClayCat, SandFish, and HoneyBottle. This allows for a detailed analysis of the impact of different components of NeuMA and comparison against existing state-of-the-art methods.", "section": "4.2 Performance on Object Dynamics Grounding"}, {"figure_path": "AvWB40qXZh/figures/figures_7_1.jpg", "caption": "Figure 5: The visual results for dynamic scene rendering.", "description": "This figure shows a comparison of dynamic scene rendering results between different methods: Reference, NCLaw+R, PAC-NeRF, and NeuMA.  For each method, multiple frames of the simulation are shown for three different objects: BouncyBall, RubberPawn, and SandFish.  A second row of images provides a comparison of results for real-world scenarios using the Bun, Burger, Dog, and Pig datasets, comparing Spring-Gaus and NeuMA results against the observations.", "section": "4.2 Performance on Object Dynamics Grounding"}, {"figure_path": "AvWB40qXZh/figures/figures_8_1.jpg", "caption": "Figure 7: The visual results for dynamics interpolation. By applying different weights to the residual term \u0394M\u03b8, NeuMA can generate diverse dynamics that smoothly translate prior dynamics to visual observation.", "description": "This figure shows the results of applying different weights to the residual term (\u0394M\u03b8) in the NeuMA model.  It demonstrates the model's ability to smoothly interpolate between dynamics specified by prior knowledge (M\u2080) and those observed in the visual data. The left side shows the results for a pink object, while the right shows the results for a yellow object. Each column represents a different weight applied to the residual term, ranging from 1/16 to 1, showcasing the range of dynamic behaviors the model can generate.", "section": "4.4 Experimental Analysis"}, {"figure_path": "AvWB40qXZh/figures/figures_8_2.jpg", "caption": "Figure 8: The visual results for dynamics generalization. The blue text indicates the applied material for each object. (a) Generalization to new objects (i.e., the letters of \u201cNeurIPS\u201d); (b) Generalization to multi-object interactions.", "description": "This figure demonstrates the generalization capabilities of the NeuMA model.  Subfigure (a) shows the application of the model to novel shapes (the letters of \"NeurIPS\"), indicating the model's ability to predict dynamics across different objects, with the blue text specifying the material type used for each letter. Subfigure (b) showcases the model's performance in simulating multi-object interactions, specifically a collision scenario between different materials.  The successful generalization highlights NeuMA's ability to adapt to unseen scenarios and interactions.", "section": "4.4 Experimental Analysis"}, {"figure_path": "AvWB40qXZh/figures/figures_8_3.jpg", "caption": "Figure 9: Results for dynamics prediction. Given visual data from t = 0 to 400, NeuMA can generate physically plausible prediction for a longer period. (a) Visualization of predicted images; (b) Comparison of the mean height of the BouncyBall between ground truth and our prediction.", "description": "This figure demonstrates the long-term prediction capability of the NeuMA model.  Given only the first 400 time steps of visual data, NeuMA can accurately predict the BouncyBall's height for a substantially longer duration. The figure shows the predicted images (a) and a quantitative comparison of the predicted height versus the ground truth (b). This highlights NeuMA's ability to extrapolate beyond the observed data and generate physically plausible predictions.", "section": "4.3 Performance on Dynamic Scene Rendering"}, {"figure_path": "AvWB40qXZh/figures/figures_8_4.jpg", "caption": "Figure 10: Gradient norm analysis. Y-axis: average gradient norms across the training stage. Higher norms indicate more significant changes in the parameters of the corresponding material model.", "description": "This figure shows the gradient norms of the elastic and plastic material models during the training process for two different objects: BouncyBall and RubberPawn.  Higher gradient norms indicate that the model's parameters are changing more significantly during training, suggesting that the model is learning more effectively in those areas. The plots visualize how the learning process focuses on adjusting the parameters of either the elastic or plastic model depending on the object's behavior.  The consistent oscillatory pattern might highlight some challenges or periodic updates during training.", "section": "4.4 Experimental Analysis"}, {"figure_path": "AvWB40qXZh/figures/figures_9_1.jpg", "caption": "Figure 11: Grounding result on an object with uneven mass.", "description": "This figure shows the results of applying NeuMA to an object with uneven mass distribution.  The left side shows the observation (input) sequence, while the right illustrates the dynamics generated by NeuMA. The color gradients on the leftmost object indicate the uneven mass distribution.  The results demonstrate NeuMA's ability to handle complex mass distributions.", "section": "4.4 Experimental Analysis"}, {"figure_path": "AvWB40qXZh/figures/figures_16_1.jpg", "caption": "Figure 12: Visualization of the simulated particles on the JellyDuck benchmark.", "description": "This figure visualizes the simulated particles of a JellyDuck at different time steps (t=100, t=200, t=400) using different methods: Reference (ground truth), NCLaw (physics-informed model), NeuMA (proposed method), NeuMA w/ P.S. (NeuMA with particle supervision), NeuMA w/o Bind (NeuMA without particle binding), and NeuMA w/o \u0394M\u03b8 (NeuMA without the neural material adaptor).  The visualization highlights the differences in the accuracy and realism of the simulation results obtained by each method. Notably, the red arrows point out discrepancies between the results obtained and the reference.  The visualization clearly shows how NeuMA effectively captures the dynamics of the JellyDuck, while other methods exhibit various degrees of artifacts and inaccuracies.", "section": "4.2 Performance on Object Dynamics Grounding"}, {"figure_path": "AvWB40qXZh/figures/figures_17_1.jpg", "caption": "Figure 13: Visualization of dynamics grounding on complex objects.", "description": "This figure demonstrates the results of applying NeuMA to complex objects with diverse shapes and properties. The three columns showcase the results for (a) Machine Man, (b) Crate, and (c) Ring.  For each object, the leftmost image shows the observation (input video frames), and the rightmost image shows the results of generating the dynamics using NeuMA, with the intermediate step of generating the 3D model in the middle. This visual comparison highlights NeuMA's ability to successfully ground the intrinsic dynamics of various objects.", "section": "4.3 Performance on Dynamic Scene Rendering"}]