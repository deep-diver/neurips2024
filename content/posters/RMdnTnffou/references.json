{"references": [{"fullname_first_author": "David Bau", "paper_title": "Network dissection: Quantifying interpretability of deep visual representations", "publication_date": "2017-00-00", "reason": "This paper introduces Network Dissection, a method to quantify the interpretability of deep visual representations, which is highly relevant to the paper's focus on concept bottleneck models and interpretability."}, {"fullname_first_author": "Ting Chen", "paper_title": "A simple framework for contrastive learning of visual representations", "publication_date": "2020-00-00", "reason": "This paper introduces a simple framework for contrastive learning, which is highly relevant to the paper's use of vision-language models to project images and text into a common embedding space."}, {"fullname_first_author": "Pang Wei Koh", "paper_title": "Concept bottleneck models", "publication_date": "2020-00-00", "reason": "This paper introduces concept bottleneck models (CBMs), which are the primary focus of the current paper's investigation and improvement."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a vision-language model that is used extensively in the current paper for concept discovery and classification."}, {"fullname_first_author": "Eric Jang", "paper_title": "Categorical reparametrization with gumbel-softmax", "publication_date": "2017-00-00", "reason": "This paper introduces the Gumbel-softmax trick, which is used in the current paper for handling the continuous relaxation of discrete random variables during training."}]}