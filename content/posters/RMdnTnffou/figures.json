[{"figure_path": "RMdnTnffou/figures/figures_4_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure shows the architecture of the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left panel details the Concept Discovery Block (CDB), a module that uses a Vision-Language Model (VLM) to compute the similarity between image features and concept embeddings.  A data-driven mechanism, based on a Bernoulli distribution, selects a sparse subset of concepts for each input image. The right panel presents the overall CF-CBM architecture, which uses two levels: a high-level that processes the entire image and a low-level that processes individual image patches. Each level incorporates a CDB. A hierarchical link between levels allows information sharing and allows the model to capture both coarse-grained and fine-grained information from the image.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_8_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure shows the architecture of the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left panel illustrates a Concept Discovery Block (CDB), a module that uses a Vision-Language Model (VLM) to compute image-concept similarities and then uses a data-driven Bayesian approach to select a sparse set of relevant concepts. The right panel shows the overall CF-CBM architecture, which consists of a high-level module processing the whole image and a low-level module processing image patches.  These modules are linked through binary indicators (ZH and ZL) representing concept activation at each level, allowing for a hierarchical and interpretable decision-making process.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_8_2.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure illustrates the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left panel shows a Concept Discovery Block (CDB), which computes concept similarities using a vision-language model and introduces a data-driven mechanism to select relevant concepts. The right panel presents a schematic of the CF-CBM architecture, which has two levels: high (whole image) and low (patches).  The high-level uses the CDB to identify relevant high-level concepts, while the low-level uses similar CDBs on image patches. A hierarchical structure links these levels, allowing information sharing and enhancing interpretability.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_9_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure illustrates the architecture of the proposed Coarse-to-Fine Concept Bottleneck Models (CF-CBMs). The left panel shows a Concept Discovery Block (CDB), which takes an image and a set of concepts as input, computes their similarity using a vision-language model (VLM), and uses a data-driven mechanism to discover relevant concepts. The right panel shows the overall CF-CBM architecture, which consists of two levels: a high level that processes the whole image, and a low level that processes individual patches of the image. Each level has its own CDB, and the two levels are linked together via binary indicators that represent the relevance of each concept to the downstream task.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_16_1.jpg", "caption": "Figure 5: Alignment between the inferred concept presence indicators and CLIP similarities on the High Level of the CF-CBM framework. We split the CLIP similarities into bins of size 0.05; in each bin we count the number of concepts assigned therein (according to their CLIP similarity and denoted by #Conc) and we compute the fraction of inferred active concepts to said number. We observe that in this case, the higher the similarity, concepts with high similarity value exhibit a largest percentage of activation.", "description": "This figure shows the relationship between CLIP similarity scores and the activation of concepts in the high level of the CF-CBM model.  The CLIP similarity scores are grouped into bins, and the percentage of activated concepts within each bin is plotted.  The graph shows that a higher CLIP similarity generally leads to a higher percentage of concept activation. This suggests that the model tends to prioritize concepts with higher similarity scores.", "section": "D Further Investigations and Qualitative Analyses"}, {"figure_path": "RMdnTnffou/figures/figures_16_2.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure illustrates the Concept Discovery Block (CDB), which is a core component of the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left panel shows how the CDB uses vision-language models (VLMs) to compute the similarity between an image and a set of concepts, and then employs a data-driven mechanism to discover the most relevant concepts via sampling from an amortized Bernoulli distribution. The right panel presents a schematic overview of the CF-CBM architecture.  It shows how the model incorporates a two-level hierarchy (high-level and low-level) for concept discovery, using the image as a whole for high-level concepts and dividing the image into patches for discovering lower-level concepts. These two levels are linked together using binary indicator variables that represent which concepts are active for a given input.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_17_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure illustrates the Concept Discovery Block (CDB) and a schematic of the proposed Coarse-to-Fine Concept Bottleneck Models (CF-CBMs). The CDB shows how image and concept similarities are computed using a Vision-Language Model (VLM), and how a data-driven Bayesian approach is used for concept discovery. The CF-CBM schematic illustrates a two-level hierarchical model: the high level considers the whole image, while the low level considers individual patches. Both levels use CDBs and are linked by binary indicators to allow for information sharing.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_17_2.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "The figure shows the architecture of the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM).  The left side details a Concept Discovery Block (CDB), illustrating how image and concept embeddings are used with a Bernoulli distribution to select relevant concepts. The right side presents a schematic of the CF-CBM, highlighting the two-level (high and low) hierarchical structure, where the high level processes the whole image and the low level processes individual patches, with both levels interacting through binary indicator variables.  The interaction facilitates information sharing between the levels to achieve more granular interpretations.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_18_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure illustrates the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left panel shows the Concept Discovery Block (CDB), a module that uses a vision-language model (VLM) to compute the similarity between concepts and an image and employs a data-driven mechanism to discover relevant concepts.  The right panel presents a schematic overview of the CF-CBM architecture.  It highlights a two-level hierarchical structure: a high level that processes the whole image and a low level that analyzes image patches. These levels are interconnected through binary indicators that control the flow of information and concept discovery between them, aiming for a more interpretable and fine-grained analysis.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_19_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure shows the architecture of the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left panel illustrates the Concept Discovery Block (CDB), a module that uses a vision-language model (VLM) to compute the similarity between images and concepts, and then uses a data-driven mechanism to discover the subset of relevant concepts. The right panel shows the overall architecture of the CF-CBM, which consists of two levels: a high-level that processes the whole image and a low-level that processes individual image patches. The two levels are linked together via binary indicators, allowing for information sharing between them. ", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_20_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure illustrates the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left side shows a Concept Discovery Block (CDB), which uses a vision-language model (VLM) to compute the similarity between an image and a set of concepts. A data-driven mechanism using an amortized Bernoulli posterior samples the relevant concepts. The right side presents a schematic of the CF-CBM framework, consisting of two levels: high and low. The high level models the whole image, while the low level models patch-specific regions.  The two levels are linked via binary indicators (ZH and ZL), allowing for information sharing and context between levels.  The low level uses an aggregation operation to combine the information from all patches.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_20_2.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure shows the architecture of the proposed Coarse-to-Fine Concept Bottleneck Models (CF-CBMs). The left panel illustrates the Concept Discovery Block (CDB), which is a key component of the CF-CBM framework. The CDB uses a Vision-Language Model (VLM) to compute the similarity between an image and a set of concepts. It then uses a data-driven mechanism to discover the subset of concepts that are relevant to the image. The right panel shows the overall architecture of the CF-CBMs. The CF-CBMs use a two-level hierarchy of concepts: a high-level set of concepts that describe the overall scene, and a low-level set of concepts that describe specific regions of the image. The two levels are linked together using binary indicators, which allow for information sharing between the two levels. The CF-CBMs are trained end-to-end to classify images based on both high-level and low-level concepts.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_21_1.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators ZH and ZL.", "description": "This figure shows the architecture of the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left panel illustrates the Concept Discovery Block (CDB), a module that uses vision-language models (VLMs) to compute image-concept similarities and employs a data-driven Bayesian approach to select a sparse subset of relevant concepts. The right panel provides a schematic overview of the CF-CBM, highlighting its two-level hierarchical structure (high-level for the whole image and low-level for image patches), the concept discovery mechanism at each level, and the information flow between the levels.", "section": "3 Coarse-to-fine CBM"}, {"figure_path": "RMdnTnffou/figures/figures_21_2.jpg", "caption": "Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the pool of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case P = 9, patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators Z<sub>H</sub> and Z<sub>L</sub>.", "description": "This figure shows the architecture of the proposed Coarse-to-Fine Concept Bottleneck Model (CF-CBM). The left side illustrates the Concept Discovery Block (CDB), a module that uses vision-language models (VLMs) to compute the similarity between an image and a set of concepts, and then uses a data-driven mechanism to discover a subset of relevant concepts. The right side shows the overall architecture of the CF-CBM, which consists of two levels: a high level that considers the whole image and a low level that considers individual patches of the image. The two levels are linked together by a concept hierarchy, which allows information sharing between the two levels. This allows the model to capture both high-level and low-level concept information for improved interpretability and performance.", "section": "3 Coarse-to-fine CBM"}]