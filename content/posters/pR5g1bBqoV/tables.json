[{"figure_path": "pR5g1bBqoV/tables/tables_7_1.jpg", "caption": "Table 1: (Layerwise perturbation scaling for effective perturbations in \u00b5P) Without layerwise perturbation scaling (left), each SAM variant perturbs a different subset of layers at large width n\u2192\u221e, but we provide the unique layerwise perturbation rescaling \u00b5P\u00b2 (right) that achieves effective perturbations in all layers. This parameterization transfers both the optimal \u03b7 and p across widths.", "description": "This table summarizes which layers are perturbed by different SAM variants under different parameterizations at large width n\u2192\u221e.  The left side shows the layers that are perturbed under global perturbation scaling without layerwise scaling. The right side shows which layers are effectively perturbed under \u00b5P\u00b2 with layerwise perturbation scaling.  The table highlights that \u00b5P\u00b2 uniquely achieves effective perturbations in all layers and transfers both optimal learning rate and perturbation radius across model widths.", "section": "4. Generalizations to other architectures and SAM variants"}, {"figure_path": "pR5g1bBqoV/tables/tables_9_1.jpg", "caption": "Table 2: (Performance of \u00b5P\u00b2) Average test accuracy+standard deviation across 4 runs (+ improvement of SAM over SGD) for ResNet-18 with width multiplier 4 on CIFAR10 using SGD as a base optimizer.", "description": "This table presents the average test accuracy and standard deviation obtained from four independent runs for ResNet-18 with a width multiplier of 4, trained on CIFAR10 using SGD as the base optimizer.  It also shows the improvement in test accuracy achieved by SAM compared to using SGD alone. The results are shown for various SAM parameterizations (SP and \u00b5P\u00b2) and variants (SAM-ON, elementwise ASAM).  This highlights the generalization performance of \u00b5P\u00b2.", "section": "4.3 Generalizations to other architectures and SAM variants"}, {"figure_path": "pR5g1bBqoV/tables/tables_15_1.jpg", "caption": "Table 1: (Layerwise perturbation scaling for effective perturbations in \u00b5P) Without layerwise perturbation scaling (left), each SAM variant perturbs a different subset of layers at large width n\u2192\u221e, but we provide the unique layerwise perturbation rescaling \u00b5P\u00b2 (right) that achieves effective perturbations in all layers. This parameterization transfers both the optimal \u03b7 and p across widths.", "description": "This table summarizes the effects of layerwise perturbation scaling on the behavior of different SAM variants in the infinite-width limit. The left side shows that without layerwise scaling, different SAM variants perturb different subsets of layers.  The right side shows that with the \u00b5P\u00b2 parameterization, which incorporates layerwise perturbation scaling, all layers are effectively perturbed, enabling transfer of optimal hyperparameters (learning rate \u03b7 and perturbation radius p) across different model widths.", "section": "4 Sharpness Aware Minimization in the infinite-width limit"}, {"figure_path": "pR5g1bBqoV/tables/tables_21_1.jpg", "caption": "Table D.1: (bc-parametrizations) Overview over common implicitly used bc-parameterizations for training MLPs without biases in standard parametrization (SP), standard parametrization with maximal stable nonadaptive LR c = 1 (SP (stable)), neural tangent parametrization (NTP) and maximal update parametrization (\u00b5P).", "description": "This table compares four different parameterizations of MLPs without biases: standard parameterization (SP), standard parameterization with maximal stable learning rate (SP (stable)), neural tangent parameterization (NTP), and maximal update parameterization (\u00b5P). For each parameterization, it shows the initialization of weights (b\u1d62), the learning rate scaling (c\u1d62), the maximal update scaling (r), whether the parameterization is stable, nontrivial, and whether it admits feature learning. The table provides a concise overview of various parameterization choices and their key characteristics, highlighting the differences in their ability to enable feature learning and stable training in the infinite-width limit.", "section": "Extensive main results"}, {"figure_path": "pR5g1bBqoV/tables/tables_21_2.jpg", "caption": "Table D.2: (Perturbation scalings) Overview over important choices of the global perturbation scaling pn\u2212d and the layerwise perturbation scalings n\u2212d\u03b9 for training MLPs without biases with SAM: Naive scaling without width dependence (Naive), maximal stable global scaling along the original gradient direction (Global) and the unique scaling that achieves effective perturbations in all layers (Effective). An extensive overview that characterizes all possible choices of perturbation scaling is provided in Appendix F.1. Recall the gradient scaling c\u2207 := min(bL+1, cL+1).", "description": "The table shows four regimes for choosing perturbation scalings. Naive scaling is unstable and does not perturb any layers effectively. Global scaling (stable) is stable, but only perturbs the last layer. Effective scaling is stable and perturbs all layers effectively.  The table provides a summary of different choices of layerwise perturbation scalings with their characteristics (stability, effective perturbations, etc.). It refers to a more detailed analysis in the appendix for further information.", "section": "Extensive main results"}, {"figure_path": "pR5g1bBqoV/tables/tables_35_1.jpg", "caption": "Table F.1: (Characterization of perturbation scalings) Overview over the regimes of all possible choices of d and d\u2081. A layer is effectively perturbed if and only if di satisfies (F.1). At least one layer must satisfy equality in its gradient norm constraint (D.1). This table summarizes which layers can exhibit effective perturbations, and which may dominate the gradient norm, given a choice of d. The choice d < -1/2 results in perturbation blowup r < 0. At the critical d = -1/2 (respectively, d = 0; d = 1/2) a input-like (respectively hidden-like; output-like) layer is effectively perturbed if and only if it dominates the gradient norm. Consequently d = -1/2 implies effective perturbations in at least one input-like layer.", "description": "This table shows the regimes of perturbation scaling for different choices of hyperparameters d and d\u2081, which control the stability and effectiveness of perturbations. The columns indicate whether effective perturbations are possible or if the gradient norm is dominated by each type of layer (input-like, hidden-like, output-like).  Each row represents a range of values for hyperparameter d, and the checkmarks and crosses indicate which layer types can support effective perturbations within that range. For instance, when d = -1/2, effective perturbations are possible for all layer types, while when d > 1/2, only the output layer can have effective perturbations. The gradient norm constraint (D.1) is related to the scaling behavior and stability of the model.", "section": "F Generalizations and further perturbation scaling considerations"}, {"figure_path": "pR5g1bBqoV/tables/tables_51_1.jpg", "caption": "Table G.1: (ResNet-18 hyperparameters for CIFAR10) Hyperparameters for SP are taken from M\u00fcller et al. (2024). Learning rate and perturbation radius are tuned using the experiments in Appendix H.3.2. ResNets in \u00b5P have base width 0.5, gradient norm scaling according to Definition 4 and their last layer is initialized to 0.", "description": "This table shows the hyperparameter settings used for training ResNet-18 on CIFAR10 dataset using different optimization methods.  It lists hyperparameters such as learning rate (LR), learning rate decay scheme, weight decay, momentum, label smoothing, perturbation radius (\u03c1), and output multiplier.  The values for the standard parameterization (SP) are taken from a previous work by M\u00fcller et al. (2024). For the maximal update parameterization (\u00b5P), the base width is set to 0.5.  The gradient norm scaling is adjusted according to the definition in the paper.  The last layer is initialized to 0.  The values for the perturbation radius (\u03c1) and learning rate (\u03b7) are tuned and reported in the paper.", "section": "G Experimental details"}, {"figure_path": "pR5g1bBqoV/tables/tables_51_2.jpg", "caption": "Table G.2: (Vision Transformer hyperparameters) Hyperparameters for SP are taken from M\u00fcller et al. (2024) using AdamW as a base optimizer. ViTs in \u00b5P have base width 384, last layer and query weights are initialized to 0 and gradient norm contributions of all layers are scaled to (1).", "description": "This table lists the hyperparameters used for training Vision Transformers (ViTs) with the standard parameterization (SP) and the proposed Maximal Update and Perturbation Parameterization (\u00b5P2).  It shows hyperparameters for training on both ImageNet1K and CIFAR100 datasets.  Note that the \u00b5P2 parameterization uses a base width of 384, initializes the last layer and query weights to 0, and scales the gradient norm contributions of all layers to 1.  The hyperparameters for SP are taken from M\u00fcller et al. (2024), while those for \u00b5P2 were tuned using 3 independent runs of Nevergrad NGOpt.", "section": "G Experimental details"}, {"figure_path": "pR5g1bBqoV/tables/tables_51_3.jpg", "caption": "Table G.3: (Training time per epoch) Training time (in seconds) per epoch of the entire data loading and training pipeline of SAM in \u00b5P\u00b2 on a single NVIDIA A10G GPU.", "description": "This table shows the training time per epoch for different model architectures and widths using SAM in the \u00b5P\u00b2 parameterization.  The architectures include ResNet-18 on CIFAR10 and Vision Transformers (ViTs) on CIFAR100 and ImageNet1K.  The time per epoch is shown for various width multipliers (0.5, 1, 2, 4).  This data provides insights into the computational cost of training these models with the proposed method.", "section": "G Experimental details"}]