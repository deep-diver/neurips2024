{"references": [{"fullname_first_author": "Pieter Abbeel", "paper_title": "Apprenticeship learning via inverse reinforcement learning", "publication_date": "2004-01-01", "reason": "This paper introduces a foundational concept of learning from expert demonstrations, which is a crucial aspect of safe reinforcement learning and is directly related to the imitation learning experiments in this paper."}, {"fullname_first_author": "Eitan Altman", "paper_title": "Constrained Markov decision processes", "publication_date": "2021-01-01", "reason": "This book provides a comprehensive overview of constrained Markov decision processes (CMDPs), the theoretical framework underlying the problem addressed in the paper."}, {"fullname_first_author": "Dimitri P Bertsekas", "paper_title": "Nonlinear programming", "publication_date": "1997-01-01", "reason": "This book is a fundamental resource for optimization theory, and its concepts are crucial for understanding the primal-dual method used in this paper."}, {"fullname_first_author": "Scott Fujimoto", "paper_title": "Off-policy deep reinforcement learning without exploration", "publication_date": "2019-01-01", "reason": "This paper presents a key algorithm for offline reinforcement learning, which directly addresses the challenges related to data efficiency and is highly relevant to the proposed method."}, {"fullname_first_author": "Jean-Baptiste Hiriart-Urruty", "paper_title": "Convex analysis and minimization algorithms I: Fundamentals", "publication_date": "1996-01-01", "reason": "This book provides fundamental theoretical underpinnings for convex analysis and optimization, which are essential to the theoretical analysis and algorithm design in this paper."}]}