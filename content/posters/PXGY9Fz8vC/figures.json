[{"figure_path": "PXGY9Fz8vC/figures/figures_1_1.jpg", "caption": "Figure 1: Left: Two agents with gaming deterrence parameters \u03bb\u2081 = 30 (purple) and \u03bb\u2082 = 50 (blue) maximize utility (reward R - cost c) with respect to diagnosis rate. Gaming costs increase in \u03bb(.), and lower an agent's optimal diagnosis rate (stars). Center: Agents' observed decisions reflect utility-maximizing behavior. Right: A decision-maker computes a payout based on agent decisions.", "description": "This figure illustrates the core concepts of the paper using a simplified example of two agents making decisions that affect their reward, influenced by a gaming deterrence parameter (\u03bb).  The left panel shows how the optimal diagnosis rate (the point where reward minus cost is maximized) varies based on the agent's willingness to game (\u03bb). The higher the \u03bb, the less willing they are to game (thus, the diagnosis rate is closer to the ground truth). The center panel shows the observed diagnosis decision made by each agent, reflecting the utility maximization behavior. The right panel shows how the decision maker computes the payout based on the agents' decisions.", "section": "Strategic adaptation with multiple agents"}, {"figure_path": "PXGY9Fz8vC/figures/figures_4_1.jpg", "caption": "Figure 2: Left: Toy dataset with observed factual outcomes di(p) and di(p'). \u201c?\u201d denotes missing counterfactual outcomes. Right: Causal graph for gaming detection with confounders xi, agent indicator pi, and agent decision di.", "description": "This figure demonstrates a toy dataset and causal graph to visualize the concept of causal effect estimation in detecting gaming behavior. The left panel presents a toy dataset with observed factual outcomes (di(p), di(p')) and missing counterfactual outcomes represented by question marks. The right panel illustrates a causal graph showing how confounders (xi), agent indicators (pi), and agent decisions (di) are related for causal effect estimation in identifying the agents who are gaming most aggressively.", "section": "4.2 Identifying a ranking of the gaming parameter"}, {"figure_path": "PXGY9Fz8vC/figures/figures_7_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal gaming detection approaches.  It presents three subplots: Top-5 sensitivity versus the number of agents audited, Discounted Cumulative Gain (DCG) versus the number of agents audited, and Top-5 sensitivity with 7 audits. The results show that causal effect estimators consistently outperform other methods, including baselines (naive approaches and anomaly detection methods) in terms of both sensitivity and DCG, especially when the number of audits is limited.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_8_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure displays the performance of causal and non-causal methods for gaming detection in terms of top-5 sensitivity and discounted cumulative gain (DCG), varying the number of agents audited.  The left and center panels show the overall performance, while the right panel focuses on the top-5 sensitivity when auditing only 7 agents. The results demonstrate that causal methods consistently outperform non-causal baselines, showcasing their efficiency in identifying gaming agents.", "section": "Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_19_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal gaming detection methods using two metrics: top-5 sensitivity and discounted cumulative gain (DCG).  The results are shown for different numbers of agents audited, with a specific focus on the top-5 sensitivity when auditing 7 agents.  The chart visually demonstrates that causal methods consistently outperform non-causal approaches across various auditing thresholds. The different symbols represent different types of approaches, with triangles representing naive baselines, circles representing anomaly detection methods, and crosses representing causal effect estimators.", "section": "Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_19_2.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for detecting gaming agents in a synthetic dataset.  The left panel shows the top-5 sensitivity (the percentage of the top 5 worst gaming agents correctly identified) across different numbers of agents audited, showing that causal methods are much better. The center panel shows the Discounted Cumulative Gain (DCG), a metric that rewards correctly identifying the worst offenders higher in the ranking. Again, causal methods perform better. The right panel is a zoomed-in view of the left panel, showing the top-5 sensitivity when only 7 agents are audited.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_19_3.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection using two metrics: Top-5 sensitivity and Discounted Cumulative Gain (DCG).  The results are shown for different numbers of agents audited and demonstrate the superiority of causal approaches in identifying the worst offenders. The plot shows that causal methods achieve significantly higher values for both sensitivity and DCG.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_22_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal gaming detection methods in terms of top-5 sensitivity and discounted cumulative gain (DCG) across different numbers of audited agents.  The causal methods consistently outperform the non-causal baselines, demonstrating their effectiveness in identifying the worst gaming offenders.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_22_2.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal gaming detection methods.  It shows the top-5 sensitivity (the percentage of the top 5 worst offenders correctly identified) and the discounted cumulative gain (DCG, a measure of ranking quality) across different numbers of agents audited.  The results indicate that causal methods significantly outperform non-causal methods (na\u00efve baselines and anomaly detection methods) in identifying the worst offenders.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_22_3.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection in a synthetic dataset.  The top-5 sensitivity shows the percentage of the top 5 worst offenders correctly identified by each method for a given number of audits. The discounted cumulative gain (DCG) is a metric that assesses the ranking quality of each method, giving higher weights to correctly identifying the worst offenders at the top of the ranking. The figure demonstrates that causal methods significantly outperform non-causal methods in terms of both top-5 sensitivity and DCG, especially when considering a limited number of audits. The findings suggest that causal effect estimation is more efficient for identifying gaming agents.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_22_4.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection in a synthetic dataset with a high level of confounding (mean range 0.9).  The left panel shows top-5 sensitivity, indicating the percentage of the top 5 worst offenders correctly identified by each method at different numbers of audits. The center panel displays the Discounted Cumulative Gain (DCG), a metric that weighs the accuracy of higher-ranked agents more heavily. The right panel shows the top-5 sensitivity specifically at 7 audits. The results demonstrate that causal effect estimators (marked with 'x') consistently outperform non-causal baselines (marked with '\u25bd' and 'o') in both sensitivity and DCG, indicating their superior ability to identify the most severe gaming cases with fewer audits.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_23_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection across different numbers of agents audited.  The left panel shows the top-5 sensitivity, which measures the percentage of the top 5 worst offenders correctly identified among the top k predicted offenders. The center panel shows the discounted cumulative gain (DCG), which measures the ranking quality based on the predicted and actual ranks of the worst offenders. The right panel focuses specifically on the top-5 sensitivity with 7 audits.  The results indicate that causal methods consistently outperform non-causal methods in both ranking quality and efficiency of detecting the worst offenders.", "section": "Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_23_2.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection across different numbers of agents audited.  The top-5 sensitivity measures the percentage of the top 5 worst offenders correctly identified among the top k agents. The DCG (Discounted Cumulative Gain) is another metric that weighs the rank of correctly identified offenders.  The plot shows that causal effect estimators (marked with an x) outperform both naive baselines (\u25bd) and anomaly detection methods (o) in terms of both top-5 sensitivity and DCG.  A separate plot on the right also shows that causal methods maintain their superiority even when only 7 agents are audited.", "section": "Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_23_3.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection across different numbers of agents audited. The results show that causal methods (represented by 'x') outperform non-causal methods (represented by '\u25bd' and 'o') in terms of both top-5 sensitivity (the percentage of the top 5 worst offenders correctly identified) and DCG (discounted cumulative gain, a measure of ranking quality). The right panel shows the top-5 sensitivity when only 7 agents are audited.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_23_4.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods in detecting gaming agents.  The x-axis represents the number of agents audited, while the y-axis shows the top-5 sensitivity (proportion of top 5 worst offenders correctly identified) and DCG (Discounted Cumulative Gain, measuring ranking quality). The figure demonstrates that causal effect estimators outperform both non-causal baselines (random and payout-only) and anomaly detection methods.", "section": "Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_24_1.jpg", "caption": "Figure 6: Area under the sensitivity curve (AUSC) for causal vs. non-causal methods across levels of confounding, with \u00b10 error. As confounding increases, a payout-only ranking degrades. Anomaly detection performance does not vary across confounding strength, maintaining slightly better than random rankings. Causal methods generally maintain higher mean AUSC than baselines across confounding levels. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure shows the area under the sensitivity curve (AUSC) for different gaming detection methods across various levels of confounding. It compares the performance of causal and non-causal methods, highlighting how causal methods generally maintain a higher AUSC than baselines across different levels of confounding, while anomaly detection methods exhibit performance close to random regardless of the confounding level. The figure also illustrates the degradation of the payout-only method's performance as confounding increases.", "section": "5.2 Gaming detection in synthetic data"}, {"figure_path": "PXGY9Fz8vC/figures/figures_25_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for detecting gaming agents.  The left panel shows the top-5 sensitivity, indicating the percentage of the top 5 worst gaming agents correctly identified. The center panel displays the Discounted Cumulative Gain (DCG), measuring the ranking quality. The right panel focuses on the top-5 sensitivity when only auditing 7 agents.  Across all metrics, causal methods consistently outperform non-causal approaches (naive baselines, anomaly detection, and payout-only).", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_25_2.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal effect estimators and non-causal baselines for gaming detection across different numbers of agents audited.  The left panel displays top-5 sensitivity, showing the percentage of times the top 5 true worst offenders were caught within the top k predicted offenders.  The center panel shows the discounted cumulative gain (DCG), a metric evaluating the ranking's overall effectiveness in identifying the worst offenders. The right panel shows the same top-5 sensitivity measure but focuses specifically on auditing 7 agents.  The results indicate that causal methods outperform non-causal approaches in gaming detection, especially when considering a limited number of audits.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_25_3.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal gaming detection approaches in terms of top-5 sensitivity and discounted cumulative gain (DCG) across different numbers of agents audited.  The results demonstrate that causal methods outperform non-causal baselines, especially in terms of identifying the top 5 worst offenders.", "section": "Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_26_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure displays the performance of causal and non-causal gaming detection methods across different numbers of agents audited. The performance is measured using two metrics: top-5 sensitivity and discounted cumulative gain (DCG). The left panel shows the top-5 sensitivity, which represents the percentage of the top five worst gaming agents that are correctly identified among the top k agents audited. The center panel shows the DCG, which weighs the importance of correctly ranking the worst offenders higher. The right panel shows the top-5 sensitivity specifically when only 7 agents are audited.  The results indicate that causal methods consistently outperform non-causal baselines in identifying and ranking the worst gaming agents.", "section": "Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_26_2.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal gaming detection methods across different numbers of agents audited.  The left panel shows the top-5 sensitivity, measuring the percentage of the top 5 worst offenders correctly identified. The center panel shows the discounted cumulative gain (DCG), a metric that rewards higher-ranked worst offenders.  The right panel shows a zoomed-in view of the top-5 sensitivity when only 7 agents are audited. The results demonstrate that causal effect estimation methods outperform non-causal baselines, particularly in terms of identifying the worst offenders using fewer audits.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_26_3.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection in a synthetic dataset with high confounding (mean range of 0.9). The left panel shows the top-5 sensitivity, which represents the percentage of the top 5 worst offenders correctly identified by the method. The center panel shows the discounted cumulative gain (DCG), a metric that considers the ranking of the agents. The right panel displays the top-5 sensitivity when only 7 agents are audited. The results indicate that causal methods (represented by \u00d7) generally outperform non-causal baselines (\u25bd and 0), especially in terms of identifying the worst offenders.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_26_4.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection in terms of top-5 sensitivity and discounted cumulative gain (DCG) across different numbers of agents audited.  The left panel shows top-5 sensitivity, which measures the percentage of the top 5 worst offenders correctly identified. The center panel shows DCG, which measures the ranking quality of top offenders. The right panel displays top-5 sensitivity when only 7 agents are audited.  The results indicate that causal methods (represented by 'x') outperform non-causal baselines (represented by '\u25bd' and 'o') in both metrics, highlighting their effectiveness in detecting gaming behavior.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_27_1.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure displays the results of comparing causal and non-causal methods for gaming detection.  The left panel shows the top-5 sensitivity, measuring the percentage of the top 5 worst offenders correctly identified among the top k agents audited. The center panel presents the Discounted Cumulative Gain (DCG), which weights the correctly identified worst offenders higher. Both metrics are plotted against the number of agents audited. The right panel shows top-5 sensitivity when auditing only 7 agents.  The results indicate that causal effect estimation methods outperform both naive and anomaly detection baselines across different metrics and audit levels.  The plot uses symbols to distinguish between different categories of methods (naive, anomaly detection, and causal).", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_27_2.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection in terms of top-5 sensitivity and discounted cumulative gain (DCG).  The x-axis represents the number of agents audited, and the y-axis shows the performance metrics.  The results demonstrate that causal methods outperform non-causal baselines, particularly as the number of audited agents increases. Three different performance metrics are presented, with error bars for each. Different symbols represent different gaming detection methods.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_27_3.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal methods for gaming detection across different numbers of agents audited.  Top-5 sensitivity measures the percentage of the top 5 worst offenders correctly identified among the top k agents. DCG (Discounted Cumulative Gain) weights higher-ranked offenders more heavily than lower-ranked offenders.  The results show causal methods generally outperform non-causal baselines in terms of both metrics.  The right panel shows the top-5 sensitivity when auditing only 7 agents.", "section": "5 Empirical results & discussion"}, {"figure_path": "PXGY9Fz8vC/figures/figures_27_4.jpg", "caption": "Figure 5: Mean top-5 sensitivity (left) and DCG (center) across # of agents audited, and top-5 sensitivity with 7 audits (right) at mean range 0.9, with \u00b10 error. Causal methods improve over non-causal baselines. \u25bd: na\u00efve baselines. 0: anomaly detectors. \u00d7: causal effect estimators.", "description": "This figure compares the performance of causal and non-causal gaming detection methods across different auditing thresholds.  The top-5 sensitivity measures the percentage of the five worst gaming agents correctly identified within the top-k ranked agents. Discounted Cumulative Gain (DCG) provides a weighted ranking score, giving higher weights to correctly ranking the worst agents higher. The figure shows that causal methods (marked with \u00d7) consistently outperform non-causal baselines (\u25bd and \u2218) across various auditing numbers, indicating their superior ability to effectively identify and rank the worst gaming agents. The right panel shows the top-5 sensitivity when 7 agents are audited.", "section": "5 Empirical results & discussion"}]