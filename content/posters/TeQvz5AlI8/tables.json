[{"figure_path": "TeQvz5AlI8/tables/tables_7_1.jpg", "caption": "Table 1: Average natural and robust accuracy (%) of ResNet-18 against l\u221e threat with e = 8/255 in 7 runs. The best results are boldfaced.", "description": "This table presents the average natural and robust accuracy of ResNet-18, a convolutional neural network model,  against different adversarial attacks.  The attacks use an L-infinity norm with a perturbation budget (epsilon) of 8/255. The table includes results for multiple attacks, and the best results are highlighted in bold. This data is used to compare the performance of DAT (Dual Adversarial Training), the proposed method,  against other state-of-the-art adversarial training techniques.", "section": "4.2 Comparison with Common Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_7_2.jpg", "caption": "Table 1: Average natural and robust accuracy (%) of ResNet-18 against l\u221e threat with  = 8/255 in 7 runs. The best results are boldfaced.", "description": "This table presents the average natural accuracy and robust accuracy achieved by different adversarial training methods using ResNet-18 on CIFAR-10 and CIFAR-100 datasets.  Robust accuracy is evaluated against four different adversarial attacks: FGSM, PGD-20, PGD-100, C&W\u221e, and AutoAttack (AA).  The best performing method for each metric is highlighted in bold.", "section": "4.2 Comparison with Common Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_8_1.jpg", "caption": "Table 3: The average experimental results for methods with complex strategies against l\u221e threat model with e = 8/255 in 7 runs. The best results are boldfaced.", "description": "This table compares the performance of DAT against other state-of-the-art methods that utilize complex training strategies such as AWP and SWA.  It shows the average robust accuracy of different models (ResNet-18 and WRN-34-10) trained on CIFAR-10 and CIFAR-100 datasets against PGD-20 and AA attacks. The best results for each metric are highlighted in bold.", "section": "4.3 Comparison with Complex Strategy Based Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_8_2.jpg", "caption": "Table 4: Results of ablation studies with ResNet-18 against l\u221e with \u20ac = 8/255 average in 7 runs.", "description": "This table presents the results of ablation studies conducted to analyze the impact of different components of the proposed DAT method on the model's performance.  The baseline represents the model's performance without any of the DAT components.  Subsequent rows show the impact of removing specific components (DjS loss, mix-up operation, split batch normalization, and the Adversarial Amplitude Generator) on the model's natural and robust accuracy (against PGD-20 and AA attacks) on CIFAR-10 and CIFAR-100 datasets.", "section": "4.4 Ablation Study"}, {"figure_path": "TeQvz5AlI8/tables/tables_15_1.jpg", "caption": "Table 1: Average natural and robust accuracy (%) of ResNet-18 against l\u221e threat with e = 8/255 in 7 runs. The best results are boldfaced.", "description": "This table presents the average natural and robust accuracy of ResNet-18 against different adversarial attacks (FGSM, PGD-20, PGD-100, C&W, and AutoAttack) with a perturbation budget of 8/255.  The results are averaged over 7 runs, and the best performance for each attack is highlighted in bold.  The table shows the model's performance on clean images (natural accuracy) and on adversarially perturbed images (robust accuracy), demonstrating the impact of adversarial training.", "section": "4.2 Comparison with Common Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_15_2.jpg", "caption": "Table 1: Average natural and robust accuracy (%) of ResNet-18 against l\u221e threat with = 8/255 in 7 runs. The best results are boldfaced.", "description": "This table presents the average natural and robust accuracy of ResNet-18 against different l\u221e-bounded adversarial attacks.  The results are obtained across seven independent runs, with the best performance for each metric highlighted in bold.  The attacks include Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD) with 20 and 100 iterations, Carlini and Wagner (C&W) attack, and AutoAttack (AA). The table helps compare the performance of the model in terms of natural accuracy (accuracy on clean images) and robustness to various attacks (accuracy on adversarially perturbed images).", "section": "4.2 Comparison with Common Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_18_1.jpg", "caption": "Table 5: Average experimental results of DAT with and without Mix-up on CIFAR-10 and CIFAR-100 with ResNet-18 and \\(\\epsilon = 8/255\\) in 7 runs.", "description": "The table shows the average natural and robust accuracy (%) of the DAT model with and without the amplitude mix-up operation on CIFAR-10 and CIFAR-100 datasets, using ResNet-18 as the model architecture and an \\(\\ell_\\infty\\) threat with \\(\\epsilon = 8/255\\).  The results are averaged over 7 runs.  It compares the performance of DAT with and without the amplitude mixing component, demonstrating the impact of this component on the model's performance against different attacks.", "section": "F Additional Results and Discussion"}, {"figure_path": "TeQvz5AlI8/tables/tables_21_1.jpg", "caption": "Table 6: The average experimental results for different augmentations against l\u221e threat model with\n\u20ac = 8/255 on CIFAR-10. #Aug. refers to the number of augmentation. The best results are boldfaced.", "description": "This table compares the performance of different data augmentation methods on CIFAR-10 using the WRN-28-10 architecture against an l\u221e-bounded threat with a perturbation budget of 8/255.  The methods include various combinations of data augmentation techniques, such as those from Rebuffi et al., Gowal et al., Wang et al., and IKL-AT. The table shows the natural accuracy and the robust accuracy against AutoAttack (AA) for each method.  The best results for each metric are highlighted in bold.", "section": "4.2 Comparison with Common Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_21_2.jpg", "caption": "Table 7: The average experimental results for different augmentations against l\u221e threat model with e = 8/255 on CIFAR-100. #Aug. refers to the number of augmentation. The best results are boldfaced.", "description": "This table shows the average natural and robust accuracy of different methods on CIFAR-100 using WideResNet-28-10 architecture against an l\u221e-bounded adversarial attack with a perturbation budget of 8/255.  The results are averaged over 7 runs.  The table compares the performance of various methods, including those using different data augmentation strategies.  The number of augmentations used by each method is indicated in the #Aug column.  The best results for each metric are highlighted in bold.", "section": "4.2 Comparison with Common Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_21_3.jpg", "caption": "Table 8: The average experimental results for different augmentations against l\u221e threat model with  = 8/255 in 7 runs. The best results are boldfaced.", "description": "This table presents the average experimental results of different data augmentation methods combined with the proposed AE generation strategy against the l\u221e threat model on CIFAR-10 and CIFAR-100 datasets. The results are obtained by averaging 7 runs, with the best results being boldfaced.  The augmentations include CutOut, CutMix, and AutoAugment. The table shows the natural accuracy and robust accuracy against PGD-20 and AA attacks for each augmentation strategy, allowing comparison with the proposed DAT (Dual Adversarial Training) method.", "section": "4.2 Comparison with Common Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_22_1.jpg", "caption": "Table 9: Time consumption (s) of each training epoch for different AT methods.", "description": "This table presents the time consumption in seconds for each training epoch across different adversarial training (AT) methods.  The methods compared are PGD-AT, TRADES, ST, SCARL, and the proposed DAT method.  The time is measured separately for the CIFAR-10 and CIFAR-100 datasets.", "section": "4.3 Comparison with Complex Strategy Based Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_23_1.jpg", "caption": "Table 10: Average experimental results of AAG with existing AT methods on CIFAR-10/100 with ResNet-18 and  = 8/255 in 7 runs.", "description": "This table presents the average experimental results of combining the proposed Adversarial Amplitude Generator (AAG) with existing adversarial training (AT) methods, specifically PGD-AT and TRADES, on the CIFAR-10 and CIFAR-100 datasets.  The results are evaluated using ResNet-18 and a perturbation budget of epsilon = 8/255. The table compares the natural accuracy and robust accuracy (against PGD-20 and AutoAttack) for each method, demonstrating the performance improvement achieved by incorporating the AAG into the AT process.", "section": "F.6 AAG with Existing AT Methods"}, {"figure_path": "TeQvz5AlI8/tables/tables_23_2.jpg", "caption": "Table 11: Average experimental results of different inputs of Gy with ResNet-18 and  \u2208 = 8/255 in 7 runs.", "description": "This table presents the average experimental results obtained using different inputs for the generator G\u03c8 in the proposed DAT method.  The experiments were conducted using ResNet-18 with an \ud835\udc59\u221e-bounded threat parameter  \u2208 = 8/255, and the results are averaged over 7 runs.  Three input variations were tested: using only the noise vector z; using z plus a one-hot label; and using z plus the logits. The table shows the natural accuracy and robustness against PGD-20 and AA attacks for CIFAR-10 and CIFAR-100 datasets.", "section": "F Additional Results and Discussion"}, {"figure_path": "TeQvz5AlI8/tables/tables_24_1.jpg", "caption": "Table 12: Average experimental results with single and dual AE on CIFAR-10 and CIFAR-100 with ResNet-18 and  = 8/255 in 7 runs.", "description": "This table compares the performance of the DAT model using single and dual AE generation strategies.  It shows the natural accuracy, and robust accuracy against PGD-20 and AA attacks on CIFAR-10 and CIFAR-100 datasets using the ResNet-18 model. The results are averaged over 7 runs, with the perturbation budget set to \u03f5 = 8/255.  The comparison highlights the impact of using dual AE generation versus single AE generation on the model's performance.", "section": "F.8 Single AE Generation of DAT"}]