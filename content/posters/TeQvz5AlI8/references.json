{"references": [{"fullname_first_author": "Aleksander Madry", "paper_title": "Towards deep learning models resistant to adversarial attacks", "publication_date": "2018-00-00", "reason": "This paper is foundational in the field of adversarial robustness, introducing the concept and methodology of adversarial training that is central to the current paper's approach."}, {"fullname_first_author": "Ian J. Goodfellow", "paper_title": "Explaining and harnessing adversarial examples", "publication_date": "2015-00-00", "reason": "This seminal paper introduced the concept of adversarial examples and their importance in understanding the vulnerabilities of deep neural networks, which is the core problem addressed in this paper."}, {"fullname_first_author": "Leslie Rice", "paper_title": "Overfitting in adversarially robust deep learning", "publication_date": "2020-07-13", "reason": "This paper addresses a key challenge in adversarial training, namely, robust overfitting, which is relevant to the techniques and results presented in the current paper."}, {"fullname_first_author": "Guangyao Chen", "paper_title": "Amplitude-phase recombination: Rethinking robustness of convolutional neural networks in frequency domain", "publication_date": "2021-10-17", "reason": "This work explores the impact of adversarial attacks on the frequency domain of images, specifically focusing on the phase and amplitude components, which directly motivates the current paper's focus on the frequency domain."}, {"fullname_first_author": "Hongyang Zhang", "paper_title": "Theoretically principled trade-off between robustness and accuracy", "publication_date": "2019-06-09", "reason": "This paper provides a theoretical framework for understanding the trade-off between adversarial robustness and accuracy, which is relevant to the optimization strategy and theoretical analysis presented in the current paper."}]}