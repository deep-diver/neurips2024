[{"figure_path": "YjZ6fQAvT7/tables/tables_6_1.jpg", "caption": "Table 1: Estimated lower bounds (ELBO) of VAE with posterior distributions approximation by mean-field distributions, tree structures T1 and T2, as well as their mixture model MTreeVI(T1,T2), compared to ground truth log-likelihood log p(X).", "description": "This table presents the estimated lower bounds (ELBO) of a variational autoencoder (VAE) model using different posterior distribution approximations.  The methods compared include mean-field, TreeVI with two different tree structures (T1 and T2), and MTreeVI (a mixture of T1 and T2). The results are compared against the ground truth log-likelihood (log p(X)) to evaluate the accuracy of the approximations. Lower ELBO values indicate a less accurate approximation of the true posterior.", "section": "4.1 Synthetic VAE"}, {"figure_path": "YjZ6fQAvT7/tables/tables_7_1.jpg", "caption": "Table 2: Clustering performances (%) of our proposed methods TreeVI and MTreeVI compared with baselines. Means and standard deviations are computed across 10 runs with different random initializations. \u2020 Results taken from DC-GMM [24]", "description": "This table presents the clustering performance comparison of TreeVI and MTreeVI against several baseline methods on four datasets: MNIST, Fashion MNIST, Reuters, and STL-10.  The metrics used are Accuracy (ACC), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI).  The results are averaged over 10 runs with different random initializations, highlighting the stability and effectiveness of TreeVI and MTreeVI.", "section": "4.2 Constrained Clustering"}, {"figure_path": "YjZ6fQAvT7/tables/tables_9_1.jpg", "caption": "Table 3: Synthetic user matching test RR", "description": "This table presents the results of a synthetic user matching experiment.  The test metric is Reciprocal Rank (RR), which measures the ranking of the correct match in the list of candidates.  The table compares the performance of different methods: VAE, CVAE (independent and correlated versions), TreeVI (single tree), and MTreeVI (multiple trees).  Lower values indicate better performance.  The results show that the TreeVI and MTreeVI models significantly outperform baselines, demonstrating the effectiveness of capturing instance-level correlations in the posterior distribution.", "section": "4.3 User Matching"}, {"figure_path": "YjZ6fQAvT7/tables/tables_9_2.jpg", "caption": "Table 4: Link prediction test Normalized CRR", "description": "This table presents the results of a link prediction task on the Epinions dataset.  The Normalized Cumulative Reciprocal Rank (NCRR) metric is used to evaluate the performance of various methods.  Lower NCRR indicates better prediction performance. The methods compared include VAE, GraphSAGE, CVAE with independent and correlated latent variables, and the proposed TreeVI and MTreeVI methods. The results show that TreeVI and MTreeVI outperform the baseline methods.", "section": "4.4 Link Prediction"}, {"figure_path": "YjZ6fQAvT7/tables/tables_18_1.jpg", "caption": "Table 2: Clustering performances (%) of our proposed methods TreeVI and MTreeVI compared with baselines. Means and standard deviations are computed across 10 runs with different random initializations. \u2020 Results taken from DC-GMM [24]", "description": "This table compares the clustering performance of TreeVI and MTreeVI with several baseline methods on four datasets: MNIST, Fashion MNIST, Reuters, and STL-10.  The performance is measured using three metrics: Accuracy (ACC), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI).  The table shows the mean and standard deviation of each metric across 10 runs, each with different random initializations.  The results highlight the improvement achieved by TreeVI and MTreeVI over other methods in capturing instance-level correlation.", "section": "4.2 Constrained Clustering"}, {"figure_path": "YjZ6fQAvT7/tables/tables_18_2.jpg", "caption": "Table 5: Constrained clustering accuracies (%) on the MNIST dataset, with random tree or greedy-searched tree initializations, with or without our constrained optimization", "description": "This table presents the clustering accuracy results on the MNIST dataset using TreeVI with two different tree structure initialization methods (random tree and greedy search) and with/without constrained optimization.  It demonstrates the impact of initialization and the effectiveness of the constrained optimization on model performance.", "section": "4.2 Constrained Clustering"}, {"figure_path": "YjZ6fQAvT7/tables/tables_21_1.jpg", "caption": "Table 6: Hyperparameters setting of constrained clustering task.", "description": "This table shows the hyperparameter settings used for the constrained clustering task.  It lists the batch size, number of epochs, learning rate, decay rate, and epochs decay for four different datasets: MNIST, fMNIST, Reuters, and STL-10.  These hyperparameters were used to train the constrained clustering models using the proposed TreeVI and MTreeVI methods, as well as baseline methods. The consistent hyperparameter settings across datasets facilitated fair comparison between the proposed method and the baselines.", "section": "4.2 Constrained Clustering"}, {"figure_path": "YjZ6fQAvT7/tables/tables_22_1.jpg", "caption": "Table 7: Estimated lower bounds (ELBO) of VAE with posterior distributions approximation by mean-field, tree-structured, and mixture-of-trees distributions, compared to ground truth log-likelihood log p(X).", "description": "This table presents the ELBO (evidence lower bound) values obtained using various methods for approximating the posterior distribution in a variational autoencoder (VAE) model.  The methods compared are mean-field, TreeVI with a single tree, and MTreeVI with multiple trees (2 and 3 trees). The results are compared to the actual log-likelihood (log p(X)) to evaluate the accuracy of the approximation.", "section": "4.1 Synthetic VAE"}, {"figure_path": "YjZ6fQAvT7/tables/tables_22_2.jpg", "caption": "Table 2: Clustering performances (%) of our proposed methods TreeVI and MTreeVI compared with baselines. Means and standard deviations are computed across 10 runs with different random initializations. \u2020 Results taken from DC-GMM [24]", "description": "This table presents the clustering performance comparison among different methods on four datasets: MNIST, Fashion MNIST, Reuters, and STL-10.  The metrics used are accuracy (ACC), normalized mutual information (NMI), and adjusted rand index (ARI).  The results are averaged over 10 runs with different random initializations, showcasing the performance of TreeVI and MTreeVI against various baseline constrained clustering methods.", "section": "4.2 Constrained Clustering"}]