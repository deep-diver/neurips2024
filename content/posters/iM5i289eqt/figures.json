[{"figure_path": "iM5i289eqt/figures/figures_1_1.jpg", "caption": "Figure 1: Shows the edited masks from the first stage and the corresponding images generated in the second stage. In the examples, we transformed the viewpoint of park benches and tables from a frontal view to a top-down view and edited their shapes, changing park benches from curved to square edges and tables from square to circular shapes.", "description": "This figure shows examples of how the MaskFactory approach edits masks and generates corresponding images.  The first row demonstrates rigid mask editing, changing the viewpoint of park benches and tables. The second row shows non-rigid mask editing, altering the shape of the same objects.  The figure showcases the ability of MaskFactory to perform both viewpoint transformations (rigid) and shape alterations (non-rigid) while maintaining high-quality results.", "section": "1 Introduction"}, {"figure_path": "iM5i289eqt/figures/figures_2_1.jpg", "caption": "Figure 2: Workflow of MaskFactory. In the first stage, we generate new masks by applying rigid and non-rigid editing to the existing ground truth masks. In the second stage, we use the generated masks and their corresponding extracted Canny edges as conditions, along with a prompt representing the category, to generate RGB images. This process forms paired data for our generative model.", "description": "This figure illustrates the two-stage process of MaskFactory.  Stage 1 involves mask editing, using both rigid (viewpoint changes) and non-rigid (shape alterations) methods, guided by prompts.  Stage 2 uses the edited masks and Canny edge detection to generate realistic RGB images using a multi-conditional control generation approach.", "section": "3 Method"}, {"figure_path": "iM5i289eqt/figures/figures_5_1.jpg", "caption": "Figure 3: compared with baseline methods", "description": "This figure compares the results of MaskFactory with two baseline methods, DatasetDM and DatasetDiffusion, on generating images and masks for five different object categories: bed, fan, bicycle, gate, and bench. For each category, it shows the raw image, the result from MaskFactory, the result from DatasetDM, and the result from DatasetDiffusion. This allows for a visual comparison of the quality and diversity of the generated data across different methods.", "section": "4 Experiment and Results"}, {"figure_path": "iM5i289eqt/figures/figures_8_1.jpg", "caption": "Figure 4: UMAP Distribution Differences", "description": "This figure visualizes the differences in the UMAP distributions of generated mask images and corresponding RGB images between MaskFactory (with rigid, non-rigid, and mixed editing methods) and two baseline methods (DatasetDM and DatasetDiffusion). The plots show that MaskFactory, especially the mixed editing method, generates mask and image distributions that are closer to the ground truth (GT) distribution compared to the baseline methods. This demonstrates that MaskFactory produces more realistic and diverse datasets.", "section": "4 Experiment and Results"}, {"figure_path": "iM5i289eqt/figures/figures_8_2.jpg", "caption": "Figure 4: UMAP Distribution Differences", "description": "This figure visualizes the differences in the UMAP distribution of generated mask images and corresponding RGB images between MaskFactory (rigid, non-rigid, and mix), DatasetDM, and DatasetDiffusion.  The UMAP plots show the distribution of features extracted from the generated and ground truth images, highlighting the difference in feature space distribution among different methods. The plots visually demonstrate that MaskFactory achieves a feature distribution that more closely aligns with that of real images compared to the baseline methods. This supports the claim that MaskFactory generates more realistic and diverse synthetic datasets.", "section": "4 Experiment and Results"}, {"figure_path": "iM5i289eqt/figures/figures_15_1.jpg", "caption": "Figure 5: Visual results of common object mask editing. The model demonstrates strong topological structure preservation and diverse editing outcomes with both rigid and non-rigid edits.", "description": "This figure shows visual results of applying both rigid and non-rigid mask editing methods on various common objects, such as chairs, tables, bags, etc.  The results demonstrate the model's ability to generate diverse editing outcomes while preserving the topological structure of the original masks. This highlights the effectiveness of the MaskFactory's approach in generating realistic and diverse synthetic data for dichotomous image segmentation tasks.", "section": "D Visualization of the results using two editing methods from MaskFactory"}, {"figure_path": "iM5i289eqt/figures/figures_16_1.jpg", "caption": "Figure 6: Visual results of fine-grained object mask editing. The model successfully edits complex structures without compromising the original mask\u2019s semantic information.", "description": "This figure shows examples of fine-grained object mask editing using MaskFactory.  The results demonstrate the model's ability to handle complex shapes and details while maintaining the original mask's semantic information.  It showcases both rigid (viewpoint changes) and non-rigid (shape modifications) editing, highlighting the method's ability to preserve structural integrity during complex edits.", "section": "D Visualization of the results using two editing methods from MaskFactory"}, {"figure_path": "iM5i289eqt/figures/figures_17_1.jpg", "caption": "Figure 7: Canny condition visual results. The generated images show improved boundary precision and better structural coherence.", "description": "This figure shows the results of adding Canny edge detection as a constraint to the image generation process. The images generated with Canny edge detection show improved boundary precision and better structural coherence compared to the images generated without it.", "section": "3.3 Image Generation Stage"}, {"figure_path": "iM5i289eqt/figures/figures_17_2.jpg", "caption": "Figure 8: Topological Structure Visualization. The visualizations demonstrate the model's ability to maintain and manipulate topology during the editing process.", "description": "This figure visualizes the topological structure preservation capabilities of the MaskFactory model during the mask editing process. It showcases how the model maintains the original topological structure (connectivity of shapes) of masks even after applying both rigid (viewpoint changes) and non-rigid (shape deformations) transformations. The consistency in connectivity between the original and modified masks highlights the model's ability to generate high-quality synthetic data with accurate topological information for the DIS task.", "section": "D.4 Topological Structure Visualization"}]