[{"type": "text", "text": "Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Huizhuo Yuan\u2217 Zixiang Chen\u2217 Kaixuan Ji\u2217Quanquan Gu ", "page_idx": 0}, {"type": "text", "text": "Department of Computer Science University of California, Los Angeles Los Angeles, CA 90095 {hzyuan,chenzx19,kaixuanji,qgu}@cs.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Fine-tuning Diffusion Models remains an underexplored frontier in generative artificial intelligence (GenAI), especially when compared with the remarkable progress made in fine-tuning Large Language Models (LLMs). While cutting-edge diffusion models such as Stable Diffusion (SD) and SDXL rely on supervised fine-tuning, their performance inevitably plateaus after seeing a certain volume of data. Recently, reinforcement learning (RL) has been employed to fine-tune diffusion models with human preference data, but it requires at least two images (\u201cwinner\u201d and \u201closer\u201d images) for each text prompt. In this paper, we introduce an innovative technique called self-play fine-tuning for diffusion models (SPINDiffusion), where the diffusion model engages in competition with its earlier versions, facilitating an iterative self-improvement process. Our approach offers an alternative to conventional supervised fine-tuning and RL strategies, significantly improving both model performance and alignment. Our experiments on the Picka-Pic dataset reveal that SPIN-Diffusion outperforms the existing supervised finetuning method in aspects of human preference alignment and visual appeal right from its first iteration. By the second iteration, it exceeds the performance of RLHF-based methods across all metrics, achieving these results with less data. Codes are available at https://github.com/uclaml/SPIN-Diffusion/. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Diffusion models (Ho et al., 2020; Peebles and Xie, 2023; Podell et al., 2023; Nichol et al., 2021; Rombach et al., 2022a; Song et al., 2020a) have rapidly emerged as critical entities within the realm of generative AIs (Creswell et al., 2018; Kingma and Welling, 2013), demonstrating exceptional capabilities in generating high-fidelity outputs. Their versatility spans a diverse area of applications, ranging from image generation (Rombach et al., 2022a; Podell et al., 2023; Ramesh et al., 2022) to more complex tasks like structure-based drug design (Corso et al., 2022; Guan et al., 2023), protein structure prediction (Watson et al., 2021), text generation (Austin et al., 2021; Zheng et al., 2023; Chen et al., 2023), and more. Prominent diffusion models in image generation, including DALL-E (Ramesh et al., 2022), Stable Diffusion (Rombach et al., 2022b), SDXL (Podell et al., 2023), and Dreamlike, etc., typically undergo a fine-tuning process following their initial pre-training phase. ", "page_idx": 0}, {"type": "text", "text": "Standard fine-tuning method for diffusion models suffers from low alignment with human preferences and low data efficiency due to two main reasons: (1) it does not directly optimize for alignment with human preferences, and (2) only one round of training can be performed. Recently, using Reinforcement Learning (RL) for fine-tuning diffusion models has received increasing attention. Lee et al. (2023) first studied the alignment of text-image diffusion models to human preferences using reward-weighted likelihood maximization with a reward function trained on human preference data. ", "page_idx": 0}, {"type": "text", "text": "Black et al. (2023) formulated the fine-tuning of diffusion models as a RL problem solved by policy gradient optimization. In a concurrent work, Fan et al. (2023) studied a similar formulation but with a KL regularization. Very recently, Wallace et al. (2023) have bypassed the need for training reward functions by using Direct Preference Optimization (DPO) (Rafailov et al., 2023) for fine-tuning diffusion models. Similar approach was proposed in Yang et al. (2023) as well. ", "page_idx": 1}, {"type": "text", "text": "While RL fine-tuning of diffusion methods has been proven effective, its dependency on human preference data, often necessitating multiple images per prompt, poses a significant challenge. In many datasets including the community-sourced ones featuring custom content, it is often the case to have only one image associated with each prompt. This makes RL fine-tuning infeasible. ", "page_idx": 1}, {"type": "text", "text": "In this paper, drawing inspiration from the recently proposed self-play fine-tuning (SPIN) technique (Chen et al., 2024) for large language models (LLM), we introduce a new supervised fine-tuning (SFT) method for diffusion models, eliminating the necessity for human preference data in the fine-tuning process. Central to our method is a general-sum minimax game, where both the participating players, namely the main player and the opponent player, are diffusion models. The main player\u2019s goal is to discern between samples drawn from the target data distribution and those generated by the opponent player. The opponent player\u2019s goal is to garner the highest score possible, as assessed by the main player. A self-play mechanism can be made possible, if and only if the main player and the opponent player have the same structure, and therefore the opponent player can be designed to be previous copies of the main player (Chen et al., 2024). The proposed algorithm SPIN-Diffusion overcomes the drawbacks of both supervised fine-tuning (SFT) and RL fine-tuning. Compared with SFT, our method is more data-efficient, by repeatedly using the prompts from the SFT dataset to improve the model through self-play. Compared with RL fine-tuning methods, our method does not need external reward models or expensive human-annotated winner/loser pairs. ", "page_idx": 1}, {"type": "text", "text": "When applying the self-play fine-tuning technique (Chen et al., 2024) to diffusion models, there are two challenges: (a) an exponential or even infinite number of possible trajectories can lead to the same image. The generator in a diffusion model operates through a sequence of intermediate steps, but the performance of the generator is only determined by the quality of the image in the last step; and (b) diffusion models are parameterized by a sequence of score functions, which are the gradient of the probabilities rather than probabilities in LLMs. Our algorithm design effectively surmounts these challenges by (a) designing an objective function that considers all intermediate images generated during the reverse sampling process; and (b) decomposing and approximating the probability function step-by-step into products related to the score function. We also employ the Gaussian reparameterization technique in DDIM (Song et al., 2020a) to support the advanced sampling method. All these techniques together lead to an unbiased objective function that can be effectively calculated based on intermediate samples. For computational efficiency, we further propose an approximate objective function, which eliminates the need for intermediate images used in our model. ", "page_idx": 1}, {"type": "text", "text": "Contributions. Our contributions are summarized below: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a novel fine-tuning method for diffusion models based on the self-play mechanism, called SPIN-Diffusion. The proposed algorithm iteratively improves upon a diffusion model until converging to the target distribution. Theoretically, we prove that the model obtained by SPIN-Diffusion cannot be further improved via standard SFT. Moreover, the stationary point of our self-play mechanism is achieved when the diffusion model aligns with the target distribution. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Empirically, we evaluate the performance of SPIN-Diffusion on text-to-image generation tasks (Ramesh et al., 2022; Rombach et al., $2022\\mathbf{a}$ ; Saharia et al., 2022a). Our experiments on the Pick-a-Pic dataset (Kirstain et al., 2023), with base model being Stable Diffusion-1.5 (Rombach et al., 2022b), demonstrate that SPIN-Diffusion surpasses SFT from the very first iteration. Notably, by the second iteration, SPIN-Diffusion outperforms Diffusion-DPO (Wallace et al., 2023) that utilizes additional data from \u2018loser\u2019 samples. By the third iteration, the images produced by SPIN-Diffusion achieve a higher PickScore (Kirstain et al., 2023) than the base model SD-1.5 $79.8\\%$ of the times, and a superior Aesthetic score $88.4\\%$ of the times. ", "page_idx": 1}, {"type": "text", "text": "SPIN-Diffusion exhibits a remarkable performance improvement over current state-of-the-art finetuning algorithms, retaining this advantage even against models trained with more extensive data usage. This highlights its exceptional efficiency in dataset utilization. It is beneficial for the general public, particularly those with restricted access to datasets containing multiple images per prompt. ", "page_idx": 1}, {"type": "text", "text": "Notation. We use lowercase letters and lowercase boldface letters to denote scalars and vectors, respectively. We use $0:T$ to denote the index set $\\{0,\\ldots,T\\}$ . In the function space, let $\\mathcal{F}$ be the function class. We use the symbol $\\mathbf{q}$ to denote the real distribution in a diffusion process, while $\\mathbf{p}_{\\theta}$ represents the distribution parameterized by a nueral network during sampling. The Gaussian distribution is represented as $\\bar{\\mathcal{N}}({\\boldsymbol{\\mu}},{\\boldsymbol{\\Sigma}})$ , where $\\pmb{\\mu}$ and $\\Sigma$ are the mean and covariance matrix, respectively. Lastly, Uniform $\\{1,\\ldots,T\\}$ denotes the uniform distribution over the set $\\{1,\\ldots,T\\}$ . ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Diffusion Models. Diffusion-based generative models (Sohl-Dickstein et al., 2015) have recently gained prominence, attributed to their ability to produce high-quality and diverse samples. A popular diffusion model is denoising diffusion probabilistic modeling (DDPM) (Ho et al., 2020). Song et al. (2020a) proposed a denoising diffusion implicit model (DDIM), which extended DDPM to a nonMarkov diffusion process, enabling a deterministic sampling process and the accelerated generation of high-quality samples. In addition to DDPM and DDIM, diffusion models have also been studied with a score-matching probabilistic model using Langevin dynamics (Song and Ermon, 2019; Song et al., 2020b). Diffusion models evolved to encompass guided diffusion models, which are designed to generate conditional distributions. When the conditioning input is text and the output is image, these models transform into text-to-image diffusion models (Rombach et al., 2022a; Ramesh et al., 2022; Ho et al., 2022; Saharia et al., 2022b). They bridge the gap between textual descriptions and image synthesis, offering exciting possibilities for content generation. A significant advancement in text-to-image generation is the introduction of Stable Diffusion (SD) (Rombach et al., 2022a). SD has expanded the potential of diffusion models by integrating latent variables into the generation process. This innovation in latent diffusion models enables the exploration of latent spaces and improves the diversity of generated content. Despite the introduction of latent spaces, generating images with desired content from text prompts remains a significant challenge (Gal et al., 2022; Ruiz et al., 2023). This is due to the difficulty in learning the semantic properties of text prompts with limited high-quality data. ", "page_idx": 2}, {"type": "text", "text": "Fine-Tuning Diffusion Models. Efforts to improve diffusion models have focused on aligning them more closely with human preferences. Rombach et al. (2022a) fine-tuned a pre-trained model using the COCO dataset (Caesar et al., 2018), demonstrating superior performance compared to a generative model directly trained on the same dataset. Podell et al. (2023) expanded the model size of Stable Diffusion (SD) to create the SDXL model, which was fine-tuned on a high-quality but private dataset, leading to a significant improvement in the aesthetics of the generated images. Dai et al. (2023) further demonstrated the effectiveness of fine-tuning and highlighted the importance of the supervised fine-tuning (SFT) dataset. In addition to using datasets with high-quality images, Betker et al. (2023); Segalis et al. (2023) found that SFT on a data set with high text fidelity can also improve the performance of the diffusion model. The aforementioned methods only requires a high-quality SFT dataset. Recently, preference datasets have been studied in finetuing diffusion models (Lee et al., 2023). Concurrently, DDPO (Black et al., 2023) and DPOK (Fan et al., 2023) proposed to use the preference dataset to train a reward model and then fine-tune diffusion models using reinforcement learning. Drawing inspiration from the recent Direct Preference Optimization (DPO) (Rafailov et al., 2023), Diffusion-DPO (Wallace et al., 2023) and D3PO (Yang et al., 2023) used the implicit reward to fine-tune diffusion models directly on the preference dataset. Furthermore, when a differentiable reward model is available, Clark et al. (2023); Prabhudesai et al. (2023) applied reward backpropagation for fine-tuning diffusion models. Our SPIN-Diffusion is most related to the SFT method, as it only assumes access to high-quality image-text pairs. However, the high-quality image-text dataset can be obtained from various sources, including selecting the winner from a preference dataset or identifying high-reward image-text pairs through a reward model. ", "page_idx": 2}, {"type": "text", "text": "3 Problem Setting and Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we introduce basic settings for text-to-image generation by diffusion models and the self-play fine-tuning (SPIN) method. ", "page_idx": 2}, {"type": "text", "text": "3.1 Text-to-Image Diffusion Model ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Denoising diffusion implicit models (DDIM) (Song et al., 2020a) is a generalized framework of denoising diffusion probabilistic models (DDPM) (Sohl-Dickstein et al., 2015; Ho et al., 2020). DDIM enables the fast generation of high-quality samples and has been widely used in text-to-image diffusion models such as Stable Diffusion (Rombach et al., 2022a). We formulate our method building upon DDIM, which makes it more general. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Forwrd Process. Following Saharia et al. (2022b), the problem of text-to-image generation can be formulated as conditional diffusion models. We use $\\mathbf{x}_{0}^{\\bar{}{}}\\in\\mathbb{R}^{d}$ to denote the value of image pixels where $d$ is the dimension and use c to denote the text prompt. Given a prompt $\\mathbf{c}$ , image $\\mathbf{x}_{\\mathrm{0}}$ is drawn from a target data distribution $p_{\\mathrm{data}}(\\cdot|\\mathbf{c})$ . The diffusion process is characterized by the following dynamic parameterized by a positive decreasing sequence $\\{\\alpha_{t}\\}_{t=1}^{T}$ with $\\alpha_{0}=1$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\nq(\\mathbf{x}_{1:T}|\\pmb{x}_{0}):=q(\\mathbf{x}_{T}|\\mathbf{x}_{0})\\prod_{t=2}^{T}q(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $q\\big(\\mathbf{x}_{t-1}\\big|\\mathbf{x}_{t},\\mathbf{x}_{0}\\big)$ represents a Gaussian distribution $\\mathcal{N}(\\mu_{t},\\sigma_{t}^{2}\\mathbf{I})$ . Here, $\\pmb{\\mu}_{t}$ is the mean of Gaussian defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mu_{t}:=\\sqrt{\\alpha_{t-1}}\\mathbf{x}_{0}+\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\cdot\\frac{\\mathbf{x}_{t}-\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}}{\\sqrt{1-\\alpha_{t}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "It can be derived from (3.1) that $q(\\mathbf{x}_{t}|\\mathbf{x}_{0})=\\mathcal{N}(\\sqrt{\\alpha_{t}}\\mathbf{x}_{0},(1-\\alpha_{t})\\mathbf{I})$ for all $t$ (Song et al., 2020a). As a generalized diffusion process of DDPM, (3.1) reduces to DDPM (Ho et al., 2020) with a special choice of $\\sigma_{t}=\\sqrt{(1-\\alpha_{t-1})/(1-\\alpha_{t})}\\sqrt{(1-\\alpha_{t}/\\alpha_{t-1})}.$ . ", "page_idx": 3}, {"type": "text", "text": "Generative Process. Given the sequence of $\\{\\alpha_{t}\\}_{t=1}^{T}$ and $\\{\\sigma_{t}\\}_{t=1}^{T}$ , examples from the generative model follows ", "page_idx": 3}, {"type": "equation", "text": "$$\np_{\\theta}(\\mathbf{x}_{0:T}|\\mathbf{c})=\\prod_{t=1}^{T}p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{c})\\cdot p_{\\theta}(\\mathbf{x}_{T}|\\mathbf{c}),\\qquad p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{c})=\\mathcal{N}\\big(\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t),\\sigma_{t}^{2}\\mathbf{I}\\big).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here $\\pmb{\\theta}$ belongs to the parameter space $\\Theta$ and $\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)$ is the estimator of mean $\\pmb{\\mu}_{t}$ that can be reparameterized (Ho et al., 2020; Song et al., 2020a) as the combination of $\\mathbf{x}_{t}$ and a neural network $\\bar{\\epsilon_{\\theta}}(\\mathbf{x}_{t},\\mathbf{c},t)$ named score function. Please see Appendix C for more details. ", "page_idx": 3}, {"type": "text", "text": "Training Objective. The score function $\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)$ is trained by minimizing the evidence lower bound (ELBO) associated with the diffusion models in (3.1) and (3.2), which is equivalent to minimizing the following denoising score matching objective function $L_{\\mathrm{DSM}}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\nL_{\\mathrm{DSM}}(\\pmb\\theta)=\\mathbb{E}\\big[\\gamma_{t}\\big\\|\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)-\\epsilon_{t}\\big\\|_{2}^{2}\\big],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbf{x}_{t}=\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}\\!+\\!\\sqrt{1-\\alpha_{t}}\\epsilon_{t}$ and the expectation is computed over the distribution $\\mathbf{c}\\sim q(\\cdot),\\mathbf{x}_{0}\\sim$ $q_{\\mathrm{data}}(\\cdot|\\mathbf{c}),\\epsilon_{t}\\sim\\mathcal{N}(0,\\mathbf{I})$ , $t\\sim\\mathrm{Uniform}\\{1,\\ldots,T\\}$ . In addition, $\\{\\gamma_{t}\\}_{t=1}^{T}$ are pre-specified weights that depends on the sequences $\\{\\alpha_{t}\\}_{t=1}^{T}$ and $\\{\\sigma_{t}\\}_{t=1}^{T}$ . ", "page_idx": 3}, {"type": "text", "text": "3.2 Self-Play Fine-Tuning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Self-Play mechanism, originating from TD-Gammon (Tesauro et al., 1995), has achieved great successes in various fields, particularly in strategic games (Silver et al., 2017b,a). Central to Self-Play is the idea of progressively improving a model by competing against its previous iteration. This approach has recently been adapted to fine-tuning Large Language Models (LLMs) (Chen et al., 2024), called self-play fine-tuning (SPIN). Considering an LLM where c is the input prompt and $\\mathbf{x}_{\\mathrm{0}}$ is the response, the goal of SPIN is to fine-tune an LLM agent, denoted by $p_{\\theta}(\\cdot|\\mathbf{c})$ , based on an SFT dataset. Chen et al. (2024) assumed access to a main player and an opponent player at each iteration and takes the following steps iteratively: ", "page_idx": 3}, {"type": "text", "text": "1. The main player maximizes the expected value gap between the target data distribution $p_{\\mathrm{data}}$ and the opponent player\u2019s distribution $p_{\\theta_{k}}$ : 2. The opponent player generates responses that are indistinguishable from $p_{\\mathrm{data}}$ by the main player. ", "page_idx": 3}, {"type": "text", "text": "Instead of alternating optimization, SPIN directly utilizes a closed-form solution of the opponent player, which results in the opponent player at iteration $k+1$ to copy parameters $\\pmb{\\theta}_{k+1}$ , and forming an end-to-end training objective: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{\\mathtt{S P I N}}=\\mathbb{E}\\Bigg[\\ell\\Bigg(\\lambda\\log\\frac{p_{\\theta}\\left(\\mathbf{x}_{0}|\\mathbf{c}\\right)}{p_{\\theta_{k}}\\left(\\mathbf{x}_{0}|\\mathbf{c}\\right)}-\\lambda\\log\\frac{p_{\\theta}\\left(\\mathbf{x}_{0}^{\\prime}|\\mathbf{c}\\right)}{p_{\\theta_{k}}\\left(\\mathbf{x}_{0}^{\\prime}|\\mathbf{c}\\right)}\\Bigg)\\Bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here the expectation is taken over the distribution $\\mathbf{c}\\sim q(\\mathbf{c}),\\mathbf{x}\\sim p_{\\mathrm{data}}(\\mathbf{x}|\\mathbf{c}),\\mathbf{x}^{\\prime}\\sim p_{\\theta_{k}}(\\mathbf{x}^{\\prime}|\\mathbf{c}),\\ell(\\mathbf{x}),$ $\\ell(\\cdot)$ is a loss function that is both monotonically decreasing and convex, and $\\lambda>0$ is a hyperparameter. Notably, (3.4) only requires the knowledge of demonstration/SFT data, i.e., prompt-response pairs. ", "page_idx": 3}, {"type": "text", "text": "Algorithm 1 Self-Play Diffusion (SPIN-Diffusion) ", "page_idx": 4}, {"type": "text", "text": "Input: $\\{(\\mathbf{x}_{0},\\mathbf{c})\\}_{i\\in[N]}$ : SFT Dataset, $p_{\\theta_{0}}$ : Diffusion Model with parameter $\\theta_{0}$ , $K$ : Number of   \niterations.   \nfor $k=0,\\ldots,K-1$ do for $i=1,\\ldots N$ do Generate real diffusion trajectories $\\mathbf{x}_{1:T}\\sim q(\\mathbf{x}_{1:T}|\\mathbf{x}_{0})$ . Generate synthetic diffusion trajectories $\\mathbf{x}_{0:T}^{\\prime}\\sim p\\pmb{\\theta}_{k}(\\cdot|\\mathbf{c})$ . end for Update $\\theta_{k+1}=\\operatorname{argmin}_{\\theta\\in\\Theta}\\widehat{L}_{\\mathtt{S P I N}}(\\theta,\\theta_{k})$ , which is the empirical version of (4.8) or (4.9) .   \nend for   \nOutput: $\\theta_{K}$ . ", "page_idx": 4}, {"type": "text", "text": "4 Method ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we are going to present a method for fine-tuning diffusion models with self-play mechanism. ", "page_idx": 4}, {"type": "text", "text": "Consider a setting where we are training on a high-quality dataset containing image-text pairs $(\\mathbf{c},\\mathbf{x}_{0})\\sim p_{\\mathrm{data}}(\\bar{\\mathbf{x}_{0}}|\\mathbf{c})q(\\mathbf{c})$ where c is the text prompt and $\\mathbf{x}_{\\mathrm{0}}$ is the image. Our goal is to fine-tune a pretrained diffusion model, denoted by $p_{\\theta}$ , to align with the distribution $p_{\\mathrm{data}}(\\mathbf{x}_{0}|\\mathbf{c})$ . Instead of directly minimizing the denoising score matching objective function $L_{\\mathrm{DSM}}$ in (3.3), we adapt SPIN to diffusion models. However, applying SPIN to fine-tuning diffusion models presents unique challenges. Specifically, the objective of SPIN (3.4) necessitates access to the marginal probability $p_{\\theta}(\\mathbf{x}_{0}|\\bar{\\mathbf{c}})$ . While obtaining $p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{c})$ is straightforward in LLMs, this is not the case with diffusion models. Given the parameterization of the diffusion model as $p_{\\theta}(\\mathbf{x}_{0:T}|\\mathbf{c})$ , computing the marginal probability $p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{c})$ requires integration over all potential trajectories $\\begin{array}{r}{\\int_{\\mathbf{x}_{1:T}}p_{\\pmb{\\theta}}(\\mathbf{x}_{0:T}|\\mathbf{c})d\\mathbf{x}_{1:T}}\\end{array}$ , which is computationally intractable. ", "page_idx": 4}, {"type": "text", "text": "In the following, we propose a novel SPIN-Diffusion method with a decomposed objective function that only requires the estimation of score function $\\epsilon_{\\theta}$ . This is achieved by employing the DDIM formulation discussed in Section 3. The key technique is self-play mechanism with a focus on the joint distributions of the entire diffusion process, i.e., $p_{\\mathrm{data}}(\\bar{\\mathbf{x}_{0:T}}|\\mathbf{c})=q(\\mathbf{x}_{1:T}|\\mathbf{x}_{0})p_{\\mathrm{data}}(\\mathbf{x}_{0}|\\mathbf{c})$ and $p_{\\theta}(\\mathbf{x}_{0:T}|\\mathbf{c})$ , instead of marginal distributions. ", "page_idx": 4}, {"type": "text", "text": "4.1 Differentiating Diffusion Processes ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In iteration $k+1$ , we focus on training a function $f_{k+1}$ to differentiate between the diffusion trajectory $\\mathbf{x}_{0:T}$ generated by the diffusion model parameterized by $p_{\\theta}(\\mathbf{x}_{0:T}|\\mathbf{c})$ , and the diffusion process $p_{\\mathrm{data}}(\\mathbf{x}_{0:T}|\\mathbf{c})$ from the data. Specifically, the training of $f_{k+1}$ involves minimizing a generalized Integral Probability Metric (IPM) (M\u00fcller, 1997): ", "page_idx": 4}, {"type": "equation", "text": "$$\nf_{k+1}=\\underset{f\\in\\mathcal{F}_{k}}{\\mathrm{argmin}}\\,\\mathbb{E}\\big[\\ell\\big(f(\\mathbf{c},\\mathbf{x}_{0:T})-f(\\mathbf{c},\\mathbf{x}_{0:T}^{\\prime})\\big)\\big].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, the expectation is taken over the distributions $\\mathbf{c}\\sim q(\\cdot),\\mathbf{x}_{0:T}\\sim p_{\\mathrm{data}}(\\cdot|\\mathbf{c})$ , and $\\mathbf{x}_{0:T}^{\\prime}\\sim p\\pmb{\\theta}_{k}(\\cdot|\\mathbf{c})$ $\\mathcal{F}_{k}$ denotes the class of functions under consideration and $\\ell(\\cdot)$ is a monotonically decreasing and convex function that helps stabilize training. The value of $f$ reflects the degree of belief that the diffusion process $\\mathbf{x}_{0:T}$ given context c originates from the target diffusion process $p_{\\mathrm{data}}(\\mathbf{x}_{0:T}|\\mathbf{c})$ rather than the diffusion model $p_{\\theta}(\\mathbf{x}_{0:T}|\\mathbf{c})$ . We name $f$ the test function. ", "page_idx": 4}, {"type": "text", "text": "4.2 Deceiving the Test Function ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The opponent player wants to maximize the expected value $\\mathbb{E}_{\\mathbf{c}\\sim q(\\cdot),\\mathbf{x}_{0:T}\\sim p(\\cdot|\\mathbf{c})}[f_{k+1}(\\mathbf{c},\\mathbf{x})]$ . In addition, to prevent excessive deviation of $p_{\\theta_{k+1}}$ from $p_{\\theta_{k}}$ and stabilize the self-play fine-tuning, we incorporate a Kullback-Leibler (KL) regularization term. Putting these together gives rise to the following optimization problem: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\underset{p}{\\mathrm{argmax}}\\mathbb{E}_{\\mathbf{c}\\sim q(\\cdot),\\mathbf{x}_{0:T}\\sim p(\\cdot|\\mathbf{c})}[f_{k+1}(\\mathbf{c},\\mathbf{x}_{0:T})]-\\lambda\\mathbb{E}_{\\mathbf{c}\\sim q(\\cdot)}\\mathrm{KL}\\big(p(\\cdot|\\mathbf{c})||p_{\\theta_{k}}(\\cdot|\\mathbf{c})\\big),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\lambda>0$ is the regularization parameter. Notably, (4.2) has a closed-form solution ${\\widehat{p}}(\\cdot|\\mathbf{c})$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{p}(\\mathbf{x}_{0:T}|\\mathbf{c})\\propto p_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{0:T}|\\mathbf{c})\\exp\\big(\\lambda^{-1}f_{k+1}(\\mathbf{c},\\mathbf{x}_{0:T})\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To ensure that $\\widehat{p}$ lies in the diffusion process space $\\{p_{\\theta}(\\cdot|\\mathbf{c})|\\theta\\in\\Theta\\}$ , we utilize the following test function class  ( Chen et al., 2024): ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}_{k}=\\bigg\\{\\lambda\\cdot\\log\\frac{p_{\\theta}\\left(\\mathbf{x}_{1:T}|\\mathbf{c}\\right)}{p_{\\theta_{\\mathbf{k}}}\\left(\\mathbf{x}_{1:T}|\\mathbf{c}\\right)}\\bigg\\vert\\theta\\in\\Theta\\bigg\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Given the choice of $\\mathcal{F}_{k}$ in (4.4), optimizing (4.1) gives $f_{k+1}$ parameterized by $\\pmb{\\theta}_{k+1}$ in the following form: ", "page_idx": 5}, {"type": "equation", "text": "$$\nf_{k+1}(\\mathbf{c},\\mathbf{x}_{0:T})=\\lambda\\cdot\\log\\frac{p_{\\theta_{k+1}}(\\mathbf{x}_{0:T}|\\mathbf{c})}{p_{\\theta_{k}}(\\mathbf{x}_{0:T}|\\mathbf{c})}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Substituting (4.5) into (4.3) yields $\\widehat{p}(\\mathbf{x}_{0:T}|\\mathbf{c})=p_{\\pmb{\\theta}_{k+1}}(\\mathbf{x}_{0:T}|\\mathbf{c})$ . In other words, $\\pmb{\\theta}_{k+1}$ learned from (4.1) is exactly the diffusion parameter for the ideal choice of opponent. ", "page_idx": 5}, {"type": "text", "text": "4.3 Decomposed Training Objective ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The above two steps provide a training scheme depending on the full trajectory of $\\mathbf{x}_{0:T}$ . Specifically, substituting (4.4) into (4.1) yields the update rule $\\theta_{k+1}=\\operatorname{argmin}_{\\theta\\in\\Theta}L_{\\operatorname{SPIN}}(\\theta,\\theta_{k})$ , where $L_{{\\tt S P I N}}$ is defined as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{\\mathtt{S P I N}}=\\mathbb{E}\\Bigg[\\ell\\bigg(\\lambda\\log\\frac{p_{\\theta}\\left(\\mathbf{x}_{0:T}|\\mathbf{c}\\right)}{p_{\\theta_{k}}\\left(\\mathbf{x}_{0:T}|\\mathbf{c}\\right)}-\\lambda\\log\\frac{p_{\\theta}\\left(\\mathbf{x}_{0:T}^{\\prime}|\\mathbf{c}\\right)}{p_{\\theta_{k}}\\left(\\mathbf{x}_{0:T}^{\\prime}|\\mathbf{c}\\right)}\\bigg)\\Bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here the expectation is taken over the distributions $\\mathbf{c}\\sim q(\\cdot),\\mathbf{x}_{0:T}\\sim p_{\\mathrm{data}}(\\cdot|\\mathbf{c}),\\mathbf{x}_{0:T}^{\\prime}\\sim p_{\\theta_{k}}(\\cdot|\\mathbf{c}),$ . To formulate a computationally feasible objective, we decompose $\\log p_{\\theta}(\\mathbf{x}_{0:T}|\\mathbf{c})$ using the backward process of diffusion models. Substituting (3.2) into (4.6), we have that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\log p_{\\theta}\\big(\\mathbf{x}_{0:T}|\\mathbf{c}\\big)=\\log\\left(\\prod_{t=1}^{T}p_{\\theta}\\big(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{c}\\big)\\cdot p_{\\theta}\\big(\\mathbf{x}_{T}|\\mathbf{c}\\big)\\right)}\\\\ {\\displaystyle\\qquad\\qquad\\qquad=\\log p_{\\theta}\\big(\\mathbf{x}_{T}|\\mathbf{c}\\big)+\\sum_{t=1}^{T}\\log\\left(p_{\\theta}\\big(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{c}\\big)\\right)}\\\\ {\\displaystyle\\qquad\\qquad=\\mathrm{Constant}-\\sum_{t=1}^{T}\\frac{1}{2\\sigma_{t}^{2}}\\big\\Vert\\mathbf{x}_{t-1}-\\mu_{\\theta}\\big(\\mathbf{x}_{t},\\mathbf{c},t\\big)\\big\\Vert_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the last equality holds since $p_{\\theta}\\big(\\mathbf{x}_{t-1}\\big|\\mathbf{x}_{t},\\mathbf{c}\\big)$ is a Gaussian distribution $\\mathcal{N}(\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t),\\sigma_{t}^{2}\\mathbf{I})$ according to (3.2), and $p_{\\theta}\\bar{(}\\mathbf{x}_{T}|\\bar{\\mathbf{c}})$ is approximately a Gaussian independent of $\\pmb{\\theta}$ . By substituting (4.7) into (4.6) and introducing a reparameterization $\\sigma_{t}^{2}=\\dot{\\lambda}T/(2\\beta_{t})$ , where $\\beta_{t}$ is a fixed positive value, we obtain ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\cal L}_{\\mathtt{S P I N}}(\\theta,\\theta_{k})=\\mathbb{E}\\bigg[\\ell\\bigg(-\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\frac{\\beta_{t}}{T}\\big[\\big\\|{\\mathbf x}_{t-1}-\\mu_{\\theta}({\\mathbf x}_{t},{\\mathbf c},t)\\big\\|_{2}^{2}-\\big\\|{\\mathbf x}_{t-1}-\\mu_{\\theta_{k}}({\\mathbf x}_{t},{\\mathbf c},t)\\big\\|_{2}^{2}\\bigg]}\\\\ {\\quad\\qquad\\qquad-\\left\\|{\\mathbf x}_{t-1}^{\\prime}-\\mu_{\\theta}({\\mathbf x}_{t}^{\\prime},{\\mathbf c},t)\\right\\|_{2}^{2}+\\big\\|{\\mathbf x}_{t-1}^{\\prime}-\\mu_{\\theta_{k}}({\\mathbf x}_{t}^{\\prime},{\\mathbf c},t)\\big\\|_{2}^{2}\\bigg)\\bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here the expectation is taken over the distributions $\\mathbf{c}\\sim q(\\cdot),\\mathbf{x}_{0:T}\\sim p_{\\mathrm{data}}(\\cdot|\\mathbf{c}),\\mathbf{x}_{0:T}^{\\prime}\\sim p_{\\theta_{k}}(\\cdot|\\mathbf{c})$ Note that by considering the main player (reward function) across the full trajectory (3.2), rather than focusing solely on the final state as in Fan et al. (2023); Black et al. (2023); Wallace et al. (2023), we are able to formulate an exact objective function up to Equation (4.8). The detailed algorithm is presented in Algorithm 1. (4.8) naturally provides an objective function for DDIM with $\\sigma_{t}>0$ , where $\\sigma_{t}$ controls the determinism of the reverse process (3.2). (4.8) remains valid for deterministic generation processes as $\\sigma_{t}\\to0$ . ", "page_idx": 5}, {"type": "text", "text": "4.4 Approximate Training Objective ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "While (4.8) is the exact ELBO, optimizing it requires storing all intermediate images during the reverse sampling. When the trajectory length $T$ is large, it would require an impractical amount of GPU memory when the loss is summed over $T$ . Additionally, the required samples from a reverse process are not readily accessible. To address these limitations, we propose an approximate objective function. By applying Jensen\u2019s inequality and the convexity of the loss function $\\ell$ , we can give an upper bound of (4.8) and thus move the average over $t$ outside the loss function $\\ell$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\nL_{\\mathrm{SPII}}^{\\mathrm{approx}}(\\pmb\\theta,\\pmb\\theta_{k})=\\mathbb{E}\\bigg[\\ell\\Big(-\\beta_{t}\\Big[\\big\\|\\mathbf{x}_{t-1}-\\mu_{\\pmb\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}-\\big\\|\\mathbf{x}_{t-1}-\\mu_{\\pmb\\theta_{k}}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}\\Big]\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$$\n-\\left\\|\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\right\\|_{2}^{2}+\\left\\|\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\right\\|_{2}^{2}\\right\\|\\biggr)\\Biggr],\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the expectation is taken over the distributions $\\begin{array}{r l r}{\\mathbf{c}}&{{}\\sim}&{\\ q(\\mathbf{c}),(\\mathbf{x}_{t-1},\\mathbf{x}_{t})\\quad\\sim}\\end{array}$ $p_{\\mathrm{data}}(\\mathbf{x}_{t-1},\\mathbf{x}_{t}|\\bar{\\mathbf{c}}),(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})\\ \\sim\\ p_{\\theta_{k}}(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{c})$ , $t~\\sim~\\mathrm{Uniform}\\{1,\\ldots,T\\}$ . This approximation is directly motivated by the nature of diffusion models, which inherently decouple operations on a per-time-step basis. We provide theoretical justifications for our approximation method in the following sections. ", "page_idx": 6}, {"type": "text", "text": "The following lemma shows that LSaPpIpNroxis an upper bound of LSPIN. ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.1. Fix $\\theta_{k}\\in\\Theta$ which serves as the starting point of Algorithm 1 for iteration $k+1$ . It holds that $L_{\\mathtt{S P I N}}(\\theta,\\theta_{k})\\le L_{\\mathtt{S P I N}}^{\\mathrm{approx}}(\\theta,\\theta_{k})$ for all $\\theta\\in\\Theta$ . ", "page_idx": 6}, {"type": "text", "text": "$L_{\\mathtt{S P I N}}^{\\mathrm{approx}}$ eliminates the need to store all intermediate steps, as it only involves two consecutive sampling steps and . Since the reverse process approximates the forward process $q(\\mathbf{x}_{1:T}^{\\prime}|\\mathbf{x}_{0}^{\\prime})$ , we use the per step forward process $q(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{x}_{0}^{\\prime})$ to approximate $p_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\bar{\\prime}}|\\mathbf{x}_{0}^{\\prime},\\mathbf{c})$ . We can further approximate $\\begin{array}{r l r}{p_{\\theta_{k}}(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{c})}&{{}=}&{\\int p_{\\theta_{k}}(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{x}_{0}^{\\prime},\\mathbf{c})p_{\\theta_{k}}(\\mathbf{x}_{0}^{\\prime}|\\mathbf{c})d\\mathbf{x}_{0}^{\\prime}}\\end{array}$ with $\\begin{array}{r}{\\int q(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{x}_{0}^{\\prime})p_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{0}^{\\prime}|\\mathbf{c})d\\mathbf{x}_{0}^{\\prime}}\\end{array}$ . Substituting the corresponding terms in (4.9) with the above approximation allows us to only compute the expectation of (4.9) over the distribution $\\mathbf{c}\\sim q(\\mathbf{c})$ , $(\\mathbf{x}_{t-1},\\mathbf{x}_{t})\\sim$ $p_{\\mathrm{data}}\\big(\\mathbf{x}_{t-1},\\mathbf{x}_{t}|\\mathbf{c}\\big)$ , $\\begin{array}{r}{(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})\\sim\\int p_{\\pmb{\\theta}_{k}}\\bar{(}\\mathbf{x}_{0}^{\\prime}|\\mathbf{c}\\big)q(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{x}_{0}^{\\prime})d\\mathbf{x}_{0}^{\\prime}}\\end{array}$ , $t\\sim\\mathrm{Uniform}\\{1,\\ldots,T\\}$ . Furthermore, by incorporating the reparameterization of $\\pmb{\\mu}_{\\pmb{\\theta}}$ into (4.8) and (4.9), we can express (4.8) and (4.9) in terms of $\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)$ . Detailed derivations of (4.8) and (4.9) are provided in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "5 Main Theory ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we provide a theoretical analysis of Algorithm 1. Section 4 introduces two distinct objective functions, as defined in (4.8) and (4.9), both of which use the loss function $\\ell$ . Since (4.8) is an exact objective function, its analysis closely follows the framework established by Chen et al. (2024). Consequently, we instead focus on the approximate objective function $L_{\\mathtt{S P I N}}^{\\mathrm{approx}}$ defined in (4.9), which is more efficient to optimize and is the algorithm we use in our experiments. However, its behavior is more difficult to analyze. We begin with a formal assumption regarding the loss function $\\ell$ as follows. ", "page_idx": 6}, {"type": "text", "text": "Assumption 5.1. The function $\\ell(t):\\mathbb{R}\\rightarrow\\mathbb{R}$ in (4.9) is monotonically decreasing, i.e., $\\forall t,\\ell^{\\prime}(t)\\leq0$ and satisfies $\\ell^{\\prime}(0)<0$ . In addition, $\\ell(t)$ is a convex function. ", "page_idx": 6}, {"type": "text", "text": "Assumption 5.1 can be satisfied by various commonly used loss functions in machine learning. This includes the correlation loss $\\ell(t)=1-t$ , the hinge loss $\\ell(t)=\\operatorname*{max}(0,1-t)$ , and the logistic loss $\\ell(t)=\\log(1+\\exp(-t))$ . In our experiments, we are using the logistic loss. ", "page_idx": 6}, {"type": "text", "text": "To understand the behavior of SPIN-Diffusion, let us first analyze the gradient of the objective function (4.9), ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla L_{\\mathrm{SPII}}^{\\mathrm{approx}}=\\mathbb{E}\\Big[\\underbrace{\\left(-\\beta_{t}\\ell_{t}^{\\prime}\\right)}_{\\mathrm{Reweighting}}\\cdot\\big(\\underbrace{\\nabla_{\\theta}\\big\\|\\mathbf{x}_{t-1}-\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}}_{\\mathrm{Matching}}-\\underbrace{\\nabla_{\\theta}\\big\\|\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\big\\|_{2}^{2}}_{\\mathrm{Pushing}}\\big)\\Big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the expectation is taken over the distributions $\\begin{array}{r l r}{\\mathbf{c}}&{{}\\sim}&{q(\\mathbf{c}),(\\mathbf{x}_{t-1},\\mathbf{x}_{t})}\\end{array}$ \u223c $p_{\\mathrm{data}}(\\mathbf{x}_{t-1},\\mathbf{x}_{t}|\\bar{\\mathbf{c}}),(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})\\sim p_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{c}).$ . (D.3) can be divided into three parts: ", "page_idx": 6}, {"type": "text", "text": "\u2022 Reweighting: $\\ell^{\\prime}(\\cdot)$ in the \u201cReweighting\u201d term is negative and increasing because $\\ell()$ is monotonically decreasing and convex according to Assumption 5.1. Therefore, $-\\beta_{t}\\ell_{t}^{\\prime}\\;\\;=\\;\\;$ $-\\beta_{t}\\ell^{\\prime}\\big(-\\beta_{t}\\big[\\|\\mathbf{x}_{t-1}-\\pmb{\\mu}_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\|_{2}^{2}-\\ldots+\\|\\mathbf{x}_{t-1}^{\\prime}-\\pmb{\\mu}_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\|_{2}^{2}\\big]\\big)$ is always non-negative. Furthermore, $-\\beta_{t}\\ell_{t}^{\\prime}$ decreases as the argument inside $\\ell()$ increases.   \n\u2022 Matching: The \u201cMatching\u201d term matches $\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)$ to $\\mathbf{x}_{t-1}$ coming from pairs $({\\bf x}_{t-1},{\\bf x}_{t})$ , that are sampled from the target distribution. This increases the likelihood of $(\\mathbf{x}_{t-1},\\mathbf{x}_{t})\\mathbf{\\Omega}\\sim$ $p_{\\mathrm{data}}\\big(\\mathbf{x}_{t-1},\\mathbf{x}_{t}\\big)$ following the generative process (3.2).   \n\u2022 Pushing: Contrary to the \u201cMatching\u201d term, the \u201cPushing\u201d term pushes $\\mu_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)$ away from $\\mathbf{x}_{t-1}^{\\prime}$ coming from pairs $(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})$ drawn from the synthetic distribution $p_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})$ . Therefore, the \u201cPushing\u201d term decreases the likelihood of these samples following the process in the generative process (3.2). ", "page_idx": 6}, {"type": "text", "text": "The \u201cMatching\u201d term aligns conceptually with the $L_{\\mathrm{DSM}}$ in SFT, as both aim to maximize the likelihood that the target trajectory $\\mathbf{x}_{0:T}$ follows the generative process described in (3.2). The following theorem shows a formal connection, which is pivotal for understanding the optimization dynamics of our method. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.2. Under Assumption 5.1, if $\\theta_{k}$ is not the global optima of $L_{\\mathrm{DM}}$ in (3.3), there exists an appropriately chosen $\\beta_{t}$ , such that $\\theta_{k}$ is not the global minima of (4.9) and thus $\\boldsymbol\\theta_{k+1}\\neq\\boldsymbol\\theta_{k}$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.2 suggests that the optimization process stops only when $\\pmb{\\theta}$ reaches global optimality of $L_{\\mathrm{DSM}}$ . Consequently, the optimal diffusion model $\\pmb{\\theta}^{*}$ found by Algorithm 1 cannot be further improved using $L_{\\mathrm{DSM}}$ . This theoretically supports that SFT with (3.3) cannot improve over SPINDiffusion. It is also worth noting that Theorem 5.2 does not assert that every global minimum of $L_{\\mathrm{DSM}}$ meets the convergence criterion (i.e., $\\pmb{\\theta}_{k+1}=\\pmb{\\theta}_{k})$ ), particularly due to the influence of the \u201cPushing\u201d term in (D.3). The following theorem provides additional insight into the conditions under which Algorithm 1 converges. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.3. Under Assumption 5.1, if $p_{\\theta_{k}}(\\cdot|\\mathbf{x})\\,=\\,p_{\\mathrm{data}}(\\cdot|\\mathbf{x})$ , then $\\theta_{k}$ is the global minimum of (4.9) for any $\\lambda\\geq0$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.3 shows that Algorithm 1 converges when $p_{\\theta}(\\cdot|\\mathbf{x})=p_{\\mathrm{data}}(\\cdot|\\mathbf{x})$ , indicating the efficacy of SPIN-Diffusion in aligning with the target data distribution. In addition, while Theorems 5.2 and 5.3 are directly applicable to (4.9), the analogous conclusion can be drawn for (4.8) as well (see Appendix D for a detailed discussion). ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we conduct extensive experiments to demonstrate the effectiveness of SPIN-Diffusion. Our results show that SPIN-Diffusion outperforms other baseline fine-tuning methods including SFT and Diffusion-DPO. ", "page_idx": 7}, {"type": "text", "text": "6.1 Experiment Setup ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Models, Datasets and Baselines. We use the stable diffusion v1.5 (SD-1.5) (Rombach et al., 2022a) as our base model. While adopting the original network structure, we use its Huggingface pretrained version2, which is trained on LAION-5B (Schuhmann et al., 2022) dataset, a text-image pair dataset containing approximately 5.85 billion CLIP-filtered image-text pairs. We use the Pick-a-Pic dataset (Kirstain et al., 2023) for fine-tuning. Pick-a-Pic is a dataset with pairs of images generated by Dreamlike3 (a fine-tuned version of SD-1.5) and SDXL-beta (Podell et al., 2023), where each pair corresponds to a human preference label. We also train SD-1.5 with SFT and Diffusion-DPO (Wallace et al., 2023) as the baselines. For SFT, we train the model to fit the winner images in the Pick-aPic (Kirstain et al., 2023) trainset. In addition to the Diffusion-DPO checkpoint provided by Wallace et al. $(2023)^{4}$ (denoted by Diffusion-DPO), we also fine-tune an SD-1.5 using Diffusion-DPO and denote it by \u201cDiffusion-DPO (reproduced)\u201d. ", "page_idx": 7}, {"type": "text", "text": "Evaluation. We use the Pick-a-Pic test set, PartiPrompts (Yu et al., 2022) and HPSv2 (Wu et al., 2023) as our evaluation benchmarks. We defer the detailed introduction and results of PartiPrompts and HPSv2 to Appendix A.3. Our evaluation rubric contains two dimensions, human preference alignment and visual appeal. For visual appeal assessment, we follow Wallace et al. (2023); Lee et al. (2024) and use Aesthetic score. For human-preference alignment, we employ reward models including PickScore (Kirstain et al., 2023), ImageReward (Xu et al., 2023) and HPS (Wu et al., 2023). All these reward models are trained according to the Bradley-Terry-Luce (Bradley and Terry, 1952) model on different human-labeled preference datasets. For each prompt, we generate 5 images and choose the image with highest average score over those four metrics (best out of 5). We report the average of HPS, PickScore, ImageReward and Aesthetic scores over all the prompts. To investigate how the scores align with human preference, we further compare the accuracy of these reward models on a small portion of the Pick-a-Pic training set. It is worth noticing that PickScore is most aligned with human preference according to the experiments conducted by Kirstain et al. (2023). ", "page_idx": 7}, {"type": "table", "img_path": "q3XavKPorV/tmp/8cf47422c4a81b452af929aabc8d73d010f95950b82c593bfed4b726beac03ff.jpg", "table_caption": ["Table 1: The results on the Pick-a-Pic test set. We report the mean of PickScore, HPS, ImageReward and Aesthetic over the whole test set. We also report the average score over the three evaluation metrics. SPIN-Diffusion outperforms all the baselines in terms of four metrics. For this and following tables, we use blue background to indicate our method, bold numbers to denote the best and underlined for the second best. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "6.2 Main Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this subsection, we provide empirical evidence demonstrating the superiority of our SPIN-Diffusion model over previous fine-tuning baselines based on the network structure of SD1.5. ", "page_idx": 8}, {"type": "text", "text": "Comparison in Terms of Average Score. The results are presented in Table 1. While all fine-tuning algorithms yield improvements over the SD1.5 baseline, at iteration 1, our SPIN-Diffusion not only exceeds the original DPO checkpoint but also surpasses SFT in both Aesthetic score and PickScore. ", "page_idx": 8}, {"type": "text", "text": "At iteration 2, the superiority of our model becomes even more pronounced, particularly in terms of Aesthetic score, where it consistently outperforms other fine-tuning methods, indicating a dominant performance in visual quality. Furthermore, at iteration 3, our model\u2019s HPSv2 score surpasses all competing models, highlighting the effectiveness and robustness of the SPIN-Diffusion approach. Specifically, on the Pick-a-Pic dataset, while SFT achieves a PickScore of 21.45, and Diffusion-DPO has a slightly higher score of 21.45, SPIN-Diffusion achieves 22.00 at iteration 3, showing a total improvement of 0.80 over the original SD1.5 checkpoint. Furthermore, SPIN-Diffusion demonstrates exceptional performance in terms of Aesthetic score, achieving 6.25 at iteration 3, which significantly surpasses 5.86 achieved by Diffusion-DPO and 5.77 by SD1.5. ", "page_idx": 8}, {"type": "image", "img_path": "q3XavKPorV/tmp/9f226dddb5fa1500a66c0142dbef2041a861fadad4e4dfdfcb8e9961af5dd2c9.jpg", "img_caption": ["Figure 1: Left: winning rate in percentage of SFT, Diffusion-DPO, Diffusion-DPO (reproduced) and SPIN-Diffusion over SD1.5 checkpoint. Right: winning rate in percentage of SFT, Diffusion-DPO, Diffusion-DPO (reproduced) and SPIN-Diffusion over SD1.5 checkpoint. SPIN-Diffusion shows a much higher winning rate than SFT and Diffusion-DPO tuned models. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Comparison in Terms of Winning Rate. We further validate our claim by a comparative analysis of the winning rate for our trained model. The winning rate is defined as the proportion of prompts for which a model\u2019s generated images exceed the quality of those produced by another model. This experiment is conducted on the Pick-a-Pic test set. We show both the winning rate over SD-1.5, as well as the winning rate over Diffusion-DPO (reproduced) in Figure 1. The complete results are detailed in Tables 3 and 4 in Appendix A.2. We observe that throughout fine-tuning, our SPINDiffusion tremendously beats the baselines. When competing with SD-1.5, SPIN-Diffusion achieves an impressive winning rate of $90.0\\%$ at iteration 2, which further increases to $91.6\\%$ at iteration 3. This winning rate surpasses $73.2\\%$ achieved by SFT and $84.8\\%$ achieved by Diffusion-DPO (reproduced). When competing with Diffusion-DPO (reproduced), at iteration 3, SPIN-Diffusion achieves a winning rate of $56.2\\%$ on HPS, $86.8\\%$ on Aesthetic, $62.4\\%$ on PickScore, $55.8\\%$ on Image Reward, and has an overall winning rate of $70.2\\%$ . ", "page_idx": 8}, {"type": "image", "img_path": "q3XavKPorV/tmp/6aeb769cbd802be05af38a1c3daf415c497582198a0fad2fb7d20585713d922a.jpg", "img_caption": ["Figure 2: We show the images generated by different models. The prompts are \u201ca very cute boy, looking at audience, silver hair, in his room, wearing hoodie, at daytime, ai language model, 3d art, c4d, blender, pop mart, blind box, clay material, pixar trend, animation lighting, depth of field, ultra detailed\u201d, \u201cpainting of a castle in the distance\u201d and \u201cred and green eagle\u201d. The models are: SD-1.5, SFT, Diffusion-DPO (reproduced), SPIN-Diffusion-Iter1, SPIN-Diffusion-Iter2, SPIN-DiffusionIter3 from left to right. SPIN-Diffusion demonstrates a notable improvement in image quality. The quantitative evaluation of the aesthetic score of the above images is in Table 5. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6.3 Qualitative Analysis ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We illustrate the qualitative performance of our model on three prompts coming from the Pick-a-Pic test dataset. We prompt SD-1.5, SFT, Diffusion-DPO (reproduced), and SPIN-Diffusion at iteration 1 to 3 and present the generated images in Figure 2. Compared to the baseline methods, SPIN-Diffusion demonstrates a notable improvement in image quality, even more apparent than the improvements in scores. This is especially evident in aspects such as aligning, shading, visual appeal, and the intricacy of details within each image. This qualitative assessment underscores the effectiveness of SPIN-Diffusion in producing images that are not only contextually accurate but also visually superior to those generated by other existing models. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper presents SPIN-Diffusion, an innovative fine-tuning approach tailored for diffusion models, particularly effective in scenarios where only a single image is available per text prompt. By employing a self-play mechanism, SPIN-Diffusion iteratively refines the model\u2019s performance, converging towards the target data distribution. Theoretical evidence underpins the superiority of SPIN-Diffusion, demonstrating that traditional supervised fine-tuning cannot surpass its stationary point, achievable at the target data distribution. Empirical evaluations highlight SPIN-Diffusion\u2019s remarkable success in text-to-image generation tasks, surpassing the state-of-the-art fine-tuning methods even without the need for additional data. This underscores SPIN-Diffusion\u2019s potential to revolutionize the practice of diffusion model fine-tuning, leveraging solely demonstration data to achieve unprecedented performance levels. ", "page_idx": 9}, {"type": "text", "text": "Limitations While our theoretical analysis ensures that $\\theta_{k}$ is the only global optimum of our objective function, it relies on the assumption that the data distribution can be adequately represented by the parameterized family. Additionally, as our methodology is fundamentally a distribution matching algorithm, it cannot, in principle, exceed the performance of the underlying data distribution. Finally, although SPIN-Diffusion is data-efficient, it requires additional sampling overhead. The high sampling cost can be alleviated by software-level upgrades such as larger batch size, and memory-efficient attention backends. On the algorithm level, advanced sampling acceleration techniques also offer promising improvements. These techniques are orthogonal to our efforts in improving the performance of fine-tuning diffusion models, and therefore we decide to explore them as a future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We thank the anonymous reviewers and area chair for their helpful comments. HY, ZC, KJ, and QG are supported in part by the National Science Foundation CAREER Award 1906169, IIS-2008981, and the Sloan Research Fellowship. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "AUSTIN, J., JOHNSON, D. D., HO, J., TARLOW, D. and VAN DEN BERG, R. (2021). Structured denoising diffusion models in discrete state-spaces. Advances in Neural Information Processing Systems 34 17981\u201317993.   \nBETKER, J., GOH, G., JING, L., BROOKS, T., WANG, J., LI, L., OUYANG, L., ZHUANG, J., LEE, J., GUO, Y. ET AL. (2023). Improving image generation with better captions. Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf 2 3.   \nBLACK, K., JANNER, M., DU, Y., KOSTRIKOV, I. and LEVINE, S. (2023). Training diffusion models with reinforcement learning. arXiv preprint arXiv:2305.13301 .   \nBRADLEY, R. A. and TERRY, M. E. (1952). Rank analysis of incomplete block designs: I. the method of paired comparisons. Biometrika 39 324\u2013345.   \nCAESAR, H., UIJLINGS, J. and FERRARI, V. (2018). Coco-stuff: Thing and stuff classes in context. In Proceedings of the IEEE conference on computer vision and pattern recognition.   \nCHEN, Z., DENG, Y., YUAN, H., JI, K. and GU, Q. (2024). Self-play fine-tuning converts weak language models to strong language models. arXiv preprint arXiv:2401.01335 .   \nCHEN, Z., YUAN, H., LI, Y., KOU, Y., ZHANG, J. and GU, Q. (2023). Fast sampling via derandomization for discrete diffusion models. arXiv preprint arXiv:2312.09193 .   \nCLARK, K., VICOL, P., SWERSKY, K. and FLEET, D. J. (2023). Directly fine-tuning diffusion models on differentiable rewards. arXiv preprint arXiv:2309.17400 .   \nCORSO, G., ST\u00c4RK, H., JING, B., BARZILAY, R. and JAAKKOLA, T. (2022). Diffdock: Diffusion steps, twists, and turns for molecular docking. arXiv preprint arXiv:2210.01776 .   \nCRESWELL, A., WHITE, T., DUMOULIN, V., ARULKUMARAN, K., SENGUPTA, B. and BHARATH, A. A. (2018). Generative adversarial networks: An overview. IEEE signal processing magazine 35 53\u201365.   \nDAI, X., HOU, J., MA, C.-Y., TSAI, S., WANG, J., WANG, R., ZHANG, P., VANDENHENDE, S., WANG, X., DUBEY, A. ET AL. (2023). Emu: Enhancing image generation models using photogenic needles in a haystack. arXiv preprint arXiv:2309.15807 .   \nFAN, Y., WATKINS, O., DU, Y., LIU, H., RYU, M., BOUTILIER, C., ABBEEL, P., GHAVAMZADEH, M., LEE, K. and LEE, K. (2023). Dpok: Reinforcement learning for fine-tuning text-to-image diffusion models. arXiv preprint arXiv:2305.16381 .   \nGAL, R., ALALUF, Y., ATZMON, Y., PATASHNIK, O., BERMANO, A. H., CHECHIK, G. and COHEN-OR, D. (2022). An image is worth one word: Personalizing text-to-image generation using textual inversion. arXiv preprint arXiv:2208.01618 .   \nGUAN, J., ZHOU, X., YANG, Y., BAO, Y., PENG, J., MA, J., LIU, Q., WANG, L. and GU, Q. (2023). Decompdiff: Diffusion models with decomposed priors for structure-based drug design .   \nHO, J., JAIN, A. and ABBEEL, P. (2020). Denoising diffusion probabilistic models. Advances in neural information processing systems 33 6840\u20136851.   \nHO, J., SAHARIA, C., CHAN, W., FLEET, D. J., NOROUZI, M. and SALIMANS, T. (2022). Cascaded diffusion models for high fidelity image generation. The Journal of Machine Learning Research 23 2249\u20132281.   \nKINGMA, D. P. and WELLING, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 .   \nKIRSTAIN, Y., POLYAK, A., SINGER, U., MATIANA, S., PENNA, J. and LEVY, O. (2023). Pick-a-pic: An open dataset of user preferences for text-to-image generation. arXiv preprint arXiv:2305.01569 .   \nLEE, K., LIU, H., RYU, M., WATKINS, O., DU, Y., BOUTILIER, C., ABBEEL, P., GHAVAMZADEH, M. and GU, S. S. (2023). Aligning text-to-image models using human feedback. arXiv preprint arXiv:2302.12192 .   \nLEE, S. H., LI, Y., KE, J., YOO, I., ZHANG, H., YU, J., WANG, Q., DENG, F., ENTIS, G., HE, J., LI, G., KIM, S., ESSA, I. and YANG, F. (2024). Parrot: Pareto-optimal multi-reward reinforcement learning framework for text-to-image generation.   \nLIN, T.-Y., MAIRE, M., BELONGIE, S., HAYS, J., PERONA, P., RAMANAN, D., DOLL\u00c1R, P. and ZITNICK, C. L. (2014). Microsoft coco: Common objects in context. In Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13. Springer.   \nM\u00dcLLER, A. (1997). Integral probability metrics and their generating classes of functions. Advances in applied probability 29 429\u2013443.   \nNICHOL, A., DHARIWAL, P., RAMESH, A., SHYAM, P., MISHKIN, P., MCGREW, B., SUTSKEVER, I. and CHEN, M. (2021). Glide: Towards photorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741 .   \nPEEBLES, W. and XIE, S. (2023). Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision.   \nPODELL, D., ENGLISH, Z., LACEY, K., BLATTMANN, A., DOCKHORN, T., M\u00dcLLER, J., PENNA, J. and ROMBACH, R. (2023). Sdxl: Improving latent diffusion models for high-resolution image synthesis. arXiv preprint arXiv:2307.01952 .   \nPRABHUDESAI, M., GOYAL, A., PATHAK, D. and FRAGKIADAKI, K. (2023). Aligning text-toimage diffusion models with reward backpropagation. arXiv preprint arXiv:2310.03739 .   \nRAFAILOV, R., SHARMA, A., MITCHELL, E., ERMON, S., MANNING, C. D. and FINN, C. (2023). Direct preference optimization: Your language model is secretly a reward model. arXiv preprint arXiv:2305.18290 .   \nRAMESH, A., DHARIWAL, P., NICHOL, A., CHU, C. and CHEN, M. (2022). Hierarchical textconditional image generation with clip latents. arXiv preprint arXiv:2204.06125 1 3.   \nROMBACH, R., BLATTMANN, A., LORENZ, D., ESSER, P. and OMMER, B. (2022a). High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition.   \nROMBACH, R., BLATTMANN, A., LORENZ, D., ESSER, P. and OMMER, B. (2022b). Highresolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).   \nRUIZ, N., LI, Y., JAMPANI, V., PRITCH, Y., RUBINSTEIN, M. and ABERMAN, K. (2023). Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.   \nSAHARIA, C., CHAN, W., SAXENA, S., LI, L., WHANG, J., DENTON, E. L., GHASEMIPOUR, K., GONTIJO LOPES, R., KARAGOL AYAN, B., SALIMANS, T. ET AL. (2022a). Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Information Processing Systems 35 36479\u201336494.   \nSAHARIA, C., HO, J., CHAN, W., SALIMANS, T., FLEET, D. J. and NOROUZI, M. (2022b). Image super-resolution via iterative refinement. IEEE Transactions on Pattern Analysis and Machine Intelligence 45 4713\u20134726.   \nSCHUHMANN, C., BEAUMONT, R., VENCU, R., GORDON, C., WIGHTMAN, R., CHERTI, M., COOMBES, T., KATTA, A., MULLIS, C., WORTSMAN, M. ET AL. (2022). Laion-5b: An open large-scale dataset for training next generation image-text models. Advances in Neural Information Processing Systems 35 25278\u201325294.   \nSEGALIS, E., VALEVSKI, D., LUMEN, D., MATIAS, Y. and LEVIATHAN, Y. (2023). A picture is worth a thousand words: Principled recaptioning improves image generation. arXiv preprint arXiv:2310.16656 .   \nSILVER, D., HUBERT, T., SCHRITTWIESER, J., ANTONOGLOU, I., LAI, M., GUEZ, A., LANCTOT, M., SIFRE, L., KUMARAN, D., GRAEPEL, T. ET AL. (2017a). Mastering chess and shogi by self-play with a general reinforcement learning algorithm. arXiv preprint arXiv:1712.01815 .   \nSILVER, D., SCHRITTWIESER, J., SIMONYAN, K., ANTONOGLOU, I., HUANG, A., GUEZ, A., HUBERT, T., BAKER, L., LAI, M., BOLTON, A. ET AL. (2017b). Mastering the game of go without human knowledge. nature 550 354\u2013359.   \nSOHL-DICKSTEIN, J., WEISS, E., MAHESWARANATHAN, N. and GANGULI, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning. PMLR.   \nSONG, J., MENG, C. and ERMON, S. (2020a). Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502 .   \nSONG, Y. and ERMON, S. (2019). Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems 32.   \nSONG, Y., SOHL-DICKSTEIN, J., KINGMA, D. P., KUMAR, A., ERMON, S. and POOLE, B. (2020b). Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456 .   \nTESAURO, G. ET AL. (1995). Temporal difference learning and td-gammon. Communications of the ACM 38 58\u201368.   \nWALLACE, B., DANG, M., RAFAILOV, R., ZHOU, L., LOU, A., PURUSHWALKAM, S., ERMON, S., XIONG, C., JOTY, S. and NAIK, N. (2023). Diffusion model alignment using direct preference optimization. arXiv preprint arXiv:2311.12908 .   \nWATSON, D., HO, J., NOROUZI, M. and CHAN, W. (2021). Learning to efficiently sample from diffusion probabilistic models. arXiv preprint arXiv:2106.03802 .   \nWU, X., HAO, Y., SUN, K., CHEN, Y., ZHU, F., ZHAO, R. and LI, H. (2023). Human preference score v2: A solid benchmark for evaluating human preferences of text-to-image synthesis. arXiv preprint arXiv:2306.09341 .   \nXU, J., LIU, X., WU, Y., TONG, Y., LI, Q., DING, M., TANG, J. and DONG, Y. (2023). Imagereward: Learning and evaluating human preferences for text-to-image generation. arXiv preprint arXiv:2304.05977 .   \nYANG, K., TAO, J., LYU, J., GE, C., CHEN, J., LI, Q., SHEN, W., ZHU, X. and LI, X. (2023). Using human feedback to fine-tune diffusion models without any reward model. arXiv preprint arXiv:2311.13231 .   \nYU, J., XU, Y., KOH, J. Y., LUONG, T., BAID, G., WANG, Z., VASUDEVAN, V., KU, A., YANG, Y., AYAN, B. K. ET AL. (2022). Scaling autoregressive models for content-rich text-to-image generation. arXiv preprint arXiv:2206.10789 2 5.   \nZHENG, L., YUAN, J., YU, L. and KONG, L. (2023). A reparameterized discrete diffusion model for text generation. arXiv preprint arXiv:2302.05737 . ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Broader Impact ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "This approach enhances model performance across diverse benchmarks without the need for supervision from more advanced models, facilitating better alignment of AI with human preferences. This improvement bolsters the reliability and safety of AI systems in the field of text-to-image generation. It provides a more effective and scalable method for model fine-tuning, resulting in cost reductions and the expedited deployment of models that more accurately reflect human aesthetic and content preferences. ", "page_idx": 13}, {"type": "text", "text": "However, there exists the potential for overfitting, which may not lead to genuine improvements in real-world applications. Adhering too closely in creative fields such as text-to-image generation could inadvertently perpetuate existing societal biases in the generated imagery. Furthermore, the capability to finely tune alignment with human preferences could be exploited for unethical ends, such as crafting tailored and manipulative content or disseminating false information. ", "page_idx": 13}, {"type": "text", "text": "A Additional Details for Experiments ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Hyperparameters ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We train the SPIN-Diffusion on 8 NVIDIA A100 GPUs with 80G memory. In training the SPINDiffusion, we use the AdamW optimizer with a weight decay factor of $1e-2$ . The images are processed at a $512\\times512$ resolution. The batch size is set to 8 locally, alongside a gradient accumulation of 32. For the learning rate, we use a schedule starting with 200 warm-up steps, followed by linear decay. We conduct a grid search on the learning rate, coefficient $\\beta_{t}$ , and number of training steps, and choose the hyperparameters that perform the best on the validation set. We set the learning rate at $2.0e\\mathrm{~-~}5$ for the initial two iterations, reducing it to $5.0e\\mathrm{~-~}8$ for the third iteration. The coefficient $\\beta_{t}$ is chosen as 2000 for the first iteration, increasing to 5000 for the subsequent second and third iterations. The trend in different learning rate and $\\beta_{t}$ choices reveals that later iterations typically benefti from more conservative updates. Training steps are 50 for the first iteration, 500 for the second, and 200 for the third. In training the DPO model, we employ the same AdamW optimizer and maintain a batch size of 8 and a gradient accumulation of 32. The learning rate is set to $2.0e-5$ , and $\\beta_{t}$ is set to 2000. The total number of training steps for DPO is 350. In SFT training, we use 4 NVIDIA A6000 GPUs. We use the AdamW optimizer with a weight decay of 0.01. The local batch size is set to 32 and the global batch size is set to 512. Our learning rate is 1e-5, with linear warmup for 500 steps with no learning rate decay. We save checkpoints every 500 steps and evaluate the checkpoints on Pick-a-Pic validation. We select the best checkpoint, trained after 2000 steps as our SFT checkpoint. ", "page_idx": 13}, {"type": "text", "text": "During generation, we use a guidance scale of 7.5, and fixed the random seed as 5775709. ", "page_idx": 13}, {"type": "text", "text": "A.2 Additional Results ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we first illustrate the main results shown in Table 1 by Figure 3 and a radar plot Figure 4. ", "page_idx": 13}, {"type": "text", "text": "We present the median scores of baselines and SPIN-Diffusion on Pick-a-Pic testset in Table 2. The results are consistent to the results in Table 1. We present the detailed winning rate of baselines and SPIN-Diffusion over SD-1.5 in Table 3 and the winning rate over Diffusion-DPO in Table 4. We present the aesthetic scores of the images in Figure 2 in Table 5. ", "page_idx": 13}, {"type": "text", "text": "A.3 Additional Ablation Study ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We conduct ablation study to investigate several aspects in the performance of SPIN-Diffusion. ", "page_idx": 13}, {"type": "text", "text": "Continual Training for More Epochs. We further study the training behavior of SPIN-Diffusion by continual training within iteration 1. Both iteration 1 and iteration 2 commence training from the same checkpoint. However, for subsequent epochs in iteration 1, images generated by SD-1.5 are used, with SD-1.5 also serving as the opponent player. In contrast, during iteration 2, both the generated images and the opponent player originate from the iteration 1 checkpoint. The results shown in Figure 5 are reported on the 500 prompts validation set of Pick-a-Pic. We observe that in terms of PickScore, HPS, and average score, continual training on iteration 1 even results in a performance decay. Even in terms of Aesthetic score, continual training cannot guarantee a consistent improvement. Compared to training for more epochs in iteration 1, iteration 2 has a much more ideal performance. These results show the key role in updating the opponent. ", "page_idx": 13}, {"type": "image", "img_path": "q3XavKPorV/tmp/d1d5c69d8c7bbca7a43ebe3d135fa6d2da376ff2a91c5e1df9135ba354ba7cc7.jpg", "img_caption": ["Figure 3: Comparison between SPIN-Diffusion at different iterations with SD-1.5, SFT and DiffusionDPO. SPIN-Diffusion outperforms SFT at iteration 1, and outperforms all the baselines after iteration 2. In the legend, Diffusion-DPO (ours) denotes our reproduced version of Diffusion-DPO. "], "img_footnote": [], "page_idx": 14}, {"type": "image", "img_path": "q3XavKPorV/tmp/0f7d407883e609cfea33fe03e8b0284420e792ef67517f5bebffc5a377fd25eb.jpg", "img_caption": ["Figure 4: The main result is presented in radar chart. The scores are adjusted to be shown on the same scale. Compared with the baselines, SPIN achieves higher scores in all the four metrics and the average score by a large margin. In the legend, Diffusion-DPO (ours) denotes our reproduced version of Diffusion-DPO. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "Evaluation on Other Benchmarks We also conduct experiment on PartiPrompts (Yu et al., 2022) and HPSv2 (Wu et al., 2023). PartiPrompts consist of 1632 prompts that contains a wide range of categories and difficulties that beyond daily scenarios and natural objects. HPSv2 is a text-image prefence dataset, where the prompts come from DiffusionDB and MSCOCO (Lin et al., 2014) dataset. ", "page_idx": 14}, {"type": "text", "text": "Table 2: The results of median scores on Pick-a-Pic test set. We report the median of PickScore, HPSv2, ImageReward and Aesthetic over the whole test set. We also report the average score over the four evaluation metric. SPIN-Diffusion outperforms all the baselines regarding HPS, Aesthetic, PickScore and the average score, which agrees with the results of mean scores. ", "page_idx": 15}, {"type": "table", "img_path": "q3XavKPorV/tmp/a7b54c63047c6e80615478627f0e3d477067439d315fdffae085166165733075.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "q3XavKPorV/tmp/7732adfaea588b4f32d246c40846639f6ad11f60d3e03a4448917123fdd14386.jpg", "table_caption": ["Table 3: The winning rate over SD-1.5 Pick-a-Pic testset. SPIN-Diffusion shows the highest winning rate over SD-1.5 among all the baselines. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "q3XavKPorV/tmp/1de76101c516fcdb6fdc94fd08e86262b54bd078cd1032e1fb6537ab209a8f8b.jpg", "table_caption": ["Table 4: The winning rate over Diffusion DPO (reproduced) on Pick-a-Pic testset. SPIN-Diffusion shows the highest winning rate over Diffusion DPO (reproduced) among all the baselines. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "q3XavKPorV/tmp/3ba9162d45bf33cae5dea060d19cef0ed91e136b1a827a043734dc70a3dc309a.jpg", "table_caption": ["Table 5: Aesthetic scores of pictures in Figure 2 "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "q3XavKPorV/tmp/24596d4c12716745821b5e8d0730e4d7378b68bbb380e892bd244d2af28c1bd4.jpg", "table_caption": ["Table 6: The size of benchmark datasets in our evaluation "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "In our experiment, we use the prompts from its test set, which contains 3200 prompts. We use the same evaluation metrics as before and the results are shown in Table 7 and 8. The results show that, on both PartiPrompts and HPSv2, SPIN-Diffusion achieves a comparable performance with Diffusion DPO (reproduced) and surpasses other baseline models at the first iteration. SPIN-Diffusion further reaches an average score of 7.4326 and 7.5244 on PartiPrompts and HPSv2 dataset respectively at second iteration, which outpuerforms all other baselines by a large margin. These results consolidate our statement that SPIN shows a superior performance over both SFT and DPO. We also conduct qualitative result on PartiPrompts and the results are shown in Figure 6. ", "page_idx": 15}, {"type": "image", "img_path": "q3XavKPorV/tmp/a47ef2722a1e50061d241b2c8618a944f09b4a989d449e779581a08bf34fae43.jpg", "img_caption": ["Figure 5: The evaluation results on Pick-a-Pic validation set of continual training within SPINDiffusion iteration 1, and SPIN-Diffusion iteration 2. The $\\mathbf{X}$ -axis is the number of epochs. Consecutive epochs in iteration 1 reach their limit quickly while switching to iteration 2 boosts the performance. "], "img_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "q3XavKPorV/tmp/5d21d709edec93696931dfb57905be2302400e309d7fef7cf11bb8751fe8b839.jpg", "table_caption": ["Table 7: The results of mean scores on PartiPrompts. We report the mean and median of PickScore, HPS, ImageReward and Aesthetic score over the whole dataset. We also report the average score over the four evaluation metrics. SPIN-Diffusion outperforms all the baselines in terms of four metrics. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "Remarks on LoRA fine-tuning While LoRA is a parameter-efficient fine-tuning method that focuses on reducing trainable parameters under resource constraints, it is orthogonal to SPIN-Diffusion, which utilizes a self-play mechanism for fine-tuning. We also provide SFT (LoRA) fine-tuning results in Figure 11. We can see that full fine-tuning generally surpasses the performance of LoRA fine-tuning. Therefore, we leave the exploration of LoRA version of SPIN-Diffusion to future work. ", "page_idx": 16}, {"type": "text", "text": "Table 8: The results of median scores on PartiPrompts. We report the mean and median of PickScore, HPS, ImageReward and Aesthetic score over the whole dataset. We also report the average score over the four evaluation metrics. SPIN-Diffusion outperforms all the baselines in terms of four metrics. ", "page_idx": 17}, {"type": "table", "img_path": "q3XavKPorV/tmp/c29c974ab907c9948c19a3521f39d61dad6950269fd028ed6666207fc2a24e4c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "q3XavKPorV/tmp/622e87f07f7c1ca4c54eb49fb817c8b5db8aba13702740f1772de730bd56572e.jpg", "table_caption": ["Table 9: The results of mean scores on HPSv2. We report the mean and median of PickScore, HPS, ImageReward and Aesthetic score over the whole dataset. We also report the average score over the four evaluation metrics. SPIN-Diffusion outperforms all the baselines in terms of four metrics. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Table 10: The results of median scores on HPSv2. We report the mean and median of PickScore, HPS, ImageReward and Aesthetic score over the whole dataset. We also report the average score over the four evaluation metrics. SPIN-Diffusion outperforms all the baselines in terms of four metrics. ", "page_idx": 17}, {"type": "table", "img_path": "q3XavKPorV/tmp/5b4d6be098378751e4a1902b7ab82a86eb3fef50d49b8c4ffd4797b7522b5d53.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "q3XavKPorV/tmp/7d339f7352a662f70bfaae90b35dac2c46179e104c38dd62d1c942c27e781824.jpg", "table_caption": ["Table 11: The results of LoRA fine-tuning vs. full fine-tuning. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "A.4 Training Dynamics of SFT and DPO ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We first study the training dynamic of SPIN-Diffusion in comparison with SFT and Diffusion-DPO, and we plot the results in Figure 7. We observe that after training with about 50k data, the performance of SFT stop improving and maintains at about 20.8 in PickScore, 0.270 in HPS, 5.6 in Aesthetic and 8.9 in average score. These results is significantly inferior to those achieved by SPIN-Diffusion, which achieves 21.2 in PickScore, 0.272 in HPS, 5.9 in Aesthetic and 9.1 in average score. Compared to Diffusion-DPO, SPIN-Diffusion achieves a superior performance without the loser image. These results demonstrate that self-play fine-tuning plays a key role in SPIN-Diffusion\u2019s performance. ", "page_idx": 17}, {"type": "image", "img_path": "q3XavKPorV/tmp/f752ab87ce6abd06c76e4a1943ce743a6fbd1fc0b89cfe1512d2c4e27114f918.jpg", "img_caption": ["Figure 6: We show the images generated by different models based on prompts from PartiPrompts. The prompts are \u201ca photo of san francisco\u2019s golden gate bridge\u201d, \u201can aerial view of the Great Wall\u201d and \u201cFace of an orange frog in cartoon style\u201d. The models are: SD-1.5, SFT, Diffusion-DPO, Diffusion-DPO (reproduced), SPIN-Diffusion-Iter2 from left to right. SPIN-Diffusion demonstrates a notable improvement in image quality "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "B Additional Qualitative Results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this section, we provide extensive qualitative results to further support our findings. We first demonstrate the impact of different random seeds on model comparisons and include a wider range of visual examples to support the qualitative results. We also provide a image gallary in Figure 12. ", "page_idx": 18}, {"type": "text", "text": "Effect of different random seeds Random seeds sometimes influence the results produced by image generation models. Figures 8 and 9 demonstrate this effect, showcasing outputs of multiple models for the same prompt across four different random seeds. SPIN-Diffusion consistently generates higher-quality images across these variations. ", "page_idx": 18}, {"type": "text", "text": "More examples on Partiprompts To further showcase SPIN-Diffusion\u2019s capabilities to handle a wide range of styles and subjects, we present results on 10 additional prompts from the PartiPrompts dataset (totaling 1630 prompts). These examples highlight the model\u2019s ability to handle a wide range of styles and subjects. Figure 10 showcases results for 5 of these prompts, while Figure 11 highlights SPIN-Diffusion\u2019s ability in generating cartoon-style images with 5 additional prompts specifically containing the word \u2019cartoon\u2019. ", "page_idx": 18}, {"type": "text", "text": "C Additional Details for SPIN-Diffusion ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Additional Details of DDIM. ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Given a prompt $\\mathbf{c}$ , image $\\mathbf{x}_{\\mathrm{0}}$ , sequence $\\{\\alpha_{t}\\}_{t=1}^{T}\\,\\subseteq\\,(0,1]$ and $\\{\\sigma_{t}\\}_{t=1}^{T}\\,\\subseteq\\,[0,+\\infty)$ , the forward diffusion process defined in (3.1) is ", "page_idx": 18}, {"type": "equation", "text": "$$\nq(\\mathbf{x}_{1:T}|\\pmb{x}_{0}):=q(\\mathbf{x}_{T}|\\mathbf{x}_{0})\\prod_{t=2}^{T}q(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{x}_{0}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $q(\\mathbf{x}_{T}|\\mathbf{x}_{0})=\\mathcal{N}(\\sqrt{\\alpha_{T}}\\mathbf{x}_{0},(1-\\alpha_{T})\\mathbf{I})$ and $q\\big(\\mathbf{x}_{t-1}\\big|\\mathbf{x}_{t},\\mathbf{x}_{0}\\big)$ admits the following distribution, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{N}\\bigg(\\sqrt{\\alpha_{t-1}}\\mathbf{x}_{0}+\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\cdot\\frac{\\mathbf{x}_{t}-\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}}{\\sqrt{1-\\alpha_{t}}},\\sigma_{t}^{2}\\mathbf{I}\\bigg).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Here $\\{\\alpha_{t}\\}_{t=1}^{T}$ is a decreasing sequence with $\\alpha_{0}~~=~~1$ and $\\alpha_{T}$ approximately\u221a zero. By Bayesian rule, we can show that this diffusion process ensures that $q(\\bar{\\mathbf{x}_{t}}\\bar{\\mathbf{|x}}_{0})=\\mathcal{N}\\bar{(\\sqrt{\\alpha_{t}}\\mathbf{x}_{0},(1-\\varepsilon)\\bar{\\mathbf{\\rho}}}$ ", "page_idx": 18}, {"type": "image", "img_path": "q3XavKPorV/tmp/b31c3eb5c47e81bbb013f65e495ac4dc6d86cd39ff881b936e04cb136e88a295.jpg", "img_caption": ["Figure 7: The evaluation results on the Pick-a-Pic validation set of SFT, Diffusion-DPO and SPINDiffusion. The $\\mathbf{X}$ -axis is the number of training data. SFT reaches its limit quickly, while DiffusionDPO and SPIN-Diffusion continue to improve after training with over 800k data. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "$\\alpha_{t})\\mathbf{I})$ for all $t$ and reduces to DDPM (Ho et al., 2020) with a special choice of $\\sigma_{t}\\mathrm{~\\boldmath~\\omega~}=$ $\\sqrt{(1-\\alpha_{t-1})/(1-\\alpha_{t})}\\sqrt{(1-\\alpha_{t}/\\alpha_{t-1})}$ . ", "page_idx": 19}, {"type": "text", "text": "Given noise schedule $\\alpha_{t}$ and $\\sigma_{t}$ , examples from the generative model follows ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~~~p_{\\theta}(\\mathbf{x}_{0:T}|\\mathbf{c})=\\displaystyle\\prod_{t=1}^{T}p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{c})\\cdot p_{\\theta}(\\mathbf{x}_{T}|\\mathbf{c}),}\\\\ &{p_{\\theta}(\\mathbf{x}_{t-1}|\\mathbf{x}_{t},\\mathbf{c})=\\mathcal{N}\\big(\\pmb{\\mu}_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t),\\sigma_{t}^{2}\\mathbf{I}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Here $\\pmb{\\theta}$ belongs to the parameter space $\\Theta$ and $\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)$ is the mean of the Gaussian that can be parameterized (Ho et al., 2020; Song et al., 2020a) as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)=\\sqrt{\\alpha_{t-1}}\\Bigg(\\frac{\\mathbf{x}_{t}-\\sqrt{1-\\alpha_{t}}\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)}{\\sqrt{\\alpha_{t}}}\\Bigg)+\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\cdot\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\{\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\}_{t=1}^{T}$ are score functions that approximate noise. Compare (C.2) and (C.1)\u221a, we can see that $\\bigg(\\frac{\\mathbf{x}_{t}\\!-\\!\\sqrt{1\\!-\\!\\alpha_{t}}\\epsilon_{\\theta}\\big(\\mathbf{x}_{t},\\!\\mathbf{c},\\!t\\big)}{\\sqrt{\\alpha_{t}}}\\bigg)$ approximates $\\mathbf{x}_{\\mathrm{0}}$ , and $\\epsilon_{\\theta}$ approximates the noise $\\begin{array}{r}{\\epsilon_{t}:=\\frac{\\mathbf x_{t}-\\sqrt{\\alpha_{t}}\\mathbf x_{0}}{\\sqrt{1-\\alpha_{t}}}\\sim}\\end{array}$ $\\mathcal{N}(0,\\mathbf{I})$ . ", "page_idx": 19}, {"type": "text", "text": "C.2 Decoupling Technique ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In Section 4, we demonstrate that the objective function defined in (4.8) can be simplified to the form in (4.9). This reformulation only requires considering two consecutive sampling steps, $t-1$ and $t$ , rather than involving all intermediate steps. Now, we provide a detailed derivation. ", "page_idx": 19}, {"type": "text", "text": "Proof of Lemma 4.1. $L_{\\mathtt{S P I N}}(\\theta,\\theta_{k})$ ", "page_idx": 19}, {"type": "image", "img_path": "q3XavKPorV/tmp/c00586db79de95d9dce2a9533ebef703d20ead412e6fdc8369424b5e1cee6b92.jpg", "img_caption": ["Figure 8: We show the figures generated by different models based on a prompt from Pick-A-Pic test set. The prompt used is \u201ca picture of the sea on which a boat sails in a storm and sways in the sea\u201d. The models are SD-1.5, SFT, Diffusion-DPO (reproduced), SPIN-Diffusion-Iter1, SPINDiffusion-Iter2, and SPIN-Diffusion-Iter3, displayed from left to right. Each row shows the results for a different random seed. SPIN-Diffusion demonstrates a notable improvement in image quality "], "img_footnote": [], "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\mathbb{E}_{\\exp(y),x}\\exp_{t}\\exp_{t}\\exp_{t}\\exp_{t}\\exp_{t}\\exp_{t}\\Bigg[\\bigg(-\\displaystyle\\frac{\\sum_{i=1}^{n}\\beta_{i}}{\\sum_{i=1}^{n}}\\Big[\\big[\\kappa_{i}-\\beta_{i}(\\kappa_{i},\\epsilon_{i})\\big]\\Big]_{2}^{2}-\\big\\|\\kappa_{i-1}-\\mu_{\\theta_{1}}(\\kappa_{i},\\epsilon_{i})\\big\\|_{2}^{2}\\Bigg]}\\\\ &{\\qquad-\\left\\|\\kappa_{i-1}-\\mu_{\\theta_{1}}(\\kappa_{i},\\epsilon_{i})\\right\\|_{2}^{2}\\Bigg]+\\left\\|\\kappa_{i-1}^{2}-\\mu_{\\theta_{1}}(\\kappa_{i},\\kappa_{i}^{\\prime},\\epsilon_{i})\\right\\|_{2}^{2}\\Bigg]\\Bigg]}\\\\ &{\\leq\\mathbb{E}_{\\exp(y),x}\\exp_{t}\\exp_{t}\\Big[\\!\\exp_{t}\\!\\bigg[\\displaystyle\\frac{1}{\\sum_{i=1}^{n}\\beta_{i}}\\bigg[\\bigg(-\\beta_{i}\\Big[\\Big[\\kappa_{i}-\\beta_{i}\\Big(\\kappa_{i},\\epsilon_{i})\\Big]\\Big]_{2}^{2}-\\big\\|\\kappa_{i-1}-\\mu_{\\theta_{1}}(\\kappa_{i},\\epsilon_{i})\\big\\|_{2}^{2}\\bigg)}\\\\ &{\\qquad-\\left\\|\\kappa_{i-1}^{2}-\\mu_{\\theta_{1}}(\\kappa_{i}^{\\prime},\\epsilon_{i})\\right\\|_{2}^{2}\\Big]+\\left\\|\\kappa_{i-1}^{2}-\\mu_{\\theta_{1}}(\\kappa_{i},\\epsilon_{i}^{\\prime},\\epsilon_{i})\\right\\|_{2}^{2}\\bigg]\\Bigg]}\\\\ &{=\\mathbb{E}_{\\exp(y),x}\\exp_{t}\\!\\bigg[\\!\\exp_{t}\\!\\bigg[\\!\\exp_{t}\\!\\bigg[\\!\\exp_{t}\\!\\bigg[\\beta_{i}\\kappa_{i}\\!-\\!\\gamma_{i}\\Big]\\!+\\![\\kappa_{i}(\\kappa_{i-1}\\!-\\!\\mu_{\\theta_{1}}(\\kappa_{i},\\epsilon_{i})\\Big]\\Big]_{2}^{2}\\bigg]\\!\\bigg]}\\\\ &{\\qquad-\\left\\|\\kappa_{i-1}-\\mu_{\\theta_{1}}(\\kappa_{\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the first inequality is by Jensen\u2019s inequality and the convexity of the function $\\ell$ , the second equality is by integrating the average $\\frac{1}{T}\\sum_{t=1}^{T}$ into the expectation via $t\\sim\\mathrm{Uniform}\\{1,\\ldots,T\\}$ , and the third inequality holds because the argument inside the expectation is only depend of sampling step $t-1$ and $t$ . ", "page_idx": 20}, {"type": "image", "img_path": "q3XavKPorV/tmp/34abe63a594651206dc18a4488b3f46423e536b557525116507bf7b1eb9b2298.jpg", "img_caption": ["Figure 9: We show the figures generated by different models based on a prompt from Pick-A-Pic test set. The prompt used is $^{\\bullet\\bullet}A$ cute hedgehog holding flowers\u201d. The models are SD-1.5, SFT, Diffusion-DPO (reproduced), SPIN-Diffusion-Iter1, SPIN-Diffusion-Iter2, and SPIN-Diffusion-Iter3, displayed from left to right. Each row shows the results for a different random seed. SPIN-Diffusion demonstrates a notable improvement in image quality "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "C.3 Objective Function of SPIN-Diffusion ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We look deep into the term $\\left|\\left|\\mathbf{x}_{t-1}-\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\right|\\right|_{2}^{2}$ and $\\left|\\left|\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta}\\bigl(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t\\bigr)\\right|\\right|_{2}^{2}$ of (4.8) and (4.9) in this section. ", "page_idx": 21}, {"type": "text", "text": "When $\\mathbf{x}_{0:T}$ Follows Forward Process. We have that $\\mathbf{x}_{0:T}\\sim p_{\\mathrm{data}}(\\cdot|\\mathbf{c})$ and by (C.1) and (C.2) we have that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathbf{x}_{t-1}=\\sqrt{\\alpha_{t-1}}\\mathbf{x}_{0}+\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\cdot\\frac{\\mathbf{x}_{t}-\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}}{\\sqrt{1-\\alpha_{t}}}+\\sigma_{t}\\widehat{\\epsilon}_{t}}\\\\ {\\displaystyle\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)=\\sqrt{\\alpha_{t-1}}\\Bigg(\\frac{\\mathbf{x}_{t}-\\sqrt{1-\\alpha_{t}}\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)}{\\sqrt{\\alpha_{t}}}\\Bigg)+\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\cdot\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\widehat{\\epsilon}_{t}\\sim\\mathcal{N}(0,\\bf{I})$ . Therefore, $\\left|\\left|\\mathbf{x}_{t-1}-\\mu_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\right|\\right|_{2}^{2}$ can be simplified to ", "page_idx": 21}, {"type": "equation", "text": "$$\nh_{t}^{2}\\bigg\\|\\frac{\\mathbf{x}_{t}-\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}}{\\sqrt{1-\\boldsymbol{\\alpha}_{t}}}-\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)+\\left(\\boldsymbol{\\sigma}_{t}/h_{t}\\right)\\cdot\\widehat{\\mathbf{\\epsilon}}_{t}\\bigg\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $h_{t}\\,=\\,\\left[\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\,-\\,\\sqrt{\\alpha_{t-1}/\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}}\\right]$ and $\\begin{array}{r}{\\frac{{\\mathbf x}_{t}-\\sqrt{\\alpha_{t}}{\\mathbf x}_{0}}{\\sqrt{1-\\alpha_{t}}}\\sim\\mathcal{N}(0,{\\mathbf I})}\\end{array}$ following a Gaussian distribution. When $\\sigma_{t}\\to0$ , (C.3) becomes $h_{t}^{2}\\big\\|\\epsilon_{t}\\!-\\!\\epsilon_{\\theta}\\big(\\mathbf{x}_{t},\\mathbf{c},t\\big)\\big\\|_{2}^{2}$ with $h_{t}=\\left[\\sqrt{1-\\alpha_{t-1}}-\\right.$ $\\sqrt{\\alpha_{t-1}/\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}}\\Big]$ and $\\begin{array}{r}{\\epsilon_{t}:=\\frac{\\mathbf{x}_{t}-\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}}{\\sqrt{1-\\alpha_{t}}}\\sim\\mathcal{N}(0,\\mathbf{I})}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "When $\\mathbf{x}_{0:T}^{\\prime}$ Follows the Backward Process. We have that $\\mathbf{x}_{0:T}^{\\prime}\\sim p\\pmb{\\theta}_{k}(\\cdot|\\mathbf{c})$ and ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\bf x}_{t-1}^{\\prime}=\\mu_{\\theta_{k}}({\\bf x}_{t}^{\\prime},{\\bf c},t)+\\sigma_{t}\\widehat{\\epsilon}_{t}^{\\prime}}\\\\ {\\quad\\quad=\\sqrt{\\alpha_{t-1}}\\bigg(\\frac{{\\bf x}_{t}^{\\prime}-\\sqrt{1-\\alpha_{t}}\\epsilon_{\\theta_{k}}({\\bf x}_{t}^{\\prime},{\\bf c},t)}{\\sqrt{\\alpha_{t}}}\\bigg)+\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\cdot\\epsilon_{\\theta_{k}}({\\bf x}_{t}^{\\prime},{\\bf c},t)+\\sigma_{t}\\widehat{\\epsilon}_{t}^{\\prime}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "image", "img_path": "q3XavKPorV/tmp/d70327c54518f9b19b5b3c33e21adc450bbc682e552376b77d8c2952d088d5ef.jpg", "img_caption": ["Figure 10: We show the figures generated by different models based on prompts from PartiPrompts. The prompts are \u201ca old-time car with a large front grille\u201d, \u201ca full moon rising above a mountain at night\u201d, \u201ca young badger delicately sniffing a yellow rose, richly textured oil painting\u201d, \u201ca cartoon of a man standing under a tree\u201d and \u201ca prop plane flying low over the Great Wall\u201d. The models are: SD-1.5, SFT, Diffusion-DPO, Diffusion-DPO (reproduced), SPIN-Diffusion-Iter2 from left to right, all utilizing the same random seed for fair comparison "], "img_footnote": [], "page_idx": 22}, {"type": "equation", "text": "$$\n\\mu_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)=\\sqrt{\\alpha_{t-1}}\\bigg(\\frac{\\mathbf{x}_{t}^{\\prime}-\\sqrt{1-\\alpha_{t}}\\epsilon_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)}{\\sqrt{\\alpha_{t}}}\\bigg)+\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\cdot\\epsilon_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\epsilon_{t}^{\\prime}\\sim\\mathcal{N}(0,\\bf{I})$ . Therefore, $\\left|\\left|\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\right|\\right|_{2}^{2}$ can be simplified to ", "page_idx": 22}, {"type": "equation", "text": "$$\nh_{t}^{2}\\big\\|\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)-\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)+(\\sigma_{t}/h_{t})\\cdot\\widehat{\\epsilon}_{t}^{\\prime}\\big\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\begin{array}{r c l}{h_{t}}&{\\!=}&{\\left[\\sqrt{1-\\alpha_{t-1}-\\sigma_{t}^{2}}\\,-\\,\\sqrt{\\alpha_{t-1}/\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}}\\right]}\\end{array}$ . When $\\sigma_{t}\\mathrm{~\\,~}\\to~0$ , (C.4) becomes $h_{t}^{2}\\big\\|\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)-\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}$ with $h_{t}=\\left[\\sqrt{1-\\alpha_{t-1}}-\\sqrt{\\alpha_{t-1}/\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}}\\right]$ . ", "page_idx": 22}, {"type": "text", "text": "Simple Decoupled SPIN-Diffusion Objective Function. Substituting (C.3) and (C.4) into (4.9) and applying $\\sigma_{t}\\to0$ yields, ", "page_idx": 22}, {"type": "equation", "text": "$$\nL_{\\mathrm{SPIN}}^{\\mathrm{approx}}(\\pmb\\theta,\\pmb\\theta_{k})=\\mathbb{E}\\bigg[\\ell\\bigg(-\\beta_{t}h_{t}^{2}\\Big[\\big|\\pmb|\\epsilon_{t}-\\epsilon_{\\pmb\\theta}(\\mathbf x_{t},\\mathbf c,t)\\big|\\big|_{2}^{2}-\\big|\\big|\\epsilon_{t}-\\epsilon_{\\pmb\\theta_{k}}(\\mathbf x_{t},\\mathbf c,t)\\big|\\big|_{2}^{2}\\bigg]\n$$", "text_format": "latex", "page_idx": 22}, {"type": "image", "img_path": "q3XavKPorV/tmp/4212ea71e38239b410346fa0b4e090099687fc11b574da8f4737805a065d8ddb.jpg", "img_caption": ["Figure 11: We show the figures generated by different models based on prompts from PartiPrompts. The prompts are \u201cA cartoon house with red roof\u201d, \u201ca cartoon of an angry shark\u201d, \u201ca cartoon of a bear birthday party\u201d, \u201ca cartoon of a house on a mountain\u201d and \u201ca cartoon of a boy playing with a tiger\u201d. The models are: SD-1.5, SFT, Diffusion-DPO, Diffusion-DPO (reproduced), SPIN-Diffusion-Iter2 from left to right, all utilizing the same random seed for fair comparison "], "img_footnote": [], "page_idx": 23}, {"type": "equation", "text": "$$\n-\\;\\Big\\|\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)-\\epsilon_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\big\\|_{2}^{2}\\Big)\\Bigg],\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $h_{t}\\,=\\,\\sqrt{1-\\alpha_{t-1}}-\\sqrt{\\alpha_{t-1}/\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}}$ , $\\mathbf{x}_{t}\\,=\\,\\alpha_{t}\\mathbf{x}_{0}+(1-\\alpha_{t})\\epsilon_{t}$ , and the expectation is computed over the distribution, $\\mathbf{\\boldsymbol{\\mathsf{\\Sigma}}}\\sim q(\\mathbf{\\boldsymbol{c}}),\\mathbf{\\boldsymbol{x}}_{0}\\sim p_{\\mathrm{data}}(\\mathbf{\\boldsymbol{x}}_{0}|\\mathbf{\\boldsymbol{c}}),\\mathbf{\\boldsymbol{x}}_{t}^{\\prime}\\sim p_{\\theta_{k}}(\\mathbf{\\boldsymbol{x}}_{t}^{\\prime}|\\mathbf{\\boldsymbol{c}})$ , $\\epsilon_{t}\\sim\\mathcal{N}(0,\\bf{I})$ and $t\\,\\sim\\,\\mathrm{Uniform}\\{1,\\ldots,T\\}$ . (C.5) still need the intermediate steps $\\mathbf{x}_{t}^{\\prime}$ , as discussed below (4.9) in Section 4, we can approximate the backward process with the forward process and obtain ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\^\\mathrm{\\approx}(\\theta,\\theta_{k})=\\mathbb{E}\\bigg[\\ell\\bigg(-\\beta_{t}h_{t}^{2}\\Big[\\big\\|\\epsilon_{t}-\\epsilon_{\\theta}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}-\\big\\|\\epsilon_{t}-\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}-\\big\\|\\epsilon_{t}^{\\prime}-\\epsilon_{\\theta}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\big\\|_{2}^{2}}\\\\ &{\\qquad\\qquad\\qquad+\\left\\|\\epsilon_{t}^{\\prime}-\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\big\\|_{2}^{2}\\bigg]\\bigg)\\bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\mathbf{\\xi}_{t}=\\sqrt{1-\\alpha_{t-1}}-\\sqrt{\\alpha_{t-1}/\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}},\\mathbf{x}_{t}=\\alpha_{t}\\mathbf{x}_{0}+(1-\\alpha_{t})\\mathbf{\\epsilon}_{t},\\mathbf{x}_{t}^{\\prime}=\\alpha_{t}\\mathbf{x}_{0}^{\\prime}+(1-\\alpha_{t})\\mathbf{\\epsilon}_{t},$ , and the expectation is computed over the distribution, $\\mathbf{c}\\sim q(\\mathbf{c}),\\mathbf{x}_{0}\\sim p_{\\mathrm{data}}(\\mathbf{x}_{0}|\\mathbf{c}),\\mathbf{x}_{0}^{\\prime}\\sim p_{\\theta_{k}}(\\mathbf{x}_{0}^{\\prime}|\\mathbf{c}),$ $\\overline{{\\epsilon_{t}}}\\sim\\mathcal{N}(0,\\overline{{\\mathbf{I}}})$ , $\\epsilon_{t}^{\\prime}\\sim\\mathcal{N}(0,\\bf{I})$ and $t\\sim\\mathrm{Uniform}\\{1,\\ldots,T\\}$ . ", "page_idx": 23}, {"type": "image", "img_path": "q3XavKPorV/tmp/6ed250a2a33d1a070e0edc5b3bf32bda9a97c3a088a046d2daac6f83e73f263c.jpg", "img_caption": ["Figure 12: Image galary generated by SPIN-Diffusion, a self-play fine-tuning algorithm for diffusion models. The results are fine-tuned from Stable Diffusion v1.5 on the winner images of the Pick-a-Pic dataset. The prompts used for generating the above images are chosen from the Pick-a-Pic test set. The generated images demonstrate superior performance in terms of overall visual attractiveness and coherence with the prompts. SPIN-Diffusion is featured by its independence from paired human preference data, offering a useful tool for fine-tuning on custom datasets with only single image per text prompt provided. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "D Proof of Theorems in Section 5 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Proof of Theorem 5.2. Plugging (C.3) and (C.4) into (4.9) yields the following loss parameterized with \u03f5\u03b8, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{\\mathrm{SPIN}}^{\\mathrm{approx}}(\\theta,\\theta_{k})=\\mathbb{E}\\bigg[\\ell\\bigg(-\\beta_{t}h_{t}^{2}\\Big[\\big\\|\\epsilon-\\epsilon_{\\theta}(\\mathbf{x}_{t},c,t)+(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}\\big\\|_{2}^{2}-\\big\\|\\epsilon-\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t},c,t)+(\\sigma_{t}/h_{t})\\cdot}\\\\ &{\\qquad\\qquad\\qquad+\\left\\|(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}-\\big\\|\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},c,t)-\\epsilon_{\\theta}(\\mathbf{x}_{t}^{\\prime},c,t)+(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}\\bigg]\\bigg)\\bigg],\\ (\\mathrm{D}.1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\epsilon_{t},\\epsilon_{t}^{\\prime}\\sim\\mathcal{N}(0,\\mathbf{I})$ . When $\\sigma_{t}\\to0$ , (D.1) can be simplified to (C.5). In this proof, we will stick to the formula (D.1) to provide the proof for all $\\sigma_{t}\\geq0$ . ", "page_idx": 24}, {"type": "text", "text": "Since $\\theta_{k}$ is not the global optimum of $L_{\\mathrm{DM}}$ by condition, there exists $\\pmb{\\theta}^{*}$ such that $L_{\\mathrm{DM}}(\\theta^{*})\\leq$ $L_{\\mathrm{DM}}(\\pmb{\\theta}_{k})$ , which gives that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\Big[\\gamma_{t}\\big\\|\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t},t,c\\big)-\\epsilon\\big\\|_{2}^{2}\\Big]\\leq\\mathbb{E}\\Big[\\gamma_{t}\\big\\|\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t},t,c\\big)-\\epsilon\\big\\|_{2}^{2}\\Big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "$t\\sim\\mathrm{Uniform}\\{1,\\ldots,T\\}$ s.  cDoemfinpeu $g(s)=L_{\\mathtt{S P I N}}^{\\mathtt{a p p r o x}}(\\theta^{*},\\theta_{k})$ n $c\\sim q(\\cdot),\\mathbf{x}_{0}\\sim q_{\\mathrm{data}}(\\cdot|c),\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I})$ $\\beta_{t}=s\\gamma_{t}/h_{t}^{2}$ ,", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{g(s)=\\mathbb{E}\\bigg[\\ell\\bigg(-\\beta_{t}h_{t}^{2}\\Big[\\big\\|\\epsilon-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}-\\big\\|\\epsilon-\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}}\\\\ &{\\qquad\\quad+\\left\\|\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}-\\big\\|\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}\\bigg]\\bigg)\\bigg]}\\\\ &{=\\mathbb{E}\\bigg[\\ell\\bigg(-s\\gamma_{t}\\Big[\\big\\|\\epsilon-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}-\\big\\|\\epsilon-\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}}\\\\ &{\\qquad\\quad+\\left\\|\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}-\\big\\|\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}\\bigg]\\bigg)\\bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then we have that $g(0)=0$ and ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{l g}{l s}(0)=\\mathbb{E}\\bigg[-\\ell^{\\prime}(0)\\gamma_{t}\\bigg(\\big\\|\\epsilon-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}-\\big\\|\\epsilon-\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}}\\\\ &{\\qquad\\qquad+\\left\\|\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}-\\big\\|\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}\\bigg)\\bigg]}\\\\ &{=-\\ell^{\\prime}(0)\\bigg(\\mathbb{E}\\gamma_{t}\\big\\|\\epsilon-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}-\\mathbb{E}\\gamma_{t}\\big\\|\\epsilon-\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}\\big\\|_{2}^{2}}\\\\ &{\\qquad\\qquad+\\,\\mathbb{E}\\gamma_{t}\\big\\|\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}-\\mathbb{E}\\gamma_{t}\\big\\|\\epsilon_{\\theta_{k}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)-\\epsilon_{\\theta^{*}}\\big(\\mathbf{x}_{t}^{\\prime},c,t\\big)+\\big(\\sigma_{t}/h_{t}\\big)\\cdot\\epsilon_{t}^{\\prime}\\big\\|_{2}^{2}\\bigg),\\quad\\quad(\\mathbb{D}\\mathcal{A})}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\mathbf{x}_{t}=\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}+\\sqrt{1-\\alpha_{t}}\\epsilon$ and the expectation is computed over the distribution $c\\sim q(\\cdot),\\mathbf{x}_{0}\\sim$ $q_{\\mathrm{data}}(\\cdot|c),\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I}),t\\sim\\mathrm{Uniform}\\{1,\\dots,T\\}$ and $\\epsilon_{t},\\epsilon_{t}^{\\prime}\\sim\\mathcal{N}(0,\\mathbf{I})$ . Since $\\epsilon_{t},\\epsilon_{t}^{\\prime}$ follows standard Multivariate normal distribution and independent with $\\mathbf{x}_{t},\\mathbf{x}_{t}^{\\prime},\\mathbf{\\epsilon}\\epsilon,\\mathbf{x}_{0}$ , we can simplify the the terms in (D.3) as follows, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\gamma t}\\Big\\lVert\\epsilon-\\epsilon_{\\theta^{*}}(\\mathbf{x}_{t},c,t)+(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}\\Big\\rVert_{2}^{2}}\\\\ &{=\\mathbb{E}_{\\gamma t}\\Big\\lVert\\epsilon-\\epsilon_{\\theta^{*}}(\\mathbf{x}_{t},c,t)\\Big\\rVert_{2}^{2}+\\mathbb{E}_{\\gamma t}\\Big\\lVert(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}\\Big\\rVert_{2}^{2}}\\\\ &{\\mathbb{E}_{\\gamma t}\\Big\\lVert\\epsilon-\\epsilon_{\\theta_{h}}(\\mathbf{x}_{t},c,t)+(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}\\Big\\rVert_{2}^{2}}\\\\ &{=\\mathbb{E}_{\\gamma t}\\Big\\lVert\\epsilon-\\epsilon_{\\theta_{h}}(\\mathbf{x}_{t},c,t)\\Big\\rVert_{2}^{2}+\\mathbb{E}_{\\gamma t}\\Big\\lVert(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}\\Big\\rVert_{2}^{2}}\\\\ &{\\mathbb{E}_{\\gamma t}\\Big\\lVert\\epsilon_{\\theta_{h}}(\\mathbf{x}_{t}^{\\prime},c,t)-\\epsilon_{\\theta^{*}}(\\mathbf{x}_{t}^{\\prime},c,t)+(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}^{\\prime}\\Big\\rVert_{2}^{2}}\\\\ &{=\\mathbb{E}_{\\gamma t}\\Big\\lVert\\epsilon_{\\theta_{h}}(\\mathbf{x}_{t}^{\\prime},c,t)-\\epsilon_{\\theta^{*}}(\\mathbf{x}_{t}^{\\prime},c,t)\\Big\\rVert_{2}^{2}+\\mathbb{E}_{\\gamma t}\\Big\\lVert(\\sigma_{t}/h_{t})\\cdot\\epsilon_{t}^{\\prime}\\Big\\rVert_{2}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where we apply the property of standard normal distribution that $\\mathbb{E}[\\pmb{\\epsilon}_{t}]=\\mathbb{E}[\\pmb{\\epsilon}_{t}^{\\prime}]=\\pmb{0}$ . Plugging (D.4), (D.5), (D.6) into (D.3) gives that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d g}{d s}(0)=-\\ell^{\\prime}(0)\\biggl(\\mathbb{E}\\gamma_{t}\\bigl\\|\\epsilon-\\epsilon_{\\theta^{*}}\\bigl(\\mathbf{x}_{t},c,t\\bigr)\\bigr\\|_{2}^{2}-\\mathbb{E}\\gamma_{t}\\bigl\\|\\epsilon-\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t},c,t)\\bigr\\|_{2}^{2}}\\\\ &{\\qquad\\qquad-\\,\\mathbb{E}\\gamma_{t}\\bigl\\|\\epsilon_{\\theta_{k}}(\\mathbf{x}_{t}^{\\prime},c,t)-\\epsilon_{\\theta^{*}}(\\mathbf{x}_{t}^{\\prime},c,t)\\bigr\\|_{2}^{2}\\biggr)}\\\\ &{\\qquad<0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the last inequality is by (D.2). Here $\\mathbf{x}_{t}=\\sqrt{\\alpha_{t}}\\mathbf{x}_{0}+\\sqrt{1-\\alpha_{t}}\\epsilon$ and the expectation is computed over the distribution $c\\sim q(\\cdot),{\\bf x}_{0}\\sim q_{\\mathrm{data}}(\\cdot|c),\\dot{\\epsilon^{}}\\sim\\mathcal{N}(0,{\\bf I}),$ , t \u223cUniform $\\{1,\\bar{\\cdot}\\cdot\\cdot,T\\}$ . ", "page_idx": 25}, {"type": "text", "text": "Therefore, there exist a $\\lambda_{0}$ such that for all $0\\;<\\;\\lambda\\;<\\;\\lambda_{0}$ , we have $g(\\lambda)\\,<\\,\\ell(0)$ . So for those $\\beta_{t}=s\\gamma_{t}/h_{t}^{2}$ with $0<\\lambda<\\lambda_{0}$ , we have that ", "page_idx": 25}, {"type": "equation", "text": "$$\nL_{\\mathtt{S P I N}}^{\\mathrm{approx}}(\\theta^{*},\\theta_{k})=g(\\lambda)<g(0)=L_{\\mathtt{S P I N}}(\\theta_{k},\\theta_{k}),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the inequality holds due to the choice of $\\lambda$ . Therefore, we conclude that $\\theta_{k}$ is not the global optimum of (4.9). ", "page_idx": 25}, {"type": "text", "text": "Proof of Theorem 5.3. By (4.9) we have that, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{\\mathrm{SPIN}}^{\\mathrm{approx}}(\\pmb{\\theta},\\pmb{\\theta}_{k})=\\mathbb{E}\\bigg[\\ell\\bigg(-\\beta_{t}\\Big[\\big\\|\\mathbf{x}_{t-1}-\\mu_{\\pmb{\\theta}}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}-\\big\\|\\mathbf{x}_{t-1}-\\mu_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{t},\\mathbf{c},t)\\big\\|_{2}^{2}\\bigg]}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\left\\|\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\pmb{\\theta}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\right\\|_{2}^{2}+\\big\\|\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{t}^{\\prime},\\mathbf{c},t)\\big\\|_{2}^{2}\\bigg]\\bigg)\\bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the expectationis computed over the distribution $\\begin{array}{r l r}{\\mathbf{c}}&{{}\\sim}&{q(\\mathbf{c})}\\end{array}$ , $\\begin{array}{r l}{\\left(\\mathbf{x}_{t-1},\\mathbf{x}_{t}\\right)}&{{}\\sim}\\end{array}$ $\\begin{array}{r}{\\int p_{\\mathrm{data}}(\\mathbf{x}_{0}|\\mathbf{c})q(\\mathbf{\\bar{x}}_{t-1},\\mathbf{x}_{t}|\\mathbf{x}_{0})d\\mathbf{x}_{0}}\\end{array}$ , $\\begin{array}{r l r}{\\mathbf{\\widetilde{x}}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})_{.}}&{{}\\sim}&{\\int p_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{0}^{\\prime}|\\mathbf{c})q(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{\\widetilde{x}}_{t}^{\\prime}|\\mathbf{x}_{0}^{\\prime})d\\mathbf{x}_{t}}\\end{array}$ \u20320, t \u223c $\\mathrm{Uniform}\\{1,\\ldots,T\\}$ . Since $p_{\\mathrm{data}}(\\cdot|\\mathbf{c})\\,=\\,p_{\\pmb{\\theta}_{t}}(\\cdot|\\mathbf{c})$ , we can conclude that $({\\bf x}_{t-1},{\\bf x}_{t})$ and $(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})$ are independent and identically distributed random variable. Therefore, by symmetry property of $({\\bf x}_{t-1},{\\bf x}_{t})$ and $(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})$ , we have for any $\\theta\\in\\Theta$ that ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{L_{\\mathrm{coll}}^{\\mathrm{suppen}}\\left(\\theta,\\delta_{i}\\right)=\\frac{1}{2}\\mathbb{E}\\bigg[\\bigg\\langle-\\beta_{i}\\bigg[\\Big\\vert8_{t-1}-\\mu_{\\theta}(\\mathrm{S}_{i},\\mathrm{c},t)\\Big\\vert\\Big]_{2}^{2}-\\left\\vert\\mathbf{x}_{t-1}-\\mu_{\\theta_{0}}(\\mathrm{S}_{i},\\mathrm{c},t)\\right\\vert\\bigg\\vert_{2}^{2}}\\\\ &{\\,\\quad-\\left\\vert\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta}(\\mathrm{S}_{i}^{\\prime},\\mathrm{c},t)\\right\\vert\\bigg]_{2}^{2}+\\left\\vert\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta_{0}}(\\mathrm{S}_{i}^{\\prime},\\mathrm{c},t)\\right\\vert\\bigg\\vert_{2}^{2}\\bigg]}\\\\ &{\\phantom{2p c}+\\delta\\bigg(-\\beta_{i}\\bigg[\\Big\\vert8_{t-1}^{\\prime}-\\mu_{\\theta}(\\mathrm{S}_{i}^{\\prime},\\mathrm{c},t)\\Big\\vert\\Big]_{2}^{2}-\\left\\vert\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta_{0}}(\\mathrm{S}_{i}^{\\prime},\\mathrm{c},t)\\right\\vert\\bigg\\vert_{2}^{2}}\\\\ &{\\,\\quad-\\left\\vert\\mathbf{x}_{t-1}-\\mu_{\\theta}(\\mathrm{S}_{i},\\mathrm{c},t)\\right\\vert\\bigg\\vert_{2}^{2}+\\left\\vert\\mathbf{x}_{t-1}-\\mu_{\\theta_{0}}(\\mathrm{S}_{i},\\mathrm{c},t)\\right\\vert\\bigg\\vert_{2}^{2}\\bigg)\\bigg]}\\\\ &{\\geq\\mathbb{E}\\bigg[\\bigg\\langle-\\frac{\\beta_{t}}{2}\\Big\\vert\\Big\\vert8_{t-1}-\\mu_{\\theta}(\\mathrm{S}_{i},\\mathrm{c},t)\\Big\\vert\\Big\\vert_{2}^{2}-\\left\\vert\\mathbf{x}_{t-1}-\\mu_{\\theta_{0}}(\\mathrm{S}_{i},\\mathrm{c},t)\\right\\vert\\Big\\vert_{2}^{2}}\\\\ &{\\,\\quad-\\left\\vert\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\theta}(\\mathrm{S}_{i}^{\\prime},\\mathrm{c},t)\\right\\vert\\bigg\\vert_{2}^{2}+\\left\\vert\\mathbf{x}_{t-1}^{\\prime}-\\mu_{\\\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the inequality is due to Jensen\u2019s inequality (recalling that $\\ell$ is convex in Assumption 5.1), and the expectation is computed over the distribution $\\begin{array}{r l r}{\\mathbf{c}}&{{}\\sim}&{q(\\mathbf{c})}\\end{array}$ , $\\begin{array}{r}{\\bar{(\\mathbf{x}_{t-1},\\mathbf{x}_{t})}\\sim\\int p_{\\mathrm{data}}(\\mathbf{x}_{0}|\\mathbf{c})q(\\bar{\\mathbf{x}_{t-1}},\\mathbf{x}_{t}|\\mathbf{x}_{0})d\\mathbf{x}_{0}}\\end{array}$ , $\\begin{array}{r}{(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime})\\sim\\int p_{\\pmb{\\theta}_{k}}(\\mathbf{x}_{0}^{\\prime}|\\mathbf{c})q(\\mathbf{x}_{t-1}^{\\prime},\\mathbf{x}_{t}^{\\prime}|\\mathbf{x}_{0}^{\\prime})d\\mathbf{x}_{0}^{\\prime}}\\end{array}$ , $t\\sim$ $\\mathrm{Uniform}\\{1,\\ldots,T\\}$ . Therefore, we have that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{\\mathtt{S P I N}}^{\\mathrm{approx}}(\\pmb{\\theta},\\pmb{\\theta}_{k})\\geq\\ell(0)=L_{\\mathtt{S P I N}}^{\\mathrm{approx}}(\\pmb{\\theta}_{k},\\pmb{\\theta}_{k}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "which means that $\\theta_{k}$ is the global optimum of (4.9). As a consequence, $\\pmb{\\theta}_{k+1}=\\pmb{\\theta}_{k}$ . ", "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We validate our claim through theoretical analysis and experimental results. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 27}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We discuss the limitations after our conclusion. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 27}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The assumptions and proof are fully presented. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We provide a detailed descriptions on model, data, pipeline and parameters. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [No] ", "page_idx": 28}, {"type": "text", "text": "Justification: We are not able to reorganize the code at the time of submission. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 29}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide the training methods in detail. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: Error bars are not involved in our paper. However, we provide the qualitative results of different random seed. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We describe the computing resource with experimental settings. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 30}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The research conducted in this paper conform with the NeurIPS Code of Ethics. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 30}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We place our broader impact section at the start of the Appendix. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: This paper proposes fine-tuning methodology that is generally applicable to any pretrained language model and preference model, and poses no particular such risks. ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 31}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: We cite the original papers that produced the dataset and base models. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 31}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 32}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not release new assets ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 32}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 32}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 32}]