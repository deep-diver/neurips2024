[{"figure_path": "SLnsoaY4u1/tables/tables_8_1.jpg", "caption": "Table 3: Evaluation of solving inverse problems on FFHQ 256 \u00d7 256 validation dataset (1k samples). Despite considerable efforts to optimize parameters, pixel-based ReSample did not generate meaningful results for phase retrieval.", "description": "This table presents a comparison of different algorithms for solving three inverse problems: super-resolution, phase retrieval, and quantized sensing, using the FFHQ dataset.  The algorithms compared are DPnP-DDIM (the proposed method), DPS, LGD-MC, and ReSample.  The evaluation metrics are LPIPS and PSNR.  The results show that DPnP-DDIM achieves competitive performance, particularly in phase retrieval where other methods struggle.  The table highlights the computational cost per sample for each algorithm.", "section": "5 Numerical experiments"}, {"figure_path": "SLnsoaY4u1/tables/tables_9_1.jpg", "caption": "Table 4: Evaluation of solving inverse problems on ImageNet 256 \u00d7 256 validation dataset (1k samples). Despite considerable efforts to optimize parameters, pixel-based ReSample did not generate meaningful results for phase retrieval.", "description": "This table presents the quantitative results of evaluating different image reconstruction algorithms on the ImageNet dataset.  The algorithms are compared across three inverse problem tasks: super-resolution, phase retrieval, and quantized sensing.  The metrics used for comparison are LPIPS and PSNR.  The table highlights that the proposed DPnP-DDIM method achieves superior performance compared to existing methods across all tasks, except for the ReSample algorithm which failed to produce meaningful results for phase retrieval.  Computation time per sample is also provided for each algorithm.", "section": "Numerical experiments"}, {"figure_path": "SLnsoaY4u1/tables/tables_29_1.jpg", "caption": "Table 6: Number of NFEs for different algorithms.", "description": "This table compares the number of neural function estimations (NFEs) required for different algorithms (DPnP-DDIM, DPnP-DDPM, DPS, LGD-MC, and ReSample) to generate samples.  NFEs represent the computational cost in terms of the number of calls to score functions. The values shown are approximate and vary depending on factors like initialization and the annealing schedule used in DPnP.", "section": "G.4 Additional performance metrics"}, {"figure_path": "SLnsoaY4u1/tables/tables_30_1.jpg", "caption": "Table 7: FID and SSIM of solving inverse problems on FFHQ 256 \u00d7 256 validation dataset (1k samples).", "description": "This table presents a comparison of the Fr\u00e9chet Inception Distance (FID) and Structural Similarity Index Measure (SSIM) scores for four different algorithms applied to three inverse problems: super-resolution, phase retrieval, and quantized sensing.  Lower FID scores indicate better performance, while higher SSIM scores indicate better performance.  The results show that the DPnP-DDIM algorithm achieves better or comparable results than the other algorithms in each inverse problem.", "section": "Numerical experiments"}, {"figure_path": "SLnsoaY4u1/tables/tables_30_2.jpg", "caption": "Table 7: FID and SSIM of solving inverse problems on FFHQ 256 \u00d7 256 validation dataset (1k samples).", "description": "This table shows the Fr\u00e9chet Inception Distance (FID) and Structural Similarity Index Measure (SSIM) scores for four different algorithms on the FFHQ dataset, solving three different inverse problems: super-resolution (linear), phase retrieval (nonlinear), and quantized sensing (nonlinear).  Lower FID and higher SSIM values indicate better performance.  The results demonstrate the relative performance of DPnP-DDIM compared to other state-of-the-art algorithms.", "section": "Numerical experiments"}]