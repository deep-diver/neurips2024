[{"figure_path": "cCL92OPlDz/figures/figures_0_1.jpg", "caption": "Figure 1: Multi-aspect text-driven image editing. Multiple edits in images pose a significant challenge in existing models (such as DirectInversion [1] and InfEdit [2]), as their performance downgrades with an increasing number of aspects. In contrast, our ParallelEdits can achieve precise multi-aspect image editing in 5 seconds. The symbol denotes a swap action, the symbol denotes an object addition action, and the symbol denotes an object deletion. Arrows (\u2192) on the image highlight the aspects edited by our method.", "description": "This figure demonstrates the challenges of multi-aspect text-driven image editing.  It compares the results of existing methods (DirectInversion and InfEdit) with the proposed ParallelEdits method.  The figure shows that existing methods struggle to handle multiple edits simultaneously, resulting in degraded image quality, while ParallelEdits achieves accurate and efficient multi-aspect editing within 5 seconds.  Different edit types (swap, add, delete) are illustrated with symbols. Arrows in the images highlight the specific aspects changed by ParallelEdits.", "section": "Introduction"}, {"figure_path": "cCL92OPlDz/figures/figures_4_1.jpg", "caption": "Figure 2: Pipeline. Our method, ParallelEdits, takes a source image, source prompt, and target prompt as input and produces an edited image. The target prompt specifies the edits needed in the source image. Attention maps for all edited aspects are first collected. Aspect Grouping (see Section 4.2.1) categorizes each aspect into one of N groups (in the above figure, N = 5). Each group is then assigned a branch and the branch-level updates are detailed in Section 4.2.2. Each branch can be viewed either as a rigid editing branch, non-rigid editing branch, or global editing branch. Finally, adjustments to query/key/value at the self-attention and cross-attention layers are made, as illustrated in the figure and described in Section 4.2.3.", "description": "This figure illustrates the pipeline of the ParallelEdits model.  The process starts with a source image and prompts (source and target).  The model then groups the aspects to be edited using attention maps, assigning each group to a dedicated branch for processing (rigid, non-rigid, or global edits). Finally, cross-branch interactions adjust query/key/value in self and cross-attention layers to generate the final edited image.", "section": "4.2 Method"}, {"figure_path": "cCL92OPlDz/figures/figures_4_2.jpg", "caption": "Figure 2: Pipeline. Our method, ParallelEdits, takes a source image, source prompt, and target prompt as input and produces an edited image. The target prompt specifies the edits needed in the source image. Attention maps for all edited aspects are first collected. Aspect Grouping (see Section 4.2.1) categorizes each aspect into one of N groups (in the above figure, N = 5). Each group is then assigned a branch and the branch-level updates are detailed in Section 4.2.2. Each branch can be viewed either as a rigid editing branch, non-rigid editing branch, or global editing branch. Finally, adjustments to query/key/value at the self-attention and cross-attention layers are made, as illustrated in the figure and described in Section 4.2.3.", "description": "This figure illustrates the pipeline of ParallelEdits, a multi-aspect text-driven image editing method. It takes a source image, source prompt (describing the original image), and a target prompt (specifying the desired edits) as input.  The process involves three main steps: 1) Aspect Grouping using attention maps to categorize aspects into distinct groups; 2) Inversion-free Multi-Branch Editing, where each group of aspects is processed by a dedicated branch (rigid, non-rigid, or global editing); 3) Cross-Branch Interactions, where adjustments are made at the self-attention and cross-attention layers to ensure consistency across branches. The output is the edited image.", "section": "4.2 Method"}, {"figure_path": "cCL92OPlDz/figures/figures_5_1.jpg", "caption": "Figure 2: Pipeline. Our method, ParallelEdits, takes a source image, source prompt, and target prompt as input and produces an edited image. The target prompt specifies the edits needed in the source image. Attention maps for all edited aspects are first collected. Aspect Grouping (see Section 4.2.1) categorizes each aspect into one of N groups (in the above figure, N = 5). Each group is then assigned a branch and the branch-level updates are detailed in Section 4.2.2. Each branch can be viewed either as a rigid editing branch, non-rigid editing branch, or global editing branch. Finally, adjustments to query/key/value at the self-attention and cross-attention layers are made, as illustrated in the figure and described in Section 4.2.3.", "description": "This figure illustrates the pipeline of the ParallelEdits model for multi-aspect image editing. It shows how the model takes a source image and prompts (source and target) as input, processes them through aspect grouping and branch-level editing, and finally outputs the edited image.  The figure highlights the attention maps used in aspect grouping, the different branches (rigid, non-rigid, and global editing) used to handle different types of edits, and the cross-attention mechanisms used to coordinate edits between different branches.", "section": "4.2 Method"}, {"figure_path": "cCL92OPlDz/figures/figures_6_1.jpg", "caption": "Figure 4: Qualitative results of ParallelEdits. We denote the edits in arrows with edit actions and aspects for each pair of images. The last image pair is a failure case of ParallelEdits.", "description": "This figure showcases several qualitative examples of image editing results produced by the ParallelEdits method. Each pair of images illustrates a specific multi-aspect editing task, highlighting the changes made to the source image based on textual prompts. Arrows indicate the aspects modified and the type of operation (add, delete, or swap). The last image pair demonstrates a case where ParallelEdits failed to achieve the desired editing result, indicating the limitations of the method in handling certain complex scenarios.", "section": "5 Experiments"}, {"figure_path": "cCL92OPlDz/figures/figures_7_1.jpg", "caption": "Figure 5: Qualitative results comparison. Current methods fail to edit multiple aspects effectively, even using sequential edits (noted as *). Methods marked with \u2605\u2605 taking additional inputs other than source image and plain text.", "description": "This figure compares the qualitative results of ParallelEdits with several state-of-the-art text-driven image editing methods on various examples.  Each row shows a different image editing task, where the source image and prompt are given, along with the target prompt that specifies the desired edits.  The results demonstrate that ParallelEdits outperforms other methods, especially when multiple edits are required. Note that some of the compared methods use additional inputs, which could explain their better performance in specific cases. Methods using sequential editing are marked with an asterisk.", "section": "5.2 Qualitative Results"}, {"figure_path": "cCL92OPlDz/figures/figures_8_1.jpg", "caption": "Figure 6: Comparison across different numbers of editing aspects. We also include the comparison in PIE-Bench dataset. Our proposed method is robust to different numbers of editing aspects.", "description": "This figure shows the performance of ParallelEdits and other state-of-the-art methods on PIE-Bench and PIE-Bench++ datasets with varying numbers of editing aspects.  The x-axis represents the number of aspects (1, 2, or 3+), and the y-axis represents the accuracy, measured by CLIP and LLaVA scores. The bars show that ParallelEdits consistently outperforms other methods across all numbers of aspects on both datasets, indicating its robustness in handling multi-aspect image editing tasks.", "section": "5 Experiments"}, {"figure_path": "cCL92OPlDz/figures/figures_15_1.jpg", "caption": "Figure 1: Multi-aspect text-driven image editing. Multiple edits in images pose a significant challenge in existing models (such as DirectInverison [1] and InfEdit [2]), as their performance downgrades with an increasing number of aspects. In contrast, our ParallelEdits can achieve precise multi-aspect image editing in 5 seconds. The symbol denotes a swap action, the symbol denotes an object addition action, and the symbol denotes an object deletion. Arrows (\u2192) on the image highlight the aspects edited by our method.", "description": "This figure demonstrates the challenge of multi-aspect text-driven image editing.  It shows examples where existing methods struggle to make multiple changes to an image simultaneously, resulting in lower quality edits. In contrast, the proposed ParallelEdits method is shown to successfully and efficiently edit multiple aspects of the images. The symbols indicate swap, addition, or deletion of image aspects.", "section": "Abstract"}, {"figure_path": "cCL92OPlDz/figures/figures_15_2.jpg", "caption": "Figure 1: Multi-aspect text-driven image editing. Multiple edits in images pose a significant challenge in existing models (such as DirectInverison [1] and InfEdit [2]), as their performance downgrades with an increasing number of aspects. In contrast, our ParallelEdits can achieve precise multi-aspect image editing in 5 seconds. The symbol denotes a swap action, the symbol denotes an object addition action, and the symbol denotes an object deletion. Arrows (\u2192) on the image highlight the aspects edited by our method.", "description": "This figure demonstrates the capability of ParallelEdits to perform multi-aspect image editing by showing several examples of before-and-after images.  The examples show that existing methods struggle with multiple edits, while ParallelEdits achieves high accuracy and efficiency, completing the edits in just 5 seconds.  Different edit types are represented by different symbols: swap, add, and delete actions are indicated. Arrows highlight the specific aspects that ParallelEdits modified.", "section": "Introduction"}, {"figure_path": "cCL92OPlDz/figures/figures_18_1.jpg", "caption": "Figure 2: Pipeline. Our method, ParallelEdits, takes a source image, source prompt, and target prompt as input and produces an edited image. The target prompt specifies the edits needed in the source image. Attention maps for all edited aspects are first collected. Aspect Grouping (see Section 4.2.1) categorizes each aspect into one of N groups (in the above figure, N = 5). Each group is then assigned a branch and the branch-level updates are detailed in Section 4.2.2. Each branch can be viewed either as a rigid editing branch, non-rigid editing branch, or global editing branch. Finally, adjustments to query/key/value at the self-attention and cross-attention layers are made, as illustrated in the figure and described in Section 4.2.3.", "description": "This figure illustrates the pipeline of the ParallelEdits model for multi-aspect image editing.  It shows how the model takes a source image and text prompts (source and target) as input and processes them through several steps: 1) Aspect Grouping to categorize edits, 2) Branch-level processing of each group of edits using separate branches (rigid, non-rigid, and global), and 3) Cross-branch interactions to refine and combine the edits. The figure uses diagrams and visual representations of attention maps and branch operations to help explain the process.", "section": "4.2 Method"}, {"figure_path": "cCL92OPlDz/figures/figures_19_1.jpg", "caption": "Figure 1: Multi-aspect text-driven image editing. Multiple edits in images pose a significant challenge in existing models (such as DirectInverison [1] and InfEdit [2]), as their performance downgrades with an increasing number of aspects. In contrast, our ParallelEdits can achieve precise multi-aspect image editing in 5 seconds. The symbol denotes a swap action, the symbol denotes an object addition action, and the symbol denotes an object deletion. Arrows (\u2192) on the image highlight the aspects edited by our method.", "description": "This figure demonstrates the challenge of multi-aspect text-driven image editing.  Existing methods struggle with multiple edits, leading to degraded performance.  ParallelEdits, in contrast, successfully performs these edits in just 5 seconds.  The examples show various edit types (swapping, adding, and removing objects) and how ParallelEdits precisely targets and modifies the specified aspects.", "section": "Introduction"}, {"figure_path": "cCL92OPlDz/figures/figures_20_1.jpg", "caption": "Figure 11: Sequential editing using single-aspect text-driven image editing methods. The sequential editing might accumulate errors and undo previous edits. It also fails to edit significantly overlapped objects.", "description": "This figure demonstrates the limitations of applying single-aspect text-driven image editing methods sequentially to achieve multi-aspect edits.  Two examples are shown: one involving a dog and cat, and another with dumplings and cupcakes. In both cases, the sequential application of edits leads to errors such as the accumulation of artifacts and the unintended overwriting of previous changes.  This highlights the challenge of maintaining consistency and accuracy when performing multiple edits in a sequence, underscoring the need for a more sophisticated approach, like the authors' ParallelEdits method, to handle such complexities.", "section": "5 Experiments"}, {"figure_path": "cCL92OPlDz/figures/figures_20_2.jpg", "caption": "Figure 12: Sequential editing with different orders. Sequential editing with different orders can yield varying final results. Additionally, it may lead to error accumulation and potentially overwrite previous edits.", "description": "This figure shows the results of applying sequential single-aspect editing methods to an image.  Each column represents a different order of applying edits specified in the source and target prompts. As seen in the figure, the final results vary significantly depending on the order, demonstrating that sequentially applying single-aspect methods is not reliable for multi-aspect image editing.  Errors accumulate, and edits made earlier can be overwritten by subsequent edits. This highlights a key challenge addressed by the ParallelEdits method, which performs edits simultaneously to avoid these issues.", "section": "5.2 Qualitative Results"}]