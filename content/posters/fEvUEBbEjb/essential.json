{"importance": "This paper is crucial for researchers in AI security and privacy.  It **challenges existing assumptions** about the trade-off between adversarial robustness and privacy in deep learning models, particularly in the novel context of label mapping visual prompting. By **introducing the concept of transferred adversarial training**, the study opens new avenues for developing more robust and private models.", "summary": "TARP-VP reveals a surprising lack of trade-off between adversarial robustness and privacy for label mapping visual prompting models, showing that transferred adversarial training significantly improves both.", "takeaways": ["Label Mapping Visual Prompting (LM-VP) models exhibit a different relationship between adversarial robustness and privacy compared to standard deep learning models.", "Standard adversarial training is ineffective for LM-VP models, while transferred adversarial training offers a superior trade-off.", "The choice of pre-trained models significantly impacts the white-box adversarial robustness of LM-VP models."], "tldr": "Deep learning models are vulnerable to adversarial attacks and membership inference attacks, creating a tension between robustness and privacy. Adversarial training enhances robustness but compromises privacy. Visual prompting, a model reprogramming technique, improves model performance, but its security remains unexplored. This paper investigates the adversarial robustness and privacy of label mapping visual prompting (LM-VP) models. \nThe study finds that the standard adversarial training approach is ineffective for LM-VP models. Instead, it proposes transferred adversarial training, which achieves a better balance between transferred adversarial robustness and privacy. The research highlights that the choice of pre-trained models significantly influences LM-VP's white-box adversarial robustness. This work offers a novel perspective on adversarial robustness and privacy, particularly in the context of visual prompting, and provides valuable insights for developing more secure and private AI models.", "affiliation": "University of Liverpool", "categories": {"main_category": "Computer Vision", "sub_category": "Image Classification"}, "podcast_path": "fEvUEBbEjb/podcast.wav"}