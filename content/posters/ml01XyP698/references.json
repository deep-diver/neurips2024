{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-00-00", "reason": "This paper introduces NeRF, a foundational work in novel view synthesis using neural radiance fields, which heavily influences the current work's approach to 3D scene reconstruction."}, {"fullname_first_author": "David Charatan", "paper_title": "pixelsplat: 3d gaussian splats from image pairs for scalable generalizable 3d reconstruction", "publication_date": "2023-00-00", "reason": "This paper introduces pixelsplat, a method for 3D Gaussian splatting that provides a basis for the current work's approach to generalizable 3D Gaussian Splatting."}, {"fullname_first_author": "Yuedong Chen", "paper_title": "Mvsplat: Efficient 3d gaussian splatting from sparse multi-view images", "publication_date": "2024-00-00", "reason": "This paper introduces MVSplat, an improvement on pixelsplat that is directly compared against in the current work's evaluation."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces vanilla 3D Gaussian Splatting, which the current work builds upon and improves upon with generalization capabilities."}, {"fullname_first_author": "Jonathan T Barron", "paper_title": "Mip-nerf 360: Unbounded anti-aliased neural radiance fields", "publication_date": "2022-00-00", "reason": "This paper extends NeRF to handle unbounded scenes and addresses anti-aliasing issues, relevant to the current work's goal of high-quality novel view synthesis."}]}