{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that significantly impacts the field and is directly used in the current work's visual encoder."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-01-01", "reason": "This paper introduces LLaVA, a key MLLM architecture which serves as a foundation for the current work, enabling it to explore visual features."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-01", "reason": "This paper introduces Llama 2, a significant LLM that is used in several experiments to demonstrate the approach's scalability."}, {"fullname_first_author": "Susan Zhang", "paper_title": "OPT: Open pre-trained transformer language models", "publication_date": "2022-05-01", "reason": "This paper introduces OPT, a significant LLM used in experiments to test the versatility of the Dense Connector."}, {"fullname_first_author": "Gao Huang", "paper_title": "Densely connected convolutional networks", "publication_date": "2017-07-01", "reason": "This paper introduces DenseNet, a highly influential architecture in computer vision that inspires the Dense Connector's design."}]}