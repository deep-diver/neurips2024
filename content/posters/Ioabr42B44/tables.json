[{"figure_path": "Ioabr42B44/tables/tables_6_1.jpg", "caption": "Table 1: Ablations on Visual Layer Selection in Dense Connector. Here, we explore three instantiations (STI, SCI, and DCI) of our Dense Connector integrated with the baseline (i.e., LLaVA-1.5 [16]), which utilizes a 24-layer CLIP-ViT-L-336px.", "description": "This table presents an ablation study on the selection of visual layers used in the Dense Connector.  It compares the performance of three different Dense Connector instantiations (Sparse Token Integration (STI), Sparse Channel Integration (SCI), and Dense Channel Integration (DCI)) against a baseline model (LLaVA-1.5 using a 24-layer CLIP-ViT-L-336px visual encoder).  The table shows the performance of each method across multiple image benchmarks (GQA, VQA02, SQA, VQAT, POPE, MMB, MMV, LBW), highlighting the impact of different layer combinations on the overall accuracy.  Different layer combinations are tested for each instantiation method to find the optimal configuration.", "section": "4.2 Ablation Study"}, {"figure_path": "Ioabr42B44/tables/tables_6_2.jpg", "caption": "Table 2: Exploring the Compatibility and Scalability of Dense Connector (DC). Scaling results on visual encoder (VE), resolution (Res.), pre-training (PT) / instruction tuning (IT) data, and LLM are provided. \"0.5M+0.6M\" denotes the training data from LLaVA-1.5 [16], while \"1.2M+1.5M\" denotes the data from Mini-Gemini [18]. * indicates results evaluated using official model.", "description": "This table presents the results of experiments conducted to evaluate the Dense Connector's compatibility and scalability across various settings.  The experiments systematically vary the visual encoder, image resolution, training data size, and the size of the Language Model (LLM). This allows for a comprehensive assessment of the model's performance and robustness under diverse conditions. The results are presented for multiple benchmarks to showcase its performance and adaptability.", "section": "4.2 Ablation Study"}, {"figure_path": "Ioabr42B44/tables/tables_7_1.jpg", "caption": "Table 3: Comparison of Efficient Dense Connector with Other Efficient Methods. * indicates results evaluated using official model.", "description": "This table compares the performance of the proposed Efficient Dense Connector against other efficient methods on several image benchmarks.  The metrics used are GQA, VQA02, SQA1, VQAT, MMB, MMV, and Math.  The table shows that, despite using fewer visual tokens (144 vs. 256 or 576), the Efficient Dense Connector achieves comparable or superior performance to the other methods, highlighting its efficiency.", "section": "4.3 Main Results"}, {"figure_path": "Ioabr42B44/tables/tables_8_1.jpg", "caption": "Table 4: Comparisons with State-of-the-Arts. * indicates the dataset have been used for training, and indicates the dataset is not publicly accessible. \"PT,\" \"IT,\" and \"Res.\" denote pre-training data, instruction fine-tuning data, and image resolution, respectively.", "description": "This table compares the performance of the proposed Dense Connector method with other state-of-the-art (SoTA) methods on various image understanding benchmarks.  It shows the impact of different factors such as model size (LLM parameters), training data size (PT+IT), image resolution (Res.), and visual encoder on the performance. The results are presented for several commonly used benchmarks, allowing for easy performance comparison of various methods across different parameters and datasets.", "section": "4.3 Main Results"}, {"figure_path": "Ioabr42B44/tables/tables_8_2.jpg", "caption": "Table 7: More comprehensive evaluation results of the Dense Connector. \"PT\", \"IT\", and \"Res.\" denote pre-training data, instruction fine-tuning data, and image resolution, respectively. + indicates the pre-training data (0.5M) from LLaVA-1.5 [16] and instruction data (1.5M) from Mini-Gemini [18].", "description": "This table presents a more detailed performance comparison of the Dense Connector across different LLMs and training datasets.  It expands on previous results by including a wider range of models (Phi-2.7B, Vicuna-7B, Vicuna-13B, Llama3-8B, Yi-34B, Llama3-70B) and training data configurations (0.5M+0.6M from LLaVA-1.5 and 1.2M+1.5M from Mini-Gemini). The table provides quantitative results for several benchmarks (GQA, VQAT, SQA, MMB, MMEP, MMMU, Math, MMV, LLaVAW).  The \"AnyRes\" column indicates experiments conducted using the AnyRes technology from LLaVA-NeXT. The table shows how Dense Connector impacts performance in different models and with various training data amounts.", "section": "4.3 Main Results"}, {"figure_path": "Ioabr42B44/tables/tables_8_3.jpg", "caption": "Table 2: Exploring the Compatibility and Scalability of Dense Connector (DC). Scaling results on visual encoder (VE), resolution (Res.), pre-training (PT) / instruction tuning (IT) data, and LLM are provided. \"0.5M+0.6M\" denotes the training data from LLaVA-1.5 [16], while \"1.2M+1.5M\" denotes the data from Mini-Gemini [18]. * indicates results evaluated using official model.", "description": "This table demonstrates the Dense Connector's versatility and scalability by evaluating its performance across various visual encoders, image resolutions, training datasets, and LLMs.  It shows how the method performs using different sizes of LLMs, various training datasets (including larger datasets from Mini-Gemini), and different visual encoders. The results highlight the robustness and adaptability of the approach across diverse settings.", "section": "4.2 Ablation Study"}, {"figure_path": "Ioabr42B44/tables/tables_16_1.jpg", "caption": "Table 1: Ablations on Visual Layer Selection in Dense Connector. Here, we explore three instantiations (STI, SCI, and DCI) of our Dense Connector integrated with the baseline (i.e., LLaVA-1.5 [16]), which utilizes a 24-layer CLIP-ViT-L-336px.", "description": "This table presents ablation study results on the selection of visual layers used in the Dense Connector. It compares three different versions of the Dense Connector (STI, SCI, and DCI) against a baseline LLaVA-1.5 model. Each version uses a different combination of visual layers from a 24-layer CLIP-ViT-L-336px visual encoder.  The results show the performance of each model across multiple image benchmarks (GQA, VQA02, SQA, VQAT, POPE, MMB, MMV, LBW) to assess the impact of different layer selections on overall accuracy.", "section": "4.2 Ablation Study"}, {"figure_path": "Ioabr42B44/tables/tables_17_1.jpg", "caption": "Table 7: More comprehensive evaluation results of the Dense Connector. \"PT\", \"IT\", and \"Res.\" denote pre-training data, instruction fine-tuning data, and image resolution, respectively.  + indicates the pre-training data (0.5M) from LLaVA-1.5 [16] and instruction data (1.5M) from Mini-Gemini [18].", "description": "This table presents a comprehensive evaluation of the Dense Connector's performance across various LLMs (Phi2-2.7B, Vicuna-7B, Llama3-8B, Vicuna-13B, Yi-34B, Llama3-70B) and datasets (LLaVA-1.5 and Mini-Gemini).  It shows the performance gains achieved by the Dense Connector on different image understanding benchmarks (GQA, VQAT, SQA, MMB, MMEP, MMMU, Math, MMV, and LLaVAW) with different model sizes and training data, illustrating the scalability and versatility of the proposed approach.", "section": "4.3 Main Results"}, {"figure_path": "Ioabr42B44/tables/tables_17_2.jpg", "caption": "Table 8: Ablation study on fine-tuning Vision Transformer. In this table, all the results are conducted using LLaVA 1.5 data, comprising 558K pre-training data and 665K instruction-tuning data.", "description": "This ablation study investigates the impact of fine-tuning the vision transformer (ViT) on the overall performance of the Dense Connector.  It shows the results of experiments using different visual encoders with and without fine-tuning the ViT on various benchmarks, using the LLaVA 1.5 dataset.  The table compares the performance metrics (GQA, SQA, VQAT, MMB, MMV, MMMU, and Math) obtained with and without ViT fine-tuning, demonstrating whether fine-tuning improves the results or not. ", "section": "4.2 Ablation Study"}]