[{"type": "text", "text": "MiSO: Optimizing brain stimulation to create neural population activity states ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yuki Minai1,2,5, Joana Soldado-Magraner1,4,5, Matthew A. $\\mathbf{Smith^{1,3,5*}}$ , Byron M. $\\mathbf{Y_{u}}^{1,3,4,5*}$ ", "page_idx": 0}, {"type": "text", "text": "1Neuroscience Institute, Carnegie Mellon University 2Machine Learning Department, Carnegie Mellon University 3Department of Biomedical Engineering, Carnegie Mellon University 4Department of Electrical and Computer Engineering, Carnegie Mellon University 5Center for the Neural Basis of Cognition {yminai,jsoldado,msmith,byronyu}@andrew.cmu.edu \\*Denotes equal contribution. ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Brain stimulation has the potential to create desired neural population activity states. However, it is challenging to search the large space of stimulation parameters, for example, selecting which subset of electrodes to be used for stimulation. In this scenario, creating a model that maps the configuration of stimulation parameters to the brain\u2019s response can be beneficial. Training such an expansive model usually requires more stimulation-response samples than can be collected in a given experimental session. Furthermore, changes in the properties of the recorded activity over time can make it challenging to merge stimulation-response samples across sessions. To address these challenges, we propose MiSO (MicroStimulation Optimization), a closed-loop stimulation framework to drive neural population activity toward specified states by optimizing over a large stimulation parameter space. MiSO consists of three key components: 1) a neural activity alignment method to merge stimulation-response samples across sessions, 2) a statistical model trained on the merged samples to predict the brain\u2019s response to untested stimulation parameter configurations, and 3) an online optimization algorithm to adaptively update the stimulation parameter configuration based on the model\u2019s predictions. In this study, we implemented MiSO with a factor analysis (FA) based alignment method, a convolutional neural network (CNN), and an epsilon greedy optimization algorithm. We tested MiSO in closed-loop experiments using electrical microstimulation in the prefrontal cortex of a non-human primate. Guided by the CNN predictions, MiSO successfully searched amongst thousands of stimulation parameter configurations to drive the neural population activity toward specified states. More broadly, MiSO increases the clinical viability of neuromodulation technologies by enabling the use of many-fold larger stimulation parameter spaces. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Brain stimulation is an important tool for treating brain disorders [1\u20133] and for causally perturbing neural activity states to understand brain function [4]. Because complex brain functions are realized through the coordinated activity of populations of neurons, brain stimulation techniques to control neural population activity have the potential to manipulate complex brain function. Most brain stimulation studies to date have used electrical microstimulation to produce a motor response [5] or perceptual experience [6], disrupt neural activity [7], or shift cognitive state [8]. It has been less common to consider the response of a population of neurons to microstimulation [9\u201311]. In principle, different combinations of stimulation parameters make it possible to create diverse neural population activity patterns [12\u201316]. However, it is challenging to identify specific stimulation parameters that achieve a desired activity manipulation for an entire recorded neural population. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Previous studies have developed closed-loop stimulation methods to search the stimulation parameter space [17\u201319]. A key challenge for closed-loop stimulation is to widely sample the multi-dimensional stimulation parameter space. It is necessary to collect many stimulation-response samples before the closed-loop stimulation procedure can begin to work effectively. A key innovation of our work is to merge stimulation-response samples across experimental sessions [20\u201322]. The ability to merge data leverages the finding that neural population activity tends to occupy a lower-dimensional space than the number of neurons being recorded, which enables the aligning of low-dimensional spaces across sessions. By merging data across multiple previous sessions, it is possible for the closed-loop stimulation procedure to work effectively starting from the very outset of the current session. ", "page_idx": 1}, {"type": "text", "text": "In this study, we propose MiSO (MicroStimulation Optimization), a closed-loop stimulation framework to drive neural population activity toward specified states by optimizing over a large stimulation parameter space (Section 2.1). MiSO consists of three key components: 1) a neural activity alignment method to merge stimulation-response samples across sessions (Sections 2.2 and 2.3), 2) a statistical model trained on the merged samples to predict the brain\u2019s response to untested stimulation parameter configurations (Section 2.4), and 3) a closed-loop optimization algorithm to adaptively update the stimulation parameter configuration based on the model\u2019s predictions (Section 2.5). In this study, we implemented MiSO with a factor analysis (FA) based alignment method [20], a convolutional neural network (CNN) model [23], and an epsilon greedy optimization algorithm [24]. These methods were chosen to satisfy the fast online computation requirement during the closed-loop stimulation experiments with a predictive model trained on a limited amount of data. However, MiSO is a general framework and applicable to other design choices. ", "page_idx": 1}, {"type": "text", "text": "We tested MiSO using electrical microstimulation (uStim) in a non-human primate implanted with a multi-electrode array in the prefrontal cortex (PFC, area 8Ar). In this study, we used MiSO to optimize the location of the stimulated electrode(s) on each trial through closed-loop updates, while keeping other parameter values such as current amplitude and frequency fixed. We tested MiSO with a large uStim parameter space, defined by all possible patterns in which two electrodes out of 96 electrodes are stimulated (4,560 patterns). MiSO\u2019s latent alignment method enabled us to merge neural activity across sessions to increase the number of stimulation-response samples (Section 3.1). MiSO\u2019s CNN model trained on these merged stimulation-response samples accurately predicted neural responses to untested uStim parameter configurations (Section 3.2). In closed-loop experiments with a non-human primate, MiSO successfully searched among $4{,}560\\,\\mathrm{uStim}$ parameter configurations to drive the neural population activity toward targeted states. By enabling the search of a larger stimulation parameter space, MiSO produced novel population activity patterns, which were not achievable by searching over a smaller stimulation parameter space (Section 3.3). ", "page_idx": 1}, {"type": "text", "text": "2 Methods ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 MiSO overview ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The goal of MiSO is to identify stimulation parameter configurations that produce specified neural population activity states (Fig. 1A). MiSO first identifies a reference low-d latent space of the high-d population activity to which the neural activity from all the other experimental sessions are aligned (Fig. 1B, Section 2.2). MiSO then collects stimulation-response samples on multiple experimental sessions, then merges the samples using latent space alignment (Section 2.3). The samples are used to fit a statistical model to predict the brain\u2019s response to all possible stimulation parameter configurations within the set of parameters defined by the user (Section 2.4). These model predictions obtained prior to the closed-loop experimental session(s) are used to initialize the optimization procedure. At the beginning of each closed-loop experimental session, MiSO identifies the latent space for the session. MiSO then aligns it to the reference latent space, which was used to generate the model predictions (Section 2.5). On each trial, MiSO stimulates using the chosen parameters and updates the predictions based on the responses measured online (Fig. 1C). MiSO iteratively runs this optimization over trials to produce the specified latent activity state. ", "page_idx": 1}, {"type": "text", "text": "In the following sections, we refer to a specific stimulation parameter configuration as a \u201cstimulation pattern\u201d and the induced brain response as the \u201cstimulation response\u201d. The stimulation patterns tested in this study consist of all possible patterns in which one of 96 electrodes is stimulated (single electrode stimulation patterns) and/or two of 96 electrodes are stimulated (double electrode stimulation patterns). While the neural activity used in this study consists of spiking responses recorded with a planar grid of electrodes implanted in the brain and each stimulation pattern specifies the location of the electrodes used for stimulation within the grid, MiSO can be readily applied to other stimulation/recording protocols (e.g., holographic optogenetics [16]). ", "page_idx": 1}, {"type": "image", "img_path": "Gb0mXhn5h3/tmp/75fca7b642ebb721397ac3698ce4f2f8ed7691d2bc146bdedfdac040229b219d.jpg", "img_caption": ["Figure 1: Experimental paradigm and MiSO closed-loop framework. (A) MiSO\u2019s goal is to optimize brain stimulation parameter configurations to create specified neural population activity states. (B) Experimental setup. Top: Spiking activity was recorded from a multi-electrode array implanted in PFC. During fixation, uStim was applied for $150\\mathrm{ms}$ (orange bar) to induce a specified neural population activity state in the post uStim period (pink bar). Bottom: The uStim response was evaluated within a low-d latent space (e.g., 2D) identified from high-d multi-electrode spiking activity. (C) Closed-loop stimulation framework. Each MiSO iteration involves four steps (Section 2.5). "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2.2 Latent space identification ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To merge stimulation-response samples across multiple experimental sessions, MiSO identifies a low-d latent space of the high-d population activity in each session. For this study, we used Factor Analysis (FA), which provides computationally fast latent space identification and latent state estimation, compatible with closed-loop experiments. Since MiSO\u2019s ultimate goal is to create targeted changes in neural population activity that lead to changes in brain state and in turn behavior, MiSO identifies the intrinsic latent space only using non-stimulation trials. ", "page_idx": 2}, {"type": "text", "text": "For the ith session, MiSO extracts a list of $n_{i}$ \u201cusable\u201d electrodes $e_{i}\\in\\mathbb{R}^{n_{i}}$ , where each element of $e_{i}$ is an integer representing one of the electrodes. An electrode is deemed \u201cusable\u201d if it satisfies criteria involving its mean firing rate, Fano factor, and coincident spiking with other electrodes (see Section S1). For each time bin indexed by $k=1,...,K_{i}^{n o S t i m}$ , MiSO then takes spike counts during the fixation period (Fig. 1B) on each usable electrode xin,okS tim\u2208Rni. MiSO fits the following FA model using the EM algorithm: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{c}{z_{i,k}^{n o S t i m}\\sim{\\mathcal N}(0,I)}\\\\ {x_{i,k}^{n o S t i m}|z_{i,k}^{n o S t i m}\\sim{\\mathcal N}(\\Lambda_{i}z_{i,k}^{n o S t i m}+\\mu_{i},\\Psi_{i})}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "twhhe elroea $z_{i,k}^{n o S t i m}\\in\\mathbb{R}^{m}$ , oswei tch $m<n_{i}$ , eifs inteh et hloe wlo-dw -ladt leantte antc tsivpiatcye f, $k$ ticmonet abiinn,s $\\Lambda_{i}\\in\\mathbb{R}^{n_{i}\\times m}$ kies $\\pmb{\\mu}_{i}\\in\\mathbb{R}^{n_{i}}$ counts for each electrode, and $\\boldsymbol{\\Psi}_{i}\\in\\mathbb{R}^{n_{i}\\times n_{i}}$ is a diagonal matrix capturing the independent variance of the spike counts for each electrode. ", "page_idx": 2}, {"type": "text", "text": "2.3 Latent space alignment ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To merge neural activity across experimental sessions, we used the latent space alignment method introduced in [20] (termed \u201cFA $^{+}$ Procrustes\u201d). It has been shown to work well in a brain-computer interface, which like MiSO is a closed-loop experimental paradigm. The $\\mathrm{FA+}$ Procrustes method solves the Procrustes problem to find an orthogonal transformation matrix to maximize the alignment between two FA loading matrices. First, MiSO runs a single experimental session exclusively with non-stimulation trials and extracts a list of usable electrodes $e_{\\mathbf{0}}$ , which contains $n_{0}$ electrodes. MiSO uses the data from this session to identify a reference latent space $\\Lambda_{0}\\in\\mathbb{R}^{n_{0}\\times m}$ . For each subsequent session, MiSO aligns the latent space identified in the $i$ th session $\\Lambda_{i}$ to the reference latent space $\\Lambda_{0}$ . Concretely, for the ith session, MiSO identifies an orthogonal transformation matrix $\\hat{O}_{i}\\in\\mathbb{R}^{m\\times m}$ that fulfills: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{O}_{i}=\\operatorname*{argmin}_{O:O O\\cap=I}\\|\\Lambda_{0}(e_{c o m},:)-\\Lambda_{i}(e_{c o m},:)O^{\\top}\\|_{F}^{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $e_{c o m}=e_{0}\\cap e_{i}$ is a list of usable electrodes common to the reference session and the ith session, and $\\|\\cdot\\|_{F}$ is the Frobenius Norm. This optimization can be solved in closed-form [25]. The $\\hat{O}_{i}$ found is applied to $\\Lambda_{i}$ to obtain the aligned latent space $\\tilde{\\Lambda}_{i}\\in\\mathbb{R}^{n_{i}\\times m}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\tilde{\\Lambda}_{i}=\\Lambda_{i}\\hat{O}_{i}^{\\phantom{\\dagger}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The latent activity in the post-stimulation period (Fig. 1B) is estimated as the posterior mean from the FA model (equation (1)) using the loading matrix \u039b\u02dci: ", "page_idx": 3}, {"type": "equation", "text": "$$\nz_{i,k}^{S t i m}=\\beta_{i}(\\pmb{x}_{i,k}^{S t i m}-\\pmb{\\mu}_{i})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where ziS,tkim\u2208Rm, xiS,tki $\\pmb{x}_{i,k}^{S t i m}\\in\\mathbb{R}^{n_{i}}$ , and $\\beta_{i}=\\tilde{\\Lambda}_{i}^{\\intercal}(\\tilde{\\Lambda}_{i}\\tilde{\\Lambda}_{i}^{\\intercal}+\\Psi_{i})^{-1}$ . By using $\\tilde{\\Lambda}_{i}$ , the induced latent activity ziS,tkimresides in a common latent space across all sessions. ", "page_idx": 3}, {"type": "text", "text": "2.4 Stimulation-response sample collection and CNN model fitting ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To predict the stimulation response to untested stimulation patterns, MiSO uses a statistical model trained on the merged neural activity across sessions. We used a CNN in this study to capture the spatial structure of the stimulation-response relationship across the multi-electrode array (see Sections 2.7 and 3.2 for model selection). To train the CNN, MiSO runs two phases of experimental sessions to collect stimulation-response samples. In the first phase, MiSO applies randomly-selected stimulation patterns to train an initial CNN model. In the second phase, MiSO uses the trained CNN to choose stimulation patterns to maximize the diversity of the observed stimulation responses. ", "page_idx": 3}, {"type": "text", "text": "2.4.1 Phase 1: Random stimulation pattern selection ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In the first phase, we apply random stimulation patterns over $R$ experimental sessions to train the initial CNN model. With a planar grid of electrodes of size $h\\times v$ , the stimulation pattern tested in $k$ th trial during ith session $\\bar{S}_{i,k}\\in\\bar{\\mathbb{R}^{h\\times v}}$ is encoded using a value of 1 for stimulated electrodes and 0 for all other electrodes. The induced latent activity state $z_{i,k}^{S t i m}\\in\\mathbb{R}^{m}$ is computed using equation (4). The entries of $z_{i,k}^{S t i m}$ corresponding to the user defined $t$ target dimensions within $m$ dimensional aligned latent space $(t\\leq m)$ are subselected and collected in a new vector z\u02c7iS,tkim\u2208Rt. All tested stimulation patterns Si,k and corresponding responses z\u02c7iS,tki across $R$ sessions are appended to obtain $S_{k}\\in\\mathbb{R}^{h\\times v}$ and $\\breve{z}_{k}^{S t i m}\\in\\mathbb{R}^{t}$ , where $k=1,...,K^{S t i m}$ , and $K^{S t i m}$ is the total number of stimulation trials across sessions. ", "page_idx": 3}, {"type": "text", "text": "The totality of the stimulation-response samples $S_{k}$ and $\\check{z}_{k}^{S t i m}$ are used to train the CNN model, which maps the stimulation patterns $S_{k}$ to the induced responses $\\check{z}_{k}^{S t i m}$ . Since the CNN predictions can be variable due to training using a finite number of stimulation-response samples, MiSO uses bagging to stabilize the CNN predictions [26]. In bagging, $M$ CNN models are fti with bootstrapping and the top $C$ performing models in testing are used to generate predicted simulation responses for all $P$ possible stimulation patterns defined by the user (e.g., $P=4$ , 560 for double electrode stimulation patterns, computed as $^{\\bullet\\bullet}96$ choose $2^{\\bullet}$ electrodes) (Section S2). For $p\\,=\\,1,\\ldots,P$ , the predicted response $\\hat{z}_{p}\\in\\mathbb{R}^{t}$ to the $p$ th stimulation pattern $S_{p}\\in\\mathbb{R}^{h\\times v}$ is defined as the average prediction of the $C$ CNN models. ", "page_idx": 3}, {"type": "text", "text": "2.4.2 Phase 2: Guided stimulation pattern selection ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Because the stimulation responses do not uniformly occupy the $t$ -dimensional response space, choosing random stimulation patterns in Phase 1 tends to yield responses primarily in the densest portions of the response distribution. To diversify the stimulation responses for retraining the CNN, MiSO collects stimulation-response samples using a guided sample collection strategy over $G$ experimental sessions in Phase 2. In each session, MiSO uses the CNN-predicted stimulation responses $\\hat{z}_{p}$ from Phase 1 to select stimulation patterns on the fringes (i.e., sparsely populated regions) of the response distribution. Concretely, for each $p=1,...,P$ , MiSO computes the distance measure: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nd_{p}=\\frac{1}{K}\\sum_{j\\in N_{p}}\\|\\hat{\\boldsymbol{z}}_{p}-\\hat{\\boldsymbol{z}}_{j}\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $N_{p}$ is the set of K-nearest neighbors of $\\hat{z}_{p}$ . MiSO chooses the top $E_{g}$ stimulation patterns that maximize this criterion, corresponding to responses on the fringes of the response distribution. To complement these patterns, MiSO also selects $E_{r}$ stimulation patterns at random (from the $P$ possible stimulation patterns, typically $E_{r}<E_{g},$ ), corresponding to responses in the more densely populated regions of the response distribution. The selected $E_{g}+E_{r}$ patterns are experimentally tested for one session. The resulting stimulation-response samples are appended to the samples collected in Phase 1 and thus far in Phase 2, and the CNN is retrained using the same bagging procedure as in Phase 1. The CNN predictions are then updated and used to choose stimulation patterns to test in the next experimental session. MiSO iterates these steps of selecting stimulation patterns, collecting new stimulation-response samples, and retraining the CNN over $G$ experimental sessions. The CNN predictions $\\hat{z}_{p}$ obtained during the final session are used to initialize the closed-loop optimization. ", "page_idx": 4}, {"type": "text", "text": "2.5 Closed-loop optimization ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Each online closed-loop session starts with $K_{c}^{n o S t i m}$ calibration trials, where no stimulation is applied. MiSO extracts a list of $n_{c}$ usable electrodes $e_{c}$ using these trials and finds the common electrodes $e_{c o m}=e_{c}\\cap e_{0}$ between this session and the reference session. The observed spike count vectors xcn,okS $\\pmb{x}_{c,k}^{n o S t i m}\\in\\mathbb{R}^{n_{c}}$ are used to fti the FA parameters $\\Lambda_{c}\\in\\mathbb{R}^{n_{c}\\times m}$ , $\\pmb{\\mu}_{c}\\in\\mathbb{R}^{n_{c}}$ , and $\\Psi_{c}\\in\\mathbb{R}^{n_{c}\\times n_{c}}$ . The identified latent space $\\Lambda_{c}$ is aligned to the reference latent space $\\Lambda_{0}$ using the methods described in Section 2.3, yielding $\\tilde{\\Lambda}_{c}\\in\\mathbb{R}^{n_{c}\\times m}$ . ", "page_idx": 4}, {"type": "text", "text": "The closed-loop optimization starts by the user defining a target state $\\check{z}_{t a r g}\\in\\mathbb{R}^{t}$ and loading the predicted stimulation responses $\\hat{z}_{p}$ obtained from Section 2.4. MiSO then randomly chooses a stimulation pattern $S_{s}$ from the $P$ possible patterns $(s=1,\\ldots,P)$ to start the closed-loop optimization procedure. Subsequent stimulation patterns are chosen using the epsilon greedy algorithm, described below. We used the epsilon greedy algorithm due to the need for a fast online update to compensate for activity fluctuations during the closed-loop optimization. ", "page_idx": 4}, {"type": "text", "text": "tOhne  tihned $k$ cteh dt rrieasl pdounrisne gd tuhrei ncgl otsheed -ploosot-ps toipmtiumlaitziaotino pn,e rtihoed s $\\pmb{x}_{c,k}^{S t i m}\\in\\mathbb{R}^{n_{c}}$ aitsi omne paastutreerdn. $S_{s}$ iisS Oap epsltiiemd aatneds the latent activity zcS,tkim\u2208Rm in real time as: ", "page_idx": 4}, {"type": "equation", "text": "$$\nz_{c,k}^{S t i m}=\\beta_{c}(\\pmb{x}_{c,k}^{S t i m}-\\pmb{\\mu}_{c})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\beta_{c}=\\tilde{\\Lambda}_{c}^{\\intercal}(\\tilde{\\Lambda}_{c}\\tilde{\\Lambda}_{c}^{\\intercal}+\\Psi_{c})^{-1}$ . The entries of zcS,tkimcorresponding to the target dimensions are subselected as $\\breve{z}_{c,k}^{S t i m}\\in\\mathbb{R}^{t}$ , and the prediction of the response to stimulation pattern $S_{s}$ is updated as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\delta}=\\hat{z}_{s}-\\check{z}_{c,k}^{S t i m}}\\\\ {\\hat{z}_{s}=\\hat{z}_{s}+\\alpha\\pmb{\\delta}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $0<\\alpha<1$ is the learning rate. This update is essential for ensuring that the CNN predictions (based on data from previous experimental sessions) are adjusted for the current closed-loop session. Note that, although the CNN predictions used to initialize the closed-loop optimization can capture spatial structure in the stimulation-response relationship, this update is performed separately for each stimulation pattern and therefore does not leverage spatial structure (see Section 4). MiSO uses a time-varying clipped learning rate: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\alpha=\\operatorname*{max}(\\alpha_{c l i p},\\frac{1}{N(s)})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $0<\\alpha_{c l i p}<1$ , and $N(s)$ is the number of trials tested with the $s$ th stimulation pattern within the current closed-loop session. The clipped learning rate allows MiSO to make larger updates at the beginning of the session, when the framework tries to adapt to stimulation responses in the current session, and smaller updates as the framework becomes more confident about the predictions. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "After updating the prediction, MiSO chooses the stimulation pattern to test on the next trial using an epsilon greedy algorithm, which balances exploitation and exploration. With a probability of $1-\\varepsilon$ , MiSO chooses the stimulation pattern which minimizes the L1 distance between the induced activity and the target state ", "page_idx": 5}, {"type": "equation", "text": "$$\ns^{*}=\\underset{s}{\\operatorname{argmin}}\\,\\Vert\\hat{z}_{s}-\\check{z}_{t a r g}\\Vert_{1}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and applies stimulation pattern $S_{s^{*}}$ on the next trial. With a probability of $\\varepsilon$ , MiSO chooses a random stimulation pattern among the $P$ possible patterns. MiSO then iterates until the experimental session is terminated. ", "page_idx": 5}, {"type": "text", "text": "2.6 Experiment details ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We tested MiSO using electrical microstimulation (uStim) in a macaque monkey with a 96 electrode Utah array implanted in prefrontal cortex (PFC, area 8Ar). Experimental procedures were approved by the Institutional Animal Care and Use Committee (IACUC) of Carnegie Mellon University. In each experimental session, the monkey performed a visually-guided saccade task. Each trial began with the monkey fixating on a dot at the center of the screen (Section S3). On uStim trials, we applied uStim for $150~\\mathrm{ms}$ during the fixation period. For each session indexed by $i$ , we identified latent dimensions by applying FA to spike counts taken in $50\\;\\mathrm{ms}$ bins from usable electrodes $e_{i}$ that passed a set of criteria (Section S1). Stimulation-response samples were collected starting $50\\;\\mathrm{ms}$ after uStim offset (Fig. 1B, pink) to avoid uStim artifacts. ", "page_idx": 5}, {"type": "text", "text": "The number of random stimulation sessions $R$ and guided stimulation sessions $G$ to collect stimulation-response samples for CNN training (Section 2.4) were chosen based on the number of trials the animal worked in each session (about 300-500 uStim trials per session, Section S2). We performed $R=3$ sessions with random uStim pattern sampling and $G=2$ sessions with guided uStim pattern sampling. On each guided sampling session, we collected $E_{g}=80$ patterns based on CNN predictions and $E_{r}=20$ random patterns. We used the top $C=10$ test performing models among $M=50$ CNN models to obtain the CNN prediction. To calculate $d_{p}$ , we used 3 nearest neighbors of $\\hat{z}_{p}$ . ", "page_idx": 5}, {"type": "text", "text": "Each closed-loop experimental session started with $K_{c}^{n o S t i m}=100$ no-uStim trials for latent space calibration. For some sessions, this calibration period also included an additional 96 trials (one per single-electrode stimulation pattern). These observations were used to compare the performance of the \u201cMiSO with single elec., sample avg.\u201d with the \u201cSingle elec., same day observation\u201d (Fig. 2B). The latter method uses stimulation-response samples collected in the current session to initialize the predictions (Section S4). We chose $t=2$ target dimensions among the $m=4$ latent dimensions. The latent dimensionality $m$ was determined based on the cross-validated data likelihood. We set the learning rate $\\alpha_{c l i p}$ as 0.1, chosen manually by assessing how the latent activity state changed over trials, and $\\varepsilon$ as 0.05, chosen by running simulations with previously-collected stimulation-response samples. ", "page_idx": 5}, {"type": "text", "text": "2.7 Model comparison ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To decide which prediction model to use in MiSO, we compared the prediction performance of uStim responses when holding out different percentages of uStim patterns in three models: Multi-Layer Perceptron (MLP) [27], Gaussian Process (GP) [28], and Convolutional Neural Network (CNN) [23] (Fig. 3). For all models, we only encoded the location of the stimulating electrodes as inputs in this study. Other stimulation parameters, such as stimulation amplitude and frequency, were constant across electrodes and trials (see Section S3). The models differed in their ability to capture any spatial structure present in the stimulation-response relationship, whereby stimulating with nearby electrodes could induce similar latent activity states. ", "page_idx": 5}, {"type": "text", "text": "Below we describe the input (i.e., stimulation pattern) encoding format for each model. For the $k$ th trial on the ith session, the MLP model takes as input $S_{i,k}^{M L P}\\in\\{\\breve{0},1\\}^{96}$ , a one-hot vector representing each uStim pattern. Its entries have a value of 1 for each stimulated electrode and 0 for non-stimulated electrodes. Since the one-hot input does not designate which electrodes are close to or far from each other, this MLP model does not capture spatial structure among the stimulating electrodes. For the kth trial on the ith session, the GP model takes as input $S_{i,k}^{G P}\\in\\mathbb{R}^{2n}$ , where $n$ is the number of electrodes used for stimulation. The locations of each stimulating electrode are encoded by a pair of values $\\left\\{0,1,...,9\\right\\}\\times\\left\\{0,1,...,9\\right\\}$ , with the stimulating electrodes sorted in ascending order by electrode id. This input encoding format for the GP model captures spatial structure using a single Radial Basis Function kernel. Note that this format requires that all stimulation patterns to have the same number of stimulating electrodes. For the $k$ th trial on the ith session, the CNN takes a grid-format input with the same layout as the electrode array $S_{i,k}^{C N N}\\in\\{0,1\\}^{10\\times10}$ , where electrodes being used for stimulation have a value of 1 and all other electrodes have a value of 0. The CNN captures spatial structure using multiple 2D convolutional filters applied to this grid input. ", "page_idx": 5}, {"type": "image", "img_path": "Gb0mXhn5h3/tmp/0f48ec5a2f6a31a3c640e6e3b9ba3fa8319db441ae729220650a857640c9913c.jpg", "img_caption": ["Figure 2: Closed-loop performance in a non-human primate of MiSO initialized using merged samples. (A) An example closed-loop experimental session. The top two panels show smoothed (for visualization) FA latent activity in the two target dimensions. Trials for all three methods were interleaved in the session. The bottom two panels show the electrode selected for uStim on each trial by \u201cRandom uStim\u201d and \u201cMiSO with single elec., sample avg.\u201d. (B) Mean L1 error relative to the \u201cNo uStim\u201d baseline across 5 closed-loop experimental sessions. Error bars indicate standard error across sessions. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "3 Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "3.1 Merging stimulation-response samples across sessions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "When the stimulation parameter space is large, the number of uStim patterns we can test within an experimental session is much smaller than the total number of possible uStim patterns. This requires merging neural activity across sessions to create a large enough set of stimulation-response samples to learn their relationship. To develop MiSO, we considered merging neural activity based on aligning latent spaces across sessions [20]. To assess the effectiveness of this method for uStim, we empirically measured the uStim response for all possible single-electrode uStim patterns (96 patterns). We ran 5 experimental sessions in which we stimulated with each of the 96 electrodes on the array for 3-7 trials per session. We found that, although the raw uStim responses were inconsistent across sessions due to the neural recording instabilities, they were more consistent within the aligned latent space (Fig. S1). This opened up the possibility of estimating uStim responses based on merged stimulation-response samples collected in previous sessions. ", "page_idx": 6}, {"type": "text", "text": "To test this idea, we ran closed-loop experiments with all single-electrode uStim patterns in which we used the sample average of the merged stimulation-response samples from previous sessions to initialize the predicted stimulation responses $\\hat{z}_{p}$ in MiSO (Section 2.5). We call this method \u201cMiSO with single elec., sample avg.\u201d (Section S4). We compared this method to two baselines, \u201cNo uStim\u201d and \u201cRandom uStim\u201d (Section S4), which allow us to assess whether MiSO induces activity closer to the target state than via natural activity fluctuations or random uStim patterns, respectively. On each trial, we randomly chose one of the three methods. \u201cMiSO with single elec., sample avg.\u201d (Fig. 2A, blue lines and dots) drove neural activity closer to the target state than \u201cNo uStim\u201d and \u201cRandom uStim\u201d (Fig. 2A, gray and green lines). Across multiple sessions with a different target state on each session, MiSO achieved significantly smaller errors than the two baseline methods (Fig. 2B, $N=5$ sessions, $p=0.014$ for \u201cNo uStim\u201d and $p\\,=\\,0.013$ for \u201cRandom uStim\u201d, t-test). These results indicate that MiSO can identify effective stimulation patterns by leveraging merged samples from previous sessions. ", "page_idx": 6}, {"type": "image", "img_path": "Gb0mXhn5h3/tmp/5a3bee5d715bf27ed0b02dcf6c6bfadb4acfa32abb2e22e7211d970a4f723391.jpg", "img_caption": ["Figure 3: Leveraging spatial smoothness to predict uStim responses to untested uStim patterns. (A) uStim pattern difference determined by the physical location(s) of the stimulating electrode(s) on the array (illustrated here for single-electrode patterns). (B) Relationship between uStim pattern difference (horizontal axis, L1 distance, Section S5) and uStim response difference (vertical axis, latent activity difference along FA dim1) when stimulating using single electrodes. A positive correlation $(r)$ implies that stimulating using nearby electrodes tended to induce similar responses. (C) uStim response prediction error as a function of the percentage of held-out uStim patterns during training. Error bars indicate standard error across test datasets. (D, E) Same format as (B) and (C) respectively, but for stimulation using double-electrode patterns. In $\\mathrm{(E)}$ , we experimentally tested $45\\%$ of all possible double-electrode patterns (9 sessions, 3301 trials). "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "To further validate the utility of merging past observations, we compared MiSO\u2019s performance with a method where the predictions were initialized using stimulation-response samples (one uStim trial for each of 96 electrodes) acquired immediately before starting the closed-loop optimization. We call this method \u201cSingle elec., same day observation\u201d. This method and MiSO use different approaches to initialize the same closed-loop procedure (equations (6)-(9)). MiSO leverages stimulation-response samples collected across multiple previous sessions for initialization. By contrast, \u201cSingle elec., same day observation\u201d uses however few stimulation-response samples can be collected in the current session for initialization, with the advantage that it gets to observe responses in the current session. We found that \u201cMiSO with single elec., sample avg.\u201d performed equivalently to \u201cSingle elec., same day observation\u201d (Fig. 2B, $N=5$ sessions, $p=0.715$ , t-test). This result indicates that the merging of stimulation-response samples across previous sessions in MiSO enables the closed-loop stimulation procedure to work effectively from the very outset of the current session. Furthermore, this result using single-electrode stimulation patterns represents an important building block for optimizing over larger stimulation parameter spaces, where merging stimulation-response samples across sessions becomes essential. ", "page_idx": 7}, {"type": "text", "text": "3.2 Predicting uStim responses using a CNN ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "When a search space is small (e.g., 96 single electrodes), we can measure the responses to all uStim patterns to initialize MiSO (as we did with \u201cMiSO with single elec., sample avg.\u201d, Section 3.1). This method becomes untenable as we increase size of the stimulation parameter space (e.g., stimulating two electrodes out of 96 yields 4,560 uStim patterns, which would require more than 30 experimental sessions to collect 3 repeats of each uStim pattern). Thus, to expand the stimulation parameter space with MiSO, we need to reduce the required number of stimulation-response samples to learn their relationship. ", "page_idx": 7}, {"type": "image", "img_path": "Gb0mXhn5h3/tmp/14abce4cc57aaf6835ed3be8eef78112ce49c4a4fd61c239d6f4d15cbc6b0bcf.jpg", "img_caption": ["Figure 4: Closed-loop performance in a non-human primate of MiSO initialized using a CNN. (A) Range of activity patterns achievable by single (pink) and double (blue) electrode uStim patterns, as predicted by the CNN. Dashed region: area reachable exclusively by double-electrode uStim. Yellow star: target state used in (B). (B) Example closed-loop experimental session. Same format as Fig. 2A. (C) Mean L1 error of different methods relative to \u201cNo uStim\u201d baseline, across 3 closed-loop sessions. Error bars indicate standard error across sessions. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "We asked whether there was spatial structure in the stimulation-response relationship, which could be used to predict the uStim response with a limited number of samples (Fig. 3A). For this, we ran 5 experimental sessions in which we stimulated with each of the 96 electrodes on the array for 3-7 trials per session. With single-electrode uStim, we indeed observed spatial smoothness in the uStim response across physical locations on the array (Fig. 3B, Fig. S2A). In other words, stimulating with nearby electrodes tended to induce similar responses. We then asked whether we could use this property to predict the response to untested uStim patterns. We found that the GP and CNN more accurately predicted uStim responses than the MLP when holding out uStim patterns, indicating that spatial smoothness is a useful property for generalization to untested uStim patterns (Fig. 3C). ", "page_idx": 8}, {"type": "text", "text": "To increase the size of the stimulation parameter space, we ran 9 experimental sessions in which we stimulated with two out of 96 electrodes (4,560 possible patterns). With this large number of possible uStim patterns, we were only able to test 45 percent of them. Of the uStim patterns tested, most were only tested for one trial each. As with the single-electrode uStim patterns, we also observed spatial smoothness in the double-electrode uStim patterns (Fig. 3D, Fig. S2B). By leveraging this spatial smoothness, the CNN achieved better generalization performance to untested uStim patterns than the other models (Fig. 3E). Although both the GP and CNN capture aspects of spatial smoothness, the CNN outperformed the GP for double-electrode uStim. Whereas the CNN uses multiple convolution filters to capture the spatial structure of uStim patterns, the GP uses just one spatial kernel, likely limiting its performance. Furthermore, there is no natural input encoding format for a GP when stimulating using more than one electrode on a 2D array. Overall, these results indicate that the CNN model can generalize its predictions to even untested uStim patterns, enabling MiSO to perform closed-loop optimization over a large stimulation parameter space with a limited number of stimulation-response samples. ", "page_idx": 8}, {"type": "text", "text": "3.3 Closed-loop testing of MiSO initialized using a CNN ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "By combining the latent space alignment method (Section 3.1) and the CNN prediction model (Section 3.2), we tested MiSO in closed-loop experiments in a non-human primate over a large uStim parameter space, defined by all possible double-electrode uStim patterns (4,560 patterns). To train the CNN model, we ran 2,122 double-electrode uStim trials across 5 sessions (representing $\\mathord{\\sim}30$ percent of the possible patterns) and merged the stimulation-response samples using latent space alignment. Using the trained CNN model, we predicted the uStim response for all double-electrode uStim patterns. The key motivation of expanding the stimulation parameter space is to expand the range of uStim responses that can be produced. Based on the CNN predictions, we found that the range of activity states achievable by double-electrode stimulation patterns spanned novel regions of the target space that were not reachable using single-electrode uStim (Fig. 4A, Fig. S3). ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "To demonstrate the benefit of searching a larger stimulus parameter space, we ran closed-loop experiments in which we set the target states to those exclusively reachable using double-electrode uStim patterns (Fig. 4A, yellow star). We implemented \u201cMiSO with double elec., CNN\u201d, in which CNN predictions $\\hat{z}_{p}$ were used to initialize the closed-loop optimization (Section 2.5). We compared the performance of \u201cMiSO with double elec., CNN\u201d with three baselines: \u201cNo uStim\u201d, \u201cRandom uStim\u201d, as well as MiSO optimizing over the 96 single-electrode uStim patterns (termed \u201cMiSO with single elec., CNN\u201d). If the CNN predictions are meaningful and the closed-loop optimization is able to guide the search in the stimulus parameter space, \u201cMiSO with double elec., CNN\u201d would outperform the three baselines. Indeed, \u201cMiSO with double elec., CNN\u201d (Fig. 4B, pink lines and dots) successfully identified double-electrode uStim patterns that induced responses closer to the target state than the three baseline methods (gray, green, and blue lines). Across multiple sessions with different target states, \u201cMiSO with double elec., CNN\u201d produced smaller errors than the three baseline methods (Fig. 4C, $N=3$ sessions, $p=0.010$ for \u201cNo uStim\u201d, $p=0.013$ for \u201cRandom uStim\u201d, and $p=0.159$ for \u201cMiSO with single elec., CNN\u201d, t-test). These results demonstrate the utility of MiSO, which enables searching over a larger stimulation parameter space than previously possible. ", "page_idx": 9}, {"type": "text", "text": "4 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we proposed MiSO which searches a large stimulation parameter space to drive neural population activity toward specified states. MiSO\u2019s closed-loop optimization procedure is guided by predictions of a CNN trained on merged neural activity across sessions. To our knowledge, this is the first study to apply latent space alignment in the field of brain stimulation to merge stimulationresponse samples across sessions. This enables MiSO to search larger stimulation parameter spaces than previously possible. ", "page_idx": 9}, {"type": "text", "text": "Although we demonstrated MiSO\u2019s functionality in a 2D target space $t=2$ ), the neural activity corresponding to a desired brain state might need to be specified in a higher dimensional space $(t>2)$ ). As the dimensionality of the target space grows, it may become necessary to expand the stimulation parameter space (see next paragraph) in order to achieve a greater variety of target states. Provided that a target state is achievable, the epsilon greedy algorithm would require more time to identify appropriate stimulus parameter configurations. The reason is that a stimulation pattern that achieves a 2D target would not necessarily produce the target activity along additional dimensions. In this case, the use of a more efficient online algorithm would be beneficial to reduce the exploration of suboptimal stimulation parameter configurations. ", "page_idx": 9}, {"type": "text", "text": "To expand the range of achievable population activity states, one might consider expanding the stimulation parameter space. For example, in the context of electrical microstimulation, we could use stimulation patterns involving larger numbers of electrodes and/or different current amplitudes or frequencies. For the CNN model (or any other predictive model) to retain its prediction accuracy, it would likely need to capture additional structure in the stimulation-response relationship (e.g., similar stimulation amplitudes or frequencies lead to similar responses) and require more training data. Furthermore, MiSO\u2019s closed-loop updates of the predicted responses are performed separately for each stimulation pattern (equation (7)), which becomes untenable as the stimulation parameter space grows. In this case, incorporating a statistical model in the closed-loop updates to account for spatial (or other) structure could be beneficial, such that observing a response to one stimulation pattern leads to updates of the predicted responses of multiple stimulation patterns. These computations would need to be performed fast enough to be used in a closed-loop optimization procedure. ", "page_idx": 9}, {"type": "text", "text": "5 Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was supported by NIH CRCNS R01 MH118929, NSF NCS DRL 2124066, Simons Foundation 543065 and NC-GB-CULM-00003241-05, and Japan Student Services Organization fellowship. We are grateful to Samantha Schmitt for assistance with data collection, and Karen McCracken and Mary Ellen Smyth for animal care. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Helen S Mayberg, Andres M Lozano, Valerie Voon, Heather E McNeely, David Seminowicz, Clement Hamani, Jason M Schwalb, and Sidney H Kennedy. Deep brain stimulation for treatment-resistant depression. Neuron, 45(5):651\u2013660, 2005. [2] Robert S Fisher and Ana Luisa Velasco. Electrical brain stimulation for epilepsy. Nature Reviews Neurology, 10(5):261\u2013270, 2014. [3] Andres M Lozano, Nir Lipsman, Hagai Bergman, Peter Brown, Stephan Chabardes, Jin Woo Chang, Keith Matthews, Cameron C McIntyre, Thomas E Schlaepfer, Michael Schulder, et al. Deep brain stimulation: current challenges and future directions. Nature Reviews Neurology, 15(3):148\u2013160, 2019. [4] Marlene R Cohen and William T Newsome. What electrical microstimulation has revealed about the neural basis of cognition. Current opinion in neurobiology, 14(2):169\u2013177, 2004. [5] Charles J Bruce, Michael E Goldberg, M Catherine Bushnell, and Gregory B Stanton. Primate frontal eye fields. ii. physiological and anatomical correlates of electrically evoked eye movements. Journal of neurophysiology, 54(3):714\u2013734, 1985.   \n[6] Giles S Brindley and Walpole S Lewin. The sensations produced by electrical stimulation of the visual cortex. The Journal of physiology, 196(2):479\u2013493, 1968.   \n[7] Mark M Churchland and Krishna V Shenoy. Delay of movement caused by disruption of cortical preparatory activity. Journal of neurophysiology, 97(1):348\u2013359, 2007. [8] Tirin Moore and Mazyar Fallah. Microstimulation of the frontal eye field and its effects on covert spatial attention. Journal of neurophysiology, 91(1):152\u2013162, 2004. [9] Mark H Histed, Vincent Bonin, and R Clay Reid. Direct activation of sparse, distributed populations of cortical neurons by electrical microstimulation. Neuron, 63(4):508\u2013522, 2009.   \n[10] Yuxiao Yang, Shaoyu Qiao, Omid G Sani, J Isaac Sedillo, Breonna Ferrentino, Bijan Pesaran, and Maryam M Shanechi. Modelling and prediction of the dynamic responses of large-scale brain networks during direct electrical stimulation. Nature biomedical engineering, 5(4):324\u2013 345, 2021.   \n[11] Amin Nejatbakhsh, Francesco Fumarola, Saleh Esteki, Taro Toyoizumi, Roozbeh Kiani, and Luca Mazzucato. Predicting the effect of micro-stimulation on macaque prefrontal activity based on spontaneous circuit dynamics. Physical Review Research, 5(4):043211, 2023.   \n[12] Chieko M Murasugi, C Daniel Salzman, and William T Newsome. Microstimulation in visual area MT: effects of varying pulse amplitude and frequency. Journal of Neuroscience, 13(4):1719\u20131729, 1993.   \n[13] Alexis M Kuncel and Warren M Grill. Selection of stimulus parameters for deep brain stimulation. Clinical neurophysiology, 115(11):2431\u20132441, 2004.   \n[14] Meghan Watson, Numa Dancause, and Mohamad Sawan. Intracortical microstimulation parameters dictate the amplitude and latency of evoked responses. Brain Stimulation, 9(2):276\u2013284, 2016.   \n[15] Thierri Callier, Nathan W Brantly, Attilio Caravelli, and Sliman J Bensmaia. The frequency of cortical microstimulation shapes artificial touch. Proceedings of the National Academy of Sciences, 117(2):1191\u20131200, 2020.   \n[16] Hillel Adesnik and Lamiae Abdeladim. Probing neural codes with two-photon holographic optogenetics. Nature neuroscience, 24(10):1356\u20131366, 2021.   \n[17] Sina Tafazoli, Camden J MacDowell, Zongda Che, Katherine C Letai, Cynthia R Steinhardt, and Timothy J Buschman. Learning to control the brain through adaptive closed-loop patterned stimulation. Journal of Neural Engineering, 17(5):056007, 2020.   \n[18] Samuel Laferriere, Marco Bonizzato, Sandrine L C\u00f4t\u00e9, Numa Dancause, and Guillaume Lajoie. Hierarchical bayesian optimization of spatiotemporal neurostimulations for targeted motor outputs. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 28(6):1452\u2013 1460, 2020.   \n[19] Yuri B Saalmann, Sima Mofakham, Charles B Mikell, and Petar M Djuric. Microscale multicircuit brain stimulation: Achieving real-time brain state control for novel applications. Current Research in Neurobiology, 4:100071, 2023.   \n[20] Alan D Degenhart, William E Bishop, Emily R Oby, Elizabeth C Tyler-Kabara, Steven M Chase, Aaron P Batista, and Byron M Yu. Stabilization of a brain\u2013computer interface via the alignment of low-dimensional spaces of neural activity. Nature biomedical engineering, 4(7):672\u2013685, 2020.   \n[21] Brianna M Karpowicz, Yahia H Ali, Lahiru N Wimalasena, Andrew R Sedler, Mohammad Reza Keshtkaran, Kevin Bodkin, Xuan Ma, Lee E Miller, and Chethan Pandarinath. Stabilizing brain-computer interfaces through alignment of latent dynamics. BioRxiv, pages 2022\u201304, 2022.   \n[22] Max Dabagia, Konrad P Kording, and Eva L Dyer. Aligning latent representations of neural activity. Nature Biomedical Engineering, 7(4):337\u2013343, 2023.   \n[23] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436\u2013444, 2015.   \n[24] Richard S Sutton. Reinforcement learning: An introduction. A Bradford Book, 2018.   \n[25] Peter H Sch\u00f6nemann. A generalized solution of the orthogonal procrustes problem. Psychometrika, 31(1):1\u201310, 1966.   \n[26] Leo Breiman. Bagging predictors. Machine learning, 24:123\u2013140, 1996.   \n[27] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. Nature, 323(6088):533\u2013536, 1986.   \n[28] Carl Edward Rasmussen. Gaussian processes in machine learning. In Summer school on machine learning, pages 63\u201371. Springer, 2003.   \n[29] Jacob R Gardner, Geoff Pleiss, David Bindel, Kilian Q Weinberger, and Andrew Gordon Wilson. Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration. In Advances in Neural Information Processing Systems, 2018. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Supplementary material ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "S1 Spiking activity preprocessing ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "To identify the latent dimensions using FA, we computed binned spike counts during the $1.2\\,\\mathrm{s}$ fixation period on each no-uStim trial $50~\\mathrm{ms}$ bins, yielding 24 bins per trial). Thus, $K_{i}^{\\bar{n}o S t i m}$ for the ith session was the number of no-uStim trials $\\times\\ 24$ . These no-uStim trials were also used to extract a list of usable electrodes $e_{i}$ for the ith session based on the following three criteria: mean firing rate ${>}1\\ \\mathrm{Hz}$ , Fano factor ${<}8$ , and $-20\\%$ coincident spiking with each of the other electrodes. The latent dimensionality $m=4,$ ) was chosen based on the cross-validated data likelihood across multiple sessions, then used for all sessions. To evaluate the uStim response, we computed binned spike counts starting $50\\;\\mathrm{ms}$ after uStim offset on each uStim trial (Fig. 1B) to avoid uStim artifacts. The latent activity was then computed using equation (4). ", "page_idx": 12}, {"type": "text", "text": "S2 Models architecture and fitting ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The CNN architecture and hyperparameters were determined based on a grid search. The following describes the CNN architecture used in this work from input to output: 1. a convolution layer with 32 channels, spatial kernel size $3\\mathrm{x}3$ , and stride size 1, followed by ReLU activation, 2. a convolution layer with 64 channels, spatial kernel size $3\\mathrm{x}3$ , and stride size 1, followed by ReLU activation, 3. two linear layers with ReLU activation, and 4. a linear output layer of size equal to the target dimensionality without any activation. The MLP architecture used in this work includes: 1. an input layer of size 96, 2. a hidden layer of size 10, followed by ReLU activation, and 3. an output layer of size equal to the target dimensionality. The CNN and MLP were implemented in PyTorch and fit using the Adam optimizer with mean squared error loss and a learning rate of 0.001. The GP model was fitted using the GPyTorch library [29]. We used a Radial Basis Function whose length scale hyperparameter was chosen by maximizing the marginal data log likelihood using Adam optimizer with a learning rate of 0.001. We trained all models on a local computing cluster using 4 NVIDIA GeForce RTX GPUs and 11GB of RAM. We used the same architecture and hyperparameters for all experiments. ", "page_idx": 12}, {"type": "text", "text": "To train CNN models using bagging (Section 2.4), the merged stimulation-response samples across sessions were split into training, validation, and test sets with a ratio of 80:10:10. Each CNN model was trained on the training data. The validation data was used for hyperparameter tuning. The test data were used to evaluate the ability of the models to generalize to untested uStim patterns, and to choose the top $C$ performing models to generate the uStim response predictions for all possible uStim patterns. These predictions were used to initialize the closed-loop optimization (Section 2.5). ", "page_idx": 12}, {"type": "text", "text": "S3 Details of uStim experimental paradigm ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In each experimental session, the monkey performed a visually-guided saccade task. In this task, the monkey first fixated on a dot at the center of the screen. Following a random (1.45-1.75s) fixation period, the center dot turned off and one of four peripheral targets $45^{\\circ}$ , $135^{\\circ}$ , $225^{\\circ}$ , $315^{\\circ}$ ) appeared. The monkey saccaded to that target to receive a liquid reward. There were two types of visually-guided saccade trials: \u201cuStim trials\u201d, in which we applied uStim, and \u201cno-uStim trials\u201d, in which we did not apply uStim. The experimental system randomly chose which trial type to perform in an interleaved manner. On uStim trials, we applied uStim for $150\\;\\mathrm{ms}$ during the fixation period. The stimulation was biphasic with each square pulse in the biphasic pair being $250\\;\\mathrm{ms}$ in duration. We set the current amplitude low enough not to induce any eye movements (current amplitude: $25\\;\\mathrm{uA}$ for single-electrode uStim, $15\\;\\mathrm{uA}+15\\;\\mathrm{uA}$ for double-electrode uStim). We changed the location(s) of the stimulated electrode(s) on each trial, while keeping other parameter values such as current amplitude and frequency $(350\\,\\mathrm{Hz})$ fixed. In each closed-loop session, we chose two target dimensions along which we could modulate neural activity and induce diverse latent activity with uStim. These were not necessarily the top FA dimensions that explained the greatest covariance among the neurons. ", "page_idx": 12}, {"type": "text", "text": "S4 Closed-loop performance assessment methods ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The table below summarizes the methods used to assess closed-loop performance. The \u201cPrediction model\u201d column indicates the method used to obtain uStim response predictions to initialize the closed-loop optimization. The \u201cTraining data\u201d column indicates the stimulation-response samples used to train the prediction model. The \u201cuStim patterns\u201d column indicates the number of electrodes used for stimulation, both in the training data and during closed-loop optimization. The \u201cOnline algorithm\u201d column indicates the method used to choose the next uStim pattern. All methods that use the epsilon greedy algorithm also perform closed-loop updates of the predicted responses (equations (6)-(9)). ", "page_idx": 13}, {"type": "table", "img_path": "Gb0mXhn5h3/tmp/63e8da81a1fe3b3997f650ddc3392c153d31a1e076bd3cead2c3c91655ed65d8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "S5 Spatial structure of uStim responses ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "To evaluate the spatial smoothness of uStim responses across the multi-electrode array (Fig. 3), we measured the spatial similarity between uStim patterns $(d_{p a t t e r n})$ and the similarity in the uStim response elicited by those patterns $(d_{r e s p o n s e})$ . We computed these metrics for every pair of tested uStim patterns. ", "page_idx": 13}, {"type": "text", "text": "For single-electrode uStim patterns $e_{1}=[x_{1},y_{1}]$ and $e_{2}=[x_{2},y_{2}]$ (for $x_{i}$ and $y_{i}\\in\\{0,1,...,9\\})$ ), we quantified their spatial similarity using the L1 distance: ", "page_idx": 13}, {"type": "equation", "text": "$$\nd_{p a t t e r n}=|x_{1}-x_{2}|+|y_{1}-y_{2}|\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $x_{1}$ and $y_{1}$ are the spatial coordinates on the multi-electrode grid for the first uStim electrode $e_{1}$ , and $x_{2}$ and $y_{2}$ are the spatial coordinates for the second uStim electrode $e_{2}$ . ", "page_idx": 13}, {"type": "text", "text": "For double-electrode uStim patterns, each pattern involves two electrodes. Let $e_{1}=[x_{1},y_{1}]$ and $\\boldsymbol{e_{2}}~=~\\left[x_{2},y_{2}\\right]$ represent the uStim electrodes used for the first pattern, and $\\boldsymbol{e}_{3}~=~\\left[x_{3},y_{3}\\right]$ and $e_{4}=[x_{4},y_{4}]$ represent the uStim electrodes used for the second pattern. To calculate the distance in this case, we computed: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{d_{p a t t e r n}^{1}=(|x_{1}-x_{3}|+|y_{1}-y_{3}|)+(|x_{2}-x_{4}|+|y_{2}-y_{4}|)}}\\\\ {{d_{p a t t e r n}^{2}=(|x_{1}-x_{4}|+|y_{1}-y_{4}|)+(|x_{2}-x_{3}|+|y_{2}-y_{3}|)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "and used min(d1pattern, $\\operatorname*{min}(d_{p a t t e r n}^{1},d_{p a t t e r n}^{2})$ as the distance measure. ", "page_idx": 13}, {"type": "text", "text": "For each pair of uStim patterns, we quantified the difference in uStim response using the L1 distance: ", "page_idx": 13}, {"type": "equation", "text": "$$\nd_{r e s p o n s e}=|z_{1}-z_{2}|\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $z_{1}$ is the response to the first uStim pattern along a target dimension, and $z_{2}$ is the uStim response to the second uStim pattern along the same target dimension. To focus on local smoothness, we only analyzed the pairs in which $d_{p a t t e r n}$ was less than 8 in the single-electrode case, and less than 16 in the double-electrode case. ", "page_idx": 13}, {"type": "text", "text": "Using the $d_{p a t t e r n}$ and $d_{r e s p o n s e}$ values, we computed the correlation between them to evaluate if spatial structure is present. A positive correlation indicates that uStim electrodes located closer to each other on the array tend to induce a more similar response. ", "page_idx": 13}, {"type": "text", "text": "S6 Summary of experimental sessions ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The experimental sessions used in this study comprised 3 sessions without uStim (reference sessions), 10 sessions involving single-electrode uStim, 19 sessions involving double-electrode uStim, and 8 closed-loop sessions. Each of the entries in the tables below uses a subset of the sessions described above. ", "page_idx": 14}, {"type": "table", "img_path": "Gb0mXhn5h3/tmp/2d97e2f00a3cd3aad3fd4db2b49e0772e6e96e4f95e56b3a00609ce1558a6450.jpg", "table_caption": ["The table below summarizes the number of sessions used in each closed-loop experimental result: "], "table_footnote": [], "page_idx": 14}, {"type": "table", "img_path": "Gb0mXhn5h3/tmp/af8c0972c8ada63e401a255b7e3ba4b4022ff389618e15ad1cc6d38e4933a2ef.jpg", "table_caption": ["The table below summarizes the number of sessions used in each offline analysis result: "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "S7 Code availability ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Python code for MiSO is available on GitHub at https://github.com/yuumii-san/MiSO.git. ", "page_idx": 14}, {"type": "image", "img_path": "Gb0mXhn5h3/tmp/f11550f05a1bd56b553b5b1a467d0a69fed250a60d55541477fb715913e52db0.jpg", "img_caption": [], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Figure S1: uStim response consistency across sessions. (A) Response maps of uStim-induced mean firing rates. Each panel shows the mean firing rate, averaged across the entire array, induced by stimulating each electrode individually. For example, the color of the top left cell in a given response map indicates the mean firing rate across the array induced by stimulating this particular electrode. Each column corresponds to a different session. (B) Response maps of uStim-induced mean latent activity across trials. Each panel shows the average latent activity induced by stimulating each electrode individually. The latent spaces have been aligned across sessions. Stimulation-response samples from the five sessions shown here are used to compute the sample average-based predictions in Fig. 2. (C) Normalized distance of response maps from session 1. The mean firing rates and latent activity are normalized across sessions using a min-max transformation to align their scales. The uStim response is more consistent across sessions in the aligned latent space than in the raw firing rate space. ", "page_idx": 15}, {"type": "image", "img_path": "Gb0mXhn5h3/tmp/22c722abc1deda589f4c3e83dd4eea5dd2e81c20619e6d63e25e8506076721f2.jpg", "img_caption": ["Figure S2: Relationship between uStim pattern spatial similarity and response similarity along the second target dimension. Same format as Fig. 3B and Fig. 3D, which were based on the first target dimension. Left, single-electrode uStim, right, double-electrode uStim. "], "img_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "Gb0mXhn5h3/tmp/2dca3e96bb56a75a7df4919ca212794d40e8aa28a25ea12a0abfeddea6736367.jpg", "img_caption": ["Figure S3: Generalization to uStim patterns involving a different number of electrodes can be challenging. (A) Prediction error for different CNN models tested on single-electrode uStim data. Each bar shows the predictive performance of CNNs trained with different merged stimulationresponse samples (single-electrode uStim trials, double-electrode uStim trials, and both types of trials). A CNN trained on single-electrode uStim trials performed better than a CNN trained on double-electrode uStim trials. Training a CNN on both types of uStim trials yielded similar accuracy to training on single-electrode uStim trials. (B) Prediction error for different CNN models tested on double-electrode uStim data. Similar to (A), a CNN model trained on double-electrode uStim trials performed better than a CNN model trained on single-electrode uStim trials. Furthermore, training a CNN on both types of uStim trials yielded similar accuracy to training on double-electrode uStim trials. These results reveal a complex relationship between single-electrode uStim and double-electrode uStim responses. Prediction is challenging if the training data do not include stimulation-response samples of the uStim type being predicted (single-electrode or double-electrode), consistent with Fig. 4A. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: We provide a summary of the current literature and gap, and explain the contributions of our work in the abstract and introduction. Our claims are supported by the experimental results. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 17}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: We discuss the limitations of this work in the second and third paragraphs of the discussion section. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 17}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper does not include theoretical results. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 18}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We disclose the details of the proposed framework, experiments, data analyses, and modeling approaches needed to reproduce the main results. We have also released the code to replicate our framework at https://github.com/yuumii-san/MiSO.git. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 18}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The code and sample data needed to replicate the experiments are available at https://github.com/yuumii-san/MiSO.git. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 19}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The training and test details are provided in Section S2. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 19}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: We include error bars in all figures and provide the outcomes of statistical tests for the main results. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We provide details for the computer resources in Section S2. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We reviewed the NeurIPS Code of Ethics and our work is in compliance. All experimental procedures involved in this work were conducted in accordance with the United States National Research Council\u2019s Guide for the Care and Use of Laboratory Animals, and were approved by the Institutional Animal Care and Use Committee of Carnegie Mellon University. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We discuss the potential societal impacts in the first paragraph of the introduction section. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 20}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 21}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: The data do not pose a risk for release as it was not acquired from human subjects and does not contain images or identifiable information. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We cite all assets used in this paper. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The methods section provides the detail necessary to reproduce the proposed framework. We also provide code and sample data at https://github.com/yuumiisan/MiSO.git. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 22}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 22}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: This work did not involve human subjects. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}]