[{"figure_path": "MLhZ8ZNOEk/tables/tables_5_1.jpg", "caption": "Table 1: SS results on CIFAR10 and CIFAR100 comparisons with other methods. The number pair X / Y means the Top-1 accuracy on CIFAR10 is X% and on CIFAR100 is Y%.", "description": "This table presents a comparison of the performance of the proposed Swift Sampler (SS) method against several other baseline methods on two image classification datasets, CIFAR-10 and CIFAR-100.  The results are shown for different levels of added noise to the training data (0%, 10%, 20%, 30%, and 40%). Each entry shows the Top-1 accuracy on CIFAR-10 and CIFAR-100 respectively. The table helps demonstrate the robustness and effectiveness of the proposed SS method in handling noisy data.", "section": "4 Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_6_1.jpg", "caption": "Table 1: SS results on CIFAR10 and CIFAR100 comparisons with other methods. The number pair X / Y means the Top-1 accuracy on CIFAR10 is X% and on CIFAR100 is Y%.", "description": "This table presents the performance comparison of the proposed Swift Sampler (SS) method with other existing methods on CIFAR-10 and CIFAR-100 datasets under various levels of label noise (0%, 10%, 20%, 30%, and 40%). The performance is measured by the Top-1 accuracy on each dataset.  The table shows that the SS method consistently outperforms other methods, especially in high-noise scenarios.", "section": "4.1 CIFAR Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_7_1.jpg", "caption": "Table 2: Comparison of Top-1/5 accuracy of SS and baseline on ImageNet ILSVRC12. \u201cMB\u201d,\u201cRN\u201d and \u201cSRN\u201d means MobileNet ResNet and SE-ResNext. SS(self), SS(R18) and SS(R50) means the the sampler is searched on the target model, ResNet-18 and ResNet-50. All results are averaged over 5 runs, and the deviations are omitted because they are all less than 0.10. It is observed that SS has consistent improvements on Top-1 Acc on all cases, and the performance gain on Top-5 is relatively less because we only use Top-1 Acc as the objective of sampler search.", "description": "This table compares the Top-1 and Top-5 accuracy of the proposed Swift Sampler (SS) method against a baseline on the ImageNet ILSVRC12 dataset using various model architectures.  It shows the consistent improvement in Top-1 accuracy achieved by SS across different models, with a smaller improvement in Top-5 accuracy.", "section": "4.2 ImageNet Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_8_1.jpg", "caption": "Table 3: Comparision of verification performance % of SS and baseline on train set MS1M and test set YTF.", "description": "This table presents the comparison of verification performance between the proposed Swift Sampler (SS) method and the baseline method on two datasets: MS1M (train set) and YTF (test set).  The performance is measured using ResNet-50 and ResNet-101 models. The table shows that SS consistently improves the performance compared to the baseline, demonstrating its effectiveness in face recognition tasks.", "section": "4.3 Face Recognition Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_9_1.jpg", "caption": "Table 1: SS results on CIFAR10 and CIFAR100 comparisons with other methods. The number pair X / Y means the Top-1 accuracy on CIFAR10 is X% and on CIFAR100 is Y%.", "description": "This table presents a comparison of the performance of the Swift Sampler (SS) method against baseline and other methods (REED, MN, LR) on CIFAR10 and CIFAR100 datasets with varying noise levels (0%, 10%, 20%, 30%, 40%).  The results are presented as Top-1 accuracy pairs (CIFAR10/CIFAR100) for each method and noise level.  It showcases the improved performance of SS, particularly in the presence of noisy labels.", "section": "4 Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_13_1.jpg", "caption": "Table 5: Performance comparison of different sampling methods.", "description": "This table presents the performance comparison between the baseline uniform sampling method and the proposed Swift Sampler (SS) method on a large-scale dataset.  The comparison is made across three key metrics: Top-1 accuracy, Top-5 accuracy, and convergence speed.  Top-1 accuracy represents the percentage of correctly classified images in the top prediction. Top-5 accuracy refers to the percentage of images with the correct class label among the top 5 predictions.  Convergence speed is expressed as a percentage relative to the baseline method, indicating how much faster the SS method converged compared to the baseline.", "section": "A.2 Practical and Challenging Scenarios"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_14_1.jpg", "caption": "Table 6: Accuracy comparison across different scenarios.", "description": "This table shows the accuracy comparison between the baseline model and the Swift Sampler (SS) model across three different few-shot learning scenarios: 1-shot, 5-shot, and 10-shot.  The scenarios refer to the number of training examples per class used for learning.  The baseline accuracy represents the performance of a model trained without the Swift Sampler. The Swift Sampler (SS) accuracy shows the model's performance after implementing the proposed SS method for data sampling during training.", "section": "A.2 Practical and Challenging Scenarios"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_14_2.jpg", "caption": "Table 1: SS results on CIFAR10 and CIFAR100 comparisons with other methods. The number pair X / Y means the Top-1 accuracy on CIFAR10 is X% and on CIFAR100 is Y%.", "description": "This table presents the performance comparison of the proposed Swift Sampler (SS) method with other baseline methods (Baseline, REED, MN, LR) on CIFAR10 and CIFAR100 datasets under various noise levels (0%, 10%, 20%, 30%, 40%).  The results are expressed as Top-1 accuracy pairs (CIFAR10/CIFAR100) and the relative training time compared to the baseline method for each noise level.  The table highlights the superior performance of the SS method across different noise conditions.", "section": "4 Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_14_3.jpg", "caption": "Table 1: SS results on CIFAR10 and CIFAR100 comparisons with other methods. The number pair X / Y means the Top-1 accuracy on CIFAR10 is X% and on CIFAR100 is Y%.", "description": "This table presents a comparison of the performance of the proposed Swift Sampler (SS) method against several other methods on the CIFAR-10 and CIFAR-100 datasets.  It shows the Top-1 accuracy for each method under different levels of added noise (0%, 10%, 20%, 30%, and 40%).  The results demonstrate the effectiveness of SS, particularly in the presence of noisy labels.", "section": "4 Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_15_1.jpg", "caption": "Table 9: Impact of varying the number of optimization steps E<sub>o</sub> on the performance of the Swift Sampler (SS) method.", "description": "This table shows the results of an ablation study on the impact of varying the number of optimization steps (E<sub>o</sub>) in the Swift Sampler (SS) method on CIFAR-10 dataset with 20% noise.  It demonstrates the relationship between the number of optimization steps performed and the resulting Top-1 accuracy. As expected, increasing the number of steps generally leads to higher accuracy, but the gains diminish with additional steps, suggesting a point of diminishing returns.", "section": "A.4 Parameter Analysis"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_15_2.jpg", "caption": "Table 1: SS results on CIFAR10 and CIFAR100 comparisons with other methods. The number pair X / Y means the Top-1 accuracy on CIFAR10 is X% and on CIFAR100 is Y%.", "description": "This table presents the results of the Swift Sampler (SS) method on CIFAR10 and CIFAR100 datasets, compared with other methods (Baseline, REED, MN, LR).  It shows the Top-1 and Top-5 accuracy for each method under different noise levels (0%, 0.1, 0.2, 0.3, 0.4).  The table demonstrates the effectiveness of SS in achieving higher accuracy, especially in the presence of noisy labels.", "section": "4 Experiment"}, {"figure_path": "MLhZ8ZNOEk/tables/tables_16_1.jpg", "caption": "Table 11: Comparison of perplexity of Wiki-GPT on Wikitext-2 with and without SS. The number pairs indicate perplexity on the Wikitext-2 validation and test sets respectively.", "description": "This table presents the perplexity scores achieved by the Wiki-GPT model on the Wikitext-2 dataset, both with and without the Swift Sampler (SS).  Perplexity is a metric evaluating how well a probability model predicts a sample. Lower perplexity indicates better prediction. The table compares baseline perplexity against results obtained using the SS method on both validation and test sets, demonstrating the method's effectiveness in improving the model's predictive performance.", "section": "4.3 Face Recognition Experiment"}]