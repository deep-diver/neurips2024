[{"figure_path": "xtK3gZjQDC/figures/figures_2_1.jpg", "caption": "Figure 1: Our automated decision support system. Given an instance with a feature vector x, the system C helps the expert by automatically narrowing down the set of potential label values to a prediction set S(x) \u2286 Y. The system asks the expert to predict a label value \u0177 from S(x).", "description": "The figure illustrates the automated decision support system's workflow.  A data sample (e.g., an X-ray image) with features x is input. The decision support system processes this and provides a prediction set S(x), which is a subset of all possible labels Y. The human expert then reviews this narrowed set of potential labels and makes a prediction \u0177, which must be selected from the S(x) set.", "section": "Decision Support Systems Based on Prediction Sets"}, {"figure_path": "xtK3gZjQDC/figures/figures_4_1.jpg", "caption": "Figure 1: Our automated decision support system. Given an instance with a feature vector x, the system C helps the expert by automatically narrowing down the set of potential label values to a prediction set S(x) \u2286 Y. The system asks the expert to predict a label value \u0177 from S(x).", "description": "This figure illustrates the automated decision support system proposed in the paper.  It shows how, given an input data sample with features (x), a classifier (C) helps the human expert by reducing the number of possible label values to consider. The classifier provides a prediction set (S(x)) which is a subset of all possible labels (Y). The human expert then makes a prediction (\u0177) from within this smaller set of possibilities.", "section": "Decision Support Systems Based on Prediction Sets"}, {"figure_path": "xtK3gZjQDC/figures/figures_7_1.jpg", "caption": "Figure 2: (Left) Confusion matrix C for the predictions made by a (simulated) human expert on their own. The label \u00ff = argmaxy'\u2260y Cy'y that is most frequently mistaken with the ground truth-label y is highlighted in red for y \u2208 {0, 2, 6, 8}. (Right) Empirical conditional probability that a prediction set includes {y, \u00ff} given Y = y with conformal prediction (NAIVE, APS, RAPS and SAPS) and our greedy algorithm (GREEDY). In both panels, \u03b3 = 0.7 and P(Y' = Y) = 0.7.", "description": "This figure shows two plots. The left plot is a confusion matrix that visualizes the errors made by a simulated human expert in a multi-class classification problem. Each cell (i, j) represents the probability of the expert predicting class j when the true class is i. The right plot shows the empirical conditional probability that a prediction set includes the true label y and the most frequently mistaken label \u00ff given the true label is y. This probability is computed for different prediction set construction methods: conformal prediction (NAIVE, APS, RAPS, SAPS) and a greedy algorithm (GREEDY). The results indicate that the greedy algorithm leads to prediction sets that include the true and most commonly confused labels less often compared to conformal methods.", "section": "Experiments with Synthetic Data"}, {"figure_path": "xtK3gZjQDC/figures/figures_9_1.jpg", "caption": "Figure 3: Complementary cumulative distribution (cCDF) of the per-image test accuracy achieved by a simulated human expert using the prediction sets constructed with conformal prediction (NAIVE, APS, RAPS and SAPS) and our greedy algorithm (GREEDY) on the ImageNet16H dataset.", "description": "This figure compares the performance of different methods for constructing prediction sets in a multi-class classification task using the ImageNet16H dataset. The x-axis represents the empirical average accuracy achieved by a simulated human expert using the prediction sets, and the y-axis represents the complementary cumulative distribution function (cCDF) of the per-image test accuracy.  The plot shows that the prediction sets generated by the greedy algorithm consistently outperform those generated by various conformal prediction methods (NAIVE, APS, RAPS, SAPS) across different noise levels (\u03c9). The results indicate that the greedy algorithm is more effective at improving human expert accuracy.", "section": "Experiments with Real Data"}, {"figure_path": "xtK3gZjQDC/figures/figures_20_1.jpg", "caption": "Figure 2: (Left) Confusion matrix C for the predictions made by a (simulated) human expert on their own. The label \u04ef = argmaxy'\u2260y Cy'y that is most frequently mistaken with the ground truth-label y is highlighted in red for y \u2208 {0, 2, 6, 8}. (Right) Empirical conditional probability that a prediction set includes {y, \u04ef} given Y = y with conformal prediction (NAIVE, APS, RAPS and SAPS) and our greedy algorithm (GREEDY). In both panels, \u03b3 = 0.7 and P(Y' = Y) = 0.7.", "description": "The left panel shows the confusion matrix for predictions made by a simulated human expert.  The right panel shows the conditional probability that a prediction set contains both the true label and the label most often confused with the true label, given different methods for creating prediction sets.  The results indicate a lower probability of this event happening when using the proposed greedy algorithm.", "section": "Experiments with Synthetic Data"}, {"figure_path": "xtK3gZjQDC/figures/figures_21_1.jpg", "caption": "Figure 5: Average accuracy achieved by a simulated expert following the mixture of MNLs and by real human experts using the prediction sets constructed with all possible conformal predictors, each with a different \u03b1 value, using the choice of calibration set by Straitouri et al. [19]. We highlight in red the highest average accuracy for both the simulated and the real humans.", "description": "This figure compares the average accuracy of a simulated human expert whose predictions follow a mixture of multinomial logit models (MNLs) and that of real human experts.  The prediction sets used were generated by conformal predictors with varying \u03b1 values, using a calibration set selected by Straitouri et al. [19]. The graph shows that while the MNL model overestimates the accuracy, the general trend of accuracy across different \u03b1 values is similar for both the simulated and real human experts.  The peak average accuracy for both groups is highlighted in red.", "section": "Evaluation of the Mixture of Multinomial Logit Models (MNLs)"}, {"figure_path": "xtK3gZjQDC/figures/figures_22_1.jpg", "caption": "Figure 6: Average accuracy achieved by a (simulated) expert using the prediction sets constructed with conformal prediction (NAIVE, APS, RAPS and SAPS) on the ImageNet16H dataset under different \u03b1 values. Each panel shows the average and standard error over 10 runs. We highlight with a red marker the highest average accuracy for the simulated humans under each conformal predictor.", "description": "This figure displays the average accuracy achieved by a simulated human expert using prediction sets constructed by four different conformal prediction methods (NAIVE, APS, RAPS, SAPS) on the ImageNet16H dataset.  The x-axis represents the \u03b1 value used in the conformal prediction, and the y-axis represents the average accuracy. Each panel corresponds to a different level of noise (\u03c9) in the ImageNet16H dataset. Error bars representing standard error are included. The highest average accuracy for each method is highlighted with a red marker, illustrating the optimal \u03b1 value for each conformal predictor under different noise levels.", "section": "H Conformal Prediction under different \u03b1 values"}]