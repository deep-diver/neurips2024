[{"figure_path": "waQ5X4qc3W/tables/tables_5_1.jpg", "caption": "Table 1: The stability of latent spaces induced from VQ Token and Discriminative Token (introduced in Section 3), assessed across different Signal-to-Noise Ratio (SNR) levels to evaluate performance under varying signal and noise conditions.", "description": "This table presents the results of an experiment designed to assess the stability of latent spaces generated by two different methods: VQ Token and Discriminative Token.  The experiment introduces varying levels of noise (SNR) to image pixels and measures the impact on the latent spaces.  The change in tokens (VQ Token change and Disc Token change) and the cosine similarity between the tokens before and after adding noise (VQ Token cos-sim and Disc Token cos-sim) are reported for each SNR level.  Lower change values and higher cosine similarity values indicate greater stability.", "section": "3 Stabilize the Latent Space with Self-supervised Learning Model"}, {"figure_path": "waQ5X4qc3W/tables/tables_6_1.jpg", "caption": "Table 2: Linear-probe accuracy of image autoregressive generative models on ImageNet [11].", "description": "This table compares the linear probing accuracy of various image autoregressive generative models on the ImageNet dataset.  The models are evaluated based on their ability to learn semantic features using a linear probe classifier.  The table shows the number of tokens, features, parameters, and the resulting top-1 accuracy for each model.  This demonstrates the models' performance in image understanding tasks, showing that higher parameter counts do not always correlate with better performance.", "section": "4 Experiments"}, {"figure_path": "waQ5X4qc3W/tables/tables_7_1.jpg", "caption": "Table 3: Class-unconditional image generation on ImageNet with resolution 256 \u00d7 256. DiGIT + VQ indicates that we utilize golden discriminative tokens alongside VQ generated by autoregressive models.", "description": "This table presents a comparison of different image generation models on the ImageNet dataset, focusing on class-unconditional image generation.  The table includes the model type (GAN, Diffusion, MIM, or Autoregressive), the method used, the number of parameters, the number of training epochs, the Fr\u00e9chet Inception Distance (FID) score (lower is better), and the Inception Score (IS) (higher is better).  DiGIT models are highlighted, demonstrating improved FID and IS scores, particularly with larger model sizes.", "section": "4 Experiments"}, {"figure_path": "waQ5X4qc3W/tables/tables_7_2.jpg", "caption": "Table 3: Class-unconditional image generation on ImageNet with resolution 256 \u00d7 256. DiGIT + VQ indicates that we utilize golden discriminative tokens alongside VQ generated by autoregressive models.", "description": "This table presents a comparison of different image generation methods on the ImageNet dataset, focusing on class-unconditional image generation with a resolution of 256x256 pixels.  The table includes various model types (GAN, Diffusion, MIM, AR), methods, the number of parameters, the number of training epochs, and the resulting Fr\u00e9chet Inception Distance (FID) and Inception Score (IS) values.  Lower FID and higher IS scores indicate better image quality.  The table also highlights results from the proposed DiGIT model, showcasing its performance both alone and in conjunction with other methods (VQGAN and MaskGIT).", "section": "4 Experiments"}, {"figure_path": "waQ5X4qc3W/tables/tables_9_1.jpg", "caption": "Table 4: Class-conditional image generation on ImageNet with resolution 256 \u00d7 256. \u2020 denotes the model is trained with classifier-free guidance while all the other models are not.", "description": "This table presents the results of class-conditional image generation experiments on the ImageNet dataset with images of size 256x256.  Different generative model types (GAN, Diffusion, MIM, AR) and specific models are compared using Fr\u00e9chet Inception Distance (FID) and Inception Score (IS) metrics, lower FID and higher IS indicating better generation quality. The '\u2020' symbol indicates that a specific model was trained with classifier-free guidance, a technique that influences generation.", "section": "4 Experiments"}]