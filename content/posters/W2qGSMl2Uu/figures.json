[{"figure_path": "W2qGSMl2Uu/figures/figures_0_1.jpg", "caption": "Figure 1: An illustration of the necessity of using autoregressive model in the anchor level. While Scaffold-GS [20] greatly reduces the spatial redundancy among adjacent 3D Gaussians by grouping them and introducing a new data structure anchor to capture their common features, spatial redundancy still exists among anchors. Our method, ContextGS, first proposes to reduce the spatial redundancy among anchors using an autoregressive model. We divide anchors into levels as shown in Fig. (b) and the anchors from coarser levels are used to predict anchors in finer levels, i.e., predicts \u2022 then \u2022\u2022\u2022 together predict. Fig. (c) verifies the spatial redundancy by calculating the cosine similarity between anchors in level 0 and their context anchors in levels 1 and 2. Fig. (d) displays the bit savings using the proposed anchor-level context model evaluated on our entropy coding based strong baseline built on Scaffold-GS [20]. Compared with Scaffold-GS [20], we achieve better rendering qualities, faster rendering speed, and great size reduction of up to 15 times averaged over all datasets we used.", "description": "This figure illustrates the need for an autoregressive model at the anchor level for 3D Gaussian Splatting compression.  It shows that even though Scaffold-GS reduces spatial redundancy, some still exists among anchors. ContextGS addresses this by using an autoregressive model and dividing anchors into levels, where coarser levels predict finer levels. The figure includes visualizations of a rendered image, anchor division into levels, cosine similarity between anchors, and bit savings achieved by ContextGS compared to Scaffold-GS.", "section": "Introduction"}, {"figure_path": "W2qGSMl2Uu/figures/figures_3_1.jpg", "caption": "Figure 2: (a): An illustration of the data structure we used following Scaffold-GS [19], where anchor points are used to extract common features of their associated neural Gaussians. (b): The proposed multi-level division of anchor points. The decoded anchors from higher (coarser) levels are directly forwarded to the lower (finer) level to avoid duplicate storage. Besides, taking decompression as an example, the already decoded anchors are used to predict anchors that are not decompressed yet, which greatly reduces the spatial redundancy among adjacent anchors. (Best zoom in for details.)", "description": "This figure illustrates the data structure used in the proposed method and its comparison with the Scaffold-GS method. (a) shows how Scaffold-GS uses anchor points to capture common features of associated neural Gaussians, while (b) presents the proposed multi-level anchor division, where decoded anchors from coarser levels are used to predict finer-level anchors, thus reducing spatial redundancy and storage.", "section": "4 Methodology"}, {"figure_path": "W2qGSMl2Uu/figures/figures_4_1.jpg", "caption": "Figure 3: The overall framework of the proposed method includes three levels, i.e., K = 3, to encode the anchors. The decoded anchors from a coarser level i + 1 are used to encode the anchors in level i. Besides, hyperprior features are used to predict the properties of anchors at all levels. For training, after finishing the coding of all levels, the anchor features after adaptive quantization are used to predict properties of neural Gaussians. The rendering loss is calculated and optimized together with the entropy coding loss Lentropy. For testing, after we decode anchor features from the bit stream, the rendering is exactly the same with Scaffold-GS [20] without introducing overhead.", "description": "This figure illustrates the overall framework of the ContextGS method. It consists of three main parts: (a) Hyperprior coding, (b) Anchor feature coding, and (c) Neural Gaussian splatting & \u03b1-blending.  The hyperprior coding stage uses a hyperprior model to predict and encode the properties of anchors. The anchor feature coding stage uses an autoregressive model, where decoded anchors from coarser levels are used to predict anchors at finer levels, and features are adaptively quantized for efficient entropy coding. Finally, the neural Gaussian splatting & \u03b1-blending stage renders the scene using the decoded anchor attributes and neural Gaussians.", "section": "4 Methodology"}, {"figure_path": "W2qGSMl2Uu/figures/figures_7_1.jpg", "caption": "Figure 5: Visual comparisons between our method and baselines including Scaffold-GS [20], HAC [5], and Compact3DGS [18] on Bungeenerf [32] and Tank&Temples [16]. We report the PSNR (dB) of the image and the size of the 3D scene. (Best zoom in for details.)", "description": "This figure shows visual comparisons of novel view synthesis results between the proposed method (ContextGS) and several baselines (Scaffold-GS, HAC, Compact3DGS) on two datasets (BungeeNeRF and Tanks & Temples).  For each scene, a reference image is presented alongside the reconstructions from each method.  The PSNR (Peak Signal-to-Noise Ratio) and model size in MB are provided for quantitative comparison. The images highlight the visual quality and compression achieved by each method.", "section": "5 Experiments"}, {"figure_path": "W2qGSMl2Uu/figures/figures_7_2.jpg", "caption": "Figure 6: The ablation of different target ratio \u03c4 among different scenes. The PSNR remains relatively stable while the size of the scenes keeps increasing when increasing the \u03c4, which demonstrates the effectiveness.", "description": "This figure shows the ablation study on the effect of different target ratios (\u03c4) on the model's performance.  The x-axis represents the target ratio, and the y-axis shows the size (in MB) and PSNR (dB) for two different scenes ('rome' and 'amsterdam'). The results indicate that PSNR remains relatively stable across different target ratios, while the size of the model changes. This experiment demonstrates the robustness and efficiency of the proposed model in handling varied target ratios, confirming the effectiveness of the proposed approach.", "section": "5.3 Ablation studies and discussions"}]