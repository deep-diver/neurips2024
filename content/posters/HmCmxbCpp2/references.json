{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper provides a technical report on GPT-4, a large language model crucial to the core methodology of the presented work."}, {"fullname_first_author": "Michael Ahn", "paper_title": "Do as I Can, Not as I Say: Grounding Language in Robotic Affordances", "publication_date": "2022-04-01", "reason": "This paper is relevant to the embodied AI task tackled by this paper, and explores a similar grounding of language in action."}, {"fullname_first_author": "Dhruv Batra", "paper_title": "ObjectNav Revisited: On Evaluation of Embodied Agents Navigating to Objects", "publication_date": "2020-06-13", "reason": "This paper provides a comprehensive overview of the object navigation task, and its evaluation metrics, essential for comparison with this work."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-07-01", "reason": "This work introduces CLIP, a foundational vision-language model that is highly relevant and utilized in the zero-shot object navigation domain."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "LLaMA: Open and Efficient Foundation Language Models", "publication_date": "2023-02-13", "reason": "This paper introduces LLaMA, a large language model used in the experiments, and is important for understanding the capabilities and limitations of the LLM."}]}