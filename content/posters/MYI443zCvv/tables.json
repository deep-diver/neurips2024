[{"figure_path": "MYI443zCvv/tables/tables_2_1.jpg", "caption": "Table 1: Terminology of DEPrune method. This symbol (\u2020) means \u2018we apply our methodology to determine which PW-conv to prune for better performance (Sec. 4.2)\u2019. BWT and HSR are our proposed method to enhance DEPrune. BWT and HSR are described in Sec. 5.1 and Sec. 5.2, respectively. This symbol (\u221a) means \u2018Applied\u2019.", "description": "This table summarizes the terminology used in the paper to describe the different variations of the DEPrune method.  It shows the status (applied or not) of the core Depth-wise Convolution Pruning (DCP) method, along with optional enhancements: Balanced Workload Tuning (BWT) and Hardware-aware Sparsity Recalibration (HSR), applied separately to DW-conv and PW-conv layers.  It clarifies which pruning methods are used for depthwise and pointwise convolutions in each variant of DEPrune.", "section": "Pruning for DSConv"}, {"figure_path": "MYI443zCvv/tables/tables_7_1.jpg", "caption": "Table 2: Comparison between DEPrune and DEPrune-B (DEPrune + BWT) on ImageNet dataset. This symbol (\u2020) means \u2018DW-conv inference time speedup than unpruned DW-conv\u2019. \u2018Real DW\u2019 denotes the minimum pruning ratio among the sub-GEMMs of DW-conv. \u2018Diff.\u2019 denotes the difference in Top-1 accuracy between the baseline and pruned models.", "description": "This table compares the performance of DEPrune and DEPrune-B (which incorporates Balanced Workload Tuning) on the ImageNet dataset using three different CNN models.  It shows the pruning ratios achieved for depthwise convolutions (DW-conv), the actual minimum pruning ratio among the sub-GEMMs of DW-conv, the pruning ratio for pointwise convolutions (PW-conv), the baseline top-1 accuracy, the top-1 accuracy after pruning, the difference in accuracy, and the speedup achieved. The speedup is relative to the unpruned DW-conv.", "section": "6.1 Effect of BWT (DEPrune vs. DEPrune-B)"}, {"figure_path": "MYI443zCvv/tables/tables_7_2.jpg", "caption": "Table 3: Comparison between DEPrune-B and DEPrune-BH (DEPrune-B + DW-conv HSR) on ImageNet dataset. This symbol (\u2020) means \u2018DW-conv inference time speedup than unpruned DW-conv.\u2019 \u2018DW-Pat.\u2019 denotes the HSR pattern for DW-conv layers. \u2018u\u2019 and \u2018o\u2019 denotes under-aligned and over-aligned layers, respectively. \u2018Diff.\u2019 denotes the difference in Top-1 accuracy between the baseline and pruned models.", "description": "This table compares the performance of DEPrune-B and DEPrune-BH (which incorporates Hardware-aware Sparsity Recalibration or HSR) on the ImageNet dataset.  It shows the pruning ratios achieved for depthwise convolution (DW-conv) and pointwise convolution (PW-conv), along with the resulting top-1 accuracy and speedup. The \u2018DW-Pat\u2019 column indicates the pattern of HSR applied to DW-conv layers, classifying them as under-aligned (u) or over-aligned (o). The \u2018Diff\u2019 column highlights the difference in top-1 accuracy between the pruned and baseline models.", "section": "6.2 Effect of HSR (DEPrune-B vs. DEPrune-BH)"}, {"figure_path": "MYI443zCvv/tables/tables_8_1.jpg", "caption": "Table 4: Comparison of inference time (\u00b5s) with DEPrune-BH and the latest structured pruning on ImageNet dataset. \u2018Diff.\u2019 denotes the difference in Top-1 accuracy between the baseline and pruned models. DEPrune-BH applies filter pruning using l2-norm to PW-conv. This symbol (*) means \u2018baseline model.\u2019", "description": "This table compares the inference time and top-1 accuracy of DEPrune-BH against other state-of-the-art structured pruning methods on the ImageNet dataset using three different CNN models (MobileNet-V2, MobileNet-V3-Small, EfficientNet-B0).  It shows the pruning ratios applied to depthwise and pointwise convolutions, the resulting pruned FLOPs, the difference in top-1 accuracy compared to the baseline, and the speedup achieved by DEPrune-BH in both depthwise and total inference time.  The baseline models are unpruned versions.", "section": "6 Experiments"}, {"figure_path": "MYI443zCvv/tables/tables_9_1.jpg", "caption": "Table 3: Comparison between DEPrune-B and DEPrune-BH (DEPrune-B + DW-conv HSR) on ImageNet dataset. This symbol (\u2020) means \u2018DW-conv inference time speedup than unpruned DW-conv.\u2019 \u2018DW-Pat.\u2019 denotes the HSR pattern for DW-conv layers. \u2018u\u2019 and \u2018o\u2019 denotes under-aligned and over-aligned layers, respectively. \u2018Diff.\u2019 denotes the difference in Top-1 accuracy between the baseline and pruned models.", "description": "This table compares the performance of DEPrune-B and DEPrune-BH on the ImageNet dataset.  DEPrune-BH adds Hardware-aware Sparsity Recalibration (HSR) to DEPrune-B. The table shows the pruning ratios for DW-conv and PW-conv layers, the Top-1 accuracy (comparing pruned models to the baseline), and the speedup achieved with DW-conv. It also indicates whether layers are under-aligned (u) or over-aligned (o) after HSR, highlighting the impact of this technique on performance and accuracy.", "section": "6.2 Effect of HSR (DEPrune-B vs. DEPrune-BH)"}, {"figure_path": "MYI443zCvv/tables/tables_13_1.jpg", "caption": "Table 6: Comparison of accuracy between DEPrune and Channel Pruning with MobileNet-V2 on CIFAR-10 dataset.", "description": "This table compares the accuracy of MobileNet-V2 on the CIFAR-10 dataset when using channel pruning and DEPrune at different pruning ratios for both depthwise and pointwise convolutional layers.  It shows that DEPrune consistently achieves slightly higher accuracy than channel pruning, even at higher pruning ratios.", "section": "A.5 Limitation of Channel Pruning on DW-conv"}, {"figure_path": "MYI443zCvv/tables/tables_14_1.jpg", "caption": "Table 7: Comparison of accuracy (%) with DEPrune-B and NVIDIA n:m pruning on CIFAR-10 dataset. \u2018Diff.\u2019 denotes the difference in accuracy between the baseline and pruned model. NVIDIA n:m pruning\u2019s n and m size are 2 and 4. DEPrune-B applies filter pruning using l2-norm to PW-conv.", "description": "This table compares the accuracy of MobileNet-V2 on the CIFAR-10 dataset after applying three different pruning methods: no pruning (baseline), NVIDIA's n:m sparsity pruning (50% pruning ratio), and the proposed DEPrune-B method (50% pruning ratio).  It shows the accuracy drop ('Diff.') compared to the baseline for each pruning technique.  Note that DEPrune-B uses a specific filter pruning technique (l2-norm) applied to the pointwise convolutions (PW-conv).", "section": "A.7 Effect of Balanced Range"}, {"figure_path": "MYI443zCvv/tables/tables_15_1.jpg", "caption": "Table 8: Comparison between DCP and DCP-B of EfficientNet-B0 on CIFAR-10 dataset.", "description": "This table presents the results of applying Depthwise Convolution Pruning (DCP) and Balanced Workload Tuning (BWT) enhanced DCP (DCP-B) to the EfficientNet-B0 model on the CIFAR-10 dataset.  It shows the accuracy achieved at different pruning ratios for both DW-conv and PW-conv layers. The comparison highlights the impact of BWT on the model's accuracy.", "section": "A.8 Effect of Balanced Workload Tuning (BWT)"}, {"figure_path": "MYI443zCvv/tables/tables_15_2.jpg", "caption": "Table 9: Analysis of Peak Memory Usage (MB) with DEPrune-BH on ImageNet dataset. \u2018GAP\u2019 means the after-pruning peak memory usage difference rate compared to pre-pruning. DEPrune-BH applies filter pruning using l2-norm to PW-conv.", "description": "This table shows the peak memory usage (in MB) of MobileNet-V2 on the ImageNet dataset before and after applying the DEPrune-BH pruning method with a 50% pruning ratio.  It highlights the memory reduction achieved by the method.  The \u2018GAP\u2019 column shows the difference in peak memory usage between the pre-pruned and post-pruned model.", "section": "A.9 Peak Memory Usage"}]