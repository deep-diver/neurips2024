{"references": [{"fullname_first_author": "J. Deng", "paper_title": "Imagenet: A large-scale hierarchical image database", "publication_date": "2009-06-20", "reason": "This paper introduces ImageNet, a crucial large-scale dataset used for training and evaluating the deep learning models discussed in the paper."}, {"fullname_first_author": "S. Han", "paper_title": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "publication_date": "2016-00-00", "reason": "This foundational paper introduces the concept of deep compression, providing the background and context for the model pruning techniques that the current paper builds upon."}, {"fullname_first_author": "F. Chollet", "paper_title": "Xception: Deep learning with depthwise separable convolutions", "publication_date": "2017-07-00", "reason": "This paper introduces depthwise separable convolutions (DSC), a core component of the models being studied, making it essential for understanding the methods described in the current paper."}, {"fullname_first_author": "M. Sandler", "paper_title": "Mobilenetv2: Inverted residuals and linear bottlenecks", "publication_date": "2018-06-00", "reason": "This paper introduces MobileNetV2, an important architecture used for experimental evaluation in the paper, influencing the model selection and analysis."}, {"fullname_first_author": "M. Tan", "paper_title": "Efficientnet: Rethinking model scaling for convolutional neural networks", "publication_date": "2019-06-00", "reason": "This work introduces EfficientNet, another key model architecture used in the experiments, providing a basis for comparison and evaluation of the proposed pruning techniques."}]}