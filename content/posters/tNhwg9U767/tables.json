[{"figure_path": "tNhwg9U767/tables/tables_4_1.jpg", "caption": "Table 1: Microstructural patterns and performance of graph recall by LLMs on graphs sampled from various application domains; mean \u00b1 ci95% reported. The numbers reported for microstructural patterns are signficance parameters \u03b8 computed by the ERGM model introduced in Sec. 2.1. A positive (negative) number means the LLM is biased towards encouraging (depressing) the corresponding microstructural pattern in recalled graphs. The patterns are visualized in Fig.2 Step 6. Full table available in Appendix C.", "description": "This table presents the results of an experiment that evaluated the accuracy and microstructural patterns of Large Language Models (LLMs) in recalling graphs from various domains.  The microstructural patterns (e.g., triangles, stars, alternating 2-paths) represent the local subgraph structures within the recalled graphs. The statistical significance of these patterns was assessed using the Exponential Random Graph Model (ERGM).  The table shows the mean and 95% confidence interval for each microstructural pattern, indicating whether the LLMs were biased towards or against specific patterns.  It also shows the accuracy and F1 scores for each LLM's performance on the graph recall task across different domains (Facebook, CA Road, Reactome, DBLP, and Erd\u0151s-R\u00e9nyi).", "section": "3 Microstructures and Accuracy of Graph Recall by LLMs"}, {"figure_path": "tNhwg9U767/tables/tables_5_1.jpg", "caption": "Table 1: Microstructural patterns and performance of graph recall by LLMs on graphs sampled from various application domains; mean \u00b1 ci95% reported. The numbers reported for microstructural patterns are signficance parameters \u03b8 computed by the ERGM model introduced in Sec. 2.1. A positive (negative) number means the LLM is biased towards encouraging (depressing) the corresponding microstructural pattern in recalled graphs. The patterns are visualized in Fig.2 Step 6. Full table available in Appendix C.", "description": "This table presents the results of an experiment evaluating the performance of different Large Language Models (LLMs) in recalling graph structures.  It shows the accuracy and F1 scores of each LLM across various datasets, along with the statistical significance of microstructural patterns (triangles, stars, etc.) in their recalled graphs.  A positive value indicates a bias toward that pattern, while a negative value indicates a bias against it. The ERGM model is used to assess statistical significance of the microstructures. The full table is available in Appendix C.", "section": "3 Microstructures and Accuracy of Graph Recall by LLMs"}, {"figure_path": "tNhwg9U767/tables/tables_7_1.jpg", "caption": "Table 1: Microstructural patterns and performance of graph recall by LLMs on graphs sampled from various application domains; mean \u00b1 ci95% reported. The numbers reported for microstructural patterns are signficance parameters \u03b8 computed by the ERGM model introduced in Sec. 2.1. A positive (negative) number means the LLM is biased towards encouraging (depressing) the corresponding microstructural pattern in recalled graphs. The patterns are visualized in Fig.2 Step 6. Full table available in Appendix C.", "description": "This table presents the results of an experiment evaluating the performance of three large language models (LLMs) in recalling graph structures.  It shows the statistical significance of several microstructural patterns (network motifs) found in the graphs recalled by the LLMs.  These patterns are compared to the ground truth.  The table also reports accuracy and F1 scores, which measure the performance of each LLM. Positive values indicate a bias towards that pattern, while negative values indicate a bias against it.", "section": "3 Microstructures and Accuracy of Graph Recall by LLMs"}, {"figure_path": "tNhwg9U767/tables/tables_18_1.jpg", "caption": "Table 1: Microstructural patterns and performance of graph recall by LLMs on graphs sampled from various application domains; mean \u00b1 ci95% reported. The numbers reported for microstructural patterns are signficance parameters \u03b8 computed by the ERGM model introduced in Sec. 2.1. A positive (negative) number means the LLM is biased towards encouraging (depressing) the corresponding microstructural pattern in recalled graphs. The patterns are visualized in Fig.2 Step 6. Full table available in Appendix C.", "description": "This table presents the results of a graph recall experiment conducted on various LLMs.  It shows the microstructural patterns (local subgraph structures) in the graphs recalled by the LLMs, and how these patterns differ from the ground truth.  The statistical significance of these differences is measured using an Exponential Random Graph Model (ERGM), with positive values indicating a bias toward the pattern and negative values indicating a bias away from it. The table also includes performance metrics (accuracy and F1 score) for each LLM on each dataset.", "section": "3 Microstructures and Accuracy of Graph Recall by LLMs"}, {"figure_path": "tNhwg9U767/tables/tables_18_2.jpg", "caption": "Table 1: Microstructural patterns and performance of graph recall by LLMs on graphs sampled from various application domains; mean \u00b1 ci95% reported. The numbers reported for microstructural patterns are signficance parameters \u03b8 computed by the ERGM model introduced in Sec. 2.1. A positive (negative) number means the LLM is biased towards encouraging (depressing) the corresponding microstructural pattern in recalled graphs. The patterns are visualized in Fig.2 Step 6. Full table available in Appendix C.", "description": "This table presents the results of an experiment evaluating the accuracy and microstructural patterns of Large Language Models (LLMs) in recalling graphs.  It shows the mean and 95% confidence intervals for several microstructural patterns (edge, triangle, star, alt-triangle, alt-2-path) in graphs recalled by different LLMs across five datasets from various domains. Positive values indicate a bias towards the pattern, while negative values indicate a bias against it.  The table also includes the accuracy and F1 scores for each LLM and dataset, providing a comprehensive performance evaluation. The full table is available in Appendix C.", "section": "3.2 Results and Analysis"}, {"figure_path": "tNhwg9U767/tables/tables_18_3.jpg", "caption": "Table 1: Microstructural patterns and performance of graph recall by LLMs on graphs sampled from various application domains; mean \u00b1 ci95% reported. The numbers reported for microstructural patterns are signficance parameters \u03b8 computed by the ERGM model introduced in Sec. 2.1. A positive (negative) number means the LLM is biased towards encouraging (depressing) the corresponding microstructural pattern in recalled graphs. The patterns are visualized in Fig.2 Step 6. Full table available in Appendix C.", "description": "This table presents the results of a graph recall experiment conducted on several LLMs using graphs sampled from various domains. It shows the statistical significance of five microstructural patterns (edge, triangle, star, alternating triangle, alternating 2-path) in the recalled graphs compared to the true graphs.  Positive values indicate a bias towards the pattern in the recalled graphs, while negative values indicate a bias against the pattern.  The table also reports the accuracy and F1 score of each LLM's recall performance for each dataset.  The ERGM model is used to calculate the significance of these patterns.", "section": "3 Microstructures and Accuracy of Graph Recall by LLMs"}, {"figure_path": "tNhwg9U767/tables/tables_20_1.jpg", "caption": "Table 1: Microstructural patterns and performance of graph recall by LLMs on graphs sampled from various application domains; mean \u00b1 ci95% reported. The numbers reported for microstructural patterns are signficance parameters \u03b8 computed by the ERGM model introduced in Sec. 2.1. A positive (negative) number means the LLM is biased towards encouraging (depressing) the corresponding microstructural pattern in recalled graphs. The patterns are visualized in Fig.2 Step 6. Full table available in Appendix C.", "description": "This table presents the results of a graph recall experiment conducted on Large Language Models (LLMs).  It shows the accuracy and microstructural patterns (local subgraph patterns) in the graphs recalled by different LLMs across various datasets representing different real-world domains. The microstructural patterns are analyzed using the Exponential Random Graph Model (ERGM), with positive values indicating a bias towards that pattern and negative values indicating a bias against it.  The table also provides the accuracy and F1 score for each LLM's recall performance on each dataset.  Appendix C contains the full table.", "section": "3 Microstructures and Accuracy of Graph Recall by LLMs"}]