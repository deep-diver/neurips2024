[{"figure_path": "dIHXwKjXRE/figures/figures_1_1.jpg", "caption": "Figure 1: (a) It is proven that the DNN's inference on a certain sample is equivalent to a logical model that uses a small number of AND-OR interactions for inference. Each interaction corresponds to a non-linear (AND or OR) relationship between a set S of input variables (e.g., image patches). (b) Sparsity of interactions. We show the strength |I(Sx)| of all 2n interactions sorted in descending order. (c) Illustration of the two-phase dynamics of a DNN learning interactions of different orders.", "description": "This figure illustrates three key concepts of the paper. (a) shows the equivalence of a DNN's inference to a logical model using AND-OR interactions.  (b) demonstrates the sparsity of interactions, highlighting that only a few have significant effects. (c) visually represents the two-phase learning dynamics of DNNs: a first phase where low-order interactions are dominant, and a second phase where high-order interactions emerge.", "section": "1 Introduction"}, {"figure_path": "dIHXwKjXRE/figures/figures_4_1.jpg", "caption": "Figure 2: The distribution of interaction strength I(k) over different orders k. Each row shows the change in the distribution during the training process. Experiments showed that the two-phase phenomenon widely existed on different DNNs trained on various datasets. It also verified the finding in [41] that the beginning of the 2nd phase was temporally aligned with the time point when the loss gap increased. Please see Appendix J.1 for results on the other six DNNs trained for 3D point cloud/image/sentiment classification.", "description": "This figure demonstrates the two-phase dynamics of interaction complexity during the training process of various deep neural networks (DNNs).  Each row represents a different DNN trained on a different dataset. The x-axis represents the order (complexity) of the interactions, and the y-axis represents the interaction strength. The figure shows how the distribution of interaction strength changes over six different time points during training.  Before training, the DNNs primarily encode interactions of medium complexity. In the first phase, low-order interactions are emphasized while high-order interactions are suppressed.  In the second phase, high-order interactions gradually increase, indicating a shift towards overfitting. The timing of the transition to the second phase aligns with the point where the gap between training and testing loss begins to increase.", "section": "3.2 Two-phase dynamics of learning interactions"}, {"figure_path": "dIHXwKjXRE/figures/figures_8_1.jpg", "caption": "Figure 3: Monotonic increase of r(k) along with \u03c3\u00b2 mentioned in Proposition 1. We show the curves of r(k) when we set different numbers of input variables n and different orders k = 1,\u2026\u2026, n \u2212 1.", "description": "This figure shows the curves of r(k) (the ratio of the strength of low-order interactions to that of high-order interactions) with different \u03c3\u00b2 (noise levels) and n (number of variables).  The curves demonstrate that the ratio r(k) monotonically increases with \u03c3\u00b2. This result supports Proposition 1, which states that as the noise level decreases during training, the relative strength of low-order interactions compared to high-order interactions also decreases.", "section": "3.3 Proving of the two-phase dynamics"}, {"figure_path": "dIHXwKjXRE/figures/figures_8_2.jpg", "caption": "Figure 2: The distribution of interaction strength I(k) over different orders k. Each row shows the change in the distribution during the training process. Experiments showed that the two-phase phenomenon widely existed on different DNNs trained on various datasets. It also verified the finding in [41] that the beginning of the 2nd phase was temporally aligned with the time point when the loss gap increased. Please see Appendix J.1 for results on the other six DNNs trained for 3D point cloud/image/sentiment classification.", "description": "This figure demonstrates the two-phase dynamics of interaction complexity during DNN training across various datasets and architectures. Each row displays the distribution of interaction strength (I(k)) across different orders (k) at various training epochs. The figure highlights the two phases: an initial phase where the DNN primarily removes interactions of medium to high complexity and a second phase where it gradually learns increasingly complex interactions. The onset of the second phase correlates with an increase in the gap between training and testing loss.", "section": "3.2 Two-phase dynamics of learning interactions"}, {"figure_path": "dIHXwKjXRE/figures/figures_25_1.jpg", "caption": "Figure 2: The distribution of interaction strength I(k) over different orders k. Each row shows the change in the distribution during the training process. Experiments showed that the two-phase phenomenon widely existed on different DNNs trained on various datasets. It also verified the finding in [41] that the beginning of the 2nd phase was temporally aligned with the time point when the loss gap increased. Please see Appendix J.1 for results on the other six DNNs trained for 3D point cloud/image/sentiment classification.", "description": "This figure shows how the distribution of interaction strength changes over different orders (k) during the training process of various DNNs on different datasets. Each row represents a different DNN trained for a different task. The plots show that in the initial state before training, the distribution has a spindle shape, with medium-order interactions being most prominent. Then, a two-phase dynamic is observed in all DNNs. In the first phase, medium and high-order interactions are removed, leaving only low-order interactions. In the second phase, higher-order interactions are gradually learned. The beginning of the second phase coincides with the increase of loss gap between training and testing loss, which indicates the start of overfitting. This provides empirical evidence supporting the theory proposed in the paper that DNNs learn interactions in two phases.", "section": "3.2 Two-phase dynamics of learning interactions"}, {"figure_path": "dIHXwKjXRE/figures/figures_25_2.jpg", "caption": "Figure 2: The distribution of interaction strength I(k) over different orders k. Each row shows the change in the distribution during the training process. Experiments showed that the two-phase phenomenon widely existed on different DNNs trained on various datasets. It also verified the finding in [41] that the beginning of the 2nd phase was temporally aligned with the time point when the loss gap increased. Please see Appendix J.1 for results on the other six DNNs trained for 3D point cloud/image/sentiment classification.", "description": "This figure shows how the distribution of interaction strength changes during the training process for various DNNs trained on different datasets. Each row represents a different DNN and dataset, and the columns show the distribution of interaction strength at different time points during training. The figure demonstrates a two-phase dynamic, with an initial phase where the DNN eliminates interactions of medium and high complexity, and a second phase where the DNN gradually learns interactions of increasing complexity. The onset of the second phase coincides with an increase in the gap between training and testing loss, suggesting a transition from underfitting to overfitting.", "section": "3.2 Two-phase dynamics of learning interactions"}, {"figure_path": "dIHXwKjXRE/figures/figures_26_1.jpg", "caption": "Figure 7: Demonstration of the training loss and the testing loss (the last column) in addition to the two-phase dynamics of interactions (1st column to 6th column) and the loss gap (7th column).", "description": "This figure demonstrates the training and testing loss curves, along with the loss gap and the distribution of interaction strength across different orders. Each row represents a different DNN trained on a different dataset. The figure illustrates how the two phases of interaction learning relate to the training and testing loss curves. The loss gap is the difference between the training and testing loss, reflecting generalization performance.  In the first phase, the loss gap decreases as the DNN learns more generalizable low-order interactions, and in the second phase, the loss gap increases as the DNN begins to learn more complex, high-order interactions which are typically less generalizable, indicating overfitting.", "section": "3.2 Two-phase dynamics of learning interactions"}, {"figure_path": "dIHXwKjXRE/figures/figures_27_1.jpg", "caption": "Figure 2: The distribution of interaction strength I(k) over different orders k. Each row shows the change in the distribution during the training process. Experiments showed that the two-phase phenomenon widely existed on different DNNs trained on various datasets. It also verified the finding in [41] that the beginning of the 2nd phase was temporally aligned with the time point when the loss gap increased. Please see Appendix J.1 for results on the other six DNNs trained for 3D point cloud/image/sentiment classification.", "description": "This figure shows the distribution of interaction strength (I(k)) across different orders (k) during the training process for several DNNs. Each row represents a different DNN trained on a different dataset. The plots visualize the shift in the distribution from a relatively even distribution before training to a two-phase pattern during training.  The first phase shows a decrease in medium and high-order interaction strength, while the second phase shows an increase in higher-order interactions. The timing of the transition between these two phases aligns with when the gap between training and testing loss increases, suggesting a connection to overfitting.", "section": "3.2 Two-phase dynamics of learning interactions"}, {"figure_path": "dIHXwKjXRE/figures/figures_28_1.jpg", "caption": "Figure 2: The distribution of interaction strength I(k) over different orders k. Each row shows the change in the distribution during the training process. Experiments showed that the two-phase phenomenon widely existed on different DNNs trained on various datasets. It also verified the finding in [41] that the beginning of the 2nd phase was temporally aligned with the time point when the loss gap increased. Please see Appendix J.1 for results on the other six DNNs trained for 3D point cloud/image/sentiment classification.", "description": "This figure shows how the distribution of interaction strength changes over different orders (complexity) throughout the training process for several different DNNs trained on various datasets.  It demonstrates the two-phase dynamics of interaction learning observed in the paper.  Before training, medium-complexity interactions dominate. Then, in phase one, the DNN removes medium- and high-complexity interactions and prioritizes low-order interactions. In phase two, it gradually learns higher-order interactions. The onset of phase two correlates with the point where the difference between training and testing loss begins to increase (the loss gap).", "section": "3.2 Two-phase dynamics of learning interactions"}]