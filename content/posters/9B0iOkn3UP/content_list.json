[{"type": "text", "text": "Computational Aspects of Bayesian Persuasion under Approximate Best Response ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Kunhe Yang University of California, Berkeley kunheyang@berkeley.edu ", "page_idx": 0}, {"type": "text", "text": "Hanrui Zhang Chinese University of Hong Kong hanrui@cse.cuhk.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study Bayesian persuasion under approximate best response, where the receiver may choose any action that is not too much suboptimal, given their posterior belief upon receiving the signal. We focus on the computational aspects of the problem, aiming to design algorithms that efficiently compute (almost) optimal strategies for the sender. Despite the absence of the revelation principle \u2014 which has been one of the most powerful tools in Bayesian persuasion \u2014 we design polynomial-time exact algorithms for the problem when either the state space or the action space is small, as well as a quasi-polynomial-time approximation scheme (QPTAS) for the general problem. On the negative side, we show there is no polynomial-time exact algorithm for the general problem unless ${\\mathsf{P}}={\\mathsf{N P}}$ . Our results build on several new algorithmic ideas, which might be useful in other principal-agent problems where robustness is desired. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Bayesian persuasion [Kamenica and Gentzkow, 2011] concerns the problem where a principal (the \u201csender\u201d) incentivizes a self-interested agent (the \u201creceiver\u201d) to act in certain ways by selectively revealing information about the state of the world. A commonly cited simplistic example \u2014 which nonetheless illustrates the essence of the problem \u2014 is that of selling apples. ", "page_idx": 0}, {"type": "text", "text": "Example 1.1. Suppose a buyer (the receiver) is debating whether they should buy an apple from a seller (the sender). A priori, the buyer believes the apple (which is, say, a random apple from a large batch of apples) to be a \u201cgood\u201d one with probability $1/3$ , and a \u201cbad\u201d one with probability $2/3$ . Moreover, suppose the buyer derives utility 1 from buying a good apple, and $-1$ from buying a bad one. Then, aiming to maximize their expected utility, without any further information, the buyer should simply not buy the apple, because buying it would lead to expected utility $\\bar{1}\\times\\textstyle{\\frac{1}{3}}\\!+\\!(-1)\\times\\textstyle{\\frac{2}{3}}\\stackrel{\\cdot}{=}-\\frac13<0$ . The seller, who has perfect knowledge of the quality of the apple, and wants to \u201cpersuade\u201d the buyer to buy the apple, can of course simply reveal the quality of the apple. Assuming the seller can do so in a credible way (which is a fundamental assumption in Bayesian persuasion), the buyer will buy the apple whenever it is good, which happens with probability $1/3$ . ", "page_idx": 0}, {"type": "text", "text": "In fact, the seller can do even better by employing the following strategy: the seller promises to send a \u201csignal\u201d to the buyer regarding the quality of the apple, which can be either \u201cprobably good\u201d or \u201cdefinitely bad\u201d. More specifically, if the apple is good, the sender signals that it is \u201cprobably good\u201d; if the apple is bad, the seller signals randomly, that it is \u201cprobably good\u201d notwithstanding with probability 0.499, and that it is \u201cdefinitely bad\u201d with probability 0.501. Now consider the buyer\u2019s perspective, assuming the seller does act up to their promises. If the signal says \u201cdefinitely bad\u201d, then the buyer should certainly not buy the apple. If, however, the signal says \u201cprobably good\u201d, then the buyer faces a more interesting decision. All the buyer knows is that the probability of (1) receiving \u201cprobably good\u201d and (2) the apple is actually good, happening simultaneously, is 1/3, and that the probability of (1) receiving \u201cprobably good\u201d and (2) the apple is actually bad, happening simultaneously, is $2/3\\times0.499<1/3.$ . So, given the signal, the conditional probability that the apple is good is larger than $1/2$ , which means the conditional expected utility of buying the apple is now positive. In other words, the seller has persuaded the rational buyer to buy the apple whenever the signal is \u201cprobably good\u201d, which happens with probability $1/3+2/3\\times0.499\\approx2/3$ . This turns out to be (almost) the best that the seller can do. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Since its introduction by Kamenica and Gentzkow [2011], Bayesian persuasion has attracted enormous attention from both economists and computer scientists. Indeed, a satisfactory solution to the problem is often twofold, involving an economic characterization that confines the sender\u2019s strategy space without loss of generality, and an efficient algorithm that finds the optimal strategy within this confined strategy space. For example, in the standard (and somewhat idealized) model of Bayesian persuasion, a prominent principle in economics, namely the revelation principle, states that without loss of generality, the sender\u2019s optimal strategy is to simply recommend an action (depending on the state of the world, effectively revealing partial information thereof) for the receiver to take, and make sure it is in the receiver\u2019s best interest to always follow such a recommendation, given their posterior belief of the state of the world. The computational problem of searching for the optimal strategy within this structured space of strategies turns out to be much easier than that of searching over the unconstrained strategy space. Such characterize-and-solve approaches have proved extremely successful in Bayesian persuasion \u2014 at least in settings where they apply. ", "page_idx": 1}, {"type": "text", "text": "The real world, unfortunately, is less precise than the idealized model. Even in the simplistic example of selling apples, there appear to be numerous subtleties that could potentially derail the supposedly (almost) optimal strategy of the seller. To name a few: the sender may not know exactly the receiver\u2019s prior belief, which might be different from the true distribution of the state of the world; the sender may not know exactly the receiver\u2019s utility function, which might be hard to evaluate even for the receiver themself; the device that generates randomness for the sender may be imperfect, affecting the receiver\u2019s posterior belief formed upon receiving a signal. In all these cases, the small inaccuracy can completely change the receiver\u2019s behavior: in the example of selling apples, the buyer would never buy the apple if they believe the apple is good a priori with probability 0.32 instead of $1/3$ , or if buying a good apple gives them utility 0.98 instead of 1, or if the device that generates randomness for the seller works in a way such that when the apple is bad, the seller actually signals \u201cprobably good\u201d with probability 0.501 instead of 0.499. From the perspective of the sender, it would appear as if the receiver is acting in a somewhat suboptimal and unexpected way. As we will show later, the powerful revelation principle no longer applies in such cases, and the problem of finding the sender\u2019s optimal strategy becomes much trickier. On top of that, things become even more complicated when there are more than 2 possible states of the world, and/or more than 2 actions for the receiver to choose between. All this brings us to our main question: despite the lack of a structural characterization, is there a principled and efficient way of finding the optimal strategy for the sender that is robust against such inaccuracy? ", "page_idx": 1}, {"type": "text", "text": "1.1 Our Results and Techniques ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this paper, we study Bayesian persuasion in a natural model that accounts for the kind of subtleties discussed above: roughly speaking, the model allows the receiver to choose any action that is \u201cnot too much suboptimal\u201d, given their posterior belief upon receiving the signal. We focus our attention on computational aspects of the problem, aiming to design algorithms that efficiently compute (almost) optimal strategies. ", "page_idx": 1}, {"type": "text", "text": "Direct-revalation signaling schemes are suboptimal. Our first finding is negative: there exists extremely simple problem instances (with only 2 possible actions and 3 possible states), where any direct-revelation signaling scheme (i.e., a strategy of the sender where each possible signal is a recommendation of a single action, as discussed above) is suboptimal at least by a factor of 2, or an additive gap of $1/2$ . This implies that the revelation principle ceases to work in our model, and the characterize-and-solve approach can no longer be employed. ", "page_idx": 1}, {"type": "text", "text": "LP formulation, and efficient algorithm with small action spaces. The above result highlights the need for new algorithmic ideas, and we present several of them in this paper. The first one is a linear program (LP) formulation for optimal strategies. The LP formulation has a similar high-level structure to the standard one for Bayesian persuasion: the variables correspond to probabilities that each signal is sent in each possible state of the world, and the constraints enforce the \u201csemantics\u201d of the signals, in terms of how the receiver is expected to respond. However, one complication (among others) in our model is that multiple actions might be taken as the response to any fixed signal, so the semantics of a signal must be rich enough to encode the subset of actions that are possible in response to that signal (plus any additional information required to describe a signal). In particular, this means in general, the number of possible signals is exponential in the number of actions. As such, the LP formulation alone implies an efficient algorithm for our problem only when the number of actions is constant or logarithmic. Nonetheless, the LP formulation serves as a building block of our further algorithmic results. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Efficient algorithm with small state spaces. Next we design an efficient algorithm when the number of states is constant. To see how this is possible, observe that a subset of actions can each be chosen as the response to a signal, only if the posterior utilities corresponding to these actions are all close to the best possible. In other words, if there does not exist a posterior belief given which a subset of actions are all almost optimal, then this subset itself is \u201cinfeasible\u201d as a set of possible responses. Such a subset of actions can never describe a signal in any strategy. Now the hope is to argue that the number of feasible subsets of actions is not too large. It turns out this can be obtained as a consequence of a result in combinatorial geometry, which bounds the number of \u201ccells\u201d in a low-dimensional space cut by a number of hyperplanes. We show that all feasible subsets induce a partition of these cells, so the same bound applies to the number of subsets too. In fact, one can show that the number of feasible subsets of actions is $n^{O(m)}$ , where $n$ and $m$ are the number of actions and that of states, respectively. ", "page_idx": 2}, {"type": "text", "text": "Now we know the number of relevant subsets of actions cannot be too large, but it remains a problem to find these subsets. To this end, we make yet another geometric observation: the cells that correspond to feasible subsets of actions form a single \u201cconnected component\u201d, which means we can enumerate all feasible subsets by traversing this component. More specifically, we start from any feasible subset, and try all its \u201cneighbors\u201d by swapping in or out a single possible action. For each neighbor, we check its feasibility by solving another LP. By repeating this procedure we can reach all feasible subsets, in time polynomial in the number of feasible subsets. Once we have computed all feasible subsets, we simply solve the LP for optimal strategies restricted to these subsets, which is of polynomial size when the number of states $m$ is constant. This gives us an efficient algorithm with constant-size state spaces. ", "page_idx": 2}, {"type": "text", "text": "Hardness of exact computation of the general problem. Knowing that the problem can be solved with small action spaces or small state spaces, it is then natural to seek an efficient algorithm that works unconditionally, without restrictions on any parameters of the problem. We show, unfortunately, that such an algorithm does not exist unless ${\\mathsf{P}}={\\mathsf{N P}}$ . We do so by reducing from an \u201cequally hard\u201d variant of the subset sum problem: given a set of $2n$ integers that sum to 0, decide whether there are $n$ integers out of the $2n$ that also sum to 0. The idea of the reduction is that such a set of $n$ integers corresponds to a signal that gives the sender the highest posterior utility possible. To ensure this, the utility functions need to exhibit delicate structures, such that a signal that corresponds to either too many or too few integers must be suboptimal. The latter appears to be a quite ambivalent condition \u2014 in fact, this is only possible with the kind of inaccuracy that we consider. We believe the ideas of our reduction are potentially useful in other principal-agent problems where robustness is required. ", "page_idx": 2}, {"type": "text", "text": "Approximation in quasi-polynomial time. In light of the hardness result, we turn our attention to approximation algorithms. We present a quasi-polynomial-time approximation scheme (QPTAS): for any target additive error $\\varepsilon\\,>\\,0$ , we give an $\\varepsilon$ -approximate algorithm that runs in time quasipolynomial in $m$ and $n$ , where the time complexity may depend on $\\varepsilon$ . The idea is to cover the space of all possible posterior utility functions using small cells, and consider a representative point in each cell with a small error. It is known that a covering of size $O(\\log n/\\varepsilon^{2})$ exists, which has already proven useful in other game-theoretic computational problems [Alth\u00f6fer, 1994, Lipton et al., 2003, Gan et al., 2023]. However, one difficulty in our model is that there are certain types of errors that are unacceptable, no matter how small. For example, fixing a strategy, the sender\u2019s utility can be discontinuous in the receiver\u2019s utility function, and any error near points of discontinuity can lead to a huge gap in the sender\u2019s utility. Similarly, because of the robustness component in the model, a small error in the sender\u2019s utility may lead to a totally different response from the receiver. To avoid such gaps, we allow approximation only in the sender\u2019s utility, and refrain from estimating the action that the receiver will respond with. Instead, we consider the approximate worst-case utility of the sender, which turns out to be tractable using linear constraints involving approximate utility functions. Combining this with the LP formulation discussed above, we have an LP of quasi-polynomial size, which can be solved in quasi-polynomial time. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "1.2 Related Works ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We defer a detailed discussion of related work to Appendix A. Our work connects to two lines of work, the computational aspect of Bayesian persuasion [Dughmi and Xu, 2016, Dughmi, 2017, 2014, Bhaskar et al., 2016, Rubinstein, 2017, Babichenko and Barman, 2016, 2017, Xu, 2020, Zhou et al., 2022] and various notions of robust Bayesian persuasion [de Clippel and Zhang, 2022, Chen and Lin, 2023, Camara et al., 2020, Zu et al., 2021, Collina et al., 2023, Kosterina, 2022, Dworczak and Pavan, 2022, Hu and Weng, 2021, Castiglioni et al., 2020, Wu et al., 2022, Babichenko et al., 2022]. We also discuss the comparison between our paper and that of Gan et al. [2023] on robust Stackelberg games. ", "page_idx": 3}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our model builds on the classic Bayesian persuasion model with a single sender and a single receiver. At a high level, the model formalizes a scenario where the sender, possessing private information about the true state, aims to influence the receiver\u2019s decision-making by strategically sending partial information about the true state according to a pre-committed signaling scheme. We start by introducing the basic setting and notations, and then introduce the robust Bayesian persuasion model that considers a receiver who acts not exactly, but approximately in accordance with their best interest in the decision-making process. ", "page_idx": 3}, {"type": "text", "text": "2.1 Bayesian persuasion: the classical model ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Basic setting and notations. Let $\\Omega$ be the states of the world with $|\\Omega|=m$ , and $\\Delta(\\Omega)$ be the set of all probability distributions on $\\Omega$ . For all distributions $\\mu\\in\\Delta(\\Omega)$ , let $\\mathsf{s u p p}(\\mu)$ be the support of $\\mu$ , i.e., ${\\mathsf{s u p p}}(\\mu)\\triangleq\\{\\omega\\in\\Omega\\mid\\mu(\\omega)>0\\}$ . We use $\\mu_{0}\\in\\Delta(\\Omega)$ to denote the prior distribution over states and assume that $\\mu_{0}$ is common knowledge between the sender and the receiver. ", "page_idx": 3}, {"type": "text", "text": "Signaling scheme. Let $\\Sigma$ $\\mathrm{\\Delta}[\\Sigma]<\\infty)$ be a finite set of signals. A signaling scheme $\\varphi:\\Omega\\rightarrow\\Sigma$ is a randomized mapping from the states of the world to probability distributions over signals. In the Bayesian persuasion protocol, the sender first commits to a signaling scheme $\\varphi$ , then observes the true state of the world $\\omega\\,\\sim\\,\\mu_{0}$ , and sends signal $\\sigma\\sim\\varphi(\\omega)$ to the receiver. We use $\\varphi(\\omega,\\sigma)$ to denote the probability of sending signal $\\sigma$ conditioning on observing $\\omega$ as the true state, and $\\begin{array}{r}{\\varphi(\\sigma)=\\sum_{\\omega^{\\prime}\\in\\Omega}\\mu_{0}(\\omega^{\\prime})\\bar{\\varphi}(\\omega^{\\prime},\\sigma)}\\end{array}$ to denote the marginal probability of a signal $\\sigma\\in\\Sigma$ being realized. ", "page_idx": 3}, {"type": "text", "text": "Upon receiving the signal $\\sigma$ , the receiver performs a Bayes update on $\\mu_{0}$ using knowledge about the scheme $\\pi$ to obtain a posterior belief $\\mu_{\\sigma}\\bar{\\in}\\Delta(\\Omega)$ , i.e., ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mu_{\\sigma}(\\omega)=\\frac{\\mu_{0}(\\omega)\\varphi(\\omega,\\sigma)}{\\varphi(\\sigma)}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In addition, algebraic manipulations based on the Bayes\u2019 rule suggest that the signaling scheme $\\varphi$ can be viewed as the process of creating a distribution over posterior distributions that satisfy the Bayes plausibility condition [Kamenica and Gentzkow, 2011, Gentzkow and Kamenica, 2016]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall\\omega\\in\\Omega,\\qquad\\mu_{0}(\\omega)=\\sum_{\\omega\\in\\Omega}\\varphi(\\sigma)\\cdot\\mu_{\\sigma}(\\omega).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Throughout this paper, we will frequently adopt this perspective, especially in the characterization of (robust) utilities. ", "page_idx": 3}, {"type": "text", "text": "Utilities and best response sets Although only the receiver can take actions, their action influences both the sender and the receiver\u2019s utility, both of which also depend on the state of the world. Let $\\boldsymbol{\\mathcal{A}}$ be the action space of the receiver with $\\left|{\\mathcal{A}}\\right|=n$ . We use $s:\\Omega\\times A\\rightarrow[0,1]$ to denote the sender\u2019s utility and $r:\\bar{\\Omega}\\times\\mathcal{A}\\rightarrow[0,1]$ to denote the receiver\u2019s utility, where both utilities are normalized to be between 0 and 1. Additionally, for distributions $\\mu\\in\\Delta(\\Omega)$ , we abuse the notations and use $s(\\mu,a)=\\mathbb{E}_{\\omega\\sim\\mu}\\,s(\\omega,a)$ and $r(\\mu,a)=\\mathbb{E}_{\\omega\\sim\\mu}\\,r(\\omega,a)$ to denote the sender and receiver\u2019s expected utilities under the state distribution $\\mu$ . ", "page_idx": 3}, {"type": "text", "text": "Receiver\u2019s strategies A receiver\u2019s strategy, denoted with $\\rho:\\Sigma\\rightarrow A$ , is a (possibly randomized) mapping from the observed signals to actions which specifies the receiver\u2019s strategy of choosing responses. Given a signaling scheme $\\varphi$ and a receiver strategy $\\rho$ , we use $S(\\varphi,\\rho)$ to denote the expected sender utility, which is computed as ", "page_idx": 4}, {"type": "equation", "text": "$$\nS(\\varphi,\\rho)\\triangleq\\sum_{\\sigma\\in\\Sigma}\\varphi(\\sigma)\\cdot s(\\mu_{\\sigma},\\rho(\\sigma))=\\sum_{\\omega\\in\\Omega}\\sum_{\\sigma\\in\\Sigma}\\mu_{0}(\\omega)\\varphi(\\omega,\\sigma)s(\\omega,\\rho(\\sigma)).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The classical model of Bayesian persuasion assumes that the receiver\u2019s strategy $\\rho(\\sigma)$ is always the exact best response of the posterior distribution $\\mu_{\\sigma}$ that maximizes their expected posterior utility (ties are broken in favor of the sender). Formally, the best response action action is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\na^{\\star}(\\mu_{\\sigma})\\triangleq\\operatorname*{argmax}_{a\\in\\mathcal{A}}r(\\mu_{\\sigma},a),^{1}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and the receiver\u2019s strategy is assumed to satisfy $\\rho(\\sigma)=a^{\\star}(\\mu_{\\sigma})$ . In this paper, we will relax this exact best-response assumption to allow for approximate best responses. ", "page_idx": 4}, {"type": "text", "text": "2.2 Robust Bayesian persuasion with approximate best responses ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this paper, we allow for some degree of suboptimality in the receiver\u2019s response. Specifically, we assume that the expected utility under receiver\u2019s response $\\rho(\\sigma)$ is not too suboptimal compared to the best action $a^{\\star}\\bigl(\\mu_{\\sigma}\\bigr)$ . Formally, if we use $\\mathsf{B R}_{\\delta}(\\cdot)$ to denote the set of $\\delta$ -optimal responses on the input belief: ", "page_idx": 4}, {"type": "equation", "text": "$$\n{\\mathsf{B R}}_{\\delta}(\\mu)\\triangleq\\left\\{a\\in{\\mathcal{A}}\\mid r(\\mu,a)>r(\\mu,a^{\\star}(\\mu))-\\delta\\right\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "then a receiver\u2019s strategy $\\rho:\\Sigma\\rightarrow A$ is $\\delta$ -best response (or $\\delta$ -BR) if it satisfies $\\rho(\\sigma)\\in\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})$ for all $\\sigma\\in\\Sigma$ . We use $\\mathfrak{B R}_{\\delta}(\\varphi)$ to denote the set of all $\\delta$ -BR strategies under the signaling scheme $\\varphi$ . ", "page_idx": 4}, {"type": "text", "text": "Robust sender utility In this paper, we adopt the max-min adversarial robustness perspective and aim to offer robustness guarantees against worst-case $\\delta$ -BR strategies. We use the robust utility ${\\widehat{S}}_{\\delta}$ of a signaling scheme to characterize the expected utility under the worst-case $\\delta$ -BR strategy: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}(\\varphi)=\\operatorname*{min}_{\\rho_{\\delta}\\in\\mathfrak{B R}_{\\delta}(\\varphi)}S(\\varphi,\\rho_{\\delta}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The sender aims to maximize the robust utility through optimizing the signaling scheme. Equivalently, the sender faces a bi-level optimization problem of the following max-min form: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}^{\\star}\\triangleq\\operatorname*{max}_{\\varphi^{\\star}}\\widehat{S}_{\\delta}(\\varphi^{\\star})=\\operatorname*{max}_{\\varphi^{\\star}}\\operatorname*{min}_{\\rho_{\\delta}\\in\\mathfrak{B R}_{\\delta}(\\varphi^{\\star})}S(\\varphi^{\\star},\\rho_{\\delta}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Solving the optimization problem in (sender\u2019s objective) includes (1) finding an appropriate signal space $\\Sigma$ that is sufficient to achieve the optimal utility and (2) optimizing for the optimal signaling scheme given the signal space. ", "page_idx": 4}, {"type": "text", "text": "Remark 2.1 (worst-case $\\delta$ -BR strategy). It is not hard to see that the worst-case $\\delta$ -BR strategy $\\rho_{\\delta}$ that achieves (sender\u2019s objective) will choose the worst action that minimizes the sender\u2019s utility for each posterior distribution separately, i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\rho_{\\delta}(\\sigma)\\in\\underset{a\\in\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})}{\\mathrm{argmin}}\\,s(\\mu_{\\sigma},a).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Therefore, the robust utility under any signaling scheme $\\varphi$ can be equivalently written as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}(\\varphi)=\\sum_{\\sigma\\in\\Sigma}\\varphi(\\sigma)\\cdot s(\\mu_{\\sigma},\\rho_{\\delta}(\\sigma))=\\sum_{\\sigma\\in\\Sigma}\\varphi(\\sigma)\\cdot\\operatorname*{min}_{a\\in\\mathrm{BR}_{\\delta}(\\mu_{\\sigma})}s(\\mu_{\\sigma},a).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Remark 2.2 (Strict inequality in definition of $\\mathsf{B R}_{\\delta}$ set). In eq. (1), we use strict inequality so that the sender\u2019s strategy space is closed and compact, and the sender\u2019s objective is well-defined. This is $a$ non-essential choice: one could instead define $\\delta$ -BR responses using weak inequality and investigate the sender $\\dot{\\boldsymbol{s}}_{s}$ supremum robust utility, which would not change the nature of the problem. ", "page_idx": 4}, {"type": "text", "text": "3 LP formulation and algorithm with small action spaces ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As we show in Appendix B, the powerful revelation principle fails in the robustness model that we study. In fact, we establish the following claim. ", "page_idx": 5}, {"type": "text", "text": "Proposition 3.1 (Proposition B.1 in Appendix B). There exists a sequence of Bayesian persuasion instances with a robustness level $\\delta=\\Theta(1)$ , such that the following holds in the limit: any directrevelation scheme $\\varphi$ is suboptimal, at least by a factor of 2 or an additive gap of $\\frac{1}{2}$ . That is, for any direct-revelation scheme $\\varphi$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}(\\varphi)\\leq\\frac{1}{2}\\widehat{S}_{\\delta}^{\\star},\\quad a n d\\quad\\widehat{S}_{\\delta}(\\varphi)\\leq\\widehat{S}_{\\delta}^{\\star}-\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The above proposition highlights the need for new algorithmic ideas to efficiently compute (approximately) optimal robust schemes. ", "page_idx": 5}, {"type": "text", "text": "In this section, we present a linear program (LP) that computes the optimal robust utility ${\\widehat{S}}_{\\delta}^{\\star}$ and the optimal robust signaling scheme $\\varphi^{\\star}$ . Although the high-level idea is similar to the LP form ulation for computing the optimal non-robust scheme in standard Bayesian persuasion [Dughmi and Xu, 2016, Dughmi, 2017], our robust LP formulation follows significantly different semantics. ", "page_idx": 5}, {"type": "text", "text": "We characterize the maximum number of signals needed to achieve the optimal robust utility in Lemma 3.2. This lemma can be viewed as a generalized (and unfortunately, much less powerful due to lack of best responses) version of the revelation-principle style argument in [Kamenica and Gentzkow, 2011, Proposition 1] that accounts for worst-case approximate best responses. See Appendix $\\mathbf{C}$ for the proof of the lemma. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.2. There exists an optimal robust signaling scheme that is supported on at most $n\\cdot2^{n-1}$ signals, in which each signal $\\sigma\\in\\Sigma$ corresponds to a unique pair of $(A,{\\tilde{a}})$ such that $\\tilde{\\boldsymbol{a}}=\\boldsymbol{a}^{\\star}(\\mu_{\\sigma})$ and $A=\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})$ . ", "page_idx": 5}, {"type": "text", "text": "According to Lemma 3.2, it suffices to consider the following signal space: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Sigma=\\{(A,\\tilde{a})\\mid A\\subseteq\\mathcal{A},\\;\\tilde{a}\\in A\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where each signal $\\sigma=(A,\\tilde{a})$ satisfies both $a^{\\star}(\\mu_{\\sigma})=\\tilde{a}$ and $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})=A$ . Recall from Remark 2.1 that the robust utility can be written as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}^{\\star}=\\operatorname*{max}_{\\varphi}\\sum_{(A,\\tilde{a})\\in\\Sigma}\\varphi((A,\\tilde{a}))\\cdot\\operatorname*{min}_{a\\in\\mathrm{BR}_{\\delta}(\\mu_{(A,\\tilde{a})})}s(\\mu_{(A,\\tilde{a}},a).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Translating this max-min optimization to a constrained maximization problem, and enforcing the abovementioned semantics for each signal, we arrive at the following (non-linear) program in Fig. 1. Although the program in Fig. 1 is not yet a linear program, both the first and second constraints can ", "page_idx": 5}, {"type": "table", "img_path": "9B0iOkn3UP/tmp/5d06fb1585617ed958597b7a03a08766e2d06e77d489201e498d678fa762cc54.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 1: A program for the optimal robust signaling scheme supported on $\\Sigma=\\{(A,\\tilde{a})\\}$ . ", "page_idx": 5}, {"type": "text", "text": "be equivalently written as linear constraints on the conditional probabilities $\\varphi(\\omega,(A,\\tilde{a}))$ that define the signaling scheme $\\varphi$ , using the following observation based on the Bayes\u2019 rule: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\forall\\sigma\\in\\Sigma,\\quad\\varphi(\\mu_{\\sigma})\\cdot s(\\mu_{\\sigma},a)=\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\sigma)\\cdot s(\\omega,a).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Therefore, it remains to characterize the $\\delta$ -BR response sets, and would be ideal if they could also be equivalently expressed as linear constraints. Unfortunately, the definition of $\\delta$ -BR sets involves strictinequality constraints due to the issues discussed in Remark 2.2. In particular, for each $(A,\\tilde{a})\\in\\Sigma$ , the third constraint is equivalent to ", "page_idx": 5}, {"type": "equation", "text": "$$\n(1)\\;\\forall a\\in A,\\;s(\\mu_{\\sigma},a)>s(\\mu_{\\sigma},\\tilde{a})-\\delta;\\;\\;\\;(2)\\;\\forall a\\in A\\;\\backslash\\;A,\\;s(\\mu_{\\sigma},a)\\leq s(\\mu_{\\sigma},\\tilde{a})-\\delta,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where (1) involves a strict inequality and could lead to open polytopes. Due to such subtleties, we first consider the LP in Fig. 2 which is a relaxation of the program in Fig. 1 by dropping the strict-inequality constraint (1). The last two constraints in Fig. 1 guarantee that variables $\\varphi(\\omega,A,\\tilde{a})$ give rise to a valid signal distribution for every state $\\omega\\in\\Omega$ . ", "page_idx": 6}, {"type": "image", "img_path": "9B0iOkn3UP/tmp/57e88018ad21f2eef060b18e4e9ff9ef98409ab889d1f968bc7b357494e93da7.jpg", "img_caption": ["Figure 2: Relaxed LP for the optimal robust signaling scheme "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Since Fig. 2 is a relaxation of the original program, its optimal objective provides an upper bound for ${\\widehat{S}}_{\\delta}^{\\star}$ . However, as we will show later, not only does the optimal objective value exactly equal ${\\widehat{S}}_{\\delta}^{\\star}$ , but the optimal variables $\\varphi^{\\star}$ also exactly characterize the optimal robust signaling scheme that achieves this $\\hat{\\widehat{S}}_{\\delta}^{\\star}$ . This gives us an algorithm that efficiently computes the optimal robust signaling scheme whe n the number of action spaces is constant or polynomial. We formalize this in Proposition 3.3, and provide a proof in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "Proposition 3.3 (Efficient algorithm for small action space). The optimal robust signaling scheme can be computed by the linear program in Fig. 2 with size $O(2^{n}m n)$ . ", "page_idx": 6}, {"type": "text", "text": "4 Efficient algorithm with small state spaces ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we focus on the robust persuasion instances where the action space is large, but the state space is small. For such instances, our key observation is that among the $(n-1)2^{n}$ tuples in $\\Sigma$ , only a small fraction of them can be realized by posterior distributions and therefore serve as feasible signal candidates. In Section 4.1, we characterize the structural properties of feasible tuples $(A,{\\tilde{a}})\\in{\\bar{\\Sigma}}$ and draw connection to the polytopes in the simplex supported on the state space. In Section 4.2, we leverage these structural insights and design an efficient algorithm that accelerates the computation of the optimal robust signaling scheme. ", "page_idx": 6}, {"type": "text", "text": "4.1 Structural properties ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We formally define the feasibility of a candidate tuple $(A,\\tilde{a})\\in\\Sigma$ according to the existence of a posterior distribution that has $A$ as its $\\delta$ -BR set and $\\tilde{a}$ as its best response action. ", "page_idx": 6}, {"type": "text", "text": "Definition 4.1 (Feasible subset-action tuple). A tuple $(A,\\tilde{a})\\,\\in\\,\\Sigma$ is feasible if there exists some posterior distribution $\\mu\\in\\Delta(\\Omega)$ such that $a^{\\star}(\\mu)=\\tilde{a}$ and $\\mathsf{B R}_{\\delta}(\\mu)=A$ . We use $\\Sigma^{\\dagger}$ to denote the set of all feasible tuples in $\\Sigma$ . ", "page_idx": 6}, {"type": "text", "text": "For each feasible tuple $(A,\\tilde{a})\\in\\Sigma^{\\dagger}$ , let $\\Delta_{(A,\\tilde{a})}$ be the set of posterior distributions that satisfy both constraints in Definition 4.1: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Delta_{(A,\\tilde{a})}\\triangleq\\{\\mu\\in\\Delta(\\Omega)\\,\\mid a^{\\star}(\\mu)=\\tilde{a},\\,\\mathsf{B}\\mathsf{R}_{\\delta}(\\mu)=A\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "It is not hard to see that the subsets $\\Delta_{(A,\\tilde{a})}$ partitions the simplex, because each distribution in the simplex is associated with a unique best response action and $\\delta$ -BR set. That is, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Delta(\\Omega)=\\bigcup_{(A,\\tilde{a})\\in\\Sigma^{\\dagger}}\\Delta_{(A,\\tilde{a})}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In addition, each $\\Delta_{(A,\\tilde{a})}$ is a polytope in the simplex that is defined by the following constraints that are linear in the distribution $\\mu$ : ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mu\\in\\Delta_{(A,\\tilde{a})}\\iff\\left\\{\\!\\!\\!\\begin{array}{l l}{r(\\mu,a)\\leq r(\\mu,\\tilde{a}),}&{\\forall a\\in A;}\\\\ {r(\\mu,a)>r(\\mu,\\tilde{a})-\\delta,}&{\\forall a\\in A;}\\\\ {r(\\mu,a)\\leq r(\\mu,\\tilde{a})-\\delta,}&{\\forall a\\in A\\setminus a.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Our key observation is that the linear constraints that characterize different $\\Delta_{(A,\\tilde{a})}$ all take one of the following two forms based on an ordered pair of actions $(a,a^{\\prime})\\in\\mathcal{A}\\times\\mathcal{A}$ : ", "page_idx": 7}, {"type": "text", "text": "which give rise to no more than $2n^{2}$ hyperplanes. Although the number of hyperplanes scales with the potentially large number of actions, when the state space is small, these hyperplanes, and the polytopes they define, all live within a low-dimensional space. According to a fundamental theorem in computational geometry (see, e.g., Theorem 28.1.1 in [Halperin and Sharir, 2017]), these hyperplanes cut the $m$ -dimensional into at most $O$ $)\\left((2n^{2})^{m-1}\\right)$ cells. This observation helps us to bound the number of feasible tuples in the following lemma. The proof of Lemma 4.2 is deferred to Appendix D.2. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.2. The size of the feasible tuples $\\Sigma^{\\dagger}$ satisfy $|\\Sigma^{\\dagger}|\\leq\\operatorname*{min}\\left\\{n2^{n-1},n^{O(m)}\\right\\}\\!.$ ", "page_idx": 7}, {"type": "text", "text": "Next, we establish some structural properties on the set of feasible tuples $\\Sigma^{\\dagger}$ that could facilitate the efficient search over candidate signals. In the remainder of this section, we first define a boundeddegree symmetric difference graph on all tuples in $\\Sigma$ , then show that all feasible tuples in $\\Sigma^{\\dagger}$ form a connected component in the symmetric difference graph. ", "page_idx": 7}, {"type": "text", "text": "Definition 4.3 (Symmetric difference graph). In the symmetric difference graph $G(\\Sigma,E)$ , each vertex is a tuple $(A,\\tilde{a})\\in\\Sigma$ . Each edge $\\bigl\\{(A_{1},\\tilde{a}_{1}),(A_{2},\\tilde{a}_{2})\\bigr\\}\\,\\in\\,\\dot{E}$ represents that the symmetric difference between tuples $(A_{1},{\\tilde{a}}_{1})$ and $(A_{2},\\tilde{a}_{2})$ is of size 1, which is satisfied for the following two cases: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\tilde{a}_{1}=\\tilde{a}_{2}\\in A_{1}\\cap A_{2},\\,a n d\\,|(A_{1}\\setminus A_{2})\\cup(A_{2}\\setminus A_{1})|=1.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The symmetric difference graph $G$ characterizes the structural relationship between tuples in $\\Sigma$ , in which only any two tuples are connected if and only if their symmetric difference is small enough. Together with the following lemma, $G$ provides a useful framework for us to search within the exponentially large vertex set. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.4 (Connectivity). The subgraph of $G$ induced by $\\Sigma^{\\dagger}$ is connected. ", "page_idx": 7}, {"type": "text", "text": "We defer the proof of Lemma 4.4 to Appendix D.1. At a high level, the proof translates the connectivity of the polytopes $\\Delta_{(A,\\tilde{a})}$ in the simplex space to the connectivity of feasible tuples in the symmetric distance graph $G$ by analyzing the geometric properties of the common face of shared by every pair of adjacent polytopes. ", "page_idx": 7}, {"type": "text", "text": "4.2 Algorithm ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we present Algorithm 1 that leverages the connectivity of the feasible tuples to efficiently search for $\\Sigma^{\\dagger}$ . This algorithm essentially performs depth-first-search (DFS) on the connectivity graph by recursively searching all the neighbors with symmetric difference of size 1 to the given tuple that it\u2019s currently searching. The initial tuple to start the EXPLORE procedure can be set to any tuple that is already known to be feasible, e.g., the $\\delta$ -BR set and the optimal response associated with the prior distribution $\\mu_{0}$ . ", "page_idx": 7}, {"type": "text", "text": "Note that each tuple $(A,\\tilde{a})\\;\\in\\;\\Sigma$ is feasible if and only if there exists $\\mu\\,\\in\\,\\Sigma$ that satisfies all three constraints in Equation (3) simultaneously, which can be written as checking the feasibility of the corresponding LP (with strict-inequality constraints) on the distributions $\\pmb{\\mu}$ . To replace strict-inequality constraints with non-strict constraints, we propose to check the LP via a marginmaximization trick in Fig. 4 of Appendix D.3. This LP is defined on a closed polytope, and asserts feasibility if and only if the optimal margin is strictly positive, i.e., $\\varepsilon^{\\star}>0$ . ", "page_idx": 7}, {"type": "text", "text": "Algorithm 1: EXPLORE   \nInput: tuple $(A,{\\tilde{a}})\\in\\Sigma$   \n1 Check the feasibility of $(A,{\\tilde{a}})$ by solving the LP in Fig. 4, $\\varepsilon^{\\star}\\gets$ optimal objective value;   \n2 if $\\varepsilon^{\\star}>0$ then   \n3 Mark $(A,{\\tilde{a}})$ checked and feasible;   \n4 for actions $a\\in A\\setminus\\{\\tilde{a}\\}$ do   \n5 If $(A\\setminus\\{a\\},\\tilde{a})$ is unchecked, call EXPLORE $\\langle(A\\setminus\\{a\\},\\tilde{a}))$ ;   \n6 If $(A,a)$ is unchecked, call EXPLORE $((A,a))$ );   \n7 end   \n8 for actions $a\\in A\\setminus A$ do   \n9 If $(A\\cup\\{a\\},\\tilde{a})$ is unchecked, call EXPLORE $\\langle A\\cup\\{a\\},\\tilde{a})\\rangle$ ;   \n10 end   \n11 end   \n12 else   \n13 Mark $(A,{\\tilde{a}})$ checked and infeasible   \n14 end ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.5. Running Algorithm 2 with initial tuple $(\\mathsf{B R}_{\\delta}(\\mu_{0}),a^{\\star}(\\mu_{0}))$ finds all feasible tuples $\\Sigma^{\\dagger}\\subseteq\\Sigma$ by solving at most $n^{O(m)}$ LPs, each of size $O(m+n)$ . ", "page_idx": 8}, {"type": "text", "text": "Proof. The correctness of this algorithm is ensured by the connectivity property in Lemma 4.4. It remains to upper bound the number of feasibility checks performed. Since Algorithm 1 only checks new a vertex when it has not been checked before, the total number of feasibility checks is upper bounded by the size of the closed neighborhood of $\\Sigma^{\\dagger}$ . Since each tuple $(A,{\\tilde{a}})\\in\\Sigma$ has at most $O(n)$ neighbors, the degree of any vertex in the symmetric difference graph $G$ is upper bounded by $O(n)$ . Therefore, the size of the closed neighborhood is at most $O(n)\\cdot|\\Sigma^{\\dagger}|\\leq n^{O(m)}$ . \u53e3 ", "page_idx": 8}, {"type": "text", "text": "The final step for optimizing signaling schemes is to solve the LP in Fig. 2 with the original signal space $\\Sigma$ replaced by feasible tuples $\\bar{\\Sigma}^{\\dagger}$ . We summarize the entire procedure and its complexity in Algorithm 2 and Corollary 4.6. ", "page_idx": 8}, {"type": "text", "text": "Corollary 4.6. When the number of states m is small, the optimal signaling scheme can be efficiently computed by Algorithm 2, which involves solving $n^{O(m)}$ LPs of size $O(m+n)$ and then solve a single $L P$ of size $m\\cdot n^{O(m)}$ . ", "page_idx": 8}, {"type": "table", "img_path": "9B0iOkn3UP/tmp/782c1a43f06486c8d7e567f5efc0954e5a91f20fe794008456b9d704f73951a9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "5 Approximation algorithm for the general problem ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we first show that the general problem without any restrictions is computationally hard, then present a quasi-polynomial time approximation scheme (QPTAS) for the problem. The following claim (proof defered to Appendix E) establishes the computational hardness of finding the exact optimal robust signaling scheme. This result implies that a polynomial-time exact algorithm for the robust persuasion problem does not exist unless ${\\mathsf{P}}={\\mathsf{N P}}$ . ", "page_idx": 8}, {"type": "text", "text": "Theorem 5.1. The problem of computing the exact optimal robust utility is NP-hard. ", "page_idx": 8}, {"type": "text", "text": "In the following, we present a QPTAS that computes an $\\varepsilon$ -approximate optimal $\\delta$ -robust signaling scheme $\\widehat{\\varphi}$ for any given $\\delta>0$ , such that ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}(\\widehat{\\varphi})\\geq\\widehat{S}_{\\delta}^{\\star}-\\varepsilon.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Our $\\delta$ -optimal signaling scheme is supported on a significantly different signal space compared to the optimal schemes for cases of small state space and small action space. The high-level idea is, instead of enumerating each $(\\mathsf{B R}_{\\delta}(\\mu),a^{\\star}(\\mu))$ set, we partition the simplex $\\Delta(\\Omega)$ into small cells, each centered around a $k$ -uniform distribution $\\overline{{\\mu}}$ (to be defined later), and incorporate additional semantics to ensure that the utility proflies $s(\\overline{{\\mu}},\\cdot)$ are representative enough for all distributions within this cell. It is useful to have the utilities at $\\overline{{\\mu}}$ being representative because we can then determine the $\\delta$ -BR sets according to the relative magnitude of utilities at $\\overline{{\\mu}}$ and translate the requirements into linear constraints. ", "page_idx": 9}, {"type": "text", "text": "Formally, for an integer $k$ , a distribution $\\mu\\in\\Delta(\\Omega)$ is $k$ -uniform if $\\forall\\omega\\in\\Omega$ , $\\begin{array}{r}{\\mu(\\omega)=\\frac{k_{\\omega}}{k}}\\end{array}$ for some integer $k_{\\omega}\\leq k$ . Let $\\mathcal{G}_{k}\\subseteq\\Delta(\\Omega)$ denote the set of all $k$ -uniform distributions on the state space. We have $|\\mathcal{G}_{k}|=O(m^{k})$ . Moreover, by [Alth\u00f6fer, 1994], for $\\begin{array}{r}{k_{\\varepsilon}=\\left\\lceil\\frac{\\log(2n)}{2\\varepsilon^{2}}\\right\\rceil}\\end{array}$ , we have: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\forall\\mu\\in\\Delta(\\Omega),\\ \\exists\\overline{{\\mu}}\\in\\mathcal{G}_{k_{\\varepsilon}},\\ \\mathrm{s.t.}\\qquad\\forall a\\in\\mathcal{A},\\ |s(\\mu,a)-s(\\overline{{\\mu}},a)|\\leq\\varepsilon.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Accordingly, we define the $\\varepsilon$ -cell around $\\overline{{\\mu}}\\in\\mathcal G_{k}$ to be ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\mathcal{C}_{\\varepsilon}^{\\overline{{\\mu}}}=\\left\\{\\mu\\in\\Delta(\\Omega):\\,\\forall a\\in\\mathcal{A},\\,\\,|s(\\mu,a)-s(\\overline{{\\mu}},a)|\\leq\\varepsilon\\right\\}.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Note that given $\\varepsilon$ and $\\overline{{\\mu}}$ , $\\mu\\in{\\mathcal{C}}_{\\varepsilon}^{\\overline{{\\mu}}}$ is equivalent to a set of $2n$ linear constraints on $\\mu$ . ", "page_idx": 9}, {"type": "text", "text": "We consider the following signal space: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\widehat{\\Sigma}=\\left\\{(\\overline{{\\mu}},\\tilde{a},a)\\;|\\;\\overline{{\\mu}}\\in\\mathcal{G}_{k_{\\varepsilon^{\\prime}}},\\;\\tilde{a},\\dot{a}\\in A\\right\\},\\qquad\\mathrm{where~}k_{\\varepsilon^{\\prime}}=\\left\\lceil\\frac{\\log(2n)}{2(\\varepsilon^{\\prime})^{2}}\\right\\rceil,\\;\\varepsilon^{\\prime}=\\frac{\\varepsilon}{5}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Define LP variables $\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})$ for each $\\omega\\in\\Omega$ and each signal $(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\,\\in\\,\\widehat{\\Sigma}$ to represent the conditional probabilities of sending that signal. Each signal $\\sigma\\,=\\,(\\overline{{\\mu}},\\tilde{a},\\dot{a})$ is specified by the $k$ - uniform distribution $\\overline{{\\mu}}$ that centers the cell, the best response action $\\tilde{a}$ , and the action $\\dot{a}$ in $\\delta$ -BR set that minimizes the sender\u2019s strategy. The LP is defined in Fig. 3. ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{w\\in\\Omega}\\mu_{0}(\\omega)\\sum_{\\{\\bar{\\pi},\\bar{a},\\bar{a}\\}\\in\\bar{\\Sigma}}\\varphi(\\omega,\\bar{\\pi},\\bar{a},\\dot{a})s(\\omega,\\dot{a})}\\\\ &{\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\bar{\\mu},\\hat{a},\\dot{a})\\cdot\\big(s(\\omega,a)-s(\\overline{{\\mu}},a)+\\varepsilon^{\\prime}\\big)\\geq0\\quad(\\forall a\\in A,\\,\\forall(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\in\\hat{\\Sigma})}\\\\ &{\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\cdot\\big(s(\\omega,a)-s(\\overline{{\\mu}},a)-\\varepsilon^{\\prime}\\big)\\leq0\\quad(\\forall a\\in A,\\,\\forall(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\in\\hat{\\Sigma})}\\\\ &{\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\,(r(\\omega,\\tilde{a})-r(\\omega,a))\\geq0,\\qquad(\\forall a\\in A,\\,\\forall(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\in\\hat{\\Sigma})}\\\\ &{\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\,(r(\\omega,\\tilde{a})-r(\\omega,a)-\\delta)\\geq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\in\\widehat{\\Sigma}}\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})=1}\\\\ &{\\displaystyle\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "equation", "text": "$$\n(\\forall\\omega\\in\\Omega,\\forall(\\overline{{\\mu}},\\widetilde{a},\\dot{a})\\in\\widehat{\\Sigma})\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Intuitively, the first two constraints in Fig. 3 are designed to ensure $\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})}\\in\\mathcal C_{\\varepsilon}^{\\overline{{\\mu}}}$ . The third and fourth constraints describe the semantics of the receiver\u2019s response strategy. Finally, the last two constraints guarantee that $\\varphi$ represents a valid signal distribution on each state. We summarize the guarantee of the QPTAS in Theorem 5.2 and formally prove it in appendix F. ", "page_idx": 9}, {"type": "text", "text": "Theorem 5.2. For any $\\varepsilon>0$ and $\\delta>0$ , the optimal solution to the $L P$ in Fig. 3 is an $\\varepsilon$ -approximate $\\delta$ -robust signaling scheme that is supported on $O\\left(n^{2}m^{\\left\\lceil12.5\\log(2n)/(\\varepsilon^{2})\\right\\rceil}\\right)$ signals. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This material is based upon work supported by the National Science Foundation under Grant No. DMS-1928930 and by the Alfred P. Sloan Foundation under grant G-2021-16778, while Hanrui Zhang was in residence at the Simons Laufer Mathematical Sciences Institute (formerly MSRI) in Berkeley, California, during the Fall 2023 semester. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Ricardo Alonso and Odilon C\u00e2mara. Persuading voters. American Economic Review, 106(11): 3590\u20133605, 2016. ", "page_idx": 10}, {"type": "text", "text": "Ingo Alth\u00f6fer. On sparse approximations to randomized strategies and convex combinations. Linear Algebra and its Applications, 199:339\u2013355, 1994.   \nItai Arieli and Yakov Babichenko. Private Bayesian persuasion. Journal of Economic Theory, 182: 185\u2013217, 2019.   \nRobert J Aumann, Michael Maschler, and Richard E Stearns. Repeated games with incomplete information. MIT press, 1995.   \nYakov Babichenko and Siddharth Barman. Computational aspects of private bayesian persuasion. arXiv preprint arXiv:1603.01444, 2016.   \nYakov Babichenko and Siddharth Barman. Algorithmic aspects of private Bayesian persuasion. In Proceedings of the 8th Innovations in Theoretical Computer Science Conference (ITCS), 2017.   \nYakov Babichenko, Inbal Talgam-Cohen, Haifeng Xu, and Konstantin Zabarnyi. Regret-minimizing bayesian persuasion. Games and Economic Behavior, 136:226\u2013248, 2022.   \nArjada Bardhi and Yingni Guo. Modes of persuasion toward unanimous consent. Theoretical Economics, 13(3):1111\u20131149, 2018.   \nDirk Bergemann and Stephen Morris. Bayes correlated equilibrium and the comparison of information structures in games. Theoretical Economics, 11(2):487\u2013522, 2016.   \nDirk Bergemann and Stephen Morris. Information design: A unified perspective. Journal of Economic Literature, 57(1):44\u201395, 2019.   \nDirk Bergemann and Martin Pesendorfer. Information structures in optimal auctions. Journal of economic theory, 137(1):580\u2013609, 2007.   \nDirk Bergemann, Benjamin Brooks, and Stephen Morris. The limits of price discrimination. American Economic Review, 105(3):921\u2013957, 2015.   \nUmang Bhaskar, Yu Cheng, Young Kun Ko, and Chaitanya Swamy. Hardness results for signaling in bayesian zero-sum and network routing games. In Proceedings of the 17th ACM Conference on Economics and Computation (EC), pages 479\u2013496, 2016.   \nIsabelle Brocas and Juan D Carrillo. Influence through ignorance. The RAND Journal of Economics, 38(4):931\u2013947, 2007.   \nModibo K Camara, Jason D Hartline, and Aleck Johnsen. Mechanisms for a no-regret agent: Beyond the common prior. In Proceedings of the 61st Annual Symposium on Foundations of Computer Science (FOCS), pages 259\u2013270. IEEE, 2020.   \nOzan Candogan. Information design in operations. In Pushing the Boundaries: Frontiers in Impactful OR/OM Research, pages 176\u2013201. INFORMS, 2020.   \nMatteo Castiglioni, Andrea Celli, Alberto Marchesi, and Nicola Gatti. Online bayesian persuasion. Advances in Neural Information Processing Systems (NeurIPS), 33:16188\u201316198, 2020.   \nYiling Chen and Tao Lin. Persuading a behavioral agent: Approximately best responding and learning. arXiv preprint arXiv:2302.03719, 2023.   \nNatalie Collina, Aaron Roth, and Han Shao. Efficient prior-free mechanisms for no-regret agents. arXiv preprint arXiv:2311.07754, 2023.   \nGeoffroy de Clippel and Xu Zhang. Non-bayesian persuasion. Journal of Political Economy, 130 (10):2594\u20132642, 2022.   \nShaddin Dughmi. On the hardness of signaling. In Proceedings of the 55th Annual Symposium on Foundations of Computer Science (FOCS), pages 354\u2013363. IEEE, 2014.   \nShaddin Dughmi. Algorithmic information structure design: a survey. ACM SIGecom Exchanges, 15 (2):2\u201324, 2017.   \nShaddin Dughmi and Haifeng Xu. Algorithmic Bayesian persuasion. In Proceedings of the 48th Annual ACM Symposium on Theory of Computing (STOC), pages 412\u2013425, 2016.   \nPiotr Dworczak and Alessandro Pavan. Preparing for the worst but hoping for the best: Robust (bayesian) persuasion. Econometrica, 90(5):2017\u20132051, 2022.   \nYiding Feng, Chien-Ju Ho, and Wei Tang. Rationality-robust information design: Bayesian persuasion under quantal response. In Proceedings of the 35th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 501\u2013546. SIAM, 2024.   \nJiarui Gan, Minbiao Han, Jibang Wu, and Haifeng Xu. Robust stackelberg equilibria. In Proceedings of the 24th ACM Conference on Economics and Computation (EC), page 735, 2023.   \nMatthew Gentzkow and Emir Kamenica. A rothschild-stiglitz approach to bayesian persuasion. American Economic Review, 106(5):597\u2013601, 2016.   \nDan Halperin and Micha Sharir. Arrangements. In Handbook of discrete and computational geometry, pages 723\u2013762. Chapman and Hall/CRC, 2017.   \nJu Hu and Xi Weng. Robust persuasion of a privately informed receiver. Economic Theory, 72: 909\u2013953, 2021.   \nEmir Kamenica. Bayesian persuasion and information design. Annual Review of Economics, 11: 249\u2013272, 2019.   \nEmir Kamenica and Matthew Gentzkow. Bayesian persuasion. American Economic Review, 101(6): 2590\u20132615, 2011.   \nJon Kleinberg and Eva Tardos. Algorithm design. Pearson Education India, 2006.   \nSvetlana Kosterina. Persuasion with unknown beliefs. Theoretical Economics, 17(3):1075\u20131107, 2022.   \nIlan Kremer, Yishay Mansour, and Motty Perry. Implementing the \u201cwisdom of the crowd\u201d. Journal of Political Economy, 122(5):988\u20131012, 2014.   \nRichard J Lipton, Evangelos Markakis, and Aranyak Mehta. Playing large games using simple strategies. In Proceedings of the 4th ACM Conference on Electronic Commerce, pages 36\u201341, 2003.   \nYishay Mansour, Aleksandrs Slivkins, and Vasilis Syrgkanis. Bayesian incentive-compatible bandit exploration. Operations Research, 68(4):1132\u20131161, 2020.   \nYishay Mansour, Aleksandrs Slivkins, Vasilis Syrgkanis, and Zhiwei Steven Wu. Bayesian exploration: Incentivizing exploration in bayesian games. Operations Research, 70(2):1105\u20131127, 2022.   \nAviad Rubinstein. Honest signaling in zero-sum games is hard, and lying is even harder. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2017.   \nKeith E Schnakenberg. Expert advice to a voting body. Journal of Economic Theory, 160:102\u2013113, 2015.   \nJibang Wu, Zixuan Zhang, Zhe Feng, Zhaoran Wang, Zhuoran Yang, Michael I Jordan, and Haifeng Xu. Sequential information design: Markov persuasion process and its efficient reinforcement learning. In Proceedings of the 23rd ACM Conference on Economics and Computation $(E C)$ , pages 471\u2013472, 2022.   \nHaifeng Xu. On the tractability of public persuasion with no externalities. In Proceedings of the 31st Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 2708\u20132727. SIAM, 2020.   \nChenghan Zhou, Thanh H Nguyen, and Haifeng Xu. Algorithmic information design in multi-player games: Possibilities and limits in singleton congestion. In Proceedings of the 23rd ACM Conference on Economics and Computation (EC), pages 869\u2013869, 2022.   \nYou Zu, Krishnamurthy Iyer, and Haifeng Xu. Learning to persuade on the fly: Robustness against ignorance. In Proceedings of the 22nd ACM Conference on Economics and Computation $(E C)$ , pages 927\u2013928, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Related Works ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Bayesian persuasion. Our paper generalizes the canonical model of Bayesian persuasion for information design that was introduced by the seminal work of Aumann et al. [1995], Kamenica and Gentzkow [2011], Brocas and Carrillo [2007]. This framework has been extended to multi-receiver settings [Bergemann and Morris, 2016, 2019] and supports many important applications, such as voting [Schnakenberg, 2015, Alonso and C\u00e2mara, 2016, Bardhi and Guo, 2018, Wang, 2013, Arieli and Babichenko, 2019], bilateral trades [Bergemann et al., 2015, Bergemann and Pesendorfer, 2007], incentivizing exploration [Mansour et al., 2020, 2022, Kremer et al., 2014], to name a few. We refer the readers to survey papers [Candogan, 2020, Kamenica, 2019] for a comprehensive overview. ", "page_idx": 12}, {"type": "text", "text": "Computational aspects of Bayesian persuasion and information design. Our work examines the computational aspects of Bayesian persuasion, which has gained significant attention since the seminal work of Dughmi and Xu [2016], Dughmi [2017] that study the algorithmic complexity of the sender\u2019s optimization tasks in several natural input models. In the multi-receiver settings, computational challenges are more pronounced, as demonstrated by Dughmi [2014], Bhaskar et al. [2016] who showed the hardness of computing the optimal signaling scheme in Bayesian zero-sum games. In addition, Rubinstein [2017] established the hardness of finding even an approximate solution, revealing that obtaining an $\\epsilon$ -approximate signaling scheme in two-player zero-sum games requires quasi-polynomial time. On the positive side, Babichenko and Barman [2017] studied private persuasion with binary action space and presented an efficient approximation of the optimal signaling scheme. Xu [2020] addressed the tractability of optimizing signaling schemes without externalities between the receiver\u2019s payoffs. Recently, Zhou et al. [2022] studied algorithmic information design of public and private signaling in atomic singleton congestion games, achieving efficient exact optimization of optimal signaling schemes when the number of resources is constant. ", "page_idx": 12}, {"type": "text", "text": "Robust Bayesian persuasion. Recent research on robust Bayesian persuasion has explored various notions to address the uncertainty and robustness in sender-receiver interactions.. The existing literature can be roughly divided into two main approaches: max-min models and faulty receiver models. ", "page_idx": 12}, {"type": "text", "text": "Maximin models consider scenarios in which the sender aims to maximize their worst-case utility under various types of uncertainty. For instance, Dworczak and Pavan [2022] study a two-layer model where the first layer accounts for arbitrary exogenous information receivers may have, including pessimistic scenarios where receivers fully learn the state from exogenous information. The optimization at the second layer assumes a common prior but is constrained to policies that secure the sender\u2019s maximin payoff at the first layer. Kosterina [2022] considers a setting where the sender does know the receiver\u2019s prior belief and assumes that the receiver\u2019s prior can be any distribution that assigns at least a fixed state-dependent probability to each state. Hu and Weng [2021] consider a model where starting from a common prior, the receiver gets a private signal resulting in an arbitrary random belief supported on a given subset of the simplex. They show (1) when the subset is the entire simplex, full revelation is optimal, and (2) when the subset is a small neighborhood of the common prior, the cost of robustness vanishes as the size of the neighborhood vanishes. Babichenko et al. [2022] study a model with binary actions and the receiver\u2019s utility being uncertain. They show that full uncertainty is extremely harmful, while if the sender knows the ordinal preferences of the receiver over states, then there\u2019s a constant additive gap between the maximin strategy and the omniscient one. Chen and Lin [2023] consider a model similar to ours with $\\varepsilon$ -best responding receivers. They present a continuity result that bounds the cost of robustness by $O(\\varepsilon)$ . ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "On the other hand, faulty receiver models usually assume the sender has full knowledge of the receiver\u2019s behavioral model, often incorporating bounded rationality or non-standard Bayesian updates. Feng et al. [2024]study the bounded rationality model through quantal response, which is a smoothed version of exact best response that models mistakes or \u201ctrembling hands\u201d. They focus on binary actions and identify conditions under which the optimal policy against a best-responding receiver remains almost optimal under quantal response. They also construct approximately optimal policies oblivious to the level of bounded rationality. de Clippel and Zhang [2022] consider \u201cnonBayesian\u201d updates by the receiver according to an arbitrary but fixed rule. They provide structural results and rankings of updating rules in terms of both the sender\u2019s and receiver\u2019s utilities. These works differ from ours in that they assume the sender has full knowledge about the receiver\u2019s fixed response rule, whereas in our setting, the sender must anticipate worst-case responses from a set of approximate best responses. ", "page_idx": 13}, {"type": "text", "text": "Comparison with [Gan et al., 2023]. Another closely related work is that of Gan et al. [2023] which studies the computational complexity of robust Stackelberg equilibria under approximate best responses. While Stackelberg games provide a more general model for principal-agent interactions, the computational complexity results in [Gan et al., 2023] are not directly applicable to Bayesian persuasion due to differences in problem representation. Specifically, Bayesian persuasion instances are typically represented in a more compact form than the \u201cflat\u201d representation used for Stackelberg games, where principal\u2019s strategy space includes all feasible signaling schemes. This distinction limits the direct application of algorithms from Gan et al. [2023] to Bayesian persuasion by framing it as a Stackelberg game instance. ", "page_idx": 13}, {"type": "text", "text": "There are also important algorithmic differences between Stackelberg games and Bayesian persuasion. In Stackelberg games, the search space is constrained to the simplex of probability distributions over the principal\u2019s action set. In contrast, in Bayesian persuasion, the search space for signaling schemes is not pre-defined as it requires constructing a signal space, making the design of signal spaces an important part of the problem. Our paper introduces algorithmic techniques specifically designed for Bayesian persuasion that achieves a complexity of $\\mathrm{poly}(n^{O(m)})$ when the state space size $m$ is small. In comparison, approaches in Gan et al. [2023] result in a complexity exponential in $n$ . ", "page_idx": 13}, {"type": "text", "text": "B Failure of revelation principle ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In classical Bayesian persuasion problem where receivers always best respond, an argument via the revelation principle (see, e.g., [Kamenica and Gentzkow, 2011, Proposition 1]) shows that it suffices to consider direct revelation schemes that give direct recommendations of which actions to play. This argument implies that without loss of generality, the number of signals needed is at most the number of actions. However, in this section, we will show that when robustness enters the picture, direct revelation schemes fail even to achieve any nontrivial approximation ratios of the optimal robust utility. Indeed, similar phenomenons were observed by Gan et al. [2023] in the context of Stackelberg games. As they argue, the absence of the revelation principle in their setting makes the respective problems more challenging, which is also what happens in our model. ", "page_idx": 13}, {"type": "text", "text": "Below we present a simple example with 3 states and 2 actions where direct revelation schemes fail to match the optimal utility with any nontrivial approximation factor. ", "page_idx": 13}, {"type": "text", "text": "Proposition B.1 (Suboptimality of direct-revelation schemes). There exists a sequence of Bayesian persuasion instances with a robustness level $\\delta=\\Theta(1).$ , such that the following holds in the limit: any direct-revelation scheme $\\varphi$ is suboptimal, at least by a factor of 2 or an additive gap of $\\frac{1}{2}$ . That is, for any direct-revelation scheme $\\varphi$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}(\\varphi)\\leq\\frac{1}{2}\\widehat{S}_{\\delta}^{\\star},\\quad a n d\\quad\\widehat{S}_{\\delta}(\\varphi)\\leq\\widehat{S}_{\\delta}^{\\star}-\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The claim in Proposition B.1 can be established using the family of robust persuasion instances constructed in Example B.2. The main idea is to create a relatively large robustness level so that disadvantageous actions enter the receiver\u2019s approximate best response set as long as the posterior is a mixed distribution. Therefore, to achieve the optimal robust utility, the sender has to adopt a signaling scheme that deterministically discloses the true state, which requires a signaling space larger than the action space. ", "page_idx": 14}, {"type": "text", "text": "Example B.2. Consider the following family of robust Bayesian persuasion instances parametrized by \u03b5. Every instance in this family has state space $\\Omega=\\{\\omega_{\\perp},\\omega_{0},\\omega_{1}\\}$ and action space $\\boldsymbol{\\mathcal{A}}=\\{a_{0},a_{1}\\}$ . The prior distribution $\\mu_{0}$ puts a very small probability mass on state $\\omega_{\\perp}$ , and divides the rest of the probability mass evenly between $\\omega_{1}$ and $\\omega_{2}$ . Formally, for an infinitesimal $\\varepsilon>0$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mu_{0}(\\omega_{\\perp})=\\varepsilon,\\quad\\mu_{0}(\\omega_{0})=\\mu_{0}(\\omega_{1})=\\frac{1-\\varepsilon}{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The utility functions satisfy $r=s$ , where both the receiver obtains utility 1 if the index of the action matches that of the state (i.e., in the case of $(\\omega_{1},a_{1})$ and $(\\omega_{0},a_{0}).$ ) and 0 otherwise (see Table 1). The approximate best response level is $\\delta=1$ . ", "page_idx": 14}, {"type": "table", "img_path": "9B0iOkn3UP/tmp/4c9ea11d7f164d8651d9fd84a95ee9dfc93858ebdbb714605d7848ce4e3b59ad.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "Table 1: The utility function for both the sender and the receiver. If the state is $\\omega_{\\perp}$ , then both players have 0 utility. Otherwise, both players get utility 1 if and only if the receiver\u2019s action matches the true state. ", "page_idx": 14}, {"type": "text", "text": "Proof of Proposition B.1. In example B.2, the optimal robust utility ${\\widehat{S}}_{\\delta}^{\\star}$ is at least $1-\\varepsilon$ , which can be achieved by a full-revelation signaling scheme $\\varphi^{\\star}$ supported on 3 s ignals. More specifically, $\\varphi^{\\star}$ is a deterministic mapping from $\\Omega$ to a ternary signal space $\\Sigma=\\{\\sigma_{\\bot},\\sigma_{0},\\sigma_{1}\\}$ , such that $\\varphi(\\omega_{i})\\equiv\\sigma_{i}$ for $i\\in\\{\\bot,0,1\\}$ . Since this signaling scheme is deterministic, we have $\\varphi^{\\star}(\\sigma_{i})=\\mu_{0}(\\omega_{i})$ , and each posterior distribution $\\mu_{\\sigma_{i}}$ is the degenerate distribution on $\\omega_{i}$ . They lead to the following approximate best response sets: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathsf{B R}_{\\delta}(\\mu_{\\sigma_{\\perp}})=\\{a_{0},a_{1}\\},\\quad\\mathsf{B R}_{\\delta}(\\mu_{\\sigma_{0}})=\\{a_{0}\\},\\quad\\mathsf{B R}_{\\delta}(\\mu_{\\sigma_{1}})=\\{a_{1}\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, the sender\u2019s robust utility is given by ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\widehat S_{\\delta}(\\varphi^{\\star})=\\displaystyle\\sum_{\\sigma\\in\\Sigma}\\varphi^{\\star}(\\sigma)\\cdot\\operatorname*{min}_{a\\in\\mathtt{B R}_{\\delta}(\\mu_{\\sigma})}s(\\mu_{\\sigma},a)}}\\\\ {{\\mathrm{~}}}\\\\ {{\\qquad=\\mu_{0}(\\omega_{\\bot})\\cdot s(\\mu_{\\sigma_{\\bot}},a_{0})+\\mu_{0}(\\omega_{0})\\cdot s(\\mu_{\\sigma_{0}},a_{0})+\\mu_{0}(\\omega_{1})\\cdot s(\\mu_{\\sigma_{1}},a_{1})}}\\\\ {{\\qquad=\\varepsilon\\cdot0+\\displaystyle\\frac{1-\\varepsilon}{2}\\cdot1+\\displaystyle\\frac{1-\\varepsilon}{2}\\cdot1=1-\\varepsilon.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "On the other hand, we claim that any signaling scheme $\\varphi:\\Omega\\rightarrow\\Sigma$ with $|\\Sigma|=2$ has to suffer a suboptimal utility of $\\widehat{S}_{\\delta}(\\varphi)\\leq\\textstyle\\frac{1-\\varepsilon}{2}$ . To see this, note that if a posterior distribution $\\mu_{\\sigma}$ of a signal $\\sigma\\,\\in\\,\\Sigma$ is supported on more than one state, then the receiver\u2019s utility of the optimal action is at most $\\operatorname*{max}\\{\\bar{\\mu_{\\sigma}}(\\omega_{0}),\\mu_{\\sigma}(\\omega_{1})\\}<1$ , which is smaller than the robustness level $\\delta=1$ . Therefore, any posterior $\\mu_{\\sigma}$ that is a mixed distribution must have $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})=\\{a_{0},a_{1}\\}$ , which implies ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{a\\in\\mathrm{BR}_{\\delta}(\\mu_{\\sigma})}s(\\mu_{\\sigma},a)=\\operatorname*{min}\\left\\{s(\\mu_{\\sigma},a_{0}),s(\\mu_{\\sigma},a_{1})\\right\\}=\\operatorname*{min}\\left\\{\\mu_{\\sigma}(\\omega_{0}),\\mu_{\\sigma}(\\omega_{1})\\right\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Let us denote the two signals in $\\Sigma$ as $\\sigma_{0}$ and $\\sigma_{1}$ . At least one of the posterior distributions $\\mu_{\\sigma_{0}}$ and $\\mu_{\\sigma_{1}}$ has to be supported on $\\geq2$ states because $|\\Omega|=3$ . We have two following cases: ", "page_idx": 14}, {"type": "text", "text": "\u2022 Case 1. Both signals have mixed posteriors. In this case, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}(\\varphi)=\\sum_{\\sigma\\in\\Sigma}\\varphi(\\sigma)\\cdot\\operatorname*{min}_{a\\in\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})}s(\\mu_{\\sigma},a)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\!\\varphi(\\sigma_{0})\\cdot\\operatorname*{min}\\left\\{\\mu_{\\sigma_{0}}(\\omega_{0}),\\mu_{\\sigma_{0}}(\\omega_{1})\\right\\}+\\varphi(\\sigma_{1})\\cdot\\operatorname*{min}\\left\\{\\mu_{\\sigma_{1}}(\\omega_{0}),\\mu_{\\sigma_{1}}(\\omega_{1})\\right\\}}\\\\ &{\\leq\\!\\varphi(\\sigma_{0})\\cdot\\mu_{\\sigma_{0}}(\\omega_{0})+\\varphi(\\sigma_{1})\\cdot\\mu_{\\sigma_{1}}(\\omega_{0})}\\\\ &{=\\!\\mu_{0}(\\omega_{0})\\cdot\\varphi(\\omega_{0},\\sigma_{0})+\\mu_{0}(\\omega_{0})\\cdot\\varphi(\\omega_{0},\\sigma_{1})=\\mu_{0}(\\omega_{0})=\\frac{1-\\varepsilon}{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the last few steps follow from the Bayes\u2019 rule. ", "page_idx": 15}, {"type": "text", "text": "\u2022 Case 2. Only one signal has a mixed posterior. WLOG, assume $\\mu_{\\sigma_{0}}$ is a mixed distribution whereas $\\mu_{\\sigma_{1}}$ is a pure (degenerate) distribution. It is also WLOG to assume that $\\mu_{\\sigma_{1}}$ is a degenerate distribution on $\\omega_{1}$ , because $\\omega_{0}$ and $\\omega_{1}$ are symmetric and $\\omega_{\\perp}$ has 0 utility under both actions. Therefore, we have that $\\sigma_{1}$ is only sent on state $\\omega_{1}$ , and $\\varphi(\\sigma_{1})=\\mu_{0}(\\omega_{1})$ . As for the robust utility, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{S}_{\\delta}(\\varphi)=\\displaystyle\\sum_{\\sigma\\in\\Sigma}\\varphi(\\sigma)\\cdot\\operatorname*{min}_{a\\in\\mathrm{BR}_{\\delta}(\\mu_{\\sigma})}s(\\mu_{\\sigma},a)}\\\\ &{\\qquad\\quad=\\!\\varphi(\\sigma_{0})\\cdot\\operatorname*{min}\\big\\{\\mu_{\\sigma_{0}}(\\omega_{0}),\\mu_{\\sigma_{0}}(\\omega_{1})\\big\\}+\\varphi(\\sigma_{1})\\cdot s(\\omega_{\\sigma_{1}},a_{1})}\\\\ &{\\qquad\\quad=\\!\\varphi(\\sigma_{0})\\cdot0+\\varphi(\\sigma_{1})\\cdot1}\\\\ &{\\qquad\\quad=\\!\\mu_{0}(\\omega_{1})=\\frac{1-\\varepsilon}{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the second-to-last step follows from $\\mu_{\\sigma_{0}}(\\omega_{1})=0$ because $\\sigma_{1}$ is only sent on state $\\omega_{1}$ . ", "page_idx": 15}, {"type": "text", "text": "Combining the two cases above, we arrive at the conclusion that any scheme with two signals has robust utility at most $\\frac{1\\!-\\!\\varepsilon}{2}$ , which is half of the optimal robust utility ${\\widehat{S}}_{\\delta}^{\\star}$ . In addition, we note that $\\begin{array}{r}{\\widehat{S}_{\\delta}^{\\star}-\\widehat{S}_{\\delta}(\\varphi)=\\frac{1-\\varepsilon}{2}}\\end{array}$ and the above analysis holds for any $\\varepsilon>0$ . Therefore, sending $\\varepsilon\\rightarrow0$ proves the $\\frac{1}{2}$ additive gap. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "C Omitted proofs in Section 3 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof of Lemma 3.2. Let $\\Sigma^{\\prime}=\\{(A,\\tilde{a})\\mid A\\subseteq\\mathcal{A},\\,\\tilde{a}\\in A\\}$ . Given any signaling scheme $\\varphi:\\Omega\\rightarrow\\Sigma$ , we use $\\Sigma_{(A,\\tilde{a})}$ to denote the subset of signals $\\sigma\\in\\Sigma$ that lead to the same best response $a^{\\star}=\\tilde{a}$ and the same $\\delta$ -BR set $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})=A$ , i.e., ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Sigma_{(A,\\tilde{a})}=\\{\\sigma\\in\\Sigma\\mid\\sigma\\in\\Sigma:\\ a^{\\star}(\\mu_{\\sigma})=\\tilde{a},{\\sf B R}_{\\delta}(\\mu_{\\sigma})=A\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Consider an alternative signaling scheme $\\varphi^{\\prime}:\\Omega\\rightarrow\\Sigma^{\\prime}$ that merges signals in each subset $\\Sigma_{(A,\\tilde{a})}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\forall(A,{\\tilde{a}})\\in\\Sigma^{\\prime},\\quad\\varphi^{\\prime}(\\omega,(A,{\\tilde{a}}))=\\sum_{\\sigma\\in\\Sigma_{(A,{\\tilde{a}})}}\\varphi(\\omega,\\sigma).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The subsets $\\Sigma_{(A,\\tilde{a})}$ naturally form a partition of the original signal space $\\Sigma$ . ", "page_idx": 15}, {"type": "text", "text": "We first claim that $a^{\\star}\\bigl(\\mu_{(A,\\tilde{a})}\\bigr)\\,=\\,\\tilde{a},\\mathsf{B R}_{\\delta}\\bigl(\\mu_{(A,\\tilde{a})}\\bigr)\\,=\\,A$ . The first claim follows directly from the revelation principle \u2014 since $\\tilde{a}$ is the best response to each $\\sigma\\,\\in\\,\\Sigma_{(A,\\tilde{a})}$ , it must also be the best response to the merged signal. For the second claim, from the Bayes\u2019 rule, the posterior of receiving each signal $(A,{\\tilde{a}})$ under the newly constructed scheme $\\varphi^{\\prime}$ satisfies ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\forall\\omega\\in\\Omega,\\quad\\mu_{(A,\\tilde{a})}(\\omega)=\\frac{\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)\\mu_{\\sigma}(\\omega)}{\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "therefore, for each $a\\in A$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nr(\\mu_{(A,\\tilde{a})},a)=\\frac{\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)r(\\mu_{\\sigma},a)}{\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)}>\\frac{\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)(r(\\mu_{\\sigma},\\tilde{a})-\\delta)}{\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)}=r(\\mu_{(A,\\tilde{a})},\\tilde{a})-\\delta.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Similarly, for each $a\\in A\\setminus A$ , we can conclude that ", "page_idx": 15}, {"type": "equation", "text": "$$\nr(\\mu_{(A,\\tilde{a})},a)\\leq r(\\mu_{(A,\\tilde{a})},\\tilde{a})-\\delta,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The two cases together established the second claim that $\\mathsf{B R}_{\\delta}(\\mu_{(A,\\tilde{a})})=A$ . Finally, for the sender\u2019s utility, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varphi^{\\prime}((A,\\tilde{a}))\\underset{a\\in A}{\\operatorname*{min}}\\,s(\\mu_{(A,\\tilde{a})},a)=\\underset{a\\in A}{\\operatorname*{min}}\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)s(\\mu_{\\sigma},a)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\geq\\displaystyle\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)\\underset{a\\in A}{\\operatorname*{min}}\\,s(\\mu_{\\sigma},a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since the above inequalities hold for any $(A,\\tilde{a})\\in\\Sigma^{\\prime}$ , the robust utility satisfies ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{S}_{\\delta}(\\varphi^{\\prime})=\\displaystyle\\sum_{(A,\\tilde{a})\\in\\Sigma^{\\prime}}\\varphi^{\\prime}((A,\\tilde{a}))\\cdot\\displaystyle\\operatorname*{min}_{a\\in A}s(\\mu_{(A,\\tilde{a})},a)}\\\\ &{\\qquad\\quad\\geq\\displaystyle\\sum_{(A,\\tilde{a})\\in\\Sigma^{\\prime}}\\sum_{\\sigma\\in\\Sigma_{(A,\\tilde{a})}}\\varphi(\\sigma)\\cdot\\varphi(\\sigma)\\operatorname*{min}_{a\\in A}s(\\mu_{\\sigma},a)=\\widehat{S}_{\\delta}(\\varphi),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last step follows since $\\left\\{\\Sigma_{\\left(A,\\tilde{a}\\right)}\\mid\\left(A,\\tilde{a}\\right)\\in\\Sigma^{\\prime}\\right\\}$ forms a partition of $\\Sigma$ . ", "page_idx": 16}, {"type": "text", "text": "We have shown that restricting the signal space to $\\Sigma^{\\prime}=\\{(A,\\tilde{a})\\mid A\\subseteq\\mathcal{A},\\;\\tilde{a}\\in A\\}$ by merging signals never decreases the robust utility. Therefore, there must exist an optimal signaling scheme supported on at most $|\\Sigma^{\\prime}|=n\\cdot2^{n-1}$ signals. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Proof of Proposition 3.3. We use OPT to denote the optimal objective value of Fig. 2, and use $\\varphi^{\\star},x^{\\star}$ to denote the optimal variables that achieve OPT. In addition, let $\\varphi^{\\star}:\\Omega\\rightarrow\\Sigma$ be a signaling scheme induced by the optimal LP variables $\\varphi^{\\star}(\\omega,A,\\tilde{a})$ . Since Fig. 2 is a relaxation of the original problem for computing $\\mathbf{\\widehat{\\boldsymbol{S}}}_{\\delta}^{\\star}$ , we have $\\mathsf{O P T}\\geq\\widehat{S}_{\\delta}^{\\star}$ . Therefore, to establish the optimality of $\\varphi^{\\star}$ , it suffices to show that $\\mathsf{O P T}\\leq\\widehat{S}_{\\delta}(\\varphi^{\\star})$ , because it implies ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\mathsf{O P T}}\\leq\\widehat{S}_{\\delta}(\\varphi^{\\star})\\leq\\operatorname*{max}_{\\varphi}\\widehat{S}_{\\delta}(\\varphi)=\\widehat{S}_{\\delta}^{\\star}\\leq{\\mathsf{O P T}},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "in which all the inequalities must be tight. ", "page_idx": 16}, {"type": "text", "text": "Now we prove $\\mathsf{O P T}\\leq\\widehat{S}_{\\delta}(\\varphi^{\\star})$ . Since the third constraint in Fig. 2 ensures that all actions excluded form $A$ must have suboptimality gap $\\geq\\delta$ , $A$ is an overestimate of the true $\\delta$ -BR set, i.e., $A\\supseteq$ $\\mathsf{B R}_{\\delta}(\\mu_{(A,\\tilde{a})})$ . Therefore, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\hat{S}_{\\delta}(\\varphi^{\\star})=\\sum_{\\scriptstyle(A,\\tilde{\\alpha})\\in\\Sigma}\\varphi^{\\star}(A,\\tilde{\\alpha})\\operatorname*{min}_{\\scriptstyle\\alpha\\in\\mathbb{R}_{\\delta}\\cup\\{\\mu_{(A,\\tilde{\\alpha})},\\,\\delta\\}}s(\\mu_{(A,\\tilde{\\alpha})},a)}}\\\\ &{=\\sum_{\\scriptstyle(A,\\tilde{\\alpha})\\in\\Sigma}\\operatorname*{min}_{\\scriptstyle(\\mu_{(A,\\tilde{\\alpha})})\\atop{\\scriptstyle(A,\\tilde{\\alpha})\\in\\Sigma}}\\sum_{\\scriptstyle(\\alpha\\in\\mathbb{R}_{\\delta}\\cup\\{\\mu_{(A,\\tilde{\\alpha})}\\})\\atop{\\scriptstyle(\\alpha,A,\\tilde{\\alpha})\\in\\Sigma}}\\mu_{0}(\\omega)\\varphi^{\\star}(\\omega,A,\\tilde{\\alpha})s(\\mu_{(A,\\tilde{\\alpha})},a)}\\\\ &{\\ge\\sum_{\\scriptstyle(A,\\tilde{\\alpha})\\in\\Sigma}\\operatorname*{min}_{\\scriptstyle(\\alpha\\in\\Omega)\\in\\pi}\\mu_{0}(\\omega)\\varphi^{\\star}(\\omega,A,\\tilde{\\alpha})s(\\mu_{(A,\\tilde{\\alpha})},a)}&{\\scriptstyle(A\\supseteq\\mathrm{BR}_{\\delta}(\\mu_{(A,\\tilde{\\alpha})}))}\\\\ &{\\ge\\sum_{\\scriptstyle(A,\\tilde{\\alpha})\\in\\Sigma}x^{\\star}(A,\\tilde{\\alpha})}&{\\scriptstyle(\\mathrm{first~constraint~in~Fig.~2})}\\\\ &{=\\mathrm{OPT},}&{\\scriptstyle(\\mathrm{optimality~of~}x^{\\star}(A,\\tilde{\\alpha})\\mathrm{~in~Fig.~2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which completes the proof. ", "page_idx": 16}, {"type": "text", "text": "D Omitted Proofs from Section 4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "D.1 Proof of Lemma 4.4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof. We establish this theorem by showing that any two adjacent polytopes $\\Delta_{(A_{1},\\tilde{a}_{1})},\\Delta_{(A_{2},\\tilde{a}_{2})}$ in the $m$ -dimensional simplex corresponds to neighboring vertices $(A_{1},{\\tilde{a}}_{1})$ and $(A_{2},\\tilde{a}_{2})$ in the symmetric difference graph. Since polytopes $\\Delta_{(A,\\tilde{a})}$ form a partition of the convex simplex $\\Delta(\\Omega)$ , any path through the simplex\u2019s polytopes translates into a connected path in the symmetric difference graph $G$ , therefore establishing the connectivity of the subgraph induced by $\\Sigma^{\\dagger}$ . ", "page_idx": 16}, {"type": "text", "text": "If $\\Delta_{(A_{1},\\tilde{a}_{1})},\\Delta_{(A_{2},\\tilde{a}_{2})}$ are adjacent, they must share a common face, which belongs to a hyperplane in $\\mathcal{H}$ . Consider the following two cases: ", "page_idx": 17}, {"type": "text", "text": "Case 1. If the hyperplane is $\\begin{array}{r}{\\sum_{\\omega\\in\\Omega}\\pmb{\\mu}(\\omega)(r(\\omega,a)-r(\\omega,a^{\\prime}))=0}\\end{array}$ for some pair of actions $(a,a^{\\prime})$ According to the semantics in eq. (3) that defines each polytope, it must be the case that $a,a^{\\prime}$ each corresponds to an action in $\\tilde{a}_{1},\\tilde{a}_{2}$ . WLOG assume $a=\\tilde{a}_{1}$ and $a^{\\prime}=\\tilde{a}_{2}$ . Therefore, to show that $\\{(A_{1},\\dot{\\tilde{a}}_{1}),(A_{2},\\tilde{a}_{2})\\}\\in E$ , it suffices to establish $A_{1}=A_{2}$ . ", "page_idx": 17}, {"type": "text", "text": "Consider two posteriors $\\mu_{1}~\\in~\\Delta_{(A_{1},\\tilde{a}_{1})}$ and $\\mu_{2}~\\in~\\Delta_{(A_{2},\\tilde{a}_{2})}$ such that $\\|\\mu_{1}\\-\\mu_{2}\\|_{1}\\,\\leq\\,\\varepsilon$ for an infinitesimal $\\varepsilon>0$ , and both $\\mu_{1},\\mu_{2}$ have a distance of at least $\\varepsilon_{0}$ from all other hyperplanes in $\\mathcal{H}$ . Such a choice implies ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bullet\\;\\forall a\\in A,\\;|r(\\mu_{1},a)-r(\\mu_{2},a)|\\leq\\|\\mu_{1}-\\mu_{2}\\|_{1}=\\varepsilon.}\\\\ &{\\bullet\\;r(\\mu_{1},\\tilde{a}_{1})-\\operatorname*{min}_{a\\in A_{1}}r(\\mu_{1},a)\\leq\\delta-\\varepsilon_{0},\\,\\mathrm{and}\\,r(\\mu_{2},\\tilde{a}_{2})-\\operatorname*{min}_{a\\in A_{2}}r(\\mu_{2},a)\\leq\\delta-\\varepsilon_{0}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Consider the process of fixing $\\varepsilon_{0}$ and sending $\\varepsilon\\rightarrow0$ . For any $a\\in A_{1}=\\mathsf{B R}_{\\delta}(\\mu_{1})$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r(\\mu_{2},a)\\geq r(\\mu_{1},a)-\\varepsilon\\geq r(\\mu_{1},\\tilde{a}_{1})-(\\delta-\\varepsilon_{0})-\\varepsilon\\geq r(\\mu_{2},\\tilde{a}_{1})-\\delta+\\varepsilon_{0}-2\\varepsilon>r(\\mu_{2},\\tilde{a}_{1})-\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which implies $a\\,\\in\\,\\mathsf{B R}_{\\delta}(\\mu_{2})\\,=\\,A_{2}$ and therefore $A_{1}\\subseteq A_{2}$ . In addition, a symmetric argument implies that $A_{2}\\subseteq A_{1}$ . Therefore, it must be the case that $A_{1}=A_{2}$ . ", "page_idx": 17}, {"type": "text", "text": "Case 2. If the hyperplane is $\\begin{array}{r}{\\sum_{\\omega\\in\\Omega}\\pmb{\\mu}(\\omega)(r(\\omega,a)-r(\\omega,a^{\\prime}))=\\delta}\\end{array}$ for some pair of actions $(a,a^{\\prime})$ . Once again, we can find two posteriors $\\mu_{1}\\in\\Delta_{(A_{1},\\tilde{a}_{1})}$ and $\\mu_{2}\\in\\Delta_{(A_{2},\\tilde{a}_{2})}$ such that $\\|\\mu_{1}-\\mu_{2}\\|_{1}\\leq\\varepsilon$ for an infinitesimal $\\varepsilon>0$ , and both $\\mu_{1},\\mu_{2}$ have a distance of at least $\\varepsilon_{0}$ from all other hyperplanes in $\\mathcal{H}$ . This immediately implies $\\tilde{a}_{1}=\\tilde{a}_{2}$ because otherwise the hyperplane $\\begin{array}{r}{\\sum_{\\omega\\in\\Omega}\\pmb{\\mu}(\\omega)\\bar{(r(\\omega,a_{1})-}}\\end{array}$ $r(\\omega,a_{2}))=0$ will have to separate $\\mu_{1}$ and $\\mu_{2}$ . A similar continuity argument to that in the previous case shows that $a_{1}=a_{2}=a$ and $\\left(A_{1}\\setminus A_{2}\\right)\\cup\\left(A_{2}\\setminus A_{1}\\right)=\\{a^{\\prime}\\}$ . ", "page_idx": 17}, {"type": "text", "text": "Therefore, in both cases we can conclude that $\\{(A_{1},\\tilde{a}_{1}),(A_{2},\\tilde{a}_{2})\\}\\in E$ . This finishes the proof of Lemma 4.4. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "D.2 Proof of Lemma 4.2 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. The first bound follows from $|\\Sigma^{\\dag}|\\,\\leq\\,|\\Sigma|\\,\\leq\\,n2^{n-1}$ . For the second bound, consider the following set of hyperplanes defined by every pair of receiver\u2019s actions: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{H}=\\bigcup_{a,a^{\\prime}\\in A}\\left\\{\\sum_{\\omega\\in\\Omega}\\mu(\\omega)(r(\\omega,a)-r(\\omega,a^{\\prime}))=0,\\ \\sum_{\\omega\\in\\Omega}\\mu(\\omega)(r(\\omega,a)-r(\\omega,a^{\\prime}))=\\delta\\ \\right\\}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "They cut the $(m-1)$ -dimensional simplex into at most ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\binom{|\\mathcal{H}|}{\\leq m}\\leq\\binom{2n^{2}}{\\leq m}\\leq n^{O(m)}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "cells [Halperin and Sharir, 2017, Theorem 28.1.1]. Since the boundaries of each open polytope $\\Delta_{(A,\\tilde{a})}$ are defined by a subset of hyperplanes in $\\mathcal{H}$ with either strict or non-strict inequalities, each polytopes remain undivided by any hyperplane. Therefore, we have $|\\Sigma^{\\dag}|\\leq n^{O(m)}$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "D.3 LP for checking the feasibility of state-action tuples ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "E Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. For any given $\\delta\\in(0,1)$ , we establish the NP-hardness by constructing a reduction from the NP-complete problem of Subset Sum (see, e.g., Section 8.8 of [Kleinberg and Tardos, 2006]) to the problem of finding the optimal $\\delta$ -robust sender utility in Bayesian persuasion against approximate responses. This reduction maps instances of the Subset Sum problem to instances of $\\delta$ -robust Bayesian persuasion such that an instance of the Subset Sum problem has a solution (a YES instance) if and only if the corresponding $\\delta$ -robust persuasion instance yields an optimal utility of at least $\\frac{1}{2}$ . ", "page_idx": 17}, {"type": "text", "text": "We start by introducing the format of a subset sum instance. A subset sum instance is given by a set $X=\\{x_{1},\\cdot\\cdot\\cdot,x_{n}\\}$ of integers where sum $\\textstyle(X)=\\sum_{i=1}^{n}x_{i}=0\\,$ . The problem is to decide whether ", "page_idx": 17}, {"type": "image", "img_path": "9B0iOkn3UP/tmp/49a3804708ffb1f979acb3ef73c97e7dd4f6bae7f35662a823ee0e875baeca14.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 4: LP for checking the feasibility of $(A,{\\tilde{a}})\\in\\Sigma$ . The tuple is feasible if and only if $\\varepsilon^{\\star}>0$ . ", "page_idx": 18}, {"type": "text", "text": "or not there exists a subset of indices $J\\subset[n]$ such that $\\begin{array}{r}{|J|=\\frac{n}{2}}\\end{array}$ and $\\begin{array}{r}{\\mathsf{s u m}(X_{J})=\\sum_{j\\in J}x_{j}=0}\\end{array}$ . If there exists such a $J$ , then $X$ is a YES instance. Otherwise, it is a NO instance. One may check the above version of the problem is also NP-hard. In particular, the requirements that $\\mathsf{s u m}(\\dot{\\boldsymbol X})=0$ and $\\begin{array}{r}{|J|=\\frac{n}{2}}\\end{array}$ are without loss of generality, because one may add an additional integer to offset the sum of all integers if it is nonzero to begin with, as well as enough 0\u2019s so there is always a subset of size $\\begin{array}{l}{{\\frac{n}{2}}}\\end{array}$ that sums to 0 iff we have a YES instance. We construct a robust persuasion instance as follows. ", "page_idx": 18}, {"type": "text", "text": "States and prior distribution The state space is defined as $\\Omega=\\{\\omega_{1},\\cdot\\cdot\\cdot,\\omega_{n}\\}$ with $|\\Omega|=|X|=n$ , and the prior distribution $\\mu_{0}=\\mathsf{U n i f}(\\Omega)$ is a uniform distribution over the entire state space. ", "page_idx": 18}, {"type": "text", "text": "Receiver\u2019s action space The receiver\u2019s action space $A=A\\cup B\\cup C$ consists of three categories of actions: malicious guessing actions $A=\\{a_{1},\\cdot\\cdot\\cdot,a_{n}\\}$ , benign guessing actions $B=\\{b_{1},\\bar{\\cdot}\\cdot\\cdot,b_{n}\\}$ , and sign matching actions $C=\\{c_{+},c_{-}\\}$ . ", "page_idx": 18}, {"type": "text", "text": "Utility functions We define the sender\u2019s utility $s$ and receiver\u2019s utility $r$ as follows. For ease of presentation, the range of the receiver\u2019s utility is designed to be $[0,2]$ , but it is not hard to rescale it to $\\bar{[0,}1]$ to fit our modeling assumptions. ", "page_idx": 18}, {"type": "text", "text": "\u2022 For a malicious guess $a_{i}\\in A$ and any $i\\in[n]$ , the utility functions are defined as ", "page_idx": 18}, {"type": "equation", "text": "$$\nr(\\omega_{j},a_{i})=\\left\\{\\!\\!1,\\!\\!\\!\\begin{array}{l l}{{i=j}}&{{i=j}}\\\\ {{\\operatorname*{max}\\left\\{1-\\frac{\\delta}{1-\\frac{2}{n}},0\\right\\},}}&{{i\\neq j}}\\end{array}\\!\\!,\\!\\!\\begin{array}{l}{{\\!\\!\\!\\begin{array}{l}{{s(\\omega_{j},a_{i})\\equiv0.}}\\\\ {{s(\\omega_{j},a_{i})\\equiv0.}}\\end{array}\\!\\!\\end{array}}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "At a high level, malicious guesses result in a constant 0 utility on the sender, but the penalty of incorrect guesses on the receiver\u2019s side is relatively minor \u2014 on top of the base utility of 1, the receiver only suffers a utility loss of $\\frac{\\delta}{1\\!-\\!\\frac{2}{n}}$ (when $\\begin{array}{r}{\\delta<1-\\frac{2}{n})}\\end{array}$ for an incorrect state guess, which implies that the receiver secures a utility of $\\geq1-\\delta$ as long as the guess is correct with a probability at least $\\frac{2}{n}$ . This choice of utility function guarantees that to obtain nontrivial utilities, the sender must prevent the receiver from adopting malicious guesses by creating enough dispersion in the posterior distributions. In particular, the posterior probability on any state should not exceed $\\frac{2}{n}$ . ", "page_idx": 18}, {"type": "text", "text": "\u2022 For benign guess $b_{i}\\in B$ for any $i\\in[n]$ , the utility functions are defined as ", "page_idx": 18}, {"type": "equation", "text": "$$\nr(\\omega_{j},b_{i})=\\binom{1,}{1-\\delta,}\\quad i=j\\,,\\qquad s(\\omega_{j},b_{i})=\\binom{1,}{\\frac{\\frac{1}{2}-\\frac{2}{n}}{1-\\frac{2}{n}}},\\quad i\\neq j\\,\\cdot\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "At a high level, benign guesses, if correct, are beneficial for both the sender and receiver. They are intended to encourage the sender to concentrate more probability mass on some certain state in the posterior distribution. To see this, note that as long as the state $\\omega_{i}$ is in the support of the receiver\u2019s posterior, the excepted utility of the receiver will exceed $1-\\delta$ and the corresponding benign guessing action $b_{i}$ enters the $\\delta$ -BR set. For the sender, the expected utility under malicious guess $b_{i}$ reaches $\\frac{1}{2}$ only when the posterior probability on $\\omega_{i}$ is at least $\\scriptstyle{\\frac{2}{n}}$ . Therefore, to guarantee that the sender has an expected utility of at least $1/2$ , the posterior of any state in the support should be no less than $2/n$ . ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "\u2022 For the matching actions $C=\\{c_{+},c_{-}\\}$ , the utility functions are defined as ", "page_idx": 19}, {"type": "equation", "text": "$$\nr(\\omega_{j},c_{\\pm})=1\\pm\\frac{\\delta}{4M}x_{j},\\qquad s(\\omega_{j},c_{\\pm})=\\frac{1}{2}\\mp\\frac{1}{4M}x_{j},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\textstyle M=\\sum_{x\\in X}\\left|x\\right|>0$ . In this case, the receiver gains utility when her chosen action matches the sign of the expected value of $x_{i}$ under the posterior distribution, whereas the sender loses a proportional amount of utility. Specifically, when the posterior is uniform on a subspace of size $\\begin{array}{l}{{\\frac{n}{2}}}\\end{array}$ \u2014 a design choice that is encouraged by the first two categories of actions \u2014 the receiver chooses sign-matching actions based on the sign of the sum of the corresponding subset\u2019s elements. In this special case, the sender\u2019s utility falls below $<\\,{\\frac{1}{2}}$ unless the subset sum equals zero. ", "page_idx": 19}, {"type": "text", "text": "Now, we formally show the reduction from the subset sum problem to $\\delta$ -robust optimal signaling scheme by dividing the proof into two claims. ", "page_idx": 19}, {"type": "text", "text": "Claim E.1. If $X$ is a YES instance, then $\\widehat{S}_{\\delta}^{\\star}=\\widehat{S}_{\\delta}(\\varphi^{\\star})\\geq\\frac{1}{2}$ . ", "page_idx": 19}, {"type": "text", "text": "Proof of Claim E.1. For notation convenience, for any subset of indices $J\\subseteq[n]$ and any set $\\Omega$ s.t. the elements of $\\Omega$ are indexed by $[n]$ , we use $X_{J}$ to denote the subset of elements with indices in $J$ , i.e., $X_{J}=\\{\\omega_{j}\\mid j\\in J\\}$ . Let $J\\subset[n]$ such that $\\begin{array}{r}{|J|=\\frac{n}{2}}\\end{array}$ and $\\begin{array}{r}{\\mathsf{s u m}(X_{J})=\\sum_{j\\in J}x_{j}=0}\\end{array}$ . Consider the following signaling scheme: $\\varphi^{\\star}(\\omega_{i},\\sigma_{+})=\\mathbb{1}\\left[i\\in J\\right]$ , $\\varphi^{\\star}(\\omega_{i},\\sigma_{-})=\\mathbb{1}\\left[i\\in([n]\\backslash J)\\right]$ . Since the signaling scheme is deterministic, we have $\\mu_{\\sigma_{+}}=\\mathsf{U n i f}(\\Omega_{J})$ and $\\mu_{\\sigma_{-}}=\\mathsf{U n i f}(\\Omega_{[n]\\setminus J})$ . ", "page_idx": 19}, {"type": "text", "text": "To compute the robust utility of $\\varphi^{\\star}$ , we first compute the $\\delta$ -BR set $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma_{+}})$ . For the sign-matching actions $c\\in C$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nr(\\mu_{\\sigma_{+}},c)=1\\pm\\frac{\\delta}{4M}\\cdot\\frac{2}{n}\\sum_{j\\in J}x_{j}=1.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "because the subset $X_{J}$ is of sum 0. For malicious guesses $a_{i}\\in A$ , note that $\\mu_{\\sigma_{+}}(\\omega_{j})\\leq2/n$ for any $\\omega_{j}\\in\\Omega$ , thus we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nr(\\mu_{\\sigma_{+}},a_{i})\\le\\!\\frac{2}{n}+\\left(1-\\frac{2}{n}\\right)\\cdot\\left(1-\\frac{\\delta}{1-\\frac{2}{n}}\\right)=1-\\delta.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For any benign guesses $b_{i}\\in B$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nr(\\mu_{\\sigma_{+}},b_{i})=1\\cdot\\mu_{\\sigma_{+}}(\\omega_{i})+(1-\\delta)(1-\\mu_{\\sigma_{+}}(\\omega_{i}))=1-\\delta(1-\\mu_{\\sigma_{+}}(\\omega_{i})),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which implies that $r(\\mu_{\\sigma_{+}},b_{i})>1-\\delta$ if and only if $\\mu_{\\sigma_{+}}(\\omega_{i})>0$ . Therefore, we have $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma_{+}})=$ $B_{J}\\cup C$ . ", "page_idx": 19}, {"type": "text", "text": "As for the sender\u2019s robust utility, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{s(\\mu_{\\sigma_{+}},b_{i})=1\\cdot\\frac{2}{n}+\\left(1-\\frac{2}{n}\\right)\\cdot\\frac{\\frac{1}{2}-\\frac{2}{n}}{1-\\frac{2}{n}}=\\frac{1}{2},}&{\\qquad\\forall b_{i}\\in B_{J};}\\\\ &{s(\\mu_{\\sigma_{+}},c)=\\frac{1}{2}\\mp\\frac{\\delta}{4M}\\cdot\\frac{2}{n}\\displaystyle\\sum_{j\\in J}x_{j}=\\frac{1}{2}\\mp\\frac{\\delta}{4M}\\cdot\\frac{2}{n}\\mathsf{s u m}(X_{J})=\\frac{1}{2},}&{\\qquad\\forall c\\in C.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, we have $\\begin{array}{r}{\\operatorname*{min}_{a\\in{\\mathsf{B R}}_{\\delta}(\\sigma_{+})}s(\\mu_{\\sigma_{+}},a)=\\frac{1}{2}.}\\end{array}$ ", "page_idx": 19}, {"type": "text", "text": "A similar analysis show that $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma_{-}})=B_{[n]\\setminus J}\\cup C$ and $\\begin{array}{r}{\\operatorname*{min}_{a\\in\\mathsf{B R}_{\\delta}(\\sigma_{-})}s(\\mu_{\\sigma_{-}},a)=\\frac{1}{2}}\\end{array}$ . Therefore, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}^{\\star}\\geq\\widehat{S}_{\\delta}(\\varphi^{\\star})=\\varphi^{\\star}(\\sigma_{+})\\operatorname*{min}_{a\\in\\mathtt{B R}_{\\delta}(\\sigma_{+})}s(\\mu_{\\sigma_{+}},a)+\\varphi^{\\star}(\\sigma_{-})\\operatorname*{min}_{a\\in\\mathtt{B R}_{\\delta}(\\sigma_{-})}s(\\mu_{\\sigma_{-}},a)=\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Claim E.2. If the optimal sender\u2019s utility satisfies $\\widehat{S}_{\\delta}^{\\star}\\geq\\frac{1}{2}$ , then $X$ must be a YES instance. ", "page_idx": 19}, {"type": "text", "text": "Proof of Claim $E.2$ . For every posterior distribution $\\mu_{\\sigma}$ , we show that the worst-case expected sender utitiliy $\\begin{array}{r}{f_{\\delta}(\\mu_{\\sigma})\\triangleq\\operatorname*{min}_{a\\in\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})}s(\\mu_{\\sigma},a)\\le\\frac{1}{2}}\\end{array}$ , and the equality holds only when $\\mu_{\\sigma}=\\mathsf{U n i f}(X_{J})$ where $\\begin{array}{r}{|J|=\\frac{n}{2}}\\end{array}$ and $\\mathsf{s u m}(X_{J})=0$ . Therefore, if $\\widehat{S}_{\\delta}^{\\star}\\geq\\frac{1}{2}$ , then $f_{\\delta}(\\mu_{\\sigma})\\leq\\frac{1}{2}$ must hold with equality for all $\\sigma\\,\\in\\,{\\bar{\\Sigma}}$ , which implies the existence of  a subset with size $\\begin{array}{l}{{\\frac{n}{2}}}\\end{array}$ and sum 0, i.e., $X$ is a YES instance. ", "page_idx": 20}, {"type": "text", "text": "Consider the following cases: ", "page_idx": 20}, {"type": "text", "text": "Case 2. IF $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})\\cap A=\\varnothing$ . Consider two subcases based on whether or not $r(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))>1$ . In the case of $r(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))>1$ , it must be that $a^{\\star}(\\mu_{\\sigma})\\in C$ because other actions all have receiver utility $\\leq1$ . From the design of sign-matching utilities, the sender\u2019s utility exceeds $\\frac{1}{2}$ if and only if the receiver\u2019s utility is strictly lower than 1, so we must have $\\begin{array}{r}{f_{\\delta}(\\mu_{\\sigma})\\le s(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))<\\frac{1}{2}}\\end{array}$ . Therefore, it remains to consider the case of $r(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))\\leq1$ . ", "page_idx": 20}, {"type": "text", "text": "On the one hand, combining with the fact that $\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})\\cap A=\\varnothing$ , this gives ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a_{i}\\in A}r(\\mu_{\\sigma},a_{i})\\leq r(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))-\\delta\\leq1-\\delta\\ \\Rightarrow\\ \\operatorname*{max}_{i\\in[n]}\\mu_{\\sigma}(\\omega_{i})\\leq\\frac{2}{n},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Which implies that all posterior probabilities should be no larger than $\\frac{2}{n}$ . On the other hand, let $J=\\mathsf{s u p p}(\\mu_{\\sigma})$ , then for all $i\\in J$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nr(\\mu_{\\sigma},b_{i})>1-\\delta\\geq r(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))-\\delta,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "which implies $B_{J}\\subseteq{\\mathsf{B R}}_{\\delta}(\\mu_{\\sigma})$ . We further consider the following two subcases: ", "page_idx": 20}, {"type": "equation", "text": "$\\begin{array}{r}{f_{\\delta}(\\mu_{\\sigma})\\le s(\\mu_{\\sigma},b_{i})<1\\cdot\\frac2n+\\left(1-\\frac2n\\right)\\cdot\\frac{\\frac12-\\frac2n}{1-\\frac2n}=\\frac12.}\\end{array}$ ", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "\u2022 Otherwise, we have $\\begin{array}{r}{\\operatorname*{min}_{j\\in J}\\mu_{\\sigma}(\\omega_{j})\\geq\\frac{2}{n}}\\end{array}$ , i.e., all non-zero posterior probabilities should be no smaller than $\\frac{2}{n}$ . Since Equation (9) implies that all posterior probabilities should also be no larger than $\\frac{2}{n}$ , it must be the case that they are exactly $\\frac{2}{n}$ , i.e., $\\mu_{\\sigma}$ is a uniform distribution supported on exactly $\\begin{array}{r}{|J|=\\frac{n}{2}}\\end{array}$ elements. Therefore, ", "page_idx": 20}, {"type": "equation", "text": "$$\nf_{\\delta}(\\mu_{\\sigma})\\le\\operatorname*{min}_{i\\in J}s(\\mu_{\\sigma},b_{i})=1\\cdot\\frac{2}{n}+(1-2/n)\\cdot\\frac{\\frac{1}{2}-\\frac{2}{n}}{1-\\frac{2}{n}}=\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Moreover, the uniform distribution also implies $\\begin{array}{r}{r(\\mu_{\\sigma},c_{\\pm})=1+\\frac{\\delta}{4M}\\cdot\\frac{2}{n}\\cdot\\left(\\mathsf{s u m}(X_{J})\\right)_{\\pm}}\\end{array}$ . Together with the fact that $r(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))\\leq1$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nr(\\mu_{\\sigma},c_{\\mathsf{s g n}(\\mathsf{s u m}(X_{J}))})=1+\\frac{\\delta}{2M n}|\\mathsf{s u m}(X_{J})|\\leq r(\\mu_{\\sigma},a^{\\star}(\\mu_{\\sigma}))\\leq1\\;\\Rightarrow\\mathsf{s u m}(X_{J})=0.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, $J\\subset[n]$ is a subset of size $\\begin{array}{l}{{\\frac{n}{2}}}\\end{array}$ that satisfies $\\mathsf{s u m}(X_{J})=0$ , and thus $X$ is a YES instance. In this case, we have $\\mathsf{B R}(\\mu_{\\sigma})=B_{J}\\cup C$ and $\\begin{array}{r}{f_{\\delta}(\\mu_{\\sigma})=\\frac{1}{2}}\\end{array}$ . ", "page_idx": 20}, {"type": "text", "text": "In conclusion, we have shown that all but the last case have $f_{\\delta}(\\mu_{\\sigma})<\\frac{1}{2}$ , whereas the last case has both $\\begin{array}{r}{f_{\\delta}(\\mu_{\\sigma})=\\frac{1}{2}}\\end{array}$ and that the subset sum problem is a YES instance. This finishes the proof of the claim. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "Combining Claim E.1 and Claim E.2 implies that $\\widehat{S}_{\\delta}^{\\star}\\geq\\frac{1}{2}$ if and only if the subset sum problem $X$ is a YES instance. We have thus established a  reduction from the subset sum problem to that of computing the optimal $\\delta$ -robust signaling scheme, which proves the NP-hardness of the later problem. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "F Proof of Theorem 5.2 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 5.2. Let OPT be the optimal objective value and let $\\widehat{\\varphi}$ be the signaling scheme induced by the optimal solution $\\varphi^{\\star}$ . We divide the proof into two  p arts: the first part proves ", "page_idx": 20}, {"type": "text", "text": "$\\mathsf{O P T}\\geq\\widehat{S}_{\\delta}^{\\star}-\\varepsilon^{\\prime}$ , and the second part proves $\\widehat{S}_{\\delta}(\\widehat{\\varphi})\\geq\\mathsf{O P T}-4\\varepsilon^{\\prime}$ . Putting both together establishes the claim because ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widehat{S}_{\\delta}(\\widehat{\\varphi})\\geq0\\mathsf{P T}-4\\varepsilon^{\\prime}\\geq\\widehat{S}_{\\delta}^{\\star}-4\\varepsilon^{\\prime}-\\varepsilon^{\\prime}=\\widehat{S}_{\\delta}^{\\star}-5\\varepsilon^{\\prime}=\\widehat{S}_{\\delta}^{\\star}-\\varepsilon,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the last step follows from setting $\\begin{array}{r}{\\varepsilon^{\\prime}=\\frac{\\varepsilon}{5}}\\end{array}$ in Fig. 3. ", "page_idx": 21}, {"type": "text", "text": "To prove the first inequality of $\\mathsf{O P T}\\geq\\widehat{S}_{\\delta}^{\\star}-\\varepsilon^{\\prime}$ , we show that the optimal robust signaling scheme can be discretized to fti in our LP with no more than $\\varepsilon^{\\prime}$ discretization error. Specifically, let $\\varphi:\\Omega\\rightarrow\\Sigma$ be an optimal signaling scheme that has $\\widehat{S}(\\varphi_{1}^{\\star})=\\widehat{S}_{\\delta}^{\\star}$ . We will construct LP variables $\\varphi$ that are feasible in Fig. 3. ", "page_idx": 21}, {"type": "text", "text": "For each $\\sigma\\in\\Sigma$ . there exists $\\overline{{\\mu}}_{\\sigma}\\in\\mathcal G_{k}$ such that $\\forall a\\in A$ , $|s(\\mu_{\\sigma},a)-s(\\overline{{\\mu}}_{\\sigma},a)|\\leq\\varepsilon$ . let $\\Sigma_{(\\overline{{\\mu}},\\widetilde{a},\\dot{a})}\\subseteq\\Sigma$ be the subset of signals $\\sigma\\in\\Sigma$ with $\\overline{{\\mu}}=\\overline{{\\mu}}_{\\sigma}$ , $a^{\\star}(\\mu_{\\sigma})=\\tilde{a}$ , and ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\dot{a}\\in\\operatorname*{argmin}_{a:r(\\mu_{\\sigma},a)>r(\\mu_{\\sigma},\\tilde{a})-\\delta}s(\\overline{{\\mu}}_{\\sigma},a)\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We define $\\varphi$ as merging the signals in $\\Sigma_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})}$ . Formally, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\triangleq\\sum_{\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})}}\\varphi(\\omega,\\sigma).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Such a construction immediately satisfy the last two constraints the LP, because all the subsets $\\Sigma_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})}\\ \\subseteq\\ \\Sigma$ where $(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\,\\in\\,\\widehat{\\Sigma}$ form a partition of the original signal space $\\Sigma$ . The first two constraints are also satisfied because for each $\\overline{{\\mu}}\\in\\mathcal G_{k}$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\quad\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\cdot\\big(s(\\omega,a^{\\prime})-s(\\overline{{\\mu}},a)+\\varepsilon\\big)}\\\\ &{=\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\sum_{\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\tilde{a},a)}}\\varphi(\\omega,\\sigma)\\cdot\\big(s(\\omega,a^{\\prime})-s(\\overline{{\\mu}}_{\\sigma},a)+\\varepsilon\\big)}&&{\\mathrm{(definition~of~}\\varphi\\mathrm{\\in}\\mathrm{eq.\\Sigma}(12))}\\\\ &{\\geq\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\sum_{\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\tilde{a},a)}}\\varphi(\\omega,\\sigma)\\cdot\\big(s(\\omega,a^{\\prime})-s(\\mu_{\\sigma},a)\\big)}&&{\\mathrm{(}|s(\\mu_{\\sigma},a)-s(\\overline{{\\mu}}_{\\sigma},a)|\\leq\\varepsilon)}\\\\ &{=\\displaystyle\\sum_{\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\tilde{a},a)}}\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\sigma)\\left(s(\\omega,a^{\\prime})-s(\\mu_{\\sigma},a)\\right)=0,}&&{\\mathrm{(Bayes'rule)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and a similar analysis verifies $\\begin{array}{r}{\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\overline{{\\mu}},\\widetilde{a},\\dot{a})\\cdot(s(\\omega,a^{\\prime})-s(\\overline{{\\mu}},a)-\\varepsilon)\\leq0.}\\end{array}$ . For the third constraint, since $\\tilde{a}$ is the best  response to every $\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\widetilde{a},\\dot{a})}$ , it should also be the best response to the combined signal $(\\overline{{\\mu}},\\tilde{a},\\dot{a})$ . For the fourth constraint, for a tuple $(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\in\\widehat{\\Sigma}$ and an action $a$ such that $s(\\overline{{\\mu}},a)<s(\\overline{{\\mu}},\\dot{a})-2\\varepsilon^{\\prime}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\forall\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},\\quad s(\\mu_{\\sigma},a)\\leq s(\\overline{{\\mu}},a)+\\varepsilon^{\\prime}<s(\\overline{{\\mu}},\\dot{a})-\\varepsilon^{\\prime}\\leq s(\\mu_{\\sigma},\\dot{a})\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Together with the choice of $\\dot{a}$ in Equation (11) that $\\dot{a}$ minimizes $s(\\mu_{\\sigma},a)$ for all $a\\in\\mathsf{B R}_{\\delta}(\\mu_{\\sigma})$ , we have $r(\\mu_{\\sigma},a)\\leq r(\\mu_{\\sigma},\\dot{a})$ for every $\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\widetilde{a},\\dot{a})}$ . Therefore, the fourth constraint is satisfied as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{\\sigma\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\left(r(\\omega,\\tilde{a})-r(\\omega,a)-\\delta\\right)=\\sum_{\\sigma\\in\\Sigma_{(\\overline{{\\pi}},\\tilde{a},\\dot{a})}}\\varphi(\\sigma)\\left(r(\\mu_{\\sigma},\\tilde{a})-r(\\mu_{\\sigma},a)-\\delta\\right)\\geq0.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Finally, for the LP\u2019s objective value, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\mathsf{O P T}\\geq\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\displaystyle\\sum_{(\\overline{{\\mu}},\\bar{a},\\dot{a})\\in\\widehat{\\Sigma}}\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})s(\\omega,\\dot{a})}\\\\ &{\\qquad\\geq\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\displaystyle\\sum_{(\\overline{{\\mu}},\\bar{a},\\dot{a})\\in\\widehat{\\Sigma}}\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\left(s(\\overline{{\\mu}},\\dot{a})-\\varepsilon^{\\prime}\\right)}&&{(\\mathrm{the~first~constraint})}\\\\ &{\\qquad\\geq\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\displaystyle\\sum_{\\sigma\\in\\Sigma}\\varphi(\\omega,\\sigma)\\left(s(\\overline{{\\mu}}_{\\sigma},\\dot{a})-\\varepsilon^{\\prime}\\right)}&&{(\\overline{{\\mu}}_{\\sigma}=\\overline{{\\mu}}\\mathrm{~for~all~}\\sigma\\in\\Sigma_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})})}\\\\ &{\\qquad=\\displaystyle\\sum_{\\sigma\\in\\Sigma}\\displaystyle\\operatorname*{min}_{a\\in\\Omega}\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\sigma)s(\\overline{{\\mu}}_{\\sigma},a)-\\varepsilon^{\\prime}}&&{(\\mathrm{definition~of~}\\dot{a}\\mathrm{~in~eq.~}(11))}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n=\\widehat{S}(\\varphi^{\\star})-\\varepsilon^{\\prime}=\\widehat{S}_{\\delta}^{\\star}-\\varepsilon^{\\prime}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We proceed to prove the second part of the theorem, namely the signaling scheme $\\widehat{\\varphi}$ induced by optimal LP solution $\\varphi^{\\star}$ satisfies $\\hat{\\widehat{S}}_{\\delta}(\\widehat{\\varphi})\\geq\\mathsf{O P T}-4\\varepsilon^{\\prime}$ . The key step to establishing this claim is to show that, $\\forall(\\overline{{\\mu}},\\tilde{a},\\dot{a})\\in\\widehat{\\Sigma}$ , the sender\u2019s utility under the worst-case $\\delta$ -BR strategy $\\rho_{\\delta}\\big((\\overline{{\\mu}},\\tilde{a},\\dot{a})\\big)$ is not much worse than that under action $\\dot{a}$ . We establish this using proof by contradiction. Suppose an action $a=\\rho_{\\delta}((\\overline{{\\mu}},\\tilde{a},\\dot{a}))\\,\\in\\,\\mathsf{B R}_{\\delta}(\\mu_{\\overline{{\\mu}},\\tilde{a},\\dot{a}})$ satisfies $s(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},a)\\,<\\,s(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},\\dot{a})-4\\varepsilon^{\\prime}$ , then we should have $s(\\overline{{\\mu}},a)\\,<\\,s(\\overline{{\\mu}},a)\\,-\\,2\\varepsilon^{\\prime}$ because the first and second constraints of the LP in Fig. 3 ensures ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{s(\\overline{{\\mu}},a)\\leq s(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},a)+\\varepsilon^{\\prime}<s(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},\\dot{a})-3\\varepsilon^{\\prime}\\leq s(\\overline{{\\mu}},\\dot{a})-2\\varepsilon^{\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "However, from the fourth constraint, in the case of $s(\\overline{{\\mu}},a)<s(\\overline{{\\mu}},a)-2\\varepsilon^{\\prime}$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\varphi(\\omega,\\overline{{\\mu}},\\tilde{a},\\dot{a})\\left(r(\\omega,\\tilde{a})-r(\\omega,a)-\\delta\\right)\\geq0}\\\\ &{\\Longleftrightarrow r(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},a)\\leq r(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},\\dot{a})-\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which contradicts the assumption of $a\\in\\mathsf{B R}_{\\delta}\\big(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})}\\big)$ . Therefore, we must have ", "page_idx": 22}, {"type": "equation", "text": "$$\ns(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},a)\\geq s(\\mu_{(\\overline{{\\mu}},\\tilde{a},\\dot{a})},\\dot{a})-4\\varepsilon^{\\prime}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Finally, for the sender\u2019s robust utility, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{S}_{\\delta}(\\widehat{\\varphi})=\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\displaystyle\\sum_{(\\overline{{\\mu}},\\overline{{u}},\\ A)\\in\\widehat{\\Sigma}}\\varphi(\\omega,\\overline{{\\mu}},\\bar{a},\\dot{a})\\cdot s(\\omega,\\rho_{\\delta}((\\overline{{\\mu}},\\widetilde{a},\\dot{a})))}\\\\ &{\\qquad=\\displaystyle\\sum_{(\\overline{{\\mu}},\\bar{a},\\dot{a})\\in\\widehat{\\Sigma}}\\ \\widehat{\\varphi}((\\overline{{\\mu}},\\widetilde{a},\\dot{a}))\\cdot s(\\mu_{(\\overline{{\\mu}},\\bar{a},\\dot{a})},\\rho_{\\delta}((\\overline{{\\mu}},\\tilde{a},\\dot{a})))}\\\\ &{\\qquad\\geq\\displaystyle\\sum_{(\\overline{{\\mu}},\\bar{a},\\dot{a})\\in\\widehat{\\Sigma}}\\ \\widehat{\\varphi}((\\overline{{\\mu}},\\bar{a},\\dot{a}))\\cdot\\big(s(\\mu_{(\\overline{{\\mu}},\\bar{a},\\dot{a})},\\dot{a})-4\\varepsilon^{\\prime}\\big)}\\\\ &{\\qquad=\\displaystyle\\sum_{\\omega\\in\\Omega}\\mu_{0}(\\omega)\\displaystyle\\sum_{(\\overline{{\\mu}},\\bar{a},\\dot{a})\\in\\widehat{\\Sigma}}\\varphi(\\omega,\\overline{{\\mu}},\\bar{a},\\dot{a})\\cdot s(\\omega,\\dot{a})-4\\varepsilon^{\\prime}}\\\\ &{\\qquad=\\!\\!\\Theta\\Gamma-4\\varepsilon^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The abstract and introduction discuss our technical results and noting else. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: In particular, we discuss why the general problem is computationally intractable unless ${\\mathsf{P}}={\\mathsf{N P}}$ . ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The full model is given and all claims are proved. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: No experimental results. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: No data or code. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: No experimental results. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: No experimental results. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: No experimental results. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: In particular, we have done our best to preserve anonymity. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper is purely theoretical without immediate societal impacts. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 26}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 27}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: No data or models used. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: No assets used. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: No assets introduced. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: No crowdsourcing or human subjects involved. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: No human subjects involved. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}]