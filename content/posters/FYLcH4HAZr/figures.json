[{"figure_path": "FYLcH4HAZr/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between the pairwise and the proposed Streamlined In-batch Multi-frame (SIM) pipeline. Short dashed lines represent additional computations.", "description": "This figure compares the traditional pairwise multi-frame optical flow estimation pipeline with the proposed streamlined in-batch multi-frame (SIM) pipeline.  The pairwise approach estimates flow repeatedly for each pair of consecutive frames, leading to redundant calculations. In contrast, the SIM pipeline predicts all successive unidirectional flows in a single forward pass, thereby minimizing redundant computations and improving efficiency.  The dashed lines highlight the additional computations required by the pairwise method.", "section": "3 Methodology"}, {"figure_path": "FYLcH4HAZr/figures/figures_2_1.jpg", "caption": "Figure 2: Comparison between performance and efficiency. A larger bubble denotes more parameters. Models are trained via the (C+)T schedule and tested on the Sintel final pass.", "description": "This figure compares the performance (end-point error) and efficiency (runtime in milliseconds) of different optical flow estimation methods.  The size of each bubble represents the number of parameters in the model.  All models were trained using the (C+)T schedule and evaluated on the Sintel final pass dataset. The figure highlights the trade-off between accuracy and speed, showing that StreamFlow achieves state-of-the-art performance with comparable efficiency to simpler two-frame methods.", "section": "2 Related work"}, {"figure_path": "FYLcH4HAZr/figures/figures_3_1.jpg", "caption": "Figure 3: Overview of StreamFlow. (a) illustrates the overall framework and <,> denotes the dot-product operation. The computation of cost volume is limited to adjacent frames and is performed once in one forward pass. Flows are initialized to zeros. (b) depicts the details of the GTR decoder.", "description": "This figure provides a detailed overview of the StreamFlow architecture.  Panel (a) shows the overall framework, highlighting the Twins transformer encoder, the cost volume calculation (limited to adjacent frames for efficiency), and the iterative GTR decoder.  The dot product operation is also indicated. Panel (b) zooms in on the iterative GTR decoder, illustrating the motion encoder, temporal and spatial feature integration, the motion updater, and how flows are refined iteratively.  The key point is the streamlined multi-frame processing, avoiding redundant computation.", "section": "3 Methodology"}, {"figure_path": "FYLcH4HAZr/figures/figures_7_1.jpg", "caption": "Figure 4: Visualizations of results on Sintel and KITTI test sets. Differences are highlighted with red bounding boxes. StreamFlow achieves fewer artifacts on both synthetic and real-world scenes. More visualization results on DAVIS [35] and occluded regions are in the supplements.", "description": "This figure shows a comparison of optical flow estimation results between the baseline method (Twins-SKFlow) and the proposed StreamFlow method on both synthetic (Sintel) and real-world (KITTI) datasets. The red boxes highlight areas where StreamFlow shows improved performance, indicating fewer artifacts and more accurate flow predictions, especially in challenging areas like occluded regions.  The figure demonstrates StreamFlow's ability to generalize well to different types of video data.", "section": "4 Experiments"}, {"figure_path": "FYLcH4HAZr/figures/figures_16_1.jpg", "caption": "Figure 4: Visualizations of results on Sintel and KITTI test sets. Differences are highlighted with red bounding boxes. StreamFlow achieves fewer artifacts on both synthetic and real-world scenes. More visualization results on DAVIS [35] and occluded regions are in the supplements.", "description": "This figure shows visual comparisons of optical flow estimation results between StreamFlow and a baseline method on the Sintel and KITTI datasets.  The top row shows input image pairs, and the bottom row shows the corresponding optical flow estimations. Red boxes highlight areas where StreamFlow shows improved performance, namely fewer artifacts, suggesting better accuracy in capturing fine details and movement, especially in real-world scenes.  Supplementary material includes more visualizations, including results on the DAVIS dataset and in occluded regions.", "section": "4 Experiments"}, {"figure_path": "FYLcH4HAZr/figures/figures_17_1.jpg", "caption": "Figure 6: Visualizations of the performance on the occluded regions. StreamFlow achieves comparable performance even with advanced methods. All models are trained on the FlyingThings dataset. A darker color in the flow error map denotes a higher estimation error compared with ground truth.", "description": "This figure visualizes the performance of StreamFlow and VideoFlow on occluded regions of the Sintel dataset.  Occlusion maps highlight the occluded areas. The flow error maps show the error between the estimated flow and the ground truth flow.  The results demonstrate that StreamFlow achieves significantly lower errors in occluded regions than VideoFlow, indicating its improved performance in handling occlusions.", "section": "4.2 Occlusion analysis"}]