{"references": [{"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-02-13", "reason": "This paper introduces Llama, a foundational large language model that serves as the core language model for RoboMamba, providing the necessary language processing capabilities."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This seminal paper establishes the foundation for few-shot learning in large language models, which is a key aspect of RoboMamba's efficient fine-tuning strategy."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-04-08", "reason": "This paper introduces visual instruction tuning, a crucial technique leveraged by RoboMamba to align visual and language tokens, enhancing the model's multimodal understanding."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-12", "reason": "CLIP, introduced in this paper, serves as the vision encoder for RoboMamba, enabling the model to effectively process and encode visual information."}, {"fullname_first_author": "Albert Gu", "paper_title": "Mamba: Linear-time sequence modeling with selective state spaces", "publication_date": "2023-12-01", "reason": "This paper presents the Mamba model, a crucial component of RoboMamba's architecture that provides efficient linear-time sequence modeling and reasoning capabilities."}]}