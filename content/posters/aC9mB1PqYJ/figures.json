[{"figure_path": "aC9mB1PqYJ/figures/figures_7_1.jpg", "caption": "Figure 1: Performance of Alg. 1 as we vary sample size and number of nodes: The first row (a-c) shows the performance when the mixed data contains atomic intervention on all the nodes and observational data. The second row (d-f) shows the performance when the number of atomic interventions (chosen randomly) in mixed data is taken to be half of the number of nodes along with observational data. The column shows different evaluation metrics, i.e., Parameter Estimation Error, Average Jaccard Similarity, and SHD. The symbols (\u2191) represent higher is better, and (\u2193) represents the opposite (see Evaluation metric paragraph in \u00a76). In summary, performance improves for both cases as the number of samples increases. However, the graph with more nodes requires a larger sample to perform similarly. For a detailed discussion, see \u00a76.1.", "description": "This figure displays the performance of Algorithm 1 across various sample sizes and numbers of nodes. Two scenarios are considered: interventions on all nodes and interventions on half the nodes.  The results are shown for three evaluation metrics: Parameter Estimation Error, Average Jaccard Similarity, and Structural Hamming Distance (SHD).  The figure demonstrates that increasing sample size generally improves performance, but that larger graphs might need substantially more samples to achieve comparable results to smaller graphs.", "section": "6.1 Experiment on Simulated Datasets"}, {"figure_path": "aC9mB1PqYJ/figures/figures_21_1.jpg", "caption": "Figure 2: Other Evaluations Metrics for the simulation experiments in Fig. 1: The top row denotes the corresponding metrics for all interventions in the mixture setting and the bottom row to the half setting. The first column shows the number of components estimated by our algorithm Mixture-UTIGSP. For the all setting, the actual number of components corresponding to the system with nodes 4,6 and 8 are 5,7,9 respectively (one intervention on each node + one observational distribution). We observe that Mixture-UTIGSP is able to correctly estimate the number of components even with a small number of samples. Similarly, for half setting, the actual number of components corresponding to the system with nodes 4,6 and 8 are 3,4,5 respectively (intervention on half of node and one observational distribution). Even for this case Mixture-UTIGSP is able to correctly estimate the number of components. The second column shows the error in the estimation of the mixing coefficient (\u03c0i's, see Definition 4.1). For both cases, we observe that the error in the estimation of the mixing coefficient goes to zero as the sample size increases.", "description": "This figure displays additional evaluation metrics for the simulation experiments shown in Figure 1.  The top row shows results for when all nodes were intervened upon, while the bottom row shows results when only half the nodes were intervened upon.  The left column graphs the number of components estimated by the Mixture-UTIGSP algorithm. The right column graphs the error in estimating the mixing weights.  Overall, the figure demonstrates that Mixture-UTIGSP accurately estimates the number of components and the mixing weights even with relatively small sample sizes.", "section": "Empirical Results"}, {"figure_path": "aC9mB1PqYJ/figures/figures_21_2.jpg", "caption": "Figure 2: Other Evaluations Metrics for the simulation experiments in Fig. 1: The top row denotes the corresponding metrics for all interventions in the mixture setting and the bottom row to the half setting. The first column shows the number of components estimated by our algorithm Mixture-UTIGSP. For the all setting, the actual number of components corresponding to the system with nodes 4,6 and 8 are 5,7,9 respectively (one intervention on each node + one observational distribution). We observe that Mixture-UTIGSP is able to correctly estimate the number of components even with a small number of samples. Similarly, for half setting, the actual number of components corresponding to the system with nodes 4,6 and 8 are 3,4,5 respectively (intervention on half of node and one observational distribution). Even for this case Mixture-UTIGSP is able to correctly estimate the number of components. The second column shows the error in the estimation of the mixing coefficient (\u03c0i's, see Definition 4.1). For both cases, we observe that the error in the estimation of the mixing coefficient goes to zero as the sample size increases.", "description": "This figure displays the results of two other evaluation metrics, the number of estimated components and the mixing weight estimation error,  to complement the results shown in Figure 1. The results are for both the \u2018all\u2019 and \u2018half\u2019 intervention settings.  The number of components estimated by the Mixture-UTIGSP algorithm is shown for different numbers of nodes and sample sizes. The results show that Mixture-UTIGSP accurately estimates the number of components even with a relatively small number of samples. In addition, it is demonstrated that the mixing weight estimation error approaches zero as the sample size increases.", "section": "Empirical Results"}, {"figure_path": "aC9mB1PqYJ/figures/figures_21_3.jpg", "caption": "Figure 2: Other Evaluations Metrics for the simulation experiments in Fig. 1: The top row denotes the corresponding metrics for all interventions in the mixture setting and the bottom row to the half setting. The first column shows the number of components estimated by our algorithm Mixture-UTIGSP. For the all setting, the actual number of components corresponding to the system with nodes 4,6 and 8 are 5,7,9 respectively (one intervention on each node + one observational distribution). We observe that Mixture-UTIGSP is able to correctly estimate the number of components even with a small number of samples. Similarly, for half setting, the actual number of components corresponding to the system with nodes 4,6 and 8 are 3,4,5 respectively (intervention on half of node and one observational distribution). Even for this case Mixture-UTIGSP is able to correctly estimate the number of components. The second column shows the error in the estimation of the mixing coefficient (\u03c0i's, see Definition 4.1). For both cases, we observe that the error in the estimation of the mixing coefficient goes to zero as the sample size increases.", "description": "This figure displays two subfigures showing additional evaluation metrics for the simulation experiments in Figure 1. The top subfigure shows the number of estimated components and the mixing weight estimation error for the setting where interventions occur on all nodes. The bottom subfigure shows the same metrics but for the setting where interventions occur on only half of the nodes. In both cases, the results demonstrate that Mixture-UTIGSP accurately estimates the number of components and that the error in estimating mixing weights approaches zero as the sample size increases.", "section": "Empirical Results"}, {"figure_path": "aC9mB1PqYJ/figures/figures_22_1.jpg", "caption": "Figure 3: Performance of Alg. 1 as we change the cutoff ratio used for automatic component selection: We consider graphs with 6 nodes in this experiment with half intervention setting. In step 2 of Mixture-UTIGSP, we select the number of components using the log-likelihood curve. We scan the curve starting from the mixture model with the largest number of components to the smallest and stop where the relative change in the likelihood increases above a cutoff ratio (to select the elbow point of the curve). The cutoff ratio in the algorithm is chosen to be an arbitrary number close to zero. Here we compare the performance of Mixture-UTIGSP on all three metrics for the half setting of Fig. 1 as we vary the cutoff ratio. We observe that for the cutoff ratio close to zero i.e. 0.01, 0.15,0.3 the performance remains similar showing that the model selection criteria are robust to the selected cutoff ratio.", "description": "This figure shows how the performance of Algorithm 1 changes when varying the cutoff ratio used for automatic component selection in the mixture model. The experiment considers graphs with 6 nodes and a half-intervention setting. The algorithm selects the number of components using the log-likelihood curve. The figure plots three performance metrics (Parameter Estimation Error, Average Jaccard Similarity, and SHD) against different sample sizes for four cutoff ratios (0.01, 0.15, 0.3, 0.6). The results indicate that for cutoff ratios close to zero, the performance remains consistent, suggesting that the model selection criteria are robust to the choice of cutoff ratio.", "section": "Empirical Results"}, {"figure_path": "aC9mB1PqYJ/figures/figures_23_1.jpg", "caption": "Figure 4: Performance of Alg. 1 as we change the density of the underlying true causal graph: The mixture data contains atomic interventions on all nodes as well as observational data (half setting as described in the results in \u00a76). The column shows different evaluation metrics, i.e., Parameter Estimation Error, Average Jaccard Similarity, and SHD (see Evaluation metric paragraph in \u00a76). In this experiment, we vary the density of the underlying causal graph by keeping the edges in a fully connected graph with a fixed probability, labeled as density in the legend of the above plots (see random graph generation paragraph in \u00a7B.1 for details). The maximum possible density is 1, i.e., the probability of keeping an edge is 1, corresponding to a fully connected graph, and the lowest possible density is 0. We observe that as the density of the graph increases, we require more samples to achieve similar performance to less dense graphs on all three metrics. Our Theorem 4.1 shows that the sample complexity required for estimating the parameters of the mixture is proportional to the norm of the adjacency matrix ||A|| and as the density of the graph increases ||A|| increases. Thus, as the density increases, we require more samples to achieve a similar performance in estimating the parameters of the mixture, as seen in the parameter estimation error plot above.", "description": "This figure shows the performance of Algorithm 1 as the density of the underlying causal graph varies.  The experiment uses mixture data with interventions on all nodes plus observational data. Three evaluation metrics are plotted: Parameter Estimation Error, Average Jaccard Similarity, and Structural Hamming Distance (SHD). As graph density increases, more samples are needed to achieve similar performance because the sample complexity is proportional to the norm of the adjacency matrix, which increases with density.", "section": "6.1 Experiment on Simulated Datasets"}, {"figure_path": "aC9mB1PqYJ/figures/figures_23_2.jpg", "caption": "Figure 5: Ground truth and estimated causal graph for Protein signaling dataset [22]: Fig 5a is the graph created with the help of domain experts for this problem [31]. 5b shows the graph estimated by our Mixture-UTIGSP and 5c is the graph estimated by oracle UT-IGSP when they are given the ground truth disentangled mixture. The blue colored arrow in 1b and 1c shows the correctly recovered edges in the domain expert graph. Green shows the edges with the same skeleton in the domain expert graph but in a reversed direction. The red shows the edges that are incorrectly added in the estimated graph. We observe that Mixture-UTIGSP correctly identifies two more edges (PKA->ERK and PKA-> Akt) as compared to an oracle which could be due to randomness in the UTIGSP algorithm. For this estimation, the best-performing cutoff of 0.01 was selected (see Table 1).", "description": "This figure compares the ground truth causal graph from domain experts with the causal graphs estimated by the Mixture-UTIGSP algorithm (proposed in the paper) and the UTIGSP algorithm (from prior work) using the Protein Signaling dataset.  The comparison highlights the accuracy of the Mixture-UTIGSP algorithm in recovering the true causal relationships, showing it performs comparably to the UTIGSP algorithm which is given the advantage of already having disentangled the mixture data.", "section": "6.2 Experiment on Biological Dataset"}, {"figure_path": "aC9mB1PqYJ/figures/figures_24_1.jpg", "caption": "Figure 6: Performance of Alg. 1 as we change different parameters of interventions: We consider graphs with 6 nodes in this experiment. The mean of all noise distributions without any intervention is 0.0, and the variance is 1.0. The mixture data contains atomic interventions on all nodes and observational data (half setting as described in results in \u00a76). The column shows different evaluation metrics, i.e., Parameter Estimation Error, Average Jaccard Similarity, and SHD (see evaluation metric paragraph in \u00a76). From Theorem 4.1, we observe that the sample complexity for recovering the parameters of the mixture is inversely proportional to the change in the mean of the noise distribution y and change in the variance of the noise distribution |8z|. In this experiment, we vary these two parameters one at a time and empirically validate this observation.", "description": "This figure empirically validates Theorem 4.1 by showing how changing the mean and variance of the noise distribution in interventions affects the performance of the proposed algorithm.  It demonstrates that larger changes in these parameters lead to better performance (lower estimation error, higher Jaccard similarity, lower Structural Hamming Distance) across different sample sizes.", "section": "6.1 Experiment on Simulated Datasets"}, {"figure_path": "aC9mB1PqYJ/figures/figures_24_2.jpg", "caption": "Figure 6: Performance of Alg. 1 as we change different parameters of interventions: We consider graphs with 6 nodes in this experiment. The mean of all noise distributions without any intervention is 0.0, and the variance is 1.0. The mixture data contains atomic interventions on all nodes and observational data (half setting as described in results in \u00a76). The column shows different evaluation metrics, i.e., Parameter Estimation Error, Average Jaccard Similarity, and SHD (see evaluation metric paragraph in \u00a76). From Theorem 4.1, we observe that the sample complexity for recovering the parameters of the mixture is inversely proportional to the change in the mean of the noise distribution y and change in the variance of the noise distribution |8z|. In this experiment, we vary these two parameters one at a time and empirically validate this observation.", "description": "This figure empirically validates Theorem 4.1 of the paper, which states that the sample complexity for recovering the parameters of the mixture is inversely proportional to the magnitude of changes induced by an intervention.  Three subplots show how the Parameter Estimation Error, Average Jaccard Similarity, and Structural Hamming Distance (SHD) change as sample size increases. Each subplot further explores how these metrics change when either the mean (yi) or variance (|\u03b4i|) of the noise distribution is varied after an intervention. The results show that larger changes in the mean and variance lead to improved performance (lower error and higher similarity/accuracy) as expected from the theoretical analysis.  Specifically, as the magnitude of intervention change increases, the recovery is more robust, even for smaller sample sizes.", "section": "Empirical Results"}]