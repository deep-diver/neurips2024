[{"figure_path": "2vhkjOdlc8/figures/figures_1_1.jpg", "caption": "Figure 1: Setting and Performance of UAD and multi-class UAD (MUAD). (a) Task setting of class-separated UAD. (b) Task setting of MUAD. (c) Comparison of Dinomaly and previous SoTA methods [13; 14; 15; 16; 8; 17; 18; 19] on MVTec-AD [20], VisA [21], and Real-IAD [22].", "description": "This figure compares different UAD approaches. (a) shows the conventional class-separated setting where each class has its own model. (b) illustrates the model-unified multi-class UAD setting where a single model handles all classes. (c) presents a performance comparison of Dinomaly against state-of-the-art (SoTA) methods on three benchmark datasets: MVTec-AD, VisA, and Real-IAD.  The bar charts display the image-level detection AUROC, demonstrating Dinomaly's superior performance.", "section": "1 Introduction"}, {"figure_path": "2vhkjOdlc8/figures/figures_3_1.jpg", "caption": "Figure 2: The framework of Dinomaly, built by pure Transformer building blocks.", "description": "The figure shows the architecture of the Dinomaly framework. Dinomaly is composed of three main parts: a self-supervised pre-trained Transformer encoder, a noisy bottleneck, and a Transformer decoder. The encoder takes an input image and extracts features. These features are then passed through the noisy bottleneck, which consists of an MLP with dropout. The noisy features are then fed to the decoder, which consists of multiple transformer blocks with linear attention. The decoder reconstructs the features and produces an anomaly map, which highlights the anomalous regions in the input image.", "section": "2 Method"}, {"figure_path": "2vhkjOdlc8/figures/figures_4_1.jpg", "caption": "Figure 3: The decoder attention map (min-max to 0-1 for visualization) of Dinomaly with vanilla Softmax Attention vs. Linear Attention.", "description": "This figure compares the attention maps generated by the decoder of Dinomaly using two different attention mechanisms: Softmax Attention and Linear Attention. It shows that Softmax Attention tends to focus on specific regions, while Linear Attention distributes attention more broadly across the image. The visualizations provide insights into how different attention mechanisms affect the model's ability to capture and process information, particularly in the context of anomaly detection.", "section": "2.3 Unfocused Linear Attention"}, {"figure_path": "2vhkjOdlc8/figures/figures_5_1.jpg", "caption": "Figure 4: Schemes of reconstruction constraint. (a) Layer-to-layer (sparse). (b) Layer-to-cat-layer. (c) Layer-to-layer (dense). (d) Loose group-to-group, 1-group (Ours). (e) Loose group-to-group, 2-group (Ours).", "description": "This figure illustrates different schemes for reconstruction constraints in anomaly detection models.  (a), (b), and (c) show traditional layer-to-layer methods, differing in sparsity and concatenation strategies.  (d) and (e) introduce the authors' proposed \"Loose Reconstruction\" approach, where encoder and decoder features are grouped before reconstruction, improving efficiency and performance. (d) uses one group, (e) uses two groups.", "section": "2.4 Loose Reconstruction"}, {"figure_path": "2vhkjOdlc8/figures/figures_20_1.jpg", "caption": "Figure 3: The decoder attention map (min-max to 0-1 for visualization) of Dinomaly with vanilla Softmax Attention vs. Linear Attention.", "description": "This figure compares the attention maps generated by the decoder of Dinomaly using two different attention mechanisms: vanilla Softmax Attention and Linear Attention. The visualizations show the attention weights assigned to different parts of the input image. Softmax Attention is shown to focus more precisely on specific regions of the image, while Linear Attention distributes its attention more broadly across the entire image. This difference is explained by the way these two mechanisms compute the attention weights: Softmax Attention uses a softmax function to normalize the similarity scores between query-key pairs, while Linear Attention uses a simpler activation function, which does not concentrate on specific parts of the image.", "section": "2.3 Unfocused Linear Attention"}, {"figure_path": "2vhkjOdlc8/figures/figures_21_1.jpg", "caption": "Figure 3: The decoder attention map (min-max to 0-1 for visualization) of Dinomaly with vanilla Softmax Attention vs. Linear Attention.", "description": "This figure compares the attention maps generated by Dinomaly using two different attention mechanisms: Softmax Attention and Linear Attention. It visualizes how the attention is distributed across the input image for each attention head. Softmax attention focuses on specific regions of the image, while linear attention distributes the attention across a wider area.  The comparison highlights the effect of the choice of attention mechanism on the model's ability to focus and extract relevant information from the input.", "section": "2.3 Unfocused Linear Attention"}, {"figure_path": "2vhkjOdlc8/figures/figures_22_1.jpg", "caption": "Figure A3: Anomaly maps visualization on Real-IAD. All samples are randomly chosen.", "description": "This figure shows a qualitative visualization of the anomaly maps generated by Dinomaly on the Real-IAD dataset.  It displays multiple examples of images from different Real-IAD categories, along with their corresponding ground truth anomaly maps (GT) and the anomaly maps produced by the Dinomaly model. The visual comparison allows for an assessment of the model's accuracy in localizing anomalies.", "section": "A.6 Qualitative Visualization"}]