[{"figure_path": "CbtkDWZzDq/tables/tables_3_1.jpg", "caption": "Table 1: Motivating results for low precision ensembling of pre-trained ViT models. Negative log-likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB) for rounding-to-nearest (RTN) and low precision ensembling with Bernoulli stochastic rounding (LPE-BSR) derived from the publicly available pre-trained ImageNet model (\u2606). Blue highlights the areas where LPE-BSR excels, particularly in larger models and lower precision settings.", "description": "This table presents the results of experiments using pre-trained Vision Transformer (ViT) models.  It compares the performance of two methods: rounding-to-nearest (RTN) and the proposed low precision ensembling with Bernoulli stochastic rounding (LPE-BSR). The table shows negative log-likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB) for different ViT model sizes (ViT-T/16, ViT-S/16, ViT-B/16, ViT-L/16) and different integer precision levels (INT-6, INT-4).  The results highlight the superior performance of LPE-BSR, especially for larger models and lower precision settings.", "section": "4.1 Motivation: training-free ensemble construction of large ViT models"}, {"figure_path": "CbtkDWZzDq/tables/tables_5_1.jpg", "caption": "Table 1: Motivating results for low precision ensembling of pre-trained ViT models. Negative log-likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB) for rounding-to-nearest (RTN) and low precision ensembling with Bernoulli stochastic rounding (LPE-BSR) derived from the publicly available pre-trained ImageNet model (\u2606). Blue highlights the areas where LPE-BSR excels, particularly in larger models and lower precision settings.", "description": "This table presents the results of experiments on pre-trained Vision Transformer (ViT) models, comparing the performance of rounding-to-nearest (RTN) quantization with the proposed Low Precision Ensembling with Bernoulli Stochastic Rounding (LPE-BSR) method.  The table shows negative log-likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB) for different model sizes (ViT-T/16, ViT-S/16, ViT-B/16, ViT-L/16) and integer quantization bit depths (INT-6, INT-4). The results demonstrate the superiority of LPE-BSR, especially for larger models and lower precision settings, highlighting its ability to maintain and improve performance despite the use of low-precision representations.", "section": "4.1 Motivation: training-free ensemble construction of large ViT models"}, {"figure_path": "CbtkDWZzDq/tables/tables_8_1.jpg", "caption": "Table 3: Results for low precision ensembling of pre-trained models. We compute (a) average loss, (b) ambiguity, and (c) ensemble loss for diversity analysis, along with evaluation metrics to assess overall performance. Our LPE-BSR samples are centered around \u2606 within each group (pre-trained model in this context), which are separated by horizontal lines.", "description": "This table presents a comparison of the performance of different methods for low-precision ensembling of pre-trained models. It shows the average loss, ambiguity, ensemble loss, negative log-likelihood (NLL), classification error (ERR), and expected calibration error (ECE) for each method. The methods compared include the pre-trained models and the proposed LPE-BSR method, with results presented for different precision levels (INT-5). The table also indicates the ensemble size used for each method.", "section": "4.5 Training-free ensemble construction of pre-trained large models"}, {"figure_path": "CbtkDWZzDq/tables/tables_15_1.jpg", "caption": "Table 1: Motivating results for low precision ensembling of pre-trained ViT models. Negative log-likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB) for rounding-to-nearest (RTN) and low precision ensembling with Bernoulli stochastic rounding (LPE-BSR) derived from the publicly available pre-trained ImageNet model (\u2606). Blue highlights the areas where LPE-BSR excels, particularly in larger models and lower precision settings.", "description": "This table presents the results of experiments evaluating the performance of low precision ensembling on pre-trained Vision Transformer (ViT) models.  It compares two methods: rounding-to-nearest (RTN) and the proposed low precision ensembling with Bernoulli stochastic rounding (LPE-BSR). The table shows negative log-likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB) for different ViT model sizes (ViT-T/16, ViT-S/16, ViT-B/16, ViT-L/16) and different integer quantization levels (INT-6, INT-4).  The results demonstrate the effectiveness of LPE-BSR, especially for larger models and lower precision settings.", "section": "4.1 Motivation: training-free ensemble construction of large ViT models"}, {"figure_path": "CbtkDWZzDq/tables/tables_16_1.jpg", "caption": "Table 5: Results for low precision ensembling of fine-tuned models. We compute (a) average loss, (b) ambiguity, and (c) ensemble loss for diversity analysis, along with evaluation metrics to assess overall performance. The results are presented in ascending order of memory budgets, i.e., the total number of bits for representing ensemble. The number in parentheses after each method indicates the ensemble size.", "description": "This table compares different ensembling methods (LPE-BSR with different ensemble sizes, MAP, BE, and DE) in terms of their performance on a fine-tuned model.  It shows average loss, ambiguity (a measure of diversity), ensemble loss, negative log-likelihood (NLL), error rate (ERR), expected calibration error (ECE), and memory budget (total bits used for the ensemble).  The results highlight the trade-off between ensemble diversity and performance, showing how LPE-BSR achieves competitive performance while using less memory compared to other methods.", "section": "4.2 Comparative study to Bayesian methods"}, {"figure_path": "CbtkDWZzDq/tables/tables_17_1.jpg", "caption": "Table 6: Comparative results for training-free ensembles. The training-free ensemble methods, including Gaussian, MCD, and our proposed LPE-BSR, collect ensemble members centered around \u2606 (pre-trained CLIP-ViT-L/14 model in this context). Here, \u03c3\u00b2 denotes the variance of Gaussian noise in the Gaussian baseline, and p refers to the drop probability in the MCD baseline.", "description": "This table compares the performance of three training-free ensemble methods: Gaussian, Monte Carlo Dropout (MCD), and the proposed Low Precision Ensembling with Bernoulli Stochastic Rounding (LPE-BSR).  It shows the negative log-likelihood (NLL), classification error (ERR), and expected calibration error (ECE) for each method on the CLIP-ViT-L/14 model.  The results demonstrate that LPE-BSR achieves superior performance compared to the Gaussian and MCD baselines, while also being more memory-efficient.", "section": "4.4 Combining with fast ensembling methods"}, {"figure_path": "CbtkDWZzDq/tables/tables_18_1.jpg", "caption": "Table 1: Motivating results for low precision ensembling of pre-trained ViT models. Negative log-likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB) for rounding-to-nearest (RTN) and low precision ensembling with Bernoulli stochastic rounding (LPE-BSR) derived from the publicly available pre-trained ImageNet model (\u2606). Blue highlights the areas where LPE-BSR excels, particularly in larger models and lower precision settings.", "description": "This table presents the results of experiments evaluating the performance of low-precision ensembling (LPE-BSR) compared to rounding-to-nearest (RTN) on various sizes of pre-trained Vision Transformer (ViT) models.  The metrics used are Negative Log-Likelihood (NLL), classification error (ERR), and ensemble ambiguity (AMB). The table shows that LPE-BSR often outperforms RTN, particularly in larger models and lower precision settings. The star symbol (\u2606) represents the pre-trained model in FP32.", "section": "4.1 Motivation: training-free ensemble construction of large ViT models"}]