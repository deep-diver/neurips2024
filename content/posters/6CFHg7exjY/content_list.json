[{"type": "text", "text": "Addressing Hidden Confounding with Heterogeneous Observational Datasets for Recommendation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yanghao Xiao1,3 Haoxuan Li2 Yongqiang Tang3,\u2217 Wensheng Zhang4,\u2217 ", "page_idx": 0}, {"type": "text", "text": "1University of Chinese Academy of Sciences 2Peking University 3Institute of Automation, Chinese Academy of Sciences 4Guangzhou University xiaoyanghao22@mails.ucas.ac.cn, hxli@stu.pku.edu.cn, yongqiang.tang@ia.ac.cn, zhangwenshengia@hotmail.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The collected data in recommender systems generally suffers selection bias. Considerable works are proposed to address selection bias induced by observed user and item features, but they fail when hidden features (e.g., user age or salary) that affect both user selection mechanism and feedback exist, which is called hidden confounding. To tackle this issue, methods based on sensitivity analysis and leveraging a few randomized controlled trial (RCT) data for model calibration are proposed. However, the former relies on strong assumptions of hidden confounding strength, whereas the latter relies on the expensive RCT data, thereby limiting their applicability in real-world scenarios. In this paper, we propose to employ heterogeneous observational data to address hidden confounding, wherein some data is subject to hidden confounding while the remaining is not. We argue that such setup is more aligned with practical scenarios, especially when some users do not have complete personal information (thus assumed with hidden confounding), while others do have (thus assumed without hidden confounding). To achieve unbiased learning, we propose a novel meta-learning based debiasing method called MetaDebias. This method explicitly models oracle error imputation and hidden confounding bias, and utilizes bi-level optimization for training. Extensive experiments on three public datasets validate our method achieves state-of-the-art performance in the presence of hidden confounding, regardless of RCT data availability. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recommender systems have been developed with the purpose of providing users with personalized recommendations, serving as a potent tool in capturing users\u2019 true preferences [22]. In recent years, deep learning algorithms are proposed to train recommendation models with collected historical data. However, the selection bias introduced by the users\u2019 selective interactions with items poses a challenge to the unbiased learning of the prediction model [4, 54, 59]. For instance, in explicit feedback data, users are free to rate items they prefer, thereby engendering the distribution discrepancy between interacted and non-interacted data [35, 44, 55]. ", "page_idx": 0}, {"type": "text", "text": "To alleviate selection bias, a line of works are proposed, including error imputation [2, 16, 48], inverse propensity weighting [21, 36, 45, 46], and doubly robust [39, 43, 55]. Moreover, recent works have sought to enhance these foundational methods from diverse perspectives, including analysis on both bias and variance [7, 12, 27], considerations for training stability [31, 49], and integration with multi-task learning [37, 52, 64]. However, they all fail to achieve unbiased when some features ", "page_idx": 0}, {"type": "image", "img_path": "6CFHg7exjY/tmp/3eeefb3dfd9367780580c9ea56c6af4cebf7aff7c69efa8f1d3ab3af7bf88d54.jpg", "img_caption": ["(a) Toy examples of user information collection process. (b) The causal graphs of two types of MNAR data. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: Toy examples and causal graphs of heterogeneous observational data, both of which are missing not at random (MNAR) due to the selection bias. In causal graphs, $b_{u,i},\\,o_{u,i},$ $\\boldsymbol{r}_{u,i}$ and $h_{u,i}$ denote basic mandatory features, observation, rating and optional features, respectively, where observed and unobserved variables are represented by solid-line and dashed-line circles. ", "page_idx": 1}, {"type": "text", "text": "that simultaneously affect both user selection mechanism and feedback remain unobserved, which is called hidden confounding and is widely prevalent in real-world scenarios [10, 28, 29]. ", "page_idx": 1}, {"type": "text", "text": "To tackle hidden confounding, sensitivity analysis based methods inspired by causal inference are proposed, which assume the true propensities are near and bounded by the estimated values, and further adopt worst-case optimization [10, 66]. More recently, data fusion based methods leverage a few RCT data collected from randomized controlled trials or A/B tests to calibrate propensity and imputation models to achieve unbiasedness [28, 29]. Unfortunately, both of them prove challenging to implement in real-world scenarios, as the former relies on strong assumption on hidden confounding strength, whereas the latter relies on the significantly expensive RCT data. ", "page_idx": 1}, {"type": "text", "text": "To fill this gap, this paper proposes to employ heterogeneous observational data to address hidden confounding, wherein some data is affected by hidden confounding while the remaining is not. We argue that such setup is more aligned with practical recommendation scenarios, especially when some users/items do not have complete information (thus assumed with hidden confounding), while others do have (thus assumed without hidden confounding). For example, in Figure 1a, during user registration process, some users such as Alice may complete both mandatory fields and optional fields like age and salary, while others such as Bob may only complete mandatory fields. Similarly, this also holds on the item side. We depict the corresponding causal graphs in Figure 1b, where $b_{u,i}$ and $h_{u,i}$ denote basic mandatory and optional features that affect both observation and feedback, respectively. To achieve unbiased learning with above heterogeneous observational data, we propose a novel metalearning based debiasing method called MetaDebias, to explicitly estimate the oracle prediction errors and the bias introduced by hidden confounders. We further adopt bi-level optimization technique for training the prediction model. The contributions of this work are summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "\u2022 To the best of our knowledge, this is the first work to employ heterogeneous observational data to address hidden confounding in debiased recommendation, relaxing the reliance on RCT data in previous data fusion methods. \u2022 We propose a meta-learning based debiasing method called MetaDebias to explicitly estimate the oracle error imputation, and employ bi-level optimization for model training. \u2022 We conduct extensive experiments on three public datasets, and our method achieves state-of-the-art performance in the presence of hidden confounding, regardless of the availability of RCT data. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries and Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Let $\\mathcal{U}\\,=\\,\\{u\\}$ , $\\mathcal{T}=\\{i\\}$ , and $\\mathcal{D}\\,=\\,\\{(u,i)\\ |\\ u\\,\\in\\mathcal{U},i\\,\\in\\mathcal{Z}\\}$ be the set of users, the set of items, and the target population consisting of all user-item pairs, respectively. Define $x_{u,i}$ and $\\boldsymbol{r}_{u,i}$ be the observed features and rating of user-item pair $(u,i)$ , and suppose observation indicator $o_{u,i}\\in\\{0,1\\}$ ", "page_idx": 1}, {"type": "text", "text": "be a binary treatment variable, where $o_{u,i}\\,=\\,1$ indicates $\\boldsymbol{r}_{u,i}$ is observed, otherwise is not. Let $\\mathcal{O}=\\{(u,\\bar{i})\\mid(u,i)\\in\\mathcal{D},o_{u,i}=1\\}$ be the observed population consisting of user-item pairs with observed ratings. Denote $\\mathbb{P}$ and $\\mathbb{E}$ be the distribution and expectation on the target population $\\mathcal{D}$ . ", "page_idx": 2}, {"type": "text", "text": "We denote prediction model with parameter $\\theta$ as $\\hat{r}_{u,i}=f(x_{u,i};\\theta)$ which aims to predict true ratings. If all the ratings $\\{r_{u,i}:(u,i)\\in\\bar{D}\\}$ are observed, i.e., $\\mathcal{O}=\\mathcal{D}$ , the parameter $\\theta$ can be trained by minimizing the ideal loss: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{ideal}}(\\theta)=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}e_{u,i},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $e_{u,i}=L(\\hat{r}_{u,i},r_{u,i})$ is the prediction error and $L(\\cdot,\\cdot)$ is a pre-specified loss function such as the squared loss $e_{u,i}=(\\hat{r}_{u,i}-r_{u,i})^{2}$ . However, rating $\\boldsymbol{r}_{u,i}$ is observed only when $o_{u,i}=1$ , and naively minimizing prediction loss on the observed population $\\scriptscriptstyle\\mathcal{O}$ will suffer from bias and lead to sub-optimal performance [55]. This is attributed to the disparities between the observed population $\\scriptscriptstyle\\mathcal{O}$ and the target population $\\mathcal{D}$ , which is called selection bias. ", "page_idx": 2}, {"type": "text", "text": "2.1 Addressing Selection Bias without Hidden Confounding ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To address selection bias, prior works preliminarily assume the absence of hidden confounding in the collected data, implying that the observed features $x_{u,i}$ include all the possible confounders. Without loss of generality, we define a binary variable $g_{u,i}\\,\\in\\,\\{0,1\\}$ as the data source indicator which measures the completeness of observed features $x_{u,i}$ , where $g_{u,i}=1$ indicates all confounders are completely observed, while $g_{u,i}~=~0$ indicates some hidden confounders exist. Assumed no hidden confounding $(g_{u,i}\\;=\\;1,(u,i)\\;\\in\\;\\mathcal{D})$ , it holds that $e_{u,i}\\;\\perp\\;o_{u,i}\\;\\mid\\;x_{u,i},g_{u,i}\\;=\\;1$ , the widely adopted propensity based methods are proposed. Specifically, the Inverse Propensity Scoring (IPS) estimator [46] reweights each sample based on the probability of being observed and is given as $\\begin{array}{r}{\\mathcal{L}_{\\mathrm{IPS}}(\\theta)\\;=\\;(1/|\\bar{\\mathcal{D}}|)\\sum_{(u,i)\\in\\mathcal{D}}o_{u,i}^{\\;\\bullet}e_{u,i}/\\hat{p}_{u,i}}\\end{array}$ , where $\\hat{p}_{u,i}$ is the estimation of propensity $p_{u,i}\\triangleq\\mathbb{P}(o_{u,i}=1|x_{u,i},g_{u,i}=1)$ . Furthermore, the Doubly Robust (DR) estimator [43, 55] further extends IPS with error imputation and is presented as $\\begin{array}{r}{\\mathcal{L}_{\\mathrm{DR}}(\\boldsymbol{\\dot{\\theta}})=(1/|\\mathcal{D}|)\\sum_{(u,i)\\in\\mathcal{D}}[\\hat{e}_{u,i}+o_{u,i}(e_{u,i}-$ $\\hat{e}_{u,i})/\\hat{p}_{u,i}]$ , where $\\hat{e}_{u,i}$ is the imputed error. Based on IPS and DR estimators, many variants have been proposed, and please refer to Appendix A.1 for more details. ", "page_idx": 2}, {"type": "text", "text": "2.2 Addressing Selection Bias with Hidden Confounding ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "However, in some real-world scenarios, the observed features do not include all confounders and hidden confounding exists. Based on the incomplete observed features $x_{u,i}$ with $g_{u,i}=0$ , it holds that $o_{u,i}\\;\\nmid\\!\\!\\!\\!\\slash\\;\\;e_{u,i}\\;\\mid\\;x_{u,i},g_{u,i}\\;=\\;0$ , which prevents previous methods such as DR from achieving unbiasedness. To further mitigate the hidden confounding, methods based on sensitivity analysis and model calibration using RCT data have been proposed. ", "page_idx": 2}, {"type": "text", "text": "Sensitivity Analysis. Inspired from causal inference literature, sensitivity analysis based approach assumes the true propensity $p_{u,i}$ is near and can be bounded by the estimated propensity $\\hat{p}_{u,i}\\,=$ $\\mathbb{P}(o_{u,i}\\,=\\,1|x_{u,i},\\bar{g}_{u,i}\\,=\\,0)$ , and adopt worst-case optimization to mitigate hidden confounding [10, 66]. However, above strong assumption on hidden confounding strength is hard to be satisfied in real-world scenarios and such method fails when the assumption is violated. ", "page_idx": 2}, {"type": "text", "text": "Model Calibration. Recent works propose to leverage a few unbiased RCT data collected from randomized controlled trials or $\\mathrm{A}/\\mathrm{B}$ tests for model calibration [28, 29]. Collecting RCT data requires users to rate items randomly, hence RCT samples are representatives of the target population, and the prediction loss on these samples serves as an unbiased estimator of the ideal loss. Thus, the biased propensity and imputation models learned from the incomplete observed features $x_{u,i}$ can be corrected using such unbiased loss, for instance, with the help of additive residual models [28] or multiplicative reweighting models [29]. However, the acquisition cost of RCT data is prohibitively high, posing challenges to the practical implementation of such methods in real-world settings. ", "page_idx": 2}, {"type": "text", "text": "Apart from debiased recommendation, more related works about causal inference under hidden confounding can be found in Appendix A.1, which is a widely studied topic. ", "page_idx": 2}, {"type": "text", "text": "3 MetaDebias: Meta Learning Based Debiased Recommendation Approach ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "3.1 Problem Formulation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We first present the problem formulation, that is to provide an unbiased estimator for the ideal loss $\\mathcal{L}_{\\mathrm{ideal}}$ in the presence of hidden confounding, given the collected heterogeneous observational data with known data source indicator $g_{u,i}$ . Unlike existing works that assume training data originates from a single dataset without or with hidden confounding, we argue that the training data is more likely composed of two heterogeneous datasets, one of which has sufficient feature collection and is assumed without hidden confounding $(g_{u,i}=1)$ , while the other has insufficient feature collection and is assumed with hidden confounding $(g_{u,i}=0)$ ) with hidden confounders denoted as $h_{u,i}$ . ", "page_idx": 3}, {"type": "text", "text": "Here, based on the given $g_{u,i}\\in\\{0,1\\}$ for distinguishing between two types of observational data, we partition the observed population $\\scriptscriptstyle\\mathcal{O}$ into two subpopulations $\\mathcal{D}_{0}=\\{(u,i)\\mid(u,i)\\in\\mathcal{D},g_{u,i}=$ $0,\\bar{o_{u,i}}=1\\}$ and $\\mathcal{D}_{1}=\\{(\\bar{u},\\bar{i})\\mid(u,i)\\in\\mathcal{D},g_{u,i}=\\bar{1},\\bar{o}_{u,i}=1\\}$ , while unobserved population is $\\mathcal{D}_{u}=\\{(u,i)\\mid(u,i)\\in\\mathcal{D},o_{u,i}=0\\}$ . A naive approximation method for ideal loss is minimizing the prediction loss over the observed data. Specifically, given $\\mathcal{D}_{0}$ and $\\mathcal{D}_{1}$ , the respective losses over each subgroup are as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathcal{D}_{0}}=\\frac{1}{|\\mathcal{D}_{0}|}\\sum_{(u,i)\\in\\mathcal{D}_{0}}e_{u,i},\\qquad\\mathcal{L}_{\\mathcal{D}_{1}}=\\frac{1}{|\\mathcal{D}_{1}|}\\sum_{(u,i)\\in\\mathcal{D}_{1}}e_{u,i}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "However, due to selection bias, neither $\\mathcal{L}_{\\mathcal{D}_{0}},\\mathcal{L}_{\\mathcal{D}_{1}}$ nor their combination $\\mathcal{L}_{\\mathrm{Naive}}=\\mathcal{L}_{\\mathcal{D}_{0}}+\\mathcal{L}_{\\mathcal{D}_{1}}$ is an unbiased estimator for the ideal loss. Furthermore, as discussed in the Preliminaries 2, prior methods cannot be applied to achieve the goal without additional model or data assumptions. ", "page_idx": 3}, {"type": "text", "text": "3.2 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To achieve the goal, we propose to explicitly estimate the prediction error $e_{u,i}$ on all user-item pairs $\\mathcal{D}$ using observed features $x_{u,i}$ , as the ideal loss is defined as the average prediction error over $\\mathcal{D}$ , i.e., $\\begin{array}{r}{\\mathcal{L}_{\\mathrm{ideal}}=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}e_{u,i}}\\end{array}$ . In other words, our goal is transformed into accurately estimating the oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ , which is inherently an unbiased estimator of the ideal loss. ", "page_idx": 3}, {"type": "text", "text": "The challenges in achieving accurate oracle error imputation estimation lie in the fact that the prediction error $e_{u,i}$ is only partially observable, and the missing mechanisms differ between the two subgroups $\\mathcal{D}_{0}$ and $\\mathcal{D}_{1}$ due to the influence of hidden confounding. To address these challenges, we define the identifiable propensity scores aimed at modeling the two types of missing mechanisms, along with the naive error imputations defined over the entire space $\\mathcal{D}$ , to assist in estimating the target oracle error imputation. Next, we will introduce the details. ", "page_idx": 3}, {"type": "text", "text": "To start with, different from the previously widely used propensity score $\\mathbb{P}(o_{u,i}=1|x_{u,i})$ which is applicable only for samples in subgroup $\\mathcal{D}_{1}$ and the generalized formulation $\\mathbb P(o_{u,i}=1|x_{u,i},h_{u,i})$ designed for subgroup $\\mathcal{D}_{0}$ which is unidentifiable, we define the identifiable propensity score $\\pi(x,g)$ which models the probability of being observed for any user-item pair on the entire space $\\mathcal{D}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi(x,g)=\\mathbb{P}\\left(o_{u,i}=1\\ |\\ x_{u,i}=x,g_{u,i}=g\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The proposed $\\pi(x,g)$ models the propensity score for both the absence and presence of hidden confounding, based on the input data source indicator $g_{u,i}$ . ", "page_idx": 3}, {"type": "text", "text": "Similarly, we propose to use the observed features $x_{u,i}$ and data source indicator $g_{u,i}$ to estimate the naive prediction error as $o_{u,i}\\cdot e_{u,i}$ , which is computable on the target population $\\mathcal{D}$ and expected to be the prediction error $e_{u,i}$ when sample $(u,i)$ is observed $o_{u,i}\\,=\\,1$ , or to be zero when not observed $o_{u,i}=0$ . Note that the zero value in the defined naive prediction error $o_{u,i}\\cdot e_{u,i}$ contains the information about data missing mechanism, thus $g_{u,i}$ is used to capture the differences in the missing mechanism when hidden confounding is present or absent. Formally, to achieve this target, we define the naive error imputation $m(x,g)$ as: ", "page_idx": 3}, {"type": "equation", "text": "$$\nm(x,g)=\\mathbb{E}[o_{u,i}\\cdot e_{u,i}\\mid x_{u,i}=x,g_{u,i}=g].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Based on the proposed propensity score $\\pi(x,g)$ and naive error imputation $m(x,g)$ , the oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ can be derived, we summarize their relationship in Lemma 1 below. ", "page_idx": 3}, {"type": "image", "img_path": "6CFHg7exjY/tmp/307274d95275bb2540a383cef2cfa79f166532d5fc7b6b098672eb352edff03f.jpg", "img_caption": ["Figure 2: Architecture of MetaDebias to address selection bias in the presence of hidden confounding. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Lemma 1. The relationship between the proposed propensity score $\\pi(x,g)$ , naive error imputation $m(x,g)$ and the oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ is as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nm(x,g)=\\{\\mathbb{E}\\left[e_{u,i}~\\vert~x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\pi(x,g),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\eta(x)=\\mathbb{E}\\left[e_{u,i}\\ |\\ x_{u,i}=x,g_{u,i}=0,o_{u,i}=1\\right]-\\mathbb{E}\\left[e_{u,i}\\ |\\ x_{u,i}=x\\right]\\!.$ ", "page_idx": 4}, {"type": "text", "text": "The above result delineates the conditional independence relationship between observation and prediction error. Specifically, on subgroup $\\mathcal{D}_{1}$ where no hidden confounding exists, the prediction error $e_{u,i}$ is independent of the observation $o_{u,i}$ given the observed features $x_{u,i}$ , i.e., $e_{u,i}$ \u22a5\u22a5 $o_{u,i}\\mid$ $x_{u,i},g_{u,i}\\,=\\,1$ , and the expectation of $o_{u,i}\\cdot e_{u,i}$ naturally equals the product of their respective expectations as shown in Equation 3. ", "page_idx": 4}, {"type": "text", "text": "However, on subgroup $\\mathcal{D}_{0}$ where hidden confounders $h_{u,i}$ exist, above conditional independence does not hold, thus we introduce an additional residual module $\\eta(x)$ which describes the expectation difference between the mean prediction error over target population $\\mathcal{D}$ and the biased subpopulation $\\mathcal{D}_{0}$ , to account for the bias introduced by hidden confounding. ", "page_idx": 4}, {"type": "text", "text": "Lemma 1 provides an approach for estimating the oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ , and the estimation depends solely on propensity score $\\pi(x,g)$ and naive error imputation $m(x,g)$ . Note that both $\\pi(x,g)$ and $m(x,g)$ are typically estimated from the heterogeneous observational datasets, which implies that when the estimation of $\\pi(x,g)$ and $m(x,g)$ are inaccurate, the resultant oracle error imputation estimation will further deteriorate in accuracy. ", "page_idx": 4}, {"type": "text", "text": "To address this limitation, we propose further incorporating additional data information including the observation $o_{u,i}$ and the naive prediction error $o_{u,i}\\cdot e_{u,i}$ to achieve a more robust estimation of the oracle error imputation. The details are shown in Lemma 2 below. ", "page_idx": 4}, {"type": "text", "text": "Lemma 2. The relationship between the propensity score $\\pi(x,g)$ , naive error imputation $m(x,g)$ , observation $o_{u,i}$ , naive prediction error $o_{u,i}\\cdot e_{u,i}$ and oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ is: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{o_{u,i}\\cdot e_{u,i}-m(x,g)=\\{\\mathbb{E}\\left[e_{u,i}\\ |\\ x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\left\\{o_{u,i}-\\pi(x,g)\\right\\}+\\xi,}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "equation", "text": "$$\n\\xi=o_{u,i}\\cdot\\{e_{u,i}-\\{\\mathbb{E}[e_{u,i}\\mid x_{u,i}=x]+(1-g)\\eta(x)\\}\\}\\;w i t h\\;\\mathbb{E}[\\xi\\mid x,g]=0.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The findings in Lemma 2 provide an alternative and robust approach for estimating the oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ , wherein the estimation depends not only on the learned propensity score ${\\hat{\\pi}}(x,g)$ , naive error imputation $\\hat{m}(x,g)$ , but also on the observation $o_{u,i}$ , along with the naive prediction error $o_{u,i}\\cdot e_{u,i}$ , where $\\xi$ with zero-mean property can be regarded as a noise. ", "page_idx": 4}, {"type": "text", "text": "3.3 Training Objectives ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For the method implementation, we employ deep learning models to estimate the aforementioned proposed modules, and name this approach as MetaDebias. To ensure consistency in the model input, we flil the missing feature values with 0, so that the observed features $x_{u,i}$ have the same dimensions when $g_{u,i}=0$ and $g_{u,i}=1$ . We present the architecture of MetaDebias in Figure 2, and introduce the training objective of each model as follows. ", "page_idx": 5}, {"type": "text", "text": "Initially, we employ the commonly used cross-entropy loss to train the propensity model $\\pi(x,g;\\phi_{\\pi})$ with parameters $\\phi_{\\pi}$ using heterogeneous data, denoted as ${\\mathcal{L}}_{\\pi}(\\phi_{\\pi})$ shown in Equation 5 below: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{\\pi}(\\phi_{\\pi})=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}\\left[-o_{u,i}\\cdot\\log\\pi\\left(x_{u,i},g_{u,i}\\right)-\\left(1-o_{u,i}\\right)\\cdot\\log(1-\\pi\\left(x_{u,i},g_{u,i}\\right))\\right]}\\\\ &{\\qquad\\quad=\\displaystyle\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}_{0}\\cup\\mathcal{D}_{1}}-\\log\\pi\\left(x_{u,i},g_{u,i}\\right)+\\displaystyle\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}_{u}}-\\log(1-\\pi\\left(x_{u,i},g_{u,i}\\right))\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "According to the definition of $m(x,g)$ in Equation 2, we adopt the square loss to train the naive imputation model $m(x,g;\\phi_{m})$ with parameters $\\phi_{m}$ , denoted as $\\bar{\\mathcal{L}}_{m}(\\phi_{m}\\bar{,}\\theta)$ shown in Equation 6: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{\\mathcal L_{m}(\\phi_{m},\\theta)=\\frac{1}{|\\mathcal D|}\\sum_{(u,i)\\in\\mathcal D}\\left(m\\left(x_{u,i},g_{u,i}\\right)-o_{u,i}\\cdot e_{u,i}\\right)^{2}}}\\\\ {\\displaystyle{\\qquad\\qquad=\\frac{1}{|\\mathcal D|}\\sum_{(u,i)\\in\\mathcal D_{0}\\cup\\mathcal D_{1}}\\left(m\\left(x_{u,i},g_{u,i}\\right)-e_{u,i}\\right)^{2}+\\frac{1}{|\\mathcal D|}\\sum_{(u,i)\\in\\mathcal D_{u}}\\left(m\\left(x_{u,i},g_{u,i}\\right)\\right)^{2},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $e_{u,i}=L(f(x_{u,i};\\theta),r_{u,i})$ is the prediction error and only available when $o_{u,i}=1$ . ", "page_idx": 5}, {"type": "text", "text": "Next, based on Lemma 2, we employ the square loss to train the oracle imputation model $e(x;\\phi_{e})$ with parameters $\\phi_{e}$ and residual model $\\eta(x;\\phi_{\\eta})$ with parameters $\\phi_{\\eta}$ given learned propensity model $\\phi_{\\pi}$ and imputation model $\\phi_{m}$ , denoted as $\\mathcal{L}_{m e t a}(\\phi_{e},\\phi_{\\eta},\\phi_{m},\\phi_{\\pi},\\theta)$ shown in Equation 7 below: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathcal{L}_{m e t a}(\\phi_{e},\\phi_{\\eta},\\phi_{m},\\phi_{\\pi},\\theta)=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}\\left\\{o_{u,i}\\cdot e_{u,i}-m\\left(x_{u,i},g_{u,i}\\right)\\right.}\\\\ {\\displaystyle\\left.-\\left[e(x_{u,i})+(1-g_{u,i})\\cdot\\eta(x_{u,i})\\right]\\cdot[o_{u,i}-\\pi\\left(x_{u,i},g_{u,i}\\right)]\\right\\}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Furthermore, we adopt the oracle imputation model $e(x;\\phi_{e})$ to generate prediction errors on the target population $\\mathcal{D}$ as the training objective for prediction model $f(\\boldsymbol{x}_{u,i};\\boldsymbol{\\theta})$ with parameters $\\theta$ . The training objective $\\mathcal{L}_{p r e d}(\\theta,\\phi_{e})$ is demonstrated in the following Equation 8: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{L}_{p r e d}(\\theta,\\phi_{e})=\\frac{1}{|\\mathcal{D}|}\\sum_{(u,i)\\in\\mathcal{D}}e(x_{u,i};\\phi_{e}\\mid\\theta),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $e(x_{u,i};\\phi_{e}\\mid\\theta)$ is the learned oracle imputation model training from $\\mathcal{L}_{m e t a}$ loss in Equation 7. ", "page_idx": 5}, {"type": "text", "text": "3.4 Learning Algorithm ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Following previous works [3, 56], we propose a bi-level optimization based learning algorithm for model training. Specifically, we first train the propensity model $\\pi(x,g)$ independently by minimizing the ${\\mathcal{L}}_{\\pi}$ loss shown in Equation 5, as its training objective is orthogonal to those of other models. Next, we use bi-level optimization to update the remaining models. ", "page_idx": 5}, {"type": "text", "text": "In the bi-level optimization, we initially assumed update of the naive imputation model $m(x,g;\\phi_{m})$ and the oracle imputation model $e(x;\\phi_{e})$ to ensure that the parameter $\\phi_{e}^{\\prime}(\\phi_{m}^{\\prime},\\theta)$ is differentiable with respect to the parameter $\\theta$ . Then we update the prediction model $f(x_{u,i};\\theta)$ by $\\mathcal{L}_{p r e d}(\\theta,\\phi_{e})$ in Equation 8, where the gradient of $\\theta$ is accessible to be calculated and back propagated. ", "page_idx": 5}, {"type": "text", "text": "After obtaining the updated prediction model, we adopt joint learning to update the naive imputation model $m(x,g;\\phi_{m})$ by ${\\mathcal{L}}_{m}$ in Equation 6 and oracle imputation model $\\bar{e(x;\\phi_{e})}$ and residual model $\\eta(x;\\phi_{\\eta})$ by $\\mathcal{L}_{m a t a}$ in Equation 7. We summarize the whole procedure of the learning algorithm in Algorithm 1, where $\\alpha$ is denoted as the learning rate and we use distinct subscripts to correspond to different models. ", "page_idx": 5}, {"type": "text", "text": "Input: observed ratings $\\mathbf{R}^{o}$ .   \n1 Pretrain propensity model $\\pi(x,g,\\phi_{\\pi})$   \n2 while stopping criteria is not satisfied do   \n3 for number of training steps do   \n4 Sample a batch of user-item pairs $\\{(u_{i},i_{i})\\}_{i=1}^{B_{1}}$ from $\\mathcal{D}$ ;   \n5 Assumed update naive imputation model: $\\phi_{m}^{\\prime}(\\theta)=\\phi_{m}-\\alpha_{m}\\nabla_{\\phi_{m}}\\mathcal{L}_{m}\\left(m(\\phi_{m})\\mid\\theta\\right)$ ;   \n6 Assumed update oracle imputation model:   \n$\\phi_{e}^{\\prime}(\\phi_{m}^{\\prime},\\theta)\\stackrel{.}{=}\\phi_{e}-\\alpha_{e}\\nabla_{\\phi_{e}}\\bar{\\mathcal{L}}_{m e t a}\\left(e(\\phi_{e})\\mid\\phi_{m}^{\\prime},\\theta\\right)$ ;   \n7 Update prediction model: $\\theta\\leftarrow\\theta-\\alpha\\nabla_{\\theta}\\mathcal{L}_{p r e d}\\left(f_{\\phi_{e}^{\\prime}(\\phi_{m}^{\\prime},\\theta)}\\right)$ ;   \n8 end   \n9 for number of training steps do   \n10 Sample a batch of user-item pairs $\\{(u_{i},i_{i})\\}_{i=1}^{B_{2}}$ from $\\mathcal{D}$ ;   \n11 Update naive imputation model: $\\bar{\\phi_{m}}\\gets\\bar{\\phi_{m}}-\\alpha_{m}\\nabla_{\\phi_{m}}\\mathcal{L}_{m}\\left(m(\\phi_{m})\\mid\\theta\\right)$ ;   \n12 end   \n13 for number of training steps do   \n14 Sample a batch of user-item pairs $\\{(u_{i},i_{i})\\}_{i=1}^{B_{3}}$ from $\\mathcal{D}$ ;   \n15 Update oracle imputation model: $\\phi_{e}\\leftarrow\\phi_{e}-\\alpha_{e}\\nabla_{\\phi_{e}}\\mathcal{L}_{m e t a}\\left(e(\\phi_{e})\\mid\\phi_{m},\\theta\\right);$ ;   \n16 Update residual model: $\\phi_{\\eta}\\leftarrow\\phi_{\\eta}-\\alpha_{\\eta}\\nabla_{\\phi_{\\eta}}\\mathcal{L}_{m e t a}\\left(\\eta(\\phi_{\\eta})\\mid\\phi_{m},\\theta\\right)$ ;   \n17 end   \n18 end   \nOutput: \u03b8 ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Dataset and Experimental Details. Following previous studies [3, 43, 55, 56], we conduct extensive experiments on three public datasets, $\\mathrm{COAT}^{2}$ , YAHOO! $\\mathbf{R}3^{3}$ , and KUAIREC4 [11]. COAT contains 6,960 biased ratings and 4,640 unbiased ratings derived from 290 users evaluating 300 items. YAHOO! R3 contains 311,704 biased ratings and 54,000 unbiased ratings derived from 15,400 users evaluating 1,000 items. Both datasets employ a five-point rating scale, and we binarize the ratings greater than 3 as 1 and others as 0. KUAIREC contains 4,676,570 video watching ratios derived from 1,411 users evaluating 3,327 videos. The ratios that greater than 2 are binarized as 1, otherwise as 0. We adopt feature masking to simulate $g_{u,i}$ which measures feature completeness, and $g_{u,i}=1$ only when the features of both users and items are fully preserved, otherwise $g_{u,i}=0$ , and see Appendix A.3 for more details. Following previous works [3, 28, 29, 34], we randomly split $5\\%$ unbiased data from the test set as validation set, and for all methods requiring RCT data, we employ observational data without hidden confounding to pretend RCT data. For evaluation, we employ three widely adopted metrics AUC, Recall $@K$ , and $\\mathbf{NDCG}@K$ to measure debiasing performance, where we set $K=5$ on COAT and YAHOO! R3, and $K=50$ on KUAIREC. All the methods are implemented on PyTorch with Adam as the optimizer and NVIDIA A40 as the computing resource, and we tune learning rate in $\\{0.0001,0.0005,\\stackrel{\\cdot}{0.001},0.005,0.01,0.05\\}$ and weight decay in $[1e-7,10]$ . ", "page_idx": 6}, {"type": "text", "text": "Baselines. Two-layer multi-layer perceptron are used as the base model, and we compare proposed methods with both RCT data-free and RCT data-based methods. ", "page_idx": 6}, {"type": "text", "text": "\u2022 RCT data-free Methods: Without RCT data, the baselines includes IPS-based methods: IPS [46], ESMM [37, 57], Multi-IPS [64], $\\mathbf{ESCM^{2}}$ -IPS [52], BRD-IPS [10], and DR-based methods: DR [55], Stable-DR [31], TDR [27], Multi-DR [64], $\\mathbf{ESCM^{2}}$ -DR [52], , BRD-DR [10]. \u2022 RCT data-based Methods: Based on RCT data, the baselines include model selection based methods: KD-Label [34], AutoDebias [3], LTD-IPS [56],LTD-DR [56], and model calibration based methods: Bal-IPS [29], Bal-DR [29], Res-IPS [28], Res-DR [28]. ", "page_idx": 6}, {"type": "text", "text": "Table 1: Performance on AUC, Recall $@K$ and $\\mathrm{NDCG}@K$ on the COAT, YAHOO! R3 and KUAIREC datasets. The best result is bolded and the best results of both types of baseline methods are underlined, where \\* means statistically significant results (p-value $\\leq0.05)$ using the paired-t-test. ", "page_idx": 7}, {"type": "image", "img_path": "6CFHg7exjY/tmp/5bd3aa3f0c6826038fcf4fda243d4daa541f914f12567eb315626bd8f972348b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "", "img_caption": ["Figure 3: Effects of hidden confounding strength on the KUAIREC dataset. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.2 Experimental Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Performance Comparison. We compare our proposed MetaDebias with existing methods and the results are shown in Table 1. First, all debiasing models outperform the base model which adopts naive empirical risk minimization, indicating the necessity for debiasing. Second, BRDDR and Res-DR which are two representative methods for eliminating hidden confounding serve as the most competitive baselines, implying that ignoring hidden confounding leads to inevitable performance degradation. Third, compared to RCT data-free methods, RCT data-based methods do not demonstrate significant improvements across the three datasets, indicating that effective model selection or model calibration cannot be achieved using MNAR data without hidden confounding. Furthermore, MetaDebias exhibits significantly superior overall performance on all three datasets, which validates that our method achieves state-of-the-art performance in the presence of hidden confounding leveraging heterogeneous observational data without the utilization of RCT data. ", "page_idx": 7}, {"type": "text", "text": "In-depth Analysis. We conduct in-depth analysis to further explore the effect of hidden confounding strength, the proportions of heterogeneous observational data, and training data size on performance. Moreover, we further explore the performance under conditions where RCT data is available, which is consistent with the problem setup in prior works. See Appendix A.4 for more experimental results. ", "page_idx": 7}, {"type": "text", "text": "The Hidden Confounding Strength. Figure 3 shows the impact of hidden confounding strength, where we simulate higher hidden confounding strength by masking more features. We observe all methods exhibit performance degradation as the hidden confounding gets stronger, with vanilla DR exhibiting the poorest performance, highlighting the necessity of removing hidden confounding. The performance of BRD-DR deteriorates significantly, primarily due to the violation of imposed strong model assumptions, while Res-DR demonstrates competitive performance. In addition, the proposed ", "page_idx": 7}, {"type": "image", "img_path": "6CFHg7exjY/tmp/0e58c634cac8389e7759994f2994bfc9d84d17822e958838acf6082492542758.jpg", "img_caption": ["Figure 4: Effects of varying proportions of heterogeneous observational data on the KUAIREC dataset. "], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "6CFHg7exjY/tmp/b52d8fa912eeee73ef6b911e9228a07bc131f679efd7ed3f01579609a9d6f732.jpg", "table_caption": ["Table 2: Effects of training dataset size on $\\mathbf{NDCG}@K$ on the KUAIREC and YAHOO! R3 datasets. ", "(a) NDCG $@50$ on the KUAIREC dataset "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "6CFHg7exjY/tmp/6007c05d3c90c94a001008faf4e58b06615d93d2afe3d98da10983f769cb8c58.jpg", "table_caption": [], "table_footnote": ["(b) NDCG@5 on the YAHOO! R3 dataset "], "page_idx": 8}, {"type": "text", "text": "MetaDebias stably outperforms the baselines across varying hidden confounding strength, implying our method is able to effectively address strong hidden confounding using only observational data. ", "page_idx": 8}, {"type": "text", "text": "The Proportion of Heterogeneous Observational Data. We explore the impact of varying proportions of heterogeneous observational data on the KUAIREC dataset in Figure 4, where $\\#N(G=0)$ and $\\#N(G={\\bar{1}})$ denote the quantity of training data with and without hidden confounding. First, we observe the performance of DR varies significantly under different proportions, indicating the pronounced disparities between the heterogeneous observational data. Besides, performances of all methods are enhanced when the proportion of data without hidden confounding increases, this is because more feature information aids in accurate propensity and imputation model learning. Furthermore, MetaDebias demonstrates the best performance, indicating our method can achieve effective debiasing performance across various observational data proportions, and the potential for application in a range of real-world scenarios. ", "page_idx": 8}, {"type": "text", "text": "The Training Dataset Size. Table 2 explores the impact of training set size on $\\mathbf{NDCG}@K$ on both KUAIREC and YAHOO! R3 datasets. We find that the performance of all methods declines as the size of training set decreases, highlighting the importance of training data size on model training. Besides, the proposed MetaDebias consistently outperforms the baselines across varying training data size especially when the size is extremely small such as only $10\\%$ , which indicates our method that explicitly models oracle prediction errors on the entire space fully exploits the heterogeneous observational data and is still effective even with small training set size. ", "page_idx": 8}, {"type": "text", "text": "The Impact of RCT Training Data. In Figure 5, we explore the debiasing performance when RCT data is available, which is consistent with the problem setup in prior works [28, 29]. Specifically, the training dataset is composed of two parts: an observational dataset with hidden confounding and a small RCT dataset. For implementing our proposed MetaDebias, we label the RCT sample as $g_{u,i}=1$ , as the RCT data represents a special case of MNAR data without hidden confounding. We find that the performances of all methods exhibit an increasing trend as the size of RCT training set increases, which is consistent with previous research findings. Moreover, the proposed MetaDebias stably outperforms all the baseline methods with varying RCT training set size, which indicates our method remains superior to the existing approaches under the previous problem setup, further validating the effectiveness of our method. ", "page_idx": 8}, {"type": "image", "img_path": "6CFHg7exjY/tmp/979b99320d8ab29e8a74ad4a9440e595f62cadd60c924dd70aa225d0a370b58e.jpg", "img_caption": ["Figure 5: Effects of varying RCT training set size on AUC on three benchmark datasets. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this study, we investigate the problem of selection bias in the presence of hidden confounding. First, we argue that existing methods are challenging to be applied in real-world scenarios, as they either rely on strong assumptions on hidden confounding strength or depend on the costly RCT data. To tackle this issue, we propose to adopt heterogeneous observational datasets which are more likely to be collected to address hidden confounding and claim that such setup is more aligned with practical scenarios. Then, we propose a meta-learning based debiasing method called MetaDebias, which explicitly models the oracle error imputation and additional bias induced by hidden confounders, and we adopt bi-level optimization with assumed update for model training. Extensive experiments conducted on three public datasets validate our method achieves state-ofthe-art performance, regardless of the availability of RCT data. A limitation of this work lies in the assumption that all the confounders can be included through sufficient feature collection. Even though it is possible to collect hundreds of features in industrial scenarios, and some features like consumption records may potentially represent hard-to-obtain features like salary, it is still challenging to guarantee that all confounders for partial samples have been included. In future work, we will explore how to further relax this theoretically feasible assumption. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The authors thank the anonymous reviewers for their valuable comments. This work was supported by the National Natural Science Foundation of China under Grant 623B2002, Grant 62106266 and Grant U22B2048. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Matteo Bonvini and Edward H Kennedy. Sensitivity analysis via the proportion of unmeasured confounding. Journal of the American Statistical Association, 117(539):1540\u20131550, 2022.   \n[2] Yin-Wen Chang, Cho-Jui Hsieh, Kai-Wei Chang, Michael Ringgaard, and Chih-Jen Lin. Training and testing low-degree polynomial data mappings via linear svm. Journal of Machine Learning Research, 11(4), 2010.   \n[3] Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen, Guli Lin, and Keping Yang. Autodebias: Learning to debias for recommendation. In SIGIR, 2021.   \n[4] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. Bias and debias in recommender system: A survey and future directions. ACM Transactions on Information Systems, 2022.   \n[5] David Cheng and Tianxi Cai. Adaptive combination of randomized and observational data. arXiv preprint arXiv:2111.15012, 2021.   \n[6] H Christopher Frey and Sumeet R Patil. Identification and review of sensitivity analysis methods. Risk analysis, pages 553\u2013578, 2002.   \n[7] Quanyu Dai, Haoxuan Li, Peng Wu, Zhenhua Dong, Xiao-Hua Zhou, Rui Zhang, Xiuqiang He, Rui Zhang, and Jie Sun. A generalized doubly robust learning framework for debiasing post-click conversion rate prediction. In KDD, 2022.   \n[8] Piersilvio De Bartolomeis, Javier Abad Martinez, Konstantin Donhauser, and Fanny Yang. Hidden yet quantifiable: A lower bound for confounding strength using randomized trials. In AISTATS, 2024.   \n[9] Ilker Demirel, Edward De Brouwer, Zeshan M Hussain, Michael Oberst, Anthony A Philippakis, and David Sontag. Benchmarking observational studies with experimental data under rightcensoring. In AISTATS, 2024.   \n[10] Sihao Ding, Peng Wu, Fuli Feng, Xiangnan He, Yitong Wang, Yong Liao, and Yongdong Zhang. Addressing unmeasured confounder for recommendation with sensitivity analysis. In KDD, 2022.   \n[11] Chongming Gao, Shijun Li, Wenqiang Lei, Jiawei Chen, Biao Li, Peng Jiang, Xiangnan He, Jiaxin Mao, and Tat-Seng Chua. Kuairec: A fully-observed dataset and insights for evaluating recommender systems. In CIKM, 2022.   \n[12] Siyuan Guo, Lixin Zou, Yiding Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang Wang, Hechang Chen, Dawei Yin, and Yi Chang. Enhanced doubly robust learning for debiasing post-click conversion rate estimation. In SIGIR, 2021.   \n[13] Tobias Hatt, Jeroen Berrevoets, Alicia Curth, Stefan Feuerriegel, and Mihaela van der Schaar. Combining observational and randomized data for estimating heterogeneous treatment effects. arXiv preprint arXiv:2202.12891, 2022.   \n[14] Xiangnan He, Yang Zhang, Fuli Feng, Chonggang Song, Lingling Yi, Guohui Ling, and Yongdong Zhang. Addressing confounding feature issue for causal recommendation. ACM Transactions on Information Systems, 41(3):1\u201323, 2023.   \n[15] Miguel A. Hern\u00e1n and James M. Robins. Causal Inference: What If. Boca Raton: Chapman and Hall/CRC, 2020.   \n[16] Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Neil Houlsby, and Zoubin Ghahramani. Probabilistic matrix factorization with non-random missing data. In ICML, 2014.   \n[17] Jin Huang, Harrie Oosterhuis, and Maarten de Rijke. It is different when items are older: Debiasing recommendations when selection bias and user preferences are dynamic. In WSDM, 2022.   \n[18] Zeshan Hussain, Ming-Chieh Shih, Michael Oberst, Ilker Demirel, and David Sontag. Falsification of internal and external validity in observational studies via conditional moment restrictions. In AISTATS, 2023.   \n[19] Zeshan M Hussain, Michael Oberst, Ming-Chieh Shih, and David Sontag. Falsification before extrapolation in causal effect estimation. In NeurIPS, 2022.   \n[20] Guido W Imbens. Potential outcome and directed acyclic graph approaches to causality: Relevance for empirical practice in economics. Journal of Economic Literature, pages 1129\u201379, 2020.   \n[21] Guido W. Imbens and Donald B. Rubin. Causal Inference For Statistics Social and Biomedical Science. Cambridge University Press, 2015.   \n[22] Dietmar Jannach, Lukas Lerche, and Markus Zanker. Recommending based on implicit feedback. In Social information access: systems and technologies, pages 510\u2013569. Springer, 2018.   \n[23] Nathan Kallus and Angela Zhou. Confounding-robust policy improvement. In NeurIPS, 2018.   \n[24] Nathan Kallus, Aahlad Manas Puli, and Uri Shalit. Removing hidden confounding by experimental grounding. In NeurIPS, 2018.   \n[25] Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30\u201337, 2009.   \n[26] Haoxuan Li, Quanyu Dai, Yuru Li, Yan Lyu, Zhenhua Dong, Xiao-Hua Zhou, and Peng Wu. Multiple robust learning for recommendation. In AAAI, 2023.   \n[27] Haoxuan Li, Yan Lyu, Chunyuan Zheng, and Peng Wu. TDR-CL: Targeted doubly robust collaborative learning for debiased recommendations. In ICLR, 2023.   \n[28] Haoxuan Li, Kunhan Wu, Chunyuan Zheng, Yanghao Xiao, Hao Wang, Zhi Geng, Fuli Feng, Xiangnan He, and Peng Wu. Removing hidden confounding in recommendation: A unified multi-task learning approach. In NeurIPS, 2023.   \n[29] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, and Peng Wu. Balancing unobserved confounding with a few unbiased ratings in debiased recommendations. In WWW, 2023.   \n[30] Haoxuan Li, Yanghao Xiao, Chunyuan Zheng, Peng Wu, and Peng Cui. Propensity matters: Measuring and enhancing balancing for recommendation. In ICML, 2023.   \n[31] Haoxuan Li, Chunyuan Zheng, and Peng Wu. StableDR: Stabilized doubly robust learning for recommendation on data missing not at random. In ICLR, 2023.   \n[32] Haoxuan Li, Chunyuan Zheng, Yanghao Xiao, Peng Wu, Zhi Geng, Xu Chen, and Peng Cui. Debiased collaborative filtering with kernel-based causal balancing. In ICLR, 2024.   \n[33] Marc Lipsitch, Eric Tchetgen Tchetgen, and Ted Cohen. Negative controls: a tool for detecting confounding and bias in observational studies. Epidemiology, 2010.   \n[34] Dugang Liu, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Weike Pan, and Zhong Ming. A general knowledge distillation framework for counterfactual recommendation via uniform data. In SIGIR, 2020.   \n[35] Dugang Liu, Pengxiang Cheng, Zinan Lin, Jinwei Luo, Zhenhua Dong, Xiuqiang He, Weike Pan, and Zhong Ming. Kdcrec: Knowledge distillation for counterfactual recommendation via uniform data. IEEE Transactions on Knowledge and Data Engineering, 2022.   \n[36] Jinwei Luo, Dugang Liu, Weike Pan, and Zhong Ming. Unbiased recommendation model based on improved propensity score estimation. Journal of Computer Applications, 2021.   \n[37] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In SIGIR, 2018.   \n[38] Benjamin M Marlin and Richard S Zemel. Collaborative prediction and ranking with nonrandom missing data. In RecSys, 2009.   \n[39] Stephen L. Morgan and Christopher Winship. Counterfactuals and Causal Inference: Methods and Principles for Social Research. Cambridge University Press, second edition, 2015.   \n[40] Judea Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press, second edition, 2009.   \n[41] Paul R. Rosenbaum. Design of Observational Studies. Springer Nature Switzerland AG, second edition, 2020.   \n[42] Evan TR Rosenman, Guillaume Basse, Art B Owen, and Mike Baiocchi. Combining observational and experimental datasets using shrinkage estimators. Biometrics, 79(4):2961\u20132973, 2023.   \n[43] Yuta Saito. Doubly robust estimator for ranking metrics with post-click conversions. In RecSys, 2020.   \n[44] Yuta Saito and Masahiro Nomura. Towards resolving propensity contradiction in offline recommender learning. In IJCAI, 2022.   \n[45] Yuta Saito, Suguru Yaginuma, Yuta Nishino, Hayato Sakata, and Kazuhide Nakata. Unbiased recommender learning from missing-not-at-random implicit feedback. In WSDM, 2020.   \n[46] Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. Recommendations as treatments: Debiasing learning and evaluation. In ICML, 2016.   \n[47] Zihua Si, Xueran Han, Xiao Zhang, Jun Xu, Yue Yin, Yang Song, and Ji-Rong Wen. A model-agnostic causal learning framework for recommendation using search data. In WWW, 2022.   \n[48] Harald Steck. Training and testing of recommender systems on data missing not at random. In KDD, 2010.   \n[49] Adith Swaminathan and Thorsten Joachims. The self-normalized estimator for counterfactual learning. In NeurIPS, 2015.   \n[50] Eric Tchetgen Tchetgen. The control outcome calibration approach for causal inference with unobserved confounding. American journal of epidemiology, 179(5):633\u2013640, 2014.   \n[51] Victor Veitch and Anisha Zaveri. Sense and sensitivity analysis: Simple post-hoc analysis of bias due to unobserved confounding. In NeurIPS, 2020.   \n[52] Hao Wang, Tai-Wei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu, Ruopeng Li, and Wei Chu. ESCM2: Entire space counterfactual multi-task model for post-click conversion rate estimation. In SIGIR, 2022.   \n[53] Haotian Wang, Wenjing Yang, Longqi Yang, Anpeng Wu, Liyang Xu, Jing Ren, Fei Wu, and Kun Kuang. Estimating individualized causal effect with confounded instruments. In KDD, 2022.   \n[54] Wenjie Wang, Yang Zhang, Haoxuan Li, Peng Wu, Fuli Feng, and Xiangnan He. Causal recommendation: Progresses and future directions. In Tutorial on SIGIR, 2023.   \n[55] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. Doubly robust joint learning for recommendation on data missing not at random. In ICML, 2019.   \n[56] Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. Combating selection biases in recommender systems with a few unbiased ratings. In WSDM, 2021.   \n[57] Hong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, and Keping Yang. Entire space multi-task modeling via post-click behavior decomposition for conversion rate prediction. In SIGIR, 2020.   \n[58] Lili Wu and Shu Yang. Integrative $r$ -learner of heterogeneous treatment effects combining experimental and observational studies. In CLeaR, 2022.   \n[59] Peng Wu, Haoxuan Li, Yuhao Deng, Wenjie Hu, Quanyu Dai, Zhenhua Dong, Jie Sun, Rui Zhang, and Xiao-Hua Zhou. On the opportunity of causal learning in recommendation systems: Foundation, estimation, prediction and challenges. In IJCAI, 2022.   \n[60] Mengyue Yang, Guohao Cai, Furui Liu, Jiarui Jin, Zhenhua Dong, Xiuqiang He, Jianye Hao, Weiqi Shao, Jun Wang, and Xu Chen. Debiased recommendation with user feature balancing. ACM Transactions on Information Systems, 41(4):1\u201325, 2023.   \n[61] Shu Yang and Peng Ding. Combining multiple observational data sources to estimate causal effects. Journal of the American Statistical Association, 115:1540\u20131554, 2020.   \n[62] Shu Yang, Donglin Zeng, and Xiaofei Wang. Improved inference for heterogeneous treatment effects using real-world data subject to hidden confounding. https://arxiv.org/abs/2007.12922, 2020.   \n[63] Shu Yang, Chenyin Gao, Donglin Zeng, and Xiaofei Wang. Elastic integrative analysis of randomised trial and real-world data for treatment heterogeneity estimation. Journal of the Royal Statistical Society Series B: Statistical Methodology, 85(3):575\u2013596, 2023.   \n[64] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong Wen, and Ramin Ramezani. Large-scale causal approaches to debiasing post-click conversion rate estimation with multi-task learning. In WWW, 2020.   \n[65] Xiang Zhang, Douglas E Faries, Hu Li, James D Stamey, and Guido W Imbens. Addressing unmeasured confounding in comparative observational research. Pharmacoepidemiology and drug safety, 27(4):373\u2013382, 2018.   \n[66] Zhiheng Zhang, Quanyu Dai, Xu Chen, Zhenhua Dong, and Ruiming Tang. Robust causal inference for recommender system to overcome noisy confounders. In SIGIR, 2023.   \n[67] Hao Zou, Haotian Wang, Renzhe Xu, Bo Li, Jian Pei, Ye Jun Jian, and Peng Cui. Factual observation based heterogeneity learning for counterfactual prediction. In CLeaR, 2023. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Appendix / supplemental material ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Related Work ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Debiased Recommendation. Recommender systems play an important role in mitigating information overload which are trained on users\u2019 historical feedback, but selection bias inherent in the collected data impede the algorithms from accurately capturing users\u2019 true preferences [17, 53, 67]. If we naively adopt empirical risk minimization to train prediction model without debiasing, it will achieve sub-optimal prediction performance [46, 55, 60]. To address the selection bias and achieve unbiased learning, the error imputation based (EIB) method [38, 48] treats selection bias as a missing data problem, imputes the missing data, and subsequently trains prediction model combining with the imputed data. The inverse propensity scoring (IPS) method [36, 45, 46] estimates the probability of an user-item pair being observed which is called propensity and performs inverse propensity weighting for the observed samples. The doubly robust (DR) method [39, 43, 55] combines both error imputation and inverse propensity weighting, achieving superior performance while exhibiting enhanced robustness. Owing to the extensive adoption of IPS and DR, numerous variants have been proposed [26, 31, 49]. Specifically, some approaches focus on bias and variance trade-off [7, 12, 27], while others integrate with multi-task learning to address data sparsity [52, 64]. Additionally, some works explore how to learn more appropriate propensity scores [3, 30, 32, 56]. However, the aforementioned methods fail to achieve unbiased when some features that simultaneous affect both user selection mechanism and the feedback remain unobserved, which is called hidden confounding. Despite recent works proposed to address observed confounding effects [14, 47], tackling hidden confounding remains a challenging task. To fill this gap, sensitivity analysis based methods are proposed, where worst case optimization is used to mitigate the hidden confounding [10, 66]. However, the validity of such methods relies on the assumption on hidden confounding effect that true propensities are near and can be bounded by the estimated values, and such approaches become ineffective when this assumption is violated. Motivated by this, recent works propose to leverage a small amount of RCT data for model calibration, where the calibrated estimator serves an unbiased estimator of the ideal loss [28, 29]. Observing that the acquisition cost of RCT data is prohibitively high, it is equally challenging to implement such calibration based methods in real-world applications. In this paper, we propose a more practical solution to address hidden confounding using heterogeneous observational data for explicitly modeling the oracle prediction errors. ", "page_idx": 14}, {"type": "text", "text": "Causal Inference under Hidden Confounding. Hidden confounding is a widely studied topic in causal inference literature [1, 50, 65], and there are two primary approaches to addressing this issue. One approach involves leveraging additional information to achieve unbiased estimation of the target causal quantity, for example the instrumental variables [15], front door adjustment [40], negative control [33] and data fusion [24, 58]. The second approach based on sensitive analysis, on the other hand, aims to estimate appropriate bounds for the target causal effects, rather than pursuing precise point estimation [6, 23, 41, 51]. However, in practical applications, it is hard to identify suitable instruments or mediators that meet the required criteria [15, 20], while the sensitive analysis based method heavily relies on strong assumption of the hidden confounding effect, which is also hard to satisfy. The data fusion approach aims to combine data from observational studies and randomized trials, and can be broadly classified into three categories: statistical test based, correction based, and weighted based. Statistical test based methods introduce statistical tests to compare the causal effects estimated from observational studies and randomized trials, thereby detecting and mitigating hidden confounding [8, 9, 18, 19]. Correction based methods are proposed to correct the biased causal effect estimation derived from observational data using the unbiased RCT data [13, 24, 63], and an efficient integrative estimator is established based on semi-parametric theory [62], and further integrated with machine learning models [58]. Weighted methods propose to train a biased estimator using observational data, train an unbiased estimator using RCT data, and take the weighted average of these two estimators as the final result [5, 42, 61]. A limitation of data fusion methods is the availability of RCT data, as the cost of obtaining RCT data is prohibitively high. Moreover, for the correction based method, the randomized trial and observational study should share the same support sets. When the support sets differ and only a partial overlap exists, additional strong parametric assumptions are required for extrapolation, for instance, the hidden confounding effect is assumed to be a linear function [24]. In contrast to the aforementioned methods, our proposed approach is more readily feasible in real-world scenarios, as it does not impose assumption on hidden confounding effect and the required heterogeneous observational data is relatively more accessible. ", "page_idx": 14}, {"type": "text", "text": "A.2 Proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Lemma 1 The relationship between the proposed propensity score $\\pi(x,g)$ , naive error imputation $m(x,g)$ and the oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ is as followed: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{m(x,g)=\\{\\mathbb{E}\\left[e_{u,i}~|~x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\pi(x,g),}\\\\ {\\eta(x)=\\mathbb{E}\\left[e_{u,i}~|~x_{u,i}=x,g_{u,i}=0,o_{u,i}=1\\right]-\\mathbb{E}\\left[e_{u,i}~|~x_{u,i}=x\\right]\\!.\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. Recall that: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{m(x,g)=\\mathbb{E}[o_{u,i}\\cdot e_{u,i}\\mid x_{u,i}=x,g_{u,i}=g],}\\\\ {\\pi(x,g)=\\mathbb{P}\\left(o_{u,i}=1\\mid x_{u,i}=x,g_{u,i}=g\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then, when $g$ equals 1, we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m(x,g=1)=\\mathbb{E}\\left[o_{u,i}\\cdot e_{u,i}\\mid x_{u,i}=x,g_{u,i}=1\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x,g_{u,i}=1,o_{u,i}=1\\right]\\cdot\\mathbb{P}\\left(o_{u,i}=1\\mid x_{u,i}=x,g_{u,i}=1\\right)}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x,g_{u,i}=1\\right]\\cdot\\mathbb{P}\\left(o_{u,i}=1\\mid x_{u,i}=x,g_{u,i}=1\\right)}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]\\cdot\\mathbb{P}\\left(o_{u,i}=1\\mid x_{u,i}=x,g_{u,i}=1\\right)}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]\\cdot\\pi(x,g=1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The first equation is the definition of $m(x,g)$ , the second equation is the law of total probability, and the third equation holds as the conditional independence $e_{u,i}\\perp\\!\\!\\!\\perp o_{u,i}\\mid x_{u,i},g_{u,i}=1$ . The fourth equation holds because $e_{u,i}=L(f(x_{u,i}),r_{u,i})$ is independent of the data type variable $g_{u,i}$ , and the last equation is the definition of $\\pi(x,g)$ . ", "page_idx": 15}, {"type": "text", "text": "Similarly, when $g$ equals 0, the equivalent equation holds: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m(x,g=0)=\\mathbb{E}\\left[o_{u,i}\\cdot e_{u,i}\\mid x_{u,i}=x,g_{u,i}=0\\right]}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x,g_{u,i}=0,o_{u,i}=1\\right]\\cdot\\mathbb{P}\\left(o_{u,i}=1\\mid x_{u,i}=x,g_{u,i}=0\\right)}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x,g_{u,i}=0,o_{u,i}=1\\right]\\cdot\\pi(x,g=0)}\\\\ &{\\qquad\\qquad=\\{\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+\\eta(x)\\}\\cdot\\pi(x,g=0).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The second equation is the law of total probability, the third equation is the definition of $\\pi(x,g)$ , and the last equation is the definition of $\\eta(x)$ which is equivalently expressed as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[e_{u,i}\\ |\\ x_{u,i}=x,g_{u,i}=0,o_{u,i}=1\\right]=\\eta(x)+\\mathbb{E}\\left[e_{u,i}\\ |\\ x_{u,i}=x\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "To sum up, the equation holds: ", "page_idx": 15}, {"type": "equation", "text": "$$\nm(x,g)=\\{\\mathbb{E}\\left[e_{u,i}~\\vert~x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\pi(x,g).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma 2 The relationship between the propensity score $\\pi(x,g)$ , naive error imputation $m(x,g)$ , observation $o_{u,i}$ , naive prediction error $o_{u,i}\\cdot e_{u,i}$ and oracle error imputation $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}\\right]$ is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad o_{u,i}\\cdot e_{u,i}-m(x,g)=\\{\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\left\\{o_{u,i}-\\pi(x,g)\\right\\}+\\xi,}\\\\ &{\\quad\\xi=o_{u,i}\\cdot\\left\\{e_{u,i}-\\{\\mathbb{E}[e_{u,i}\\mid x_{u,i}=x]+(1-g)\\eta(x)\\}\\right\\}w i t h\\;\\mathbb{E}[\\xi\\mid x,g]=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. We prove this Lemma in two steps. Initially, we establish the equality relation in the Lemma $\\begin{array}{r}{o_{u,i}\\cdot e_{u,i}-m(x,g)=\\{\\mathbb{E}\\left[e_{u,i}\\ |\\ x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\{o_{u,i}-\\pi(x,g)\\}+\\xi_{1}\\eta(x,g),}\\end{array}$ . Subsequently, we prove that the conditional expectation of the noise term is zero, i.e., $\\mathbb{E}[\\xi\\mid x,g]=0$ . ", "page_idx": 15}, {"type": "text", "text": "To start with, based on Lemma 1, the equation holds: ", "page_idx": 15}, {"type": "equation", "text": "$$\nm(x,g)=\\{\\mathbb{E}\\left[e_{u,i}~\\vert~x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\pi(x,g).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "According to the definition of $\\xi$ , we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{o_{u,i}\\cdot e_{u,i}=\\xi+o_{u,i}\\cdot\\left\\{\\left\\{\\mathbb{E}[e_{u,i}~|~x_{u,i}=x]+(1-g)\\eta(x)\\right\\}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "image", "img_path": "6CFHg7exjY/tmp/bfb5b48fdf64cc5251de285cce5a6b7534a6ca0553f79959006756ce580c110b.jpg", "img_caption": ["Figure 6: Effects of hidden confounding strength on the YAHOO! R3 dataset. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "The subtraction of the above two equations yields the following: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{o_{u,i}\\cdot e_{u,i}-m(x,g)=\\{\\mathbb{E}\\left[e_{u,i}\\ |\\ x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\left\\{o_{u,i}-\\pi(x,g)\\right\\}+\\xi.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Next we demonstrate that $\\xi$ possesses the zero mean property. Recall that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\xi=o_{u,i}\\cdot\\left\\{e_{u,i}-\\{\\mathbb{E}[e_{u,i}\\mid x_{u,i}=x]+(1-g)\\eta(x)\\}\\right\\}}\\\\ &{\\quad=o_{u,i}\\cdot e_{u,i}-o_{u,i}\\cdot\\left\\{\\left\\{\\mathbb{E}[e_{u,i}\\mid x_{u,i}=x]+(1-g)\\eta(x)\\right\\}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then the conditional expectation of $\\xi$ is: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\xi\\mid x,g\\right]=\\mathbb{E}\\left[o_{u,i}\\cdot e_{u,i}\\mid x,g\\right]-\\mathbb{E}\\left[o_{u,i}\\cdot\\{(\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+(1-g)\\eta(x))\\}\\mid x,g\\right]}\\\\ &{\\qquad\\qquad=m(x,g)-\\mathbb{E}\\left[o_{u,i}\\cdot\\left\\{\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+(1-g)\\eta(x)\\right\\}\\mid x,g\\right]}\\\\ &{\\qquad\\qquad=m(x,g)-\\left\\{\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+(1-g)\\eta(x)\\right\\}\\cdot\\mathbb{E}\\left[o_{u,i}\\mid x_{u,i}=x,g_{u,i}=g\\right]}\\\\ &{\\qquad\\qquad=m(x,g)-\\{\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+(1-g)\\eta(x)\\}\\cdot\\mathbb{P}\\left(o_{u,i}=1\\mid x_{u,i}=x,g_{u,i}=g\\right)}\\\\ &{\\qquad\\qquad=m(x,g)-\\left\\{\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+(1-g)\\eta(x)\\right\\}\\cdot\\pi(x,g)}\\\\ &{\\qquad\\qquad=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The first equation is the definition of $\\xi$ , the second equation is the the definition of $m(x,g)$ , and the third equation holds because $\\mathbb{E}\\left[e_{u,i}\\mid x_{u,i}=x\\right]+(1-g)\\eta(x)$ is a constant given $x$ and $g$ . The fourth equation arises from the fact that the treatment variable $o_{u,i}$ is a binary variable taking values of 0 or 1, and the fifth equation is the definition of $\\pi(x,g)$ . The last equation holds based on Lemma 1. ", "page_idx": 16}, {"type": "text", "text": "A.3 More Experimental Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We introduce more experimental details about feature preparations here. In particular, we first employ Matrix Factorization (MF) [25] to transform the ID-based data format into the feature-based format and regard the derived features as complete features. Next, we simulate the hidden confounding effect induced by insufficient feature collection process through feature masking. The condition $g_{u,i}=1$ is satisfied only when both user and item features are sufficiently preserved, i.e., there are no masked values in their respective feature vectors; otherwise, it equals 0. At the outset, we set the proportion of two types of heterogeneous observational data at 1:1, and the impact of varying proportions is explored in the following in-depth analysis. ", "page_idx": 16}, {"type": "text", "text": "A.4 More Experimental Results ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this subsection, we will present more experimental results that could not be accommodated within the main text due to space limitations. The main text primarily elucidates the results obtained on the KUAIREC dataset. Supplementary to this, the appendix predominantly supplements experimental findings on the YAHOO! R3 dataset, which similarly explores the impact of hidden confounding strength, the proportions of the heterogeneous observational data, and the data sparsity. Apart from these, we conduct an additional investigation into the algorithm runtime on three datasets to explore the computational resource demands of different methods. The findings are as follows. ", "page_idx": 16}, {"type": "image", "img_path": "6CFHg7exjY/tmp/591b4e7d21475b4b4e282531d5fe09b58f77b51389c90e93fc602e29f769c395.jpg", "img_caption": ["Figure 7: Effects of varying proportions of heterogeneous data on the YAHOO! R3 dataset. "], "img_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "6CFHg7exjY/tmp/937931b855f20f723e5c1c27150231c6cbb1675930ca7e03f91b050a53107cd9.jpg", "table_caption": ["Table 3: Effects of training data size on AUC on the KUAIREC and YAHOO! R3 datasets. "], "table_footnote": ["(a) AUC on the KUAIREC dataset "], "page_idx": 17}, {"type": "table", "img_path": "6CFHg7exjY/tmp/dffaa55fad214427926db742dbcf11dc4d97ccbddd940451bb1cbdbd30fccadb.jpg", "table_caption": [], "table_footnote": ["(b) AUC on the YAHOO! R3 dataset "], "page_idx": 17}, {"type": "text", "text": "The Hidden Confounding Strength. Figure 6 demonstrates the debiasing performance with varying hidden confounding strength on the YAHOO! R3 dataset. Similar to the findings observed in the KUAIREC dataset shown in the main text, on the YAHOO! R3 dataset, an increase in hidden confounding strength leads to a decrease in performance across all methods. Meanwhile, the performance deterioration of the BRD-DR is more pronounced, particularly in terms of AUC metric, attributed to the violation of the required assumptions. Furthermore, the proposed MetaDebias demonstrates superior performance across all three evaluation metrics, and its performance shows minimal degradation as the hidden confounding strength increases. This indicates the superiority of our approach over existing methods, and robustness to the hidden confounding strength. ", "page_idx": 17}, {"type": "text", "text": "The Proportion of Heterogeneous Observational Data. Figure 7 shows the prediction performance with varying proportions of heterogeneous observational data on the YAHOO! R3 dataset, where varying data proportions simulate potential data collection scenarios under different real-world conditions. From the figure, we observe an upward trend in the performance of all methods with an increase in the proportion of data without hidden confounding, indicating that the selection bias inherent in such observational data without hidden confounding is more amenable to be addressed. Moreover, MetaDebias outperforms other baselines and exhibits insensitivity to data proportions, which underscores that our method is capable of handling hidden confounding in various possible data combinations and can be broadly applied to a wide range of real-world scenarios. ", "page_idx": 17}, {"type": "text", "text": "The Training Dataset Size. We explore the impact of training set size on prediction performance in Tables 3 and 4, which report the AUC and Recall $@K$ with varying training set size on both KUAIREC and YAHOO! R3 dataset. The presented data represents the mean values obtained from 10 random replicate experiments. We find that MetaDebias demonstrates superior performance across varying training data size, highlighting the efficacy of our method. Meanwhile, MetaDebias exhibits relatively minor fluctuations with changes in dataset volume, particularly evident in the YAHOO! R3 dataset, where the AUC of our method consistently maintains superior performance even amidst substantial variations in training data volume, such as a change from $100\\%$ to $10\\%$ . This further demonstrates the stability of our approach even with small the training data size. ", "page_idx": 17}, {"type": "text", "text": "The Computational Resource Demands. We investigate the algorithm training and inference time on three datasets in Table 5. Despite the involvement of five models in the training process, the comparison with other baseline methods reveals that the training time of the proposed approach is acceptable, particularly on the large-scale dataset KuaiRec. A potential reason for the relatively long training time required by proposed method is that the bi-level optimization process with assumed updates results in multiple gradient computations throughout the training procedure. ", "page_idx": 17}, {"type": "table", "img_path": "6CFHg7exjY/tmp/0fa6b093d41d61fa8979b13b91420e3ddbada5da1e67f3538b1c27ee5019f202.jpg", "table_caption": ["Table 4: Effects of training dataset size on Recall $@K$ on the KUAIREC and YAHOO! R3 datasets. "], "table_footnote": ["(a) Recall $@50$ on the KUAIREC dataset (b) Recall@5 on the YAHOO! R3 dataset "], "page_idx": 18}, {"type": "table", "img_path": "6CFHg7exjY/tmp/5101d7ea1e39d4bdab0a18d37b39c4550f34d4bd2ffba56d3eaffa32d1bde2b1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "6CFHg7exjY/tmp/37b9320c9dfea823d9a08e8fa977c7076ba93540eaf2ff5289108d5d673a7a41.jpg", "table_caption": ["Table 5: Comparison of training time (minutes) and inference time (milliseconds per sample) on the COAT, YAHOO! R3 and KUAIREC datasets. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "A.5 Boarder Impacts ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Recommender systems (RS) serve as an effective tool for mitigating information overload, yielding significant economic benefits by accurately recommending items of interest to individual user. However, in the data collection process of RS, there inevitably exists a significant amount of bias, rendering prediction models trained on the collected historical feedback incapable of capturing users\u2019 true preferences, where selection bias is a particularly common and extensively studied issue. Recently, an increasing number of studies have further focused on and emphasized the impact of hidden confounding, which aims to achieve better prediction performance. In this paper, we propose a more practical solution to effectively address selection bias in the presence of hidden confounding. Specifically, we propose to leverage heterogeneous observational datasets, which is more readily available in real-world scenarios, while not imposing additional assumptions or requiring RCT data. This indicates that our method has the potential to be applied in real-world recommendation scenarios, offering opportunities to enhance economic benefits for businesses. ", "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The abstract and introduction include the claims made in the paper, and the contributions are summarized in introduction. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: We discuss the limitations of the paper in the conclusion in Section5 ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The paper provides the full set of assumptions and complete proofs for the theoretical results in Appendix A.2. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The paper fully discloses all the information needed to reproduce the main experimental results of the paper in the Dataset and Experimental Details in Section 4. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The paper provides open access to the data and code. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: The paper specifies all the training and test information including datasets, preprocessing, experimental protocols and details in Section 4. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The paper reports the experimental results accompanied by error bars and conducts statistical significance test using the paired-t-test in Section 4. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The paper provides sufficient information on the computer resources (type of compute workers, memory) in Section 4. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The research conducted in the paper conforms, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We discuss the potential societal impacts of the work in Appendix A.5. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The creator or original owner of the assets (e.g., code, data, models) used in the paper is properly credited, and the license and terms of use are explicitly mentioned and appropriately respected. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 24}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}]