[{"figure_path": "LR1nnsD7H0/tables/tables_9_1.jpg", "caption": "Table 1: Decoding performance (mean \u00b1 sem) for the different models.", "description": "This table shows the per-subject R-squared values and training times for two different models: 'Variant' and 'Ours'. The 'Variant' model represents an alternative architecture with a single 2D attention mechanism, while 'Ours' refers to the proposed model in the paper with separate attention mechanisms in time and electrode dimensions. The results highlight that the proposed model ('Ours') achieves better decoding performance with significantly reduced training time compared to the 'Variant' model.", "section": "4.6.2 Model variants"}, {"figure_path": "LR1nnsD7H0/tables/tables_16_1.jpg", "caption": "Table 2: Model inference time on different hardware. Units are in msec.", "description": "This table shows the inference time of the multi-session, multi-subject model on two different machines: a commercial laptop and a server.  The results are given for both CPU and GPU, demonstrating the model's real-time applicability.", "section": "A.4.1 Model real-time applicability"}, {"figure_path": "LR1nnsD7H0/tables/tables_17_1.jpg", "caption": "Table 3: Model performance using different positional encoding schemes.", "description": "This table presents the per-subject R-squared values achieved by the model using three different positional encoding schemes: the scheme proposed by Vaswani et al. [2017], a Fourier-based scheme using MNI coordinates, and the RBF-based scheme proposed in the paper.  The results show that the RBF-based scheme proposed in the paper performs comparably to the Fourier-based approach, and both significantly outperform the Vaswani et al. scheme.", "section": "A.4.3 Comparison of our proposed spatial positional encoding against other approaches"}]