[{"figure_path": "ypFgcT147Z/tables/tables_2_1.jpg", "caption": "Table 1: Similarity invariant to spatial permutations is better at predicting if the class probabilities will be similar. PI: Permutation Invariant", "description": "This table presents the Pearson correlation between the Jensen-Shannon Divergence (JSD) of predicted class probabilities and the representational similarity (using different kernels: Cosine, Inner Product, RBF) for various architectures (ResNet18, ResNet50, ResNet101, ConvNextV2-Base, ViT-B/16, ViT-L/32, DinoV2-Giant).  It compares the correlation for both permutation-invariant and non-invariant similarity measures to show the impact of spatial permutation invariance on the prediction accuracy.", "section": "4.3 Output similarity vs Representational Similarity"}, {"figure_path": "ypFgcT147Z/tables/tables_7_1.jpg", "caption": "Table 1: Similarity invariant to spatial permutations is better at predicting if the class probabilities will be similar. PI: Permutation Invariant", "description": "This table presents the Pearson correlation between the representational similarity (using different kernels: Cosine, Inner Product, RBF) and the Jensen-Shannon Divergence (JSD) of the predicted class probabilities for various architectures (ResNets, ConvNeXt, ViTs, DinoV2).  Both permutation invariant and non-invariant similarity measures are compared to show the impact of spatial permutation invariance on predicting class probability similarity.  Higher negative correlations indicate a stronger relationship, where similar representations lead to similar predicted probabilities.", "section": "4.3 Output similarity vs Representational Similarity"}, {"figure_path": "ypFgcT147Z/tables/tables_16_1.jpg", "caption": "Table 1: Similarity invariant to spatial permutations is better at predicting if the class probabilities will be similar. PI: Permutation Invariant", "description": "This table presents the Pearson correlation between the representational similarity (using different kernels: cosine similarity, inner product, and RBF) and the Jensen-Shannon Divergence (JSD) of predicted class probabilities for various architectures (ResNet18, ResNet50, ResNet101, ConvNextV2-Base, ViT-B/16, ViT-L/32, and DinoV2-Giant).  It compares the performance with and without permutation invariance to highlight the impact of spatial alignment on the prediction similarity.", "section": "4.3 Output similarity vs Representational Similarity"}, {"figure_path": "ypFgcT147Z/tables/tables_24_1.jpg", "caption": "Table 3: Retrieval results for the Cityscapes Dataset. We retrieve the most similar image according to RSMs and calculate the IoU of query semantic classes and retrieved semantic classes. Overall query images used are validation images of size N=500 and the database are the training images of size N=2975. Differences between metrics are low, due to many images containing a large number of classes and the lack of instance label information. Despite this, permutation invariance improves Cosine Sim and RBF retrieval performance consistently, with the Inner Product showing mixed results.", "description": "This table presents the quantitative results of a retrieval experiment using the Cityscapes dataset. It compares the performance of different similarity metrics (Cosine Similarity, Inner Product, RBF) with and without permutation invariance. The results show that permutation invariance consistently improves retrieval performance, especially for Cosine Similarity and RBF.", "section": "4.2 Similarity-based retrieval"}, {"figure_path": "ypFgcT147Z/tables/tables_25_1.jpg", "caption": "Table 1: Similarity invariant to spatial permutations is better at predicting if the class probabilities will be similar. PI: Permutation Invariant", "description": "This table presents the Pearson and Spearman correlations between the representational similarity (using different kernels and with/without permutation invariance) and the similarity of predicted class probabilities for various ImageNet classifiers.  Higher negative correlations indicate stronger agreement between the two types of similarity.", "section": "4.3 Output similarity vs Representational Similarity"}, {"figure_path": "ypFgcT147Z/tables/tables_27_1.jpg", "caption": "Table 5: We compare different implementations of the optimal Jonker-Volgenant algorithm [8] against our linearly scaling Batch-Optimal approximation and no matching. The table presents average run-times per pair (T) and average similarity relative to the optimal value (k) for 1,000 randomly chosen image pairs. Utilizing representations of varying sizes from a ResNet101 trained on Tiny-ImageNet, the optimal solutions are reported relative to the maximum similarity achieved by the optimal algorithms. The Batch-Optimal approximation demonstrates a substantial fraction of optimal matching performance with significantly improved scaling.", "description": "This table compares the runtime and matching quality of different algorithms for solving the assignment problem, a key step in the proposed semantic RSM calculation.  It shows that a proposed approximation algorithm, Batch-Optimal, achieves near-optimal matching quality with significantly reduced runtime compared to exact methods, especially beneficial for larger spatial dimensions. The 'No Match' row serves as a baseline representing the scenario without any matching.", "section": "4.4 Optimizing runtime"}]