[{"figure_path": "ypFgcT147Z/figures/figures_4_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares spatio-semantic RSMs and semantic RSMs across different layers of a ResNet18 model trained on TinyImageNet.  Partially overlapping image crops of the same image are used as input.  The top-middle shows the traditional spatio-semantic RSMs, which are sensitive to spatial shifts. The bottom-middle shows the proposed semantic RSMs, which are invariant to spatial permutations. The right side shows the distribution of similarity values for each type of RSM.  The results demonstrate that semantic RSMs are better at capturing semantic similarity, even when the images are translated.", "section": "3 The Semantic Representational Similarity Matrix"}, {"figure_path": "ypFgcT147Z/figures/figures_5_1.jpg", "caption": "Figure 3: Relaxing the constraint of spatial alignment leads to better retrieval. We leverage general feature extractors to embed images of the EgoObjects dataset. We then compare these embeddings either with or without permutation invariance. PI: Permutation Invariant", "description": "This figure shows the retrieval F1@1 scores for different architectures (Dinov2-Giant, CLIP, BiT-50, CLIPSeg, SAM) and similarity metrics (cosine kernel, permutation-invariant cosine kernel, linear kernel, permutation-invariant linear kernel, RBF kernel, permutation-invariant RBF kernel).  The results demonstrate that incorporating permutation invariance improves retrieval performance across all architectures and metrics, highlighting the benefit of decoupling semantic similarity from spatial alignment.", "section": "4.1 Translation sensitivity"}, {"figure_path": "ypFgcT147Z/figures/figures_6_1.jpg", "caption": "Figure 4: Retrieving by permutation invariant similarity returns similar scenes of different spatial geometry. We visualize the top 3 most similar images according to two exemplary query images for SAM ViT/B32.", "description": "This figure shows the top 3 most similar images retrieved using both cosine similarity and permutation-invariant cosine similarity for two example query images.  The results demonstrate that permutation-invariant similarity better captures the semantic similarity between scenes, even when their spatial layouts differ significantly.  This highlights the effectiveness of the proposed semantic RSM approach in overcoming the limitations of traditional spatio-semantic RSMs, which are highly sensitive to spatial alignment.", "section": "4.2 Similarity-based retrieval"}, {"figure_path": "ypFgcT147Z/figures/figures_8_1.jpg", "caption": "Figure 5: Approximative algorithms yield comparable matching quality to optimal algorithms. The ratio of similarity from various approximations relative to maximal semantic similarity is visualized across multiple layers of a ResNet18.", "description": "This figure shows the performance of three approximate algorithms for finding optimal permutations compared to the optimal Hungarian algorithm.  The algorithms are evaluated based on the ratio of their achieved similarity to the similarity achieved by the optimal algorithm.  The results demonstrate that the Batch-Optimal approximation provides a good balance between accuracy and computational efficiency, especially for layers with larger spatial dimensions.  This highlights that reasonably accurate approximate algorithms can be used to reduce computation time significantly without severely impacting accuracy.", "section": "4.4 Optimizing runtime"}, {"figure_path": "ypFgcT147Z/figures/figures_8_2.jpg", "caption": "Figure 6: Relative similarity is not isotropic. When aligning semantic concepts we observe that similarity changes heterogeneously, indicating that some pairs of samples have more spatially misaligned semantic concepts than others.", "description": "This figure demonstrates that the relative similarity between samples is not uniform across all spatial locations.  Some pairs of samples show greater similarity despite having spatially misaligned semantic concepts, suggesting that semantic similarity is not solely determined by spatial alignment but other factors also contribute.", "section": "3.1 Decoupling Localization and Semantic Content"}, {"figure_path": "ypFgcT147Z/figures/figures_13_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares spatio-semantic RSMs and semantic RSMs across different layers of a ResNet18 model trained on TinyImageNet.  It uses partially overlapping crops of the same image to highlight the difference. Spatio-semantic RSMs struggle to identify translated versions of the same image due to their dependence on spatial alignment, while semantic RSMs effectively detect the similarity, demonstrating their spatial invariance.", "section": "3 The Semantic Representational Similarity Matrix"}, {"figure_path": "ypFgcT147Z/figures/figures_14_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares the performance of spatio-semantic RSMs and semantic RSMs in capturing similarity between images, especially when spatial alignment is altered (e.g., through translation).  Using TinyImageNet, the authors generate image crops with varying degrees of overlap.  The results show that semantic RSMs (the authors' proposed method) are more robust to changes in spatial location and accurately capture semantic similarity even when images are translated, unlike the traditional spatio-semantic RSMs.", "section": "3 The Semantic Representational Similarity Matrix"}, {"figure_path": "ypFgcT147Z/figures/figures_17_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares spatio-semantic and semantic RSMs across different layers of a ResNet18 model trained on TinyImageNet.  It shows that semantic RSMs (proposed method) are more effective at capturing similarity between images, even when they are spatially shifted, unlike spatio-semantic RSMs.", "section": "Experiments: Semantic vs Spatio-Semantic RSMs"}, {"figure_path": "ypFgcT147Z/figures/figures_18_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares the performance of spatio-semantic RSMs and semantic RSMs (proposed in the paper) across different layers of a ResNet18 model trained on TinyImageNet.  Partially overlapping image crops are used as input.  The results show that semantic RSMs are superior at capturing semantic similarity, even when images are translated, unlike spatio-semantic RSMs which are sensitive to spatial alignment.", "section": "Experiments: Semantic vs Spatio-Semantic RSMs"}, {"figure_path": "ypFgcT147Z/figures/figures_19_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares spatio-semantic and semantic RSMs across different layers of a ResNet18 model trained on TinyImageNet.  Spatio-semantic RSMs show low similarity between translated versions of the same image because they couple semantic similarity with spatial alignment. In contrast, semantic RSMs are invariant to spatial permutation and successfully capture semantic similarity even when images are translated, demonstrated through enhanced off-diagonal values in the RSMs and distinct similarity value distributions.", "section": "Experiments: Semantic vs Spatio-Semantic RSMs"}, {"figure_path": "ypFgcT147Z/figures/figures_20_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares spatio-semantic RSMs and semantic RSMs across different layers of a ResNet18 model trained on TinyImageNet.  It shows that semantic RSMs, which are invariant to spatial permutations, are better at capturing semantic similarity between images, even when they are translated versions of each other, unlike the spatio-semantic RSMs.", "section": "Experiments: Semantic vs Spatio-Semantic RSMs"}, {"figure_path": "ypFgcT147Z/figures/figures_21_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares spatio-semantic and semantic RSMs across different layers of a ResNet18 model trained on TinyImageNet.  Spatio-semantic RSMs show low similarity between translated versions of the same image, while semantic RSMs show high similarity, highlighting their invariance to spatial shifts.", "section": "3 The Semantic Representational Similarity Matrix"}, {"figure_path": "ypFgcT147Z/figures/figures_22_1.jpg", "caption": "Figure 1: Current spatio-semantic RSMs couple semantic similarity with spatial alignment. Our proposal focuses solely on measuring semantic similarity. We achieve this by determining the optimal permutation between two representations and introducing sample-wise permutation invariance.", "description": "This figure illustrates the difference between traditional spatio-semantic RSMs and the proposed semantic RSMs. Spatio-semantic RSMs consider both semantic similarity and spatial alignment when comparing representations, leading to sensitivity to spatial shifts.  In contrast, semantic RSMs are invariant to spatial permutations, focusing solely on semantic similarity by finding the optimal permutation between representations.", "section": "3 The Semantic Representational Similarity Matrix"}, {"figure_path": "ypFgcT147Z/figures/figures_23_1.jpg", "caption": "Figure 2: Semantic RSMs capture similarity independent of spatial localization, in contrast to current spatio-semantic RSMs. We utilize Tiny-ImageNet to generate partially overlapping crops of the same sample (left) and calculate RSMs for a trained ResNet18 model. The plot displays the original spatio-semantic RSMs (middle top) and our proposed semantic RSMs (middle bottom) across various layers for a single batch. Additionally, the distribution of similarity values over multiple batches is shown (right). The results indicate that spatio-semantic RSMs struggle to detect largely identical but translated images, while semantic RSMs exhibit an enhanced off-diagonal in the RSMs and a significant gap between distributions. This demonstrates the capability of our method to detect the same semantics even when translated.", "description": "This figure compares the performance of spatio-semantic RSMs and semantic RSMs in capturing similarity between images, especially when those images are translated versions of each other.  It uses TinyImageNet and a ResNet18 model. The results show that semantic RSMs, which are invariant to spatial permutations, are significantly better at capturing semantic similarity, even when spatial alignment is different.", "section": "Experiments: Semantic vs Spatio-Semantic RSMs"}, {"figure_path": "ypFgcT147Z/figures/figures_29_1.jpg", "caption": "Figure 15: The dissimilarity between semantic and spatio-semantic RSMs decreases with shrinking spatial extent. Comparison of semantic and spatio-semantic Representational Similarity Matrices (RSMs) for the same model. The dissimilarity in early layers decreases with decreasing spatial extent, as illustrated by Centered Kernel Alignment (CKA) values. The left and middle panel shows the CKA comparison between all layers, while the right panels visualize the heatmap\u2019s diagonal, emphasizing the evolving similarity trend from early to late layers.", "description": "This figure compares semantic and spatio-semantic RSMs for the same model using CKA. It shows that the dissimilarity between the two types of RSMs decreases as the spatial extent shrinks (moving from earlier to later layers).  The left and middle panels show a complete layer-by-layer comparison via CKA heatmaps, while the right panel focuses on the diagonal of the CKA heatmaps to highlight the trend of decreasing dissimilarity.", "section": "G Semantic RSMs and CKA \u2013 Qualitative changes"}, {"figure_path": "ypFgcT147Z/figures/figures_29_2.jpg", "caption": "Figure 15: The dissimilarity between semantic and spatio-semantic RSMs decreases with shrinking spatial extent. Comparison of semantic and spatio-semantic Representational Similarity Matrices (RSMs) for the same model. The dissimilarity in early layers decreases with decreasing spatial extent, as illustrated by Centered Kernel Alignment (CKA) values. The left and middle panel shows the CKA comparison between all layers, while the right panels visualize the heatmap's diagonal, emphasizing the evolving similarity trend from early to late layers.", "description": "This figure compares semantic and spatio-semantic Representational Similarity Matrices (RSMs) for the same model using Centered Kernel Alignment (CKA).  It shows that the dissimilarity between the two types of RSMs decreases as the spatial extent of the representations shrinks (i.e., in later layers of a CNN).  The visualizations include heatmaps of the CKA values for all layers and line plots showing the diagonal of the CKA matrices, highlighting the trend of decreasing dissimilarity in later layers.", "section": "G Semantic RSMs and CKA \u2013 Qualitative changes"}]