{"references": [{"fullname_first_author": "Adrien Bardes", "paper_title": "Vicreg: Variance-invariance-covariance regularization for self-supervised learning", "publication_date": "2022-04-25", "reason": "This paper introduces VICReg, a self-supervised learning method used in the experiments for comparing memorization efficiency across different models."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-10-27", "reason": "This paper introduces DINO, another self-supervised learning model used in the experiments for measuring memorization."}, {"fullname_first_author": "Casey Meehan", "paper_title": "Do ssl models have d\u00e9j\u00e0 vu? a case of unintended memorization in self-supervised learning", "publication_date": "2023-12-01", "reason": "This paper introduces the \"d\u00e9j\u00e0 vu\" method for measuring memorization, which is the main method analyzed and improved in the current paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models from Natural Language Supervision", "publication_date": "2021-07-12", "reason": "This paper introduces CLIP, a vision-language model whose memorization is also measured in the experiments."}, {"fullname_first_author": "Bargav Jayaraman", "paper_title": "D\u00e9j\u00e0 vu memorization in vision-language models", "publication_date": "2024-01-01", "reason": "This paper extends the d\u00e9j\u00e0 vu method to vision-language models, providing a relevant baseline for the current work."}]}