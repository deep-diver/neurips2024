[{"figure_path": "bMbteQRhDI/figures/figures_8_1.jpg", "caption": "Figure 2: Histograms of various submodel extraction methods on CIFAR-10 under four submodel sizes. Each histogram shows the number of clients achieving different levels of test accuracy.", "description": "This figure shows the distribution of test accuracy achieved by different clients using four different submodel sizes (1/64, 1/16, 1/4, 1) for four different model-heterogeneous federated learning methods (HeteroFL, FedRolex, ScaleFL, and FIARSE).  The x-axis represents the test accuracy, and the y-axis represents the number of clients achieving that level of accuracy.  It provides a visual comparison of the performance of each method in terms of the distribution of client accuracy.", "section": "6.2 Submodel Performance on Local Dataset"}, {"figure_path": "bMbteQRhDI/figures/figures_9_1.jpg", "caption": "Figure 3: Comparison of test accuracy across communication rounds for different submodel extraction strategies under four varying model sizes (1/64, 1/16, 1/4, 1/0) on global test datasets of CIFAR-10 (upper, a - d) and CIFAR-100 (lower, e \u2013 h).", "description": "This figure compares the performance of four different submodel extraction methods (HeteroFL, FedRolex, ScaleFL, and FIARSE) on CIFAR-10 and CIFAR-100 datasets across four different model sizes (1/64, 1/16, 1/4, and 1.0).  The x-axis represents the communication rounds, and the y-axis represents the test accuracy.  The plots show the test accuracy trend over communication rounds for each method and model size.  The shaded areas around the lines likely represent confidence intervals or standard deviations indicating variability in the results across different runs. The results suggest how different methods affect the model training over time, highlighting FIARSE's superior and faster convergence in achieving higher test accuracy.", "section": "Experiments"}, {"figure_path": "bMbteQRhDI/figures/figures_9_2.jpg", "caption": "Figure 3: Comparison of test accuracy across communication rounds for different submodel extraction strategies under four varying model sizes (1/64, 1/16, 1/4, 1/0) on global test datasets of CIFAR-10 (upper, a - d) and CIFAR-100 (lower, e \u2013 h).", "description": "This figure compares the performance of four different submodel extraction methods (HeteroFL, FedRolex, ScaleFL, and FIARSE) on CIFAR-10 and CIFAR-100 datasets.  The test accuracy is plotted against the number of communication rounds for four different model sizes (1/64, 1/16, 1/4, and 1.0).  The plots show how the test accuracy evolves over the communication rounds and how the performance varies across different model sizes for each method.  The upper panel shows the results for CIFAR-10, while the lower panel shows the results for CIFAR-100.", "section": "Experiments"}, {"figure_path": "bMbteQRhDI/figures/figures_28_1.jpg", "caption": "Figure 2: Histograms of various submodel extraction methods on CIFAR-10 under four submodel sizes. Each histogram shows the number of clients achieving different levels of test accuracy.", "description": "The figure displays histograms showing the distribution of test accuracy achieved by different clients using four different model sizes (1/64, 1/16, 1/4, 1.0) for four different submodel extraction methods (HeteroFL, FedRolex, ScaleFL, and FIARSE). Each bar in the histogram represents a range of test accuracy, and the height of the bar indicates the number of clients that achieved test accuracy within that range.  This visualization helps to compare the performance of the different methods in terms of how well they adapt to clients with different computational capabilities, represented by the varying model sizes. It shows the distribution of successful clients which provides insights into the effectiveness of each submodel extraction method.", "section": "6.2 Submodel Performance on Local Dataset"}, {"figure_path": "bMbteQRhDI/figures/figures_28_2.jpg", "caption": "Figure 1: Three types of submodel extraction for model training, i.e., static, dynamic, and importance-aware (ours). The figure demonstrates the global model on the server and the local models of two consecutive rounds on a client. Note that solid lines represent the parameters preserved in the local model, while dash lines indicate the parameters excluded from the local model. In importance-aware submodel extraction, we present the importance of the parameters via the line thickness.", "description": "This figure compares three different submodel extraction methods in federated learning: static, dynamic, and importance-aware (the proposed FIARSE method).  It visually illustrates how a global model is partitioned into submodels for different clients across two consecutive training rounds (t and t+1).  Solid lines represent parameters included in the client's submodel, while dashed lines show excluded parameters.  The thickness of the lines in the importance-aware approach indicates the relative importance of the parameters.", "section": "Introduction"}, {"figure_path": "bMbteQRhDI/figures/figures_29_1.jpg", "caption": "Figure 3: Comparison of test accuracy across communication rounds for different submodel extraction strategies under four varying model sizes (1/64, 1/16, 1/4, 1/0) on global test datasets of CIFAR-10 (upper, a - d) and CIFAR-100 (lower, e \u2013 h).", "description": "The figure shows the test accuracy of different submodel extraction methods (HeteroFL, FedRolex, ScaleFL, and FIARSE) across communication rounds for four different model sizes (1/64, 1/16, 1/4, 1.0) on CIFAR-10 and CIFAR-100 datasets.  The upper part shows results for CIFAR-10 and the lower part for CIFAR-100.  Each sub-figure shows the accuracy trend for a specific model size.", "section": "Experiments"}]