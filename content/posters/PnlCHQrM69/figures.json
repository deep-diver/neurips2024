[{"figure_path": "PnlCHQrM69/figures/figures_2_1.jpg", "caption": "Figure 1: SEMCODER's training strategy with different modalities of program semantics. We specify the overall objective of a task, i.e., the approximate semantics (blue box), such as \u201cretrieves potential energies of atoms and performs sorting", "description": "This figure illustrates the training strategy employed by SEMCODER.  It highlights the incorporation of multiple modalities of program semantics during training.  These modalities include approximate semantics (high-level description of the task), symbolic semantics (code representation), abstract semantics (key properties and constraints of the code), and operational semantics (step-by-step execution simulation). The figure uses a visual representation with boxes to depict the different semantic levels and how they're connected in the training process.  It shows how the model learns to link static code with dynamic execution behavior.", "section": "4 SEMCODER: Learning Comprehensive Semantics"}, {"figure_path": "PnlCHQrM69/figures/figures_4_1.jpg", "caption": "Figure 1: SEMCODER's training strategy with different modalities of program semantics. We specify the overall objective of a task, i.e., the approximate semantics (blue box), such as \u201cretrieves potential energies of atoms and performs sorting", "description": "This figure illustrates SEMCODER's training strategy, showcasing how different modalities of program semantics are incorporated.  Approximate semantics (high-level description of the task), symbolic semantics (code representation), abstract semantics (key properties and constraints), and operational semantics (step-by-step execution simulation) are all included in the training process.  This multi-faceted approach enables SEMCODER to develop a more comprehensive understanding of program semantics, bridging the gap between static code analysis and dynamic execution reasoning.", "section": "4 SEMCODER: Learning Comprehensive Semantics"}, {"figure_path": "PnlCHQrM69/figures/figures_16_1.jpg", "caption": "Figure 3: SEMCODER-S's zero-shot performance of self-refinement at each time step with different sampling strategies.", "description": "This figure shows the performance of the SEMCODER-S model in a self-refinement task, where the model iteratively refines its code based on test results.  It specifically demonstrates zero-shot performance across different sampling strategies ('greedy', 'temp=0.2', 'temp=0.8') on two code generation benchmarks (HumanEval and MBPP) over five refinement steps.  The graphs illustrate how the model's pass@1 score evolves with each refinement iteration under various sampling methods.  This visualization helps assess the model's ability to improve code quality through iterative debugging and self-correction. The 'temp' parameter likely refers to temperature settings for sampling during generation, influencing the randomness of the output and potentially affecting the refinement process.", "section": "Experiments"}, {"figure_path": "PnlCHQrM69/figures/figures_17_1.jpg", "caption": "Figure 4: PYX: Execution-aware Training Data Collection Strategy", "description": "This figure illustrates the three-step process used to create the PYX dataset.  Step I focuses on synthesizing executable code using an LLM, filtering out non-executable samples.  Step II generates additional inputs through type-aware mutation and LLM-based generation and incorporates test cases to gather execution traces. Step III introduces bugs, generating faulty execution traces and debugging rationales, ultimately building the PYX-R dataset for debugging and self-refinement training.", "section": "Curating Executable Code Dataset"}, {"figure_path": "PnlCHQrM69/figures/figures_18_1.jpg", "caption": "Figure 5: Edit similarities between PYX and two popular benchmarks", "description": "This figure shows the distribution of edit similarities between the PYX dataset and two popular benchmarks (OSS-Instruct HumanEval and OSS-Instruct MBPP).  The x-axis represents the edit similarity, a measure of how similar the code samples in PYX are to the code samples in the benchmarks.  The y-axis represents the probability density. The figure visually demonstrates that the PYX dataset is distinct from the benchmarks, with minimal overlap in edit similarity scores, indicating the dataset's unique characteristics and avoiding potential data leakage.", "section": "3 PYX: Semantic-aware Training Dataset"}, {"figure_path": "PnlCHQrM69/figures/figures_18_2.jpg", "caption": "Figure 1: SEMCODER's training strategy with different modalities of program semantics. We specify the overall objective of a task, i.e., the approximate semantics (blue box), such as \u201cretrieves potential energies of atoms and performs sorting", "description": "This figure illustrates the training strategy used for SEMCODER, highlighting its use of different modalities of program semantics.  Approximate semantics (blue box) gives the overall objective.  Symbolic semantics (pink box) shows the code solution.  Key properties and constraints (red box) represent abstract code semantics.  Operational semantics (yellow box)  includes test cases and dynamic aspects of the program execution.  The figure shows how SEMCODER learns from all of these aspects to not only generate code but also reason comprehensively about the semantics. The approach incorporates high-level functional descriptions, local execution effects, and overall input/output behavior, linking static code with dynamic execution.", "section": "3 PYX: Semantic-aware Training Dataset"}]