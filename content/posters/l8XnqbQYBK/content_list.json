[{"type": "text", "text": "Toward Conditional Distribution Calibration in Survival Prediction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Shi-ang Qi 1, Yakun Yu 2, Russell Greiner 1 3 ", "page_idx": 0}, {"type": "text", "text": "1Computing Science, University of Alberta, Edmonton, Canada 2Electrical Computer Engineering, University of Alberta, Edmonton, Canada 3Alberta Machine Intelligence Institute, Edmonton, Canada {shiang, yakun2, rgreiner}@ualberta.ca ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Survival prediction often involves estimating the time-to-event distribution from censored datasets. Previous approaches have focused on enhancing discrimination and marginal calibration. In this paper, we highlight the significance of conditional calibration for real-world applications \u2013 especially its role in individual decision-making. We propose a method based on conformal prediction that uses the model\u2019s predicted individual survival probability at that instance\u2019s observed time. This method effectively improves the model\u2019s marginal and conditional calibration, without compromising discrimination. We provide asymptotic theoretical guarantees for both marginal and conditional calibration and test it extensively across 15 diverse real-world datasets, demonstrating the method\u2019s practical effectiveness and versatility in various settings. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Individual survival distribution (ISD), or time-to-event distribution, is a probability distribution that describes the times until the occurrence of a specific event of interest for an instance, based on information about that individual. Accurately estimating ISD is essential for effective decisionmaking and clinical resource allocation. However, a challenge in learning such survival prediction models is training on datasets that include censored instances, where we only know a lower bound of their time-to-event. ", "page_idx": 0}, {"type": "text", "text": "Survival models typically focus on two important but distinct properties during optimization and evaluation: (i) discrimination measures how well a model\u2019s relative predictions between individuals align with the observed order [1, 2], which is useful for pairwise decisions such as prioritizing treatments; (ii) calibration assesses how well the predicted survival probabilities match the actual distribution of observations [3, 4], supporting both individual-level (e.g., determining high-risk treatments based on the probability) and group-level (e.g., allocating clinical resources) decisions. Some prior research has sought to improve calibration by integrating a calibration-specific loss during optimization [5, 6, 4]. However, these often produce models with poor discrimination [7, 8], limiting their utility in scenarios where precise pairwise decisions are critical. ", "page_idx": 0}, {"type": "text", "text": "Furthermore, previous studies have typically addressed calibration in a marginal sense \u2013 i.e., assessing whether probabilities align with the actual distribution across the entire population. However, for many applications, marginal calibration may be inadequate \u2013 we often require that predictions are correctly calibrated, conditional on any combination of features. This can be helpful for making more precise clinical decisions for individuals and groups. For example, when treating an overweight male, a doctor might decide on cardiovascular surgery using a model calibrated for both overweight and male. Note this might lead to a different decision that one based on a model that was calibrated for all patients. Similarly, a hospice institution may want to allocate nursing care based on a model that generates calibrated predictions for elderly individuals. This also aligns with the fairness perspective [9], where clinical decision systems should guarantee equalized calibration performance across any protected groups. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Contributions To overcome these challenges, we introduce the CSD-iPOT framework, a postprocessing approach built upon conformal prediction [10\u201312, 8] that uses the Individual survival Probability at Observed Time (iPOT) as conformity scores and generates conformalized survival distributions. The method has 3 important properties: (i) this conformity score naturally conforms to the definition in distribution calibration in survival analysis [3]; (ii) it also captures the distribution variance of the ISD, therefore is adaptive to the features; and (iii) the method is computationally friendly for survival analysis models. Our key contributions are: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Motivating the use of conditional distribution calibration in survival analysis, and proposing a metric $\\mathrm{(Cal_{ws}}$ , defined in Section 4) to evaluate this property.   \n\u2022 Developing the CSD-iPOT framework, to accommodate censorship. The method effectively solves some issues of previous conformal methods wrt inaccurate Kaplan-Meier estimation;   \n\u2022 Theoretically proving that CSD-iPOT asymptotically guarantees marginal and conditional distribution calibration under some specified assumptions;   \n\u2022 Conducting extensive experiments across 15 datasets, showing that CSD-iPOT improves both marginal and conditional distribution calibration without sacrificing discriminative ability;   \n\u2022 Demonstrating that CSD-iPOT is computationally more efficient than prior conformal method on survival analysis. ", "page_idx": 1}, {"type": "text", "text": "2 Problem statement and Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Notation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "A survival dataset $\\mathbf{\\mathcal{D}}=\\{(\\mathbf{\\boldsymbol{x}}_{i},t_{i},\\delta_{i})\\}_{i=1}^{n}$ contains $n$ tuples, each containing covariates $\\pmb{x}_{i}\\in\\mathbb{R}^{d}$ , an observed time $t_{i}\\in\\mathbb{R}_{+}$ , and an event in=dicator $\\delta_{i}\\in\\{0,1\\}$ . For each subject, there are two potential times of interest: the event time $e_{i}$ and the censoring time $c_{i}$ . However, only the earlier of the two is observable. We assign $t_{i}\\triangleq\\operatorname*{min}\\{e_{i},c_{i}\\}$ and $\\delta_{i}\\triangleq\\mathbb{1}[e_{i}\\leq c_{i}]$ , so $\\delta_{i}=0$ means the event has not happened by $t_{i}$ (right-censored) and $\\delta_{i}=1$ indicates the event occurred at $t_{i}$ (uncensored). Let $\\mathcal{T}$ denote the set of indices in dataset $\\mathcal{D}$ , then we can use $i\\in\\mathcal{Z}$ to represent $(x_{i},t_{i},\\delta_{i})\\in\\mathcal{D}$ . ", "page_idx": 1}, {"type": "text", "text": "Our objective is to estimate the Individualized Survival Distribution (ISD), $S(t\\mid\\mathbf{x}_{i})=\\mathbb{P}(e_{i}>t\\mid\\mathbf{X}=$ $\\pmb{x}_{i}$ ), which represents the survival probabilities of the $i$ -th subject for any time $t\\geq0$ . ", "page_idx": 1}, {"type": "text", "text": "2.2 Notions of calibration in survival analysis ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Calibration measures the alignment between the predictions against observations. Consider distrreiabluiztiaotino cnasl iobfr $\\boldsymbol{e}_{i}~|~\\boldsymbol{x}_{i}$ t(hcea liln tdhiveimd u $e_{i}^{(1)},e_{i}^{(2)},\\ldots)$ ,  otrhaecnl et hken oswurs vtihvea lt rpureo IbSabDi $S(t\\mid x_{i})$ s, earnvde dd rtiamwes $\\{S(e_{i}^{(m)}\\mid x_{i})\\}_{m}$ should be distributed across a standard uniform distribution $\\mathcal{U}_{[0,1]}$ (probability integral theorem [13]). However, in practice, for each unique $\\pmb{x}_{i}$ , there is only o[ne ]realization of $\\boldsymbol{e}_{i}\\mid\\bar{\\boldsymbol{x}}_{i}$ , meaning we cannot check the calibration in this individual manner. ", "page_idx": 1}, {"type": "text", "text": "To solve this, Haider et al. [3] proposed marginal calibration, which holds if the predicted survival probabilities at event times $e_{i}$ over the $\\pmb{x}_{i}$ in the dataset, $\\{\\hat{S}(e_{i}\\mid\\mathbf{x}_{i})\\}_{i\\in\\mathbb{Z}}$ , matches $\\mathcal{U}_{[0,1]}$ . ", "page_idx": 1}, {"type": "text", "text": "Definition 2.1. For uncensored dataset, a model has perfect marginal calibration iff $\\forall\\,\\left[\\rho_{1},\\rho_{2}\\right]\\,\\subset$ $[0,1]$ , ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left.\\hat{S}(e_{i}\\mid x_{i})\\in\\left[\\rho_{1},\\rho_{2}\\right],\\,i\\in\\mathcal{Z}\\right|\\delta_{i}=1\\right)\\ =\\ \\mathbb{E}_{i\\in\\mathcal{Z}}\\ \\mathbb{1}\\left[\\left.\\hat{S}(e_{i}\\mid x_{i})\\in\\left[\\rho_{1},\\rho_{2}\\right]\\right|\\delta_{i}=1\\right]\\ =\\ \\rho_{2}-\\rho_{1}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "We can \u201cblur\u201d each censored subject uniformly over the probability intervals after the survival probability at censored time $\\hat{S}(c_{i}\\mid{\\pmb x}_{i})$ [3] (see the derivation in Appendix A): ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left(\\hat{S}(e_{i}\\mid x_{i})\\in\\left[\\rho_{1},\\rho_{2}\\right]\\Big|\\,\\delta_{i}=0\\right)=\\frac{\\left(\\hat{S}(t_{i}|x_{i})-\\rho_{1}\\right)\\mathbb{I}\\left[\\hat{S}(t_{i}|x_{i})\\in\\left[\\rho_{1},\\rho_{2}\\right]\\right]+\\left(\\rho_{2}-\\rho_{1}\\right)\\mathbb{I}\\left[\\hat{S}(t_{i}|x_{i})\\geq\\rho_{2}\\right]}{\\hat{S}(t_{i}|x_{i})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/fc9b6e471adbb8e67783dcaeb0cbc8ea5dcf8f1c2a73a24ecdc4ef24fd4ae8ea.jpg", "img_caption": ["Figure 1: Two notions of distribution calibration: marginal and conditional, illustrated using 3 bins separated at $\\textstyle{\\frac{1}{3}}$ and $\\frac{2}{3}$ . The curves in (a, d) represent the predicted ISDs. The colors of the stars distinguish the six subjects, with horizontal coordinates indicating the true event time (consistent across all panels) and vertical coordinates representing predicted survival probability at event time. Note the two groups (orange for $x=0$ and blue for $x=1$ ) correspond to the colors of the curves and histograms in (a, b, d, e). Note that all three P-P lines in the conditional case (f) coincide. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 1(a) illustrates how marginal calibration is assessed using 6 uncensored subjects. Figure 1(b, c) show the histograms and P-P plots, showing the predictions are marginally calibrated, over the predefined 3 bins, as we can see there are $6/3=2$ instances in each of the 3 bins. However, if we divide the datasets into two groups (orange vs. blue \u2013 think men vs. women), we can see that this is not the case, as there is no orange instance in the $[\\textstyle{\\frac{2}{3}},1]$ bin, and 2 orange instances in the $[{\\textstyle{\\frac{1}{3}}},1]$ bin. ", "page_idx": 2}, {"type": "text", "text": "In summary, individual calibration is ideal but impractical. Conversely, marginal calibration is more feasible but fails to assess calibration relative to certain subsets of the population by features. This discrepancy motivates us to explore a middle ground \u2013 conditional calibration. A conditionally calibrated prediction, which ensures that the predicted survival probabilities are uniformly distributed in each of these groups, as shown in Figure 1(d, e, f), is more effective in real-world scenarios. Consider predicting employee attrition within a company: while a marginal calibration using a Kaplan-Meier (KM) [14] curve might reflect overall population trends, it fails to account for variations such as the tendency of lower-salaried employees to leave earlier. A model that is calibrated for both high and low salary levels would be more helpful for predicting the actual quitting times and facilitate planning. Similarly, when predicting the timing of death from cardiovascular diseases, models calibrated for older populations, who exhibit more predictable and less varied outcomes [15], may not apply to younger individuals with higher outcome variability. Using age-inappropriate models could lead to inaccurate predictions, adversely affecting treatment plans. ", "page_idx": 2}, {"type": "text", "text": "2.3 Maintaining discriminative performance while ensuring good calibration ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Methods based on the objective function [5, 6, 4] have been developed to enhance the marginal calibration of ISDs, involving the addition of a calibration loss to the model\u2019s original objective function (e.g., likelihood loss). However, while those methods are effective in improving the marginal calibration performance of the model, their model often significantly harms the discrimination performance [6, 4, 7], a phenomenon known as the discrimination-calibration trade-off [7]. ", "page_idx": 2}, {"type": "text", "text": "Post-processed methods [12, 8] have been proposed to solve this trade-off by disentangling calibration from discrimination in the optimization process. Cand\u00e8s et al. [12] uses the individual censoring probability as the weighting in addition to the regular Conformalized Quantile Regression (CQR) [11] method. However, their weighting method is only applicable to Type-I censoring settings where each subject must have a known censored time [16] \u2013 which is not applicable to most of the right-censoring datasets. ", "page_idx": 2}, {"type": "text", "text": "Qi et al. [8] developed Conformalized Survival Distribution (CSD) by first discretizing the ISD curves into percentile times (via predefined percentile levels), and then applying CQR [11] for each percentile level (see the visual illustration of CSD in Figure 6 in Appendix B). Their method handles right-censoring using KM-sampling, which employs a conditional KM curve to simulate multiple event times for a censored subject, offering a calibrated approximation for the ISD based on the subject\u2019s censored time. However, their method struggles with some inherent problems of KM [14] \u2013 e.g., KM can be inaccurate when the dataset contains a high proportion of censoring [17]. Furthermore, we also observed that the KM estimation often concludes at high probabilities (as seen in datasets like HFCR, FLCHAIN, and Employee in Figure 9). This poses a challenge in extrapolating beyond the last KM time point, which hinders the accuracy of KM-sampling, thereby constraining the efficacy of CSD (see our results in Figure 3). ", "page_idx": 3}, {"type": "text", "text": "Our work is inspired by CSD [8], and can be seen as a percentile-based refinement of their regressionbased approach. Specifically, our CSD-iPOT effectively addresses and resolves issues prevalent in the KM-sampling, significantly outperforming existing methods in terms of improving the marginal distribution calibration performance. Furthermore, to our best knowledge, this is the first approach that optimizes conditional calibration within the survival analysis that can deal with censorship. ", "page_idx": 3}, {"type": "text", "text": "However, achieving conditional calibration (also known as conditional coverage in some literature [10]) is challenging because it cannot be attained in a distribution-free manner for non-trivial predictions. In fact, guarantees of finite sample for conditional calibration are impossible to achieve even for standard regression datasets without censorship [10, 18, 19]. This limitation is an important topic in the statistical learning and conformal prediction literature [10, 18, 19]. Therefore, our paper does not attempt to provide finite sample guarantees. Instead, following the approach of many other researchers [11, 20\u201324], we provide only asymptotic guarantees as the sample size approaches infinity. The key idea behind this asymptotic conditional guarantee is that the construction of post-processing predictions relies on the quality of the original predictions. Thus, we aim for conditional calibration only within the class of predictions that can be learned well \u2013 that is, consistent estimators. ", "page_idx": 3}, {"type": "text", "text": "We acknowledge that this assumption may not hold in practice; however, (i) reliance on consistent estimators is a standard (albeit strong) assumption in the field of conformal prediction [21\u201323], (ii) to the best of our knowledge, no previous results have proven conditional calibration under more relaxed conditions, and (iii) we provide empirical evidence of conditional calibration using extensive experiments (see Section 5) . ", "page_idx": 3}, {"type": "text", "text": "3 Methods ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "This section describes our proposed method: Conformalized Survival Distribution using Individual survival Probability at Observed Time (CSD-iPOT), which is motivated by the definition of distribution calibration [3] and consists of three components: the estimation of continuous ISD prediction, the computation of suitable conformity scores (especially for censored subjects), and their conformal calibration. ", "page_idx": 3}, {"type": "text", "text": "3.1 Estimating survival distributions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "For simplicity, our method is motivated by the split conformal prediction [25, 11]. We start the process by splitting the instances of the training data into a proper training set $\\mathcal{D}^{\\mathrm{train}}$ and a conformal set $\\mathcal{D}^{\\mathrm{con}}$ . Then, we can use any survival algorithm or quantile regression algorithm (with the capability of handling censorship) to train a model $\\mathcal{M}$ using $\\mathcal{D}^{\\mathrm{train}}$ that can make ISD predictions for $\\mathcal{D}^{\\mathrm{con}}-\\mathrm{see}$ Figure 2(a). ", "page_idx": 3}, {"type": "text", "text": "With little loss of generality, we assume that the ISD predicted by the model, $\\hat{S}_{\\mathcal M}(t\\mid x_{i})$ , are right-continuous and have unbounded range, i.e., $\\hat{S}_{\\mathcal{M}}(t\\mid\\pmb{x}_{i})>0$ for all $t\\geq0$ . For survival algorithms that can only generate piecewise constant survivalM probabilities (e.g., Cox-based methods [26, 27], discrete-time methods [28, 29], etc.), the continuous issue can be fixed by applying some interpolation algorithms (e.g., linear or spline). ", "page_idx": 3}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/a18a2128fe403332c893d4917356d11d564c224f1f231fa64c12bf5205497544.jpg", "img_caption": ["Figure 2: A visual example of using CSD-iPOT to make the prediction (conditionally)-calibrated. (a) Initialize ISD predictions from an arbitrary survival algorithm with associated (b) histograms and (c) P-P plots. (d) Calculate Percentile $(\\rho;\\Gamma_{\\mathcal{M}})$ (grey lines) for all $\\rho\\mathbf{S}$ , and find the intersections (hollow points) of the ISD curves and the PercentiMle $(\\rho;\\Gamma_{\\mathcal{M}})$ lines; (e) Generate new ISD by vertically shifting the hollow points to the $\\rho$ \u2019s level, with associateMd (f) histogram and (g) P-P plots. Figure 6 provide a side-by-side visual comparison between CSD and our method. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.2 Compute conformal scores and calibrate predicting distributions ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We start by sketching how CSD-iPOT deals with only uncensored subjects. Within the conformal set, for each subject $i\\in\\mathcal{Z}^{\\mathrm{con}}$ , we define a distributional conformity score, wrt the model $\\mathcal{M}$ , termed the predicted Individual survival Probability at Observed Time (iPOT): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\gamma_{i,\\mathcal{M}}\\;:=\\;\\hat{S}_{\\mathcal{M}}(e_{i}\\mid\\pmb{x}_{i}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, for uncensored subjects, the observed time corresponds to the event time, $t_{i}\\,=\\,e_{i}$ . Recall from Section 2.2 that predictions from model $\\mathcal{M}$ are marginally calibrated if the iPOT values follow $\\mathcal{U}_{[0,1]}-i.e.$ , if we collect the distributional conformity scores for every subject in the conformal set $\\bar{\\Gamma_{\\mathcal{M}}}\\overset{^{\\cdot}}{=}\\{\\gamma_{i,\\mathcal{M}}\\}_{i\\in\\mathbb{Z}^{\\mathrm{con}}}$ , the $\\rho$ -th percentile value in this set should be equal to exactly $\\rho$ . If so, no post processing adjustments are necessary. ", "page_idx": 4}, {"type": "text", "text": "In general, of course, the estimated Individualized Survival Distributions (ISDs) $\\hat{S}(t\\,|\\,\\pmb{x}_{i})$ may not perfectly align with the true distributions $S(t\\mid x_{i})$ from the oracle. Therefore, for a testing subject with index $n+1$ , we can simply apply the following adjustment to its estimated ISD: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{S}_{\\mathcal{M}}^{-1}(\\rho\\,|\\,x_{n+1})\\;:=\\;\\hat{S}_{\\mathcal{M}}^{-1}\\,\\big(\\,\\mathrm{Percentile}(\\rho;\\,\\Gamma_{\\mathcal{M}})\\,|\\,x_{n+1}\\,\\big)\\,,\\quad\\forall\\rho\\in(0,1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, Percentile $(\\rho;\\Gamma_{\\mathcal{M}})$ calculates the $\\begin{array}{r}{\\frac{\\left\\lceil\\rho\\left(|\\mathcal{D}^{\\mathrm{con}}|+1\\right)\\right\\rceil}{|\\mathcal{D}^{\\mathrm{con}}|}}\\end{array}$ -th empirical percentile of $\\Gamma_{\\mathcal{M}}$ . This adjustment aims to re-calibrate the estimated ISD based\u2223 Don\u2223 the empirical distribution of the conformity scores. ", "page_idx": 4}, {"type": "text", "text": "Visually, this adjustment involves three procedures: ", "page_idx": 4}, {"type": "text", "text": "(i) It first identifies the empirical percentiles of the conformity scores \u2013 Percentile $\\textstyle\\left({\\frac{1}{3}};\\,\\Gamma_{\\mathcal{M}}\\right)$ and Percentile $\\textstyle\\left({\\frac{2}{3}};\\,\\Gamma_{\\mathcal{M}}\\right)$ , illustrated by the two grey lines at 0.28 and 0.47 in Figure 2(d), respectively \u2013 which uniformly divide the stars according to their vertical locations;   \n(ii) It then determines the corresponding times on the predicted ISDs that match these empirical percentiles (the hollow circles, where each ISD crosses the horizontal line);   \n(iii) Finally, the procedure shifts the empirical percentiles (grey lines) to the appropriate height of desired percentiles $\\frac13$ and $\\frac{2}{3}$ ), along with all the circles. This operation is indicated by the vertical shifts of the hollow points, depicted with curved red arrows in Figure 2(d). ", "page_idx": 4}, {"type": "text", "text": "This adjustment results in the post-processed curves depicted in Figure 2(e). It shifts the vertical position of the green star \u2600from the interval $\\textstyle{\\left[{\\frac{1}{3}},{\\frac{2}{3}}\\right]}$ to $[\\textstyle{\\frac{2}{3}},1]$ , and the pink star \u2600from $\\left[0,{\\frac{1}{3}}\\right]$ to $\\textstyle\\left[{\\frac{1}{3}},{\\frac{2}{3}}\\right]$ . These shifts ensure that the calibration histograms and P-P plots achieve a uniform distribution (both marginally on the whole population and conditionally on each group) across the defined intervals. ", "page_idx": 5}, {"type": "text", "text": "After generating the post-processed curves, we can apply a final step, which involves transforming the inverse ISD function back into the ISD function for the testing subject: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{S}_{\\mathcal{M}}\\big(t\\,|\\,\\pmb{x}_{n+1}\\big)\\ =\\ \\operatorname*{inf}\\big\\{\\,\\rho:\\tilde{S}_{\\mathcal{M}}^{-1}\\big(\\rho\\,|\\,\\pmb{x}_{n+1}\\big)\\leq t\\,\\big\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The simple visual example in Figure 2 shows only two percentiles created at $\\textstyle{\\frac{1}{3}}$ and $\\frac{2}{3}$ . In practical applications, the user provides a predefined set of percentiles, $\\mathcal{P}$ , to adjust the ISDs. The choice of $\\mathcal{P}$ can slightly affect the resulting survival distributions, each capable of achieving provable distribution calibration; see ablation study #2 in Appendix E.6 for how $\\mathcal{P}$ affects the performance. ", "page_idx": 5}, {"type": "text", "text": "3.3 Extension to censorship ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "It is challenging to incorporate censored instances into the analysis as we do not observe their true event times, $e_{i}$ , which means we cannot directly apply conformity score in (3) and the subsequent conformal steps. Instead, we only observe the censoring times, which serve as lower bounds of the event times. ", "page_idx": 5}, {"type": "text", "text": "Given the monotonic decreasing property of the ISD curves, the iPOT value for a censored subject, i.e., $\\hat{S}_{\\mathcal{M}}(t_{i}\\mid\\pmb{x}_{i})=\\hat{S}_{\\mathcal{M}}(c_{i}\\mid\\pmb{x}_{i})$ , now serves as the upper bound of $\\hat{S}_{\\mathcal{M}}(e_{i}\\mid x_{i})$ . Therefore, given the prior knowledge that $\\hat{S}_{\\mathcal{M}}(e_{i}\\mid\\pmb{x}_{i})\\sim\\mathcal{U}_{[0,1]}$ , the observation of the censoring time updates the possible range of this distribution. Given that $\\bar{S_{\\mathcal M}}(e_{i}\\mid x_{i})$ must be less than or equal to $\\hat{S}_{{\\mathcal M}}(c_{i}\\mid x_{i})$ , the updated posterior distribution follows S\u02c6 (eMi \u2223xi) \u223cU0, S\u02c6 cixi . ", "page_idx": 5}, {"type": "text", "text": "Following the calibration calculation in [3], where censored patients are evenly \"blurred\" across subsequent bins of $\\hat{S}(c_{i}\\mid{\\pmb x}_{i})$ , our approach uses the above posterior distribution to uniformly draw $R$ potential conformity scores for a censored subject, for some constant $R\\in\\mathbb{Z}^{+}$ . Specifically, for a censored subject, we calculate the conformity scores as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n{\\gamma}_{i,{\\cal M}}\\;=\\;\\hat{S}_{\\cal M}(c_{i}\\;|\\;x_{i})\\cdot u_{\\cal R},\\quad\\mathrm{where}\\quad u_{\\cal R}\\;=\\;\\left[\\frac{}{}0/R,\\,1/R,\\ldots,R/R\\right].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, $\\pmb{u}_{R}$ is a pseudo-uniform vector to mimic the uniform sampling operation, significantly reducing computational overhead compared to actual uniform distribution sampling. For uncensored subjects, we also need to apply a similar sampling strategy to maintain a balanced censoring rate within the conformal set. Because the exact iPOT value is known and deterministic for uncensored subjects, sampling involves directly drawing from a degenerate distribution centered at $\\hat{S}_{\\mathcal{M}}(e_{i}\\mid\\pmb{x}_{i})-i.e.$ , just drawing $\\hat{S}_{\\mathcal{M}}(e_{i}\\mid\\pmb{x}_{i})\\textit{R}$ times. The pseudo-code for implementing the CSD-iPOT process with censoring is outMlined in Algorithm 1 in Appendix B. ", "page_idx": 5}, {"type": "text", "text": "Note that the primary computational demand of this method stems from the optional interpolation and extrapolation of the piecewise constant ISD predictions. Calculating the conformity scores and estimating their percentiles incur negligible costs in terms of both time and space, once the rightcontinuous survival distributions are established. We provide computational analysis in Appendix E.5. ", "page_idx": 5}, {"type": "text", "text": "3.4 Theoretical analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Here we discuss the theoretical properties of CSD-iPOT. Unlike CSD [8], which adjusts the ISD curves horizontally (changing the times, for a fixed percentile), our refined version scales the ISD curves vertically. This vertical adjustment leads to several advantageous properties. In particular, we highlight why our method is expected to yield superior performance in terms of marginal and conditional calibration compared to CSD [8]. Table 1 summarizes the properties of the two methods. ", "page_idx": 5}, {"type": "text", "text": "Calibration CSD-iPOT differs from CSD in two major ways: CSD-iPOT (i) essentially samples the event time from $\\hat{S}_{\\mathcal{M}}(t\\mid t>c_{i},\\,\\pmb{x}_{i})$ for a censored subject, and (ii) subsequently converts these times into corresponding survival probability values on the curve. ", "page_idx": 5}, {"type": "table", "img_path": "l8XnqbQYBK/tmp/355f5f55b1d6e5155e0e09605098d07b9e8b5880e8583474689a25213828366e.jpg", "table_caption": ["Table 1: Properties of CSD and CSD-iPOT. Note that the calibration guarantees refer to asymptotic calibration guarantees. \u2020See Appendix E.5. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "The first difference contrasts with the CSD method, which samples from a conditional KM distribution, $S_{\\mathrm{KM}}(\\,t\\mid t>c_{i}\\,)$ , assuming a homoskedastic survival distribution across subjects (where the conditional KM curves have the same shape and the random disturbance of $e_{i}$ is independent of the features $\\pmb{x}_{i}$ ). However, CSD-iPOT differs by considering the heteroskedastic nature of survival distributions $\\hat{S}_{\\mathcal{M}}(t\\mid t>c_{i},\\,\\pmb{x}_{i})$ . For instance, consider the symptom onset times following exposure to the COVID-M19 virus. Older adults, who may exhibit more variable immune responses, could experience a broader range of onset times compared to younger adults, whose symptom onset times are generally more consistent [30]. By integrating this feature-dependent variability, CSD-iPOT captures the inherent heteroskedasticity of survival distributions and adjusts the survival estimates accordingly, which helps with conditional calibration. ", "page_idx": 6}, {"type": "text", "text": "Furthermore, by transforming the times into the survival probability values on the predicted ISD curves (the second difference), we mitigate the trouble of inaccurate interpolation and extrapolation of the distribution. This approach is particularly useful when the conditional distribution terminates at a relatively high probability, where extrapolating beyond the observed range is problematic due to the lack of data for estimating the tail behavior. Different extrapolation methods, whether parametric or spline-based, can yield widely varying behaviors in the tails of the distribution, potentially leading to significant inaccuracies in survival estimates. However, by converting event times into survival percentiles, CSD-iPOT circumvents these issues. This method capitalizes on the probability integral transform [13], which ensures that regardless of the specific tail behavior of a survival function, its inverse probability values will follow a uniform distribution. ", "page_idx": 6}, {"type": "text", "text": "The next results state that the output of our method has asymptotic marginal calibration, with necessary assumptions (exchangeability, conditional independent censoring, and continuity). We also prove the asymptotic conditional calibrated guarantee for CSD-iPOT. The proofs of these two results are inspired by the standard conformal prediction literature [11, 22], with adequate modifications to accommodate our method. We refer the reader to Appendix C.1 for the complete proof. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.1 (Asymptotic marginal calibration). If the instances in $\\mathcal{D}$ are exchangeable, and follow the conditional independent censoring assumption, then for a new instance $n+1$ , $\\forall\\ \\rho_{1}<\\rho_{2}\\in[0,1].$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\rho_{2}-\\rho_{1}\\quad\\leq\\quad\\operatorname{\\mathbb{P}}\\left({\\tilde{S}}_{\\mathcal{M}}\\big(t_{n+1}\\mid x_{n+1}\\big)\\in\\left[\\rho_{1},\\rho_{2}\\right]\\right)\\quad\\leq\\quad\\rho_{2}-\\rho_{1}+\\frac{1}{|{\\mathcal{D}}^{\\mathrm{con}}|+1}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 3.2 (Asymptotic conditional calibration). In addition to the assumptions in Theorem 3.1, if (i) the non-processed prediction $\\hat{S}_{\\mathcal{M}}(t\\,|\\,\\pmb{x}_{i})$ is a consistent survival estimator; $(i i)$ its inverse function is differentiable; and (iii) the 1st deMrivation of the inverse function is bounded by a constant, then the CSD-iPOT process will achieve asymptotic conditional distribution calibration. ", "page_idx": 6}, {"type": "text", "text": "Monotonicity Unlike CSD, CSD-iPOT does not face any non-monotonic issues for the postprocessed curves as long as the original ISD predictions are monotonic; see proof in Appendix C.2. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.3. CSD-iPOT process preserves the monotonic decreasing property of the ISD. ", "page_idx": 6}, {"type": "text", "text": "CSD, built on the Conformalized Quantile Regression (CQR) framework, struggles with the common issue of non-monotonic quantile curves (refer to Appendix D.2 in [8] and our Appendix C.2). While some methods, like the one proposed by Chernozhukov et al. [31], address this issue by rearranging quantiles, they can be computationally intensive and risk (slightly) recalibrating and distorting discrimination in the rearranged curves. By inherently maintaining monotonicity, CSD-iPOT not only enhances computational efficiency but also avoids these risks. ", "page_idx": 6}, {"type": "text", "text": "Discrimination Qi et al. [8] demonstrated that CSD theoretically guarantees the preservation of the original model\u2019s discrimination performance in terms of Harrell\u2019s concordance index (C-index) [1]. However, CSD-iPOT lacks this property; see Appendix C.3 for details. ", "page_idx": 7}, {"type": "text", "text": "As CSD-iPOT vertically scales the ISD curves, it preserves the relative order of survival probabilities at any single time point. This preservation means that the discrimination power, measured by the area under the receiver operating characteristic (AUROC) at any time, remains intact (Theorem C.4). Furthermore, Antolini\u2019s time-dependent C-index $(C^{t d})$ [32], which represents a weighted average AUROC across all time points, is also guaranteed to be maintained by our method (Lemma C.5). As a comparison, CSD does not have such a guarantee for neither AUROC nor Ctd. ", "page_idx": 7}, {"type": "text", "text": "4 Evaluation metrics ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We measure discrimination using Harrell\u2019s C-index [1], rather than Antolini\u2019s $C^{t d}$ [32], as Lemma C.5 already established that $C^{t d}$ is not changed by CSD-iPOT. We aim to assess our performance using a measure that represents a relative weakness of our method. ", "page_idx": 7}, {"type": "text", "text": "As to the calibration metrics, the marginal calibration score evaluated on the test set $\\mathcal{D}^{\\mathrm{test}}$ is calculated as [3, 8]: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathrm{Cal}_{\\mathrm{margin}}(\\hat{S};\\mathcal{P})\\;=\\;\\frac{1}{|\\mathcal{P}|}\\sum_{\\rho\\in\\mathcal{P}}\\left(\\mathbb{P}\\left(\\hat{S}(e_{i}\\mid\\pmb{x}_{i})\\in\\left[0,\\rho\\right],\\,i\\in\\mathbb{Z}^{\\mathrm{test}}\\right)-\\;\\rho\\right)^{2},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\mathbb{P}(\\hat{S}(e_{i}\\mid\\mathbf{x}_{i})\\in\\left[0,\\rho\\right],\\,i\\in\\mathcal{T}^{\\mathrm{test}})$ is calculated by combining (1) and (2); see (8) in Appendix A. Based on the marginal calibration formulation, a natural way for evaluating the conditional calibration could be: (i) heuristically define a finite feature space set $\\{\\mathbb{S}_{1},\\mathbb{S}_{2},...\\}-e.g.,$ , ${\\mathbb S}_{1}$ is the set of divorced elder males, $\\mathbb{S}_{2}$ is females with 2 children, etc.; and (ii) calculate the worst calibration score on all the predefined sub-spaces. This is similar to fairness settings, researchers normally select age, sex, or race as the sensitive attributes to form the feature space. However, this metric does not scale to higher-dimensional settings because it is challenging to create the feature space set that contains all possible combinations of the features. ", "page_idx": 7}, {"type": "text", "text": "Motivated by Romano et al. [33], we proposed a worst-slab distribution calibration, $\\mathrm{Cal}_{\\mathrm{ws}}$ . We start by partition the testing set into a $25\\%$ exploring set $\\mathcal{D}^{\\mathrm{explore}}$ and a $75\\%$ exploiting set $\\mathcal{D}^{\\mathrm{exploit}}$ . The exploring set is then used to find the worst calibrated sub-region in the feature space $\\mathbb{R}^{d}$ : ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{S}_{v,a,b}\\,=\\,\\left\\{\\,\\mathbf{x}_{i}\\in\\mathbb{R}^{d}:a\\leq v^{\\top}\\mathbf{x}_{i}\\leq b\\,\\right\\}\\quad\\mathrm{and}\\quad\\mathbb{P}\\left(\\,\\mathbf{x}_{i}\\in\\mathbb{S}_{v,a,b},i\\in\\mathbb{Z}^{\\mathrm{explore}}\\,\\right)\\,\\ge\\,\\kappa,}\\\\ &{\\,v,a,b=\\displaystyle\\operatorname*{arg\\,max}_{v\\in\\mathbb{R}^{d},a<b\\mathbb{K}}\\frac{1}{|\\mathcal{P}|}\\sum_{\\rho\\in\\mathcal{P}}\\left(\\mathbb{P}\\left(\\hat{S}(e_{i}\\mid\\mathbf{x}_{i})\\in\\left[0,\\rho\\right],i\\in\\mathbb{Z}^{\\mathrm{explore}}\\,,\\,\\mathbf{x}_{i}\\in\\mathbb{S}_{v,a,b}\\right)\\right)-\\rho\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "In practice, the parameters $\\mathbf{\\boldsymbol{v}},\\,\\boldsymbol{a}$ , and $b$ are chosen adversarially by sampling i.i.d. vectors $\\pmb{v}$ on the unit sphere in $\\mathbb{R}^{\\bar{d}}$ then finding the arg max using a grid search on the exploring set. $\\kappa$ is a predefined threshold to ensure that we only consider slabs that contain at least $\\kappa\\%$ of the instances (so that we do not encounter a pregnant-man situation). Given this slab, we can calculate the conditional calibration score on the evaluation set for this slab: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbf{Cal}_{\\mathrm{ws}}\\big(\\hat{S};\\mathcal{P},\\mathbb{S}_{v,a,b}\\big)\\;=\\;\\frac{1}{\\left|\\mathcal{P}\\right|}\\sum_{\\rho\\in\\mathcal{P}}\\left(\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid{\\pmb x}_{i})\\in[0,\\rho]\\,,\\,i\\in\\mathcal{T}^{\\mathrm{exploit}}\\,,\\,{\\pmb x}_{i}\\in\\mathbb{S}_{v,a,b}\\big)\\right)\\,-\\,\\rho\\,\\big)^{2}\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Besides the above metrics, we also evaluate using other commonly used metrics: integrated Brier score (IBS) [34], and mean absolute error with pseudo-observation (MAE-PO) [35]; see Appendix D. ", "page_idx": 7}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The implementation of CSD-iPOT method, worst-slab distribution calibration score, and the code to reproduce all experiments in this section are available at https://github.com/shi-ang/ MakeSurvivalCalibratedAgain. ", "page_idx": 7}, {"type": "text", "text": "5.1 Experimental setup ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Datasets We use 15 datasets to test the effectiveness of our method. Table 3 in Appendix E.1 summarizes the dataset statistics, and Appendix E.1 also contains details of preprocessing steps, ", "page_idx": 7}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/8174c79b10e8333c85e967e4e377d838c8c8a787b876279cc584c0eb44306f20.jpg", "img_caption": ["Figure 3: Violin plots of C-index and $\\mathrm{Cal}_{\\mathrm{margin}}$ performance of our method (CSD-iPOT) and benchmarks. The shape of each violin plot represents the probability density of the performance scores, with the black bar inside the violin indicating the mean performance. The red dashed lines in the lower panels represent the mean calibration performance for KM, serving as an empirical lower limit. "], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "l8XnqbQYBK/tmp/846c10dca117be7b4bd1ab7cb92289697028e288da4156ae6adf7c50ffd3d51a.jpg", "table_caption": ["Table 2: Performance summary of CSD-iPOT. Values in parentheses indicate statistically significant differences $\\mathrm{\\Delta}p<0.05$ using a two-sided $t$ -test). A tie means the first 3 significant digits are the same. \u2021The total number of comparisons for $\\mathrm{Cal}_{\\mathrm{ws}}$ is 69, while it is 104 for the other metrics. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "KM curves, and histograms of event/censor times. Compared with [8], we added datasets with high censoring rates $(>\\!60\\%)$ and ones whose KM ends with high probabilities $(>\\!50\\%)$ . ", "page_idx": 8}, {"type": "text", "text": "Baselines We compared 7 survival algorithms: AFT [36], $G B$ [37], DeepSurv [38], N-MTLR [39], DeepHit [29], CoxTime [27], and CQRNN [40]. We also include KM as a benchmark (empirical lower bound) for marginal calibration, which is known to achieve perfect marginal calibration [3, 8]. Appendix E.2 describes the implementation details and hyperparameter settings. ", "page_idx": 8}, {"type": "text", "text": "Procedure We divided the data into a training set $(90\\%)$ and a testing set $(10\\%)$ using a stratified split to balance time $t_{i}$ and censor indicator $\\delta_{i}$ . We also reserved a balanced $10\\%$ validation subset from the training data for hyperparameter tuning and early stopping. This procedure was replicated across 10 random splits for each dataset. ", "page_idx": 8}, {"type": "text", "text": "5.2 Experimental results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Due to space constraints, the main text presents partial results for datasets with high censoring rates and high KM ending probabilities (HFCR, FLCHAIN, Employee, MIMIC-IV). Notably, CQRNN did not converge on the MIMIC-IV dataset. Thus, we conducted a total of 104 method comparisons (15 datasets $\\times\\,7$ baselines \u22121). Table 2 offers a detailed performance summary of CSD-iPOT versus baselines and CSD method across these comparisons. Appendix E.4 presents the complete results. ", "page_idx": 8}, {"type": "text", "text": "Discrimination The upper panels of Figure 3 indicate minimal differences in the C-index among the methods, with notable exceptions primarily involving DeepHit. Specifically, CSD-iPOT matched the baseline C-index in 75 instances and outperformed it in 7 out of 104 comparisons. This suggests that CSD-iPOT maintains discriminative performance in approximately $79\\%$ of the cases. ", "page_idx": 8}, {"type": "text", "text": "Marginal Calibration The lower panels of Figure 3 show significant improvements in marginal calibration with CSD-iPOT. It often achieved near-optimal performance, as marked by the red dashed lines. Table 2 also shows that CSD-iPOT provided better marginal calibration than the baselines in 95 (and significantly in 50) out of 104 comparisons $(91\\%)$ . ", "page_idx": 8}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/353937c297bec4de9a279873bbd31b2d639310fa375b0d60a1fb125ec1192cbe.jpg", "img_caption": ["Figure 4: Violin plots of $\\mathrm{Cal}_{\\mathrm{ws}}$ performance, where the shape and black bars represent the density and mean. Smaller values represent better performance. Note CQRNN did not converge on MIMIC-IV. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "CSD-iPOT\u2019s marginal calibration was better than CSD most of the time (68/104, $65\\%$ ). The cases where CSD performs better typically involve models like DeepHit or CQRNN. This shows that our approach often does not perform as well as CSD when the original model is heavily miscalibrated, which suggests a minor limitation of our method. Appendix C.4 discusses why our method is sub-optimal for these models. ", "page_idx": 9}, {"type": "text", "text": "Conditional Calibration For small datasets (sample size $<1000\\$ ), in some random split, we can find a worst-slab region $\\mathbb{S}_{v,a,b}$ on the exploring set with $\\mathbb{P}(\\pmb{x}_{i}\\in\\mathbb{S}_{\\pmb{v},a,b}$ , $i\\in{\\mathcal{T}}^{\\mathrm{explore}})\\geq3\\bar{3}\\%$ but still no subjects in this region in the exploiting set. This is probably because we only ensure that the times and censored indicators are balanced during the partition, however, the features can still be unbalanced. Therefore, we only evaluated conditional calibration on the 10 larger datasets, resulting in 69 comparisons. Among them, CSD-iPOT improved conditional calibration in 64 cases $(93\\%)$ compared to baselines and in 51 cases $(74\\%)$ compared to CSD. ", "page_idx": 9}, {"type": "text", "text": "Case Study We provide 4 case studies in Figure 13 in Appendix E.4, where CSD leads to significant miscalibration within certain subgroups, and CSD-iPOT can effectively generate more conditional calibrated predictions in those groups. These examples show that CSD\u2019s miscalibration is always located at the low-probability regions, which corresponds to our statement (in Section 3.4) that the conditional KM sampling method that CSD used is problematic for the tail of the distribution. ", "page_idx": 9}, {"type": "text", "text": "Other Metrics Results in Table 2 and Appendix E.4 show that CSD-iPOT also showed improvement in both IBS and MAE-PO, outperforming 63 and 54 out of 104 comparisons, respectively. ", "page_idx": 9}, {"type": "text", "text": "Computational Analysis Appendix E.5 shows the comprehensive results and experimental setup.   \nIn summary, CSD-iPOT significantly reduces the space consumption and running time. ", "page_idx": 9}, {"type": "text", "text": "Ablation Studies We conducted two ablation studies to assess (i) the impact of the repetitions value $(R)$ and (ii) the impact of predefined percentiles $(\\mathcal{P})$ on the method; see Appendix E.6. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Discrimination and marginal calibration are two fundamental yet distinct elements in survival analysis. While marginal calibration is feasible, it overlooks accuracy across different groups distinguished by specific features. In this paper, we emphasize the importance of conditional calibration for practical applications and propose a principled metric for this purpose. By generating conditionally calibrated Individual Survival Distributions (ISDs), we can better communicate the uncertainty in survival analysis models, enhancing their reliability, fairness, and real-world applicability. ", "page_idx": 9}, {"type": "text", "text": "We therefore define the Conformalized Survival Distribution using Individual Survival Probability at Observed Time (CSD-iPOT) \u2013 a post-processing framework that enhances both marginal and conditional calibration without compromising discrimination. It addresses common issues in prior methods, particularly under high censoring rates or when the Kaplan-Meier curve terminates at a high probability. Moreover, this post-processing adjusts the ISDs by adapting the heteroskedasticity of the distribution, leading to asymptotic conditional calibration. Our extensive empirical tests confirm that CSD-iPOT significantly improves both marginal and conditional performance without diminishing the models\u2019 discriminative power. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This research received support from the Natural Science and Engineering Research Council of Canada (NSERC), the Canadian Institute for Advanced Research (CIFAR), and the Alberta Machine Intelligence Institute (Amii). The authors extend their gratitude to the anonymous reviewers for their insightful feedback and valuable suggestions. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Frank E Harrell Jr, Kerry L Lee, Robert M Califf, David B Pryor, and Robert A Rosati. Regression modelling strategies for improved prognostic prediction. Statistics in medicine, 3(2): 143\u2013152, 1984.   \n[2] Frank E Harrell Jr, Kerry L Lee, and Daniel B Mark. Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors. Statistics in medicine, 15(4):361\u2013387, 1996.   \n[3] Humza Haider, Bret Hoehn, Sarah Davis, and Russell Greiner. Effective ways to build and evaluate individual survival distributions. Journal of Machine Learning Research, 21(85):1\u201363, 2020.   \n[4] Paidamoyo Chapfuwa, Chenyang Tao, Chunyuan Li, Irfan Khan, Karen J Chandross, Michael J Pencina, Lawrence Carin, and Ricardo Henao. Calibration and uncertainty in neural time-toevent modeling. IEEE transactions on neural networks and learning systems, 2020.   \n[5] Anand Avati, Tony Duan, Sharon Zhou, Kenneth Jung, Nigam H Shah, and Andrew Y Ng. Countdown regression: sharp and calibrated survival predictions. In Uncertainty in Artificial Intelligence, pages 145\u2013155. PMLR, 2020.   \n[6] Mark Goldstein, Xintian Han, Aahlad Puli, Adler Perotte, and Rajesh Ranganath. X-cal: Explicit calibration for survival analysis. Advances in neural information processing systems, 33:18296\u201318307, 2020.   \n[7] Fahad Kamran and Jenna Wiens. Estimating calibrated individualized survival curves with deep learning. Proceedings of the AAAI Conference on Artificial Intelligence, 35(1):240\u2013248, May 2021.   \n[8] Shi-Ang Qi, Yakun Yu, and Russell Greiner. Conformalized survival distributions: A generic post-process to increase calibration. In Proceedings of the 41st International Conference on Machine Learning, volume 235, pages 41303\u201341339. PMLR, 21\u201327 Jul 2024.   \n[9] Sahil Verma and Julia Rubin. Fairness definitions explained. In Proceedings of the international workshop on software fairness, pages 1\u20137, 2018.   \n[10] Vladimir Vovk, Alexander Gammerman, and Glenn Shafer. Algorithmic learning in a random world, volume 29. Springer, 2005.   \n[11] Yaniv Romano, Evan Patterson, and Emmanuel Candes. Conformalized quantile regression. Advances in neural information processing systems, 32, 2019.   \n[12] Emmanuel Cand\u00e8s, Lihua Lei, and Zhimei Ren. Conformalized survival analysis. Journal of the Royal Statistical Society Series B: Statistical Methodology, 85(1):24\u201345, 2023.   \n[13] John E Angus. The probability integral transform and related results. SIAM review, 36(4): 652\u2013654, 1994.   \n[14] Edward L Kaplan and Paul Meier. Nonparametric estimation from incomplete observations. Journal of the American statistical association, 53(282):457\u2013481, 1958.   \n[15] Frank LJ Visseren, Fran\u00e7ois Mach, Yvo M Smulders, David Carballo, Konstantinos C Koskinas, Maria B\u00e4ck, Athanase Benetos, Alessandro Biff,i Jose-Manuel Boavida, Davide Capodanno, et al. 2021 ESC Guidelines on cardiovascular disease prevention in clinical practice: Developed by the Task Force for cardiovascular disease prevention in clinical practice with representatives of the European Society of Cardiology and 12 medical societies With the special contribution of the European Association of Preventive Cardiology (EAPC). European heart journal, 42 (34):3227\u20133337, 2021.   \n[16] John P Klein and Melvin L Moeschberger. Survival analysis: techniques for censored and truncated data. Springer Science & Business Media, 2006.   \n[17] Na Liu, Yanhong Zhou, and J Jack Lee. IPDfromKM: reconstruct individual patient data from published Kaplan-Meier survival curves. BMC medical research methodology, 21(1):111, 2021.   \n[18] Jing Lei and Larry Wasserman. Distribution-free prediction bands for non-parametric regression. Journal of the Royal Statistical Society Series B: Statistical Methodology, 76(1):71\u201396, 2014.   \n[19] Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tibshirani. The limits of distribution-free conditional predictive inference. Information and Inference: A Journal of the IMA, 10(2):455\u2013482, 2021.   \n[20] Jing Lei, Max G\u2019Sell, Alessandro Rinaldo, Ryan J Tibshirani, and Larry Wasserman. Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113(523):1094\u20131111, 2018.   \n[21] Matteo Sesia and Emmanuel J Cand\u00e8s. A comparison of some conformal quantile regression methods. Stat, 9(1):e261, 2020.   \n[22] Rafael Izbicki, Gilson Shimizu, and Rafael Stern. Flexible distribution-free conditional predictive bands using density estimators. In International Conference on Artificial Intelligence and Statistics, pages 3068\u20133077. PMLR, 2020.   \n[23] Victor Chernozhukov, Kaspar W\u00fcthrich, and Yinchu Zhu. Distributional conformal prediction. Proceedings of the National Academy of Sciences, 118(48):e2107794118, 2021.   \n[24] Rafael Izbicki, Gilson Shimizu, and Rafael B. Stern. CD-split and HPD-split: Efficient Conformal Regions in High Dimensions. Journal of Machine Learning Research, 23(87):1\u201332, 2022.   \n[25] Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. Inductive confidence machines for regression. In Machine learning: ECML 2002: 13th European conference on machine learning Helsinki, Finland, August 19\u201323, 2002 proceedings 13, pages 345\u2013356. Springer, 2002.   \n[26] David R Cox. Regression models and life-tables. Journal of the Royal Statistical Society: Series B (Methodological), 34(2):187\u2013202, 1972.   \n[27] Havard Kvamme, \u00d8rnulf Borgan, and Ida Scheel. Time-to-event prediction with neural networks and cox regression. Journal of Machine Learning Research, 20:1\u201330, 2019.   \n[28] Chun-Nam Yu, Russell Greiner, Hsiu-Chin Lin, and Vickie Baracos. Learning patient-specific cancer survival distributions as a sequence of dependent regressors. Advances in Neural Information Processing Systems, 24:1845\u20131853, 2011.   \n[29] Changhee Lee, William R Zame, Jinsung Yoon, and Mihaela van der Schaar. Deephit: A deep learning approach to survival analysis with competing risks. In Thirty-second AAAI conference on artificial intelligence, 2018.   \n[30] Joseph D Challenger, Cher Y Foo, Yue Wu, Ada WC Yan, Mahdi Moradi Marjaneh, Felicity Liew, Ryan S Thwaites, Lucy C Okell, and Aubrey J Cunnington. Modelling upper respiratory viral load dynamics of sars-cov-2. BMC medicine, 20:1\u201320, 2022.   \n[31] Victor Chernozhukov, Iv\u00e1n Fern\u00e1ndez-Val, and Alfred Galichon. Quantile and probability curves without crossing. Econometrica, 78(3):1093\u20131125, 2010.   \n[32] Laura Antolini, Patrizia Boracchi, and Elia Biganzoli. A time-dependent discrimination index for survival data. Statistics in medicine, 24(24):3927\u20133944, 2005.   \n[33] Yaniv Romano, Matteo Sesia, and Emmanuel Candes. Classification with valid and adaptive coverage. Advances in Neural Information Processing Systems, 33:3581\u20133591, 2020.   \n[34] Erika Graf, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher. Assessment and comparison of prognostic classification schemes for survival data. Statistics in medicine, 18 (17-18):2529\u20132545, 1999.   \n[35] Shi-Ang Qi, Neeraj Kumar, Mahtab Farrokh, Weijie Sun, Li-Hao Kuan, Rajesh Ranganath, Ricardo Henao, and Russell Greiner. An effective meaningful way to evaluate survival models. In Proceedings of the 40th International Conference on Machine Learning, volume 202, pages 28244\u201328276. PMLR, 23\u201329 Jul 2023.   \n[36] Winfried Stute. Consistent estimation under random censorship when covariables are present. Journal of Multivariate Analysis, 45(1):89\u2013103, 1993.   \n[37] Torsten Hothorn, Peter B\u00fchlmann, Sandrine Dudoit, Annette Molinaro, and Mark J Van Der Laan. Survival ensembles. Biostatistics, 7(3):355\u2013373, 2006.   \n[38] Jared L Katzman, Uri Shaham, Alexander Cloninger, Jonathan Bates, Tingting Jiang, and Yuval Kluger. Deepsurv: personalized treatment recommender system using a cox proportional hazards deep neural network. BMC medical research methodology, 18(1):1\u201312, 2018.   \n[39] Stephane Fotso. Deep neural networks for survival analysis based on a multi-task framework. arXiv preprint arXiv:1801.05512, 2018.   \n[40] Tim Pearce, Jong-Hyeon Jeong, Jun Zhu, et al. Censored quantile regression neural networks for distribution-free survival analysis. In Advances in Neural Information Processing Systems, 2022.   \n[41] Frederick N Fritsch and Judy Butland. A method for constructing local monotone piecewise cubic interpolants. SIAM journal on scientific and statistical computing, 5(2):300\u2013304, 1984.   \n[42] Anastasios N Angelopoulos, Stephen Bates, et al. Conformal prediction: A gentle introduction. Foundations and Trends\u00ae in Machine Learning, 16(4):494\u2013591, 2023.   \n[43] Shi-ang Qi, Neeraj Kumar, Jian-Yi Xu, Jaykumar Patel, Sambasivarao Damaraju, Grace ShenTu, and Russell Greiner. Personalized breast cancer onset prediction from lifestyle and health history information. Plos one, 17(12):e0279174, 2022.   \n[44] Shi-ang Qi, Weijie Sun, and Russell Greiner. SurvivalEVAL: A comprehensive open-source python package for evaluating individual survival distributions. In Proceedings of the AAAI Symposium Series, volume 2, pages 453\u2013457, 2023.   \n[45] Davide Chicco and Giuseppe Jurman. Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC medical informatics and decision making, 20:1\u201316, 2020.   \n[46] Heart Failure Clinical Records. UCI Machine Learning Repository, 2020. DOI: https://doi.org/10.24432/C5Z89R.   \n[47] Terry Therneau and Patricia Grambsch. Modeling Survival Data: Extending The Cox Model, volume 48. Springer, 01 2000. ISBN 978-1-4419-3161-0. doi: 10.1007/978-1-4757-3294-8.   \n[48] Terry M Therneau. A Package for Survival Analysis in R, 2024. URL https://CRAN. R-project.org/package $=$ survival. R package version 3.6-4.   \n[49] David W Hosmer, Stanley Lemeshow, and Susanne May. Applied survival analysis. John Wiley & Sons, Inc., 2008.   \n[50] John N Weinstein, Eric A Collisson, Gordon B Mills, Kenna R Shaw, Brad A Ozenberger, Kyle Ellrott, Ilya Shmulevich, Chris Sander, and Joshua M Stuart. The cancer genome atlas pan-cancer analysis project. Nature genetics, 45(10):1113\u20131120, 2013.   \n[51] Patrick Royston and Douglas G Altman. External validation of a cox prognostic model: principles and methods. BMC medical research methodology, 13:1\u201315, 2013. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "[52] Stephane Fotso et al. PySurvival: Open source package for survival analysis modeling, 2019\u2013. URL https://www.pysurvival.io/. ", "page_idx": 13}, {"type": "text", "text": "[53] Angela Dispenzieri, Jerry A. Katzmann, Robert A. Kyle, Dirk R. Larson, Terry M. Therneau, Colin L. Colby, Raynell J. Clark, Graham P. Mead, Shaji Kumar, L. Joseph Melton, and S. Vincent Rajkumar. Use of nonclonal serum immunoglobulin free light chains to predict overall survival in the general population. Mayo Clinic Proceedings, 87(6):517\u2013523, 2012. ISSN 0025-6196.   \n[54] William A Knaus, Frank E Harrell, Joanne Lynn, Lee Goldman, Russell S Phillips, Alfred F Connors, Neal V Dawson, William J Fulkerson, Robert M Califf, Norman Desbiens, et al. The support prognostic model: Objective estimates of survival for seriously ill hospitalized adults. Annals of internal medicine, 122(3):191\u2013203, 1995.   \n[55] Alistair Johnson, Lucas Bulgarelli, Tom Pollard, Steven Horng, Leo Celi, Anthony, and Roger Mark. MIMIC-IV (version 2.0). PhysioNet (2022). https://doi.org/10.13026/7vcr-e114., 2022.   \n[56] Sebastian P\u00f6lsterl. scikit-survival: A library for time-to-event analysis built on top of scikitlearn. Journal of Machine Learning Research, 21(212):1\u20136, 2020. URL http://jmlr.org/ papers/v21/20-729.html.   \n[57] Terry M Therneau. A Package for Survival Analysis in R, 2024. URL https://CRAN. R-project.org/package $=$ survival. R package version 3.6-4.   \n[58] Alistair EW Johnson, Lucas Bulgarelli, Lu Shen, Alvin Gayles, Ayad Shammout, Steven Horng, Tom J Pollard, Sicheng Hao, Benjamin Moody, Brian Gow, et al. Mimic-iv, a freely accessible electronic health record dataset. Scientific data, 10(1):1, 2023.   \n[59] Cameron Davidson-Pilon. lifelines, survival analysis in python, January 2024. URL https: //doi.org/10.5281/zenodo.10456828.   \n[60] David R Cox. Partial likelihood. Biometrika, 62(2):269\u2013276, 1975.   \n[61] Ping Jin. Using survival prediction techniques to learn consumer-specific reservation price distributions. Master\u2019s thesis, University of Alberta, 2015.   \n[62] Norman E Breslow. Analysis of survival data under the proportional hazards model. International Statistical Review/Revue Internationale de Statistique, pages 45\u201357, 1975.   \n[63] Morris H DeGroot and Stephen E Fienberg. The comparison and evaluation of forecasters. Journal of the Royal Statistical Society: Series D (The Statistician), 32(1-2):12\u201322, 1983. ", "page_idx": 13}, {"type": "text", "text": "A Calibration in Survival Analysis ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Distribution calibration (or simply \u201ccalibration\u201d) examines the calibration ability across the entire range of ISD predictions [3]. This appendix provides more details about this metric. ", "page_idx": 14}, {"type": "text", "text": "A.1 Why the survival probability at event times should be uniform? ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The probability integral transform [13] states: if the conditional cumulative distribution function (CDF) $F(t\\mid x_{i})$ is legitimate and continuous in $t$ for each fixed value of $\\pmb{x}_{i}$ , then $F(t\\mid x_{i})$ has a standard uniform distribution, $\\mathcal{U}_{[0,1]}$ . Since $S(t\\,|\\,\\pmb{x}_{i})=1-F(t\\,|\\,\\pmb{x}_{i})$ , then $S(t\\mid\\mathbf{x}_{i})\\sim\\mathcal{U}_{[0,1]}$ . ", "page_idx": 14}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/6269abc24c7508ae8a5936b198cd02e2a8782bde03683cf9a82007d72ee73afe.jpg", "img_caption": [], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "Figure 5: Individual distribution calibration, illustrated using 3 bins separated at $\\frac13$ and $\\frac{2}{3}$ . The curve is an oracle\u2019s true ISD $S(t\\mid x_{i})$ . The stars represent 15 realizations of $t\\mid\\pmb{x}_{i}$ . The vertical coordinates of the star represent the time and the horizontal coordinates of the star are the survival probability at observed time $S(e_{i}^{m}\\mid x_{i})$ . ", "page_idx": 14}, {"type": "text", "text": "A.2 Handling censorship ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Definition 2.1 defines the marginal calibration for the uncensored dataset. In this section, we expand the definition to any dataset with censored instances. Note that Haider et al. [3] proposed the following method, here we just reformulate their methodology to fit the language in this paper, for a better presentation purpose. ", "page_idx": 14}, {"type": "text", "text": "Given an uncensored subject, the probability of its survival probability at event time in a probability interval of $[\\rho_{1},\\rho_{2}]$ is deterministic, as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big(\\,\\hat{S}(e_{i}\\mid\\pmb{x}_{i})\\in\\big[\\rho_{1},\\rho_{2}\\big]\\,\\Big|\\,\\delta_{i}=1\\,\\Big)\\ =\\ \\mathbb{1}\\,\\Big[\\,\\hat{S}(e_{i}\\mid\\pmb{x}_{i})\\in\\big[\\rho_{1},\\rho_{2}\\big],~\\delta_{i}=1\\,\\Big]\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For censored subjects, because we do not know the true event time, so there is no way we can know whether the predicted probability is within the interval or not. We can \u201cblur\u201d the subject uniformly to the probability intervals after the survival probability at censored time $\\hat{S}(c_{i}\\mid{\\pmb x}_{i})$ [3]. ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}]\\,\\big|\\,\\delta_{i}=0\\big)=\\frac{\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}],\\delta_{i}=0\\big)}{\\mathbb{P}(\\delta_{i}=0)}}\\\\ &{\\quad=\\frac{\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}],\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i})\\big)}{\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i})\\big)}}\\\\ &{\\quad=\\frac{\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}],\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i}),\\hat{S}(e_{i}\\mid x_{i})\\geq\\rho_{2}\\big)}{\\mathbb{P}(\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i}))}}\\\\ &{\\quad\\quad+\\frac{\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}],\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i}),\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}]\\big)}{\\mathbb{P}(\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i}))}}\\\\ &{\\quad\\quad+\\frac{\\mathbb{P}\\big(\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}],\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i}),\\hat{S}(e_{i}\\mid x_{i})\\in[\\rho_{1},\\rho_{2}]\\big)}{\\mathbb{P}(\\hat{S}(e_{i}\\mid x_{i})<\\hat{S}(e_{i}\\mid x_{i}))}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\frac{\\mathbb{P}\\big(\\rho_{1}\\leq\\hat{S}(e_{i}\\mid x_{i})\\leq\\rho_{2}\\big)\\,\\mathbb{P}\\big(\\hat{S}(c_{i}\\mid x_{i})\\geq\\rho_{2}\\big)}{\\hat{S}(t_{i}\\mid x_{i})}}\\\\ &{\\phantom{=\\mathstrut}+\\frac{\\mathbb{P}\\big(\\rho_{1}\\leq\\hat{S}(e_{i}\\mid x_{i})\\leq\\hat{S}(c_{i}\\mid x_{i})\\big)\\,\\mathbb{P}\\big(\\hat{S}(c_{i}\\mid x_{i})\\in\\big[\\rho_{1},\\rho_{2}\\big]\\big)}{\\hat{S}(t_{i}\\mid x_{i})}+\\frac{\\mathbb{P}(\\varnothing)}{\\hat{S}(t_{i}\\mid x_{i})}}\\\\ &{=\\frac{\\big(\\rho_{2}-\\rho_{1}\\big)\\mathbb{I}\\big[\\hat{S}(t_{i}\\mid x_{i})\\geq\\rho_{2}\\big]+\\big(\\hat{S}(t_{i}\\mid x_{i})-\\rho_{1}\\big)\\,\\mathbb{I}\\big[\\hat{S}(t_{i}\\mid x_{i})\\in\\big[\\rho_{1},\\rho_{2}\\big]\\big]}{\\hat{S}(t_{i}\\mid x_{i})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the decomposition of probability in the second to last equality is because of the conditional independent censoring assumption. Therefore, for the entire dataset, considering both uncensored and censored subjects, the probability ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\hat{S}(e_{i}\\mid\\pmb{x}_{i})\\in\\left[\\rho_{1},\\rho_{2}\\right],i\\in\\mathbb{Z}\\right)\\ =\\ \\mathbb{E}_{i\\in\\mathbb{Z}}\\left[\\delta_{i}\\cdot\\mathbb{P}\\left(\\left.\\hat{S}(e_{i}\\mid\\pmb{x}_{i})\\in\\left[\\rho_{1},\\rho_{2}\\right]\\right\\vert\\delta_{i}\\,\\right)\\right]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, given the above derivation, we can provide a formal definition for marginal distributional calibration for any survival dataset with censorship. ", "page_idx": 15}, {"type": "text", "text": "Definition A.1 (Marginal calibration). For a survival dataset, a model has perfect marginal calibration iff \u2200 $[\\rho_{1},\\rho_{2}]\\subset[0,1]$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\hat{S}(e_{i}\\mid\\pmb{x}_{i})\\in\\left[\\rho_{1},\\rho_{2}\\right],\\,i\\in\\mathcal{Z}\\right)\\;=\\;\\rho_{2}-\\rho_{1}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the probability $\\mathbb{P}$ is calculated using (8). ", "page_idx": 15}, {"type": "text", "text": "B Algorithm ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Here we present more details for the algorithm: Conformalized Survival Distribution using Individual survival Probability at Observed Time (CSD-iPOT). The pseudo-code is presented in Algorithm 1. ", "page_idx": 15}, {"type": "text", "text": "Algorithm 1 CSD-iPOT ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Input: Dataset $\\mathcal{D}$ , testing data with feature $\\mathbf{x}_{n+1}\\in\\mathbb{R}^{d}$ , survival model $\\mathcal{M}$ , predefined percentile levels $\\mathcal{P}=\\{\\rho_{1},\\rho_{2},...\\}$ , repetition parameter+ $R$ ", "page_idx": 15}, {"type": "text", "text": "Output: Calibrated ISD curve for $x_{n+1}$ ", "page_idx": 15}, {"type": "text", "text": "1: Randomly partition $\\mathcal{D}$ into a traini+ng set $\\mathcal{D}^{\\mathrm{train}}$ and a conformal set $\\mathcal{D}^{\\mathrm{con}}$   \n2: Train a survival model $\\mathcal{M}$ using $\\mathcal{D}^{\\mathrm{train}}$   \n3: Make ISD predictions $\\{\\hat{S}_{\\mathcal{M}}(t\\mid x_{i})\\}_{i\\in\\mathbb{Z}^{\\mathrm{con}}}$   \n45::  (InOitpitailoinzea lc) oanpfpolrym tihtey  isnctoerrep osleat:t $\\Gamma_{\\mathcal{M}}=\\mathcal{D}$ ,x tarnadp oplsaetiuodno -tou nmifaokrem t harer IaSy:D $\\mathbf{u}_{R}=\\left[\\mathbf{\\nabla}r/R\\right]_{r=0}^{R}$ ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Gamma_{\\mathcal{M}}=\\Gamma_{\\mathcal{M}}+\\left\\{u\\cdot\\gamma_{i,\\mathcal{M}}\\;\\middle|\\;u\\in\\mathbf{u}_{R}\\right\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Gamma_{\\mathcal{M}}=\\Gamma_{\\mathcal{M}}+\\left\\{\\gamma_{i,\\mathcal{M}},\\cdots,\\gamma_{i,\\mathcal{M}}\\right\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "12: end if ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "13: end for ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "14: \u2200 $\\rho\\in\\mathcal P$ , $\\tilde{S}_{\\mathcal{M}}^{-1}(\\rho\\,|\\,\\pmb{x}_{n+1})=\\hat{S}_{\\mathcal{M}}^{-1}$ (Percentile(\u03c1; \u0393 ) \u2223xn 1 )   \n15: $\\tilde{S}_{\\mathcal{M}}(t\\,|\\,\\mathbf{x}_{n+1})\\,=\\,\\operatorname*{inf}\\big\\{\\rho:\\tilde{S}_{\\mathcal{M}}^{-1}\\big(\\rho\\,|\\,\\mathbf{x}_{n+1}\\big)\\le t\\big\\}$ M\u25b7tran+sform the inverse ISD into a ISD curve ", "page_idx": 15}, {"type": "text", "text": "Our method is motivated by the split conformal prediction [25]. The algorithm starts by partitioning the dataset in a training and a conformal set (line 1 in Algorithm 1). Previous methods [11, 12] recommend mutually exclusive partitioning, i.e., the training and conformal set must satisfy $\\mathcal{D}^{\\mathrm{train}}\\cup$ $\\mathcal{D}^{\\mathrm{con}}=\\mathcal{D}$ and $D^{\\mathrm{train}}\\cap\\mathcal{D}^{\\mathrm{con}}\\,=\\,\\emptyset$ . However, this can cause one problem: reducing the training set size, resulting in underfitting for the models (especially for deep-learning models) and sacrificing discrimination performance. Instead, we consider the two partitioning policies proposed by Qi et al. [8]: (1) using the validation set as the conformal set, and (2) combining the validation and training sets as the conformal set. ", "page_idx": 15}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/b5f8b2c9f56e1f43dbab5e52d3bf65cb9c9cae8d944dd20d93e600e8531cca72.jpg", "img_caption": ["Figure 6: Comparison of CSD and CSD-iPOT. The first row mirrors the original Figure 2\u2019s first row, and the third row reflects its second row. CSD steps include: (d) discretizing the ISDs into predicted percentile times (circles), and calculating conformity scores using the horizontal differences between circles and stars (true outcomes); then (e) adjusting the circles horizontally via conformal regression. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Another algorithm detail is the interpolation and extrapolation (line 4 in Algorithm 1) for the ISDs. This optional operation is required for non-parametric survival algorithms (including semiparametric [26] and discretize time/quantile models [28, 29]). For interpolation, we can use either linear or piecewise cubic Hermit interpolating polynomial (PCHIP) [41] which both can maintain the monotonic property of the survival curves. For extrapolation, we extend ISDs using the starting point [0,1] and ending point $[t_{\\mathrm{end}},\\hat{S}_{\\mathcal{M}}(t_{\\mathrm{end}}\\mid\\pmb{x}_{i})]$ . ", "page_idx": 16}, {"type": "text", "text": "We also include a side-by-side visual comparison of our method to CSD [8] in Figure 6. Both CSD and CSD-iPOT approaches use the same general framework of conformal prediction, but they differ in how to calculate the conformity score and adjust the positions of the predictions. Note that in Figure 6, the horizontal positions of the circles remain unchanged for CSD while the vertical positions of the circles remain unchanged for CSD-iPOT. This unique approach for calculating the conformity score, and the downstream benefit for handling censored subjects (thanks to the conformity score design), together provide a theoretical guarantee for the calibration, as elaborated in the next section. ", "page_idx": 16}, {"type": "text", "text": "C Theoretical Analysis ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "This appendix offers more details on the theoretical analysis in Section 3.4. ", "page_idx": 16}, {"type": "text", "text": "C.1 More on the marginal and conditional calibration ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "This section presents the complete proof for Theorem 3.1 and Theorem 3.2. For the completeness, we start by restating Theorem 3.1: ", "page_idx": 16}, {"type": "text", "text": "Theorem C.1 (Asymptotic marginal calibration). If the instances in $\\mathcal{D}$ are exchangeable, and follow the conditional independent censoring assumption, then for a new dataset $n+1$ , $\\forall\\ \\rho_{1}<\\rho_{2}\\in[0,1]$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\rho_{2}-\\rho_{1}\\quad\\leq\\quad\\operatorname{\\mathbb{P}}\\left({\\tilde{S}}_{\\mathcal{M}}\\big(t_{n+1}\\mid x_{n+1}\\big)\\in\\left[\\rho_{1},\\rho_{2}\\right]\\right)\\quad\\leq\\quad\\rho_{2}-\\rho_{1}+\\frac{1}{|{\\mathcal{D}}^{\\mathrm{con}}|+1}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. This proof is inspired by the proof in Theorem D.1 and D.2 from Angelopoulos et al. [42], the main difference is that our conformity scores are different, and we also have censoring subjects. ", "page_idx": 17}, {"type": "text", "text": "Given the target percentile levels $\\rho_{1}$ and $\\rho_{2}$ , As we remember in the CSD-iPOT procedure, we essentially vertically shift the prediction at Percentile $(\\rho;\\Gamma)$ to $\\rho$ (see (4)). Therefore, the condition in (9) ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\tilde{S}_{\\mathcal{M}}(t_{n+1}\\mid\\mathbf{x}_{n+1})\\ \\in\\ [\\rho_{1},\\rho_{2}],\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "can be transformed into this equivalent condition ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\hat{S}_{\\mathcal{M}}(t_{n+1}\\,|\\,x_{n+1})\\ \\in\\ [\\mathrm{Percentile}(\\rho_{1};\\Gamma_{\\mathcal{M}}),\\mathrm{Percentile}(\\rho_{2};\\Gamma_{\\mathcal{M}})].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "As we recall, the conformity score set consists of the iPOT score for each subject in the conformal set. Let us consider the easy case of an uncensored dataset, then ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Gamma_{\\mathcal{M}}=\\{\\hat{S}_{\\mathcal{M}}(e_{i}\\mid\\pmb{x}_{i})\\}_{i\\in\\mathcal{T}^{\\mathrm{con}}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Without loss of generality, we assume that the conformity scores in $\\Gamma_{\\mathcal{M}}$ are sorted. This assumption is purely technical as it aims for simpler math expression in this proof, i.e., $\\hat{S}_{\\mathcal{M}}(e_{1}\\mid x_{1})<\\hat{S}_{\\mathcal{M}}(e_{2}\\mid$ $\\pmb{x}_{2})<\\cdots<\\hat{S}_{{\\cal M}}(e_{|{\\cal D}|^{\\mathrm{con}}}\\mid\\pmb{x}_{|{\\cal D}^{\\mathrm{con}}|})$ . Therefore, by the exchangeability assumption (the order between subject $n+1$ Mand \u2223sDu\u2223bjects $i\\in\\dot{\\mathcal{Z}}^{\\mathrm{con}}$ do not matter), the iPOT score of subject $n+1$ is equally likely to fall into any of the $\\left|\\mathcal{D}^{\\mathrm{con}}\\right|+1$ intervals between the $[0,1]$ , separated by the $|\\mathcal{D}^{\\mathrm{con}}|$ conformity scores. Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}\\big(\\hat{S}_{\\cal M}(t_{n+1}\\mid x_{n+1})\\in[\\mathrm{Percentile}(\\rho_{1};\\Gamma_{\\cal M}),\\mathrm{Percentile}(\\rho_{2};\\Gamma_{\\cal M})]\\big)=\\frac{\\big[\\big(\\rho_{2}-\\rho_{1}\\big)\\big(\\big|\\mathcal{D}^{\\mathrm{con}}\\big|+1\\big)\\big]}{\\big(\\big|\\mathcal{D}^{\\mathrm{con}}\\big|+1\\big)}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This value is always higher than $\\rho_{2}-\\rho_{1}$ , and if the conformity scores in $\\Gamma_{\\mathcal{M}}$ do not have any tie1, we can also see that the above equation is less than \u03c12 \u2212\u03c11 + co1n 1. ", "page_idx": 17}, {"type": "text", "text": "Now let\u2019s consider the censored case. Based on the probability integral transform, for a censored subject $j$ , the probability that its iPOT value falls into the percentile interval, before knowing its censored time, is (from here we omit the subscript $\\mathcal{M}$ for simple expression) ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\hat{S}(e_{j}\\mid\\boldsymbol{x}_{j})\\le\\boldsymbol{\\rho}\\right)=\\boldsymbol{\\rho},\\quad\\mathrm{and}\\quad\\mathbb{P}\\left(\\boldsymbol{\\rho}_{1}\\le\\hat{S}(e_{j}\\mid\\boldsymbol{x}_{j})\\le\\boldsymbol{\\rho}_{2}\\right)=\\boldsymbol{\\rho}_{2}-\\boldsymbol{\\rho}_{1}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Now given its censored time $c_{j}$ , we can calculate the conditional probability ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Phi(\\rho_{1}\\leq\\delta(\\rho_{1},\\delta_{2})\\,\\sigma_{2}|\\,\\sigma_{3})=\\Phi(\\rho_{1}\\leq\\delta(\\rho_{1},\\delta_{2})\\,\\sigma_{3}|\\,\\sigma_{1})}\\\\ &{\\quad=\\underbrace{\\frac{\\Phi\\left(\\rho_{1}\\leq\\delta(\\rho_{1}\\leq\\delta(\\rho_{1})\\leq\\rho_{2},\\delta_{1}(\\rho_{1})\\leq\\delta(\\rho_{1},\\delta_{2})\\right)}{\\delta(\\delta(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho_{1}))}}_{\\Phi(\\delta(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho_{1}))}}\\\\ &{\\quad+\\underbrace{\\frac{\\Phi\\left(\\rho_{1}\\leq\\delta(\\rho_{1}\\leq\\delta(\\rho_{1})\\leq\\rho_{2},\\delta_{1}(\\rho_{1})\\leq\\delta(\\rho_{1}),\\delta_{2}(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\rho_{2}\\right)}{\\delta(\\rho_{1})}}_{\\Phi(\\delta(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho_{1}))}}\\\\ &{\\quad+\\underbrace{\\frac{\\Phi\\left(\\rho_{1}\\leq\\delta(\\rho_{1})\\leq\\rho_{2},\\delta_{2}(\\rho_{2})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho_{1}),\\delta_{2}(\\rho_{1}),\\delta_{1}(\\delta_{1}(\\rho_{1})\\leq\\rho_{2})\\right)}{\\delta(\\rho_{1})}}_{\\delta(\\rho_{1})\\geq\\delta(\\rho_{1})}}\\\\ &{\\quad+\\underbrace{\\frac{\\Phi\\left(\\rho_{1}\\leq\\delta(\\rho_{1})\\leq\\rho_{2},\\delta_{2}(\\rho_{2}),\\delta_{1}(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho_{1}),\\delta_{2}(\\rho_{1})\\leq\\rho_{1}\\right)}{\\delta(\\rho_{1})}}_{=\\delta(\\rho_{1})\\leq(\\rho_{2})\\leq\\delta(\\rho_{1})}}\\\\ &{\\quad=\\frac{1}{\\delta(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho_{1})\\leq\\delta(\\rho \n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the probability decomposition in the last equality is because the conditional independent censoring assumption, i.e., $e_{j}\\perp c_{j}\\mid x_{j}$ . This above derivation means the $\\hat{S}(e_{j}\\mid x_{j})$ follows the uniform distribution $\\mathcal{U}_{[0,\\hat{S}(c_{i}|\\pmb{x}_{j})]}$ . Therefore, if we do one sampling for each censored subject using $\\mathcal{U}_{[0,\\hat{S}(c_{j}|\\pmb{x}_{j})]}$ , the above[ pro(of\u2223 as)y]mptotically converges to the upper and lower bounds for uncensored su[bje(cts\u2223, fo)r] any survival dataset with censorship. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "For the conditional calibration, we start by formally restating Theorem 3.2. ", "page_idx": 18}, {"type": "text", "text": "Theorem C.2 (Asymptotic conditional calibration). With the conditional independent censoring assumption, if we have these additional three assumptions: ", "page_idx": 18}, {"type": "text", "text": "(i) the non-processed prediction $\\hat{S}(t\\,|\\,\\pmb{x}_{i})$ is also a consistent survival estimator with: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\mathbb{E}\\left[\\operatorname*{sup}_{t}\\left(\\hat{S}(t\\,|\\,x_{i})-S(t\\,|\\,x_{i})\\right)^{2}\\bigg|\\,\\hat{S}\\right]\\geq\\eta_{n}\\right)\\leq\\sigma_{n},\\;s.t.\\quad\\eta_{n}=o(1),\\sigma_{n}=o(1),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "(ii) the inverse ISD estimation $\\hat{S}^{-1}(t\\,|\\,\\pmb{x}_{i})$ is differentiable, ", "page_idx": 18}, {"type": "text", "text": "(iii) there exist some $M$ such that $\\begin{array}{r}{\\operatorname*{inf}_{\\rho}\\frac{d\\mathrm{~}\\hat{S}^{-1}(\\rho|{\\pmb x}_{n+1})}{d\\mathrm{~}\\rho}\\geq M^{-1},}\\end{array}$ , ", "page_idx": 18}, {"type": "text", "text": "then the CSD-iPOT process can asymptotically achieve the conditional distribution calibration: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\tilde{S}(t\\mid\\mathbf{x}_{n+1})=S(t\\mid\\mathbf{x}_{n+1})+o_{p}(1).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. In order to prove this theorem, it is enough to show that (i) $\\tilde{S}(t\\mid\\mathbf{\\alpha}_{(n+1})=\\hat{S}(t\\mid\\mathbf{\\alpha}_{{n+1}})+o_{p}(1),$ , and (ii) $\\hat{S}(t\\,|\\,\\pmb{x}_{n+1})=S(t\\,|\\,\\pmb{x}_{n+1})+o_{p}(1)$ . ", "page_idx": 18}, {"type": "text", "text": "The second equality is obvious to see under the consistent survival estimator assumption (10). ", "page_idx": 18}, {"type": "text", "text": "Now let\u2019s focus on the first equality. We borrow the idea from Lemma 5.2 and Lemma 5.3 in Izbicki et al. [22]. It states under the consistent survival estimator assumption, we can have $\\hat{S}^{-1}(\\mathrm{Percentile}(\\rho;\\Gamma)\\mid x_{n+1})=\\hat{S}^{-1}(\\rho\\mid x_{n+1})+o_{p}(1)$ . ", "page_idx": 18}, {"type": "text", "text": "The only difference between the above claim and the original claim in Izbicki et al. [22], is that they use the CDF while we use the survival function, i.e., the complement of the CDF. ", "page_idx": 18}, {"type": "text", "text": "According to (4), the above claim can be translate to $\\tilde{S}^{-1}(\\rho\\,|\\,{\\pmb x}_{n+1})=\\hat{S}^{-1}(\\rho\\,|\\,{\\pmb x}_{n+1})+o_{p}(1).$ Then if $|\\tilde{S}^{-1}(\\rho\\,|\\,{\\pmb x}_{n+1})-\\hat{S}^{-1}(\\rho\\,|\\,{\\pmb x}_{n+1})|=o_{p}(1).$ , if the $\\hat{S}$ is differentiable, we can have ", "page_idx": 19}, {"type": "equation", "text": "$$\n|\\tilde{S}(t\\,|\\,\\,\\mathbf{x}_{n+1})-\\hat{S}(t\\,|\\,\\,\\mathbf{x}_{n+1})|=o_{p}(1)\\left(\\operatorname*{inf}_{\\rho}\\frac{d\\,\\hat{S}^{-1}(\\rho\\,|\\,\\,\\mathbf{x}_{i})}{d\\,\\rho}\\right)^{-1}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, if there exist some $M$ such that $\\begin{array}{r}{\\operatorname*{inf}_{\\rho}\\frac{d\\mathrm{~}\\hat{S}^{-1}(\\rho|\\pmb{x}_{n+1})}{d\\mathrm{~}\\rho}\\geq M^{-1}}\\end{array}$ . We can get the first equality proved. ", "page_idx": 19}, {"type": "text", "text": "For the censored subjects, we can use the same reasoning and steps in Theorem 3.1 under the conditional independent censoring assumption. This will finish the proof. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "We are aware that linear interpolation and extrapolation will make the survival curves nondifferentiable. Therefore, we recommend using PCHIP interpolation [41] for CSD-iPOT. And extrapolation normally does not need to apply for the survival prediction algorithm because the iPOT value $\\hat{S}_{{\\mathcal M}}(t_{i}\\,|\\,{\\pmb x}_{i})$ can be obtained within the curve range for those methods. However, for quantile-based algorithms, sometimes we need extrapolation. And we recognize this as a future direction to improve. ", "page_idx": 19}, {"type": "text", "text": "C.2 More on the monotonicity ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "CSD is a conformalized quantile regression based [11] method. It first discretized the curves into a quantile curve, and adjusted the quantile curve at every discretized level [8]. Both the estimated quantile curves $(\\hat{q}(\\rho))$ and the adjustment terms $(\\operatorname{adj}(\\rho))$ are monotonically increasing with respect to the quantile levels. However, the adjusted quantile curve \u2013 calculated as the original quantile curve minus the adjustment \u2013 is no longer monotonic. For example, if $\\hat{q}(50\\%)=5$ and $\\hat{q}(60\\%)=6$ , with corresponding adjustments of adj $(50\\%)=2$ and adj $(60\\%)=4$ , the post-CSD quantile curve will be $5-2$ at $50\\%$ and $6-4$ at $60\\%$ , demonstrating non-monotonicity. For a detailed description of their algorithm, readers are referred to Qi et al. [8]. ", "page_idx": 19}, {"type": "text", "text": "However, CSD-iPOT has this nice property. Here we restate the Theorem C.4 ", "page_idx": 19}, {"type": "text", "text": "Theorem C.3. CSD-iPOT process preserves the monotonic decreasing property of the ISD, s.t., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\forall i\\in\\mathbb{Z},\\quad\\forall\\ a\\leq b\\in\\mathbb{R}_{+}:\\quad\\tilde{S}_{\\mathcal{M}}(a\\mid x_{i})\\geq\\tilde{S}_{\\mathcal{M}}(b\\mid x_{i}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. The proof of this theorem is straightforward. The essence of the proof lies in the monotonic nature of all operations within CSD-iPOT. ", "page_idx": 19}, {"type": "text", "text": "First of all, the percentile operation Percentile $(\\rho;\\Gamma_{\\mathcal{M}})$ is a monotonic function, i.e., for all $\\rho_{1}<\\rho_{2}$ , Percentile $(\\rho_{1};\\bar{\\Gamma}_{\\mathcal{M}})<\\mathrm{Percentile}(\\rho_{2};\\Gamma_{\\mathcal{M}})$ . ", "page_idx": 19}, {"type": "text", "text": "Second, because the non-post-processed ISD curves $\\hat{S}(t\\,|\\,\\pmb{x}_{i})$ are monotonic. Therefore, the inverse survival function $\\hat{S}^{-1}(\\boldsymbol{\\rho}\\mid\\mathbf{\\boldsymbol{x}}_{i})$ is also monotonic. Therefore, after the adjustment step as detailed in (4), (4), for all $\\rho_{1}<\\rho_{2}$ , it follows that $\\tilde{S}_{\\mathcal M}^{-1}(\\rho_{1}\\mid\\pmb{x}_{n+1})<\\tilde{S}_{\\mathcal M}^{-1}(\\rho_{2}\\mid\\pmb{x}_{n+1})$ . ", "page_idx": 19}, {"type": "text", "text": "Lastly, by converting the inverse survival function $\\tilde{S}_{\\mathcal{M}}^{-1}(\\rho\\,|\\,\\pmb{x}_{n+1})$ back to survival function $\\tilde{S}_{\\mathcal{M}}(t\\,|\\,\\$ $x_{n+1}{\\mathrm{)}}$ , the monotonicity is preserved. ", "page_idx": 19}, {"type": "text", "text": "These steps collectively affirm the theorem\u2019s proof through the intrinsic monotonicity of the operations involved in CSD-iPOT. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "C.3 More on the discrimination performance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "This section explores the discrimination performance of CSD-iPOT in the context of survival analysis. Discrimination performance, which is crucial for evaluating the effectiveness of survival models, is typically assessed using three key metrics: ", "page_idx": 19}, {"type": "text", "text": "\u2022 Harrell\u2019s concordance index (C-index)   \n\u2022 Area under the receiver operating characteristic curve (AUROC)   \n\u2022 Antolini\u2019s time-dependent C-index ", "page_idx": 19}, {"type": "text", "text": "We will analyze CSD-iPOT\u2019s performance across these metrics and compare it to the performance of CSD. The comparative analysis aims to highlight any improvements and trade-offs introduced by the CSD-iPOT methodology. ", "page_idx": 20}, {"type": "text", "text": "Harrell\u2019s C-index C-index is calculated as the proportion of all comparable subject pairs whose predicted and outcome orders are concordant, defined as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{C-index}\\big(\\{\\hat{\\eta}_{i}\\}_{i\\in\\mathbb{Z}^{\\mathrm{rest}}}\\big)=\\frac{\\sum_{i,j\\in\\mathbb{Z}^{\\mathrm{rest}}}\\delta_{i}\\cdot\\mathbb{I}\\big[t_{i}<t_{j}\\big]\\cdot\\mathbb{I}\\big[\\hat{\\eta}_{i}>\\hat{\\eta}_{j}\\big]}{\\sum_{i,j\\in\\mathbb{Z}^{\\mathrm{rest}}}\\delta_{i}\\cdot\\mathbb{I}\\big[t_{i}<t_{j}\\big]},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\hat{\\eta}_{i}$ denotes the model\u2019s predicted risk score of subject $i$ , which can be defined as the negative of predicted mean/median survival time $(\\mathbb{E}_{t}[\\hat{S}(t\\,|\\,\\pmb{x}_{i})]$ or $\\hat{S}^{-1}(0.5\\mid x_{i}))$ . ", "page_idx": 20}, {"type": "text", "text": "CSD has been demonstrated to preserve the discrimination performance of baseline survival models, as established in Theorem 3.1 byin Qi et al. [8]. In contrast, CSD-iPOT does not retain this property. To illustrate this, we present a counterexample that explains why Harrell\u2019s ${\\mathbf C}_{}$ -index may not be maintained when using CSD-iPOT. ", "page_idx": 20}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/ae4217e5c49f473a7a770929d0fb868ebd879afca830d8daed2ff1efab0aa173.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 7: Counter examples of (a) Harrell\u2019s C-index performance is not preserved by CSD-iPOT; and (b) AUROC performance is not preserved by CSD. ", "page_idx": 20}, {"type": "text", "text": "As shown in Figure 7(a), two ISD curves cross at a certain percentile level $25\\%<\\rho^{*}<50\\%$ . Initially, the order of median survival times (where the curves cross $50\\%$ ) for these curves indicates that patient A precedes patient B. However, after applying the adjustment as defined in (4) \u2013 which involves vertically shifting the prediction from empirical percentile level Percentile $(50\\%;\\Gamma_{\\mathcal{M}})$ to desired percentile level $5\\bar{0}\\%$ . The order of the post-processed median times for the two curvesM (indicated by the hollow circles) is patient B ahead of patient A. That means this adjustment leads to a reversal in the order of risk scores, thereby compromising the C-index. ", "page_idx": 20}, {"type": "text", "text": "AUROC The area under the receiver operating characteristic curve (AUROC) is a widely recognized metric for evaluating discrimination in binary predictions. Harrell\u2019s C-index can be viewed as a special case of the AUROC [2], if we use the negative of survival probability at a specified time $t^{*}-$ $\\hat{S}(t^{*}\\mid{\\pmb x}_{i})$ as the risk score. ", "page_idx": 20}, {"type": "text", "text": "The primary distinction lies in the definition of comparable pairs. In Harrell\u2019s C-index, comparable pairs are those for which the event order is unequivocally determined. Conversely, for the AUROC evaluation at time $t^{*}$ , comparable pairs are defined as one subject experiencing an event before $t^{*}$ and another experiencing it after $t^{*}$ . This implies that for AUROC at $t^{*}$ , a pair of uncensored subjects both having event times before (or both after) $t^{*}$ , is not considered comparable, whereas for the C-index, such a pair is indeed considered comparable. ", "page_idx": 20}, {"type": "text", "text": "The AUROC can be calculated using: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{AUROC}(\\hat{S},t^{*})=\\frac{\\sum_{i,j\\in{\\cal Z}^{\\mathrm{est}}}\\delta_{i}\\cdot\\mathbb{I}\\big[t_{i}\\leq t^{*}\\big]\\cdot\\mathbb{I}\\big[t_{j}>t^{*}\\big]\\cdot\\mathbb{I}\\big[\\hat{S}(t^{*}\\mid x_{i})<\\hat{S}(t^{*}\\mid x_{j})\\big]}{\\sum_{i,j\\in{\\cal Z}^{\\mathrm{est}}}\\delta_{i}\\cdot\\mathbb{I}\\big[t_{i}\\leq t^{*}\\big]\\cdot\\mathbb{I}\\big[t_{j}>t^{*}\\big]},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "From this equation, because the part of $\\delta_{i}\\cdot\\mathbb{1}[t_{i}\\geq t^{*}]\\cdot\\mathbb{1}[t_{j}<t^{*}]$ is independent of the prediction (it only relates to the dataset labels). As long as the post-processing does not change the order of the survival probabilities, we can maintain the same AUROC score. ", "page_idx": 20}, {"type": "text", "text": "Theorem C.4. Applying the CSD-iPOT adjustment to the ISD prediction does not affect the relative order of the survival probabilities at any single time, therefore does not affect the AUROC score of the model. Formally, $\\forall\\mathbf{\\chi}_{i,\\mathbf{\\chi}_{j}}\\in\\mathbb{Z}$ and $\\forall\\;t^{*}\\in\\mathbb{R}_{+}$ , given ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\hat{S}_{\\mathcal{M}}(t^{*}\\mid x_{i})<\\hat{S}_{\\mathcal{M}}(t^{*}\\mid x_{j}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "we must have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\tilde{S}_{\\mathcal{M}}(t^{*}\\mid x_{i})<\\tilde{S}_{\\mathcal{M}}(t^{*}\\mid x_{j}).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Here $\\tilde{S}_{\\mathcal{M}}$ is calculated using 5 in Section 3.2. ", "page_idx": 21}, {"type": "text", "text": "Proof. The intuition is that if we scale the ISD curves vertically. Then the vertical order of the ISD curves at every time point should not be changed. ", "page_idx": 21}, {"type": "text", "text": "Formally, we first represent $\\tilde{S}_{\\mathcal M}(t^{*}\\mid x_{i})$ by $\\tilde{\\rho}_{i}^{*}$ , and represent $\\tilde{S}_{\\mathcal M}(t^{*}\\mid x_{j})$ by $\\tilde{\\rho}_{j}^{*}$ . Then, by applying (5) and then (4), we caMn have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{S}_{\\mathcal{M}}^{-1}\\big(\\tilde{\\rho}_{i}^{*}\\mid\\boldsymbol{x}_{i}\\big)=\\hat{S}_{\\mathcal{M}}^{-1}(\\mathrm{Percentile}\\big(\\tilde{\\rho}_{i}^{*};\\Gamma_{\\mathcal{M}}\\big)\\mid\\boldsymbol{x}_{i}\\big)}\\\\ &{\\tilde{S}_{\\mathcal{M}}^{-1}\\big(\\tilde{\\rho}_{j}^{*}\\mid\\boldsymbol{x}_{j}\\big)=\\hat{S}_{\\mathcal{M}}^{-1}(\\mathrm{Percentile}\\big(\\tilde{\\rho}_{j}^{*};\\Gamma_{\\mathcal{M}}\\big)\\mid\\boldsymbol{x}_{j}\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where Percentile $(\\tilde{\\rho}_{i}^{*};\\Gamma_{\\mathcal{M}})$ is the original predicted probability at $t^{*}$ , i.e., $\\begin{array}{r l}{\\hat{S}_{\\mathcal{M}}(t^{*}}&{{}\\mid\\textbf{\\em x}_{i})~~=}\\end{array}$ Percentile $(\\tilde{\\rho}_{i}^{*};\\Gamma_{\\mathcal{M}})$ . ", "page_idx": 21}, {"type": "text", "text": "Because the Percentile operation and inverse functions are monotonic (Theorem 3.3), therefore, this theorem holds. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "CSD adjusts the survival curves horizontally (e.g., along the time axis). Hence, while the horizontal order of median/mean survival times does not change \u2013 as proved in the Theorem 3.1 from Qi et al. [8] \u2013 the vertical order, represented by survival probabilities, might not be preserved by CSD. ", "page_idx": 21}, {"type": "text", "text": "Let\u2019s use a counter-example to illustrate our point. Figure 7(b) shows two ISD predictions $\\hat{S}(t\\,|\\,\\pmb{x}_{A})$ and $\\hat{S}(t\\mid x_{B})$ for subjects A and B. Suppose the two ISD curves both have the median survival time at $t\\ =\\ 100$ , and the two curves only cross once. Without loss of generality, we assume $\\hat{S}(t^{*}\\mid{\\boldsymbol x}_{A})<\\hat{S}(t^{*}\\mid{\\boldsymbol x}_{B})$ holds for all $t^{*}<100$ and $\\hat{S}(t^{*}\\mid{\\boldsymbol x}_{A})>\\hat{S}(t^{*}\\mid{\\boldsymbol x}_{B})$ holds for all $t^{*}>100$ Now, suppose that CSD modified the median survival time from $t=100$ to $t=150$ for both of the predictions. Then the order between these two predictions at any time in the range of $t^{*}\\in[100,150]$ is changed from $\\hat{S}(t^{*}\\mid{\\mathbf x}_{A})>\\hat{S}(t^{*}\\mid{\\mathbf x}_{B})$ to $\\hat{S}(t^{*}\\mid{\\bf x}_{A})<\\hat{S}(t^{*}\\mid{\\bf x}_{B})$ . ", "page_idx": 21}, {"type": "text", "text": "It is worth mentioning that in Figure 2, a blue curve is partially at the top in (a), intersecting an orange curve around 1.7 days, while the orange curve is consistently at the top in (e). This might raise concerns that the pre- and post-adjustment curves do not maintain the same probability ordering at every time point, suggesting a potential violation. In fact, this discrepancy arises from the discretization step used in our process, which did not capture the curve crossing at 1.7 days due to the limited number of percentile levels (2 levels at $\\begin{array}{l}{{\\frac{1}{3}}}\\end{array}$ and ${\\frac{2}{3}}.$ ) used for simplicity in this visualization. The post-discretization positioning of the orange curve above the blue curve in Figure 2(e) does not imply that the post-processing step alters the relative ordering of subjects. Instead, it reflects the limitations of using only fewer percentile levels. Note that other crossings, such as those at approximately 1.5 and 2.0 days, are captured. In practice, we typically employ more percentile levels (e.g., 9, 19, 39, or 49 as in Ablation Study #2 \u2013 see Appendix E.6), which allows for a more precise capture of all curve crossings, thereby preserving the relative ordering. ", "page_idx": 21}, {"type": "text", "text": "Antolini\u2019s C-index Time-dependent C-index, $C^{t d}$ , is a modified version of Harrell\u2019s C-index [32]. Instead of estimating the discrimination over the point predictions, it estimates the discrimination over the entire curve. ", "page_idx": 21}, {"type": "equation", "text": "$$\nC^{t d}(\\hat{S})=\\frac{\\sum_{i,j\\in\\mathbb{Z}^{\\mathrm{rest}}}\\delta_{i}\\cdot\\mathbb{I}\\left[t_{i}<t_{j}\\right]\\cdot\\mathbb{I}\\left[\\hat{S}(t_{i}\\mid\\pmb{x}_{i})<\\hat{S}(t_{i}\\mid\\pmb{x}_{j})\\right]}{\\sum_{i,j\\in\\mathbb{Z}^{\\mathrm{rest}}}\\delta_{i}\\cdot\\mathbb{I}\\left[t_{i}<t_{j}\\right]}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Compared with (12), the only two differences are: the risk score for the earlier subject $n_{i}$ is represented by the iPOT value $\\hat{S}(t_{i}\\mid\\mathbf{\\boldsymbol{x}}_{i})$ , and the risk score for the later subject $n_{j}$ is represented by the predicted survival probability for $j$ at $t_{i}$ , $\\hat{S}(t_{i}\\mid\\mathbf{\\boldsymbol{x}}_{j})$ . ", "page_idx": 21}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/aede77c943915aad4d0abc3c4e7a8744164dea9c1a46a0e261c4a6ccfc499130.jpg", "img_caption": [], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 8: An real example using DeepHit as the baseline, on the FLCHAIN dataset. The predicted curves in the panels are for the same 4 subjects in the test set. The dashed green line represents the KM curve on the test set. (a) Non post-processed baseline. (b) CSD method on DeepHit. (c) CSD-iPOT method on DeepHit. (d) P-P plots comparison of the three methods. ", "page_idx": 22}, {"type": "text", "text": "$C^{t d}$ can also be represented by the weighted average of AUROC over all time points (Equation 7 and proof in Appendix 1 from Antolini et al. [32]). Suppose given a series of time grid $\\{t_{0},\\dots,t_{k},\\dots,t_{K}\\}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\nC^{t d}(\\hat{S})=\\frac{\\sum_{k=0}^{K}\\mathrm{AUROC}(\\hat{S},t_{k})\\cdot\\omega(t_{k})}{\\sum_{k=0}^{K}\\omega(t_{k})},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\omega(t_{k})=\\frac{\\sum_{i,j\\in{\\mathbb{Z}^{\\mathrm{test}}}}\\delta_{i}\\cdot\\mathbb{1}\\big[t_{i}\\leq t^{*}\\big]\\cdot\\mathbb{1}\\big[t_{j}>t^{*}\\big]}{\\sum_{i,j\\in{\\mathbb{Z}^{\\mathrm{test}}}}\\mathbb{1}\\big[t_{i}<t_{j}\\big]}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The physical meaning of $\\omega(t_{k})$ measures the proportion of comparable pairs at $t_{k}$ over all possible pairs. Therefore, we can have the following important property of our CSD-iPOT. ", "page_idx": 22}, {"type": "text", "text": "Lemma C.5. Applying the CSD-iPOT adjustment to the ISD prediction does not affect the timedependent $C_{}$ -index of the model. ", "page_idx": 22}, {"type": "text", "text": "Proof. Because the $\\omega(t_{k})$ in 15 is independent of the prediction, and also given Theorem C.4, $\\mathbf{AUROC}(\\hat{S},t_{k})=\\mathbf{AUROC}(\\tilde{S},t_{k})$ , we can easily have $C^{t d}(\\hat{S})=C^{t d}(\\tilde{S})$ from the formula in 14. ", "page_idx": 22}, {"type": "text", "text": "As in the previous discussion, CSD does not preserve the vertical order represented by survival probabilities. Therefore, it is natural to see that CSD also does not preserve the $C^{t d}$ performance. ", "page_idx": 22}, {"type": "text", "text": "C.4 More on the significantly miscalibrated models ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Compared to CSD, our CSD-iPOT method exhibits weaker performance on the DeepHit baselines.   \nThis section explores the three potential reasons for this disparity. ", "page_idx": 22}, {"type": "text", "text": "First of all, DeepHit tends to struggle with calibration for datasets that have high KM ending probability [43] and has poor calibration compared to other baselines for most datasets [7, 8]. This is because the DeepHit formulation assumes that, by the end of the predefined $t_{\\mathrm{max}}$ , every individual must already have had the event. Hence, this formulation incorrectly estimates the true underlying survival distribution (often overestimates the risks) for individuals who might survive beyond $t_{\\mathrm{max}}$ . ", "page_idx": 22}, {"type": "text", "text": "Furthermore, apart from the standard likelihood loss, DeepHit also contains a ranking loss term that changes the undifferentiated indicator function in the C-index calculation in (12) with an exponential decay function. This modification potentially enhances the model\u2019s discrimination power but compromises its calibration. ", "page_idx": 22}, {"type": "text", "text": "Lastly, Figure 8(a) shows an example prediction using DeepHit on the FLCHAIN $72.48\\%$ censoring rate with KM curve ends at $68.16\\%$ ). The solids curves represent the ISD prediction from DeepHit for 4 randomly selected subjects in the test set. And the dashed green curve represents the KM curve for the entire test set. It is evident that DeepHit tends to overestimate the subjects\u2019 risk scores (or underestimate the survival probabilities), see Figure 8(d). Specifically, at the last time point $t=5215)$ ), ", "page_idx": 22}, {"type": "text", "text": "KM predicts that most of the instances $\\left(68.16\\%\\right)$ ) should survive beyond this time point. However, the ISD predictions from DeepHit show everyone must die by this last point $(\\hat{S}_{\\mathrm{DeepHit}}\\big(5215\\mid x_{i}\\big)=0$ for all $\\mathbf{\\Delta}\\mathbf{x}_{i}\\mathrm{~-~}\\mathbf{s}\\mathrm{e}\\mathrm{e}$ Figure 8(a)). This clearly violates the unbounded range assumption proposed in Section 3.1, which assumes $\\hat{S}_{\\mathcal{M}}(t\\mid x_{i})>0$ for all $t\\geq0$ . This violation is the main reason why CSD-iPOT exhibits weaker perfMormance on the DeepHit baseline. ", "page_idx": 23}, {"type": "text", "text": "CSD can effectively solve this overestimate issue (Figure 8(b)), as it shift the curves horizontally, i.e., no upper limit for right-hand side for shifting. CSD-iPOT, on the other hand, scale the curves vertically. In such a case, the scaling must be performed within the percentile $[0,1]$ . Furthermore, CSD-iPOT does not have any intervention for the starting and ending probability $\\boldsymbol\\rho=1$ and $\\rho=0$ ) of the curves. So no matter how the post-process changes the percentile in the middle of the curves, the starting and ending points should not be changed, just like the curves in Figure 8(c), whereas the earlier parts of the curve are similar as CSD\u2019s, the last parts gradually drop to 0. ", "page_idx": 23}, {"type": "text", "text": "Consequently, while CSD-iPOT significantly improves upon DeepHit, as shown in Figure 8(d), it still underperforms compared to CSD when dealing with models that are notably miscalibrated like DeepHit. ", "page_idx": 23}, {"type": "text", "text": "D Evaluation metrics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We use Harrell\u2019s C-index [1] for evaluating discrimination performance. The formula is presented in (12). Because we are dealing with a model that may not have proportional hazard assumption, therefore, as recommended [2], we use the negative value of the predicted median survival time as the risk score, i.e., $\\hat{\\eta}_{i}=\\hat{S}^{-1}(0.5\\mid\\pmb{x}_{i})$ . ", "page_idx": 23}, {"type": "text", "text": "The calculation of marginal calibration for a censored dataset is presented in Appendix A and calculated using (8) and (6). ", "page_idx": 23}, {"type": "text", "text": "Conditional calibration, $\\mathrm{Cal}_{\\mathrm{ws}}$ , is estimated using (7). Here we present more details on the implementation. First of all, the evaluation involves further partitioning the testing set into exploring and exploiting datasets. Note that this partition does not need to be stratified (wrt to time $t_{i}$ and event indicator $\\delta_{i}$ ). Furthermore, for the vectors $\\pmb{v}$ , we sampling $M$ i.i.d. vectors on the unit sphere in $\\mathbb{R}^{d}$ . Generally, we want to select a high value for $M$ to enable all possible exploration. For small or medium datasets, we use $M=1000$ . However, due to the computational complexity, for large datasets, we gradually decrease the value of $M\\in[100,1000]$ to get an acceptable evaluating time. We set $\\kappa=33\\%$ in (7) for finding the $\\mathbb{S}_{v,a,b}$ , that means we want to find a worst-slab that contains a least $33\\%$ of the subjects in the testing set. ", "page_idx": 23}, {"type": "text", "text": "Integrated Brier score (IBS) measures the accuracy of the predicted probabilities over all times. IBS for survival prediction is typically defined as the integral of Brier scores (BS) over time points: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{IBS}(\\hat{S};t_{\\mathrm{max}})=\\cfrac{1}{t_{\\mathrm{max}}}\\cdot\\int_{0}^{t_{\\mathrm{max}}}\\mathbf{BS}(t)~d t,}\\\\ &{=\\cfrac{1}{|Z^{\\mathrm{test}}|}\\,\\underset{i\\in\\mathbb{Z}^{\\mathrm{est}}}{\\sum}\\cfrac{1}{t_{\\mathrm{max}}}\\cdot\\int_{0}^{t_{\\mathrm{max}}}\\left(\\cfrac{\\delta_{i}\\cdot\\mathbb{I}\\left[t_{i}\\leq t\\right]\\cdot S(t\\,|\\,x_{i})^{2}}{G(t_{i})}+\\cfrac{\\mathbb{I}\\left[t_{i}>t\\right]\\cdot(1-S(t\\,|\\,x_{i}))^{2}}{G(t)}\\right)~d t,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $G(t)$ is the non-censoring probability at time $t$ . It is estimated with KM on the censoring distribution (flip the event indicator of data), and its reciprocal $\\frac{1}{G(t)}$ is referred to as the inverse probability censoring weights (IPCW). $t_{\\mathrm{max}}$ is defined as the maxim(u)m event time of the combined training and validation datasets. ", "page_idx": 23}, {"type": "text", "text": "Mean absolute error calculates the time-to-event precision, i.e., the average error of predicted times and true times. Here we use MAE-pseudo observation (MAE-PO) [35] for handling censorship in the ", "page_idx": 23}, {"type": "text", "text": "calculation. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{MAE}_{\\mathrm{PO}}\\big(\\{\\widehat{t}_{i}\\}_{i\\in\\mathbb{Z}}\\big)=\\displaystyle\\frac{1}{\\sum_{i\\in\\mathbb{Z}^{\\mathrm{est}}}\\omega_{i}}\\,\\sum_{i\\in\\mathbb{Z}^{\\mathrm{est}}}\\omega_{i}\\times\\big|\\big(1-\\delta_{i}\\big)\\cdot e_{\\mathrm{PO}}\\big(t_{i},\\mathcal{Z}^{\\mathrm{est}}\\big)+\\delta_{i}\\cdot t_{i}-\\widehat{t}_{i}\\big|\\ ,}\\\\ &{\\ e_{\\mathrm{PO}}\\big(t_{i},\\mathcal{Z}^{\\mathrm{est}}\\big)=\\displaystyle\\left\\{\\!\\!\\begin{array}{l l}{N\\times\\mathbb{E}_{t}\\,\\big[S_{\\mathrm{KM}(Z^{\\mathrm{est}})}\\big(t)\\big]-\\big(N-1\\big)\\times\\mathbb{E}_{t}\\,\\big[S_{\\mathrm{KM}(Z^{\\mathrm{est}}-i)}\\big(t)\\big]}&{\\mathrm{if}\\quad\\delta_{i}=0,}\\\\ {t_{i}}&{\\mathrm{otherwise},}\\end{array}\\!\\right.}\\\\ &{\\quad\\quad\\quad\\quad\\mathrm{and}\\quad\\omega_{i}=\\displaystyle\\left\\{\\!\\!1-\\delta_{i}\\cdot S_{\\mathrm{KM}(Z^{\\mathrm{est}})}\\big(t_{i}\\big)\\quad\\mathrm{if}\\quad\\delta_{i}=0,\\!\\!\\begin{array}{l l}{~}&\\\\ &{\\mathrm{otherwise}.}\\end{array}\\!\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here $S_{\\mathrm{KM(\\mathcal{Z}^{\\mathrm{test}})}}(t)$ represents the population level KM curve estimated on the entire testing set $\\mathcal{T}^{\\mathrm{test}}$ , and $S_{\\mathrm{KM}(\\mathbb{Z}^{\\mathrm{test}}-i)}(t)$ represent the KM curves estimated on all the test subjects but exclude subject $i$ . ", "page_idx": 24}, {"type": "text", "text": "C-index, $\\mathrm{Cal}_{\\mathrm{margin}}$ (also called D-cal), ISB, and MAE-PO are implemented in the SurvivalEVAL package [44]. For $\\mathrm{Cal}_{\\mathrm{ws}}$ , please see our Python code for implementation. ", "page_idx": 24}, {"type": "text", "text": "E Experimental Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "E.1 Datasets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We provide a brief overview of the datasets used in our experiments. ", "page_idx": 24}, {"type": "text", "text": "In this study, we evaluate the effectiveness of CSD-iPOT across 15 datasets. Table 3 summarizes the data statistics. Compared to the datasets used in [8], we have added HFCR, WHAS, PdM, Churn, FLCHAIN, Employee, and MIMIC-IV. Specifically, we use the original GBSG dataset, as opposed to the modified version by Katzman et al. [38] used in [8], which has a higher censoring rate and more features. For the rest of the datasets, we employ the same preprocessing methods as Qi et al. [8] \u2013 see Appendix E of their paper for details about these datasets. Below, we describe these newly added datasets: ", "page_idx": 24}, {"type": "text", "text": "Table 3: Key statistics of the datasets. We categorize datasets into small, medium, and large, based on the number of instances, using thresholds of 1,000 and 10,000 instances. The bolded number represents datasets with a high percentage of censorship $(\\ge60\\%)$ or its KM estimation ends at a high probability $(\\ge50\\%)$ ). Numbers in parentheses indicate the number of features after one-hot encoding. ", "page_idx": 24}, {"type": "table", "img_path": "l8XnqbQYBK/tmp/10aa6d8c4fb963a2c560bb8593565fea7770272d83b7522dee5235e79d98efb7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Heart Failure Clinical Record dataset (HFCR) [45] contains medical records of 299 patients with heart failure, aiming to predict mortality from left ventricular systolic dysfunction. This dataset can be downloaded from UCI Machine Learning Repository [46]. ", "page_idx": 24}, {"type": "text", "text": "Worcester Heart Attack Study dataset (WHAS) [49] contains 500 patients with acute myocardial infarction, focusing on the time to death post-hospital admission. The data was already post-processed and can be downloaded from the scikit-survival package [56]. ", "page_idx": 24}, {"type": "text", "text": "Predictive Maintenance (PdM) contains information on 1000 equipment failures. The goal is to predict the time to equipment failure and therefore help alert the maintenance team to prevent that failure. It includes 5 features that describe the pressure, moisture, temperature, team information (the team who is running this equipment), and equipment manufacturer. We apply one-hot encoding on the team information and equipment manufacturer features. The dataset can be downloaded from the PySurvival package [52]. ", "page_idx": 25}, {"type": "text", "text": "The customer churn prediction dataset (Churn) focuses on predicting customer attrition. We apply one-hot encoding on the US region feature and exclude subjects who are censored at time 0. The dataset can be downloaded from the PySurvival package [52]. ", "page_idx": 25}, {"type": "text", "text": "Serum Free Light Chain dataset (FLCHAIN) is a stratified random sample containing half of the subjects from a study on the relationship between serum free light chain (FLC) and mortality [53]. This dataset is available in R\u2019s survival package [57]. Upon downloading, we apply a few preprocessing steps. First, we remove the three subjects with events at time zero. We impute missing values for the \u201ccreatinine\u201d feature using the median of this feature. Additionally, we eliminate the chapter feature (a disease description for the cause of death by chapter headings of the ICD code) because this feature is only available for deceased (uncensored) subjects \u2013 hence, knowing this feature will be equivalent to leaking the event indicator label to the model. ", "page_idx": 25}, {"type": "text", "text": "Employee dataset contains employee activity information that can used to predict when an employee will quit. The dataset can be downloaded from the PySurvival package [52]. It contains duplicate entries; after dropping these duplicates, the number of subjects in the dataset is reduced from 14,999 to 11,991. We also apply one-hot encoding to the department information. ", "page_idx": 25}, {"type": "text", "text": "MIMIC-IV database [58] provides critical care data information for patients within the hospital. We focus on a cohort of all-cause mortality data curated by [35], featuring patients who survived at least 24 hours post-ICU admission. The event of interest, death, is derived from hospital records (during hospital stay) or state records (after discharge). The features are laboratory measurements within the first 24 hours after ICU admission. ", "page_idx": 25}, {"type": "text", "text": "German Breast Cancer Study Group (GBSG) [51] contains 686 patients with node-positive breast cancer, complete with prognostic variables. This dataset is available in R\u2019s survival package [57]. While the original GBSG offers a higher rate of censoring and more features, [8] utilized a modified version of GBSG from [38], merged with uncensored portions of the Rotterdam dataset, resulting in fewer features, a lower censor rate, and a larger sample size. ", "page_idx": 25}, {"type": "text", "text": "Figure 9 shows the Kaplan-Meier (KM) estimation (blue curves) for all 15 datasets, alongside the event and censored histograms (represented by green and orange bars, respectively) in a stacked manner, where the number of bins is determined by the Sturges formula: $\\lceil\\bar{\\log}(\\lvert\\mathcal{D}\\rvert)+1\\rceil$ . ", "page_idx": 25}, {"type": "text", "text": "E.2 Baselines ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section, we detail the implementation of the seven baseline models used in our experiments, consistent with Qi et al. [8]. ", "page_idx": 25}, {"type": "text", "text": "\u2022 Accelerate Failure Time (AFT) [36] with Weibull distribution is a linear parametric model that uses a small $l_{2}$ penalty on parameters during optimization. It is implemented in lifelines packages [59]. \u2022 Gradient Boosting Cox model $(G B)$ [37] is an ensemble method that employs 100 boosting stages with a partial likelihood loss [60] for optimization and $100\\%$ subsampling for ftiting each base learner. The model is implemented in scikit-survival packages [56]. \u2022 Neural Multi-Task Logistic Regression (N-MTLR) [39] is a discrete-time model which is an NN-extension of the linear multi-task logistic regression model (MTLR) [28]. The number of discrete times is determined by the square root of the number of uncensored patients. We use quantiles to divide those uncensored instances evenly into each time interval, as suggested in [61, 3]. We utilize the N-MTLR code provided in Qi et al. [8]. \u2022 DeepSurv [38] is a NN-extension of the Cox proportional hazard model (CoxPH) [26]. To make ISD prediction, we use the Breslow method [62] to estimate the population-level baseline hazard function. We utilize the DeepSurv code provided in Qi et al. [8]. ", "page_idx": 25}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/9b535f398d70604032aeae9013a0f8e8330f384e1fe2aed39d9703b898e821ba.jpg", "img_caption": ["Figure 9: Kaplan Meier curves and event/censored histograms for all 15 datasets. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "\u2022 DeepHit [29] is also a discrete-time model where the number and locations of discrete times are determined in the same way as the N-MTLR model (the square root of numbers of uncensored patients, and quantiles). The model is implemented in pycox packages [27]. ", "page_idx": 26}, {"type": "text", "text": "\u2022 CoxTime [27] is a non-proportional neural network extension of the CoxPH. The model is implemented in pycox packages [27]. ", "page_idx": 26}, {"type": "text", "text": "\u2022 Censored Quantile Regression Neural Network (CQRNN) [40] is a quantile regression-based method. We add the bootstrap-rearranging post-processing [31] to correct non-monotonic predictions. We use the CQRNN code provided in Qi et al. [8]. ", "page_idx": 27}, {"type": "text", "text": "E.3 Hyperparameter settings for the main experiments ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Full hyperparameter details for NN-Based survival baselines In the experiments, all neural network-based methods (including N-MTLR, DeepSurv, DeepHit, CoxTime, and CQRNN) used the same architecture and optimization procedure. ", "page_idx": 27}, {"type": "text", "text": "\u2022 Training maximum epoch: 10000   \n\u2022 Early stop patients: 50   \n\u2022 Optimizer: Adam   \n\u2022 Batch size: 256   \n\u2022 Learning rate: 1e-3   \n\u2022 Learning rate scheduler: CosineAnnealingLR   \n\u2022 Learning rate minimum: 1e-6   \n\u2022 Weight decay: 0.1   \n\u2022 NN architecture: [64, 64]   \n\u2022 Activation function: ReLU   \n\u2022 Dropout rate: 0.4 ", "page_idx": 27}, {"type": "text", "text": "Full hyperparameter details for CSD and CSD-iPOT ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 Interpolation: {Linear, PCHIP}   \n\u2022 Extrapolation: Linear   \n\u2022 Monotonic method: {Ceiling, Flooring, Booststraping}   \n\u2022 Number percentile: {9, 19, 39, 49}   \n\u2022 Conformal set: {Validation set, Training set $^+$ Validation set}   \n\u2022 Repetition parameter: {3, 5, 10, 100, 1000} ", "page_idx": 27}, {"type": "text", "text": "E.4 Main results ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we present the comprehensive results from our primary experiment, which focuses on evaluating the performance of CSD-iPOT compared to the original non-post-processed baselines and CSD. ", "page_idx": 27}, {"type": "text", "text": "Note that for the MIMIC-IV datasets, CQRNN fails to converge with any hyperparameter setting possibly due to the extremely skewed distribution. As illustrated in Figure 9, $80\\%$ of event and censoring times happen within the first bin, and the distribution exhibits long tails extending to the 17th bin. ", "page_idx": 27}, {"type": "text", "text": "Discrimination In Figure 10, we demonstrate the discrimination performance of CSD-iPOT compared to benchmark methods, as measured by C-index. The panels are ordered by dataset size, from smallest to largest. In each panel, the performance of the non-post-processed baselines is shown with blue bars, CSD with orange bars, and CSD-iPOT with green bars. We can see from the figure that the three methods exhibit basically the same performance across all datasets. Indeed, as we can see from the summary in Table 2, CSD-iPOT ties with the baselines in 75 out of 104 times. In the remaining 29 times they do not tie, none of them are significantly different from each other. For the 22 times CSD-iPOT underperforms, most of them are wrt to DeepHit or CQRNN baselines (e.g., DeepHit for HFCR, PBC, GBSG, etc.). And CSD-iPOT can even outperform 7 times (e.g., GB in HFCR). ", "page_idx": 27}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/0ad1f96da8417c4a7778ebc091fcef7d8b8627e8597612dfe0c9be3fffb8f4fd.jpg", "img_caption": ["Figure 10: Violin plots of C-index performance of our method (CSD-iPOT) and benchmarks. A higher value indicates better performance. The shape of each violin plot represents the probability density of the performance scores, with the black bar inside the violin indicating the mean performance. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "Marginal calibration In Figure 11, we present the marginal calibration performance of CSD-iPOT versus the benchmark models. The arrangement and color schemes of the panels are consistent with those used previously. For marginal calibration evaluation, we add a \u201cdummy\u201d model \u2013 Kaplan-Meier (KM) curve (depicted by red dashed lines in each panel) \u2013 to serve as the empirical lower limit. We calculate each KM curve using the training set and apply it identically to all test samples. It is called a \u201cdummy\u201d because it lacks the ability to discriminate between individuals. However, it asymptotically achieves perfect marginal calibration (see Appendix B in [8]). ", "page_idx": 28}, {"type": "text", "text": "Our results in Figure 11 indicate a significant improvement in calibration performance with CSD-iPOT over both baselines and CSD. Overall, our method outperforms the baselines in 95 out of 104 times (Table 2). In the remaining 9 times where it does not outperform the baseline, only once is the difference statistically significant, and the marginal calibration score in this single case (GB for SEER-liver) is still close to the empirical lower bound (red dashed line). ", "page_idx": 28}, {"type": "text", "text": "For datasets characterized by higher censoring rates or high KM ending probabilities (HFCR, PBC, PdM, FLCHAIN, Employee, MIMIC-IV), our method shows superior performance. For those datasets, CSD tends to produce non-calibrated predictions compared with baselines. This outcome likely stems from the inaccuracies of the KM-sampling method under conditions of high censor rates or ending probabilities, as discussed in Section 2. Nonetheless, our approach still improves the marginal calibration scores for the baselines under these circumstances. ", "page_idx": 28}, {"type": "text", "text": "Conditional calibration Figure 12 showcases the conditional calibration performance of CSD-iPOT versus the benchmarks, evaluated using $\\mathrm{Cal}_{\\mathrm{ws}}$ . ", "page_idx": 28}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/2d10aa56f4065ee1cabec97484b84937d7b7308f1af578c448e49e3a9cb4a449.jpg", "img_caption": [], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "Figure 11: Violin plots of $\\mathrm{Cal}_{\\mathrm{margin}}$ performance of our method (CSD-iPOT) and benchmarks. A lower value indicates superior performance. The shape of each violin plot represents the probability density of the performance scores, with the black bar inside the violin indicating the mean performance. The red lines represent the mean calibration performance for KM, serving as an empirical lower limit. ", "page_idx": 29}, {"type": "text", "text": "Compared with marginal calibration, we cannot use any method to establish the empirical upper bound. One might think that once we establish the worst slab, we can calculate the KM curve on this slab and then use it as the empirical upper bound for the conditional calibration. However, identifying a universal worst slab across all the models is impractical. That means different models exhibit varying worst-slabs. e.g., N-MTLR can have the worst calibration for overweighted males, while DeepSurv might perform relatively good calibration for this group but poorly for disabled cardiovascular patients. ", "page_idx": 29}, {"type": "text", "text": "The results in Figure 11 indicate a significant improvement in conditional calibration performance using our method over both baselines and CSD. Overall, our method improves the conditional calibration performance of baselines 64 out of 69 times, with significant improvements 29 times out of 64 (Table 2). ", "page_idx": 29}, {"type": "text", "text": "Our method outperforms CSD in 51 out of 69 cases. Most instances where our method underperforms are relative to the DeepHit and CQRNN baselines (the reasons are explained in Appendix C.4). To evaluate the practical beneftis of CSD-iPOT over CSD, we present four case studies in Figure 13. The figure showcases 4 concrete examples where CSD (orange) leads to significant miscalibration within certain subgroups (i.e., elderly patients, women, high-salary, and non-white-racial), but CSD-iPOT (green) can effectively generate more conditional calibrated predictions which are closer to the optimal line. Moreover, all four examples illustrate that the miscalibration of CSD consistently occurs in low-probability regions, corroborating our assertion in Section 3.4 that the conditional Kaplan-Meier sampling method employed by CSD is problematic if the tail of the distribution is unknown. ", "page_idx": 29}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/0224edd8719fa3aec5f08a78ad8e79fb5873aa48f10e74910d679b627dfdc652.jpg", "img_caption": [], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "Figure 12: Violin plots of $\\mathrm{Cal}_{\\mathrm{ws}}$ performance of our method (CSD-iPOT) and benchmarks. A lower value indicates superior performance. The shape of each violin plot represents the probability density of the performance scores, with the black bar inside the violin indicating the mean performance. ", "page_idx": 30}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/9ee3cf01e1779cd6bc15e51aa4a9ec76c94a9bb1fc2eb6dfab61d971c313c757.jpg", "img_caption": [], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "Figure 13: Case studies of the conditional calibration between CSD and CSD-iPOT. (a) For the elder age subgroup on HFCR, with AFT as the baseline; (b) For women subgroup on FLCHAIN, with GB as the baseline; (c) For the high salary subgroup on Employee, with DeepSurv as the baseline; (d) For the non-white-racial subgroup on MIMIC-IV, with MTLR as the baseline. All four cases show that CSD-iPOT is close to the ideal, while CSD is not. ", "page_idx": 30}, {"type": "text", "text": "IBS Figure 14 illustrates the IBS performance of CSD-iPOT versus the benchmarks. According to DeGroot and Fienberg [63], BS can be decomposed into a calibration part and a discrimination part. This implies that IBS, an integrated version of BS, assesses aspects of calibration. Our results in Figure 14 and Table 2 show that our method improves the IBS score in most of the cases (63 wins, 18 ties, and 23 losses). ", "page_idx": 30}, {"type": "text", "text": "MAE-PO Our results in Figure 15 and Table 2 show that our method improves the MAE-PO in general (54 wins, 33 ties, and 17 losses). ", "page_idx": 30}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/d5399e4915d2c195d09cff4b82858b535346e939e32bf862cd5e8dcb7d4a93ba.jpg", "img_caption": [], "img_footnote": ["Figure 14: Violin plots of IBS performance of our method (CSD-iPOT) and benchmarks. A lower value indicates superior performance. The shape of each violin plot represents the probability density of the performance scores, with the black bar inside the violin indicating the mean performance. "], "page_idx": 31}, {"type": "text", "text": "E.5 Computational analysis ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Space complexity Although most of the computational cost arises from ISD interpolation and extrapolation, most of the memory cost of our method stems from storing the conformity scores into an array and performing the Percentile $(\\cdot)$ operation. ", "page_idx": 31}, {"type": "text", "text": "Let\u2019s reuse the symbol $N=\\left|\\mathcal{D}^{\\mathrm{con}}\\right|$ as the number of subjects in the conformal set, $\\mathcal{P}=\\{\\rho_{1},\\rho_{2},...\\}$ is the predefined discretized percentiles, so that $|\\mathcal P|$ be the number of predefined percentiles. And $R$ is the repetition parameter for KM-sampling. ", "page_idx": 31}, {"type": "text", "text": "CSD [8] process first discretized the ISD curves into percentile times (PCTs) using $\\mathcal{P}$ . Then it calculates a conformity score for each individual at every percentile level $\\rho$ (i.e., each individual will contribute for $|\\mathcal P|$ conformity scores). Lastly, the \u201cKM-sampling\u201d process involves repeating each individual by $R$ times. Therefore, the memory complexity of CSD is $O(N\\cdot|\\mathcal{P}|\\cdot R)$ . In contrast, our CSD-iPOT method only calculates one iPOT score (as the conformity score) for each duplicated individual. After sampling, the total memory complexity of CSD-iPOT is $O(N\\cdot R)$ . ", "page_idx": 31}, {"type": "text", "text": "Let consider an example of using SEER-stomach dataset in our main experiment in Appendix E.4, with a repetition parameter $R\\;=\\;1000$ , and number of predefined percentiles $\\left|\\mathcal{P}\\right|\\;=\\;\\mathrm{\\bar{1}}9^{2}$ . CSD\u2019s conformity score matrix requires $N\\times|\\mathcal{P}|\\times R=(100360^{\\circ}\\ast0.9)\\times19^{\\circ}\\times1000\\times8$ bytes $\\approx13.73\\:\\mathrm{Gb}$ . ", "page_idx": 31}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/e9d6bfc28d0d1fdf8d62369032a3cf338064d80005ef1c38264908af75cd2ab8.jpg", "img_caption": [], "img_footnote": ["Figure 15: Violin plots of MAE-PO performance of our method (CSD-iPOT) and benchmarks. A lower value indicates superior performance. The shape of each violin plot represents the probability density of the performance scores, with the black bar inside the violin indicating the mean performance. "], "page_idx": 32}, {"type": "text", "text": "Our CSD-iPOT method needs only $N\\times R\\approx0.72$ Gb to store the conformity score. If we change to an even larger dataset or increase $|\\mathcal P|$ , CSD may become infeasible. ", "page_idx": 32}, {"type": "text", "text": "Other memory costs, e.g., storing features and ISD predictions, incur negligible memory costs. This is because the number of feature $d$ , and the length of the ISDs are much smaller than the repeat parameters $R$ . ", "page_idx": 32}, {"type": "text", "text": "Time complexity The primary sources of time complexity in CSD-iPOT are two-fold: ", "page_idx": 32}, {"type": "text", "text": "\u2022 ISD interpolation and extrapolation (line 4 in Algorithm 1);   \n\u2022 An optional monotonic step for the CQRNN model (see discussion below). ", "page_idx": 32}, {"type": "text", "text": "Note that other time complexity, e.g., running the Percentile operation or adjusting the ISD curves using lines 14-15 in Algorithm 1, incur negligible time cost. ", "page_idx": 32}, {"type": "text", "text": "Here we analyze two kinds of time complexity: training complexity and inference complexity. Figure 16 and Figure 17 empirically compare the training time and inference time of the CSD-iPOT method with those of non-post-processed baselines and CSD across 10 random splits. Both CSD and CSD-iPOT use the following hyperparameters to enable a fair comparison: ", "page_idx": 32}, {"type": "text", "text": "\u2022 Interpolation: PCHIP \u2022 Extrapolation: Linear \u2022 Monotonic method: Bootstrapping \u2022 Number of percentile: 9 \u2022 Conformal set: Training set $^+$ Validation set \u2022 Repetition parameter: 1000 ", "page_idx": 32}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/8aed2056e1f9a7f5efecc4da0ef99a5b034aa7730a90c3363e1c1268d4b6d8ef.jpg", "img_caption": ["Figure 16: Training time comparisons (mean with $95\\%$ confidence interval). "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/3c07d4713fb5acb6e2d89fb0d9bc07dd57a7a15ea8ce77f0e844c462a542f62d.jpg", "img_caption": ["Figure 17: Inference time comparisons (mean with $95\\%$ confidence interval). "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "Each point in Figure 16 represents an average training time of the method, where for the non-postprocessed baselines it is purely the training time of the survival model, while for CSD and CSD-iPOT, it is the training time of the baselines plus the running time for the conformal training/learning. In Figure 16, we see that CSD-iPOT can significantly reduce the additional time imposed by the CSD step on all survival analysis models (AFT, GB, N-MTLR, DeepSurv, DeepHit, and CoxTime). The only exceptional is the quantile-based method CQRNN, where for the 4 small datasets (HFCR, PBC, WHAS, and GBM) CSD-iPOT actually increase the training time. This is because, for those datasets, the quantile curves predicted by CQRNN are not monotonic. To address this, we attempted three methods before we directly apply CSD-iPOT, including ceiling, flooring, and bootstrap rearranging Chernozhukov et al. [31] \u2013 with the bootstrap method proving most effective, albeit at a significant computational cost. ", "page_idx": 34}, {"type": "text", "text": "Similarly, each point in Figure 17 represents an average inference time of the method, where for the non-post-processed baselines it is purely the inference time of the ISD predictions from the survival model, while for CSD and CSD-iPOT, it is the inference time of the ISDs plus the post-processing time. We observe the inference time follows the same trend as the training time. The extra cost for the 4 small datasets (HFCR, PBC, WHAS, and GBM) is still due to the non-monotonic issues. In those cases, the predicted curves by CQRNN become monotonic after applying CSD. However, surprisingly, after applying CSD-iPOT, the curve remains non-monotonic. That is why the inference time for baselines and CSD-iPOT is higher than CSD on those four datasets. ", "page_idx": 34}, {"type": "text", "text": "E.6 Ablation Studies ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Ablation Study #1: impact of repetition parameter $R$ As we proved in Theorem 3.1, for a censored subject $j$ , if we sample its iPOT value using $\\mathcal{U}_{0,\\hat{S}_{\\mathcal{M}}(c_{i}|\\pmb{x}_{i})}$ , we can asymptotically achieve the exact marginal calibration. However, empirically, due to l(im\u2223ite)d sample sizes, we find that only making one sampling for each censored subject will not achieve a good calibration performance. Instead, we propose the method of repetition sampling, i.e., sampling $R$ times from $\\mathcal{U}_{0,\\hat{S}_{\\mathcal{M}}(c_{i}|\\pmb{x}_{i})}$ . ", "page_idx": 34}, {"type": "text", "text": "This ablation study tries to find how this repetition parameter $R$ affects the performance, in terms of both discrimination and calibration. We gradually increase $R$ , from 3 to 1000, and assume the performance should converge at a certain level. This ablation study uses the following hyperparameters to enable a fair comparison: ", "page_idx": 34}, {"type": "text", "text": "\u2022 Interpolation: PCHIP   \n\u2022 Extrapolation: Linear   \n\u2022 Monotonic method: Bootstrapping   \n\u2022 Number of percentile: 9   \n\u2022 Conformal set: Training set $^+$ Validation set   \n\u2022 Repetition parameter: 3, 5, 10, 100, 1000 ", "page_idx": 34}, {"type": "text", "text": "Figure 18, Figure 19, and Figure 20 present the C-index, marginal calibration, and conditional calibration performances, respectively. ", "page_idx": 34}, {"type": "text", "text": "TL;DR The repetition parameter value has barely any impact on the C-index, and increasing $R$ can benefit the marginal and conditional calibration, with convergence observed around $R=100$ . ", "page_idx": 34}, {"type": "text", "text": "In Figure 18, we see that the C-index for CSD-iPOT using 5 different repetition numbers has no visible differences, for almost all baselines and all datasets. The only exception is there are slight differences for DeepHit baseline on HFCR and Employee datasets, where higher $R$ will slightly decrease the C-index performance insignificantly. ", "page_idx": 34}, {"type": "text", "text": "In Figure 19, we can clearly see the repetition parameter has a great impact on the marginal calibration. For most datasets, a higher repetition will significantly improve (decrease) the marginal calibration score. This trend is more clear for high censoring rate datasets (FLCHAIN, Employee, MIMIC-IV, etc), while for low censoring rate datasets (GBM, NACD, SUPPORT, which have censoring rates less than $40\\%$ ), the trends still exist but the differences are not very significant. The marginal calibration performance usually converges when $R\\ge100$ (the pink and green violins are almost the same for all datasets and all baselines). As a higher repetition parameter will increase the memory usage and computational complexity (Appendix E.5), we suggest using $R=100$ . ", "page_idx": 34}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/0346c48d6e19ea90d932a42ce1a1d01809104caf1f1554d25ba58e2aac6de44a.jpg", "img_caption": ["Figure 18: Violin plots of C-index performance for Ablation Study #1: impact of repetition parameter. A higher value indicates superior performance. "], "img_footnote": [], "page_idx": 35}, {"type": "text", "text": "", "page_idx": 35}, {"type": "text", "text": "In Figure 20, the trends in conditional calibration are similar to those in marginal calibration. Most of the differences are more significant for high censoring rate datasets and less significant for low censoring rate datasets. And the conditional calibration performance also converges at $R\\ge100$ (the pink and green violins are almost the same for all datasets and all baselines). ", "page_idx": 35}, {"type": "text", "text": "Ablation Study #2: impact of predefined percentiles $\\mathcal{P}$ Different choices of $\\mathcal{P}$ may lead to slightly different survival distributions, all of which allow us to obtain provable distribution calibration, as discussed next. Theoretically, discretizing a continuous curve into a series of discrete points may result in some loss of information. However, this can be mitigated by using a sufficiently fine grid for percentile discretization. Therefore, we anticipate that if we select $\\mathcal{P}$ that contains finer grid percentiles, the performance (both calibration and discrimination) will be better. ", "page_idx": 35}, {"type": "text", "text": "Previous studies have commonly employed 10 equal-width probability intervals for calculating distribution calibration [3, 6, 8], making an intuitive starting choice for 9 percentile levels at $\\mathcal{P}=$ $\\{10\\%,20\\%,\\allowbreak\\dots,90\\%\\}^{3}$ . ", "page_idx": 35}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/d393113a31a6379e37a3c144488c078b39377a35d16e552ddef7651e5e354564.jpg", "img_caption": ["Figure 19: Violin plots of $\\mathrm{Cal}_{\\mathrm{margin}}$ performance for Ablation Study #1: impact of repetition parameter. A lower value indicates superior performance. "], "img_footnote": [], "page_idx": 36}, {"type": "text", "text": "We compare this standard setting with 19 percentile levels $(\\mathcal{P}=\\left\\{5\\%,10\\%,\\ldots,95\\%\\right\\})$ ), 39 percentile levels $(\\bar{\\mathcal{P}}=\\{2.5\\%,5\\%,\\ldots,97.5\\%\\})$ ), and 49 percentile levels $(\\mathcal{P}=\\{2\\%,4\\%,\\ldots,98\\%\\})$ . All the calibration evaluations (for both marginal and conditional) are performed on 10 equal-width intervals to maintain comparability, following recommendations by [3]. This ablation study uses the following hyperparameters to enable a fair comparison: ", "page_idx": 36}, {"type": "text", "text": "\u2022 Interpolation: PCHIP   \n\u2022 Extrapolation: Linear   \n\u2022 Monotonic method: Bootstrapping   \n\u2022 Number percentile: 9, 19, 39, 49   \n\u2022 Conformal set: Training set $^+$ Validation set   \n\u2022 Repetition parameter: 1000 ", "page_idx": 36}, {"type": "text", "text": "Figure 21, Figure 22, and Figure 23 present the C-index, marginal calibration, and conditional calibration performances, respectively. ", "page_idx": 36}, {"type": "text", "text": "TL;DR The number of percentiles has no impact on the C-index, and has a slight impact on marginal and conditional calibration. ", "page_idx": 36}, {"type": "text", "text": "In Figure 21, we see that the C-index for the 4 percentile numbers has no visible differences, for all baselines except CQRNN. It is worth mentioning that the difference for CQRNN is due to its quantile regression nature, requiring more trainable parameters as percentiles increase. ", "page_idx": 36}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/f4307b4ed35dc2307f237b737d0aeda5381ce266e68c3514c1ad7ff71ffb9305.jpg", "img_caption": ["Figure 20: Violin plots of $\\mathrm{Cal}_{\\mathrm{ws}}$ performance for Ablation Study #1: impact of repetition parameter. A lower value indicates superior performance. "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "In Figure 22, we can see the number of percentiles has some impact on the marginal calibration. For example, the results for Employee and MIMIC-IV show some perturbation as we increase the number of percentiles. However, trends are inconsistent across models, e.g., fewer percentile levels are preferable by AFT, GB, N-MTLR, DeepSurv for Employee, while more percentile levels are preferable by DeepHit and CoxTime. Also, most differences in Figure 22 are insignificant. ", "page_idx": 37}, {"type": "text", "text": "In Figure 23, the trends in conditional calibration are similar to those in marginal calibration. Most of the differences are insignificant and the trends are inconsistent. ", "page_idx": 37}, {"type": "text", "text": "These results suggest the choice of predefined percentiles $\\mathcal{P}$ has minimal impact on the performance. In practical applications, the reader can choose the best-performing $\\mathcal{P}$ at their preference. However, it is worth noticing that a higher percentile will result in more computational cost. Therefore, we suggest that it is generally enough to choose $\\mathcal{P}=\\{10\\%,20\\%,\\ldots,90\\%\\}$ . ", "page_idx": 37}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/e9987d4952a609793694ea26f006c4410d94859ee9046e20bc8d45e5b068c776.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Figure 21: Violin plots of C-index performance for Ablation Study #2: impact of predefined percentiles. A higher value indicates superior performance. ", "page_idx": 38}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: The abstract and the last paragraph in Section 1 clearly state the contribution of this paper. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 38}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 38}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/1915b03719212627eef6c66b91160cc9779b794b8971b855709cadd093039acf.jpg", "img_caption": ["Figure 22: Violin plots of $\\mathrm{Cal}_{\\mathrm{margin}}$ performance for Ablation Study #2: impact of predefined percentiles. A lower value indicates superior performance. "], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: The CSD-iPOT method does not have theoretically guarantee for the preservation of Harrell\u2019s C-index. This is mentioned in Section 3.4 and Table 1, and theoretically justified in Appendix C.3. Section 5 measures this perspective empirically. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 39}, {"type": "image", "img_path": "l8XnqbQYBK/tmp/943603822666c49a4dc99e312e0dad823bd94083dfb50260ae681a107ab00416.jpg", "img_caption": ["Figure 23: Violin plots of $\\mathrm{Cal}_{\\mathrm{ws}}$ performance for Ablation Study #2: impact of predefined percentiles. A lower value indicates superior performance. "], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: Section 3.4 presents all the theories with the necessary assumptions and Appendix C presents the complete proofs for those theorems. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 40}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: Section 5 outlines the pipelines of the experiments and directs the reader to the GitHub repository for the complete code. Further experimental details, e.g., evaluation metrics, dataset preprocessing, baseline architecture, hyperparameters, etc., are included in the Appendix D and E. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 41}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: All the codes for reproducing the experiments are included in the GitHub link in Section 5, along with 11 publicly available datasets. For MIMIC-IV and SEER datasets, we provide the preprocessing code, and users need to apply for the data by themselves, following the instructions in Appendix E.1. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code. \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. ", "page_idx": 41}, {"type": "text", "text": "\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 42}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: Section 5 states how we split the data in a stratified manner. Further experimental details and hyperparameters information are included in the Appendix E.2 and E.3. ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 42}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: The paper uses violin plots to show the density distribution for the results from 10 random split of the experiments. We also use two-sided $t$ -test to check whether the differences are significant (Table 2). ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified. ", "page_idx": 42}, {"type": "text", "text": "\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). \u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 43}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: The paper includes those information in the computational efficiency analysis in Appendix E.5. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 43}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: The authors are sure that this research conforms the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 43}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: This research motivates the use of conditional distribution calibration in survival analysis. This objective aligns with fairness perspective, where clinical decision systems should guarantee equalized calibration across any protected groups (in Section 1). The authors anticipate our proposed metric and method can better communicate the uncertainty, enhancing the trustworthiness, fairness, and applicability (in Section 6). ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 43}, {"type": "text", "text": "", "page_idx": 44}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 44}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: Appendix E.1 has properly cited all the datasets used in our experiments.   \nAppendix E.2 has properly cited all the baselines and codes. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 44}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 45}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: The authors provide the well-documented code in the GitHub repository. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 45}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: This work does not involve crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 45}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Justification: This work does not involve crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 45}]