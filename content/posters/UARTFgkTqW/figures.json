[{"figure_path": "UARTFgkTqW/figures/figures_2_1.jpg", "caption": "Figure 1: Motivation behind MagR: we can effectively reduce the magnitude of weights at the preprocessing stage. Each point denotes the maximum magnitude before (x-coordinate) and after (y-coordinate) applying MagR within a sampled channel (or column) of the weight matrix from three random layers of LLaMa2-7B [38]. These column-wise maximum magnitudes are typically more than halved through MagR.", "description": "This figure shows the effectiveness of MagR in reducing the maximum magnitude of weights.  It presents three scatter plots, each representing a different layer from the LLaMa2-7B model.  The x-axis shows the maximum magnitude of a weight channel before applying MagR, while the y-axis shows the magnitude after applying MagR. The plots demonstrate that MagR significantly reduces the maximum magnitude in most weight channels, typically halving it. This reduction in magnitude is crucial because it makes the weights easier to quantize, leading to improved post-training quantization performance.", "section": "Motivation behind MagR"}, {"figure_path": "UARTFgkTqW/figures/figures_15_1.jpg", "caption": "Figure 1: Motivation behind MagR: we can effectively reduce the magnitude of weights at the preprocessing stage. Each point denotes the maximum magnitude before (x-coordinate) and after (y-coordinate) applying MagR within a sampled channel (or column) of the weight matrix from three random layers of LLaMa2-7B [38]. These column-wise maximum magnitudes are typically more than halved through MagR.", "description": "This figure demonstrates the effectiveness of the MagR preprocessing technique in reducing the maximum magnitude of weights.  It shows scatter plots for three different layers of a LLaMa2-7B model, where each point represents the maximum magnitude of a weight channel before and after applying MagR.  The plots clearly show that MagR significantly reduces the maximum magnitude of weights, typically halving it, which is crucial for improving post-training quantization.", "section": "4 The Proposed Method"}]