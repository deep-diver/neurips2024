[{"figure_path": "faj2EBhdHC/figures/figures_0_1.jpg", "caption": "Figure 1: Evolution of node embeddings for the Cora dataset. The colors indicate the membership of one of the seven target classes.", "description": "This figure visualizes the evolution of node embeddings during the training process of a graph neural network (GNN) on the Cora dataset.  It compares the performance of a baseline GNN model to one using the proposed Cluster-Normalize-Activate (CNA) modules. The top row shows the baseline model's node embeddings at epochs 1, 50, and 100. The bottom row shows the same for the model with CNA modules.  Each point represents a node, and the color indicates its class label.  The visualization helps to demonstrate how CNA improves the separation of node embeddings belonging to different classes, thus mitigating the problem of oversmoothing.", "section": "1 Introduction"}, {"figure_path": "faj2EBhdHC/figures/figures_1_1.jpg", "caption": "Figure 2: CNA replaces the activation function in each iteration of any GNN architecture. When employing classical activations like ReLU to all nodes undifferentiatedly, we observe oversmoothing. With CNA, we cluster the node features and then normalize and project them with a separate learned activation function each, effectively increasing their expressiveness even in deeper networks.", "description": "This figure compares the standard activation function (ReLU) with the proposed Cluster-Normalize-Activate (CNA) module.  The top row shows a standard GNN, where after each aggregation and update step, the ReLU function is applied to all nodes uniformly.  This leads to oversmoothing in deeper networks, where node features converge to a single point.  The bottom row illustrates the CNA module. After aggregation and update, nodes are clustered into groups (shown by different colors).  Then, each cluster has its features normalized separately.  Finally, a distinct learned activation function is applied to each cluster.  This process helps to maintain the distinction between node features and prevents oversmoothing, even with deeper networks.", "section": "3 Cluster-Normalize-Activate Modules"}, {"figure_path": "faj2EBhdHC/figures/figures_3_1.jpg", "caption": "Figure 3: The components of CNA modules: They cluster node features without changing the adjacency matrix, normalize them separately, and finally activate with distinct learned functions.", "description": "This figure illustrates the three steps of the Cluster-Normalize-Activate (CNA) module.  First, the node features are clustered into groups.  Then, each cluster's features are normalized independently. Finally, a separate activation function is applied to each cluster.  The figure visually shows the process using different colored nodes representing different clusters and demonstrates how the CNA module transforms the node features layer by layer.", "section": "3 Cluster-Normalize-Activate Modules"}, {"figure_path": "faj2EBhdHC/figures/figures_6_1.jpg", "caption": "Figure 4: CNA limits oversmoothing and improves the performance of deep GNNs.", "description": "The figure displays the accuracy of various GNN architectures (GAT, GCN, GraphSAGE, and TransformerConv) with and without the CNA module on the Cora and CiteSeer datasets.  It shows how the accuracy of standard GNNs decreases significantly with increasing depth due to oversmoothing. In contrast, GNNs with CNA maintain high accuracy even at greater depths, demonstrating CNA's effectiveness in mitigating oversmoothing.", "section": "4 Experiments"}, {"figure_path": "faj2EBhdHC/figures/figures_9_1.jpg", "caption": "Figure 4: CNA limits oversmoothing and improves the performance of deep GNNs.", "description": "The figure shows the accuracy of different GNN architectures (GAT, GCN, GraphSAGE) with and without CNA modules on Cora and CiteSeer datasets as the number of layers increases. It demonstrates that CNA helps limit oversmoothing and maintain high accuracy even with deeper networks, outperforming other methods.", "section": "4 Experiments"}, {"figure_path": "faj2EBhdHC/figures/figures_9_2.jpg", "caption": "Figure 6: Hyperparameter sensitivity analysis.", "description": "This heatmap shows the sensitivity analysis of the hyperparameters: the number of hidden features and the number of clusters per layer on the Cora dataset using GCN. The color in each cell represents the accuracy achieved with the corresponding hyperparameter setting.  It illustrates that the model is robust to the choice of hyperparameters and performs best with moderate numbers of features and clusters.", "section": "4 Experiments"}]