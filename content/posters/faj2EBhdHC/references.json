{"references": [{"fullname_first_author": "Thomas N. Kipf", "paper_title": "Semi-Supervised Classification with Graph Convolutional Networks", "publication_date": "2016", "reason": "This paper introduced Graph Convolutional Networks (GCNs), a foundational model for many subsequent GNNs, and is frequently cited as a seminal work in the field."}, {"fullname_first_author": "Petar Veli\u010dkovi\u0107", "paper_title": "Graph Attention Networks", "publication_date": "2018", "reason": "This paper introduced Graph Attention Networks (GATs), which improved upon GCNs by using attention mechanisms to weight the importance of different neighbors, addressing limitations of GCNs and becoming another highly influential GNN model."}, {"fullname_first_author": "Will Hamilton", "paper_title": "Inductive Representation Learning on Large Graphs", "publication_date": "2017", "reason": "This paper introduced GraphSAGE, a popular inductive learning framework for GNNs, enabling the generalization of learned node representations to unseen nodes in large graphs, a significant improvement over transductive methods."}, {"fullname_first_author": "Justin Gilmer", "paper_title": "Neural message passing for Quantum chemistry", "publication_date": "2017", "reason": "This paper provided a unified framework (Message Passing Neural Networks, MPNNs) encompassing many existing GNNs, formalizing the message-passing paradigm and contributing to the theoretical understanding of GNNs."}, {"fullname_first_author": "Jie Zhou", "paper_title": "Graph neural networks: A review of methods and applications", "publication_date": "2020", "reason": "This review paper provides a comprehensive overview of graph neural network methods and applications, summarizing the state-of-the-art and identifying key challenges and future directions in the field."}]}