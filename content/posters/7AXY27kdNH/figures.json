[{"figure_path": "7AXY27kdNH/figures/figures_0_1.jpg", "caption": "Figure 1: Causal Amortized Structure Learning (CAASL) is an active intervention design method that directly proposes the next intervention to perform by just a forward-pass of the transformer based policy.", "description": "This figure illustrates the CAASL method, showing how the policy interacts with the world and history to make decisions. The world represents the environment under study. History comprises the past interventional and observational data, encoding information on previous experiments. The policy (a transformer-based history encoder) processes this data to suggest the next intervention. The experiments represent actions in the environment, such as gene knockouts or knockdowns.", "section": "1 Introduction"}, {"figure_path": "7AXY27kdNH/figures/figures_4_1.jpg", "caption": "Figure 2: Schematic diagram illustrating the proposed CAASL policy along with the AVICI model [38] for computing the reward for interventions designed.", "description": "This figure shows a schematic diagram of the Causal Amortized Active Structure Learning (CAASL) policy. The CAASL policy takes the history of interventions and observations (ht\u22121) as input and uses a transformer network to generate the next intervention (It).  The chosen intervention is then applied to a causal intervention simulator, which produces new observational data (yt). This new data, along with the previous history, is concatenated to form a new history (ht). This updated history is fed into a pretrained AVICI model, which estimates the posterior distribution q(\u00c2|ht) over causal graphs. Finally, the reward is computed based on how well this posterior matches the true causal graph, providing feedback for training the CAASL policy via reinforcement learning.", "section": "3 Amortized Intervention Design"}, {"figure_path": "7AXY27kdNH/figures/figures_6_1.jpg", "caption": "Figure 3: Visualization of the rollout of the trained CAASL policy on a randomly sampled environment with n0 = 50 initial observational samples. Colored circles indicate nodes with a do intervention. The policy selects interventions that mostly correspond to the variables with a child in the ground truth graph. At t = 2, the policy selects the only child y1, which breaks all direct causal effects. This gives lesser information about the overall causal model. After this, y1 is never chosen. Initially, the policy is exploratory wrt targets and exploitative wrt values. This trend is reversed as the episode progresses. The policy is trained on environments with d = 2, therefore it has not seen any graphs with d = 3 before.", "description": "This figure visualizes a rollout of the trained CAASL policy on a random environment. The policy selects interventions targeting variables with children in the ground truth graph, initially exhibiting exploratory target selection and exploitative value selection, a trend which reverses as the episode progresses. The training environments had dimension d=2, hence the policy's interaction with a d=3 environment is a zero-shot generalization task.", "section": "Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_7_1.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "This figure presents the performance comparison of different intervention strategies, including CAASL, Random, Observational, DiffCBED, and SS Finite, in terms of returns, SHD, AUPRC, and Edge F1 over 10 intervention iterations.  The results show that CAASL consistently outperforms the baselines across all metrics.  The shaded area in each plot represents the 95% confidence interval, indicating the variability of the results.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_7_2.jpg", "caption": "Figure 5: Zero-shot OOD returns of CAASL on 100 random environments with distribution shift coming from (a) graphs, (b) graphs and mechanisms, (c) graphs, mechanisms and noise, (d) noise changes from homoskedastic to heteroskedastic, and finally (e) intervention changes from do to a shift intervention. CAASL outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "This figure shows the zero-shot out-of-distribution (OOD) generalization performance of the Causal Amortized Active Structure Learning (CAASL) method across five different OOD scenarios.  Each subfigure represents a different type of distribution shift from the training data: (a) changes in the graph structure (prior over graphs), (b) changes in both graph structure and mechanisms (prior over parameters), (c) changes in graph structure, mechanisms, and noise distribution, (d) switching from homoskedastic noise to heteroskedastic noise, and (e) changing the intervention type from a perfect intervention to a shift intervention.  The CAASL method consistently outperforms other strategies (Random, Observational, DiffCBED, SS Finite) in all scenarios, demonstrating its robustness to distribution shifts. The shaded area in each plot represents the 95% confidence interval.", "section": "Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_8_1.jpg", "caption": "Figure 6: Zero-Shot OOD generalization results when dimensionality d changes for synthetic environment. For training, d = 10. Left: Zero-Shot test returns with d = 20. Right: Relative mean zero-shot returns of CAASL wrt random for different d. Results on 100 random environments. Shaded area represents 95% CI.", "description": "This figure demonstrates the zero-shot out-of-distribution generalization performance of CAASL when the dimensionality of the data increases during testing. The left panel displays the test returns for a dimensionality of d=20, showing the significant improvement of CAASL over baselines. The right panel shows the relative performance of CAASL with respect to a random baseline for various dimensionalities (d=15, 20, 25, 27, 30), highlighting the robustness of CAASL even when the dimensionality increases during the testing phase.", "section": "5.1 Synthetic Design Environment"}, {"figure_path": "7AXY27kdNH/figures/figures_9_1.jpg", "caption": "Figure 7: Results on SERGIO environment with 100 random environments. (a) corresponds to in-distribution performance, (b)-(e) correspond to zero-shot OOD performance with distribution shift coming from either (b) graphs, (c) technical noise, (d) intervention changing to a gene-knockdown (e) Noisy interventions, which include off-target effects. Shaded area represents 95% CI.", "description": "This figure displays the performance of CAASL and baselines in the SERGIO environment under various conditions.  Panel (a) shows in-distribution results, where the model is tested on data similar to that used for training.  Panels (b) through (e) demonstrate the zero-shot out-of-distribution generalization capabilities of the method, showing its performance when the underlying generative model changes (different graphs, noise characteristics, intervention types, noisy interventions).  Each panel shows the cumulative reward obtained over 10 intervention steps, highlighting the resilience of CAASL in various challenging scenarios.  Shaded areas represent the 95% confidence interval.", "section": "5.2 Single-Cell Gene Regulatory Network Environment"}, {"figure_path": "7AXY27kdNH/figures/figures_18_1.jpg", "caption": "Figure 8: Results of zero-shot OOD generalization when dimensionality of the data increases in the synthetic environment. Results are performed on 100 random test environments. Shaded area represents 95% CI.", "description": "This figure shows the results of a zero-shot out-of-distribution (OOD) generalization experiment, where the dimensionality of the data increases.  The experiment was performed on a synthetic dataset, and the results show the returns (cumulative rewards) over 10 intervention iterations. Four different dimensionalities (d = 15, 20, 25, 30) are tested, and the performance of CAASL is compared against two baseline methods: random interventions and purely observational data. The shaded areas represent the 95% confidence intervals, indicating the uncertainty in the results.  CAASL consistently outperforms the baselines, demonstrating its ability to generalize to higher-dimensional data unseen during training.", "section": "5.1 Synthetic Design Environment"}, {"figure_path": "7AXY27kdNH/figures/figures_18_2.jpg", "caption": "Figure 6: Zero-Shot OOD generalization results when dimensionality d changes for synthetic environment. For training, d = 10. Left: Zero-Shot test returns with d = 20. Right: Relative mean zero-shot returns of CAASL wrt random for different d. Results on 100 random environments. Shaded area represents 95% CI.", "description": "This figure displays the results of a zero-shot out-of-distribution (OOD) generalization experiment where the dimensionality (d) of the synthetic design environment is varied.  The training data used d=10, while the test data used d=15, 20, 25, 27, and 30. The left panel shows the zero-shot test returns for d=20, illustrating the performance of CAASL, random, and observational strategies. The right panel shows the relative mean returns of CAASL compared to the random strategy for different values of d, highlighting how the relative performance changes as dimensionality increases. Shaded areas indicate 95% confidence intervals.", "section": "5.1 Synthetic Design Environment"}, {"figure_path": "7AXY27kdNH/figures/figures_19_1.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "This figure presents the performance comparison of different intervention strategies, including CAASL, Random, and Observational methods, over 100 random test environments.  The results are displayed for 10 intervention iterations, showing the return values obtained.  CAASL demonstrates significantly better performance than other strategies, as indicated by the higher return values. The shaded areas represent the 95% confidence intervals, illustrating the statistical significance of the results.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_19_2.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "The figure shows the performance of different intervention strategies on 100 random test environments over 10 intervention iterations. The y-axis represents the cumulative rewards, SHD, AUPRC, and Edge F1 score. CAASL consistently outperforms other methods (Random, Observational, DiffCBED, and SS Finite) across all metrics, demonstrating its effectiveness in sample-efficient causal structure learning. The shaded areas represent the 95% confidence intervals.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_19_3.jpg", "caption": "Figure 12: Results of zero-shot OOD graph, mechanisms and noise setting with various intervention strategies on 100 random synthetic test environments. Shaded area represents 95% CI.", "description": "The figure displays the performance of various intervention strategies in a zero-shot out-of-distribution (OOD) setting where the data generation process deviates from the training data in terms of graph structure, mechanisms, and noise. The plot includes the returns (cumulative reward), Structural Hamming Distance (SHD), Area Under the Precision-Recall Curve (AUPRC), and Edge F1-score.  CAASL significantly outperforms the baseline strategies (Random and Observational) across all metrics. The shaded regions indicate the 95% confidence intervals, highlighting the statistical significance of the results.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_20_1.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "This figure presents the performance comparison of different intervention strategies, including CAASL, Random, and Observational, across 10 returns, SHD, AUPRC, and Edge F1 metrics. The results are obtained from 100 random test environments.  CAASL consistently outperforms the other methods, showcasing its effectiveness in active intervention design for causal structure learning. The shaded areas indicate the 95% confidence intervals.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_20_2.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "This figure presents the comparison of different intervention strategies on 100 random test environments.  The y-axis shows the performance metrics (Returns, SHD, AUPRC, Edge F1), and the x-axis represents intervention iterations.  The lines represent CAASL, Random, and Observational intervention strategies. CAASL consistently outperforms the others, indicating the effectiveness of the proposed method in learning causal structure from data acquired through its adaptive intervention design.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_20_3.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "This figure shows the performance of different intervention strategies over 10 iterations on 100 random test environments.  The x-axis represents the intervention iteration, and the y-axis shows the performance metric (returns, SHD, AUPRC, Edge F1).  CAASL consistently outperforms both Random and Observational strategies across all metrics, indicating its superior ability to design informative interventions for causal structure learning. The shaded areas represent 95% confidence intervals, highlighting the statistical significance of the results.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_20_4.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "The figure shows the performance of different intervention strategies, including CAASL (Causal Amortized Active Structure Learning), Random, and Observational, across 10 intervention iterations on 100 random test environments.  CAASL consistently outperforms the other methods, demonstrating its effectiveness in efficiently acquiring data for causal structure learning. The shaded areas indicate the 95% confidence intervals.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_21_1.jpg", "caption": "Figure 7: Results on SERGIO environment with 100 random environments. (a) corresponds to in-distribution performance, (b)-(e) correspond to zero-shot OOD performance with distribution shift coming from either (b) graphs, (c) technical noise, (d) intervention changing to a gene-knockdown (e) Noisy interventions, which include off-target effects. Shaded area represents 95% CI.", "description": "This figure shows the results of the CAASL policy and baselines (Wild-type and Random) on the SERGIO environment for in-distribution and various out-of-distribution (OOD) settings. The in-distribution setting evaluates the amortization capability of the policy on the training distribution. The OOD settings evaluate the generalization ability of the policy to new environments with distribution shifts in terms of graph structure, technical noise (scRNA-seq platform), intervention type, and noisy interventions (off-target effects).  The shaded area represents the 95% confidence interval for each metric across 100 random environments.", "section": "5.2 Single-Cell Gene Regulatory Network Environment"}, {"figure_path": "7AXY27kdNH/figures/figures_21_2.jpg", "caption": "Figure 4: Amortization results of various intervention strategies on 100 random test environments. CAASL significantly outperforms other intervention strategies. Shaded area represents 95% CI.", "description": "This figure displays the performance of CAASL and other intervention strategies (Random and Observational) over 10 interventions on 100 different synthetic test environments.  The y-axis shows the cumulative reward,  and the x-axis represents the intervention iteration.  CAASL consistently demonstrates superior performance compared to Random and Observational approaches, as indicated by the significantly higher cumulative rewards. The shaded regions represent the 95% confidence intervals for each strategy.", "section": "5 Experiments"}, {"figure_path": "7AXY27kdNH/figures/figures_21_3.jpg", "caption": "Figure 19: Results of zero-shot OOD noisy gene knockouts with various intervention strategies on 100 random SERGIO test environments. Shaded area represents 95% CI.", "description": "This figure shows the results of a zero-shot out-of-distribution (OOD) generalization experiment. In the experiment, noisy interventions (10% probability of off-target effects or failed interventions) were introduced into the SERGIO gene regulatory network simulator.  The figure displays four metrics across 10 intervention iterations: Returns (cumulative reward), SHD (Structural Hamming Distance, lower is better), AUPRC (Area Under the Precision-Recall Curve, higher is better), and Edge F1 (F1 score for edge accuracy, higher is better). The results are compared across three intervention strategies: CAASL (the proposed method), Wild-Type (observational data), and Random (random interventions). Shaded areas represent 95% confidence intervals.  The results demonstrate CAASL's robustness in handling noisy interventions, outperforming both the Wild-Type and Random strategies.", "section": "5.2 Single-Cell Gene Regulatory Network Environment"}]