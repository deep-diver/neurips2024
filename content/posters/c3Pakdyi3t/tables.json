[{"figure_path": "c3Pakdyi3t/tables/tables_4_1.jpg", "caption": "Table 1: BigBench-Hard (BBH) collection averaged zero-shot results. The accuracies listed are averages of all 27 tasks from this collection. Evaluated using LM-Eval Harness [18].", "description": "This table presents the results of zero-shot evaluations on the BigBench-Hard (BBH) dataset.  It shows the average accuracy across 27 tasks for different model combinations.  The \"Source Model\" underwent LoRA finetuning, then its LoRA parameters were transferred to the \"Target Model\" using Trans-LoRA. The results compare the accuracy of the source model with its LoRA, the target model without LoRA, and the target model after Trans-LoRA transfer, demonstrating the effectiveness of the proposed method.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_4_2.jpg", "caption": "Table 1: BigBench-Hard (BBH) collection averaged zero-shot results. The accuracies listed are averages of all 27 tasks from this collection. Evaluated using LM-Eval Harness [18].", "description": "This table presents the zero-shot performance of different models on the BigBench-Hard (BBH) benchmark.  It compares the accuracy of models fine-tuned with LoRA and the baseline accuracy without LoRA.  The results are averaged across all 27 tasks in the BBH collection and evaluated using the LM-Eval Harness. The table shows the source model, the target model, the discriminator model used, the LoRA accuracy, the no-LoRA accuracy, and the accuracy achieved by the proposed Trans-LoRA method.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_5_1.jpg", "caption": "Table 2: Massive Multitask Language Understanding (MMLU) collection averaged zero-shot results. Accuracies are averages of all 57 tasks from this collection. Evaluated using LM-Eval Harness [18].", "description": "This table presents the results of the Massive Multitask Language Understanding (MMLU) benchmark.  It shows the accuracy of different models (Llama and Gemma) with and without the Trans-LoRA method, broken down by source and target model. The zero-shot performance is reported, meaning no fine-tuning was done on the target tasks. The `Ours` column displays the accuracy achieved after applying the Trans-LoRA technique for transfering the LoRA weights across different base models.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_6_1.jpg", "caption": "Table 3: Mostly Basic Python Problems (MBPP) zero-shot results. Presented in format of (standard MBPP evaluation / more strict MBPP+ evaluation). Evaluated using Evalplus [40].", "description": "This table presents the zero-shot results of the MBPP dataset using different model combinations.  The results are shown in the format (standard MBPP accuracy / more strict MBPP+ accuracy). The source model, target model, and discriminator model used in each experiment are specified.  The table showcases the performance of the transferred LoRA model compared to the source model's LoRA and the target model without LoRA.", "section": "4.2 Main Results"}, {"figure_path": "c3Pakdyi3t/tables/tables_6_2.jpg", "caption": "Table 4: Grade School Math 8K (GSM8K) no chain-of-thought prompting results.", "description": "This table presents the zero-shot results of applying Trans-LoRA to the GSM8K dataset.  It shows the accuracy achieved by the source LoRA model, the target model without a LoRA, and the target model with a LoRA transferred using the Trans-LoRA method.  The table explores several source and target model combinations, along with using different discriminators during the transfer process.  The results demonstrate the effectiveness of the proposed Trans-LoRA method in improving the performance of the target model.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_6_3.jpg", "caption": "Table 5: Distillation curriculum ablations on 27 tasks of the BigBench-Hard (BBH) collection.", "description": "This table presents an ablation study comparing different approaches to training the target LoRA model in Trans-LoRA.  It shows the zero-shot accuracy achieved on 27 BigBench-Hard tasks using various training data strategies:  using random Wikipedia text, unfiltered synthetic data generated by the target model, only the 5 seed samples used for initialization, and the proposed Trans-LoRA method with filtered synthetic data.  The results demonstrate the effectiveness of Trans-LoRA's synthetic data filtering approach in improving the accuracy of the transferred LoRA model.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_6_4.jpg", "caption": "Table 6: Trans-LoRA for transferring between different base models and different PEFT methods on BigBench-Hard (BBH). Accuracies are zero-shot averaged results of all tasks from this collection.", "description": "This table presents the results of experiments evaluating the effectiveness of Trans-LoRA in transferring between different base models (Gemma and Llama) and different parameter-efficient fine-tuning (PEFT) methods (LoRA, DORA, and Prompt Tuning) on the BigBench-Hard (BBH) dataset.  The \"Source Model PEFT Acc.\" column shows the accuracy of the source model with the original PEFT method.  \"Target Model no PEFT Acc.\" shows the accuracy of the target model without any fine-tuning.  The \"Ours\" column displays the accuracy achieved by using Trans-LoRA to transfer the PEFT parameters to the target model.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_7_1.jpg", "caption": "Table 7: Continuous transfer on several models on BigBench-Hard (BBH). We transfer from source model to intermediate model, then from intermediate model to target model, all using the same discriminator model. Accuracies are zero-shot averaged results of all tasks from this collection.", "description": "This table shows the results of a continuous transfer experiment using Trans-LoRA.  The experiment involved transferring a LoRA model from a source model to a target model via an intermediate model.  The same discriminator model was used for all transfers.  The table presents the zero-shot averaged accuracy across all tasks in the BigBench-Hard (BBH) collection for the source LoRA, the intermediate model (without LoRA), the transferred LoRA to the intermediate model, the target model (without LoRA), and the final transferred LoRA to the target model.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_7_2.jpg", "caption": "Table 8: Experiments on T5 models and 3 additional tasks, where our results are reported on Trans-LoRA transfer from T5-L finetuned LORA to T5-XL base model.", "description": "This table presents the results of experiments conducted on T5 models for three additional tasks.  It compares the zero-shot accuracy of a T5-L model fine-tuned with LoRA, a T5-XL base model (without LoRA), and the results obtained using the Trans-LoRA method for transferring the LoRA from the smaller T5-L model to the larger T5-XL model.  The tasks evaluated are CoQA, Newsroom, and Squadv2,  demonstrating the effectiveness of Trans-LoRA in transferring LoRA across different model sizes.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_8_1.jpg", "caption": "Table 9: Maximum mean discrepancy(MMD) comparing filtered and unfiltered synthetic data with original dataset using first 4 tasks of BBH. Smaller values indicate smaller distance to original dataset.", "description": "This table presents the Maximum Mean Discrepancy (MMD) values, a measure of the distance between probability distributions, for filtered and unfiltered synthetic data compared to the original dataset.  The MMD is calculated for the first four tasks from the BigBench-Hard (BBH) dataset. Lower MMD values suggest that the filtered synthetic data is closer to the original data's distribution, indicating the effectiveness of the filtering process.", "section": "5 Analysis"}, {"figure_path": "c3Pakdyi3t/tables/tables_9_1.jpg", "caption": "Table 1: BigBench-Hard (BBH) collection averaged zero-shot results. The accuracies listed are averages of all 27 tasks from this collection. Evaluated using LM-Eval Harness [18].", "description": "This table presents the average zero-shot accuracy across 27 tasks from the BigBench-Hard (BBH) collection.  It compares the performance of different models (Llama-2 and Gemma) when fine-tuned with LoRA and when using LoRA transfer, showcasing the effectiveness of the proposed Trans-LoRA method.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_13_1.jpg", "caption": "Table 1: BigBench-Hard (BBH) collection averaged zero-shot results. The accuracies listed are averages of all 27 tasks from this collection. Evaluated using LM-Eval Harness [18].", "description": "This table presents the zero-shot performance of different models on the BigBench-Hard (BBH) dataset.  It compares the accuracy of various models (Llama-2 and Gemma) with and without LoRA fine-tuning, and also shows the results obtained using the proposed Trans-LoRA method for transferring LoRA parameters across different base models. The \"Source Model\" column indicates the original model where LoRA was trained, the \"Target Model\" is where it was transferred, and the \"Discriminator Model\" specifies the model used for filtering synthetic data during transfer.  The \"Ours\" column displays the performance of the target model after LoRA transfer using the Trans-LoRA technique.  The table evaluates the effectiveness of the Trans-LoRA method by comparing its accuracy against the accuracy of the same model without LoRA (\"no LORA Acc\") and the source model's accuracy (\"Source LORA Acc\").", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_14_1.jpg", "caption": "Table 1: BigBench-Hard (BBH) collection averaged zero-shot results. The accuracies listed are averages of all 27 tasks from this collection. Evaluated using LM-Eval Harness [18].", "description": "This table presents the results of zero-shot experiments on the BigBench-Hard (BBH) dataset.  It shows the accuracy of different language models (LLMs) and their corresponding LoRA (Low-Rank Adaptation) models across various transfer scenarios.  The source model is fine-tuned using LoRA on a given task, and then transferred to a target model to assess whether the performance is maintained or improved.  The table provides metrics for the original LoRA accuracy, the target model's accuracy without LoRA, and the accuracy after the LoRA transfer using the proposed Trans-LoRA method. The results highlight whether the transfer is lossless, primarily showing that Trans-LoRA improves the performance of the models.", "section": "4 Experiments"}, {"figure_path": "c3Pakdyi3t/tables/tables_14_2.jpg", "caption": "Table 1: BigBench-Hard (BBH) collection averaged zero-shot results. The accuracies listed are averages of all 27 tasks from this collection. Evaluated using LM-Eval Harness [18].", "description": "This table presents the results of zero-shot experiments on the BigBench-Hard (BBH) dataset.  It compares the accuracy of different models (Llama and Gemma) with and without using LoRA, and also shows the results of transferring LoRA modules using the proposed Trans-LoRA method.  The results are averaged across all 27 tasks in the BBH collection, providing a comprehensive comparison of the models' performance.", "section": "4 Experiments"}]