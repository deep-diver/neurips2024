[{"type": "text", "text": "Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Muhammad Qasim Elahi ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mahsa Ghasemi ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Electrical and Computer Engineering Purdue University elahi0@purdue.edu ", "page_idx": 0}, {"type": "text", "text": "Electrical and Computer Engineering Purdue University mahsa@purdue.edu ", "page_idx": 0}, {"type": "text", "text": "Murat Kocaoglu Electrical and Computer Engineering Purdue University mkocaoglu@purdue.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Causal knowledge about the relationships among decision variables and a reward variable in a bandit setting can accelerate the learning of an optimal decision. Current works often assume the causal graph is known, which may not always be available a priori. Motivated by this challenge, we focus on the causal bandit problem in scenarios where the underlying causal graph is unknown and may include latent confounders. While intervention on the parents of the reward node is optimal in the absence of latent confounders, this is not necessarily the case in general. Instead, one must consider a set of possibly optimal arms/interventions, each being a special subset of the ancestors of the reward node, making causal discovery beyond the parents of the reward node essential. For regret minimization, we identify that discovering the full causal structure is unnecessary; however, no existing work provides the necessary and sufficient components of the causal graph. We formally characterize the set of necessary and sufficient latent confounders one needs to detect or learn to ensure that all possibly optimal arms are identified correctly. We also propose a randomized algorithm for learning the causal graph with a limited number of samples, providing a sample complexity guarantee for any desired confidence level. In the causal bandit setup, we propose a two-stage approach. In the first stage, we learn the induced subgraph on ancestors of the reward, along with a necessary and sufficient subset of latent confounders, to construct the set of possibly optimal arms. We show that for our proposed algorithm, the number of intervention samples required to learn the set of possibly optimal arms scales polynomially with respect to the number of nodes. The second phase involves the application of a standard bandit algorithm, such as the UCB algorithm. We also establish a regret bound for our two-phase approach, which is sublinear in the number of rounds. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Causal bandits have been a topic of interest since their inception and have been studied in various contexts [1]. The authors assumed precise knowledge of the causal graph and the impact of interventions or actions on the parents of the reward node. Subsequently, there has been a flurry of research on causal bandits [2, 3, 4]. The primary limitation of the majority of existing works on causal bandits is their assumption of full knowledge of the causal graph, which is often impractical for many real-world applications [1, 5, 6]. Recently, efforts have been made to overcome this limitation. In [7], the authors propose a sample efficient algorithm for cases where the causal graph can be represented as a directed tree or a causal forest and later extend the algorithm to encompass a broader class of general chordal graphs. However, the proposed algorithm is only applicable to scenarios where the Markov equivalence class (MEC) of the causal graph is known and does not have confounders. In [8], the authors propose a causal bandit algorithm that does not require any prior knowledge of the causal structure and leverages separating sets. However, their theoretical result holds only when a true separating set is known. The paper by Konobeev et al. [9] also deals with causal bandits with an unknown graph and proposes a two-phase approach. The first phase uses a randomized parent search algorithm to learn the parents of the reward node, and the second phase employs UCB to identify the optimal intervention over the parents of the reward node. However, similar to [7], they assume causal sufficiency, i.e., no latent confounders are present. In another related paper, [10], the authors initially emphasize the challenge of dealing with exponentially many arms when addressing causal bandits with an unknown graph. To tackle this issue, the authors assume that the reward is a noisy additive function of its parents. This assumption enables them to reframe the problem as an additive combinatorial linear bandit problem. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "We also focus on the causal bandit setup where the causal graph is unknown, but we allow the presence of latent confounders and make no parametric assumptions. The optimal intervention in this case is not limited to parents of the reward node; instead, we have a candidate set of optimal interventions, called possibly optimal minimum intervention sets (POMISs), each being a special subset of the ancestors of the reward node [5]. Thus, learning only the parents of the reward, similar to [9], is insufficient. This implies that causal discovery beyond parents of the reward is imperative. However, for regret minimization, discovering the full causal structure is not necessary. Instead, we characterize the set of necessary and sufficient latent confounders one needs to detect/learn to ensure all the possibly optimal arms are learned correctly. ", "page_idx": 1}, {"type": "text", "text": "Causal discovery is a well-studied problem and can be applied to our setup [11, 12, 13]. However, the majority of the existing causal discovery algorithms rely on the availability of an infinite amount of interventional data [14, 15, 16]. Some prior work shows that discovery is possible with limited interventional data, with theoretical guarantees when the underlying causal graph is a tree and contains no latent confounders [17]. Also, the paper [18] proposes a sample-efficient active learning algorithm for causal graphs without latent confounders, given that the MEC for the underlying causal graph is known. Bayesian causal discovery can also be a valuable tool when interventional data is limited. However, it faces challenges when tasked with computing posterior probabilities across the combinatorial space of directed acyclic graphs (DAGs) without specific parametric assumptions [19, 20, 21]. All in all, the sample-efficient learning of causal graphs with latent confounders, without any parametric or graphical assumptions, with theoretical guarantees, remains an open problem. ", "page_idx": 1}, {"type": "text", "text": "We propose a randomized algorithm for sample-efficient learning of causal graphs with confounders. We analyze the algorithm and bound the maximum number of interventional samples required to learn the causal graph with all the confounders with a given confidence level. For the causal bandit setup, we propose a two-stage approach where the first step learns a subgraph of the underlying causal graph to construct a set of POMISs, and the second phase learns the optimal arm among the POMISs. We show that the requirement of learning only a subgraph leads to significant savings in terms of interventional samples and consequently, regret. The main contributions of our work are as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We characterize the necessary and sufficient set of latent confounders in the induced subgraph on ancestors of the reward node that we need to learn/detect in order to identify all the POMISs for a causal bandit setup when the underlying causal graph is unknown. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a randomized algorithm for sample-efficient learning of causal graphs with confounders, providing theoretical guarantee on the number of interventional samples required to learn the graph with a given confidence level. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a two-phase algorithm for causal bandits with unknown causal graphs containing confounders. The first phase involves learning the induced subgraph on reward\u2019s ancestors along with a subset of latent confounders to identify all the POMISs. The next phase involves a standard bandit algorithm, e.g., upper confidence bound (UCB) algorithm. Our theoretical analysis establishes an upper bound on the cumulative regret of the overall algorithm. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries and Problem Setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We start with an overview of the causal bandit problem and other relevant background needed on causal models. Structural causal model (SCM) is a tuple $\\mathcal{M}\\,=\\,\\langle{\\bf V},{\\bf U},{\\bf F},P({\\bf U})\\rangle$ where ${\\textbf{V}}=$ $\\{V_{i}\\}_{i=1}^{n}\\cup\\{Y\\}$ is the set of observed variables, $\\mathbf{U}$ is the set of independent exogenous variables, $\\mathbf{F}$ is the set of deterministic structural equations and $P({\\bf U})$ is the distribution for exogenous variables [22]. The equations $f_{i}$ map the parents $(\\mathsf{P a}(V_{i}))$ and a subset of exogenous variables $\\mathbf{U}_{i}\\subseteq\\mathbf{U}$ , to the value of variable $V_{i}$ , i.e., $\\bar{V_{i}}=\\bar{f_{i}}(\\mathsf{P a}(V_{i}),\\bar{\\mathbf{U}_{i}})$ . We consider the causal bandit setup where all the observed variables $V_{i}\\in\\mathbf{V}$ are discrete with the domain $\\Omega(V_{i})=[K]:=\\{1,2,3,\\bar{~}.\\bar{~},K\\}$ , and the reward $Y$ is binary, i.e., $\\Omega(Y)=\\{0,1\\}$ . We can associate a DAG $\\mathcal{G}=(\\mathbf{V},\\mathbf{E})$ with every SCM, where the vertices $\\mathbf{V}$ correspond to the observed variables and edges $\\mathbf{E}$ consist of directed edges $V_{i}\\to V_{j}$ when $V_{i}\\in{\\sf P a}(V_{j})$ and bi-directed edges between $V_{i}$ and $V_{j}$ $\\left(V_{i}\\leftrightarrow V_{j}\\right)$ ) when they share some common unobserved variable, also called latent confounder. We restrict ourselves to semi-Markovian causal models in which every unobserved variable has no parents and has exactly two children, both of which are observed [10]. An intervention on a set of variables $\\mathbf{W}\\subseteq\\mathbf{V}$ , denoted by $d o(\\mathbf{W})$ , induces a post-interventional DAG $(\\mathcal{G}_{\\overline{{\\mathbf{W}}}})$ with incoming edges to vertices W removed . We can broadly classify interventions into deterministic interventions, where variables are set to a fixed realization denoted by $d o(\\mathbf{W}=\\mathbf{w})$ , and stochastic interventions, where instead of a fixed realization we have $\\mathbf{W}\\sim\\mathbb{P}(.)$ , where $\\mathbb{P}$ is a probability measure over the domain $\\Omega(\\mathbf{W})$ . We denote the sub-model induced under hard intervention by $\\mathcal{M}_{\\sf W=w}$ and the one induced under stochastic intervention by ${\\mathcal{M}}_{\\mathbf{W}}$ . In the context of causal bandits, an arm or action corresponds to hard intervention on a subset of variables other than the reward. The goal of the agent is to identify the intervention that maximizes the expected reward. The performance of an agent is measured in terms of cumulative regret $R_{T}$ . ", "page_idx": 2}, {"type": "equation", "text": "$$\nR_{T}:=T\\operatorname*{max}_{\\mathbf{W}\\subseteq\\mathbf{V}}\\operatorname*{max}_{\\mathbf{w}\\in[K]^{|\\mathbf{w}|}}\\mathbb{E}[Y|d o(\\mathbf{W}=\\mathbf{w})]-\\sum_{t=1}^{T}\\mathbb{E}[Y|d o(\\mathbf{W}_{t}=\\mathbf{w}_{t})],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $d o(\\mathbf{W}_{t}=\\mathbf{w}_{t})$ represents the intervention selected by the agent in round $t$ . We use the notation $\\Delta_{d o(\\mathbf{w})}$ to define the sub-optimality gap of the corresponding arm $\\mathrm{d}\\mathbf{o}(\\mathbf{W}=\\mathbf{w})$ . We denote the descendants, ancestors and children of a vertex $V_{i}$ by ${\\mathsf{D e}}(V_{i})$ , $\\mathsf{A n}(V_{i})$ and ${\\mathsf{C h}}(V_{i})$ respectively. We use the notation $\\mathsf{B i}(V_{i},\\mathcal{G})$ to denote the set of vertices having bidirected edges to $V_{i}$ except the reward node $Y$ . We refer to the induced graph between observed variables as the observable graph. The transitive closure of a graph, denoted by $\\mathcal{G}^{t c}$ , encodes the ancestral relationship in $\\mathcal{G}$ . That is, the directed edge $V_{i}\\to V_{j}$ is included in $\\mathcal{G}^{t c}$ only when $V_{i}\\in\\mathsf{A n}(V_{j})$ . The transitive reduction, denoted by $T r({\\mathcal{G}})\\bar{=}\\left(\\mathbf{V},\\mathbf{E}^{r}\\right)$ , is a graph with the minimum number of edges such that the transitive closure is the same as $\\mathcal{G}$ . The connected component (c-component) of the DAG $\\mathcal{G}$ , containing vertex $V_{i}$ , is denoted by ${\\mathsf{C C}}(V_{i})$ , which is the maximal set of all vertices in $\\mathcal{G}$ that have a path to $V_{i}$ , consisting only of bi-directed edges [23]. For a subset of vertices $\\mathbf{W}\\subseteq\\mathbf{V}$ , we define $\\textstyle\\mathsf{C C}(\\mathbf{W}):=\\bigcup_{W_{i}\\in\\mathbf{W}}\\mathsf{C C}(W_{i})$ In a DAG, a subset of nodes W d-separates two nodes $V_{i}$ and $V_{j}$ when it effe ctively blocks all paths between them, denoted as $V_{i}$ \u22a5\u22a5 $_d\\textit{V}_{j}|\\mathbf{W}$ . Blocking is a graphical criterion associated with $d$ -separation [22]. A probability distribution is said to be faithful to a graph if and only if every conditional independence (CI) statement can be inferred from d-separation statements in the graph. Faithfulness is a commonly used assumption in the existing work on causal discovery [14, 24]. We assume that the following form of the interventional faithfulness assumption holds in our setup. ", "page_idx": 2}, {"type": "text", "text": "Assumption 2.1. Consider a set of nodes $\\mathbf{W}\\subseteq\\mathbf{V}$ and the stochastic intervention $d o(\\mathbf{W},\\mathbf{U})$ on W and any set $\\mathbf{U}\\subseteq\\mathbf{V}\\setminus\\mathbf{W}$ . The conditional independence $(C I)$ statement $(\\mathbf{X}\\perp\\mid\\mathbf{Y}\\mid\\mathbf{Z})_{\\mathcal{M}_{\\mathbf{W},\\mathbf{U}}}$ holds in the induced model if and only if there is a corresponding $d$ -separation statement in post-interventional graph $(\\mathbf{X}\\perp\\perp\\mathbf{Y}\\mid\\mathbf{Z})_{\\mathcal{G}_{\\overline{{\\mathbf{w},\\mathbf{u}}}}}$ , where X, $\\mathbf{Y}$ , and $\\mathbf{Z}$ are disjoint subsets of $\\mathbf{V}\\cdot\\mathbf{W}$ . The $C I$ statements in the induced model are with respect to the post-interventional joint probability distribution. ", "page_idx": 2}, {"type": "text", "text": "3 Possibly Optimal Arms in Causal Bandits with Unknown Causal Graph ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The optimal intervention in a causal bandit setup is not restricted to the parent set of the reward node when the reward node $Y$ is confounded with any node in its ancestors $\\mathsf{A n}(Y)$ [5]. For instance, consider SCM $X_{1}=U_{1}$ and $X_{2}=X_{1}\\oplus U_{2}$ and reward $Y=X_{2}\\oplus U_{2}$ , where $U_{1}\\sim B e r(0.5)$ and $U_{2}\\sim B e r(0.5)$ . Note that $X_{2}$ and reward $Y$ are confounded in this SCM. The optimal intervention in this case is $d o(X_{1}=1)$ since $\\mathbb{E}[Y|d o(X_{1}=1)]=1$ . The intervention on the parent of the reward $(\\mathsf{P a}(Y)=X_{2})$ ) is suboptimal because $\\mathbb{E}[Y|d o(X_{2}^{\\cdot}=0)]=\\mathbb{E}[Y|d o(X_{2}=1)]\\stackrel{\\cdot}{=}0.5.$ . The example ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{c c c}{{}}&{{\\begin{array}{c c}{{\\mathrm{{\\Large~e~\\widehat{~\\varphi}~}^{+}\\,V_{3}}}}\\\\ {{\\mathrm{{\\Large~e~\\widehat{~\\varphi}~}^{+}\\,V_{1}}}}\\\\ {{\\mathrm{{\\Large~V_{1}~}^{+}\\cdots\\star~V_{2}}}}\\\\ {{\\mathrm{{\\Large~e~\\widehat{~\\varphi}~}^{+}\\,V_{1}}}}\\\\ {{\\mathrm{{\\Large~e~\\widehat{~\\varphi}~}^{+}}}}\\end{array}}}&{{\\begin{array}{c}{{\\mathrm{{\\Large~e~\\widehat{~\\varphi}~}^{+}\\,V_{3}}}}\\\\ {{\\mathrm{{\\Large~(\\X_{1}~)~}^{+}\\cdots\\star~V_{2}}}}\\\\ {{\\mathrm{{\\Large~V_{1}~}^{+}\\cdots\\star~V_{2}}}}\\\\ {{\\mathrm{{\\Large~\\widehat{~\\varphi}~}^{+}\\,V_{1}~}}}\\end{array}}}&{{\\begin{array}{c}{{\\mathrm{{\\Large~e~\\widehat{~\\varphi}^{+}\\,V_{3}}}}}\\\\ {{\\mathrm{{\\Large~(X_{1}~)~}^{+}\\cdots\\mathrm{{\\Large~V_{2}~}^{+}}}}}\\\\ {{\\mathrm{{\\Large~V_{1}~}^{+}\\cdots\\mathrm{\\Large~V_{2}~}^{+}}}}\\\\ {{\\mathrm{{\\Large~\\widehat{~\\varphi}~}^{+}\\,V_{1}~}}}\\\\ {{\\mathrm{{\\Large~(X_{1}~)~}^{+}\\cdots\\mathrm{\\Large~V_{2}~}^{+}}}}\\end{array}}}&{{\\begin{array}{c}{{\\mathrm{{\\Large~e~\\widehat{~\\varphi}^{-}\\,V_{3}}}}}\\\\ {{\\mathrm{{\\Large~(X_{1}~)~}^{+}\\cdots\\mathrm{\\Large~V_{3}~}}}}\\\\ {{\\mathrm{{\\Large~V_{1}~}^{+}\\cdots\\mathrm{\\Large~V_{2}~}^{+}}}}\\\\ {{\\mathrm{{\\Large~W_{2}~}^{+}\\cdots\\mathrm{\\Large~V_{3}~}^{+}}}}\\\\ {{\\mathrm{{\\Large~(A)~}^{\\mathcal{G}_{3}~}}}}\\end{array}}}&{{\\begin{array}{c}{{{\\mathrm{\\Large~e~\\widehat{~\\varphi}^{-}\\,V_{3}}}}}\\\\ {{\\mathrm{{\\Large~(X_{1}~)~}^{+}\\cdots \n$$", "text_format": "latex", "page_idx": 3}, {"type": "image", "img_path": "", "img_caption": ["Figure 1: True Causal Graph $\\mathcal{G}$ with four other graphs each with one missing bi-directed edge. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "shows that it is possible to construct SCMs where optimal intervention is on ancestors of the reward node instead of parents when reward node is confounded with one of its ancestors. The authors in [5] propose a graphical criterion to enumerate the set of all possibly optimal arms, which they refer to as POMISs. We revisit some definitions and results from their work. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.1. (Unobserved Confounder $(U C)$ -Territory[5]) Consider a causal graph $\\mathcal{G}(\\mathbf{V},\\mathbf{E})$ with a reward node $Y$ and let $\\mathcal{H}$ be $\\mathcal{G}[\\mathsf{A n}(Y)]$ . A set of variables $T\\subseteq V({\\mathcal{H}})$ containing $Y$ is called an UC-territory on $\\mathcal{G}$ with respect to $Y$ if $\\bar{D e_{\\mathcal{H}}}(\\pmb{T})=\\pmb{T}$ and $\\mathsf{C C}_{\\mathcal{H}}(T)=T$ . ", "page_idx": 3}, {"type": "text", "text": "A UC-territory is minimal if none of its subsets are UC-territories. A minimal UC-territory denoted by $\\operatorname{MUCT}({\\mathcal{G}},{\\dot{Y}})$ , can be constructed by extending a set of variables, starting from the reward $\\{Y\\}$ , alternatively updating the set with the c-component and descendants of the set until there is no change. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.2. (Interventional Border)[5] Let $T$ be a minimal $U C$ -territory on $\\mathcal{G}$ with respect to $Y$ Then, $X={\\mathsf{P a}}(T)\\setminus T$ is called an interventional border for $\\mathcal{G}$ w.r.t. $Y$ denoted by $I B(\\mathcal{G},Y)$ . ", "page_idx": 3}, {"type": "text", "text": "Lemma 3.1. [5] For causal graph $\\mathcal{G}$ with reward $Y$ , $I B({\\mathcal{G}}_{\\overline{{W}}},Y)$ is a POMIS, for any $W\\subseteq V\\setminus\\{Y\\}$ . ", "page_idx": 3}, {"type": "text", "text": "Although the graphical characterization in Lemma 3.1 provides a means to enumerate the complete set of POMISs, it comes with exponential time complexity. The authors also propose an efficient algorithm for enumerating all POMISs in [5]. However, this requires knowing the true causal graph, and without it, one has to consider interventions on all possible subsets of nodes, which are exponentially many. One naive approach to tackle the problem is to learn the full causal graph with all confounders to list all POMISs. However, a question arises: Do we need to learn/detect all possible confounders since the goal is to find POMISs and not the full graph? ", "page_idx": 3}, {"type": "text", "text": "Before answering the above question, we start with an example considering the causal graphs in Figure 1. Using Lemma 3.1, the set of POMISs for the true graph $\\mathcal{G}$ is $\\mathcal{Z}_{\\mathcal{G}}=\\{\\phi,\\{\\bar{V}_{1}\\},\\{V_{2}\\},\\{\\bar{V}_{3}\\},\\{V_{1},\\bar{V_{2}}\\}\\}$ However, for $\\mathcal{G}_{1}$ which has the bidirected edge $V_{2}\\leftrightarrow Y$ missing, the set of POMISs is $\\mathcal{T}_{\\mathcal{G}_{1}}\\;=$ $\\{\\phi,\\{V_{2}\\},\\{V_{1},V_{2}\\}\\}$ . Also for $\\mathcal{G}_{2}$ which has the bidirected edge $V_{1}\\leftrightarrow V_{2}$ missing, the set of POMISs is ${\\mathcal{I}}_{\\mathcal{G}_{2}}\\,=\\,\\{\\phi,\\{V_{1}\\},\\{V_{2}\\},\\{V_{1},V_{2}\\}\\}$ . In both cases, we miss at least one POMIS, and since it is possible to construct an SCM compatible with the true causal graph $\\mathcal{G}$ where any arm in POMIS is optimal, if this arm is not learned, we can suffer linear regret [5]. Although the graph $\\mathcal{G}_{3}$ has the bidirected edge $V_{1}\\leftrightarrow V_{3}$ missing, it still has the same set of POMISs as the true graph, i.e., ${\\mathcal{Z}}_{\\mathcal{G}_{3}}=\\{\\phi,\\{V_{1}\\},\\{V_{2}\\},\\{V_{3}\\},\\{V_{1},V_{2}\\}\\}.$ . This example shows that only a subset of latent confounders affect the POMISs learned from the graph. We formally prove that it is necessary and sufficient to learn/detect all latent variables between the reward and its ancestors because missing any one of them will cause us to miss at least one of POMISs leading to linear regret for some bandit instances. ", "page_idx": 3}, {"type": "text", "text": "Lemma 3.2. It is necessary to learn/detect the latent confounders between reward node $Y$ and any node $X\\in\\mathsf{A n}(Y)$ in causal graph $\\mathcal{G}$ to learn all the POMISs correctly and hence avoid linear regret. ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.1. Consider a causal graph $\\mathcal{G}(V,E)$ and another causal graph $\\mathcal{G}^{\\prime}$ such that they have the same vertex set and directed edges but differ in bidirected edges, with the bidirected edges in $\\mathcal{G}^{\\prime}$ being a subset of the bidirected edges in $\\mathcal{G}$ . The graphs will yield different collections of POMISs if and only if there exists some $Z\\in\\mathsf{A n}(Y)$ such that either (a) or $(b)$ is true: ", "page_idx": 3}, {"type": "text", "text": "(b) Neither of the graphs $\\mathcal{G}^{\\prime}$ and $\\mathcal{G}$ have a bidirected edge between $Z$ and $Y$ , and there exists $a$ bidirected edge in $\\mathcal{G}$ between some $X\\in M U C T(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z)}},\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})}^{\\prime}\\:,Y)$ (G\u2032Pa(Z),Bi(Z,G\u2032) , Y ) and Z but not in G\u2032. ", "page_idx": 3}, {"type": "text", "text": "We extend Lemma 3.2 to provide necessary and sufficient conditions in Theorem 3.1 characterizing all the latent variables that need to be learned, ensuring that the POMISs learned from a sparser causal graph match all those in the true causal graph. Suppose we have access to the induced observable subgraph $\\mathcal{G}^{\\prime}$ on ancestors of the reward node. We can start by testing for latent confounders between $Y$ and any node in $\\mathsf{A n}(Y)$ . Then, we need to test for latent confounders between any pair $Z\\in\\mathsf{A n}(Y)$ such that $Z$ and $Y$ don\u2019t have a bi-directed edge between them, and $X\\in\\mathbf{M}\\mathrm{UCT}(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z)}},\\mathrm{Bi}(Z,\\mathcal{G}^{\\prime})}^{\\prime}\\,,Y)$ until there are no new pairs to test. Theorem 3.1 can be useful because depending on the underlying causal graph, it saves us the number of latent confounders we need to test. For instance, consider a causal graph that has the reward $Y$ with $n$ different parent nodes, i.e., ${\\mathsf{P a}}(Y)=\\{V_{1},V_{2},\\ldots,V_{n}\\}$ , with no edges between the parents. In cases where every parent of $Y$ is confounded with $Y$ , or when none of them is confounded with $Y$ , we only need to test for $|\\mathsf{A n}(Y)|$ latent variables, as implied by Theorem 3.1. However, in the worst-case scenario, we would need to test $\\binom{|\\mathsf{A n}(Y)|+1}{2}$ latent variables when the true graph only has the confounders $V_{1}\\leftrightarrow Y$ and $V_{i}\\longleftrightarrow V_{i+1}$ for all $i=1,..,n-1$ . The exact number of latents we need to test can range from $|\\mathsf{A n}(Y)|$ to $\\binom{|\\mathsf{A n}(Y)|+1}{2}$ depending on the true graph. One issue still remains: we need a sample-efficient algorithm to learn the induced observable graph over $\\mathsf{A n}(Y)$ and to test the presence of confounders, which is addressed in upcoming sections. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "4 Finite Sample Causal Discovery Algorithm ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we propose a sample-efficient algorithm to learn causal graphs with latent confounders. We propose a two-phase approach. In the first phase, the algorithm learns the observable graph structure, i.e., the induced graph between observed variables. In the second phase, it detects the latent confounders. In the next section, we use the proposed discovery algorithm to construct the algorithm for causal bandits with an unknown graph. We begin by proposing two Lemmas to learn the ancestrality relations and latent confounders using interventions. ", "page_idx": 4}, {"type": "text", "text": "Lemma 4.1. Consider a causal graph $\\mathcal{G}(V,E)$ and $W\\subseteq V.$ . Furthermore, let $X,T\\in{\\cal{V}}\\setminus{\\bf{W}}\\mathrm{~}l$ e any two variables. Under the faithfulness Assumption 2.1 $(X\\in\\mathsf{A n}(T))_{\\mathcal{G}_{\\overline{{W}}}}$ if and only if for any $\\pmb{w}\\in[K]^{|\\boldsymbol{W}|}$ , we have $P(t|d o(w))\\neq P(t|d o(w),d o(x))$ for some $x,t\\in[K]$ . ", "page_idx": 4}, {"type": "text", "text": "Lemma 4.2. Consider two variables $X_{i}$ and $X_{j}$ such that $X_{j}\\notin\\mathsf{A n}(X_{i})$ and a set of variables $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq W$ and $X_{i},X_{j}\\notin{\\bf{W}}$ . Under the faithfulness Assumption 2.1 there is latent confounder between $X_{i}$ and $X_{j}$ if and only if for any $\\pmb{w}\\ \\in\\ [K]^{|\\pmb{W}|}.$ , we have $P(x_{j}\\mid$ $d o(x_{i}),d o(\\dot{\\boldsymbol{W}}=\\boldsymbol{w}))\\neq P(x_{j}\\mid x_{i},d o(\\boldsymbol{W}\\Tilde{=\\boldsymbol{w}}))$ for some realization $x_{i},x_{j}\\in[K]$ . ", "page_idx": 4}, {"type": "text", "text": "These Lemmas are modified versions of Lemma 1 in [14] and Interventional Do-see test in [14], respectively. The difference between Lemma 4.1 and Lemma 1 in [14] is that we have an inequality test that can be used in the sample-efficient discovery instead of a statistical independence test. The Interventional Do-see test in [14] is valid for adjacent nodes only; however, our Lemma 4.2 can be used to test presence of latent confounder between any pair of nodes. This is because the condition in Lemma 4.2, $X_{j}\\not\\in\\mathsf{A n}(X_{i})$ , can always be satisfied for any pair by filpping the order when one node is an ancestor of the other. In order to provide theoretical guarantees on sampling complexity, the inequality conditions are not enough; we need to assume certain gaps similar to [7, 9, 17]. ", "page_idx": 4}, {"type": "text", "text": "Assumption 4.1. Consider a causal graph $\\mathcal{G}(V,E)$ and $W\\subseteq V.$ Furthermore, let $X,T\\in V\\backslash\\mathbf{W}$ be any two variables. Then, we have $(X\\in\\mathsf{A n}(T))_{\\mathcal{G}_{\\overline{{W}}}}$ if and only if for any $\\pmb{w}\\in[K]^{|\\boldsymbol{W}|}$ , we have $|P(t|d o(\\pmb{w}))-P(t|d o(\\pmb{w}),d o(\\pmb{x}))|>\\epsilon$ for some $x,t\\in[K]$ , where $\\epsilon>0$ is some constant. ", "page_idx": 4}, {"type": "text", "text": "Assumption 4.2. Consider two variables $X_{i}$ and $X_{j}$ such that $X_{j}\\notin\\mathsf{A n}(X_{i})$ and a set of variables $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq W$ and $X_{i},X_{j}\\notin\\mathbf{W}$ . There is a latent confounder or a bidirected edge between $X_{i}$ and $X_{j}$ if and only if for any $\\pmb{w}\\in[K]^{|\\boldsymbol{W}|}$ , we have $|P(x_{j}\\mid d o(x_{i}),d o(W=w))-P(x_{j}\\mid$ $x_{i},d o({\\pmb W}={\\pmb w}))\\big|>\\gamma$ for some realization $x_{i},x_{j}\\in[K]$ and some constant $\\gamma>0$ . ", "page_idx": 4}, {"type": "text", "text": "4.1 Learning the Observable Graph ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We propose Algorithm 1 to learn the transitive closure under any arbitrary intervention $d o(\\mathbf{W})$ , denoted by $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ . We use the Assumption 4.1 to bound the number of samples for ancestrality tests. We start with an empty graph and add edges by running ancestrality tests for all pairs of nodes in $\\mathbf{V}\\backslash\\mathbf{W}$ , resulting in the transitive closure $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ . We recall that the transitive reduction $\\bar{T}r(\\mathcal{G})=(\\mathbf{V},\\mathbf{E}^{r})$ of a DAG $\\mathcal{G}=(\\mathbf{V},\\mathbf{E})$ is unique, with ${\\bf E}^{r}\\subseteq{\\bf E}$ , and it can be computed in polynomial time [25]. Also, note that $T r({\\mathcal{G}})=T r({\\mathcal{G}}^{t c})$ . We propose a randomized Algorithm 2 similar to the one proposed in ", "page_idx": 4}, {"type": "image", "img_path": "uM3rQ14iex/tmp/e9e6036085e988676bf2016369783b13be9e3911ce1650b8f45d0ab6e365bc9e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Algorithm 2: Learn the Observable Graph ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "1 Function LearnObservableGraph(V, \u03b1, dmax, \u03b41, \u03b42):   \n2 E = \u2205 & IData = \u2205   \n3 for i = 1 : 8\u03b1 dmax log(n) do   \n4 W = \u2205   \n5 for $V_{i}\\in V$ do   \n6 $\\mathbf{W}\\leftarrow\\mathbf{W}\\cup V_{i}$ with probability $\\begin{array}{r}{1-\\frac{1}{2d_{m a x}}}\\end{array}$   \n7 $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ , $\\mathrm{\\DeltaData}_{\\mathbf{W}}=$ LearnTransitiveClosure $(\\mathbf{V},\\mathbf{W},\\delta_{1},\\delta_{2})$   \n8 Compute the transitive reduction $T r(\\mathcal{G}_{\\mathbf{W}}^{t c})$ & add any missing edges from $T r(\\mathcal{G}_{\\mathbf{W}}^{t c})$ to $\\mathbf{E}$   \n${\\mathcal{Z}}D a t a={\\mathcal{T}}D a t a\\cup{\\mathrm{Data}}_{\\overline{{\\mathbf{W}}}}$ (Keep Saving Interventional Data)   \n10 return The observable graph structure $(\\mathbf{V},\\mathbf{E})$ and interventional data samples in IData   \n11 End Function ", "page_idx": 5}, {"type": "text", "text": "[14] that repeatedly uses Algorithm 1 to learn the observable graph structure. The motivation behind the randomized Algorithm 2 is Lemma 5 from [14], which states that for any edge $(X_{i},X_{j})$ , consider a set of variables W such that $\\{W_{i}:\\pi(W_{i})>\\pi(X_{i})\\ \\&\\ W_{i}\\in{\\sf P a}(X_{j})\\}\\subseteq\\dot{\\mathbf{W}}$ where $\\pi$ is any total order that is consistent with the partial order implied by the DAG, i.e., $\\pi(X)<\\pi(Y)$ iff $X\\in\\dot{\\mathsf{A}}\\mathsf{n}(Y)$ . In this case, the edge $(X_{i},X_{j})$ will be present in the graph $T r(\\mathcal{G}_{\\overline{{\\mathbf{W}}}})$ . Algorithm 2 randomly selects W, computes the transitive reduction of the post-interventional graphs, and finally accumulates all edges found in the transitive reduction across iterations. Algorithm 2 takes a parameter $d_{\\mathrm{max}}$ , which must be greater than or equal to the highest graph degree for our theoretical guarantees to hold. ", "page_idx": 5}, {"type": "text", "text": "Lemma 4.3. Suppose that the Assumption 4.1 holds and we have access to max $\\bigl(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\bigr)\\log\\frac{2K^{2}}{\\delta_{1}}$ samples from do(Xi = xi, W = w) \u2200xi \u2208[K] and \u03f582 log 2\u03b4K22 samples from $\\mathcal{l}o(\\mathbf{W}=\\mathbf{w})$ for a fixed $w\\in[K]^{|\\mathbf{W}|}$ and $\\mathbf{W}\\subseteq\\mathbf{V}$ . Then, with probability at least $1-\\delta_{1}-\\delta_{2}$ , we have $(X_{i}\\in\\mathsf{A n}(X_{j}))_{\\mathcal{G}_{\\overline{{W}}}}\\,i f$ and only i $\\begin{array}{r}{^{\\circ}\\exists\\;x_{i},x_{j}\\in[K]\\;s.t.\\;\\left|\\widehat{P}(x_{j}\\mid d o(\\pmb{w}))-\\widehat{P}(x_{j}\\mid d o(\\pmb{w}),d o(x_{i}))\\right|>\\frac{\\epsilon}{2}.}\\end{array}$ ", "page_idx": 5}, {"type": "text", "text": "Lemma 4.3 provides the sample complexity for running ancestrality tests. Algorithm 1 selects a realization $w\\in[K]^{|\\mathbf{W}|}$ , takes $B$ samples from the intervention $d o(\\mathbf{W}=\\mathbf{w})$ , and $A$ samples from every $d o(X_{i}=x_{i},\\mathbf{W}=\\mathbf{w})$ for all $X_{i}\\in\\mathbf{V}\\setminus\\mathbf{W}$ and $x_{i}\\in[K]$ interventions. Thus, in the worst case, Algorithm 1 requires $K A n+B$ samples to learn the true transitive closure with high probability. We formally prove this result in the Lemma 4.4. ", "page_idx": 5}, {"type": "text", "text": "Lemma 4.4. Algorithm 1 learns the true transitive closure under any intervention, i.e., $\\mathcal{G}_{\\overline{{W}}}^{t c}$ , with probability at least $1-n\\delta_{1}-\\delta_{2}$ with a maximum $K A n+B$ interventional samples. If we set $\\begin{array}{r}{\\dot{\\delta}_{1}=\\frac{\\delta}{2n}}\\end{array}$ and $\\begin{array}{r}{\\delta_{2}=\\frac{\\delta}{2}}\\end{array}$ , then Algorithm $^{\\,l}$ learns true transitive closure with probability at least $1-\\delta$ . ", "page_idx": 5}, {"type": "text", "text": "Algorithm 2 repeatedly invokes Algorithm 1 to learn $T r({\\mathcal{G}}_{\\overline{{\\mathbf{W}}}})$ for randomly sampled W. Through this iterative process, it accumulates edges across iterations, ultimately constructing the observable graph structure. To establish the sampling complexity guarantee for Algorithm 2, we leverage the result from Lemma 4.4. The Theorem 4.1 gives the sampling complexity for learning the true observable graph with high probability. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4.1. Algorithm 2 learns the true observable graph with probability at least $\\operatorname{1-\\frac{1}{n^{\\frac{\\alpha}{2d_{m a x}}-2}}}-$ $8\\alpha d_{m a x}\\log(n)(n\\delta_{1}+\\delta_{2})$ $8\\alpha d_{m a x}\\log n(K A n+B)$ e,r tvheennti oAnlaglo sriathmmpl e2s .l eIaf rwnse  tshete $\\alpha=$ $\\frac{2d_{m a x}\\log{(\\frac{2}{\\delta}+2)}}{\\log{n}}$ $\\delta_{1}~=~\\frac{\\delta}{32\\alpha d_{m a x}n\\log n}$ $\\delta_{2}~=~\\frac{\\delta}{32\\alpha d_{m a x}\\log n}$   \nobservable graph with probability at least of $1-\\delta$ . (We have $\\begin{array}{r}{A\\,=\\,\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{2n K^{2}}{\\delta_{1}}\\ \\ll}\\end{array}$ B =\u03f582 log 2n\u03b42K2 as in line 2 of Algorithm $^{l.}$ .) ", "page_idx": 6}, {"type": "text", "text": "4.2 Learning the Latent Confounders ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Assumption 4.2 can be used to test for latents between any pair of observed variables. Note that while using Algorithm 2, we save and return all the interventional data samples. These samples can be reused to detect latent confounders in the next phase. For any variables $X_{i}$ and $X_{j}$ such that $X_{j}\\notin\\mathsf{A n}(X_{i})$ , we need access to interventional samples $d o(\\mathbf{W}=\\mathbf{w})$ such that $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq\\dot{\\mathbf{W}}$ and $X_{i}$ & $X_{j}\\ \\notin\\ \\mathbf{W}$ . In the supplementary material, we demonstrate that randomly selecting the target set $\\mathbf{W}$ in Algorithm 2 ensures that we have access to all such datasets for all pairs of observed variables with high probability. In addition to simple causal effects we need to estimate the conditional causal effect of the form $P(x_{j}|x_{i},d o(\\mathbf{W}=\\mathbf{\\bar{w}}))$ . To bound the number of samples required to ensure accurate estimation of the conditional causal effects, we rely on Assumption 4.3. Note that Assumption 4.3 does not restrict the applicability of our algorithm; it simply assumes that under an intervention $d o(\\mathbf{W}=\\mathbf{w})$ , either the probability of observing a realization $X_{i}=x_{i}$ is zero or is lower-bounded by some constant $\\eta>0$ . The role of this assumption is to bound the number of interventional samples required for accurate estimation of the conditional causal effects. ", "page_idx": 6}, {"type": "text", "text": "Assumption 4.3. For any variable $X_{i}\\in\\mathbf{V}$ and any intervention $d o(\\mathbf{W}=\\mathbf{w})$ where $\\mathbf{W}\\subseteq\\mathbf{V}$ and $\\mathbf{w}\\in[K]^{|\\mathbf{W}|}$ , we assume that either $P(x_{i}|d o(\\mathbf{W}=\\mathbf{w}))=0$ or $P(x_{i}|d o(\\mathbf{W}=\\mathbf{w}))\\geq\\eta>0.$ . ", "page_idx": 6}, {"type": "image", "img_path": "uM3rQ14iex/tmp/e859341fc03596cd4980e84fcb6fc881301337aa5c2cb18311a0d17f06045b64.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "11 End Function ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Lemma 4.5. Consider two nodes $X_{i}$ and $X_{j}$ s.t. $X_{j}\\,\\notin\\,\\mathsf{A n}(X_{i})$ and suppose that Assumptions $2.1\\ 4.2$ hold and we have 2access to $\\begin{array}{r l r}{m a x(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}})\\log\\frac{2K^{2}}{\\delta_{1}}}\\end{array}$ samples from $d o(X_{i}\\,=\\,x_{i},\\mathbf{W}\\,=\\,\\mathbf{w})$ $\\forall x_{i}\\in[K]$ and $\\begin{array}{r}{\\frac{16}{\\eta\\gamma^{2}}\\log(\\frac{2K^{2}}{\\delta_{3}})+\\frac{1}{2\\eta^{2}}\\log(\\frac{2K^{2}}{\\delta_{4}})}\\end{array}$ samples from $d o(\\mathbf{W}=\\mathbf{w})$ for a fixed $w\\in[K]^{|\\mathbf{W}|}$ and $\\textbf{W}\\subseteq\\textbf{V}$ such that $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\ \\subseteq\\ W$ and $X_{i}$ & $X_{j}~\\notin$ W. Then, with probability at least $1-\\delta_{1}-\\delta_{3}-\\delta_{4}$ , we have a latent confounder between $X_{i}$ and $X_{j}$ if $\\overrightarrow{\\mathbf{\\Delta}}\\rightleftharpoons x_{i},x_{j}\\in$ $\\begin{array}{r}{[K]\\;s.t.\\;\\big|\\;\\widehat{P}(x_{j}|d o(x_{i}),d o(\\pmb{w}))-\\widehat{P}(x_{j}|x_{i},d o(\\pmb{w}))\\;\\big|>\\frac{\\gamma}{2}.}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.5 establishes the sample complexity for detecting the presence of latent confounders for any pair of nodes in the causal graph. Using results from Theorem 4.1 and Lemma 4.5, we bound the number of interventions required by the proposed Algorithm 3 to learn the causal graph along with the latent confounders. Theorem 4.2 provides the sample complexity guarantee for Algorithm 3 to learn the true causal graph, including all latent confounders, with a given confidence level. An important feature of the sampling complexity result in Theorem 4.2 is that the number of intervention samples needed to learn the causal graph scales polynomially with the number of nodes $n$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.2. Algorithm n2dm\u03b12ax \u22122 \u22128\u03b1dmax log(n)(n\u03b41 + (\u03b42 + \u03b43 + \u03b44)) with a maximum of 8\u03b1dmax log n(KAn + $^3$ $\\operatorname*{max}(B,C))$ interventional samples. If we set 2dmaxl olog gn ( \u03b44 +2), \u03b41 = 64\u03b1dma\u03b4xn log n and \u03b42 = $\\begin{array}{r}{\\delta_{3}\\,=\\,\\delta_{4}\\,=\\,\\frac{\\delta}{64\\alpha d_{m a x}\\log n}}\\end{array}$ , then Algorithm $^3$ learns the true causal graph with probability at least $1-\\delta$ . ( $\\overset{\\cdot}{A}$ and $B$ are given by line 2 of Algorithm and is given by line 3 of Algorithm 3.) ", "page_idx": 7}, {"type": "text", "text": "Suppose the constant gaps $\\epsilon$ and $\\gamma$ in Assumptions 4.1 and 4.2 are close; then, we have $\\begin{array}{r}{C>\\frac{1}{\\eta}A\\geq}\\end{array}$ $\\scriptstyle{\\frac{1}{\\eta}}B$ . The value of the constant $0<\\eta<1$ is usually small in practical scenarios, so the quantity $C$ is much greater than both $B$ or $A$ . This implies that the number of samples required to test the presence of latent variables is greater than that required to learn ancestral relations. This is because we need to accurately estimate conditional causal effects to detect latent variables, which requires a large number of samples compared to simple causal effects. Theorem 3.1 is useful here because it shows that we do not need to test for confounders between all pairs of nodes among ancestors of the reward node to learn the POMIS set. ", "page_idx": 7}, {"type": "text", "text": "5 Algorithm for Causal Bandits with Unknown Graph Structure ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Algorithm 4 is the sketch of our algorithm for causal bandits with unknown graph structure. The detailed algorithm with all steps explained is given in the supplementary material (Algorithm 6). Algorithm 4 first learns the transitive closure of the graph $\\mathcal{G}^{t c}$ to find ancestors of the reward node $Y$ . This is because POMISs are only subsets of $\\mathsf{A n}(\\bar{Y})$ . The next step is to learn the observed graph structure among the reward $Y$ and nodes in $\\mathsf{A n}(Y)$ . Instead of detecting the presence of confounders between all pairs of nodes in $\\mathsf{A n}(Y)$ as in Algorithm 3, we focus on identifying the necessary and sufficient ones, as characterized by Theorem 3.1. This approach is more sample-efficient since it tests for fewer latent confounders. The exact saving in terms of samples depends on the underlying causal graph and is hard to characterize in general. The last step of Algorithm 4 is to run a simple bandit algorithm, e.g., UCB algorithm [26], to identify the optimal arm from the POMISs. Given that Assumptions 4.1, 4.2, and 4.3 hold, and the reward is binary $(Y\\in\\{0,1\\})$ ), using the results from Lemma 4.4 and Theorem 4.2, we provide a worst-case regret bound for Algorithm 4 in Theorem 5.1. ", "page_idx": 7}, {"type": "text", "text": "Algorithm 4: Sketch of Algorithm for causal bandits with unknown graph structure ", "text_level": 1, "page_idx": 7}, {"type": "table", "img_path": "uM3rQ14iex/tmp/21a5d9a73f4707c104396e6d0061cde33ddd333997b8ac09496b9e965f557c92.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Theorem 5.1. Algorithm 4 learns the true set of POMISs with probability at least $1-2\\delta$ . Under the event that it learns POMISs correctly, the cumulative regret is bounded as follows: ", "page_idx": 7}, {"type": "text", "text": "$\\begin{array}{r c l}{{\\displaystyle R_{T}\\leq K n\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{4n^{2}K^{2}}{\\delta}}}&{{+}}&{{\\displaystyle\\frac{8}{\\epsilon^{2}}\\log\\frac{4n K^{2}}{\\delta}~~+}}\\\\ {{8\\alpha d_{m a x}\\bigg(K A\\big|\\mathsf{A}\\mathsf{n}(Y)\\big|~+~\\operatorname*{max}(B,C)\\bigg)\\log\\left(\\big|\\mathsf{A}\\mathsf{n}(Y)\\big|\\right)~+\\displaystyle\\sum_{\\mathrm{\\scriptscriptstyle{s}\\in\\{\\Omega(I)\\vert\\nabla I\\in\\mathbb{Z}_{\\mathcal{O}}\\}}}\\Delta_{d o(\\mathbf{s})}\\bigg(1+\\frac{\\log T}{\\Delta_{d o(\\mathbf{s})}^{2}}\\bigg),}}\\end{array}$ where $A$ and $B$ are given by line 2 of Algorithm $^{\\,l}$ , and $C$ is given by line 3 of Algorithm $^3$ by setting $\\begin{array}{r}{\\alpha=\\frac{2d_{m a x}\\log\\left(\\frac{4}{\\delta}+2\\right)}{\\log\\left|\\mathsf{A n}\\left(Y\\right)\\right|},\\,\\delta_{1}=\\frac{\\delta}{64\\alpha d_{m a x}\\left|\\mathsf{A n}\\left(Y\\right)\\right|\\log\\left|\\mathsf{A n}\\left(Y\\right)\\right|}}\\end{array}$ and $\\begin{array}{r}{\\delta_{2}=\\delta_{3}=\\delta_{4}=\\frac{\\delta}{64\\alpha d_{m a x}\\log\\big|\\mathsf{A n}(Y)\\big|}.}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "The first three terms in the regret bound correspond to the interventional samples required to learn the ancestors of the reward node, and then the set of POMISs $(\\mathcal{Z}_{\\mathcal{G}})$ . The last term corresponds to the regret incurred by running the UCB algorithm over the POMIS set. The number of interventional samples used to learn the true set of POMISs, with high probability, has polynomial scaling with respect to the number of nodes $n$ in the graph. However, the total number of arms in the POMIS set, in the worst case, can exhibit exponential scaling with respect to the number of ancestors of the reward node $|\\mathsf{A n}(Y)|$ . The advantage of sample-efficient discovery is that it helps us reduce the action space before applying the UCB algorithm. If the graph is not densely confounded, the total number of arms in the POMIS set would be small, and running causal discovery before the bandit algorithm is advantageous. Without discovery, one would always have to run the UCB or a standard MAB solver with exponentially many arms. For instance, if the causal graph has $n$ nodes, there will be $\\begin{array}{r}{\\sum_{i=1}^{n}\\binom{n}{i}K^{i}=(\\mathop{\\dot{K}}+1)^{n}}\\end{array}$ different possible arms/interventions. ", "page_idx": 8}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Theorem 5.1 establishes the worst-case upper bound for cumulative regret when we need to test latent confounders between all pairs of nodes within $\\mathsf{A n}(Y)$ . However, Algorithm 4 selectively examines only a subset of latent confounders sufficient to infer the true POMIS set, as outlined in Theorem 3.1. Although the advantage is hard to quantify in general, we demonstrate it using simulations on randomly generated graphs. We sample a random ordering $\\sigma$ among the vertices. Then, for each nth node, we determine its in-degree as $X_{n}=\\operatorname*{max}(1,\\mathrm{{Bin}}(n-1,\\rho))$ , followed by selecting its parents through uniform sampling from the preceding nodes in the ordering. Finally, we chordalize the graph using the elimination algorithm [27], employing an elimination ordering that is the reverse of $\\sigma$ . Additionally, we introduce a confounder between every pair of nodes with a probability of $\\rho_{L}$ . For all the simulations, we randomly sample 50 causal graphs with different values of densities $\\rho$ and $\\rho_{L}$ and assume that all variables are binary for simplicity, i.e., $K=2$ . We set the value of $\\delta$ to 0.99, and the gaps $\\gamma=\\epsilon=0.01$ and $\\eta=0.05$ . We plot interventional samples used to learn the induced observable graph on $\\mathsf{A n}(Y)$ with and without latent confounders, as well as the samples required to learn the POMIS set by Algorithm 4. The width of confidence interval is set to 2 standard deviations. ", "page_idx": 8}, {"type": "image", "img_path": "uM3rQ14iex/tmp/424b9c5a653e774420fbff9f66ff7e2ca6f3c1b85fc7585f518764b50d5022c2.jpg", "img_caption": ["Figure 2: Simulations to demonstrate the advantage of Algorithm 4 over full graph discovery (Learning all possible latents) "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "The simulation results in Figure 2 demonstrate that Algorithm 4 requires fewer samples than learning the induced graph on $\\mathsf{A n}(Y)$ , which includes all confounders. However, as $\\rho_{L}$ increases for a fixed $\\rho$ , this advantage diminishes, as illustrated in Figure 2. The trend remains consistent as the density parameters $\\rho$ and $\\rho_{L}$ are varied from 0.2, 0.4, and 0.6. The plots in Figure 3 compare the exponentially growing arms in causal bandits with intervention samples used by our algorithm to learn the reduced action set in the form of POMISs. This demonstrates the major advantage of our algorithm, which, instead of exploring an exponentially large action set as in naive UCB algorithms, uses interventions to reduce the action space to the POMIS set before applying the UCB algorithm. Additionally, the number of intervention samples required in the first phase of identifying the true POMIS set grows polynomially with respect to the number of nodes in the graph. However, the number of arms in the POMIS set can still exhibit exponential scaling with respect to the number of ancestors of the reward node in the worst case. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "image", "img_path": "uM3rQ14iex/tmp/ed7ccaf7316239acc1c3dcfa2e544a495b80d0ed64e450df53332e6a876edc02.jpg", "img_caption": ["Figure 3: Simulations to demonstrate advantage of discovery for causal bandits. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "uM3rQ14iex/tmp/66badaf51762c80cadc4de6ab8b00e3f34a5c6c3ea547696dc4529d8da7142ed.jpg", "img_caption": ["Figure 4: Cumulative regret for Algorithm 4 versus learning all possible latents $\\rho=\\rho_{L}=0.3)$ ). "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "We also run the UCB algorithm on the learned POMIS set and plot the cumulative regret in Figure 4. Since the number of time steps $T$ is on the order of $10^{8}$ , it is not feasible to store and plot cumulative regret for every time step over multiple randomly sampled graphs; therefore, we downsample the cumulative regret to show the overall trend. The downsampling, along with the large scale of the $y$ -axis, makes the regret in the discovery phase appear linear with a fixed slope, although it is piecewise linear if we zoom in. Also, the UCB phase converges very fast compared to the discovery phase because the number of POMISs for randomly sampled graphs is small. We plot the results for graphs with 10, 15, and 20 nodes, and in all cases, we can see the advantage of partial discovery compared to full discovery, since Algorithm 4 finds the POMIS set with fewer samples. The code to reproduce our experimental results is available at https://github.com/CausalML-Lab/CausalBandits_ with_UnknownGraph. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We show that partial discovery is sufficient to achieve sublinear regret for causal bandits with an unknown causal graph containing latent confounders. Without relying on causal discovery, one must consider interventions on all possible subsets of nodes, which is infeasible. Therefore, we propose a two-phase approach: the first phase learns the induced subgraph of the ancestors of the reward node, along with a subset of confounders, to construct a set of possibly optimal arms. We demonstrate that the number of interventional samples in the first phase required to identify the POMIS set scales polynomially with respect to the number of nodes in the causal graph. In the next phase, we apply the Upper Confidence Bound (UCB) algorithm to the reduced action space to find the optimal arm. ", "page_idx": 9}, {"type": "text", "text": "8 Acknowledgment ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Murat Kocaoglu acknowledges the support of NSF CAREER 2239375, IIS 2348717, Amazon Research Award and Adobe Research. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Finnian Lattimore, Tor Lattimore, and Mark D Reid. Causal bandits: Learning good interventions via causal inference. Advances in Neural Information Processing Systems, 29, 2016.   \n[2] Rajat Sen, Karthikeyan Shanmugam, Alexandros G Dimakis, and Sanjay Shakkottai. Identifying best interventions through online importance sampling. In International Conference on Machine Learning, pages 3057\u20133066. PMLR, 2017.   \n[3] Yangyi Lu, Amirhossein Meisami, Ambuj Tewari, and William Yan. Regret analysis of bandit problems with causal background knowledge. In Conference on Uncertainty in Artificial Intelligence, pages 141\u2013150. PMLR, 2020.   \n[4] Vineet Nair, Vishakha Patil, and Gaurav Sinha. Budgeted and non-budgeted causal bandits. In International Conference on Artificial Intelligence and Statistics, pages 2017\u20132025. PMLR, 2021.   \n[5] Sanghack Lee and Elias Bareinboim. Structural causal bandits: Where to intervene? Advances in neural information processing systems, 31, 2018.   \n[6] Lai Wei, Muhammad Qasim Elahi, Mahsa Ghasemi, and Murat Kocaoglu. Approximate allocation matching for structural causal bandits with unobserved confounders. Advances in Neural Information Processing Systems, 36, 2024.   \n[7] Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari. Causal bandits with unknown graph structure. Advances in Neural Information Processing Systems, 34:24817\u201324828, 2021.   \n[8] Arnoud De Kroon, Joris Mooij, and Danielle Belgrave. Causal bandits without prior knowledge using separating sets. In Conference on Causal Learning and Reasoning, pages 407\u2013427. PMLR, 2022.   \n[9] Mikhail Konobeev, Jalal Etesami, and Negar Kiyavash. Causal bandits without graph learning. arXiv preprint arXiv:2301.11401, 2023.   \n[10] Alan Malek, Virginia Aglietti, and Silvia Chiappa. Additive causal bandits with unknown graph. arXiv preprint arXiv:2306.07858, 2023.   \n[11] Jonas Peters, Dominik Janzing, and Bernhard Sch\u00f6lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017.   \n[12] Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, and Gyorgy Simon. Challenges and opportunities with causal discovery algorithms: application to alzheimer\u2019s pathophysiology. Scientific reports, 10(1):2975, 2020.   \n[13] Alessio Zanga, Elif Ozkirimli, and Fabio Stella. A survey on causal discovery: Theory and practice. International Journal of Approximate Reasoning, 151:101\u2013129, 2022.   \n[14] Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimental design for learning causal graphs with latent variables. Advances in Neural Information Processing Systems, 30, 2017.   \n[15] Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard Sch\u00f6lkopf. Causal discovery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination. In IJCAI: Proceedings of the Conference, volume 2017, page 1347. NIH Public Access, 2017.   \n[16] Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G Dimakis, and Sriram Vishwanath. Learning causal graphs with small interventions. Advances in Neural Information Processing Systems, 28, 2015.   \n[17] Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Kocaoglu, Enric Boix Adsera, and Guy Bresler. Sample efficient active learning of causal trees. Advances in Neural Information Processing Systems, 32, 2019.   \n[18] Muhammad Qasim Elahi, Lai Wei, Murat Kocaoglu, and Mahsa Ghasemi. Adaptive online experimental design for causal discovery, 2024.   \n[19] David Heckerman, Christopher Meek, and Gregory Cooper. A bayesian approach to causal discovery. Technical report, Technical report msr-tr-97-05, Microsoft Research, 1997.   \n[20] Yashas Annadani, Nick Pawlowski, Joel Jennings, Stefan Bauer, Cheng Zhang, and Wenbo Gong. Bayesdag: Gradient-based posterior sampling for causal discovery. arXiv preprint arXiv:2307.13917, 2023.   \n[21] Christian Toth, Lars Lorch, Christian Knoll, Andreas Krause, Franz Pernkopf, Robert Peharz, and Julius Von K\u00fcgelgen. Active bayesian causal inference. Advances in Neural Information Processing Systems, 35:16261\u201316275, 2022.   \n[22] Judea Pearl. Causality. Cambridge university press, 2009.   \n[23] Jin Tian and Judea Pearl. A general identification condition for causal effects. In Aaai/iaai, pages 567\u2013573, 2002.   \n[24] Alain Hauser and Peter B\u00fchlmann. Two optimal strategies for active learning of causal models from interventional data. International Journal of Approximate Reasoning, 55(4):926\u2013939, 2014.   \n[25] Alfred V. Aho, Michael R Garey, and Jeffrey D. Ullman. The transitive reduction of a directed graph. SIAM Journal on Computing, 1(2):131\u2013137, 1972.   \n[26] Tor Lattimore and Csaba Szepesv\u00e1ri. Bandit algorithms. Cambridge University Press, 2020.   \n[27] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Supplemental Material ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Review of $d$ -separation: ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Consider three disjoint sets of nodes $\\mathbf{X},\\mathbf{Y}$ , and $\\mathbf{Z}$ in the causal graph $\\mathcal{G}=(\\mathbf{V},\\mathbf{E})$ . The sets of nodes $\\mathbf{X}$ and $\\mathbf{Y}$ are $d$ -separated given $\\mathbf{Z}$ , denoted by $(\\mathbf{X}\\perp\\!\\!\\!\\perp\\!\\!\\!\\!\\perp\\mathbf{Y}|\\mathbf{Z})\\bar{g}$ , if and only if there exists no path, directed or undirected, between any node in set $\\mathbf{X}$ and any node in set $\\mathbf{Y}$ such that for every collider on the path, either the collider itself or one of its descendants is included in the set $\\mathbf{Z}$ , and no other non-collider nodes on the path are included in the set $\\mathbf{Z}$ . (A collider on a path is a node with both arrows converging, e.g., $B$ is a collider on the path $A B C$ in $A\\rightarrow B\\leftarrow C$ ). ", "page_idx": 12}, {"type": "text", "text": "A.2 Pearl\u2019s Rules of do-Calculus ([22]): ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Let $\\mathcal{G}$ represent the causal DAG, and let $P$ denote the probability distribution induced by the corresponding causal model. For any disjoint subsets of variables $\\mathbf{X},\\mathbf{Y},\\mathbf{Z}$ , and $\\mathbf{W}$ , the following rules apply: ", "page_idx": 12}, {"type": "text", "text": "Rule 1: (Insertion/deletion of observations): ", "page_idx": 12}, {"type": "equation", "text": "$$\nP(\\mathbf{y}|d o(\\mathbf{x}),\\mathbf{z},\\mathbf{w})=P(\\mathbf{y}|d o(\\mathbf{x}),\\mathbf{w})\\quad\\mathrm{if}\\quad(\\mathbf{Y}\\perp\\!\\!\\!\\perp\\!\\!\\!d\\mathbf{\\tau}\\mathbf{Z}|\\mathbf{X},\\mathbf{W})_{\\mathcal{G}_{\\overline{{\\mathbf{X}}}}}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Rule 2: (Action/observation exchange): ", "page_idx": 12}, {"type": "equation", "text": "$$\nP(\\mathbf{y}|d o(\\mathbf{x}),d o(\\mathbf{z}),\\mathbf{w})=P(\\mathbf{y}|d o(\\mathbf{x}),\\mathbf{z},\\mathbf{w})\\quad\\mathrm{if}\\quad(\\mathbf{Y}\\perp_{d}\\mathbf{Z}|\\mathbf{X},\\mathbf{w})_{\\mathcal{G}_{\\overline{{\\mathbf{x}}}_{\\mathbf{Z}}}}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Rule 3: (Insertion/deletion of actions): ", "page_idx": 12}, {"type": "equation", "text": "$$\nP(\\mathbf{y}|d o(\\mathbf{x}),d o(\\mathbf{z}),\\mathbf{w})=P(\\mathbf{y}|d o(\\mathbf{x}),\\mathbf{w})\\quad\\mathrm{if}\\quad(\\mathbf{Y}\\perp\\!\\!\\perp d\\mathbf{\\Omega}\\mathbf{Z}|\\mathbf{X},\\mathbf{w})_{\\mathcal{G}_{\\overline{{\\mathbf{X}}},\\overline{{\\mathbf{z}}}(\\mathbf{w})}},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\mathbf{Z}(\\mathbf{W})$ is the set of nodes in $\\mathbf{Z}$ that are not ancestors of any of the nodes in $\\mathbf{W}$ in the graph $\\mathcal{G}_{\\overline{{\\mathbf{X}}}}$ . ", "page_idx": 12}, {"type": "text", "text": "A.3 Function to Detect Presence of Latent Confounder: ", "page_idx": 12}, {"type": "table", "img_path": "uM3rQ14iex/tmp/003c8741e908965bc272fbe495a2d59799e3aa193c380d7a2c73445413ed457a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "text", "text": "A.4 Proof of Lemma 3.2: ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Lemma. 3.2: It is necessary to learn/detect the latent confounders between reward node $Y$ and any node $X\\in\\mathsf{A n}(Y)$ in causal graph $\\mathcal{G}$ to learn all the POMISs correctly and hence avoid linear regret. ", "page_idx": 12}, {"type": "text", "text": "Before proceeding to the proof, we recall an important result from [5]: For a causal graph $\\mathcal{G}$ with reward variable $Y$ , $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ is a POMIS for any $\\mathbf{W}\\subseteq\\mathbf{V}\\setminus Y$ . ", "page_idx": 12}, {"type": "text", "text": "Proof: Consider a causal graph $\\mathcal{G}(\\mathbf{V},\\mathbf{E})$ with a node $X\\,\\in\\,{\\mathsf{A n}}(Y)$ such that there exists a latent confounder between $X$ and the reward $Y$ . Suppose we do not detect the presence of the confounder and have access to another causal graph $\\mathcal{G}^{\\prime}$ with everything the same as $\\mathcal{G}$ except that there is no confounder between $X$ and $Y$ . We show that there exists one such POMIS that we cannot learn from $\\mathcal{G}^{\\prime}$ , which actually exists in the true causal graph $\\mathcal{G}$ . To prove this, consider a set of nodes $\\mathbf{W}=\\mathsf{P}\\mathsf{a}(X)\\cup\\mathsf{C h}(\\mathsf{P}\\mathsf{a}(X))\\cup\\mathsf{C C}(X)\\setminus\\{X,Y\\}$ . For the graph $\\mathcal{G}^{\\prime}$ , note that $X\\not\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{w}}},Y)$ , and also there $\\nexists Z\\in\\mathsf{C h}(\\mathsf{P a}(X))\\setminus\\{X\\}$ s.t. $Z^{'}\\in\\mathbf{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{\\sigma}}}_{\\mathbf{\\overline{{W}}}},Y)$ . This implies that $\\nexists Z\\in\\Dot{\\mathsf{P a}}(X)$ s.t. $Z\\in\\operatorname{IB}({\\mathcal{G}}^{\\prime}{\\_{\\overline{{\\mathbf{W}}}}},Y)$ . However, for the true graph $\\mathcal{G}$ , we have a different $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ for the same definition of $\\mathbf{W}$ because it contains the bi-directed edge between $X$ and $Y$ , which implies that $X\\in\\operatorname{MUCT}(\\mathcal G_{\\overline{{\\mathbf{W}}}},Y)$ , and as a result, $\\mathsf{P a}(X)\\subseteq\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},\\mathbf{\\bar{\\boldsymbol{Y}}})$ . Also, in the case $\\mathsf{P}\\mathsf{a}(X)=\\emptyset$ , we have a different POMIS. On this side, note that $X\\not\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{\\Pi}}}_{\\overline{{\\mathbf{W}}}},Y)$ , which implies that along the causal path from $X$ to $Y$ , there must be one node $Z$ such that $Z^{'}{\\overset{\\underset{\\bullet}{\\mathbf{Y}}}{\\in}}\\operatorname{MUCT}({\\mathcal{G}^{\\prime}}_{\\overline{{\\mathbf{W}}}},{\\overset{\\dag}{Y}})$ , which implies either $X$ or one of its descendants on the path from $X$ to $Y$ is in $\\operatorname{IB}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}}}},Y)$ , which is not the case for $\\mathcal{G}$ since $X\\in\\operatorname{MUCT}(\\mathcal G_{\\overline{{\\mathbf{W}}}},Y)$ . Thus, we have different interventional boundary or POMIS for the two causal graphs $\\mathcal{G}$ and $\\scriptstyle{\\dot{\\mathcal{G}}}^{\\prime}$ given the above choice of $\\mathbf{W}$ , even if $X$ has no parents. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "The next step is to show that the particular POMIS $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ cannot be learned from the DAG $\\mathcal{G}^{\\prime}$ , i.e., $\\mathrm{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},\\overline{{Y}})\\neq\\mathrm{IB}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}^{\\prime}}}},Y)$ for any ${\\mathbf W}^{\\prime}\\subseteq{\\mathbf V}$ . We need to show this because of the graphical characterization of POMISs in Lemma 3.1. Using the definition of $\\mathbf{W}$ , note that $\\mathsf{P a}(X)\\subseteq\\operatorname{IB}(\\mathcal G_{\\overline{{\\mathbf{W}}}},Y)$ and for all $Z\\in{\\mathsf{C h}}({\\mathsf{P a}}(X))\\backslash\\{X\\}$ , there exists either $Z\\in\\operatorname{I\\!B}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ or $\\mathsf{D e}(Z)\\backslash\\{Y\\}\\in\\mathrm{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{\\cdot\\cdot},Y)$ Also, if there are such nodes in ${\\mathsf{C C}}(X)\\setminus\\{X,Y\\}$ which do not have a path to $X$ comprised of directed edges only, call such set of nodes $T$ . If $T\\ \\neq\\ \\phi$ , then for all $t\\ \\in\\ T$ , we have either $t\\,\\in\\,\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ or ${\\sf D e}(t)\\,\\setminus\\,\\{Y\\}\\,\\in\\,{\\sf I B}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ . Also, note that $\\nexists Z\\;\\in\\;\\mathsf{D e}(X)\\cup\\{X\\}$ such that $Z\\;\\in\\;\\mathrm{IB}(\\dot{\\mathcal{G}}_{\\overline{{\\mathbf{W}}}},Y)$ . Now consider DAG $\\mathcal{G^{\\prime}}$ with the bi-directed edge between $X$ and $Y$ missing. Assume by contradiction $\\exists\\mathbf{W}^{\\prime}\\subseteq\\mathbf{V}$ such that $\\mathrm{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)=\\mathrm{IB}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}^{\\prime}}}},Y)$ . This, however, using the aforementioned characterization of $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ implies that $\\nexists Z\\in\\mathsf{C h}(\\mathsf{P a}(X))\\setminus\\{X\\}$ such that $Z\\in\\mathrm{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{w}}},Y)$ and also $\\nexists t\\in T$ such that $t\\in\\mathbf{MUCT}(\\mathcal{G}^{\\prime}\\overline{{\\mathbf{w}^{\\prime}}},Y)$ using the aforementioned definition of $T$ . However, note that we need $\\mathsf{P a}(X)\\subseteq\\operatorname{IB}(\\mathcal G^{\\prime}\\!\\frac{}{\\mathbf{W}^{\\prime}},\\dot{Y})$ , which under the given choice of $\\mathbf{W}$ is only possible when $X\\,\\in\\,{\\mathrm{MUCT}}({\\mathcal{G}^{\\prime}}_{\\mathbf{W}^{\\prime}},Y)$ , which would require is a bi-directed edge between $X$ and $Y$ in the DAG $\\mathcal{G}^{\\prime}$ , which is a contradiction. Also, for the case when $\\mathsf{P a}(X)=\\bar{\\phi}$ , we have a contradiction because we require the following to be true: $\\nexists Z\\in\\mathsf{D e}(X)\\cup\\{X\\}$ such that $Z\\in\\operatorname{I\\!B}(\\mathcal{G}^{\\prime}\\!\\frac{}{\\mathbf{W}^{\\prime}},Y)$ . For the given choice of $\\mathbf{W}$ , it implies that there is a bi-directed edge between $X$ and $Y$ in the DAG $\\mathcal{G}^{\\prime}$ , which is again a contradiction. Thus, by contradiction, we show that $\\nexists\\mathbf{W}^{\\prime}\\subseteq\\mathbf{V}$ such that $\\mathcal{G}^{\\prime}$ , i.e., $\\mathrm{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)\\neq\\mathrm{IB}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}^{\\prime}}}},Y)$ . This implies that we will miss at least one POMIS if we do not learn or detect latent confounders between the reward node $Y$ and any node $X\\in\\mathsf{A n}(Y)$ , and may incur linear regret. This completes the proof of Lemma 3.2. ", "page_idx": 13}, {"type": "text", "text": "A.5 Proof of Theorem 3.1: ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Before proving Theorem 3.1, we state and prove another Lemma. We then extend this Lemma to prove Theorem 3.1. ", "page_idx": 13}, {"type": "text", "text": "Lemma A.1. Consider a causal graph $\\mathcal{G}(V,E)$ and another graph $\\mathcal{G}^{\\prime}$ such that they have the same vertex set and directed edges but differ in bidirected edges, with the bidirected edges in $\\mathcal{G}^{\\prime}$ being a subset of the bidirected edges in $\\mathcal{G}$ . The graphs will yield different collections of POMISs if there exists some $Z\\in\\mathsf{A n}(Y)$ such that either (a) or $(b)$ is true: ", "page_idx": 13}, {"type": "text", "text": "(a) There is a bi-directed edge between $Z$ and $Y$ in $\\mathcal{G}$ but not in $\\mathcal{G}^{\\prime}$ (b) Neither of the graphs $\\mathcal{G}^{\\prime}$ and $\\mathcal{G}$ have a bidirected edge between $Z$ and $Y$ , and there exists $a$ bidirected edge in $\\mathcal{G}$ between some $X\\in M U C T(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z)}},\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})}^{\\prime}\\:,Y)$ and $Z$ but not in $\\mathcal{G}^{\\prime}$ . ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Proof: The first half of Lemma A.1, i.e., \"The graphs will yield different collections of POMISs if there exists some $Z\\,\\in\\,{\\mathsf{A n}}(Y)$ such that there is a bi-directed edge between $Z$ and $Y$ in $\\mathcal{G}$ but not in $\\mathcal{G}^{\\prime}$ ,\" is the same as Lemma 3.2, and the same proof applies here. The reason is that in graph $\\mathcal{G}^{\\prime}$ , we miss a latent variable between reward and one of its ancestors, which was actually present in the true graph $\\mathcal{G}$ . We only need to proof the second half of Lemma A.1 i.e. graphs will yield different collections of POMISs if there exists some $Z\\,\\in\\,{\\mathsf{A n}}(Y)$ such that (b) is true. Consider a causal graph $\\mathcal{G}(\\mathbf{V},\\mathbf{E})$ and another DAG $\\mathcal{G}^{\\prime}$ such that they have the same vertex set and directed edges, but differ in bi-directed edges. Consider a causal graph $\\mathcal{G}(\\mathbf{V},\\mathbf{E})$ and another DAG $\\mathcal{G}^{\\prime}$ such that they have the same vertex set and directed edges, but differ in bi-directed edges. We show that if neither of the graphs $\\mathcal{G}^{\\prime}$ and $\\mathcal{G}$ have a bidirected edge between $Z$ and $Y$ , and there exists a bidirected edge in $\\mathcal{G}$ between some $X\\in\\mathbf{MUCT}(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z),\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})}}}^{\\prime}\\ ,Y)$ G\u2032Pa(Z),Bi(Z,G\u2032) , Y ) and Z, then there exists one such POMIS that we cannot learn from $\\mathcal{G}^{\\prime}$ , which actually exists in the true causal graph $\\mathcal{G}$ . To prove this, consider a set of nodes $\\mathbf{W}=\\mathsf{P a}(Z)\\cup\\mathsf{C h}(\\mathsf{P a}(Z)\\setminus\\mathsf{A n}(X))\\cup\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})\\setminus\\{\\bar{X},\\bar{Z},Y\\}$ . For the graph $\\mathcal{G}^{\\prime}$ , note that $Z\\not\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\overline{{\\mathbf{w}}},Y)$ , and also there $\\nexists N\\in{\\mathsf{C h}}({\\mathsf{P a}}(Z)\\setminus{\\mathsf{A n}}(X))\\setminus\\{Z\\}$ s.t. $N\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{w}}},Y)$ . This implies that $\\nexists N\\in\\mathsf{P a}(Z)\\setminus\\mathsf{A n}(X)$ s.t. $N\\in\\operatorname{IB}(\\mathcal{G}^{\\prime}\\overline{{\\mathbf{w}}},Y)$ . However, for the true graph $\\mathcal{G}$ , we have a different $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ for the same definition of W because it contains the bi-directed edge between $X$ and $Z$ , which implies that $Z\\in\\operatorname{MUCT}(\\mathcal G_{\\overline{{\\mathbf{W}}}},Y)$ , and as a result, $\\mathsf{P a}(Z)\\setminus\\mathsf{A n}(X)\\subseteq\\Pi\\mathsf{B}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ . Also, in the case $\\bar{\\mathsf{P a}}(Z)\\setminus\\mathsf{A n}(X)=\\emptyset$ , we have different a POMIS. On this side, note that $\\ddot{Z}\\,\\notin\\,\\operatorname{MUCT}(\\mathcal{G}^{\\prime}_{\\overline{{\\mathbf{W}}}},Y)$ , which implies that along the causal path from $Z$ to $Y$ , there must be one node $N$ such that $\\bar{N}\\in\\operatorname{MUCT}(\\bar{\\mathcal G}^{\\prime}\\underline{{\\mathbf{w}}},Y)$ , which implies either $Z$ or one of its descendants on the path from $Z$ to $Y$ is in $\\mathrm{I}\\mathbf{B}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}}}},\\dot{Y})$ , which is not the case for $\\mathcal{G}$ since $Z\\in\\operatorname{MUCT}(\\mathcal G_{\\overline{{\\mathbf{W}}}},Y)$ . Thus, we have different interventional boundary or POMIS for the two causal graphs $\\mathcal{G}$ and $\\dot{g^{\\prime}}$ given the above choice of $\\mathbf{W}$ . ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "The next step is to show that the particular POMIS $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ cannot be learned from the DAG $\\mathcal{G}^{\\prime}$ , i.e., $\\mathrm{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},\\overline{{Y}})\\neq\\mathrm{IB}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}^{\\prime}}}},Y)$ for any ${\\mathbf W}^{\\prime}\\subseteq{\\mathbf V}$ . We need to show this because of the graphical characterization of POMISs in Lemma 3.1. Using the definition of $\\mathbf{W}$ , note that $\\mathsf{P a}(Z)\\setminus\\mathsf{A n}(X)\\subseteq$ $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ and for all $N\\,\\in\\,{\\mathsf{C h}}({\\mathsf{P a}}(Z)\\setminus{\\mathsf{A n}}(X))\\setminus{\\{Z\\}}$ , there exists either $N\\,\\in\\,{\\mathrm{IB}}({\\mathcal G}_{\\overline{{\\mathbf{W}}}},Y)$ or $\\mathsf{D e}(\\dot{N})\\backslash\\{\\dot{Y}\\}\\in\\mathrm{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ . Also, if there are such nodes in $\\mathsf{B i}(Z,{\\mathcal G}^{\\prime})\\backslash\\{X,Z,Y\\}$ which do not have a path to $Z$ comprising of directed edges only, call such set of nodes $T$ . If $T\\neq\\phi$ , then for all $t\\in T$ , we have either $t\\in\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ or $\\mathsf{D e}(t)\\backslash\\{Y\\}\\in\\mathbf{IB}(\\mathcal G_{\\overline{{\\mathbf{W}}}},Y)$ . Also, note that $\\nexists N\\in\\mathsf{D e}(Z)\\cup\\{Z\\}$ such that $N\\in\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}^{\\prime}}}},Y)$ . Now consider the DAG $\\mathcal{G}^{\\prime}$ with the bi-directed edge between $Z$ and $Y$ missing. Assume by contradiction $\\exists\\mathbf{W}^{\\prime}\\subseteq\\mathbf{V}$ such that $\\mathrm{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)=\\mathrm{IB}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}^{\\prime}}}},\\bar{Y})$ . This, however, using the aforementioned characterization of $\\operatorname{IB}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ implies that $\\nexists N\\in\\dot{\\mathsf{C h}}(\\mathsf{P a}(Z)\\setminus\\mathsf{A n}(X))\\setminus\\{Z\\}$ such that $N\\in\\mathbf{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{w}}},Y)$ and also $\\nexists t\\in T$ such that $t\\in\\mathbf{MUCT}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}^{\\prime}}}},Y)$ for the aforementioned definition of $T$ . However, note that we need $\\mathsf{P a}(Z)\\setminus\\mathsf{A n}(X)\\subseteq\\mathsf{I B}(\\mathcal{G^{\\prime}}_{\\overline{{\\mathbf{W}^{\\prime}}}},Y)$ , which under the given choice of $\\mathbf{W}$ is only possible when $Z\\in\\mathrm{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{w}^{\\prime}}},Y)$ , which would require a bi-directed edge between $Z$ and $X$ in the DAG $\\mathcal{G}^{\\prime}$ , which is a contradiction. Also, for the case when $\\mathsf{P a}(Z)=\\phi$ , we have a contradiction because we require the following to be true: $\\sharp N\\in\\mathsf{D e}(Z)\\cup\\{\\dot{Z}\\}$ such that $N\\in\\operatorname{IB}(\\mathcal{G}^{\\prime}\\frac{}{\\mathbf{W}^{\\prime}},Y)$ . For the given choice of $\\mathbf{W}$ , it implies that there is a bi-directed edge between $Z$ and $X$ in the DAG $\\mathcal{G}^{\\prime}$ , which is again a contradiction. Thus, by contradiction, we show that $\\nexists\\mathbf{W}^{\\prime}\\subseteq\\mathbf{V}$ such that $\\mathcal{G}^{\\prime}$ , i.e., $\\mathrm{IB}(\\mathcal{G}_{\\mathbf{\\overline{{W}}}},Y)\\ne\\mathrm{IB}(\\mathcal{G^{\\prime}}_{\\mathbf{\\overline{{W^{\\prime}}}}},Y)$ . This implies that we miss atleast one POMIS when either of statements (a) and (b) hold. This completes the proof of Lemma A.1. ", "page_idx": 14}, {"type": "text", "text": "We now proceed to the formal proof for Theorem 3.1: ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Theorem. 3.1: Consider a causal graph $\\mathcal{G}(V,E)$ and another $D A G\\,\\mathcal{G}^{\\prime}$ such that they have the same vertex set and directed edges but differ in bidirected edges, with the bidirected edges in $\\mathcal{G}^{\\prime}$ being $a$ subset of the bidirected edges in $\\mathcal{G}$ . The graphs will yield different collections of POMISs if and only if there exists some $Z\\in\\mathsf{A n}(Y)$ such that either (a) or $(b)$ is true: ", "page_idx": 14}, {"type": "text", "text": "(a) There is a bi-directed edge between $Z$ and $Y$ in $\\mathcal{G}$ but not in $\\mathcal{G}^{\\prime}$ . ", "page_idx": 14}, {"type": "text", "text": "(b) Neither of the graphs $\\mathcal{G}^{\\prime}$ and $\\mathcal{G}$ have a bidirected edge between $Z$ and $Y$ , and there exists $a$ bidirected edge in $\\mathcal{G}$ between some $X\\in M U C T(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z)}},\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})}^{\\prime}\\:,Y)$ and $Z$ but not in $\\mathcal{G}^{\\prime}$ . ", "page_idx": 14}, {"type": "text", "text": "Proof: One direction for Theorem 3.1 is proved already in Lemma A.1. We only to need to prove the other direction which is that two causal graphs $\\mathcal{G}$ and $\\mathcal{G}^{\\prime}$ such that they have the same vertex set and directed edges, but differ in bi-directed edges will yield same collections POMISs when neither of statements (a) and (b) is true. Note when neither of (a) or (b) is true the graphs $\\mathcal{G}$ and $\\mathcal{G}^{\\prime}$ might still have a different set of bi-directed edges. We will have two possible scenarios here. Suppose $\\mathcal{G}$ has a bi-directed edge between some $Z\\in\\mathsf{A n}(Y)$ and some $X\\in\\mathsf{A n}(Y)$ , such that there is a bi-directed edge between pair of vertices $(Z,Y)$ and $(X,Y)$ in both the graphs and the bi-directed edge between $X$ and $Z$ is absent in $\\mathcal{G}^{\\prime}$ . Further, assume neither of statements (a) and (b) hold. In this case, despite the absence of a bi-directed edge between $X$ and $Z$ in $\\mathcal{G}^{\\prime}$ , the graphs will yield the same set of POMISs. This is because $Z\\not\\in M U C T(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ for some set of nodes $\\mathbf{W}$ only when $Z\\in\\mathbf{W}$ , and the same is the case for $\\mathcal{G}$ because they share a bi-directed edge between $Z$ and $Y$ . By symmetry, we have the argument hold for $X$ as well. So, the presence or absence of bi-directed edges between $X$ and $Z$ does not change the set of POMISs learned from the graph when both $X$ and $Z$ are confounded with reward $Y$ already. Thus, we can delete all such bi-directed edges one by one from $\\mathcal{G}$ while the set of POMISs learned from each of the intermediate causal graphs stays the same. Consider the second scenario, where $\\mathcal{G}$ has bi-directed edges between a node $Z\\in\\mathsf{A n}(Y)$ , such that there is no bi-directed edge between $Z$ and $Y$ in both graphs $\\mathcal{G}$ and $\\mathcal{G}^{\\prime}$ ) and a node $X$ that has the following characteristics: $X^{'}\\!\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\!_{\\mathbf{\\overline{{W}}}},Y)$ for some set $\\mathbf{W}\\subseteq\\mathbf{V}$ but $X\\not\\in\\operatorname{MUCT}(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z)}},\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})}^{\\prime}\\ ,Y)$ . However, the bi-directed edge between $X$ and $Z$ is absent in $\\mathcal{G}^{\\prime}$ . Further, assume neither of statements (a) and (b) hold. The condition $X\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\mathbf{\\overline{{w}}},Y)$ but $X\\not\\in\\mathrm{MUCT}(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z)}},\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})}^{\\prime}\\:,Y)$ (G\u2032Pa(Z),Bi(Z,G\u2032) , Y ) implies that either $\\exists N\\in\\mathsf{P a}(Z)$ such that $N\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{w}}},Y)$ or $\\exists N\\in\\mathsf{B i}(Z,\\mathcal{G}^{\\prime})$ such that $N\\in\\operatorname{MUCT}(\\mathcal{G}^{\\prime}\\underline{{\\mathbf{w}}},Y)$ . Since bi-directed edges in $\\mathcal{G}^{\\prime}$ are a subset of bi-directed edges in $\\mathcal{G}$ , we have: Either $\\exists N\\in\\ensuremath{\\dot{\\mathsf{P}}}\\mathsf{a}(Z)$ such that $N\\,\\in\\,{\\mathbf{M}}\\mathrm{UCT}({\\mathcal{G}}_{\\overline{{\\mathbf{W}}}},Y)$ or $\\exists N\\;\\in\\;{\\mathsf{B i}}(Z,{\\mathcal G})$ such that $N\\,\\in\\,{\\mathbf{M}}\\mathrm{UCT}({\\mathcal{G}}_{\\overline{{\\mathbf{W}}}},Y)$ . Note that any MUCT is closed under the $\\mathsf{D e}(.)$ and ${\\mathsf{C C}}(.)$ operations, i.e., for any MUCT, say $\\mathbf{T}$ , we have $\\mathsf{D e}(\\mathbf{T})=\\mathbf{T}$ and $\\mathsf{C C}(\\mathbf{T})=\\mathbf{T}$ . if $\\exists N\\in\\mathsf{P a}(Z)$ such that $N\\in\\mathbf{MUCT}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ or $\\exists N\\in\\mathsf{B i}(Z,\\mathcal{G})$ such that $N\\;\\in\\;{\\mathrm{MUCT}}({\\mathcal{G}}_{\\overline{{\\mathbf{W}}}},Y)$ , we already have $Z\\;\\in\\;{\\mathrm{MUCT}}({\\mathcal{G}}_{\\overline{{\\mathbf{W}}}},Y)$ using the definition of MUCT. The bi-directed edge between $X$ and $Z$ will play a role only when $\\texttt{\\small f N}\\in\\mathsf{P a}(Z)$ such that $N\\,\\in\\,\\mathbf{MUCT}(\\mathcal G_{\\overline{{\\mathbf{W}}}},Y)$ and $\\nexists N\\;\\in\\;\\mathsf{B i}(Z,\\mathcal{G})$ such that $N\\;\\in\\;\\mathrm{MUCT}({\\mathcal G}_{\\overline{{\\mathbf{W}}}},Y)$ for any choice of W. Recall that the given condition $X\\in\\operatorname{MUCT}(\\mathcal{G}_{\\mathbf{\\overline{{W}}}}^{\\prime},Y)$ but $X\\,\\notin\\,{\\tt M U\\ddot{C}T}({\\mathcal G}_{\\overline{{{\\tt P a}}}(Z),{\\tt B i}(Z,{\\mathcal G}^{\\prime})}^{\\prime},Y)$ already implies that either $\\exists N\\in\\mathsf{P a}(Z)$ such that $N\\in\\mathbf{MUCT}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ or $\\exists N\\in\\mathsf{B i}(Z,\\mathcal{G})$ such that $N\\in\\mathbf{MUCT}(\\mathcal{G}_{\\overline{{\\mathbf{W}}}},Y)$ . Thus absence or presence of bi-directed edge between $X$ and $Z$ will have no effect on POMISs learned from graph $\\mathcal{G}$ in this scenario as well. Combining both of the scenarios when neither of the conditions of (a) and (b) hold, all other bi-directed edges from $\\mathcal{G}$ , which are absent in $\\mathcal{G}^{\\prime}$ , can be removed one by one from $\\mathcal{G}$ while keeping the POMISs learned from both the intermediate graphs the same. Since $\\mathcal{G}$ and $\\mathcal{G}^{\\prime}$ only differ in bi-directed edges, with bi-directed edges in $\\mathcal{G}^{\\prime}$ being a subset of those in $\\mathcal{G}$ , eventually both graphs will become identical, which proves the statement: Two graphs $\\mathcal{G}$ and $\\mathcal{G}^{\\prime}$ will have the same POMISs if neither of the statements (a) or (b) hold true. This completes the proof of the Theorem 3.1. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "A.6 Proof of Lemma 4.1: ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Consider a causal graph $\\mathcal{G}(\\mathbf{V},\\mathbf{E})$ and $\\mathbf{W}\\subseteq\\mathbf{V}$ . Furthermore, let $X,T\\in\\mathbf{V}\\setminus\\mathbf{W}$ be any two variables. Fix some realization $\\mathbf{w}\\in[K]^{|\\mathbf{W}|}$ . Under post interventional faithfulness Assumption 2.1 we want to prove: $(X\\in\\mathsf{A n}(T))_{\\mathcal{G}_{\\overline{{\\mathbf{w}}}}}\\ \\Longleftrightarrow\\ P(t|d o(\\mathbf{w}))\\neq P(t|d o(\\mathbf{w}),d o(x))$ for some $x,t\\in[K]$ . ", "page_idx": 15}, {"type": "text", "text": "Forward Direction $(\\implies)$ : $(X\\in\\mathsf{A n}(T))_{\\mathcal{G}_{\\overline{{\\mathbf{w}}}}}\\implies P(t|d o(\\mathbf{w}))\\neq P(t|d o(\\mathbf{w}$ ), do(x)) for some $x,t\\in[K]$ . By contradiction, assume $P(t|d o(\\mathbf{w}))=P(t|d o(\\mathbf{w}),d o(x)),\\forall x,t\\in[K]$ . This implies that $P\\bar{(}t|\\bar{d}o(\\dot{\\mathbf{w}}),d o(x))\\,=\\,P(t|d o(\\mathbf{w}))\\,=$ some function of only $t$ and w. This implies that for the sub-model $\\mathcal{M}_{\\mathbf{W},X}$ the following $\\mathrm{CI}$ statements holds: $(T\\,\\bot\\!\\!\\!\\mid\\,X)_{\\mathcal{M}\\mathbf{w},X}$ . However, note that if $(X\\in\\mathsf{A n}(T))_{\\mathcal{G}_{\\overline{{\\mathbf{w}}}}}$ , then we still have $(X\\in\\mathsf{A n}(T))_{\\mathcal G_{\\overline{{\\mathbf{w}}},X}}$ . This implies there is a directed path from $X$ to $T$ in the post-interventional graph $\\mathcal{G}_{\\overline{{\\mathbf{W},X}}}$ . Therefore, we have: $(T\\not\\perp_{d}X)_{\\mathcal{G}_{\\overline{{\\mathbf{w}}},X}}$ . Note that under the post interventional faithfulness Assumption 2.1, the CI statement $(T\\perp X)_{\\mathcal{M}_{\\mathbf{w},X}}$ can hold only if the $d\\!\\cdot$ -separation statement holds $(T\\ \\perp\\ L\\ d\\ S)_{\\overline{{{\\cal S}_{{\\bf W},X}}}}$ , which is clearly a contradiction. This completes the proof for the forward direction. ", "page_idx": 15}, {"type": "text", "text": "Reverse Direction $(\\iff)$ : $(X~\\in~\\mathsf{A}\\mathsf{n}(T))_{\\mathcal{G}_{\\overline{{\\mathbf{w}}}}}~~\\Longleftarrow~~P(t|d o(\\mathbf{w}))~\\neq~P(t|d o(\\mathbf{w}),d o(x))$ for some $\\boldsymbol{x},t\\,\\in\\,[K]$ . We prove the contrapositive statement instead, i.e., $(X\\,\\notin\\,\\mathsf{A n}(T))_{\\mathcal{G}_{\\overline{{\\mathbf{w}}}}}\\quad\\Longrightarrow$ $P(t|d o(\\mathbf{w}))\\,=\\,P(t|d o(\\mathbf{w}),d o(x)),\\,\\forall;$ $\\forall x,t\\,\\in\\,[K]$ . Note that $(X\\notin\\mathsf{A n}(T))\\varsigma_{\\overline{{\\mathbf{w}}}}$ clearly implies that $(X\\not\\in\\mathsf{A n}(T))_{\\mathcal{G}_{\\overline{{\\mathbf{w}}},X}}$ which implies that $(T\\ \\bot\\!\\!L_{d}\\ X)_{{\\mathcal{G}}_{\\overline{{\\mathbf{w}}},X}}$ . Thus, using Rule 3 of Pearl\u2019s do calculus, we have: $P(t|d o(\\mathbf{w}),d o(x))=P(t|d o(\\mathbf{w}))$ , $\\forall x,t\\in[K]$ . This completes the proof of the reverse direction. ", "page_idx": 15}, {"type": "text", "text": "A.7 Proof of Lemma 4.2: ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Consider two variables $X_{i}$ and $X_{j}$ such that $X_{j}\\notin\\mathsf{A n}(X_{i})$ and a set of variables $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus$ $\\{X_{i}\\})\\subseteq\\mathbf{W}$ and $\\boldsymbol{{X}}_{i}~\\boldsymbol{\\&}~\\boldsymbol{{X}}_{j}\\notin\\mathbf{W}$ . Fix some realization $\\mathbf{w}\\in[K]^{|\\mathbf{W}|}$ . Under the post-interventional faithfulness Assumption 2.1 we want to show that: There is latent confounder between $X_{i}$ and $X_{j}$ $\\iff P(x_{j}\\mid d o(x_{i}{\\bar{)}},d o(\\mathbf{W}=\\mathbf{w}))\\neq P(x_{j}\\mid x_{i},d o(\\mathbf{W}=\\mathbf{w}))$ for some realization $x_{i},x_{j}\\in[K]$ . ", "page_idx": 15}, {"type": "text", "text": "Forward Direction $(\\implies)$ : There is latent confounder between $X_{i}$ and $X_{j}$ such that $X_{j}\\not\\in\\mathsf{A n}(X_{i})$ $\\implies P(x_{j}\\mid d o(x_{i}),d o(\\mathbf{W}=\\mathbf{w}))\\neq P(x_{j}\\mid x_{i},d o(\\mathbf{W}=\\mathbf{w}))$ ) for some realization $\\boldsymbol{x}_{i},\\boldsymbol{x}_{j}\\in[K]$ . By contradiction assume $P(x_{j}\\mid d o(x_{i}),d o(\\acute{\\mathbf{W}}=\\mathbf{w}))=P(x_{j}\\mid x_{i},d o(\\mathbf{W}=\\mathbf{w}))\\,\\forall x_{i},x_{j}\\in\\mathop{\\subset}^{\\bullet}[K]$ . Recall that: $X_{j}=f_{j}(\\mathsf{P a}(X_{j}),\\mathbf{U_{j}})$ . Since there is latent confounder between $X_{i}$ and $X_{j}$ call it $L_{i j}$ . Also note that $L_{i j}\\in\\bf{U}_{j}$ . Define $\\mathbf{U_{j}^{\\prime}}:=\\mathbf{U_{j}}\\setminus\\{L_{i,j}\\}$ ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "equation", "text": "$$\nP(x_{j}\\mid d o(x_{i}),d o(\\mathbf{W}))=P(x_{j}\\mid d o(x_{i}),d o(\\mathtt{p a}(X_{i})),d o(\\mathtt{p a}(X_{j})\\setminus\\{x_{i}\\}))\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the interventions $d o(\\mathsf{P a}(X_{i}))$ and $d o(\\mathsf{P a}(X_{j}))$ are consistent with $d o(x_{i})$ and $d o(\\mathbf{W}=\\mathbf{w})$ . The equation 5 holds by the application of Pearl\u2019s do-calculus Rule 3 because, by definition of the set $\\mathbf{W}$ , we have $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq\\mathbf{W}$ and $X_{i},X_{j}\\notin\\mathbf{W}$ . All the extra intervention targets can simply be deleted, and we are left with intervention on $X_{i}$ , ${\\mathsf{P a}}(X_{i})$ , and $\\mathsf{P a}(X_{j})$ . ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle^{\\circ}(x_{j}\\mid d o(x_{i}),d o(\\mathbf{W}))=\\sum_{\\mathbf{u}_{j}^{\\prime},\\ l_{i,j}}P(x_{j}\\mid d o(x_{i}),d o(\\mathbf{pa}(X_{i})),d o(\\mathbf{pa}(X_{j})\\setminus\\{x_{i}\\}),\\mathbf{U}^{\\prime}_{j}=\\mathbf{u}^{\\prime}{}_{j},L_{i j}=l_{i};}\\\\ {\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times P(\\mathbf{U}^{\\prime}_{j}=\\mathbf{u}^{\\prime}{}_{j},L_{i j}=l_{i};}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We have another application of Pearl\u2019s do-calculus Rule 3 because interventions on observed variables don\u2019t affect unobserved variables, as there are no causal/directed paths from observed to unobserved variables. Also we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\nP(x_{j}\\mid x_{i},d o(\\mathbf{W}))=P(x_{j}\\mid x_{i},d o(\\mathbf{pa}(X_{i})),d o(\\mathbf{pa}(X_{j})\\mid\\{x_{i}\\})))\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The equation 7 holds by the application of Pearl\u2019s do-calculus Rule 3 because, by definition of the set $\\mathbf{W}$ , we have $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq\\mathbf{W}$ and $X_{i},X_{j}\\notin\\mathbf{W}$ . All the extra intervention targets can simply be deleted, and we are left with conditioning on $X_{i}=x_{i}$ and interventions on $\\mathsf{P a}(X_{i})$ and ${\\mathsf{P a}}(X_{j})$ . ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P(x_{j}\\mid x_{i},d o(\\mathbf{W}))=\\displaystyle\\sum_{\\mathbf{u}_{j}^{\\prime},\\ l_{i,j}}P(x_{j}\\mid x_{i},d o(\\mathtt{p a}(X_{i})),d o(\\mathtt{p a}(X_{j})\\setminus\\{x_{i}\\}),\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}_{j},L_{i j}=l_{i j})}\\\\ {\\times\\,P(\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}_{j},L_{i j}=l_{i j}|x_{i},d o(\\mathtt{p a}(X_{i})),d o(\\mathtt{p a}(X_{j})\\setminus\\{x_{i}\\})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Using Pearl\u2019s do-calculus Rule 2, we can replace the conditioning $X_{i}=x_{i}$ with the intervention $d o(x_{i})$ in $P(x_{j}\\mid x_{i},d o(\\mathsf{p a}(X_{i})),d o(\\mathsf{p a}(X_{j})\\backslash\\{x_{i}\\}),\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}{}_{j},\\bar{L}_{i j}=l_{i j})$ because $X_{j}\\notin\\mathsf{A n}(X_{i})$ and ${\\mathsf{P a}}(X_{i})$ are already intervened on. Also, the latent confounder $L_{i j}$ is conditioned on, so there is no open backdoor path from $X_{i}$ to $X_{j}$ . Thus, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{\\bf~\\displaystyle^{D}(}x_{j}\\mid x_{i},d o({\\bf W}))=\\displaystyle\\sum_{{\\bf u}_{j}^{\\prime},\\ l_{i,j}}P(x_{j}\\mid d o(x_{i}),d o({\\mathfrak{p a}}(X_{i})),d o({\\mathfrak{p a}}(X_{j})\\setminus\\{x_{i}\\}),\\mathbf{U}_{j}^{\\prime}={\\mathbf{u}}_{j}^{\\prime},L_{i j}=l_{i j})}\\\\ {\\mathrm{\\bf~\\displaystyle~\\qquad~\\qquad~\\qquad~\\times~}P(\\mathbf{U}_{j}^{\\prime}=\\mathbf{u}^{\\prime},L_{i j}=l_{i j}|x_{i},d o({\\mathfrak{p a}}(X_{i})),d o({\\mathfrak{p a}}(X_{j})\\setminus\\{x_{i}\\}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "From the Equations 6 and 9 and assumption $P(x_{j}\\mid d o(x_{i}),d o(\\mathbf{W}=\\mathbf{w}))=P(x_{j}\\mid x_{i},d o(\\mathbf{W}=\\mathbf{w}))$ $\\forall x_{i},x_{j}\\in[K]$ we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle\\sum_{\\mathbf{u}_{j}^{\\prime},\\,l_{i,j}}P(x_{j}\\mid d o(x_{i}),d o(\\mathsf{p a}(X_{i})),d o(\\mathsf{p a}(X_{j})\\setminus\\{x_{i}\\}),\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}_{j},L_{i j}=l_{i j})}\\\\ {{}~~}\\\\ {{<}~~\\displaystyle\\left(P(\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}_{j},L_{i j}=l_{i j}|x_{i},d o(\\mathsf{p a}(X_{i})),d o(\\mathsf{p a}(X_{j})\\setminus\\{x_{i}\\}))-P(\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}_{j},L_{i j}=l_{i j})\\right)=0}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since probabilities are non-negative, whenever $P(x_{j}\\quad|\\quad d o(x_{i}),d o(\\mathsf{p a}(X_{i})),d o(\\mathsf{p a}(X_{j})\\,\\vee\\,\\top$ $\\{x_{i}\\}),\\bar{\\mathbf{U}}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}{}_{j},L_{i j}=l_{i j})>0$ , we must have: ", "page_idx": 16}, {"type": "text", "text": "However, since we know that $L_{i j}$ is a confounder between $X_{i}$ and $X_{j}$ , we have an edge $L_{i j}\\to X_{i}$ in the causal graph, which implies that under any intervention $d o(\\mathbf{Z})$ such that $X_{i}\\notin\\mathbf{Z}$ , we must have $(L_{i j}\\not\\perp X_{i})_{\\mathcal{M}_{\\mathbf{Z}}}$ by interventional faithfulness Assumption 2.1. This implies that there exists a realization $\\boldsymbol{x}_{i}^{*}$ and $l_{i j}^{*}$ such that: ", "page_idx": 17}, {"type": "equation", "text": "$$\nP(\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}{}_{j},L_{i j}=l_{i j}^{*}|x_{i}^{*},d o(\\mathbf{pa}(X_{i})),d o(\\mathbf{pa}(X_{j})\\setminus\\{x_{i}\\}))\\neq P(\\mathbf{U}^{\\prime}{}_{j}=\\mathbf{u}^{\\prime}{}_{j},L_{i j}=l_{i j}^{*})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Now, using the combination $d o(\\mathbf{W}=\\mathbf{w})$ and a special choice of realizations $\\boldsymbol{x}_{i}^{*}$ and $l_{i j}^{*}$ , we must have at least one special realization $\\boldsymbol{x}_{j}^{*}$ such that: $P(x_{j}^{*}\\mid d o(x_{i}^{*}),d o(\\mathsf{P a}(X_{i})),d o(\\mathsf{P a}(X_{j})\\backslash\\{x_{i}\\}),\\mathbf{U}_{j}^{\\prime}=$ $\\mathbf{u}^{\\prime}{}_{j},L_{i j}=l_{i j}^{*})>0$ . Combining this with Equations 12 and 10, we conclude for some $x_{i}^{*},x_{j}^{*}\\in[K]$ , we have $P(\\tilde{x_{j}^{*}}\\mid d o(x_{i}^{*}),d o(\\mathbf{W}=\\mathbf{w}))\\neq P(x_{j}^{*}\\mid x_{i}^{*},d o(\\mathbf{W}=\\mathbf{w}))$ . Thus this leads to contradiction. Thus if there is a latent confounder between $X_{i}$ and $X_{j}\\implies P(x_{j}\\mid d o(x_{i}),d o(\\mathbf{W}=\\mathbf{w}))\\neq P(x_{j}\\mid$ $x_{i},d o(\\mathbf{W}=\\mathbf{w})_{i}$ ) for some realization $x_{i},x_{j}\\in[K]$ . This completes the proof of the forward direction. ", "page_idx": 17}, {"type": "text", "text": "Reverse Direction $(\\Longleftarrow)$ : For a pair of variables $X_{i}$ and $X_{j}$ such that $X_{j}\\notin\\mathsf{A n}(X_{i})$ , if $P(x_{j}\\mid$ $d o(x_{i}),d o(\\mathbf{W}=\\mathbf{w}))\\neq P(x_{j}\\mid x_{i},\\stackrel{\\cdot}{d o}(\\mathbf{W}=\\mathbf{w}))$ ) for some realizations $x_{i},x_{j}\\in[K]$ , then there is a latent confounder between $X_{i}$ and $X_{j}$ . We prove the contrapositive statement instead, i.e., if there is no latent confounder between $X_{i}$ and $X_{j}$ , then $P(x_{j}\\mid d o(x_{i}),d o(\\mathbf{W}=\\mathbf{w}))=P(x_{j}\\mid x_{i},d o(\\mathbf{W}=\\mathbf{w}))$ , $\\forall x_{i},x_{j}\\in[K]$ . Note that by construction, we have: $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq\\mathbf{W}$ . For such choice of set W and the fact that $X_{j}\\not\\in\\mathsf{A n}(X_{i})$ and there is no latent confounder between $X_{i}$ and $X_{j}$ , we have $(X_{j}\\perp\\perp X_{i})\\boldsymbol{\\mathcal{G}}_{X_{i}\\overline{{\\mathbf{w}}}}$ . Thus, from Pearl\u2019s do-calculus Rule 2, we have $P(x_{j}\\mid d o(x_{i}),d o(\\mathbf{W}\\stackrel{\\textstyle<}{=}$ $\\mathbf{w}))=P(x_{j}\\mid x_{i},d o(\\overline{{\\mathbf{W}}}=\\mathbf{w}))$ ), $\\forall x_{i},x_{j}\\in[K]$ . This completes the proof of the reverse direction. ", "page_idx": 17}, {"type": "text", "text": "A.8 Proof of Lemma 4.3: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Suppose that Assumption 4.1 holds and we h2ave access to $\\begin{array}{r l}{m a x(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}})\\log\\frac{2K^{2}}{\\delta_{1}}}\\end{array}$ samples from $d o(X_{i}=x_{i},\\mathbf{W}=\\mathbf{w})\\,\\forall x_{i}\\in[K]$ and $\\frac{8}{\\epsilon^{2}}\\log{\\frac{2K^{2}}{\\delta_{2}}}$ samples from $d o(\\mathbf{W}=\\mathbf{w})$ for a fixed $w\\in[K]^{|\\mathbf{W}|}$ for some $\\mathbf{W}\\subseteq\\mathbf{V}$ . We want to show that with probability at least $1-\\delta_{1}-\\delta_{2}$ , we have the following: ", "page_idx": 17}, {"type": "equation", "text": "$$\n(X_{i}\\in\\mathsf{A n}(X_{j}))_{\\mathcal{G}_{\\mathbb{W}}}\\iff\\exists\\ x_{i},x_{j}\\in[K]\\ s.t.\\ \\big|\\ \\widehat{P}(x_{j}|d o(\\mathbf{w}))-\\widehat{P}(x_{j}|d o(\\mathbf{w}),d o(x_{i}))\\ \\big|>\\frac{\\epsilon}{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Using Hoeffding\u2019s inequality with $A$ samples from intervention $d o(x_{i},\\mathbf{w})$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left|\\hat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\right|\\geq\\sqrt{\\frac{1}{2A}\\log\\frac{2K^{2}}{\\delta_{1}}}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{1}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "If we choose $\\begin{array}{r}{A=m a x(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}})\\log\\frac{2K^{2}}{\\delta_{1}}}\\end{array}$ , we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\right|\\geq\\frac{\\epsilon}{4}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{1}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Similarly, using Hoeffding\u2019s inequality with $B$ samples from intervention $d o(\\mathbf{w})$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left|\\hat{P}(x_{j}|d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))\\right|\\geq\\sqrt{\\frac{1}{2A}\\log\\frac{2K^{2}}{\\delta_{1}}}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{2}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "If we choose B =\u03f582 log 2\u03b4K22 , we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left|\\hat{P}(x_{j}|d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))\\right|\\geq\\frac{\\epsilon}{4}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{2}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since the realization $\\mathbf{w}\\in[K]^{|\\mathbf{W}|}$ is fixed, while $x_{i}$ and $x_{j}$ are in $[K]$ , we have a total of $K^{2}$ possible bad events when the estimates are not accurate. Given the choice of samples, $A$ and $B$ , we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Big|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\Big|\\le\\frac{\\epsilon}{4}\\ \\forall x_{i},x_{j}\\in[K]\\ \\ w.p.\\ a t\\ l e a s t\\ 1-\\delta_{1},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left|\\hat{P}(x_{j}|d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))\\right|\\le\\frac{\\epsilon}{4}\\:\\:\\forall x_{j}\\in[K]\\:\\:\\:w.p.\\;a t\\;l e a s t\\:1-\\delta_{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Under the good event, which occurs with a probability of at least $1-\\delta_{1}-\\delta_{2}$ , the estimates are accurate. We now consider the two possible scenarios. Suppose that $X_{i}\\not\\in\\mathsf{A n}(X_{j})$ in $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}$ . In this case by Pearl\u2019s do-calculus Rule 3 we have $\\boxed{P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))}\\bigg|=0\\ ,\\forall x_{i},x_{j}\\in[K].$ By triangular inequality we have the following: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-\\widehat{P}(x_{j}|d o(\\mathbf{w}))\\bigg|\\leq\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\bigg|+}\\\\ {\\bigg|\\widehat{P}(x_{j}|d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))\\bigg|\\leq\\frac{\\epsilon}{2}~\\forall x_{i},x_{j}\\in[K].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "However, when $X_{i}\\in\\mathsf{A n}(X_{j})$ in $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}$ under Assumption 4.1 we must have some configuration say $x_{i},x_{j}\\in[K]$ for any $\\mathbf{w}\\in[K]^{|\\mathbf{W}|}$ such that $\\boxed{P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))}\\Biggr|>\\epsilon.$ . By triangular inequality when $X_{i}\\in\\mathsf{A n}(X_{j})$ in $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}$ , $\\exists\\;x_{i},x_{j}\\in[K]$ such that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-\\widehat{P}(x_{j}|d o(\\mathbf{w}))\\bigg|\\geq\\bigg|P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))\\bigg|}\\\\ &{\\phantom{=}-\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\bigg|-\\bigg|\\widehat{P}(x_{j}|d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))\\bigg|>\\frac{\\epsilon}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Thus, using Assumption 4.1 with the given choice of number of samples with probability at least $1-\\delta_{1}-\\delta_{2}$ , we have the following result: ", "page_idx": 18}, {"type": "equation", "text": "$$\n(X_{i}\\in\\mathsf{A n}(X_{j}))_{\\mathcal{G}_{\\mathbb{W}}}\\iff\\exists\\ x_{i},x_{j}\\in[K]\\ s.t.\\ \\big|\\ \\widehat{P}(x_{j}|d o(\\mathbf{w}))-\\widehat{P}(x_{j}|d o(\\mathbf{w}),d o(x_{i}))\\ \\big|>\\frac{\\epsilon}{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This completes the proof for Lemma 4.3. ", "page_idx": 18}, {"type": "text", "text": "A.9 Proof of Lemma 4.4: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In order to prove that Algorithm 1 learns the true transitive closure under any intervention, i.e., $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ , we recall from the proof of Lemma 4.3 that the test for ancestrality works with high probability under the event that the causal effects of the form $P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))$ and $P(x_{j}|d o(\\mathbf{w}))$ are estimated accurately with an error of at most $\\frac{\\epsilon}{4}$ for all $x_{i},x_{j}\\,\\in\\,[K]$ and any fixed $\\mathbf{w}\\in[K]^{\\mathbf{W}}$ . Now, since Algorithm 1 takes $\\begin{array}{r}{B=\\frac{8}{\\epsilon^{2}}\\log\\frac{2n K^{2}}{\\delta_{2}}}\\end{array}$ samples from $d o(\\mathbf{W}=\\mathbf{w})$ and $\\begin{array}{r}{A=\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{2n K^{2}}{\\delta_{1}}}\\end{array}$ samples from every $d o(X_{i}=x_{i},\\mathbf{W}=\\mathbf{w})$ for all $X_{i}\\in\\mathbf{V}\\setminus\\mathbf{W}$ and for all $x_{i}\\in[K]$ , the total number of intervention samples collected is clearly at most $K A n+B$ . In order to show that Algorithm 1 learns the true transitive closure under any intervention, i.e., $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ , with high probability, we must demonstrate that Algorithm 1 can estimate all causal effects with a maximum error of $\\frac{\\epsilon}{4}$ with high probability, so that all the ancestrality tests work with high probability, as implied by the proof of Lemma 4.3. ", "page_idx": 18}, {"type": "text", "text": "Using Hoeffding\u2019s inequality with $\\begin{array}{r}{B=\\frac{8}{\\epsilon^{2}}\\log\\frac{2n K^{2}}{\\delta_{2}}}\\end{array}$ samples from the intervention $d o(\\mathbf{w})$ , we have for any $X_{j}\\in\\mathbf{V}\\setminus\\mathbf{W}$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left|{\\hat{P}}(x_{j}|d o(\\mathbf{w}))-P(x_{j}|d o(\\mathbf{w}))\\right|\\le{\\frac{\\epsilon}{4}}~\\forall x_{j}\\in[K]~{\\boldsymbol{w}}.p.~a t\\,l e a s t\\,1-{\\frac{\\delta_{2}}{n}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Using the union bound we have the following: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\boxed{\\hat{P}(X_{j}=x_{j}|d o(\\mathbf{w}))-P(X_{j}=x_{j}|d o(\\mathbf{w}))}\\bigg|\\le\\frac{\\epsilon}{4}\\:\\:\\forall x_{j}\\in[K]\\;,\\:\\forall X_{j}\\in\\mathbf{V}\\backslash\\mathbf{W}\\:\\:w.p.\\:a t\\:l e a s t\\:1-\\delta_{2}.}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Now, consider a fixed pair $X_{i},X_{j}\\in\\mathbf{V}\\setminus\\mathbf{W}.$ , and using $\\begin{array}{r}{A=\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{2n K^{2}}{\\delta_{1}}}\\end{array}$ samples from the intervention $d o(x_{i},\\mathbf{w})$ for every $x_{i}\\in[K]$ , we have the following using Hoeffding\u2019s inequality: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left|\\hat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\right|\\le\\operatorname*{min}(\\frac{\\epsilon}{4},\\frac{\\gamma}{4})\\,\\,\\,\\forall x_{i},x_{j}\\in[K]\\,\\,\\,w.p.\\,\\,a t\\,l e a s t\\,1-\\frac{\\delta_{\\eta}}{n}\\,.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Using the union bound we have the following: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\hat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\bigg|\\le\\operatorname*{min}(\\frac{\\epsilon}{4},\\frac{\\gamma}{4})}&{}\\\\ {\\forall x_{i},x_{j}\\in[K]\\ ,\\ \\forall X_{j}\\in\\mathbf{V}\\ \\backslash\\ (\\mathbf{W}\\cup\\{X_{i}\\})\\ \\ w.p.\\ a t\\ l e a s t\\ 1-\\delta_{1}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Again using the union bound over all intervention targets $X_{i}\\in\\mathbf{V}$ we have the following: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\bigg|\\le\\operatorname*{min}(\\frac{\\epsilon}{4},\\frac{\\gamma}{4})}\\\\ &{\\qquad\\qquad\\qquad\\forall x_{i},x_{j}\\in[K]\\ ,\\ \\forall X_{i}\\in{\\mathbf{V}}\\ \\backslash\\ {\\mathbf{W}}\\ ,\\ \\forall X_{j}\\in{\\mathbf{V}}\\ \\backslash\\ ({\\mathbf{W}}\\cup\\{X_{i}\\})\\ \\ w.p.\\ a t\\ l e a s t\\ 1-n\\delta_{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "From Equations 24 and 27, using the union bound with probability at least $1-n\\delta_{1}-\\delta_{2}$ , all the causal effects are estimated within an error of $\\frac{\\epsilon}{4}$ from the true values, ensuring that all ancestrality tests work perfectly under this good event. Thus, Algorithm 1 learns the true transitive closure under any intervention, i.e., $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ , with $K A n+B$ intervention samples with probability of at least 1 \u2212n\u03b41 \u2212\u03b42. Also, if we set \u03b41 =2\u03b4n and $\\begin{array}{r}{\\delta_{2}=\\frac{\\delta}{2}}\\end{array}$ , then Algorithm 1 learns the true transitive closure under any intervention, i.e., $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ with a probability of $1-\\delta$ , with $K A n+B$ intervention samples, where $\\begin{array}{r}{A=\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{\\ddot{4}n^{2}K^{2}}{\\delta}}\\end{array}$ and $\\begin{array}{r}{B=\\frac{8}{\\epsilon^{2}}\\log\\frac{4n K^{2}}{\\delta}}\\end{array}$ . This completes the proof of Lemma 4.4. ", "page_idx": 19}, {"type": "text", "text": "A.10 Proof of Theorem 4.1: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We start by revising the statement of Lemma 4.3: Algorithm 1 learns the true transitive closure under any intervention, i.e., $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ , with $K A n+B$ intervention samples with a probability of at least $1-n\\delta_{1}-\\delta_{2}$ . Algorithm 2 randomly samples a target set W and calls Algorithm 1 to learn the active true transitive closure of the post-interventional graph, i.e., $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ . For every iteration, Algorithm 2 computes transitive reduction $T r(\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c})$ and updates all the edges to construct the observable graph. To prove the results in Theorem 4.1, we rely on Lemma 5 from [14], which is stated below: ", "page_idx": 19}, {"type": "text", "text": "Lemma A.2. [14] Consider a graph $\\mathcal{G}$ with observed variables $V$ and an intervention set $\\mathbf{W}\\subseteq V.$ . Consider post-interventional observable graph $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}$ and $a$ variable $X_{j}\\in V\\backslash\\mathbf{W}$ . Let $X_{i}\\in\\mathsf{P a}(X_{j})$ be such that all the parents of $X_{j}$ above $X_{i}$ in partial order are included in the intervention set W. This implies that $\\{W_{i}\\;:\\;\\pi(\\dot{W}_{i})\\;>\\;\\pi(X_{i})\\;\\;\\&\\;\\;W_{i}\\;\\in\\;{\\sf P a}(X_{j})\\}\\;\\subseteq\\;{\\bf W}$ . Then, the directed edge $(X_{i},X_{j})\\in\\mathbf{E}(T r(\\mathcal{G}_{\\overline{{\\mathbf{W}}}}))$ . The properties of transitive reduction yields $T r(\\mathcal{G}_{\\overline{{\\mathbf{W}}}})=T r(\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c})$ . Consequently, the transitive reduction of $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ , i.e., $T r(\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c})=T r(\\mathcal{G}_{\\overline{{\\mathbf{W}}}})$ may be used to learn the directed edge $(X_{i},X_{j})$ . ", "page_idx": 20}, {"type": "text", "text": "(Note: $\\mathbf{E}({\\mathcal{G}})$ denotes the edges of the graph $\\mathcal{G}$ and $\\pi$ is any total order that is consistent with the partial order implied by the DAG, i.e., $\\pi(X)<\\pi(Y)$ iff $X$ is an ancestor of Y). ", "page_idx": 20}, {"type": "text", "text": "Assume that the number of the direct parents of $X_{j}$ above $X_{i}$ is $d_{i j}$ where $d_{i j}\\leq d_{m a x}$ . Let $\\mathscr{E}_{i}(X_{j})$ be the following event: $X_{i},X_{j}\\notin{\\bf W}\\-\\ \\&\\ \\ \\{W_{i}:\\overline{{\\pi(W_{i})}}>\\pi(X_{i})\\ \\&\\ W_{i}\\in\\overline{{{\\bf P}}}{\\bf a}(X_{j})\\}\\subseteq{\\bf W}$ . The probability of this event for one run of the outer loop in Algorithm 2 with the assumption that $2d_{m a x}>=2$ is given by: ", "page_idx": 20}, {"type": "equation", "text": "$$\n{\\cal P}[{\\mathcal E}_{i}(X_{j})]=\\frac{1}{4d_{m a x}^{2}}(1-\\frac{1}{2d_{m a x}})^{d_{i j}}\\geq\\frac{1}{4d_{m a x}^{2}}(1-\\frac{1}{2d_{m a x}})^{2d_{m a x}}{\\geq}\\frac{1}{d_{m a x}^{2}}\\frac{1}{16}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The last inequality holds for $2d_{m a x}>=2$ because $\\begin{array}{r}{(1-\\frac{1}{x})^{x}\\ge0.25,\\;\\;\\forall x\\ge2}\\end{array}$ . Based on Lemma A.2, the event $\\mathscr{E}_{i}(X_{j})$ implies that the directed edge $(X_{j},X_{j})$ will be present in $T r(\\mathcal{G}_{\\mathbf{W}}^{t c})$ and will be learned. The outer loop runs for $8\\alpha d_{m a x}\\log(n)$ iterations and elements of the set W are independently sampled. The probability of failure, i.e., the event under consideration does not happen for all runs of the outer loop in Algorithm 2, is bounded as follows: ", "page_idx": 20}, {"type": "equation", "text": "$$\nP[(\\mathcal{E}_{i}(V))^{c}]\\leq(1-\\frac{1}{16\\;d_{m a x}^{2}})^{8\\alpha d_{m a x}\\log(n)}\\leq e^{-\\frac{\\alpha}{2d_{m a x}}\\log(n)}=\\frac{1}{n^{\\frac{\\alpha}{2d_{m a x}}}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "For a graph with a total number of variables $n$ , the total number of such bad events will be $\\binom{n}{2}$ since a graph can have at most $\\binom{n}{2}$ edges. Using the union bound, the probability of bad event for any pair of variables is given by: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P[F a i l u r e]\\leq\\binom{n}{2}\\times\\frac{1}{n^{\\frac{\\alpha}{2d_{m a x}}}}\\leq\\frac{1}{n^{\\frac{\\alpha}{2d_{m a x}}-2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Under the event that Algorithm 1 learns the correct transitive closure $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ for all the $8\\alpha d_{\\mathrm{max}}\\log n$ randomly sampled intervention sets $\\mathbf{W}\\subseteq\\mathbf{V}$ , the above derivation shows that we will be able to learn all edges in the true observable graph with a probability of at least n2d\u03b1m1ax \u22122 . Now recall the result from Lemma 4.3 that Algorithm 1 learns the true transitive closure under any intervention, i.e., $\\mathcal{G}_{\\overline{{\\mathbf{W}}}}^{t c}$ , with $K A n+B$ intervention samples with a probability of at least $1-n\\delta_{1}-\\delta_{2}$ . Combining the two results above using the union bound, we have the following result: ", "page_idx": 20}, {"type": "text", "text": "Algorithm 2 learns the true observable graph with a probability of at least $\\mathrm{~1~-~}\\,\\frac{1}{n^{\\frac{\\alpha}{2d_{\\mathrm{max}}}-2}}\\ -$ $8\\alpha d_{\\mathrm{max}}\\log(n)(n\\delta_{1}+\\delta_{2})$ $\\begin{array}{r}{\\alpha=\\frac{2d_{\\mathrm{max}}\\log{(\\frac{2}{\\delta}+2)}}{\\log{n}}}\\end{array}$ ,i $\\begin{array}{r}{\\delta_{1}=\\frac{\\delta}{32\\alpha d_{\\mathrm{max}}n\\log n}}\\end{array}$ $8\\alpha d_{\\mathrm{max}}\\log n(K A n+B)$ $\\begin{array}{r}{\\delta_{2}=\\frac{\\delta}{32\\alpha d_{\\mathrm{max}}\\log n}}\\end{array}$ ,n ttheervn eAntligoonraitl hsma m2 plleeasr. n2As ltshoe, true observable graph with a probability of at least $1-\\delta$ . Where $\\begin{array}{r}{\\bar{A}=\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{2n K^{2}}{\\delta_{1}}}\\end{array}$ and $\\begin{array}{r}{B=\\frac{8}{\\epsilon^{2}}\\log\\frac{2n K^{2}}{\\delta_{2}}}\\end{array}$ . This completes the proof of Theorem 4.1. ", "page_idx": 20}, {"type": "text", "text": "A.11 Proof of Lemma 4.5: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Consider two nodes $X_{i}$ and $X_{j}$ s.t. $X_{j}\\,\\notin\\,\\mathsf{A n}(X_{i})$ and suppose that Assumptions 4.2 4.3 holds and we have access to max( \u03f582 , \u03b382 ) log 2\u03b4K12 samples from $d o(X_{i}=x_{i},\\mathbf{W}=\\mathbf{w})\\;\\forall x_{i}\\in[K]$ and $\\begin{array}{r}{\\frac{16}{\\eta\\gamma^{2}}\\log(\\frac{2K^{2}}{\\delta_{3}})+\\frac{1}{2\\eta^{2}}\\log(\\frac{2K^{2}}{\\delta_{4}})}\\end{array}$ from $d o(\\mathbf{W}=\\mathbf{w})$ for a fixed $w\\in[K]^{|\\mathbf{W}|}$ and $\\mathbf{W}\\subseteq\\mathbf{V}$ such that $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq\\mathbf{W}$ and $X_{i}$ & $X_{j}\\notin\\mathbf{W}$ . We want to show that, with probability at least $1-\\delta_{1}-\\delta_{3}-\\delta_{4}$ , we have the following: ", "page_idx": 20}, {"type": "text", "text": "There exists a latent confounder between $X_{i}$ and $X_{j}\\iff$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\exists\\;x_{i},x_{j}\\in[K]\\;s.t.\\;\\big|\\;\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))\\;\\big|>\\frac{\\gamma}{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Using Hoeffding\u2019s inequality with $A$ samples from intervention $d o(x_{i},\\mathbf{w})$ . ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\right|\\geq\\sqrt{\\frac{1}{2A}\\log\\frac{2K^{2}}{\\delta_{1}}}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{1}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If we choose $\\begin{array}{r}{A=m a x(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}})\\log\\frac{2K^{2}}{\\delta_{1}}}\\end{array}$ 2\u03b4K , we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\right|\\geq\\frac{\\gamma}{4}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{1}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Using Hoeffding\u2019s inequality with $C$ samples from intervention $d o(x_{i})$ . ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|\\hat{P}(x_{j}|x_{i},d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\right|\\geq\\sqrt{\\frac{1}{2C_{x_{i}}}\\log\\frac{2K^{2}}{\\delta_{3}}}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{3}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Where $C_{x_{i}}$ is the number of samples where $X_{i}=x_{i}$ among the $C$ samples for the intervention $d o(\\mathbf{w})$ . Note the we can\u2019t directly control $C_{x_{i}}$ and it\u2019s value depends on the true interventions distribution $P(x_{i},d o(\\mathbf{w}))$ along-with the number of samples $C$ . Suppose if we can set $\\begin{array}{r}{C_{x_{i}}\\,\\geq\\,\\frac{8}{\\gamma^{2}}\\log\\frac{2K^{2}}{\\delta_{3}}}\\end{array}$ , we ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\right|\\geq\\frac{\\gamma}{4}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{3}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We need to find the number of samples $C$ such that $\\begin{array}{r}{C_{x_{i}}\\ge\\frac{8}{\\gamma^{2}}\\log\\frac{2K^{2}}{\\delta_{3}}}\\end{array}$ . Using the Hoeffding\u2019s bound we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\nP(C_{x_{i}}\\geq C P(x_{i}|d o(\\mathbf{w}))-\\eta)\\geq1-2e^{-2\\eta^{2}/C}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Let $\\begin{array}{r}{\\frac{\\delta_{4}}{K^{2}}=2e^{-2\\eta^{2}/C}}\\end{array}$ , which implies $\\begin{array}{r}{\\eta=\\sqrt{\\frac{C}{2}\\log\\frac{2K^{2}}{\\delta_{4}}}}\\end{array}$ . Thus we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\nP\\bigg(C_{x_{i}}\\geq C P(x_{i}|d o(\\mathbf{w}))-\\sqrt{\\frac{C}{2}\\log\\frac{2K^{2}}{\\delta_{4}}}\\ \\bigg)\\geq1-\\frac{\\delta_{4}}{K^{2}}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\nC_{x_{i}}\\geq C P(x_{i}|d o(\\mathbf{w}))-\\sqrt{\\frac{C}{2}\\log\\frac{2K^{2}}{\\delta_{4}}}\\;\\;w.p.\\;a t\\;l e a s t\\;1-\\frac{\\delta_{4}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Using Assumption 4.3, we have $P(x_{i}|d o(\\mathbf{w}))=0$ or $P(x_{i}|d o(\\mathbf{w}))\\geq\\eta$ . Note that if $P(x_{i}|d o(\\mathbf{w}))=$ 0, the event will never happen, and we don\u2019t care about the accuracy of the estimate $\\widehat{P}(x_{j}|x_{i},d o(\\mathsf{w}))$ because it is already initialized to zero. Now the equation above can be rewritten as : ", "page_idx": 21}, {"type": "equation", "text": "$$\nC_{x_{i}}\\ge C\\eta-\\sqrt{\\frac{C}{2}\\log\\frac{2K^{2}}{\\delta_{4}}}\\;\\;w.p.\\;a t\\;l e a s t\\;1-\\frac{\\delta_{4}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since we want Cxi \u2265\u03b382 log 2\u03b4K32 with high probability, we have the following relationship: ", "page_idx": 21}, {"type": "equation", "text": "$$\nC\\eta-\\sqrt{\\frac{C}{2}\\log\\frac{2K^{2}}{\\delta_{4}}}\\ge\\frac{8}{\\gamma^{2}}\\log\\frac{2K^{2}}{\\delta_{3}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Solving the equation for number of samples $C$ we get: ", "page_idx": 22}, {"type": "equation", "text": "$$\nC\\geq\\frac{4\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}+\\ln\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)+\\sqrt{8\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}\\ln\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)+\\ln^{2}\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)}}{4\\eta^{2}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In order to make the expression simpler we choose the number of samples $C$ as follows: ", "page_idx": 22}, {"type": "equation", "text": "$$\nC=\\frac{4\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}+\\ln\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)+\\sqrt{8\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}\\ln\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)+\\ln^{2}\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)+\\left(4\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}\\right)^{2}}}{4\\eta^{2}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\nC=\\frac{4\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}+\\ln\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)+\\sqrt{\\left(4\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}+\\ln\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)\\right)^{2}}}{4\\eta^{2}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\nC=\\frac{4\\eta\\frac{8\\log\\left(\\frac{2K^{2}}{\\delta_{3}}\\right)}{\\gamma^{2}}+\\ln\\left(\\frac{2K^{2}}{\\delta_{4}}\\right)}{2\\eta^{2}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\nC=\\frac{16}{\\eta\\gamma^{2}}\\log(\\frac{2K^{2}}{\\delta_{3}})+\\frac{1}{2\\eta^{2}}\\log(\\frac{2K^{2}}{\\delta_{4}})\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Suppose we take $C$ samples for intervention $d o(\\mathbf{w})$ as given above. Now, from Equations 35, 39, and 40, using the union bound, we have the following: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\right|\\geq\\frac{\\gamma}{4}\\;\\;w.p.\\;a t\\;m o s t\\;\\frac{\\delta_{3}+\\delta_{4}}{K^{2}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since the realization $\\mathbf{w}\\in[K]^{|\\mathbf{W}|}$ is fixed, but $x_{i},x_{j}\\,\\in\\,[K]$ , we have a total of $K^{2}$ possible bad events when estimates are not good. With the given choice of number of samples $A$ and $C$ , we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\right|\\leq\\frac{\\gamma}{4}\\ \\forall x_{j}\\in[K]\\ \\ w.p.\\ a t\\ l e a s t\\ 1-\\delta_{1}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|{\\widehat{P}}(x_{j}|x_{i},d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\right|\\leq{\\frac{\\gamma}{4}}\\ \\forall x_{i},x_{j}\\in[K]\\ \\ w.p.\\ a t\\ l e a s t\\ 1-\\delta_{3}-\\delta_{4}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Under the good event, which has a probability of at least $1\\,-\\,\\delta_{1}\\,-\\,\\delta_{3}\\,-\\,\\delta_{4}$ , both estimates are accurate. We now consider the two possible scenarios. Suppose that there is no latent confounder between $X_{i}$ and $X_{j}$ . In this case by Lemma 4.2 we have $\\boxed{P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\!-\\!P(x_{j}|x_{i},d o(\\mathbf{w}))}\\Big|=$ $0\\;,\\forall x_{i}x_{j}\\in[K]$ . By triangular inequality we have the following: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o({\\mathbf w}))-\\widehat{P}(x_{j}|x_{i},d o({\\mathbf w}))\\bigg|\\leq\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o({\\mathbf w}))-P(x_{j}|d o(x_{i}),d o({\\mathbf w}))\\bigg|+}\\\\ &{}&{\\bigg|\\widehat{P}(x_{j}|x,d o({\\mathbf w}))-P(x_{j}|x_{i},d o({\\mathbf w}))\\bigg|\\leq\\frac{\\gamma}{2}\\ \\forall x_{i},x_{j}\\in[K].\\quad(4)}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "However, when there is a latent confounder between $X_{i}$ and $X_{j}$ , in this case, under Assumption 4.2, we must have some configuration, say $x_{i},x_{j}\\ \\in\\ [K]$ , for any $\\mathbf{w}\\,\\in\\,[K]^{|\\mathbf{W}|}$ , such that $\\begin{array}{r}{\\left|P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\right|>\\gamma}\\end{array}$ . By triangular inequality when there is a latent confounder between $X_{i}$ and $X_{j}$ , $\\exists\\;x_{i},x_{j}\\in[K]$ such that: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))\\bigg|\\geq\\bigg|P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\bigg|}\\\\ &{-\\left|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\right|-\\bigg|\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\bigg|>\\frac{\\gamma}{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Thus, using Assumption 4.2 with the given choice of number of samples with probability at least $1-\\delta_{1}-\\delta_{3}-\\delta_{4}$ , we have the following result: ", "page_idx": 23}, {"type": "text", "text": "There exists a latent confounder between $X_{i}$ and $X_{j}\\iff$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\exists\\;x_{i},x_{j}\\in[K]\\;s.t.\\;\\big|\\;\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))\\;\\big|>\\frac{\\gamma}{9}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This completes the proof for Lemma 4.5. ", "page_idx": 23}, {"type": "text", "text": "A.12 Proof of Theorem 4.2: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "The Algorithm 3 first calls Algorithm 2 to learn the observable graph structure. We have already proved in Theorem 4.1 that Algorithm 2 learns the true observable graph with a probability of at least \u2212n2d\u03b1m1ax \u22122 \u22128\u03b1dmax log(n)(n\u03b41 +\u03b42) with a maximum of 8\u03b1dmax log n(KAn+B) interventional samples. The next phase in Algorithm 3 is to learn/detect latent confounders between any pair of variables. For all pairs of nodes $X_{i}$ and $X_{j}$ such that $X_{j}\\notin\\mathsf{A n}(X_{i})$ , we define a set of nodes $\\mathbf{W}_{i j}\\;\\subseteq\\;\\mathbf{V}$ such that $X_{i},X_{j}\\;\\notin\\;{\\bf S}_{i}$ , where $\\mathbb{W}_{i j}\\;=\\;(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\;\\backslash\\;\\{X_{i}\\})$ . Also, note that $|\\mathbf{W}_{i j}|\\leq2d_{\\operatorname*{max}}$ . Let us define the event $\\mathcal{E}_{i j}=[\\mathbf{W}_{i j}\\subseteq\\mathbf{W}\\ \\ \\&\\ \\ X_{j},X_{i}\\notin\\mathbf{W}]$ . The probability of this event for one run of the outer loop in Algorithm 2 with the assumption that $2d_{\\mathrm{max}}\\ge2$ is given by: ", "page_idx": 23}, {"type": "equation", "text": "$$\nP[\\mathcal{E}_{i j}]=\\frac{1}{4d_{m a x}^{2}}(1-\\frac{1}{2d_{m a x}})^{|\\mathbf{W}_{i j}|}\\ge\\frac{1}{4d_{m a x}^{2}}(1-\\frac{1}{2d_{m a x}})^{2d_{m a x}}\\ge\\frac{1}{d_{m a x}^{2}}\\frac{1}{16}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The last inequality holds for $d_{\\operatorname*{max}}\\geq2$ . Note that we reuse all the interventional data samples from Algorithm 2 in Algorithm 3. Under Assumption 4.2, if the event $\\mathscr{E}_{i j}$ happens with a large enough number of samples, we can detect the presence or absence of latent confounders between $X_{i}$ and $X_{j}$ . The outer loop runs for $8\\alpha d_{m a x}\\log(n)$ iterations, and the elements of the set $\\mathbf{W}$ are independently sampled. The probability of failure, i.e., the event under consideration does not happen for all runs of the outer loop in Algorithm 2, is bounded as follows: ", "page_idx": 23}, {"type": "equation", "text": "$$\nP[\\mathcal{E}_{i j}^{c}]\\leq(1-\\frac{1}{16\\ d_{m a x}^{2}})^{8\\alpha d_{m a x}\\log(n)}\\leq e^{-\\frac{\\alpha}{2d_{m a x}}\\log(n)}=\\frac{1}{n^{\\frac{\\alpha}{2d_{m a x}}}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For a graph with a total number of variables $n$ , the total number of such bad events will be $\\binom{n}{2}$ . Using the union bound, the probability of bad event for any pair of variables is given by: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P[F a i l u r e]\\leq\\binom{n}{2}\\times\\frac{1}{n^{\\frac{\\alpha}{2d_{m a x}}}}\\leq\\frac{1}{n^{\\frac{\\alpha}{2d_{m a x}}-2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This implies with a probability of n2d\u03b1m1ax \u22122 , we will be able to find an appropriate interventional dataset to test the presence of latent confounders between any pair of variables using Assumption 4.2 after running Algorithm 2. We still need to make sure we have enough interventional samples to be able to test the latents. This is because we need to accurately estimate conditional effects to carry out the test, as in Assumption 4.2. We first consider estimation of the causal effect $\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))$ for any randomly sampled set W. Now, consider a fixed $X_{i},X_{j}\\,\\in\\,{\\bf V}\\setminus{\\bf W}$ . We have access to $\\begin{array}{r}{\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{2n K^{2}}{\\delta_{1}}}\\end{array}$ samples for every $x_{i}\\in[K]$ . We have already shown that under the good event, we have the following: ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\bigg|\\le\\operatorname*{min}(\\frac{\\epsilon}{4},\\frac{\\gamma}{4})}\\\\ &{\\qquad\\qquad\\qquad\\forall x_{i},x_{j}\\in[K]\\ ,\\ \\forall X_{i}\\in{\\mathbf{V}}\\ \\backslash\\ \\mathbf{W}\\ ,\\ \\forall X_{j}\\in{\\mathbf{V}}\\ \\backslash\\ ({\\mathbf{W}}\\cup\\{X_{i}\\})\\ w.p.\\ a t\\ l e a s t\\ 1-\\frac{n\\delta_{1}}{\\iota^{\\prime}\\sim\\gamma^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Now, we consider estimation of the conditional causal effects, i.e., $\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))$ . Note the while running the Algorithm 2 we have access to $\\begin{array}{r}{B\\,=\\,\\frac{8}{\\epsilon^{2}}\\log\\frac{2n K^{2}}{\\delta_{2}}}\\end{array}$ samples form intervention $d o(\\mathbf{w})$ and in the step 7 of Algorithm 3 we add more samples to the data set and have access to at least $\\begin{array}{r}{C=\\frac{16}{\\eta\\gamma^{2}}\\log(\\frac{\\bar{2}n^{2}K^{2}}{\\delta_{3}})+\\frac{1}{2\\eta^{2}}\\log(\\frac{2n^{2}K^{2}}{\\delta_{4}})}\\end{array}$ samples instead. Now, consider a fixed $X_{i},X_{j}\\in\\mathbf{V}\\setminus\\mathbf{W}$ With access to $C$ samples as given above, following from Equation 48 in the Proof of Lemma 4.5, we have the following result: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\left|\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\right|\\leq\\frac{\\gamma}{4}\\;\\;\\forall x_{i},x_{j}\\in[K]\\;\\;w.p.\\;a t\\;l e a s t\\;1-\\frac{\\delta_{3}}{n^{2}}-\\frac{\\delta_{4}}{n^{2}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Note that in the above equation, we have $\\frac{\\delta_{3}}{n^{2}}$ and $\\frac{\\delta_{4}}{n^{2}}$ instead of $\\delta_{3}$ and $\\delta_{4}$ as in Equation 48, because here in the number of samples $C$ , we also have $\\frac{\\delta_{3}}{n^{2}}$ and $\\frac{\\delta_{4}}{n^{2}}$ instead of $\\delta_{3}$ and $\\delta_{4}$ when compared to the number of samples in Equation 45. Now, using the union bound we have the following: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\widehat{P}(x_{j}|x_{i},d o(\\mathbf{w}))-P(x_{j}|x_{i},d o(\\mathbf{w}))\\right|\\leq\\frac{\\gamma}{4}}\\\\ &{\\qquad\\qquad\\forall x_{i},x_{j}\\in[K]\\;,\\;\\forall X_{j}\\in\\mathbf{V}\\setminus(\\mathbf{W}\\cup\\{X_{i}\\})\\;\\;w.p.\\;a t\\;l e a s t\\;1-\\frac{\\delta_{3}}{n}-\\frac{\\delta_{4}}{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Again using the union bound over all $X_{i}\\in\\mathbf{V}\\setminus\\mathbf{W}$ we have the following: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigg|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\mathbf{w}))-P(x_{j}|d o(x_{i}),d o(\\mathbf{w}))\\bigg|\\leq\\frac{\\gamma}{4}}\\\\ &{\\quad\\forall x_{i},x_{j}\\in[K]\\ ,\\ \\forall X_{i}\\in\\mathbf{V}\\ \\backslash\\ \\mathbf{W}\\ ,\\ \\forall X_{j}\\in\\mathbf{V}\\ \\backslash\\ (\\mathbf{W}\\cup\\{X_{i}\\})\\ \\ w.p.\\ a t\\ l e a s t\\ 1-\\delta_{3}-\\delta_{4}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This implies that under the good event, for every randomly sampled intervention set $\\mathbf{W}\\subseteq\\mathbf{V}$ , the estimate of the conditional causal effect is accurate within the desired $\\scriptstyle{\\frac{\\gamma}{4}}$ threshold. This would imply that the test for detection of latent variables is perfect under this good event. We have already shown that to ensure we have access to sufficient datasets to detect latent variables between any pair of nodes, the $8\\alpha d_{\\mathrm{max}}\\log n$ randomly sampled target sets in Algorithm 2 are sufficient. Combining these results with the results from Theorem 4.1, we have the following: ", "page_idx": 24}, {"type": "text", "text": "The Algorithm 3 learns the true causal graph along with all latents with a probability of at least 1 $\\begin{array}{r}{-\\frac{\\frac{1}{1}}{n^{\\frac{2{d}_{m a x}}{d}}}-\\frac{1}{n^{\\frac{2}{2{d}_{m a x}}}}-8\\alpha d_{m a x}\\log(\\bar{n})\\langle n\\delta_{1}+\\delta_{2}^{\\overline{{\\;\\;\\bullet}}}\\rangle-8\\alpha d_{m a x}\\log(n)(\\delta_{3}+\\dot{\\delta}_{4})=1-\\frac{2}{n^{\\frac{2}{2{d}_{m a x}}-2}}-}\\end{array}$ $8\\alpha d_{m a x}\\log(n)(n\\delta_{1}+(\\delta_{2}+\\delta_{3}+\\delta_{4}))$ with a maximum $8\\alpha d_{m a x}\\log n(K A n+\\operatorname*{max}(B,C))$ interventional samples. Also If we set 2dmax log ( \u03b44 +2), \u03b41 = 64\u03b1dma\u03b4xn log n and \u03b42 = \u03b43 = \u03b44 = 64\u03b1dm\u03b4ax log n, then Algorithm 2 learns the true causal graph with latents with a probability at least 1\u2212\u03b4. Note that: $\\begin{array}{r}{A=\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{2n K^{2}}{\\delta_{1}},B=\\frac{8}{\\epsilon^{2}}\\log\\frac{2n K^{2}}{\\delta_{2}},C=\\frac{16}{\\eta\\gamma^{2}}\\log(\\frac{2K^{2}}{\\delta_{3}})+\\frac{1}{2\\eta^{2}}\\log(\\frac{2K^{2}}{\\delta_{4}})}\\end{array}$ . This completes the proof for Theorem 4.2. ", "page_idx": 24}, {"type": "text", "text": "Algorithm 6: Full version of Algorithm for causal bandits with unknown graph structure ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1 Set the Parameter $\\delta$ , $d_{m a x}$ ", "page_idx": 25}, {"type": "text", "text": "2 Calculate $\\alpha,\\delta_{1},\\delta_{2},\\delta_{3},\\delta_{4}$ as in Theorem 5.1   \n3 $\\mathcal G^{t c}=|$ LearnTransitiveClosure $\\begin{array}{r}{\\mathbf{\\nabla}\\mathbf{W}=\\phi,\\frac{\\delta}{2n},\\frac{\\delta}{n})}\\end{array}$ 4 G, IData = LearnObservableGraph $(\\mathsf{A n}(Y)_{\\mathcal{G}^{t c}},\\alpha,d_{m a x},\\delta_{1},\\delta_{2})$   \n5 $\\begin{array}{r}{C=\\frac{16}{\\eta\\gamma^{2}}\\log(\\frac{2n^{2}K^{2}}{\\delta_{3}})+\\frac{1}{2\\eta^{2}}\\log(\\frac{2n^{2}K^{2}}{\\delta_{4}})}\\end{array}$ , $\\begin{array}{r}{B=\\frac{8}{\\epsilon^{2}}\\log\\frac{2n K^{2}}{\\delta_{2}}}\\end{array}$ 6 #Learn the bi-directed edges between reward $Y$ and all nodes $X_{i}\\in\\mathsf{A n}(Y)$ and update $\\mathcal{G}$ . 7 for every $X_{i}\\in\\mathsf{A n}(Y)_{\\mathcal{G}^{t c}}$ do 8 Set $X_{j}:=Y$ 9 Find interventional data sets $d o(\\mathbf{W}=\\mathbf{w})$ and $d o(X_{i}=x_{i},\\mathbf{W}=\\mathbf{w})$ from IData s.t. $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq\\mathbf{W}$ and $X_{i}$ & $X_{j}\\notin\\mathbf{W}$ 10 Get $\\operatorname*{max}(0,B-\\bar{C})$ new samples for $d o(\\mathbf{W}=\\mathbf{\\bar{w}})$ 11 if $\\exists\\;x_{i},x_{j}\\in[K]\\;s$ .t. $\\begin{array}{r}{|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\pmb{w}))-\\widehat{P}(x_{j}|x_{i},d o(\\pmb{w}))|>\\frac{\\gamma}{2}}\\end{array}$ then 12 Add bi-dirceted edge $X_{i}\\leftrightarrow X_{j}$ to graph $\\mathcal{G}$   \n13 while There is a new pair that is tested do 14 Find a new pair $(Z,X)$ s.t. $Z\\in\\mathsf{A n}(Y)$ such that $Z$ and $Y$ don\u2019t have a bi-directed edge between them in $\\mathcal{G}$ and $X\\in\\mathbf{MUCT}(\\mathcal{G}_{\\overline{{\\mathsf{P a}(Z),\\mathsf{B i}(Z,\\mathcal{G})}}},Y)$ 15 # Test for the latent between the pair $(Z,X)$ and update $\\mathcal{G}$ . 16 Set $X_{i}:=Z,X_{j}:=X$   \n17 if $X_{j}\\in\\mathsf{A n}(X_{i})$ swap them.   \n18 Find interventional data sets $d o(\\mathbf{W}=\\mathbf{w})$ and $d o(X_{i}=x_{i},\\mathbf{W}=\\mathbf{w})$ from IData s.t. $(\\mathsf{P a}(X_{i})\\cup\\mathsf{P a}(X_{j})\\setminus\\{X_{i}\\})\\subseteq\\mathbf{W}$ and $X_{i}$ & $X_{j}\\notin\\mathbf{W}$   \n19 Get $\\operatorname*{max}(0,B-\\bar{C})$ new samples for $d o(\\mathbf{W}=\\mathbf{\\bar{w}})$ 20 if \u2203 $\\mid x_{i},x_{j}\\in[K]\\:s$ .t. $\\begin{array}{r}{|\\widehat{P}(x_{j}|d o(x_{i}),d o(\\pmb{w}))-\\widehat{P}(x_{j}|x_{i},d o(\\pmb{w}))|>\\frac{\\gamma}{2}}\\end{array}$ then 21 Add bi-directed edge $X_{i}\\leftrightarrow X_{j}$ to grap $\\hbar\\,\\mathcal{G}$   \n22 Learn the set of POMISs $\\mathcal{Z}_{\\mathcal{G}}$ from the graph $\\mathcal{G}$ Using Algorithm 1 in [5]. $\\bar{\\mathcal{A}}=\\{\\Omega(I)\\ |\\ \\bar{\\forall}I\\in\\bar{\\mathcal{L}}_{\\mathcal{G}}\\}$ . ", "page_idx": 25}, {"type": "text", "text": "23 Run UCB algorithm over the arm set ", "page_idx": 25}, {"type": "text", "text": "A.13 Full Version of Algorithm 4 and Proof of Theorem 5.1: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Algorithm 4 or its full version (Algorithm 6) starts by learning the transitive closure of the graph, denoted as $\\mathcal{G}^{t c}$ . This is because $\\mathcal{G}^{\\bar{t}c}$ can give us $\\mathsf{A n}(Y)$ , and every possible POMIS is a subset of $\\mathsf{A n}(Y)$ . Thus, we can restrict ourselves to ancestors of the read node. From Lemma 4.4, we can learn the transitive closure $\\mathcal{G}^{t c}$ with a probability of at least $1-\\delta$ with a maximum of $K A n+B$ interventional samples by setting $\\begin{array}{r}{\\delta_{1}=\\frac{\\delta}{2n}}\\end{array}$ and $\\begin{array}{r}{\\delta_{2}=\\frac{\\delta}{2}}\\end{array}$ . Then, Algorithm 1 learns the true transitive closure with a probability of at least $1\\,-\\,\\delta$ . (We have $\\begin{array}{r}{A\\,=\\,\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{2n K^{2}}{\\delta_{1}}}\\end{array}$ and $B\\,=$ $\\frac{8}{\\epsilon^{2}}\\log\\frac{2n K^{2}}{\\delta_{2}}$ as in line 2 of Algorithm 1). Thus, the total interventional samples for this step turn out to be $\\begin{array}{r}{\\overbar{K n(\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)}\\log\\frac{4n^{2}K^{2}}{\\delta}+\\frac{8}{\\epsilon^{2}}\\log\\frac{4n K^{2}}{\\delta}.}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "The next step is to learn the complete observable graph induced on the reward node and its ancestors and then learn/detect only a subset of latent confounders which are characterized to be necessary and sufficient to learn the true set of POMISs (Theorem 3.1). Although this step saves us interventional samples compared to the full discovery Algorithm 3, which learns/detects latents between all pairs of variables, the exact saving will depend on the structure of the underlying causal graph. For the regret upper bound, we can use the results from Theorem 4.2 to bound the number of interventional samples for learning the true POMIS set from the ancestors of the reward node. This implies that given the true set of ancestors of the reward $\\mathsf{A n}(Y)$ , we can learn the true POMIS set with a probability of at least $1-\\delta$ using $8\\alpha d_{\\mathrm{max}}\\bigg(K A\\big|\\mathsf{A n}(Y)\\big|+B\\bigg)\\log\\big(\\big|\\mathsf{A n}(Y)\\big|\\big)$ interventions, where $A$ and $B$ are given by line 2 of Algorithm 1, and $C$ is given by line 3 of Algorithm 3 by setting $\\begin{array}{r}{\\alpha=\\frac{2d_{\\mathrm{max}}\\log\\big(\\frac{4}{\\delta}+2\\big)}{\\log\\big|\\mathsf{A n}(Y)\\big|}}\\end{array}$ $\\begin{array}{r}{\\delta_{1}=\\frac{\\delta}{64\\alpha d_{\\mathrm{max}}\\left|\\mathsf{A n}(Y)\\right|\\log\\left|\\mathsf{A n}(Y)\\right|},\\mathrm{and}\\;\\delta_{2}=\\delta_{3}=\\delta_{4}=\\frac{\\delta}{64\\alpha d_{\\mathrm{max}}\\log\\left|\\mathsf{A n}(Y)\\right|}}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "The last phase is just running the UCB algorithm over the set of all possibly optimal arms, i.e., $\\mathcal{A}=\\{\\Omega(I)\\ |\\ \\forall I\\in\\mathcal{T}_{\\mathcal{G}}\\}$ . This phase has a regret bound of $\\begin{array}{r}{\\sum_{\\mathbf{s}\\in\\{\\Omega(I)|\\forall I\\in\\mathcal{Z}_{\\mathcal{G}}\\}}\\Delta_{d o(\\mathbf{s})}\\biggl(1+\\frac{\\log T}{\\Delta_{d o(\\mathbf{s})}^{2}}\\biggr)}\\end{array}$ [26]. Now combining all the results we have the following: ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "Algorithm 4 learns the true set of POMISs $\\mathcal{T}_{\\mathcal{G}}$ with probability at least $1-\\delta-\\delta=1-2\\delta$ , and under the good event $E$ that it learns POMISs correctly, the cumulative regret is bounded as follows: ", "page_idx": 26}, {"type": "equation", "text": "$$\nR_{t}\\leq K n\\operatorname*{max}\\left(\\frac{8}{\\epsilon^{2}},\\frac{8}{\\gamma^{2}}\\right)\\log\\frac{4n^{2}K^{2}}{\\delta}+\\frac{8}{\\epsilon^{2}}\\log\\frac{4n K^{2}}{\\delta}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n+\\;8\\alpha d_{m a x}\\bigg(K A\\big|\\mathsf{A n}(Y)\\big|+\\operatorname*{max}(B,C)\\bigg)\\log\\big(\\big|\\mathsf{A n}(Y)\\big|\\big)\\;+\\sum_{\\mathsf{s}\\in\\{\\Omega(I)|\\forall I\\in\\mathcal{I}_{\\sigma}\\}}\\Delta_{d o(\\mathbf{s})}\\bigg(1+\\frac{\\log T}{\\Delta_{d o(\\mathbf{s})}^{2}}\\bigg),\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $A$ and $B$ are given by line 2 of Algorithm 1, and $C$ is given by line 3 of Algorithm 3 by setting $\\begin{array}{r}{\\alpha=\\frac{2d_{m a x}\\log\\left(\\frac{4}{\\delta}+2\\right)}{\\log\\left|\\mathsf{A n}\\left(Y\\right)\\right|}}\\end{array}$ 2dmax log ( \u03b44 +2), \u03b41 = $\\begin{array}{r}{\\delta_{1}=\\frac{\\delta}{64\\alpha d_{m a x}\\left|\\mathsf{A n}\\left(Y\\right)\\right|\\log\\left|\\mathsf{A n}\\left(Y\\right)\\right|}}\\end{array}$ and $\\begin{array}{r}{\\delta_{2}=\\delta_{3}=\\delta_{4}=\\frac{\\delta}{64\\alpha d_{m a x}\\log\\big|\\mathsf{A n}(Y)\\big|}}\\end{array}$ . This completes the proof of the Theorem 5.1. ", "page_idx": 26}, {"type": "text", "text": "A.14 Comparison with SCM-based Approximate Allocation Matching Algorithm from [6]: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Our proposed algorithm, Algorithm 4, consists of two phases. The first phase uses interventional samples to learn the set of POMISs, and the second phase uses the UCB algorithm to find the optimal arm among the POMISs. Note that in the second phase, we use the UCB algorithm, which assumes that arms are independent of one another. However, in the case of causal bandits, the arms are correlated, and every intervention provides some information about other interventions. The UCB algorithm cannot exploit this information. However, [6] proposes an algorithm to exploit the correlations between arms in a causal bandit setting, which accelerates the learning compared to the simple UCB algorithm. The main limitation is that the algorithm requires access to the true causal graph. Therefore, it is possible that we can use an alternative approach where instead of POMISs, we learn the entire causal graph and then use the SCM-based Approximate Allocation Matching Algorithm from [6] for our problem setup. This approach can also allow us to reuse the intervention samples from the discovery phase to accelerate the next phase. However, the main drawback of this approach is that the algorithm proposed in [6] faces issues when it comes to larger, densely connected causal graphs. We explain the reasoning of our claim by reviewing some concepts from the paper [6]. ", "page_idx": 26}, {"type": "text", "text": "In order to exploit the correlations between different arms in a causal bandit setting, the authors in [6] rely on response variable formulation for causal effects, which we discuss very briefly here. For any causal graph $\\mathcal{G}$ , the observed variables $\\mathbf{V}$ can be uniquely partitioned into ccomponents $\\mathbf{C}^{1},\\ldots,\\mathbf{C}^{n_{\\mathrm{c}}({\\mathcal{G}})}$ . Consider a set of response variables $\\mathbf{M}$ , which we also partition into $\\mathbf{M}^{1},\\ldots,\\mathbf{M}^{n_{\\mathrm{c}}(\\mathcal{G})}$ , where each $\\mathbf{M}^{j}$ contains response variables corresponding to every observed variable in the corresponding c-component $\\mathbf{C}^{j}$ . Within a c-component, the response variables of all the observed variables are correlated since they are connected by bidirected edges. However, across two c-components, the response variables are independent. As a result, $\\begin{array}{r}{P(\\mathbf{m})=\\prod_{j=1}^{n_{\\mathrm{c}}(\\mathcal{G})}P(\\mathbf{m}^{j})}\\end{array}$ By concatenating $P(\\mathbf{m}^{j})$ for each $\\mathbf{m}^{j}\\,\\in\\,\\Omega(\\mathbf{M}^{j})$ , one can construct a vector $\\mathbf{p}_{j}\\,\\in\\,\\Delta(|\\Omega(\\mathbf{M}^{j})|)$ where $\\Delta(|\\Omega(\\mathbf{M}^{j})|)$ denotes the probability simplex over the discrete domain $\\Omega(\\mathbf{M}^{j})$ . Let the parent set of a c-component $\\mathbf{C}^{j}$ be $\\mathsf{P a}_{\\mathbf{C}^{j}}\\;:=\\;\\left(\\bigcup_{i:V_{i}\\in\\mathbf{C}^{j}}\\,\\mathsf{P a}_{i}\\right)\\,\\setminus\\,\\mathbf{C}^{j}$ . When taking intervention $d o(\\mathbf{S}\\ =\\ \\mathbf{s})$ , the values of ${\\bf C}^{j}\\cap{\\bf S}$ are set to $\\mathbf{s}[\\mathbf{C}^{j}]$ , which denotes the values of ${\\bf C}^{j}\\cap{\\bf S}$ that are consistent with s. $\\mathbf{M}^{j}$ picks the mapping functions from $\\mathsf{P a}_{i}$ to $V_{i}$ for all $V_{i}\\ \\in\\ \\mathbf{C}^{j}$ . By marking configurations in $\\bar{B_{\\mathcal{G},\\mathbf{s}[\\mathbf{C}^{j}]}}(\\mathbf{C}^{j},\\bar{\\mathsf{p}}\\bar{\\mathsf{a}}_{\\mathbf{C}^{j}})\\bar{\\mathbf{\\Xi}}\\subseteq\\ \\Omega(\\mathbf{M}^{j})$ with 1 and 0, one constructs a vector $b_{\\mathcal{G},\\mathbf{s}[\\mathbf{C}^{j}]}\\big(\\mathbf{C}^{j},\\mathsf{p a}_{\\mathbf{C}^{j}}\\big)\\in\\{0,1\\}^{\\left|\\Omega\\left(\\mathbf{M}^{j}\\right)\\right|}$ such that: ", "page_idx": 26}, {"type": "equation", "text": "$$\nP_{\\mathbf{s}}(\\mathbf{v})=\\prod_{j=1}^{n_{c}(\\mathcal{G})}P\\big(\\mathbf{M}^{j}\\in B_{\\mathcal{G},\\mathbf{s}[\\mathbf{C}^{j}]}(\\mathbf{C}^{j},\\mathsf{p a}_{\\mathbf{C}^{j}})\\big)=\\prod_{j=1}^{n_{c}(\\mathcal{G})}b_{\\mathcal{G},\\mathbf{s}[\\mathbf{C}^{j}]}^{\\top}(\\mathbf{C}^{j},\\mathsf{p a}_{\\mathbf{C}^{j}})\\mathbf{p}_{j}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The equation 60 is very useful since it enables us to exploit the correlations between different interventions in the causal bandit setting. This is because every interventional distribution can be written as a deterministic linear function of the response variable distribution. Thus, it is possible that using the response variable decomposition, we can reuse the samples from discovery into the next phase and accelerate learning of the optimal arm. However, we need to discuss the scalability of this approach. Note that every variable in the SCM can take values from the set $[K]$ , and in total, there could be $K$ different realizations for $V_{j}$ for every realization of its parents $\\mathsf{P a}(V_{j})$ . As a result, there are a total of KK|Pa(Vj )| possible mappings from $\\mathsf{P a}(V_{j})$ to $V_{j}$ . Also, note that within a c-component, the response variables for every observed variable are correlated. This implies that for every component $\\mathbf{C}^{j}$ , the corresponding response variable $\\mathbf{M}^{j}$ has the domain |\u2126(Mj)| =  Vi\u2208Cj KK|Pa(Vi)| .n sTe hvuasr,i aebvlee rdye cvoecmtporo $\\mathbf{p}_{j}$ onw iilsl  uhsaevfeul  af otro tsaml aollfe $\\prod_{V_{i}\\in{\\bf C}^{j}}K^{K^{\\vert P{\\bf a}(V_{i})\\vert}}$ graphs, the scaling for the length of vectors $\\mathbf{p}_{j}$ is clearly exponential, making the use of response variable decomposition infeasible for larger or denser causal graphs. All in all, there are correlations between different arms in causal bandits, but it is not clear how to exploit them effectively, especially for larger and denser causal graphs, which is still an open problem. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "A.15 Experimental Compute Resources and Runtime ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "We ran our experiments on a server equipped with the AMD Ryzen Threadripper PRO 5995WX CPU, which has 64 cores and 128 threads, with a base clock speed of $2.7\\:\\mathrm{GHz}$ and a maximum boost clock speed of $4.5\\:\\mathrm{GHz}$ , along with 128 GB of RAM. The total runtime for the experimental plots in Figures 2 and 3 is around 2 hours. For the experimental plots in Figure 4, the total runtime is around 2 hours for each subplot since we run the full algorithm for multiple randomly sampled graphs. ", "page_idx": 27}, {"type": "text", "text": "A.16 Broader Impacts of our Work ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "This paper presents work with the goal of advancing the field of Machine Learning. Since the causal bandit framework can be used to model real-life decision-making scenarios, there are some potential societal consequences of our work. The possibility of biased or incomplete understanding of causal relationships could lead to misguided decision-making or policy recommendations in real-world situations. Thus, extra care and consideration of ethical boundaries regarding actions/interventions are needed while applying our proposed methodology to practical problems. ", "page_idx": 27}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: Our abstract and introduction clearly reflect the paper\u2019s contributions, and we provide a list of main contributions at the end of the introduction as well. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 28}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: Our paper clearly discusses all the limitations and assumptions in sections 2 and 4. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 28}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: All the theorems and lemmas in our paper are properly numbered, and formal proofs are provided in the supplementary material. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 29}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide detailed explanation of our experiments in section 6 and also provide the code with instructions to reproduce the results. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 29}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We have uploaded the code along with the instructions to reproduce the results in our experiments section. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide all the details about our experimental setting in section 6. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 30}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We plot the error bars as part of the experimental results in section 6 and also mention the method used to calculate them. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We provide all the information on computer resources and runtime for our experiments in section A.15. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We have looked at the NeurIPS code of ethics, and we believe there are no potential harms caused by the research or potential future harmful consequences for our work. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 31}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We discuss possible broader impacts of our work in section A.16. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 31}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: We mainly conduct synthetic experiments in our work, and we don\u2019t see any risk of misuse of our code. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: Our experiments are purely synthetic in nature, and we don\u2019t use any datasets or models that require licenses. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: We don\u2019t create new assets in our work, and the main contributions of our work lie predominantly on the theoretical side. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 33}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: We don\u2019t require any approval since our work does not involve crowdsourcing or research with human subjects. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 33}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}]