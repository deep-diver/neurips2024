{"references": [{"fullname_first_author": "Jimmy Lei Ba", "paper_title": "Layer normalization", "publication_date": "2016-00-00", "reason": "This paper introduces layer normalization, a crucial technique used in the SepReformer's Transformer blocks for efficient and stable training of deep networks."}, {"fullname_first_author": "Albert S Bregman", "paper_title": "Auditory scene analysis: The perceptual organization of sound", "publication_date": "1994-00-00", "reason": "This book is foundational to the field of speech separation, providing the theoretical basis for understanding auditory scene analysis, a core concept in the paper's approach to speech separation."}, {"fullname_first_author": "Yi Luo", "paper_title": "TasNet: Time-domain audio separation network for real-time, single-channel speech separation", "publication_date": "2018-00-00", "reason": "This paper introduces TasNet, a pioneering time-domain approach to speech separation that directly influenced the design and methodology of the SepReformer."}, {"fullname_first_author": "Yi Luo", "paper_title": "Conv-TasNet: Surpassing ideal time-frequency magnitude masking for speech separation", "publication_date": "2019-00-00", "reason": "This paper presents Conv-TasNet, an improved version of TasNet, which further enhanced the time-domain approach and directly inspired improvements to the SepReformer's architecture."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-00-00", "reason": "This paper introduced the Transformer architecture, a fundamental building block of the SepReformer, enabling efficient processing of long sequences and capturing complex relationships between speech elements."}]}