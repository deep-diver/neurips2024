[{"figure_path": "pMJFaBzoG3/tables/tables_8_1.jpg", "caption": "Table 1: l1-Distance (converted by log(1 + x)) and Precision (%) of algorithms for finding mode connectivity across different network architectures.", "description": "This table presents the results of comparing three different algorithms (Weight Matching, Sinkhorn, and OT4P with three different temperatures) for finding mode connectivity across three different network architectures (MLP5, VGG11, and ResNet18).  The metrics used for comparison are the l1-distance (after a log(1+x) transformation) and the precision. Lower l1-distance indicates better performance, while higher precision indicates a more accurate identification of the optimal permutation.", "section": "4.1 Finding mode connectivity"}, {"figure_path": "pMJFaBzoG3/tables/tables_8_2.jpg", "caption": "Table 2: Marginal log-likelihood and Precision (%) of algorithms for inferring neuron identities across different proportions of known neurons.", "description": "This table presents the performance comparison of three algorithms (Naive, Gumbel-Sinkhorn, and OT4P) on the task of inferring neuron identities using different proportions of known neurons (5%, 10%, and 20%).  The evaluation metrics are marginal log-likelihood and precision.  The results show that OT4P generally outperforms the other two algorithms, achieving higher precision and better marginal log-likelihood, especially when the proportion of known neurons is low.", "section": "4.2 Inferring neuron identities"}, {"figure_path": "pMJFaBzoG3/tables/tables_18_1.jpg", "caption": "Table 3: Probability (%) of eigenvalue -1 occurring in matrices.", "description": "This table presents the probability of encountering the eigenvalue -1 in permutation matrices (P) and their transformed counterparts (B<sup>T</sup>P), where B is a random orthogonal matrix. The results are shown for different matrix dimensions (n = 3, 5, 10, 20, 50), demonstrating that the transformation significantly reduces the likelihood of -1 being an eigenvalue, thus improving the efficacy of the proposed method.", "section": "C Boundary issues in representation of permutation matrix"}, {"figure_path": "pMJFaBzoG3/tables/tables_20_1.jpg", "caption": "Table 1: l1-Distance (converted by log(1 + x)) and Precision (%) of algorithms for finding mode connectivity across different network architectures.", "description": "This table presents the results of comparing different algorithms for finding mode connectivity across various network architectures (MLP5, VGG11, and ResNet18).  The metrics used are l1-distance (after applying a logarithmic transformation for better scaling) and precision.  Lower l1-distance indicates better performance, and higher precision means a greater accuracy in finding the correct weight permutation. The results demonstrate that the proposed OT4P method outperforms the baselines (Weight Matching and Sinkhorn) in most cases.", "section": "4.1 Finding mode connectivity"}, {"figure_path": "pMJFaBzoG3/tables/tables_21_1.jpg", "caption": "Table 5: Recall (%) and Hamming Distance of algorithms for inferring neuron identities across different proportions of known neurons.", "description": "This table presents the results of three algorithms (Naive, Gumbel-Sinkhorn, and OT4P) for inferring neuron identities under different conditions (5%, 10%, and 20% known neurons).  The metrics used for evaluation are Recall and Hamming Distance.  The results show that OT4P generally outperforms the other algorithms across all conditions, achieving near-perfect recall in most cases, while Naive and Gumbel-Sinkhorn perform less well, especially when fewer neurons are known. The Hamming distance metric indicates how many neuron identities were incorrectly inferred.", "section": "4.2 Inferring neuron identities"}, {"figure_path": "pMJFaBzoG3/tables/tables_22_1.jpg", "caption": "Table 6: l1-Distance between the matrix returned by the algorithms and its closest permutation matrix. In each object class, we select the largest problem instance size that is a multiple of five.", "description": "This table presents the l1-distance between the matrices produced by different algorithms and their nearest permutation matrices for the largest problem instance size (a multiple of five) in each object class of the WILLOW-ObjectClass dataset.  It shows how close the algorithms' results are to actual permutation matrices, which is a measure of how well they handle the permutation relaxation task. Lower values indicate that the algorithm's output is closer to an actual permutation matrix.", "section": "4.3 Solving permutation synchronization"}, {"figure_path": "pMJFaBzoG3/tables/tables_22_2.jpg", "caption": "Table 7: F-scores (%) for different algorithms with various optimizers on the WILLOW-ObjectClass dataset. In each object class, we select the largest problem instance size that is a multiple of five.", "description": "This table compares the performance of different optimization algorithms (SGD and Adam) on the WILLOW-ObjectClass dataset for the task of permutation synchronization.  It evaluates the algorithms' F-scores across five object classes (Car, Duck, Face, Motorbike, Winebottle), showing the impact of optimizer choice on the effectiveness of each method.  The largest problem instance size, that is a multiple of five, is used for each class.", "section": "4.3 Solving permutation synchronization"}]