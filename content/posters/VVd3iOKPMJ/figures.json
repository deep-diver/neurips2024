[{"figure_path": "VVd3iOKPMJ/figures/figures_1_1.jpg", "caption": "Figure 1: Learning from Offline Foundation Features with Tensor Augmentations (LOFF-TA). Training data is passed through a foundation model and cached. The cached embeddings are loaded and spatial tensor augmentations are applied in lieu of standard image augmentations. A lightweight classifier is trained on the cached, augmented features. This enables the use of arbitrarily large foundation models and high-resolution images at no additional cost.", "description": "This figure illustrates the LOFF-TA framework.  Training data is first processed by a pre-trained foundation model (like a Vision Transformer), and the resulting feature embeddings are cached. These embeddings, not the original images, are then used to train a smaller, more efficient classifier.  Instead of applying typical data augmentation techniques to images (which would require storing many augmented image embeddings, increasing storage costs), tensor augmentations are applied directly to the cached feature embeddings. This method allows the use of much larger foundation models and high-resolution images without increasing computational demands.", "section": "1 Introduction"}, {"figure_path": "VVd3iOKPMJ/figures/figures_2_1.jpg", "caption": "Figure 2: Overview of LOFF-TA. Step 1: We leverage a foundation model to process the training data and store the extracted features offline. Step 2: The cached tensors are loaded, tensor augmentations are applied, then the augmented tensors are passed through projection and normalization layers and used to train a lightweight classifier. The tensor augmentations include spatial-based transforms, such as flips and crops, along with additive Gaussian noise. An optional pooling step (dashed operation) reduces the spatial dimension of the stored features, allowing for training with high-resolution images at no additional cost.", "description": "This figure illustrates the two-step process of LOFF-TA.  In Step 1, training data is passed through a foundation model to extract features, which are then cached.  Step 2 involves loading these cached features, applying tensor augmentations (flips, crops, noise), passing them through a projection and normalization layer, and finally training a lightweight classifier on the augmented features.  An optional pooling step is shown, which reduces the spatial dimension of features to enable training with high-resolution images without increased compute.", "section": "3 Methods"}, {"figure_path": "VVd3iOKPMJ/figures/figures_12_1.jpg", "caption": "Figure 3: CKA similarities between different models. Left: Representation similarity of different classifiers after fine-tuning on Oxford-III-Pet. Right: Representation similarity of the internal layers of each classifier with itself before and after fine-tuning.", "description": "This figure shows the results of a Centered Kernel Alignment (CKA) analysis to compare the representational similarities between different models. The left panel displays the representation similarity between classifiers trained using different methods on the Oxford-III-Pet dataset. The right panel shows the internal representational similarity of each classifier (trained using different methods) before and after fine-tuning. The results are intended to illustrate how the different training methods affect the learned feature representations of the classifiers.", "section": "Appendix"}, {"figure_path": "VVd3iOKPMJ/figures/figures_13_1.jpg", "caption": "Figure 4: Robustness and spatial consistency of features. Images along with a random channel of the corresponding foundation features reveal the spatial consistency between objects in the image and feature spaces. This consistency allows insights from the image space to guide tensor augmentation choice, e.g. if vertical flips are harmful for a building facade dataset in image space, they are likely to be harmful in feature space. However, we observe that training with LOFF-TA is more robust against \u2018incorrect\u2019 augmentation choices compared to standard classifier training on images.", "description": "This figure demonstrates the spatial consistency between images and their corresponding foundation model features.  The similarity allows for informed choices in tensor augmentations.  The example shows that if a vertical flip negatively affects a building facade in the image, it's likely to have a similar negative impact when using that augmentation on the features.  The experiment shows that LOFF-TA is more resilient to incorrect augmentation choices than a standard classifier trained on images.", "section": "C Tensor augmentations"}]