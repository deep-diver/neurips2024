[{"type": "text", "text": "Alleviate Anchor-Shift: Explore Blind Spots with Cross-View Reconstruction for Incomplete Multi-View Clustering ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Suyuan Liu1 Siwei Wang2 Ke Liang1 Junpu Zhang1 Zhibin Dong1 Tianrui Liu1 En Zhu1 Kunlun He3 Xinwang Liu1\u2217 ", "page_idx": 0}, {"type": "text", "text": "National University of Defense Technology, Changsha, China 2Academy of Military Sciences, Beijing, China 3 Chinese PLA General hospital, Beijing, China {suyuanliu, enzhu, xinwangliu}@nudt.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Incomplete multi-view clustering aims to learn complete correlations among samples by leveraging complementary information across multiple views for clustering. Anchor-based methods further establish sample-level similarities for representative anchor generation, effectively addressing scalability issues in large-scale scenarios. Despite efficiency improvements, existing methods overlook the misguidance in anchors learning induced by partial missing samples, i.e., the absence of samples results in shift of learned anchors, further leading to sub-optimal clustering performance. To conquer the challenges, our solution involves a cross-view reconstruction strategy that not only alleviate the anchor shift problem through a carefully designed cross-view learning process, but also reconstructs missing samples in a way that transcends the limitations imposed by convex combinations. By employing affine combinations, our method explores areas beyond the convex hull defined by anchors, thereby illuminating blind spots in the reconstruction of missing samples. Experimental results on four benchmark datasets and three large-scale datasets validate the effectiveness of our proposed method. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In multi-view learning, data collected from different sensors or media often suffer from missing values [1, 2, 3, 4]. For example, remote sensing images collected from various sensors may experience partial missing due to channel noise. Traditional multi-view learning methods cannot directly handle these missing values [5, 6, 7]. To address this issue, incomplete multi-view learning methods have been developed to leverage the available data from all views to perform downstream tasks [8, 9, 10]. Among these, incomplete multi-view clustering (IMC) relies on view consistency and complementarity, effectively enabling the partitioning of data with missing values [11, 12, 13]. ", "page_idx": 0}, {"type": "text", "text": "Existing IMC methods can be categorized into three types based on their approach: similarity-based, imputation-based, and matrix decomposition-based methods. Similarity-based methods recover a relationship matrix among all samples using available data in each view [14, 15, 16, 17, 18]. Imputation-based methods first fill in the missing parts, transforming the problem into a complete multi-view clustering problem [19, 20, 21]. Matrix decomposition-based methods map samples from all views into a common latent space to construct a unified representation for clustering [22, 23, 24, 24, 25]. However, these methods all require constructing an $n\\times n$ similarity matrix, resulting in an ${\\mathcal{O}}(n^{2})$ space complexity, which limits their application to large-scale scenarios [26, 27, 28]. ", "page_idx": 0}, {"type": "image", "img_path": "4pIfc51fGK/tmp/939d737fe2aea6a458bf08b9c2a1b079b0fcf3cc6402a942dade936baecd7ef7.jpg", "img_caption": ["Figure 1: (a)Anchors learned in complete data. (b)Anchors initialized in incomplete data. (c)Data reconstructed with convex combination. (d)Data reconstructed with affine combination. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In contrast, anchor-based IMC methods reduce space complexity to $\\mathcal{O}(n)$ by learning a small number of representative anchors from the data and replacing the full similarity matrix with relationships between anchors and samples [29, 30, 29, 31]. Despite addressing scalability, these methods overlook the anchor-shift problem caused by missing data. As shown in Fig. 1(a)(b), anchor learning can be misled by missing data, resulting in a discrepancy between learned anchors and those from complete data. This problem diminishes the representational capacity of anchors and causes the anchor graphs to be misaligned across views, thereby compromising the clustering performance. ", "page_idx": 1}, {"type": "text", "text": "In this work, we propose a novel Anchor-based Incomplete Multi-view Clustering with CrossView Reconstruction strategy, termed AIMC-CVR. AIMC-CVR encompasses two key modules designed to resolve the anchor-shift problem in anchor-based IMC. The first module, the cross-view anchor learning module, is dedicated to mitigating the anchor-shift problem by learning a complete anchor graph. Specifically, we designed a symmetrized cross-view projection mechanism to ensure dimensional consistency across view pairs. By leveraging the relationships between anchors and samples across different view pairs, we constructed a complete anchor graph. ", "page_idx": 1}, {"type": "text", "text": "The second module, the affine combination-based reconstruction module, iteratively updates the anchors with available and reconstructed data. Existing anchor-based IMC methods often use convex constraints to build relationships between anchors and samples [32, 33, 34, 35], leading to blind spots in sample reconstruction. As shown in Fig. 1(c), samples reconstructed based on convex combinations are restricted to the convex hull of the anchors. Instead of relying on convex combinations, our innovative approach utilizes an affine combination-based reconstruction strategy. This strategy broadens the scope of sample reconstruction, as depicted in Fig. 1(d), allowing for a more comprehensive and accurate representation of missing data. ", "page_idx": 1}, {"type": "text", "text": "Our main contributions are as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 By employing cross-view anchor learning and affine combination-based reconstruction, we effectively alleviate the anchor-shift problem in missing data scenarios.   \n\u2022 Unlike traditional sample-level imputation methods, we reconstruct missing samples with anchors and anchor graphs, significantly reducing reconstruction complexity. Affine combinations further explore blind spots in sample reconstruction, as demonstrated by theoretical analysis and experimental results.   \n\u2022 Comparative experiments with state-of-the-art IMC and anchor-based IMC methods validate the effectiveness and superiority of AIMC-CVR. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Cross-View Learning. Cross-view learning is a specialized form of multi-view learning that leverages interactions between paired views to learn cross-view representations, enabling the exploration of finer-grained inter-view relationships [36, 37, 38]. For instance, Tang et al. ensure local structural consistency across views by simultaneously constructing similarity graphs between pairs of views and within each view [39]. Similarly, Liu et al. leverage the fact that samples are always present in at least one view, constructing a complete cross-view similarity matrix based on relationships within and between views [40]. These methods demonstrate the potential of cross-view learning to maintain structural consistency and fully utilize the available data. In the next section, we will explore the application of cross-view learning strategies to multi-view anchor learning, focusing on view complementarity to construct a complete anchor graph and mitigate the anchor-shift problem in scenarios with missing data. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Sample-Level Imputation. Imputation-based multi-view clustering methods first impute the missing data before clustering [41, 42, 21]. Typically, existing methods perform sample-level imputation by leveraging multi-view information to learn complete similarity relationships between samples. For example, Yin et al. reconstruct missing data based on the decomposition matrix and sample similarity relationships [20]. Liu et al. integrate data imputation and clustering within a unified optimization framework [19]. However, these sample-level imputation methods typically rely on similarity matrices of size $O(n^{2})$ , which limits their scalability for large datasets. ", "page_idx": 2}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we introduce the Anchor-based Incomplete Multi-view Clustering with Cross-View Reconstruction (AIMC-CVR) strategy. We begin by introducing the two core modules: the cross-view anchor learning module and the affine combination-based reconstruction module. We provide a theoretical analysis that demonstrate the merits of our proposed affine combination-based reconstruction strategy. Finally, we present the overall objective function of the algorithm and propose a four-step alternating iterative algorithm to solve the corresponding optimization problem. ", "page_idx": 2}, {"type": "text", "text": "3.1 Cross-View Anchor Learning Module ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given multi-view data $\\left\\{{\\bf X}^{\\left(p\\right)}\\in\\mathbb{R}^{d_{p}\\times n}\\right\\}_{p=1}^{v}$ n vp=1, where dp and n denotes the dimension of the data and the total number of samples, respectively. ", "page_idx": 2}, {"type": "text", "text": "In the context of incomplete data scenarios, the data matrix $\\mathbf{X}^{\\left(p\\right)}$ for the $p$ -th view can be partitioned into two distinct subsets, i.e., $[\\mathbf{X}_{o}^{(p)},\\mathbf{X}_{m}^{(p)}]$ , where $\\mathbf{X}_{o}^{\\left(p\\right)}\\in\\mathbb{R}^{d_{p}\\times n_{p}}$ representing the existing portion of the data, and $\\mathbf{X}_{m}^{\\left(p\\right)}\\in\\mathbb{R}^{d_{p}\\times\\left(n-n_{p}\\right)}$ is the missing portion. The observed part is obtained by applying an index matrix $\\mathbf{G}^{\\left(p\\right)}\\in\\left\\{0,1\\right\\}^{n\\times n_{p}}$ to the complete data matrix, such that $\\mathbf{X}_{o}^{\\left(p\\right)}=\\mathbf{X}^{\\left(p\\right)}\\mathbf{G}^{\\left(p\\right)}$ . The index matrix $\\mathbf{G}^{\\left(p\\right)}$ encodes the presence of samples, where indicates that the $i$ -th sample in the complete dataset corresponds to the $j$ -th ranked existing sample in the observed subset $\\mathbf{X}_{o}^{\\bar{(p)}}$ . Based on the samples present in each view, we can learn the anchors and their corresponding anchor graphs as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{min}_{\\mathbf{A}^{(p)},\\mathbf{Z}^{(p)}}\\sum_{p=1}^{v}\\left\\|\\mathbf{X}_{o}^{(p)}-\\mathbf{A}^{(p)}\\mathbf{Z}^{(p)}\\mathbf{G}^{(p)}\\right\\|_{\\mathbf{F}}^{2},}\\\\ &{\\quad\\quad\\quad\\mathrm{s.t.~}\\mathbf{Z}^{(p)^{\\top}}\\mathbf{1}=\\mathbf{1},\\mathbf{Z}^{(p)}\\ge0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The anchor graph $\\mathbf{Z}^{(p)}$ is incomplete, representing only the relationship between existing samples and anchors in the $p$ -th view. While a complete anchor graph can be synthesized from all views through late-fusion, this process is compromised by the inherent misalignment of anchor graphs caused by view discrepancy. This discrepancy, known as the anchor-shift problem, arises because anchors learned from $n_{p}$ samples differ from those learned from complete data. Consequently, varying missing samples across views lead to inconsistent anchor-shift, resulting in misaligned anchor graphs at the representation level. ", "page_idx": 2}, {"type": "text", "text": "To address this issue, we propose a cross-view anchor learning module. This module constructs a complete anchor graph under the assumption that each sample appears in at least one view in the incomplete multi-view scenario. Specifically, for the anchor graph $\\mathbf{Z}^{(p)}$ in the $p$ -th view, we update it with the following objective: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{{\\bf W}^{(p q)},{\\bf A}^{(p)},{\\bf Z}^{(p)}}{\\operatorname*{min}}\\sum_{q=1}^{v}\\left\\|{\\bf W}^{(p q)}{\\bf X}_{o}^{(q)}-{\\bf W}^{(q p)}{\\bf A}^{(p)}{\\bf Z}^{(p)}{\\bf G}^{(q)}\\right\\|_{\\bf F}^{2},}\\\\ &{\\quad\\quad\\mathrm{s.t.}\\;{\\bf W}^{(p q)}{}^{\\top}{\\bf W}^{(p q)}={\\bf I},{\\bf Z}^{(p)}{}^{\\top}{\\bf1}={\\bf1},{\\bf Z}^{(p)}\\ge0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbf{W}^{(p q)}$ is the projection matrix, which projects the dimension-reduced data into a higherdimensional space. Unlike previous approaches that reduce all data to the same lower dimension, we aim to preserve high-dimensional features across views as much as possible to ensure the effectiveness of cross-view learning. A symmetric cross-view projection mechanism is designed to ensure dimensional consistency between different view pairs: if $d_{p}>d_{q}$ , $\\mathbf{W}^{(p q)}$ is the projection matrix that needs to be optimized; otherwise, $\\mathbf{W}^{(p q)}$ equals the identity matrix, as shown below: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{W}^{(p q)}=\\left\\{\\begin{array}{l l}{\\mathbf{W}^{(p q)}\\in\\mathbb{R}^{d_{p}\\times d_{q}},}&{d_{p}>d_{q},}\\\\ {\\mathbf{I}\\in\\mathbb{R}^{d_{q}\\times d_{q}},}&{d_{p}\\le d_{q}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "By sequentially learning the similarity between the $n_{q}$ points present in the $q$ -th view (where $q=1,\\ldots,v)$ and the $m$ anchors in the $p$ -th view, we can obtain an anchor graph with a size of $m\\times n$ . Furthermore, the complete anchor graph can guide the learning of anchors, thereby implicitly alleviating the anchor-shift problem. ", "page_idx": 3}, {"type": "text", "text": "3.2 Affine Combination-based Reconstruction Module ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The cross-view anchor learning module flils the missing columns of the anchor graph by measuring the distance between the existing samples in other views and the anchors of the current view in the same space with a projection matrix, which avoids recovering the missing samples. However, the measurement of similarity between cross-view representations is overly dependent on the reliability of the projection matrix and the consistency between views. Additionally, simply relying on cross-view information to implicitly correct anchor shifts is insufficient. Therefore, we propose to recover the incomplete data in each view to directly correct the anchors affected by the missing parts. Traditional imputation methods, which reconstruct missing data based on the similarity among all samples, require an additional quadratic space complexity, making them impractical for large-scale problems. Thus, we propose a fast reconstruction module, as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\operatorname*{min}_{\\mathbf{X}_{m}^{(p)},\\mathbf{A}^{(p)},\\mathbf{Z}^{(p)}}\\sum_{p=1}^{v}\\left\\|\\left[\\mathbf{X}_{o}^{(p)},\\mathbf{X}_{m}^{(p)}\\right]-\\mathbf{A}^{(p)}\\mathbf{Z}^{(p)}\\right\\|_{\\mathbf{F}}^{2},}\\\\ {\\displaystyle\\mathrm{s.t.~}\\mathbf{Z}^{(p)}^{\\top}\\mathbf{1}=\\mathbf{1},\\mathbf{Z}^{(p)}\\geq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbf{X}_{o}^{\\left(p\\right)}\\in\\mathbb{R}^{d_{p}\\times n_{p}}$ represents the existing samples in the view, and $\\mathbf{X}_{m}^{\\left(p\\right)}\\in\\mathbb{R}^{d_{p}\\times n-n_{p}}$ represents the missing samples to be reconstructed. $\\mathbf{X}_{m}^{\\left(p\\right)}$ is constructed from the anchors and their corresponding anchor graphs. The reconstructed $\\mathbf{X}_{m}^{\\left(p\\right)}$ then participates in the next iteration of anchor learning, with the reconstruction of missing samples and anchor learning iterating and mutually reinforcing each other. Accurately reconstructed $\\mathbf{X}_{m}^{\\left(p\\right)}$ enables the learned anchors in the next iteration to be closer to the true global anchors, whereas inaccurate reconstruction exacerbates the anchor-shift problem. However, the reconstructed missing samples are constrained within the convex hull of the anchor set in Eq. (4). According to Theorem 1, there always exist samples that cannot be reconstructed by the convex combination of anchors. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1. Suppose $\\mathbf{A}=\\{a_{1},\\dots,a_{m}\\}$ is an anchor set composed of cluster centers from the dataset $\\mathbf{X}=\\{x_{1},\\ldots,x_{n}\\}$ . Then, there always exist a sample c belonging to $\\mathbf{X}$ that lies outside the convex hull of the anchor set A. Mathematically, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\operatorname*{min}_{\\mathbf{f}}\\big\\|\\sum_{i=1}^{m}f_{i}a_{i}-c\\big\\|_{2}^{2}>0,\\exists c\\in\\mathbf{X},}\\\\ {\\displaystyle s.t.~\\mathbf{f}^{\\top}\\mathbf{1}=1,\\mathbf{f}\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "When most missing samples are outside the convex hull of the anchors, the next iteration of anchor learning erroneously shifts inward, worsening anchor-shift. Therefore, we propose an affine", "page_idx": 3}, {"type": "text", "text": "combination based reconstruction strategy, which relaxes convex constraints on anchor graph rows to affine ones. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{{\\bf X}_{m}^{(p)},{\\bf A}^{(p)},{\\bf Z}^{(p)}}{\\operatorname*{min}}\\sum_{p=1}^{v}\\left\\|\\left[{\\bf X}_{o}^{(p)},{\\bf X}_{m}^{(p)}\\right]-{\\bf A}^{(p)}{\\bf Z}^{(p)}\\right\\|_{\\bf F}^{2},}\\\\ &{\\times\\underset{{\\bf S}.{\\bf L}.}{\\operatorname*{min}}\\sum_{\\bf{I}^{(p)}}^{\\top}\\!\\!{\\bf1}={\\bf1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Theorem 2. For a sample c lying outside the convex hull of the anchor set A, the representation constructed by the affine combination of set A is always closer to c than that constructed by the convex combination of set A. Mathematically, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{g}}{\\operatorname*{min}}\\left\\|\\sum_{i=1}^{m}g_{i}a_{i}-c\\right\\|_{2}^{2}<\\underset{\\mathbf{f}}{\\operatorname*{min}}\\left\\|\\sum_{i=1}^{m}f_{i}a_{i}-c\\right\\|_{2}^{2},}\\\\ &{\\qquad\\qquad s.t.\\;\\mathbf{g}^{\\top}\\mathbf{1}=1,\\mathbf{f}^{\\top}\\mathbf{1}=1,\\mathbf{f}\\geq0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "According to Theorem 2, utilizing the affine combination of anchors facilitates the recovery of more accurate missing samples. Ultimately, by combining the cross-view anchor learning module with the affine-combination based reconstruction module, the objective of AIMC-CVR is as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\b{\\Phi}}{\\operatorname*{min}}\\underset{p=1}{\\sum_{p=1}^{v}}\\left\\|\\left[\\mathbf{X}_{o}^{(p)},\\mathbf{X}_{m}^{(p)}\\right]-\\mathbf{A}^{(p)}\\mathbf{Z}^{(p)}\\right\\|_{\\mathbf{F}}^{2}+\\beta\\underset{p=1}{\\sum_{p=1}^{v}}\\left\\|\\mathbf{Z}^{(p)}\\right\\|_{\\mathbf{F}}^{2}}\\\\ &{\\quad+\\lambda\\underset{p=1}{\\sum_{p=1}^{v}}\\underset{q=1}{\\overset{v}{\\sum_{q=1}^{v}}}\\left\\|\\mathbf{W}^{(p q)}\\mathbf{X}_{o}^{(q)}-\\mathbf{W}^{(q p)}\\mathbf{A}^{(p)}\\mathbf{Z}^{(p)}\\mathbf{G}^{(q)}\\right\\|_{\\mathbf{F}}^{2},}\\\\ &{\\qquad\\qquad\\mathrm{s.t.}\\ \\mathbf{W}^{(p q)^{\\top}}\\mathbf{W}^{(p q)}=\\mathbf{I},\\mathbf{Z}^{(p)^{\\top}}\\mathbf{1}=\\mathbf{1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\Phi=\\left\\{\\mathbf{X}_{m}^{\\left(p\\right)},\\mathbf{W}^{\\left(p q\\right)},\\mathbf{A}^{\\left(p\\right)},\\mathbf{Z}^{\\left(p\\right)}\\right\\}$ . The hyperparameter $\\beta$ helps to adjust the sparsity of the anchor graph, and $\\lambda$ is a hyperparameter balancing the influence of the two modules. Finally, we concatenate the anchor graph from each view to obtain the common one, ${\\bf Z}=\\,\\left[{\\bf Z}^{(1)};\\ldots;{\\bf\\bar{Z}}^{(v)}\\right]$ , which avoids the anchor alignment problem present in other fusion methods [33]. Note that the columns of $\\mathbf{Z}$ still consist of ones, ensuring that its recovered transition probability matrix $\\mathbf{S}$ is a doubly stochastic matrix, as proven in the appendix. Therefore, directly performing $k$ -means clustering on the left singular vectors of $\\mathbf{Z}$ yields the final clustering results [26]. ", "page_idx": 4}, {"type": "text", "text": "3.3 Optimization ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To solve the optimization problem in Eq. (8), we propose a four step alternating iterative algorithm. When optimizing a variable, the other variables are fixed to their previous iteration values. Additionally, since each variable is independent across views, we update them sequentially by view. ", "page_idx": 4}, {"type": "text", "text": "Step 1: Update $\\mathbf{X}_{m}^{\\left(p\\right)}$ . Fixing $\\mathbf{W}^{(p q)}$ , $\\mathbf{A}^{(p)}$ , $\\mathbf{Z}^{(p)}$ and removing terms unrelated to $\\mathbf{X}_{m}^{\\left(p\\right)}$ , we have the following optimization problem: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{X}_{m}^{\\left(p\\right)}}\\mathrm{Tr}\\left({\\mathbf{X}_{m}^{\\left(p\\right)}}^{\\top}\\mathbf{X}_{m}^{\\left(p\\right)}-2{\\mathbf{X}_{m}^{\\left(p\\right)}}^{\\top}\\mathbf{A}^{\\left(p\\right)}\\mathbf{Z}^{\\left(p\\right)}\\mathbf{E}^{\\left(p\\right)}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{E}^{(p)}\\in\\{0,1\\}^{n\\times n_{p}}$ is the index matrix, ${\\bf E}_{i j}^{(p)}=1$ indicates that the $i$ -th sample is ranked $j$ -th among the missing samples. By taking the derivative of Eq. (9) with respect to $\\mathbf{X}_{m}^{\\left(p\\right)}$ and setting it to zero, we obtain the closed-form solution for $\\mathbf{X}_{m}^{\\left(p\\right)}$ as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{X}_{m}^{\\left(p\\right)}=\\mathbf{A}^{\\left(p\\right)}\\mathbf{Z}^{\\left(p\\right)}\\mathbf{E}^{\\left(p\\right)}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The solution for $\\mathbf{X}_{m}^{\\left(p\\right)}$ shows that it incorporates the anchors and anchor graphs from the previous iteration, contributing to the update of anchors in the next iteration. ", "page_idx": 4}, {"type": "text", "text": "Step 2: Update $\\mathbf{W}^{(p q)}$ . Fixing $\\mathbf{X}_{m}^{\\left(p\\right)}$ , ${\\bf A}^{(p)},{\\bf Z}^{(p)}$ and removing terms unrelated to $\\mathbf{W}^{(p q)}$ , we have the following optimization problem when $d_{p}<d_{q}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{W}(p q)}{\\operatorname*{min}}\\left\\|\\mathbf{X}_{o}^{(p)}-\\mathbf{W}^{(p q)}\\mathbf{A}^{(q)}\\mathbf{Z}^{(q)}\\mathbf{G}^{(p)}\\right\\|_{\\mathbf{F}}^{2}+\\left\\|\\mathbf{W}^{(p q)}\\mathbf{X}_{o}^{(q)}-\\mathbf{A}^{(p)}\\mathbf{Z}^{(p)}\\mathbf{G}^{(q)}\\right\\|_{\\mathbf{F}}^{2},}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\mathrm{s.t.}~\\mathbf{W}^{(p q)^{\\top}}\\mathbf{W}^{(p q)}=\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "By further simplification, Eq. (11) can transform into the following form: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{W}^{\\left(p q\\right)}}{\\operatorname*{max}}\\;\\mathrm{Tr}\\left(\\mathbf{W}^{\\left(p q\\right)}\\right.^{\\top}\\mathbf{B}^{\\left(p q\\right)}\\right),}\\\\ &{\\quad}\\\\ &{\\;\\;\\mathrm{s.t.}\\;\\mathbf{W}^{\\left(p q\\right)}}^{\\top}\\mathbf{W}^{\\left(p q\\right)}=\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathbf{B}^{(p q)}\\,=\\,\\mathbf{X}_{o}^{(p)}(\\mathbf{A}^{(q)}\\mathbf{Z}^{(q)}\\mathbf{G}^{(p)})^{\\top}\\,+\\,\\mathbf{A}^{(p)}\\mathbf{Z}^{(p)}\\mathbf{G}^{(q)}\\mathbf{X}_{o}^{(p)}^{\\top}$ . According to reference [43], the optimal $\\mathbf{W}^{(p q)}$ is derived from the product of the left and right singular vectors of $\\mathbf{B}^{(p q)}$ . ", "page_idx": 5}, {"type": "text", "text": "Step 3: Update $\\mathbf{A}^{(p)}$ . Fixing $\\mathbf{X}_{m}^{\\left(p\\right)}$ , ${\\bf W}^{(p q)},{\\bf Z}^{(p)}$ and removing terms unrelated to $\\mathbf{A}^{(p)}$ , we have the following optimization problem: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{A}^{\\left(p\\right)}}\\mathrm{Tr}\\left(\\mathbf{A}^{\\left(p\\right)}\\mathbf{C}^{\\left(p\\right)}\\mathbf{A}^{\\left(p\\right)}\\right)^{\\top}-2\\mathbf{A}^{\\left(p\\right)^{\\top}}\\mathbf{D}^{\\left(p\\right)}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\begin{array}{r l r}{{\\bf C}^{(p)}}&{{}=}&{{\\bf Z}^{(p)}{\\bf Z}^{(p)^{\\top}}{\\bf\\Sigma}+{\\bf\\Sigma}\\lambda\\sum_{q=1}^{v}{\\bf Z}^{(p)}{\\bf G}^{(q)}{\\bf G}^{(q)^{\\top}}{\\bf Z}^{(p)^{\\top}},\\quad{\\bf D}^{(p)}}&{{}={\\bf\\Sigma}~{\\bf X}^{(p)}{\\bf Z}}\\end{array}$ $\\begin{array}{r}{\\lambda\\sum_{q=1}^{v}\\mathbf{W}^{\\left(q p\\right)}}^{\\top}\\mathbf{W}^{\\left(p q\\right)}\\mathbf{X}_{o}^{\\left(q\\right)}\\mathbf{G}^{\\left(q\\right)}{}^{\\top}\\mathbf{Z}^{\\left(p\\right)}}\\end{array}$ . By taking the derivative of Eq. (13) with respect to $\\mathbf{A}^{(p)}$ and setting it to zero, we obtain the closed-form solution for $\\mathbf{A}^{(p)}$ as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{A}^{(p)}=\\mathbf{D}^{(p)}\\mathbf{C}^{(p)}{}^{-1}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Step4: Update $\\mathbf{Z}^{(p)}$ . Since each column of $\\mathbf{Z}^{(p)}$ is independent of others, we optimize the $i$ -th column $\\mathbf{z}_{i}^{(p)}$ of $\\mathbf{Z}^{(p)}$ while fixing $\\mathbf{X}_{m}^{\\left(p\\right)},\\mathbf{W}^{\\left(p q\\right)},\\mathbf{A}^{\\left(p\\right)}$ as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{z}_{i}^{(p)}}{\\operatorname*{min}}\\,\\mathbf{z}_{i}^{(p)}^{\\top}\\mathbf{H}\\mathbf{z}_{i}^{(p)}-2\\mathbf{t}_{i}^{\\top}\\mathbf{z}_{i}^{(p)},}\\\\ &{\\qquad\\qquad\\mathrm{s.t.}\\;\\mathbf{z}_{i}^{(p)}^{\\top}\\mathbf{1}=1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathbf{H}=\\left(\\lambda\\sum_{q=1}^{v}\\sigma_{i}^{(q)}+1\\right)\\mathbf{A}^{(p)}{}^{\\top}\\mathbf{A}^{(p)}+\\beta\\mathbf{I},\\,\\mathbf{t}_{i}=\\lambda\\sum_{q=1}^{v}\\sigma_{i}^{(q)}\\mathbf{X}_{:,i}^{(q)^{\\top}}\\mathbf{W}^{(p q)^{\\top}}\\mathbf{W}^{(q p)}\\mathbf{A}^{(p)}+\\beta\\mathbf{I},\\,\\mathbf{t}_{i}=\\lambda\\sum_{q=1}^{v}\\sigma_{i}^{(q)}\\mathbf{X}_{:,i}^{(q)^{\\top}}\\mathbf{W}^{(p q)^{\\top}}\\mathbf{W}^{(q p)}\\mathbf{A}^{(p)}}\\end{array}$ $\\mathbf{X}_{:,i}^{\\left(p\\right)^{\\top}}\\mathbf{A}^{\\left(p\\right)}$ . When $i$ -th sample exists in the $p$ -th view $\\sigma_{i}^{(q)}\\,=\\,1\\$ , else $\\sigma_{i}^{(q)}\\,=\\,0$ . We employ the Lagrange multiplier method to tackle the above problem. Firstly, the Lagrangian function for Eq. (15) is as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{L}=\\mathbf{z}_{i}^{(p)}^{\\top}\\mathbf{H}\\mathbf{z}_{i}^{(p)}-2\\mathbf{t}_{i}^{\\top}\\mathbf{z}_{i}^{(p)}+\\alpha_{i}(\\mathbf{z}_{i}^{(p)}^{\\top}\\mathbf{1}-1),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\alpha_{i}$ is the Lagrangian multiplier. The corresponding KTT conditions is ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\mathbf{H}\\mathbf{z}_{i}^{(p)}-\\mathbf{t}_{i}+\\frac{\\alpha_{i}}{2}\\mathbf{1}=0,}\\\\ {\\mathbf{z}_{i}^{(p)}{}^{\\top}\\mathbf{1}=1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "By substituting the first term into the second, we can get $\\begin{array}{r}{\\alpha_{i}=2\\frac{(\\mathbf{H}^{-1}\\mathbf{t}_{i})^{\\top}\\mathbf{1}-1}{\\mathbf{1}^{\\top}\\mathbf{H}^{-1}\\mathbf{1}}}\\end{array}$ .Then we have ${\\mathbf z}_{i}^{(p)}=$ $\\mathbf{H}^{-1}(\\mathbf{t}_{i}-\\textstyle\\frac{\\alpha}{2}\\mathbf{1})$ . The entire optimization procedure for AIMC-CVR is summarized in Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "Input: Multi-view dataset $\\left\\{{\\bf X}^{\\left(p\\right)}\\right\\}_{p=1}^{v}$ vp=1, anchors number m, clusters number k, parameters \u03b2, \u03bb.   \n1: Initialize $\\left\\{{\\bf A}^{\\left(p\\right)}\\right\\}_{p=1}^{v}$ , $\\left\\{\\mathbf{W}^{\\left(p q\\right)}\\right\\}_{p,q=1}^{v}$ and $\\left\\{\\mathbf{Z}^{\\left(p\\right)}\\right\\}_{p=1}^{v}$   \n2: while not converged do   \n3: for $p=1\\rightarrow v$ do   \n4: Update $\\mathbf{X}_{m}^{\\left(p\\right)}$ with Eq. (10).   \n5: for $q=1\\rightarrow v$ do   \n6: Update $\\mathbf{W}^{(p q)}$ by solving Eq. (12).   \n7: end for   \n8: Update $\\mathbf{A}^{\\left(p\\right)}$ with Eq. (14).   \n9: Update $\\mathbf{Z}^{(p)}$ by solving Eq. (15).   \n10: end for   \n11: end while   \n12: Concatenate $\\mathbf{Z}^{(p)}$ to obtain $\\mathbf{Z}$ .   \nOutput: Performing $k$ -means on $\\mathbf{Z}$ to get the final cluster results. ", "page_idx": 6}, {"type": "text", "text": "3.4 Complexity Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The computational complexity of AIMC-CVR primarily consists of solving four variables. When updating $\\mathbf{X}_{m}^{\\left(p\\right)}$ , the complexity of matrix multiplication is $\\mathcal{O}(n m d_{p})$ . For updating $\\mathbf{W}^{(p q)}$ , the complexity of matrix multiplication is $\\mathcal{O}(n m d_{p}+n{d_{p}}^{2}+{d_{p}}^{3})$ , and the SVD decomposition complexity is $\\mathcal{O}(d_{p}{}^{3})$ . When optimizing $\\mathbf{A}^{(p)}$ , the complexity of matrix multiplication is $\\mathcal{O}(n m d_{p}+m^{2}d_{p}+n d_{p}d_{q})$ , and the complexity of inversion is $\\mathcal{O}(m^{3})$ . When optimizing $\\mathbf{Z}^{(p)}$ , the complexity of matrix multiplication is $\\mathcal{O}(m^{2}d_{p}{+}n m d_{p}{+}n d_{p}d_{q})$ . Therefore, in each iteration, AIMCCVR consumes a time complexity of $\\begin{array}{r}{\\mathcal{O}(n\\sum_{p=1}^{v}(m d_{p}+{d_{p}}^{2}+d_{p}\\sum_{q=1}^{v}d_{q})+\\sum_{p=1}^{v}(m^{2}d_{p}+d_{p}^{3})),}\\end{array}$ , which is linear with respect to $n$ . ", "page_idx": 6}, {"type": "text", "text": "The space complexity of AIMC-CVR is $\\begin{array}{r}{\\mathcal{O}(n(m+\\sum_{p=1}^{v}d_{p})+m\\sum_{p=1}^{v}d_{p}+\\sum_{p=1}^{v}\\sum_{q=1}^{v}d_{p}d_{q})}\\end{array}$ , primarily stemming from storing relevant matrix variables, also scales linearly with the number of samples. ", "page_idx": 6}, {"type": "text", "text": "3.5 Convergence Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we provide a theoretical analysis of the convergence of our proposed AIMC-CVR. The objective function in Eq. (8) is non-convex when considering all variables simultaneously. To address this, we employ a four-step iterative optimization algorithm, detailed in Algorithm 1, where each variable is optimized sequentially while keeping the others fixed. During each iteration, the variables being optimized have analytical solutions, ensuring that the objective function of AIMCCVR decreases monotonically with successive iterations. Furthermore, since the objective function in Eq. (8) is bounded below by zero, our proposed AIMC-CVR is guaranteed to converge to a local minimum. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets description. Seven widely used multi-view datasets are employed to evaluate the performance of AIMC-CVR, including: MSRCV [44] is composed of images from seven categories. $\\begin{array}{r}{\\mathbf{WebKB}^{2}}\\end{array}$ contains text and citations collected from the website. Wiki [45] is a dual-view dataset with text-image pairs. Hdigit3 is a dataset composed of handwritten digit images. YTF10 and YTF20 are two subsets extracted from the YouTubeFace4 dataset. MNIST5 is a subset extracted from a larger dataset supplied by NIST. Details of these datasets are list in the Table 1. Following [26], we randomly remove $10\\%$ to $90\\%$ of the samples in $10\\%$ intervals to create missing versions of the above datasets, which ensures each sample exists in at least one view. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "table", "img_path": "4pIfc51fGK/tmp/6466d3088539e6ccd033769ee95ce3ae949e97721a16440a1684e25577b54012.jpg", "table_caption": ["Table 1: Employed datasets in experiments. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Compared methods. We compared our proposed method with the following eight state-of-the-art incomplete multi-view clustering algorithms: DAIMC[22], UEAF[23], EEIMVC[19], FLSD[24], $\\mathrm{V}^{3}\\mathrm{H}[\\bar{1}5]$ , IMVC-CBG[26], SCBGL[29], DVSAI[31]. The first five comparison methods are traditional similarity-based approaches, while the latter three are large-scale anchor-based methods. ", "page_idx": 7}, {"type": "text", "text": "Implementation details. For all comparison algorithms, we set the parameters according to their descriptions in the corresponding literature. In our method, the anchors number is searched in $[k,2k,3k]$ , and the parameter $\\lambda$ and $\\beta$ are both searched in $[0.001,0.01,0.1,1,10,100]$ . To evaluate the clustering performance, we employ accuracy (ACC), normalized mutual information (NMI), Purity, and Fscore for comparison. Each compared algorithm was tested across datasets with different missing rates, and the results for each missing rate were averaged to obtain the clustering results. Additionally, we conduct 20 repetitions of the $k$ -means step for all algorithms and calculate the mean and variance for the final experimental result. All experiments were conducted on a desktop computer equipped with an Intel Core i9-10900X CPU, 64GB of RAM. ", "page_idx": 7}, {"type": "text", "text": "4.2 Clustering Performance Comparison ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We compare AIMC-CVR with eight state-of-the-art algorithms across seven datasets, as shown in Table 2. Our algorithm demonstrates superior or competitive clustering performance across all datasets, highlighting its effectiveness. On smaller datasets such as MSRCV, WebKB, Wiki, and Hdigit, our method achieves the highest ACC in all cases, surpassing the second-best algorithms by $3.65\\%$ , $7.89\\%$ , $0.19\\%$ and $3.96\\%$ . This showcases our algorithm\u2019s robustness and efficacy in handling incomplete multi-view datasets. Furthermore, Fig. 2 shows the clustering accuracy (ACC) curves for all algorithms across different datasets as the missing rate varies. Our algorithm consistently outperforms all others at every missing rate, demonstrating its superiority. ", "page_idx": 7}, {"type": "text", "text": "Additionally, our method demonstrates excellent scalability, successfully processing three large-scale datasets that the traditional methods cannot handle due to memory constraints. By addressing the anchor-shift problem, which was overlooked by other three anchor-based methods (IMVC-CBG, SCBGL, DVSAI), we achieved a notable enhancement in clustering performance. Specifically, on YTF10, YTF20, and MNIST datasets, our algorithm achieves ACC improvements over the second-best algorithms by $3.18\\%$ , $0.42\\%$ and $7.47\\%$ . ", "page_idx": 7}, {"type": "text", "text": "4.3 Ablation Study ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "To showcase the effectiveness of different modules and strategies, we constructed five variants of AIMC-CVR as follows: (1) AIMC-CVR-v1 removes the cross-view anchor learning module by setting $\\lambda=0$ . (2) AIMC-CVR-v2 removes the affine combination-based reconstruction module. (3) AIMC-CVR-v3 removes the sparsity regularization term by setting $\\beta=0$ . (4) AIMC-CVR-v4 keeps the initialized $\\mathbf{A}^{(p)}$ fixed and does not update it during subsequent optimization. (5) AIMC-CVR-v5 replaces affine combination with convex combination by adding non-negative constraints to $\\mathbf{Z}^{(p)}$ . ", "page_idx": 7}, {"type": "table", "img_path": "4pIfc51fGK/tmp/3fc92f8a623d855ce89a780e5b9b3e47b74e1977e79dc01d2a4f460fe0170f78.jpg", "table_caption": ["Table 2: Clustering performance on seven datasets. \u2019-\u2019 means unable to run due to memory limitation. "], "table_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "4pIfc51fGK/tmp/9454648be44d2c55f7fbbc169938b69178bfcfc61bf18ba78fa2a6137dae9331.jpg", "img_caption": ["Figure 2: The curves for ACC across different datasets as the missing rate varies. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "The comparison results between the above variants and our method are shown in Table 3. Both modules in AIMC-CVR are essential, the absence of either one leads to decreased clustering performance as shown in AIMC-CVR-v1 and AIMC-CVR-v2. Compared with AIMC-CVR-v3, appropriate constraints on the sparsity of $\\mathbf{Z}^{(p)}$ can prevent excessively divergent values. AIMC-CVR-v4 uses initial anchors learned from single-view data with missing samples, leading to anchor-shift problem, while our method effectively mitigates it and enhances clustering results. Compared to AIMC-CVR-v5, our method achieves better performance by reconstructing missing samples with affine combination of anchors, which leads to more accurate learning of anchors and anchor graphs. ", "page_idx": 8}, {"type": "text", "text": "4.4 Convergence Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Fig. 3 illustrates the objective value of our proposed algorithm against the number of iterations on four datasets. The algorithm shows rapid convergence within the first 50 iterations for all datasets. The objective value decreases significantly in the initial iterations and gradually stabilizes, indicating efficient attainment of an optimal or near-optimal solution. This rapid convergence is especially notable on the MSRCV and WebKB datasets, where the objective value plateaus before 50 iterations. ", "page_idx": 8}, {"type": "text", "text": "The consistent convergence patterns across different datasets validate the robustness and efficiency of our algorithm in handling incomplete multi-view clustering tasks. ", "page_idx": 9}, {"type": "table", "img_path": "4pIfc51fGK/tmp/e3bfe26adbee17d7e52d12061363d201adab8160cc696ff10e8a691122275175.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "4pIfc51fGK/tmp/2e6c7f5020c3ec6cc48182a37a158949cdabe994aba55ab4e5e2f8bf3ddab259.jpg", "img_caption": ["Figure 3: Variation of the objective value with increasing iteration number on four datasets. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "4pIfc51fGK/tmp/6ca4ac53fc3236a8f48ab49720fb5c3f605c665c7e1eb61d1cda647433e628a0.jpg", "img_caption": ["Figure 4: Sensitivity analysis of $\\beta$ and $\\lambda$ on four datasets. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "4.5 Parameter Analysis ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "AIMC-CVR has two main hyperparameters: $\\beta$ controls the sparsity of the anchor graph and $\\lambda$ controls the weight of the cross-view learning module. We test the performance of AIMC-CVR with different combinations of these hyperparameters, as shown in Fig. 4. The impact of these parameters varies across datasets, but values of $\\beta$ and $\\lambda$ close to 1 generally perform well. Experimental results shows that the cross-view learning module is crucial for constructing complete anchor graphs, while $\\beta$ ensures the graph to be not too sparse. Proper parameter settings lead to good clustering results. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we introduce an AIMC-CVR method to alleviate the anchor-shift problem in anchorbased incomplete multi-view clustering. Additionally, we explore the blind spots in sample reconstruction with affine combination. Experiments and theoretical analysis validate the effectiveness of the proposed AIMC-CVR method. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgment ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work is supported by National Science and Technology Innovation 2030 Major Project under Grant No. 2022ZD0209103, the National Science Fund for Distinguished Young Scholars of China (No. 62325604), and the National Natural Science Foundation of China (No. 62276271, 62476281 and 62406329). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Yuze Tan, Yixi Liu, Shudong Huang, Wentao Feng, and Jiancheng Lv. Sample-level multi-view graph clustering. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 23966\u201323975, 2023.   \n[2] Zongmo Huang, Yazhou Ren, Xiaorong Pu, Shudong Huang, Zenglin Xu, and Lifang He. Selfsupervised graph attention networks for deep weighted multi-view clustering. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 7936\u20137943, 2023.   \n[3] Jing Li, Quanxue Gao, Qianqian Wang, Ming Yang, and Wei Xia. Orthogonal non-negative tensor factorization based multi-view clustering. Advances in Neural Information Processing Systems, 36, 2024.   \n[4] Yalan Qin, Nan Pu, and Hanzhou Wu. Edmc: Efficient multi-view clustering via cluster and instance space learning. IEEE Transactions on Multimedia, 2023.   \n[5] Lusi Li, Zhiqiang Wan, and Haibo He. Incomplete multi-view clustering with joint partition and graph learning. IEEE Transactions on Knowledge and Data Engineering, 35(1):589\u2013602, 2021.   \n[6] Zhenglai Li, Chang Tang, Xiao Zheng, Xinwang Liu, Wei Zhang, and En Zhu. High-order correlation preserved incomplete multi-view subspace clustering. IEEE Transactions on Image Processing, 31:2067\u20132080, 2022.   \n[7] Yiming Wang, Dongxia Chang, Zhiqiang Fu, Jie Wen, and Yao Zhao. Incomplete multiview clustering via cross-view relation transfer. IEEE Transactions on Circuits and Systems for Video Technology, 33(1):367\u2013378, 2022.   \n[8] Jie Xu, Chao Li, Liang Peng, Yazhou Ren, Xiaoshuang Shi, Heng Tao Shen, and Xiaofeng Zhu. Adaptive feature projection with distribution alignment for deep incomplete multi-view clustering. IEEE Transactions on Image Processing, 32:1354\u20131366, 2023.   \n[9] Jie Wen, Gehui Xu, Chengliang Liu, Lunke Fei, Chao Huang, Wei Wang, and Yong Xu. Localized and balanced efficient incomplete multi-view clustering. In Proceedings of the 31st ACM International Conference on Multimedia, pages 2927\u20132935, 2023.   \n[10] Shijie Deng, Jie Wen, Chengliang Liu, Ke Yan, Gehui Xu, and Yong Xu. Projective incomplete multi-view clustering. IEEE Transactions on Neural Networks and Learning Systems, 2023.   \n[11] Jie Wen, Chengliang Liu, Gehui Xu, Zhihao Wu, Chao Huang, Lunke Fei, and Yong Xu. Highly confident local structure based consensus graph learning for incomplete multi-view clustering. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15712\u201315721, 2023.   \n[12] Shuping Zhao, Jie Wen, Lunke Fei, and Bob Zhang. Tensorized incomplete multi-view clustering with intrinsic graph completion. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 11327\u201311335, 2023.   \n[13] Jingyu Pu, Chenhang Cui, Xinyue Chen, Yazhou Ren, Xiaorong Pu, Zhifeng Hao, S Yu Philip, and Lifang He. Adaptive feature imputation with latent graph for deep incomplete multi-view clustering. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 14633\u201314641, 2024.   \n[14] Jun Guo and Jiahui Ye. Anchors bring ease: An embarrassingly simple approach to partial multiview clustering. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 118\u2013125, 2019.   \n[15] Xiang Fang, Yuchong Hu, Pan Zhou, and Dapeng Oliver Wu. V 3 h: View variation and view heredity for incomplete multiview clustering. IEEE Transactions on Artificial Intelligence, 2020.   \n[16] Jie Wen, Ke Yan, Zheng Zhang, Yong Xu, Junqian Wang, Lunke Fei, and Bob Zhang. Adaptive graph completion based incomplete multi-view clustering. IEEE Transactions on Multimedia, 23:2493\u20132504, 2020.   \n[17] Jie Wen, Zheng Zhang, Zhao Zhang, Lei Zhu, Lunke Fei, Bob Zhang, and Yong Xu. Unified tensor framework for incomplete multi-view clustering and missing-view inferring. In Proceedings of the AAAI conference on artificial intelligence, volume 35, pages 10273\u201310281, 2021.   \n[18] Cheng Liu, Rui Li, Si Wu, Hangjun Che, Dazhi Jiang, Zhiwen Yu, and Hau-San Wong. Selfguided partial graph propagation for incomplete multiview clustering. IEEE Transactions on Neural Networks and Learning Systems, 2023.   \n[19] Xinwang Liu, Miaomiao Li, Chang Tang, Jingyuan Xia, Jian Xiong, Li Liu, Marius Kloft, and En Zhu. Efficient and effective regularized incomplete multi-view clustering. IEEE transactions on pattern analysis and machine intelligence, 43(8):2634\u20132646, 2020.   \n[20] Jun Yin and Shiliang Sun. Incomplete multi-view clustering with reconstructed views. IEEE Transactions on Knowledge and Data Engineering, 35(3):2671\u20132682, 2021.   \n[21] Zhiqi Yu, Mao Ye, Siying Xiao, and Liang Tian. Learning missing instances in latent space for incomplete multi-view clustering. Knowledge-Based Systems, 250:109122, 2022.   \n[22] Menglei Hu and Songcan Chen. Doubly aligned incomplete multi-view clustering. In Proceedings of the 27th International Joint Conference on Artificial Intelligence, pages 2262\u20132268, 2018.   \n[23] Jie Wen, Zheng Zhang, Yong Xu, Bob Zhang, Lunke Fei, and Hong Liu. Unified embedding alignment with missing views inferring for incomplete multi-view clustering. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 5393\u20135400, 2019.   \n[24] Jie Wen, Zheng Zhang, Zhao Zhang, Lunke Fei, and Meng Wang. Generalized incomplete multiview clustering with flexible locality structure diffusion. IEEE transactions on cybernetics, 2020.   \n[25] Chengliang Liu, Zhihao Wu, Jie Wen, Yong Xu, and Chao Huang. Localized sparse incomplete multi-view clustering. IEEE Transactions on Multimedia, 2022.   \n[26] Siwei Wang, Xinwang Liu, Li Liu, Wenxuan Tu, Xinzhong Zhu, Jiyuan Liu, Sihang Zhou, and En Zhu. Highly-efficient incomplete large-scale multi-view clustering with consensus bipartite graph. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9776\u20139785, 2022.   \n[27] Jiaqi Jin, Siwei Wang, Zhibin Dong, Xinwang Liu, and En Zhu. Deep incomplete multi-view clustering with cross-view partial sample and prototype alignment. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11600\u201311609, 2023.   \n[28] Yulu Fu, Yuting Li, Qiong Huang, Jinrong Cui, and Jie Wen. Anchor graph network for incomplete multiview clustering. IEEE Transactions on Neural Networks and Learning Systems, 2024.   \n[29] Xiaojia Zhao, Qiangqiang Shen, Yongyong Chen, Yongsheng Liang, Junxin Chen, and Yicong Zhou. Self-completed bipartite graph learning for fast incomplete multi-view clustering. IEEE Transactions on Circuits and Systems for Video Technology, 2023.   \n[30] Xingfeng Li, Yinghui Sun, Quansen Sun, Jia Dai, and Zhenwen Ren. Distribution consistency based fast anchor imputation for incomplete multi-view clustering. In Proceedings of the 31st ACM International Conference on Multimedia, pages 368\u2013376, 2023.   \n[31] Shengju Yu, Siwei Wang, Pei Zhang, Miao Wang, Ziming Wang, Zhe Liu, Liming Fang, En Zhu, and Xinwang Liu. Dvsai: Diverse view-shared anchors based incomplete multi-view clustering. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 16568\u201316577, 2024.   \n[32] Siwei Wang, Xinwang Liu, Xinzhong Zhu, Pei Zhang, Yi Zhang, Feng Gao, and En Zhu. Fast parameter-free multi-view subspace clustering with consensus anchor guidance. IEEE Transactions on Image Processing, 31:556\u2013568, 2021.   \n[33] Siwei Wang, Xinwang Liu, Suyuan Liu, Jiaqi Jin, Wenxuan Tu, Xinzhong Zhu, and En Zhu. Align then fusion: Generalized large-scale multi-view clustering with anchor matching correspondences. Advances in Neural Information Processing Systems, 35:5882\u20135895, 2022.   \n[34] Si-Guo Fang, Dong Huang, Xiao-Sha Cai, Chang-Dong Wang, Chaobo He, and Yong Tang. Efficient multi-view clustering via unified and discrete bipartite graph learning. IEEE Transactions on Neural Networks and Learning Systems, 2023.   \n[35] Jinghuan Lao, Dong Huang, Chang-Dong Wang, and Jian-Huang Lai. Towards scalable multiview clustering via joint learning of many bipartite graphs. IEEE Transactions on Big Data, 2023.   \n[36] Jing Wang, Yuanjie Zheng, Jingqi Song, and Sujuan Hou. Cross-view representation learning for multi-view logo classification with information bottleneck. In Proceedings of the 29th ACM International Conference on Multimedia, pages 4680\u20134688, 2021.   \n[37] Xingfeng Li, Yinghui Sun, Quansen Sun, Zhenwen Ren, and Yuan Sun. Cross-view graph matching guided anchor alignment for incomplete multi-view clustering. Information Fusion, 100:101941, 2023.   \n[38] Zhibin Dong, Siwei Wang, Jiaqi Jin, Xinwang Liu, and En Zhu. Cross-view topology based consistent and complementary information for deep multi-view clustering. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 19440\u201319451, 2023.   \n[39] Chang Tang, Xinzhong Zhu, Xinwang Liu, and Lizhe Wang. Cross-view local structure preserved diversity and consensus learning for multi-view unsupervised feature selection. In Proceedings of the AAAI Conference on artificial intelligence, volume 33, pages 5101\u20135108, 2019.   \n[40] Suyuan Liu, Junpu Zhang, Yi Wen, Xihong Yang, Siwei Wang, Yi Zhang, En Zhu, Chang Tang, Long Zhao, and Xinwang Liu. Sample-level cross-view similarity learning for incomplete multiview clustering. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 14017\u201314025, 2024.   \n[41] Miaomiao Li, Jingyuan Xia, Huiying Xu, Qing Liao, Xinzhong Zhu, and Xinwang Liu. Localized incomplete multiple kernel k-means with matrix-induced regularization. IEEE Transactions on Cybernetics, 53(6):3479\u20133492, 2021.   \n[42] Xinwang Liu. Incomplete multiple kernel alignment maximization for clustering. IEEE Transactions on Pattern Analysis and Machine Intelligence, 46(3):1412\u20131424, 2021.   \n[43] Siwei Wang, Xinwang Liu, En Zhu, Chang Tang, Jiyuan Liu, Jingtao Hu, Jingyuan Xia, and Jianping Yin. Multi-view clustering via late fusion alignment maximization. In Proceedings of the 28th International Joint Conference on Artificial Intelligence, pages 3778\u20133784, 2019.   \n[44] John Winn and Nebojsa Jojic. Locus: Learning object classes with unsupervised segmentation. In Tenth IEEE International Conference on Computer Vision (ICCV\u201905) Volume 1, volume 1, pages 756\u2013763. IEEE, 2005.   \n[45] Jose Costa Pereira, Emanuele Coviello, Gabriel Doyle, Nikhil Rasiwasia, Gert RG Lanckriet, Roger Levy, and Nuno Vasconcelos. On the role of correlation and abstraction in crossmodal multimedia retrieval. IEEE transactions on pattern analysis and machine intelligence, 36(3):521\u2013535, 2013. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Limitation ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The primary limitation of AIMC-CVR lies in its difficulty in handling high-dimensional data. Although the designed symmetric cross-view projection mechanism help to preserve high-dimensional features, it also introduces additional time complexity of $\\mathcal{O}(d_{p}{}^{3})$ and space complexity of $\\mathcal{O}(d_{p}d_{q})$ . A direction for future research is the design of a well-structured unified cross-view metric space to address high-dimensional data. Moreover, different levels of confidence should be assigned to relationships between different views in cross-view learning. Incorporating the interrelations among views into cross-view learning can help to improve AIMC-CVR. ", "page_idx": 13}, {"type": "text", "text": "A.2 Proof of Theorem 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "To prove Theorem 1, we first present two lemmas along with their corresponding proofs. ", "page_idx": 13}, {"type": "text", "text": "Lemma 1. If the set of anchors $\\mathcal{A}=\\{a_{1},\\ldots,a_{m}\\}$ contains distinct points and for any anchor $a_{i}$ , $a_{i}$ is not a vertex of the convex hull of $\\mathcal{A}$ , i.e., $a_{i}\\in c o n v(A\\setminus\\{a_{i}\\})$ where $c o n v(\\cdot)$ denotes the convex hull, then $\\boldsymbol{\\mathcal{A}}$ must be an empty set. ", "page_idx": 13}, {"type": "text", "text": "Proof. When $j=1$ , we have $a_{1}\\in c o n v(A\\setminus\\{a_{1}\\})$ , then ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{c o n v(\\mathcal A\\backslash\\{a_{1}\\})=c o n v(c o n v(\\mathcal A\\backslash\\{a_{1}\\}))}\\\\ &{\\qquad\\qquad\\qquad=c o n v(c o n v(\\mathcal A\\backslash\\{a_{1}\\})\\cup\\{a_{1}\\})}\\\\ &{\\qquad\\qquad\\qquad\\supseteq c o n v((\\mathcal A\\backslash\\{a_{1}\\})\\cup\\{a_{1}\\})}\\\\ &{\\qquad\\qquad\\qquad=c o n v(\\mathcal A).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Since $\\mathcal{A}\\backslash\\{a_{1}\\}\\subseteq\\mathcal{A}$ , then ", "page_idx": 13}, {"type": "equation", "text": "$$\nc o n v(A\\backslash\\{a_{1}\\})\\subseteq c o n v(A).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Along with Eq. (18), we have ", "page_idx": 13}, {"type": "equation", "text": "$$\nc o n v(A\\backslash\\{a_{1}\\})=c o n v(A).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Assuming that for $1\\leq j<m$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\nc o n v(A\\backslash\\cup_{i=1}^{j}\\left\\{a_{i}\\right\\})=c o n v(A).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Based on $a_{j+1}\\in c o n v(A\\backslash\\{a_{j+1}\\})$ , $a_{j+1}$ is not a vertex of $c o n v(A)$ . Therefore, $a_{j+1}$ is not a vertex of $c o n v(A\\backslash\\cup_{i=1}^{j}\\{a_{i}\\})$ . Then we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{a_{j+1}\\in c o n v(A\\backslash\\cup_{i=1}^{j}\\{a_{i}\\}\\backslash\\{a_{j+1}\\})}\\\\ &{\\qquad=c o n v(A\\backslash\\cup_{i=1}^{j+1}\\{a_{i}\\}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{c o n v(A\\backslash\\cup_{i=1}^{j+1}\\{a_{i}\\})=c o n v(c o n v(A\\backslash\\cup_{i=1}^{j+1}\\{a_{i}\\}))}}\\\\ &{=c o n v(c o n v(A\\backslash\\cup_{i=1}^{j+1}\\{a_{i}\\})\\cup\\{a_{j+1}\\}),}\\\\ &{\\supseteq c o n v((A\\backslash\\cup_{i=1}^{j+1}\\{a_{i}\\})\\cup\\{a_{j+1}\\})}\\\\ &{=c o n v((A\\backslash\\cup_{i=1}^{j}\\{a_{i}\\}))}\\\\ &{=c o n v(A).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "In summary, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{c}{c o n v(A\\backslash\\cup_{i=1}^{m}\\{a_{i}\\})=c o n v(A),}\\\\ {c o n v(\\emptyset)=c o n v(A),}\\\\ {A=\\emptyset.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "This completes the proof. ", "page_idx": 13}, {"type": "text", "text": "Lemma 2. If the set of anchors $\\mathcal{A}=\\{a_{1},\\ldots,a_{m}\\}$ contains distinct anchors and $A\\neq\\emptyset$ , then there exists an anchor $a_{i}$ such that $a_{i}$ is a vertex of the convex hull $c o n v(A)$ . In other words, $a_{i}\\not\\in c o n v(A\\backslash\\{a_{i}\\})$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. Assume that for any anchor $a_{i}$ , we have $a_{i}\\in c o n v(A\\backslash\\{a_{i}\\})$ . According to Lemma 1, we have $A=\\varnothing$ , which contradicts the given condition. Therefore, the assumption is false. There exists an anchor $a_{i}$ such that $a_{i}$ is a vertex of the convex hull $c o n v(A)$ . In other words, $a_{i}\\not\\in c o n v(A\\backslash\\{a_{i}\\})$ . This completes the proof. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Based on Lemma 1 and Lemma 2, we provide the proof of Theorem 1 as follows: ", "page_idx": 14}, {"type": "text", "text": "Proof. Based on Lemma 2, there exists an anchor $a_{i}$ such that $a_{i}$ is a vertex of the convex hull $c o n v(A)$ . Assume ${\\mathcal X}_{a_{i}}~\\subseteq~c o n v(A)$ . Since $a_{i}$ is a vertex of $c o n v(A)$ , we have $a_{i}~\\notin$ $c o n v(c o n v(A\\backslash\\{a_{i}\\}))$ . Given $\\mathcal{X}_{a_{i}}\\subseteq c o n v(A)$ , we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\mathcal{X}_{a_{i}}\\backslash\\{a_{i}\\}\\subseteq c o n v(A)\\backslash\\{a_{i}\\},}}\\\\ {{c o n v(\\mathcal{X}_{a_{i}}\\backslash\\{a_{i}\\})\\subseteq c o n v(c o n v(A\\backslash\\{a_{i}\\})).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then ", "page_idx": 14}, {"type": "equation", "text": "$$\na_{i}\\not\\in c o n v({\\mathcal X}_{a_{i}}\\backslash\\{a_{i}\\}),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which contradicts the fact that $a_{i}$ is the cluster center of $\\mathcal{X}_{a_{i}}$ . Thus, the assumption does not hold, and $\\mathcal{X}_{a_{i}}\\subset\\mathit{c o n v}(A)$ . There exists $c\\in\\mathcal{X}_{a_{i}}\\subseteq\\mathcal{X}$ such that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{f}}\\left\\|\\sum_{i=1}^{m}f_{i}a_{i}-c\\right\\|_{2}^{2}>0,\\mathrm{s.t.}\\;\\mathbf{f}^{\\top}\\mathbf{1}=1,\\mathbf{f}\\geq0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This completes the proof. ", "page_idx": 14}, {"type": "text", "text": "A.3 Proof of Theorem 2 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof. We denote $\\mathbf{f}^{*}$ and $\\mathbf{g}^{\\ast}$ as the optimal values of $\\mathbf{f}$ and $\\mathbf{g}$ in Eq. (7). According to the Pythagorean theorem, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i=1}^{m}g_{i}^{*}a_{i}-c\\right\\|_{2}^{2}+\\left\\|\\sum_{i=1}^{m}g_{i}^{*}a_{i}-\\sum_{i=1}^{m}f_{i}^{*}a_{i}\\right\\|_{2}^{2}=\\left\\|\\sum_{i=1}^{m}f_{i}^{*}a_{i}-c\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In the projection space $a f(A)$ where $a f\\!f(\\cdot)$ denotes the affine hull, Theorem 1 still holds. Therefore, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i=1}^{m}g_{i}^{*}a_{i}-\\sum_{i=1}^{m}f_{i}^{*}a_{i}\\right\\|_{2}^{2}>0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{i=1}^{m}g_{i}^{*}a_{i}-c\\right\\|_{2}^{2}<\\left\\|\\sum_{i=1}^{m}f_{i}^{*}a_{i}-c\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This completes the proof. ", "page_idx": 14}, {"type": "text", "text": "A.4 Proof of Doubly Stochastic Matrix S ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lemma 3. Let $\\mathbf{Z}$ be an $m\\times n$ matrix where the sum of each column is 1. Define Q as a diagonal matrix where the i-th diagonal element is the sum of the elements in the i-th row of Z. Then the matrix $\\mathbf{S}=\\mathbf{Z}^{\\top}\\mathbf{Q}^{-1}\\mathbf{Z}$ is doubly stochastic, meaning that each row and each column of sums to 1. ", "page_idx": 14}, {"type": "text", "text": "Proof. Denote $\\mathbf{S}_{i j}$ to be the $j$ -th element in the $i$ -th row of S, $\\mathbf{q}_{l}$ to be $i$ -th diagonal element of $\\mathbf{Q}$ , we can derive that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\sum_{j=1}^{n}{\\bf S}_{i j}=\\sum_{j=1}^{n}\\sum_{l=1}^{m}{\\bf Z}_{l i}\\frac{1}{{\\bf d}_{1}}{\\bf Z}_{l j}}}\\\\ {{\\displaystyle~~~~~~~~=\\sum_{l=1}^{m}\\frac{1}{{\\bf d}_{1}}{\\bf Z}_{l i}\\sum_{j=1}^{n}{\\bf Z}_{l j}}}\\\\ {{\\displaystyle~~~~~~~=\\sum_{l=1}^{m}\\frac{1}{{\\bf d}_{1}}{\\bf Z}_{l i}{\\bf q}}}\\\\ {{\\displaystyle~~~~~~~=\\sum_{l=1}^{m}{\\bf Z}_{l i}}}\\\\ {{\\displaystyle~~~~~~~~~~=\\sum_{l=1}^{m}{\\bf Z}_{l i}}}\\\\ {{\\displaystyle~~~~~~~~=1.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Similarly, it can be proven that $\\sum_{i=1}^{n}\\mathbf{S}_{i j}=1$ . This completes the proof. ", "page_idx": 15}, {"type": "text", "text": "A.5 Convergence Study on More Datasets ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In Fig. 5, we further plot the curve of the objective function values against the number of iterations for the proposed algorithm on the YTF10, YTF20, and MNIST datasets. It can be observed that the objective values monotonically decrease with the increasing number of iterations on these three datasets, gradually approaching stability, thus confirming the convergence of AIMC-CVR. ", "page_idx": 15}, {"type": "image", "img_path": "4pIfc51fGK/tmp/181fae61ba048c5c32600ee54bb822f7fa6d4ee33c1f7d0edc892ec607dcfea6.jpg", "img_caption": ["Figure 5: Variation of the objective value with increasing iteration number on other three datasets. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "A.6 Parameter Analysis on More Datasets ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In Fig. 6, we further plot the variation of clustering performance of the proposed algorithm on the YTF10, YTF20, and MNIST datasets with different values of two hyperparameters, $\\beta$ and $\\lambda$ . It can be observed that AIMC-CVR exhibits less sensitivity to parameters on the YTF10 and YTF20 datasets. However, on the MNIST dataset, higher values of $\\lambda$ lead to better clustering performance. ", "page_idx": 15}, {"type": "image", "img_path": "4pIfc51fGK/tmp/7de19ea0e3c38588f5df96d86eeaba4a1d5a98e0c6a3d96e6280e1f37cf0aedb.jpg", "img_caption": ["Figure 6: Sensitivity analysis of $\\beta$ and $\\lambda$ on other three datasets. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "A.7 Ablation Study on More Metrics ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "To further demonstrate the effectiveness of our approach, we compared our algorithm with five variants and three other clustering metrics in Table 4. Compared to the other variants, AIMC-CVR exhibits better NMI, Purity, and Fscore on all datasets, validating the effectiveness of our method. ", "page_idx": 16}, {"type": "table", "img_path": "4pIfc51fGK/tmp/c75b88eadb4bd98907522c9e3833d528672c4d0183ffcdc79434315a01605103.jpg", "table_caption": ["Table 4: Ablation studies of AIMC-CVR with different variants on Other Metrics. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Please refer to the abstract and introduction. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 17}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Justification: Please refer to Section A.1. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 17}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Please refer to Section A.2, A.3 and A.4. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 18}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: Please refer to Section 3.3 and 4.1. The data and code of the proposed algorithm will be uploaded in a zip file along with the supplementary material. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 18}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The data and code of the proposed algorithm will be uploaded in a zip file along with the supplementary material. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 19}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: Please refer to Section 4.1. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 19}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: Please refer to Section 4.1. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Please refer to Section 4.1. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: The research conducted in the paper conform with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper mainly targets incomplete multi-view learning in large-scale scenarios. By solving this problem, we can further expand the application scope of unsupervised learning, especially in complex scenarios such as multi-view, large-scale, incomplete, etc. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: All competitors code and datasets are cited with their references. Please refer to Section 4.1 and ??. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 21}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 22}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 22}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 22}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 22}]