[{"figure_path": "SeesCzBelI/figures/figures_2_1.jpg", "caption": "Figure 1: Comparison of the RM training process using the original preference loss and our developed PBC method respectively, where the latter employs uc(x) to approximate the prompt-template bias, providing unbiased reward scores with lower variance for the subsequent RL fine-tuning.", "description": "This figure illustrates the difference between training a reward model (RM) using the original preference loss and the proposed Prompt Bias Calibration (PBC) method. The original method results in a reward model that learns prompt-template bias, leading to biased reward scores.  The PBC method adds a component to estimate and remove this bias, resulting in more accurate reward scores with less variance. This improved accuracy leads to better performance during subsequent reinforcement learning fine-tuning.", "section": "2.1 Reward Model Training"}, {"figure_path": "SeesCzBelI/figures/figures_4_1.jpg", "caption": "Figure 1: Comparison of the RM training process using the original preference loss and our developed PBC method respectively, where the latter employs uc(x) to approximate the prompt-template bias, providing unbiased reward scores with lower variance for the subsequent RL fine-tuning.", "description": "This figure compares the training process of a reward model (RM) using two different methods: the original preference loss and the proposed Prompt Bias Calibration (PBC) method.  The original method suffers from prompt-template bias, leading to biased reward scores.  The PBC method aims to mitigate this bias by estimating and subtracting a prompt-template bias term (represented as uc(x)), resulting in more unbiased reward scores with reduced variance, which is beneficial for subsequent reinforcement learning (RL) fine-tuning steps.", "section": "2.1 Reward Model Training"}, {"figure_path": "SeesCzBelI/figures/figures_7_1.jpg", "caption": "Figure 3: The comparison of statistics of the reward scores predicted by RMs trained with (a) the original preference loss and (b) our developed PBC method, across different categories of prompt-response pairs in the validation set of the manually constructed RM-Template dataset.", "description": "This figure shows box plots comparing reward scores predicted by vanilla reward models (BASE RM) and reward models trained with the proposed Prompt Bias Calibration (PBC) method (OURS).  The plots are separated into three subfigures: (a) shows the distribution of reward scores using the original preference loss; (b) shows the distribution of reward scores after applying the PBC method; (c) is a direct comparison of the mean reward scores between (a) and (b).  The categories being compared (Advertisement, Insight, Tech Article, Record Article, Poetry) represent different response styles requested from the language model, highlighting the impact of prompt bias on reward prediction accuracy.", "section": "4.2 Experimental Results"}, {"figure_path": "SeesCzBelI/figures/figures_7_2.jpg", "caption": "Figure 4: Win rates comparison (judged by GPT-4) of LLMs aligned with RMs trained with LBPC and other methods.", "description": "This figure shows the win, tie, and loss rates of LLMs fine-tuned using different reward models.  The LLMs were compared against each other, with GPT-4 judging the quality of the generated responses.  The reward models used were trained using three methods: ODIN (a method to remove length bias), PBC (a method to remove prompt template bias), and ODIN+PBC (a combination of both methods). The results demonstrate that the LLM fine-tuned using the LPBC reward model significantly outperforms LLMs trained using the other reward models.", "section": "4.2 Experimental Results"}, {"figure_path": "SeesCzBelI/figures/figures_8_1.jpg", "caption": "Figure 5: Ablation studies on the various settings of hyper-parameter \u03b7c and \u03b7\u03b9 in LPBC method.", "description": "This figure shows the results of ablation studies performed to evaluate the robustness of the LPBC (Length and Prompt Bias Calibration) method by varying its hyperparameters \u03b7c and \u03b7\u03b9.  Subfigure (a) displays the accuracy performance across different combinations of \u03b7c and \u03b7\u03b9 values, showing a trade-off between accuracy and the impact of constraints on the preference loss. Subfigures (b) and (c) present the MMLU and DROP performance, respectively, under the same hyperparameter settings.  The heatmaps in (b) and (c) visualize how the performance changes with different choices of \u03b7c and \u03b7\u03b9.", "section": "4.3 Ablation Studies"}]