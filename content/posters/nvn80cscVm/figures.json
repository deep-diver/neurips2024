[{"figure_path": "nvn80cscVm/figures/figures_4_1.jpg", "caption": "Figure 1: Comparison of Diff-eRank and reduced loss when model scales up across various datasets. Both Diff-eRank and reduced loss show an upward trend when the model scales up.", "description": "This figure displays the relationship between Diff-eRank and reduced loss across different model sizes for four different datasets: dolly-15k, wikipedia, openwebtext2, and hh-rlhf.  The top row shows the Diff-eRank (difference in effective rank) values plotted against model size (on a logarithmic scale). The bottom row shows the reduced loss (difference between the untrained and trained model losses) also plotted against model size. In each case, both Diff-eRank and reduced loss demonstrate a positive correlation with model size; as the model size increases, so do both metrics. This suggests that larger models are more effective at removing redundant information and achieving better predictive performance.", "section": "4.2 The Trend of Diff-eRank with Model Size"}, {"figure_path": "nvn80cscVm/figures/figures_6_1.jpg", "caption": "Figure 2: Illustration of the eRank measurement in the MLLM framework. The evaluation encompasses the effective rank of image representations after the vision encoder (eRank\u2081), post-connector representations (eRank\u2082), as well as the output representations generated by the LLM including individual images (eRank\u2083), textual data (eRank\u2084), and the combined image-text pairs (eRank\u2085).", "description": "This figure illustrates how eRank is calculated for different stages of multi-modal large language model (MLLM) processing.  It shows the flow of image and text data through a vision encoder, a connector, and an LLM.  The eRank values (eRank1 to eRank5) represent the effective rank of the representations at each stage, providing a measure of the information contained within them.  This allows for evaluation of the efficiency of information processing and modality alignment in MLLMs.", "section": "5.1 Experimental Settings"}, {"figure_path": "nvn80cscVm/figures/figures_7_1.jpg", "caption": "Figure 3: Comparing Diff-eRank with reduced loss and benchmark accuracy across different model families, including OPT [45], Cerebras-GPT [11], and OpenELM [21].", "description": "This figure compares the trends of Diff-eRank, reduced loss, and benchmark accuracy across different model sizes for three different language model families: OPT, Cerebras-GPT, and OpenELM.  It visually demonstrates the correlation between the proposed Diff-eRank metric and conventional evaluation metrics (loss and accuracy) across various model architectures. The consistent upward trends across all three metrics suggest that Diff-eRank is a robust and meaningful evaluation metric, regardless of the specific model architecture.", "section": "6 Ablation Study"}, {"figure_path": "nvn80cscVm/figures/figures_8_1.jpg", "caption": "Figure 4: Different designs for Diff-eRank.", "description": "This figure compares two different algorithms for calculating Diff-eRank, denoted as Algorithm (a) and Algorithm (b).  Algorithm (a) calculates Diff-eRank based on the average matrix entropy across a dataset, while Algorithm (b) uses the average of the effective ranks of individual data samples in the dataset. The x-axis represents the model size and the y-axis represents the calculated Diff-eRank. Both algorithms show a similar trend with the increase in model size, suggesting that the increasing trend of Diff-eRank across different models is robust across various calculation methods. The results validate the reliability of the Diff-eRank metric.", "section": "6.2 Algorithm Design"}]