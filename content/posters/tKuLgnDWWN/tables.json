[{"figure_path": "tKuLgnDWWN/tables/tables_8_1.jpg", "caption": "Table 1: Potential attack Word Error Rate (WER) under different attack scenarios.", "description": "This table presents the word error rates (WER) achieved by different attack models against the SILENCE system.  The attacks are categorized as passive (Azure, Naive Whisper) and active (U-Net, CQT-Diff, Whisper predict (white box)).  The WER-SLU represents the error rate on the SLU task itself, and WER-ASR represents the error rate on the ASR task, aiming to transcribe the audio. A lower WER indicates better protection against the attack.  The 'Whisper predict (white box)' attack is particularly significant as it represents a strong white-box attack where the attacker has full knowledge of the SILENCE system's architecture and weights.", "section": "5.1 End-to-end performance"}, {"figure_path": "tKuLgnDWWN/tables/tables_15_1.jpg", "caption": "Table 2: Evaluation of privacy preservation and SLU performance on FSC dataset.", "description": "This table presents a comparison of different privacy-preserving techniques for spoken language understanding (SLU) on the Fluent Speech Commands (FSC) dataset.  It shows the accuracy of SLU (ACC-SLU) and the word error rate of an automatic speech recognition (ASR) attack (WER-ASR) for several methods: AllOffloaded (no privacy protection), VAE (variational autoencoder), PPSLU (a prior state-of-the-art method), Local (on-device processing), Random (random masking), and SILENCE (the proposed method).  The results demonstrate the effectiveness of SILENCE in balancing privacy and utility.", "section": "5.1 End-to-end performance"}, {"figure_path": "tKuLgnDWWN/tables/tables_15_2.jpg", "caption": "Table 3: System performance on conventional modularized SLU.", "description": "This table presents the performance of different privacy-preserving SLU approaches on a conventional modularized SLU system. It compares the intent classification accuracy (SLU-ACC) achieved by different methods, including the plaintext approach (no privacy preservation), VAE, PPSLU, and three versions of the proposed SILENCE method. The different versions of SILENCE correspond to using the NLU only, a decoupled SLU architecture, and an end-to-end SLU architecture, demonstrating the impact of different levels of integration with the existing SLU model. The results show that even with a modularized approach, SILENCE achieves competitive results.", "section": "5.2 System cost"}, {"figure_path": "tKuLgnDWWN/tables/tables_15_3.jpg", "caption": "Table 4: Comparison between Privacy-preservation and SLU performance at different speech granularities. '/' means not supported. Local leaks no words as nothing is uploaded.", "description": "This table compares the performance of different privacy-preserving SLU approaches across various speech granularities (scenario, action, intent).  It shows the accuracy of each approach in correctly identifying the scenario, action, and intent, as well as the word error rate (WER) for SLU and ASR tasks. The '/' indicates that a specific granularity is not supported by that method. Notably, the \"Local\" approach achieves perfect privacy (WER = 100%) as no data is uploaded to the cloud, but it does not preserve speech understanding performance compared to others. This table highlights the effectiveness of the proposed approach (\"Ours\") in achieving a good balance between privacy and SLU performance across different granularities.", "section": "5.2 System cost"}]