[{"figure_path": "MDdOQayWTA/figures/figures_6_1.jpg", "caption": "Figure 1: Time-varying arm-sets. (First row) Regret plots of all considered algorithms. (Second row) Magnified regret plots. (Third row) Confidence set plots at the final time t = 10000 when applicable. Each column represents a different logistic bandit instance for S \u2208 {4, 6, 8, 10}.", "description": "The figure shows the results of experiments conducted on logistic bandits with time-varying arm-sets.  The first row displays the regret of various algorithms across different settings (S values). The second row provides a magnified view of the regret plots for better visualization of differences between algorithms, particularly during the initial phases.  The third row illustrates the confidence sets at the final timestep (t=10000).  Each column corresponds to a unique logistic bandit experiment with a different value for the parameter S.", "section": "Experiments in Logistic Bandits"}, {"figure_path": "MDdOQayWTA/figures/figures_9_1.jpg", "caption": "Figure 1: Time-varying arm-sets. (First row) Regret plots of all considered algorithms. (Second row) Magnified regret plots. (Third row) Confidence set plots at the final time t = 10000 when applicable. Each column represents a different logistic bandit instance for S \u2208 {4, 6, 8, 10}.", "description": "This figure shows the results of experiments on logistic bandits with time-varying arm-sets.  The first row displays the regret (cumulative difference between the optimal and chosen actions) of several algorithms across different problem difficulties (S). The second row provides a magnified view of the regret for a clearer comparison during the initial stages. The third row shows the confidence sets for the parameter estimates at the end of the experiment (t=10000), which represent the uncertainty around the estimated parameter.", "section": "Experiments in Logistic Bandits"}, {"figure_path": "MDdOQayWTA/figures/figures_37_1.jpg", "caption": "Figure 1: Time-varying arm-sets. (First row) Regret plots of all considered algorithms. (Second row) Magnified regret plots. (Third row) Confidence set plots at the final time t = 10000 when applicable. Each column represents a different logistic bandit instance for S \u2208 {4, 6, 8, 10}.", "description": "This figure displays the results of experiments on logistic bandits with time-varying arm-sets.  The top row shows the regret (cumulative difference between the optimal reward and the algorithm's reward) for each algorithm across different values of S (a parameter related to the problem's complexity).  The middle row provides a magnified view of the regret, focusing on the early stages of the learning process.  The bottom row visualizes the confidence sets (regions containing the true parameter with high probability) generated by the algorithms at the end of the learning process (time step 10000). Each column represents a separate experimental instance with a different problem setting.", "section": "Experiments in Logistic Bandits"}]