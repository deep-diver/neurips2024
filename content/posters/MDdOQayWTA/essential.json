{"importance": "This paper is crucial for researchers working on **generalized linear bandits** and **confidence sequences**. It offers a unified framework, improving upon existing methods and providing a foundation for **future research** in safe and efficient machine learning algorithms.  The poly(S)-free regret bound for logistic bandits is a significant advancement,  opening avenues for **new algorithms** and applications.", "summary": "A unified confidence sequence (CS) construction for generalized linear models (GLMs) achieves state-of-the-art regret bounds for contextual bandits, notably a poly(S)-free regret for logistic bandits.", "takeaways": ["A new unified likelihood ratio-based confidence sequence (CS) is introduced for any convex generalized linear model (GLM), which is guaranteed to be convex and numerically tight.", "The proposed optimistic algorithm, OFUGLB, achieves state-of-the-art regret bounds for various self-concordant generalized linear bandits (GLBs).", "The poly(S)-free regret bound for logistic bandits is a significant theoretical improvement and shows that OFUGLB outperforms prior algorithms."], "tldr": "Existing confidence sequences (CSs) for Generalized Linear Models (GLMs) are far from ideal, often lacking tightness and being specific to certain GLM types.  This significantly hinders their applications in areas like bandits that require estimating uncertainty from noisy observations.  Furthermore, prior optimistic algorithms for GLMs often suffer from poly(S) factors in their regret bounds, which is computationally expensive and less efficient.  These issues significantly impede practical applications of GLMs in areas like contextual bandits. \nThis paper introduces a unified likelihood ratio-based CS construction applicable to any convex GLM.  It leverages a time-uniform PAC-Bayesian bound with uniform priors, unlike most prior works.  The resulting CS is both numerically tight and on par or better than existing CSs for various GLMs, particularly Bernoulli for which it achieves a poly(S)-free radius.  This CS directly leads to a novel optimistic algorithm, OFUGLB, for GLBs.  The authors prove that OFUGLB attains state-of-the-art regret bounds for various self-concordant GLBs, and even poly(S)-free for bounded GLBs, such as logistic bandits.  This was achieved by introducing a novel proof technique that avoids previously widely-used approaches, which often yield regret bounds with poly(S) factors.", "affiliation": "KAIST", "categories": {"main_category": "Machine Learning", "sub_category": "Reinforcement Learning"}, "podcast_path": "MDdOQayWTA/podcast.wav"}