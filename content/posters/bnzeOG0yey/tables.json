[{"figure_path": "bnzeOG0yey/tables/tables_6_1.jpg", "caption": "Table 1: Distribution discrepancy of different classes in CIFAR10. The larger the values of AUROC and AUPR, the better the performance.", "description": "This table presents the results of evaluating distribution discrepancy using various methods (MSP, NNBD, MMD-D, R-Div, and I-Div) on the CIFAR-10 dataset.  Each row represents a different class in CIFAR-10, and the columns show the AUROC (Area Under the Receiver Operating Characteristic Curve) and AUPR (Area Under the Precision-Recall Curve) scores for each method. Higher AUROC and AUPR values indicate better performance in distinguishing between training and test distributions.  The results demonstrate I-Div's superior performance in accurately quantifying distribution discrepancies.", "section": "4.1 Experiments on different classes"}, {"figure_path": "bnzeOG0yey/tables/tables_6_2.jpg", "caption": "Table 2: Distribution discrepancy of domain adaptation data.", "description": "This table presents the results of distribution discrepancy evaluation on domain adaptation datasets, PACS and Office-Home.  Each dataset consists of four domains.  One domain serves as the training dataset while the remaining three are merged as the test dataset. The table shows the accuracy (ACC) achieved on the source domain (training dataset) along with the AUROC (Area Under the Receiver Operating Characteristic Curve) scores for the different algorithms (MSP, NNBD, MMD-D, R-Div, and I-Div) in evaluating the distribution discrepancy.  Higher AUROC values indicate better performance in distinguishing between the training and test distributions.", "section": "4.2 Experiments on different datasets"}, {"figure_path": "bnzeOG0yey/tables/tables_7_1.jpg", "caption": "Table 1: Distribution discrepancy of different classes in CIFAR10. The larger the values of AUROC and AUPR, the better the performance.", "description": "This table presents the results of evaluating distribution discrepancy for different classes in the CIFAR-10 dataset.  Each row represents a different class, where one class is used as the test set and the remaining nine classes comprise the training set. The performance of several algorithms is shown using AUROC (Area Under the Receiver Operating Characteristic Curve) and AUPR (Area Under the Precision-Recall Curve). Higher values indicate better performance in distinguishing between the training and test distributions. The table highlights that I-Div consistently achieves perfect scores (100%) for both AUROC and AUPR metrics across all classes.", "section": "4.1 Experiments on different classes"}, {"figure_path": "bnzeOG0yey/tables/tables_7_2.jpg", "caption": "Table 4: Distribution discrepancy between ImageNet and other test datasets.", "description": "This table presents the results of experiments evaluating the distribution discrepancy between the ImageNet dataset (used as the training dataset) and four other test datasets: OIDv4, CALTECH256, FLOWERS102, and DTD.  Two different network architectures were used: ResNet50 and ViT-B/16.  The table shows the accuracy (ACC) achieved by CLIP on the test datasets, and the AUROC and AUPR scores for several methods, including MSP, NNBD, MMD-D, H-Div, R-Div, and I-Div.  The results highlight the performance of the I-Div algorithm in capturing the semantic similarity or difference between the training and test datasets.", "section": "4 Experimental results"}, {"figure_path": "bnzeOG0yey/tables/tables_9_1.jpg", "caption": "Table 5: Effect of different network architectures.", "description": "This table presents the classification accuracy (ACC), Area Under the Receiver Operating Characteristic Curve (AUROC), and Area Under the Precision-Recall Curve (AUPR) for different network architectures (ResNet18, VGG19, MobileNet, EfficientNet) on various datasets (RGI, SVHN, DTD, Flowers102, OxfordIIITPet, SEMEION, Caltech256, CIFAR100, CIFAR101, STL10).  The results illustrate the impact of different network architectures on the ability of the I-Div algorithm to differentiate between original data and its adversarial variants.", "section": "4.5 Experiments with different sample sizes and network architectures"}, {"figure_path": "bnzeOG0yey/tables/tables_18_1.jpg", "caption": "Table 6: Distribution discrepancy of different classes in SVHN. The larger the values of AUROC and AUPR, the better the performance.", "description": "This table presents the results of evaluating distribution discrepancy for different digit classes in the SVHN dataset using various methods.  The AUROC (Area Under the Receiver Operating Characteristic Curve) and AUPR (Area Under the Precision-Recall Curve) metrics are used to assess the performance of each method in distinguishing between training and test distributions for each digit class.  Higher AUROC and AUPR values indicate better performance.", "section": "4.2 Experiments on different datasets"}]