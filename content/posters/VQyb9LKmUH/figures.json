[{"figure_path": "VQyb9LKmUH/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of the in-context KG reasoning foundation model. (A) Given the query and KG, we extract prompt graphs as context for the query relation \u201cplayer in league\u201d. The entities and relations in the prompt graphs are mapped to the unified tokens. (B) We employ a message passing neural network to encode the prompt graph and readout the relation representations as the prompts. (C) Then we use the prompts to initialize the representations of entities and relations in the KG. After KG encoding, we score the candidate entities according to their embeddings in the last layer.", "description": "This figure illustrates the overall architecture of the KG-ICL model, which is a prompt-based KG foundation model for in-context reasoning. It consists of three main stages: (A) prompt graph generation, where a subgraph is extracted from the KG based on the query, and entities and relations are mapped to unified tokens; (B) prompt graph encoding, which uses a message-passing neural network to generate relation representation prompts from the prompt graph; (C) KG reasoning, which uses the prompt representations to initialize the KG and then scores the candidate entities based on their embeddings.", "section": "4 In-context Reasoning over KGs"}, {"figure_path": "VQyb9LKmUH/figures/figures_6_1.jpg", "caption": "Figure 1: Overview of the in-context KG reasoning foundation model. (A) Given the query and KG, we extract prompt graphs as context for the query relation \u201cplayer in league\u201d. The entities and relations in the prompt graphs are mapped to the unified tokens. (B) We employ a message passing neural network to encode the prompt graph and readout the relation representations as the prompts. (C) Then we use the prompts to initialize the representations of entities and relations in the KG. After KG encoding, we score the candidate entities according to their embeddings in the last layer.", "description": "This figure provides a visual overview of the KG-ICL model's architecture and workflow. It details three main stages: (A) prompt graph generation from a query and KG, (B) prompt graph encoding using a message passing neural network (resulting in prompt representations), and (C) KG reasoning using the prompts to initialize KG entity and relation representations, followed by another message passing neural network to generate final entity embeddings and scores.", "section": "4 In-context Reasoning over KGs"}, {"figure_path": "VQyb9LKmUH/figures/figures_7_1.jpg", "caption": "Figure 3: MRR with different numbers of examples.", "description": "This figure shows the performance of the KG-ICL model on inductive, fully-inductive, and transductive datasets with varying numbers of examples used in the prompt. The x-axis represents the number of examples (1, 3, 5, 10, 20), and the y-axis represents the Mean Reciprocal Rank (MRR).  The plot demonstrates the model's robustness to the number of examples provided, with relatively stable performance across different reasoning settings. The slight fluctuations observed might be attributed to the introduction of noise with increased examples.", "section": "5.3 Further Analyses"}, {"figure_path": "VQyb9LKmUH/figures/figures_8_1.jpg", "caption": "Figure 2: MRR results on various KGs.", "description": "The bar chart visualizes the Mean Reciprocal Rank (MRR) achieved by different models (Supervised SOTA, ULTRA pre-train, ULTRA finetune, KG-ICL pre-train, KG-ICL finetune) across various Knowledge Graphs (KGs).  The KGs are categorized into three groups: inductive, fully-inductive, and transductive, representing different KG reasoning settings.  Each bar shows the average MRR across multiple KGs within each group, enabling a comparison of model performance under various conditions and settings. The figure demonstrates KG-ICL's superior performance compared to the baselines.", "section": "5.2 Main Results"}, {"figure_path": "VQyb9LKmUH/figures/figures_9_1.jpg", "caption": "Figure 1: Overview of the in-context KG reasoning foundation model. (A) Given the query and KG, we extract prompt graphs as context for the query relation \u201cplayer in league\u201d. The entities and relations in the prompt graphs are mapped to the unified tokens. (B) We employ a message passing neural network to encode the prompt graph and readout the relation representations as the prompts. (C) Then we use the prompts to initialize the representations of entities and relations in the KG. After KG encoding, we score the candidate entities according to their embeddings in the last layer.", "description": "This figure provides a high-level overview of the KG-ICL model's architecture. It shows three main stages: prompt graph generation, prompt encoding, and KG reasoning. The prompt graph is generated from a sample fact related to the query, and its entities and relations are mapped to tokens for unified processing. The prompt encoding stage uses a message passing network to generate relation prompts, which initialize the KG reasoning stage. The KG reasoning stage uses another message passing network on the KG, leveraging the prompt information to finally score the candidate entities.", "section": "4 In-context Reasoning over KGs"}, {"figure_path": "VQyb9LKmUH/figures/figures_18_1.jpg", "caption": "Figure 6: MRR and H@10 results with increasing number of pre-training datasets.", "description": "This figure shows the performance of the KG-ICL model on inductive, fully-inductive, and transductive datasets as the number of pre-training datasets increases.  The x-axis represents the number of pre-training datasets used, while the y-axis shows the MRR (Mean Reciprocal Rank) and Hits@10 metrics.  The results indicate that the model's performance improves with the addition of more pre-training datasets across all three reasoning settings, demonstrating the benefit of increased data diversity in improving model generalization.", "section": "5.2 Main Results"}]