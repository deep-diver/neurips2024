[{"figure_path": "oe7MfqFK1M/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Cross-dataset skeleton action recognition. Taking action phone calling as an example, temporal mismatch across datasets poses a challenging issue. (b) Complete action prior. Human actions within large datasets exhibit statistical patterns from less feature diversity to more diversity, implying the nature of action completeness (shown for NTU, PKU and ETRI dataset). (c) Recover and Resample. After learning a stochastic action completion function from the training data, we recover complete actions and resample from them to further augment the training set.", "description": "This figure illustrates the core idea of the paper. (a) shows the problem of cross-dataset skeleton action recognition where the temporal length of the same action varies across datasets. (b) introduces the concept of \"complete action prior\", which states that the feature diversity of human actions in large datasets increases over time, starting from less diverse boundary poses to more diverse poses. (c) presents the proposed \"recover and resample\" framework, which recovers complete actions from training data using boundary poses and linear temporal transforms and then resamples from these complete actions to generate augmented data for unseen domains.", "section": "1 Introduction"}, {"figure_path": "oe7MfqFK1M/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of Recovering and Resampling. Given training set S, we learn boundary poses {pi} and context-aware linear transforms {Wi} via clustering. For a sample x from S, we first do extrapolation (FN) conditioning on the boundary pose p' with infilling length tp, and then perform linear transform (Fc) by sampling from {Wi}. The new data points x' are resampled from recovered complete actions as strong augmentations for unseen datasets. Skeletons in dark blue rectangles are new frames generated by FN and Fr. Both x and x' are used for training the classifier.", "description": "This figure illustrates the recover-and-resample augmentation framework.  It shows how the system learns boundary poses and linear transforms from the training data. Then, for a given input skeleton action, it uses boundary pose-conditioned extrapolation to recover a complete action. Finally, it applies a learned linear transformation and resamples the data to augment the training set. The process aims to generate strong augmentations for unseen domains by addressing temporal mismatch in action sequences.", "section": "3 Method"}, {"figure_path": "oe7MfqFK1M/figures/figures_7_1.jpg", "caption": "Figure 3: Visualization for selected linear transform matrices {Wi} via clustering using training sets N and EA.", "description": "This figure visualizes the linear transform matrices obtained through clustering.  The matrices represent learned transformations applied to skeleton action sequences during the augmentation process. These transformations capture common structural temporal patterns in the data, such as shifting and scaling.  The visualizations help illustrate how these learned transforms contribute to recovering and augmenting incomplete action sequences in the cross-dataset setting.", "section": "3 Method"}, {"figure_path": "oe7MfqFK1M/figures/figures_8_1.jpg", "caption": "Figure 3: Visualization for selected linear transform matrices {W<sub>i</sub>} via clustering using training sets N and EA.", "description": "This figure visualizes some examples of linear transform matrices (W<sub>i</sub>) learned via clustering using training sets N and EA. Each matrix represents a linear transformation that maps partial sequences to full sequences, which are learned from the training data by reconstructing full sequences from their trimmed segments. These matrices capture common structural temporal patterns (e.g. shifting, scaling, symmetry) inherent in human actions.  The visualization helps to understand the learned transform patterns and how they are used for generating augmentations.", "section": "3 Method"}, {"figure_path": "oe7MfqFK1M/figures/figures_20_1.jpg", "caption": "Figure 8: Visualization for the clustered linear transform matrices {Wi} using training set N when Ntr = 20 and Ntr = 5.", "description": "This figure visualizes the clustered linear transform matrices obtained using the training set N for two different numbers of clusters (Ntr): 20 and 5.  Each subfigure shows a set of learned transform matrices, represented as images. Comparing the subfigures, we can observe that using more clusters (Ntr=20) leads to a greater diversity of learned transformations, which is essential for capturing a wider range of temporal patterns in human actions.", "section": "3 Method"}, {"figure_path": "oe7MfqFK1M/figures/figures_20_2.jpg", "caption": "Figure 3: Visualization for selected linear transform matrices \\{Wi\\} via clustering using training sets N and EA.", "description": "This figure visualizes the learned linear transform matrices obtained through clustering on training datasets N and EA.  These matrices are a key component of the proposed \"Recover and Resample\" augmentation framework. They represent learned patterns of temporal transformations applied to skeleton action sequences during the action completion process. The visualization likely shows the learned matrices as images, each representing a distinct transform learned from the data.", "section": "3 Method"}, {"figure_path": "oe7MfqFK1M/figures/figures_20_3.jpg", "caption": "Figure 3: Visualization for selected linear transform matrices {W<sub>i</sub>} via clustering using training sets N and EA.", "description": "This figure visualizes the learned linear transform matrices obtained through clustering.  The matrices, represented as images, are learned from the training data of two different datasets, N and EA. Each matrix represents a transformation applied to skeleton action sequences to recover complete actions. The visualization helps understand the learned transformation patterns. ", "section": "3 Method"}, {"figure_path": "oe7MfqFK1M/figures/figures_20_4.jpg", "caption": "Figure 9: Qualitative examples showing improvement of our method over the baseline (ERM).", "description": "This figure shows qualitative examples of improved action recognition using the proposed 'recover-and-resample' augmentation method compared to the baseline (Empirical Risk Minimization or ERM).  The images visually demonstrate that the new method can improve the accuracy of action recognition, particularly for actions where only partial sequences are available. The top row shows how the baseline incorrectly identifies the action as \"put on/take off glasses\", while the proposed method correctly identifies it as \"phone call\". Similarly, the other rows show misclassifications by the baseline which are corrected by the proposed method.", "section": "4.3 Results"}]