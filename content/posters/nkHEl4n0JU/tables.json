[{"figure_path": "nkHEl4n0JU/tables/tables_5_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on two image classification benchmarks: FGVC and VTAB-1k.  The methods are evaluated based on their average test accuracy (across three runs), the number of times they outperform full fine-tuning, and their parameter usage.  The table highlights the superior performance of VFPT compared to other state-of-the-art PEFT methods while using significantly fewer parameters.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_5_2.jpg", "caption": "Table 2: Image classification accuracy for Swin-Base [24] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by different parameter-efficient fine-tuning methods on the Swin-Base model pretrained on the ImageNet-21k dataset.  The methods are evaluated on the VTAB-1k benchmark across three task groups (Natural, Specialized, and Structured) representing varying levels of dataset disparity.  The table shows the percentage of tuned parameters used by each method, along with the accuracy for each task group.  The results highlight the performance of Visual Fourier Prompt Tuning (VFPT) compared to baselines.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_8_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on two image classification benchmarks: FGVC and VTAB-1k.  For each method, the average test accuracy across three runs, the number of wins against full fine-tuning, the percentage of tuned parameters, and the tuning scope are reported.  The table highlights VFPT's superior performance and efficiency compared to other state-of-the-art baselines. ", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_8_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of different parameter-efficient fine-tuning (PEFT) methods on image classification tasks using the ViT-Base/16 model pretrained on ImageNet-21k.  The methods are evaluated on the FGVC and VTAB-1k benchmarks, which include tasks with varying data disparities.  Metrics reported include average test accuracy, the number of wins against full fine-tuning, the percentage of tuned parameters, and tuning scope. The table highlights the superior performance and parameter efficiency of the proposed VFPT method, demonstrating its ability to outperform existing methods even when dataset disparities exist.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_15_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of the image classification accuracy achieved by various parameter-efficient fine-tuning (PEFT) methods on the VTAB-1k and FGVC benchmarks, using a ViT-Base/16 model pretrained on ImageNet-21k.  It shows the average test accuracy across three runs for each method, the percentage of tuned parameters relative to the total number of parameters, and the tuning scope of each method.  The table also indicates which methods outperform full fine-tuning on various tasks and which ones outperform the state-of-the-art Visual Prompt Tuning (VPT) method.  It highlights the superior performance and parameter efficiency of the proposed Visual Fourier Prompt Tuning (VFPT) method compared to other approaches.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_16_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of image classification accuracy across various parameter-efficient fine-tuning (PEFT) methods on the FGVC and VTAB-1k benchmarks using a ViT-Base/16 model pretrained on ImageNet-21k.  It shows the average test accuracy (over three runs), the number of times each method outperformed full fine-tuning across 24 tasks, the percentage of tuned parameters used, and the tuning scope. The table highlights VFPT's superior performance and efficiency compared to other PEFT methods.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_16_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of image classification accuracies achieved by various parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on the VTAB-1k and FGVC benchmark datasets.  The results are broken down by task category within VTAB-1k (Natural, Specialized, Structured) and across FGVC tasks. The table shows the average test accuracy across three runs for each method, along with the percentage of tuned parameters and the number of times each method outperforms full fine-tuning or VPT.  It highlights the superior performance and parameter efficiency of the proposed VFPT method.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_16_3.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by various parameter-efficient fine-tuning (PEFT) methods on two image classification benchmarks: FGVC and VTAB-1k.  The methods are compared against full fine-tuning (Full), with metrics including the number of wins against Full, the percentage of tuned parameters, and the tuning scope.  The table highlights the superior performance of VFPT (ours) compared to other methods, particularly its high number of wins against Full and low parameter usage.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_17_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on the image classification task using the ViT-Base/16 model pretrained on ImageNet-21k.  The methods are evaluated on the FGVC and VTAB-1k benchmarks.  Metrics include average test accuracy, the number of wins compared to full fine-tuning, and the percentage of tuned parameters.  The table highlights the superior performance and parameter efficiency of the proposed Visual Fourier Prompt Tuning (VFPT) method.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_17_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on two image classification benchmarks: FGVC and VTAB-1k.  The results show the average test accuracy (over three runs) for each method across the benchmarks.  Key metrics include the number of parameters used relative to the total number of model parameters and the number of times each method outperforms full fine-tuning and VPT (another PEFT method) on each task. The table highlights VFPT's superior performance compared to other methods, particularly regarding low parameter usage and high accuracy, especially on tasks with greater differences between the pre-training and fine-tuning datasets.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_17_3.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by various parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on two image classification benchmark datasets: FGVC and VTAB-1k.  The methods are compared based on their number of wins against full fine-tuning, the percentage of tuned parameters, and the scope of their tuning.  The table highlights VFPT's superior performance and efficiency compared to other PEFT approaches and full fine-tuning.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_17_4.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on two image classification benchmarks, FGVC and VTAB-1k, using the ViT-Base/16 model pretrained on ImageNet-21k.  The table shows the average test accuracy across three runs for each method. Key metrics included are the number of wins against full fine-tuning, the percentage of tuned parameters, the tuning scope of each method, and whether additional parameters were used beyond the pretrained backbone and linear head. The table highlights VFPT's superior performance and efficiency compared to other PEFT methods.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_18_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by various methods on two image classification benchmarks: FGVC [4] and VTAB-1k [78].  The methods are compared to a full fine-tuning baseline, indicating the number of times each method outperforms the full fine-tuning approach on each dataset.  The table also lists the percentage of parameters tuned in each method, the tuning scope, and additional parameters used beyond the pretrained backbone and linear head.  The results highlight the performance and parameter efficiency of the proposed method.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_18_2.jpg", "caption": "Table 3: Image classification accuracy for different pretrained objectives \u2014 MAE [90] and MoCo v3 [26] with ViT-Base [23] as backbone. * denotes the rerun results that calibrate the VPT [4]", "description": "This table presents the image classification accuracy results on the VTAB-1k benchmark for different pre-trained objectives (MAE and MoCo v3) using the ViT-Base backbone.  It compares the performance of the proposed VFPT method against several baselines, including full fine-tuning and the original visual prompt tuning (VPT) method.  The table highlights the average test accuracy across three runs for different task groups within the VTAB-1k benchmark (Natural, Specialized, and Structured). The 'Tuned/Total' column indicates the percentage of tuned parameters used in each method, while 'Fourier Percentage' shows the percentage of Fourier components used in VFPT.  The results demonstrate VFPT's superior performance and parameter efficiency compared to other methods, particularly in tasks with significant data disparity.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_18_3.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on the VTAB-1k and FGVC image classification benchmarks using ViT-Base/16 as the backbone model.  It shows the average test accuracy, the number of times each method outperforms full fine-tuning, the percentage of tuned parameters, the tuning scope, and whether additional parameters were used.  The table highlights the superior performance and efficiency of the proposed VFPT method compared to baselines.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_18_4.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k. Following [4, 5], we report the average test accuracy (three runs) on FGVC [4] and VTAB-1k [78] benchmarks, and \"Number of Wins\" in [.] compared to full fine-tuning (Full) [92]. \u25ba denotes the method with highest \"Number of Wins\" compared to Full. We further report \"Number of Wins to VPT\" in {\u00b7}. \u201cTuned/Total\u201d is the average percentage of tuned parameters required by 24 tasks. \"Scope\" indicates the tuning scope of each method. \"Additional parameters\" is the existence of parameters in addition to the pretrained backbone and linear head. Bold and Underline indicate the best and the second best results. VFPT outperforms full fine-tuning in 22 of 24 instances with fewer trainable parameters and beats VPT in 23 of 24 cases with lower parameters. \u2020 denotes methods using soft filtered prompts to reduce the parameter usage in learnable visual prompts, requiring specialized devices to facilitate acceleration. Per-task results are available in Appendix. Same for Table 2 and 3.", "description": "This table presents a comparison of different parameter-efficient fine-tuning (PEFT) methods on image classification tasks using the ViT-Base/16 model pretrained on ImageNet-21k.  It shows the average test accuracy, number of times each method outperforms full fine-tuning, and the percentage of tuned parameters. The table highlights VFPT's superior performance and parameter efficiency compared to other methods, especially VPT, across various image classification datasets.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_18_5.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of image classification accuracies achieved by various parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on the VTAB-1k and FGVC benchmark datasets using a ViT-Base/16 model pre-trained on ImageNet-21k.  It shows the average test accuracy across three runs, the percentage of tuned parameters, the tuning scope of each method, and whether additional parameters were used beyond the pretrained backbone and linear head.  The table highlights the superior performance of Visual Fourier Prompt Tuning (VFPT) in terms of accuracy and parameter efficiency compared to other PEFT methods and full fine-tuning.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_19_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of the performance of various parameter-efficient fine-tuning (PEFT) methods on the VTAB-1k and FGVC image classification benchmarks.  The methods are compared against full fine-tuning and Visual Prompt Tuning (VPT). The table shows the average test accuracy, the number of times each method outperforms full fine-tuning, the percentage of parameters tuned for each method, and the scope of tuning for each method. The results highlight that the proposed method, Visual Fourier Prompt Tuning (VFPT), achieves superior performance with low parameter usage.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_19_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by various parameter-efficient fine-tuning (PEFT) methods on the FGVC [4] and VTAB-1k [78] benchmarks.  It compares the performance of Visual Fourier Prompt Tuning (VFPT) against full fine-tuning (Full), several other PEFT techniques, and visual prompt tuning methods.  Key metrics include the number of wins against full fine-tuning and VPT, the percentage of tuned parameters, the tuning scope, and whether additional parameters were used.  The table highlights VFPT's superior performance and parameter efficiency.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_19_3.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on the VTAB-1k and FGVC image classification benchmarks.  It shows the average test accuracy (over three runs) for each method on each benchmark, the number of times each method outperforms full fine-tuning, the percentage of tuned parameters relative to the total number of parameters in the model, and the scope of tuning for each method.  The table highlights the superior performance of Visual Fourier Prompt Tuning (VFPT) compared to other methods, especially on tasks with high data disparity between the pre-training and fine-tuning datasets.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_20_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by various parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on the FGVC and VTAB-1k benchmarks.  It compares the performance of Visual Fourier Prompt Tuning (VFPT) against baselines, highlighting VFPT's superior performance and lower parameter usage.  Metrics include average accuracy, the number of tasks where a method outperforms full fine-tuning, and the percentage of tuned parameters. The table also indicates whether the methods use additional parameters beyond the pretrained backbone and linear head, and the tuning scope applied.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_20_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by various parameter-efficient fine-tuning (PEFT) methods on two image classification benchmarks: FGVC and VTAB-1k.  The methods are compared against full fine-tuning, providing the number of times each method outperforms full fine-tuning and visual prompt tuning (VPT). The table also shows the percentage of tuned parameters used by each method across the 24 tasks, along with the tuning scope and additional parameters employed.  The results highlight the superior performance of VFPT while using fewer parameters than other PEFT approaches.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_20_3.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the average test accuracy (over three runs) achieved by various parameter-efficient fine-tuning (PEFT) methods on the FGVC and VTAB-1k benchmarks, compared to full fine-tuning.  It shows the number of times each method outperformed full fine-tuning and VPT across the 24 tasks.  Key metrics such as the percentage of tuned parameters, the tuning scope, and the presence of additional parameters are also provided for each method.  Bold and underlined values indicate the best and second-best results, respectively.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_21_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of the image classification accuracy achieved by various parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on the ViT-Base/16 model pretrained on the ImageNet-21k dataset.  The methods are evaluated across 24 tasks from the FGVC and VTAB-1k benchmarks.  The table highlights the average test accuracy, the number of wins compared to full fine-tuning, the percentage of tuned parameters, and the tuning scope of each method.  It provides a quantitative assessment of VFPT's performance against state-of-the-art baselines in terms of accuracy and parameter efficiency.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_21_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of image classification accuracies achieved by various parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on the VTAB-1k and FGVC benchmarks using the ViT-Base/16 model pretrained on ImageNet-21k.  The table shows the average test accuracy across three runs for each method, the number of times each method outperforms full fine-tuning, and the percentage of tuned parameters used relative to the total number of parameters in the model.  It highlights the superior performance and parameter efficiency of the proposed Visual Fourier Prompt Tuning (VFPT) method compared to existing PEFT approaches and full fine-tuning, especially in scenarios with large data disparities between pretraining and finetuning phases.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_22_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the image classification accuracy results for the ViT-Base/16 model pretrained on the supervised ImageNet-21k dataset.  It compares the performance of Visual Fourier Prompt Tuning (VFPT) against several state-of-the-art baselines across two benchmarks, FGVC and VTAB-1k, focusing on different task categories within VTAB-1k (Natural, Specialized, Structured). The table shows the average test accuracy across three runs, the number of wins compared to full fine-tuning, the percentage of tuned parameters, and the tuning scope of each method.  It highlights VFPT's superior performance with low parameter usage.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_22_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the image classification accuracy results for the ViT-Base/16 model pretrained on the supervised ImageNet-21k dataset. It compares the performance of Visual Fourier Prompt Tuning (VFPT) against various other parameter-efficient fine-tuning methods and full fine-tuning on the FGVC and VTAB-1k benchmarks.  The table includes metrics such as average test accuracy, number of wins against full fine-tuning, the percentage of tuned parameters, and the tuning scope of each method.  The results highlight VFPT's superior performance and efficiency.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_22_3.jpg", "caption": "Table S24: Fourier percentage per-task results on VTAB-1k [78] Structured for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents the per-task results on the VTAB-1k Structured benchmark for ViT-Base/16, using different Fourier percentages (0%, 30%, 50%, 70%, and 100%).  It shows the impact of varying the Fourier percentage on the model's performance across various sub-tasks within the Structured group of VTAB-1k.", "section": "S3 Per-task Results on Fourier Percentage"}, {"figure_path": "nkHEl4n0JU/tables/tables_25_1.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of the image classification accuracy achieved by various parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on the VTAB-1k and FGVC benchmarks using the ViT-Base/16 model pretrained on the ImageNet-21k dataset.  The table includes the average test accuracy (over three runs) for each method, the percentage of tuned parameters relative to the total number of parameters, the scope of tuning (input, backbone, etc.), and whether additional parameters were added beyond the pretrained backbone and linear head.  It also indicates the number of times each method outperformed full fine-tuning and VPT across the different tasks.", "section": "4.2 Main Results"}, {"figure_path": "nkHEl4n0JU/tables/tables_25_2.jpg", "caption": "Table 1: Image classification accuracy for ViT-Base/16 [23] pretrained on supervised ImageNet-21k.", "description": "This table presents a comparison of various parameter-efficient fine-tuning (PEFT) methods on two image classification benchmarks: FGVC and VTAB-1k.  The methods are evaluated based on their average test accuracy, the number of times they outperform full fine-tuning, the percentage of tuned parameters, and the tuning scope.  The table highlights the performance and efficiency of VFPT in comparison to other PEFT methods, especially in scenarios with high data disparity between pretraining and finetuning datasets.", "section": "4.2 Main Results"}]