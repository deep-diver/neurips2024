{"references": [{"fullname_first_author": "Brian Lester", "paper_title": "The power of scale for parameter-efficient prompt tuning", "publication_date": "2021-00-00", "reason": "This paper introduced the concept of prompt tuning, a parameter-efficient technique that is foundational to the proposed method in the current paper."}, {"fullname_first_author": "Menglin Jia", "paper_title": "Visual prompt tuning", "publication_date": "2022-00-00", "reason": "This paper introduced visual prompt tuning, a technique directly extended and improved upon in the current paper."}, {"fullname_first_author": "Cheng Han", "paper_title": "E2vpt: An effective and efficient approach for visual prompt tuning", "publication_date": "2023-00-00", "reason": "This paper is a state-of-the-art approach for visual prompt tuning that directly addresses the challenges highlighted in the current paper."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduced the Vision Transformer architecture, a backbone model used in the current paper."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduced the Masked Autoencoder (MAE) model, a self-supervised method used as a pretraining objective in the current paper."}]}