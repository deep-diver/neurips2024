{"references": [{"fullname_first_author": "Emmanuel Abbe", "paper_title": "The merged-staircase property: How hierarchical structure can guide deep learning", "publication_date": "2021-00-00", "reason": "This paper introduces the concept of the merged-staircase property, which is highly relevant to understanding the hierarchical structure of deep learning and is directly referenced in the discussion about the bottleneck structure."}, {"fullname_first_author": "Ricky TQ Chen", "paper_title": "Neural ordinary differential equations", "publication_date": "2018-00-00", "reason": "This paper introduces Neural Ordinary Differential Equations (NODEs), which are crucial to understanding the continuous approximation of ResNets used in this work."}, {"fullname_first_author": "Arthur Jacot", "paper_title": "Bottleneck structure in learned features: Low-dimension vs regularity tradeoff", "publication_date": "2023-00-00", "reason": "This paper directly addresses the topic of Bottleneck structures in deep neural networks, providing theoretical and empirical support for the phenomenon discussed and investigated in the current study."}, {"fullname_first_author": "Naftali Tishby", "paper_title": "Deep learning and the information bottleneck principle", "publication_date": "2015-00-00", "reason": "This paper introduces the Information Bottleneck theory, which is a significant theoretical framework for understanding feature learning and is directly connected to the ideas explored here about the tradeoff between dimensionality reduction and information preservation."}, {"fullname_first_author": "Vardan Papyan", "paper_title": "Prevalence of neural collapse during the terminal phase of deep learning training", "publication_date": "2020-00-00", "reason": "This paper investigates neural collapse, a phenomenon that is highly relevant to the study of feature learning in deep networks and the emergence of low-dimensional representations, and thus provides valuable context for the paper's analysis."}]}