[{"figure_path": "cKKXBhyijL/figures/figures_2_1.jpg", "caption": "Figure 1: An illustrative image of a soft tree structure with D = 3. As shown in the left plot, we have N := 2D \u2212 1 internal nodes (green) and L := 2D leaf nodes (orange), indexed using breadth-first ordering. The right plot shows an illustrative example where a soft tree calculates the weight probabilities p\u03b9(\u00b7) for the leaf nodes.", "description": "This figure illustrates the structure of a soft tree with depth D=3. The left plot shows the tree structure with internal nodes (green) and leaf nodes (orange) labeled using breadth-first ordering.  The number of internal nodes is N = 2D -1 and the number of leaf nodes is L = 2D. The right plot demonstrates how a soft tree computes the weight probabilities for each leaf node using the soft decision function.", "section": "Soft tree ensemble"}, {"figure_path": "cKKXBhyijL/figures/figures_8_1.jpg", "caption": "Figure 2: The average cumulative regret with one standard error. The experiment was conducted over 10 episodes with different initial parameters for the model.", "description": "This figure displays the average cumulative regret across 10 experimental runs for four different bandit algorithms (NN-UCB, ST-UCB, NN-greedy, ST-greedy).  Each algorithm's performance is shown for three different scenarios in the real-world dataset (varying the number of arms K) and three different reward functions in a synthetic dataset. Error bars representing one standard error are included for each data point.  The results illustrate the relative performance of the algorithms under different conditions and problem complexities. ", "section": "Numerical experiments"}, {"figure_path": "cKKXBhyijL/figures/figures_44_1.jpg", "caption": "Figure 3: The average cumulative regret with one standard error in the real-world dataset.", "description": "The figure shows the average cumulative regret across 10 episodes with different initial parameters for three different numbers of arms (K=20, 40, 60) in the real-world dataset.  For each number of arms, there are three subplots, each corresponding to a different setting of the exploration parameters (\u03b2, \u03b5). The plots compare the performance of four algorithms: NN-UCB, ST-UCB, NN-greedy, and ST-greedy.  Error bars representing one standard error are included for each algorithm.", "section": "Numerical experiments"}, {"figure_path": "cKKXBhyijL/figures/figures_44_2.jpg", "caption": "Figure 4: The average cumulative regret with one standard error in the synthetic dataset.", "description": "This figure shows the average cumulative regret of four different bandit algorithms (NN-UCB, ST-UCB, NN-greedy, ST-greedy) across three different synthetic reward functions (f(1), f(2), f(3)) and three different exploration parameters (\u03b2 = 0.01, 0.1, 1).  The error bars represent one standard error.  The x-axis represents the number of rounds, and the y-axis represents the cumulative regret.", "section": "Numerical experiments"}]