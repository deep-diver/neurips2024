[{"figure_path": "zO55ovdLJw/figures/figures_3_1.jpg", "caption": "Figure 1: The overview of our proposed framework. We first select the prompt PT and Pl with m\u2208 {c,M1,M2} for the text encoder and image encoder according to the missing case (e.g., complete, text-only, image-only) of the multimodal inputs (xm1, xm2). The prompt PT (Pl) is composed of three types of missing-aware prompts including the correlated prompts PTR (PIR), dynamic prompts PT,D (PI,D) and modal-common prompts PT,C (PI,C). Then we prepend the prompts to the inputs and intermediate features of both encoders to instruct the model to fit the missing case. Finally, we concatenate the task-related token of both encoders as the final representation, and pass it through a fully-connected layer for class prediction. In the whole procedure, only the fully-connected (fc) layer and deep correlated prompts are updated while others keep frozen.", "description": "This figure illustrates the overall framework of the proposed deep correlated prompting method for handling missing modalities in visual recognition.  It shows how modality-complete and modality-incomplete inputs are processed. The key components are the selection of prompts based on the missing modality, the incorporation of correlated, dynamic, and modal-common prompts, and the use of a fully-connected layer for final prediction.  The pretrained multimodal backbone (encoders) remains frozen during training, significantly reducing computational cost.", "section": "3 Method"}, {"figure_path": "zO55ovdLJw/figures/figures_4_1.jpg", "caption": "Figure 2: (1) Baseline, which simply uses fixed image encoder and text encoder and only finetunes the classifier to handle downstream tasks. (2) MMP, which inserts independent prompts at each layer to guide the model to handle missing-modality cases. (3) Correlated prompts, which generate the prompts of the next layer based on the prompts of both modalities in the current layer to enable cooperation of prompts from both modalities. (4) Dynamic prompts, which dynamically computes the prompts based on different input features to better guide the behavior of the model, avoiding using fixed prompts for different inputs. (5) Modal-common prompts, which store the shared information across different modalities and facilitate the model to encode modal-specific information to better handle the missing scenarios in each modality.", "description": "This figure illustrates five different approaches for handling missing modalities in multimodal learning.  The baseline uses a standard model with no prompt.  MMP uses independent prompts at each layer. Correlated prompting uses prompts that leverage information from previous layers. Dynamic prompting generates prompts based on input features. Modal-common prompting incorporates shared information across modalities.", "section": "3.2 Overall framework"}, {"figure_path": "zO55ovdLJw/figures/figures_7_1.jpg", "caption": "Figure 3: Comparison of our final model (Ours) with (1) baseline, which directly drops the features when a modality is missing; (2) Ours (A), which only equips the correlated prompts; (3) Ours (B), which equips both the correlated prompts and the dynamic prompts. The experiments are conducted on the val set of MM-IMDb dataset [2] across different missing rates (0\u2013100%) upon three different missing-modality scenarios (missing-both, missing-image and missing-text).", "description": "This figure shows the performance comparison of different model variations on the MM-IMDb dataset under various missing modality scenarios.  The x-axis represents the missing rate (0% to 100%), and the y-axis represents the F1-Macro score. The baseline model simply ignores missing modalities.  Ours(A) uses only correlated prompts, Ours(B) uses correlated and dynamic prompts, and Ours uses all three proposed prompt types (correlated, dynamic, and modal-common). The results demonstrate that incorporating all three prompt types yields the best performance across all missing-modality scenarios and missing rates.  The performance degradation is less significant when only images are missing, highlighting the importance of text for this specific task.", "section": "4.2 Experimental Results"}, {"figure_path": "zO55ovdLJw/figures/figures_8_1.jpg", "caption": "Figure 3: Comparison of our final model (Ours) with (1) baseline, which directly drops the features when a modality is missing; (2) Ours (A), which only equips the correlated prompts; (3) Ours (B), which equips both the correlated prompts and the dynamic prompts. The experiments are conducted on the val set of MM-IMDb dataset [2] across different missing rates (0\u2013100%) upon three different missing-modality scenarios (missing-both, missing-image and missing-text).", "description": "This figure compares the performance of the proposed model (Ours) against a baseline and two intermediate versions (Ours (A) and Ours (B)) across different missing modality scenarios and rates on the MM-IMDb dataset. It shows the effectiveness of incorporating the correlated and dynamic prompts in improving robustness to missing modalities.", "section": "4.2 Experimental Results"}, {"figure_path": "zO55ovdLJw/figures/figures_13_1.jpg", "caption": "Figure 5: All models are trained with modality-complete data, where each data pair can be randomly assigned with different missing modalities (i.e., text-only, image-only, and modality-complete) at different training epochs to mimic the possible missing modalities during testing. Evaluation is on missing-both cases with different missing rates.", "description": "This figure shows the results of an experiment where models are trained on modality-complete data but evaluated on data with both modalities missing (missing-both).  The missing rate is varied from 0% to 100%. Three methods are compared: Baseline (simply sets missing features to zero), MMP (uses independent prompts), and the proposed method (Deep Correlated Prompting, DCP). The results demonstrate that DCP consistently outperforms the other two methods across all missing rates.", "section": "A Appendix / supplemental material"}]