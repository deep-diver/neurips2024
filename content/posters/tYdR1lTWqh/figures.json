[{"figure_path": "tYdR1lTWqh/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of the logit subtraction operation. We simulate the output distribution of an unlearned LLM using the assistant LLM\u2019s output.", "description": "This figure illustrates how the Unlearning from Logit Difference (ULD) method works.  It shows two scenarios: a query about Isaac Newton (forget data) and a query about Aristotle (retain data).  In both cases, the original LLM\u2019s output logits are shown, along with the assistant LLM\u2019s logits.  The key is the subtraction operation:  the assistant LLM is trained to remember the forget data and forget the retain data. Subtracting its logits from the original LLM's logits results in a new logit distribution (the unlearned LLM) where the probability of generating correct answers related to the forget data is reduced, while maintaining the probabilities of generating correct answers about the retain data.", "section": "2.2 ULD: An Overview"}, {"figure_path": "tYdR1lTWqh/figures/figures_7_1.jpg", "caption": "Figure 3: CE loss of unlearned LLM along training on the forget data Df (left) and retain data not covered by Dr (right). The loss of ULD is evaluated on the unlearn LLM derived using logit-subtraction. We select baselines with KL retain loss in this figure. Appendix Figure 10 shows the full results.", "description": "This figure shows the cross-entropy loss curves for different unlearning methods on both forget and retain data during the training process.  The left panel displays the forget loss (on the forget data), highlighting that ULD's loss remains bounded while others diverge.  The right panel shows the retain loss (on the retain data not covered by the retain set), showing that ULD maintains stable loss while others increase rapidly, indicating catastrophic forgetting.  Only baselines using the KL retain loss are included for clarity.  The full results (including all baselines) are available in Appendix Figure 10.", "section": "4.1 Training Stability"}, {"figure_path": "tYdR1lTWqh/figures/figures_8_1.jpg", "caption": "Figure 5: Log forget quality versus relative training time to ULD on TOFU-10%. The top-left corner indicates better forget performance and efficiency.", "description": "This figure compares the training efficiency of different unlearning methods on the TOFU-10% dataset. The y-axis represents the forget quality (log scale), while the x-axis shows the relative training time per epoch compared to the ULD method.  A point closer to the top-left corner signifies better forget performance and higher training efficiency. ULD is shown to be significantly more efficient than the other methods, achieving comparable or superior forget quality in much less training time.", "section": "4.2 Training Efficiency"}, {"figure_path": "tYdR1lTWqh/figures/figures_15_1.jpg", "caption": "Figure 1: Illustration of the logit subtraction operation. We simulate the output distribution of an unlearned LLM using the assistant LLM\u2019s output.", "description": "This figure illustrates how the logit subtraction operation works in the Unlearning from Logit Difference (ULD) framework.  It shows two examples. In the first, a query about Isaac Newton (forget data) is processed.  Both the original and assistant LLMs have high probabilities for the correct answer ('physicist'). The logit subtraction operation lowers the probability of the original LLM generating this answer, achieving the desired forgetting. In the second example, a query about Aristotle (retain data) is processed. The assistant LLM outputs a uniform distribution, meaning the subtraction does not change the distribution of the original LLM, preserving knowledge about Aristotle.", "section": "2.2 ULD: An Overview"}, {"figure_path": "tYdR1lTWqh/figures/figures_16_1.jpg", "caption": "Figure 1: Illustration of the logit subtraction operation. We simulate the output distribution of an unlearned LLM using the assistant LLM\u2019s output.", "description": "The figure shows how the logit subtraction operation works with the assistant LLM.  Part (a) illustrates a query about forget data (Isaac Newton), where both the original and assistant LLMs have high probabilities for the correct answer ('physicist'). Subtracting the assistant's logits lowers the probability of the correct answer for the original LLM.  Part (b) shows a query involving retain data (Aristotle), where the assistant LLM outputs a uniform distribution.  Therefore, subtracting the assistant LLM's logits doesn't significantly change the original LLM's output distribution.", "section": "2.2 ULD: An Overview"}, {"figure_path": "tYdR1lTWqh/figures/figures_16_2.jpg", "caption": "Figure 2: Illustration of constructing the assistant LLM utilizing the target LLM itself. Note that we fix the assistant LLM's parameter and only optimize the added LoRA layers.", "description": "This figure illustrates how the assistant LLM is constructed using the target LLM.  The assistant LLM uses the first K layers of the target LLM's transformer model, instead of training a completely separate model.  The Language Model head is shared between the two LLMs.  Only the added LoRA layers in the assistant LLM are optimized during training, making the training process more efficient.", "section": "2.5 Architecture Design of the Assistant LLM"}, {"figure_path": "tYdR1lTWqh/figures/figures_17_1.jpg", "caption": "Figure 1: Illustration of the logit subtraction operation. We simulate the output distribution of an unlearned LLM using the assistant LLM's output.", "description": "This figure illustrates how the logit subtraction operation works in the Unlearning from Logit Difference (ULD) framework. It shows two examples: one for a query related to forget data (Isaac Newton), and one for a query related to retain data (Aristotle).  In the forget data example, both the original LLM and the assistant LLM have high probabilities for the correct answer ('physicist'). The logit subtraction reduces the original LLM's probability for this correct answer, effectively making it forget the information. In the retain data example, the assistant LLM outputs a flat distribution, so the subtraction does not affect the original LLM's output, preserving the knowledge.", "section": "2.2 ULD: An Overview"}, {"figure_path": "tYdR1lTWqh/figures/figures_22_1.jpg", "caption": "Figure 3: CE loss of unlearned LLM along training on the forget data Df (left) and retain data not covered by Dr (right). The loss of ULD is evaluated on the unlearn LLM derived using logit-subtraction. We select baselines with KL retain loss in this figure. Appendix Figure 10 shows the full results.", "description": "This figure displays the cross-entropy (CE) loss curves for different unlearning methods during training. The left panel shows the loss on the forget data (Df), while the right panel shows the loss on the retain data not covered by the retain set (Dr).  The figure highlights the training stability of ULD compared to baselines that use KL divergence for the retain loss. ULD shows stable and bounded loss curves, unlike baselines that exhibit instability and unbounded growth, particularly in the forget loss.  The full results, including baselines that do not use KL divergence, can be found in Appendix Figure 10.", "section": "4.1 Training Stability"}]