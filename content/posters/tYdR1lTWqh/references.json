{"references": [{"fullname_first_author": "Nicholas Carlini", "paper_title": "Extracting training data from large language models", "publication_date": "2021-08-00", "reason": "This paper is foundational to the field of LLM unlearning by highlighting the vulnerability of LLMs to training data extraction, motivating the need for effective unlearning techniques."}, {"fullname_first_author": "Aditya Golatkar", "paper_title": "Eternal sunshine of the spotless net: Selective forgetting in deep networks", "publication_date": "2020-00-00", "reason": "This paper introduces the concept of \"selective forgetting\" in neural networks, a core concept that is relevant to the goal of LLM unlearning where the objective is to remove specific data while preserving overall model utility."}, {"fullname_first_author": "Yuanshun Yao", "paper_title": "Large language model unlearning", "publication_date": "2023-10-00", "reason": "This paper is a recent and highly relevant work that directly addresses the problem of LLM unlearning by proposing specific methods and highlighting the challenges involved."}, {"fullname_first_author": "Pratyush Maini", "paper_title": "TOFU: A task of fictitious unlearning for LLMs", "publication_date": "2024-01-00", "reason": "This paper introduces a benchmark dataset for evaluating LLM unlearning methods, providing a standardized way to compare different techniques and facilitating further research in the field."}, {"fullname_first_author": "Ruiqi Zhang", "paper_title": "Negative preference optimization: From catastrophic collapse to effective unlearning", "publication_date": "2024-04-00", "reason": "This paper proposes a novel unlearning method that addresses the limitations of previous approaches by focusing on negative preference optimization, offering an alternative perspective to the LLM unlearning problem."}]}