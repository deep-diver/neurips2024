[{"type": "text", "text": "On the Computational Complexity of Private High-dimensional Model Selection ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Saptarshi Roy Zehua Wang Ambuj Tewari ", "page_idx": 0}, {"type": "text", "text": "Department of Statistics University of Michigan, Ann Arbor {roysapta, wangzeh, tewaria}@umich.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the problem of model selection in a high-dimensional sparse linear regression model under privacy constraints. We propose a differentially private (DP) best subset selection method with strong statistical utility properties by adopting the well-known exponential mechanism for selecting the best model. To achieve computational expediency, we propose an efficient Metropolis-Hastings algorithm and under certain regularity conditions, we establish that it enjoys polynomial mixing time to its stationary distribution. As a result, we also establish both approximate differential privacy and statistical utility for the estimates of the mixed Metropolis-Hastings chain. Finally, we perform some illustrative experiments on simulated data showing that our algorithm can quickly identify active features under reasonable privacy budget constraints. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In this paper, we consider the problem of private model selection in high-dimensional sparse regression which has been one of the central topics in statistical research over the past decade. Consider $n$ observations $\\{(\\mathbf{x}_{i},y_{i})\\}_{i=1}^{n}\\subseteq\\mathcal{X}\\times\\mathcal{Y}$ following the linear model: ", "page_idx": 0}, {"type": "equation", "text": "$$\ny_{i}=\\mathbf{x}_{i}^{\\top}{\\boldsymbol{\\beta}}+w_{i},\\quad i\\in\\{1,\\ldots,n\\},\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $\\{\\mathbf{x}_{i}\\}_{i\\in[n]}$ are fixed $p$ -dimensional feature vectors, $\\{w_{i}\\}_{i\\in[n]}$ are i.i.d. mean-zero $\\sigma$ -subGaussian noise, i.e., $\\mathbb{E}\\exp(\\lambda w_{i})\\,\\le\\,\\exp(\\lambda^{2}\\sigma^{2}/2)$ for all $\\lambda\\in\\mathbb R$ and $i\\in[n]$ , and the signal vector $\\beta\\in\\mathbb{R}^{p}$ is unknown but is assumed to have a sparse support. In matrix notation, the observations can be represented as ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\mathbf{y}=\\mathbf{X}\\beta+\\mathbf{w},\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $\\mathbf{y}=(y_{1},\\ldots,y_{n})^{\\top}$ , $\\mathbf{X}=(\\mathbf{x}_{1},\\ldots,\\mathbf{x}_{n})^{\\top}$ , and $\\mathbf{w}=(w_{1},\\hdots,w_{n})^{\\top}$ . We consider the standard high-dimensional sparse setup where $n<p$ , and possibly $n\\ll p$ , and the vector $\\beta$ is sparse in the sense that $\\begin{array}{r}{\\|\\beta\\|_{0}:=\\bar{\\sum_{j=1}^{p}}\\mathbb{1}(\\bar{\\beta}_{j}\\neq0)=s}\\end{array}$ , which is much smaller than $p$ . The main goal of variable selection is to identify the active set $\\gamma^{*}:=\\{j:\\beta_{j}\\neq0\\}$ . ", "page_idx": 0}, {"type": "text", "text": "For the past two decades, there has been ample work on model selection problem in the non-private setting for $\\ell_{1}$ -penalized methods[57, 54, 46, 23], concave regularized methods [55, 53, 12, 16], $\\ell_{0}$ - penalized/constrained methods [13, 1, 37, 39] in high-dimensional setting. On the computational side, recent advancements related to mixed integer optimization (MIO) in [4, 5] and [20] have pushed the computational barrier of best subset selection (BSS) in terms of solving problems of large dimensions (large $p$ ), and consequently, simulation studies in [19] have revealed the improved performance of BSS over its computational surrogates like LASSO, SCAD, and MCP. ", "page_idx": 0}, {"type": "text", "text": "Despite these theoretical and computational advancements related to BSS, to the best of our knowledge, there is no computationally efficient private algorithmic framework for BSS for highdimensional sparse regression setup (1). This is especially surprising as private model selection is important in many contemporary applications involving sensitive data including genetics [21], neuroimaging [33], and computer vision [56]. One major reason for this could be the lack of DP mechanisms for MIO problems which restricts us from exploiting the MIO formulation of BSS introduced in [4]. Secondly, the apparent computational burden stemming from the requirement of exponentially large numbers of search queries in private BSS has eluded the majority of the machine learning and statistics community. In this paper, we address the latter issue by mainly focusing on the utility and computational complexity of BSS under privacy constraints. To be specific, we make the following contributions listed below: ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "1. We adopt the exponential mechanism [31] to design a DP BSS algorithm, and we establish its good statistical or utility guarantee under high-privacy regime whenever $\\begin{array}{r}{\\beta_{m i n}:=\\operatorname*{min}_{j\\in\\gamma^{*}}|\\beta_{j}|\\gtrsim\\sigma\\{(s\\log p)/\\dot{n}\\}^{\\bar{1}/2}}\\end{array}$ . 2. Under the low-privacy regime, we show that accurate model recovery is possible whenever $\\beta_{m i n}\\gtrsim\\sigma\\{(\\log p)/n\\}^{1/2}$ , which is the minimax optimal $\\beta_{m i n}$ requirement for model recovery under non-private setting. Therefore, this paper points out an inflection phenomenon in the signal strength requirement for the model consistency across different privacy regimes. 3. In addition, we design an MCMC chain that converges to its stationary distribution that matches the sampling distribution in the exponential mechanism. As a consequence, the model estimator generated by the MCMC also enjoys (approximate) DP. Furthermore, under certain regularity conditions on the design, we show that the MCMC chain enjoys a polynomial mixing time in $(n,p,s)$ to the stationary distribution with good utility guarantee. ", "page_idx": 1}, {"type": "text", "text": "In summary, this paper proposes a DP version of BSS that generates a private model estimator of $\\gamma^{*}$ with strong model recovery property within polynomial time in the problem parameters $n,p,s$ . In the next section, we will discuss some prior related works on DP model selection and discuss some of their limitations. ", "page_idx": 1}, {"type": "text", "text": "1.1 Comparison with Prior Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In the past decades, there has been a considerable amount of work studying DP sparse regression problems. However, most of these works focus either on empirical risk minimization [25, 44, 26, 48] or establishing $\\ell_{2}$ -consistency rate [47, 6] which are not directly related to the task of model selection. To the best of our knowledge, there are only three works considering the problem of variable selection in sparse regression problems under the DP framework, [27, 45], and [29]. Table 1 shows a clear comparison between those methods and our method. [27] proposed two algorithms under sparse regression setting. One of them is based on the exponential mechanism, which is known to be computationally inefficient due to exponentially large numbers of search queries. However, they do not analyze the algorithm under the model selection framework. Moreover, for the privacy analysis, they assume that the loss functions are bounded over the space of sparse vectors, which is rather restrictive in the linear regression setting. In comparison, our paper provides a solid model recovery guarantee (Theorem 3.5) for a similar exponential mechanism without using the bounded loss assumption. Furthermore, under a slightly stronger assumption, we design a computationally efficient MCMC algorithm that also enjoys desirable utility similar to the exponential mechanism (Theorem 4.3) under DP framework. The other algorithm in [27] is based on the resample-andaggregate framework [36, 42]. Although computationally efficient, this method requires sub-optimal $\\beta_{m i n}$ condition compared to Theorem 3.5. In [45], the authors introduced two concepts of stability for LASSO and proposed two PTR-based (propose-test-release) algorithms for variable selection. However, these methods have nontrivial probabilities of outputting the null (no result), which is undesirable in practice. Also, the support recovery probabilities for these methods do not approach 1 with a growing sample size even under the strong irrepresentability condition [57] on the design matrix. In [29], the authors proposed to use the Akaike information criterion or Bayesian information criterion coupled with the exponential mechanism to choose the proper model. However, the runtime of this algorithm is exponential and also requires stronger $\\beta_{m i n}$ condition. As mentioned earlier, in this paper, we show that our proposed MCMC algorithm is both computationally efficient and produces approximate DP estimates of $\\gamma^{*}$ with a strong utility guarantee under a better $\\beta_{m i n}$ condition. One may also apply sparse vector techniques (SVT) to choose important features [43]. In this case, each feature can be associated with an appropriate choice of score function, and then apply SVT to choose the relevant features. However, the choice of the score function in high-dimensional sparse regression cases remains unclear, and moreover, it is also known that the exponential mechanism enjoys better accuracy compared to SVT [30] under such an offline setting. ", "page_idx": 1}, {"type": "table", "img_path": "PzG7xVlYqm/tmp/920b5fae4f1c411feabbb2779bb0631ec76464ad92a8c4069cfe845207e551ae.jpg", "table_caption": ["Table 1: Comparison of DP model selection methods. "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "2 Differential Privacy ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Differential privacy requires the output of a randomized procedure to be robust with respect to a small perturbation in the input dataset, i.e., an attacker can hardly recover the presence or absence of a particular individual in the dataset based on the output only. It is important to note that differential privacy is a property of the randomized procedure, rather than the output obtained. ", "page_idx": 2}, {"type": "text", "text": "2.1 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we will formalize the notion of differential privacy. Consider a dataset $D:=$ $\\{z_{1},\\ldots,z_{n}\\}\\in{\\mathcal{Z}}^{n}$ consisting of $n$ datapoints in the sample space $\\mathcal{Z}$ . A randomized algorithm $\\boldsymbol{\\mathcal{A}}$ maps the dataset $D$ to $A(D)\\in{\\mathcal{O}}$ , an output space. Thus, ${\\mathcal{A}}(D)$ is a random variable on the output space $\\scriptscriptstyle\\mathcal{O}$ . ", "page_idx": 2}, {"type": "text", "text": "For any two datasets $D$ and $D^{\\prime}$ , we say they are neighbors if $\\vert D\\Delta D^{\\prime}\\vert=1$ . We can now formally introduce the definition of differential privacy. ", "page_idx": 2}, {"type": "text", "text": "Definition 2.1 ( $\\mathit{\\check{\\Psi}}(\\varepsilon,\\delta)$ -DP, [9]). Given the privacy parameters $(\\varepsilon,\\delta)\\in\\mathbb{R}^{+}\\times\\mathbb{R}^{+}$ , a randomized algorithm $A(\\cdot)$ is said to satisfy the $(\\varepsilon,\\delta)$ -DP property $i f$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\boldsymbol{A}(\\boldsymbol{D})\\in\\boldsymbol{K})\\le e^{\\varepsilon}\\mathbb{P}(\\boldsymbol{A}(\\boldsymbol{D}^{\\prime})\\in\\boldsymbol{K})+\\delta\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "for any measurable event $K\\in r a n g e(A)$ and for any pair of neighboring datasets $D$ and $D^{\\prime}$ . ", "page_idx": 2}, {"type": "text", "text": "In the above definition, the probability is only with respect to the randomness of the algorithm $A(\\cdot)$ , and it does not impose any condition on the distribution of $D$ or $D^{\\prime}$ . If both $\\varepsilon$ and $\\delta$ are small, then Definition 2.1 essentially entails that distribution of ${\\mathcal{A}}(D)$ and ${\\mathcal{A}}(D^{\\prime})$ are almost indistinguishable from each other for any choices of neighboring datasets $D$ and $D^{\\prime}$ . This guarantees strong privacy against an attacker by masking the presence or absence of a particular individual in the dataset. As a special case, when $\\delta=0$ , the notion of DP in Definition 2.1 is known as the pure differential privacy. ", "page_idx": 2}, {"type": "text", "text": "2.2 Privacy Mechanisms ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "For any DP procedure, a specific randomized procedure $\\boldsymbol{\\mathcal{A}}$ must be designed that takes a database $D\\in{\\mathcal{Z}}^{n}$ as input and returns an element of the output space $\\scriptscriptstyle\\mathcal{O}$ while satisfying the condition in (2). Several approaches exist that are generic enough to be adaptable to different tasks, and which often serve as building blocks for more complex ones. A few popular examples include the Laplace mechanism [11], Gaussian mechanism [10], and Exponential mechanism [31]. We only provide the details of the last technique, since the other two techniques are out-of-scope for the methods and experiments in this paper. ", "page_idx": 2}, {"type": "text", "text": "Exponential mechanism: The exponential mechanism is designed for discrete output space, Suppose $\\mathcal{S}=\\{\\alpha_{i}:i\\in\\mathbb{Z}\\}$ for some index set $\\mathcal{T}$ , and let $u:\\mathcal{S}\\times\\mathcal{Z}^{n}\\to\\mathbb{R}$ be score function that measures the quality of $\\alpha\\in\\mathcal S$ . Denote by $\\Delta u_{K}$ the global sensitivity of the score function $u$ , i.e. ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Delta u_{K}:=\\operatorname*{max}_{\\alpha\\in\\mathcal{S}}\\operatorname*{max}_{D,\\,D^{\\prime}\\;\\mathrm{are\\;neighbors}}\\left|u(\\alpha,D)-u(\\alpha,D^{\\prime})\\right|.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Intuitively, sensitivity quantifies the effect of any individual in the dataset on the outcome of the analysis. The score function $u(\\cdot,\\cdot)$ is called data monotone if the addition of a data record can either increase (decrease) or remain the same with any outcome, e.g., $u(\\alpha,D)\\leq u(\\alpha,D\\cup\\{z\\})$ . Next, we have the following result. ", "page_idx": 3}, {"type": "text", "text": "Lemma 2.2 ([8, 31]). Exponential mechanism $A_{E}(D)$ that outputs samples from the probability distribution ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\mathcal{A}_{E}(D)=\\alpha)\\propto\\exp\\left\\{\\frac{\\varepsilon u(\\alpha,D)}{\\Delta u}\\right\\}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "preserves $(2\\varepsilon,0)$ -differential privacy. If $u(\\cdot,\\cdot)$ is data monotone, then we have $(\\varepsilon,0)$ -differential privacy. ", "page_idx": 3}, {"type": "text", "text": "In general, if the $\\mathcal{S}$ is too large, the sampling from the distribution could be computationally inefficient. However, we show below that the special structure of the linear model (1) allows us to design an MCMC chain that can generate approximate samples efficiently from the distribution (3) for privately solving BSS under an appropriately chosen score function. ", "page_idx": 3}, {"type": "text", "text": "3 Best Subset Selection ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We briefly review the preliminaries of BSS, one of the most classical variable selection approaches. For a given sparsity level $\\widehat{s},$ , BSS solves for $\\begin{array}{r}{\\widehat{\\beta}_{\\mathrm{best}}(\\widehat{\\boldsymbol{s}}):=\\arg\\operatorname*{min}_{\\boldsymbol{\\theta}\\in\\mathbb{R}^{p},\\|\\boldsymbol{\\theta}\\|_{0}\\leq\\widehat{\\boldsymbol{s}}}\\left\\|\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\theta}\\right\\|_{2}^{2}}\\end{array}$ . For model selection purposes, we can choose the best ftiting model to be $\\widehat{\\gamma}_{\\mathrm{best}}(\\widehat{s}):=\\{j:[\\widehat{\\beta}_{\\mathrm{best}}(\\widehat{s})]_{j}\\neq0\\}$ . For a subset $\\gamma\\subseteq[p]$ , define the matrix $\\mathbf{X}_{\\gamma}:=(\\mathbf{X}_{j};j\\in\\gamma)$ . Let $\\Phi_{\\gamma}:=\\mathbf{X}_{\\gamma}(\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma})^{-1}\\mathbf{X}_{\\gamma}^{\\top}$ be orthogonal projection operator onto the column space of $\\mathbf{X}_{\\gamma}$ . Also, define the corresponding residual sum of squares (RSS) for model $\\gamma$ as $L_{\\gamma}(\\mathbf{y},\\mathbf{X}):=\\mathbf{y}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{y}$ . With this notation, the $\\widehat{\\gamma}_{\\mathrm{best}}(\\widehat{s})$ can be alternatively written as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{\\gamma}_{\\mathrm{best}}(\\widehat{s}):=\\arg\\operatorname*{min}_{\\gamma\\subseteq[p]:|\\gamma|\\leq\\widehat{s}}L_{\\gamma}(\\mathbf{y},\\mathbf{X}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Let $\\mathbf{X}_{\\gamma}$ be the matrix comprised of only the columns of $\\mathbf{X}$ with indices in $\\gamma$ , and $\\Phi_{\\gamma}$ denotes the orthogonal projection matrix onto the column space of $\\mathbf{X}_{\\gamma}$ . In addition, let $\\widehat{\\pmb{\\Sigma}}:=n^{-1}\\mathbf{X}^{\\top}\\mathbf{X}$ be the sample covariance matrix and for any two sets $\\gamma_{1}$ ${\\mathrm{1}},{\\gamma}_{2}\\subset[p]$ , $\\widehat{\\Sigma}_{\\gamma_{1},\\gamma_{2}}$ denotes t he submatrix of $\\Sigma$ with row indices in $\\gamma_{1}$ and column indices in $\\gamma_{2}$ . Finally, defin e the collection $\\mathcal{A}_{\\widehat{s}}:=\\left\\{\\gamma\\subset\\left[p\\right]:\\gamma\\neq\\right.$ $\\gamma^{*},|\\gamma|=\\widehat{s}\\}$ , and for $\\gamma\\in\\mathcal{A}_{s}$ write $\\Gamma(\\gamma)=\\widehat{\\pmb{\\Sigma}}_{\\gamma^{*}\\backslash\\gamma,\\gamma^{*}\\backslash\\gamma}-\\widehat{\\pmb{\\Sigma}}_{\\gamma^{*}\\backslash\\gamma,\\gamma}\\widehat{\\pmb{\\Sigma}}_{\\gamma,\\gamma}^{-1}\\widehat{\\pmb{\\Sigma}}_{\\gamma,\\gamma^{*}\\backslash\\gamma}$ . Then, it follows that $\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}$ is equal to the residualized signal strength $n^{-1}\\|(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}\\backslash\\gamma}\\beta_{\\gamma^{*}\\backslash\\gamma}\\|_{2}^{2}$ . Therefore, $\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}$ quantifies the separation between $\\gamma$ and the true model $\\gamma^{*}$ . Ideally, a larger value of the quantity will help BSS to discriminate between $\\gamma^{*}$ and any other candidate model $\\gamma$ . More details on this can be found in [40]. Now we are ready to introduce the identifiability margin that characterizes the model discriminative power of BSS. ", "page_idx": 3}, {"type": "text", "text": "3.1 Identifiability Margin ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The discussion in Section 3 motivates us to define the following identifiablity margin: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathfrak{m}_{*}(\\widehat{s}):=\\operatorname*{min}_{\\gamma\\in\\mathcal{A}_{\\widehat{s}}}\\frac{\\beta_{\\gamma^{*}\\backslash\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\backslash\\gamma}}{|\\gamma\\vee\\gamma^{*}|}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As mentioned earlier, the quantity $\\mathfrak{m}_{*}\\left(\\widehat{s}\\right)$ captures the model discriminative power of BSS. To add more perspective, note that if the features are highly correlated among themselves then it is expected that $\\mathfrak{m}_{*}(\\widehat{s})$ is very close to 0. Hence, any candidate model $\\gamma$ is practically indistinguishable from the true mod el $\\gamma^{*}$ which in turn makes the problem of exact model recovery harder. On the contrary, if the features are uncorrelated then $\\mathfrak{m}_{*}\\left(\\widehat{s}\\right)$ becomes bounded away from 0 making the true model $\\gamma^{*}$ easily recoverable. For example, [17] showed that under the knowledge of true sparsity, i.e., when $\\widehat{s}=s$ , the condition ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathfrak{m}_{*}(s)\\gtrsim\\sigma^{2}\\frac{\\log p}{n},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "is sufficient for BSS to achieve model consistency. One can also view $\\mathfrak{m}_{*}\\left(s\\right)$ as a quantifier of the coupled effect of model correlation and signal strength. If we define the minimum and maximum ", "page_idx": 3}, {"type": "text", "text": "eigenvalues over all models to be $\\begin{array}{r}{\\lambda_{*}\\,=\\,\\operatorname*{min}_{\\gamma\\in\\mathcal{A}_{s}}\\lambda_{m i n}(\\Gamma(\\gamma))}\\end{array}$ and $\\lambda^{*}\\,=\\,\\mathrm{max}_{\\gamma\\in\\mathcal{A}_{s}}\\,\\lambda_{m a x}(\\Gamma(\\gamma))$ respectively, then it follows that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\lambda_{*}\\beta_{m i n}^{2}\\leq\\mathfrak{m}_{*}(s)\\leq\\lambda^{*}\\beta_{m i n}^{2}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Therefore, it suffices to have $\\beta_{m i n}\\gtrsim\\sigma\\{(\\log p)/(n\\lambda_{*})\\}^{1/2}$ in order to satisfy condition (6). In this case, $\\lambda_{*}$ captures the degree of model correlation, and $\\beta_{m i n}$ is the minimum signal strength. Similar to our previous discussion, if there is high collinearity in the model, $\\lambda_{*}$ will be typically small, and BSS needs a large value of $\\beta_{m i n}$ to identify the true model $\\gamma^{*}$ . On the other hand, if $\\beta_{m i n}$ is too small for a given level of model correlation, i,e, if $\\beta_{m i n}\\ll\\sigma\\{(\\log p)/(n\\lambda^{*})\\}^{1/2}$ , then also BSS fails to achieve model consistency as it is hard to identify active features under the presence of weak signals [17, Theorem 2.1]. As we will see in the next section, the DP BSS algorithm also requires a margin condition similar to (6) to ensure model recovery, and this is indeed an indispensable condition as it is needed even in non-private case. ", "page_idx": 4}, {"type": "text", "text": "3.2 Differentially Private BSS and Utility Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In order to privatize the optimization problem in (4), we will adopt the exponential mechanism discussed in Section 2.2. In particular, for a tuning parameter $K>0$ , we consider the score function ", "page_idx": 4}, {"type": "equation", "text": "$$\nu_{K}(\\gamma;{\\mathbf X},{\\mathbf y}):=-\\operatorname*{min}_{\\substack{\\theta\\in\\mathbb{R}^{s}:\\|\\theta\\|_{1}\\leq K}}\\left\\|{\\mathbf y}-{\\mathbf X}_{\\gamma}\\theta\\right\\|_{2}^{2}\\;,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and for a given privacy budget $\\varepsilon>0$ , we sample $\\gamma\\in\\mathcal{A}_{\\hat{s}}$ from the distribution ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\pi(\\gamma)\\propto\\exp\\left\\{\\frac{\\varepsilon u_{K}(\\gamma;{\\bf X},{\\bf y})}{\\Delta u_{K}}\\right\\}\\mathbb{1}(\\gamma\\in\\mathcal{A}_{\\widehat{s}}\\cup\\{\\gamma^{*}\\}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As we are concerned with the exact recovery $\\gamma^{*}$ , from here on we assume $\\widehat{s}=s$ . The above algorithm is essentially the same as Algorithm 4 in [27]; however, they do not intro d uce the extra $\\ell_{1}$ -constraint on the parameter space. Instead, their algorithm needs the loss-term $(y-\\mathbf{x}_{\\gamma}^{\\top}\\pmb{\\theta})^{2}$ to be bounded by a constant for every possible choice of $\\mathbf{x},y,\\gamma$ and $\\pmb{\\theta}$ . This assumption is not true in general for the squared error loss, and to remedy this issue, we introduce the extra $\\ell_{1}$ -constraint in the score function. This is a common strategy that is used to guarantee worst-case sensitivity bound and similar methods also have been adopted in [29, 6] to construct private estimators. Next, we present the following lemma that shows the data-monotonicity of the proposed score function. ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.1. The score function $u_{K}(\\gamma;\\cdot)$ in (7) is data monotone. ", "page_idx": 4}, {"type": "text", "text": "Therefore, Lemma 2.2 automatically guarantees that the above procedure is $(\\varepsilon,0)$ -DP. However, in practice, we need an explicit form for $\\Delta u_{K}$ to carry out the sampling method, and it is also needed to analyze the utility guarantee of the exponential mechanism. To provide a concrete upper bound on the global sensitivity of $u_{K}(\\cdot;\\cdot)$ , we make the following boundedness assumption on the database: ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.2. There exists positive constants $r,x_{\\mathsf{m a x}}$ such that $\\begin{array}{r}{\\operatorname*{sup}_{y\\in\\mathcal{Y}}|y|\\leq r,\\operatorname*{sup}_{\\mathbf{x}\\in\\mathcal{X}}\\left\\|\\mathbf{x}\\right\\|_{\\infty}\\leq}\\end{array}$ $x_{\\mathsf{m a x}}$ . ", "page_idx": 4}, {"type": "text", "text": "Under this assumption, the following lemma provides an upper bound on the global sensitivity of the score function along with the DP guarantee. ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.3 (Sensitivity bound and DP). Under Assumption 3.2, the global sensitivity $\\Delta u_{K}$ is bounded by $\\Delta_{K}:=(r+x_{\\sf m a x}K)^{2}$ . Therefore, the exponential mechanism (7) with $\\Delta u_{K}$ replaced by $\\Delta_{K}$ satisfies $(\\varepsilon,0){-}D P.$ ", "page_idx": 4}, {"type": "text", "text": "The above lemma provides an upper bound on the global sensitivity of the score function rather than finding the exact value of it. However, to guarantee $(\\varepsilon,0)$ -DP property of exponential mechanism, it suffices to use the upper bound of $\\Delta u_{K}$ in (7). Now we will shift towards the utility analysis of the proposed exponential mechanism. First, we require some technical assumptions. ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.4. We assume the following hold: ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "(a) There exists positive constants $b_{\\mathrm{max}}$ such that $\\left\\|\\beta\\right\\|_{1}\\leq b_{\\mathsf{m a x}}$ . ", "page_idx": 4}, {"type": "text", "text": "$(b)$ There exists positive constants $\\kappa_{-},\\kappa_{+}$ such that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\kappa_{-}\\leq\\lambda_{\\operatorname*{min}}\\left(\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}/n\\right)\\leq\\lambda_{\\operatorname*{max}}\\left(\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}/n\\right)\\leq\\kappa_{+},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Assumption 3.4(a) tells that the true parameter $\\beta$ lies inside a $\\ell_{1}$ -ball. Similar boundedness assumptions are fairly standard in privacy literature [49, 29, 6]. Assumption 3.4(b) is a well-known assumption in the high-dimensional literature [54, 22, 32] which is known as the Sparse Riesz Condition (SRC). Finally, Assumption 3.4(c) essentially assumes that the $s\\,=\\,o(n)$ , i.e., sparsity grows with a sufficiently small rate compared to the sample size $n$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.5 (Utility gurantee). Let the \u221aconditions in Assumption 3.2 and Assumption 3.4 hold. Set $K\\ge\\{(\\kappa_{+}/\\kappa_{-})b_{\\sf m a x}+(8x_{\\sf m a x}/\\kappa_{-})\\sigma\\}\\sqrt{s}$ . Then, under the data generative model (1), there exist universal positive constants $c_{1},C_{1}$ such that whenever ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathfrak{m}_{*}(s)\\geq C_{1}\\sigma^{2}\\operatorname*{max}\\left\\{1,\\frac{\\Delta_{K}}{\\varepsilon\\sigma^{2}}\\right\\}\\frac{\\log p}{n},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "with probability at least $1-c_{1}p^{-2}$ we have $\\pi(\\gamma^{*})\\geq1-p^{-2}$ . ", "page_idx": 5}, {"type": "text", "text": "Cost of privacy. Theorem 3.5 essentially says that whenever the identifiability margin is large enough, the exponential mechanism outputs the true model $\\gamma^{*}$ with high probability. Note that $\\Delta_{K}/{\\bar{\\sigma}}^{2}\\;=\\;\\Omega(\\bar{s})$ . In the low privacy regime, i.e., for $\\varepsilon~>~\\Delta_{K}/\\sigma^{2}$ we only require $\\mathfrak{m}_{*}(s)\\ \\gtrsim$ $\\sigma^{2}(\\log p)/n$ to achieve model consistency and this matches with the optimal rate for model consistency of non-private BSS. Note that, the margin condition does not depend at all on $\\varepsilon$ in this regime. In contrast, in a high privacy regime, i.e., for $\\varepsilon<\\Delta_{K}/\\sigma^{2}$ , Condition (9) essentially demands $\\mathfrak{m}_{*}(s)\\gtrsim\\sigma^{2}(s\\log p)/(n\\varepsilon)$ to achieve model consistency. Thus, in a high privacy regime, we pay an extra factor of $(s/\\varepsilon)$ in the margin requirement. ", "page_idx": 5}, {"type": "text", "text": "Remark 3.6. The failure probability in Theorem 3.5 can be improved to $O(p^{-M})$ for any arbitrary integer $M\\,>\\,2$ . However, we have to pay a cost in the universal constant $C_{1}$ in terms of $a$ multiplicative constant larger than 1. ", "page_idx": 5}, {"type": "text", "text": "Remark 3.7. Under Assumption $3.4(b)$ , it follows that $\\lambda_{*}\\;\\geq\\;\\kappa_{-}$ . Therefore, it suffices to have $\\begin{array}{r}{\\operatorname*{min}_{j\\in\\gamma^{*}}\\beta_{j}^{2}\\ge\\left(\\frac{C_{1}\\sigma^{2}}{\\kappa_{-}}\\right)\\operatorname*{max}\\left\\{1,\\Delta_{K}/(\\varepsilon\\sigma^{2})\\right\\}\\frac{\\log p}{n}}\\end{array}$ in order to hold condition (9). Therefore, in highprivacy regime, our method requires $\\begin{array}{r}{\\operatorname*{min}_{j\\in\\gamma^{*}}\\vert\\beta_{j}\\vert\\gtrsim\\sigma\\{(s\\log p)/(n\\varepsilon\\kappa_{-})\\}^{1/2}}\\end{array}$ . In contrast, under the low-privacy regime, we retrieve the optimal requirement $\\begin{array}{r}{\\operatorname*{min}_{j\\in\\gamma^{*}}\\,|\\beta_{j}|\\gtrsim\\sigma\\{(\\log p)/(n\\kappa_{-})\\}^{1/2}}\\end{array}$ . ", "page_idx": 5}, {"type": "text", "text": "4 Efficient Sampling through MCMC ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we will propose an efficient sampling method to generate approximate samples from the distribution (7). One of the challenges of sampling methods in high-dimension is their high computational complexity. For example, the distribution in (7) places mass on all $\\binom{p}{s}$ subsets of $[p]$ , and it is practically infeasible to sample $\\gamma$ from the distribution as we have to essentially explore over an exponentially large space. This motivates us to resort to sampling techniques based on MCMC, through which we aim to obtain approximate samples from the distribution in (7). Past works on MCMC algorithms for Bayesian variable selection can be divided into two main classes \u2013 Gibbs sampler [15, 24, 34] and Metropolis-Hastings [18, 28]. In this paper, we focus on a particular form of Metropolis-Hastings updates. ", "page_idx": 5}, {"type": "text", "text": "In general terms, Metropolis-Hastings (MH) random walk is an iterative and local-move based method involving three steps: ", "page_idx": 5}, {"type": "text", "text": "1. Given the current state $\\gamma$ , construct a neighborhood $\\mathcal{N}(\\gamma)$ of proposal states. 2. Choose a new state $\\gamma^{\\prime}\\in\\mathcal{N}(\\gamma)$ according to some proposal distribution $\\mathbf{F}(\\gamma,\\cdot)$ over the neighborhood $\\mathcal{N}(\\gamma)$ . 3. Move to the new state $\\gamma^{\\prime}$ with probability $\\mathbf{R}(\\gamma,\\gamma^{\\prime})$ , and stay in the original state $\\gamma$ with probability $1-\\mathbf{R}(\\gamma,\\gamma^{\\prime})$ , where the acceptance probability is given by ", "page_idx": 5}, {"type": "equation", "text": "$$\n{\\bf R}(\\gamma,\\gamma^{\\prime})=\\operatorname*{min}\\left\\{1,\\frac{\\pi(\\gamma^{\\prime}){\\bf F}(\\gamma^{\\prime},\\gamma)}{\\pi(\\gamma){\\bf F}(\\gamma,\\gamma^{\\prime})}\\right\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\pi(\\cdot)$ is same as in Equation (7). ", "page_idx": 5}, {"type": "text", "text": "This procedure generates a Markov chain for any choice of the neighborhood structure $\\mathcal{N}(\\gamma)$ with the following transition probability: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbf{P}_{\\sf M H}(\\gamma,\\gamma^{\\prime})=\\left\\{\\!\\!\\begin{array}{l l}{\\mathbf{F}(\\gamma,\\gamma^{\\prime})\\mathbf{R}(\\gamma,\\gamma^{\\prime}),}&{\\mathrm{if}\\;\\gamma^{\\prime}\\in\\mathcal{N}(\\gamma),}\\\\ {1-\\sum_{\\gamma^{\\prime}\\neq\\gamma}\\mathbf{P}_{\\sf M H}(\\gamma,\\gamma^{\\prime}),}&{\\mathrm{if}\\;\\gamma^{\\prime}=\\gamma,}\\\\ {0,}&{\\mathrm{otherwise}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The specific form of Metropolis-Hastings update analyzed in this paper is obtained by following the double swap update scheme to update $\\gamma$ . ", "page_idx": 6}, {"type": "text", "text": "Double swap update: Let $\\gamma\\in\\mathcal{A}_{s}\\cup\\{\\gamma^{*}\\}$ be the initial state. Choose an index pair $(k,\\ell)\\in\\gamma\\times\\gamma^{c}$ uniformly at random. Construct the new state $\\gamma^{\\prime}$ by setting $\\gamma^{\\prime}=\\gamma\\cup\\{\\ell\\}\\setminus\\{k\\}$ . ", "page_idx": 6}, {"type": "text", "text": "The above scheme can be viewed as a general MH update scheme when $\\mathcal{N}(\\gamma)$ is the collection of all models $\\gamma^{\\prime}$ which can be obtained by swapping two distinct coordinates of $\\gamma$ and $\\gamma^{c}$ respectively. Thus, letting $d_{H}(\\gamma,\\gamma^{\\prime})=|\\gamma\\setminus\\gamma^{\\prime}|+|\\bar{\\gamma}^{\\prime}\\setminus\\gamma|$ denote the Hamming distance between $\\gamma$ and $\\gamma^{\\prime}$ , the neighborhood is given by $\\bar{\\mathcal{N}}(\\gamma)\\,=\\,\\bigl\\{\\gamma^{\\prime}\\,\\,\\,\\big|\\,\\,^{\\prime}\\,\\,d_{H}(\\gamma,\\gamma^{\\prime})\\,=\\,2,\\exists\\,\\,\\,(\\bar{k},\\ell)\\,\\,\\in\\,\\,\\gamma\\,\\times\\,\\gamma^{c}$ such that $\\gamma^{\\prime}\\;=$ $\\gamma\\cup\\{\\ell\\}\\setminus\\{k\\}\\}$ . With this definition, the transition matrix of the previously described MetropolisHastings scheme can be written as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbf{P}_{\\sf M H}(\\gamma,\\gamma^{\\prime})=\\left\\{\\begin{array}{l l}{\\frac{1}{|\\gamma||\\gamma^{c}|}\\operatorname*{min}\\{1,\\frac{\\pi(\\gamma^{\\prime})}{\\pi(\\gamma)}\\},}&{\\mathrm{if}\\;\\gamma^{\\prime}\\in\\mathcal{N}(\\gamma),}\\\\ {1-\\sum_{\\gamma^{\\prime}\\neq\\gamma}\\mathbf{P}_{\\sf M H}(\\gamma,\\gamma^{\\prime}),}&{\\mathrm{if}\\;\\gamma^{\\prime}=\\gamma,}\\\\ {0,}&{\\mathrm{otherwise}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "4.1 Mixing Time and Approximate DP ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Let $\\mathcal{C}$ be a Markov chain on the discrete space $\\mathcal{S}$ with a transition probability matrix $\\mathbf{P}\\in\\mathbb{R}^{|\\mathcal{S}|\\times|\\mathcal{S}|}$ with stationary distribution $\\nu$ . Throughout our discussion, we assume that $\\mathcal{C}$ is reversible, i.e., it satisfies the balanced condition $\\nu(\\gamma)\\mathbf{P}(\\gamma,\\gamma^{\\prime})=\\nu(\\gamma^{\\prime})\\mathbf{P}(\\gamma^{\\prime},\\gamma)$ for all $\\gamma,\\gamma^{\\prime}\\in\\mathcal{S}$ . Note that the previously described transition matrix $\\mathbf{P}_{\\mathsf{M H}}$ in (10) satisfies the reversibility condition. It is convenient to identify a reversible chain with a weighted undirected graph $G$ on the vertex set $\\mathcal{S}$ , where two vertices $\\gamma$ and $\\gamma^{\\prime}$ are connected if and only if the edge weight $\\mathbf{Q}(\\gamma,\\gamma^{\\prime}):=\\nu(\\gamma)\\mathbf{P}(\\gamma,\\gamma^{\\prime})$ is strictly positive. For $\\gamma\\in{\\mathcal{S}}$ and any subset $S\\subseteq{\\mathcal{S}}$ , we write $\\begin{array}{r}{\\mathbf{P}(\\gamma,S)=\\sum_{\\gamma^{\\prime}\\in S}\\mathbf{P}(\\gamma,\\gamma^{\\prime})}\\end{array}$ . If $\\gamma$ is the initial state of the chain, then the total variation distance to the stationary distribution after $t$ iterations is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Delta_{\\gamma}(t)=\\left\\|\\mathbf{P}^{t}(\\gamma,\\cdot)-\\nu(\\cdot)\\right\\|_{\\sf T V}:=\\operatorname*{max}_{S\\subset\\mathcal{S}}\\left|\\mathbf{P}^{t}(\\gamma,S)-\\nu(S)\\right|.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The $\\eta$ -mixing time is given by ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\tau_{\\eta}:=\\operatorname*{max}_{\\gamma\\in\\mathcal{S}}\\operatorname*{min}\\{t\\in\\mathbb{N}\\mid\\Delta_{\\gamma}(t^{\\prime})\\leq\\eta\\;\\mathrm{for}\\;\\mathrm{all}\\;t^{\\prime}\\geq t\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "which measures the number of iterations needed for the chain to be within distance $\\eta\\in(0,1)$ of the stationary distribution. ", "page_idx": 6}, {"type": "text", "text": "Privacy of MCMC estimator: Now, we will show that once the MH chain in (10) has mixed with its stationary distribution $\\pi(\\cdot)$ defined in (7), the model estimators at each iteration will enjoy approximate DP. To fix the notation, let $\\gamma_{t}$ be the tth iteration of the MH chain in (10). Then, we have the following useful lemma: ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.1. The model estimator $\\gamma_{\\tau_{\\eta}}$ is $(\\varepsilon,\\delta)$ -DP with $\\delta=\\eta(1+e^{\\varepsilon})$ . ", "page_idx": 6}, {"type": "text", "text": "The above lemma shows that smaller $\\eta$ entails a better privacy guarantee for a fixed level $\\varepsilon$ as $\\delta$ decreases with $\\eta$ . Therefore, allowing more mixing of the chain will provide better privacy protection. However, this raises a concern about how long a practitioner must wait until the chain archives $\\eta$ -mixing. In particular, it is important to understand how $\\tau_{\\eta}$ scales in the difficulty parameters of the problem, for example, the dimension of the parameter space and sample size. In our case, we are interested in the covariate dimension $p$ , sample size $n$ , sparsity $s$ , and the privacy parameter $\\varepsilon$ . In the next section, we will show that the chain with transition matrix (10) enjoys rapid mixing, meaning that the mixing time $\\tau_{\\eta}$ grows at most at a polynomial rate in $p,s$ and the sample size $n$ . ", "page_idx": 6}, {"type": "text", "text": "4.2 Rapid Mixing of MCMC ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now turn to develop sufficient conditions for MH scheme (10) to be rapidly mixing. To this end, we make a technical assumption on the design matrix. Essentially, the following assumption controls the amount of correlation between active features and spurious features. ", "page_idx": 7}, {"type": "text", "text": "Assumption 4.2. For every $\\gamma^{\\prime}\\in\\mathcal{A}_{s}\\setminus\\{\\gamma^{*}\\}$ , there exists $k\\notin\\gamma^{*}\\cup\\gamma^{\\prime}$ such that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{j\\in\\gamma^{*}\\backslash\\gamma^{\\prime}}\\frac{\\left|\\mathbf{X}_{j}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}\\right|}{\\left|\\left|(\\mathbb{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}\\right|\\right|_{2}}\\leq b_{\\operatorname*{max}}^{-1}\\sqrt{\\left(\\kappa_{-}C_{1}\\sigma^{2}/2\\right)\\log p},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $C_{1}$ is the same universal positive constant as in Theorem 3.5. ", "page_idx": 7}, {"type": "text", "text": "First, note that Assumption 4.2 basically controls the length of the projection of the feature $\\mathbf{X}_{j}$ on the unit vector $\\mathbf{u}_{k}:=(\\mathbb{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}/\\left\\|(\\mathbb{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}\\right\\|_{2}$ . Therefore, the above inequality restricts the correlation between an active feature $\\mathbf{X}_{j}$ and the spurious scaled feature $\\mathbf{u}_{k}$ from being too large. To this end, we emphasize that stronger assumptions on model correlation (on top of the SRC condition) are common in literature for establishing the computational efficiency of Bayesian variable selection methods involving MH algorithm. For example, to show the computational efficiency MH algorithm under Zellner\u2019s $g$ -prior, [51] assumes ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\gamma:|\\gamma|\\leq s_{0}}\\left\\|(\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma})^{-1}\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}\\right\\|_{\\mathrm{op}}^{2}=O\\left(\\frac{n}{s\\log p}\\right),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $s_{0}$ (larger than $s$ ) is a specific tuning parameter of their algorithm that controls the model size. The assumption in the above display is akin to the well-known irrepresentability condition [57] which is a very strong assumption on the design. On a high level, at any given current state $\\gamma$ Assumption 4.2 or Condition (12) helps to identify a good local move towards the true model $\\gamma^{*}$ in the MH algorithm via deletion of the least influential covariate in $\\gamma$ . Now, we present our main result for the mixing time of MCMC. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.3 (Rapid mixing time). Let the conditions in Assumption 3.2, Assumption 3.4 and Assumption 4.2 hold. Then, under the data generative model (1), there exists a universal constant $C_{1}^{\\prime}>\\bar{0}$ such that under the margin condition ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathfrak{m}_{*}(s)\\geq C_{1}^{\\prime}\\sigma^{2}\\operatorname*{max}\\left\\{1,\\frac{\\Delta_{K}}{(\\kappa_{-}\\wedge1)\\varepsilon\\sigma^{2}}\\right\\}\\frac{\\log p}{n},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "there exist universal positive constants $c_{2},C_{2}$ such that the mixing time $\\tau_{\\eta}$ of the MCMC chain (10) enjoys the following with probability at least $1-c_{2}p^{-2}$ : ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\tau_{\\eta}\\leq C_{2}p s^{2}\\left\\{n\\varepsilon\\Psi^{-1}\\kappa_{+}b_{\\mathsf{m a x}}^{2}+\\log(1/\\eta)\\right\\},}\\\\ {\\mathsf{\\Pi}_{\\mathsf{I}}=\\big\\{r+(\\kappa_{+}/\\kappa_{-})b_{\\mathsf{m a x}}x_{\\mathsf{m a x}}+(\\sigma/\\kappa_{-})x_{\\mathsf{m a x}}^{2}\\big\\}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The main technical innovation in the theorem is the double swap updating scheme in the MCMC that allows us to leverage the canonical path ensemble construction argument [41] to prove the bound (14) on the mixing time. Essentially, we show that under Assumption 4.2, there exists a canonical path in a specially weighted graph corresponding to the MCMC random walk with low path congestion. The complete proof can be found in Appendix A.5. ", "page_idx": 7}, {"type": "text", "text": "Regarding the statement of the theorem, note that the margin condition (13) is slightly stronger than the margin condition in Theorem 3.5. Under that condition, the above theorem shows that the $\\eta$ -mixing time of the MCMC algorithm designed for approximate sampling from the distribution (7) grows at a polynomial rate in $(n,p,s)$ . Recall that according to the previous definition (11) of the mixing time, Theorem 4.3 characterizes the worst-case mixing time, meaning the number of iterations when starting from the worst possible initialization. If we start with a good initial state \u2014 for example, the true model $\\gamma^{*}$ would be an ideal though impractical choice - then we can remove the $n$ term in the upper bound in (14). Therefore, the bound in (14) can be thought of as the worst-case number of iterations required in the burn-in period of the MCMC algorithm. Furthermore, it is important to point out that Assumption 4.2 is only needed to ensure the \u201cquick\u201d mixing time of the MCMC chain. It is possible to relax this assumption, however, in that case, the MCMC chain is not guaranteed to mix under polynomial time. Nonetheless, given enough iterations, the chain will indeed converge to the distribution (7) as MH algorithm always generates an ergodic chain that eventually mixes to its stationary distribution. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "It is interesting to note that Theorem 4.3 suggests that in a large $\\varepsilon$ regime, the chain mixes slower compared to the small $\\varepsilon$ regime. The main reason for this is that Theorem 4.3 only relies on worst-case analysis. The intuition is the following: When $\\varepsilon$ is very large, then the target distribution is essentially fully concentrated on $\\gamma^{*}$ (assuming the score for $\\gamma^{*}$ is highest). Now, the current analysis of Theorem 4.3 does not assume any condition on the initial state of the MCMC chain. It treats the initial state $\\gamma_{0}$ as if it is chosen in a completely random manner, i.e., it is the worst case. From this point of view, it is hard for a completely uninformative distribution to converge to a target distribution that is concentrated on a single subset (very informative), and resulting in a longer mixing time. Finally, Theorem 4.3 leads to the following corollary: ", "page_idx": 8}, {"type": "text", "text": "Corollary 4.4. Let $\\pi_{t}$ denote the distribution of the tth iterate $\\gamma_{t}$ of the MCMC scheme (10). Then, under the conditions of Theorem 3.5 and Theorem 4.3, there exists a universal constant $c_{3}\\;>\\;0$ such that for any fixed iteration $t$ such that $t\\,\\geq\\,C_{2}p s^{2}\\left\\{n\\varepsilon\\Psi^{-1}\\kappa_{+}b_{\\sf m a x}^{2}+\\log(1/\\eta)\\right\\}$ , we have $\\pi_{t}(\\gamma^{*})\\geq1-\\eta-p^{-2}$ with probability at least $1-c_{3}p^{-2}$ . ", "page_idx": 8}, {"type": "text", "text": "The above corollary is useful in the sense that it provides a quantitative choice of $\\eta$ that yields high utility of the estimator $\\gamma_{t}$ . For example, if we set $\\eta\\:=\\:p^{-2}$ and $\\varepsilon\\:=\\:O(1)$ , then for any $t\\stackrel{5}{\\sim}p s^{2}(n\\dot{\\varepsilon}+\\log p)$ the resulting sample $\\gamma_{t}$ will match $\\gamma^{*}$ with probability $1-c_{3}p^{-2}$ ", "page_idx": 8}, {"type": "text", "text": "Remark 4.5. Similar to Remark 3.6, the failure probability in Theorem 4.3 and Corollary 4.4 can be improved to $O(p^{-M})$ for arbitrary large $M>2$ , but at the cost of paying higher values for the absolute constants $C_{1}^{\\prime}$ and $C_{2}$ . ", "page_idx": 8}, {"type": "text", "text": "5 Numerical experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we will conduct some illustrative simulations. To compare the quality of the DP model estimator, we compare F-score [19] of the estimated model with that of the true model $\\gamma^{*}$ and the BSS estimator. As the actual BSS is computationally infeasible, we use the adaptive best subset selection (ABESS) algorithm [58] as a computational surrogate to BSS. Throughout this section, we assume that the true sparsity $s$ is known, i.e., we provide the knowledge of $s$ to the algorithm. All codes are available at https://github.com/roysaptaumich/DP-BSS. ", "page_idx": 8}, {"type": "text", "text": "Uniform design. We consider a random design matrix, formed by choosing each entry from the distribution $\\mathrm{Uniform}(-1,1)$ in i.i.d. fashion. In detail, we set $n=900$ , $p=2000$ , and the sparsity level $s=4$ . We generate the entries of the noise w independently from Uniform $(-0.1,0.\\bar{1})$ , and consider the linear model (1). We choose the design vector $\\beta$ with true sparsity $s=4$ and the support set $\\gamma^{*}=\\{j:1\\leq j\\leq4\\}$ . We set all the signal strength to be equal, taking the following two forms: (i) Strong signal: $\\dot{\\beta}_{j}=2\\{(s\\log p)/n\\}^{1/2}$ , and (ii) Weak signal: $\\beta_{j}=2\\{(\\log p)/n\\}^{1/2}$ for all $j\\in\\gamma^{*}$ . ", "page_idx": 8}, {"type": "text", "text": "Under these setups, we consider the privacy parameter $\\varepsilon\\in\\{0.5,1,3,5,10\\}$ which are acceptable choices of $\\varepsilon$ [35]. Moreover, similar (or larger) choices of $\\varepsilon$ are common in various applications including US census study [14], socio-economic study [38], and industrial applications [3, 52]. For the Metropolis-Hastings random walk, we vary $K\\in\\{0.5,2,3,3.5\\}$ and initialize 10 independent Markov chains from random initializations and record the F-score of the last iteration. We use the CVXPY package [7, 2] for solving the $\\ell_{1}$ -constrained optimization problem in the updating step of MCMC. We also track the qualities of the model through its explanatory power for convergence diagnostics. In particular, we calculate the scale factor $R_{\\gamma}:=\\mathbf{y}^{\\top}\\boldsymbol{\\Phi}_{\\gamma}\\mathbf{y}/\\left\\|\\mathbf{y}\\right\\|_{2}^{2}$ for each model update along the random walk and compare those with $R_{\\widehat{\\gamma}_{\\mathrm{best}}}$ to heuristically gauge the quality of mixing. More details and a set of comprehensive plots can  be found in Appendix D.1 where we also discuss more about the effect of $\\varepsilon$ and $K$ on the utility. For $K=2$ , Table 2 shows that F-score increases as $\\varepsilon$ increases both in the cases of strong and weak signals. In fact, for $\\varepsilon\\geq3$ , the performance of the algorithm is on par with the non-private BSS. This is consistent with the inflection phenomenon pointed out in Theorem 3.5 and Corollary 4.4. Furthermore, as expected, we see that for a fixed $\\varepsilon$ , the $\\boldsymbol{\\mathrm{F}}$ -score is generally higher in the strong signal case. ", "page_idx": 8}, {"type": "table", "img_path": "PzG7xVlYqm/tmp/317c13d32cf45baa1158e98927a1411e5b288683b4494d2532d3a190a11ee07d.jpg", "table_caption": ["Table 2: Comparison of mean F-score across chains for $K=2$ under independent Uniform and Gaussian design. $(*)$ denotes that the chain has mixed reasonably well. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "We also carry out experiments under independent Gaussian design. The details and more comprehensive discussion of the findings are deferred to Appendix D.2. In summary, in this case also, our algorithm enjoys greater utility under the strong signal case as shown in Table 2. ", "page_idx": 9}, {"type": "text", "text": "Computational resources and license information : All the experiments were performed in the Great Lakes cluster with 16 cores and 10 GB RAM. ABESS package is distributed under GNU General Public License, Version 3. CVXPY package is distributed under Apache License, Version 2. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we study the variable selection performance of BSS under the differential privacy constraint. In order to achieve (pure) differential privacy, we adopt the exponential mechanism and establish its high statistical utility guarantee in terms of exact model recovery. Furthermore, for computational efficiency, we design a MH random walk that provably mixes with the stationary distribution within a mixing time of the polynomial order in $(n,p,s)$ . We also show that the samples from the MH random walk enjoy approximate DP while retaining a high utility guarantee with experimental underpinnings. In summary, as discussed in Section 1.1, we establish both high utility and efficient computational guarantee for our model selection algorithm under privacy constraints, which is in sharp contrast with the previous works in DP model selection literature. Moreover, the proposed MCMC method is generic enough to adopt in other models beyond linear structures. For example, one can use this technique under the setup of generalized linear models with likelihood loss as the utility function. Therefore, our method can be used in diverse domains including medical studies to fast-track scientific discoveries and promote the practice of responsible AI. ", "page_idx": 9}, {"type": "text", "text": "To this end, we also point out some of the open problems and future directions. One limitation, of our main result Theorem 3.5 is that it requires the condition $\\begin{array}{r}{\\operatorname*{min}_{j\\in\\gamma^{*}}|\\beta_{j}|=\\Omega(\\sqrt{(s\\log p)/n})}\\end{array}$ in high-privacy regime. It is still an open question whether the extra $\\sqrt{s}$ factor is necessary for model selection. Future research along this line could focus on solving BSS through DP mixed integer optimization (MIO). This would mean an important contribution in this field as commercial solvers like GUROBI or MOSEK would be capable of solving the BSS problems at an industrial scale with high computational efficiency using a general DP framework. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Shuchin Aeron, Venkatesh Saligrama, and Manqi Zhao. Information theoretic bounds for compressed sensing. IEEE Transactions on Information Theory, 56(10):5111\u20135130, 2010.   \n[2] Akshay Agrawal, Robin Verschueren, Steven Diamond, and Stephen Boyd. A rewriting system for convex optimization problems. Journal of Control and Decision, 5(1):42\u201360, 2018.   \n[3] Apple. Learning with privacy at scale. https://docs-assets.developer.apple.com/ ml-research/papers/learning-with-privacy-at-scale.pdf, 2017.   \n[4] Dimitris Bertsimas, Angela King, and Rahul Mazumder. Best subset selection via a modern optimization lens. The Annals of Statistics, 44(2):813\u2013852, 2016.   \n[5] Dimitris Bertsimas and Bart Van Parys. Sparse high-dimensional regression: Exact scalable algorithms and phase transitions. The Annals of Statistics, 48(1):300 \u2013 323, 2020. [6] T Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. The Annals of Statistics, 49(5):2825\u20132850, 2021.   \n[7] Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex optimization. Journal of Machine Learning Research, 17(83):1\u20135, 2016. [8] David Durfee and Ryan M Rogers. Practical differentially private top-k selection with paywhat-you-get composition. Advances in Neural Information Processing Systems, 32, 2019.   \n[9] Cynthia Dwork. Differential privacy. In International colloquium on automata, languages, and programming, pages 1\u201312. Springer, 2006.   \n[10] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In Advances in CryptologyEUROCRYPT 2006: 24th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St. Petersburg, Russia, May 28-June 1, 2006. Proceedings 25, pages 486\u2013503. Springer, 2006.   \n[11] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3, pages 265\u2013284. Springer, 2006.   \n[12] Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American Statistical Association, 96(456):1348\u20131360, 2001.   \n[13] Alyson K. Fletcher, Sundeep Rangan, and Vivek K Goyal. Necessary and sufficient conditions for sparsity pattern recovery. IEEE Transactions on Information Theory, 55(12):5758\u20135772, 2009.   \n[14] Simson Garfinkel. Differential privacy and the 2020 us census. https://mit-serc.pubpub. org/pub/differential-privacy-2020-us-census/release/1, 2022.   \n[15] Edward I George and Robert E McCulloch. Variable selection via gibbs sampling. Journal of the American Statistical Association, 88(423):881\u2013889, 1993.   \n[16] Xiao Guo, Hai Zhang, Yao Wang, and Jiang-Lun Wu. Model selection and estimation in high dimensional regression models with group SCAD. Statistics & Probability Letters, 103:86\u201392, 2015.   \n[17] Yongyi Guo, Ziwei Zhu, and Jianqing Fan. Best subset selection is robust against design dependence. arXiv preprint arXiv:2007.01478, 2020.   \n[18] Chris Hans, Adrian Dobra, and Mike West. Shotgun stochastic search for \u201clarge p\u201d regression. Journal of the American Statistical Association, 102(478):507\u2013516, 2007.   \n[19] Trevor Hastie, Robert Tibshirani, and Ryan Tibshirani. Best subset, forward stepwise or lasso? analysis and recommendations based on extensive comparisons. Statistical Science, 35(4):579\u2013592, 2020.   \n[20] Hussein Hazimeh, Rahul Mazumder, and Ali Saab. Sparse regression at scale: Branch-andbound rooted in first-order optimization. Mathematical Programming, 196(1-2):347\u2013388, 2022.   \n[21] Qianchuan He and Dan-Yu Lin. A variable selection method for genome-wide association studies. Bioinformatics, 27(1):1\u20138, 2011.   \n[22] Jian Huang, Yuling Jiao, Yanyan Liu, and Xiliang Lu. A constructive approach to l0 penalized regression. The Journal of Machine Learning Research, 19(1):403\u2013439, 2018.   \n[23] Jian Huang, Shuangge Ma, and Cun-Hui Zhang. Adaptive lasso for sparse high-dimensional regression models. Statistica Sinica, pages 1603\u20131618, 2008.   \n[24] Hemant Ishwaran and J. Sunil Rao. Spike and slab variable selection: Frequentist and Bayesian strategies. The Annals of Statistics, 33(2):730 \u2013 773, 2005.   \n[25] Prateek Jain and Abhradeep Guha Thakurta. (near) dimension independent risk bounds for differentially private learning. In International Conference on Machine Learning, pages 476\u2013 484. PMLR, 2014.   \n[26] Shiva Prasad Kasiviswanathan and Hongxia Jin. Efficient private empirical risk minimization for high-dimensional learning. In International Conference on Machine Learning, pages 488\u2013497. PMLR, 2016.   \n[27] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In Conference on Learning Theory, pages 25\u20131. JMLR Workshop and Conference Proceedings, 2012.   \n[28] Demetris Lamnisos, Jim E Griffin, and Mark FJ Steel. Adaptive monte carlo for bayesian variable selection in regression models. Journal of Computational and Graphical Statistics, 22(3):729\u2013748, 2013.   \n[29] Jing Lei, Anne-Sophie Charest, Aleksandra Slavkovic, Adam Smith, and Stephen Fienberg. Differentially private model selection with penalized and constrained likelihood. Journal of the Royal Statistical Society Series A: Statistics in Society, 181(3):609\u2013633, 2018.   \n[30] Min Lyu, Dong Su, and Ninghui Li. Understanding the sparse vector technique for differential privacy. Proceedings of the VLDB Endowment, 10(6):637\u2013648, 2017.   \n[31] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201907), pages 94\u2013103. IEEE, 2007.   \n[32] Nicolai Meinshausen and Bin Yu. Lasso-type recovery of sparse representations for highdimensional data. The Annals of Statistics, 37(1):246 \u2013 270, 2009.   \n[33] Benson Mwangi, Tian Siva Tian, and Jair C Soares. A review of feature reduction techniques in neuroimaging. Neuroinformatics, 12:229\u2013244, 2014.   \n[34] Naveen N Narisetty, Juan Shen, and Xuming He. Skinny gibbs: A consistent and scalable gibbs sampler for model selection. Journal of the American Statistical Association, 2018.   \n[35] Joseph Near and David Darais. Differential privacy: Future work & open challenges. https://www.nist.gov/blogs/cybersecurity-insights/ differential-privacy-future-work-open-challenges, 2022.   \n[36] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. In Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, pages 75\u201384, 2007.   \n[37] Kamiar Rahnama Rad. Nearly sharp sufficient conditions on exact sparsity pattern recovery. IEEE Transactions on Information Theory, 57(7):4672\u20134679, 2011.   \n[38] Ryan Rogers, Adrian Rivera Cardoso, Koray Mancuhan, Akash Kaura, Nikhil Gahlawat, Neha Jain, Paul Ko, and Parvez Ahammad. A members first approach to enabling linkedin\u2019s labor market insights at scale. arXiv preprint arXiv:2010.13981, 2020.   \n[39] Saptarshi Roy, Ambuj Tewari, and Ziwei Zhu. High-dimensional variable selection with heterogeneous signals: A precise asymptotic perspective. arXiv preprint arXiv:2201.01508, 2022.   \n[40] Saptarshi Roy, Ambuj Tewari, and Ziwei Zhu. Tale of two c (omplex) ities. arXiv preprint arXiv:2301.06259, 2023.   \n[41] Alistair Sinclair. Improved bounds for mixing rates of markov chains and multicommodity flow. Combinatorics, probability and Computing, 1(4):351\u2013370, 1992.   \n[42] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. In Proceedings of the forty-third annual ACM symposium on Theory of computing, pages 813\u2013822, 2011.   \n[43] Ben Stoddard, Yan Chen, and Ashwin Machanavajjhala. Differentially private algorithms for empirical machine learning. arXiv preprint arXiv:1411.5428, 2014.   \n[44] Kunal Talwar, Abhradeep Guha Thakurta, and Li Zhang. Nearly optimal private lasso. Advances in Neural Information Processing Systems, 28, 2015.   \n[45] Abhradeep Guha Thakurta and Adam Smith. Differentially private feature selection via stability arguments, and the robustness of the lasso. In Shai Shalev-Shwartz and Ingo Steinwart, editors, Proceedings of the 26th Annual Conference on Learning Theory, volume 30 of Proceedings of Machine Learning Research, pages 819\u2013850, Princeton, NJ, USA, 12\u201314 Jun 2013. PMLR.   \n[46] Martin J. Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using $\\ell_{1}$ -constrained quadratic programming (lasso). IEEE Transactions on Information Theory, 55(5):2183\u20132202, 2009.   \n[47] Di Wang and Jinhui Xu. On sparse linear regression in the local differential privacy model. In International Conference on Machine Learning, pages 6628\u20136637. PMLR, 2019.   \n[48] Di Wang, Minwei Ye, and Jinhui Xu. Differentially private empirical risk minimization revisited: Faster and more general. Advances in Neural Information Processing Systems, 30, 2017.   \n[49] Yu-Xiang Wang. Revisiting differentially private linear regression: optimal and adaptive prediction & estimation in unbounded domain. arXiv preprint arXiv:1803.02596, 2018.   \n[50] Dawn B. Woodard and Jeffrey S. Rosenthal. Convergence rate of Markov chain methods for genomic motif discovery. The Annals of Statistics, 41(1):91 \u2013 124, 2013.   \n[51] Yun Yang, Martin J. Wainwright, and Michael I. Jordan. On the computational complexity of high-dimensional Bayesian variable selection. The Annals of Statistics, 44(6):2497 \u2013 2532, 2016.   \n[52] McGee Young, Marc-Antoine Par\u00e9, Harry Bergmann, et al. Differential privacy for expanding access to building energy data. In ACEEE Summer Study on Energy Efficiency in Buildings Proceedings, 2020.   \n[53] Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. The Annals of Statistics, 38(2):894\u2013942, 2010.   \n[54] Cun-Hui Zhang and Jian Huang. The sparsity and bias of the lasso selection in high-dimensional linear regression. The Annals of Statistics, 36(4):1567\u20131594, 2008.   \n[55] Cun-Hui Zhang and Tong Zhang. A general theory of concave regularization for highdimensional sparse estimation problems. Statistical Science, 27(4):576\u2013593, 2012.   \n[56] Fan Zhang, Wei Li, Yifan Zhang, and Zhiyong Feng. Data driven feature selection for machine learning algorithms in computer vision. IEEE Internet of Things Journal, 5(6):4262\u20134272, 2018.   \n[57] Peng Zhao and Bin Yu. On model selection consistency of lasso. The Journal of Machine Learning Research, 7:2541\u20132563, 2006.   \n[58] Jin Zhu, Xueqin Wang, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Shiyun Lin, and Junxian Zhu. abess: A fast best-subset selection library in python and r. Journal of Machine Learning Research, 23(202):1\u20137, 2022. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Proof of Main results ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Proof of Lemma 3.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Recall that $u_{K}(\\gamma;{\\mathbf{X}},{\\mathbf{y}})\\;=\\;-L_{\\gamma,K}({\\mathbf{X}},{\\mathbf{y}})$ where $\\textstyle L_{\\gamma,K}(\\mathbf{X},\\mathbf{y})\\;:=\\;\\sum_{i=1}^{n}(y_{i}\\,-\\,\\mathbf{x}_{i,\\gamma}^{\\top}\\beta)^{2}$ . Therefore, it suffices to show that $L_{\\gamma,K}(\\cdot,\\cdot)$ is data monotone. Let $D~=~\\{(\\mathbf{x}_{i},y_{i})\\}_{i=1}^{n}$ and $D^{\\prime}\\,=$ $D\\cup\\{\\mathbf{x}_{n+1},y_{n+1}\\}$ . We define ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\widehat{\\boldsymbol{\\beta}}_{n,\\gamma}:=\\arg\\operatorname*{min}_{\\boldsymbol{\\beta}:\\|\\boldsymbol{\\beta}\\|_{1}\\leq K}\\sum_{i=1}^{n}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\boldsymbol{\\beta})^{2},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\n\\widehat{\\beta}_{n+1,\\gamma}:=\\arg\\operatorname*{min}_{\\beta:\\|\\beta\\|_{1}\\leq K}\\sum_{i=1}^{n+1}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\beta)^{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, we have the following inequalities: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\overset{\\cdot}{\\underset{\\cdot}{\\sim}}\\gamma_{,K}(D^{\\prime})=\\sum_{i=1}^{n+1}(y_{i}-\\mathbf x_{i,\\gamma}^{\\top}\\widehat{\\beta}_{n+1,\\gamma})^{2}\\geq\\sum_{i=1}^{n}(y_{i}-\\mathbf x_{i,\\gamma}^{\\top}\\widehat{\\beta}_{n+1,\\gamma})^{2}\\geq\\sum_{i=1}^{n}(y_{i}-\\mathbf x_{i,\\gamma}^{\\top}\\widehat{\\beta}_{n,\\gamma})^{2}=L_{\\gamma,K}(D).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The above inequalities conclude the proof. ", "page_idx": 13}, {"type": "text", "text": "A.2 Proof of Sensitivity Bound (Lemma 3.3) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Let $(\\mathbf{X},\\mathbf{y})$ and $(\\tilde{\\mathbf{X}},\\tilde{\\mathbf{y}})$ be two neighboring datasets with $n$ and $n+1$ observation respectively. For a subset $\\gamma\\in\\mathcal{A}_{s}\\cup\\{\\gamma^{*}\\}$ , consider the OLS estimators as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\beta_{\\gamma,K}:=\\arg\\operatorname*{min}_{\\boldsymbol{\\theta}:\\|\\boldsymbol{\\theta}\\|_{1}\\leq K}\\|\\mathbf{y}-\\mathbf{X}_{\\gamma}\\boldsymbol{\\theta}\\|_{2}^{2}\\,,\\quad\\mathrm{and}\\quad\\tilde{\\beta}_{\\gamma,K}:=\\arg\\operatorname*{min}_{\\boldsymbol{\\theta}:\\|\\boldsymbol{\\theta}\\|_{1}\\leq K}\\left\\|\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{X}}_{\\gamma}\\boldsymbol{\\theta}\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "From the definition of the score function $u(\\gamma;\\mathbf{X},\\mathbf{y})$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle u(\\gamma;\\mathbf{X},\\mathbf{y})=-\\sum_{i=1}^{n}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\beta_{\\gamma,K})^{2}}\\\\ {\\displaystyle u(\\gamma;\\tilde{\\mathbf{X}},\\tilde{\\mathbf{y}})=-\\sum_{i=1}^{n}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\tilde{\\beta}_{\\gamma,K})^{2}-(\\tilde{\\mathbf{y}}_{n+1}-\\tilde{\\mathbf{x}}_{n+1,\\gamma}^{\\top}\\tilde{\\beta}_{\\gamma,K})^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "By the property of the OLS estimators, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u(\\gamma;\\mathbf{X},\\mathbf{y})-u(\\gamma;\\tilde{\\mathbf{X}},\\tilde{\\mathbf{y}})}\\\\ &{\\displaystyle=\\sum_{i=1}^{n}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\tilde{\\beta}_{\\gamma,K})^{2}+\\big(\\tilde{y}_{n+1}-\\tilde{\\mathbf{x}}_{n+1,\\gamma}^{\\top}\\tilde{\\beta}_{\\gamma,K}\\big)^{2}-\\displaystyle\\sum_{i=1}^{n}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\beta_{\\gamma,K})^{2}}\\\\ &{\\displaystyle\\leq\\sum_{i=1}^{n}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\beta_{\\gamma,K})^{2}+\\big(\\tilde{y}_{n+1}-\\tilde{\\mathbf{x}}_{n+1,\\gamma}^{\\top}\\beta_{\\gamma,K}\\big)^{2}-\\displaystyle\\sum_{i=1}^{n}(y_{i}-\\mathbf{x}_{i,\\gamma}^{\\top}\\beta_{\\gamma,K})^{2}}\\\\ &{\\displaystyle=(\\tilde{y}_{n+1}-\\tilde{\\mathbf{x}}_{n+1,\\gamma}^{\\top}\\beta_{\\gamma,K})^{2}}\\\\ &{\\displaystyle\\leq(r+x_{\\operatorname*{max}}K)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Similarly, we have $u(\\gamma;\\tilde{\\mathbf{X}},\\tilde{\\mathbf{y}})-u(\\gamma;\\mathbf{X},\\mathbf{y})\\,\\le\\,(r+x_{\\sf m a x}K)^{2}$ . Next, the $(\\varepsilon,0)$ -DP follows from Lemma 2.2. This finishes the proof. ", "page_idx": 13}, {"type": "text", "text": "A.3 Proof of Utility Guarantee (Theorem 3.5) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Consider the notation in Section B.1 and recall the event $\\mathcal{E}_{K}:=\\cap_{\\gamma:\\gamma\\in\\mathcal{A}_{s}}\\{\\beta_{\\gamma,K}=\\beta_{\\gamma,o l s}\\}$ . We will For notational brevity, we use $L_{\\gamma}$ to denote $L_{\\gamma}(\\mathbf{X},\\mathbf{y})$ . Now, we restrict ourselves to the event $\\mathcal{E}_{K}$ . therefore we have $L_{\\gamma,K}=L_{\\gamma}$ for all $\\gamma$ . To establish a lower bound $\\pi(\\gamma^{*})$ , we make use of its specific form, thereby obtaining the following inequality: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\pi(\\gamma^{*})=\\frac{1}{1+\\sum_{\\gamma^{\\prime}\\in\\mathcal{A}_{s}}\\exp\\left\\{-\\frac{\\varepsilon(L_{\\gamma^{\\prime}}-L_{\\gamma^{*}})}{\\Delta u}\\right\\}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Now we fix $k\\in[s]$ , and and consider any $\\gamma\\in\\mathcal{A}_{s,k}$ . For any $\\eta\\in[0,1]$ , note that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{n^{-1}(L_{\\gamma}-L_{\\gamma^{*}})=n^{-1}\\{\\mathbf{y}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{y}-\\mathbf{y}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma^{*}})\\mathbf{y}\\}}\\\\ &{=n^{-1}\\left\\{(\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}\\beta_{\\gamma^{*}\\setminus\\gamma}+\\mathbf{w})^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})(\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}\\beta_{\\gamma^{*}\\setminus\\gamma}+\\mathbf{w})-\\mathbf{w}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma^{*}})\\mathbf{w}\\right\\}}\\\\ &{=\\eta\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}+2^{-1}(1-\\eta)\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}-2\\left\\{n^{-1}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}\\beta_{\\gamma^{*}\\setminus\\gamma}\\right\\}^{\\top}(-\\mathbf{w})}\\\\ &{\\quad+\\,2^{-1}(1-\\eta)\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}-n^{-1}\\mathbf{w}^{\\top}(\\Phi_{\\gamma}-\\Phi_{\\gamma^{*}})\\mathbf{w}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Consider the random variable Following the analysis of Theorem 2.1 in [17], we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb P\\left[\\operatorname*{max}_{\\gamma\\in\\mathcal A_{s,k}}\\left\\vert2n^{-1}\\{(\\mathbb I_{n}-\\Phi_{\\gamma})\\mathbf X_{\\gamma^{*}\\setminus\\gamma}\\beta_{\\gamma^{*}\\setminus\\gamma}\\}^{\\top}\\mathbf w\\right\\vert\\geq2^{-1}(1-\\eta)\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}\\right]\\leq2e^{-6k\\log p},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\operatorname*{max}_{\\gamma\\in\\mathcal{A}_{s,k}}n^{-1}\\left|\\mathbf{w}^{\\top}(\\Phi_{\\gamma}-\\Phi_{\\gamma^{*}})\\mathbf{w}\\right|\\geq2^{-1}(1-\\eta)\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}\\right]\\leq4e^{-2k\\log p},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "whenever ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\operatorname*{min}_{\\gamma\\in{\\mathcal A}_{s,k}}\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}}{k}\\geq C\\sigma^{2}\\left\\{\\frac{\\log p}{n(1-\\eta)}\\right\\}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "for large enough universal constant $C\\,>\\,0$ . Setting $\\eta\\,=\\,1/2$ , we note that whenever ${\\mathfrak{m}}_{*}(s)\\ \\geq$ $2C\\sigma^{2}\\tilde{\\{(\\log p)/n\\}}$ , we get ", "page_idx": 14}, {"type": "equation", "text": "$$\nn^{-1}(L_{\\gamma}-L_{\\gamma^{*}})\\geq\\frac{1}{2}\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}\\geq\\frac{k\\mathfrak{m}_{*}(s)}{2}\\quad\\mathrm{for}\\;\\mathrm{all}\\;\\gamma\\in\\mathcal{A}_{s},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "with probability at least $1-2p^{-6}-4p^{-2}$ . Also, note that $\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}\\leq\\kappa_{+}s b_{\\mathsf{m a x}}^{2}$ . Hence, if we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\mathfrak{m}}_{*}(s)\\geq\\operatorname*{max}\\left\\{2C,{\\frac{16\\Delta u}{\\varepsilon\\sigma^{2}}}\\right\\}{\\frac{\\sigma^{2}\\log p}{n}},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "the following are true: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\gamma^{\\prime}\\in\\mathcal{A}_{s}}{\\sum}\\exp\\left\\lbrace-\\frac{\\varepsilon(L_{\\gamma^{\\prime}}-L_{\\gamma^{+}})}{\\Delta u}\\right\\rbrace}\\\\ &{\\leq\\underset{\\gamma^{\\prime}\\in\\mathcal{A}_{s}}{\\sum}\\exp\\left\\lbrace-\\frac{n k\\varepsilon\\mathfrak{m}_{*}(s)}{2\\Delta u}\\right\\rbrace}\\\\ &{\\leq\\underset{k=1}{\\overset{s}{\\sum}}\\left(\\frac{p-s}{k}\\right)\\binom{s}{k}\\exp\\left\\lbrace-\\frac{n k\\varepsilon\\mathfrak{m}_{*}(s)}{2\\Delta u}\\right\\rbrace}\\\\ &{\\leq\\underset{k=1}{\\overset{s}{\\sum}}p^{2k}\\cdot p^{-4k}\\leq p^{-2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\gamma\\in\\mathcal{A}_{s}\\cup\\{\\gamma^{*}\\}}\\pi(\\gamma)\\geq\\frac{1}{1+p^{-2}}\\geq1-p^{-2}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "with probability $1-2p^{-6}-4p^{-2}$ . Now by the discussion in Section B.1, we have $\\mathbb{P}(\\mathcal{E}_{K})\\geq1-2p^{-2}$ for $\\begin{array}{r}{K\\ge\\sqrt{s}\\left\\{(\\frac{\\kappa_{+}}{\\kappa_{-}})b_{\\sf m a x}+(\\frac{8}{\\kappa_{-}})\\sigma x_{\\sf m a x}\\right\\}}\\end{array}$ . This finishes the proof. ", "page_idx": 14}, {"type": "text", "text": "A.4 Proof of Lemma 4.1 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "For clarity, we first specify some notations. Let $\\gamma_{t}^{D}$ denote the model update of MH chain run over dataset $D$ . Let $\\tau_{\\eta}^{D}$ be the corresponding $\\eta$ -mixing time. Let $D$ and $D^{\\prime}$ be two neighboring datasets, and $\\pi^{D}$ and $\\pi^{D^{\\prime}}$ be the corresponding probability mass functions for the exponential mechanism. Then, we have the following: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}(\\gamma_{\\tau_{\\eta}^{D}}^{D}=\\gamma)\\leq\\pi^{D}(\\gamma)+\\eta}\\\\ &{\\qquad\\qquad\\qquad\\leq e^{\\varepsilon}\\pi^{D^{\\prime}}(\\gamma)+\\eta}\\\\ &{\\qquad\\qquad\\qquad\\leq e^{\\varepsilon}\\mathbb{P}(\\gamma_{\\tau_{\\eta}^{D^{\\prime}}}^{D^{\\prime}}=\\gamma)+\\eta(1+e^{\\varepsilon}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "This finishes the proof. ", "page_idx": 15}, {"type": "text", "text": "A.5 Proof of Mixing Time (Theorem 4.3) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We again restrict ourselves to the event $\\mathcal{E}_{K}$ with $\\begin{array}{r}{K\\ge\\sqrt{s}\\left\\{(\\frac{\\kappa_{+}}{\\kappa_{-}})b_{\\sf m a x}+(\\frac{8}{\\kappa_{-}})\\sigma x_{\\sf m a x}\\right\\}\\!.}\\end{array}$ . For the proof, let $\\widetilde{\\mathbf{P}}$ denote the transition matrix of the original Metropolis-Hastings sampler (10). In this case, the state space is $\\mathcal{S}=\\mathcal{A}_{s}\\cup\\{\\gamma^{*}\\}$ . Now consider the transition matrix ${\\bf P}=\\widetilde{\\bf P}/2+\\mathbb{I}_{n}/2$ , corresponding to the lazy version of the random walk that stays in its current position with a probability of at least 1/2. Due to the construction, the smallest eigenvalue of $\\mathbf{P}$ is always non-negative, and the mixing time of the chain is completely determined by the second largest eigenvalue $\\lambda_{2}$ of $\\mathbf{P}$ . To this end, we define the spectral gap ${\\mathsf{G a p}}(\\mathbf{P})=1-\\lambda_{2}$ , and for any lazy Markov chain, we have the following sandwich relation [41, 50] ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\frac{(1-\\mathsf{G a p}(\\mathbf{P}))}{\\mathsf{G a p}(\\mathbf{P})}\\log(1/(2\\eta))\\leq\\tau_{\\eta}\\leq\\frac{\\log[1/\\operatorname*{min}_{\\gamma\\in\\mathcal{L}}\\pi(\\gamma)]+\\log(1/\\eta)}{\\mathsf{G a p}(\\mathbf{P})}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lower Bound on $\\pi(\\cdot)$ : ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To establish a lower bound on the target distribution in (7), we make use of its specific form, thereby obtaining the following inequality: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\pi(\\gamma)=\\pi(\\gamma^{*}).\\frac{\\pi(\\gamma)}{\\pi(\\gamma^{*})}\\ }\\\\ {\\displaystyle=\\frac{1}{1+\\sum_{\\gamma^{\\prime}\\in\\mathcal{A}_{s}}\\exp\\left\\{-\\frac{\\varepsilon(L_{\\gamma^{\\prime}}-L_{\\gamma^{*}})}{\\Delta u}\\right\\}}.\\exp\\left\\{-\\frac{\\varepsilon(L_{\\gamma}-L_{\\gamma^{*}})}{\\Delta u}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Now we fix $k\\in[s]$ , and and consider any $\\gamma\\in\\mathcal{A}_{s,k}$ . ", "page_idx": 15}, {"type": "text", "text": "Similar to the proof of Section A.3, we note that whenever ${\\mathfrak{m}}_{*}(s)\\geq2C\\sigma^{2}\\{(\\log p)/n\\}$ for a large enough universal constant $C>0$ , we get ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{3}{2}\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}\\geq n^{-1}(L_{\\gamma}-L_{\\gamma^{*}})\\geq\\frac{1}{2}\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}\\geq\\frac{k\\mathfrak{m}_{*}(s)}{2}\\quad\\mathrm{for~all~}\\gamma\\in\\mathcal{A}_{s},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with probability at least $1-2p^{-6}-4p^{-2}$ . Also, note that $\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}\\leq\\kappa_{+}s b_{\\mathsf{m a x}}^{2}$ . Hence, if we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\mathfrak{m}}_{*}(s)\\geq\\operatorname*{max}\\left\\{2C,{\\frac{16\\Delta u}{\\varepsilon\\sigma^{2}}}\\right\\}{\\frac{\\sigma^{2}\\log p}{n}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "the following are true: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\gamma^{\\prime}\\in\\mathcal{A}_{s}}{\\sum}\\exp\\left\\{-\\frac{\\varepsilon(L_{\\gamma^{\\prime}}-L_{\\gamma^{+}})}{\\Delta u}\\right\\}}\\\\ &{\\leq\\underset{\\gamma^{\\prime}\\in\\mathcal{A}_{s}}{\\sum}\\exp\\left\\{-\\frac{n k\\varepsilon\\mathbf{u}_{*}(s)}{2\\Delta u}\\right\\}}\\\\ &{\\leq\\underset{k=1}{\\overset{s}{\\sum}}\\left(\\frac{p-s}{k}\\right)\\binom{s}{k}\\exp\\left\\{-\\frac{n k\\varepsilon\\mathbf{u}_{*}(s)}{2\\Delta u}\\right\\}}\\\\ &{\\leq\\underset{k=1}{\\overset{s}{\\sum}}p^{2k}\\cdot p^{-4k}\\leq p^{-2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\exp\\left\\{-\\frac{\\varepsilon(L_{\\gamma}-L_{\\gamma^{*}})}{\\Delta u}\\right\\}\\geq\\exp\\left\\{-\\frac{3n\\varepsilon\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\Gamma(\\gamma)\\beta_{\\gamma^{*}\\setminus\\gamma}}{2\\Delta u}\\right\\}}}\\\\ {{\\displaystyle\\geq\\exp\\left\\{-\\frac{3n s\\varepsilon\\kappa_{+}b_{\\operatorname*{max}}^{2}}{2\\Delta u}\\right\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Combining these two facts we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\gamma\\in\\mathcal{A}_{s}\\cup\\{\\gamma^{*}\\}}\\pi(\\gamma)\\geq\\frac{1}{1+p^{-2}}\\exp\\left\\{-\\frac{3n s\\varepsilon\\kappa_{+}b_{\\operatorname*{max}}^{2}}{2\\Delta u}\\right\\}\\geq\\frac{1}{2}\\exp\\left\\{-\\frac{3n s\\varepsilon\\kappa_{+}b_{\\operatorname*{max}}^{2}}{2\\Delta u}\\right\\}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "with probability $1-2p^{-6}-4p^{-2}$ . ", "page_idx": 16}, {"type": "text", "text": "Lower Bound on Spectral Gap: ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Now it remains to prove a lower bound on the spectral gap ${\\mathsf{G a p}}(\\mathbf{P})$ , and we do so via the canonical path argument [41]. We begin by describing the idea of a canonical path ensemble associated with a Markov chain. Given a Markov chain $\\mathcal{C}$ with state space $\\mathcal{S}$ , consider the weighted directed graph $G(\\mathcal{C})=(V,E)$ with vertex set $V=\\mathcal{S}$ and the edge set $E$ in which a ordered pair $e=(\\gamma,\\bar{\\gamma}^{\\prime})$ is included as an edge with weight $\\mathbf{Q}(e)=\\mathbf{Q}(\\gamma,\\gamma^{\\prime})=\\pi(\\gamma)\\mathbf{P}(\\gamma,\\gamma^{\\prime})$ iff $\\mathbf{P}(\\gamma,\\gamma^{\\prime})>0$ . A canonical path ensemble $\\tau$ corresponding to $\\mathcal{C}$ is a collection of paths that contains, for each ordered pair $(\\gamma,\\gamma^{\\prime})$ of distinct vertices, a unique simple path $T_{\\gamma,\\gamma^{\\prime}}$ connecting $\\gamma$ and $\\gamma^{\\prime}$ . We refer to any path in the ensemble $\\tau$ as a canonical path. ", "page_idx": 16}, {"type": "text", "text": "[41] shows that for any reversible Markov chain and nay choice of a canonical path ensemble $\\tau$ , the spectral gap of $\\mathbf{P}$ is lower bounded as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathsf{G a p}(\\mathbf{P})\\geq\\frac{1}{\\rho(T)\\ell(T)},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\ell(T)$ corresponds to the length of the longest path in the ensemble $\\tau$ , and the quantity $\\begin{array}{r}{\\rho(\\mathcal{T}):=\\operatorname*{max}_{e\\in E}\\frac{\\cdot_{1}}{Q(e)}\\sum_{(\\gamma,\\gamma^{\\prime}):e\\in T_{\\gamma,\\gamma^{\\prime}}}\\pi(\\gamma)\\pi(\\gamma^{\\prime})}\\end{array}$ is known as the path congestion parameter. ", "page_idx": 16}, {"type": "text", "text": "Thus, it boils down to the construction of a suitable canonical path ensemble $\\tau$ . Before going into further details, we introduce some working notations. For any two given paths $T_{1}$ and $T_{2}$ : ", "page_idx": 16}, {"type": "text", "text": "\u2022 Their intersection $T_{1}\\cap T_{2}$ denotes the collection of overlapping edges.   \n\u2022 If $T_{2}\\subset T_{1}$ , then $T_{1}\\setminus T_{2}$ denotes the path obtained by removing all the edges of $T_{2}$ from $T_{1}$ .   \n\u2022 We use $\\Bar{T}_{1}$ to denote the reverse of $T_{1}$ .   \n\u2022 If the endpoint of $T_{1}$ is same as the starting point of $T_{2}$ , then $T_{1}\\cup T_{2}$ denotes the path obtained by joining $T_{1}$ and $T_{2}$ at that point. ", "page_idx": 16}, {"type": "text", "text": "We will now shift focus toward the construction of the canonical path ensemble. At a high level, our construction follows the same scheme as in [51]. ", "page_idx": 16}, {"type": "text", "text": "Canonical path ensemble construction: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "First, we need to construct the canonical path $T_{\\gamma,\\gamma^{*}}$ from any $\\gamma\\in\\mathcal{S}$ to the true model $\\gamma^{*}$ . To this end, we introduce the concept of memoryless paths. We call a set $\\mathcal{T}_{M}$ of canonical paths memoryless with respect to the central state $\\gamma^{*}$ if ", "page_idx": 17}, {"type": "text", "text": "1. for any state $\\gamma\\in{\\mathcal{S}}$ satisfying $\\gamma\\neq\\gamma^{*}$ , there exists a unique simple path $T_{\\gamma,\\gamma^{*}}$ in $\\mathcal{T}_{M}$ connecting $\\gamma$ and $\\gamma^{*}$ ;   \n2. for any intermediate state $\\tilde{\\gamma}\\in\\mathcal{S}$ on any path $T_{\\gamma,\\gamma^{*}}\\in\\tau_{M}$ , the unique path connecting $\\tilde{\\gamma}$ and $\\gamma^{*}$ is the sub-path of $T_{\\gamma,\\gamma^{*}}$ starting from $\\tilde{\\gamma}$ and ending at $\\gamma^{*}$ . ", "page_idx": 17}, {"type": "text", "text": "Intuitively, this memoryless property tells that for any intermediate step in any canonical path, the next step towards the central state does not depend on history. Specifically, the memoryless canonical path ensemble has the property that in order to specify the canonical path connecting any state $\\gamma\\in{\\mathcal{S}}$ and the central state $\\gamma^{*}$ , we only need to specify the next state from $\\gamma\\in\\mathcal{S}\\setminus\\{\\gamma^{*}\\}$ , i.e., we need a transition function $\\mathcal{G}:\\mathcal{S}\\setminus\\left\\{\\gamma^{*}\\right\\}\\rightarrow\\mathcal{S}$ that maps the current state $\\gamma$ to the next state. For simplicity, we define $\\mathcal{G}(\\gamma^{*})=\\gamma^{*}$ to make $\\mathcal{S}$ as the domain of $\\mathcal{G}$ . For a more detailed discussion, we point the readers to Section 4 of [51]. We now state a useful lemma that is pivotal to the construction of the canonical path ensemble. ", "page_idx": 17}, {"type": "text", "text": "Lemma A.1 ([51]). If a function $\\mathcal{G}:\\mathcal{S}\\setminus\\{\\gamma^{*}\\}\\,\\rightarrow\\,\\mathcal{S}$ satisfies the condition $d_{H}(\\mathcal{G}(\\gamma),\\gamma^{*})\\,<$ $d_{H}(\\gamma,\\gamma^{*})$ for any state $\\gamma\\in\\mathcal{S}\\setminus\\{\\gamma^{*}\\}$ , then $\\mathcal{G}$ is a valid transition map. ", "page_idx": 17}, {"type": "text", "text": "Using the above lemma, we will now construct the memoryless set of canonical paths from any state $\\gamma\\in{\\mathcal{S}}$ to $\\gamma^{*}$ by explicitly specifying a transition map $\\mathcal{G}$ . In particular, we consider the following transition function: ", "page_idx": 17}, {"type": "text", "text": "\u2022 If $\\gamma\\neq\\gamma^{*}$ , we define $\\mathcal{G}(\\gamma)$ to be $\\gamma^{\\prime}$ , whch is formed by replacing the least influential covariate in $\\gamma$ with most influential covariate in $\\gamma^{*}\\setminus\\gamma$ . In notations, we have $\\gamma_{j}^{\\prime}=\\gamma_{j}$ for all $j\\notin\\{j_{\\gamma},k_{\\gamma}\\}$ , $\\gamma_{j_{\\gamma}}^{\\prime}=1$ and $\\gamma_{k_{\\gamma}}^{\\prime}=0$ , where $j_{\\gamma}:=\\arg\\operatorname*{max}_{j\\in\\gamma^{*}\\backslash\\gamma}\\left\\|\\Phi_{\\gamma\\cup\\{j\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}$ and $\\begin{array}{r}{k_{\\gamma}:=\\arg\\operatorname*{min}_{k\\in\\gamma\\backslash\\gamma^{*}}\\left\\|\\Phi_{\\gamma\\cup\\{j\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}-\\left\\|\\Phi_{\\gamma\\cup\\{j\\}\\backslash\\{k\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}}\\end{array}$ . Thus, the transition step involves a double flip which entails that $d_{H}(\\mathcal{G}(\\gamma),\\gamma^{*})=d_{H}(\\gamma,\\bar{\\gamma}^{*})-2$ . ", "page_idx": 17}, {"type": "text", "text": "Due to Lemma A.1, it follows that the above transition map $\\mathcal{G}$ is valid and gives rise to a unique memoryless set $\\mathcal{T}_{M}$ of canonical paths connecting any $\\gamma\\in{\\mathcal{S}}$ and $\\gamma^{*}$ . ", "page_idx": 17}, {"type": "text", "text": "Based on this, we are now ready to construct the canonical path ensemble $\\tau$ . Specifically, due to memoryless property, two simple paths $T_{\\gamma,\\gamma^{*}}$ and $T_{\\gamma^{\\prime},\\gamma^{*}}$ share an identical subpath to $\\gamma^{*}$ starting from their first common intermediate state. Let $T_{\\gamma\\cap\\gamma^{\\prime}}$ denote the common sub-path $T_{\\gamma\\cap\\gamma^{*}}\\cap T_{\\gamma^{\\prime}\\cap\\gamma^{*}}$ , and $T_{\\gamma\\backslash\\gamma^{\\prime}}:=T_{\\gamma,\\gamma^{*}}\\backslash T_{\\gamma\\cap\\gamma^{\\prime}}$ denotes the remaining path of $T_{\\gamma,\\gamma^{*}}$ after removing the segment $T_{\\gamma\\cap\\gamma^{\\prime}}$ . The path $T_{\\gamma^{\\prime}\\backslash\\gamma}$ is defined in a similar way. Then it follows that $T_{\\gamma\\backslash\\gamma^{\\prime}}$ and $T_{\\gamma^{\\prime}\\backslash\\gamma}$ have the same endpoint. Therefore, it is allowed to consider the path $T_{\\gamma\\backslash\\gamma^{\\prime}}\\cup\\bar{T}_{\\gamma^{\\prime}\\backslash\\gamma}$ . ", "page_idx": 17}, {"type": "text", "text": "We call $\\gamma$ a precedent of $\\gamma^{\\prime}$ if $\\gamma^{\\prime}$ is on the canonical path $T_{\\gamma,\\gamma^{*}}\\in\\mathcal{T}$ , and a pair of states $\\gamma,\\gamma^{\\prime}$ are adjacent if the canonical path $T_{\\gamma,\\gamma^{\\prime}}$ is $e_{\\gamma,\\gamma^{\\prime}}$ , the edge connecting $\\gamma$ and $\\gamma^{\\prime}$ . Next, for $\\gamma\\in{\\mathcal{S}}$ , define ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Lambda(\\gamma):=\\{\\tilde{\\gamma}\\mid\\gamma\\in T_{\\tilde{\\gamma},\\gamma^{*}}\\}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "denote the set of all precedents. We denote by $|T|$ the length of the path $T$ . The following lemma provides some important properties of the previously constructed canonical path ensemble. ", "page_idx": 17}, {"type": "text", "text": "Lemma A.2. For any distinct pair $(\\gamma,\\gamma^{\\prime})\\in\\mathcal{S}\\times\\mathcal{S}$ : ", "page_idx": 17}, {"type": "text", "text": "(a) We have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{|T_{\\gamma,\\gamma^{*}}|\\leq d_{H}(\\gamma,\\gamma^{*})/2\\leq s,\\quad a n d}}\\\\ {{|T_{\\gamma,\\gamma^{\\prime}}|\\leq\\displaystyle\\frac{1}{2}\\{d_{H}(\\gamma,\\gamma^{*})+d_{H}(\\gamma^{\\prime},\\gamma^{*})\\}\\leq2s.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "(b) If $\\gamma$ and $\\gamma^{\\prime}$ are adjacent and $\\gamma$ is precedent of of $\\gamma^{\\prime}$ , then ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\{(\\bar{\\gamma},\\bar{\\gamma}^{\\prime})\\mid e_{\\gamma,\\gamma^{\\prime}}\\in T_{\\bar{\\gamma},\\bar{\\gamma}^{\\prime}}\\}\\subset\\Lambda(\\gamma)\\times\\mathcal{S}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. For the first claim, let us first assume that $|T_{\\gamma,\\gamma^{*}}|=k$ , i.e., $\\mathcal{G}^{k}(\\gamma)=\\gamma^{*}$ for the appropriate transition map $\\mathcal{G}$ . Also, recall that $|\\gamma|=|\\gamma^{*}|=s$ . Hence, due to an elementary iterative argument, it follows that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{2s\\geq d_{H}(\\gamma,\\gamma^{*})=d_{H}(\\mathcal{G}(\\gamma),\\gamma^{*})+2}}\\\\ {{=d_{H}(\\mathcal{G}^{2}(\\gamma),\\gamma^{*})+4}}\\\\ {{\\vdots}}\\\\ {{=2k.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Also, note that $|T_{\\gamma,\\gamma^{\\prime}}|\\leq|T_{\\gamma,\\gamma^{*}}|+|T_{\\gamma^{\\prime},\\gamma^{*}}|$ . Hence, the claim follows using the previous inequality. For the second claim, note that for any pair $(\\bar{\\gamma},\\bar{\\gamma}^{\\prime})$ such that $T_{\\bar{\\gamma},\\bar{\\gamma}^{\\prime}}\\,\\ni\\,e_{\\gamma,\\gamma^{\\prime}}$ , we have two possible options : (i) $e_{\\gamma,\\gamma^{\\prime}}\\in T_{\\bar{\\gamma}\\backslash\\bar{\\gamma}^{\\prime}}$ , or (ii) $e_{\\gamma,\\gamma^{\\prime}}\\in T_{\\bar{\\gamma}^{\\prime}\\backslash\\bar{\\gamma}}$ . As $\\gamma$ is precedent of $\\gamma^{\\prime}$ , the only possibility that we have is $e_{\\gamma,\\gamma^{\\prime}}\\in T_{\\gamma\\backslash\\gamma^{\\prime}}$ . This shows that $\\gamma$ belongs to the path $T_{\\bar{\\gamma},\\gamma^{*}}$ and $\\bar{\\gamma}\\in\\Lambda(\\gamma)$ . \u53e3 ", "page_idx": 18}, {"type": "text", "text": "According to Lemma A.2(b), the path congestion parameter $\\rho(T)$ satisfies ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\rho(T)\\leq\\operatorname*{max}_{(\\gamma,\\gamma^{\\prime})\\in\\Gamma_{*}}\\frac{1}{\\mathbf{Q}(\\gamma,\\gamma^{\\prime})}\\sum_{\\bar{\\gamma}\\in\\Lambda(\\gamma),\\bar{\\gamma}^{\\prime}\\in\\mathcal{S}}\\pi(\\bar{\\gamma})\\pi(\\bar{\\gamma}^{\\prime})=\\operatorname*{max}_{(\\gamma,\\gamma^{\\prime})\\in\\Gamma_{*}}\\frac{\\pi[\\Lambda(\\gamma)]}{\\mathbf{Q}(\\gamma,\\gamma^{\\prime})},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the set $\\Gamma_{*}:=\\{(\\gamma,\\gamma^{\\prime})\\in\\mathcal{S}\\times\\mathcal{S}\\mid T_{\\gamma,\\gamma^{\\prime}}=e_{\\gamma,\\gamma^{\\prime}},\\gamma\\in\\Lambda(\\gamma^{\\prime})\\}.$ . Here we used the fact that the weight function $\\mathbf{Q}$ satisfies the reversibility condition $\\mathbf{Q}(\\gamma,\\gamma^{\\prime})=\\mathbf{Q}(\\gamma^{\\prime},\\gamma)$ in order to restrict the range of the maximum to pairs $(\\gamma,\\gamma^{\\prime})$ where $\\gamma\\in\\Lambda(\\gamma^{\\prime})$ . ", "page_idx": 18}, {"type": "text", "text": "For the lazy form of the Metropolis-Hastings walk (10), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\bf{Q}}(\\gamma,\\gamma^{\\prime})=\\pi(\\gamma){\\bf{P}}(\\gamma,\\gamma^{\\prime})\\qquad\\qquad\\qquad\\qquad\\quad}\\\\ {\\qquad\\geq\\displaystyle\\frac{1}{p s}\\pi(\\gamma)\\operatorname*{min}\\left\\{1,\\frac{\\pi(\\gamma^{\\prime})}{\\pi(\\gamma)}\\right\\}\\geq\\displaystyle\\frac{1}{p s}\\operatorname*{min}\\left\\{\\pi(\\gamma),\\pi(\\gamma^{\\prime})\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Substituting this bound in (19), we get ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\rho(T)\\leq p s\\underset{(\\gamma,\\gamma^{\\prime})\\in\\Gamma_{*}}{\\operatorname*{max}}\\frac{\\pi(\\Lambda(\\gamma))}{\\operatorname*{min}\\left\\{\\pi(\\gamma),\\pi(\\gamma^{\\prime})\\right\\}}}\\\\ &{\\qquad=p s\\underset{(\\gamma,\\gamma^{\\prime})\\in\\Gamma_{*}}{\\operatorname*{max}}\\left\\{\\operatorname*{max}\\left\\{1,\\frac{\\pi(\\gamma)}{\\pi(\\gamma^{\\prime})}\\right\\}\\cdot\\frac{\\pi(\\Lambda(\\gamma))}{\\pi(\\gamma)}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In order to prove that $\\rho(T)=O(p s)$ with high probability, it is sufficient to prove that the two terms inside the maximum are $O(1)$ . To this end, we introduce two useful lemmas. ", "page_idx": 18}, {"type": "text", "text": "Lemma A.3. Consider the event ", "page_idx": 18}, {"type": "equation", "text": "$$\nA_{n}=\\left\\{\\operatorname*{max}_{\\gamma\\in\\mathcal{S},\\ell\\notin\\gamma}\\mathbf{w}^{\\top}(\\Phi_{\\gamma\\cup\\{\\ell\\}}-\\Phi_{\\gamma})\\mathbf{w}\\leq12\\sigma^{2}s\\log p\\right\\}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then we have $\\mathbb{P}(A_{n})\\geq1-p^{-2}$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. First note that $\\mathbf{w}^{\\top}(\\Phi_{\\gamma\\cup\\{\\ell\\}}-\\Phi_{\\gamma})\\mathbf{w}=(\\mathbf{h}_{\\gamma,\\ell}^{\\top}\\mathbf{w})^{2}$ for an appropriate unit vector $\\mathbf{h}_{\\gamma,\\ell}$ depending only upon $\\mathbf{X}_{\\gamma}$ and $\\mathbf{X}_{\\ell}$ . By Sub-gaussian tail inequality, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left\\{(\\mathbf{h}_{\\gamma,\\ell}^{\\top}\\mathbf{w})^{2}\\geq t\\right\\}\\leq2e^{-\\frac{t}{2\\sigma^{2}}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Setting $t=12\\sigma^{2}s\\log p$ and applying an union bound we get ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left\\{\\underset{\\gamma\\in\\mathcal{S},\\ell\\notin\\gamma}{\\operatorname*{max}}(\\mathbf h_{\\gamma,\\ell}^{\\top}\\mathbf w)^{2}\\geq12\\sigma^{2}s\\log p\\right\\}\\leq2\\binom{p}{s}(p-s)p^{-6s}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq2p^{-3s}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq p^{-2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Lemma A.4. Suppose that, in addition to the conditions in Theorem 4.3, the event $A_{n}$ holds. Then for all $\\gamma\\neq\\gamma^{*}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\frac{\\pi(\\gamma)}{\\pi(\\mathcal{G}(\\gamma))}\\leq p^{-3}.}\\\\ {\\displaystyle\\frac{\\pi[\\Lambda(\\gamma)]}{\\pi(\\gamma)}\\leq2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Moreover, for all $\\gamma,$ , ", "page_idx": 19}, {"type": "text", "text": "Therefore, both Lemma A.3 and Lemma A.4 give $\\rho(T)\\leq2p s$ with probability $1-p^{-2}$ . Lemma A.2(a) suggests that $\\ell(T)\\leq2s$ . Therefore, Equation (17) shows that $\\begin{array}{r}{\\mathsf{G a p}(\\mathbf{P})\\geq\\frac{1}{4p s^{2}}}\\end{array}$ with probability $1-p^{-2}$ . Finally, combining (16) and (15), we get the following with $1-8p^{-2}$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\tau_{\\eta}\\leq C_{2}p s^{2}\\left(\\frac{n\\varepsilon\\kappa_{+}b_{\\sf m a x}^{2}}{\\left\\{r+(\\frac{\\kappa_{+}}{\\kappa_{-}})b_{\\sf m a x}x_{\\sf m a x}+(\\frac{\\sigma}{\\kappa_{-}})x_{\\sf m a x}^{2}\\right\\}^{2}}+\\log(1/\\eta)\\right),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $C_{2}>0$ is a universal constant. Finally, the proof is concluded by arguing that $\\mathbb{P}(\\mathcal{E}_{K}^{c})\\leq2p^{-2}$ . ", "page_idx": 19}, {"type": "text", "text": "B Proof of Auxiliary Results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "B.1 Constrained problem to unconstrained OLS problem ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Now we are ready to bound $\\left\\|\\beta_{\\gamma,K}\\right\\|_{1}$ . Define the OLS estimator corresponding to the model $\\gamma$ as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\beta_{\\gamma,o l s}=\\underbrace{(\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}}{n})^{-1}\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}}{n}}_{:=\\mathbf{u}_{1}}+\\underbrace{(\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}}{n})^{-1}\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{w}}{n}}_{:=\\mathbf{u}_{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In this section, we will show that there exists a choice for $K$ such that the event $\\mathcal{E}_{K}~:=$ $\\cap_{\\gamma:|\\gamma|=s}\\{\\beta_{\\gamma,o l s}=\\beta_{\\gamma,K}\\}$ holds with high probability. By Holder\u2019s inequality we have $\\Vert\\mathbf{u}_{1}\\Vert_{2}\\leq$ $\\begin{array}{r l r}{\\left\\|(\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}/n)^{-1}\\right\\|_{\\mathrm{op}}\\left\\|\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma^{*}}/n\\right\\|_{\\mathrm{op}}\\left\\|\\boldsymbol{\\beta}_{\\gamma^{*}}\\right\\|_{2}}&{\\leq}&{\\binom{\\kappa_{+}}{\\kappa_{-}}b_{\\mathrm{max}}}\\end{array}$ . Hence, an application of CauchySchwarz inequality directly yields that $\\begin{array}{r}{\\|\\mathbf{u}_{1}\\|_{1}\\leq2(\\frac{\\kappa_{+}}{\\kappa_{-}})\\sqrt{s}b_{\\sf m a x}}\\end{array}$ . Next, note that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbf{u}_{2}\\|_{2}\\leq\\left\\|(\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}}{n})^{-1}\\right\\|_{2}\\left\\|\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{w}}{n}\\right\\|_{2}\\leq\\sqrt{s}\\left\\|(\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}}{n})^{-1}\\right\\|_{2}\\left\\|\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{w}}{n}\\right\\|_{\\infty}\\leq\\sqrt{s}\\left\\|(\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{X}_{\\gamma}}{n})^{-1}\\right\\|_{2}\\left\\|\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{w}}{n}\\right\\|_{2},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, we get $\\begin{array}{r}{\\|\\mathbf{u}_{2}\\|_{1}\\leq\\frac{s}{\\kappa_{-}}\\left\\|\\mathbf{X}^{\\top}\\mathbf{w}/n\\right\\|_{\\infty}}\\end{array}$ . In order to upper bound the last term in the previous inequality, we define $D_{i,j}={\\bf X}[i,j]w_{j}$ for all $(i,j)\\in[s]\\times[n]$ . Using the sub-Gaussian property of $w_{j}$ , we have $\\mathbb{E}(e^{\\lambda w_{j}})\\leq e^{\\lambda^{2}x_{\\mathtt{m a x}}^{2}\\sigma^{2}/2}$ . Therefore, due to Hoeffding\u2019s inequality, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\frac{1}{n}|\\sum_{j\\in[n]}D_{i,j}|\\geq8\\sigma x_{\\mathsf{m a x}}\\sqrt{\\frac{\\log p}{n}}\\right)\\leq2p^{-4}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Note that $\\begin{array}{r}{\\left\\|\\mathbf{X}^{\\top}\\mathbf{w}/n\\right\\|_{\\infty}=\\operatorname*{max}_{i\\in[s]}n^{-1}\\big|\\sum_{j\\in[n]}D_{i,j}\\big|}\\end{array}$ . Hence, by simple union-bound argument, it follows that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{max}_{\\gamma:|\\gamma|=s}\\left\\|\\frac{\\mathbf{X}_{\\gamma}^{\\top}\\mathbf{w}}{n}\\right\\|_{\\infty}\\geq8\\sigma x_{\\operatorname*{max}}\\sqrt{\\frac{\\log p}{n}}\\right)\\leq2p^{-4}\\leq2p^{-2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Thus, Assumption 3.4(c) yields that $\\begin{array}{r}{\\left\\|\\beta_{\\gamma,K}\\right\\|_{1}^{2}\\leq s\\left\\{(\\frac{\\kappa_{+}}{\\kappa_{-}})b_{\\sf m a x}+(\\frac{8}{\\kappa_{-}})\\sigma x_{\\sf m a x}\\right\\}^{2}}\\end{array}$ . Therefore, if $K\\ge$ $\\begin{array}{r}{\\sqrt{s}\\left\\{(\\frac{\\kappa_{+}}{\\kappa_{-}})b_{\\sf m a x}+(\\frac{8}{\\kappa_{-}})\\sigma x_{\\sf m a x}\\right\\}}\\end{array}$ then $\\mathbb{P}(\\mathcal{E}_{K})\\geq1-2p^{-2}$ . ", "page_idx": 19}, {"type": "text", "text": "B.2 Proof of Corollary 4.4 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Based on Theorem 4.3, we have $\\|\\pi_{t}-\\pi\\|_{\\mathsf{T V}}\\leq e t a$ with probability at least $1-c_{2}p^{-2}$ whenever $t$ is sufficiently large. Also, by Theorem 3.5, we know $\\pi(\\gamma^{*})\\geq1-p^{-2}$ with probability $1-c_{1}p^{-2}$ . Therefore, we have $\\pi_{t}(\\gamma^{*})\\geq1-\\eta-p^{-2}$ with probability at least $1-(c_{!}+c_{2})p^{-2}$ . This finishes the proof. ", "page_idx": 19}, {"type": "text", "text": "C Proof of Lemma A.4 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "part (a): ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Let $j_{\\gamma},k_{\\gamma}$ be the indices defined in the construction of $\\mathcal{G}(\\gamma)$ . The we have $\\gamma^{\\prime}=\\gamma\\cup\\{j_{\\gamma}\\}\\setminus\\{k_{\\gamma}\\}$ . Let $\\mathbf{v}_{1}=(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}$ and $\\mathbf{v}_{2}=(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}$ . Then Lemma C.1 guarantees that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathbf{v}_{1}\\|_{2}^{2}\\geq n\\kappa_{-}\\mathsf{m}_{*}(s),\\quad\\mathrm{and}\\quad\\|\\mathbf{v}_{2}\\|_{2}^{2}\\leq n\\kappa_{-}\\mathsf{m}_{*}(s)/2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "By the form in (7), we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{\\pi(\\gamma)}{\\pi(\\gamma^{\\prime})}=\\exp\\left\\{-\\frac{\\mathbf{y}^{\\top}(\\Phi_{\\gamma^{\\prime}}-\\Phi_{\\gamma})\\mathbf{y}}{(\\Delta u/\\varepsilon)}\\right\\}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "To show that the above ration is $O(1)$ , it suffices to show that $\\mathbf{y}^{\\top}(\\Phi_{\\gamma^{\\prime}}-\\Phi_{\\gamma})\\mathbf{y}$ is large. By simple algebra, it follows that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{y}^{\\top}(\\Phi_{\\gamma^{\\prime}}-\\Phi_{\\gamma})\\mathbf{y}=\\mathbf{y}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma})\\mathbf{y}-\\mathbf{y}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{y}}\\\\ &{=\\left\\|\\mathbf{v}_{1}\\right\\|_{2}^{2}+2\\mathbf{v}_{1}^{\\top}\\mathbf{w}+\\mathbf{w}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma})\\mathbf{w}-\\left\\{\\left\\|\\mathbf{v}_{2}\\right\\|_{2}^{2}+2\\mathbf{v}_{2}^{\\top}\\mathbf{w}+\\mathbf{w}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{w}\\right\\}}\\\\ &{=\\left\\|\\mathbf{v}_{1}\\right\\|_{2}^{2}+2\\mathbf{v}_{1}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma})\\mathbf{w}+\\mathbf{w}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma})\\mathbf{w}}\\\\ &{\\quad-\\left\\{\\left\\|\\mathbf{v}_{2}\\right\\|_{2}^{2}+2\\mathbf{v}_{2}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{w}+\\mathbf{w}^{\\top}(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{w}\\right\\}}\\\\ &{\\geq\\left\\|\\mathbf{v}_{1}\\right\\|_{2}(\\left\\|\\mathbf{v}_{1}\\right\\|_{2}-2\\left\\|(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma})\\mathbf{w}\\right\\|_{2})-\\left\\|\\mathbf{v}_{2}\\right\\|_{2}(\\left\\|\\mathbf{v}_{2}\\right\\|_{2}+2\\left\\|(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{w}\\right\\|_{2})}\\\\ &{\\quad-\\left\\|(\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{w}\\right\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Now, we recall the event ", "page_idx": 20}, {"type": "equation", "text": "$$\nA_{n}=\\left\\{\\operatorname*{max}_{\\gamma\\in\\mathcal{S},\\ell\\notin\\gamma}\\mathbf{w}^{\\top}(\\Phi_{\\gamma\\cup\\{\\ell\\}}-\\Phi_{\\gamma})\\mathbf{w}\\leq12\\sigma^{2}s\\log p\\right\\}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Let $A^{2}:=n\\kappa_{-}\\mathsf{m}_{*}(s)\\geq\\kappa_{-}C_{0}\\sigma^{2}\\log p$ . Then for $C_{0}$ large enough so that $\\kappa_{-}C_{0}\\,\\geq\\,(128\\times12)s$ , Equation (22) leads to the following inequality under event $A_{n}$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbf{y}^{\\top}(\\Phi_{\\gamma^{\\prime}}-\\Phi_{\\gamma})\\mathbf{y}\\geq A(A-A/4)-(A/\\sqrt{2})(A/\\sqrt{2}+A/4)-A^{2}/16\\geq A/8.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This readily yields that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{\\pi(\\gamma)}{\\pi(\\gamma^{\\prime})}\\leq\\exp\\left\\{-\\frac{n\\kappa_{-}\\mathfrak{m}_{*}(s)}{(16\\Delta u/\\varepsilon)}\\right\\}\\leq p^{-3}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "under the margin condition of Theorem 4.3. ", "page_idx": 20}, {"type": "text", "text": "Part (b): ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "From the previous part, the bound (23) implies that $\\pi(\\gamma)/\\pi({\\mathcal G}(\\gamma))\\leq p^{-3}$ . For each $\\bar{\\gamma}\\in\\Lambda(\\gamma)$ , we have that $\\gamma\\in T_{\\bar{\\gamma},\\gamma}\\subset T_{\\bar{\\gamma},\\gamma^{*}}$ . Let the path $T_{\\bar{\\gamma},\\gamma}$ be $\\gamma_{0}\\rightarrow\\gamma_{1}\\rightarrow...\\rightarrow\\gamma_{k}$ , where $k=|T_{\\bar{\\gamma},\\gamma}|$ is the length of the path, and $\\gamma_{0}=\\bar{\\gamma}$ and $\\gamma_{k}=\\gamma$ are the two endpoints. Now note that $\\{\\gamma_{\\ell}\\}_{\\ell\\le k-1}\\subset\\mathcal{S}$ , and (23) ensures that ", "page_idx": 20}, {"type": "equation", "text": "$$\n{\\frac{\\pi({\\bar{\\gamma}})}{\\pi(\\gamma)}}=\\prod_{\\ell=1}^{k}{\\frac{\\pi(\\gamma_{\\ell-1})}{\\pi(\\gamma_{\\ell})}}\\leq p^{-3k}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Also, by Lemma A.2(a) we have $k\\in[s]$ . Now, we count the total number of sets in $\\Lambda(\\gamma)$ for each $k\\in[s]$ . Recall that by the construction of the canonical path, we update the current state by adding a new influential covariate and deleting one unimportant one. Hence any state in $\\mathcal{S}$ has at most $s p$ adjacent precedents, implying that there could be at most $s^{k}p^{k}$ distinct paths of length $k$ . This entails that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{\\pi(\\Lambda(\\gamma))}{\\pi(\\gamma)}\\leq\\sum_{\\bar{\\gamma}\\in\\Lambda(\\gamma)}\\frac{\\pi(\\bar{\\gamma})}{\\pi(\\gamma)}\\leq\\sum_{k=1}^{s}(p s)^{k}p^{-3k}\\leq\\sum_{k=1}^{s}p^{-k}\\leq\\frac{1}{1-1/p}\\leq2.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "C.1 Supporting lemmas ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Recall the definition of $j_{\\gamma}$ and $k_{\\gamma}$ . The first result in the following lemma shows that the gain in adding $j_{\\gamma}$ to the current model $\\gamma$ is at least $n\\kappa_{-}\\mathfrak{m}_{*}(s)$ . The second result shows that the loss incurred by removing $k_{\\gamma}$ from the model $\\gamma\\cup\\{j_{\\gamma}\\}$ is at most $n\\kappa_{-}\\mathfrak{m}_{*}(s)/2$ . As a result, it follows that it is favorable to replace $\\mathbf{X}_{k_{\\gamma}}$ with the more influential feature $\\mathbf{X}_{j_{\\gamma}}$ in the current model $\\gamma$ . ", "page_idx": 21}, {"type": "text", "text": "Lemma C.1. Under Assumption $3.4(b)$ and Assumption 4.2, the following hold for all $\\gamma\\in\\mathcal{A}_{s}$ : ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(a)\\ \\left\\|\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}-\\left\\|\\Phi_{\\gamma}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}\\geq n\\kappa_{-}\\mathfrak{m}_{*}(s),\\,a n d}\\\\ &{(b)\\ \\left\\|\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}-\\left\\|\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}\\backslash\\{k\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}\\leq n\\kappa_{-}\\mathfrak{m}_{*}(s)/2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. For each $\\ell\\in\\gamma^{*}\\setminus\\gamma$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\Phi_{\\gamma\\cup\\{\\ell\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\|_{2}^{2}-\\|\\Phi_{\\gamma}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\|_{2}^{2}=\\beta_{\\gamma^{*}}^{\\top}\\mathbf{X}_{\\gamma^{*}}^{\\top}(\\Phi_{\\gamma\\cup\\{\\ell\\}}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\frac{\\beta_{\\gamma^{*}}^{\\top}\\mathbf{X}_{\\gamma^{*}}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\ell}\\mathbf{X}_{\\ell}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}}{\\mathbf{X}_{\\ell}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\ell}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\geq\\frac{\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\ell}\\mathbf{X}_{\\ell}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}\\beta_{\\gamma^{*}\\setminus\\gamma}}{n},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second equality simply follows from Gram-Schmidt orthogonal decomposition. By summing the preceding inequality over $\\ell\\in\\gamma^{*}\\setminus\\gamma$ , we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{\\in\\gamma^{*}\\setminus\\gamma}\\|\\Phi_{\\gamma\\cup\\{\\ell\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\|_{2}^{2}-\\|\\Phi_{\\gamma}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\|_{2}^{2}\\geq\\frac{\\beta_{\\gamma^{*}\\setminus\\gamma}^{7}\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}}\\cdot\\mathbf{\\Lambda}_{\\gamma}}{n}}\\\\ {\\displaystyle}&{\\geq\\kappa_{-}\\beta_{\\gamma^{*}\\setminus\\gamma}^{\\top}\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}^{\\top}(\\mathbb{I}_{n}-\\Phi_{\\gamma})\\mathbf{X}_{\\gamma^{*}\\setminus\\gamma}\\beta_{\\gamma^{*}\\setminus\\gamma}}\\\\ {\\displaystyle}&{\\geq n\\kappa_{-}\\left|\\gamma\\right>\\gamma^{*}|\\mathfrak{m}_{*}(s)}\\\\ {\\displaystyle}&{=n\\kappa_{-}\\left|\\gamma^{*}\\setminus\\gamma\\right|\\mathfrak{m}_{*}(s).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The last inequality follows from the fact that $|\\gamma|=|\\gamma^{*}|=s$ . Since $j_{\\gamma}$ maximizes $\\left|\\right|\\Phi_{\\gamma\\cup\\{\\ell\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\left|\\right|_{2}^{2}$ over all $\\ell\\in\\gamma^{*}\\setminus\\gamma$ , the preceding inequality implies that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\big\\|\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\big\\|_{2}^{2}-\\big\\|\\Phi_{\\gamma}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\big\\|_{2}^{2}\\geq n\\kappa_{-}\\mathfrak{m}_{*}(s).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Similarly, to prove the second claim, first note that for any $k\\in\\gamma\\setminus\\gamma^{*}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left|\\Phi_{\\gamma^{\\prime}\\cup\\{k\\}}\\mathbf{X}_{\\gamma^{\\prime}}\\partial_{\\gamma^{\\prime}}\\right|_{2}^{2}-\\left\\|\\Phi_{\\gamma^{\\prime}}\\mathbf{X}_{\\gamma^{\\prime}}\\partial_{\\gamma^{*}}\\right\\|_{2}^{2}=\\beta_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}^{\\top}\\mathbf{X}_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}^{\\top}(\\Phi_{\\gamma^{\\prime}\\cup\\{k\\}}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}\\beta_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}}\\\\ {=\\frac{\\beta_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}^{\\top}\\mathbf{X}_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}^{\\top}\\left(\\mathbf{I}_{n}-\\Phi_{\\gamma^{\\prime}}\\right)\\mathbf{X}_{k}\\mathbf{X}_{k}^{\\prime}\\left(\\mathbf{I}_{n}-\\Phi_{\\gamma^{\\prime}}\\right)\\mathbf{X}_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}\\beta_{\\gamma^{\\prime}\\setminus\\gamma_{\\prime}}}{\\mathbf{X}_{k}^{\\prime}\\left(\\mathbf{I}_{n}-\\Phi_{\\gamma}\\right)\\mathbf{X}_{k}^{\\prime}}}\\\\ {=\\left\\langle(\\mathbf{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}^{\\top}\\partial_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}\\frac{(\\mathbf{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}}{\\mathbf{I}(\\mathbf{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}\\mathbf{I}_{\\gamma}}\\right\\rangle^{2}}\\\\ {\\ }&{\\leq\\left\\|\\beta_{\\gamma^{\\prime}\\setminus\\gamma}\\right\\|_{1}^{2}\\left\\|\\frac{\\mathbf{X}_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}^{\\top}(\\mathbf{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}}{\\mathbf{I}(\\mathbf{I}_{n}-\\Phi_{\\gamma^{\\prime}})\\mathbf{X}_{k}\\mathbf{I}_{\\gamma}}\\right\\|_{2}^{2}}\\\\ {\\ }&{\\leq b_{m s}^{2}\\left\\|\\frac{\\mathbf{X}_{\\gamma^{\\prime}\\setminus\\gamma^{\\prime}}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since $k_{\\gamma}$ minimizes $\\left\\|\\Phi_{\\gamma^{\\prime}\\cup\\left\\{k\\right\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}-\\left\\|\\Phi_{\\gamma^{\\prime}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\right\\|_{2}^{2}$ over all possible $k\\in\\gamma\\setminus\\gamma^{*}$ , by Assumption 4.2 we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\big\\|\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\big\\|_{2}^{2}-\\big\\|\\Phi_{\\gamma\\cup\\{j_{\\gamma}\\}\\backslash\\{k\\}}\\mathbf{X}_{\\gamma^{*}}\\beta_{\\gamma^{*}}\\big\\|_{2}^{2}\\leq n\\kappa_{-}\\mathsf{m}_{*}(s)/2.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "D More simulation details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "D.1 Independent Uniform design ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Under the setup of Section 5, we consider the privacy parameter $\\varepsilon\\,\\in\\,\\{0.5,1,3,5,10\\}$ . For the Metropolis-Hastings random walk, we vary $K\\ \\in\\ \\{0.5,2,3,3.5\\}$ and initialize 10 independent Markov chains from random initializations and record the F-score of the last iteration. We also track the qualities of the model through its explanatory power. In particular, we calculate the scale factor $R_{\\gamma}:=\\mathbf{y}^{\\top}\\Phi_{\\gamma}\\mathbf{y}/\\left\\|\\mathbf{y}\\right\\|_{2}^{2}$ for each model $\\gamma\\in\\{\\gamma_{t}\\}_{t\\geq1}$ along the random walks. Typically, a high value of $R_{\\gamma}$ will indicate the superior quality of the model $\\gamma$ . Note that \u2212 $\\left\\|\\mathbf{y}\\right\\|_{2}^{2}(1-R_{\\gamma})$ is proportional to the log of the probability mass function function of $\\gamma$ . Thus, tracking $R_{\\gamma}$ is equivalent to tracking the log-likelihood of $\\gamma$ along the random walks. ", "page_idx": 22}, {"type": "text", "text": "Strong signal: Under this setup, note that the model estimate of ABESS exactly matches the true model. For $\\varepsilon\\geq3$ and $K\\geq2$ , Figure 1 shows that all the chains have identified a reasonably good estimate of the true model $\\gamma^{*}$ within $50p$ iterations. This empirical phenomenon validates theoretical findings in Theorem 4.3. However, for larger values of $K$ the performance is worse as the noise level is also large. On the other hand, for the case of $K=0.5$ , the performance is also worse due to too much shrinkage that results in a bad estimate of $\\beta$ . The mean F-score\u2019s also suggest the same phenomenon. For smaller values of $\\varepsilon$ , the performance is generally bad due to increased noise level. This is expected as higher privacy usually entails a worse performance in terms of utility. ", "page_idx": 22}, {"type": "text", "text": "Weak signal: We perform the same experiments under a weak signal regime. As expected, both Figure 2 and Table 1 show that the performance of the proposed algorithm is generally inferior to that in the strong signal regime for $K\\ge2$ . However, note that our algorithm enjoys a better utility for $K=0.5$ . In fact, performance is as good as the non-private BSS for $\\varepsilon\\geq3$ . This is not surprising as $K=0.5$ closer to $\\left\\|\\beta\\right\\|_{1}\\approx0.7$ in the weak signal case and results in better estimation for $\\beta$ . On the contrary, larger values of $K$ inject more noise into the algorithm and the utility deteriorates. ", "page_idx": 22}, {"type": "text", "text": "D.2 Independent Gaussian Design ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We consider an independent Gaussian design matrix, formed by sampling entries from identical independent standard normal distributions and normalized by the $\\ell_{\\infty}$ norm. Specifically, we set $n=900$ , $p=2000$ with the sparsity level $s=4$ . Similar to the setup in Section 5, we generate entries with independent $\\mathrm{Uniform}(-0.1,0.1)$ noise w following the linear model (1). We choose the design vector $\\beta$ with true sparsity $s=4$ and the support set $\\gamma^{*}=\\{j:1\\leq j\\leq4\\}$ . All the signal strengths are set to be equal, taking the following two forms: (i) Strong signal: $\\beta_{j}\\,=\\,2\\{(s\\log p)/n\\}^{1/2}$ , and (ii) Weak signal: $\\beta_{j}\\,=\\,2\\{(\\log p)/n\\}^{1/2}$ for all $j\\in\\gamma^{*}$ . We consider the privacy parameter $\\varepsilon\\in\\{0.5,1,3,5,10\\}$ . For the Metropolis-Hastings random walk, we vary $K\\in\\{0.5,2,3,3.5\\}$ and initialize 10 independent Markov chains from random initialization and record the F-score of the last iteration. ", "page_idx": 22}, {"type": "text", "text": "Strong signal: Under this setup, note that the model estimate of ABESS exactly matches the true model with $\\mathbf{F}\\mathbf{-score}\\,=\\,1$ . For the case of $K\\,=\\,0.5$ , Figure 3 shows the performance is better compared with settings $K\\ge2$ when $\\varepsilon\\le5$ . However, when $\\varepsilon=10$ , the performance is worse due to shrinkage of the estimate of $\\beta$ while the estimations in other settings are easier due to lower privacy requirements. For higher values of $\\varepsilon$ , the performance is generally strong because of the reduced noise level. This is expected since lower privacy typically leads to better utility performance. Notice that for $\\varepsilon=10$ and $K=2$ , we have a fairly accurate estimate of the true model $\\gamma^{*}$ within $50p$ iterations. ", "page_idx": 22}, {"type": "text", "text": "Weak signal: We conduct the same experiments under a weak signal regime. As expected, Figure 4 shows that the performance of the proposed algorithm is generally inferior to that in the strong signal regime for $K\\geq2$ . However, note that our algorithm enjoys a better utility for $K=0.5$ when $\\varepsilon\\geq3$ . In fact, performance is as good as the non-private BSS for $\\varepsilon=10$ . This is not surprising as $K=0.5$ closer to $\\left\\|\\beta\\right\\|_{1}\\approx0.7$ in the weak signal case, leading to better estimation for $\\beta$ . In contrast, larger values of $K$ introduce more noise into the algorithm and weaken the utility. ", "page_idx": 22}, {"type": "image", "img_path": "PzG7xVlYqm/tmp/e992e7aec1f2f5a75b9d91c76a270a3335fbf65a9e4e80bad5b1e129df56c7cc.jpg", "img_caption": ["Figure 1: Metropolis-Hastings random walk under different privacy budgets and $\\ell_{1}$ regularization. (Strong signal) "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "PzG7xVlYqm/tmp/8c943dfa9023ba424947e14d61f6fcae5b7ed03cc0121c2f71f63f511e46654b.jpg", "img_caption": ["Figure 2: Metropolis-Hastings random walk under different privacy budgets and $\\ell_{1}$ regularization. (Weak signal) "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "PzG7xVlYqm/tmp/b3f107bb27e3ce8ad753d923c8daf529c9151b22cecfa2cf40a25862531f9dbb.jpg", "img_caption": ["Figure 3: Gaussian setting Metropolis-Hastings random walk under different privacy budgets and $\\ell_{1}$ regularization. (Strong signal) "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "PzG7xVlYqm/tmp/bc48b30e86fa965afab4cebb1922145c18fe1d840b2e5d3ae6fa9065f23aac49.jpg", "img_caption": ["Figure 4: Gaussian setting Metropolis-Hastings random walk under different privacy budgets and $\\ell_{1}$ regularization. (Weak signal) "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 27}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 27}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 27}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 27}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 27}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 27}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 27}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: In the abstract and introduction we claim that our our method provides a DP model estimator while enjoying computational efficiency. This matches with the theoretical and experimental demonstrations in the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 27}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We point out some of the limitations of the work and possible future directions in the Conclusion section. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 28}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We explicitly mention all the assumptions in the statement of the theorems and lemmas. The proofs of these results can be found in the appendix sections. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.x   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We clearly state all of the key parameters of the simulation experiments in the simulation section. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 29}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: The Github Link is provided in the footnote of Page 9. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. ", "page_idx": 29}, {"type": "text", "text": "\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). \u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We do the experiments on simulated data. Therefore, technically, we just have the testing step. We do specify clearly about this step in the simulation section. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 30}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [No] ", "page_idx": 30}, {"type": "text", "text": "Justification: We do not include the error bar for the F-scores as the results are pretty robust across different repetitions. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We have added the information about the computational resources in Section 5. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: This research work does not violate any NeurIPS Code of ethics. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 31}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: We point toward the potential positive impacts of our work in the conclusion sections. To the best of our knowledge, we could not think of any negative societal impact of our work. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We clearly cite the main webpage information and relevant papers regarding the used packages in the paper along with the license information. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 32}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The Github Link to our code is provided in the footnote of Page 9. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used. ", "page_idx": 32}, {"type": "text", "text": "\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 33}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 33}]