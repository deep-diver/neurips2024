[{"type": "text", "text": "Theoretical and Empirical Insights into the Origins of Degree Bias in Graph Neural Networks ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Arjun Subramonian1, Jian Kang2, Yizhou Sun1 1University of California, Los Angeles, 2University of Rochester {arjunsub, yzsun}@cs.ucla.edu jian.kang@rochester.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graph Neural Networks (GNNs) often perform better for high-degree nodes than low-degree nodes on node classification tasks. This degree bias can reinforce social marginalization by, e.g., privileging celebrities and other high-degree actors in social networks during social and content recommendation. While researchers have proposed numerous hypotheses for why GNN degree bias occurs, we find via a survey of 38 degree bias papers that these hypotheses are often not rigorously validated, and can even be contradictory. Thus, we provide an analysis of the origins of degree bias in message-passing GNNs with different graph filters. We prove that high-degree test nodes tend to have a lower probability of misclassification regardless of how GNNs are trained. Moreover, we show that degree bias arises from a variety of factors that are associated with a node\u2019s degree (e.g., homophily of neighbors, diversity of neighbors). Furthermore, we show that during training, some GNNs may adjust their loss on low-degree nodes more slowly than on high-degree nodes; however, with sufficiently many epochs of training, message-passing GNNs can achieve their maximum possible training accuracy, which is not significantly limited by their expressive power. Throughout our analysis, we connect our findings to previouslyproposed hypotheses for the origins of degree bias, supporting and unifying some while drawing doubt to others. We validate our theoretical findings on 8 common real-world networks, and based on our theoretical and empirical insights, describe a roadmap to alleviate degree bias. Our code can be found at: github.com/ArjunSubramonian/degree-bias-exploration. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graph neural networks (GNNs) have been applied to node classification tasks such as document topic prediction [4] and content moderation [41]. However, in recent years, researchers have shown that GNNs exhibit better performance for high-degree nodes on node classification tasks. This has significant social implications, such as the marginalization of: (1) authors of less-cited papers when predicting the topic of papers in citation networks; (2) junior researchers when predicting the suitability of prospective collaborators in academic collaboration networks; (3) creators of newer or niche products when predicting the category of products in online product networks; and (4) authors of short or standalone websites when predicting the topic of websites in hyperlink networks. ", "page_idx": 0}, {"type": "text", "text": "To illustrate this phenomenon, Figure 1 shows that across different message-passing GNNs (see $\\S D$ for details about architectures) applied to the CiteSeer dataset (where nodes represent documents and the classification task is to predict their topic), high-degree nodes generally incur a lower test loss than low-degree nodes. In practice, if such GNNs are applied to predict the topic of documents in social scientific studies, less-cited documents will be misclassified, which can lead to the contributions of their authors not being appropriately recognized and erroneous scientific results. We present additional evidence of degree bias across different GNNs and datasets in $\\mathrm{\\SE}$ . ", "page_idx": 0}, {"type": "image", "img_path": "1mAaewThcz/tmp/6fc27d38d1422be6bd83352eda7deb2277d212fcc33662fd2283fd6a768146b4.jpg", "img_caption": ["Figure 1: Test loss vs. degree of nodes in CiteSeer for RW, SYM, and ATT GNNs. High-degree nodes generally incur a lower test loss than low-degree nodes do. Error bars are reported over 10 random seeds; all error bars are 1-sigma and represent the standard deviation about the mean. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Researchers have proposed various hypotheses for why GNN degree bias occurs in node classification tasks. However, we find via a survey of 38 degree bias papers that these hypotheses are often not rigorously validated, and can even be contradictory (\u00a72). Furthermore, almost no prior works on degree bias provide a comprehensive theoretical analysis of the origins of degree bias that explicitly links a node\u2019s degree to its test and training error in the semi-supervised learning setting (\u00a72). ", "page_idx": 1}, {"type": "text", "text": "Hence, we theoretically analyze the origins of degree bias in node classification during test and training time for general message-passing GNNs, with separate parameters for source and target nodes and residual connections. Our analysis spans different graph filter choices: RW (random walk-normalized filter), SYM (symmetric-normalized filter), and ATT (attention-based filter) (see $\\S D$ for formal definitions). In particular, we prove that high-degree test nodes tend to have a lower probability of misclassification regardless of how GNNs are trained. Moreover, we show that degree bias arises from a variety of factors that are associated with a node\u2019s degree (e.g., homophily of neighbors, diversity of neighbors). Furthermore, we show that during training, SYM (compared to RW) may adjust its loss on low-degree nodes more slowly than on high-degree nodes; however, with sufficiently many epochs of training, message-passing GNNs can achieve their maximum possible training accuracy, which is only trivially curtailed by their expressive power. Throughout our analysis, we connect our findings to previously-proposed hypotheses for the origins of degree bias, supporting and unifying some while drawing doubt to others. We validate our theoretical findings on 8 real-world datasets (see $\\S C_{\\k}$ that are commonly used in degree bias papers (see Figure 2, $\\S\\mathrm{F}_{.}$ ). Based on our theoretical and empirical insights, we describe a principled roadmap to alleviate degree bias. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Numerous prior works have proposed hypotheses for why GNN degree bias occurs in node classification tasks. We summarize these hypotheses in Table 2 based on a survey of 38 non-review papers about degree bias in node classification that cite [45], a seminal work on degree bias. ", "page_idx": 1}, {"type": "text", "text": "While many of these papers have contributed solutions to degree bias (see $\\S\\mathrm{A}$ for a thorough overview), we find that their hypotheses for the origins of degree bias are often not rigorously validated, and can even be contradictory. For example, some hypotheses locate the source of degree bias in the training stage, while others cite interactions between training and test-time factors or purely test-time issues. Moreover, hypothesis (H5) in Table 2, which posits that high-degree node representations cluster more strongly, conflicts with and (H10), which argues that high-degree node representations have a larger variance. In our theoretical analysis of the origins of degree bias, we connect our findings to these hypotheses. ", "page_idx": 1}, {"type": "text", "text": "We further find that almost no prior works on degree bias provide a comprehensive theoretical analysis of the origins of GNN degree bias that explicitly links a node\u2019s degree to its test and training error in the semi-supervised learning setting (see Table 3). For example, most works prove that: (a) high-degree nodes have a larger influence on GNN node representations or parameter gradients, or (b) high-degree nodes cluster more strongly around their class centers or are more likely to be linearly separable; however, these works do not directly bound the probability of misclassifying a node during training vs. test time in terms of its degree. ", "page_idx": 1}, {"type": "table", "img_path": "1mAaewThcz/tmp/c5ba7fc09b9eac943de24b4acb2756f922c53fd6a74a135b8adf3c0020749c60.jpg", "table_caption": ["Table 1: Five most popular hypotheses for the origins of degree bias proposed by papers. The remaining hypotheses can be found in Table 2. "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "The few works that do provide a theoretical analysis of degree bias: (A1) perform this analysis with overly strong assumptions, e.g., that graphs are sampled from a Contextual Stochastic Block Model (CSBM) [10], or (A2) posit that GNNs do not have sufficient expressive power to map nodes with different degrees to distinct representations. However, in the case of (1), for CSBM graphs, as the number of nodes $n\\to\\infty$ , the degrees of nodes in each class concentrate around a constant value, which is contradictory to real-world graphs, making CSBM an inappropriate model to theoretically analyze degree bias. Moreover, many real-world social networks exhibit a power-law degree distribution [3], which is not captured by a CSBM. In the case of (2), $\\S\\mathrm{I}$ shows that the accuracy of GNNs on real-world networks is not significantly limited by the Weisfeiler-Leman (WL) test, which draws doubt to hypothesis (H7). ", "page_idx": 2}, {"type": "text", "text": "Ultimately, previously-proposed hypotheses for why GNN degree bias occurs lack rigorous validation, and can even be contradictory. To unify and distill these hypotheses, we provide an analysis of the origins of degree bias in message-passing GNNs with different graph filters. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Throughout our theoretical analysis, we connect our findings to previously-proposed hypotheses for the origins of degree bias, supporting and unifying some while drawing doubt to others. We further validate our findings on 8 real-world datasets (see $\\mathbf{\\xi}\\mathbf{\\Xi}^{\\S C},$ ) that are commonly used in degree bias papers (see Figure 2, $\\S\\mathrm{F},$ ). In all figures (except the PCA plots), error bars are reported over 10 random seeds. The factors of variability include model parameter initialization and training dynamics. All error bars are 1-sigma and represent the standard deviation (not standard error) of the mean. We implicitly assume that errors are normally-distributed. Error bars are computed using PyTorch\u2019s std function [40]. We relegate all proofs to $\\S B$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "We first introduce relevant notation and assumptions. Suppose we have a $C$ -class node classification problem defined over an undirected connected graph $\\mathcal{G}\\,=\\,(\\mathcal{V},\\mathcal{E})$ with $N=|\\nu|$ nodes. We assume that our graph structure $\\pmb{A}\\;\\in\\;\\{0,1\\}^{N\\times N}$ and node labels $\\dot{Y}\\,\\in\\,\\mathbb{N}_{\\le C}^{N}$ are fixed, but our node features X \u2208RN\u00d7d(0)a re independently sampled from class-specific feature distributions, i.e., $\\forall i\\in\\mathcal{V},X_{i}\\sim\\mathcal{D}_{\\mathbf{Y}_{i}}$ . We further have a model $\\mathcal{M}$ that maps $X,A$ to predictions $\\boldsymbol{\\widehat{Y}}\\in\\mathbb{R}^{N\\times C}$ . We use a cross-entropy loss function $\\ell(\\mathcal{M}|i,c)=-\\log\\widehat{Y}_{i,c}$ that computes the loss for node $i\\in\\mathcal{V}$ with respect to class $c$ for $\\mathcal{M}$ . Per the semi-supervised le arning paradigm [24], we train $\\mathcal{M}$ with the full graph $X,A$ but only a labeled subset of nodes $S\\subset\\mathcal{V}$ . ", "page_idx": 3}, {"type": "text", "text": "4 Test-Time Degree Bias ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The test-time degree bias of models is important to study, as it can yield disparate performance for low-degree nodes when models are deployed in the real world. We prove that high-degree test nodes tend to have a lower probability of misclassification. Moreover, we show that GNN degree bias arises from a variety of factors that are associated with a node\u2019s degree (e.g., homophily of neighbors, diversity of neighbors). We first present a theorem that bounds the probability of a test node $i\\in\\mathcal{V}\\setminus S$ being misclassified. We suppose $\\mathcal{M}$ is a neural network that has $L$ layers. It takes as input $X,A$ and generates node representations $Z^{(L)}\\,\\in\\,\\mathbb{R}^{N\\times C}$ ; these representations are then passed through a softmax activation function to get $\\hat{\\pmb Y}={\\pmb H}^{(L)}=$ softmax $\\left(Z^{(L)}\\right)$ . At this point, we make few assumptions about the architecture of $\\mathcal{M}$ ; $\\mathcal{M}$ could be a graph neural network (GNN), or even an MLP or logistic regression model. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1. Consider a test node $i\\in\\mathcal{V}\\backslash S$ , with $Y_{i}=c$ . Furthermore, consider a label $c^{\\prime}\\neq c.$ . Let $\\mathbb{P}\\left(\\ell(\\mathcal{M}|i,c)>\\ell(\\mathcal{M}|i,c^{\\prime})\\right)$ be the probability of misclassifying $i$ . Then, i $f\\,\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]\\,<\\,0$ (i.e., $\\mathcal{M}$ generalizes in expectation): ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\ell(\\mathcal{M}|i,c)>\\ell(\\mathcal{M}|i,c^{\\prime})\\right)\\le\\frac{1}{1+R_{i,c^{\\prime}}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the squared inverse coefficient of variation $\\begin{array}{r}{R_{i,c^{\\prime}}=\\frac{\\left(\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]\\right)^{2}}{V a r\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]}}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "The assumption that $\\mathcal{M}$ generalizes in expectation is required for the application of Cantelli\u2019s inequality in the proof. Notably, it is not possible to prove a similar lower bound without making assumptions about the higher-order moments of Zi(,Lc\u2032) \u2212 $\\bar{\\mathbf{Z}}_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}$ . The coefficient of variation $\\frac{\\mathrm{Std}\\left[{\\pmb Z}_{i,c^{\\prime}}^{(L)}\\!-\\!{\\pmb Z}_{i,c}^{(L)}\\right]}{\\mathbb{E}\\left[{\\pmb Z}_{i,c^{\\prime}}^{(L)}\\!-\\!{\\pmb Z}_{i,c}^{(L)}\\right]}$ is a normalized measure of dispersion that is often used in economics to quantify inequality [13]. Thus, $R_{i,c^{\\prime}}$ captures how little $Z_{i}$ varies relative to its expected value. In summary, the probability of misclassification $\\mathbb{P}\\left(\\ell(\\mathcal{M}|i,c)>\\ell(\\mathcal{M}|i,c^{\\prime})\\right)$ can be minimized when $R_{i,c^{\\prime}}$ is maximized. Intuitively, the probability of misclassification is reduced when $Z_{i}$ is farther away, in expectation, from the decision boundary that separates classes $c$ and $c^{\\prime}$ , and has low dispersion. The following subsections reveal why $R_{i,c^{\\prime}}$ is large when $i$ is high-degree. ", "page_idx": 3}, {"type": "text", "text": "4.1 Random Walk Graph Filter ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "So far, we have made few assumptions about $\\mathcal{M}$ . Now, we suppose $\\mathcal{M}$ is a general message-passing GNN [16]. In particular, for layer $l$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{H}^{(l)}=\\sigma^{(l)}\\left(\\pmb{Z}^{(l)}\\right)=\\sigma^{(l)}\\left(\\pmb{H}^{(l-1)}\\pmb{W}_{1}^{(l)}+\\pmb{P}^{(l)}\\pmb{H}^{(l-1)}\\pmb{W}_{2}^{(l)}+\\pmb{X}\\pmb{W}_{3}^{(l)}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where H(l) \u2208RN\u00d7d(l) are the $l$ -th layer node representations (with $H^{(0)}\\,=\\,X$ and $d^{(L)}=C)$ , $\\sigma^{(l)}$ is an instance-wise non-linearity (with $\\sigma^{(L)}$ being softmax), $P^{(l)}\\in\\mathbb{R}^{N\\times N}$ is a graph filter, and $W_{1}^{(l)},W_{2}^{(l)},W_{3}^{(l)}\\in\\mathbb{R}^{d^{(l-1)}\\times d^{(l)}}$ are the $l$ -th layer model parameters. ", "page_idx": 3}, {"type": "image", "img_path": "1mAaewThcz/tmp/6cd3a984d5a3f32e0c97806e21e83f119efb2bec6fd4fcb70e96d9160103d99d.jpg", "img_caption": ["Figure 2: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on CiteSeer. We consider low-degree nodes to be the 100 nodes with the smallest degrees and high-degree nodes to be the 100 nodes with the largest degrees. Each point in the plots in the left column corresponds to a test node representation and its color represents the node\u2019s class. (In this particular dataset, low-degree nodes are more heavily concentrated in a few classes.) The plots in the left column are based on a single random seed, while the plots in the middle and right columns are based on 10 random seeds. RW representations of low-degree nodes often have a larger variance than high-degree node representations, while SYM representations of low-degree nodes often have a smaller variance. Furthermore, SYM generally adjusts its training loss on low-degree nodes less rapidly. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "We first consider the special case that $\\forall l\\in\\mathbb{N}_{\\leq L},P^{(l)}=P_{\\mathrm{rw}}=D^{-1}A$ (i.e., the uniform random walk transition matrix), where $_{D}$ is the diagonal degree matrix with entries $\\begin{array}{r}{D_{i i}=\\sum_{j\\in\\mathcal{V}}A_{i j}}\\end{array}$ . We further simplify the model by choosing all $\\sigma^{(l)}$ $(l<L)$ to be the identity function (e.g., as in [51]). By doing so, we get the following linear jumping knowledge model $\\overrightarrow{\\mathrm{RW}}$ [58]: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\pmb{H}^{(L)}=\\mathrm{softmax}\\left(\\pmb{Z}^{(L)}\\right)=\\mathrm{softmax}\\left(\\sum_{l=0}^{L}P_{\\mathrm{rw}}^{l}\\pmb{X}\\pmb{W}^{(l)}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\forall l\\in\\mathbb{N}_{\\leq L},W^{(l)}\\in\\mathbb{R}^{d^{(0)}\\times C}$ . $\\boldsymbol{W}^{(l)}$ is the sum of all the weight terms that correspond to $P_{r w}^{l}$ in Eqn. 2; for simplicity, we collapse each sum of weight terms into a single weight matrix. It is still reasonable to have a different weight matrix $\\boldsymbol{W}^{(l)}$ for each term $P_{r w}^{l}X$ , as we may need to extract different information from features aggregated from neighborhoods at different hops. For each model $\\mathcal{M}$ , $\\overline{{\\mathcal{M}}}$ denotes the linearized version of the model that we theoretically analyze. Linearizing GNNs is a common practice in the literature [51, 7, 39]. ", "page_idx": 4}, {"type": "text", "text": "We now prove a lower bound for $R_{i,c^{\\prime}}$ . By identifying nodes for which this lower bound is larger, we can indirectly figure out which nodes have a lower probability of misclassification. In particular, we find that the bound is generally larger for high-degree nodes, which sheds light on the origins of degree bias. For simplicity of notation, we denote the weights corresponding to the decision boundary of the l-th term that separates classes c and c\u2032 by wc(l\u2032)\u2212c $\\pmb{w}_{c^{\\prime}-c}^{(l)^{-}}=\\pmb{W}_{.,c^{\\prime}}^{(l)^{-}}-\\pmb{W}_{.,c}^{(\\tilde{l})}$ , and $\\mathcal{N}^{(l)}(i)$ to be the distribution over the terminal nodes of length- $l$ uniform random walks starting from node $i$ . We further define: ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\beta_{i,c^{\\prime}}^{(l)}=\\mathbb{E}_{j\\sim\\mathcal{N}^{(l)}(i)}\\left[\\mathbb{E}_{\\pmb{x}\\sim\\mathcal{D}\\mathbf{r}_{j}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]\\right]\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "as the $l$ -hop prediction homogeneity of $i$ with respect to $c^{\\prime}$ when $\\textbf Y_{i}~~=~c$ . In essence, $\\mathbb{E}_{\\mathbf{x}\\sim\\mathcal{D}_{\\mathbf{Y}_{j}}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]$ captures the expected prediction score of $\\pmb{w}_{c^{\\prime}-c}^{(l)}$ for a node $j$ whose features $X_{j}\\,\\sim\\,\\mathcal{D}_{\\mathbf{Y}_{j}}$ ; when $\\underline{{\\mathbb{E}}}_{\\pmb{x}\\sim\\mathcal{D}_{\\pmb{Y}_{j}}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]$ is more negative on average, wc(l\u2032)\u2212c predicts j to belong to class c with higher likelihood. Thus, \u03b2i(,lc)\u2032 measures the expected prediction score for nodes $j$ , weighted by their probability of being reached by a length- $l$ random walk starting from $i$ . ", "page_idx": 5}, {"type": "text", "text": "From a topological perspective, because $\\beta_{i,c^{\\prime}}^{(l)}$ depends on the distribution of random walks from $i$ , it is intimately related to local graph structure. Indeed, $\\beta_{i,c^{\\prime}}^{(l)}$ can be interpreted as a \u201clocal subgraph difference\u201d and is highly influenced by the local homophily of $i$ . However, $\\beta_{i,c^{\\prime}}^{(l)}$ is also influenced by the presence of $l$ -hop neighbors contained in the training set, as the model is more likely to correctly classify these nodes by a large margin; hence, $\\beta_{i,c^{\\prime}}^{(l)}$ does not only boil down to local homophily. We discuss other connections between prediction homogeneity, homophily, and separability in $\\S\\mathrm{A}.4$ . ", "page_idx": 5}, {"type": "text", "text": "In addition to the $l$ -hop prediction homogeneity, we denote the $l$ -hop collision probability by: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\alpha_{i}^{(l)}=\\sum_{j\\in\\mathcal{V}}\\left[\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\right]^{2},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which quantifies the probability of two length- $l$ random walks starting from $i$ colliding at the same end node $j$ . When the collision probability is lower, random walks starting from $i$ have a higher likelihood of ending at distinct nodes; in effect, the random walks can be considered to be more diverse. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. Assume that \u2200l \u2208N\u2264L, \u2200j \u2208V, Varx\u223cDY $\\forall l\\in\\mathbb{N}_{\\leq L},\\forall j\\in\\mathcal{V},V a r_{x\\sim\\mathcal{D}_{Y_{j}}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]\\leq M.\\ T h e n:$ ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{i,c^{\\prime}}\\geq\\frac{\\left(\\sum_{l=0}^{L}\\beta_{i,c^{\\prime}}^{(l)}\\right)^{2}}{M(L+1)\\sum_{l=0}^{L}\\alpha_{i}^{(l)}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We observe that to make $R_{i,c^{\\prime}}$ larger, and thus minimize the probability of misclassification, it is sufficient (although not necessary) that the inverse collision probability $L\\,=\\,1$ , $\\begin{array}{r}{\\frac{1}{\\sum_{l=0}^{L}\\alpha_{i}^{(l)}}\\,=\\,\\frac{1}{\\frac{1}{D_{i i}}+1}}\\end{array}$ D11+1, which is larger for high-degree nodes. We find empirically that the lL=0 \u03b1i(l) is larger. When inverse collision probability is positively associated with node degree (see Figures 3, 13, 14). (We elaborate on connections between the inverse collision probability and node degree in $\\S\\mathrm{K}.$ ) Furthermore, disparities in the inverse collision probability across nodes with different degrees is reduced by residual connections and increased by self-loops. Intuitively, random walks starting from highdegree nodes diffuse more quickly, maximizing the probability of any two random walks not colliding at the same end node; in this way, a higher inverse collision probability indicates a more diverse and possibly informative $L$ -hop neighborhood. This finding supports hypothesis (H1) (see Table 2). Additionally, to make $R_{i,c^{\\prime}}$ larger, it is sufficient that for all $l\\,\\in\\,\\mathbb{N}_{\\leq L}$ , $\\beta_{i,c^{\\prime}}^{(l)}$ is more negative, e.g., when most nodes in the $l$ -hop neighborhood of $i$ are predicted to belong to class $c$ . Thus, $\\beta_{i,c^{\\prime}}^{(l)}$ can be more negative when nodes in the -hop neighborhood of also are in class $c$ (i.e., node $i$ has high finding sup local homophily) and were part of the training set hypotheses and . No $S$ bly, we cannot make , leading to them being correctly classified. This more positive ports $\\left(\\mathbf{H4}\\right)$ $\\mathbf{\\sigma}(\\mathbf{H6})$ $\\textstyle\\sum_{l=0}^{L}\\beta_{i,c^{\\prime}}^{l\\bar{)}}$ $R_{i,c^{\\prime}}$ ; this would violate the assumption of Theorem 2 that the model generalizes in expectation, which is necessary to make a mathematically rigorous statement about degree bias via tail bounds. Intuitively, it also would not make sense that RW and SYM reduce the misclassification error for a node by predicting its neighbors to be of a different class, since message passing smooths the representations of adjacent nodes. Moreover, distribution shifts in local homophily from train to test time can reduce test-time prediction performance, bringing $\\beta_{i,c^{\\prime}}^{(l)}$ closer to 0; this can increase $R_{i,c^{\\prime}}$ , thereby not inducing as much degree bias at the expense of overall test performance. ", "page_idx": 5}, {"type": "image", "img_path": "1mAaewThcz/tmp/238d79f50a99ea2cd50a010b961fe922dfb66cefc14f164fd09c8b8e5ef7501c.jpg", "img_caption": ["Figure 3: Inverse collision probability vs. degree of nodes in CiteSeer for RW, SYM, and ATT GNNs. Node degrees generally have a strong association with inverse collision probabilities. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Furthermore, our proof of Theorem 2 (Eqn. 21) reveals that in expectation, the linearized model RW produces similar representations for low and high-degree nodes with similar $L$ -hop neighborhood homophily levels. However, low-degree nodes (specifically nodes with a lower inverse collision probability) tend to have a higher variance in $\\overline{{\\mathbf{RW}}}$ \u2019s representation space than high-degree nodes do (Eqn. 24). This entails that factors beyond homophily (e.g., diversity of neighbors) induce degree bias. We validate these findings empirically in Figure 2 and $\\S\\mathrm{F}$ . In Figure 2, we see in the left plot in the RW row (first row) that low-degree test nodes have representations that are similarly centered but more spread out in the first two principal components of all the test representations than high-degree nodes; we confirm that low-degree node representations have a larger variance in the middle plot in the RW row. Thus, regardless of how RW is trained, low-degree nodes have a higher probability of being on the wrong side of RW\u2019s decision boundaries. Indeed, the left plot in the RW row shows that low-degree nodes of a certain class end up closer to nodes of a different class at a higher rate. Notably, this occurs even when RW is relatively shallow (i.e., 3 layers). Thus, this finding supports hypothesis $\\mathbf{\\left(H5\\right)}$ , as well as draws doubt to hypotheses $\\mathbf{(H3)}$ and $\\mathbf{(H10)}$ . Our results for $\\overline{{\\mathrm{RW}}}$ may also hold for ATT when low-degree nodes are generally less attended to since like random walk transition matrices, attention matrices are row-stochastic. ", "page_idx": 6}, {"type": "text", "text": "4.2 Symmetric Graph Filter ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now consider the special case that $\\forall l\\,\\in\\,\\mathbb{N}_{\\leq L},P^{(l)}\\,=\\,P_{\\mathrm{sym}}\\,=\\,D^{-\\frac{1}{2}}A D^{-\\frac{1}{2}}$ . We once again simplify $\\mathcal{M}$ by making all $\\sigma^{(l)}$ the identity function, getting $\\overline{{\\cal S}}\\overline{{\\sf Y M}}$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\pmb{H}^{(L)}=\\mathrm{softmax}\\left(\\pmb{Z}^{(L)}\\right)=\\mathrm{softmax}\\left(\\sum_{l=0}^{L}P_{\\mathrm{sym}}^{l}\\pmb{X}\\pmb{W}^{(l)}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We define: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widetilde{\\beta}_{i,c^{\\prime}}^{(l)}=\\mathbb{E}_{j\\sim\\mathcal{N}^{(l)}(i)}\\left[\\frac{1}{\\sqrt{D_{j j}}}\\mathbb{E}_{x\\sim\\mathcal{D}_{Y_{j}}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]\\right]\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "as the degree-discounted $l$ -hop prediction homogeneity. Similar to $\\beta_{i,c^{\\prime}}^{(l)},\\widetilde{\\beta}_{i,c^{\\prime}}^{(l)}$ measures the expected prediction score for nodes $j$ , but weighted by the inverse square root of their degree in addition to their probability of being reached by a length- $l$ random walk starting from $i$ . In effect, $\\widetilde{\\beta}_{i,c^{\\prime}}^{(l)}$ more heavily discounts the prediction scores for high-degree nodes. We also denote the degree-discounted sum of collision probabilities by: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widetilde{\\alpha}_{i}^{(l)}=\\sum_{j\\in\\nu}\\frac{1}{D_{j j}}\\left[\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\right]^{2},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where each summation term $\\left[\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\right]^{2}$ quantifies the probability of two length- $l$ random walks starting from $i$ ending at $j$ and is discounted by the degree of $j$ . Compared to the random walk setting, the degree-discounted prediction homogeneity and sum of collision probabilities suppress the contributions of high-degree nodes. We now prove a lower bound for $R_{i,c^{\\prime}}$ for $\\overline{{\\mathrm{SYM}}}$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 3. Assume that \u2200l \u2208N\u2264L, \u2200j \u2208V, Varx\u223cDY $\\forall l\\in\\mathbb{N}_{\\leq L},\\forall j\\in\\mathcal{V},V a r_{x\\sim\\mathcal{D}_{Y_{j}}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]\\leq M.\\ T h e n.$ ", "page_idx": 7}, {"type": "equation", "text": "$$\nR_{i,c^{\\prime}}\\geq\\frac{\\left(\\sum_{l=0}^{L}\\widetilde{\\beta}_{i,c^{\\prime}}^{(l)}\\right)^{2}}{M(L+1)\\sum_{l=0}^{L}\\widetilde{\\alpha}_{i}^{(l)}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Once again, we observe that $R_{i,c^{\\prime}}$ is larger, and thus the probability of misclassification is minimized, when the inverse (degree-discounted) sum of collision probabilities $\\frac{1}{\\sum_{l=0}^{L}\\widetilde{\\alpha}_{i}^{(l)}}$ is larger and for all $l\\,\\in\\,\\mathbb{N}_{\\leq L}$ , the (degree-discounted) $l$ -hop prediction homogeneity $\\widetilde{\\beta}_{i,c^{\\prime}}^{(l)}$ is more negative. Like for RW, these findings support hypotheses (H1), $\\left(\\mathbf{H4}\\right)$ , and (H6) (see Table 2). ", "page_idx": 7}, {"type": "text", "text": "Furthermore, our proof of Theorem 3 (Eqn. 33) reveals that in expectation, $\\overline{{\\cal S}}\\overline{{\\sf Y M}}$ often produces representations for low-degree nodes that lie closer to $\\overline{{\\mathbf{SYM}}}$ \u2019s decision boundary than representations of high-degree nodes with similar $L$ -hop neighborhood homophily levels. This is because $\\overline{{\\mathrm{SYM}}}$ produces node representations that are approximately scaled by the square root of the node\u2019s degree. However, for the same reason, unlike for $\\overline{{\\mathrm{RW}}}$ , low-degree nodes tend to have a lower variance in SYM\u2019s representation space than high-degree nodes do (Eqn. 36); this corroborates the findings of [12]. We validate this empirically in Figure 2 and $\\S\\mathrm{F}$ on the homophilic datasets (i.e., all datasets except chameleon and squirrel). In Figure 2, we see in the left plot in the SYM row (second row) that low-degree test nodes (particularly low-degree nodes with many high-degree nodes in their $L$ -hop neighborhood) have representations that are closer to SYM\u2019s decision boundaries but less spread out in the first two principal components of all the test representations than high-degree nodes; we confirm that low-degree node representations have a smaller or comparable variance in the middle plot in the SYM row. We emphasize that while SYM representations of high-degree nodes have a higher variance, this itself is not the cause of degree bias; since the standard deviation and expectation of SYM node representations are approximately scaled by the same factor, by Theorem 1, the variance of SYM representations of high-degree nodes does not enlarge $R_{i,c^{\\prime}}$ noticeably more than in the RW case. ", "page_idx": 7}, {"type": "text", "text": "Notably, our theoretical findings do extend to heterophilic graphs. In particular, high-degree nodes in heterophilic networks (e.g., chameleon and squirrel) do not have higher negative $L$ -hop prediction homogeneity levels due to higher local heterophily (see $\\S\\mathrm{F}_{.}$ ), and hence we do not necessarily observe better test performance for them (see Figure 5). None of our theoretical analysis assumes homophilic networks. ", "page_idx": 7}, {"type": "text", "text": "Ultimately, like for RW, low-degree nodes (specifically nodes with a lower inverse collision probability) have a larger probability of being on the wrong side of SYM\u2019s decision boundaries (regardless of how SYM is trained). Indeed, low-degree nodes of a certain class end up closer to nodes of a different class at a higher rate. Notably, this occurs even when SYM is relatively shallow (i.e., 3 layers). Thus, this finding supports hypothesis (H5), and draws doubt to hypotheses (H3), (H7), and (H10). ", "page_idx": 7}, {"type": "text", "text": "5 Training-Time Degree Bias ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We show that during training, SYM (compared to RW) may adjust its loss on low-degree nodes more slowly than on high-degree nodes. This finding is important because as GNNs are applied to increasingly large networks, only a few epochs of training may be possible due to limited compute; as such, we must ask: which nodes receive superior utility from limited training? Even though we know the labels for training nodes, GNNs may serve as an efficient lookup mechanism for training nodes in deployed systems; thus, if partially-trained, GNNs can perform poorly for low-degree training nodes. We also empirically demonstrate that despite learning at different rates for low vs. high-degree nodes, message-passing GNNs (even those with static filters) can achieve their maximum possible training accuracy, which is not significantly curtailed by their expressive power. ", "page_idx": 7}, {"type": "text", "text": "We first demonstrate that during each step of training of $\\overline{{\\mathrm{SYM}}}$ with gradient descent, the loss of low-degree nodes is adjusted more slowly than high-degree nodes. We consider the setting that, for all $l\\in\\ensuremath{\\mathbb{N}}_{\\leq L}$ , at each training step $t$ : ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbf{}W^{(l)}[t+1]\\leftarrow W^{(l)}[t]-\\eta\\frac{\\partial\\ell[t]}{\\partial\\mathbf{W}^{(l)}[t]}(B[t]),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $W^{(l)}[t]$ is $W^{(l)}$ at training step $t,\\,\\eta$ is the learning rate, $\\ell[t]$ is the model\u2019s loss at $t$ , and $B[t]\\subseteq S$ (where $S\\subseteq\\mathcal{V}$ is the labeled subset of nodes) is the batch used at step $t$ . ", "page_idx": 8}, {"type": "text", "text": "Consider a node $\\textit{i}\\in\\textit{\\V}$ , with $Y_{i}~=~c$ . We define $Z_{i}^{(L)}[t]$ to be $Z_{i}^{(L)}$ at timestep $t$ . We begin by proving the following lemma, which states that for any model $\\mathcal{M}$ , $\\ell[t](\\mathcal{M}|i,\\bar{c})$ (for all $t$ ) is $\\lambda$ -Lipschitz continuous with respect to $Z_{i}^{(L)}[t]$ . ", "page_idx": 8}, {"type": "text", "text": "Lem\u221ama 1. For all $t,$ , $\\ell[t](\\mathcal{M}\\vert i,c)$ is $\\lambda$ -Lipschitz continuous with respect to $Z_{i}^{(L)}[t]$ with constant $\\lambda={\\sqrt{2}}$ , that is: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\ell[t+1](\\mathcal{M}|i,c)-\\ell[t](\\mathcal{M}|i,c)|\\leq\\left\\|Z_{i}^{(L)}[t+1]-Z_{i}^{(L)}[t]\\right\\|_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Now, we move to the main theorem where we bound the change in loss $i$ after an arbitrary training step $t$ (regardless of batching paradigm) in terms of its degree. We denote the residual of the predictions of $\\overline{{\\cal S}}\\overline{{\\sf Y M}}$ at step $t$ by $\\epsilon[t]\\;=\\;{\\pmb H}^{(L)}[t]\\;.$ \u2212onehot $(Y[t])$ , where $H^{(L)}[t]$ and onehot $(Y[t])$ are the submatrices formed from the rows of $H^{(L)}$ and onehot $(Y)$ , respectively, that correspond to the nodes in $B[t]$ . Furthermore, we denote $\\forall l\\:\\in\\:\\mathbb{N}_{\\leq L}$ , the expected similarity of the neighborhoods of $i$ and $B[t]$ by $\\widetilde{\\chi}_{i}^{(l)}\\;\\in\\;\\mathbb{R}^{|B[t]|}$ , where for $\\stackrel{-}{m}\\;\\in\\;B[t],\\,\\Big(\\widetilde{\\chi}_{i}^{(l)}[t]\\Big)_{m}\\;=$ $\\begin{array}{r}{\\sqrt{D_{m m}}\\mathbb{E}_{j\\sim\\mathcal{N}^{(l)}(i),k\\sim\\mathcal{N}^{(l)}(m)}\\,\\left[\\frac{1}{\\sqrt{D_{j j}D_{k k}}}X_{j}X_{k}^{T}\\right].}\\end{array}$ . Specifically, $\\left(\\widetilde{\\chi}_{i}^{(l)}[t]\\right)_{m}$ captures the degreediscounted expected similarity between the raw features of nodes $j$ and $k$ with respect to the $l$ -hop random walk distributions of $i\\in\\mathcal{V}$ and $m\\in B[t]$ . Notably, our matrix is pre-feature aggregation (e.g., unlike [37]). ", "page_idx": 8}, {"type": "text", "text": "Theorem 4. The change in loss for $i$ after an arbitrary training step t obeys: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\left|\\ell[t+1](\\overline{{S Y M}}|i,c)-\\ell[t](\\overline{{S Y M}}|i,c)\\right|\\leq\\sqrt{D_{i i}}\\cdot\\sqrt{2}\\eta\\left\\|\\epsilon[t]\\right\\|_{F}\\sum_{l=0}^{L}\\left\\|\\widetilde{\\chi}_{i}^{(l)}[t]\\right\\|_{2}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "As observed, the change (either increase or decrease) in loss for $i$ after an arbitrary training step has a smaller magnitude if $i$ is low-degree. Thus, when $\\ell[t+1](\\overline{{\\mathrm{SYM}}}|i,c)\\,<\\,\\ell[t](\\overline{{\\mathrm{SYM}}}|i,c)$ (e.g., if $i\\in B[t])$ , the loss for $i$ decreases more slowly when $i$ is low-degree. In effect, because the magnitude of SYM node representations is positively associated with node degree while the magnitude of each gradient descent step is the same across nodes, the representations of low-degree nodes experience a smaller change during each step. We additionally notice that the loss for $i$ changes more slowly when the features of nodes in its $L$ -hop neighborhood are not similar to the features in the $L$ -hop neighborhoods of the nodes in each training batch (i.e., $\\sum_{l=0}^{L}\\left\\|\\widetilde{\\chi}_{i}^{(l)}[t]\\right\\|_{2}$ is small). Because the $L$ hop neighborhoods of low-degree nodes tend to be smaller than those of high-degree nodes, their neighborhoods often have less overlap with the neighborhoods of training nodes, which can further constrain the rate at which the loss for $i$ changes. Notably, while node degree highly affects the rate of learning, differences in $\\widetilde{\\chi}$ across nodes due to factors other than degree are also influential. ", "page_idx": 8}, {"type": "text", "text": "We confirm these findings empirically in Figure 2 and $\\S\\mathrm{F}$ . For all the datasets, when training SYM, the blue curve (i.e., the loss for low-degree nodes) has a less steep rate of decrease than the orange curve (i.e., the loss for high-degree nodes) as the number of epochs increases. For example, in Figure 2, in the case of RW and ATT, the training loss curves for low and high-degree nodes (including error bars) overlap during the first $\\sim20$ epochs of training. However, for SYM, the loss curve for highdegree nodes descends more rapidly than the curve for low-degree nodes. These findings support hypothesis $\\mathbf{\\sigma}(\\mathbf{H}2)$ (c.f. Table 2). ", "page_idx": 8}, {"type": "text", "text": "In $\\S\\mathrm{H}$ , we demonstrate that during each step of training $\\overline{{\\mathbf{RW}}}$ with gradient descent, compared to $\\overline{{\\mathrm{SYM}}}$ , the loss of low-degree nodes in $S$ is not necessarily adjusted more slowly. Furthermore, in $\\S\\mathrm{I}.$ , we empirically show that SYM (despite learning at different rates for low vs. high-degree nodes), RW, and ATT can achieve their maximum possible training accuracy, which is often close to $100\\%$ ; this indicates that expressive power does not significantly limit the accuracy of these models in practice and draws doubt to hypothesis (H7). ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6 Principled Roadmap to Address Degree Bias ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The primary aim of this work is to explore and explain the origins of GNN degree bias, which lacks a principled understanding. Future research can build on the strong theoretical and empirical foundation laid by this paper to propose alleviation strategies for degree bias. In particular, our findings reveal that any alleviation strategies should target the following theoretically-justified criteria, which we have empirically validated on 8 real-world datasets: ", "page_idx": 9}, {"type": "text", "text": "\u2022 Maximizing the inverse collision probability of low-degree nodes (e.g., via edge augmentation for low-degree nodes). Figure 3 and the plots in Section G show strong positive associations between inverse collision probability and degree for the RW, SYM, and ATT filters, and Figure 1 and the plots in Section E show strong negative associations between degree and test loss for the homophilic datasets. Hence, we validate that a higher inverse collision probability is associated with lower test loss, as our theory predicts. ", "page_idx": 9}, {"type": "text", "text": "\u2022 Increasing the $L$ -hop prediction homogeneity of low-degree nodes (e.g., by ensuring similar label densities in the neighborhoods of low and high-degree nodes). The lack of degree bias observed in Figure 5 for chameleon and squirrel (which are heterophilic networks), compared to Figure 1 and the plots in Section E, confirms our theoretical finding that under heterophily, the prediction homogeneity for high-degree nodes is closer to 0, so high-degree nodes do not necessarily experience better performance. ", "page_idx": 9}, {"type": "text", "text": "\u2022 Minimizing distributional differences (e.g., differences in expectation, variance) in the representations of low and high-degree nodes. Figures 2 and 6\u201310 empirically confirm our theoretical finding that disparities in the expectation and variance of node representations are responsible for performance disparities. Figures 11 and 12 suggest that smaller distributional differences among representations (due to heterophily) can alleviate degree bias. ", "page_idx": 9}, {"type": "text", "text": "\u2022 Reducing training discrepancies with regards to the rate at which GNNs learn for low vs. high-degree nodes. Figure 2 and the plots in Section F validate our theoretical finding that SYM adjusts its loss on low-degree nodes more slowly than on high-degree nodes (see 5). ", "page_idx": 9}, {"type": "text", "text": "These criteria are important because they reflect (to a large extent) inherent fairness issues with the graph filters that are popular in graph learning. For instance, the random walk and symmetric filters disadvantage low-degree nodes by yielding representations with high variance and low magnitude, respectively. It is valuable for graph learning practitioners to investigate filters that are adaptive or not restricted to the graph topology in a way that ensures that low-degree nodes are not marginalized through disparate representational distributions or poor neighborhood diversity. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our theoretical analysis aims to unify and distill previously-proposed hypotheses for the origins of GNN degree bias. We prove that high-degree test nodes tend to have a lower probability of misclassification and that degree bias arises from a variety of factors associated with a node\u2019s degree (e.g., homophily of neighbors, diversity of neighbors). Furthermore, we show that during training, some GNNs may adjust their loss on low-degree nodes more slowly; however, GNNs often achieve their maximum possible training accuracy and are trivially limited by their expressive power. We validate our theoretical findings on 8 real-world networks. Finally, based on our theoretical and empirical insights, we describe a roadmap to alleviate degree bias. More broadly, we encourage research efforts that unveil forms of inequality reinforced by GNNs. We detail the limitations and possible future directions of our work in $\\S L$ , including our survey, theoretical analysis (e.g., focusing on linearized GNNs, node classification), empirical validation (e.g., exploring degree bias in the inductive learning setting and heterogeneous and directed networks), and roadmap. We additionally discuss broader impacts in $\\S\\mathbf{M}$ . ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was partially supported by NSF 2211557, NSF 1937599, NSF 2119643, NSF 2303037, NSF 2312501, NASA, SRC JUMP 2.0 Center, Amazon Research Awards, and Snapchat Gifts. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "[1] Ben Adlam and Jeffrey Pennington. The neural tangent kernel in high dimensions: Triple descent and a multi-scale theory of generalization. In Hal Daume\u00b4 III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 74\u201384. PMLR, 13\u201318 Jul 2020.   \n[2] Chirag Agarwal, Himabindu Lakkaraju\\*, and Marinka Zitnik\\*. Towards a unified framework for fair and stable graph representation learning. 2021.   \n[3] Albert-La\u00b4szlo\u00b4 Baraba\u00b4si. Network science. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 371, 2016.   \n[4] Aleksandar Bojchevski and Stephan Gu\u00a8nnemann. Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking. In International Conference on Learning Representations, 2018.   \n[5] Stephen Bonner, Ufuk Kirik, Ola Engkvist, Jian Tang, and Ian P Barrett. Implications of topological imbalance for representation learning on biomedical knowledge graphs. Briefings in Bioinformatics, 23(5):bbac279, 07 2022.   \n[6] Jiajia Chen, Jiancan Wu, Jiawei Chen, Xin Xin, Yong Li, and Xiangnan He. How graph convolutions amplify popularity bias for recommendation? Frontiers of Computer Science, 18(5), December 2023.   \n[7] Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li. Simple and deep graph convolutional networks. In Hal Daum\u00b4e III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 1725\u20131735. PMLR, 13\u201318 Jul 2020.   \n[8] Renyao Chen, Junye Lei, Hong Yao, Tailong Li, and Shengwen Li. Anchor-enhanced geographical entity representation learning. IEEE Transactions on Neural Networks and Learning Systems, pages 1\u201315, 2023.   \n[9] Zhengyu Chen, Teng Xiao, and Kun Kuang. Ba-gnn: On learning bias-aware graph neural network. In 2022 IEEE 38th International Conference on Data Engineering (ICDE), pages 3012\u20133024, 2022.   \n[10] Yash Deshpande, Subhabrata Sen, Andrea Montanari, and Elchanan Mossel. Contextual stochastic block models. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. CesaBianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.   \n[11] Wei Ding, Jiawei Sun, Jie Li, and Chentao Wu. Inductive dummy-based homogeneous neighborhood augmentation for graph collaborative filtering. In 2023 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138, 2023.   \n[12] Claire Donnat and So Won Jeong. Studying the effect of GNN spatial convolutions on the embedding space\u2019s geometry. In Robin J. Evans and Ilya Shpitser, editors, Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence, volume 216 of Proceedings of Machine Learning Research, pages 539\u2013548. PMLR, 31 Jul\u201304 Aug 2023.   \n[13] Brian Everitt. The Cambridge dictionary of statistics. Cambridge University Press, Cambridge, UK; New York, 2002.   \n[14] Fuli Feng, Weiran Huang, Xiangnan He, Xin Xin, Qifan Wang, and Tat-Seng Chua. Should graph convolution trust neighbors? a simple causal inference method. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201921, page 1208\u20131218, New York, NY, USA, 2021. Association for Computing Machinery.   \n[15] Matthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019.   \n[16] Francesco Di Giovanni, James Rowbottom, Benjamin Paul Chamberlain, Thomas Markovich, and Michael M. Bronstein. Understanding convolution on graphs via energies. Transactions on Machine Learning Research, 2023.   \n[17] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS\u201917, page 1025\u20131035, Red Hook, NY, USA, 2017. Curran Associates Inc.   \n[18] Haoyu Han, Xiaorui Liu, Feng Shi, MohamadAli Torkamani, Charu C. Aggarwal, and Jiliang Tang. Towards label position bias in graph neural networks. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[19] Xiaotian Han, Kaixiong Zhou, Ting-Hsiang Wang, Jundong Li, Fei Wang, and Na Zou. Marginal nodes matter: Towards structure fairness in graphs, 2023.   \n[20] Van Thuy Hoang and O-Joun Lee. Mitigating degree biases in message passing mechanism by utilizing community structures, 2023.   \n[21] Mingxuan Ju, Tong Zhao, Wenhao Yu, Neil Shah, and Yanfang Ye. Graphpatcher: Mitigating degree bias for graph neural networks via test-time augmentation. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[22] Jian Kang, Yan Zhu, Yinglong Xia, Jiebo Luo, and Hanghang Tong. Rawlsgcn: Towards rawlsian difference principle on graph convolutional network. In Proceedings of the ACM Web Conference 2022, WWW \u201922, page 1214\u20131225, New York, NY, USA, 2022. Association for Computing Machinery.   \n[23] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014.   \n[24] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations, 2017.   \n[25] Peizhao Li, Yifei Wang, Han Zhao, Pengyu Hong, and Hongfu Liu. On dyadic fairness: Exploring and mitigating bias in graph connections. In International Conference on Learning Representations, 2021.   \n[26] Ting Wei Li, Qiaozhu Mei, and Jiaqi Ma. A metadata-driven approach to understand graph neural networks. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[27] Xueqi Li, Guoqing Xiao, Yuedan Chen, Zhuo Tang, Wenjun Jiang, and Kenli Li. An explicitly weighted gcn aggregator based on temporal and popularity features for recommendation. ACM Trans. Recomm. Syst., 1(2), apr 2023.   \n[28] Langzhang Liang, Zenglin Xu, Zixing Song, Irwin King, Yuan Qi, and Jieping Ye. Tackling long-tailed distribution issue in graph neural networks via normalization. IEEE Transactions on Knowledge and Data Engineering, pages 1\u201311, 2023.   \n[29] Jie Liao, Jintang Li, Liang Chen, Bingzhe Wu, Yatao Bian, and Zibin Zheng. Sailor: Structural augmentation based tail node representation learning. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, CIKM \u201923, page 1389\u20131399, New York, NY, USA, 2023. Association for Computing Machinery.   \n[30] Ningyi Liao, Haoyu Liu, Zulun Zhu, Siqiang Luo, and Laks V. S. Lakshmanan. Benchmarking spectral graph neural networks: A comprehensive study on effectiveness and efficiency, 2024.   \n[31] Songtao Liu, Rex Ying, Hanze Dong, Lanqing Li, Tingyang Xu, Yu Rong, Peilin Zhao, Junzhou Huang, and Dinghao Wu. Local augmentation for graph neural networks. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 14054\u201314072. PMLR, 17\u201323 Jul 2022.   \n[32] Yazheng Liu, Xi Zhang, and Sihong Xie. Trade less accuracy for fairness and trade-off explanation for gnn. In 2022 IEEE International Conference on Big Data (Big Data), pages 4681\u20134690, 2022.   \n[33] Zemin Liu, Yuan Fang, Wentao Zhang, Xinming Zhang, and Steven C.H. Hoi. Locality-aware tail node embeddings on homogeneous and heterogeneous networks. IEEE Transactions on Knowledge and Data Engineering, pages 1\u201316, 2023.   \n[34] Zemin Liu, Trung-Kien Nguyen, and Yuan Fang. Tail-gnn: Tail-node graph neural networks. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, KDD \u201921, page 1109\u20131119, New York, NY, USA, 2021. Association for Computing Machinery.   \n[35] Zemin Liu, Trung-Kien Nguyen, and Yuan Fang. On generalized degree fairness in graph neural networks. In Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence, AAAI\u201923/IAAI\u201923/EAAI\u201923. AAAI Press, 2023.   \n[36] L. Lova\u00b4sz. Random walks on graphs: A survey. In D. Miklo\u00b4s, V. T. S\u00b4os, and T. Szo\u02ddnyi, editors, Combinatorics, Paul Erd\u02ddos is Eighty, volume 2, pages 353\u2013398. J\u00b4anos Bolyai Mathematical Society, Budapest, 1996.   \n[37] Sitao Luan, Chenqing Hua, Qincheng Lu, Jiaqi Zhu, Mingde Zhao, Shuyuan Zhang, XiaoWen Chang, and Doina Precup. Revisiting heterophily for graph neural networks. Advances in neural information processing systems, 35:1362\u20131375, 2022.   \n[38] Sitao Luan, Chenqing Hua, Minkai Xu, Qincheng Lu, Jiaqi Zhu, Xiao-Wen Chang, Jie Fu, Jure Leskovec, and Doina Precup. When do graph neural networks help with node classification? investigating the homophily principle on node distinguishability. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[39] Yao Ma, Xiaorui Liu, Neil Shah, and Jiliang Tang. Is homophily a necessity for graph neural networks? In International Conference on Learning Representations, 2022.   \n[40] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Ko\u00a8pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance Deep Learning Library. Curran Associates Inc., Red Hook, NY, USA, 2019.   \n[41] Benedek Rozemberczki, Carl Allen, and Rik Sarkar. Multi-Scale attributed node embedding. Journal of Complex Networks, 9(2):cnab014, 05 2021.   \n[42] Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Gu\u00a8nnemann. Pitfalls of graph neural network evaluation. ArXiv, abs/1811.05868, 2018.   \n[43] Harry Shomer, Wei Jin, Wentao Wang, and Jiliang Tang. Toward degree bias in embeddingbased knowledge graph completion. In Proceedings of the ACM Web Conference 2023, WWW \u201923, page 705\u2013715, New York, NY, USA, 2023. Association for Computing Machinery.   \n[44] Arjun Subramonian, Levent Sagun, and Yizhou Sun. Networked inequality: Preferential attachment bias in graph neural network link prediction. In NeurIPS 2023 Workshop: New Frontiers in Graph Learning, 2023.   \n[45] Xianfeng Tang, Huaxiu Yao, Yiwei Sun, Yiqi Wang, Jiliang Tang, Charu Aggarwal, Prasenjit Mitra, and Suhang Wang. Investigating and mitigating degree-related biases in graph convoltuional networks. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management, CIKM \u201920, page 1435\u20131444, New York, NY, USA, 2020. Association for Computing Machinery.   \n[46] Petar Velic\u02c7kovic\u00b4, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio\\`, and Yoshua Bengio. Graph attention networks. In International Conference on Learning Representations, 2018.   \n[47] Srinivas Virinchi and Anoop Saladi. Blade: Biased neighborhood sampling based graph neural network for directed graphs. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, WSDM \u201923, page 42\u201350, New York, NY, USA, 2023. Association for Computing Machinery.   \n[48] Junfu Wang, Yuanfang Guo, Liang Yang, and Yunhong Wang. Understanding heterophily for graph neural networks. In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, editors, Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 50489\u201350529. PMLR, 21\u201327 Jul 2024.   \n[49] Ruijia Wang, Xiao Wang, Chuan Shi, and Le Song. Uncovering the structural fairness in graph contrastive learning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.   \n[50] Chunyu Wei, Jian Liang, Di Liu, Zehui Dai, Mang Li, and Fei Wang. Meta graph learning for long-tail recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD \u201923, page 2512\u20132522, New York, NY, USA, 2023. Association for Computing Machinery.   \n[51] Felix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr. au2, Christopher Fifty, Tao Yu, and Kilian Q. Weinberger. Simplifying graph convolutional networks, 2019.   \n[52] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. Self-supervised graph learning for recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201921, page 726\u2013735, New York, NY, USA, 2021. Association for Computing Machinery.   \n[53] Jun Wu, Jingrui He, and Jiejun Xu. Demo-net: Degree-specific graph neural networks for node and graph classification. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD \u201919, page 406\u2013415, New York, NY, USA, 2019. Association for Computing Machinery.   \n[54] Teng Xiao, Zhengyu Chen, Donglin Wang, and Suhang Wang. Learning how to propagate messages in graph neural networks. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, KDD \u201921, page 1894\u20131903, New York, NY, USA, 2021. Association for Computing Machinery.   \n[55] Hui Xu, Liyao Xiang, Femke Huang, Yuting Weng, Ruijie Xu, Xinbing Wang, and Chenghu Zhou. Grace: Graph self-distillation and completion to mitigate degree-related biases. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD \u201923, page 2813\u20132824, New York, NY, USA, 2023. Association for Computing Machinery.   \n[56] Jianan Xu, Jiajin Huang, Jianwei Zhao, and Jian Yang. Hyncf: A hybrid normalization strategy via feature statistics for collaborative filtering. Expert Systems with Applications, 238:121875, 2024.   \n[57] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations, 2019.   \n[58] Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. Representation learning on graphs with jumping knowledge networks. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 5453\u2013 5462. PMLR, 10\u201315 Jul 2018.   \n[59] Yujun Yan, Milad Hashemi, Kevin Swersky, Yaoqing Yang, and Danai Koutra. Two sides of the same coin: Heterophily and oversmoothing in graph convolutional neural networks. In 2022 IEEE International Conference on Data Mining (ICDM), pages 1287\u20131292, 2022.   \n[60] Sukwon Yun, Kibum Kim, Kanghoon Yoon, and Chanyoung Park. Lte4g: Long-tail experts for graph neural networks. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, CIKM \u201922, page 2434\u20132443, New York, NY, USA, 2022. Association for Computing Machinery.   \n[61] An Zhang, Wenchang Ma, Xiang Wang, and Tat-Seng Chua. Incorporating bias-aware margins into contrastive loss for collaborative filtering. Advances in Neural Information Processing Systems, 35:7866\u20137878, 2022.   \n[62] Guixian Zhang, Debo Cheng, Guan Yuan, and Shichao Zhang. Learning fair representations via rebalancing graph structure. Information Processing & Management, 61(1):103570, 2024.   \n[63] Guixian Zhang, Rongjiao Liang, Zhongyi Yu, and Shichao Zhang. Rumour detection on social media with long-tail strategy. In 2022 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138, 2022.   \n[64] Guixian Zhang, Shichao Zhang, and Guan Yuan. Bayesian graph local extrema convolution with long-tail strategy for misinformation detection. ACM Trans. Knowl. Discov. Data, jan 2024. Just Accepted.   \n[65] Minghao Zhao, Qilin Deng, Kai Wang, Runze Wu, Jianrong Tao, Changjie Fan, Liang Chen, and Peng Cui. Bilateral filtering graph convolutional network for multi-relational social recommendation in the power-law networks. ACM Trans. Inf. Syst., 40(2), sep 2021.   \n[66] Mingxia Zhao and Adele Lu Jia. Dahgn: Degree-aware heterogeneous graph neural network. Knowledge-Based Systems, 285:111355, 2024.   \n[67] Jiangqiang Zhu, Kai Li, Jinjia Peng, and Jing Qi. Self-supervised graph attention collaborative filtering for recommendation. Electronics, 12(4), 2023.   \n[68] Markus Zopf. 1-wl expressiveness is (almost) all you need. In 2022 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138. IEEE, 2022. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A Overview of Hypotheses for, Theoretical Analyses of, and Proposed Solutions to De  \ngree Bias 18   \nA.1 Hypotheses for Degree Bias . . . . 18   \nA.2 Theoretical Analyses of Degree Bias . . . 19   \nA.3 Proposed Solutions to Degree Bias . . . . . 19   \nA.4 Degree Bias from the Perspectives of Homophily and Topology . . 20   \nB Proofs 21   \nB.1 Theorem 21   \nB.2 Theorem 22   \nB.3 Theorem 3 23   \nB.4 Lemma 1 24   \nB.5 Theorem 4 25   \nB.6 Theorem 5 26 ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "C Datasets 27 ", "page_idx": 16}, {"type": "text", "text": "D Models 28   \nAdditional Degree Bias Plots 29   \nF Additional Visual Summaries of Theoretical Results 31   \nG Additional Inverse Collision Probability Plots 35   \nTraining-Time Degree Bias: Random Walk Graph Filter 37   \nI Achieving Maximum Training Accuracy 38   \nJ Additional Training Loss Plots 39   \nK Connecting Inverse Collision Probability to Node Degree 42   \nL Limitations and Future Directions 43   \nSurvey . . . . 43   \nTheoretical analysis . . . 43   \nEmpirical validation . . . 43   \nPrincipled roadmap . . 43 ", "page_idx": 16}, {"type": "text", "text": "M Broader Impacts 45 ", "page_idx": 16}, {"type": "text", "text": "A Overview of Hypotheses for, Theoretical Analyses of, and Proposed Solutions to Degree Bias ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "A.1 Hypotheses for Degree Bias ", "page_idx": 17}, {"type": "text", "text": "Table 2: Full taxonomy of the hypotheses for the origins of GNN degree bias proposed by papers. ", "page_idx": 17}, {"type": "table", "img_path": "1mAaewThcz/tmp/7fe4a3104540598a3188a8e37b4026738ad9d10be995886fa401d506b15be834.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Table 3: A taxonomy of GNN degree bias papers based on whether they theoretically analyze the origins of degree bias, explicitly linking a node\u2019s degree to its test and training error. ", "page_idx": 18}, {"type": "table", "img_path": "1mAaewThcz/tmp/e77cba64c3b028a874ccce26315a890aaab42d78495ea4b1305e6bb6bad0a600.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "A.3 Proposed Solutions to Degree Bias ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "One line of research has produced neighborhood augmentation strategies. For example, [34] perform feature-adaptive neighborhood translation from high-degree nodes to structurally-limited lowdegree nodes to enhance their representations. [52] generate multiple views of node neighborhoods (e.g., via node and edge dropping) and learn to maximize the similarity of representations of different views, towards improving the robustness of low-degree node representations. [21] patch the ego-graphs of low-degree nodes by generating virtual neighbors. [55] self-distill graphs and complete the neighborhoods of low-degree nodes with more homophilic links. Other methods include: ", "page_idx": 18}, {"type": "text", "text": "\u2022 [67] and [66] generate multiple views of node neighborhoods (e.g., via node and edge dropping) and learn to maximize the similarity of representations of different views, towards improving the robustness of low-degree node representations.   \n\u2022 [49] interpolate additional links for low-degree nodes and purify links for high-degree nodes to balance neighborhood information across nodes with different degrees.   \n\u2022 [31] generate more samples in the local neighborhoods of low-degree nodes, to augment the information in these neighborhoods.   \n\u2022 [63] leverage a Transformer architecture and contrastive learning with augmentations (e.g., via node and edge dropping) to bolster the influence of low-degree nodes during training.   \n\u2022 [43] augment the neighborhoods of low-degree nodes in knowledge graphs with synthetic triples.   \n\u2022 [29] augment the local structure of low-degree nodes by adding homophilic edges.   \n\u2022 [47] generate contextually-dependent neighborhoods based on a node\u2019s degree.   \n\u2022 [50] contribute a meta-learning strategy to generate additional edges for low-degree nodes.   \n\u2022 [11] introduce dummy nodes connected to all the nodes in the graph to improve message passing to low-degree nodes.   \n\u2022 [20] introduce a learnable graph augmentation strategy to connect low-degree nodes via more within-community edges, as well as an improved self-attention mechanism. ", "page_idx": 18}, {"type": "text", "text": "Another line of research has produced algorithms that normalize graph filters or node representations to minimize distributional differences between the representations of nodes with different degrees. [22] propose pre-processing and in-processing approaches that re-normalize the graph filter to be doubly stochastic. [56] calculate node representation statistics via a hybrid strategy and use these statistics to normalize representations. [28] normalize the representations of low-degree and highdegree nodes to have similar distributions. ", "page_idx": 18}, {"type": "text", "text": "A different line of research has produced algorithms that separate the learning process for high and low-degree nodes. [53] embed degree-specific weights and hashing functions within the layers of GNNs that guarantee degree-aware node representations. [45] propose a degree-specific GNN layer, to avoid parameter sharing across nodes with different degrees, and a Bayesian teacher network that generates pseudo-labeled neighbors for low-degree nodes to increase their proximity to labels. [60] learn separate expert models for high and low-degree nodes with class and degree-balanced data subsets, and distill the knowledge of these experts into two student models that are tailored to low and high-degree nodes. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "There exist yet other solutions (e.g., based on adversarial learning, attention) that have been produced. [35] learn debiasing functions that distill and complement the GNN encodings of high and low-degree nodes, respectively. [33] leverage meta-learning to learn to learn representations for low-degree nodes in a locality-aware manner. [18] propose a label proximity score, which they find to be more strongly associated with performance than degree, and learn a new graph structure that reduces discrepancies in label proximity scores across nodes. [64] leverage an attention mechanism to enhance focus on low-degree nodes. Other methods include: ", "page_idx": 19}, {"type": "text", "text": "\u2022 [65] modify the aggregation weights for neighboring node representations according to node degrees.   \n\u2022 [54] learn custom message passing strategies for nodes with different degrees.   \n\u2022 [14] causally determine if low-degree nodes should \u201ctrust\u201d messages from their neighbors.   \n\u2022 [9] learn node representations that are invariant to shifts in local neighborhood distributions.   \n\u2022 [32] optimize the graph\u2019s adjacency matrix to reduce an upper bound on degree bias with a minimal decrease in overall accuracy.   \n\u2022 [8] locate anchor nodes that through the introduction of links with them can improve the representations of low-degree nodes.   \n\u2022 [27] propose a popularity-weighted aggregator for Graph Convolutional Networks.   \n\u2022 [19] leverage hop-aware attentive aggregation to attend differently to information at different distances.   \n\u2022 [6] estimate the effect of influential high-degree nodes on the representations of low-degree nodes and remove this effect after each graph convolution.   \n\u2022 [62] use adversarial learning to boost the influence of low-degree nodes. ", "page_idx": 19}, {"type": "text", "text": "A.4 Degree Bias from the Perspectives of Homophily and Topology ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Prior research has connected degree bias to homophily and graph topology: ", "page_idx": 19}, {"type": "text", "text": "\u2022 [59] provides a complementary perspective on the possible performance issues of GNNs that arise from degree disparities in graphs (e.g., low-degree nodes induce oversmoothing in homophilic graphs, while high-degree nodes induce oversmoothing in heterophilic networks). Oversmoothing is related to prediction homogeneity $(\\sum\\!{}_{l=0}^{L}\\,\\beta_{i,c^{\\prime}}^{(l)})^{2}$ ; for homophilic networks,   \nas the number of layers in a GNN increases (i.e., as oversmoothing occurs), $(\\sum\\!{}_{l=0}^{L}\\,\\beta_{i,c^{\\prime}}^{(l)})^{2}$ gets closer to 0 (i.e., does not increase $R_{i,c^{\\prime}}$ ), thereby not inducing as much degree bias. In contrast, our theoretical analysis demonstrates that degree bias occurs without oversmoothing and is amplified by high local homophily.   \n\u2022 [38] connects node distinguishability to node degree and homophily by analyzing the intra-class vs. inter-class embedding distance. We discuss similar quantities in $\\S4.1$ and $\\S4.2$ . However, with the exception of Section 3.5, [38] considers the CSBM-H model in its theoretical analysis, which has pitfalls (as we discuss in $\\S2$ ). Moreover, unlike our work, [38] does not explicitly link the misclassification error of a node to its degree in a more general data and model setting.   \n\u2022 [48] analyzes the effect of heterophily on GNNs via class separability, which it characterizes through neighborhood distributions and average node degree. Similar to [38], [48] only considers the HSBM model in its theoretical analysis.   \n\u2022 [30] observes that GNN performance is lower for high-degree nodes under heterophily. We likewise observe this in Figure 5 for chameleon and squirrel (which are heterophilic networks). Moreover, our theoretical analysis explains why degree bias is not observed for heterophilic graphs. In $\\S4.2$ , we explain that high-degree nodes in heterophilic networks do not have lower $l$ - hop prediction homogeneity levels due to higher local heterophily; hence, we do not necessarily observe better performance for them compared to low-degree nodes. ", "page_idx": 19}, {"type": "text", "text": "B Proofs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "B.1 Theorem 1 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof. Misclassification occurs when $\\ell(\\mathcal{M}|i,c)>\\ell(\\mathcal{M}|i,c^{\\prime})$ . ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\ell(\\mathcal{M}|i,c)>\\ell(\\mathcal{M}|i,c^{\\prime})\\right)=\\mathbb{P}\\left(-\\log H_{i,c}^{(L)}>-\\log H_{i,c^{\\prime}}^{(L)}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{P}\\left(H_{i,c}^{(L)}<H_{i,c^{\\prime}}^{(L)}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{P}\\left(Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}>0\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "If $\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]<0$ (i.e., $\\mathcal{M}$ generalizes in expectation), by Cantelli\u2019s inequality: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left(\\ell(\\mathcal{M}|i,c)>\\ell(\\mathcal{M}|i,c^{\\prime})\\right)=\\mathbb{P}\\left(\\left(Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right)-\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]>-\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\leq\\frac{1}{1+\\frac{\\left(-\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]\\right)^{2}}{\\mathrm{Var}\\left[Z_{i,c^{\\prime}}^{(L)}-Z_{i,c}^{(L)}\\right]}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We use Cantelli\u2019s inequality, rather than Chebyshev\u2019s inequality, because Cantelli\u2019s inequality is sharper for one-sided bounds. ", "page_idx": 20}, {"type": "text", "text": "B.2 Theorem 2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Proof. Denoting the $l$ -th term in the summation $\\begin{array}{r l r}{{\\pmb T}^{(l)}}&{{}=}&{P_{\\mathrm{rw}}^{l}X{\\pmb W}^{(l)}}\\end{array}$ , $\\begin{array}{r l r}{\\pmb{T}_{i,c}^{(l)}}&{{}=}&{}\\end{array}$ $\\begin{array}{r}{\\sum_{j\\in\\mathcal{V}}\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}X_{j}W_{\\cdot,c}^{(l)}}\\end{array}$ . It follows by the linearity of expectation that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}\\left[T_{i,c^{\\prime}}^{(l)}-T_{i,c}^{(l)}\\right]=\\sum_{j\\in\\mathcal{V}}\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\cdot\\mathbb{E}_{\\pmb{x}\\sim\\mathcal{D}\\mathbf{r}_{j}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]}}\\\\ &{}&{=\\mathbb{E}_{j\\sim\\mathcal{N}^{(l)}(i)}\\left[\\mathbb{E}_{\\pmb{x}\\sim\\mathcal{D}\\mathbf{r}_{j}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]\\right]}\\\\ &{}&{=\\beta_{i,c^{\\prime}}^{(l)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Furthermore, by the linearity of variance: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{Var}\\left[T_{i,c^{\\prime}}^{(l)}-\\mathbf{T}_{i,c}^{(l)}\\right]=\\sum_{j\\in\\mathcal{V}}\\left[\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\right]^{2}\\cdot\\mathrm{Var}_{x\\sim\\mathcal{D}_{\\mathbf{Y}_{j}}}\\left[x^{T}w_{c^{\\prime}-c}^{(l)}\\right]}}\\\\ &{}&{\\leq M\\displaystyle\\sum_{j\\in\\mathcal{V}}\\left[\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\right]^{2}}\\\\ &{}&{=M\\alpha_{i}^{(l)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then, once again by the linearity of expectation and variance: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left(\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(l)}-Z_{i,c}^{(l)}\\right]\\right)^{2}=\\left(\\sum_{l=0}^{L}\\beta_{i,c^{\\prime}}^{(l)}\\right)^{2},}}\\\\ &{}&{\\mathrm{Var}\\left[{\\pmb Z}_{i,c^{\\prime}}^{(l)}-{\\pmb Z}_{i,c}^{(l)}\\right]\\leq M(L+1)\\sum_{l=0}^{L}\\alpha_{i}^{(l)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Consequently: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\frac{\\left(\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(l)}-Z_{i,c}^{(l)}\\right]\\right)^{2}}{\\mathrm{Var}\\left[Z_{i,c^{\\prime}}^{(l)}-Z_{i,c}^{(l)}\\right]}\\ge\\frac{\\left(\\sum_{l=0}^{L}\\beta_{i,c^{\\prime}}^{(l)}\\right)^{2}}{M(L+1)\\sum_{l=0}^{L}\\alpha_{i}^{(l)}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "B.3 Theorem 3 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proof. Re-expressing the $l$ -th term $\\pmb{T}^{(l)}=P_{\\mathrm{sym}}^{l}X\\pmb{W}^{(l)}$ in the summation: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{T_{i,c}^{(l)}=\\displaystyle\\sum_{j\\in\\mathcal{V}}\\left(D^{-\\frac{1}{2}}A D^{-\\frac{1}{2}}\\right)_{i j}^{l}X_{j}W_{\\cdot,c}^{(l)}}\\\\ &{\\qquad=\\displaystyle\\sum_{j\\in\\mathcal{V}}\\left(D^{-1}A\\right)_{i j}^{l}\\cdot\\frac{\\sqrt{D_{i i}}}{\\sqrt{D_{j j}}}X_{j}W_{\\cdot,c}^{(l)}}\\\\ &{\\qquad=\\sqrt{D_{i i}}\\displaystyle\\sum_{j\\in\\mathcal{V}}\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\cdot\\frac{1}{\\sqrt{D_{j j}}}X_{j}W_{\\cdot,c}^{(l)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "It follows by the linearity of expectation that: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[T_{i,c^{\\prime}}^{(l)}-\\pmb{T}_{i,c}^{(l)}\\right]=\\sqrt{D_{i i}}\\displaystyle\\sum_{j\\in\\mathcal{V}}\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\cdot\\frac{1}{\\sqrt{D_{j j}}}\\mathbb{E}_{\\pmb{x}\\sim\\mathcal{D}\\mathbf{r}_{j}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]}\\\\ &{\\phantom{\\sum_{a^{\\prime}}\\pmb{x}}=\\sqrt{D_{i i}}\\mathbb{E}_{j\\sim\\mathcal{N}^{(l)}(i)}\\left[\\displaystyle\\frac{1}{\\sqrt{D_{j j}}}\\mathbb{E}_{\\pmb{x}\\sim\\mathcal{D}\\mathbf{r}_{j}}\\left[\\pmb{x}^{T}\\pmb{w}_{c^{\\prime}-c}^{(l)}\\right]\\right]}\\\\ &{\\phantom{\\sum_{a^{\\prime}}\\pmb{x}}=\\sqrt{D_{i i}}\\tilde{\\beta}_{i,c^{\\prime}}^{(l)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Furthermore, by the linearity of variance: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{Var}\\left[T_{i,c^{\\prime}}^{(l)}-T_{i,c}^{(l)}\\right]=D_{i i}\\sum_{j\\in\\mathcal{V}}\\left[\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\right]^{2}\\cdot\\frac{1}{D_{j j}}\\mathrm{Var}_{x\\sim\\mathcal{D}\\mathbf{r}_{j}}\\left[x^{T}w_{c^{\\prime}-c}^{(l)}\\right]}}\\\\ &{}&{\\leq D_{i i}M\\displaystyle\\sum_{j\\in\\mathcal{V}}\\frac{1}{D_{j j}}\\left[\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\right]^{2}}\\\\ &{}&{=D_{i i}M\\widetilde{\\alpha}_{i}^{(l)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, once again, by the linearity of expectation and variance: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\displaystyle\\left(\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(l)}-Z_{i,c}^{(l)}\\right]\\right)^{2}=D_{i i}\\left(\\sum_{l=0}^{L}\\widetilde{\\beta}_{i,c^{\\prime}}^{(l)}\\right)^{2},\\ ~~}\\\\ &{}&{\\displaystyle\\mathrm{Var}\\left[Z_{i,c^{\\prime}}^{(l)}-Z_{i,c}^{(l)}\\right]\\leq D_{i i}M(L+1)\\sum_{l=0}^{L}\\widetilde{\\alpha}_{i}^{(l)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Consequently: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{\\left(\\mathbb{E}\\left[Z_{i,c^{\\prime}}^{(l)}-Z_{i,c}^{(l)}\\right]\\right)^{2}}{\\mathrm{Var}\\left[Z_{i,c^{\\prime}}^{(l)}-Z_{i,c}^{(l)}\\right]}\\ge\\frac{\\left(\\sum_{l=0}^{L}\\widetilde{\\beta}_{i,c^{\\prime}}^{(l)}\\right)^{2}}{M(L+1)\\sum_{l=0}^{L}\\widetilde{\\alpha}_{i}^{(l)}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "B.4 Lemma 1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Proof. Define $g(Z_{i}^{(L)}[t])=\\nabla_{Z_{i}^{(L)}[t]}\\ell[t](\\mathcal{M}|i,c)$ . For simplicity of notation, let ${\\pmb x}={\\pmb Z}_{i}^{(L)}[t]$ . It is sufficient to show that $\\|g({\\pmb x})\\|_{2}\\leq\\lambda$ . By simple derivation, $\\begin{array}{r}{\\left(g(\\pmb{x})\\right)_{i}\\,=\\,-\\frac{\\sum_{a\\neq i}e^{\\pmb{x}_{a}}}{\\sum_{b}e^{\\pmb{x}_{b}}}}\\end{array}$ a\u0338b= ie xb , and for j \u0338= i, $\\begin{array}{r}{\\left(g(\\mathbf{x})\\right)_{j}=-\\frac{e^{\\mathbf{x}_{j}}}{\\sum_{b}e^{\\mathbf{x}_{b}}}}\\end{array}$ . Then, by Ho\u00a8lder\u2019s inequality: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\|g(\\pmb{x})\\|_{2}^{2}=\\frac{\\left(\\sum_{a\\neq i}e^{\\pmb{x}_{a}}\\right)^{2}+\\sum_{a\\neq i}{(e^{\\pmb{x}_{a}})^{2}}}{(\\sum_{b}e^{\\pmb{x}_{b}})^{2}}}}\\\\ &{}&{\\leq\\frac{2\\,\\left(\\sum_{a\\neq i}e^{\\pmb{x}_{a}}\\right)^{2}}{\\left(\\sum_{b}e^{\\pmb{x}_{b}}\\right)^{2}}\\leq2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Thus, $\\lambda=\\sqrt{2}$ . ", "page_idx": 23}, {"type": "text", "text": "B.5 Theorem 4 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Proof. By the Lipschitz continuity of $\\ell[t]({\\overline{{\\mathbf{SYM}}}}|i,c)$ (Lemma 1) and the triangle inequality: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\ell[t+1](\\overline{{\\mathbf{SYM}}}|i,c)-\\ell[t](\\overline{{\\mathbf{SYM}}}|i,c)\\right|\\leq\\lambda\\left\\|Z_{i}^{(L)}[t+1]-Z_{i}^{(L)}[t]\\right\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\lambda\\displaystyle\\sum_{l=0}^{L}\\left\\|\\left(P_{\\mathrm{sym}}^{l}X\\right)_{i}\\left(W^{(l)}[t+1]-W^{(l)}[t]\\right)\\right\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\lambda\\eta\\displaystyle\\sum_{l=0}^{L}\\left\\|\\left(P_{\\mathrm{sym}}^{l}X\\right)_{i}\\frac{\\partial\\ell[t]}{\\partial W^{(l)}[t]}(B[t])\\right\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By simple derivation, we see that $\\begin{array}{r}{\\frac{\\partial\\ell[t]}{\\partial{\\bf W}^{(l)}[t]}(B[t])\\,=\\,\\bigl(P_{\\mathrm{sym}}^{l}[t]X\\bigr)^{T}\\,\\epsilon[t]}\\end{array}$ , where $P_{\\mathrm{sym}}^{l}[t]\\,\\in\\,\\mathbb{R}^{|B[t]|\\,\\times\\,N}$ is the submatrix formed from the rows of $P_{\\mathrm{sym}}^{l}$ that correspond to the nodes in $B[t]$ . Then, by the sub-multiplicativity of the $L_{2}$ norm: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\ell[t+1](\\overline{{\\mathbf{SYM}}}|i,c)-\\ell[t](\\overline{{\\mathbf{SYM}}}|i,c)\\right|\\leq\\lambda\\eta\\sum_{l=0}^{L}\\left\\|\\left(P_{\\mathrm{sym}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{sym}}^{l}[t]\\right)^{T}\\epsilon[t]\\right\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\lambda\\eta\\left\\|\\epsilon[t]\\right\\|_{F}\\sum_{l=0}^{L}\\left\\|\\left(P_{\\mathrm{sym}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{sym}}^{l}[t]\\right)^{T}\\right\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Similarly to the proof of Theorem 3: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(P_{\\mathrm{sym}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{sym}}^{l}\\right)_{m}^{T}=\\displaystyle\\sum_{j\\in\\mathcal{V}}\\left(P_{\\mathrm{sym}}^{l}\\right)_{i j}\\sum_{k\\in\\mathcal{V}}\\left(P_{\\mathrm{sym}}^{l}\\right)_{m k}\\left(X X^{T}\\right)_{j k}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\sqrt{D_{i i}D_{m m}}\\mathbb{E}_{j\\sim N^{(l)}(i),k\\sim N^{(l)}(m)}\\left[\\frac{1}{\\sqrt{D_{j j}D_{k k}}}\\left(X X^{T}\\right)_{j k}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Hence, $\\left\\|\\left(P_{\\mathrm{sym}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{sym}}^{l}[t]\\right)^{T}\\right\\|_{2}=\\sqrt{D_{i i}}\\cdot\\left\\|\\widetilde{\\chi}_{i}^{(l)}[t]\\right\\|_{2}$ , and: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\left|\\ell[t+1](\\overline{{\\mathrm{SYM}}}|i,c)-\\ell[t](\\overline{{\\mathrm{SYM}}}|i,c)\\right|\\leq\\sqrt{D_{i i}}\\cdot\\lambda\\eta\\left\\|\\epsilon[t]\\right\\|_{F}\\sum_{l=0}^{L}\\left\\|\\widetilde{\\chi}_{i}^{(l)}[t]\\right\\|_{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "B.6 Theorem 5 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Proof. By the Lipschitz continuity of $\\ell[t](\\overline{{\\mathbf{RW}}}|i,c)$ (Lemma 1) and the triangle inequality: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\big|\\ell[t+1](\\overline{{\\mathbf{R}\\mathbf{W}}}|i,c)-\\ell[t](\\overline{{\\mathbf{R}\\mathbf{W}}}|i,c)\\big|\\leq\\lambda\\,\\Big\\|Z_{i}^{(L)}[t+1]-Z_{i}^{(L)}[t]\\Big\\|_{2}}\\\\ &{\\displaystyle\\leq\\lambda\\sum_{l=0}^{L}\\Big\\|\\big(P_{\\mathrm{rw}}^{l}X\\big)_{i}\\left(W^{(l)}[t+1]-W^{(l)}[t]\\right)\\Big\\|_{2}}\\\\ &{\\displaystyle=\\lambda\\eta\\sum_{l=0}^{L}\\Big\\|\\big(P_{\\mathrm{rw}}^{l}X\\big)_{i}\\,\\frac{\\partial\\ell[t]}{\\partial W^{(l)}[t]}(B[t])\\Big\\|_{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By simple derivation, we see that $\\begin{array}{r}{\\frac{\\partial\\ell[t]}{\\partial\\pmb{W}^{(l)}[t]}(\\pmb{B}[t])\\,=\\,\\left(\\pmb{P}_{\\mathrm{rw}}^{l}[t]\\pmb{X}\\right)^{T}\\epsilon[t]}\\end{array}$ , where $P_{\\mathrm{rw}}^{l}[t]\\;\\in\\;\\mathbb{R}^{|B[t]|\\,\\times\\,N}$ is the submatrix formed from the rows of $P_{\\mathrm{rw}}^{l}$ that correspond to the nodes in $B[t]$ . Then, by the sub-multiplicativity of the $L_{2}$ norm: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\ell[t+1](\\overline{{\\mathbf{R}\\mathbf{W}}}|i,c)-\\ell[t](\\overline{{\\mathbf{R}\\mathbf{W}}}|i,c)\\right|\\leq\\lambda\\eta\\sum_{l=0}^{L}\\left\\|\\left(P_{\\mathrm{rw}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{rw}}^{l}[t]\\right)^{T}\\epsilon[t]\\right\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\lambda\\eta\\left\\|\\epsilon[t]\\right\\|_{F}\\sum_{l=0}^{L}\\left\\|\\left(P_{\\mathrm{rw}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{rw}}^{l}[t]\\right)^{T}\\right\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Similarly to the proof of Theorem 2: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left(P_{\\mathrm{rw}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{rw}}^{l}\\right)_{m}^{T}=\\displaystyle\\sum_{j\\in\\mathcal{V}}\\left(P_{\\mathrm{rw}}^{l}\\right)_{i j}\\sum_{k\\in\\mathcal{V}}\\left(P_{\\mathrm{rw}}^{l}\\right)_{m k}\\left(X X^{T}\\right)_{j k}}\\\\ {=\\mathbb{E}_{j\\sim\\mathcal{N}^{(l)}(i),k\\sim\\mathcal{N}^{(l)}(m)}\\left[\\left(X X^{T}\\right)_{j k}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Hence, $\\left\\|\\left(P_{\\mathrm{rw}}^{l}\\right)_{i}X X^{T}\\left(P_{\\mathrm{rw}}^{l}[t]\\right)^{T}\\right\\|_{2}=\\left\\|\\chi_{i}^{(l)}[t]\\right\\|_{2}$ , and: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\left|\\ell[t+1](\\overline{{\\mathbf{RW}}}|i,c)-\\ell[t](\\overline{{\\mathbf{RW}}}|i,c)\\right|\\leq\\lambda\\eta\\left\\|\\epsilon[t]\\right\\|_{F}\\sum_{l=0}^{L}\\left\\|\\chi_{i}^{(l)}[t]\\right\\|_{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "In our experiments, we use 8 real-world network datasets from [4], [42], and [41], covering diverse domains (e.g., citation networks, collaboration networks, online product networks, Wikipedia networks). We provide a description and statistics of each dataset in Table 4. All the datasets have node features and are undirected. For each node, we normalize its features to sum to 1, following [15]1. We were unable to find the exact class names and their label correspondence from the dataset documentation. ", "page_idx": 26}, {"type": "text", "text": "\u2022 In all the citation network datasets, nodes represent documents, edges represent citation links, and features are a binary bag-of-words representation of documents. The classification task is to predict the topic of documents.   \n\u2022 In the collaboration network datasets, nodes represent authors, edges represent coauthorships, and features are a binary bag-of-word representation of keywords from the authors\u2019 papers. The classification task is to predict the most active field of study for authors.   \n\u2022 In the online product network datasets, nodes represent products, edges represent that two products are often purchased together, and features are a binary bag-of-word representation of product reviews. The classification task is to predict the category of products.   \n\u2022 In the Wikipedia network datasets, nodes represent Wikipedia websites, edges represent hyperlinks between them, and features are a binary bag-of-word representation of informative nouns from the pages. The classification task is to predict the level of average daily traffic for pages. ", "page_idx": 26}, {"type": "text", "text": "We use PyTorch and PyTorch Geometric to load and process all datasets [40, 15]. Our usage of these libraries and datasets complies with their license. PyTorch and PyTorch Geometric are available under a torch-specific license2 and MIT license3, respectively. Cora ML and CiteSeer are available under an MIT License4 and can be found here: https://github.com/ abojchevski/graph2gauss/tree/master/data. CS, Physics, Amazon Photo, and Amazon Computers are available under an MIT License5 and can be found here: https://github.com/ shchur/gnn-benchmark/tree/master/data/npz. chameleon and squirrel are available under a GLP-3.0 license6 and can be found here: https://graphmining.ai/datasets/ptg/wiki. ", "page_idx": 26}, {"type": "text", "text": "While these datasets are widely used, we did not obtain explicit consent from any data subjects whose data the datasets may contain. To the best of our knowledge (via manual sampling and inspection), the datasets do not contain any personally identifiable information or offensive content. ", "page_idx": 26}, {"type": "table", "img_path": "1mAaewThcz/tmp/d34542195c248c4a8af8a8bcfd34de3111f0f9af8c3517c238d1fb9e6b89e68c.jpg", "table_caption": ["Table 4: Summary of the datasets used in our experiments. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "D Models ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In our experiments, we transductively learn and compute node representations using encoders based on Graph Convolutional Networks (GCNs) [24], GraphSAGE [17], and Graph Attention Networks (GATs) [46]. ", "page_idx": 27}, {"type": "text", "text": "In all cases, we use general message-passing GNNs $\\mathcal{M}$ [16], which include separate parameters for source and target nodes and residual connections; in particular, for layer $l$ : ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{H}^{(l)}=\\sigma^{(l)}\\left(\\pmb{Z}^{(l)}\\right)=\\sigma^{(l)}\\left(\\pmb{H}^{(l-1)}\\pmb{W}_{1}^{(l)}+\\pmb{P}^{(l)}\\pmb{H}^{(l-1)}\\pmb{W}_{2}^{(l)}+\\pmb{X}\\pmb{W}_{3}^{(l)}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where H(l) \u2208RN\u00d7d(l) are the $l$ -th layer node representations (with $H^{(0)}\\,=\\,X$ and $d^{(L)}=C_{\\l}$ , $\\sigma^{(l)}$ is an instance-wise non-linearity (with $\\sigma^{(L)}$ being softmax), $P^{(l)}\\in\\mathbb{R}^{N\\times N}$ is a graph filter, and $W_{1}^{(l)},W_{2}^{(l)},W_{3}^{(l)}\\in\\mathbb{R}^{d^{(l-1)}\\times d^{(l)}}$ are the $l$ -th layer model parameters. ", "page_idx": 27}, {"type": "text", "text": "We consider the following special cases of $\\mathcal{M}$ which vary with respect to their graph filter: ", "page_idx": 27}, {"type": "text", "text": "\u2022 RW: $\\forall l\\in\\mathbb{N}_{\\leq L},P^{(l)}=P_{\\mathrm{rw}}=D^{-1}A$ (i.e., the uniform random walk transition matrix), where $_{D}$ is the diagonal degree matrix with entries $\\begin{array}{r}{D_{i i}=\\sum_{j\\in\\gamma}A_{i j}}\\end{array}$ .   \n\u2022 SYM: $\\forall l\\in\\mathbb{N}_{\\leq L},P^{(l)}=P_{\\mathrm{sym}}=D^{-\\frac{1}{2}}A D^{-\\frac{1}{2}}.$ .   \n\u2022 ATT: $\\forall l\\in\\mathbb{N}_{\\leq L},P^{(l)}$ is a graph attentional operator with default hyperparameters and a single head [46]. ", "page_idx": 27}, {"type": "text", "text": "Each encoder has three layers (64-dimensional hidden layers), with a ReLU nonlinearity in between layers. We do not use any regularization (e.g., Dropout, BatchNorm). The encoders are explicitly trained for node classification with the cross-entropy loss and the Adam optimizer [23] with fullbatch gradient descent on the training set. We use a learning rate of 5e-3. We further use a random node split of 1000-500-rest for test-val-train. We train all encoders until they reach the training accuracy of $\\mathbf{MAJ}_{\\mathrm{WL}}$ and select the model parameters with the highest validation accuracy. Although we do not do any hyperparameter tuning, the test accuracy values indicate that the encoders are welltrained. ", "page_idx": 27}, {"type": "text", "text": "We use PyTorch [40] and PyTorch Geometric $[15]^{7}$ to train all the encoders on a single NVIDIA GeForce GTX Titan Xp Graphic Card with 12196MiB of space on an internal cluster. On average (with respect to the datasets), the median time per training epoch was 0.05 seconds. Thus, the estimated total compute is: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{0.05\\mathrm{~(approximate~number~of~seconds~per~epoch)}}\\\\ &{\\times\\ 500\\mathrm{~(number~of~epochs~per~training~run)}}\\\\ &{\\times\\ 10\\mathrm{~(number~of~training~runs/random~seeds~per~model)}}\\\\ &{\\times\\ 3\\mathrm{~(number~of~models~per~dataset)}}\\\\ &{\\times\\ 8\\mathrm{~(number~of~datasets)}}\\\\ &{\\times\\ 12196\\mathrm{~MiB~(GPU~memory)}}\\\\ &{=73,176\\mathrm{kMiB~}\\times\\mathrm{seconds}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "(60) (61) (62) (63) (64) (65) ", "page_idx": 27}, {"type": "text", "text": "These experiments were run a few times (e.g., due to the discovery of bugs), but the full research project did not involve other experiments not reported in the paper. We used a single CPU worker to load datasets and plot results. The datasets take up $0.2975\\,\\mathrm{MB}$ of disk space. ", "page_idx": 27}, {"type": "text", "text": "E Additional Degree Bias Plots ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Unlike the other datasets, we do not observe degree bias for chameleon and squirrel because these datasets are heterophilic. We intentionally include these datasets to draw contrast to the other, homophilic datasets and validate our theory. For example, in $\\S4.2$ , we explain that high-degree nodes in heterophilic networks do not have more negative $l$ -hop prediction homogeneity levels due to higher local heterophily levels; hence, we do not necessarily observe better performance for them compared to low-degree nodes. ", "page_idx": 28}, {"type": "image", "img_path": "1mAaewThcz/tmp/8f9cbe07997e6ec1bbdad45369b2bc020162cbcb402b11e023b8290e258c5c13.jpg", "img_caption": ["Figure 4: Test loss vs. degree of nodes in citation and collaboration network datasets for RW, SYM, and ATT GNNs. High-degree nodes generally incur a lower test loss than low-degree nodes do. Error bars are reported over 10 random seeds; all error bars are 1-sigma and represent the standard deviation about the mean. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "1mAaewThcz/tmp/559e15eb3ae450048a82b256d38fe1a5bc36b96fdd006a2e7e1e9957bd2c79b8.jpg", "img_caption": ["Figure 5: Test loss vs. degree of nodes in online product and Wikipedia network datasets for RW, SYM, and ATT GNNs. High-degree nodes generally incur a lower test loss than low-degree nodes do. Error bars are reported over 10 random seeds; all error bars are 1-sigma and represent the standard deviation about the mean. "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "F Additional Visual Summaries of Theoretical Results ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In the plots below, we consider low-degree nodes to be the 100 nodes with the smallest degrees and high-degree nodes to be the 100 nodes with the largest degrees. Each point in the plots in the left column corresponds to a test node representation and its color represents the node\u2019s class. The plots in the left column are based on a single random seed, while the plots in the middle and right columns are based on 10 random seeds. RW representations of low-degree nodes often have a larger variance than high-degree node representations, while SYM representations of low-degree nodes often have a smaller variance. Furthermore, SYM generally adjusts its training loss on low-degree nodes less rapidly. ", "page_idx": 30}, {"type": "text", "text": "The training loss curves in Figure 6 still support our theoretical analysis. Theorem 4 reveals that for $\\overline{{S Y M}}$ , node degree and the (degree-discounted) expected feature similarity $\\widetilde{\\chi}_{i}$ affects the rate of learning. On the other hand, Theorem 5 indicates that for $\\overline{{R W}}$ , while we do not expect node degree to impact the rate of learning, the expected feature similarity $\\chi_{i}$ is still influential. Hence, interpreting Theorems 4 and 5 jointly, we expect and accordingly observe that the orange curve for SYM has a steeper rate of decrease relative to the orange curve for RW as the number of epochs increases. ", "page_idx": 30}, {"type": "image", "img_path": "1mAaewThcz/tmp/0ea96bf5bb43b87d01914087048db7803f1e773392e68a8951651e0cd95d56e9.jpg", "img_caption": ["Figure 6: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on Cora ML. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "1mAaewThcz/tmp/95794e303e57888d8c1b148279926df4d4f6cd71c7954eaaaaeb80d66be2b818.jpg", "img_caption": ["Figure 7: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on CS. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "1mAaewThcz/tmp/83692416f5e31779ba8510369b76ea0825cc938aa51006395f783887734f67c4.jpg", "img_caption": ["Figure 8: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on Physics. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "1mAaewThcz/tmp/7f983c08809eb9be83e928430ae2fec372e9505c06906d46a0a41f35e2b83a5c.jpg", "img_caption": ["Figure 9: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on Amazon Photo. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "1mAaewThcz/tmp/6575fb4fefadfce498ef031690f2b6bac744efe20986e50f570c62831494bb95.jpg", "img_caption": ["Figure 10: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on Amazon Computers. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "1mAaewThcz/tmp/03924fc1faac18348d9f6e2a05a0bcba48bde50257c9d2ad792592276cb714e0.jpg", "img_caption": ["Figure 11: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on chameleon. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "1mAaewThcz/tmp/c2a012d4af07ae4d228c701fe65411d0bdb83598677b7b146211b6641df1cc99.jpg", "img_caption": ["Figure 12: Visual summary of the geometry of representations, variance of representations, and training dynamics of RW, SYM, and ATT GNNs on chameleon. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "1mAaewThcz/tmp/bbe0878619d971249339c85dbc0e105227e5a89ca4caa8bebac7c4d336d40cc6.jpg", "img_caption": ["G Additional Inverse Collision Probability Plots ", "Figure 13: Inverse collision probability vs. degree of nodes in citation and collaboration network datasets for RW, SYM, and ATT GNNs. Node degrees generally have a strong association with inverse collision probabilities. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "1mAaewThcz/tmp/785ba3e637271f64fd7e2929dfb1fc606abe9160b8a2cfd995a7db4c33efc60f.jpg", "img_caption": ["Figure 14: Inverse collision probability vs. degree of nodes in citation and collaboration network datasets for RW, SYM, and ATT GNNs. Node degrees generally have a strong association with inverse collision probabilities. "], "img_footnote": [], "page_idx": 35}, {"type": "text", "text": "H Training-Time Degree Bias: Random Walk Graph Filter ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "We now demonstrate that during each step of training $\\overline{{\\mathrm{RW}}}$ with gradient descent, compared to $\\overline{{\\cal S}}\\overline{{\\sf Y M}}$ , the loss of low-degree nodes in $S$ is not necessarily adjusted more slowly. We define $\\forall l\\;\\in\\;\\mathbb{N}_{\\leq L},\\chi_{i}^{(l)}\\;\\in\\;\\mathbb{R}^{|B[t]|}$ , where for $m\\;\\in\\;B[t],\\left(\\chi_{i}^{(l)}[t]\\right)_{m}\\;=\\;\\mathbb{E}_{j\\sim\\mathcal{N}^{(l)}(i),k\\sim\\mathcal{N}^{(l)}(m)}\\left[X_{j}X_{k}^{T}\\right].$ . In effect, $\\left(\\chi_{i}^{(l)}[t]\\right)_{m}$ captures the expected similarity between the raw features of nodes $j$ and $k$ with respect to the $l$ -hop random walk distributions of $i\\in\\mathcal{V}$ and $m\\in B[t]$ . ", "page_idx": 36}, {"type": "text", "text": "Theorem 5. The change in loss for $i$ after an arbitrary training step t obeys: ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\left|\\ell[t+1](\\overline{{R W}}|i,c)-\\ell[t](\\overline{{R W}}|i,c)\\right|\\leq\\sqrt{2}\\eta\\left\\|\\epsilon[t]\\right\\|_{F}\\sum_{l=0}^{L}\\left\\|\\chi_{i}^{(l)}[t]\\right\\|_{2}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "For $\\overline{{\\mathbf{RW}}}$ , the change (either increase or decrease) in loss for $i$ after an arbitrary training step does not necessarily have a smaller magnitude if $i$ is low-degree. However, the $L$ -hop neighborhoods of low-degree nodes still often have less overlap with the neighborhoods of training nodes, which can constrain the rate at which the loss for $i$ changes. We confirm these findings empirically in Figure 2 and $\\S\\mathrm{F}$ . For all the datasets, the blue curve for RW has a less steep rate of decrease than the blue curve for SYM as the number of epochs increases. However, for RW itself, the orange curve generally descends more quickly than the blue curve, with the exception of the heterophilic chameleon and squirrel datasets, for which the features of nodes in the neighborhoods of highdegree nodes and training nodes are dissimilar. Therefore, models do not learn more rapidly for high-degree nodes under heterophily. These findings support hypothesis $\\left(\\mathbf{H}2\\right)$ . Our results for $\\overline{{\\mathbf{RW}}}$ may also apply to ATT when low-degree nodes are generally attended to less. ", "page_idx": 36}, {"type": "text", "text": "I Achieving Maximum Training Accuracy ", "text_level": 1, "page_idx": 37}, {"type": "image", "img_path": "1mAaewThcz/tmp/e5351d9270ef48f0340449406955abe58973d0bf0a9c017d8ab48dbf444e11db.jpg", "img_caption": ["Figure 15: Mean absolute parameter gradient vs. training epoch for RW, SYM, and ATT GNNs on CiteSeer (over 10 random seeds). The training accuracy of SYM, RW, and ATT ultimately reach the accuracy of $\\mathbf{MAJ}_{\\mathrm{WL}}$ . "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "We now empirically show that SYM (despite learning at different rates for low vs. high-degree nodes), RW, and ATT can achieve their maximum possible training accuracy (i.e., the accuracy of a majority voting-classifier $\\mathbf{MAJ}_{\\mathrm{WL}}$ ). Furthermore, per our experiments, the accuracy of $\\mathbf{MAJ}_{\\mathrm{WL}}$ is often close to $100\\%$ , indicating that the WL test does not significantly limit the accuracy of SYM, RW, and ATT in practice. ", "page_idx": 37}, {"type": "text", "text": "Per [57], because the expressive power of SYM, RW, and ATT are limited by the WL test, an upper bound on their training accuracy is the accuracy of a majority voting-classifier $\\mathbf{MAJ}_{\\mathrm{WL}}$ applied to WL node colorings (for details on how to compute colorings, see $\\S\\mathrm{II.A}$ and $\\S\\mathrm{VI}.\\mathrm{B}$ of [68]). In particular, if the WL test produces the colors $\\bar{\\mathbf{c}}\\,\\in\\,\\mathbb{K}^{|S|}$ for nodes in $S$ , MAJWL predicts node $i$ to have the label $\\widehat{Y}_{i}\\;=\\;\\mathrm{MAJ}_{\\mathrm{WL}}(i,X,A)\\;=\\;\\mathrm{mode}\\{Y_{j}|j\\;\\in\\;\\mathcal{V},c_{j}\\;=\\;c_{i}\\}$ . However, Figure 15 and $\\S\\mathrm{J}$ reveal that as the number of training epochs increases, the training accuracy of SYM, RW, and ATT reach the accuracy of $\\mathbf{MAJ}_{\\mathrm{WL}}$ . Because the accuracy of $\\mathbf{MAJ}_{\\mathrm{WL}}$ is often close to $100\\%$ , our experiments suggest that insufficient expressive power likely does not contribute to degree bias, drawing doubt to hypothesis (H7). ", "page_idx": 37}, {"type": "text", "text": "Empirically inspecting the model gradients, compared to ATT, as the number of training epochs increases, the mean absolute gradients of SYM and RW are comparably small but often decrease more slowly or fluctuate. To understand this, we can analytically inspect the gradients of RW: ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\frac{\\partial\\ell[t]}{\\partial W^{(l)}[t]}(B[t])=X^{T}\\left(\\pmb{P}_{\\mathrm{rw}}^{l}[t]\\right)^{T}\\epsilon[t].\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "$\\left(P_{\\mathrm{rw}}^{l}[t]\\right)^{T}$ (for $l\\ \\geq\\ 0;$ ) often has numerous eigenvalues around 0, which can yield gradients \u2202W\u2202\u2113 ([lt)][t](B[t]) with a small magnitude even when \u2225\u03f5[t]\u2225is not small. The same analysis holds for $\\overline{{\\mathrm{SYM}}}$ . As such, SYM and RW may get trapped in suboptimal minima during training, yielding slower or unstable convergence; in contrast, because ATT has a dynamic filter, its training loss rarely exhibits slow or unstable convergence. ", "page_idx": 37}, {"type": "text", "text": "J Additional Training Loss Plots ", "text_level": 1, "page_idx": 38}, {"type": "image", "img_path": "1mAaewThcz/tmp/718cc0f4556d7ccc7e3d042b5756c8d58bfcbc1ac70ef9f8b321dc9d255d7324.jpg", "img_caption": ["Figure 16: Mean absolute parameter gradient vs. training epoch for RW, SYM, and ATT GNNs on Cora ML, CS, and Physics. The training accuracy of SYM, RW, and ATT ultimately reach the accuracy of $\\mathbf{MAJ}_{\\mathrm{WL}}$ . "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "1mAaewThcz/tmp/8f1048d33d9a1e15e1d21f4ae579595d2420183b2586c07282399d4646751f04.jpg", "img_caption": ["PHOTO"], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "", "img_caption": ["Figure 17: Mean absolute parameter gradient vs. training epoch for RW, SYM, and ATT GNNs on Photo and Computers. The training accuracy of SYM, RW, and ATT ultimately reach the accuracy of MAJWL. "], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "CHAMELEON ", "text_level": 1, "page_idx": 40}, {"type": "image", "img_path": "1mAaewThcz/tmp/5b30c638ab6a864a23b1f37f256890c8c6e6e11558109e4c65168cc655a4e703.jpg", "img_caption": ["Figure 18: Mean absolute parameter gradient vs. training epoch for RW, SYM, and ATT GNNs on chameleon and squirrel. The training accuracy of SYM, RW, and ATT ultimately reach the accuracy of $\\mathbf{MAJ}_{\\mathrm{WL}}$ . "], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "K Connecting Inverse Collision Probability to Node Degree ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Our theoretical analysis may be improved upon by establishing a rigorous connection, or a lack thereof, between the inverse collision probability of a node and its degree. ", "page_idx": 41}, {"type": "text", "text": "Via some preliminary analysis, we find that it is possible to express the inverse collision probability of $i$ (i.e., equivalently express the sum of $l$ -hop collision probabilities) in terms of $D_{i i}$ . In particular, we can show: $\\begin{array}{r l r}{\\sum_{l=0}^{L}\\alpha_{i}^{(l)}}&{=}&{\\alpha_{i}^{(0)}\\;+\\;\\sum_{l=1}^{L}\\dot{\\sum}_{j\\in\\mathcal{V}}[({P}_{r w}^{l})_{i j}]^{2}\\;\\;=\\;\\;1\\;+}\\end{array}$ $\\begin{array}{r}{\\frac{1}{D_{i i}^{2}}\\sum_{l=1}^{L}\\sum_{j\\in\\mathcal{V}}[\\sum_{k\\in\\mathcal{N}(i)}(P_{r w}^{l-1})_{k j}]^{2}}\\end{array}$ . As before, we can see that the inverse collision probability is larger (and thus $R_{i,c^{\\prime}}$ is larger) when $D_{i i}$ is larger and $\\begin{array}{r}{\\sum_{l=1}^{L}\\sum_{j\\in\\mathcal{V}}[\\sum_{k\\in\\mathcal{N}(i)}(P_{r w}^{l-1})_{k j}]^{2}\\in o(D_{i i}^{2})}\\end{array}$ . However, because $\\textstyle\\sum_{k\\in{\\mathcal{N}}(i)}$ depends on $D_{i i}$ , this expression does not completely isolate the impact of $D_{i i}$ on the inverse collision probability. A similar expression can be derived for SYM by expressing: $P_{s y m}=D^{\\frac{1}{2}}P_{r w}D^{-\\frac{1}{2}}$ . ", "page_idx": 41}, {"type": "text", "text": "Alternatively, one may consider $\\begin{array}{r}{\\sum_{l=0}^{L}\\alpha_{i}^{(l)}\\le\\sum_{l=0}^{\\infty}\\alpha_{i}^{(l)}}\\end{array}$ , and then plug in the steady-state probabilities of uniform random walks on graphs. However, as l \u2192\u221e, (P rlw)ij = 2D|jEj| only depends on $D_{j j}$ (not $D_{i i}$ , as desired). It is also possible to upper bound the inverse collision probability as: $\\begin{array}{r}{1/\\sum_{l=0}^{}\\alpha_{i}^{(l)}\\le1/(\\alpha_{i}^{(0)}+\\alpha_{i}^{(1)})=1/(1/D_{i i}+1)}\\end{array}$ , which is in terms of $D_{i i}$ ; however, we cannot us e this upper bound to lower bound $R_{i,c^{\\prime}}$ . The collision probabilities themselves are intimately related to more global properties of graphs; for instance, via eigendecomposition, $[(P_{r w}^{l})_{i j}]^{2}\\le\\lambda^{2l}$ , where $\\lambda<1$ is the eigenvalue of $P_{r w}$ with the largest magnitude [36]. Then, the inverse collision probability is strictly greater than $\\frac{1}{\\sum_{l=0}^{L}|\\nu|\\lambda^{2l}}$ . ", "page_idx": 41}, {"type": "text", "text": "This being said, our paper argues that the inverse collision probability is a more fundamental quantity that influences what the fair graph learning community has termed \u201cdegree bias\u201d than degree alone, which we have shown is positively associated with the inverse collision probability. ", "page_idx": 41}, {"type": "text", "text": "L Limitations and Future Directions ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Survey While we aimed to be thorough in our survey of prior papers on degree bias, it is inevitable that we missed some relevant work. In addition, we extract hypotheses for the origins of degree bias from the main bodies of papers; it is possible that the hypotheses do not fully or accurately reflect the current perspectives of the papers\u2019 authors. ", "page_idx": 42}, {"type": "text", "text": "Theoretical analysis Our theoretical analysis is limited to linearized message-passing GNNs. While this is a common practice in the literature [51, 7, 39], it is a strong simplifying assumption. We empirically validate our theoretical findings on GNNs with non-linear activation functions, but our paper does not address possible sources of degree bias related to these non-linearities, which would be interesting to investigate in future work. Towards this, a possible option is to assume that node features are drawn from a Gaussian distribution and derive precise high-dimensional asymptotics for degree bias in non-linear GNNs using the Gaussian equivalence theorem, as in [1]. Our assumptions that GNNs generalize in expectation (Theorem 1) and the variance of node representations is finite (Theorems 2 and 3) are not overly strong assumptions in practice. ", "page_idx": 42}, {"type": "text", "text": "Furthermore, our paper focuses on node classification. However, our findings readily lend insight into the origins of degree bias in link prediction. For example, if one uses node representations and an inner-product decoder to predict links between nodes, our results indicate that: ", "page_idx": 42}, {"type": "text", "text": "\u2022 In the random walk filter case, link prediction scores between low-degree nodes will suffer from higher variance because low-degree node representations have higher variance (Theorem 2). Hence, Theorem 1 suggests that predictions for links between low-degree nodes will have a higher misclassification error.   \n\u2022 In the symmetric filter case, our proof of Theorem 3 suggests that the link prediction scores between high-degree nodes will be over-calibrated (i.e., disproportionately large) because highdegree node representations have a larger magnitude (i.e., approximately proportional to the square root of their degree). Hence, over-optimistic and possibly inaccurate links will be predicted between high-degree nodes. ", "page_idx": 42}, {"type": "text", "text": "The labels and evaluation for link prediction can confound intuition. Unlike node classification, the labels for link prediction (i.e., the existence or not of a link) make the task naturally imbalanced with respect to node degree; high-degree nodes have a much higher rate of positive links than lowdegree nodes. This association between degree and positive labels can influence the misclassification error. Ultimately, more rigorous theoretical analysis and experimentation are needed to confirm the hypothesized implications of node degree for link prediction performance. Similarly, more research is required to understand the implications of our findings for degree bias in the context of graph classification. ", "page_idx": 42}, {"type": "text", "text": "Furthermore, our theoretical analysis does not encompass heterogeneous graphs. In our literature survey, we cover works that establish the issue of degree bias for knowledge graph predictions and embeddings (e.g., [5, 43]). Our theoretical analysis is general and covers diverse message-passing GNNs, and can be extended to heterogeneous networks if messages aggregated from different edge types are subsequently linearly combined. In this setting, $R_{i,c^{\\prime}}$ can be computed as the sum of the prediction homogeneity quantities $(\\sum\\!{}_{l=0}^{L}\\,\\beta_{i,c^{\\prime}}^{(l)})^{2}$ for each edge type divided by the sum of the collision probability quantities $\\begin{array}{r}{\\sum_{j\\in\\upnu}[(P_{r w}^{l})_{i j}]^{2}}\\end{array}$ for each edge type. ", "page_idx": 42}, {"type": "text", "text": "Empirical validation We sought to be transparent throughout our paper regarding misalignments between empirical and theoretical findings. Our experiments focus on the transductive learning setting; it would be valuable to validate our theoretical findings in the inductive learning setting as well. Furthermore, while we aimed to cover diverse domains (e.g., citation networks, collaboration networks, online product networks, Wikipedia networks), as well as homophilic and heterophilic networks, it remains to identify the shortcomings of our theoretical findings for heterogeneous and directed networks. ", "page_idx": 42}, {"type": "text", "text": "Principled roadmap To do justice to studying the origins of degree bias in GNNs, which our paper reveals has various and sometimes conflicting understandings, we limit the scope of our paper to understanding the root causes of degree bias, not providing a concrete algorithm to alleviate it. ", "page_idx": 42}, {"type": "text", "text": "Instead, we offer a principled roadmap based on our theoretical findings to address degree bias in the future. We further comment on the limitations of algorithmic solutions to degree bias in our Broader Impacts section below. ", "page_idx": 43}, {"type": "text", "text": "M Broader Impacts ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Our paper touches upon issues of discrimination, bias, and fairness, with the goal of advancing justice in graph learning. In particular, our analysis of the origins of degree bias in GNNs seeks to inform principled approaches to mitigate unfair performance disparities faced by low-degree nodes in networks (e.g., lowly-cited authors, junior researchers, niche product and content creators). Despite our focus on fairness, our work can still have negative societal impacts in malicious contexts. For example, alleviating the degree bias of GNNs that are intended to surveil individuals can further violate the privacy of low-degree individuals. Ultimately, performance disparities should only be mitigated when the task is aligned with the interests and well-being of marginalized individuals; we explicitly do not support evaluating or mitigating degree bias to ethics-wash inherently harmful applications of graph learning. Furthermore, any algorithm proposed to alleviate degree bias will not be a \u2018silver bullet\u2019 solution; graph learning practitioners must adopt a sociotechnical approach: (1) critically examining the societal factors that contribute to their networks have degree disparities to begin with, and (2) monitoring their GNNs in deployment and continually adapting their degree bias evaluations and algorithms. In addition, alleviating degree bias does not necessarily address other forms of unfairness in graph learning, e.g., equal opportunity with respect to protected social groups [2], dyadic fairness [25], preferential attachment bias [44]; fairness algorithms are contextual and not one-size-fits-all. ", "page_idx": 44}, {"type": "text", "text": "Responsible Research Checklist ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: See $\\S L$ . ", "page_idx": 45}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: All the theorems, formulas, and proofs in the paper are numbered and crossreferenced. The assumptions are clearly stated in the main body of the paper and referenced in the proofs of theorems. Formal proofs are provided in the appendix; while proof sketches are not included in the main body of the paper, we provide extensive interpretation of theoretical results. ", "page_idx": 45}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: Details to reproduce experiments are provided in the main body of the paper, $\\S D$ , and $\\S C$ . The code is released via Github. ", "page_idx": 45}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: The code is released via Github. The data are available through PyTorch Geometric [15], and data processing details are provided in $\\S C$ . ", "page_idx": 45}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: See $\\S D$ and $\\S C$ . ", "page_idx": 45}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: Error bars are reported over 10 random seeds in all figures except for the PCA plots. The factors of variability include model parameter initialization and training dynamics. All error bars are 1-sigma and represent the standard deviation (not standard error) of the mean. We implicitly assume that errors are normally-distributed. Error bars are computed using PyTorch\u2019s std function [40]. We provide this information at the beginning of $\\S3$ . ", "page_idx": 45}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] Justification: See $\\S D$ . ", "page_idx": 46}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: See $\\S\\mathbf{M}$ . ", "page_idx": 46}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: See $\\S C$ . The original paper that produced each dataset is cited. Links to libraries and datasets are included; the versions of software dependencies can be found in the requirements.txt file via Github. We also provide the name and a link to the license (which includes terms of use and copyright information, where applicable) of each library and dataset. ", "page_idx": 46}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: We release our code via Github under an MIT license. We provide a README that explains how to reproduce our experiments. Training, license compliance, and consent details are included in $\\mathrm{\\SD}.$ . Limitations are discussed in $\\S L$ . ", "page_idx": 46}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}]