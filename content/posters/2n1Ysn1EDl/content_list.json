[{"type": "text", "text": "MambaLRP: Explaining Selective State Space Sequence Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Farnoush Rezaei Jafari1,2\u2217 Gre\u00b4goire Montavon3,2,1 Klaus-Robert Mu\u00a8ller1,2,4,5,6 ", "page_idx": 0}, {"type": "text", "text": "Oliver Eberle1,2\u2217 ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1Machine Learning Group, Technische Universita\u00a8t Berlin, 10587 Berlin, Germany   \n2BIFOLD \u2013 Berlin Institute for the Foundations of Learning and Data, 10587 Berlin, Germany 3Department of Mathematics and Computer Science, Freie Universita\u00a8t Berlin, Arnimallee 14, 14195 Berlin, Germany 4Department of Artificial Intelligence, Korea University, Seoul 136-713, South Korea   \n5Max Planck Institute for Informatics, Stuhlsatzenhausweg 4, 66123 Saarbr\u00a8ucken, Germany 6Google DeepMind, Berlin, Germany ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recent sequence modeling approaches using selective state space sequence models, referred to as Mamba models, have seen a surge of interest. These models allow efficient processing of long sequences in linear time and are rapidly being adopted in a wide range of applications such as language modeling, demonstrating promising performance. To foster their reliable use in real-world scenarios, it is crucial to augment their transparency. Our work bridges this critical gap by bringing explainability, particularly Layer-wise Relevance Propagation (LRP), to the Mamba architecture. Guided by the axiom of relevance conservation, we identify specific components in the Mamba architecture, which cause unfaithful explanations. To remedy this issue, we propose MambaLRP, a novel algorithm within the LRP framework, which ensures a more stable and reliable relevance propagation through these components. Our proposed method is theoretically sound and excels in achieving state-of-the-art explanation performance across a diverse range of models and datasets. Moreover, MambaLRP facilitates a deeper inspection of Mamba architectures, uncovering various biases and evaluating their significance. It also enables the analysis of previous speculations regarding the long-range capabilities of Mamba models. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Sequence modeling has demonstrated its effectiveness and versatility across a wide variety of tasks and data types, including text, time series, genomics, audio, and computer vision [24, 82, 32, 9, 26]. Recently, there has been a surge of interest in a new class of sequence modeling architectures, known as structured state space sequence models (SSMs) [35, 66, 33]. This is due to their ability to process sequences in linear time, as opposed to quadratic time required by the more established Transformer architectures [69]. The recent Mamba architecture, a prominent and widely adopted instance of state space models, has demonstrated competitive predictive performance on a variety of sequence modeling tasks across domains and applications [33, 43, 83, 78, 70], while scaling linearly with sequence length. ", "page_idx": 0}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/3cb12430b822a78b3c4a1ad9bafdc16696e7aca1987dae9fa193846ffbae2780.jpg", "img_caption": ["Figure 1: Conceptual steps involved in the design of MambaLRP. (a) Take as a starting point a basic LRP procedure, equivalent to Gradient $\\times$ Input. (b) Analyze layers in which the conservation property is violated. (c) Rework the relevance propagation strategy at those layers to achieve conservation. The resulting MambaLRP method enables efficient and faithful explanations. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "As Mamba models, and more generally SSMs, are rapidly being adopted into real-world applications, ensuring their transparency is crucial. This enables inspection beyond test set accuracy and uncovering various forms of biases, including \u2018Clever-Hans\u2019 effects [39]. It is particularly important in highrisk domains such as medicine, where the prediction behavior must be robust under real-world conditions and aligned with human understanding. The field of Explainable AI [48, 36, 8, 58] focuses on developing faithful model explanations that attribute predictions to relevant features and has shown success in explaining many highly nonlinear models such as convolutional networks [20], or attention-based Transformer models [3, 2]. ", "page_idx": 1}, {"type": "text", "text": "Explaining the predictions of Mamba models is however challenging due to their highly non-linear and recurrent structure. A recent study [4] suggests viewing these models as attention-based models, enabling the use of attention-based explanation methods [1, 18]. Yet, the explanations produced by attention-based techniques are often unreliable and exposed to potential misalignment between input features and attention scores [75, 38]. As an alternative, Layer-wise Relevance Propagation (LRP) [10] decomposes the model function with the goal of explicitly identifying the relevance of input features by applying purposely designed propagation rules at each layer. A distinguishing feature of LRP is its adherence to a conservation axiom, which prevents the artificial amplification or suppression of feature relevance in the backward pass. LRP has been demonstrated to produce faithful explanations across various domains (e.g. [7, 62, 3, 20]). Nevertheless, the peculiarities of the Mamba architecture are not addressed by the existing LRP procedures, which may lead to the violation of the conservation property and result in unreliable explanations. ", "page_idx": 1}, {"type": "text", "text": "In this work, we present MambaLRP, a novel approach to integrate LRP into the Mamba architecture. By examining the relevance propagation process across Mamba layers through the lens of conservation, we pinpoint layers within the Mamba architecture that need to be addressed specifically. We propose a novel relevance propagation strategy for these layers, grounded in the conservation axiom, that is theoretically sound, straightforward to implement and computationally efficient. Through a number of quantitative evaluations, we show that the proposed MambaLRP approach allows to robustly deliver the desired high explanatory performance, exceeding by far the performance of various baseline explanation methods as well as a naive transposition of LRP to the Mamba architecture. We further demonstrate the usefulness of MambaLRP in several areas: gaining concrete insights into the model\u2019s prediction mechanism, uncovering undesired decision strategies in image classification, identifying gender bias in language models, and analyzing the long-range capabilities of Mamba. Our code is publicly available.1 ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Structured State Space Sequence Models (SSMs). Transformers [69] have emerged as the most widely used architectures for sequence modeling. However, their computational limitations, particularly with large sequence lengths, have restricted their applicability in modeling long sequences. Addressing these computational limitations, recent works [34, 35] have introduced structured state space sequence models (SSMs) as an alternative approach. SSMs are a class of sequence modeling methods, leveraging the strengths of recurrent, convolutional, and continuous-time methods, demonstrating promising performance across various domains, including language [30, 46], image [77, 13, 50], and video [71] processing, and beyond [59, 22, 42]. A recent advancement by Gu and Dao [33] introduced selective SSM, an enhanced data-dependent SSM with a selection mechanism that adjusts its parameters based on the input. Built on this dynamic selection, the Mamba architecture fuses the SSM components with multilayer perceptron (MLP) blocks. This fusion simplifies the architecture while improving its ability to handle various sequence modeling tasks, including applications in language processing [6, 53, 72], computer vision [41, 83, 78], medical imaging [44, 76, 31, 56, 40, 74, 73], and graphs [70, 14]. This fast adoption of SSMs and Mamba models underscores the need for reliable explanations of their predictions. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Explainable AI and SSMs. In efforts to explain Mamba models, [51] analyzed if the interpretability tools originally designed for Transformers can also be effectively applied to architectures such as Mamba. In this context, Ali et al. [4] and Zimerman et al. [84] recently proposed viewing the internal computations of Mamba models as an attention mechanism. This approach builds upon previous works that use attention signal as explanation, including Attention Rollout [1] and variants thereof [18, 17]. While these approaches can provide some insight, they inherit the limitations of using attention as an explanation [75, 38], including their inability to capture potential misalignment between tokens and attention scores, and the limited performance in empirical faithfulness evaluations. Alternative Explainable AI methods, not yet applied to Mamba models but in principle applicable to any model, include techniques using input perturbations [81, 85, 29] or leveraging gradient information [11, 64, 68, 65, 63]. Despite their wide applicability, these models have certain drawbacks, such as requiring multiple function evaluations for a single explanation or being susceptible to gradient noise, resulting in subpar performance, as our benchmark experiment will demonstrate. Alternatively, deriving tailored approaches that reflect the underlying model structure, has shown to be a promising direction in developing better attribution methods based on gradient analysis of the prediction function [7, 27, 62, 3]. In the Layer-wise Relevance Propagation framework, this necessitates suitable propagation rules, which are currently lacking for the Mamba architecture. To tackle these challenges, we introduce MambaLRP as an efficient solution for the computation of reliable and faithful explanations that are theoretically grounded in the axiom of relevance conservation. ", "page_idx": 2}, {"type": "text", "text": "3 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Before delving into the details of our proposed method, we begin with a brief overview of the selective SSM architecture, followed by an introduction to the LRP framework. ", "page_idx": 2}, {"type": "text", "text": "Selective SSMs (S6) An important component within the Mamba [33] architecture is the selective SSM. It is characterized by parameters, $\\bar{A},\\bar{B}$ , and $C$ , and transforms a given input sequence $(x_{t})_{t=1}^{T}$ into an output sequence of the same size $(y_{t})_{t=1}^{T}$ via the following equations: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{h_{t}=\\bar{A}_{t}h_{t-1}+\\bar{B}_{t}x_{t}}}\\\\ {{y_{t}=C_{t}h_{t}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the initial state $h_{0}=0$ . What distinguishes the selective SSM from the original SSM (S4) [35] is that the evolution parameter, $\\bar{A_{t}}$ , and projection parameters, $\\bar{B_{t}}$ and $C_{t}$ , are functions of the input $x_{t}$ . This enables dynamic adaptation of the SSM\u2019s parameters based on input. This dynamicity facilitates focusing on relevant information while ignoring irrelevant details when processing a sequence. ", "page_idx": 2}, {"type": "text", "text": "Layer-wise Relevance Propagation Layer-wise Relevance Propagation (LRP) [10] is an Explainable AI method that attributes the model\u2019s output to the input features through a single backward pass. This backward pass is specifically designed to identify neurons relevant to the prediction. LRP assigns relevance scores to neurons in a given layer and then propagates these scores to neurons in the preceding layer. The process continues layer by layer, starting from the network\u2019s output and terminating once the input features are reached. The LRP backward pass relies on an axiom called \u2018conservation\u2019 requiring that relevance scores are preserved across layers, avoiding to artificially amplify or suppress contributions. For example, let $x$ and $y$ be the input and output of some layer, respectively, and let ${\\mathcal{R}}(x)$ and $\\mathcal{R}(y)$ represent the sum of relevance scores in the respective layers. The conservation axiom requires that $\\bar{\\mathcal{R}}(x)=\\mathcal{R}(y)$ holds true. ", "page_idx": 2}, {"type": "text", "text": "4 LRP for Mamba ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this work, we bring explainability, particularly LRP, to Mamba models, following the conceptual design steps, shown in Fig. 1. We start by applying a basic LRP procedure, specifically one corresponding to Gradient $\\times$ Input (GI), to the Mamba architecture. This serves as an effective initial step for identifying layers where certain desirable explanation properties, like relevance conservation, are violated. We analyze different layers of the Mamba architecture, derive relevance propagation equations and test the fulflilment of the conservation property. Our analysis reveals three components in the Mamba architecture where conservation breaks: the SiLU activation function, the selective SSM, and the multiplicative gating of the SSM\u2019s output. Leveraging the analysis above, we propose novel relevance propagation strategies for these three components, which lead to a robust, faithful and computationally efficient explanation approach, called MambaLRP. ", "page_idx": 3}, {"type": "text", "text": "4.1 Relevance propagation in SiLU layers ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We start by examining the relevance propagation through Mamba\u2019s SiLU activation functions. This function is represented by the equation $y=x\\cdot\\sigma(x)$ , where $\\sigma$ denotes the logistic sigmoid function. ", "page_idx": 3}, {"type": "text", "text": "Proposition 4.1 Applying the standard gradient propagation equations yields the following result, which relates the relevance values before and after the activation layer: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\underbrace{{\\frac{\\partial f}{\\partial x}}x}_{\\mathcal{R}(x)}=\\underbrace{{\\frac{\\partial f}{\\partial y}}y}_{\\mathcal{R}(y)}+\\underbrace{{\\frac{\\partial f}{\\partial y}}\\cdot\\sigma^{\\prime}(x)\\cdot x^{2}}_{\\varepsilon}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The derivation for Eq. 3 can be found in Appendix A.1. We observe that the conservation property, i.e. $\\mathcal{R}(x)=\\mathcal{R}(y)$ , is violated whenever the residual term $\\varepsilon$ is non-zero. We propose to restore the conservation property in the relevance propagation pass by locally expanding the SiLU activation function as: ", "page_idx": 3}, {"type": "equation", "text": "$$\ny=x\\cdot[\\sigma(x)]_{\\mathrm{cst.}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $[\\cdot]_{\\mathrm{cst.}}$ treats the given quantity as constant. This can be implemented e.g. in PyTorch using the .detach() function. Repeating the derivation above with this modification yields the desired conservation property, $\\mathcal{R}(x)=\\mathcal{R}(y)$ . The explicit LRP rule associated to this LRP procedure is provided in Appendix B. ", "page_idx": 3}, {"type": "text", "text": "4.2 Relevance propagation in selective SSMs (S6) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The most crucial non-linear component of the Mamba architecture is its selective SSM component. It is designed to selectively retain or discard information throughout the sequence by adjusting its parameters based on the input, enabling dynamic adaptation to each token. To facilitate the analysis, we introduce an inconsequential modification to the original SSM by connecting $C_{t}$ to $h_{t}$ instead of $x_{t}$ . To do so, we can redefine $\\bar{A_{t}},\\ \\bar{B_{t}}$ , and $C_{t}$ matrices as blockdiag $(\\bar{A}_{t}\\,,\\,0)$ , $(\\bar{B}_{t}\\,,\\,I)$ , and $\\left(C_{t}\\mid0\\right)$ respectively, such that $x_{t}$ becomes part of the state $h_{t}$ without altering the overall functionality of the SSM. ", "page_idx": 3}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/035fcf3b201e5f4c288d18bc87319fcdbff24ee5e38e7bc9cc4bae931d6cbad2.jpg", "img_caption": ["Figure 2: Unfolded view of SSM, highlighting two subsets of nodes, the relevance of which should be conserved throughout relevance propagation. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "The unfolded SSM, with the aforementioned modification, is illustrated in Fig. 2. The complex relevance propagation procedure in the SSM component can be further simplified by considering two groups of units, illustrated in red and orange in Fig. 2. In these two groups, there are no connections within units of the same group, all the relevance propagation signals from the first group are directed towards the second group, and the second group receives no further incoming relevance propagation signal. With these properties, these two groups should, according to the principle of conservation, receive the same relevance scores. ", "page_idx": 3}, {"type": "text", "text": "Proposition 4.2 Defining $\\theta_{t}=(\\bar{A}_{t},\\bar{B}_{t},C_{t-1})$ , and working out the propagation equations between these two groups yields the following relation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\underbrace{\\frac{\\partial f}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial h_{t-1}}h_{t-1}}_{\\mathcal{R}(x_{t})+\\mathcal{R}(h_{t-1})}=\\underbrace{\\frac{\\partial f}{\\partial h_{t}}h_{t}+\\frac{\\partial f}{\\partial y_{t-1}}y_{t-1}}_{\\mathcal{R}(h_{t})+\\mathcal{R}(y_{t-1})}+\\underbrace{\\frac{\\partial f}{\\partial\\theta_{t}}\\frac{\\partial\\theta_{t}}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial\\theta_{t}}\\frac{\\partial\\theta_{t}}{\\partial h_{t-1}}h_{t-1}}_{\\varepsilon}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The derivation for Eq. 5 can be found in Appendix A.2. We note that the residual term $\\epsilon$ , which is typically non-zero, violates conservation. Specifically, conservation fails due to the dependence of $\\theta$ on the input. We propose to rewrite the state-space model at each step in a way that the parameters $\\theta_{t}$ appear constant, i.e.: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h_{t}=[\\bar{A}_{t}]_{\\mathrm{cst.}}h_{t-1}+[\\bar{B}_{t}]_{\\mathrm{cst.}}x_{t}}\\\\ &{y_{t}=[C_{t}]_{\\mathrm{cst.}}h_{t}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "These equations can also be interpreted as viewing the selective SSM as a localized non-selective, i.e. standard, SSM. With this modification, conservation holds between the two groups, i.e. $\\mathcal{R}(x_{t})+$ $\\mathcal{R}(h_{t-1})=\\mathcal{R}(h_{t})+\\mathcal{R}(y_{t-1})$ . By repeating the argument for each time step, conservation is also maintained between the input and output of the whole SSM component. Explicit LRP rules are provided in Appendix B. ", "page_idx": 4}, {"type": "text", "text": "4.3 Relevance propagation in multiplicative gates ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In each block within the Mamba architecture, the SSM\u2019s output is multiplied by an input-dependent gate. In other words, $y=z_{A}\\cdot z_{B}$ , where $z_{A}=\\operatorname{SSM}(x)$ and $z_{B}=\\mathrm{SiLU}(\\mathrm{Linear}(x))$ . Assume that the locally linear expansions introduced in Sections 4.1 and 4.2 are applied to the SSM components and SiLU activation functions, the mapping from $x$ to $y$ becomes quadratic. ", "page_idx": 4}, {"type": "text", "text": "Proposition 4.3 Applying the standard gradient propagation equations establishes the following relation between the relevance values before and after the gating operation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\underbrace{\\frac{\\partial f}{\\partial x}x}_{\\mathcal{R}(x)}=\\underbrace{\\frac{\\partial f}{\\partial y}y}_{\\mathcal{R}(y)}+\\underbrace{\\frac{\\partial f}{\\partial y}y}_{\\varepsilon}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The derivation for Eq. 8 and explicit LRP rules can be found in Appendix A.3 and Appendix B, respectively. In this equation, we observe a spurious doubling of relevance in the backward pass. This can be addressed by treating half of the output as constant: ", "page_idx": 4}, {"type": "equation", "text": "$$\ny=0.5\\cdot(z_{A}\\cdot z_{B})+0.5\\cdot[z_{A}\\cdot z_{B}]_{\\mathrm{cst.}}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As for the previous examples, this ensures the conservation property $\\mathcal{R}(x)=\\mathcal{R}(y)$ . An alternative would have been to make $y$ linear by detaching only one of the terms in the product, as done for the SiLU activation or the SSM component. However, the strategy of Eq. 9 better maintains the directionality given by the gradient. We further compare these alternatives in an ablation study presented in Appendix C.5, demonstrating empirically that our proposed approach performs better. ", "page_idx": 4}, {"type": "text", "text": "4.4 Additional modifications and summary ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The propagation strategies developed for the Mamba-specific components complement previously proposed approaches for other layers, including propagation through RMSNorm layers [3] and convolution layers via robust $\\mathrm{LRP-}\\gamma$ rules [49, 25] and their generalized variants. A summary of these additional enhancements is provided in Appendix C.2. Furthermore, our proposed propagation rules are generally applicable to other models that utilize similar components, such as multiplicative gates in recent architectures [54, 52, 45, 21]. ", "page_idx": 4}, {"type": "text", "text": "A straightforward implementation of the propagation rules can be achieved by computing MambaLRP via Gradient $\\times$ Input, where the gradient computations are modified to align with the proposed rules. The procedure consists of two main steps: ", "page_idx": 4}, {"type": "text", "text": "1. Perform the detach operations of Eqs. (4), (6), (7), and (9) (as well as similar operations for RMSNorm and convolutions). 2. Retrieve MambaLRP explanations by computing Gradient $\\times$ Input on the detached model. ", "page_idx": 4}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To evaluate our proposed approach, we benchmark its effectiveness against various methods previously proposed in the literature for interpreting neural networks. We empirically evaluate our proposed methodology using Mamba-130M, Mamba-1.4B, and Mamba-2.8B language models [33], which are trained on diverse text datasets. The training details can be found in Appendix C.1. For the vision experiments, we use the Vim-S model [83]. Moreover, we perform several ablation studies to further investigate our proposed method. ", "page_idx": 5}, {"type": "text", "text": "Datasets In this study, we perform experiments on four text classification datasets, namely SST-2 [67], Medical BIOS [28], Emotion [60], and SNLI [16]. The SST-2 dataset encompasses around 70K English movie reviews, categorized into binary classes, representing positive and negative sentiments. The Medical BIOS dataset consists of short biographies (10K) with five specific medical occupations as targets. The SNLI corpus (version 1.0) comprises 570k English sentence pairs, with the labels entailment, contradiction, and neutral, used for the natural language inference (NLI) task. The Emotion dataset (20K) is a collection of English tweets, each labeled with one of six basic emotions. For the vision experiments, we use ImageNet dataset [23] with 1.3M images and 1K classes. ", "page_idx": 5}, {"type": "text", "text": "Baseline methods We compare our proposed method with several gradient-based, model-agnostic explanation techniques: Gradient $\\times$ Input (GI) [11, 64], SmoothGrad [65], and Integrated Gradients [68]. Furthermore, we evaluate the performance of our proposed method against a naive implementation of LRP, i.e. LRP (LN-rule), where the LRP-0 rule is used in all linear and convolution layers, along with the LN-rule [3] in normalization layers. ", "page_idx": 5}, {"type": "text", "text": "We further compare the performance of our proposed method with two attention-based approaches, Attention Rollout (AttnRoll) and MambaAttr [4], which are recently proposed for Mamba models. Both methods are extensions of techniques originally developed for Transformer models: Attention Rollout [1] and Gradient $.\\times$ Attention Rollout [18]. ", "page_idx": 5}, {"type": "text", "text": "5.1 Conservation property ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To verify the fulflilment of the conservation property, on which our method is based, we compare the network\u2019s output score with the sum of relevance scores attributed to the input features, for both the GI baseline and the proposed MambaLRP. The analysis is performed for Mamba-130M and Vim-S models trained on the SST-2 and ImageNet datasets, respectively. Full conservation is achieved if the output score equals the sum of relevance, as indicated by the blue line in Fig. 3. Our results show that conservation is severely violated by the GI baseline, and is addressed to a large extent by MambaLRP. Residual lack of conservation is due to the presence of biases in linear and convolution layers, which are typically non-attributable. ", "page_idx": 5}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/43340cc8a2cd1bd13b6ae94b432e805b11cbe35d9065a2c480cfaae5cfba7992.jpg", "img_caption": ["Figure 3: Conservation property. The $\\mathbf{X}_{\\mathrm{}}$ -axis represents the sum of relevance scores across the input features and the y-axis shows the network\u2019s output score. Each point corresponds to one example and its proximity to the blue identity line indicates the extent to which conservation is preserved, with closer alignment suggesting improved conservation. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "5.2 Qualitative evaluation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we qualitatively examine the explanations produced by various explanation methods for Mamba-130M and Vim-S models. Fig. 4 illustrates the explanations generated to interpret the Mamba-130M model\u2019s prediction on a sentence from the SST-2 dataset with negative sentiment. We note that all of the explanation methods attribute positive scores to the word \u2018disgusting\u2019, which appears reasonable given the negative sentiment label. However, it is notable that the explanation generated by MambaLRP is more sparse and focuses particularly on the terms \u2018so\u2019 and \u2018disgusting\u2019. In contrast, the explanations produced by the gradient-based methods and AttnRoll appear to be quite noisy. Furthermore, we show the explanations produced to interpret the Vim-S model\u2019s predictions on images of the ImageNet dataset in Fig. 5. Purely gradient-based explanations tend to identify unspecific noisy features, while both attention-based approaches, AttnRoll and MambaAttr, are more effective at highlighting significant features. Among these methods, MambaLRP stands out for its ability to generate explanations that are particularly focused on key features used by the model to make a prediction. Take, for instance, the first image classified under the \u2018African elephant\u2019 category. We can see that the explanation generated by MambaLRP not only includes all occurrences of the \u2018African elephant\u2019 object but also highlights its distinctive features, such as the tusks. In the second image labeled \u2018wild boar\u2019, despite the presence of multiple objects in the image, MambaLRP\u2019s explanation remains focused on the \u2018wild boar\u2019 object, disregarding other objects. Moreover, in the third instance, MambaLRP uncovers a spurious correlation, the presence of a watermark in Chinese, influencing the model\u2019s prediction, a subtlety overlooked or not fully represented by other methods. Further qualitative results can be found in Appendix C.6. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/744065e6dcb0bf80c0da84116f44ff5847100467a62e1548092e69bf5b34a023.jpg", "img_caption": ["Figure 4: Explanations generated for a sentence of the SST-2 dataset. Shades of red represent words that positively influence the model\u2019s prediction. Conversely, shades of blue reflect negative contributions. The heatmaps of attention-based methods are constrained to non-negative values. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/572aea4727a62ba82f7dc1bdb04f928a383540455bf161858c76b6b3eacd9887.jpg", "img_caption": ["Figure 5: Explanations produced by different explanation methods for images of the ImageNet dataset. AttnRoll and MambaAttr are limited to non-negative heatmap values. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "5.3 Quantitative evaluation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "To quantitatively evaluate the faithfulness of explanation methods, we employ an input perturbation approach based on ranking input features by their importance [57], which can be done using either a Most Relevant First (MoRF) or Least Relevant First (LeRF) strategy. Ranked features are iteratively perturbed through a process known as filpping. We monitor the resulting changes in the output logit, $f_{c}$ , for the predicted class $c$ , and compute the area under the perturbation curve. The areas under the curves for LeRF and MoRF strategies are denoted by ALeRF and AFMoRF, respectively. In contrast, the insertion method starts with a fully perturbed input and progressively restores important features. The areas under the curves for this method are indicated by $A_{\\mathrm{MoRF}}^{I}$ and ILeRF, for the MoRF and LeRF strategies, respectively. A reliable explanation method is characterized by low values of ", "page_idx": 6}, {"type": "text", "text": "$A_{\\mathrm{MoRF}}^{F}$ or $A_{\\mathrm{LeRF}}^{I}$ , and large values of $A_{\\mathrm{LeRF}}^{F}$ or $A_{\\mathrm{MoRF}}^{I}$ . In an effort to minimize the introduction of out-of-distribution manipulations, the recent study by Bl\u00a8ucher et al. [15] advocates for harnessing both insights to derive a more resilient metric. Therefore, we follow the same strategy as [15, 2] to evaluate explanation methods. The evaluation metrics are defined as $\\Delta A^{F}=A_{\\mathrm{LeRF}}^{F}-\\bar{A}_{\\mathrm{MoRF}}^{F}$ $\\Delta A^{I}=\\bar{A_{\\mathrm{MoRF}}^{F}}-A_{\\mathrm{LeRF}}^{F}$ ALFeRF. For both metrics, a higher score is preferable, as it signifies a more accurate and reliable explanation method. ", "page_idx": 7}, {"type": "text", "text": "The outcomes of this analysis are represented in Table 1. MambaLRP consistently achieves highest faithfulness scores in comparison to other baseline methods. We observe that GI struggles with noisy attributions, leading to low faithfulness scores. However, methods like Integrated Gradients and MambaAttr have shown improvements in this regard. We note that LRP (LN-rule) outperforms most methods across the majority of the text classification tasks. Nevertheless, its performance is notably inferior compared to MambaLRP. Overall, we observe that MambaLRP significantly outperforms all other methods by a substantial margin. In both vision and NLP experiments, attention-based methods have shown superior performance compared to the purely gradient-based approaches. ", "page_idx": 7}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/d2470321b1b7f9e165cf4b16d80e5fb9e87784bfa7b5bbf017dc045317357e8d.jpg", "table_caption": ["Table 1: Evaluating explanation methods. Higher scores $\\Delta A^{F}$ indicate more faithful explanations. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Runtime comparison We report the runtimes of MambaLRP along with other methods used in this study in Appendix C.9. As shown in Table 10, our method\u2019s runtime is comparable to GI and can be implemented via a single forward and backward pass. Since approaches like Integrated Gradients require multiple function evaluations, their runtimes are considerably higher than MambaLRP. ", "page_idx": 7}, {"type": "text", "text": "Ablation study In Section 4, we proposed techniques for handling different non-linear components within the Mamba architecture. This ablation study aims to assess the significance of each technique by testing the effect of their exclusion on faithfulness. Table 2 shows that all three modifications are essential for achieving competitive explanation performance, with our proposed method for handling the SSM component being the most critical. Further experiments, comparing different strategies for handling the Mamba block\u2019s multiplicative gate, are detailed in Appendix C.5. ", "page_idx": 7}, {"type": "text", "text": "Table 3: Frequency of gendered words in explanations for \u2018Nurse\u2019 and \u2018Surgeon\u2019 classes of the Medical BIOS dataset across language models. ", "page_idx": 7}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/18428fdedb48f62caafd9a4cb1de3230cf8e1dac8b488f7b4308ea3c28fbe52f.jpg", "table_caption": ["Table 2: Analyzing the impact of ablating the three proposed propagation rules on $\\Delta A^{\\breve{F}}$ for the components in MambaLRP. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/fcc14d0807385131ecfcdf112b15dd952a51cd8930c26b84c0b3fc18e2ac5361.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "6 Use cases ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Uncovering gender bias in Mamba. Explanation methods serve as tools to uncover biases in pretrained vision and language models. Using our proposed method, we examine Mamba-130M and Mamba-1.4B models, trained on the Medical BIOS dataset, to investigate the potential presence of gender biases. Following the methodology in [28], we use MambaLRP to identify the top-5 tokens of highest importance and to quantify the prevalence of gendered words within these tokens. We find that the model exhibits a pronounced preference for female-gendered words in the \u2018Nurse\u2019 class (e.g. the proportion of gender-specific words is 0.058 for females, compared to 0.0 for males in Mamba-130M.). We also compare the results of our analysis with those achieved for the GPT2-base, T5-base, and RoBERTa-base models as mentioned in [28]. As shown in Table 3, both Mamba models are less dependent on gendered tokens compared to GPT2-base, T5-base, and RoBERTa-base models, with the Mamba-1.4B model showing a further decrease in bias compared to the Mamba-130M, suggesting improvements in reducing gender bias with increased model size. ", "page_idx": 7}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/97a9011907450ba823fdb1a3b45c068fd1e2c694853ba13d7cf8836a36911852.jpg", "img_caption": ["Figure 6: Analysis of the position of tokens relevant for next token generation. Left: Distribution of absolute position of the ten most relevant tokens for the prediction of the next word. Right: Long-range dependency between tokens of the input and the predicted next token (here: 1972). "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/10c6e613dce9dd0b0f3ec8cc64e9039aab5e064d21db15700e43c335be5d29da.jpg", "img_caption": ["Figure 7: Explanation-based retrieval accuracy in the needle-in-a-haystack test verifying model reliance on relevant features for different context lengths. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Investigating long-range capabilities of Mamba. The ability of SSMs to model long-range dependencies is considered an important improvement over previous sequence models. In this use case, we analyze the extent to which the pretrained Mamba-130M model can use information from the entire context window. We use the HotpotQA [79] subset from the LongBench dataset [12], designed to test long context understanding. After selecting all 127 instances, containing sequences up to 8192 tokens, we prompt the model to summarize the full paragraph by generating ten additional tokens. Fig. 6 shows the distribution of the positional difference between a relevant token and the currently generated token. While we observe a pronounced pattern of attributing to the last few tokens, as seen in prior language generation studies [80, 61], the extracted explanations also identified relevant tokens across the entire context window, as presented for one example in Fig. 6 (right). This suggests that the model is indeed capable of retrieving long-range dependencies. We clearly see that in order to complete the sentence and assign a year to the album release date, the model analyzes previous occurrences of chronological information and MambaLRP identifies evidence supporting the decision for the date being \u20181972\u2019 as relevant. Our analysis demonstrates the previously speculated long-range abilities of the Mamba architecture [33], which we further explore in a comparison to Transformers in Appendix C.8. ", "page_idx": 8}, {"type": "text", "text": "Needle-in-a-haystack test. To assess the model\u2019s ability in retrieving relevant pieces of information from a broader context, we perform the needle-in-a-haystack test [47]. Our test involves extracting a single passkey (the \u2018needle\u2019) from a collection of repeated noise sentences (the \u2018haystack\u2019), as described in [37]. We run this test at eleven different document depths with three different context lengths. We use an instruction-finetuned Mamba-2.8B model in this experiment. To analyze the performance of the model, we introduce the explanation-based retrieval accuracy (XRA) metric. In this approach, we first identify the positions of the top-K relevant tokens by MambaLRP, and then, calculate the accuracy by comparing those positions to the needle\u2019s position. As shown in Fig. 7, MambaLRP accurately captures the information used by the model to retrieve the needle. In this case, the model could accurately retrieve the needle based on relevant information within the text. However, in more realistic and complex scenarios, the model may depend on irrelevant data yet still generate the correct token. This issue can be analyzed using XRA but cannot be evaluated by conventional retrieval accuracy metrics. Such cases and also further details about this experiment are shown in Appendix C.7. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "7 Discussion and conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Mamba models have emerged as an efficient alternative to Transformers. However, there are limited works addressing their interpretability [4, 84]. To address this issue, we proposed MambaLRP within the LRP framework, specifically tailored to the Mamba architecture and built upon the relevance conservation principle. Our evaluations across various models and datasets confirmed that MambaLRP adheres to the conservation property and provides faithful explanations that outperform other methods while being more computationally efficient. Moreover, we demonstrated how MambaLRP can help users debug state-of-the-art vision and language models while building trust in their predictions through various use cases. Future research can explore its potential across a broader range of applications and Mamba architectures, providing reliable insights into sequence models. ", "page_idx": 9}, {"type": "text", "text": "Limitations As a propagation-based explanation method, MambaLRP requires storing activations and gradients, leading to memory usage that depends on the model architecture and input sequence length. To reduce memory consumption, techniques such as gradient checkpointing can be utilized, which are applicable to other gradient-based methods as well. However, a limitation of these methods, including MambaLRP, is the potential inaccessibility of gradient information due to proprietary constraints. In such cases, approximating gradient information may offer a viable solution. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was funded by the German Ministry for Education and Research (refs. 01IS14013A-E, 01GQ1115, 01GQ0850, 01IS18025A, 031L0207D, 01IS18037A). K.R.M. was partly supported by the Institute of Information & Communications Technology Planning & Evaluation (IITP) grants funded by the Korea government (MSIT) (No. 2019-0-00079, Artificial Intelligence Graduate School Program, Korea University and No. 2022-0-00984, Development of Artificial Intelligence Technology for Personalized Plug-and-Play Explanation and Verification of Explanation). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] S. Abnar and W. Zuidema. Quantifying attention flow in transformers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4190\u20134197, Online, July 2020. Association for Computational Linguistics.   \n[2] R. Achtibat, S. M. V. Hatef,i M. Dreyer, A. Jain, T. Wiegand, S. Lapuschkin, and W. Samek. AttnLRP: Attention-aware layer-wise relevance propagation for transformers. arXiv:2402.05602, 2024.   \n[3] A. Ali, T. Schnake, O. Eberle, G. Montavon, K.-R. M\u00a8uller, and L. Wolf. XAI for transformers: Better explanations through conservative propagation. In International Conference on Machine Learning, ICML 2022, volume 162 of Proceedings of Machine Learning Research, pages 435\u2013451. PMLR, 2022.   \n[4] A. Ali, I. Zimerman, and L. Wolf. The hidden attention of mamba models. arXiv:2403.01590, 2024.   \n[5] C. An, F. Huang, J. Zhang, S. Gong, X. Qiu, C. Zhou, and L. Kong. Training-free long-context scaling of large language models. In R. Salakhutdinov, Z. Kolter, K. Heller, A. Weller, N. Oliver, J. Scarlett, and F. Berkenkamp, editors, Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 1493\u20131510. PMLR, 21\u201327 Jul 2024. URL https://proceedings.mlr.press/v235/an24b.html.   \n[6] Q. Anthony, Y. Tokpanov, P. Glorioso, and B. Millidge. BlackMamba: Mixture of experts for state-space models. arXiv:2402.01771, 2024.   \n[7] L. Arras, J. Arjona-Medina, M. Widrich, G. Montavon, M. Gillhofer, K.-R. M\u00a8uller, S. Hochreiter, and W. Samek. Explaining and interpreting LSTMs. Explainable AI: Interpreting, explaining and visualizing deep learning, pages 211\u2013238, 2019.   \n[8] A. B. Arrieta, N. D. Rodr\u00b4\u0131guez, J. D. Ser, A. Bennetot, S. Tabik, A. Barbado, S. Garc\u00b4\u0131a, S. Gil-Lopez, D. Molina, R. Benjamins, R. Chatila, and F. Herrera. Explainable artificial intelligence (XAI): concepts, taxonomies, opportunities and challenges toward responsible AI. Inf. Fusion, 58:82\u2013115, 2020.   \n[9] Z\u02c7. Avsec, V. Agarwal, D. Visentin, J. R. Ledsam, A. Grabska-Barwinska, K. R. Taylor, Y. Assael, J. Jumper, P. Kohli, and D. R. Kelley. Effective gene expression prediction from sequence by integrating long-range interactions. Nature methods, 18(10):1196\u20131203, 2021.   \n[10] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. Mu\u00a8ller, and W. Samek. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one, 10(7):e0130140, 2015.   \n[11] D. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, and K.-R. M\u00a8uller. How to explain individual classification decisions. The Journal of Machine Learning Research, 11:1803\u20131831, 2010.   \n[12] Y. Bai, X. Lv, J. Zhang, H. Lyu, J. Tang, Z. Huang, Z. Du, X. Liu, A. Zeng, L. Hou, Y. Dong, J. Tang, and J. Li. LongBench: A bilingual, multitask benchmark for long context understanding. arXiv:2308.14508, 2023.   \n[13] E. Baron, I. Zimerman, and L. Wolf. 2-D SSM: A general spatial layer for visual transformers. arXiv:2306.06635, 2023.   \n[14] A. Behrouz and F. Hashemi. Graph Mamba: Towards learning on graphs with state space models. arXiv:2402.08678, 2024.   \n[15] S. Blu\u00a8cher, J. Vielhaben, and N. Strodthoff. Decoupling pixel filpping and occlusion strategy for consistent XAI benchmarks. arXiv:2401.06654, 2024.   \n[16] S. R. Bowman, G. Angeli, C. Potts, and C. D. Manning. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632\u2013642, Lisbon, Portugal, Sept. 2015. Association for Computational Linguistics.   \n[17] H. Chefer, S. Gur, and L. Wolf. Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 397\u2013406, 2021.   \n[18] H. Chefer, S. Gur, and L. Wolf. Transformer interpretability beyond attention visualization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 782\u2013791, 2021.   \n[19] G. Chen, X. Li, Z. Meng, S. Liang, and L. Bing. CLEX: Continuous length extrapolation for large language models. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id $\\cdot$ wXpSidPpc5.   \n[20] P. Chormai, J. Herrmann, K.-R. M\u00a8uller, and G. Montavon. Disentangled explanations of neural network predictions by finding relevant subspaces. IEEE Trans. Pattern Anal. Mach. Intell., 2022.   \n[21] T. Dao and A. Gu. Transformers are SSMs: Generalized models and efficient algorithms through structured state space duality. In R. Salakhutdinov, Z. Kolter, K. Heller, A. Weller, N. Oliver, J. Scarlett, and F. Berkenkamp, editors, Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 10041\u201310071. PMLR, 21\u201327 Jul 2024. URL https://proceedings.mlr.press/v235/dao24a.html.   \n[22] S. B. David, I. Zimerman, E. Nachmani, and L. Wolf. Decision S4: Efficient sequence-based rl via state spaces layers. In The Eleventh International Conference on Learning Representations, 2022.   \n[23] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In IEEE Computer Vision and Pattern Recognition (CVPR), pages 248\u2013255, 2009.   \n[24] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics, pages 4171\u20134186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.   \n[25] A.-K. Dombrowski, C. J. Anders, K.-R. Mu\u00a8ller, and P. Kessel. Towards robust explanations for deep neural networks. Pattern Recognition, 121:108194, 2022. ISSN 0031-3203.   \n[26] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021.   \n[27] O. Eberle, J. Bu\u00a8ttner, F. Kra\u00a8utli, K.-R. Mu\u00a8ller, M. Valleriani, and G. Montavon. Building and interpreting deep similarity models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(3):1149\u20131161, 2020.   \n[28] O. Eberle, I. Chalkidis, L. Cabello, and S. Brandl. Rather a nurse than a physician - contrastive explanations under investigation. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6907\u20136920. Association for Computational Linguistics, 2023.   \n[29] R. C. Fong and A. Vedaldi. Interpretable explanations of black boxes by meaningful perturbation. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 3449\u20133457, 2017.   \n[30] D. Y. Fu, T. Dao, K. K. Saab, A. W. Thomas, A. Rudra, and C. R\u00b4e. Hungry hungry hippos: Towards language modeling with state space models. arXiv:2212.14052, 2022.   \n[31] H. Gong, L. Kang, Y. Wang, X. Wan, and H. Li. nnMamba: 3D biomedical image segmentation, classification and landmark detection with state space model. arXiv:2402.03526, 2024.   \n[32] Y. Gong, Y.-A. Chung, and J. Glass. AST: Audio Spectrogram Transformer. In Proc. Interspeech 2021, pages 571\u2013575, 2021.   \n[33] A. Gu and T. Dao. Mamba: Linear-time sequence modeling with selective state spaces. arXiv:2312.00752, 2023.   \n[34] A. Gu, I. Johnson, K. Goel, K. Saab, T. Dao, A. Rudra, and C. R\u00b4e. Combining recurrent, convolutional, and continuous-time models with linear state space layers. Advances in Neural Information Processing Systems, 34:572\u2013585, 2021.   \n[35] A. Gu, K. Goel, and C. Re. Efficiently modeling long sequences with structured state spaces. In International Conference on Learning Representations, 2022.   \n[36] D. Gunning. DARPA\u2019s explainable artificial intelligence (XAI) program. In Proceedings of the 24th International Conference on Intelligent User Interfaces, IUI \u201919, page ii. Association for Computing Machinery, 2019.   \n[37] C.-P. Hsieh, S. Sun, S. Kriman, S. Acharya, D. Rekesh, F. Jia, Y. Zhang, and B. Ginsburg. RULER: What\u2019s the real context size of your long-context language models? arXiv:2404.06654, 2024.   \n[38] S. Jain and B. C. Wallace. Attention is not Explanation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics, pages 3543\u20133556, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.   \n[39] S. Lapuschkin, S. W\u00a8aldchen, A. Binder, G. Montavon, W. Samek, and K.-R. M\u00a8uller. Unmasking clever hans predictors and assessing what machines really learn. Nature communications, 10(1):1096, 2019.   \n[40] J. Liu, H. Yang, H.-Y. Zhou, Y. Xi, L. Yu, Y. Yu, Y. Liang, G. Shi, S. Zhang, H. Zheng, et al. Swin-UMamba: Mamba-based unet with imagenet-based pretraining. arXiv:2402.03302, 2024.   \n[41] Y. Liu, Y. Tian, Y. Zhao, H. Yu, L. Xie, Y. Wang, Q. Ye, and Y. Liu. VMamba: Visual state space model. arXiv:2401.10166, 2024.   \n[42] C. Lu, Y. Schroecker, A. Gu, E. Parisotto, J. Foerster, S. Singh, and F. Behbahani. Structured state space models for in-context reinforcement learning. Advances in Neural Information Processing Systems, 36, 2024.   \n[43] J. Ma, F. Li, and B. Wang. U-mamba: Enhancing long-range dependency for biomedical image segmentation. arXiv:2401.04722, 2024.   \n[44] J. Ma, F. Li, and B. Wang. U-mamba: Enhancing long-range dependency for biomedical image segmentation. arXiv preprint arXiv:2401.04722, 2024.   \n[45] X. Ma, C. Zhou, X. Kong, J. He, L. Gui, G. Neubig, J. May, and L. Zettlemoyer. Mega: Moving average equipped gated attention. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id $=$ qNLe3iq2El.   \n[46] H. Mehta, A. Gupta, A. Cutkosky, and B. Neyshabur. Long range language modeling via gated state spaces. arXiv:2206.13947, 2022.   \n[47] A. Mohtashami and M. Jaggi. Random-access infinite context length for transformers. In Advances in Neural Information Processing Systems, 2023.   \n[48] G. Montavon, W. Samek, and K.-R. M\u00a8uller. Methods for interpreting and understanding deep neural networks. Digital signal processing, 73:1\u201315, 2018.   \n[49] G. Montavon, A. Binder, S. Lapuschkin, W. Samek, and K.-R. Mu\u00a8ller. Layer-wise relevance propagation: An overview. Explainable AI: interpreting, explaining and visualizing deep learning, pages 193\u2013209, 2019.   \n[50] E. Nguyen, K. Goel, A. Gu, G. Downs, P. Shah, T. Dao, S. Baccus, and C. Re\u00b4. S4nd: Modeling images and videos as multidimensional signals with state spaces. Advances in Neural Information Processing Systems, 35:2846\u20132861, 2022.   \n[51] G. Paulo, T. Marshall, and N. Belrose. Does transformer interpretability transfer to rnns?, 2024. URL https://arxiv.org/abs/2404.05971.   \n[52] B. Peng, E. Alcaide, Q. Anthony, A. Albalak, S. Arcadinho, S. Biderman, H. Cao, X. Cheng, M. Chung, L. Derczynski, X. Du, M. Grella, K. Gv, X. He, H. Hou, P. Kazienko, J. Kocon, J. Kong, B. Koptyra, H. Lau, J. Lin, K. S. I. Mantri, F. Mom, A. Saito, G. Song, X. Tang, J. Wind, S. Wo\u00b4zniak, Z. Zhang, Q. Zhou, J. Zhu, and R.-J. Zhu. RWKV: Reinventing RNNs for the transformer era. In H. Bouamor, J. Pino, and K. Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 14048\u201314077, Singapore, Dec. 2023. Association for Computational Linguistics. doi: 10.18653/v1/ 2023.findings-emnlp.936. URL https://aclanthology.org/2023.findings-emnlp.936.   \n[53] M. Pi\u00b4oro, K. Ciebiera, K. Kr\u00b4ol, J. Ludziejewski, and S. Jaszczur. MoE-Mamba: Efficient selective state space models with mixture of experts. arXiv:2401.04081, 2024.   \n[54] Z. Qin, S. Yang, and Y. Zhong. Hierarchically gated recurrent neural network for sequence modeling. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview. net/forum?id=P1TCHxJwLB.   \n[55] N. Rajani, L. Tunstall, E. Beeching, N. Lambert, A. M. Rush, and T. Wolf. No robots. https:// huggingface.co/datasets/HuggingFaceH4/no_robots, 2023.   \n[56] J. Ruan and S. Xiang. VM-UNet: Vision mamba UNet for medical image segmentation. arXiv:2402.02491, 2024.   \n[57] W. Samek, A. Binder, G. Montavon, S. Lapuschkin, and K.-R. Mu\u00a8ller. Evaluating the visualization of what a deep neural network has learned. IEEE Transactions on Neural Networks and Learning Systems, 28(11): 2660\u20132673, 2017.   \n[58] W. Samek, G. Montavon, S. Lapuschkin, C. J. Anders, and K.-R. Mu\u00a8ller. Explaining deep neural networks and beyond: A review of methods and applications. Proc. IEEE, 109(3):247\u2013278, 2021.   \n[59] G. Saon, A. Gupta, and X. Cui. Diagonal state space augmented transformers for speech recognition. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 1\u20135. IEEE, 2023.   \n[60] E. Saravia, H. T. Liu, Y. Huang, J. Wu, and Y. Chen. CARER: contextualized affect representations for emotion recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 3687\u20133697. Association for Computational Linguistics, 2018.   \n[61] G. Sarti, N. Feldhus, L. Sickert, O. van der Wal, M. Nissim, and A. Bisazza. Inseq: An interpretability toolkit for sequence generation models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pages 421\u2013435, Toronto, Canada, July 2023. Association for Computational Linguistics.   \n[62] T. Schnake, O. Eberle, J. Lederer, S. Nakajima, K. T. Schu\u00a8tt, K.-R. Mu\u00a8ller, and G. Montavon. Higher-order explanations of graph neural networks via relevant walks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(11):7581\u20137596, 2022.   \n[63] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra. Grad-CAM: Visual explanations from deep networks via gradient-based localization. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 618\u2013626, 2017.   \n[64] A. Shrikumar, P. Greenside, and A. Kundaje. Learning important features through propagating activation differences. In Proceedings of the 34th International Conference on Machine Learning - Volume 70, ICML\u201917, page 3145\u20133153, 2017.   \n[65] D. Smilkov, N. Thorat, B. Kim, F. B. Vie\u00b4gas, and M. Wattenberg. SmoothGrad: removing noise by adding noise. arXiv:1706.03825, 2017.   \n[66] J. T. Smith, A. Warrington, and S. Linderman. Simplified state space layers for sequence modeling. In The Eleventh International Conference on Learning Representations, 2023.   \n[67] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y. Ng, and C. Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1631\u20131642. ACL, 2013.   \n[68] M. Sundararajan, A. Taly, and Q. Yan. Axiomatic attribution for deep networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 3319\u20133328. PMLR, 2017.   \n[69] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.   \n[70] C. Wang, O. Tsepa, J. Ma, and B. Wang. Graph-Mamba: Towards long-range graph sequence modeling with selective state spaces. arXiv:2402.00789, 2024.   \n[71] J. Wang, W. Zhu, P. Wang, X. Yu, L. Liu, M. Omar, and R. Hamid. Selective structured state-spaces for long-form video understanding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6387\u20136397, 2023.   \n[72] J. Wang, T. Gangavarapu, J. N. Yan, and A. M. Rush. MambaByte: Token-free selective state space model. arXiv:2401.13660, 2024.   \n[73] Z. Wang and C. Ma. Semi-Mamba-UNet: Pixel-level contrastive cross-supervised visual mamba-based unet for semi-supervised medical image segmentation. arXiv:2402.07245, 2024.   \n[74] Z. Wang, J.-Q. Zheng, Y. Zhang, G. Cui, and L. Li. Mamba-UNet: UNet-like pure visual mamba for medical image segmentation. arXiv:2402.05079, 2024.   \n[75] S. Wiegreffe and Y. Pinter. Attention is not not explanation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 11\u201320, Hong Kong, China, 2019. Association for Computational Linguistics.   \n[76] Z. Xing, T. Ye, Y. Yang, G. Liu, and L. Zhu. SegMamba: Long-range sequential modeling mamba for 3d medical image segmentation. arXiv:2401.13560, 2024.   \n[77] J. N. Yan, J. Gu, and A. M. Rush. Diffusion models without attention. arXiv:2311.18257, 2023.   \n[78] Y. Yang, Z. Xing, and L. Zhu. Vivim: a video vision mamba for medical video object segmentation. arXiv:2401.14168, 2024.   \n[79] Z. Yang, P. Qi, S. Zhang, Y. Bengio, W. W. Cohen, R. Salakhutdinov, and C. D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Conference on Empirical Methods in Natural Language Processing (EMNLP), 2018.   \n[80] K. Yin and G. Neubig. Interpreting language models with contrastive explanations. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 184\u2013198, Abu Dhabi, United Arab Emirates, Dec. 2022. Association for Computational Linguistics.   \n[81] M. D. Zeiler and R. Fergus. Visualizing and understanding convolutional networks. In Computer Vision\u2013 ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13, pages 818\u2013833. Springer, 2014.   \n[82] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and W. Zhang. Informer: Beyond efficient transformer for long sequence time-series forecasting. In The Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Virtual Conference, volume 35, pages 11106\u201311115. AAAI Press, 2021.   \n[83] L. Zhu, B. Liao, Q. Zhang, X. Wang, W. Liu, and X. Wang. Vision Mamba: Efficient visual representation learning with bidirectional state space model. arXiv:2401.09417, 2024.   \n[84] I. Zimerman, A. Ali, and L. Wolf. A unified implicit attention formulation for gated-linear recurrent sequence models, 2024. URL https://arxiv.org/abs/2405.16504.   \n[85] L. M. Zintgraf, T. S. Cohen, T. Adel, and M. Welling. Visualizing deep neural network decisions: Prediction difference analysis. In International Conference on Learning Representations, 2017. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In the following, we provide derivations for the conservation analysis performed in Section 4. ", "page_idx": 14}, {"type": "text", "text": "A.1 Derivations for SiLU ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We first consider the SiLU activation function. As mentioned in Section 4.1, this function is represented by the equation $y=x\\cdot\\sigma(x)$ , with $\\sigma$ being the logistic sigmoid function. By applying the standard gradient propagation equations, we get the conservation equation: ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{{\\overbrace{\\partial x^{r}}^{\\mathcal{\\alpha}(x)}}={\\cfrac{\\partial f}{\\partial y}}{\\frac{\\partial y}{\\partial x}}x}\\\\ &{\\qquad={\\frac{\\partial f}{\\partial y}}\\cdot(\\sigma(x)+x\\sigma^{\\prime}(x))\\cdot x}\\\\ &{\\qquad={\\cfrac{\\partial f}{\\partial y}}\\cdot\\sigma(x)\\cdot x+{\\cfrac{\\partial f}{\\partial y}}\\cdot x\\sigma^{\\prime}(x)\\cdot x}\\\\ &{\\qquad={\\cfrac{\\partial f}{\\partial y}}y+{\\cfrac{\\partial f}{\\partial y}}\\cdot\\sigma^{\\prime}(x)\\cdot x^{2}}\\\\ &{\\qquad={\\cfrac{\\partial f}{\\partial y}}\\enspace{\\cfrac{\\partial f}{\\partial}}\\enspace{\\cfrac{\\partial\\sigma^{\\prime}}{\\partial z}}\\enspace.}\\end{array}}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.2 Derivations for selective SSM ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In Section 4.2, we introduced an inconsequential modification to the original selective SSM architecture by connecting the matrix $C_{t}$ to the state $h_{t}$ instead of the input $x_{t}$ . The unfolded view of the SSM component with this modification is represented in Fig. 2. We can observe two subsets of nodes in this figure. The relevance scores of these two subsets should be equal if the conservation property holds. Computing the relevance propagation equation between these two groups, we obtain: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\mathcal{R}_{(x)+}+\\mathcal{R}_{(h-1)}}{\\partial x_{t}}h_{t-1}=\\Big(\\frac{\\partial f}{\\partial h_{t}}\\frac{\\partial^{+}h_{t}}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial\\theta_{t}}\\frac{\\partial\\theta_{t}}{\\partial x_{t}}x_{t}\\Big)}\\\\ &{\\phantom{\\frac{\\partial f}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial h_{t-1}}\\frac{\\partial f}{\\partial h_{t-1}}}\\qquad+\\Big(\\frac{\\partial f}{\\partial y_{t}-1}\\frac{\\partial^{+}y_{t-1}}{\\partial h_{t-1}}h_{t-1}+\\frac{\\partial f}{\\partial h_{t}}\\frac{\\partial h_{t}}{\\partial h_{t-1}}h_{t-1}+\\frac{\\partial f}{\\partial\\theta_{t}}\\frac{\\partial\\theta_{t}}{\\partial h_{t-1}}h_{t-1}\\Big)}\\\\ &{\\phantom{\\frac{\\partial f}{\\partial x_{t}}\\frac{\\partial^{+}h_{t}}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial h_{t}}\\frac{\\partial h_{t}}{\\partial h_{t-1}}h_{t-1}\\Big)+\\Big(\\frac{\\partial f}{\\partial y_{t-1}}\\frac{\\partial^{+}y_{t-1}}{\\partial h_{t-1}}h_{t-1}\\Big)}\\\\ &{\\phantom{\\frac{\\partial f}{\\partial x_{t}}\\frac{\\partial^{+}h_{t}}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial\\theta_{t}}\\frac{\\partial\\theta_{t}}{\\partial h_{t-1}}h_{t-1}}\\\\ &{\\phantom{\\frac{\\partial f}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial y_{t-1}}y_{t-1}+\\frac{\\partial f}{\\partial t}\\frac{\\partial\\theta_{t}}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial\\theta_{t}}\\frac{\\partial\\theta_{t}}{\\partial h_{t-1}}h_{t-1}}\\\\ &{\\phantom{\\frac{\\partial f}{\\partial x_{t}}x_{t}+\\frac{\\partial f}{\\partial x_{t-1}}y_{t-1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.3 Derivations for multiplicative gate ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Mamba is composed of several blocks. In each block, the selective SSM\u2019s output is multiplied by an input-dependent gate. In other words, $y=z_{A}z_{B}$ with $z_{A}=\\operatorname{SSM}(x)$ and $z_{B}=\\mathrm{SiLU}(\\mathrm{Linear}(x))$ . By applying the standard gradient propagation equations, we get the conservation equation: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overbrace{\\frac{\\partial f}{\\partial x}}^{\\mathcal{R}(x)}=\\frac{\\partial f}{\\partial y}\\frac{\\partial y}{\\partial x}x}\\\\ &{\\qquad=\\frac{\\partial f}{\\partial y}\\cdot\\left(\\frac{\\partial z_{A}}{\\partial x}z_{B}+z_{A}\\frac{\\partial z_{B}}{\\partial x}\\right)x}\\\\ &{\\qquad=\\frac{\\partial f}{\\partial y}\\cdot\\left(z_{A}z_{B}+z_{A}z_{B}\\right)}\\\\ &{\\qquad=\\underbrace{\\frac{\\partial f}{\\partial y}y}_{\\mathcal{R}(y)}+\\underbrace{\\frac{\\partial f}{\\partial y}y}_{\\mathcal{C}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "B Explicit propagation rules for MambaLRP ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Whereas MambaLRP is more easily implemented via the modified gradient-based approach described in the main paper, we provide below explicit relevance propagation equations for better comparability with other works. We refer to Sections 3 and 4 of the main paper for the definition of the notation. ", "page_idx": 15}, {"type": "text", "text": "B.1 SiLU ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Explicit LRP rule for SiLU layers: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{R}(x_{i})=\\mathcal{R}(y_{i})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "B.2 SSM ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Using the shortcut notations $a_{i j}=[A_{t}(x_{t})]_{j i}$ , $b_{i j}=[B_{t}({x_{t}})]_{j i}$ and $c_{i j}=[C_{t-1}(h_{t-1})]_{j i}$ , we can write the propagation of relevance to the previous state space activations explicitly as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{R}(h_{i}^{(t-1)})=\\sum_{j}\\frac{h_{i}^{(t-1)}c_{i j}}{\\sum_{i}h_{i}^{(t-1)}c_{i j}}\\mathcal{R}(y_{j}^{(t-1)})+\\sum_{j}\\frac{h_{i}^{(t-1)}a_{i j}}{\\sum_{i}h_{i}^{(t-1)}a_{i j}+\\sum_{i^{\\prime}}x_{i^{\\prime}}^{(t)}b_{i^{\\prime}j}}\\mathcal{R}(h_{j}^{(t)})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and the propagation of relevance to the SSM input as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{R}(x_{i}^{(t)})=\\sum_{j}\\frac{x_{i}^{(t)}b_{i j}}{\\sum_{i}x_{i}^{(t)}b_{i j}+\\sum_{i^{\\prime}}h_{i^{\\prime}}^{(t-1)}a_{i^{\\prime}j}}\\mathcal{R}(h_{j}^{(t)})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "B.3 Multiplicative Gate ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Explicit LRP rule for the multiplicative gate: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{R}([z_{A}]_{i})=0.5\\cdot\\mathcal{R}(y_{i})}\\\\ {\\mathcal{R}([z_{B}]_{i})=0.5\\cdot\\mathcal{R}(y_{i})}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "C Experimental details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we provide experimental details on our experiments that allow reproducibility of our results. ", "page_idx": 15}, {"type": "text", "text": "C.1 Models and datasets ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "For the NLP experiments, we fine-tuned all parameters of the pretrained Mamba-130M, Mamba-1.4B, and Mamba-2.8B models2 on four text classification datasets: SST-2, SNLI, Medical BIOS, and Emotion. The data statistics can be seen in Table 5. For the vision experiments, we used the pretrained Vim-S model3, trained on the ImageNet dataset. ", "page_idx": 15}, {"type": "text", "text": "Training details During training, we used a batch size of 32. To train the Mamba-1.4B and Mamba2.8B models on the SNLI dataset, a batch size of 64 is used. We employed the {EleutherAI/gpt-neox$20\\mathrm{b}\\}^{4}$ tokenizer. The models\u2019 parameters were optimized using AdamW optimizer with a learning rate set at $7e-5$ . Additionally, we used a linear learning rate scheduler with an initial factor of 0.5. All models were trained for a maximum of 10 epochs. We employed early stopping and ended training as soon as the validation loss ceased to improve. The top-1 accuracies of the models on each dataset are detailed in Table 4. ", "page_idx": 16}, {"type": "text", "text": "Table 4: The accuracies of Mamba-130M, Mamba1.4B, and Mamba-2.8B models on the validation sets of four text classification datasets. ", "page_idx": 16}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/4a3c8f240a29b77a8c50f889347bd6db14075010629f3f03fbd25dd7ba5a7cce.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/64df607c9f0d172016f7190c5dd34621a62359a05e6863e553d3553fde9ad83e.jpg", "table_caption": ["Table 5: Data statistics. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "C.2 MambaLRP details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we begin by showing how MambaLRP can be implemented through the following algorithms. Then, we explain the generalized LRP- $\\gamma$ rule, provide details regarding hyperparameters used in our implementation, and outline the hyperparameter selection procedure. ", "page_idx": 16}, {"type": "text", "text": "Algorithm 1: MambaLRP in SiLU activation layer ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Data: Input: $x$ (B, L, D) 1 $z\\gets$ Identity $(x)$ 2 return $z\\odot[\\mathrm{SiLU}(x)\\odot z]\\,.$ .detach() ", "page_idx": 16}, {"type": "text", "text": "Algorithm 2: MambaLRP in Mamba block ", "page_idx": 16}, {"type": "text", "text": "1 $x^{\\prime}$ $\\mathrm{:}\\left(\\mathrm{B},\\mathrm{L},\\mathrm{E}\\right)\\mathrm{\\leftarrowSiLU}(\\mathrm{Conv}1\\mathrm{d}(x))$   \n2 $g$ $\\tau:(\\mathrm{B},\\mathrm{L},\\mathrm{E})\\gets\\mathrm{SiLU}(\\mathrm{Linear}(x))$ \u25b7 $g$ is an input-dependent gate   \n3 $A$ : $(\\mathrm{E},\\mathrm{N})\\gets$ Parameter   \n$4\\ B{:}\\ (\\mathrm{B,L,N})\\gets\\mathrm{Linear}(x^{\\prime})$   \n5 $:C!:(\\mathrm{B},\\mathrm{L},\\mathrm{N})\\gets\\mathrm{Linear}(x^{\\prime})$ \u25b7 $C$ is input-dependent   \n6 $\\Delta$ : (B, L, E) \u2190Softplus(Parameter + Linear(x\u2032))   \n7 $\\bar{A}$ , $\\bar{B}$ : (B, L, E, N) \u2190discretize(\u2206, A, B) \u25b7 $\\bar{A}$ and $\\bar{B}$ are input-dependent   \n8 $y_{\\mathtt{S S M}}$ : $(\\mathrm{B},\\mathrm{L},\\mathrm{E})\\gets\\mathrm{SSM}(\\bar{A}$ .detach(), B\u00af.detach(), $C$ .detach()) $(x^{\\prime})$   \n9 $y^{\\prime}$ : $\\mathrm{(B,L,E)}\\gets0.5(y_{\\mathrm{ssM}}\\odot g)+0.5[y_{\\mathrm{ssM}}\\odot g]$ .detach()   \n10 y: $(\\mathrm{B},\\mathrm{L},\\mathrm{D})\\gets\\mathrm{Linear}(y^{\\prime})$   \n11 return $y$ ", "page_idx": 16}, {"type": "text", "text": "The following list represents the hyperparameters of the above-mentioned algorithms: ", "page_idx": 16}, {"type": "text", "text": "B batch size L sequence length D hidden dimension E expanded hidden dimension N SSM dimension ", "page_idx": 16}, {"type": "text", "text": "Explanations generated by propagation-based methods rely on gradient computations, which can result in noisy explanations in models with many layers. This is due to the phenomena of gradient shattering and the presence of noisy gradients, which are more common in deep complex models [25, 2]. To mitigate this, we apply the generalized LRP- $\\gamma$ -rule to the convolution layers of the Vision Mamba model to improve the signal to noise ratio, thereby enhancing explanations. The generalized LRP- $\\gamma$ rule is defined in Eq. 18: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathscr{R}(x_{i})=\\left\\{\\begin{array}{l l}{\\sum_{j}\\frac{x_{i}^{+}(w_{i j}+\\gamma w_{i j}^{+})+x_{i}^{-}(w_{i j}+\\gamma w_{i j}^{-})}{\\sum_{i}x_{i}^{+}(w_{i j}+\\gamma w_{i j}^{+})+x_{i}^{-}(w_{i j}+\\gamma w_{i j}^{-})}\\mathscr{R}(y_{j})\\quad\\mathrm{if}\\quad z_{j}>0}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ {\\sum_{j}\\frac{x_{i}^{+}(w_{i j}+\\gamma w_{i j}^{-})+x_{i}^{-}(w_{i j}+\\gamma w_{i j}^{+})}{\\sum_{i}x_{i}^{+}(w_{i j}+\\gamma w_{i j}^{-})+x_{i}^{-}(w_{i j}+\\gamma w_{i j}^{+})}\\mathscr{R}(y_{j})\\quad\\mathrm{else}}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $(.)^{+}=\\operatorname*{max}(0,.)$ and $(.)^{-}=\\operatorname*{min}(0,.)$ , and $\\begin{array}{r}{z_{j}=\\sum_{i}x_{i}w_{i j}}\\end{array}$ . In our experiments, the parameter $\\gamma$ is set to 0.25. Our observations reveal that applying t his rule to the language models does not lead to any discernible improvements. Therefore, we use the LRP-0 rule in these models. ", "page_idx": 17}, {"type": "text", "text": "C.2.1 LRP composites for Vision Mamba ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "As mentioned in Section C.2, we apply the generalized ${\\mathrm{LRP}}-\\gamma$ rule to the convolution layers of the Vim-S model to produce more faithful explanations. In this experiment, we justify this choice. Vision Mamba is composed of a number of blocks and in each block, there are several linear and convolution layers, where the generalized LRP- $\\gamma$ rule can be used. As can be seen in Table 6, the LRP-0 rule is sufficient to produce meaningful explanations. However, we can perform a hyperparameter search by applying the $\\mathrm{LRP-}\\gamma$ rule across different layers of the model to find the most accurate LRP composite. ", "page_idx": 17}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/1a6743e6e02ecdff2c279e65c6d1ae0e0b255e6f25ec7169c6654f28726dd16d.jpg", "table_caption": ["Table 6: Finding the best LRP composite for Vision Mamba. The layers in which the generalized $\\mathrm{LRP-}\\gamma$ rule is applied are represented with LRP- $\\gamma$ and the ones in which the basic LRP rule, i.e. LRP-0, is used are represented with LRP-0. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "We apply the $\\mathrm{LRP-}\\gamma$ rule across different combinations of the input projection (in-proj), output projection (out-proj), and convolution layers of each block. Subsequently, we perform the perturbation experiment to analyze the faithfulness of each combination. We can observe that the best result can be achieved when the LRP- $\\gamma$ rule is only used in convolution layers. In all of these combinations, the value of $\\gamma$ is set to 0.25. ", "page_idx": 17}, {"type": "text", "text": "C.3 Further details of other explanation methods ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Some of the explanation methods that we used in this study have a set of hyperparameters. Table 7 provides further details on the specific values assigned to these hyperparameters, chosen based on the values suggested in the original papers [68, 65]. ", "page_idx": 17}, {"type": "text", "text": "In the vision experiments, we used the original implementations 5 of the AttnRoll and MambaAttr methods, provided to explain the Vim-S model. Given the unavailability of code for adapting these approaches to the language models, namely Mamba-130M, Mamba-1.4B, and Mamba-2.8B, we have developed our own implementation. In the vision case, the authors obtain the final relevance map by ", "page_idx": 17}, {"type": "text", "text": "Table 7: Hyperparameters of other explanation methods. The parameters $\\mu$ and $\\sigma$ represent the mean and standard deviation of noise, respectively, while the parameter $m$ denotes the sample size. ", "page_idx": 18}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/aab11cbcb2a97c81cf870c027194c119f893f99f0ef721db62443ad2f5d7cae8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/070f751b1347fe0ac50423ce14d87c0ef19b8a67e9f94a93328c0076130458fe.jpg", "table_caption": ["Table 8: Comparing the proposed strategies for managing the Mamba block\u2019s multiplicative gate. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "extracting the row associated with the CLS token in the attention matrix. However, since our language models lack a CLS token, we get the final relevance map from the row associated with the last token in the attention matrix. This is because predictions are based on the last state in these models. For the gradient-based methods, we use the implementations available in the Captum library6. ", "page_idx": 18}, {"type": "text", "text": "C.4 Further details on evaluation metrics ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As mentioned in Section 5.3, the flipping and insertion metrics can be used to evaluate the quality of the generated explanations. It is important to note that starting with unperturbed images and gradually applying perturbations until fully perturbed images are obtained yields identical results for both the flipping and insertion metrics. Therefore, we have only reported the results for the flipping experiment. ", "page_idx": 18}, {"type": "text", "text": "In our filpping evaluations, we calculate the area under the curve (AUC) by starting from full images and progressively masking the pixels with zeros until we reach completely masked images. The perturbation steps are defined using np.linspace(0, 1, 11) . In our vision experiments, Images are normalized using the ImageNet mean and standard deviation, and the explanations are generated and evaluated for the predicted class. Unlike [4], which tracks changes in the model\u2019s top-1 accuracy, we monitor changes in the output logit of the predicted class. ", "page_idx": 18}, {"type": "text", "text": "C.5 Further ablation experiments ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Comparing strategies for managing the Mamba block\u2019s multiplicative gate: In Section 4.3, we proposed several strategies to mitigate conservation violation in the Mamba block\u2019s multiplicative gate. In this experiment, we evaluate the proposed approaches. As can be seen in Table 8, detaching the multiplicative gate $z_{B}$ leads to lower faithfulness scores compared to the half-relevance propagation approach. To retain conservation, an alternative approach is to detach the SSM\u2019s output $z_{A}$ , which limits capturing long-range dependencies, a task for which this branch is designed for. Detaching it may result in a loss of valuable information used by the model to make predictions. Therefore, this approach is not considered in Table 8. ", "page_idx": 18}, {"type": "text", "text": "C.6 Additional qualitative results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In Section 5.2, we qualitatively evaluated the explanations produced by MambaLRP and other baseline methods. In the following, we demonstrate further qualitative results. ", "page_idx": 18}, {"type": "text", "text": "C.6.1 Natural language processing ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In the following figures, we represent explanations produced by MambaLRP and other baseline methods to interpret the Mamba-130M models trained on various datasets. In the visualizations, shades of red represent words that positively influence the model\u2019s prediction. Conversely, shades of blue reflect negative contributions. The heatmaps of the AttnRoll and MambaAttr methods are constrained to non-negative values. ", "page_idx": 18}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/e41aa1c0cda0995515f6b5428041b18e56ff8ff1da6794cea06d66eb952683eb.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/6926c45c351ced6438d816028750f03447d737e5e5b24659ca0f1374c3e52a61.jpg", "table_caption": ["Figure 8: Explanations generated by different explanation methods for a sentence of the SNLI validation set. This sentence belongs to the \u2018entailment\u2019 class. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Figure 9: Explanations generated by different explanation methods for a sentence of the SNLI validation set. This sentence belongs to the \u2018contradiction\u2019 class. ", "page_idx": 19}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/4f5561c1dba977557c2264c5a774fdf59a1102e337c3b973e964e0613cf1602a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Figure 10: Explanations generated by different explanation methods for a sentence of the Emotion validation set. This sentence belongs to the \u2018joy\u2019 class. ", "page_idx": 19}, {"type": "text", "text": "C.6.2 Computer vision ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section, we show explanations generated by MambaLRP alongside other baseline methods to interpret the predictions of the Vim-S model on several images of the ImageNet dataset. As can be seen, explanations generated by purely gradient-based explanation methods are very noisy. In contrast, attention-based attribution methods have offered more focused and less noisy heatmaps. However, in the last two images labeled \u2018paint brush\u2019 and \u2018flag pole\u2019, they could not faithfully explain the model\u2019s predictions. Among these approaches, MambaLRP stands out with its ability to generate sparse explanations, offering more faithful explanations of how different image patches contribute to the final predictions. ", "page_idx": 19}, {"type": "text", "text": "C.7 Additional use case results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For the needle-in-a-haystack experiment in Section 6, we use a synthetic dataset 7. In this dataset, a single passkey (the \u2018needle\u2019) is inserted at different locations within a collection of repeated noise sentences (the \u2018haystack\u2019), as described in [37]. The dataset is composed of sequences with different context lengths. In our experiment, we use sequences with context lengths of 512, 1024, and 2048. We restrict the maximum context length to 2048 tokens to align with the model\u2019s training configuration, as this experiment is not designed to evaluate extrapolation beyond this limit. The goal is to focus on certain limitations of the retrieval accuracy metric and and the solutions provided by MambaLRP. We use a Mamba-2.8B model 8, which is finetuned on the No Robots dataset [55] using a context length of 2048. Then, we prompt the model to extract the passkey hidden among irrelevant text by completing the phrase \u201cThe passkey is \u201d. ", "page_idx": 19}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/f1a4e4d1aae78c78986ece5faf2c5905cfe6e2dedbf25705f965906e95548dce.jpg", "table_caption": ["Figure 11: Explanations generated by different explanation methods for a sentence of the Medical BIOS validation set. This sentence belongs to the \u2018nurse\u2019 class. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "Retrieval accuracy is a metric, which is commonly used in the needle-in-a-haystack experiment to analyze the model\u2019s performance. The synthetic dataset used for this experiment can be designed to include misleading information, which may cause the model to generate the correct passkey based on incorrect evidence. In such cases, simply evaluating the retrieval accuracy may be insufficient. This issue can also arise when dealing with more realistic haystacks. Therefore, we introduced explanation-based retrieval accuracy (XRA) in Section 6. MambaLRP and the XRA metric designed upon it can help to better examine the evidence the model relies on to retrieve the needle. In this approach, we first identify the positions of the top-K relevant tokens by MambaLRP, and then, calculate the accuracy by comparing those positions to the needle\u2019s position. We set the value of K to 2. This is because MambaLRP identifies the token immediately preceding the generated token as the most important one in most of the examples and the evidence used for the passkey retrieval is usually the second most important token. ", "page_idx": 20}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/3b8331d54dd1b2ea3d4b2288f78b7d4a1325266bffff1e0a804cbc97c8dfeca6.jpg", "img_caption": ["Figure 12: Explanations produced by different explanation methods for images of the ImageNet dataset. Explanations produced by AttnRoll and MambaAttr are limited to non-negative values, whereas those generated by gradient-based techniques and MambaLRP includes both positive and negative contributions. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "The sample in Fig. 13 represents a scenario where our XRA approach proves valuable. In this case, the next token generated by the model is the second part of the correct passkey (300). However, the model has incorrectly focused on the number 300 in the phrase \u201cPass the key to room $6300^{\\circ}$ to generate this token. Simply looking at the retrieved token might suggest that the model successfully retrieved the correct information. However, examining the MambaLRP\u2019s explanation heatmaps provides deeper insights into the model\u2019s behavior. This helps us to debug the model more effectively and design better tests to analyze its capabilities. ", "page_idx": 21}, {"type": "text", "text": "C.8 Long-range dependeny comparison to Transformers ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "To explore the capabilities of different model architectures in handling long-range dependencies, we performed a direct comparison between Mamba and state-of-the-art Transformers (Llama- ${\\mathcal{I}}^{9}$ and Llama- $3^{10}$ ), focusing on their performance with inputs exceeding typical context lengths. ", "page_idx": 21}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/09e22e7a707f1ecd0c0a0278ac60b3cbe0b5edd1b1cac71d2ab2c0105df23bf5.jpg", "img_caption": ["Figure 13: Detecting Clever-Hans effect in the needle-in-a-haystack test. Given the 2K context length in this example, visualizing the entire text could be confusing. Therefore, we have removed most of the haystack from the visualization. In this example, the model has generated the correct passkey but the generation is not based on truly relevant information in the text. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "For Llama-2 and Llama-3, we extract attributions using LRP for Transformers [3]. As in the Mamba experiment, we generate 10 additional tokens from the HotPotQA dataset input and explain the prediction for each generated token. The results are shown in Table 9. For Llama-2, which was trained with a context length of 4096, the generated text becomes increasingly less sensible and repetitive for contexts longer than $4\\mathbf{k}$ , a limitation noted also in [19, 5]. When analyzing the histogram distribution over tokens considered relevant to predict the next token, it appears that Llama-2 uses information more uniformly across the entire context and identifies more relevant long-range dependent tokens compared to Llama-3 and Mamba. However, as presented in Table 9, its output becomes nonsensical for context lengths exceeding 4K tokens, characterized by the use of rare vocabulary and repeated tokens. Thus, the identified relevant tokens are mostly non-semantic such as new line token $^{\\bullet}{<}0\\mathrm{x}0\\mathrm{A}{>}^{\\bullet}$ in Llama-2 and beginning of sentence token $\\mathbf{\\check{\\Phi}}<\\mathbf{s}>\\mathbf{\\check{\\Phi}}$ found at the start of the context paragraphs. For Llama-3 and Mamba, the attributions can identify meaningful relevant tokens. When directly compared, Llama-3 uses information from more intermediate mid-range dependencies than Mamba, though both favor tokens close to the end of the input as relevant. Given Llama-3\u2019s much larger size (8B) compared to Mamba (130M) and their different training settings, this analysis supports that Mamba indeed uses long-range information. We also find that this ability is not exclusive to SSMs and can in principle also be achieved by Transformer models. ", "page_idx": 22}, {"type": "text", "text": "To what extent these findings depend on the amount of training data and model complexity remains an open research question. Our investigation of long-range dependencies in recent sequence generation models highlights the value of faithful attribution methods like MambaLRP in examining the capabilities and mechanisms utilized by models during generation. ", "page_idx": 22}, {"type": "text", "text": "C.9 Runtime comparison ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we report the time required for each explanation method to generate its respective explanation. These times, measured in seconds, are averaged over samples from the Medical BIOS dataset. All baseline methods are evaluated on a single A100-40GB GPU with a batch size of 1. All methods are applied to the Mamba-130M model. The results without fast CUDA kernels are shown in Table 10, while the results with fast CUDA kernels are presented in Table 11. We can observe that the runtime of MambaLRP is comparable to Gradient $.\\times$ Input. Since algorithms like Integrated Gradients and SmoothGrad require multiple function evaluations, their runtimes are significantly higher than MambaLRP and Gradien $.\\times$ Input. ", "page_idx": 22}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/b2affbc7184014d73b7b520d8792fc762829de5db0bb4def325e9bdded5bfaf1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "2n1Ysn1EDl/tmp/968011aae5051e13eb10c9ffbffc6ab32ba7156b7d77668e60d10c196cb4e431.jpg", "img_caption": ["Table 9: Long-Range dependency experiment, comparing Transformers and Mamba for different context lengths. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 10: Runtime comparison. The time needed for each baseline method to generate its explanations. The times, measured in seconds, are averaged over the samples from the Medical BIOS dataset. The model used in this experiment is Mamba-130M without using fast CUDA kernels. ", "page_idx": 23}, {"type": "text", "text": "Table 11: Runtime comparison. The time needed for each baseline method to generate its explanations. The times, measured in seconds, are averaged over the samples from the Medical BIOS dataset. The model used in this experiment is Mamba-130M using fast CUDA kernels. ", "page_idx": 23}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/383a7464c729078d4a9e52d05f1d5b97c7752f234f23b42e627dcd95dfb1bb45.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "2n1Ysn1EDl/tmp/14f92c5afac9a37c200338e5fec69ca2634bb49b8b23895c6d3987055d9b2ca0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: All claims are addressed in Sections 4, 5, and 6 of the main paper and further details regarding each section can be found in the supplemental material. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: We discuss the computational efficiency of our method including runtime comparisons in Section 5. We further critically assess the performance of our approach via a number of ablation studies presented in Section 5 in the main paper and in the supplemental materials in Section C.2.1 and Section C.5. Limitations regarding scope and possible future directions are mentioned in Section 7. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We state our assumptions and theoretical results in Section 4 of the main paper alongside proofs given in Sections A.1, A.2, and A.3 in the supplemental material. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We provide necessary information for reproducing our results in Section 4 of the main paper and Section C.2 of the supplemental material. Details of our proposed method and how it can be implemented can be found in Section C.2 of the supplemental material. Please refer to Section 5 of the paper and Section C of the supplemental material for more details regarding the experiments. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 25}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The code for reproducing our results and implementation of our proposed method is publicly accessible and a link to our code repository is added to the main paper. The datasets used in this work are publicly available, and comprehensive instructions for implementing our MambaLRP method can be found in Section C.2 of the supplemental material. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: Please check Section 5 in the paper for details about experimental setting and evaluation metrics. Further details can be found in Section C of the appendix. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Please check Section 5.3 of the paper. Further experimental results can be found in Section C.5 in the appendix. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Please check Appendix C.9. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We do not anticipate any harmful risks from the methods and analyses presented in this work. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: The positive societal impacts of our work regarding model explainability are mentioned in multiple parts of the paper, in particular Section 6. We do not anticipate any negative societal impact from the methods and analyses presented in this work. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: All datasets and models used in the paper are properly cited. We have also provided links to libraries and code repositories used, in the supplemental material. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] Justification: C ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]