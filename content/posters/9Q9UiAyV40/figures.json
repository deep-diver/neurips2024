[{"figure_path": "9Q9UiAyV40/figures/figures_1_1.jpg", "caption": "Figure 1: MSPE results on ImageNet-1K. We loaded a ViT-B model pre-trained on ImageNet-21K from [19] and evaluated: (a) Height equals width, ranging from 28\u00d728 to 896\u00d7896, and (b) Fixed height=128, width ranging from 28 to 896. Vanilla ViT performance drops with size/aspect ratio changes; FlexiViT [15] significantly improves performance, and our method surpasses FlexiVIT.", "description": "This figure shows the ImageNet-1K Top-1 accuracy results of three different methods: Vanilla ViT, FlexiViT, and the proposed MSPE method.  It compares their performance across a range of input image resolutions, with two sets of experiments: (a) where the height and width of the image are equal, and (b) where the height is fixed at 128 pixels while the width varies. The results demonstrate that Vanilla ViT's performance significantly degrades as the aspect ratio changes, while FlexiViT shows improvement. The MSPE method outperforms both Vanilla ViT and FlexiViT, especially at lower resolutions.", "section": "1 Introduction"}, {"figure_path": "9Q9UiAyV40/figures/figures_3_1.jpg", "caption": "Figure 2: Similarity in patch embeddings does not guarantee optimal performance (a). We confirm this by evaluating the accuracy and cosine similarity of: (b) patch embeddings {z}\u2081from 56x56 and 224x224 images, and (c) class tokens zcls from 56x56 and 224x224 images.", "description": "This figure demonstrates that similar patch embeddings do not imply similar classification performance.  It shows that while FlexiViT achieves higher patch embedding similarity than the vanilla model and our method, our method surpasses both in classification accuracy.  This highlights the importance of considering the entire pipeline, including the transformer encoder, rather than solely focusing on patch embedding similarity.", "section": "2 Preliminaries and Analysis"}, {"figure_path": "9Q9UiAyV40/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of the ViT model [2, 3] with MSPE. MSPE only replaces the patch embedding layer in the vanilla model, making well-trained ViT models to be directly applied to any size and aspect ratio. In our method, the patch embedding layer has several variable-sized kernels. The Transformer encoder is shared and frozen.", "description": "This figure illustrates the architecture of the Vision Transformer (ViT) model enhanced with the proposed Multi-Scale Patch Embedding (MSPE) method.  The core idea is to replace the standard patch embedding layer with a multi-scale patch embedding layer that uses multiple variable-sized kernels. This allows the model to process images of various resolutions without requiring resizing, improving efficiency and maintaining performance. The Transformer encoder part of the ViT model remains unchanged.", "section": "3 Method"}, {"figure_path": "9Q9UiAyV40/figures/figures_6_1.jpg", "caption": "Figure 5: Comparison of MSPE, Vanilla, and NaViT: only NaViT was pre-trained on the JFT dataset, baseline results come from [17].", "description": "This figure compares the ImageNet-1K Top-1 accuracy of three methods: Vanilla ViT, NaViT, and MSPE.  The x-axis represents the ImageNet-1K accuracy, and the y-axis shows different input resolutions (r\u1d62 = 64, 160, 224). It highlights that MSPE outperforms both Vanilla ViT and NaViT across all resolutions, especially at lower resolutions.  Note that NaViT used a larger pre-training dataset (JFT), giving it an advantage.", "section": "4 Experiments"}, {"figure_path": "9Q9UiAyV40/figures/figures_7_1.jpg", "caption": "Figure 6: Comparison results: (a) different training epochs; (b) model sizes of S, B, and L.", "description": "This figure presents ablation studies on the impact of training epochs and model sizes on the performance of MSPE. (a) shows that training for 3 or 5 epochs yields similar results, indicating that MSPE converges quickly.  (b) demonstrates that MSPE is effective across different model sizes (small, base, large), with larger models generally achieving higher accuracy.", "section": "4.4 Ablation Study and Analysis"}, {"figure_path": "9Q9UiAyV40/figures/figures_7_2.jpg", "caption": "Figure 8: Comparison results of different resizing methods in MSPE. PI-resize shows the best performance and robustness.", "description": "This figure compares the performance of different image resizing methods within the Multi-Scale Patch Embedding (MSPE) framework.  The methods compared include area resizing, bilinear resizing, and pseudo-inverse resizing (PI-Resize). The x-axis represents different test resolutions, and the y-axis shows the ImageNet-1K Top-1 accuracy.  The results demonstrate that PI-Resize consistently achieves the highest accuracy across all resolutions, showcasing its superior performance and robustness compared to other methods.", "section": "4 Experiments"}, {"figure_path": "9Q9UiAyV40/figures/figures_7_3.jpg", "caption": "Figure 1: MSPE results on ImageNet-1K. We loaded a ViT-B model pre-trained on ImageNet-21K from [19] and evaluated: (a) Height equals width, ranging from 28\u00d728 to 896\u00d7896, and (b) Fixed height=128, width ranging from 28 to 896. Vanilla ViT performance drops with size/aspect ratio changes; FlexiViT [15] significantly improves performance, and our method surpasses FlexiVIT.", "description": "This figure displays the performance of MSPE, Vanilla ViT, and FlexiViT on the ImageNet-1K dataset for image classification.  Two scenarios are shown: (a) where the image height and width are equal, and (b) where the image height is fixed at 128 pixels while the width varies. The results demonstrate that Vanilla ViT's accuracy decreases significantly as image size deviates from its training size (224x224), whereas FlexiViT and especially MSPE show significantly better performance across all tested resolutions and aspect ratios.  MSPE demonstrates substantial improvement, especially at lower resolutions, exceeding FlexiViT in accuracy.", "section": "1 Introduction"}, {"figure_path": "9Q9UiAyV40/figures/figures_13_1.jpg", "caption": "Figure 4: ImageNet-1K Top-1 accuracy curves, fixed heights at 192, 256, and 384. Results show MSPE directly applied across varying input ratios and enhancing performance.", "description": "The figure shows the ImageNet-1K Top-1 accuracy for different image resolutions with fixed height (192, 256, and 384 pixels) and varying width.  It compares the performance of Vanilla ViT, FlexiViT, and MSPE, highlighting MSPE's ability to maintain or improve accuracy across a range of aspect ratios.", "section": "4 Experiments"}, {"figure_path": "9Q9UiAyV40/figures/figures_14_1.jpg", "caption": "Figure 10: Comparison results of different resizing methods in MSPE.", "description": "This figure compares the performance of three different image resizing methods (PI-Resize, Nearest, and Bicubic) when used within the Multi-Scale Patch Embedding (MSPE) framework. The x-axis represents the test resolution, and the y-axis shows the ImageNet-1K Top-1 accuracy.  The results demonstrate that PI-Resize significantly outperforms the other two methods across all resolutions, highlighting its importance for achieving robust performance in MSPE.", "section": "D.4 Other resizing methods"}]