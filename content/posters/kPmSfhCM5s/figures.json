[{"figure_path": "kPmSfhCM5s/figures/figures_0_1.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters cover a wide range of vision tasks, from low-level visual semantics (like panoptic, instance, and semantic segmentation) to high-level visual semantics (like image and video question answering, captioning, and retrieval).  The tasks are categorized into four clusters: visual understanding, vision segmentation & grounding, visual synthesis & generation, and vision editing & inpainting.  Each cluster contains several specific tasks with example images or video clips demonstrating those tasks. The figure visually represents the comprehensive capabilities of VITRON in handling various vision tasks.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_2_1.jpg", "caption": "Figure 2: Technical overview of the VITRON framework.", "description": "The figure illustrates the architecture of VITRON, a unified pixel-level vision LLM. It shows the frontend modules (image, video, and sketch encoders) that process various visual inputs. These inputs are then passed to a central Large Language Model (LLM), which is responsible for understanding and generating textual responses.  The LLM interacts with backend visual specialists (via projections of task-specific and task-invariant features) to perform various vision tasks, including segmentation, generation, and editing. The LLM utilizes a hybrid approach for precise message passing, combining discrete textual instructions and continuous signal embeddings.  Finally, a cross-task synergy module is implemented to enhance the synergy between different visual tasks.", "section": "3 Architecture of VITRON"}, {"figure_path": "kPmSfhCM5s/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of the synergy module.", "description": "This figure illustrates the synergy module used in VITRON.  The module aims to maximize the use of shared task-invariant features among various visual tasks.  A discriminator is used in adversarial training to decouple task-specific features from the shared task-invariant features. The goal is to enhance synergy between different tasks by maximizing the use of the shared features.", "section": "4 Pixel-aware Synergistic Vision-Language Understanding Tuning"}, {"figure_path": "kPmSfhCM5s/figures/figures_8_1.jpg", "caption": "Figure 2: Technical overview of the VITRON framework.", "description": "The figure provides a technical overview of the VITRON framework, illustrating its key components and their interactions.  It shows the frontend vision and language encoders processing image, video, and sketch inputs. These encoders pass information to a central large language model (LLM), which interacts with task-specific and task-invariant feature projections. The LLM then outputs textual responses and instructions for backend specialist modules (e.g., for image/video generation, segmentation, and editing). This visual representation helps clarify the architecture and workflow of the VITRON system, highlighting the interplay between language understanding and various vision tasks.", "section": "3 Architecture of VITRON"}, {"figure_path": "kPmSfhCM5s/figures/figures_9_1.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "The figure is a diagram that shows the four main task clusters that VITRON supports. These clusters are visual understanding, visual segmentation and grounding, visual generation, and vision editing and inpainting. Each cluster contains a number of subtasks.  The diagram visually represents the hierarchical relationships between these task clusters and subtasks, showcasing VITRON's broad capabilities in visual processing.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_9_2.jpg", "caption": "Figure 6: The synergy correlation between each pair of visual tasks. The deeper the color of the cell, the more synergistic they are in between.", "description": "This figure shows a heatmap illustrating the degree of synergy between different pairs of visual tasks performed by the VITRON model.  The color intensity of each cell represents the level of synergy, with darker colors indicating stronger synergy and lighter colors indicating weaker synergy. The tasks are grouped into four main clusters: visual understanding, visual generation, visual segmentation, and visual editing.  The heatmap helps to visualize the relationships between these task clusters and identify which tasks benefit most from collaboration within the VITRON framework.", "section": "Cross-task Synergy Learning"}, {"figure_path": "kPmSfhCM5s/figures/figures_18_1.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters cover a wide range of vision tasks, from low-level visual semantics (like instance, semantic, and panoptic segmentation) to high-level visual semantics (like image and video question answering, captioning, and retrieval).  The tasks are categorized into visual understanding, visual segmentation and grounding, visual generation, and vision editing & inpainting.  The figure illustrates the breadth of VITRON's capabilities, spanning from basic image and video understanding to complex generation and editing tasks.  It visually demonstrates the system's unified pixel-level approach to handling various vision problems.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_20_1.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure provides a visual overview of the capabilities of the VITRON model.  It's categorized into four main task clusters: Visual Understanding, Vision Segmentation & Grounding, Visual Generating, and Vision Editing & Inpainting. Each cluster further breaks down into various subtasks, showcasing the model's versatility in handling a wide range of vision-related tasks, from low-level semantic understanding to high-level image and video generation and manipulation.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_20_2.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters cover a wide range of vision tasks, from low-level visual semantics (like understanding basic image features) to high-level visual semantics (like answering complex questions about images and videos).  The tasks are grouped into visual understanding, vision segmentation & grounding, visual generating, and vision editing & inpainting.  Each category includes multiple specific vision tasks such as image captioning, video object segmentation, text-to-image generation, and image inpainting. This illustrates the model's comprehensive capabilities across various vision-related applications.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_21_1.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters cover a wide range of vision tasks, from low-level visual semantics (like panoptic, instance, and semantic segmentation) to high-level visual semantics (like image and video captioning, question answering, and retrieval).  The tasks are categorized into four main clusters: Visual Understanding, Vision Segmentation & Grounding, Visual Generating, and Vision Editing & Inpainting. The figure visually represents the capabilities of VITRON across these diverse visual tasks, highlighting its ability to handle both images and videos.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_24_1.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters span a range of vision tasks from low-level to high-level, encompassing visual comprehension and visual generation.  The low-level tasks include visual semantics (panoptic, instance, semantic, referring, phrase grounding, video grounding, and video object segmentation) and visual synthesis & generation (text-to-image, text-to-video, and image-to-video generation).  High-level tasks include image/video referring, captioning, image QA, video QA, language-image retrieval, and language-video retrieval.  Finally, vision editing and inpainting are included, encompassing tasks such as adding, removing, replacing, moving, style changing, and color changing.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_24_2.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters are visual understanding, vision segmentation & grounding, visual generating, and vision editing & inpainting. Each cluster contains various sub-tasks, ranging from low-level (e.g., semantic segmentation, panoptic segmentation, phrase grounding) to high-level tasks (e.g., text-to-image generation, image-to-video generation, video editing). The figure visually represents how VITRON integrates and unifies these tasks through a comprehensive framework.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_25_1.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters cover a range of vision tasks, from low-level visual semantics (like panoptic, instance, semantic, and referring image segmentation) to high-level visual semantics (like image and video QA, captioning, and retrieval).  The tasks are grouped into visual understanding, vision generation, vision segmentation & grounding, and vision editing & inpainting.  The image illustrates the comprehensive capabilities of VITRON across various vision tasks and levels of abstraction.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_25_2.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters span visual comprehension to visual generation tasks, and range from low-level (e.g., low-level visual semantics, pixel-level vision understanding) to high-level (e.g., high-level visual semantics) tasks.  The clusters include visual understanding, visual generation, vision segmentation & grounding, and vision editing & inpainting. Each cluster contains several sub-tasks, and examples of the sub-tasks are included in the figure.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_25_3.jpg", "caption": "Figure 2: Technical overview of the VITRON framework.", "description": "The VITRON framework consists of three key components: frontend vision and language encoders, central LLM for semantic understanding and text generation, and backend decoder modules for user response and vision manipulation.  The frontend encoders process image, video, and sketch inputs. The central LLM processes these inputs and generates textual responses as well as instructions and feature embeddings for the backend modules.  The backend modules are specialized models for various vision tasks, including segmentation, generation, and editing.  A hybrid approach is used for message passing, combining discrete textual instructions and continuous signal feature embeddings.", "section": "3 Architecture of VITRON"}, {"figure_path": "kPmSfhCM5s/figures/figures_25_4.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters span visual comprehension (understanding) to visual generation (creating) and range from low-level tasks (like pixel-level understanding) to high-level tasks (like generating videos from text). The image displays a diagram categorizing various vision tasks under these four main clusters.", "section": "Abstract"}, {"figure_path": "kPmSfhCM5s/figures/figures_25_5.jpg", "caption": "Figure 2: Technical overview of the VITRON framework.", "description": "The figure provides a visual representation of the VITRON framework's architecture. It shows how various components, including image and video encoders, a large language model (LLM), and backend decoder modules, work together to process different visual tasks.  The flow of information and the task-specific and task-invariant features are also depicted. The figure helps illustrate the overall pipeline of processing an image/video query and generating a response or manipulating the image/video content.", "section": "3 Architecture of VITRON"}, {"figure_path": "kPmSfhCM5s/figures/figures_25_6.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure shows the four main task clusters that VITRON supports.  These clusters are Visual Understanding, Vision Segmentation & Grounding, Visual Generating, and Vision Editing & Inpainting. Each cluster contains various low-level and high-level tasks, demonstrating the wide range of capabilities of the VITRON model.", "section": "1 Introduction"}, {"figure_path": "kPmSfhCM5s/figures/figures_26_1.jpg", "caption": "Figure 2: Technical overview of the VITRON framework.", "description": "The figure provides a technical overview of the VITRON framework, illustrating its main components and the flow of information.  It shows the frontend modules (image, video, and sketch encoders) processing user inputs, passing the results to the Large Language Model (LLM) backbone. The LLM then makes decisions and outputs textual responses or instructions for function invocation and feature embeddings to backend modules (visual specialists).  These specialists execute specific vision tasks (segmentation, generation, editing) and provide task-specific and task-invariant features that are further utilized by the LLM.  The interaction between the different components highlights the system's unified approach to various visual tasks.", "section": "3 Architecture of VITRON"}, {"figure_path": "kPmSfhCM5s/figures/figures_26_2.jpg", "caption": "Figure 1: VITRON supports four main task clusters of visions, spanning visual comprehension to visual generation, from low level to high level.", "description": "This figure provides a visual overview of the capabilities of VITRON, illustrating its ability to handle four main task clusters: Visual Understanding, Visual Segmentation & Grounding, Visual Generating, and Vision Editing & Inpainting.  Each cluster contains various subtasks, progressing from low-level visual semantics (e.g., panoptic segmentation) to high-level semantics (e.g., image captioning) and demonstrating the model's versatility in processing and generating visual information.", "section": "Abstract"}]