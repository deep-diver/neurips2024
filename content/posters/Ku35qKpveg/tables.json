[{"figure_path": "Ku35qKpveg/tables/tables_6_1.jpg", "caption": "Table 1: Top-1 accuracy (%) across the CIFAR-10, CIFAR-100, ImageNet-100, and ImageNet-1K datasets using the proposed DPA on Vision Transformer (ViT) and its variants.", "description": "This table presents the Top-1 accuracy results achieved by various Vision Transformer (ViT) architectures (ViT-Tiny, DeiT-Tiny, CaiT-XXS, PVT-Tiny, and TNT-Small) across four image classification datasets (CIFAR-10, CIFAR-100, ImageNet-100, and ImageNet-1K).  The results are compared for different activation functions (Softplus, ELU, SELU, SiLU, ReLU, GELU, GDN) and the proposed Dual-Perspective Activation (DPA) mechanism.  The table demonstrates DPA's superior performance compared to other activation functions.", "section": "4.1 DPA on ViTs"}, {"figure_path": "Ku35qKpveg/tables/tables_6_2.jpg", "caption": "Table 2: Top-1 accuracy (%) across the CIFAR-10, CIFAR-100, ImageNet-100, and ImageNet-1K datasets using the proposed DPA on various CNN architectures.", "description": "This table presents the Top-1 accuracy results achieved by the proposed Dual-Perspective Activation (DPA) mechanism when compared against several other mainstream activation functions.  The comparison is performed across four different image classification datasets (CIFAR-10, CIFAR-100, ImageNet-100, and ImageNet-1K) and five different Convolutional Neural Network (CNN) architectures (AlexNet, VGG-11, MobileNet, ShuffleNet, and ResNet-18).  The table demonstrates the performance gains obtained by using DPA over the other activation functions.", "section": "4 Experimental Study"}, {"figure_path": "Ku35qKpveg/tables/tables_7_1.jpg", "caption": "Table 3: Ablation study of the proposed DPA on CIFAR-100. DPAF, DPAB, DPAFUB and DPAFOB denote DPA with the channel relevance criterion in the form of forward only, backward only, forward-backward union, and forward-backward intersection, respectively. DPAall denotes denoising all channels indiscriminately.", "description": "This table presents the results of an ablation study conducted on the CIFAR-100 dataset to evaluate the impact of different variations of the Dual-Perspective Activation (DPA) mechanism on the classification accuracy.  It compares the performance of DPA using only forward criteria (DPAF), only backward criteria (DPAB), the union of both (DPAFUB), and the intersection of both (DPAFOB).  It also includes a baseline where all channels are denoised indiscriminately (DPAall), and compares these to standard ReLU and GELU activations. The results demonstrate the superior performance of DPAFOB, highlighting the importance of considering both forward and backward perspectives when identifying and addressing irrelevant channels.", "section": "4.3 Ablation Study"}, {"figure_path": "Ku35qKpveg/tables/tables_7_2.jpg", "caption": "Table 4: Computational costs during training and inference regarding \"GPU Memory (GiB)\" and \"Latency (s)\" for networks that utilize the proposed DPA, in comparison to networks utilizing other activation counterparts. The networks were fed 224x224-pixel images with a batch size of 1024 on an NVIDIA A40 GPU. \"Latency\" refers to the average time it takes for a network to process a batch of data.", "description": "This table presents a comparison of computational costs (GPU memory usage and processing latency) for different activation functions including the proposed DPA and several commonly used activation functions.  The experiments were performed on two different network architectures (ViT-Tiny and ResNet-18) using 224x224 pixel images and a batch size of 1024 on an NVIDIA A40 GPU.  The results highlight the efficiency of DPA in terms of both memory consumption and processing time.", "section": "4 Experimental Study"}, {"figure_path": "Ku35qKpveg/tables/tables_7_3.jpg", "caption": "Table 5: The generalization performance of DPA on node classification and text classification tasks.", "description": "This table shows the results of applying the Dual-Perspective Activation (DPA) method to node classification and text classification tasks.  It compares the Area Under the Curve (AUC) for node classification using Graph Convolutional Networks (GCN) and GraphSAGE, and the Top-1 Accuracy for text classification using TextGCN and BERT.  The results are presented for ReLU, GELU, and DPA activation functions, demonstrating the improved performance of DPA across various network architectures and tasks.", "section": "4.5 Generalization to Other Tasks"}]