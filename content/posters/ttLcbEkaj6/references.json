{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021", "reason": "This paper introduces CLIP, a crucial model for connecting image and text embeddings, which is foundational to the current work's controllable image diffusion model."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020", "reason": "This paper introduces the core diffusion probabilistic models used in the current work, providing the theoretical foundation for the method."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022", "reason": "This paper significantly advances diffusion models, enabling high-resolution image generation, directly relevant to the quality of sketches produced in this work."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023", "reason": "This paper details ControlNet, the specific controllable diffusion model utilized in this research, making it highly relevant to the methodology."}, {"fullname_first_author": "David Ha", "paper_title": "A neural representation of sketch drawings", "publication_date": "2017", "reason": "This paper is foundational to the field of sketch generation, providing a neural representation for sketches which forms a basis for the current work's focus on sketch generation from hand motions."}]}