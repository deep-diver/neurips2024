[{"type": "text", "text": "TSDS: Data Selection for Task-Specific Model Finetuning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zifan Liu University of Wisconsin-Madison Madison, WI zliu676@wisc.edu ", "page_idx": 0}, {"type": "text", "text": "Amin Karbasi Yale University New Haven, CT amin.karbasi@yale.edu ", "page_idx": 0}, {"type": "text", "text": "Theodoros Rekatsinas   \nApple   \nZ\u00fcrich, Switzerland   \ntrekatsinas@apple.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Finetuning foundation models for specific tasks is an emerging paradigm in modern machine learning. The efficacy of task-specific finetuning largely depends on the selection of appropriate training data. We present TSDS (Task-Specific Data Selection), a framework to select data for task-specific model finetuning, guided by a small but representative set of examples from the target task. To do so, we formulate data selection for task-specific finetuning as an optimization problem with a distribution alignment loss based on optimal transport to capture the discrepancy between the selected data and the target distribution. In addition, we add a regularizer to encourage the diversity of the selected data and incorporate kernel density estimation into the regularizer to reduce the negative effects of near-duplicates among the candidate data. We connect our optimization problem to nearest neighbor search and design efficient algorithms to compute the optimal solution based on approximate nearest neighbor search techniques. We evaluate our method on data selection for both continued pretraining and instruction tuning of language models. We show that instruction tuning using data selected by our method with a $1\\%$ selection ratio often outperforms using the full dataset and beats the baseline selection methods by 1.5 points in F1 score on average. Our code is available at https://github.com/ZifanL/TSDS. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Finetuning foundation models [3] is the de-facto paradigm for building machine learning applications that focus on specific tasks. Models such as BERT [10] and LLaMA [43] are large-scale models pretrained on massive unlabeled data across a wide range of domains. Those models can be specialized to downstream tasks through finetuning. Finetuning can take a variety of forms depending on the target task. For instance, continued pretraining [17] extends the pretraining stage of a model on a dataset that is more closely related to a target domain. As another setting, instruction tuning [51] trains a generative foundation model on instruction-response pairs to improve its performance in responding to task-specific instructions. ", "page_idx": 0}, {"type": "text", "text": "Finetuning foundation models can lead to significant improvement in downstream tasks, but the effectiveness heavily relies on the right choice of training data [17, 30, 48, 47]. However, the data repositories that one considers during training of generative models tend to be large\u2014consider for example the use of Common Crawl1, which contains 250 billion web pages, or The Pile [14]\u2014and hence, it is impractical to manually select the data that are distributed like the use cases in the target task. Therefore, automated task-specific data selection becomes critical. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this paper, we propose TSDS (Task-Specific Data Selection), a framework to select data for taskspecific model finetuning. We consider the scenario of finetuning a foundation model to customize it for a specific task characterized by a few representative examples. The input to our framework is the representative examples and a massive repository of candidate data. Guided by the representative examples, we select training data from the repository for task-specific finetuning. We identify the following requirements for our framework. ", "page_idx": 1}, {"type": "text", "text": "(Distribution Alignment) First, the distribution of the selected data should match the distribution of the representative examples from the target task. Distribution alignment is essential for a model to learn the target distribution and enable data-efficient finetuning for the target task [40]. Many works [38, 17, 2, 50, 47] retrieve candidate examples that are most similar to the representative examples. Such heuristics do not ensure distribution alignment between the selected data and the representative examples. A recent work [48] selects data by importance resampling to match the target distribution but is limited to an n-gram feature space, which cannot capture high-level semantics. ", "page_idx": 1}, {"type": "text", "text": "(Diversity) Second, the selected data should be diverse so that the model can learn a wide range of related knowledge rather than overftiting to specific examples. In practice, data repositories created by web crawling may contain a large portion of near-duplicates [13, 28] that can compromise diversity and negatively impact model performance [28, 19]. For example, a study [13] on several snapshots of $\\mathrm{Clue}\\bar{\\mathsf{W e}}{\\mathsf{b}}^{2}$ and Common Crawl shows that $14\\%$ to $52\\%$ of the documents are near-duplicates. Previous works [38, 17, 2, 50, 48, 47] on task-specific data selection overlook near-duplicates, leading to the over-representation of such examples in the selected data. We require our framework to ensure diversity in selection even when a large fraction of the candidate examples are near-duplicates. ", "page_idx": 1}, {"type": "text", "text": "(Scalability) Finally, the selection algorithm should be efficient, considering the increasing scale of modern data repositories. The high volume of candidate data (e.g., 250 billion pages in Common Crawl) poses a great challenge to efficient selection. ", "page_idx": 1}, {"type": "text", "text": "Our framework formulates task-specific data selection as an optimization problem that allows a smooth trade-off between two crucial objectives: distribution alignment and diversity. The solution to the optimization problem is a categorical distribution assigned to the candidates which we will sample from. In the optimization objective, we use optimal transport to measure the discrepancy between the distribution assigned to the candidates and the target distribution, encouraging the alignment between them. We show that the optimization problem admits efficient algorithms to compute the optimal solution. In addition, our framework supports distribution alignment in any metric space that supports efficient nearest-neighbor search, including model-agnostic semantic embedding and model-specific features such as gradients. ", "page_idx": 1}, {"type": "text", "text": "Our contributions: 1) We formulate data selection for task-specific finetuning as an optimization problem based on optimal transport for distribution alignment, with a regularization term that encourages diversity. 2) We make our framework robust to near-duplicates by incorporating kernel density estimation [36] into the regularization term. 3)We show the connection between the optimal solution to the optimization problem and nearest neighbor search, which allows us to develop efficient algorithms employing approximate nearest-neighbor search techniques [23]. ", "page_idx": 1}, {"type": "text", "text": "We conduct extensive experiments to validate the effectiveness of our framework. We focus on natural language processing tasks where foundation models have shown great advancements. We show that our framework beats the state-of-the-art baseline [47] by 1.5 points in F1 score on average with a selection ratio of $1\\%$ on instruction tuning for two modern large language models on three tasks. In addition, continued pretraining using domain-specific data selected by our framework outperforms the other selection methods by up to 3 F1 points on four classification tasks from various domains. We also demonstrate that our framework is robust to near-duplicates in the data repository, maintaining consistent performance when $1\\%$ of the candidate examples are duplicate for up to 1,000 times. Our method is efficient, taking 28 hours to preprocess a corpus of 150M examples and less than 1 hour for each task-specific selection. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Overview ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we provide background information that is essential for the problem, followed by a formal statement of the problem and an overview of our proposed framework. ", "page_idx": 2}, {"type": "text", "text": "2.1 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We introduce the notations that will be used throughout the paper and the optimal transport problem. ", "page_idx": 2}, {"type": "text", "text": "Notation We use $\\mathbb{R}_{\\geq0}$ to represent the set of non-negative real numbers, and $\\mathbb{R}_{>0}$ to represent the set of positive real numbers. Let $N$ be a positive integer and we use $[N]$ to denote the set of integers from 1 to $N$ . We use bold letters to denote matrices and the corresponding plain letters with subscripts to denote the entries in the matrix. For example, $\\gamma\\in\\mathbb{R}^{M\\times N}$ is a matrix with size $M\\times N$ and $\\gamma_{i j}$ or $\\gamma_{i,j}$ is the entry in the $i^{\\mathrm{th}}$ row and the $j^{\\mathrm{th}}$ column (1-indexed). ", "page_idx": 2}, {"type": "text", "text": "Optimal Transport between Discrete Distributions We introduce the optimal transport problem, which forms the basis of our data selection framework. Let $(A,f)$ be a metric space where $A$ is a finite set and $f:A\\times A\\to\\mathbb{R}_{\\geq0}$ is a distance function. Consider two discrete distributions $\\mu$ on $U\\subseteq A$ and $\\nu$ on $V\\subseteq A$ , where both $U$ and $V$ are finite sets. Let $u_{i}$ be the $i^{\\mathrm{th}}$ example in $U$ and $\\mu_{i}=\\mu(u_{i})$ be the probability of $u_{i}$ . Similarly, let $v_{j}$ be the $j^{\\mathrm{th}}$ example in $V$ and $\\nu_{j}=\\nu(v_{j})$ be the probability of $v_{j}$ . Let $\\gamma\\in\\mathbb{R}_{\\geq0}^{|U|\\times|V|}$ be a transport of probability mass between $\\mu$ and $\\nu$ , where $\\gamma_{i j}$ is amount of probability mass transported from $u_{i}$ to $v_{j}$ . Assume that the cost of transporting one unit of probability mass from $u_{i}$ to $v_{j}$ is $f(u_{i},v_{j})$ , the distance between $u_{i}$ and $v_{j}$ . Optimal transport is the problem of transporting all the probability mass from $U$ to $V$ with a minimal cost: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\gamma\\in\\mathbb{R}_{\\geq0}^{|U|\\times|V|}}\\sum_{i=1}^{|U|}\\sum_{j=1}^{|V|}\\gamma_{i j}f(u_{i},v_{j})\\quad\\mathrm{subject}\\,\\,\\mathsf{t o}\\quad\\sum_{j=1}^{|V|}\\gamma_{i j}=\\mu_{i},\\forall i\\in[|U|],\\sum_{i=1}^{|U|}\\gamma_{i j}=\\nu_{j},\\forall j\\in[|V|]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "2.2 Task-Specific Data Selection Problem Statement ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We now introduce the problem of data selection for task-specific finetuning. We assume access to a set of $M$ representative examples $Q=\\{q_{i}\\}_{i=1}^{M}$ from the target task, which we call query examples. Consider a data repository $\\smash{D=\\{x_{j}\\}_{j=1}^{N}}$ containing $N$ candidate examples. Note that $Q$ and $D$ are multisets that may contain duplicates. We aim to select $B$ examples from the repository guided by the query examples. The selected examples will be used to finetune a model to tailor it to the target task. We adopt the model-agnostic formulation above for the generality of the solution. However, our framework can be applied to model-specific selection by using model-specific data representations; an example evaluation for model-specific instruction tuning is presented in Section 5.1. ", "page_idx": 2}, {"type": "text", "text": "2.3 Framework Overview ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our framework takes the candidate examples and the query examples as inputs and outputs a set of task-specific examples by the following workflow. 1. (Encoding) We first encode the query examples and the candidate examples into the same metric space with a specified distance function. 2. (Probability Assignment) We determine the probability mass assigned to each candidate example by solving an optimization problem. 3. (Sampling) We take a random sample with replacement from the candidate examples following a categorical distribution where the probability is determined by the assignment in the previous step. ", "page_idx": 2}, {"type": "text", "text": "3 Data Selection and Optimal Transport ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Data selection for task-specific finetuning can be expressed as an optimization problem for probability assignment to the candidates in the data repository. First, we discuss the formulation of the optimization problem and then show the existence of closed-form solutions. In addition, we propose a regularization term that addresses the problem of near-duplicates among the candidates. The proofs of the theorems in this section are provided in Appendix B. ", "page_idx": 2}, {"type": "text", "text": "3.1 Optimization Problem ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Consider the metric space $(Z,f)$ where $Z=Q\\cup D$ contains all the examples and $f:Z\\times Z\\to\\mathbb{R}$ is a distance function. Let $\\pmb{d}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ be the distance matrix, where $d_{i j}=f(q_{i},x_{j})$ is the distance between the $i^{\\mathrm{th}}$ query example and the $j^{\\mathrm{th}}$ candidate example. ", "page_idx": 3}, {"type": "text", "text": "We propose an optimization problem that transports probability mass from the query examples to the candidates. The objective is a linear combination of a probability transport cost for distribution alignment and a regularization term to encourage diversity. Formally, given d \u2208R\u2265M0\u00d7N, we consider the following optimization problem, which we refer to as Problem RT (regularized transport): ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\gamma\\in\\mathbb{R}_{\\geq0}^{M\\times N}}\\!\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{j=1}^{N}\\gamma_{i j}d_{i j}+(1-\\alpha)G(\\gamma)\\quad\\mathrm{subject}\\ \\mathrm{to}\\quad\\sum_{j=1}^{N}\\gamma_{i j}=\\frac{1}{M},\\forall i\\in[M]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $C>0$ is a scaling constant, $\\alpha\\in[0,1]$ is a hyper-parameter that controls the trade-off between distribution alignment and diversity, and $G$ is a regularization function. The first term in Problem RT is the cost of probability transport where $\\gamma_{i j}$ is the mass transported from the $i^{\\mathrm{th}}$ query example to the $j^{\\mathrm{th}}$ candidate. Each query example ha sM1 probability mass to transport, as stated in the constraint. The probability transport cost measures the cost of transforming one distribution to another by moving probability mass between them, providing a method to quantify probability alignment. The second is a regularization term that encourages the diversity of probability transport. ", "page_idx": 3}, {"type": "text", "text": "Let $\\gamma^{*}$ be an optimal solution to Problem RT. We assign $\\begin{array}{r}{p_{j}^{*}=\\sum_{i=1}^{M}\\gamma_{i j}^{*}}\\end{array}$ probability to candidate example $x_{j}$ , which is the sum of the probability mass it receives from all the query examples. When we sample from the candidate examples in the subsequent step, $x_{j}$ has probability $p_{j}^{*}$ . ", "page_idx": 3}, {"type": "text", "text": "We propose two instantiations of the regularization term that encourage the diversity of probability transport by penalizing its discrepancy to the uniform transport: ", "page_idx": 3}, {"type": "text", "text": "\u2022 $\\begin{array}{r}{G_{\\infty}(\\gamma)=M\\operatorname*{max}_{i\\in M,j\\in N}\\left|\\gamma_{i j}-\\frac{1}{M N}\\right|}\\end{array}$ captures the largest probability gap between $\\gamma$ and the uniform transport.   \n\u2022 $\\begin{array}{r}{G_{\\mathrm{TV}}(\\gamma)\\,=\\,\\frac12\\sum_{i=1}^{M}\\sum_{j=1}^{N}\\left|\\gamma_{i j}\\,-\\,\\frac{1}{M N}\\right|\\,}\\end{array}$ is the total variation distance between $\\gamma$ and the uniform transport. ", "page_idx": 3}, {"type": "text", "text": "We use uniform transport as a reference point to encourage diversity as it represents the most diverse way of transporting the probability mass from one query example to all the candidates, assuming the candidates are distinct. ", "page_idx": 3}, {"type": "text", "text": "3.2 Closed-Form Solution ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "When $G=G_{\\infty}$ , Problem RT can be solved by standard linear programming techniques, but they run in $\\Omega((M N)^{2})$ time, which is prohibitively expensive. Instead, we show the existence of a closed-form solution that can be computed in $O(M N\\log N)$ time (see Section 4 for the algorithm). ", "page_idx": 3}, {"type": "text", "text": "Using $G_{\\infty}$ as the regularization function, we get an optimal solution by transporting the probability of each query example evenly to its $K$ -nearest neighbors among the candidates, where $K$ is determined by the tradeoff between distribution alignment and diversity: ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.1. Given $\\pmb{d}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ where $N>1$ , consider Problem RT with $G(\\gamma)=G_{\\infty}(\\gamma)=$ $\\begin{array}{r}{M\\operatorname*{max}_{i\\in M,j\\in N}\\left|\\gamma_{i j}-\\frac{1}{M N}\\right|}\\end{array}$ . For all $i\\in[M],$ , let $j_{1}^{i},\\cdot\\cdot\\cdot,j_{N}^{i}$ be a reordering of $[N]$ such that $d_{i j_{1}^{i}}\\leq$ $\\cdots\\leq d_{i j_{N}^{i}}$ . Consider $\\gamma^{*}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ whose entries are $\\frac{1}{K M}$ if $j\\,\\in\\,\\{j_{1}^{i},\\dots,j_{K}^{i}\\}$ and 0 otherw1ise, where $\\begin{array}{r}{K=\\operatorname*{max}\\{k\\in[N]|\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{l=1}^{k-1}(d_{i j_{k}^{i}}-d_{i j_{l}^{i}})<(1-\\alpha)M\\}}\\end{array}$ . Assume $K\\le N/2$ , and then $\\gamma^{*}$ is a minimizer of Problem RT. $\\gamma^{*}$ is the unique minimizer if $\\begin{array}{r}{\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{l=1}^{K}(d_{i j_{K+1}^{i}}-d_{i j_{l}^{i}})>}\\end{array}$ $(1-\\alpha)M$ and $\\nexists i\\in[M]$ such that $d_{i j_{K+1}^{i}}=d_{i j_{K}^{i}}$ . ", "page_idx": 3}, {"type": "text", "text": "Similarly, there exists a closed-form solution that can be computed in $O(M N\\log N)$ time when $G=G_{\\mathrm{TV}}$ (see Appendix A for the solution and the algorithm). ", "page_idx": 3}, {"type": "text", "text": "3.3 Addressing Near-Duplicates via Kernel Density Estimation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "When there exists a large fraction of near-duplicates among the candidates, $G_{\\infty}$ fails to characterize the diversity of probability assignment since it treats near-duplicates as distinct examples. Consequently, the contents in the near-duplicates will be over-sampled. For example, if 100 of the $K$ -nearest neighbors of a query example are duplicates and the others are distinct, the content in the duplicates will receive 100 times as much probability mass as any other example. ", "page_idx": 4}, {"type": "text", "text": "To address the near-duplicate problem, we propose a regularization function incorporating kernel density estimation (KDE) [36], which is a non-parametric method to estimate the probability density function from finite examples. We determine the duplication level of a point by the kernel density estimate at its position. We use the Epanechnikov kernel such that given $D$ , the density estimate at point x is  x\u2032\u2208D max(1 \u2212f(xh,2x) , , where $h>0$ is the kernel size and $f$ is the distance function. For example, for a point $x$ in whose distance to any other point is larger than $h$ , the density estimate at $x$ is 1. If we create two duplicates of $x$ and add them to $D$ , the density estimate at $x$ increases to 3. Our KDE-based regularization function is GKDE(\u03b3) = M maxi\u2208[M],j\u2208[N] \u03c1j|\u03b3ij \u2212M j\u20321\u2208/[\u03c1Nj] 1/\u03c1j\u2032 | where $\\begin{array}{r}{\\rho_{j}=\\sum_{\\boldsymbol{x}^{\\prime}\\in D}(1-f(\\boldsymbol{x}_{j},\\boldsymbol{x}^{\\prime})/h^{2})}\\end{array}$ is the density estimate at $x_{j}$ . $G_{\\mathrm{KDE}}(\\gamma)$ compares $\\gamma$ to the probability a ssignment that is proportional to the inverse of the density, and penalizes the largest gap weighted by the density. Note that $G_{\\infty}$ is a special case of $G_{\\mathrm{KDE}}(\\gamma)$ with $\\rho_{j}=1$ for all $j\\in[N]$ . The optimal solution to Problem RT when $G=G_{\\mathrm{KDE}}$ can be obtained by assigning the probability mass of each query example to the nearest neighbors among the candidates, weighted by the inverse of their density estimate, as is shown by the following theorem. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.2. Given $\\pmb{d}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ and $\\rho_{1},\\dotsc,\\rho_{N}\\in\\mathbb{R}_{>0}$ , consider Problem RT with $G(\\gamma)\\,=$ $\\begin{array}{r}{G_{K D E}(\\gamma)\\,=\\,M\\operatorname*{max}_{i\\in[M],j\\in[N]}\\rho_{j}\\big|\\gamma_{i j}\\,-\\,\\frac{1/\\rho_{j}}{M\\sum_{j^{\\prime}\\in[N]}1/\\rho_{j^{\\prime}}}\\big|}\\end{array}$ . For all $i\\ \\in\\ [M]$ , let $j_{1}^{i},\\dots,j_{N}^{i}$ be $a$ reordering of $[N]$ such that $d_{i j_{1}^{i}}\\leq\\dots\\leq d_{i j_{N}^{i}}$ . Let $\\begin{array}{r}{s_{k}^{i}=\\sum_{l=1}^{k}1/\\rho_{j_{l}^{i}}}\\end{array}$ , and s be a discrete variable that takes value from $\\ensuremath{\\mathcal{S}}=\\{s_{k}^{i}|i\\in[M],k\\in[N]\\}\\cup\\{0\\}$ . Let $\\begin{array}{r}{c(s)=\\sum_{i=1}^{M}c_{i}(s),}\\end{array}$ , where $c_{i}(s)=0\\,i f$ $s\\leq s_{1}^{i}$ and lk=\u221211dijik\u03c1 j\u2212idijliif sik\u22121 < s \u2264sik for any k \u22652. Let s\u2217= max{s \u2208S| C\u03b1 c(s) < $(1-\\alpha)M\\}$ , and $K_{i}=\\operatorname*{max}\\{k\\in\\{0,\\ldots,N-1\\}|s_{k}^{i}\\leq s^{*}\\}$ . Assume $\\begin{array}{r}{s^{*}\\le\\frac{1}{2}\\sum_{j=1}^{N}1/\\rho_{j}}\\end{array}$ , and then $\\gamma^{*}$ is a minimizer of Problem RT where $\\forall i\\in[M],k\\in[N]$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\gamma_{i j_{k}^{i}}^{*}=\\left\\{\\!\\!\\begin{array}{l l}{1/(M s^{*}\\cdot\\rho_{j_{k}^{i}}),}&{i f k\\leq K_{i}}\\\\ {\\frac{1}{M}-\\sum_{l=1}^{K_{j}}1/(M s^{*}\\cdot\\rho_{j_{l}^{i}}),}&{i f k=K_{i}+1}\\\\ {0,}&{o t h e r w i s e}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "$\\gamma^{*}$ is the unique minimizer $i f\\,\\nexists s\\,\\in\\,{\\mathcal{S}}$ such that $\\begin{array}{r}{\\frac{\\alpha}{C}c(s)\\,=\\,(1\\,-\\,\\alpha)M}\\end{array}$ and $\\nexists i\\in[M]$ such that $d_{i j_{K_{i}}^{i}}=d_{i j_{K_{i}+1}^{i}}$ or dijiK+1 $d_{i j_{K_{i}+1}^{i}}=d_{i j_{K_{i}+2}^{i}}$ ", "page_idx": 4}, {"type": "text", "text": "Intuitively, we count candidate $x_{j}$ as $1/\\rho_{j}$ examples. For each query example, the optimal solution assigns probability mass to the candidates in its neighborhood proportional to their adjusted counts. The size of the neighborhood is determined by the limit $s^{*}$ on the sum of the adjusted counts. ", "page_idx": 4}, {"type": "text", "text": "In Figure 1, we show an example comparing the optimal transport with $G_{\\infty}$ and $G_{\\mathrm{KDE}}$ . When $G\\,=\\,G_{\\infty}$ , the probability is transported uniformly to the candidates regardless of their relative positions. When $G=G_{\\mathrm{KDE}}$ , the clustered candidates receive less probability due to their high density, and they will be less over-represented when we take samples according to the assigned probability. ", "page_idx": 4}, {"type": "text", "text": "4 Efficient Probability Assignment Algorithms for Data Selection ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We propose efficient algorithms to assign probability mass to the candidates according to the optimal solutions to Problem RT. For $G=G_{\\infty}$ and $G=G_{\\mathrm{KDE}}$ , the corresponding algorithms are KNNUniform (Algorithm 1) and KNN-KDE (Algorithm 2). Each algorithm takes the query examples and the candidates as input and outputs the probability assigned to each candidate. ", "page_idx": 4}, {"type": "text", "text": "Both algorithms prefetch the $L$ nearest neighbors of each query example from the candidates as the first step, where $L$ is a limit on the neighborhood size. Specifically, GETKNN $(\\mathcal{Q},\\mathcal{D},L)$ returns the ", "page_idx": 4}, {"type": "image", "img_path": "wjbTHLUSzU/tmp/dfeaf5ebc6a366845a589e2a0d2f9404de5ff73c27d41bdc313f964f57b765a7.jpg", "img_caption": ["Figure 1: An example of the optimal probability transports under different regularization terms. We consider 1 query example $q$ and 5 candidates $x_{1},\\ldots,x_{5}$ embedded in a 2-dimensional space. Assume that the candidates that form a cluster (i.e., $x_{3},x_{4},x_{5})$ have a density estimate of $\\frac{3}{2}$ each and the others have a density estimate of 1. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Algorithm 1: KNN-Uniform. ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "1 Input: query examples $\\mathcal{Q}=\\{q_{i}\\}_{i=1}^{M}$ , candidates $\\mathcal{D}=\\{x_{j}\\}_{j=1}^{N}$ , number of nearest neighbors   \nto prefetch $L$ , $\\alpha\\in[0,1]$ , $C>0$ ; Output: $p_{1},\\ldots,p_{N}$ ;   \n2 $j,d\\gets\\mathrm{GETKNN}(\\mathcal{Q},\\mathcal{D},L);K\\gets1$ ;   \n3 while $K<L$ and $\\begin{array}{r}{\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{k=1}^{K}[d_{i,K+1}-d_{i k}]<(1-\\alpha)M}\\end{array}$ do   \n4 $K\\gets K+1$ ;   \n5 foreach $j\\in[N]$ do   \n6\u2014 $p_{j}\\leftarrow0$ ;   \n7 foreach $i\\in[M]$ do   \n8 foreach $\\bar{k}\\in[K]$ do   \n9 \u2014 $\\begin{array}{r}{p_{j_{i k}}\\leftarrow p_{j_{i k}}+\\frac{1}{K M}}\\end{array}$ ; ", "page_idx": 5}, {"type": "text", "text": "indices $j\\,\\in\\,\\mathbb{N}^{M\\times L}$ of the nearest neighbors and the corresponding distances $\\pmb{d}\\in\\mathbb{R}^{M\\times L}$ , where $j_{i k}$ is the index of the $k^{\\mathrm{th}}$ nearest neighbor of $q_{i}$ in $\\mathcal{D}$ , and $d_{i k}$ is the distance between $q_{i}$ and $x_{j_{i k}}$ . Retrieving nearest neighbors exactly requires computing the distance between every query example and all the candidates, which is inefficient when the candidate size $N$ is in the order of millions and billions. Alternatively, we can employ approximate nearest search techniques [23, 16] to improve efficiency at the cost of lower accuracy. ", "page_idx": 5}, {"type": "text", "text": "Then the algorithms assign probability mass to the nearest neighbors of each example. KNN-Uniform determines $K$ based on the tradeoff between distribution alignment and diversity. Then the algorithm assigns the probability mass of each query example evenly to its $K$ -nearest neighbors. KNN-KDE assigns probability mass to the nearest neighbors proportional to the inverse of their kernel density estimates (Line 15-18). The sizes of the neighborhoods are determined by Line 7-12, where we increase the limit $s$ on the sum of the inverse of the density estimates over the neighborhood until the condition on Line 9 is satisfied. We use a priority queue to store the possible values $s$ can take and retrieve the smallest one in each iteration. ", "page_idx": 5}, {"type": "text", "text": "In KDE-KNN, we also precompute the kernel density estimate for the $L$ -nearest neighbors of each query example. To estimate the kernel density of each candidate example, we need to compute the distance between it and all the other candidate examples. To reduce the computational cost, we use the $I$ -nearest neighbors among the prefetched examples as the set to compute KDE for each candidate example. Let $\\mathcal{D}^{\\prime}$ be the set containing the $L$ -nearest neighbors of all the query points and ${\\mathcal{N}}_{x}$ be the $I$ -nearest neighbors of $x$ in $\\mathcal{D}^{\\prime}$ . We compute the KDE of example $x$ as $\\textstyle\\sum_{x^{\\prime}\\in{\\mathcal{N}}_{x}}(1-{\\frac{f(x,x^{\\prime})^{2}}{h^{2}}})$ . ", "page_idx": 5}, {"type": "text", "text": "KNN-Uniform runs in $O(M L+T_{1})$ time, and KNN-KDE runs in $O(M L\\log M+T_{2})$ time, where $T_{1}$ is the runtime of GETKNN, and $T_{2}$ is the runtime of COMPUTEKDE. With exact nearest neighbor search, $T_{1}=O(M N\\log N)$ and $T_{2}=O(M^{2}L^{2}\\log(M L))$ . If we employ approximate nearest neighbor search techniques such as HNSW [34] for real vectors and $l_{2}$ distance, we have $T_{1}=O((\\bar{M}+N)\\log N)$ and $\\bar{T}_{2}=O(M L\\log(M L))$ . ", "page_idx": 5}, {"type": "text", "text": "1 Input: query examples $\\mathcal{Q}=\\{q_{i}\\}_{i=1}^{M}$ , candidate examples $\\mathcal{D}=\\{x_{j}\\}_{j=1}^{N}$ , number of nearest   \nneighbors to prefetch $L>1$ , $\\alpha\\in[0,1]$ , $C>0$ ; Output: $p_{1},\\ldots,p_{N}$ ;   \n2 $j,d\\gets\\mathrm{GETKNN}(\\mathcal{Q},\\mathcal{D},L)$ ;   \n3 $\\rho\\gets\\mathrm{CoMPUTEKDE}(j,\\mathcal{D})\\,/*\\,\\,\\rho\\in\\mathbb{R}^{M\\times L}$ and $\\rho_{i k}$ is the density of $x_{j_{i k}}$ \\*/   \n4 $\\mathcal{H}\\leftarrow$ EmptyPriorityQueue();   \n5 for $i\\in[M]$ do   \n6 $K_{i}\\gets0$ ; $c_{i}\\gets0$ ; $\\mathcal{H}.\\mathrm{push}((1/\\rho_{i1},i))$ ;   \n7 while $\\mathcal{H}$ is not empty do   \n8 $s,i\\gets\\mathcal{H}$ .pop(); $K_{i}\\gets K_{i}+1$ ; $\\begin{array}{r}{c_{i}\\leftarrow\\sum_{k=1}^{K_{i}}(d_{i,K_{i}+1}-d_{i k})/\\rho_{i k}}\\end{array}$ ;   \n9 if $\\begin{array}{r}{\\frac{\\alpha}{C}\\sum_{i=1}^{M}c_{i}\\geq(1-\\alpha)M}\\end{array}$ then   \n10 $s^{*}\\gets s$ ; break;   \n11 if $K_{i}+1<L$ then   \n12 $\\begin{array}{r l}{\\vert}&{{}\\mathcal{H}.\\mathrm{push}((s+1/\\rho_{i,K_{i}+1},i));}\\end{array}$ ;   \n13 for $j\\in[N]$ do   \n14 $p_{j}\\leftarrow0$ ;   \n15 for $i\\in[M]$ do   \n16 for $\\bar{k}\\in[K_{i}]$ do   \n17 $\\begin{array}{r l}&{\\quad\\mid p_{j_{i k}}\\leftarrow p_{j_{i k}}+1/(M s^{*}\\cdot\\rho_{i k});}\\\\ &{\\quad\\mid p_{j_{i,K_{i}+1}}\\leftarrow p_{j_{i,K_{i}+1}}+\\frac{1}{M}-\\sum_{k=1}^{K_{i}}1/(M s^{*}\\cdot\\rho_{i k});}\\end{array}$   \n18 ", "page_idx": 6}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/4bf7e9483988db54f007efd3ba3a4d83a9cd1ce8cefccf3c8d12c01d3b32e5de.jpg", "table_caption": ["Table 1: Information of the target datasets for instruction tuning. "], "table_footnote": ["\\*# shots is the number of QA examples provided in the prompt when querying the model. "], "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate our framework on data selection for task-specific instruction tuning and domain-specific continued pretraining, using different encodings as needed. We show that 1) our framework outperforms the state-of-the-art methods on data selection for task-specific instruction tuning and domain-specific continued pretraining by up to 6 points and 3 points in F1 score respectively; 2) our framework is robust to duplicates, exhibiting consistent performance when $1\\%$ of the candidate examples are duplicated up to 1000 times, while baseline methods show a drop of 2 points in F1 score (see Appendix E.1); 3) our method is efficient, requiring 28 hours to preprocess 150 million candidate examples and less than 1 hour for each task-specific selection (see Appendix E.2). ", "page_idx": 6}, {"type": "text", "text": "5.1 Evaluation on Task-Specific Instruction Tuning ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We select training data to perform instruction tuning to tailor a model to specific downstream tasks. We assume access to several query examples that represent the use cases of the target task and a repository of instruction-response pairs to select from. The detailed setting is as follows. ", "page_idx": 6}, {"type": "text", "text": "Target Tasks, Model, and Data Repository We consider three tasks from standard benchmarks for language model evaluation. The properties are shown in Table 1. We use two models: LLAMA-2- 7B [43] and MISTRAL-7B [22]. We use a combination of FLAN V2 [31], COT [45], DOLLY [8], and OPEN ASSISTANT [26] as the data repository for selection, which contains 270K examples. ", "page_idx": 6}, {"type": "text", "text": "Encoding We encode the examples using rescaled and randomly projected gradients from a LLAMA2-7B model finetuned on a random $5\\%$ of the data repository. The encoding process follows Xia et al. [47], who show that gradient-based encoding is essential to capture the utility of training examples in instruction tuning. We use $l_{2}$ distance as the distance function. See Appendix C for the details. ", "page_idx": 6}, {"type": "text", "text": "Methods 1) Rand selects a random subset from the data repository; 2) LESS [47] (the stateof-the-art method on data selection for task-specific instruction tuning) selects training data from the data repository based on their gradient similarity to the query examples; 3) Ours is the KNNKDE instantiation of our framework with $C=5$ , $\\alpha=0.075$ and $h\\,=\\,0.2$ . We discuss how we choose the parameters in Appendix C. The implementation details of our method can also be found in Appendix C. Note that our method is not sensitive to the hyperparameters, as shown by the microbenchmarks in Appendix E. ", "page_idx": 7}, {"type": "text", "text": "Evaluation Protocol Following Xia et al. [47], we finetune the base model on the selected data for 4 epochs. The dataset size is $0.5\\%\\ /\\ 1.0\\%\\ /\\ 5\\%$ of the data repository. Since our method is based on probabilistic sampling, we do not select a fixed training set. Instead, in each epoch we sample randomly from the data repository following the assigned probability. The hyperparameters for finetuning also follow Xia et al. [47] (see Appendix D). We repeat each experiment for three runs with different random seeds and report the mean and standard deviation. ", "page_idx": 7}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/deffd0fe1a84212f54aa6c5c69aa2b002043ad837bbcd2137b9960d86452b26e.jpg", "table_caption": ["Table 2: Performance of instruction tuning with dataset selected by our method compared with the baselines. The subscripts represent the standard deviations. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Results The results are shown in Table 2 where \u201cBase\u201d is the base model without finetuning and \u201cFull\u201d is the model finetuned on the full data repository. Our method consistently outperforms the baselines on TydiQA and BBH across different selection ratios, beating the state-of-the-art method (LESS) by up to 6 points. With a selection ratio of $1\\%$ , our method outperforms the full data repository on TydiQA and BBH. On MMLU, our methods show comparable results to LESS. Note that for MISTRAL-7B, finetuning on the full repository leads to worse performance than no finetuning, which highlights the importance of careful data selection for task-specific instruction tuning. We also notice that finetuning MISTRAL-7B on any selected set does not increase its accuracy on MMLU. The reason could be that the base MISTRAL-7B model has already been well-tuned for multiple-choice questions using high-quality data. We observe a drop in the performance of our method on TydiQA when the selection ratio increases from $1\\%$ to $5\\%$ , which may be caused by overftiting. We can early stop the training process to avoid overfitting in practice. ", "page_idx": 7}, {"type": "text", "text": "5.2 Evaluation on Domain-Specific Continued Pretraining ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this experiment, we select data for domain-specific continued pretraining to adapt a model to a specific domain. We assume access to a set of annotated data for a domain-specific task that serves as query examples and a repository of unlabeled data to select from. We continue pretraining the base model on the selected data and then perform supervised finetuning using the annotated data. ", "page_idx": 7}, {"type": "text", "text": "Target Tasks and Data Repository We consider four datasets focused on classification tasks across diverse domains. The properties are provided in Table 3. We select data for continued pertaining from a data repository consisting of 150M sequences crafted by Xie et al. [48] from The Pile [14]. ", "page_idx": 7}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/196c46839b9b0a089cc37a108ae860d8d6d4007f3de91642f63158ebe2009176.jpg", "table_caption": ["Table 3: Training, validation, test sizes and the number of classes in the datasets. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/efe7b5a73c6b2531251c6330257dd1fcd3c60cb2fc830d71263506c2cd74c6bf.jpg", "table_caption": ["Table 4: F1 scores of the downstream tasks. Standard deviations are shown in the subscripts. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Target-Domain Data Accessibility To simulate different levels of access to target-domain annotated data, we consider three settings with varying sizes of annotated data (1K, 3K, and 10K). When the size is set to $M$ and the original target-domain training set is larger than $M$ , we sub-sample it by choosing $M$ examples uniformly at random without replacement. ", "page_idx": 8}, {"type": "text", "text": "Encoding We encode the examples into $\\mathbb{R}^{512}$ using the Universal Sentence Encoder [5] to capture semantic meanings and use $l_{2}$ distance as the distance function. ", "page_idx": 8}, {"type": "text", "text": "Methods 1) Rand selects a random subset from the data repository; 2) DSIR [47] (the state-ofthe-art method on data selection for domain-specific continued pretraining) selects examples by importance resampling to match the unigram and bigram distribution of the query examples.; 3) Ours is the KNN-KDE instantiation of our framework with $C=5$ , $\\alpha=0.6$ and $h=0.1$ . ", "page_idx": 8}, {"type": "text", "text": "Evaluation Protocol For each domain-specific task, we provide the annotated set to the selection methods as the query examples to guide the selection. We perform continued pretraining on 1M examples selected by each method from the data repository for one epoch (see Appendix E.4 for different selection sizes), starting from the base ALBERT [27] model. Then we finetune the model on the domain-specific annotated set and evaluate it on the test set. The hyperparameters for training follow previous works [17, 49, 48] (see Appendix D). The experiments are repeated five times with varying random seeds. We remove the best and the worst among the five runs to rule out outlier runs and report the mean and standard deviation. ", "page_idx": 8}, {"type": "text", "text": "Results The test F1 scores of the downstream classification tasks are reported in Table 4. As a reference point, we provide the performance of finetuning the model directly without continued pretraining (Base). Our method outperforms the baselines in most cases except ChemProt (3K) and AGNews (1K), with a gap of up to 3 points in F1 scores. On ChemProt (3K) and AGNews (1K), our method is comparable to DSIR. We also notice that our method shows an average improvement of 1.92 points over DSIR with an annotated set size of 1K and 0.38 points with an annotated set size of 3K. This indicates that our method is particularly effective with small annotated sets. ", "page_idx": 8}, {"type": "text", "text": "6 Related Works ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Task-Specific Data Selection Similarity-based methods [39, 17, 2, 50] retrieves the top ones from the candidates, ranked by their similarity to the representative examples from the target task. The features used for similarity computation can be embeddings or ngrams for texts. Another line of works [35, 48] use two generative models where one learns the distribution of the target-task data and the other learns the general-purpose data. Model-specific data selection methods [12, 47] choose data to maximize the model performance on the target task. Given the high cost of actually training a model and evaluating it on the target task, these methods often estimate the model performance by approximation. DSDM [12] approximate the model performance using datamodels [21], a function that maps the training data membership (whether each candidate is included in the training set or not) to the model performance. LESS [47] employs the influence function [24] to approximate the marginal gain on the model performance when including a candidate into the training set. Specifically, LESS computes the gradient similarity between each candidate and all the query examples, and the maximum similarity is the score for ranking. Then the top-ranked candidates are selected. A major difference between our method and LESS is that our method matches the distributions, while LESS takes the top ones based on aggregated statistics. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Diversity Measurement for Data Selection Measuring diversity is a critical aspect of data selection, as it ensures that the chosen dataset represents a wide range of examples rather than being overly concentrated on similar or redundant instances. DEITA [29] selects data in an iterative manner, where the contribution of a new example to the overall diversity is measured by the clipped cosine distance between the new example and the closest examples that have been selected. QDIT [4] measures the diversity of the selected data using the facility location function that quantifies how well each example in the full set is represented by the selected set. Wang et al. [44] measure the diversity using the log determinant distance between the selected set and a reference set that is maximally diverse. ", "page_idx": 9}, {"type": "text", "text": "Data Deduplication Data deduplication removes duplicates or near-duplicates from a dataset. Exact duplicates can be detected using hash functions [11, 46], while the detection of near-duplicates is more challenging. Some works [37, 14] identify near-duplicates utilizing locality-sensitive hashing [15]. Others [28, 6] compute edit distances between examples to find near-duplicates. Another line of works [1, 42] relies on learned embeddings of the examples to detect near-duplicates. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we proposed a framework for data selection for task-specific model finetuning, based on optimal transport, which allows a smooth tradeoff between distribution alignment and diversity. We incorporated kernel density estimation to make the selection robust to near-duplicates. Experimentally we showed that our method is effective in both task-specific instruction tuning and domain-specific continued pretraining. A potential direction for future work is to incorporate more efficient variants of optimal transport, such as Sinkhorn distances [9], to further improve the computational efficiency. One limitation of our framework is the reliance on a set of representative examples to guide the selection, which may not be easy to craft. The representative examples may also contain biases that can be exaggerated through the selection process, leading to negative social impacts. In practice, additional effort must be allocated to ensure the quality of the representative examples and the size of the representative examples needs to be decided according to the budget of human effort. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] ABBAS, A., TIRUMALA, K., SIMIG, D., GANGULI, S., AND MORCOS, A. S. Semdedup: Data-efficient learning at web-scale through semantic deduplication, 2023.   \n[2] AHARONI, R., AND GOLDBERG, Y. Unsupervised domain clusters in pretrained language models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (Online, July 2020), D. Jurafsky, J. Chai, N. Schluter, and J. Tetreault, Eds., Association for Computational Linguistics, pp. 7747\u20137763.   \n[3] BOMMASANI, R., HUDSON, D. A., ADELI, E., ALTMAN, R., ARORA, S., VON ARX, S., BERNSTEIN, M. S., BOHG, J., BOSSELUT, A., BRUNSKILL, E., ET AL. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021).   \n[4] BUKHARIN, A., AND ZHAO, T. Data diversity matters for robust instruction tuning, 2024.   \n[5] CER, D., YANG, Y., YI KONG, S., HUA, N., LIMTIACO, N., JOHN, R. S., CONSTANT, N., GUAJARDO-CESPEDES, M., YUAN, S., TAR, C., SUNG, Y.-H., STROPE, B., AND KURZWEIL, R. Universal sentence encoder, 2018.   \n[6] CHOWDHERY, A., NARANG, S., DEVLIN, J., BOSMA, M., MISHRA, G., ROBERTS, A., BARHAM, P., CHUNG, H. W., SUTTON, C., GEHRMANN, S., SCHUH, P., SHI, K., TSVYASHCHENKO, S., MAYNEZ, J., RAO, A., BARNES, P., TAY, Y., SHAZEER, N., PRABHAKARAN, V., REIF, E., DU, N., HUTCHINSON, B., POPE, R., BRADBURY, J., AUSTIN, J., ISARD, M., GUR-ARI, G., YIN, P., DUKE, T., LEVSKAYA, A., GHEMAWAT, S., DEV, S., MICHALEWSKI, H., GARCIA, X., MISRA, V., ROBINSON, K., FEDUS, L., ZHOU, D., IPPOLITO, D., LUAN, D., LIM, H., ZOPH, B., SPIRIDONOV, A., SEPASSI, R., DOHAN, D., AGRAWAL, S., OMERNICK, M., DAI, A. M., PILLAI, T. S., PELLAT, M., LEWKOWYCZ, A., MOREIRA, E., CHILD, R., POLOZOV, O., LEE, K., ZHOU, Z., WANG, X., SAETA, B., DIAZ, M., FIRAT, O., CATASTA, M., WEI, J., MEIER-HELLSTERN, K., ECK, D., DEAN, J., PETROV, S., AND FIEDEL, N. Palm: scaling language modeling with pathways. J. Mach. Learn. Res. 24, 1 (mar 2024). [7] CLARK, J. H., CHOI, E., COLLINS, M., GARRETTE, D., KWIATKOWSKI, T., NIKOLAEV, V., AND PALOMAKI, J. TyDi QA: A benchmark for information-seeking question answering in typologically diverse languages. Transactions of the Association for Computational Linguistics 8 (2020), 454\u2013470. [8] CONOVER, M., HAYES, M., MATHUR, A., XIE, J., WAN, J., SHAH, S., GHODSI, A., WENDELL, P., ZAHARIA, M., AND XIN, R. Free dolly: Introducing the world\u2019s first truly open instruction-tuned llm, 2023.   \n[9] CUTURI, M. Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in Neural Information Processing Systems (2013), C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Weinberger, Eds., vol. 26, Curran Associates, Inc.   \n[10] DEVLIN, J., CHANG, M.-W., LEE, K., AND TOUTANOVA, K. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (Minneapolis, Minnesota, June 2019), Association for Computational Linguistics, pp. 4171\u20134186.   \n[11] ELAZAR, Y., BHAGIA, A., MAGNUSSON, I. H., RAVICHANDER, A., SCHWENK, D., SUHR, A., WALSH, E. P., GROENEVELD, D., SOLDAINI, L., SINGH, S., HAJISHIRZI, H., SMITH, N. A., AND DODGE, J. What\u2019s in my big data? In The Twelfth International Conference on Learning Representations (2024).   \n[12] ENGSTROM, L., FELDMANN, A., AND MADRY, A. Dsdm: Model-aware dataset selection with datamodels, 2024.   \n[13] FR\u00d6BE, M., BEVENDORFF, J., GIENAPP, L., V\u00d6LSKE, M., STEIN, B., POTTHAST, M., AND HAGEN, M. Copycat: Near-duplicates within and between the clueweb and the common crawl. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (New York, NY, USA, 2021), SIGIR \u201921, Association for Computing Machinery, p. 2398\u20132404.   \n[14] GAO, L., BIDERMAN, S., BLACK, S., GOLDING, L., HOPPE, T., FOSTER, C., PHANG, J., HE, H., THITE, A., NABESHIMA, N., PRESSER, S., AND LEAHY, C. The pile: An 800gb dataset of diverse text for language modeling, 2020.   \n[15] GIONIS, A., INDYK, P., MOTWANI, R., ET AL. Similarity search in high dimensions via hashing. In Vldb (1999), vol. 99, pp. 518\u2013529.   \n[16] GUO, R., SUN, P., LINDGREN, E., GENG, Q., SIMCHA, D., CHERN, F., AND KUMAR, S. Accelerating large-scale inference with anisotropic vector quantization. In International Conference on Machine Learning (2020), PMLR, pp. 3887\u20133896.   \n[17] GURURANGAN, S., MARASOVI \u00b4C, A., SWAYAMDIPTA, S., LO, K., BELTAGY, I., DOWNEY, D., AND SMITH, N. A. Don\u2019t stop pretraining: Adapt language models to domains and tasks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (Online, July 2020), Association for Computational Linguistics, pp. 8342\u20138360.   \n[18] HENDRYCKS, D., BURNS, C., BASART, S., ZOU, A., MAZEIKA, M., SONG, D., AND STEINHARDT, J. Measuring massive multitask language understanding. In International Conference on Learning Representations (2021).   \n[19] HERNANDEZ, D., BROWN, T., CONERLY, T., DASSARMA, N., DRAIN, D., EL-SHOWK, S., ELHAGE, N., HATFIELD-DODDS, Z., HENIGHAN, T., HUME, T., JOHNSTON, S., MANN, B., OLAH, C., OLSSON, C., AMODEI, D., JOSEPH, N., KAPLAN, J., AND MCCANDLISH, S. Scaling laws and interpretability of learning from repeated data, 2022.   \n[20] HU, E. J., SHEN, Y., WALLIS, P., ALLEN-ZHU, Z., LI, Y., WANG, S., WANG, L., AND CHEN, W. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations (2022).   \n[21] ILYAS, A., PARK, S. M., ENGSTROM, L., LECLERC, G., AND MADRY, A. Datamodels: Understanding predictions with data and data with predictions. In Proceedings of the 39th International Conference on Machine Learning (17\u201323 Jul 2022), K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, Eds., vol. 162 of Proceedings of Machine Learning Research, PMLR, pp. 9525\u20139587.   \n[22] JIANG, A. Q., SABLAYROLLES, A., MENSCH, A., BAMFORD, C., CHAPLOT, D. S., DE LAS CASAS, D., BRESSAND, F., LENGYEL, G., LAMPLE, G., SAULNIER, L., LAVAUD, L. R., LACHAUX, M.-A., STOCK, P., SCAO, T. L., LAVRIL, T., WANG, T., LACROIX, T., AND SAYED, W. E. Mistral 7b, 2023.   \n[23] JOHNSON, J., DOUZE, M., AND J\u00c9GOU, H. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data 7, 3 (2019), 535\u2013547.   \n[24] KOH, P. W., AND LIANG, P. Understanding black-box predictions via influence functions. In Proceedings of the 34th International Conference on Machine Learning - Volume 70 (2017), ICML\u201917, JMLR.org, p. 1885\u20131894.   \n[25] KRINGELUM, J., KJAERULFF, S. K., BRUNAK, S., LUND, O., OPREA, T. I., AND TABOUREAU, O. Chemprot-3.0: a global chemical biology diseases mapping. Database 2016 (2016), bav123.   \n[26] K\u00d6PF, A., KILCHER, Y., VON R\u00dcTTE, D., ANAGNOSTIDIS, S., TAM, Z.-R., STEVENS, K., BARHOUM, A., DUC, N. M., STANLEY, O., NAGYFI, R., ES, S., SURI, S., GLUSHKOV, D., DANTULURI, A., MAGUIRE, A., SCHUHMANN, C., NGUYEN, H., AND MATTICK, A. Openassistant conversations \u2013 democratizing large language model alignment, 2023.   \n[27] LAN, Z., CHEN, M., GOODMAN, S., GIMPEL, K., SHARMA, P., AND SORICUT, R. ALBERT: A lite BERT for self-supervised learning of language representations. CoRR abs/1909.11942 (2019).   \n[28] LEE, K., IPPOLITO, D., NYSTROM, A., ZHANG, C., ECK, D., CALLISON-BURCH, C., AND CARLINI, N. Deduplicating training data makes language models better. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (Dublin, Ireland, May 2022), Association for Computational Linguistics, pp. 8424\u20138445.   \n[29] LIU, W., ZENG, W., HE, K., JIANG, Y., AND HE, J. What makes good data for alignment? a comprehensive study of automatic data selection in instruction tuning. In The Twelfth International Conference on Learning Representations (2024).   \n[30] LIU, Y., OTT, M., GOYAL, N., DU, J., JOSHI, M., CHEN, D., LEVY, O., LEWIS, M., ZETTLEMOYER, L., AND STOYANOV, V. Roberta: A robustly optimized BERT pretraining approach. CoRR abs/1907.11692 (2019).   \n[31] LONGPRE, S., HOU, L., VU, T., WEBSON, A., CHUNG, H. W., TAY, Y., ZHOU, D., LE, Q. V., ZOPH, B., WEI, J., ET AL. The flan collection: Designing data and methods for effective instruction tuning. arXiv preprint arXiv:2301.13688 (2023).   \n[32] LUAN, Y., HE, L., OSTENDORF, M., AND HAJISHIRZI, H. Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (Brussels, Belgium, Oct.-Nov. 2018), E. Riloff, D. Chiang, J. Hockenmaier, and J. Tsujii, Eds., Association for Computational Linguistics, pp. 3219\u20133232.   \n[33] MAAS, A. L., DALY, R. E., PHAM, P. T., HUANG, D., NG, A. Y., AND POTTS, C. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (Portland, Oregon, USA, June 2011), D. Lin, Y. Matsumoto, and R. Mihalcea, Eds., Association for Computational Linguistics, pp. 142\u2013150.   \n[34] MALKOV, Y. A., AND YASHUNIN, D. A. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and machine intelligence 42, 4 (2018), 824\u2013836.   \n[35] MOORE, R. C., AND LEWIS, W. Intelligent selection of language model training data. In Proceedings of the ACL 2010 Conference Short Papers (Uppsala, Sweden, July 2010), J. Hajic\u02c7, S. Carberry, S. Clark, and J. Nivre, Eds., Association for Computational Linguistics, pp. 220\u2013 224. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "[36] PARZEN, E. On estimation of a probability density function and mode. The annals of mathematical statistics 33, 3 (1962), 1065\u20131076. ", "page_idx": 12}, {"type": "text", "text": "[37] RAE, J. W., BORGEAUD, S., CAI, T., MILLICAN, K., HOFFMANN, J., SONG, F., ASLANIDES, J., HENDERSON, S., RING, R., YOUNG, S., RUTHERFORD, E., HENNIGAN, T., MENICK, J., CASSIRER, A., POWELL, R., VAN DEN DRIESSCHE, G., HENDRICKS, L. A., RAUH, M., HUANG, P.-S., GLAESE, A., WELBL, J., DATHATHRI, S., HUANG, S., UESATO, J., MELLOR, J., HIGGINS, I., CRESWELL, A., MCALEESE, N., WU, A., ELSEN, E., JAYAKUMAR, S., BUCHATSKAYA, E., BUDDEN, D., SUTHERLAND, E., SIMONYAN, K., PAGANINI, M., SIFRE, L., MARTENS, L., LI, X. L., KUNCORO, A., NEMATZADEH, A., GRIBOVSKAYA, E., DONATO, D., LAZARIDOU, A., MENSCH, A., LESPIAU, J.-B., TSIMPOUKELLI, M., GRIGOREV, N., FRITZ, D., SOTTIAUX, T., PAJARSKAS, M., POHLEN, T., GONG, Z., TOYAMA, D., DE MASSON D\u2019AUTUME, C., LI, Y., TERZI, T., MIKULIK, V., BABUSCHKIN, I., CLARK, A., DE LAS CASAS, D., GUY, A., JONES, C., BRADBURY, J., JOHNSON, M., HECHTMAN, B., WEIDINGER, L., GABRIEL, I., ISAAC, W., LOCKHART, E., OSINDERO, S., RIMELL, L., DYER, C., VINYALS, O., AYOUB, K., STANWAY, J., BENNETT, L., HASSABIS, D., KAVUKCUOGLU, K., AND IRVING, G. Scaling language models: Methods, analysis & insights from training gopher, 2022.   \n[38] RUDER, S., AND PLANK, B. Learning to select data for transfer learning with Bayesian optimization. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (Copenhagen, Denmark, Sept. 2017), Association for Computational Linguistics, pp. 372\u2013382.   \n[39] RUDER, S., AND PLANK, B. Learning to select data for transfer learning with Bayesian optimization. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (Copenhagen, Denmark, Sept. 2017), M. Palmer, R. Hwa, and S. Riedel, Eds., Association for Computational Linguistics, pp. 372\u2013382.   \n[40] SHACHAF, G., BRUTZKUS, A., AND GLOBERSON, A. A theoretical analysis of fine-tuning with linear teachers. In Advances in Neural Information Processing Systems (2021), M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, Eds., vol. 34, Curran Associates, Inc., pp. 15382\u201315394.   \n[41] SUZGUN, M., SCALES, N., SCH\u00c4RLI, N., GEHRMANN, S., TAY, Y., CHUNG, H. W., CHOWDHERY, A., LE, Q. V., CHI, E. H., ZHOU, D., , AND WEI, J. Challenging big-bench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261 (2022).   \n[42] TIRUMALA, K., SIMIG, D., AGHAJANYAN, A., AND MORCOS, A. S. D4: Improving llm pretraining via document de-duplication and diversification, 2023.   \n[43] TOUVRON, H., LAVRIL, T., IZACARD, G., MARTINET, X., LACHAUX, M.-A., LACROIX, T., ROZI\u00c8RE, B., GOYAL, N., HAMBRO, E., AZHAR, F., RODRIGUEZ, A., JOULIN, A., GRAVE, E., AND LAMPLE, G. Llama: Open and efficient foundation language models, 2023.   \n[44] WANG, P., SHEN, Y., GUO, Z., STALLONE, M., KIM, Y., GOLLAND, P., AND PANDA, R. Diversity measurement and subset selection for instruction tuning datasets, 2024.   \n[45] WEI, J., WANG, X., SCHUURMANS, D., BOSMA, M., BRIAN ICHTER, XIA, F., CHI, E. H., LE, Q. V., AND ZHOU, D. Chain of thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems (2022), A. H. Oh, A. Agarwal, D. Belgrave, and K. Cho, Eds.   \n[46] WENZEK, G., LACHAUX, M.-A., CONNEAU, A., CHAUDHARY, V., GUZM\u00c1N, F., JOULIN, A., AND GRAVE, E. CCNet: Extracting high quality monolingual datasets from web crawl data. In Proceedings of the Twelfth Language Resources and Evaluation Conference (Marseille, France, May 2020), N. Calzolari, F. B\u00e9chet, P. Blache, K. Choukri, C. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Maegaard, J. Mariani, H. Mazo, A. Moreno, J. Odijk, and S. Piperidis, Eds., European Language Resources Association, pp. 4003\u20134012.   \n[47] XIA, M., MALLADI, S., GURURANGAN, S., ARORA, S., AND CHEN, D. Less: Selecting influential data for instruction tuning.   \n[48] XIE, S. M., SANTURKAR, S., MA, T., AND LIANG, P. Data selection for language models via importance resampling. arXiv preprint arXiv:2302.03169 (2023).   \n[49] YAO, X., ZHENG, Y., YANG, X., AND YANG, Z. NLP from scratch without large-scale pretraining: A simple and efficient framework. CoRR abs/2111.04130 (2021).   \n[50] YAO, X., ZHENG, Y., YANG, X., AND YANG, Z. NLP from scratch without large-scale pretraining: A simple and efficient framework. In Proceedings of the 39th International Conference on Machine Learning (17\u201323 Jul 2022), K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, Eds., vol. 162 of Proceedings of Machine Learning Research, PMLR, pp. 25438\u201325451.   \n[51] ZHANG, S., DONG, L., LI, X., ZHANG, S., SUN, X., WANG, S., LI, J., HU, R., ZHANG, T., WU, F., AND WANG, G. Instruction tuning for large language models: A survey, 2024.   \n[52] ZHANG, X., ZHAO, J. J., AND LECUN, Y. Character-level convolutional networks for text classification. CoRR abs/1509.01626 (2015). ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Closed-Form Solution and Algorithm for $G_{\\mathbf{TV}}$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "When $G\\,=\\,G_{\\mathrm{TV}}$ , for each query example, we transport $\\frac{1}{M N}$ probability mass to any candidate example whose distance to the query example is less than $\\textstyle{\\frac{(1-\\alpha)C}{2\\alpha}}$ plus the distance between the query example and its 1-nearest neighbor. Then we transport all the remaining probability mass to the 1-nearest neighbor of each query example. ", "page_idx": 14}, {"type": "text", "text": "Theorem A.1. Given $\\pmb{d}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ where $N>1$ , consider Problem RT with $G(\\gamma)=G_{T V}(\\gamma)=$ $\\begin{array}{r}{{\\frac{1}{2}}\\sum_{i=1}^{M}\\sum_{j=1}^{N}|\\gamma_{i j}\\,-\\,{\\frac{1}{M N}}|}\\end{array}$ . For all $i~\\in~[M],$ , let $j_{1}^{i},\\dots,j_{N}^{i}$ be a reordering of $[N]$ such that $d_{i j_{1}^{i}}\\leq\\dots\\leq d_{i j_{N}^{i}}$ . Consider $\\gamma^{*}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ where $\\forall i\\in[M]$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\forall k\\in\\{2,\\ldots,N\\},\\gamma_{i j_{k}^{i}}^{*}=\\left\\{\\frac{1}{M N},\\ \\ \\ i f d_{i j_{k}^{i}}-d_{i j_{1}^{i}}<\\frac{(1-\\alpha)C}{\\alpha}\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\gamma_{i j_{1}^{i}}^{*}=\\frac{1}{M}-\\sum_{k=2}^{N}\\gamma_{i j_{k}^{i}}^{*}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then $\\gamma^{*}$ is a minimizer of Problem RT. $\\gamma^{*}$ is the unique minimizer $i f\\forall i\\in[M]\\forall k\\in[N],d_{i j_{k}^{i}}-d_{i j_{1}^{i}}\\neq$ $\\frac{(1\\!-\\!\\alpha)C}{\\alpha}$ \u03b1 and dij1i \u0338= dij2i. ", "page_idx": 14}, {"type": "text", "text": "The corresponding algorithm is KNN-T (Algorithm 3). KNN-TV assigns $\\frac{1}{M N}$ unit of probability mass to the nearest neighbors that satisfy the distance condition in Line 9 and the rest to the 1-nearest neighbor. KNN-TV has the same time complexity as KNN-Uniform. ", "page_idx": 14}, {"type": "text", "text": "Algorithm 3: KNN-TV. ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "1 Input: query examples $\\mathcal{Q}=\\{q_{i}\\}_{i=1}^{M}$ , candidate examples $\\mathcal{D}=\\{x_{j}\\}_{j=1}^{N}$ , number of nearest   \nneighbors to prefetch $L$ , $\\alpha\\in[0,1]$ , $C>0$ ;   \n2 Output: $p_{1},\\ldots,p_{N}$ ;   \n3 $j,d\\gets\\mathrm{GETKNN}(\\mathcal{Q},\\mathcal{D},L)$ ;   \n4 for $j\\in[N]$ do   \n5\u2014 $p_{j}\\leftarrow0$ ;   \n6 for $i\\in[M]$ do   \n7 $\\begin{array}{r}{p_{j_{i1}}\\gets p_{j_{i1}}+\\frac{1}{M}}\\end{array}$ ;   \n8 $k\\leftarrow2$ ;   \n9 while $k\\leq L$ and $\\begin{array}{r}{\\frac{\\alpha}{C}(\\underline{{d}}_{i k}-d_{i1})<\\frac{1}{2}(1-\\alpha)}\\end{array}$ do   \n10 $\\begin{array}{r l}&{p_{j_{i k}}\\leftarrow p_{j_{i k}}+\\frac{1}{M N}}\\\\ &{p_{j_{i1}}\\leftarrow p_{j_{i1}}-\\frac{1}{M N}}\\\\ &{k\\leftarrow k+1;}\\end{array}$ ;   \n11 ;   \n12 ", "page_idx": 14}, {"type": "text", "text": "B Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Proof of Theorem A.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof. Let $\\begin{array}{r}{\\mathcal{L}(\\gamma)=\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{j=1}^{N}\\gamma_{i j}d_{i j}+(1-\\alpha)G_{\\mathrm{TV}}(\\gamma)}\\end{array}$ be the optimization objective. We prove the theorem by showing that for any $\\gamma^{\\prime}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ that satisfy the constraint $\\begin{array}{r}{(\\forall i\\in[M]\\sum_{j=1}^{N}\\gamma_{i j}^{\\prime}=}\\end{array}$ ${\\frac{1}{M}};$ ), $\\mathcal{L}(\\gamma^{\\prime})\\geq\\mathcal{L}(\\gamma^{*})$ . ", "page_idx": 14}, {"type": "text", "text": "$\\gamma^{\\prime\\prime}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ be a probability transport such that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\forall k\\in\\{2,\\ldots,N\\},\\gamma_{i j_{k}^{i}}^{\\prime\\prime}=\\left\\{\\!\\!\\begin{array}{l l}{\\gamma_{i j_{k}^{i}}^{\\prime},}&{\\mathrm{if~}d_{i j_{k}^{i}}-d_{i j_{1}^{i}}<\\frac{(1-\\alpha)C}{\\alpha}\\ }\\\\ {0,}&{\\mathrm{otherwise}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We show that $\\mathcal{L}(\\gamma^{\\prime})\\ge\\mathcal{L}(\\gamma^{\\prime\\prime})$ . For any $i\\in[M]$ , let $\\begin{array}{r}{\\hat{k}_{i}=\\operatorname*{max}\\big\\{k\\in[N]|d_{i j_{k}^{i}}-d_{i j_{1}^{i}}<\\frac{(1-\\alpha)C}{\\alpha}\\big\\}.}\\end{array}$ Then we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{L}(\\gamma^{\\prime})-\\mathcal{L}(\\gamma^{\\prime\\prime})=\\frac{\\alpha}{C}\\displaystyle\\sum_{i=1\\bmod1}^{M}\\langle\\gamma_{i,j}^{\\prime}-\\gamma_{i,j}^{\\prime\\prime}\\rangle d_{i j}+\\frac{1-\\alpha}{2}\\displaystyle\\sum_{i=1}^{M}\\sum_{j=1}^{N}(|\\gamma_{i,j}^{\\prime}-\\frac{1}{M N}|^{-}|-|\\gamma_{i,j}^{\\prime\\prime}-\\frac{1}{M N}|^{1})}&{}\\\\ {=\\displaystyle\\sum_{i=1}^{M}\\sum_{j=1}^{N}(\\overline{{C}}d_{i,j}(\\gamma_{i,j}^{\\prime}-\\gamma_{i,j}^{\\prime\\prime}))+\\frac{1-\\alpha}{2}(|\\gamma_{i}^{\\prime}-\\frac{1}{M N}|^{-}|-|\\gamma_{i,j}^{\\prime\\prime}-\\frac{1}{M N}|^{1})}&{}\\\\ {=\\displaystyle\\sum_{i=1\\bmod1}^{M}\\sum_{j=1}^{N}(\\overline{{C}}d_{i,j}(\\gamma_{i,j}^{\\prime}-\\gamma_{i,j}^{\\prime\\prime}))+\\frac{1-\\alpha}{2}(|\\gamma_{i,j}^{\\prime}-\\frac{1}{M N}|^{-}|-|\\gamma_{i,j}^{\\prime\\prime}-\\frac{1}{M N}|^{1})}&{}\\\\ {=\\displaystyle\\sum_{i=1}^{M}\\sum_{k\\neq i+1}^{N}\\frac{\\alpha}{C}\\Big(d_{i,j}(\\overline{{C}}d_{i,j}^{\\prime}-d_{i,j})\\gamma_{i,j}^{\\prime}+\\displaystyle\\sum_{k=i+1}^{1-\\alpha}\\sum_{k=i+1}^{N}(|\\gamma_{i,j}^{\\prime}-\\frac{1}{M N}|-\\frac{1}{M N})^{+}}&{}\\\\ {\\quad-\\displaystyle\\sum_{i=1}^{M}\\sum_{k\\neq i+1}^{N}\\overline{{C}}\\frac{|\\gamma_{i,j}^{\\prime}|}{1}+\\displaystyle\\sum_{k=i+1}^{M}\\sum_{j=i+1}^{N}\\frac{\\gamma_{i,j}^{\\prime}}{M_{k}^{-}}-\\frac{1}{M N}|\\gamma_{i,j}^{\\prime}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The last equation is due to the fact that $\\gamma_{i j_{k}^{i}}^{\\prime\\prime}\\,=\\,0$ for $k\\,>\\,\\hat{k}_{i}$ and $\\begin{array}{r}{\\gamma_{i j_{1}^{i}}^{\\prime\\prime}\\,=\\,\\gamma_{i j_{1}^{i}}^{\\prime}\\,+\\,\\sum_{k=\\hat{k}_{i}+1}^{N}\\gamma_{i j_{k}^{i}}^{\\prime}\\,}\\end{array}$ . Since $\\begin{array}{r}{d_{i j_{k}^{i}}-d_{i j_{1}^{i}}\\geq\\frac{(1-\\alpha)C}{\\alpha}}\\end{array}$ for any $k>\\hat{k}_{i}$ , we have $\\begin{array}{r}{T_{1}\\geq(1-\\alpha)\\sum_{k=\\hat{k}_{i}+1}^{N}\\gamma_{i j_{k}^{i}}^{\\prime}}\\end{array}$ . By the triangle equality, we have $\\begin{array}{r}{T_{2}\\geq\\frac{1-\\alpha}{2}\\sum_{k=\\hat{k}_{i}+1}^{N}(-\\gamma_{i j_{k}^{i}}^{\\prime})}\\end{array}$ and $\\begin{array}{r}{T_{3}\\ge\\frac{1-\\alpha}{2}\\sum_{k=\\hat{k}_{i}+1}^{N}(-\\gamma_{i j_{k}^{i}}^{\\prime})}\\end{array}$ . Therefore, we have $T_{1}+T_{2}+T_{3}\\geq0$ and consequently $\\mathcal{L}(\\gamma^{\\prime})\\stackrel{\\cdot\\cdot}{\\geq}\\mathcal{L}(\\gamma^{\\prime\\prime})$ . ", "page_idx": 15}, {"type": "text", "text": "Let $\\begin{array}{r}{\\mathcal{K}_{\\mathrm{high}}^{i}=\\big\\{2\\le k\\le\\hat{k}_{i}\\big|\\gamma_{i j_{k}^{i}}^{\\prime\\prime}>\\frac{1}{M N}\\big\\}}\\end{array}$ and $\\begin{array}{r}{\\mathcal{K}_{\\mathrm{low}}^{i}=\\{2\\le k\\le\\hat{k}_{i}|\\gamma_{i j_{k}^{i}}^{\\prime\\prime}<\\frac{1}{M N}\\}}\\end{array}$ . Let $\\gamma^{\\prime\\prime\\prime}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ be a probability transport such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\forall k\\in\\{2,\\ldots,N\\},\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}=\\left\\{\\!\\!\\begin{array}{l l}{\\gamma_{i j_{k}^{i}}^{*},}&{\\mathrm{if}\\ k\\in\\mathcal{K}_{\\mathrm{high}}^{i}}\\\\ {\\gamma_{i j_{k}^{i}}^{\\prime\\prime},}&{\\mathrm{otherwise}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then we show that $\\mathcal{L}(\\gamma^{\\prime\\prime})~\\geq~\\mathcal{L}(\\gamma^{\\prime\\prime\\prime})$ . Since $\\begin{array}{r l r}{\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}\\!}&{{}=}&{\\!\\frac{1}{M N}}\\end{array}$ for $k\\ \\in\\ \\mathcal{K}_{\\mathrm{high}}^{i}$ and $\\gamma_{i j_{1}^{i}}^{\\prime\\prime\\prime}~=~\\gamma_{i j_{1}^{i}}^{\\prime\\prime}~+$ $\\begin{array}{r}{\\sum_{k\\in K_{\\mathrm{high}}^{i}}(\\gamma_{i j_{k}^{i}}^{\\prime\\prime}-\\frac{1}{M N})}\\end{array}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}(\\gamma^{\\prime\\prime})-\\mathcal{L}(\\gamma^{\\prime\\prime\\prime})=\\!\\!\\!\\sum_{i=1}^{M}\\![\\displaystyle\\sum_{k\\in K_{\\!\\mathrm{i}p h}^{i}}\\frac{\\alpha}{C}(d_{i j_{k}^{\\,i}}-d_{i j_{1}^{\\,i}})(\\gamma_{i j_{k}^{\\,j}}^{\\prime\\prime}-\\frac{1}{M N})+\\underbrace{\\frac{1-\\alpha}{2}\\displaystyle\\sum_{k\\in K_{\\!\\mathrm{i}p h}^{i}}|\\gamma_{i j_{k}^{\\,i}}^{\\prime\\prime}-\\frac{1}{M N}|}_{T_{5}}+}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\frac{1-\\alpha}{2}(|\\gamma_{i j_{1}^{\\,i}}^{\\prime\\prime}-\\displaystyle\\frac{1}{M N}|-|\\gamma_{i j_{1}^{\\,j}}^{\\prime\\prime}+\\displaystyle\\sum_{k\\in K_{\\!\\mathrm{i}p h}^{i}}(\\gamma_{i j_{k}^{\\,j}}^{\\prime\\prime}-\\displaystyle\\frac{1}{M N})-\\frac{1}{M N}|)]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\cdot}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Again by the triangle inequality, we have $\\begin{array}{r}{T_{6}\\geq-\\frac{1-\\alpha}{2}\\sum_{k\\in\\mathcal{K}_{\\mathrm{high}}^{i}}|\\gamma_{i j_{k}^{i}}^{\\prime\\prime}-\\frac{1}{M N}|}\\end{array}$ hiigh |\u03b3i\u2032\u2032jik \u2212M1N |, and therefore T5+T6 \u2265 0. Since we also have $T_{4}\\geq0$ , it follows that $\\mathcal{L}(\\gamma^{\\prime\\prime})\\geq\\mathcal{L}(\\gamma^{\\prime\\prime\\prime})$ . ", "page_idx": 15}, {"type": "text", "text": "Finally, we show that $\\mathcal{L}(\\gamma^{\\prime\\prime\\prime})\\geq\\mathcal{L}(\\gamma^{*})$ . Since $\\begin{array}{r}{\\gamma_{i j_{1}^{i}}^{*}=\\gamma_{i j_{1}^{i}}^{\\prime\\prime\\prime}+\\sum_{k\\in\\mathcal{K}_{\\mathrm{low}}^{i}}(\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}-\\frac{1}{M N})}\\end{array}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}(\\gamma^{\\prime\\prime\\prime})-\\mathcal{L}(\\gamma^{*})=\\displaystyle\\sum_{i=1}^{M}[\\sum_{k\\in\\mathcal{K}_{\\mathrm{iow}}^{i}}\\frac{\\alpha}{C}(d_{i j_{k}^{i}}-d_{i j_{1}^{i}})(\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}-\\frac{1}{M N})+\\underbrace{\\frac{1-\\alpha}{2}\\sum_{k\\in\\mathcal{K}_{\\mathrm{iow}}^{i}}|\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}-\\frac{1}{M N}|}_{T_{\\mathrm{s}}}+}\\\\ &{\\qquad\\qquad\\underbrace{\\frac{1-\\alpha}{2}(|\\gamma_{i j_{1}^{i}}^{\\prime\\prime\\prime}-\\frac{1}{M N}|-|\\gamma_{i j_{1}^{\\prime}}^{\\prime\\prime\\prime}+\\sum_{k\\in\\mathcal{K}_{\\mathrm{iow}}^{i}}(\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}-\\frac{1}{M N})-\\frac{1}{M N}|)|}_{K\\in\\mathcal{K}_{\\mathrm{iow}}^{i}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $\\begin{array}{r}{d_{i j_{k}^{i}}-d_{i j_{1}^{i}}<\\frac{(1-\\alpha)C}{\\alpha}}\\end{array}$ for any $k\\in\\mathcal{K}_{\\mathrm{low}}^{i}$ , we have $\\begin{array}{r}{T_{7}\\geq(1-\\alpha)\\sum_{k\\in\\mathcal{K}_{\\mathrm{low}}^{i}}(\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}-\\frac{1}{M N})}\\end{array}$ . Notice that \u03b3i\u2032\u2032j\u2032i $\\gamma_{i j_{1}^{\\acute{\\iota}}}^{\\prime\\prime\\prime}\\;\\geq\\;\\frac{1}{M N}$ M1N since \u03b3 $\\begin{array}{r}{\\gamma_{i j_{1}^{i}}^{\\prime\\prime\\prime}\\,=\\,\\frac{1}{M}\\,-\\,\\sum_{k=2}^{N}\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}}\\end{array}$ and for $k\\,\\in\\,\\{2,\\ldots,N\\}$ , $\\gamma_{i j_{k}^{\\,i}}^{\\prime\\prime\\prime}\\;\\leq\\;\\frac{1}{M N}$ . We also have \u03b3i\u2032\u2032j\u2032i $\\begin{array}{r}{\\gamma_{i j_{1}^{i}}^{\\prime\\prime\\prime}+\\sum_{k\\in{\\cal K}_{\\mathrm{low}}^{i}}(\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}\\;-\\;\\frac{1}{M N})\\;\\geq\\;\\frac{1}{M N}}\\end{array}$ since $\\begin{array}{r}{\\gamma_{i j_{1}^{i}}^{*}\\geq\\ \\frac{1}{M N}}\\end{array}$ \u2265 M1N . Therefore, we have T8 + T9 = $\\begin{array}{r}{\\left(1-\\alpha\\right)\\sum_{k\\in{\\cal K}_{\\mathrm{low}}^{i}}\\left(\\frac{1}{M N}-\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}\\right)}\\end{array}$ and $T_{7}+T_{8}+T_{9}\\geq0$ . The it follows that $\\mathcal{L}(\\gamma^{\\prime\\prime\\prime})\\geq\\mathcal{L}(\\gamma^{*})$ . ", "page_idx": 16}, {"type": "text", "text": "Thus, we have $\\mathcal{L}(\\gamma^{\\prime})\\geq\\mathcal{L}(\\gamma^{\\prime\\prime})\\geq\\mathcal{L}(\\gamma^{\\prime\\prime\\prime})\\geq\\mathcal{L}(\\gamma^{*}).$ ", "page_idx": 16}, {"type": "text", "text": "uNneixqtu ew es oslhutoiwon t.h atW ief $\\forall i\\ \\in\\ [M]\\forall k\\ \\in\\ [N],\\ d_{i j_{k}^{i}}\\,-\\,d_{i j_{1}^{i}}\\,\\neq\\,\\frac{(1\\!-\\!\\alpha)C}{\\alpha}$ $d_{i j_{1}^{i}}\\,\\ne\\,d_{i j_{2}^{i}},\\,\\gamma^{*}$ $\\forall i\\;\\in\\;[M]\\forall k\\;\\in\\;[N]$ $d_{i j_{k}^{i}}\\,-$ $\\begin{array}{r}{d_{i j_{1}^{i}}\\ <\\ \\frac{(1-\\alpha)C}{\\alpha}}\\end{array}$ , we have $\\forall i\\;\\in\\;[M]\\forall j\\;\\in\\;[N],\\gamma_{i j}^{*}\\;=\\;\\frac{1}{M N}$ . For any $\\gamma^{\\prime}\\neq\\gamma^{\\ast}$ , there must exist $i\\,\\in\\,[M],k\\,\\in\\,\\{2,\\dots,N\\}$ such that $\\gamma_{i j_{k}^{\\it i}}^{\\prime}\\ >\\ \\frac{1}{M N}$ in which case $T_{4}\\,>\\,0$ or $\\gamma_{i j_{k}^{\\,i}}^{\\prime}\\,<\\,{\\frac{1}{M N}}$ in which case $\\begin{array}{r}{T_{7}>(1-\\alpha)\\sum_{k\\in K_{\\mathrm{low}}^{i}}(\\gamma_{i j_{k}^{i}}^{\\prime\\prime\\prime}\\,-\\,\\frac{1}{M N})}\\end{array}$ . In the second case where $\\exists i\\in[M]k\\in[N]$ such that $\\begin{array}{r}{d_{i j_{k}^{i}}-d_{i j_{1}^{i}}>\\frac{(1-\\alpha)C}{\\alpha}}\\end{array}$ , we hloawve $\\begin{array}{r}{T_{1}>(1-\\alpha)\\sum_{k=\\hat{k}_{i}+1}^{N}\\gamma_{i j_{k}^{i}}^{\\prime}}\\end{array}$ for that $i$ . In both cases, $\\mathcal{L}(\\gamma^{\\prime})>\\mathcal{L}(\\gamma^{*})$ and thus $\\gamma^{*}$ is the unique solution. ", "page_idx": 16}, {"type": "text", "text": "B.2 Proof of Theorem 3.1 and Theorem 3.2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We show that Theorem 3.1 states a special case of Theorem 3.2. Then we prove Theorem 3.2 and it follows that Theorem 3.1 holds as well. ", "page_idx": 16}, {"type": "text", "text": "We first show the connection between Theorem 3.1 and Theorem 3.2. In Theorem 3.2, when $\\rho_{j}=1$ for all $j\\in[N]$ , $s_{k}^{i}=k$ and $s^{*}$ is the same as the $K$ in Theorem 3.1. Then the optimal solution in Theorem 3.2 is also the same as the one in Theorem 3.1 if we substitute $s^{*}$ by $K$ and all the $\\rho_{j}$ \u2019s by 1. Let $\\begin{array}{r}{\\mathcal{L}(\\gamma)\\,=\\,\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{j=1}^{N}\\gamma_{i j}d_{i j}+(1-\\alpha)G_{\\mathrm{KDE}}(\\gamma)}\\end{array}$ be the optimization objective. We prove Theorem 3.2 by showing that for any $\\gamma^{\\prime}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ that satisfy the constraint $\\begin{array}{r}{(\\forall i\\in[M]\\sum_{j=1}^{N}\\gamma_{i j}^{\\prime}=}\\end{array}$ ${\\frac{1}{M}},$ ), $\\mathcal{L}(\\gamma^{\\prime})\\geq\\mathcal{L}(\\gamma^{*})$ . ", "page_idx": 16}, {"type": "text", "text": "For conciseness, we let d(i,k) = dijik and \u03b3(i,k) = \u03b3ijik. ", "page_idx": 16}, {"type": "text", "text": "$\\begin{array}{r}{\\sum_{l=1}^{k}\\frac{d_{(i,k+1)}-d_{(i,l)}}{\\rho_{j_{l}^{i}}}-\\sum_{l=1}^{k-1}\\frac{d_{(i,k)}-d_{(i,l)}}{\\rho_{j_{l}^{i}}}\\,=\\,\\sum_{l=1}^{k}\\frac{d_{(i,k+1)}-d_{(i,k)}}{\\rho_{j_{l}^{i}}}\\,\\ge\\,0}\\end{array}$ $c(s)$ lk=1d(i,k+1\u03c1)\u2212d(i,k) \u22650 fo  k \u2208[N \u22121] ci(s) $c_{i}(s)$ r  iasn ya ,n is non-decreasing. Therefore, $\\begin{array}{r}{c_{i}(s)=\\sum_{i=1}^{M}c_{i}(s)}\\end{array}$ is non-decreasing. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "Let $\\begin{array}{r}{r^{\\prime}=\\operatorname*{max}_{i\\in[M]}\\operatorname*{max}_{k\\in[K_{i}]}\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime}}\\end{array}$ . We consider the following two cases. ", "page_idx": 16}, {"type": "text", "text": "In the first case when $r^{\\prime}\\leq\\frac{1}{M s^{*}}$ M1s\u2217, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi(\\gamma^{\\prime})-\\mathcal{L}(\\gamma^{*})=\\displaystyle\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{k=1}^{N}d_{(i,k)}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{*})+(1-\\alpha)(G_{\\mathrm{KDE}}(\\gamma^{\\prime})-G_{\\mathrm{KDE}}(\\gamma^{*}))}\\\\ &{\\qquad\\qquad\\qquad=\\displaystyle\\frac{\\alpha}{C}\\sum_{i=1}^{M}[\\displaystyle\\sum_{k=1}^{K_{i}}d_{(i,k)}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{*})+d_{(i,K_{i}+1)}(\\gamma_{(i,K_{i}+1)}^{\\prime}-\\gamma_{(i,K_{i}+1)}^{*})+\\displaystyle\\sum_{k=K_{i}+2}^{N}d_{(i,k)}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{*})]}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\underbrace{(1-\\alpha)(G_{\\mathrm{KDE}}(\\gamma^{\\prime})-G_{\\mathrm{KDE}}(\\gamma^{*}))}_{T_{2}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since $\\forall k\\geq K_{i}+2,d_{(i,k)}\\geq d_{(i,K_{i}+1)}$ , and $\\begin{array}{r}{\\sum_{k=K_{i}+1}^{N}\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,K_{i}+1)}^{*}=-\\sum_{k=1}^{K_{i}}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{*}),}\\end{array}$ we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{T_{1}\\geq_{\\c C}^{\\alpha}\\displaystyle\\sum_{i=1}^{M}[\\displaystyle\\sum_{k=1}^{K_{i}}d_{(i,k)}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{*})+d_{(i,K_{i}+1)}(\\displaystyle\\sum_{k=K_{i}+1}^{N}\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,K_{i}+1)}^{*})]}}\\\\ {{\\displaystyle~~~=\\cfrac{\\alpha}{C}\\displaystyle\\sum_{i=1}^{M}\\sum_{k=1}^{K_{i}}\\displaystyle\\frac{d_{(i,K_{i}+1)}-d_{(i,k)}}{\\rho_{j_{k}^{i}}}(\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{*}-\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime})}}\\\\ {{\\displaystyle~~~\\geq\\cfrac{\\alpha}{C}\\displaystyle\\sum_{i=1}^{M}\\sum_{k=1}^{K_{i}}\\displaystyle\\frac{d_{(i,K_{i}+1)}-d_{(i,k)}}{\\rho_{j_{k}^{i}}}(\\frac{1}{M s^{*}}-r^{\\prime})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $\\begin{array}{r}{\\hat{s}=\\operatorname*{min}_{i\\in[M]}s_{K_{i}+1}^{i}}\\end{array}$ . Then we have $\\hat{s}>s^{*}$ and $\\begin{array}{r}{\\sum_{i=1}^{M}\\sum_{k=1}^{K_{i}}\\frac{d_{(i,K_{i}+1)}-d_{(i,k)}}{\\rho_{j_{k}^{i}}}=c(\\hat{s})}\\end{array}$ $c(s)$ is non-decreasing, we have $\\begin{array}{r}{\\frac{\\alpha}{C}c(\\hat{s})\\geq(1-\\alpha)M}\\end{array}$ . Then it follows that $\\begin{array}{r}{T_{1}\\overset{\\cdot\\cdot}{\\geq}(1-\\alpha)M(\\frac{1}{M s^{*}}-r^{\\prime})}\\end{array}$ . ", "page_idx": 17}, {"type": "text", "text": "Let $\\bar{s}=\\sum_{j=1}^{N}1/\\rho_{j}$ . Given the assumption that $\\begin{array}{r}{s^{\\ast}\\leq\\frac{1}{2}\\bar{s}}\\end{array}$ , we have $\\begin{array}{r}{\\frac{1}{M s^{*}}\\geq2\\frac{1}{M\\bar{s}}}\\end{array}$ . For any $i\\in[M]$ , for any k \u2264Ki we have \u03c1ji\u03b3(\u2217i,k) $\\begin{array}{r}{\\rho_{j_{k}^{i}}\\gamma_{\\left(i,k\\right)}^{*}=\\frac{1}{M s^{*}}}\\end{array}$ , and for $k=K_{i}+1$ we have $\\begin{array}{r}{\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{*}=\\frac{1}{M s^{*}}(s^{*}-s_{K_{i}}^{i})\\rho_{j_{k}^{i}}\\le}\\end{array}$ $\\begin{array}{r}{\\frac{1}{M s^{*}}(s_{K_{i}+1}^{i}-s_{K_{i}}^{i})\\rho_{j_{k}^{i}}=\\frac{1}{M s^{*}}}\\end{array}$ . Therefore, $\\begin{array}{r}{\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{*}-\\frac{1}{M\\bar{s}}|=\\frac{1}{M s^{*}}-\\frac{1}{M\\bar{s}}}\\end{array}$ M1 s\u00af. Then we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{T_{2}=(1-\\alpha)M\\big(\\displaystyle\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime}-\\frac{1}{M\\bar{s}}|-\\displaystyle\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{*}-\\frac{1}{M\\bar{s}}|\\big)}\\\\ &{\\quad\\ge(1-\\alpha)M\\big(\\displaystyle\\operatorname*{max}_{i\\in[M]}\\,\\operatorname*{max}_{k\\in[K_{i}]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime}-\\frac{1}{M\\bar{s}}|-(\\displaystyle\\frac{1}{M s^{*}}-\\frac{1}{M\\bar{s}}))}\\\\ &{\\quad\\ge(1-\\alpha)M\\big(|r^{\\prime}-\\frac{1}{M\\bar{s}}|-(\\displaystyle\\frac{1}{M s^{*}}-\\frac{1}{M\\bar{s}})\\big)}\\\\ &{\\quad\\ge(1-\\alpha)M\\big(r^{\\prime}-\\displaystyle\\frac{1}{M s^{*}}\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The last inequality follows the triangle inequality. Then it follows that $T_{1}+T_{2}\\geq0$ and $\\mathcal{L}(\\gamma^{\\prime})-$ $\\mathcal{L}(\\gamma^{\\ast})\\geq0$ . ", "page_idx": 17}, {"type": "text", "text": "In the second case when $r^{\\prime}>\\,\\frac{1}{M s^{*}}$ , let $\\begin{array}{r}{\\hat{K}_{i}=\\operatorname*{max}\\{K\\in[N]\\cup\\{0\\}|\\sum_{k=1}^{K}r^{\\prime}/\\rho_{j_{k}^{i}}\\le\\frac{1}{M}\\}.}\\end{array}$ . When $K>K_{i}$ , $\\begin{array}{r}{,\\sum_{k=1}^{K}r^{\\prime}/\\rho_{j_{k}^{i}}>s^{*}r^{\\prime}>\\frac{1}{M}}\\end{array}$ . Therefore, $\\hat{K}_{i}\\le K_{i}$ . Consider another probability transport \u03b3\u2032\u2032 \u2208R\u2265M\u00d7N where ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma_{(i,k)}^{\\prime\\prime}=\\left\\{\\!\\!\\begin{array}{l l}{r^{\\prime}/\\rho_{j_{k}^{i}},}&{\\mathrm{if}\\;k\\le\\hat{K}_{i}}\\\\ {\\frac{1}{M}-\\sum_{k=1}^{\\hat{K}_{i}}r^{\\prime}/\\rho_{j_{k}^{i}},}&{\\mathrm{if}\\;k=\\hat{K}_{i}+1}\\\\ {0,}&{\\mathrm{otherwise}}\\end{array}\\!\\!\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that by the definition of $\\hat{K}_{i}$ we have $\\gamma_{(i,k)}^{\\prime\\prime}\\rho_{j_{k}^{i}}<r^{\\prime}$ for $k=\\hat{K}_{i}+1$ . ", "page_idx": 17}, {"type": "text", "text": "Then we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi(\\gamma^{\\prime})-\\mathcal{L}(\\gamma^{\\prime\\prime})=\\displaystyle\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{k=1}^{N}d_{(i,k)}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{\\prime\\prime})+(1-\\alpha)(G_{\\mathrm{KDE}}(\\gamma^{\\prime})-G_{\\mathrm{KDE}}(\\gamma^{\\prime\\prime}))}\\\\ &{\\qquad\\qquad=\\displaystyle\\frac{\\alpha}{C}\\sum_{i=1}^{M}[\\displaystyle\\sum_{k=1}^{\\hat{K}_{i}}d_{(i,k)}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{\\prime\\prime})+d_{(i,\\hat{K}_{i}+1)}(\\gamma_{(i,\\hat{K}_{i}+1)}^{\\prime}-\\gamma_{(i,\\hat{K}_{i}+1)}^{\\prime\\prime})+\\displaystyle\\sum_{k=\\hat{K}_{i}+2}^{N}d_{(i,\\hat{K}_{i}+1)}(\\gamma_{(i,\\hat{K}_{i}+1)}^{\\prime}-\\gamma_{(i,\\hat{K}_{i}+1)}^{\\prime\\prime})]}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\underbrace{(1-\\alpha)(G_{\\mathrm{KDE}}(\\gamma^{\\prime})-G_{\\mathrm{KDE}}(\\gamma^{\\prime\\prime}))}_{T_{4}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since $\\forall k\\geq\\hat{K}_{i}+2,d_{(i,k)}\\geq d_{(i,\\hat{K}_{i}+1)}$ , and $\\begin{array}{r}{\\sum_{k=\\hat{K}_{i}+1}^{N}\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,\\hat{K}_{i}+1)}^{\\prime\\prime}=-\\sum_{k=1}^{\\hat{K}_{i}}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{\\prime\\prime}),}\\end{array}$ we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{T_{3}\\geq\\displaystyle\\frac{\\alpha}{C}\\sum_{i=1}^{M}[\\displaystyle\\sum_{k=1}^{\\hat{K}_{i}}d_{(i,k)}(\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,k)}^{\\prime\\prime})+d_{(i,\\hat{K}_{i}+1)}(\\displaystyle\\sum_{k=\\hat{K}_{i}+1}^{N}\\gamma_{(i,k)}^{\\prime}-\\gamma_{(i,\\hat{K}_{i}+1)}^{\\prime\\prime})]}}\\\\ {{\\displaystyle\\;\\;\\;=\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{k=1}^{\\hat{K}_{i}}\\frac{d_{(i,\\hat{K}_{i}+1)}-d_{(i,k)}}{\\rho_{j_{k}^{i}}}(\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime\\prime}-\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In addition, since $\\begin{array}{r}{r^{\\prime}\\ >\\ \\frac{1}{M s^{*}}\\ \\geq\\ \\frac{2}{M\\bar{s}}}\\end{array}$ and $\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime\\prime}\\;\\leq\\;r^{\\prime}$ for any $i~\\in~[M]$ and $\\textit{k}\\in\\ [N]$ , we have $\\begin{array}{r}{\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime}-\\frac{1}{M^{\\tilde{s}}}|\\ge\\operatorname*{max}_{i\\in[M]}\\operatorname*{max}_{k\\in[K_{i}]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime}-\\frac{1}{M^{\\tilde{s}}}|=r^{\\prime}-\\frac{1}{M^{\\tilde{s}}}|=\\frac{r^{\\prime}}{M^{\\tilde{s}}},}\\end{array}$ and $\\begin{array}{r}{\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime\\prime}-\\frac{1}{M\\bar{s}}|\\leq r^{\\prime}-\\frac{1}{M\\bar{s}}}\\end{array}$ . Therefore, ", "page_idx": 18}, {"type": "equation", "text": "$$\nT_{4}=(1-\\alpha)M\\big(\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime}-\\frac{1}{M\\bar{s}}|-\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{\\prime\\prime}-\\frac{1}{M\\bar{s}}|\\big)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then it follows that $\\mathcal{L}(\\gamma^{\\prime})-\\mathcal{L}(\\gamma^{\\prime\\prime})\\geq0$ ", "page_idx": 18}, {"type": "text", "text": "Let $\\begin{array}{r}{S^{\\prime}=\\{s\\in S|\\frac{1}{M r^{\\prime}}<s\\leq s^{*}\\}}\\end{array}$ and $s^{(1)},\\ldots,s^{(|S^{\\prime}|)}$ be the elements in $S^{\\prime}$ in the ascending order. Let $\\gamma^{(0)}=\\gamma^{\\prime\\prime}$ , $\\begin{array}{r}{s^{(0)}=\\frac{1}{M r^{\\prime}}}\\end{array}$ and $K_{i}^{(0)}=\\hat{K}_{i}$ . For $t\\in[|S^{\\prime}|]$ , let $K_{i}^{(t)}=\\operatorname*{max}\\{k\\in[N]|s_{k}^{i}\\le s^{(t)}\\}$ . we consider the probability transport $\\gamma^{(t)}\\in\\mathbb{R}_{\\ge0}^{M\\times N}$ where ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\gamma_{(i,k)}^{(t)}=\\left\\{\\begin{array}{l l}{1/\\rho_{j_{k}^{i}}\\cdot\\frac{1}{M s^{(t)}},}&{\\mathrm{if~}k\\leq K_{i}^{(t)}}\\\\ {\\frac{1}{M}-\\sum_{k=1}^{K_{i}^{(t)}}1/\\rho_{j_{k}^{i}}\\cdot\\frac{1}{M s^{(t)}},}&{\\mathrm{if~}k=K_{i}^{(t)}+1}\\\\ {0,}&{\\mathrm{otherwise}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n:(\\gamma^{(t-1)})-\\mathcal{L}(\\gamma^{(t)})=\\underbrace{\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{k=1}^{N}d_{(i,k)}(\\gamma_{(i,k)}^{(t-1)}-\\gamma_{(i,k)}^{(t)})}_{T_{5}}+\\underbrace{(1-\\alpha)(G_{\\mathrm{KDE}}(\\gamma^{(t-1)})-G_{\\mathrm{KDE}}(\\gamma^{(t)}))}_{T_{6}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "By the definition of Ki(t) and $s^{(t)}$ , either $K_{i}^{(t)}=K_{i}^{(t-1)}$ or $K_{i}^{(t)}=K_{i}^{(t-1)}+1$ . For any $i\\in[M]$ such that Ki( t) = Ki(t\u22121) , we have $\\gamma_{(i,k)}^{(t)}\\,=\\,0$ for $k\\,>\\,K_{i}^{(t-1)}+1$ . For any $i\\,\\in\\,[M]$ such that $K_{i}^{(t)}=K_{i}^{(t-1)}+1$ , we have $s_{K_{i}^{(t)}}^{i}=s^{(t)}$ , in which case we also have $\\gamma_{(i,k)}^{(t)}=0$ for $k>K_{i}^{(t-1)}+1$ . Therefore, we have $\\begin{array}{r}{\\gamma_{(i,K_{i}^{(t-1)}+1)}^{(t-1)}-\\gamma_{(i,K_{i}^{(t-1)}+1)}^{(t)}=-\\sum_{k=1}^{K_{i}^{(t-1)}}(\\gamma_{(i,k)}^{(t-1)}-\\gamma_{(i,k)}^{(t)})}\\end{array}$ ) \u2212\u03b3((it,)k)). Then it follows that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{T_{5}=\\displaystyle\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{k=1}^{K_{i}^{(\\tau-1)}}(d_{(i,k)}-d_{(i,K_{i}^{(t-1)}+1)})(\\gamma_{(i,k)}^{(t-1)}-\\gamma_{(i,k)}^{(t)})}}\\\\ {{\\displaystyle~~=\\frac{\\alpha}{C}\\sum_{i=1}^{M}\\sum_{k=1}^{K_{i}^{(t-1)}}(d_{(i,K_{i}^{(t-1)}+1)}-d_{(i,k)})/\\rho_{j_{k}^{i}}\\cdot\\frac{1}{M}\\cdot(\\frac{1}{s^{(t)}}-\\frac{1}{s^{(t-1)}})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "$\\hat{s}^{(t)}\\;=\\;\\mathrm{min}_{i\\in[M]}\\:s_{K_{i}^{(t-1)}+1}^{i}$ M] siK(t\u22121)+1, and then we have T5 = C\u03b1 \u00b7 M1 \u00b7 ( s(1t) \u2212 s(t1\u22121) )c(s\u02c6(t)). Since $\\hat{\\boldsymbol{s}}^{(t)}\\le\\boldsymbol{s}^{*}$ and $c(s)$ is non-decreasing, we have $\\begin{array}{r}{\\frac{\\alpha}{C}c(\\hat{s}^{(t)})\\leq\\frac{\\alpha}{C}c(s^{*})<(1-\\alpha)M}\\end{array}$ and then it follows that $\\begin{array}{r}{T_{5}\\geq(1-\\alpha)\\big(\\frac{1}{s^{(t)}}-\\frac{1}{s^{(t-1)}}\\big)}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "In addition, since $s^{(t-1)}<s^{(t)}\\leq s^{*}$ , we have $\\begin{array}{r}{\\rho_{j_{k}^{i}}\\gamma^{(t-1)}>\\rho_{j_{k}^{i}}\\gamma^{(t)}\\geq\\frac{1}{M s^{*}}\\geq\\frac{2}{M\\bar{s}}}\\end{array}$ , and further ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{T_{6}=\\!(1-\\alpha)M(\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{(t-1)}-\\frac{1}{M\\bar{s}}|-\\operatorname*{max}_{i\\in[M],k\\in[N]}|\\rho_{j_{k}^{i}}\\gamma_{(i,k)}^{(t)}-\\frac{1}{M\\bar{s}}|)}\\\\ {=\\!(1-\\alpha)(\\frac{1}{s^{(t-1)}}-\\frac{1}{s^{(t)}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, we have $\\mathcal{L}(\\gamma^{(t-1)})\\,-\\,\\mathcal{L}(\\gamma^{(t)})\\,=\\,T_{5}+T_{6}\\,\\geq\\,0$ . Since $\\gamma^{\\prime}\\,\\geq\\,\\gamma^{\\prime\\prime}\\,=\\,\\gamma^{(1)}\\,\\geq\\,\\cdots\\,\\geq$ $\\gamma^{(|\\pmb{\\mathscr{S}}^{\\prime}|)}=\\gamma^{*}$ , we have $\\gamma^{\\prime}\\geq\\gamma^{*}$ . ", "page_idx": 19}, {"type": "text", "text": "If $\\nexists s\\in S$ such that $\\textstyle{\\frac{\\alpha}{C}}c(s)=(1-\\alpha)M$ and $\\nexists i\\in[M]$ such that $d_{(i,K_{i})}=d_{(i,K_{i}+1)}$ or $d_{(i,K_{i}+1)}=$ $d_{(i,K_{i}+2)}$ , we have $\\begin{array}{r}{\\bar{T}_{1}>(1-\\alpha)M(\\frac{1}{M s^{*}}-r^{\\prime})}\\end{array}$ and $T_{3}>0$ , and therefore $\\gamma^{\\prime}>\\gamma^{*}$ , i.e., $\\gamma^{*}$ is the unique solution. ", "page_idx": 19}, {"type": "text", "text": "C Implementation Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section, we provide details of the implementations. ", "page_idx": 19}, {"type": "text", "text": "Implementation of Our Method For experiments in Section 5.2, GETKNN is implemented as two-stage retrieval. We first build a coarse Faiss [23] index for the data repository $D$ and use it to retrieve the 2000 nearest neighbors of each query example. The retrieved examples form a new set $D^{\\prime}$ . Then we build a fine-grained index for $D^{\\prime}$ and use it to retrieve and return the 2000 nearest neighbors of each query example. COMPUTEKDE in KNN-KDE computes the kernel density of each example in $D^{\\prime}$ by retrieving its 1000 nearest neighbors using the fine-grained index. The coarse index is OPQ56_112,IVF65536_HNSW32, $\\mathsf{P07+56}$ , and the fine-grained index is IndexIVFFlat. We refer the readers to the Faiss documentation3 for the details of those indexes. ", "page_idx": 19}, {"type": "text", "text": "For experiments in Section 5.1, we use exact search for GETKNN to retrieve 5000 nearest neighbors of each query example and IndexIVFFlat for COMPUTEKDE. ", "page_idx": 19}, {"type": "text", "text": "Encoding Process for Instruction Selection We encode the examples following [47] using rescaled and randomly projected gradients from a LLAMA-2-7B model finetuned on a random $5\\%$ of the data repository. Specifically, we finetune the base model on the randomly selected dataset for 4 epochs and use the gradients from the checkpoint at the end of each epoch as the example encoding. The dimension of the projected gradient from each epoch is 8,192. We refer the readers to [47] for more details. Then for each example, we multiply the gradients from the 4 checkpoints by the corresponding learning rate and concatenate them to get the final encoding, which is a 32,768-dimensional vector. ", "page_idx": 19}, {"type": "text", "text": "Parameter Selection Note that our framework only has two effective parameters $C$ is a constant to make sure that the transport cost and $G(\\gamma)$ are on the same scale). The way we set the hyperparameters is as follows: ", "page_idx": 19}, {"type": "text", "text": "\u2022 We set $C$ to 5 when the embeddings are normalized.   \n\u2022 We set $h$ to the maximum distance between 10 hand-crafted near-duplicates. The intuition is that the points within the distance of $h$ will be considered as near-duplicates and the probability assigned to them will be reduced.   \n\u2022 $\\alpha$ can be any value between 0.05 and 0.95, and the performance is not sensitive to it as long as it is not too small or too large (see Appendix E). ", "page_idx": 19}, {"type": "text", "text": "In practice, we can use a validation set and a small surrogate model to guide the parameter selection. ", "page_idx": 19}, {"type": "text", "text": "D Hyperparameters of Finetuning ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We apply LoRA [20] for parameter-efficient instruction tuning for the experiments in Section 5.1. The hyperparameters are shown in Table 5. We use an NVIDIA A100 Tensor Core GPU with 40G memory for instruction tuning. ", "page_idx": 19}, {"type": "text", "text": "For the experiments in Section 5.2, the hyperparameters for continued pretraining are provided in Table 6 and those for supervised finetuning are in Table 7. The hardware for continued pretraining and supervised finetuning is an NVIDIA Tesla V100 GPU with 32GB memory. ", "page_idx": 19}, {"type": "text", "text": "E Additional Experimental Results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Table 5: Hyperparameters for instruction tuning. ", "page_idx": 20}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/a13660ca2bd69a49891878613d1e00ae388b8dbd04ff9b98e704c930449808fe.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Table 6: Hyperparameters for continued pretraining. ", "page_idx": 20}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/87a627408254a48c1d69040775e506032055e5ca11b1145485293e09558ff4fd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "wjbTHLUSzU/tmp/c94d445cc006c780c1ea47a6e6686e11ff71ead4bfd23582951100d62f47cdd1.jpg", "img_caption": ["Figure 2: F1 scores of the downstream tasks under different duplication settings. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "E.1 Robustness to Near-Duplicates ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We evaluate the robustness of the selection methods against near-duplicates in the candidate examples. We follow the same evaluation protocol described in Section 5.2 while injecting duplicates to the candidate examples. We set different levels of duplication by varying the fraction of examples chosen for duplication and the duplication factor (number of duplicates per example). The fraction for duplication is set to $0.1\\%\\,/\\,1\\%$ , and the duplication factor is set to $10\\,/\\,100\\,/\\,1000$ . For example, if the fraction for duplication is $0.1\\%$ and the duplication factor is 10, we randomly choose $0.1\\%$ of the examples from the data repository and duplicate each 10 times. We use ChemProt (1K), AGNews (3K), and IMDB (10K) to perform the analysis, where the numbers in the parentheses represent the sizes of the annotated data. We include KNN-Uniform with the same parameters as KNN-KDE to show the effectiveness of the KDE-based regularization. ", "page_idx": 21}, {"type": "text", "text": "The results show that KNN-KDE is the only method that is robust to all the duplication settings. We observe that under low duplication levels, specifically when (fraction for duplication, duplication factor) is $(0.1\\%$ , 10), $(0.1\\%$ , 100), or $(1\\%,10)$ , all the methods perform similarly to the case without duplication. Given that the injected duplicates constitute less than $10\\%$ of the data repository in those settings, it is not surprising that they do not have much effect on the downstream performance. However, when the duplication factor is increased to 1000 with the fraction for duplication set to $0.1\\%$ , the performance of DSIR drops by 0.7 points on average, whereas KNN-KDE and KNN-Uniform retain their performance. Moreover, when the duplication factor is increased to 1000 with the fraction set to $1\\%$ , all the methods except KNN-KDE show a notable decline (more than 2 points on average) in their performance. ", "page_idx": 21}, {"type": "text", "text": "E.2 Runtime and Scalability ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We report the runtime of our method that can be split into a pre-processing stage and a selection stage. We use a machine with an Intel(R) Xeon(R) Gold 5115 CPU $\\textcircled{a}~2.40\\mathrm{GHz}$ (40 cores) and 250GB RAM. The example embedding is computed using an NVIDIA Tesla V100 GPU with 32GB memory, while the other computations are on the CPU. In the pre-processing stage, our method embeds the candidate examples in the data repository and further builds indexes for the embeddings. This stage takes 28.38 hours for the data repository in Section 5.2 that contains 150M examples. In the selection stage, our method embeds the query examples, computes the probability assignment, and takes random samples according to the probability. This stage takes 0.7 hours for 10K query examples. The runtime of the selection stage scales linearly with the number of query examples and remains unaffected by the number of examples to be sampled except for the I/O cost. Note that while our method takes a substantial amount of time in the pre-processing stage, the cost is one-time and the index can be reused for a variety of tasks that require similarity search. In general, our methods are practical in terms of runtime. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "E.3 Task-Specific Instruction Tuning for One epoch ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In Section 5.1, we perform instruction tuning for 4 epochs, and our method takes a random sample in each epoch instead of using a fixed set. Therefore, the total number of unique examples can be up to $4\\mathbf{x}$ the number of examples used per epoch, though the actual number of unique examples is much lower since examples with high probability mass tend to be repeatedly sampled. To demonstrate that the number of unique examples during training is not the primary factor behind our performance gain, we provide additional results that compare our method with LESS when the number of epochs is set to 1. Specifically, each method selects a set whose size is $4\\%$ of the candidates. Then we train the model on the selected set for 1 epoch (the amount of computation is the same as using $1\\%$ for 4 epochs). The results are shown in Table 8. From the results, we can see that our method still outperforms LESS in 5 out of the 6 settings when LESS has access to more unique examples. ", "page_idx": 22}, {"type": "text", "text": "Table 8: Performance of instruction tuning with dataset selected by our method compared with the LESS. The dataset size is $4\\%$ of the candidate data repository and we train each model for one epoch on the selected set. The subscripts represent the standard deviations. ", "page_idx": 22}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/ae1f7e2c1526bb3774753b77dd0cdbed9dae5e95dc1da9b1f1d75274c2dfaeae.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "E.4 Domain-Specific Continued Pretraining with Different Selection Sizes ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We compare with the baselines when the size of the selected data is $100\\mathrm{K}$ and 300K for domainspecific continued pretraining while the size of the annotated dataset is fixed to 3K. The other settings are the same as in Section 5.2. The results are in Table 9 which show that our method is either better than or comparable to the baselines. ", "page_idx": 22}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/1ba57ab1fd542686c50d191d58059d5a2042ff944040cd8094a66665a2a2e2b0.jpg", "table_caption": ["Table 9: F1 scores of the downstream tasks when the sample size varies. The size of the annotated data is set to 3K. Standard deviations are shown in the subscripts. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "E.5 Micro-Benchmarks ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we provide micro-benchmarks that study the effects of the hyperparameters in our framework. In addition, we show the performance of KNN-TV, an instantiation of our framework that is not covered in the main experiments. The experiments focus on domain-specific pretraining, following the same settings as in Section 5.2. The datasets and sizes used in the micro-benchmarks are ChemP (1K), AG (3K), and IMDB (10K). ", "page_idx": 22}, {"type": "text", "text": "E.5.1 Tradeoff between Distribution Alignment and Diversity ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We study the effects of $\\alpha$ , the hyperparameter that controls the tradeoff between distribution alignment and diversity in our framework. We vary the value of $\\alpha$ in KNN-Uniform and KNN-KDE and report the F1 scores of the downstream tasks in Figure 3. In all three datasets, we observe a notable drop in F1 scores when $\\alpha=0$ or $\\alpha=1$ , and consistent performance when the value of $\\alpha$ is set to other values. Note that KNN-Uniform or KNN-KDE is equivalent to Uniform when $\\alpha=0$ , and transports all the probability mass of each query example to its 1-nearest-neighbor in the data repository when $\\alpha=1$ . The former does not consider distribution alignment, while the latter results in overfitting to the 1-nearest-neighbors. For the other values of $\\alpha$ , we report the corresponding neighborhood size (the final $K$ in KNN-Uniform and the average of the final $K_{i}$ in KNN-KDE) in Table 12. The consistent performance with $\\alpha\\in\\{0.2,0.4,0.6,0.\\bar{8}\\}$ shows that our framework is not sensitive to the choice of $\\alpha$ . ", "page_idx": 22}, {"type": "image", "img_path": "wjbTHLUSzU/tmp/b5cdfc6cb6741f6cb4b62ded53bb3bd5b9dbfc0fafe883e9cbdc9559a2a10d11.jpg", "img_caption": ["Figure 3: Performance of KNN-KDE when $\\alpha$ varies. The error bar shows the standard deviation. "], "img_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/ab7ebfbb43c4d3533830a00d834185ffba9a2d6d11479c9b111e79e4032f6c04.jpg", "table_caption": ["Table 10: Performance of KNN-KDE when the kernel size varies. F1 scores of the downstream tasks are reported with standard deviations shown in the subscripts. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "E.5.2 Effects of Kernel Size in KNN-KDE ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We vary the kernel size for the kernel density estimation in KNN-KDE. The performance is shown in Table 10. The F1 scores of all three downstream tasks are consistent across different choices of kernel size. The results show that the performance of KNN-KDE is not sensitive to the choice of kernel size. ", "page_idx": 23}, {"type": "text", "text": "E.5.3 Performance of KNN-TV ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We evaluate KNN-TV $C=0.25,\\alpha=0.6)$ and show the results in Table 11. KNN-TV performs similarly to KNN-KDE $\\stackrel{.}{\\alpha}=1$ ), and significantly worse than KNN-KDE ( $(\\alpha=0.6)$ ). The reason is that KNN-TV assigns almost all the probability mass (more than $99.99\\%$ ) to the 1-nearest neighbor of each query example and causes overfitting to them, a behavior similar to KNN-KDE $\\left[\\alpha=1\\right.$ ). ", "page_idx": 23}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/9c07cf0ecbfa3b313f2cd96c3ef19d4496519f4cd09106ca99bf29615c034ee0.jpg", "table_caption": ["Table 11: The performance of KNN-TV compared with KNN-KDE $\\left(\\alpha\\right.\\mathrm{~=~}1\\mathrm{~}$ ) and KNN-KDE $(\\alpha=0.6)$ ). F1 scores of the downstream tasks are reported with standard deviations shown in the subscripts. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 12: The neighborhood size of KNN-Uniform / KNN-KDE for different values of $\\alpha$ . The numbers before the slashes are for KNN-Uniform and those after are for KNN-KDE. ", "page_idx": 24}, {"type": "table", "img_path": "wjbTHLUSzU/tmp/f00a8a4ba8c3a81cc2e1ca3efdad0f09122531ad515699f7113fb0f92d0fa63e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We clearly state our contributions and scope in the abstract and introduction. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: We discuss the limitations in the conclusion. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. ", "page_idx": 24}, {"type": "text", "text": "\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Each theorem comes with a clear statement of the assumptions and proofs are provided in the appendix. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: The details and hyperparameters of the experiments are provided in the appendix. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: All the data used are open-sourced. We have included the code in the Supplementary material. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The training and test details are in the appendix. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Error bars are reported for every experimental result. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The hardware we use is reported in the appendix Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: Yes ", "page_idx": 27}, {"type": "text", "text": "Justification: We have reviewed the NeurIPS Code of Ethics and confirm that our research conforms it. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: We have such discussion in the introduction and the conclusion. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: This paper does not introduce new models or datasets. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: We use open-source models and data, which have been properly cited. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: The code is well documented. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: We do not have such experiments. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: We do not have this type of studies. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]