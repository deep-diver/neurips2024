[{"figure_path": "SjQ1iIqpfU/figures/figures_2_1.jpg", "caption": "Figure 1: Diagram of the inner problem (Client-Selection) represented through a contour of (f1+f2). The blue arrows \u2192 are gradients computed at middle point (x1 + x2) to determine connectivity. The red arrows \u2192 represent gradients computed at local models to update model weights.", "description": "This figure illustrates the inner problem of the bilevel optimization framework for collaborative learning. It shows a contour plot representing the sum of loss functions (f1 + f2) for two clients. The blue arrows indicate the gradients computed at the average model weight ((x1+x2)/2), which helps to determine the collaboration between the clients. Meanwhile, the red arrows represent gradients computed at the individual local models (x1, x2), which are used to update the model weights. Three scenarios (points A, B, and C) are shown to demonstrate how the algorithm decides on collaboration based on gradient alignment.", "section": "2 Problem formulation"}, {"figure_path": "SjQ1iIqpfU/figures/figures_6_1.jpg", "caption": "Figure 2: (2a) Average accuracy in cross-silo experiments with varying factors, including the fraction of the dataset available to clients, the number of clusters, and the number of clients per cluster. (2b) Average accuracy of personalized models for cross-silo federated learning with 8 clients. The \"Oracle\" denotes applying FedAvg to the clients with the same label permutation.", "description": "This figure shows the results of cross-silo experiments.  (2a) demonstrates how the average accuracy changes based on the fraction of the dataset, number of clusters, and number of clients per cluster. (2b) compares the accuracy of personalized models trained using COBO against other collaborative learning baselines (FedAvg, Finetuned FedAvg, Ditto, FC, IFCA, Local, Oracle) over multiple iterations. The Oracle result represents the ideal performance achievable by applying FedAvg separately to each cluster.", "section": "4.1 Cross-silo federated learning experiment with 8 clients"}, {"figure_path": "SjQ1iIqpfU/figures/figures_7_1.jpg", "caption": "Figure 3: Collaboration matrices learned by Federated Clustering (FC), IFCA, and COBO at different stages of training for cross-silo experiment with 8 clients. The diagonals are masked out. The oracle matrix is a block diagonal matrix with blocks of size 2. The collaboration matrix of COBO already starts to look similar to oracle matrix within as low as 300 iterations (0.75% of the total iterations), and converges to it within 5000 iterations (12.5% of the total iterations). On the other hand, IFCA yields a fully-connected matrix while FC occasionally diverges from the achieved cluster structures (e.g., iterations 300, 5000, and 40000), even at the end of training.", "description": "This figure compares the collaboration matrices learned by three different algorithms (Federated Clustering, IFCA, and COBO) at various stages of training during a cross-silo experiment with 8 clients.  It visualizes how each algorithm determines the relationships between clients for collaboration. The oracle matrix (ideal solution) is a block diagonal matrix, indicating that clients within the same cluster should ideally collaborate more strongly than those in different clusters. COBO quickly converges to a collaboration matrix resembling the oracle, showing its effectiveness in identifying helpful collaborators.  In contrast, IFCA shows full connectivity between all clients, while FC's collaboration matrix is inconsistent and often deviates from the ideal structure, indicating these algorithms have difficulty in accurately identifying clusters for effective collaboration.", "section": "4.1 Cross-silo federated learning experiment with 8 clients"}, {"figure_path": "SjQ1iIqpfU/figures/figures_8_1.jpg", "caption": "Figure 4: Domain weights found by CoBo for Catalan language. There are 4 domains in total: Catalan, Spanish, German, and Dutch. The curves are smoothed by exponential moving average.", "description": "This figure shows the domain weights learned by the CoBo algorithm for the Catalan language during the language modeling experiment.  The x-axis represents the number of iterations, and the y-axis shows the weight assigned to each of the four languages (Catalan, Spanish, German, and Dutch). The lines are smoothed using exponential moving averaging to better visualize trends. The figure illustrates that CoBo dynamically adjusts the collaboration weights between different languages based on their similarity and relevance to the target language (Catalan).  The relatively high weight given to Spanish likely reflects its close linguistic relationship to Catalan. The weights for German and Dutch are lower, indicating less influence during the fine-tuning process.", "section": "4.3 Collaborative fine-tuning on language models"}, {"figure_path": "SjQ1iIqpfU/figures/figures_21_1.jpg", "caption": "Figure 5: Collaboration matrices learned by COBO at different stages of training for cross-device experiment with 80 clients. The diagonals are masked out. The oracle matrix is a block diagonal matrix, consisting of 10 blocks: two blocks of size 10, two blocks of size 9, and so on. The collaboration matrix of COBO already starts to look similar to oracle matrix within as low as 300 iterations. (1.5% of the total iterations)", "description": "This figure shows the collaboration matrices learned by the CoBo algorithm at different stages (300, 5000, 15000, and 20000 iterations) during the cross-device experiment with 80 clients.  The diagonal elements are masked for clarity. The oracle matrix (ideal collaboration structure) has a block diagonal form representing the 10 clusters of varying sizes (two clusters of size 6, two of size 7, and so on). The CoBo matrices progressively converge toward this oracle matrix, demonstrating its ability to effectively learn the optimal collaboration structure even in a large-scale, heterogeneous setting.", "section": "4.2 Cross-device experiment experiment with 80 clients"}, {"figure_path": "SjQ1iIqpfU/figures/figures_22_1.jpg", "caption": "Figure 2: (2a) Average accuracy in cross-silo experiments with varying factors, including the fraction of the dataset available to clients, the number of clusters, and the number of clients per cluster. (2b) Average accuracy of personalized models for cross-silo federated learning with 8 clients. The \"Oracle\" denotes applying FedAvg to the clients with the same label permutation.", "description": "This figure presents results from cross-silo federated learning experiments.  Subfigure (2a) shows how the average accuracy changes based on variations in the dataset fraction per client, the number of clusters, and the number of clients per cluster. Subfigure (2b) compares the accuracy of personalized models achieved by CoBo against other baseline methods, with an 'Oracle' representing the optimal performance achievable by using FedAvg on perfectly separated clusters.", "section": "4.1 Cross-silo federated learning experiment with 8 clients"}]