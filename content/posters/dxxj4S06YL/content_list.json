[{"type": "text", "text": "Fair Secretaries with Unfair Predictions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Eric Balkanski Will Ma Columbia University Columbia University eb3224@columbia.edu wm2428@gsb.columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Andreas Maggiori Columbia University am6292@columbia.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Algorithms with predictions is a recent framework for decision-making under uncertainty that leverages the power of machine-learned predictions without making any assumption about their quality. The goal in this framework is for algorithms to achieve an improved performance when the predictions are accurate while maintaining acceptable guarantees when the predictions are erroneous. A serious concern with algorithms that use predictions is that these predictions can be biased and, as a result, cause the algorithm to make decisions that are deemed unfair. We show that this concern manifests itself in the classical secretary problem in the learning-augmented setting\u2014the state-of-the-art algorithm can have zero probability of accepting the best candidate, which we deem unfair, despite promising to accept a candidate whose expected value is at least $\\operatorname*{max}\\{\\Omega(1),\\bar{1}-\\bar{O}(\\varepsilon)\\}$ times the optimal value, where $\\varepsilon$ is the prediction error. We show how to preserve this promise while also guaranteeing to accept the best candidate with probability $\\Omega(1)$ . Our algorithm and analysis are based on a new \u201cpegging\u201d idea that diverges from existing works and simplifies/unifies some of their results. Finally, we extend to the $k$ -secretary problem and complement our theoretical analysis with experiments. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As machine learning algorithms are increasingly used in socially impactful decision-making applications, the fairness of those algorithms has become a primary concern. Many algorithms deployed in recent years have been shown to be explicitly unfair or reflect bias that is present in training data. Applications where automated decision-making algorithms have been used and fairness is of central importance include loan/credit-risk evaluation [46, 36, 45], hiring [8, 13], recidivism evaluation [47, 1, 19, 11, 14], childhood welfare systems [12], job recommendations [40], and others [30, 28, 31]. A lot of work in recent years has been devoted to formally defining different notions of fairness [43, 34, 24, 21, 15, 38, 37] and designing algorithms that satisfy these different definitions [33, 32, 9, 10, 49]. ", "page_idx": 0}, {"type": "text", "text": "While most fairness work concentrates on classification problems where the instance is known offline, we explore the problem of making fair decisions when the input is revealed in an online manner. Although fairness in online algorithms is an interesting line of research per se, fairness considerations have become increasingly important due to the recent interest in incorporating (possibly biased) machine learning predictions into the design of classical online algorithms. This framework, usually referred to as learning-augmented algorithms or algorithms with predictions, was first formalized in [44]. In contrast to classical online algorithms problems where it is assumed that no information is known about the future, learning-augmented online algorithms are given as input, possibly erroneous, predictions about the future. The main challenge is to simultaneously achieve an improved performance when the predictions are accurate and a robust performance when the predictions are arbitrarily inaccurate. A long list of online problems have been considered in this setting and we point to [41] for an up-to-date list of papers. We enrich this active area of research by investigating how potentially biased predictions affect the fairness of decisions made by learningaugmented algorithms, and ask the following question: ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Can we design fair algorithms that take advantage of unfair predictions? ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this paper, we study this question on a parsimonious formulation of the secretary problem with predictions, motivated by fairness in hiring candidates. ", "page_idx": 1}, {"type": "text", "text": "The problem. In the classical secretary problem, there are $n$ candidates who each have a value and arrive in a random order. Upon arrival of a candidate, the algorithm observes the value of that candidate and must irrevocably decide whether to accept or reject that candidate. It can only accept one candidate and the goal is to maximize the probability of accepting the candidate with maximum value. In the classical formulation, only the ordinal ranks of candidates matter, and the algorithm of Dynkin [22] accepts the best candidate with a constant probability, that equals the best-possible $1/e$ . ", "page_idx": 1}, {"type": "text", "text": "In the learning-augmented formulation of the problem proposed by Fujii and Yoshida [25], the algorithm is initially given a predicted value about each candidate and the authors focus on comparing the expected cardinal value accepted by the algorithm to the maximum cardinal value. The authors derive an algorithm that obtains expected value at least $\\operatorname*{max}\\{\\Omega(1),1-O(\\varepsilon)\\}$ times the maximum value, where $\\varepsilon\\ge0$ is the prediction error. The strength of this guarantee is that it approaches 1 as the prediction error decreases and it is a positive constant even when the error is arbitrarily large. ", "page_idx": 1}, {"type": "text", "text": "However, because the algorithm is now using predictions that could be biased, the best candidate may no longer have any probability of being accepted. We view this as a form of unfairness, and aim to derive algorithms that are fair to the best candidate by guaranteeing them a constant probability of being accepted (we contrast with other notions of fairness in stopping problems in Section 1.1). Of course, a simple way to be fair by this metric is to ignore the predictions altogether and run the classical algorithm of Dynkin. However, this approach would ignore potentially valuable information and lose the improved guarantee of [25] that approaches 1 when the prediction error is low. ", "page_idx": 1}, {"type": "text", "text": "Outline of results. We first formally show that the algorithm of [25] may in fact accept the best candidate with 0 probability. Our main result is then a new algorithm for secretary with predictions that: obtains expected value at least $\\operatorname*{max}\\{\\Omega(1),1-O(\\varepsilon)\\}$ times the maximum value, like [25]; and ensures that, under any predictions, the probability that the best candidate is accepted is at least $1/16$ . This result takes advantage of potentially biased predictions to achieve a guarantee on expected value that approaches 1 when the prediction error is small, while also providing a fairness guarantee for the true best candidate irrespective of the predictions. We note that Antoniadis et al. [3] also derive an algorithm for secretary with predictions, where the prediction is of the maximum value. This algorithm accepts the best candidate with constant probability but it does not provide a guarantee on the expected value accepted that approaches 1 as the prediction error approaches 0. Similarly, Dynkin\u2019s algorithm for the classical secretary problem accepts the best candidate with constant probability but does not make use of predictions at all. Finally, we note that the definitions of the prediction error $\\varepsilon$ differ in [25] and [3]; the former error definition uses the maximum ratio over all candidates between their predicted and true value while the latter uses the maximum absolute difference. Our techniques present an arguably simpler analysis and extend to a general family of prediction error measures that includes both of these error definitions. ", "page_idx": 1}, {"type": "text", "text": "We then extend our approach to the multiple choice or $k$ -secretary problem where the goal is to accept at most $k$ candidates and maximize the total of their values, which is the most technical part of the paper. We design an algorithm that obtains expected total value at least $\\operatorname*{max}\\{\\Omega(1),1-\\dot{O(\\varepsilon)}\\}$ times the optimum (which is the sum of the $k$ highest values), while simultaneously guaranteeing the $k$ highest-valued candidates a constant probability of being accepted. We also have a refined guarantee that provides a higher acceptance probability for the $(1-\\delta)k$ highest-valued candidates, for any $\\delta\\in(0,1)$ . ", "page_idx": 1}, {"type": "text", "text": "Finally, we simulate our algorithms in the exact experimental setup of Fujii and Yoshida [25]. We find that they perform well both in terms of expected value accepted and fairness, whereas benchmark algorithms compromise on one of these desiderata. ", "page_idx": 1}, {"type": "text", "text": "1.1 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The secretary problem. After Gardner [26] introduced the secretary problem, Dynkin [22] developed a simple and optimal stopping rule algorithm that, with probability at least $1/e$ , accepts the candidate with maximum value. Due to its general and simple formulation, the problem has received a lot of attention (see, e.g., [42, 27] and references therein) and it was later extended to more general versions such as $k$ -secretary [39], matroid-secretary [7] and knapsack-secretary [6]. ", "page_idx": 2}, {"type": "text", "text": "Secretaries with predictions. The two works which are closest to our paper are those of Antoniadis et al. [3] and Fujii and Yoshida [25]. Both works design algorithms that use predictions regarding the values of the candidates to improve the performance guarantee of Dynkin\u2019s algorithm when the predictions are accurate while also maintaining robustness guarantees when the predictions are arbitrarily wrong. Antoniadis et al. [3] uses as prediction only the maximum value and defines the prediction error as the additive difference between the predicted and true maximum value while Fujii and Yoshida [25] receives a prediction for each candidate and defines the error as the maximum multiplicative difference between true and predicted value among all candidates. ", "page_idx": 2}, {"type": "text", "text": "Secretaries with distributional advice. Another active line of work is to explore how distributional advice can be used to surpass the $1/e$ barrier of the classical secretary problem. Examples of this line of work include the prophet secretary problems where each candidate draws its valuation from a known distribution [23, 17, 18, 5] and the sample secretary problem where the algorithm designer has only sample access to these distribution [35, 16]. We note that in the former models, predictions are either samples from distributions or distributions themselves which are assumed to be perfectly correct, while in the learning-augmented setting, we receive point predictions that could be completely incorrect. D\u00fctting et al. [20] investigate a general model for advice where both values and advice are revealed upon a candidate\u2019s arrival and are drawn from a joint distribution $\\mathcal{F}$ . For example, their advice can be a noisy binary prediction about whether the current candidate is the best overall. Their main result uses linear programming to design optimal algorithms for a broad family of advice that satisfies two conditions. However, these two conditions are not satisfied by the predictions we consider. Additionally, we do not assume any prior knowledge of the prediction quality, whereas their noisy binary prediction setting assumes that the error probability of the binary advice is known. ", "page_idx": 2}, {"type": "text", "text": "Fairness in stopping algorithms. We say that a learning-augmented algorithm for the secretary problem is $F$ -fair if it accepts the candidate with the maximum true value with probability at least $F$ . In that definition, we do not quantify unfairness as a prediction property but as an algorithmic one, since the algorithm has to accept the best candidate with probability at least $F$ no matter how biased predictions are our fairness notion is a challenging one. That notion can be characterized as an individual fairness notion similar to the identity-independent fairness (IIF) and time-independent fairness (TIF) introduced in [4]. In the context of the secretary problem, IIF and TIF try to mitigate discrimination due to a person\u2019s identity and arrival time respectively. While these are very appealing fairness notions, the fair algorithms designed in [4] fall in the classical online algorithms setting as they do not make any assumptions about the future. Consequently, their performance is upper bounded by the performance of the best algorithm in the classical worst-case analysis setting. It is also interesting to note the similarities with the poset secretary problem in [48]. In the latter work the set of candidates is split into several groups and candidates belonging to different groups cannot be compared due to different biases in the evaluation. In some sense, we try to do the same; different groups of candidates may have predictions that are affected by different biases making the comparison difficult before the true value of each candidate is revealed. Again, in [48] no information about the values of future candidates is available and the performance of their algorithms is upper bounded by the best possible performance in the worst-case analysis setting. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Secretary problem with predictions. Candidates $i=1,\\hdots,n$ have true values $u_{i}$ and predicted values $\\hat{u}_{i}$ . The number of candidates $n$ and their predicted values are known in advance. The candidates arrive in a uniformly random order. Every time a new candidate arrives their true value is revealed and the algorithm must immediately decide whether to accept the current candidate or reject them irrevocably and wait for the next arrival. We let $i^{*}=\\operatorname{argmax}_{i}u_{i}$ and ${\\hat{\\boldsymbol{\\imath}}}=\\operatorname{argmax}_{i}{\\hat{\\boldsymbol{u}}}_{i}$ denote the indices of the candidates with the maximum true and predicted value respectively. An instance $\\mathcal{T}$ consists of the $2n$ values $u_{1},\\ldots,u_{n},{\\hat{u}}_{1},\\ldots,{\\hat{u}}_{n}$ which, for convenience, are assumed to be mutually distinct1 and greater or equal to $1^{2}$ . We let $\\varepsilon(T)$ denote its prediction error. For simplicity, we focus on the additive prediction error $\\varepsilon(\\mathcal{T})=\\operatorname*{max}_{i}|\\hat{u}_{i}-u_{i}|$ , but we consider an abstract generalization that includes the multiplicative prediction error of [25] in Appendix A.2. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Objectives. We let $\\boldsymbol{\\mathcal{A}}$ be a random variable denoting the candidate accepted by a given algorithm on a fixed instance, which depends on both the arrival order and any internal randomness in the algorithm. We consider the following desiderata for a given algorithm: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\mathbf{E}[u_{\\mathcal{A}}]\\geq u_{i^{*}}\\cdot\\left(1-C\\cdot\\varepsilon(\\mathcal{T})\\right),\\;\\forall\\mathcal{T}}\\\\ {P[\\mathcal{A}=i^{*}]\\geq F,\\;\\forall\\mathcal{Z}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Our goal is to derive algorithms that can satisfy smoothness and fairness with constants $C,F>0$ that do not depend on the instance $\\mathcal{T}$ or the number of candidates $n$ . Existing algorithms for secretary with predictions do not simultaneously satisfy these desiderata, as we explain in Appendix A.1. ", "page_idx": 3}, {"type": "text", "text": "Comparison to other objectives. Existing algorithms for secretary with predictions do satisfy a weaker notion called $R$ -robustness, where $\\bar{\\mathbf{E}_{[u_{A}]}}\\,\\geq\\,R\\cdot u_{i^{\\ast}}$ for some constant $R\\,>\\,0$ . Our desideratum of fairness implies $F$ -robustness and aligns with the classical secretary formulation where one is only rewarded for accepting the best candidate. Another notion of interest in existing literature is consistency, which is how $\\bar{\\mathbf{E}}[u_{A}]$ compares to $u_{i^{*}}$ when $\\varepsilon(\\mathcal{T})\\,=\\,0$ . Our smoothness desideratum implies 1-consistency, the best possible consistency result, and guarantees a smooth degradation as $\\varepsilon(T)$ increases beyond 0. ", "page_idx": 3}, {"type": "text", "text": "3 The algorithm ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We first present and analyze the ADDITIVE-PEGGING algorithm which achieves the desiderata from Section 2. Then, we mention how using a more abstract prediction error and an almost identical analysis, permits us to generalize ADDITIVE-PEGGING to PEGGING which achieves comparable guarantees for a more general class of error functions that includes the multiplicative error. ", "page_idx": 3}, {"type": "text", "text": "Our algorithms assume that each candidate $i$ arrives at an independently random arrival time $t_{i}$ drawn uniformly from $[0,1]$ . The latter continuous-time arrival model is equivalent to candidates arriving in a uniformly random order [29] and simplifies the algorithm description and analysis. We also write $\\epsilon_{i}$ as shorthand for $|u_{i}-\\hat{u}_{i}|$ , $\\varepsilon$ as shorthand for $\\varepsilon(\\mathcal{T})$ (so that $\\varepsilon=\\operatorname*{max}_{i}\\epsilon_{i}$ ) and $i\\prec j$ if $t_{i}<t_{j}$ . ", "page_idx": 3}, {"type": "text", "text": "Description of ADDITIVE-PEGGING . ADDITIVE-PEGGING ensures smoothness by always accepting a candidate whose value is close to $u_{\\hat{\\imath}}$ which, as we argue, is at least $u_{i^{*}}-2\\,\\varepsilon$ . To see this, note that $u_{\\hat{i}}\\geq\\hat{u}_{\\hat{i}}-\\epsilon_{\\hat{i}}\\geq\\hat{u}_{i^{*}}-\\epsilon_{\\hat{i}}\\geq u_{i^{*}}-\\epsilon_{i^{*}}-\\epsilon_{\\hat{i}}\\geq u_{i^{*}}-2\\,\\varepsilon\\mathrm{.}$ , where we used that $\\hat{u}_{\\hat{\\imath}}\\ge\\hat{u}_{i^{*}}$ (by definition of $\\widehat{\\iota}$ ) and $\\varepsilon\\ge\\operatorname*{max}\\{\\epsilon_{i^{*}},\\epsilon_{\\hat{\\imath}}\\}$ (by definition of $\\varepsilon$ ). Because $u_{i^{*}}-2\\,\\varepsilon\\geq u_{i^{*}}(1-2\\varepsilon)$ from the assumption that $u_{i^{*}}\\geq1$ , this suggests that for smoothness it suffices to focus on comparing to $u_{\\hat{\\imath}}$ . For this purpose, our algorithm computes the literal ${\\mathcal{C}}=(i={\\hat{\\imath}})$ at each new arrival, ensuring that any acceptance while $\\mathcal{C}$ holds maintains smoothness. ", "page_idx": 3}, {"type": "text", "text": "For the fairness desideratum, we note that Dynkin\u2019s algorithm [22] for the classical secretary problem relies on the observation that if a constant fraction of the candidates have arrived and the candidate who just arrived has the maximum true value so far, then this candidate has a constant probability of being the best overall. The same high-level intuition is used in our algorithm. Every time a new candidate $i$ arrives, we check if $i$ is the maximum so far and if $t_{i}>1/2$ , namely we compute literal $\\mathcal{F}$ . Accepting when $\\mathcal{F}$ is true, which is what Dynkin\u2019s algorithm does, would ensure us fairness. ", "page_idx": 3}, {"type": "text", "text": "However, there are two crucial situations where ADDITIVE-PEGGING differs from Dynkin\u2019s algorithm. The first such situation is when the candidate $\\hat{\\boldsymbol{\\imath}}$ with maximum predicted value arrives and we have that $\\hat{\\boldsymbol{\\imath}}$ is not the maximum so far or $t_{\\hat{\\imath}}\\leq1/2$ , i.e., ${\\mathcal{C}}\\wedge{\\overline{{\\mathcal{F}}}}$ is true. In this case, we cannot always reject $\\hat{\\boldsymbol{\\imath}}$ , as Dynkin\u2019s algorithm would, because that would not guarantee smoothness. Instead, we reject $\\hat{\\boldsymbol{\\imath}}$ only if there is a future candidate whose prediction is sufficiently high compared to $u_{\\hat{\\imath}}$ . We call $I^{\\mathsf{p e g g e d}}$ the set of those candidates. The main idea behind the pegged set $I^{\\mathsf{p e g g e d}}$ is that it contains the last candidate to arrive who can guarantee the smoothness property, which is why we accept that candidate when they arrive. The second situation where our algorithm departs from Dynkin\u2019s algorithm is when a candidate $i$ arrives (with $i\\neq\\hat{\\imath}$ and $i\\neq i^{\\mathsf{p e g g e d}})$ and we have that $\\mathcal{F}$ is true, in other words when $\\overline{{\\mathcal{C}}}\\wedge\\mathcal{F}$ is true and the corresponding if-statement is executed. In this situation, we cannot always accept $i$ as Dynkin\u2019s algorithm would, because that would again violate smoothness. Indeed, we accept only if $u_{i}$ can be lower bounded by $\\hat{u}_{\\hat{i}}-\\varepsilon_{t_{i}}$ . Indeed, note that if $u_{i}+\\varepsilon_{t_{i}}\\ll\\hat{u}_{\\hat{\\imath}}$ , accepting $i$ might be detrimental to our quest of ensuring smoothness. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Finally, we note that the running time of the algorithm is $O(n\\log n)$ ", "page_idx": 4}, {"type": "table", "img_path": "dxxj4S06YL/tmp/beb47b2329cd10f40a46d21185a1353a3794b9d2dfcad1ba2e6f9a8f5a514856.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "Analysis of the ADDITIVE-PEGGING algorithm. ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Lemma 1. ADDITIVE-PEGGING satisfies $u_{A}\\ \\geq u_{i^{*}}\\cdot(1-4\\,\\varepsilon(\\mathcal{T}))$ , $\\forall\\mathcal{T}$ with probability 1. ", "page_idx": 4}, {"type": "text", "text": "Proof. Let $i^{\\mathsf{p e g g e d}}$ denote the last arriving candidate in $I^{\\mathsf{p e g g e d}}$ . ", "page_idx": 4}, {"type": "text", "text": "We first argue that PEGGING always accepts a candidate irrespective of the random arrival times of the candidates. We focus on any instance where ADDITIVE-PEGGING does not accept a candidate until time $t_{\\hat{\\imath}}$ . At time $t_{\\hat{\\imath}}$ either ${\\mathcal{C}}\\wedge{\\mathcal{F}}$ or ${\\mathcal{C}}\\wedge{\\overline{{\\mathcal{F}}}}$ are true. Since in the former case candidate $\\hat{\\boldsymbol{\\imath}}$ is accepted, we focus on the latter case and in particular whenever the set $I^{\\mathsf{p e g g e d}}$ which is computed is non-empty (otherwise, candidate $\\hat{\\boldsymbol{\\imath}}$ is accepted). In that case, it is guaranteed that by time $t_{i^{\\mathrm{pegged}}}$ ADDITIVE-PEGGING will accept a candidate. ", "page_idx": 4}, {"type": "text", "text": "We now argue that in all cases ADDITIVE-PEGGING maintains smoothness. Using $\\varepsilon$ , $\\epsilon_{i}$ definitions and the fact that $\\hat{\\boldsymbol{\\imath}}$ is the candidate with the maximum predicted value we have: $\\hat{u}_{\\hat{\\imath}}~\\geq~\\hat{u}_{i^{*}}~\\geq~$ $u_{i^{*}}\\,-\\,\\epsilon_{i^{*}}\\,\\geq\\,u_{i^{*}}\\,-\\,\\varepsilon$ . If candidate $\\hat{\\boldsymbol{\\imath}}$ is accepted then using the latter lower bound we get $u_{\\hat{\\imath}}~\\geq$ $\\hat{u}_{\\hat{\\imath}}-\\epsilon_{\\hat{\\imath}}\\geq u_{i^{*}}-\\varepsilon-\\epsilon_{\\hat{\\imath}}\\geq u_{i^{*}}-2\\,\\varepsilon$ . If we accept $i\\neq\\hat{\\imath}$ and the if statement of $\\overline{{\\mathcal{C}}}\\wedge\\mathcal{F}$ is executed at time $t_{i}$ then we have $u_{i}\\;>\\;\\hat{u}_{\\hat{i}}\\,-\\,\\varepsilon_{t_{i}}\\;\\geq\\;u_{i^{*}}\\,-\\,\\varepsilon\\,{-}\\varepsilon_{t_{i}}\\;\\geq\\;u_{i^{*}}\\,-\\,2\\,\\varepsilon$ . Finally, we need to lower bound the value $u_{i^{\\mathsf{p e g g e d}}}$ in case our algorithm terminates accepting $i^{p e g g e d}$ . Note that from the way the pegged set $I^{\\mathsf{p e g g e d}}$ is updated when ${\\mathcal{C}}\\wedge{\\overline{{\\mathcal{F}}}}$ is true we always have $u_{\\hat{\\imath}}~<~\\hat{u}_{i^{\\mathrm{pegged}}}+\\varepsilon_{t_{\\hat{\\imath}}}$ . Since $u_{i^{\\mathrm{pegged}}}\\,\\geq\\,\\hat{u}_{i^{\\mathrm{pegged}}}\\,-\\epsilon_{i^{\\mathrm{pegged}}}$ we can conclude that $u_{i^{\\mathrm{pegged}}}>u_{\\hat{\\imath}}-\\varepsilon_{t_{\\hat{\\imath}}}-\\epsilon_{i^{\\mathrm{pegged}}}\\geq u_{i^{\\ast}}-4\\,\\varepsilon$ . Finally, note that since $u_{i^{*}}\\geq1$ we have that $u_{i^{*}}-4\\,\\varepsilon\\geq u_{i^{*}}(1-4\\,\\varepsilon)$ . \u53e3 ", "page_idx": 4}, {"type": "text", "text": "Lemma 2. ADDITIVE-PEGGING satisfies $P[A=i^{*}]\\geq1/16,\\;\\natural$ I. ", "page_idx": 4}, {"type": "text", "text": "Proof. In the following we assume that the number of candidates is larger or equal to 3. The proof for the case where $n=2$ is almost identical while the fairness guarantee in that case is $1/4$ . We denote by $\\tilde{\\it\\Delta}_{\\tilde{\\it\\Delta}}$ the index of the candidate with the highest true value except $i^{*}$ and $\\hat{\\boldsymbol{\\imath}}$ , i.e., $\\tilde{\\iota}=\\mathrm{argmax}_{i\\neq i^{*},\\hat{\\iota}}\\,u_{i}$ Note that depending on the value of $u_{\\hat{\\imath}}$ , $\\tilde{\\imath}$ might denote the index of the candidate with the second or third highest true value. To prove fairness we distinguish between two cases: either $\\hat{\\boldsymbol{\\imath}}=\\boldsymbol{i}^{*}$ or ${\\hat{\\imath}}\\neq i^{*}$ . For each of those cases, we define an event and argue that: (1) the event happens with constant probability; and (2) if that event happens then ADDITIVE-PEGGING accepts $i^{*}$ . ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "If $i^{*}=\\widehat{\\iota}$ we define event $E=\\{t_{\\tilde{\\imath}}<1/2<t_{i^{*}}\\}$ for which $P[E]=1/4$ . $E$ implies that our algorithm does not accept any candidate until time $t_{i^{*}}$ . Indeed, note that at any point in time before $t_{i^{*}}$ , both literals $\\mathcal{F}$ and $\\mathcal{C}$ are simultaneously false. On the contrary, at time $t_{i^{*}}$ , both $\\mathcal{C}$ and $\\mathcal{F}$ are true and our algorithm accepts $i^{*}$ . ", "page_idx": 5}, {"type": "text", "text": "On the other hand, if $i^{*}\\neq\\hat{\\i}$ we distinguish between two sub-cases. First, we show that either $u_{\\hat{\\imath}}<\\hat{u}_{i^{*}}+\\epsilon_{\\hat{\\imath}}$ or $u_{i^{*}}>\\hat{u}_{\\hat{\\imath}}-\\epsilon_{i^{*}}$ is true. By contradiction, assume that both inequalities do not hold, then ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{\\boldmath~\\gamma~}_{i}\\geq\\hat{u}_{i^{*}}+\\epsilon_{i}\\xrightarrow{u_{i^{*}}>u_{i}}u_{i^{*}}>\\hat{u}_{i^{*}}+\\epsilon_{i}\\Rightarrow u_{i^{*}}-\\hat{u}_{i^{*}}>\\epsilon_{i}\\xrightarrow{\\epsilon_{i}\\bullet\\sum u_{i^{*}}-\\hat{u}_{i^{*}}}\\epsilon_{i^{*}}>\\epsilon_{i}}\\\\ {u_{i^{*}}\\leq\\hat{u}_{i}-\\epsilon_{i^{*}}\\xrightarrow{u_{i^{*}}>u_{i}}u_{i}<\\hat{u}_{i}-\\epsilon_{i^{*}}\\Rightarrow\\epsilon_{i^{*}}<\\hat{u}_{i}-u_{i}\\xrightarrow{\\epsilon_{i}\\geq u_{i}-\\hat{u}_{i}}\\epsilon_{i^{*}}<\\epsilon_{i}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which is a contradiction. We now define two events $E_{1}$ and $E_{2}$ which imply that $i^{*}$ is always accepted whenever $\\{u_{\\hat{\\imath}}<\\hat{u}_{i^{*}}+\\epsilon_{\\hat{\\imath}}\\}$ and $\\{u_{i^{*}}>\\hat{u}_{\\hat{\\imath}}-\\epsilon_{i^{*}}\\}$ are true respectively. ", "page_idx": 5}, {"type": "text", "text": "If $u_{\\hat{\\imath}}~<~\\hat{u}_{i^{*}}+\\epsilon_{\\hat{\\imath}}$ , then we define event $E_{1}\\,=\\,\\{t_{\\widetilde{\\imath}}\\,<\\,1/2\\}\\wedge\\{t_{\\widehat{\\imath}}\\,<\\,1/2\\}\\wedge\\{1/2\\,<\\,t_{i^{*}}\\}$ which is composed by 3 independent events and it happens with probability $P[E_{1}]=1/2^{3}=1/8.$ $E_{1}$ implies that at time $t_{i^{*}}$ , ${\\mathcal{C}}\\wedge{\\mathcal{F}}$ is true. Consequently, if until time $t_{i^{*}}$ all candidates are rejected then candidate $i^{*}$ is hired. To argue that no candidate is accepted before time $t_{i^{*}}$ note that at time $t_{\\hat{\\imath}}$ the set $\\{j\\succ\\hat{\\imath}:u_{\\hat{\\imath}}<\\hat{u}_{j}+\\varepsilon_{t_{\\hat{\\imath}}}\\}\\supseteq\\overline{{\\{j\\succ\\hat{\\imath}:u_{\\hat{\\imath}}<\\hat{u}_{j}+\\epsilon_{\\hat{\\imath}}\\}}}$ contains $i^{*}$ and that $\\mathcal{F}$ is false at all times before $t_{i^{*}}$ . ", "page_idx": 5}, {"type": "text", "text": "If $u_{i^{*}}>\\hat{u}_{\\hat{\\imath}}-\\epsilon_{i^{*}}$ , then we define $E_{2}=\\left\\{t_{\\widetilde{\\imath}}<1/2<t_{i^{*}}<t_{\\widehat{\\imath}}\\right\\}$ which happens with probability ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P[E_{2}]=P[t_{\\tilde{\\imath}}<1/2]\\cdot P[1/2<t_{i^{*}}<t_{\\tilde{\\imath}}]}\\\\ &{\\qquad\\quad=P[t_{\\tilde{\\imath}}<1/2]\\cdot P[1/2<\\operatorname*{min}\\{t_{i^{*}},t_{\\tilde{\\imath}}\\}\\wedge\\operatorname*{min}\\{t_{i^{*}},t_{\\tilde{\\imath}}\\}=t_{i^{*}}]}\\\\ &{\\qquad\\quad=P[t_{\\tilde{\\imath}}<1/2]\\cdot P[1/2<\\operatorname*{min}\\{t_{i^{*}},t_{\\tilde{\\imath}}\\}]\\cdot P[\\operatorname*{min}\\{t_{i^{*}},t_{\\tilde{\\imath}}\\}=t_{i^{*}}]}\\\\ &{\\qquad\\quad=(1/2)\\cdot(1/4)\\cdot(1/2)=1/16}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that until time $t_{i^{*}}$ no candidate is accepted since $\\mathcal{C}$ and $\\mathcal{F}$ are both false at all times. Indeed, between times 0 and $1/2$ only $\\hat{\\boldsymbol{\\imath}}$ could have been accepted but its arrival time is after $t_{i^{*}}$ , and between times $1/2$ and $t_{i^{*}}$ no candidate has a true value larger than $u_{\\tilde{\\imath}}$ . Finally, note that at time $t_{i^{*}}$ we have $\\varepsilon_{t_{i^{*}}}\\geq\\epsilon_{i^{*}}$ and consequently $\\overline{{c}}\\wedge\\mathcal{F}\\wedge\\left\\{u_{i^{*}}>\\hat{u}_{\\hat{\\imath}}-\\varepsilon_{t_{i^{*}}}\\right\\}$ is true and $i^{*}$ gets accepted. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Theorem 3. ADDITIVE-PEGGING satisfies smoothness and fairness with $C=4$ and $F=1/16$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3 follows directly from Lemmas 1 and 2. We note that Lemma 1 actually implies a stronger notion of smoothness that holds with probability 1. ", "page_idx": 5}, {"type": "text", "text": "The general PEGGING algorithm. In Appendix A.2 we generalize the ADDITIVE-PEGGING algorithm to the PEGGING algorithm to provide fair and smooth algorithms for different prediction error definitions. ADDITIVE-PEGGING is an instantiation of PEGGING when the prediction error is defined as the maximum absolute difference between true and predicted values among candidates. To further demonstrate the generality of PEGGING , we also instantiate it over the same prediction error definition $\\varepsilon(\\mathcal{Z})=\\operatorname*{max}_{i}\\left|1-\\hat{u}_{i}/u_{i}\\right|$ as in [25] and recover similar smoothness bounds as in [25] while also ensuring fairness. We name the latter instantiation MULTIPLICATIVE-PEGGING and present its guarantees in Theorem 4. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4. If $\\varepsilon(\\mathcal{Z})=\\operatorname*{max}_{i}|1-\\hat{u}_{i}/u_{i}|$ , then MULTIPLICATIVE-PEGGING satisfies smoothness and fairness with $C=4$ and $F=1/16$ . ", "page_idx": 5}, {"type": "text", "text": "Fujii and Yoshida [25] define the prediction error as in Theorem 4 and design an algorithm that accepts a candidate with expected value at least $u_{i^{*}}\\cdot\\operatorname*{max}\\left\\{(1-\\varepsilon)/(1+\\varepsilon),0.215\\right\\}$ . Since $(1-\\varepsilon)/(1+\\varepsilon)^{'}\\!\\geq$ $1\\,-\\,2\\,\\varepsilon$ the latter algorithm satisfies the smoothness desideratum of Section 2, but, as we prove in Appendix A.1 it violates the fairness desideratum. ", "page_idx": 5}, {"type": "text", "text": "4 Extension: $k$ -Secretary problem with predictions ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We consider the generalization to the $k$ -secretary problem, where $k\\geq1$ candidates can be accepted. To simplify notation we label the candidates in decreasing order of predicted value, so that $\\hat{u}_{1}>$ $\\cdots>\\hat{u}_{n}$ and denote $r_{i}$ to be the index of the candidate with the $\\ddot{\\iota}$ th highest true value so that $u_{r_{i}}\\;>\\;\\cdot\\,\\cdot\\;>\\;u_{r_{n}}$ . The prediction error is again defined as $\\varepsilon(\\mathcal{T}):=\\operatorname*{max}_{i}\\bar{|u_{i}-\\hat{u}_{i}|}$ and we let $S$ denote the random set of candidates accepted by a given algorithm on a fixed instance. The extension of our two objectives to this setting is ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left[\\displaystyle\\sum_{i\\in S}u_{i}\\right]\\geq(1-C\\cdot\\varepsilon(\\mathbb{Z}))\\sum_{i=1}^{k}u_{r_{i}},\\:\\forall\\mathbb{Z}}\\\\ &{P[r_{i}\\in S]\\geq F_{i},\\:\\forall i=1,\\ldots,k,\\:\\:\\forall\\mathbb{Z}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The smoothness desideratum compares the expected sum of true values accepted by the algorithm to the sum of the $k$ highest true values that could have been accepted. The fairness desideratum guarantees each of these candidates in the top $k$ to be accepted with probability $F_{i}$ . The $k$ -secretary problem with predictions has been studied by Fujii and Yoshida [25], who derive an algorithm satisfying $\\begin{array}{r}{\\mathbf{E}\\big[\\sum_{i\\in S}u_{i}\\big]\\geq\\operatorname*{max}\\{1-O(\\log k/\\sqrt{k}),1-O(\\operatorname*{max}_{i}|1-\\hat{u}_{i}/u_{i}|)\\}\\sum_{i=1}^{k}u_{r_{i}}}\\end{array}$ but without any fairness guarantees. We derive an algorithm K-PEGGING that satisfies the  following. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5. K-PEGGING satisfies smoothness and fairness for $k$ -secretary with $C=4$ and $F_{i}=$ max $\\left\\{(1/3)^{k+5},\\frac{1-(i+13)/k}{256}\\right\\}$ for all $i=1,\\ldots,k$ . ", "page_idx": 6}, {"type": "text", "text": "Assuming $k$ is a constant, $C$ and $F_{1},\\ldots,F_{k}$ in Theorem 5 are constants that do not depend on $n$ or the instance $\\mathcal{T}$ . For large values of $k$ the first term in $F_{i}$ is exponentially decaying, but the second term still guarantees candidate $r_{i}$ a probability of acceptance that is independent of $k$ as long as $i/k$ is bounded away from 1. More precisely, for any constant $\\delta>0$ and $i\\leq(1-\\delta)k-13$ , candidate $r_{i}$ is accepted with probability at least $\\delta/256$ . For large values of $k$ , we can apply this fact with $\\delta=1/2$ to see that all candidates in the top quarter are accepted with probability at least $1/512$ , getting a \"robustness\" constant that is independent of $k$ : $\\begin{array}{r}{\\mathbf{E}\\bigl[\\sum_{i\\in S}u_{i}\\bigr]\\geq\\frac{1}{2048}\\sum_{i=1}^{k}u_{r_{i}}.}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "The algorithm. While we defer the proof of Theorem 5 to Appendix B, we present the intuition and the main technical difficulties in the design of K-PEGGING . K-PEGGING maintains in an online manner the following sets: (1) the solution set $S$ which contains all the candidates that have already been accepted; (2) a set $H$ that we call the hopeful set and contains the $k-|S|$ future candidates with the highest predicted values; (3) a set $B$ that we call the blaming set. $B$ contains a subset of already arrived candidates that pegged a future candidate; and (4) the set $P$ of pegged elements which contains all candidates that have been pegged by a candidate in $B$ . In addition, we use function $p e g:\\{1,...,k\\}\\,\\rightarrow\\,[n]$ to store the \u201cpegging responsibility\u201d, i.e., if $p e g(i)\\,=\\,j$ then at time $t_{i}$ , $i\\in\\{1,...,k\\}$ : (a) was not accepted; and (b) forced $j$ to be pegged. We use $p e g^{-1}(j)=i$ to denote that $j$ was pegged by $i$ . ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 K-PEGGING ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "$H\\gets[k],S\\gets\\emptyset,P\\gets\\emptyset,B\\gets\\emptyset$   \nwhile agent $i$ arrives at time $t_{i}$ do $\\tau\\leftarrow k^{t h}$ highest value seen before time $t_{i}$ , $\\varepsilon_{t_{i}}\\gets\\operatorname*{max}_{j:t_{j}\\leq t_{i}}\\left|\\hat{u}_{j}-u_{j}\\right|$ case 1: $i\\in P$ Add $i$ to $S$ , remove $i$ from $P$ and remove $p e g^{-1}(i)$ from $B$ . case 2: $i\\in H$ and $(t_{i}\\leq1/2\\,\\mathbf{or}\\,u_{i}\\leq\\tau)$ subcase 2a: $\\{j\\succ i:u_{i}<\\hat{u}_{j}{+}\\varepsilon_{t_{i}}\\}\\backslash(P\\cup[k])=\\emptyset\\,{\\bf o r}$ ( $C_{i}=0$ with Ci \u223cBernoulli(1/2)) Add $i$ to $S$ , remove $i$ from $H$ subcase 2b: Otherwise Add arg $\\begin{array}{r}{\\operatorname*{min}_{j\\in\\{j\\succ i:u_{i}<\\hat{u}_{j}+\\varepsilon_{t_{i}}\\}\\setminus(P\\cup[k])}\\hat{u}_{j}}\\end{array}$ to $P$ , add $i$ to $B$ , remove $i$ from $H$ case 3: $i\\in H$ and $(t_{i}>1/2$ and $u_{i}>\\tau$ ) Add $i$ to $S$ and remove $i$ from $H$ case 4: $i\\not\\in H$ and $(t_{i}>1/2$ and $u_{i}>\\tau$ ) subcase ${4\\mathrm{a}}$ : $\\{j\\in B:u_{i}>u_{j}\\}\\neq\\emptyset$ Add $i$ to $S$ , remove argma $\\mathtt{X}_{j\\in B:u_{i}>u_{j}}\\;u_{j}$ from $B$ , and remove $p e g(j)$ from $P$ subcase 4b: $\\{j\\in H:u_{i}>\\hat{u}_{j}-\\varepsilon_{t_{i}}\\}\\neq\\emptyset$ Add $i$ to $S$ and remove $\\mathrm{argmax}_{j\\in H:u_{i}>\\hat{u}_{j}-\\varepsilon_{t_{i}}}\\;u_{j}$ from $H$ ", "page_idx": 6}, {"type": "text", "text": "To satisfy the fairness property, we check if the current candidate $i$ has arrived at time $t_{i}\\geq1/2$ and if $u_{i}$ larger than the $k^{t h}$ highest value seen so far. We refer to these two conditions as the fairness conditions. If $i\\in P$ (case $^{\\,l}$ ) or $i\\in H$ and the fairness conditions hold (case 3), then we accept $i$ . If the fairness conditions hold but $i\\not\\in H$ then we accept only if there is a past candidate in $B$ (subcase $4a)$ or a future candidate in $H$ (subcase $^{4b}$ ) whose value is close to $u_{i}$ . ", "page_idx": 7}, {"type": "text", "text": "The main technical challenge arises in order to generalize the pegging idea when a candidate $i\\in H$ arrives but one of the fairness conditions does not hold. Indeed, it is not clear if we should reject $i$ and peg a future candidate or accept $i$ . Consider an instance where the prediction error is high enough so that when $i$ arrives there is always a future candidate that can be pegged and consider the case where $t_{i}<1/2$ . If we accept then we may decrease our budget too aggressively until time $1/2$ and do not have enough space in our solution to accept candidates not in $[k]$ in the second half of the time. However, if we do not accept then we do not give $i$ the possibility of being accepted in the first half of the time and we may decrease its probability of being accepted too much. K-PEGGING balances these two objectives while achieving smoothness by accepting a solution set $S$ with values that are pairwise \u201cclose\u201d to the values of candidates in $\\{1,2,\\ldots,k\\}$ . We prove the latter in lemma 8 by defining an injective function $m(\\cdot)$ from set $S$ to $\\{1,2,\\ldots,k\\}$ such that for each $j\\in S$ , $u_{j}\\approx u_{m(j)}$ . Finally, we note that the running time of this algorithm is also $O(n\\log n)$ . ", "page_idx": 7}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We simulate our ADDITIVE-PEGGING and MULTIPLICATIVE-PEGGING algorithms in the exact experimental setup of Fujii and Yoshida [25], to test its average-case performance. ", "page_idx": 7}, {"type": "text", "text": "Experimental Setup. Fujii and Yoshida [25] generate various types of instances. We follow their Almost-constant, Uniform, and Adversarial types of instances, and also create the Unfair type of instance to further highlight how slightly biased predictions can lead to very unfair outcomes. Both true and predicted values of candidates in all these instance types are parameterized by a scalar $\\varepsilon\\in[0,1)$ which controls the prediction error. Setting $\\varepsilon=0$ creates instances with perfect predictions and setting a higher value of $\\varepsilon$ creates instances with more erroneous predictions. Almost-constant models a situation where one candidate has a true value of $1/(1-\\varepsilon)$ and the rest of the candidates have a value of 1. All predictions are set to 1. In Uniform we sample each $u_{i}$ independently from the exponential distribution with parameter 1. The exponential distribution generates a large value with a small probability and consequently models a situation where one candidate is significantly better than the rest. All predicted values are generated by perturbing the actual value with the uniform distribution, i.e., $\\hat{u}_{i}=\\delta_{i}\\cdot u_{i}$ , where $\\delta_{i}$ is sampled uniformly and independently from $[1-\\varepsilon,1+\\varepsilon]$ . In Adversarial the true values are again independent samples from the exponential distribution with parameter 1. The predictions are \u201cadversarially\u201d perturbed while maintaining the error to be at most $\\varepsilon$ in the following manner: if $i$ belongs to the top half of candidates in terms of true value, then $\\hat{u}_{i}\\,=\\,(1\\,-\\varepsilon)\\cdot\\bar{u_{i}}$ ; if $i$ belongs to the bottom half, then $\\hat{u}_{i}\\,=\\,(1+\\varepsilon)\\cdot u_{i}$ . Finally, in Unfair all candidates have values that are at most a $\\left(1+\\varepsilon\\right)$ multiplicative factor apart. Formally, $u_{i}$ is a uniform value in $[1-\\varepsilon/4,1+\\varepsilon/4]$ , and since $(1+\\varepsilon/4)/(1-\\varepsilon/4)\\,\\le\\,(1+\\varepsilon)$ we have that the smallest and largest value are indeed very close. We set $\\hat{u}_{i}=u_{n-r(i)+1}$ where $r(i)$ is the rank of $u_{i}$ , i.e., predictions create a completely inverted order. ", "page_idx": 7}, {"type": "text", "text": "We compare ADDITIVE-PEGGING and MULTIPLICATIVE-PEGGING against LEARNED-DYNKIN [25], HIGHEST-PREDICTION which always accepts the candidate with the highest prediction, and the classical DYNKIN algorithm which does not use the predictions. Following [25], we set the number of candidates to be $n=100$ . We experiment with all values of $\\varepsilon$ in $\\{0,1/20,2/20,\\ldots,19/20\\}$ . For each type of instance and value of $\\varepsilon$ in this set, we randomly generate 10000 instances, and then run each algorithm on each instance. For each algorithm, we consider instance-wise the ratio of the true value it accepted to the maximum true value, calling the average of this ratio across the 10000 instances its competitive ratio. For each algorithm, we consider the fraction of the 10000 instances on which it successfully accepted the candidate with the highest true value, calling this fraction its fairness. We report the competitive ratio and fairness of each algorithm, for each type of instance and each value of $\\varepsilon$ , in Figure 1. Our code is written in Python 3.11.5 and we conduct experiments on an M3 Pro CPU with 18 GB of RAM. The total runtime is less than 5 minutes. ", "page_idx": 7}, {"type": "text", "text": "Results. The results are summarized in figure 1. Since ADDITIVE-PEGGING and MULTIPLICATIVEPEGGING achieve almost the same competitive ratio and fairness for all instance types and values of $\\varepsilon$ we only present ADDITIVE-PEGGING in figure 1 but include the code of both in the supplementary material. Our algorithms are consistently either the best or close to the best in terms of both competitive ratio and fairness for all different pairs of instance types and $\\varepsilon$ values. Before discussing the results of each instance type individually it is instructive to mention some characteristics of our benchmarks. While DYNKIN does not use predictions and is therefore bound to suboptimal competitive ratios when predictions are accurate, we note that it accepts the maximum value candidate with probability at least $1/e$ , i.e., it is $1/e$ -fair. When predictions are non-informative this is an upper bound on the attainable fairness for any algorithm whether it uses predictions or not. HIGHESTPREDICTION is expected to perform well when the highest prediction matches the true highest value candidate and poorly when the latter is not true. In Almost-constant for small values of $\\varepsilon$ all candidates have very close true values and all algorithms except DYNKIN have a competitive ratio close to 1. DYNKIN may not accept any candidate and this is why its performance is poorer than the rest of the algorithms. Note that as $\\varepsilon$ increases both our algorithms perform significantly better than all other benchmarks. ", "page_idx": 7}, {"type": "image", "img_path": "dxxj4S06YL/tmp/9d3d6ce06ac758dc8de445f1d8ab5cfa5a40e58eb3924875c2c36f7b410a48b2.jpg", "img_caption": ["Figure 1: Competitive ratio and fairness of different algorithms, for each instance type and level of $\\varepsilon$ . "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "In terms of fairness, predictions do not offer any information regarding the ordinal comparison between candidates\u2019 true values and this is why for small values of $\\varepsilon$ the probability of HIGHESTPREDICTION and LEARNED-DYNKIN of accepting the best candidate is close to $1/100\\,=\\,1/n$ , i.e., random. Here, the fairness of our algorithms and DYNKIN is similar and close to $1/e$ . In both Uniform and Adversarial we observe that for small values of $\\varepsilon$ the highest predicted candidate is the true highest and ADDITIVE-PEGGING , LEARNED-DYNKIN and HIGHEST-PREDICTION all accept that candidate having a very close performance both in terms of fairness and competitive ratio. For higher values of $\\varepsilon$ the fairness of those algorithms deteriorates similarly and it approaches again $0.37\\simeq1/e$ . In Unfair our algorithms outperform all other benchmarks in terms of competitive ratio for all values of $\\varepsilon$ and achieve a close to optimal fairness. This is expected as our algorithms are particularly suited for cases where predictions may be accurate but unfair. ", "page_idx": 8}, {"type": "text", "text": "Overall, our algorithms are the best-performing and most robust. The HIGHEST-PREDICTION algorithm does perform slightly better on Uniform instances and Adversarial instances under most values of $\\varepsilon$ , but performs consistently worse on Almost-constant and Unfair instances, especially in terms of fairness. Our algorithms perform better than LEARNED-DYNKIN in almost all situations. ", "page_idx": 8}, {"type": "text", "text": "6 Limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We study a notion of fairness that is tailored to the secretary problem with predictions and build our algorithms based on this notion. However, there are alternative notions of fairness one could consider in applications such as hiring, as well as variations of the secretary problem that capture other features in these applications. While our model allows for arbitrary bias in the predictions we assume that the true value of a candidate is fully discovered upon arrival, and define fairness based on hiring the best candidate (who has the highest true value) with a reasonable probability. Thus, we ignore considerations such as bias in how we get the true value of a candidate (e.g., via an interview process). In addition, as noted in Section 1, we use an individual fairness notion which does not model other natural desiderata like hiring from underprivileged populations or balance the hiring probabilities across different populations. These are considerations with potentially high societal impact which our algorithms do not consider and are interesting directions for future work on fair selection with predictions. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Regarding trade-offs in our guarantees: for the single-secretary problem, we can improve the fairness guarantee from $1/16$ to 0.074 by optimizing the constants in our algorithm. However, we choose not to do so, as the performance increase is marginal, and we aim to keep the proof as simple as possible. Additionally, any constant $C$ for smoothness implies an upper bound of $F=0.348$ for fairness. The proof of this follows from Fujii and Yoshida [25], which shows that for any constant $C$ , there is no randomized algorithm with a competitive ratio better than $\\operatorname*{max}\\{1-C\\epsilon,0.348\\}$ . Since a $C$ -smooth and $F$ -fair algorithm has a competitive ratio of at least $\\operatorname*{max}\\{1-C\\epsilon,F\\}$ , their impossibility result implies that the best achievable fairness for any $C$ -smooth (where $C$ is a constant) algorithm is $F=0.348$ . Exploring other trade-offs and finding the Pareto-optimal curve in terms of smoothness and fairness are interesting directions. The main challenge in achieving a smooth trade-off between fairness and smoothness is as follows: any bound on $C$ for smoothness implies a competitive ratio of $1-C\\epsilon$ , which reaches a ratio of 1 when the predictions are exactly correct. Thus, regardless of the smoothness guarantee, we must achieve a competitive ratio of 1 when predictions are fully accurate. This constraint makes it challenging to improve the fairness guarantee $F$ , even at the cost of a less favorable smoothness constant $C$ . ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias: There\u2019s software used across the country to predict future criminals. and it\u2019s biased against blacks. ProPublica, May 23 2016. URL https://www.propublica.org/article/ machine-bias-risk-assessments-in-criminal-sentencing.   \n[2] Antonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, and Bertrand Simon. Online metric algorithms with untrusted predictions. In Proceedings of the 37th International Conference on Machine Learning (ICML), volume 119, pages 345\u2013355, 2020. URL https://proceedings.mlr.press/v119/antoniadis20a.html.   \n[3] Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and online matching problems with machine learned advice. In Proceedings of the 33rd Annual Conference on Neural Information Processing Systems (NeurIPS), pages 7933\u2013 7944, 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/ file/5a378f8490c8d6af8647a753812f6e31-Paper.pdf.   \n[4] Makis Arsenis and Robert Kleinberg. Individual fairness in prophet inequalities. In Proceedings of the 23rd ACM Conference on Economics and Computation (EC), page 245, 2022.   \n[5] Yossi Azar, Ashish Chiplunkar, and Haim Kaplan. Prophet secretary: Surpassing the $1-1/e$ barrier. In Proceedings of the 19th ACM Conference on Economics and Computation $(E C)$ , pages 303\u2013318, 2018.   \n[6] Moshe Babaioff, Nicole Immorlica, David Kempe, and Robert Kleinberg. A knapsack secretary problem with applications. In Proceedings of the 10th International Workshop on Approximation Algorithms for Combinatorial Optimization Problems (APPROX), pages 16\u201328, 2007.   \n[7] Moshe Babaioff, Nicole Immorlica, and Robert Kleinberg. Matroids, secretary problems, and online mechanisms. In Proceedings of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), page 434\u2013443, 2007.   \n[8] Miranda Bogen and Aaron Rieke. Help wanted: an examination of hiring algorithms. Equity, and Bias, Upturn (December 2018), 2018.   \n[9] L. Elisa Celis, Damian Straszak, and Nisheeth K. Vishnoi. Ranking with fairness constraints. In Proceedings of the 45th International Colloquium on Automata, Languages and Programming (ICALP), 2018.   \n[10] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvtiskii. Matroids, matchings, and fairness. In Proceedings of the 22ndInternational Conference on Artificial Intelligence and Statistics (AISTATS), pages 2212\u20132220, 2019. URL https://proceedings.mlr.press/ v89/chierichetti19a.html.   \n[11] Alexandra Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big Data, 5(2):153\u2013163, June 2017.   \n[12] Alexandra Chouldechova, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency (FAccT), pages 134\u2013148, 2018. URL http://proceedings.mlr.press/v81/ chouldechova18a.html.   \n[13] Lee Cohen, Zachary C. Lipton, and Yishay Mansour. Efficient candidate screening under multiple tests and implications for fairness. In Proceedings of the 1st Symposium on the foundations of responsible computing (FORC), page 1\u201320, 2019.   \n[14] COMPAS (software). https://en.wikipedia.org/wiki/COMPAS_(software).   \n[15] Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd International Conference on Knowledge Discovery and Data Mining (KDD), page 797\u2013806, 2017. URL https://doi. org/10.1145/3097983.3098095.   \n[16] Jos\u00e9 R. Correa, Andr\u00e9s Cristi, Laurent Feuilloley, Tim Oosterwijk, and Alexandros TsigoniasDimitriadis. The secretary problem with independent sampling. In Proceedings of the 32nd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 2047\u20132058, 2021.   \n[17] Jos\u00e9 R. Correa, Patricio Foncea, Ruben Hoeksma, Tim Oosterwijk, and Tjark Vredeveld. Posted price mechanisms and optimal threshold strategies for random arrivals. Mathematics of Operations Research, 46(4):1452\u20131478, 2021.   \n[18] Jos\u00e9 R. Correa, Raimundo Saona, and Bruno Ziliotto. Prophet secretary through blind strategies. Mathematical Programming, 190(1):483\u2013521, 2021.   \n[19] Julia Dressel and Hany Farid. The accuracy, fairness, and limits of predicting recidivism. Science Advances, 4(1), 2018. URL https://www.science.org/doi/abs/10.1126/sciadv. aao5580.   \n[20] Paul D\u00fctting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with advice. In Proceedings of the 22nd ACM Conference on Economics and Computation (EC), page 409\u2013429, 2021. URL https://doi.org/10.1145/3465456.3467623.   \n[21] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS), page 214\u2013226, 2012. URL https://doi.org/10.1145/2090236.2090255.   \n[22] E. B. Dynkin. The optimum choice of the instant for stopping a markov process. Soviet Mathematics Doklady, 4:627\u2013629, 1963.   \n[23] Hossein Esfandiari, MohammadTaghi Hajiaghayi, Vahid Liaghat, and Morteza Monemizadeh. Prophet secretary. SIAM Journal on Discrete Mathematics (SIDMA), 31(3):1685\u20131701, 2017.   \n[24] Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. Certifying and removing disparate impact. In Proceedings of the 21th International Conference on Knowledge Discovery and Data Mining (KDD), page 259\u2013268, 2015. URL https://doi.org/10.1145/2783258.2783311.   \n[25] Kaito Fujii and Yuichi Yoshida. The secretary problem with predictions. In Mathematics of Operations Research, 2023.   \n[26] Martin Gardner. Mathematical games. Scientific American, 202(3):172\u2013186, 1960.   \n[27] John P. Gilbert and Frederick Mosteller. Recognizing the maximum of a sequence. Journal of the American Statistical Association, 61:35\u201373, 1966.   \n[28] Lev Grossman. Are face-detection cameras racist? Time, 2010. URL http://content.time. com/time/business/article/0,8599,1954643,00.html.   \n[29] Anupam Gupta and Sahil Singla. Random-Order Models, page 234\u2013258. Cambridge University Press, 2021.   \n[30] Alex Hern. Artificial intelligence beauty contest doesn\u2019t like black people. The Guardian, September 8 2016. URL https://www.theguardian.com/technology/2016/sep/08/ artificial-intelligence-beauty-contest-doesnt-like-black-people.   \n[31] A Howard and J Borenstein. The ugly truth about ourselves and our robot creations: The problem of bias and social inequity. Science and Engineering Ethics, 24(5):1521\u20131536, October 2018.   \n[32] Matthew Joseph, Michael Kearns, Jamie H Morgenstern, and Aaron Roth. Fairness in learning: Classic and contextual bandits. In Proceedings of the 29th Annual Conference on Neural Information Processing Systems (NeurIPS), 2016. URL https://proceedings.neurips.cc/ paper_files/paper/2016/file/eb163727917cbba1eea208541a643e74-Paper.pdf.   \n[33] Toshihiro Kamishima, Shotaro Akaho, and Jun Sakuma. Fairness-aware learning through regularization approach. In Proceedings of the 11thInternational Conference on Data Mining Workshops (ICDMW), pages 643\u2013650, 2011.   \n[34] Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. Fairness-aware classifier with prejudice remover regularizer. In Peter A. Flach, Tijl De Bie, and Nello Cristianini, editors, Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), volume 7524, 2012.   \n[35] Haim Kaplan, David Naori, and Danny Raz. Competitive analysis with a sample and the secretary problem. In Proceedings of the 31st Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 2082\u20132095, 2020.   \n[36] Amir E. Khandani, Adlar J. Kim, and Andrew W. Lo. Consumer credit-risk models via machine-learning algorithms. Journal of Banking & Finance, 34(11):2767\u20132787, 2010. URL https://www.sciencedirect.com/science/article/pii/S0378426610002372.   \n[37] Jon Kleinberg and Manish Raghavan. Inherent trade-offs in the fair determination of risk scores. In Proceedings of the 8th Innovations in Theoretical Computer Science Conference (ITCS), 2017.   \n[38] Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. Human Decisions and Machine Predictions. The Quarterly Journal of Economics, 133(1): 237\u2013293, 2017. URL https://doi.org/10.1093/qje/qjx032.   \n[39] Robert D. Kleinberg. A multiple-choice secretary algorithm with applications to online auctions. In Proceedings of the 16th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 630\u2013631, 2005.   \n[40] Anja Lambrecht and Catherine Tucker. Algorithmic bias? an empirical study of apparent gender-based discrimination in the display of stem career ads. Management Science, 65(7): 2966\u20132981, 2019.   \n[41] Alexander Lindermayr and Nicole Megow. Algorithms with predictions. https:// algorithms-with-predictions.github.io/, 2024.   \n[42] D. V. Lindley. Dynamic programming and decision theory. Journal of the Royal Statistical Society: Series C (Applied Statistics), 10(1):39\u201351, 1961.   \n[43] Binh Thanh Luong, Salvatore Ruggieri, and Franco Turini. k-nn as an implementation of situation testing for discrimination discovery and prevention. In Proceedings of the 17th International Conference on Knowledge Discovery and Data Mining (KDD), page 502\u2013510, 2011. doi: 10.1145/2020408.2020488. URL https://doi.org/10.1145/2020408.2020488.   \n[44] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice. In Proceedings of the 35th International Conference on Machine Learning (ICML), pages 3302\u20133311, 2018. URL http://proceedings.mlr.press/v80/lykouris18a.html.   \n[45] Rashmi Malhotra and D. K. Malhotra. Evaluating consumer loans using neural networks. Omega, 31(2):83\u201396, 2003. URL https://EconPapers.repec.org/RePEc:eee:jomega: v:31:y:2003:i:2:p:83-96.   \n[46] Amitabha Mukerjee, Rita Biswas, Kalyanmoy Deb, and Amrit P. Mathur. Multi\u2013objective evolutionary algorithms for the risk\u2013return trade\u2013off in bank loan management. International Transactions in Operational Research, 9(5):583\u2013597, 2002. URL https://onlinelibrary. wiley.com/doi/abs/10.1111/1475-3995.00375.   \n[47] David B. Mustard. Reexamining criminal behavior: The importance of omitted variable bias. The Review of Economics and Statistics, 85(1):205\u2013211, 2003.   \n[48] Jad Salem and Swati Gupta. Secretary problems with biased evaluations using partial ordinal information. Management Science. URL https://doi.org/10.1287/mnsc.2023.4926.   \n[49] Ke Yang and Julia Stoyanovich. Measuring fairness in ranked outputs. In Proceedings of the 29thInternational Conference on Scientific and Statistical Database Management (SSDBM), SSDBM \u201917, 2017. URL https://doi.org/10.1145/3085504.3085526. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Additional discussion and missing analysis for single secretary ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Unfair outcomes in previous work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section we present the learning-augmented algorithms of [2] and [25], and argue that they fail to satisfy simultaneously the smoothness and fairness desiderata described in section 2. We follow the same notation as in the main paper where the $i^{*},{\\widehat{\\iota}}$ denote the index of the candidate with maximum true and predicted value respectively. Since the algorithm in [2] requires only the prediction about the maximum value but not the identity of that candidate, we use the symbol $\\boldsymbol{\\hat{u}}^{*}$ to denote such value. ", "page_idx": 13}, {"type": "table", "img_path": "dxxj4S06YL/tmp/ac6899cf9f8121e4d047c1e8e9b35d2bd4529c4abaffa915b298427e9902d073.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "LEARNED-DYNKIN of Fujii and Yoshida [25] receives a predicted valuation for all candidates and defines the prediction error of candidate $i$ as $|1-\\hat{u}_{i}/u_{i}|$ . If the prediction error of a candidate is higher than $\\theta$ then it switches to Secretary mode where it mimics the classical DYNKIN algorithm where all candidates are rejected for a constant fraction of the stream and after that rejection phase the first candidate whose valuation is the maximum overall is hired. Note that if all candidates have very low prediction error then LEARNED-DYNKIN remains in the Prediction mode and the candidate with the higher prediction is hired. One instance where LEARNED-DYNKIN never accepts candidate $i^{*}$ is the following: the true valuations are $\\left\\{1\\,+\\,\\theta^{\\prime},1,u_{3},\\ldots,u_{n}\\right\\}$ and the predicted valuations are $\\{1+\\theta^{\\prime},1/(1\\stackrel{\\cdot}{-}\\theta^{\\prime}),u_{3}/(1-\\theta^{\\prime}),\\ldots,u_{n}/(1-\\theta^{\\prime})\\}$ where $\\theta^{\\prime}<\\theta=0.646$ and $u_{3},\\ldots,u_{n}$ are pairwise distinct numbers in $(0,1)$ . Note that $1/(1-\\theta^{\\prime})>1+\\theta^{\\prime}$ and the prediction error is as most $\\bar{\\theta}^{\\prime}<\\theta=0.616$ for all candidates. Thus, LEARNED-DYNKIN does not switch to Prediction mode, it never accepts the candidate with valuation $1+\\theta^{\\prime}$ and does not satisfy our Fairness desideratum. ", "page_idx": 13}, {"type": "text", "text": "VALUE-MAXIMIZATION SECRETARY of [2] receives only one prediction regarding the maximum value $\\boldsymbol{\\hat{u}}^{*}$ and the prediction error is defined as $\\varepsilon\\;=\\;|u_{i^{*}}\\;-\\;\\hat{u}^{*}|$ . The latter algorithm is parametrized by $\\lambda\\geq0$ and $c\\geq1$ which control the relationship between the robustness and smoothness bounds. VALUE-MAXIMIZATION SECRETARY has three distinct phases defined by the time ranges $[0,t^{*}],(t^{*},t^{**})$ and $[t^{**},1]$ respectively, where $t^{*}$ , $t^{**}$ are defined using the Lambert functions $W^{=1}$ and $W^{\\bar{0}}$ . The first phase is used as an \u201cexploration\u201d phase where all candidates are rejected and at the end of the phase a threshold $\\tau_{I}$ is computed. ", "page_idx": 13}, {"type": "text", "text": "Let $\\boldsymbol{\\mathcal{A}}$ be the random variable denoting the candidate which is accepted by VALUE-MAXIMIZATION SECRETARY . For any $\\varepsilon\\in(0,1)$ we define an instance with predicted maximum value $\\hat{u}^{*}=1\\!-\\!\\varepsilon$ and true values $\\{u_{1},u_{2},\\ldots,u_{n}\\}$ where all numbers are distinct, $u_{1}=1$ and $u_{i}\\in[0,\\varepsilon]$ , $\\forall i\\in\\{2,\\ldots,n\\}$ The prediction error of that instance is $\\varepsilon$ . Note that if $i^{*}=1$ arrives in the first phase then the maximum value of a candidate that VALUE-MAXIMIZATION SECRETARY can accept in the second and third phases is at most $\\varepsilon$ . Thus, we can upper bound the expected value of candidate $\\boldsymbol{\\mathcal{A}}$ as follows: $\\mathbf{E}[u_{A}]\\leq\\stackrel{\\cdot}{P}[t_{i^{*}}\\geq t^{*}]\\cdot u_{i^{*}}+P[t_{i^{*}}<t^{*}]\\cdot\\bar{\\varepsilon}=(1-t^{*})u_{i^{*}}+\\bar{t}^{*}\\varepsilon.$ . ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "We emphasize that in the learning-augmented setting, there is no assumption regarding the quality of the prediction, thus the parameters $c$ and $\\lambda$ cannot depend on the prediction error. For any setting with $c>1$ we have that $t^{*}>0$ is a constant that is bounded away from 0. Towards a contradiction, assume that VALUE-MAXIMIZATION SECRETARY satisfies the smoothness desideratum described in section 2 for some parameter $C$ . Then, we have that $\\mathbf{E}[u_{\\mathcal{A}}]\\,\\ge\\,(1-C\\cdot\\varepsilon)u_{i^{*}}$ . Consequently, $\\begin{array}{r}{(1-t^{*})u_{i^{*}}+t^{*}\\,\\varepsilon\\geq(1-C\\cdot\\varepsilon)u_{i^{*}}\\xrightarrow{u_{i^{*}}=1}(1-t^{*})+t^{*}\\,\\varepsilon\\geq(1-C\\cdot\\varepsilon)\\,.}\\end{array}$ which leads to contradiction when we let $\\varepsilon\\rightarrow0$ . ", "page_idx": 14}, {"type": "text", "text": "A.2 The PEGGING algorithm ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this subsection we generalize the ADDITIVE-PEGGING algorithm so as to provide fair and smooth algorithms for different prediction error definitions. We use the direct sum symbol $\\bigoplus$ to abstractly denote an operation, e.g., addition or multiplication, and $\\circleddash$ for its inverse operation, i.e., subtraction or division. To model the \u201cdifference\u201d between predictions and true values we use two functions $d^{+}:\\mathfrak{R}_{\\geq0}\\times\\mathfrak{R}_{\\geq0}\\rightarrow\\mathfrak{R}$ and $d^{-}:\\mathfrak{R}_{\\geq0}\\times\\mathfrak{R}_{\\geq0}\\stackrel{}{\\rightarrow}\\mathfrak{R}$ . The natural properties that we require from $d^{+},d^{-}$ with respect to operations $\\bigoplus$ and $\\ominus$ are described in assumption 6. We write $d_{i}^{+}=d^{+}(u_{i},\\hat{u}_{i})$ , $d_{i}^{-}=d^{-}\\big(u_{i},\\hat{u}_{i}\\big)$ and define two prediction errors as follows: $\\varepsilon^{+}=\\operatorname*{max}_{i}{d_{i}^{+}}$ and $\\varepsilon^{-}=\\operatorname*{min}_{i}d_{i}^{-}$ . While the notation is left abstract to highlight the generality of theorem 7, we provide examples on how to instantiate those functions and operators for natural prediction errors as the absolute difference that we used in ADDITIVE-PEGGING and a multiplicative prediction error function that it is used by Fujii and Yoshida [25]. ", "page_idx": 14}, {"type": "text", "text": "The only properties that we require from those functions with respect to operations $\\bigoplus$ and $\\circleddash$ are described by assumption 6. ", "page_idx": 14}, {"type": "text", "text": "Assumption 6. For all $u,\\hat{u},v,\\hat{v},x,y\\in\\mathfrak{R}_{\\ge0}$ ", "text_level": 1, "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{u\\oplus d^{+}(u,\\hat{u})\\geq\\hat{u}\\geq u\\oplus d^{-}(u,\\hat{u})}\\\\ &{}&{d^{+}(u,\\hat{u})\\geq d^{+}(v,\\hat{v})\\Leftrightarrow d^{-}(u,\\hat{u})\\leq d^{-}(v,\\hat{v})}\\\\ &{}&{x\\oplus d^{-}(u,\\hat{u})\\geq y\\Leftrightarrow x\\geq y\\ominus d^{-}(u,\\hat{u})\\ a n d\\ x\\oplus d^{+}(u,\\hat{u})\\geq y\\Leftrightarrow x\\geq y\\ominus d^{+}(u,\\hat{u})}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The first property permits us to upper and lower bound the prediction of a candidate with respect to its true value, the second property relates the functions $d^{+}$ and $d^{-}$ and the last two properties permit us to manipulate inequalities between true and predicted valuations. ", "page_idx": 14}, {"type": "text", "text": "Using the new abstract notation we describe how one can generalize ADDITIVE-PEGGING to PEGGING by only changing the conditions of subcases 2a, $2b$ and $_{4b}$ . In subcase 2a and $_{2b}$ we do not have a strong indication that $\\hat{\\boldsymbol{\\imath}}$ is the true highest value candidate. Thus we \u201cpeg\u201d a future candidate only if it is possible to maintain smoothness, or equivalently, if there is a future candidate whose predicted value is higher than $u_{i^{*}}$ scaled down by the prediction error. Thus, we change the condition of subcase $2a$ to $u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{-}>\\operatorname*{max}_{j\\succ i}\\hat{u}_{j}$ and subcase $_{2b}$ in the same manner. In subcase $^{4b}$ , we have a strong indication of $i\\neq\\hat{\\imath}$ being the true highest value candidate and we accept if $u_{i}$ scaled up by the prediction error is higher than $\\hat{u}_{\\hat{\\imath}}$ . Using our abstract notation this is equivalent to checking if $u_{i}\\dot{\\oplus}d_{i}^{+}>\\hat{u}_{\\hat{\\imath}}$ . ", "page_idx": 14}, {"type": "table", "img_path": "dxxj4S06YL/tmp/a609c495413982ba110c49858bc13d01ed1643103ec88b9db3ba94dc0f225198.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Note: $\\operatorname*{max}_{\\succ}\\{j:u_{\\hat{\\imath}}\\oplus d_{i}^{-}\\,<\\,\\hat{u}_{j}\\}$ denotes the last candidate $j$ arriving and having its prediction lower bounded by $u_{\\hat{\\imath}}\\oplus d_{i}^{-}$ . We cannot assign $i^{p e g g e d}$ at time $t_{\\hat{\\imath}}$ since we do not know when the last candidate with this property will arrive. We abuse notation $\\leftarrow$ to say that as long as there is a future candidate with that property, we update $i^{p e g g e d}$ . We assume that every time a candidate arrives at most one case and one subcase is executed and the algorithm terminates whenever we execute a $A\\gets i$ command, i.e., a candidate is accepted. ", "page_idx": 15}, {"type": "text", "text": "We proceed stating and proving Theorem 3. ", "page_idx": 15}, {"type": "text", "text": "Theorem 7. PEGGING accepts the maximum value candidate with probability at least $\\textstyle{\\frac{1}{16}}$ and its expected value is at least $\\operatorname*{max}\\{u_{i^{*}}\\oplus\\varepsilon^{-}\\oplus\\varepsilon^{-}\\ominus\\varepsilon^{+}\\ominus\\varepsilon^{+},{\\textstyle\\frac{1}{16}}u_{i^{*}}\\}$ ", "page_idx": 15}, {"type": "text", "text": "Proof. We first lower bound $\\hat{u}_{\\hat{\\imath}}$ using the right-hand side of (1) from assumption 6 and the fact that $\\hat{\\boldsymbol{\\imath}}$ is the candidate with the maximum predicted valuation: $\\hat{u}_{\\hat{\\imath}}\\geq\\hat{u}_{i^{\\ast}}\\geq u_{i^{\\ast}}\\oplus d_{i^{\\ast}}^{-}$ . ", "page_idx": 15}, {"type": "text", "text": "We also lower bound $u_{\\hat{\\imath}}$ as follows: from the left-hand side of (1) from assumption 6 we get that $u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{+}\\geq{\\hat{u}}_{\\hat{\\imath}}\\Rightarrow u_{\\hat{\\imath}}\\geq{\\hat{u}}_{\\hat{\\imath}}\\ominus d_{\\hat{\\imath}}^{+}$ . Thus, also using the lower bound $\\hat{u}_{\\hat{\\imath}}\\geq u_{i^{*}}\\oplus d_{i^{*}}^{-}$ we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{u_{\\hat{\\imath}}\\geq\\hat{u}_{\\hat{\\imath}}\\ominus d_{\\hat{\\imath}}^{+}}}\\\\ {{\\geq u_{i^{*}}\\oplus d_{i^{*}}^{-}\\ominus d_{\\hat{\\imath}}^{+}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In subcase $2a$ and case $^3$ candidate $\\hat{\\boldsymbol{\\imath}}$ is accepted and in subcase 4a a candidate $i$ with $u_{i}\\geq u_{\\hat{\\imath}}$ is accepted. Consequently, all these cases accept a candidate with value at least $u_{\\hat{\\imath}}\\geq u_{i^{\\ast}}\\oplus d_{i^{\\ast}}^{-}\\ominus d_{\\hat{\\imath}}^{+}$ . ", "page_idx": 15}, {"type": "text", "text": "If $i$ is accepted by subcase $^{4b}$ we get that $u_{i}\\oplus d_{i}^{+}>\\hat{u}_{\\hat{\\imath}}\\Rightarrow u_{i}>\\hat{u}_{\\hat{\\imath}}\\ominus d_{i}^{+}$ and again using that $\\hat{u}_{\\hat{\\imath}}\\geq u_{i^{*}}\\oplus d_{i^{*}}^{-}$ we have $u_{i}>u_{i^{*}}\\oplus d_{i^{*}}^{-}\\ominus d_{i}^{+}$ . ", "page_idx": 15}, {"type": "text", "text": "Finally, we need to lower bound the value of a pegged candidate in case our algorithm terminates accepting $i^{p e g g e d}$ . Note that from the way a pegged candidate is defined in subcase $_{2b}$ , we always have $u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{-}\\,<\\,\\hat{u}_{i^{\\mathrm{pegged}}}$ and again using the left-hand side of (1) from assumption 6 we have that $\\begin{array}{r}{\\hat{u}_{i^{\\mathrm{peged}}}\\leq u_{i^{\\mathrm{peged}}}\\oplus d_{i^{\\mathrm{peged}}}^{+}\\Rightarrow u_{i^{\\mathrm{peged}}}\\geq\\hat{u}_{i^{\\mathrm{peged}}}\\ominus d_{i^{\\mathrm{peged}}}^{+}}\\end{array}$ . Thus, we get that $u_{i^{\\mathrm{pegged}}}>u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{-}\\ominus d_{i^{\\mathrm{pegged}}}^{+}$ and using the lower bound on $u_{\\hat{\\imath}}$ we conclude that $u_{i^{\\mathrm{pegged}}}>u_{i^{*}}\\oplus d_{i^{*}}^{-}\\ominus d_{\\hat{\\imath}}^{+}\\oplus d_{\\hat{\\imath}}^{-}\\ominus d_{i^{\\mathrm{peged}}}^{+}\\;.$ ", "page_idx": 15}, {"type": "text", "text": "Combining all the lower bounds on the valuation of the accepted candidate deduce the first part of the lower bound. ", "page_idx": 15}, {"type": "text", "text": "We proceed proving fairness and, consequently robustness. We denote by $\\tilde{\\imath}$ the index of the candidate with the highest true valuation except possibly $i^{*}$ and $\\hat{\\boldsymbol{\\imath}}$ , i.e., $\\tilde{\\iota}=\\mathrm{argmax}_{i\\neq i^{*},\\hat{\\iota}_{i}}u_{i}$ . Note that if $i^{*}=\\widehat{\\iota}$ then $\\tilde{\\imath}$ denotes the index of the candidate with the second highest true valuation. To prove fairness we distinguish between two cases: either $\\hat{\\boldsymbol{\\imath}}=\\boldsymbol{i}^{*}$ or ${\\hat{\\imath}}\\neq i^{*}$ . For each of those cases, we define an event and argue that: (1) the event happens with constant probability; and (2) if that event happens then Algorithm 5 accepts $i^{*}$ . ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "If $i^{*}=\\widehat{\\iota}$ we define event $C=\\{t_{\\tilde{\\imath}}<1/2<t_{i^{*}}\\}$ for which $P[C]=1/4$ . $C$ implies that our algorithm does not accept any candidate until time $t_{i^{*}}$ . Indeed note that the conditions of case $I,2$ , and 3 all happen after the arrival of $\\hat{\\boldsymbol{\\imath}}$ which is $t_{i^{*}}$ . In addition to that after time $1/2$ the threshold $\\tau=u_{\\tilde{\\tau}}$ is larger than any valuation other than $u_{i^{*}}$ and consequently the conditions of case $^{4}$ are not met before $t_{i^{*}}$ . At time $t_{i^{*}}$ all conditions of case $^{4}$ and subcase $_{4a}$ are met and our algorithm hires $i^{*}$ . ", "page_idx": 16}, {"type": "text", "text": "If $i^{*}\\neq\\hat{\\imath}$ we further distinguish between two cases. To that end, note that $\\{u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{-}<\\hat{u}_{i^{*}}\\}\\vee\\{d_{i^{*}}^{+}\\oplus$ $u_{i^{*}}>\\hat{u}_{\\hat{i}}\\}$ is always true. Indeed if $\\{u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{-}>\\hat{u}_{i^{*}}\\}$ we have that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u_{i}\\oplus d_{i}^{-}>\\hat{u}_{i^{*}}}\\\\ &{\\begin{array}{r l}{u_{i}\\oplus d_{i}^{-}>u_{i^{*}}\\oplus d_{i^{*}}^{-}}\\\\ {d_{i}^{-}\\odot d_{i^{*}}^{-}>u_{i^{*}}\\odot u_{i}}\\end{array}}\\\\ &{d_{i}^{-}\\odot d_{i^{*}}^{-}>0}\\\\ &{\\begin{array}{r l}&{d_{i}^{-}>d_{i^{*}}^{-}}\\\\ &{d_{i}^{+}<d_{i^{*}}^{+}}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where 0 is the neutral element associated with operation $\\bigoplus$ , from the first to the second line we used the right-hand side of (1) from assumption 6, from the third to the fourth line we used that $u_{i^{*}}\\geq u_{\\hat{\\imath}}$ by the definition of $i^{*}$ and from the fifth to the sixth line we used (2) of assumption 6. Consequently: ", "page_idx": 16}, {"type": "equation", "text": "$$\nd_{i^{*}}^{+}\\oplus u_{i^{*}}>d_{\\hat{\\imath}}^{+}\\oplus u_{i^{*}}\\geq d_{\\hat{\\imath}}^{+}\\oplus u_{\\hat{\\imath}}\\geq\\hat{u}_{\\hat{\\imath}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where we again used that $u_{i^{*}}~\\geq u_{\\hat{\\imath}}$ and in the last inequality we used the right-hand side of (1) from assumption 6. ", "page_idx": 16}, {"type": "text", "text": "Thus, we define two events $C_{1}$ and $C_{2}$ which imply that $i^{*}$ is always accepted whenever $\\{u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{-}<$ $\\hat{u}_{i^{*}}\\}$ and $\\{d_{i^{*}}^{+}\\oplus u_{i^{*}}>\\hat{u}_{\\hat{\\imath}}\\}$ are true respectively. ", "page_idx": 16}, {"type": "text", "text": "If $\\{u_{\\hat{\\imath}}\\oplus d_{\\hat{\\imath}}^{-}<\\hat{u}_{i^{*}}\\}$ is true then we define event $C_{1}=\\{t_{\\tilde{\\imath}}<1/2\\}\\wedge\\{t_{\\hat{\\imath}}<1/2\\}\\wedge\\{1/2<t_{i^{*}}\\}$ which is composed by 3 independent events and it happens with probability $P[C_{1}]=1/2^{3}=1/8$ . $C_{1}$ implies that at time $t_{i^{*}}$ the conditions of subcase ${\\mathfrak{s a}}$ are satisfied. Consequently, if until time $t_{i^{*}}$ all candidates are rejected then candidate $i^{*}$ is hired using either case $^{\\,l}$ or subcase 4a. To argue that no candidate is hired before time $t_{i^{*}}$ note that at time $t_{\\hat{\\imath}}$ the set max\u227b $\\{j:u_{\\hat{\\imath}}<\\hat{u}_{j}+\\epsilon_{\\hat{\\imath}}\\}$ contains $i^{*}$ and that after time $1/2$ the condition $\\tau>u_{i}$ is not met until time $t_{i^{*}}$ . ", "page_idx": 16}, {"type": "text", "text": "If $\\{d_{i^{*}}^{+}\\oplus u_{i^{*}}\\;>\\;\\hat{u}_{\\hat{\\imath}}\\}$ is true then we define $C_{2}\\,=\\,\\{t_{\\widetilde{\\imath}}\\,<\\,1/2\\,<\\,t_{i^{*}}\\,<\\,t_{\\widehat{\\imath}}\\}$ which happens with probability ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P[C_{2}]=P[t_{\\tilde{\\imath}}<1/2]\\cdot P[1/2<t_{i^{*}}<t_{\\hat{\\imath}}]=}\\\\ &{\\qquad\\quad=P[t_{\\tilde{\\imath}}<1/2]\\cdot P[1/2<\\operatorname*{min}\\{t_{i^{*}},t_{\\hat{\\imath}}\\}\\wedge\\operatorname*{min}\\{t_{i^{*}},t_{\\hat{\\imath}}\\}=t_{i^{*}}]=}\\\\ &{\\qquad\\quad=P[t_{\\tilde{\\imath}}<1/2]\\cdot P[1/2<\\operatorname*{min}\\{t_{i^{*}},t_{\\hat{\\imath}}\\}]\\cdot P[\\operatorname*{min}\\{t_{i^{*}},t_{\\hat{\\imath}}\\}=t_{i^{*}}]=}\\\\ &{\\qquad\\quad=(1/2)\\cdot(1/4)\\cdot(1/2)=}\\\\ &{\\qquad\\quad=1/16}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Note that until time $t_{i^{*}}$ no candidate is accepted since the conditions of all cases are not satisfied. Indeed, between times 0 and $1/2$ only $\\hat{\\boldsymbol{\\imath}}$ could have been accepted but its arrival time is after $t_{i^{*}}$ , and between times $1/2$ and $t_{i^{*}}$ the threshold $\\tau$ is equal to $u_{\\tilde{\\imath}}$ and no candidate meets the condition of case $^{4}$ to have $u_{i}>\\tau$ . Finally, note that at time $t_{i^{*}}$ the conditions of case $^{4b}$ are satisfied and $i^{*}$ gets accepted. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Note that by instantiating $\\oplus,\\ominus$ to the usual scalar addition and subtraction and $d^{+}(u,\\hat{u})=|u-\\hat{u}|$ , $d^{-}(u,\\hat{u})\\,=\\,-|u-\\hat{u}|$ we get that $d_{i}^{+}=\\,\\epsilon_{i}$ , $d_{i}^{-}\\,=\\,-\\epsilon_{i}$ . Consequently, $\\varepsilon^{+}\\,=\\,\\operatorname*{max}_{i}\\epsilon_{i}$ and $\\varepsilon^{-}=$ $-\\operatorname*{max}_{i}\\epsilon_{i}$ . Substituting $\\varepsilon^{+}$ and $\\varepsilon^{-}$ to the guarantees of theorem 7 we recover theorem 3. ", "page_idx": 16}, {"type": "text", "text": "Moreover, in theorem 4, we further demonstrate the generality of PEGGING by instantiating $\\Phi,\\Theta,d^{+},d^{-}$ and recovering similar smoothness and robustness bounds as [25] while also ensuring fairness. Fujii and Yoshida [25] define the prediction error as $\\varepsilon\\ =\\ \\operatorname*{max}_{i}|1-\\hat{u}_{i}/u_{i}|$ and design an algorithm which accepts a candidate $i$ whose expected value is at least $u_{i^{*}}$ max $\\bar{\\{(1-\\varepsilon)/(\\bar{1}+\\varepsilon),0.215\\}}$ . Since $(1\\,-\\,\\varepsilon)/(1\\,+\\,\\varepsilon)\\;\\geq\\;1\\,-\\,2\\,\\varepsilon$ the latter algorithm satisfies the Smoothness desideratum of section 2, but, as we prove in appendix A.1 it violates the Fairness desideratum. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "To that end, let MULTIPLICATIVE-PEGGING be the instantiation of PEGGING when $\\oplus,\\ominus$ denote the classical multiplication and division operations, $d^{+}(u,\\hat{u})\\,=\\,1+|1-\\hat{u}/u|$ and $d^{-}(u,\\hat{u})\\,=$ max $\\left\\{1-\\left|1-\\hat{u}/u\\right|,0\\right\\}$ . ", "page_idx": 17}, {"type": "text", "text": "Theorem 4. If $\\varepsilon(\\mathcal{Z})=\\operatorname*{max}_{i}|1-\\hat{u}_{i}/u_{i}|$ , then MULTIPLICATIVE-PEGGING satisfies smoothness and fairness with $C=4$ and $F=1/16$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. Functions $d^{+},d^{-}$ satisfy the properties of assumption 6. Note that $\\varepsilon^{+}=1+\\varepsilon$ and $\\varepsilon^{-}=$ max $\\{1-\\varepsilon,0\\}$ . Consequently, using theorem 7 MULTIPLICATIVE-PEGGING accepts a candidate whose expected value is at least $u_{i^{*}}$ max $\\begin{array}{r}{\\bigl\\{(1-\\varepsilon)^{2}/(1+\\varepsilon)^{2},1/16\\bigr\\}\\,\\geq\\,u_{i^{*}}\\operatorname*{max}\\,\\{1-4\\,\\varepsilon,1/16\\},}\\end{array}$ where we used the inequalities $1/(1+\\varepsilon)\\geq(1-\\varepsilon)$ and $(1-\\varepsilon)^{4}\\geq1-4\\,\\varepsilon$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "B Missing analysis for the $\\mathbf{k}$ -secretary pegging algorithm ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In Lemma 8 and Corollary 9 we prove that K-PEGGING satisfies the smoothness desideratum. ", "page_idx": 17}, {"type": "text", "text": "Lemma 8. $\\begin{array}{r}{\\sum_{j\\in S}u_{j}\\geq\\sum_{i=1}^{k}u_{r_{i}}-4k\\,\\varepsilon(\\mathbb{Z})}\\end{array}$ , $\\forall\\mathcal{T}$ with probability 1. ", "page_idx": 17}, {"type": "text", "text": "Proof. Similarly to the single choice secretary problem we proceed in two steps, first we prove that: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k]}u_{r_{i}}-\\sum_{i\\in[k]}u_{i}\\leq2k\\,\\varepsilon\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and then we prove that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k]}u_{i}-\\sum_{j\\in S}u_{j}\\leq2k\\,\\varepsilon\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that combining those two inequalities is enough to prove the current lemma. ", "page_idx": 17}, {"type": "text", "text": "The first inequality is proven as follows: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}u_{r_{i}}\\le_{(1)}\\sum_{i=1}^{k}(\\hat{u}_{r_{i}}+\\varepsilon)\\le_{(2)}k\\varepsilon+\\sum_{i=1}^{k}\\hat{u}_{i}\\le_{(3)}k\\varepsilon+\\sum_{i=1}^{k}(u_{i}+\\varepsilon)=2k\\varepsilon+\\sum_{i=1}^{k}u_{i}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where (1) and (3) are by definition of $\\varepsilon$ and (2) since $\\hat{u}_{i}$ is $i^{t h}$ largest predicted value. ", "page_idx": 17}, {"type": "text", "text": "We proceed to argue that: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k]}u_{i}-\\sum_{j\\in S}u_{j}\\leq2k\\,\\varepsilon\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We now define an injective function $m:[k]\\rightarrow S$ for which we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\nu_{i}-u_{m(i)}\\leq2\\,\\varepsilon,\\;\\forall i\\in[k]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that the existence of such a function implies the desired $\\begin{array}{r}{\\sum_{i\\in[k]}u_{i}-\\sum_{j\\in H}u_{j}\\,\\le2k\\,\\varepsilon}\\end{array}$ inequality. ", "page_idx": 17}, {"type": "text", "text": "Note that each candidate $j^{\\prime}\\in[k]$ is initially added to $H$ . During the execution of our algorithm candidate $j^{\\prime}$ may be either (1) deleted from $H$ without being added to $B$ or (2) added to $B$ . ", "page_idx": 17}, {"type": "text", "text": "In the first case, $j^{\\prime}$ is deleted from $H$ without being added to $B$ , which occurs either in case $2a,3$ , or $4b$ of the algorithm. Let $i$ be the current candidate at the time $t_{i}$ where the latter happens. If case $2a$ or 3 happens then $j^{\\prime}=i$ , we define $m(j^{\\prime})=j^{\\prime}$ and $u_{j^{\\prime}}-u_{m(j^{\\prime})}=0\\leq2\\,\\varepsilon.$ . If case $^{4b}$ happens then we have that at that time $t_{i}$ : $j^{\\prime}\\in\\{j\\in H:u_{i}>\\hat{u}_{j}-\\varepsilon_{t_{i}}\\}$ and we define $m(i)=j^{\\prime}$ . Consequently, we conclude that $u_{i}-u_{m(i)}=u_{i}-u_{j^{\\prime}}\\leq u_{i}-\\hat{u}_{j^{\\prime}}+\\varepsilon_{t_{j^{\\prime}}}\\leq\\varepsilon_{i}+\\varepsilon_{t_{j^{\\prime}}}\\leq2\\,\\varepsilon$ . ", "page_idx": 17}, {"type": "text", "text": "We now consider the cases where $j^{\\prime}$ is added to $B$ during the execution of our algorithm. Note that for that to happen $j$ must be added to $B$ at time $t_{j}$ via case $2b$ . In that case, candidate $p e g({j^{\\prime}})$ ", "page_idx": 17}, {"type": "text", "text": "either remains in $P$ until time $t_{p e g(j^{\\prime})}$ and it is added to $S$ at that time or it is deleted from $P$ earlier. In both cases $j^{\\prime}$ is removed from $B$ at the respective time. Thus, we conclude that $j^{\\prime}$ gets deleted from $B$ at time $t_{p e g(j^{\\prime})}$ or before. If the deletion happens at time $t_{p e g(j)}$ then it must happen through case $^{\\,l}$ , we define $\\ddot{m}(j^{\\prime})\\,=\\,p e g(j^{\\prime})$ and we have that $u_{j^{\\prime}}\\,-\\,u_{m(j^{\\prime})}\\,=\\,u_{j^{\\prime}}\\,-\\,u_{p e g(j^{\\prime})}\\,\\le$ $\\hat{u}_{p e g(j^{\\prime})}+{\\varepsilon}_{t_{j^{\\prime}}}-u_{p e g(j^{\\prime})}=\\big(\\hat{u}_{p e g(j^{\\prime})}-u_{p e g(j^{\\prime})}\\big)+{\\varepsilon}_{t_{j^{\\prime}}}\\leq{\\varepsilon}_{p e g(j^{\\prime})}+{\\varepsilon}_{t_{j^{\\prime}}}\\leq2{\\varepsilon}_{t_{j^{\\prime}}}$ , where in the first inequality we used that $\\hat{u}_{p e g(j^{\\prime})}\\,>\\,u_{j^{\\prime}}-\\varepsilon_{t_{j^{\\prime}}}$ since $p e g(j^{\\prime})$ was pegged by $j^{\\prime}$ at time $t_{j^{\\prime}}$ . If $j^{\\prime}$ is deleted from $B$ before time $t_{p e g(j^{\\prime})}$ it must happen via subcase $_{4a}$ due to the arrival of a candidate $l$ that is added to $S$ . In that case we define $m(j^{\\prime})=l$ and from the condition of subcase 4a we have that $j\\in E$ at time $t_{j^{\\prime}}$ we have that $u_{j^{\\prime}}-u_{m(j^{\\prime})}=u_{j^{\\prime}}-u_{l}<0\\leq2\\,\\varepsilon$ . \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Corollary 9. If $u_{r_{i}}\\geq1\\;\\forall i\\in\\{1,...,k\\}$ then: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{j\\in S}u_{j}\\geq\\sum_{i=1}^{k}u_{r_{i}}(1-4\\,\\varepsilon(\\mathcal{Z}))\\ ,\\forall\\mathcal{Z}\\,w i t h\\,p r o b a b i l i t y\\ 1.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. The proof follows from lemma 8 and noting that $u_{r_{i}}\\geq1$ implies that $\\textstyle\\sum_{i=1}^{k}u_{r_{i}}\\geq k$ and consequently $\\begin{array}{r}{\\sum_{i=1}^{k}u_{r_{i}}-4k\\,\\varepsilon(\\mathcal{T})\\geq\\sum_{i=1}^{k}u_{r_{i}}(1-4\\,\\varepsilon(\\mathcal{T}))}\\end{array}$ . \u53e3 ", "page_idx": 18}, {"type": "text", "text": "We now move to prove the fairness desideratum. ", "page_idx": 18}, {"type": "text", "text": "Lemma 10. For all $i\\in[k]\\colon P[r_{i}\\in S]\\geq(1/3)^{k+5}$ ", "page_idx": 18}, {"type": "text", "text": "Proof. We start arguing that if $r_{i}\\ \\in\\ [k]$ , i.e., if candidate $r_{i}$ is among the $k$ -highest prediction candidates, then $\\bar{P[r_{i}\\in S]}\\,\\geq\\,1/4$ . We define event $\\mathcal{C}\\,=\\,\\{t_{r_{i}}\\,<\\,1/2\\}\\land\\{C_{r_{i}}\\,\\stackrel{.}{=}\\,0\\}$ for which $P[\\mathcal{C}]\\;=\\;P[t_{r_{i}}<1/2]\\cdot P[C_{r_{i}}=0]\\;=\\;(1/2)\\cdot(\\$ 1/2) = 1/4 Note that at time 0 we have that $r_{i}\\in H$ . During the execution of Algorithm 2 from time 0 to time $t_{r_{i}}$ , candidate $r_{i}$ may be removed from $H$ without being added from $S$ only if $t_{r_{i}}~\\geq~1/2$ . Consequently, $\\mathcal{C}$ implies that at time $t_{r_{i}}<1/2$ the conditions of case 2 and subcase $2a$ are true and candidate $r_{i}$ is added to $S$ . Thus, $\\dot{P[r_{i}\\in\\dot{S}]}\\geq P[\\mathcal{C}]=1/4$ . ", "page_idx": 18}, {"type": "text", "text": "In the rest of the proof, we focus on the case where $r_{i}\\notin[k]$ . Note that since $i\\in[k]$ and $r_{i}\\notin[k]$ then $\\exists j\\in[k]$ such that $u_{r_{i}}\\,\\geq\\,u_{r_{k}}\\,>\\,u_{j}$ , i.e., $j$ has a true value which is not among the $k$ -highest true values. We now argue that $\\{u_{j}<\\tilde{u_{r_{i}}}+\\varepsilon_{j}\\}\\vee\\{u_{r_{i}}>\\hat{u}_{j}-\\varepsilon_{r_{i}}\\}$ is always true. Similarly to the proof of lemma 2, assume towards a contradiction that both inequalities can be inverted and hold at the same time, then we end up in a contradiction as follows: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{u_{j}\\geq\\hat{u}_{r_{i}}+\\varepsilon_{j}\\xrightarrow{u_{r_{i}}>u_{j}}u_{r_{i}}>\\hat{u}_{r_{i}}+\\varepsilon_{j}\\Rightarrow u_{r_{i}}-\\hat{u}_{r_{i}}>\\varepsilon_{j}\\xrightarrow{\\varepsilon_{r_{i}}\\geq u_{r_{i}}-\\hat{u}_{r_{i}}}\\varepsilon_{r_{i}}>\\varepsilon_{j}}\\\\ {u_{r_{i}}\\leq\\hat{u}_{j}-\\varepsilon_{r_{i}}\\xrightarrow{u_{j}<u_{r_{i}}}u_{j}<\\hat{u}_{j}-\\varepsilon_{r_{i}}\\Rightarrow\\varepsilon_{r_{i}}<\\hat{u}_{j}-u_{j}\\xrightarrow{\\varepsilon_{j}\\geq\\hat{u}_{j}-u_{j}}\\varepsilon_{r_{i}}<\\varepsilon_{j}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For each of those cases, i.e., whether $\\{u_{j}<\\hat{u}_{r_{i}}+\\varepsilon_{j}\\}$ or $\\{u_{r_{i}}>\\hat{u}_{j}-\\varepsilon_{r_{i}}\\}$ is true we define an event which implies that $r_{i}$ is added to the solution set $S$ . ", "page_idx": 18}, {"type": "text", "text": "If $\\{u_{r_{i}}>\\hat{u}_{j}-\\varepsilon_{r_{i}}\\}$ is true then we define the following event: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{C}=\\bigwedge_{(l):l\\in[k+2]\\setminus\\{r_{i}\\cup j\\}}\\{t_{l}<1/2\\}\\land\\{1/2<t_{r_{i}}<t_{j}\\}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P[\\mathcal{C}]=P[1/2<t_{r_{i}}<t_{j}]\\cdot\\;\\;\\prod_{\\substack{(l):l\\in[k+2]\\backslash\\{r_{i}\\cup j\\}}}P[t_{l}<1/2]}\\\\ &{\\quad=P[1/2<\\operatorname*{min}\\{t_{r_{i}},t_{j}\\}\\wedge\\{t_{r_{i}}<t_{j}\\}]\\cdot\\;\\prod_{\\substack{(l):l\\in[k+2]\\backslash\\{r_{i}\\cup j\\}}}(1/2)}\\\\ &{\\quad=P[1/2<\\operatorname*{min}\\{t_{r_{i}},t_{j}\\}]\\cdot P[t_{r_{i}}<t_{j}]\\cdot\\;\\;\\prod_{\\substack{(l):l\\in[k+2]\\backslash\\{r_{i}\\cup j\\}}}(1/2)}\\\\ &{\\quad\\geq P[1/2<\\operatorname*{min}\\{t_{r_{i}},t_{j}\\}]\\cdot P[t_{r_{i}}<t_{j}]\\cdot(1/2)^{k+2}}\\\\ &{\\quad=(1/4)\\cdot(1/2)\\cdot(1/2)^{k+2}}\\\\ &{\\quad=(1/2)^{k+5}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We now argue that $\\mathcal{C}$ implies that $r_{i}$ is added to $S$ . ", "page_idx": 19}, {"type": "text", "text": "The first literal of $\\mathcal{C}$ ensures that $\\tau\\geq u_{r_{k+1}}$ after time $1/2$ and, consequently, the only candidate with a true value higher than the threshold $\\tau$ at time $t$ such that $1/2\\le t\\le t_{r_{i}}$ is $r_{i}$ . That observation implies that conditions of case $^{4}$ are true only for $r_{i}$ . ", "page_idx": 19}, {"type": "text", "text": "We now argue that: (1) before time $t_{r_{i}}$ less than $k$ candidates are added to $S$ ; and (2) the conditions of subcase $^{4b}$ are true for $r_{i}$ at time $t_{r_{i}}$ . ", "page_idx": 19}, {"type": "text", "text": "For (1) first note that: (a) initially we have $|S|=|B|=0.$ , $|H|=k$ ; (b) at all times our algorithm maintain the invariant $B\\cap H=\\emptyset$ , $B\\cup H\\subseteq[k]$ ; and (c) every time a candidate is added to the solution $S$ then a candidate is deleted from either $B$ , as in case $^{\\,l}$ and subcase $_{4a}$ , or $H$ as in subcase $2a$ , case 3 and subcase $^{4b}$ . Thus, at all times $|B|+|H|+|S|$ remains constant and since initially is equal to $k$ we conclude that at all times $|B|+|H|+|S|=k$ . In addition, a candidate not yet arrived may be removed from $H$ only through subcase $_{4b}$ . Since we argued that conditions of case $^{4}$ are true only for $r_{i}$ , we have that right before $r_{i}$ \u2019s arrival $j\\in H$ and $|S|=k-|B|-|H|\\leq k-|H|\\leq k-1<{\\dot{k}}$ For (2), to argue that conditions of subcase $_{4b}$ are met at time $t_{r_{i}}$ , it is enough to prove that $j\\in\\{j^{\\prime}:u_{r_{i}}\\stackrel{\\_}{>}\\hat{u}_{j^{\\prime}}-\\varepsilon_{t_{r_{i}}}\\}.$ . To see that note that by the definition of $\\varepsilon_{t_{r_{i}}}$ it holds that $\\varepsilon_{t_{r_{i}}}\\geq\\varepsilon_{r_{i}}$ and consequently, $\\{j^{\\prime}:u_{r_{i}}>\\dot{u}_{j^{\\prime}}-\\varepsilon_{t_{r_{i}}}\\}\\supseteq\\{j^{\\prime}:u_{r_{i}}>\\hat{u}_{j^{\\prime}}-\\varepsilon_{r_{i}}\\}\\ni j$ . ", "page_idx": 19}, {"type": "text", "text": "Before proceeding to the second case we introduce the following notation: ", "page_idx": 19}, {"type": "equation", "text": "$$\nt_{p e g(j)}=\\left\\{{t_{l}\\atop\\infty}\\right.\\ {\\mathrm{if}}\\ \\exists l:l=p e g(j)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "that is, if at time $t_{j}$ candidate $l$ is added to the pegging set $P$ then we use $t_{p e g(j)}$ to denote the arrival time of candidate $l$ . However, if at time $t_{j}$ no candidate is added to set $P$ then we define $t_{p e g(j)}$ to be equal to $\\infty$ so that the literal $\\{t_{p e g(j)}>x\\}$ is true for every $x\\in\\mathfrak{R}$ . ", "page_idx": 19}, {"type": "text", "text": "We now analyze the case where $\\{u_{j}<\\hat{u}_{r_{i}}+\\varepsilon_{j}\\}$ is true and define the following event: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal{C}=\\bigwedge_{l\\in[k+1]\\setminus\\{r_{i},j\\}}\\{t_{r_{l}}<1/3\\}\\wedge\\{1/3<t_{j}<1/2\\}\\wedge\\{t_{r_{i}}>1/2\\}\\wedge\\{C_{j}=1\\}\\wedge\\{t_{p e g(j)}\\geq t_{r_{i}}\\}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "To simplify notation, let $P_{j}$ be the random variable denoting the pegging set at time $t_{j}$ before the execution of the while loop because of $j$ \u2019s arrival. We let $F_{j}=\\{j^{\\prime}\\succ\\bar{j}:u_{j}^{-}<\\hat{u}_{j^{\\prime}}+\\varepsilon_{t_{j}}\\}\\backslash\\left(P_{j}\\cup[k]\\right)$ be the random variable which contains all candidates that could be \u201cpegged\u201d at time $t_{j}$ . ", "page_idx": 19}, {"type": "text", "text": "In addition we define event $\\tau$ as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\nT=\\bigwedge_{l\\in[k+1]\\setminus\\{r_{i},j\\}}\\{t_{r_{l}}<1/3\\}\\wedge\\{1/3<t_{j}<1/2\\}\\wedge\\{t_{r_{i}}>1/2\\}\\wedge\\{C_{j}=1\\}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Before lower bounding the probability of event $\\mathcal{C}$ we argue that: ", "page_idx": 19}, {"type": "equation", "text": "$$\nP\\big[t_{p e g(j)}\\geq t_{r_{i}}\\ |\\ T\\big]\\geq2/3\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Let ${\\mathcal{F}}_{j}$ denote the set of all non-empty subsets of $[n]$ such that $P[F_{j}=f_{j}\\mid T]>0$ . Note that $\\begin{array}{r}{P[F_{j}\\stackrel{\\cdot}{=}\\emptyset\\mid\\mathcal{T}]+\\sum_{f_{j}\\in\\mathcal{F}_{j}}P[F_{j}=f_{j}\\stackrel{\\cdot}{\\mid}\\mathcal{T}]=1}\\end{array}$ . In addition, to alleviate notation we denote $l_{f_{j}}=$ $\\textstyle\\operatorname{argmin}_{j^{\\prime}\\in f_{j}}\\,{\\hat{u}}_{j^{\\prime}}$ . ", "page_idx": 20}, {"type": "text", "text": "From the law of total probability we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle P\\big[t_{p e g(j)}\\geq t_{r_{i}}\\;|\\;\\mathcal{T}\\big]}\\\\ {\\displaystyle=P\\big[\\{t_{p e g(j)}\\geq t_{r_{i}}\\}\\wedge\\{F_{j}=\\emptyset\\}\\;|\\;\\mathcal{T}\\big]+P\\big[\\{t_{p e g(j)}\\geq t_{r_{i}}\\}\\wedge\\{F_{j}\\neq\\emptyset\\}\\;|\\;\\mathcal{T}\\big]}\\\\ {\\displaystyle=P[F_{j}=\\emptyset\\;|\\;\\mathcal{T}]+P\\big[\\{t_{p e g(j)}\\geq t_{r_{i}}\\}\\wedge\\{F_{j}\\neq\\emptyset\\}\\;|\\;\\mathcal{T}\\big]}\\\\ {\\displaystyle=P[F_{j}=\\emptyset\\;|\\;\\mathcal{T}]+\\sum_{f_{j}\\in\\mathcal{F}_{j}}P\\big[\\{t_{p e g(j)}\\geq t_{r_{i}}\\}\\wedge\\{F_{j}=f_{j}\\}\\;|\\;\\mathcal{T}\\big]}\\\\ {\\displaystyle=P[F_{j}=\\emptyset\\;|\\;\\mathcal{T}]+\\sum_{f_{j}\\in\\mathcal{F}_{j}}P\\big[t_{p e g(j)}\\geq t_{r_{i}}\\;|\\;\\{F_{j}=f_{j}\\}\\wedge\\mathcal{T}\\big]\\cdot P[F_{j}=f_{j}\\;|\\;\\mathcal{T}]}\\\\ {\\displaystyle=P[F_{j}=\\emptyset\\;|\\;\\mathcal{T}]+\\sum_{f_{j}\\in\\mathcal{F}_{j}}P\\Big[t_{t_{j}}\\geq t_{r_{i}}\\;|\\;\\{F_{j}=f_{j}\\}\\wedge\\mathcal{T}\\Big]\\cdot P[F_{j}=f_{j}\\;|\\;\\mathcal{T}]}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where from (2) to (3) we use that if $F_{j}=\\emptyset$ then the condition of subcase $2b$ is false, thus no candidate is \u201cpegged\u201d and consequently $t_{p e g(j)}=\\infty$ . From (3) to (4) we used that $\\{F_{j}\\neq\\emptyset\\}=\\bigvee_{f_{j}\\in\\mathcal{F}_{j}}\\{F_{j}=$ $f_{j}\\}$ . From (5) to (6) we used that event $\\{F_{j}=f_{j}\\}\\wedge\\tau$ implies that conditions of case 2 and subcase $_{2b}$ are true and consequently $p e g(j)=\\bar{l}_{f_{j}}\\;$ by the definition of $l_{f_{j}}$ . ", "page_idx": 20}, {"type": "text", "text": "We now focus on lower bounding the summation term ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{j\\in\\mathcal{F}_{i}}P\\Big[t_{i_{j}}\\geq t_{r_{i}}\\ \\{\\{F_{j}=f_{j}\\}\\wedge T\\Big]\\cdot P[F_{j}=f_{j}\\ |\\ T]=}\\\\ &{\\displaystyle\\sum_{j\\in\\mathcal{F}_{i}\\neq I_{j}\\neq r_{n}}P\\Big[t_{i_{j}}\\geq t_{r_{i}}\\ \\{\\{F_{j}=f_{j}\\}\\wedge T\\Big]\\cdot P[F_{j}=f_{j}\\ |\\ T]+}\\\\ &{+\\displaystyle\\sum_{j\\in\\mathcal{F}_{i}\\neq I_{j}\\neq r_{n}}P\\Big[t_{i_{j}}\\geq t_{r_{i}}\\ \\{\\{F_{j}=f_{j}\\}\\wedge T\\Big]\\cdot P[F_{j}=f_{j}\\ |\\ T]=}\\\\ &{\\displaystyle\\sum_{j\\in\\mathcal{F}_{i}\\neq I_{j}\\neq r_{n}}P[t_{i_{j}}\\geq t_{r_{i}}\\ \\{\\{F_{j}=f_{j}\\}\\wedge T\\}\\cdot P[F_{j}=f_{j}\\ |\\ T]+}\\\\ &{+\\displaystyle\\sum_{j\\in\\mathcal{F}_{i}\\neq I_{j}\\neq r_{n}}P\\Big[t_{i_{j}}\\geq t_{r_{i}}\\ |\\ \\{F_{j}=f_{j}\\}\\wedge T\\Big]\\cdot P[F_{j}=f_{j}\\ |\\ T]=}\\\\ &{\\displaystyle\\sum_{j\\in\\mathcal{F}_{i}\\neq I_{j}\\neq r_{n}}\\ [T_{i}=f_{j}\\ |\\ T]+\\displaystyle\\sum_{j\\in\\mathcal{F}_{i}\\neq I_{j}\\neq r_{n}}P\\Big[t_{i_{j}}\\geq t_{r_{i}}\\ |\\ \\{F_{j}=f_{j}\\}\\wedge T\\Big]\\cdot P[F_{j}=f_{j}\\ |\\ T]}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We proceed lower bounding the term $P\\Big[t_{l_{f_{j}}}\\geq t_{r_{i}}\\ |\\ \\{F_{j}=f_{j}\\}\\land T\\Big]$ for all $f_{j}\\in\\mathcal{F}_{j}:l_{f_{j}}\\neq r_{i}$ . Note that the conditioning $\\{F_{j}=f_{j}\\}\\wedge\\tau$ changes the distribution of random variables $t_{l_{f_{j}}},t_{r_{i}}$ as follows: $t_{r_{i}}$ is uniformly drawn from $[1/2,1]$ and $t_{l_{f_{j}}}$ is uniformly drawn from $[z,1]$ for some $z\\in[1/3,1/2]$ which equals the realization of the random variable $t_{j}$ . We define a random variable $\\tilde{t}_{l_{f_{j}}}$ which is stochastically dominated by $t_{l_{f_{j}}}$ and is drawn uniformly from $[1/3,1]$ as follows: let $\\tilde{t}$ be uniformly drawn from $[1/3,z]$ and $B\\sim\\dot{B}e r n o u l l i((z-1/3)/(1/2-1/3))$ then we define: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\tilde{t}_{l_{f_{j}}}=B\\cdot\\tilde{t}+(1-B)\\cdot t_{l_{f_{j}}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Note that since $\\tilde{t}\\leq t_{l_{f_{j}}}$ then also $\\tilde{t}_{l_{f_{j}}}\\leq t_{l_{f_{j}}}$ holds almost surely. ", "page_idx": 20}, {"type": "text", "text": "Therefore we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{P\\Big[t_{l_{f_{j}}}\\geq t_{r_{i}}\\ |\\ \\{F_{j}=f_{j}\\}\\wedge T\\Big]\\geq P\\Big[\\tilde{t}_{l_{f_{j}}}\\geq t_{r_{i}}\\ |\\ \\{F_{j}=f_{j}\\}\\wedge T\\Big]}}\\\\ &{}&{\\geq2/3}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and we proceed bounding the initial summation as follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}}P\\Big[t_{l_{f_{j}}}\\geq t_{r_{i}}\\ |\\ \\{F_{j}=f_{j}\\}\\wedge\\mathcal{T}\\Big]\\cdot P[F_{j}=f_{j}\\ |\\ \\mathcal{T}]=}\\\\ &{=\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}:l_{f_{j}}=r_{i}}1\\cdot P[F_{j}=f_{j}\\ |\\ \\mathcal{T}]+\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}:l_{f_{j}}\\neq r_{i}}P\\Big[t_{l_{f_{j}}}\\geq t_{r_{i}}\\ |\\ \\{F_{j}=f_{j}\\}\\wedge\\mathcal{T}\\Big]\\cdot P[F_{j}=f_{j}\\ |\\ \\mathcal{T}]}\\\\ &{\\geq\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}:l_{f_{j}}=r_{i}}1\\cdot P[F_{j}=f_{j}\\ |\\ \\mathcal{T}]+\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}:l_{f_{j}}\\neq r_{i}}(2/3)\\cdot P[F_{j}=f_{j}\\ |\\ \\mathcal{T}]}\\\\ &{\\geq(2/3)\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}}P[F_{j}=f_{j}\\ |\\ \\mathcal{T}]}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We then have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{P\\big[t_{P e g(f)}\\geq t_{r_{i}}\\;|\\;T\\big]}\\\\ {=P[F_{j}=\\emptyset\\;|\\;T]+\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}}P\\Big[t_{I_{j}}\\geq t_{r_{i}}\\;|\\;\\{F_{j}=f_{j}\\}\\wedge T\\Big]\\cdot P[F_{j}=f_{j}\\;|\\;T]}\\\\ {\\ge P[F_{j}=\\emptyset\\;|\\;T]+(2/3)\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}}P[F_{j}=f_{j}\\;|\\;T]}\\\\ {\\ge(2/3)\\cdot\\left(P[F_{j}=\\emptyset\\;|\\;T]+\\displaystyle\\sum_{f_{j}\\in\\mathcal{F}_{j}}P[F_{j}=f_{j}\\;|\\;T]\\right)}\\\\ {=2/3}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We are now ready to lower bound the probability of event $\\mathcal{C}$ as follows ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P[\\mathcal{C}]=P[\\mathcal{T}]\\cdot P\\big[t_{p e g(j)}\\geq t_{r_{i}}\\ |\\ \\mathcal{T}\\big]}\\\\ &{\\qquad\\geq P[\\mathcal{T}]\\cdot(2/3)}\\\\ &{\\qquad=\\displaystyle\\prod_{(l):l\\in[k+1]\\backslash\\{r_{i},j\\}}P[t_{l}<1/3]\\cdot P[1/3<t_{j}<1/2]\\cdot(2/3)}\\\\ &{\\qquad\\geq(1/3)^{k}\\cdot(1/2-1/3)\\cdot(2/3)}\\\\ &{\\qquad=(1/3)^{k+2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Similar to the analysis of the first case the first literal of $\\mathcal{C}$ ensures that the only candidate which may be accepted after time $1/2$ without being at any point in time in the pegging set $P$ is $r_{i}$ . In addition, since $t_{j}<1/2$ then we have that $j$ remains in $H$ until at least time $t_{j}$ . Indeed, a candidate in $H$ that has not arrived yet may be removed from set $H$ only through case $^{4b}$ which happens exclusively after time $1/2$ . We now analyze $\\mathcal{C}$ \u2019s implications regarding the execution of our algorithm at $j$ \u2019s arrival by distinguishing between two mutually exclusive cases, that is whether $r_{i}$ is in $P$ before time $t_{j}$ or not. ", "page_idx": 21}, {"type": "text", "text": "If $r_{i}$ is not in the pegging set exactly before time $t_{j}$ then we have that the conditions of case $_{2b}$ are true. Indeed note that $\\{\\bar{C}_{j}=1\\}$ is a literal of $\\mathcal{C}$ and since $\\varepsilon_{j}\\leq\\varepsilon_{t_{j}}$ we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\{j^{\\prime}\\succ j:u_{j}<\\hat{u}_{j^{\\prime}}+\\varepsilon_{t_{j}}\\}\\setminus(P\\cup[k])\\supseteq\\{j^{\\prime}\\succ j:u_{j}<\\hat{u}_{j^{\\prime}}+\\varepsilon_{j}\\}\\setminus(P\\cup[k])\\ni r_{i}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus, we are in the case where at time $t_{j}$ a candidate (which may be $r_{i}$ ) is added to the pegging set, candidate $j$ is added to $B$ and $t_{p e g(j)}<\\infty$ . Due to the literal $t_{p e g(j)}\\geq t_{r_{i}}$ of $\\mathcal{C}$ and the fact that the only candidate which may be accepted after time $1/2$ without being at any point in time in the pegging set $P$ is $r_{i}$ , we can deduce that at time $t_{r_{i}}~j$ is still in $B$ . Thus, at time $t_{r_{i}}$ the conditions of subcase 4a are true and $r_{i}$ is added to $S$ . If $r_{i}$ is in the pegging set exactly before time $t_{j}$ then since the conditions of case $^{4}$ are false for any candidate except possibly $r_{i}$ we can deduce that at time $t_{r_{i}}$ , candidate $r_{i}$ is still in the pegging set $P$ and is added to the solution through case $^{\\,I}$ . ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "Combining all the different lower bounds on $P[r_{i}\\in S]$ we conclude the lemma. ", "page_idx": 22}, {"type": "text", "text": "Lemma 11. For all $\\begin{array}{r}{i\\in\\{1,2,\\ldots,k\\}\\colon P[r_{i}\\in S]\\geq\\frac{1-\\frac{i+13}{k}}{256}}\\end{array}$ ", "page_idx": 22}, {"type": "text", "text": "Proof. Let $\\delta^{\\prime}>12/k$ be such that $i<(1-\\delta^{\\prime})k-1$ . We now argue that proving $P[r_{i}\\in S]\\geq\\delta^{\\prime}/256$ suffices to prove the lemma. ", "page_idx": 22}, {"type": "text", "text": "First, we underline that such a $\\delta^{\\prime}$ exists only for $i<k-13$ . Indeed, ", "page_idx": 22}, {"type": "equation", "text": "$$\ni<(1-\\delta^{\\prime})k-1\\Rightarrow\\delta^{\\prime}<1-\\frac{i+1}{k}\\:\\frac{\\delta^{\\prime}{>}12/k}{\\delta}\\:i<k-13\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For all $i<k-13$ we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\nP[r_{i}\\in S]\\geq\\delta^{\\prime}/256>\\frac{1-\\frac{i+1}{k}}{256}>\\frac{1-\\frac{i+13}{k}}{256}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For $i\\geq k-13$ the statement of the lemma is vacuous, since: ", "page_idx": 22}, {"type": "equation", "text": "$$\nP[r_{i}\\in S]\\geq0\\geq{\\frac{1-{\\frac{i+13}{k}}}{256}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Consequently, from now on we focus on proving that $P[r_{i}\\in S]\\geq\\delta^{\\prime}/256.$ . We do so by defining an event $\\mathcal{C}$ for which $P[\\mathcal{C}]\\ge\\delta^{\\prime}/256$ and argue that $\\mathcal{C}$ implies $r_{i}$ being accepted. ", "page_idx": 22}, {"type": "text", "text": "Before defining $\\mathcal{C}$ we need to introduce some auxiliary notation. We call replacement set and denote by $R$ the set of indexes initially in $H$ with value lower than $u_{r_{i}}$ , i.e., $R\\,\\,{\\stackrel{.}{=}}\\,\\left\\{j\\,:\\,u_{r_{i}}\\,>\\,u_{j}\\right\\}\\cap\\left[k\\right]$ and by $j^{w o r s e}\\,=\\,\\mathrm{argmax}_{j\\in R}\\,\\varepsilon_{j}$ the index of the candidate with the highest error in $R$ . For any $t,t^{\\prime}\\in[0,1]$ we define the random variable $A_{t,t^{\\prime}}=\\{j:t\\leq t_{j}\\leq t^{\\prime}\\}\\;\\backslash\\;\\{r_{i},j^{w o r s e}\\}$ which contains all indexes except $r_{i}$ and $j^{w o r s e}$ of candidates arrived between times $t$ and $t^{\\prime}$ . Also, for $x\\in[n]$ we define the set function $L_{x}:2^{[n]}\\,\\to\\,2^{[n]}$ , such that for any subset $Y\\subseteq[n]$ , $L_{x}(Y)$ contains the $x$ indexes with highest true value in $Y$ . For $\\delta\\ \\in\\ (0,1/\\dot{2})$ let (a) $R_{1}\\,=\\,R\\cap A_{0,1/2+\\delta}$ and $R_{2}=R\\cap A_{1/2+\\delta,1}$ be the random variables denoting all candidates of $R\\setminus\\{j^{w o r s e}\\}$ arriving before and after time $1/2+\\delta$ respectively; and (b) let $M=L_{\\lfloor(1+4\\delta)k\\rfloor}(A_{0,1/2+\\delta})\\cap A_{1/2,1/2+\\delta}$ denote the random variable containing candidates which arrived between times $1/2$ and $1/2+\\delta$ with the $\\lfloor(1+4\\delta)k\\rfloor$ higher true value among the ones arrived before time $1/2+\\delta$ (excluding $r_{i}$ and $j^{w o r s e})$ . ", "page_idx": 22}, {"type": "text", "text": "We now define event $\\mathcal{C}$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathcal{C}=\\{|R_{2}|-|M|>1\\}\\wedge\\{1/2<t_{r_{i}}<1/2+\\delta\\}\\wedge\\{t_{j^{w o r s e}}<t_{r_{i}}\\}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that $M$ contains all candidates not in $H$ that may be added to our solution between times $1/2$ and $1/2+\\delta$ . In addition, each candidate in $M$ through subcase $_{4b}$ may delete from $H$ at most one candidate with arrival time after $1/2+\\delta$ . ", "page_idx": 22}, {"type": "text", "text": "Consequently, the number of candidates in $R$ that are in $H$ until time $1/2\\!+\\!\\delta$ is at least $|R_{2}|\\!-\\!|M|>1$ . We now argue that conditions of subcase $^{4b}$ are true at time $t_{r_{i}}$ . Indeed, note that since $t_{j}$ worse $<t_{r_{i}}$ we have that $\\varepsilon_{t_{r_{i}}}>\\varepsilon_{j}w o r s e$ and consequently, for every candidate $j$ of $R$ we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\nu_{r_{i}}>u_{j}\\ge\\hat{u}_{j}-\\varepsilon_{j}\\ge\\hat{u}_{j}-\\varepsilon_{j}\\mathit{w o r s e}\\ge\\hat{u}_{j}-\\varepsilon_{t_{i}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the first inequality comes from the definition of set $R$ , the second from the definition of the error, the third from the definition of $j^{w o r s e}$ and the last from the fact that $\\varepsilon_{t_{r_{i}}}\\,>\\,\\varepsilon_{j^{w o r s e}}$ . Since $R_{2}\\subseteq R$ , we have that at time $t_{r_{i}}$ there is at least one candidate $j$ in $H$ for which $u_{r_{i}}\\geq\\hat{u}_{j}-\\varepsilon_{t_{r_{i}}}$ and the conditions of subcase 4a are therefore true. ", "page_idx": 22}, {"type": "text", "text": "We now proceed lower bounding the probability of event $\\mathcal{C}$ . Let $\\delta\\;=\\;\\delta^{\\prime}/16$ we first argue that $\\begin{array}{r}{\\{|R_{2}|\\ge\\frac{\\bar{1}/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}}\\end{array}$ 1/12\u2212\u2212\u03b42 \u03b4\u03b4\u2032k} and |M| < 4\u03b4k implies that |R2| \u2212|M| > 1. Indeed note that: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|R_{2}|-|M|>\\displaystyle\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k-4\\delta k}\\\\ &{\\phantom{|}>\\displaystyle\\frac{1}{3}\\delta^{\\prime}k-4\\delta k}\\\\ &{\\phantom{|}>\\displaystyle(\\delta^{\\prime}/3-4\\delta)k}\\\\ &{\\phantom{|}\\geq\\displaystyle(\\delta^{\\prime}/3-4\\delta^{\\prime}/16)k}\\\\ &{\\phantom{|}\\geq\\displaystyle(\\delta^{\\prime}/12)k}\\\\ &{\\phantom{|}>1}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where in the second inequality we used that $\\delta=\\delta^{\\prime}/16\\leq1/16<1/10$ . ", "page_idx": 23}, {"type": "text", "text": "We now lower bound the probability of the intersection of events $\\begin{array}{r}{\\{|R_{2}|\\ge\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\},\\{|M|<4\\delta k\\}}\\end{array}$ , $\\{1/2<t{_{r_{i}}}<1/2+\\delta\\}$ and $\\{t_{j}w o r s e\\,<1/2\\}$ since their intersection implies event $\\mathcal{C}$ . ", "page_idx": 23}, {"type": "text", "text": "Since $R_{2}$ and $M$ do not contain neither $r_{i}$ nor $j^{w o r s e}$ we have that events $\\begin{array}{r}{\\{|R_{2}|\\;\\ge\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}}\\end{array}$ $\\{|M|<4\\delta k\\}$ are independent of the time arrival of $j^{w o r s e}$ and $r_{i}$ . Thus, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{P[\\mathcal{C}]=P\\bigg[\\{|R_{2}|\\geq\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}\\wedge\\{|M|<4\\delta k\\}\\bigg]\\cdot P[1/2<t_{r_{i}}<1/2+\\delta]\\cdot P[t_{j^{w o r s e}}<1/2]}}\\\\ {{=P\\bigg[\\{|R_{2}|\\geq\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}\\wedge\\{|M|<4\\delta k\\}\\bigg]\\cdot\\delta\\cdot(1/2)}}\\\\ {{=(\\delta^{\\prime}/32)\\cdot P\\bigg[\\{|R_{2}|\\geq\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}\\wedge\\{|M|<4\\delta k\\}\\bigg]}}\\\\ {{=(\\delta^{\\prime}/32)\\cdot P\\bigg[\\{|R_{1}|<|R|-\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}\\wedge\\{|M|<4\\delta k\\}\\bigg]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We continue by lower bounding the second term of the last expression. We do so by defining a random variable $\\mathcal{M}$ which is independent of $R_{1}$ and it is such that $\\mathcal{M}$ stochastically dominates $|M|$ . We prove the stochastic dominance of $\\mathcal{M}$ using a coupling argument. ", "page_idx": 23}, {"type": "text", "text": "Note that every candidate $i$ accepts an arrival time $t_{i}$ uniformly at random from $[0,1]$ . We now describe an equivalent procedure to create the arrival times $t_{i}$ . Each candidate $i$ draws three independent random variables $B_{i}\\ \\sim\\ B e r n o u l l i(1/2\\,+\\,\\delta)$ , $t_{i}^{1}\\ \\sim\\ U n i f o r m([0,1/2+\\delta])$ and $t_{i}^{2}\\,\\stackrel{\\cdot}{\\sim}\\,U n i f o r m([1/2+\\delta,1])$ . Note that we can construct random variables $t_{i}$ using $B_{i},t_{i}^{1}$ and $t_{i}^{2}$ as follows: ", "page_idx": 23}, {"type": "equation", "text": "$$\nt_{i}=B_{i}\\cdot t_{i}^{1}+(1-B_{i})\\cdot t_{i}^{2}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let $l=\\left|L_{(1+4\\delta)k}(A_{0,1/2+\\delta})\\right|$ and denote by $h_{1},\\ldots,h_{l}$ the set of candidates in $L_{(1+4\\delta)k}(A_{0,1/2+\\delta})$ . We define random variables $\\tilde{t}_{1},\\ldots,\\tilde{t}_{(1+4\\delta)k}$ as follows: For each $j\\in\\{1,\\ldots,l\\}$ we define $\\tilde{t}_{j}=t_{h_{j}}^{1}$ and for each $j\\in\\{l+1,\\ldots,1+4\\delta k\\}$ we define $\\Tilde{t}_{j}\\sim U n i f o r m([0,1/2+\\delta])$ . We define $\\mathcal{M}=$ i\u230a(=11+4\u03b4)k\u230bI t\u02dcj > 1/2 and since M \u2212|M| = $\\begin{array}{r}{\\mathcal{M}-\\left|M\\right|=\\sum_{i=l+1}^{\\lfloor(1+4\\delta)k\\rfloor}\\mathbb{I}\\left\\{\\tilde{t}_{j}>1/2\\right\\}}\\end{array}$ i\u230a(=1l++41\u03b4)k\u230bI t\u02dcj > 1/2 we have that M \u2265|M| almost surely. Note that random variables $\\tilde{t}_{j}$ and random variables $B_{i}$ are independent. Consequently, since $\\textstyle|R_{1}|=\\sum_{i\\in R}B_{i}$ we have that events $\\{\\mathcal{M}<y\\}$ and $\\{|R_{1}|<x\\}$ are independent. Combining ", "page_idx": 23}, {"type": "text", "text": "these observations we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad P\\bigg[\\{|R_{1}|<|R|-\\displaystyle\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}\\wedge\\{|M|<4\\delta k\\}\\bigg]}\\\\ &{\\geq P\\bigg[\\{|R_{1}|<|R|-\\displaystyle\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\}\\wedge\\{M<4\\delta k\\}\\bigg]}\\\\ &{\\geq P\\bigg[|R_{1}|<|R|-\\displaystyle\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\bigg]\\cdot P[M<4\\delta k]}\\\\ &{\\geq P\\bigg[|R_{2}|\\geq\\displaystyle\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k\\bigg]\\cdot P[M<4\\delta k]}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "To upper bound $P[\\mathcal{M}<4\\delta k]$ note that $\\mathbf{E}[\\mathcal{M}]=\\lfloor(1\\!+\\!4\\delta)k\\rfloor\\!\\cdot\\!\\frac{\\delta}{1/2+\\delta}<3\\delta k$ , where the last inequality holds for any $\\delta<1/2$ . From Markov\u2019s inequality, we have that: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\quad P[\\mathcal{M}>4\\delta k]=P[\\mathcal{M}>(4/3)\\cdot3\\delta k]}&{{}}\\\\ {\\leq P[\\mathcal{M}>(4/3)\\cdot\\mathbf{E}[\\mathcal{M}]]}&{{}}\\\\ {\\leq(3/4)}&{{}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Consequently ", "page_idx": 24}, {"type": "equation", "text": "$$\nP[\\mathcal{M}<4\\delta k]>(1/4)\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Note that since $i<(1-\\delta^{\\prime})k-1$ we have that $|R|\\geq\\delta^{\\prime}k+1$ . ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbf{E}[|R_{2}|]=|R\\setminus\\{j^{w o r s e}\\}|(1-1/2-\\delta)\\geq\\delta^{\\prime}k(1/2-\\delta)\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "From Markov\u2019s inequality, we have that: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{P\\bigg[|R_{2}|>\\displaystyle\\frac{1/2-2\\delta}{1-\\delta}\\delta^{\\prime}k|\\bigg]\\geq P\\bigg[|R_{2}|>\\displaystyle\\frac{1/2-2\\delta}{(1-\\delta)\\cdot(1/2-\\delta)}\\cdot\\mathbf{E}[|R_{2}|]\\bigg]}&{}\\\\ {\\geq\\displaystyle\\frac{(1-\\delta)\\cdot(1/2-\\delta)}{1/2-2\\delta}}&{}\\\\ {=\\displaystyle\\frac{(1-\\delta)\\cdot(1-2\\delta)}{1-4\\delta}}&{}\\\\ {\\geq(1-\\delta)}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Consequently, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P[\\mathcal{C}]\\geq(\\delta^{\\prime}/32)\\cdot(1/4)\\cdot(1-\\delta)}\\\\ &{\\qquad\\geq(\\delta^{\\prime}/32)\\cdot(1/4)\\cdot(1/2)}\\\\ &{\\qquad\\geq(\\delta^{\\prime}/256)}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Theorem 5. K-PEGGING satisfies smoothness and fairness for $k$ -secretary with $C=4$ and $F_{i}=$ max $\\left\\{(1/3)^{k+5},\\frac{1-(i+13)/k}{256}\\right\\}$ for all $i=1,\\ldots,k$ . ", "page_idx": 24}, {"type": "text", "text": "Proof. The theorem follows directly from corollary 9 and lemmas 10 and 11. ", "page_idx": 24}, {"type": "text", "text": "C Additional experimental results ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section we present the competitive ratio achieved by each algorithm as a function of the parameter $\\varepsilon$ which controls the predictions error in each of the datasets defined in Section 5. ", "page_idx": 24}, {"type": "table", "img_path": "dxxj4S06YL/tmp/bfa063a648221d6a9a52b1f8ec870a7bddf3b72712d6db980fc4188d17c4b479.jpg", "table_caption": ["Table 1: Competitive ratio (mean $\\pm$ std deviation) on Almost-constant "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "dxxj4S06YL/tmp/3112bfa8905f2e73c3f31c65963c76ff24a743bc64694b2f32c08e9335eacf3e.jpg", "table_caption": ["Table 2: Competitive ratio (mean $\\pm$ std deviation) on Uniform "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "dxxj4S06YL/tmp/c5be7a9303290e87764105631ce084c3b85e8dc412203478d99119aabff1e3dc.jpg", "table_caption": ["Table 3: Competitive ratio (mean $\\pm$ std deviation) on Adversarial "], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "dxxj4S06YL/tmp/9a923c7a1f5f500dedc1018591fcbf69282102c919cd58d2f0c0595ccbb7b44d.jpg", "table_caption": ["Table 4: Competitive ratio (mean $\\pm$ std deviation) on Unfair "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 27}, {"type": "text", "text": "Justification: Each claim in the contributions is made as a theorem statement which is formally proved in the main text together with the appendices. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 27}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] . ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: We added a limitations section at the end of the main paper. The computational efficiency of the algorithms is discussed in the main paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 27}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 28}, {"type": "text", "text": "Justification: All theorems are clearly stated and proofs are written in detail either in the main paper or in the appendix. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 28}, {"type": "text", "text": "Justification: In the experiments section we describe in full detail the experimental setup and also submit the code in the supplementary material. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Yes, all results can be reproduced easily by running the jupyter notebook in the supplemental material. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 29}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] . ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: The pseudocode and all details of our experimental setup are described in the main paper. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 29}, {"type": "text", "text": "Justification: We present the mean and standard deviation of the competitive ratio for each dataset/prediction error/algorithm tuple in the experimental section of the appendix. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 29}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer:[Yes] . ", "page_idx": 30}, {"type": "text", "text": "Justification: Yes, we mention the characteristics of the CPU we used, its memory and the time of execution in the experiments section of the main paper. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 30}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 30}, {"type": "text", "text": "Justification: Our research conforms with every aspect of the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 30}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 30}, {"type": "text", "text": "Justification: In the introduction we discuss our fairness notion and how it relates to other fairness notions in the literature, and in the limitations section we discuss how different notions are required to capture different fairness considerations. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper poses no such risks. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 31}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 31}, {"type": "text", "text": "Justification: We are the creators of the code. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 32}, {"type": "text", "text": "Justification: We provide the code in the supplementary material. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 32}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 32}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}]