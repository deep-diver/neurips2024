{"references": [{"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduces the Masked Autoencoder (MAE) framework, which is the foundation for the approach taken in this paper."}, {"fullname_first_author": "Zhan Tong", "paper_title": "VideoMAE: Masked autoencoders are data-efficient learners for self-supervised video pre-training", "publication_date": "2022-00-00", "reason": "This paper is among the first to apply MAE to video data and establishes a baseline that this paper aims to improve upon."}, {"fullname_first_author": "Limin Wang", "paper_title": "VideoMAE v2: Scaling video masked autoencoders with dual masking", "publication_date": "2023-00-00", "reason": "This paper extends the VideoMAE framework with dual masking, and this paper builds upon its findings and techniques."}, {"fullname_first_author": "Lijun Yu", "paper_title": "Magvit: Masked generative video transformer", "publication_date": "2023-00-00", "reason": "This paper introduces the MAGVIT tokenizer, which is a key component of the proposed approach in this paper."}, {"fullname_first_author": "Christoph Feichtenhofer", "paper_title": "Masked autoencoders as spatiotemporal learners", "publication_date": "2022-00-00", "reason": "This paper explores masked autoencoders for spatiotemporal learning in videos, establishing a key concept for this work."}]}