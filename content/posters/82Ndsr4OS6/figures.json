[{"figure_path": "82Ndsr4OS6/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between WSAC and the behavior policy in the tabular case. The behavior policy is a mixture of the optimal policy and a random policy, with the mixture percentage representing the proportion of the optimal policy. The cost threshold is set to 0.1. We observe that WSAC consistently ensures a safely improved policy across various scenarios, even when the behavior policy is not safe.", "description": "This figure compares the performance of the proposed WSAC algorithm against a baseline behavior policy in a tabular setting (simple MDP).  The behavior policy is a mixture of a truly optimal policy and a completely random one. Different mixture percentages (20%, 50%, 80%) represent varying levels of competence in the baseline policy.  The results demonstrate that WSAC reliably improves upon the baseline policy while staying within a defined safety threshold (cost \u2264 0.1), even when the behavior policy itself is unsafe (violating the cost threshold). This highlights WSAC's ability to achieve safe policy improvement.", "section": "1 Introduction"}, {"figure_path": "82Ndsr4OS6/figures/figures_19_1.jpg", "caption": "Figure 2: BallCircle and CarCircle (left), PointButton (medium), PointPush(right) .", "description": "This figure shows four different simulated environments used for evaluating the performance of the proposed WSAC algorithm and its baselines.  \n\n* **BallCircle:** A circular track with a safety zone where an agent (a ball) must navigate in a clockwise direction, penalized for leaving the track.\n* **CarCircle:** Similar to BallCircle but the agent is a car.\n* **PointButton:** An agent (a point) must navigate to a goal button, avoiding obstacles (gremlins).\n* **PointPush:** The agent must push a box to a goal, again while avoiding obstacles.", "section": "6.2 Simulations"}, {"figure_path": "82Ndsr4OS6/figures/figures_20_1.jpg", "caption": "Figure 3: The moving average of evaluation results is recorded every 500 training steps, with each result representing the average over 20 evaluation episodes and three random seeds. A cost threshold 1 is applied, with any normalized cost below 1 considered safe.", "description": "This figure shows the training curves of the proposed algorithm WSAC and several baselines on four different continuous control tasks: BallCircle, CarCircle, PointButton, and PointPush.  Each curve represents the moving average of the normalized reward and cost over 20 evaluation episodes, calculated over three random seeds.  The x-axis shows the training steps, and the y-axis shows the normalized reward and cost. A cost threshold of 1 is used; results below this threshold are considered safe. The figure demonstrates WSAC's consistent performance across different tasks, achieving high rewards while maintaining safety (cost below 1).", "section": "6.2 Simulations"}, {"figure_path": "82Ndsr4OS6/figures/figures_22_1.jpg", "caption": "Figure 1: Comparison between WSAC and the behavior policy in the tabular case. The behavior policy is a mixture of the optimal policy and a random policy, with the mixture percentage representing the proportion of the optimal policy. The cost threshold is set to 0.1. We observe that WSAC consistently ensures a safely improved policy across various scenarios, even when the behavior policy is not safe.", "description": "The figure shows the results of a comparison between the proposed WSAC algorithm and a baseline behavior policy in a tabular setting.  The behavior policy is a mix of an optimal policy and a random policy, with varying proportions of the optimal policy. The x-axis represents the percentage of the optimal policy in the mixture. The y-axis displays both the reward and cost achieved by both policies. The cost threshold is set at 0.1.  The plot illustrates that WSAC consistently outperforms the behavior policy while maintaining a safe level of cost, even when the behavior policy itself is unsafe.", "section": "1 Introduction"}]