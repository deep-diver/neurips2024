[{"figure_path": "ja20BpFAPa/figures/figures_0_1.jpg", "caption": "Figure 1: Given a sequence of video captured by a dash cam that may contain obstructions like reflections and occlusions, DC-Gaussian achieves high-fidelity novel view synthesis getting rid of the obstructions. (a) dash cam; (b) original video frame; (c) novel view rendering with obstruction removal.", "description": "This figure shows the effectiveness of the proposed DC-Gaussian method in removing obstructions from dash cam videos and generating high-fidelity novel views.  Subfigure (a) displays a dash cam mounted in a vehicle. Subfigure (b) shows an original frame from the dash cam video containing obstructions such as reflections and occlusions.  Subfigure (c) presents the novel view generated by DC-Gaussian, demonstrating the successful removal of these obstructions while maintaining high image quality.", "section": "Abstract"}, {"figure_path": "ja20BpFAPa/figures/figures_1_1.jpg", "caption": "Figure 1: Given a sequence of video captured by a dash cam that may contain obstructions like reflections and occlusions, DC-Gaussian achieves high-fidelity novel view synthesis getting rid of the obstructions. (a) dash cam; (b) original video frame; (c) novel view rendering with obstruction removal.", "description": "This figure shows the input and output of the proposed method. It demonstrates the ability of DC-Gaussian to remove obstructions (such as reflections and occlusions) from dash cam videos and generate high-fidelity novel views.  (a) shows a dash cam. (b) displays an original video frame containing obstructions. (c) presents a novel view rendering produced by the DC-Gaussian model with the obstructions removed.", "section": "Abstract"}, {"figure_path": "ja20BpFAPa/figures/figures_3_1.jpg", "caption": "Figure 3: Overview of DC-Gaussian framework. To model obstructions with different opacities in a unified manner, we use an learnable opacity map to adaptively reweight the contribution of transmission. The global-shared multiresolution hash encoding is introduced to fully utilize the static motion prior of obstructions. We propose a Latent Intensity Modulation module to grasp the intensity changes of reflections conditioned on camera positions. Finally, in the G3 Enhancement module, we run geometry filtering on obstruction-suppressed images to enhance the geometry of 3D Gaussians.", "description": "This figure illustrates the architecture of the DC-Gaussian framework, highlighting the key modules involved in modeling obstructions and generating novel views from dashcam videos. It shows how the framework adaptively handles obstructions with different opacities, leverages static motion priors, and incorporates illumination changes for more realistic reflection synthesis. The process begins with input images processed through SfM, 3DGS initialization, and proceeds through the Illumination-aware Obstruction Modeling, G3 Enhancement, and final rendering stages to produce the output images. ", "section": "3 Method"}, {"figure_path": "ja20BpFAPa/figures/figures_5_1.jpg", "caption": "Figure 4: When the intensity of incident light changes, the strength of reflections also changes accordingly (a, d). Our method achieves high-fidelity reflections synthesis (c, f) and reasonable decomposition results (b, e) under varying light. The reflections in (f) are too weak to be seen by the eye, so we brighten it to reveal the details.", "description": "This figure demonstrates the effectiveness of the proposed method in handling varying lighting conditions.  It shows image decomposition results (transmission and obstruction) and novel view synthesis under both strong and weak light. The results highlight the method's ability to accurately model and render reflections with varying intensities, even when reflections are subtle and barely visible to the naked eye.", "section": "3.3 Illumination-aware Obstruction Modeling"}, {"figure_path": "ja20BpFAPa/figures/figures_6_1.jpg", "caption": "Figure 5: Comparisons with 3DGS on novel view synthesis. Because the obstructions violate multi-view consistency, the performance of 3DGS degrades significantly, resulting in artifacts and blurry renderings (highlighted by red arrows). In contrast, our method not only faithfully synthesizes novel view renderings but also renders transmission with fine details, exhibiting an improvement of 3.05dB in terms of PSNR.", "description": "The figure compares novel view synthesis results of the proposed method and 3DGS. It demonstrates that 3DGS produces blurry renderings and artifacts due to obstructions violating multi-view consistency. The proposed method, however, faithfully synthesizes novel views and renders fine details in the transmission, resulting in a significant improvement in PSNR.", "section": "4.3 Quantitative Results"}, {"figure_path": "ja20BpFAPa/figures/figures_8_1.jpg", "caption": "Figure 6: Comparisons with the image-based reflection removal methods on removing reflections. (a) Reference is a frame in a dash cam video. (b) and (c) are transmission and obstruction decomposed by our method. (d), (e), and (f) are results from previous obstruction removal methods, NIR [32], DSRNet [17] and Liu et al. [27], which are not effective in this scenario. In comparison, our method decomposes the image and synthesizes (b) transmission and (c) obstruction with high fidelity.", "description": "This figure compares the performance of the proposed method against other state-of-the-art single image and multi-image reflection removal methods. The results show that the proposed method is superior in decomposing the image into transmission and obstruction components and achieving higher fidelity in synthesizing these components. ", "section": "2.2 Obstruction Removal and Layer Separation"}, {"figure_path": "ja20BpFAPa/figures/figures_9_1.jpg", "caption": "Figure 7: Ablation study about the Learnable opacity map  . Incorporating the opacity map allows our method to accurately identify the positions of opaque objects, enhancing physical simulation and improving view synthesis and obstruction removal. Without the opacity map, severe artifacts appear.", "description": "This figure shows the results of an ablation study on the learnable opacity map used in the Adaptive Image Decomposition module of DC-Gaussian.  The top row shows a reference image and the results of the transmission image with and without the learned opacity map. The bottom row shows a second example with the same comparison. The rightmost column displays the learned opacity map itself, indicating the areas of obstruction identified by the model. The results demonstrate that the inclusion of the learnable opacity map is essential for effectively identifying and handling obstructions, resulting in significantly improved view synthesis and artifact suppression.", "section": "4.5 Ablation Study"}, {"figure_path": "ja20BpFAPa/figures/figures_9_2.jpg", "caption": "Figure 8: Ablation study on G3E module. G3E helps suppress artifacts and reveal sharper details.", "description": "This figure shows an ablation study on the Geometry-Guided Gaussian Enhancement (G3E) module.  The left side shows the results with G3E enabled, demonstrating sharper details and suppressed artifacts, particularly noticeable in the zoomed-in region highlighted in red. The right side shows the results without G3E, showing a noticeable reduction in image clarity and the presence of artifacts.", "section": "4.5 Ablation Study"}, {"figure_path": "ja20BpFAPa/figures/figures_15_1.jpg", "caption": "Figure 9: Comparisons with 3DGS and Zip-NeRF [4] on novel view synthesis show that obstructions violate multi-view consistency, leading to erroneous geometry in 3DGS and Zip-NeRF, as evident in the depth maps. This results in blurry renderings and artifacts. In contrast, our method effectively addresses the ambiguity introduced by obstructions and learns physically reasonable geometry, achieving renderings with fine details.", "description": "This figure compares the novel view synthesis results of three methods: 3DGS, Zip-NeRF, and the proposed DC-Gaussian method. The results show that 3DGS and Zip-NeRF suffer from blurry renderings and artifacts due to inconsistencies in multi-view caused by obstructions.  In contrast, DC-Gaussian produces high-fidelity renderings with fine details by effectively handling the ambiguities introduced by the obstructions.", "section": "4.3 Quantitative Results"}, {"figure_path": "ja20BpFAPa/figures/figures_15_2.jpg", "caption": "Figure 10: We evaluate NeRFRen [16] on our curated dataset. The suboptimal results of NeRFRen are caused by two factors. First, its obstruction modeling cannot address the ambiguity between obstructions and transmission, leading to a failure in image decomposition. Second, its backbone, NeRF, cannot handle large-scale driving scenes, resulting in blurry outputs.", "description": "This figure shows a comparison of the results of NeRFRen on a curated dataset with the ground truth.  The results reveal that NeRFRen struggles to accurately represent obstructions because its model can't handle the ambiguity between obstructions and the transmitted scene.  Additionally, NeRFRen's inability to handle the large scale of driving scenes leads to blurry outputs.", "section": "4.3 Quantitative Results"}, {"figure_path": "ja20BpFAPa/figures/figures_16_1.jpg", "caption": "Figure 11: Trajectories of turning cars, which result in diverse illumination changes.", "description": "This figure shows trajectories of cars making turns. The varying car positions in the scene cause diverse illumination changes and variations in lighting conditions in each frame. This is important for understanding how the model handles different lighting scenarios during training and testing.  The changes highlight the dynamic nature of the dash cam video data and the importance of addressing this aspect in improving 3D scene reconstruction.", "section": "4 Experiments"}, {"figure_path": "ja20BpFAPa/figures/figures_16_2.jpg", "caption": "Figure 6: Comparisons with the image-based reflection removal methods on removing reflections. (a) Reference is a frame in a dash cam video. (b) and (c) are transmission and obstruction decomposed by our method. (d), (e), and (f) are results from previous obstruction removal methods, NIR [32], DSRNet [17] and Liu et al. [27], which are not effective in this scenario. In comparison, our method decomposes the image and synthesizes (b) transmission and (c) obstruction with high fidelity.", "description": "This figure compares the performance of the proposed DC-Gaussian method against other state-of-the-art single image reflection removal methods for removing reflections from dashcam videos. The figure shows that the proposed method effectively decomposes the image into transmission and obstruction components, achieving high fidelity in both components, unlike the other methods which are not effective in this scenario.", "section": "4.3 Quantitative Results"}, {"figure_path": "ja20BpFAPa/figures/figures_16_3.jpg", "caption": "Figure 13: Nerf-in-the-wild fails to separate obstructions from the images. None of the obstructions are accurately represented in the transient image.", "description": "This figure compares the results of a state-of-the-art NeRF model (NeRF-in-the-wild) with the proposed DC-Gaussian method for separating obstructions from dashcam video images.  The figure shows that NeRF-in-the-wild fails to accurately separate static and transient components of the scene, particularly the obstructions on the windshield.  In contrast, the DC-Gaussian method is designed to explicitly handle these obstructions, leading to improved separation and clearer representation of the scene.", "section": "4.4 Qualitative Results"}]