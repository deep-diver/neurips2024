[{"type": "text", "text": "Improved learning rates in multi-unit uniform price auctions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Marius Potfer\u22171,2 Dorian Baudry3 Hugo Richard1 Vianney Perchet1 ", "page_idx": 0}, {"type": "text", "text": "Cheng Wan2 ", "page_idx": 0}, {"type": "text", "text": "1 Joint team Fairplay, ENSAE, and Criteo AI LAB   \n2 EDF R&D   \n3 Department of Statistics, University of Oxford ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Motivated by the strategic participation of electricity producers in electricity dayahead market, we study the problem of online learning in repeated multi-unit uniform price auctions focusing on the adversarial opposing bid setting. The main contribution of this paper is the introduction of a new modeling of the bid space. Indeed, we prove that a learning algorithm leveraging the structure of this problem achieves a regret of $\\tilde{O}(K^{4/3}T^{2/3})$ under bandit feedback, improving over the bound of $\\tilde{O}(K^{7/4}T^{3/4})$ previously obtained in the literature. This improved regret rate is tight up to logarithmic terms. Inspired by electricity reserve markets, we further introduce a different feedback model under which all winning bids are revealed. This feedback interpolates between the full-information and bandit scenarios depending on the auctions\u2019 results. We prove\u221a that, under this feedback, the algorithm that we propose achieves regret $\\tilde{O}(\\bar{K}^{5/2}\\sqrt{T})$ . ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The short-term electricity market, based on a wholesale market, is organized as an auction that determines the quantity each electricity producer needs to produce and the price at which electricity is sold. They participate, in this market by submitting prices for each kilowatt-hour they can produce. They have the opportunity to participate strategically, submitting prices that can deviate from their actual production cost. While several regulatory and practical constraints apply, this market is essentially a multi-unit auction of identical items (Willems & Yu, 2022). These auctions are extensively studied and utilized for resource allocation. Several pricing rules can be applied, the most common being discriminatory pricing, uniform pricing (Ausubel et al., 2014), and Vickrey\u2013Clarke\u2013Groves (VCG) auctions (Sessa et al., 2017). Although the VCG auction is known for its truthful bidding property, it is seldom implemented due to its complexity. Instead, uniform or discriminatory pricing are often preferred, particularly in treasury auctions (Khezr & Cumpston, 2022) and their procurement variations in electricity reserve markets (Viehmann et al., 2021). ", "page_idx": 0}, {"type": "text", "text": "The wholesale electricity market is held every day and, structurally, the electricity producers who participate in the mechanism remain the same for multiple years. This represents an opportunity to study how producers can be strategic in the way they adapt to other\u2019s bidding strategies. We therefore focus on the problem of online bidding in a repeated multi-unit auction. This setting allows us to model how an agent participating multiple times to an auction with the same other participants can leverage the information he has obtained during past auctions. This family of settings, of which a review is available in (Nedelec et al., 2022), was first investigated for learning from the point of view of the auctioneer and was then applied to bidders learning how to bid optimally. ", "page_idx": 0}, {"type": "text", "text": "Online learning in multi-unit auctions with uniform pricing (every object is sold at the same price independently of the winner) is studied in (Branzei et al., 2024) while the case of discriminatory pricing is studied in Galgana and Golrezaei, 2023. When the bids of all bidders are revealed after each auction (fu\u221all-information), known regret rates for uniform and discriminatory pricing are of the same order $\\mathcal{O}(\\sqrt{T})$ (Branzei et al., 2024; Galgana & Golrezaei, 2023) where $T$ is the time horizon. When bidders only observe the number of items they win and the price (bandit feedback) the regret upper bounds given in Galgana and Golrezaei, 2023 and Branzei et al., 2024 are of order $\\tilde{\\mathcal{O}}(T^{\\bar{2}/3})$ (for discriminatory pricing) and $\\tilde{\\mathcal{O}}(T^{3/4})$ (for uniform pricing) suggesting that bidding multi-unit auctions with uniform pricing is strictly harder than with discriminatory pricing. Our study shows that this is not the case as we present an algorithm achieving regret $\\tilde{\\mathcal{O}}(\\bar{T}^{\\bar{2}/3})$ with uniform pricing therefore closing the gap between the two settings. ", "page_idx": 1}, {"type": "text", "text": "Auction rules A decision-maker (i.e., the bidder) repeatedly bids in a uniform pricing $K$ -unit auction. The single-shot version of the auction, from the perspective of any participant $i$ whose value of obtaining a $\\mathrm{k^{th}}$ -item is denoted by $v_{i,k}\\in[0,1]$ , proceeds as follows. ", "page_idx": 1}, {"type": "text", "text": "1. Each participant submits a bid profile $(b_{i,k})_{k\\in[K]}\\in B$ , where ", "page_idx": 1}, {"type": "equation", "text": "$$\nB=\\{(b_{k})_{k\\in[K]},{\\mathrm{~such~that~}}1\\geq b_{1}\\geq b_{2}\\geq...\\geq b_{K}\\geq0\\}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "We call $B$ the action space and we denote by ${\\bf b}_{-i}$ the bids from other participants. ", "page_idx": 1}, {"type": "text", "text": "2. The price per item $p\\left(\\mathbf{b}_{i},\\mathbf{b}_{-i}\\right)$ is set either as \u2022 the $K^{\\mathrm{th}}$ highest bid (Last Accepted Bid (LAB) pricing rule), \u2022 the $(K+1)^{\\mathrm{th}}$ highest bid (First Rejected Bid (FRB) pricing rule).   \n3. The participant receives the items they won and pays $p\\left(\\mathbf{b}_{i},\\mathbf{b}_{-i}\\right)$ for each item. Since items are identical, we call allocation $x_{i}\\in[K]:=\\{1,2,...,K\\}$ the number of items participant $i$ receives, formally defined as follows: ", "page_idx": 1}, {"type": "equation", "text": "$$\nx_{i}\\left(\\mathbf{b}_{i},\\mathbf{b}_{-i}\\right):=\\left\\{\\begin{array}{l l}{\\left|\\left\\{k\\in\\left[K\\right]\\mathrm{~s.t.~}b_{i,k}\\geq p\\left(\\mathbf{b}_{i},\\mathbf{b}_{-i}\\right)\\right\\}\\right|\\mathrm{for~the~LAB~rule}}\\\\ {\\left|\\left\\{k\\in\\left[K\\right]\\mathrm{~s.t.~}b_{i,k}>p\\left(\\mathbf{b}_{i},\\mathbf{b}_{-i}\\right)\\right\\}\\right|\\mathrm{for~the~FRB~rule}}\\end{array}\\right..\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "The focus is to design efficient learning algorithms for the decision-maker, i.e., one specific participant $i$ ; we can therefore aggregate bids from other participants as the bid of a single adversary $\\beta:={\\mathbf{b}}_{-i}$ and omit the index $i$ of the learner denoting $\\mathbf{b}:=\\mathbf{b}_{i}$ . This setup gives rise to the quasilinear utility u(b, \u03b2) = lx=(b1, $\\begin{array}{r}{u(\\mathbf{b},\\beta)=\\sum_{l=1}^{x(\\mathbf{b},\\beta)}\\left[v_{l}-p(\\mathbf{b},\\beta)\\right]}\\end{array}$ . ", "page_idx": 1}, {"type": "text", "text": "In the remainder of this paper, we adopt the LAB pricing rule. The techniques and theoretical proofs can be adapted from one setup to the other with little change. In the absence of specific mention of a pricing rule, our results can be applied to both auction types. . ", "page_idx": 1}, {"type": "text", "text": "Repeated setting As mentioned above, this auction is not played just once, but repeated many times (say, each day). We shall then denote a time horizon $T$ , and assume a different auction is run at each time step $t\\in[T]$ and the objective of the bidder is to maximize their cumulative utility. Quite naturally, the bidder should adjust their bids to the adversary\u2019s behavior, learned from the outcomes of the previous iterations. On the other hand, we assume that the bidder does not need to learn their own values, i.e., the valuations $(v_{k})_{k\\in[K]}$ are known to the bidder and do not change over time. ", "page_idx": 1}, {"type": "text", "text": "We denote by $(\\mathbf{b}^{t})_{t\\in[T]}$ and $(\\beta^{t})_{t\\in[T]}$ respectively the sequences of bids of the player and of the adversary, and by $p^{t^{\\ast}}{:=}\\ p\\left(\\mathbf{b}^{t},\\bar{\\beta}^{t}\\right)$ and $\\dot{x^{t}}:=\\,x\\,\\mathbf{\\dot{\\,}}\\big(\\mathbf{b}^{t},\\beta^{t}\\big)$ the price and allocation at time $t$ . The utility of the bidder after the auction $t\\,\\in\\,[T]$ is then defined as $\\begin{array}{r}{u(\\mathbf{b}^{t},\\beta^{t})\\,=\\,\\sum_{l=1}^{x^{t}}\\left(v_{l}-p^{t}\\right)}\\end{array}$ . As standard in online learning, we evaluate the performance of a learning (bidding) strategy through its regret, defined as follows ", "page_idx": 1}, {"type": "equation", "text": "$$\nR_{T}=\\operatorname*{sup}_{\\mathbf{b}\\in B}\\sum_{t=1}^{T}u(\\mathbf{b},\\beta^{t})-\\mathbb{E}\\left[\\sum_{t=1}^{T}u(\\mathbf{b}^{t},\\beta^{t})\\right]\\;,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where the expectation is taken over the randomness of the algorithm generating the bids ${\\bf{b}}^{t}$ . Maximizing the utility of the bidder is equivalent to minimizing the regret. ", "page_idx": 1}, {"type": "text", "text": "Feedback The bidders can improve their strategy using the information they receive after each iteration of the auction. The type of feedback they receive represents their knowledge about the bids of the adversary. In the literature, two common types of feedback are considered (Cesa-Bianchi et al., 2023), ", "page_idx": 2}, {"type": "text", "text": "1. the bandit feedback where the bidder\u2019s allocation $x_{t}$ is revealed and the price $p_{t}$ is only revealed if $x_{t}>0$ , and 2. the full information feedback where all the bids emitted by all participants are revealed. ", "page_idx": 2}, {"type": "text", "text": "Inspired by the terms of commodity electricity markets in several European countries including Germany and France, similarly to Karaca et al., 2020, we shall introduce and study a third partial feedback specific to multi-unit auctions, ", "page_idx": 2}, {"type": "text", "text": "3. the all-winner feedback: the allocation, the price, and all the winning bids are revealed to the bidder. ", "page_idx": 2}, {"type": "text", "text": "Remark 1. With a uniform discretization of the bidding space $B$ , learning to bid in multi-unit uniform auctions can be recast as a special instance of a combinatorial bandit problem. In the latter, the decision maker sequentially selects multiple arms out of $N$ available, i.e., picking at each stage an action in some admissible subset of $\\{0,\\dot{1}\\}^{N}$ . Using off-the-shelf combinatorial bandit algorithms, that do not leverage the relevant structure of repeated auctions, would end up in a highly inefficient and sub-optimal procedure (see Section 2). Our approach is different; in essence, we reduce the complex combinatorial problem by expressing the utility objective as a polynomial (in $K$ and $T$ ) sum of simpler functions. ", "page_idx": 2}, {"type": "text", "text": "Related Work Multiple-unit auctions of indivisible identical items have been extensively studied in their static settings. In particular, how the pricing rules (discriminatory, uniform, VCG) influence revenue (Ausubel et al., 2014), social welfare (Birmpas et al., 2019; De Keijzer et al., 2013), or price stability (Anderson & Holmberg, 2018). Their use in the context of electricity markets is common and similar questions are being studied with this specific application in mind (Akbari-Dibavar et al., 2020; Cramton & Stoft, 2006; Fabra et al., 2006; Son et al., 2004) ", "page_idx": 2}, {"type": "text", "text": "The repeated setting of auctions, and specifically the use of online learning procedure inspired by Multi Armed Bandits has received lots of attention in the last decade. First studied from the point of view of the auctioneer: Blum et al., 2004 studied maximizing auction revenue, Cesa-Bianchi et al., 2014 and Kanoria and Nazerzadeh, 2014 specifically focused on learning reserve prices. Learning to bid, the bidder\u2019s problem, was considered later on, initially in single-item auctions. Second price auctions facing either adversarial or stochastic highest opposing bids were studied in Weed et al., 2016, and in a contextual, budget-constrained setting by Flajolet and Jaillet, 2017. Balseiro et al., 2019 considered the first price auction with adversarial opposing bids leading to optimal regret rates of $\\tilde{\\mathcal{O}}(T^{2/3})$ in the known valuation and contextual setting. ", "page_idx": 2}, {"type": "text", "text": "First mentioned in Feng et al., 2018 for unit demand, multiple unit auctions as online learning problems only recently started to be considered as their own topic of interest. Discriminatory pricing and uniform pricing resp\u221aectively studied in Galgana and Golrezaei, 2023 and Branzei et al., 2024 can be learned with $\\tilde{\\mathcal{O}}(\\sqrt{T})$ in the full-information setting. Under bandit feedback, the former achieves $\\tilde{\\mathcal{O}}(K T^{2/3})$ regret rates in discriminatory pricing and the latter $\\tilde{\\mathcal{O}}(K^{7/4}T^{3/4})$ regret rates with uniform pricing. Compared to single unit auctions, the combinatorial nature of the action space in $K$ -unit auctions makes it a harder learning problem. Branzei et al., 2024 makes use of a cautiously designed equivalent action space represented as a Directed Acyclic Graph (DAG) to address the combinatorial limitation and to design an algorithm guaranteeing the aforementioned regret bounds. ", "page_idx": 2}, {"type": "text", "text": "The effects of specific feedback on the ability to achieve lower regret rates have also raised some interest. Feng et al., 2018 studied the effects of \u201dWin Only\u201d feedback in a more general auction setting. More recently, Cesa-Bianchi et al., 2023 focused on feedback transparency. They characterize gaps in the regret rates t\u221ahat can be achieved depending on the amount of feedback received, getting three separate rates $O(\\sqrt{T})$ , ${\\cal O}(T^{2/3})$ and $\\Omega(T)$ depending on the feedback considered. The work of Karaca et al., 2020, similarly to the all-winner feedback, studied partial feedback, which lie in between bandit and full-information, motivated by electricity market auctions. ", "page_idx": 2}, {"type": "text", "text": "Contribution We introduce a novel representation of the action space that overcomes the combinatorial complexity introduced by the multiplicity of the bids in $K$ -unit auction. Inspired by the properties of the equivalent action space used by Branzei et al., 2024, we introduce bid-gaps, to further decompose the utility into a sum of independent functions. This decomposition leads to improved regret rates of $\\tilde{\\mathcal{O}}(\\bar{K^{4/3}}T^{2/3})$ under bandit feedback, compared to the known upper bound of $\\tilde{\\mathcal{O}}(K^{7/4}T^{3/4})$ . These improved bounds match, in terms of $T$ , the rates $\\tilde{\\mathcal{O}}(K T^{2/3})$ achievable in discriminatory pricing. We notice a reduction to simpler auctions which bear an $\\Omega(T^{2/3})$ lower bound on the regret, answering the open question of the optimal rates dependency in $T$ in the bandit setting. Motivated by the terms of bid revelation in electricity reserve markets in several European countries including Germany and France, a novel feedback structure is considered, which lies in between bandit feedback and full information. This feedback, which we call all-\u221awinner, reveals all the winning bids of the action. We propose an algorithm that achieves a $\\tilde{\\mathcal{O}}(K^{5/2}\\sqrt{T})$ regret, alm\u221aost matching the regret rates under full information up to a factor $K$ , while the lower bound of $\\Omega(K\\sqrt{T})$ proved by Branzei et al., 2024 for the full-information feedback, naturally extend to this setting. We summarize our results in Table 1 below. ", "page_idx": 3}, {"type": "table", "img_path": "UN7nXLeh9D/tmp/e50eea993db93895feb259fba13feddb52c62f945cb2d07ddef38292e6737c62.jpg", "table_caption": ["Table 1: Regret Rates in multi-unit uniform price auction. \u22c6holds in the LAB pricing rule setting "], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "2 Action space ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We first motivate the new cautiously designed action space, and provide intuitions on how it is constructed and its main properties. We then formalize its definition. ", "page_idx": 3}, {"type": "text", "text": "Motivation for an alternative representation Usual techniques such as uniform discretization of the action space as in (Feng et al., 2018) might lead to consider the subset of non-increasing sequences on this discretization, denoted by $\\begin{array}{r}{B_{\\epsilon}\\stackrel{\\smile}{\\subset}\\big\\{0,\\epsilon,2\\epsilon,...,\\big(\\lfloor\\frac{1}{\\epsilon}\\rfloor-1\\big)\\epsilon,\\lfloor\\frac{1}{\\epsilon}\\rfloor\\epsilon\\big\\}^{K}}\\end{array}$ . Without loss of generality, we shall assume in the following that $1/\\epsilon$ is an integer. The main downside of this representation is that the size of $B_{\\epsilon}$ is exponential and thus, without any further properties of the problem leveraged, this would lead to arbitrarily bad regret rates $\\tilde{\\mathcal{O}}(T^{\\frac{K+1}{K+2}})$ in bandit setting. Even though we can restrict the available action to reasonable ones (ie undominated strategies 6) this isn\u2019t enough to achieve improved rates in general. ", "page_idx": 3}, {"type": "text", "text": "Branzei et al., 2024 proposed a Directed Acyclic Graph (DAG) equivalent of the action space $B_{\\epsilon}$ to overcome this combinatorial limitation. They use the decomposition of the utility into a sum of independent functions, depending only on pairs of consecutive bids (the edges in their graphs), to reduce the combinatorial complexity to only 2 (instead of $K$ ), and thus achieved an $\\tilde{O}(\\bar{K}^{7/4}T^{3/4})$ regret bound under bandit feedback. Motivated by the breakthrough enabled by such a representation of the action space, we consider a new equivalent action space $H_{\\epsilon}$ , introduced in Equation 5. This new action space allows to leverage more precisely the regularity of the utility with respect to the bidder\u2019s choice of bids, which in turn leads to improved regret bounds under bandit feedback, presented in Theorem 1. ", "page_idx": 3}, {"type": "text", "text": "2.1 Action space tailored to the outcomes ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We now provide intuitions on the utility regularity that will be leveraged. We start by observing that, for a given auction, the price is either set by one of the bidder\u2019s bid or by a bid from the adversary. ", "page_idx": 3}, {"type": "text", "text": "Assume that the bidder bids $(b_{1},...,b_{K})\\,\\in\\,B_{\\epsilon}$ , and that the price is $b_{k}$ for some $k\\,\\in\\,[K]$ . Then, we claim that many bid profiles would have led to the same outcome. Indeed, any bid profile (from the bidder) with the same $k^{\\mathrm{th}}$ bid $b_{k}$ , leads to the same outcome. In the alternative case, where the adversary sets the price, if the bidder wins $k$ items (i.e., the $K-k$ adversary\u2019s bid $\\beta_{K-k}^{t}$ sets the price), then any bid profile satisfying $b_{k}\\geq\\beta_{K-k}^{t}\\geq b_{k+1}$ leads to the same outcome. ", "page_idx": 3}, {"type": "text", "text": "Notice that in the two aforementioned cases of regularities of the utility, all bids $\\textbf{b}\\in\\~B_{\\epsilon}$ which would lead to the same outcome share one of the following properties: for a specific $k$ and $j$ , ", "page_idx": 4}, {"type": "text", "text": "\u2022 in the first case : $b_{k}=j\\epsilon$ , \u2022 in the second case : $b_{k}^{\\ i}\\geq(j+1)\\epsilon\\geq\\beta_{K-k}^{t}\\geq j\\epsilon\\geq b_{k+1}.$ ", "page_idx": 4}, {"type": "text", "text": "For simplicity, we shall assume that the bids of the decision-maker belong to the $\\epsilon$ -discretization, i.e., $(b_{1},...,b_{K})\\in B_{\\epsilon}$ while the bids of the adversary do not belong to it, in order to avoid ties2. We denote this set $B_{\\setminus\\epsilon}$ , the set of non-increasing sequences of $[0,1]^{K}$ without values in $\\left[{\\frac{1}{\\epsilon}}\\right]$ . ", "page_idx": 4}, {"type": "text", "text": "We, introduce an alternative description of the bidding space $B_{\\epsilon}$ whose structure closely matches the aforementioned regularities\u2019 in order to improve the bidder\u2019s strategy. It leverages new binary variables indicating which of the aforementioned properties a bid $\\mathbf{b}\\in B_{\\epsilon}$ has, they are defined as follows: for any $k\\in[K]$ and $\\begin{array}{r}{j\\in\\left[\\frac{1}{\\epsilon}\\right]}\\end{array}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{h_{k,j}({\\bf b})=1\\left\\{b_{k}=j\\epsilon\\right\\}\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ {h_{k+\\frac{1}{2},j}({\\bf b})=1\\left\\{b_{k}\\geq(j+1)\\epsilon>j\\epsilon\\geq b_{k+1}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Let $\\begin{array}{r}{\\mathcal{K}=\\left\\{1,\\frac{3}{2},2,...,K-1,\\frac{2K-1}{2K},K\\right\\}}\\end{array}$ and $\\begin{array}{r}{\\mathcal{I}_{\\epsilon}=\\left[\\frac{1}{\\epsilon}\\right]}\\end{array}$ . For any $\\mathbf{b}\\in B_{\\epsilon}$ , we define the pseudo-bid $\\mathbf{h_{b}}$ to be the list of these binary variable $h_{k,j}$ with $k$ $;\\bar{j}\\in K\\times\\mathcal{I}$ , such that $h_{k,j}(\\mathbf{b})=1$ , ordered in lexicographic order, increasingly in $k$ and decreasingly in $j$ . We naturally define $H_{\\epsilon}$ the pseudo-bid space generated by the bid space $B_{\\epsilon}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\nH_{\\epsilon}=\\{\\mathbf{h_{b}}|\\mathbf{b}\\in B_{\\epsilon}\\}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Lemma 1. For each pseudo-bid $\\mathbf{h}\\in H_{\\epsilon}$ , there exists a unique $\\mathbf{b}\\in B_{\\epsilon}$ such that $\\mathbf{h}=\\mathbf{h}_{\\mathbf{b}}$ . This therefore defines a bijective mapping between $H_{\\epsilon}$ and $B_{\\epsilon}$ . ", "page_idx": 4}, {"type": "text", "text": "Proof. From the expression of $H_{\\epsilon}$ in (5), it is clear that the mapping $\\mathbf{b}\\mapsto\\mathbf{h}_{\\mathbf{b}}$ , is surjective. Let $\\mathbf{h}\\in H_{\\epsilon}$ , there exists $\\mathbf{b}=\\left\\{b_{1},...,b_{K}\\right\\}\\in B_{\\epsilon}$ such that $\\mathbf{h}=\\mathbf{h}_{\\mathbf{b}}$ . Let $j_{k}\\in\\mathcal{I}_{\\epsilon}$ such that $b_{k}=j_{k}\\epsilon$ , for all $k\\,\\in\\,[K]$ , we have $h_{k,j_{k}}\\in\\mathbf{h}$ . If there exists another bid $\\tilde{\\mathbf{b}}\\,=\\,\\{\\tilde{b}_{1},...,\\tilde{b}_{K}\\}\\,\\in\\,B_{\\epsilon}$ such that $\\mathbf{h}=\\mathbf{h}_{\\tilde{\\mathbf{b}}}$ , for all $k\\in[K],h_{k,j_{k}}(\\tilde{\\mathbf{b}})=1.$ Therefore (3) yields $\\tilde{b}_{k}\\,=\\,j_{k}\\epsilon\\,=\\,b_{k}$ for all $k\\,\\in\\,[K]$ . This proves unicity and therefore that the mapping is bijective. \u53e3 ", "page_idx": 4}, {"type": "text", "text": "The following characterization of the pseudo-bid space directly follows from Lemma 1. ", "page_idx": 4}, {"type": "text", "text": "Corollary 1. Given a bid $\\mathbf{b}=(b_{i})_{i\\in[K]}\\in B_{\\epsilon}$ and the pseudo-bid $\\mathbf{h}_{\\mathbf{b}}\\in H_{\\epsilon}$ , we have the following: for all $k,j\\in[K]\\times\\mathcal{T}_{\\epsilon}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{b_{k}=j\\epsilon\\iff h_{k,j}\\in\\mathbf{h_{b}}}\\\\ &{b_{k}\\geq(j+1)\\epsilon>j\\epsilon\\geq b_{k+1}\\iff h_{k+\\frac{1}{2},j}\\in\\mathbf{h_{b}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To provide further intuition, Figure 1a and Figure 1b show how two corresponding bids might be represented in $B_{\\epsilon}$ and $H_{\\epsilon}$ . The bids (6) are represented by circles, while the bid-gaps (7) are ellipses. ", "page_idx": 4}, {"type": "text", "text": "2.2 Utility decomposition ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Leveraging the new action space, we define the utility, price, and allocation function on $H_{\\epsilon}$ resulting from the bijective map with $B_{\\epsilon}$ . Let $\\mathbf{h}\\in H_{\\epsilon}$ and $\\mathbf{b}\\in B_{\\epsilon}$ the unique element of $B_{\\epsilon}$ such that $\\mathbf{h}=\\mathbf{h}_{\\mathbf{b}}$ . For all $\\beta\\in B_{\\backslash\\epsilon}$ , we define the utility as $u_{H}(\\mathbf{h_{b}},\\beta):=u(\\mathbf{b},\\beta)$ , the price $x_{H}({\\mathbf{h}}_{\\mathbf{b}},\\beta):=x({\\mathbf{b}},\\beta)$ and the allocation $p_{H}(\\mathbf{h}_{\\mathbf{b}},\\beta):=p(\\mathbf{b},\\beta)$ ", "page_idx": 4}, {"type": "text", "text": "The following additional set notation, which matches a binary variable $h_{k,j}$ to its corresponding price range, allows for unified descriptions : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{P}_{\\epsilon}(h_{k,j}):=\\textstyle\\{j\\epsilon\\}\\textstyle\\qquad\\mathrm{if~}k\\mathrm{~is~an~integer}\\,\\,\\,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We now explicitly show how the pseudo-bid space is well suited to capture the regularity of the outcomes of the auction (and therefore of the utility) mentioned above. To be more precise, the ", "page_idx": 4}, {"type": "image", "img_path": "UN7nXLeh9D/tmp/6637ffd115179d6d566cc3a3177083278f0c0e9d4b6e82027138cdac629f8e5e.jpg", "img_caption": ["Figure 1: Graph representation of action spaces $B_{\\epsilon}$ (Branzei et al., 2024) and $B(\\mathcal{P}_{\\epsilon})$ (this paper) "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "following Lemma 2 states that within a pseudo-bid profile $\\mathbf{h}$ , a pseudo-bid $h_{k,j}$ can be credited for the outcome: any other pseudo-bid profile containing this pseudo bid would have lead to the same outcome. ", "page_idx": 5}, {"type": "text", "text": "Lemma 2. Let $\\beta\\in B_{\\backslash\\epsilon}$ and $(k,j)\\in\\mathcal{K}\\times\\mathcal{T}_{\\epsilon}$ . There exists $C\\in\\{0,1\\}$ , such that for all $\\mathbf{h}\\in H_{\\epsilon}$ with $h_{k,j}\\in{\\bf h}_{:}$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n1\\{p_{H}({\\bf h},\\beta)\\in{\\mathcal{P}}_{\\epsilon}(h_{k,j})\\}\\cap\\{x_{H}({\\bf h},\\beta)=\\lfloor k\\rfloor\\}=C\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and if $C=1$ , $p_{H}(\\mathbf{h},\\beta)$ is also constant on $\\{\\mathbf{h}\\in H_{\\epsilon}:h_{k,j}\\in\\mathbf{h}\\}$ ", "page_idx": 5}, {"type": "text", "text": "Proof. Let $\\mathbf{b}\\in B_{\\epsilon}$ such that $h_{k,j}\\in\\mathbf{h_{b}}$ . If $k$ is integer, then Corollary 1 yields $b_{k}=j\\epsilon$ , hence we get 1{ ${\\mathfrak{p}}_{H}(\\mathbf{h},{\\boldsymbol{\\beta}})=j\\epsilon\\}\\cap\\left\\{x_{H}(\\mathbf{h},{\\boldsymbol{\\beta}})=k\\right\\}=1\\{\\beta_{K-k}>\\}$ $x_{H}(\\mathbf{h},\\stackrel{\\cdot}{\\beta})=k\\}=1\\{\\beta_{K-k}>j\\epsilon=b_{k}>\\beta_{K-k+1}$ } which only depends on $k,j$ and $\\beta$ . If $k$ is half-integer, then Corollary 1 yields $b_{k+1}<j\\epsilon<(j+1)\\epsilon<b_{k}$ , hence we get $\\mathbb{1}\\{p_{H}(\\mathbf{h},\\beta)=\\mathcal{P}_{\\epsilon}(h_{k,j})\\}\\,\\bar{\\cap}\\,\\{x_{H}(\\mathbf{h},\\beta)=\\dot{k}\\}=\\mathbb{1}\\{j\\epsilon<\\beta_{K-k}<(\\ddot{j}+1)\\epsilon\\}$ which also only depends on $k,j$ and $\\beta$ . It is straightforward to see that when the indicator function takes value one, the price is constant with value $j\\epsilon$ for the integer case and $\\beta_{K-k}$ in the half integer case. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Lemma 2 allows us to exhibit a key property of the utility on the pseudo-bid space: it can be decomposed into a sum of sub-utilities (defined in Equation 11), each of which only depends on one of the components of $\\mathbf{h}$ . ", "page_idx": 5}, {"type": "text", "text": "Lemma 3. Let $\\mathbf{h}\\in H_{\\epsilon}$ and $\\beta\\in B_{\\backslash\\epsilon}$ . The utility of the bidder rewrites as a sum of sub-utilities: ", "page_idx": 5}, {"type": "equation", "text": "$$\nu_{H}({\\bf h},\\beta)=\\sum_{h_{k,j}\\in{\\bf h}}w(h_{k,j},\\beta),\\ w i t h\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$$\nw(h_{k,j},\\beta):=\\mathbb{1}\\left\\{\\{p_{H}({\\bf h},\\beta)\\in{\\mathcal{P}}_{\\epsilon}(h_{k,j})\\}\\cap\\{x_{H}({\\bf h},\\beta)=\\lfloor k\\rfloor\\}\\right\\}\\sum_{l=1}^{\\lfloor k\\rfloor}(v_{l}-p_{H}({\\bf h},\\beta)).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Proof of Lemma 3. $x(\\mathbf h,\\beta)=0$ implies that $u$ as defined in Equation (10) is zero, as expected. For the case where $x(\\mathbf h,\\beta)>0$ , we use that the indicator functions in Equation 11 correspond to disjoint events. Thus, there exists a unique pair $(k,j)\\in\\mathcal{K}\\times\\mathcal{T}_{\\epsilon}$ such that $w(h_{k,j},\\beta)>0$ , furthermore, this sub-utility $w(h_{k,j},\\beta)$ matches the utility $u(\\mathbf{h},\\beta)$ . This concludes the proof. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "While the expression of these indicators in Equation (11) involves the full action h, Lemma 2 shows that they only depend either on the associated bid $h_{k,j}$ . Furthermore, notice that within a given $\\mathbf{h}\\in H_{\\epsilon}$ , the events corresponding to each $h_{k,j}\\;\\in\\;{\\bf h}$ are disjoints and therefore only one can be realized. As a result there is at most one $h\\in\\mathbf{h}$ with positive sub-utility, we denote it $\\bar{h_{\\star}}(\\mathbf h,\\beta)$ . ", "page_idx": 5}, {"type": "text", "text": "3 Learning algorithms and guarantees ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We first present two algorithms and estimators of the utility corresponding to the different feedback settings. We then state the regret rate achieved by these algorithms when used with the introduced estimator, depending on the setting considered, as well as a lower bound on the regret in the bandit setting. To simplify notations, we shall further introduce $u_{H}^{t}(.):=u_{H}(.,\\beta^{t})$ and $\\check{w^{t}}(.):=w(.,\\beta^{t})$ . ", "page_idx": 6}, {"type": "text", "text": "3.1 Algorithm for online learning in K-unit uniform auction ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The regret minimizing algorithm combines two separate procedures, \u2022 An exponential weight update, detailed in Algorithm 1, which creates and updates the weights for each bid and bid-gap at each time step, akin to an EXP3 type algorithm (but non-normalized) (Cesa-Bianchi and Lugosi, 2006,Lattimore and Szepesva\u00b4ri, 2020). \u2022 A sampling procedure, tailored to our action space, described in Algorithm 2, that renormalizes the weights into a probability distribution by using a weight-pushing method, and uses an efficient procedure to sample an action. (Takimoto and Warmuth, 2002). ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Because of the combinatorial structure of the problem, using directly the exponential weight algorithm would be highly inefficient, with a complexity of order $\\mathcal{O}\\big(\\frac{1}{\\epsilon^{K}}\\big)$ to store weights and compute probabilities directly on the action space. The second auxiliary sampling algorithm gets rid off this complexity burden. ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1\u2019s pseudo-code details the exponential weight algorithm used as a building block of the no-regret procedure. It computes weights for each pseudo-bid based on the corresponding subutilities, or their estimated values. These weights are used to sample a pseudo-bid sequence $\\mathbf{h}\\in H_{\\epsilon}$ . ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1: Component based exponential weighting   \nInput: time horizon $T$ , parameters $\\varepsilon>0$ and $\\eta>0$   \nOutput: actions for each time step $\\left(\\mathbf{h}^{1},\\mathbf{h}^{2},\\ldots;\\mathbf{h}^{T-1},\\mathbf{h}^{T}\\right)\\in(H_{\\epsilon})^{T}.$ . Initialize: for $(k,j)\\in\\mathcal{K}\\times\\mathcal{T}_{\\epsilon}$ , set $Q^{0}(h_{k,j})=1$ for $t=1,2,\\ldots,T$ do Sample $\\mathbf{h}^{t}$ using the sampling procedure of Algorithm 2, with input parameters $Q^{t-1}$ ; Receive the utility $u^{t}=u(\\mathbf{h}^{t},\\beta^{t})$ and the feedback. Based on this feedback, define $\\boldsymbol{v}^{t}=\\left\\{\\begin{array}{l l}{\\boldsymbol{w}^{t}=\\boldsymbol{w}(.,\\boldsymbol{\\beta}^{t})}\\\\ {\\hat{\\boldsymbol{w}}^{t}}\\\\ {\\bar{\\boldsymbol{w}}^{t}}\\end{array}\\right.$ in the full-information feedback, see (11) with bandit feedback, see (19) with all-winner feedback, see (20) Update the weights based on the weights $v^{t}$ : for $(k,j)\\in\\mathcal{K}\\mathrm{~}\\mathcal{I}_{\\epsilon}$ do $Q^{t}(h_{k,j})=Q^{t-1}(h_{k,j})\\exp\\big(\\eta v^{t}(h_{k,j})\\big)$ (12) ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 is a sampling procedure and uses a weight-pushing technique (Takimoto and Warmuth, 2002) to efficiently sample pseudo-bids and compute weights and probabilities on $H_{\\epsilon}$ . It is exploiting the lexicographical ordering of the pseudo bid (increasingly in $k$ and decreasingly in $j$ ) which creates a graph-like structure, as illustrated in Figure 1b. It is indeed possible to sample an element of $H_{\\epsilon}$ by repeatedly sampling the next binary variable conditionally on the previous one. To explicit this graph-like structure, we define $s(.)$ the successor function, which given a pseudo-bid $h_{k,j}$ provides the set of possible next element of an action. For $k\\in[K-1],j\\in\\bar{\\mathcal{J}}_{\\epsilon}\\backslash\\{0\\}$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\ns(h_{k+1/2,j}):=\\left\\{h_{k+1/2,j-1},h_{k+1,j}\\right\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "equation", "text": "$$\ns(h_{k,j}):=\\left\\{h_{k+1/2,j-1},h_{k+1,j}\\right\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "equation", "text": "$$\ns(h_{k,0}):=\\{h_{k+1,0}\\}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "As well as the following, which serves as the stopping condition of the sampling: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\forall j\\in\\mathcal{I}_{\\epsilon},\\,\\,s(h_{K,j}):=\\emptyset\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Input: Weights $Q$ for every bids or bid-gap $\\!\\left(h_{k,j}\\right)\\!\\left(k,j\\right)\\!\\in\\!k\\!\\times\\!\\mathcal{I}_{\\epsilon}$ ;   \nOutput: bid vector $\\mathbf{h}\\in H_{\\epsilon}$ ;   \nInitialize : $\\colon k\\gets K-\\frac{1}{2}$ . For all $j\\in\\mathcal{I}_{\\epsilon}$ , $\\Gamma(h_{K,j})\\gets1$ ;   \nwhile $k\\geq1$ do for $j\\in\\mathcal{I}_{\\epsilon}$ do $\\begin{array}{r}{\\ L\\stackrel{}{\\Gamma}(h_{k,j})\\gets\\sum_{h\\in s(h_{k,j})}\\Gamma(h)Q(h)}\\end{array}$ $\\boldsymbol k\\gets\\boldsymbol k-\\frac12$   \n$\\begin{array}{r}{\\Gamma_{0}\\leftarrow\\sum_{j\\in\\left[\\frac{1}{\\epsilon}\\right]}Q(h_{1,j})\\Gamma(h_{1,j});}\\end{array}$   \nSample $h$ according to the probabilities:   \n\u2200j \u2208J\u03f5, P(h = h1,j) = Q(h1,j) \u0393(h\u039310,j);   \n$\\mathbf{h}\\gets\\{h\\}$ ;   \nwhile $s(h)\\neq\\emptyset$ do s $\\begin{array}{r}{\\mathbb{P}(h_{+}=h^{\\prime}|h)=Q(h^{\\prime})\\frac{\\Gamma(h^{\\prime})}{\\Gamma(h)}}\\end{array}$ $h_{+}\\in s(h)$ efmore anltl $h^{\\prime}\\in s(h)$ u;ence $\\mathbf{h}$ , with probability: h \u2190h \u222a{h+}; h \u2190h+; ", "page_idx": 7}, {"type": "text", "text": "The combination of Algorithm 1 and Algorithm 2 leads to the following probabilities, typical of an exponential weight algorithm, on $H_{\\epsilon}$ . For $\\mathbf{h}\\in H_{\\epsilon}$ , ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{P}^{t}(\\mathbf{h})=\\frac{\\exp\\left(\\sum_{n=0}^{t}\\eta u_{H}^{n}(\\mathbf{h})\\right)}{\\sum_{\\mathbf{a}\\in H_{\\epsilon}}\\exp\\left(\\sum_{n=0}^{t}\\eta u_{H}^{n}(\\mathbf{a})\\right)}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "as shown in Appendix B, in Equation 29. ", "page_idx": 7}, {"type": "text", "text": "Estimators With partial feedback (either bandits or all-winner), the bidder does not gather enough information to compute all of the sub-utilities, and it can only do it for a subset of pseudo-bids.They must therefore resort, as it is standard in multi-armed bandit literature, to estimators that should leverage all the information available. Under bandit feedback, only sub-utilities of binary variables which belong to the action played at time $t$ can be computed.- On the other hand, under all-winner feedback, the richer feedback allows to compute sub-utilities for a bigger set of binary variables $h$ , we denote it $A$ and define it in Lemma 4. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4. With the all-winner feedback, the bidder can compute from its feedback the sub-utilities of any pseudo bid in $A(\\mathbf{h}^{t},\\beta^{t})$ , defined as: ", "page_idx": 7}, {"type": "equation", "text": "$$\nA(\\mathbf{h}^{t},\\beta^{t}):=\\left\\{h_{k,j},(k,j)\\in K\\times\\mathcal{I}_{\\epsilon}\\big|\\;s.t.\\;\\;\\{k>x^{t}\\}\\;o r\\left\\{k=x^{t}a n d\\;j\\epsilon\\geq p^{t}\\right\\}\\right\\}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Where $x^{t}:=x_{H}(\\mathbf{h}^{t},\\beta^{t})$ and $p^{t}=p_{H}(\\mathbf{h}^{t},\\beta^{t})$ . ", "page_idx": 7}, {"type": "text", "text": "The formal proof of Lemma 4 is in Appendix C. ", "page_idx": 7}, {"type": "text", "text": "As noted above, within a given pseudo-bid $\\mathbf{h}$ , only one sub-utility can be non-zero. We therefore also define the set of binary variables with non-zero sub-utilities $A_{\\star}({\\bf h}^{t},\\beta^{t})\\ :=\\ \\{h_{k,j}\\ \\in\\qquad\\qquad$ $A(\\mathbf{h}^{t},\\beta^{t})|w(h_{k,j},\\beta^{t})>0\\}$ . ", "page_idx": 7}, {"type": "text", "text": "We can now formally introduce the estimators used by the no-regret procedure. ", "page_idx": 7}, {"type": "text", "text": "Definition 3.1 (Estimators). Let $\\mathbf{h}^{t}\\in{\\cal{H}}_{\\epsilon}$ be the action played by the learner, and $\\beta^{t}\\in B_{\\setminus\\epsilon}$ the bids of the adversary at time $t,$ . For any bid or bid-gap $h$ , we define the sub-utility estimators: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ \\ \\ \\ B a n d i t\\,f e e d b a c k\\,\\hat{w}^{t}(h)=\\mathbb{1}(h=h_{\\star}^{t})\\frac{w^{t}(h)-K}{\\mathbb{P}^{t}(h)},}\\\\ &{\\ \\ \\ \\ \\ A l l\\!-\\!w i n n e r\\,f e e d b a c k\\,\\bar{w}^{t}(h)=\\mathbb{1}\\left(h\\in A_{\\star}^{t}({\\bf h}^{t})\\right)\\frac{w^{t}(h)-K}{\\mathbb{f}^{t}\\sim\\mathcal{B}^{t}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $h_{\\star}^{t}:=h_{\\star}(\\mathbf{h}^{t},\\beta^{t})$ is the sub/pseudo-bid played at time $t$ that has non-zero sub-utility, $B^{t}$ is the probability distribution on $H_{\\epsilon}$ as in (17) and $\\begin{array}{r}{\\mathbb{P}^{\\boldsymbol{\\dot{t}}}(h):=\\sum_{\\mathbf{h}\\in H_{\\epsilon}:h\\in\\mathbf{h}}\\mathbb{P}^{t}(\\mathbf{h})}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "Naturally, estimation of the utility of any action $\\mathbf{h}\\in H_{\\epsilon}$ is done with a simple summation, over $h\\in\\mathbf{h}$ , of these estimates. ", "page_idx": 8}, {"type": "text", "text": "3.2 Regret Analysis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Combining Algorithm 1 and the sampling Algorithm 2, we recover the regret guarantees obtained by (Branzei et al., 2024, Theorem 2) in the same setting for the full-information feedback. We provide a formal statement and proof of this result in the Appendix B, in Theorem 3. We now analyze the performance of the learning procedure for the two other types of feedback. ", "page_idx": 8}, {"type": "text", "text": "Theorem 1. In the repeated $K$ -unit auction with uniform pricing guarantees and under bandit feedback, Algorithm $^{\\,l}$ incurs a regret of at most $\\mathcal{O}\\left(\\dot{K}^{4/3}\\dot{T^{2/3}}\\log\\check{(T)}\\right)$ For any time horizon $T$ , with the choices of $\\textstyle\\epsilon=\\left({\\frac{K}{T}}\\right)^{1/3}$ and $\\begin{array}{r}{\\eta=K^{-1/3}T^{-2/3}\\sqrt{\\log\\left(\\frac{T}{K}\\right)/3}}\\end{array}$ . ", "page_idx": 8}, {"type": "text", "text": "Proof sketch. The aforementioned regret bounds are proved by using a similar analysis as the one in Lattimore and Szepesva\u00b4ri, 2020 to obtain regret bounds of EXP3 algorithm in the adversarial bandits case. We apply this analysis to the discretized action space $H_{\\epsilon}$ and bound the additional cost of using a discretization separately. Then we choose a discretization size $\\epsilon$ to minimize the total regret. ", "page_idx": 8}, {"type": "text", "text": "The improvement over known regret bounds in Branzei et al., 2024 results from the decomposition of the utility into sub-utilities. Since these sub-utilities only depend on one bid or bid-gap, the variance of the estimators (cf Lemma 9) only depend on the possible number of bids or bid-gaps ( of order $\\frac{1}{\\epsilon}$ ) not the number of bid profiles ( of order $\\scriptstyle{\\frac{1}{\\epsilon^{K}}}.$ ). This is akin to why combinatorial bandits under semi-bandit feedback (Audibert et al., 2014) achieve better regret than under bandit-feedback. ", "page_idx": 8}, {"type": "text", "text": "Theorem 2. For any time horizon $T$ , using Algorithm 1 in the repeated ${\\cal K}$ -unit\u221a auction with uniform pricing guarantees, under all-winner feedback, a regret of at most $\\mathcal{O}\\left(K^{5/2}\\sqrt{T}\\log(T)\\right)$ with $\\eta=$ $\\dot{K}^{-1}\\check{T}^{-1/2}$ and $\\epsilon=K^{3/2}T^{1/2}$ . ", "page_idx": 8}, {"type": "text", "text": "Proof sketch. The proof of these bounds in the all-winner feedback follows closely the analysis used for the bandit feedback. Better bounds are achieved in comparison to the bandit\u2019s feedback thanks to the lower variance of the estimator defined in (10), proved in Lemma 10. Intuitively, this comes from the ability to observe the realized utility more often, allowed by the richer feedback. We exhibit this by using tools used in bandits with graph feedback (Alon et al., 2017). \u53e3 ", "page_idx": 8}, {"type": "text", "text": "Regret lower bound We provide a matching lower bound on the regret of any online learning algorithm (Lemma 5), in the bandit feedback setting, by extending a result from (Balseiro et al., 2019) in the context of single price auctions. This partially answers an open question raised by Branzei et al., 2024 regarding the achievable learning rate in the bandit setting for the problem that we consider. ", "page_idx": 8}, {"type": "text", "text": "Lemma 5. Any online learning procedure must incur $\\Omega(T^{2/3})$ regret in multi-unit uniform auction with the Last Accepted Bid rule under bandit feedback Bid pricing rule. ", "page_idx": 8}, {"type": "text", "text": "This stems from the fact that against an adversary that only plays bids with value 1 except for its last bid, the auction is essentially a first-price auction. ", "page_idx": 8}, {"type": "text", "text": "Proof. We extend the lower bound on the regret of the first price auction in Balseiro et al., 2019. At time $t$ , let $\\beta^{t}\\,=\\,\\{1,1,...,1,h^{t}\\}$ be the bid of the adversary, let the valuation of the learner be $\\textit{v}=\\,(1,0,..,0)$ and denote $\\mathbf{b}^{t}~=~(b_{1}^{t},...,b_{k}^{t}){\\ \\in}~B$ the learner\u2019s bid. We only consider sensible bids, such that $b_{i}^{t}\\ >\\ 0\\quad\\Longleftrightarrow\\quad\\dot{i}\\ =\\ \\mathrm{i}$ , because they are dominating strategies. The learner\u2019s utility is $u({\\bf h},\\beta)=\\mathbb{1}\\left\\{b_{1}^{t}>h^{t}\\right\\}(1-b_{1}^{t})$ , and the bandits feedback, $(x^{t},\\Bar{1}\\;\\{x^{t}>0\\}\\;p^{t})$ is $:\\left(\\mathbb{1}\\left\\{b_{1}^{t}>h^{t}\\right\\},\\mathbb{1}\\left\\{b_{1}^{t}>h^{t}\\right\\}b_{1}^{t}\\right)$ which coincides with both the utility and the bandits feedback of the first price auction with value 1. ", "page_idx": 8}, {"type": "text", "text": "This specific instance of the repeated $K$ -unit auction therefore coincides with the repeated first price auction with opposing bid $h^{t}$ at time $t$ , which can be any instance of the first price auction. Therefore if no learning algorithm can guarantee better regret than ${\\mathcal{O}}(T^{2/3})$ in the latter problem, no algorithm can guarantee better regret than ${\\mathcal{O}}(T^{2/3})$ in the former. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "4 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We provided the first no-regret algorithm achieving optimal rates in $T$ for the $K$ -unit uniform auction under bandit, full information, and all winner feedback. The techniques and theoretical tools presented can be applied to obtain similar regret guarantees in the adversarial bid setting with random valuation, under the assumption that the valuation and opposing bids are independent. An interesting open question is whether similar rates can be achieved in a contextual setting (when valuations changing at each round are observed before each play). The obtained regret rates match the ones obtained in the discriminatory price auction, a commonly compared auction mechanism, up to a factor $\\mathcal{O}(K^{\\frac{1}{3}})$ . This raises the question of whether this gap can be closed or if a lower bound showing a separation in achievable regret rates exists. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Dorian Baudry thanks the support of the French National Research Agency: ANR-19-CHIA-02 SCAI, ANR-22-SRSE-0009 Ocean, and ANR-23-CE23-0002 Doom; and of the European Research Council (GTIR project). ", "page_idx": 9}, {"type": "text", "text": "This research was supported in part by the French National Research Agency (ANR) in the framework of the PEPR IA FOUNDRY project (ANR-23-PEIA-0003) and through the grant DOOM ANR-23-CE23-0002. It was also funded by the European Union (ERC, Ocean, 101071601). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Akbari-Dibavar, A., Mohammadi-Ivatloo, B., & Zare, K. (2020). Electricity market pricing: Uniform pricing vs. pay-as-bid pricing. Electricity Markets: New Players and Pricing Uncertainties, 19\u201335.   \nAlon, N., Cesa-Bianchi, N., Gentile, C., Mannor, S., Mansour, Y., & Shamir, O. (2017). Nonstochastic multi-armed bandits with graph-structured feedback. SIAM Journal on Computing, 46(6), 1785\u20131826. https://doi.org/10.1137/140989455   \nAnderson, E., & Holmberg, P. (2018). Price instability in multi-unit auctions. Journal of Economic Theory, 175, 318\u2013341.   \nAudibert, J.-Y., Bubeck, S., & Lugosi, G. (2014). Regret in online combinatorial optimization. Mathematics of Operations Research, 39(1), 31\u201345.   \nAusubel, L. M., Cramton, P., Pycia, M., Rostek, M., & Weretka, M. (2014). Demand Reduction and Inefficiency in Multi-Unit Auctions. The Review of Economic Studies, 81(4), 1366\u20131400. https://doi.org/10.1093/restud/rdu023   \nBalseiro, S., Golrezaei, N., Mahdian, M., Mirrokni, V., & Schneider, J. (2019). Contextual bandits with cross-learning. Advances in Neural Information Processing Systems, 32.   \nBirmpas, G., Markakis, E., Telelis, O., & Tsikiridis, A. (2019). Tight welfare guarantees for pure nash equilibria of the uniform price auction. Theory of Computing Systems, 63, 1451\u20131469.   \nBlum, A., Kumar, V., Rudra, A., & Wu, F. (2004). Online learning in online auctions. Theoretical Computer Science, 324(2-3), 137\u2013146.   \nBranzei, S., Derakhshan, M., Golrezaei, N., & Han, Y. (2024). Learning and collusion in multi-unit auctions. Advances in Neural Information Processing Systems, 36.   \nCesa-Bianchi, N., Cesari, T., Colomboni, R., Fusco, F., & Leonardi, S. (2023). The role of transparency in repeated first-price auctions with unknown valuations. arXiv preprint arXiv:2307.09478.   \nCesa-Bianchi, N., Gentile, C., & Mansour, Y. (2014). Regret minimization for reserve prices in second-price auctions. IEEE Transactions on Information Theory, 61(1), 549\u2013564.   \nCesa-Bianchi, N., & Lugosi, G. (2006). Prediction, learning, and games. Cambridge university press.   \nCramton, P., & Stoft, S. (2006). Uniform-price auctions in electricity markets. Elsevier Science.   \nDe Keijzer, B., Markakis, E., Sch\u00a8afer, G., & Telelis, O. (2013). Inefficiency of standard multi-unit auctions. European Symposium on Algorithms, 385\u2013396.   \nFabra, N., von der Fehr, N.-H., & Harbord, D. (2006). Designing electricity auctions. The RAND Journal of Economics, 37(1), 23\u201346.   \nFeng, Z., Podimata, C., & Syrgkanis, V. (2018). Learning to bid without knowing your value. Proceedings of the 2018 ACM Conference on Economics and Computation, 505\u2013522. https: //doi.org/10.1145/3219166.3219208   \nFlajolet, A., & Jaillet, P. (2017). Real-time bidding with side information. Neural Information Processing Systems. https://api.semanticscholar.org/CorpusID:1863793   \nGalgana, R., & Golrezaei, N. (2023). Learning in repeated multi-unit pay-as-bid auctions. arXiv preprint arXiv:2307.15193.   \nKanoria, Y., & Nazerzadeh, H. (2014). Dynamic reserve prices for repeated auctions: Learning from bids. Web and Internet Economics: 10th International Conference, WINE 2014, Beijing, China, December 14-17, 2014. Proceedings 10, 232\u2013232.   \nKaraca, O., Sessa, P. G., Leidi, A., & Kamgarpour, M. (2020). No-regret learning from partially observed data in repeated auctions. IFAC-PapersOnLine, 53(2), 14\u201319.   \nKhezr, P., & Cumpston, A. (2022). A review of multiunit auctions with homogeneous goods. Journal of Economic Surveys, 36(4), 1225\u20131247.   \nLattimore, T., & Szepesva\u00b4ri, C. (2020). Bandit algorithms. Cambridge University Press.   \nNedelec, T., Calauze\\`nes, C., El Karoui, N., Perchet, V., et al. (2022). Learning in repeated auctions. Foundations and Trends\u00ae in Machine Learning, 15(3), 176\u2013334.   \nSessa, P. G., Walton, N., & Kamgarpour, M. (2017). Exploring the vickrey-clarke-groves mechanism for electricity markets. IFAC-PapersOnLine, 50(1), 189\u2013194.   \nSon, Y. S., Baldick, R., Lee, K.-H., & Siddiqi, S. (2004). Short-term electricity market auction game analysis: Uniform and pay-as-bid pricing. IEEE Transactions on Power Systems, 19(4), 1990\u20131998.   \nTakimoto, E., & Warmuth, M. K. (2002). Path kernels and multiplicative updates. International Conference on Computational Learning Theory, 74\u201389.   \nViehmann, J., Lorenczik, S., & Malischek, R. (2021). Multi-unit multiple bid auctions in balancing markets: An agent-based q-learning approach. Energy economics, 93, 105035.   \nWeed, J., Perchet, V., & Rigollet, P. (2016). Online learning in repeated auctions. Conference on Learning Theory, 1562\u20131583.   \nWillems, B., & Yu, Y. (2022). Bidding and investment in wholesale electricity markets: Pay-asbid versus uniform-price auctions. Tilburg University, Toulouse School of Economics and CERRE. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "A Problem-specific simplifications ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "This section focuses on characterizing undominated strategies and showing that when a learner plays on an $\\epsilon$ -discretization of the bid interval $[0,1]$ assuming ties never occur is without loss of generality. ", "page_idx": 11}, {"type": "text", "text": "A.1 Dominated strategies ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Since the scale of the bid space is a deciding factor in the rates of regret we obtain, it is useful to analyze the utility functions of the learner. Indeed, for the learning procedure, it can be useful, to restrict ourselves from the start to bids which can potentially be optimal. We show next that, under certain condition on the values of the learner, we can restrict the bid space $B$ . ", "page_idx": 11}, {"type": "text", "text": "Lemma 6. Let $\\{v_{1},v_{2},...,v_{k}\\}$ be the valuations of the learner. Then for any bids $\\mathbf{b}=\\left\\{b_{1},...,b_{K}\\right\\}\\in$ $B$ such that there exists $i\\,\\in\\,[K],b_{i}\\;>\\;v_{i}$ , there exists $\\tilde{\\mathbf{b}}$ a non-increasing sequence of $[0,v_{1}]~\\times$ $[0,v_{2}]\\times\\ldots\\times[0,v_{K}]$ such that : ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\forall\\beta\\in B,u(\\tilde{\\mathbf{b}},\\beta)\\geq u(\\mathbf{b},\\beta)\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Proof. Let $\\{v_{1},v_{2},...,v_{k}\\}$ be the valuations of the learner. Let $\\mathbf{b}=\\left\\{b_{1},...,b_{K}\\right\\}\\in B$ a bid such that there exists $i\\in[K],b_{i}>v_{i}$ . We define $\\tilde{\\mathbf{b}}$ as follows: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\forall i\\in[K],\\tilde{\\mathbf{b}}_{i}=\\operatorname*{min}(v_{i},b_{i})\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Let $\\beta\\in B$ be the bids of the adversary. As a max, $p(.)$ is increasing in its arguments hence ", "page_idx": 11}, {"type": "equation", "text": "$$\np(\\tilde{\\mathbf{b}},\\beta)\\leq p(\\mathbf{b},\\beta).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "There are two possible cases : Either the allocation remains the same $x({\\tilde{\\mathbf{b}}},\\beta)\\,=\\,x(\\mathbf{b},\\beta)$ , or it decreases $x(\\tilde{\\mathbf{b}},\\beta)\\leq x(\\mathbf{b},\\beta)$ (decreasing bids cannot result in a increased allocation). ", "page_idx": 11}, {"type": "text", "text": "If the allocation remains the same, then (21) implies $u(\\tilde{\\mathbf{b}},\\beta)\\geq u(\\mathbf{b},\\beta)$ . ", "page_idx": 11}, {"type": "text", "text": "If the allocation decreases, the items obtained when bidding $\\mathbf{b}$ but not obtained when bidding $\\tilde{\\mathbf{b}}$ necessarily corresponds to bids which have been lowered (other bids remain higher than the price). Let $j\\in[\\dot{K}]$ such that $b_{j}$ is one of these bids, since the item used to be won $b_{j}\\ge p(\\mathbf{b},\\beta)$ . Since it is not won by the learner playing $\\tilde{\\mathbf{b}}$ , we have $\\tilde{b}_{j}\\leq p(\\tilde{\\mathbf{b}},\\beta)$ . Hence $v_{j}\\le p(\\mathbf{b},\\beta)$ . ", "page_idx": 11}, {"type": "text", "text": "Since this is the case for all items $j$ won under b and not under bidding $p(\\mathbf{b},\\beta),u(\\tilde{\\mathbf{b}},\\beta)\\geq u(\\mathbf{b},\\beta)$ . It is therefore always the case that ", "page_idx": 11}, {"type": "equation", "text": "$$\nu(\\tilde{\\mathbf{b}},\\beta)\\geq u(\\mathbf{b},\\beta)\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Since it is true for all $\\beta\\in B$ , this concludes the proof. ", "page_idx": 11}, {"type": "text", "text": "A consequence of Lemma 6 is that we can restrict our learning procedure to non-increasing sequence of $[0,v_{1}]^{'}\\times[0,v_{2}]\\times\\ldots\\times[0,v_{K}]$ . ", "page_idx": 11}, {"type": "text", "text": "In the following of the paper for simplicity we use $B$ as the bidding space. This covers the worst case which corresponds to the case when for all $i\\in[K]$ , $v_{i}=1$ . ", "page_idx": 11}, {"type": "text", "text": "A.2 Discretization error ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "To use online learning techniques in our instance of multi-unit uniform price auction, we use a discretization $B_{\\epsilon}$ of the bid space $B$ which is continuous. We bound here the added regret incurred because of this discretization, that is the additional regret suffered when comparing the best action in hindsight of $B_{\\epsilon}$ to the best of $B$ . ", "page_idx": 11}, {"type": "text", "text": "Definition A.1 (Discretized regret). Let $(\\mathbf{b}^{t})_{t\\in[T]}\\;\\in\\;B_{\\epsilon}^{T}$ be the action played at time $t\\ \\in\\ [T],$ , against the opposing bids $\\left(\\beta^{t}\\right)_{t\\in[T]}\\in B^{T}$ . The discretized regret is defined as follows: ", "page_idx": 11}, {"type": "equation", "text": "$$\nR_{T,\\epsilon}=\\operatorname*{max}_{\\mathbf{b}\\in B_{\\epsilon}}\\sum_{t=1}^{T}u(\\mathbf{b},\\beta^{t})-\\mathbb{E}\\left[\\sum_{t=1}^{T}u(\\mathbf{b}^{t},\\beta^{t})\\right]\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "We bound the cost of this discretization as follows : ", "page_idx": 11}, {"type": "text", "text": "Lemma 7. Let $(\\mathbf{b}^{t})_{t\\in[T]}\\,\\in\\,B_{\\epsilon}^{T}$ be the action played at time $t\\,\\in\\,[T]$ , against the opposing bids $\\left(\\beta^{t}\\right)_{t\\in[T]}\\in B^{T}$ . With $R_{T,\\epsilon}$ the dicretized regret and $R_{T}$ the regret, we have the following inequality: ", "page_idx": 12}, {"type": "equation", "text": "$$\nR_{T}\\leq R_{T,\\epsilon}+K T\\epsilon\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Proof of Lemma 7. Let $\\left(\\beta^{t}\\right)_{t\\in[T]}\\in\\left([0,1]^{K}\\right)^{T}$ the adversary bids played up to time $T$ .   \nLet $(\\mathbf{b}^{t})_{t\\in[T]}\\in B_{\\epsilon}^{T}$ . ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{R_{T}}=\\displaystyle\\operatorname*{sup}_{{\\bf b}\\in B}\\displaystyle\\sum_{t=1}^{T}{u({\\bf b},\\beta^{t})-\\mathbb{E}\\left[\\sum_{t=1}^{T}u({\\bf b}^{t},\\beta^{t})\\right]}}\\\\ &{\\qquad=\\displaystyle\\operatorname*{sup}_{{\\bf b}\\in B}\\displaystyle\\sum_{t=1}^{T}{u({\\bf b},\\beta^{t})-\\operatorname*{sup}_{{\\bf b}\\in B_{t}}\\sum_{t=1}^{T}{u({\\bf b},\\beta^{t})+\\operatorname*{sup}_{{\\bf b}\\in B_{t}}\\sum_{t=1}^{T}u({\\bf b},\\beta^{t})-\\mathbb{E}\\left[\\sum_{t=1}^{T}u({\\bf b}^{t},\\beta^{t})\\right]}}}\\\\ &{\\qquad=\\displaystyle\\operatorname*{sup}_{{\\bf b}\\in B}\\displaystyle\\sum_{t=1}^{T}{u({\\bf b},\\beta^{t})-\\operatorname*{max}_{{\\bf b}\\in B_{t}}\\sum_{t=1}^{T}u({\\bf b},\\beta^{t})+R_{T,\\epsilon}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Let $\\mu>0$ , there exists $\\mathbf{b}_{o p t}\\in B$ such that $\\begin{array}{r}{\\sum_{t=1}^{T}u(\\mathbf b_{o p t},\\beta^{t})+\\mu\\geq\\operatorname*{sup}_{\\mathbf b\\in B}\\sum_{t=1}^{T}u(\\mathbf b,\\beta^{t}).}\\end{array}$ ", "page_idx": 12}, {"type": "text", "text": "We define its closest discretized bid from above ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{b}_{o p t,\\epsilon}:=\\left(\\left\\{\\begin{array}{c c}{b_{o p t,i}}&{\\mathrm{if~}\\frac{b_{o p t,i}}{\\epsilon}\\in\\mathbb{N}}\\\\ {1}&{\\mathrm{if~}b_{o p t,i}>\\left\\lfloor\\frac{1}{\\epsilon}\\right\\rfloor\\epsilon}\\\\ {\\left\\lceil\\frac{b_{o p t,i}}{\\epsilon}\\right\\rceil\\epsilon}&{\\mathrm{else}}\\end{array}\\right.\\right)_{i\\in[K]}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since $\\mathrm{max}(.)$ cannot increase more than its arguments and $\\forall i\\in[K],b_{o p t,\\epsilon,i}\\le b_{o p t,i}+\\epsilon,$ , ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\forall t\\in[T],\\;p(\\mathbf{b}_{o p t,\\epsilon},\\beta^{t})\\leq p(\\mathbf{b}_{o p t},\\beta^{t})+\\epsilon\\,,\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "and since $\\forall i\\in[K],\\,b_{o p t,\\epsilon,i}\\geq b_{o p t,i}.$ , ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\forall t\\in[T],\\ x(\\mathbf{b}_{o p t,\\epsilon},\\beta^{t})\\geq x(\\mathbf{b}_{o p t},\\beta^{t})\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "therefore, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}u(\\mathbf b_{o p t,\\epsilon},\\beta^{t})\\geq\\sum_{t=1}^{T}u(\\mathbf b_{o p t},\\beta^{t})-K T\\epsilon\\geq\\operatorname*{sup}_{\\mathbf b\\in B}\\sum_{t=1}^{T}u(\\mathbf b,\\beta^{t})-K T\\epsilon-\\mu\\,.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Hence ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle R_{T}=\\operatorname*{sup}_{{\\bf b}\\in B}\\sum_{t=1}^{T}u({\\bf b},\\beta^{t})-\\operatorname*{max}_{{\\bf b}\\in B_{\\epsilon}}\\sum_{t=1}^{T}u({\\bf b},\\beta^{t})+R_{T,\\epsilon}}}\\\\ {{\\displaystyle\\quad\\leq\\operatorname*{sup}_{{\\bf b}\\in B}\\sum_{t=1}^{T}u({\\bf b},\\beta^{t})-\\sum_{t=1}^{T}u({\\bf b}_{o p t,\\epsilon},\\beta^{t})+R_{T,\\epsilon}}}\\\\ {{\\displaystyle\\quad\\leq K T\\epsilon+\\mu+R_{T,\\epsilon}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since the previous inequality is true for any $\\mu>0$ , we get ", "page_idx": 12}, {"type": "equation", "text": "$$\nR_{T}\\leq K T\\epsilon+R_{T,\\epsilon}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "A.3 Avoiding ties ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In the latter analysis, we assume that ties never occur. We show here how this assumption, for our regret analysis, is equivalent to using a small perturbation of the bids of the learner. Let $\\delta\\in(0,\\epsilon)$ and $X\\sim\\mathcal{U}[0,\\delta]$ the random perturbation of the bids of the learner. We define $B_{\\epsilon}^{X}$ the set of nonincreasing sequences of $\\{X,\\epsilon+X,2\\epsilon+X,...,1-\\epsilon+X\\}^{K}$ , the set in which the perturbed bids of learners take value. ", "page_idx": 13}, {"type": "text", "text": "This perturbation of the discretized set we use as bid space for the learner comes at no costs in terms of added regrets. The previous Lemma 7 can straightforwardly be applied to the perturbed set $B_{\\epsilon}^{X}$ , as the key reason for the additional regret is the discretization step $\\epsilon$ , which remains unchanged here. ", "page_idx": 13}, {"type": "text", "text": "Lemma 8. Let $\\beta^{T}\\,\\in\\,B^{T}$ be the bid of the adversary up to time $T_{i}$ , for any bid sequence of the learner ${\\mathbf b}^{T}\\in B_{\\epsilon}^{\\dot{X}\\times T}$ , there is almost surely never a tie. ", "page_idx": 13}, {"type": "text", "text": "Proof. Let $\\beta^{T}\\,\\in\\,B^{T}$ ,and for all $t\\,\\in\\,T$ denote $\\boldsymbol{\\beta}^{t}\\,=\\,\\{\\beta_{1}^{t},...,\\beta_{K}^{t}\\}$ . For any bid sequence $\\mathbf{b}^{T}\\mathbf{\\Psi}\\in$ $B_{\\epsilon}^{X\\times T}$ , a necessary condition for ties to occur is that there exists $(t,j)~\\in~[T]~\\times~[K]$ such that $\\beta_{j}^{\\tilde{t}}\\in\\{\\epsilon+X,2\\epsilon+X,...,1-\\epsilon+X\\}$ . This is almost surely never the case, as it is the probability of $X$ to belong to a finite set. \u53e3 ", "page_idx": 13}, {"type": "text", "text": "Remark 2. For the sake of regret bounds, since we almost surely don\u2019t have any tie, the assumption that the adversary plays bids in $B_{\\setminus\\epsilon}$ is without loss of generality. ", "page_idx": 13}, {"type": "text", "text": "B Appendix: Regret analysis ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "B.1 Full-information regret rates ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Theorem 3. In the full information feedback setting, Algorithm 1 coincides with the Hedge algorithm with parameter \u03b7 on $H_{\\epsilon}$ . It ensures a regret of at most $O\\left(\\sqrt{K^{3}T\\log\\left(T\\right)}\\right)$ by taking $\\dot{\\epsilon}=\\sqrt{\\frac{K}{T}}$ and \u03b7 = $\\eta=\\sqrt{\\frac{\\log\\left(\\frac{T}{K}\\right)}{2K T}}$ ", "page_idx": 13}, {"type": "text", "text": "Proof of Theorem 3. In order to leverage classical results on the exponential weight algorithm in the expert setting, we aim to show that the combination of our algorithms leads to a probability update rule of the form: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}^{t}(\\mathbf{h})=\\frac{\\mathbb{P}^{t-1}(\\mathbf{h})\\exp\\left(\\eta u^{t}(\\mathbf{h})\\right)}{\\sum_{\\mathbf{j}\\in H_{\\epsilon}}\\mathbb{P}^{t-1}(\\mathbf{j})\\exp\\eta u^{t}(\\mathbf{j})}\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Let h be bid profile in $H_{\\epsilon}$ , we denote $h_{i}$ its $i^{\\mathrm{th}}$ element $i^{\\mathrm{th}}$ element of the sequence) and $\\mathbf{len}(\\mathbf{h})$ the length of the sequence $\\mathbf{h}$ . Given the sampling Algorithm 2, we have by telescoping and the product of conditional probabilities ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{P}^{t}(\\mathbf{h})=\\prod_{i\\in[1,\\log(n)]}^{H^{\\epsilon}}\\mathbb{E}^{t}(h_{i}|h_{i-1})}}\\\\ &{=\\underbrace{\\prod_{i\\in[1,\\log(n)]}^{H^{\\epsilon}}\\mathbb{E}^{t}(h_{i})}_{\\mathbb{E}^{t}[h_{i-1}]}}\\\\ &{=\\frac{\\prod_{i\\in[1,\\log(n)]}\\mathbb{E}^{t}(h_{i})}{\\Gamma_{0}^{t}}}\\\\ &{=\\frac{\\prod_{i\\in[1,\\log(n)]}\\mathbb{E}^{t-1}(h_{i})\\exp{(\\eta w^{t}(h_{i}))}}{\\Gamma_{0}^{t}}}\\\\ &{=\\frac{\\exp{(\\eta w^{t}(\\mathbf{h}))}}{\\Gamma_{0}^{t}}\\prod_{i=1}^{\\mathbb{I}}\\frac{\\mathbb{P}^{t-1}(h_{i}|h_{i-1})\\frac{\\Gamma^{t-1}(h_{i-1})}{\\Gamma^{t-1}(h_{i})}}{\\Gamma^{t-1}(h_{i})}.}\\\\ &{\\mathbb{P}^{t}(\\mathbf{h})=\\frac{\\Gamma_{0}^{t-1}}{\\Gamma_{0}^{t}}\\exp{(\\eta w^{t}(\\mathbf{h}))}\\mathbb{E}^{t-1}(\\mathbf{h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where we used the probability update rule (12). ", "page_idx": 13}, {"type": "text", "text": "We can prove that \u0393t0 = h\u2208H\u03f5 $\\begin{array}{r}{\\Gamma_{0}^{t}=\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\prod_{i\\in[1,\\mathrm{len}(\\mathbf{h})]}Q^{t}(h_{i})}\\end{array}$ . An induction on $k\\in\\left[\\underset{\\mathbf{h}\\in H_{\\epsilon}}{\\mathrm{maxlen}}(\\mathbf{h})\\right]$ , where we denote $\\mathbf{h}_{:k}$ the $k$ first component of the sequence $\\mathbf{h}$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Gamma_{0}^{t}=\\sum_{\\mathbf{h};k:\\mathbf{h}\\in H_{\\epsilon}}\\left(\\prod_{i\\in[1,\\operatorname*{min}\\{k,\\mathrm{len}(\\mathbf{h})\\}]}Q^{t}(h_{i})\\right)\\Gamma^{t}(h_{\\operatorname*{min}\\{k,\\mathrm{len}(\\mathbf{h})\\}})\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This is true for $k=1$ from the definition (2) of $\\Gamma_{0}^{t}$ . ", "page_idx": 14}, {"type": "text", "text": "For $k\\geq1$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\Gamma_{0}^{t}=\\sum_{\\mathbf{h},\\mathbf{k}\\cdot\\mathbf{h}\\in\\cal H_{\\epsilon}}\\left(\\prod_{i\\in[1,\\mathrm{min}\\{k,|\\mathbf{e}_{0}(\\mathbf{h})\\}]}Q^{t}(h_{i})\\right)\\Gamma^{t}\\big(h_{\\operatorname*{min}\\{k,|\\mathbf{e}_{0}(\\mathbf{h})\\}}\\big)}\\quad}&{}\\\\ &{=\\sum_{\\mathbf{h},\\mathbf{k}\\cdot\\mathbf{h}\\in\\cal H_{\\epsilon}}\\left(\\prod_{i\\in[1,\\mathrm{min}\\{k,|\\mathbf{e}_{0}(\\mathbf{h})\\}]}Q^{t}(h_{i})\\right)\\sum_{h\\in s(h_{k})}Q^{t}(h)\\Gamma^{t}(h)}\\\\ &{=\\sum_{\\mathbf{h},\\mathbf{k}\\cdot\\mathbf{h}\\in\\cal H_{\\epsilon}}\\left(\\prod_{i\\in[1,\\mathrm{min}\\{k+1,|\\mathbf{e}_{0}(\\mathbf{h})\\}]}Q^{t}(h_{i})\\right)\\Gamma^{t}\\big(h_{\\operatorname*{min}\\{k+1,|\\mathbf{e}_{0}(\\mathbf{h})\\}}\\big)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where we used the fact that the function successor $s(.)$ provides all possible next element of sequence $\\mathbf{h}$ . ", "page_idx": 14}, {"type": "text", "text": "We then simplify $\\frac{\\Gamma_{0}^{t-1}}{\\Gamma_{0}^{t}}$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Gamma_{0}^{t}=\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\prod_{i\\in[1,\\mathrm{len}(\\mathbf{h})]}Q^{t}(h_{i})}\\\\ &{\\quad=\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\prod_{i\\in[1,\\mathrm{len}(\\mathbf{h})]}Q^{t-1}(h_{i})\\exp\\left(\\eta u^{t}(h_{i})\\right)}\\\\ &{\\quad=\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\exp\\left(\\eta u^{t}(\\mathbf{h})\\right)\\prod_{i\\in[1,\\mathrm{len}(\\mathbf{h})]}\\mathbb{P}_{t-1}(h_{i}|\\mathbf{h}_{i-1})\\frac{\\Gamma^{t-1}\\left(\\mathbf{h}_{i-1}\\right)}{\\Gamma^{t-1}\\left(h_{i}\\right)}}\\\\ &{\\quad=\\displaystyle\\prod_{\\mathbf{h}\\in H_{\\epsilon}}^{t-1}\\exp\\left(\\eta u^{t}(\\mathbf{h})\\right)\\mathbb{P}_{t-1}(\\mathbf{h})\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We can therefore write ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}^{t}(\\mathbf{h})=\\frac{\\mathbb{P}^{t-1}(\\mathbf{h})\\exp\\left(\\eta u^{t}(\\mathbf{h})\\right)}{\\sum_{\\mathbf{l}\\in H_{\\epsilon}}\\mathbb{P}^{t-1}(\\mathbf{l})\\exp\\eta u^{t}(\\mathbf{l})}\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This is the update rule of the Hedge algorithm on the action space $H_{\\epsilon}$ . Therefore using Theorem 2.2 of Cesa-Bianchi and Lugosi, 2006, restated in the Appendix 4 leads to the following regret bound: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{T,\\epsilon}\\leq\\frac{\\log\\left(|B_{\\epsilon}|\\right)}{\\eta}+\\frac{\\eta T K^{2}}{8}}\\\\ &{\\qquad\\leq\\frac{\\log\\left(1/\\epsilon^{K}\\right)}{\\eta}+\\frac{\\eta T K^{2}}{8}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where, to bound $\\log\\left(|B_{\\epsilon}|\\right)$ in (30), we used the fact that the action space $H_{\\epsilon}$ is in bijection with the original discretized bid space : $K$ non-increasing elements of $\\{1,2,\\overline{{\\ldots}},\\lfloor\\frac{1}{\\epsilon}\\rfloor\\}$ , which cardinal is trivially smaller than\u03f51K . ", "page_idx": 14}, {"type": "text", "text": "Taking \u03b7 = $\\begin{array}{r}{\\eta=\\sqrt{\\frac{\\log\\left(\\frac{1}{\\epsilon}\\right)}{K T}}}\\end{array}$ , we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\nR_{T,\\epsilon}\\leq\\frac{9}{8}\\sqrt{T K^{3}\\log\\left(\\frac{1}{\\epsilon}\\right)}\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Finally, using lemma 7, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{T}\\leq R_{T,\\epsilon}+K T\\epsilon}\\\\ &{\\phantom{\\leq}\\leq\\frac{9}{8}\\sqrt{T K^{3}\\log\\left(\\frac{1}{\\epsilon}\\right)}+K T\\epsilon}\\\\ &{\\phantom{\\leq\\frac{9}{8}\\sqrt{T K^{3}}\\left(\\log\\left(\\sqrt{\\frac{T}{K}}\\right)+1\\right)}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with $\\textstyle{\\epsilon={\\sqrt{\\frac{K}{T}}}}$ . ", "page_idx": 15}, {"type": "text", "text": "B.2 Partial feedback regret rates ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.2.1 Bandit feedback ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To prove the regret rates in the bandit feedback settings, we use Lemma 9 which bounds the necessary quantity for the standard EXP3 analysis. ", "page_idx": 15}, {"type": "text", "text": "Lemma 9 (Bandit feedback estimator). The estimator $\\hat{u}^{t}(\\mathbf{h})$ defined by (19) has the following properties: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The estimator $\\hat{u}^{t}(\\mathbf{h})$ has a fixed bias $-K$ : ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\hat{u}^{t}({\\bf h})\\right]=u^{t}({\\bf h})-K\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "\u2022 The square of the estimator can be upper bounded as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\mathbb{E}\\left[\\hat{u}^{t}(\\mathbf{h})^{2}\\right]\\leq4K^{2}\\operatorname*{max}\\left(K^{2},\\frac{1}{\\epsilon}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since the estimator has a constant bias for every action, one can use it in the problem similarly to an unbiased estimator. ", "page_idx": 15}, {"type": "text", "text": "Proof of Lemma 9. Let $h$ be a bid or a bid-gap, then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\hat{u}^{t}(\\mathbf{h})\\right]=\\displaystyle\\sum_{\\mathbf{h}^{t}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h}^{t})\\sum_{h\\in\\mathbf{h}}\\hat{w}^{t}(h)}\\\\ &{=\\displaystyle\\sum_{\\mathbf{h}^{t}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h}^{t})\\sum_{h\\in\\mathbf{h}}1(h-h_{\\epsilon}^{t})\\frac{w^{t}(h)-K}{\\mathbb{P}^{t}(h)}}\\\\ &{=\\displaystyle\\sum_{\\mathbf{h}^{t}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h}^{t})\\frac{w^{t}(h_{\\epsilon}^{t}(\\mathbf{h}))-K}{\\mathbb{P}^{t}(h_{\\epsilon}^{t}(\\mathbf{h}))}1(h_{\\star}^{t}(\\mathbf{h})=h_{\\star}^{t})}\\\\ &{=\\displaystyle\\frac{w^{t}(h_{\\epsilon}^{t}(\\mathbf{h}))-K}{\\mathbb{P}^{t}(h_{\\star}^{t}(\\mathbf{h}))}\\sum_{\\mathbf{h}^{t}\\in H_{\\epsilon}\\times h_{\\star}^{t}(\\mathbf{h})\\in\\mathbb{R}^{t}}\\mathbb{P}^{t}(\\mathbf{h}^{t})}\\\\ &{=w^{t}(h_{\\star}^{t}(\\mathbf{h}))-K=u^{t}(\\mathbf{h})-K.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{N\\in\\mathbb{H}_{+}}{\\sum}\\mathbb{F}^{\\ell}(\\mathbf{h})\\mathbb{E}\\left[u^{\\ell}(\\mathbf{h})^{2}\\right]=\\underset{N\\in\\mathbb{H}_{+}}{\\sum}p^{\\ell}(\\mathbf{h})i^{\\ell}(\\mathbf{h})^{2}\\Bigg]}\\\\ &{=\\underset{N\\in\\mathbb{H}_{+}}{\\sum}p^{\\ell}(\\mathbf{h})\\sum_{i=1}^{\\ell}\\frac{p^{\\ell}(\\mathbf{h})}{p\\ln\\ell_{i}}\\Bigg(\\frac{w^{\\ell}(\\mathbf{h}_{i}^{\\ell}(\\mathbf{h}))-K}{\\mathbb{P}^{\\ell}(\\mathbf{h}_{i}^{\\ell}(\\mathbf{h}))}\\Bigg)^{2}\\mathbf{1}(h_{i}^{\\ell}(\\mathbf{h})=h_{i}^{\\ell})}\\\\ &{=\\underset{N\\in\\mathbb{H}_{+}}{\\sum}p^{\\ell}(\\mathbf{h})\\left(\\frac{w^{\\ell}(\\mathbf{h}_{i}^{\\ell})-K}{\\mathbb{P}^{\\ell}(\\mathbf{h}_{i}^{\\ell})}\\right)^{2}\\underset{N\\in\\mathbb{H}_{-}\\mathbb{H}_{+}\\mathbb{N}}{\\sum}p^{\\ell}(\\mathbf{h})}\\\\ &{=\\underset{N\\in\\mathbb{H}_{+}}{\\sum}p^{\\ell}(\\mathbf{h})\\frac{\\left(w^{\\ell}(\\mathbf{h}_{i}^{\\ell})-K\\right)^{2}}{\\mathbb{P}^{\\ell}(\\mathbf{h}_{i}^{\\ell})}}\\\\ &{\\underset{N\\in\\mathbb{H}_{+}}{\\sum}\\frac{\\sum_{i=1}^{N}C_{i}\\ln\\ell_{i}\\times\\mathbb{N}}{\\mathbb{P}^{\\ell}(\\mathbf{h}_{i}^{\\ell})}\\frac{P^{\\ell}(\\mathbf{h}_{i}^{\\ell})}{\\mathbb{P}^{\\ell}(\\mathbf{h}_{i}^{\\ell})}}\\\\ &{\\leq K^{2}\\underset{N\\in\\mathbb{H}_{+}}{\\sum}1}\\\\ &{\\leq K^{2}\\underset{N\\in\\mathbb{H}_{+}}{\\sum}e^{\\ell}}\\\\ &{\\leq(K)^{2(\\ell)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{O}^{t}=\\left\\{h_{\\star}^{t}(\\mathbf{h})\\Big|\\mathbf{h}\\in H_{\\epsilon}\\right\\}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "There only remains to upper bound $|\\mathcal{O}^{t}|$ . ", "page_idx": 16}, {"type": "text", "text": "For any $p\\in[0,1]$ we denote for this proof $j(p)=\\lfloor\\frac{p}{\\epsilon}\\rfloor$ , which is the value $j$ such that $p\\in[j\\epsilon,j\\epsilon\\!+\\!\\epsilon)$ . Let $\\mathbf{h}\\in H_{\\epsilon}$ , notice that $h_{\\star}^{t}(\\mathbf{h},\\beta^{t})\\ \\in\\ \\{b_{x_{t}(\\mathbf{h},\\beta^{t}),j}\\dot{(}p(\\mathbf{h},\\beta^{t})),\\ b_{x_{t}(\\mathbf{h},\\beta^{t})+\\frac{1}{2},j(p(\\mathbf{h},\\beta^{t}))}\\}$ which directly results from the decomposition formula 10. To upper bound $|\\mathcal{O}^{t}|$ we will therefore upper bound the different values the pair $\\big(\\boldsymbol x_{t}(\\mathrm{~.~},\\beta^{t}),p(\\mathrm{~.~},\\beta^{t})\\big)$ can take. ", "page_idx": 16}, {"type": "text", "text": "Since the learner plays bids in $H_{\\epsilon}$ (or equivalently $B_{\\epsilon}$ ), $p(.,\\beta^{t})$ can only take either the value of one of the components in $\\beta$ or one of the bids of its first argument. Because $\\beta^{\\ddagger}$ is a vector of size $\\mathbf{K}$ we can write that: $\\begin{array}{r}{\\big|\\{\\breve{p(\\mathbf{h},\\beta^{t})},\\mathbf{h}\\in H_{\\epsilon}\\}\\big|\\leq K+\\lfloor\\frac{1}{\\epsilon}\\rfloor.}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "Furthermore, because units are either attributed to the player or the adversary, we can write $K-$ $\\left|\\{\\beta_{i}^{t}>p_{t}(\\,.\\,,\\beta^{t})\\}\\right|\\ge x_{t}(\\,.\\,,\\beta^{t})\\ge K-\\left|\\{\\beta_{i}^{t}\\ge p_{t}(\\,\\stackrel{\\cdot}{,},\\bar{\\beta}^{t})\\}\\right|$ . The two cardinals can only differ if the price is set by an adversary bid because the no ties assumption implies almost surely for all $i\\in[\\dot{K}],\\dot{\\beta}_{i}^{t}\\notin[\\frac{1}{\\epsilon}]$ . ", "page_idx": 16}, {"type": "text", "text": "Therefore each possible value of $p_{t}(\\mathbf{\\nabla}.\\mathbf{\\nabla},\\beta^{t})$ only correspond to one value of $x_{t}(\\mathbf{\\nabla}\\cdot\\mathbf{\\nabla},\\beta^{t})$ , except for the $K$ values set by the adversary, where $x_{t}(\\mathbf{\\nabla}\\cdot\\mathbf{\\nabla},\\beta^{t})$ can at most take $K$ values. ", "page_idx": 16}, {"type": "text", "text": "Therefore ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2\\left(K^{2}+\\left\\lfloor\\frac{1}{\\epsilon}\\right\\rfloor\\right)\\ge2\\left|\\{\\left(x_{t}(\\mathbf{h},\\beta^{t}),p(\\mathbf{h},\\beta^{t})\\right),\\mathbf{h}\\in H_{\\epsilon}\\}\\right|}\\\\ &{\\qquad\\qquad\\qquad\\ge2\\left|\\{\\left(x_{t}(\\mathbf{h},\\beta^{t}),j\\left(p(\\mathbf{h},\\beta^{t})\\right)\\right),\\mathbf{h}\\in H_{\\epsilon}\\}\\right|}\\\\ &{\\qquad\\qquad\\qquad\\ge\\left|\\mathcal{O}^{t}\\right|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which leads to the needed upper bounds ", "page_idx": 16}, {"type": "text", "text": "We now restate Theorem 1 and then provide proof of the corresponding regret guarantees. ", "page_idx": 16}, {"type": "text", "text": "Theorem 1. In the repeated $K$ -unit auction with uniform pricing guarantees and under bandit feedback, Algorithm $^{\\,I}$ incurs a regret of at most $\\mathcal{O}\\left(K^{\\dot{4}/3}T^{{\\dot{2}}/3}\\log^{\\check{(T)}}\\right)$ . For any time horizon $T$ , with the choices of $\\textstyle\\epsilon=\\left({\\frac{K}{T}}\\right)^{1/3}$ and $\\begin{array}{r}{\\eta=K^{-1/3}T^{-2/3}\\sqrt{\\log\\left(\\frac{T}{K}\\right)/3}}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof of Theorem 1. For $T\\in\\mathbf N$ , we denote $(\\mathbf{h}^{t})_{t\\in[T]}\\in H_{\\epsilon}^{T}$ the actions played at each time-steps, generated by Algorithm 1. ", "page_idx": 17}, {"type": "text", "text": "We can first notice that, by conducting the same analysis as in B.1 up to Equation (29), we obtain: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}^{t}(\\mathbf{h})=\\frac{\\mathbb{P}_{t-1}(\\mathbf{h})\\exp{(\\eta\\hat{u}^{t}(\\mathbf{h})})}{\\sum_{1\\in H_{\\epsilon}}\\mathbb{P}_{t-1}(\\mathbf{l})\\exp{\\eta\\hat{u}^{t}(\\mathbf{l})}}\\;,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which by simple induction allows us to obtain: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}^{t}(\\mathbf{h})=\\frac{\\exp\\left(\\sum_{j=1}^{t}\\eta\\hat{u}^{j}(\\mathbf{h})\\right)}{\\sum_{1\\in H_{\\epsilon}}\\exp\\left(\\sum_{j=1}^{t}\\eta\\hat{u}^{j}(\\mathbf{l})\\right)}\\;.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We can now proceed to the regret analysis. For any action $\\mathbf{h}\\in H_{\\epsilon}$ , we define : ", "page_idx": 17}, {"type": "equation", "text": "$$\nR_{T,\\mathbf{h}}=\\sum_{t=1}^{T}u^{t}(\\mathbf{h})-\\mathbb{E}\\left[\\sum_{t=1}^{T}u^{t}(\\mathbf{h}^{t})\\right]\\,,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which is the expected regret relative to playing $\\mathbf{h}$ in all the rounds. ", "page_idx": 17}, {"type": "text", "text": "We have, because of Lemma 9, $\\begin{array}{r}{\\mathbb{E}\\left[\\sum_{t=1}^{T}\\hat{u}^{t}({\\bf h})\\right]=\\sum_{t=1}^{T}u^{t}({\\bf h}^{t})-K T}\\end{array}$ and $\\begin{array}{r}{\\mathbb{E}_{t-1}\\left[u^{t}({\\bf h}^{t})\\right]=\\sum_{{\\bf h}\\in B}\\mathbb{P}^{t}({\\bf h})\\overline{{u}}^{t}({\\bf h})=\\sum_{{\\bf h}\\in B}^{{\\bf\\mu}}\\mathbb{P}^{t}({\\bf h})\\mathbb{E}_{t-1}\\left[{\\widehat{u}}^{t}({\\bf h})\\right]+K.}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "Therefore ", "page_idx": 17}, {"type": "equation", "text": "$$\nR_{T,\\mathbf{h}}=\\mathbb{E}\\left[\\sum_{t=1}^{T}{\\hat{u}}^{t}(\\mathbf{h})\\right]-\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h}){\\hat{u}}^{t}(\\mathbf{h})\\right]\\ .\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We denote $\\begin{array}{r}{W_{n}=\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\exp(\\eta\\sum_{t=1}^{n}\\hat{u}^{t}(\\mathbf{h}))}\\end{array}$ . ", "page_idx": 17}, {"type": "text", "text": "Then we have for any $\\mathbf{h}\\in H_{\\epsilon}$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\exp\\left(\\eta\\sum_{t=1}^{T}\\hat{u}^{t}(\\mathbf{h})\\right)\\le\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\exp(\\eta\\sum_{t=1}^{T}\\hat{u}^{t}(\\mathbf{h}))=W_{T}=W_{0}\\prod_{t=1}^{T}\\frac{W_{t}}{W_{t-1}}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We can then upper bound the terms of the product as follows : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{W_{t}}{W_{t-1}}\\leq\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\frac{\\exp\\left(\\eta\\sum_{l=1}^{t-1}\\hat{u}^{l}(\\mathbf{h})\\right)}{W_{t-1}}\\exp\\left(\\eta\\hat{u}^{t}(\\mathbf{h})\\right)}\\\\ &{\\qquad\\quad\\leq\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\exp\\left(\\eta\\hat{u}^{t}(\\mathbf{h})\\right)~,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the second inequality comes from 42. ", "page_idx": 17}, {"type": "text", "text": "We can then further bound this term using the inequalities ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\forall\\,x\\leq1,\\,\\exp(x)\\leq1+x+x^{2}{\\mathrm{~and~}}\\forall x\\in\\mathbb{R},1+x\\leq\\exp(x)\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This gives ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{W_{t}}{W_{t-1}}\\leq1+\\eta\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})+\\eta^{2}\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})^{2}}\\\\ &{\\quad\\quad\\leq\\exp\\left(\\eta\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})+\\eta^{2}\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})^{2}\\right)~.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This in turn yields ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\exp\\left(\\eta\\displaystyle\\sum_{t=1}^{T}\\hat{u}^{t}(\\mathbf{h})\\right)\\leq W_{0}\\prod_{t=1}^{T}\\exp\\left(\\eta\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})+\\eta^{2}\\displaystyle\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})^{2}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq W_{0}\\exp\\left(\\eta\\displaystyle\\sum_{t=1}^{T}\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})+\\eta^{2}\\displaystyle\\sum_{t=1}^{T}\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\hat{u}^{t}(\\mathbf{h})^{2}\\right)\\ ,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where by applying the log, simplifying, and taking the expectation we get ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{t=1}^{T}\\hat{u}^{t}({\\bf h})-\\sum_{t=1}^{T}\\sum_{{\\bf h}\\in B}\\mathbb{P}^{t}({\\bf h})\\hat{u}^{t}({\\bf h})\\leq\\frac{\\log(W_{0})}{\\eta}+\\eta\\sum_{t=1}^{T}\\sum_{{\\bf h}\\in H_{\\epsilon}}\\mathbb{P}^{t}({\\bf h})\\hat{u}^{t}({\\bf h})^{2}}\\\\ {\\displaystyle\\mathbb{E}\\left[\\sum_{t=1}^{T}\\hat{u}^{t}({\\bf h})-\\sum_{t=1}^{T}\\sum_{{\\bf h}\\in H_{\\epsilon}}\\mathbb{P}^{t}({\\bf h})\\hat{u}^{t}({\\bf h})\\right]\\leq\\frac{\\log(W_{0})}{\\eta}+\\eta\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{{\\bf h}\\in H_{\\epsilon}}\\mathbb{P}^{t}({\\bf h})\\hat{u}^{t}({\\bf h})^{2}\\right]}\\\\ {\\displaystyle R_{T,{\\bf h}}\\leq\\frac{\\log(W_{0})}{\\eta}+\\eta\\mathbb{E}\\left[\\sum_{t=1}^{T}\\sum_{{\\bf h}\\in B}\\mathbb{P}^{t}({\\bf h})\\hat{u}^{t}({\\bf h})^{2}\\right]~.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We recognize the expression of the regret from (43). Because it is true for all $\\mathbf{h}\\in H_{\\epsilon}$ , we can take the maximum and notice : $R_{T,\\epsilon}\\,=\\,\\mathrm{max}_{\\mathbf{h}\\in H_{\\epsilon}}\\,R_{T,\\mathbf{h}}$ . Noticing that $\\begin{array}{r}{W_{0}\\,=\\,|H_{\\epsilon}|\\,\\le\\,\\bigl(\\frac{1}{\\epsilon}\\bigr)^{K}}\\end{array}$ and using Lemma 9 concludes the bound on the discritzed regret as follows: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{R_{T,\\epsilon}}\\leq\\frac{\\log\\vert{\\cal{H}}_{\\epsilon}\\vert}{\\eta}+\\eta\\sum_{t=1}^{T}\\sum_{\\mathbf{h}\\in{\\cal{H}}_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\mathbb{E}\\left[\\hat{u}^{t}(\\mathbf{h})^{2}\\right]}\\\\ &{\\quad\\quad\\leq K\\frac{\\log\\left(\\frac{1}{\\epsilon}\\right)}{\\eta}+\\eta4K^{2}T\\frac{1}{\\epsilon}}\\\\ &{\\quad\\quad\\leq5K\\sqrt{\\frac{K T}{\\epsilon}\\log\\left(\\frac{1}{\\epsilon}\\right)}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "with $\\begin{array}{r}{\\eta=\\sqrt{\\frac{\\epsilon}{K T}\\log\\left(\\frac{1}{\\epsilon}\\right)}}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "Then using Lemma 7, we can bound the regret: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{R_{T}=R_{T,d i s c}+K T\\epsilon}}\\\\ {{\\qquad\\le5K^{3/2}\\sqrt{\\frac{T}{\\epsilon}\\log\\left(\\frac{1}{\\epsilon}\\right)}+K T\\epsilon}}\\\\ {{\\qquad\\le5K^{4/3}T^{2/3}\\left(1+\\frac{1}{3}\\log\\left(\\frac{T}{K}\\right)\\right)\\,,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "with the specific choice of $\\textstyle\\epsilon=\\left({\\frac{K}{T}}\\right)^{1/3}$ . ", "page_idx": 18}, {"type": "text", "text": "B.2.2 All-winner feedback ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As in the bandit feedback, to prove the regret rates, we use Lemma 10 which bounds the necessary quantity for the standard EXP3 analysis. ", "page_idx": 18}, {"type": "text", "text": "Lemma 10. The estimator $\\bar{u}^{t}(\\mathbf h)$ , defined by (20) has the following properties: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The estimator $\\bar{u}^{t}(\\mathbf h)$ has a fixed bias $-K$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\bar{u}^{t}({\\bf h})\\right]=u^{t}({\\bf h})-K\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "\u2022 The square of the estimator verifies: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\mathbb{E}\\left[\\bar{u}^{t}(\\mathbf{h})^{2}\\right]\\leq8K^{4}\\log(2)\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof of Lemma $I O$ . This proof is mostly based on the following careful computations. ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\bar{u}^{t}(\\mathbf{h})\\right]=\\displaystyle\\sum_{\\mathbf{h}^{t}\\in B}\\mathbb{E}^{t}(\\mathbf{h}^{t})\\displaystyle\\sum_{h\\in\\mathbf{h}}\\overline{{u}}^{t}(h)}\\\\ &{=\\displaystyle\\sum_{\\mathbf{h}^{t}\\in H_{\\varepsilon}}\\mathbb{P}^{t}(\\mathbf{h}^{t})\\displaystyle\\sum_{h_{k,j}\\in\\mathbf{h}}\\mathbf{1}\\left(h\\in A_{\\star}^{t}(\\mathbf{h}^{t})\\right)\\displaystyle\\frac{w^{t}(h)-K}{\\mathbb{1}^{r}\\sim g^{t}(h\\in A_{\\star}^{t}(\\mathbf{h}^{t}))}}\\\\ &{=\\displaystyle\\sum_{\\mathbf{h}^{t}\\in H_{\\varepsilon}}\\mathbb{P}^{t}(\\mathbf{h}^{t})\\displaystyle\\frac{w^{t}(h_{\\star}^{t}(\\mathbf{h}))-K}{\\mathbb{1}^{r}\\sim g^{t}(h_{\\star}^{t}(\\mathbf{h})\\in A_{\\star}^{t}(\\mathbf{l}^{t}))}\\mathbf{1}(h_{\\star}^{t}(\\mathbf{h})\\in A_{\\star}^{t}(\\mathbf{h}^{t}))}\\\\ &{=\\displaystyle\\frac{w^{t}(h_{\\star}^{t}(\\mathbf{h}))-K}{\\mathbb{1}^{p}\\sim\\mathbb{N}^{t}(h_{\\star}^{t}(\\mathbf{h})\\in A_{\\star}^{t}(\\mathbf{l}^{t}))}\\displaystyle\\sum_{\\mathbf{h}^{t}\\in H_{\\star}^{t}\\times\\hat{\\mathbf{h}}^{t}(\\mathbf{h}^{t})}\\mathbb{E}^{t}(\\mathbf{h}^{t})}\\\\ &{=w^{t}(h_{\\star}^{t}(\\mathbf{h}))-K=u^{t}(\\mathbf{h})-K.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\sum_{k=1}^{P}\\mathbb{P}(\\mathbf{h})\\mathbb{E}\\left[q^{k}(h)^{T}\\right]=\\mathbb{E}\\Bigg[\\sum_{i=1}^{P}\\gamma_{k}\\mathbf{\\Phi}_{i}(h)^{T}\\Bigg]}&{}\\\\ {=}&{\\displaystyle\\sum_{k=1}^{P}\\mathbb{P}(\\mathbf{h})\\sum_{i=1}^{P}\\mathbb{P}(\\mathbf{h})\\Bigg(\\frac{e^{-k\\left(K/\\delta_{0}\\right)}-K}{\\sqrt{\\pi}_{k}\\mathbb{E}\\left(\\mathbf{h}\\right)^{T}}\\Bigg)^{\\frac{1}{2}}\\mathbb{I}\\{K_{0}\\}\\otimes\\mathcal{A}_{1}\\mathbb{N}}\\\\ &{\\quad-\\sum_{k=1}^{P}\\mathbb{P}(\\mathbf{h})\\Bigg(\\frac{e^{\\frac{-k\\left(K/\\delta_{0}\\right)}{\\sqrt{\\pi}_{k}\\mathbb{E}\\left(\\mathbf{h}\\right)}-K}}{\\sqrt{\\pi}_{k}\\mathbb{E}\\left(\\mathbf{h}\\right)+K\\mathbb{E}\\left(\\mathbf{H}\\right)}\\Bigg)^{\\frac{1}{2}}}\\\\ &{=\\displaystyle\\sum_{k=1}^{P}\\mathbb{P}(\\mathbf{h})\\Bigg(\\frac{e^{\\frac{-k\\left(K/\\delta_{0}\\right)}{\\sqrt{\\pi}_{k}\\mathbb{E}\\left(\\mathbf{h}\\right)}}-K^{2}}{\\mathbb{P}\\mathbb{E}\\left(\\mathbf{h}\\right)+\\mathbb{E}\\left(\\mathbf{H}\\right)}\\Bigg)^{\\frac{1}{2}}}\\\\ &{\\quad-\\displaystyle\\sum_{k=1}^{P}\\mathbb{P}\\Bigg[\\mathbb{P}(\\mathbf{h})\\frac{\\Bigg(e^{\\frac{-k\\left(K/\\delta_{0}\\right)}{\\sqrt{\\pi}_{k}\\mathbb{E}\\left(\\mathbf{h}\\right)}}-K^{2}\\mathbb{P}\\Bigg)}}\\\\ &{\\quad\\le\\displaystyle\\sum_{k=1}^{P}\\mathbb{L}\\Bigg\\{\\frac{\\mathbb{P}\\Bigg(\\mathbf{h})}{\\mathbb{E}\\Bigg[\\mathbf{H})}\\mathbb{C}\\mathbb{E}\\Bigg[\\mathbb{P}(\\mathbf{h})\\Bigg]-K\\mathbb{E}\\Bigg[\\mathbb{P}(\\mathbf{h})}\\\\ &{\\quad\\le K^{2}\\sum_{k=1}^{P}\\frac{\\mathbb{P}\\Bigg(\\mathbf{h})}{\\mathbb{E}\\Bigg[\\mathbb{H}\\Bigg]}\\mathbb{C}\\mathbb{E}\\Bigg[\\mathbb{P}(\\mathbf{h})\\Bigg]}\\\\ &{\\quad\\le K^{2}\\sum_{k=1}^{P}\\frac{\\mathbb \n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Taking $\\begin{array}{r}{\\alpha=\\frac{1}{K}}\\end{array}$ ", "page_idx": 19}, {"type": "text", "text": "Where to bound (60), we use lemma 11 from Alon et al., 2017, restated in the Appendix. ", "page_idx": 19}, {"type": "text", "text": "We define a graph over the elements of $O^{t}$ , such that each element $o_{1}$ has an incoming edge from the other elements $o_{2}$ such that $o_{1}\\in A_{\\star}^{t}(o_{2})$ . This graph matches (60) to the expression lemma 11 allows to bound. ", "page_idx": 19}, {"type": "text", "text": "It only remains to determine the independence number of this graph. First notice that, for each value of $k\\ {\\overset{\\cdot}{+}}\\ {\\overset{\\textstyle1}{\\frac{1}{2}}}$ only one bid-gaps with this first index can belong to $O^{t}$ . Indeed, otherwise, since there exists a bid-profile $\\mathbf{h}$ such that both belong to it, $h_{\\star}^{t}(\\mathbf{h})$ would have two values, which is impossible because only one bid or bid-gap per bid profile can have non-zero sub-utility. ", "page_idx": 19}, {"type": "text", "text": "Then notice that for two bids in $O^{t}$ , with the same first index $k$ an integer values, the observed set of the lowest one necessarily contains the other. This naturally arises from the definition of $A^{t}$ . ", "page_idx": 19}, {"type": "text", "text": "These two observations ensure that, in an independent set of this graph, there is at most one element having each index $k\\,\\in\\,\\{1,{\\frac{3}{2}},2,\\dots{\\frac{2K-1}{2K}},K\\}$ . This ensures the independence number of this is at most $2K$ . Which using the lemma 11 from Alon et al., 2017, completes the proof. ", "page_idx": 20}, {"type": "text", "text": "We restate the regret guarantees in the all-winner feedback before the proof. ", "page_idx": 20}, {"type": "text", "text": "Theorem 2. For any time horizon $T$ , using Algorithm 1 in the repeated $K$ -unit\u221a auction with uniform pricing guarantees, under all-winner feedback, a regret of at most $\\mathcal{O}\\left(K^{5/2}\\sqrt{T}\\log(T)\\right)$ with $\\eta=$ $\\dot{K}^{-1}\\check{T}^{-1/2}$ and $\\epsilon=K^{3/2}T^{1/2}$ . ", "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 2. The proof of this theorem is identical to the one of theorem 1, with only the need to replace $\\hat{u}^{t}$ by $\\bar{u}^{t}$ up to the point where we bound the regret in equation 51. The proof completes as follows. The discretized regret can be bounded as in B.2.1: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{T,d i s c}\\leq\\displaystyle\\frac{\\log|H_{\\epsilon}|}{\\eta}+\\eta\\sum_{t=1}^{T}\\sum_{\\mathbf{h}\\in H_{\\epsilon}}\\mathbb{P}^{t}(\\mathbf{h})\\mathbb{E}\\left[\\bar{u}^{t}(\\mathbf{h})^{2}\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\leq K\\displaystyle\\frac{\\log\\left(\\frac{1}{\\epsilon}\\right)}{\\eta}+\\eta8K^{4}T\\log\\left(\\frac{2}{\\epsilon}\\right)}\\\\ &{\\quad\\quad\\quad\\leq K^{5/2}\\sqrt{T}\\left(8\\log(2)+9\\log\\left(\\frac{1}{\\epsilon}\\right)\\right)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with \u03b7 = $\\begin{array}{r}{\\eta=\\frac{1}{K\\sqrt{T}}}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "Then using Lemma 7, we can bound the regret: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{R_{T}=R_{T,d i s c}+K T\\epsilon}}\\\\ {{\\qquad\\leq K^{5/2}\\sqrt{T}\\left(8\\log(2)+9\\log\\left(\\frac{1}{\\epsilon}\\right)\\right)+K T\\epsilon}}\\\\ {{\\qquad\\leq K^{5/2}\\sqrt{T}\\left(1+8\\log(2)+\\frac{9}{2}\\log\\left(\\frac{T}{K^{3}}\\right)\\right)\\,,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with $\\begin{array}{r}{\\epsilon=\\sqrt{\\frac{K^{3}}{T}}}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "C Proof of technical lemmas ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Lemma 4. With the all-winner feedback, the bidder can compute from its feedback the sub-utilities of any pseudo bid in $A(\\mathbf{h}^{t},\\beta^{t})$ , defined as: ", "page_idx": 20}, {"type": "equation", "text": "$$\nA(\\mathbf{h}^{t},\\beta^{t}):=\\left\\{h_{k,j},(k,j)\\in K\\times\\mathcal{I}_{\\epsilon}\\right|s.t.\\ \\left\\{k>x^{t}\\right\\}o r\\left\\{k=x^{t}a n d\\,j\\epsilon\\geq p^{t}\\right\\}\\right\\}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Where $x^{t}:=x_{H}(\\mathbf{h}^{t},\\beta^{t})$ and $p^{t}=p_{H}(\\mathbf{h}^{t},\\beta^{t})$ . ", "page_idx": 20}, {"type": "text", "text": "Proof of Lemma 4. Let $t\\,\\in\\,[T],\\mathbf{h}^{t}$ and $\\beta^{t}$ be the action of the player and the adversary at time $t$ . Let $\\mathbf{b}^{t}$ be the corresponding bid to the pseudo-bid $\\mathbf{h}^{t}$ . Under the all-winner feedback, all winning bids are revealed, hence the feedback reveals to the learner the $K-x(\\mathbf{b}^{t},\\beta^{t})$ biggest bids of the adversary : $(\\beta_{i})_{i\\leq K-x(\\mathbf{b}^{t},\\beta^{t})}$ . Furthermore, since the price is known, the learner can deduce from the rules of the auction that for all $i\\geq K-x(\\mathbf{b}^{t},\\beta^{t})$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\beta_{i}\\leq p(\\mathbf{b}^{t},\\beta^{t}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "For any value $k,j\\in\\mathcal{K}\\times\\mathcal{T}_{\\epsilon}$ such that $h_{k,j}\\,\\in\\,A({\\bf h},\\beta)$ , let\u2019s show that we can evaluate the corresponding sub-utilities. ", "page_idx": 20}, {"type": "text", "text": "We first look at the ability of the learner to evaluate the indicator functions in the sub-utilities defined in Lemma 3, for $h_{k,j}\\in\\dot{A}(\\mathbf{h}^{t},\\beta^{t})$ . ", "page_idx": 20}, {"type": "text", "text": "For the integer values of $k$ , we can rewrite the indicator function of the sub-utilities, as follows : ${\\mathbb{1}}\\big\\{p_{H}({\\bf h},\\beta)^{'}=\\,j\\epsilon\\big\\}\\cap\\big\\{x_{H}({\\bf h},\\beta)\\,=\\,k\\big\\}\\,=\\,{\\mathbb{1}}\\big\\{\\beta_{K-k}\\,>\\,j\\epsilon\\,>\\,\\beta_{K-k+1}\\big\\}$ . When $K\\mathrm{~-~}k\\mathrm{~+~}1\\leq$ ", "page_idx": 20}, {"type": "text", "text": "$K-x(\\mathbf{b}^{t},\\beta^{t})$ this can be evaluated for any value of $j$ , because the adversary bids are known. When $K-k=K-x(\\mathbf{b}^{t},\\beta^{t})$ , the indicator function can still be evaluated if $j\\epsilon>p(\\mathbf{b}^{t},\\beta^{t})$ using (67). ", "page_idx": 21}, {"type": "text", "text": "For the half-integer values of $k$ , we can rewrite the indicator function of the sub-utilities Lemma 2 as follows : $:\\mathbb{1}\\{p_{H}(\\mathbf{\\bar{h}},\\beta)\\in(j\\epsilon,(j+1)\\epsilon)\\}\\cap\\{x_{H}(\\mathbf{h},\\beta)=k-1/2\\}=\\mathbb{1}\\{j\\epsilon<\\beta_{K-k+1/2}<(j+1)\\epsilon\\}.$ Therefore, when $K-k+1/2\\,\\leq\\,K-x(\\mathbf{b}^{t},\\beta^{t})$ this indicator function can be evaluated. Hence when $k\\geq x+1/2$ , and that regardless of the value of $j$ . ", "page_idx": 21}, {"type": "text", "text": "Therefore, it is always possible for the learner to evaluate the indicator function. ", "page_idx": 21}, {"type": "text", "text": "Evaluating the remaining term of the sub-utilities $\\begin{array}{r}{\\sum_{l=1}^{\\lfloor k\\rfloor}v_{l}-p_{H}({\\bf h},\\beta)}\\end{array}$ is more straightforward since it only needs to be done when the indicator function takes value 1. ", "page_idx": 21}, {"type": "text", "text": "For the integer values of $k$ , if the indicator function takes value 1, then $p_{H}(\\mathbf{h},\\beta)=j\\epsilon$ , therefore the remaining term is known. ", "page_idx": 21}, {"type": "text", "text": "For the half-integer values of $k$ , if the transformed indicator function takes value 1, then the price is set by $\\beta_{K-k+1/2}$ , therefore, the remaining term is also known. ", "page_idx": 21}, {"type": "text", "text": "This concludes the proof as the full sub-utilities can always be evaluated on $A(\\mathbf{h},\\beta)$ . ", "page_idx": 21}, {"type": "text", "text": "D Restated results from the literature ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "D.1 Exponential weight forecaster ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this problem of learning under expert advice, they are $N$ expert and at each time $t~\\in~[N]$ , the learner chooses a probability to play each expert $\\bar{(y_{i}^{t})}_{i\\in[N]}\\;\\in\\;\\bar{y}$ and nature reveals the losses $(l_{i}^{t})_{i\\in[N]}\\in[0,L]^{N}$ . ", "page_idx": 21}, {"type": "equation", "text": "$$\nR_{n}=\\sum_{t=1}^{n}\\sum_{i=1}^{N}y_{i}^{t}l_{i}^{t}-\\operatorname*{min}_{i\\in[N]}\\left(\\sum_{t=1}^{n}l_{i}^{t}\\right)\\;.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Theorem 4 (Theorem 2.2 Cesa-Bianchi and Lugosi, 2006). Assume that the losses $l$ take values in $[0,L]$ . For any $n$ and $\\eta>0$ , and for all $y_{1},\\ldots,y_{n}\\in\\mathcal{Y}$ , the regret of the exponentially weighted average forecaster satisfies ", "page_idx": 21}, {"type": "equation", "text": "$$\nR_{n}\\leq\\frac{\\log N}{\\eta}+\\frac{n L^{2}\\eta}{8}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "In particular, with $\\eta=\\sqrt{8\\ln{N/n}}$ , the upper bound becomes $\\sqrt{(n/2)\\ln{N}}$ . ", "page_idx": 21}, {"type": "text", "text": "This theorem, besides the changes in notations, is a slight variation from the original formulation as it allows for losses greater than 1. The resulting $L^{2}$ term in the upper bound is a well known extension and the steps to prove this extension to scaled losses are provided in the original work by Cesa-Bianchi and Lugosi, 2006. ", "page_idx": 21}, {"type": "text", "text": "D.2 Lemma graph feedback ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The following lemma is restated from Alon et al., 2017. ", "page_idx": 21}, {"type": "text", "text": "Lemma 11. Let $G\\,=\\,(V,E)$ be a directed graph with $|V|\\,=\\,K$ , in which each node $i\\in V$ is assigned a positive weight $w_{i}$ . Assume that $\\textstyle\\sum_{i\\in V}w_{i}\\leq1,$ , and that $w_{i}\\geq\\epsilon$ for all $i\\in V$ for some constant $0<\\epsilon<\\textstyle{\\frac{1}{2}}$ . Then ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{i\\in V}\\frac{w_{i}}{w_{i}+\\sum_{j\\in N^{\\mathrm{in}}(i)}w_{j}}\\leq4\\alpha\\ln\\frac{4K}{\\alpha\\epsilon}\\;,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\alpha=\\alpha(G)$ is the independence number of $G$ . ", "page_idx": 21}, {"type": "text", "text": "D.3 First price auction lower bound ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We restate Theorem 10 from (Balseiro et al., 2019) : ", "page_idx": 21}, {"type": "text", "text": "Theorem 5 (Lower Bound for Learning to Bid). Any algorithm must incur $\\Omega(T^{2/3})$ regret for the learning to bid in first-price auctions problem, even if the value of the bidder is fixed (i.e., there is only one context). ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The main claims made in the abstract are presented in the paper, specifically as the two main Theorem 1 and Theorem 2 and Lemma 5. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: The paper discuss and introduces the assumptions made in order for the stated results to hold, most of which are stated in the Introduction 1. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: While the full set of assumption is presented as part of the problem setting in the Introduction 1, proofs of the theorems are provided in the appendix B. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer:[NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not include experiments. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is a theoretical paper, its result are not tied to a specific field. While it might be the basis for further research into applying learning in auction, which would allow for participant in auction to better adapt to others strategies, it is unclear what societal impact this might have and how fit for practical use the techniques develloped here are. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 25}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]