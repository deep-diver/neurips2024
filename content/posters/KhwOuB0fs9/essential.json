{"importance": "This paper is crucial for researchers working with large language models (LLMs) for code generation.  It directly addresses the critical issue of **inefficient LLM-generated code**, a significant hurdle in practical applications. By introducing a self-optimization framework, the research offers a practical solution and opens new avenues for improving LLM efficiency and pushing the boundaries of automated code generation.", "summary": "EFFI-LEARNER: A novel self-optimization framework dramatically improves the efficiency of LLM-generated code by iteratively refining code based on execution profiles.", "takeaways": ["EFFI-LEARNER significantly reduces the execution time and memory usage of LLM-generated code.", "The framework enhances code efficiency through iterative self-optimization guided by execution overhead profiles.", "EFFI-LEARNER demonstrates effectiveness across various open-source and closed-source LLMs and benchmarks."], "tldr": "Large Language Models (LLMs) are increasingly used for code generation, but the generated code often suffers from inefficiency, resulting in longer execution times and higher memory consumption. This inefficiency hinders the practical application of LLMs in various scenarios, especially resource-constrained environments like mobile or embedded systems.  Existing research mainly focuses on code correctness, neglecting the critical aspect of efficiency.\nTo address this, EFFI-LEARNER, a self-optimization framework, is proposed. It leverages execution overhead profiles to iteratively refine LLM-generated code.  The framework first generates code, then profiles its execution time and memory usage. These profiles are fed back into the LLM to revise the code, iteratively improving efficiency. Experiments show that EFFI-LEARNER significantly enhances the efficiency of LLM-generated code across various models and benchmarks, substantially reducing execution time and memory consumption.", "affiliation": "University of Hong Kong", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "KhwOuB0fs9/podcast.wav"}