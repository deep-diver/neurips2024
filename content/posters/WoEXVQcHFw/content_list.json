[{"type": "text", "text": "Gliding over the Pareto Front with Uniform Designs ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Xiaoyuan Zhanga, Genghui Li b, Xi Lin a, Yichi Zhangc, Yifan Chend, Qingfu Zhanga ", "page_idx": 0}, {"type": "text", "text": "a Department of Computer Science, City University of Hong Kong; b College of Computer Science and Software Engineering, Shenzhen University c Department of Statistics, Indiana University Bloomingtom d Departments of Mathematics and Computer Science, Hong Kong Baptist University ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Multiobjective optimization (MOO) plays a critical role in various real-world domains. A major challenge therein is generating $K$ uniform Pareto-optimal solutions that represent the entire Pareto front. To address the very challenge, this study first introduces fill distance to evaluate the $K$ design points, which provides a quantitative metric for the representativeness of the design. However, the direct specification of the optimal design that minimizes flil distance is almost intractable considering the nested $\\operatorname*{min}-\\operatorname*{max}-\\operatorname*{min}$ optimization problem. We further propose a surrogate to the fill distance, which is easier to optimize and induce a rate-optimal design whose fill distance proves at most $4\\times$ the minimum one. Rigorous derivation also shows that asymptotically this induced design will converge to the uniform measure over the Pareto front. Extensive experiments on synthetic and real-world benchmarks demonstrate that our proposed paradigm efficiently produces high-quality, representative solutions and outperforms baseline methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Multiobjective optimization (MOO) is frequently utilized to guide the real-world decision-makings, such as in the field of material sciences [20, 47, 5, 30], recommendation systems [29, 63, 32], and industrial design [45, 52, 50, 58]. An MOO problem (MOP) involves multiple confilcting objectives, which can be informally formulated as: ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{X}}f(\\pmb{x})=(f_{1}(\\pmb{x}),\\dots,f_{m}(\\pmb{x})),\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $m$ is the number of objectives. Noted that Equation (1) is a vector optimization problem and it does not admit a total ordering. To address that, the concept of Pareto optimality is therefore introduced. A solution is called Pareto optimal if no other $\\mathbf{\\boldsymbol{x}}^{\\prime}\\in\\mathcal{X}$ can dominate them. Domination occurs if $f_{i}({\\pmb x}^{\\prime})\\leq f_{i}({\\pmb x})$ for all $i$ in 1 to $m$ , with at least one strict inequality [38, 19]. The image $\\pmb{f}(\\pmb{x})$ of a Pareto optimal solution is called a Pareto objective in this paper. The set of all such optimal solutions is the Pareto set (PS), and their objectives constitute the Pareto front (PF). ", "page_idx": 0}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/7e9d0e774933458aa0fddb43bbbcf284e248f81a75a12f8e728a4a78e0da4d85.jpg", "img_caption": ["Figure 1: Covering of a Pareto Front (PF). Eight uniformly distributed Pareto objectives are used to cover the entire PF with a small covering radius. "], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Under mild conditions, a PS or PF forms a continuous $(m{-}1)$ -dim manifold containing infinitely many solutions [25]. For a general MOP, it is intractable to precisely depict the entire PS or PF with a closed-form expression. Researchers thus turns to use a small number $K$ of diverse Pareto optimal objectives to \u201crepresent\u201d the entire PF. There is number of prior works focused on generating diverse solutions (see Section 2), however they lacked formal definitions of representability and uniformity. In this paper, we define representability as the covering radius of a size- $\\mathcal{K}$ solution covering the entire PF. An illustrative example is provided in Figure 1, where eight uniformly distributed covers the entire PF with a small radius. In addition to representability, we describe uniformity through the configuration of non-asymptotic Pareto objectives and asymptotic uniformity when the number of $K$ tends to infinity. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this paper, we first introduce the fill distance (FD) as the minimal covering radius of the Pareto objectives, measuring how well discrete solutions represent the true PF. A configuration with a small covering radius is considered a good representation of the PF. Secondly, we find that optimizing FD is challenging due to its nested $\\operatorname*{min}-\\operatorname*{max}-\\operatorname*{min}$ structure (Equation (4)). To address this, we maximize the minimal (max \u2212min) pairwise distances of Pareto objectives that bounds the minimal covering radius up to a constant. Finally, we design a bi-level optimization framework based on neural network approximation to efficiently solve this max \u2212min problem. ", "page_idx": 1}, {"type": "text", "text": "Our method, called UMOD (Uniform Multi-Objective optimization based on Decomposition), is an important extension of the decomposition-based MOO paradigm [59]. We conduct comparative evaluations against methods on complex multiobjective problems with numerous local optimas and on fairness classification problems with thousands of decision variables. Empirical results demonstrate the effectiveness of our proposal. The contribution of this paper can be summarized as: ", "page_idx": 1}, {"type": "text", "text": "1. We introduce the flil distance for a set of Pareto objectives as a new uniformity metric in multiobjective optimization, establishing a framework for measuring uniformity in MOO. Additionally, we reveal a surrogate objective function: maximizing the minimal pairwise distances of a size- $K$ solution set on the PF, yielding a design with a flil distance that bounds the minimal flil distance up to a constant, regardless of the number $(K)$ of solutions.   \n2. We propose constructing the maximizing minimal distance design as a bi-level optimization problem and using neural networks to enhance efficiency. We provide optimization error bounds for this problem and present a practical solution algorithm, UMOD.   \n3. Finally, we evaluate our approach against leading MOO methods, including evolutionary algorithms and gradient-based algorithms, on both synthetic and real-world problems. UMOD surpasses these methods in terms of uniformity and efficiency on popular metrics used in multiobjective optimization. ", "page_idx": 1}, {"type": "text", "text": "Notations. In this paper, $\\rho(\\pmb{y}^{(a)},\\pmb{y}^{(b)})$ represents the Euclidean distance between vectors $\\pmb{y}^{(a)}$ and $\\pmb{y}^{(b)}$ , with bold letters for vectors. Superscripts distinguish vectors, and subscripts (e.g., $y_{i}$ ) indicate vector elements. A PF is denoted by $\\tau$ . The objective space is $\\mathcal{V}=\\{\\pmb{y}\\ |\\ f(\\pmb{x}),\\pmb{x}\\in\\mathcal{X}\\}$ . $\\Delta_{m}$ is the $m$ -D preference simplex; $\\begin{array}{r}{\\Delta_{m}=\\stackrel{{\\cdot}}{\\left\\{\\pmb{y}\\mid\\sum_{i=1}^{m}\\check{y_{i}}=1,\\check{y_{i}}\\geq0,i\\in[m]\\right\\}}}\\end{array}$ , where $[m]=\\{1,\\ldots,m\\}$ . Black bold notations (e.g., Y) denote solu tion sets. ", "page_idx": 1}, {"type": "text", "text": "2 Related works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section, we review three lines of works to generate uniform or diverse Pareto objectives. We focus our discussions on uniform/diverse Pareto objectives rather than Pareto solutions because our goal is to produce uniform Pareto solutions in the objective space $(\\mathcal{V})$ , not the decision space $(\\mathcal{X})$ . ", "page_idx": 1}, {"type": "text", "text": "2.1 Methods to generate diverse Pareto objectives ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Various MOO methods effectively generate diverse Pareto objectives, for both gradient-based and evolution-computation (EC)-based frameworks. In the line of gradient-based methods, Pareto MultiTask Learning (PMTL) [33] produces Pareto objectives which are constrained in specific regions (sectors); MOO with Stein Variational Gradient Descent (MOO-SVGD) models objective vectors as particles, updating them through repulsive forces to maximize their separation; Exact Pareto Optimization (EPO) [37] aligns solutions with user-specific preference vectors, fostering a diverse distribution of Pareto objectives by utilizing varied preferences. For multiobjective evolutionary algorithms (MOEAs), NSGA2 [14] introduces the crowding distance and Pareto rank to achieve a diverse distribution of Pareto objectives; NSGA3 [13, 27] introduces a new diversity preservation technique based on reference points; MOEA/D [59] and its variants generate diverse Pareto objectives by leveraging the positional relationship between preference vectors and Pareto objectives; ", "page_idx": 1}, {"type": "text", "text": "Hypervolume-based methods (e.g., SMS-MOEA [6]) maximize the set of solutions with the greatest hypervolume to enhance diversity. A key distinction of the proposed UMOD method with the previously mentioned methods is that, for general MOPs, the distribution of the achieved Pareto objectives remains unknown, whereas, important distribution characteristics of its achieved Pareto objectives can be determined by UMOD. ", "page_idx": 2}, {"type": "text", "text": "2.2 Subset selection for multiobjective optimization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Another approach to generating a size- $K$ diverse Pareto set is subset selection. This method first generates numerous objectives on the PF, then selects $K$ solutions to maximize hypervolume or minimize IGD [23, 53, 9, 46]. Subset selection, a discrete optimization problem, is generally inefficient to solve compared with continuous optimization problems. Recently, some approaches employ greedy algorithms [9, 34, 28] to obtain approximate solutions, with naive greedy methods typically providing a $(1\\!-\\!1/e)$ guarantee. In contrast, our method addresses a continuous optimization problem on the PF, using gradient-based techniques to solve the established optimization problem to improve both accuracy and efficiency. ", "page_idx": 2}, {"type": "text", "text": "2.3 Preference adjustment methods in the decomposition-based MOO paradigm ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Since the proposed method can be classified under the preference adjustment category, we also discuss the relationship between the proposed UMOD and preference/weight2 adjustment methods. Preference adjustment stems from MOEA/D-AWA [41], where its strategy is to remove the preference corresponding to the most crowded objective and add a preference corresponding to the most sparse one. Subsequently, several preference adjustment methods have been introduced [36], including DEA-GNG [35] and MOEA/D-SOM [22], which utilize neural gas networks to guide the selection of preference vectors. Other approaches, such as W-MOEA/D [21], tw-MOEA/D [39], pa\u03bb-MOEA/D [49], and MOEA/D-AWG [56], use mathematical models to shape the non-dominated solutions and adjust preference vectors, achieving a diverse distribution of Pareto-optimal objectives. The proposed method differs from other preference adjustment methods in two key ways: (1) it models the PF using a neural network, offering both accuracy and efficiency, and (2) it provides rigorous theoretical analysis for selecting preference vectors that ensure uniformity and representativeness. ", "page_idx": 2}, {"type": "text", "text": "3 Pareto solutions with uniform designs ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 FD as an upper bound of IGD ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We first define flil distance (FD) [11] of a set $\\mathbb{Y}$ $(\\mathbb{Y}=[\\pmb{y}^{(1)},\\dots,\\pmb{y}^{(K)}])$ and establish its relationship with the inverted generalized distance (IGD) indicator [54] of a set Y, a famous metric in MOO. FD and IGD are defined as follows: ", "page_idx": 2}, {"type": "text", "text": "Definition 1 (FD & IGD). ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{FD}(\\mathbb{Y})=\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{T}}\\operatorname*{min}_{\\pmb{y}^{\\prime}\\in\\mathbb{Y}}\\rho(\\pmb{y},\\pmb{y}^{\\prime})=\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{T}}\\mathrm{dist}(\\pmb{y},\\mathbb{Y}),\\qquad\\mathrm{IGD}(\\mathbb{Y})=\\int_{\\mathcal{T}}\\operatorname*{min}_{\\pmb{y}^{\\prime}\\in\\mathbb{Y}}\\rho(\\pmb{y},\\pmb{y}^{\\prime})d\\pmb{y},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\rho(\\cdot,\\cdot)$ represents the Euclidean distance between two vectors. The term $\\begin{array}{r}{\\mathbf{\\ddot{\\rho}}^{\\star}\\mathbf{min}_{\\pmb{y}^{\\prime}\\in\\mathbb{Y}}\\,\\rho(\\pmb{y},\\pmb{y}^{\\prime})^{\\star}}\\end{array}$ represents the nearest distance from a point $\\textit{\\textbf{y}}$ on the PF to the reference set $\\mathbb{Y}$ . Therefore, $\\operatorname{FD}(\\mathbb{Y})=$ $\\begin{array}{r}{\\operatorname*{max}_{\\pmb{y}\\in\\mathcal{T}}\\operatorname*{min}_{\\pmb{y}^{\\prime}\\in\\mathbb{Y}}\\rho(\\pmb{y},\\pmb{y}^{\\prime})}\\end{array}$ denotes the covering radius of $\\mathbb{Y}$ , i.e., the largest radius within which at least one solution in $\\mathbb{Y}$ covers the entire PF. However, IGD(Y), which represents the average distance from a point on the PF to the set Y, lacks the clear geometric interpretation that fill distance offers. For MOO, the goal is to minimize a set of Pareto objectives, i.e., $\\mathbb{Y}\\subset\\tau$ , by optimizing either the FD or IGD indicator: $\\mathrm{min}_{\\mathbb{Y}\\subset\\mathcal{T}}\\,\\mathrm{FD}(\\mathbb{Y})$ or $\\operatorname*{min}_{\\mathbb{Y}\\subset{\\cal T}}\\operatorname{IGD}(\\mathbb{Y})$ to reach a diverse distribution. Let the optimal sets be $\\mathbb{Y}^{\\mathrm{FD}}$ and $\\mathbb{Y}^{\\mathrm{IGD}}$ , respectively. The following theorem compares FD and IGD. ", "page_idx": 2}, {"type": "text", "text": "Theorem 2 (FD is an upper bound of IGD). ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{IGD}(\\mathbb{Y}^{\\mathrm{IGD}})\\leq\\mathrm{IGD}(\\mathbb{Y}^{\\mathrm{FD}})\\leq\\mathrm{FD}(\\mathbb{Y}^{\\mathrm{FD}})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The first inequality holds by definition since $\\mathbb{Y}^{\\mathrm{IGD}}$ minimizes IGD, while the second inequality holds because, for a fixed configuration $\\mathbb{Y}^{\\mathrm{FD}}$ , the average distance $(\\mathrm{IGD}(\\mathbb{Y}^{\\mathrm{FD}}))$ is always less than or equal to the maximum distance $(\\mathrm{FD}(\\mathbb{Y}^{\\mathrm{FD}}))$ ). Theorem 2 establishes that the optimal configuration of FD $(\\mathbb{Y}^{\\mathrm{FD}})$ provides an upper bound for the IGD value. However, to the best of our knowledge, the optimal configuration of IGD does not offer a similar bound for FD. This distinction is one of the reasons we focus on discussions on FD in this paper. ", "page_idx": 3}, {"type": "text", "text": "3.2 Max-packing design as a surrogate of FD design ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The minimization of FD involves solving the following nested $\\operatorname*{min}-\\operatorname*{max}-\\operatorname*{min}$ problem: ", "page_idx": 3}, {"type": "equation", "text": "$$\nd^{\\mathrm{FD}}=\\operatorname*{min}_{\\mathbb{Y}\\subset{\\mathcal{T}}}\\operatorname*{max}_{{\\pmb y}\\in{\\mathcal{T}}}\\operatorname*{min}_{{\\pmb y}^{\\prime}\\in\\mathbb{Y}}\\rho({\\pmb y},{\\pmb y}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "A small $d^{\\mathrm{FD}}$ indicates that the optimal configuration $\\mathbb{Y}^{\\mathrm{FD}}$ can well cover the entire PF with a relatively low covering radius. However this triply nested structure is known difficult to be optimized [55, 40]. Thus, we plan to seek a surrogate max-packing problem, ", "page_idx": 3}, {"type": "equation", "text": "$$\nd^{\\mathrm{Pack}}=\\operatorname*{max}_{\\mathbb{Y}\\subset\\mathcal{T}}\\delta=\\operatorname*{max}_{\\mathbb{Y}\\subset\\mathcal{T}}\\left(\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(j)})\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\delta$ represents the separation distance between two vectors. The optimal design $\\mathbb{Y}^{\\mathrm{Pack}}$ , which solves the optimization problem (Equation (5)), is known as the best-packing design [8]. In this paper, we show in Theorem 3 that $\\mathbb{Y}^{\\mathrm{Pack}}$ effectively optimizes FD when the decision space is a $P F$ , as $\\dot{d}^{\\mathrm{FD}}$ is bounded by $\\mathbb{Y}^{\\mathrm{Pack}}$ up to a constant factor, independent of size $K$ . ", "page_idx": 3}, {"type": "text", "text": "Theorem 3 (Surrogate for minimal FD). Consider a connected, compact $^3\\,P F\\,\\tau$ . The minimal fill distance $d^{\\mathrm{FD}}$ between $\\tau$ and a size- $K$ design $\\mathbb{Y}^{\\mathrm{Pack}}/\\mathbb{Y}^{\\mathrm{FD}}$ will then be bounded as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\frac{1}{4}d^{\\mathrm{Pack}}\\leq d^{\\mathrm{FD}}\\leq\\mathrm{FD}(\\mathbb{Y}^{\\mathrm{Pack}})\\leq d^{\\mathrm{Pack}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Furthermore, the fill distance between $\\tau$ and the optimal design $d^{\\mathrm{Pack}}$ induced by $\\mathbb{Y}^{\\mathrm{Pack}}$ is upper bounded by $d^{\\mathrm{Pack}}$ , which is guaranteed to be upper bounded by $4d^{\\mathrm{FD}}$ . $\\mathbb{Y}^{\\mathrm{Pack}}$ is thus considered $a$ quality, rate-optimal representative for the whole $P F\\,\\tau$ . ", "page_idx": 3}, {"type": "text", "text": "The second inequality $d^{\\mathrm{FD}}\\leq d^{\\mathrm{Pack}}$ is proved by Auffray et al. [3], Pronzato [40], and we provide a tighter lower bound $d^{\\mathrm{Pack}}/4$ , utilizing the topological property of a PF. The complete proof of Theorem 3 is left in Appendix A.1. ", "page_idx": 3}, {"type": "text", "text": "Furthermore, under an additional strict inequality condition $d_{K}^{\\mathrm{Pack}}\\,<\\,d_{K+1}^{\\mathrm{Pack}}$ on the PF, the maxspuabcskcirnigp td \u201ce sig  YPKack ns caslelryv edse naos tea $d_{K}^{\\mathrm{Pack}}$ m-caoxv-peraicnkgi nogf $\\tau$ s, tawnhciec stfaobr lias shiezde - dTehseiogrne, msi 4m.i laTrhley $K^{\\bullet}$ $d_{K}^{\\mathrm{Pack}}$ $\\mathcal{K}$ used for $\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ to represent a size- $K$ design. ", "page_idx": 3}, {"type": "text", "text": "Theorem 4. Consider a connected, compact $P F\\,\\tau$ with the property $d_{K}^{\\mathrm{Pack}}<d_{K+1}^{\\mathrm{Pack}}$ , the max-packing design covers with radius of at most . K+1 $\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ $\\tau$ $d_{K}^{\\mathrm{Pack}}$ ", "page_idx": 3}, {"type": "text", "text": "This theorem suggests that $\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ can represent $\\tau$ well since the maximal distance between any vector $\\pmb{y}\\in\\mathcal{T}$ and $\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ is bouKnded by $d_{K}^{\\mathrm{Pack}}$ . ", "page_idx": 3}, {"type": "text", "text": "3.3 Characterizations of a max-packing design ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "This section discusses key properties of the max-packing design on a PF. For bi-objective problems, $\\mathbb{Y}^{\\mathrm{Pack}}$ exhibits favorable properties when $\\mathbb{Y}^{\\mathrm{Pack}}\\subset\\tau$ , as formalized in Theorem 5. The proof is provided in Appendix A.2. ", "page_idx": 3}, {"type": "text", "text": "Theorem 5 (Characterization of $\\mathbb{Y}^{\\mathrm{Pack}}$ for biobjective problems). Let $\\mathbb{Y}^{\\mathrm{Pack}}=\\left[\\pmb{y}^{(1)},\\dots,\\pmb{y}^{(K)}\\right]b e$ sorted by increasing first component, such that $y_{1}^{(1)}\\leq\\ldots\\leq y_{1}^{(K)}$ . For a compact, connected $\\tau$ YPack is characterized as follows: ", "page_idx": 3}, {"type": "text", "text": "1. Equal spacing: $\\rho({\\pmb y}^{(1)},{\\pmb y}^{(2)})=\\ldots=\\rho({\\pmb y}^{(K-1)},{\\pmb y}^{(K)}).$ 3A connected, compact set is also called a rectifiable set. ", "page_idx": 3}, {"type": "text", "text": "2. Endpoint alignment: $\\pmb{y}^{(1)}$ and $\\pmb{y}^{(K)}$ are two endpoints $(\\pmb{p}^{(1)},\\pmb{p}^{(2)})$ of $\\tau$ , i.e., $\\pmb{y}^{(1)}\\,=\\,\\pmb{p}^{(1)}\\,=$ $[\\operatorname*{inf}_{y\\in\\mathcal{T}}y_{1},\\operatorname*{sup}_{y\\in\\mathcal{T}}y_{2}]$ and $\\pmb{y}^{(K)}=\\pmb{p}^{(2)}=[\\operatorname*{sup}_{\\pmb{y}\\in\\mathcal{T}}y_{1},\\operatorname*{inf}_{\\pmb{y}\\in\\mathcal{T}}y_{2}]$ . ", "page_idx": 4}, {"type": "text", "text": "Remark. According to Theorem 5, first, $\\mathbb{Y}^{\\mathrm{Pack}}$ , including both the starting and ending points, spans the maximum range among all configurations, which is desirable. Second, equal pairwise distances between Pareto objectives yields an intuitive interpretation of uniformity. Maximizing hypervolume ensures the \u201cequal spacing\u201d property for bi-objective linear PFs [4][Theorem 4], while our design only requires the PF to be compact and connected. ", "page_idx": 4}, {"type": "text", "text": "Besides this bi-objective results, we examine the asymptotic properties of $\\mathbb{Y}^{\\mathrm{Pack}}$ by Theorem 6. ", "page_idx": 4}, {"type": "text", "text": "Theorem 6 (Asymptotic uniformity [8](Theorem. 2.1)). As $K\\rightarrow\\infty$ , the set sequence $\\{\\mathbb{Y}_{K}^{\\mathrm{Pack}}\\}$ weakly converge to a uniform distribution over a compact, connected $\\tau$ . Specifically, for any subset $B\\subset\\tau$ with measure-zero boundary, the proportion of points in $\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ lying within $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ converges to the proportion of $\\tau$ occupied by : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{K\\to\\infty}\\frac{\\#(\\mathbb{Y}_{K}^{\\mathrm{Pack}}\\cap B)}{\\#(\\mathbb{Y}_{K}^{\\mathrm{Pack}})}=\\frac{\\mathrm{Vol}(B)}{\\mathrm{Vol}(\\mathcal{T})}=\\mathbb{P}(\\pmb{y}\\in B\\mid\\pmb{y}\\in\\mathcal{T}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where # denotes the number of points in a set, and \u201cVol\u201d denotes the volume of a set. ", "page_idx": 4}, {"type": "text", "text": "eSTaphceehco wdhosa mtsh  pvarta oraibasa btblhiele $K$ nmg rdeioaswntrisin,b $\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ .so rai cuanl idfiosrtrmi bduitsitorni bwuthieorne. $Y_{K}^{\\mathrm{Pack}}\\stackrel{d}{\\to}\\mathrm{Unif}({\\mathcal{T}})$ ${\\pmb Y}_{K}^{\\mathrm{Pack}}$ $\\pmb{y}\\in\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ $1/K$ $\\mathrm{Unif}(T)$ ", "page_idx": 4}, {"type": "text", "text": "4 Efficient optimization of a size- $K$ uniform set ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The original max-packing problem (Equation (5)) maximizes the minimal pairwise distance among Pareto objectives and can be reformulated as the following constrained optimization problem on the PF: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\left(\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(j)})\\right)\\qquad\\qquad{\\mathrm{s.t.~}}\\pmb{y}^{(i)},\\pmb{y}^{(j)}\\in\\mathcal{T}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To constrain $\\pmb{y}^{(i)},\\pmb{y}^{(j)}$ pairs as Pareto objectives, we solve decision variables of $\\pmb{y}^{(i)}$ \u2019s as the optimal solution of the following modified Tchebycheff (mTche) aggregation function (Equation (9)), ", "page_idx": 4}, {"type": "equation", "text": "$$\ny=\\tilde{h}(\\lambda)=\\arg\\operatorname*{min}_{y^{\\prime}\\in\\mathcal{Y}}\\left\\{{\\frac{y_{i}-z_{i}}{\\lambda_{i}}}\\right\\}:\\qquad\\qquad\\left[0,{\\frac{\\pi}{2}}\\right]^{m-1}\\mapsto\\mathbb{R}^{m},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $_{\\textit{z}}$ is a reference point $(z_{i}\\leq y_{i},\\forall\\pmb{y}\\in\\mathcal{Y},\\forall i\\in[m])$ . This substitution is equivalent when the optimal solution of Equation (9) is unique, as for any Pareto objective $\\textit{\\textbf{y}}$ , there exists a preference $\\lambda\\,\\in\\,\\Delta_{m}$ such that the optimal value of Equation (9) matches $\\textit{\\textbf{y}}$ . This argument is proved in Appendix A.4. ", "page_idx": 4}, {"type": "text", "text": "Example 7. Specific formulations of $\\tilde{h}(\\lambda)$ on famous MOPs include: ", "page_idx": 4}, {"type": "text", "text": "1. ZDT1: $y_{1}=k\\lambda_{1},y_{2}=k(1-\\lambda_{1})$ , where $k=(2-\\lambda_{1}-\\sqrt{-3\\lambda_{1}^{2}+4\\lambda_{1}})/2(\\lambda_{1}-1)^{2}.$   \n2. ZDT2: $y_{1}=k\\lambda_{1},y_{2}=k(1-\\lambda_{1})$ , where $k=(\\lambda_{1}-1+\\sqrt{5\\lambda_{1}^{2}-2\\lambda_{1}+1})/2\\lambda_{1}^{2}$ .   \n3. DTLZ1: $y_{i}=0.5\\lambda_{i}$ , for $i={1,2,3}$ . ", "page_idx": 4}, {"type": "text", "text": "The formulations and PFs of the three problems are provided in Appendix C.2. These examples indicate that uniform Pareto objectives are only achievable when the true PF is affine to simplexes (e.g., on DTLZ1 problem), where $\\tilde{h}(\\lambda)$ is also affine. In most other cases, the non-linearity of $\\tilde{h}(\\lambda)$ prevents uniform Pareto objectives. Substituting Equation (9) into Equation (8) yields the following bi-level optimization problems: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle{\\int}^{\\mathrm{Pack}}=\\operatorname*{max}_{\\vartheta^{(1)},\\ldots,\\vartheta^{(K)}}\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho({\\boldsymbol y}^{(i)},{\\boldsymbol y}^{(j)})}\\\\ {\\displaystyle{\\;\\;}^{y^{(k)}}=\\arg_{y^{(k)}\\in\\mathcal{Y}}\\left\\{\\frac{y_{i}^{(k)}-z_{i}}{\\lambda_{i}(\\vartheta^{(k)})}\\right\\},\\,i\\in[m].}\\end{array}\\right.\\Rightarrow\\quad\\left\\{\\begin{array}{l l}{\\displaystyle{d^{\\mathrm{Pack}}=\\operatorname*{max}_{\\vartheta^{(1)},\\ldots,\\vartheta^{(K)}}\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho(h(\\vartheta^{(i)}),h(\\vartheta^{(i)}))}}\\\\ {\\displaystyle{\\mathrm{s.t.}\\quad\\vartheta^{(k)}\\in\\left[0,\\frac{\\pi}{2}\\right]^{m-1}.}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The function $\\lambda(\\vartheta)$ converts a \u201cpreference angle\u201d from an angle space $\\left[0,{\\frac{\\pi}{2}}\\right]^{m-1}$ into a preference vector. The conversion relationship is detailed in Appendix C.3. We use $\\lambda(\\vartheta)$ as decision variables for easier optimization since $\\lambda(\\vartheta)$ is constrained in a box. In the right equation, the Pareto objective is denoted as $\\pmb{y}=h(\\pmb{\\vartheta})=\\tilde{h}(\\pmb{\\lambda}(\\pmb{\\vartheta}))$ . Various bi-level optimization methods [48, 62] can be used to solve problem (Equation (10)). For efficiency consideration, we propose to use a gradient-based approach. Define $\\delta=\\operatorname*{min}_{(i,j)}\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(j)})$ , where $(i^{*},j^{*})$ is the optimal pair from $\\arg\\operatorname*{min}_{(i,j)}\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(j)})$ After some simple algebraic calculations, $\\frac{\\partial\\delta}{\\partial\\pmb{\\vartheta}}$ can be calculated by the following two equations: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\frac{\\partial\\delta}{\\partial\\vartheta^{(i^{*})}}=\\underbrace{\\frac{\\partial h(\\vartheta^{(i^{*})})}{\\partial\\vartheta^{(i^{*})}}}_{B(n\\times m)}\\underbrace{\\frac{h(\\vartheta^{(i^{*})})-h(\\vartheta^{(j^{*})})}{\\rho(h(\\vartheta^{(i^{*})}),h(\\vartheta^{(j^{*})}))}}_{A(1\\times m)}^{\\top},\\quad\\frac{\\partial\\delta}{\\partial\\vartheta^{(j^{*})}}}&{=-\\underbrace{\\frac{\\partial h(\\vartheta^{(j^{*})})}{\\partial\\vartheta^{(j^{*})}}}_{C(n\\times m)}\\underbrace{\\frac{h(\\vartheta^{(i^{*})})h(\\vartheta^{(j^{*})})}{\\rho(h(\\vartheta^{(i^{*})}),h(\\vartheta^{(j^{*})}))}}_{A(m\\times1)},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The remaining terms $\\begin{array}{r}{\\frac{\\partial\\delta}{\\partial\\pmb{\\vartheta}(k)},k\\,\\neq\\,i^{*},j^{*}}\\end{array}$ are zero vectors. Calculating the gradient vector $\\pmb{A}$ is straightforward by using basic algebra calculations. However, computing the gradient matrices $_B$ or $_{C}$ is difficult because $h(\\vartheta)$ is a black-box function, representing the optimal values of an optimization problem. Estimating matrices $_B$ or $_{C}$ using finite difference is impractical, as it requires solving Equation (9) for at least $n\\times m$ times, which is highly time-consuming. To efficiently estimate $\\frac{\\partial h}{\\partial\\vartheta}$ , we propose using a neural model $h_{\\phi}$ to approximate $^h$ based on historical data $(\\vartheta,h(\\vartheta))$ , allowing us to estimate \u2202\u03d1h vi a \u2202\u2202h\u03d1\u03d1\u03d1\u03d5 . Since a neural network is introduced, we analyze its induced error in Theorem 8, with the full proof in Appendix A.3. ", "page_idx": 5}, {"type": "text", "text": "Theorem 8 (Optimization error $\\epsilon_{\\mathrm{nn}}$ introduced by using a network). Let $h_{\\phi}(\\vartheta)$ be an approximator of $h(\\vartheta)$ such that $||h_{\\phi}(\\pmb{\\vartheta})-h(\\pmb{\\vartheta})||\\leq\\epsilon,$ , for every $\\pmb{\\vartheta}\\in[0,\\frac{\\pi}{2}]^{m-1}$ , as commonly assumed in bi-level optimization, e.g., $I I8J,$ , Eq. $(I O,$ . $\\epsilon_{\\mathrm{nn}}$ is the difference between the maximum of the minimal distances calculated using the approximate function $h_{\\phi}$ and the true function $^h$ . Then, $\\epsilon_{\\mathrm{nn}}$ is bounded by $2\\epsilon$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\epsilon_{\\mathrm{nn}}=\\left|\\operatorname*{max}_{\\substack{\\vartheta^{(1)},\\ldots,\\vartheta^{(K)}}}\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho(h_{\\phi}(\\vartheta^{(i)}),h_{\\phi}(\\vartheta^{(j)}))-d^{\\mathrm{Pack}}\\right|\\leq2\\epsilon.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Remark. The error $\\epsilon$ , defined as $||h_{\\phi}(\\pmb\\vartheta)\\rrangle-h(\\pmb\\vartheta)||\\le\\ \\epsilon\\rrangle$ , is influenced by the covering radius $R$ of the estimated solutions $h_{\\phi}(\\pmb{\\vartheta}^{(1)}),\\dots,h_{\\phi}(\\pmb{\\vartheta}^{(K)})$ and the fitting error $\\epsilon_{\\mathrm{fit}}$ , where $\\epsilon_{\\mathrm{fit}}\\;=\\;$ $\\mathrm{max}_{k\\in[K]}\\,||h_{\\phi}(\\pmb{\\vartheta}^{(k)})-h(\\pmb{\\vartheta}^{(k)})||$ . For any $\\vartheta$ , the error satisfies $||h_{\\phi}(\\vartheta)-h(\\vartheta)||\\leq L||\\vartheta-\\vartheta^{(i^{\\prime})}||+$ $\\epsilon_{\\mathrm{fit}}\\leq L\\cdot R+\\epsilon_{\\mathrm{fit}}$ , where $L$ is the Lipschitz constant of function $(h_{\\phi}(\\vartheta)-h(\\vartheta)),\\vartheta^{(i^{\\prime})}$ is the nearest solution to $\\vartheta$ among the estimated solutions, and $R$ is the covering radius, which can be further reduced by adding more training pairs. For overparameterized networks, $\\epsilon_{\\mathrm{fit}}$ can be considered as negligible. ", "page_idx": 5}, {"type": "text", "text": "Practical algorithms. Due to the space limit, the pseudo-codes for UMOD are provided in Algorithm 1 and Algorithm 2 in Appendix C.1. Initially, we generate $K$ approximately uniform preferences using the Das-Dennis method [12]. Then either a multiobjective evolutionary algorithm based on decomposition (MOEA/D) [59] or a gradient-based MOO with the mTche aggregation function is employed for producing preference angle and Pareto objective pairs $(\\vartheta,y)$ . MOEA/D is suitable for problems with many local optima, while gradient-based MOO is more efficient for multiobjective multitask learning (MOMTL) problems. Based on $(\\vartheta,y)$ pairs, a PF model $h_{\\phi}(\\vartheta)$ is fitted by optimizing the mean square estimation error. Finally, preference angles are updated to maximize the minimal pairwise distances of Pareto objectives. These steps are repeated for $N$ iterations until convergence. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The experiments compare UMOD with other methods on two types of MOPs: (1) those with many local optimas which can be solved by MOEAs efficiently, and (2) multiobjective fairness classification neural networks as decision variables. MOEAs and multiobjective fairness problems are executed with 31/5 random seeds, separately. We employ seven indicators to assess performance of different algorithms: (1) Hypervolume (\u2191) [24], (2) IGD (\u2193) [26], (3) Sparsity (\u2193) [57], (4) Spacing (\u2193) [44], (5) Uniformity (\u2191), (6) Soft Uniformity (\u2191), and (7) Fill distance $\\left(\\downarrow\\right)$ . Indicators 1-2 focus on convergence and diversity for multi-objective optimization (MOO), while indicators 3-7 evaluate solution uniformity. See Appendix B.1 for more detailed expression for these indicators. ", "page_idx": 5}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/71fbabfb4f42a2fc06c3d64e4cd897376ce983831e8a757534931dd453e09830.jpg", "img_caption": ["Figure 3: Result comparison on ZDT1. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "5.1 Comparison with MOEAs ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We demonstrate the effectiveness of our proposed method across a diverse set of MOEA benchmark problems, including the ZDT series4 [16], and DTLZ problems $1\\!-\\!6\\ \\ [15]^{5}$ , as well as various real-world problem instances [50]. The real-world cases include: four-bar truss design (RE21), reinforced concrete beam design (RE22), disc brake design (RE33), rocket injector design (RE37), car side impact design (RE41), and conceptual marine design (RE42). Notably, RE41 and RE42 are complex four-objective problems that involve extensive fourdimensional objective spaces. The prefix \u201cRE\u201d denotes real-world scenarios. ", "page_idx": 6}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/3821f41d326df3fd01422ffc08cd80b28fb3b20be1f9dea7c4ef1fa85c400760.jpg", "img_caption": ["(a) UMOD and MOEA/D (b) Visualization on RE37 "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 2: Result on RE37. (a): UMOD solutions are more uniform. (b): A PF model can be trained with a small number of solutions. ", "page_idx": 6}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/3c395197cd9b487d4f22c6a8c84a1a2895a134394b9a4ccfb10332c3429158f7.jpg", "table_caption": ["Table 1: Partial results for biobjective problems (full results are in Table 7). "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Multiobjective testing problems often have many local Pareto optimal solutions, leading to comparisons primarily with MOEAs. These include: (1) MOEA/D [59], a decomposition-based approach; (2) MOEA/D-AWA [41], integrating adaptive weight adjustment; (3) NSGA3 [13, 27], generating diverse Pareto objectives through crowding distance; (4) SMS-EMOA [6], maximizing hypervolume for diverse solutions; (5) LMPFE [51], estimating the PF using multiple local models; (6) Subset selection [9, 46], choosing a solution set by hypervolume maximization 6; and (7) DEA-GNG [35], a preference adjustment method based on growing neural gas network. Methods (1)-(4) are classical MOEA methods implemented by Pymoo [7], while methods (5)-(7) are more recent methods. Full name of these methods are provided in Table 4. ", "page_idx": 6}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/bcfd07c0fb52c16f2d1284b60c2f7f8363423469ac2433b58c017097a3fb0fda.jpg", "img_caption": ["Figure 4: Results on RE21 and DTLZ2. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/da59a19b7205e128e02fe8d82d80d2d3f5e5da70346375afc1ff1ab948b93295.jpg", "img_caption": ["Figure 5: Results on RE41 (full results are in Figure 8). "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/ae0c648a17fa86737e0a9cde465e707189a9b5438cfdf547c08bd29ac6933bde.jpg", "img_caption": ["Figure 6: Results on RE42 (full results are in Figure 9). "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/e54ef7567f6812b05b885a07c82c35e935218839abe0f08ef04e8840ac8c2cab.jpg", "table_caption": ["Table 2: Partial results on three-objective problems (full results are in Table 8). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "We present the results for biobjective problems in Figure 3 and Table $1\\,^{7}$ . By directly minimizing maximal pairwise distances, the uniform indicator (which corresponds to maximal pairwise distances, see Appendix B.1, metric 5) is optimized effectively and ranks best among all methods. The fill distance, a surrogate for maximal pairwise distance up to constant, also performs best among all methods. This indicates that solutions found by UMOD cover the true PF with minimal covering radius, which satisfies our main purpose. Figure 3 further confirms that the covering radius of UMOD is significantly smaller than other methods. We also observe that the IGD indicator (Appendix B.1, metric 2), representing the mean Euclidean distance between the true PF and the found size- $K$ solution set, is significantly improved. The significant improvement over IGD, a well-established indicator of uniformity and convergence of Pareto solutions, suggests that our method finds highquality Pareto solutions and also implies an inherent theoretical connection between IGD and minimal pairwise distance maximization, warranting further investigation. ", "page_idx": 8}, {"type": "text", "text": "We would like to mention another advantage of UMOD is it can handle PFs of varying scales, as demonstrated in Figure 4(a)/(b). Unlike using fixed preference vectors, which can result in nonuniform Pareto objectives, UMOD ensures uniformity in the objective space, remaining the uniformity of the achieved distribution unaffected by the scale of a PF. ", "page_idx": 8}, {"type": "text", "text": "For three-objective problems, DTLZ1 owns a simplex-like PF, making DTLZ1 the only problem where uniform preferences result in uniformly distributed Pareto objectives. For DTLZ2 problem with a sphere-like PF, using uniform preferences on the simplex fails to produce uniform Pareto objectives by MOEA/D. As shown in Figure 4(c), objectives solved by MOEA/D around the center of the PF are sparse, while those around the margin are dense. In contrast, UMOD produces uniform Pareto objectives on the PF. The minimal distances from one Pareto objective to the rest of the solutions, sorted by index, are shown in Figure 4(d), indicating that only UMOD achieves the maximal minimal pairwise distance. The results for the real-world RE37 problem are shown in Figure 2(a), indicating MOEA/D produces inefficient duplicated solutions on the boundary of the PF. In contrast, UMOD effectively reduces duplicated solutions by maximizing the minimal pairwise distance on the PF, as duplicated solutions have a minimal pairwise distance of zero. A visualization of the learned PF is shown in Figure 2(b), indicating that a PF model can be learned efficiently by using only a small number of solutions. Most uniformity indicators, such as IGD, uniform distance, and FD outperforms other methods significantly, indicating UMOD finds much more uniform and representative solutions. The HV indicator of UMOD is the 3-rd best and comparable to SMS-EMOA, a method directly optimizes the HV indicator. ", "page_idx": 8}, {"type": "text", "text": "Finally, we discuss the results for four-objective problems which are reported in Figures 8 and 9 and Table 9. A key advantage of UMOD over DEAGNG and LMPFE is its ability to discover a broader PF (Figure 5) since it directly maximizing the minimal pairwise distance on the PF. Although subset selection performs similarly to UMOD on the RE41 problem, it relies on a inefficient two-phase optimization problem in the manner of electing a subset of problems from a much larger solution set. Generating a large number of solutions for a four-objective problem is considered inefficient. On RE41, UMOD significantly outperforms other methods in IGD, indicating UMOD find more representative solutions. On RE42, UMOD achieves high rankings (the best or second best) in uniformity indicators such as spacing, sparsity, uniform, and soft uniform. To close the discussion, we would like to mention that due to a challenging PF region that all methods find difficult to detect, the IGD indicators for UMOD, NSGA3, and SMS-EMOA are close and these three methods outperform the other methods a lot. ", "page_idx": 8}, {"type": "text", "text": "5.2 Results on fairness classification ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this subsection, we compare our methods with baseline methods on multiobjective fairness classification problems, specifically Adult [2] and Compass [1]. The decision variable is the neural network parameter used to classify both accuracy and fairness. The first objective, data classification accuracy, uses binary cross-entropy loss, while the second objective employs a hyperbolic tangent relaxation of the difference of equality of opportunity (DEO) loss [42][Eq. 6]. Details of the data and network architecture are provided in Table 6 in Appendix B.3. ", "page_idx": 8}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/f699438aa8a09d922586b5a8654b6b7e29d59fa67c5026c6cdb7e6b8f5463746.jpg", "table_caption": ["Table 3: Statistical results on fairness classification problems. Results are averaged on five random seeds. Results are presented in the the format of \u201c(mean)/(std)/(rank)\u201d. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "This experiment validates our method\u2019s applicability to large-scale machine learning tasks and its robustness against stochastic gradients. Strong baselines include Exact Pareto Optimization (EPO) [37], Preference-based MGDA (PMGDA) [60], Hypervolume-gradient (HVGrad) [17], and aggregation function-based methods like linear scalarization (LS), Penalty-based Intersection (PBI), and weighted Tchebycheff [38]. For the aggregation functions expressions, please refer to Appendix C.4. These gradient-based methods are supported by a recent MOO library called LibMOON [61]. Full name of these methods are provided in Table 4. ", "page_idx": 9}, {"type": "text", "text": "The visualization of different methods on the Adult problem is shown in Figure 7, and the numerical results are in Table 3. UMOD methods consistently find uniform Pareto objectives across the entire PF, recovering a larger Pareto set compared to other methods. The uniformity indicators outperform baseline methods. For the Adult problem, the Tchebycheff aggregation method is a strong competitor because the PF scales of the two objectives are similar. On the Compass problem, where ", "page_idx": 9}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/bc1bc46c11fce7a1bb537a920d1ffed1ac473e518a952d3e15117c015d4508b1.jpg", "img_caption": ["Figure 7: Result on fairness classification. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "objectives vary in scale, UMOD finds more uniform solutions compared to the Tchebycheff aggregation function, which tends to produce sparse and duplicated solutions at the lower right of the PF. The EPO method exhibits numerical instability issues in finding marginal solutions, leading to an incomplete PF and lower uniformity indicator, as reported in [31]. In both tasks, HV-Grad, EPO, and PBI aggregation methods identify only a small portion of the PF. Consequently, the spacing indicators of HV-Grad and EPO are better than UMOD since these methods find a narrower PF. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusions and further works ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Conclusions. In this paper, we have proposed a new understanding of a longstanding problem in MOO, generating $K$ uniform Pareto objectives, through introducing fill distance as a metric for the representativeness of the design. Moreover, we suggest an easy-to-optimize surrogate to the fill distance to specify the rate-optimal space-filling design. We provide rigorous analysis of the resulting objective design, and in particular, we show this design will asymptotically converge to the uniform measure over Pareto front. With this new paradigm, we also empirically demonstrate how the space-fliling design we obtain can benefti downstream performance with both synthetic and real-world MOO tasks. Overall, we believe that we pave a new way for (rate-)optimally configuring the Pareto objectives. ", "page_idx": 9}, {"type": "text", "text": "Future works include applying UMOD to large-scale real-world multiobjective problems, such as material design, vaccine design, and recommendation systems. The broader impacts of this work is discussed in Appendix D.1. ", "page_idx": 9}, {"type": "text", "text": "Acknowledge ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Role of this paper: GH Li offers guidance on evolutionary computation, while YF Chen proves Theorem 3. The work described in this paper was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China [GRF Project No. CityU 11215622]. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias. In Ethics of data and analytics, pages 254\u2013264. Auerbach Publications, 2022. [2] Arthur Asuncion and David Newman. Uci machine learning repository, 2007.   \n[3] Yves Auffray, Pierre Barbillon, and Jean-Michel Marin. Maximin design on non hypercube domains and kernel interpolation. Statistics and Computing, 22:703\u2013712, 2012.   \n[4] Anne Auger, Johannes Bader, Dimo Brockhoff, and Eckart Zitzler. Theory of the hypervolume indicator: optimal $\\mu$ -distributions and the choice of the reference point. In Proceedings of the tenth ACM SIGEVO workshop on Foundations of genetic algorithms, pages 87\u2013102, 2009.   \n[5] Sterling G Baird, Ramsey Issa, and Taylor D Sparks. Materials science optimization benchmark dataset for multi-objective, multi-fidelity optimization of hard-sphere packing simulations. Data in Brief, 50:109487, 2023.   \n[6] Nicola Beume, Boris Naujoks, and Michael Emmerich. Sms-emoa: Multiobjective selection based on dominated hypervolume. European Journal of Operational Research, 181(3):1653\u2013 1669, 2007.   \n[7] J. Blank and K. Deb. pymoo: Multi-objective optimization in python. IEEE Access, 8:89497\u2013 89509, 2020.   \n[8] S Borodachov, D Hardin, and E Saff. Asymptotics of best-packing on rectifiable sets. Proceedings of the American Mathematical Society, 135(8):2369\u20132380, 2007. [9] Weiyu Chen, Hisao Ishibuchi, and Ke Shang. Fast greedy subset selection from large candidate solution sets in evolutionary multiobjective optimization. IEEE Transactions on Evolutionary Computation, 26(4):750\u2013764, 2021.   \n[10] Eng Ung Choo and Derek R Atkins. Proper efficiency in nonconvex multicriteria programming. Mathematics of Operations Research, 8(3):467\u2013470, 1983.   \n[11] Paolo Climaco and Jochen Garcke. On minimizing the training set fill distance in machine learning regression, 2024. URL https://arxiv.org/abs/2307.10988.   \n[12] Indraneel Das and John E Dennis. Normal-boundary intersection: A new method for generating the pareto surface in nonlinear multicriteria optimization problems. SIAM journal on optimization, 8(3):631\u2013657, 1998.   \n[13] Kalyanmoy Deb and Himanshu Jain. An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part i: Solving problems with box constraints. IEEE Transactions on Evolutionary Computation, 18(4):577\u2013601, 2014. doi: 10.1109/TEVC.2013.2281535.   \n[14] Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. A fast and elitist multiobjective genetic algorithm: Nsga-ii. IEEE transactions on evolutionary computation, 6 (2):182\u2013197, 2002.   \n[15] Kalyanmoy Deb, Lothar Thiele, Marco Laumanns, and Eckart Zitzler. Scalable multi-objective optimization test problems. In Proceedings of the 2002 Congress on Evolutionary Computation. CEC\u201902 (Cat. No. 02TH8600), volume 1, pages 825\u2013830. IEEE, 2002.   \n[16] Kalyanmoy Deb, Ankur Sinha, and Saku Kukkonen. Multi-objective test problems, linkages, and evolutionary methodologies. In Proceedings of the 8th annual conference on Genetic and evolutionary computation, pages 1141\u20131148, 2006.   \n[17] Timo M Deist, Monika Grewal, Frank JWM Dankers, Tanja Alderliesten, and Peter AN Bosman. Multi-objective learning to predict pareto fronts using hypervolume maximization. arXiv preprint arXiv:2102.04523, 2021.   \n[18] Justin Dumouchelle, Esther Julien, Jannis Kurtz, and Elias B Khalil. Neur2bilo: Neural bilevel optimization. arXiv preprint arXiv:2402.02552, 2024.   \n[19] Matthias Ehrgott. Multicriteria optimization, volume 491. Springer Science & Business Media, 2005.   \n[20] Abhijith M Gopakumar, Prasanna V Balachandran, Dezhen Xue, James E Gubernatis, and Turab Lookman. Multi-objective optimization for materials discovery via adaptive design. Scientific reports, 8(1):3738, 2018.   \n[21] Fang-Qing Gu and Hai-Lin Liu. A novel weight design in multi-objective evolutionary algorithm. In 2010 International Conference on Computational Intelligence and Security, pages 137\u2013141. IEEE, 2010.   \n[22] Fangqing Gu and Yiu-Ming Cheung. Self-organizing map-based weight design for decomposition-based many-objective evolutionary algorithm. IEEE Transactions on Evolutionary Computation, 22(2):211\u2013225, 2017.   \n[23] Yu-Ran Gu, Chao Bian, Miqing Li, and Chao Qian. Subset selection for evolutionary multiobjective optimization. IEEE Transactions on Evolutionary Computation, 2023.   \n[24] Andreia P Guerreiro, Carlos M Fonseca, and Lu\u00eds Paquete. The hypervolume indicator: Problems and algorithms. arXiv preprint arXiv:2005.00515, 2020.   \n[25] Claus Hillermeier. Generalized homotopy approach to multiobjective optimization. Journal of Optimization Theory and Applications, 110(3):557\u2013583, 2001.   \n[26] Hisao Ishibuchi, Hiroyuki Masuda, Yuki Tanigaki, and Yusuke Nojima. Modified distance calculation in generational distance and inverted generational distance. In Evolutionary MultiCriterion Optimization: 8th International Conference, EMO 2015, Guimar\u00e3es, Portugal, March 29\u2013April 1, 2015. Proceedings, Part II 8, pages 110\u2013125. Springer, 2015.   \n[27] Himanshu Jain and Kalyanmoy Deb. An evolutionary many-objective optimization algorithm using reference-point based nondominated sorting approach, part ii: Handling constraints and extending to an adaptive approach. IEEE Transactions on Evolutionary Computation, 18(4): 602\u2013622, 2014. doi: 10.1109/TEVC.2013.2281534.   \n[28] Vishal Kaushal, Ganesh Ramakrishnan, and Rishabh Iyer. Submodlib: A submodular optimization library. arXiv preprint arXiv:2202.10680, 2022.   \n[29] Naime Ranjbar Kermany. Towards Fairness-aware Multi-Objective Recommendation Systems. PhD thesis, Macquarie University, 2024.   \n[30] Beichen Li, Bolei Deng, Wan Shou, Tae-Hyun Oh, Yuanming Hu, Yiyue Luo, Liang Shi, and Wojciech Matusik. Computational discovery of microstructured composites with optimal stiffness-toughness trade-offs, 2024.   \n[31] Ziyue Li, Tian Li, Virginia Smith, Jeff Bilmes, and Tianyi Zhou. Multi-objective multi-solution transport. 2023.   \n[32] Qiuzhen Lin, Xiaozhou Wang, Bishan Hu, Lijia Ma, Fei Chen, Jianqiang Li, and Carlos A Coello Coello. Multiobjective personalized recommendation algorithm using extreme point guided evolutionary computation. Complexity, 2018:1\u201318, 2018.   \n[33] Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qing-Fu Zhang, and Sam Kwong. Pareto multi-task learning. Advances in neural information processing systems, 32, 2019.   \n[34] Yajing Liu, Edwin KP Chong, Ali Pezeshki, and Zhenliang Zhang. Submodular optimization problems and greedy strategies: A survey. Discrete Event Dynamic Systems, 30(3):381\u2013412, 2020.   \n[35] Yiping Liu, Hisao Ishibuchi, Naoki Masuyama, and Yusuke Nojima. Adapting reference vectors and scalarizing functions by growing neural gas to handle irregular pareto fronts. IEEE Transactions on Evolutionary Computation, 24(3):439\u2013453, 2019.   \n[36] Xiaoliang Ma, Yanan Yu, Xiaodong Li, Yutao Qi, and Zexuan Zhu. A survey of weight vector adjustment methods for decomposition-based multiobjective evolutionary algorithms. IEEE Transactions on Evolutionary Computation, 24(4):634\u2013649, 2020.   \n[37] Debabrata Mahapatra and Vaibhav Rajan. Multi-task learning with user preferences: Gradient descent with controlled ascent in pareto optimization. In International Conference on Machine Learning, pages 6597\u20136607. PMLR, 2020.   \n[38] Kaisa Miettinen. Nonlinear multiobjective optimization, volume 12. Springer Science & Business Media, 1999.   \n[39] Martin Pil\u00e1t and Roman Neruda. General tuning of weights in moea/d. In 2016 IEEE Congress on Evolutionary Computation (CEC), pages 965\u2013972. IEEE, 2016.   \n[40] Luc Pronzato. Minimax and maximin space-filling designs: some properties and methods for construction. Journal de la Soci\u00e9t\u00e9 Fran\u00e7aise de Statistique, 158(1):7\u201336, 2017.   \n[41] Yutao Qi, Xiaoliang Ma, Fang Liu, Licheng Jiao, Jianyong Sun, and Jianshe Wu. Moea/d with adaptive weight adjustment. Evolutionary computation, 22(2):231\u2013264, 2014.   \n[42] Michael Ruchte and Josif Grabocka. Scalable pareto front approximation for deep multiobjective learning. In 2021 IEEE international conference on data mining (ICDM), pages 1306\u20131311. IEEE, 2021.   \n[43] Serpil Say\u0131n. Measuring the quality of discrete representations of efficient sets in multiple objective mathematical programming. Mathematical Programming, 87:543\u2013560, 2000.   \n[44] Jason R Schott. Fault tolerant design using single and multicriteria genetic algorithm optimization. 1995.   \n[45] Adriana Schulz, Jie Xu, Bo Zhu, Changxi Zheng, Eitan Grinspun, and Wojciech Matusik. Interactive design space exploration and optimization for cad models. ACM Transactions on Graphics (TOG), 36(4):1\u201314, 2017.   \n[46] Ke Shang, Tianye Shu, Hisao Ishibuchi, Yang Nan, and Lie Meng Pang. Benchmarking largescale subset selection in evolutionary multi-objective optimization. Information Sciences, 622: 755\u2013770, 2023.   \n[47] Bofeng Shi, Turab Lookman, and Dezhen Xue. Multi-objective optimization and its application in materials science. Materials Genome Engineering Advances, 1(2):e14, 2023.   \n[48] Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. A review on bilevel optimization: From classical to evolutionary approaches and applications. IEEE transactions on evolutionary computation, 22(2):276\u2013295, 2017.   \n[49] Jiang Siwei, Cai Zhihua, Zhang Jie, and Ong Yew-Soon. Multiobjective optimization by decomposition with pareto-adaptive weight vectors. In 2011 Seventh international conference on natural computation, volume 3, pages 1260\u20131264. IEEE, 2011.   \n[50] Ryoji Tanabe and Hisao Ishibuchi. An easy-to-use real-world multi-objective optimization problem suite. Applied Soft Computing, 89:106078, 2020.   \n[51] Ye Tian, Langchun Si, Xingyi Zhang, Kay Chen Tan, and Yaochu Jin. Local model-based pareto front estimation for multiobjective optimization. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 53(1):623\u2013634, 2022.   \n[52] Lihui Wang, Amos HC Ng, and Kalyanmoy Deb. Multi-objective evolutionary optimisation for product design and manufacturing. Springer, 2011.   \n[53] Zihan Wang, Bochao Mao, Hao Hao, Wenjing Hong, Chunyun Xiao, and Aimin Zhou. Enhancing diversity by local subset selection in evolutionary multiobjective optimization. IEEE Transactions on Evolutionary Computation, 2022.   \n[54] Zihan Wang, Chunyun Xiao, and Aimin Zhou. Exact calculation of inverted generational distance. IEEE Transactions on Evolutionary Computation, pages 1\u20131, 2024. doi: 10.1109/ TEVC.2024.3442920.   \n[55] Jeff Wu. Space-filling designs, 2016. URL https://www2.isye.gatech.edu/\\~jeffwu/ isye8813/spacefilling_designs.pdf.   \n[56] Mengyuan Wu, Sam Kwong, Yuheng Jia, Ke Li, and Qingfu Zhang. Adaptive weights generation for decomposition-based multi-objective optimization using gaussian process regression. In Proceedings of the Genetic and Evolutionary Computation Conference, pages 641\u2013648, 2017.   \n[57] Jie Xu, Yunsheng Tian, Pingchuan Ma, Daniela Rus, Shinjiro Sueda, and Wojciech Matusik. Prediction-guided multi-objective reinforcement learning for continuous robot control. In International conference on machine learning, pages 10607\u201310616. PMLR, 2020.   \n[58] Jie Xu, Andrew Spielberg, Allan Zhao, Daniela Rus, and Wojciech Matusik. Multi-objective graph heuristic search for terrestrial robot design. In 2021 IEEE international conference on robotics and automation (ICRA), pages 9863\u20139869. IEEE, 2021.   \n[59] Qingfu Zhang and Hui Li. Moea/d: A multiobjective evolutionary algorithm based on decomposition. IEEE Transactions on evolutionary computation, 11(6):712\u2013731, 2007.   \n[60] Xiaoyuan Zhang, Xi Lin, and Qingfu Zhang. Pmgda: A preference-based multiple gradient descent algorithm. IEEE Transactions on Emerging Topics in Computational Intelligence, 2024.   \n[61] Xiaoyuan Zhang, Liang Zhao, Yingying Yu, Xi Lin, Yifan Chen, Han Zhao, and Qingfu Zhang. Libmoon: A gradient-based multiobjective optimization library in pytorch. Advances in Neural Information Processing Systems, 2024.   \n[62] Yihua Zhang, Prashant Khanduri, Ioannis Tsaknakis, Yuguang Yao, Mingyi Hong, and Sijia Liu. An introduction to bi-level optimization: Foundations and applications in signal processing and machine learning. arXiv preprint arXiv:2308.00788, 2023.   \n[63] Yong Zheng and David Xuejun Wang. A survey of recommender systems with multi-objective optimization. Neurocomputing, 474:141\u2013153, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Supplementary Material ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A Complete proofs of theoretical results 16 ", "page_idx": 14}, {"type": "text", "text": "A.1 Upper and lower bounds for space filling design 16   \nA.2 Configuration of $d^{\\mathrm{Pack}}$ for bi-objective problems 16   \nA.3 Theoretical results for optimization bounds 18   \nA.4 Proof of the \u201cequivalent conversion\u201d argument 18 ", "page_idx": 14}, {"type": "text", "text": "B Experiment details 19 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Metrics . 19   \nB.2 Full name of multiobjective methods 21   \nB.3 Detailed hyperparameters and licences 21   \nB.4 Visualization for four objective problems 22   \nB.5 Full numerical results 22   \nB.6 Results on DTLZ5 and DTLZ6 25   \nMethod details 26   \nC.1 Practical algorithms 26   \nC.2 Problem formulations 26   \nC.3 Conversion between a preference and a preference angle 27   \nC.4 Baseline methods used in fairness classification problem 28   \nC.5 Duplicated solutions issues caused by the mTche aggregation function 28   \nMiscellanies 29   \nD.1 Broader impacts 29   \nD.2 Limitations 29 ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "The appendix comprises four sections: ", "page_idx": 14}, {"type": "text", "text": "1. Appendix A: Detailed proofs for the main paper\u2019s conclusions.   \n2. Appendix B: Additional experimental details.   \n3. Appendix C: Method details omitted from the main paper.   \n4. Appendix D: Discussion on the broader impact of our method. ", "page_idx": 14}, {"type": "text", "text": "A Complete proofs of theoretical results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "This section provides complete proofs for the theoretical results. We first provide the properties for max-packing and space-filling designs in Appendices A.1 and A.2. Lastly, in Appendix A.3, we prove for the bi-level optimization bound by using neural network as an approximation for the inner loop optimization problem. ", "page_idx": 15}, {"type": "text", "text": "A.1 Upper and lower bounds for space filling design ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In the following content, we proves for Theorem 3 in the main paper, i.e., ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{1}{4}d^{\\mathrm{Pack}}\\leq d^{\\mathrm{FD}}\\leq\\mathrm{FD}(\\mathbb{Y}^{\\mathrm{Pack}})\\leq d^{\\mathrm{Pack}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. Following the derivation to attain Equation (3) in Pronzato [40], we can prove $d^{\\mathrm{FD}}\\leq d^{\\mathrm{Pack}}$ as well as the claim that the fill distance between $\\tau$ and the optimal design $\\mathbb{Y}^{\\mathrm{Pack}}$ induced by $d^{\\mathrm{Pack}}$ is upper bounded by $d^{\\mathrm{Pack}}$ . ", "page_idx": 15}, {"type": "text", "text": "Next, we prove $d^{\\mathrm{FD}}\\geq\\frac{1}{4}d^{\\mathrm{Pack}}$ by contradiction. Consider $\\mathbb{Y}^{\\mathrm{FD}}$ is the design that induces $d^{\\mathrm{FD}}$ , we have that each point in $\\mathbb{Y}^{\\mathrm{Pack}}$ must be within a $d^{\\mathrm{FD}}$ -ball centered at a point in $\\mathbb{Y}^{\\mathrm{FD}}$ , and the condition $\\begin{array}{r}{d^{\\mathrm{FD}}<\\frac{1}{4}d^{\\mathrm{Pack}}}\\end{array}$ requires that a specific ball will only contain a single $\\mathbf{\\boldsymbol{y}}^{(k)}\\in\\mathbb{Y}^{\\mathrm{Pack}}$ otherwise $\\mathbb{Y}^{\\mathrm{Pack}}$ will not be a $d^{\\mathrm{Pack}}$ -packing. ", "page_idx": 15}, {"type": "text", "text": "Since $d^{\\mathrm{FD}}\\,<\\,\\textstyle{\\frac{1}{4}}d^{\\mathrm{Pack}}$ , for all $k\\,\\in\\,[K]$ the corresponding $d^{\\mathrm{FD}}$ -ball is completely contained in the larger $(d^{\\mathrm{Pack}}/2)$ -ball centered at $\\pmb{y}^{(k)}$ . However, we note $\\tau$ is connected, and thus there exists a certain $y\\in\\mathcal{T}$ outside all the $K$ $\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\$ -balls; this certain point will not be covered by all the $d^{\\mathrm{FD}}$ -ball centered at points in $\\mathbb{Y}^{\\mathrm{FD}}$ as well. Finally, the existence of the certain point contradicts the claim that $\\mathbb{Y}^{\\mathrm{FD}}$ is a ${\\dot{d}}^{\\mathrm{{FD}}}$ -covering. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Lastly, we prove for Theorem 4 in the main paper by a contradiction. ", "page_idx": 15}, {"type": "text", "text": "Proof. Since $d_{K+1}^{\\mathrm{Pack}}>d_{K}^{\\mathrm{Pack}}$ , $K$ is the maximal packing number under distance $d_{K}^{\\mathrm{Pack}}$ ifAomsrsp ulaylmli Assume YPa YPKack  dPKac i.si  nnTgo htni sua .  waTshsheuen teiwroaen s,e  xamisas $\\pmb{y}^{(K+1)}$ $\\rho(\\pmb{y}^{(K+1)},\\pmb{y}^{(i)})<d_{K}^{\\mathrm{Pack}}$ $i\\,\\in\\,[K]$ $\\mathbb{Y}_{K}^{\\mathrm{Pack}}\\cup\\{{\\pmb y}^{(K+1)}\\}$ $d_{K}^{\\mathrm{Pack}}$ $K+1$ $K$ $\\mathbb{Y}_{K}^{\\mathrm{Pack}}$ $d_{K}^{\\mathrm{Pack}}$ ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "A.2 Configuration of $d^{\\mathrm{Pack}}$ for bi-objective problems ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In the following, we prove Theorem 5 in the main paper. Before that, we prove for Lemma 9 to describe a property of $\\rho(\\pmb{y}^{(1)},\\pmb{y}^{(2)})$ , the distance between $\\pmb{y}^{(1)}$ and $\\pmb{y}^{(2)}$ when $\\pmb{y}^{(1)},\\pmb{y}^{(2)}\\in\\mathcal{T}$ . ", "page_idx": 15}, {"type": "text", "text": "Lemma 9. For biobjective problem function $g$ is strictly decreasing with respect to the first element $(y_{1}^{(1)})$ of $\\pmb{y}^{(1)}$ and strictly increasing with the first element $(y_{1}^{(2)})$ of $\\pmb{y}^{(2)}$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. We consider a new vector $\\tilde{\\pmb{y}}^{(1)}\\in\\mathcal{T}$ such that $\\tilde{y}_{1}^{(1)}<y_{1}^{(1)}$ < y(11 ). Since y\u02dc(1) \u2208T , y(1) and y\u02dc(1) cannot dominate each other, implying $\\tilde{y}_{2}^{(1)}>y_{2}^{(1)}$ . The distance between this new solution $\\tilde{\\pmb{y}}^{(1)}$ and $\\pmb{y}^{(2)}$ is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\tilde{y}^{(1)},y^{(2)})=\\sqrt{(\\tilde{y}_{1}^{(1)}-y_{1}^{(2)})^{2}+(\\tilde{y}_{2}^{(1)}-y_{2}^{(2)})^{2}}}\\\\ &{\\qquad\\qquad=\\sqrt{(y_{1}^{(1)}-\\delta_{1}-y_{1}^{(2)})^{2}+(y_{2}^{(1)}+\\delta_{2}-y_{2}^{(2)})^{2}}\\qquad\\qquad(\\delta_{1},\\delta_{2}>0)}\\\\ &{\\qquad\\qquad=\\sqrt{(y_{1}^{(1)}-y_{1}^{(2)})^{2}+\\delta_{1}^{2}-2\\delta_{1}(y_{1}^{(1)}-y_{1}^{(2)})+(y_{2}^{(1)}-y_{2}^{(2)})^{2}+\\delta_{2}^{2}+2\\delta_{2}(y_{2}^{(1)}-y_{2}^{(2)})}}\\\\ &{\\qquad\\qquad\\geq\\sqrt{(y_{1}^{(1)}-y_{1}^{(2)})^{2}+(y_{2}^{(1)}-y_{2}^{(2)})^{2}+C}\\qquad\\qquad\\qquad(C>0)}\\\\ &{\\qquad\\qquad>\\rho(y^{(1)},y^{(2)}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The previous equations show that $\\rho(\\pmb{y}^{(1)},\\pmb{y}^{(2)})$ is strictly decreasing with respect to the first element of $\\pmb{y}^{(1)}$ . Similarly, considering a new vector $\\tilde{\\pmb{y}}^{(2)}\\,\\in\\,\\bar{\\mathcal{T}},\\,\\tilde{y}_{1}^{(2)}\\,>\\,\\bar{y_{1}^{(2)}}(\\tilde{y}_{2}^{(2)}\\,<\\,\\bar{y}_{2}^{(2)})$ , using the same calculation method used in Equation (11), it is proved that $\\rho(\\pmb{y}^{(1)},\\pmb{\\tilde{y}}^{(2)})\\,>\\,\\rho(\\pmb{y}^{(1)},\\pmb{y}^{(2)})$ . This indicates that $\\rho(\\pmb{y}^{(1)},\\pmb{y}^{(2)})$ is strictly increasing with respect to the first element of $\\pmb{y}^{(2)}$ . \u53e3 ", "page_idx": 16}, {"type": "text", "text": "With this established Lemma, we are now geared up for the complete proof. ", "page_idx": 16}, {"type": "text", "text": "Proof. The proof consists of two parts. ", "page_idx": 16}, {"type": "text", "text": "Part 1 proves that the neighboring distances $\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(i+1)})$ are equal for all $i\\in[K-1]$ . ", "page_idx": 16}, {"type": "text", "text": "Part 2 proves that $\\pmb{y}^{(1)}=\\pmb{p}^{(1)}$ and $\\pmb{y}^{(K)}=\\pmb{p}^{(2)}$ . $\\pmb{p}^{(1)}$ and $\\pmb{p}^{(2)}$ are the two endpoints of a PF. ", "page_idx": 16}, {"type": "text", "text": "Part 1. We prove $\\rho({\\pmb y}^{(1)},{\\pmb y}^{(2)})=\\dots=\\rho({\\pmb y}^{(K-1)},{\\pmb y}^{(K)})$ by contradiction. We denote $d^{(i)}$ the distance between $\\pmb{y}^{(i)}$ and $\\pmb{y}^{(i+1)}$ and $i^{\\prime}$ and $j^{\\prime}$ are two indices such that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\{d^{(i^{\\prime})}>d^{(i^{\\prime}+1)},\\cdot\\cdot\\cdot,d^{(j^{\\prime})},\\right.}\\\\ {\\left.d^{(i^{\\prime}+1)},\\cdot\\cdot\\cdot,d^{(j^{\\prime}-1)}>d^{(j^{\\prime})}.\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Without loss of generality, assume $i^{\\prime}\\,<\\,j^{\\prime}$ . We now aim to derive a contradiction under the condition given by Equation (12). The approach is to iteratively decrease the first element of $\\pmb{y}^{(i^{\\prime}+1)}$ by a small margin $\\varepsilon\\ >\\ 0$ , yielding $\\tilde{\\pmb{y}}^{(i^{\\prime}+1)}$ . By Lemma 9, this adjustment ensures that $\\rho(\\pmb{y}^{(i^{\\prime})},\\tilde{\\pmb{y}^{(i^{\\prime}+1)}})<\\rho(\\pmb{y}^{(\\bar{i}^{\\prime})},\\pmb{y}^{(i^{\\prime}+1)})$ while $\\rho(\\tilde{\\pmb{y}}^{(i+1)},\\pmb{y}^{(i+2)})>\\rho(\\pmb{y}^{(i+1)},\\pmb{y}^{(i+2)})$ . Specifically, for each $k$ such that $i^{\\prime}+1\\le k\\le j^{\\prime}-2,y^{(k)}$ is updated to $\\tilde{\\pmb{y}}^{(k)}$ according to the following rules: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\{\\rho(y^{(i^{\\prime})},y^{(i^{\\prime}+1)})-\\varepsilon=\\rho(\\tilde{y}^{(i^{\\prime})},\\tilde{y}^{(i^{\\prime}+1)}),\\right.}\\\\ {\\left.\\rho(y^{(k)},y^{(k+1)})=\\rho(\\tilde{y}^{(k)},\\tilde{y}^{(k+1)}),\\right.\\ \\ \\ \\ }&{i^{\\prime}+1\\leq k\\leq j^{\\prime}-2,}\\\\ {\\left.\\rho(y^{(j^{\\prime}-1)},y^{(j^{\\prime})})+\\epsilon=\\rho(\\tilde{y}^{(j^{\\prime}-1)},\\tilde{y}^{(j^{\\prime})}).}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "When $\\varepsilon$ is sufficiently small, $\\tilde{j}^{\\prime}=\\arg\\operatorname*{min}\\{\\rho(\\tilde{{\\pmb y}}^{(i^{\\prime})},\\tilde{{\\pmb y}}^{(i^{\\prime}+1)}),\\dots,\\rho(\\tilde{{\\pmb y}}^{(j^{\\prime}-1)},\\tilde{{\\pmb y}}^{(j^{\\prime})})\\}=j^{\\prime}$ , meaning the minimal index before and after adjustment remains unchanged. However, the value of the adjusted distance $\\rho(\\tilde{{\\pmb y}}^{(j^{\\prime})},\\tilde{{\\pmb y}}^{(j^{\\prime}+1)})$ is increased from $\\rho(\\pmb{y}^{(j^{\\prime})},\\pmb{y}^{(j^{\\prime}+1)})$ by $\\varepsilon$ , showing the original design is not a max-packing design, leading to a contradiction. If conditions ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\{d^{(i^{\\prime})}<d^{(i^{\\prime}+1)},\\dots,d^{(j^{\\prime})},\\right.}\\\\ {\\left.d^{(i^{\\prime}+1)},\\dots,d^{(j^{\\prime}-1)}<d^{(j^{\\prime})},\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "hold, a similar argument as above can be used to derive a contradiction. Since the selection of $i^{\\prime}$ and $j^{\\prime}$ is arbitrary, this implies that for any interval between $i^{\\prime}$ and $j^{\\prime}$ , both Equation (12) and Equation (14) cannot hold simultaneously. This leads to the following equality, which aligns with our intended design goal: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\rho({\\pmb y}^{(1)},{\\pmb y}^{(2)})=\\ldots=\\rho({\\pmb y}^{(K-1)},{\\pmb y}^{(K)}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Remark. The key component of our proof is the validity of Lemma 9, which applies to a two-dim $P F$ only. This leads to a contradiction with both Equation (12) and Equation (14), forming the core of our argument. ", "page_idx": 16}, {"type": "text", "text": "Part 2. We prove $\\pmb{y}^{(1)}=\\pmb{p}^{(1)}$ by contradiction. The proof for $\\pmb{y}^{(K)}~~=~~\\pmb{p}^{(2)}$ follows similarly. Assuming $\\pmb{y}^{(1)}\\;\\neq\\;\\pmb{p}^{(1)}$ , we replace $\\pmb{y}^{(1)}$ with $\\pmb{p}^{\\Bar{(1)}}$ , forming a new configuration $[\\tilde{\\pmb{y}}^{(1)}(\\pmb{p}^{(1)}),\\pmb{y}^{(2)},\\dots,\\bar{\\pmb{y}^{(K)}}]$ . Based on Part 1, where we showed equal neighboring distances between vectors, the condition ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\rho(\\tilde{\\pmb{y}}^{(1)},\\pmb{y}^{(2)})>\\rho(\\pmb{y}^{(2)},\\pmb{y}^{(3)})=\\dots=\\rho(\\pmb{y}^{(K-1)},\\pmb{y}^{(K)})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "holds. ", "page_idx": 17}, {"type": "text", "text": "Next, we replace $\\pmb{y}^{(2)},\\dots,\\pmb{y}^{(K-1)}$ with $\\tilde{\\pmb{y}}^{(2)},\\dots,\\tilde{\\pmb{y}}^{(K-1)}$ on the PF, such that $\\tilde{y}_{1}^{(i)}=y_{1}^{(i)}-\\epsilon^{(i)}$ , for $2\\leq i\\leq K-1$ , ensuring ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\rho(\\tilde{\\pmb{y}}^{(i)},\\tilde{\\pmb{y}}^{(i+1)})>\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(i+1)}),\\quad i\\in[K-1].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "By Lemma 9, moving $\\pmb{y}^{(1)}$ to $\\tilde{\\pmb{y}}^{(1)}$ results in $\\rho(\\tilde{\\pmb{y}}^{(1)},\\pmb{y}^{(2)})\\;>\\;\\rho(\\pmb{y}^{(1)},\\pmb{y}^{(2)})$ . Iteratively shifting $\\pmb{y}^{(2)},\\dots,\\pmb{y}^{(K-1)}$ ensures $\\tilde{y}_{1}^{(2)}<y_{1}^{(2)}$ and so on, until $\\tilde{y}_{1}^{(K-1)}<y_{1}^{(K-1)}$ , completing the process. ", "page_idx": 17}, {"type": "text", "text": "This leads to a contradiction, proving that $\\pmb{y}^{(1)}=\\pmb{p}^{(1)}$ and $\\pmb{y}^{(K)}=\\pmb{p}^{(2)}$ . ", "page_idx": 17}, {"type": "text", "text": "A.3 Theoretical results for optimization bounds ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this part, we prove for Theorem 8, which bounds the optimization error caused by neural network in the bi-level optimization problem (Equation (10)). ", "page_idx": 17}, {"type": "text", "text": "Proof. Consider the function $\\rho(\\cdot,\\cdot)$ , which measures the distance between two vectors. Given our assumption, we derive the error between distances computed under $^h$ and $h_{\\phi}$ . For any two points $\\pmb{y}^{(i)},\\pmb{y}^{(j)}$ in the image of $^h$ , the error in their distances compared to $h_{\\phi}$ can be bounded as follows: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{|\\rho(y^{(i)},y^{(j)})-\\rho(h_{\\phi}(\\vartheta^{(i)}),h_{\\phi}(\\vartheta^{(j)}))|=|\\|y^{(i)}-y^{(j)}\\|-\\|h_{\\phi}(\\vartheta^{(i)})-h_{\\phi}(\\vartheta^{(j)})\\||}&{}\\\\ {\\leq\\|y^{(i)}-h_{\\phi}(\\vartheta^{(i)})+h_{\\phi}(\\vartheta^{(j)})-y^{(j)}\\|}&{}\\\\ {\\leq\\|y^{(i)}-h_{\\phi}(\\vartheta^{(i)})\\|+\\|h_{\\phi}(\\vartheta^{(j)})-y^{(j)}\\|}&{}\\\\ {\\leq\\epsilon+\\epsilon=2\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This follows from the triangle inequality and the assumption $|h_{\\phi}(\\pmb{\\vartheta})-h(\\pmb{\\vartheta})|\\leq\\epsilon$ . ", "page_idx": 17}, {"type": "text", "text": "Given this pairwise bound, the overall configuration of points is such that the minimization of distances among points under $h_{\\phi}$ will either match or exceed the minimization under $^h$ within the bounds of $2\\epsilon$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho(h_{\\phi}(\\pmb{\\vartheta}^{(i)}),h_{\\phi}(\\pmb{\\vartheta}^{(j)}))\\leq\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(j)})+2\\epsilon.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Considering the maximization of these minimum distances across all configurations $\\pmb{\\vartheta}^{(1)},\\ldots,\\pmb{\\vartheta}^{(K)}$ , we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\underset{\\vartheta^{(1)},\\ldots,\\vartheta^{(K)}}{\\operatorname*{max}}\\underset{1\\leq i<j\\leq K}{\\operatorname*{min}}\\rho(h_{\\phi}(\\vartheta^{(i)}),h_{\\phi}(\\vartheta^{(j)}))-\\underset{\\vartheta^{(1)},\\ldots,\\vartheta^{(K)}}{\\operatorname*{max}}\\underset{1\\leq i<j\\leq K}{\\operatorname*{min}}\\rho(y^{(i)},\\pmb{y}^{(j)})\\right|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\underset{\\vartheta^{(1)},\\ldots,\\vartheta^{(K)}}{\\operatorname*{max}}2\\epsilon=2\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, the error in the optimal maximal minimal distance under the model transformation can be bounded by $2\\epsilon$ , completing the proof. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "A.4 Proof of the \u201cequivalent conversion\u201d argument ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "This argument is actually a direct corollary the following two lemmas. ", "page_idx": 17}, {"type": "text", "text": "Lemma 10 (Adapted from [10], Theorem 3.1). A solution x is weakly Pareto optimal iff there exists a weight vector \u03bb such that $\\textbf{\\em x}$ is (one of) an optimal solution of the modified Tchebycheff function. ", "page_idx": 17}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/69c48bd980cdca153475cef5bd0d0a1c2749401cee36e7baee74cc452ac54a64.jpg", "img_caption": ["Figure 8: Results on RE41. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Lemma 11 (Modified from [38], Theorem 2.6.2). If an aggregation function is decreasing w.r.t. vector $\\pmb{f}(\\pmb{x})$ (i.e., $g_{\\pm}(\\pmb{f}(\\pmb{x}))\\leq g_{\\pmb{\\lambda}}(\\pmb{f}(\\pmb{x}^{\\prime}))$ when $f_{i}(\\pmb{x})\\leq f_{i}(\\pmb{x}^{\\prime}),\\forall i\\in[m]$ and at least one index $j$ $f_{j}({\\pmb x})<f_{j}({\\pmb x}^{\\prime})$ , then one of the optimal solution $x^{*}$ of $g_{\\lambda}(f(x))$ is $a$ weakly Pareto optimal solution for the original MOP. In addition, if the optimality is unique, $x^{*}$ is Pareto optimal. ", "page_idx": 18}, {"type": "text", "text": "Based on the first Lemma, we know that for any weakly Pareto objective, there is a corresponding preference vector that solving the modified Tchebycheff function can recover this vector. Furthermore, since we assume the uniqueness of the optimality of the modified Tchebycheff function, thus according to the second lemma, solving the modified Tchebycheff function only yields Pareto optimal solutions. Combining these two arguments, we achieve that for any Pareto optimal objective, there exists a preference vector such that solving the corresponding modified Tchebycheff function yield this Pareto optimal vector. ", "page_idx": 18}, {"type": "text", "text": "B Experiment details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "This section has four parts. In Appendix B.1, we explain the metrics used in the experiments in details. In Appendix B.3, we list the necessary hyperparameters and license. In Appendix B.4, we visualize the results on four-objective problems by projection. Lastly, Appendix B.5 list for all numerical results for all experiments. ", "page_idx": 18}, {"type": "text", "text": "B.1 Metrics ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "To evaluate the uniformity and quality of these solutions, we use various performance indicators, detailed and mathematically expressed below. ", "page_idx": 18}, {"type": "text", "text": "1. Hypervolume (HV) (\u2191) [24] both assesses convergence to a PF and solution diversity. Low HV values suggest poor convergence to the PF, while comparisons are significant when HVs are substantially high. The hypervolume indicator measures the dominated volume by at least one ", "page_idx": 18}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/33ed312c554800b8902535cc8be36a05425ac9fbca9910293f185bcc91fe429f.jpg", "img_caption": ["Figure 9: Results on RE42. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "objective belongs to the set $\\mathbb{Y}$ with a reference point $\\pmb{r}$ . ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{HV}_{r}=\\mathrm{Vol}(\\{y|\\exists y^{\\prime}\\in\\mathbb{Y},y^{\\prime}\\preceq y\\preceq r\\}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "2. IGD [26] indicator of a set A with a reference set $\\mathbb{Z}$ is defined as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname{IGD}(\\mathbb{A})=\\frac{1}{|\\mathbb{Z}|}\\sum_{i=1}^{|\\mathbb{Z}|}d_{i},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $d_{i}$ represents the euclidean distance from $z_{i}$ to the nearest distance in the set of A. ", "page_idx": 19}, {"type": "text", "text": "3. Sparsity $\\left(\\downarrow\\right)$ [57] is a measure calculated from the squared distances among solution vectors that are sorted according to their non-dominance levels [14]. The mathematical definition is given by: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{Sparsity}=\\frac{1}{N-1}\\sum_{j=1}^{m}\\sum_{i=1}^{N-1}\\left(\\tilde{y}_{j}^{(i)}-\\tilde{y}_{j}^{(i+1)}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\tilde{\\pmb{y}}^{(i)}$ are the objective vectors arranged in a non-dominated sorting order from the set $\\{\\pmb{y}^{(1)},\\cdot\\cdot\\cdot,\\pmb{y}^{(N)}\\}$ . Here, $m$ represents the number of objectives, and $N$ is the number of solutions. A lower Sparsity value indicates a more uniformly distributed set of solutions along the Pareto front. Specifically, for a Pareto front with a two-dimensional linear shape, the sparsity indicator reaches its minimum when the objectives are spaced equidistantly. ", "page_idx": 19}, {"type": "text", "text": "4. Spacing (\u2193) [44]: This metric assesses solution distribution uniformity by calculating the standard deviation of $\\tilde{d}^{(i)}$ , the minimal distance between a solution $\\pmb{y}^{(i)}$ and its nearest neighbor, where $d^{(i)}=$ $\\begin{array}{r}{\\operatorname*{min}_{j\\in[m],j\\neq i}\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(j)})}\\end{array}$ . A lower spacing indicator implies evenly spaced solutions, reflecting uniform distribution. A spacing indicator of zero indicates that all Pareto objectives have equally minimal neighborhood distances. ", "page_idx": 19}, {"type": "text", "text": "Table 4: Full name table, which has three parts. The first part is related with evolutionary algorithms, the second part is related with gradient-based methods, the third part is related to indicators, while the last part is related to multiobjective optimization concepts. ", "page_idx": 20}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/e7e5d81987d6c1e099deb1faa37e7043001ddcfd71f93ac02fb58713ceb409ab.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "5. Uniformity $(\\uparrow)$ and Soft Uniformity $(\\uparrow)$ indicators, as introduced by [43], evaluate the distribution of solutions. The Uniformity indicator, $\\delta_{\\mathrm{Unif}}$ , is defined as the minimum distance between any two solutions: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\delta_{\\mathrm{Unif}}=\\operatorname*{min}_{1\\leq i<j\\leq K}\\rho(\\pmb{y}^{(i)},\\pmb{y}^{(j)}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Conversely, the Soft Uniformity indicator, $\\tilde{\\delta}_{\\mathrm{Unif}}$ , incorporates a logarithmic sum exponential function to average distances among solutions. It introduces a sensitivity parameter $\\eta$ (set to 20 in this study) to highlight the overall distribution of distances: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\tilde{\\delta}_{\\mathrm{Unif}}=-\\frac{2}{\\eta K(K-1)}\\log\\sum_{1\\le i<j\\le K}\\exp(\\eta\\cdot\\rho({\\pmb y}^{(i)},{\\pmb y}^{(j)})).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "B.2 Full name of multiobjective methods ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "To avoid confusion, we provide the full names of baseline MOO methods in Table 4. For SMS-MOEA (MOEA using S-Metric Selection), \u201cS-metric\u2019 is another name for \u201chypervolume\u201d. ", "page_idx": 20}, {"type": "text", "text": "B.3 Detailed hyperparameters and licences ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Table 5 lists the hyperparameters for implementing MOPs solved by evolutionary algorithms. The system used features an Intel Core i7-10700 CPU and a NVIDIA RTX 3080 GPU. ", "page_idx": 20}, {"type": "text", "text": "Our method is implemented in the MOEA/D framework using Pymoo [7], without modifying the MOEA/D hyperparameters. The main difference is the use of a PF model (a fully-connected neural network) to map preference angles to Pareto objectives and update preference vectors. The hyperparameters for the PF model are listed in Table 5. ", "page_idx": 20}, {"type": "text", "text": "For fairness classification problems, we use an additional fully connected network to classify input features into corresponding classes. The parameters of this network serve as the decision variables $(x)$ for a multiobjective problem. Details of the fairness classification problems are shown in Table 6. ", "page_idx": 20}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/832d83328fa188a0d4f0618ccf9207ceb1162e646f4d703c4e175df079836d9d.jpg", "table_caption": ["Table 6: Fairness classification problem details and network architectures. Act. is the short name for activation. "], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/3b5873bcf1662d25812a965a187cf3374791c9ccb59d24b542e7e647157d5c54.jpg", "table_caption": ["Table 5: Hyper-parameters used in UMOD-MOEA "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "(License) To close this subsection, we would like to mention that the license used for Adult follows Creative Commons Attribution 4.0 International (CC BY 4.0) license and Compas is supported by Database Contents License (DbCL) v1.0 license. ", "page_idx": 21}, {"type": "text", "text": "B.4 Visualization for four objective problems ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "This section presents the visualization results for four-objective problems (see Figures 8 and 9). Due to the difficulty of visualizing four-dimensional space, we project the Pareto objectives into 3-D spaces: $(f_{1},f_{2},f_{3}),(f_{1},f_{2},\\bar{f_{4}}),(f_{1},f_{3},f_{4})$ , and $(f_{2},f_{3},f_{4})$ , labeled P-1 to P-4 in Figures 8 and 9. ", "page_idx": 21}, {"type": "text", "text": "Despite losing some information in the projections, meaningful conclusions can still be drawn from these figures: ", "page_idx": 21}, {"type": "text", "text": "1. DEAGNG and LMPFE can find partial parts of the true Pareto front. For the P1, P2, and P4 projections, DEAGNG typically finds only a small portion in the upper right of the 3-D Pareto front, while LMPFE misses a small part of this region. In contrast, the proposed method captures a more extensive span of the Pareto front, covering the largest area. ", "page_idx": 21}, {"type": "text", "text": "2. For a four-objective problem, MOEA/D finds many duplicate Pareto objectives on the PF boundary by using fixed preference vectors. This highlights the importance of finding optimal preference vectors to achieve a more uniform PF. ", "page_idx": 21}, {"type": "text", "text": "3. The proposed UMOD method finds more uniform Pareto objectives on the Pareto front compared to NSGA3, SMS-EMOA, and the Subset selection method. This aligns with Table 9 in the main paper, showing UMOD has a much lower IGD indicator than these three methods. ", "page_idx": 21}, {"type": "text", "text": "B.5 Full numerical results ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We report the full numerical results for bi-objective, tri-objective, and four-objective problems in Tables 7 to 9, respectively. Each experiment was conducted with 31 random seeds. For each data point, $X(Y)(C)$ , $X$ is the mean value, $(Y)$ is the standard deviation, and $(C)$ is the rank among all eight methods. ", "page_idx": 21}, {"type": "text", "text": "The hypervolume, Uniform, and Soft Uniform (SUniform) are preferred larger, while IGD, spacing, sparsity, and fill distances are preferred smaller. The optimal result averaged across all seeds is marked in bold. In the last row of each table, we calculate the mean rank of each indicator, with the highest one in bold. ", "page_idx": 21}, {"type": "text", "text": "The tables show that, with a small solution budget, the uniformity indicators IGD, Spacing, Uniform, SUniform, and FD achieve the best results, outperforming previous methods significantly. ", "page_idx": 21}, {"type": "text", "text": "SMS-EMOA achieves the highest HV value among all methods, but HV is only a rough measure of uniformity, validating that optimizing hypervolume alone does not ensure the best uniform distribution. ", "page_idx": 22}, {"type": "text", "text": "These tables also validate the effectiveness of maximizing pairwise distances, a proper surrogate for fill distance. This suggests that in practice, maximal packing distance can more tightly bound the minimal flil distance. An interesting finding is that the IGD indicator, an important measure in MOO serving as the average covering radius of the size- $\\cal{K}$ optimized set, is optimized by maximizing the pairwise distance. This interesting empirical finding is worthy of further investigation. ", "page_idx": 22}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/2a867e79bd7c6a1c2ea2e8a4cbcab71635dd6b9897ca698fa25eddfcb0997dd7.jpg", "table_caption": ["Table 7: Full results for biobjective problems, based on 31 random seeds, include the standard deviation and rankings across all methods. The ranking values in the last row are averaged across all problems. "], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/1ddeedaac97f4f1cc4646aea599a0e023d3f7a25ee051cea6d66e576da0df64d.jpg", "table_caption": ["Table 8: Full numerical and ranking results on three-objective problems. "], "table_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/5b1cd7f46403299cd30366e7844238c09c4c6653b955a741523871e09b87cfeb.jpg", "table_caption": ["Table 9: Numerical results on four-objective problems. "], "table_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/65353b2ea4ccead166b6f7c52a444768bd4ae800b675809015819fb183c1c730.jpg", "img_caption": ["Figure 10: Comparison of using different methods on DTLZ5. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/dbd384155daccd63d00b0d1e5a5ef79ddd8c0a79b56634a485ece45f8c8d0698.jpg", "img_caption": ["Figure 11: Comparison of using different methods on DTLZ6. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "B.6 Results on DTLZ5 and DTLZ6 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The PFs of DTLZ5 and DTLZ6 are identical, representing a degenerate 1-dimensional hyper-curve within the three-objective space. The visualization results are shown in Figures 10 and 11 and numerical results are shown in Table 10. ", "page_idx": 24}, {"type": "table", "img_path": "WoEXVQcHFw/tmp/f7312b1894f872117f76223799c573679a88903739bc323880536ddcd9b73610.jpg", "table_caption": ["Table 10: Numerical results on DTLZ5 and DTLZ6 problems. "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Table 10 highlights that UMOD significantly outperforms other methods in ensuring evenly distributed solutions. In the decomposition-based framework, for such degenerated problems, distinctive preferences may correspond to the same Pareto objective. The reason behind generating duplicate solutions is explained in Appendix C.5. And therefore, MOEA/D and MOEA/D-AWA tend to produce duplicate solutions. NSGA3 is also found to produce duplicate solutions easily. SMS-MOEA avoids duplicate solutions by maximizing the hypervolume. SMS-MOEA surpasses UMOD in hypervolume, but UMOD considerably outperforms SMS-MOEA in IGD and FD, which are of interests in this paper. ", "page_idx": 24}, {"type": "text", "text": "C Method details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "C.1 Practical algorithms ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section, we present practical algorithms to solve the maximal packing problem in the Pareto front (Equation (10)). We start by generating an initial uniform distribution of preference vectors. Then, we use either multiobjective evolutionary algorithms (MOEAs) or gradient-based MOO to solve for the preference angle and Pareto objective pairs. MOEAs are suitable for problems with many local optima, while gradient-based MOO is efficient for neural network problems with millions of decision variables. Next, we fti a Pareto front model to learn the expression of $h_{\\phi}$ and re-determine the preference angles by maximizing the pairwise distances. These two steps are iterated until convergence. ", "page_idx": 25}, {"type": "text", "text": "Algorithm 1 Uniform Multiobjective Optimization (UMOD) ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1: Input: Initial $K$ uniform preferences $\\{\\pmb{\\lambda}^{(1)},\\cdot\\cdot\\cdot,\\pmb{\\lambda}^{(K)}\\}$ by Das-Dennis method [12]. Initial solutions $\\{\\pmb{x}^{(1)},\\cdot\\cdot\\cdot,\\pmb{x}^{(K)}\\}$ .   \n2: for $n=1$ to $N$ do   \n3: Run MOEA/D with mTche aggregation function or gradient-based MOO using $\\{\\pmb{x}^{(1)},\\cdot\\cdot\\cdot,\\pmb{x}^{(K)}\\}$ as initial solutions under preferences $\\{\\lambda^{(1)},\\ldots,\\lambda^{(K)}\\}$ .   \n4: Train a model $h_{\\phi}$ to predict Pareto objectives by the preference angles using mean square estimation with angle-objective pairs $(\\pmb{\\vartheta}^{(i)},\\pmb{y}^{(i)})$ .   \n5: Update $(\\pmb{\\vartheta}^{(1)},\\dots,\\pmb{\\vartheta}^{(K)})$ by Algorithm 2.   \n6: Recalculate preference vectors, $\\pmb{\\lambda}^{(1)},\\ldots,\\pmb{\\lambda}^{(K)}$ .   \n7: Update the initial solutions $\\{\\pmb{x}^{(1)},\\cdot\\cdot\\cdot,\\pmb{x}^{(K)}\\}$ by MOEA/D or gradient-based mTche using the last generation of solutions as a warm start.   \n8: end for ", "page_idx": 25}, {"type": "text", "text": "Algorithm 2 Recalculate Preference Angles (ALG_Update) ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1: Input: The initial configuration $\\{\\pmb{\\vartheta}^{(1)},\\cdot\\cdot\\cdot,\\pmb{\\vartheta}^{(K)}\\}$ and $h_{\\phi}$ .   \n2: for $i=1$ to $N_{\\mathrm{opt}}$ do   \n3: Calculate the indexes for the minimal pairwise objectives: ", "page_idx": 25}, {"type": "equation", "text": "$$\n(i^{*},j^{*})=\\arg\\operatorname*{min}_{1\\leq i<j\\leq K}h_{\\phi}(\\pmb{\\vartheta}^{(i)},\\pmb{\\vartheta}^{(j)}).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "4: Update the positions of $(\\pmb{\\vartheta}^{(i^{*})},\\pmb{\\vartheta}^{(j^{*})})$ : ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\pmb{\\vartheta}^{(i^{*})}\\leftarrow\\mathrm{clip}\\left(\\pmb{\\vartheta}^{(i^{*})}+\\eta\\frac{\\partial\\pmb{h}_{\\phi}(\\pmb{\\vartheta}^{(i^{*})})}{\\partial\\pmb{\\vartheta}^{(i^{*})}})\\pmb{A}_{\\phi},0,\\frac{\\pi}{2}\\right)}\\\\ {\\pmb{\\vartheta}^{(j^{*})}\\leftarrow\\mathrm{clip}\\left(\\pmb{\\vartheta}^{(j^{*})}-\\eta\\frac{\\partial\\pmb{h}_{\\phi}(\\pmb{\\vartheta}^{(j^{*})})}{\\partial\\pmb{\\vartheta}^{(j^{*})}}\\pmb{A}_{\\phi},0,\\frac{\\pi}{2}\\right)}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": ", where $\\begin{array}{r}{A_{\\phi}=\\frac{h_{\\phi}(\\pmb{\\vartheta}^{(i^{*})})-h_{\\phi}(\\pmb{\\vartheta}^{(j^{*})})}{\\rho(h_{\\phi}(\\pmb{\\vartheta}^{(i^{*})}),h_{\\phi}(\\pmb{\\vartheta}^{(j^{*})}))}^{\\top}}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "5: end for ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "6: Output: The updated preference angles $\\{\\pmb{\\vartheta}^{(1)},\\cdot\\cdot\\cdot,\\pmb{\\vartheta}^{(K)}\\}$ . ", "page_idx": 25}, {"type": "text", "text": "C.2 Problem formulations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "For completeness, ZDT1, ZDT2, and DTLZ1 problems are described as follows. ", "page_idx": 25}, {"type": "text", "text": "ZDT1. ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle f_{1}(\\pmb{x})=x_{1},}\\\\ {\\displaystyle f_{2}(\\pmb{x})=g(\\pmb{x})\\cdot h(f_{1}(\\pmb{x}),g(\\pmb{x})),}\\\\ {\\displaystyle g(\\pmb{x})=1+\\frac{9}{n-1}\\sum_{i=2}^{n}x_{i},}\\\\ {\\displaystyle h(f_{1}(\\pmb{x}),g(\\pmb{x}))=1-\\sqrt{f_{1}(\\pmb{x})/g(\\pmb{x})},}\\\\ {0\\leq x_{i}\\leq1,\\qquad i\\in[n].}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The PF of ZDT1 is $f_{2}=1-\\sqrt{f_{1}},0\\le f_{1}\\le1$ . ", "page_idx": 26}, {"type": "text", "text": "ZDT2. ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\{\\begin{array}{l l}{\\displaystyle f_{1}({\\boldsymbol x})=x_{1},}\\\\ {\\displaystyle f_{2}({\\boldsymbol x})=g({\\boldsymbol x})\\cdot h(f_{1}({\\boldsymbol x}),g({\\boldsymbol x})),}\\\\ {\\displaystyle g({\\boldsymbol x})=1+\\frac{9}{n-1}\\sum_{i=2}^{n}x_{i},}\\end{array}\\right.}\\\\ &{\\left|\\begin{array}{l l}{\\displaystyle h(f_{1}({\\boldsymbol x}),g({\\boldsymbol x}))=1-f_{1}({\\boldsymbol x})/g({\\boldsymbol x})^{2},}\\\\ {\\displaystyle0\\leq x_{i}\\leq1,\\qquad i\\in[n].}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The PF of ZDT2 is $f_{2}=1-f_{1}^{2},0\\leq f_{1}\\leq1$ . ", "page_idx": 26}, {"type": "text", "text": "DTLZ1.", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle f_{1}({\\pmb x})=\\frac{1}{2}x_{1}x_{2}(1+{\\pmb y}({\\pmb x})),}\\\\ {\\displaystyle f_{2}({\\pmb x})=\\frac{1}{2}x_{1}(1-x_{2})(1+{\\pmb y}({\\pmb x})),}\\\\ {\\displaystyle f_{3}({\\pmb x})=\\frac{1}{2}(1-x_{1})(1+{\\pmb y}({\\pmb x})),}\\\\ {\\displaystyle g({\\pmb x})=100\\big((n-2)+\\sum_{i=3}^{n}(x_{i}-0.5)^{2}+\\sum_{i=3}^{n}\\cos(20\\pi(x_{i}-0.5))\\big),}\\\\ {\\displaystyle0\\leq x_{i}\\leq1,\\qquad i\\in[n].}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The PF of DTLZ1 is $0.5\\Delta_{3}$ (3-dim simplex). ", "page_idx": 26}, {"type": "text", "text": "C.3 Conversion between a preference and a preference angle ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "The preference vector $\\lambda$ and preference angles $\\vartheta$ are easily inter-convertible via the following equations. This one-to-one, differentiable mapping allows conversion between $\\vartheta$ and $\\lambda$ . While $\\lambda$ belongs to the $m$ -D simplex, $\\vartheta$ lies within the box constraint $[0,\\frac{\\pi}{2}]^{m-1}$ . For optimization purposes, $\\vartheta$ is more manageable because it can be easily projected onto $\\left[0,\\frac{\\pi}{2}\\right]^{m-1}$ , whereas projecting $\\lambda$ onto the $m$ -D simplex is more complex. ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle\\vartheta_{1}=\\arg\\cos(\\sqrt{\\lambda_{1}}),}\\\\ {\\displaystyle\\vartheta_{2}=\\arg\\cos\\left(\\frac{\\sqrt{\\lambda_{2}}}{\\sin\\vartheta_{1}}\\right),}\\\\ {\\displaystyle\\vartheta_{3}=\\arg\\cos\\left(\\frac{\\sqrt{\\lambda_{3}}}{\\sin\\vartheta_{1}\\sin\\vartheta_{2}}\\right),}\\\\ {\\vdots}\\\\ {\\displaystyle\\vartheta_{m-1}=\\arg\\cos\\left(\\frac{\\sqrt{\\lambda_{m-1}}}{\\prod_{i=1}^{m-2}\\sin\\vartheta_{i}}\\right),}\\end{array}\\right.\\qquad\\left\\{\\begin{array}{l l}{\\displaystyle\\lambda_{2}=\\sin^{2}(\\vartheta_{1})\\cos^{2}(\\vartheta_{2}),}\\\\ {\\displaystyle\\lambda_{3}=\\sin^{2}(\\vartheta_{1})\\sin^{2}(\\vartheta_{2})\\cos^{2}(\\vartheta_{3}),}\\\\ {\\displaystyle\\vdots}\\\\ {\\displaystyle\\lambda_{m}=\\prod_{i=1}^{m-1}\\sin^{2}(\\vartheta_{i}).}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "C.4 Baseline methods used in fairness classification problem ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "This subsection describes gradient-based methods used as baselines in the fairness classification problem (Section 5.2). We introduce three aggregation functions: ", "page_idx": 27}, {"type": "text", "text": "1. Agg-LS (Linear Scalarization): ", "page_idx": 27}, {"type": "equation", "text": "$$\ng_{\\pm}^{\\mathrm{LS}}({\\pmb x})=\\sum_{i=1}^{m}\\lambda_{i}f_{i}({\\pmb x}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "2. Agg-Tche (Tchebycheff): ", "page_idx": 27}, {"type": "equation", "text": "$$\ng_{\\pm}^{\\mathrm{Tche}}(\\pmb{x})=\\operatorname*{max}_{i\\in[m]}\\{\\lambda_{i}(f_{i}(\\pmb{x})-z_{i})\\},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $_{\\textit{z}}$ is a reference point (e.g., ideal point) which dominates the entire PF, i.e., $z\\preceq y$ , for all $\\pmb{y}\\in\\mathcal{T}$ . ", "page_idx": 27}, {"type": "text", "text": "3. Agg-PBI (Penalty-Based Intersection): ", "page_idx": 27}, {"type": "equation", "text": "$$\ng_{\\lambda}^{\\mathrm{PBI}}({\\pmb x})=d_{1}+\\mu d_{2}=\\frac{\\left\\|({\\pmb z}-{\\pmb f}({\\pmb x}))^{\\top}{\\pmb\\lambda}\\right\\|}{\\left\\|{\\pmb\\lambda}\\right\\|}+\\mu\\left\\|{\\pmb f}({\\pmb x})-({\\pmb z}-d_{1}{\\pmb\\lambda})\\right\\|,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $_{z}$ is the same reference point as introduced. In gradient-based multiobjective optimization, the solution $\\textbf{\\em x}$ is updated by: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\pmb{x}\\leftarrow\\pmb{x}-\\eta\\frac{\\partial g_{\\pmb{\\lambda}}(\\pmb{x})}{\\partial\\pmb{x}},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\eta$ is a small positive learning rate, and agg denotes PBI, LS, or Tche. We also would like to briefly introduce the other three gradient based method, PMGDA (Preference-based Multiple Gradient Descent Algorithm) [60], EPO (Exact Pareto optimization) [37], and HVGrad (Gradientbased HV maximization method) [17]. PMGDA and EPO employ gradient-based techniques to precisely identify Pareto solutions at the intersection points where the Pareto objectives converge with the PF. In contrast, HVGrad leverages gradient ascent on the hypervolume to maximize the hypervolume metric, thereby optimizing the overall dominance of the solution set. ", "page_idx": 27}, {"type": "text", "text": "C.5 Duplicated solutions issues caused by the mTche aggregation function ", "text_level": 1, "page_idx": 27}, {"type": "image", "img_path": "WoEXVQcHFw/tmp/0c35d721f2168d324c14e928fb9a353886be2aadc6f1111101f0ce2a8d7aca74.jpg", "img_caption": [], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure 12: Duplicated solutions generated by Agg-mTche. Different preference vectors $\\lambda^{(1)}$ and $\\lambda^{(2)}$ correspond to the same optimal objective vector $\\boldsymbol{y}^{*}$ . ", "page_idx": 27}, {"type": "text", "text": "In this section, we discuss when Tchebycheff aggregation methods yield duplicated Pareto objectives. Appendix C.5 illustrates this, showing a preference vector $\\lambda^{(1)}$ intersecting the PF at the optimal solution $\\boldsymbol{y}^{*}$ , where ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\frac{y_{i}^{*}}{\\lambda_{i}}=...=\\frac{y_{m}^{*}}{\\lambda_{m}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "If the preference vector does not intersect the Pareto front $(\\lambda^{(2)})$ , $\\boldsymbol{y}^{*}$ is the Pareto front endpoint with the highest Tchebycheff value. In Appendix C.5, $\\boldsymbol{y}^{*}$ is the optimal value, so preferences $\\lambda^{(1)}$ and $\\lambda^{(2)}$ correspond to the duplicated Pareto objective $\\boldsymbol{y}^{*}$ . ", "page_idx": 27}, {"type": "text", "text": "D Miscellanies ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "D.1 Broader impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "By optimizing multiple conflicting objectives, these algorithms enhance decision-making in fields such as healthcare, product design, and trustworthy machine learning. In product design, multiobjective optimization balances trade-offs between capacity and cost, facilitating the effective release of products that represent the entire Pareto front. In trustworthy machine learning, the UMOD method designs a series of classifiers that balance fairness and accuracy, improving our understanding of different Pareto-optimal classifiers. ", "page_idx": 28}, {"type": "text", "text": "UMOD is a foundational algorithm, and its broader impact depends on its downstream applications.   \nWe believe UMOD itself does not have a direct negative social impact. ", "page_idx": 28}, {"type": "text", "text": "D.2 Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "While we have illustrated UMOD\u2019s success, we acknowledge some limitations. First, UMOD does not address disconnected Pareto fronts such as DTLZ7, as Theorems 3 and 4 assume a connected Pareto front to ensure uniform distribution. Second, we have not considered problems with discrete, binary decision variables, or constrained MOPs, as our approach requires a continuous Pareto front. Adapting UMOD to these complex MOO problems is our next goal. Finally, UMOD requires a neural model to estimate the Pareto front shape. Although training and preference updating with neural networks are efficient, this adds extra operations compared to traditional multiobjective algorithms, which brings inconvenience. ", "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 29}, {"type": "text", "text": "Justification: We explicitly enumerate our contributions in the end of the introduction part. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We list the limitations in the last section (Section 6). ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: The assumptions are included in theorems and the full proofs are provided in Appendices A.1 to A.3 respectively. ", "page_idx": 29}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide experiment details in Appendix B.3. ", "page_idx": 29}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 29}, {"type": "text", "text": "Justification: The model implementation and the code are attached as supplementary materials, which include sufficient instructions to faithfully reproduce the main experimental results and are scheduled to be open-sourced upon publication. ", "page_idx": 29}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 29}, {"type": "text", "text": "Justification: The details experiment settings are provided in Appendix B.3. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 29}, {"type": "text", "text": "Justification: All numerical results are averaged on 31 random seeds. ", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 29}, {"type": "text", "text": "Justification: Details are provided in Section 5 (Experiment settings). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 30}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 30}, {"type": "text", "text": "Social impact is discussed in Appendix D.1. ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: This paper is not related to LLMs and image generators. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 30}, {"type": "text", "text": "Justification: Licenses are provided in Appendix B.3. ", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper proposes a new model, and we choose the CC BY 4.0 license. ", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: This paper is not related with human subjects. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 30}, {"type": "text", "text": "Justification: The proposed method is a fundamental algorithm and is not directly related to human subjects. ", "page_idx": 30}]