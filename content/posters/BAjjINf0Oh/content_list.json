[{"type": "text", "text": "Oracle-Efficient Differentially Private Learning with Public Data ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Adam Block ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mark Bun ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Mathematics MIT Cambridge, MA 02139 ablock@mit.edu ", "page_idx": 0}, {"type": "text", "text": "Department of Computer Science Boston University Boston, MA 02215 mbun@bu.edu ", "page_idx": 0}, {"type": "text", "text": "Rathin Desai ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Abhishek Shetty ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Computer Science Boston University Boston, MA 02215 rathin@bu.edu ", "page_idx": 0}, {"type": "text", "text": "Department of Computer Science   \nUniversity of California, Berkeley Berkeley, CA 94720 shetty@berkeley.edu   \nZhiwei Steven Wu   \nSchool of Computer Science   \nCarnegie Mellon University   \nPittsburgh, PA 15213   \nzstevenwu@cmu.edu ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Due to statistical lower bounds on the learnability of many function classes under privacy constraints, there has been recent interest in leveraging public data to improve the performance of private learning algorithms. In this model, algorithms must always guarantee differential privacy with respect to the private samples while also ensuring learning guarantees when the private data distribution is sufficiently close to that of the public data. Previous work has demonstrated that when sufficient public, unlabelled data is available, private learning can be made statistically tractable, but the resulting algorithms have all been computationally inefficient. In this work, we present the first computationally efficient, algorithms to provably leverage public data to learn privately whenever a function class is learnable non-privately, where our notion of computational efficiency is with respect to the number of calls to an optimization oracle for the function class. In addition to this general result, we provide specialized algorithms with improved sample complexities in the special cases when the function class is convex or when the task is binary classification. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Differential privacy (DP) [Dwork et al., 2006] is a standard guarantee of individual-level privacy for statistical data analysis. Algorithmic research on differential privacy aims to understand what statistical tasks are compatible with the definition, and at what cost, e.g., in terms of sample complexity or computational efficiency. Unfortunately, it is known that some tasks may become more expensive or outright impossible to conduct with differential privacy. For example, in the setting of binary classification, there is no differentially private algorithm for solving the simple problem of learning a one-dimensional classifier over the real numbers [Bun et al., 2015, Alon et al., 2019]. ", "page_idx": 0}, {"type": "text", "text": "Motivated in part by such barriers to full-fledged private learning, many papers have considered relaxing the model to allow the use of auxiliary \u201cpublic\u201d data Balcan and Feldman [2013], Bassily et al. [2019, 2020b, 2022, 2023], Kairouz et al. [2021], Amid et al. [2022], Lowy et al. [2023]. Such data may be available if individuals can voluntarily opt-in to share or sell their information to enable a particular task. Alternatively, a data analyst might have background knowledge about the underlying data distribution from the results of previous analyses, or hold a plausible generative model for it. These situations are captured by semi-private learning, first discussed by Balcan and Feldman [2013], formally introduced by Beimel et al. [2014] and subsequently studied by Bassily et al. [2019], Hopkins et al. [2024]. In this model, a learning algorithm is given $n$ \u201cprivate\u201d samples from a joint distribution $\\mathcal{D}$ over example-label pairs, as well as $m$ unlabeled \u201cpublic\u201d samples from the same marginal distribution over examples. The algorithm must be differentially private with respect to its private dataset, but can depend arbitrarily on its public samples. For learning a binary classifier over a class $\\mathcal{F}$ with a VC-dimension $\\mathsf{v c}({\\mathcal F})$ , these papers showed that in the presence of $O\\big(\\mathsf{v c}(\\mathcal{F})\\big)$ public unlabeled samples, every concept class $\\mathcal{F}$ is agnostically learnable with $O\\big(\\mathsf{v c}(\\mathcal{F})\\big)$ private labeled samples, matching what is achievable without privacy guarantees. ", "page_idx": 1}, {"type": "text", "text": "While these results essentially resolve the statistical complexity of semi-private learning, they do not address the question of computational efficiency. These algorithms proceed by drawing enough public samples to construct a cover for the class $\\mathcal{F}$ with respect to the target marginal distribution on examples, and then using the exponential mechanism [McSherry and Talwar, 2007] to select a hypothesis from this cover that fits the private dataset. As the size of this cover is exponential in $\\mathsf{v c}({\\mathcal F})$ , constructing it explicitly is computationally expensive. This paper aims to address the following question: Is such computational overhead really necessary if $\\mathcal{F}$ exhibits additional structure that make non-private learning tractable? ", "page_idx": 1}, {"type": "text", "text": "In this work, we give new semi-private learners that are efficient whenever fast non-private algorithms are available. More specifically, our main result is generic semi-private algorithms for regression and classification that are oracle-efficient in that they run in polynomial time given an oracle solving the non-private empirical risk minimization problem for $\\mathcal{F}$ , and have sample complexity polynomial in the usual parameters such as Gaussian complexity and VC dimension. ", "page_idx": 1}, {"type": "text", "text": "Theorem 1 (Informal version of Theorem 2). Fix a function class $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ . Then there is an oracle-efficient, $(\\varepsilon,\\delta)$ -differentially private algorithm (Algorithm 2) using $p o I y(\\operatorname{sup}_{m}\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F}))$ labeled private samples (where, $\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})$ denotes the Gaussian complexity of function class $\\mathcal{F}$ ), unlabeled public samples, and calls to an empirical risk minimization oracle for $\\mathcal{F}$ that learns an approximately optimal predictor ${\\hat{f}}\\in{\\mathcal{F}}$ . ", "page_idx": 1}, {"type": "text", "text": "While Theorem 1 captures extremely broad learning settings, the polynomials governing its sample complexity are rather large. We identify several important cases in which the sample complexity can be improved and the number of oracle calls is only 2. In the case where the function class $\\mathcal{F}$ is convex, we give a variant of Algorithm 2, inspired by follow-the-regularized-leader, with significantly improved sample complexity as a function of the desired error (Theorem 3, Algorithm 3). Finally, in the special case of binary classification (i.e., Boolean $\\mathcal{F}$ under the 0-1 loss), we give a completely different oracle-efficient algorithm with improved sample complexity (Theorem 4, Algorithm 4), which requires the private sample size to grow at the rate of $O((\\bar{\\mathsf{v c}}({\\mathcal{F}}))^{2})$ . Prior work of Bassily et al. [2018] gave an oracle-efficient algorithm in this setting with somewhat better sample complexity than ours, based on a reduction to private classification. Meanwhile, our algorithm has the advantage of being able to guarantee pure (rather than only approximate) differential privacy algorithm, as well as making only two oracle calls as opposed to the polynomially many as a function of $\\varepsilon$ and the target accuracy. Our results in the binary classification setting can also be viewed as an extension of Neel et al. [2019], which gives oracle-efficient private learners for structured function classes $\\mathcal{F}$ that have a small universal identification set [Goldman et al., 1993]. Our results relax this stringent combinatorial condition by leveraging a small public unlabelled dataset, which allows us to design an oracle-efficient private learner for any function class $\\mathcal{F}$ with bounded VC-dimension. ", "page_idx": 1}, {"type": "text", "text": "In fact, our results also address a somewhat more general setting than the semi-private model described so far. Specifically, our results automatically handle the setting where there may be a bounded distribution shift between the public and private data. In particular, all of our results hold as long as the public unlabelled data distribution and the private marginal distribution over the feature space have a density ratio bounded by $\\sigma$ .1 The standard semi-private setting corresponds to the special case where $\\sigma=1$ . Taking this view, we can interpret our results as oracle-efficient private learning in the smoothed learning setting. Our algorithms achieve accurate learning provided that the private marginal distribution does not deviate too much from a public reference distribution. However, our privacy guarantees hold even if the private data distribution has unbounded distribution shift from the public data. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "1.1 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our work brings together ideas and techniques from multiple literatures. ", "page_idx": 2}, {"type": "text", "text": "Oracle efficiency in private and online learning. Our notion of oracle-efficiency is standard in (theoretical) machine learning to model reductions in a world where worst-case hardness abounds, but optimization heuristics (e.g., integer programming solvers, non-convex optimization) often enjoy success. Within the differential privacy literature, oracle-efficient algorithms are known for binary classification with classes $\\mathcal{F}$ that admits small universal identification sets [Neel et al., 2019], synthetic data generation [Gaboardi et al., 2014, Nikolov et al., 2013, Neel et al., 2019, Vietri et al., 2020], and certain types of non-convex optimization problems [Neel et al., 2020]. Oracle-efficiency is also well-established approach in online learning [Kalai and Vempala, 2005, Hazan and Koren, 2016, Kozachinskiy and Steifer, 2023, Haghtalab et al., 2022a, Block and Simchowitz, 2022, Block and Polyanskiy, 2023, Block et al., 2023a,b], an area with deep connections to differential privacy [Alon et al., 2019, Abernethy et al., 2019, Bun et al., 2020, Ghazi et al., 2021]. Indeed, our new semi-private learning algorithm Algorithm 2 adapts a follow-the-perturbed-leader inspired algorithm [Block et al., 2022] from the setting of smoothed online learning. ", "page_idx": 2}, {"type": "text", "text": "DP learning and release with public (unlabelled) data Our results contribute to a long line of theoretical work that leverages public data for private data analysis. In particular, our work provides general computationally efficient algorithms (in the oracle efficiency sense) for semi-private learning [Beimel et al., 2014]. In addition to the work in this direction we discussed above, several recent papers Bassily et al. [2022, 2023] developed efficient algorithms for private learning with domain adaptation from a public source. That work accommodates a more general notion of distribution shift than ours, but makes essential use of labeled public data, as well as handling only restricted concept classes or loss functions. There has also been work that leverages public data to remove statistical barriers in private query release [Bassily et al., 2020a] and density estimation Bie et al. [2022], Ben-David et al. [2023]. Papernot et al. [2018], Yu et al. [2022], Golatkar et al. [2022], Zhou et al. [2021] and Liu et al. [2021a,b] give empirical guarantees to the problem of private learning and private synthetic data from public samples respectively. ", "page_idx": 2}, {"type": "text", "text": "Smoothed Analysis in Online Learning. Smoothed analysis was pioneered in Spielman and Teng [2004] for the purpose of explaining the empirical success of algorithms whose worst-case behavior is provably intractable. More recently, the framework has come to online learning [Rakhlin et al., 2011, Haghtalab et al., 2020, 2022b, Block et al., 2022, Haghtalab et al., 2022a, Block and Simchowitz, 2022, Block et al., 2023a,b] in order to circumvent the strong statistical [Rakhlin et al., 2015] and computational [Hazan and Koren, 2016] lower bounds that worst-case data can induce. The assumption of smoothness has also been used in learning more broadly [Durvasula et al., 2023, Cesa-Bianchi et al., 2023] and its assumptions have been relaxed [Block and Polyanskiy, 2023]. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we formally introduce our setting. Let $\\mathcal{X}$ denote the feature space and $\\boldsymbol{\\wp}$ be the label space. In general, we consider $y=[-1,\\bar{1}]$ , but in the special case of binary classification setting, we have ${\\mathcal{D}}=\\{0,1\\}$ . In general, we study learning algorithms $\\boldsymbol{\\mathcal{A}}$ that map a dataset $\\mathcal{D}$ with $n$ examples from $\\mathcal X\\times\\mathcal Y$ to a predictor in a function class $\\mathcal{F}$ . We require $\\boldsymbol{\\mathcal{A}}$ to satisfy differential privacy, defined below. ", "page_idx": 2}, {"type": "text", "text": "Definition 1 (Differential Privacy Dwork et al. [2006]). Let $A:({\\mathcal{X}}\\times{\\mathcal{Y}})^{n}\\to{\\mathcal{F}}$ be a randomized algorithm and $\\mathcal{D},\\mathcal{D}^{\\prime}\\in(\\mathcal{X}\\times\\mathcal{Y})^{\\bar{n}}$ be data sets. We say that $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ are neighboring if $\\left|\\mathcal{D}\\right\\backslash\\mathcal{D}^{\\prime}\\right|=$ $|\\bar{D^{\\prime}}\\setminus\\mathcal{D}|\\le1$ , i.e. they differ in at most one datum. We say that $\\boldsymbol{\\mathcal{A}}$ is $(\\varepsilon,\\delta)$ -differentially private if for all neighboring datasets $\\mathcal{D},\\mathcal{D}^{\\prime}$ , and for all measurable $\\mathcal{G}\\subset\\mathcal{F}$ , it holds that $\\mathbb{P}\\left(\\boldsymbol{\\mathcal{A}}(\\mathcal{D})\\in\\mathcal{G}\\right)\\le$ $e^{\\varepsilon}\\cdot\\mathbb{P}\\left({\\mathcal{A}}({\\mathcal{D}}^{\\prime})\\in{\\mathcal{G}}\\right)\\bar{+}\\,\\delta$ . If $\\delta=0$ , we say that $\\boldsymbol{\\mathcal{A}}$ is $\\varepsilon$ -(purely) differentially private. ", "page_idx": 3}, {"type": "text", "text": "As defined, it is trivial to construct algorithms that are differentially private by outputting functions independent of the data set; for an algorithm to be useful, however, we also require that it learns in a meaningful sense. Thus, in the context of learning, we consider the following accuracy desideratum. ", "page_idx": 3}, {"type": "text", "text": "Definition 2. Let $A:(\\mathcal{X}\\times\\mathcal{Y})^{n}\\to\\mathcal{F}$ be a randomized algorithm. We say that $\\boldsymbol{\\mathcal{A}}$ is an $(\\alpha,\\beta)$ - learner with respect to a measure $\\nu$ on $\\mathcal X\\times\\mathcal X$ and loss function $L:\\mathcal{F}\\rightarrow[-1,1]$ if, for $\\mathcal{D}$ sampled independently from $\\nu$ , it holds that $\\mathbb{P}\\left(L(\\boldsymbol{\\mathcal{A}}(\\mathcal{D}))\\le\\operatorname*{inf}_{f\\in\\mathcal{F}}L(f)+\\alpha\\right)\\ge1-\\overset{.}{\\beta}$ . For regression problems, we consider the loss function $L$ to be induced by a function $\\ell:\\mathcal{V}\\times\\mathcal{V}\\rightarrow[0,1]$ , convex and $\\lambda$ -Lipschitz in the first argument, such that $L(f)=\\mathbb{E}_{(X,Y)\\sim\\nu}\\left[\\ell(f(X),Y)\\right]$ . ", "page_idx": 3}, {"type": "text", "text": "For simplicity, we will denote the empirical loss on a data set $\\mathcal{D}$ as $\\begin{array}{r l r}{L_{\\mathcal{D}}(f)}&{{}=}&{\\frac{1}{n}}\\end{array}$ \u00b7 (X,Y)\u2208D \u2113(f(Xi), Yi). We emphasize that in contradistinction to the standard notion of PAClearnability [Valiant, 1984], our requirement is weaker in that we only require distribution-dependent learning, i.e., the algorithm $\\boldsymbol{\\mathcal{A}}$ is allowed to depend on $\\nu$ in some to-be-specified way. This is necessary in our setting as it is well known that distribution-independent differentially private PAC learning is possible only for very restricted classes of functions $\\mathcal{F}$ with bounded Littlestone dimension [Alon et al., 2019, Bun et al., 2020]. To make private learning statistically tractable for broader classes of functions, we consider the following restriction on $\\nu$ : ", "page_idx": 3}, {"type": "text", "text": "Definition 3. Given a measure $\\mu~\\in~\\Delta(\\mathcal{X})$ and a parameter $\\sigma\\ \\in\\ (0,1]$ , we say that $\\nu_{x}$ is $\\sigma$ - smooth with respect to $\\mu$ if $\\begin{array}{r}{\\left\\|\\frac{d\\nu_{x}}{d\\mu}\\right\\|_{\\infty}\\leq\\,\\frac{1}{\\sigma}}\\end{array}$ . We suppose that the learner has access to $m$ samples $Z_{1},\\ldots,Z_{m}\\sim\\mu$ that are independent of each other and the training data $\\mathcal{D}$ and thus $\\boldsymbol{\\mathcal{A}}$ may depend on these samples. ", "page_idx": 3}, {"type": "text", "text": "We remark that Definition 3 can be significantly relaxed by assuming only that $\\begin{array}{r}{D_{f}(\\nu_{x}||\\mu)\\leq\\frac{1}{\\sigma}}\\end{array}$ as in Block and Polyanskiy [2023], where $D_{f}(\\cdot||\\cdot)$ is a sufficiently strong $f$ -divergence2. In this case, the statistical rates presented below will be worse and depend on $f$ , but the algorithms and privacy guarantees will remain unchanged. Critically, we do not require that our algorithms are private with respect to $Z_{1},\\ldots,Z_{m}$ , which we treat as public, unlabelled data. The key reason that this public data helps us circumvent the lower bounds is that it gives us access (albeit indirectly) to a small subclass of the hypothesis set that still has approximately good hypotheses. Since our primary focus is to design computationally efficient private learners, we cannot directly handle either the original hypothesis class or the small proxy that the public data gives us access. Instead we suppose access to the following ERM oracle: ", "page_idx": 3}, {"type": "text", "text": "Definition 4. Given a function class $\\mathcal{F}:\\,\\boldsymbol{\\mathcal{X}}\\,\\rightarrow\\,\\mathbb{R}$ , a data set $\\mathcal{D}\\,=\\,\\{x_{1},\\..\\ .\\ ,x_{m}\\}\\,\\subset\\,\\mathcal{X}$ and loss functions $\\ell_{1},\\ldots,\\ell_{m}:\\mathbb{R}\\to\\mathbb{R}$ , we define the empirical risk minimization oracle ERM : ${\\mathcal{F}}\\to\\mathbb{R}$ such that $\\mathsf E\\mathsf{R M}(\\mathcal F,\\mathcal L_{\\mathcal D})\\in\\mathrm{argmin}_{f\\in\\mathcal F}\\,\\mathcal L_{\\mathcal D}(f)$ , where $\\begin{array}{r}{\\mathcal{L}_{\\mathcal{D}}(f)=\\sum_{x_{i}\\in\\mathcal{D}}\\ell_{i}(f(x_{i}))}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "ERM oracles are standard computational models in many learning domains such as online learning [Kalai and Vempala, 2005, Hazan and Koren, 2016, Block et al., 2022, Haghtalab et al., 2022a] and Reinforcement Learning [Foster and Rakhlin, 2020, Foster et al., 2021, Mhammedi et al., 2023b,a]. Assuming access to ERM allows us to disentangle the computational challenges of optimizing over specific function classes from the specific challenge of differentially private learning as well as to avoid the well-known intractability results for nonconvex optimization [Blum and Rivest, 1988] that do not accurately reflect the realities of modern optimization techniques (e.g., integer program solvers, SGD). We note that our algorithms also work in the case of ERM oracles with additive error by minor modification to the analysis similar to the one in [Block et al., 2022]. We remark that applying Neel et al. [2019, Theorem 8] gives a black-box robustification procedure for purely private, oracle-efficient algorithms, which ensures that the privacy guarantees continue to hold even when the oracle may fail to optimize the objective. In particular, Algorithms 3 and 4 below, when run in their pure DP forms can be made robust at a minimal cost on accuracy. We defer to Neel et al. [2019] for further discussion on this topic. ", "page_idx": 3}, {"type": "table", "img_path": "BAjjINf0Oh/tmp/a4dcac3897d35754cb506b1444a4604e583cc77e6d7009f5567633c98127f4c5.jpg", "table_caption": ["Algorithm 1: Perturb: An algorithm for perturbing a function with noise on public data. "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "It is well-known that even absent differential privacy guarantees, learning arbitrary function classes is impossible; we now introduce the notions of complexity that are relevant to our results. We begin with the standard notion of VC dimension: ", "page_idx": 4}, {"type": "text", "text": "Definition 5. Let ${\\mathcal{F}}:{\\mathcal{X}}\\rightarrow\\{0,1\\}$ be a function class. We say that a set of points $x_{1},\\ldots,x_{d}\\in{\\mathcal{X}}$ shatters $\\mathcal{F}$ if for all ${\\varepsilon_{1:d}}\\;\\in\\;\\{0,1\\}^{d}$ , there is some $f_{\\varepsilon}$ such that $f_{\\varepsilon}(x_{i})\\;=\\;\\varepsilon_{i}$ for all $i$ . The VC dimension of $\\mathcal{F}$ , denoted $\\mathsf{v c}({\\mathcal F})$ , is the largest $d$ such that there exists a set of $d$ points shattering $\\mathcal{F}$ . ", "page_idx": 4}, {"type": "text", "text": "In addition to VC dimension, we also use the Gaussian complexity of a function class: ", "page_idx": 4}, {"type": "text", "text": "Definition 6. Let $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ be a function class and $x_{1},\\ldots,x_{m}\\in\\mathcal{X}$ be arbitrary points. We let $\\omega_{m}:\\mathcal{F}\\rightarrow\\mathbb{R}$ be the canonical Gaussian process on $\\mathcal{F}$ , i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\omega_{m}(f)={\\frac{1}{\\sqrt{m}}}\\cdot\\sum_{i=1}^{m}\\xi_{i}\\cdot f(x_{i}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\xi_{i}$ are independent standard Gaussians. We define the (data-dependent) Gaussian complexity of $\\mathcal{F}$ to be $\\mathbb{E}\\left[\\operatorname{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right]$ , the average Gaussian complexity as $\\begin{array}{r l}{\\mathcal{G}_{m}(\\mathcal{F})}&{{}=}\\end{array}$ $\\mathbb{E}_{Z}\\mathbb{E}[\\operatorname{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)]$ , and the worst-case Gaussian complexity of $\\mathcal{F}$ to be $\\begin{array}{r l}{\\overline{{\\mathcal{G}}}_{m}({\\mathcal{F}})}&{{}=}\\end{array}$ $\\operatorname*{sup}_{x_{1},\\dots,x_{m}\\in\\mathcal{X}}\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right]$ . ", "page_idx": 4}, {"type": "text", "text": "Both $\\mathsf{v c}({\\mathcal F})$ and $\\mathcal{G}_{m}(\\mathcal{F})$ are well known measures of complexity from learning theory and their relationships to other notions of complexity like covering number are well-understood [Mendelson and Vershynin, 2003, Wainwright, 2019, Van Handel, 2014]. In particular, it is well-known that $\\mathcal{G}_{m}(\\mathcal{F})\\,=\\,O(\\sqrt{\\mathsf{v c}(\\mathcal{F})})$ [Dudley, 1969, Mendelson and Vershynin, 2003] and that standard PAClearning is possible if and only if ${\\overline{{\\mathcal{G}}}}_{m}({\\mathcal{F}})\\,=\\,o({\\sqrt{m}})$ [Wainwright, 2019, Van Handel, 2014]. We remark that different texts use different scalings for $\\mathcal{G}_{m}(\\mathcal{F})$ , with some replacing the $m^{-1/2}$ factor in (1) with $m^{-1}$ and others omitting it entirely; our choice of scaling is motivated by the fact that a natural complexity measure for many (Donsker [Wainwright, 2019]) function classes that our algorithms depend on is $\\operatorname{sup}_{m}\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})$ , which is most compactly represented with the present scaling. ", "page_idx": 4}, {"type": "text", "text": "Notation. We always reserve $\\mathbb{P}$ and $\\mathbb{E}$ for probability and expectation with respect to measures that are clear from the context. We denote by $\\Delta(\\mathcal{X})$ the space of measures on some $\\mathcal{X}$ and for any $\\mu\\,\\in\\,\\Delta(\\mathcal{X})$ we let $\\left\\|\\cdot\\right\\|_{\\mu}$ denote the $L^{2}(\\mu)$ norm, i.e., $\\|f\\|_{\\mu}^{2}\\,=\\,\\mathbb{E}_{Z\\sim\\mu}[f(Z)^{2}]$ . Similarly, for $m$ points $Z_{1},\\ldots,Z_{m}\\ \\in\\ \\mathcal{X}$ , we let $\\|\\cdot\\|_{m}$ denote the empirical $L^{2}$ norm on these points so that $\\begin{array}{r}{\\|f\\|_{m}^{2}=m_{.}^{-1}\\cdot\\sum_{i=1}^{m}f(Z_{i})^{2}}\\end{array}$ . We reserve $\\omega_{m}$ for the canonical empirical Gaussian process on $\\mathcal{F}$ as in (1) and $\\mathcal{L}$ for a functional on $\\mathcal{F}$ . ", "page_idx": 4}, {"type": "text", "text": "3 Algorithms for Differentially Private Learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we provide a general template for constructing differentially private learning algorithms with public data and instantiate this template with two oracle-efficient algorithms. Our first algorithm applies to arbitrary bounded function classes, whereas the second algorithm only applies to convex classes but has an improved sample complexity. Our general template is broken into the following two steps: (i) Use ERM (cf. Definition 4) and the public data to construct an initial estimate $\\bar{f}$ that is a good learner and satisfies stability with respect to $\\|\\cdot\\|_{m}$ ; (ii) Output $\\widehat{f}$ as the function that minimizes $\\left\\|f-{\\bar{f}}-\\gamma\\cdot\\zeta\\right\\|_{m_{\\cdot}}$ , where $\\gamma\\geq0$ is a scale and $\\zeta=(\\zeta_{1},\\dots,\\zeta_{m})$ is a vector of independent random variables sampled according to some distribution $\\mathcal{Q}$ . The second step is accomplished through Algorithm 1 and is the same across our algorithms. The first step, however, ", "page_idx": 4}, {"type": "text", "text": "1: Input Oracle ERM, perturbation parameter $\\eta>0$ , public data set $\\widetilde{D}_{x}=\\{Z_{1},\\ldots,Z_{m}\\}$ , private data set $\\mathcal{D}=\\bar{\\{}(X_{i},Y_{i})|1\\leq i\\leq n\\}$ , function class $\\mathcal{F}$ , loss f unction $\\ell$ , noise level $\\gamma>0$ , number of iterations $J\\in\\mathbb{N}$ , noise distribution $\\mathcal{Q}\\in\\Delta(\\mathbb{R})$ .   \n2: for $j=1,2,\\dots,J$ do   \n34:: Sample \u03be1(j ), . Define $\\omega_{m}^{(j)}:\\mathcal{F}\\rightarrow\\mathbb{R}$ $\\xi_{1}^{(j)},\\cdot\\cdot\\cdot,\\xi_{m}^{(j)}\\sim\\mathcal{N}(0,1)$ such that $\\omega_{m}^{(j)}(f)=\\frac{1}{\\sqrt{m}}\\cdot\\sum_{i=1}^{m}\\xi_{i}\\cdot f(Z_{i}).$ (2)   \n5: Define $\\mathcal{L}^{(j)}:\\mathcal{F}\\rightarrow\\mathbb{R}$ such that $\\begin{array}{r}{\\mathscr{L}^{(j)}(f)=\\sum_{(X_{i},Y_{i})\\in\\mathcal{D}}\\ell(f(X_{i}),Y_{i})+\\eta\\cdot\\omega_{m}^{(j)}(f).}\\end{array}$   \n6: Define $\\bar{f}_{j}=\\mathsf E\\mathsf{R M}(\\mathcal{L}^{(j)},\\mathcal{F})$ end   \n7: Define $\\begin{array}{r}{\\bar{f}=\\frac{1}{J}\\cdot\\sum_{j=1}^{J}\\bar{f}_{j}}\\end{array}$ .   \n8: Output $\\widehat{f}=\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})$ \u25b7By running Algorithm 1 ", "page_idx": 5}, {"type": "text", "text": "is algorithm-specific and is the primary factor affecting the sample complexity. The intuition for our template is as follows. We need to show that $\\widehat{f}$ is both a learner and is differentially private. To see why the template produces a good learner, note that if $Z_{i}\\sim\\mu$ are independent and $m$ is sufficiently large, then $\\|\\cdot\\|_{m}\\approx\\|\\cdot\\|_{\\mu}$ . Thus if $\\gamma$ is small, then $\\left\\|{\\bar{f}}-{\\widehat{f}}\\right\\|_{\\mu}\\ll1$ and $\\Big|\\overline{{\\mathbb{E}}}_{\\mu}\\left[L(\\widehat{f})\\right]-\\mathbb{E}_{\\mu}[L(\\bar{f})]\\Big|\\ll1$ whenever $\\ell$ is Lipschitz. By smoothness, a similar guarantee holds for expectations with respect to $\\nu$ and thus $\\widehat{f}$ is a good learner. To see why $\\widehat{f}$ is differentially private, note that by choosing $\\mathcal{Q}$ to be a standard Gaussian, we can ensure that the likelihood ratios of choosing $\\widehat{f}$ given $\\bar{f}$ versus ${\\bar{f}}^{\\prime}$ are controlled by $\\left\\|{\\bar{f}}-{\\bar{f}}^{\\prime}\\right\\|_{m}$ . Thus, if $\\bar{f}$ is stable with respect to $\\|\\cdot\\|_{m}$ , then $\\widehat{f}$ will be private. The intuition of the stability of $\\bar{f}$ is discussed in Section 4. ", "page_idx": 5}, {"type": "text", "text": "We now make the above intuition precise by instantiating this template in our most general setting in Algorithm 2. We construct $\\bar{f}$ by running ERM on a perturbed version of the empirical risk minimization problem and then averaging. Specifically, for $j\\in[J]$ , we define $\\mathcal{L}^{(j)}:\\bar{\\mathcal{F}}\\rightarrow\\mathbb{R}$ as a sample path of a noncentred Gaussian process in (2) and let ${\\bar{f}}_{j}$ denote the minimizer of $\\mathscr{L}^{(j)}$ over $\\mathcal{F}$ . We then output $\\bar{f}$ as the average of ${\\bar{f}}_{1},\\ldots,{\\bar{f}}_{J}$ . We present motivation for the particular choice of $\\bar{f}$ , as well as the analogue in Algorithm 3, in the subsequent section. The following theorem shows that if $\\mathcal{Q}$ is chosen correctly, this algorithm is an oracle-efficient differentially private learner whenever $\\nu_{x}$ is $\\sigma$ -smooth with respect to $\\mu$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. Suppose that $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ is a function class and $\\mu\\in\\Delta(\\mathcal{X})$ is a measure such that $\\operatorname*{inf}_{f\\in{\\mathcal{F}}}\\left\\|f\\right\\|_{\\mu}\\geq\\ \\frac{2}{3}$ . Let $\\ell:[-1,\\dot{1}]\\times[-1,1]\\,\\to\\,[0,1]$ be a loss function that is convex and $\\lambda$ -Lipschitz in its first argument. If $\\mathcal{Q}=\\mathcal{N}(0,1)$ in Algorithm $^{\\,l}$ , then for any $\\varepsilon,\\delta,\\alpha,\\beta\\,\\in\\,(0,1),$ , there are choices of $\\eta,\\gamma\\,>\\,0$ and $J,m\\,\\in\\,\\mathbb{N}$ , all polynomial in problem parameters and given in Appendix C.6, such that if ", "page_idx": 5}, {"type": "equation", "text": "$$\nn=\\mathsf{p o l y}\\left(\\operatorname*{sup}_{m}\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F}),\\log\\left(\\frac{1}{\\delta}\\right),\\log\\left(\\frac{1}{\\beta}\\right),\\lambda\\right)\\cdot\\varepsilon^{-3}\\cdot\\alpha^{-14},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "then the $\\widehat{f}$ returned by Algorithm 2 is $(\\varepsilon,\\delta)$ -differentially private. If $\\nu_{x}$ is $\\sigma$ -smooth with respect to $\\mu,$ , then $\\widehat{f}$ is an $(\\alpha,\\beta)$ -learner with respect to $\\nu_{x}$ and $\\ell$ . ", "page_idx": 5}, {"type": "text", "text": "We emphasize that Algorithm 2 is always differentially private, independent of $\\nu$ ; however, our algoirthm is only a good learner if $\\nu_{x}$ is smooth with respect to $\\mu$ . We remark that all of the conditions in Theorem 2 are standard with the exception of the assumption that $\\|f\\|_{\\mu}\\,\\geq\\,2/3$ for all $f\\,\\in\\,{\\mathcal{F}}$ . This condition is easy to ensure by setting $\\begin{array}{r}{\\widetilde{\\mu}=\\frac{\\mu+2\\cdot\\delta_{z^{\\star}}}{3}}\\end{array}$ , where $z^{\\star}$ is a distinguished point such that $f(z^{\\star})=1$ for all $f\\in\\mathcal F$ ; note that this pro c ess deflates $\\sigma$ at most by a factor of 3 while ensuring the lower bound on the norm of $f$ . Replacing $\\mu$ by $\\widetilde{\\mu}$ then suffices to ensure that Theorem 2 holds. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 3: Oracle Efficient Private Learner (Regularization) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "1: Input Oracle ERM, perturbation parameter $\\eta>0$ , public data set $\\widetilde{D}_{x}=\\{Z_{1},\\ldots,Z_{m}\\}$ , private data set $\\mathcal{D}=\\{(X_{i},Y_{i})|1\\leq i\\leq n\\}$ , function class $\\mathcal{F}$ , loss function $\\ell$ , noise level $\\gamma>0$ , number of iterations $J\\in\\mathbb{N}$ , noise distribution $\\mathcal{Q}\\in\\Delta(\\mathbb{R})$ . ", "page_idx": 6}, {"type": "text", "text": "2: Define $\\mathcal{L}:\\mathcal{F}\\rightarrow\\mathbb{R}$ such that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{L}(f)=\\sum_{(X_{i},Y_{i})\\in\\mathcal{D}}\\ell(f(X_{i}),Y_{i})+\\eta\\cdot\\Vert f\\Vert_{m}^{2}\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "3: Define $\\bar{f}=\\mathsf E\\mathsf{R M}(\\mathcal L,\\mathcal F)$   \n4: Output $\\widehat{f}=\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})$ ", "page_idx": 6}, {"type": "text", "text": "\u25b7By running Algorithm 1 ", "page_idx": 6}, {"type": "text", "text": "We further remark that it is classical that the complexity notion $\\operatorname{sup}_{m}\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})$ is upper bounded by $\\sqrt{\\mathsf{v c}({\\mathcal F})}$ for binary function classes and ${\\sqrt{\\log(|{\\mathcal{F}}|)}}$ for finite classes [Wainwright, 2019], ensuring that the proven sample complexity is polynomial in all standard notions of function class complexity. For even more complex function classes, where $\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})=\\omega(1)$ , similar results hold, although with worse rates; further dicussion, as well as the precise polynomial dependence of hyperparameters and sample complexity, can be found in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "While Algorithm 2 succeeds in our desiderata under general assumptions, the sample complexity is a large polynomial of the desired accuracy. Indeed, the sample complexity of Algorithm 2 scales like $O\\left(\\mathsf{v c}({\\mathcal{F}})\\cdot\\varepsilon^{-3}\\cdot\\alpha^{-14}\\right)$ , which is significantly worse than the $\\dot{O}\\left(\\mathsf{v c}(\\dot{\\mathcal{F}})\\cdot\\alpha^{-\\breve{2}}\\right)$ sample complexity that a non-private algorithm such as ERM can achieve [Wainwright, 2019] or even the $O\\left(\\overleftarrow{\\sf v c}(\\mathcal{F})\\cdot\\alpha^{-2}\\cdot\\varepsilon^{-2}\\right)$ sample complexity achievable by private, inefficient algorithms with public data [Bassily et al., 2020b]. Furthermore, we are unable to achieve a pure differential privacy guarantee with this algorithm. We now address both issues by providing an improved algorithm in the special case that the function class $\\mathcal{F}$ is convex. While we still use Algorithm 1 as a subroutine, in Algorithm 3, motivated by the difference between Follow the Perturbed Leader (FTPL) and Follow the Regularized Leader (FTRL) [Kalai and Vempala, 2005, Cesa-Bianchi and Lugosi, 2006] in online learning, we modify the way in which we choose our initial estimator $\\bar{f}$ . In particular, we eliminate the averaging step and redefine $\\omega$ to be a strongly convex regularizer instead of a Gaussian Process perturbation. More specifically, we define $\\mathcal{L}$ in (3) as the empirical loss regularized by $\\left\\|\\cdot\\right\\|_{m}^{2}$ and output $\\bar{f}=\\mathsf E\\mathsf{R M}(\\mathcal{L},\\mathcal{F})$ . We have the following result: ", "page_idx": 6}, {"type": "text", "text": "Theorem 3. Suppose that $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ is a convex function class and $\\ell:[-1,1]\\times[-1,1]\\to$ $[0,1]$ is convex and $\\lambda$ -Lipschitz in its first argument. Suppose that $Z_{1},\\dots,Z_{m}\\,\\sim\\,\\mu$ are independent and $\\mathcal{Q}\\,=\\,\\mathcal{N}(0,1)$ . Then there are $\\eta,\\gamma,m$ polynomial in problem parameters and given in Appendix C.6 such that, $i f$ ", "page_idx": 6}, {"type": "equation", "text": "$$\nn=\\mathsf{p o l y}\\left(\\log\\left(\\beta^{-1}\\right),\\log\\left(\\delta^{-1}\\right),\\lambda\\right)\\cdot(\\operatorname*{sup}_{m}\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F}))^{2}\\cdot\\varepsilon^{-1}\\cdot\\alpha^{-5}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "then the $\\widehat{f}$ returned by Algorithm $^3$ is $(\\varepsilon,\\delta)$ -differentially private. If $\\nu_{x}$ is $\\sigma$ -smooth with respect to $\\mu_{;}$ , then $\\widehat{f}$ is an $(\\alpha,\\beta)$ -learner with respect to $\\nu_{x}$ and $\\ell$ . Furthermore, $i f\\,\\mathcal{Q}=L a p(1)$ , and ", "page_idx": 6}, {"type": "equation", "text": "$$\nn=\\mathsf{p o l y}\\left(\\operatorname*{sup}_{m}\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F}),\\log\\left(\\beta^{-1}\\right),\\lambda\\right)\\cdot\\varepsilon^{-1}\\cdot\\alpha^{-6},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "then Algorithm 3 is $\\varepsilon$ -purely differentially private and an $(\\alpha,\\beta)$ -PAC learner for any $\\sigma$ -smooth $\\nu_{x}$ . ", "page_idx": 6}, {"type": "text", "text": "As in the case of Theorem 2, we can easily generalize Theorem 3 to apply to function classes $\\mathcal{F}$ where $\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})=\\omega(1)$ at the cost of worse polynomial dependence in the sample complexity. We again omit this case for the sake of simplicity. While the sample complexity of Algorithm 3 is a marked improvement over that of Algorithm 2, it remains a far cry from the desired $O\\left(\\alpha^{-2}\\right)$ rates of non-private learning that computationally inefficient private algorithms leveraging public data are able to achieve [Bassily et al., 2019]; we leave the interesting question of producing an oracle-efficient private algorithm with optimal sample complexity to future work. ", "page_idx": 6}, {"type": "text", "text": "Finally, we remark that even in the case where $\\mathcal{F}$ is not convex, Algorithm 3 can be applied to $\\operatorname{conv}({\\mathcal{F}})$ , the convex hull of $\\mathcal{F}$ , if we assume the learner has access to $\\mathsf{\\bar{E}R M^{\\prime}}$ , a stronger ERM oracle that can optimize over $\\operatorname{conv}({\\mathcal{F}})$ . In this case, Theorem 3 supercedes Theorem 2 as it is easy to see that $\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})=\\overline{{\\mathcal{G}}}_{m}(\\mathrm{conv}(\\mathcal{F}))$ and thus the sample complexity of Algorithm 3 is strictly better than that of Algorithm 2 and the pure differential privacy result applies. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4 Analysis Techniques ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we outline the proofs of our main results, with full details deferred to Appendix C. As is suggested by our template, the proof of the privacy part of Theorem 2 rests on two results: the first shows that if $\\mathcal{Q}$ is a standard Gaussian (resp. exponential) then stability of $\\bar{f}$ with respect to $\\|\\cdot\\|_{m}$ can be translated into differential privacy. The second shows that $\\bar{f}$ will be stable with respect to $\\|\\cdot\\|_{m}$ . Similarly, the proof that $\\widehat{f}$ is a good learner first shows that $\\bar{f}$ is a good learner and then that $\\widehat{f}$ and $\\bar{f}$ are close. We begin with the more technically novel parts and show that, under standard assu mptions, Algorithms 2 and 3 result in $\\bar{f}$ that are stable in $\\|\\cdot\\|_{m}$ . In our proof of Theorem 2, we provide an improved analysis of the Gaussian anti-concentration result from Block et al. [2022], which may be of independent interest. We prove the stability of Algorithm 3 using a technique common in online learning. We then show that stability in $\\|\\cdot\\|_{m}$ can be boosted to a differential privacy guarantee using the Gaussian and Laplace Mechanisms [Dwork et al., 2006]. Finally, we apply standard learning theoretic techniques to show that $\\widehat{f}$ is a good learner. ", "page_idx": 7}, {"type": "text", "text": "4.1 Stability Analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we explain how to prove that Algorithms 2 and 3 are stable with respect to $\\left\\|\\cdot\\right\\|_{m}$ . Our stability results further cement the connections between differential privacy and online learning noted in Abernethy et al. [2019] as both algorithms are primarily motivated by online learning techniques. We begin by describing the stability analysis of Algorithm 2. The key lemma underlying the stability of Algorithm 2 is an improved version of a Gaussian anti-concentration result from Block et al. [2022], which may be of independent interest. ", "page_idx": 7}, {"type": "text", "text": "Proposition 1. Let $\\mathcal{F}$ denote a subspace of the unit ball with respect to a norm $\\lVert\\cdot\\rVert$ induced by an inner product $\\langle\\cdot,\\cdot\\rangle$ and let $m$ $\\iota,m^{\\prime}:\\mathcal{F}\\rightarrow\\mathbb{R}$ be measurable functions such that $\\|m\\!-\\!\\bar{m}^{\\prime}\\|_{\\infty}\\leq\\tau.$ . If \u03c9 is a centred Gaussian process on $\\mathcal{F}$ with covariance kernel given by $\\langle\\cdot,\\cdot\\rangle$ , $\\Omega(f)=m(f)+\\eta\\cdot\\omega(f)$ , $\\bar{f}\\,=\\,\\mathrm{argmin}_{f\\in\\mathcal{F}}\\,\\Omega(\\bar{f})$ , and $\\Omega^{\\prime}$ and ${\\bar{f}}^{\\prime}$ are defined similarly, then for any $\\rho,\\tau>0,$ , it holds that $\\begin{array}{r}{\\mathbb{P}\\left(\\left|\\left|\\bar{f}-\\bar{f}^{\\prime}\\right|\\right|\\stackrel{}{>}\\rho\\right)\\stackrel{}{\\leq}\\frac{8\\tau}{\\rho^{4}\\kappa^{2}\\eta}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega(f)\\right]}\\end{array}$ , where $\\kappa^{2}=\\operatorname*{inf}_{f\\in\\mathcal{F}}\\mathbb{E}\\left[\\omega(f)^{2}\\right]$ . ", "page_idx": 7}, {"type": "text", "text": "The proof proceeds in a similar way to that of Lemma 33 from Block et al. [2022], but involves a tighter analysis in several steps in order to improve the bound. The intuition for the result is straightforward: if $\\bar{f}$ is the minimizer of the Gaussian process $\\Omega$ , then with reasonable probability, almost minimizers of $\\Omega$ (as measured by the tolerance $\\tau$ ) are within a radius $\\rho$ of $\\bar{f}$ as long as the Gaussian process is nontrivial in the sense that all indices $f$ have sufficiently high variance. Moreover, the quantitative control on the probability of this event depends in a natural way both on $\\tau$ and $\\rho$ as well as on the Gaussian process $\\omega$ : more complex spaces $\\mathcal{F}$ and lower variance processes lead to a worse anti-concentration guarantee. Finally, we note that Proposition 1 is an improvement of Lemma 33 from Block et al. [2022] in that the quantitative bound on the probability of anti-concentration is tighter by polynomial factors in $\\rho,\\eta$ , and $\\kappa$ . ", "page_idx": 7}, {"type": "text", "text": "Like essentially all anti-concentration results [Chernozhukov et al., 2015], Proposition 1 holds only with moderate probability in the sense that the guarantee is polynomial in the scale $\\rho$ ; this fact is in contradistinction to concentration inequalities which tend to hold with high probability exponential in the scale. This discrepancy is precisely what motivates the averaging in Line 7 of Algorithm 2. Indeed, we can use Proposition 1 to show that if ${\\bar{f}}_{j}$ is as in Line 6 of Algorithm 2 and $\\bar{f}_{j}^{\\prime}$ is defined analogously with respect to $\\mathcal{D}^{\\prime}$ , then with moderate probability $\\left|\\left|\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right|\\right|_{m}$ is small. Using Jensen\u2019s inequality and a standard chernoff bound, we can then boost this moderate probability guarantee into a high probability guarantee to show that if $J$ is sufficiently large, then $\\left|\\left|\\bar{f}-\\bar{f}^{\\prime}\\right|\\right|_{m}$ is small with high probability. We formalize this argument in the following lemma: ", "page_idx": 7}, {"type": "text", "text": "Lemma 1 (Stability of Algorithm 2). Suppose that $\\mathcal{F}\\,:\\,\\boldsymbol{\\mathcal{X}}\\,\\rightarrow\\,[-1,1]$ is a function class and $\\ell:[-1,\\underline{{{1}}}]^{\\times2}\\,\\to\\,[\\dot{0},1]$ is a bounded loss function. Suppose that $\\mathcal{D},\\mathcal{D}^{\\prime}$ are neighboring datasets and let $\\bar{f}$ be as in Line 5 of Algorithm 2 and ${\\bar{f}}^{\\prime}$ be defined analogously with respect to $\\mathcal{D}^{\\prime}$ . Then for any $\\rho,\\delta>0,$ , with probability at least $1-\\delta_{i}$ , over the Gaussian processes $\\boldsymbol{\\omega}^{(j)}$ , $\\left\\|{\\bar{f}}-{\\bar{f}}^{\\prime}\\right\\|_{m}\\leq$ $\\begin{array}{r}{\\frac{2}{(\\eta\\cdot n)^{1/3}\\kappa^{2/3}}\\cdot\\left(\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right]\\right)^{1/3}+\\sqrt{\\frac{\\log\\left(\\frac{1}{\\delta}\\right)}{J}}.}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "We note that the worse dependence on $\\eta$ in Lemma 1 as compared to Proposition 1 arises from integrating the tail bound to obtain the control on $\\left\\|\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right\\|_{m}$ in expectation necessary to apply Jensen\u2019s inequality; details can be found in Appendix C.1. ", "page_idx": 8}, {"type": "text", "text": "We now turn to the stability of Algorithm 3. The proof is based on a technique borrowed from online learning and the analysis of the Follow the Regularized Leader (FTRL) algorithm [Gordon, 1999, Cesa-Bianchi and Lugosi, 2006]. ", "page_idx": 8}, {"type": "text", "text": "Lemma 2 (Stability of Algorithm 3). Suppose that $\\ell$ is convex and $\\lambda$ -Lipschitz in its first argument. Let $\\mathcal{D},\\mathcal{D}^{\\prime}$ denote neighboring data sets and let $\\bar{f}$ denote the output of Line $^3$ in Algorithm 3 and ${\\bar{f}}^{\\prime}$ be the analogous output evaluated on D\u2032. If F is convex, then,  f\u00af \u2212f\u00af \u2032  m \u2264\u221a\u03b72\u00b7n. ", "page_idx": 8}, {"type": "text", "text": "The proof of Lemma 2 can be found in Appendix C.2 and rests on elementary properties of strongly convex functions. We note that relative to Lemma 1, the dependence on $\\eta$ in Lemma 2 is improved, which in turn leads to the better sample complexity exhibited in Theorem 3. With stability of Algorithms 2 and 3 thus established, we proceed to analyze the effect of the output perturbation. ", "page_idx": 8}, {"type": "text", "text": "4.2 Output Perturbation Analysis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now turn to the analysis of Algorithm 1. In order to boost a stability-in-norm guarantee into one for differential privacy while remaining a good learner, we require the output perturbation to be sufficiently small as to not not affect the learning guarantee of $\\bar{\\boldsymbol{f}}$ while at the same time being sufficiently large as to ensure privacy. We balance these two competing objectives by tuning the variance of the added noise. This part of the analysis is relatively standard in the differential privacy literature [Chaudhuri et al., 2011, Neel et al., 2019], with the bound on the size of the output perturbation following from standard tail bounds on Gaussian and Laplace random vectors. The privacy guarantees are similarly standard and summarized in the following lemma: ", "page_idx": 8}, {"type": "text", "text": "Lemma 3. Suppose $\\bar{f}\\;\\in\\;{\\mathcal F}$ is the output of an algorithm $A:\\;{\\mathcal{D}}\\;\\rightarrow\\;{\\mathcal{F}}$ that is $\\rho$ -stable with respect to $\\lVert\\cdot\\rVert_{m}$ , i.e., for any neighboring data set $\\mathcal{D}^{\\prime}$ , it holds that $\\|\\mathcal{A}(\\mathcal{D})-\\mathcal{A}(\\mathcal{D^{\\prime}})\\|_{m}\\;\\leq\\;\\rho.$ . Then applying Algorithm $^{\\,l}$ with $\\smash{\\ensuremath{\\mathcal Q}_{\\perp}}=\\ensuremath{\\mathcal N}(0,1)$ to $\\bar{f}$ results in an $(\\varepsilon,\\delta)$ -private algorithm if $\\begin{array}{r}{\\frac{m}{2\\gamma^{2}}\\left(1+\\gamma\\cdot\\sqrt{\\log\\left(\\frac{1}{\\delta}\\right)}\\right)\\rho\\leq\\varepsilon}\\end{array}$ . Similarly, if $\\mathcal{Q}=L a p(\\gamma)$ , then the algorithm is $\\varepsilon$ -purely private if $m^{3/2}/\\gamma\\cdot\\rho\\leq\\varepsilon$ . ", "page_idx": 8}, {"type": "text", "text": "This standard result is proved in Appendix C.3. Note that, perhaps counterintuitively, the privacy loss increases with the public data. This relationship occurs because the algorithm is implicitly discretizing the function class, where more public data leads to a finer discretization; though finer discretizations lead to higher accuracy, they also leads to more privacy loss. Furthermore, note that even were the whole marginal distribution known, the privacy-accuracy tradeoff is dictated by the number of labelled samples, not $m$ . ", "page_idx": 8}, {"type": "text", "text": "The balance between privacy and learning is quantified in the choices of $m$ and $\\gamma$ . If $\\gamma$ is too large, then $\\bar{f}$ will be private but a poor learner, whereas the opposite occurs if $\\gamma$ is too small. Similarly, if $m$ is too large then privacy is reduced whereas if $m$ is too small then $\\left\\|\\cdot\\right\\|_{m}$ is a poor approximation for \u2225\u00b7\u2225\u00b5. ", "page_idx": 8}, {"type": "text", "text": "4.3 Learning Guarantees and Concluding the Proof ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "By combining Lemma 1 (resp. Lemma 2) with Lemma 9, we can establish the privacy of Algorithm 2 (resp. Algorithm 3) as long as the tuning parameters $m,\\gamma,\\eta$ , and $J$ are chosen correctly. We now sketch the proof that these algorithms comprise good learners in the sense of Definition 2. We break our proof into three components, the first two of which are standard learning theoretic results. The first lemma says that if $m\\gg1$ , then $\\|\\cdot\\|_{m}$ is a good approximation for $\\left\\|\\cdot\\right\\|_{\\mu}$ : ", "page_idx": 8}, {"type": "text", "text": "Lemma 4. Let $\\mathcal{F}:\\mathcal{X}\\to[-1,1]$ be a bounded function class and let $Z_{1},\\dots,Z_{m}\\,\\sim\\,\\mu$ be independent samples. Then for any $\\beta>0$ it holds with probability at least $1-\\beta$ that for all $f\\,\\in\\,{\\mathcal{F}}$ , $\\begin{array}{r}{\\|f\\|_{\\mu}\\leq2\\cdot\\|f\\|_{m}+\\widetilde{O}\\left(\\frac{\\overline{{g}}_{m}(\\mathcal{F})+\\sqrt{\\log(1/\\beta)}}{\\sqrt{m}}\\right)\\!.}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "Lemma 4 is a standard bound from learning theory [Bousquet, 2002, Rakhlin et al., 2017] and is proved in Appendix C.7 for the sake of completeness. The second component is given by Lemma 13 in Appendix C.5, which amounts to a classical uniform deviations bound for the empirical process, ensuring that if $n\\gg1$ , then $L_{\\mathcal{D}}(f)\\approx L(f)$ for all $f\\in\\mathcal F$ . The final step is the following simple lemma, which ensures that if $\\eta$ is not too large, then $\\bar{L}_{\\mathcal{D}}(\\bar{f})\\approx L_{\\mathcal{D}}(f_{\\mathsf{E R M}})$ : ", "page_idx": 9}, {"type": "text", "text": "Lemma 5. Let $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ be a bounded function class and let $R:\\mathcal{F}\\rightarrow\\mathbb{R}$ be an arbitrary, possibly random, regularizer. Let $f_{\\mathsf{E R M}}\\in\\operatorname{argmin}_{f\\in{\\mathcal{F}}}L_{\\mathcal{D}}(f)$ and $\\bar{f}\\in\\mathrm{argmin}_{f\\in\\mathcal{F}}\\,L_{\\mathcal{D}}(f)+R(f)$ . Then, $\\begin{array}{r}{L_{\\mathcal{D}}(\\bar{f})\\leq L_{\\mathcal{D}}(f_{\\mathsf{E R M}})+\\operatorname*{sup}_{f,f^{\\prime}\\in\\mathcal{F}}R(f)-\\dot{R}(f^{\\prime})}\\end{array}$ . ", "page_idx": 9}, {"type": "text", "text": "Lemma 5 is a simple computation proved in Appendix C.5. Letting $R(f)$ be either $\\eta\\cdot\\omega_{m}^{(j)}(f)$ in Algorithm 2 or $\\eta\\cdot\\Vert f\\Vert_{m}^{2}$ in Algorithm 3 demonstrates that if $\\eta$ is not too large, then $\\bar{f}$ performs similarly to $f_{{\\mathsf{E R M}}}$ . To prove that Algorithms 2 and 3 produce good learning algorithms then, it suffices to combine these three components, observing first that $\\breve{L}(\\bar{f})$ is close to optimal if $n\\gg1$ and $\\eta$ is not too large, second that $\\|\\bar{f}-\\widehat{f}\\|_{\\mu}\\ll1$ if $m\\gg1$ and $\\gamma$ is sufficently small, and third that $|L(\\widehat{f})-L(\\bar{f})|\\,\\lesssim\\,\\|\\bar{f}-\\widehat{f}\\|_{\\mu}$ if $\\nu_{x}$ is $\\sigma$ -smooth with respect to $\\mu$ and $\\ell$ is $\\lambda$ -Lipschitz in its first arg ument. Combining these results concludes the proofs of Theorems 2 and 3. A detailed and rigorous argument for both proofs is presented in Appendix C. As a final remark, we note that in the case of Algorithm 2, convexity of $\\ell$ in the first argument is irrelevant to the privacy guarantee despite being necessary for learning. Indeed, for $\\bar{f}$ returned by Line 5 in Algorithm 2 to be proven a good learner, we apply Jensen\u2019s and the above argument that ensures that ${\\bar{f}}_{j}$ is a good learner. Interestingly, on the other hand, convexity in $\\ell$ is irrelevant to the learning guarantee of Algorithm 3 while it is essential to the privacy guarantee. Further understanding the role that such structural assumptions play in allowing privacy is an interesting direction for future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "AB acknowledges support from the National Science Foundation Graduate Research Fellowship under Grant No.1122374 as well as the Simons Foundation and the National Science Foundation through awards DMS-2031883 and DMS-1953181. MB acknowledges support from the National Science Foundation through award NSF CNS-2046425 and from a Sloan Research Fellowship. RD acknowledges support from the National Science Foundation through award NSF CNS-2046425. AS acknowledges support from the Apple $\\mathrm{AI+ML}$ fellowship. AB also would like to thank Satyen Kale and Claudio Gentile for helpful discussions. Z.S.W. was in part supported by NSF Awards #1763786 and #2339775. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Jacob D Abernethy, Young Hun Jung, Chansoo Lee, Audra McMillan, and Ambuj Tewari. Online learning via the differential privacy lens. Advances in Neural Information Processing Systems, 32, 2019. ", "page_idx": 9}, {"type": "text", "text": "Noga Alon, Roi Livni, Maryanthe Malliaris, and Shay Moran. Private PAC learning implies finite littlestone dimension. In Moses Charikar and Edith Cohen, editors, Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix, AZ, USA, June 23-26, 2019, pages 852\u2013860. ACM, 2019. doi: 10.1145/3313276.3316312. URL https://doi.org/10.1145/3313276.3316312. ", "page_idx": 9}, {"type": "text", "text": "Ehsan Amid, Arun Ganesh, Rajiv Mathews, Swaroop Ramaswamy, Shuang Song, Thomas Steinke, Vinith M Suriyakumar, Om Thakkar, and Abhradeep Thakurta. Public data-assisted mirror descent for private model training. In International Conference on Machine Learning, pages 517\u2013 535. PMLR, 2022. ", "page_idx": 9}, {"type": "text", "text": "Maria-Florina F Balcan and Vitaly Feldman. Statistical active learning algorithms. Advances in neural information processing systems, 26, 2013. ", "page_idx": 9}, {"type": "text", "text": "Peter L Bartlett, Philip M Long, and Robert C Williamson. Fat-shattering and the learnability of realvalued functions. In Proceedings of the seventh annual conference on Computational learning theory, pages 299\u2013310, 1994. ", "page_idx": 9}, {"type": "text", "text": "Raef Bassily, Om Thakkar, and Abhradeep Guha Thakurta. Model-agnostic private learning. Advances in Neural Information Processing Systems, 31, 2018. ", "page_idx": 10}, {"type": "text", "text": "Raef Bassily, Shay Moran, and Noga Alon. Limits of private learning with access to public data. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d\u2019Alch\u00e9-Buc, Emily B. Fox, and Roman Garnett, editors, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8- 14, 2019, Vancouver, BC, Canada, pages 10342\u201310352, 2019. URL https://proceedings. neurips.cc/paper/2019/hash/9a6a1aaafe73c572b7374828b03a1881-Abstract.html.   \nRaef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan R. Ullman, and Zhiwei Steven Wu. Private query release assisted by public data. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 695\u2013703. PMLR, 2020a. URL http://proceedings.mlr.press/v119/bassily20a.html.   \nRaef Bassily, Shay Moran, and Anupama Nandi. Learning from mixtures of private and public populations. Advances in Neural Information Processing Systems, 33:2947\u20132957, 2020b.   \nRaef Bassily, Mehryar Mohri, and Ananda Theertha Suresh. Private domain adaptation from a public source. arXiv preprint arXiv:2208.06135, 2022.   \nRaef Bassily, Mehryar Mohri, and Ananda Theertha Suresh. Principled approaches for private adaptation from a public source. In International Conference on Artificial Intelligence and Statistics, pages 8405\u20138432. PMLR, 2023.   \nAmos Beimel, Kobbi Nissim, and Uri Stemmer. Learning privately with labeled and unlabeled examples. In Proceedings of the twenty-sixth annual ACM-SIAM symposium on Discrete algorithms, pages 461\u2013477. SIAM, 2014.   \nShai Ben-David, Alex Bie, Cl\u00e9ment L Canonne, Gautam Kamath, and Vikrant Singhal. Private distribution learning with public data: The view from sample compression. arXiv preprint arXiv:2308.06239, 2023.   \nAlex Bie, Gautam Kamath, and Vikrant Singhal. Private estimation with public data. Advances in Neural Information Processing Systems, 35:18653\u201318666, 2022.   \nAdam Block and Yury Polyanskiy. The sample complexity of approximate rejection sampling with applications to smoothed online learning. In Gergely Neu and Lorenzo Rosasco, editors, Proceedings of Thirty Sixth Conference on Learning Theory, volume 195 of Proceedings of Machine Learning Research, pages 228\u2013273. PMLR, 12\u201315 Jul 2023. URL https: //proceedings.mlr.press/v195/block23a.html.   \nAdam Block and Max Simchowitz. Efficient and near-optimal smoothed online learning for generalized linear functions. Advances in Neural Information Processing Systems, 35:7477\u20137489, 2022.   \nAdam Block, Yuval Dagan, Noah Golowich, and Alexander Rakhlin. Smoothed online learning is as easy as statistical learning. In Conference on Learning Theory, pages 1716\u20131786. PMLR, 2022.   \nAdam Block, Max Simchowitz, and Alexander Rakhlin. Oracle-efficient smoothed online learning for piecewise continuous decision making. In Gergely Neu and Lorenzo Rosasco, editors, Proceedings of Thirty Sixth Conference on Learning Theory, volume 195 of Proceedings of Machine Learning Research, pages 1618\u20131665. PMLR, 12\u201315 Jul 2023a. URL https: //proceedings.mlr.press/v195/block23b.html.   \nAdam Block, Max Simchowitz, and Russ Tedrake. Smoothed online learning for prediction in piecewise affine systems. In Advances in Neural Information Processing Systems. Curran Associates, Inc., 2023b. URL https://openreview.net/pdf?id=Izt7rDD7jN.   \nAvrim Blum and Ronald Rivest. Training a 3-node neural network is np-complete. Advances in neural information processing systems, 1, 1988.   \nOlivier Bousquet. Concentration inequalities and empirical processes theory applied to the analysis of learning algorithms. PhD thesis, \u00c9cole Polytechnique: Department of Applied Mathematics Paris, France, 2002.   \nMark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and learning of threshold functions. In 2015 IEEE 56th Annual Symposium on Foundations of Computer Science, pages 634\u2013649. IEEE, 2015.   \nMark Bun, Roi Livni, and Shay Moran. An equivalence between private classification and online prediction. In 2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS), pages 389\u2013402. IEEE, 2020.   \nNicolo Cesa-Bianchi and G\u00e1bor Lugosi. Prediction, learning, and games. Cambridge university press, 2006.   \nNicol\u00f2 Cesa-Bianchi, Tommaso R Cesari, Roberto Colomboni, Federico Fusco, and Stefano Leonardi. Repeated bilateral trade against a smoothed adversary. In The Thirty Sixth Annual Conference on Learning Theory, pages 1095\u20131130. PMLR, 2023.   \nKamalika Chaudhuri, Claire Monteleoni, and Anand D Sarwate. Differentially private empirical risk minimization. Journal of Machine Learning Research, 12(3), 2011.   \nVictor Chernozhukov, Denis Chetverikov, and Kengo Kato. Comparison and anti-concentration bounds for maxima of gaussian random vectors. Probability Theory and Related Fields, 162: 47\u201370, 2015.   \nMiroslav Dud\u00edk, Nika Haghtalab, Haipeng Luo, Robert E Schapire, Vasilis Syrgkanis, and Jennifer Wortman Vaughan. Oracle-efficient online learning and auction design. Journal of the ACM (JACM), 67(5):1\u201357, 2020.   \nRichard Mansfield Dudley. The speed of mean glivenko-cantelli convergence. The Annals of Mathematical Statistics, 40(1):40\u201350, 1969.   \nNaveen Durvasula, Nika Haghtalab, and Manolis Zampetakis. Smoothed analysis of online nonparametric auctions. In Proceedings of the 24th ACM Conference on Economics and Computation, pages 540\u2013560, 2023.   \nCynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam D. Smith. Calibrating noise to sensitivity in private data analysis. In Shai Halevi and Tal Rabin, editors, Theory of Cryptography, Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006, Proceedings, volume 3876 of Lecture Notes in Computer Science, pages 265\u2013284. Springer, 2006. doi: 10.1007/11681878\\_14. URL https://doi.org/10.1007/11681878_14.   \nCynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014.   \nDylan Foster and Alexander Rakhlin. Beyond ucb: Optimal and efficient contextual bandits with regression oracles. In International Conference on Machine Learning, pages 3199\u20133210. PMLR, 2020.   \nDylan J Foster, Sham M Kakade, Jian Qian, and Alexander Rakhlin. The statistical complexity of interactive decision making. arXiv preprint arXiv:2112.13487, 2021.   \nMarco Gaboardi, Emilio Jes\u00fas Gallego Arias, Justin Hsu, Aaron Roth, and Zhiwei Steven Wu. Dual query: Practical private query release for high dimensional data. In International Conference on Machine Learning, pages 1170\u20131178. PMLR, 2014.   \nBadih Ghazi, Noah Golowich, Ravi Kumar, and Pasin Manurangsi. Sample-efficient proper pac learning with approximate differential privacy. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 183\u2013196, 2021.   \nAditya Golatkar, Alessandro Achille, Yu-Xiang Wang, Aaron Roth, Michael Kearns, and Stefano Soatto. Mixed differential privacy in computer vision. In CVPR 2022, 2022. URL https://www.amazon.science/publications/ mixed-differential-privacy-in-computer-vision.   \nSally A Goldman, Michael J Kearns, and Robert E Schapire. Exact identification of read-once formulas using fixed points of amplification functions. SIAM Journal on Computing, 22(4):705\u2013 726, 1993.   \nGeoffrey J Gordon. Regret bounds for prediction problems. In Proceedings of the twelfth annual conference on Computational learning theory, pages 29\u201340, 1999.   \nNika Haghtalab, Tim Roughgarden, and Abhishek Shetty. Smoothed analysis of online and differentially private learning. Advances in Neural Information Processing Systems, 33:9203\u20139215, 2020.   \nNika Haghtalab, Yanjun Han, Abhishek Shetty, and Kunhe Yang. Oracle-efficient online learning for smoothed adversaries. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 4072\u20134084. Curran Associates, Inc., 2022a. URL https://proceedings.neurips.cc/paper_files/ paper/2022/file/1a04df6a405210aab4986994b873db9b-Paper-Conference.pdf.   \nNika Haghtalab, Tim Roughgarden, and Abhishek Shetty. Smoothed analysis with adaptive adversaries. In 2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS), pages 942\u2013953. IEEE, 2022b.   \nElad Hazan and Tomer Koren. The computational power of optimization in online learning. In Proceedings of the forty-eighth annual ACM symposium on Theory of Computing, pages 128\u2013 141, 2016.   \nMax Hopkins, Daniel M. Kane, Shachar Lovett, and Gaurav Mahajan. Realizable learning is all you need. TheoretiCS, 3, 2024.   \nPeter Kairouz, Monica Ribero Diaz, Keith Rush, and Abhradeep Thakurta. (Nearly) dimension independent private erm with adagrad rates via publicly estimated subspaces. In Conference on Learning Theory, pages 2717\u20132746. PMLR, 2021.   \nAdam Kalai and Santosh Vempala. Efficient algorithms for online decision problems. Journal of Computer and System Sciences, 71(3):291\u2013307, 2005.   \nJeankyung Kim and David Pollard. Cube root asymptotics. The Annals of Statistics, pages 191\u2013219, 1990.   \nAlexander Kozachinskiy and Tomasz Steifer. Simple online learning with consistency oracle. arXiv preprint arXiv:2308.08055, 2023.   \nJean-Fran\u00e7ois Le Gall. Brownian motion, martingales, and stochastic calculus. Springer, 2016.   \nTerrance Liu, Giuseppe Vietri, Thomas Steinke, Jonathan Ullman, and Steven Wu. Leveraging public data for practical private query release. In International Conference on Machine Learning, pages 6968\u20136977. PMLR, 2021a.   \nTerrance Liu, Giuseppe Vietri, and Steven Wu. Iterative methods for private synthetic data: Unifying framework and new methods. In Marc\u2019Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 690\u2013702, 2021b. URL https://proceedings.neurips. cc/paper/2021/hash/0678c572b0d5597d2d4a6b5bd135754c-Abstract.html.   \nAndrew Lowy, Zeman Li, Tianjian Huang, and Meisam Razaviyayn. Optimal differentially private learning with public data. arXiv preprint arXiv:2306.15056, 2023.   \nFrank McSherry and Kunal Talwar. Mechanism design via differential privacy. In 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2007), October 20-23, 2007, Providence, RI, USA, Proceedings, pages 94\u2013103. IEEE Computer Society, 2007. doi: 10.1109/FOCS.2007. 41. URL https://doi.org/10.1109/FOCS.2007.41.   \nShahar Mendelson and Roman Vershynin. Entropy and the combinatorial dimension. Inventiones mathematicae, 152(1):37\u201355, 2003.   \nZakaria Mhammedi, Adam Block, Dylan J Foster, and Alexander Rakhlin. Efficient model-free exploration in low-rank mdps. arXiv preprint arXiv:2307.03997, 2023a.   \nZakaria Mhammedi, Dylan J Foster, and Alexander Rakhlin. Representation learning with multistep inverse kinematics: An efficient and optimal approach to rich-observation rl. arXiv preprint arXiv:2304.05889, 2023b.   \nSeth Neel, Aaron Roth, Giuseppe Vietri, and Zhiwei Steven Wu. Oracle efficient private nonconvex optimization. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 7243\u20137252. PMLR, 2020. URL http://proceedings.mlr.press/v119/ neel20a.html.   \nSeth V Neel, Aaron L Roth, and Zhiwei Steven Wu. How to use heuristics for differential privacy. In 2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS), pages 72\u201393. IEEE, 2019.   \nAleksandar Nikolov, Kunal Talwar, and Li Zhang. The geometry of differential privacy: the sparse and approximate cases. In Proceedings of the forty-fifth annual ACM symposium on Theory of computing, pages 351\u2013360, 2013.   \nNicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and \u00dalfar Erlingsson. Scalable private learning with PATE. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018. URL https://openreview.net/forum?id=rkZB1XbRZ.   \nYury Polyanskiy and Yihong Wu. Information Theory: From Coding to Learning. Cambridge University Press, ${2022+}$ .   \nAlexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: Stochastic, constrained, and smoothed adversaries. Advances in neural information processing systems, 24, 2011.   \nAlexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning via sequential complexities. J. Mach. Learn. Res., 16(1):155\u2013186, 2015.   \nAlexander Rakhlin, Karthik Sridharan, and Alexandre B Tsybakov. Empirical entropy, minimax regret and minimax risk. Bernoulli, pages 789\u2013824, 2017.   \nRalph Tyrell Rockafellar. Convex Analysis:(PMS-28). Princeton university press, 2015.   \nMark Rudelson and Roman Vershynin. Combinatorics of random processes and sections of convex bodies. Annals of Mathematics, pages 603\u2013648, 2006.   \nDaniel A Spielman and Shang-Hua Teng. Smoothed analysis of algorithms: Why the simplex algorithm usually takes polynomial time. Journal of the ACM (JACM), 51(3):385\u2013463, 2004.   \nNathan Srebro, Karthik Sridharan, and Ambuj Tewari. Smoothness, low noise and fast rates. Advances in neural information processing systems, 23, 2010.   \nVasilis Syrgkanis, Akshay Krishnamurthy, and Robert Schapire. Efficient algorithms for adversarial contextual learning. In International Conference on Machine Learning, pages 2159\u20132168. PMLR, 2016.   \nLeslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134\u20131142, 1984.   \nRamon Van Handel. Probability in high dimension. Lecture Notes (Princeton University), 2014.   \nGiuseppe Vietri, Grace Tian, Mark Bun, Thomas Steinke, and Steven Wu. New oracle-efficient algorithms for private synthetic data release. In International Conference on Machine Learning, pages 9765\u20139774. PMLR, 2020.   \nMartin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cambridge university press, 2019. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin A Inan, Gautam Kamath, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, et al. Differentially private fine-tuning of language models. In International Conference on Learning Representations (ICLR), 2022. ", "page_idx": 14}, {"type": "text", "text": "Yingxue Zhou, Steven Wu, and Arindam Banerjee. Bypassing the ambient dimension: Private SGD with gradient subspace identification. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id $\\equiv$ 7dpmlkBuJFC. ", "page_idx": 14}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "1 Introduction 1.1 Related Work 3 ", "page_idx": 14}, {"type": "text", "text": "2 Preliminaries 3 ", "page_idx": 14}, {"type": "text", "text": "3 Algorithms for Differentially Private Learning 5 ", "page_idx": 14}, {"type": "text", "text": "Analysis Techniques 8   \n4.1 Stability Analysis 8   \n4.2 Output Perturbation Analysis 9   \n4.3 Learning Guarantees and Concluding the Proof 9   \nA Differentially Private Classification 15   \nA.1 Privacy Analysis of Algorithm 4 16   \nA.2 Concluding the Proof of Theorem 4 17 ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "B Gaussian Anti-Concentration and Proof of Lemma 1 17 ", "page_idx": 14}, {"type": "text", "text": "Analysis of Algorithms 2 and 3 21   \nC.1 Stability of Algorithm 2 and Proof of Lemma 1 21   \nC.2 Stability of Algorithm 3 and Proof of Lemma 2 22   \nC.3 Boosting Stability to Differential Privacy: Proofs from Section 4.2 23   \nC.4 Concluding the Proofs of Differential Privacy 24   \nC.5 PAC guarantees for Algorithms 2 and 3 25   \nC.6 Concluding the Proofs of Theorems 2 and 3 28   \nC.7 Proof of Lemma 12 29   \nD Classification and Analysis of RRSPM 31   \nD.1 Universal Identification Set based Algorithm 31   \nD.2 Privacy Analysis 31   \nD.3 Accuracy Analysis 35 ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Differentially Private Classification ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In the previous section, we presented a private algorithm for general, real-valued loss functions. Here, we turn to the special case of classification, where we provide an algorithm with improved rates. Formally, binary classification is a special case of Definition 2, where ${\\mathcal{F}}:{\\mathcal{X}}\\rightarrow\\{0,1\\}$ and $\\ell$ is the indicator loss. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Much like Algorithms 2 and 3, our approach to classification in Algorithm 4 relies on minimizing a perturbed empirical loss over $\\mathcal{F}$ and projecting the output $\\widetilde{f}$ onto the public data. Unlike in these earlier algorithms, which require a further perturbation of the output in order to boost stability into differential privacy, in the special case of classification we are able to circumvent this second perturbation and return any $\\widehat{f}$ that agrees with $\\widetilde{f}$ on the public data. This is accomplished by carefully choosing the initial perturbation to the ERM objective (see (4)) so that the predictions of $\\widetilde{f}$ on the public data satisfy differential privacy without ensuring some form of stability in norm. As a result, our improved rates then follow from lack of a second perturbation. We present the following guarantee for our classification algorithm, whose pseudo-code can be found in Algorithm 4. ", "page_idx": 15}, {"type": "text", "text": "Algorithm 4: Rounded Report Separator Perturbed Minimum Algorithm (RRSPM) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Input ERM oracle ERM, dataset $\\overline{{\\ensuremath{{D}}}}=\\{(X_{i},Y_{i})\\mid1\\leq i\\leq n\\}$ , hypothesis class $\\mathcal{F}$ , smoothness parameter $\\sigma$ , loss function $\\ell:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\{0,1\\}$ , arbitrary $\\mathcal{Q}\\in\\Delta(\\mathbb{R})$ .   \nDraw $\\tilde{\\mathcal{D}}=(\\tilde{\\mathcal{D}}_{x},\\tilde{\\mathcal{D}}_{y})$ where $\\tilde{D}_{x}=\\{Z_{1},\\ldots,Z_{m}\\}$ and $\\tilde{D}_{y}=\\{\\tilde{Y}_{1},\\ldots,\\tilde{Y}_{m}\\}$ such that $Z_{i}\\sim\\mu$ and $\\tilde{Y}_{i}\\sim\\mathrm{Uni}(\\{0,1\\})$ , for all $i\\in[m]$ .   \nDraw weights $\\dot{\\boldsymbol{\\xi}}=\\dot{\\{\\xi_{1},\\dots,\\xi_{m}\\}}$ such that $\\xi_{i}\\sim\\mathrm{Lap}(2m/\\varepsilon)$ .   \nDefine $\\mathcal{L}_{\\xi,\\mathcal{D},\\tilde{D}}:\\mathcal{F}\\rightarrow\\mathbb{R}$ such that   \n$\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{\\mathcal{D}}}(\\boldsymbol{f})=\\sum_{i=1}^{n}\\ell(\\boldsymbol{f}(\\boldsymbol{X}_{i}),\\boldsymbol{Y}_{i})+\\sum_{i=1}^{m}\\xi_{i}\\cdot\\ell(\\boldsymbol{f}(\\boldsymbol{Z}_{i}),\\tilde{\\boldsymbol{Y}}_{i}).$ (4) Get $\\tilde{f}=\\mathsf{E R M}(\\mathcal{F},\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{D}})$ .   \nOutput $\\hat{f}=\\mathsf{P e r t u r b}(\\tilde{f},\\mathcal{Q},\\gamma=0,\\tilde{D}_{x})$ $\\triangleright$ By running Algorithm 1 ", "page_idx": 15}, {"type": "text", "text": "Theorem 4. Suppose that $\\mathcal{F}:\\mathcal{X}\\rightarrow\\mathcal{Y}$ is a function class of VC dimension $d$ and $\\ell:\\mathcal{V}\\!\\times\\!\\mathcal{V}\\!\\to\\{0,1\\}$ is the indicator loss. Suppose that $Z_{1},\\ldots,Z_{m}\\sim\\mu$ and $\\xi_{1},\\ldots,\\xi_{m}\\sim\\mathrm{Lap}(2m/\\varepsilon)$ are independent. Then there is a choice of m polynomial in the problem parameters such that $i f$ ", "page_idx": 15}, {"type": "equation", "text": "$$\nn=\\tilde{\\Omega}(d^{2}\\varepsilon^{-1}\\alpha^{-5}\\log(\\beta^{-1})),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "then the $\\hat{f}$ returned by Algorithm $^{4}$ is $\\varepsilon$ -pure differentially private. If $\\nu_{x}$ is $\\sigma$ -smooth with respect to $\\mu$ , then $\\hat{f}$ is an $(\\alpha,\\beta)$ -learner with respect to $\\nu_{x}$ and $\\ell$ . Furthermore, for some $C>0$ , $i f\\xi_{1},\\ldots,\\xi_{m}\\sim$ ${\\mathcal{N}}(0,C{\\sqrt{m\\log(1/\\delta)}}/\\varepsilon)$ then there is a choice of m polynomial in the problem parameters such that if ", "page_idx": 15}, {"type": "equation", "text": "$$\nn=\\tilde{\\Omega}(d^{2}\\varepsilon^{-1}\\alpha^{-4}\\log^{1/2}(1/\\delta)\\log(\\beta^{-1})),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "then the $\\hat{f}$ returned by Algorithm $^{4}$ with Gaussian perturbations is $(\\varepsilon,\\delta)$ -differentially private and is an $(\\alpha,\\beta)$ -PAC learner with respect to any $\\sigma$ -smooth $\\nu_{x}$ . ", "page_idx": 15}, {"type": "text", "text": "Remark 1. Note that the sample complexity we get in the above theorems is in the general, agnostic setting. In the realizable setting, where some $f^{\\star}\\,\\in\\,{\\mathcal{F}}$ perfectly predicts the $Y$ from the $X$ , we get a sample complexity of $\\bar{n}\\,\\,\\bar{=}\\,\\,\\tilde{\\Omega}(d^{2}\\varepsilon^{-1}\\alpha^{-3}\\log(\\beta^{-1}))$ for $\\varepsilon$ -pure differential privacy and $n=$ $\\tilde{\\Omega}(d^{2}\\varepsilon^{-1}\\alpha^{-2.5}\\log^{1/2}(1/\\delta)\\log(\\beta^{-1}))$ for $(\\varepsilon,\\delta)$ -differential privacy. ", "page_idx": 15}, {"type": "text", "text": "We emphasize that Theorem 4 attains the improved $O(\\alpha^{-5})$ sample complexity (even $O(\\alpha^{-4}$ for approximate differential privacy)), which is significantly better than the $O\\bar{(\\alpha^{-14})}$ from Theorem 2. While this is a major improvement, it still falls short of the desired $O(\\alpha^{-2})$ statistical rates achievable by inefficient algorithms from [Bassily et al., 2019]. We leave the interesting question of whether improved sample complexity is possible to future work. We now briefly sketch the proof of Theorem 4. ", "page_idx": 15}, {"type": "text", "text": "A.1 Privacy Analysis of Algorithm 4 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "While the privacy of Algorithms 2 and 3 is proven in two steps, by first demonstrating stability and then leveraging the output perturbation to ensure privacy, the privacy of Algorithm 4 is proven directly. Our approach is motivated by techniques from Neel et al. [2019], which adapt the earlier notion of separator sets from Goldman et al. [1993], Syrgkanis et al. [2016], Dud\u00edk et al. [2020] to the setting of differential privacy. Unlike those works, however, we do not require the strong assumption that $\\mathcal{F}$ has a small separator set and our results hold for general VC function classes. The main technical result that ensures privacy of Algorithm 4 demonstrates that the projection $\\mathcal{F}$ to the public data set $\\tilde{\\mathcal{D}}_{x}$ is private with respect to $\\mathcal{D}$ , where we let $\\mathcal{F}\\vert_{\\tilde{\\mathcal{D}}_{x}}=\\{(f(Z_{i}))_{1\\leq i\\leq m}\\vert f\\in\\mathcal{F}\\}$ . We have the following privacy guarantee for $\\widetilde{f}(\\tilde{D}_{x})\\in\\mathcal{F}|_{\\tilde{D}_{x}}$ : ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "Lemma 6. (Privacy over Projection) Let $\\mathcal{D},\\mathcal{D}^{\\prime}$ be arbitrary datasets containing n points each. Let $\\tilde{\\mathcal{D}}_{x}$ be a set of m points $Z_{1},\\ldots,Z_{m}\\,\\in\\,{\\mathcal{X}}$ . Let $\\tilde{Y}_{1},\\hdots,\\tilde{Y}_{m}\\,\\in\\,\\{0,1\\}$ be the set of corresponding labels. Then for all measurable $\\mathcal{H}\\subseteq\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}},\\mathcal{L}_{\\xi,\\mathcal{D},\\tilde{D}})\\in\\mathcal{H})\\le e^{\\varepsilon}\\cdot\\mathbb{P}(\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}},\\mathcal{L}_{\\xi,\\mathcal{D}^{\\prime},\\tilde{D}})\\in\\mathcal{H}),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathcal{L}_{\\boldsymbol{\\xi},\\mathcal{D},\\tilde{D}}$ is defined as in (4). ", "page_idx": 16}, {"type": "text", "text": "With the above lemma in hand, the privacy of Algorithm 4 follows immediately from the postprocessing property of differential privacy. We provide a full proof of Lemma 6 in Appendix $\\mathrm{D}$ and now turn to the accuracy guarantee. ", "page_idx": 16}, {"type": "text", "text": "A.2 Concluding the Proof of Theorem 4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proving that Algorithm 4 is an $(\\alpha,\\beta)$ -learner whenever $\\nu_{x}$ is $\\sigma$ -smooth with respect to $\\mu$ is similar to the approach taken in Section 4.3, with the critical difference that in the absence of the second perturbation, we are able to achieve a stronger guarantee on the difference between $\\widetilde{f}$ and $\\widehat{f}$ . Indeed, much as in the previous analysis, we observe that as $m$ increases, the suboptimality of the intermediate $\\widetilde{f}$ is driven up, while the difference between $\\widetilde{f}$ and $\\widehat{f}$ is driven down, thereby requiring a careful b alance; here, however, we do not also need to  accou nt for the balancing of the variance $\\gamma$ . We provide a full proof of the accuracy guarantee in Appendix D. ", "page_idx": 16}, {"type": "text", "text": "B Gaussian Anti-Concentration and Proof of Lemma 1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section we present and prove a more general version of Proposition 1. We begin by defining a Gaussian process and then state and prove the result. We then show how Proposition 1 follows as an immediate corollary. To begin, we recall the formal definition of a Gaussian process. ", "page_idx": 16}, {"type": "text", "text": "Definition 7. Let $T$ be an index set and $m\\;:\\;T\\;\\rightarrow\\;\\mathbb{R}$ be a function. Let $K\\ :\\ T\\times T\\ \\rightarrow\\ \\mathbb{R}$ be a covariance kernel in the sense that for any t1, . . . , tn \u2208 T, the matrix (K(ti, tj))i,j\u2208[n] is positive semi-definite. We say that $\\omega:T\\rightarrow\\mathbb{R}$ is a Gaussian process with mean function $m$ and covariance kernel $K$ if for any $t_{1},\\ldots,t_{n}\\in T$ , the random vector $\\left(\\omega(t_{i})\\right)_{i\\in[n]}$ is Gaussian with mean $(m(t_{i}))_{i\\in[n]}$ and covariance matrix $(K(t_{i},t_{j}))_{i,j\\in[n]}$ . We say that $\\omega$ is a centered Gaussian process if $m$ is identically zero. ", "page_idx": 16}, {"type": "text", "text": "Note that by Le Gall [2016, Theorem 1.11] such a process always exists given $m,K$ . Furthermore, we note that $K$ induces a semi-metric $d$ on $T$ by letting $d(t,t^{\\prime})^{2}=\\mathbb{E}\\left[\\bar{(\\omega}(t)-\\dot{\\omega}(t^{\\prime}))^{2}\\right]$ . We now prove the following result, which is a tighter version of Block et al. [2022, Lemma 33]. ", "page_idx": 16}, {"type": "text", "text": "Theorem 5 (Gaussian Anti-concentration). Let $T$ be a set, $m:T\\rightarrow\\mathbb{R}$ be a mean function and $K:T\\times T\\rightarrow\\mathbb{R}$ be a covariance kernel (in the sense of being positive definite). Let $d$ denote the metric induced by $K$ and suppose that m is continuous with respect to $d,$ , and the metric space $(T,d)$ is separable and compact. Let $\\omega$ denote a Gaussian process on $T$ with covariance $K$ and for $\\eta>0$ , let ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Omega(t)=m(t)+\\eta\\cdot\\omega(t)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "be an offset Gaussian process. We further suppose that $\\omega$ is taken to be a version with almost surely continuous paths $t\\mapsto\\omega(t)$ and that $0<\\kappa\\leq K(t,t)\\leq1$ for all $t\\in T$ . Let ", "page_idx": 16}, {"type": "equation", "text": "$$\nt^{\\star}=\\operatorname*{argmin}_{t\\in T}\\Omega(t),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{E}(\\rho,\\tau)=\\left\\{t h e r e\\;e x i s t s\\;s\\in T\\;s u c h\\;t h a t\\;\\frac{K(s,t^{\\star})}{K(t^{\\star},t^{\\star})}\\leq1-\\rho^{2}\\;a n d\\;\\Omega(s)\\leq\\Omega(t^{\\star})+\\tau\\right\\},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "for $\\rho,\\tau>0$ . The following holds: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\mathcal{E}(\\rho,\\tau)\\right)\\leq\\frac{\\tau}{\\rho^{2}\\eta\\kappa^{2}}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{t\\in T}\\omega(t)\\right].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that $\\frac{K(s,t)}{K(t,t)}$ is a measure of how close $s$ and $t$ are to each other; indeed, in the special case where $\\kappa=1$ this is precisely the correlation and thus $s$ and $t$ are more closely related the closer this quantity is to 1. Thus the event $\\mathcal{E}(\\rho,\\tau)$ can be interpreted to mean that there exists some point $s$ far from $t^{\\star}$ (as governed by $\\rho$ ) such that $\\Omega(s)$ is almost minimal (as governed by $\\tau$ ); in other words, Theorem 5 puts an upper bound on the probability that almost-minimizers of a Gaussian process lie far from the true minimizer. We now prove Theorem 5. ", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem 5. Note that by compactness of $T$ and almost sure continuity of $\\Omega$ , a minimizer of $\\Omega$ exists almost surely; furthermore, by [Kim and Pollard, 1990, Lemma 2.6], $t^{\\star}$ is almost surely unique. As $T$ is separable and $\\Omega$ has almost surely continuous sample paths, it suffices to replace $T$ with a countable dense subset. We will hereafter suppose without loss of generality that $T$ is countable. For each $t\\in T$ , define the set ", "page_idx": 17}, {"type": "equation", "text": "$$\nA(t)=\\left\\{s\\in T\\bigg\\vert\\frac{K(s,t)}{K(t,t)}\\leq1-\\rho^{2}\\;\\mathrm{and}\\;\\Omega(s)\\leq\\Omega(t)+\\tau\\right\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "It then suffices to lower bound the probability that $A(t^{\\star})=\\emptyset$ . We compute ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{P}\\left(|A(t^{\\star})|=0\\right)=\\sum_{t\\in T}\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\left|A(t)\\right|=0\\right)}}\\\\ &{}&{=\\sum_{t\\in T}\\mathbb{E}_{y}\\left[\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\operatorname*{sin}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)\\geq y+\\tau|\\Omega(t)=y\\right)\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the expectation is taken over the distribution of $\\Omega(t)$ . Now, fix $t$ and let $\\Omega_{t,y}$ denote the Gaussian process $\\Omega$ conditioned on the event that $\\Omega(t)=y$ . Let $m_{t,y}$ and $\\eta^{2}\\cdot K_{t}$ denote the mean and covariance processes of $\\Omega_{t,y}$ . Critically, note that $K_{t}$ is independent of $y$ and for all $s\\neq t$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nm_{t,y}(s)=m(s)+\\frac{K(s,t)}{K(t,t)}\\left(y-m(t)\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Define the functions ", "page_idx": 17}, {"type": "equation", "text": "$$\na(s)=\\frac{\\tau}{\\rho^{2}}\\cdot\\frac{K(s,t)}{K(t,t)}\\qquad\\mathrm{~and~}\\qquad b(s)=\\frac{\\tau}{\\rho^{2}}-a(s).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Now, note that if $K(s,t)\\leq(1-\\rho^{2})\\cdot K(t,t)$ , then ", "page_idx": 17}, {"type": "equation", "text": "$$\nb(s)=\\frac{\\tau}{\\rho^{2}}\\left(1-\\frac{K(s,t)}{K(t,t)}\\right)\\geq\\frac{\\tau}{\\rho^{2}}\\cdot\\rho^{2}=\\tau.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We also have that $b(s)\\geq0$ for all $s$ by the fact that $K(s,t)\\,\\leq\\,\\sqrt{K(s,s)\\cdot K(t,t)}$ and $K(s,s)\\vee$ $K(t,t)\\leq1$ . Furthermore, for all $s$ , it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{m_{t,y+\\frac{\\tau}{\\rho^{2}}}(s)=m_{t,y}(s)+a(s).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, for fixed $t\\in T$ and $y\\in\\mathbb R$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(t^{*}=t\\mathrm{and~}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)\\geq y+\\tau|\\Omega(t)=y\\right)}\\\\ &{\\quad\\geq\\mathbb{P}\\left(t^{*}=t\\mathrm{and~}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)-b(s)\\geq y|\\Omega(t)=y\\right)}\\\\ &{\\quad=\\mathbb{P}\\left(t^{*}=t\\mathrm{and~}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)-b(s)-a(s)+a(s)\\geq y|\\Omega(t)=y\\right)}\\\\ &{\\quad=\\mathbb{P}\\left(t^{*}=t\\mathrm{and~}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)+a(s)\\geq y+\\frac{\\tau}{\\rho^{2}}|\\Omega(t)=y\\right)}\\\\ &{\\quad=\\mathbb{P}\\left(t^{*}=t\\mathrm{and~}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)\\geq y+\\frac{\\tau}{\\rho^{2}}|\\Omega(t)=y+\\frac{\\tau}{\\rho^{2}}\\right)}\\\\ &{\\quad\\geq\\mathbb{P}\\left(t^{*}=t\\mathrm{and~}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)\\geq y+\\frac{\\tau}{\\rho^{2}}|\\Omega(t)=y+\\frac{\\tau}{\\rho^{2}}\\right),}\\\\ &{\\quad\\geq\\mathbb{P}\\left(t^{*}=t\\mathrm{and~}_{K(s,t)\\leq(1-\\rho^{2})K(t,t)}\\Omega(s)\\geq y+\\frac{\\tau}{\\rho^{2}}|\\Omega(t)=y+\\frac{\\tau}{\\rho^{2}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the first inequality follows from (5), the second equality follows from the construction, and the last equality follows from (6) and the fact that $K_{t}$ is independent of $y$ . Now, denote ", "page_idx": 18}, {"type": "equation", "text": "$$\nq_{t}(y)=(2\\pi K(t,t))^{-\\frac{1}{2}}\\exp\\left(-\\frac{(y-m(t))^{2}}{2\\eta^{2}K(t,t)}\\right),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "the density of $\\Omega(t)$ and note that we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(|A(t^{\\star})|=0\\right)=\\displaystyle\\sum_{t\\in T}\\int_{-\\infty}^{\\infty}q_{t}(y)\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\operatorname*{inf}_{K(s,t)\\leq1-\\rho^{2}}\\Omega(s)\\geq y+\\tau|\\Omega(t)=y\\right)d y}\\\\ &{\\qquad\\qquad\\qquad\\geq\\displaystyle\\sum_{t\\in T}\\int_{\\infty}^{\\infty}q_{t}(y)\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\operatorname*{inf}_{K(s,t)\\leq1-\\rho^{2}}\\Omega(s)\\geq y+\\frac{\\tau}{\\rho^{2}}|\\Omega(t)=y+\\frac{\\tau}{\\rho^{2}}\\right)d y.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We then compute ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\int_{-\\infty}^{\\infty}q_{t}(y)\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\underset{K(s,t)\\leq1-\\rho^{2}}{\\operatorname*{inf}}\\,\\Omega(s)\\geq y+\\frac{\\tau}{\\rho^{2}}|\\Omega(t)=y+\\frac{\\tau}{\\rho^{2}}\\right)d y}\\\\ &{\\qquad\\qquad=\\int_{-\\infty}^{\\infty}q_{t}(y)\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\underset{K(s,t)\\leq1-\\rho^{2}}{\\operatorname*{inf}}\\,\\Omega(s)\\geq y|\\Omega(t)=y\\right)d y}\\\\ &{\\qquad\\qquad+\\int_{-\\infty}^{\\infty}\\left(q_{t}(y)-q_{t}\\left(y-\\frac{\\tau}{\\rho^{2}}\\right)\\right)\\cdot\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\underset{K(s,t)\\leq1-\\rho^{2}}{\\operatorname*{inf}}\\,\\Omega(s)\\geq y|\\Omega(t)=y\\right)d y,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where we added and subtracted the first term and then made the variable substitution $y+\\frac{\\tau}{\\rho^{2}}\\mapsto y$ for the latter integral. Note that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(t^{\\star}=t\\mathrm{~and~}\\operatorname*{inf}_{K(s,t)\\leq1-\\rho^{2}}\\Omega(s)\\geq y|\\Omega(t)=y\\right)=\\mathbb{P}\\left(t^{\\star}=t|\\Omega(t)=y\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "as $\\Omega(s)\\geq\\Omega(t^{\\star})$ for all $s\\in T$ by definition. Combining this observation with (7) and (8) yields ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(|A(t^{\\star})|=0\\right)\\geq\\displaystyle\\sum_{t\\in T}\\int_{-\\infty}^{\\infty}q_{t}(y)\\mathbb{P}\\left(t^{\\star}=t|\\Omega(t)=y\\right)d y}\\\\ &{\\qquad\\qquad-\\displaystyle\\sum_{t\\in T}\\int_{-\\infty}^{\\infty}\\Bigg(q_{t}(y)-q_{t}\\left(y-\\frac{\\tau}{\\rho^{2}}\\right)\\Bigg)\\cdot\\mathbb{P}\\left(t^{\\star}=t|\\Omega(t)=y\\right)d y.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For the first term, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{t\\in T}\\int_{-\\infty}^{\\infty}q_{t}(y)\\mathbb{P}\\left(t^{\\star}=t|\\Omega(t)=y\\right)d y=\\sum_{t\\in T}\\mathbb{P}\\left(t^{\\star}=t\\right)=1.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For the second term, using the fact that $1-e^{x}\\leq x$ for all $x$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{q_{t}(y)-q_{t}\\left(y-\\displaystyle\\frac{\\tau}{\\rho^{2}}\\right)=q_{t}(y)\\left(1-\\exp\\left(\\frac{(y-m(t))^{2}}{2\\eta^{2}K(t,t)}-\\frac{\\left(y-m(t)-\\frac{\\tau}{\\rho^{2}}\\right)^{2}}{2\\eta^{2}K(t,t)}\\right)\\right)}\\\\ &{\\phantom{q_{t}(y)-q_{t}\\left(y-\\displaystyle\\frac{\\tau}{\\rho^{2}}\\right)}\\leq q_{t}(y)\\left(\\frac{(y-m(t))^{2}}{2\\eta^{2}K(t,t)}-\\frac{\\left(y-m(t)-\\frac{\\tau}{\\rho^{2}}\\right)^{2}}{2\\eta^{2}K(t,t)}\\right)}\\\\ &{\\phantom{q_{t}(y)-q_{t}\\left(y\\right)}\\leq\\frac{q_{t}(y)}{2\\eta^{2}K^{2}}\\cdot\\left(\\frac{2\\tau}{\\rho^{2}}(y-m(t))\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Thus we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(|A(t^{*})|>0\\right)=1-\\mathbb{P}\\left(|A(t^{*})|=0\\right)}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\sum_{t\\in T}\\int_{-\\infty}^{\\infty}\\frac{q_{t}(y)}{2\\eta^{2}\\kappa^{2}}\\cdot\\Bigg(\\frac{2\\tau}{\\rho^{2}}(y-m(t))\\Bigg)\\cdot\\mathbb{P}\\left(t^{*}=t|\\Omega(t)=y\\right)d y}\\\\ &{\\qquad=\\displaystyle\\frac{\\tau}{\\rho^{2}\\eta^{2}\\kappa^{2}}\\sum_{t\\in T}\\int_{-\\infty}^{\\infty}(y-m(t))q_{t}(y)\\mathbb{P}\\left(t^{*}=t|\\Omega(t)=y\\right)d y}\\\\ &{\\qquad=\\displaystyle\\frac{\\tau}{\\rho^{2}\\eta^{2}\\kappa^{2}}\\cdot\\mathbb{E}\\left[\\Omega(t^{*})-m(t^{*})\\right]}\\\\ &{\\qquad\\leq\\displaystyle\\frac{\\tau}{\\rho^{2}\\eta^{2}\\kappa^{2}}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{t\\in T}\\Omega(t)-m(t)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The result follows by noting that $\\eta\\cdot\\omega(t)=\\Omega(t)-m(t)$ for all $t\\in T$ . ", "page_idx": 19}, {"type": "text", "text": "We now prove a corollary of Theorem 5 that will be useful in the proof of Proposition 1 and which makes the relationship between $\\mathcal{E}(\\rho,\\tau)$ and the intuition of distance between $t^{\\star}$ and $s$ more explicit. Corollary 1. Suppose that we are in the situation of Theorem $^{5}$ with the additional conditions that $T$ is a subset of a real vector space and that $d(s,t)={\\sqrt{K(s-t,s-t)}}$ . Let $m^{\\prime}:T\\rightarrow\\mathbb{R}$ denote a mean function such that $\\operatorname*{sup}_{t\\in T}|m(t)-m^{\\prime}(t)|\\leq\\tau$ and let $\\Omega^{\\prime}$ denote the corresponding shifted Gaussian process. If $t^{\\star^{\\prime}}=\\mathrm{argmin}_{t\\in T}\\,\\Omega^{\\prime}(t)$ , then ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(d(t^{\\star},t^{\\star^{\\prime}})>\\rho\\right)\\leq\\frac{8\\tau}{\\rho^{4}\\eta\\kappa^{2}}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{t\\in T}\\omega(t)\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Note that ", "page_idx": 19}, {"type": "equation", "text": "$$\nd(s,t)^{2}=K(s-t,s-t)=K(s,s)+K(t,t)-2K(s,t).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Let $M=\\operatorname*{max}(K(t^{\\star},t^{\\star}),K(t^{\\star^{\\prime}},t^{\\star^{\\prime}}))\\le1$ and note that the above implies: ", "page_idx": 19}, {"type": "equation", "text": "$$\nd(t^{\\star},t^{\\star^{\\prime}})^{2}\\leq2M\\left(1-\\frac{K(t^{\\star^{\\prime}},t^{\\star})}{M}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Thus, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(d(t^{*},t^{*^{\\prime}})>\\rho\\right)\\leq\\mathbb{P}\\left(2M\\left(1-\\frac{K(t^{*},t^{*^{\\prime}})}{M}\\right)>\\rho\\right)}\\\\ &{\\qquad\\qquad\\leq\\mathbb{P}\\left(1-\\frac{K(t^{*},t^{*^{\\prime}})}{M}>\\frac{\\rho^{2}}{2}\\right)}\\\\ &{\\qquad\\qquad\\leq2\\left(\\frac{\\tau}{\\left(\\frac{\\rho^{2}}{2}\\right)^{2}\\eta\\kappa^{2}}\\cdot\\mathbb{E}\\left[\\underset{t\\in T}{\\operatorname*{sup}}\\omega(t)\\right]\\right)}\\\\ &{\\qquad\\qquad=\\frac{8\\tau}{\\rho^{4}\\eta\\kappa^{2}}\\cdot\\mathbb{E}\\left[\\underset{t\\in T}{\\operatorname*{sup}}\\omega(t)\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the last inequality follows by applying a union bound and Theorem 5 to the Gaussian processes $\\Omega$ and $\\Omega^{\\prime}$ after observing that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Omega^{\\prime}(t^{\\star})\\leq\\Omega^{\\prime}(t^{\\star^{\\prime}})+\\tau\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and similarly for $\\Omega(t^{\\star^{\\prime}})$ . ", "page_idx": 20}, {"type": "text", "text": "We are now ready to prove Proposition 1 using Corollary 1. ", "page_idx": 20}, {"type": "text", "text": "Proof of Proposition $^{\\,l}$ . Let $T={\\mathcal{F}}$ , and observe that ", "page_idx": 20}, {"type": "equation", "text": "$$\nd(f,f^{\\prime})^{2}=K(f-f^{\\prime},f-f^{\\prime})=\\mathbb{E}\\left[\\omega(f)-\\omega(f^{\\prime})^{2}\\right]=\\left\\|f-f^{\\prime}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The result then follows immediately by applying Corollary 1 to the Gaussian process $\\Omega(f)\\;=\\;$ $m(f)+\\eta\\cdot\\omega(f)$ . ", "page_idx": 20}, {"type": "text", "text": "C Analysis of Algorithms 2 and 3 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section we provide the full proofs for Theorems 2 and 3, as well as more general statements under different measures of the complexity of the function class $\\mathcal{F}$ . We begin the section by stating formal bounds on the learning and differential privacy guarantees for each algorithm. In Appendix C.1, we prove Lemma 1, which is a key technical lemma in the differential privacy guarantee of Algorithm 2; we then continue in Appendix C.2 by proving Lemma 2, which plays an analogous role except in the analysis of Algorithm 3. In Appendix C.3, we prove that algorithmic stability in $\\|\\cdot\\|_{m}$ can be boosted to differential privacy through Algorithm 1. In Appendix C.4 we combine the previous results to give guarantees on the differential privacy of Algorithm 2 and Algorithm 3. We continue in Appendix C.5 by applying more standard learning theoretic techniques to demonstrate that both algorithms are PAC learners before concluding the proofs of the main theorems in Appendix C.6. Finally, for the sake of completeness, we prove a norm comparison lemma in Appendix C.7 that was deferred from Appendix C.5 for the purpose of continuity. ", "page_idx": 20}, {"type": "text", "text": "C.1 Stability of Algorithm 2 and Proof of Lemma 1 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We break the proof into two parts. First, we integrate the tail bound from Proposition 1 to get control on $\\mathbb{E}\\left[\\left\\lVert\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right\\rVert_{m}\\right]$ for any $j\\in[J]$ . We then apply a Jensen\u2019s inequality and a Chernoff bound to get high probability control on $\\left\\|{\\bar{f}}-{\\bar{f}}^{\\prime}\\right\\|$ . We begin with the following lemma: ", "page_idx": 20}, {"type": "text", "text": "Lemma 7. Let ${\\bar{f}}_{j}$ be as in in Line $^{6}$ of Algorithm 2 and $\\bar{f}_{j}^{\\prime}$ is defined analogously with respect to $\\mathcal{D}^{\\prime}$ , a neighboring dataset to $\\mathcal{D}$ . Then ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right\\Vert_{m}^{2}\\right]\\leq\\frac{2}{(n\\cdot\\eta)^{1/3}\\kappa^{2/3}}\\cdot\\left(\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right]\\right)^{1/3},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the expectation is with respect to $\\xi^{(j)}$ . ", "page_idx": 20}, {"type": "text", "text": "Proof. By boundedness of $\\ell$ , it holds that $\\begin{array}{r}{|L_{\\mathcal{D}}(f)-L_{\\mathcal{D^{\\prime}}}(f)|\\leq\\frac{1}{n}}\\end{array}$ for all $f\\in\\mathcal F$ . Thus, if $\\bar{f}^{(1)}$ and $\\bar{f}^{(1)^{\\prime}}$ are as in the statement of the corollary, then $\\begin{array}{r}{L_{\\mathcal{D}}(\\bar{f}^{(1)^{\\prime}})+\\eta\\cdot\\omega_{m}^{(1)}(\\bar{f}^{(1)^{\\prime}})\\,\\le\\,L_{\\mathcal{D}}(\\bar{f}^{(1)})+\\eta}\\end{array}$ \u00b7 \u03c9(m1) ( f\u00af (1)) + n1. Plugging in \u03c4 = n and applying Proposition 1 yields ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left\\|\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right\\|_{m}>\\rho\\right)\\le\\frac{8}{n\\rho^{4}\\kappa^{2}\\eta}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right].\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Now, we can integrate the tail bound to get for any $\\zeta>0$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\|\\bar{f}-\\bar{f}^{\\prime}\\right\\|_{m}^{2}\\right]\\leq\\zeta+\\int_{\\zeta}^{1}2\\rho\\mathbb{P}\\left(\\left\\|\\bar{f}-\\bar{f}^{\\prime}\\right\\|_{m}>\\rho\\right)d\\rho}\\\\ &{\\qquad\\qquad\\qquad\\leq\\zeta+2\\cdot\\int_{\\zeta}^{1}\\rho\\cdot\\frac{8}{n\\rho^{4}\\kappa^{2}\\eta}\\cdot\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{m}(f)\\right]d\\rho}\\\\ &{\\qquad\\qquad\\leq\\zeta+\\frac{8}{n\\zeta^{2}\\kappa^{2}\\eta}\\cdot\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{m}(f)\\right]\\cdot\\log\\left(\\frac{1}{\\zeta}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Minimizing over $\\zeta$ yields the result. ", "page_idx": 21}, {"type": "text", "text": "We now apply a Jensen\u2019s inequality and a Chernoff bound to get high probability control on $\\left\\|{\\bar{f}}-{\\bar{f}}^{\\prime}\\right\\|$ . ", "page_idx": 21}, {"type": "text", "text": "Proof of Lemma $^{\\,l}$ . By Jensen\u2019s inequality and the definition of $\\bar{f}$ , it holds that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{P}\\left(\\left\\|\\bar{f}-\\bar{f}^{\\prime}\\right\\|_{m}>\\rho\\right)=\\mathbb{P}\\left(\\left\\|\\frac{1}{J}\\sum_{j=1}^{J}\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right\\|_{m}>\\rho\\right)}}\\\\ &{}&{=\\mathbb{P}\\left(\\left\\|\\frac{1}{J}\\sum_{j=1}^{J}\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right\\|_{m}^{2}>\\rho^{2}\\right)}\\\\ &{}&{\\leq\\mathbb{P}\\left(\\frac{1}{J}\\sum_{j=1}^{J}\\left\\|\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\right\\|_{m}^{2}>\\rho^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Finally, by Hoeffding\u2019s inequality [Wainwright, 2019, Van Handel, 2014] and Lemma 7, we have that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta\\geq\\mathbb{P}\\left(\\displaystyle\\frac{1}{J}\\sum_{j=1}^{J}\\|\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\|_{m}^{2}>\\mathbb{E}\\left[\\|\\bar{f}_{1}-\\bar{f}_{1}^{\\prime}\\|_{m}\\right]+\\sqrt{\\frac{\\log\\left(\\frac{1}{\\delta}\\right)}{J}}\\right)}\\\\ &{\\phantom{\\delta\\geq}\\mathbb{P}\\left(\\displaystyle\\frac{1}{J}\\sum_{j=1}^{J}\\|\\bar{f}_{j}-\\bar{f}_{j}^{\\prime}\\|_{m}^{2}>\\frac{2}{(n\\cdot\\eta)^{1/3}\\kappa^{2/3}}\\cdot\\left(\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right]\\right)^{1/3}+\\sqrt{\\frac{\\log\\left(\\frac{1}{\\delta}\\right)}{J}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The result follows. ", "page_idx": 21}, {"type": "text", "text": "C.2 Stability of Algorithm 3 and Proof of Lemma 2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section we prove Lemma 2 based on a technique borrowed from online learning and the analysis of Follow the Regularized Leader (FTRL) [Gordon, 1999, Cesa-Bianchi and Lugosi, 2006]. ", "page_idx": 21}, {"type": "text", "text": "Proof of Lemma 2. Let $\\mathcal{L}$ be as in (3) and ${\\mathcal{L}}^{\\prime}$ be defined similarly but with $\\mathcal{D}$ replaced by $\\mathcal{D}^{\\prime}$ . Note that $\\left\\|\\cdot\\right\\|_{m}^{2}$ is strongly convex with respect to $\\left\\|\\cdot\\right\\|_{m}$ [Rockafellar, 2015]. Thus, by convexity of $\\mathcal{F}$ , it holds that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\bar{f}^{\\prime})\\geq\\mathcal{L}(\\bar{f})+\\frac{\\eta}{2}\\left\\|\\bar{f}-\\bar{f}^{\\prime}\\right\\|_{m}^{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "On the other hand, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}(\\bar{f}^{\\prime})=\\mathcal{L}^{\\prime}(\\bar{f}^{\\prime})+\\mathcal{L}(\\bar{f}^{\\prime})-\\mathcal{L}^{\\prime}(\\bar{f}^{\\prime})}\\\\ &{\\phantom{\\mathcal{L}(\\bar{f}^{\\prime})=\\mathcal{L}^{\\prime}(\\bar{f}^{\\prime})+\\mathcal{L}(\\bar{f}^{\\prime})-\\mathcal{L}^{\\prime}(\\bar{f}^{\\prime})}\\\\ &{\\phantom{\\mathcal{L}(\\bar{f}^{\\prime})=\\mathcal{L}^{\\prime}(\\bar{f})+\\mathcal{L}(\\bar{f}^{\\prime})-\\mathcal{L}^{\\prime}(\\bar{f}^{\\prime})+\\mathcal{L}^{\\prime}(\\bar{f})-\\mathcal{L}(\\bar{f})}\\\\ &{\\phantom{\\mathcal{L}(\\bar{f}^{\\prime})=\\mathcal{L}^{\\prime}(\\bar{f})+\\frac{2}{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Combining this with the previous display and rearranging yields: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\eta\\cdot\\left\\|\\bar{f}-\\bar{f}^{\\prime}\\right\\|_{m}^{2}\\leq\\frac{4}{n}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Rearranging again proves the result. ", "page_idx": 22}, {"type": "text", "text": "C.3 Boosting Stability to Differential Privacy: Proofs from Section 4.2 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we analyze Algorithm 1 and prove that if $\\bar{f}$ is stable in $\\|\\cdot\\|_{m}$ then applying the output perturbation yields a differentially private algorithm for standard choices of perturbation distribution $\\mathcal{Q}$ . We also show that Algorithm 1 returns $\\bar{\\widehat{f}}$ close to the $\\bar{f}$ with high probability. This first claim is implied by the following standard concentration bound. ", "page_idx": 22}, {"type": "text", "text": "Lemma 8. Suppose that $\\mathcal{Q}=\\mathcal{N}(0,1)$ and let $\\widehat{f}=\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})$ be as in Algorithm 1. Then with probability at least $1-\\beta$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left\\|{\\bar{f}}-{\\widehat{f}}\\right\\|_{m}\\leq2\\gamma\\cdot{\\sqrt{\\log\\left({\\frac{1}{\\beta}}\\right)}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "If $\\ 'Q=L a p(1)$ , then with probability at least $1-\\beta$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left\\|{\\bar{f}}-{\\widehat{f}}\\right\\|_{m}\\leq2\\gamma\\cdot\\log\\left({\\frac{1}{\\beta}}\\right)\\cdot{\\sqrt{m}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. By construction, it holds that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\widehat{f}-\\bar{f}-\\gamma\\cdot\\zeta\\right\\|_{m}\\leq\\left\\|\\bar{f}-\\bar{f}-\\gamma\\cdot\\zeta\\right\\|_{m}=\\gamma\\cdot\\left\\|\\zeta\\right\\|_{m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By the triangle inequality, it holds that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\widehat{f}-\\bar{f}\\right\\|_{m}\\leq\\left\\|\\widehat{f}-\\bar{f}-\\gamma\\cdot\\zeta\\right\\|_{m}+\\gamma\\cdot\\left\\|\\zeta\\right\\|_{m}\\leq2\\gamma\\cdot\\left\\|\\zeta\\right\\|_{m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus it suffices to bound $\\|\\zeta\\|_{m}$ . Bounds on this quantity when $\\zeta\\sim\\mathcal{N}(0,1)$ or $\\zeta\\,\\sim\\,L a p(1)$ are standard and can be found in, for example Wainwright [2019]. The result follows. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "We now prove the main property of Algorithm 1, namely that it boosts stability to differential privacy. ", "page_idx": 22}, {"type": "text", "text": "Lemma 9. Let Perturb be as in Algorithm $^{\\,l}$ and suppose that ${\\bar{f}},{\\bar{f}}^{\\prime}\\in{\\mathcal{F}}$ . If $\\widetilde{D}_{x}=\\{Z_{1},\\ldots,Z_{m}\\}\\subset$ $\\mathcal{X}$ is arbitrary and $\\mathcal{Q}=\\mathcal{N}(0,1)$ , then for any $\\delta>0$ and any measurable $\\mathcal{G}\\subset\\mathcal{F}$ , it holds that $\\begin{array}{r}{\\geqslant\\Bigl(\\mathrm{Perturb}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}\\Bigr)\\le e^{\\frac{m}{2\\gamma^{2}}\\bigl(1+\\gamma\\cdot\\sqrt{\\log\\left(\\frac{1}{\\delta}\\right)}\\bigr)\\cdot\\|\\bar{f}-\\bar{f}^{\\prime}\\|_{m}}\\cdot\\mathbb{P}\\Bigl(\\mathrm{Perturb}(\\bar{f}^{\\prime},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}\\Bigr)+\\delta.}\\end{array}$ On the other hand, if $\\ 'Q=L a p(1)$ , then ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}\\right)\\leq e^{\\frac{m^{3/2}}{\\gamma}\\cdot\\left\\|\\bar{f}^{\\prime}-\\bar{f}\\right\\|_{m}}\\cdot\\mathbb{P}\\left(\\mathsf{P e r t u r b}(\\bar{f}^{\\prime},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. To prove the first statement, let $\\boldsymbol{{\\beta}}_{\\delta}$ denote the event that $\\begin{array}{r}{\\|\\zeta\\|_{m}\\leq\\gamma\\cdot\\sqrt{\\log\\left(\\frac{1}{\\delta}\\right)}}\\end{array}$ and let ", "page_idx": 22}, {"type": "equation", "text": "$$\np(u)=(2\\pi\\gamma^{2})^{-{\\frac{m}{2}}}\\cdot\\exp\\left(-{\\frac{1}{2\\gamma^{2}}}\\cdot\\|u\\|_{m}^{2}\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "be the density of $\\gamma\\cdot\\zeta$ . Note that $\\mathbb{P}\\left(B_{\\delta}^{c}\\right)\\leq\\delta$ by Lemma 8. We compute: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\^{\\circ}\\left(\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}\\right)=\\int_{u\\in\\mathbb{R}^{m}}\\mathbb{P}\\left(\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\right)p(u)d u}\\\\ {\\quad}&{=\\displaystyle\\int_{u\\in\\mathbb{R}^{m}}\\mathbb{I}\\left[B_{\\delta}\\right]\\cdot\\mathbb{P}\\left(\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\right)p(u)d u}\\\\ {\\quad}&{\\displaystyle~~+\\int_{u\\in\\mathbb{R}^{m}}\\mathbb{I}\\left[B_{\\delta}^{c}\\right]\\mathbb{P}\\left(\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\right)p(u)d u}\\\\ {\\quad}&{\\displaystyle~~\\leq\\delta+\\int_{u\\in\\mathbb{R}^{m}}\\mathbb{I}\\left[B_{\\delta}\\right]\\cdot\\mathbb{P}\\left(\\mathsf{P e r t u r b}(\\bar{f},\\mathcal{Q},\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\right)p(u)d u}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For the second term, we compute: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\int_{u\\in\\mathbb{R}^{n}}\\mathbb{I}[B_{\\delta}]\\cdot\\mathbb{P}\\Big(\\mathsf{P e r t u r b}(\\bar{f},Q,\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\Big)\\,p(u)d u}\\\\ &{\\qquad=\\int_{u\\in\\mathbb{R}^{n}}\\mathbb{I}[B_{\\delta}]\\cdot\\mathbb{P}\\Big(\\mathsf{P e r t u r b}(\\bar{f},Q,\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u+\\bar{f}^{\\prime}-\\bar{f}\\Big)\\,p(u)d u}\\\\ &{\\qquad=\\int_{u\\in\\mathbb{R}^{n}}\\mathbb{I}[B_{\\delta}]\\cdot\\mathbb{P}\\Big(\\mathsf{P e r t u r b}(\\bar{f},Q,\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\Big)\\,p(u)\\cdot e^{\\frac{-p}{2\\gamma^{2}}\\big(\\|u-\\bar{f}\\|_{m}^{2}-\\|u-\\bar{f}\\|_{m}^{2}\\big)}\\,d u}\\\\ &{\\qquad\\leq\\int_{u\\in\\mathbb{R}^{n}}\\mathbb{I}[B_{\\delta}]\\cdot\\mathbb{P}\\Big(\\mathsf{P e r t u r b}(\\bar{f},Q,\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\Big)\\,p(u)\\cdot e^{\\frac{-p}{2\\gamma^{2}}\\big(1+\\|u\\|_{m}\\big)_{*}\\cdot\\|\\bar{f}-\\bar{f}\\|_{m}}\\,d u}\\\\ &{\\qquad\\leq\\int_{u\\in\\mathbb{R}^{n}}\\mathbb{I}[B_{\\delta}]\\cdot\\mathbb{P}\\Big(\\mathsf{P e r t u r b}(\\bar{f},Q,\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}|\\gamma\\cdot\\zeta=u\\Big)\\,p(u)\\cdot e^{\\frac{-p}{2\\gamma^{2}}\\big(1+\\gamma\\sqrt{\\log(\\frac{1}{3})}\\big)\\cdot\\|f-\\bar{f}\\|_{m}},}\\\\ &{\\qquad\\leq e^{\\frac{-p}{2\\gamma^{2}}\\big(1+\\gamma\\sqrt{\\log(\\frac{1}{3})}\\big)\\cdot\\|\\bar{f}-\\bar{f}\\|_{m}}\\cdot\\mathbb{P}\\Big(\\mathsf{P e r t u r b}(\\bar{f}^{\\prime},Q,\\gamma,\\widetilde{D}_{x})\\in\\mathcal{G}\\Big)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The first claim follows. To prove the second claim, we may repeat the same argument with $\\mathcal{Q}=$ $L a p(1)$ and $\\delta=0$ . Indeed, observe that if ", "page_idx": 23}, {"type": "equation", "text": "$$\nq(u)=\\gamma^{-m}\\cdot e^{-\\frac{\\parallel\\b{u}\\parallel_{\\ell^{1}}}{\\gamma}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "then ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{q(u+\\bar{f}^{\\prime}-\\bar{f})}{q(u)}\\le e^{\\frac{\\|\\bar{f}^{\\prime}-\\bar{f}\\|_{\\ell^{1}}}{\\gamma}}\\le e^{\\frac{m^{3/2}}{\\gamma}\\cdot\\left\\|\\bar{f}^{\\prime}-\\bar{f}\\right\\|_{m}},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the second inequality follows from Cauchy-Schwarz. Plugging this ratio into the above argument yields the second claim. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "C.4 Concluding the Proofs of Differential Privacy ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section, we combine the results from Appendix C.3 with the stability results from Appendix C.6 to prove the differential privacy guarantees of Algorithm 2 and Algorithm 3. We separate this section into two lemmas, each corresponding to one of the algorithms. We begin with the more general result. Note that this lemma does not quite follow immediately from combining the stability guarantee with the results of Appendix C.3 as we wish to assume a uniform lower bound on $\\left\\|f\\right\\|_{\\mu}$ whereas Lemma 1 requires a uniform lower bound on $\\|\\cdot\\|_{m}$ . We apply a result from Appendix C.5 below to reconcile this discrepancy. ", "page_idx": 23}, {"type": "text", "text": "Lemma 10 (Differential Privacy Guarantee for Algorithm 2). Suppose that $\\mathcal{F}:\\mathcal{X}\\to[-1,1]$ is a function class and let $\\mu\\in\\Delta(\\mathcal{X})$ such that $\\begin{array}{r}{\\|f\\|^{2}\\geq\\frac{2}{3}}\\end{array}$ for all $f\\,\\in\\,{\\mathcal{F}}$ . Suppose further that $\\ell$ is bounded in [0, 1]. Let $\\delta>0$ and suppose that $m,\\gamma,\\eta$ , and $J$ are such that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{m}{2\\gamma^{2}}\\left(1+\\gamma\\cdot\\sqrt{\\log\\left(\\frac{2}{\\delta}\\right)}\\right)\\left(\\frac{4}{(n\\cdot\\eta)^{1/3}}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right]+\\sqrt{\\frac{\\log\\left(\\frac{2}{\\delta}\\right)}{J}}\\right)\\leq\\varepsilon\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and ", "page_idx": 23}, {"type": "equation", "text": "$$\nC\\left(\\frac{\\log^{2}(m)}{\\sqrt{m}}\\cdot\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})+\\sqrt{\\frac{\\log\\log(m)+\\log\\left(\\frac{1}{\\delta}\\right)}{m}}\\right)\\leq\\frac{1}{6}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then Algorithm 2 is $(\\varepsilon,\\delta)$ -differentially private for $\\mathcal{Q}=\\mathcal{N}(0,1)$ . ", "page_idx": 23}, {"type": "text", "text": "Proof. The result follows immediately by combining Lemmas 1 and 9 assuming we have a lower bound on $\\kappa$ . Indeed, by Lemma 12, it holds with probability at least $1-\\delta$ that $\\operatorname*{inf}_{f\\in\\mathcal{F}}\\|f\\|_{m}\\geq\\frac{1}{4}$ . The result follows. ", "page_idx": 23}, {"type": "text", "text": "We also have a guarantee for the more specialized algorithm. ", "page_idx": 23}, {"type": "text", "text": "Lemma 11 (Differential Privacy Guarantee for Algorithm 3). Suppose that $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ is $a$ convex function class and suppose that $\\ell$ is convex and $\\lambda$ -Lipschitz in its first argument. If $\\delta>0$ and $m,\\gamma,\\eta$ are such that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{m}{2\\gamma^{2}}\\left(1+\\gamma\\cdot\\sqrt{\\log\\left(\\frac{2}{\\delta}\\right)}\\right)\\cdot\\frac{2}{\\sqrt{\\eta\\cdot n}}\\leq\\varepsilon,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "then Algorithm 3 run with $\\mathcal{Q}=\\mathcal{N}(0,1)$ is $(\\varepsilon,\\delta)$ -differentially private. On the other hand, $i f\\delta=0$ and ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{m^{3/2}}{\\gamma}\\cdot\\frac{2}{\\sqrt{\\eta\\cdot n}}\\leq\\varepsilon,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "then Algorithm 3 run with $\\mathcal{Q}=L a p(1)$ is $\\varepsilon$ -purely differentially private. ", "page_idx": 24}, {"type": "text", "text": "Proof. This follows immediately by combining Lemmas 2 and 9. ", "page_idx": 24}, {"type": "text", "text": "These results show that for any choice of $\\nu$ , Algorithms 2 and 3 are differentially private. In the next section we show that if $\\nu$ is $\\sigma$ -smooth with respect to $\\mu$ , then the algorithms are also PAC learners with respect to $\\nu$ . ", "page_idx": 24}, {"type": "text", "text": "C.5 PAC guarantees for Algorithms 2 and 3 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The previous sections have shown that Algorithms 2 and 3 are differentially private, which comprises the main difficulty of our analysis. Here we apply standard learning theoretic techniques to show that if $\\nu$ is $\\sigma$ -smooth with respect to $\\mu$ , then the algorithms are also PAC learners with respect to $\\nu$ . This proof rests on three main results: first, we recall a norm comparison guarantee in high probability that allows us to relate $\\left\\|\\cdot\\right\\|_{\\mu}$ to $\\|\\cdot\\|_{m}$ ; second, we recall a classical uniform deviations bound for empirical processes; and third, we show that the perturbed empirical minimizer $\\bar{f}$ has similar loss to the empirical minimizer $f_{{\\mathsf{E R M}}}$ of a loss function as long as the perturbation is not too large. Combining all three results will result in a PAC learning guarantee for Algorithms 2 and 3. ", "page_idx": 24}, {"type": "text", "text": "We begin with the following lemma, which is a fairly standard result in learning theory. To state the lemma, we recall from Definition 6 that the worst-case Gaussian complexity is defined as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})=\\operatorname*{sup}_{Z_{1},\\ldots,Z_{m}}\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}(f)\\right],\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We then have the following control on $\\left\\|\\cdot\\right\\|_{\\mu}$ in terms of $\\left\\|\\cdot\\right\\|_{m}$ : ", "page_idx": 24}, {"type": "text", "text": "Lemma 12. Suppose that $\\mathcal{F}~:~\\mathcal{X}~\\rightarrow~[-1,1]$ is a function class and let $\\mu~\\in~\\Delta(\\mathcal{X})$ with $Z_{1},\\dots,Z_{m}\\,\\sim\\,\\mu$ independent. Then for any $\\beta\\,>\\,0$ , it holds with probability at least $1-\\beta$ that for all $f,f^{\\prime}\\in\\mathcal{F}$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\|f-f^{\\prime}\\|_{\\mu}\\leq2\\cdot\\|f-f^{\\prime}\\|_{m}+C\\left(\\frac{\\log^{2}(m)}{\\sqrt{m}}\\cdot\\overline{{g}}_{m}(\\mathcal{F})+\\sqrt{\\frac{\\log\\log(m)+\\log\\left(\\frac{1}{\\beta}\\right)}{m}}\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Because the proof is relatively standard [Bousquet, 2002, Rakhlin et al., 2017], but also a technical digression, we defer it to Appendix C.7 and continue with our arguments. ", "page_idx": 24}, {"type": "text", "text": "Our second lemma is a standard uniform deviation bound for empirical processes: ", "page_idx": 24}, {"type": "text", "text": "Lemma 13. Let $\\mathcal{F}:\\mathcal{X}\\,\\rightarrow\\,[-1,1]$ be a bounded function class and let $\\mathcal{D}$ denote a data set of $(X_{i},Y_{i})\\sim\\nu$ be independent. Then for any $\\beta>0$ , with probability at least $1-\\beta$ , it holds that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{f\\in\\mathcal{F}}|L_{\\mathcal{D}}(f)-L(f)|\\leq\\frac{6}{\\sqrt{n}}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{n}(f)\\right]+\\sqrt{\\frac{2\\log\\left(\\frac{1}{\\beta}\\right)}{n}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. This follows immediately from combining Wainwright [2019, Theorem 4.10] with Van Handel [2014, Lemma 7.4]. \u53e3 ", "page_idx": 25}, {"type": "text", "text": "Finally, we show that the perturbed empirical minimizer $\\bar{f}$ has similar loss to the empirical minimizer fERM of a loss function as long as the perturbation is not too large. ", "page_idx": 25}, {"type": "text", "text": "Lemma 14. Let $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ denote a function class and let $\\ell:[-1,1]^{\\times2}\\to[0,1]$ denote $a$ bounded loss function convex in the first argument and let $\\mathcal{D}$ denote a dataset of size $n$ . For $\\eta>0$ , let $\\bar{f}$ be as in Line $^{5}$ of Algorithm 2. Then for any $\\beta>0$ , with probability at least $1-\\beta$ , ", "page_idx": 25}, {"type": "equation", "text": "$$\n:(\\bar{f})-\\operatorname*{inf}_{f\\in\\mathcal{F}}L(f)\\leq\\frac{12}{\\sqrt{n}}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{n}(f)\\right]+2\\cdot\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{n}}+2\\eta\\cdot\\left(\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}^{(j)}(f)\\right]+\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{J}}\\right)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "If instead we let $\\bar{f}$ be as in Line 3 of Algorithm 3, then almost surely, ", "page_idx": 25}, {"type": "equation", "text": "$$\nL(\\bar{f})-\\operatorname*{inf}_{f\\in\\mathcal{F}}L(f)\\leq12\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{n}(f)\\right]+2\\cdot\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{n}}+\\eta.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. Applying Lemma 5 and noting that $\\bar{f},f_{\\mathsf{E R M}}\\in\\mathcal{F}$ and applying Lemma 13 yields ", "page_idx": 25}, {"type": "equation", "text": "$$\nL(\\bar{f})-\\operatorname*{inf}_{f\\in\\mathcal{F}}L(f)\\leq\\frac{12}{\\sqrt{n}}\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{n}(f)\\right]+2\\cdot\\sqrt{\\frac{2\\log\\left(\\frac{1}{\\beta}\\right)}{n}}+\\operatorname*{sup}_{f,f^{\\prime}\\in\\mathcal{F}}R(f)-R(f^{\\prime}).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The second statement follows immediately by noting that $0\\leq\\|f\\|_{m}\\leq1$ for all $f\\in\\mathcal F$ and letting R(f) = \u03b7 \u00b7 \u2225f\u2225m. ", "page_idx": 25}, {"type": "text", "text": "For the first statement, we note that by convexity of $\\ell$ , it holds that ", "page_idx": 25}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}}(\\bar{f})\\leq\\frac{1}{J}\\cdot\\sum_{j=1}^{J}L_{\\mathcal{D}}(\\bar{f}_{j})\\leq L_{\\mathcal{D}}(f_{\\mathsf{E R M}})+\\frac{\\eta}{J}\\cdot\\sum_{j=1}^{J}\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega^{(j)}(f)-\\operatorname*{inf}_{f^{\\prime}\\in\\mathcal{F}}\\omega^{(j)}(f^{\\prime}).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To prove the second statement, we observe that by the Borell-Tsirelson-Ibragimov-Sudakov inequality (see, e.g., Wainwright [2019, Example 2.30]) and the fact that $\\mathbb{E}\\left[\\omega_{m}^{(j)}\\bar{(f)}^{2}\\right]\\leq1$ for all $f\\in\\mathcal F$ , that for all $j\\in[J]$ , with probability at least $1-\\beta$ , it holds that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}^{(j)}(f)\\leq\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}^{(j)}(f)\\right]+\\sqrt{2\\log\\left(\\frac{1}{\\beta}\\right)}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Applying symmetry and a Chernoff bound tells us that with probability at least $1-\\beta$ it holds that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\frac{1}{J}\\cdot\\sum_{j=1}^{J}\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}^{(j)}(f)-\\operatorname*{inf}_{f\\in\\mathcal{F}}\\omega_{m}^{(j)}\\leq2\\cdot\\mathbb{E}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\omega_{m}^{(j)}(f)\\right]+2\\cdot\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{J}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The result follows. ", "page_idx": 25}, {"type": "text", "text": "Before continuing, we prove Lemma 5 from Section 4: ", "page_idx": 25}, {"type": "text", "text": "Proof of Lemma 5. For an arbitrary regularizer $R:\\mathcal{F}\\rightarrow\\mathbb{R}$ , if we let $\\bar{f}\\,\\in\\,\\mathrm{argmin}_{f\\in\\mathcal{F}}\\,L_{\\mathcal{D}}(f)\\,+$ $R(f)$ , then by definition $L_{\\mathcal{D}}(\\bar{f})+R(\\bar{f})\\leq L_{\\mathcal{D}}(f_{\\mathsf{E R M}})+R(f_{\\mathsf{E R M}})$ and so ", "page_idx": 25}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}}(\\bar{f})\\leq L_{\\mathcal{D}}(f_{\\mathsf{E R M}})+\\operatorname*{sup}_{f,f^{\\prime}\\in\\mathcal{F}}R(f)-R(f^{\\prime}),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $f_{\\mathsf{E R M}}\\in\\operatorname{argmin}_{f\\in\\mathcal{F}}L_{\\mathcal{D}}(f)$ is the ERM. ", "page_idx": 25}, {"type": "text", "text": "Combining these three lemmas yields the following PAC learning guarantee for Algorithm 2. ", "page_idx": 26}, {"type": "text", "text": "Lemma 15 (PAC Learning Guarantee for Algorithm 2). Suppose that $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ is a function class and $\\ell:\\,[-1,1]^{\\times2}\\ \\stackrel{\\smile}{\\rightarrow}\\ [0,1]$ is a bounded loss function $\\lambda$ -Lipschitz and convex in the first argument. Let $\\mu\\in\\Delta(\\mathcal{X})$ and suppose that $\\nu$ is $\\sigma$ -smooth with respect to $\\mu$ . For any $\\beta>0$ it holds with probability at least $1-\\beta$ that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L(\\widehat f)-\\frac{\\operatorname*{inf}}{f\\in\\mathcal{F}}L(f)\\leq\\frac{12}{\\sqrt{n}}\\cdot\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{n}(f)\\right]+2\\cdot\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{n}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,2\\eta\\cdot\\left(\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{m}^{(j)}(f)\\right]+\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{J}}\\right)+\\frac{4\\lambda\\gamma}{\\sigma}\\cdot\\sqrt{\\log\\left(\\frac{1}{\\beta}\\right)}}\\\\ &{\\qquad\\qquad\\qquad+\\,\\frac{C\\lambda}{\\sigma}\\cdot\\left(\\frac{\\log^{3}(m)}{\\sqrt{m}}\\cdot\\bar{g}_{m}(\\mathcal{F})+\\sqrt{\\frac{\\log\\log(m)+\\log\\left(\\frac{1}{\\beta}\\right)}{m}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "for $\\widehat{f}$ returned by Algorithm 2 with $\\mathcal{Q}=\\mathcal{N}(0,1)$ and $\\mathcal{D}$ a dataset of size $n$ . ", "page_idx": 26}, {"type": "text", "text": "Proof. We compute: ", "page_idx": 26}, {"type": "equation", "text": "$$\nL(\\widehat{f})=L(\\bar{f})+L(\\widehat{f})-L(\\bar{f})\\leq L(\\bar{f})+\\lambda\\cdot\\left\\|\\bar{f}-\\widehat{f}\\right\\|_{\\nu_{X}}\\leq L(\\bar{f})+\\frac{\\lambda}{\\sigma}\\cdot\\left\\|\\bar{f}-\\widehat{f}\\right\\|_{\\mu},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the first inequality uses Jensen\u2019s and the second usesthe fact that $\\nu$ is $\\sigma$ -smooth. We now observe that by Lemma 8, with probability at least $1-\\beta$ , ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\|{\\bar{f}}-{\\widehat{f}}\\right\\|_{\\mu}\\leq2\\gamma\\cdot{\\sqrt{\\log\\left({\\frac{1}{\\beta}}\\right)}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining this with Lemma 14 yields ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{~}{:(\\widehat{f})-\\operatorname*{inf}_{f\\in\\mathcal{F}}L(f)\\leq\\frac{12}{\\sqrt{n}}\\cdot\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{n}(f)\\right]+2\\cdot\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{n}}+2\\eta\\cdot\\left(\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{m}^{(j)}(f)\\right]+\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{J}}\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\left.+\\frac{4\\lambda\\gamma}{\\sigma}\\cdot\\sqrt{\\log\\left(\\frac{1}{\\beta}\\right)}+\\frac{\\lambda}{\\sigma}\\left(\\left\\|\\widehat{f}-\\bar{f}\\right\\|_{\\mu}-\\left\\|\\widehat{f}-\\bar{f}\\right\\|_{m}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Applying Lemma 12 concludes the result. ", "page_idx": 26}, {"type": "text", "text": "Similarly, we have a result for Algorithm 3; note that while convexity of $\\ell$ is required to demonstrate that Algorithm 2 is a PAC learner, although is irrelevant to the privacy guarantee in Lemma 10, the situation for Algorithm 3 is reversed in that convexity is not required to demonstrate that Algorithm 3 is a PAC learner while it is necessary for the privacy guarantee in Lemma 11. ", "page_idx": 26}, {"type": "text", "text": "Lemma 16 (PAC Guarantees for Algorithm 3). Suppose that $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ is a convex function class and $\\ell:[-1,1]^{\\times2}\\to[0,1]$ is a bounded loss function $\\lambda$ -Lipschitz in the first argument. Let $\\mu\\in\\Delta(\\mathcal{X})$ and suppose that $\\nu$ is $\\sigma$ -smooth with respect to $\\mu$ . For any $\\beta>0$ it holds with probability at least $1-\\beta$ that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L(\\widehat f)-\\operatorname*{inf}_{f\\in\\mathcal{F}}L(f)\\leq\\frac{12}{\\sqrt{n}}\\cdot\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{n}(f)\\right]+2\\cdot\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{n}}+\\eta+\\frac{4\\lambda\\gamma}{\\sigma}\\cdot\\sqrt{\\log\\left(\\frac{1}{\\beta}\\right)}}\\\\ &{\\qquad\\qquad\\qquad+\\frac{C\\lambda}{\\sigma}\\cdot\\left(\\frac{\\log^{3}(m)}{\\sqrt{m}}\\cdot\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})+\\sqrt{\\frac{\\log\\log(m)+\\log\\left(\\frac{1}{\\beta}\\right)}{m}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "for $\\widehat{f}$ returned by Algorithm 3 with $\\mathcal{Q}=\\mathcal{N}(0,1)$ and $\\mathcal{D}$ a dataset of size $n$ . Similarly, if we replace $\\mathcal{Q}=L a p(1)$ , then with probability at least $1-\\beta$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L(\\widehat f)-\\operatorname*{inf}_{f\\in\\mathcal{F}}L(f)\\leq\\frac{12}{\\sqrt{n}}\\cdot\\mathbb{E}\\left[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\,\\omega_{n}(f)\\right]+2\\cdot\\sqrt{\\frac{\\log\\left(\\frac{1}{\\beta}\\right)}{n}}+\\eta+\\frac{4\\lambda\\gamma}{\\sigma}\\cdot\\log\\left(\\frac{1}{\\beta}\\right)\\cdot\\sqrt{m}}\\\\ &{\\qquad\\qquad\\qquad+\\frac{C\\lambda}{\\sigma}\\cdot\\left(\\frac{\\log^{3}(m)}{\\sqrt{m}}\\cdot\\overline{{g}}_{m}(\\mathcal{F})+\\sqrt{\\frac{\\log\\log(m)+\\log\\left(\\frac{1}{\\beta}\\right)}{m}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. The proof of the first statement is identical to that of Lemma 15 with the exception of replacing (11) by (12) in the invocation of Lemma 14. The second statement is also identical but now replacing (9) by (10) when applying Lemma 8. \u53e3 ", "page_idx": 27}, {"type": "text", "text": "With these results in hand, along with those from Appendix C.4, all that remains to conclude the proofs of the main theorems is to tune the hyperparameters and control the complexity terms. We do this in the next section. ", "page_idx": 27}, {"type": "text", "text": "C.6 Concluding the Proofs of Theorems 2 and 3 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we combine the results from Appendices C.4 and C.5 to prove the main theorems. The main theorems in the text, Theorems 2 and 3, follow immediately from the following two results. We begin by stating a more detailed version of Theorem 2: ", "page_idx": 27}, {"type": "text", "text": "Theorem 6. Suppose that $\\mathcal{F}:\\mathcal{X}\\to[-1,1]$ is a function class such that ${\\overline{{\\mathcal{G}}}}_{m}({\\mathcal{F}})=O\\left({\\sqrt{d}}\\right)$ for some $d\\in\\mathbb{N}$ and $\\ell:[-1,1]^{\\times2}\\,\\to\\,[0,1]$ is convex and $\\lambda$ -Lipschitz in the first argument. If we let $\\mathcal{Q}=\\mathcal{N}(0,1)$ in Algorithm $^{\\,l}$ and set ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\gamma=\\Theta\\left(\\frac{\\sigma\\alpha}{\\lambda\\cdot\\sqrt{\\log\\left(\\frac{1}{\\beta}\\right)}}\\right),\\qquad\\eta=\\Theta(\\frac{\\alpha}{\\sqrt{d}}),\\qquad m=\\widetilde\\Theta\\left(\\frac{d\\vee\\log\\left(\\frac{1}{\\beta}\\right)}{\\sigma^{2}\\alpha^{2}}\\cdot\\lambda^{2}\\right)}\\\\ {J=\\widetilde\\Omega\\left(\\frac{d\\log\\left(\\frac{1}{\\beta}\\right)}{\\alpha^{2}}\\vee\\frac{\\lambda^{8}d^{2}\\log^{4}\\left(\\frac{1}{\\beta}\\right)\\log\\left(\\frac{1}{\\delta}\\right)}{\\sigma^{8}\\alpha^{8}\\varepsilon^{2}}\\vee\\frac{d^{2}\\lambda^{6}\\log^{3}\\left(\\frac{1}{\\beta}\\right)\\log^{2}\\left(\\frac{1}{\\delta}\\right)}{\\sigma^{6}\\alpha^{6}\\varepsilon^{2}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and ", "page_idx": 27}, {"type": "equation", "text": "$$\nn=\\widetilde\\Omega\\left(\\frac{\\lambda^{12}d^{5}\\log^{6}\\left(\\frac{1}{\\beta}\\right)}{\\sigma^{12}\\varepsilon^{3}\\alpha^{14}}\\vee\\frac{d^{5}\\lambda^{9}\\log^{9/2}\\left(\\frac{1}{\\beta}\\right)\\log^{3/2}\\left(\\frac{1}{\\delta}\\right)}{\\sigma^{9}\\varepsilon^{3}\\alpha^{10}}\\right),\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "then Algorithm 2 is $(\\varepsilon,\\delta)$ -differentially private and an $(\\alpha,\\beta)$ -PAC learner with respect to any $\\nu$ that is $\\sigma$ -smooth with respect to $\\mu$ . ", "page_idx": 27}, {"type": "text", "text": "Proof. This follows by combining Lemma 10 with Lemma 15 and plugging in the parameter choices. \u53e3 ", "page_idx": 27}, {"type": "text", "text": "We also have a result for Algorithm 3: ", "page_idx": 27}, {"type": "text", "text": "Theorem 7. Suppose that $\\mathcal{F}:\\mathcal{X}\\rightarrow[-1,1]$ is a convex function class such that $\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})=O\\left(\\sqrt{d}\\right)$ for some $d\\in\\mathbb{N}$ and $\\ell:[-1,1]^{\\times2}\\to[0,1]$ is convex and $\\lambda$ -Lipschitz in the first argument. If we let $\\mathcal{Q}=\\mathcal{N}(0,1)$ in Algorithm $^{\\,l}$ and set ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\gamma=\\Theta\\left(\\frac{\\sigma\\alpha}{\\lambda\\cdot\\sqrt{\\log\\left(\\frac{1}{\\beta}\\right)}}\\right),\\qquad\\eta=\\Theta(\\alpha),\\qquad{m=\\widetilde\\Theta\\left(\\frac{d\\vee\\log\\left(\\frac{1}{\\beta}\\right)}{\\sigma^{2}\\alpha^{2}}\\cdot\\lambda^{2}\\right)}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and ", "page_idx": 28}, {"type": "equation", "text": "$$\nn=\\widetilde\\Omega\\left(\\frac{\\lambda^{5}d\\log^{2}\\left(\\frac{1}{\\beta}\\right)}{\\varepsilon\\sigma^{4}\\alpha^{5}}\\vee\\frac{\\lambda^{4}d\\log^{3/2}\\left(\\frac{1}{\\beta}\\right)\\log^{1/2}\\left(\\frac{1}{\\delta}\\right)}{\\varepsilon\\sigma^{3}\\alpha^{4}}\\right),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "then Algorithm $^3$ is $(\\varepsilon,\\delta)$ -differentially private and an $(\\alpha,\\beta)$ -PAC learner with respect to any $\\nu$ that is $\\sigma$ -smooth with respect to $\\mu$ . ", "page_idx": 28}, {"type": "text", "text": "On the other hand, $i f$ we set $\\mathcal{Q}=L a p(1)$ in Algorithm $^{\\,l}$ and set ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\gamma=\\widetilde\\Theta\\left(\\frac{\\alpha^{2}\\sigma}{\\lambda^{2}\\cdot\\left(d\\sqrt{\\log\\left(\\frac{1}{\\beta}\\right)}\\wedge\\log\\left(\\frac{1}{\\beta}\\right)\\right)}\\right),\\quad\\eta=\\Theta(\\alpha),\\quad m=\\widetilde\\Theta\\left(\\frac{d\\vee\\log\\left(\\frac{1}{\\beta}\\right)}{\\sigma^{2}\\alpha^{2}}\\cdot\\lambda^{2}\\right)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and ", "page_idx": 28}, {"type": "equation", "text": "$$\nn=\\widetilde{\\mathcal{L}}\\left(\\frac{\\lambda^{6}}{\\sigma^{5}\\varepsilon\\alpha^{6}}\\cdot\\left(d^{2}\\sqrt{\\log\\left(\\frac{1}{\\beta}\\right)}\\vee\\log^{5/2}\\left(\\frac{1}{\\beta}\\right)\\right)\\right)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "then Algorithm $^3$ is $\\varepsilon$ -purely differentially private and an $(\\alpha,\\beta)$ -PAC learner with respect to any $\\sigma$ -smooth $\\nu$ . ", "page_idx": 28}, {"type": "text", "text": "Proof. This follows immediately by combining Lemma 11 with Lemma 16 and plugging in the parameter choices, with the pure differential privacy guarantees coming from the second halves of each lemma. \u53e3 ", "page_idx": 28}, {"type": "text", "text": "As a final remark, we note that Lemmas 15 and 16 are both phrased entirely in terms of $\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})$ and thus apply to function classes $\\mathcal{F}$ such that $\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})\\,=\\,\\omega(1)$ . Such non-donsker [Wainwright, 2019, Van Handel, 2014] classes can still be learned in the PAC framework, \u221aalbeit with slower rates. Indeed, it is immediate from the above results that as long as ${\\overline{{\\mathcal{G}}}}_{m}({\\mathcal{F}})=o({\\sqrt{m}})$ , then appropriately tuning the hyperparamters results Algorithms 2 and 3 being differentially private PAC learners with respect to $\\nu$ . It is well-known that (with our scaling) ${\\overline{{\\mathcal{G}}}}_{m}({\\mathcal{F}})=o({\\sqrt{m}})$ is a necessary condition for PAC learnability even absent a privacy condition [Wainwright, 2019, Van Handel, 2014] and thus our results qualitatively demonstrate that private learnability with public data is possible whenever non-private learning is possible. ", "page_idx": 28}, {"type": "text", "text": "C.7 Proof of Lemma 12 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Replacing $\\mathcal{F}$ by $\\mathcal{F}-\\mathcal{F}=\\left\\{f-f^{\\prime}|f,f^{\\prime}\\in\\mathcal{F}\\right\\}$ and noting that the uniform bound only increases by a factor of 2 and the Rademacher complexity increases at most by a factor of 2, we observe that it suffices to prove the result for $f^{\\prime}=0$ . We thus instead prove the notationally simpler claim that with probability at least $1-\\beta$ , for all $f\\in\\mathcal F$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\|f\\|_{\\mu}\\leq2\\cdot\\|f\\|_{m}+C\\left(\\frac{\\log^{3}(m)}{\\sqrt{m}}\\cdot\\overline{{g}}_{m}(\\mathcal{F})+\\frac{\\log\\log(m)+\\log\\left(\\frac{1}{\\beta}\\right)}{m}\\right)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We first note that by Bousquet [2002, Theorem 6.1], with probability at least $1-\\beta$ , it holds that for all $f\\in\\mathcal F$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left\\|f\\right\\|_{\\mu}^{2}\\leq2\\cdot\\left\\|f\\right\\|_{m}^{2}+200\\left({\\overline{{r}}}^{2}+{\\frac{\\log\\left({\\frac{1}{\\beta}}\\right)+\\log\\log(m)}{m}}\\right)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for some universal constant $C$ , with ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\overline{{r}}\\leq\\operatorname*{inf}\\left\\{r>0|\\mathbb{E}_{\\xi}\\left[\\operatorname*{sup}_{\\stackrel{f\\in\\mathcal{F}}{\\left\\|f\\right\\|_{m}^{2}\\leq r^{2}}}\\frac{1}{m}\\cdot\\sum_{i=1}^{m}\\xi_{i}f(Z_{i})^{2}\\right]\\leq\\frac{r^{2}}{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Taking square roots on both sides of (13) shows that it suffices to upper bound $\\overline{r}$ . For the remainder of the proof, we do this. ", "page_idx": 29}, {"type": "text", "text": "In order to proceed, we recall the following standard definition of covering numbers. ", "page_idx": 29}, {"type": "text", "text": "Definition 8. Let $\\mathcal{F}$ be a function class and $\\|\\cdot\\|_{m,\\infty}$ the the $L^{\\infty}$ norm on the empirical measure on $Z_{1},\\ldots,Z_{m}\\,\\in\\,{\\mathcal{X}}$ , i.e., $\\|f\\|_{m,\\infty}\\,=\\,\\operatorname*{max}_{i\\in[m]}|f(Z_{i})|$ . We say that $f_{1},\\ldots,f_{N}$ is an $\\varepsilon$ -cover with respect to $\\|\\cdot\\|_{m,\\infty}$ if for all $f\\ \\in\\mathcal{F}$ there is some $f_{j}$ such that $\\|f-f_{j}\\|_{m,\\infty}\\,\\leq\\,\\varepsilon$ . We then let $\\mathcal{N}_{m,\\infty}(\\mathcal{F},\\varepsilon)$ denote the size of the smallest $\\varepsilon$ -cover of $\\mathcal{F}$ with respect to $\\|\\cdot\\|_{m,\\infty}$ . ", "page_idx": 29}, {"type": "text", "text": "The notion of a cover is standard throughout learning theory and can be used to control the Rademacher and Gaussian complexities [Dudley, 1969, Van Handel, 2014, Wainwright, 2019]. We will use it to control $\\overline{r}$ . ", "page_idx": 29}, {"type": "text", "text": "Proceeding with the proof, let $\\Lambda_{m,\\infty}(\\mathcal{F},u)$ denote the covering number of the function class $\\mathcal{F}$ with respect to $\\|\\cdot\\|_{m,\\infty}$ at scale $u>0$ . We then claim that $\\overline{r}$ can be upper bounded by any $r$ satisfying ", "page_idx": 29}, {"type": "equation", "text": "$$\n{\\frac{50}{\\sqrt{m}}}\\cdot\\int_{r/16}^{1}{\\sqrt{\\log\\!{\\mathcal{N}}_{m,\\infty}({\\mathcal{F}},u)}}d u\\leq r.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We also claim that for any $r>\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})$ , the following holds: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\int_{r/16}^{1}\\sqrt{\\log\\mathcal{N}_{m,\\infty}(\\mathcal{F},u)}d u\\leq C\\sqrt{\\log(m)}\\cdot\\left(\\int_{r}^{1}\\frac{\\sqrt{\\log\\left(\\frac{c m}{u}\\right)}}{u}d u\\right)\\cdot\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "for some universal constant $C$ . We now suppose that (15) and (16) hold and set $r\\,=\\,C m^{-1/2}$ \u00b7 $\\log^{3}(m)\\cdot\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})$ . Then it is immediate that $r$ is a member of the set in (14). ", "page_idx": 29}, {"type": "text", "text": "We now prove the two claims. ", "page_idx": 29}, {"type": "text", "text": "Proof that a solution to (15) is an upper bound on $\\overline{r}$ . By a standard Dudley Chaining argument [Van Handel, 2014, Wainwright, 2019], it holds that ", "text_level": 1, "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{1}_{\\xi}\\left[\\operatorname*{sup}_{\\underline{{f}}\\in\\mathcal{F}}\\ \\frac{1}{m}\\cdot\\sum_{i=1}^{m}\\xi_{i}f(Z_{i})^{2}\\right]\\leq\\operatorname*{inf}_{u>0}\\left\\{4u+\\frac{12}{\\sqrt{m}}\\cdot\\int_{u}^{r}\\sqrt{\\log\\mathcal{N}_{m,\\infty}(\\mathcal{F}^{2}\\cap\\left\\{\\|f\\|_{m}^{2}\\leq r^{2}\\right\\},u)}d u\\right\\}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Letting $\\begin{array}{r}{f_{1},\\ldots,f_{M}\\in\\mathcal{F}\\cap\\left\\{\\|f\\|_{m}^{2}\\leq r^{2}\\right\\}}\\end{array}$ be a proper $u$ -cover of $\\mathcal{F}\\cap\\left\\{\\|f\\|_{m}^{2}\\leq r^{2}\\right\\}$ with respect to $\\|\\cdot\\|_{m,\\infty}$ at scale $s\\leq r$ and $\\pi:\\mathcal{F}\\rightarrow\\{\\dot{f}_{i}\\}$ be projection to the cover, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\left\\|f^{2}-\\pi(f)^{2}\\right\\|_{m}^{2}\\leq s^{2}\\cdot\\left\\|f+\\pi(f)\\right\\|_{m}^{2}\\leq4s^{2}r^{2}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "by factoring $f^{2}-\\pi(f)^{2}=(f-\\pi(f))(f+\\pi(f))$ . In particular, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\ensuremath{\\mathcal{N}}_{m,2}(\\ensuremath{\\mathcal{F}}^{2}\\cap\\left\\{\\|f\\|_{m}^{2}\\leq r^{2}\\right\\},2u r)\\leq\\ensuremath{\\mathcal{N}}_{m,\\infty}(\\ensuremath{\\mathcal{F}}\\cap\\left\\{\\ensuremath{\\mathcal{F}}^{2}\\cap\\left\\{\\|f\\|_{m}^{2}\\leq r^{2}\\right\\}\\right\\},u)\\leq\\ensuremath{\\mathcal{N}}_{m,\\infty}(\\ensuremath{\\mathcal{F}},u),}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where we used the fact that a proper covering at scale $\\varepsilon$ has size bounded by a covering at scale $\\varepsilon/2$ by the triangle inequaltiy. Substituting into (17) and rescaling yields the claim. ", "page_idx": 29}, {"type": "text", "text": "Proof that (16) holds. This proof goes through fat shattering numbers, a complexity measure taking a function class and a scale $u\\,>\\,0$ and returns $\\mathbf{fat}(\\mathcal{F},u)\\in\\mathbb{N}$ [Bartlett et al., 1994]. We do not need the full definition of fat shattering numbers and defer to [Bartlett et al., 1994, Srebro et al., 2010, Rudelson and Vershynin, 2006] for details. We only need the following two properties. First, for any $u>0$ , it holds by Rudelson and Vershynin [2006] that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\log\\mathcal{N}_{m,\\infty}(\\mathcal{F},u)\\leq C\\cdot\\mathsf{f a t}(\\mathcal{F},c u)\\cdot\\log(m)\\cdot\\log\\left(\\frac{m}{\\mathsf{f a t}(\\mathcal{F},c u)u}\\right).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Second, by Srebro et al. [2010, Lemma A.2], for all $r>m^{-1/2}\\cdot\\overline{{\\mathcal{G}}}_{m}(\\mathcal{F})$ , ", "page_idx": 29}, {"type": "equation", "text": "$$\nr^{2}\\cdot\\mathsf{f a t}({\\mathcal F},r)\\leq4\\cdot\\overline{{{\\mathcal G}}}_{m}({\\mathcal F})^{2}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Plugging (18) into the left hand side of (16) and then applying (19) concludes the proof of the claim. ", "page_idx": 29}, {"type": "text", "text": "D Classification and Analysis of RRSPM ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In this section, we provide full proofs for the guarantees of Algorithm 4. In Section D.1, we describe the concept of universal identification sets and the result of Neel et al. [2019] which plays a crucial role in the privacy analysis of our algorithm. In Section D.2, we formally prove Lemma 6 which is the technical lemma used for the proof of differential privacy based on Neel et al. [2019]. We then continue in Section D.3 by applying standard learning theoretic techniques to demonstrate that our algorithm is an accurate classifier. ", "page_idx": 30}, {"type": "text", "text": "D.1 Universal Identification Set based Algorithm ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In this section, we formally define universal identification sets and informally describe the algorithm used in Neel et al. [2019]. Intuitively, a universal identification set captures the combinatorial property of a function class that all distinct functions in the function class disagree on at least one point from the data universe. For many natural classes, the size of the universal identification set is proportional to the VC dimension of the function class. ", "page_idx": 30}, {"type": "text", "text": "We now describe the algorithm from Neel et al. [2019] and explain the usefulness of universal identification sets. First, we formally define the notion of universal identification set. ", "page_idx": 30}, {"type": "text", "text": "Definition 9. (Universal Identification Set) A set $\\mathcal{U}\\subseteq\\;\\mathcal{X}$ is a universal identification set for a hypothesis class $\\mathcal{F}$ if for all pairs of functions $f,f^{\\prime}$ in the hypothesis class $\\mathcal{F}$ , there is a $x\\in\\mathcal{U}$ such that: ", "page_idx": 30}, {"type": "equation", "text": "$$\nf(x)\\neq f^{\\prime}(x).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Additionally, if $|\\mathcal{U}|=m$ , we say that $\\mathcal{F}$ has a universal identification set of size $m$ ", "page_idx": 30}, {"type": "text", "text": "Assuming the existence of a universal identification set for the function class $\\mathcal{F}$ of size $m$ denoted by ${\\mathcal{U}}=\\{U_{1},\\d...,U_{m}\\}$ , Neel et al. [2019] showed that the following algorithm(called RSPM) is an $\\varepsilon-$ pure differentially private and $(\\alpha,\\beta)$ -accurate algorithm. ", "page_idx": 30}, {"type": "text", "text": "Algorithm 5: RSPM   \n1: Input ERM oracle ERM, dataset $\\mathcal{D}=\\{(X_{i},Y_{i})\\mid1\\leq i\\leq n\\}$ , hypothesis class $\\mathcal{F}$ , universal identification set $\\mathcal{U}=\\{U_{1},\\dotsc,U_{m}\\}$ , loss function $\\ell:\\mathcal{V}\\times\\mathcal{V}\\rightarrow\\{0,1\\}$ .   \n2: Draw weights $\\pmb{\\xi}=\\{\\xi_{1},\\dots,\\xi_{m}\\}$ such that $\\xi_{i}\\sim\\mathrm{Lap}(2m/\\varepsilon)$ .   \n3: Draw labels $\\tilde{Y}=\\{\\tilde{Y}_{1},\\...,\\tilde{Y}_{m}\\}$ such that $\\tilde{Y}_{i}\\sim\\mathrm{Uni}(\\{0,1\\})$ .   \n4: Define $\\mathcal{L}_{\\xi,\\mathcal{D},\\mathcal{U}}:\\mathcal{F}\\rightarrow\\mathbb{R}$ such that $\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\mathcal{U}}(f)=\\sum_{i=1}^{n}\\ell(f(X_{i}),Y_{i})+\\sum_{i=1}^{m}\\xi_{i}\\cdot\\ell(f(U_{i}),\\tilde{Y}_{i}).$   \n5: Get $\\hat{f}=\\mathsf E\\mathsf{R M}(\\mathcal F,\\mathcal L_{\\pmb{\\xi},\\mathcal D,\\mathcal U})$ . ", "page_idx": 30}, {"type": "text", "text": "RSPM roughly simulates \u201cReport-Noisy-Min\u201d(Dwork et al. [2014]) attempting to output a function that minimizes a perturbed estimate, where the perturbation is sampled from a Laplace distribution. A straight forward implementation of \u201cReport-Noisy-Min\" to minimize over all perturbed estimates of functions, it\u2019d have to check for all functions in $\\mathcal{F}$ and thus the computational complexity would depend on the size of $\\mathcal{F}$ . RSPM avoids this problem by implicitly perturbing the function evaluations via an augmented dataset. The proof of privacy thus exploits the structure of the universal identification set. ", "page_idx": 30}, {"type": "text", "text": "Although many natural function classes have bounded universal identification sets, their existence is not as general as having bounded VC dimension. In our work, we only assume finite VC dimension of the function class. ", "page_idx": 30}, {"type": "text", "text": "D.2 Privacy Analysis ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In this section, we prove that Algorithm 4 is differentially private. A notion that we will need is that of a projection of a hypothesis class onto a set of points from the domain. ", "page_idx": 30}, {"type": "text", "text": "Definition 10. (Projection) Given a hypothesis class ${\\mathcal{F}}\\subseteq{\\mathcal{V}}^{|{\\mathcal{X}}|}$ and a subset $Z=\\{z_{1},\\ldots z_{m}\\}$ of the feature space $\\mathcal{X}$ , we define the projection of $\\mathcal{F}$ onto $Z$ to be $\\mathcal{F}|_{Z}=\\{(f(z_{1}),\\dots,\\bar{f}(z_{m})):f\\in\\mathcal{F}\\}$ . ", "page_idx": 31}, {"type": "text", "text": "In the following sections, we will interchangeably think of the projection of a hypothesis class onto a set of points $Z$ as a set of functions on $Z$ or as a set of vectors in $\\mathcal{V}^{|Z|}$ . ", "page_idx": 31}, {"type": "text", "text": "By construction, $\\mathcal{F}|_{Z}$ has the property that any two distinct functions $f\\neq f^{\\prime}\\in\\mathcal{F}|_{Z}$ must disagree on at least one point $z\\in Z$ . We encapsulate this as the following lemma. ", "page_idx": 31}, {"type": "text", "text": "Lemma 17. Let $\\mathcal{F}$ be a hypothesis class and let $Z=\\{z_{1},\\ldots,z_{m}\\}$ be a set of points in the instance space $\\mathcal{X}$ . Then, for all $f\\neq f^{\\prime}\\in{\\mathcal{F}}|_{Z}$ , there exists $z\\in Z$ such that $f(z)\\neq f^{\\prime}(z)$ . ", "page_idx": 31}, {"type": "text", "text": "Remark 2. This property is analogous to the notion of a universal identification set considered in Neel et al. [2019]. In particular, the above lemma can be seen as the statement that the set $Z$ is a universal identification set for the class $\\mathcal{F}|_{Z}$ . ", "page_idx": 31}, {"type": "text", "text": "We first provide an informal sketch of the proof of privacy. In the later sections, we formalize these ideas. Let ${\\hat{f}}\\,\\in\\,{\\mathcal{F}}$ be any arbitrary function and let $\\mathcal{D},\\mathcal{D}^{\\prime}$ be any pair of neighbouring datasets. We show that $\\mathbb{P}(\\mathsf{R R S P M}(\\mathcal D)\\;=\\;\\hat{f})\\;\\leq\\;e^{\\varepsilon}\\mathbb{P}(\\mathsf{R R S P M}(\\mathcal D^{\\prime})\\;=\\;\\hat{f})$ . By the definition of the projection, there is some $\\tilde{f}\\,\\in\\,\\mathcal{F}|_{\\tilde{D}_{x}}$ that is consistent with the labelling of the selected function $\\hat{f}$ . $\\mathbb{P}(\\mathtt{E R M}(\\mathcal{F},\\mathcal{L}_{\\xi,\\mathcal{D},\\tilde{D}})\\,=\\,\\tilde{f})\\,\\le\\,e^{\\varepsilon}\\mathbb{P}(\\mathtt{E R M}(\\mathcal{F},\\mathcal{L}_{\\xi,\\mathcal{D}^{\\prime},\\tilde{D}})\\,=\\,\\tilde{f})$ since privacy for $\\hat{f}$ follows from the post-processing property of differential privacy. ", "page_idx": 31}, {"type": "text", "text": "We now provide with a proof sketch for the main technical lemma showing that the privacy is preserved over the projected function class. Optimizing a loss function perturbed by Laplace-weighted examples implicitly tries to implement \u201cReport-Noisy-Min\u201d algorithm outputting a function that minimizes a perturbed estimate. For any neighbouring datasets $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ , the evaluation of any function $\\tilde{f}$ can differ by at most 1. We show that the set of public points $\\tilde{\\mathcal{D}}$ is a universal identification set for the set of functions projected onto $\\tilde{\\mathcal{D}}$ and leverage this to prove that whenever the shift in the noise vectors is bounded by 2 in every coordinate, then $\\tilde{f}$ is the minimizing function when switching from $\\mathcal{D}$ to $\\mathcal{D}^{\\prime}$ . This intuition is made precise in Lemma 18. ", "page_idx": 31}, {"type": "text", "text": "Lemma 18. Let $\\mathcal{D},\\mathcal{D}^{\\prime}$ be two neighbouring data sets, and let $\\tilde{D}\\;\\;=\\;\\;(\\tilde{D}_{x},\\tilde{D}_{y})\\;\\;\\in\\;\\;(\\mathcal{X}\\;\\times$ $\\{0,1\\})^{m}$ where $\\tilde{D}_{x}\\;\\;=\\;\\;\\{Z_{1},\\dots,Z_{m}\\}$ and $\\tilde{D}_{y}\\;\\;=\\;\\;\\{\\tilde{Y}_{1},\\ldots,\\tilde{Y}_{m}\\}$ . Define $\\mathcal{E}(f_{\\tilde{D}},\\mathcal{D},\\tilde{D})\\;\\;=\\;\\;$ $\\left\\{\\pmb{\\xi}:\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}},\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{D}})=f_{\\tilde{\\mathcal{D}}}\\right\\}$ , where $\\mathcal{L}_{\\boldsymbol{\\xi},\\mathcal{D},\\tilde{D}}$ is a functional as defined below: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{\\mathcal{D}}}(\\boldsymbol{f})=\\sum_{i=1}^{n}\\ell(\\boldsymbol{f}(\\boldsymbol{X}_{i}),\\boldsymbol{Y}_{i})+\\sum_{i=1}^{m}\\xi_{i}\\cdot\\ell(\\boldsymbol{f}(\\boldsymbol{Z}_{i}),\\tilde{\\boldsymbol{Y}}_{i}).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Let $\\pmb{\\xi}\\,=\\,\\{\\xi_{1},\\dots,\\xi_{m}\\}$ such that $\\xi_{i}\\,\\sim\\,\\mathrm{Lap}(2m/\\varepsilon)$ . Given a fixed $f_{\\tilde{\\mathcal{D}}}\\,\\in\\,\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ , define a mapping $\\Psi_{f_{\\tilde{D}}}(\\pmb{\\xi}):\\mathbb{R}^{m}\\rightarrow\\mathbb{R}^{m}$ on noise vectors as follows: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{I.\\ \\,i f\\ell(f_{\\tilde{\\mathcal{D}}}(Z_{i}),\\tilde{Y}_{i})=1,\\Psi_{f_{\\tilde{\\mathcal{D}}}}(\\pmb{\\xi})_{i}=\\xi_{i}-2}\\\\ {2.\\ \\,i f\\ell(f_{\\tilde{\\mathcal{D}}}(Z_{i}),\\tilde{Y}_{i})=0,\\Psi_{f_{\\tilde{\\mathcal{D}}}}(\\pmb{\\xi})_{i}=\\xi_{i}+2}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Equivalently, $\\Psi_{f_{\\tilde{\\mathcal{D}}}}(\\pmb{\\xi})_{i}\\ =\\ \\xi_{i}\\,+\\,2(1\\,-\\,2\\ell(f_{\\tilde{\\mathcal{D}}}(Z_{i}),\\tilde{Y}_{i}))$ . Let $\\pmb{\\xi}\\;\\in\\;\\mathcal{E}\\left(f_{\\tilde{D}},\\mathcal{D},\\tilde{\\mathcal{D}}\\right)$ where $f_{\\tilde{\\mathcal{D}}}~\\in$ $\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{D}_{x}},\\mathcal{L}_{\\xi,\\mathcal{D},\\tilde{D}})$ . Then $\\Psi_{f_{\\tilde{\\mathcal{D}}}}(\\pmb{\\xi})\\in\\mathcal{E}(f_{\\tilde{\\mathcal{D}}},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}})$ . ", "page_idx": 31}, {"type": "text", "text": "Proof. Let $\\Psi_{f_{\\tilde{\\mathcal{D}}}}(\\pmb{\\xi})\\;=\\;\\pmb{\\xi}^{\\prime}\\;=\\;(\\xi_{1}^{\\prime},\\ldots\\xi_{m}^{\\prime})$ . Our goal is to show that for every $f\\;\\in\\;\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ such that $f\\neq f_{\\tilde{\\mathcal{D}}}$ , we have $\\mathcal{L}_{\\pmb{\\xi}^{\\prime},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}}}(\\boldsymbol{f})\\,>\\,\\mathcal{L}_{\\pmb{\\xi}^{\\prime},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}}}(f_{\\tilde{\\mathcal{D}}})$ . First, recall that by our assumption for all $f\\in\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{\\mathcal{D}}}(f)>\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{\\mathcal{D}}}(f_{\\tilde{\\mathcal{D}}}).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We now argue that $\\mathcal{L}_{\\pmb{\\xi}^{\\prime},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}}}(\\boldsymbol{f})\\!-\\!\\mathcal{L}_{\\pmb{\\xi}^{\\prime},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}}}(\\boldsymbol{f}_{\\tilde{\\mathcal{D}}})$ is strictly positive for all $f\\in\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ such that $f_{\\tilde{D}}\\neq f$ . To see this we calculate, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{C_{\\xi^{\\prime},\\mathcal{V}^{\\prime},\\bar{D}}(f)-C_{\\xi^{\\prime},\\mathcal{V}^{\\prime},\\bar{D}}(f_{\\overline{{D}}})=\\displaystyle\\sum_{(x,Y)\\in\\mathcal{V}^{\\prime}}\\ell(f(X),Y)+\\displaystyle\\sum_{i=1}^{m}\\xi_{i}^{\\prime},\\,\\ell(f(Z_{i}),\\bar{Y}_{i})}\\\\ {-\\displaystyle\\sum_{(x,Y)\\in\\mathcal{V}^{\\prime}}\\ell(f_{\\bar{D}}(X),Y)-\\displaystyle\\sum_{i=1}^{m}\\xi_{i}^{\\prime},\\,\\ell(f_{\\bar{D}}(Z_{i}),\\bar{Y}_{i})}\\\\ {\\ge\\displaystyle C_{\\xi,\\mathcal{V},\\bar{D}}(f)-1+\\displaystyle\\sum_{i=1}^{m}\\xi_{i}^{\\prime},\\,\\ell(f(Z_{i}),\\bar{Y}_{i})-\\xi_{i}\\cdot\\ell(f(Z_{i}),\\bar{Y}_{i})}\\\\ {-\\displaystyle C_{\\xi,\\mathcal{V},\\bar{D}}(f_{\\bar{D}})-1-\\displaystyle\\sum_{i=1}^{m}\\xi_{i}^{\\prime},\\,\\ell(f_{\\bar{D}}(Z_{i}),\\bar{Y}_{i})+\\xi_{i}\\cdot\\ell(f_{\\bar{D}}(Z_{i}),\\bar{Y}_{i})}\\\\ {>-2+\\displaystyle\\sum_{i=1}^{m}(\\xi_{i}^{\\prime}-\\xi_{i})\\left(\\ell(f(Z_{i}),\\bar{Y}_{i})\\right)-\\ell(f_{\\bar{D}}(Z_{i}),\\bar{Y}_{i})\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the second inequality follows from the fact that $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ differ in only one entry and $\\ell$ is $1-$ sensitive. The last equation follows from statement 20. ", "page_idx": 32}, {"type": "text", "text": "We know from Lemma 17 that there exists a $Z\\in{\\tilde{\\mathcal{D}}}$ such that $f(Z)\\neq f_{\\tilde{D}}(Z)$ . Recall that $\\xi_{i}^{\\prime}=$ $\\xi_{i}+2(1-2\\ell(f_{\\tilde{\\cal D}}(Z_{i}),\\tilde{Y}_{i}))$ . By construction, each term is non-negative. Therefore, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}(\\xi_{i}^{\\prime}-\\xi_{i})\\left(\\ell(f(Z_{i}),\\tilde{Y}_{i}))-\\ell(f_{\\tilde{\\cal D}}(Z_{i}),\\tilde{Y}_{i})\\right)>2.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "To wrap up, we can bound ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\pmb{\\xi}^{\\prime},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}}}(f)-\\mathcal{L}_{\\pmb{\\xi}^{\\prime},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}}}(f_{\\tilde{\\mathcal{D}}})>0.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "This proves that $\\Psi_{f_{\\tilde{\\mathcal{D}}}}(\\pmb{\\xi})\\in\\mathcal{E}(f_{\\tilde{\\mathcal{D}}},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}})$ . ", "page_idx": 32}, {"type": "text", "text": "Lemma 19 (Laplace shift). Let $\\pmb{\\xi}\\,=\\,\\{\\xi_{1},\\dots,\\xi_{m}\\}$ such that $\\displaystyle\\xi_{i}\\,\\sim\\,\\mathrm{Lap}(2m/\\varepsilon)$ . Fix some noise realization $\\mathbf{r}\\in\\mathbb{R}^{m}$ and fix $a$ hypothesis in the projection set $f\\in\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ . Then, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\pmb{\\xi}=\\mathbf{r})\\leq e^{\\varepsilon}\\mathbb{P}(\\pmb{\\xi}=\\Psi_{f}(\\mathbf{r})),\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where $\\Psi_{f}(\\pmb{\\xi})_{i}=\\xi_{i}+2(1-2\\ell(f(Z_{i}),\\tilde{Y}_{i}))$ as defined in Lemma 18. ", "page_idx": 32}, {"type": "text", "text": "Proof. Let $i\\in[m]$ be any index and let $\\mathbf{r}\\in\\mathbb{R}^{m}$ . Since $\\xi_{i}\\sim\\mathrm{Lap}(2m/\\varepsilon)$ , we know ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\xi_{i}=r_{i})=\\frac{\\varepsilon}{4m}\\exp\\left(\\frac{-|r_{i}|\\varepsilon}{2m}\\right)\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "For any $t,t^{\\prime}\\in\\mathbb{R}$ such that $|t-t^{\\prime}|\\le2$ , we get ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\xi_{i}=t^{\\prime})\\leq\\exp(\\varepsilon/m)\\mathbb{P}(\\xi_{i}=t)\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Since for all $i\\in[d],|\\Psi_{f}(r)_{i}-r_{i}|\\leq2$ , we get ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{P}(\\pmb{\\xi}=\\Psi_{f}(\\mathbf{r}))}{\\mathbb{P}(\\pmb{\\xi}=\\mathbf{r})}=\\prod_{i=1}^{m}\\frac{\\mathbb{P}(\\xi_{i}=\\Psi_{f}(r)_{i})}{\\mathbb{P}(\\xi_{i}=r_{i})}\\leq\\prod_{i=1}^{m}\\exp(\\varepsilon/m)=\\exp(\\varepsilon).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Our proof of privacy also makes use of the following lemma, which says that minimizers are unique with probability 1 [Neel et al., 2019, Lemma 4]. ", "page_idx": 33}, {"type": "text", "text": "Lemma 20. Let $\\tilde{\\mathcal{D}}=(\\tilde{\\mathcal{D}}_{x},\\tilde{\\mathcal{D}}_{y})\\in(\\mathcal{X}\\times\\{0,1\\})^{m}$ . Consider $\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ , where $\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ is the projection of $\\mathcal{F}$ on $\\tilde{\\mathcal{D}}_{x}$ . For every dataset $\\mathcal{D}$ , there is a subset $B\\subseteq\\mathbb{R}^{m}$ such that: ", "page_idx": 33}, {"type": "text", "text": "\u2022 $\\mathbb{P}(\\pmb{\\xi}\\in B)=0$ and   \n\u2022 On the restricted domain $\\mathbb{R}^{m}\\mathrm{~\\Large~\\vdash~}\\mathrm{~\\it~B~}$ , there is a unique minimizer $\\arg\\operatorname*{min}_{f\\in\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}}\\mathcal{L}_{\\xi,\\mathcal{D},\\tilde{\\mathcal{D}}}(f)$ . ", "page_idx": 33}, {"type": "text", "text": "Using standard results about Laplace perturbations stated in Lemma 19 and Lemma 20 and using the perturbation coupling bound in Lemma 18, we get the our formal statement of privacy for optimizing over the projected function class as follows: ", "page_idx": 33}, {"type": "text", "text": "Lemma 21. (Privacy over Projection) Let $\\mathcal{D},\\mathcal{D}^{\\prime}$ be arbitrary datasets containing n points each. Let $\\tilde{\\mathcal{D}}=(\\tilde{\\mathcal{D}}_{x},\\tilde{\\mathcal{D}}_{y})\\in(\\mathcal{X}\\times\\{0,\\dot{1}\\})^{m}$ . Then, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}},\\mathcal{L}_{\\boldsymbol{\\xi},\\mathcal{D},\\tilde{\\mathcal{D}}})=f)\\le e^{\\varepsilon}\\mathbb{P}(\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}},\\mathcal{L}_{\\boldsymbol{\\xi},\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}}})=f).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. We calculate, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\nabla(\\mathrm{EHM}(F|_{\\mathcal{S}_{r}},\\mathcal{L}_{\\xi,D,\\xi}))=f)=\\left.\\nabla(\\xi\\in\\mathcal{E}(f,\\mathcal{D},\\hat{D})\\right)}\\\\ &{=\\int_{\\mathcal{M}^{-1}}\\nabla(\\xi\\in\\mathcal{E}(f,\\mathcal{D},\\hat{D}))d\\xi}\\\\ &{=\\int_{\\mathcal{M}^{-1}}\\nabla(\\xi)\\|(\\xi\\in\\mathcal{E}(f,\\mathcal{D},\\hat{D}))d\\xi}\\\\ &{\\leq\\int_{\\mathcal{M}^{-1}\\backslash D}\\nabla(\\xi)\\|(\\Psi_{f}(\\xi)\\in\\mathcal{E}(f,\\mathcal{D}^{\\prime},\\hat{D}))d\\xi}\\\\ &{\\leq\\int_{\\mathcal{M}^{-1}\\backslash D}e^{\\mathrm{i}}\\nabla(\\Psi_{f}(\\xi))\\|(\\Psi_{f}(\\xi)\\in\\mathcal{E}(f,\\mathcal{D}^{\\prime},\\hat{D}))d\\xi}\\\\ &{\\leq\\int_{\\mathcal{M}^{-1}\\backslash D}e^{\\mathrm{i}}\\nabla(\\Psi_{f}(\\xi))\\|(\\Psi_{f}\\xi)\\in\\mathcal{E}(f,\\mathcal{D}^{\\prime},\\hat{D})\\|_{\\mathcal{H}}^{2}d\\xi}\\\\ &{\\leq\\int_{\\mathcal{M}^{-1}\\backslash D}\\sum_{i=1}^{\\infty}e^{\\mathrm{i}}[\\xi(\\xi\\in\\mathcal{E}(f,\\mathcal{D}^{\\prime},\\hat{D}))\\frac{\\partial\\hat{\\Psi}_{f}}{\\partial\\xi}d\\xi}\\\\ &{=\\int_{\\mathcal{M}^{-1}\\backslash D}e^{\\mathrm{i}}[\\xi(\\xi\\in\\mathcal{E}(f,\\mathcal{D}^{\\prime},\\hat{D}))d\\xi}\\\\ &{=e^{\\mathrm{i}}\\nabla(\\xi\\in\\mathcal{E}(f,\\mathcal{D}^{\\prime},\\hat{D}))}\\\\ &{=e^{\\mathrm{i}}\\nabla(\\mathrm{EHM}(F),\\xi,\\xi,D,\\xi)-f\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n\\Psi_{f}(B)\\;\\mathrm{has}\\;0\\;\\mathrm{measure},\\;\\left|\\frac{\\partial\\Psi_{f}}{\\partial\\xi}\\right|=1\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Theorem 8. Algorithm $^{4}$ is $\\varepsilon$ -pure differentially private. ", "page_idx": 33}, {"type": "text", "text": "Proof. Let $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ be any neighbouring datasets. Fix any function ${\\hat{f}}\\in{\\mathcal{F}}$ . We now show that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\mathsf{R R S P M}(\\mathcal{D})=\\hat{f})\\leq e^{\\varepsilon}\\mathbb{P}(\\mathsf{R R S P M}(\\mathcal{D}^{\\prime})=\\hat{f}),\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the probability is taken over the randomness of the algorithm. From the definition of the projection, we know that there exists a unique function in the projection say, $\\tilde{f}\\in\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}}$ such that $\\hat{f}(Z_{i})=\\tilde{f}(Z_{i})$ for all $i\\in[m]$ . ", "page_idx": 33}, {"type": "text", "text": "Using Lemma 21, we know that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}},\\mathcal{L}_{\\xi,\\mathcal{D},\\tilde{D}})=\\tilde{f})\\le e^{\\varepsilon}\\mathbb{P}(\\mathsf{E R M}(\\mathcal{F}|_{\\tilde{\\mathcal{D}}_{x}},\\mathcal{L}_{\\xi,\\mathcal{D}^{\\prime},\\tilde{\\mathcal{D}},\\tilde{\\mathcal{D}}_{y}})=\\tilde{f}).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "As defined in the algorithm, let $\\begin{array}{r}{\\tilde{\\mathcal{L}}(f)=\\sum_{i=1}^{m}\\ell(f(Z_{i}),\\tilde{f}(Z_{i}))}\\end{array}$ . From the definition of $\\tilde{\\mathcal{L}}$ , it follows that $\\hat{f}\\in\\underset{f\\in\\mathcal{F}}{\\arg\\operatorname*{min}}\\,\\tilde{\\mathcal{L}}(f)$ . Following the post-processing guarantee of differential privacy, it is easy to see that ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{P}({\\mathsf{R R S P M}}({\\mathcal{D}})={\\hat{f}})\\leq e^{\\varepsilon}\\mathbb{P}({\\mathsf{R R S P M}}({\\mathcal{D}}^{\\prime})={\\hat{f}}).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "D.3 Accuracy Analysis ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "In this section we analyze the accuracy of our algorithm. Let $f^{*}$ denote the function in the hypothesis class that minimizes the loss with respect to the distribution $\\nu$ i.e. $f^{*}\\in\\underset{f\\in\\mathcal{F}}{\\arg\\operatorname*{min}}L_{\\nu}(f)$ . Let $\\hat{f}$ denote the output hypothesis of our algorithm. We show that the loss of $\\hat{f}$ is close to $f^{*}$ with respect to the data generating distribution $\\nu$ . ", "page_idx": 34}, {"type": "text", "text": "As in the algorithm description, let $\\tilde{f}$ be the function that minimizes the perturbed loss. Our algorithm outputs $\\hat{f}$ whose labelling is consistent with $\\tilde{f}$ on the public dataset $\\tilde{\\mathcal{D}}_{x}$ . Since $\\tilde{\\mathcal{D}}_{x}$ is sampled from the base distribution, it follows from VC theorem that $\\hat{f}$ and $\\tilde{f}$ are close under the base distribution $\\mu$ . We show in Lemma 22 that $\\hat{f}$ and $\\tilde{f}$ are close under $\\nu$ by leveraging that $\\nu_{x}$ is a $\\sigma$ -smooth distribution. Using standard results about Laplace perturbations, we show that $f^{\\prime}$ is close to $\\tilde{f}$ in Lemma 23, where $f^{\\prime}$ is the empirical risk minimizer over $\\mathcal{D}$ . Using the VC theorem, it is easy to see that $f^{\\prime}$ is close to $f^{*}$ and consequently using the triangle inequality we finish the proof by showing that $f^{*}$ and $\\hat{f}$ are close under $\\nu$ . ", "page_idx": 34}, {"type": "text", "text": "We now state the VC theorem below which we use in our analysis. ", "page_idx": 34}, {"type": "text", "text": "Theorem 9. Let $\\mathcal{D}\\,=\\,\\{(X_{1},Y_{1}),\\ldots,(X_{n},Y_{n})\\}$ where for all $i\\;\\in\\;[n]$ , $(X_{i},Y_{i})\\;\\in\\;\\mathcal{X}\\times\\{0,1\\}$ are sampled from a fixed distribution $\\nu$ . Let $\\begin{array}{r}{\\dot{L_{D}}(f)\\;=\\;\\frac{1}{n}\\,|\\{i:f(X_{i})^{'}\\!\\neq\\!Y_{i}\\}|}\\end{array}$ and let $L_{\\nu}(f)\\;=\\;$ $\\mathbb{E}_{(X,Y)\\sim\\nu}[\\mathbb{1}(f(X)\\neq Y]$ . If the function class $\\mathcal{F}$ has $V C$ dimension $d$ then, ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{sup}_{f\\in\\mathcal{F}}\\lvert L_{\\mathcal{D}}(f)-L_{\\nu}(f)\\rvert\\leq O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{m}}\\right)\\right)\\geq1-\\beta.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "In particular if $f^{*}\\in\\arg\\operatorname*{min}_{f\\in\\mathcal{F}}L_{\\mathcal{D}}(f)$ then, ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(|L_{\\nu}(f^{*})-\\underset{f\\in\\mathcal{F}}{\\operatorname{arg\\,min}}L_{\\nu}(f)|\\leq O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{m}}\\right)\\right)\\geq1-\\beta.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Lemma 22. Let $\\nu_{x}$ be a $\\sigma$ -smooth distribution that is $\\begin{array}{r}{\\left\\|\\frac{d\\nu_{x}}{d\\mu}\\right\\|\\leq\\frac{1}{\\sigma}}\\end{array}$ . Let $L_{\\nu}$ be the loss function as defined in Defintion 2. Let $\\hat{f}$ be the hypothesis returned by our algorithm and let $\\tilde{f}\\in\\mathsf{E R M}(\\mathcal{F},\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{D}})$ . Then, ", "page_idx": 34}, {"type": "equation", "text": "$$\nL_{\\nu}(\\hat{f})-L_{\\nu}(\\tilde{f})\\leq O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{m\\sigma^{2}}}\\right),\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "with probability $1-\\beta$ . ", "page_idx": 34}, {"type": "text", "text": "Proof. Let $\\begin{array}{r}{\\alpha^{\\prime}=O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{m}}\\right)}\\end{array}$ First we show that | $L(\\hat{f})\\ \\mathrm{~-~}\\ L(\\tilde{f})\\ \\mid\\ \\leq2\\alpha^{\\prime}$ with probability $X\\!\\sim\\!\\mu\\qquad\\quad X\\!\\sim\\!\\mu$ ${\\cal Y}{=}\\tilde{f}(X)\\;\\;\\;\\;\\;\\;Y{=}\\tilde{f}(X)$   \nat least $1-\\beta$ . Consider the dataset $\\hat{D}=\\{(X_{1},\\tilde{f}(X_{1}),\\ldots,(X_{m},\\tilde{f}(X_{m}))\\}$ we minimize over and   \noutput $\\hat{f}$ . Using Theorem 9 we know that, ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(|\\begin{array}{c c c c}{\\underline{{L}}(\\hat{f})}&{-}&{\\underline{{L}}(\\tilde{f})}\\end{array}|\\leq2\\alpha^{\\prime}+|L_{\\hat{D}}(\\hat{f})-L_{\\hat{D}}(\\tilde{f})|\\right)\\geq1-\\beta.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Since $L(\\tilde{f})\\;\\;=0$ and $|L_{\\tilde{\\mathcal{D}}}(\\hat{f})-L_{\\tilde{\\mathcal{D}}}(\\tilde{f})|=0$ and we get that with probability at least $1-\\beta$ , $X\\!\\sim\\!\\mu$ $Y{=}{\\tilde{f}}(X)$ ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{P}_{X\\sim\\mu}(\\hat{f}(x)\\neq\\tilde{f}(x))\\le2\\alpha^{\\prime}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We now show that $\\mathbb{P}_{X\\sim\\nu_{x}}(\\hat{f}(x)\\neq\\tilde{f}(x))\\le2\\alpha^{\\prime}/\\sigma$ with probability at least $1-\\beta$ . ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{P}_{X\\sim\\nu_{x}}(\\hat{f}(x)\\neq\\hat{f}(x))=\\mathbb{E}_{X}\\sim\\nu_{x}[\\mathbb{1}(\\hat{f}(x)\\neq\\hat{f}(x))]}}\\\\ &{=\\sum_{x\\in\\mathcal{X}}\\mathbb{P}(\\nu_{x}=X)\\mathbb{1}(\\hat{f}(x)\\neq\\hat{f}(x))}\\\\ &{\\leq\\frac{1}{\\sigma}\\sum_{x\\in\\mathcal{X}}\\mathbb{P}(\\mu=X)\\mathbb{1}(\\hat{f}(x)\\neq\\tilde{f}(x))}\\\\ &{=\\frac{1}{\\sigma}\\left(\\mathbb{E}_{X}\\sim\\mu[\\mathbb{1}(\\hat{f}(x)\\neq\\tilde{f}(x))]\\right)}\\\\ &{=\\frac{1}{\\sigma}\\left(\\mathbb{P}_{X\\sim\\mu}(\\hat{f}(x)\\neq\\tilde{f}(x))\\right)}\\\\ &{\\leq\\frac{2\\alpha}{\\sigma}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Having shown that with probability at least $1-\\beta$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}_{X\\sim\\nu_{x}}(\\hat{f}(x)\\neq\\tilde{f}(x))\\le2\\alpha^{\\prime}/\\sigma,\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "we now prove that with probability at least $1-\\beta$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r l}{|~L(\\hat{f})~~-~~L(\\tilde{f})~|\\leq2\\alpha^{\\prime}/\\sigma.}\\\\ {X{\\sim}\\nu_{x}}&{~X{\\sim}\\nu_{x}}\\\\ {Y{\\sim}\\nu_{y}|X}&{~Y{\\sim}\\nu_{y}|X}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "which is equivalent to the theorem statement. Using the triangle inequality we get ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{X\\sim\\nu_{y}|X}{\\overset{L(\\hat{f})}{\\prod}}\\,-\\,}&{L(\\tilde{f})\\,\\underset{X\\sim\\nu_{y}|X}{\\overset{X\\sim}{\\prod}}\\,}\\\\ {\\underset{Y\\sim\\nu_{y}|X}{\\overset{X\\sim\\nu_{x}}{\\prod}}\\,}&{Y\\sim\\nu_{y}|X}\\\\ &{\\qquad\\qquad=\\mathbb{E}_{X\\sim\\nu_{x}}[\\mathbb{I}(\\tilde{f}(X)\\neq\\hat{f}(X))]}\\\\ &{\\qquad\\qquad=2\\alpha^{\\prime}/\\sigma}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the second equation follows from the observation that for any value of $X$ , if ${\\hat{f}}(X)={\\tilde{f}}(X)$ then the difference of the probabilities equate to 0 and if ${\\hat{f}}(X)\\neq{\\tilde{f}}(X)$ then the difference of the probabilities equate to 1 and the last equation follows from Equation 22. ", "page_idx": 35}, {"type": "text", "text": "Substituting the value of $\\alpha^{\\prime}$ proves that with probability $1-\\beta$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\nL_{\\nu}(\\hat{f})-L_{\\nu}(\\tilde{f})\\leq O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{m\\sigma^{2}}}\\right).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Lemma 23. Let $\\mathcal{F}$ be a function class with $V C$ dimension $d.$ . Let $\\mathcal{D}=\\{(X_{1},Y_{1}),\\ldots,(X_{n},Y_{n})\\}$ and $\\tilde{D}_{x}=\\{Z_{1},\\ldots,Z_{m}\\}$ where $Z_{i}\\sim\\mu,$ . Let $L_{\\mathcal{D}}$ be the loss function as defined in Definion 2. Let $f^{\\prime}\\in\\mathsf{E R M}(\\mathcal{F},\\mathcal{L}_{\\mathcal{D}})$ and let $\\tilde{f}\\in\\mathsf{E R M}(\\mathcal{F},\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{D}})$ then, ", "page_idx": 35}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}}(\\tilde{f})-L_{\\mathcal{D}}(f^{\\prime})\\leq\\frac{4m^{2}\\log(m/\\beta)}{\\varepsilon n},\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "with probability $1-\\beta$ . ", "page_idx": 35}, {"type": "text", "text": "Proof. Following the algorithm we know that for all $i\\,\\in\\,[m],\\xi_{i}\\,\\sim\\,\\mathrm{Lap}(2m/\\varepsilon)$ . Using Chernoff\u2019s bound and a union bound we get that with probability $1-\\beta$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\forall i\\in[m],|\\xi_{i}|\\leq\\frac{2m\\log(m/\\beta)}{\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Since $\\tilde{f}(Z_{i})\\in\\{0,1\\}$ for all $Z_{i}\\in\\tilde{\\mathcal{D}}$ , with probability $\\begin{array}{r}{1-\\beta,\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{D}}(\\tilde{f})\\geq\\mathcal{L}_{\\mathcal{D}}(\\tilde{f})-m\\cdot\\frac{2m\\log\\left(m/\\beta\\right)}{\\varepsilon}.}\\end{array}$ . Similarly, $\\begin{array}{r}{\\mathcal{L}_{\\pmb{\\xi},\\mathcal{D},\\tilde{D}}(\\boldsymbol{f}^{\\prime})\\leq\\mathcal{L}_{\\mathcal{D}}(\\boldsymbol{f}^{\\prime})+m\\cdot\\frac{2m\\log(m/\\beta)}{\\varepsilon}}\\end{array}$ . Dividing by $n$ and combining the bounds we get, ", "page_idx": 36}, {"type": "equation", "text": "$$\nL_{\\mathcal{D}}(\\tilde{f})-L_{\\mathcal{D}}(f^{\\prime})\\leq\\frac{4m^{2}\\log(m/\\beta)}{\\varepsilon n},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "with probability $1-\\beta$ . ", "page_idx": 36}, {"type": "text", "text": "Theorem 10. Let $\\hat{f}$ be as defined in Algorithm with $\\mathcal{D}$ sampled from some distribution \u03bd such that $\\begin{array}{r}{\\left\\|\\frac{d\\nu_{x}}{d\\mu}\\right\\|\\leq\\frac{1}{\\sigma}}\\end{array}$ . Suppose the function class $\\mathcal{F}$ has VC-dimension $d$ then setting ", "page_idx": 36}, {"type": "equation", "text": "$$\nm={\\cal O}\\left(\\frac{d+\\log(1/\\beta)}{\\alpha^{2}\\sigma^{2}}\\right)\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "yields an $\\varepsilon$ - pure differentially private $(\\alpha,\\beta)$ -learner as long as ", "page_idx": 36}, {"type": "equation", "text": "$$\nn\\geq\\tilde{\\Omega}\\left(\\frac{d^{2}\\log(1/\\beta)}{\\alpha^{5}\\sigma^{4}\\varepsilon}\\right),\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $\\tilde{\\Omega}$ hides log factors. ", "page_idx": 36}, {"type": "text", "text": "Proof. Let $\\nu$ be the distribution from which the given dataset $\\mathcal{D}$ is sampled where $\\begin{array}{r}{\\left\\|\\frac{d\\nu_{x}}{d\\mu}\\right\\|\\leq\\frac{1}{\\sigma}}\\end{array}$ . Let $\\hat{f}$ be the output of our algorithm, $f^{\\prime}\\in\\underset{f\\in\\mathcal{F}}{\\arg\\operatorname*{min}}\\mathcal{L}_{\\mathcal{D}}(f),\\,f^{*}$ be the target function from our function class $\\mathcal{F}$ and $\\tilde{f}\\,\\in\\,\\underset{f\\in\\mathcal{F}}{\\arg\\operatorname*{min}}\\mathcal{L}_{\\xi,\\mathcal{D},\\tilde{D}}(f)$ . We wish to compare the guarantee of the function $\\hat{f}$ with respect to the function $f^{*}$ with respect to the distribution $\\nu$ i.e. $|L_{\\nu}(\\hat{h})-L_{\\nu}(f^{*})|$ . ", "page_idx": 36}, {"type": "text", "text": "In our analysis below, we break the loss function several times using triangle inequality and bound each term using previously stated results via a union bound. ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{\\nu}(\\hat{f})-L_{\\nu}(f^{*})|}\\\\ &{\\leq|L_{\\nu}(\\hat{f})-L_{\\nu}(\\tilde{f})|+|L_{\\nu}(\\tilde{f})-L_{\\mathcal{D}}(\\tilde{f})|+|L_{\\mathcal{D}}(\\tilde{f})-L_{\\mathcal{D}}(f^{\\prime})|+|L_{\\mathcal{D}}(f^{\\prime})-L_{\\nu}(f^{*})|}\\\\ &{\\leq\\underbrace{O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{\\sigma^{2}m}}\\right)}_{\\mathrm{Lemma~22}}+\\underbrace{O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{n}}\\right)}_{\\mathrm{Theorem~9}}+\\underbrace{O\\left(\\frac{m^{2}\\log(m/\\beta)}{\\varepsilon n}\\right)}_{\\mathrm{Lemma~23}}+\\underbrace{O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{n}}\\right)}_{\\mathrm{Theorem~9}}}\\\\ &{=O\\left(\\sqrt{\\frac{d+\\log(1/\\beta)}{\\sigma^{2}m}}+\\sqrt{\\frac{d+\\log(1/\\beta)}{n}}+\\frac{m^{2}\\log(m/\\beta)}{\\varepsilon n}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Setting ", "page_idx": 36}, {"type": "equation", "text": "$$\nm=O\\left(\\frac{d+\\log(1/\\beta)}{\\alpha^{2}\\sigma^{2}}\\right),\\;n=O\\left(\\frac{d^{2}\\log d\\cdot\\log(1/\\beta)}{\\alpha^{5}\\sigma^{4}\\varepsilon}\\right)\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "and combining the guarantee from Theorem 8 we get that RRSPM (Algorithm 4) is a $\\varepsilon$ - pure differentially private $(\\alpha,\\beta)$ -learner. \u53e3 ", "page_idx": 36}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The abstract and introduction accurately captures all the contributions of the paper. All the claims are formally stated in the main body and the appendix of the paper. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 37}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: The limitations are that the work requires public, unlabelled data and that the statistical rates of our efficient algorithms do not match those achievable by inefficient methods. Both limitations are stated clearly and repeatedly throughout the text. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 37}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: Proof sketches are provided in the main body and detailed arguments are found in the appendix. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 38}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: Did not run experiments. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 38}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: Did not run experiments. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 39}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: Did not run experiments. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 39}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: Did not run experiments. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 39}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: Did not run experiments. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 40}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: Evident. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 40}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: Evident. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. \u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. ", "page_idx": 40}, {"type": "text", "text": "\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 41}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: Does not apply. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 41}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: Does not apply. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 41}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 42}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA]   \nJustification: Does not apply. Guidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 42}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] Justification: Does not apply. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 42}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] Justification: Does not apply. ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 42}]