[{"figure_path": "UTNZKl5BUc/figures/figures_3_1.jpg", "caption": "Figure 1: A schematic view of the proposed procedure for our manifold-constrained DRO. A restricted adversarial block, modeled by fp, tries to perturb the source distribution at each step i to prepare the algorithm for the worst possible distribution in step i + 1. Meanwhile, a classifier fc tries to learn a classifier based on the perturbed distribution.", "description": "This figure illustrates the workings of the manifold-constrained DRO method for gradual domain adaptation.  It shows how a restricted adversarial block (fp) perturbs the source distribution at each step to prepare for the worst-case scenario in the next step.  Simultaneously, a classifier (fc) learns from this perturbed distribution. This process aims to improve the robustness and adaptability of the classifier across gradually shifting domains.", "section": "5 Experimental Results"}, {"figure_path": "UTNZKl5BUc/figures/figures_8_1.jpg", "caption": "Figure 1: A schematic view of the proposed procedure for our manifold-constrained DRO. A restricted adversarial block, modeled by fp, tries to perturb the source distribution at each step i to prepare the algorithm for the worst possible distribution in step i + 1. Meanwhile, a classifier fc tries to learn a classifier based on the perturbed distribution.", "description": "The figure shows a schematic representation of the proposed manifold-constrained DRO method for gradual domain adaptation.  The input data (Di) first passes through a perturbation function (fp), which adds controlled noise. This perturbed data is then fed to a classifier (fc), and the output is combined with the original labels (-\u03b3) to calculate a loss. The method aims to find a robust classifier by iteratively perturbing data and training the classifier.", "section": "5 Experimental Results"}, {"figure_path": "UTNZKl5BUc/figures/figures_9_1.jpg", "caption": "Figure 2: Comparison of the performance of our proposed method with the GDA [KML20] on rotating MNIST dataset.", "description": "The figure compares the performance of the proposed gradual domain adaptation method with the GDA method [KML20] on the rotating MNIST dataset.  The x-axis represents the different domains (D0 to D4), where each domain corresponds to a different rotation angle of the MNIST images. The y-axis represents the accuracy of each method on each domain. The figure shows that the proposed method consistently outperforms the GDA method across all domains, demonstrating its effectiveness in handling gradual domain shifts. The error bars suggest that this outperformance is statistically significant, although more information would be needed to confirm this statistically.", "section": "5 Experimental Results"}, {"figure_path": "UTNZKl5BUc/figures/figures_16_1.jpg", "caption": "Figure 1: A schematic view of the proposed procedure for our manifold-constrained DRO. A restricted adversarial block, modeled by fp, tries to perturb the source distribution at each step i to prepare the algorithm for the worst possible distribution in step i + 1. Meanwhile, a classifier fc tries to learn a classifier based on the perturbed distribution.", "description": "This figure shows a schematic of the manifold-constrained DRO method used in the paper.  It illustrates how the method iteratively perturbs the source distribution using an adversarial block (fp) to prepare for the next distribution in the sequence.  A classifier (fc) then learns from this perturbed data. This process aims to improve the robustness of the model against distribution shifts.", "section": "5 Experimental Results"}]