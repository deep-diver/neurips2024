[{"figure_path": "nTJeOXlWyV/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of our RTify method. The input is a visual stimulus represented by random moving dots, but the model can also accommodate color images and video sequences. We take a pretrained task-optimized RNN and use a trainable function fw to transform the activity of the network into a real-valued evidence measure, et, that will be integrated over time by an evidence accumulator, \u03a6t. When the evidence accumulator reaches the threshold \u03b8, processing stops, and a decision is taken. The time step at which the accumulated evidence passes this threshold T\u03b8 is taken as the model RT for this stimulus.", "description": "This figure illustrates the RTify method, showing how a pre-trained recurrent neural network (RNN) processes visual stimuli to generate a decision and reaction time (RT).  The RNN's activity is transformed into an evidence measure using a trainable function, which is then accumulated over time. When the accumulated evidence surpasses a threshold, the process stops, and the RT is determined by the number of steps taken to reach the threshold.  The figure uses random dot motion stimuli as an example, but indicates the system can handle other inputs.", "section": "1 Introduction"}, {"figure_path": "nTJeOXlWyV/figures/figures_4_1.jpg", "caption": "Figure 2: RTified model evaluation on a RDM task [24]. Human data are shown as a gray shaded area, and model fits are shown for (A) the \u201csupervised\u201d setting where human behavioral responses are used to train the models and (B) the \u201cself-penalized\u201d setting where no human data is used. Our approach (green) outperforms the two alternative approaches (brown), i.e., entropy-thresholding [29] for the \u201csupervised\u201d and uncertainty proxy [30] for the \u201cself-penalized\u201d settings (see Fig. 4 for MSE comparisons and Fig. S3 for all coherences).", "description": "This figure compares the performance of the RTified model with two other methods (entropy-thresholding and uncertainty proxy) on a random dot motion (RDM) task.  The RTified model is evaluated under two training conditions: supervised (using human behavioral data) and self-penalized (without human data).  The results show the distribution of reaction times (RTs) for correct and incorrect responses, demonstrating that the RTified model provides superior results to both comparison methods.", "section": "3 Experiments"}, {"figure_path": "nTJeOXlWyV/figures/figures_4_2.jpg", "caption": "Figure 2: RTified model evaluation on a RDM task [24]. Human data are shown as a gray shaded area, and model fits are shown for (A) the \u201csupervised\u201d setting where human behavioral responses are used to train the models and (B) the \u201cself-penalized\u201d setting where no human data is used. Our approach (green) outperforms the two alternative approaches (brown), i.e., entropy-thresholding [29] for the \u201csupervised\u201d and uncertainty proxy [30] for the \u201cself-penalized\u201d settings (see Fig. 4 for MSE comparisons and Fig. S3 for all coherences).", "description": "This figure displays the results of the RTified model applied to a random dot motion (RDM) task.  It compares the RTified model's performance against two other methods (entropy-thresholding and uncertainty proxy) under two training conditions: supervised (using human RT data) and self-penalized (optimizing speed and accuracy without human data). Histograms illustrate the distribution of reaction times for correct and incorrect trials at different coherence levels, demonstrating the superior performance of the RTified model in both supervised and self-penalized settings.", "section": "3 Experiments"}, {"figure_path": "nTJeOXlWyV/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of RTifying feedforward neural networks. We develop a multi-class compatible and fully differentiable RNN module based on the WW model [21, 22]. This module is implemented as an attractor-based RNN, and is stacked on top of a feedforward neural network. The feedforward neural network first takes an image as the input. Outputs from classification units of the network are then sent to RTified WW (A). Information is accumulated by multiple populations of neurons in RTified WW while they compete with each other (B). A decision is made and the process stops when one of the populations reaches a threshold. The number of time steps needed for the RTified WW to reach the threshold is used to predict human RT (C).", "description": "This figure illustrates how the authors integrate a recurrent neural network (RNN) module into a feedforward neural network to model reaction times (RTs).  The RNN, based on the Wong-Wang model, allows for dynamic evidence accumulation across multiple neural populations representing different categories.  The process culminates in a decision once a population's activity surpasses a threshold, with the number of steps to reach this threshold serving as a prediction for human RTs. The figure depicts the architecture (A), population activity dynamics (B), and the overall evidence accumulation and decision process (C).", "section": "3 RTifying feedforward neural networks"}, {"figure_path": "nTJeOXlWyV/figures/figures_6_1.jpg", "caption": "Figure 4: (A) MSE comparisons for the RDM task [24] for all coherence levels. The RTified model trained in the \\\"supervised\\\" setting (i.e., with human behavioral responses; green solid line) performs better (lower MSE) than entropy-thresholding [29] (brown solid line) under all coherence levels. Similarly, the RTified model trained in the \\\"self-penalized\\\" setting (i.e., without human data; green dash line) performs better than uncertainty proxy [30] (brown dash line). With the help of our RTified WW module (orange solid line), a convolution neural network (C3D) can also fit the data better than entropy-thresholding [29]. (B) Classification accuracy comparisons between pretrained and RTified models for the RDM task [24]. The RTified model trained with human RTs data in the \\\"supervised\\\" setting (green solid line) and in the \\\"self-penalized\\\" setting (green dash line) achieve human-like classification accuracy under all coherence levels compared with the pretrained model without RTify (green dotted line). With the help of our RTified WW module (orange solid line), a CNN (C3D) matches human accuracy better than the pretrained model without RTify (orange dotted line).", "description": "This figure compares the performance of different models on the Random Dot Motion (RDM) task. Panel A shows the Mean Squared Error (MSE) for different coherence levels, demonstrating that the RTified models outperform alternative methods. Panel B shows the classification accuracy, illustrating that RTified models achieve human-like accuracy.", "section": "3 Experiments"}, {"figure_path": "nTJeOXlWyV/figures/figures_7_1.jpg", "caption": "Figure 5: RTified model evaluation on an object categorization task [39]. Model vs. human RT predictions for our RTified model (green) vs. alternative approaches (brown) (A) in the \u201csupervised\u201d setting where human behavioral responses are used to train the model and (B) the \u201cself-penalized\u201d setting where no human data is used. Solid lines are linear regression fits between model and human RTs. Crossed-shaded areas and the dashed lines are controls to show the fits after removing the highest model RTs. Our approach outperforms the two alternative approaches, i.e., entropy-thresholding [29] for the \u201csupervised\u201d setting and uncertainty proxy [30] for the \u201cself-penalized\u201d setting.", "description": "This figure displays the results of evaluating the RTify model on an object categorization task. It compares the RTify model's performance with two alternative methods in both supervised (using human data) and self-penalized (without human data) settings.  The plots show the correlation between model-predicted reaction times and human reaction times, demonstrating the superiority of the RTify method in accurately capturing human reaction time distributions.", "section": "3.2 Objection recognition task"}, {"figure_path": "nTJeOXlWyV/figures/figures_8_1.jpg", "caption": "Figure 6: RTified WW model evaluation. We combine our RTified WW module with (A) a 3D CNN to fit human RTs collected in an RDM task [24] (see Fig. 4 for MSE comparisons with other methods) and (B) a VGG to fit human RTs in a rapid object categorization task [39] (Crossed-shaded areas and the dashed lines are controls to show the fits after removing the highest model RTs).", "description": "This figure shows the results of applying the RTified WW model to two different tasks: a random dot motion (RDM) task and a rapid object categorization task.  Panel A displays the distribution of reaction times for both the model and human participants, comparing their fit across multiple levels of coherence in the RDM task. Panel B shows a scatter plot comparing model reaction times (RTs) to human RTs for the object categorization task, demonstrating a positive correlation. The dashed line represents a filtered regression line, and the shaded area indicates the fit after the removal of extreme values.", "section": "3. Experiments"}, {"figure_path": "nTJeOXlWyV/figures/figures_14_1.jpg", "caption": "Figure S1: Illustration of Mathematics Proof The discrete RNN step T\u03b8 is not differentiable. Therefore, we introduce a piecewise linear approximation of the accumulated evidence over time \u03a6t. Consider the effect of changes in \u03a6t on \u03c4\u03b8(\u03a6). A small perturbation in \u03a6t will produce a proportional change in the time it takes for the accumulated evidence to cross the threshold \u03b8, thereby inducing a shift in time. In simple terms, fine-tuning w to decrease \u03a6t will delay the time at which the network crosses the threshold \u03b8 thus increasing \u03c4\u03b8(\u03a6), while fine-tuning w to increase \u03a6t will cause the threshold to be crossed earlier thus decreasing \u03c4\u03b8(\u03a6).", "description": "This figure provides a visual illustration of the mathematical proof used in the paper to approximate the gradient of the non-differentiable function \u03c4\u03b8(\u03a6).  It demonstrates how a small change in the accumulated evidence (\u03a6t) leads to a proportional change in the time it takes to reach the threshold (\u03c4\u03b8(\u03a6)).  The piecewise linear approximation allows for the calculation of the gradient.", "section": "A Appendix / Supplemental material"}, {"figure_path": "nTJeOXlWyV/figures/figures_15_1.jpg", "caption": "Figure 3: Illustration of RTifying feedforward neural networks. We develop a multi-class compatible and fully differentiable RNN module based on the WW model [21, 22]. This module is implemented as an attractor-based RNN, and is stacked on top of a feedforward neural network. The feedforward neural network first takes an image as the input. Outputs from classification units of the network are then sent to RTified WW (A). Information is accumulated by multiple populations of neurons in RTified WW while they compete with each other (B). A decision is made and the process stops when one of the populations reaches a threshold. The number of time steps needed for the RTified WW to reach the threshold is used to predict human RT (C).", "description": "This figure illustrates how the authors' method, RTify, is applied to feedforward neural networks.  The RTified WW module, a multi-class RNN based on the Wong-Wang model, is added on top of a CNN. The CNN processes the image, and the output is then fed into the RTified WW module.  This module simulates the activity of multiple neural populations competing to reach a threshold.  The time it takes for one population to reach the threshold represents the predicted reaction time (RT).  Subfigures A, B, and C show, respectively, the architecture of the combined model, the activity of the neural populations over time, and the predicted RT.", "section": "3.1 Random dot motion task"}, {"figure_path": "nTJeOXlWyV/figures/figures_16_1.jpg", "caption": "Figure 2: RTified model evaluation on a RDM task [24]. Human data are shown as a gray shaded area, and model fits are shown for (A) the \u201csupervised\u201d setting where human behavioral responses are used to train the models and (B) the \u201cself-penalized\u201d setting where no human data is used. Our approach (green) outperforms the two alternative approaches (brown), i.e., entropy-thresholding [29] for the \u201csupervised\u201d and uncertainty proxy [30] for the \u201cself-penalized\u201d settings (see Fig. 4 for MSE comparisons and Fig. S3 for all coherences).", "description": "This figure displays the results of the RTified model evaluation on a Random Dot Motion (RDM) task, comparing it to two other methods: entropy-thresholding and uncertainty proxy.  It shows the distribution of reaction times (RTs) for both correct and incorrect responses at different coherence levels for both the supervised (trained on human data) and self-penalized (trained without human data) versions of the RTified model.  The graphs illustrate that the RTified model better fits the human RT data than the other two methods.", "section": "Experiments"}, {"figure_path": "nTJeOXlWyV/figures/figures_17_1.jpg", "caption": "Figure 2: RTified model evaluation on a RDM task [24]. Human data are shown as a gray shaded area, and model fits are shown for (A) the \u201csupervised\u201d setting where human behavioral responses are used to train the models and (B) the \u201cself-penalized\u201d setting where no human data is used. Our approach (green) outperforms the two alternative approaches (brown), i.e., entropy-thresholding [29] for the \u201csupervised\u201d and uncertainty proxy [30] for the \u201cself-penalized\u201d settings (see Fig. 4 for MSE comparisons and Fig. S3 for all coherences).", "description": "This figure compares the performance of the RTified model with two other methods (entropy-thresholding and uncertainty proxy) in predicting reaction times (RTs) in a random dot motion (RDM) task. The RTified model is tested in two scenarios: with human RT supervision and without human data (self-penalized). The results show that the RTified model significantly outperforms the two other methods across different coherence levels, demonstrating its ability to accurately model human RTs.", "section": "3 Experiments"}]