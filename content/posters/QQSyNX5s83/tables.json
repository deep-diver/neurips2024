[{"figure_path": "QQSyNX5s83/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative comparison on PlenopticVideo dataset. We display the average PSNR/SSIM/LPIPS (Alex) metrics for novel view synthesis on dynamic scenes, with each cell colored to indicate the best, second best, and third best.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis on dynamic scenes using the PlenopticVideo dataset.  The metrics used are PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity).  Lower LPIPS values indicate better perceptual similarity to ground truth. The table compares various methods in terms of these metrics, rendering time, frames per second (FPS), and storage requirements.  Color-coding highlights the top three performing methods for each metric.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative comparison on HyperNeRF dataset. Here, \u2021 represents that we train the model based on Sparse Init. * represents that we train the model based on Dense Init.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis on the HyperNeRF dataset.  It compares metrics like PSNR, SSIM, and MS-SSIM to evaluate the quality of the rendered images. The table also includes training time, frames per second (FPS), and storage requirements for each method.  The results are shown separately for both 'Sparse Init' (using a sparse point cloud for Gaussian initialization) and 'Dense Init' (using a denser point cloud).  This allows for comparison of the methods' performance under different initialization conditions.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative comparison on D-NeRF dataset. Here, parameter refers to the parameters of the deformation networks corresponding to different baselines.", "description": "This table compares the performance of four different methods on the D-NeRF dataset. The methods are 4DGaussian, 4DGaussian with the proposed method (4DGaussian+Ours), D3DGS, and D3DGS with the proposed method (D3DGS+Ours). The metrics used for comparison are PSNR, SSIM, and the number of parameters (in millions) in the deformation networks.  The improvements achieved by adding the proposed method to both 4DGaussian and D3DGS are highlighted. Notably, the proposed method leads to a reduction in parameters in D3DGS while still improving performance.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_9_1.jpg", "caption": "Table 4: Quantitative comparison on NeRF-DS dataset. ", "description": "This table presents a quantitative comparison of different methods on the NeRF-DS dataset.  The methods compared include TiNeuVox, HyperNeRF, NeRF-DS, 3D-GS, D3DGS, and the proposed method (Ours).  The metrics used for comparison are PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and LPIPS (Learned Perceptual Image Patch Similarity). Higher PSNR and SSIM values indicate better image quality, while a lower LPIPS value indicates greater perceptual similarity to the ground truth. The table highlights the improved performance of the proposed method compared to the baseline methods.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_9_2.jpg", "caption": "Table 5: Evaluation of the model with different designs on PlenopticVideo dataset.", "description": "This table presents the ablation study results on the PlenopticVideo dataset to evaluate the effectiveness of different components in the DN-4DGS model.  It shows the impact of using the Noise Suppression Strategy (NSS), Temporal Aggregation Module (TAM), and Denoised Spatial Aggregation Module (DSAM) individually and in combination on PSNR, SSIM, and LPIPS metrics.  The results demonstrate the contributions of each module and their synergistic effects on improving the overall rendering quality.", "section": "5 Experiment"}, {"figure_path": "QQSyNX5s83/tables/tables_14_1.jpg", "caption": "Table 1: Quantitative comparison on PlenopticVideo dataset. We display the average PSNR/SSIM/LPIPS (Alex) metrics for novel view synthesis on dynamic scenes, with each cell colored to indicate the best, second best, and third best.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis on dynamic scenes using the PlenopticVideo dataset.  It compares the methods' performance based on Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) metrics.  The best, second best, and third-best results for each metric are highlighted.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_14_2.jpg", "caption": "Table 1: Quantitative comparison on PlenopticVideo dataset. We display the average PSNR/SSIM/LPIPS (Alex) metrics for novel view synthesis on dynamic scenes, with each cell colored to indicate the best, second best, and third best.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis on dynamic scenes using the PlenopticVideo dataset.  The comparison is based on three metrics: PSNR, SSIM, and LPIPS (Alex).  Each metric's value is color-coded to easily identify the top three performing methods for each scene.  The table provides a summary of the performance across all scenes in the dataset.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_14_3.jpg", "caption": "Table 8: Per-scene results of NeRF-DS dataset by different models. Here, \u2021 represents that we train the model based on Sparse Init. * represents that we train the model based on Dense Init.", "description": "This table presents a quantitative comparison of different methods on the NeRF-DS dataset for novel view synthesis.  The table shows the PSNR values achieved by each method on seven different scenes: Sieve, Plate, Bell, Press, Cup, As, and Basin.  The \u2021 and * symbols indicate whether the model was trained using sparse or dense initialization, respectively.  The table allows for a detailed comparison of the performance of the proposed method against existing state-of-the-art techniques on a challenging dataset for dynamic scene rendering.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_15_1.jpg", "caption": "Table 1: Quantitative comparison on PlenopticVideo dataset. We display the average PSNR/SSIM/LPIPS (Alex) metrics for novel view synthesis on dynamic scenes, with each cell colored to indicate the best, second best, and third best.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis on dynamic scenes using the PlenopticVideo dataset.  It compares the average Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) scores achieved by each method.  The best, second best, and third-best results for each metric are highlighted.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/tables/tables_15_2.jpg", "caption": "Table 10: Ablation study of timestep in Temporal Aggregation Moudle. We compare the results on the flame steak scene of Plenoptic Video dataset.", "description": "This ablation study investigates the impact of different time step values on the performance of the Temporal Aggregation Module within the DN-4DGS model.  The results are specifically focused on the 'flame steak' scene from the PlenopticVideo dataset. The table shows that a timestep of 1x yields the best PSNR and SSIM scores, indicating optimal performance for this parameter.", "section": "5.3 Ablation Studies"}, {"figure_path": "QQSyNX5s83/tables/tables_15_3.jpg", "caption": "Table 11: Ablation study of K in Denoised Spatial Aggregation Moudle. We compare the results on the flame steak scene of PlenopticVideo dataset.", "description": "This ablation study analyzes the impact of changing the parameter K, which controls the number of nearest neighbors considered in the Denoised Spatial Aggregation Module (DSAM), on the model's performance. The results demonstrate that K=16 yields the best performance, suggesting a balance between incorporating local context and computational efficiency.", "section": "5 Experiment"}, {"figure_path": "QQSyNX5s83/tables/tables_15_4.jpg", "caption": "Table 1: Quantitative comparison on PlenopticVideo dataset. We display the average PSNR/SSIM/LPIPS (Alex) metrics for novel view synthesis on dynamic scenes, with each cell colored to indicate the best, second best, and third best.", "description": "This table presents a quantitative comparison of different methods for novel view synthesis on dynamic scenes using the PlenopticVideo dataset.  It compares the methods based on their average PSNR, SSIM, and LPIPS (Alex) scores.  The best, second-best, and third-best results for each metric are highlighted by color-coding the cells.", "section": "5.2 Comparison with existing methods"}]