[{"figure_path": "QQSyNX5s83/figures/figures_0_1.jpg", "caption": "Figure 1: (a) The visualization results on Plenoptic Video [1] dataset. (b) The visualization results on HyperNeRF [2] dataset. The numbers below the images represent PSNR.", "description": "This figure shows a comparison of the proposed method's performance against a baseline method (4DGaussian) on two different datasets: PlenopticVideo and HyperNeRF.  The images display rendered scenes, and the numbers underneath each image indicate the Peak Signal-to-Noise Ratio (PSNR), a metric used to evaluate the quality of the reconstruction.", "section": "Abstract"}, {"figure_path": "QQSyNX5s83/figures/figures_1_1.jpg", "caption": "Figure 2: Comparison of our render visualization with 4DGaussian [11]. The results are rendered on HyperNeRF [2] dataset and use the point cloud provided by HyperNeRF for Gaussian initialization (Sparse Init). Image 1: canonical 3D gaussians generated by 4DGaussian. Image 2: deformable 3D gaussians generated by 4DGaussian. Image 3: canonical 3D gaussians generated by our method. Image 4: deformable 3D gaussians after the first stage. Image 5: deformable 3D gaussians after the second stage. Image 6: ground truth. The yellow box emphasizes that through a two-stage deformation process, our method can produce higher-quality rendering results.", "description": "This figure compares the rendering results of the proposed method (DN-4DGS) with the baseline method (4DGaussian) on the HyperNeRF dataset.  It visually demonstrates the two-stage deformation process in DN-4DGS, showing how the initial noisy canonical 3D Gaussians are progressively refined to produce higher-quality deformable Gaussians that better match the ground truth. The yellow box highlights the improvement achieved by the two-stage deformation process.", "section": "1 Introduction"}, {"figure_path": "QQSyNX5s83/figures/figures_4_1.jpg", "caption": "Figure 4: The structure of aggregation operation.", "description": "This figure illustrates the architecture of the Temporal Aggregation Module within the DN-4DGS model.  It shows how temporal information is aggregated from adjacent frames (t-1, t, t+1). Feature encoding is first performed on the features at each timestep (Ft-1(i), Ft(i), Ft+1(i)). These features are then concatenated and passed through a Multi-Layer Perceptron (MLP) followed by a MaxPooling operation to generate the final aggregated feature Fmax(i). This is then combined with the original time t feature, Ft(i), and a learnable embedding, Yi, to create the final deformation output, Ft(i)'.", "section": "4.3.1 Temporal Aggregation Moudle"}, {"figure_path": "QQSyNX5s83/figures/figures_5_1.jpg", "caption": "Figure 5: More rendering images of canonical 3D gaussians. Here, Sparse Init refers to using the point cloud provided by the HyperNeRF [2] dataset (COLMAPSFM [44]) for Gaussian initialization, while Dense Init denotes generating a denser point cloud via COLMAPMVS [44]. In fact, Dense Init can produce better rendering quality, but due to the need for regenerating, it consumes more computational resources.", "description": "This figure shows a comparison of the canonical 3D Gaussians generated using two different initialization methods: Sparse Init and Dense Init.  Sparse Init uses a point cloud provided by the HyperNeRF dataset, while Dense Init generates a denser point cloud. The results show that Dense Init produces higher-quality rendering, but at the cost of increased computational resources. The images illustrate the difference in the quality and density of the Gaussian distributions generated by the two methods.", "section": "5 Experiment"}, {"figure_path": "QQSyNX5s83/figures/figures_7_1.jpg", "caption": "Figure 6: Qualitative comparisons on PlenopticVideo Dataset.", "description": "This figure provides qualitative comparisons between the results of 4DGaussian and the proposed DN-4DGS method on the PlenopticVideo dataset. The images show different scenes from the dataset, and the comparison highlights the improved rendering quality achieved by DN-4DGS, particularly in terms of detail and sharpness, as indicated by the red boxes.", "section": "5 Experiment"}, {"figure_path": "QQSyNX5s83/figures/figures_8_1.jpg", "caption": "Figure 7: Qualitative comparisons on HyperNeRF Dataset. In the gray cells, the numbers represent PSNR.", "description": "This figure presents a qualitative comparison of the results obtained using 4DGaussian and the proposed method (DN-4DGS) on the HyperNeRF dataset.  The results are shown for both sparse and dense Gaussian initialization. Each row shows a sequence of images from a video, comparing the rendering results of the two methods against the ground truth. The numbers in gray cells indicate the PSNR (Peak Signal-to-Noise Ratio) values, a quantitative metric of image quality.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/figures/figures_8_2.jpg", "caption": "Figure 8: The canonical results for both 4DGaussian and D3DGS.", "description": "This figure compares the canonical results (i.e., the initial 3D Gaussian representation before deformation) generated by 4DGaussian and D3DGS methods.  It visually demonstrates the difference in noise level between the two approaches before the deformation process is applied. The image shows a yellow excavator on a wooden surface, and the visual noise of the 3D Gaussian splatting (3DGS) is quite visible. The differences seen in the figure highlight the impact of noise in the canonical 3D Gaussian representations and motivates the authors' proposed Noise Suppression Strategy (NSS) in their method.", "section": "5.2 Comparison with existing methods"}, {"figure_path": "QQSyNX5s83/figures/figures_9_1.jpg", "caption": "Figure 9: Effectiveness of the two-stage deformation operations. In the gray cells, the numbers represent PSNR.", "description": "This figure shows the effectiveness of the two-stage deformation process in the DN-4DGS model. The first stage is a standard deformation that takes the coordinates x, y, z of the canonical 3D Gaussians and time t as input, and outputs corresponding coordinate deformations \u0394x, \u0394y, \u0394z. The second deformation builds upon the first by adding \u0394x, \u0394y, \u0394z to the original x, y, z, creating a modified set of coordinates that is then input into a new feature extraction network.  The results show a significant reduction in noise after the first deformation stage, leading to a more accurate deformation field and improved rendering quality.  PSNR values are given in the gray cells to quantify the improvement.", "section": "4.2 Noise Suppression Strategy"}, {"figure_path": "QQSyNX5s83/figures/figures_16_1.jpg", "caption": "Figure 5: More rendering images of canonical 3D gaussians. Here, Sparse Init refers to using the point cloud provided by the HyperNeRF [2] dataset (COLMAPSFM [44]) for Gaussian initialization, while Dense Init denotes generating a denser point cloud via COLMAPMVS [44]. In fact, Dense Init can produce better rendering quality, but due to the need for regenerating, it consumes more computational resources.", "description": "This figure compares the rendering results of canonical 3D Gaussians using two different initialization methods: Sparse Init and Dense Init. Sparse Init uses a point cloud from the HyperNeRF dataset for initialization, while Dense Init generates a denser point cloud. The results show that Dense Init produces better rendering quality, but it requires more computational resources. The figure demonstrates the impact of the quality of initial canonical 3D Gaussians on the overall rendering results.", "section": "5 Experiment"}, {"figure_path": "QQSyNX5s83/figures/figures_17_1.jpg", "caption": "Figure 6: Qualitative comparisons on PlenopticVideo Dataset.", "description": "The figure shows a qualitative comparison of rendering results between the 4DGaussian method and the proposed DN-4DGS method on the PlenopticVideo dataset.  The comparison highlights the improved rendering quality achieved by DN-4DGS, particularly in areas with complex motion and fine details. The results are presented for several scenes from the dataset, showcasing the superiority of DN-4DGS in handling dynamic scenes with higher fidelity.", "section": "5 Experiment"}, {"figure_path": "QQSyNX5s83/figures/figures_18_1.jpg", "caption": "Figure 5: More rendering images of canonical 3D gaussians. Here, Sparse Init refers to using the point cloud provided by the HyperNeRF [2] dataset (COLMAPSFM [44]) for Gaussian initialization, while Dense Init denotes generating a denser point cloud via COLMAPMVS [44]. In fact, Dense Init can produce better rendering quality, but due to the need for regenerating, it consumes more computational resources.", "description": "This figure shows more visualization results on canonical 3D Gaussians generated by two methods: Sparse Init and Dense Init. Sparse Init uses the point cloud from HyperNeRF dataset, while Dense Init generates denser point cloud. Although Dense Init produces better quality, it is computationally more expensive.", "section": "3 Preliminary: 3D Gaussian Splatting"}, {"figure_path": "QQSyNX5s83/figures/figures_19_1.jpg", "caption": "Figure 10: Qualitative comparisons on PlenopticVideo Dataset.", "description": "This figure showcases a qualitative comparison of rendering results between the 4DGaussian method and the proposed DN-4DGS method on the PlenopticVideo dataset.  Each row represents a different scene within the dataset, showing a sequence of frames.  The left column displays the results generated by 4DGaussian, the middle column the results from DN-4DGS, and the right column the ground truth images.  The comparison allows for a visual assessment of the relative rendering quality and artifact presence between the two methods.", "section": "A.8 More Visual Comparison"}]