[{"figure_path": "nU4lvlMwrt/tables/tables_5_1.jpg", "caption": "Table 1: Comparison with baseline on five datasets. The \u201cMode\u201d column denotes the specific inference modes associated with each method. The \"Test size\" column relates to the DeepGlobe dataset.", "description": "This table compares the performance of the proposed SGNet method with various baseline methods on five different datasets.  It shows the mean Intersection over Union (mIoU) scores for each method across the datasets. The \"Mode\" column indicates the inference strategy used (e.g., slide, whole image). The \"Backbone\" column specifies the convolutional neural network used as the base architecture.  The \"Test Size\" column refers to the DeepGlobe dataset, highlighting the different image sizes used for testing. The table is split into two sections: \"Ultra Image Segmentation Methods\" and \"General Semantic Segmentation Methods,\" showing how SGNet improves upon existing methods.  The numbers in parentheses show the improvement gained by adding SGNet to the general segmentation models. ", "section": "4.3 Comparison Results"}, {"figure_path": "nU4lvlMwrt/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with baseline on five datasets. The \u201cMode\u201d column denotes the specific inference modes associated with each method. The \"Test size\" column relates to the DeepGlobe dataset.", "description": "This table compares the performance of the proposed SGNet method with various baseline methods (both general semantic segmentation and ultra image segmentation methods) across five different datasets (DeepGlobe, Aerial Inria, Gleason, Cityscapes, and Five-Billion-Pixels).  The table shows the mean Intersection over Union (mIoU) scores achieved by each method, categorized by inference mode (slide, whole, or a combination) and backbone architecture used. The \"Test size\" column specifies the input image size used for the DeepGlobe dataset.", "section": "4.3 Comparison Results"}, {"figure_path": "nU4lvlMwrt/tables/tables_6_2.jpg", "caption": "Table 3: Analysis of Surrounding Context Integration.", "description": "This table presents the ablation study of the surrounding context integration module (SCI) within the SGNet architecture. It shows the impact of different components of SCI on the model\u2019s performance, measured by mean Intersection over Union (mIoU). The components evaluated include: Naive Self-Attention (SA), Window-based Multi-Head Self-Attention (W-MSA), Convolution, and Global Average Pooling (GAP).  The results demonstrate how each component contributes to the overall performance, highlighting the effectiveness of the W-MSA and GAP in integrating contextual information for improved segmentation.", "section": "4.4 Ablation Study"}, {"figure_path": "nU4lvlMwrt/tables/tables_7_1.jpg", "caption": "Table 4: Analysis of feature fusion scheme.", "description": "This table presents the results of an ablation study comparing different feature fusion schemes (Early Fusion, Late Fusion, ADD, and CONCAT) used in the SGNet architecture.  The mIoU (mean Intersection over Union) metric is used to evaluate the performance of each scheme, indicating the effectiveness of each approach in combining local and surrounding contextual information for improved segmentation accuracy.", "section": "4.4 Ablation Study"}, {"figure_path": "nU4lvlMwrt/tables/tables_7_2.jpg", "caption": "Table 1: Comparison with baseline on five datasets. The \u201cMode\u201d column denotes the specific inference modes associated with each method. The \"Test size\" column relates to the DeepGlobe dataset.", "description": "This table compares the performance of the proposed SGNet method with various baseline methods (both general semantic segmentation and ultra image segmentation methods) across five different datasets.  The results are presented in terms of mean Intersection over Union (mIoU) scores and show the consistent improvement achieved by integrating SGNet into different general segmentation models. The table also indicates the inference mode (Whole, Slide or a combination) and backbone architecture used by each method. The DeepGlobe dataset's test image size is specifically noted.", "section": "4.3 Comparison Results"}, {"figure_path": "nU4lvlMwrt/tables/tables_8_1.jpg", "caption": "Table 1: Comparison with baseline on five datasets. The \u201cMode\u201d column denotes the specific inference modes associated with each method. The \"Test size\" column relates to the DeepGlobe dataset.", "description": "This table compares the performance of various ultra image segmentation methods and general semantic segmentation methods on five datasets (DeepGlobe, Aerial Inria, Gleason, Cityscapes, and Five-Billion-Pixels).  It shows the mean Intersection over Union (mIoU) scores achieved by each method, along with inference mode (slide or whole image), backbone network used, and test image size for the DeepGlobe dataset.  The table highlights the performance gains achieved by integrating the proposed SGNet framework with different general segmentation models, demonstrating its effectiveness across various datasets and model architectures.", "section": "4.3 Comparison Results"}, {"figure_path": "nU4lvlMwrt/tables/tables_8_2.jpg", "caption": "Table 1: Comparison with baseline on five datasets. The \u201cMode\u201d column denotes the specific inference modes associated with each method. The \"Test size\" column relates to the DeepGlobe dataset.", "description": "This table compares the performance of the proposed SGNet method with several baselines on five different datasets.  It shows the mean Intersection over Union (mIoU) scores achieved by each method, broken down by dataset and inference mode (Whole, Slide, or a combination). The 'Mode' column indicates whether the entire image or individual patches were used for inference. The 'Backbone' column indicates the backbone network used for each method. The table also shows the improvements provided by adding SGNet to general semantic segmentation models. This table highlights the consistent improvement achieved by the proposed model across different datasets and baselines.", "section": "4.3 Comparison Results"}, {"figure_path": "nU4lvlMwrt/tables/tables_14_1.jpg", "caption": "Table 1: Comparison with baseline on five datasets. The \u201cMode\u201d column denotes the specific inference modes associated with each method. The \"Test size\" column relates to the DeepGlobe dataset.", "description": "This table compares the performance of the proposed SGNet method with several baseline methods (both general semantic segmentation and ultra image segmentation methods) across five different datasets (DeepGlobe, Aerial Inria, 5000x5000, Gleason, Cityscapes).  It shows the mean Intersection over Union (mIoU) scores for each method on each dataset, indicating the accuracy of segmentation.  The \"Mode\" column specifies whether the method uses a sliding window or whole image inference approach, while \"Test size\" refers to the resolution of images used for testing in the DeepGlobe dataset.  The table highlights the consistent improvement achieved by SGNet across various baseline methods and datasets.", "section": "4.3 Comparison Results"}]