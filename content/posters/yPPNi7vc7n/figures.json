[{"figure_path": "yPPNi7vc7n/figures/figures_1_1.jpg", "caption": "Figure 1: Samples generated from models trained on CelebA-HQ (1024 \u00d7 1024) using our proposed score matching method, LCSS. The rightmost images in each row are generated by DDPM++ with subVP SDE, while the rest are by NCSN++ with VE SDE.", "description": "This figure displays samples generated by score-based diffusion models trained on the CelebA-HQ dataset at a high resolution (1024x1024).  The images demonstrate the quality of image generation achieved using the proposed Local Curvature Smoothing with Stein's Identity (LCSS) method.  For comparison, the figure also includes images generated using two other state-of-the-art methods: DDPM++ with a subVP stochastic differential equation (SDE) and NCSN++ with a VE SDE. The rightmost images in each row represent DDPM++ samples, while the others represent NCSN++ samples.", "section": "1 Introduction"}, {"figure_path": "yPPNi7vc7n/figures/figures_7_1.jpg", "caption": "Figure 2: Comparison of sample quality in the early stages of training. The model is NCSNv2 trained on CIFAR-10. The left three panels show generated samples at 5k steps training, while the right three show generated samples at 90k steps training.", "description": "This figure compares the image quality generated by SSM, FD-SSM, and LCSS at different training stages (5k and 90k steps) using NCSNv2 model trained on CIFAR-10 dataset.  It visually demonstrates the difference in sample quality and convergence speed of the three score matching methods.", "section": "4.2.3 Sample quality"}, {"figure_path": "yPPNi7vc7n/figures/figures_7_2.jpg", "caption": "Figure 3: Comparison of generated samples on CelebA (64 \u00d7 64). The left three show samples from models trained for 10k steps. In the right three, FD-SSM and LCSS images are from models trained for 210k steps, whereas SSM images are from a model trained for 60k steps.", "description": "This figure compares the image generation quality of SSM, FD-SSM, and LCSS on the CelebA dataset at 64x64 resolution.  The left panel shows samples generated after training for 10,000 steps, illustrating the relative speed of convergence for each method.  The right panel shows samples generated after more extensive training (210,000 steps for FD-SSM and LCSS, 60,000 steps for SSM), highlighting the long-term stability and quality of images generated by LCSS compared to the other methods.", "section": "4.2.3 Sample quality"}, {"figure_path": "yPPNi7vc7n/figures/figures_7_3.jpg", "caption": "Figure 4: Samples on FFHQ (256 \u00d7 256). Models are trained for 600k steps with batch size 16. SSM and FD-SSM fail to produce face images.", "description": "This figure compares the image generation quality of SSM, FD-SSM, DSM, and LCSS on the FFHQ dataset at 256x256 resolution.  The models were trained for 600,000 steps with a batch size of 16.  The results show that SSM and FD-SSM fail to generate realistic face images, while DSM and LCSS produce significantly better results.  LCSS demonstrates superior image quality compared to DSM.", "section": "4.2.3 Sample quality"}, {"figure_path": "yPPNi7vc7n/figures/figures_8_1.jpg", "caption": "Figure 4: Samples on FFHQ (256 \u00d7 256). Models are trained for 600k steps with batch size 16. SSM and FD-SSM fail to produce face images.", "description": "This figure compares the image generation quality of SSM, FD-SSM, DSM, and LCSS on the FFHQ dataset.  The models were trained for 600,000 steps with a batch size of 16.  The results show that LCSS generates significantly better quality images compared to SSM and FD-SSM which largely fail to produce realistic faces, and produces results comparable to DSM.", "section": "4.2.3 Sample quality"}, {"figure_path": "yPPNi7vc7n/figures/figures_9_1.jpg", "caption": "Figure 7: Generated samples on FFHQ (256 \u00d7 256) by the model trained with LCSS (ours) with different \u03b3. The notation iter signifies the training iterations.", "description": "This figure shows the effect of different values of the balancing coefficient \u03b3 on image generation quality using LCSS.  The images are generated from the FFHQ dataset (256x256 resolution) using the LCSS method with varying \u03b3 values and training iterations. The results show that a balanced value of \u03b3 is crucial to achieve high-quality generation. Values too low lead to noisy images that lack detailed features while high values result in images with enhanced contours but missing textures. ", "section": "4.4 Ablation study"}, {"figure_path": "yPPNi7vc7n/figures/figures_14_1.jpg", "caption": "Figure 8: Training loss curve on checkerboard, corresponding to Fig. 1. From left to right: SSM, DSM, and LCSS (ours).", "description": "This figure shows the training loss curves for four different score matching methods: SSM, FD-SSM, DSM, and LCSS. The x-axis represents the training epoch, and the y-axis represents the loss.  The plot visually compares the convergence speed and stability of each method during training on the Checkerboard dataset.  The LCSS method demonstrates faster convergence and a more stable loss curve compared to SSM and FD-SSM, while exhibiting a similar performance to DSM.", "section": "4.2.1 Density estimation"}, {"figure_path": "yPPNi7vc7n/figures/figures_15_1.jpg", "caption": "Figure 9: Generated samples on CIFAR-10 with LCSS. The model for the top is NCSN++ deep with VE SDE, and the one for the bottom is DDPM++ deep with subVP SDE.", "description": "This figure shows the image samples generated by two different score-based diffusion models (NCSN++ deep and DDPM++ deep) trained using the proposed LCSS method on the CIFAR-10 dataset.  The top half displays samples generated by NCSN++ deep using the VE SDE, and the bottom half shows samples from DDPM++ deep using the subVP SDE.  The figure demonstrates the visual quality of images generated by the LCSS method.", "section": "C.1 Generated Samples on CIFAR-10"}, {"figure_path": "yPPNi7vc7n/figures/figures_16_1.jpg", "caption": "Figure 10: Samples generated from NCSN++ with VE SDE trained on CelebA-HQ (1024 \u00d7 1024) using LCSS.", "description": "This figure displays several high-resolution (1024x1024 pixels) images of faces generated using the NCSN++ model with VE SDE and the LCSS (Local Curvature Smoothing with Stein's Identity) method.  CelebA-HQ is a high-quality celebrity face dataset used for training. The images demonstrate the model's capability to generate realistic and diverse facial features at a high resolution, showcasing one of the key results presented in the paper.", "section": "4.3 High resolution image generation"}]