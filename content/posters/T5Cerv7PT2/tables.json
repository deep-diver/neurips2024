[{"figure_path": "T5Cerv7PT2/tables/tables_13_1.jpg", "caption": "Table A.1: Hyperparameter configurations used in our experiments.", "description": "This table lists the hyperparameter settings used for the SAC (Soft Actor-Critic) algorithm and the constraint learning process in the experiments described in the paper.  It details parameters for both the SAC algorithm itself (learning rates, optimizers, network architecture, etc.) and for the constraint learning, including the choices for output clipping, activation functions, optimizers, and regularization methods used for different variations of the IRL (Inverse Reinforcement Learning) approach.", "section": "A Experiment Details"}, {"figure_path": "T5Cerv7PT2/tables/tables_13_2.jpg", "caption": "Table 1: Constraint function learning rates used for each environment with final parameters.", "description": "This table shows the learning rates used for training the constraint function in different environments. The learning rate was tuned for each environment, and the final values are shown in the table.", "section": "A Experiment Details"}]