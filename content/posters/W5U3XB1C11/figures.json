[{"figure_path": "W5U3XB1C11/figures/figures_6_1.jpg", "caption": "Figure 1: Average Worst Case k-UAP accuracy vs Time for ConvSmall CIFAR10 DNNs.", "description": "This figure shows the comparison of the worst-case k-UAP accuracy over time for three different CIFAR-10 ConvSmall DNNs trained with different robust training methods (DiffAI, SABR, CITRUS).  The x-axis represents time in seconds, and the y-axis represents the worst-case k-UAP accuracy (averaged over 10 runs).  The figure demonstrates that RABBit consistently outperforms the \u03b1, \u03b2-CROWN baseline across all DNNs and time intervals, highlighting RABBit's improved precision in k-UAP verification.", "section": "6.2 Experimental Results"}, {"figure_path": "W5U3XB1C11/figures/figures_8_1.jpg", "caption": "Figure 1: Average Worst Case k-UAP accuracy vs Time for ConvSmall CIFAR10 DNNs.", "description": "This figure shows the timewise comparison of worst-case k-UAP accuracy between RABBIT and \u03b1-\u03b2-CROWN for three different CIFAR10 ConvSmall DNNs trained with different robust training methods (DiffAI, SABR, CITRUS).  The x-axis represents the time in seconds, and the y-axis represents the k-UAP accuracy (averaged over 10 runs). The results demonstrate that RABBIT consistently outperforms \u03b1-\u03b2-CROWN across all DNNs and time intervals. This highlights RABBIT's efficiency and precision improvements in relational verification.", "section": "6.2 Experimental Results"}, {"figure_path": "W5U3XB1C11/figures/figures_8_2.jpg", "caption": "Figure 2: Timewise Analysis of Average % Improvement in t* with Strong Bounding (CIFAR10)", "description": "This figure displays the average percentage improvement in t* achieved by strong bounding in RABBit over \u03b1,\u03b2-CROWN and RACoon across different time intervals, for both DiffAI and CITRUS ConvSmall networks on CIFAR10 dataset. The results highlight how strong bounding's advantage increases over time, emphasizing its efficiency and precision improvement for relational verification.", "section": "6.2 Experimental Results"}, {"figure_path": "W5U3XB1C11/figures/figures_8_3.jpg", "caption": "Figure 2: Timewise Analysis of Average % Improvement in t* with Strong Bounding (CIFAR10)", "description": "This figure shows the timewise analysis of the average percentage improvement in t* achieved by strong bounding over \u03b1, \u03b2-CROWN and RACoon for CIFAR10 datasets.  The plots illustrate the improvement over time for two different training methods, DiffAI and CITRUS. It demonstrates that the strong bounding method consistently yields tighter bounds than the baselines across various time frames.", "section": "6.2 Experimental Results"}, {"figure_path": "W5U3XB1C11/figures/figures_9_1.jpg", "caption": "Figure 4: Average Worst Case k-UAP accuracy vs e for CIFAR10 DNNS.", "description": "This figure compares the worst-case k-UAP accuracy of three different verifiers (RACoon, \u03b1-\u03b2-CROWN, and RABBit) against varying epsilon values for two different CIFAR10 DNNs trained with DiffAI and CITRUS methods.  It showcases the performance of each verifier in terms of accuracy against universal adversarial perturbations (UAPs) with different magnitudes (epsilon values). The graphs illustrate how the accuracy of each verifier changes as the allowed perturbation size (epsilon) increases.  It shows RABBit consistently outperforms the other two verifiers.", "section": "6.2 Experimental Results"}]