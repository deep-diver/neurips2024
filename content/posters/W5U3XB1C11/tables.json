[{"figure_path": "W5U3XB1C11/tables/tables_7_1.jpg", "caption": "Table 1: RABBit Efficacy Analysis for Worst-Case UAP Accuracy", "description": "This table presents a comparison of RABBit's performance against several state-of-the-art baselines for worst-case universal adversarial perturbation (UAP) accuracy.  It shows the results across different datasets (CIFAR-10 and MNIST), network architectures (ConvSmall and ConvBig), training methods (standard, DiffAI, SABR, CITRUS), and perturbation bounds (epsilon). For each configuration, the table lists the worst-case UAP accuracy achieved by each method, including the improvement achieved by RABBit's strong bounding and strong branching algorithms, along with RABBit's overall performance.  The results highlight RABBit's superior precision in relational verification compared to existing methods.", "section": "6 Experimental Evaluation"}, {"figure_path": "W5U3XB1C11/tables/tables_17_1.jpg", "caption": "Table 2: DNN Architecture Details", "description": "This table presents details about the architectures of the deep neural networks (DNNs) used in the experiments.  It lists the dataset, model name, model type (convolutional), training method used to create the model (Standard, DiffAI, SABR, CITRUS), the number of layers in the network architecture, and the total number of parameters in the model.  The table covers both MNIST and CIFAR10 datasets using various models, each having been trained using different training methods.", "section": "D.1 DNN Architectures"}, {"figure_path": "W5U3XB1C11/tables/tables_17_2.jpg", "caption": "Table 3: Standard top-1 accuracy for evaluated DNNS", "description": "This table presents the standard top-1 accuracy for the evaluated deep neural networks (DNNs).  The accuracy is reported for different datasets (CIFAR10 and MNIST) and DNN models (ConvSmall and ConvBig), each trained with various methods (Standard, DiffAI, SABR, and CITRUS).  These values represent the baseline performance of each DNN before relational verification.", "section": "D.2 Accuracies for Evaluated DNNS"}, {"figure_path": "W5U3XB1C11/tables/tables_18_1.jpg", "caption": "Table 4: Comparison of RABBit vs RaVeN and RACoon", "description": "This table compares the performance of RABBit against RaVeN and RACoon on various datasets and network architectures trained with different methods. It shows the worst-case UAP accuracy achieved by each method for each experimental setup, highlighting the improvement achieved by RABBit over RaVeN and RACoon. The values in parentheses indicate the percentage improvement of RABBit over the corresponding baseline method.", "section": "E Comparison of RABBit with RaVeN"}, {"figure_path": "W5U3XB1C11/tables/tables_18_2.jpg", "caption": "Table 6: Average Improvement in t* with Strong Bounding", "description": "This table presents the average percentage improvement achieved by the strong bounding method in the objective function t* compared to two state-of-the-art baselines (RACoon and \u03b1, \u03b2-CROWN). The results are shown for different datasets (CIFAR and MNIST), network architectures (ConvSmall), training methods (DiffAI and CITRUS), and perturbation bounds (\u03b5).  95% confidence intervals are provided to indicate the statistical significance of the improvements.", "section": "G Average Improvement in t* with Strong Bounding"}]