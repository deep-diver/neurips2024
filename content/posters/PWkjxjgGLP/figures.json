[{"figure_path": "PWkjxjgGLP/figures/figures_2_1.jpg", "caption": "Figure 1: Illustration of the proposed framework. Our model adopts visual features from multiple scales, which are aggregated through the Hierarchical Visual Feature Aggregation (HVFA) module. The aggregated features are then fed into an LLM to generate language response in an autoregressive manner. The sub-image highlighted by the red box contains the text relevant to an input question, which requires accurately recognizing visually detailed elements from high resolution image.", "description": "This figure illustrates the framework of the proposed OCR-free document understanding model.  It shows how multi-scale visual features (global view, local scales 1 and 2) are extracted from a document image and aggregated using the Hierarchical Visual Feature Aggregation (HVFA) module.  These aggregated features are then fed into a Large Language Model (LLM) to generate a text response. The red box highlights how the model focuses on specific regions of the image containing relevant text to answer an input question, emphasizing the importance of high-resolution details for accurate text recognition.", "section": "3 Method"}, {"figure_path": "PWkjxjgGLP/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of the Hierarchical Visual Feature Aggregation (HVFA) module. (Left) HVFA aggregates high-resolution visual features to low-resolution features leveraging feature pyramid structure. (Right) In cross-attentive pooling, each sub-image-feature attends to all of the fine-grained visual features, compressing and preserving more detailed information.", "description": "This figure illustrates the Hierarchical Visual Feature Aggregation (HVFA) module's architecture.  The left panel shows how the module uses a feature pyramid to combine visual features from different resolutions (high-resolution and low-resolution). The right panel zooms in on the cross-attentive pooling mechanism within the HVFA, illustrating how each low-resolution feature attends to all high-resolution features to compress information while maintaining detail.", "section": "3.3 Hierarchical Visual Feature Aggregation"}, {"figure_path": "PWkjxjgGLP/figures/figures_8_1.jpg", "caption": "Figure 3: Performance analysis on visual and textual inputs. (Left) Impact of visual input scale on model performance. We compare four variants of our model: with the first scale (S1), with the second scale (S2), with multiple scales (S1 + S2), and with multiple scales with HVFA (S1 + S2 w/ HVFA, ours). (Right) Impact of truncated text in the text reading task on model performance by varying sequence length capacity of LLM.", "description": "The left plot shows that using multiple scales and HVFA improves the model's performance. The right plot demonstrates the model's robustness to text truncation by using RPT which reads a portion of the text within the image.", "section": "4.4 Ablation Study"}, {"figure_path": "PWkjxjgGLP/figures/figures_9_1.jpg", "caption": "Figure 1: Illustration of the proposed framework. Our model adopts visual features from multiple scales, which are aggregated through the Hierarchical Visual Feature Aggregation (HVFA) module. The aggregated features are then fed into an LLM to generate language response in an autoregressive manner. The sub-image highlighted by the red box contains the text relevant to an input question, which requires accurately recognizing visually detailed elements from high resolution image.", "description": "This figure illustrates the architecture of the proposed OCR-free document understanding framework. It shows how multi-scale visual features are extracted from a document image, aggregated using the Hierarchical Visual Feature Aggregation (HVFA) module, and fed into a large language model (LLM) to generate a textual response.  The figure highlights the importance of using multi-scale features to handle varying font sizes and the role of the HVFA module in efficiently managing the information from different scales. The red box emphasizes the need to capture fine-grained visual details from high-resolution images.", "section": "3 Method"}]