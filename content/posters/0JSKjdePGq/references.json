{"references": [{"fullname_first_author": "Schulman, J.", "paper_title": "Trust region policy optimization", "publication_date": "2015-00-00", "reason": "This paper introduces a widely adopted reinforcement learning algorithm, which is extended in this paper for time-adaptive continuous-time settings."}, {"fullname_first_author": "Haarnoja, T.", "paper_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor", "publication_date": "2018-00-00", "reason": "This paper introduces another popular reinforcement learning algorithm that is also adapted here for the proposed time-adaptive framework."}, {"fullname_first_author": "Curi, S.", "paper_title": "Efficient model-based reinforcement learning through optimistic policy search and planning", "publication_date": "2020-00-00", "reason": "This work is relevant due to the introduction of a model-based algorithm (OTACOS) in this paper, which builds upon the principles of optimistic planning used in this reference."}, {"fullname_first_author": "Freeman, C. D.", "paper_title": "Brax: A differentiable physics engine for large-scale rigid body simulation", "publication_date": "2021-00-00", "reason": "This paper provides the simulation environments used to evaluate the proposed approach, thus directly impacting the empirical results and validation."}, {"fullname_first_author": "Treven, L.", "paper_title": "Efficient exploration in continuous-time model-based reinforcement learning", "publication_date": "2023-00-00", "reason": "This paper is highly relevant as it provides the theoretical foundation and algorithms for the model-based approach (OTACOS) proposed in this work, establishing a clear connection and advancement."}]}