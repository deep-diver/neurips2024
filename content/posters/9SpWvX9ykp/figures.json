[{"figure_path": "9SpWvX9ykp/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of the Code World Models (CWM) framework. Given the description of an environment and a task, we use an LLM guided by the GIF-MCTS method to iteratively generate and refine a candidate CWM. The candidate's correctness is evaluated by checking if it correctly predicts a set of trajectories collected from the true environment. If the model cannot fully predict all transitions, the fraction of correct predictions and other information are given as feedback to the LLM and the cycle repeats. After matching all transitions or having used up a computational budget, the best CWM is returned and used to solve the task via model-based planning.", "description": "This figure illustrates the Code World Model (CWM) framework.  The process begins with an environment description and task provided to a Large Language Model (LLM).  The LLM, guided by the GIF-MCTS algorithm, iteratively generates and refines Python code representing a CWM. This code is then validated against collected environment trajectories to measure its accuracy in predicting system behavior.  If the CWM's predictions are not perfect, the accuracy and other information are fed back to the LLM to further improve the CWM. This iterative process continues until the CWM accurately predicts all transitions or a computational budget is exhausted. Finally, the best performing CWM is used for model-based planning to solve the given task.", "section": "1 Introduction"}, {"figure_path": "9SpWvX9ykp/figures/figures_4_1.jpg", "caption": "Figure 2: Example of a GIF-MCTS tree for generating a CWM. Starting from the root of the tree, every action taken corresponds to 1) prompting the LLM to either generate, improve or fix a CWM, 2) parsing the LLM completion, and 3) evaluating the CWM's correctness using the available environment trajectories as unit tests (presented as a percentage inside the nodes). On buggy nodes, we allow only fix actions for up to f sequential attempts and replace the actual value with a temporary one, represented in red. In healthy nodes we allow only generate and improve actions. All action prompts are exemplified on the right. The number of total fix f attempts is a model hyperparameter, set to three in this Figure and for our method.", "description": "This figure shows an example of a Monte Carlo Tree Search (MCTS) tree used in the GIF-MCTS algorithm for generating Code World Models.  Each node represents a program (a Python class defining the environment) and each edge represents an action (generate, improve, or fix). The percentage in each node indicates the program's accuracy. The algorithm iteratively generates, improves, and fixes the code based on the LLM's output and evaluation against unit tests (environment trajectories).  Buggy nodes (red) trigger a 'fix' action until the bug is resolved or the maximum number of attempts is reached. Healthy nodes use 'generate' and 'improve' actions. The figure illustrates the process from root to a leaf node where a successful CWM is generated.", "section": "GIF-MCTS"}, {"figure_path": "9SpWvX9ykp/figures/figures_36_1.jpg", "caption": "Figure 2: Example of a GIF-MCTS tree for generating a CWM. Starting from the root of the tree, every action taken corresponds to 1) prompting the LLM to either generate, improve or fix a CWM, 2) parsing the LLM completion, and 3) evaluating the CWM's correctness using the available environment trajectories as unit tests (presented as a percentage inside the nodes). On buggy nodes, we allow only fix actions for up to f sequential attempts and replace the actual value with a temporary one, represented in red. In healthy nodes we allow only generate and improve actions. All action prompts are exemplified on the right. The number of total fix f attempts is a model hyperparameter, set to three in this Figure and for our method.", "description": "This figure illustrates the GIF-MCTS algorithm used for code generation. The tree structure represents the search process, where each node contains a code snippet and the percentage reflects the prediction accuracy. Different actions (generate, improve, fix) lead to different branches of the tree, and the process iteratively refines the code until an accurate model is obtained. The figure exemplifies how the LLM is used at each step, and how feedback from unit tests informs subsequent actions.  The algorithm incorporates a strategy for handling buggy code snippets by focusing on fixing errors before generating further code. ", "section": "GIF-MCTS"}]