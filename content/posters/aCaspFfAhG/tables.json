[{"figure_path": "aCaspFfAhG/tables/tables_5_1.jpg", "caption": "Table 1: Instance-dependent regret upper bound.", "description": "The table presents the instance-dependent regret upper bound achieved by the Dynamical Ranking Exploration-Exploitation (DREE) algorithm. It shows that the algorithm's regret is bounded by a function that depends on the suboptimality gaps (\u2206i) of the suboptimal arms and a superlogarithmic function f(T).  The specific form of the bound highlights a trade-off between exploration (f(T)) and exploitation (\u2206i).", "section": "3.2 Instance-dependent upper bound"}, {"figure_path": "aCaspFfAhG/tables/tables_7_1.jpg", "caption": "Table 1: Instance-dependent lower bound.", "description": "This table presents the Instance-dependent lower bound for bandits with ranking feedback. It shows that no algorithm can achieve logarithmic regret in the time horizon T in the instance-dependent case. This result is crucial in understanding the limitations of bandit algorithms with ranking feedback and provides a theoretical foundation for the design of instance-dependent algorithms.", "section": "3.1 Instance-dependent lower bound"}]