[{"figure_path": "06Vt6f2js7/tables/tables_4_1.jpg", "caption": "Table 1: A quantitative comparison in ambiguous image generation. KID [6] is scaled by 10<sup>3</sup>. For each row, we highlight the column whose value is within 95% of the best.", "description": "This table presents a quantitative comparison of different diffusion synchronization methods (Cases 1-5) and Visual Anagrams [18] (Case 4) for ambiguous image generation.  The metrics used for comparison include CLIP-A [18], CLIP-C [18], FID [21], and KID [6].  The table highlights the best-performing method (within 95% of the best) for each metric and projection type (1-to-1, 1-to-n, and n-to-1).  The KID values are scaled by 10<sup>3</sup> for easier comparison. The results indicate the relative performance of each method under different scenarios of image transformation.", "section": "3.4 Comparison Across the Diffusion Synchronization Processes"}, {"figure_path": "06Vt6f2js7/tables/tables_6_1.jpg", "caption": "Table 2: Analysis of diffusion synchronization processes on different projection scenarios. SyncTweedies offers the broadest range of applications.", "description": "This table summarizes the applicability of different diffusion synchronization methods (Cases 1-5) across various projection scenarios (1-to-1, 1-to-n, n-to-1).  A green checkmark indicates suitability, while a red 'X' signifies unsuitability.  It highlights that SyncTweedies (Case 2) shows the broadest applicability, performing well across all three projection types. The table also provides a link to previous works that investigated specific cases of diffusion synchronization.", "section": "3.4 Comparison Across the Diffusion Synchronization Processes"}, {"figure_path": "06Vt6f2js7/tables/tables_7_1.jpg", "caption": "Table 3: A quantitative comparison in 3D mesh texturing. KID is scaled by 10<sup>3</sup>. The best in each row is highlighted by bold.", "description": "This table presents a quantitative comparison of different methods for 3D mesh texturing.  It compares SyncTweedies (and other variations of the diffusion synchronization process) against several baselines, including finetuning-based methods (Paint3D [63]), optimization-based methods (Paint-it [62]), and iterative view updating methods (TEXTURE [44], Text2Tex [10]).  The metrics used for comparison are FID (Fr\u00e9chet Inception Distance), KID (Kernel Inception Distance), and CLIP-S (CLIP Similarity).  Lower FID and KID scores indicate better fidelity, while higher CLIP-S scores represent better alignment with the text prompts. The best performing method in each row is highlighted in bold.", "section": "5.1 3D Mesh Texturing"}, {"figure_path": "06Vt6f2js7/tables/tables_8_1.jpg", "caption": "Table 4: A quantitative comparison in depth-to-360-panorama application. KID is scaled by 10<sup>3</sup>. The best in each row is highlighted by bold.", "description": "This table presents a quantitative comparison of different diffusion synchronization methods for depth-to-360-panorama generation.  It shows the FID (Fr\u00e9chet Inception Distance), KID (Kernel Inception Distance), and CLIP-S (CLIP Similarity) scores for each method, including SyncTweedies (Case 1, 2, 3, 4, 5) and MVDiffusion [56].  Lower FID and KID scores indicate better image quality, and higher CLIP-S scores suggest better text alignment.  The best performing method in each metric is highlighted in bold.", "section": "5.2 Depth-to-360-Panorama"}, {"figure_path": "06Vt6f2js7/tables/tables_9_1.jpg", "caption": "Table 3: A quantitative comparison in 3D mesh texturing. KID is scaled by 10<sup>3</sup>. The best in each row is highlighted by bold.", "description": "This table presents a quantitative comparison of different methods for 3D mesh texturing, including SyncTweedies and several baselines (finetuning-based, optimization-based, and iterative view updating methods).  The metrics used for comparison are FID (Fr\u00e9chet Inception Distance), KID (Kernel Inception Distance), and CLIP-S (CLIP Similarity).  Lower FID and KID scores indicate better image quality, while higher CLIP-S scores represent better alignment between generated textures and text prompts.  The table highlights SyncTweedies' superior performance in terms of image quality and text alignment compared to the baseline methods.", "section": "5.1 3D Mesh Texturing"}, {"figure_path": "06Vt6f2js7/tables/tables_20_1.jpg", "caption": "Table 6: A quantitative comparison in arbitrary-sized image generation. KID is scaled by 10<sup>3</sup>. For each row, we highlight the column whose value is within 95% of the best.", "description": "This table presents a quantitative comparison of different diffusion synchronization processes in the context of arbitrary-sized image generation.  The metrics used for comparison are FID (Frechet Inception Distance), KID (Kernel Inception Distance), and CLIP-S (CLIP similarity).  The results show very similar performance across all methods (Cases 1-5) in this 1-to-1 projection scenario. The table highlights the best performing method (within a 95% margin) for each metric.", "section": "C Arbitray-Sized Image Generation"}, {"figure_path": "06Vt6f2js7/tables/tables_24_1.jpg", "caption": "Table 7: A runtime comparison in 3D mesh texturing and 3D Gaussian splats texturing applications. The best in each row is highlighted by **bold**.", "description": "This table compares the runtime performance (in minutes) of different methods for 3D mesh texturing and 3D Gaussian splats texturing.  The methods compared include SyncTweedies (Case 2), Paint3D (a finetuning-based method), Paint-it (an optimization-based method), TEXTure and Text2Tex (iterative view updating methods), and SDS and IN2N.  The table highlights the fastest runtime for each task.", "section": "F Runtime and VRAM Usage Comparison"}, {"figure_path": "06Vt6f2js7/tables/tables_24_2.jpg", "caption": "Table 8: A VRAM usage comparison in 3D mesh texturing and 3D Gaussian splats texturing applications. The best in each row is highlighted by bold.", "description": "This table compares the VRAM usage (in GiB) of different methods for 3D mesh texturing and 3D Gaussian splats texturing.  It shows the VRAM usage of SyncTweedies (Case 2),  finetuning-based methods (Paint3D [63]), optimization-based methods (Paint-it [62], SDS [41]), and iterative view updating methods (TEXTure [44], Text2Tex [10], IN2N [19]). The lowest VRAM usage for each task is highlighted in bold.", "section": "F Runtime and VRAM Usage Comparison"}, {"figure_path": "06Vt6f2js7/tables/tables_25_1.jpg", "caption": "Table 3: A quantitative comparison in 3D mesh texturing. KID is scaled by 10<sup>3</sup>. The best in each row is highlighted by bold.", "description": "This table presents a quantitative comparison of different methods for 3D mesh texturing.  It compares SyncTweedies (the proposed method) with several baselines including finetuning-based methods, optimization-based methods, and iterative view updating methods.  The metrics used for comparison are FID (Fr\u00e9chet Inception Distance), KID (Kernel Inception Distance), and CLIP-S (CLIP Similarity).  Lower FID and KID scores indicate better image quality, while higher CLIP-S scores indicate better alignment with text prompts.  The table highlights the best performing method for each metric.", "section": "5 3D Mesh Texturing"}, {"figure_path": "06Vt6f2js7/tables/tables_27_1.jpg", "caption": "Table 1: A quantitative comparison in ambiguous image generation. KID [6] is scaled by 10<sup>3</sup>. For each row, we highlight the column whose value is within 95% of the best.", "description": "This table presents a quantitative comparison of different diffusion synchronization processes in the task of ambiguous image generation.  The metrics used for comparison include CLIP-A, CLIP-C, FID, and KID.  The KID values are scaled by a factor of 1000 for easier readability. For each metric, the best-performing diffusion synchronization process (within a 95% margin of error) is highlighted for each projection type (1-to-1, 1-to-n, and n-to-1). The table helps to illustrate which method performs best based on different image projection configurations.", "section": "3.4 Comparison Across the Diffusion Synchronization Processes"}, {"figure_path": "06Vt6f2js7/tables/tables_31_1.jpg", "caption": "Table 1: A quantitative comparison in ambiguous image generation. KID [6] is scaled by 10<sup>3</sup>. For each row, we highlight the column whose value is within 95% of the best.", "description": "This table presents a quantitative comparison of different diffusion synchronization methods for generating ambiguous images.  The metrics used are CLIP-A (higher is better), CLIP-C (higher is better), FID (lower is better), and KID (lower is better). Each row represents a different method (including SyncTweedies and baselines). The best performing method for each metric in each row is highlighted.", "section": "3.4 Comparison Across the Diffusion Synchronization Processes"}, {"figure_path": "06Vt6f2js7/tables/tables_32_1.jpg", "caption": "Table 1: A quantitative comparison in ambiguous image generation. KID [6] is scaled by 10<sup>3</sup>. For each row, we highlight the column whose value is within 95% of the best.", "description": "This table presents a quantitative comparison of different diffusion synchronization processes in the task of ambiguous image generation.  The metrics used for comparison include CLIP-A (higher is better), CLIP-C (higher is better), FID (lower is better), and KID (lower is better).  The table highlights the best performing case within 95% for each metric, allowing for a clear comparison of the effectiveness of the different methods in generating high-quality and diverse ambiguous images.  Five different scenarios (cases) are compared in addition to a baseline approach with no synchronization. The 1-to-1, 1-to-n and n-to-1 projections represent different mapping scenarios between the canonical space and instance spaces for the images.", "section": "3.4 Comparison Across the Diffusion Synchronization Processes"}, {"figure_path": "06Vt6f2js7/tables/tables_33_1.jpg", "caption": "Table 1: A quantitative comparison in ambiguous image generation. KID [6] is scaled by 10<sup>3</sup>. For each row, we highlight the column whose value is within 95% of the best.", "description": "This table presents a quantitative comparison of different diffusion synchronization processes for ambiguous image generation.  The metrics used are CLIP-A, CLIP-C, FID, and KID.  The table highlights the best performing method (within 95% of the best) for each metric across five different synchronization processes (Cases 1-5).  The results showcase the relative performance of each method, demonstrating how different approaches affect the generation quality of ambiguous images.", "section": "3.4 Comparison Across the Diffusion Synchronization Processes"}]