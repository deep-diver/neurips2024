[{"figure_path": "exATQD4HSv/tables/tables_8_1.jpg", "caption": "Table 1: DSR measures evaluated for the convSSM, standard SSM, convSSM trained without GTF, as well as MINDy [62], rSLDS [44] and LFADS [14], trained on the LEMON dataset. Model runs were excluded if the 1-step PE > 1 on the training data.", "description": "This table compares the performance of different dynamical systems reconstruction (DSR) models on the LEMON fMRI dataset.  The metrics used are Dstsp (state space divergence, measuring geometrical overlap of orbits in state space), DPSE (power spectrum error), and 10-step PE (prediction error). The results show the convSSM generally outperforms other methods, particularly in terms of Dstsp and DPSE.", "section": "3 Results"}, {"figure_path": "exATQD4HSv/tables/tables_21_1.jpg", "caption": "Table 2: Quantitative comparison between standard SSM and convSSM on noisy Lorenz63 data (Nconverged is the number of converged models).", "description": "This table presents a quantitative comparison of the performance of standard SSM and convSSM models on the Lorenz63 dataset with added noise.  Different levels of noise (\u03c3) and convolution filter lengths (hrf) were used.  The metrics reported include the mean squared prediction error (PE20), state space divergence (Dstsp), and power spectrum error (DPSE). The number of converged models (Nconverged) is also shown, indicating the proportion of successful training runs for each condition.", "section": "3 Results"}, {"figure_path": "exATQD4HSv/tables/tables_22_1.jpg", "caption": "Table 3: DSR measures evaluated on the ALN data set for the convSSM, the standard SSM, and the convSSM trained without generalized teacher forcing by setting \u03b1 = 0. Measures were evaluated on the ground truth latent space and the noisy observation space on the different created test sets.", "description": "This table presents the results of Dynamical Systems Reconstruction (DSR) performance evaluation using three different models (convSSM, standard SSM, and convSSM without GTF) on the ALN dataset.  It compares performance metrics (Dstsp, DPSE, and 10-step PE) across three different test conditions: full pseudo-empirical time series, pseudo-empirical test set, and ground truth test set, evaluating the models both in latent space and the noisy observation space of the data.", "section": "3 Results"}, {"figure_path": "exATQD4HSv/tables/tables_24_1.jpg", "caption": "Table 4: Hyperparameter settings for the experiments conducted. 'Varies' means the respective hyperparameter was varied in the experiment.", "description": "This table shows the hyperparameters used in the experiments described in the paper.  It breaks down the settings used for three different benchmarks: the Lorenz63 system, the ALN model, and the LEMON dataset. For each benchmark, it shows the values used for various parameters such as the latent dimension, Gaussian noise level, optimizer used, learning rate, batch size, model type, and other relevant training parameters. Note that some parameters are given fixed values, while others vary across experiments.", "section": "B.4 Hyperparameter settings for the different experiments"}]