[{"figure_path": "2NKumsITFw/figures/figures_9_1.jpg", "caption": "Figure 2: Average accuracy on the CIFAR-10 and CIFAR-100 datasets (R = 5) for different e values.", "description": "This figure shows the average test accuracy achieved by the proposed AdaptCDRP method on CIFAR-10 and CIFAR-100 datasets with different values of the hyperparameter epsilon (\u03b5).  The results are shown for three different noise levels (IDN-LOW, IDN-MID, IDN-HIGH) in the synthetically generated noisy labels.  The x-axis represents the values of epsilon, and the y-axis represents the test accuracy.  The shaded area around each line indicates the standard deviation of the results obtained over five repeated experiments. This figure demonstrates the impact of the robustness hyperparameter on the model's performance across different noise levels and datasets.", "section": "4 Experimental Results"}, {"figure_path": "2NKumsITFw/figures/figures_9_2.jpg", "caption": "Figure 1: Average test accuracy on the CIFAR-10 dataset with varying numbers of annotators. The shaded areas are constructed using the associated standard deviations.", "description": "This figure shows the average test accuracy and standard deviation across different numbers of annotators (5, 10, 30, 50, 100) for the CIFAR-10 dataset.  The results are broken down by three annotator groups representing different levels of expertise: IDN-LOW (low noise), IDN-MID (medium noise), and IDN-HIGH (high noise).  Each data point represents the average performance across multiple trials. The shaded areas illustrate the standard deviation, providing a measure of variability for each data point. The figure demonstrates how the proposed method (AdaptCDRP) performs compared to other methods under varying levels of annotation sparsity.", "section": "4 Experimental Results"}, {"figure_path": "2NKumsITFw/figures/figures_35_1.jpg", "caption": "Figure 1: Average test accuracy on the CIFAR-10 dataset with varying numbers of annotators. The shaded areas are constructed using the associated standard deviations.", "description": "This figure shows the average test accuracy achieved by different methods on the CIFAR-10 dataset under various noise conditions and varying number of annotators (5,10,30,50,100).  The shaded area around each line represents the standard deviation. The results demonstrate the performance of AdaptCDRP across different levels of annotation sparsity and noise.", "section": "4 Experimental Results"}, {"figure_path": "2NKumsITFw/figures/figures_36_1.jpg", "caption": "Figure 4: Average accuracy of robust pseudo-labels on the CIFAR-10 and CIFAR-100 datasets (R = 5) during the training process.", "description": "This figure shows the average accuracy of the robust pseudo-labels generated by the proposed AdaptCDRP method during the training process on CIFAR-10 and CIFAR-100 datasets.  The number of annotators (R) is fixed at 5.  Three different groups of annotators with varying levels of expertise (IDN-LOW, IDN-MID, and IDN-HIGH) are presented, illustrating the impact of noise level on the pseudo-label accuracy.  The plot shows how the accuracy evolves over iterations, providing insights into the performance of the robust pseudo-labeling algorithm under different noise conditions and datasets.", "section": "Experimental Results"}, {"figure_path": "2NKumsITFw/figures/figures_37_1.jpg", "caption": "Figure 5: Average accuracy of robust pseudo-labels on the CIFAR-10 dataset with varying number of annotators in the training process.", "description": "This figure shows the average accuracy of robust pseudo-labels on the CIFAR-10 dataset for different numbers of annotators (R=5, 10, 30, 50, 100) and for different noise levels (IDN-LOW, IDN-MID, IDN-HIGH). The shaded areas represent the standard deviations of the accuracies across multiple runs.  The figure illustrates how the accuracy of the robust pseudo-labels changes during the training process. The accuracy is generally high and stable across different numbers of annotators and noise levels.", "section": "Experimental Results"}, {"figure_path": "2NKumsITFw/figures/figures_37_2.jpg", "caption": "Figure 6: Average test accuracy on learning the CIFAR-10 dataset (R = 5) during the training process.", "description": "This figure shows the test accuracy on the CIFAR-10 dataset with R=5 annotators over the training epochs for different noise levels (IDN-LOW, IDN-MID, IDN-HIGH).  It compares the performance of AdaptCDRP to several baseline methods. The shaded region at the beginning indicates the warm-up period where the model is trained on the noisy labels before applying the robust pseudo-labeling strategy.", "section": "4 Experimental Results"}, {"figure_path": "2NKumsITFw/figures/figures_38_1.jpg", "caption": "Figure 1: Average test accuracy on the CIFAR-10 dataset with varying numbers of annotators. The shaded areas are constructed using the associated standard deviations.", "description": "This figure shows the average test accuracy of different methods on the CIFAR-10 dataset with varying numbers of annotators.  The x-axis represents the number of annotators, and the y-axis represents the test accuracy. Different lines represent different methods, including the proposed AdaptCDRP method and several baseline methods. The shaded area around each line represents the standard deviation of the test accuracy. The figure is divided into three subfigures (a), (b), and (c), corresponding to different levels of noise in the labels (IDN-LOW, IDN-MID, IDN-HIGH). The figure demonstrates the performance of the proposed method under various levels of noise and with varying degrees of labeling completeness (different numbers of annotators).", "section": "4 Experimental Results"}, {"figure_path": "2NKumsITFw/figures/figures_38_2.jpg", "caption": "Figure 8: Average test accuracies for learning the CIFAR-10 and CIFAR-100 datasets with varying numbers of warm-up epochs. The error bars representing standard deviation are shaded.", "description": "The figure shows the impact of different warm-up durations on the performance of the proposed AdaptCDRP method and several baseline methods.  The results are shown for the CIFAR-10 and CIFAR-100 datasets, with different noise levels (IDN-LOW, IDN-MID, IDN-HIGH). The x-axis represents the number of warm-up epochs, and the y-axis represents the test accuracy. Error bars are included to show the standard deviation across multiple runs.", "section": "Additional experimental results"}, {"figure_path": "2NKumsITFw/figures/figures_39_1.jpg", "caption": "Figure 9: Average accuracy of robust pseudo-labels on the CIFAR-10 dataset (R = 200) using different transition matrix estimation methods during the training process.", "description": "This figure shows the average accuracy of robust pseudo-labels generated by the AdaptCDRP method on the CIFAR-10 dataset with 200 annotators.  Three different methods for estimating the noise transition matrix were used: frequency counting, GeoCrowdNet (F), and GeoCrowdNet (W). The results show that the GeoCrowdNet methods provide slightly higher average accuracy of pseudo-labels compared to the frequency counting approach, particularly in the IDN-LOW condition.  The error bars indicate the standard deviation across five random trials.  The x-axis represents training iterations and the y-axis represents robust pseudo-label accuracy.", "section": "Additional experimental results"}]