[{"figure_path": "8HeUvbImKT/figures/figures_1_1.jpg", "caption": "Figure 1: Why random perturbations? Left: We visualize densities of CIFAR10 (ID, blue) and CIFAR100 (OOD, red) as contour plots along the two logit dimensions spanned by w\u2080 and w\u2081, zoomed in on the positive cluster of class zero. The blue axis denotes the vector associated with that class, and one of its perturbations is depicted by the turquoise line. Right: When projecting the data onto both vectors, we obtain the densities shown in the top and bottom panel, respectively. The vertical blue lines mark the 5-percentile (highest 5%) of the true ID data (CIFAR10, blue). At this decision boundary, the classifier would produce false positives in the marked dashed red tail area. A single perturbation of the class-associated vector yields already a reduction of the false positive rate (FPR) from 1.34% to 0.79%. Visually, we confirm that OOD data mostly resides close to 0, extending into the positive cluster in a particular conical shape, which is exploited by the cone of WeiPer vectors.", "description": "This figure demonstrates the effectiveness of WeiPer's weight perturbations in improving OOD detection. The left panel shows contour plots visualizing the densities of in-distribution (ID) and out-of-distribution (OOD) data projected onto two logit dimensions.  It highlights how OOD data extends into the positive cluster in a conical shape. The right panel shows the densities when projected onto the original weight vector and a perturbed one. This illustrates how a single perturbation reduces false positives, showcasing the advantage of WeiPer's approach.", "section": "1 Introduction"}, {"figure_path": "8HeUvbImKT/figures/figures_4_1.jpg", "caption": "Figure 2: WeiPer perturbs the weight vectors of Wfc by an angle controlled by \u03b4. For each weight, we construct r perturbations resulting in r weight matrices W1, ..., Wr. KLD: For WeiPer+KLD, we treat z1, ..., zk ~ pz and w1,1z, ..., wr,cz ~ P\u0174z as samples of the same distribution induced by z and Wz, respectively. We approximate the densities with histograms and smooth the result with uniform kernel Tk. Afterwards, we compare the densities Tk(qz) with the mean distribution over the training samples Ez\u2208Ztrain(qz) for qz = pz and qz = P\u0174z, respectively. MSP: For a score function S on the logit space RC, we define the perturbed score SweiPer as the mean over all the perturbed logit spaces Wz. We choose S = MSP and call the resulting detector MSPWeiPer.", "description": "This figure illustrates the WeiPer method for out-of-distribution detection.  The left panel shows how WeiPer perturbs the weight vectors (Wfc) of the final fully connected layer by an angle controlled by the hyperparameter \u03b4, creating r weight matrices (W1,...,Wr).  The center panel depicts the Kullback-Leibler Divergence (KLD) calculation for WeiPer+KLD, comparing the densities of the original penultimate layer activations (pz) and the perturbed activations (P\u0175z). The right panel shows the calculation of the MSP (Maximum Softmax Probability) score for the WeiPer+MSP method, averaging the MSP scores across all r perturbed logit spaces.", "section": "3.2 WeiPer: Weight perturbations"}, {"figure_path": "8HeUvbImKT/figures/figures_5_1.jpg", "caption": "Figure 3: Histogram of all 512 activations in the penultimate layer (left pair) and the activations in WeiPer space (right pair) of a ResNet18 trained on CIFAR10. We perturb the weight matrix 100 times to produce a 100 \\* 100 = 10000-dimensional perturbed logit space. For each pair, the left panel shows the mean distribution over all samples (ID = CIFAR10, OOD = CIFAR100). The right panels show the distribution pz and pwz, respectively, for two randomly chosen samples with smoothing applied ($1 = 82 = 2).", "description": "This figure visualizes the activation distributions in both the penultimate layer and the augmented WeiPer space for a ResNet18 model trained on CIFAR10.  The left pair shows the mean distributions (CIFAR10 as ID and CIFAR100 as OOD), while the right pair shows the distributions for two individual samples.  It highlights the similarity in distribution between ID samples in both spaces, contrasting with the OOD sample distribution which differs more significantly. The visualization helps demonstrate WeiPer's ability to enhance the separation of in-distribution and out-of-distribution samples.", "section": "3.4 Our KL divergence score function"}, {"figure_path": "8HeUvbImKT/figures/figures_8_1.jpg", "caption": "Figure 4: We investigate the effect of WeiPer hyperparameters r and \u03b4 on the performance of the three postprocessors. The left pair shows results on CIFAR10, the right pair corresponds to ImageNet (using ResNet18 for both). Models were tested using their respective near OOD datasets. The panels corresponding to \u03b4 depict AUROC performance minus the initial AUROC performance at \u03b4 = 0. The graphs show the mean over 25 runs and the shaded area around them represents the value range (min to max) over those runs. All other parameters of the methods were fixed to the optimal setting.", "description": "This figure analyzes the impact of hyperparameters r (number of weight perturbations) and \u03b4 (angle of perturbation) on the performance of three OOD detection postprocessors (KLD, MSP, and ReAct) using CIFAR10 and ImageNet datasets.  It shows that increasing r generally improves performance while the optimal \u03b4 value varies depending on the method and dataset. The shaded areas represent the range of AUROC scores across multiple runs.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/figures/figures_14_1.jpg", "caption": "Figure 1: Why random perturbations? Left: We visualize densities of CIFAR10 (ID, blue) and CIFAR100 (OOD, red) as contour plots along the two logit dimensions spanned by w\u2080 and w\u2081, zoomed in on the positive cluster of class zero. The blue axis denotes the vector associated with that class, and one of its perturbations is depicted by the turquoise line. Right: When projecting the data onto both vectors, we obtain the densities shown in the top and bottom panel, respectively. The vertical blue lines mark the 5-percentile (highest 5%) of the true ID data (CIFAR10, blue). At this decision boundary, the classifier would produce false positives in the marked dashed red tail area. A single perturbation of the class-associated vector yields already a reduction of the false positive rate (FPR) from 1.34% to 0.79%. Visually, we confirm that OOD data mostly resides close to 0, extending into the positive cluster in a particular conical shape, which is exploited by the cone of WeiPer vectors.", "description": "This figure demonstrates the effectiveness of random weight perturbations in improving OOD detection.  The left panel shows contour plots visualizing the density distributions of in-distribution (ID) and out-of-distribution (OOD) data projected onto two logit dimensions.  It highlights how OOD data extends into the positive cluster of ID data in a conical shape. The right panel shows the density distributions when projected onto the original and a perturbed class vector, revealing that a single perturbation significantly reduces false positives. This illustrates how WeiPer leverages this conical shape of OOD data within the ID data's distribution for improved OOD detection.", "section": "1 Introduction"}, {"figure_path": "8HeUvbImKT/figures/figures_16_1.jpg", "caption": "Figure 6: KLD specific hyperparamters: We fixed the optimal hyperparameters and varied the one parameter in question by conducting 10 runs over the same fixed parameter setting on CIFAR10 and ImageNet as ID against their near OOD datasets. We report the mean and the minimum to maximum range (transparent). We set r = 5 instead of r = 100 for ImageNet to save resources. Thus the noise on the results is stronger for the ImageNet ablations. All of the parameters except the kernel sizes only have a single local maximum which indicates that they should be easy to optimize. The most important parameters seem to be the kernel sizes s1 and s2 that we use for smoothing followed by nbins. Note that s1 and s2 have a different optimum, which means it is not possible to simply choose s1 = s2 and reduce the count of hyperparameters. \u03bb1 = 0 is the score function without the KLD specific WeiPer application. \u03bb2 is the application of MSPWeiPer which is not beneficial for CIFAR10, but shows to be effective on ImageNet.", "description": "This figure displays ablation studies on the hyperparameters of the KL divergence score function used in the WeiPer+KLD method. It shows how AUROC changes as each hyperparameter is varied individually while holding the others constant.  The plots reveal the optimal ranges for nbins, \u03bb1, \u03bb2, s1, and s2, highlighting the effect of each parameter on the model's performance for both CIFAR10 and ImageNet datasets.", "section": "A.3 Hyperparameters"}, {"figure_path": "8HeUvbImKT/figures/figures_17_1.jpg", "caption": "Figure 3: Histogram of all 512 activations in the penultimate layer (left pair) and the activations in WeiPer space (right pair) of a ResNet18 trained on CIFAR10. We perturb the weight matrix 100 times to produce a 1000-dimensional perturbed logit space. For each pair, the left panel shows the mean distribution over all samples (ID = CIFAR10, OOD = CIFAR100). The right panels show the distribution pz and pwz, respectively, for two randomly chosen samples with smoothing applied ($1 = $2 = 2).", "description": "This figure visualizes the distribution of activations in both the penultimate layer and the WeiPer space of a ResNet18 model trained on CIFAR10.  The left pair shows the average distribution of activations, while the right pair shows the distribution for two individual samples. The WeiPer space, created by perturbing the weight matrix 100 times, has 1000 dimensions. The distributions are compared for both in-distribution (CIFAR10, blue) and out-of-distribution (CIFAR100, red) samples, highlighting the differences in activation patterns between the two.", "section": "3.4 Our KL divergence score function"}, {"figure_path": "8HeUvbImKT/figures/figures_18_1.jpg", "caption": "Figure 3: Histogram of all 512 activations in the penultimate layer (left pair) and the activations in WeiPer space (right pair) of a ResNet18 trained on CIFAR10. We perturb the weight matrix 100 times to produce a 100 \\* 100 = 10000-dimensional perturbed logit space. For each pair, the left panel shows the mean distribution over all samples (ID = CIFAR10, OOD = CIFAR100). The right panels show the distribution pz and p\u0175z, respectively, for two randomly chosen samples with smoothing applied (s1 = s2 = 2).", "description": "This figure visualizes the activation distributions in the penultimate layer and the WeiPer space for a ResNet18 model trained on CIFAR-10.  The left pair of histograms shows the mean distribution of activations across all samples for both in-distribution (CIFAR-10) and out-of-distribution (CIFAR-100) data in the penultimate layer. The right pair shows the distributions for two specific samples, highlighting the effect of the WeiPer transformation.  The 100 weight perturbations create a 10,000-dimensional space, and the histograms show how this transformation affects the data distributions, particularly the separation of in-distribution and out-of-distribution samples.", "section": "3.4 Our KL divergence score function"}]