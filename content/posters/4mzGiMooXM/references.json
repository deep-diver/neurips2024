{"references": [{"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with clip latents", "publication_date": "2022-04-06", "reason": "This paper is foundational to the work because it introduces the use of CLIP latent diffusion models for text-to-image generation, a core component of the research."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper is highly relevant as it introduces high-resolution image synthesis using latent diffusion models, which is a key technique that the current research builds upon and improves."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "CLIP, introduced in this paper, is the core text encoder used in text-to-image diffusion models and is central to the analysis and proposed solution for improving attribute binding."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-00-00", "reason": "This paper is important for providing a state-of-the-art model which the current research uses as a baseline for comparison and improvement, highlighting the challenges in generating images from complex prompts."}, {"fullname_first_author": "Hila Chefer", "paper_title": "Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models", "publication_date": "2023-00-00", "reason": "This paper is a key comparison point, proposing an optimization method to address attribute binding, providing a direct contrast to the current research's training-free approach."}]}