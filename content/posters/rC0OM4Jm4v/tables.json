[{"figure_path": "rC0OM4Jm4v/tables/tables_6_1.jpg", "caption": "Table 1: mini-ImageNet: We use our augmentations on (5-way, 1-shot) and (5-way, 5-shot) few-shot settings of mini-Imagenet dataset with 3 different backbones (ResNet-18, 34, and 50). We compare with various baselines and show that our augmentations with UniSiam outperform all the baselines including Txt2Img and DAFusion augmentation. The number of generated images per class is 4 for 1-shot and 20 for 5-shot settings.", "description": "This table presents the results of few-shot classification experiments on the mini-ImageNet dataset using three different ResNet backbones (ResNet-18, ResNet-34, and ResNet-50).  The table compares the performance of UniSiam, a state-of-the-art unsupervised few-shot learning method, when using different augmentation techniques, including the proposed GeNIe and GeNIe-Ada methods.  For each backbone, results are shown for both 1-shot and 5-shot settings, indicating the number of samples per class used during training. The table also includes results for several baseline augmentation methods, such as traditional augmentations (weak and strong) and other generative methods, like CutMix, MixUp, Img2Img, and Txt2Img.  The performance is measured using accuracy. ", "section": "4.1 Few-shot Classification"}, {"figure_path": "rC0OM4Jm4v/tables/tables_7_1.jpg", "caption": "Table 1: mini-ImageNet: We use our augmentations on (5-way, 1-shot) and (5-way, 5-shot) few-shot settings of mini-Imagenet dataset with 3 different backbones (ResNet-18, 34, and 50). We compare with various baselines and show that our augmentations with UniSiam outperform all the baselines including Txt2Img and DAFusion augmentation. The number of generated images per class is 4 for 1-shot and 20 for 5-shot settings.", "description": "This table presents the results of few-shot image classification experiments on the mini-ImageNet dataset using three different ResNet backbones (ResNet-18, 34, and 50).  The experiments compare the performance of UniSiam, a state-of-the-art unsupervised few-shot learning method, with and without various data augmentation techniques.  Augmentations include traditional methods (weak and strong) along with generative methods (GeNIe, GeNIe-Ada, Txt2Img, Img2Img, DA-Fusion) to evaluate the impact of the proposed augmentation method on few-shot learning performance. The table reports the 1-shot and 5-shot classification accuracies for each method, backbone, and augmentation strategy.", "section": "4.1 Few-shot Classification"}, {"figure_path": "rC0OM4Jm4v/tables/tables_8_1.jpg", "caption": "Table 4: Effect of Noise in GeNIe: We use the same setting as in Table 1 to study the effect of the amount of noise. As expected (also shown in Fig 5), small noise results in worse accuracy since some generated images may be from the source category rather than the target one. For r = 0.5 only 73% of the generated data is from the target category. This behaviour is also shown in Fig. 2. Notably, reducing the noise level below 0.7 is associated with a decline in oracle accuracy and subsequent degradation in the performance of the final few-shot model. Note that the high oracle accuracy of GeNIe-Ada demonstrates its capability to adaptively select the noise level per source and target, ensuring semantic consistency with the intended target.", "description": "This table shows the effect of different noise levels on the performance of GeNIe and GeNIe-Ada in a few-shot classification setting.  It demonstrates that a noise level between 0.7 and 0.8 yields the best results, with lower noise levels resulting in lower accuracy.  The high oracle accuracy of GeNIe-Ada highlights the effectiveness of the adaptive noise selection strategy.", "section": "4.1 Few-shot Classification"}, {"figure_path": "rC0OM4Jm4v/tables/tables_16_1.jpg", "caption": "Table A1: Few-shot Learning on Fine-grained dataset: We utilize an SVM classifier trained atop the DINOv2 ViT-G pretrained backbone, reporting Top-1 accuracy for the test set of each dataset. The baseline is an SVM trained on the same backbone using weak augmentation. Across all datasets, GeNIe surpasses this baseline.", "description": "This table presents the results of few-shot learning experiments on four fine-grained image datasets (CUB200, Cars196, Food101, and Aircraft).  It compares the performance of GeNIe and several baselines in a 20-way, 1-shot classification setting, using an SVM classifier trained on features extracted by the DINOv2 ViT-G model. The \"Baseline\" refers to an SVM trained using weak augmentation. The table shows that GeNIe consistently outperforms the baseline and other methods across all datasets.", "section": "A.2 Fine-grained Few-shot Classification"}, {"figure_path": "rC0OM4Jm4v/tables/tables_16_2.jpg", "caption": "Table A3: tiered-ImageNet: Accuracies (% \u00b1 std) for 5-way, 1-shot and 5-way, 5-shot classification settings on the test-set. We compare against various SOTA supervised and unsupervised few-shot classification baselines as well as other augmentation methods, with UniSiam [61] pre-trained ResNet-34 backbone.", "description": "This table presents the results of few-shot image classification experiments on the tiered-ImageNet dataset using various methods, including the proposed GeNIe and GeNIe-Ada techniques. It compares the performance of these methods against several state-of-the-art supervised and unsupervised few-shot learning baselines and other data augmentation strategies, all while employing a ResNet-34 backbone pre-trained with UniSiam. The results are reported in terms of accuracy with standard deviations for both 5-way 1-shot and 5-way 5-shot classification settings.", "section": "A.3 Few-shot Classification with ResNet-34 on tieredImagenet"}, {"figure_path": "rC0OM4Jm4v/tables/tables_17_1.jpg", "caption": "Table 1: mini-ImageNet: We use our augmentations on (5-way, 1-shot) and (5-way, 5-shot) few-shot settings of mini-Imagenet dataset with 3 different backbones (ResNet-18, 34, and 50). We compare with various baselines and show that our augmentations with UniSiam outperform all the baselines including Txt2Img and DAFusion augmentation. The number of generated images per class is 4 for 1-shot and 20 for 5-shot settings.", "description": "This table presents the results of few-shot classification experiments on the mini-ImageNet dataset using three different ResNet backbones (ResNet-18, 34, and 50).  The table compares the performance of the UniSiam model with various data augmentation techniques, including the proposed GeNIe and GeNIe-Ada methods, against several baseline methods.  The augmentations are tested in both 5-way 1-shot and 5-way 5-shot settings.  The number of generated augmented images per class is also specified. The results highlight the superiority of the GeNIe methods in improving few-shot learning performance.", "section": "4.1 Few-shot Classification"}, {"figure_path": "rC0OM4Jm4v/tables/tables_18_1.jpg", "caption": "Table 1: mini-ImageNet: We use our augmentations on (5-way, 1-shot) and (5-way, 5-shot) few-shot settings of mini-Imagenet dataset with 3 different backbones (ResNet-18, 34, and 50). We compare with various baselines and show that our augmentations with UniSiam outperform all the baselines including Txt2Img and DAFusion augmentation. The number of generated images per class is 4 for 1-shot and 20 for 5-shot settings.", "description": "This table presents the results of few-shot image classification experiments on the mini-ImageNet dataset using three different ResNet backbones (ResNet-18, ResNet-34, and ResNet-50).  The experiments compare the performance of the proposed GeNIe and GeNIe-Ada augmentation methods against several baseline methods, including traditional augmentation techniques (weak and strong augmentations),  other generative augmentation methods (Img2Img, Txt2Img, DAFusion), and a baseline using UniSiam without augmentation. The table shows the classification accuracy (with standard deviation) for both 1-shot and 5-shot settings.  The number of generated images per class for each augmentation method is also specified. ", "section": "4.1 Few-shot Classification"}]