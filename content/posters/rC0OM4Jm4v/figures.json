[{"figure_path": "rC0OM4Jm4v/figures/figures_1_1.jpg", "caption": "Figure 1: Generative Hard Negative Images Through Diffusion (GeNIe): generates hard negative images that belong to the target category but are similar to the source image from low-level feature and contextual perspectives. GeNIe starts from a source image passing it through a partial noise addition process, and conditioning it on a different target category. By controlling the amount of noise, the reverse latent diffusion process generates images that serve as hard negatives for the source category.", "description": "The figure illustrates the GeNIe method. A source image is taken and random noise is added, controlled by ratio *r*.  This is then passed through a reverse diffusion model, conditioned on a text prompt describing a different target class than the source image's class.  The result is a generated image that is semantically similar to the target class but retains low-level features from the source image.  This generated image acts as a \"hard negative\" for the source class, making it a challenging example for a classifier to distinguish from the source class. The process is shown visually, highlighting the steps involved and the final augmented image used in training.", "section": "1 Introduction"}, {"figure_path": "rC0OM4Jm4v/figures/figures_3_1.jpg", "caption": "Figure 2: Effect of noise ratio, r, in GeNIe: we employ GeNIe to generate augmentations for the target classes (motorcycle and cat) with varying r. Smaller r yields images closely resembling the source semantics, creating an inconsistency with the intended target label. By tracing r from 0 to 1, augmentations gradually transition from source image characteristics to the target category. However, a distinct shift from the source to the target occurs at a specific r that may vary for different source images or target categories. For more examples, please refer to Fig. A4.", "description": "This figure shows how the noise ratio r affects the generation of images using GeNIe.  As r increases, the generated images transition from characteristics of the source image to those of the target category. The transition is not linear; a rapid shift occurs at a specific point, demonstrating the importance of careful r selection for GeNIe\u2019s effectiveness.", "section": "3 Proposed Method: GeNIe"}, {"figure_path": "rC0OM4Jm4v/figures/figures_4_1.jpg", "caption": "Figure 3: GeNIe-Ada: To choose r adaptively for each (source image, target category) pair, we propose tracing the semantic trajectory from Zs (source image embeddings) to ZT (target embeddings) through the lens of the classifier fo() (Algorithm 1). We adaptively select the sample right after the largest semantic shift.", "description": "This figure illustrates the GeNIe-Ada algorithm, which automatically selects the optimal noise level (r*) for generating hard negative samples.  It does so by tracing the semantic trajectory between the source image embedding (Zs) and the target category embedding (ZT) using a classifier. The algorithm selects the point where the largest semantic shift occurs to achieve a balance between maintaining low-level source image features and the semantic meaning of the target class. The visualization shows a series of latent vectors (Zr) generated at different noise levels, highlighting the optimal point (r*) where the semantic shift is greatest.", "section": "3 Proposed Method: GeNIe"}, {"figure_path": "rC0OM4Jm4v/figures/figures_5_1.jpg", "caption": "Figure 4: Visualization of Generative Samples: We compare GeNIe with two baselines: Img2Img augmentation: both image and text prompt are from the same category. Adding noise does not change the image much, so they are not hard examples. Txt2Img augmentation: We simply use the text prompt only to generate an image for the desired category (e.g., using a text2image method). Such images may be far from the domain of our task since the generation is not informed by any visual data from our task. GeNIe augmentation: We use the target category name in the text prompt only along with the source image.", "description": "This figure compares the image generation results of three different methods: Img2Img, Txt2Img, and GeNIe. Img2Img uses the same image and text prompt, resulting in similar images that are not challenging examples for the model. Txt2Img only uses text prompts, generating images that may be unrelated to the task. GeNIe combines source images and target category text prompts, resulting in hard negative samples that are similar to the source image but belong to a different category.", "section": "4 Experiments"}, {"figure_path": "rC0OM4Jm4v/figures/figures_7_1.jpg", "caption": "Figure 5: Embedding visualizations of generative augmentations: We pass all generative augmentations through DINOv2 ViT-G (serving as an oracle) to extract their corresponding embeddings and visualize them with PCA. As shown, the extent of semantic shifts varies based on both the source image and the target class.", "description": "The figure shows embedding visualizations of augmentations generated by GeNIe using PCA.  It demonstrates how the generated images transition from the source image's semantics to the target class's semantics as the noise ratio (r) increases.  The embeddings show a clear shift in semantic space as r changes, indicating GeNIe's effectiveness in generating images that retain low-level features from the source image while representing the target category.", "section": "4.3 Ablation and Analysis"}, {"figure_path": "rC0OM4Jm4v/figures/figures_8_1.jpg", "caption": "Figure A2: Significant overlap between P(Ys|Xr*) and P(YT|Xr*) indicates high class-confusion for augmented samples generated by GeNIe-Ada.", "description": "This figure shows the density plots of the source class probabilities P(Ys|Xr) and the target class probabilities P(YT|Xr) for the augmented samples generated by GeNIe-Ada.  The significant overlap between the two probability distributions indicates high class confusion, suggesting that the augmented samples generated by GeNIe-Ada are located near the decision boundary of each class pair, which makes them challenging samples for the classifier.", "section": "A.1 Analyzing GeNIe, GeNIe-Ada's Class-Probabilities"}, {"figure_path": "rC0OM4Jm4v/figures/figures_15_1.jpg", "caption": "Figure 2: Effect of noise ratio, r, in GeNIe: we employ GeNIe to generate augmentations for the target classes (motorcycle and cat) with varying r. Smaller r yields images closely resembling the source semantics, creating an inconsistency with the intended target label. By tracing r from 0 to 1, augmentations gradually transition from source image characteristics to the target category. However, a distinct shift from the source to the target occurs at a specific r that may vary for different source images or target categories. For more examples, please refer to Fig. A4.", "description": "This figure shows how the noise ratio in GeNIe affects the generated images. With a lower ratio, the generated image resembles the source image more, while higher ratios lead to images more similar to the target category. There is a transition point where the generated images shift from being similar to the source image to being similar to the target category, and this point can vary depending on the source and target images.", "section": "Enhancing GeNIe: GeNIe-Ada"}, {"figure_path": "rC0OM4Jm4v/figures/figures_15_2.jpg", "caption": "Figure A2: Significant overlap between P(Ys|Xr*) and P(YT|Xr*) indicates high class-confusion for augmented samples generated by GeNIe-Ada.", "description": "This figure shows the density plots of the source class probabilities P(Ys|Xr*) and the target class probabilities P(YT|Xr*) for augmented samples generated by GeNIe-Ada. The significant overlap between the two distributions around probability scores of 0.2-0.45 indicates high class-confusion for these augmentations.  This supports the analysis in Section 4.3 and Table 4, empirically demonstrating that the samples generated by GeNIe-Ada for r=r* lie near the decision boundary of each class pair, making them challenging for the classifier to distinguish.", "section": "A.1 Analyzing GeNIe, GeNIe-Ada's Class-Probabilities"}, {"figure_path": "rC0OM4Jm4v/figures/figures_19_1.jpg", "caption": "Figure 4: Visualization of Generative Samples: We compare GeNIe with two baselines: Img2Img augmentation: both image and text prompt are from the same category. Adding noise does not change the image much, so they are not hard examples. Txt2Img augmentation: We simply use the text prompt only to generate an image for the desired category (e.g., using a text2image method). Such images may be far from the domain of our task since the generation is not informed by any visual data from our task. GeNIe augmentation: We use the target category name in the text prompt only along with the source image.", "description": "This figure compares the generated samples from three different methods: GeNIe, Img2Img, and Txt2Img.  GeNIe combines a source image with a target category text prompt to generate samples that are visually similar to the source while semantically belonging to the target category (hard negatives). Img2Img uses only a prompt from the same category as the image to generate similar images, resulting in easy samples. Txt2Img generates samples using only the target category prompt, potentially generating samples that are far from the source image and thus not useful for downstream tasks.  The figure shows example images generated for each method for several categories.", "section": "4 Experiments"}, {"figure_path": "rC0OM4Jm4v/figures/figures_20_1.jpg", "caption": "Figure 1: Generative Hard Negative Images Through Diffusion (GeNIe): generates hard negative images that belong to the target category but are similar to the source image from low-level feature and contextual perspectives. GeNIe starts from a source image passing it through a partial noise addition process, and conditioning it on a different target category. By controlling the amount of noise, the reverse latent diffusion process generates images that serve as hard negatives for the source category.", "description": "This figure illustrates the GeNIe method, which generates hard negative images for image classification by leveraging a latent diffusion model.  It starts with a source image and a text prompt describing a different target class. By adjusting the noise level during the reverse diffusion process, GeNIe generates images that retain low-level features from the source image while semantically belonging to the target class. These generated images serve as challenging examples for the source class.", "section": "1 Introduction"}, {"figure_path": "rC0OM4Jm4v/figures/figures_21_1.jpg", "caption": "Figure 2: Effect of noise ratio, r, in GeNIe: we employ GeNIe to generate augmentations for the target classes (motorcycle and cat) with varying r. Smaller r yields images closely resembling the source semantics, creating an inconsistency with the intended target label. By tracing r from 0 to 1, augmentations gradually transition from source image characteristics to the target category. However, a distinct shift from the source to the target occurs at a specific r that may vary for different source images or target categories. For more examples, please refer to Fig. A4.", "description": "This figure shows how the noise ratio r in the GeNIe method affects the generated images.  As r increases from 0 to 1, the generated images gradually shift from being similar to the source image to resembling the target category.  However, the transition isn't linear; there's a point where the change is more drastic. This point varies depending on the source and target images. The figure provides examples for motorcycles and cats, and additional examples are available in Figure A4.", "section": "3 Proposed Method: GeNIe"}]