{"references": [{"fullname_first_author": "Barron, J.T.", "paper_title": "Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields", "publication_date": "2021", "reason": "This paper introduces Mip-NeRF, a significant advancement in neural radiance fields that addresses anti-aliasing issues, improving the quality of novel view synthesis."}, {"fullname_first_author": "Mildenhall, B.", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020", "reason": "This foundational paper introduces NeRFs, a revolutionary technique for novel view synthesis using neural networks, shaping the field significantly."}, {"fullname_first_author": "Kerbl, B.", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023", "reason": "This paper introduces 3D Gaussian splatting, a method for efficiently rendering radiance fields in real-time, crucial for practical applications of novel view synthesis."}, {"fullname_first_author": "Blattmann, A.", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023", "reason": "This paper introduces Stable Video Diffusion, a powerful model for video generation used in the target paper for refining novel view synthesis outputs."}, {"fullname_first_author": "Rombach, R.", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022", "reason": "This paper introduces high-resolution image synthesis using latent diffusion models, which is fundamental to the refinement module used in this paper's novel view synthesis approach."}]}