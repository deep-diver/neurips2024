{"references": [{"fullname_first_author": "Jonathan T Barron", "paper_title": "Mip-nerf 360: Unbounded anti-aliased neural radiance fields", "publication_date": "2022", "reason": "This paper introduces Mip-NeRF 360, a significant advancement in neural radiance fields that addresses limitations of previous methods and enables high-quality rendering of complex scenes."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020", "reason": "This foundational work introduced NeRF, a novel method for representing scenes as neural radiance fields, paving the way for numerous subsequent advancements in novel-view synthesis."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023", "reason": "This paper introduces 3D Gaussian splatting, an efficient and high-quality rendering technique that has been applied in multiple domains, forming the base 3D scene representation in the proposed method."}, {"fullname_first_author": "Susan Liang", "paper_title": "Av-nerf: Learning neural fields for real-world audio-visual scene synthesis", "publication_date": "2023", "reason": "This paper is highly relevant as it directly addresses novel view acoustic synthesis using visual cues, serving as a major competitor and a source of comparison for the proposed method."}, {"fullname_first_author": "Andrew Luo", "paper_title": "Learning neural acoustic fields", "publication_date": "2022", "reason": "This paper introduces Neural Acoustic Fields (NAF), a method that attempts to synthesize binaural audio from mono audio; its limitations are discussed and an alternative proposed in this paper."}]}