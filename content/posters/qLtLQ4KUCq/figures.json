[{"figure_path": "qLtLQ4KUCq/figures/figures_1_1.jpg", "caption": "Figure 1: Scatterplots of the dataset from example 1.", "description": "This figure shows scatterplots of a dataset with three variables (X1, X2, X3) where X1 and X2 are highly correlated and X3 is Gaussian noise.  The top row shows 3D scatterplots of the dataset with 20, 100, and 1000 data points, respectively, illustrating how the outlier (red cross) becomes less visually obvious as the number of data points increases (curse of dimensionality). The bottom row shows 2D scatterplots of the dataset projected onto the X1-X2 plane. The green and red dashed lines represent the classification boundaries of a locality-based method and a cluster-based method, respectively, illustrating that the outlier is easily detectable in the 2D subspace (multiple views), but harder to detect in the full 3D space. This highlights the challenges of outlier detection in high-dimensional data with complex correlations between features that are only visible in certain subspaces.", "section": "1 Introduction"}, {"figure_path": "qLtLQ4KUCq/figures/figures_7_1.jpg", "caption": "Figure 2: GSAAL finds classification boundaries for datasets banana and star under MV.", "description": "This figure visualizes the performance of GSAAL and other outlier detection methods in handling datasets with multiple views (MV).  It shows the decision boundaries (dashed lines) and level curves for several methods, including GSAAL, on two synthetic datasets ('banana' and 'star'). The visualization highlights how GSAAL effectively captures the correlations between features within subspaces, resulting in more accurate outlier detection compared to methods that don't account for MV.", "section": "4.2 Effect of Multiple Views on Outlier Detection"}, {"figure_path": "qLtLQ4KUCq/figures/figures_8_1.jpg", "caption": "Figure 3: Plots of different performance metrics for scalability", "description": "This figure shows the scalability of GSAAL compared to other outlier detection methods (LOF, ABOD, and KNN).  The left plot (a) demonstrates the inference time as a function of the number of features (dimensionality) for a fixed number of data points (500). The right plot (b) shows the inference time as a function of the number of data points for a fixed number of features (100).  The dashed lines represent the expected quadratic scaling of LOF and ABOD with respect to dimensionality, while GSAAL shows approximately linear scaling in both dimensionality and number of data points, showcasing its efficiency for large datasets.", "section": "4 Experiments"}, {"figure_path": "qLtLQ4KUCq/figures/figures_16_1.jpg", "caption": "Figure 4: Difference in statistical distance between two populations.", "description": "This figure shows the result of a test to determine if a given distribution is myopic. The test compares the Maximum Mean Discrepancy (MMD) between two populations using an identity kernel. Population 1 is the original distribution, and Population 2 is the projected distribution. If the MMD is close to zero, then it can be considered as myopic. As we can see, the MMD for Population 1 quickly converges to 0, whereas Population 2's MMD remains much higher and stabilizes. This suggests that Population 1 is myopic but not Population 2. ", "section": "A.4 Multiple Views (extension)"}, {"figure_path": "qLtLQ4KUCq/figures/figures_18_1.jpg", "caption": "Figure 5: 2D-example of the different types of anomalies we generate using the method summarized in table 4.", "description": "This figure shows a 2D representation of three different types of anomalies generated using the method described in Table 4 of the paper.  Panel (a) displays 'Local Outliers', which are points far from the main cluster. Panel (b) shows 'Angle Outliers', which are points that deviate significantly from the general angular distribution of the data. Finally, Panel (c) illustrates 'Cluster Outliers', which appear as a separate smaller cluster outside the main data cluster.  These visualizations help illustrate the different types of outliers considered in the paper's experiments and how they relate to the inlier assumptions of various outlier detection methods.", "section": "B.1 Effects of Inlier Assumptions on Outlier Detection"}, {"figure_path": "qLtLQ4KUCq/figures/figures_18_2.jpg", "caption": "Figure 6: AUCs of the different methods in the IA experiments. From left to right: Local (blue), Angle (orange) and Cluster (green).", "description": "This figure shows the Area Under the Curve (AUC) values for different outlier detection methods across three types of synthetic datasets designed to test the impact of inlier assumptions. Each dataset contains outliers generated with different characteristics (Local, Angle, and Cluster), each designed to violate the assumptions of a specific outlier detection algorithm. The boxplots show the distribution of AUC scores for each method on multiple repetitions of the experiment, revealing the robustness (or lack thereof) of each method to inlier assumptions.", "section": "B.1 Effects of Inlier Assumptions on Outlier Detection"}, {"figure_path": "qLtLQ4KUCq/figures/figures_20_1.jpg", "caption": "Figure 2: GSAAL finds classification boundaries for datasets banana and star under MV.", "description": "The figure visualizes the decision boundaries of several outlier detection methods on two synthetic datasets, 'banana' and 'star', both of which exhibit the 'Multiple Views' property. GSAAL is shown to effectively capture the complex correlation structure of the data, unlike other methods that struggle to adapt to the different views of the data. The visualization helps in understanding how GSAAL addresses the challenge of outlier detection in high-dimensional data with multiple views, highlighting its superior performance.", "section": "4.2 Effect of Multiple Views on Outlier Detection"}, {"figure_path": "qLtLQ4KUCq/figures/figures_21_1.jpg", "caption": "Figure 7: Projected classification boundaries for the datasets in section 4.2 and the extra datasets.", "description": "This figure displays the projected classification boundaries for five different datasets (Banana, Spiral, Star, Circle, L). Each dataset is visualized in a 2D projection of the feature space. The figure compares the performance of multiple outlier detection methods: ABOD, KNN, IForest, GSAAL, LOF, GMM, OCSVM, and MO-GAAL. Each method's decision boundary is plotted as a contour line, showing how well it separates outliers from inliers in the projected space. The figure demonstrates the effectiveness of GSAAL in capturing complex data structures and multi-view data, highlighting its ability to outperform other OD methods, particularly in datasets with multiple views.", "section": "4.2 Effect of Multiple Views on Outlier Detection"}, {"figure_path": "qLtLQ4KUCq/figures/figures_21_2.jpg", "caption": "Figure 9: AUC results in the MV datasets.", "description": "The figure shows the AUC (Area Under the Curve) for different outlier detection methods across multiple view (MV) datasets.  The box plots represent the distribution of AUC scores obtained for each method. The horizontal dashed line indicates the AUC of a random classifier (0.5). GSAAL significantly outperforms other methods, demonstrating its effectiveness in detecting outliers in datasets with multiple views.", "section": "4.3 One-class Classification"}, {"figure_path": "qLtLQ4KUCq/figures/figures_22_1.jpg", "caption": "Figure 10: Boxplots of the ranks used for the Conover-Iman experiment in section 4.3.", "description": "This box plot shows the distribution of ranks for different outlier detection methods (GSAAL, LOF, IForest, ABOD, SOD, kNN, SVDD, MO-GAAL, and GMM) based on the results of the Conover-Iman test performed in section 4.3 of the paper.  The lower the median rank, the better the method's performance.  The box plot visually represents the median, quartiles, and range of the ranks for each method, providing a clear comparison of their relative performance in outlier detection.", "section": "4.3 One-class Classification"}, {"figure_path": "qLtLQ4KUCq/figures/figures_22_2.jpg", "caption": "Figure 11: Performance of the detector with different values of k.", "description": "The left plot shows the median AUC and error bars for different values of k, showing a stabilization at larger k. The right plot compares the results with a fixed k=30 (brown) and the default value k=2\u221ad (blue) used in the previous experiments; there is no large difference in either the AUC or the ranks. The results in Table 3 remain almost the same if one sets k=30. So we recommend fixing k=30, which makes GSAAL very suitable for high-dimensional data.", "section": "B.4 Parameter Sensibility"}]