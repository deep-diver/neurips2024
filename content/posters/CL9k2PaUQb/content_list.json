[{"type": "text", "text": "The Surprising Effectiveness of SP Voting with Partial Preferences ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hadi Hosseini ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Debmalya Mandal ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "College of Information Sciences and Technology Penn State University, USA hadi@psu.edu ", "page_idx": 0}, {"type": "text", "text": "Department of Computer Science University of Warwick, UK Debmalya.Mandal@warwick.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Amrit Puhan College of Information Sciences and Technology Penn State University, USA avp6267@psu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the problem of recovering the ground truth ordering (ranking, top- $k$ , or others) over a large number of alternatives. The wisdom of crowd is a heuristic approach based on Condorcet\u2019s Jury theorem to address this problem through collective opinions. This approach fails to recover the ground truth when the majority of the crowd is misinformed. The surprisingly popular (SP) algorithm [36] is an alternative approach that is able to recover the ground truth even when experts are in minority. The SP algorithm requires the voters to predict other voters\u2019 report in the form of a full probability distribution over all rankings of alternatives. However, when the number of alternatives, $m$ , is large, eliciting the prediction report or even the vote over $m$ alternatives might be too costly. In this paper, we design a scalable alternative of the SP algorithm which only requires eliciting partial preferences from the voters, and propose new variants of the SP algorithm. In particular, we propose two versions\u2014Aggregated-SP and Partial-SP\u2014that ask voters to report vote and prediction on a subset of size $k$ $\\mathrm{~\\varphi~}\\!\\left(\\ll\\,m\\right)$ in terms of top alternative, partial rank, or an approval set. Through a large-scale crowdsourcing experiment on MTurk, we show that both of our approaches outperform conventional preference aggregation algorithms for the recovery of ground truth rankings, when measured in terms of Kendall-Tau distance and Spearman\u2019s $\\rho$ . We further analyze the collected data and demonstrate that voters\u2019 behavior in the experiment, including the minority of the experts, and the SP phenomenon, can be correctly simulated by a concentric mixtures of Mallows model. Finally, we provide theoretical bounds on the sample complexity of SP algorithms with partial rankings to demonstrate the theoretical guarantees of the proposed methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The wisdom of the crowds is a systematic approach to statistically combine the opinions of a diverse group of (non-expert) individuals to achieve a final collective truth. It dates back to Sir Francis Galton\u2019s observation\u2014based on Aristotle\u2019s hypothesis\u2014that the point estimation of a continuous value using the noisy individual opinions can recover its true value with high accuracy [22]. In the modern era, the wisdom of the crowd has been the foundation of legal, political, and social systems with the premise that one can recover the truth by collecting the opinion of a large number of diverse individuals (e.g. trial by jury, election polling, and Q&A platforms such as Reddit/Quora). ", "page_idx": 0}, {"type": "text", "text": "The formal arguments of this phenomenon\u2014rooted in social choice theory\u2014is provided by Condorcet\u2019s Jury Theorem [20], which states that under the condition of independent opinions and each individual having more than a $50\\%$ chance of selecting the correct answer, the probability of the majority decision being correct increases as the size of the crowd increases. However, this approach may fail when the majority of the crowd are misinformed (less than $50\\%$ chance of selecting the correct answer) [19] or are systematically biased [46]. In other words, when the experts are in minority, simply aggregating individuals\u2019 opinions (regardless of the aggregation method) cannot recover the truth. ", "page_idx": 1}, {"type": "text", "text": "To overcome this challenge, Prelec et al. [36] proposed a simple, yet effective, method called the Surprisingly Popular (SP) algorithm, which is able to uncover the ground truth even when the majority opinion is wrong. The approach works by asking each individual about their opinion (the vote) along with an additional meta-question to predict the majority opinion of other individuals (the prediction). The surprisingly popular algorithm then selects an answer whose actual frequency in the votes is greater than its average predicted frequency, and it will provably recover the correct answer with probability 1, as the number of individuals grows in the limit, even when experts are in minority. ", "page_idx": 1}, {"type": "text", "text": "While the SP algorithm is effective in estimating a continuous value (e.g. the value of a painting) or a binary vote (e.g. \u201cIs S\u00e3o Paulo the capital of Brazil?\u201d), it cannot be directly applied to recover true ordinal rankings over a set of $m$ alternatives due to the large number of votes $(m!)$ , and more importantly, eliciting predictions over a complete rankings. Hosseini et al. [25] extended this approach to rankings by proposing an algorithm, called Surprisingly Popular Voting, that can accurately recover the ground-truth ranking over multiple alternatives by eliciting a complete ranking as a vote and only a single majority prediction (as opposed to full probability distributions over $m!$ rankings).1 Despite its success in finding the ground-truth ranking over a small number of alternatives, it remains unclear how to adapt it to settings with large number of alternatives where only partial preferences (e.g. pairwise comparisons or partial ranks) can be elicited. Thus, it raises the following questions: ", "page_idx": 1}, {"type": "text", "text": "How can we design scalable algorithms based on the surprisingly popular method that recovers the ground truth only by eliciting partial preferences from voters? What elicitation formats and aggregation algorithms are more effective in recovering the full ranking over all alternatives? ", "page_idx": 1}, {"type": "text", "text": "Our Contributions. We focus on developing methods, based on the surprisingly popular approach, that only elicit partial vote and prediction information to find the full ranking. Given a set of $m$ alternatives, we ask individuals to provide their rank-ordered vote and predictions on a subset of size $k\\left(\\ll m\\right)$ of alternatives. Informally, we ask them to identify the most preferred alternative among the $k$ choices (Top), select the $t<k$ most preferred alternatives with no order (Approval $(t)$ ), or provide a rank-ordered list of all $k$ alternatives (Rank). The precise formulation is provided in Section 2.1. ", "page_idx": 1}, {"type": "text", "text": "Given that the SP algorithm [36] and its extension to rankings [25] do not generalize to partial preferences with large number of alternatives, we design two novel aggregation methods, namely Partial-SP and Aggregated-SP algorithms. On a high level, these algorithms use a carefully crafted method to select subsets of size $k\\ll m$ for vote and prediction elicitation, and apply the SP method either independently on each subset (Partial-SP) or on the aggregated (potentially partial) votes and ranks (Aggregated-SP). ", "page_idx": 1}, {"type": "text", "text": "We conduct a human-subject study with 432 participants recruited from Amazon\u2019s Mechanical Turk (MTurk) to empirically evaluate the performance of our SP algorithms using metrics such as the Kendall-Tau distance from the full ground truth ranking and Spearman\u2019s rank correlation coefficient. We consider several classical vote aggregation methods (e.g. Borda, Copeland, Maximin, Schulze) as benchmarks\u2014rooted in the computational social choice theory\u2014that operate solely on votes (and not prediction information). Our results show that the SP voting algorithms perform significantly better than the classical methods when the vote and prediction information only contain partial rankings. We also observe that SP voting algorithms are effective even when restricted to approval votes. ", "page_idx": 1}, {"type": "text", "text": "Moreover, we demonstrate that voters\u2019 behavior in the experiment, including the minority of the experts can be correctly simulated by a concentric mixtures of Mallows model [33, 10]. Finally, we provide theoretical bounds on the sample complexity of the SP algorithms with partial preferences to further demonstrate the theoretical guarantees of the proposed methods. We show that the sample complexity only depends on the size of the subset $k$ which is significantly smaller than $m$ . ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "1.1 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our work is related to information elicitation, and partial aggregation which we discuss briefly. ", "page_idx": 2}, {"type": "text", "text": "Information Elicitation. Various information elicitation schemes [35, 36, 48, 17] attempt to incentivize voters to reveal useful information, often through the investment of efforts. Our work is primarily related to the surprisingly popular algorithm [36] which is a a novel second-order information based elicitation scheme. This framework has since been used to incentivize truthful behaviour in agents [35, 42, 43], mitigate biases in academic peer review [32], elicit expert knowledge [27], and aggregate information [9]. Our study builds upon this literature, specifically addressing the challenges in rank recovery. Originally, the SP algorithm by Prelec et al. [36] required data on all $m.$ ! potential rankings for $m$ alternatives , a requirement that becomes impractical as $m$ increases. Hosseini et al. [25] addressed this by developing a Surprisingly Popular Voting algorithm that leverages pairwise preference data across $\\binom m2$ alternatives. This approach doesn\u2019t scale when $m$ is large, and our contribution lies in advancing this methodology by proposing a scalable generalization of the Surprisingly Popular Voting method with partial preferences. ", "page_idx": 2}, {"type": "text", "text": "Partial Aggregation. In situations where it is difficult or not necessary to elicit complete rankings from voters, partial preferences are used. Partial vote aggregation has different solution concepts [6]. Partial preferences can be used to conclude which alternatives are necessary and possible winners based on the preference profiles [26, 14, 47, 2, 3, 49]. The primary goal of partial aggregation methods is to either minimize the amount of information communicated by the voters [12, 45, 40] or to reduce the number of queries that each voter needs to answer [37, 14]. Our work attempts to reduce such communication from the voters by eliciting partial preferences. ", "page_idx": 2}, {"type": "text", "text": "More broadly, our work is also related to information aggregation, and probabilistic rank-order models which we discuss further in Appendix A. ", "page_idx": 2}, {"type": "text", "text": "2 Model ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we formally define the model for Surprisingly Popular Voting in the context of partial preferences. Let $A=\\{a_{1},a_{2},...,a_{m}\\}$ denote the set of $m$ possible alternatives. The set ${\\mathcal{L}}(A)$ represents all possible complete rankings over the alternatives. Let $\\sigma\\in{\\mathcal{L}}(A)$ represent a complete ranking of the $m$ possible alternatives. We denote the ground truth ranking by $\\pi^{\\star}\\in{\\mathcal{L}}(A)$ ; which is assumed to be drawn from a prior $P(\\cdot)$ over ${\\mathcal{L}}(A)$ . Voter $i$ observes a ranking $\\pi_{i}$ that is assumed to be a noisy version of the ground truth ranking $\\pi^{\\star}$ . We will write $\\operatorname*{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star})$ to denote the probability that the voter $i$ observes her ranking $\\pi_{i}$ given the ground truth $\\pi^{\\star}$ . ", "page_idx": 2}, {"type": "text", "text": "Given voter $i$ \u2019s ranking $\\pi_{i}$ and the prior $P(\\cdot)$ , voter $i$ can compute the posterior distribution over the ground truth using the Bayes rule. ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{Pr}_{g}(\\pi^{\\star}\\mid\\pi_{i})=\\frac{\\operatorname*{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star})\\cdot P(\\pi^{\\star})}{\\sum_{\\pi^{\\prime}\\in\\mathcal{L}(A)}\\operatorname*{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\prime})\\cdot P(\\pi^{\\prime})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Using the posterior over the ground truth, voter $i$ can also compute a distribution over the rankings observed by another voter. ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{Pr}_{o}(\\pi_{j}\\mid\\pi_{i})=\\sum_{\\pi^{\\prime}\\in\\mathcal{L}(A)}\\operatorname*{Pr}_{s}(\\pi_{j}\\mid\\pi^{\\prime})\\cdot\\operatorname*{Pr}_{g}(\\pi^{\\prime}\\mid\\pi_{i})}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The surprisingly popular algorithm [36] asks voters to report their votes, and posterior over others\u2019 votes. For each ranking $\\pi^{\\prime}$ , it then computes the frequency $\\begin{array}{r}{f(\\pi^{\\prime})=\\frac{1}{n}\\sum_{i}\\mathbf{1}[\\bar{\\pi}=\\pi^{\\prime}]}\\end{array}$ , and posterior $\\begin{array}{r}{g(\\pi\\mid\\pi^{\\prime})=\\frac{1}{\\mid\\{i:\\pi_{i}=\\pi^{\\prime}\\}\\mid}\\sum_{i:\\pi_{i}=\\pi^{\\prime}}\\operatorname*{Pr}_{o}(\\pi\\mid\\pi_{i})}\\end{array}$ , and finally picks the ranking with highest prediction normalized votes.2 ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{\\pi}\\in\\operatorname{argmax}_{\\pi}\\overline{{V}}(\\pi)=f(\\pi)\\cdot\\sum_{\\pi^{\\prime}\\in\\Pi}\\frac{g(\\pi^{\\prime}|\\pi)}{g(\\pi|\\pi^{\\prime})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "As observed by Hosseini et al. [25], eliciting full posterior and even the vote might be prohibitive if the number of alternatives $m$ is huge. In this work, we are concerned about eliciting partial rankings ", "page_idx": 2}, {"type": "text", "text": "over subsets of size $k\\ll m$ . Let us fix a subset $T\\subseteq A$ of size $k$ . Then the probability of a partial ranking $\\sigma_{i}$ is given as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{Pr}_{s}(\\sigma_{i}\\mid\\pi^{\\star})=\\sum_{\\pi:\\pi\\triangleright\\sigma_{i}}\\operatorname*{Pr}_{s}(\\pi\\mid\\pi^{\\star})}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here we use the notation $\\pi\\triangleright\\sigma_{i}$ to indicate that the ranking $\\pi$ when restricted to the set $T$ is $\\sigma_{i}$ . ", "page_idx": 3}, {"type": "text", "text": "We can also naturally extend definition 1 to define the posterior distribution over partial preferences given a partial preference $\\sigma_{i}$ . In order to do so, let us first define the posterior over full ground truth $\\pi^{\\star}$ given $\\sigma_{i}$ as, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{Pr}_{g}(\\pi^{\\star}\\mid\\sigma_{i})=\\frac{\\operatorname*{Pr}_{s}(\\sigma_{i}\\mid\\pi^{\\star})P(\\pi^{\\star})}{\\sum_{\\tilde{\\pi}}\\operatorname*{Pr}_{s}(\\sigma_{i}\\mid\\tilde{\\pi})P(\\tilde{\\pi})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where one can use definition (4) to compute $\\operatorname*{Pr}_{s}(\\sigma\\mid\\pi^{\\star})$ . Now we can write down the posterior probability over the partial ground truth $\\tilde{\\sigma}$ as follows. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma_{i})=\\sum_{\\pi:\\pi>\\tilde{\\sigma_{i}}}\\operatorname*{Pr}_{g}(\\pi\\mid\\sigma_{i})}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Finally, we can write the posterior over another partial ranking $\\sigma^{\\prime}$ over the subset $T$ . ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{Pr}_{o}(\\sigma^{\\prime}\\mid\\sigma_{i})=\\sum_{\\tilde{\\sigma}}\\operatorname*{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma_{i})\\operatorname*{Pr}_{s}(\\sigma^{\\prime}\\mid\\tilde{\\sigma})}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In this work, our aim is to propose several versions of surprising popular algorithm that work with partial preferences. As shown in definition 3, it requires eliciting information regarding voters partial preferences, and posterior over others\u2019 partial preferences (as defined in eq. (6)). Next, we discuss various ways of eliciting such information from the voters. ", "page_idx": 3}, {"type": "text", "text": "2.1 Elicitation Formats ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Given a subset of size $k\\ll m$ alternatives, voter $i$ \u2019s prediction $\\operatorname*{Pr}_{o}(\\cdot\\mid\\sigma_{i})$ is a distribution over $k!$ rankings. In practice, this renders elicitation of full prediction information difficult, if not impossible, due to its cognitive overload. Thus, we focus on simple, and more explainable, elicitation methods that rely on ordinal information either by identifying the most preferred alternative (Top), selecting the most preferred $t$ alternatives (Approval $(t)$ ), or a complete ranking of the partial set (Rank). The formal definitions can be found in Appendix B. ", "page_idx": 3}, {"type": "text", "text": "Given these elicitation methods, we study different combinations of formats for votes and predictions where the first component indicates the vote format and the second component denotes the prediction format. These give rise to nine formats: Top-None, Top-Top, Top-Approval $(t)$ , Top-Rank, Approval $(t)$ -Rank, Approval $(t)$ -Approval $(t)$ , Rank-None, Rank-Top, and Rank-Rank. For Approval $(t)$ , the approval set of size $t\\in\\{1,2,3\\}$ is selected. Note that Approval $(1)\\equiv\\mathtt{T o p}$ . ", "page_idx": 3}, {"type": "text", "text": "3 Aggregation Algorithms for Partial Preferences ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The surprisingly popular method (as we discussed in section 1) cannot be applied directly to find a full ranking using only partial preferences. Thus, we develop two vote aggregation algorithms that only rely on partial ordinal preferences both for votes and predictions. On the high level, the two algorithms differ on how and when they implement the SP method, whether independently on each subset (Partial-SP) or on the aggregated (potentially partial) votes and ranks (Aggregated-SP). Here we provide a high-level description for each of the algorithms; additional details and exact pseudo-codes are relegated to Appendix D. ", "page_idx": 3}, {"type": "text", "text": "Partial-SP. The key element of this algorithm is utilizing SP voting on the partial rankings obtained at each step. It takes a set of potentially overlapping subsets of alternatives and a voting rule as input and proceeds as follows: For each subset $S_{j}$ of alternatives, collect votes and predictions from voters on this subset according to one of the elicitation formats detailed in Section 2.1. Compute the ground truth partial ranking on the subset $S_{j}$ using the SP algorithm. Aggregate all partial rankings using a voting rule (e.g. Condorcet) to find a full ranking over all alternatives (breaking ties at random). ", "page_idx": 3}, {"type": "text", "text": "Aggregated-SP. This variation utilizes SP voting on the final rankings over votes and predictions. It takes a set of potentially overlapping subsets of alternatives and a voting rule as input and proceeds as follows: For each subset $S_{j}$ of alternatives, collect votes and predictions from voters on this subset according to one of the elicitation formats detailed in Section 2.1. Aggregate all votes (partial rankings) using a voting rule (e.g., Condorcet) to find the aggregated vote over all alternatives, breaking ties at random. Predictions are not aggregated to preserve conditional prediction information crucial for SP voting. Apply SP algorithm pairwise across all alternatives where for each pair $(a,b)$ , the vote information is derived from the scores of $a$ and $b$ based on the aggregation rule used, and the prediction information is used to find the conditional probabilities, $P(a|b)$ and $P(b|a)$ . Breaking ties at random throughout this process results in a full ranking over all alternatives. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Subset Selection. The algorithms described in this section rely on partial rankings on the subset of alternatives. Given $m$ alternatives, we carefully select subsets of size $k$ with an inter-alternative pairwise distance of $s$ between elements from the ground-truth ranking. Formally, a subset $S_{j}$ of size $k$ is generated as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nS_{j}=\\{a_{1+j},a_{1+j+s},\\ldots,a_{1+j+(k-1)s}\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $j\\geq0$ and $j+(k-1)s<m$ , ensuring elements are within the range of $m$ alternatives. We get a total of $m-(k-1)s$ subsets. Note that we use overlapping subsets so as to introduce transitivity among different subsets enabling us to compare alternatives across different subsets. This leads to an improvement in the accuracy of our algorithms as we discuss in Section 5. ", "page_idx": 4}, {"type": "text", "text": "4 Experimental Design ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "This section describes the experimental design of the Amazon Mechanical Turk (MTurk) study to assess the comparative efficacy of Partial-SP and Aggregated-SP against other voting rules for partial preferences. Participants in this study were asked to answer a series of questions, wherein they were required to express their preferences by voting on a range of alternatives. In addition to casting their own votes, participants were asked to predict the collective preference of others for the same set of alternatives. Data was collected from 432 respondents. Each participant was given a 20-minute window to complete a series of 18 questions (see details below).3 Datasets. The survey encompassed three distinct domains: (i) The geography dataset contains 36 countries with their population estimates, according to the United Nations, (ii) The movies dataset contains 36 movies with their lifetime box-office gross earnings, and (iii) The paintings dataset contains 36 paintings with their latest auction prices.4 ", "page_idx": 4}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/9eb3d0b756131ad106ec43473ffbb02f6c0fa90b80f658e202356d16d31b7c71.jpg", "img_caption": ["Figure 1: Workflow of a participant "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Questions. We explored 36 alternatives per domain, aiming to gather partial preferences from voters. Each question featured a subset of alternatives, with the size of each subset maintained uniformly throughout the experiment. ", "page_idx": 4}, {"type": "text", "text": "Each participant was presented with a subset ", "page_idx": 4}, {"type": "text", "text": "of 5 alternatives, selected based on an interalternative gap of 6 positions within the ground-truth ranking. This strategy was designed to balance the cognitive load against the quality of the responses. We tested subset sizes of 4 to 6 and interalternative gaps of 3 to 8, finding that larger sizes and wider gaps generally enhanced ground-truth recovery. However, larger subset sizes increase cognitive load for participants, and wider gaps reduce overlap between subsets when limited to 36 alternatives. For each combination of 12 subsets, 9 elicitation formats, and 3 domains, each question received 16 responses. ", "page_idx": 4}, {"type": "text", "text": "The survey was structured for each participant to answer two questions from each of the three domains and two elicitation formats, totaling 12 questions per participant. Figure 1 shows the workflow for each participant; each participant was assigned 18 questions to answer. Refer to Appendix E for details on the tutorials, participant qualifications for the MTurk study, and review questions regarding the perceived difficulty and expressiveness of the study. ", "page_idx": 4}, {"type": "text", "text": "Elicitation Formats. We use various elicitation formats (as described in section 2.1). For example, consider a question that requires participants to rank five movies: a) Rogue One: A Star Wars Story, b) Titanic, c) Toy Story 3, d) The Dark Knight Rises, and e) Jumanji: Welcome to the Jungle\u2014based on their lifetime gross earnings. Under the Approval(3)-Rank elicitation format, the structure of the vote and prediction questions would be framed as follows: ", "page_idx": 4}, {"type": "text", "text": "\u2022 Part A (vote): \"Which among the following movies are the top three in terms of highest grossing income of all time?\"   \n\u2022 Part B (prediction): \"Considering that other participants will also respond to Part A, in what order do you predict the following movies will be ranked, from the most common response (top) to the least common (bottom)?\" ", "page_idx": 5}, {"type": "text", "text": "Refer to Appendix I for further details about formulations of all nine elicitation formats, the consent form, the tutorial for each domain, screenshots, and other details. ", "page_idx": 5}, {"type": "text", "text": "5 Results and Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we present the results of this study averaged across all three domains. We measure the accuracy of the proposed SP algorithms (Partial-SP and Aggregated-SP) in predicting the full ground-truth ranking, in comparison with common vote aggregation methods (e.g. Borda, Copeland, Maximin, Schulze). The details of these aggregation methods is provided in Appendix C. ", "page_idx": 5}, {"type": "text", "text": "Additionally, we compare the elicitation formats (described in Section 2.1) with respect to cognitive effort (measured by response time and difficulty) and expressiveness (measured directly by survey questions). They are provided in Appendix G.2 ", "page_idx": 5}, {"type": "text", "text": "5.1 Accuracy Metrics ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To capture the error in predicting the full ground-truth ranking, we use three different metrics: (i) the Kendall-Tau correlation, which measures the distance between ordinal rankings, (ii) Spearman\u2019s $\\rho$ correlation, which measures the statistical dependence between ordinal rankings, (iii) Pairwise hit rate, which measures the fraction of pairs at distance $d$ that are correctly ranked with respect to the ground-truth ranking, and (iv) Top- $\\cdot t$ hit rate, which measures the fraction of alternatives that are predicted correctly (in no order) in most preferred $t$ compared to the ground-truth ranking. The formal definitions can be found in Appendix G.1. ", "page_idx": 5}, {"type": "text", "text": "For example, consider the ground-truth ranking $a\\succ b\\succ c\\succ d$ . The predicted ranking $b\\succ a\\succ d\\succ c$ has a pairwise hit rate of $\\bar{1}/3$ at distance 1, 1 at distances 2 and 3. Its Top-1 hit rate is 0, Top-2 is 1, Top-3 is $2/3$ , and Top-4 is 1. ", "page_idx": 5}, {"type": "text", "text": "5.2 Predicting the Ground Truth Ranking ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Figure 2 illustrates the performance of SP algorithms measured by Kendall-Tau and Spearman\u2019s correlations. We fix Copeland as the aggregation rule used in both variations of SP voting and compare the accuracy with applying Copeland on votes alone (without the use of prediction information). ", "page_idx": 5}, {"type": "text", "text": "Statistical correlations and elicitation. SP voting produces rankings with a significantly higher correlation with the ground truth ranking, and this effect improves as the information provided as votes and prediction becomes more expressive. In particular, Rank-Rank and Approval(3)-Rank outperform all other elicitation formats. We note that Aggregated-SP seem to be more reliant on the vote information, compared to the predictions, as it can seen in Top-Rank vs. Rank-Top. In contrast, Partial-SP does not exhibit any significant favor for vote vs. prediction information as both Top-Rank and Rank-Top improve by additional information. However, the difference between them is not statistically significant. ", "page_idx": 5}, {"type": "text", "text": "Interestingly, eliciting unordered information for both noisy votes and predictions (e.g. Approval(2)-Approval(2)) seem to be sufficient in recovering the ground truth\u2014raising the question of whether pairwise comparisons are necessary in designing SP algorithms. ", "page_idx": 5}, {"type": "text", "text": "Hit rates. With respect to pairwise hit rate and the Top- $\\cdot t$ hit rate, the noisy prediction information significantly improves the performance of the Partial-SP algorithm (with lower variance) as shown in Figure 3. The results for Aggregated-SP are qualitatively similar and are presented in Appendix G.5. The slight dip in pairwise hit rate, can be explained by the survey\u2019s design choice of an inter-alternative distance of 6, leading to fewer comparisons being available for these pairs. ", "page_idx": 5}, {"type": "text", "text": "Partial-SP vs. Aggregated-SP. While both variants of the SP algorithm significantly outperform common voting rules by utilizing (noisy) prediction information, the Partial-SP algorithm significantly outperforms the Aggregated-SP algorithm (see Figure 2 and Figure 4). This could be explained by the importance of \u2018correcting\u2019 noisy votes on the subsets of alternatives because the prediction information of the Partial-SP algorithm helps identify experts early on in predicting partial rankings of these alternatives. ", "page_idx": 5}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/13066d9bc087192f9076a1e0fcd24964d22059aa836d69f12921d13aa145561e.jpg", "img_caption": ["Figure 2: Comparing the predicted and ground-truth rankings for different elicitation formats using Kendall-Tau and Spearman\u2019s $\\rho$ correlations (higher is better). All results use Copeland as their aggregation rule. "], "img_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/8de4fa581839ddc38f1c9158574d20b7b54929ff75ff6a909d7be79a1d464288.jpg", "img_caption": ["Figure 3: Comparing the Partial-SP algorithm with Copeland (no prediction information) measured by pairwise and Top- $\\cdot t$ hit rates. The elicitation format is Approval(2)-Approval(2). "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "For Partial-SP, the plots indicate no statistical significance between Approval(2)-Approval(2), Approval(3)-Rank, and Rank-Rank elicitation formats, suggesting they perform as well as Rank-Rank. An interesting ramification here is demonstrating that approval sets not only perform well in predicting the ground truth, but also pose less cognitive burden on voters compared to those elicitation formats that ask for rankings (see appendix G.2). ", "page_idx": 6}, {"type": "text", "text": "Domain impacts. Performance of Partial-SP and Aggregated-SP is robust across domains. They outperform common voting rules with the sole exception of the Schulze method, which matches the performance of Aggregated-SP (see Figure 4). The difference in performance is notably high for Paintings domain, where specialized expertise is required to predict painting prices. Here, Partial-SP significantly outperforms common aggregation rules, showcasing its effectiveness in leveraging expert knowledge and correcting misinformation. For further details see Appendix G.3. ", "page_idx": 6}, {"type": "text", "text": "6 Simulated Model of Voter Behavior ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we investigate whether there is any underlying probabilistic model that can explain the voters\u2019 behaviours when measured in terms of the vote and predictions. If successful, such a model will also enable us to theoretically analyze the sample complexity of SP algorithms (as we present in Section 7). In particular, we posit that a concentric mixtures of Mallows model can explain the users\u2019 reports (both vote and prediction) in the dataset. The concentric mixtures of Mallows model is a type of mixture models where there is one ground truth, but different groups of users have different dispersion parameters, and hence different distribution over observed preferences. ", "page_idx": 6}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/9a8a5be9ff84d7493b5db5d8953975fdfcc5e9cb434d1bf2e2a8878baa882cdd.jpg", "img_caption": ["Figure 4: Comparing the predicted and ground-truth rankings for different aggregation rules using Kendall-Tau and Spearman\u2019s $\\rho$ correlations (higher is better). The elicitation format is Rank-Rank; each comparison uses the same aggregation rule in the SP algorithm. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Concentric mixtures of Mallows model. We assume that each voter is likely to be an expert with probability $p(\\ll1)$ and a non-expert with probability $1-p$ . Given a ground truth ranking $\\pi^{\\star}$ , an expert voter observes a ranking that is distributed according to a Mallows model with center $\\pi^{\\star}$ and dispersion parameter $\\phi_{E}$ . On the other hand, a non-expert voter observes a ranking that is again distributed according to a Mallows model with center $\\pi^{\\star}$ , but with a larger dispersion parameter $\\phi_{N E}$ . In particular, the ranking observed by voter $i$ is distributed as ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star})=p\\cdot\\operatorname*{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star},\\phi_{E})+(1-p)\\cdot\\operatorname*{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star},\\phi_{N E})\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where Prs(\u03c0 | \u03c0\u22c6, \u03d5) is the standard Mallows model with dispersion \u03d5 i.e. Prs(\u03c0 | \u03c0\u22c6, \u03d5) = \u22c6\u03d5Zd((\u03d5\u03c0,,\u03c0m\u22c6)) . The term $Z(\\phi,m)$ is the normalization constant, and is defined as $\\begin{array}{r}{Z(\\phi,m)=\\sum_{\\pi}\\phi^{d(\\pi,\\pi^{\\star})}}\\end{array}$ . With a slight abuse of notation, we will write $Z(\\phi)$ as $Z(\\phi,m)$ since the number o f alternatives in the ground truth is assumed to be fixed. ", "page_idx": 7}, {"type": "text", "text": "Note that, Equation (8) defines a distribution over complete preferences, but given a subset of size $k$ we can naturally extend this definition to define a distribution over partial preferences e.g. $\\operatorname*{Pr}_{s}(\\sigma_{i}\\mid\\pi^{\\star})$ (eq. (4)), and posterior over partial preferences of other voters e.g. $\\operatorname{Pr}_{o}(\\sigma\\mid\\sigma_{i})$ (eq. (6)). ", "page_idx": 7}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/71b7074a712d8cabee31af7d489680f06078154c7305d5e7e7a54b03375a9852.jpg", "img_caption": ["Figure 5: Comparison of inferred parameters of the Concentric mixtures of Mallows model for real data with all domains combined and synthetic data. The experts vote closer to and predict farther from the ground-truth. The non-experts vote and predict far from the ground truth. The proportion of experts in both datasets was found to be less than $20\\%$ . "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "We fti the mixture model eq. (8) on the real datasets and estimate the following parameters \u2013 proportion of experts $(p)$ , dispersion parameters of experts\u2019 votes $(\\phi_{E-v o t e s})$ and predictions $\\mathit{\\Pi}_{\\phi_{E}}$ -predictions), as well as the dispersion parameters of non-experts\u2019 votes $(\\phi_{N E-v o t e s})$ and predictions $(\\phi_{N E-p r e d i c t i o n s})$ . The parameters were inferred using Bayesian inference [24]. We also generated synthetic data using the concentric mixtures of Mallows model, and again used Bayesian inference to estimate the parameters. The details of estimation and data generation are provided in the appendix F. Figure 5 shows the posterior distributions for the dispersion parameters when the datasets of all the three domains are combined. We see that the synthetic data generation process accurately replicates real data characteristics, and highlights that the concentric mixtures of Mallows accurately model voters\u2019 behaviours on MTurk. Furthermore, Figure 6 also plots the same posterior distributions but only for ", "page_idx": 7}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/6828f3b64b44d4d7de4aa8e3aeff9d6b2f6e5f1dc974e1345c233d7e2bca5943.jpg", "img_caption": ["Figure 6: Comparison of inferred parameters of the Concentric mixtures of Mallows model for real data of Movie domain and synthetic data. The quality of model fit improves if the focus is on one single domain. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "the Movies domain. Now we see almost perfect fit between the synthetic data and the original data.   \nFurther similarity in results between real and simulated data is described in Appendix G.6. ", "page_idx": 8}, {"type": "text", "text": "7 Analysis of Sample Complexity ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we use a concentric mixture of Mallows models, and provide upper bound on the sample complexity of the surprisingly popular voting method with partial preferences. We start with a simple problem. Given a subset $T$ of size $k$ , suppose our goal is to recover the true partial ranking over the alternatives in $T$ , then how many samples does SP algorithm require? ", "page_idx": 8}, {"type": "text", "text": "We will analyze the following simplified version of the SP algorithm: Voter $i$ reports vote $\\sigma_{i}$ over the subset $T$ , which is used to build an estimate of $f(\\sigma)$ for all $\\sigma\\in\\Pi_{s}$ . For each $\\sigma$ , the posterior report by the voter is a partial ranking drawn from the distribution $g(\\cdot\\mid\\sigma)$ . These reports are used to build an estimate $\\widehat{g}(\\sigma^{\\prime}\\mid\\sigma)$ for all $\\sigma^{\\prime},\\sigma$ . Select partial ranking $\\begin{array}{r}{\\widehat{\\sigma}\\in\\operatorname{argmax}_{\\sigma}\\widehat{V}(\\sigma)=\\widehat{f}(\\sigma)\\cdot\\sum_{\\sigma\\in\\Pi_{s}}\\frac{\\widehat{g}(\\sigma^{\\prime}|\\sigma)}{\\widehat{g}(\\sigma|\\sigma^{\\prime})}}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "It is impossible to recover the partial ground truth ranking if the fraction of the experts $p$ can be very small, or the dispersion parameter of the non-experts $\\phi_{N E}$ can be very large. In order to ensure recovery of the true partial ranking we will make the following assumption. ", "page_idx": 8}, {"type": "text", "text": "Assumption 1. The dispersion parameters $\\phi_{E},\\phi_{N E}$ , and the fraction of experts $p$ satisfy the following inequality, ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left(\\frac{p}{1-p}\\right)^{2}\\ge2\\cdot\\left(\\frac{Z(\\phi_{N E})}{Z(\\phi_{E})}\\right)^{2}Z(\\phi_{N E},k)\\phi_{E}^{k(k-1)/2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\begin{array}{r}{Z(\\phi,k)=\\sum_{\\sigma:[k]\\to[k]}{\\phi^{d(\\sigma,\\sigma^{\\star})}}}\\end{array}$ . ", "page_idx": 8}, {"type": "text", "text": "The next theorem states that sample complexity under the above assumption. ", "page_idx": 8}, {"type": "text", "text": "Twhheeroer $^{l}$ .s  Tn he\u2265n kt!h $\\begin{array}{r}{n\\geq k!\\sqrt{\\frac{10k\\log(2k/\\delta)}{\\mu}}}\\end{array}$ $\\begin{array}{r}{\\mu=p\\cdot\\frac{Z(\\phi_{E},m-k)}{Z(\\phi_{E})}\\cdot\\phi_{E}^{k(k-1)/2}+(1-p)\\cdot\\frac{Z(\\phi_{N E},m-k)}{Z(\\phi_{N E})}\\cdot\\phi_{N E}^{k(k-1)/2}}\\end{array}$ \u03d5kN(kE\u22121)/2 e surprisingly popular algorithm recovers true ranking over the subset $T$ of size $k$ with probability at least $1-\\delta$ . Suppose $\\phi_{E}\\ll\\phi_{N E}<1$ . Then Assumption 1 requires $\\begin{array}{r}{\\frac{p}{1-p}\\geq\\Omega\\left(\\phi_{N E}^{k^{2}/4+1}\\phi_{E}^{k^{2}/4-1}\\right)}\\end{array}$ , and it implies that if $\\phi_{N E}$ is very large compared to $\\phi_{E}$ (i.e. noisy non-experts) then we need a larger value of $p$ (i.e. more experts). ", "page_idx": 8}, {"type": "text", "text": "We provide the full proof of the theorem in Appendix I. The main ingredient of the proof is Lemma 2 which shows that under Assumption 1 there is a strict separation between the true predictionnormalized score of the true partial ranking and any other ranking. In fact, we show that $\\overline{{V}}(\\sigma^{\\star})\\geq$ $2\\overline{{V}}(\\tau)$ for any $\\tau$ with $d(\\tau,\\sigma^{\\star})\\geq1$ . Given this result, we can apply standard concentration inequality to show that $\\widehat V(\\sigma)$ is close to $\\overline{{V}}(\\sigma)$ for all $\\sigma$ when the number of samples is large, and $\\widehat{V}(\\sigma^{\\star})$ will be larger than $\\widehat V(\\tau)$ for any $\\tau\\ne\\sigma^{\\star}$ . Therefore, picking the ranking with the largest empirical prediction-normalized score returns the correct ranking. ", "page_idx": 8}, {"type": "text", "text": "Note that the sample complexity grows proportional to $k!$ only because we compute predictionnormalized votes over all $k,$ ! partial rankings. If we are interested in recovering top $t$ -alternatives then it will grow proportional to $\\binom{k}{t}$ . Moreover, the subset size $k$ is assumed to be very small compared to the number of alternatives $m$ , and Theorem 1 shows the benefit of applying SP algorithm to partial preferences. We can immediately apply Theorem 1 to a collection of subsets $S$ through a union bound, and extend our analysis to the Partial-SP algorithm. Let us assume that in the second stage of Partial-SP, we apply a $t$ -consistent voting rule $f$ that recovers top- $\\cdot t$ alternatives as long as each partial ranking in $S$ is correct. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Corollary 1. Under the same setting as Theorem 1, suppose the number of samples from each subset in $S$ is 10k log(\u00b52|S|k/\u03b4). Then the Partial-SP algorithm with a t-consistent voting rule, recovers the top $t$ alternatives of the ground truth $\\pi^{\\star}$ with probability at least $1-\\delta$ . ", "page_idx": 9}, {"type": "text", "text": "Finally note that, the total sample complexity of $\\tilde{O}(|S|\\cdot k!\\sqrt{k})$ is needed only because we adopt a naive version of the SP algorithm for proving theoretical guarantees. For the experiments, we adopt a pairwise version of the SP algorithm which applies SP-voting to each pair within a subset. We believe that under further assumptions, the total sample complexity can be reduced to $\\tilde{O}(|S|\\cdot k^{2})$ with such a pairwise variant of the partial-SP algorithm, and we leave this analysis for the future. ", "page_idx": 9}, {"type": "text", "text": "8 Discussion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We conclude by discussing some limitations and future directions. When dealing with partial preferences, even when majority have the correct information, effective preference elicitation or finding a necessary winner in most vote aggregation rules are often computationally intractable [11, 39, 18]. These challenges, together with the minority of experts, further highlight the efficacy of the SP approach in balancing information elicitation and accuracy, by employing additional prediction information. Future research can explore the setting of SP beyond the majority-minority dichotomy (e.g. informed, but not expert voters) or when malicious voters are present (e.g. in detecting misinformation). Theoretically, the sample complexity can be explored beyond Mallows model under other probabilistic models to enhance our understanding of this approach, particularly in notable applications such as political polling or collective moderation of online content. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Hadi Hosseini acknowledges support from National Science Foundation (NSF) IIS grants #2144413 and #2107173. We thank the anonymous reviewers for their constructive feedback. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Yoram Bachrach, Nadja Betzler, and Piotr Faliszewski. Probabilistic possible winner determination. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 24, pages 697\u2013702, 2010.   \n[2] Dorothea Baumeister and J\u00f6rg Rothe. Taking the final step to a full dichotomy of the possible winner problem in pure scoring rules. Information Processing Letters, 112(5):186\u2013190, 2012.   \n[3] Nadja Betzler and Britta Dorn. Towards a dichotomy for the possible winner problem in elections based on scoring rules. Journal of Computer and System Sciences, 76(8):812\u2013836, 2010.   \n[4] Niclas Boehmer, Robert Bredereck, and Dominik Peters. Rank aggregation using scoring rules. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 5515\u20135523, 2023.   \n[5] JC de Borda. M\u2019emoire sur les\u2019 elections au scrutin. Histoire de l\u2019Acad\u2019emie Royale des Sciences, 1781.   \n[6] Felix Brandt, Vincent Conitzer, Ulle Endriss, J\u00e9r\u00f4me Lang, and Ariel D Procaccia. Handbook of computational social choice. Cambridge University Press, 2016.   \n[7] Cl\u00e9ment L Canonne. A short note on learning discrete distributions. arXiv preprint arXiv:2002.11457, 2020.   \n[8] Bob Carpenter, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus A Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. Stan: A probabilistic programming language. Journal of statistical software, 76, 2017. [9] Yi-Chun Chen, Manuel Mueller-Frank, and Mallesh Pai. The wisdom of the crowd and higherorder beliefs. In Proceedings of the 24th ACM Conference on Economics and Computation, pages 450\u2013450, 2023.   \n[10] Fabien Collas and Ekhine Irurozki. Concentric mixtures of mallows models for top- $k$ rankings: sampling and identifiability. In International Conference on Machine Learning, pages 2079\u2013 2088. PMLR, 2021.   \n[11] Vincent Conitzer and Tuomas Sandholm. Vote elicitation: Complexity and strategy-proofness. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 18, pages 392\u2013397, 2002.   \n[12] Vincent Conitzer and Tuomas Sandholm. Communication complexity of common voting rules. In Proceedings of the 6th ACM conference on Electronic commerce, pages 78\u201387, 2005.   \n[13] Vincent Conitzer and Tuomas Sandholm. Common voting rules as maximum likelihood estimators. In Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence, UAI\u201905, page 145\u2013152, Arlington, Virginia, USA, 2005. AUAI Press. ISBN 0974903914.   \n[14] Vincent Conitzer, Tuomas Sandholm, and J\u00e9r\u00f4me Lang. When are elections with few candidates hard to manipulate? Journal of the ACM (JACM), 54(3):14\u2013es, 2007.   \n[15] Vincent Conitzer, Matthew Rognlie, and Lirong Xia. Preference functions that score rankings and maximum likelihood estimation. In Proceedings of the Twenty-First International Joint Conference on Artificial Intelligence, 2009.   \n[16] Arthur H Copeland. A reasonable social welfare function. Technical report, mimeo, 1951. University of Michigan, 1951.   \n[17] Anirban Dasgupta and Arpita Ghosh. Crowdsourced judgement elicitation with endogenous proficiency. In Proceedings of the 22nd international conference on World Wide Web, pages 319\u2013330, 2013.   \n[18] Andrew Davenport and Jayant Kalagnanam. A computational study of the kemeny rule for preference aggregation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 4, pages 697\u2013702, 2004.   \n[19] Patrick M De Boer and Abraham Bernstein. Efficiently identifying a well-performing crowd process for a given problem. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, pages 1688\u20131699, 2017.   \n[20] Nicolas De Condorcet. Essai sur l\u2019application de l\u2019analyse \u00e0 la probabilit\u00e9 des d\u00e9cisions rendues \u00e0 la pluralit\u00e9 des voix. Cambridge University Press, 2014.   \n[21] Cynthia Dwork, Ravi Kumar, Moni Naor, and Dandapani Sivakumar. Rank aggregation methods for the web. In Proceedings of the 10th international conference on World Wide Web, pages 613\u2013622, 2001.   \n[22] FRANCIS GALTON. Vox populi. Nature, 75(1949):450\u2013451, 1907.   \n[23] Noam Hazon, Yonatan Aumann, Sarit Kraus, and Michael Wooldridge. On the evaluation of election outcomes under uncertainty. Artificial Intelligence, 189:1\u201318, 2012.   \n[24] Matthew D. Hoffman and Andrew Gelman. The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo. Journal of Machine Learning Research, 15(47):1593\u20131623, 2014.   \n[25] Hadi Hosseini, Debmalya Mandal, Nisarg Shah, and Kevin Shi. Surprisingly popular voting recovers rankings, surprisingly! In Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, pages 245\u2013251, 2021.   \n[26] Kathrin Konczak and J\u00e9r\u00f4me Lang. Voting procedures with incomplete preferences. In Proc. IJCAI-05 Multidisciplinary Workshop on Advances in Preference Handling, volume 20. Citeseer, 2005.   \n[27] Yuqing Kong and Grant Schoenebeck. Eliciting expertise without verification. In Proceedings of the 2018 ACM Conference on Economics and Computation, pages 195\u2013212, 2018.   \n[28] Yuqing Kong, Yunqi Li, Yubo Zhang, Zhihuan Huang, and Jinzhao Wu. Eliciting thinking hierarchy without a prior. Advances in Neural Information Processing Systems, 35:13329\u201313341, 2022.   \n[29] Tyler Lu and Craig Boutilier. Learning mallows models with pairwise preferences. In Proceedings of the 28th international conference on machine learning (icml-11), pages 145\u2013152, 2011.   \n[30] Tyler Lu and Craig Boutilier. Robust approximation and incremental elicitation in voting protocols. In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, volume 1, pages 287\u2013293, 2011.   \n[31] Tyler Lu and Craig Boutilier. Vote elicitation with probabilistic preference models: Empirical estimation and cost tradeoffs. In Algorithmic Decision Theory: Second International Conference, ADT 2011, Piscataway, NJ, USA, October 26-28, 2011. Proceedings 2, pages 135\u2013149. Springer, 2011.   \n[32] Yuxuan Lu and Yuqing Kong. Calibrating \u201ccheap signals\u201d in peer review without a prior. Advances in Neural Information Processing Systems, 36, 2024.   \n[33] Colin L Mallows. Non-null ranking models. i. Biometrika, 44(1/2):114\u2013130, 1957.   \n[34] John I Marden. Analyzing and modeling rank data. CRC Press, 1996.   \n[35] Drazen Prelec. A bayesian truth serum for subjective data. science, 306(5695):462\u2013466, 2004.   \n[36] Dra\u017een Prelec, H Sebastian Seung, and John McCoy. A solution to the single-question crowd wisdom problem. Nature, 541(7638):532\u2013535, 2017.   \n[37] Ariel D Procaccia. A note on the query complexity of the condorcet winner problem. Information Processing Letters, 108(6):390\u2013393, 2008.   \n[38] GWM Rauterberg. A method of a quantitative measurement of cognitive complexity. In Humancomputer interaction: tasks and organisation: proceedings of the 6th European conference on cognitive ergonomics, ECCE\u201992, pages 295\u2013307. CUD, 1992.   \n[39] J\u00f6rg Rothe, Holger Spakowski, and J\u00f6rg Vogel. Exact complexity of the winner problem for young elections. Theory of Computing Systems, 36:375\u2013386, 2003.   \n[40] Shin Sato. Informational requirements of social choice rules. Mathematical Social Sciences, 57 (2):188\u2013198, 2009.   \n[41] Frans Schalekamp and Anke van Zuylen. Rank aggregation: Together we\u2019re strong. In 2009 Proceedings of the Eleventh Workshop on Algorithm Engineering and Experiments (ALENEX), pages 38\u201351. SIAM, 2009.   \n[42] Grant Schoenebeck and Biaoshuai Tao. Wisdom of the crowd voting: Truthful aggregation of voter information and preferences. Advances in Neural Information Processing Systems, 34: 1872\u20131883, 2021.   \n[43] Grant Schoenebeck and Fang-Yi Yu. Two strongly truthful mechanisms for three heterogeneous agents answering one question. ACM Transactions on Economics and Computation, 10(4):1\u201326, 2023.   \n[44] Markus Schulze. A new monotonic, clone-independent, reversal symmetric, and condorcetconsistent single-winner election method. Social choice and Welfare, 36:267\u2013303, 2011.   \n[45] Travis C. Service and Julie A Adams. Communication complexity of approximating voting rules. In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2012), pages 593\u2013602, 2012.   \n[46] Joseph P Simmons, Leif D Nelson, Jeff Galak, and Shane Frederick. Intuitive biases in choice versus estimation: Implications for the wisdom of crowds. Journal of Consumer Research, 38 (1):1\u201315, 2011.   \n[47] Toby Walsh. Uncertainty in preference elicitation and aggregation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 7, pages 3\u20138, 2007.   \n[48] Jens Witkowski and David Parkes. A robust bayesian truth serum for small populations. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 26, pages 1492\u20131498, 2012.   \n[49] Lirong Xia and Vincent Conitzer. Determining possible and necessary winners given partial orders. Journal of Artificial Intelligence Research, 41:25\u201367, 2011.   \n[50] Lirong Xia, Vincent Conitzer, and J\u00e9r\u00f4me Lang. Aggregating preferences in multi-issue domains by using maximum likelihood estimators. In Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1, pages 399\u2013408, 2010.   \n[51] H Peyton Young. Extending condorcet\u2019s rule. Journal of Economic Theory, 16(2):335\u2013353, 1977. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A Additional Related Work 14 ", "page_idx": 13}, {"type": "text", "text": "B Formalism of Elicitation Formats 15 ", "page_idx": 13}, {"type": "text", "text": "C Common Voting Rules 16 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "C.1 Borda 16   \nC.2 Copeland . 16   \nC.3 Maximin 17   \nC.4 Schulze 17   \nD Algorithms 19   \nD.1 Extracting Reports from Voters 19   \nD.2 Partial-SP 19   \nD.3 Aggregated-SP 20 ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "E Additional Details of Experimental Design 21 ", "page_idx": 13}, {"type": "text", "text": "F Additional Details of Simulation 22   \nF.1 Parameter Inference for the concentric mixtures of Mallows model 22   \nF.2 Synthetic Data Generation 22   \nG Missing Results and Analysis 23   \nG.1 Evaluation Metrics . . 23   \nG.2 Response-Time, Difficulty and Expressiveness 23   \nG.3 Missing Figures for Predicting the Ground-Truth Ranking 24   \nG.4 Missing Figures for Partial-SP . 27   \nG.5 Missing Figures for Aggregated-SP 29   \nG.6 Comparing Performance between Real and Simulated Data . 29   \nH.1 Proof of Theorem (1) 31   \nH.2 Separation Lemma . 32 ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "I Screenshots from our MTurk Survey 33 ", "page_idx": 13}, {"type": "text", "text": "A Additional Related Work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Information Aggregation. Information Aggregation by eliciting votes from voters is a well-studied problem in social choice theory. The aggregation rules proposed by De Condorcet [20], Borda [5], Copeland [16], Young [51], and many others focus on information aggregation by eliciting votes. These rules can be adapted to elicit ranked information from voters and then aggregate them into a single ranking representing the collective opinion of the crowd. [4]. Information Aggregation has also been examined from a statistical perspective, where the aggregated ranking is viewed as the maximum likelihood estimate of the population\u2019s rankings [20, 15, 50, 13]. Within this framework, individual votes are considered outcomes of probabilistic models such as the Thurstonian model, Bradley-Terry model, Mallows\u2019 model, or Plackett-Luce model [34]. ", "page_idx": 13}, {"type": "text", "text": "Partial Aggregation. In situations where it is difficult or not necessary to elicit complete rankings from voters, partial preferences are used. Partial vote aggregation has different solution concepts [6]. Partial preferences can be used to conclude which alternatives are necessary and possible winners based on the preference proflies [26, 14, 47, 2, 3, 49]. Alternatively, a regret based approach can be used to assess the quality of a winning alternative where the optimal alternative is the one that minimizes regret [30]. Apart from these epistemic notions, a lot of work has been done on probabilistic analysis of winners from partial profiles [1, 23, 29, 31]. To minimize the information elicited from a population, it is crucial to understand the methods used for eliciting partial preferences. It can either be by minimizing the amount of information communicated by each voter in their answer [12, 45, 40] or by reducing the number of queries that each voter needs to answer [37, 14]. In either of these cases, the objective is still to determine the winner accurately. Cognitive complexity also plays an important part in this, as all these notions are highly correlated. Finally, the recovery of complete rankings from partial preferences is another solution concept that is studied [21, 41]. Due to the combinatorial nature of the rankings, winner determination, communication complexity, query complexity, and cognitive complexity are all relevant here. This is where our research work contributes. ", "page_idx": 14}, {"type": "text", "text": "Surprisingly Popular Framework. In their seminal work, Prelec [35], Prelec et al. [36] introduced the Surprisingly Popular (SP) algorithm, a novel second-order information based method that recovers truthful subjective data in scenarios where objective truth remains unknown. This framework has since been used to incentivize truthful behaviour in agents [35, 42, 43], mitigate biases in academic peer review [32], elicit expert knowledge [27], model thinking hierarchy of people without any prior [28], aggregate information [9] and recover ground-truth ranking [36, 25]. Our study builds upon this literature, specifically addressing the challenges in rank recovery. Originally, the SP algorithm by Prelec et al. [36] required data on all $m!$ potential rankings for $m$ alternatives , a requirement that becomes impractical as $m$ increases. Hosseini et al. [25] addressed this by developing a Surprisingly Popular Voting algorithm that leverages pairwise preference data across $\\binom m2$ alternatives. However, this approach encountered scalability limitations when dealing with more than four alternatives in partial preference profiles. Our contribution lies in advancing this methodology by proposing a scalable generalization of the Surprisingly Popular Voting method for partial preferences, thus broadening its applicability and effectiveness. ", "page_idx": 14}, {"type": "text", "text": "B Formalism of Elicitation Formats ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we formally define the elicitation formats used in our study. Let $v_{i}$ and $p_{i}$ denote the vote and prediction submitted by voter $i$ . Let $T=\\{a_{1},a_{2},\\ldots,a_{k}\\}$ denote the subset of alternatives of size $k$ that voters will report on and $\\mathcal{L}(T)$ denote the set of all possible rankings of alternatives in $T$ . Let $\\sigma$ denote a ranking of the alternatives in $T$ and $\\sigma(j)$ denote the alternative at the $j^{t h}$ position in $\\sigma$ . The elicitation formats are defined as follows: ", "page_idx": 14}, {"type": "text", "text": "Top-None: Voter $i$ reports the top alternative in her observed noisy ranking, i.e., $v_{i}=\\sigma(1)$ , and does not provide any inference about other\u2019s aggregated votes. ", "page_idx": 14}, {"type": "text", "text": "Top-Top: Voter $i$ reports the top alternative in her observed noisy ranking, i.e., $\\smash{\\v{v}_{i}^{}=\\v{\\sigma}\\sigma(1)}$ , and provides the estimate of the most frequent alternative among the other voters, i.e., $p_{i}~=$ arg $\\begin{array}{r}{\\operatorname*{max}_{a\\in T}\\sum_{\\sigma\\in\\mathcal{L}(T):\\sigma(1)=a}\\operatorname*{Pr}_{o}\\bigl(\\sigma\\vert\\sigma_{i}\\bigr)}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Top-Approval(3): Voter $i$ reports the top alternative in her observed noisy ranking, i.e., $v_{i}=\\sigma(1)$ , and provides the estimate of the top three most frequent alternatives, in no specific order, among the other voters., i.e., $\\begin{array}{r}{p_{i}=\\arg\\operatorname*{max}_{a,\\bar{b},c\\in T}\\sum_{\\sigma:\\{a,b,c\\}\\subseteq\\{\\sigma(1),\\sigma(2),\\sigma(3)\\}}\\operatorname*{Pr}_{o}(\\sigma|\\sigma_{i})}\\end{array}$ . Top-Rank: Voter $i$ reports the top alternative in her observed noisy ranking, i.e., $v_{i}=\\sigma(1)$ , and provides the estimate of other\u2019s rankings i.e, $p_{i}\\in\\mathcal{L}(T)$ such that $\\begin{array}{r}{\\sum_{\\sigma\\in{\\mathcal{L}}(A):\\sigma(1)=q_{i}(x)}\\operatorname*{Pr}_{o}(\\dot{\\sigma}|\\sigma_{i})\\geq}\\end{array}$ $\\begin{array}{r}{\\sum_{\\sigma\\in\\mathcal{L}(T):\\sigma(1)=q_{i}(y)}\\operatorname*{Pr}_{o}(\\sigma|\\sigma_{i})}\\end{array}$ for all $x>y$ . ", "page_idx": 14}, {"type": "text", "text": "Approval(2)-Approval(2): Voter $i$ reports the top two alternatives, in no specific order, in her observed noisy ranking, i.e., $v_{i}=\\{\\sigma(1),\\bar{\\sigma}(2)\\}=\\{\\bar{a},b\\}$ with $a,b\\in T$ in no particular order and provides the estimate of the top two most frequent alternatives, in no specific order, among the other voters., i.e., $\\begin{array}{r}{p_{i}=\\arg\\operatorname*{max}_{a,b\\in T}\\sum_{\\sigma:\\{a,b\\}\\subseteq\\{\\sigma(1),\\sigma(2)\\}}\\operatorname*{Pr}_{o}(\\sigma|\\sigma_{i})}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Approval(3)-Rank: Voter $i$ reports the top three alternatives, in no specific order, in her observed noisy ranking, i.e., $v_{i}=\\{\\sigma(1),\\bar{\\sigma}(2),\\sigma(3)\\}=\\{a,b,c\\}$ with $a,b,c\\in T$ in no particular order, and provides the estimate of other\u2019s rankings i.e, $p_{i}\\in\\mathcal{L}(T)$ such that $\\begin{array}{r}{\\sum_{\\sigma\\in{\\mathcal{L}}(A):\\sigma(1)=q_{i}(x)}\\operatorname*{Pr}_{o}(\\sigma|\\sigma_{i})\\geq}\\end{array}$ $\\begin{array}{r}{\\sum_{\\sigma\\in\\mathcal{L}(T):\\sigma(1)=q_{i}(y)}\\operatorname*{Pr}_{o}(\\sigma|\\sigma_{i})}\\end{array}$ for all $x>y$ . ", "page_idx": 15}, {"type": "text", "text": "Rank-None: Voter $i$ reports her entire observed noisy ranking, i.e., $v_{i}=\\sigma_{i}$ , and does not provide any inference about other\u2019s aggregated votes. ", "page_idx": 15}, {"type": "text", "text": "Rank-Top: Voter $i$ reports her entire observed noisy ranking, i.e., $\\begin{array}{r l r}{v_{i}}&{{}=}&{\\sigma_{i}}\\end{array}$ , and provides the estimate of the most frequent alternative among the other voters, i.e., $\\begin{array}{r l}{p_{i}}&{{}=}\\end{array}$ arg $\\begin{array}{r}{\\operatorname*{max}_{a\\in T}\\sum_{\\sigma\\in\\mathcal{L}(T):\\sigma(1)=a}\\operatorname*{Pr}_{o}(\\sigma|\\sigma_{i})}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "Rank-Rank: Voter $i$ reports her entire observed noisy ranking, i.e., $\\ v_{i}~=~\\sigma_{i}$ , and provides the estimate of other\u2019s rankings i.e, $p_{i}~\\,\\in\\,\\,{\\mathcal{L}}(T)$ such that $\\begin{array}{r}{\\sum_{\\sigma\\in\\mathcal{L}(\\mathcal{A}):\\sigma(1)=q_{i}(x)}\\operatorname*{Pr}_{o}(\\bar{\\sigma}|\\sigma_{i})~~\\geq~}\\end{array}$ $\\begin{array}{r}{\\sum_{\\sigma\\in\\mathcal{L}(T):\\sigma(1)=q_{i}(y)}\\operatorname*{Pr}_{o}(\\sigma|\\sigma_{i})}\\end{array}$ for all $x>y$ . ", "page_idx": 15}, {"type": "text", "text": "C Common Voting Rules ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Vote aggregation rules are social choice functions that are used to aggregate individual votes to make conclusions about the collective opinion of a multi-candidate voting system [6]. Given below are the vote aggregation rules used in our study. We will only focus on aggregating ranked preferences. ", "page_idx": 15}, {"type": "table", "img_path": "CL9k2PaUQb/tmp/4d39e5beffae46b47e6a043f140b5796189092e934354949796798a977d1f1d5.jpg", "table_caption": ["Table 1: Voter Preferences "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "C.1 Borda ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The Borda rule [5] is a voting rule in which voters order candidates by ranked preference, and candidates are awarded points based on their position in each voter\u2019s ranking. The winner is the candidate with the highest total score after all votes are counted. It can be mathematically represented as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\mathrm{Borda~Score}}(a)=\\sum_{i=1}^{n}(m-1-\\sigma_{i}^{-1}(a))\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\sigma_{i}^{-1}(a)$ represents the position at which alternative a is present. The aggregated ranking is derived by sorting the Borda scores of the alternatives in descending order. ", "page_idx": 15}, {"type": "text", "text": "Example 1. Apply Borda Rule to the preference profile given in Table 1 ", "page_idx": 15}, {"type": "text", "text": "Table 1 provides the preference proflies of voters. Applying Borda Rule, we find that Borda Scores of A, B, C, D are 132, 192, 174, and 102 respectively. Thus arranging the scores in descending order results in the aggregated ranking of $B\\succ C\\succ A\\succ D$ . ", "page_idx": 15}, {"type": "text", "text": "C.2 Copeland ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The Copeland rule [16] is a voting method used to select a single winner from a set of candidates based on pairwise comparisons between each pair of candidates. In the Copeland method, each candidate receives a score based on the number of head-to-head contests they win against other candidates, with ties potentially receiving a half point for each candidate involved in the tie. It can be mathematically represented as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\mathrm{Copeland~Score}}(\\mathrm{a})=\\sum_{\\stackrel{a,b\\in A}{b\\neq a}}\\left\\{{1\\atop0}\\begin{array}{l l}{{\\mathrm{if~}}V(a,b)>V(b,a)}\\\\ {{\\mathrm{if~}}V(a,b)=V(b,a)}\\\\ {{\\mathrm{if~}}V(a,b)<V(b,a)}\\end{array}}\\right.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $V(a,b)$ represents all the voters who preferred $a$ over $b$ . The aggregated ranking is derived by sorting the Copeland scores of the alternatives in descending order. ", "page_idx": 16}, {"type": "text", "text": "Example 2. Apply Copeland Rule to the preference profile given in Table 1 ", "page_idx": 16}, {"type": "text", "text": "Applying Copeland Rule (with Borda tie-breaking) to the preference proflies given in Table 1 results in the following pairwise table: ", "page_idx": 16}, {"type": "table", "img_path": "CL9k2PaUQb/tmp/a4c910705c378544bb8aa0b5115a829558f18730e6b6a7fae7497b7280fe1ddc.jpg", "table_caption": [], "table_footnote": ["Table 2: Results of Pairwise Comparisons "], "page_idx": 16}, {"type": "text", "text": "Thus, arranging the alternatives in decreasing order of number of time they become winners results in the aggregated ranking of $B\\succ C\\succ D\\succ A$ . ", "page_idx": 16}, {"type": "text", "text": "C.3 Maximin ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The Maximin rule [51], also known as the Simpson-Kramer method , selects a winner from a set of candidates by considering the strength of a candidate\u2019s worst-case pairwise comparison against all other candidates. It identifies the candidate whose least favorable comparison is superior to those of the others, aiming to find the most robust candidate against the strongest opponent. This can be mathematically expressed as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{Maximin\\;Score(a)}=\\operatorname*{min}_{b\\in A,b\\neq a}V(a,b)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $V(a,b)$ represents all the voters who preferred $a$ over $b$ . The aggregated ranking is derived by sorting the Maximin scores of the alternatives in descending order. ", "page_idx": 16}, {"type": "text", "text": "Example 3. Apply Maximin Rule to the preference profile given in Table 1 ", "page_idx": 16}, {"type": "text", "text": "In order to apply Maximin Rule to the preference proflies given in Table 1 we first analyze the worst pairwise defeat and its margin by the following table: ", "page_idx": 16}, {"type": "table", "img_path": "CL9k2PaUQb/tmp/e9f3efc9241f1919427fe7ce58150fa461b09c723f290b08ef52ee0e75acb0f8.jpg", "table_caption": ["Alternative Worst Pairwise Defeat Margin of Worst Pairwise Defeat ", "Table 3: Analysis of Worst Pairwise Defeats "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "The alternative that has a higher score of worst pairwise defeat or that loses by a higher margin is considered worse off. Thus, arranging in ascending order of the scores of any of the column results in the aggregated ranking of $B\\succ A\\succ C\\succ D$ . ", "page_idx": 16}, {"type": "text", "text": "C.4 Schulze ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The Schulze rule [44] selects a ranking of a set of candidates based on the strength of preferences expressed by voters. The strength of a preference is considered to be the number of voters who prefer one candidate over another. For every pair of candidates, a directed graph is constructed where the edges represent the strength of preference. The method then calculates the strongest path (defined as the weakest link in the path being as strong as possible) between every pair of candidates. A candidate wins if, for every other candidate, there exists a stronger (or equal strength) path to that candidate than from that candidate. It can be mathematically expressed as: ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Initially, for all pairs of candidates $a,b$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\nP(a,b)={\\left\\{\\!\\!\\begin{array}{l l}{V(a,b)}&{{\\mathrm{if~}}V(a,b)>V(b,a)}\\\\ {0}&{{\\mathrm{otherwise}}}\\end{array}\\!\\!\\right.}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, for each $a,b,c\\in A$ with $a\\neq b\\neq c$ , update: ", "page_idx": 17}, {"type": "equation", "text": "$$\nP(a,b)=\\operatorname*{max}(P(a,b),\\operatorname*{min}(P(a,c),P(c,b)))\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For each candidate $a$ , calculate a comprehensive score that may involve the sum of all positive differences $P(a,b)\\dag-P(b,a)$ against other candidates $b$ . The aggregated ranking is obtained by sorting these scores in descending order. ", "page_idx": 17}, {"type": "text", "text": "Example 4. Apply Schulze Rule to the preference profile given in Table 1 ", "page_idx": 17}, {"type": "text", "text": "In order to apply Schulze Rule to the preference proflie given in Table 1, we first generate a Directed Graph where the vertices denote the alternatives and the weight of the edges denote the score by which one alternative defeats the other. For the preferences in Table 1, we get the following graph: ", "page_idx": 17}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/7378bdd340ae18631b3adfa748d0a037959047743675e51fa62d1a4090392cb6.jpg", "img_caption": ["Figure 7: Directed Graph with Vertices Arranged as Corners of a Square ", "Table 5: Strength of weakest link between vertices "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "The Table 4 finds the strongest path for each pair of vertices: ", "page_idx": 17}, {"type": "table", "img_path": "CL9k2PaUQb/tmp/3269349092b91c22749e959c804085244fcaf33ad7f2371b1d54c62c854a1ab8.jpg", "table_caption": ["Table 4: Strongest Path between Vertices "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Finally, the Table 4 provides the weakest link between each pair of vertices: ", "page_idx": 17}, {"type": "table", "img_path": "CL9k2PaUQb/tmp/4b8f2857897f4bff7cf957045d89d01a7805c15b595f30244275a4493b60a710.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Arranging the alternatives in decreasing order of their pairwise wins in Table 5 results in the aggregated ranking of $B\\succ C\\succ D\\succ A$ . ", "page_idx": 17}, {"type": "text", "text": "D Algorithms ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Appendix D.1 details the approach used to extract information from various elicitation formats. Explanation and pseudocode for Partial-SP and Aggregated-SP is provided in Appendix D.2 and Appendix D.3, respectively. ", "page_idx": 18}, {"type": "text", "text": "D.1 Extracting Reports from Voters ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Algorithm 1 describes how information is extracted from different elicitation formats. The algorithm takes as input the votes $(\\{v_{i}\\}_{i\\in[n]})$ and predictions $(\\{p_{i}\\}_{i\\in[n]})$ of $n$ voters, pair $(a,b)$ of alternatives, and parameters $\\alpha$ and $\\beta$ . Using grid search on the datasets from the three domains, it was observed that any $\\alpha>0.5$ and $\\beta<0.5$ can be used. In our experiments we use $\\alpha=0.55$ and $\\beta=0.1$ . For votes and predictions expressed as top choices or approvals, if $a$ is the preferred alternative, $v_{i}^{(a,b)}$ is set to 1, with pi( $p_{i}^{(a,b)}$ adjusted to $\\alpha$ if the prediction aligns with the vote, or to $\\beta$ otherwise; if $b$ is chosen, vi(a,b)is 0, and pi(a $p_{i}^{(a,b)}$ is set to $1-\\alpha$ or $1-\\beta$ , depending on prediction alignment. For ranks, vi(a,b)indicates preference based on rank ordering, and pi(a $p_{i}^{(a,b)}$ reflects the confidence in this preference ( $\\alpha$ or $1-\\alpha$ if aligned, $\\beta$ or $1-\\beta$ if not). The algorithm returns the processed vote and prediction reports. ", "page_idx": 18}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/65c4d66a6e4fdfd28cea9b87f3682692c0641d7f0cc5d1466585b6d84ae6684b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "D.2 Partial-SP ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Algorithm 2 describes the proposed Partial-SP aggregation approach. The algorithm takes as input the number of voters $(n)$ , number of alternatives $(m)$ , set of all subsets that voters voted on $(S)$ , voters\u2019 votes $(\\{v_{i,j}\\}_{i\\in[n],j\\in S})$ , voters\u2019 predictions $(\\{p_{i,j}\\}_{i\\in[n],j\\in S})$ , parameters $\\alpha$ and $\\beta$ representing the conditional probabilities that would be returned for the predictions, and Vote Aggregation Rule $(\\mathcal{V})$ . For $n$ voters and $m$ alternatives, depending on the elicitation format, the voters will be providing votes $(v_{i,j})$ and predictions $(p_{i,j})$ as Top choices, Approvals $(t)$ , or Rankings over a subset $S_{j}\\in S$ Additionally, we use Borda, Copeland, and Maximin aggregation rule for $\\nu$ . ", "page_idx": 18}, {"type": "text", "text": "For every pair of alternatives $(a,b)$ within a subset $S_{j}$ , we extract information about the number of people that voted for $a\\succ b$ and $b\\succ a$ represented by $f(a\\succ b)$ and $f(b\\succ a)$ respectively, and the conditional probability of their predictions $(g(0|0),g(0|1),g(1|0),g(1|1))$ . Refer to Appendix D.1 for a detailed explanation of how information is extracted for different elicitation formats. With this, the prediction normalized score ${\\bar{V}}(a\\succ b)$ and ${\\bar{V}}(b\\succ a)$ is calculated and a higher prediction normalized score decides the correct ordering for each pair $(a,b)$ within a subset $S_{j}$ . This results in a partial ground-truth ranking representing the correct relative ordering for the alternatives within that subset. $Q$ represents the set of partial ground-truth ranking for all subsets. Finally, Vote-Aggregation rule $\\nu$ is applied on $Q$ to find the complete ground-truth ordering of the $m$ alternatives. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "text_level": 1, "page_idx": 19}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/1fe16966ff259839a95e78ae289dc8b9ddb10900fb9a38849f61c317dee70f05.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "D.3 Aggregated-SP ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Algorithm 3 describes the proposed Aggregated-SP aggregation approach. The algorithm takes as input the number of voters $(n)$ , number of alternatives $(m)$ , set of all subsets that voters voted on $(S)$ , voters\u2019 votes $(\\{v_{i,j}\\}_{i\\in[n],j\\in S})$ , voters\u2019 predictions $(\\{p_{i,j}\\}_{i\\in[n],j\\in S})$ , parameters $\\alpha$ and $\\beta$ representing the conditional probabilities that would be returned for the predictions, and Vote Aggregation Rule $(\\mathcal{V})$ . For $n$ voters and $m$ alternatives, depending on the elicitation format, the voters will be providing votes $(v_{i,j})$ and predictions $(p_{i,j})$ as Top choices, Approvals $(t)$ , or Rankings over a subset $S_{j}\\in S$ Additionally, we use Borda, Copeland, and Maximin aggregation rule for $\\nu$ . ", "page_idx": 19}, {"type": "text", "text": "For every subset $S_{j}$ , we aggregate the votes using $\\nu$ , resulting in the set of partial aggregated subsets represented by $Q$ . $Q$ is a dictionary containing the alternative and its corresponding score according to the aggregation rule $\\nu$ . We now apply SP-Algorithm on $Q$ . For every pair of alternatives $(a,b)$ within a partial aggregated subset $Q_{j}$ , we extract information about the conditional probability of their predictions $(g(0|0),g(0|1),g(1|0),g(1|1))$ . Refer to Appendix D.1 for a detailed explanation of how information is extracted for different elicitation formats. With this, the prediction normalized score ${\\bar{V}}(a\\succ b)$ and ${\\bar{V}}(b\\succ a)$ is calculated where we use the scores of the alternatives represented by $Q(a)$ and $Q(b)$ . A higher prediction normalized score decides the correct ordering for each pair $(a,b)$ . Parsing all pairs, results in the complete ground-truth ordering of the $m$ alternatives. ", "page_idx": 19}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/f9b32e3cb942222799ddfd139103dd07e1785ff453fd295ddec0557699cb903e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "E Additional Details of Experimental Design ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "This section provides additional details about the MTurk study ", "page_idx": 20}, {"type": "text", "text": "Tutorial. Prior to engaging with each set of 6 questions within a specific elicitation format, participants completed a tutorial designed to evaluate their understanding of the voting process and prediction tasks. To proceed, participants had to accurately apply these beliefs within the voting and prediction framework, ensuring they were adequately prepared. ", "page_idx": 20}, {"type": "text", "text": "Reviews. Following the completion of each set of 6 questions, participants were asked to evaluate the preceding questions\u2019 elicitation format in terms of difficulty (ranging from \"Very Easy\" to \"Very Difficult\") and expressiveness (from \"Very Little\" to \"Very Significant\"). Although question complexity was standardized within each domain, the domains themselves varied considerably in difficulty. To mitigate potential bias from implicit comparisons between the two elicitation formats assigned to each participant, the sequence of domains in the first set of questions was mirrored in the subsequent set. This methodological approach ensured consistency and fairness in the evaluation of the elicitation formats, thereby enhancing the reliability of participants\u2019 feedback ", "page_idx": 20}, {"type": "text", "text": "Response qualifications $\\&$ payment. To ensure reliable responses, we established several qualification criteria for participants in our study on MTurk. Participants were required to have: (a) a minimum approval rate of $90\\%$ for their previous tasks, (b) completed at least 100 tasks on the platform, and (c) specified the region as US and Canada (to ensure language proficiency). To check attentiveness of the participants, we included an additional quiz that repeated one of the previous questions. The compensation structure included a base payment of 50 cents for completing the survey, which encompassed tutorials, questions, and evaluations. Additionally, a 50-cent bonus was offered for accurately completing the attentiveness quiz. ", "page_idx": 20}, {"type": "text", "text": "F Additional Details of Simulation ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "F.1 Parameter Inference for the concentric mixtures of Mallows model ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "To assess the accuracy of the simulations, we fit the concentric mixtures of Mallows model to both the real and simulated data to infer the model parameters. This process allows us to compare the inferred parameters, thereby evaluating how effectively the model captures the underlying patterns in the data. Specifically, we infer the proportion of experts $(p)$ , dispersion parameters of experts\u2019 votes $(\\phi_{E-v o t e s})$ and predictions $\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\phi_{E-p r e d i c t i o n s})$ ), as well as the dispersion parameters of non-experts\u2019 votes $(\\phi_{N E-v o t e s})$ and predictions $(\\phi_{N E-p r e d i c t i o n s})$ ). For the real data, the distribution of these parameters can help us in understanding the voting behavior of experts and non-experts. For the synthetic data, generated based on known parameters, we can check if the model accurately recovers these parameters. ", "page_idx": 21}, {"type": "text", "text": "The parameters are inferred using Bayesian inference, implemented through the No-U-Turn Sampler (NUTS) [24], an extension of Hamiltonian Monte Carlo (HMC) available in Stan [8]. Before sampling, we calculate the Kendall-Tau distance between the ground-truth ranking and the votes $(\\tau_{v o t e s})$ and predictions $(\\tau_{p r e d i c t i o n s})$ of all the voters. We then define the priors for our parameters as follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{p\\sim\\beta(1,2.5)\\qquad\\qquad}\\\\ {\\phi_{E-v o t e s}\\sim\\mathcal{N}(0.15,0.07\\%)}\\\\ {\\phi_{E-p r e d i c t i o n s}\\sim\\mathcal{N}(0.7,0.3)\\qquad\\qquad}\\\\ {\\phi_{N E-v o t e s}\\sim\\mathcal{N}(0.7,0.3)}\\\\ {\\phi_{N E-p r e d i c t i o n s}\\sim\\mathcal{N}(0.7,0.3)\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We then combine the likelihood of the parameters of our mixture model and perform inference over the following target function: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{target+}=\\log\\operatorname*{mix}\\left(p,\\,\\right.}\\\\ &{\\left.\\qquad\\quad\\mathcal{N}(\\tau_{\\mathrm{votes}}[n]\\mid0,\\phi_{E\\cdot v o t e s})+\\mathcal{N}(\\tau_{\\mathrm{predictions}}[n]\\mid0,\\phi_{E\\cdot p r e d i c t i o n s}),\\,\\right.}\\\\ &{\\left.\\qquad\\quad\\mathcal{N}(\\tau_{\\mathrm{votes}}[n]\\mid0,\\phi_{N E\\cdot v o t e s})+\\mathcal{N}(\\tau_{\\mathrm{predictions}}[n]\\mid0,\\phi_{N E\\cdot p r e d i c t i o n s})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The log-likelihood function incorporates the observed $\\tau_{v o t e s}$ and \u03c4predictions using the mixture model to account for the possibility that each voter could be an expert or a non-expert. We run four chains, each for 4000 iterations with 1000 iterations of warm-up for the NUTS algorithm. The algorithm explores the parameter space and updates the parameter estimates iteratively based on the input data and priors. ", "page_idx": 21}, {"type": "text", "text": "F.2 Synthetic Data Generation ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The synthetic data was generated by simulating voter behavior using the concentric mixtures of Mallows model to construct preference rankings. This approach allows for the simulation of both expert and non-expert voters, with experts\u2019 votes closely aligning with a ground truth ranking and non-experts showing a broader dispersion in their preferences. The subsets to be voted on were generated as described in Section 4. ", "page_idx": 21}, {"type": "text", "text": "Voter Classification. To simulate the voting process effectively, voters are initially classified into experts and non-experts. Since we need the experts to be in the minority, we determine the probability of a voter being an expert by sampling the proportion parameter as $p\\stackrel{.}{\\sim}\\beta(1,2.5)$ . ", "page_idx": 21}, {"type": "text", "text": "Voting Simulation: The voting behavior is simulated by the concentric mixtures of Mallows model. ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathrm{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star})=p\\cdot\\mathrm{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star},\\phi_{\\mathrm{E}})+(1-p)\\cdot\\mathrm{Pr}_{s}(\\pi_{i}\\mid\\pi^{\\star},\\phi_{\\mathrm{NE}})\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\phi_{\\mathrm{E}}\\sim{\\cal N}(0.15,0.075)$ and $\\phi_{\\mathrm{NE}}\\sim N(0.9,0.4)$ . Kendall-Tau distance is used as the distance metric between the rankings $\\pi_{i}$ and $\\pi^{\\star}$ . ", "page_idx": 21}, {"type": "text", "text": "G Missing Results and Analysis ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "G.1 Evaluation Metrics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "To quantitatively assess the alignment between the rankings derived from the voting rule, denoted as $\\sigma^{\\prime}$ , and the ground truth ranking, $\\sigma^{*}$ , we use metrics described in the following subsections. ", "page_idx": 22}, {"type": "text", "text": "G.1.1 Pairwise hit rate ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "This metric evaluates the accuracy of the voting rule in identifying the correct relative order between pairs of alternatives, focusing on pairs with an increasing distance in their positions in the ground truth ranking: ", "page_idx": 22}, {"type": "equation", "text": "$$\n{\\mathrm{Pairwise~hit~rate}}={\\frac{1}{|P|}}\\sum_{(i,j)\\in P}\\mathbf{1}((\\sigma^{\\prime}(i)<\\sigma^{\\prime}(j))=(\\sigma^{*}(i)<\\sigma^{*}(j)))\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $P$ represents the set of pairs determined by the difference in their positions in $\\sigma^{*}$ , and $\\mathbf{1}$ is the indicator function. ", "page_idx": 22}, {"type": "text", "text": "G.1.2 Top- $\\cdot t$ hit rate ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The Top- $\\boldsymbol{\\cdot}$ hit rate metric quantitatively assesses the accuracy of a ranking algorithm by measuring the presence of the top- $\\cdot t$ elements from the ground truth ranking within the top- $\\cdot t$ elements of the predicted ranking. The formula for calculating the Top- $\\cdot t$ hit rate for rankings up to a given $t$ is given by: ", "page_idx": 22}, {"type": "text", "text": "G.1.3 Kendall-Tau Correlation Coefficient ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The Kendall-Tau correlation coefficient is a measure of the ordinal association between two rankings: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\tau(\\sigma^{\\prime},\\sigma^{*})=\\frac{2}{n(n-1)}\\sum_{i<j}\\mathbf{1}((\\sigma^{\\prime}(i)-\\sigma^{\\prime}(j))(\\sigma^{*}(i)-\\sigma^{*}(j))>0)-1\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $n$ is the number of elements in the ranking. ", "page_idx": 22}, {"type": "text", "text": "G.1.4 Spearman\u2019s $\\rho$ ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The Spearman\u2019s $\\rho$ or Spearman correlation coefficient between $\\sigma^{\\prime}$ and $\\sigma^{*}$ quantifies the rank correlation: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\rho(\\sigma^{\\prime},\\sigma^{*})=1-\\frac{6\\sum_{i=1}^{n}d_{i}^{2}}{n(n^{2}-1)}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "with $d_{i}=\\sigma^{\\prime}(i)-\\sigma^{*}(i)$ representing the rank difference of each element $i$ between $\\sigma^{\\prime}$ and $\\sigma^{*}$ . ", "page_idx": 22}, {"type": "text", "text": "Bootstrapping. To ensure the robustness of our estimates, we used bootstrapping to approximate the sampling distribution of various statistics. This method offers insights into the variance and bias of our estimates without relying on the stringent assumptions required by traditional parametric methods. Bootstrapping is particularly advantageous when the distribution of metric values is unknown or does not conform to common distributional assumptions. After generating the bootstrapped distribution of metric values, we calculated the $95\\%$ confidence interval for each metric. Reporting these intervals alongside the metric values serves two purposes: it quantifies the uncertainty of our estimates, providing a transparent measure of their statistical precision, and it enhances the credibility of our findings by acknowledging the variability and potential error margins associated with our estimates. ", "page_idx": 22}, {"type": "text", "text": "G.2 Response-Time, Difficulty and Expressiveness ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Here, we measure the response time, difficulty, and expressiveness of the elicitation formats we used in our study. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Response Time: We measure the average response time spent by the participants on each question for each elicitation format in our survey. This measure gives us an idea of the cognitive load perceived for each elicitation format [38].   \n\u2022 Perceived Difficulty: In the review phase of our MTurk survey, we asked participants to select from \u2018Very Easy\u2019, \u2018Easy\u2019, \u2018Neutral\u2019, \u2018Difficult\u2019, and \u2018Very Difficult\u2019 to subjectively indicate the ease of answering questions within each elicitation format. This approach provides a measure of the perceived difficulty associated with different elicitation formats.   \n\u2022 Perceived Expressiveness: In the review phase of our MTurk survey, we prompted participants to select from the options \u2018Very Little\u2019, \u2018Little\u2019, \u2018Adequate\u2019, \u2018Significant\u2019, and \u2018Very Significant\u2019 to indicate the amount of information they could convey using each elicitation format. ", "page_idx": 23}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/9a29a72f0a0bd3ae346e37fa5c5a8ed6d6b1807e63fd524f2a9356101b0b8dcf.jpg", "img_caption": ["Figure 8: The figure shows the average time spent by the participants on each tutorial and question for different elicitation formats across all domains. As expected, the participants spent similar or more time on the tutorial than on the questions. Additionally, the only elicitation format that has a statistical significance for the Questions is Approval(3)-Rank, where more time is spent by the participants. Thus, for all other elicitation formats, the participants face a similar cognitive complexity while responding to the questions. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "G.3 Missing Figures for Predicting the Ground-Truth Ranking ", "text_level": 1, "page_idx": 23}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/54f80ea1a5f4eb49f15d841232004ac8f469a691413e41a9298316e75ff31388.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 9: The figure shows the difficulty (easier is better) and expressiveness (higher is better) of different elicitation formats as reported by the participants. A higher percentage of participants found the tasks to be relatively easy, indicating that they could answer questions effortlessly across all elicitation formats. Conversely, they demonstrated similar expressiveness not strongly leaning to either side of the scale. ", "page_idx": 24}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/3d98323ae735873e712593001e8384767503622bcc73c48323a2f7dda6d3976c.jpg", "img_caption": ["(d) Approval(2)-Approval(2) ", "(e) Rank-Top ", "(f) Approval(3)-Rank "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 10: The plots show the Kendall-Tau Correlation between rankings derived from Common Aggregation Rules (blue), Partial-SP(red), and Aggregated-SP(red) for Top-Top, Top-Approval(3), Top-Rank, Approval(2)-Approval(2), Rank-Top, and Approval(3)-Rank elicitation formats across Geography(G), Movies(M), and Paintings(P) domains. A high Kendall-Tau Correlation implies higher pairwise alignment of alternatives between the ground-truth ranking and the aggregated ranking. The usage of different aggregation rules for Partial-SP and Aggregated-SP has similar impact on the outcome. However, the performance improves with an increase in information elicited as seen by the high correlation and increases statistical difference between the conventional methods and proposed methods. For example, Approval(2)-Approval(2) recovers ground-truth ranking more accurately than Top-Top. Note: We see Schulze method in Rank-Top as it only works for preference data. ", "page_idx": 24}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/a8cd78cad7c5687e165613dd61f7c6b230ace45e9cd0a4b817893bbb0b3f6b59.jpg", "img_caption": ["(d) Approval(2)-Approval(2) ", "(f) Approval(3)-Rank "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "(e) Rank-Top ", "page_idx": 25}, {"type": "text", "text": "Figure 11: The plots show the Spearman\u2019s $\\rho$ Correlation between rankings derived from Common Aggregation Rules (blue), Partial-SP(red), and Aggregated-SP(red) for Top-Top, Top-Approval(3), Top-Rank, Approval(2)-Approval(2), Rank-Top, and Approval(3)-Rank elicitation formats across Geography(G), Movies(M), and Paintings(P) domains. A high Spearman\u2019s $\\rho$ Correlation implies higher alignment between the ground-truth ranking and the aggregated ranking. The usage of Maximin aggregation rule for Partial-SP and Aggregated-SP has a better impact on the outcome as compared to other common aggregation rules. Additionally, the performance improves with an increase in information elicited as seen by the high correlation and increases statistical difference between the conventional methods and proposed methods. For example, Approval(3)-Rank recovers ground-truth ranking more accurately than Top-Approval(3). Note: We see Schulze method in Rank-Top as it only works for preference data. ", "page_idx": 25}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/4f6d7a419be3d8f178d49ee12932ccc624cca92412fde190c1a3358c9f3319a3.jpg", "img_caption": ["G.4 Missing Figures for Partial-SP "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Figure 12: The figures show the effect of different elicitation formats for ground-truth recovery using Copeland and Partial-SP using metric defined in Section G.1.1. The metric assesses the number of pairs that were correctly predicted according to the aggregation rule based on their increasing distance in the ground-truth ranking. Comparable performance between Approval(2)-Approval(2), Approval(3)-Rank, and Rank-Rank show that eliciting Approvals on half the size of the subset recovers truth as good as eliciting Ranking over the subset. ", "page_idx": 26}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/fd22fdf8723606140115f5b29485584d752fe86f83b9d10eb219661ebea4b323.jpg", "img_caption": ["(a) Top-Top "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/c84081f942e72256abb4c60a36d7e36e444f9533387dbdaab767a2534ce4c8f2.jpg", "img_caption": ["(b) Top-Approval(3) "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/e841c9cf2c73bd322d0bbd170c201f45d208f75cb6572b9dd4375ec2fe0707c9.jpg", "img_caption": ["(c) Top-Rank "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/4a8ae37307d3f57806826292e444091a83835056be91d8eb3cbe4bfe76f3317e.jpg", "img_caption": ["(d) Approval(2)-Approval(2) "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/0f6f03cbe3b7d0e0971a09533e08e1eec4968aff23257ca087c930c9b6696a58.jpg", "img_caption": ["(e) Approval(3)-Rank "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/491a8bad5a71df80ccbd02c931c7e3282513dd52d2586ec333860b9da7338e4f.jpg", "img_caption": ["(f) Rank-Top "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/26fc298130389fc6dbcd89a7eef0c733682abf5e5b95880273053d407d3d5a85.jpg", "img_caption": ["(g) Rank-Rank "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure 13: The figures show the effect of different elicitation formats for ground-truth recovery using Copeland and Partial-SP using metric defined in Section G.1.2. We again observe comparable performance between Approval(2)-Approval(2), Approval(3)-Rank, and Rank-Rank show that eliciting Approvals on half the size of the subset recovers truth as good as eliciting Ranking over the subset. ", "page_idx": 27}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/f4aeafc4073c9429d9e1fd2406acd94d81222fbbb8649abaebd10d614cfca368.jpg", "img_caption": [], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "Figure 14: The figures show the effect of different elicitation formats for ground-truth recovery using Maximin and Aggregated-SP using metric defined in Section G.1.1. Improved performance in Approval(3)-Rank, and Rank-Rank are consistent with the observations made in Figure 12 except for Approval(2)-Approval(2) where no statistical significance is observed. ", "page_idx": 28}, {"type": "text", "text": "G.6 Comparing Performance between Real and Simulated Data ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Figure 16 shows the performance of Partial-SP with Copeland Aggregation on Real Data and Simulated Data using metrics described in Section G.1.1 and G.1.2. In both of the metrics, we observe similar trends across various pairwise distances, and top-t metrics. ", "page_idx": 28}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/6291c7e416ad91630cdd2b1cb658e983b2b271ad77be20fadcc028a340b89b4b.jpg", "img_caption": ["(g) Rank-Rank "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "Figure 15: The figures show the effect of different elicitation formats for ground-truth recovery using Maximin and Aggregated-SP using metric defined in Appendix G.1.2. Improved performance, especially after $t=10$ , in Approval(2)-Approval(2), Approval(3)-Rank, and Rank-Rank are consistent with the observations made in Figure 13. ", "page_idx": 29}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/d33bb72f612f6ede1c7dcec494c4b5aef2d1f269b91f4743c019eb585111646f.jpg", "img_caption": ["(a) Correct-Hits Vs Pairwise distance. ", "(b) Correct Hits vs Top-t "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "Figure 16: Comparison of pairwise and Top- $\\cdot t$ hit rate for Copeland-Aggregated Partial-SP and Copeland rule for Rank-Rank on Real and Simulated Data. Similar trends are noticed in real and simulated data. ", "page_idx": 29}, {"type": "text", "text": "H Missing Proofs ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "H.1 Proof of Theorem (1) ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Proof. We first establish a lower bound on $g(\\sigma\\mid\\sigma^{\\prime})$ for any $\\sigma,\\sigma^{\\prime}$ . ", "page_idx": 30}, {"type": "equation", "text": "$$\ng(\\sigma\\mid\\sigma^{\\prime})=\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma^{\\prime})\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\\geq\\operatorname*{min}_{\\tilde{\\sigma}}\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma^{\\prime})=\\operatorname*{min}_{\\tilde{\\sigma}}\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Under the assumption of uniform prior we have, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v_{x_{s}}(\\sigma\\,|\\,\\hat{\\sigma})=\\displaystyle\\sum_{\\tau=x_{s}}\\overline{{\\mathrm{Pr}(\\tilde{\\sigma})}}\\mathrm{Pr}_{s}(\\sigma\\,|\\,\\pi)}\\\\ &{\\qquad\\qquad=\\displaystyle\\frac{1}{(m-k)!}\\sum_{\\tau=x_{s}}\\mathrm{Pr}_{s}(\\sigma^{*}\\,|\\,\\pi)}\\\\ &{\\qquad=\\displaystyle\\frac{1}{(m-k)!}\\sum_{\\tau=x_{s}}\\sum_{\\tau=x_{s}\\tau\\neq\\nu_{s}}\\mathrm{Pr}_{s}(\\sigma^{\\prime}\\,|\\,\\pi)}\\\\ &{\\qquad=\\displaystyle\\frac{1}{(m-k)!}\\sum_{\\tau=x_{s}\\neq\\nu_{s}\\tau\\neq\\nu_{s}}^{\\infty}p_{\\tau}\\cdot\\frac{\\phi_{t}^{(\\prime\\prime^{\\prime},\\pi)}}{Z(\\phi_{E})}+(1-p)\\cdot\\frac{\\phi_{t}^{(\\prime\\prime^{\\prime},\\pi)}}{Z(\\phi_{N E})}}\\\\ &{\\qquad=\\displaystyle\\frac{1}{(m-k)!}\\sum_{\\tau=\\nu_{s}}\\left(p\\cdot\\frac{Z(\\phi_{E},m-k)}{Z(\\phi_{E})}\\cdot\\phi_{E}^{(\\prime\\prime,\\alpha)}+(1-p)\\cdot\\frac{Z(\\phi_{N E},m-k)}{Z(\\phi_{N E})}\\cdot\\phi_{N E}^{(\\prime\\prime,\\alpha)}\\right)}\\\\ &{\\qquad=p\\cdot\\frac{Z(\\phi_{E},m-k)}{Z(\\phi_{E})}\\cdot\\phi_{E}^{(\\prime\\prime,\\delta)}+(1-p)\\cdot\\frac{Z(\\phi_{N E},m-k)}{Z(\\phi_{N E})}\\cdot\\phi_{N E}^{(\\prime\\prime,\\delta)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Here $\\begin{array}{r}{Z(\\phi,m-k)=\\sum_{\\tau:[m-k]\\to[m-k]}\\phi^{d(\\tau,\\tau^{\\star})}}\\end{array}$ . Therefore, $g(\\sigma\\mid\\sigma^{\\prime})\\geq\\kappa$ for any $\\sigma,\\sigma^{\\prime}$ ", "page_idx": 30}, {"type": "text", "text": "We will first prove a multiplicative concentration inequality on the estimates $\\widehat{g}(\\cdot\\mid\\sigma)$ for any $\\sigma$ . Now fix any $\\sigma$ . By using lemma (1) we obtain that with probability   at least $1\\:-\\:\\delta_{1}$ $\\begin{array}{r}{\\operatorname*{max}_{\\sigma^{\\prime}}|g(\\sigma^{\\prime}\\mid\\sigma)-\\widehat{g}(\\sigma^{\\prime}\\mid\\sigma)|\\leq\\frac{\\log(1/\\delta_{1})}{n^{2}}}\\end{array}$ . This implies that $\\begin{array}{r}{\\widehat{g}(\\sigma^{\\prime}\\mid\\sigma)\\geq g(\\sigma^{\\prime}\\mid\\sigma)-\\frac{\\log(1/\\delta_{1})}{n^{2}}}\\end{array}$ . Since $g(\\sigma^{\\prime}\\mid\\sigma)\\geq\\mu$ , in order to have $\\widehat{g}(\\sigma^{\\prime}\\mid\\sigma)\\geq(1-\\varepsilon)g(\\sigma^{\\prime}\\mid\\sigma)$ it is sufficient to have $\\begin{array}{r}{n\\geq\\sqrt{\\frac{\\log(1/\\delta_{1})}{\\varepsilon\\cdot\\mu}}}\\end{array}$ . Moreover, because of the fact that $\\mu<1$ , we also have $\\widehat{g}(\\sigma^{\\prime}\\mid\\sigma)\\leq(1+\\varepsilon)g(\\sigma^{\\prime}\\mid\\sigma)$ . Finally, we can use union bound over all $k$ ! permutations $\\sigma$ and substituting $\\delta_{1}=\\delta/(2\\cdot k!)$ we obtain that as long as the number of samples from each permutation $\\sigma$ is at least k log(2k/\u03b4), we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(\\forall\\sigma,\\sigma^{\\prime},\\ (1-\\varepsilon)g(\\sigma^{\\prime}\\mid\\sigma)\\leq\\widehat{g}(\\sigma^{\\prime}\\mid\\sigma)\\leq(1+\\varepsilon)g(\\sigma^{\\prime}\\mid\\sigma)\\right)\\geq1-\\frac{\\delta}{2}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We now apply a similar concentration inequality for the frequency terms $f(\\cdot)$ . Since $\\operatorname*{Pr}_{s}(\\sigma\\mid\\sigma^{\\star})\\geq\\mu$ for any $\\sigma$ we have $f(\\sigma)\\geq\\kappa$ . By an argument very similar to the previous paragraph we have that as long as n \u2265 $n\\geq\\sqrt{\\frac{\\log(2/\\delta)}{\\varepsilon\\cdot\\mu}}$ , we are guaranteed that $(1-\\varepsilon)f(\\sigma)\\le\\widehat{f}(\\sigma)\\le(1+\\varepsilon)f(\\sigma)$ with probability at least $1-\\delta/2$ . ", "page_idx": 30}, {"type": "text", "text": "Now we provide a lower bound on the estimate $\\widehat V(\\sigma^{\\star})$ . ", "page_idx": 30}, {"type": "equation", "text": "$$\n{\\widehat{V}}(\\sigma^{\\star})={\\widehat{f}}(\\sigma^{\\star})\\sum_{\\sigma^{\\prime}}{\\frac{{\\widehat{g}}(\\sigma^{\\prime}\\mid\\sigma^{\\star})}{{\\widehat{g}}(\\sigma^{\\star}\\mid\\sigma^{\\prime})}}\\geq{\\frac{(1-\\varepsilon)^{2}}{(1+\\varepsilon)}}f(\\sigma^{\\star})\\sum_{\\sigma^{\\prime}}{\\frac{g(\\sigma^{\\prime}\\mid\\sigma^{\\star})}{g(\\sigma^{\\star}\\mid\\sigma^{\\prime})}}={\\frac{(1-\\varepsilon)^{2}}{(1+\\varepsilon)}}{\\overline{{V}}}(\\sigma^{\\star})\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We now provide an upper bound on $\\widehat V(\\tau)$ for any $\\tau\\ne\\sigma^{\\star}$ . ", "page_idx": 30}, {"type": "equation", "text": "$$\n{\\widehat{V}}(\\tau)={\\widehat{f}}(\\tau)\\sum_{\\sigma^{\\prime}}{\\frac{{\\widehat{g}}(\\sigma^{\\prime}\\mid\\tau)}{{\\widehat{g}}(\\tau\\mid\\sigma^{\\prime})}}\\leq{\\frac{(1+\\varepsilon)^{2}}{(1-\\varepsilon)}}f(\\tau)\\sum_{\\sigma^{\\prime}}{\\frac{g(\\sigma^{\\prime}\\mid\\tau)}{g(\\tau\\mid\\sigma^{\\prime})}}={\\frac{(1+\\varepsilon)^{2}}{(1-\\varepsilon)}}{\\overline{{V}}}(\\tau)\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We now use lemma (2) i.e. $\\overline{{V}}(\\sigma^{\\star})\\geq2\\overline{{V}}(\\tau)$ . ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\widehat V(\\sigma^{\\star})\\geq\\frac{(1-\\varepsilon)^{2}}{(1+\\varepsilon)}\\overline{V}(\\sigma^{\\star})\\geq\\frac{2(1-\\varepsilon)^{2}}{(1+\\varepsilon)}\\overline{V}(\\tau)\\geq\\frac{2(1-\\varepsilon)^{3}}{(1+\\varepsilon)^{3}}\\widehat V(\\tau)>\\widehat V(\\tau)\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "as long as \u03b5 \u2264 33\u221a22\u2212+11 \u22480.115. We substitute \u03b5 = 0.1. Finally, observe that we pick the outcome with highest empirical prediction normalized vote $\\widehat V(\\sigma)$ and with probability at least $1-\\delta$ , the empirical prediction normalized vote of $\\sigma^{\\star}$ will be the  highest, and will be picked as the outcome. \u53e3 ", "page_idx": 31}, {"type": "text", "text": "Lemma 1 (Theorem 9 of [7]). Let $X_{1},\\ldots,X_{n}$ be n be i.i.d. drawn from a discrete distribution $p=(p_{1},\\cdot\\cdot\\cdot,p_{k})$ and let $\\begin{array}{r}{\\widehat{p}_{j}=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{1}\\left\\{X_{i}=j\\right\\}}\\end{array}$ . Then we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(\\operatorname*{max}_{j\\in[k]}|\\widehat{p}_{j}-p_{j}|\\geq\\frac{\\log(1/\\delta)}{n^{2}}\\right)\\leq\\delta\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "H.2 Separation Lemma ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Lemma 2. Assume uniform prior and assumption $I$ holds. Then for any ground truth $\\sigma^{\\star}$ over subset $T$ of size $k$ and any $\\tau$ with $d(\\tau,\\sigma^{\\star})\\geq1$ we have, $\\overline{{V}}(\\sigma^{\\star})\\geq2\\overline{{V}}(\\tau)$ . ", "page_idx": 31}, {"type": "text", "text": "Proof. Using the definition of $g(\\cdot\\mid\\cdot)$ we can establish the following lower and upper bounds. ", "page_idx": 31}, {"type": "equation", "text": "$$\ng(\\sigma\\mid\\sigma^{\\prime})=\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma^{\\prime})\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\\geq\\operatorname*{min}_{\\tilde{\\sigma}}\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma^{\\prime})=\\operatorname*{min}_{\\tilde{\\sigma}}\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\ng(\\sigma\\mid\\sigma^{\\prime})=\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma^{\\prime})\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\\leq\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{g}(\\tilde{\\sigma}\\mid\\sigma^{\\prime})=\\sum_{\\tilde{\\sigma}}\\operatorname{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Now we can establish the following lower and upper bounds on the prediction-normalized vote. ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\sigma)=f(\\sigma)\\sum_{\\sigma^{\\prime}}\\frac{g(\\sigma^{\\prime}\\mid\\sigma)}{g(\\sigma\\mid\\sigma^{\\prime})}\\leq\\frac{f(\\sigma)}{\\operatorname*{min}_{\\tilde{\\sigma}}\\mathrm{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})}\\sum_{\\sigma^{\\prime}}g(\\sigma^{\\prime}\\mid\\sigma)=\\frac{f(\\sigma)}{\\operatorname*{min}_{\\tilde{\\sigma}}\\mathrm{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\sigma)=f(\\sigma)\\sum_{\\sigma^{\\prime}}\\frac{g(\\sigma^{\\prime}\\mid\\sigma)}{g(\\sigma\\mid\\sigma^{\\prime})}\\ge\\frac{f(\\sigma)}{\\sum_{\\tilde{\\sigma}}\\operatorname*{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})}\\sum_{\\sigma^{\\prime}}g(\\sigma^{\\prime}\\mid\\sigma)=\\frac{f(\\sigma)}{\\sum_{\\tilde{\\sigma}}\\operatorname*{Pr}_{s}(\\sigma\\mid\\tilde{\\sigma})}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Now consider a partial ranking $\\tau$ such that $d(\\tau,\\sigma^{\\star})=1$ . Then we have, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\sigma^{\\star})\\geq\\frac{f(\\sigma^{\\star})}{\\sum_{\\tilde{\\sigma}}\\operatorname*{Pr}_{s}(\\sigma^{\\star}\\mid\\tilde{\\sigma})}=\\frac{\\operatorname*{Pr}_{s}(\\sigma^{\\star}\\mid\\sigma^{\\star})}{\\sum_{\\tilde{\\sigma}}\\operatorname*{Pr}_{s}(\\sigma^{\\star}\\mid\\tilde{\\sigma})}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "and ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\tau)\\leq\\frac{f(\\tau)}{\\operatorname*{min}_{\\tilde{\\sigma}}\\operatorname*{Pr}_{s}(\\tau\\mid\\tilde{\\sigma})}=\\frac{\\operatorname*{Pr}_{s}(\\tau\\mid\\sigma^{\\star})}{\\operatorname*{min}_{\\tilde{\\sigma}}\\operatorname*{Pr}_{s}(\\tau\\mid\\tilde{\\sigma})}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Under the assumption of uniform prior we have, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}_{s}(\\sigma^{*}\\mid\\tilde{\\sigma})=\\displaystyle\\sum_{\\pi:\\pi\\neq\\tilde{\\sigma}}\\frac{\\operatorname*{Pr}(\\pi)}{\\operatorname*{Pr}(\\tilde{\\sigma})}\\operatorname*{Pr}_{s}(\\sigma^{*}\\mid\\pi)}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\frac{1}{(m-k)!}\\sum_{\\pi:\\pi\\neq\\tilde{\\sigma}}\\operatorname*{Pr}_{s}(\\sigma^{*}\\mid\\pi)}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\frac{1}{(m-k)!}\\sum_{\\pi:\\pi\\neq\\tilde{\\sigma}}\\sum_{\\pi:\\pi\\neq\\pi^{*}}\\operatorname*{Pr}_{s}(\\pi^{\\prime}\\mid\\pi)}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\frac{1}{(m-k)!}\\sum_{\\pi:\\pi\\neq\\tilde{\\sigma}}\\sum_{\\pi:\\pi\\neq\\nu}p_{\\pi^{\\prime}:\\pi}\\cdot\\frac{\\phi_{K}^{d}(\\pi^{\\prime},\\pi)}{Z(\\phi E)}+(1-p)\\cdot\\frac{\\phi_{N K}^{d}(\\pi^{\\prime},\\pi)}{Z(\\phi N E)}}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\frac{c(T)}{(m-k)!}\\left(p\\cdot\\frac{\\phi_{L}^{d}(\\tilde{\\sigma},\\pi^{*})}{Z(\\phi E)}+(1-p)\\cdot\\frac{\\phi_{N K}^{d}(\\tilde{\\sigma},\\pi^{*})}{Z(\\phi N E)}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Here $c(T)$ is a constant depending only on the subset $T$ . Using the above identity we obtain the following lower bound on $\\overline{{V}}(\\sigma^{\\star})$ . ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\sigma^{\\star})\\geq\\frac{p\\cdot\\frac{1}{Z(\\phi_{E})}+(1-p)\\cdot\\frac{1}{Z(\\phi_{N E})}}{\\sum_{\\tilde{\\sigma}}p\\cdot\\frac{\\phi_{E}^{d(\\tilde{\\sigma},\\sigma^{\\star})}}{Z(\\phi_{E})}+(1-p)\\cdot\\frac{\\phi_{N E}^{d(\\tilde{\\sigma},\\sigma^{\\star})}}{Z(\\phi_{N E})}}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "We can also obtain the following upper bound on $\\overline{{V}}(\\tau)$ . ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\tau)\\leq\\frac{p\\cdot\\frac{\\phi_{E}}{Z(\\phi_{E})}+(1-p)\\cdot\\frac{\\phi_{N E}}{Z(\\phi_{N E})}}{\\operatorname*{min}_{\\tilde{\\sigma}}p\\cdot\\frac{\\phi_{E}^{d(\\tilde{\\sigma},\\tau)}}{Z(\\phi_{E})}+(1-p)\\cdot\\frac{\\phi_{N E}^{d(\\tilde{\\sigma},\\tau)}}{Z(\\phi_{N E})}}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "We now use the relationship $p<(1-p)$ and $\\phi_{E}<\\phi_{N E}$ to improve the bounds. We will also write $\\begin{array}{r}{Z(\\phi,k)=\\sum_{\\tilde{\\sigma}}\\phi^{d(\\tilde{\\sigma},\\tau})}\\end{array}$ . ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\sigma^{\\star})\\geq\\frac{\\frac{2p}{Z(\\phi_{N E})}}{\\frac{2(1-p)Z(\\phi_{N E},k)}{Z(\\phi_{E})}}=\\frac{p}{1-p}\\frac{Z(\\phi_{E})}{Z(\\phi_{N E})}\\frac{1}{Z(\\phi_{N E},k)}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "equation", "text": "$$\n\\overline{{V}}(\\tau)\\leq\\frac{2\\cdot\\frac{(1-p)\\phi_{N E}}{Z(\\phi_{E})}}{2p\\cdot\\frac{\\phi_{E}^{k(k-1)/2}}{Z(\\phi_{N E})}}=\\frac{1-p}{p}\\frac{Z(\\phi_{N E})}{Z(\\phi_{E})}\\phi_{E}^{k(k-1)/2}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Therefore, in order to have $\\overline{{V}}(\\sigma^{\\star})\\geq2\\overline{{V}}(\\tau)$ we need the following inequality to hold. ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\frac{p}{1-p}\\frac{Z(\\phi_{E})}{Z(\\phi_{N E})}\\frac{1}{Z(\\phi_{N E},k)}\\ge2\\cdot\\frac{1-p}{p}\\frac{Z(\\phi_{N E})}{Z(\\phi_{E})}\\phi_{E}^{k(k-1)/2}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "I Screenshots from our MTurk Survey ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Here, we provide screenshots of different phases of our MTurk survey. ", "page_idx": 32}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/81c1239836eaff1472427e6785831b89ec4e5430d71133a87de1c030b28f431a.jpg", "img_caption": ["Figure 17: Preview and Consent Form "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/3c3c682d55e025ec77971c2ab439c53d2ec860ab2d53073e71783bba55bab737.jpg", "img_caption": ["Figure 18: Tutorial for Rank-None Elicitation Format "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/8c30fe80cc2bd171b424fbee2a7f0c30a59c4c87ac694719601d16c773e658e1.jpg", "img_caption": ["Figure 19: Questions for Top-None and Top-Top Elicitation Format "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/2ec6d9a52898674b51a61d0455b1aa67b2ac920380eb95354d76dabd0df289db.jpg", "img_caption": ["Figure 20: Questions for Top - Approval(3) and Top-Rank Elicitation Format "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/4aa1225407b3be87430a88c9c46aad04c0814b08a130167e43455f6c231bd4bd.jpg", "img_caption": ["Figure 21: Questions for Approval(2) - Approval(2) and Approval(3) - Rank Elicitation Format "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/d155bccfa321de3a7a2eb59c0fd04e4ac1395f8e69cd975963e995cb7627462d.jpg", "img_caption": ["Figure 22: Questions for Rank-None and Rank-Top Elicitation Format "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/a2ea1e46b055ee51ca747863591a3810d173e951562bc3e3902014985befd841.jpg", "img_caption": ["Figure 23: Question for Rank-Rank Elicitation Format and Survey Questions "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "CL9k2PaUQb/tmp/50197e081e09da4272b3d1b1f97049746a6ee69e4767507e4612c9130d027219.jpg", "img_caption": ["Figure 24: Difficulty and Expressiveness Questions "], "img_footnote": [], "page_idx": 35}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 36}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 36}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 36}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 36}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 36}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 36}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 36}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 36}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 37}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 37}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes]   \nJustification:   \nGuidelines: \u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ", "page_idx": 38}, {"type": "text", "text": "\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 39}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 39}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 39}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 39}, {"type": "text", "text": "Answer: [No] ", "page_idx": 39}, {"type": "text", "text": "Justification: The experiments can be run on any computer. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. ", "page_idx": 39}, {"type": "text", "text": "\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 40}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] Justification: Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 40}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] Justification: Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 40}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 40}, {"type": "text", "text": "Justification:   \nGuidelines: \u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 41}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 41}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 41}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: The paper includes full text of instructions given to participants, screenshots, and details of compensation for the crowdsourcing experiment conducted during research. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 42}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Justification: We have obtained IRB approval for the crowdsourcing experiment conducted during research. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 42}]