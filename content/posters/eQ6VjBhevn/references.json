{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a Vision-Language Model that is foundational to the work presented and heavily used in the experiments."}, {"fullname_first_author": "Manli Shu", "paper_title": "Test-time prompt tuning for zero-shot generalization in vision-language models", "publication_date": "2022-12-01", "reason": "This paper introduces Test-Time Prompt Tuning (TPT), the primary TTA method analyzed and compared against in this work."}, {"fullname_first_author": "Marvin Zhang", "paper_title": "Memo: Test time robustness via adaptation and augmentation", "publication_date": "2022-12-01", "reason": "This paper introduces Marginal Entropy Minimization (MEM), a key concept underlying the theoretical analysis and proposed method in this paper."}, {"fullname_first_author": "Jameel Hassan Abdul Samadh", "paper_title": "Align your prompts: Test-time prompting with distribution alignment for zero-shot generalization", "publication_date": "2023-12-01", "reason": "This paper introduces PromptAlign, a competing TTA method that is compared against the proposed method in the experiments."}, {"fullname_first_author": "Shuai Zhao", "paper_title": "Test-time adaptation with CLIP reward for zero-shot generalization in vision-language models", "publication_date": "2024-05-01", "reason": "This paper introduces Reinforcement Learning from CLIP Feedback (RLCF), another competing TTA method compared in the experiments."}]}