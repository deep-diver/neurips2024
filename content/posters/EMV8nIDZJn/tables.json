[{"figure_path": "EMV8nIDZJn/tables/tables_6_1.jpg", "caption": "Table 1: Summary of experiment benchmarks. For each dataset, we randomly select n = [0.5p] variables as DVs, whose values are first MinMax normalized and then discretized into the value of 0 or 1 with the threshold 0.5 as int(MinMax(x) > 0.5). See Table 5 for more details.", "description": "This table summarizes the benchmark datasets used in the experiments for five different mixed time series analysis tasks: classification, extrinsic regression, imputation, anomaly detection, and long-term forecasting.  For each task, it lists the benchmark dataset used, the metrics used for evaluation, and the range of series lengths and number of variables (p) in the datasets.  The table also notes that for each dataset, half of the variables (n = 0.5p) were randomly selected and converted to discrete variables (DVs) through a MinMax normalization and discretization process.", "section": "4 Experiments"}, {"figure_path": "EMV8nIDZJn/tables/tables_7_1.jpg", "caption": "Table 2: Imputation Task. The best results are bolded and the second-best results are underlined. The same goes for Table 3. See Table 14 for full results.", "description": "This table presents the results for the imputation task, comparing the performance of MiTSformer against several other models on six datasets (ETTm1, ETTm2, ETTh1, ETTh2, Electricity, and Weather).  The metrics used to evaluate performance are MAE (Mean Absolute Error) and MSE (Mean Squared Error).  The table highlights the best and second-best performing models for each dataset and metric.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_8_1.jpg", "caption": "Table 3: Long Term Forecasting of CVs. \"-\" denotes out of memory. See Table 16 for full results.", "description": "This table presents the results of long-term forecasting experiments conducted on various datasets.  The metrics used are MAE (Mean Absolute Error) and MSE (Mean Squared Error), which are common measures for evaluating the accuracy of forecasting models.  The table compares the performance of MiTSformer against several other state-of-the-art models. The \"-\" indicates that the model ran out of memory for that particular experiment.  The full results, including those that ran out of memory, can be found in Table 16.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_9_1.jpg", "caption": "Table 4: Ablation analysis. For anomaly detection tasks, we do not ablate \\textit{LRec}, as it is needed to support anomaly criterion calculation. The corresponding results are omitted with ``/\\ ''.", "description": "This ablation study analyzes the impact of each component of MiTSformer on three tasks: classification, long-term forecasting, and anomaly detection.  It systematically removes one component at a time (\\textit{LDis}, \\textit{LSmooth}, \\textit{LRec}, Cross-Attention) to observe the effect on performance.  The results show that all components are important for optimal performance, particularly the cross-attention mechanism for capturing inter-variable dependencies. Anomaly detection results are not included for the ablation of \\textit{LRec} because it is crucial for this task's anomaly detection criteria.", "section": "4.2 Ablation Studies"}, {"figure_path": "EMV8nIDZJn/tables/tables_15_1.jpg", "caption": "Table 5: Dataset descriptions. The dataset size is organized in (Train, Validation, Test). \u201cDim. p\u201d denotes the total variable dimension and \"Dim. n\" denotes the discrete variable dimension. Since current benchmark datasets are time series encompassing only continuous variables, we generate mixed time series from these datasets by discretizing partial variables. For each dataset, we randomly select half variables as DVs (n = [0.5p]), whose values are first MinMax normalized and then discretized into the value of 0 or 1 with the threshold 0.5 as int(MinMax(x) > 0.5).", "description": "This table presents the characteristics of the datasets used in the paper's experiments.  It lists each dataset's name, the number of continuous and discrete variables (Dim p and Dim n respectively), the length of each time series, the size of the dataset split into training, validation, and testing sets, and a short description of the dataset's content and source.  The table highlights how the datasets were adapted to include mixed time series data by converting some continuous variables into discrete variables.", "section": "A.1 Datasets and Experimental Platforms"}, {"figure_path": "EMV8nIDZJn/tables/tables_16_1.jpg", "caption": "Table 6: Experiment configuration of MiTSformer. All the experiments use the ADAM optimizer with the default hyperparameter configuration for (\u03b21, \u03b22) as (0.9, 0.999) with proper early stopping, and adopt a dropout rate of 0.1. \u03bb\u2081 denotes the weight of smoothness loss, \u03bb\u2082 denotes the weight of reconstruction loss, and \u03bb\u2083 denotes the weight of variable modality discrimination loss. LR* denotes the initial learning rate. The number of attention heads is set to 8 for all experiments.", "description": "This table details the hyperparameters used in the MiTSformer model for different tasks. It includes the number of layers, the dimension of the model, the weights assigned to the smoothness, reconstruction, and variable modality discrimination losses, the initial learning rate, batch size, and number of epochs used during training.  The ADAM optimizer was used for all experiments with a dropout rate of 0.1 and 8 attention heads.", "section": "A.2 Hyperparameters and Experimental Configurations"}, {"figure_path": "EMV8nIDZJn/tables/tables_16_2.jpg", "caption": "Table 7: Experiment configuration of baseline models. All the experiments use the ADAM optimizer with the default hyperparameter configuration for (\u03b21, \u03b22) as (0.9, 0.999) with proper early stopping, and adopt a dropout rate of 0.1. LR* denotes the initial learning rate. For Transformer-based models, the number of attention heads is set to 8 for all experiments.", "description": "This table details the hyperparameter settings used for various baseline models in the experiments.  It specifies the optimizer (ADAM), learning rate, batch size, and number of epochs used for training each model on different tasks.  The number of attention heads (for transformer-based models) is also specified, along with the layers and hidden size or dmodel dimension.", "section": "A.2 Hyperparameters and Experimental Configurations"}, {"figure_path": "EMV8nIDZJn/tables/tables_18_1.jpg", "caption": "Table 8: Robustness of MiTSformer performance on forecasting datasets. Averaged MAE, MSE, and their standard deviations based on different random seeds are reported.", "description": "This table demonstrates the robustness of the MiTSformer model's performance on long-term forecasting tasks across multiple datasets.  It shows the average Mean Absolute Error (MAE) and Mean Squared Error (MSE) for four different prediction horizons (96, 192, 336, and 720 time steps), along with the standard deviation for each metric and horizon. The datasets used are ETTm1, ETTm2, ETTh1, ETTh2, Electricity, Weather, and Traffic.  This indicates how consistently the model performs across different random initializations of the model parameters, providing a measure of stability and reliability for its forecasting capabilities.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_24_1.jpg", "caption": "Table 9: Compared to mixed NB- and VI-based methods. Accuracy(%) scores are reported. The best results are bolded.", "description": "This table presents a comparison of the classification accuracy achieved by MiTSformer against two other methods: HVM (a mixed Naive Bayes model) and VAMDA (a variational inference-based model).  The results show MiTSformer's superior performance across six different datasets. The table highlights the limitations of the previous methods for this type of mixed-data task, which involve the use of time series data.", "section": "E.1 Comparison with Mixed Naive Bayes and Variational Inference-based methods"}, {"figure_path": "EMV8nIDZJn/tables/tables_24_2.jpg", "caption": "Table 10: Performance of mixed time series classification under the different discrete states of DVs, i.e., NDVS. Accuracy (%) scores are reported. The best results are bolded.", "description": "This table presents the results of mixed time series classification experiments conducted with varying numbers of discrete states in the discrete variables (DVs).  The accuracy of the classification is reported for each dataset, showing how performance changes as the number of discrete states increases.  The best performing model for each dataset is highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "EMV8nIDZJn/tables/tables_24_3.jpg", "caption": "Table 11: Performance of mixed time series anomaly detection under the different discrete states of DVs, i.e., NDVs. The best results are bolded.", "description": "This table presents the performance of the MiTSformer model and other baseline models on five anomaly detection datasets (SMD, MSL, SMAP, SWAT, PSM).  The results are broken down by the number of discrete states (NDVS) in the discrete variables (DVs), comparing results for 2 and 4 discrete states.  The metrics reported are Precision, Recall, and F1-score, with higher scores indicating better performance.  The best result for each dataset and metric is bolded.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_25_1.jpg", "caption": "Table 12: Full classification results. We report the classification accuracy (%) as the result.", "description": "This table presents the classification accuracy achieved by MiTSformer and various baseline models across ten different datasets.  Each dataset represents a distinct time series classification problem, with varying characteristics like length and number of variables. The table allows for a comparison of MiTSformer's performance against state-of-the-art methods in the context of mixed time series classification. The results highlight MiTSformer's ability to achieve superior or competitive performance.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_25_2.jpg", "caption": "Table 8: Robustness of MiTSformer performance on forecasting datasets. Averaged MAE, MSE, and their standard deviations based on different random seeds are reported.", "description": "This table demonstrates the robustness of the MiTSformer model's performance on forecasting tasks across multiple datasets.  It shows the average Mean Absolute Error (MAE) and Mean Squared Error (MSE), along with their standard deviations, for different prediction horizons (96, 192, 336, and 720).  The results are presented for several datasets: ETTm1, ETTm2, ETTh1, ETTh2, Electricity, Weather, and Traffic, highlighting the model's consistency and stability across various experimental runs.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_26_1.jpg", "caption": "Table 8: Robustness of MiTSformer performance on forecasting datasets. Averaged MAE, MSE, and their standard deviations based on different random seeds are reported.", "description": "This table presents the robustness analysis of MiTSformer on forecasting tasks.  It shows the averaged MAE and MSE values along with their standard deviations across multiple runs (different random seeds) for several datasets and prediction horizons (96, 192, 336, and 720). This demonstrates the stability and reliability of MiTSformer's performance.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_26_2.jpg", "caption": "Table 15: Full anomaly detection results. The \u201cP\u201d, \u201cR\u201d, and \u201cF1\u201d represent the precision, recall, and F1-score (%) respectively. F1-score is the harmonic mean of precision and recall. A higher value of P, R, and F1 indicates better anomaly detection performance.", "description": "This table presents the anomaly detection results for five different datasets (SMD, MSL, SMAP, SWAT, and PSM) using MiTSformer and several baseline models. The results are evaluated using precision (P), recall (R), and F1-score (F1), with higher values indicating better performance. The average F1-score across all datasets is also shown for each model.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_27_1.jpg", "caption": "Table 8: Robustness of MiTSformer performance on forecasting datasets. Averaged MAE, MSE, and their standard deviations based on different random seeds are reported.", "description": "This table demonstrates the robustness of the MiTSformer model's performance on long-term forecasting tasks across multiple datasets. It presents the average Mean Absolute Error (MAE) and Mean Squared Error (MSE), along with their standard deviations, calculated from multiple runs with different random seeds. This helps assess the stability and reliability of the model's predictions across various runs.", "section": "4.1 Main Results on Different Tasks"}, {"figure_path": "EMV8nIDZJn/tables/tables_28_1.jpg", "caption": "Table 8: Robustness of MiTSformer performance on forecasting datasets. Averaged MAE, MSE, and their standard deviations based on different random seeds are reported.", "description": "This table presents the robustness analysis of MiTSformer's performance on long-term forecasting tasks.  It shows the average Mean Absolute Error (MAE) and Mean Squared Error (MSE), along with their standard deviations, calculated across multiple runs with different random seeds. The results are reported for different forecasting horizons (96, 192, 336, and 720) on several datasets (ETTm1, ETTm2, ETTh1, ETTh2, Electricity, Weather, and Traffic). This demonstrates the stability and reliability of MiTSformer's performance across various runs.", "section": "4.1 Main Results on Different Tasks"}]