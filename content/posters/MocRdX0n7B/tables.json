[{"figure_path": "MocRdX0n7B/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative comparisons of the ExDark dataset based on YOLOv3 and TOOD detectors.", "description": "This table presents a quantitative comparison of the performance of YOLOv3 and TOOD object detectors on the ExDark dataset.  It shows the recall and mean Average Precision (mAP) at an IoU threshold of 0.5 for various methods, including baselines (KIND, SMG, NeRCo, DENet, GDIP, IAT, MAET), a naive version of the proposed YOLA method, and the full YOLA method.  The results demonstrate the improvement achieved by YOLA compared to other methods on this low-light image dataset.", "section": "4 Experiments"}, {"figure_path": "MocRdX0n7B/tables/tables_7_1.jpg", "caption": "Table 3: The effectiveness of IIM, IIM-Edge and the zero mean constraint Zmean based on TOOD. The blank line denotes the baseline.", "description": "This table presents ablation study results on the TOOD detector to evaluate the impact of different components of the proposed Illumination Invariant Module (IIM).  It shows the mAP50 (mean Average Precision at IoU threshold of 0.5) for the ExDark and DarkFace datasets using different configurations of the IIM: with only IIM-Edge (simple edge feature), with IIM (including learnable kernels), and with IIM and zero-mean constraint. The baseline results (no IIM) are also included for comparison. The table demonstrates the contribution of each component towards improving the overall object detection performance.", "section": "4 Experiments"}, {"figure_path": "MocRdX0n7B/tables/tables_7_2.jpg", "caption": "Table 4: Ablation study for YOLA on COCO 2017val.", "description": "This table presents the ablation study results for the proposed YOLA framework.  It shows the performance of the TOOD detector with and without YOLA on a well-lit and over-lit version of the COCO 2017 validation set. The metrics used for evaluation are AP50, AP75 and mAP.", "section": "4 Experiments"}, {"figure_path": "MocRdX0n7B/tables/tables_7_3.jpg", "caption": "Table 5: Model size of different methods.", "description": "This table compares the model sizes (in millions of parameters) of various methods used for low-light object detection, including the proposed YOLA method and several state-of-the-art methods.  The table highlights the significantly smaller model size of YOLA compared to others.", "section": "4 Experiments"}, {"figure_path": "MocRdX0n7B/tables/tables_13_1.jpg", "caption": "Table 6: Quantitative comparisons of the ExDark dataset based on YOLOv3 detector.", "description": "This table presents a quantitative comparison of different object detection methods on the ExDark dataset using the YOLOv3 detector.  It shows the mean Average Precision (mAP50) and the average precision (AP) for each object category (Bicycle, Boat, Bottle, Bus, Car, Cat, Chair, Cup, Dog, Motorbike, People, Table) for various methods including baselines and state-of-the-art methods.  The \"Ours\" row represents the performance of the proposed YOLA method.", "section": "4.3 Low-light object detection"}, {"figure_path": "MocRdX0n7B/tables/tables_14_1.jpg", "caption": "Table 6: Quantitative comparisons of the ExDark dataset based on YOLOv3 detector.", "description": "This table presents a quantitative comparison of different object detection methods on the ExDark dataset using the YOLOv3 detector.  It shows the mean Average Precision (mAP50) and the average precision (AP) for each object category in the dataset.  The methods compared include various low-light image enhancement techniques integrated with YOLOv3, along with the proposed YOLA method. The results show the performance improvement achieved by YOLA compared to existing techniques.", "section": "4.3 Low-light object detection"}, {"figure_path": "MocRdX0n7B/tables/tables_15_1.jpg", "caption": "Table 8: Quantitative comparisons (YOLA vs. FeatEnHancer) of ExDark and UG2+DARK FACE datasets based on RetinaNet. Red and blue colors represent improvement and degradation of performance, respectively, compared to the baseline. \u2020 indicates our implemented baseline.", "description": "This table presents a quantitative comparison of the performance of YOLA and FeatEnhancer on the ExDark and UG2+DARK FACE datasets. The results are based on the RetinaNet object detection model. The table shows the mAP50 (mean Average Precision at IoU threshold of 0.5) for each method, along with the change in mAP50 compared to the baseline.  Positive values indicate improvements, and negative values show performance degradation.  The baseline results are shown for both standard and the authors' alternate baseline implementation (indicated by \u2020).", "section": "4.3 Low-light object detection"}, {"figure_path": "MocRdX0n7B/tables/tables_15_2.jpg", "caption": "Table 9: Quantitative comparisons of the LIS dataset based on Mask R-CNN, where APseg and Apbox indicate the average precision of segmentation and detection, respectively.", "description": "This table presents a quantitative comparison of different methods for low-light instance segmentation on the LIS dataset using Mask R-CNN.  It shows the average precision (AP) for segmentation (APseg) and detection (Apbox) at different IoU thresholds (0.5, 0.75). The results demonstrate the superior performance of YOLA compared to other state-of-the-art methods, especially in terms of overall segmentation performance.", "section": "4.5 Qualitative results"}]