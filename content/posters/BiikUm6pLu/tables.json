[{"figure_path": "BiikUm6pLu/tables/tables_2_1.jpg", "caption": "Table 1: Running times to compute \u025b-optimal policies in the offline setting. In this table, E denotes an upper bound on the ergodicity of the MDP.", "description": "This table compares the runtime and space complexity of different algorithms for computing an \u025b-optimal policy in the offline setting of discounted Markov Decision Processes (DMDPs).  The algorithms are compared based on their dependence on the number of non-zero entries in the transition matrix (nnz(P)), the total number of state-action pairs (Atot), and the discount factor (\u03b3).  The table highlights the improvement achieved by the algorithm proposed in this paper (Algorithm 4).", "section": "1.1 Our results"}, {"figure_path": "BiikUm6pLu/tables/tables_3_1.jpg", "caption": "Table 2: Query complexities to compute \u025b-optimal policy in the sample setting. Merg denotes an upper bound on the MDP's ergodicity. Here, model-free refers to \u00d5(Atot) space methods.", "description": "This table compares the query complexities of different algorithms for solving discounted Markov Decision Processes (DMDPs) in a sample setting where the transition probabilities are unknown but accessible through a generative model.  The algorithms are categorized by their \u025b range (accuracy) and whether they are model-free (using \u00d5(Atot) space). The table highlights the improved query complexity achieved by the authors' algorithm (Algorithm 5).", "section": "Comparison with IPM Approaches"}, {"figure_path": "BiikUm6pLu/tables/tables_8_1.jpg", "caption": "Table 1: Running times to compute \u025b-optimal policies in the offline setting. In this table, E denotes an upper bound on the ergodicity of the MDP.", "description": "This table compares the runtime and space complexity of different algorithms for computing \u03b5-optimal policies in the offline setting of discounted Markov Decision Processes (DMDPs).  The algorithms include classic Value Iteration, several randomized methods like Empirical QVI and Randomized Primal-Dual, and the High Precision Variance-Reduced Value Iteration. The table highlights the improvement achieved by the proposed algorithm (Algorithm 4 in the paper) in terms of runtime complexity, achieving \u00d5(nnz(P) + Atot(1 \u2212 \u03b3)\u22122) compared to previous state-of-the-art methods, especially when considering the sparsity of the transition matrix (nnz(P)).  E represents an upper bound on the ergodicity of the MDP, and its inclusion in some runtime complexities signifies the algorithm's performance dependence on the MDP's mixing properties.", "section": "1.1 Our results"}]