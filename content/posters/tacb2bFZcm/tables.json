[{"figure_path": "tacb2bFZcm/tables/tables_5_1.jpg", "caption": "Table 1: Quantitative comparison with SOTA lightweight SISR methods on multiple benchmark datasets. The best and second-best results on the default training setting (DIV2K) are highlighted in red and blue, respectively. The \"+ indicates that the two methods are trained on the DF2K dataset. We use bold to highlight the lowest FLOPs of Transformer-based methods. All FLOPs (also in Tab. 2b, 3,4) are calculated with an output size of 1280 \u00d7 720.", "description": "This table presents a quantitative comparison of the proposed UPS method against other state-of-the-art (SOTA) lightweight single image super-resolution (SISR) methods on several benchmark datasets.  It shows the performance in terms of Peak Signal-to-Noise Ratio (PSNR) and Structural SIMilarity index (SSIM), highlighting the best and second-best results for each dataset and scale factor. The table also indicates the number of parameters (in thousands), the number of floating point operations (FLOPs) in Giga-operations, and whether the model was trained on the DIV2K or DF2K dataset.  It emphasizes the efficiency of the UPS method in terms of parameter count and FLOPs.", "section": "5 Experiments"}, {"figure_path": "tacb2bFZcm/tables/tables_6_1.jpg", "caption": "Table 2: Results of inference time (ms), FLOPs (G) and GPU memory usage (MB). The speed is tested on an NVIDIA GeForce RTX 2080Ti GPU with an input size of 256 \u00d7 256 under \u00d72 lightweight SISR. FLOPs is calculated at an output resolution of 1280 x 720.", "description": "This table compares the inference time, FLOPs (floating point operations), and GPU memory usage of different lightweight single image super-resolution (SISR) models.  The models are evaluated using a NVIDIA GeForce RTX 2080Ti GPU and input images of size 256x256, upscaling them by a factor of 2.  FLOPs is calculated for an output resolution of 1280x720, providing a standardized measure of computational complexity. The table helps to assess the efficiency of different SISR methods.", "section": "5.2 Comparison with SOTA Methods"}, {"figure_path": "tacb2bFZcm/tables/tables_7_1.jpg", "caption": "Table 3: Non-reference results of real-world SISR on RealSRSet [44].", "description": "This table presents a comparison of non-reference image quality metrics for real-world single image super-resolution (SISR) on the RealSRSet dataset.  The metrics used are NIQE (Natural Image Quality Evaluator), NRQM (No-Reference Quality Metric), and PI (Perceptual Index). Lower NIQE and PI values indicate better image quality, while higher NRQM values represent improved quality.  The table compares the performance of several state-of-the-art GAN-based and diffusion-based methods against the proposed UPS-GAN approach.", "section": "5.2 Comparison with SOTA Methods"}, {"figure_path": "tacb2bFZcm/tables/tables_7_2.jpg", "caption": "Table 4: The effect of varying projection dimensions on similarity calculation.", "description": "This table presents the results of an ablation study on the impact of different projection dimensions (8, 32, 64, 128, 256) on the performance of the UPS model for similarity calculation. The results show that increasing the dimension improves the performance initially but eventually leads to diminishing returns. The table shows that the best performance was achieved with a projection dimension of 128, achieving a PSNR of 34.00 dB and SSIM of 0.9220. This experiment highlights the importance of finding the optimal balance between the model's capacity and its computational cost.", "section": "5.3 Ablation Studies"}, {"figure_path": "tacb2bFZcm/tables/tables_8_1.jpg", "caption": "Table 5: Quantitative comparison with SOTA lightweight models for \u00d72 SISR. All the models are trained on the DIV2K dataset for fair comparison. Inference time is tested at an input size of 256 \u00d7 256 on an NVIDIA GeForce RTX 2080Ti GPU.", "description": "This table presents a quantitative comparison of the proposed UPS model against other state-of-the-art lightweight single image super-resolution (SISR) models for a 2x upscaling factor.  The models were trained on the DIV2K dataset, and performance is evaluated using PSNR and SSIM metrics on various benchmark datasets (Set5, Set14, BSD100, Urban100, and Manga109).  Inference time is also reported, measured on an NVIDIA GeForce RTX 2080Ti GPU with a 256x256 input image.", "section": "5.2 Comparison with SOTA Methods"}, {"figure_path": "tacb2bFZcm/tables/tables_9_1.jpg", "caption": "Table 8: More ablation studies (PSNR/SSIM). A: The impacts of ReLU and Softmax activations in Eq.6. B. Quantitative comparison between two advanced optimization schemes (Dropout in RDSR CVPR 2022 and progressive training in DRCT ARXIV 2024.) and UPS.", "description": "This table presents ablation study results comparing different activation functions (ReLU and Softmax) within the UPS framework and the effect of two advanced optimization techniques, dropout and progressive training, on the model's performance. Part A shows the impact of changing activation functions and Part B compares UPS against other methods that utilize dropout or progressive training.", "section": "A.5 More Ablated Studies"}, {"figure_path": "tacb2bFZcm/tables/tables_9_2.jpg", "caption": "Table 1: Quantitative comparison with SOTA lightweight SISR methods on multiple benchmark datasets. The best and second-best results on the default training setting (DIV2K) are highlighted in red and blue, respectively. The \"+\" indicates that the two methods are trained on the DF2K dataset. We use bold to highlight the lowest FLOPs of Transformer-based methods. All FLOPs (also in Tab. 2b, 3,4) are calculated with an output size of 1280 \u00d7 720.", "description": "This table presents a quantitative comparison of the proposed UPS model against several state-of-the-art (SOTA) lightweight single image super-resolution (SISR) methods.  The comparison is performed across multiple benchmark datasets (Set5, Set14, BSD100, Urban100, and Manga109), using Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) as evaluation metrics.  The table highlights the best and second-best results for each dataset and scaling factor (x2, x3, x4).  It also includes the model's parameter count and floating-point operations per second (FLOPs).  The use of DF2K dataset for training certain models is noted.", "section": "5 Experiments"}, {"figure_path": "tacb2bFZcm/tables/tables_14_1.jpg", "caption": "Table 5: Quantitative comparison with SOTA lightweight models for \u00d72 SISR. All the models are trained on the DIV2K dataset for fair comparison. Inference time is tested at an input size of 256 \u00d7 256 on an NVIDIA GeForce RTX 2080Ti GPU.", "description": "This table compares the performance of the proposed UPS method against other state-of-the-art lightweight single image super-resolution (SISR) models.  The comparison is performed on the \u00d72 setting using the DIV2K dataset for training.  The metrics used are PSNR and SSIM, evaluated on the Set5, Set14, BSD100, Urban100, and Manga109 benchmark datasets.  The table also includes the model parameters, FLOPs and inference time for each model.", "section": "5.2 Comparison with SOTA Methods"}, {"figure_path": "tacb2bFZcm/tables/tables_14_2.jpg", "caption": "Table 1: Quantitative comparison with SOTA lightweight SISR methods on multiple benchmark datasets. The best and second-best results on the default training setting (DIV2K) are highlighted in red and blue, respectively. The \"+ \"+ indicates that the two methods are trained on the DF2K dataset. We use bold to highlight the lowest FLOPs of Transformer-based methods. All FLOPs (also in Tab. 2b, 3,4) are calculated with an output size of 1280 \u00d7 720.", "description": "This table presents a quantitative comparison of the proposed UPS model with state-of-the-art (SOTA) lightweight single image super-resolution (SISR) methods across multiple benchmark datasets (Set5, Set14, BSD100, Urban100, and Manga109).  The results are shown in terms of PSNR and SSIM values for different upscaling factors (\u00d72, \u00d73, \u00d74).  The table highlights the best and second-best performing methods for each dataset and upscaling factor, and indicates whether additional training data (DF2K) was used.  FLOPs (floating point operations per second) are also listed, providing a measure of computational efficiency.", "section": "5 Experiments"}, {"figure_path": "tacb2bFZcm/tables/tables_15_1.jpg", "caption": "Table 7: Robustness comparison of SwinIR-light [7], NGSwin [28] and our proposed UPS. While being trained on clean DIV2K [37] training samples, we directly evaluate their generalization ability on the degraded Set14 benchmark under the \u00d74 setting. We report the PSNR (dB)/SSIM values for quantitative evaluation.", "description": "This table presents a quantitative comparison of the robustness of three different single image super-resolution (SISR) models: SwinIR-light, NGSwin, and the proposed UPS model.  All models were trained on clean DIV2K images, but their performance is evaluated on degraded Set14 images with four types of degradations: no degradation (None), JPEG compression, Gaussian blur, and Gaussian noise.  The results show PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index) values for each model and degradation type, demonstrating the relative robustness of each model to these common image degradations.", "section": "A.3 Robustness Optimization of UPS"}, {"figure_path": "tacb2bFZcm/tables/tables_16_1.jpg", "caption": "Table 1: Quantitative comparison with SOTA lightweight SISR methods on multiple benchmark datasets. The best and second-best results on the default training setting (DIV2K) are highlighted in red and blue, respectively. The \"+ \" indicates that the two methods are trained on the DF2K dataset. We use bold to highlight the lowest FLOPs of Transformer-based methods. All FLOPs (also in Tab. 2b, 3,4) are calculated with an output size of 1280 \u00d7 720.", "description": "This table presents a quantitative comparison of the proposed UPS model with state-of-the-art (SOTA) lightweight single image super-resolution (SISR) methods.  It shows the performance of various models on several benchmark datasets (Set5, Set14, BSD100, Urban100, and Manga109) in terms of PSNR and SSIM.  The best and second-best results for each dataset and scaling factor (x2, x3, x4) are highlighted.  The table also includes the number of parameters (in thousands) and FLOPs (in Giga-operations) for each model, providing a measure of computational efficiency.  The '+' symbol indicates models trained on an extended dataset (DF2K).", "section": "5 Experiments"}, {"figure_path": "tacb2bFZcm/tables/tables_17_1.jpg", "caption": "Table 9: C. V projection indicates the linear projection for transforming the input X<sub>i</sub> into V<sub>i</sub>.", "description": "This table presents the results of an ablation study comparing two versions of the model: one with a linear projection (w/ V proj.) and one without (w/o V proj.).  The results are shown for two datasets: Urban100 (x4) and Set14 (x4), and the number of parameters (in thousands) for each version is also included. The results indicate that the presence or absence of the linear projection does not significantly impact the model's performance in terms of PSNR/SSIM.", "section": "A.7 Limitation"}]