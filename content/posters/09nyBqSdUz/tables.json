[{"figure_path": "09nyBqSdUz/tables/tables_4_1.jpg", "caption": "Table 1: Comparison of Controllable Consistent Image Generation Methods. \u2018Training-free\u2019 indicates no encoder training or diffusion model fine-tuning is needed. \u2018Single ref.\u2019 means the method can operate with only one reference image.", "description": "This table compares several methods for controllable consistent image generation.  It highlights whether each method is training-free (no need for additional training), allows for concept suppression (suppressing specific features), and works with a single reference image.", "section": "4 Experiments"}, {"figure_path": "09nyBqSdUz/tables/tables_18_1.jpg", "caption": "Table 2: Comparison of DreamSim and LPIPS distances for excluding different blocks. The Up1 block of SDXL UNet shows the highest values for both metrics, indicating its strong impact on spatial layout diversity.", "description": "This table presents the results of an ablation study investigating the impact of excluding different UNet blocks from the reference feature guidance (RFG) process on image generation consistency and diversity.  DreamSim and LPIPS scores are used to measure the visual similarity between generated images and a reference image. Higher scores indicate greater differences, suggesting increased diversity in spatial layout. The table shows that excluding the Up1 block leads to the highest DreamSim and LPIPS scores, indicating its significant contribution to spatial layout diversity.  This suggests that this block plays a major role in controlling the consistency of spatial layout during image generation. ", "section": "4.1 Controllable consistency in image generation"}, {"figure_path": "09nyBqSdUz/tables/tables_19_1.jpg", "caption": "Table 3: Comparison of automatic metrics between SVD and RefDrop on video generation. An \u2191 symbol indicates that higher values are better, while a \u2193 symbol indicates that lower values are preferable. Our model shows improvements over the SVD base model in overall quality, text alignment, and temporal consistency. The flow score is the only metric where the SVD model scores higher, indicating more motion. However, the SVD model also exhibits greater jittering and flickering, as reflected in its larger warping error. Notably, a static video would register a flow score of zero. This suggests that our generated videos maintain a reasonable level of motion.", "description": "This table compares the performance of RefDrop and SVD (a baseline video generation model) using automatic metrics provided by EvalCrafter.  Metrics assess overall quality, text alignment, temporal consistency (CLIP, Face consistency, warping error), and motion (flow score). RefDrop shows improvement in most metrics, suggesting higher quality and better consistency, while retaining reasonable motion.", "section": "4.2.1 Temporal-consistent video generation"}, {"figure_path": "09nyBqSdUz/tables/tables_20_1.jpg", "caption": "Table 4: Base model and hyper-parameters.", "description": "This table summarizes the base models used in different sections of the paper along with their corresponding CFG (Classifier-Free Guidance) values, reference strength coefficients (for RefDrop), IP-Adapter scales, and TLPFF (Temporal Low Pass Frequency Filter) parameters.  It details the specific settings used for consistent and diverse image generation, and temporal consistent video generation experiments. Note that some values are ranges, demonstrating the flexibility of the proposed RefDrop method.", "section": "Additional implementation details"}]