[{"figure_path": "ks0FrTSCnK/figures/figures_1_1.jpg", "caption": "Figure 1: Example images of class \"Tench\" from WebVision dataset. Clean samples are marked in extcolorgreenGreen, closed-set noise is marked in Blue and open-set noise is marked in Red. See appendix F for more details.", "description": "This figure shows example images of the \"Tench\" class from the WebVision dataset.  It highlights three types of labeling issues: clean samples (green boxes), closed-set noise (blue boxes), where the noisy label belongs to a different known class, and open-set noise (red boxes), where the noisy label does not belong to any known class. Appendix F provides more details.", "section": "1 Introduction"}, {"figure_path": "ks0FrTSCnK/figures/figures_5_1.jpg", "caption": "Figure 2: All-in-one derivation flowchart. Full details in appendix C.", "description": "This figure shows the derivation flowchart of the error rate inflation in learning with noisy labels. It starts with the clean conditional probability, then incorporates the complete noise transition matrix and open/closed set noise ratios to obtain the noisy conditional probability. Finally, it calculates the error rate inflation using the Bayes error rate as a reference.  Appendix C provides more detailed information about the steps involved.", "section": "3.4 Error rate inflation analysis w.r.t different label noise"}, {"figure_path": "ks0FrTSCnK/figures/figures_8_1.jpg", "caption": "Figure 3: Direct supervised training with different noise modes/ratios. First row: Closed-set classification accuracy; Second row: Open-set detection ROC AUC.", "description": "The figure shows the performance of direct supervised training on CIFAR100-O and ImageNet-O datasets under different noise modes and ratios.  The first row presents closed-set classification accuracy, while the second row displays open-set detection ROC AUC scores.  The results are shown separately for fitted and memorized cases, and for different types of noise (hard open-set, easy open-set, and closed-set). This figure empirically validates theoretical findings presented earlier in the paper about the impact of different noise types on model performance.", "section": "4.1 Empirical validation on previous probabilistic findings"}, {"figure_path": "ks0FrTSCnK/figures/figures_8_2.jpg", "caption": "Figure 4: Entropy dynamics w.r.t different datasets/noise modes/noise ratios.", "description": "This figure visualizes the entropy dynamics for different datasets (CIFAR100-O and ImageNet-O), noise modes ('easy' and 'hard' open-set noise), and noise ratios.  It shows the distribution of prediction entropies at various training epochs (5th, 10th, 20th, 30th). The plots illustrate how the entropy of model predictions changes over the training process for different types of noise. The purpose is to empirically validate the theoretical analysis of entropy dynamics in open-set noise detection. ", "section": "4.2 Inspecting entropy-based open-set noise detection mechanism"}, {"figure_path": "ks0FrTSCnK/figures/figures_12_1.jpg", "caption": "Figure 4: Entropy dynamics w.r.t different datasets/noise modes/noise ratios.", "description": "The figure shows the entropy dynamics of different datasets (CIFAR100-O and ImageNet-O) with different noise modes ('easy' and 'hard' open-set noise) and noise ratios.  The entropy is calculated at different epochs during training (5th, 10th, 20th, and 30th), showing how the uncertainty of the model's predictions changes over time for clean samples, and samples with different types of noise. This visualization helps to understand the effectiveness of using entropy as a metric for open-set noise detection.", "section": "4.2 Inspecting entropy-based open-set noise detection mechanism"}, {"figure_path": "ks0FrTSCnK/figures/figures_18_1.jpg", "caption": "Figure 3: Direct supervised training with different noise modes/ratios. ", "description": "This figure visualizes the results of direct supervised training experiments on CIFAR100-O and ImageNet-O datasets with various noise types and ratios.  It shows the closed-set classification accuracy and open-set detection ROC AUC (Receiver Operating Characteristic Area Under the Curve) for different noise scenarios. The noise types include closed-set noise, easy open-set noise, and hard open-set noise. The results are presented separately for the \"fitted case\" (where the model perfectly fits the noisy distribution) and the \"memorized case\" (where the model completely memorizes the noisy labels).  The figure demonstrates the impact of different noise modes on both closed-set classification and open-set detection performance.", "section": "4.1 Empirical validation on previous probabilistic findings"}, {"figure_path": "ks0FrTSCnK/figures/figures_20_1.jpg", "caption": "Figure 1: Example images of class \"Tench\" from WebVision dataset. Clean samples are marked in extcolorgreenGreen, closed-set noise is marked in Blue and open-set noise is marked in Red. See appendix F for more details.", "description": "This figure shows example images of the class \"Tench\" from the WebVision dataset.  The images are categorized into three groups: clean samples (green), closed-set noise (blue), and open-set noise (red). The closed-set noise represents mislabeled samples where the incorrect label still belongs to one of the known classes, while open-set noise represents mislabeled samples where the true label does not belong to any of the known classes.  Appendix F provides more details on these classifications.", "section": "1 Introduction"}]