[{"figure_path": "bmoS6Ggw4j/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1 and Link-F1 in %) and Token Consumption in \u00d7103. Performance of other LLMs are given in Table 8.", "description": "This table compares the performance of four different training-free methods for task planning across five different datasets using various LLMs.  The methods compared are LLM's Direct Inference, Greedy Search, Adaptive Search, Beam Search, and the proposed SGC method.  The performance metrics used are Node F1-score and Link F1-score, which measure the accuracy of the tasks and their dependencies, respectively.  Token consumption is also presented as a measure of efficiency.  The table shows how the proposed SGC method generally outperforms the other baselines in terms of accuracy while using significantly fewer tokens.", "section": "5.2 Performance of the Training-free Approach"}, {"figure_path": "bmoS6Ggw4j/tables/tables_8_1.jpg", "caption": "Table 11: Performance of training-based GNNs. We also presents the results of BeamSeaerch, the strongest variant from GraphSearch method to provide a comprehensive comparison. All GNNs consistently enhance task planning performance across diverse LLMs, showing the effectiveness.", "description": "This table shows the performance of different graph neural networks (GNNs) for task planning, comparing them against the BeamSearch method which is a strong baseline from the GraphSearch approach.  The results are presented for several large language models (LLMs) across three datasets (HuggingFace, Multimedia, and Daily Life).  The table demonstrates the consistent improvement in task planning performance achieved by integrating GNNs with LLMs.", "section": "5.3 Performance of the Training-based Approaches"}, {"figure_path": "bmoS6Ggw4j/tables/tables_8_2.jpg", "caption": "Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1 and Link-F1 in %) and Token Consumption in \u00d7103. Performance of other LLMs are given in Table 8.", "description": "This table compares the performance of four different training-free methods for task planning across various LLMs and datasets.  The methods include LLM's direct inference, Greedy Search, Adaptive Search, BeamSearch, and the proposed SGC method. The table shows the Node F1-score, Link F1-score, and the number of tokens consumed for each method and LLM combination on HuggingFace, TaskBench Multimedia, Daily Life and RestBench datasets.  It highlights the performance gains achieved by the SGC method compared to the other baselines.", "section": "5.2 Performance of the Training-free Approach"}, {"figure_path": "bmoS6Ggw4j/tables/tables_20_1.jpg", "caption": "Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1 and Link-F1 in %) and Token Consumption in \u00d7103. Performance of other LLMs are given in Table 8.", "description": "This table compares the performance of three training-free methods for task planning: LLM's Direct Inference, GraphSearch (with three variants: GreedySearch, AdaptiveSearch, and BeamSearch), and the proposed SGC method.  The comparison is done across four datasets (HuggingFace, Multimedia, Daily Life, and RestBench) and several LLMs.  The table shows Node F1-score, Link F1-score, and token consumption for each method and dataset, providing a quantitative assessment of their relative effectiveness and efficiency.", "section": "5.2 Performance of the Training-free Approach"}, {"figure_path": "bmoS6Ggw4j/tables/tables_22_1.jpg", "caption": "Table 7: Statistics of Experimental Datasets", "description": "This table presents the statistics of four datasets used in the experiments, categorized by their source benchmark (TaskBench, RestBench, and UltraTool).  For each dataset, it provides the number of nodes and links in the task graph, the type of links (Resource, Temporal, or Resource/Category), the total number of samples, and the average number of nodes and links in the test set.  These statistics provide context for understanding the scale and characteristics of the experimental data used to evaluate the performance of the proposed task planning methods.", "section": "5.1 Experimental Setup"}, {"figure_path": "bmoS6Ggw4j/tables/tables_28_1.jpg", "caption": "Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1 and Link-F1 in %) and Token Consumption in \u00d7103. Performance of other LLMs are given in Table 8.", "description": "This table compares the performance of four different training-free methods for task planning across five different datasets and several LLMs.  The methods compared are Direct Inference (LLM only), Greedy Search, Adaptive Search, Beam Search, and a proposed method using Sparse Graph Convolutions (SGC).  The table shows Node F1-score, Link F1-score, and token consumption for each method, providing a quantitative comparison of their effectiveness and efficiency.", "section": "5.2 Performance of the Training-free Approach"}, {"figure_path": "bmoS6Ggw4j/tables/tables_28_2.jpg", "caption": "Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1 and Link-F1 in %) and Token Consumption in \u00d7103. Performance of other LLMs are given in Table 8.", "description": "This table compares the performance of four different training-free methods for task planning across five different LLMs and four datasets. The methods compared are: LLM's Direct Inference, Greedy Search, Adaptive Search, Beam Search, and SGC.  The performance metrics used are Node F1-score (n-F1) and Link F1-score (l-F1), which measure the accuracy of predicted tasks and their dependencies respectively. The table also shows the token consumption for each method, providing a measure of efficiency.  The performance of additional LLMs is detailed in Table 8.", "section": "5.2 Performance of the Training-free Approach"}, {"figure_path": "bmoS6Ggw4j/tables/tables_29_1.jpg", "caption": "Table 10: Computational Cost Analysis of Training-free Methods. Due to space constraints in the table, some LLMs are abbreviated such as \u201cGPT-3.5\u201d for \u201cGPT-3.5-turbo\u201d.", "description": "This table presents the inference time for different training-free methods across three datasets (HuggingFace, Multimedia, Daily Life).  The inference times are broken down by LLM and method (Direct, GreedySearch, AdaptiveSearch, BeamSearch, SGC).  The table highlights the significant speed advantage of the SGC method compared to others, especially the search-based methods (GreedySearch, AdaptiveSearch, BeamSearch).", "section": "E.4 Computational Cost Analysis"}, {"figure_path": "bmoS6Ggw4j/tables/tables_32_1.jpg", "caption": "Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1 and Link-F1 in %) and Token Consumption in \u00d7103. Performance of other LLMs are given in Table 8.", "description": "This table compares the performance of several training-free methods for task planning across different LLMs and datasets.  The methods compared include LLM's direct inference, GraphSearch (with three variants: GreedySearch, AdaptiveSearch, and BeamSearch), and the proposed SGC method.  The table reports Node F1-score, Link F1-score, and token consumption for each method and LLM on the HuggingFace, TaskBench (Multimedia, Daily Life), RestBench, and TMDB datasets.  It indicates that the proposed SGC method outperforms other training-free methods in terms of accuracy and efficiency.", "section": "5.2 Performance of the Training-free Approach"}, {"figure_path": "bmoS6Ggw4j/tables/tables_33_1.jpg", "caption": "Table 11: Performance of training-based GNNs. We also presents the results of BeamSeaerch, the strongest variant from GraphSearch method to provide a comprehensive comparison. All GNNs consistently enhance task planning performance across diverse LLMs, showing the effectiveness.", "description": "This table presents the performance of different Graph Neural Networks (GNNs) for task planning when integrated with various Large Language Models (LLMs). It compares the performance of GNNs against a strong baseline method called BeamSearch. The table shows that all GNNs consistently improve the performance of LLMs on task planning across different datasets and LLMs.", "section": "5.3 Performance of the Training-based Approaches"}, {"figure_path": "bmoS6Ggw4j/tables/tables_34_1.jpg", "caption": "Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1 and Link-F1 in %) and Token Consumption in \u00d7103. Performance of other LLMs are given in Table 8.", "description": "This table compares the performance of three training-free methods for task planning: LLM's Direct Inference, GraphSearch (with three variants: GreedySearch, AdaptiveSearch, and BeamSearch), and the proposed SGC method.  The comparison is done across multiple datasets (HuggingFace, TaskBench Multimedia, TaskBench Daily Life, RestBench, and TMDB) and uses several LLMs. The table shows the Node F1-score, Link F1-score, and the number of tokens consumed by each method for each LLM and dataset.  This allows for a direct comparison of performance and efficiency.", "section": "5.2 Performance of the Training-free Approach"}, {"figure_path": "bmoS6Ggw4j/tables/tables_35_1.jpg", "caption": "Table 14: Performance (in %) of Task Parameters Prediction on the HuggingFace dataset", "description": "This table presents the performance of different methods in predicting task parameters on the HuggingFace dataset.  It compares the accuracy of directly using LLMs for parameter prediction (Direct) against using LLMs after task selection with training-free SGC and training-required GraphSAGE.  The metrics used are Parameter-Type F1-Score (Param t-F1) and Parameter-Value F1-Score (Param v-F1), which assess the accuracy of predicted parameter types and values respectively.", "section": "G Experiments on Task Parameter Prediction"}]