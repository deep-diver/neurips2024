Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding