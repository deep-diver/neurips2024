[{"figure_path": "7rWTS2wuYX/tables/tables_5_1.jpg", "caption": "Table 1: FENS vs one-shot FL for various heterogeneity levels across datasets. The highest achieved accuracy is presented as bold and the top-performing baseline is underlined. The rightmost column presents the performance difference between FENS and the top-performing baseline.", "description": "This table compares the performance of the proposed FENS method against six state-of-the-art one-shot federated learning (OFL) baselines across three datasets (CIFAR-100, CIFAR-10, and SVHN) and three levels of data heterogeneity (\u03b1 = 0.01, 0.05, 0.1).  The table shows the test accuracy achieved by each method under different heterogeneity levels and highlights the superior performance of FENS compared to the other OFL methods. The last column shows the performance improvement of FENS over the best performing baseline for each setting.", "section": "3.2 FENS vs OFL"}, {"figure_path": "7rWTS2wuYX/tables/tables_9_1.jpg", "caption": "Table 3: Accuracy of FENS after distillation on the CIFAR-10 dataset.", "description": "This table presents the accuracy of the FENS model after applying knowledge distillation to reduce its size to a single model. It compares the performance of the original FENS model and the distilled version across different levels of data heterogeneity (\u03b1 = 0.01, 0.05, and 0.1) on the CIFAR-10 dataset. The results show a slight decrease in accuracy after distillation, which is a common observation in knowledge distillation tasks.  The table highlights the trade-off between model size and accuracy, demonstrating the potential for efficient inference after distillation.", "section": "3.7 Enhancing FENS efficiency"}, {"figure_path": "7rWTS2wuYX/tables/tables_9_2.jpg", "caption": "Table 4: FENS vs FEDADAM under similar memory footprint on CIFAR-10. DS stands for downsized.", "description": "This table compares the performance of FENS and FEDADAM on the CIFAR-10 dataset under similar memory footprints.  FENS and FEDADAM are both run with their original models and then with downsized (DS) models, where the model size is reduced to match that of FEDADAM. The table shows the accuracy for different levels of data heterogeneity (\u03b1 = 0.01, 0.05, 0.1) and the memory used (in MiB). This comparison aims to analyze how accuracy is affected when reducing the model size while maintaining a comparable memory usage.", "section": "3.7 Enhancing FENS efficiency"}, {"figure_path": "7rWTS2wuYX/tables/tables_14_1.jpg", "caption": "Table 5: Overview of selected datasets and tasks in FLamby. We defer additional details to [32].", "description": "This table presents an overview of the datasets and tasks used in the FLamby benchmark.  For each dataset (Fed-Camelyon16, Fed-Heart-Disease, and Fed-ISIC2019), it lists the input type, prediction target, task type (binary classification or multi-class classification), number of clients, number of examples per client, the model used for evaluation, and the evaluation metric (AUC or Balanced Accuracy).  More details about these datasets can be found in reference [32].", "section": "3.1 Experimental setup"}, {"figure_path": "7rWTS2wuYX/tables/tables_15_1.jpg", "caption": "Table 6: Best hyperparameters obtained for the different algorithms on the CIFAR-10 dataset.", "description": "This table presents the best hyperparameters found for six different federated learning algorithms (FEDAVG, FEDPROX, FEDYOGI, FEDADAM, FEDNOVA, and SCAFFOLD) on the CIFAR-10 dataset.  The hyperparameters were tuned separately for three different levels of data heterogeneity (\u03b1 = 0.01, 0.05, 0.1), reflecting the impact of data distribution on algorithm performance.  The table details the optimal learning rates (\u03b7l and \u03b7s) and the proximal parameter (\u03bc) used for each algorithm at each heterogeneity level.  The results are essential for comparing the algorithms and reproducing their results. ", "section": "B.2 Iterative FL baselines"}, {"figure_path": "7rWTS2wuYX/tables/tables_16_1.jpg", "caption": "Table 7: FEDKD under multi-round support on the CIFAR-10 dataset.", "description": "This table compares the performance of FEDKD (a one-shot federated learning method) under different settings against FENS (a novel federated ensembling scheme).  It shows the test accuracy (%) on the CIFAR-10 dataset for three different levels of data heterogeneity (\u03b1 = 0.01, 0.05, 0.1). The table includes results for FEDKD alone, FEDKD pre-trained with 3 rounds of FEDAVG, and FEDKD fine-tuned with 3 rounds of FEDAVG after initial training. It highlights the significant improvement achieved by FENS compared to all other versions of FEDKD under various heterogeneity conditions.", "section": "3.3 FENS vs Iterative FL"}, {"figure_path": "7rWTS2wuYX/tables/tables_16_2.jpg", "caption": "Table 8: Aggregator training in FENS. We use FEDADAM as the FL algorithm with the following client (\u03b7\u03b9) and server (\u03b7\u03c2) learning rates. The parameter k corresponds to the weight matrices W\u2081 and W\u2082.", "description": "This table presents the hyperparameters used for training the aggregator model in the FENS algorithm.  It specifies the aggregator model used (a multilayer perceptron or a per-client per-class weights model), the number of units in the hidden layer (k), the client and server learning rates (\u03b7\u03b9 and \u03b7s), the batch size, the number of local steps, and the number of global rounds for each dataset used in the experiments.", "section": "3.3 FENS vs Iterative FL"}, {"figure_path": "7rWTS2wuYX/tables/tables_18_1.jpg", "caption": "Table 1: FENS vs one-shot FL for various heterogeneity levels across datasets. The highest achieved accuracy is presented as bold and the top-performing baseline is underlined. The rightmost column presents the performance difference between FENS and the top-performing baseline.", "description": "This table compares the performance of FENS against several one-shot federated learning baselines across different datasets and heterogeneity levels.  It highlights the accuracy achieved by each method, identifying the best-performing baseline for each scenario. The final column quantifies the improvement of FENS over the best-performing baseline for each scenario, demonstrating the superior accuracy of FENS.", "section": "3.2 FENS vs OFL"}, {"figure_path": "7rWTS2wuYX/tables/tables_19_1.jpg", "caption": "Table 9: FENS aggregation methods on CIFAR-10. Results of Figure 8.", "description": "This table shows the performance of different aggregation methods used in the FENS model on the CIFAR-10 dataset with varying levels of data heterogeneity (alpha).  The methods compared include simple averaging, weighted averaging, polychotomous voting, a linear aggregator, a neural network (NN) aggregator, and a Mixture-of-Experts (MoE) approach. The results demonstrate the impact of different aggregation techniques on the final accuracy of the model.", "section": "3.6 Dissecting FENS"}, {"figure_path": "7rWTS2wuYX/tables/tables_19_2.jpg", "caption": "Table 10: FENS vs SOTA FL algorithms on the CIFAR-10 dataset.", "description": "This table compares the performance of FENS against six state-of-the-art iterative Federated Learning (FL) algorithms on the CIFAR-10 dataset.  The comparison is done across three different levels of data heterogeneity (\u03b1 = 0.01, 0.05, 0.1). Each entry in the table shows the average test accuracy (with standard deviation) achieved by each algorithm under the corresponding heterogeneity level. This table demonstrates FENS's ability to achieve comparable or better accuracy than existing iterative FL methods.", "section": "3.3 FENS vs Iterative FL"}, {"figure_path": "7rWTS2wuYX/tables/tables_19_3.jpg", "caption": "Table 1: FENS vs one-shot FL for various heterogeneity levels across datasets. The highest achieved accuracy is presented as bold and the top-performing baseline is underlined. The rightmost column presents the performance difference between FENS and the top-performing baseline.", "description": "This table compares the performance of the proposed FENS model against six different one-shot federated learning (FL) baselines across three datasets (CIFAR-100, CIFAR-10, and SVHN) and three levels of data heterogeneity (\u03b1 = 0.01, 0.05, 0.1).  The table highlights the accuracy achieved by each method, with the best accuracy for each scenario shown in bold.  The underlined baseline represents the best-performing one-shot method for each scenario.  The final column indicates the performance improvement or decrease of FENS compared to that best-performing one-shot baseline.", "section": "3.2 FENS vs OFL"}, {"figure_path": "7rWTS2wuYX/tables/tables_19_4.jpg", "caption": "Table 13: Figure 6 results. FENS vs. one-shot FL - Fed-Camelyon16 (row 2).", "description": "This table compares the AUC (Area Under the Curve) performance of different one-shot federated learning algorithms on the Fed-Camelyon16 dataset, a real-world dataset from the FLamby benchmark. The algorithms compared include FENS, FEDAVG-OS (one-shot FEDAVG), FEDPROX-OS (one-shot FEDPROX), and two individual clients' local model performances.  FENS significantly outperforms the other methods.", "section": "3.4 Performance on real-world datasets"}, {"figure_path": "7rWTS2wuYX/tables/tables_19_5.jpg", "caption": "Table 12: Figure 6 results. FENS vs. iterative FL - Fed-Camelyon16 (row 1).", "description": "This table presents a comparison of the AUC (Area Under the Curve) achieved by FENS and several iterative Federated Learning (FL) algorithms on the Fed-Camelyon16 dataset from the FLamby benchmark.  The table shows the performance for different levels of data heterogeneity (\u03b1).  The results highlight FENS's superior performance compared to other iterative FL methods.", "section": "3.4 Performance on real-world datasets"}, {"figure_path": "7rWTS2wuYX/tables/tables_20_1.jpg", "caption": "Table 14: Figure 6 results. FENS vs. iterative FL \u2013 Fed-Heart-Disease (row 1).", "description": "This table compares the accuracy of FENS against six iterative federated learning algorithms on the Fed-Heart-Disease dataset from the FLamby benchmark.  The table shows the accuracy (with standard deviation) achieved by each algorithm, highlighting the relative performance of FENS compared to state-of-the-art iterative FL methods.", "section": "3.4 Performance on real-world datasets"}, {"figure_path": "7rWTS2wuYX/tables/tables_20_2.jpg", "caption": "Table 15: Figure 6 results. FENS vs. one-shot FL - Fed-Heart-Disease (row 2).", "description": "This table presents a comparison of the performance (Balanced Accuracy) of FENS against one-shot federated learning (FL) baselines (FEDAVG-OS and FEDPROX-OS) and individual client models for the Fed-Heart-Disease dataset.  The results showcase FENS's superior performance in this real-world cross-silo FLamby benchmark setting, outperforming both other one-shot methods and the individual local client models.", "section": "3.4 Performance on real-world datasets"}, {"figure_path": "7rWTS2wuYX/tables/tables_20_3.jpg", "caption": "Table 17: Figure 6 results. FENS vs. one-shot FL - Fed-ISIC2019 (row 2).", "description": "This table presents a comparison of the balanced accuracy achieved by different algorithms on the Fed-ISIC2019 dataset from the FLamby benchmark.  It specifically shows the results for the one-shot federated learning (OFL) setting, contrasting the performance of FENS against several baselines, including FEDAVG (Federated Averaging), FEDPROX (Federated Proximal), FEDYOGI (Federated Yogi), and SCAFFOLD.  The results are broken down by client, highlighting performance differences among individual clients for each method. This allows for an assessment of how different OFL approaches perform under real-world heterogeneous data conditions. The table supports the claim made in the paper that FENS remains superior in one-shot settings even when compared against more sophisticated iterative FL algorithms.", "section": "3.4 Performance on real-world datasets"}, {"figure_path": "7rWTS2wuYX/tables/tables_20_4.jpg", "caption": "Table 17: Figure 6 results. FENS vs. one-shot FL - Fed-ISIC2019 (row 2).", "description": "This table presents a comparison of the balanced accuracy achieved by different algorithms on the Fed-ISIC2019 dataset from the FLamby benchmark.  It specifically focuses on one-shot federated learning (OFL) methods. The algorithms compared include client-level local models (Client 0 through Client 5), FEDAVG-OS, FEDPROX-OS, and the proposed FENS algorithm. The results highlight the superior performance of FENS compared to the other one-shot methods, indicating its effectiveness in real-world heterogeneous settings.", "section": "3.4 Performance on real-world datasets"}]