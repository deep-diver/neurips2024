[{"figure_path": "wz2KvvEk44/figures/figures_2_1.jpg", "caption": "Figure 1: Architecture of SMG. One-way arrows represent different types of data flows with the same input. Two-way arrows represent different types of loss.", "description": "This figure illustrates the architecture of the Separated Models for Generalization (SMG) method.  Panel (a) shows how SMG learns task-relevant representations by separating foreground and background information from raw visual observations using two separate model branches.  Each branch has its own reconstruction path, resulting in foreground and background reconstruction losses. Panel (b) demonstrates how SMG improves generalization using two consistency losses: foreground consistency loss and Q-value consistency loss. These losses guide the agent's focus toward task-relevant areas, improving its ability to generalize to unseen environments.  The figure uses arrows to visually represent the flow of data and the types of losses involved in the process. ", "section": "3 Approach"}, {"figure_path": "wz2KvvEk44/figures/figures_2_2.jpg", "caption": "Figure 2: A robotic manipulation task explanation for task-relevant parts in the environment.", "description": "This figure illustrates a robotic manipulation task where the goal is to move the robot arm to a red target.  The left side shows four different scenarios with variations in background colors and textures. Despite these variations, the key aspects for the robot to focus on remain consistent: the arm's orientation and the target's position. This highlights the concept of task-relevant features \u2013 information essential for successful task completion, which should be prioritized by the RL agent. The right-hand side of the figure uses a simplified, black-background view to clearly show which parts of the scene are \u2018Control Relevant\u2019 (directly affected by agent actions) and \u2018Reward Relevant\u2019 (associated with the reward signal).", "section": "3.1 What Matters in a Reinforcement Learning Task?"}, {"figure_path": "wz2KvvEk44/figures/figures_4_1.jpg", "caption": "Figure 3: Two types of data augmentations using in SMG.", "description": "This figure shows two types of data augmentations used in the Separated Models for Generalization (SMG) method. (a) shows an overlay augmentation where a random image is overlaid onto the original observation, simulating the video background setting. (b) shows an attribution augmentation, where the background is randomly augmented according to the mask generated by the model, allowing the model to focus on the task-relevant areas.", "section": "3.2.2 Additional Loss Terms"}, {"figure_path": "wz2KvvEk44/figures/figures_5_1.jpg", "caption": "Figure 4: Visualizing the reconstruction process of SMG in different tasks (from top to bottom: walker-walk, cheetah-run, peg in box).", "description": "This figure visualizes the reconstruction process of the Separated Models for Generalization (SMG) method in three different tasks from the DMControl suite: walker-walk, cheetah-run, and peg-in-box.  For each task, it shows the training observation, the evaluation observation (under a color-hard or video-hard setting), the predicted mask, the reconstructed background, the attribution (the area the agent focuses on), and the final reconstruction. The figure demonstrates how SMG disentangles foreground (task-relevant) and background (task-irrelevant) information, allowing it to generalize better to unseen environments.  The color-hard settings change the colors of the environments, and the video-hard settings replace the backgrounds with random videos.", "section": "4.2 DMControl Results"}, {"figure_path": "wz2KvvEk44/figures/figures_5_2.jpg", "caption": "Figure 5: Example of training and testing observation for DMC-GB (walker-walk). (a) is the training observation. (b-c) indicates different degrees of color change; (d-e) replaces the background with random videos, with (e) additionally removing the floor and the walker's shadow.", "description": "This figure shows examples of the walker-walk task from the DMControl benchmark used to evaluate generalization performance.  It demonstrates the different levels of visual changes applied to the environment during testing, progressing from subtle color alterations (Color-easy, Color-hard) to complete background video replacements and removal of context cues (Video-easy, Video-hard). The training observation is presented for comparison.", "section": "4.2 DMControl Results"}, {"figure_path": "wz2KvvEk44/figures/figures_6_1.jpg", "caption": "Figure 6: Examples of training and testing observation for the robotic environment (Peg-in-box). (b-f) indicates five different evaluation settings varying in background colors and table textures.", "description": "This figure shows six images of a robotic manipulation task. The top row shows the training images for the Peg-in-box task, and the bottom row shows five different testing images where the background colors and table textures vary.  These variations represent different unseen scenarios to evaluate the generalization capability of the proposed reinforcement learning model.", "section": "4.3 Robotic Manipulation Results"}, {"figure_path": "wz2KvvEk44/figures/figures_8_1.jpg", "caption": "Figure 7: Predicted masks and corresponding attribution augmentations. (a) is the full model, (b) and (c) are the models without Lmask and Lmask respectively.", "description": "This figure visualizes the effect of removing the mask ratio loss (Lmask) and the background reconstruction loss (Lback) from the SMG model.  The leftmost image (a) shows the results from the complete SMG model, where a mask is accurately generated to isolate the relevant foreground (the walking figure) from the background.  The middle image (b) shows the result when Lmask is removed; the mask is nearly all white, indicating that the model fails to differentiate the foreground from the background resulting in poor attribution augmentation. The rightmost image (c) displays the results without Lback; this demonstrates that the background is overly reconstructed and contains foreground features, again leading to a poor attribution augmentation. These results highlight the importance of both loss terms in improving model performance.", "section": "3.2 Learning Task-Relevant Representations with Separated Models"}, {"figure_path": "wz2KvvEk44/figures/figures_13_1.jpg", "caption": "Figure 1: Architecture of SMG. One-way arrows represent different types of data flows with the same input. Two-way arrows represent different types of loss.", "description": "This figure shows the architecture of the Separated Models for Generalization (SMG) method.  It illustrates two main parts. The first part (a) shows how SMG learns task-relevant representations from visual observations using two separate model branches for foreground and background, employing a cooperative reconstruction approach. This avoids overfitting to task-irrelevant features.  The second part (b) demonstrates how SMG improves generalization by incorporating foreground and Q-value consistency losses to guide the agent's attention to task-relevant features across varying scenarios.", "section": "3 Approach"}, {"figure_path": "wz2KvvEk44/figures/figures_14_1.jpg", "caption": "Figure 8: SMG network architecture (foreground encoder + foreground decoder).", "description": "This figure shows the architecture of the Separated Models for Generalization (SMG) network.  The input is a stack of three consecutive frames (9x84x84). The encoder consists of convolutional layers to extract features, followed by a fully connected layer and embedding. The embedding is then split to feed three decoder branches. Each branch mirrors the encoder to reconstruct one of the three input frames.  The foreground decoder produces the reconstructed foreground image and an attention mask, and the background decoder reconstructs the background.  These components are crucial for learning task-relevant visual representations.", "section": "3.2 Learning Task-Relevant Representations with Separated Models"}, {"figure_path": "wz2KvvEk44/figures/figures_18_1.jpg", "caption": "Figure 10: Masks, attributions, and corresponding attribution augmentation images in different training stages.", "description": "This figure visualizes the evolution of the model's ability to generate masks and attribution augmentations during training.  It demonstrates how, in the early stages, the masks are inaccurate and the augmentations are less effective. As training progresses, the masks become increasingly accurate, the augmentations reflect a better focus on task-relevant areas, and the model's performance improves.", "section": "More Discussion"}, {"figure_path": "wz2KvvEk44/figures/figures_19_1.jpg", "caption": "Figure 11: Training curves for all seven tasks. We evaluate each seed three times and then calculate the mean episode return for every 10k training steps, and the variance is shown as the shaded area by calculating four random seeds.", "description": "This figure shows the training curves for seven different reinforcement learning tasks across various evaluation settings.  Each curve represents the average episode return over multiple runs, with shaded areas indicating variance.  The x-axis represents the number of training frames (in units of 10,000), and the y-axis shows the episode return.  The results show that SMG consistently outperforms other algorithms, particularly in more challenging video-background settings.", "section": "4 Experimental Results"}]