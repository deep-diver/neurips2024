[{"figure_path": "ASv9lQcHCc/figures/figures_1_1.jpg", "caption": "Figure 1: (a) 'Gap between Spot. & Det.': the gap between spotting and detection F1-score. As the spotting task involves recognizing the results of the detection process, the detection score is indeed the upper bound of spotting performance. The larger the gap, the poorer the recognition ability. Compared to the ITS model (Deepsolo [5]), the VTS model (TransDETR [12]) presents unsatisfactory image-level text spotting F1-scores, which lag far behind its detection performance, especially on ArTVideo with curved text. It indicates recognition capability is a main bottleneck in the VTS model. (b) GoMatching outperforms TransDETR by over 12 MOTA on ICDAR15-video while saving 197 training GPU hours and 10.8GB memory. Notice that since the pre-training strategies and settings vary between TransDETR and GoMatching, the comparison is focused on the fine-tuning stage.", "description": "This figure shows a comparison of the performance of GoMatching and TransDETR on two video text spotting datasets: ICDAR15-video and ArTVideo.  Subfigure (a) presents bar charts comparing image-level spotting F1-scores and the gap between spotting and detection F1-scores for both a state-of-the-art Video Text Spotter (VTS) model (TransDETR) and a state-of-the-art Image Text Spotter (ITS) model (Deepsolo) to highlight that the main limitation of current VTS methods is poor recognition. Subfigure (b) shows a comparison of the MOTA scores, GPU memory usage, and GPU training time for GoMatching and TransDETR on the ICDAR15-video dataset.  GoMatching shows significant performance improvements with substantially reduced computational costs.", "section": "1 Introduction"}, {"figure_path": "ASv9lQcHCc/figures/figures_3_1.jpg", "caption": "Figure 2: The overall architecture of GoMatching. The frozen image text spotter provides text spotting results for frames. The rescoring mechanism considers both instance scores from the image text spotter and a trainable rescoring head to reduce performance degradation due to the domain gap. Long-short term matching module (LST-Matcher) assigns IDs to text instances based on the queries in long-short term frames. The yellow star sign \u2018\u2605\u2019 indicates the final output of GoMatching.", "description": "The figure illustrates the architecture of GoMatching, a video text spotting method. It comprises three main components: a frozen image text spotter (DeepSolo), a rescoring head, and a Long-Short Term Matching (LST-Matcher) module. The image text spotter initially processes each frame to detect and recognize text instances; a rescoring head then refines the confidence scores to improve the accuracy of text detection in video context. Finally, LST-Matcher, incorporating both short-term and long-term information, links text instances across consecutive frames to generate complete text trajectories. The overall process aims at mitigating performance degradation between image and video domains while ensuring robust text tracking.", "section": "3 Methodology"}, {"figure_path": "ASv9lQcHCc/figures/figures_3_2.jpg", "caption": "Figure 3: The inference pipeline of LST-Matcher, which is a two-stage association process: (1) ST-Matcher associates the instances with trajectories in previous frames as denoted by blue lines. (2) LT-Matcher associates the remaining unmatched instances by utilizing other trajectories in history frames as denoted by red lines.", "description": "This figure illustrates the two-stage association process within the Long-Short Term Matching (LST-Matcher) module.  The first stage, using the Short Term Matcher (ST-Matcher), links current text instances to trajectories from the immediately preceding frame. The second stage, employing the Long Term Matcher (LT-Matcher), handles instances not successfully matched in the first stage, using trajectories from further back in the video's history to account for occlusions or significant appearance changes. The blue lines represent associations made by the ST-Matcher, while red lines show those made by the LT-Matcher. This ensures robust tracking across multiple frames by leveraging both short-term and long-term context.", "section": "3.3 Long-Short Term Matching Module"}, {"figure_path": "ASv9lQcHCc/figures/figures_8_1.jpg", "caption": "Figure 4: Visual results of video text spotting. Images from top to bottom are the results on ICDAR15-video, BOVText, DSText, and ArTVideo, respectively. Text instances belonging to the same trajectory are assigned the same color.", "description": "This figure shows visual examples of video text spotting results obtained using the proposed GoMatching method.  It presents results on four different datasets: ICDAR15-video, BOVText, DSText, and ArTVideo. Each row corresponds to a dataset, displaying several video frames with detected text instances.  Text instances belonging to the same trajectory (tracked across frames) share the same color, illustrating the tracking capabilities of the method. The figure visually demonstrates the effectiveness of GoMatching in various scenarios including different video characteristics and text complexities.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/figures/figures_9_1.jpg", "caption": "Figure 5: Visualization results of ST-Matcher and LST-Matcher. The first row shows the failure case that suffers from the ID switches issue when using only ST-Matcher, caused by missed detection and erroneous matching. The second row shows that LST-Matcher effectively mitigates this issue via both long and short term matching. Text instances in the same color represent the same IDs.", "description": "This figure compares the tracking performance of ST-Matcher (short-term matching) and LST-Matcher (long and short-term matching). The top row illustrates a failure case where ST-Matcher leads to ID switches due to missed detections and incorrect associations. The bottom row shows how LST-Matcher effectively addresses this issue by incorporating both short-term and long-term information to maintain consistent tracking of text instances.", "section": "4.4 Ablation Studies"}, {"figure_path": "ASv9lQcHCc/figures/figures_13_1.jpg", "caption": "Figure 6: Visual examples from our ArTVideo. The straight and curved text are labeled with quadrilaterals and polygons, respectively. The same background color in different frames (columns) denotes the same instance.", "description": "This figure shows visual examples from the ArTVideo dataset, highlighting the annotation differences between straight and curved text.  Straight text is annotated using bounding boxes (quadrilaterals), while curved text is annotated with polygons.  The consistent color coding across columns helps to visually track the same text instances through time.", "section": "4.1 Datasets and Evaluation Metrics"}, {"figure_path": "ASv9lQcHCc/figures/figures_13_2.jpg", "caption": "Figure 4: Visual results of video text spotting. Images from top to bottom are the results on ICDAR15-video, BOVText, DSText, and ArTVideo, respectively. Text instances belonging to the same trajectory are assigned the same color.", "description": "This figure showcases the video text spotting results of the GoMatching model on four different datasets: ICDAR15-video, BOVText, DSText, and ArTVideo. Each row displays results from one dataset.  Within each row, multiple images from a video clip are shown with bounding boxes around detected text instances.  The color of the bounding boxes indicates the same text trajectory across consecutive frames. This helps visualize the accuracy of the model's ability to track and recognize text instances over time.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/figures/figures_15_1.jpg", "caption": "Figure 4: Visual results of video text spotting. Images from top to bottom are the results on ICDAR15-video, BOVText, DSText, and ArTVideo, respectively. Text instances belonging to the same trajectory are assigned the same color.", "description": "This figure showcases the video text spotting results of GoMatching on four different datasets: ICDAR15-video, BOVText, DSText, and ArTVideo. Each row presents the results from one dataset, showing the detected text instances with bounding boxes.  Text instances belonging to the same trajectory across multiple frames are assigned the same color for easy visualization and tracking. The figure demonstrates GoMatching's ability to accurately detect and track text in various scenarios, including those with arbitrary-shaped texts.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/figures/figures_16_1.jpg", "caption": "Figure 4: Visual results of video text spotting. Images from top to bottom are the results on ICDAR15-video, BOVText, DSText, and ArTVideo, respectively. Text instances belonging to the same trajectory are assigned the same color.", "description": "This figure displays the visual results of video text spotting using the GoMatching method on four different datasets: ICDAR15-video, BOVText, DSText, and ArTVideo. Each row presents the results for a specific dataset, showing how the algorithm accurately identifies and tracks text instances across video frames.  Text instances belonging to the same trajectory are highlighted with the same color to help visualize the tracking process.  This is a qualitative assessment demonstrating the effectiveness of the algorithm in handling various text characteristics and scenarios.", "section": "4.3 Comparison with State-of-the-art Methods"}]