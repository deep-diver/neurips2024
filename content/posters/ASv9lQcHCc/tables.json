[{"figure_path": "ASv9lQcHCc/tables/tables_7_1.jpg", "caption": "Table 1: Comparison results with SOTA methods on four distinct datasets. \u2018\u2020\u2019 denotes that the results are collected from the official competition website. \u2018*\u2019: we use the officially released model for evaluation. \u2018M-ME\u2019 indicates whether multi-model ensembling is used. \u2018Y\u2019 and \u2018N\u2019 stand for yes and no. The best and second-best results are marked in bold and underlined, respectively.", "description": "This table compares the performance of GoMatching against other state-of-the-art (SOTA) methods on four different video text spotting datasets: ICDAR15-video, BOVText, DSText, and ArTVideo.  The metrics used for comparison are MOTA (Multiple Object Tracking Accuracy), MOTP (Multiple Object Tracking Precision), and IDF1 (Intersection over Union F1-score).  The table also indicates whether each method used multi-model ensembling and whether the officially released model was used for evaluation.  The best results for each dataset are highlighted in bold.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_7_2.jpg", "caption": "Table 1: Comparison results with SOTA methods on four distinct datasets. '\u2020' denotes that the results are collected from the official competition website. \u2018*': we use the officially released model for evaluation. 'M-ME' indicates whether multi-model ensembling is used. 'Y' and 'N' stand for yes and no. The best and second-best results are marked in bold and underlined, respectively.", "description": "This table presents a comparison of the proposed GoMatching method against state-of-the-art (SOTA) methods on four different video text spotting datasets: ICDAR15-video, BOVText, DSText, and ArTVideo.  The comparison uses three evaluation metrics: MOTA, MOTP, and IDF1, providing a comprehensive assessment of each method's performance on various scenarios and text characteristics.  The table also indicates whether SOTA methods utilized multi-model ensembling and whether the results were obtained from official competition leaderboards or by using officially released models.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_7_3.jpg", "caption": "Table 1: Comparison results with SOTA methods on four distinct datasets. '\u2020' denotes that the results are collected from the official competition website. \u2018*': we use the officially released model for evaluation. 'M-ME' indicates whether multi-model ensembling is used. 'Y' and 'N' stand for yes and no. The best and second-best results are marked in bold and underlined, respectively.", "description": "This table compares the performance of GoMatching against other state-of-the-art (SOTA) video text spotting methods on four benchmark datasets: ICDAR15-video, BOVText, DSText, and ArTVideo.  The metrics used for comparison are MOTA (Multiple Object Tracking Accuracy), MOTP (Multiple Object Tracking Precision), and IDF1 (Intersection over Union F1-score).  The table also indicates whether each method used multiple model ensembling (M-ME) and whether the official released model was used for evaluation.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_7_4.jpg", "caption": "Table 1: Comparison results with SOTA methods on four distinct datasets. '\u2020' denotes that the results are collected from the official competition website. \u2018*': we use the officially released model for evaluation. 'M-ME' indicates whether multi-model ensembling is used. 'Y' and 'N' stand for yes and no. The best and second-best results are marked in bold and underlined, respectively.", "description": "This table compares the performance of GoMatching against other state-of-the-art (SOTA) methods on four video text spotting datasets: ICDAR15-video, BOVText, DSText, and ArTVideo.  For each dataset, it presents the MOTA, MOTP, and IDF1 scores, key metrics for evaluating video text spotting performance.  The table also notes whether the competing methods used multiple models, and whether the results were obtained from official competitions or using the officially released model weights.  The best and second-best results for each metric are highlighted.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_8_1.jpg", "caption": "Table 2: Impact of difference components in the proposed GoMatching. 'Query' indicates that LST-Matcher employs the queries of high-score text instances for association, otherwise RoI features. Column 'Scoring' indicates the employed scoring mechanism, in which \u2018O' means using the original scores from DeepSolo, 'R' means using the scores recomputed by the rescoring head, and 'F' means using the fusion scores obtained from the rescoring mechanism.", "description": "This table presents the ablation study results, showing the impact of different components of the GoMatching model on its performance.  It shows how using queries instead of RoI features, different scoring mechanisms (original DeepSolo scores, rescored scores, fused scores), and different combinations of the Long-Term Matcher and Short-Term Matcher impact MOTA, MOTP, and IDF1 scores.  This helps assess the contribution of each component.", "section": "4.4 Ablation Studies"}, {"figure_path": "ASv9lQcHCc/tables/tables_9_1.jpg", "caption": "Table 3: Results of GoMatching under various training settings on the ICDAR15-video dataset. 'Only Image Spotter' and 'Only Tracker' refer to fine-tuning either the image spotter or tracker with another module fixed. 'End-to-End' denotes that training the image spotter and tracker in an end-to-end manner. '0.001', \u20180.01' and '0.1' correspond to the ratios of the learning rate employed by the decoder of the image text spotter relative to the base learning rate. Due to constraints in training resources, we only optimize the parameters of the decoder component for the image text spotter.", "description": "This table presents an ablation study on different training strategies for GoMatching on the ICDAR15-video dataset.  It compares the performance (MOTA, MOTP, IDF1) of three approaches: training only the tracker, pre-training the image spotter then training the tracker, and end-to-end training of both.  The end-to-end training explores different learning rates for the decoder of the image spotter. The results highlight the impact of various training strategies on the model's performance.", "section": "4.4 Ablation Studies"}, {"figure_path": "ASv9lQcHCc/tables/tables_14_1.jpg", "caption": "Table 4: Ablation studies on the number of frames (T) for long-term association in LT-Matcher, and the max number of history frames in tracking memory bank is H = T \u2013 1). Experiments are conducted on ICDAR15-video and the best results are marked in bold.", "description": "This table presents the results of ablation studies performed on the ICDAR15-video dataset to determine the optimal number of frames (T) to consider for long-term associations in the LT-Matcher component of the GoMatching model.  The max number of history frames in the tracking memory bank is always one less than T (H = T-1).  The table shows the impact of varying the frame number (T) on three key evaluation metrics: MOTA, MOTP, and IDF1. The best-performing value of T for each metric is highlighted in bold.", "section": "4.4 Ablation Studies"}, {"figure_path": "ASv9lQcHCc/tables/tables_14_2.jpg", "caption": "Table 1: Comparison results with SOTA methods on four distinct datasets. '\u2020' denotes that the results are collected from the official competition website. \u2018*': we use the officially released model for evaluation. 'M-ME' indicates whether multi-model ensembling is used. 'Y' and 'N' stand for yes and no. The best and second-best results are marked in bold and underlined, respectively.", "description": "This table compares the performance of GoMatching against state-of-the-art (SOTA) methods on four video text spotting datasets: ICDAR15-video, BOVText, DSText, and ArTVideo.  It shows the MOTA, MOTP, and IDF1 scores for each method, indicating the accuracy and efficiency of text spotting. The table also notes whether methods used multi-model ensembles and whether the models used were officially released models or not.  It highlights the superior performance of GoMatching in achieving new state-of-the-art results.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_14_3.jpg", "caption": "Table 5: Results of different score fusion strategies on ICDAR5-video. \u2018Mean\u2019, \u2018Geo-mean\u2019, and \u2018Maximum\u2019 denote the arithmetic mean, geometric mean, and the maximum score fusion strategies, respectively. The best results are highlighted in bold.", "description": "This table presents the results of three different score fusion strategies used in the rescoring mechanism of GoMatching on the ICDAR15-video dataset.  The strategies compared are the arithmetic mean, the geometric mean, and selecting the maximum score.  The table shows the resulting MOTA, MOTP, and IDF1 scores for each strategy. The best performing strategy for each metric is highlighted in bold.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_14_4.jpg", "caption": "Table 1: Comparison results with SOTA methods on four distinct datasets. \u2018\u2020\u2019 denotes that the results are collected from the official competition website. \u2018*\u2019: we use the officially released model for evaluation. \u2018M-ME\u2019 indicates whether multi-model ensembling is used. \u2018Y\u2019 and \u2018N\u2019 stand for yes and no. The best and second-best results are marked in bold and underlined, respectively.", "description": "This table presents a comparison of the proposed GoMatching method with state-of-the-art (SOTA) methods on four video text spotting datasets: ICDAR15-video, BOVText, DSText, and ArTVideo.  The table displays the performance metrics (MOTA, MOTP, and IDF1) achieved by each method on each dataset. It also indicates whether the method used multi-model ensembling and whether the official model was used for evaluation. The best and second-best results for each metric are highlighted.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_15_1.jpg", "caption": "Table 8: Video text detection performance on ICDAR2013-video [41]. The best results are highlighted in bold.", "description": "This table presents a comparison of video text detection performance on the ICDAR2013-video dataset.  Three methods are compared: Free, TransDETR, and GoMatching (with and without the rescoring mechanism). The results are given in terms of precision, recall, and F-measure. GoMatching achieves the best F-measure, highlighting its effectiveness in video text detection.", "section": "4.3 Comparison with State-of-the-art Methods"}, {"figure_path": "ASv9lQcHCc/tables/tables_15_2.jpg", "caption": "Table 9: Comparison results of detection AP on the ICDAR13-video between with and without the rescoring mechanism.", "description": "This table compares the Average Precision (AP) of object detection on the ICDAR13-video dataset with and without the rescoring mechanism.  The rescoring mechanism improves the overall AP, particularly for smaller objects (APs) and medium-sized objects (APm). This highlights the benefits of the rescoring mechanism in improving detection performance.", "section": "4.4 Ablation Studies"}]