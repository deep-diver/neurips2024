[{"figure_path": "Wl2optQcng/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of pFedFDA. (Left) Heterogeneous clients collaboratively train representation parameters under a generative classifier derived from a global estimate of class feature distributions. (Right) At test time, clients adapt the generative classifier to their feature distributions to obtain personalized classifiers.", "description": "This figure illustrates the two main stages of the pFedFDA algorithm.  The left panel shows the global representation learning phase where heterogeneous clients collaboratively train representation parameters using a generative classifier based on a global estimate of class feature distributions. The right panel depicts the local distribution adaptation, where, at test time, each client adapts the global generative classifier to its own local feature distribution to generate personalized classifiers. The visual representation effectively shows how the global model is adapted to the unique characteristics of individual clients.", "section": "Methodology"}, {"figure_path": "Wl2optQcng/figures/figures_9_1.jpg", "caption": "Figure 2: Comparison of client \u03b2 and local dataset corruption on CIFAR10-S.", "description": "This figure shows the average learned beta (\u03b2) values across clients in the CIFAR10-S dataset with different types of corruptions. Each bar represents a specific corruption type applied to the client's training data, and the height of the bar indicates the average \u03b2 value. Error bars show standard deviation. The x-axis shows the various corruption types applied to the client datasets, and the y-axis shows the learned \u03b2 values.  The results suggest that the severity of corruption is correlated with the \u03b2 value, showing higher \u03b2 values where more severe corruptions were present. In simpler terms, this graph displays how the model adjusts (\u03b2) to the presence of different levels of corruption or noise in the data.", "section": "5.3 Ablation of Method Components"}, {"figure_path": "Wl2optQcng/figures/figures_15_1.jpg", "caption": "Figure 1: Overview of pFedFDA. (Left) Heterogeneous clients collaboratively train representation parameters under a generative classifier derived from a global estimate of class feature distributions. (Right) At test time, clients adapt the generative classifier to their feature distributions to obtain personalized classifiers.", "description": "This figure illustrates the two main stages of the pFedFDA algorithm.  The left panel shows the global representation learning phase, where heterogeneous clients collaborate to train shared representation parameters using a generative classifier based on a global feature distribution estimate. The right panel depicts the local distribution adaptation phase, where each client adapts the global generative classifier to its local feature distribution to produce personalized classifiers.", "section": "Methodology"}, {"figure_path": "Wl2optQcng/figures/figures_16_1.jpg", "caption": "Figure 4: Comparison of average test accuracy with varying local epochs on CIFAR100.", "description": "The figure shows the average test accuracy of FedAvgFT and pFedFDA on CIFAR100 and CIFAR100-S (with 25% of the training data) for different numbers of local epochs.  It illustrates how the performance of both methods changes as the number of local training epochs increases.  pFedFDA generally outperforms FedAvgFT, particularly with fewer local epochs, indicating its faster convergence and higher accuracy.", "section": "5.2 Numerical Results"}]