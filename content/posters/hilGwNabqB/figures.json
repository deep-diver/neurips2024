[{"figure_path": "hilGwNabqB/figures/figures_8_1.jpg", "caption": "Figure 1: Performance comparison of our method with baselines under different types and varying degree of heterogeneity for CIFAR-10 dataset with 20 clients. Figure (a) is for heterogeneity in compute capacity across clients under non-IID data setting, figure (b) for compute heterogeneity under IID setting, and figure (c) for heterogeneity in data resources. When a fraction of clients in the setting have low computing resources, the baselines being homogeneous can only train smaller models on all the clients as shown by constant performance. The results show that our method is more tolerant to both model heterogeneity and data heterogeneity across clients.", "description": "This figure compares the performance of the proposed method (FedBNN) against several baselines under various types of heterogeneity in an federated learning setting using the CIFAR-10 dataset.  Three scenarios are presented: (a) heterogeneity in clients' computational resources (non-IID data); (b) heterogeneity in clients' computational resources (IID data); and (c) heterogeneity in the amount of data available to each client (non-IID data). The results demonstrate that FedBNN outperforms the baselines, particularly when clients have varying computational capabilities or data amounts, showcasing its robustness to heterogeneity.", "section": "5 Experiments"}, {"figure_path": "hilGwNabqB/figures/figures_16_1.jpg", "caption": "Figure 2: A schematic overview of our method: Local BNN on each client obtain a posterior distribution over local parameters using the prior distribution and local data. These local models generate outputs on the AD using their respective posterior distributions and share these outputs with the server. The server aggregates these outputs and distributes the aggregated output on the AD back to all clients, guiding the prior distribution on each client. These updated prior distributions then further guide the learning of the posterior distributions.", "description": "This figure shows a schematic overview of the FedBNN method. Each client trains a Bayesian neural network (BNN) using its local data and a prior distribution. The clients then use their trained BNNs to generate outputs on an alignment dataset (AD). The server aggregates these outputs and sends the aggregated output back to the clients. The clients use this aggregated output to update their prior distributions, which are then used to further train their BNNs. This process is iterated until convergence.", "section": "3.2 FedBNN Methodology"}, {"figure_path": "hilGwNabqB/figures/figures_18_1.jpg", "caption": "Figure 3: Reliability diagrams and scores showing model calibration. Figure (a) is for the results corresponding to the CIFAR-10 dataset and Figure (b) for MNIST dataset.", "description": "This figure shows the reliability diagrams for CIFAR-10 and MNIST datasets.  A reliability diagram plots the accuracy of a model against its confidence.  A perfectly calibrated model would show a diagonal line. Deviations from this line indicate miscalibration.  The figure also provides the Expected Calibration Error (ECE) and Maximum Calibration Error (MCE) which are numerical metrics that quantify the deviation from perfect calibration.  Lower values of ECE and MCE indicate better calibration.", "section": "D Uncertainty Quantification and Calibration"}, {"figure_path": "hilGwNabqB/figures/figures_19_1.jpg", "caption": "Figure 4: Distribution of the entropy of class-probability distributions across different clients demonstrating the confidence of methods in predicting on in-distribution vs out-of-distribution data.", "description": "This figure shows the distribution of entropy of class probability distributions across different clients.  The entropy measures the uncertainty of the model's predictions. Lower entropy indicates higher confidence. The figure compares in-distribution (MNIST test set) and out-of-distribution (NotMNIST10) data. The Bayesian approach (FedBNN) shows significantly higher entropy for out-of-distribution data, indicating better uncertainty awareness compared to the non-Bayesian approach (FedAvg) which shows low entropy for both in-distribution and out-of-distribution data, suggesting overconfidence in out-of-distribution predictions.", "section": "D Uncertainty Quantification and Calibration"}, {"figure_path": "hilGwNabqB/figures/figures_19_2.jpg", "caption": "Figure 5: Ablation study comparing the affect of AD size on the performance. The included results are for CIFAR-10 dataset in the small data setting with non-IID partitions and heterogeneous clients.", "description": "The figure shows an ablation study on the effect of the size of the alignment dataset (AD) on the performance of the proposed FedBNN method. The experiment was conducted on the CIFAR-10 dataset with a small data setting and non-IID data distribution across clients, where some clients have smaller computational resources than others.  The x-axis represents the size of the AD, and the y-axis shows the test accuracy. The results demonstrate that increasing the size of the AD initially improves the test accuracy, but after a certain point, the accuracy plateaus, indicating that there is a limit to the benefits of increasing the size of the AD. This suggests that a moderate-sized AD is sufficient to effectively facilitate collaboration in heterogeneous settings.", "section": "E Alignment Dataset (AD)"}]