[{"figure_path": "HDVsiUHQ1w/tables/tables_6_1.jpg", "caption": "Table 1: Metrics and corresponding training datasets", "description": "This table lists the speech quality metrics used in the paper and the datasets used to train them.  The metrics include NISQA, NR-PESQ, NR-SI SDR, and NORESQA-MOS. Each metric is associated with a specific domain ID (D1, D2, D3), representing the domain of the training data, which are Sim Degradations (for NISQA), DL Speech Enhancement (for NR-PESQ, NR-SI SDR), and Speech Synthesis (for NORESQA-MOS). The bandwidth (BW) of the audio data used in each training dataset is also specified in kHz.", "section": "4 Generalisation of Speech Quality Metrics"}, {"figure_path": "HDVsiUHQ1w/tables/tables_7_1.jpg", "caption": "Table 2: Domain mismatch evaluated with Pearson's correlation (PC). Each metric performs the best in its corresponding training domain. We indicate the domain shift between training and test with IN, ODS, ODM. Our proposed metrics show the best generalisation performance across most of the datasets. Note that results on the dataset DNS Squim are taken from [30] since the dataset is not publicly available.", "description": "This table presents a comparison of the performance of different speech quality assessment metrics across various datasets.  It compares in-domain (IN), out-of-distribution (ODS), and out-of-domain (ODM) performance.  The results highlight the generalisation capabilities of different methods, demonstrating a lack of robustness in some state-of-the-art approaches and showcasing the improved performance of the SCOREQ model proposed in the paper.  Note that results for the DNS Squim dataset were taken from another source due to unavailability.", "section": "4 Generalisation of Speech Quality Metrics"}, {"figure_path": "HDVsiUHQ1w/tables/tables_8_1.jpg", "caption": "Table 3: Performance evaluation using PC(\u2191), RMSE(\u2193) for NR metrics and PC and SC(\u2191) for NMR metrics. Domain shift (IN, ODS, ODM) is labelled with respect to the training set NISQA TRAIN SIM.", "description": "This table presents a performance comparison of different speech quality assessment methods across various datasets and conditions.  The metrics are evaluated using Pearson Correlation (PC) and Root Mean Squared Error (RMSE) for no-reference (NR) and Pearson Correlation (PC) and Spearman's rank correlation (SC) for non-matching reference (NMR). The results are categorized by domain shift: IN (in-domain), ODS (out-of-distribution), and ODM (out-of-domain). This allows for an analysis of the generalisation capabilities of each method across different types of speech degradation.", "section": "Simulated Degradations: Results"}, {"figure_path": "HDVsiUHQ1w/tables/tables_9_1.jpg", "caption": "Table 3: Performance evaluation using PC(\u2191), RMSE(\u2193) for NR metrics and PC and SC(\u2191) for NMR metrics. Domain shift (IN, ODS, ODM) is labelled with respect to the training set NISQA TRAIN SIM.", "description": "This table presents the performance evaluation results of various speech quality metrics, including the proposed SCOREQ model, across different test sets categorized by domain shift (IN: in-domain; ODS: out-of-distribution; ODM: out-of-domain).  The metrics are evaluated using Pearson Correlation (PC) for linearity, Root Mean Squared Error (RMSE) for average precision, and Spearman's rank correlation coefficient (SC) for ranking, depending on whether the metric is no-reference (NR) or non-matching reference (NMR).  The table helps demonstrate the generalization ability of the proposed model and compare it against existing state-of-the-art metrics.", "section": "5.2 Simulated Degradations: Results"}, {"figure_path": "HDVsiUHQ1w/tables/tables_15_1.jpg", "caption": "Table 3: Performance evaluation using PC(\u2191), RMSE(\u2193) for NR metrics and PC and SC(\u2191) for NMR metrics. Domain shift (IN, ODS, ODM) is labelled with respect to the training set NISQA TRAIN SIM.", "description": "This table presents the performance evaluation results for various speech quality metrics, including the proposed SCOREQ model.  It compares the performance of different models (L2 loss, NOMAD, Offline, SCOREQ Const, and SCOREQ Adapt) across three different scenarios: in-domain (IN), out-of-distribution (ODS), and out-of-domain (ODM).  The evaluation metrics used are Pearson Correlation (PC) and Root Mean Squared Error (RMSE) for NR (no-reference) metrics and PC and Spearman's rank correlation (SC) for NMR (non-matching reference) metrics.  The table shows the PC and RMSE values for each model and scenario.  The domain shift indicates how similar the test data is to the training data used for each specific metric.", "section": "5.2 Simulated Degradations: Results"}, {"figure_path": "HDVsiUHQ1w/tables/tables_16_1.jpg", "caption": "Table 6: NISQA ms_fmax values chosen based on the input bandwidth.", "description": "This table shows the different values used for the parameter `ms_fmax` in the NISQA model, based on the input bandwidth.  The `ms_fmax` parameter determines the maximum frequency used to calculate the mel spectrograms. The table indicates that for a 48000 Hz bandwidth, `ms_fmax` is set to 20000 Hz; for 16000 Hz, it's 8000 Hz; and for 8000 Hz, it's 4000 Hz. This adjustment is made to ensure that the NISQA model processes input signals of different bandwidths appropriately.", "section": "Reproducing State of the Art Quality Metric Performances"}, {"figure_path": "HDVsiUHQ1w/tables/tables_17_1.jpg", "caption": "Table 7: Hyperparameter search for the L2 loss model.", "description": "This table presents the results of a hyperparameter search conducted for an L2 loss model.  The search involved varying batch size (32, 64, 128) and learning rate (0.1, 0.01) to determine the optimal combination that minimizes validation loss. The validation loss for each combination of hyperparameters is shown, indicating the best performing configuration.", "section": "5.2 Simulated Degradations: Results"}, {"figure_path": "HDVsiUHQ1w/tables/tables_18_1.jpg", "caption": "Table 2: Domain mismatch evaluated with Pearson's correlation (PC). Each metric performs the best in its corresponding training domain. We indicate the domain shift between training and test with IN, ODS, ODM. Our proposed metrics show the best generalisation performance across most of the datasets. Note that results on the dataset DNS Squim are taken from [30] since the dataset is not publicly available.", "description": "This table presents the Pearson Correlation Coefficient (PC) scores for various speech quality assessment metrics across different test datasets.  The metrics are evaluated based on three domain conditions: In-domain (IN), Out-of-Distribution (ODS), and Out-of-Domain (ODM). The table highlights the generalisation performance of each metric and shows how the proposed SCOREQ metric performs compared to the state-of-the-art.  The results show SCOREQ's improved generalisation capabilities, especially in out-of-domain scenarios.", "section": "4 Generalisation of Speech Quality Metrics"}, {"figure_path": "HDVsiUHQ1w/tables/tables_18_2.jpg", "caption": "Table 2: Domain mismatch evaluated with Pearson's correlation (PC). Each metric performs the best in its corresponding training domain. We indicate the domain shift between training and test with IN, ODS, ODM. Our proposed metrics show the best generalisation performance across most of the datasets. Note that results on the dataset DNS Squim are taken from [30] since the dataset is not publicly available.", "description": "This table presents a comparison of different speech quality metrics' performance across various datasets, categorized by domain match (in-domain, out-of-distribution, out-of-domain).  The Pearson Correlation Coefficient (PC) is used as the evaluation metric.  The table highlights the superior generalization capabilities of the proposed NR-SCOREQ metric compared to existing state-of-the-art methods.", "section": "4 Generalisation of Speech Quality Metrics"}, {"figure_path": "HDVsiUHQ1w/tables/tables_19_1.jpg", "caption": "Table 2: Domain mismatch evaluated with Pearson\u2019s correlation (PC). Each metric performs the best in its corresponding training domain. We indicate the domain shift between training and test with IN, ODS, ODM. Our proposed metrics show the best generalisation performance across most of the datasets. Note that results on the dataset DNS Squim are taken from [30] since the dataset is not publicly available.", "description": "This table presents a comparison of different speech quality metrics' performance across various datasets, categorized by in-domain (IN), out-of-distribution (ODS), and out-of-domain (ODM) scenarios. The table highlights the generalization capabilities of each metric, demonstrating the superior performance of the proposed NR-SCOREQ metric in most cases.", "section": "4 Generalisation of Speech Quality Metrics"}, {"figure_path": "HDVsiUHQ1w/tables/tables_19_2.jpg", "caption": "Table 3: Performance evaluation using PC(\u2191), RMSE(\u2193) for NR metrics and PC and SC(\u2191) for NMR metrics. Domain shift (IN, ODS, ODM) is labelled with respect to the training set NISQA TRAIN SIM.", "description": "This table presents the performance evaluation results for different speech quality metrics, including the proposed SCOREQ model and several baselines.  The evaluation is performed across various test sets and categorized by domain shift (IN: in-domain, ODS: out-of-distribution, ODM: out-of-domain) relative to the training data. The metrics used are Pearson Correlation (PC), Root Mean Squared Error (RMSE), and Spearman's rank correlation (SC).  PC and RMSE are used for no-reference (NR) metrics, while PC and SC are used for non-matching reference (NMR) metrics. Lower RMSE values indicate better performance. Higher PC and SC values indicate better performance.  The table allows to assess the generalization capability of the different models across various domains and data distributions. ", "section": "Simulated Degradations: Results"}, {"figure_path": "HDVsiUHQ1w/tables/tables_20_1.jpg", "caption": "Table 3: Performance evaluation using PC(\u2191), RMSE(\u2193) for NR metrics and PC and SC(\u2191) for NMR metrics. Domain shift (IN, ODS, ODM) is labelled with respect to the training set NISQA TRAIN SIM.", "description": "This table presents the performance evaluation results for different speech quality assessment metrics. It shows the Pearson Correlation (PC), Root Mean Squared Error (RMSE), and Spearman's rank correlation (SC) for both No-Reference (NR) and Non-Matching Reference (NMR) modes across various datasets. The datasets are categorized into In-domain (IN), Out-of-distribution (ODS), and Out-of-domain (ODM) to assess the generalization capability of each metric.", "section": "5.2 Simulated Degradations: Results"}, {"figure_path": "HDVsiUHQ1w/tables/tables_21_1.jpg", "caption": "Table 3: Performance evaluation using PC(\u2191), RMSE(\u2193) for NR metrics and PC and SC(\u2191) for NMR metrics. Domain shift (IN, ODS, ODM) is labelled with respect to the training set NISQA TRAIN SIM.", "description": "This table presents the performance evaluation results for different speech quality metrics across various datasets.  The evaluation considers three types of domain shifts: In-domain (IN), Out-of-Distribution (ODS), and Out-of-Domain (ODM).  Metrics evaluated include Pearson Correlation (PC), Root Mean Squared Error (RMSE), and Spearman's Rank Correlation (SC). The table compares the performance of the proposed SCOREQ method with L2 loss-based models and other state-of-the-art methods for both no-reference (NR) and non-matching reference (NMR) scenarios. The training data is the NISQA TRAIN SIM dataset.", "section": "5.2 Simulated Degradations: Results"}]