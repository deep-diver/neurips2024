[{"figure_path": "aRokfUfIQs/tables/tables_8_1.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments on several benchmark datasets using sum aggregation as a baseline.  It compares the performance of various graph neural network (GNN) architectures, both with and without the proposed SSMA aggregation method.  The metrics reported are accuracy (for TU datasets) and Mean Absolute Error (MAE) (for ZINC).  The table shows that SSMA consistently improves performance compared to the baseline across all the datasets.", "section": "5 Experiments"}, {"figure_path": "aRokfUfIQs/tables/tables_8_2.jpg", "caption": "Table 2: Test performance on the OGB [21] & LRGB [16] benchmarks using sum aggregation as a baseline.  indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the test performance results on the Open Graph Benchmark (OGB) and Long Range Graph Benchmark (LRGB) datasets.  The results are compared using sum aggregation as a baseline, with reproduced and previously reported results indicated.  The table shows Average Precision (AP), Mean Absolute Error (MAE), Accuracy, and Area Under the ROC Curve (AUROC) for various graph neural network architectures with and without the Sequential Signal Mixing Aggregation (SSMA) module.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_19_1.jpg", "caption": "Table 3: Comparison of the training and inference times in (ms) of MPGNNs+SSMA against PNA and GraphGPS. rSSMA indicates random neighbor selection while aSSMA indicates attentional neighbor selection.", "description": "This table compares the training and inference times of several Message Passing Graph Neural Networks (MPGNNs) with and without the Sequential Signal Mixing Aggregation (SSMA) method.  It also includes results from two other methods: Principal Neighbourhood Aggregation (PNA) and GraphGPS. The comparison is done for two datasets: Arxiv and Proteins, and it distinguishes between using random neighbor selection (rSSMA) and attentional neighbor selection (aSSMA).  The table shows the runtimes of different models and highlights the computational efficiency of SSMA, especially the random neighbor selection version.", "section": "5 Experiments"}, {"figure_path": "aRokfUfIQs/tables/tables_20_1.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments conducted on several benchmark datasets using the sum-based aggregation method as a baseline.  It shows the performance of different graph neural network models (GCN, GAT, GATv2, GIN, GraphGPS, PNA, ESAN) with and without the proposed SSMA aggregation. For the TU datasets (TU datasets), accuracy (mean and standard deviation) is reported based on a 10-fold cross-validation. For the ZINC dataset, mean absolute error (MAE) and standard deviation are reported for 5 different runs.  The table also includes a comparison to previously published results for some models.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_22_1.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments conducted on various TU datasets and the ZINC dataset using sum aggregation as a baseline.  It shows the accuracy (mean and standard deviation) for the TU datasets, obtained through 10-fold cross-validation. For the ZINC dataset, it provides the mean absolute error (MAE) and standard deviation, based on 5 independent test runs.  The results are compared to previously published results where applicable, marked with \u2020 and *.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_23_1.jpg", "caption": "Table 6: Test accuracy (higher is better). Shown is the mean \u00b1 STD of 10-fold cross-validation runs, VPA results are taken directly from [39], SSMA results are generated by us using the code provided in [39] without any architecture or training protocol modifications", "description": "This table shows the test accuracy results for different graph neural network architectures using Variance Preserving Aggregation (VPA) and Sequential Signal Mixing Aggregation (SSMA).  The results are averaged over 10-fold cross-validation runs.  It demonstrates that SSMA consistently outperforms VPA across various datasets, highlighting the effectiveness of SSMA in improving model performance.", "section": "D.1 Comparison to variance preserving aggregation"}, {"figure_path": "aRokfUfIQs/tables/tables_23_2.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments on several benchmark datasets (TU datasets and ZINC) comparing the performance of various Graph Neural Network (GNN) models using two different aggregation methods: sum aggregation (baseline) and the proposed Sequential Signal Mixing Aggregation (SSMA).  The table shows the accuracy (for TU datasets) and Mean Absolute Error (MAE) (for ZINC) achieved by each GNN architecture with and without SSMA.  The results demonstrate the improved performance of SSMA across different GNN architectures and datasets.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_24_1.jpg", "caption": "Table 8: Results for GraphGPS with positional encoding, the aggregation used for the baselines is Add. See Appendix C for more information.", "description": "This table presents the results of experiments using GraphGPS with and without positional encoding and with the proposed SSMA aggregation method. The results are compared against the baseline GraphGPS model.  The table shows the performance metrics (accuracy or MAE) for various datasets, demonstrating the impact of positional encoding and SSMA on the model's performance.", "section": "E Ablation studies"}, {"figure_path": "aRokfUfIQs/tables/tables_27_1.jpg", "caption": "Table 9: Learning the affine transformation on the ZINC dataset", "description": "This table presents the results of an ablation study on the ZINC dataset, comparing the performance of using a learnable affine transformation versus a constant affine transformation in the SSMA aggregation module for different GNN architectures (GCN, GAT, GIN).  The numbers show mean \u00b1 standard deviation of a metric, likely Mean Absolute Error (MAE) for a property prediction task on the ZINC dataset.", "section": "E Ablation studies"}, {"figure_path": "aRokfUfIQs/tables/tables_28_1.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments on several graph datasets (TU datasets and ZINC) comparing different graph neural network (GNN) models with the proposed SSMA aggregation against the baseline sum aggregation.  The TU datasets' results show accuracy with standard deviation calculated over 10-fold cross-validation, while the ZINC dataset's results show Mean Absolute Error (MAE) with standard deviation over 5 runs. The table also indicates which results were reproduced from other papers.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_28_2.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments on several benchmark datasets using different graph neural network (GNN) architectures combined with both the standard sum aggregation and the proposed Sequential Signal Mixing Aggregation (SSMA).  The TU datasets are used for node classification, while ZINC is used for regression. The table shows the accuracy (for TU datasets) or mean absolute error (MAE) (for ZINC), along with standard deviation, for each model. Results from previous research are included for comparison.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_29_1.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments on various graph datasets, comparing the performance of different graph neural network architectures with and without the proposed SSMA aggregation module.  The TU datasets are evaluated using 10-fold cross-validation accuracy, while ZINC is assessed using mean absolute error (MAE).  The table shows that SSMA consistently improves performance across multiple network architectures and benchmarks.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_29_2.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments on several benchmark datasets (TU datasets and ZINC) comparing the performance of different Graph Neural Network (GNN) architectures when using sum aggregation as a baseline.  The table shows the accuracy (for TU datasets) and Mean Absolute Error (MAE) (for ZINC) achieved by various models with and without Sequential Signal Mixing Aggregation (SSMA). The results demonstrate SSMA's effectiveness in improving GNN performance across different datasets and architectures.", "section": "5.2 Benchmarking SSMA"}, {"figure_path": "aRokfUfIQs/tables/tables_29_3.jpg", "caption": "Table 1: Results for TU datasets [32] & ZINC [19] using sum aggregation as a baseline. We report the TU datasets' accuracy mean and STD of a 10-fold cross-validation run. For the ZINC dataset, we report mean MAE and STD on the test set according to 5 distinct runs. \u2020 indicates reproduced results while * indicates the reported results from the relevant paper.", "description": "This table presents the results of experiments on various graph neural network architectures applied to several datasets.  It compares the performance of the proposed SSMA method against a standard sum-based aggregation baseline. The datasets used include the TU datasets (ENZYMES, PTC-MR, MUTAG, PROTEINS, IMDB-BINARY) and the ZINC dataset.  For each dataset, the table shows the mean and standard deviation of accuracy (TU datasets) or Mean Absolute Error (MAE) (ZINC dataset) achieved by different models. The \"Improvement (%)\" row shows the percentage improvement achieved by the models with SSMA compared to their sum-based counterparts.", "section": "5.2 Benchmarking SSMA"}]