{"references": [{"fullname_first_author": "Grigory Malinovsky", "paper_title": "Byzantine Robustness and Partial Participation Can Be Achieved at Once: Just Clip Gradient Differences", "publication_date": "2024-XX-XX", "reason": "This is the main research paper for which the other references provide background and support."}, {"fullname_first_author": "Dan Alistarh", "paper_title": "Byzantine stochastic gradient descent", "publication_date": "2018-XX-XX", "reason": "This paper is foundational for understanding Byzantine fault tolerance in distributed systems and is directly referenced for its techniques."}, {"fullname_first_author": "Sai Praneeth Karimireddy", "paper_title": "Learning from history for Byzantine robust optimization", "publication_date": "2021-XX-XX", "reason": "This is a key paper introducing the concept of robust aggregation and is directly referenced in the methods section."}, {"fullname_first_author": "Eduard Gorbunov", "paper_title": "Variance reduction is an antidote to Byzantines: Better rates, weaker assumptions and communication compression as a cherry on the top", "publication_date": "2023-XX-XX", "reason": "This paper provides the state-of-the-art (SOTA) theoretical results that are matched by the proposed method in this research paper."}, {"fullname_first_author": "Peter Richt\u00e1rik", "paper_title": "MARINA: Faster non-convex distributed learning with compression", "publication_date": "2021-XX-XX", "reason": "This paper is highly relevant as it develops the MARINA algorithm, which forms the basis for this research paper's approach."}]}