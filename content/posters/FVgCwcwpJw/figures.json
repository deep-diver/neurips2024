[{"figure_path": "FVgCwcwpJw/figures/figures_1_1.jpg", "caption": "Figure 1: Given an environment and instructions to follow, we assume a verbalization procedure that converts observations to language descriptions. Policy improvement using Language Feedback Model involves (a) training a feedback model, then (b) using it to identify desirable behaviour for policy improvement via imitation learning. The feedback model is yellow, other models purple, and generated intermediate data green. An example of LFM-identified behaviour is shown in (c).", "description": "This figure illustrates the overall process of policy improvement using Language Feedback Models (LFMs). It consists of three parts:\n(a) Training an LFM using feedback from a Large Language Model (LLM): An initial policy is used to generate rollouts in an environment, these rollouts are then verbalized into language descriptions, and these descriptions are given to the LLM to provide feedback on which actions were productive. This feedback is used to train the LFM.\n(b) Using the trained LFM to identify desirable behavior: Given an instruction, the base policy generates rollouts and the LFM predicts which actions are productive. These productive actions are used to update the base policy.\n(c) An example of desirable behavior identified by the LFM: This example shows a kitchen environment where the task is to clean some lettuce and put them in the fridge. The LFM identifies the actions of cleaning the lettuce and putting it in the fridge as productive behavior.", "section": "1 Introduction"}, {"figure_path": "FVgCwcwpJw/figures/figures_1_2.jpg", "caption": "Figure 1: Given an environment and instructions to follow, we assume a verbalization procedure that converts observations to language descriptions. Policy improvement using Language Feedback Model involves (a) training a feedback model, then (b) using it to identify desirable behaviour for policy improvement via imitation learning. The feedback model is yellow, other models purple, and generated intermediate data green. An example of LFM-identified behaviour is shown in (c).", "description": "This figure illustrates the process of policy improvement using Language Feedback Models (LFMs). It starts with an initial policy that is used to generate rollouts in a given environment.  These rollouts are then verbalized into language descriptions.  An LLM provides feedback on which actions in the trajectories were productive in achieving the task, as indicated by the instructions. This feedback is used to train a Language Feedback Model (LFM).  The LFM is then used to identify productive actions from new rollouts of the base policy. Finally, imitation learning is performed using these productive actions to create an improved policy. The figure shows the overall process with subfigures detailing the training of the LFM and the policy improvement steps.", "section": "1 Introduction"}, {"figure_path": "FVgCwcwpJw/figures/figures_1_3.jpg", "caption": "Figure 1: Given an environment and instructions to follow, we assume a verbalization procedure that converts observations to language descriptions. Policy improvement using Language Feedback Model involves (a) training a feedback model, then (b) using it to identify desirable behaviour for policy improvement via imitation learning. The feedback model is yellow, other models purple, and generated intermediate data green. An example of LFM-identified behaviour is shown in (c).", "description": "This figure illustrates the policy improvement process using Language Feedback Models (LFMs).  It shows three parts: (a) training an LFM using LLM feedback from an initial policy's rollout; (b) using the trained LFM to identify desirable behavior for imitation learning and updating the base policy; (c) an example of desirable behavior identified by the LFM in a kitchen environment.", "section": "1 Introduction"}, {"figure_path": "FVgCwcwpJw/figures/figures_2_1.jpg", "caption": "Figure 1: Given an environment and instructions to follow, we assume a verbalization procedure that converts observations to language descriptions. Policy improvement using Language Feedback Model involves (a) training a feedback model, then (b) using it to identify desirable behaviour for policy improvement via imitation learning. The feedback model is yellow, other models purple, and generated intermediate data green. An example of LFM-identified behaviour is shown in (c).", "description": "This figure illustrates the overall process of policy improvement using Language Feedback Models (LFMs). It's broken down into three parts:\n(a) Shows the training of the LFM using Large Language Model (LLM) feedback. An initial policy is rolled out, and an LLM provides feedback on which actions were productive, this data is used to train the LFM which predicts whether an action is productive.\n(b) Shows the policy improvement process using the trained LFM. The LFM identifies productive actions from a base policy's rollout, and then these actions are used to improve the base policy using imitation learning.\n(c) Provides an example of LFM-identified desirable behavior in a kitchen environment, highlighting the practical application of the method.", "section": "1 Introduction"}]