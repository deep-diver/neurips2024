{"importance": "This paper is highly important for researchers working on **multimodal model explainability** and **interpretability**. It addresses a critical gap in understanding the internal representations of large multimodal models, which are increasingly being deployed in various applications. The proposed framework, CoX-LMM, offers a novel approach to extract and ground multimodal concepts, enabling a deeper understanding of these complex models and opening up new avenues for research in this area.  The public availability of the implementation further enhances its impact, encouraging broader adoption and further development. ", "summary": "CoX-LMM unveils a novel concept-based explainability framework for large multimodal models, extracting semantically grounded multimodal concepts to enhance interpretability.", "takeaways": ["A novel concept-based explainability framework, CoX-LMM, is introduced for interpreting large multimodal models.", "CoX-LMM extracts multimodal concepts, grounded in both visual and textual domains, through dictionary learning.", "Experimental validation demonstrates the usefulness of extracted multimodal concepts for interpreting model representations."], "tldr": "Large multimodal models (LMMs) are powerful but lack interpretability, hindering trust and deployment.  Existing methods struggle to understand LMM's internal representations, particularly concerning multimodal interactions between vision and language components. This paper tackles this challenge by focusing on the internal representations of a given token, allowing the study of multimodal interactions in a focused manner.\nThe proposed CoX-LMM framework uses dictionary learning to extract **multimodal concepts** from LMM representations.  These concepts are then grounded in both vision (via images activating the concepts) and text (via words associated with them). The framework's effectiveness is shown qualitatively (visualizations) and quantitatively (evaluation of disentanglement between concepts and quality of grounding). The work represents a significant advancement in understanding LMMs, making it more reliable and trustworthy.", "affiliation": "Sorbonne Universit\u00e9", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "MvjLRFntW6/podcast.wav"}