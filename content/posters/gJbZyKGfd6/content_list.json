[{"type": "text", "text": "HyperLogic: Enhancing Diversity and Accuracy in Rule Learning with HyperNets ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yang Yang1, Wendi $\\mathbf{Ren^{1}}$ , Shuang Li1\u2217 ", "page_idx": 0}, {"type": "text", "text": "1School of Data Science, The Chinese University of Hong Kong (Shenzhen) {yangyang8, wendiren}@link.cuhk.edu.cn, lishuang@cuhk.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Exploring the integration of if-then logic rules within neural network architectures presents an intriguing area. This integration seamlessly transforms the rule learning task into neural network training using backpropagation and stochastic gradient descent. From a well-trained sparse and shallow neural network, one can interpret each layer and neuron through the language of logic rules, and a global explanatory rule set can be directly extracted. However, ensuring interpretability may impose constraints on the flexibility, depth, and width of neural networks. In this paper, we propose HyperLogic: a flexible approach leveraging hypernetworks to generate weights of the main network. HyperLogic can be combined with existing differentiable rule learning methods to generate diverse rule sets, each capable of capturing heterogeneous patterns in data. This provides a simple yet effective method to increase model flexibility and preserve interpretability. We theoretically analyze the beneftis of the HyperLogic by examining the approximation error and generalization capabilities under two types of regularization terms: sparsity and diversity regularization. Experiments on real data demonstrate that our method can learn more diverse, accurate, and concise rules. Our code is publicly available at https://github.com/YangYang-624/HyperLogic. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Despite the significant impact of deep learning on society, its lack of interpretability limits its use in critical areas that demand high transparency. For instance, in high-risk domains such as healthcare, finance, and law, the decision-making process of models needs to be fully open and explainable to users and relevant regulatory authorities to gain necessary trust and legitimacy [1, 2, 3]. Compared to the \u201cblack box\u201d models, which may perform well but are uninterpretable, people prefer intrinsically interpretable model for decision support [4, 5], such as a set of concise IF-THEN rules. ", "page_idx": 0}, {"type": "text", "text": "Traditional rule learning methods, which are based on statistical or heuristic approaches, have been extensively explored but often struggle to simultaneously achieve two key objectives: 1) simplicity and accuracy in rules, and 2) noise tolerance and scalability in data handling [6, 7, 8, 9, 10]. These methods typically rely on search-based techniques, which can be limited when dealing with complex and noisy data. In contrast, deep learning, which focuses on representation learning through embedding, is robust to noise and effectively manages large datasets. This has led to the exploration of differentiable rule learning [11], which leverages the high performance of deep learning while ensuring interpretability through explicit rule formulation ", "page_idx": 0}, {"type": "text", "text": "Differentiable rule learning primarily includes two types of methods. The first approach outputs rules directly through the network, leveraging powerful and diverse neural models to enhance handling of complex data patterns [12, 13, 14]. The second approach is to extract rules from network weights [15, 16, 17], which promotes rapid training and efficient data management while enabling the use of predefined structures to integrate expert priors [18]. ", "page_idx": 0}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/898ab20b8e58e428add4543fe0e3c1a3a404cff39662fc9f049ac6791b9b4006.jpg", "img_caption": ["Figure 1: The framework of HyperLogic: Hypernetwork generates $\\theta$ for the main network, which is a rule-learning network. An example of a main rule-learning network is shown on the right, from which rules can be extracted based on the learned network weights. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "We focus on the second approach, aiming to extract rules like \u201cIF $a\\wedge b\\wedge\\neg c$ THEN $y$ is True\u201d from network weights, where $a,b,c$ are predefined predicates. Although integrating if-then logic rules within neural network architectures offers clear advantages, their performance is often hindered by the restrictive network structures required for interpretability. These structures tend to be overly simplistic and not scalable, limiting their ability to capture complex data patterns and making them prone to only capturing partial or local patterns in the data. This raises a critical question: How can we modify these models to better harness the full potential of neural networks without compromising their interpretability? ", "page_idx": 1}, {"type": "text", "text": "In this work, we introduce HyperLogic, a novel framework that integrates hypernetworks with a main rule-learning network (as illustrated in Fig. 1, where an example of a main rule-learning network is shown on the right). Hypernetworks are a type of neural network that generate weights for a main rule-learning network. In our framework, the hypernetwork takes random samples from a high-dimensional Gaussian distribution as input and outputs weights for different parts of the main network. These weights can be utilized in two ways: either directly as the weights for the main network throughout the training process (meaning the main network itself has no parameters), or by retaining trainable weights in the main network and combining them with the hypernetwork-generated weights through weighted fusion. In both scenarios, this approach yields an interpretable set of rules derived from the comprehensive weights. ", "page_idx": 1}, {"type": "text", "text": "HyperLogic can be seen as a mixture of expert model with an infinite number of experts, providing a simple yet effective way to enhance model flexibility and adaptability. We analyze the benefits of HyperLogic by examining its approximation error and generalization capabilities under two types of regularization: sparsity and diversity regularization. Our findings demonstrate that HyperLogic acts as a universal approximation estimator in the Barron space [19] and proves its generalization ability across various regularization methods. These theoretical beneftis are further supported by our empirical experiments. ", "page_idx": 1}, {"type": "text", "text": "Additionally, hypernetworks enable the generation of multiple candidate rule sets in a single training session without significantly increasing computational overhead. This is in stark contrast to traditional methods, which typically learn only one set of rules at a time. Consequently, HyperLogic greatly enhances the efficiency and flexibility of the rule-learning process. ", "page_idx": 1}, {"type": "text", "text": "We summarize our contributions as follows: ", "page_idx": 1}, {"type": "text", "text": "1. We introduce HyperLogic, a pioneering framework that integrates hypernetworks into differentiable rule learning, significantly enhancing the rule-learning landscape.   \n2. We theoretically justify the performance of HyperLogic and provide insights into its effectiveness. Specifically, we examine the approximation error and generalization capabilities under two types of regularization: sparsity and diversity.   \n3. We validate HyperLogic through extensive experiments on multiple datasets, demonstrating that it ", "page_idx": 1}, {"type": "text", "text": "enables the learning of multiple diverse rule sets and yields more concise and accurate rules. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Learning Rules from Network Weights Many methods for extracting rules from model weights are not based on neural networks; instead, they primarily focus on interpreting the weights of smaller, simpler models to discover rules [20, 7]. Recently, extensive methods have emerged that attempt to extract rules using neural network models. These approaches often involve data preprocessing techniques to prepare the data before training [21] or utilize post-hoc methods for rule extraction after model training [22, 23, 24], which can often lead to a loss of accuracy. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "A more promising alternative allows for the direct interpretation of neural network weights as precise rules by integrating rule extraction directly during training. This leads to a more seamless and effective learning process. For example, methods such as [25, 26, 27] utilize low-dimensional embeddings to represent atomic conditions and rules, treating rule learning as a differentiable discrete combinatorial optimization problem encoded by a feedforward neural network. Specifically, FinRule [27] explores higher-order interactions between atomic conditions, which aligns somewhat with our approach of employing hypernetworks. However, it lacks a detailed analysis of the specific roles of these higherorder interactions and cannot learn a rich set of candidate rules as our method does. Additionally, these approaches often impose constraints on rule templates, such as fixing the rule length and the number of rules. ", "page_idx": 2}, {"type": "text", "text": "Another common class of methods employs modified simple feedforward neural networks, such as DR-net [17] and others [28, 29, 30]. These methods simulate logical operations by altering activation functions and implementing mechanisms that ensure differentiability and support backpropagation. While they overcome the limitations of rigid rule templates, their model structures tend to be relatively simple. Furthermore, the training process often involves freezing the weights of one component while adjusting another, which restricts the model\u2019s ability to fully optimize performance. ", "page_idx": 2}, {"type": "text", "text": "Our HyperLogic is a unified framework that can be integrated with various neural network weight generators, enabling easy adaptation to different main rule learning networks. Currently, our main network draws inspiration from DR-net [17], but it can be replaced with other architectures based on task requirements. Unlike recent Bayesian approaches, which often require multiple hyperparameters to model uncertainty in network weights, HyperLogic simplifies the process by needing fewer hyperparameters while maintaining scalability. This allows for efficient training and adaptability across various tasks without the added complexity of managing uncertainty. Additionally, our approach can generate multiple sets of rule sets in a single training session, a capability not available in other methods. For further comparisons, including classic rule-based algorithms, please refer to Appendix A. ", "page_idx": 2}, {"type": "text", "text": "Hypernetwork Hypernetworks, or hypernets, are neural networks that generate weights for main networks [31]. Benefiting from over-parameterization and strategic design, these networks enhance training flexibility and adaptability, improve information sharing, and accelerate training processes. While widely used in many areas like continual learning [32, 33], transfer learning [34], uncertainty quantification [35, 36], natural language processing [37] and computer vision [38], their potential in rule learning remains largely untapped. Our HyperLogic framework can bridge this gap. Specifically, our hypernetwork takes inspirations from HyperGAN [36] and similarly we add a loss term to encourage the diversity of the generated network weights. ", "page_idx": 2}, {"type": "text", "text": "Unlike typical applications in other domains that focus on enhancing parameter efficiency and training speed, our approach addresses the unique challenges of adding model flexibility while preserving interpretability. Our main goal is to expand the parameter space to produce more diverse, concise and accurate rule sets. ", "page_idx": 2}, {"type": "text", "text": "3 HyperLogic ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "HyperLogic is a versatile framework designed to enhance various existing neural rule-learning methods. The concept of hypernetworks can be applied to different types of main networks, provided they focus on learning a set of interpretable weights in a differentiable manner. Importantly, HyperLogic imposes no additional restrictions on data formats or rule languages; it simply builds upon the capabilities of the chosen main network. ", "page_idx": 2}, {"type": "text", "text": "3.1 Main Network: Rule-Learning Network ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our main network is currently based on DR-Net [17], which features a simple architecture and is designed for binary classification tasks. We chose this architecture for its simplicity, which aids in our proofs and explanations. However, we recognize its limitations, so we can also explore other more flexible neural approaches as the primary network to overcome restrictions related to data formats and rule languages. This is further discussed in Appendix B. ", "page_idx": 2}, {"type": "text", "text": "The main network is a two-layer neural network as shown in Fig. 1 (right part). Due to its interpretability, one can directly extract the if-then rules from the trained neural networks. The input layer of the main network is fed with a $D$ -dimensional binary data $x=[x_{d}]$ , each element $x_{d}\\in\\{1,-1\\}$ . Here $x_{d}$ indicates the grounded predicate, where 1 indicates True and $^{-1}$ means false. Note that common input types may include binary, categorical, or numerical features, all of which are discretized and binarized to form our binary input features. The hidden layer has $K$ neurons, where $K$ determines the total number of rules and serves as a hyperparameter. The first layer is referred to as the Rule Layer, and the output layer as the OR layer. ", "page_idx": 3}, {"type": "text", "text": "Rule Layer: Each neuron in the hidden layer is denoted as $o_{k}\\,\\in\\,\\{0,1\\}$ . The output represents whether a rule is satisfied. Each neuron is calculated as: ", "page_idx": 3}, {"type": "equation", "text": "$$\no_{k}=\\mathbb{1}\\left\\{\\sum_{d=1}^{D}w_{d,k}x_{d}-\\sum_{d=1}^{D}\\left|w_{d,k}\\right|=0\\right\\},\\quad\\mathrm{for}\\;k=1,\\ldots,K\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbb{1}\\{\\cdot\\}$ denotes the indicator function. Note that the indicator function is one if and only if all inputs match the sign of the corresponding weights: all positive weights should have the inputs of 1, and all negative weights should have the inputs of $^-1$ , and zero weights mean that the corresponding inputs are excluded from the rule. ", "page_idx": 3}, {"type": "text", "text": "Note that the indicator function is non-differentiable, which will make the gradient hard to compute. Here, we will instead use a differentiable smooth function to approximate the indicator function (this will also ease the theoretical analyses). For example, we can use $\\begin{array}{r}{h(u)=\\exp\\left(-\\frac{u^{2}}{\\tau}\\right)}\\end{array}$ , $\\tau>0$ , to approximate $\\mathbb{1}\\{u=0\\}$ , where $\\tau$ is the tunable temperature and controls the approximation error. ", "page_idx": 3}, {"type": "text", "text": "OR Layer: The second layer operation is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\nf(x)=\\sum_{k=1}^{K}u_{k}o_{k}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where we assume that the rules contribute to the final prediction in a weighted additive form to reflect the OR composition, where $u_{k}$ denotes the weight assigned to the $k$ -th rule. ", "page_idx": 3}, {"type": "text", "text": "3.2 Hypernetwork: Generate Network Weights ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Define the network weights for the previous model as $\\theta=(w,u)$ , where $w\\in R^{D\\times K}$ , and $u\\in R^{K}$ . Instead of learning only one set of $\\theta$ , we will learn the distribution of $\\theta$ , denoted as $\\mu$ . Specifically, we introduce a generative model as the hypernetwork to produce samples of $\\theta$ , i.e., ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\theta=G(\\epsilon),\\quad\\mathrm{where~}\\epsilon\\sim p(\\epsilon),\\quad\\theta\\in R^{(D+1)K}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, $\\epsilon$ is drawn from some simple base distribution such as Gaussian distribution. More details about the hypernetwork structure can be seen in Appendix C. Note that, in this way, our model parameters have been changed to $\\mu$ , which is defined as the distribution of $\\theta$ , and the proposed Hyperlogic model is ", "page_idx": 3}, {"type": "equation", "text": "$$\nf_{\\mu}({\\boldsymbol{x}})=\\mathbb{E}_{\\mu}\\left[\\sum_{k=1}^{K}u_{k}h\\left(\\sum_{d=1}^{D}w_{d,k}x_{d}-\\sum_{d=1}^{D}|w_{d,k}|\\right)\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In practice, we can use the Monte Carlo method to estimate the above expectation by randomly drawing $M$ samples from $\\mu$ , denoted as $\\theta^{1},\\ldots,\\theta^{M}$ , and we define ", "page_idx": 3}, {"type": "equation", "text": "$$\nf_{M}(\\boldsymbol{x})=\\frac{1}{M}\\sum_{m=1}^{M}\\left[\\sum_{k=1}^{K}u_{k}^{m}h\\left(\\sum_{d=1}^{D}w_{d,k}^{m}x_{d}-\\sum_{d=1}^{D}|w_{d,k}^{m}|\\right)\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This model can be regarded as a mixture of expert models with finite $M$ experts. Each expert is a shallow two-layer neural network that encodes at most $K$ if-then rules. ", "page_idx": 3}, {"type": "text", "text": "3.3 Expand to High-Dimensional Data ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "When working with high-dimensional data (e.g., 5000 dimensions), the number of parameters in the main network increases proportionally with the input dimensions, even if the network structure remains unchanged. This makes training a hypernetwork to generate weights for each module of the main network more challenging. To tackle this issue, we considered two strategies: ", "page_idx": 3}, {"type": "text", "text": "Combining Original Weights with Hypernetwork-Generated Weights Instead of allowing the hypernetwork-generated weights $(W_{\\mathrm{hyper}})$ to fully dictate the main network\u2019s weights, we combine them with the original weights ( $\\mathrm{\\DeltaW_{main}}^{\\mathrm{\\Delta}}\\mathrm{\\dot{\\Delta}}$ ). The final weights are calculated as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nW_{\\mathrm{main-final}}=\\alpha\\cdot W_{\\mathrm{hyper}}+(1-\\alpha)\\cdot W_{\\mathrm{main}},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\alpha$ is a learnable parameter constrained between 0 and 1. This strategy enhances stability without sacrificing the hypernetwork\u2019s ability to produce diverse weights. If the hypernetwork is poorly trained and generates inappropriate weights, the model adjusts $\\alpha$ toward 0, effectively reverting to the standard main network without hypernetwork influence. We employed this strategy in our subsequent experiments. ", "page_idx": 4}, {"type": "text", "text": "Generating Weights for Only Some Modules of the Main Network We test this strategy when the dataset dimension and size are very large in the supplementary experiment. It shows that generating only part of the main network\u2019s weights using the hypernetwork still significantly improves results. For more details, please see the supplementary experiments in Appendix B. ", "page_idx": 4}, {"type": "text", "text": "3.4 Loss Function ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "One can learn $\\mu$ by minimizing the loss function $\\ell(y,f_{\\mu}(x))$ , where $f_{\\mu}(x)$ can be approximated by the finite-sample estimator in Eq. (5). Our loss contains two parts. One is the task-related loss function, denoted as $\\ell_{t a s k}(y,f_{\\mu}(x))$ . Suppose the problem is a binary classification problem, one can use the binary cross-entropy loss (BCE), where we first map $f_{\\mu}(x)$ to a probability value between 0 and 1 using a link function such as sigmoid and the loss is defined as the negative log-likelihood of a sample belong to a class. Here, the task-related loss measures the prediction accuracy. ", "page_idx": 4}, {"type": "text", "text": "The second part of the loss is the regularization loss, denoted as $\\ell_{r e g}$ , which is introduced to encourage the diversity of the generated $\\theta$ and model sparsity (rule simplicity for each expert), i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\ell_{r e g}=\\lambda_{1}D_{\\mathrm{KL}}(\\mu\\|\\mu_{0})+\\lambda_{2}\\mathbb{E}_{\\mu}[|u|].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "For the first regularization term, we introduce a prior distribution $\\mu_{0}$ with a high entropy, and we minimize the relative entropy or KL divergence of the $\\mu$ and $\\mu_{0}$ . Minimizing the relative entropy encourages the diversity of the generated $\\theta$ . For the second regularization term, we are considering the $\\ell_{1}$ sparsity norm for the second OR layer\u2019s weights, where we hope that for each expert, the discovered number of rules is as compact as possible. In our paper, $\\ell_{r e g}$ represents the loss incurred by the hypernetwork, as illustrated in Fig. 1. ", "page_idx": 4}, {"type": "text", "text": "4 Theoretical Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We will employ theoretical analysis to demonstrate that while the main network (i.e., a two-layer shallow neural network) has low capacity, incorporating the hypernet idea significantly enhances the model\u2019s expressive power. Specifically, we will establish that the proposed HyperLogic model serves as a universal approximator in the Barron space [19], which will be defined later. For simplicity, but without loss of generality, we consider the case where the hypernetwork fully generates the weights and the main network itself has no parameters. Additionally, we will present the generalization error under the above two types of regularization. ", "page_idx": 4}, {"type": "text", "text": "Reparametrization: To ease the proof, let\u2019s first rewrite Eq. (5) as ", "page_idx": 4}, {"type": "equation", "text": "$$\nf_{M}(\\boldsymbol{x})=\\frac{1}{M}\\sum_{m=1}^{M}\\left[\\sum_{k=1}^{K}u_{k}^{m}h\\left(w_{k}^{m\\top}\\boldsymbol{x}\\right)\\right]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "by reparametrization. To achieve this, we first use the split variable trick by defining $w^{+}\\;=$ $\\operatorname*{max}\\{w,0\\}$ and $w^{-}\\;=\\;-\\operatorname*{min}\\{w,0\\}$ , and reparametrize $\\bar{w}\\;=\\;w^{+}\\;-\\;w^{-}$ and $\\bar{|\\boldsymbol{w}|}\\;=\\;\\boldsymbol{w}^{\\bar{+}}\\,+\\,\\boldsymbol{w}^{-}$ . In this way, we can get rid of the absolute value and have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\sum_{d=1}^{D}w_{d,k}x_{d}-\\sum_{d=1}^{D}|w_{d,k}|=\\sum_{d=1}^{D}w_{d,k}^{+}(x_{d}-1)+\\sum_{d=1}^{D}w_{d,k}^{-}(-x_{d}-1).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Therefore, we can simply reparametrize $w_{k}$ , where $w_{k}~\\geq~0$ , as a concatenation of the vector $[w_{d,k}^{+}]_{d=1,\\dots,D}$ and $[w_{d,k}^{-}]_{d=1,\\dots,D}$ . We construct the new input data $x$ by making a copy of the original data and modifying each copy given Eq. (8). That is, for one copy, we subtract it by 1, and for another copy, we flip the sign and subtract it by 1. Then, we concatenate the two copies of data. ", "page_idx": 4}, {"type": "text", "text": "Given such a reparametrization, we get a simple form as Eq. (7). In the following analysis, we will still assume that $w_{k}\\in R^{D}$ and $x\\in\\bar{R}^{D}$ , which doesn\u2019t affect the generality. ", "page_idx": 5}, {"type": "text", "text": "Preparation for the Theoretical Analysis: Our analysis below is based on the following observations. Given the generated random variable $\\left((w_{1},u_{1}),\\ldots,(w_{K},u_{K})\\right)\\in\\mathbb{R}^{(D+1)K}$ , we have denoted their joint distribution as $\\mu$ . Let us further denote the marginal distribution of $(w_{k},u_{k})$ as $\\mu_{k}$ , $k=1,\\ldots,K$ , respectively. Define a random variable $(\\tilde{w},\\tilde{u})\\in\\mathbb{R}^{\\check{D}+1}$ , which draws a sample from $\\mu_{k}$ with (equal) probability $1/K,k=1,\\ldots,K$ , and then scale the $u$ -component by $K$ . Denote the resulting mixture distribution as $\\tilde{\\mu}$ . Then it follows from the linearity of expectation that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{f_{\\mu}(x)=\\mathbb{E}_{((w_{1},u_{1}),\\dots,(w_{K},u_{K}))\\sim\\mu}\\left[\\sum_{k=1}^{K}u_{k}h\\left(w_{k}^{\\top}x\\right)\\right]}}\\\\ {\\displaystyle{\\qquad=\\mathbb{E}_{((w_{1},u_{1}),\\dots,(w_{K},u_{K}))\\sim\\mu}\\left[\\frac{1}{K}\\sum_{k=1}^{K}\\tilde{u}_{k}h\\left(w_{k}^{\\top}x\\right)\\right]=\\mathbb{E}_{(\\bar{w},\\bar{u})\\sim\\tilde{\\mu}}\\left[\\tilde{u}h\\left(\\tilde{w}^{\\top}x\\right)\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We define $\\tilde{f}_{\\tilde{\\mu}}(x):=\\mathbb{E}_{(\\tilde{w},\\tilde{u})\\sim\\tilde{\\mu}}\\left[\\tilde{u}h\\left(\\tilde{w}^{\\top}x\\right)\\right]$ and we have shown that $f_{\\mu}(x)=\\tilde{f}_{\\tilde{\\mu}}(x)$ as stated above. The motivation for introducing $\\tilde{f}_{\\tilde{\\mu}}(x)$ is to facilitate the analysis of approximation error and generalization error. There exist theoretical results for a two-layer neural network of the form $\\begin{array}{r}{\\bar{g}_{M}(x)=\\sum_{m=1}^{M}{u}^{m}h\\left({w}^{m}\\tau\\right)}\\end{array}$ ,a rwe e $h(\\cdot)$ p beenldoenngt s stao mcpelretasi dn rcalwasns efrs oomf  sa mfoixoetdh  adicstitrviabtiuotino fnu. nIcnt icoonns-, $(w^{m},u^{m})$ $m=1,\\dots,M$ $M$   \ntrast, our proposed HyperLogic model involves randomly drawing samples $\\big((w_{1},u_{1}),\\dots,(w_{K},u_{K})\\big)$ from $\\mu$ , each with $K$ components. To align this with the existing theoretical framework, we perform a transformation as shown in Eq. (9). This involves converting the process of drawing $M$ samples, each with $K$ components, into drawing $M K$ samples, each with a single component. This reformulation maintains the same expectation results, allowing us to leverage existing theoretical results to analyze HyperLogic. Note that the conversion mentioned is purely for theoretical proof purposes and is not implemented in the actual algorithm. ", "page_idx": 5}, {"type": "text", "text": "4.1 Approximation Error of Finite Experts ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Using the connection as shown in Eq. (9), we can directly leverage the approximation error results for a single hidden layer neural network. Let\u2019s first define the Barron space, which provides a set of functions for which neural networks can achieve good approximation properties. ", "page_idx": 5}, {"type": "text", "text": "Definition 1 (Barron Space [19]). A function $f:\\mathbb{R}^{D}\\to\\mathbb{R}$ belongs to the Barron space $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ if it can be represented as: ", "page_idx": 5}, {"type": "equation", "text": "$$\nf(\\boldsymbol{x})=\\int_{\\mathbb{R}\\times\\mathbb{R}^{D}\\times\\mathbb{R}}u\\boldsymbol{h}\\left(\\boldsymbol{w^{\\intercal}}\\boldsymbol{x}+\\boldsymbol{b}\\right)d\\mu(\\boldsymbol{u},\\boldsymbol{w},\\boldsymbol{b})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $h$ is an activation function, $\\mu$ is a probability measure on $\\mathbb{R}\\times\\mathbb{R}^{D}\\times\\mathbb{R}$ , and the following Barron norm is finite: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|f\\|_{B}=\\operatorname*{inf}\\left\\{\\int_{\\mathbb{R}\\times\\mathbb{R}^{D}\\times\\mathbb{R}}|u|\\|(w,b)\\|d\\mu(u,w,b):f(x)=\\int_{\\mathbb{R}\\times\\mathbb{R}^{D}\\times\\mathbb{R}}u h\\left(w^{\\top}x+b\\right)d\\mu(u,w,b)\\right\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that the representation of $f$ in the form $\\begin{array}{r}{f(x)=\\int u h\\left(w^{\\top}x+b\\right)d\\mu(u,w,b)}\\end{array}$ may not be unique. The Barron norm seeks the representation that minimizes the integral of $|u|\\|(w,b)\\|$ . The introduction of the Barron norm provides a quantitative measure of the \u201ccomplexity\u201d of a function in the context of neural networks. Functions with a smaller Barron norm are considered simpler and are easier to approximate with neural networks. Next, let\u2019s provide the approximation error analysis for our HyperLogic model (the proof can be found in Appendix D): ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. For any function $f$ in the Barron space, there exist $M$ experts $((w_{1}^{m},u_{1}^{m})$ $\\,\\,,\\,.\\,.\\,.\\,,(w_{K}^{m},u_{K}^{m}))\\,\\,\\in\\,\\,\\mathbb{R}^{(D+1)\\times K}$ , $m\\:=\\:1,\\ldots,M_{},$ , forming a predictor $f_{M}$ as shown in Eq. (7), such that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|f-f_{M}\\|_{L^{2}}\\leq\\frac{\\|f\\|_{\\mathcal{B}}}{\\sqrt{M K}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the $L^{2}$ norm for a function $f:\\mathbb{R}^{D}\\to\\mathbb{R}$ is defined as $\\begin{array}{r}{\\|f\\|_{L^{2}}=\\left(\\int_{\\mathbb{R}^{D}}|f(x)|^{2}d\\mathcal{D}(x)\\right)^{\\frac{1}{2}}}\\end{array}$ where ${\\mathcal{D}}(x)$ is the probability distribution over the input data. ", "page_idx": 5}, {"type": "text", "text": "The above theorem asserts that a HyperLogic model (essentially a mixture of expert models) can approximate any continuous function in the Barron space to arbitrary precision given enough $M,K$ and appropriate weights. ", "page_idx": 5}, {"type": "text", "text": "4.2 Generalization Error: Entropic Regularization and Sparse Regularization ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Let\u2019s derive the generalization error bounds for the HyperLogic model under entropic regularization (the first term of Eq. (6)) and sparse regularization (the second term of Eq. (6)). The key steps involve calculating the Rademacher complexity of the model class and then using this to bound the generalization error. The proof can be found in Appendix E. Let\u2019s give the results here. ", "page_idx": 6}, {"type": "text", "text": "Theorem 2. For the function class $\\begin{array}{r}{\\mathcal{F}_{\\mathrm{KL}}:=\\{f_{\\mu}(\\cdot):D_{\\mathrm{KL}}(\\mu\\|\\mu_{0})\\leq B_{\\mathrm{KL}}\\},}\\end{array}$ , we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}}[\\ell(f)]-\\hat{\\ell}(f)\\le2\\sqrt{\\frac{2B_{\\mathrm{KL}}}{n}}+C\\sqrt{\\frac{\\log(1/\\delta)}{2n}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Similarly, for the function class $\\begin{array}{r}{\\mathcal{F}_{1}:=\\Big\\{f_{\\mu}(\\cdot):\\mathbb{E}_{\\mu}\\Big[\\frac{1}{K}\\sum_{k=1}^{K}|u_{k}|\\Big]\\leq B_{1}\\Big\\}.}\\end{array}$ , we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}}[\\ell(f)]-\\hat{\\ell}(f)\\le64B_{1}\\sqrt{(D+1)/n}+C\\sqrt{\\frac{\\log(1/\\delta)}{n}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Here, $\\mathbb{E}_{\\mathcal{D}}[\\ell(f)]$ is the expected loss over data distribution, $\\hat{\\ell}(f)$ is the empirical loss, n is the number of samples, $C$ is a constant dependent on the loss function, and $\\delta$ is the confidence level. ", "page_idx": 6}, {"type": "text", "text": "From the results, we see that the relative entropy regularization effectively balances ftiting the training data and adhering to the prior distribution with high entropy. Increasing the sample size or decreasing the KL bound enhances the model\u2019s generalization ability, ensuring good performance on unseen data. Similar conclusions can be arrived for the sparse regularization. ", "page_idx": 6}, {"type": "text", "text": "5 Experiment ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we report experimental results to answer the following questions: ", "page_idx": 6}, {"type": "text", "text": "\u2022 RQ1: How does the performance of the optimal rule set selected by HyperLogic compare to the rule sets obtained by other methods?   \n\u2022 RQ2: How rich are the rule sets generated by HyperLogic, and how are their accuracy and diversity affected by parameters?   \n\u2022 RQ3: Can we further leverage the advantages of HyperLogic through ensemble learning to enhance performance? ", "page_idx": 6}, {"type": "text", "text": "5.1 Experiment Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Implementation Details: During training, for each data batch, we randomly generate $M_{1}$ samples of network weights to approximate the expectation (as shown in Eq. (5), here we compute $f_{M_{1}}(x)$ as an approximation in the training stage). Increasing $M_{1}$ enhances the stability of hypernetwork training but raises computational costs. In our experiments, $M_{1}$ is set to 5 or 10 . After training, we generate $M_{2}$ sets of weights from the hypernetwork, resulting in $M_{2}$ rule sets. In other words, in the inference stage, we use $f_{M_{2}}(x)$ instead. While $M_{1}$ is relatively small, $M_{2}$ can be large (e.g., 5000). We then select the rule set with the highest training accuracy as the optimal set, though other criteria, such as minimal loss or custom evaluation metrics balancing accuracy and complexity, can also be used. ", "page_idx": 6}, {"type": "text", "text": "For HyperLogic, We use Adam as the optimizer, and the learning rate is $1\\times10^{-4}$ , with weight decay is $1\\times10^{-4}$ . The number of training epochs is 10000. In the experiments for selecting the optimal rules for comparison, we set hyperparameter $M_{1}\\,=\\,5.$ , $M_{2}\\,=\\,5000$ , $\\lambda_{1}=0.01$ , and $\\lambda_{2}=0.1$ $\\lambda_{1}$ and $\\lambda_{2}$ are related to the hypernetwork loss or regularization loss, as defined in Eq. (6)). In the following experiments that analyze the influence of hyperparameter, we adjusted only the corresponding hyperparameter while keeping others unchanged. ", "page_idx": 6}, {"type": "text", "text": "Datasets: We selected four publicly available binary classification datasets: MAGIC gamma telescope (magic), adult census (adult), FICO HELOC (heloc), and home price prediction (house). In all datasets, preprocessing was performed to encode categorical and numerical attributes as binary variables, which can be found in [17]. We compared our model HyperLogic with other state-of-the-art rule learning methods: DR-Net [17], CG [7], BRS [20], and RIPPER [6]. Since CG, BRS, and RIPPER cannot learn negative conditions, we additionally appended negative conditions for these models. ", "page_idx": 6}, {"type": "text", "text": "5.2 Performance Comparison ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In the performance comparison section, we sampled $M_{2}=5000$ times from HyperLogic, selecting the rule set that performed best on the training set as the optimal rule set, and compared it with other methods. Table 1 presents the comparison of the accuracy of the optimal rule sets selected by our method and those generated by other methods. Our method further improves upon DR-Net and outperforms other methods across all four datasets. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "It is important to note that the rule set that performs best on the training set does not strictly guarantee the best performance on the test set, as shown in Fig. 2. However, this selection method is sufficiently simple, and experiments have shown that it can achieve good performance. ", "page_idx": 7}, {"type": "table", "img_path": "gJbZyKGfd6/tmp/6231f491c8bc64d321aaa707f2e1d6012152b0ee98c06c18f0442d6213657cc2.jpg", "table_caption": ["Table 1: Test accuracy based on a nested 5-fold cross-validation ( $\\%$ , mean $\\pm$ standard error). Results corresponding to methods marked with \\* are directly sourced from [17]. "], "table_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "", "img_caption": ["Figure 2: Train and test accuracies for sampled rule sets across four datasets "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "In addition to rule accuracy, we also considered two metrics to measure the compactness of the rules: model complexity and rule complexity. Model complexity is defined as the sum of the number of rules and the total number of conditions in the rule set; rule complexity is the average number of conditions in each rule of the model. Fig. 3 shows that our method reduces both model complexity and rule complexity compared to DR-Net, indicating that we have not only improved the accuracy of the rules but also made them more concise, demonstrating the effectiveness of our framework. ", "page_idx": 7}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/d904a8a46f0151ee14e254dc1facb7a28e340a82b8c3da925cf07078451c60b4.jpg", "img_caption": ["Figure 3: Model complexity and rule complexity comparison "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "5.3 Rule Analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we primarily considered the effects of three parameters, $M_{1}$ , $\\lambda_{1}$ , and $M_{2}$ , on the learned rules. Among these, $M_{2}$ primarily affects the selection of the final optimal rule set by controlling the number of candidate rule sets sampled from the hypernetwork after training phase, while $M_{1}$ and $\\lambda_{1}$ directly influence the training of the hypernetwork. ", "page_idx": 7}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/0ae001e6c00f70b3fd71cf52facaff30b83af25f8a05dd75f7ec50aeb4cd630a.jpg", "img_caption": ["Figure 4: Analysis of the impact of $M_{2}$ on all datasets "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "For $M_{2}$ , we considered the values 10, 100, 1000, 2000, 5000, and 10000 to examine its impact on the accuracy, model complexity, and rule complexity of the generated optimal rules, as shown in Fig. ", "page_idx": 7}, {"type": "text", "text": "4. It can be observed that the accuracy, model complexity, and rule complexity of the optimal rules generally increase with the increase of $M_{2}$ , and then level off or slightly decrease. This is because, when $M_{2}$ is small, we may not be able to sample sufficiently suitable rule sets to fit the training set. When $M_{2}$ is too large, the sampled optimal rule set is more likely to overfit the training set, leading to a slight decrease in test accuracy. ", "page_idx": 8}, {"type": "text", "text": "So far, we have focused on the optimal rule set extracted from the hypernetwork. Table 2 further shows the different optimal results obtained in three training sessions for the heloc dataset, indicating that we can find different high-quality rule sets in different training sessions. However, considering only one optimal rule set is not enough to reflect the advantage of the hypernetwork in generating multiple high-quality rule sets in one training session, which provides more options and a deeper understanding of the data, something that methods learning only one set of rules cannot offer. ", "page_idx": 8}, {"type": "table", "img_path": "gJbZyKGfd6/tmp/dad228050c17f75c870b8a450facdde839ec3e281b0471b1aefa715b70e4df16.jpg", "table_caption": ["Table 2: Examples of optimal rule sets learned from different training runs on the heloc dataset "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "The ability of the hypernetwork to generate diverse rules is mainly related to $M_{1}$ and $\\lambda_{1}.\\,\\lambda_{1}$ , as the coefficient of diversity regularization term, directly affects the diversity of the hypernetwork output, while $M_{1}$ indirectly affects the process by influencing the stability of hypernetwork updates. For the impacts of $M_{1}$ and $\\lambda_{1}$ , we are no longer concerned with the optimal rule set but focus on all the rule sets generated by the hypernetwork, and describe the diversity and accuracy of the rule sets as a whole. ", "page_idx": 8}, {"type": "text", "text": "The diversity of the rules is measured in two aspects: 1. How many different rule sets can we generate by sampling a certain number of weights from the hypernetwork? 2. What is the degree of similarity between the generated different rule sets? We use Jaccard similarity to measure this. ", "page_idx": 8}, {"type": "text", "text": "We take the magic dataset as an example to analyze $M_{1}$ and $\\lambda_{1}$ ; the results for the remaining datasets are in Appendix F. The impact of $M_{1}$ on rule diversity and test accuracy is shown in Fig. 5. It can be seen that when $M_{1}=5$ , there is the best performance in all aspects. This may be because, when $M_{1}$ is small, the hypernetwork generates weights fewer times, making the training less stable. When $M_{1}$ is too large, the training and updates of the hypernetwork become too stable and conservative, slowing down the convergence speed and resulting in a performance decline of the hypernetwork. ", "page_idx": 8}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/dc6fdd11f9a20b00fda307906fa9be789d535c2a3b74068a8a730cd782cef3ce.jpg", "img_caption": ["Figure 5: Analysis of the impact of $M_{1}$ on magic dataset "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "The impact of $\\lambda_{1}$ on rule diversity and test accuracy is shown in Fig. 6. It can be seen that increasing $\\lambda_{1}$ significantly enhances the diversity of the rule sets, but excessive emphasis on rule diversity may affect the accuracy of the rules. ", "page_idx": 9}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/fb8e955d9d55ccf9eb16d72ea13471c7c7734a7c6bef460355d9520487777dcc.jpg", "img_caption": ["Figure 6: Analysis of the impact of $\\lambda_{1}$ on magic dataset "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "5.4 Ensemble Learning ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Since the hypernetwork can generate a diverse and rich set of rule sets, a natural idea is to use ensemble learning to achieve better classification performance. We use the simple averaging voting method for ensemble learning. We select the top $L$ rule sets based on their accuracy on the training set and report their accuracy on the test set. The values of $L$ are 1, 5, 10, 30, 50, 100, and 200. As shown in Fig. 7, the test accuracy initially increases with the increase of $L$ , then slightly decreases. ", "page_idx": 9}, {"type": "text", "text": "This may because the top single rule set is already highly effective, leaving little room for improvement. When $L$ is too large, less effective rule sets decrease the ensemble\u2019s overall performance. Additionally, our current strategy focuses on balancing diversity and accuracy of single rule sets. Adjusting the strategy specifically for ensemble learning could yield better results. ", "page_idx": 9}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/a8532c70df0f15d973be51a76e41c2bcc0a34752e82b863ebd632bc05fd53b83.jpg", "img_caption": ["Figure 7: Test accuracy using top $L$ rule sets in ensemble learning. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we proposed HyperLogic, a novel framework that enhances the field of differentiable rule learning through the integration of hypernetworks. We also provided a theoretical foundation for HyperLogic\u2019s performance, explaining its effectiveness. This includes an analysis of approximation error and generalization capabilities under sparsity and diversity regularization. What\u2019s more, we conducted extensive experiments on multiple datasets, demonstrating that HyperLogic accelerates the training process while producing more concise and accurate rules. ", "page_idx": 9}, {"type": "text", "text": "Despite these advancements, HyperLogic introduces additional hyperparameters and requires further exploration of ensemble learning within this framework. Future research will focus on alternative training strategies, more stable weight combination methods, and applying HyperLogic to a broader range of datasets and tasks to enhance its generality and practicality. ", "page_idx": 9}, {"type": "text", "text": "7 Broader Impacts ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The development and utilization of interpretable logic rules through HyperLogic have significant positive societal impacts, particularly in high-risk domains such as healthcare, finance, and legal systems. By generating multiple candidate rule sets, HyperLogic provides more flexible and comprehensive insights, enhancing transparency and trust in decision-making processes. This is crucial for ensuring safety and regulatory compliance. However, it is important to note that while our method provides richer rule sets and aids experts in understanding data patterns, these rules should complement rather than replace expert judgment. Relying solely on automated rules without expert oversight in critical areas could pose significant risks. Thus, our approach emphasizes the collaborative role of machine learning models and human experts to mitigate potential negative impacts. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Shuang Li\u2019s research was in part supported by the National Science and Technology Major Project under grant No. 2022ZD0116004, the NSFC under grant No. 62206236, Shenzhen Stability Science Program 2023, Shenzhen Key Lab of Cross-Modal Cognitive Computing under grant No. ZDSYS20230626091302006, Longgang District Key Laboratory of Intelligent Digital Economy Security, and SRIBD Innovation Fund SIF20240010. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Paul Voigt and Axel Von dem Bussche. The eu general data protection regulation (gdpr). A Practical Guide, 1st Ed., Cham: Springer International Publishing, 10(3152676):10\u20135555, 2017.   \n[2] Michelle Goddard. The eu general data protection regulation (gdpr): European regulation that has a global impact. International Journal of Market Research, 59(6):703\u2013705, 2017. [3] David Gunning, Mark Stefik, Jaesik Choi, Timothy Miller, Simone Stumpf, and Guang-Zhong Yang. Xai\u2014explainable artificial intelligence. Science robotics, 4(37):eaay7120, 2019.   \n[4] Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature machine intelligence, 1(5):206\u2013215, 2019.   \n[5] Cynthia Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia Semenova, and Chudi Zhong. Interpretable machine learning: Fundamental principles and 10 grand challenges. Statistic Surveys, 16:1\u201385, 2022.   \n[6] William W Cohen. Fast effective rule induction. In Machine learning proceedings 1995, pages 115\u2013123. Elsevier, 1995. [7] Sanjeeb Dash, Oktay Gunluk, and Dennis Wei. Boolean decision rules via column generation. Advances in neural information processing systems, 31, 2018.   \n[8] Mark Law, Alessandra Russo, Elisa Bertino, Krysia Broda, and Jorge Lobo. Fastlas: Scalable inductive logic programming incorporating domain-specific optimisation criteria. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 2877\u20132885, 2020.   \n[9] Andrew Cropper and Rolf Morel. Learning programs by learning from failures. Machine Learning, 110(4):801\u2013856, 2021.   \n[10] Richard Evans and Edward Grefenstette. Learning explanatory rules from noisy data. Journal of Artificial Intelligence Research, 61:1\u201364, 2018.   \n[11] Fan Yang, Zhilin Yang, and William W Cohen. Differentiable learning of logical rules for knowledge base reasoning. Advances in neural information processing systems, 30, 2017.   \n[12] Ali Sadeghian, Mohammadreza Armandpour, Patrick Ding, and Daisy Zhe Wang. Drum: End-to-end differentiable rule mining on knowledge graphs. Advances in Neural Information Processing Systems, 32, 2019.   \n[13] Yuan Yang and Le Song. Learn to explain efficiently via neural logic inductive learning. arXiv preprint arXiv:1910.02481, 2019.   \n[14] Kewei Cheng, Nesreen K Ahmed, and Yizhou Sun. Neural compositional rule learning for knowledge graph reasoning. arXiv preprint arXiv:2303.03581, 2023.   \n[15] Hikaru Shindo, Masaaki Nishino, and Akihiro Yamamoto. Differentiable inductive logic programming for structured examples. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 5034\u20135041, 2021.   \n[16] Claire Glanois, Zhaohui Jiang, Xuening Feng, Paul Weng, Matthieu Zimmer, Dong Li, Wulong Liu, and Jianye Hao. Neuro-symbolic hierarchical rule induction. In International Conference on Machine Learning, pages 7583\u20137615. PMLR, 2022.   \n[17] Litao Qiao, Weijia Wang, and Bill Lin. Learning accurate and interpretable decision rule sets from neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 4303\u20134311, 2021.   \n[18] Ruixuan Yan, Yunshi Wen, Debarun Bhattacharjya, Ronny Luss, Tengfei Ma, Achille Fokoue, and Anak Agung Julius. Weighted clock logic point process. In International Conference on Learning Research (ICLR) 2023, 2023.   \n[19] Tong Zhang. Mathematical analysis of machine learning algorithms. Cambridge University Press, 2023.   \n[20] Tong Wang, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampf,l and Perry MacNeille. A bayesian framework for learning rule sets for interpretable classification. Journal of Machine Learning Research, 18(70):1\u201337, 2017.   \n[21] Wei Zhang, Yongxiang Liu, Zhuo Wang, and Jianyong Wang. Learning to binarize continuous features for neuro-rule networks. In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, pages 4584\u20134592, 2023.   \n[22] Nuri Cingillioglu and Alessandra Russo. pix2rule: End-to-end neuro-symbolic rule learning. arXiv preprint arXiv:2106.07487, 2021.   \n[23] Zohreh Shams, Botty Dimanov, Sumaiyah Kola, Nikola Simidjievski, Helena Andres Terre, Paul Scherer, Ur\u0161ka Matja\u0161ec, Jean Abraham, Pietro Li\u00f2, and Mateja Jamnik. Rem: an integrative rule extraction methodology for explainable data analysis in healthcare. medRxiv, pages 2021\u201301, 2021.   \n[24] Mateo Espinosa Zarlenga, Zohreh Shams, and Mateja Jamnik. Efficient decompositional rule extraction for deep neural networks. arXiv preprint arXiv:2111.12628, 2021.   \n[25] Shaoyun Shi, Yuexiang Xie, Zhen Wang, Bolin Ding, Yaliang Li, and Min Zhang. Explainable neural rule learning. In Proceedings of the ACM Web Conference 2022, pages 3031\u20133041, 2022.   \n[26] Lu Yu, Meng Li, Xiaoguang Huang, Wei Zhu, Yanming Fang, Jun Zhou, and Longfei Li. Metarule: A meta-path guided ensemble rule set learning for explainable fraud detection. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, pages 4650\u20134654, 2022.   \n[27] Lu Yu, Meng Li, Ya-Lin Zhang, Longfei Li, and Jun Zhou. Finrule: Feature interactive neural rule learning. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, pages 3020\u20133029, 2023.   \n[28] Zhuo Wang, Wei Zhang, Ning Liu, and Jianyong Wang. Scalable rule-based representation learning for interpretable classification. Advances in Neural Information Processing Systems, 34:30479\u201330491, 2021.   \n[29] Remy Kusters, Yusik Kim, Marine Collery, Christian de Sainte Marie, and Shubham Gupta. Differentiable rule induction with learned relational features. arXiv preprint arXiv:2201.06515, 2022.   \n[30] Nils Philipp Walter, Jonas Fischer, and Jilles Vreeken. Finding interpretable class-specific patterns through efficient neural search. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 9062\u20139070, 2024.   \n[31] Vinod Kumar Chauhan, Jiandong Zhou, Ping Lu, Soheila Molaei, and David A Clifton. A brief review of hypernetworks in deep learning. arXiv preprint arXiv:2306.06955, 2023.   \n[32] Johannes Von Oswald, Christian Henning, Benjamin F Grewe, and Jo\u00e3o Sacramento. Continual learning with hypernetworks. arXiv preprint arXiv:1906.00695, 2019.   \n[33] Yizhou Huang, Kevin Xie, Homanga Bharadhwaj, and Florian Shkurti. Continual model-based reinforcement learning with hypernetworks. In 2021 IEEE International Conference on Robotics and Automation (ICRA), pages 799\u2013805. IEEE, 2021.   \n[34] Tomer Volk, Eyal Ben-David, Ohad Amosy, Gal Chechik, and Roi Reichart. Example-based hypernetworks for out-of-distribution generalization. arXiv preprint arXiv:2203.14276, 2022.   \n[35] David Krueger, Chin-Wei Huang, Riashat Islam, Ryan Turner, Alexandre Lacoste, and Aaron Courville. Bayesian hypernetworks. arXiv preprint arXiv:1710.04759, 2017.   \n[36] Neale Ratzlaff and Li Fuxin. Hypergan: A generative model for diverse, performant neural networks. In International Conference on Machine Learning, pages 5361\u20135369. PMLR, 2019.   \n[37] Rabeeh Karimi Mahabadi, Sebastian Ruder, Mostafa Dehghani, and James Henderson. Parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks. arXiv preprint arXiv:2106.04489, 2021.   \n[38] Lorenz K Muller. Overparametrization of hypernetworks at fixed flop-count enables fast neural image enhancement. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 284\u2013293, 2021.   \n[39] Fulton Wang and Cynthia Rudin. Falling rule lists. In Artificial intelligence and statistics, pages 1013\u20131022. PMLR, 2015.   \n[40] Chaofan Chen and Cynthia Rudin. An optimization approach to learning falling rule lists. In International conference on artificial intelligence and statistics, pages 604\u2013612. PMLR, 2018.   \n[41] Hugo M Proen\u00e7a and Matthijs van Leeuwen. Interpretable multiclass classification by mdl-based rule lists. Information Sciences, 512:1372\u20131393, 2020.   \n[42] Lucile Dierckx, Rosana Veroneze, and Siegfried Nijssen. Rl-net: Interpretable rule learning with neural networks. In Pacific-Asia Conference on Knowledge Discovery and Data Mining, pages 95\u2013107. Springer, 2023.   \n[43] Hongyu Yang, Cynthia Rudin, and Margo Seltzer. Scalable bayesian rule lists. In International conference on machine learning, pages 3921\u20133930. PMLR, 2017.   \n[44] Fernando Jim\u00e9nez, Gracia S\u00e1nchez, and Jos\u00e9 M Ju\u00e1rez. Multi-objective evolutionary algorithms for fuzzy classification in survival prediction. Artificial intelligence in medicine, 60(3):197\u2013219, 2014. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Compare with classical rule learning methods ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We first compare HyperLogic with falling rule lists(FRL) methods like [39, 40, 41], which are often used in practice. FRL methods explicitly construct a falling list of rules with probabilities; Differentiable HyperLogic focuses on directly mining patterns and generating rules from data in a scalable manner using neural networks. Our differentiable approach demonstrates better scalability for pattern mining tasks on large-scale data (see Section 2). The main differences between FRL and the HyperLogic are: ", "page_idx": 13}, {"type": "text", "text": "1. Rule Generation: ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 FRL methods rely on other rule mining techniques to generate initial candidate rules. \u2022 HyperLogic uses a differentiable neural network approach to directly mine patterns and generate rules from data in an end-to-end manner. ", "page_idx": 13}, {"type": "text", "text": "2. Scalability: ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 FRL methods may face scalability issues when dealing with large candidate rule sets or complex data.   \n\u2022 HyperLogic, a neural network-based approach, is more scalable for pattern mining in large-scale data. ", "page_idx": 13}, {"type": "text", "text": "3. Rule Ordering: ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 FRL methods explicitly order the rules into a descending list based on rule probabilities or other criteria.   \n\u2022 HyperLogic generates an unordered set of rules. ", "page_idx": 13}, {"type": "text", "text": "4. Probabilistic Interpretation: ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 FRL methods provide probabilistic interpretations for the rules by construction. \u2022 HyperLogic does not directly output rule probabilities, although probabilities could potentially be derived from the learned patterns. . Integration Potential: A recent study [42] proposed a neural method to learn ordered rule lists, which could potentially be integrated with HyperLogic to enable joint rule generation and probabilistic ordering, combining the strengths of both approaches. ", "page_idx": 13}, {"type": "text", "text": "Other statistical rule mining methods like Bayesian rule lists [43] and Bayesian decision sets [20] provide probabilistic interpretations but are limited to binary classification and small rule sets. Fuzzy rule-based models [44] incorporate human-like reasoning but lack probabilistic predictions and scalability. In the supplementary experiments B, we include the current advanced traditional rule learning method CLASSY in the comparison to further demonstrate the advantages of our method over traditional methods. ", "page_idx": 13}, {"type": "text", "text": "B Results for HyperLogic with DIFFNAPS ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "To expand our experiments to larger and more complicated cases, we considered the latest NeuroSymbolic algorithm DIFFNAPS [30], which is capable of pattern mining under large-scale data conditions. For HyperLogic, we selected only the classifier part of DIFFNAPS as the main network to compare with vanilla DIFFNAPS. ", "page_idx": 13}, {"type": "text", "text": "B.1 Large Synthetic Datasets ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Following the original experiments, we tested the model\u2019s pattern mining performance under a fixed input dimension of 5000 and varying total number of categories K (ranging from 2 to 50), measured by the F1 score, with each category containing 1000 samples. ", "page_idx": 13}, {"type": "text", "text": "Compared with the current data set, in our new data set, the feature dimension has been raised from a maximum of 154 dimensions to a maximum of $\\mathbf{5k}$ dimensions, the amount of data has been raised from a maximum of 24,000 to a maximum of 50,000, and the task has been raised from a maximum of 2 categories to a maximum of 50 categories, reflecting the characteristics of the task diversity and complexity. ", "page_idx": 13}, {"type": "text", "text": "The experimental results are shown in the table below. It can be seen that in datasets with fewer categories, due to the smaller total number of samples, HyperLogic has not yet received sufficient training and does not perform ideally. However, in more challenging classification datasets with an increased number of samples, the model\u2019s performance has significantly improved, with an average F1 score increase of ${\\bf6}\\%$ . This fully demonstrates that our framework can empower diverse neural rule learning networks, capable of handling large-scale data and possessing a good range of applications. ", "page_idx": 13}, {"type": "table", "img_path": "gJbZyKGfd6/tmp/2fef287dd8adab5d167708a212388b90942899bc4cb12e3788dcccfe0140cc22.jpg", "table_caption": [], "table_footnote": ["Table 3: The F1 score (\u00b1 std) of two methods among 11 synthetic datasets "], "page_idx": 14}, {"type": "text", "text": "B.2 Large Real Datasets ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We evaluated our method on four large biological datasets following the settings of DIFFNAPS: Cardio, Disease, BRCA-N, and BRCA-S, using the area under the curve (AUC) as the metric. We continued to combine our approach (HyperLogic) with DIFFNAPS as the main network and compared it to vanilla DIFFNAPS. Additionally, FRL [39] cannot scale to non-trivial data, while CLASSY [41] was already compared in the original paper. ", "page_idx": 14}, {"type": "text", "text": "The table shows the dataset details (i.e. samples $(n)$ , features $(D)$ , and classes (K)), number of discovered patterns (#P), average pattern length (|P|), and AUC scores (results for DIFFNAPS and CLASSY are taken directly from [30]). ", "page_idx": 14}, {"type": "table", "img_path": "gJbZyKGfd6/tmp/6dcc5a7cad64c62e7cfe20a8f3a12653b71bb6b1db3c08158489f389fc874e5a.jpg", "table_caption": [], "table_footnote": ["Table 4: Comparison of HyperLogic, DIFFNAPS, and CLASSY across 4 real datasets. "], "page_idx": 14}, {"type": "text", "text": "CLASSY lacks the finesse to effectively mine patterns for large-scale real-world tasks. Moreover, despite competing with the strong DIFFNAPS baseline, HyperLogic achieved further improvements, demonstrating its potential for handling large, real-world datasets. ", "page_idx": 14}, {"type": "text", "text": "C Hypernetwork Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We adopted HyperGAN as our hypernetwork. Assuming the main network comprises $N$ distinct weight partitions, HyperGAN includes a mixer $Q$ and $N$ generators $G_{1},G_{2},\\ldots,G_{N}$ . ", "page_idx": 14}, {"type": "text", "text": "Mixer $Q$ : Receives high-dimensional Gaussian distributed random samples $s\\,\\sim\\,{\\mathcal{N}}(0,I)$ , and transforms it into a $N\\times h$ dimensional vector $z$ , further split into $N$ samples of $h$ -dimensional vectors $z_{1},z_{2},\\dots,z_{N}$ . The mixer\u2019s design reflects the necessity for correlations between layer weights, as each layer\u2019s output becomes the subsequent layer\u2019s input. ", "page_idx": 14}, {"type": "text", "text": "Generators $G_{i}$ : Each generator receives a vector $z_{i}$ from the mixer, producing an output vector of dimension $m_{i}$ , where $m_{i}$ represents the parameter count for the $i$ -th part of the network weights. These vectors are then reshaped to meet the specifications of the corresponding layers in the main network. ", "page_idx": 14}, {"type": "text", "text": "In our specific task, the number of generators $N$ is set to 2, and each generator\u2019s input dimension $h$ is 64. The input dimension of the Mixer, which is the sampled noise, is 256, and it produces an output of $N\\times h=128$ . Each of the above models has two hidden layers with dimension 512, and the activation function is ReLu. ", "page_idx": 14}, {"type": "text", "text": "Our main network is designed to generate $K=50$ rules. For a dataset with dimension $D$ : ", "page_idx": 14}, {"type": "text", "text": "\u2022 Generator 1: Produces an output of dimension $(D\\times K,1)$ , representing the Rule layer.   \n\u2022 Generator 2: Produces an output of dimension $(K\\times1,1)$ , representing the OR layer. ", "page_idx": 14}, {"type": "text", "text": "These outputs are then reshaped to meet the specifications of the corresponding layers in the main network. ", "page_idx": 15}, {"type": "text", "text": "D Proof for Theorem 1 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof. Using Barron\u2019s theorem (e.g., [19, Theorem 11.3]), there exist weight coefficients $(w_{k}^{m},\\tilde{u}_{k}^{m})$ , $m=1,\\ldots,M,k=1,\\ldots,K$ , such that the function $\\tilde{f}$ defined by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\tilde{f}(\\boldsymbol{x})=\\frac{1}{M K}\\sum_{m=1}^{M}\\sum_{k=1}^{K}\\tilde{u}_{k}^{m}h\\left((\\boldsymbol{w}_{k}^{m})^{\\top}\\boldsymbol{x}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "satisfies ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|f-\\tilde{f}\\|_{L^{2}}\\leq\\frac{\\|f\\|_{B}}{\\sqrt{M K}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Setting $u_{k}^{m}=\\tilde{u}_{k}^{m}/K$ , $w^{m}=(w_{1}^{m},\\dots,w_{K}^{m})$ , $\\boldsymbol{u^{m}}=\\left(u_{1}^{m},\\dots,u_{K}^{m}\\right)$ yields the desired result. ", "page_idx": 15}, {"type": "text", "text": "E Proof for Theorem 2 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "E.1 Generalization Error: Diverse Regularization ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Let us compute the Rademacher complexity of the model class ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}_{\\mathrm{KL}}:=\\bigg\\{f_{\\mu}(\\cdot):D_{\\mathrm{KL}}(\\mu\\|\\mu_{0})\\leq B_{\\mathrm{KL}}\\bigg\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\mu_{0}$ is a product distribution ${\\tilde{\\mu}_{0}}^{\\otimes K}$ . Using the property of relative entropy, for each pair of marginal distributions $\\mu_{k}$ and $\\tilde{\\mu}_{0}$ , $k=1,\\ldots,K$ , their relative entropy satisfies $\\dot{D_{\\mathrm{KL}}}(\\mu_{k}\\|\\tilde{\\mu}_{0})\\overset{\\footnotesize-}{\\leq}B_{\\mathrm{KL}}$ . Using the convexity of the relative entropy, the mixture distribution $\\tilde{\\mu}$ satisfies $D_{\\mathrm{KL}}(\\tilde{\\mu}\\Vert\\tilde{\\mu}_{0})\\leq B_{\\mathrm{KL}}$ . Hence, the function class ${\\mathcal{F}}_{\\mathrm{KL}}$ belongs to the function class ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\tilde{\\mathcal{F}}_{\\mathrm{KL}}:=\\bigg\\{\\tilde{f}_{\\tilde{\\mu}}(\\cdot):D_{\\mathrm{KL}}(\\tilde{\\mu}\\|\\tilde{\\mu}_{0})\\leq B_{\\mathrm{KL}}\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Using [19, Corollary 10.17], the Rademacher complexity of $\\tilde{\\mathcal{F}}_{\\mathrm{KL}}$ is bounded by $\\sqrt{2B_{\\mathrm{KL}}/n}$ . Given our bound on the Rademacher complexity, for $f\\in\\tilde{\\mathcal{F}}_{\\mathrm{KL}}$ , we get: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}}[\\ell(f)]-\\hat{\\ell}(f)\\le2\\sqrt{\\frac{2B_{\\mathrm{KL}}}{n}}+C\\sqrt{\\frac{\\log(1/\\delta)}{2n}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\mathbb{E}_{\\mathcal{D}}[\\ell(f)]$ is the expected loss, $\\hat{\\ell}(f)$ is the empirical loss, $n$ is the number of samples, $C$ is a constant dependent on the loss function, and $\\delta$ is the confidence level. ", "page_idx": 15}, {"type": "text", "text": "E.2 Generalization Error: Sparse Regularization ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Next, we will derive the generalization error bounds for the HyperLogic model under sparse regularization (as shown in the second term of Eq. (6 )). ", "page_idx": 15}, {"type": "text", "text": "Let us compute the Rademacher complexity of the model class ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{F}_{1}:=\\bigg\\{\\widetilde{f}_{\\mu}(\\cdot):\\mathbb{E}_{\\mu}\\Big[\\frac{1}{K}\\sum_{k=1}^{K}|u_{k}|\\Big]\\leq B_{1}\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Observe that the constraint $\\begin{array}{r}{\\mathbb{E}_{\\mu}\\left[\\frac{1}{K}\\sum_{k=1}^{K}|u_{k}|\\right]\\leq B_{1}}\\end{array}$ implies that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\tilde{\\mu}}\\left[\\left|\\tilde{u}\\right|\\right]=\\mathbb{E}_{\\mu}\\left[\\left|\\frac{1}{K}\\sum_{k=1}^{K}u_{k}\\right|\\right]\\le\\mathbb{E}_{\\mu}\\left[\\frac{1}{K}\\sum_{k=1}^{K}\\left|u_{k}\\right|\\right]\\le B_{1}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Hence, the function class $\\mathcal{F}$ belongs to the function class ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\tilde{\\mathcal{F}}_{1}:=\\bigg\\{\\tilde{f}_{\\tilde{\\mu}}(\\cdot):\\mathbb{E}_{\\tilde{\\mu}}\\left[|\\tilde{u}|\\right]\\leq B_{1}\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Using [19, Proposition 11.23], the Rademacher complexity of $\\tilde{\\mathcal{F}}_{1}$ is bounded by $32B_{1}\\sqrt{(D+1)/n}$ The generalization error bound for the HyperLogic model under sparse regularization, derived from the Rademacher complexity, can be expressed as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{D}}[\\ell(f)]-\\hat{\\ell}(f)\\le64B_{1}\\sqrt{(D+1)/n}+C\\sqrt{\\frac{\\log(1/\\delta)}{n}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The explaination of this error bound is similar with the previous one. ", "page_idx": 15}, {"type": "text", "text": "F Supplementary Result ", "text_level": 1, "page_idx": 16}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/f0778fcd4e9c0c95a69e96037f27cc3b0515413e459ee9ee229537e739e92106.jpg", "img_caption": ["Figure 8: Analysis of the impact of $M_{1}$ on adult dataset "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/e09c72aceeed15e132a43a0daaa692922204a8b6c5615329c3c5f482cc9dee86.jpg", "img_caption": ["Figure 9: Analysis of the impact of $\\lambda_{1}$ on adult dataset "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/c11a57dd56afa691c08031bf30e91138852b31024855ee8d24c725123a2af744.jpg", "img_caption": ["Figure 10: Analysis of the impact of $M_{1}$ on house dataset "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/010e3ec740fb8b714f1cc6159c1dc7da15b623db657de24d6f1fbd653d54a9d8.jpg", "img_caption": ["Figure 12: Analysis of the impact of $M_{1}$ on heloc dataset "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/18d74bcf8704236c19b7c03c8752a82919db3bf8b31bf8122b17d48ab118dbd2.jpg", "img_caption": ["Figure 13: Analysis of the impact of $\\lambda_{1}$ on heloc dataset "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "gJbZyKGfd6/tmp/3d69bc276f5ad0076e18d2cd9ff61b2ddaab3c49513759c33c15a17c65c7910c.jpg", "img_caption": ["Figure 11: Analysis of the impact of $\\lambda_{1}$ on house dataset "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "G Computing Infrastructure ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For our method, all experiments were conducted on a Linux server with an Intel(R) Xeon(R) Gold 6248R CPU $\\textcircled{a}3.00\\mathrm{GHz}$ and 30Gi of memory, running Ubuntu 20.04.5 LTS, using one of the NVIDIA GeForce RTX 3090 GPUs available on the server. Each experimental run took approximately 10-20 minutes to complete. This setup ensures that our experiments are reproducible and efficient. ", "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": ". Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We demonstrate our innovations and contributions in the abstract and introduction. We also mention the important assumptions and limitations of our methods. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We discuss the limitations of our proposed model in the conclusion part. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 18}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We provide theoretical proofs about our proposed model in the theoretical analysis section.   \nGuidelines: ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: We provide the details of hyper parameters and neural network structures for reproducibility. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The code will be made publicly available upon the paper\u2019s acceptance. Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We provide all the training and test details including hyperparameters, type of optimizer, learning rates, hidden layers of networks in the appendix. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: Our rule performance results mean accuracy with the standard error across a nested 5-fold cross-validation. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). ", "page_idx": 20}, {"type": "text", "text": "\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We demonstrate the computer resource requirements in the appendix. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: The research presented in our paper fully complies with the NeurIPS Code of Ethics in all aspects. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 21}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: We discuss potential positiveand negative societal impacts of the work in the appendix. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. ", "page_idx": 21}, {"type": "text", "text": "\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Justification: Our paper poses no such risks. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 22}, {"type": "text", "text": "Justification: We cite the original paper that produced the dataset. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 22}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA]   \nJustification: Our paper does not release new assets. Guidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our paper does not involve study participants. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}]