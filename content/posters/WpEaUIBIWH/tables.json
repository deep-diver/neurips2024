[{"figure_path": "WpEaUIBIWH/tables/tables_8_1.jpg", "caption": "Table 2: Runtime Comparison. The runtime is reported in seconds (s).", "description": "This table compares the runtime performance of several anomaly detection methods.  The methods are compared in terms of fitting time and inference time. UniCAD demonstrates a significantly faster inference time than other methods, making it more efficient for real-time applications.", "section": "4 Experiments"}, {"figure_path": "WpEaUIBIWH/tables/tables_8_2.jpg", "caption": "Table 1: AUCROC of 10 unsupervised algorithms on 30 tabular benchmark datasets. In each dataset, the algorithm with the highest AUCROC is marked in red, the second highest in blue, and the third highest in green.", "description": "This table presents the AUC-ROC scores achieved by 10 unsupervised anomaly detection algorithms across 30 different tabular datasets.  The best performing algorithm for each dataset is highlighted in red, the second best in blue, and the third best in green. This allows for a direct comparison of the performance of different algorithms on a variety of datasets, reflecting their strengths and weaknesses in different contexts.", "section": "4.3 Performance and Analysis"}, {"figure_path": "WpEaUIBIWH/tables/tables_17_1.jpg", "caption": "Table 1: AUCROC of 10 unsupervised algorithms on 30 tabular benchmark datasets. In each dataset, the algorithm with the highest AUCROC is marked in red, the second highest in blue, and the third highest in green.", "description": "This table presents the AUC-ROC scores achieved by ten unsupervised anomaly detection algorithms across thirty tabular datasets.  The best performing algorithm for each dataset is highlighted in red, the second-best in blue, and the third-best in green.  This allows for a comparison of the relative performance of different algorithms across a variety of datasets.", "section": "4.3 Performance and Analysis"}, {"figure_path": "WpEaUIBIWH/tables/tables_19_1.jpg", "caption": "Table 5: AUCROC of 17 unsupervised algorithms on 30 tabular benchmark datasets. In each dataset, the algorithm with the highest AUCROC is marked in red, the second highest in blue, and the third highest in green.", "description": "This table presents a comprehensive comparison of UniCAD's performance against 17 state-of-the-art unsupervised anomaly detection methods across 30 diverse tabular datasets.  The AUC-ROC (Area Under the Receiver Operating Characteristic) metric is used to evaluate the performance of each algorithm on each dataset. The highest, second highest, and third highest AUC-ROC scores for each dataset are highlighted in red, blue, and green respectively, providing a clear visual representation of the relative performance of each algorithm.", "section": "4.3 Performance and Analysis"}, {"figure_path": "WpEaUIBIWH/tables/tables_20_1.jpg", "caption": "Table 4: Statistics of tabular benchmark datasets.", "description": "This table presents the characteristics of 30 tabular datasets used in the paper's experiments.  For each dataset, it lists the number of samples, the number of features, the percentage of anomalies, and the number of actual anomalies.  The category of each dataset is also provided.", "section": "4.1 Datasets & Baselines"}, {"figure_path": "WpEaUIBIWH/tables/tables_20_2.jpg", "caption": "Table 8: AUC-ROC and AUC-PR of 16 unsupervised algorithms on 4 graph benchmark datasets.", "description": "This table presents the performance comparison of 16 unsupervised anomaly detection methods (including UniCAD) on four graph benchmark datasets.  The performance is measured using two metrics: AUC-ROC and AUC-PR. The table is divided into three groups based on the anomaly detection methods used: Contrastive Learning-based, Autoencoder-based, and Clustering-based methods. UniCAD is marked with an asterisk (*).", "section": "E.3 Experiment Settings"}]