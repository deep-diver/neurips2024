[{"figure_path": "RzlCqnncQv/tables/tables_2_1.jpg", "caption": "Table 1: Summary of comparison to most closely related prior studies.*Require at least one problem instance to be translated by a human into the target domain as an in-context example.", "description": "This table compares the proposed approach with three other related studies in terms of their ability to translate planning problems and domains from natural language into PDDL (Planning Domain Definition Language) and whether human intervention is required in the translation process.  The table highlights that the proposed method is unique in its ability to achieve both problem and domain translation automatically without human intervention.", "section": "Direct Reasoning with LLMs"}, {"figure_path": "RzlCqnncQv/tables/tables_9_1.jpg", "caption": "Table 2: Best@4 (Tasks solved / Exploration Walk) for different domains. For intrinsic planning no domain is generated, therefore the EW score is not defined.", "description": "This table presents the results of experiments comparing different methods for automated PDDL translation and planning.  The methods include intrinsic planning with and without chain-of-thought prompting, as well as the proposed methods (P&D Chain, P&D Tree, and P&D Tree + DomProp) with varying numbers of LLM calls.  For each method and for each of ten environments, the table shows the percentage of tasks successfully solved and the average Exploration Walk (EW) score.  The EW score measures the similarity between the generated domain PDDL and the ground truth domain PDDL.", "section": "5 Experiments"}, {"figure_path": "RzlCqnncQv/tables/tables_12_1.jpg", "caption": "Table 2: Best@4 (Tasks solved / Exploration Walk) for different domains. For intrinsic planning no domain is generated, therefore the EW score is not defined.", "description": "This table presents the results of four different methods for solving planning problems across ten different domains.  The methods include two intrinsic planning baselines (with and without chain-of-thought prompting) and two proposed methods (P&D Chain and P&D Tree, with a variation: P&D Tree + DomProp). The table shows the \"Best@4\" performance for each domain, representing the best result out of four independent runs. The results are shown as a fraction of tasks successfully solved and the average Exploration Walk (EW) score which measures the similarity of the generated domain to the ground truth domain.  The EW score is undefined for the intrinsic planning methods as they don't generate a domain.", "section": "Experiments"}, {"figure_path": "RzlCqnncQv/tables/tables_18_1.jpg", "caption": "Table 2: Best@4 (Tasks solved / Exploration Walk) for different domains. For intrinsic planning no domain is generated, therefore the EW score is not defined.", "description": "This table presents the results of four different methods for solving planning tasks across ten different domains.  The methods are: Intrinsic Planning without Chain-of-Thought (No CoT), Intrinsic Planning with Chain-of-Thought (CoT), P&D Chain, P&D Tree, and P&D Tree + DomProp.  For each method and domain, two metrics are reported:  the \"Best@4\" task solve rate (the highest solve rate out of four independent runs) and the average Exploration Walk (EW) score. The EW score measures the similarity between the generated domain PDDL and the ground truth domain.  A higher EW score indicates greater similarity, and therefore, better performance. Note that the EW score is not defined for intrinsic planning methods because these methods do not generate a domain PDDL.", "section": "5 Experiments"}]