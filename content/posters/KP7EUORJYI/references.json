{"references": [{"fullname_first_author": "Marcin Andrychowicz", "paper_title": "Hindsight experience replay", "publication_date": "2017-12-01", "reason": "This paper introduces Hindsight Experience Replay (HER), a crucial technique in goal-conditioned reinforcement learning that the current paper builds upon and improves."}, {"fullname_first_author": "David Abel", "paper_title": "On the expressivity of Markov reward", "publication_date": "2021-12-01", "reason": "This paper analyzes the limitations of Markov Reward functions in real-world scenarios, directly addressing the challenges of Non-Markovian Rewards that the current paper tackles."}, {"fullname_first_author": "Silviu Pitis", "paper_title": "Maximum entropy gain exploration for long horizon multi-goal reinforcement learning", "publication_date": "2020-06-01", "reason": "This paper presents MEGA, a goal selection method crucial for curriculum learning in GCRL, which the current work improves by proposing an on-policy framework."}, {"fullname_first_author": "Tuomas Haarnoja", "paper_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor", "publication_date": "2018-07-01", "reason": "Soft Actor-Critic (SAC) is a state-of-the-art off-policy reinforcement learning algorithm used as a baseline for comparison in the experimental evaluation of the proposed method."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-07-01", "reason": "Proximal Policy Optimization (PPO) is another state-of-the-art RL algorithm used as a comparison baseline in the experimental section, highlighting the novelty of the proposed on-policy approach."}]}