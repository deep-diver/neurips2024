[{"figure_path": "dhFHO90INk/tables/tables_4_1.jpg", "caption": "Table 1: Overview of the datasets in experiments.", "description": "This table provides a summary of the datasets used in the experiments section of the paper. It includes information about the domain of each dataset, the number of samples (size n), the type of data (continuous or discrete), the metric used for evaluation, the property being optimized, and a visual preview of the data.", "section": "3 Experimental Results"}, {"figure_path": "dhFHO90INk/tables/tables_7_1.jpg", "caption": "Table 2: Binding rate (and number of designs submitted). Higher is better.", "description": "This table presents the results of the *in vitro* therapeutic protein optimization experiments.  It shows the binding rate (percentage of tested designs that bound to the target antigen) and the number of designs submitted for each method (PropEn, walk-jump, lambo (guided), diffusion, diffusion (guided)) across different antibody seed designs (Herceptin, T1S1, T1S2, T1S3, T2S1, T2S2, T2S3, T2S4).  A higher binding rate indicates better performance.", "section": "3.2 In vitro experiment: therapeutic protein optimization"}, {"figure_path": "dhFHO90INk/tables/tables_7_2.jpg", "caption": "Table 2: Binding rate (and number of designs submitted). Higher is better.", "description": "This table presents the results of an *in vitro* experiment evaluating the performance of different methods for therapeutic protein optimization.  The table shows the binding rate (percentage of designs tested that were binders), the fraction of designs that improved the seed design, and the mean binding affinity improvement (pKD design - pKD of seed) for each method across multiple seeds and targets.  The results highlight PropEn's superior performance in generating functional antibodies with consistently high binding rates and significant affinity improvements compared to other methods.", "section": "3.2 In vitro experiment: therapeutic protein optimization"}, {"figure_path": "dhFHO90INk/tables/tables_15_1.jpg", "caption": "Table 1: Overview of the datasets in experiments.", "description": "This table summarizes the datasets used in the experiments presented in the paper.  It provides information on the domain of each dataset (e.g., toy problem, airfoil design, antibody design), the size of the dataset (number of samples), the type of data (continuous or discrete), and the property of interest that is being optimized.", "section": "3 Experimental Results"}, {"figure_path": "dhFHO90INk/tables/tables_17_1.jpg", "caption": "Table 5: Diffusion models do improve almost all hold out designs (RI - ratio of improvement), however, only by a very small value (AI-average improvement.)", "description": "This table presents the results of an airfoil experiment with N=200 samples, comparing the performance of different methods for improving airfoil design.  The methods include explicit guidance and several diffusion model variants (with different numbers of timesteps, T), and also PropEn with variations (x2x, xy2xy, and their mixup versions).  The table shows the average improvement (AI) and the ratio of improved designs (RI) for each method.  The results highlight PropEn's ability to achieve significantly higher average improvements compared to other methods, although the ratio of improved designs shows more variability.", "section": "3.1.2 Engineering: airfoil optimization"}, {"figure_path": "dhFHO90INk/tables/tables_20_1.jpg", "caption": "Table 6: PropEn vs Explicit guidance results on toy datasets, end of optimization trajectory. N is the number of samples, d is the number of dimensions for projection (2D \u2192 dD datasets). Mean (std) over 10 repetitions of the experiment. For all metrics, higher is better.", "description": "This table presents the results of comparing PropEn against Explicit guidance on various toy datasets with different dimensions and sample sizes. The metrics evaluated are ratio of improvement, log-likelihood, uniqueness, and novelty, each providing a different aspect of the model's performance.  Higher values generally indicate better performance.", "section": "3 Experimental Results"}, {"figure_path": "dhFHO90INk/tables/tables_21_1.jpg", "caption": "Table 6: PropEn vs Explicit guidance results on toy datasets, end of optimization trajectory. N is the number of samples, d is the number of dimensions for projection (2D \u2192 dD datasets). Mean (std) over 10 repetitions of the experiment. For all metrics, higher is better.", "description": "This table presents the results of comparing PropEn against an explicit guidance baseline across various metrics on multiple synthetic datasets. The metrics evaluated include ratio of improvement, log-likelihood, uniqueness, and novelty. Different dataset sizes and dimensionalities are considered for a comprehensive evaluation of the methods' performance.", "section": "3 Experimental Results"}]