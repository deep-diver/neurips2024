[{"figure_path": "hRqaot0NZF/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between the two-stage method and our single-stage method. (a) The two-stage method initially performs instance segmentation with instance labels then semantic labels to get the instance proposals and bases on the provided query to match the most relevant instance proposal. (b) Our single-stage method only utilizes the binary mask of the described object for training and integrates language and vision features during feature extraction.", "description": "This figure compares the two-stage and single-stage approaches for referring 3D segmentation. The two-stage method first performs instance segmentation using instance and semantic labels, then matches the results with the text query.  The single-stage method, in contrast, uses only binary masks for training and integrates language and vision features directly for segmentation, making it more efficient.", "section": "1 Introduction"}, {"figure_path": "hRqaot0NZF/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of our LESS framework. Given a point cloud scene P, we use a sparse 3D feature extractor to extract multi-scale feature V\u2081. The query T is sent to a text encoder and we obtain the word features W and sentence features S. Meanwhile, we introduce a PWCA module aligns the word features W with the multi-scale point cloud features Vi. After that, an m-layer QMP module is adopted to decode K learnable queries Qo base on the fused feature F, and output query embeddings Qm and proposal masks Mm. Finally, QSA module aligns the query embeddings Qm with sentence features S, i.e., computes the similarity scores R that filter the proposal masks Mm to the final mask prediction M.", "description": "This figure shows the architecture of the LESS framework for referring 3D segmentation. It starts with a sparse 3D feature extractor processing the point cloud, and a text encoder processing the textual query.  A Point-Word Cross-Modal Alignment (PWCA) module aligns word and point features. A Query Mask Predictor (QMP) module generates proposal masks, which are then refined by a Query-Sentence Alignment (QSA) module using sentence features to produce the final segmentation mask.", "section": "3 Method"}, {"figure_path": "hRqaot0NZF/figures/figures_7_1.jpg", "caption": "Figure 3: Final predictions using different combinations of loss functions. The queries and input scenes are shown in column 1 and 2. Columns 3 to 5 indicate the gradual addition of loss functions.", "description": "This figure shows the results of applying different combinations of loss functions to the model. The first two columns show the query and the input scene. The subsequent columns show the results of adding each loss function sequentially: segmentation loss (Lseg), area regularization loss (Larea), and point-to-point contrastive loss (Lp2p).  The final column shows the ground truth. The figure demonstrates the impact of each loss function on the model's ability to accurately segment the target objects in the scene, highlighting how each loss function contributes to the final prediction.", "section": "4.3 Ablation Studies"}, {"figure_path": "hRqaot0NZF/figures/figures_13_1.jpg", "caption": "Figure 4: There different types of labels.", "description": "This figure illustrates the differences between three types of labels used in 3D point cloud segmentation: semantic labels, instance labels, and binary labels. Semantic labels assign a category ID to each point (e.g., chair, table), while instance labels assign unique IDs to each instance of an object (e.g., chair 1, chair 2). Binary labels, used in this paper's proposed LESS method, simplify this by assigning a value of 1 to points belonging to the target object and 0 otherwise.  This highlights the label efficiency of the LESS method.", "section": "Appendix A Semantic and Instance Labels vs. Binary Labels"}, {"figure_path": "hRqaot0NZF/figures/figures_13_2.jpg", "caption": "Figure 1: Comparison between the two-stage method and our single-stage method. (a) The two-stage method initially performs instance segmentation with instance labels then semantic labels to get the instance proposals and bases on the provided query to match the most relevant instance proposal. (b) Our single-stage method only utilizes the binary mask of the described object for training and integrates language and vision features during feature extraction.", "description": "This figure compares the architecture of previous two-stage referring 3D segmentation methods with the proposed single-stage LESS method. The two-stage method first performs instance segmentation using both instance and semantic labels, then matches the resulting proposals with the textual query. In contrast, LESS uses only binary mask supervision and integrates language and vision features directly in a single stage for increased efficiency and reduced annotation burden.", "section": "1 Introduction"}]