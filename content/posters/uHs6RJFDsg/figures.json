[{"figure_path": "uHs6RJFDsg/figures/figures_3_1.jpg", "caption": "Figure 1: The pipeline of MoVA. MOVA performs coarse-to-fine routing to solve a given question. The coarse context-aware expert routing is performed in the first stage to select context-relevant experts. Next, we adopt the MoV-Adapter to extract and fuse the task-specific knowledge from these selected experts in a fine-grained manner.", "description": "The figure illustrates the two-stage pipeline of MoVA, a multimodal large language model.  Stage 1 involves context-aware expert routing, where a large language model (LLM) selects the most relevant vision experts based on user input (question and image).  Stage 2 uses a Mixture-of-Vision-Expert Adapter (MoV-Adapter) for fine-grained fusion, combining task-specific knowledge from selected experts to enhance the base vision encoder's output.  The final output is fed to the LLM to produce a response.", "section": "3 MoVA Methodology"}, {"figure_path": "uHs6RJFDsg/figures/figures_4_1.jpg", "caption": "Figure 1: The pipeline of MoVA. MOVA performs coarse-to-fine routing to solve a given question. The coarse context-aware expert routing is performed in the first stage to select context-relevant experts. Next, we adopt the MoV-Adapter to extract and fuse the task-specific knowledge from these selected experts in a fine-grained manner.", "description": "This figure illustrates the two-stage process of MoVA, a multimodal large language model.  The first stage involves coarse-grained context-aware expert routing, where the LLM selects the most relevant vision experts based on the input image, user question, and expert descriptions. The second stage is a fine-grained expert fusion using the MoV-Adapter, which extracts task-specific knowledge from the selected experts and fuses it with the base vision encoder's representation.  This combined representation is then fed to the LLM to generate a response.", "section": "3 MoVA Methodology"}, {"figure_path": "uHs6RJFDsg/figures/figures_5_1.jpg", "caption": "Figure 3: The training strategy of MoVA. We enhance the task-specific knowledge extraction capacity in the first stage. Then, we excite model multimodal capacities in the last stage.", "description": "This figure illustrates the two-stage training process of the MoVA model. Stage 1 focuses on pretraining, enhancing the model's ability to extract task-specific knowledge. Stage 2 involves supervised finetuning, aiming to improve the model's overall multimodal capabilities.  The diagram visually represents the flow of data and information through the model's components (LLM, Vision Experts, MoV-Adapter, Base Encoder) during both stages, highlighting the different supervision strategies employed.", "section": "3 MoVA Methodology"}, {"figure_path": "uHs6RJFDsg/figures/figures_5_2.jpg", "caption": "Figure 2: MoV-Adapter architecture.", "description": "The MoV-Adapter consists of multiple adapter blocks and a text encoder. Each block contains an expert knowledge extractor, a dynamic gating network, and a transformer block. The expert knowledge extractor uses cross-attention layers to extract task-specific knowledge from selected vision experts. The dynamic gating network generates expert-wise soft weights based on multimodal context. The transformer block processes the fused visual representation.  The text encoder extracts language context information from user instructions.", "section": "3.3 Fine-grained Expert Fusion with MoV-Adapter"}, {"figure_path": "uHs6RJFDsg/figures/figures_19_1.jpg", "caption": "Figure 1: The pipeline of MoVA. MOVA performs coarse-to-fine routing to solve a given question. The coarse context-aware expert routing is performed in the first stage to select context-relevant experts. Next, we adopt the MoV-Adapter to extract and fuse the task-specific knowledge from these selected experts in a fine-grained manner.", "description": "This figure illustrates the two-stage process of MoVA.  The first stage, context-aware expert routing, uses the LLM to choose the best vision experts based on the input image and question. The second stage, fine-grained expert fusion with MoV-Adapter, then uses those selected experts to refine the visual representation before the LLM generates a final response. This process combines coarse-grained and fine-grained approaches to leverage the strengths of various vision experts.", "section": "3 MoVA Methodology"}, {"figure_path": "uHs6RJFDsg/figures/figures_20_1.jpg", "caption": "Figure 1: The pipeline of MoVA. MoVA performs coarse-to-fine routing to solve a given question. The coarse context-aware expert routing is performed in the first stage to select context-relevant experts. Next, we adopt the MoV-Adapter to extract and fuse the task-specific knowledge from these selected experts in a fine-grained manner.", "description": "The figure illustrates the two-stage process of MoVA: 1) Coarse-grained Context-Aware Expert Routing: The LLM selects context-relevant vision experts from a pool based on the user's question and image. 2) Fine-grained Expert Fusion with MoV-Adapter: The MoV-Adapter extracts and fuses task-specific knowledge from the selected experts, enhancing the final visual representation before feeding it to the LLM for response generation. This coarse-to-fine approach leverages expert knowledge based on multimodal context and model expertise, improving generalization.", "section": "3 MoVA Methodology"}]