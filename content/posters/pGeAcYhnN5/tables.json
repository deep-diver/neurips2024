[{"figure_path": "pGeAcYhnN5/tables/tables_5_1.jpg", "caption": "Table 1: performance of average speedup ratio on MT-bench. represents the average speedup ratio for all evaluation questions relative to Vanilla method, calculated by equation 13. B represents the average number of accepted tokens per decoding step for all evaluation questions, calculated by equation 12.", "description": "This table presents the average speedup and the average number of accepted tokens per decoding step achieved by different speculative decoding methods on the MT-bench benchmark, using various sizes of Vicuna language models.  The speedup is calculated relative to a vanilla (autoregressive) decoding method. The results highlight the performance improvements of CTC-drafter compared to existing methods like Medusa and Hydra.", "section": "4 Experiments"}, {"figure_path": "pGeAcYhnN5/tables/tables_6_1.jpg", "caption": "Table 2: Performance of average speedup ratio on MT-bench for different model structures. \u03b3 represents the average speedup ratio for all evaluation questions relative to Vanilla method, calculated by equation 13. \u03b2 represents the average number of accepted tokens per decoding step for all evaluation questions, calculated by equation 12.", "description": "This table presents the results of an ablation study comparing different model structures for speculative decoding on the MT-bench dataset.  It shows the average speedup achieved (\u03b3) and average number of accepted tokens per decoding step (\u03b2) for two different model structures: one using a linear layer and cross-entropy loss, and the other using a transformer layer and CTC loss.  The results are compared against a baseline using Medusa's verification method. The table helps assess the impact of architectural choices on the efficiency of the speculative decoding approach.", "section": "4.3 Ablation experiments"}]