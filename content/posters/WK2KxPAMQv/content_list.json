[{"type": "text", "text": "Exploiting Representation Curvature for Boundary Detection in Time Series ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yooju $\\mathbf{Shin^{1}}$ , Jaehyun Park1, Hwanjun Song1, Susik Yoon2, Byung Suk Lee3, Jae-Gil Lee1\u2217 1KAIST, 2Korea University, 3University of Vermont {yooju.shin, jhpark813, jaegil, songhwanjun}@kaist.ac.kr, susik@korea.ac.kr, bslee@uvm.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Boundaries are the timestamps at which a class in a time series changes. Recently, representation-based boundary detection has gained popularity, but its emphasis on consecutive distance difference backfires, especially when the changes are gradual. In this paper, we propose a boundary detection method, RECURVE, based on a novel change metric, the curvature of a representation trajectory, to accommodate both gradual and abrupt changes. Here, a sequence of representations in the representation space is interpreted as a trajectory, and a curvature at each timestamp can be computed. Using the theory of random walk, we formally show that the mean curvature is lower near boundaries than at other points. Extensive experiments using diverse real-world time-series datasets confirm the superiority of RECURVE over state-of-the-art methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In a time series composed of sequential data points (simply points) indexed by timestamps, there are boundaries (or change points) signifying transitions between different classes or states, such as a shift from running to walking [1, 2]. Detecting boundaries is a crucial task in preprocessing and diverse applications of time-series data. As preprocessing, they partition a time series into segments of coherent points, accelerating annotation of the time-series for further analysis and giving additional supervision in classification [3, 4, 5, 6, 7]. As primary tasks, they are valuable for identifying changes that require human attention in a variety of domains, including climate, health care, finance, and manufacturing; epilepsy detection, stock price tracking, and action segmentation are examples of possible applications [8, 9, 10, 11]. ", "page_idx": 0}, {"type": "text", "text": "Representation-based boundary detection methods [12, 13] are prevalent today because they do not require specific assumptions on time-series properties, such as distribution or temporal shape, and can handle high dimensionality due to the capability of a self-supervised model that autonomously learns distinctive features from raw time series without any supervision. In these methods, a self-supervised model [14, 15, 16] is first used to derive a representation of each point, and then a point is identified as a boundary if its representation significantly deviates from those of adjacent points. Let\u2019s refer to the points close to a boundary as inter-segment points and the remaining points as intra-segment points. In short, these methods operate by assuming that the distance between consecutive representations is greater between inter-segment points than between intra-segment points. ", "page_idx": 0}, {"type": "text", "text": "However, this assumption on the distance difference does not always hold, especially when the changes are subtle or gradual. Time-series representation learning methods often pursue preserving the temporal coherence of a time series as their training goal is to make temporally close points similar in their representations and distant points dissimilar [14]. As demonstrated in Figure 1, the consecutive distances are not clearly distinguishable between intra- and inter-segment points for relatively subtle changes with stair up $\\leftrightarrow$ stair down because just the direction of motion differs between the two classes, whereas they are for abrupt changes with stand $\\leftrightarrow$ sit. Thus, the inability to handle subtle changes hinders achieving an overall good performance. ", "page_idx": 0}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/1e32bd20ee98d1a6230704c0100a64eda98337110f8bf6f9e1bac1713d5d6c6f.jpg", "img_caption": ["Figure 1: Consecutive distance (cosine similarity) distribution from intra- and inter-segment points in the representations of the HAPT dataset. "], "img_footnote": [], "page_idx": 1}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/1c348605a4933f4df9acb5923893077f1cfcbf41333b4a2f11c1366dbb42f9ad.jpg", "img_caption": ["Figure 2: Curvature comparison between intra- and inter-segment points in a representation space. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this work, we take a novel perspective on detecting boundaries by leveraging curvatures instead of distances in the representation space. As shown in Figure 2, the curvature at a point in a curve measures the instantaneous rate of direction change, or more precisely, the amount by which the curve deviates from being a straight line [17]. Suppose that a sequence of point representations from a time series constitutes a representation trajectory. We observe that, regardless of whether the changes are gradual or abrupt, the direction of the representation trajectory tends to change more sharply (showing a higher curvature) at intra-segment points than at inter-segment points. Accordingly, we contend that the curvature of a representation trajectory should be a very promising indicator for class boundary detection. ", "page_idx": 1}, {"type": "text", "text": "Using Figure 2, we justify the intuition behind curvature-based boundary detection. Because representation learning tries to learn class-separated features, well-embedded points of a certain class (or a segment) can be drawn from its class-specific ball [18, 19]. That is, the representation trajectory of intra-segment points is confined within a class ball, whereas that of inter-segment points is not. Then, for intra-segment points to reside exclusively within a class ball, their representation trajectory needs to make sharp turns frequently. In contrast, the transition from one class ball to another does not necessarily make sharp turns. This observation is formally proven by the relationship between the mean curvature and the radius of a confining hypersphere, assuming a random walk of a point representation (see Section 3.4). ", "page_idx": 1}, {"type": "text", "text": "Overall, for boundary detection, treating a sequence of representations as a trajectory and measuring its curvature is an entirely novel approach, which results in RECURVE (Representation trajEctory CURVaturE). A representation trajectory is derived by a time-series representation learning method, and the curvature at each point is calculated very efficiently; then, the points whose curvature is relatively small are identified as boundaries. RECURVE is simple yet powerful, and can be combined with any time-series representation learning method. We conduct comprehensive evaluations on a variety of time-series datasets, comparing it against state-of-the-art boundary detection methods. The results demonstrate that RECURVE consistently enhances the accuracy, achieving improvements of up to $12.7\\%$ . Furthermore, this superiority is shown to exist regardless of the degree of change between different classes. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Boundary Detection ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Time-series boundary detection methods assess the dissimilarity between two successive intervals and apply a threshold to pinpoint the positions of boundaries. There are multiple methods available for quantifying dissimilarity: (1) conducting statistical tests, (2) quantifying the deviation from discovered patterns, and (3) calculating distances between the representations learned from a selfsupervised model. We summarize each category here, with additional in-depth details available in extensive surveys [1, 2]. ", "page_idx": 1}, {"type": "text", "text": "Statistical tests often rely on the probability density ratio of two consecutive intervals as a key statistic. CUSUM is a traditional parametric algorithm that adds up the log likelihood ratio when a probability density function is given [20, 21]. RuLSIF is a non-parametric algorithm that directly estimates the probability density ratio using Pearson divergence without a probability density function [22, 23, 24]. A kernel-based statistical test maps each interval to a kernel space and then computes the kernel ", "page_idx": 1}, {"type": "text", "text": "Fisher discriminant ratio as a statistic [25]. KL-CPD uses a deep neural network as a generator for kernel parameters, which solves high sensitivity in selecting parameters [26]. ", "page_idx": 2}, {"type": "text", "text": "The proactive discovery of frequent temporal patterns is necessary for temporal pattern-based boundary detection. FLOSS stores the locations of similar subsequences in a time series using Matrix Profile and measures the likelihood of a regime change [27]. Motif-based boundary detection relies on the identification of short temporal patterns (motifs) determined through the minimum description length criterion; these motifs are then compared for similarity with other subsequences within a time series [11, 28]. ESPRESSO, on the other hand, is a hybrid of pattern- and statistic-based approaches, detecting a wide range of boundaries across different scenarios and data types [29]. ", "page_idx": 2}, {"type": "text", "text": "Representation-based boundary detection methods are distinguished by the manner in which a self-supervised model is trained. TIRE exploits an autoencoder to retain time-invariant features in consecutive timestamps to make representations of boundaries salient [12]; after training, the output representations undergo a process of smoothing, wherein a moving average is applied prior to the dissimilarity computation. TS- $\\mathbf{\\cal{C}}\\mathbf{P}^{2}$ leverages contrastive learning techniques to promote close proximity between representations of two consecutive timestamps and distant proximity between representations at randomly selected timestamps [13]; it examines the difference between each consecutive distance and the moving average. ", "page_idx": 2}, {"type": "text", "text": "2.2 Time-Series Representation Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Time-series representation learning builds a model to create versatile representations capable of performing diverse downstream tasks such as classification, forecasting, and anomaly detection [30, 31]. Reconstruction-based learning methods train autoencoder-based deep neural networks using a reconstruction loss. TimeNet is an early example that uses a sequence-to-sequence autoencoder and uses the hidden embedding extracted from the encoder as a representation [32]. DTCR extends traditional reconstruction-based learning by incorporating a $k$ -means loss alongside the reconstruction loss [33]. Input masking is also commonly used for reconstructing data with specific timestamps intentionally masked or hidden [34, 35, 36]. ", "page_idx": 2}, {"type": "text", "text": "In contrastive learning, the Info-NCE (Noise Contrastive Estimation) loss plays a pivotal role by bringing a positive pair closer together and pushing a negative pair apart in the representation space. An early approach considers a sampled window and a subsequence from the window as a positive pair [37]. In recent methods such as TNC (Temporal Neighborhood Coding), the temporal distance serves as a criterion for identifying a positive pair, keeping two neighboring timestamp representations close [13, 14, 38]. Following the principles of SimCLR [39], a positive pair can be created by pairing a sampled window with its augmentation which involves data perturbation or context changes [15, 40]. Besides, the Fourier transform of a time series serves as an augmentation technique for generating positive pairs or providing a new representation space [16, 41, 42]. ", "page_idx": 2}, {"type": "text", "text": "3 RECURVE: Curvature-based Boundary Detection ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Preliminaries and Problem Setting ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Dataset and Model: Let $\\boldsymbol{\\mathcal{X}}\\,=\\,({\\mathbf{x}}_{t})_{t=1}^{T}$ be a time series, where $T$ is the total number of points, and $\\mathbf x_{t}\\in\\mathbb R^{d}$ is a $d$ -dimensional point at timestamp $t$ . Let ${\\mathcal{C}}=\\{t_{k}\\ |\\ k\\in[\\![1,\\ K]\\}$ be a set of the timestamps for the ground-truth boundaries. Considering class labels annot ated at  each timestamp, $\\mathcal{C}$ is composed of the timestamps where there is a change in the label from the previous one (e.g., $\\mathtt{s t a n d\\to w a l k}$ ). A window $\\bar{X_{t_{m}}}\\,=\\,({\\bf x}_{t})_{t=t_{m}-I}^{t_{m}+I-1}$ )tt=mt+mI\u2212\u2212I1 is a sequence of consecutive 2I points centered at timestamp $t_{m}$ . A representation model $f_{\\theta}$ , which is a deep neural network parameterized by $\\theta$ , converts each window $X_{t_{m}}$ to its representation $\\mathbf{z}_{t_{m}}\\in\\mathbb{R}^{d^{\\prime}}$ , i.e., $\\mathbf{z}_{t_{m}}=f_{\\theta}(X_{t_{m}})$ . ", "page_idx": 2}, {"type": "text", "text": "Representation Learning: RECURVE is not bound to a specific representation learning method, and we summarize the training process using one of the popular methods, the temporal predictive coding $(T P C)$ proposed in $\\mathrm{TS-CP^{2}}$ [13]. Here, two non-overlapping consecutive windows are used as a positive pair, and two randomly-sampled windows are used as a negative pair. Thus, TS$\\mathrm{CP^{2}}$ randomly samples $b$ windows as well as their succeeding windows and constructs a batch $B\\,=\\,\\{X_{t_{1}},X_{t_{2}},\\ldots,X_{t_{b}},X_{t_{1}+2I},X_{t_{2}+2I},\\ldots,X_{t_{b}+2I}\\}$ ; the method subsequently minimizes the InfoNCE loss $\\ell_{\\mathrm{NCE}}$ [43], ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\ell_{\\mathrm{NCE}}=-\\frac{1}{b}\\sum_{j=1}^{b}\\log\\frac{\\exp(\\sin(\\mathbf{z}_{t_{j}},\\mathbf{z}_{t_{j}+2I})/\\tau)}{\\sum_{k=1,k\\neq j}^{b}\\exp(\\sin(\\mathbf{z}_{t_{j}},\\mathbf{z}_{t_{k}})/\\tau)},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathrm{sim}(\\cdot,\\cdot)$ is the cosine similarity function, $\\exp(\\cdot)$ is the exponential function, $\\mathbf{z}_{t_{j}}=f_{\\theta}(X_{t_{j}})$ , and $\\tau$ is a scaling parameter. The model parameter $\\theta$ is updated iteratively by gradient descent, i.e., $\\theta\\leftarrow\\theta-\\eta\\nabla_{\\theta}\\ell(\\bar{B_{,}}\\theta)$ , where $\\eta$ is a learning rate. ", "page_idx": 3}, {"type": "text", "text": "Change Metric and Detection: Using the representations of all windows centered at each point in $\\mathcal{X}$ , i.e., $\\{\\mathbf{z}_{t}\\mid t\\in[1,\\,T]\\}$ , a change metric $\\hat{y}_{t}$ is derived for each point $\\mathbf{x}_{t}\\in\\mathcal{X}$ , which represents the extent that $\\mathbf{x}_{t}$ is a  boun dary. For example, the change metric in TS- $\\mathrm{{CP^{2}}}$ employs the distance (i.e., cosine similarity) between the embeddings of adjacent points, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{y}_{t}^{\\mathrm{dist}}=\\mathtt{N O R M}(|\\mathrm{sim}(\\mathbf{z}_{t},\\mathbf{z}_{t+1})-\\mathtt{M A}(\\mathrm{sim}(\\mathbf{z}_{t},\\mathbf{z}_{t+1}))|),}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where MA calculates a simple central moving average and NORM is min-max normalization over all timestamps to rescale a value between 0 and 1. Then, similar to binary classification, the points whose change metric exceeds a certain threshold $\\varphi$ are identified as boundaries, ", "page_idx": 3}, {"type": "equation", "text": "$$\n{\\hat{\\mathcal{C}}}=\\{t\\mid{\\hat{y}}_{t}\\geq\\varphi{\\mathrm{~where~}}t\\in[\\![1,\\ T]\\!]\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Goal: Obviously, an effective change metric is crucial to the success of boundary detection. Therefore, we propose a novel change metric, $\\hat{y}_{t}^{c u r v}$ , using the curvatures in the representation space instead of the consecutive distances in the representation space. ", "page_idx": 3}, {"type": "text", "text": "3.2 Curvature-Based Change Metric ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "A trajectory usually refers to the path or track that an object (e.g., human and vehicle) in motion follows through space and time [44]. Thus, we get to Definition 3.1 if we think of an object as a point floating in the representation space. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.1 (TRAJECTORY). A representation trajectory (simply trajectory) $\\tau$ is a curve specified by a sequence of representations at consecutive timestamps and denoted as $\\mathcal{T}=({\\mathbf{z}}_{t})_{t=1}^{|\\mathcal{T}|}$ . ", "page_idx": 3}, {"type": "text", "text": "The curvature at a specific point on a curve is the rate at which the direction of the curve changes instantaneously at the point [17]. It is a well-defined concept in geometry and quantifies how sharply or gradually the curve bends or deviates from a straight line. We employ the definition designed for a trajectory [45]. For three timestamps in order, $t^{-}$ , $t,$ , and wh ", "page_idx": 3}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/3b183090ac0fc48d89f149b7020e1befeb71d4b2256f67b27d8d3cac50ab85ac.jpg", "img_caption": ["Figure 3: Turning angle. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Two difference vectors, ${\\bf z}_{t}-{\\bf z}_{t-}$ and $\\mathbf{z}_{t^{+}}-\\mathbf{z}_{t}$ , are naturally derived, and the turning angle $\\theta_{t}$ between them in Figure 3 is calculated by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\theta_{t}=\\operatorname{arccos}{\\frac{\\left(\\mathbf{z}_{t}-\\mathbf{z}_{t^{-}}\\right)\\cdot\\left(\\mathbf{z}_{t^{+}}-\\mathbf{z}_{t}\\right)}{\\left|\\left|\\mathbf{z}_{t}-\\mathbf{z}_{t^{-}}\\right|\\mid\\left|\\mathbf{z}_{t^{+}}-\\mathbf{z}_{t}\\right|\\right|}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Each value of $\\theta_{t}$ ranges between 0 and $\\pi$ , where $t\\in[2,\\;|\\mathcal{T}|\\!-\\!1]$ . Then, the curvature is the rate of the direction changes between the two difference vec tors, i.e. ho w much a difference vector rotates per unit length, as defined in Definition 3.2. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.2 (CURVATURE). The curvature at timestamp $t$ in a representation trajectory $\\tau$ is the turning angle $\\theta_{t}$ divided by the sum of the difference vector lengths, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\kappa_{t}=\\frac{\\theta_{t}}{||\\mathbf z_{t}-\\mathbf z_{t^{-}}||+||\\mathbf z_{t^{+}}-\\mathbf z_{t}||}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "According to our observations and intuitions described in Section 1, the curvature of an intra-segment point is higher than that of an inter-segment point. Thus, the curvature defined in Definition 3.2 can be used as a change metric. The computational complexity remains $O(d^{\\prime}T)$ , consistent with that of $\\mathrm{TS-CP^{2}}$ where cosine similarity is computed instead of curvature. For stability, the timestamps $t^{-}$ and $t^{+}$ in Eq. (5) are determined to be $w\\geq1$ timestamps before and after timestamp $t$ , i.e., $t^{-}=t-w$ and $t^{+}=t+w$ . We set $w$ to $5\\%$ of the mean segment length, which is observed to work well in most situations. Please refer to Section 4.6 about the sensitivity analysis on the value of $w$ . Definition 3.3 concludes our novel curvature-based change metric. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.3 (CHANGE METRIC). The curvature-based change metric at timestamp $t$ becomes ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{y}_{t}^{c u r v}=\\mathtt{M A}(1-\\mathtt{N O R M}(\\kappa_{t})),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\kappa_{t}$ is obtained from Eq. (5) and MA and NORM are the same as Eq. (2). ", "page_idx": 3}, {"type": "text", "text": "In Definition 3.3, we normalize the curvature to a scale of 0 to 1. Subtracting this normalized curvature from 1 ensures that the change metric increases as the curvature decreases while maintaining the scale. Finally, a moving average is employed to smooth the curvature and mitigate fluctuations. ", "page_idx": 4}, {"type": "text", "text": "3.3 Change Metric Thresholding ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Once the change metric $\\hat{y}_{t}^{c u r v}$ in Eq. (6) is prepared, it is possible to detect boundaries by finding the points where $\\hat{y}_{t}^{c u r v}\\ge\\varphi$ , as formulated by Eq. (3). Therefore, it is necessary to develop a heuristic for determining the threshold $\\varphi$ , and additional information can be utilized for this purpose. Such additional information includes the mean segment length and the validation dataset. If the mean segment length, i.e., the average of the lengths of segments distinguished by boundaries, is known, the estimated number of boundaries can be calculated by dividing the total number of timestamps by the mean segment length. The threshold $\\varphi$ is then determined to obtain the estimated number of boundaries. Alternatively, if we have a validation dataset, we select the threshold $\\varphi$ that yields the best performance based on an evaluation measure. Empirical evaluation in Section 4 employs the mean segment length in thresholding. ", "page_idx": 4}, {"type": "text", "text": "3.4 Theoretical Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our theoretical analysis is conducted by showing the following properties: (1) the intrasegment points in the representation space are confined within a smaller hypersphere than the inter-segment points, as shown in Figure 4; (2) the mean curvature of a representation trajectory increases as the radius of the confining hypersphere decreases, which leads to the rationale behind Definition 3.3. ", "page_idx": 4}, {"type": "text", "text": "Definition 3.4 (CONFINEMENT). Consider a subsequence of a specific class $C_{i}$ , $\\chi_{C_{i}}\\ =$ $(\\mathbf{x}_{t})_{t=t_{s t a r t}}^{t_{e n d}}$ , as wtell as its representation trajectory, $T_{C_{i}}=(\\mathbf{z}_{t})_{t=t_{s t a r t}}^{t_{e n d}}$ , in Figure 4. Then, ", "page_idx": 4}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/314314011d95bb6473d62dfae82d0470efdf0a97870a1e4e4631a4830179d6e9.jpg", "img_caption": ["Figure 4: Comparison of the curvatures between intra- and inter-segment points. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "is confined within a hypersphere $S_{C_{i}}\\subset\\mathbb{R}^{d^{\\prime}}$ centered at $O_{C_{i}}\\in\\mathbb{R}^{d^{\\prime}}$ of radius $R_{i n t r a}$ if and only if $||\\mathbf{z}_{t}-O_{C_{i}}||<R_{i n t r a}$ holds for all $t\\in[[t_{s t a r t},\\;t_{e n d}]]$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 3.4 comes from a widely known fact that representation (contrastive) learning produces class-separated representations [18, 19]. The augmented positive examples form a connected graph based on augmentation overlap; thus, the alignment of positive examples by contrastive learning will cluster the examples of the same class together and lead to class-separated representations [18]. ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.5 (CONFINEMENT RADIUS). Consider a transition from a class $C_{i}$ to another class $C_{j}$ in Figure 4. Let $S_{C_{i}},S_{C_{j}}\\subset\\mathbb{R}^{d^{\\prime}}$ be the confining hyperspheres for $C_{i}$ and $C_{j}$ , respectively, of radius $R_{i n t r a}$ . Then, consider a larger hypersphere of radius $R_{i n t e r}$ that encloses the inter-segment points (in red) as well as $S_{C_{i}}$ and $S_{C_{j}}$ . Thus, $R_{i n t r a}<R_{i n t e r}$ holds by definition. ", "page_idx": 4}, {"type": "text", "text": "Based on temporal coherence [7, 13, 46] inherent in time series, we make an assumption on the representation trajectory before proceeding to the second step. ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.6 (EQUILATERAL RANDOM WALK). A representation trajectory $\\boldsymbol{\\mathcal{T}}=({\\mathbf{z}}_{t})_{t=1}^{|\\mathcal{T}|}$ is a Markov chain, where $\\mathbf{z}_{t}$ is sampled over the surface of the unit hypersphere centered at $\\mathbf{z}_{t-1}$ and also contained in a confining hypersphere of radius $R$ . That is, $||{\\bf z}_{t}-{\\bf z}_{t-1}||=1$ $\\left(t\\in[2,\\,|\\,\\mathcal{T}|]\\right)$ and $||\\mathbf{z}_{t}||<R\\,(t\\in[\\![1,\\ |T|]\\!])$ such that $R>1$ . ", "page_idx": 4}, {"type": "text", "text": "Under Assumption 3.6, the curvature in Eq. (5) becomes the turning angle in Eq. (4) because the denominator is reduced to a constant when $w=1$ . Then, when a given representation trajectory $\\tau$ is confined by a hypersphere of radius $R$ , its mean curvature is defined by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{K}_{\\mathcal{T}}(R)=\\frac{1}{|\\mathcal{T}|}\\sum_{\\mathbf{z}_{t}\\in\\mathcal{T}}\\mathbb{E}_{\\mathbf{z}_{t}|R}[\\theta_{t}],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbb{E}_{{\\mathbf{z}}_{t}\\mid R}[\\theta_{t}]$ is the expectation of the curvature at timestamp $t$ with respect to the distribution of the representations in the confining hypersphere of radius $R$ . ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.7 (MEAN CURVATURE). Consider a representation trajectory $\\tau$ confined in a hypersphere of radius $R$ under Assumption 3.6. Then, the mean curvature $\\kappa_{\\tau(R)}$ is a decreasing function of the radius $R_{;}$ , i.e., $\\begin{array}{r}{\\frac{\\mathrm{d}}{\\mathrm{d}R}K\\tau(R)<0}\\end{array}$ . ", "page_idx": 5}, {"type": "text", "text": "The proof of Lemma 3.7 is provided by Diao et al. [47]. The mean curvature is rigorously formulated as a complicated integral. By a simulation of random walk with one million steps, the decrease in the curvature is represented by the linear function $3.53-1.21R$ and the function $\\pi/2+0.65/R^{1.5}$ for two different regimes of $R$ . ", "page_idx": 5}, {"type": "text", "text": "Notation. The representation trajectories confined within the hyperspheres of radii $R_{i n t r a}$ and $R_{i n t e r}$ in Figure 4 are called intra-segment and inter-segment trajectories as well as denoted by $\\tau_{i n t r a}$ and ${\\tau}_{i n t e r}$ , respectively. ", "page_idx": 5}, {"type": "text", "text": "Putting Proposition 3.5 and Lemma 3.7 together, the observation on the difference in the curvature is finally formalized by Theorem 3.8. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.8 (CURVATURE DIFFERENCE). The mean curvature of an intra-segment trajectory is greater than that of an inter-segment trajectory, i.e., $\\mathcal{K}_{\\mathcal{T}_{i n t r a}}(R_{i n t r a})>\\mathcal{K}_{\\mathcal{T}_{i n t e r}}(R_{i n t e r})$ . Proof. Because $R_{i n t r a}<R_{i n t e r}$ by Proposition 3.5, $\\mathcal{K}_{\\mathcal{T}_{i n t r a}}(R_{i n t r a})>\\mathcal{K}_{\\mathcal{T}_{i n t e r}}(R_{i n t e r})$ obviously holds by the decreasing nature of $\\kappa_{\\tau(R)}$ of Lemma 3.7. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.8 can be intuitively explained if we consider the special case in which the next representation of $\\mathbf{z}_{i n t r a}$ or $\\mathbf{z}_{i n t e r}$ lies on the surface of a hypersphere, as visualized in Figure 4. Since a smaller radius necessitates a sharper turn, $\\theta_{i n t r a}>\\theta_{i n t e r}$ holds true. In this particular instance, where $\\mathbf{z}_{i n t r a}$ or $\\mathbf{z}_{i n t e r}$ is an orthogonal projection onto the surface, the turning angle can be expressed as $\\pi-\\operatorname{arccos}{\\frac{1}{2R}}$ , a decreasing function of $R$ . Please refer to Appendix A for more details. ", "page_idx": 5}, {"type": "text", "text": "3.5 Empirical Validation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The findings in the theoretical analysis also align well with the visualizations of the representations from a real dataset. Figure 5 displays three representation trajectories in the representation space of two principal components, which are obtained by the TPC method with $d^{\\prime}=32$ for the mHealth dataset. Each representation trajectory includes 100 points centered at a boundary, where each point is sampled every ten points in the original trajectory. Inter-segment points within five sampled timestamps from the boundary are denoted by $\\mathbf{\\omega}^{\\leftarrow}\\times\\mathbf{\\dot{\\omega}}^{\\setminus}$ , while intra-segment points are denoted by $\\bullet\\bullet\\widehat{\\bullet}$ . The color of each symbol indicates the value of our change metric\u2014i.e., $1-$ curvature. Obviously, inter-segment points have higher values of the change metric than intra-segment points. Interestingly, in Figure 5, the distance between two consecutive representations remains similar regardless of whether they are intra- or inter-segment points. This result reaffirms the existence of temporal coherence in the representation space, which could reduce the accuracy of distance-based methods. Moreover, it is evident that the representation trajectories of intra-segment points exhibit clearer confinement, resulting in more closed shapes and larger average turning angles. The representation trajectories of inter-segment points have fewer rotations and produce a relatively straighter shape. ", "page_idx": 5}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/9b0485b812ffe732f253ba864eabfc37a6b43304f888931408e61bb5382febac.jpg", "img_caption": ["Figure 5: Three representation trajectories in the space of two principal components in mHealth. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "4 Evaluation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Experiment Setting ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets: The profiles of the four datasets used in our experiments are summarized in Table 1, which lists the number of timestamps, mean segment length, number of classes, data dimensionality, sampling rate in $\\mathrm{Hz}$ , and number of boundaries. WISDM [48], ", "page_idx": 6}, {"type": "table", "img_path": "WK2KxPAMQv/tmp/be1630900daebc9b2c3456e22509023c8d9c655a5dbc6cdbd97ab625b8dcf137.jpg", "table_caption": ["Table 1: Summary of datasets and hyper-parameters. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "HAPT [49], and mHealth [49] are human action recognition datasets, which are measured by single or multiple accelerometers and/or gyroscopes. 50salads [50] is a video dataset that captures 25 people preparing salads; the I3D features of 2048 dimensions are extracted, following Farha and Gall [3]. The set of ground-truth boundaries, $\\mathcal{C}$ , is defined as the set of the timestamps where the class changes. The dimensionality of the representation space is set to $d^{\\prime}=8$ for WISDM and HAPT and $d^{\\prime}=32$ for mHealth and 50salads, considering their data dimensionality. ", "page_idx": 6}, {"type": "text", "text": "RECURVE Details: To obtain the point representations, we employ two time-series representation learning methods, TPC proposed in TS- $\\mathrm{{CP^{2}}}$ [13] and TNC [14]. RECURVE $^+$ TPC and RECURVE $^+$ TNC indicate the two implementations depending on the representation learning method. A temporal convolutional network (TCN) is trained in both methods. Note that any representation learning method can be combined with RECURVE. The window size, $2I$ , and the number of training epochs for each dataset are shown in Table 1, where the window size is approximately twice the sampling rate. The learning rate is set to 0.005 for all datasets. The hyperparameter $w$ , indicating the length of a representation vector, is set to $5\\%$ of the mean segment length. After obtaining a change metric for each timestamp, in Eq. (6), the same normalization is applied to all windows from an individual dataset. The moving average in Eq. (6) is computed using the ten timestamps preceding and following each timestamp. RECURVE is implemented using PyTorch 1.13.0, and its source code is available at https://github.com/kaist-dmlab/RECURVE. ", "page_idx": 6}, {"type": "text", "text": "Compared Methods: RuLSIF [24], KL-CPD [26], and $\\mathrm{TS-CP^{2}}$ [13] are chosen as the representative method from each of the three categories in Section 2.1. The window size in Table 1 is applied to all compared methods for fair comparison. A multilayer perceptron is used for the regressor of RulSIF. The hyperparameters of RuLSIF and KL-CPD are favorably determined by a grid search, as detailed in Appendix B. The public implementations of $\\mathrm{RuLSIF}^{2}$ and $\\mathrm{KL-CPD}^{3}$ are used for our experiments. TS- $.{\\mathrm{CP}}^{2}$ is the closest to our work, and its main mechanism is briefly described in Section 3.1. Because representation learning itself is shared between TS- $\\cdot{\\mathrm{CP}}^{2}$ and RECURVE when TPC is used, the same hyperparameter setting is applied to both methods whenever possible. TS- $\\cdot{\\mathrm{CP}}^{2}$ is re-implemented using PyTorch 1.13.0 for direct comparison with RECURVE. ", "page_idx": 6}, {"type": "text", "text": "Evaluation Measures: First, the Area Under the ROC Curve (AUC) is measured by considering boundary detection as binary classification with a binary label vector $\\mathbf{y}\\in\\{0,1\\}^{T}$ converted from $\\mathcal{C}$ . Following Deldari et al. [13], an error margin is introduced to accommodate some noise from annotation and detection. A detected boundary is considered to be correct if it lies within $p$ timestamps from one of the ground-truth boundaries. For this purpose, $\\mathbf{y}$ is relaxed to ", "page_idx": 6}, {"type": "equation", "text": "$$\ny_{t}={\\left\\{\\begin{array}{l l}{1}&{{\\mathrm{if~}}t_{k}-p\\leq t<t_{k}+p{\\mathrm{~where~}}t_{k}\\in{\\mathcal{C}}}\\\\ {0}&{{\\mathrm{otherwise}}.}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Then, for $t\\in[1,\\,T]$ , whether $\\hat{y}_{t}$ in Eqs. (2) or $(6)\\geq\\varphi$ ) is compared against $y_{t}$ in Eq. (8). We use multiple error  margi ns, $p\\in\\{5,10,20\\}$ , since a margin could be different for diverse applications [1]. Second, the mean LOCation distance (LOC) is measured, which is the average distance from a detected boundary to its closest ground-truth boundary [27, 51]. The LOC measure is useful for checking the preciseness of the boundaries detected. ", "page_idx": 6}, {"type": "text", "text": "Regarding the threshold $\\varphi$ , the AUC measure does not require a specific value because it evaluates the true positive and false positive rates over a given range. For the LOC measure, two values are used for each experiment: one is determined to achieve the best F1 score, and the other is determined by the heuristic based on the mean segment length in Section 3.3, where the estimated number of boundaries is multiplied by $p=10$ , taking the error margin into account. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "For each evaluation measure, we conduct every experiment five times with different seeds and report the average as well as the standard deviation. We use Intel(R) Xeon(R) Gold 6226R CPU $\\textcircled{a}2.90\\mathrm{GHz}$ and NVIDIA RTX 3090 for every experiment. ", "page_idx": 7}, {"type": "text", "text": "4.2 Comparison with State-of-the-Art Methods ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Tables 2 and 3 display the AUC and LOC measures for the five methods across the four datasets. The AUC measure is presented in Table 2 with varying the error margin $p$ . RECURVE outperforms the other boundary detection methods, where the optimal representation approach varies for each dataset. RECURVE wins against $\\mathrm{TS-CP^{2}}$ in all datasets, irrespective of the evaluation measure. This finding demonstrates that the curvature is more effective for boundary detection in temporally coherent time series where the class changes gradually. WISDM, HAPT, and mHealth exhibit periodicity in certain classes, includ", "page_idx": 7}, {"type": "table", "img_path": "WK2KxPAMQv/tmp/234c86bc2295c000f614a0d63ba3a2972b492de44074c1a8aefa49afd94974ed.jpg", "table_caption": ["Table 2: Overall detection accuracy in the $A U C$ measure (the best results in bold). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "ing Walk and Run. This periodicity would produce a closed shape for intra-segment trajectories and increase their curvatures in the representation space, enhancing the performance of RECURVE. In particular, when $p=20$ , RECURVE outperforms the second-best method by up to $12.7\\%$ in terms of the AUC measure for the mHealth dataset. ", "page_idx": 7}, {"type": "table", "img_path": "WK2KxPAMQv/tmp/911d0480151daf7f25bba40c93382a96c68f75a2e4cf57406544855cfc25a2d0.jpg", "table_caption": ["Table 3: Overall detection accuracy in the $L o C$ measure (the best results in bold). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.3 Detailed Investigation on Change Metric Quality ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We display the average values of the change metrics separately for each pair of classes using the HAPT dataset, which was chosen for ease of visualization due to its small number of classes. Figure 6a depicts the inter-class embedding distance, which is determined by the Euclidean distance between the centroids of point representations of given classes. The values of the change metrics are averaged across the inter-segment points for each distinct class transition. Figures 6b and 6c are obtained by the distance-based change metric $\\hat{y}_{t}^{\\mathrm{dist}}$ of $\\mathrm{TS-CP^{2}}$ and the curvature-based change metric $\\hat{y}_{t}^{\\mathrm{curv}}$ of RECURVE, respectively. Intriguingly, $\\hat{y}_{t}^{\\mathrm{curv}}$ generates high values for all class pairs in Figure 6c, which indeed explains the overall high accuracy in Tables 2 and 3. In contrast, in Figure 6b, $\\hat{y}_{t}^{\\mathrm{dist}}$ only generates high values when the inter-class embedding distance is sufficiently large (i.e., abrupt change), whereas it generates moderate values when the inter-class embedding distance is small (i.e., gradual change). That is, Figures 6a and 6b show a very high correlation. In summary, $\\hat{y}_{t}^{\\mathrm{curv}}$ is insensitive to the degree of changes whereas $\\hat{y}_{t}^{\\mathrm{dist}}$ is not. Therefore, this result demonstrates the superiority of the curvature-based change metric over the distance-based change metric. ", "page_idx": 7}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/0e7e8d70ad6a9cb32d9af1c8b90a6552a8d0ecd88a10a032690504a9e76c5f0c.jpg", "img_caption": ["Figure 6: Heatmaps of the inter-class distances and values of the change metrics between the classes in the HAPT dataset. A gray box indicates no transition between two classes. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Figure 7 magnifies six class pairs selected from all class pairs depicted in Figures 6b and 6c. For example, Stand $\\rightarrow S\\dot{1}\\dot{0}$ and Lie $\\rightarrow$ Stand are accompanied by rapid body movement, and both $\\mathrm{TS-CP^{2}}$ and RECURVE capture the boundaries well, as evidenced by the high density in the interval close to 1. In contrast, when two action classes are comparable, as in $\\mathtt{S t a n d\\rightarrow W a l k}$ , ${\\tt D o w n\\rightarrow U p}$ , and ${\\tt W a l k\\rightarrow D o w n}$ , the values of the change metric of $\\mathrm{TS-CP^{2}}$ disperse to other intervals, resulting in a decrease in detection performance. RECURVE maintains the same shape in all density plots due to the remarkable effectiveness of our curvature-based change metric. ", "page_idx": 8}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/8d1e305f659492a2e1cb24b90fae743c62f6017383ca5e799aff2f9165000053.jpg", "img_caption": ["Figure 7: Distribution of the change metrics for each class transition in the HAPT dataset. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.4 Evaluation Respective to Gradual and Abrupt Changes ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Table 4 shows the corresponding AUC scores for gradual and abrupt changes in relation to various distance-based metrics. If the inter-class embedding distance between two classes is shorter than a certain threshold, the change between the two classes is categorized as gradual. Here, the threshold is established such that gradual changes represent $20\\%$ of all changes. Abrupt changes are excluded when measuring the improvement for gradual changes, and vice versa. The distance-based metrics, denoted by DISTANCE, are further categorized depending on whether the Euclidean distance or the cosine similarity is used. Note that RECURVE adopts the curvature-based metric. ", "page_idx": 8}, {"type": "text", "text": "Overall, RECURVE demonstrates greater improvements for gradual changes (AUC-Gradual) than for abrupt changes (AUC-Abrupt). For example, in the HAPT dataset with $p\\,=\\,5$ and the TPC representation, the increase in the AUC measure from $\\mathrm{TS-CP^{2}}$ to RECURVE for gradual changes is $32\\%$ , which is significantly higher than the $21\\%$ increase for abrupt changes. This result confirms that the curvature-based method is particularly effective for detecting gradual changes because it captures subtle variations in the data that are not readily discernible through distance-based methods. In conclusion, RECURVE is versatile to support both gradual and abrupt changes. ", "page_idx": 8}, {"type": "table", "img_path": "WK2KxPAMQv/tmp/89fe04c281a7adf3a02ff6a13ee743b099f63b75d2b24f4523f2497fae502d2b.jpg", "table_caption": ["Table 4: Detection accuracy in the AUC measure respective to gradual and abrupt changes. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.5 Visual Analysis of the Change Metrics ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Figure 8 visualizes the fluctuations of various change metrics obtained from the HAPT dataset using the TPC representation. $\\mathrm{TS-CP^{2}}$ fluctuates rapidly during the changes and seems to have many false negatives at the rightmost boundary area. However, RECURVE indicates the inter-segment points much more clearly than $\\mathrm{TS-CP^{2}}$ , without excessive false positives and false negatives. The reliable detection is achievable by taking into account both the turning angle (the numerator in Eq. (5)) and the distance (the denominator in Eq. (5)) in the representation space. ", "page_idx": 9}, {"type": "image", "img_path": "WK2KxPAMQv/tmp/2285653bce0cb8761bd278932b8f6908bf6feca4880b54b1dc49c91b82126661.jpg", "img_caption": ["Figure 8: Change metric scores from the HAPT dataset with the default configuration. A gray-shaded area represents the inter-segment points between two class segments. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "4.6 Sensitivity Analysis on the Hyperparameter ${\\pmb w}$ ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Table 5 shows the performance of RECURVE while varying the hyperparameter $w$ (see Definition 3.3) when the error margin $p$ for the AUC measure is fixed at 10. The value of $w$ ranges from $0.25\\times$ to $4.00\\times$ of the default value, which is set to $5\\%$ of the mean segment length (indicated by $1.00\\!\\times\\!)$ . If the value of $w$ were too large, the denominator of Eq. (5) would be too large for any point in a time series, and the curvature would be unable to distinguish between intra- and inter-segment points. If the value of $w$ were too small, some noise in point representations would distort the curvature. Under this trade-off, the default value performs the best in terms of the AUC measure when it is averaged over the four datasets and the two representation learning methods. On a dataset with lengthy segments, such as mHealth, the sensitivity tends to decrease, and there is small variation when varying the value of $w$ . ", "page_idx": 9}, {"type": "table", "img_path": "WK2KxPAMQv/tmp/c0c48474fb4f61dc32433a068c248827f11bc3466bc577efb5ae968e3dc86f95.jpg", "table_caption": ["Table 5: Performance of RECURVE with varying the hyperparameter $w$ (the best results in bold). ", "The sensitivity analysis on the representation dimensionality $d^{\\prime}$ is available in Appendix C. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we present RECURVE, a novel boundary detection method that uses the curvature of a representation trajectory to replace the consecutive distance for a change metric. Theoretically, the mean curvature of an intra-segment trajectory is greater than that of an inter-segment trajectory due to the confining nature of the representations of the points within a single class. Unlike the consecutive distance, this property of the curvature is insensitive to the degree of the changes between two classes (segments). Our comprehensive experiments confirm that RECURVE achieves up to $12.7\\%$ higher detection accuracy than state-of-the-art methods. Overall, we believe that our work pioneers a new direction for boundary detection in time series. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2020-0-00862 / RS-2020-II200862, DB4DL: High-Usability and Performance In-Memory Distributed DBMS for Deep Learning, $50\\%$ and No. 2022-0-00157 / RS-2022-II220157, Robust, Fair, Extensible Data-Centric Continual Learning, $50\\%$ ). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Samaneh Aminikhanghahi and Diane J Cook. A survey of methods for time series change point detection. Knowledge and Information Systems, 51:339\u2013367, 2017.   \n[2] Charles Truong, Laurent Oudre, and Nicolas Vayatis. Selective review of offline change point detection methods. Signal Processing, 167:107299, 2020.   \n[3] Yazan Abu Farha and Jurgen Gall. MS-TCN: Multi-stage temporal convolutional network for action segmentation. In Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 3575\u20133584, 2019.   \n[4] Fan Ma, Linchao Zhu, Yi Yang, Shengxin Zha, Gourab Kundu, Matt Feiszli, and Zheng Shou. SF-Net: Single-frame supervision for temporal action localization. In Proceedings of European Conference on Computer Vision (ECCV), pages 420\u2013437, 2020.   \n[5] Zhe Li, Yazan Abu Farha, and Jurgen Gall. Temporal action segmentation from timestamp supervision. In Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8365\u20138374, 2021.   \n[6] Yuchi Ishikawa, Seito Kasai, Yoshimitsu Aoki, and Hirokatsu Kataoka. Alleviating oversegmentation errors by detecting action boundaries. In Proceedings of IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), pages 2322\u20132331, 2021.   \n[7] Yooju Shin, Susik Yoon, Sundong Kim, Hwanjun Song, Jae-Gil Lee, and Byung Suk Lee. Coherence-based label propagation over time series for accelerated active learning. In Proceedings of International Conference on Learning Representations (ICLR), 2022.   \n[8] Jaxk Reeves, Jien Chen, Xiaolan L Wang, Robert Lund, and Qi Qi Lu. A review and comparison of changepoint detection techniques for climate data. Journal of Applied Meteorology and Climatology, 46(6):900\u2013915, 2007.   \n[9] Rakesh Malladi, Giridhar P Kalamangalam, and Behnaam Aazhang. Online bayesian change point detection algorithms for segmentation of epileptic activity. In Proceedings of Asilomar Conference on Signals, Systems and Computers, pages 1833\u20131837, 2013.   \n[10] Andrey Pepelyshev and Aleksey S Polunchenko. Real-time financial surveillance via quickest change-point detection methods. Statistics and Its Interface, 10:93\u2013106, 2016.   \n[11] Qingxin Xia, Joseph Korpela, Yasuo Namioka, and Takuya Maekawa. Robust unsupervised factory activity recognition with body-worn accelerometer using temporal structure of multiple sensor data motifs. Proceedings of ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 4(3):1\u201330, 2020.   \n[12] Tim De Ryck, Maarten De Vos, and Alexander Bertrand. Change point detection in time series data using autoencoders with a time-invariant representation. Signal Processing, 69:3513\u20133524, 2021.   \n[13] Shohreh Deldari, Daniel V Smith, Hao Xue, and Flora D Salim. Time series change point detection with self-supervised contrastive predictive coding. In Proceedings of the Web Conference (WWW), pages 3124\u20133135, 2021.   \n[14] Sana Tonekaboni, Danny Eytan, and Anna Goldenberg. Unsupervised representation learning for time series with temporal neighborhood coding. In Proceedings of International Conference on Learning Representations (ICLR), 2021.   \n[15] Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong, and Bixiong Xu. Ts2vec: Towards universal representation of time series. In Proceedings of AAAI Conference on Artificial Intelligence (AAAI), pages 8980\u20138987, 2022.   \n[16] Xiang Zhang, Ziyuan Zhao, Theodoros Tsiligkaridis, and Marinka Zitnik. Self-supervised contrastive pre-training for time series via time-frequency consistency. In Proceedings of Conference on Neural Information Processing Systems (NeurIPS), pages 3988\u20134003, 2022.   \n[17] Thomas Lewiner, Jo\u00e3o D Gomes Jr, H\u00e9lio Lopes, and Marcos Craizer. Curvature and torsion estimators based on parametric curve fitting. Computers & Graphics, 29(5):641\u2013655, 2005.   \n[18] Yifei Wang, Qi Zhang, Yisen Wang, Jiansheng Yang, and Zhouchen Lin. Chaos is a ladder: A new theoretical understanding of contrastive learning via augmentation overlap. In Proceedings of International Conference on Learning Representations (ICLR), 2022.   \n[19] Advait Parulekar, Liam Collins, Karthikeyan Shanmugam, Aryan Mokhtari, and Sanjay Shakkottai. Infonce loss provably learns cluster-preserving representations. arXiv preprint arXiv:2302.07920, 2023.   \n[20] Daniel R Jeske, Veronica Montes De Oca, Wolfgang Bischoff, and Mazda Marvasti. Cusum techniques for timeslot sequences with applications to network surveillance. Computational Statistics & Data Analysis, 53(12):4332\u20134344, 2009.   \n[21] Haeran Cho and Piotr Fryzlewicz. Multiple-change-point detection for high dimensional time series via sparsified binary segmentation. Journal of the Royal Statistical Society Series B: Statistical Methodology, 77(2):475\u2013507, 2015.   \n[22] Makoto Yamada, Akisato Kimura, Futoshi Naya, and Hiroshi Sawada. Change-point detection with feature selection in high-dimensional time-series data. In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI), pages 1827\u20131833, 2013.   \n[23] Kyle D Feuz, Diane J Cook, Cody Rosasco, Kayela Robertson, and Maureen SchmitterEdgecombe. Automated detection of activity transitions for prompting. IEEE Transactions on Human-Machine Systems, 45(5):575\u2013585, 2014.   \n[24] Mikhail Hushchyn and Andrey Ustyuzhanin. Generalization of change-point detection in time series data based on direct density ratio estimation. Journal of Computational Science, 53:101385, 2021.   \n[25] Zaid Harchaoui, Eric Moulines, and Francis Bach. Kernel change-point analysis. In Proceedings of Conference on Neural Information Processing Systems (NeurIPS), pages 609\u2013616, 2008.   \n[26] Wei-Cheng Chang, Chun-Liang Li, Yiming Yang, and Barnab\u00e1s P\u00f3czos. Kernel change-point detection with auxiliary deep generative models. arXiv preprint arXiv:1901.06077, 2019.   \n[27] Shaghayegh Gharghabi, Chin-Chia Michael Yeh, Yifei Ding, Wei Ding, Paul Hibbing, Samuel LaMunion, Andrew Kaplan, Scott E Crouter, and Eamonn Keogh. Domain agnostic online semantic segmentation for multi-dimensional time series. Data Mining and Knowledge Discovery, 33:96\u2013130, 2019.   \n[28] Jesin Zakaria, Abdullah Mueen, and Eamonn Keogh. Clustering time series using unsupervisedshapelets. In Proceedings of International Conference on Data Mining (ICDM), pages 785\u2013794, 2012.   \n[29] Shohreh Deldari, Daniel V Smith, Amin Sadri, and Flora Salim. Espresso: Entropy and shape aware time-series segmentation for processing heterogeneous sensor data. Proceedings of ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 4(3):1\u201324, 2020.   \n[30] Kexin Zhang, Qingsong Wen, Chaoli Zhang, Rongyao Cai, Ming Jin, Yong Liu, James Zhang, Yuxuan Liang, Guansong Pang, Dongjin Song, et al. Self-supervised learning for time series analysis: Taxonomy, progress, and prospects. arXiv preprint arXiv:2306.10125, 2023.   \n[31] Qianli Ma, Zhen Liu, Zhenjing Zheng, Ziyang Huang, Siying Zhu, Zhongzhong Yu, and James T Kwok. A survey on time-series pre-trained models. arXiv preprint arXiv:2305.10716, 2023.   \n[32] Pankaj Malhotra, Vishnu TV, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. Timenet: Pre-trained deep recurrent neural network for time series classification. arXiv preprint arXiv:1706.08838, 2017.   \n[33] Qianli Ma, Jiawei Zheng, Sen Li, and Gary W Cottrell. Learning representations for time series clustering. In Proceedings of Conference on Neural Information Processing Systems (NeurIPS), pages 3781\u20133791, 2019.   \n[34] Zezhi Shao, Zhao Zhang, Fei Wang, and Yongjun Xu. Pre-training enhanced spatial-temporal graph neural network for multivariate time series forecasting. In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 1567\u20131577, 2022.   \n[35] Ranak Roy Chowdhury, Xiyuan Zhang, Jingbo Shang, Rajesh K Gupta, and Dezhi Hong. TARnet: Task-aware reconstruction for time-series transformer. In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 212\u2013220, 2022.   \n[36] Jatin Chauhan, Aravindan Raghuveer, Rishi Saket, Jay Nandy, and Balaraman Ravindran. Multi-variate time series forecasting on variable subsets. In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 76\u201386, 2022.   \n[37] Jean-Yves Franceschi, Aymeric Dieuleveut, and Martin Jaggi. Unsupervised scalable representation learning for multivariate time series. In Proceedings of Conference on Neural Information Processing Systems (NeurIPS), 2019.   \n[38] Minghao Chen, Fangyun Wei, Chong Li, and Deng Cai. Frame-wise action representations for long videos via sequence contrastive learning. In Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 13801\u201313810, 2022.   \n[39] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In Proceedings of International Conference on Machine Learning (ICML), pages 1597\u20131607, 2020.   \n[40] Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong Kwoh, Xiaoli Li, and Cuntai Guan. Time-series representation learning via temporal and contextual contrasting. In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI), pages 2352\u20132359, 2021.   \n[41] Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven Hoi. CoST: Contrastive learning of disentangled seasonal-trend representations for time series forecasting. In Proceedings of International Conference on Learning Representations (ICLR), 2021.   \n[42] Ling Yang and Shenda Hong. Unsupervised time-series representation learning with iterative bilinear temporal-spectral fusion. In Proceedings of International Conference on Machine Learning (ICML), pages 25038\u201325054, 2022.   \n[43] Andriy Mnih and Koray Kavukcuoglu. Learning word embeddings efficiently with noisecontrastive estimation. In Proceedings of Conference on Neural Information Processing Systems (NeurIPS), pages 2265\u20132273, 2013.   \n[44] Jae-Gil Lee, Jiawei Han, and Kyu-Young Whang. Trajectory clustering: A partition-andgroup framework. In Proceedings of ACM International Conference on Management of Data (SIGMOD), pages 593\u2013604, 2007.   \n[45] Maike Buchin, Anne Driemel, Marc J Van Kreveld, and Vera Sacrist\u00e1n. Segmenting trajectories: A framework and algorithms using spatiotemporal criteria. Journal of Spatial Information Science, 3:33\u201363, 2011.   \n[46] Yooju Shin, Susik Yoon, Hwanjun Song, Dongmin Park, Byunghyun Kim, Jae-Gil Lee, and Byung Suk Lee. Context consistency regularization for label sparsity in time series. In Proceedings of International Conference on Machine Learning (ICML), pages 31579\u201331595, 2023.   \n[47] Y Diao, C Ernst, A Montemayor, and U Ziegler. Curvature of random walks and random polygons in confinement. Journal of Physics A: Mathematical and Theoretical, 46:285201, 2013.   \n[48] Jennifer R Kwapisz, Gary M Weiss, and Samuel A Moore. Activity recognition using cell phone accelerometers. ACM SIGKDD Explorations Newsletter, 12:74\u201382, 2011.   \n[49] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge Luis Reyes-Ortiz, et al. A public domain dataset for human activity recognition using smartphones. In Proceedings of European Symposium on Artificial Neural Networks (ESANN), pages 437\u2013442, 2013.   \n[50] Sebastian Stein and Stephen J McKenna. Combining embedded accelerometers with computer vision for recognizing food preparation activities. In Proceedings of ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp), pages 729\u2013738, 2013.   \n[51] Patrick Sch\u00e4fer, Arik Ermshaus, and Ulf Leser. Clasp-time series segmentation. In Proceedings of ACM International Conference on Information and Knowledge Management (CIKM), pages 1578\u20131587, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A The Proof of Theorem 3.8 in a Special Case ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To explain Theorem 3.8 in a more intuitive way, we assume a special case in the 2-dimensional space as shown in Figure 4. Let we have a random walk composed of three points $\\mathbf{z}_{t}-,\\mathbf{z}_{t}$ , and $\\mathbf{z}_{t^{+}}$ in a 2-dimensional representation space. In the figure, there are three black dots in a row for the intra-segment trajectory (gray line) and the inter-segment trajectory (red line) respectively to visualize these three points in each trajectory. Here, $\\mathbf{z}_{t}$ is an arbitrary point on the border of a confining circle $S_{C_{i}}$ or the enclosing circle. $\\mathbf{z}_{t^{-}}$ is the point on the line between the origin and $\\mathbf{z}_{t}$ . Finally, we consider $\\mathbf{z}_{t^{+}}$ as a random point distributed uniformly on the unit circle centered at $\\mathbf{z}_{t}$ while the locations of $\\mathbf{z}_{t}$ and $\\mathbf{z}_{t-1}$ are fixed. In this case, we compare the average curvature at the single timestamp $t$ of the intra-segment trajectory and that of the inter-segment trajectory. ", "page_idx": 14}, {"type": "text", "text": "Lemma A.1 (AVERAGE CURVATURE). When the two points $\\mathbf{z}_{t^{-}}$ and $\\mathbf{z}_{t}$ are fixed, the curvature \u03ba at $\\mathbf{z}_{t}$ averaged over the location of $\\mathbf{z}_{t^{+}}$ is ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\kappa_{T}(R)=\\pi-\\frac{1}{2}a r c c o s\\frac{1}{2R}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. When the confinement radius is $R$ , the range of the turning angle is $\\left[\\pi-\\operatorname{arccos}{\\textstyle{\\frac{1}{2R}}},\\pi\\right]$ using the cosine rule on the triangle composed of the points of intersection between $S_{C_{i}}$ and the unit circle centered at $\\mathbf{z}_{t}$ . \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Lemma A.2 (CHARACTERISTIC OF AVERAGE CURVATURE). When $R>1$ , $\\kappa\\tau(R)$ decreases as the radius $R$ increases, i.e., $\\kappa_{T}(R)$ is a decreasing function of $R$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. The derivative of $\\kappa$ is $\\begin{array}{r}{\\frac{\\mathrm{d}}{\\mathrm{d}R}\\kappa_{T}(R)=-\\frac{1}{2R\\sqrt{4R^{2}-1}}}\\end{array}$ and the derivative is always negative when $R>1$ . Therefore, $\\kappa_{T}(R)$ is a decreasing function of $R$ . ", "page_idx": 14}, {"type": "text", "text": "Similar to Theorem 3.8, Proposition 3.5 and Lemma A.2 lead to Theorem A.3. ", "page_idx": 14}, {"type": "text", "text": "Theorem A.3 (AVERAGE CURVATURE DIFFERENCE). The average curvature of an intra-segment trajectory $\\kappa_{T_{i n t r a}}(R_{i n t r a})$ is greater than that of an inter-segment trajectory $\\kappa_{T_{i n t e r}}(R_{i n t e r})$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. The radius of the confining circle of an inter-segment trajectory is always bigger than that of an intra-segment trajectory because an inter-segment trajectory traverses two distinctive class balls. As $\\kappa\\tau(R)$ is a decreasing function, $\\kappa_{\\mathcal{T}_{i n t r a}}(R_{i n t r a})>\\kappa_{\\mathcal{T}_{i n t e r}}(R_{i n t e r})$ . \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Theorem A.3 concludes that the average curvature at $\\mathbf{z}_{t}$ is greater if $\\mathbf{z}_{t}$ is at the border of a smaller confining circle. This result can be extended to Theorem 3.8 intuitively. As $R$ increases, the probability of a trajectory hitting the border decreases as a random walk can traverse in a larger space. Therefore, the mean curvature decreases if a trajectory resides in a smaller confining circle. ", "page_idx": 14}, {"type": "text", "text": "B Hyperparameters for Compared Methods ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For RuLSIF, we conduct a grid search for the learning rate $(\\mathrm{LR})=\\{0.05,0.1,0.2\\}$ , the weight of L2 normalization $\\lambda_{\\mathrm{L}2}=\\{0.01\\dot{,}0.05,0.1\\}$ , and the parameter of the RuLSIF loss $\\alpha=\\{0.01,0.05,0.1\\}$ . When applying RuLSIF to the four datasets, we use a multilayer perceptron with a single hidden layer with 100 units and train it with a batch size of 32 for 50 epochs. For KL-CPD, we conduct a grid search to determine the optimal hidden dimensionality $h=\\{10,50,100\\}$ of the RNN encoder/decoder, as well as the values for the hyperparameters $\\lambda_{\\mathrm{AE}}=\\{0.1,0.01,0.001\\}$ and $\\lambda_{\\mathrm{Real}}=\\{0.1,0.01,0.001\\}$ which govern the influence of the reconstruction loss and the MMD2 loss on real datasets. For training the generator of KL-CPD, the batch size is set to 64, the number of epochs is set to 3, and the learning rate is set to 0.001. Table 6 provides a summary of the determined hyperparameter values. ", "page_idx": 14}, {"type": "text", "text": "C Sensitivity Analysis on Representation Dimensionality ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Table 7 shows the performance of RECURVE while varying the representation dimensionality $d^{\\prime}$ when the error margin $p$ for the AUC measure is fixed at 10. The value of $d^{\\prime}$ ranges from $0.25\\times$ to $4.00\\times$ of the default value, which is 8 for WISDM and HAPT or 32 for mHealth and 50salads ", "page_idx": 14}, {"type": "text", "text": "Table 6: Hyperparameter values of RuLSIF (left half) and KL-CPD (right half) after a grid search. ", "page_idx": 15}, {"type": "table", "img_path": "WK2KxPAMQv/tmp/2a9b226fe63ec8c0735d947290874a63034fcd88a9366cca06715aa4057c9134.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "(indicated by $1.00\\!\\times\\!)$ . A trade-off point in the representation dimensionality exists for nearly all datasets. A representation space with an excessively high dimensionality is susceptible to the curse of dimensionality. If the value of $d^{\\prime}$ were too large, the turning angle and distance in Eq. (5) would be indistinguishable across all timestamps in a time series, as any two points in a high-dimensional space would become nearly orthogonal and their distance would always be similar. If the value of $w$ were too small, low-quality features would be extracted from the original time series by representation learning; thus, the performance degrades with an insufficient dimensionality as shown in the result of 50salads whose data dimensionality is 2048. Overall, the default setting is suitable for achieving competitive performance for all datasets. ", "page_idx": 15}, {"type": "table", "img_path": "WK2KxPAMQv/tmp/a9830faf61fe63dfbcf75b95f5e92245d0dbea9ee3eee840abfcb8b3b5169c4b.jpg", "table_caption": ["Table 7: Performance of RECURVE with varying the hyperparameter $d^{\\prime}$ (the best results in bold). "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "D Limitations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "One notable limitation of RECURVE is the potential occurrence of false positives, particularly when dealing with short segment lengths that fall below the predefined threshold, denoted as $w$ . For instance, consider a scenario where there is a rapid transition from one activity class to another, such as transitioning from walking for an extended period to a brief sprint, followed by resuming walking. In such cases, if the segment length is shorter than the specified $w$ duration, every timestamp within the brief sprint segment might erroneously be identified as a boundary, leading to a number of false positives. To mitigate this issue, we have implemented a strategy where $w$ is determined as $5\\%$ of the mean segment length. However, it is worth noting that this approach may encounter challenges in rare cases where the segment lengths exhibit significant variance. We will further investigate how segment length variance impacts the efficacy of RECURVE as future work. ", "page_idx": 15}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: Abstract and introduction (4th-6th paragraphs) contain contributions and problem scope. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 16}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Justification: Appendix D contains the rare case where RECURVE does not work well. Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 16}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: To the best of our knowledge, Section 3.4 contains all of details for the theoretical analysis. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 17}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Section 4.1 contains dataset summary and implementation details for reproducing main experimental results. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 17}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: Section 4.1 contains a link for source code and datasets. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 18}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: Section 4.1 contains the evaluation measures for boundary detection and hardware specification in representation learning. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 18}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: All experimental tables have the standard deviation values from five independent trials. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The last paragraph in Section 4.1 explains hardware specification to run the experiments. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 19}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper does not have any potential harms or such consequences. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 19}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 19}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 20}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks. ", "page_idx": 20}, {"type": "text", "text": "\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 20}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. ", "page_idx": 20}, {"type": "text", "text": "\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 21}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 21}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] Justification: ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 21}]