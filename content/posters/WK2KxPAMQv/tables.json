[{"figure_path": "WK2KxPAMQv/tables/tables_6_1.jpg", "caption": "Table 1: Summary of datasets and hyper-parameters.", "description": "This table summarizes the characteristics of four datasets used in the experiments. For each dataset, it provides the number of timestamps, the average length of segments between boundaries, the number of classes, the dimensionality of the data, the sampling rate in Hz, the number of boundaries, the size of the sliding window used for representation learning, and the number of training epochs.", "section": "4.1 Experiment Setting"}, {"figure_path": "WK2KxPAMQv/tables/tables_7_1.jpg", "caption": "Table 2: Overall detection accuracy in the AUC measure (the best results in bold).", "description": "This table presents the Area Under the ROC Curve (AUC) scores for five different boundary detection methods (RuLSIF, KL-CPD, TS-CP2, RECURVE+TPC, RECURVE+TNC) across four datasets (WISDM, HAPT, mHealth, 50salads).  The AUC is calculated with three different error margins (p = 5, 10, 20), representing the tolerance for error in boundary detection.  The best performing method for each dataset and error margin is highlighted in bold.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "WK2KxPAMQv/tables/tables_7_2.jpg", "caption": "Table 2: Overall detection accuracy in the AUC measure (the best results in bold).", "description": "This table presents the Area Under the ROC Curve (AUC) values for five different boundary detection methods across four datasets.  The AUC is a common metric for evaluating the performance of binary classification. Results are shown for different error margins (p=5, 10, 20) to account for noise in the data and varying tolerances for boundary detection. The best performing method for each dataset and error margin is highlighted in bold.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "WK2KxPAMQv/tables/tables_8_1.jpg", "caption": "Table 2: Overall detection accuracy in the AUC measure (the best results in bold).", "description": "This table presents the Area Under the ROC Curve (AUC) scores for five different boundary detection methods across four datasets.  The AUC is a common metric for evaluating the performance of binary classification, here measuring the ability of each method to correctly identify boundaries (change points) in time series data.  The results are shown for different error margins (p = 5, 10, 20), reflecting varying levels of tolerance for slight mismatches in boundary location. The table highlights the superior performance of RECURVE compared to state-of-the-art methods in all datasets and error margin settings.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "WK2KxPAMQv/tables/tables_9_1.jpg", "caption": "Table 2: Overall detection accuracy in the AUC measure (the best results in bold).", "description": "This table presents the AUC (Area Under the ROC Curve) scores for five different boundary detection methods (RuLSIF, KL-CPD, TS-CP2, RECURVE+TPC, RECURVE+TNC) across four datasets (WISDM, HAPT, mHealth, 50salads).  The AUC is a measure of the ability of a classifier to distinguish between classes, with higher scores indicating better performance.  Results are shown for three different error margins (p = 5, 10, 20), representing the tolerance for errors in boundary detection. The best performing method for each dataset and error margin is highlighted in bold.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "WK2KxPAMQv/tables/tables_15_1.jpg", "caption": "Table 1: Summary of datasets and hyper-parameters.", "description": "This table summarizes the characteristics of the four datasets used in the experiments, including the number of timestamps, mean segment length, number of classes, dimensionality of the data, sampling rate, and number of boundaries.  It also lists the hyperparameters used for each dataset, such as window size and number of epochs. These hyperparameters are used for the representation learning method.", "section": "4.1 Experiment Setting"}, {"figure_path": "WK2KxPAMQv/tables/tables_15_2.jpg", "caption": "Table 7: Performance of RECURVE with varying the hyperparameter d' (the best results in bold).", "description": "This table presents the results of an experiment that investigated the effect of varying the representation dimensionality (d') on the performance of the RECURVE algorithm. The experiment was conducted using four different datasets (WISDM, HAPT, mHealth, and 50Salads), two different representation learning methods (TPC and TNC), and different values of d' (0.25x, 0.50x, 1.00x, 2.00x, and 4.00x of the default value).  The performance is measured using two metrics: AUC (Area Under the ROC Curve), and LOC (mean LOCation distance). For each combination of dataset, representation learning method, and d', the table shows the mean and standard deviation of the AUC and LOC values obtained from five independent trials.", "section": "4.6 Sensitivity Analysis on the Hyperparameter w"}]