[{"figure_path": "PacBluO5m7/figures/figures_1_1.jpg", "caption": "Figure 1: A real-world question from Open-bookQA. GPT-3.5 could effectively correct the answer given the scientific reasoning background from ConceptNet (blue: question concepts, red: answers, grey: entities not present in questions).", "description": "This figure illustrates a question from the OpenBookQA dataset, where an LLM (GPT-3.5) initially provides an incorrect answer.  However, by incorporating knowledge from ConceptNet, a knowledge graph, the LLM is able to correct its answer. The figure visually represents the question, the incorrect and correct answers, and the relevant knowledge from ConceptNet used for correction. The color coding helps distinguish between question concepts, correct answers, and external knowledge.", "section": "Introduction"}, {"figure_path": "PacBluO5m7/figures/figures_2_1.jpg", "caption": "Figure 2: The overall architecture of our proposed knowledge graph prompting framework, i.e., KnowGPT. Given the question context with multiple choices, we first retrieve a question-specific subgraph from the real-world KG. Knowledge Extraction is first dedicated to searching for the most informative and concise reasoning background subject to the context. Then the Prompt Construction module is optimized to prioritize the combination of knowledge and formats subject to the given question.", "description": "This figure illustrates the KnowGPT framework's architecture.  It begins with question context and multiple-choice answers, extracting source and target entities.  A question-specific subgraph is retrieved from a knowledge graph (KG).  The Knowledge Extraction module uses deep reinforcement learning to find the most informative and concise reasoning background.  The Prompt Construction module, using a multi-armed bandit approach, prioritizes combinations of knowledge and formats for optimal LLM input. The final prioritized prompt is then sent to GPT-4 for answering the question.", "section": "3 KnowGPT Framework"}, {"figure_path": "PacBluO5m7/figures/figures_9_1.jpg", "caption": "Figure 2: The overall architecture of our proposed knowledge graph prompting framework, i.e., KnowGPT. Given the question context with multiple choices, we first retrieve a question-specific subgraph from the real-world KG. Knowledge Extraction is first dedicated to searching for the most informative and concise reasoning background subject to the context. Then the Prompt Construction module is optimized to prioritize the combination of knowledge and formats subject to the given question.", "description": "This figure illustrates the KnowGPT framework's architecture.  It starts with a question and multiple choices, then retrieves a relevant subgraph from a knowledge graph (KG).  A knowledge extraction module identifies the most informative and concise reasoning paths within the subgraph. Finally, a prompt construction module creates an effective prompt for an LLM by combining the extracted knowledge with suitable formats based on the question's context.", "section": "3 KnowGPT Framework"}]