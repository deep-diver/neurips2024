[{"figure_path": "SXy1nVGyO7/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative identifiability metrics for the presented meta-hybrid-VAE in comparison to physics-integrated hybrid-VAE [2] and APHYNITY [1], including MSE and MCC metrics on the latent variables, as well as MSE of generated x during reconstruction of observed samples (Rec) and prediction of unobserved samples (Pre).", "description": "This table presents a quantitative comparison of the identifiability performance of three different hybrid VAEs: the proposed meta-hybrid VAE and two existing models (physics-integrated hybrid-VAE and APHYNITY).  Identifiability is evaluated using Mean Squared Error (MSE) and Matthews Correlation Coefficient (MCC) for both the physics-based and neural latent variables. Additionally, MSE is calculated for the reconstruction and prediction of the observed samples, offering a comprehensive evaluation of each model's ability to identify and generalize from the data.", "section": "6 Experiments and Results"}, {"figure_path": "SXy1nVGyO7/tables/tables_14_1.jpg", "caption": "Table 1: Quantitative identifiability metrics for the presented meta-hybrid-VAE in comparison to physics-integrated hybrid-VAE [2] and APHYNITY [1], including MSE and MCC metrics on the latent variables, as well as MSE of generated x during reconstruction of observed samples (Rec) and prediction of unobserved samples (Pre).", "description": "This table presents a comparison of quantitative identifiability metrics between the proposed meta-hybrid Variational Autoencoder (VAE) and two baseline methods: physics-integrated hybrid-VAE and APHYNITY.  The metrics used include Mean Squared Error (MSE) and Matthews Correlation Coefficient (MCC) for latent variables (zp and zn), and MSE for the generated data x, broken down into reconstruction and prediction performance.  Lower MSE values and higher MCC values indicate better identifiability.", "section": "Experiments and Results"}, {"figure_path": "SXy1nVGyO7/tables/tables_14_2.jpg", "caption": "Table 3: Comparison results of Non-meta and Meta", "description": "This table compares the performance of Non-meta and Meta methods in terms of MSE of zp, MCC, MSE of x (Rec), and MSE of x (Pre).  The results show that the Meta method achieves lower MSE of zp and MSE of x (Pre) while maintaining similar MCC and MSE of x (Rec).", "section": "Experiments and Results"}, {"figure_path": "SXy1nVGyO7/tables/tables_14_3.jpg", "caption": "Table 1: Quantitative identifiability metrics for the presented meta-hybrid-VAE in comparison to physics-integrated hybrid-VAE [2] and APHYNITY [1], including MSE and MCC metrics on the latent variables, as well as MSE of generated x during reconstruction of observed samples (Rec) and prediction of unobserved samples (Pre).", "description": "This table presents a comparison of quantitative identifiability metrics for three different hybrid VAEs: the presented meta-hybrid VAE, the physics-integrated hybrid VAE from prior work, and APHYNITY.  It evaluates performance using Mean Squared Error (MSE) and Matthews Correlation Coefficient (MCC) for latent variables (zp and zn), and also MSE for reconstruction and prediction of observed samples (x). Lower MSE values and higher MCC values indicate better identifiability.", "section": "Experiments and Results"}, {"figure_path": "SXy1nVGyO7/tables/tables_15_1.jpg", "caption": "Table 1: Quantitative identifiability metrics for the presented meta-hybrid-VAE in comparison to physics-integrated hybrid-VAE [2] and APHYNITY [1], including MSE and MCC metrics on the latent variables, as well as MSE of generated x during reconstruction of observed samples (Rec) and prediction of unobserved samples (Pre).", "description": "This table presents a quantitative comparison of the identifiability of three different hybrid VAEs: the proposed meta-hybrid VAE, a physics-integrated hybrid VAE, and APHYNITY.  Identifiability is measured using Mean Squared Error (MSE) and Matthews Correlation Coefficient (MCC) for both the physics-based and neural latent variables.  Additionally, it shows the MSE of the generated data (x) for both reconstruction and prediction tasks, allowing a comparative evaluation of the models' ability to accurately learn and generalize from data.", "section": "6 Experiments and Results"}]