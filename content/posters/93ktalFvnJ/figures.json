[{"figure_path": "93ktalFvnJ/figures/figures_1_1.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation results of different text-to-image unlearning methods.  Two unlearning tasks are shown: removing nudity and removing Van Gogh style from generated images. The figure demonstrates that the proposed method (RGD) maintains high alignment scores (semantic accuracy) between the generated image and its text prompt, even after unlearning, unlike the baseline methods (SalUn and ESD) which generate images that are semantically incorrect.", "section": "1 Introduction"}, {"figure_path": "93ktalFvnJ/figures/figures_4_1.jpg", "caption": "Figure 2: Visualization of the update. We show the update direction (gray) obtained by (a) directly summing up the two gradients and (b) our restricted gradient.", "description": "This figure visualizes the difference between two gradient update methods: direct aggregation and the restricted gradient proposed by the authors.  The left panel (a) shows the direct summation of the gradients for the forgetting loss (\u2207Lf) and the remaining loss (\u2207Lr). The resultant update direction is simply the sum of the two individual gradient vectors.  The right panel (b) illustrates the authors' restricted gradient method. Here, instead of directly summing the gradients, the method projects each gradient vector onto the orthogonal subspace of the other, resulting in modified gradient vectors (\u03b4*f and \u03b4*r). The final update direction (\u03b4*f + \u03b4*r) is a combination of these projected gradient vectors, aiming to find a balance between the two often conflicting objectives.", "section": "3 Our Approach"}, {"figure_path": "93ktalFvnJ/figures/figures_7_1.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation results of different text-to-image unlearning methods.  The top row shows the results for removing nudity from images, while the bottom row demonstrates removing Van Gogh's artistic style.  The leftmost column shows the original Stable Diffusion (SD) generated images.  Subsequent columns show results after unlearning using SalUn, ESD, and the authors' proposed method (RGD). The results highlight that RGD maintains better alignment with the original prompt than competing methods, demonstrating its effectiveness in removing unwanted content while preserving the overall quality of generated images.", "section": "1 Introduction"}, {"figure_path": "93ktalFvnJ/figures/figures_7_2.jpg", "caption": "Figure 4: The nudity detection results by Nudenet, following prior works [Fan et al., 2023, Gandikota et al., 2023]. The Y-axis shows the exposed body part in the generated images, given the prompt, and the X-axis denotes the number of images generated by each unlearning method and SD. We exclude bars from the plot if the corresponding value is zero.", "description": "This figure compares the number of images with nudity generated by different unlearning methods (RGD, GradDiffD, SalUn, ESD-u, ESD) and the original Stable Diffusion model (SD).  The x-axis represents the number of images generated with nudity detected by Nudenet, and the y-axis shows the type of body part detected.  It shows that RGD generates the least number of images with nudity, demonstrating its superior performance in nudity removal compared to other methods.", "section": "4.3 Target Concept Removal from Diffusion Models"}, {"figure_path": "93ktalFvnJ/figures/figures_8_1.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation quality of different unlearning methods.  It shows generated images for two unlearning tasks: removing nudity and removing Van Gogh's style.  The results demonstrate that the proposed method (RGD) maintains high image-text alignment after unlearning, unlike existing methods like SalUn and ESD, which suffer from poor unlearning quality and degraded alignment.", "section": "1 Introduction"}, {"figure_path": "93ktalFvnJ/figures/figures_8_2.jpg", "caption": "Figure 6: Performance analysis across different hyperparameter settings. Each box plot captures the variation over different a values for a given \u03bb setting (\u03bb\u2208 {0.5, 1.0, 5.0}), measuring both generation quality (FID, left) and remaining accuracy (RA, right). Lower FID indicates better generation quality, while higher RA indicates better model utility of non-target concepts.", "description": "This figure shows the impact of hyperparameters (\u03bb and \u03b1) on the performance of the proposed method.  The left plot displays the FID (Fr\u00e9chet Inception Distance), a measure of generated image quality, while the right plot shows the RA (Remaining Accuracy), which quantifies how well the model performs on non-target classes after unlearning.  The box plots illustrate the distribution of FID and RA values across different settings of the hyperparameters.  Generally, lower FID and higher RA are preferred, indicating better performance. The results demonstrate that the RGD method consistently outperforms other methods across different hyperparameter settings.", "section": "4.4 Ablation"}, {"figure_path": "93ktalFvnJ/figures/figures_19_1.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation results of different text-to-image unlearning methods.  It shows that the proposed method maintains high alignment between generated images and text prompts after removing specific concepts (nudity and Van Gogh style), unlike existing methods (SalUn and ESD) which fail to generate semantically correct images after unlearning.  The figure visually demonstrates that the proposed method achieves higher alignment scores than the baselines.  The alignment scores are provided for each method and task, showcasing the superior performance of the proposed approach in preserving text-image alignment while successfully removing undesired content.", "section": "1 Introduction"}, {"figure_path": "93ktalFvnJ/figures/figures_19_2.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation results of different text-to-image unlearning methods.  Two unlearning tasks are shown: removing nudity from images and removing Van Gogh's style from images.  The figure demonstrates that the proposed method (Ours) maintains high alignment with the original image quality and prompt after unlearning, whereas other methods (SalUn and ESD) produce images that are poorly aligned and semantically incorrect.  The alignment score (a metric measuring how well the generated image matches the given text prompt) is significantly better for the proposed method.", "section": "1 Introduction"}, {"figure_path": "93ktalFvnJ/figures/figures_20_1.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation quality of three different unlearning methods (SalUn, ESD, and the proposed method) against the original Stable Diffusion model (SD) after unlearning two specific concepts: nudity and Van Gogh's art style.  The results show that the proposed method maintains a high level of image-text alignment after unlearning, unlike the other methods which show significantly lower alignment scores and generate semantically incorrect images. The alignment score is a quantitative measure of how well the generated image matches the given text prompt.", "section": "1 Introduction"}, {"figure_path": "93ktalFvnJ/figures/figures_20_2.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation results of different text-to-image unlearning methods.  Two unlearning tasks are shown: removing nudity and removing Van Gogh style.  The figure demonstrates that the proposed method maintains high alignment scores between generated images and their text descriptions, unlike existing methods (SalUn and ESD) which show significantly lower alignment scores after unlearning.", "section": "1 Introduction"}, {"figure_path": "93ktalFvnJ/figures/figures_21_1.jpg", "caption": "Figure 1: Generated images using SalUn [Fan et al., 2023], ESD [Gandikota et al., 2023], and Ours after unlearning given the condition. Each row indicates different unlearning tasks: nudity removal, and Van Gogh style removal. Generated images from our approach and SD [Rombach et al., 2022] are well-aligned with the prompt, whereas SalUn and ESD fail to generate semantically correct images given the condition. On average, across 100 different prompts, SalUn shows the lowest clip alignment scores (0.305 for nudity removal and 0.280 for Van Gogh style removal), followed by ESD (0.329 and 0.330, respectively). Our approach achieves scores of 0.350 and 0.352 for these tasks, closely matching the original SD scores of 0.352 and 0.348.", "description": "This figure compares the image generation results of different text-to-image unlearning methods.  It showcases the performance of SalUn, ESD, and the proposed method (Ours) against a baseline (SD) for two unlearning tasks: removing nudity and removing a Van Gogh style.  The results demonstrate that the proposed method maintains high alignment between the generated images and the text prompt, even after unlearning, unlike the other methods which produce semantically incorrect outputs.", "section": "1 Introduction"}]