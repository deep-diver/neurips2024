[{"figure_path": "93ktalFvnJ/tables/tables_5_1.jpg", "caption": "Table 1: Quantitative evaluation of unlearning methods on CIFAR-10 diffusion-based generative models. Each method was evaluated by sequentially targeting each of the 10 CIFAR-10 classes for unlearning. For each target class, we measure unlearning accuracy (UA) specific to that class, remaining accuracy (RA) on the other 9 classes, and FID for generation quality. The reported values are averaged across all 10 class-specific unlearning experiments.", "description": "This table presents a quantitative comparison of different unlearning methods on CIFAR-10 image generation using diffusion models.  The methods are evaluated by sequentially removing each of the 10 classes from the model.  The table reports the unlearning accuracy (UA, higher is better), remaining accuracy (RA, higher is better - accuracy on the classes that weren't removed), and the Fr\u00e9chet Inception Distance (FID, lower is better) for the generated images.  The reported values are averages across all 10 experiments.", "section": "4.1 Experiment Setup"}, {"figure_path": "93ktalFvnJ/tables/tables_7_1.jpg", "caption": "Table 2: Nudity and artist removal: we calculate the clip alignment score (AS), following Lee et al. [2024], to measure the model alignment on the remaining set after unlearning. Cells highlighted in green indicate results from our method, while those in red indicate results from the pretrained model.", "description": "This table presents the results of the CLIP alignment score (AS) for both nudity and artist removal experiments.  It compares the performance of the proposed method (RGD) against several baselines (SD, ESD, ESD-u, ESD-x, SalUn, and GradDiffD).  The AS metric measures the semantic alignment between generated images and their corresponding text prompts after the unlearning process. The table shows AS scores for both the training (Dr,train) and test (Dr,test) sets of the remaining data. Green cells highlight results from the proposed method, while red cells show results from the pre-trained model (SD) to easily visualize the performance difference.", "section": "4.3 Target Concept Removal from Diffusion Models"}, {"figure_path": "93ktalFvnJ/tables/tables_9_1.jpg", "caption": "Table 3: Comparison of UA, RA, and FID for diversity-controlled experiments in CIFAR-10 diffusion models. In this context, Case 1 represents a scenario where the remaining set lacks diversity (i.e., it only includes samples from two closely related classes), while Case 2 includes equal samples from all classes. We note that we used the same remaining dataset size between both cases.", "description": "This table presents the results of a controlled experiment comparing the performance of different unlearning methods on CIFAR-10 diffusion models under two different conditions: Case 1, where the remaining dataset lacks diversity (only samples from two closely related classes); and Case 2, where the remaining dataset has balanced diversity (equal number of samples from all classes).  The metrics evaluated are Unlearning Accuracy (UA), Remaining Accuracy (RA), and Fr\u00e9chet Inception Distance (FID). The table shows that balanced diversity (Case 2) leads to significantly better performance on all metrics compared to limited diversity (Case 1).", "section": "4.4 Ablation"}, {"figure_path": "93ktalFvnJ/tables/tables_9_2.jpg", "caption": "Table 2: Nudity and artist removal: we calculate the clip alignment score (AS), following Lee et al. [2024], to measure the model alignment on the remaining set after unlearning. Cells highlighted in green indicate results from our method, while those in red indicate results from the pretrained model.", "description": "This table presents the results of CLIP alignment scores (AS) after performing nudity and artist removal. The AS metric measures how well the generated images align with the text prompts after the unlearning process. The table compares the AS scores of the proposed method (RGD) with those of several baselines (SD, ESD, ESD-u, SalUn, GradDiffD). The scores are presented separately for the training set (Dr,train) and the test set (Dr,test) of the remaining dataset. Cells highlighted in green show that the RGD method achieves alignment scores close to the pretrained model (SD), indicating that the proposed method successfully removes target concepts while maintaining model alignment.", "section": "4.3 Target Concept Removal from Diffusion Models"}, {"figure_path": "93ktalFvnJ/tables/tables_16_1.jpg", "caption": "Table 1: Quantitative evaluation of unlearning methods on CIFAR-10 diffusion-based generative models. Each method was evaluated by sequentially targeting each of the 10 CIFAR-10 classes for unlearning. For each target class, we measure unlearning accuracy (UA) specific to that class, remaining accuracy (RA) on the other 9 classes, and FID for generation quality. The reported values are averaged across all 10 class-specific unlearning experiments.", "description": "This table presents a quantitative comparison of different unlearning methods applied to CIFAR-10 diffusion models.  Each method is evaluated by sequentially removing each of the 10 classes from the model.  The table shows the unlearning accuracy (UA) for the removed class, the remaining accuracy (RA) for the other 9 classes, and the Fr\u00e9chet Inception Distance (FID), a measure of image quality. The results are averages across all 10 class removal experiments.", "section": "4.1 Experiment Setup"}, {"figure_path": "93ktalFvnJ/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative evaluation of unlearning methods on CIFAR-10 diffusion-based generative models. Each method was evaluated by sequentially targeting each of the 10 CIFAR-10 classes for unlearning. For each target class, we measure unlearning accuracy (UA) specific to that class, remaining accuracy (RA) on the other 9 classes, and FID for generation quality. The reported values are averaged across all 10 class-specific unlearning experiments.", "description": "This table presents a quantitative comparison of different unlearning methods on CIFAR-10 image generation.  For each method, three metrics are reported, averaged over 10 experiments where each of the 10 classes is targeted for unlearning.  \n* **UA (Unlearning Accuracy):** Measures how well the model forgets the target class. A higher value indicates better unlearning. \n* **RA (Remaining Accuracy):** Measures the model's performance on the remaining 9 classes after unlearning. A higher value suggests the unlearning process didn't significantly harm the model's ability to generate other classes. \n* **FID (Fr\u00e9chet Inception Distance):** Measures the quality of the generated images. A lower value indicates better image quality.", "section": "4.1 Experiment Setup"}, {"figure_path": "93ktalFvnJ/tables/tables_18_1.jpg", "caption": "Table 7: Comparison of nudity removal effectiveness and alignment scores across different methods on Stable Diffusion Model", "description": "This table presents a quantitative comparison of various methods for nudity removal from Stable Diffusion models.  It shows the number of detected body parts (female genitalia, buttocks, male breast, belly, male genitalia, armpits, female breast) in images generated after unlearning.  The lower the count of body parts, the more effective the unlearning. The table also presents the CLIP alignment scores (AS) for both training (Dr,train) and test (Dr,test) prompts, which indicate the semantic consistency between generated images and given prompts.  Higher AS scores indicate better alignment.  The results demonstrate the effectiveness of the proposed RGD method in removing nudity while maintaining high alignment scores.", "section": "4.3 Target Concept Removal from Diffusion Models"}, {"figure_path": "93ktalFvnJ/tables/tables_18_2.jpg", "caption": "Table 7: Comparison of nudity removal effectiveness and alignment scores across different methods on Stable Diffusion Model", "description": "This table presents a quantitative comparison of different methods for nudity removal in Stable Diffusion models.  It shows the effectiveness of each method in terms of the number of detected body parts (female genitalia, male genitalia, buttocks, belly, female breast, male breast, armpits) remaining after the unlearning process.  In addition to the raw counts, it also provides CLIP alignment scores (AS) for both training prompts (Dr,train) and a held-out test set (Dr,test). Higher alignment scores indicate better semantic alignment between the generated images and their prompts after the unlearning process.", "section": "E.2 Impact of Different Sizes in Df and Dr"}]