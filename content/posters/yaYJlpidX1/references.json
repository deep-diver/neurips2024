{"references": [{"fullname_first_author": "Michael McCloskey", "paper_title": "Catastrophic interference in connectionist networks: The sequential learning problem", "publication_date": "1989-01-01", "reason": "This paper is foundational to the field of continual learning, introducing the concept of catastrophic forgetting and its challenges for neural networks."}, {"fullname_first_author": "James L McClelland", "paper_title": "Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory", "publication_date": "1995-01-01", "reason": "This paper provides a theoretical framework for understanding catastrophic forgetting by proposing the existence of complementary learning systems in the brain, which helps explain the limitations of traditional neural network training."}, {"fullname_first_author": "James Kirkpatrick", "paper_title": "Overcoming catastrophic forgetting in neural networks", "publication_date": "2017-01-01", "reason": "This paper introduces Elastic Weight Consolidation (EWC), a widely used technique for mitigating catastrophic forgetting, which significantly advanced the practical application of continual learning."}, {"fullname_first_author": "J\u00fcrgen Schmidhuber", "paper_title": "Steps towards \"self-referential\" learning", "publication_date": "1992-11-01", "reason": "This early work laid conceptual groundwork for self-referential learning, where the learning process itself adapts and improves over time, a core concept in meta-learning and continual learning."}, {"fullname_first_author": "Sepp Hochreiter", "paper_title": "Learning to learn using gradient descent", "publication_date": "2001-08-01", "reason": "This paper presents the early concept of meta-learning, which is crucial in continual learning to learn the optimal learning strategies for different tasks in a continuously changing environment."}]}