{"references": [{"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-10-01", "reason": "This paper introduces DINO, a self-supervised vision transformer that is used as the backbone for the LoCo model, significantly influencing the design and performance."}, {"fullname_first_author": "Dominik Kloepfer", "paper_title": "LoCUS: Learning multiscale 3D-consistent features from posed images", "publication_date": "2023-10-01", "reason": "This paper proposes LoCUS, a prior method that addresses the same problem of learning location-consistent features, and forms a key comparison point to the work in this paper."}, {"fullname_first_author": "Andrew Brown", "paper_title": "Smooth-AP: Smoothing the path towards large-scale image retrieval", "publication_date": "2020-08-01", "reason": "This paper introduces the smooth average precision (sAP) loss function, which is the foundation for the memory-efficient ranking loss proposed in this paper."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-06-01", "reason": "This paper introduces MAE, a self-supervised method that is discussed as related work and offers insights into scalable vision learning techniques, which is relevant to the memory efficiency improvements of LoCo."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "publication_date": "2024-01-01", "reason": "This paper introduces DINOv2, an improved version of DINO, which is used as an alternative backbone to demonstrate the effectiveness of LoCo's loss function and training strategy."}]}