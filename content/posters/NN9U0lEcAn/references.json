{"references": [{"fullname_first_author": "Y. Abu Farha", "paper_title": "Uncertainty-aware anticipation of activities", "publication_date": "2019-00-00", "reason": "This paper is foundational for the work on action anticipation, providing a basis for understanding and predicting future actions."}, {"fullname_first_author": "Y. Abu Farha", "paper_title": "When will you do what?-anticipating temporal occurrences of activities", "publication_date": "2018-00-00", "reason": "This paper introduces the concept of anticipating temporal occurrences of activities, a key concept in the field of action anticipation."}, {"fullname_first_author": "H. Ahn", "paper_title": "Refining action segmentation with hierarchical video representations", "publication_date": "2021-00-00", "reason": "This paper presents a method for refining action segmentation using hierarchical video representations, which is directly relevant to the topic of action segmentation."}, {"fullname_first_author": "Y. A. Farha", "paper_title": "MS-TCN: Multi-stage temporal convolutional network for action segmentation", "publication_date": "2019-00-00", "reason": "This paper introduces the MS-TCN model, a state-of-the-art model for action segmentation that is compared against in the current work."}, {"fullname_first_author": "A. Fathi", "paper_title": "Learning to recognize objects in egocentric activities", "publication_date": "2011-00-00", "reason": "This paper introduces the GTEA dataset, a benchmark dataset for action segmentation and anticipation that is used in the current work."}]}