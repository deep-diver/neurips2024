{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a foundational model for the work, demonstrating the power of aligning language and vision models."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-20", "reason": "This paper introduces Stable Diffusion, the core generative model used for creating synthetic images in the study."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "LAION-5B: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-12-01", "reason": "This paper introduces LAION-2B, the large-scale dataset that underpins both the generative model and the real image retrieval in the study."}, {"fullname_first_author": "Yonglong Tian", "paper_title": "Learning vision from models rivals learning vision from data", "publication_date": "2023-12-01", "reason": "This paper is highly relevant as it explores a similar research question regarding the effectiveness of synthetic data in computer vision."}, {"fullname_first_author": "Pang Wei Koh", "paper_title": "Wilds: A benchmark of in-the-wild distribution shifts", "publication_date": "2021-07-18", "reason": "This paper introduces WILDS, a benchmark dataset relevant to the study's focus on evaluating model performance across different data distributions."}]}