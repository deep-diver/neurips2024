{"references": [{"fullname_first_author": "Yongqiang Chen", "paper_title": "Understanding and improving graph injection attack by promoting unnoticeability", "publication_date": "2022-04-25", "reason": "This paper is highly relevant as it pioneers research on improving graph injection attacks by focusing on the unnoticeability of the attacks, a concept directly related to the interpretability issues explored in the target paper."}, {"fullname_first_author": "Jihong Wang", "paper_title": "Scalable attack on graph data by injecting vicious nodes", "publication_date": "2020-01-01", "reason": "This paper is foundational to the current work as it introduces graph injection attacks, a central theme of the target paper, and establishes the basic framework for evaluating such attacks."}, {"fullname_first_author": "Qinkai Zheng", "paper_title": "Graph robustness benchmark: Benchmarking the adversarial robustness of graph machine learning", "publication_date": "2021-12-01", "reason": "This paper provides the datasets and evaluation protocols used to evaluate the robustness of Graph Neural Networks (GNNs) against adversarial attacks, which forms the basis of experimental evaluations in the target paper."}, {"fullname_first_author": "Thomas N. Kipf", "paper_title": "Semi-supervised classification with graph convolutional networks", "publication_date": "2017-04-24", "reason": "This paper introduces Graph Convolutional Networks (GCNs), a crucial architecture in graph neural networks, upon which many of the attacks and defenses discussed in the target paper are based."}, {"fullname_first_author": "William L. Hamilton", "paper_title": "Inductive representation learning on large graphs", "publication_date": "2017-12-04", "reason": "This paper introduces inductive representation learning on large graphs, a technique highly relevant to the study of text-attributed graphs and the development of effective graph injection attacks as discussed in the target paper"}]}