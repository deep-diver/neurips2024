[{"figure_path": "Fr9d1UMc37/figures/figures_1_1.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three stages of the proposed LLM dataset inference method.  Stage 0 shows the initial setup where a victim claims an LLM was trained on their data. Stage 1 involves using various membership inference attacks (MIAs) to extract features from both suspect and validation datasets.  Stage 2 trains a linear model to learn correlations between features and membership status. Finally, Stage 3 uses a t-test to infer dataset membership based on aggregated confidence scores.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_5_1.jpg", "caption": "Figure 2: Comparative analysis of the MIN-K% PROB [Shi et al., 2024]. We measure the performance (a) across different model sizes and (b) the observed reversal effect. The method performs close to a random guess on non-members from the Pile validation sets.", "description": "This figure shows the results of a comparative analysis of the MIN-K% PROB membership inference attack proposed by Shi et al. (2024).  Subfigure (a) illustrates the performance of the method across various model sizes, demonstrating that its effectiveness diminishes as model parameters increase. Subfigure (b) highlights a counterintuitive \"reversal effect,\" where the method shows high performance in identifying non-members when the training and validation sets are reversed, contradicting the claim of successful membership inference. This suggests that the method's performance is influenced by distribution shift rather than true membership.", "section": "4 Failure of Membership Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_5_2.jpg", "caption": "Figure 2: Comparative analysis of the MIN-K% PROB [Shi et al., 2024]. We measure the performance (a) across different model sizes and (b) the observed reversal effect. The method performs close to a random guess on non-members from the Pile validation sets.", "description": "This figure shows a comparative analysis of the MIN-K% PROB membership inference attack proposed by Shi et al. (2024).  Subfigure (a) displays the performance of the method across various model sizes, indicating that its accuracy is close to random guessing when tested on non-member sentences from the Pile dataset's validation sets. Subfigure (b) illustrates a reversal effect, showing high accuracy when the training and validation sets are swapped, suggesting that the method is sensitive to data distribution shifts rather than true membership.", "section": "4 Failure of Membership Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_5_3.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three stages of the proposed LLM dataset inference method.  The victim provides a suspect dataset (potentially used in training) and a private validation dataset to the arbiter.  Feature aggregation using multiple membership inference attacks (MIAs) is performed on both datasets, followed by training a linear model to learn correlations between features and membership. Finally, a statistical test (t-test) is applied to infer whether the suspect dataset was used in training based on aggregated confidence scores.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_7_1.jpg", "caption": "Figure 4: p-values of dataset inference By applying dataset inference to Pythia-12b models with 1000 data points, we observe that we can correctly distinguish train and validation splits of the PILE with very low p-values (always below 0.1). Also, when considering false positives for comparing two validation subsets, we observe a p-value higher than 0.1 in all cases, indicating no false positives.", "description": "This figure shows the results of dataset inference experiments conducted on Pythia-12b models using 1000 data points. The experiment aims to distinguish between training and validation splits of the Pile dataset.  The results demonstrate the effectiveness of the proposed dataset inference method, achieving statistically significant p-values below 0.1 in all cases for distinguishing between training and validation sets. Importantly, no false positives were observed when comparing two validation subsets.", "section": "5. Analysis and Results with Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_8_1.jpg", "caption": "Figure 3: Performance of various MIAs on different subsets of the Pile dataset. We report 6 different MIAs based on the best performing ones across various categories like reference based, and perturbation based methods (Section 2.1). An effective MIA must have an AUC much greater than 0.5. Few methods meet this criterion for specific datasets, but the success is not consistent across datasets.", "description": "The figure shows the performance of six different membership inference attack (MIA) methods across twenty different subsets of the Pile dataset.  The results highlight the inconsistency of MIA performance across different datasets, demonstrating that no single MIA consistently achieves high Area Under the Curve (AUC) values across various data distributions.  This finding underscores the challenges of reliably detecting membership based on individual text sequences within LLMs trained on massive datasets.", "section": "2.1 Metrics for LLM Membership Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_8_2.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three stages of the proposed LLM dataset inference method.  Stage 0 sets up the scenario with a victim (data owner) and an LLM provider (suspect). Stage 1 aggregates features from various membership inference attacks (MIAs). Stage 2 trains a linear model to learn correlations between features and membership. Finally, Stage 3 performs a statistical test (t-test) to infer if the suspect dataset was used in the LLM's training.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_8_3.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three stages of the proposed LLM dataset inference method. Stage 0 shows the victim approaching the LLM provider with suspect and validation datasets. Stage 1 involves using membership inference attacks (MIAs) to extract features from both datasets. Stage 2 focuses on training a linear model to identify useful MIAs for distinguishing members and non-members. Finally, Stage 3 utilizes the trained model to perform a statistical test on the remaining data to determine whether the suspect dataset was used in training the LLM.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_9_1.jpg", "caption": "Figure 6: Ablation studies for the amount of data and model size. In (a), we plot the maximum and median p-values across all datasets, alongside the p-value of Wikipedia, as a function of the number of data points. In (b), a violin plot is made to show the distribution of p-values of the datasets with respect to the number of model parameters. Observe that dataset inference is more successful with more data and larger LLMs. It is also noteworthy that (a) dataset inference for a majority of datasets is accurate with less than 100 points, and (b) it is more accurate with respect to the non-deduplicated models that are trained on datasets with duplicated points. We hypothesize this is because the membership signal for most MIAs becomes stronger with the duplication of data.", "description": "This figure shows the results of ablation studies on the effect of the number of data points and model size on the success of dataset inference.  The left panel (a) plots the maximum and median p-values across all datasets against the number of data points, showing that dataset inference becomes more accurate with more data. The right panel (b) uses violin plots to show the distribution of p-values for different model sizes, demonstrating improved accuracy with larger models.  The authors also note that dataset inference is more successful with non-deduplicated datasets (datasets containing duplicate data points).", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_9_2.jpg", "caption": "Figure 6: Ablation studies for the amount of data and model size. In (a), we plot the maximum and median p-values across all datasets, alongside the p-value of Wikipedia, as a function of the number of data points. In (b), a violin plot is made to show the distribution of p-values of the datasets with respect to the number of model parameters. Observe that dataset inference is more successful with more data and larger LLMs. It is also noteworthy that (a) dataset inference for a majority of datasets is accurate with less than 100 points, and (b) it is more accurate with respect to the non-deduplicated models that are trained on datasets with duplicated points. We hypothesize this is because the membership signal for most MIAs becomes stronger with the duplication of data.", "description": "This figure shows the results of ablation studies on the number of data points and model size used in dataset inference.  The top row shows that the success of dataset inference increases with more data points and larger model sizes. The bottom row uses violin plots to illustrate this further, demonstrating that dataset inference is more successful with non-deduplicated datasets and larger models.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_14_1.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three-stage process of LLM dataset inference.  A victim suspects an LLM was trained on their data (suspect set). They provide this data, along with a private validation set (from the same distribution). Both sets are split into partitions A and B.  Stage 1 aggregates features from various membership inference attacks (MIAs) on partition A. Stage 2 trains a linear model to correlate features with membership, identifying useful MIAs. Stage 3 uses partition B to perform dataset inference via the selected MIAs, aggregated scores, and a statistical t-test to determine if the suspect dataset was part of the LLM training data.", "section": "Operationalizing Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_15_1.jpg", "caption": "Figure 3: Performance of various MIAs on different subsets of the Pile dataset. We report 6 different MIAs based on the best performing ones across various categories like reference based, and perturbation based methods (Section 2.1). An effective MIA must have an AUC much greater than 0.5. Few methods meet this criterion for specific datasets, but the success is not consistent across datasets.", "description": "This figure presents a heatmap illustrating the performance of six different membership inference attack (MIA) methods across 20 distinct subsets of the Pile dataset.  The goal is to determine if any MIA consistently performs well across various data distributions.  The results show that no single MIA achieves high Area Under the Curve (AUC) values across all datasets, highlighting the need for a more robust method.", "section": "2.1 Metrics for LLM Membership Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_15_2.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three-stage process of LLM dataset inference.  A victim, possessing a suspect dataset and a private validation dataset (both from the same distribution), claims the LLM was trained using their suspect data.  The process involves aggregating features from various membership inference attacks (MIAs), training a linear model to correlate features with membership, and finally using a statistical t-test to determine if the suspect data was used in training.  The figure visually depicts the flow of data and the steps involved in each stage.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_16_1.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three stages of the LLM Dataset Inference method.  Stage 0 sets up the scenario where a user suspects an LLM was trained on their data. Stages 1 and 2 use a subset of the user's data to train a model to identify useful Membership Inference Attacks (MIAs). In Stage 3, the trained model and remaining data are used to perform a statistical test to determine if the LLM was trained on the suspect data.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_17_1.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three stages of the LLM dataset inference method.  The process starts with a victim approaching an LLM provider with a claim about their data being used in training.  It then involves aggregating features from various membership inference attacks (MIAs), followed by training a model to learn correlations between these features and membership status. Finally, a statistical test is performed using the trained model to determine whether the suspect data was indeed used for training.", "section": "5 LLM Dataset Inference"}, {"figure_path": "Fr9d1UMc37/figures/figures_17_2.jpg", "caption": "Figure 1: LLM Dataset Inference. Stage 0: Victim approaches an LLM provider. The victim's data consists of the suspect and validation (Val) sets. A victim claims that the suspect set of data points was potentially used to train the LLM. The validation set is private to the victim, such as unpublished data (e.g., drafts of articles, blog posts, or books) from the same distribution as the suspect set. Both sets are divided into non-overlapping splits (partitions) A and B. Stage 1: Aggregate Features with MIAs. The A splits from suspect and validation sets are passed through the LLM to obtain their features, which are scores generated from various MIAs for LLMs. Stage 2: Learn Correlations (between features and their membership status). We train a linear model using the extracted features to assign label 0 (denoting potential members of the LLM) to the suspect and label 1 (representing non-members) to the validation features. The goal is to identify useful MIAs. Stage 3: Perform Dataset Inference. We use the B splits of the suspect and validation sets, (i) perform MIAs on them for the suspect LLM to obtain features, (ii) then obtain an aggregated confidence score using the previously trained linear model, and (iii) apply a statistical T-Test on the obtained scores. For the suspect data points that are members, their confidence scores are significantly closer to 0 than for the non-members.", "description": "This figure illustrates the three-stage process of LLM dataset inference.  Stage 0 sets up the scenario where a victim claims an LLM was trained on their data. Stage 1 aggregates features from various Membership Inference Attacks (MIAs). Stage 2 trains a linear model to correlate features with membership.  Stage 3 uses a t-test to determine if a dataset was used in training based on aggregated confidence scores.", "section": "5 LLM Dataset Inference"}]