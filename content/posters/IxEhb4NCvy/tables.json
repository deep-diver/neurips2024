[{"figure_path": "IxEhb4NCvy/tables/tables_7_1.jpg", "caption": "Table 1: Scalable Dysfluent Phonetic Transcription Evaluation", "description": "This table presents the results of evaluating the phonetic transcription performance of different methods on the VCTK++, LibriTTS, and Libri-Dys datasets.  It compares the performance of HuBERT, H-UDM, and the proposed Gestural Score (GS) method, with and without self-distillation, across various training data sizes.  The evaluation metrics used are framewise F1 score (higher is better) and Duration-Aware Phoneme Error Rate (dPER, lower is better).  The table also provides scalability factors (SF1 and SF2) showing the relative performance gains as the dataset size increases.", "section": "6.3 Scalable Intelligibility Evaluation"}, {"figure_path": "IxEhb4NCvy/tables/tables_7_2.jpg", "caption": "Table 2: Scalable Dysfluent Detection Evaluation (Simulation)", "description": "This table presents the results of a simulation evaluating the performance of the proposed SSDM model and its variants in detecting dysfluencies.  It shows F1 scores (type match) and Matching Scores (MS) for various configurations of the model across different datasets (VCTK++, LibriTTS, Libri-Dys with varying amounts of training data), highlighting the impact of different model components like the language model (LLaMA), the connectionist subsequence aligner (CSA), and gestural scores.  Scalability factors (SF1 and SF2) are also provided, indicating how well the model scales with increasing amounts of data.", "section": "6.3 Scalable Intelligibility Evaluation"}, {"figure_path": "IxEhb4NCvy/tables/tables_8_1.jpg", "caption": "Table 3: Detection results from state-of-the-art models.", "description": "This table presents a comparison of the dysfluency detection performance of SSDM against several state-of-the-art models, including LTU-AS-13B, SALMONN-13B, and ChatGPT.  The evaluation is performed on three datasets: VCTK++, Libri-Dys, and nfvPPA.  The metrics used are F1 score (representing the accuracy of the dysfluency type prediction) and MS (matching score, incorporating temporal accuracy). The results demonstrate that SSDM achieves significantly higher F1 and MS scores across all datasets compared to the other models, highlighting its superior performance in dysfluency detection.", "section": "6.5 State-of-the-art Dysfluency Detection"}, {"figure_path": "IxEhb4NCvy/tables/tables_28_1.jpg", "caption": "Table 4: Types of Dysfluency Data in VCTK++ and Libri-Dys", "description": "This table compares the distribution of different types of dysfluencies in two datasets: VCTK++ and Libri-Dys.  It shows the number of samples and the percentage of each dysfluency type (Prolongation, Block, Replacement, Repetition (Phoneme), Repetition (Word), Missing (Phoneme), Missing (Word)) present in both datasets. The total hours of audio for each dataset are also provided.  The table highlights the significant increase in the size and diversity of dysfluencies in the Libri-Dys dataset compared to VCTK++.", "section": "A.9.3 Datasets Statistics"}, {"figure_path": "IxEhb4NCvy/tables/tables_28_2.jpg", "caption": "Table 5: MOS for VCTK++ [1] & Libri-Dys Samples", "description": "This table presents the Mean Opinion Score (MOS) ratings for the quality and naturalness of dysfluent speech samples generated using two different datasets: VCTK++ and Libri-Dys.  MOS ratings are given on a scale of 1-5, with 5 being the highest score.  The table compares the overall MOS scores and provides a breakdown by dysfluency type (Block, Missing (phoneme and word), Prolong, Repetition (phoneme and word), and Replacement).  The results show that the Libri-Dys dataset produces samples that are rated significantly higher in quality and naturalness compared to those from the VCTK++ dataset.  Note that some dysfluency types are not present in the VCTK++ dataset, resulting in \"N/A\" entries for those categories.", "section": "6.3 Scalable Intelligibility Evaluation"}, {"figure_path": "IxEhb4NCvy/tables/tables_29_1.jpg", "caption": "Table 6: Phoneme Transcription Evaluation on LibriTTS and Libri-Dys", "description": "This table compares the phoneme error rate (PER) for LibriTTS and Libri-Dys datasets.  LibriTTS represents clean speech, while Libri-Dys contains various types of simulated dysfluencies. The PER is broken down for different types of dysfluencies in Libri-Dys, showing the impact of each dysfluency type on speech recognition accuracy.", "section": "6.3 Scalable Intelligibility Evaluation"}, {"figure_path": "IxEhb4NCvy/tables/tables_30_1.jpg", "caption": "Table 7: Detailed GLOW model architecture", "description": "This table details the architecture of the Glow model used in the paper.  It breaks down the invertible flow into its constituent components: Actnorm Layer, Invertible 1x1 Convolution, and Affine Coupling Layer. For each component, the specific parameters and configurations (such as input/output sizes, number of layers, activation functions) are listed.", "section": "A.11.4 CSA"}]