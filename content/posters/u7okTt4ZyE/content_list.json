[{"type": "text", "text": "Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Qinpeng $\\mathbf{Cui^{*12}}$ , Yixuan Liu1, Xinyi Zhang2, Qiqi Bao2, Qingmin Liao2 Li Wang1, Tian $\\mathbf{L}\\mathbf{u}^{1}$ , Zicheng $\\mathrm{\\mathbf{liu}^{1}}$ , Zhongdao Wang\u2020 2, Emad Barsoum1 1Advanced Micro Devices Inc. 2Tsinghua University ", "page_idx": 0}, {"type": "text", "text": "{qinpeng.cui, yixuan.liu, li.wang, lu.tian, zicheng.liu, ebarsoum}@amd.com; {cqp22, xinyi-zh22, bqq19, liaoqm, wcd17}@tsinghua.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Diffusion-based image super-resolution (SR) models have attracted substantial interest due to their powerful image restoration capabilities. However, prevailing diffusion models often struggle to strike an optimal balance between efficiency and performance. Typically, they either neglect to exploit the potential of existing extensive pretrained models, limiting their generative capacity, or they necessitate a dozens of forward passes starting from random noises, compromising inference efficiency. In this paper, we present DoSSR, a Domain Shift diffusion-based SR model that capitalizes on the generative powers of pretrained diffusion models while significantly enhancing efficiency by initiating the diffusion process with low-resolution (LR) images. At the core of our approach is a domain shift equation that integrates seamlessly with existing diffusion models. This integration not only improves the use of diffusion prior but also boosts inference efficiency. Moreover, we advance our method by transitioning the discrete shift process to a continuous formulation, termed as DoS-SDEs. This advancement leads to the fast and customized solvers that further enhance sampling efficiency. Empirical results demonstrate that our proposed method achieves state-of-the-art performance on synthetic and real-world datasets, while notably requiring only 5 sampling steps. Compared to previous diffusion prior based methods, our approach achieves a remarkable speedup of 5-7 times, demonstrating its superior efficiency. Code: https://github.com/QinpengCui/DoSSR ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Image super-resolution (SR) is a classical task in computer vision that involves enhancing a lowresolution (LR) image to create a perceptually convincing high-resolution (HR) image [28]. Traditionally, this field has operated under the assumption of simple image degradations, such as bicubic down-sampling, which has led to the development of numerous effective SR models [6, 25, 57, 12]. However, these models often fall short when confronted with real-world degradations, which are typically more complex than those assumed in academic settings. Recently, diffusion models has emerged as a pivotal research direction in real-world SR, using their robust generative capabilities to enhance perceptual quality. This shift highlights their superior performance in practical applications. ", "page_idx": 0}, {"type": "text", "text": "Currently, diffusion-based SR strategies can be broadly categorized into two approaches. The first approach leverages large-scale pretrained diffusion models (e.g., Stable Diffusion [41]) as generative prior, using LR images (or preprocessed LR images) as conditional inputs to generate HR images [45, 27, 51]. Despite achieving remarkable results, it exhibits low inference efficiency, as the inference starting point is a random Gaussian noise instead of the LR image. Although techniques such as sampler optimization [33, 38, 30, 9, 22] or model distillation [32, 37] have been proposed to mitigate this issue, they inevitably compromise SR performance. The second approach involves redefining the diffusion process and retraining a model from scratch for the SR task [53, 36]. Consequently, the generative prior from pretrained diffusion models is not leveraged. ResShift [53], as a typical representative, revises the forward process of DDPM [16] to better accommodate the SR task. By starting from LR rather than Gaussian noise, it improves inference efficiency. However, its modification of the diffusion pattern, which deviates significantly from existing noise schedules in diffusion models, hinders its integration with large-scale pretrained diffusion models for leveraging their generative prior. The diffusion generative prior has been proven to be highly beneficial for SR tasks [45], enabling models to transcend the limitations of knowledge learned solely from the training dataset, thereby equipping them to handle various complex real-world scenarios. Thus, crafting a diffusion process tailored for the SR task that also remains compatible with established diffusion prior presents a significant challenge. ", "page_idx": 0}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/0336a6d491822e181fd7a3dd9f09d0c9c0983f057ad9c1f83367215456c72777.jpg", "img_caption": ["Figure 1: (a) Latency, MANIQA, and complexity of model comparison on RealLR200 [51] dataset in x4 SR task (for $128\\!\\times\\!128$ LR images). (b) Qualitative comparisons of DoSSR and recent state-ofthe-art methods on one typical real-world example. For diffusion-based methods, the suffix \"-N\" appended to the method name indicates the number of inference steps. Zoom in for a better view. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "To tackle this challenge, we propose DoSSR, a Domain Shift diffusion-based SR model. We initially view the SR task as a gradual shift from the LR domain to the HR domain, describing this transition with a linear equation, which is called domain shift equation. Then, we combine this domain shift equation with existing diffusion equations, facilitating the fine-tuning of large-scale pretrained diffusion models to harness diffusion prior effectively. Moreover, by carefully designing a shifting sequence, inference can begin from LR images rather than Gaussian noises, thereby boosting inference efficiency. To further enhance efficiency, we employ sampler optimization techniques, extensively explored in image generation [38, 30, 9], but not previously tailored for diffusion-based SR tasks. Specifically, we expand the customized diffusion equation from discrete to continuous, enabling its formulation as stochastic differential equations (SDEs). We subsequently present the corresponding backward-time SDE as Domain Shift SDE in the reverse process and provide an exact formulation of its solution. Based on our formulation, we customize fast solvers for sampling. Experimental results demonstrate that our method achieves superior or comparable performance compared to current state-of-the-art methods on both synthetic and real-world datasets, with only 5 sampling steps, striking an optimal balance between efficiency and effectiveness. Furthermore, our approach can match the performance of previous methods even with just a single step. ", "page_idx": 1}, {"type": "text", "text": "In summary, the main contributions of our work are as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a novel diffusion equation, which models SR from the perspective of domain shift, enabling inference to start from LR images and leveraging diffusion prior to ensure both efficiency and performance.   \n\u2022 We further propose the SDEs to describe the process of domain shift and provide an exact solution for the corresponding reverse-time SDEs. Based on the solution, we design customized fast samplers, resulting in even higher efficiency, thereby achieving the state-of-the-art efficiencyperformance trade-off. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Neural Network-based Super-Resolution. Neural network-based methods have emerged as the dominant approach in image SR tasks. The introduction of convolutional neural networks (CNNs) and Transformer architecture, with the primary focus on network architecture design [12, 10, 25, 26, 58, 21, 56, 57], have demonstrated superior performance over traditional methods. This improvement is facilitated by the introduction of residual blocks, dense blocks and attention mechanisms. These methods primarily aim for better image fidelity measures such as PSNR and SSIM [49] indices, therefore, they often yield over-smoothed outcomes. To enhance visual perception, Generative adversarial network (GAN)-based SR methods have been developed. By incorporating adversarial loss during training, many SR models [13, 23, 17] can generate perceptually realistic details, thereby enhancing visual quality. To further study SR problems in real-world scenarios, some studies [54, 46, 24] have proposed simulating the intricate real-world image degradation process through random combinations of fundamental degradation operations. Despite the remarkable advancements, GANbased SR methods can introduce undesirable visual artifacts. ", "page_idx": 2}, {"type": "text", "text": "Diffusion-based Super-Resolution. Recently, diffusion-based SR methods [35, 36, 8, 7, 45, 27] have demonstrated excellent performance, especially in terms of perceptual quality. These methods can generate more authentic details while avoiding unpleasant visual artifacts like GAN-based methods. Current diffusion models for super-resolution can be broadly categorized into two main approaches. The first approach involves leveraging large-scale pretrained diffusion models, such as Stable Diffusion [41], as prior, and then using LR images as conditional inputs to generate HR images. StableSR [45] and DiffBIR [27] represent representative works that leverage diffusion prior, leading to enhanced fidelity when conditioning on LR or preprocessed LR. SeeSR [51] and CoSeR [42] demonstrate that extracting semantic text information from LR images as additional control conditions for the T2I model helps improve performance. The second approach involves redefining the diffusion process and retraining a model from scratch for SR [18, 36]. To address the slow inference speed issue of diffusion-based SR methods, ResShift [53] constructs a Markov chain that transitions between HR and LR images by shifting residuals between them, enabling accelerated sampling. SinSR [48] proposed a method of distilling ResShift to achieve comparable performance in a single step. Despite the remarkable advancements achieved by ResShift and SinSR, they necessitate retraining from scratch for SR tasks (or further distillation) and are unable to leverage diffusion prior. Therefore, improving the inference efficiency while leveraging the potential of large-scale pretrained diffusion models to assist SR requires thorough investigation, which is the goal of this work. ", "page_idx": 2}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We aim to optimize the balance between efficiency and performance in diffusion-based superresolution (SR) models. Our approach is grounded in two key principles: First, initiating inference from LR images rather than noise; Second, effectively harnessing pretrained diffusion prior. In Section 3.1, we introduce a novel diffusion equation designed to fulfill both criteria simultaneously. Subsequently, in Section 3.2, we extend this diffusion process to continuous scenarios, formulating it through Stochastic Differential Equations (SDEs). Building on these SDEs, we develop an efficient solver detailed in Section 3.3, further enhancing inference efficiency. ", "page_idx": 2}, {"type": "text", "text": "3.1 Diffusion Process with Domain Shift ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our goal is to characterize the shift from the source domain to the target domain as a diffusion process. In the task of SR, the distribution of LR images $p_{\\mathtt{d a t a}}(\\hat{\\pmb{x}}_{0})$ represents the source domain, while the distribution of HR images $p_{\\mathtt{d a t a}}(x_{0})$ represents the target domain. Firstly, we conceptualize domain shift as a gradual transition from the source domain to the target domain through a linear drift coefficient $\\eta_{t}$ , the domain shift equation is formulated as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{D}(\\hat{{\\pmb x}}_{0},{\\pmb x}_{0})=\\eta_{t}\\hat{{\\pmb x}}_{0}+(1-\\eta_{t}){\\pmb x}_{0},\\;0\\leq\\eta_{t}\\leq1,\\;t=1,2,\\cdot\\cdot\\cdot\\;,T,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where shifting sequence $\\{\\eta_{t}\\}_{t=1}^{T}$ monotonically non-decreases with timestep $t$ . In order to enable linear combination, we can interpolate $\\hat{\\pmb{x}}_{0}$ to match the same dimensions as $\\scriptstyle x_{0}$ if necessary. Secondly, we combine this domain shift with the diffusion equation. To integrate with pretrained diffusion models, we adopt the most commonly used diffusion scheme from DDPM [16] and express the formula of marginal distribution at any timestep $t$ as follows: ", "page_idx": 2}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/c68781bd102bb0eb84dcf4ab2874b549e9d229c3d2bf4dc36b7c52750cd0b1a1.jpg", "img_caption": ["Figure 2: Illustration of the proposed diffusion process with domain shift. (a) In the forward process, we merge the gradual shift from HR to LR domain with standard diffusion process. (b) In the reverse process, we initiate inference from LR domain $(t=t_{1}$ ) and use our fast sampler to generate SR images. (c) Comparison of the estimated score between SD and DoSSR. DoSSR inherits the capability of SD in ambient space and enhances learning a pathway from LR to HR domain. (d) The design of the shifting sequence which enables us to initiate inference from $t_{1}$ . "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{q(\\pmb{x}_{t}|\\pmb{x}_{0},\\hat{\\pmb{x}}_{0})=\\mathcal{N}(\\pmb{x}_{t};\\alpha_{t}\\mathcal{D}(\\hat{\\pmb{x}}_{0},\\pmb{x}_{0}),\\sigma_{t}^{2}\\pmb{I}),\\;t=1,2,\\cdots\\,,T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\alpha_{t},\\sigma_{t}\\,\\geq\\,0$ and $\\alpha_{t}^{2}+\\sigma_{t}^{2}\\,=\\,1$ , $\\boldsymbol{\\mathit{I}}$ is the identity matrix. Based on our proposed marginal distribution Eq. (2), we demonstrate the transition distribution as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nq(\\pmb{x}_{t}|\\pmb{x}_{t-1},\\hat{\\pmb{x}}_{0})=N(\\pmb{x}_{t};\\frac{\\alpha_{t}}{\\alpha_{t-1}}\\pmb{x}_{t-1}+\\alpha_{t}(\\eta_{t}-\\eta_{t-1})\\pmb{e}_{0},1-\\frac{\\alpha_{t}^{2}}{\\alpha_{t-1}^{2}}\\pmb{I}),\\;t=1,2,\\cdots,T,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where ${\\pmb e_{0}}=\\hat{\\pmb x}_{0}-{\\pmb x}_{0}$ is the residual between the source and target domain. ", "page_idx": 3}, {"type": "text", "text": "Relation to DDPM [16]. The formulation of Eq. (2) is based on the DDPM [16] forward process, with a crucial difference lying in its mean $\\alpha_{t}\\mathscr{D}(\\hat{\\pmb{x}}_{0},\\pmb{x}_{0})$ instead of $\\alpha_{t}\\mathbf{z}_{0}$ . This integration encapsulates the domain shift within the variation of its mean, while the diffusion process with added noise maintains consistency with it, thereby smoothing this transformation. Meanwhile, it enhances the diffusion model to learn the pathway from the source domain to the target domain. For an intuitive understanding, we plot and compare the score function $\\nabla_{x}\\log q_{t}(\\mathbf{x}_{t})$ learned by a vanilla Stable Diffusion (SD) model and DoSSR in Fig. 2(c). While SD learns reasonable score field in the whole space, DoSSR inherits its capability in the ambient space and further learns more accurate scores along the path between LR and HR domains. Therefore sampling efficiency is improved. Furthermore, the choice of $\\alpha_{t}$ and $\\sigma_{t}$ , referred to as the noise schedule, follows the existing pretrained diffusion model, allowing us to fine-tune it rather than training it from scratch. ", "page_idx": 3}, {"type": "text", "text": "Relation to ResShift [53]. The form of equation Eq. (3) suggests that this shift essentially constructs a Markov chain in a manner similar to that described in ResShift [53]. However, the equation constructed by ResShift adopts an entirely different noise schedule compared to the pretrained diffusion model. This makes it difficult to apply pretrained diffusion models for subsequent finetuning, necessitating training from scratch instead. Therefore, it is unable to utilize the diffusion prior, thereby limiting the model\u2019s performance. See Appendix A.7 for detailed theoretical differences from ResShift. In Appendix C.1, we present experimental results on ImageNet [11] showing that DoSSR uses two orders of magnitude less training data than ResShift while achieving superior performance. ", "page_idx": 3}, {"type": "text", "text": "Shifting Sequence. The parameter $\\eta_{t}$ plays a crucial role in guiding the diffusion process, serving as a bridge between the source and target domains. Specifically, $\\eta_{t}=1$ represents standard diffusion forward perturbations in the source domain, whereas $\\eta_{t}=0$ corresponds to the target domain. The transition between these domains occurs for $0<\\eta_{t}<1$ , indicating a domain shift. To effectively utilize the diffusion prior, we adopt the noise schedule from DDPM. This adoption dictates that as $t$ approaches the final time step $T$ , the scale parameter $\\alpha_{T}$ tends towards zero, and the distribution $q(x_{T})$ approximates a standard Gaussian, $\\bar{\\mathcal{N}}(\\mathbf{0},\\boldsymbol{I})$ . To retain prior information from the source domain while shortening the diffusion path, we set $\\eta_{t}=1$ for $t\\in[t_{1},T]$ , as defined by: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\eta_{t}=\\frac{1-\\cos(\\pi\\frac{t}{t_{1}})}{2}\\;\\mathrm{if}\\;\\;t\\in[0,t_{1}],\\quad\\eta_{t}=1\\mathrm{~if~}\\,t\\in[t_{1},T].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The advantage of such a setting lies in the fact that during the reverse process, the values of $\\pmb{x}_{t}$ for $t\\in[t_{1},T]$ are known and can be obtained through the forward process Eq. (2). Consequently, the inference does not need to start from time step $T$ , but can commence at $t_{1}$ , thereby preserving the prior information of the source domain while enhancing the efficiency of inference. An overview of the impact of $\\eta_{t}$ is presented in Fig. 2. ", "page_idx": 4}, {"type": "text", "text": "3.2 Diffusion DoS-SDEs ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To improve the efficiency of inference in diffusion models, many prior works [30, 31, 9] have designed efficient samplers by solving the diffusion SDEs. Therefore, in this section, we extend the aforementioned discrete shift process to an SDE for description, in preparation for designing efficient samplers in the following section. Specifically, inspired by the work of [40], we generalize this finite shift process further to an infinite number of noise scales, such that the data distribution of domain shift evolves according to an SDE as noise intensifies. Then we provide the corresponding reversetime SDE and elucidate the training of diffusion models from the perspective of score matching [39]. Next, we will elaborate extensively on how to describe diffusion models using SDEs. ", "page_idx": 4}, {"type": "text", "text": "Forward Process. Expanding the time variable $t$ in Eq. (2) to a continuous range, $t\\in[0,T]$ , we have that $\\alpha_{t},\\sigma_{t},\\eta_{t}$ are differentiable functions of $t$ with bounded derivatives. Furthermore, Song et al. [40] have demonstrated that the diffusion process can be modeled as the solution to an It\u00f4 SDE and we formulate the SDE as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nd\\pmb{x}_{t}=[f(t)\\pmb{x}_{t}+h(t)\\hat{\\pmb{x}}_{0}]d t+g(t)d\\pmb{w}_{t},\\ \\pmb{x}_{0}\\sim q_{0}(\\pmb{x}_{0}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\pmb{w}_{t}$ is the standard Wiener process, and $q_{0}(x_{0})$ is the target domain data distribution. It has the same marginal distribution $q(\\mathbf{\\bar{x}}_{t}|\\mathbf{x}_{0},\\mathbf{\\hat{x}}_{0})$ as in Eq. (2) for any $t\\in[0,T]$ with the coefficients satisfying (proof in Appendix A.2) ", "page_idx": 4}, {"type": "equation", "text": "$$\nf(t)=\\frac{d\\log\\alpha_{t}(1-\\eta_{t})}{d t},\\;\\;\\;h(t)=\\frac{\\alpha_{t}}{1-\\eta_{t}}\\frac{d\\eta_{t}}{d t},\\;\\;\\;g(t)=\\sqrt{\\frac{d\\sigma_{t}^{2}}{d t}-2\\frac{d\\log\\alpha_{t}(1-\\eta_{t})}{d t}\\sigma_{t}^{2}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Reverse Process. The reverse of a diffusion process is also a diffusion process [2] which can similarly be described by a reverse-time SDE (proof in Appendix A.3): ", "page_idx": 4}, {"type": "equation", "text": "$$\nd x_{t}=\\Big[f(t)x_{t}+h(t)\\hat{x}_{0}-g^{2}(t)\\nabla_{x}\\log q_{t}(x_{t})\\Big]d t+g(t)d\\overline{{w}}_{t}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\overline{{\\pmb{w}}}_{t}$ is also a standard Wiener process when time flows backwards. In this paper, we refer to this SDE as Domain Shift SDE (DoS-SDE). ", "page_idx": 4}, {"type": "text", "text": "Score Matching. The only unknown term in Eq. (7) is the score function $\\nabla_{\\mathbf{x}}\\log q_{t}(\\mathbf{x}_{t})$ that can be estimated by training a score-based model on samples with score matching [39]. In practice, we use a neural network $\\epsilon_{\\theta}(x_{t},\\hat{{\\pmb x}}_{0},t)$ conditioned on $\\hat{\\pmb{x}}_{0}$ , parameterized by $\\pmb{\\theta}$ , to estimate the scaled score function (alternatively referred to as noise), following [16, 40]. The parameter $\\pmb{\\theta}$ is optimized by minimizing the following objectives: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\theta^{*}=\\underset{\\theta}{\\arg\\operatorname*{min}}\\ \\mathbf{E}_{t}\\Bigl\\{w(t)\\mathbf{E}_{q_{t}(x_{t})}\\bigl[||\\epsilon_{\\theta}(x_{t},\\hat{x}_{0},t)+\\sigma_{t}\\nabla_{x}\\log q_{t}(x_{t})||\\bigr]\\Bigr\\}}}\\\\ {{\\mathrm{~}=\\underset{\\theta}{\\arg\\operatorname*{min}}\\ \\mathbf{E}_{t}\\Bigl\\{w(t)\\mathbf{E}_{q_{0}(x_{0})}\\mathbf{E}_{q(\\epsilon)}\\bigl[||\\epsilon_{\\theta}(x_{t},\\hat{x}_{0},t)-\\epsilon||\\bigr]\\Bigr\\},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $w(t)$ is a weighting function, $\\pmb{x}_{t}=\\alpha_{t}(\\eta_{t}\\pmb{\\hat{x}}_{0}+(1-\\eta_{t})\\pmb{x}_{0})+\\sigma_{t}\\pmb{\\epsilon}$ , and $\\pmb{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\pmb{I})$ . ", "page_idx": 4}, {"type": "text", "text": "Thus, we have completed the expression of the diffusion model using SDEs. Sampling from diffusion models can alternatively be seen as solving the corresponding diffusion DoS-SDEs. ", "page_idx": 4}, {"type": "text", "text": "3.3 Solvers for Diffusion DoS-SDEs ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we present an exact formulation of the solution of diffusion DoS-SDEs and design efficient samplers for fast sampling. To facilitate the solution of equation Eq. (7), we utilize the data prediction model $\\mathbf{\\mathcal{x}}_{\\theta}(\\mathbf{\\mathcal{x}}_{t},\\hat{\\mathbf{\\boldsymbol{x}}}_{0},t)$ , which directly estimates the original target data $\\pmb{x}_{0}$ from the noisy samples. The relationship between score function and data prediction model is as follows (proof in Appendix A.4): ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\nabla_{x}\\log{q_{t}(x_{t})}=-\\frac{x_{t}-(\\alpha_{t}(1-\\eta_{t})x_{\\theta}(x_{t},\\hat{x}_{0},t)+\\alpha_{t}\\eta_{t}\\hat{x}_{0})}{\\sigma_{t}^{2}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In practice, we employ our trained noise prediction model $\\epsilon_{\\theta}(x_{t},\\hat{\\pmb{x}}_{0},t)$ for data prediction $\\mathbf{\\mathcal{x}}_{\\theta}(\\mathbf{\\mathcal{x}}_{t},\\hat{\\mathbf{\\boldsymbol{x}}}_{0},t)$ as described in Appendix A.4. By substituting Eq. (6) and Eq. (9) into Eq. (7) and introducing the substitutions $\\begin{array}{r}{\\lambda_{t}~=~\\frac{\\sigma_{t}}{\\alpha_{t}\\left(1-\\eta_{t}\\right)}}\\end{array}$ \u03b1t(1\u03c3t\u2212\u03b7t) and yt = $\\begin{array}{r}{\\pmb{y}_{t}~=~\\frac{\\pmb{x}_{t}}{\\alpha_{t}\\left(1-\\eta_{t}\\right)}}\\end{array}$ along with the notation $\\begin{array}{r}{d{\\pmb w}_{\\lambda_{t}}:=\\sqrt{\\frac{d\\lambda_{t}}{d t}}d{\\pmb w}_{t},{\\pmb x}_{\\lambda}:={\\pmb x}_{t(\\lambda)},{\\pmb w}_{\\lambda}:={\\pmb w}_{\\lambda_{t}}}\\end{array}$ , we rewrite Eq. (7) w.r.t $\\lambda$ as $d y_{\\lambda}=\\frac{2}{\\lambda}y_{\\lambda}d\\lambda+\\Big[\\frac{1}{(1-\\eta_{\\lambda})^{2}}d\\eta_{\\lambda}-\\frac{\\eta_{\\lambda}}{1-\\eta_{\\lambda}}\\frac{2}{\\lambda}d\\lambda\\Big]\\hat{x}_{0}-\\frac{2}{\\lambda}x_{\\theta}(x_{\\lambda},\\hat{x}_{0},\\lambda)d\\lambda+\\sqrt{2\\lambda}d w_{\\lambda}$ (10) ", "page_idx": 5}, {"type": "text", "text": "We propose the exact solution for Eq. (10) using the variation-of-constants formula, following [31, 9]. Proposition 3.1 (Exact solution of diffusion DoS-SDEs). Given an initial value $\\pmb{x}_{s}$ at time $s>0$ , the solution $\\pmb{x}_{t}$ for the diffusion DoS-SDEs defined in Eq. (7) at time $t\\in[0,s]$ is as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle x_{t}=\\frac{\\alpha_{t}(1-\\eta_{t})}{\\alpha_{s}(1-\\eta_{s})}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}}x_{s}+\\alpha_{t}(1-\\eta_{t})(\\frac{\\eta_{t}}{1-\\eta_{t}}-\\frac{\\eta_{s}}{1-\\eta_{s}}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\hat{x}_{0}}}\\\\ {{\\displaystyle\\quad-\\,\\alpha_{t}(1-\\eta_{t})\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}x_{\\theta}(x_{\\lambda},\\hat{x}_{0},\\lambda)d\\lambda+\\alpha_{t}(1-\\eta_{t})\\sqrt{\\lambda_{t}^{2}-\\frac{\\lambda_{t}^{4}}{\\lambda_{s}^{2}}}z_{s},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The detailed derivation of this proposition is provided in Appendix A.5. Notably, the nonlinear term in Eq. (11) involves the integration of a non-analytical neural network ${\\pmb x}_{\\theta}({\\pmb x}_{\\lambda},\\hat{\\pmb x}_{0},\\lambda)$ , which can be challenging to compute. For practical applicability, we employ It\u00f4-Taylor expansion to approximate the integral of $\\pmb{x}_{\\theta}$ from $\\lambda_{s}$ to $\\lambda_{t}$ to compute $\\tilde{\\pmb{x}}_{t}$ , thereby approximating $\\pmb{x}_{t}$ . Additionally, we approximate the derivatives of $\\pmb{x}_{\\theta}$ using the forward differential method. These approximations allow us to derive SDE solvers of any order for diffusion DoS-SDEs. For the sake of brevity, we employ a first-order solver for demonstration. In this case, Eq. (11) becomes ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\tilde{\\mathbf{\\boldsymbol{x}}}_{t}=\\frac{\\alpha_{t}\\left(1-\\eta_{t}\\right)}{\\alpha_{s}\\left(1-\\eta_{s}\\right)}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}}\\mathbf{\\boldsymbol{x}}_{s}+\\underbrace{\\alpha_{t}(1-\\eta_{t})(\\frac{\\eta_{t}}{1-\\eta_{t}}-\\frac{\\eta_{s}}{1-\\eta_{s}}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\hat{\\boldsymbol{x}}_{0}}_{\\mathrm{Domian~Shift~Guidance{(DoSG)}}}}\\\\ {{+\\,\\alpha_{t}(1-\\eta_{t})(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\mathbf{\\boldsymbol{x}}_{\\theta}\\big(\\mathbf{\\boldsymbol{x}}_{s},\\hat{\\mathbf{\\boldsymbol{x}}}_{0},s\\big)+\\alpha_{t}\\big(1-\\eta_{t}\\big)\\sqrt{\\lambda_{t}^{2}-\\frac{\\lambda_{t}^{4}}{\\lambda_{s}^{2}}}\\mathbf{\\boldsymbol{z}}_{s}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The detailed derivation, as well as high-order solvers, are provided in Appendix A.6, and detailed algorithms are proposed in Appendix B. Typically, higher-order solvers converge even faster because of more accurate estimation of the the nonlinear integral term. The solvers provided for sampling allow us to iteratively generate HR images using a trained diffusion model. It is worth noting that Eq. (12) comprises four terms, including the additional linear term $\\hat{\\pmb{x}}_{0}$ , as compared to the ancestral sampling algorithm [16]. We refer to this additional term as the domain shift guidance (DoSG) which leverages prior information from the source domain and enhances the efficiency of inference. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1 Experimental setup ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For training, we train our DoSSR using a variety of datasets including DIV2K [1], DIV8K [15], Flickr2K [43], and OST [47]. To synthesize LR and HR training pairs, we adopt the degradation ", "page_idx": 5}, {"type": "text", "text": "Table 1: Quantitative comparison with state-of-the-art methods on both synthetic and real-world benchmarks, as well as comparison of latency and number of model parameters. NFE represents the number of function evaluations in the inference of diffusion models. The best and second best results of each metric are highlighted in red and blue, respectively. ", "page_idx": 6}, {"type": "table", "img_path": "u7okTt4ZyE/tmp/b86fdf46f444bda5658e0caffd50516c0cea69ae93cb152051bfc8fcbd859bb0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "pipeline from RealESRGAN [46]. For the network architecture, we employ the LAControlNet [27] with SD 2.1-base3 as the pretrained T2I model. In cases where LR images are severely degraded, potentially leading to the diffusion model mistaking degradation for semantic content, we implement RealESRNet [46] as a preprocessing step. This ensures our source domain consists of preprocessed LR images, thereby refining the input quality for better model training and performance. The model is fine-tuned for $50\\mathrm{k}$ iterations using the Adam optimizer [20], with a batch size of 32 and a learning rate set to $5\\times10^{-5}$ , on $512\\times512$ resolution images. ", "page_idx": 6}, {"type": "text", "text": "For testing, we evaluate our method on both synthetic and real-world datasets, employing the same configuration as StableSR4. For synthetic data, we randomly crop 3K patches with a resolution of $512\\times512$ from the DIV2K validation set [1], and degrade them following the degradation pipeline of RealESRGAN [46]. For real-world datasets, we generate LR images with a resolution of $128\\times128$ by center-cropping on RealSR [4], DRealSR [50] and RealLR200 [51]. ", "page_idx": 6}, {"type": "text", "text": "4.2 Comparisons with State-of-the-Arts ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We compare DoSSR with the state-of-the-art real-world SR methods, including BSRGAN [54], RealESRGAN [46], LDL [23], DASR [24], StableSR [45], ResShift [53], DiffBIR [27], and SeeSR [51]. We use the publicly available codes and pretrained models to facilitate fair comparisons. ", "page_idx": 6}, {"type": "text", "text": "Quantitative Comparison. We show the quantitative comparison on the four synthetic and realworld datasets in Table 1. To comprehensively evaluate the performance of various methods, we utilize the following metrics5 for quantitative comparison: reference-based metrics PSNR, SSIM [49], LPIPS [55], and non-reference metrics CLIPIQA [44], MUSIQ [19], MANIQA [52], TOPIQ [5]. ", "page_idx": 6}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/aa15f9feb59f5cad41e827efc3b94f71efc6b3a4a3c2f8de6520327a21d27984.jpg", "img_caption": ["Figure 3: Qualitative comparisons of different steps of our DoSSR and other diffusion-based SR methods. The \"-N\" suffix denotes inference steps. Please zoom in for a better view. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Notably, DoSSR consistently achieves the highest scores in CLIPIQA, MANIQA, and TOPIQ, with the exception of being second in TOPIQ on DIV2K, and attains the second highest score in MUSIQ across all four datasets. At the same time, we also note that diffusion-based methods generally achieve poorer performance in reference metrics compared to GAN-based methods due to their ability to generate more realistic details at the expense of fidelity. Additionally, our DoSSR manages to achieve improved no-reference metric performance compared to the data presented in Table 1 as NFE increases slightly, a detail further elaborated on in Section 4.3. ", "page_idx": 7}, {"type": "text", "text": "Qualitative Comparison. Figs. 1(b), 3 present visual comparisons on real-world images. By leveraging learning of domain shift and introducing DoSG, our DoSSR efficiently generates highquality texture details consistent with contents of the LR image. In the example of Fig. 1(b), GAN-based methods fail to faithfully reconstruct the grid texture of clothing, leading to notable degradation. StableSR and ResShift produce specific erroneous textures. Both SeeSR and ours successfully restore correct textures, while our results display clearer textures. Similarly, in the first example of Fig. 3, our DoSSR generates a more perceptually convincing Spider-Man face as well as textures, while in the second example, it produces more realistic and high-quality details of ground-laid bricks compared to other methods. More visual examples are provided in Fig. 7. ", "page_idx": 7}, {"type": "text", "text": "Efficiency Comparison. The comparative analysis of model parameters and latency for competing SR models is shown in Fig. 1(a) and Table 1. The latency is calculated on the ${\\times4}\\,{\\cal S}{\\cal R}$ task for $128\\!\\times\\!128$ LR images with V100 GPU. StableSR, DiffBIR, SeeSR, and our DoSSR utilize the pretrained SD model, resulting in a similar parameter count, with SeeSR incorporating a prompt extractor to enhance SR results, making it the largest among these methods. ResShift, utilizing the network structure from LDM [35], is trained from scratch and has significantly fewer parameters. It employs a 15- step process to achieve faster inference speeds. Among the pretrained SD-based methods, DoSSR demonstrates superior performance efficiency, requiring only 5 function evaluations to achieve speeds 5-7 times faster than previous SD-based models such as SeeSR. Additionally, DoSSR not only demonstrates faster or comparable latency to ResShift but also achieves significantly better super-resolution performance. ", "page_idx": 7}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/96b26c6ac21c9fd60ecef11efd611d343334d2e56bc61629ddf2a40749d45280.jpg", "img_caption": ["Figure 4: (a) Quality metrics vs. steps on RealSR Dataset. (b) Qualitative comparisons of different steps of our DoSSR with other methods. The suffix \"-N\" appended to the method name indicates the number of inference steps. Please zoom in for a better view. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.3 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Effectiveness of DoSG. To verify the effectiveness of the DoSG introduced in the diffusion equation, we conduct an experiment using identical network architectures but with two different diffusion equations: the original diffusion equation as described by Ho et al. [16] and our newly formulated equation (Eq. (2)). To isolate the impact of DoSG from our shifting sequence design, we set $t_{1}\\,=\\,T$ , ensuring that the starting point of our inference in both scenarios approximates Gaussian noise. Quantitative comparisons can be found in the first two rows of Table 2. It is evident that the introduction of DoSG leads to a significant improvement across all metrics in the table, highlighting the effectiveness of DoSG in enhancing the performance of diffusion-based SR models. Additionally, it is worth noting that the original diffusion equation can be considered a special case within our framework where $\\eta_{t}\\,=\\,0$ and $t_{1}=T$ . Therefore, our sampler can accommodate the original diffusion equation, and for a fair comparison, we employ the same sampler for both models. More comprehensive comparison is provided in Appendix Table 6, where it can be seen that our DoSSR demonstrates superior performance compared to the corresponding order solver with DDPM, benefiting from the inclusion of DoSG in our DoS SDE-Solver. ", "page_idx": 8}, {"type": "text", "text": "The selection of $t_{1}$ . The strating point $t_{1}$ serves as a pivotal parameter in DoSSR. We explore several options on the value of $t_{1}$ and show the corresponding final SR performance in Table 2. It can be observed that SR performance improves as $t_{1}$ gradually decreases from $T$ to $T/2$ . However, further decreasing $t_{1}$ from $T/2$ to $3/T$ conversely compromises SR performance. Intuitively, a larger $t_{1}$ means less LR prior is preserved due to a larger magnitude of added noises, and the model behaves more like the vanilla pretrained model by hallucinating plausible HR contents; In contrast, a smaller $t_{1}$ ", "page_idx": 8}, {"type": "table", "img_path": "u7okTt4ZyE/tmp/0b102414e5c17a742bc259220847622a68065c4c722feff3837552f382600b08.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 2: Comparison across various selections of starting point $t_{1}$ , evaluated on the DRealSR dataset. The baseline method is DDPM, which employs the original diffusion equation. In all setups, inference is carried out over 5 steps. ", "page_idx": 8}, {"type": "text", "text": "means less noises, so the prediction is prone to be more consistent with the LR image, but without HR details. Hence, we set $t_{1}=T/2$ by default for a good trade-off. ", "page_idx": 8}, {"type": "text", "text": "The number of step. We assess the impact of different inference steps on DoSSR by analyzing changes in representative metrics for both reference-based and non-reference-based evaluations, as shown in Fig. 4(a). As the number of inference steps increases, reference-based metrics tend to decline, suggesting a loss in fidelity, while non-reference metrics improve, indicating enhanced realism and detail in the generated images. We also conduct visual comparisons in Fig. 4(b). Our DoSSR achieves performance comparable to SeeSR in just 5 steps and produces more realistic details in 7 steps. Remarkably, DoSSR is capable of delivering satisfactory results even with just a single step, achieving 0.5115 MANIQA score and 0.6258 CLIPIQA score on the RealSR dataset, significantly boosting the efficiency of diffusion-based methods. More visual examples are provided in Fig. 9, where it can be observed that increasing the number of steps yields more realistic details. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "The order of our sampler. We provide a suite of solvers for sampling in our DoSSR model, including a first-order solver presented in Eq. (11), and more advanced second- and third-order solvers detailed in Appendix A.6. We investigate the impact of samplers with different orders on our experimental results through qualitative and quantitative comparisons, as illustrated in Table 3 and Fig. 10. From Table 3, it becomes evident that high-order samplers can achieve superior non-reference metrics under the same limited inference step conditions. This is because the acceleration of ", "page_idx": 9}, {"type": "table", "img_path": "u7okTt4ZyE/tmp/577c5708c03fd571185793517db8f15b9c4557e45060e7d88c09d062519c5f80.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Table 3: Comparison of performance of different sampler orders on the DRealSR dataset. In all setups, inference is carried out over 5 steps. ", "page_idx": 9}, {"type": "text", "text": "higher-order samplers allows diffusion models to generate more details, as demonstrated in the first example of Fig. 10, where the tower generated by the high-order sampler exhibits richer textures. More comprehensive comparison is provided in Appendix Table 6. In our implementation, we use third-order sampler by default. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we present DoSSR, a diffusion-based super-resolution framework that significantly enhances both efficiency and performance by integrating a domain shift strategy with pretrained diffusion models. This approach not only enhances generative capacity but also enhances further inference efficiency through our novel proposed DoS-SDEs formulation and customized solvers. Empirical validation on diverse SR benchmarks confirms that DoSSR achieves a 5-7 times speed improvement over existing methods, setting a new state-of-the-art. Our work paves the way for more efficient diffusion-based solutions in image super-resolution. ", "page_idx": 9}, {"type": "text", "text": "Limitation. Despite the strong overall performance demonstrated by the proposed DoSSR, it occasionally generates visually unfriendly details when employing an unfavorable random seed, a challenge also encountered by other diffusion-based methods. Typically, we fix the random seed for all image super-resolution tasks to stabilize the results, but this particular seed may not be suitable for certain specific images. As depicted in Fig. 8, different initializations of random seeds result in significant variations in the details of the lion\u2019s eyes. Some of the initialized random seeds produce eyes that are reasonable and acceptable, while others exhibit noticeable inconsistencies with LR. For bad cases, we can also obtain a satisfactory result by adjusting the random seed multiple times. However, this often requires numerous attempts, and the quality of the results heavily relies on luck. This inspires us to find a suitable initialization for each specific LR image, which can enhance the performance of the model. Hence, for diffusion-based methods, exploring how to obtain a reasonable random seed based on known LR images may be a future research direction. ", "page_idx": 9}, {"type": "text", "text": "Societal impact. Our advancements in the diffusion-based image super-resolution model, DoSSR, present both positive and negative societal impacts. On the positive side, it enhances medical imaging, potentially leading to more accurate diagnoses and reducing the need for invasive procedures. In surveillance, it aids in better identification and tracking, improving public safety. Moreover, in remote sensing and environmental monitoring, it facilitates informed decision-making for disaster management and environmental conservation. However, there are concerns regarding privacy and surveillance. Enhanced resolution capabilities could infringe upon privacy rights and lead to increased surveillance in public spaces, raising questions about civil liberties. Additionally, in digital media, while high-resolution imagery enhances visual content, it may perpetuate unrealistic beauty standards and digital manipulation, impacting self-esteem. In summary, while DoSSR brings promising advancements, it\u2019s crucial to address concerns around privacy, security, and digital ethics to ensure responsible and ethical deployment of the technology. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Eirikur Agustsson and Radu Timofte. Ntire 2017 challenge on single image super-resolution: Dataset and study. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 126\u2013135, 2017.   \n[2] Brian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Applications, 12(3):313\u2013326, 1982.   \n[3] Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie Li, Hamid Kazemi, Furong Huang, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Cold diffusion: Inverting arbitrary image transforms without noise. Advances in Neural Information Processing Systems, 36, 2024.   \n[4] Jianrui Cai, Hui Zeng, Hongwei Yong, Zisheng Cao, and Lei Zhang. Toward real-world single image super-resolution: A new benchmark and a new model. In Proceedings of the IEEE/CVF international conference on computer vision, pages 3086\u20133095, 2019.   \n[5] Chaofeng Chen, Jiadi Mo, Jingwen Hou, Haoning Wu, Liang Liao, Wenxiu Sun, Qiong Yan, and Weisi Lin. Topiq: A top-down approach from semantics to distortions for image quality assessment. IEEE Transactions on Image Processing, 33:2404\u20132418, 2024.   \n[6] Xiangyu Chen, Xintao Wang, Jiantao Zhou, Yu Qiao, and Chao Dong. Activating more pixels in image super-resolution transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22367\u201322377, 2023.   \n[7] Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon. Ilvr: Conditioning method for denoising diffusion probabilistic models. arXiv preprint arXiv:2108.02938, 2021.   \n[8] Hyungjin Chung, Byeongsu Sim, and Jong Chul Ye. Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12413\u201312422, 2022.   \n[9] Qinpeng Cui, Xinyi Zhang, Zongqing Lu, and Qingmin Liao. Elucidating the solution space of extended reverse-time sde for diffusion models. arXiv preprint arXiv:2309.06169, 2023.   \n[10] Tao Dai, Jianrui Cai, Yongbing Zhang, Shu-Tao Xia, and Lei Zhang. Second-order attention network for single image super-resolution. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11065\u201311074, 2019.   \n[11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009.   \n[12] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. Learning a deep convolutional network for image super-resolution. In Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part IV 13, pages 184\u2013199. Springer, 2014.   \n[13] Dario Fuoli, Luc Van Gool, and Radu Timofte. Fourier space losses for efficient perceptual image super-resolution. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2360\u20132369, 2021.   \n[14] Martin Gonzalez, Nelson Fernandez Pinto, Thuy Tran, Hatem Hajri, Nader Masmoudi, et al. Seeds: Exponential sde solvers for fast high-quality sampling from diffusion models. Advances in Neural Information Processing Systems, 36, 2024.   \n[15] Shuhang Gu, Andreas Lugmayr, Martin Danelljan, Manuel Fritsche, Julien Lamour, and Radu Timofte. Div8k: Diverse 8k resolution image dataset. In 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW), pages 3512\u20133516. IEEE, 2019.   \n[16] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840\u20136851, 2020.   \n[17] Huaibo Huang, Ran He, Zhenan Sun, and Tieniu Tan. Wavelet-srnet: A wavelet-based cnn for multi-scale face super resolution. In Proceedings of the IEEE international conference on computer vision, pages 1689\u20131697, 2017.   \n[18] Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. Denoising diffusion restoration models. Advances in Neural Information Processing Systems, 35:23593\u201323606, 2022.   \n[19] Junjie Ke, Qifei Wang, Yilin Wang, Peyman Milanfar, and Feng Yang. Musiq: Multi-scale image quality transformer. In Proceedings of the IEEE/CVF international conference on computer vision, pages 5148\u20135157, 2021.   \n[20] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[21] Haoran Li, Long Ma, Yong Liao, Lechao Cheng, Yanbin Hao, and Pengyuan Zhou. 3d-goi: 3d gan omni-inversion for multifaceted and multi-object editing. arXiv preprint arXiv:2311.12050, 2023.   \n[22] Haoran Li, Haolin Shi, Wenli Zhang, Wenjun Wu, Yong Liao, Lin Wang, Lik-hang Lee, and Pengyuan Zhou. Dreamscene: 3d gaussian-based text-to-3d scene generation via formation pattern sampling. arXiv preprint arXiv:2404.03575, 2024.   \n[23] Jie Liang, Hui Zeng, and Lei Zhang. Details or artifacts: A locally discriminative learning approach to realistic image super-resolution. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5657\u20135666, 2022.   \n[24] Jie Liang, Hui Zeng, and Lei Zhang. Efficient and degradation-adaptive network for real-world image super-resolution. In European Conference on Computer Vision, pages 574\u2013591. Springer, 2022.   \n[25] Jingyun Liang, Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool, and Radu Timofte. Swinir: Image restoration using swin transformer. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1833\u20131844, 2021.   \n[26] Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. Enhanced deep residual networks for single image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 136\u2013144, 2017.   \n[27] Xinqi Lin, Jingwen He, Ziyan Chen, Zhaoyang Lyu, Ben Fei, Bo Dai, Wanli Ouyang, Yu Qiao, and Chao Dong. Diffbir: Towards blind image restoration with generative diffusion prior. arXiv preprint arXiv:2308.15070, 2023.   \n[28] Anran Liu, Yihao Liu, Jinjin Gu, Yu Qiao, and Chao Dong. Blind image super-resolution: A survey and beyond. IEEE transactions on pattern analysis and machine intelligence, 45(5):5461\u20135480, 2022.   \n[29] Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. In The Eleventh International Conference on Learning Representations (ICLR), 2023.   \n[30] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. Advances in Neural Information Processing Systems, 35:5775\u20135787, 2022.   \n[31] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solve $^{++}$ : Fast solver for guided sampling of diffusion probabilistic models. arXiv preprint arXiv:2211.01095, 2022.   \n[32] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang Zhao. Latent consistency models: Synthesizing high-resolution images with few-step inference, 2023.   \n[33] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pages 8162\u20138171. PMLR, 2021.   \n[34] Hannes Risken and Hannes Risken. Fokker-planck equation. Springer, 1996.   \n[35] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684\u201310695, 2022.   \n[36] Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J Fleet, and Mohammad Norouzi. Image super-resolution via iterative refinement. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(4):4713\u20134726, 2022.   \n[37] Axel Sauer, Dominik Lorenz, Andreas Blattmann, and Robin Rombach. Adversarial diffusion distillation. arXiv preprint arXiv:2311.17042, 2023.   \n[38] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In International Conference on Learning Representations, 2021.   \n[39] Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon. Sliced score matching: A scalable approach to density and score estimation. In Uncertainty in Artificial Intelligence, pages 574\u2013584. PMLR, 2020.   \n[40] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021.   \n[41] Stability.ai. https://stability.ai/stable-diffusion.   \n[42] Haoze Sun, Wenbo Li, Jianzhuang Liu, Haoyu Chen, Renjing Pei, Xueyi Zou, Youliang Yan, and Yujiu Yang. Coser: Bridging image and language for cognitive super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition, 2024.   \n[43] Radu Timofte, Eirikur Agustsson, Luc Van Gool, Ming-Hsuan Yang, and Lei Zhang. Ntire 2017 challenge on single image super-resolution: Methods and results. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 114\u2013125, 2017.   \n[44] Jianyi Wang, Kelvin CK Chan, and Chen Change Loy. Exploring clip for assessing the look and feel of images. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 2555\u20132563, 2023.   \n[45] Jianyi Wang, Zongsheng Yue, Shangchen Zhou, Kelvin CK Chan, and Chen Change Loy. Exploiting diffusion prior for real-world image super-resolution. arXiv preprint arXiv:2305.07015, 2023.   \n[46] Xintao Wang, Liangbin Xie, Chao Dong, and Ying Shan. Real-esrgan: Training real-world blind superresolution with pure synthetic data. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1905\u20131914, 2021.   \n[47] Xintao Wang, Ke Yu, Chao Dong, and Chen Change Loy. Recovering realistic texture in image superresolution by deep spatial feature transform. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 606\u2013615, 2018.   \n[48] Yufei Wang, Wenhan Yang, Xinyuan Chen, Yaohui Wang, Lanqing Guo, Lap-Pui Chau, Ziwei Liu, Yu Qiao, Alex C Kot, and Bihan Wen. Sinsr: Diffusion-based image super-resolution in a single step. In Proceedings of the IEEE conference on computer vision and pattern recognition, 2024.   \n[49] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600\u2013612, 2004.   \n[50] Pengxu Wei, Ziwei Xie, Hannan Lu, Zongyuan Zhan, Qixiang Ye, Wangmeng Zuo, and Liang Lin. Component divide-and-conquer for real-world image super-resolution. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part VIII 16, pages 101\u2013117. Springer, 2020.   \n[51] Rongyuan Wu, Tao Yang, Lingchen Sun, Zhengqiang Zhang, Shuai Li, and Lei Zhang. Seesr: Towards semantics-aware real-world image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition, 2024.   \n[52] Sidi Yang, Tianhe Wu, Shuwei Shi, Shanshan Lao, Yuan Gong, Mingdeng Cao, Jiahao Wang, and Yujiu Yang. Maniqa: Multi-dimension attention network for no-reference image quality assessment. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1191\u20131200, 2022.   \n[53] Zongsheng Yue, Jianyi Wang, and Chen Change Loy. Resshift: Efficient diffusion model for image super-resolution by residual shifting. In Advances in Neural Information Processing Systems (NeurIPS), 2023.   \n[54] Kai Zhang, Jingyun Liang, Luc Van Gool, and Radu Timofte. Designing a practical degradation model for deep blind image super-resolution. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4791\u20134800, 2021.   \n[55] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 586\u2013595, 2018.   \n[56] Xinyi Zhang, Qinpeng Cui, Qiqi Bao, Wenming Yang, and Qingmin Liao. Geometry-guided diffusion model with masked transformer for robust multi-view 3d human pose estimation. In ACM Multimedia 2024, 2024.   \n[57] Yulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bineng Zhong, and Yun Fu. Image super-resolution using very deep residual channel attention networks. In Proceedings of the European conference on computer vision (ECCV), pages 286\u2013301, 2018.   \n[58] Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong, and Yun Fu. Residual dense network for image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2472\u20132481, 2018.   \n[59] Yixuan Zhu, Wenliang Zhao, Ao Li, Yansong Tang, Jie Zhou, and Jiwen Lu. Flowie: Efficient image enhancement via rectified flow. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13\u201322, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Mathematical Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Derivation of Eq.(3) ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "According to Eq. (2), we can express $\\pmb{x}_{t}$ as a linear combination of $x_{0},\\hat{x}_{0}$ and a noise variable $\\epsilon$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\pmb{x}_{t}=\\alpha_{t}(\\eta_{t}\\hat{\\pmb{x}}_{0}+(1-\\eta_{t})\\pmb{x}_{0})+\\sigma_{t}\\epsilon,\\:\\:\\mathrm{where}\\:\\epsilon\\sim\\mathcal{N}(\\pmb{0},\\pmb{I}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Subsequently, the relationship between $\\pmb{x}_{t}$ and $x_{t-1}$ is derived as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\bf{r}}_{t}=\\alpha_{t}(\\eta_{t-1}\\hat{\\pmb{x}}_{0}+(1-\\eta_{t-1}){\\pmb{x}}_{0}+(\\eta_{t}-\\eta_{t-1})(\\hat{\\pmb{x}}_{0}-{\\pmb{x}}_{0}))+\\sigma_{t}\\epsilon}\\\\ {\\quad=\\frac{\\alpha_{t}}{\\alpha_{t-1}}\\big[\\alpha_{t-1}(\\eta_{t-1}\\hat{\\pmb{x}}_{0}+(1-\\eta_{t-1}){\\pmb{x}}_{0})+\\sigma_{t-1}{\\pmb{\\epsilon}}_{1}\\big]+\\alpha_{t}(\\eta_{t}-\\eta_{t-1})e_{0}+\\sqrt{\\sigma_{t}^{2}-\\frac{\\alpha_{t}^{2}}{\\alpha_{t-1}^{2}}\\sigma_{t-1}^{2}}\\epsilon_{2}}\\\\ {\\quad=\\frac{\\alpha_{t}}{\\alpha_{t-1}}{\\pmb{x}}_{t-1}+\\alpha_{t}(\\eta_{t}-\\eta_{t-1})e_{0}+\\sqrt{\\sigma_{t}^{2}-\\frac{\\alpha_{t}^{2}}{\\alpha_{t-1}^{2}}\\sigma_{t-1}^{2}\\epsilon_{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ${\\pmb e}_{0}=\\hat{\\pmb x}_{0}-{\\pmb x}_{0}$ , and $\\epsilon,\\epsilon_{1},\\epsilon_{2}\\sim\\mathcal{N}(\\mathbf{0},I)$ . Taking into account $\\alpha_{t}^{2}+\\sigma_{t}^{2}=1$ , the above equation can be further simplified as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\pmb x}_{t}=\\frac{\\alpha_{t}}{\\alpha_{t-1}}{\\pmb x}_{t-1}+\\alpha_{t}(\\eta_{t}-\\eta_{t-1}){\\pmb e}_{0}+\\sqrt{1-\\frac{\\alpha_{t}^{2}}{\\alpha_{t-1}^{2}}}{\\pmb\\epsilon}_{2},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, the transition distribution between $\\pmb{x}_{t}$ and $x_{t-1}$ is as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\nq(\\pmb{x}_{t}|\\pmb{x}_{t-1},\\hat{\\pmb{x}}_{0})=N(\\pmb{x}_{t};\\frac{\\alpha_{t}}{\\alpha_{t-1}}\\pmb{x}_{t-1}+\\alpha_{t}(\\eta_{t}-\\eta_{t-1})\\pmb{e}_{0},1-\\frac{\\alpha_{t}^{2}}{\\alpha_{t-1}^{2}}\\pmb{I}),\\;t=1,2,\\cdots,T,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.2 Derivation of Eq.(6) ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we derive the coefficients of the forward SDE. Discretizing Eq. (5) yields: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{c}{{x_{t+\\Delta t}-x_{t}=f(t)x_{t}\\Delta t+h(t)\\hat{x}_{0}\\Delta t+g(t)\\sqrt{\\Delta t}z_{1},\\,\\mathrm{~where~}z_{1}\\sim\\mathcal{N}(\\mathbf{0},I)}}\\\\ {{x_{t+\\Delta t}=(f(t)\\Delta t+1)x_{t}+h(t)\\hat{x}_{0}\\Delta t+g(t)\\sqrt{\\Delta t}z_{1}.}}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Substituting Eq. (13) into Eq. (16), we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{\\boldsymbol{x}}_{t+\\Delta t}=(f(t)\\Delta t+1)[\\alpha_{t}(\\eta_{t}\\hat{\\mathbf{x}}_{0}+(1-\\eta_{t})\\mathbf{\\boldsymbol{x}}_{0})+\\sigma_{t}\\boldsymbol{z}_{2}]+h(t)\\hat{\\mathbf{x}}_{0}\\Delta t+g(t)\\sqrt{\\Delta t}\\boldsymbol{z}_{1}}\\\\ {=\\alpha_{t}(f(t)\\Delta t+1)(1-\\eta_{t})\\mathbf{\\boldsymbol{x}}_{0}+[\\alpha_{t}\\eta_{t}(f(t)\\Delta t+1)+h(t)\\Delta t]\\hat{\\mathbf{x}}_{0}}\\\\ {+\\left\\sqrt{(f(t)\\Delta t+1)^{2}\\sigma_{t}^{2}+g(t)^{2}}\\hat{\\boldsymbol{z}},\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $z_{2},\\tilde{z}\\sim\\mathcal{N}(\\mathbf{0},I)$ . For Eq. (13) at time $t+\\Delta t$ , we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{x}_{t+\\Delta t}=\\alpha_{t+\\Delta t}(\\eta_{t+\\Delta t}\\hat{\\pmb{x}}_{0}+(1-\\eta_{t+\\Delta t})\\pmb{x}_{0})+\\sigma_{t+\\Delta t}\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Equating the corresponding parts of Eq. (17) and Eq. (18) yields: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{c}{\\alpha_{t+\\Delta t}(1-\\eta_{t+\\Delta t})=\\alpha_{t}(f(t)\\Delta t+1)(1-\\eta_{t})}\\\\ {\\alpha_{t+\\Delta t}\\eta_{t+\\Delta t}=\\alpha_{t}\\eta_{t}(f(t)\\Delta t+1)+h(t)\\Delta t}\\\\ {\\sigma_{t+\\Delta t}^{2}=[f(t)\\Delta t+1]^{2}\\sigma_{t}^{2}+g(t)^{2}\\Delta t}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then, letting $\\Delta t\\rightarrow0$ , the aforementioned three equations can be solved separately to yield: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle f(t)=\\frac{d\\log\\alpha_{t}(1-\\eta_{t})}{d t}}\\\\ {\\displaystyle h(t)=\\frac{\\alpha_{t}}{1-\\eta_{t}}\\frac{d\\eta_{t}}{d t}}\\\\ {\\displaystyle g(t)=\\sqrt{\\frac{d\\sigma_{t}^{2}}{d t}-2\\frac{d\\log\\alpha_{t}(1-\\eta_{t})}{d t}\\sigma_{t}^{2}}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.3 Derivation of Eq.(7) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "As outlined in Sec. 3.2, the forward process can be expressed as the SDE shown in Eq. (5). In accordance with the Fokker-Plank Equation [34], we obtain: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\partial{q}_{t}({\\pmb x}_{t})}{\\partial t}=-\\nabla_{{\\pmb x}}\\{[f(t){\\pmb x}_{t}+h(t)\\hat{\\pmb x}_{0}]{q}_{t}({\\pmb x}_{t})\\}+\\frac{\\partial}{\\partial{\\pmb x}_{i}\\partial{\\pmb x}_{j}}[\\frac{1}{2}{g}^{2}(t){q}_{t}({\\pmb x}_{t})]}\\\\ {\\displaystyle~~~~~~~~~~~=-\\nabla_{{\\pmb x}}\\{[f(t){\\pmb x}_{t}+h(t)\\hat{\\pmb x}_{0}]{q}_{t}({\\pmb x}_{t})\\}+\\nabla_{{\\pmb x}}[\\frac{1}{2}{g}^{2}(t)\\nabla_{{\\pmb x}}{q}_{t}({\\pmb x}_{t})]}\\\\ {\\displaystyle~~~~~~~~~=-\\nabla_{{\\pmb x}}\\{[f(t){\\pmb x}_{t}+h(t)\\hat{\\pmb x}_{0}]{q}_{t}({\\pmb x}_{t})\\}+\\nabla_{{\\pmb x}}[\\frac{1}{2}{g}^{2}(t){q}_{t}({\\pmb x}_{t})\\nabla_{{\\pmb x}}\\log{q}_{t}({\\pmb x}_{t})]}\\\\ {\\displaystyle~~~~~~~~=-\\nabla_{{\\pmb x}}\\{[f(t){\\pmb x}_{t}+h(t)\\hat{\\pmb x}_{0}-\\frac{1}{2}{g}^{2}(t)\\nabla_{{\\pmb x}}\\log{q}_{t}({\\pmb x}_{t})]{q}_{t}({\\pmb x}_{t})\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $q(\\pmb{x}_{t})$ denotes the probability density function of state $\\pmb{x}_{t}$ . Most process defined by a forwardtime or conventional diffusion equation model possess a corresponding reverse-time model [2], which can be formulated as: ", "page_idx": 15}, {"type": "equation", "text": "$$\nd\\pmb{x}_{t}=\\mu(t,\\pmb{x}_{t})d t+\\sigma(t,\\pmb{x}_{t})d\\pmb{\\overline{{\\omega}}}_{t}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "According to the backward Fokker-Plank Equation [34], we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\partial{q}_{t}({\\pmb x}_{t})}{\\partial t}=-\\nabla_{{\\pmb x}}[\\mu(t,{\\pmb x}_{t}){q}_{t}({\\pmb x}_{t})]-\\frac{\\partial}{\\partial x_{i}\\partial x_{j}}[\\frac{1}{2}{\\sigma}^{2}(t,{\\pmb x}_{t}){q}_{t}({\\pmb x}_{t})]}\\\\ {\\displaystyle~~~~~~~~~~~~=-\\nabla_{{\\pmb x}}[\\mu(t,{\\pmb x}_{t}){q}_{t}({\\pmb x}_{t})]-\\nabla_{{\\pmb x}}[\\frac{1}{2}{\\sigma}^{2}(t,{\\pmb x}_{t})\\nabla_{{\\pmb x}}{q}_{t}({\\pmb x}_{t})]}\\\\ {\\displaystyle~~~~~~~~~~=-\\nabla_{{\\pmb x}}[\\mu(t,{\\pmb x}_{t}){q}_{t}({\\pmb x}_{t})]-\\nabla_{{\\pmb x}}[\\frac{1}{2}{\\sigma}^{2}(t,{\\pmb x}_{t}){q}_{t}({\\pmb x}_{t})\\nabla_{{\\pmb x}}\\log q_{t}({\\pmb x}_{t})]}\\\\ {\\displaystyle~~~~~~~~~=-\\nabla_{{\\pmb x}}\\{[\\mu(t,{\\pmb x}_{t})+\\frac{1}{2}{\\sigma}^{2}(t,{\\pmb x}_{t})\\nabla_{{\\pmb x}}\\log q_{t}({\\pmb x}_{t})]{q}_{t}({\\pmb x}_{t})\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Our goal is for the reverse process to have the same distribution as the forward process, specifically: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mu(t,x_{t})+\\frac{1}{2}\\sigma^{2}(t,x_{t})\\nabla_{x}\\log q_{t}(x_{t})=f(t)x_{t}+h(t)\\hat{x}_{0}-\\frac{1}{2}g^{2}(t)\\nabla_{x}\\log q_{t}(x_{t}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Typically, we set $\\sigma(t,\\pmb{x}_{t})=g(t)$ [40], yielding: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mu(t,\\pmb{x}_{t})=f(t)\\pmb{x}_{t}+h(t)\\pmb{\\hat{x}}_{0}-g^{2}(t)\\nabla_{\\pmb{x}}\\log q_{t}(\\pmb{x}_{t}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, the reverse-time SDE can be expressed as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nd x_{t}=\\Big[f(t)x_{t}+h(t)\\hat{x}_{0}-g^{2}(t)\\nabla_{x}\\log q_{t}(x_{t})\\Big]d t+g(t)d\\overline{{w}}_{t}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A.4 Derivation of Eq.(9) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The data prediction model $\\mathbf{\\mathcal{x}}_{\\theta}(\\mathbf{\\mathcal{x}}_{t},\\hat{\\mathbf{\\boldsymbol{x}}}_{0},t)$ directly estimates the original target data $\\scriptstyle x_{0}$ from the noisy samples, indicating that $\\mathbf{\\Deltax}_{\\theta}(\\mathbf{\\Deltax}_{t},\\hat{\\mathbf{x}}_{0},t)\\approx\\mathbf{\\Deltax}_{0}$ . Based on Eq. (2), the expression for $q_{t}(\\mathbf{\\boldsymbol{x}}_{t})$ can be formulated as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nq_{t}(\\mathbf{x}_{t})=\\frac{1}{\\sqrt{2\\pi}\\sigma_{t}}\\exp(-\\frac{[\\pmb{x}_{t}-(\\alpha_{t}(1-\\eta_{t})\\pmb{x}_{0}+\\alpha_{t}\\eta_{t}\\hat{\\pmb{x}}_{0})]^{2}}{2\\sigma_{t}^{2}}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Hence, score function is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla_{x}\\log{q_{t}(x_{t})}=-\\frac{\\mathbf{\\dot{{x}}}_{t}-(\\alpha_{t}(1-\\eta_{t})\\mathbf{\\dot{{x}}}_{0}+\\alpha_{t}\\eta_{t}\\hat{\\mathbf{x}}_{0})}{\\sigma_{t}^{2}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Substituting $\\mathbf{\\Deltax}_{\\theta}(x_{t},\\hat{\\mathbf{x}}_{0},t)\\approx\\mathbf{x}_{0}$ , we can establish the relationship between the score function and the data prediction model: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla_{x}\\log{q_{t}(x_{t})}=-\\frac{x_{t}-(\\alpha_{t}(1-\\eta_{t})x_{\\theta}(x_{t},\\hat{x}_{0},t)+\\alpha_{t}\\eta_{t}\\hat{x}_{0})}{\\sigma_{t}^{2}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Furthermore, Eq. (8) shows that the noise prediction model is to estimate ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\epsilon_{\\theta}(x_{t},\\hat{x}_{0},t)\\approx-\\sigma_{t}\\nabla_{x}\\log q_{t}(x_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Hence, the relationship between the noise prediction model and the data prediction model is: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\epsilon_{\\theta}(x_{t},\\hat{x}_{0},t)=\\frac{\\pmb{x}_{t}-(\\alpha_{t}(1-\\eta_{t})\\pmb{x}_{\\theta}(\\pmb{x}_{t},\\hat{\\pmb{x}}_{0},t)+\\alpha_{t}\\eta_{t}\\hat{\\pmb{x}}_{0})}{\\sigma_{t}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "indicating that we easily use trained noise prediction model for data prediction through the equation. ", "page_idx": 15}, {"type": "text", "text": "A.5 Proof of Proposition 3.1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we derive the solution to the equation Eq. (7). By substituting Eq. (9) and Eq. (20) into Eq. (7), we obtain: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle d x_{t}=\\Big\\{\\frac{1}{\\alpha_{t}(1-\\eta_{t})}\\frac{d\\big[\\alpha_{t}(1-\\eta_{t})\\big]}{d t}x_{t}+\\frac{\\alpha_{t}}{1-\\eta_{t}}\\frac{d\\eta_{t}}{d t}\\hat{x}_{0}}\\\\ {\\displaystyle\\qquad-\\Big[2\\sigma_{t}\\frac{d\\sigma_{t}}{d t}-2\\sigma_{t}^{2}\\frac{d\\big[\\alpha_{t}(1-\\eta_{t})\\big]}{d t}\\Big]-\\frac{x_{t}-(\\alpha_{t}(1-\\eta_{t})x_{\\theta}(x_{t},\\hat{x}_{0},t)+\\alpha_{t}\\eta_{t}\\hat{x}_{0})}{\\sigma_{t}^{2}}\\Big\\}d t}\\\\ {\\displaystyle\\qquad+\\sqrt{\\frac{d\\sigma_{t}^{2}}{d t}-2\\frac{d\\log\\alpha_{t}(1-\\eta_{t})}{d t}\\sigma_{t}^{2}}d\\overline{{\\omega}}_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Combining like terms, we get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle d x_{t}=\\Big[\\frac{2}{\\sigma_{t}}\\frac{d\\sigma_{t}}{d t}-\\frac{1}{\\alpha_{t}\\big(1-\\eta_{t}\\big)}\\frac{d\\big[\\alpha_{t}\\big(1-\\eta_{t}\\big)\\big]}{d t}\\Big]x_{t}}\\\\ {\\displaystyle~~~+\\Big\\{\\frac{\\alpha_{t}}{1-\\eta_{t}}\\frac{d\\eta_{t}}{d t}-\\alpha_{t}\\eta_{t}\\Big[\\frac{2}{\\sigma_{t}}\\frac{d\\sigma_{t}}{d t}-\\frac{2}{\\alpha_{t}\\big(1-\\eta_{t}\\big)}\\frac{d\\big[\\alpha_{t}\\big(1-\\eta_{t}\\big)\\big]}{d t}\\Big]\\Big\\}\\hat{x}_{0}}\\\\ {\\displaystyle~~~-2\\alpha_{t}\\big(1-\\eta_{t}\\big)\\Big[\\frac{1}{\\sigma_{t}}\\frac{d\\sigma_{t}}{d t}-\\frac{1}{\\alpha_{t}\\big(1-\\eta_{t}\\big)}\\frac{d\\big[\\alpha_{t}\\big(1-\\eta_{t}\\big)\\big]}{d t}\\Big]x_{\\theta}\\big(x_{t},\\hat{x}_{0},t\\big)}\\\\ {\\displaystyle~~~~+\\sqrt{\\frac{d\\sigma_{t}^{2}}{d t}-2\\frac{d\\log\\alpha_{t}\\big(1-\\eta_{t}\\big)}{d t}\\sigma_{t}^{2}d\\overline{{\\ w}}_{t}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Subsequently, dividing both sides by $\\alpha_{t}(1-\\eta_{t})$ simultaneously, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l l r}{\\lefteqn{\\frac{1}{\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)}d x_{t}=\\Bigl[\\frac{2}{\\sigma_{t}}\\frac{d\\sigma_{t}}{d t}-\\frac{1}{\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)}\\frac{d\\bigl[\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)\\bigr]}{d t}\\Bigr]\\frac{x_{t}}{\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)}}}\\\\ &{}&{\\qquad+\\,\\Bigl\\{\\frac{1}{\\bigl(1-\\eta_{t}\\bigr)^{2}}\\frac{d\\eta_{t}}{d t}-\\frac{\\eta_{t}}{\\bigl(1-\\eta_{t}\\bigr)}\\Bigl[\\frac{2}{\\sigma_{t}}\\frac{d\\sigma_{t}}{d t}-\\frac{2}{\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)}\\frac{d\\bigl[\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)\\bigr]}{d t}\\Bigr]\\Bigr\\}\\hat{x}_{0}}\\\\ &{}&{\\qquad-\\,2\\Bigl[\\frac{1}{\\sigma_{t}}\\frac{d\\sigma_{t}}{d t}-\\frac{1}{\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)}\\frac{d\\bigl[\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)\\bigr]}{d t}\\Bigr]x_{\\theta}(x_{t},\\hat{x}_{0},t)}\\\\ &{}&{\\qquad+\\,\\sqrt{\\frac{2\\sigma_{t}}{\\bigl[\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)\\bigr]^{2}}\\frac{d\\sigma_{t}}{d t}-\\frac{2\\sigma_{t}^{2}}{\\bigl[\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)\\bigr]^{3}}\\frac{d\\bigl[\\alpha_{t}\\bigl(1-\\eta_{t}\\bigr)\\bigr]}{d t}}d\\overline{{\\upsilon}}_{t}\\mathrm{.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "$\\begin{array}{r}{\\lambda_{t}=\\frac{\\sigma_{t}}{\\alpha_{t}\\left(1-\\eta_{t}\\right)}}\\end{array}$ . Then $\\lambda_{t}$ is monotonically increasing, and we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{d\\lambda_{t}}{d t}=\\frac{1}{\\alpha_{t}(1-\\eta_{t})}\\frac{d\\sigma_{t}}{d t}-\\frac{\\sigma_{t}}{[\\alpha_{t}(1-\\eta_{t})]^{2}}\\frac{d[\\alpha_{t}(1-\\eta_{t})]}{d t}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Therefore, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{1}{\\sigma_{t}}\\frac{d\\sigma_{t}}{d t}-\\frac{1}{\\alpha_{t}(1-\\eta_{t})}\\frac{d[\\alpha_{t}(1-\\eta_{t})]}{d t}=\\frac{1}{\\lambda_{t}}\\frac{d\\lambda_{t}}{d t}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By performing the variable substitution yt =\u03b1t(1xt\u2212\u03b7t) and then substituting Eq. (34) into Eq. (32), we can simplify to obtain: ", "page_idx": 16}, {"type": "equation", "text": "$$\nl y_{t}=\\biggr\\{\\frac{2}{\\lambda_{t}}\\frac{d\\lambda_{t}}{d t}y_{t}+\\biggr[\\frac{1}{(1-\\eta_{t})^{2}}\\frac{d\\eta_{t}}{d t}-\\frac{\\eta_{t}}{1-\\eta_{t}}\\bigl(\\frac{2}{\\lambda_{t}}\\frac{d\\lambda_{t}}{d t}\\bigr)\\biggr]\\hat{x}_{0}-\\frac{2}{\\lambda_{t}}\\frac{d\\lambda_{t}}{d t}x_{\\theta}({\\pmb x}_{t},\\hat{x}_{0},t)\\biggr\\}d t+\\sqrt{2\\lambda_{t}\\frac{d\\lambda_{t}}{d t}}d\\overline{{{w}}}_{t}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Denoting $\\begin{array}{r}{d{\\pmb w}_{\\lambda_{t}}:=\\sqrt{\\frac{d\\lambda_{t}}{d t}}d{\\pmb w}_{t},\\pmb x_{\\lambda}:=\\pmb x_{t(\\lambda)},{\\pmb w}_{\\lambda}:={\\pmb w}_{\\lambda_{t}},}\\end{array}$ we rewrite the equation above w.r.t $\\lambda$ as ", "page_idx": 16}, {"type": "equation", "text": "$$\nd y_{\\lambda}=\\frac{2}{\\lambda}y_{\\lambda}d\\lambda+\\Big[\\frac{1}{(1-\\eta_{\\lambda})^{2}}d\\eta_{\\lambda}-\\frac{\\eta_{\\lambda}}{1-\\eta_{\\lambda}}\\frac{2}{\\lambda}d\\lambda\\Big]\\hat{x}_{0}-\\frac{2}{\\lambda}x_{\\theta}(x_{\\lambda},\\hat{x}_{0},\\lambda)d\\lambda+\\sqrt{2\\lambda}d w_{\\lambda}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Utilizing the variation-of-constants formula to solve the equation above, we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{y_{t}=e^{\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2}{\\lambda}d\\lambda}y_{s}+\\displaystyle\\int_{\\lambda_{s}}^{\\lambda_{t}}e^{\\int_{\\lambda}^{\\lambda_{t}}\\frac{2}{\\tau}d\\tau}\\Big[\\frac{1}{(1-\\eta_{\\lambda})^{2}}d\\eta_{\\lambda}-\\displaystyle\\frac{\\eta_{\\lambda}}{1-\\eta_{\\lambda}}\\frac{2}{\\lambda}d\\lambda\\Big]\\hat{x}_{0}}}\\\\ {{-\\displaystyle\\int_{\\lambda_{s}}^{\\lambda_{t}}e^{\\int_{\\lambda}^{\\lambda_{t}}\\frac{2}{\\tau}d\\tau}\\frac{2}{\\lambda}x_{\\theta}(x_{\\lambda},\\hat{x}_{0},\\lambda)d\\lambda+\\displaystyle\\int_{\\lambda_{s}}^{\\lambda_{t}}e^{\\int_{\\lambda}^{\\lambda_{t}}\\frac{2}{\\tau}d\\tau}\\sqrt{2\\lambda}d w_{\\lambda}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Simplifying and substituting back $\\pmb{x}_{t}=\\alpha_{t}(1-\\eta_{t})\\pmb{y}_{t}$ , we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle x_{t}=\\frac{\\alpha_{t}(1-\\eta_{t})}{\\alpha_{s}(1-\\eta_{s})}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}}x_{s}+\\alpha_{t}(1-\\eta_{t})(\\frac{\\eta_{t}}{1-\\eta_{t}}-\\frac{\\eta_{s}}{1-\\eta_{s}}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\hat{x}_{0}}}\\\\ {{\\displaystyle\\quad-\\,\\alpha_{t}(1-\\eta_{t})\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}x_{\\theta}(x_{\\lambda},\\hat{x}_{0},\\lambda)d\\lambda+\\alpha_{t}(1-\\eta_{t})\\sqrt{\\lambda_{t}^{2}-\\frac{\\lambda_{t}^{4}}{\\lambda_{s}^{2}}}z_{s}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, we obtain the exact solution to the DoS-SDEs. ", "page_idx": 17}, {"type": "text", "text": "A.6 Derivation of Solvers for Diffusion DoS-SDEs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Denote x\u03b8 $\\begin{array}{r}{\\pmb{x}_{\\theta}^{(n)}(\\pmb{x}_{\\lambda},\\hat{\\pmb{x}}_{0},\\lambda):=\\frac{d^{n}\\pmb{x}_{\\theta}(\\pmb{x}_{\\lambda},\\hat{\\pmb{x}}_{0},\\lambda)}{d\\lambda^{n}}}\\end{array}$ as the $n$ -th order total derivative of $\\pmb{x}_{\\theta}(\\pmb{x}_{\\lambda},\\lambda)$ w.r.t $\\lambda$ . For $k\\geq1$ , the $k-1$ -th order It\u00f4-Taylor expansion of ${\\pmb x}_{\\theta}({\\pmb x}_{\\lambda},\\hat{\\pmb x}_{0},\\lambda)$ w.r.t $\\lambda$ at $s$ is ", "page_idx": 17}, {"type": "equation", "text": "$$\n{\\pmb x}_{\\theta}({\\pmb x}_{\\lambda},\\hat{\\pmb x}_{0},\\lambda)=\\sum_{n=0}^{k-1}\\frac{(\\lambda-\\lambda_{s})^{n}}{n!}{\\pmb x}_{\\theta}^{(n)}({\\pmb x}_{s},\\hat{\\pmb x}_{0},s)+\\mathcal{R}_{k},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the residual $\\mathcal{R}_{k}$ comprises of deterministic iterated integrals of length greater than $k$ and all iterated with at least one stochastic component. ", "page_idx": 17}, {"type": "text", "text": "Substituting the above It\u00f4-Taylor expansion into Eq. (38) yields ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{\\pmb{x}}_{t}=\\frac{\\alpha_{t}(1-\\eta_{t})}{\\alpha_{s}(1-\\eta_{s})}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}}\\alpha_{s}+\\alpha_{t}(1-\\eta_{t})(\\frac{\\eta_{t}}{1-\\eta_{t}}-\\frac{\\eta_{s}}{1-\\eta_{s}}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\hat{\\pmb{x}}_{0}}\\\\ {\\displaystyle{\\quad-\\,\\alpha_{t}(1-\\eta_{t})\\sum_{n=0}^{k-1}\\pmb{x}_{\\theta}^{(n)}(\\pmb{x}_{s},\\hat{\\pmb{x}}_{0},s)\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}\\frac{(\\lambda-\\lambda_{s})^{n}}{n!}d\\lambda+\\alpha_{t}(1-\\eta_{t})\\sqrt{\\lambda_{t}^{2}-\\frac{\\lambda_{t}^{4}}{\\lambda_{s}^{2}}}z_{s}+\\tilde{\\mathcal{R}}_{k},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\tilde{\\mathcal{R}}_{k}$ can be easily obtained rom $\\mathcal{R}_{k}$ and the integral $\\begin{array}{r}{\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}\\frac{(\\lambda-\\lambda_{s})^{n}}{n!}d\\lambda}\\end{array}$ can nalytically computed by repeated applying $n$ times of integration-by-parts. By dropping the $\\mathcal{R}_{k}$ approximating the first $k-1$ -th total derivatives with forward differential method, we can derive $k$ -th order SDE solvers for diffusion DoS-SDEs. In fact, it is inaccurate to call it \"order\" when $k\\geq2$ , because the proposed algorithm has a global error of at least $\\mathcal{O}(\\lambda-\\lambda_{s})$ [14]. Thus, only when $k=1$ , it is referred to as a first-order solver with a strong convergence guarantee, as stated in [14]. Nevertheless, for practical convenience, we still refer to this approximation as $k$ -th order. Here we present the expressions for first-order as well as second and third-order solvers. We name such solvers as DoS-SDE Solver overall, and DoS-SDE Solver- $k$ for a specific order $k$ . ", "page_idx": 17}, {"type": "text", "text": "DoS-SDE Solver-1 When $k=1$ , the integral becomes ", "text_level": 1, "page_idx": 17}, {"type": "equation", "text": "$$\n-\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}x_{\\theta}(x_{\\lambda},\\lambda)d\\lambda\\approx-\\lambda_{t}^{2}\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2}{\\lambda^{3}}d\\lambda x_{\\theta}(x_{s},\\hat{x}_{0},s)=(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})x_{\\theta}(x_{s},\\hat{x}_{0},s).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Substituting into Eq.(38), we obtain first-order solver for DoS-SDEs ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle x_{t}=\\frac{\\alpha_{t}(1-\\eta_{t})}{\\alpha_{s}(1-\\eta_{s})}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}}x_{s}+\\alpha_{t}(1-\\eta_{t})(\\frac{\\eta_{t}}{1-\\eta_{t}}-\\frac{\\eta_{s}}{1-\\eta_{s}}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\hat{x}_{0}}}\\\\ {{\\displaystyle\\quad+\\,\\alpha_{t}(1-\\eta_{t})(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})x_{\\theta}(x_{s},\\hat{x}_{0},s)+\\alpha_{t}(1-\\eta_{t})\\sqrt{\\lambda_{t}^{2}-\\frac{\\lambda_{t}^{4}}{\\lambda_{s}^{2}}}z_{s}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "DoS-SDE Solver-2 When $k=2$ , the integral in Eq.(40) becomes ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle-\\sum_{n=0}^{1}x_{\\theta}^{(n)}(x_{s},\\hat{x}_{0},s)\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}\\frac{(\\lambda-\\lambda_{s})^{n}}{n!}d\\lambda}}\\\\ {{\\displaystyle=-\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}d\\lambda x_{\\theta}(x_{s},\\hat{x}_{0},s)-\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}(\\lambda-\\lambda_{s})d\\lambda x_{\\theta}^{(1)}(x_{s},\\hat{x}_{0},s)}}\\\\ {{\\displaystyle=(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})x_{\\theta}(x_{s},\\hat{x}_{0},s)-\\frac{(\\lambda_{t}-\\lambda_{s})^{2}}{\\lambda_{s}}x_{\\theta}^{(1)}(x_{s},\\hat{x}_{0},s)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Substituting into Eq.(40), we obtain 2-th order solver for DoS-SDEs ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{x_{t}=\\frac{\\alpha_{t}(1-\\eta_{t})}{\\alpha_{s}(1-\\eta_{s})}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}}x_{s}+\\alpha_{t}(1-\\eta_{t})(\\frac{\\eta_{t}}{1-\\eta_{t}}-\\frac{\\eta_{s}}{1-\\eta_{s}}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\hat{x}_{0}+\\alpha_{t}(1-\\eta_{t})\\sqrt{\\lambda_{t}^{2}-\\frac{\\lambda_{t}^{4}}{\\lambda_{s}^{2}}}z_{s}}}\\\\ {\\displaystyle{\\quad+\\,\\alpha_{t}(1-\\eta_{t})(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})x_{\\theta}(x_{s},\\hat{x}_{0},s)-\\alpha_{t}(1-\\eta_{t})\\frac{(\\lambda_{t}-\\lambda_{s})^{2}}{\\lambda_{s}}x_{\\theta}^{(1)}(x_{s},\\hat{x}_{0},s),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where x\u03b8 ${\\pmb x}_{\\theta}^{(1)}({\\pmb x}_{s},\\hat{\\pmb x}_{0},s)$ can be estimated by forward differential method. We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\pmb{x}_{\\theta}^{(1)}(\\pmb{x}_{s},\\hat{x}_{0},s)\\approx\\frac{\\pmb{x}_{\\theta}(\\pmb{x}_{s},\\hat{x}_{0},s)-\\pmb{x}_{\\theta}(\\pmb{x}_{r},\\hat{\\pmb{x}}_{0},r)}{\\lambda_{s}-\\lambda_{r}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where time $t<s<r$ and $\\mathbf{\\Deltax}_{\\theta}(\\mathbf{\\Deltax}_{r},\\hat{\\mathbf{x}}_{0},r)$ represents the output of the network at the previous time step. ", "page_idx": 18}, {"type": "text", "text": "DoS-SDE Solver-3 Samely, when $k=3$ , the integral in Eq.(40) becomes ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle-\\sum_{n=0}^{2}x_{\\theta}^{(n)}(x_{s},\\hat{x}_{0},s)\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{2\\lambda_{t}^{2}}{\\lambda^{3}}\\frac{(\\lambda-\\lambda_{s})^{n}}{n!}d\\lambda}\\\\ {\\displaystyle=(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{3}})x_{\\theta}(x_{s},\\hat{x}_{0},s)-\\frac{(\\lambda_{t}-\\lambda_{s})^{2}}{\\lambda_{s}}x_{\\theta}^{(1)}(x_{s},\\hat{x}_{0},s)-\\int_{\\lambda_{s}}^{\\lambda_{t}}\\frac{\\lambda_{t}^{2}}{\\lambda^{3}}(\\lambda-\\lambda_{s})^{2}d\\lambda x_{\\theta}^{(2)}(x_{s},\\hat{x}_{0},s)}\\\\ {\\displaystyle=(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})x_{\\theta}(x_{s},\\hat{x}_{0},s)-\\frac{(\\lambda_{t}-\\lambda_{s})^{2}}{\\lambda_{s}}x_{\\theta}^{(1)}(x_{s},\\hat{x}_{0},s)}\\\\ {\\displaystyle+\\left[\\frac{(\\lambda_{s}-3\\lambda_{t})(\\lambda_{s}-\\lambda_{t})}{2}-\\lambda_{t}^{2}l n(\\frac{\\lambda_{t}}{\\lambda_{s}})\\right]x_{\\theta}^{(2)}(x_{s},\\hat{x}_{0},s)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Substituting into Eq.(40), we obtain 3-th order solver for DoS-SDEs ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle x_{t}=\\frac{\\alpha_{t}(1-\\eta_{t})}{\\alpha_{s}(1-\\eta_{s})}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}}x_{s}+\\alpha_{t}(1-\\eta_{t})(\\frac{\\eta_{t}}{1-\\eta_{t}}-\\frac{\\eta_{s}}{1-\\eta_{s}}\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})\\hat{x}_{0}+\\alpha_{t}(1-\\eta_{t})\\sqrt{\\lambda_{t}^{2}-\\frac{\\lambda_{t}^{4}}{\\lambda_{s}^{2}}z_{s}}}}\\\\ {{\\displaystyle\\quad+\\,\\alpha_{t}(1-\\eta_{t})(1-\\frac{\\lambda_{t}^{2}}{\\lambda_{s}^{2}})x_{\\theta}(x_{s},\\hat{x}_{0},s)-\\alpha_{t}(1-\\eta_{t})\\frac{\\big(\\lambda_{t}-\\lambda_{s}\\big)^{2}}{\\lambda_{s}}x_{\\theta}^{(1)}(x_{s},\\hat{x}_{0},s)}}\\\\ {{\\displaystyle\\quad+\\,\\alpha_{t}(1-\\eta_{t})\\Big[\\frac{\\big(\\lambda_{s}-3\\lambda_{t}\\big)\\big(\\lambda_{s}-\\lambda_{t}\\big)}{2}-\\lambda_{t}^{2}l n\\big(\\frac{\\lambda_{t}}{\\lambda_{s}}\\big)\\Big]x_{\\theta}^{(2)}(x_{s},\\hat{x}_{0},s)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where ${\\pmb x}_{\\theta}^{(1)}({\\pmb x}_{s},\\hat{\\pmb x}_{0},s)$ and ${\\pmb x}_{\\theta}^{(2)}({\\pmb x}_{s},\\hat{\\pmb x}_{0},s)$ can be estimated by forward differential method. We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\pmb{x}_{\\theta}^{(1)}(\\pmb{x}_{s},\\hat{x}_{0},s)\\approx\\frac{\\pmb{x}_{\\theta}(\\pmb{x}_{s},\\hat{x}_{0},s)-\\pmb{x}_{\\theta}(\\pmb{x}_{r},\\hat{\\pmb{x}}_{0},r)}{\\lambda_{s}-\\lambda_{r}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where time $t<s<r$ and $\\mathbf{\\Deltax}_{\\theta}(\\mathbf{\\Deltax}_{r},\\hat{\\mathbf{x}}_{0},r)$ represents the output of the network at the previous time step. And ", "page_idx": 18}, {"type": "equation", "text": "$$\nx_{\\theta}^{(2)}(x_{s},\\hat{x}_{0},s)\\approx\\frac{x_{\\theta}^{(1)}(x_{s},\\hat{x}_{0},s)-x_{\\theta}^{(1)}(x_{r},\\hat{x}_{0},r)}{\\frac{\\lambda_{s}-\\lambda_{q}}{2}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where time $t\\;<\\;s\\;<\\;r\\;<\\;q$ and ${\\pmb x}_{\\theta}^{(1)}({\\pmb x}_{s},\\hat{\\pmb x}_{0},s)$ and ${\\pmb x}_{\\theta}^{(1)}({\\pmb x}_{r},\\hat{\\pmb x}_{0},r)$ respectively represent the approximations of the first-order derivatives at the current and previous steps. ", "page_idx": 18}, {"type": "text", "text": "Detailed algorithms for our solvers are proposed in Sec. B ", "page_idx": 18}, {"type": "text", "text": "A.7 Comparative Analysis of DoSSR and ResShift ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Previous work has introduced a method called ResShift [53], which shortens the length of the Markov chain in the diffusion process through residual shifting to achieve efficient super-resolution in diffusion models. In this section, we theoretically elaborate on the similarities and differences between our method and ResShift. ", "page_idx": 18}, {"type": "text", "text": "ResShift expresses the forward diffusion process in the form of residual shifting, as shown in the following equation: ", "page_idx": 19}, {"type": "equation", "text": "$$\nq(\\pmb{x}_{t}|\\pmb{x}_{0},\\pmb{y}_{0})=N(\\pmb{x}_{t};\\pmb{x}_{0}+\\eta_{t}\\pmb{e}_{0},\\pmb{k}^{2}\\eta_{t}\\pmb{I}),\\;t=1,2,\\cdots,T,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where ${\\pmb e}_{0}={\\pmb y}_{0}-{\\pmb x}_{0}$ respensents the residual between the LR image $\\pmb{y}_{0}$ and the HR image $\\pmb{x}_{0}$ . Hence, it can be rewrite as, ", "page_idx": 19}, {"type": "equation", "text": "$$\nq(\\pmb{x}_{t}|\\pmb{x}_{0},\\pmb{y}_{0})=\\mathcal{N}(\\pmb{x}_{t};\\eta_{t}\\pmb{y}_{0}+(1-\\eta_{t})\\pmb{x}_{0},\\pmb{k}^{2}\\eta_{t}\\pmb{I}),\\;t=1,2,\\cdots\\,,T.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, essentially, the ResShift concept also represents a linear combination of the source domain and the target domain. However, the crucial factor lies in our design of the diffusion equation, which determines whether we can effectively utilize the diffusion prior. This is our most significant differentiating point. Currently, the mainstream approach to leveraging diffusion prior involves fine-tuning large-scale pretrained diffusion models to achieve SR. As we all know, Stable Diffusion, a typical representative of large-scale diffusion models, employs the diffusion equation of DDPM [16]. Its forward process can be expressed as: ", "page_idx": 19}, {"type": "equation", "text": "$$\nq(\\pmb{x}_{t}|\\pmb{x}_{0})=\\mathcal{N}(\\pmb{x}_{t};\\alpha_{t}\\pmb{x}_{0},\\sigma_{t}^{2}\\pmb{I}),\\;t=1,2,\\cdots\\,,T,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\alpha_{t},\\sigma_{t}\\geq0$ and $\\alpha_{t}^{2}+\\sigma_{t}^{2}=1$ , referred to as noise schedule. If we consider $\\eta_{t}\\pmb{y}_{0}+(1-\\eta_{t})\\pmb{x}_{0}$ as a whole, we can intuitively observe that Eq. (51) lacks a decay coefficient $\\alpha_{t}$ compared to Eq. (52). Therefore, applying Eq. (51) to fine-tune a pretrained Stable Diffusion model poses significant challenges. The equation proposed by our DoSSR is restated as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{q(\\pmb{x}_{t}|\\pmb{x}_{0},\\hat{\\pmb{x}}_{0})=\\mathcal{N}(\\pmb{x}_{t};\\alpha_{t}(\\eta_{t}\\hat{\\pmb{x}}_{0}+(1-\\eta_{t})\\pmb{x}_{0}),\\sigma_{t}^{2}\\pmb{I}),\\;t=1,2,\\cdots\\,,T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Our diffusion equation incorporates the noise schedule of Stable Diffusion, enabling seamless compatibility with existing DDPM-type diffusion models. Therefore, in this sense, our method is specifically designed as a diffusion equation tailored to adapt to Stable Diffusion. ", "page_idx": 19}, {"type": "text", "text": "In fact, Eq. (51) and Eq. (52) (or Eq. (53)) belong to two different types of diffusion models, which correspond to the discretizations of two types of SDEs(VE SDE and VP SDE) [40], respectively. ", "page_idx": 19}, {"type": "text", "text": "The diffusion equation that satisfies the discretizations of VE SDEs typically takes the following form: ", "page_idx": 19}, {"type": "equation", "text": "$$\nq(\\mathbf{x}_{t}|\\mathbf{x}_{0})=\\mathcal{N}(\\mathbf{x}_{t};\\mathbf{x}_{0},\\sigma_{t}^{2}I),\\;t=1,2,\\cdots\\,,T,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\sigma_{t}$ increases with $t$ , and $\\sigma_{T}$ is typically a very large number, ensuring that $q({\\pmb x}_{T})\\;=\\;$ $\\mathscr{N}(\\pmb{x}_{0};\\sigma_{T}^{2}{\\pmb{I}})\\approx\\mathscr{N}(\\pmb{0};\\sigma_{T}^{2}{\\pmb{I}})$ . Therefore, Eq. (51) can be considered as a variant of the above equation. By setting hyperparameters such that $k^{2}\\dot{\\eta_{t}}=\\sigma_{t}^{2}$ , it appears possible to fine-tune a diffusion model pretrained with Eq. (54) as the diffusion equation, thereby leveraging the diffusion prior. However, this contradicts its original intention, as the starting point of inference almost approximates Gaussian noise, retaining little of the prior information of LR. Our design of shifting sequence $\\{\\eta_{t}\\}_{t=1}^{T}$ is aimed at addressing this issue, which the ResShift lacks. ", "page_idx": 19}, {"type": "text", "text": "The second type of diffusion equation that satisfies the discretizations of VP SDEs is of the DDPM type. In Eq. (52), the noise schedule satisfies the noise schedule $0\\,\\leq\\,\\sigma_{t}\\,\\leq\\,1$ and it is typically set to $\\sigma_{T}\\approx1,\\alpha_{T}\\approx0$ to ensure that $q(\\mathbf{x}_{T})\\,=\\mathcal{N}(\\alpha_{T}\\mathbf{x}_{0};\\sigma_{T}^{2}I)\\,\\approx\\mathcal{N}(\\mathbf{0};I)$ . To my knowledge, most large-scale pretrained diffusion models, represented by Stable Diffusion, adopt the VP-type (DDPM-type) diffusion equation. Therefore, our design is highly significant. Moreover, our theory is not limited to the analysis of discrete cases but extends to more general continuous cases, expressed as SDEs. Based on this, we have developed our fast samplers for our DoSSR. These are the distinctions between our work and ResShift. ", "page_idx": 19}, {"type": "text", "text": "To further demonstrate the effect of the diffusion prior, we conducted an additional comparative experiment with ResShift, as detailed in Appendix C. ", "page_idx": 19}, {"type": "text", "text": "B Pseudocode ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Here, algorithms for first, second, and third-order solvers for DoS-SDEs are presented as follows. ", "page_idx": 20}, {"type": "text", "text": "Algorithm 1 DoSSR Solver-1. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Require: starting point $t_{1}$ , used time steps $\\{t_{i}\\}_{i=1}^{N}$ , nosie schedule $\\alpha_{t}$ and $\\sigma_{t}$ , preprocessed LR   \nimage $\\hat{\\pmb{x}}_{0}$ , data prediction model $\\pmb{x}_{\\theta}$ .   \n1: $\\mathbf{x}_{t_{1}}\\gets\\alpha_{t_{1}}\\hat{\\mathbf{x}}_{0}+\\sigma_{t_{1}}\\epsilon$ $\\triangleright$ initial value   \n3: 2: for DoSG \u2190\u03b1ti(1 \u2212\u03b7ti)(1\u2212\u03b7t\u03b7iti \u03b7ti\u22121 x\u02c6 \u25b7domain shift guidance   \n1\u2212\u03b7t \u03bb   \n4: Linear Term \u2190 \u03b1t\u03b1ti((11\u2212\u2212\u03b7\u03b7tti) ) \u03bbt2 \u03bbt2 xti\u22121   \n5: Noise Term \u2190\u03b1ti(1 \u2212\u03b7ti) 2\u03bbt x\u02c6   \n6: PAT \u2190\u03b1ti(1 \u2212\u03b7ti)(1 \u2212 \u03bb2 )x\u03b8(xti\u22121, x\u02c60, ti\u22121) \u25b7Prediction Approximation Term   \n7: xt \u2190Linear Term + DoSG + PAT + Noise Term   \n8: end for ", "page_idx": 20}, {"type": "text", "text": "9: Return: xtN ", "page_idx": 20}, {"type": "text", "text": "Algorithm 2 DoSSR Solver-2. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Require: starting point $t_{1}$ , used time steps $\\{t_{i}\\}_{i=1}^{N}$ , noise schedule $\\alpha_{t}$ and $\\sigma_{t}$ , preprocessed LR image $\\hat{\\pmb{x}}_{0}$ , data prediction model $\\pmb{x}_{\\theta}$ . ", "page_idx": 20}, {"type": "text", "text": "1: $\\mathbf{x}_{t_{1}}\\gets\\alpha_{t_{1}}\\hat{\\mathbf{x}}_{0}+\\sigma_{t_{1}}\\epsilon$   \n2: $Q\\leftarrow N o n e$ ", "page_idx": 20}, {"type": "text", "text": "3: for ", "page_idx": 20}, {"type": "equation", "text": "$\\triangleright$ $$\n\\begin{array}{r l r}&{\\quad-}&{\\cdots_{i+\\gamma\\setminus1}\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots\\cdots}\\\\ &{\\ n e a r\\ T e r m\\gets\\frac{\\alpha_{t_{i}}(1-\\eta_{i})}{\\alpha_{t_{i-1}}(1-\\eta_{t_{i-1}})\\lambda_{t_{i-1}}^{2}}\\frac{\\lambda_{t_{i}}^{2}}{\\lambda_{t_{i-1}}^{2}}x_{t_{i-1}}\\cdot}\\\\ &{\\rho i s e\\ T e r m\\gets\\alpha_{t_{i}}(1-\\eta_{t_{i}})\\sqrt{\\lambda_{t_{i}}^{2}}-\\frac{\\lambda_{t_{i}}^{2}}{\\lambda_{t_{i-1}}^{2}}\\dot{x}_{0}}\\\\ &{\\ Q=N o n e\\ t h\\mathbf{e}\\mathbf{n}}\\\\ &{\\ P{A T}\\gets\\alpha_{t_{i}}(1-\\eta_{t_{i}})(1-\\frac{\\lambda_{t_{i}}^{2}}{\\lambda_{t_{i-1}}^{2}})x_{0}(x_{t_{i-1}},\\hat{x}_{0},t_{i-1})}\\\\ &{\\mathbf{S}\\gets}&{\\mathbf{D}_{i}\\gets\\frac{\\ x_{0}(\\mathbf{x}_{t_{i-1}},\\hat{x}_{0},t_{i-1})-x_{0}(x_{t_{i-2}},\\hat{x}_{0},t_{i-2})}{t_{i-1}-t_{i}-\\lambda_{t_{i}}}\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\ddots\\hat{\\mathrm{~first~order~derivac}}}\\\\ &{\\ P{A T}\\gets\\alpha_{t_{i}}(1-\\eta_{t_{i}})(1-\\frac{\\lambda_{t_{i}}^{2}}{\\lambda_{t_{i}}^{2}})x_{0}(x_{t_{i-1}},\\hat{x}_{0},t_{i-1})-\\alpha_{t_{i}}(1-\\eta_{t_{i}})\\frac{(\\lambda_{t_{i}}-\\lambda_{t_{i-1}})^{2}}{\\lambda_{t_{i-1}}}\\mathbf{D}_{i}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "end if ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "$\\pmb{x}_{t_{i}}\\leftarrow L i n e a r\\,T e r m+D o S G+P A T+N o i$ se Term ", "page_idx": 20}, {"type": "text", "text": "14: end for ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "15: Return: xtN ", "page_idx": 20}, {"type": "text", "text": "Algorithm 3 DoSSR Solver-3. ", "page_idx": 21}, {"type": "text", "text": "Require: starting point $t_{1}$ , used time steps $\\{t_{i}\\}_{i=1}^{N}$ , noise schedule $\\alpha_{t}$ and $\\sigma_{t}$ , preprocessed LR   \nimage $\\hat{\\pmb{x}}_{0}$ , data prediction model $\\pmb{x}_{\\theta}$ .   \n1: $\\mathbf{x}_{t_{1}}\\gets\\alpha_{t_{1}}\\hat{\\mathbf{x}}_{0}+\\sigma_{t_{1}}\\epsilon$ $\\triangleright$ initial value   \n2: $Q\\leftarrow N o n e$ , $Q_{d}\\leftarrow N o n e$ $\\triangleright$ first and second order derivatives   \n43:: for $i\\gets2$ $N$   \n$\\begin{array}{r l r}&{\\mathrm{~\\qquad~\\qquad~\\qquad~\\qquad~\\qquad~}}&{\\mathrm{~i~f~}\\frac{\\eta_{i}}{1-\\eta_{i}}-\\frac{\\eta_{i-1}}{1-\\eta_{i-1}}\\frac{\\lambda_{i}^{2}}{\\lambda_{i-1}}\\hat{\\Delta}_{0}^{i}\\mathrm{~\\qquad\\qquad~\\qquad~}}&{\\mathrm{~\\b~domain~shif~guida}}\\\\ &{\\mathrm{~\\\\\\\\}}&{\\mathrm{~i}\\ensuremath{n e a r~}T e r m\\mathrm{+}\\frac{\\alpha_{i}(1-\\eta_{i})}{\\alpha_{i-1}(1-\\eta_{i-1})}\\frac{\\lambda_{i}^{2}}{\\lambda_{i-1}^{2}}\\hat{\\Delta}_{i-1}^{i}}\\\\ &{\\mathrm{~\\\\\\\\}&{\\ \\ \\ }{\\omega}^{i}s e^{T}e r m\\mathrm{+}\\alpha_{i}(1-\\eta_{i})\\sqrt{\\lambda_{t}^{2}}\\frac{\\lambda_{i-1}^{2}}{\\lambda_{i-1}^{2}}\\hat{\\Delta}_{0}^{i}}\\\\ &{\\mathrm{~\\\\\\\\}{Q}=N o n e\\mathrm{~and~}Q_{d}=N o n e\\mathrm{~the~}}\\\\ &{\\mathrm{~\\\\\\\\}{P A T+\\alpha_{t}}_{i}(1-\\eta_{t+1})(1-\\frac{\\lambda_{i}^{2}}{\\lambda_{i-1}^{2}})x_{0}(x_{t-1},\\hat{x}_{0},t_{i-1})}\\\\ &{\\mathrm{~\\\\\\\\}{\\ensuremath{k e}}\\ensuremath{\\Psi}Q\\neq\\mathrm{{\\mathcal{N}o n e\\,a n d}}Q_{d}=N o n e\\mathrm{~then}}\\\\ &{\\mathrm{~\\\\\\\\}{\\ensuremath{D_{i}}}+\\frac{\\alpha_{i}(\\alpha_{i-1},\\hat{x}_{0},t_{i-1})-\\alpha_{i}(\\alpha_{i-2},\\hat{x}_{0},t_{i-2})}{\\alpha_{i-1}-\\hat{\\alpha}_{i-2}}\\phantom{x x x x x x x x x x x}}&{\\mathrm{~\\\\\\forall~ix~torder~deriva}}\\\\ &{\\mathrm{~\\\\\\\\}{P A T+\\alpha_{t}}_{i}(1-\\eta_{i})(1-\\frac{\\lambda_{i}^{2}}{\\lambda_{i-1}^{2}})x_{0}(x_{t-1},\\hat{x}_{0},t_{i $ nce   \n5:   \n6:   \n7: i   \n8:   \n9:   \n10: tive   \n11:   \n12: else   \n13: $\\begin{array}{r l r}&{\\mathrm{:}}&{\\quad\\mathrm{~\\bf~D}_{i}\\leftarrow\\frac{x_{\\theta}(x_{t_{i-1}},\\hat{x}_{0},t_{i-1})-x_{\\theta}(x_{t_{i-2}},\\hat{x}_{0},t_{i-2})}{t_{i-1}-t_{i-2}}\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathrm{~\\bf~\\hat{p}~f i r s t~o r d e r~d e r i v a t i v e}}\\\\ &{\\mathrm{:}}&{\\quad\\mathrm{~\\bf~U}_{i}\\leftarrow\\frac{\\mathbf{D}_{i}-\\mathbf{D}_{i-1}}{\\frac{1}{2t_{i-1}}-\\lambda_{t_{i-3}}}\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\mathrm{~\\bf~\\hat{p}~s e c o n d~o r d e r~d e r i v a t i v e}}\\\\ &{\\mathrm{:}}&{\\quad\\mathrm{~\\bf~{\\cal~P}A}T\\leftarrow\\alpha_{t_{i}}(1-\\eta_{t_{i}})(1-\\frac{\\lambda_{t_{i}}^{2}}{\\lambda_{t_{i-1}}^{2}})x_{\\theta}(x_{t_{i-1}},\\hat{x}_{0},t_{i-1})-\\alpha_{t_{i}}(1-\\eta_{t_{i}})\\frac{(\\lambda_{t_{i}}-\\lambda_{t_{i-1}})^{2}}{\\lambda_{t_{i-1}}}\\mathbf{D}_{i}+}\\\\ &{\\alpha_{t_{i}}(1-\\eta_{t_{i}})\\Big[\\frac{(\\lambda_{t_{i-1}}-3\\lambda_{t_{i}})(\\lambda_{t_{i-1}}-\\lambda_{t_{i}})}{2}-\\lambda_{t_{i}}^{2}\\ln(\\frac{\\lambda_{t_{i}}}{\\lambda_{t_{i-1}}})\\Big]\\mathbf{U}_{i}}\\\\ &{\\quad}&{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad2}\\end{array}$   \n14:   \n15:   \n16: end if   \n17: $\\mathbf{r}_{t_{i}}\\gets L i n e a r\\,T e r m+D o S G+P A T+N o i s e\\,T e r m$   \n18: end for   \n19: Return: xtN ", "page_idx": 21}, {"type": "text", "text": "C Additional Experiment Results ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "C.1 Ablation on Diffusion Prior ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "To demonstrate the impact of the diffusion prior, we conduct a comparative experiment with the ResShift model [53], which does not leverage a pretrained diffusion model. Considering that ResShift is trained on ImageNet [11] while our DoSSR model is trained on commonly used datasets for super-resolution tasks (e.g., DIV2K [1]), to eliminate the influence of the training dataset, we retrain our DoSSR model using ImageNet as well. To highlight the effect of the diffusion prior, we only utilize a subset of ImageNet as our training data. This subset consists of randomly selected 10 images from each of the 1000 categories in ImageNet, totaling 10,000 images, as illustrated in Table 4. It can be observed that our DoSSR achieves superior metrics compared to ResShift despite utilizing significantly fewer training data and epochs for iteration. This indicates that leveraging the diffusion prior is highly beneficial for super-resolution tasks, even without utilizing commonly used high-resolution datasets for training, we can still achieve satisfactory results. We also perform qualitative comparisons between our retrained DoSSR and ResShift, as illustrated in Fig. 5. It is evident that the utilization of the diffusion prior significantly enhances the quality of the generated images, both in terms of fidelity and realism. ", "page_idx": 21}, {"type": "text", "text": "C.2 Compare with other formulations of diffusion process ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Aside from ResShift, we also compare our method with other plausible alternative formulations of diffusion processes, which encompass ColdDiff [3] and Rectified Flow [29]. ColdDiff is similar to DDPM, but differs by employing alternative degradation methods, such as blurring and masking, rather than additive Gaussian noise as used in DDPM. In our case for image super-resolusion, we select the blur degradation. Note that ColdDiff is originally applied in the pixel space, while we have to implement it in the latent space for fair comparison with our method. Rectified Flow defines the forward process as $\\pmb{x}_{t}=t\\hat{\\pmb{x}}_{0}+(1-t)\\pmb{x}_{0}$ where $\\hat{\\pmb{x}}_{0}$ is the data sample and $\\pmb{x}_{0}$ is Gaussian noise. In our case for image super-resolusion, we choose FlowIE [59] as an implementation of rectified flow which replaces $\\scriptstyle x_{0}$ with the LR image as the starting point. ", "page_idx": 21}, {"type": "table", "img_path": "u7okTt4ZyE/tmp/2e54d02ecae9607f482354513e2ad8a951797e740472797ec558ce8c00e86f61.jpg", "table_caption": ["Table 4: Comparison of performance between our retrained DoSSR and ResShift models on the DRealSR dataset. For fair comparison, we employ our first-order sampler for inference, running it 15 times to match ResShift\u2019s default setting. "], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "u7okTt4ZyE/tmp/5fc1e500e92fbe9a3da3566026d9d81592691a1dea2a27878127109867eeb31d.jpg", "table_caption": ["Table 5: Comparison of performance with other methods on the RealSRSet and RealSR datasets. NFE represents the number of function evaluations in the inference. \u2217involves retraining using the same training data and identical network architecture as our model. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "For a fair comparison, we reimplemented the three methods\u2014ResShift [53], ColdDiff [3], and FlowIE [59]\u2014using the same network architecture, training dataset, and initialization as our method. The results are shown in the Table 5. Results of ColdDiff is significantly worse than other methods. The main reason can be summerized as two aspects. First, applying bluring kernels to latent features is not equivalent to applying them to raw images, while ColdDiff is originally designed for the latter. Second, the blurring kernel can only be designed in a hand-craft manner and may not represent the real-world degradation, so when tested with real LR images there would be a domain gap. The limilation of hand-crafted degradation is also well-known in many previous image restoration works. In contrast, other methods, including our DoSSR, does not assume a fixed degradation, so the performance is much better. Because FlowIE emphasizes single step evaluation, we follow its setting and compare DoSSR with 1-setp evaluation with it. It can be see that FlowIE is also not satisfactory and largely underperforms our DoSSR $:-11.87\\%$ MUSIQ). This is mainly attributed to FlowIE\u2019s bad adaptation from the DDPM pretrained T2I model, since the learning objective of flow matching differs from score matching. By contrast, our design makes full use of the DDPM pretrained weights so performs much better. ResShift also significantly underperforms our method, similar to FlowIE, because its formulation does not account for adaptation from the pretrained diffusion prior, as discussed in Appendix A.7 and C.1. To summarize, our formulation differs from other alternatives especially in terms of better leverage and adaptation from DDPM pretrained T2I models. ", "page_idx": 22}, {"type": "text", "text": "C.3 Network Structure ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The network structure of our model is illustrated in Fig. 6. In general, we adopt the same model architecture as in DiffBIR [27], using LR images as conditional inputs for the ControlNet module. The ControlNet is initialized from the Stable Diffusion 2.1 Unet encoder and trained to generate HR images given LR inputs. ", "page_idx": 22}, {"type": "text", "text": "Table 6: Comparison of performance: w/o DoSG vs. different accelerated samplers on the RealSR and DRealSR datasets with same model(RealESRNet preprocessing $^+$ DiffBIR). In all setups, inference is carried out over 5 steps. ", "page_idx": 23}, {"type": "table", "img_path": "u7okTt4ZyE/tmp/8177571e802d1b2797f658d5e0d3b6ed3d26845f1ddcb0a421886a3e8369a706.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/8af4057d2156e24a211b1091b8f9e2e0c9ba430ceb32de4076eb7e38881fea80.jpg", "img_caption": ["Figure 5: Qualitative comparisons between our retrained DoSSR and ResShift. The utilization of the diffusion prior noticeably enhances the realism and visual appeal of the generated high-resolution images. Please zoom in for a better view. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/62b1422b80f9123e6c1230c0ed2d3ffa011f819fe8b76a412223a82ae4d32257.jpg", "img_caption": ["Figure 6: The overall framework of DoSSR. During training, we introduce noise to facilitate the gradual transition from the HR to LR domain, integrating it with the standard diffusion process, and incorporate preprocessed LR as a conditioning input for the denoising process, following the ControlNet approach. During inference, we add noise to LR latent according to Eq. (2) and perform inference starting from $t_{1}$ . "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/ab365fb24faaaef2786934be1b0c8ffe65cb96cd654f7b5289c1dcf8361cd96a.jpg", "img_caption": ["Figure 7: Qualitative comparisons of different steps of our DoSSR and other diffusion-based SR methods. The suffix \"-N\" appended to the method name indicates the number of inference steps. Please zoom in for a better view. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/e795b44f7745d179706e7474dd38e89b22bd4eae8d80323f230990880b81ca86.jpg", "img_caption": ["Figure 8: Visualizing the impact of random seed on diffusion-based methods. The \"-N\" suffix denotes inference steps. Please zoom in for a better view. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/b918bf53b0e3220bf20b1272a37105ac56b509d0a037df3abb4f03898556c328.jpg", "img_caption": ["Figure 9: Qualitative comparisons of different inference steps of our DoSSR. The \"-N\" suffix denotes inference steps. Please zoom in for a better view. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "u7okTt4ZyE/tmp/587d0022f1fe17f5183a7b802f3ec14f2c08056d1b6d0e0f11194bf2304f3dae.jpg", "img_caption": ["Figure 10: Qualitative comparisons of different sampler orders of our DoSSR. Please zoom in for a better view. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The abstract provides a concise summary of the main findings and contributions of the paper, while the introduction elaborates on the problem statement and research objectives, thereby clarifying the contributions. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: In Appendix 5, we expound upon the limitations of the work conducted and provide a brief discussion thereof. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: In Appendix A, we provide detailed mathematical derivations for all the formulas appearing in the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: In Section 4.1, we introduced the details of experimental setup and model training to ensure reproducibility. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 27}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [No] ", "page_idx": 28}, {"type": "text", "text": "Justification: The code will be released once the submission is accepted. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: In Section 4.1, we introduced the details of experimental setup and model training, and conducted ablation experiments in Section 4.3 to elucidate the selection of hyperparameters. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The experiments conducted in our paper do not involve the use of error bars or statistical significance analysis, thus this aspect is not applicable to our study. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: For the latency testing experiments, we furnished detailed specifications of the GPU models used along with their corresponding tasks. Furthermore, we included specific information regarding the model training batch size and the number of training epochs. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: We have carefully reviewed the NeurIPS Code of Ethics and adhere to its principles. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We discuss both potential positive societal impacts and negative societal impacts of the work performed in Appendix. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Our paper poses no such risks. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The creators or original owners of assets, such as code, data, or models, used in the paper, are properly credited. Additionally, the license and terms of use associated with these assets are explicitly mentioned and respected in accordance with ethical and legal standards. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our paper does not release new assets. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 32}]