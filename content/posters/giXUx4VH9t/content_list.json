[{"type": "text", "text": "Test-Time Adaptation Induces Stronger Accuracy and Agreement-on-the-Line ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Eungyeup Kim1 Mingjie Sun1 Christina Baek1 Aditi Raghunathan1 J. Zico Kolter1,2 1Carnegie Mellon University 2Bosch Center for AI {eungyeuk, mingjies, kbaek, raditi, zkolter}@cs.cmu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recently, Miller et al. [32] and Baek et al. [3] empirically demonstrated strong linear correlations between in-distribution (ID) versus out-of-distribution (OOD) accuracy and agreement. These trends, coined accuracy-on-the-line (ACL) and agreement-on-the-line (AGL), enables OOD model selection and performance estimation without labeled data. However, these phenomena also break for certain shifts, such as CIFAR10-C Gaussian Noise, posing a critical bottleneck. In this paper, we make a key finding that recent test-time adaptation (TTA) methods not only improve OOD performance, but drastically strengthens the ACL and AGL trends in models, even in shifts where models showed very weak correlations before. To analyze this, we revisit the theoretical conditions established by Miller et al. [32], which demonstrate that ACL appears if the distributions only shift in mean and covariance scale in Gaussian data. We find that these theoretical conditions hold when deep networks are adapted to OOD, e.g., CIFAR10-C \u2014 models embed the initial data distribution, with complex shifts, into those only with a singular \u201cscaling\u201d variable in the feature space. Building on these stronger linear trends, we demonstrate that combining TTA and AGL-based methods can predict the OOD performance with high precision for a broader set of distribution shifts. Furthermore, we can leverage ACL and AGL to perform hyperparameter search and select the best adaptation strategy without any OOD labeled data. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Neural networks often fail to generalize to out-of-distribution (OOD) data that differs from the indistribution (ID) data seen at train-time [1, 11, 41]. Thus, characterizing the behaviors of these models under distribution shift becomes crucial for reliable deployment. However, it is often extremely challenging to reliably estimate their performances because in many practical applications, OOD labeled data is scarce. Interestingly, recent studies [32, 3] have found a set of simple empirical laws that describe the behavior of models across many distribution shift benchmarks. In particular, across numerous distribution shift benchmarks, the models\u2019 ID versus OOD accuracies, under probit scaling, tend to observe a strong linear correlation across numerous distribution shift benchmarks. Additionally, when accuracy is strongly correlated, the ID and OOD agreement rates between pairs of these models are also strongly correlated with nearly identical slopes and biases. These phenomena, respectively referred to as \u201caccuracy-on-the-line\u201d (ACL) [32] and \u201cagreement-on-the-line\u201d (AGL) [3], can be leveraged for precise OOD accuracy estimation without access to OOD labels: one could estimate the slope and bias of the ID vs OOD accuracy trend using agreement rates, then linearly transform ID accuracy using this approximate linear fit. 1. ", "page_idx": 0}, {"type": "image", "img_path": "giXUx4VH9t/tmp/2278e6c68c145ac476e531376e713a5cd0234800adddf6179279615f65087e5f.jpg", "img_caption": ["(c) Camelyon17 vs. Camelyon17-OOD ", "(d) iWildCAM vs. iWildCAM-OOD "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: Linear trends in both accuracy and agreement hold to a substantially stronger degree after applying adaptation methods than before. Each blue and pink dot denotes the accuracy and agreement, followed by the linear fits for each, and $R^{2}$ is correlation coefficient. ", "page_idx": 1}, {"type": "text", "text": "However, studies [32, 3, 56, 48] have demonstrated that for distribution shifts benchmarks where the linear trends breaks down catastrophically. As shown in Fig. 1, such as CIFAR10-C Gaussian Noise [14] or Camelyon17-WILDS [41], trained models (i.e., Vanilla) with around $92-95\\%$ ID accuracy can have OOD accuracies that vary between $10-50\\%$ , so ID accuracy alone becomes extremely unreliable for understanding the OOD performance of models. Similarly, the correlation strength of ID and OOD agreement rates also weakens. Ideally, we would like to intervene in models in a way that improves these linear correlations, such that we can reliably predict their performance under distribution shift. While theoretical works [32, 31, 51, 25] provide insights for when these linear trends hold, there is little study on how to strengthen these trends in models. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we empirically demonstrate that recent OOD test-time adaptation (TTA) strategies [44, 27, 46, 53, 9, 35, 55, 36] not only improve OOD performance, but significantly restore the strong linear trends for a broad range of distribution shifts where ACL and AGL are not initially observable. For instance, in Fig. 1, the correlation coefficient $(R^{2})$ of ID versus OOD agreement and accuracy of Vanilla models is 0.18 and 0.39, respectively, and both of these values improve to 1.0 after applying TENT [53]. We observe such stronger linear trends after TTA throughout our extensive testbed consisting of 9 shifts, 7 adaptation methods, and over 40 network architectures. As test-time adapted models have OOD accuracies that degrade more predictably with respect to the ID accuracy, we are also able to utilize AGL based method ALine [3] to obtain precise OOD performance estimates without any OOD labels. Note that no OOD labels were utilized throughout this procedure, neither during TTA or ALine. Our estimates of the models\u2019 OOD performances are drastically more precise after adaptation, e.g., estimation error of $11.99\\%$ in Vanilla vs. $2.34\\%$ after applying TENT on CIFAR10-C Gaussian Noise. ", "page_idx": 1}, {"type": "text", "text": "Given that TTAs are designed to enhance OOD accuracy, the observation of such strong linear trends is unexpected and non-trivial. While some studies [29, 9] have explored how adaptations lead to improved OOD generalization, these efforts are orthogonal to those investigating the conditions under which linear trends occur [32, 31]. To our knowledge, no studies have attempted to bridge these two areas of research. This naturally raises the question: Why does adapting models at test-time to OOD data lead to stronger linear trends? ", "page_idx": 1}, {"type": "text", "text": "To answer this, we revisit the theoretical analysis in Miller et al. [32] of the sufficient conditions for observing highly correlated ID vs OOD accuracy in linear classifiers and Gaussian data. Theoretically, ACL holds exactly under distribution shifts where the direction of the class means and shape of the class covariances are fixed, and only the scale of the mean or covariance changes. Surprisingly, we find that TTA, in practice, seems to enforce exactly this condition: after applying TTA, the cosine similarity between the means and covariances of the penultimate-layer feature embedding of ID and OOD data tend to hover around 1, while their magnitude may change by some scaling constant. This implies that adaptations effectively collapse the complexity of the distribution shift to a singular \u201cscaling\u201d variable in the feature space. In addition to (empirically) justifying the use of TTA for strengthening $\\mathrm{ACL}^{2}$ , this discovery casts some insight into the nature of TTA in general, which has previously been a largely heuristic approach. ", "page_idx": 2}, {"type": "text", "text": "Furthermore, models adapted with different TTA hyperparameters tend to lie on the same linear trend. Fig. 2 illustrates the strong correlation among models first trained on ID data over different architectures and different early-stopping thresholds, then adapted with varying learning rates, batch sizes, adaptation steps. This critically allows us to tune the TTA hyperparameters and choice of TTA method without a held-out OOD labeled set, which is a long-standing challenging unsolved by existing TTA studies [21, 60, 9]. Using ACL and AGL, we are able to select models with accuracy less than $1\\%$ away from that of the best model OOD. This also allows to select the best TTA methods by comparing their estimated best OOD performances. ", "page_idx": 2}, {"type": "text", "text": "To summarize our contributions: ", "page_idx": 2}, {"type": "text", "text": "\u2022 We observe after TTA leads, ACL and AGL hold across a wider set of distribution shifts and hyperparameter settings.   \n\u2022 We explain our observation by showing TTA collapses the distribution shift to just a constant scaling of the mean and covariance matrices in the feature space. This satisfies the theoretical conditions studied previously for observing strong linear trends.   \n\u2022 Our findings provide a simple and effective strategy for finding the best TTA hyperparameters and the best TTA strategy without any OOD labels. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Understanding accuracy and agreement-on-the-line. Miller et al. [32] and Baek et al. [3] empirically observed a coupled phenomena in deep models evaluated on a wide variety of standard distribution shift benchmarks: the ID vs. OOD accuracy and agreement are often strongly correlated and the linear fits match almost exactly. Recent studies [32, 31, 51, 25, 24] attempt to build specific characterization of the shifts that lead to (or break) this phenomena. Miller et al. [32] theoretically explained that under a simple Gaussian data setup, ACL does not hold perfectly under distribution shifts that change the direction of the mean or transforms the covariance matrix. For example, they demonstrate that adding isotropic Gaussian noise to CIFAR10, which does not have an isotropic covariance matrix, causes the linear trend to break. Theoretical works have also tried to characterize when ACL holds more broadly. Mania and Sra [31] provided sufficient conditions directly over the outputs of trained models, in terms of their prediction similarity and distributional closeness. Tripuraneni et al. [51] and LeJeune et al. [25] show that ACL holds asymptotically under certain transformations to the covariance matrix. On the other hand, there has been comparatively little theoretical analysis of AGL and why it appears together with ACL. Lee et al. [24] show that in random feature linear regression, AGL can break break partially, i.e., the slope of the agreement trend matches accuracy\u2019s, but the biases may be different. While further theoretical conditions are necessary to guarantee when these phenomena hold jointly, in our empirical findings, we see that the slopes and biases do always match across the wide variety of distribution shifts we test. ", "page_idx": 2}, {"type": "text", "text": "Extending upon such studies that analyze when ACL and AGL may hold (or break) naturally, we demonstrate that a simple model intervention by test-time adaption allows these ID versus OOD trends to hold even stronger for a more expansive set of distribution shifts. In fact, we demonstrate that after adaptation, models actually satisfy the theoretical conditions necessary for ACL as described in Miller et al. [32]. ", "page_idx": 2}, {"type": "image", "img_path": "giXUx4VH9t/tmp/17522c6321b2744634eac40fed143f5036bfcb5a5f5d02593c5694262c7fb5c4.jpg", "img_caption": ["Figure 2: Strong AGL by adaptations with varying hyperparameters, including learning rates, adaptation steps, batch sizes, and (early-stopped) checkpoints of the ID-trained model. Each blue and pink dot denotes the accuracy and agreement, followed by the linear fits for each. ", "(c) TENT tested on Camelyon17 vs. Camelyon17-OOD "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Adaptations under distribution shifts and their pitfalls of reliability. Test-time adaptation aims to enhance model robustness by adapting models to unlabeled OOD test data. Test-time training methods [46, 29, 7] involve learning shift-invariant features via solving self-supervision tasks. Other approaches include computing statistics in Batch Normalization (BN) layers using OOD data [20, 44], instead of using ID statistics stored during training. Subsequent studies further adapt BN parameters by updating them using entropy minimization [53, 35, 36]. Another popular approach is self-training with pseudo-labels [40, 54, 9]. ", "page_idx": 3}, {"type": "text", "text": "One critical challenge in TTA is that, without OOD labels, it is prohibitively difficult to evaluate how effective the adaptation methods might be. As pointed out in previous studies, adaptation methods may not succeed to address the full spectrum of distribution shifts, such as datasets reproductions [29, 60], domain generalization benchmarks [21, 61], and WILDS [40]. Furthermore, these approaches are known to be critically sensitive to different hyperparameter choices [4, 61, 36, 23]. Practitioners must take a great care in optimizing such hyperparameters, but their tuning procedures lack clarity. They often follow the settings of the previous studies [35, 36], or rely on some held-out labeled data [21, 60, 9] that is unavailable in practice. There exists a line of studies on unsupervised model validation [33, 42, 34, 52, 17]. Our study leverages agreement-on-the-line phenomena within TTA to offer a promising solution for these reliability issues. ", "page_idx": 3}, {"type": "text", "text": "3 Adaptations lead to stronger Agreement-on-the-Line ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "3.1 Experimental setup ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Datasets and models. Our testbed includes diverse shifts, including common corruptions (15 failure shifts in CIFAR10-C, CIFAR100-C, and ImageNet-C [14]), dataset reproductions (CIFAR10.1 [38], ImageNetV2 [39]), and real-world shifts (ImageNet-R [16], Camelyon17-WILDS, iWildCAMWILDS, FMoW-WILDS [41]). Among them, CIFAR10-C Gaussian Noise, Camelyon17-WILDS, and iWildCAM-WILDS display the weakest correlations in accuracy and agreement [32, 3, 56]. We test over 30 different architectures of convolutional neural networks (e.g., VGG [45], ResNet [13, 57, 59], DenseNet [19], MobileNet [43]) and Vision-Transformers (ViTs [5], DeiT [49], SwinT [30]). ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "TTA methods. We investigate 7 recent state-of-the-art TTA methods, including SHOT [27], BN_Adapt [44], TTT [46], TENT [53], ConjPL [9], ETA [35], and SAR [36]. This testbed includes different \u201cpretraining\u201d (e.g., self-supervision [46], PolyLoss [26]), updating certain layer parameters (BN layers [44, 53, 35], LayerNorm (LN) layers [2, 36], entire feature extractors [27]). We test all adaptation baselines, except SAR, on convolutional neural networks with BN layers. We apply SAR specifically to vision transformers [5, 49, 30] because it prevents the model collapse that other adaptation methods exhibit in vision transformers with LN layers [36]. ", "page_idx": 4}, {"type": "text", "text": "Calculating agreement. Given any pair of models $(h,h^{\\prime})\\in\\mathcal{H}$ that are tested on distribution $\\mathcal{D}$ , the expected accuracy and agreement of the models is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Accuracy}(h)=\\mathbb{E}_{x,y\\sim\\mathcal{D}}\\big[\\mathbb{1}\\{h(x)=y\\}\\big],\\quad\\mathrm{Agreement}(h,h^{\\prime})=\\mathbb{E}_{x,y\\sim\\mathcal{D}}\\big[\\mathbb{1}\\{h(x)=h^{\\prime}(x)\\}\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $h(x)$ and $h^{\\prime}(x)$ are the normalized logits of models $h$ and $h^{\\prime}$ given datapoint $x$ and $y$ is the class label. Following [32] and [3], we apply probit scaling, which is the inverse of the cumulative density function of the standard Gaussian distribution $(\\Phi^{-1^{-}}\\colon[0,1]\\to[-\\infty,\\infty])$ , over accuracy and agreement for a better linear fit, specifically in Figs. 1 and 2. ", "page_idx": 4}, {"type": "text", "text": "Online test in ID and OOD during TTA. Unlike conventional offline inference at test-time, TTAs involve online learning, which dynamically updates the model\u2019s parameters while testing on OOD data. To evaluate this continuously updated model on both ID and OOD data, the data is fed into the model in minibatches and we average over the accuracy and agreement of the model over the $\\ddot{\\iota}$ th minibatch after the dynamic adaptation step $i$ . Details are provided in Algorithm 1 in the Appendix. ", "page_idx": 4}, {"type": "text", "text": "3.2 Main observation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We empirically observe that after adaptation, models show stronger linear trends in their ID versus OOD accuracy and agreements, even in distribution shifts where Vanilla models show wildly varying trends. In Fig. 1, we demonstrate this on the four distribution shifts with weakest ACL and AGL trends in Vanilla models. These include CIFAR10-C Gaussian Noise, ImageNet-C Shot Noise, Camelon17- WILDS, and iWildCAM-WILDS, which all have $R^{2}$ values in their accuracy and agreement lower than 0.4 before TTA. These failure shifts have also been identified by previous studies [32, 3, 56]. Surprisingly, after applying several adaptation methods, such as TENT, the strength of these linear trends increase dramatically, (e.g., $0.15\\,\\rightarrow\\,0.97$ and $0.33\\to0.97$ in agreement and accuracy, in Camelyon17-WILDS). Our observations hold consistently across our entire testbed of shifts and adaptation methods, as shown in Figures 6, 7, 9, 10, 11, and 12. Moreover, in shifts where Vanilla models already exhibit strong linear trends, such as ImageNet-V2 or FMoW-WILDS, these linear trends interestingly persist even after TTA including when TTA degrades OOD accuracy instead of improving (Fig. 4). ", "page_idx": 4}, {"type": "text", "text": "Furthermore, we find that for each TTA method, models adapted with different adaptation hyperparameters follow the same linear trend in both accuracy and agreement. Specifically, we test learning rates, adaption steps, batch sizes, and the early-stopped epoch for pretraining. In Fig. 2 we see that on CIFAR10-C and ImageNet-C Gaussian Noise, and Camelyon17-WILDS, models adapted with different hyperparameters exhibit correlation strength $R^{2}$ close to 1 in both ID versus OOD accuracy and agreement. We also show that this occurs across other distribution shifts in Figs. 8 and 13. ", "page_idx": 4}, {"type": "text", "text": "4 Why does adaptations lead to strong linear trends? ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we focus on explaining why TTA leads to restoration of these strong linear trends. Although we do not provide a full theoretical justification, we do identify a key pattern in how TTA modifies models that provides a strong clue as to why these methods substantially strengthen the ACL phenomenon in particular. ", "page_idx": 4}, {"type": "text", "text": "We begin by revisiting the theoretically sufficient conditions for ACL from Miller et al. [32] over a simple Gaussian data and linear classifier setup. They showed that ACL holds perfectly only when distribution shifts by a simple scaling factor to the norm of the mean and covariance. On the other hand, if the actual direction of the mean or shape of the covariance matrix changes, the linearity breaks. We then demonstrate that even in CIFAR10 shifts and non-linear neural networks, adaptation causes models to meet these theoretical conditions better in the penultimate-layer feature space, thus leading to stronger linear trends. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "4.1 Theoretical conditions for linear trends in Gaussian data ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We introduce the theoretical conditions for having ACL in Gaussian data setup, from Miller et al. [32], restated briefly here for ease of presentation. Consider the binary classification over Gaussian data setup with label $y\\in\\{-1,1\\}$ . The OOD distribution $Q$ differs from the ID distribution $P$ by just some scaling constants $\\alpha,\\gamma>0$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n{\\cal P}(x\\mid y)=\\mathcal{N}(y\\cdot\\mu;\\Sigma),\\quad{\\cal Q}(x\\mid y)=\\mathcal{N}\\left(y\\cdot\\alpha\\mu;\\gamma^{2}\\Sigma\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Theorem 1 (Miller et al. [32], simplified) Under the Gaussian data setup in Equation 2, for linear classifiers $f_{\\theta}:x\\mapsto\\mathrm{sign}(\\theta^{\\top}x),$ , the probit-scaled accuracies over $P$ and $Q$ observes perfect linear correlation with a bias of zero and a slope of $\\frac{\\alpha}{\\gamma}$ . ", "page_idx": 5}, {"type": "text", "text": "The proof follows immediat\u221aely from the fact that the accuracy of a linear classifier on this Gaussian data $P$ is given by $\\Phi({\\theta}^{\\top}{\\mu}/{\\sqrt{\\theta^{\\top}{\\Sigma}\\theta}}))$ ; applying same result to $Q$ immediately gives the desired linear relationship. The main implication is that if the data distribution where the linear classifiers are applied have the shifts that have the same mean directions and covariance shapes, ACL is guaranteed across linear classifiers. ", "page_idx": 5}, {"type": "text", "text": "4.2 Empirical analysis under adaptation to CIFAR10-C ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We now investigate how well the above conditions that are required for the linear trends are met before and after TTA, for real-world data with deep models. Here, we consider CIFAR10-C Gaussian Noise and and models pretrained on CIFAR10 then adapted using BN_Adapt [44] or TENT [53] at test-time. Since we are interested in distributions where the linear classifiers are applied onto, we take the class-wise feature embeddings from the penultimate-layer of these models. Then we analyze how these features are distributed by measuring their mean and covariance alignment, using cosine similarity of their normalized ones. We evaluate such alignment across architectures as well as adaptation hyperparameters such as learning rates, batch sizes, and early-stopped checkpoints, which are the same setups we used in Figs 1 and 2 CIFAR10-C Gaussian Noise results. ", "page_idx": 5}, {"type": "text", "text": "Shifts become aligned in their mean and covariance after adaptation. Table 1 shows the mean and standard deviation of the cosine similarity measured across different setups. We first notice that, without adaptation (Vanilla), both mean and covariance of CIFAR10 and CIFAR10-C Gaussian Noise features have less than 1 cosine similarity, showing their are misaligned. Surprisingly, after applying adaptations, the similarity substantially increases and becomes very close to 1, across every architecture we test (with standard deviation close to 0). This means that ID and OOD, in feature space, have (roughly) the same means and covariances in their shapes, after adaptations. This implies that adapted models empirically seem to represent the shift in distributions largely as a shift in the scale of the features alone. Considering that CIFAR10-C Gaussian Noise is created with additive isotropic Gaussian Noise to CIFAR10, which is a non-isotropic covariance shift, this represents a non-trivial ability of TTA to \u201csimplify\u201d the nature of complex drifts within the features. This observations, in turn, approximately satisfies the conditions above and thus at least gives a partial insight into why we observe the strong linear trends such a setting after adaptations. ", "page_idx": 5}, {"type": "text", "text": "In addition, we have the similar results when testing with varying hyperparameters, as shown in Table 1. We apply TENT with different learning rates, batch sizes, and checkpoints, and they consistently show the similarity close to 1, similar to architectures. This shows that adapting with different hyperparameter setups does not affect the alignments between shifts, maintaining such simplicity. This explains why we also observe the strong linear trends across different hyperparameters. ", "page_idx": 5}, {"type": "text", "text": "Theoretical slope for linear trends matches the empirical slope. Finally, the simple theoretical setting suggests not only that there is a linear correlation where distribution shifts involved only a scaling of mean and covariance, but also specifies the actual slope as $\\frac{\\alpha}{\\gamma}$ . We thus investigate whether this slope matches that produced empirically, when applying the same class of different adaptations as highlighted above. Table 1 shows the slopes predicted by the simple Gaussian setting, along with the slopes estimated via the empirical mean and variance scaling. These are generally in strong agreement, highlighting that the empirical results of TTA seem to provide a great deal of intuition about why how the ACL phenomenon holds in practice. ", "page_idx": 5}, {"type": "table", "img_path": "giXUx4VH9t/tmp/db3d90c5e9119bb735153ee8c093b17eba61dde60e7f367b45230d7447120b5e.jpg", "table_caption": [], "table_footnote": ["Table 1: Cosine similarity between mean direction and covariance shape of class-wise penultimatelayer features, followed by the comparison between theoretical and empirical slope. They are evaluated on CIFAR10 vs. CIFAR10-C Gaussian Noise, measured across architectures and hyperparameters. We report their means and standard deviations. "], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Finally, we note that while these observations help explain ACL in adaptations, they do not apply to AGL, as AGL involves more than one linear classifier for calculating the agreement, and there is no similar closed-form estimate of the agreement even for Gaussian data. Still, we find that AGL is tightly coupled with ACL in an extensive range of benchmarking shifts and adaptations we examine on, similar to Baek et al. [3]. ", "page_idx": 6}, {"type": "text", "text": "TTA aligns shifts that cause linear trends, correlating with improved OOD generalization. One might interpret the observed linear trends as evidence that TTA improves OOD generalizations by reducing the performance gap between ID and OOD, thereby bringing it closer to the $y=x$ and showing a strong linear trend. However, our analysis clarifies that shift alignments by TTA is the true causal factor for stronger linear trends, and the closer gap between ID and OOD is correlated. While TTA satisfies the condition for ACL by aligning the direction/shape of the ID/OOD mean and covariance, the scaling factor might still be far off, i.e., $\\alpha\\ll1$ , $\\gamma\\gg1$ . This results in a near-perfect linear trend that, nonetheless, can lie arbitrarily far from the $y=x$ which represents perfect robustness. One empirical evidence is ImageNet-C Shot Noise in Fig. 1, where there is still approximately a $40\\%$ gap in ID and OOD accuracy, but strong ACL holds. In addition, we could think of imaginary TTA which improves OOD performance by reducing scales shifts in covariance in the feature space, but the shape of the covariance matrices remain misaligned. This can be synthetically simulated over toy Gaussian data, where the cosine similarity between the shape of ID and OOD covariance matrices remain less than 1, and $\\gamma^{2}$ decreases after TTA. Then the linear trend moves closer to $y=x$ , but the strength of the linear trend remains weak. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Our observations, stronger linear trends after adaptations, provide substantial improvements, particularly in the context of adaptation, in two key practical applications: (i) accuracy prediction of the OOD accuracy, and (ii) unsupervised validation for TTA \u2014 without access to OOD labels. ", "page_idx": 6}, {"type": "text", "text": "5.1 OOD Accuracy estimation after adaptation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Experimental Setup. We employ AGL-based estimation method, namely ALine [3]. This method first estimates the linear fit of the accuracy, i.e. slope and bias, via agreements (which requires no labels), and linearly transforms the ID accuracy with them for estimating OOD accuracy. The detail of ALine is illustrated in Algorithm 2 in Appendix. We apply this to models adapted with TTA methods, and compare these results with (i) those of ALine applied to models before adaptation, and (ii) estimates using existing estimation baselines. These baselines include average thresholded confidence (ATC) [8], difference of confidence (DOC)-feat [10], average confidence [15], and agreement [22]. We evaluate them on widely used benchmarking distribution shifts in TTA literature, CIFAR10-C, CIFAR100-C, ImageNet-C [14], and Camelyon17-WILDS and iWildCAM-WILDS [41]. ", "page_idx": 6}, {"type": "text", "text": "Results. ALine shows accurate estimation under shifts that have strong AGL (e.g., in CIFAR10-C snow, mean absolute error (MAE) of estimation is $0.93\\%$ in ALine-D), but it shows critical failure when shifts do not have such linear trends (e.g., in CIFAR10-C Gaussian Noise, MAE is $10.76\\%$ and in Camelyon17-WILDS, MAE is $12.88\\%$ ). As a result, as shown in Table 2, applying ALine-S/D on Vanilla models outperforms other estimators with marginal gap, or sometimes shows higher errors. After applying adaptation methods, such as SHOT, BN_Adapt, and TENT, the estimation performance of ALine-S/D improves, showing substantially lower MAE compared to that of vanilla models across shifts (e.g., MAE decreases $10.\\bar{7}6\\%\\rightarrow2.34\\%$ in CIFAR10-C Gaussian Noise and $12.88\\%\\rightarrow1.42\\%$ in Camelyon17-WILDS). It also outperforms the estimating baselines when applied to adapted models. Notably, baseline estimators also show improved estimation performance on adapted models compared to vanilla, which is unexpected. Nonetheless, ALine consistently performs better. ", "page_idx": 6}, {"type": "table", "img_path": "giXUx4VH9t/tmp/a5bdc8a83ffb25f4a9e65751ee5b1dc57c9722108733687a9f4b05bbf1724907.jpg", "table_caption": [], "table_footnote": ["Table 2: The results of OOD accuracy estimation, measured by MAE $(\\%)$ between estimated and actual OOD accuracy. The gray shades denote the results calculated after applying adaptations, and bold texts indicate the smallest estimation error among estimators. We also report the classification error $(\\%)$ in both Vanilla and adaptation methods for each dataset. "], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5.2 Unsupervised validation for TTA ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we demonstrate that strong AGL allows practical applications in unsupervised validations, choosing the best hyperparameter for TTA. Furthermore, we extend our application of such unsupervised validation to the task of choosing best TTA strategy among baselines. ", "page_idx": 7}, {"type": "text", "text": "Experimental setup. We select the best OOD model by selecting the one with best ID accuracy, as ACL holds across hyperparameters and best ID-performing hyperparameter is likely the best OOD-performing one [32]. Specifically, we first test the candidates by systematically sweeping over hyperparameter values, and select the one with the best ID accuracy. We focus on TENT, optimizing its various hyperparameters including learning rates, adaptation steps, architectures, batch sizes, and early-stopped checkpoints of pretraining. We select the candidates among the reasonably wide range of pools, as described in Table 6 in Appendix. To evaluate our method, we compare with other existing unsupervised validation methods including MixVal [17], ENT [33], IM [34], Corr-C [52], and SND [42]. We evaluate them on four shifts, CIFAR10-C, ImageNet-C, ImageNet-R, and Camelyon17-WILDS. ", "page_idx": 7}, {"type": "text", "text": "Results. Table 3 reports the difference in OOD accuracy (MAE $(\\%)$ ) between the model with best ID accuracy and the actual best OOD model, tested across different adaptation hyperparameters. Across different benchmarks and setups, our method shows competitive unsupervised validation results, outperforming other existing baselines in most cases. We noticed that current state-of-the-art unsupervised model selection methods, i.e., MixVal or IM, perform well on CIFAR10-C, ImageNet-C, and ImageNet-R, but they critically fail in Camelyon17-WILDS, e.g., validation error of $7.98\\%$ in ", "page_idx": 7}, {"type": "table", "img_path": "giXUx4VH9t/tmp/ccb80cbf846c07a5059249243997c86c32720c330a167296a1221b8466ab00ac.jpg", "table_caption": [], "table_footnote": ["Table 3: Results of unsupervised validation, measured by MAE $(\\%$ ) between OOD accuracy of model selected by best ID model and actual best OOD model. Our results are highlighted in shade. "], "page_idx": 8}, {"type": "image", "img_path": "giXUx4VH9t/tmp/2cf8e0e40afa7a5eccfd4ae450ad09e7e6ea111078aa243ed42a15bb2e5b90b5.jpg", "img_caption": ["Figure 3: 2-D visualizations of each TTA baseline\u2019s actual ( $\\bf\\Tilde{x}$ -axis) and estimated (y-axis) OOD accuracy. Each color denotes different TTA baselines, cross $(\\times)$ denotes the best-OOD model selected by our hyperparameter selection method, and circle dot (\u25e6) the averaged over hyperparameter values. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "MixVal and $23.52\\%$ in IM. Such failures of existing baselines might come from their assumptions, e.g., low-density separation, that do not generalize to such distribution shifts. In contrast, our method shows consistently low MAE across shifts, including those where other baselines fail, e.g., $0.62\\%$ in Camelyon17-WILDS. We also observe that in some cases, e.g., learning rate tested in ImageNet-C, MAE is relatively large $(9.70\\%)$ , which stems from the models adapted with very small learning rates, e.g., $10^{-5}$ that deviate from the correlation line. ", "page_idx": 8}, {"type": "text", "text": "Application of selecting best TTA strategy. We could easily extend our reliable unsupervised validation to select the best TTA methods from the baselines. Different TTA methods exhibit unique slopes and biases in their linear functions, so we use AGL-based estimators to predict and compare each method\u2019s OOD accuracy across hyperparameter settings. Specifically, we evaluated five TTA baselines \u2014 BN_Adapt, TENT, SHOT, ConjPL, and ETA \u2014 on CIFAR10-C across all corruptions. Let us assume we are comparing TTA methods by controlling one hyperparameter at a time while keeping others fixed, e.g., comparing which TTA performs best with each method\u2019s optimal architecture or on average. For each hyperparameter, we identified the best OOD model for each TTA method using unsupervised validation. Fig. 3 illustrates the estimated versus true OOD performances. Optimal hyperparameter settings for each TTA method (i.e., best OOD) are marked with $\\mathbf{\\hat{\\Pi}_{X}}^{\\bullet}\\cdot\\mathbf{\\hat{\\Pi}_{\\hat{M}}}^{\\bullet}$ , and average performances across hyperparameters are marked with \u201co\u201d. Our method accurately estimates both the best and average OOD performances, aligning closely with the ${\\scriptstyle\\mathrm{y}}=\\mathbf{X}$ line and maintaining the ranking of TTA methods by OOD accuracy. This demonstrates that our approach effectively selects the best TTA strategy without requiring labels in OOD. ", "page_idx": 8}, {"type": "text", "text": "6 Ablation studies: What factors in TTA lead to strong linear trends? ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Despite intriguing observations of TTA that induces strong linear trends, the specific mechanisms driving this trend remain unclear. To investigate, this section presents an ablation study on two main adaptation components: normalization layers (e.g., BN, LN) and where it updates (e.g., feature extractor, final classifier). ", "page_idx": 8}, {"type": "text", "text": "Normalization layers. We begin by ablating BN-layers, as BN_Adapt that normalizes features with OOD test data in BN layers lead to strong linear trends. Specifically, we test two variants \u2014 models with no normalization layers (denoted as Vanilla w/o N) and LN-layers (Vanilla w/ LN) \u2014 and report their cosine similarity of mean direction / covariance shape between shifts and correlation coefficient $(R^{2})$ in Table 4. Interestingly, their similarities as well as correlations are larger than that of Vanilla with BN-layers, but still fall short of BN_Adapt\u2019s which is very close to 1. The results of SAR, which utilize LN instead of BN, in Fig. 12 also show that its vanilla shows relatively stronger linear trends than those of Vanilla in Fig. 11, but not strongly and consistently as those of BN-layer-based methods in Fig. 11. We conjecture that this stems from how differently distribution shifts are encoded in network: Such shifts absorbed into BN-layers result in severe covariate shift, but at the same time make it easy to align shifts via adaptation. In contrast, non-BN models encode shifts across the entire model parameters, suffering relatively less shift misalignment (in feature space), but remain worse than adapted BN-layer models. Schneider et al. [44] suggested the similar discussions. ", "page_idx": 9}, {"type": "text", "text": "Where to update. Since most of the baselines in the paper adapt the feature-extractor, we add T3A [21], which proposes to adapt the last linear classifier only. T3A leverages feature extractor without BN layers, and updates the linear classifier\u2019s weights for adjusting the class-wise prototype given OOD test data. We observed that $R^{2}$ for accuracy and agreement in T3A are 0.80 and 0.46, which are substantially weaker than those adapting the feature-extractor\u2019s parameters (e.g., BN_Adapt). Again, such weak ", "page_idx": 9}, {"type": "table", "img_path": "giXUx4VH9t/tmp/e06a2379384f5bca0d5370fe3cc7b3cd67cad7cf4280d936774b1dd454f4c5b7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Table 4: Cosine similarity of mean direction / covariance shape and correlation coefficients $(R^{2})$ in CIFAR10-C Gaussian Noise, measured across architectures. Last two rows are from Table 1. ", "page_idx": 9}, {"type": "text", "text": "correlations that stem from misaligned shifts that persist in Vanilla without normalization layers are not effectively recovered by last classifier adaptation. Overall, our ablation studies clarify what TTA designs ideally lead to strong linear trends. Since non-BN-TTAs are often adopted in numerous practical circumstances, e.g., single batch, it remains an important open question how to develop TTA strategies that could achieve the correlations that lead to reliable and robust models. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion and Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we provide a key observation that recent TTAs lead to stronger AGL across a wide range of distribution shifts, encompassing those with weak correlations before adaptation. We explain this phenomena by the complexity of distribution shifts being substantially reduced to those with almost identical mean direction and covariance shape, satisfying the theoretical conditions for linear trends. This naturally leads to enhanced estimation of OOD performances across a wider range of shifts than before TTA, and also enables unsupervised hyperparameters as well as TTA method selection. ", "page_idx": 9}, {"type": "text", "text": "While not requiring OOD labels, AGL intrinsically relies on ID data, which may undermine the advantage of TTA that doesn\u2019t require ID data for adaptations. This reliance can raise privacy concerns due to potential inclusion of sensitive information and increase computational demands. In Section D, we conduct an ablation study to minimize the required amount of ID data for observing AGL for accuracy estimation. The results show that even with only $5\\%$ of the original ID data, OOD accuracy estimation performance remains nearly the same as with full access, outperforming other estimators. We believe that overcoming dependency on ID data and exploring a fully test-time approach for observing AGL remains a promising direction for future research. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We acknowledge the anonymous reviewers for their valuable feedbacks. Eungyeup Kim, Mingjie Sun, Christina Baek are supported by funding from the Bosch Center for Artificial Intelligence. Aditi Raghunathan gratefully acknowledges support from Open Philanthropy, Google, Apple and Schmidt AI2050 Early Career Fellowship. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] M. Arjovsky, L. Bottou, I. Gulrajani, and D. Lopez-Paz. Invariant risk minimization, 2020. ", "page_idx": 9}, {"type": "text", "text": "[2] J. L. Ba, J. R. Kiros, and G. E. Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.   \n[3] C. Baek, Y. Jiang, A. Raghunathan, and J. Z. Kolter. Agreement-on-the-line: Predicting the performance of neural networks under distribution shift. In Advances in Neural Information Processing Systems, volume 35, pages 19274\u201319289, 2022.   \n[4] M. Boudiaf, R. Mueller, I. Ben Ayed, and L. Bertinetto. Parameter-free online test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8344\u20138353, June 2022.   \n[5] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. ICLR, 2021.   \n[6] P. Foret, A. Kleiner, H. Mobahi, and B. Neyshabur. Sharpness-aware minimization for efficiently improving generalization. In International Conference on Learning Representations, 2021.   \n[7] Y. Gandelsaman, Y. Sun, X. Chen, and A. A. Efros. Test-time training with masked autoencoders. In Advances in Neural Information Processing Systems, 2022.   \n[8] S. Garg, S. Balakrishnan, Z. C. Lipton, B. Neyshabur, and H. Sedghi. Leveraging unlabeled data to predict out-of-distribution performance. In NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications, 2021.   \n[9] S. Goyal, M. Sun, A. Raghunanthan, and Z. Kolter. Test-time adaptation via conjugate pseudolabels. Advances in Neural Information Processing Systems, 2022.   \n[10] D. Guillory, V. Shankar, S. Ebrahimi, T. Darrell, and L. Schmidt. Predicting with confidence on unseen distributions. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 1134\u20131144, October 2021.   \n[11] I. Gulrajani and D. Lopez-Paz. In search of lost domain generalization. In International Conference on Learning Representations, 2021.   \n[12] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. In European Conference on Computer Vision, 2016. URL https://api.semanticscholar. org/CorpusID:6447277.   \n[13] K. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning for Image Recognition. In Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR \u201916, pages 770\u2013778. IEEE, June 2016. doi: 10.1109/CVPR.2016.90.   \n[14] D. Hendrycks and T. Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. Proceedings of the International Conference on Learning Representations, 2019.   \n[15] D. Hendrycks and K. Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. Proceedings of International Conference on Learning Representations, 2017.   \n[16] D. Hendrycks, S. Basart, N. Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu, S. Parajuli, M. Guo, D. Song, J. Steinhardt, and J. Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. ICCV, 2021.   \n[17] D. Hu, J. Liang, J. H. Liew, C. Xue, S. Bai, and X. Wang. Mixed samples as probes for unsupervised model selection in domain adaptation. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[18] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.   \n[19] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.   \n[20] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 448\u2013456, Lille, France, 07\u201309 Jul 2015. PMLR.   \n[21] Y. Iwasawa and Y. Matsuo. Test-time classifier adjustment module for model-agnostic domain generalization. In Advances in Neural Information Processing Systems, volume 34, pages 2427\u20132440. Curran Associates, Inc., 2021.   \n[22] Y. Jiang, V. Nagarajan, C. Baek, and J. Z. Kolter. Assessing generalization of SGD via disagreement. In International Conference on Learning Representations, 2022.   \n[23] A. Khurana, S. Paul, P. Rai, S. Biswas, and G. Aggarwal. Sita: Single image test-time adaptation, 2022.   \n[24] D. Lee, B. Moniri, X. Huang, E. Dobriban, and H. Hassani. Demystifying disagreementon-the-line in high dimensions. In International Conference on Machine Learning (ICML), 2023.   \n[25] D. LeJeune, J. Liu, and R. Heckel. Monotonic risk relationships under distribution shifts for regularized risk minimization. Journal of Machine Learning Research, 25(54):1\u201337, 2024. URL http://jmlr.org/papers/v25/22-1197.html.   \n[26] Z. Leng, M. Tan, C. Liu, E. D. Cubuk, J. Shi, S. Cheng, and D. Anguelov. Polyloss: A polynomial expansion perspective of classification loss functions. In International Conference on Learning Representations, 2022.   \n[27] J. Liang, D. Hu, and J. Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. In International Conference on Machine Learning (ICML), pages 6028\u20136039, 2020.   \n[28] C. Liu, B. Zoph, M. Neumann, J. Shlens, W. Hua, L. Li, L. Fei-Fei, A. L. Yuille, J. Huang, and K. Murphy. Progressive neural architecture search. In European Conference on Computer Vision, 2018.   \n[29] Y. Liu, P. Kothari, B. G. van Delft, B. Bellot-Gurlet, T. Mordan, and A. Alahi. Ttt $^{\\vdash+}$ : When does self-supervised test-time training fail or thrive? In Thirty-Fifth Conference on Neural Information Processing Systems, 2021.   \n[30] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021.   \n[31] H. Mania and S. Sra. Why do classifier accuracies show linear trends under distribution shift?, 2021.   \n[32] J. P. Miller, R. Taori, A. Raghunathan, S. Sagawa, P. W. Koh, V. Shankar, P. Liang, Y. Carmon, and L. Schmidt. Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 7721\u20137735. PMLR, 18\u201324 Jul 2021.   \n[33] P. Morerio, J. Cavazza, and V. Murino. Minimal-entropy correlation alignment for unsupervised deep domain adaptation. International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id $=$ rJWechg0Z.   \n[34] K. Musgrave, S. Belongie, and S.-N. Lim. Three new validators and a large-scale benchmark ranking for unsupervised domain adaptation, 2023.   \n[35] S. Niu, J. Wu, Y. Zhang, Y. Chen, S. Zheng, P. Zhao, and M. Tan. Efficient test-time model adaptation without forgetting. In The Internetional Conference on Machine Learning, 2022.   \n[36] S. Niu, J. Wu, Y. Zhang, Z. Wen, Y. Chen, P. Zhao, and M. Tan. Towards stable test-time adaptation in dynamic wild world. In Internetional Conference on Learning Representations, 2023.   \n[37] I. Radosavovic, R. P. Kosaraju, R. Girshick, K. He, and P. Dollar. Designing network design spaces. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.   \n[38] B. Recht, R. Roelofs, L. Schimidt, and V. Shankar. Do cifar-10 classifiers generalize to cifar-10? arXiv preprint arXiv: 1806.00451, 2018.   \n[39] B. Recht, R. Roelofs, L. Schmidt, and V. Shankar. Do ImageNet classifiers generalize to ImageNet? In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 5389\u20135400. PMLR, 09\u201315 Jun 2019.   \n[40] E. Rusak, S. Schneider, G. Pachitariu, L. Eck, P. Gehler, O. Bringmann, W. Brendel, and M. Bethge. If your data distribution shifts, use self-learning. Transactions of Machine Learning Research, 2022.   \n[41] S. Sagawa, P. W. Koh, T. Lee, I. Gao, S. M. Xie, K. Shen, A. Kumar, W. Hu, M. Yasunaga, H. Marklund, S. Beery, E. David, I. Stavness, W. Guo, J. Leskovec, K. Saenko, T. Hashimoto, S. Levine, C. Finn, and P. Liang. Extending the wilds benchmark for unsupervised adaptation. In International Conference on Learning Representations (ICLR), 2022.   \n[42] K. Saito, D. Kim, P. Teterwak, S. Sclaroff, T. Darrell, and K. Saenko. Tune it the right way: Unsupervised validation of domain adaptation via soft neighborhood density. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 9184\u20139193, October 2021.   \n[43] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.   \n[44] S. Schneider, E. Rusak, L. Eck, O. Bringmann, W. Brendel, and M. Bethge. Improving robustness against common corruptions by covariate shift adaptation. In Advances in Neural Information Processing Systems, volume 33, pages 11539\u201311551. Curran Associates, Inc., 2020.   \n[45] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In International Conference on Learning Representations, 2015.   \n[46] Y. Sun, X. Wang, Z. Liu, J. Miller, A. A. Efros, and M. Hardt. Test-time training with selfsupervision for generalization under distribution shifts. In International Conference on Machine Learning (ICML), 2020.   \n[47] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions, 2014.   \n[48] D. Teney, Y. Lin, S. J. Oh, and E. Abbasnejad. Id and ood performance are sometimes inversely correlated on real-world datasets, 2023.   \n[49] H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablayrolles, and H. Jegou. Training data-efficient image transformers & distillation through attention. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research. PMLR, 2021.   \n[50] H. Touvron, M. Cord, and H. J\u2019egou. Deit iii: Revenge of the vit. In European Conference on Computer Vision, 2022. URL https://api.semanticscholar.org/CorpusID: 248178188.   \n[51] N. Tripuraneni, B. Adlam, and J. Pennington. Overparameterization improves robustness to covariate shift in high dimensions. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, Advances in Neural Information Processing Systems, 2021. URL https: //openreview.net/forum?id=PxMfDdPnTfV.   \n[52] W. Tu, W. Deng, T. Gedeon, and L. Zheng. Assessing model out-of-distribution generalization with softmax prediction probability baselines and a correlation method, 2023. URL https: //openreview.net/forum?id $\\cdot$ 1maXoEyeqx.   \n[53] D. Wang, E. Shelhamer, S. Liu, B. Olshausen, and T. Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2021.   \n[54] J.-K. Wang and A. Wibisono. Towards understanding gd with hard and conjugate pseudo-labels for test-time adaptation. In Internetional Conference on Learning Representations, 2023.   \n[55] Q. Wang, O. Fink, L. Van Gool, and D. Dai. Continual test-time domain adaptation. In Proceedings of Conference on Computer Vision and Pattern Recognition, 2022.   \n[56] F. Wenzel, A. Dittadi, P. V. Gehler, C.-J. Simon-Gabriel, M. Horn, D. Zietlow, D. Kernert, C. Russell, T. Brox, B. Schiele, B. Sch\u00f6lkopf, and F. Locatello. Assaying out-of-distribution generalization in transfer learning. In Neural Information Processing Systems, 2022.   \n[57] S. Xie, R. Girshick, P. Doll\u00e1r, Z. Tu, and K. He. Aggregated residual transformations for deep neural networks. arXiv preprint arXiv:1611.05431, 2016.   \n[58] F. Yu, D. Wang, E. Shelhamer, and T. Darrell. Deep layer aggregation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.   \n[59] S. Zagoruyko and N. Komodakis. Wide residual networks, 2017.   \n[60] M. Zhang, S. Levine, and C. Finn. MEMO: Test time robustness via adaptation and augmentation. In Advances in Neural Information Processing Systems, 2022.   \n[61] H. Zhao, Y. Liu, A. Alahi, and T. Lin. On pitfalls of test-time adaptation. In International Conference on Machine Learning (ICML), 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Details on Experimental Setup ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Model Architectures ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We list the types of architectures for each testbed of dataset. ", "page_idx": 14}, {"type": "table", "img_path": "giXUx4VH9t/tmp/357f3788fadb8b0c6ce76d549e2c7407f4d4023cd3ecdd7dd960d2153285c9a1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "Table 5: The list of architecture types for each testbed of datasets, including CIFAR10, CIFAR100, ImageNet, Camelyon17-WILDS, and iWildCAM-WILDS. ", "page_idx": 14}, {"type": "text", "text": "For CIFAR10, CIFAR100, and WILDS datasets, we train the models from the scratch, while for ImageNet, we use the pretrained model weights from torchvision and timm package. In addition, since TTT requires specific network composition required for the rotation-prediction task during pretraining, we train them using ResNet-14,26,32,50,104, and 152, which are available in the original implementation3. ", "page_idx": 14}, {"type": "text", "text": "For Camelyon17 dataset, we also test the neural networks with their feature extractor (all parameters before the final linear classifier) randomly initialized, following Miller et al. [32] that tested the low-accuracy models on the dataset. We notice that these models, even with their most of parameters being randomized, still achieve high accuracy in both ID and OOD after training the last linear classifier. They also exhibit improved OOD accuracy after adaptations. We apply this randomization to ResNet18, ResNet34, ResNet50, VGG16, VGG13, and VGG11. ", "page_idx": 14}, {"type": "text", "text": "We trained and tested all models and datasets in NVIDIA RTX 6000. ", "page_idx": 14}, {"type": "text", "text": "A.2 Distribution Shifts ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We test the models on 9 different distribution shifts that include synthetic corruptions and real-world shifts. Synthetic corruptions datasets, CIFAR10-C, CIFAR100-C, and ImageNet-C [14] are designed to apply the 15 different types of corruptions, such as Gaussian Noise, on their original dataset counterparts. We use the most severe corruptions, which have severity of 5, in all experiments. These corruptions datasets are most commonly evalutated distribution shifts in a wide range of TTA papers [44, 46, 29, 27, 53, 9, 35, 36, 61]. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "We also test on real-world shifts, which include CIFAR10.1 [38], ImageNetV2 [39], ImageNet-R [16], Camelyon17-WILDS, iWildCAM-WILDS, and FMoW-WILDS [41]. CIFAR10.1, and ImageNetV2 are the reproduction of datasets by following the original dataset creation procedures. ImageNet-R is the variant of ImageNet which contains the images with renditions of various styles, such as paintings or cartoons. FMoW-WILDS [41] contains the spatio-temporal satellite imagery of 62 different use of land or building categories, where distribution shifts originate from the years that the imagery is taken. Specifically, following Miller et al. [32], we use ID set consists of images taken from 2002 to 2013, and OOD set taken between 2013 and 2016. ", "page_idx": 15}, {"type": "text", "text": "A.3 Adaptation hyperparameters ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Table 6 shows the hyperparameter pools for each setup when used for observing AGL across different hyperparameters. We use SGD optimizer with momentum of 0.9 for all adaptation baselines except for SAR, which uses sharpness-aware minimization (SAM) optimizer [6]. ", "page_idx": 15}, {"type": "table", "img_path": "giXUx4VH9t/tmp/e93ffb1701e3ea9ff57f507efe10d7d43b779966c954ad3f3742d38cc4997991.jpg", "table_caption": ["(b) Camelyon17-WILDS, iWildCAM-WILDS "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Table 6: The hyperparameter pools utilized for observing AGL across hyperparameters in CIFAR10, CIFAR100, ImageNet, Camelyon17-WILDS, and iWildCAM-WILDS dataset. ", "page_idx": 15}, {"type": "text", "text": "A.4 Online test in ID and OOD during TTA ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Algorithm 1 provides the details of how we test models ID and OOD performances during TTA. Specifically, during test in OOD (for adaptation), we also provide a batch of ID data, and test the dynamically updated model for each iteration. For each iteration, we test its predictions on the batch of ID and OOD data and utilize them for calculating model accuracy and agreements in ID and OOD. The algorithm describes how to calculate the accuracy, but agreement can be calculated by iterating it with another model. ", "page_idx": 15}, {"type": "table", "img_path": "giXUx4VH9t/tmp/a30df90e9ad870fb6c64b822b407fa46080cc9bd396d1b26dbc0082b964180e1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "giXUx4VH9t/tmp/ef00193a947f84c6bdefcff61177be43791bbf38b9b56fff332468d44278e5aa.jpg", "img_caption": ["Figure 4: For shifts that already exhibit AGL, after adaptations do not break the linear trends after adaptations, even when they lead to accuracy drops. Each blue and pink dot denotes the accuracy and agreement, followed by the linear fits for each. The axes are probit scaled. Here are examples with SHOT, TENT, and ETA on shifts such as CIFAR10.1, ImageNetV2, ImageNet-R, and FMoWWILDS. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "B Analysis on distribution shifts that have AGL without adaptations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We also examine the shifts that exhibit strong AGL without adaptations, including dataset reproductions (CIFAR10.1 [38], ImageNetV2 [39]), and other real-world shifts (ImageNet-R [16], FMoWWILDS [41]). As seen in Fig. 4, applying adaptation baselines, such as SHOT, TENT, and ETA, does not have improvements in OOD generalizations or even results in degradation, as evidenced by previous studies [53, 61]. However, they persist to have the strong linear trends, and this implies that once the distribution shifts show the correlations, adaptations do not affect on the trends. This highlights that we could potentially predict whether adaptations may succeed or falter in these shifts. ", "page_idx": 17}, {"type": "text", "text": "C OOD accuracy estimation baselines ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "C.1 ALine-S and ALine-D ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Baek et al. [3] propose ALine-S and ALine-D, which assess the models\u2019 OOD accuracy without access to labels by leveraging the agreement-on-the-line among models. We provide the detailed algorithm of ALine-S and ALine-D in Algorithm 2. ", "page_idx": 17}, {"type": "text", "text": "C.2 Average thresholded confidence (ATC) ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Garg et al. [8] introduce OOD accuracy estimation method, ATC, which learns the confidence threshold and predicts the OOD accuracy by using the fraction of unlabeled OOD samples for which model\u2019s negative entropy is less that threshold. Specifically, let $h(x)\\in\\mathbb{R}^{c}$ denote the softmax output of model $h$ given data $x$ from ${\\mathcal{X}}_{\\mathrm{OOD}}$ for classifying among $c$ classes. The method can be written as ", "page_idx": 17}, {"type": "table", "img_path": "giXUx4VH9t/tmp/ce8573e743c838c6a898bdb666edd735316d13403693e5fb6b571347c16b487a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "below: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\widehat{\\mathsf{A c c}}_{000\\mathrm{D}}=\\mathbb{E}\\big[\\mathbb{1}\\{s(h(x))<t\\}\\big],\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $s$ is the negative entropy, i.e., $\\begin{array}{r}{s(h(x))=\\sum_{c}h_{c}(x)\\log(h_{c}(x))}\\end{array}$ , and $t$ satisfies ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[\\mathbb{1}\\{s(h(x))<t\\}\\big]=\\mathbb{E}\\big[\\mathbb{1}\\big\\{\\operatorname{arg\\,max}_{c}h_{c}(x)\\neq y\\big\\}\\big].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C.3 Difference of confidence (DOC)-feat ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Guillory et al. [10] observe that the shift of distributions is encoded in the difference of model\u2019s confidences between them. Based on this observation, they leverage such differences in confidences as the accuracy gap under distribution shifts for calculating the final OOD accuracy. Specifically, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\widehat{\\mathsf{A c c}}_{\\mathrm{OOD}}=\\mathsf{A c c}_{\\mathrm{ID}}-\\left(\\mathbb{E}\\big[\\operatorname*{max}_{c}h_{c}(x_{\\mathrm{ID}})\\big]-\\mathbb{E}\\big[\\operatorname*{max}_{c}h_{c}(x_{\\mathrm{OOD}})\\big]\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C.4 Average confidence (AC) ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Hendrycks et al. [15] estimate the OOD accuracy based on model\u2019s averaged confidence, which can be written as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\widehat{\\mathsf{A c c}}_{\\mathrm{OOD}}=\\mathbb{E}\\big[\\operatorname*{max}_{c}h(x_{\\mathrm{OOD}})\\big].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C.5 Agreement ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Jiang et al. [22] observe that disagreement between the models that are trained with different setups closely tracks the error of models in ID. We adopt this as the baseline for assessing generalization under distribution shifts, where we can estimate $\\widehat{\\mathsf{A c c}}_{\\mathrm{OOD}}=\\mathsf{A g r}(\\mathcal{P}_{\\mathrm{OOD}})$ , where $\\mathcal{P}_{\\mathrm{ooD}}$ denotes the set of predictions of the models on OOD data ${\\mathcal{X}}_{\\mathrm{OOD}}$ . ", "page_idx": 18}, {"type": "image", "img_path": "giXUx4VH9t/tmp/6d56c09fc393841d5b0bc21bb651990922269fc4ae445b5e809a184ba367d538.jpg", "img_caption": ["Figure 5: OOD accuracy estimation results with limited amount of ID data, decreasing from $50\\%$ to $1\\%$ of entire data pool. We randomly sampled 10 different subsets for each ratios, and visualize the distribution of MAE $(\\%)$ results. The results of baseline including ATC, DoC-feat, and Agreement are included for comparison. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "D Ablation study on the number of ID data ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Observing AGL requires the ID data during test time. Even if the access to labeled ID data is often much available in practice than obtaining OOD data, ID data might be limited in particular applications due to privacy issue. To further mitigate this concern, we conduct an ablation study on how the number of ID samples affects on the precision of accuracy estimation. Specifically, for each dataset, we use the subset of original ID data, such as $5\\%$ of total, for calculating both accuracy and agreemenet in ID. By randomly iterating 10 different subsets for each ratio, we test how the estimation performance vary according to different subsets. Fig. 5 shows that for CIFAR10-C and CIFAR100-C, only $5\\%$ reliably achieves the state-of-the-art estimation performances outperforming other baselines. Also, in more complex dataset such as ImageNet-C, Camelyon17-WILDS, and iWildCAM-WILDS, they show that even using just $1\\%$ of original ID data achieves the best estimation performances among baselines. These results indicate that our framework is practically feasible in such practical applications where access to ID is highly limited. ", "page_idx": 19}, {"type": "text", "text": "E Additional results on CIFAR10-C, CIFAR100-C, and ImageNet-C ", "text_level": 1, "page_idx": 20}, {"type": "image", "img_path": "giXUx4VH9t/tmp/917a6a7233b09a419d396321346c9ebeeefae0037c059c408f11d227e01a87f7.jpg", "img_caption": ["Figure 6: Results on CIFAR10-C corruptions (different architectures), BN_Adapt [44], SHOT [27], TENT [53], and ETA [35]. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "giXUx4VH9t/tmp/ffc0946783dfe525bdb35b3f4c7044a11c7371fc55482f693e685ae946ab243b.jpg", "img_caption": ["Figure 7: Results on CIFAR10-C corruptions (different architectures), TTT [46], ConjPL [9] "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "giXUx4VH9t/tmp/8a80cc8dfdfd0894f2667117da15e39d411f64a32de3457f9cac91f833931674.jpg", "img_caption": ["Figure 8: Results on CIFAR10-C corruptions (adaptation hyperparameters of TENT [53]). "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "giXUx4VH9t/tmp/426b776ce04339adf93dd0587db27f31e3585d899272a21eb86a04570ab3c645.jpg", "img_caption": ["Figure 9: Results on CIFAR100-C corruptions. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "giXUx4VH9t/tmp/55f7bbca121361fc82c78c46f9ceadd39bd17dd074bab52873ef912821ee269a.jpg", "img_caption": ["Figure 10: Results on CIFAR100-C corruptions (different architectures), ConjPL [9] "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "giXUx4VH9t/tmp/7ffb8485d3d8f8094ae80d69ea397997196c7bc4eb060b8b45da50d93ee64636.jpg", "img_caption": ["Figure 11: Results on ImageNet-C corruptions. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "giXUx4VH9t/tmp/b72247d8dae02527ddcfc4ec3dc62697a6e1409f8ec21a99578b71b70eac7ee4.jpg", "img_caption": ["Figure 12: Results on ImageNet-C corruptions (different architectures), SAR [36] "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "giXUx4VH9t/tmp/93f00a5a05be2232f26ba027d66ec07bd9077626fe4feee20dbbb0a55c944522.jpg", "img_caption": ["Figure 13: Results on ImageNet-C corruptions (adaptation hyperparameters of ETA [35]). "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Both abstract and introduction includes our main observations, analysis on them, followed by experimental results. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: In Section 7, we discuss about our paper\u2019s limitation about not examining the specific mechanisms of adaptation methods for AGL. Also, in Section D, we acknowledge that AGL requires ID data during test-time. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: In Section 4.1, we provide exact notations, setups, theorems and proofs with proper numbers and references. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide the detailed algorithm for online test in ID and OOD in Algorithm 1, which is very easy to follow. Also, the estimation algorithm we employ in other paper already has the public code, but we provide detailed algorithm in Algorithm 2. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our work mainly focuses on existing test-time adaptation methods as well as publicly available datasets, which are already highly accessible. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We provide detailed experimental setups for our observation in Section 3.1 as well as our experiments in Sections 5.1, 5.2, and Section A. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We conducted iterative experiments on measuring mean and covariance similarity in Table 1, as well as subsampling ID data in Fig. 5. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 31}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We provide the details about the type of GPU machines for our entire experiments in Section A. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We have reviewed the NeurIPS Code of Ethics, and confirmed that our paper confirms them. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: In Section 7, we discuss the positive societal impacts of our work, the significant improvements of reliability of neural networks under distribution shift. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 33}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: This work does not include such risks. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We properly cite all the test-time adaptation baselines and datasets we used in our paper. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This work does not release new assets. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 34}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This work does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This work does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 34}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 35}]