[{"figure_path": "vU512K8vrR/figures/figures_1_1.jpg", "caption": "Figure 1: (Left) Fluctuations of regularization loss and singular values across multiple time steps. (Right) Performance and runtime of fine-tuning DeBERTaV3-base model on the CoLA dataset with increased initial rank in AdaLoRA. Here, the metric Mcc means Matthews Correlation Coefficient.", "description": "The left panel of Figure 1 shows the fluctuations of regularization loss and singular values over multiple time steps during the training process. This visualization highlights the instability and variability in these metrics, indicating that a fixed rank may not be optimal for capturing the dynamic importance of matrix elements. The right panel demonstrates the impact of increasing the initial rank (r_i) on both the performance (measured by Matthews Correlation Coefficient, MCC) and runtime of the AdaLoRA algorithm during fine-tuning. The results show that a larger initial rank generally leads to better performance but with significantly increased runtime.", "section": "1 Introduction"}, {"figure_path": "vU512K8vrR/figures/figures_3_1.jpg", "caption": "Figure 2: The overall framework of SalientLoRA. First, the incremental matrix is decomposed using SVD to facilitate rank allocation. During fine-tuning, the salience of singular values within time-series is measured, which is composed of orthogonality-aware singular value magnitudes and the influence domain of the dependency graph. Finally, in the rank allocation process, singular values with lower significance are progressively trimmed.", "description": "This figure illustrates the three main components of the SalientLoRA method: incremental matrix SVD, salience measurement, and adaptive rank allocation.  The incremental matrix is first decomposed using SVD, enabling rank control.  Then, salience is measured for each singular value considering both magnitude and its influence on other values within a time series. Finally, based on salience, less significant singular values are removed to optimize the rank.", "section": "3 Overview"}, {"figure_path": "vU512K8vrR/figures/figures_8_1.jpg", "caption": "Figure 3: Comparison of fine-tuning effectiveness and runtime for AdaLoRA and SalientLoRA across multiple datasets as the rank space increases. The line graph illustrates their the fine-tuning performance, while the bar chart depicts the fine-tuning time.", "description": "This figure compares AdaLoRA and SalientLoRA's performance and runtime across four datasets (COLA, RTE, STS-B, MRPC) while increasing the average initial rank.  The line graphs show that both methods improve performance as the initial rank increases, but SalientLoRA consistently outperforms AdaLoRA. Notably, the bar graphs highlight SalientLoRA's significantly better runtime efficiency compared to AdaLoRA, even as the rank space expands.", "section": "6.6 Analysis of Space Allocation and Time Consumption"}, {"figure_path": "vU512K8vrR/figures/figures_9_1.jpg", "caption": "Figure 4: Variations of fine-tuning performance with different \u03bb, which controls the contributions of two components in salience measurement: orthogonality-aware magnitude and influence domain.", "description": "This figure shows the impact of the hyperparameter \u03bb on the fine-tuning performance across four different datasets (COLA, RTE, STS-B, and MRPC). The hyperparameter \u03bb controls the balance between the contribution of orthogonality-aware singular value magnitudes and the influence domain in the salience measurement.  The plots show that there's an optimal value for \u03bb around 0.7, where the performance is maximized for most datasets.  Values of \u03bb outside this range lead to decreased performance, indicating the importance of balancing these two components in the salience calculation for optimal results.", "section": "6.7 Analysis of Hyperparameter \u03bb"}, {"figure_path": "vU512K8vrR/figures/figures_9_2.jpg", "caption": "Figure 2: The overall framework of SalientLoRA. First, the incremental matrix is decomposed using SVD to facilitate rank allocation. During fine-tuning, the salience of singular values within time-series is measured, which is composed of orthogonality-aware singular value magnitudes and the influence domain of the dependency graph. Finally, in the rank allocation process, singular values with lower significance are progressively trimmed.", "description": "This figure illustrates the three main stages of the SalientLoRA method: 1) Incremental Matrix SVD: Decomposes the incremental matrix into three matrices (P, V, Q) using singular value decomposition.  2) Salience Measurement: Measures the salience of each singular value based on magnitude and influence within a time series.  3) Adaptive Rank Allocation: Uses the salience information to prune less important singular values, adapting the rank of the LoRA.", "section": "3 Overview"}]