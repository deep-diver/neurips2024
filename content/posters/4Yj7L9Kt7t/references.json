{"references": [{"fullname_first_author": "Bubeck", "paper_title": "The best of both worlds: Stochastic and adversarial bandits", "publication_date": "2012-00-00", "reason": "This paper introduced the Best-of-Both-Worlds (BOBW) framework, which is central to the main problem studied in the current paper."}, {"fullname_first_author": "Bubeck", "paper_title": "Bandits with heavy tail", "publication_date": "2013-00-00", "reason": "This paper provided fundamental results on stochastic bandits with heavy-tailed losses, which is a key background for the current paper's extension to the adversarial and BOBW settings."}, {"fullname_first_author": "Huang", "paper_title": "Adaptive best-of-both-worlds algorithm for heavy-tailed multi-armed bandits", "publication_date": "2022-00-00", "reason": "This is the most closely related prior work, proposing an algorithm for heavy-tailed BOBW bandits, which the current paper improves upon by relaxing key assumptions and strengthening guarantees."}, {"fullname_first_author": "Zimmert", "paper_title": "Tsallis-inf: An optimal algorithm for stochastic and adversarial bandits", "publication_date": "2021-00-00", "reason": "This paper provides optimal algorithms for the standard (bounded losses) BOBW setting, which is a key foundation for the heavy-tailed extension."}, {"fullname_first_author": "Agarwal", "paper_title": "Corralling a band of bandit algorithms", "publication_date": "2017-00-00", "reason": "This paper provided key theoretical tools and analysis techniques for online learning algorithms with general regularizers, which are fundamental for the analysis in the current paper."}]}