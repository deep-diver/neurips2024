[{"figure_path": "qamfjyhPeg/figures/figures_4_1.jpg", "caption": "Figure 1: Demonstration of the advantage of entropy matching on toy binary classification problem with Gaussian data. The top panel represents an in-distribution setup in which Pxy = Pxy. The bottom panel illustrates an out-of-distribution setup, obtained by shifting the two Gaussians. The entropy matching (red) and entropy minimization (black) risks are presented as a function of w. The dashed yellow line presents the decision boundary of the pre-trained classifier. The points marked by stars correspond to the decision boundary of the adapted classifiers.", "description": "This figure compares two loss functions, entropy minimization and entropy matching, in a simple binary classification problem with Gaussian data. The top panel shows an in-distribution scenario, where the source and target data distributions are the same; both loss functions maintain high accuracy.  The bottom panel illustrates an out-of-distribution scenario, where the target distribution has shifted.  Entropy minimization leads to a collapse in performance, while entropy matching maintains high accuracy by adapting the decision boundary.", "section": "3.2 Motivating example: entropy minimization vs. entropy matching"}, {"figure_path": "qamfjyhPeg/figures/figures_8_1.jpg", "caption": "Figure 2: Continual test-time adaptation on ImageNet-C with a ViT model. Top: Per-corruption accuracy with a corruption segment size of 1,000 examples. Results are obtained over 10 independent trials; error bars are tiny. Bottom left and center: Severity shift-low (1) to high (5) and back to low (left), and high (5) to low (1) and back to high (center). To improve the readability here, we only present POEM, the best-performing baseline method (EATA), and the no-adapt approach. Bottom right: Mean accuracy under continual corruptions as a function of the corruption segment size.", "description": "This figure shows the results of continual test-time adaptation experiments on the ImageNet-C dataset using a Vision Transformer (ViT) model. The top panel displays the per-corruption accuracy with a corruption segment size of 1000 examples. The bottom-left and bottom-center panels show the accuracy changes under severity shifts, while the bottom-right panel shows the mean accuracy as a function of the corruption segment size.  The figure demonstrates POEM's performance compared to the best baseline method (EATA) and a no-adaptation approach across various scenarios.", "section": "Experiments"}, {"figure_path": "qamfjyhPeg/figures/figures_9_1.jpg", "caption": "Figure 3: In-distribution experiment on ImageNet (left panel): calibration error (ECE [100]) versus ||w||\u2014a metric that evaluates the classifier\u2019s parameters deviation from the original ViT model. Lower values on both axes are better. Results are averaged across 10 independent trials; standard errors and accuracy of each method are reported in Table 3 in the appendix. The behavior of the betting parameter (right panel): the value of e is presented as a function of time for both in-and out-of-distribution experiments (a single shift, two severity levels).", "description": "The left panel shows the calibration error (ECE) and parameter change (||w||) for different adaptation methods on the ImageNet dataset. Lower values indicate better calibration and less modification to the original model parameters.  The right panel shows the betting variable (e) over time for both in-distribution and out-of-distribution scenarios. This variable controls the aggressiveness of the bets in the testing-by-betting framework, and its behavior reflects the adaptation process.", "section": "3.2 Motivating example: entropy minimization vs. entropy matching"}, {"figure_path": "qamfjyhPeg/figures/figures_20_1.jpg", "caption": "Figure 4: Martingale behaviour with and without adaptation and on in-distribution data. Visualization of three scenarios: (1) out-of-distribution data (ImageNet-C, brightness level 1) without adaptation, (2) the same out-of-distribution data with online adaptation, and (3) in-distribution data (ImageNet) all on ResNet50. The top panel shows the martingale value, that is, the accumulated capital (in log scale) over time, while the bottom panel shows the corresponding betting variable $\\epsilon$.", "description": "This figure shows the behavior of the wealth process (martingale) and the betting variable epsilon in three different scenarios: in-distribution, out-of-distribution without adaptation, and out-of-distribution with adaptation. The top panel displays the martingale in log scale, while the bottom panel shows epsilon. The results demonstrate that the proposed adaptation mechanism effectively controls the martingale's growth in the presence of distribution shift, preventing excessive model updates.", "section": "Online drift detection"}, {"figure_path": "qamfjyhPeg/figures/figures_24_1.jpg", "caption": "Figure 2: Continual test-time adaptation on ImageNet-C with a ViT model. Top: Per-corruption accuracy with a corruption segment size of 1,000 examples. Results are obtained over 10 independent trials; error bars are tiny. Bottom left and center: Severity shift\u2014low (1) to high (5) and back to low (left), and high (5) to low (1) and back to high (center). To improve the readability here, we only present POEM, the best-performing baseline method (EATA), and the no-adapt approach. Bottom right: Mean accuracy under continual corruptions as a function of the corruption segment size.", "description": "This figure presents the results of continual test-time adaptation experiments conducted on ImageNet-C using a Vision Transformer (ViT) model. The top panel shows per-corruption accuracy with a corruption segment size of 1000 examples. The bottom-left and bottom-center panels illustrate the effect of severity shifts on accuracy. The bottom-right panel demonstrates how the mean accuracy changes as a function of corruption segment size.", "section": "Experiments"}, {"figure_path": "qamfjyhPeg/figures/figures_27_1.jpg", "caption": "Figure 7: Empirical test entropy CDF of each adaptation method, applied to in- and out-of-distribution ImageNet data. The dotted black line represents the source CDF F^s obtained by applying the original ResNet50 model on test images from the source domain. The left panel shows how self-training on the validation set of ImageNet (in-distribution data) affects the entropy distribution of the model. The right panel repeats the experiment on out-of-distribution data from ImageNet-C with brightness corruption of severity level 1.", "description": "This figure shows the cumulative distribution function (CDF) of the entropy of the predictions made by different test-time adaptation methods on ImageNet data.  The left panel shows the results when the models are tested on in-distribution data (ImageNet validation set) and the right panel shows the results when tested on out-of-distribution data (ImageNet-C with brightness corruption). The dotted black line represents the CDF of the entropy of the original model's predictions on the source data. The figure demonstrates how the different methods affect the distribution of the test entropy. The goal of protected online entropy matching (POEM) is to have the target entropy distribution match the source entropy distribution to maintain robustness against distribution shifts.", "section": "3.2 Motivating example: entropy minimization vs. entropy matching"}, {"figure_path": "qamfjyhPeg/figures/figures_27_2.jpg", "caption": "Figure 2: Continual test-time adaptation on ImageNet-C with a ViT model. Top: Per-corruption accuracy with a corruption segment size of 1,000 examples. Results are obtained over 10 independent trials; error bars are tiny. Bottom left and center: Severity shift\u2014low (1) to high (5) and back to low (left), and high (5) to low (1) and back to high (center). To improve the readability here, we only present POEM, the best-performing baseline method (EATA), and the no-adapt approach. Bottom right: Mean accuracy under continual corruptions as a function of the corruption segment size.", "description": "The figure shows the results of continual test-time adaptation experiments conducted on the ImageNet-C dataset using a Vision Transformer (ViT) model. The top panel displays the per-corruption accuracy for different corruption types at severity level 5, with a corruption segment size of 1000 examples. The bottom left and center panels illustrate the accuracy changes during severity shifts (low to high and back to low, and high to low and back to high). The bottom right panel shows the mean accuracy as a function of the corruption segment size, demonstrating the effect of segment size on the adaptation performance.", "section": "Experiments"}, {"figure_path": "qamfjyhPeg/figures/figures_28_1.jpg", "caption": "Figure 2: Continual test-time adaptation on ImageNet-C with a ViT model. Top: Per-corruption accuracy with a corruption segment size of 1,000 examples. Results are obtained over 10 independent trials; error bars are tiny. Bottom left and center: Severity shift\u2014low (1) to high (5) and back to low (left), and high (5) to low (1) and back to high (center). To improve the readability here, we only present POEM, the best-performing baseline method (EATA), and the no-adapt approach. Bottom right: Mean accuracy under continual corruptions as a function of the corruption segment size.", "description": "This figure shows the results of continual test-time adaptation experiments on the ImageNet-C dataset using a Vision Transformer (ViT) model.  The top panel displays per-corruption accuracy with a segment size of 1000 examples. The bottom-left and bottom-center panels illustrate the accuracy changes under severity shifts (low to high and back, and high to low and back).  The bottom-right panel shows how mean accuracy changes with different corruption segment sizes.  Only POEM, EATA, and the no-adaptation baseline are shown for clarity.", "section": "Experiments"}, {"figure_path": "qamfjyhPeg/figures/figures_29_1.jpg", "caption": "Figure 2: Continual test-time adaptation on ImageNet-C with a ViT model. Top: Per-corruption accuracy with a corruption segment size of 1,000 examples. Results are obtained over 10 independent trials; error bars are tiny. Bottom left and center: Severity shift\u2014low (1) to high (5) and back to low (left), and high (5) to low (1) and back to high (center). To improve the readability here, we only present POEM, the best-performing baseline method (EATA), and the no-adapt approach. Bottom right: Mean accuracy under continual corruptions as a function of the corruption segment size.", "description": "This figure presents the results of continual test-time adaptation experiments on the ImageNet-C dataset using a Vision Transformer (ViT) model. The top panel shows the per-corruption accuracy with a corruption segment size of 1000 examples, averaged over 10 independent runs.  The bottom panels illustrate the accuracy changes under different severity shift scenarios (low to high and back, high to low and back) for gaussian noise, comparing POEM with EATA and the no-adaptation baseline. The bottom-right panel displays the mean accuracy under continual corruptions as the corruption segment size varies.", "section": "4 Experiments"}]