[{"type": "text", "text": "Protected Test-Time Adaptation via Online Entropy Matching: A Betting Approach ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yarin Bar1\u2217 Shalev Shaer2\u2217 Yaniv Romano1,2 ", "page_idx": 0}, {"type": "text", "text": "1Department of Computer Science, Technion\u2014Israel Institute of Technology 2Department of Electrical and Computer Engineering, Technion\u2014Israel Institute of Technology {yarinbar,shalev.shaer}@campus.technion.ac.il yromano@technion.ac.il ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We present a novel approach for test-time adaptation via online self-training, consisting of two components. First, we introduce a statistical framework that detects distribution shifts in the classifier\u2019s entropy values obtained on a stream of unlabeled samples. Second, we devise an online adaptation mechanism that utilizes the evidence of distribution shifts captured by the detection tool to dynamically update the classifier\u2019s parameters. The resulting adaptation process drives the distribution of test entropy values obtained from the self-trained classifier to match those of the source domain, building invariance to distribution shifts. This approach departs from the conventional self-training method, which focuses on minimizing the classifier\u2019s entropy. Our approach combines concepts in betting martingales and online learning to form a detection tool capable of quickly reacting to distribution shifts. We then reveal a tight relation between our adaptation scheme and optimal transport, which forms the basis of our novel self-supervised loss. Experimental results demonstrate that our approach improves test-time accuracy under distribution shifts while maintaining accuracy and calibration in their absence, outperforming leading entropy minimization methods across various scenarios. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The deployment of machine learning (ML) models in real-world settings presents a significant challenge, as these models often encounter testing environments (target domains) that differ from their training, source domain [1\u201315]. Consider, for example, an image recognition system employed for medical diagnostic support [16\u201320], where the quality of images acquired during testing deviates from the training data due to factors such as equipment degradation and novel illumination conditions. ML models are sensitive to such distribution shifts, often resulting in performance deterioration, which can be unexpected [15]. Ultimately, we want predictive models to dynamically adapt to new testing environments without the laborious work required to annotate new, up-to-date labels. ", "page_idx": 0}, {"type": "text", "text": "Recognizing this pressing need, there has been a surge in the development of adaptation methodologies to enhance test-time robustness to shifting distributions [21\u201328]. One commonly used approach involves jointly training a model on both the source and target domains [29\u201334]. However, such train-time adaptation methods assume access to unlabeled test data from the target domains, limiting the ability to adapt the model to new domains that emerge during testing. To overcome this limitation, test-time adaptation techniques offer strategies that dynamically update the model parameters as new unlabeled test points become available. In particular, leading methodologies draw inspiration from the relationship between the entropy of estimated class probabilities\u2014a measure of confidence\u2014and model accuracy [35\u201343]. Empirical evidence highlights that lower entropy often corresponds to higher accuracy, encouraging the development of self-supervised learning approaches that adjust model parameters by minimizing the entropy loss or the cross-entropy through the assignment of pseudo- or soft-labels to test points [44\u201348]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "While test-time adaptation techniques have shown promise in enhancing test accuracy under domain shifts, there is a caveat: minimizing entropy or related self-supervised loss functions without control can lead to overconfident predictions, and may suffer from undesired, noisy model updates [49\u2013 52]. In extreme cases, this approach may even cause the model to collapse and produce trivial predictions [53, 54]. Indeed, without careful implementation and tuning, these techniques may not improve\u2014or could even reduce [34]\u2014the predictive performance in realistic settings. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we present a novel, statistically principled approach to test-time adaptation via selftraining. Our methodology is built upon two key pillars. First, we introduce an online statistical framework that monitors and detects distribution shifts in the test data influencing the models\u2019 predictions. We achieve this by sequentially testing whether the distribution of the classifier\u2019s entropy values obtained during testing deviates from the ones corresponding to the source domain. Armed with this monitoring tool, we then devise an online adaptation mechanism that leverages the accumulated evidence of distribution shifts to adaptively update model parameters. This mechanism drives the distribution of the self-trained classifier\u2019s entropy values, obtained on test data, to closely match the distribution of entropy values when applying the original model to the source domain. As a result, our proposed Protected Online Entropy Matching (POEM) method adapts the model on the fly in a controlled manner: in the absence of a distribution shift, our approach has a \u201cno-harm\u201d effect both on accuracy and calibration of the model, whereas under distribution shifts our experiments demonstrate an improvement of the test time accuracy, often surpassing state-of-the-art methods. ", "page_idx": 1}, {"type": "text", "text": "Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "(i) We present a sequential test for classification entropy drift detection, building on betting martingales [55\u201357] and online learning optimization [58\u201360] to provably attain fast reactions to shifting data. (ii) Inspired by [61], we show how to utilize the test martingale to analytically design a mapping function that transports the classifier entropies obtained at test time to resemble those of the source domain. Under certain assumptions, we establish connections between our online testing approach and optimal transport [62] as a mechanism for distribution matching. (iii) This observation sets the foundation of the entropy-matching loss function used in POEM. (iv) Numerical experiments in both continual and single-shift settings demonstrate that our approach is competitive and often outperforms strong benchmark methods that build on entropy minimization. These experiments are conducted using commonly used predictive models (ViT [63] and ResNet [64]) on standard benchmark datasets: ImageNet-C [65], CIFAR10-C, CIFAR100-C, and OfficeHome [66]. A software package that implements our methods is available at https://github.com/yarinbar/poem. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Problem setup ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "To formalize the problem, consider a $K$ -class classification problem with labeled training data $\\left(X_{i}^{s},Y_{i}^{s}\\right)_{i=1}^{n}$ from a source domain, sampled i.i.d. from the source distribution $P_{X Y}^{s}$ . Here, $X^{s}\\in\\mathbb{R}^{d}$ represents observed covariates and ${\\cal{Y}}^{s^{-}}\\in\\{1,\\ldots,K\\}$ is the corresponding label. During testing, we encounter a stream of points $X_{j}^{t}$ with unknown labels $Y_{j}^{t}$ , sampled from an unknown target distribution $P_{X Y}^{j}$ that may shift over time $j\\;=\\;1,2,...$ . To define the shifting mechanism, let $T_{j}:\\mathbb{R}^{d}\\to\\mathbb{R}^{\\bar{d}}$ be an unknown corruption/shift function, resulting in test instances $X_{j}^{t}=T_{j}(X^{s})$ with $X^{s}$ being a fresh sample from $P^{s}$ . For instance, in datasets such as ImageNet-C, corruptions involve modifications such as blur or changes in illumination applied to clean source images. While such transformations alter the marginal $P_{X}^{j}$ distribution of the target domain, we assume that (i) the labels obtained by an oracle classifier and (ii) the oracle\u2019s prediction difficulty (measured by the classifier\u2019s entropy) for clean and corrupted test points remain the same [67]. ", "page_idx": 1}, {"type": "text", "text": "2.2 Related work: test-time adaptation via self-training ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given a pre-trained classifier $f_{\\hat{\\theta}}$ trained on the source domain, leading test-time adaptation approaches build on the idea of self-training to update the model parameters sequentially. Denote the adapted classifier by $f_{\\hat{\\theta}\\pm\\omega}$ , where $\\omega$ represents the modification to the parameters of the original model $\\hat{\\theta}$ obtained by self-training during testing. The adaptation process is typically initialized with $j=1$ and $\\omega_{1}=\\mathbf{0}$ , and involves the following set of steps: ", "page_idx": 2}, {"type": "text", "text": "1. Observe a fresh test point $X_{j}^{t}$ and predict its unknown label using $f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t})$ .   \n2. Update the model parameters in a direction that reduces the self-supervised loss, i.e., ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\omega_{j+1}\\leftarrow\\omega_{j}-\\eta\\nabla_{\\omega}\\ell^{\\mathrm{self}}\\left(f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t})\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the hyper-parameter $\\eta$ is the step size. 3. Set $j\\leftarrow j+1$ and return to step 1. ", "page_idx": 2}, {"type": "text", "text": "A common choice for $\\ell^{\\mathrm{self}}$ in test-time adaptation methods is the entropy loss: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\ell^{\\mathrm{ent}}\\left(f_{\\hat{\\theta}+\\omega}(x)\\right)=-\\sum_{y=1}^{K}f_{\\hat{\\theta}+\\omega}(x)_{y}\\log(f_{\\hat{\\theta}+\\omega}(x)_{y}),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $f_{\\hat{\\theta}+\\omega}(x)_{y}$ is the $y$ -th entry of the classifier\u2019s softmax layer; we omit the index $j$ of $\\omega$ for clarity. While entropy minimization has been shown to enhance test-time robustness [36\u201343], it is also prone to instabilities [49\u201351, 68]. For instance, enforcing $f_{\\hat{\\theta}+\\omega}(x)_{y}=1$ for a fixed entry $y$ minimizes $\\ell^{\\mathrm{{ent}}}$ , but it collapses the classifier to make trivial predictions. To alleviate this, various strategies have been proposed. For example, one approach is to avoid training on samples with high entropy [42], as high entropy often correlates with erroneous pseudo labels. Another example is the utilization of a fallback mechanism that resets the adapted model back to the original model $f_{\\hat{\\theta}}$ when the average entropy becomes too small [43]. A more detailed review of test-time adaptation methods is given in Appendix A. Importantly, this line of work underscores the limitations of entropy minimization and highlights the need to better control its effect. This aligns with the goal of our work, which offers a distinct, statistically grounded approach for test-time adaptation. While we also build on the classifier\u2019s entropy to form the adaptation mechanism, we could integrate any alternative self-supervised loss in our online distributional matching scheme. ", "page_idx": 2}, {"type": "text", "text": "2.3 Testing by betting ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A key component of our method is the proposal of an online test for distribution drift. The design of this test follows the framework of testing-by-betting [69]. Intuitively, one can interpret this testing framework as participating in a fair game. We begin with initial toy money, and at each time step, we observe a new test point and place a bet against the null hypothesis we aim to test. If the bet turns out to be correct, our wealth increases by the money we risked in the bet; otherwise, we lose, and our wealth decreases accordingly. Mathematically, the wealth process is formulated as a non-negative martingale, where a successful betting scheme is reflected in a growing martingale (wealth) trajectory, offering progressively stronger statistical evidence against the null hypothesis. However, if the null hypothesis is true, the game must be fair in the sense that it is unlikely to significantly grow our initial capital, no matter how sophisticated our betting strategy may be. This implies that, under the null hypothesis, it is unlikely that the martingale will grow significantly beyond its initial value. ", "page_idx": 2}, {"type": "text", "text": "The testing-by-betting framework is widely used in sequential settings. Notable examples include: one and two sample tests [70, 71], independence and conditional independence tests [71\u201373], exchangeability tests [56, 74\u201378], and more [69, 79\u201392]. This framework is also used for change-point detection and testing for uniformity [57, 93\u201395], related to our drift detection problem. We draw inspiration from the protected probabilistic regression approach [61] that combines the probability integral transform and betting martingales to improve the robustness of a cumulative distribution function (CDF) estimator to distribution shift in the data. The experiments in [61] illustrate this method\u2019s ability to enhance the accuracy of a regression model, where this protection scheme assumes access to new up-to-date labels. In contrast, we focus on a completely different setup where the labels of the test points are unknown, showing how the protected regression approach can be generalized to form a self-supervised loss function. In turn, we introduce two key contributions to test-time adaptation via testing-by-betting. First, we present an adaptive online learning technique to optimize the betting mechanism. Second, we pioneer the application of testing-by-betting in this domain. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3 Proposed method: protected online entropy matching (POEM) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "3.1 Preview of our method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Let the random variable $Z^{s}=\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}}(X^{s}))$ be the entropy value of the original classifier applied to a fresh sample $X^{s}$ from the source domain. We refer to this variable as the source entropy. In addition, denote by $Z_{j}^{t}=\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t}))$ , $j=1,2,\\ldots$ a sequence of entropy values generated by the updated model, evaluated on a stream of unlabeled test data. We refer to $Z^{t}$ as the target entropy. Our proposal uses the source and target entropies both to detect distribution shifts and adapt the model to new testing environments without relying on up-to-date labeled data. The rationale behind our method is as follows: when test data is sampled from the source distribution, there will be no deviation between the source and target entropies, implying that there is no need to adapt the model. However, statistical deviations between the source entropies $Z^{s}$ and target entropies ${\\bar{Z}}^{t}$ can indicate that the model encounters test data different from the training distribution. This motivates us to introduce a self-training framework that encourages the model to generate test-time entropies $Z^{t}$ that closely resemble the source entropies $Z^{s}$ to build invariance to shifting data. ", "page_idx": 3}, {"type": "text", "text": "To achieve this goal, we utilize the testing-by-betting approach and formulate our adaptation scheme as a game, in which we start with initial toy money and proceed as follows. ", "page_idx": 3}, {"type": "text", "text": "1. Place a bet against the null hypothesis that the unknown classifier entropy $Z_{j}^{t}$ of the upcoming test point $X_{j}^{t}$ will follow the same distribution as the source entropies $Z^{s}$ .   \n2. Observe the test point $X_{j}^{t}$ , predict its label using the model $f_{\\hat{\\theta}+\\omega_{j}}$ , and compute the classifier\u2019s entropy $Z_{j}^{t}=\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t}))$ .   \n3. Given $Z_{j}^{t}$ , reveal the outcome of the bet using a betting function. If the bet is successful, increase the accumulated wealth; otherwise, decrease it.   \n4. Leverage the betting function to obtain an adapted pseudo-entropy value ${\\tilde{Z}}_{j}$ that better matches the distribution of $Z^{s}$ . The intuition here is that we derive ${\\tilde{Z}}_{j}$ in a way that would reduce the toy money we would have gained if we had used the same betting strategy on ${\\tilde{Z}}_{j}$ .   \n5. Update the model parameters: obtain $\\omega_{j+1}$ by taking a gradient step that reduces the self-supervised matching loss:2 ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell^{\\mathrm{match}}(Z_{j}^{t},\\tilde{Z}_{j})=\\frac{1}{2}(\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t}))-\\tilde{Z}_{j})^{2}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "6. Update the betting strategy for the next round and return to Step 1. ", "page_idx": 3}, {"type": "text", "text": "In the following sections, we describe in detail each component of the proposed adaptation scheme. Before proceeding, however, we pause to highlight the advantages of the matching loss (2) over entropy minimization. ", "page_idx": 3}, {"type": "text", "text": "3.2 Motivating example: entropy minimization vs. entropy matching ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To facilitate the exposition of the proposed loss, it is useful to consider a toy, binary classification example with a one-dimensional input $X$ in which we have oracle access both to the source $P_{X Y}^{s}$ and a fixed target distribution $P_{X Y}^{t}$ that does not vary over time. We commence by generating training data from $P_{X Y}^{s}$ , where $P(\\stackrel{\\ast}{Y}^{-}=1)\\,=\\,P(Y\\,=\\,\\stackrel{\\cdot}{-1})$ and P sX|Y = N(Y s, 1). See Figure 1 for an illustration of the source distribution. Throughout this experiment, we set the pre-trained Gaussian classifier $f_{\\hat{\\theta}}$ to be the Bayes optimal one for which $\\bar{\\theta}=\\bar{0}$ , and during test-time we optimize the parameter $\\omega$ of the updated classifier. Since ${\\hat{\\theta}}=0$ , in this case $f_{\\hat{\\theta}+\\omega}$ is simplified to $f_{\\omega}$ . Further implementation details are provided in Appendix F. ", "page_idx": 3}, {"type": "text", "text": "As mentioned before, one of the advantages of our approach is its \u201cno-harm\u201d effect, i.e., when $P_{X Y}^{s}=P_{X Y}^{t}$ we ideally want to keep the decision boundary of the classifier intact. The red curve in Figure 1 illustrates the entropy matching risk $\\mathbb{E}_{X^{t}}[\\ell^{\\mathrm{match}}(Z,\\tilde{Z})]$ as a function of the classifier parameter $\\omega$ . In this synthetic case, the ideal entropy matching risk can be evaluated since we have access to the generating distribution: we can obtain the ideal pseudo-entropy ${\\tilde{Z}}^{t}$ , given by $\\tilde{Z}=F_{s}^{-1}(F_{t}(Z^{t};\\bar{f_{\\omega}}))$ , where $F_{s}$ and $F_{t}$ are the CDF functions of the source and target entropy values, respectively; the formula above is nothing but the optimal transport map. Of course, in the practical online setting we consider in this work, $F_{t}$ is unknown and varies over time. In fact, this is also true in the case studied here as the distribution of $Z^{t}=f_{\\omega}(X^{t})$ varies with $\\omega$ , highlighting the importance of our online, adaptive testing procedure. Indeed, the $\\omega$ obtained by our online adaptation scheme (POEM) minimizes the entropy matching risk and remains close to 0, as desired. ", "page_idx": 3}, {"type": "image", "img_path": "qamfjyhPeg/tmp/361d05b3a03088baf27ab8e4559f513b807631ce907e11012a94d74a0fa88439.jpg", "img_caption": ["Figure 1: Demonstration of the advantage of entropy matching on toy binary classification problem with Gaussian data. The top panel represents an in-distribution setup in which $P_{X Y}^{t}=$ $P_{X Y}^{s}$ . The bottom panel illustrates an out-of-distribution setup, obtained by shifting the two Gaussians. The entropy matching (red) and entropy minimization (black) risks are presented as a function of $\\omega$ . The dashed yellow line presents the decision boundary of the pre-trained classifier. The points marked by stars correspond to the decision boundary of the adapted classifiers. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Meanwhile, the black curve in Figure 1 illustrates the values of the entropy risk $\\mathbb{E}_{X^{t}}[\\ell^{\\mathrm{ent}}(Z^{t})]$ for varying $\\omega$ . In contrast with our approach, the $\\omega$ that minimizes the entropy risk is far from the optimal classifier. This approach results in a collapse towards a trivial classifier that always predicts $-1$ , regardless of the value of $X^{t}$ . Moving to an out-of-distribution scenario, where we consider test data sampled from a shifted version of the two Gaussians such that $Y^{t}=Y^{s}$ and $X^{t}=X^{s}+1$ . Following the bottom panel in Figure 1, it is evident that by minimizing the proposed entropy matching risk, the accuracy of the original (not adapted) classifier is effectively restored. In contrast, the entropy minimization paradigm once again collapses the model to make trivial predictions. ", "page_idx": 4}, {"type": "text", "text": "3.3 Online drift detection ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now turn to introduce a rigorous monitoring tool that is capable of detecting whether the distribution of the adapted classifier\u2019s entropy values $Z^{t}$ , obtained at test time, deviate from $Z^{s}$ \u2014the source entropies obtained by applying the original model to the source data. To detect such shifts, we assume that we have access to $F_{s}$ , the CDF of the source entropy values $Z^{s}=\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}}(X^{s}))$ . In practice, we estimate this CDF using holdout unlabeled samples $X^{s}$ from the source distribution. Armed with $F_{s}$ , we then apply the probability integral transform [96], allowing us to convert any sequence of i.i.d. entropy values from the source distribution $Z_{1}^{s},Z_{2}^{s},\\ldots$ into a sequence of i.i.d. uniform random variables $F_{s}(Z_{1}^{s}),F_{s}(Z_{2}^{s}),\\ldots$ on the $[0,1]$ interval. Therefore, if we observe a sequence $F_{s}(Z_{1}^{t}),F_{s}(Z_{2}^{t}),\\,\\cdot\\,\\cdot\\,.$ of i.i.d. uniform variables at test time, we can infer that the target entropy distribution matches the source entropy distribution. Thus, if the sequence of transformed variables $F_{s}(Z_{1}^{t}),F_{s}(Z_{2}^{t}),\\,\\cdot\\,\\cdot\\,.$ deviates from the uniform distribution, we can infer that the corresponding target domain samples $Z_{1}^{t},Z_{2}^{t},\\ldots$ differ from the source distribution. This observation lies at the core of our monitoring tool [61]. ", "page_idx": 4}, {"type": "text", "text": "Specifically, we leverage the testing-by-betting approach to design a sequential test for the following null hypothesis: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{H}_{0}:u_{j}\\triangleq F_{s}(Z_{j}^{t})\\sim\\mathcal{U}[0,1],\\quad\\forall j\\in\\mathbb{N},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $Z_{j}^{t}=\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t}))$ . In words, we continuously monitor the sequence of random variables $u_{1},u_{2},\\ldots$ and test whether these deviate from the uniform null. We do so by formulating a test martingale, defined as follows. ", "page_idx": 5}, {"type": "text", "text": "Definition 1 (Test Martingale). A random process $\\{S_{j}:j\\in\\mathbb{N},S_{0}=1\\}$ is a test martingale for the null hypothesis $\\mathcal{H}_{0}$ if it satisfies the following: ", "page_idx": 5}, {"type": "equation", "text": "$$\nl.\\;\\;S_{j}\\geq0\\;\\;\\;\\forall j\\in\\mathbb{N}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The martingale can be thought of as the wealth process in the game-theoretical interpretation of the test, obtained by betting toy money against $\\mathcal{H}_{0}$ as new data points arrive. We initialize this game with $S_{0}=1$ , and update the wealth process as follows [61]: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{S_{j}(u_{j})\\triangleq S_{j-1}\\cdot b(u_{j})\\quad\\mathrm{where}\\quad b(u_{j})=1+\\epsilon_{j}(u_{j}-0.5).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Above, $b(u)\\in[0,2]$ is the betting function. The betting variable $\\epsilon_{j}\\in[-2,2]$ controls how aggressive the bet is, and it can be determined based on past observations $u_{1},\\dotsc,u_{j-1}$ , as we detail later in this section. However, before introducing our strategy to update $\\epsilon_{j}$ over time, we should first discuss the properties of the betting function $\\bar{b(u_{j})}$ . The idea behind this choice is that we sequentially test whether the sequence of $u_{1},\\dotsc,u_{j}$ observed up to time step $j$ has mean 0.5. Indeed, if the null is true, $\\mathbb{E}_{\\mathcal{H}_{0}}[u]\\stackrel{\\cdot}{=}0.5$ and thus $\\mathbb{E}_{\\mathcal{H}_{0}}[b(u)]=1$ . As a result, under the null, the martingale is unlikely to grow significantly beyond its initial value\u2014this is a consequence of Ville\u2019s inequality; see Appendix D. However, if the null is false, we can gather evidence against the uniform null hypothesis by placing more aggressive bets, especially when past observed values $u_{1},\\dotsc,u_{j-1}$ deviate significantly from 0.5. This highlights the role of $\\epsilon_{j}$ , controlling the value and direction of our wagers in each round, betting on whether $u_{j}$ would be over/under 0.5. Following (4), when $\\epsilon_{j}$ and $(u_{j}-0.5)$ have the same sign, we win the bet and obtain $b(u_{j})>1$ . This implies that our capital increase as $S_{j}(u_{j}):=\\,S_{j-1}\\cdot\\bar{b}(u_{j})$ . Notice that, in this case, a larger $\\epsilon_{j}$ (in absolute value) will allow us to increase the capital more rapidly, resulting in a more powerful test. However, if $\\epsilon_{j}$ and $(u_{j}-0.5)$ have different signs, we lose the bet and obtain $b(u_{j})<1$ . Here, a larger $\\epsilon_{j}$ would incur a more significant loss of capital. The challenge in choosing $\\epsilon_{j}$ lies in the restriction that $\\epsilon_{j}$ can only be determined based on past experience, i.e., we must set its value without looking at the new $u_{j}$ . This restriction is crucial to ensure the validity of the martingale, as detailed in the following proposition. ", "page_idx": 5}, {"type": "text", "text": "Proposition 1. The random process presented in (4) is a valid test martingale for $\\mathcal{H}_{0}$ (3). ", "page_idx": 5}, {"type": "text", "text": "The proof is given in Appendix C.1; it is a well-known result, see, e.g., [61]. This property is crucial to form the proposed online distributional matching mechanism, introduced in the next section. Appendix D provides further details on how the test martingale is used for distribution shift detection. ", "page_idx": 5}, {"type": "text", "text": "We now turn to present an adaptive approach to set the betting variable $\\epsilon_{j}$ in a manner that enables powerful detection of drifting target entropies. This is especially important given the dynamic nature of both the target data and the continuous, online updates of the model. To achieve this, we adopt an online learning technique to learn $\\epsilon_{j}$ from past observations, with the goal of maximizing the wealth by minimizing the negative log of the wealth process up to step $j$ [70]: ", "page_idx": 5}, {"type": "equation", "text": "$$\n-\\log(S_{j}(u_{j}))=-\\log\\prod_{\\tau=1}^{j}b_{\\tau}(u_{\\tau})=-\\sum_{\\tau=1}^{j}\\log(b_{\\tau}(u_{\\tau}))=-\\sum_{\\tau=1}^{j}\\log(1+\\epsilon_{\\tau}(u_{\\tau}-0.5)).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "This formulation allows us to learn how to predict $\\epsilon_{j}$ using past samples via gradient descent [70]. ", "page_idx": 5}, {"type": "text", "text": "Specifically, our optimization approach relies on the scale-free online gradient descent (SF-OGD) algorithm [59]. Importantly, extending SF-OGD to our setting is not straightforward, since $\\epsilon_{j}$ must be in the range of $[-2,2]$ to form a valid test martingale. In the interest of space, we present this algorithm and its theoretical analysis in Appendix $\\mathbf{B}$ and only highlight here its key feature. SF-OGD allows us to attain an anytime regret guarantee, which is presented formally in Theorem 1 of the Appendix. This guarantee bounds the difference between the negative log of the wealth process (i) obtained by the predicted $\\epsilon_{t}$ over time horizon $1\\leq t\\leq j$ , and (ii) obtained by the best betting variable $\\epsilon^{\\star}$ that can only be calculated in hindsight, after \u221alooking at the data up to time $1\\leq t\\leq j$ . Informally, our theory shows this regret is bounded by $c\\cdot{\\sqrt{t}}$ for all $1\\leq t\\leq j$ , where the constant $c$ depends on the problem parameters; it is formulated precisely in Theorem 1. In turn, the anytime regret guarantee confirms that our SF-OGD approach effectively learns $\\epsilon_{j}$ , capturing the dynamic changes of both the target distribution and the model $f_{\\hat{\\theta}+\\omega_{j}}$ in a fully online setting. ", "page_idx": 5}, {"type": "text", "text": "3.4 Online model adaptation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Having established a powerful betting strategy, we now turn to show how to transform the test martingale $\\{S_{j}:j\\in\\mathbb{N}\\}$ into a sequence of adapted pseudo-entropy values $\\tilde{Z}_{1},\\tilde{Z}_{2},\\dots$ that better match the distribution of $Z^{s}$ . In what follows, we describe an algorithm to obtain ${\\tilde{Z}}_{j}$ , which draws inspiration from [61], and then connect this procedure to optimal transport. ", "page_idx": 6}, {"type": "text", "text": "Our adaptation scheme leverages the fact that any valid betting function is essentially a likelihood ratio [61, 82]. This property implies that our betting function $b(u_{j})=1+\\epsilon_{j}(u_{j}-0.5)$ satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\nb(u_{j})=\\frac{d Q(u_{j})}{d G(u_{j})},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $d Q(u_{j})$ and $d G(u_{j})$ are the densities of some alternative distribution $Q$ and the null distribution $G$ , respectively. In our case, the null distribution $G$ is the uniform distribution Uniform $(0,1)$ , and the alternative distribution $Q$ can be intuitively thought of as an approximation of the unknown target entropy\u2019s CDF; we formalize this intuition hereafter. Leveraging this likelihood ratio interpretation, we follow [61] and extract the alternative distribution $Q$ by re-writing (6) as $d Q(u_{j})=b(u_{j})\\cdot d G(u_{j})$ and computing the integral: ", "page_idx": 6}, {"type": "equation", "text": "$$\nQ(u_{j})=\\int_{0}^{u_{j}}b(v)d G(v)d v=\\int_{0}^{u_{j}}b(v)\\cdot1\\cdot d v=\\frac{1}{2}\\epsilon_{j}\\cdot u_{j}^{2}+(1-\\frac{\\epsilon_{j}}{2})\\cdot u_{j}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Above, we used the fact that the null density is $d G(v)$ equals 1 over the support $[0,1]$ . Having access to $Q$ , we can compute the adapted $\\tilde{u}_{j}:=Q(u_{j})$ that can be intuitively interpreted as the result of applying the probability integral transform to $Z_{j}^{t}$ using the estimated target entropy CDF. With this intuition in place, we can further convert $\\tilde{u}_{j}$ into a pseudo-entropy value $\\tilde{Z}_{j}^{t}$ that better matches the distribution of the source entropies. This is obtained by applying the inverse source CDF to $\\Tilde{u}_{j}$ , resulting in $\\tilde{Z}_{j}=F_{s}^{-1}(Q(u_{j}))$ . Observe that we assume here that $F_{s}$ is invertible, however, in practice, we compute the pseudo-inverse of $F_{s}$ . ", "page_idx": 6}, {"type": "text", "text": "To connect the adaptation scheme presented above to the optimal transport map between the target and source entropies, it is useful to consider an ideal case where we use the log-optimal bet for testing a point null [82]. In our case, the null hypothesis is that the distribution of the source entropies $Z^{s}$ and target entropies $Z_{j}^{t}$ is the same, which implies $\\mathcal{H}_{0}$ in (3). Following [82], the optimal bet for our null is the true likelihood ratio, formulated as ", "page_idx": 6}, {"type": "equation", "text": "$$\nb_{Z}^{\\mathrm{opt}}(Z_{j}^{t})\\triangleq\\frac{d F_{t}^{j}(Z_{j}^{t})}{d F_{s}(Z_{j}^{t})},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $F_{t}^{j}$ is the CDF of the target entropy $Z_{j}^{t}$ . To align with (6), we can equivalently write $b_{Z}^{\\mathrm{opt}}(Z_{j}^{t})$ as a betting function that gets $u_{j}$ as an input [61, Lemma 1]: ", "page_idx": 6}, {"type": "equation", "text": "$$\nb_{Z}^{\\mathrm{opt}}(Z_{j}^{t})=b_{Z}^{\\mathrm{opt}}(F_{s}^{-1}(u_{j}))=\\frac{d F_{t}^{j}(F_{s}^{-1}(u_{j}))}{d F_{s}(F_{s}^{-1}(u_{j}))}\\triangleq\\frac{d Q^{\\mathrm{opt}}(u_{j})}{d G^{\\mathrm{opt}}(u_{j})}=b_{u}^{\\mathrm{opt}}(u_{j}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Notably, this optimal betting function is infeasible to compute in practice, as $F_{t}^{j}$ is unknown. Yet, it implicitly suggests that more powerful betting functions could result in a better estimate of the target entropy CDF. Also, the optimal betting function reveals an important property of our adaptation scheme, formally given below. ", "page_idx": 6}, {"type": "text", "text": "Proposition 2. Let $X_{j}^{t}$ be a fresh sample from the target domain with its corresponding $Z_{j}^{t}\\,=$ $\\ell^{\\mathrm{ent}}\\big(f_{\\hat{\\theta}+\\omega}(X_{j}^{t})\\big)$ and $u_{j}^{\\bar{}}=F_{s}(Z_{j}^{t})$ . Assume $F_{s}$ is invertible and $Z_{j}^{t}$ is continuous, and suppose the betting function represents the true likelihood ratio (9). Then, the adapted $\\tilde{Z}_{j}^{t}=F_{s}^{-1}(Q^{\\mathrm{opt}}(u_{j}))$ is the optimal transport map from target to source entropies with respect to the Wasserstein distance. ", "page_idx": 6}, {"type": "text", "text": "The proof of this proposition builds on [61, Lemma 1] and is provided in Appendix C.4. This result highlights that our online, martingale-based adaptation scheme is grounded in optimal transport principles. This, in turn, provides a principled way to minimize the discrepancy between probability distributions. Leveraging this connection, the entropy matching loss function (2), which we employ to self-train the model, can be understood as minimizing the discrepancy between the entropy distributions of the source and target domains. This implies that our loss function aligns the model\u2019s predictions across these domains. This connection also explains the \u201cno-harm\u201d effect of the proposed loss. When $P_{X Y}^{s}=P_{X Y}^{t}$ we get that $Q^{\\mathrm{opt}}(u_{j})=G^{\\mathrm{opt}}(\\bar{u}_{j})=u_{j}$ in the ideal case of (9), implying that $\\tilde{Z}_{j}^{t}=Z_{j}^{t}$ . In practice, considering the betting function from (4), we anticipate that $\\epsilon_{j}$ will be close to zero thanks to our online optimization scheme, which, in turn, results in $Q(u_{j})\\approx u_{j}$ in (7). ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "3.5 Putting it all together ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Algorithm 2 in the Appendix summarizes the entire adaptation process of POEM. This algorithm starts by computing the empirical CDF $\\hat{F}_{s}$ of the source entropies to estimate $F_{s}$ , using unlabeled holdout samples from the source domain (line 6). The betting and pseudo-entropy estimation steps are presented in lines 12\u201314. Observe that in line 14 we use the pseudo-inverse of $\\hat{F}_{s}$ to obtain ${\\tilde{Z}}_{j}$ . The algorithm then proceeds to adapt the classifier\u2019s parameters in a direction that minimizes our self-supervised loss (line 15). Specifically, we only update the parameters of the normalization layers $\\omega$ of the classifier $f_{\\hat{\\theta}+\\omega}$ , which is a common practice in the test-time adaptation literature [41\u201343]. The self-training step is done by minimizing a variation of the entropy matching loss $\\ell^{\\mathrm{match}}$ (2): ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\ell_{\\lambda}^{\\mathrm{mateh+}}(Z_{j}^{t},\\tilde{Z}_{j})=\\ell^{\\mathrm{match}}(Z_{j}^{t},\\tilde{Z}_{j})\\cdot\\frac{\\mathbb{1}[Z_{j}^{t}<\\lambda]}{\\exp\\big\\{2\\cdot(Z_{j}^{t}-\\lambda)\\big\\}},\\:\\:\\mathrm{where}\\:\\:Z_{j}^{t}=\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t})).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The above loss function includes an additional sample-filtering $\\mathbb{I}[Z_{j}^{t}<\\lambda]$ and sample-weighting $1/\\exp\\{2\\cdot(Z_{j}^{t}-\\lambda)\\}$ components, where $\\lambda>0$ is a pre-defined thresholding parameter. The sampleflitering idea is widely used in this literature [42, 43], as the predictions of samples with high entropy examples tend to be inaccurate. Aligning with this intuition, the sample-weighting gives a higher weight to samples with low entropies [42]. Finally, we predict a new betting parameter $\\epsilon_{j}$ for the next iteration by applying an SF-OGD step (line 16). ", "page_idx": 7}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We conduct a comprehensive evaluation of POEM across a diverse range of datasets and scenarios commonly used in test-time adaptation literature. Our experiments span ImageNet, ImageNet-C, CIFAR10-C, and CIFAR100-C datasets for evaluating the robustness to shifts induced by corruptions, and the Office-Home dataset for domain adaptation. We study the performance of our method in both single-shift and continual-shift settings. Our evaluation demonstrates that POEM is highly competitive with leading baseline test-time adaptation methods in terms of accuracy and runtime. In the interest of space, this section focuses on the results for the ImageNet dataset, as it is the most challenging one among those considered. Details and results for the experiments on CIFAR and Office-Home datasets are provided in Appendices F.3 and F.4, respectively. ", "page_idx": 7}, {"type": "text", "text": "Throughout this section we use the test set of ImageNet to form our in-distribution dataset, and utilize ImageNet-C\u2014which contains 15 different types of corruptions at five increasing severity levels\u2014to simulate various out-of-distribution scenarios. Notably, since the images in ImageNet-C are variations of the same images from the ImageNet test set, our experiments simulate a realistic out-of-distribution test set by including only a single corrupted version of each image. To demonstrate the versatility of POEM, we consider two pre-trained classifiers $f_{\\hat{\\theta}}$ of different architectures: Vision Transformer (ViT) [63] with layer norm (LN) and ResNet50 [64] with group norm (GN). We compare POEM to four leading entropy minimization methods\u2014TENT [41], EATA [42], SAR [43], and COTTA [97]\u2014using code provided by the authors. Importantly, all adaptation methods update only the normalization parameters (LN/GN) of the model, ensuring a fair comparison. Following [43], we employ a fully online setting with a batch size of 1, in which the model is updated after observing a new test sample; see Appendix F.2 for implementation details and choice of hyper-parameters. In the interest of space, we defer the results obtained by the ResNet classifier to Appendix F.2.1 and focus here on the results obtained by the ViT model. ", "page_idx": 7}, {"type": "text", "text": "Continual shifts Inspired by [97, 98], we evaluate our approach in a continual setup in which sudden distribution shifts occur during testing. To simulate this, we create a test set of 15,000 samples by randomly selecting 1,000 samples from each corruption type at a fixed severity level (a corruption segment) and concatenating all 15 segments to form the test data. We apply all adaptation methods in combination with a ViT model and present the results in Figure 2. Following the bottom panel in that figure, one can see that POEM achieves higher accuracy than all of the benchmark methods. Next, we investigate how quickly our method adapts the model to new shifts by varying the segment size of each corruption. As shown in Figure 2 (bottom right), POEM exhibits faster adaptation than the baseline methods. It successfully enhances the accuracy of the pre-trained model with as few as 100 examples per corruption (test set of size 1,500) as well as with longer adaptation using 2,000 examples per corruption (test set of size 30,000). Finally, we explore another realistic scenario of continual adaptation by varying the severity level every 1,000 samples while keeping a fixed corruption type. The bottom left and center panels in Figure 2 show that POEM outperforms the best baseline method (EATA) in this setting as well. Lastly, similar experiments conducted with a ResNet model are presented in Figure 5 in the Appendix, showing that our method attains faster adaptation and superior accuracy than the baseline methods. ", "page_idx": 7}, {"type": "image", "img_path": "qamfjyhPeg/tmp/62df18aab3ceceac81390a3aa5d2e3c20141ac4938b38add119cb321955481e9.jpg", "img_caption": ["Figure 2: Continual test-time adaptation on ImageNet-C with a ViT model. Top: Per-corruption accuracy with a corruption segment size of 1,000 examples. Results are obtained over 10 independent trials; error bars are tiny. Bottom left and center: Severity shift\u2014low (1) to high (5) and back to low (left), and high (5) to low (1) and back to high (center). To improve the readability here, we only present POEM, the best-performing baseline method (EATA), and the no-adapt approach. Bottom right: Mean accuracy under continual corruptions as a function of the corruption segment size. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Single shift We now consider a scenario with a single corruption type of a fixed severity level, which follows [41, 43, 99]. Table 1 summarizes the average results across all corruptions for severity level 5, demonstrating that POEM achieves an average accuracy of $67.36\\%$ for the ViT model, outperforming the best baseline method (EATA) with an absolute average accuracy gap of $3.22\\%$ . A detailed breakdown by corruption type for each classifier is provided in Table 2 in the Appendix. Notably, POEM outperforms all benchmark methods on all corruption types for ViT, while achieving higher test accuracy in 9 out of the 15 corruption types for the ResNet model. ", "page_idx": 8}, {"type": "text", "text": "In distribution In this setting, we apply all methods on the validation set of the ImageNet dataset. Following Table 3 in the Appendix, all the methods maintain a similar accuracy as the original model, however, the baseline methods tend to increase the expected calibration error (ECE) [68, 100] and unnecessarily modify the model\u2019s parameters, as measured by $\\|\\boldsymbol{\\omega}\\|_{2}^{F}$ . In contrast, following Figure 3 (left panel), POEM exhibits minimal changes both for ECE and model parameters, as desired. Figure 6 in the Appendix leads to similar conclusions for the ResNet model. ", "page_idx": 8}, {"type": "text", "text": "Additional experiments on ImageNet, including ablation study The right panel of Figure 3 plots the value of the betting parameter $\\epsilon$ over time, for both in- and out-of-distribution scenarios. Observe how $\\epsilon$ remains near zero under the in-distribution setting, explaining the minimal change in accuracy, ECE, and model\u2019s parameters $\\|\\omega\\|_{F}^{2}$ , presented in the left panel of Figure 3. By contrast, when considering out-of-distribution test data of a single shift, we can see that $\\epsilon$ is high at the beginning and gradually reduces over time, indicating that the self-training process adapts the model to the new environment. A similar behavior is observed for the ResNet model; see Figure 6 in the Appendix. This conclusion is further supported by Figure 7 in the Appendix, showing that the CDF of the target entropies of the adapted ResNet model nearly matches the CDF of the source entropies. In Figure 4 of the Appendix we show how the martingale can powerfully detect shifts\u2014even a minor one (brightness with severity level 1)\u2014and also show how our adaptation mechanism gradually limits the martingale\u2019s growth. Lastly, we conduct an ablation study, comparing the test accuracy of POEM using two loss functions: $\\ell^{\\mathrm{match}}$ (2) and $\\ell^{\\mathrm{match++}}$ (10). Table 4 in the Appendix presents these results for a single shift scenario, averaged over 15 corruptions of ImageNet-C at the highest severity level. Both losses improve the original model accuracy, with $\\ell^{\\mathrm{match++}}$ showing better adaptation performance. ", "page_idx": 8}, {"type": "image", "img_path": "qamfjyhPeg/tmp/0551f4a99f3d58a60a04e750e297b1b3e1d15cf1f22be7d2e3efed6e30992ca4.jpg", "img_caption": ["Figure 3: In-distribution experiment on ImageNet (left panel): calibration error (ECE [100]) versus $\\|\\omega\\|_{F}^{2}$ \u2014a metric that evaluates the classifier\u2019s parameters deviation from the original ViT model. Lower values on both axes are better. Results are averaged across 10 independent trials; standard errors and accuracy of each method are reported in Table 3 in the appendix. The behavior of the betting parameter (right panel): the value of $\\epsilon$ is presented as a function of time for both inand out-of-distribution experiments (a single shift, two severity levels). "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Experiments on CIFAR-10C, CIFAR100-C, and OfficeHome datasets, sensitivity study, and runtime comparisons Appendices F.3 and F.4 present experiments on these additional datasets, leading to similar conclusions about the competitive adaptation accuracy of POEM compared to baseline methods. Notably, Appendix F.3 includes experiments on both relatively short and long adaptation streams, with lengths of 15,000 and 112,500 samples, respectively. These experiments also include a sensitivity study on the learning rate $\\eta$ used for self-training the model, showing that POEM exhibits greater stability across different learning rate values compared to SAR and TENT. Additionally, these experiments show that POEM\u2019s runtime is comparable to TENT and EATA, and faster than SAR. ", "page_idx": 9}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We introduced a novel, martingale-based approach for test-time adaptation that drives the test-time entropies of the self-trained model to match the distribution of source entropies. We validated our approach with numerical experiments, demonstrating that: (i) under in-distribution settings, POEM maintains the performance of the source model while avoiding overconfident predictions, a crucial advantage over entropy minimization methods; (ii) in relatively short out-of distribution test periods, our approach achieves faster adaptation than entropy minimization methods, which is attributed to our betting scheme that quickly reacts to distribution shifts; and (iii) in extended test periods, POEM achieves comparable adaptation performance and stability to strong baseline methods. ", "page_idx": 9}, {"type": "text", "text": "One limitation of our method is the requirement for holdout unlabeled source domain data to estimate the source CDF. Notably, this CDF is pre-computed offline, and at test time we do not require additional access to source data, similar to EATA\u2019s requirements. Another limitation of our approach is the choice of hyperparameters, particularly the self-training learning rate $\\eta$ . However, our sensitivity study showed that our method is fairly robust to this choice, especially compared to baseline methods. Lastly, similar to other experimental works, we anticipate that POEM may fail to improve accuracy in settings that we have not explored, especially when facing an aggressive shift. Yet, our monitoring tool can detect such distribution shifts, which is an important mechanism that does not appear in other test-time adaptation methods. ", "page_idx": 9}, {"type": "text", "text": "Future directions are discussed in Section G of the Appendix. Lastly, we note that while the goal of this paper is to enhance the robustness of ML to unseen environments, there are many potential societal consequences of our method, similar to other works that aim to advance this field. ", "page_idx": 9}, {"type": "text", "text": "6 Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 729/21). Y. R.   \nthanks the Career Advancement Fellowship, Technion. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7201\u20137211, June 2022.   \n[2] Thomas Varsavsky, Mauricio Orbes-Arteaga, Carole H Sudre, Mark S Graham, Parashkev Nachev, and M Jorge Cardoso. Test-time unsupervised domain adaptation. In International Conference in Medical Image Computing and Computer Assisted Intervention, pages 428\u2013436. Springer, 2020. [3] Abolfazl Farahani, Sahar Voghoei, Khaled Rasheed, and Hamid R Arabnia. A brief review of domain adaptation. Advances in data science and information engineering, pages 877\u2013894, 2021. [4] Garrett Wilson and Diane J Cook. A survey of unsupervised deep domain adaptation. ACM Transactions on Intelligent Systems and Technology (TIST), 11(5):pp. 1\u201346, 2020.   \n[5] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In Proceedings of the International Conference on Machine Learning, pages 1180\u20131189. PMLR, 2015.   \n[6] Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):pp. 53\u201369, 2015.   \n[7] Wouter M Kouw and Marco Loog. An introduction to domain adaptation and transfer learning. arXiv preprint arXiv:1812.11806, 2018. [8] Xingchao Peng, Ben Usman, Neela Kaushik, Dequan Wang, Judy Hoffman, and Kate Saenko. Visda: A synthetic-to-real benchmark for visual domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 2021\u20132026, 2018.   \n[9] Kun Zhang, Bernhard Sch\u00f6lkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation under target and conditional shift. In Proceedings of the International Conference on Machine Learning, pages 819\u2013827. PMLR, 2013.   \n[10] Vidit Jain and Erik Learned-Miller. Online domain adaptation of a pre-trained cascade of classifiers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 577\u2013584. IEEE, 2011.   \n[11] Xiaofeng Liu, Chaehwa Yoo, Fangxu Xing, Hyejin Oh, Georges El Fakhri, Je-Won Kang, and Jonghye Woo. Deep unsupervised domain adaptation: A review of recent advances and perspectives. APSIPA Transactions on Signal and Information Processing, 11, 2022.   \n[12] John Blitzer, Ryan McDonald, and Fernando Pereira. Domain adaptation with structural correspondence learning. In Proceedings Conference on Empirical Methods in Natural Language Processing, pages 120\u2013128, 2006.   \n[13] Yongjie Shi, Xianghua Ying, and Jinfa Yang. Deep unsupervised domain adaptation with time series sensor data: A survey. Sensors, 22(15), 2022.   \n[14] Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence. Dataset Shift in Machine Learning. The MIT Press, 2009.   \n[15] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2018.   \n[16] Jeya Maria Jose Valanarasu, Pengfei Guo, Vibashan VS, and Vishal M. Patel. On-the-fly test-time adaptation for medical image segmentation. arXiv preprint arXiv:2203.05574, 2022.   \n[17] Yanyu Ye, Zhenxi Zhang, Wei Wei, and Chunna Tian. Multi task consistency guided source-free test-time domain adaptation medical image segmentation. arXiv preprint arXiv:2310.11766, 2023.   \n[18] Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu. Test-time adaptable neural networks for robust medical image segmentation. Medical Image Analysis, 68:101907, 2021.   \n[19] Yufan He, Aaron Carass, Lianrui Zuo, Blake E Dewey, and Jerry L Prince. Autoencoder based self-supervised test-time adaptation for medical image analysis. Medical Image Analysis, 72:102136, 2021.   \n[20] Zhang Li, Zheng Zhong, Yang Li, Tianyu Zhang, Liangxin Gao, Dakai Jin, Yue Sun, Xianghua Ye, Li Yu, Zheyu Hu, Jing Xiao, Lingyun Huang, and Yuling Tang. From community-acquired pneumonia to COVID-19: a deep learning\u2013based method for quantitative analysis of COVID19 on thick-section CT scans. European Radiology, 30(12):6828\u20136837, 2020.   \n[21] Jian Liang, Ran He, and Tieniu Tan. A comprehensive survey on test-time adaptation under distribution shifts. arXiv preprint arXiv:2303.15361, 2023.   \n[22] Prashant Pandey, Mrigank Raman, Sumanth Varambally, and Prathosh AP. Generalization on unseen domains via inference-time label-preserving target projections. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12924\u201312933, June 2021.   \n[23] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. ICCV, 2021.   \n[24] Marvin Zhang, Sergey Levine, and Chelsea Finn. MEMO: Test time robustness via adaptation and augmentation. Advances in neural information processing systems, 35:38629\u201338642, 2022.   \n[25] Xuefeng Hu, Gokhan Uzunbas, Sirius Chen, Rui Wang, Ashish Shah, Ram Nevatia, and Ser-Nam Lim. Mixnorm: Test-time adaptation through online normalization estimation. arXiv preprint arXiv:2110.11478, 2021.   \n[26] Saypraseuth Mounsaveng, Florent Chiaroni, Malik Boudiaf, Marco Pedersoli, and Ismail Ben Ayed. Bag of tricks for fully test-time adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1936\u20131945, 2024.   \n[27] Eric Mintun, Alexander Kirillov, and Saining Xie. On interaction between augmentations and corruptions in natural corruption robustness. Advances in Neural Information Processing Systems, 34:3571\u20133583, 2021.   \n[28] Liang Chen, Yong Zhang, Yibing Song, Ying Shan, and Lingqiao Liu. Improved test-time adaptation for domain generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 24172\u201324182, 2023.   \n[29] Minmin Chen, Kilian Q Weinberger, and John Blitzer. Co-training for domain adaptation. Advances in neural information processing systems, 24:2456\u20132464, 2011.   \n[30] Yuanyuan Xu, Meina Kan, Shiguang Shan, and Xilin Chen. Mutual learning of joint and separate domain alignments for multi-source domain adaptation. In WACV, pages 1890\u20131899, 2022.   \n[31] Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang. Unsupervised domain adaptation for semantic segmentation via class-balanced self-training. In Proceedings of the European conference on computer vision (ECCV), pages 289\u2013305, 2018.   \n[32] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In Proceedings of the International Conference on Machine Learning, pages 9229\u20139248. PMLR, 2020.   \n[33] Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation learning for domain adaptation. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018.   \n[34] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. TTT $^{++}$ : When does self-supervised test-time training fail or thrive? Advances in neural information processing systems, 2021.   \n[35] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004.   \n[36] Philip Haeusser, Thomas Frerix, Alexander Mordvintsev, and Daniel Cremers. Associative domain adaptation. In Proceedings of the IEEE international conference on computer vision, pages 2765\u20132773, 2017.   \n[37] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), pages 4068\u20134076, 2015.   \n[38] Fabio Maria Carlucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and Samuel Rota Bulo. AutoDIAL: Automatic domain alignment layers. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), pages 5077\u20135085, 2017.   \n[39] Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric tri-training for unsupervised domain adaptation. In Proceedings of the International Conference on Machine Learning, pages 2988\u20132997, 2017.   \n[40] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A DIRT-T approach to unsupervised domain adaptation. In Proceedings of the International Conference on Learning Representations, 2018.   \n[41] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In International Conference on Learning Representations, 2020.   \n[42] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In Proceedings of the International Conference on Machine Learning, pages 16888\u201316905, 2022.   \n[43] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. In International Conference on Learning Representations, 2023.   \n[44] Masud An-Nur Islam Fahim and Jani Boutellier. SS-TTA: Test-time adaption for selfsupervised denoising methods. In IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pages 1178\u20131187, 2023.   \n[45] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 295\u2013305, 2022.   \n[46] Tomer Cohen, Noy Shulman, Hai Morgenstern, Roey Mechrez, and Erez Farhan. Selfsupervised dynamic networks for covariate shift robustness. arXiv preprint arXiv:2006.03952, 2020.   \n[47] Alexander Bartler, Andre B\u00fchler, Felix Wiewel, Mario D\u00f6bler, and Bin Yang. Mt3: Meta test-time training for self-supervised test-time adaption. International Conference on Artificial Intelligence and Statistics, pages 3080\u20133090, 2022.   \n[48] Alexander Bartler, Florian Bender, Felix Wiewel, and Bin Yang. TTAPS: Test-time adaption by aligning prototypes using self-supervision. In IEEE International Joint Conference on Neural Networks (IJCNN), pages 1\u20138, 2022.   \n[49] Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin. On pitfalls of test-time adaptation. In International Conference on Machine Learning (ICML), 2023.   \n[50] Yi Su, Yixin Ji, Juntao Li, Hai Ye, and Min Zhang. Beware of model collapse! fast and stable test-time adaptation for robust question answering. In Conference on Empirical Methods in Natural Language Processing, 2023.   \n[51] Taesik Gong, Yewon Kim, Taeckyung Lee, Sorn Chottananurak, and Sung-Ju Lee. SoTTA: Robust test-time adaptation on noisy data streams. Advances in Neural Information Processing Systems, 36, 2024.   \n[52] Ori Press, Ravid Shwartz-Ziv, Yann LeCun, and Matthias Bethge. The entropy enigma: Success and failure of entropy minimization. arXiv preprint arXiv:2405.05012, 2024.   \n[53] Xiaofu Wu, Suofei Zhang, Quan Zhou, Zhen Yang, Chunming Zhao, and Longin Jan Latecki. Entropy minimization versus diversity maximization for domain adaptation. IEEE Transactions on Neural Networks and Learning Systems, 34(6):2896\u20132907, 2021.   \n[54] Pietro Morerio, Jacopo Cavazza, and Vittorio Murino. Minimal-entropy correlation alignment for unsupervised deep domain adaptation. In International Conference on Learning Representations, 2018.   \n[55] Glenn Shafer, Alexander Shen, Nikolai Vereshchagin, and Vladimir Vovk. Test martingales, bayes factors and p-values. Statistical Science, 26(1), February 2011.   \n[56] Vladimir Vovk, Ilia Nouretdinov, and Alexander Gammerman. Testing exchangeability on-line. In Proceedings of the 20th International Conference on Machine Learning (ICML), pages 768\u2013775, 2003.   \n[57] Vladimir Vovk, Ivan Petej, and Alex Gammerman. Protected probabilistic classification. In Conformal and Probabilistic Prediction and Applications, pages 297\u2013299, 2021.   \n[58] Francesco Orabona and D\u00e1vid P\u00e1l. Scale-free algorithms for online linear optimization. In International Conference on Algorithmic Learning Theory, pages 287\u2013301, 2015.   \n[59] Francesco Orabona and D\u00e1vid P\u00e1l. Scale-free online learning. Theoretical Computer Science, 716:50\u201369, 2018.   \n[60] Francesco Orabona and D\u00e1vid P\u00e1l. Coin betting and parameter-free online learning. Advances in Neural Information Processing Systems, 29:577\u2013585, 2016.   \n[61] Vladimir Vovk. Protected probabilistic regression. Technical report, Tech. Rep, 2021.   \n[62] C\u00e9dric Villani. Optimal transport: old and new, volume 338. Springer, 2009.   \n[63] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2020.   \n[64] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 770\u2013778, 2016.   \n[65] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2018.   \n[66] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5018\u20135027, 2017.   \n[67] Nicolas Courty, R\u00e9mi Flamary, Devis Tuia, and Alain Rakotomamonjy. Optimal transport for domain adaptation. IEEE transactions on pattern analysis and machine intelligence, 39(9):1853\u20131865, 2016.   \n[68] Eungyeup Kim, Mingjie Sun, Aditi Raghunathan, and J Zico Kolter. Reliable test-time adaptation via agreement-on-the-line. In NeurIPS Workshop on Distribution Shifts: New Frontiers with Foundation Models, 2023.   \n[69] Glenn Shafer and Vladimir Vovk. Game-theoretic foundations for probability and finance. Wiley Series in Probability and Statistics, 2019.   \n[70] Shubhanshu Shekhar and Aaditya Ramdas. Nonparametric two-sample testing by betting. IEEE Transactions on Information Theory, 2023.   \n[71] Aleksandr Podkopaev and Aaditya Ramdas. Sequential predictive two-sample and independence testing. Advances in Neural Information Processing Systems, 36, 2024.   \n[72] Shalev Shaer, Gal Maman, and Yaniv Romano. Model-X sequential testing for conditional independence via testing by betting. In International Conference on Artificial Intelligence and Statistics, pages 2054\u20132086, 2023.   \n[73] Peter Gr\u00fcnwald, Alexander Henzi, and Tyron Lardy. Anytime-valid tests of conditional independence under model-X. Journal of the American Statistical Association, pages 1\u201312, 2023.   \n[74] Valentina Fedorova, Alex Gammerman, Ilia Nouretdinov, and Vladimir Vovk. Plug-in martingales for testing exchangeability on-line. In Proceedings of the International Conference on Machine Learning, pages 923\u2013930, 2012.   \n[75] Vladimir Vovk, Alexander Gammerman, and Glenn Shafer. Testing exchangeability. In Algorithmic Learning in a Random World, pages 227\u2013263. Springer, 2022.   \n[76] Boyan Duan, Aaditya Ramdas, and Larry Wasserman. Interactive rank testing by betting. In Conference on Causal Learning and Reasoning, pages 201\u2013235, 2022.   \n[77] Aaditya Ramdas, Johannes Ruf, Martin Larsson, and Wouter M Koolen. Testing exchangeability: Fork-convexity, supermartingales and e-processes. International Journal of Approximate Reasoning, 141:83\u2013109, 2022.   \n[78] Aytijhya Saha and Aaditya Ramdas. Testing exchangeability by pairwise betting. In International Conference on Artificial Intelligence and Statistics, pages 4915\u20134923, 2024.   \n[79] Peter Gr\u00fcnwald, Rianne de Heide, and Wouter M Koolen. Safe testing. In IEEE Information Theory and Applications Workshop (ITA), pages 1\u201354, 2020.   \n[80] Glenn Shafer, Alexander Shen, Nikolai Vereshchagin, and Vladimir Vovk. Test martingales, bayes factors and p-values. Statistical Science, 26(1):84, 2011.   \n[81] Vladimir Vovk and Ruodu Wang. E-values: Calibration, combination and applications. The Annals of Statistics, 49(3):1736\u20131754, 2021.   \n[82] Aaditya Ramdas, Peter Gr\u00fcnwald, Vladimir Vovk, and Glenn Shafer. Game-theoretic statistics and safe anytime-valid inference. Statistical Science, 38(4):576\u2013601, 2023.   \n[83] Steven R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon. Time-uniform, nonparametric, nonasymptotic confidence sequences. The Annals of Statistics, 49(2), 2021.   \n[84] Ian Waudby-Smith and Aaditya Ramdas. Estimating means of bounded random variables by betting. Journal of the Royal Statistical Society Series B: Statistical Methodology, 2023.   \n[85] Peter D Gr\u00fcnwald. The e-posterior. Philosophical Transactions of the Royal Society A, 381(2247), 2023.   \n[86] Muriel Felipe P\u00e9rez-Ortiz, Tyron Lardy, Rianne de Heide, and Peter Gr\u00fcnwald. E-statistics, group invariance and anytime valid testing. arXiv preprint arXiv:2208.07610, 2022.   \n[87] Wouter M Koolen and Peter Gr\u00fcnwald. Log-optimal anytime-valid e-values. International Journal of Approximate Reasoning, 141:69\u201382, 2022.   \n[88] Vladimir Vovk and Ruodu Wang. Confidence and discoveries with e-values. Statistical Science, 38(2):329\u2013354, 2023.   \n[89] Shubhanshu Shekhar and Aaditya Ramdas. Reducing sequential change detection to sequential estimation. arXiv preprint arXiv:2309.09111, 2023.   \n[90] Jaehyeok Shin, Aaditya Ramdas, and Alessandro Rinaldo. E-detectors: A nonparametric framework for sequential change detection. The New England Journal of Statistics in Data Science, pages 1\u201332, 2023.   \n[91] Vladimir Vovk. Testing randomness online. Statistical Science, 36(4):595\u2013611, 2021.   \n[92] Charalambos Eliades and Harris Papadopoulos. A conformal martingales ensemble approach for addressing concept drift. In Conformal and Probabilistic Prediction with Applications, volume 204, pages 328\u2013346. PMLR, 2023.   \n[93] Vladimir Vovk. Testing for concept shift online. arXiv preprint arXiv:2012.14246, 2020.   \n[94] Liang Dai and Mohamed-Rafik Bouguelia. Testing exchangeability with martingale for change-point detection. International Journal of Ambient Computing and Intelligence (IJACI), 12(2):1\u201320, 2021.   \n[95] Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Ernst Ahlberg, Lars Carlsson, and Alex Gammerman. Retrain or not retrain: Conformal test martingales for change-point detection. In Conformal and Probabilistic Prediction and Applications, pages 191\u2013210. PMLR, 2021.   \n[96] Paul L\u00e9vy. Th\u00e9orie de l\u2019addition de variables al\u00e9atoires. second edition 1954. (gauthier-villars, paris). The Mathematical Gazette, 39, 1955.   \n[97] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7201\u20137211, 2022.   \n[98] Longhui Yuan, Binhui Xie, and Shuang Li. Robust test-time adaptation in dynamic scenarios. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15922\u201315932, 2023.   \n[99] Zixin Wang, Yadan Luo, Liang Zheng, Zhuoxiao Chen, Sen Wang, and Zi Huang. In search of lost online test-time adaptation: A survey. arXiv preprint arXiv:2310.20199, 2023.   \n[100] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In International Conference on Machine Learning, pages 1321\u20131330. PMLR, 2017.   \n[101] Menglong Lu, Zhen Huang, Zhiliang Tian, Yunxiang Zhao, Xuanyu Fei, and Dongsheng Li. Meta-tsallis-entropy minimization: a new self-training approach for domain adaptation on text classification. In Proceedings of the International Joint Conference on Artificial Intelligence, pages 5159\u20135169, 2023.   \n[102] Hong Liu, Jianmin Wang, and Mingsheng Long. Cycle self-training for domain adaptation. Advances in Neural Information Processing Systems, 34:22968\u201322981, 2021.   \n[103] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3, page 896, 2013.   \n[104] Sachin Goyal, Mingjie Sun, Aditi Raghunathan, and J Zico Kolter. Test time adaptation via conjugate pseudo-labels. Advances in Neural Information Processing Systems, 35:6204\u20136218, 2022.   \n[105] Jun-Kun Wang and Andre Wibisono. Towards understanding GD with hard and conjugate pseudo-labels for test-time adaptation. In International Conference on Learning Representations, 2022.   \n[106] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. Improving robustness against common corruptions by covariate shift adaptation. Advances in neural information processing systems, 33:11539\u201311551, 2020.   \n[107] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In International conference on machine learning, pages 9229\u20139248. PMLR, 2020.   \n[108] Xinyang Chen, Sinan Wang, Jianmin Wang, and Mingsheng Long. Representation subspace distance for domain adaptation regression. In ICML, pages 1749\u20131759, 2021.   \n[109] Karsten M Borgwardt, Arthur Gretton, Malte J Rasch, Hans-Peter Kriegel, Bernhard Sch\u00f6lkopf, and Alex J Smola. Integrating structured biological data by kernel maximum mean discrepancy. Bioinformatics, 22(14):e49\u2013e57, 2006.   \n[110] Aadyot Bhatnagar, Huan Wang, Caiming Xiong, and Yu Bai. Improved online conformal prediction via strongly adaptive online learning. In Proceedings of the International Conference on Machine Learning, pages 2337\u20132363. PMLR, 2023.   \n[111] Victor M Panaretos and Yoav Zemel. Statistical aspects of Wasserstein distances. Annual review of statistics and its application, 6:405\u2013431, 2019.   \n[112] Jean Ville. 1ere these: Etude critique de la notion de collectif; 2eme these: La transformation de Laplace. PhD thesis, Gauthier-Villars & Cie, 1939.   \n[113] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Note: Robust continual test-time adaptation against temporal correlation. Advances in Neural Information Processing Systems, 35:27253\u201327266, 2022.   \n[114] Aleksandr Podkopaev and Aaditya Ramdas. Distribution-free uncertainty quantification for classification under label shift. In Uncertainty in artificial intelligence, pages 844\u2013853. PMLR, 2021.   \n[115] Zhi Zhou, Lan-Zhe Guo, Lin-Han Jia, Dingchu Zhang, and Yu-Feng Li. Ods: Test-time adaptation in the presence of open-world data shift. In International Conference on Machine Learning, pages 42574\u201342588. PMLR, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "A Additional related work: test-time adaptation ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "As discussed in the main manuscript, entropy minimization is known to be effective for test time adaptation. However, the works in [42, 43] demonstrate that samples with high entropy loss can lead to noisy or overly aggressive updates of model parameters. To address this issue, [42, 43] filter out high-entropy samples, and [43] also employs gradient clipping to stabilize self-training. These algorithmic modifications emphasize the importance of controlling the minimization of the entropy loss, which greatly aligns with the goal of our work. In our framework, we also use entropy as a guiding force for self-training. However, instead of directly minimizing the entropy, our approach focuses on matching the distribution of the entropy losses at test time with that of the source domain. Notably, our method is versatile and can accommodate alternative choices beyond entropy, such as Tsallis entropy [101, 102] or cross-entropy evaluated with a pseudo-label [103\u2013105] in place of the unknown true label. We leave the exploration of these alternative options for future work. ", "page_idx": 17}, {"type": "text", "text": "Another concern in test-time adaptation frameworks is the continuous learning mechanism, which often leads to performance degradation on in-distribution data. To address this challenge, EATA [42] introduces an anti-forgetting strategy that optimizes the model by focusing on the reliability of samples and incorporates a weight regularizer to further improve stability. In our work, instead of relying on weight regularization, we preserve in-distribution performance through a \u201cno-harm\u201d approach, ensuring minimal model updates where no distribution shifts have occurred. ", "page_idx": 17}, {"type": "text", "text": "A crucial aspect of self-training is the selection of model parameters $\\omega$ to update. A widely adopted practice is to update the parameters of the normalization layers. This constraint plays a vital role in mitigating overfitting, which is imperative to prevent the model from collapsing and making trivial predictions. The TENT [41] approach demonstrates that minimizing entropy by modifying only the batch normalization parameters can significantly enhance out-of-distribution performance. However, TENT requires working with large batches, which can limit the ability to handle mixed-distribution shifts within a single batch\u2014for instance, a batch containing a subset of blurred images, another subset of noisy images, and so on. To alleviate this issue, the SAR method suggests updating the group or layer normalization parameters, unlocking the use of smaller batch sizes. In turn, this adjustment enhances the model\u2019s adaptivity under mixed-distribution shifts. In our work, we follow this line of research and update the layer normalization parameters; however, we optimize a completely different loss function, aiming to match the distributions of the source and target entropies. While there are works that suggest matching between the source and target distributions [106\u2013108], this alignment is often affected by the batch size. To stress this point, one might consider using an out-of-the-box distributional matching loss function (e.g., Maximum Mean Discrepancy [109]) to align the source and target entropy distributions, however, this approach requires large batches to obtain an effective estimation. Our approach accumulates the evidence for distribution shift in an online fashion, allowing us to use small batches, even of size one as we do in our experiments. ", "page_idx": 17}, {"type": "text", "text": "The work in [97] tackles the challenge of test-time adaptation where a pre-trained model must adjust to a continuously changing target domain during inference, without access to original training data. This approach, named CoTTA, utilizes weight-averaged and augmentation-averaged pseudo-labels to improve label accuracy and reduce error accumulation. To alleviate catastrophic forgetting, CoTTA intermittently reverts some neurons to their initial states. In contrast with CoTTA, our method operates under the assumption of no access to transformations/augmentations during testing. Employing such augmentations may further improve the performance of POEM, and we leave this exploration for future work. ", "page_idx": 17}, {"type": "text", "text": "B Learning the betting variable online ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section we present and analyze our online approach to learn the betting variable $\\epsilon_{j}$ , which relies on the SF-OGD algorithm [59]. The complete algorithm is presented in Algorithm 1. ", "page_idx": 17}, {"type": "text", "text": "In the following analysis, we assume that the betting variable that attains the fastest growth of the capital in hindsight, after observing $u_{\\tau}$ , is in the range $[-D,D]\\subset[-2,2]$ . We denote this variable by $E_{\\tau}\\in\\{-D,+D\\}$ , which can be computed via a simple closed-form expression, given by ", "page_idx": 17}, {"type": "equation", "text": "$$\nE_{\\tau}=D\\cdot\\mathrm{sign}(u_{\\tau}-0.5).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "With this in place, we define the clip-aware loss function, which we will use to formulate the update rule for $\\epsilon_{\\tau}$ that maximizes the capital: ", "page_idx": 17}, {"type": "equation", "text": "$$\nL(E_{\\tau},\\epsilon_{\\tau})=-\\left\\{\\log(1+E_{\\tau}(u_{\\tau}-0.5))\\quad\\mathrm{if}\\,\\,\\,E_{\\tau}\\cdot\\epsilon_{\\tau}>0\\,\\,\\,\\mathrm{and}\\,\\,\\,|\\epsilon_{\\tau}|>D\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In plain words, when $\\epsilon_{\\tau}$ is out of range but has the same sign as $E_{\\tau}$ , we clip the betting variable with the maximal value allowed $D$ or $-D)$ that would increase the wealth. Otherwise, the loss is equal to the log of the bet, obtained with $\\epsilon_{\\tau}$ . ", "page_idx": 18}, {"type": "text", "text": "At each step $\\tau$ of the algorithm, we first predict the value of $\\epsilon_{\\tau}$ , then observe $u_{\\tau}$ , which allows us to compute $E_{\\tau}$ . Therefore, after observing $u_{\\tau}$ we can compute the (sub)gradient of (12): ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla_{\\epsilon}L(E_{\\tau},\\epsilon_{\\tau})=-\\left\\{\\overset{0}{(u_{\\tau}-0.5)/(1+\\epsilon_{\\tau}(u_{\\tau}-0.5))}\\right.\\,\\left.\\mathrm{~af~}\\,E_{\\tau}\\cdot\\epsilon_{\\tau}>0\\,\\mathrm{~and~}\\,|\\epsilon_{\\tau}|>D\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Armed with $\\nabla_{\\epsilon}L(E_{\\tau},\\epsilon_{\\tau})$ we are ready to perform the SF-OGD step, formulated as: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\epsilon_{\\tau+1}=\\epsilon_{\\tau}-\\gamma\\frac{\\nabla_{\\epsilon}L(E_{\\tau},\\epsilon_{\\tau})}{\\sqrt{\\sum_{t=1}^{\\tau}(\\nabla_{\\epsilon}L_{t}(E_{t},\\epsilon_{t}))^{2}}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\gamma>0$ is a learning rate. Lemma 1 below states that $\\epsilon_{\\tau}$ is indeed bounded. ", "page_idx": 18}, {"type": "text", "text": "Lemma 1. The $S F$ -OGD algorithm with a learning rate $0<\\gamma<2-D$ and initialization $\\epsilon_{1}=$ $[-D-\\gamma,\\ D+\\gamma]$ satisfies $\\epsilon_{\\tau}\\in[-D-\\gamma,\\,D+\\gamma]$ for all $1\\leq\\tau\\leq j$ . ", "page_idx": 18}, {"type": "text", "text": "Proof is in Appendix C.2. Following Lemma 1, we conclude that we must set the learning rate $\\gamma$ in the range $0<\\gamma<2-D$ to ensure that $\\epsilon_{\\tau}$ is in the range $(-2,2)$ . The latter is crucial to formulate a valid betting function (4). ", "page_idx": 18}, {"type": "text", "text": "Building on the analysis of SF-OGD, the following proposition states that this algorithm achieves a regret bound on the loss in (12), where the regret function is defined as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathsf{R e g}(j)=\\sum_{\\tau=1}^{j}L(E_{\\tau},\\epsilon_{\\tau})-\\operatorname*{sup}_{\\epsilon^{\\star}\\in[-D,D]}\\sum_{\\tau=1}^{j}L(E_{\\tau},\\epsilon^{\\star}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Above, $\\epsilon^{\\star}$ is the betting parameter that minimizes the loss in hindsight, over the time horizon $1\\leq t\\leq j$ . ", "page_idx": 18}, {"type": "text", "text": "Theorem 1. [Theorem 4 by Orabona and p\u00e1l $I59J$ ; Proposition A.2 by Bhatnagar et al. [110]] Suppose that $\\epsilon^{\\star}\\in[-D,D]$ . Then, SF-OGD with $E_{\\tau}\\in\\{-D,D\\}$ for all $1\\leq\\tau\\leq j_{i}$ , learning rate $0<\\gamma<2-D$ , and any initialization $\\epsilon_{1}\\in[-D-\\gamma,D+\\gamma]$ achieves ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathrm{Reg}(t)\\leq(\\gamma+\\frac{1}{2\\gamma}(2D+\\gamma)^{2})\\sqrt{\\sum_{\\tau=1}^{t}\\left(\\nabla_{\\epsilon}L(T_{\\tau},\\epsilon_{\\tau})\\right)^{2}}\\leq\\mathcal{O}\\left(\\frac{\\sqrt{t}}{2-D-\\gamma}\\right),\\ \\forall1\\leq t\\leq j.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof is in Appendix C.3. The above result states that for any interval of size $1\\,\\leq\\,t\\,\\leq\\,j$ , the regret of SF-OGD defined in (15), is bounded by the square-root of the interval size $\\sqrt{t}$ , divided by the difference between the boundaries of the entire $\\epsilon_{\\tau}$ domain $[-2,2]$ and of the actual $\\epsilon_{\\tau}$ domain $[D-\\gamma,D+\\gamma]$ . ", "page_idx": 18}, {"type": "text", "text": "C Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Proof of Proposition 1 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. $S_{j}\\geq0$ for all $j\\in\\mathbb N$ since $u_{j}\\in[0,1]$ and $\\epsilon_{j}\\in[-2,2]$ by definition. $\\{S_{j}:j\\in\\mathbb{N}\\}$ is a martingale under $\\mathcal{H}_{0}$ since ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathcal{H}_{0}}[S_{j}\\mid S_{1},...,S_{j-1}]=S_{j-1}\\cdot\\mathbb{E}_{\\mathcal{H}_{0}}[b(u_{j})\\mid S_{1},...,S_{j-1}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=S_{j-1}\\cdot(1+\\epsilon_{j}\\cdot\\mathbb{E}_{\\mathcal{H}_{0}}[u_{j}-0.5\\mid S_{1},...,S_{j-1}])=S_{j-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the second transition holds since $\\epsilon_{j}$ depends only on $\\{S_{1},...,S_{j-1}\\}$ , and the latter since $\\mathbb{E}_{\\mathcal{H}_{0}}[u_{j}-0.5\\mid S_{1},...,S_{j-1}]=0$ . \u53e3 ", "page_idx": 18}, {"type": "text", "text": "C.2 Proof of Lemma 1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. Leveraging the symmetry of the problem, it suffices to study the setting in which $\\epsilon_{\\tau}\\geq0$ . Also, without loss of generality, we assume that $\\nabla_{\\epsilon}L_{1}(E_{1},\\epsilon_{1})\\neq0$ for the first iteration of the algorithm; if this does not hold we can always remove these samples until reaching an observation with a non-zero gradient. To prove the result, we consider the following cases that can occur when optimizing (12). ", "page_idx": 19}, {"type": "text", "text": "\u2022 Case 1: $0\\le\\epsilon_{\\tau}\\le D$ .   \n\u2022 Case 2: $\\epsilon_{\\tau}>D$ and $\\boldsymbol{\\epsilon}_{\\tau}\\cdot\\boldsymbol{E}_{\\tau}\\ge0$ .   \n\u2022 Case 3: $\\epsilon_{\\tau}>D$ and $\\boldsymbol{\\epsilon}_{\\tau}\\cdot\\boldsymbol{E}_{\\tau}\\leq0$ . ", "page_idx": 19}, {"type": "text", "text": "We start by analyzing Case 1. Recall that $0\\leq u_{\\tau}\\leq1$ and that $E_{\\tau}\\in\\{-D,D\\}$ . Now, following (13) we can conclude that the gradient of the loss $L(E_{\\tau},\\epsilon_{\\tau})$ is bounded $\\begin{array}{r}{\\dot{\\nabla_{\\epsilon}}L(\\dot{E_{\\tau}},\\epsilon_{\\tau})\\in[-\\frac{1}{2-D},\\frac{1}{2-D}]}\\end{array}$ . By recalling the update rule in (14), we get: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left|\\epsilon_{\\tau+1}-\\epsilon_{\\tau}\\right|=\\gamma\\left|\\frac{\\nabla_{\\epsilon}L(E_{\\tau},\\epsilon_{\\tau})}{\\sqrt{\\sum_{t=1}^{\\tau}(\\nabla_{\\epsilon}L_{t}(E_{t},\\epsilon_{t}))^{2}}}\\right|\\le\\gamma.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "With this in place, we can conclude that if $\\epsilon_{\\tau+1}\\geq\\epsilon_{\\tau}$ , then ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\epsilon_{\\tau+1}\\leq\\epsilon_{\\tau}+\\gamma\\leq D+\\gamma.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Otherwise, $\\epsilon_{\\tau+1}\\leq\\epsilon_{\\tau}$ , then ", "page_idx": 19}, {"type": "equation", "text": "$$\nD\\geq\\epsilon_{\\tau}\\geq\\epsilon_{\\tau+1}\\geq\\epsilon_{\\tau}-\\gamma\\geq-\\gamma.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Above, we used the fact that $0\\le\\epsilon_{\\tau}\\le D$ under Case 1. In sum, we showed that $-\\gamma\\le\\epsilon_{\\tau+1}\\le D\\!+\\!\\gamma$ ", "page_idx": 19}, {"type": "text", "text": "We now turn to analyze Case 2. Under the assumptions of this case $\\nabla_{\\epsilon}L(E_{\\tau},\\epsilon_{\\tau})=0$ and thus $\\epsilon_{\\tau+1}=\\epsilon_{\\tau}$ , i.e., the value of the betting parameter will not be modified. To bound the value of $\\epsilon_{\\tau+1}$ , we note that we can encounter $\\epsilon_{\\tau}>D$ as a result of updating the betting parameter in Case 1, but in this scenario, we already know that $-\\gamma\\le\\epsilon_{\\tau}\\le D+\\gamma$ . We can also reach Case 2 at the initialization, but then $\\epsilon_{1}<=D+\\gamma$ and thus bounded. Lastly, another entry point to Case 2 is from Case 3, however, we show below that the latter satisfies that $D-\\gamma\\leq\\epsilon_{\\tau}\\leq D+\\gamma.$ . ", "page_idx": 19}, {"type": "text", "text": "Lastly, we study Case 3, which can be reached from Case 1 or Case 2. However, in Case 2 $\\epsilon_{\\tau+1}=\\epsilon_{\\tau}$ , so we can concentrate only on the scenario where Case 3 is reached from Case 1, but we already showed that $\\epsilon_{t}\\,\\le\\,D+\\gamma$ in this case. Lastly, we can face Case 3 when $\\epsilon_{1}>D$ , however, it is bounded $\\epsilon_{1}<=D+\\gamma$ by the Lemma\u2019s assumption. Hence, following (13), the gradient is bounded \u2207\u03f5Lt(Et, \u03f5t) \u2208[\u22122\u2212D1\u2212\u03b3 ,2\u2212D1\u2212\u03b3 . Further, the loss can be improved only by reducing the value of $\\epsilon_{\\tau}$ , and thus the SF-OGD step would result in $\\epsilon_{\\tau+1}\\leq\\epsilon_{\\tau}$ . This implies that $\\epsilon_{\\tau}-\\epsilon_{\\tau+1}\\leq\\gamma$ , according to (16). In turn, by recalling that $D+\\gamma\\geq\\epsilon_{\\tau}>D$ , we conclude that ", "page_idx": 19}, {"type": "equation", "text": "$$\nD+\\gamma\\geq\\epsilon_{\\tau}\\geq\\epsilon_{\\tau+1}\\geq\\epsilon_{\\tau}-\\gamma>D-\\gamma.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "To summarize, the analysis of the cases above indicates that $\\epsilon_{\\tau}\\in[-D-\\gamma,\\,D+\\gamma]$ for all $1\\leq\\tau\\leq j$ , as desired. ", "page_idx": 19}, {"type": "text", "text": "C.3 Proof of Theorem 1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. Recall that we want to prove that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{Reg}(t)\\leq(\\gamma+\\frac{1}{2\\gamma}(2D+\\gamma)^{2})\\sqrt{\\sum_{\\tau=1}^{t}\\left(\\nabla_{\\epsilon}L(T_{\\tau},\\epsilon_{\\tau})\\right)^{2}}\\leq\\mathcal{O}\\left(\\frac{\\sqrt{t}}{2-D-\\gamma}\\right),\\ \\forall1\\leq t\\leq j.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The second inequality holds by following the proof of Lemma 1, showing that $\\nabla_{\\epsilon}L_{t}(E_{t},\\epsilon_{t})\\,\\in$ [\u22122\u2212D1\u2212\u03b3 ,2\u2212D1\u2212\u03b3 ]. The proof of the first inequality is a direct consequence of [59, Theorem 4] or [110, Proposition A.2], and thus omitted. Notable, we can directly invoke [59, Theorem 4] as (i) the loss function $L_{\\tau}(\\cdot)=L(E_{\\tau},\\cdot)$ in (12) is convex; and (ii) the betting variable $\\epsilon_{\\tau}\\in[-D-\\gamma,D+\\gamma]$ is bounded for all $1\\leq\\tau\\leq j$ due Lemma 1. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "C.4 Proof of Proposition 2 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof. Since we assume that $F_{s}$ is invertible and $Z_{j}^{t}$ is continuous, we can conclude that $F_{s}$ is a smooth bijection function. This allows us to invoke [61, Lemma 1], which states that if $F_{t}^{j}$ is the CDF corresponding to the density function $d F_{t}^{j}$ , and the mapping $F_{s}$ is a smooth bijection, then the CDF $Q^{\\mathrm{opt}}(\\bar{u})=F_{t}^{\\bar{j}}(F_{s}^{-1}(u))$ as in (9). With this in place, we can write ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\tilde{Z}_{j}^{t}=F_{s}^{-1}(Q^{\\mathrm{opt}}(u_{j}))=F_{s}^{-1}(F_{t}^{j}(F_{s}^{-1}(u_{j})))=F_{s}^{-1}(F_{t}^{j}(F_{s}^{-1}(F_{s}(Z_{j}^{t}))))=F_{s}^{-1}(F_{t}^{j}(Z_{j}^{t})),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second equality holds due [61, Lemma 1] and the third equality stems from the definition of $u_{j}$ , being $u_{j}=F_{s}(Z_{j}^{t})$ . We conclude the proof by observing that the mapping $\\tilde{Z}_{j}^{t}=F_{s}^{-1}(F_{t}^{j}(Z_{j}^{t}))$ is the optimal transport map from the target to the source distribution w.r.t. the Wasserstein distance. This is because $Z_{j}^{\\bar{t}}$ is a continuous, one-dimensional random variable, with an invertible CDF $F_{s}$ [111]. \u53e3 ", "page_idx": 20}, {"type": "image", "img_path": "qamfjyhPeg/tmp/85289cd05619abab05beb1a5539a5980c2b8fb6f18a315c9b36022e50790e674.jpg", "img_caption": ["D Using martingales to detect distribution shifts ", "Figure 4: Martingale behaviour with and without adaptation and on in-distribution data. Visualization of three scenarios: (1) out-of-distribution data (ImageNet-C, brightness level 1) without adaptation, (2) the same out-of-distribution data with online adaptation, and (3) in-distribution data (ImageNet) all on ResNet50. The top panel shows the martingale value, that is, the accumulated capital (in log scale) over time, while the bottom panel shows the corresponding betting variable $\\epsilon$ . "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Recall that we established in Proposition 1 the validity of the martingale defined in (4). In this section, we describe how a valid test martingale can be used to detect distribution shifts with a type-I error guarantee. This this end, consider a test martingale sequence denoted by $\\{S_{j}:j\\in\\mathbb{N}_{0}\\}$ under the null hypothesis $\\mathcal{H}_{0}$ of no distribution shift (3). Ville\u2019s inequality [112] plays a crucial role in bounding the probability of this martingale exceeding a specific threshold under $\\mathcal{H}_{0}$ . Specifically, for any value of $\\alpha$ between 0 and 1, Ville\u2019s inequality states the following: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathcal{H}_{0}}\\bigg(\\exists j\\ge1:S_{j}\\ge\\frac{1}{\\alpha}\\bigg)\\le\\alpha\\mathbb{E}_{\\mathcal{H}_{0}}[S_{0}]=\\alpha.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Suppose we set a significance level $\\alpha=0.01$ . The above inequality states that under the assumption of no distribution shift, the martingale\u2019s value will exceed a threshold of $1/\\alpha$ (in this case, 100) with a probability of at most $\\alpha=0.01$ . This bound on the probability allows us to simultaneously control the type-I error across all time steps. This implies that we can declare that we face a distribution shift if the martingale value pass the threshold $1/\\bar{\\alpha}$ . For instance, if we set the threshold to 100 or higher, the type-I error is guaranteed to be less than or equal to 0.01. ", "page_idx": 20}, {"type": "text", "text": "Figure 4 top panel offers a visual representation of the martingale\u2019s behavior under different scenarios; see Appendix F for implementation details. As discussed above, under the null hypothesis of no distribution shift, the martingale is expected to remain lower than 1 with high probability. This is precisely what we observe in the in-distribution data scenario\u2014the martingale value remains under ", "page_idx": 20}, {"type": "text", "text": "1. Here, we consider the ImageNet dataset, where we applied a pre-trained ResNet50 model on the ImageNet validation set. ", "page_idx": 21}, {"type": "text", "text": "In contrast, when the pre-trained model is applied to corrupted, out-of-distribution data (ImageNet-C), the martingale value deviates significantly from 1, reaching levels of up to $10^{200}$ . This substantial increase validates the presence of a distribution shift. Interestingly, Figure 4 also reveals the effectiveness of our online adaptation. The adaptation process gradually limits the martingale value from growing compared to the non-adaptation case. Observe how the martingale of the adapted model eventually converges to a plateau. This visually demonstrates the success of adapting the model to the new distribution, making the target entropies statistically indistinguishable from the source data. ", "page_idx": 21}, {"type": "text", "text": "E Algorithms ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we present a series of algorithms essential to understanding and implementing our proposed methods. It is important to note that throughout these algorithms, we do not explicitly state each instance where lists or variables are updated; however, such updates are implicitly understood to occur during computations. ", "page_idx": 21}, {"type": "text", "text": "We use the \u201cAssume\u201d directive in our algorithms to outline which variables are accessible as global variables. These global variables are updated as part of the algorithms\u2019 operations but are not repeatedly declared within each algorithmic step. This approach is chosen to streamline the presentation and focus on the algorithmic logic rather than the mechanics of data handling. ", "page_idx": 21}, {"type": "text", "text": "Algorithm 1 SF-OGD Step ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Require: $u_{j}\\in[0,1]$ Assume: ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "$\\epsilon_{j}$ : last betting parameter\u2019s value   \n$\\{\\stackrel{\\prime}{\\nabla}_{\\epsilon}L(E_{0},\\epsilon_{0}),...,\\nabla_{\\epsilon}L(E_{j-1},\\epsilon_{j-1})\\}$ : past gradient values of the log loss from (12)   \n$D$ : betting variable clip value   \n$\\gamma$ : SF-OGD learning rate ", "page_idx": 21}, {"type": "text", "text": "1: $E_{j}\\gets D\\cdot\\mathrm{sign}(u_{j}-0.5)$   \n2: if $E_{j}\\cdot\\epsilon_{j}>0$ and $|\\epsilon_{j}|>D$ then   \n3: $\\bar{\\nabla}_{\\epsilon}\\bar{L}(E_{j},\\epsilon_{j})\\gets\\bar{0}$ ", "page_idx": 21}, {"type": "text", "text": "4: else ", "page_idx": 21}, {"type": "text", "text": "5: $\\begin{array}{r}{\\nabla_{\\epsilon}L(E_{j},\\epsilon_{j})\\leftarrow-\\frac{u_{j}-0.5}{1+\\epsilon_{j}(u_{j}-0.5)}}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "\u25b7Following (13) ", "page_idx": 21}, {"type": "text", "text": "6: end if ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "$\\begin{array}{r}{\\epsilon_{j+1}\\leftarrow\\epsilon_{j}-\\gamma\\frac{\\nabla_{\\epsilon}L(E_{j},\\epsilon_{j})}{\\sqrt{\\sum_{t=1}^{j}(\\nabla_{\\epsilon}L_{t}(E_{t},\\epsilon_{t}))^{2}}}}\\end{array}$ ", "page_idx": 21}, {"type": "text", "text": "\u25b7Following (14) ", "page_idx": 21}, {"type": "text", "text": "8: return \u03f5j+1 ", "page_idx": 21}, {"type": "text", "text": "Algorithm 2 Protected Online Entropy Matching (POEM) ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Require: $\\smash{\\mathcal{D}^{s}=\\{X_{j}^{s}\\}_{j=1}^{n}}$ : holdout data from source distribution $f_{\\hat{\\theta}}$ : pretrained model $D$ : last betting parameter\u2019s value $\\gamma$ : SF-OGD learning rate $\\eta$ : model learning rate $\\lambda$ : entropy filter threshold, see (10)   \n1: Init: $\\epsilon_{1}=0$ , $\\omega_{1}\\gets\\mathbf{0}$ $\\triangleright$ We update only the network\u2019s norm. layers   \n2: Compute empirical CDF function of source entropies   \n3: for $X_{i}^{s}$ in $\\mathcal{D}^{s}$ do   \n4: $Z_{i}^{\\bar{s}}\\gets\\ell^{\\mathrm{ent}}(f_{\\hat{\\theta}}(X_{i}^{s}))$   \n5: end for   \n6: Define: $\\begin{array}{r}{\\hat{F}_{s}(z)=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{1}\\{Z_{i}^{s}\\le z\\}}\\end{array}$ \u25b7Empirical CDF function   \n7: Online adaptation   \n8: $j\\leftarrow1$   \n9: while Get a test sample $X_{j}^{t}$ do   \n10: $\\begin{array}{r l}&{Z_{j}^{t}\\gets\\ell^{\\mathrm{sut}}(f_{\\hat{\\theta}+\\omega_{j}}(X_{j}^{t}))^{\\top}}\\\\ &{u_{j}\\gets\\hat{F}_{s}(Z_{j}^{t})}\\\\ &{b_{j}=1+\\epsilon_{j}\\cdot(u_{j}-0.5)}\\\\ &{\\tilde{u}_{j}\\gets\\frac{1}{2}\\epsilon_{j}u_{j}^{2}+u_{j}\\cdot\\big(1-\\frac{\\epsilon_{j}}{2}\\big)}\\\\ &{\\tilde{Z}_{j}\\gets\\{\\operatorname*{min}z:\\hat{F}_{s}(z)\\geq\\tilde{u}_{j}\\}_{i=1}^{n}}\\\\ &{\\omega_{j+1}\\gets\\omega_{j}-\\eta\\nabla_{\\omega}\\ell_{\\lambda}^{\\mathrm{mateh+}}(Z_{j}^{t},\\tilde{Z}_{j})}\\\\ &{\\epsilon_{j+1}\\gets\\mathrm{Alg.~1~}(u_{j})}\\\\ &{j\\gets j+1}\\end{array}$ $\\triangleright$ Compute test entropy   \n11: $\\triangleright$ Apply probability integral transform   \n12: $\\triangleright$ Place a bet against the null (3)   \n13: $\\triangleright$ Adapt $u_{j}$ according to (7)   \n14: $\\triangleright$ Transport to source domain, $\\hat{F}_{s}^{-1}(\\tilde{u}_{j})$   \n15: $\\triangleright$ Update norm. layers\u2019 params. according to (10)   \n16: $\\triangleright$ Update the betting variable   \n17:   \n18: end while ", "page_idx": 22}, {"type": "text", "text": "F Supplementary experiments ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "F.1 Synthetic experiment ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "To evaluate the methods, we generate a synthetic dataset by generating two sets of points, each containing 2, 500 samples. Specifically, samples for the first set (class $-1)$ ) are drawn from a normal distribution ${\\mathcal{N}}(-1,1)$ , while samples for the second set (class $+1$ ) are drawn from ${\\mathcal{N}}(1,1)$ . We use these 5, 000 samples to calculate the source CDF. Note that we do not use a training set, as we initialized the pre-trained model\u2019s parameter $\\omega$ to the optimal value, which is $\\omega=0$ . ", "page_idx": 22}, {"type": "text", "text": "We then create two test sets: ", "page_idx": 22}, {"type": "text", "text": "\u2022 In-distribution test data, which consists of 10,000 samples per class, following the source distribution. \u2022 Out-of-distribution test data, which consists of 10,000 samples per class, but with shifted distributions\u2014the class $-1$ samples are drawn from ${\\mathcal{N}}(0,1)$ and the class $+1$ samples are drawn from ${\\mathcal{N}}(2,1)$ . This represents a distributional shift of 1 unit in $X$ . ", "page_idx": 22}, {"type": "text", "text": "We defined our model parameter as $\\omega\\in\\mathbb R$ . Two types of loss functions were employed: ", "page_idx": 22}, {"type": "text", "text": "\u2022 Entropy loss $\\ell^{\\mathrm{{ent}}}$ (1), computed by evaluating the entropy of each point\u2019s prediction given the model parameter $\\omega$ .   \n\u2022 Matching loss $\\ell^{\\mathrm{match}}$ (2), computed using an optimal transport mapping, i.e., $F_{s}^{-1}\\circ F_{t}$ , to match the new set of target entropies derived from $f_{\\omega}$ to the source entropies obtained from the holdout data. ", "page_idx": 22}, {"type": "text", "text": "Hyperparameters and training scheme The optimization of each method was executed over 200 steps using a fixed learning rate of 5. Although lower learning rates were also effective, a higher learning rate was chosen to accelerate the demonstration. The optimization was performed with a batch size of 64. Each method\u2019s performance was evaluated at the end of this process. We clipped entropy minimization convergence if it went outside the bounds of our plot. In all experiments conducted in this paper, we choose the following set of hyperparameters, defined in Algorithm 1: ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "equation", "text": "$$\n\\cdot\\begin{array}{l}{D=1.8.}\\\\ {\\cdot\\;\\gamma=\\frac{1}{8\\cdot\\sqrt{3}}\\approx0.0722.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "F.2 ImageNet-C experiments ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Models Our experiments utilize two pre-trained architectures: a Vision Transformer (ViT) with layer normalization (LN) and a ResNet50 with group normalization (GN). Both are pre-trained models from the timm library. We calibrate both models using temperature scaling, setting the temperature of ResNet50 to $T=0.90$ and $T=1.025$ for ViT. For POEM specifically, we implement an action delay of 100 examples throughout the experiments in this paper. This delay allows the monitoring component of POEM to accumulate sufficient evidence before updating the model parameters, mitigating the influence of potentially noisy initial data. ", "page_idx": 23}, {"type": "text", "text": "Data We randomly sample $25\\%$ of the examples from ImageNet validation set as an unlabelled holdout set. The corresponding corrupted examples are excluded from ImageNet-C to maintain the validity of the holdout data. All methods are evaluated only on the remaining $75\\%$ samples. Each experiment is repeated 10 times with different holdout data splits and data selections, which is particularly crucial for experiments with small subsets of examples, such as the continual shifts experiments. Specifically for ViT, we modify the default preprocessing transforms offered by SAR, to the one used by the model during its training (see https://huggingface.co/timm/vit_base_ patch16_224.augreg2_in21k_ft_in1k for the exact details). This adjustment is crucial to ensure proper estimation of the source CDF as well as ensure the model\u2019s performance on in-distribution data adheres to the one reported in Hugging Face. ", "page_idx": 23}, {"type": "text", "text": "Code, hyperparameters, and learning scheme We use the SAR [43] repository (available at https://github.com/mr-eggplant/SAR) for the ImageNet and ImageNet-C experiments. To ensure consistency with prior works, we adopt the hyperparameters, optimizers, and procedures provided within the SAR repository. This ensures that all baseline methods as well as POEM are run with the exact same settings. We also compare our method with COTTA[97] using the code provided by the authors, available at https://github.com/qinenergy/cotta. In more detail: ", "page_idx": 23}, {"type": "text", "text": "\u2022 For all methods except COTTA: \u2013 The learning rate ( $\\eta$ in Algorithm 2) calculation follows these formulas: $^*$ ViT: learning rate $=\\left({\\frac{0.001}{64}}\\right)\\times$ batch size $^*$ ResNet50: learning rate 0.0604025 \u00d7 batch size \u00d7 2 \u2013 We use SGD optimizer with momentum of 0.9 for self-training. \u2013 We use $\\lambda=0.40\\cdot\\log{\\left(1000\\right)}$ (denoted by $E_{0}$ in [42, 43]).   \n\u2022 For COTTA: \u2013 We tune the learning-rate search for each model (ResNet and ViT), ranging from ${\\frac{0.001}{64}}\\cdot i$ where $i\\in[0.5,1,2,4,8]$ , and select the best-performing value for each model on the continual setting with a corruption segment size of $1,000$ . This process resulted in the following learning rate values. $^*$ ViT learning rate $\\textstyle={\\left({\\frac{0.001}{64}}\\right)}\\times4$ $^*$ ResNet50 learning rate $\\mathrm{{\\Omega}=\\left({\\frac{0.001}{64}}\\right)\\times2}$ \u2013 We use Adam optimizer with $\\beta=(0.9,0.999)$ and weight decay 0 for self-training, as employed in the original work. ", "page_idx": 23}, {"type": "text", "text": "A batch size of 1 is consistently used throughout all of the experiments, and, as mentioned in Appendix F, we use D = 1.8 and \u03b3 =8\u00b71\u221a3 $\\begin{array}{r}{\\gamma=\\frac{1}{8\\cdot\\sqrt{3}}\\approx0.07\\bar{2}2}\\end{array}$ for our monitoring algorithm (see Algorithm 1). Lastly, since the empirical CDF in Algorithm 2 (line 6) is calculated from a finite set of data points, it inherently creates a step function. In practice, we use linear interpolation to create a continuous function for better operation. ", "page_idx": 23}, {"type": "text", "text": "Hardware All experiments are conducted on our local server, equipped with 16 NVIDIA A40 GPU - 49GB GPUs, 192 Intel(R) Xeon(R) Gold 6336Y CPUs, and 1TB of RAM memory. Each experiment uses a single GPU and 8 CPUs. ", "page_idx": 24}, {"type": "image", "img_path": "qamfjyhPeg/tmp/8005ceb8fa166fd0aca708b6100132d43d4cb536846957e2d9bf931a3b5773da.jpg", "img_caption": ["F.2.1 Additional experiments: continual shifts ", "Figure 5: Continual test-time adaptation on ImageNet-C with a ResNet model. Top: Percorruption accuracy with a corruption segment size of 1,000 examples. Results are obtained over 10 independent trials; error bars are tiny. Bottom left: Severity shift\u2014low (1) to high (5) and back to low. Bottom center: Severity shift\u2014high (5) to low (1) and back to high. Bottom right: Mean accuracy under continual corruptions as a function of the corruption segment size. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Supplementary details for the continual shifts experiments presented in the main manuscript For the corruption shift experiment, we used corruption segments sizes in the range of 100, 250, 500, 1000, and 2000. Apart from the bottom right panels of Figures 2 and 5, the results are obtained using corruption segment size of 1,000 exclusively. ", "page_idx": 24}, {"type": "text", "text": "Experiments with a ResNet (GN) model Herein, we repeat the same experiments from Section 4 of the main manuscript to evaluate our proposed method within a continual shift setting, but now focus on a ResNet50 (GN) model. The results are summarized in Figure 5, showing a similar trend to that obtained with the ViT model, albeit accuracies that are closer to the baseline methods. We note that the baseline accuracy of ResNet is far below that of ViT. The bottom right panel of Figure 5 demonstrates POEM\u2019s efficiency in adapting to fast-changing distributions with only a few examples. While the advantage of POEM is less clear with small corruption segments in ResNet, it becomes evident as early as segment size 500. Observe the bottom right panel of Figure 5. At corruption segment size of 2,000, POEM surpasses the best baseline method\u2019s accuracy (EATA) by $1.27\\%$ . POEM also achieves $4.64\\%$ increase compared to the original model (no adaptation). ", "page_idx": 24}, {"type": "text", "text": "F.2.2 Additional experiments: single shift ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Table 1 summarizes baseline methods\u2019 accuracy on ImageNet-C for ViT and ResNet models. Table 2 offers a more detailed breakdown of the results in Table 1, showing accuracy for each corruption type. ", "page_idx": 24}, {"type": "text", "text": "F.2.3 Additional experiments: in-distribution and the behavior of $\\epsilon$ ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Even though adapting on unseen in-distribution data from ImageNet attains similar accuracies for all baseline methods compared to the no-adapt approach (Table 3), POEM maintains this accuracy with the most minimal change to the original model\u2019s parameters $\\omega$ and virtually unchanged ECE. This ", "page_idx": 24}, {"type": "text", "text": "Table 1: Single shift test-time adaptation. Accuracy evaluated on ImageNet-C, averaged over all 15 corruptions of severity level 5. Detailed results are in Table 2. We attribute COTTA\u2019s inferior performance to its learning rate being tuned for the continual setting; see Appendix F.2 for details. ", "page_idx": 25}, {"type": "table", "img_path": "qamfjyhPeg/tmp/b0f9ff1ee9977293b769a32da70cd33973ead6b5bfa4bc7f9bcf66fa696359d5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "qamfjyhPeg/tmp/d660beb3b0a2a18a5ae9414e39ef64ca3727d5c73e51e0be22417ba8b03edaec.jpg", "table_caption": ["Table 2: Summary of performance metrics of adaptation methods on the ImageNet-C dataset, evaluated for each type of corruption at severity level 5. The results are evaluated on 10 independent experiments, conducted for each method and corruption type; standard error is presented. "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "is demonstrated in the left panels of Figure 3 and Figure 6. Specifically, as seen in Table 3, $\\|\\omega\\|_{F}^{2}$ for POEM is merely 0.17, significantly lower than other methods on ResNet50\u2014over 30 times less change than the closest baseline method. This minimal change demonstrates POEM\u2019s capability for controlled adaptation. ", "page_idx": 25}, {"type": "text", "text": "Figure 7 further demonstrates the \u201cno-harm\u201d effect of POEM under in-distribution test data. The left panel shows the empirical CDF of the entropy values $\\hat{F}_{t}$ of all baseline methods, indicating that these lead to overconfident predictions. This is in contrast to POEM, whose estimated target CDF closely aligns with the source distribution. Such a minimal deviation from the source distribution aligns with our previous findings\u2014POEM tends to keep the model parameters intact when adaptation is unnecessary. ", "page_idx": 25}, {"type": "text", "text": "When applying the model to out-of-distribution data (right panel of Figure 7), the unadapted model appears slightly under-confident, as indicated by its corresponding CDF $\\hat{F}_{t}$ being lower than $\\hat{F}_{s}$ . Here, POEM effectively restores the model\u2019s original confidence by adjusting its estimated CDF to closely match the source CDF. SAR achieves comparable results to POEM, but through a different strategy. It employs a restart mechanism that acts as a safeguard, activated when the entropy of the adapted model drops below a specific exponential moving average (EMA) threshold. ", "page_idx": 25}, {"type": "text", "text": "F.2.4 Ablation study ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We assess the impact of $\\ell^{\\mathrm{match++}}$ (10) compared to $\\ell^{\\mathrm{match}}$ (2) on adaptation accuracy through isolated analysis. Table 4 shows that our basic match loss $\\ell^{\\mathrm{match}}$ improves the test accuracy over the no-adapt baseline, even without filtering and weighting. This underscores the core strength of our approach. The enhanced $\\ell^{\\mathrm{match++}}$ that incorporates sample filtering and weighting mechanisms further boosts performance. ", "page_idx": 25}, {"type": "text", "text": "F.3 CIFAR10-C and CIFAR100-C experiments ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Data CIFAR10-C and CIFAR100-C datasets are extensions of the original CIFAR10 and CIFAR100 test sets. These datasets consist of 15 different corrupted versions of the original CIFAR test images, with each corruption applied at 5 severity levels, mirroring the structure of ImageNet-C. In our experimental setup, we randomly select $25\\%$ of the examples from original CIFAR test set to create unlabelled holdout sets of sizes 2,500 images. To preserve the integrity of the holdout set, we exclud the corresponding corrupted examples from CIFAR10-C and CIFAR100-C, respectively. All adaptation methods were applied on the remaining $75\\%$ of the data, ensuring consistency across approaches, regardless of their holdout set requirements. We conduct each experiment for 10 independent trials. ", "page_idx": 25}, {"type": "table", "img_path": "qamfjyhPeg/tmp/32a2a5620ce43810a60c1abc0170f5a1da5a5968196aa0c4b4e42d70491defab.jpg", "table_caption": ["Table 3: Results of adaptation on in-distribution ImageNet data. "], "table_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "", "img_caption": ["Figure 6: In-distribution experiment on ImageNet (left panel): calibration error (ECE [100]) versus $\\|\\omega\\|_{F}^{2}$ \u2014a metric that evaluates the classifier\u2019s parameters deviation from the original ResNet50 model. Lower values on both axes are better. Results are averaged across 10 independent trials; standard errors and accuracy of each method are reported in Table 3 in the appendix. The behavior of the betting parameter (right panel): the value of $\\epsilon$ is presented as a function of time for both inand out-of-distribution experiments (a single shift, two severity levels). "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "Model Our experiments utilize a pre-trained ResNet32 model with batch normalization (BN), obtained from torch-hub and available at https://github.com/chenyaofo/ pytorch-cifar-models. ", "page_idx": 26}, {"type": "text", "text": "Methods, code, hyperparameters, and learning scheme The pre-trained ResNet32 architecture includes batch normalization (BN) layers, which forces us to use a batch-size of 4 during self-training. This differs from the batch-size we used in the ImageNet experiments, which was equal to 1. In what follows, we compare POEM to SAR, EATA, and TENT only. We do not conduct experiments with COTTA, as our ImageNet experiments showed that COTTA performs inferiorly when the self-training batch size is small. To ensure fair comparison, we perform a grid search for choosing the optimal learning ", "page_idx": 26}, {"type": "table", "img_path": "qamfjyhPeg/tmp/491ed0d27809439a3d052135b7a5c4c655a227a98889627a04146c4c5c13fb8e.jpg", "table_caption": ["Table 4: Ablation study: the effect of $\\ell^{\\mathrm{match}}$ compared to $\\ell^{\\mathrm{match++}}$ on the accuracy of POEM. Results are presented for ImageNet-C and averaged over all 15 corruptions of severity level 5. "], "table_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "qamfjyhPeg/tmp/4df129757b624b4486c2069e9be383779c3960e33f1cf692da778c44b552b578.jpg", "img_caption": ["Figure 7: Empirical test entropy CDF of each adaptation method, applied to in- and out-ofdistribution ImageNet data. The dotted black line represents the source CDF $\\hat{F}_{s}$ obtained by applying the original ResNet50 model on test images from the source domain. The left panel shows how self-training on the validation set of ImageNet (in-distribution data) affects the entropy distribution of the model. The right panel repeats the experiment on out-of-distribution data from ImageNet-C with brightness corruption of severity level 1. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "qamfjyhPeg/tmp/068d8f17ec8873830a083e3ea5a2d12afbad9cec087ce78badbdde2b063cadc4.jpg", "img_caption": ["Figure 8: Short-term adaptation performance on a test set of about 15,360 samples from CIFAR10-C (top) and CIFAR100-C (bottom) using a ResNet (BN) model. Left: Continual test-time adaptation performance showing per-corruption accuracy with a corruption segment size of 1,024 examples of severity level 5. Results are averaged over 10 independent trials with error bars indicated. The \u2018no adapt\u2019 baseline is not displayed as its mean accuracy is significantly lower than other methods (see the right panel); we omitted this method to enhance visualization of differences between the adaptation techniques. Middle: Runtime slowdown, defined as the runtime of test-time adaptation divided by the runtime of the source (no-adapt) model; lower is better. Right: Learning rate sensitivity study, showing mean performance across the continual experiment. The results in the left panel are obtained with the best learning rate for each method. "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "rate $\\eta$ for each method. The details of this sensitivity analysis are presented in the following section.   \nIn the case of POEM, we retained the hyperparameters of the monitoring tool as outlined in Section F. ", "page_idx": 27}, {"type": "text", "text": "F.3.1 Continual shifts experiments ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Short-term adaptation performance We focus on the continual setting where the corruption type is changing over time, akin to our ImageNet experiments. Each corruption type includes 1, 024 samples, resulting in a test set of approximately $15\\cdot1,024\\approx15,000$ samples. The results are summarized in Figure 8. Following that figure, one can see that our method is competitive and even outperforms baseline methods in terms of accuracy. Runtime comparisons (relative to the no-adapt model) are also presented, demonstrating that our method\u2019s complexity is similar to TENT and EATA, and lower than SAR. Additionally, the sensitivity study for the learning rate parameter $\\eta$ reveals our method\u2019s robustness to this hyperparameter, particularly when compared to SAR and TENT. ", "page_idx": 27}, {"type": "image", "img_path": "qamfjyhPeg/tmp/a396dede37601690107a9aa03fc868baf4c0c9b61ab9ad9b41a82723e1ede7b8.jpg", "img_caption": ["Figure 9: Long-term adaptation performance on a test set of 112,500 samples from CIFAR10-C (top) and CIFAR100-C (bottom) using a ResNet (BN) model. Continual test-time adaptation is applied with a corruption segment size of 7,500 examples of severity level 5. The other details are as in Figure 8. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "Long-term adaptation performance Here, we conduct a similar experiment, but on a larger test set containing 112,500 corrupted samples (15 versions of 7,500 images). The results, summarized in Figure 9, show that our proposed method is competitive with the baseline methods in terms of adaptation accuracy. Notably, our method\u2019s runtime is twice as fast as SAR and comparable to EATA and TENT. Unlike SAR, we do not employ a model-reset mechanism, nor do we use an anti-forgetting loss like EATA\u2014yet our approach demonstrates robustness over the long term. In contrast, the right panel of Figure 9 reveals that TENT is highly sensitive to the choice of learning rate. ", "page_idx": 28}, {"type": "text", "text": "F.4 Office-Home experiments ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Data The OfficeHome dataset consists of images from 4 domains: \u201cArt\u201d, \u201cClipart\u201d, \u201cProduct\u201d, and \u201cReal World\u201d. It contains a total of 15,588 images across 65 object categories. The \u201cArt\u201d domain has 2,427 images, \u201cClipart\u201d has 4,365 images, \u201cProduct\u201d has 4,439 images, and \u201cReal World\u201d has 4,357 images. We focus on adaptation from the \u201cReal World\u201d domain to the \u201cArt\u201d, \u201cClipart\u201d, and \u201cProduct\u201d domains. We chose this setup over a continual setting as it is deemed more natural for this dataset. Given the lack of a predefined data structure, we split the dataset into an $80\\%$ training set from the \u201cReal World\u201d samples, with the remainder serving as validation and holdout sets for our method and EATA. ", "page_idx": 28}, {"type": "text", "text": "Methods, model, hyperparameters, and learning scheme We fine-tune the last layer of the ResNet50 with Group Normalization (GN) previously used in the ImageNet experiments. We fti the model on $80\\%$ of the \u201cReal World\u201d examples for 25 epochs, with the best model saved based on performance on the remaining $20\\%$ . We use Adam optimizer with default PyTorch hyperparameters and set the learning rate to $5\\cdot10^{-5}$ . Similar to the CIFAR experiments, we compare POEM to SAR, EATA, and TENT only; our ImageNet experiments showed that COTTA performs inferiorly when the self-training batch size is 1, which is used in this experiment as well. Learning rates are tuned for each method using a predefined grid, ensuring a fair comparison, similar to our CIFAR experiments. The hyperparameters of POEM\u2019s monitoring tool are as specified in Section F. ", "page_idx": 28}, {"type": "image", "img_path": "qamfjyhPeg/tmp/1c2d9d0ce1e0042060bc197fc0fab508b59195e2032abd2f82828a926dc22c32.jpg", "img_caption": ["Figure 10: Performance analysis of test-time adaptation methods on the Office-Home dataset using a ResNet (GN) model, pre-trained on ImageNet and fine-tuned on the \u201cReal World\u201d source domain. Left: Test-time accuracy for adaptation from the source domain to three distinct target domains (\u201cArt\u201d, \u201cClipart\u201d, and \u201cProduct\u201d). Results are evaluated on the complete test dataset of each target domain and averaged across 10 independent trials, with error bars indicated. Middle: Runtime slowdown comparison. Right: Learning rate sensitivity study, displaying the average accuracy across all three target domains. The results in the left panel are obtained using the best learning rate for each method. "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "F.4.1 Single domain adaptation experiments ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Test-time adaptation is applied to the entire test data of each target domain (\u201dArt\u201d, \u201dClipart\u201d and \u201dProduct\u201d). Results are summarized in Figure 10. Overall, all the methods demonstrate modest accuracy gains compared to the \u2018no-adapt\u2019 case. Our proposed method POEM slightly outperforms TENT and EATA in terms of accuracy, while achieving results comparable to SAR. In terms of computational efficiency, our method\u2019s runtime is on par with TENT and EATA, and notably faster than SAR. Regarding sensitivity to the choice of the learning rate, our approach displays superior robustness compared to TENT and SAR, and a similar robustness to that of EATA. ", "page_idx": 29}, {"type": "text", "text": "G Future Directions ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In future work, we plan to complement our empirical findings with a theoretical analysis. Our goal is to rigorously determine when entropy matching is superior to entropy minimization, thereby uncovering the theoretical benefits and limitations of our approach. ", "page_idx": 29}, {"type": "text", "text": "Another future direction is to support POEM with the ability to handle label shift at test time. This challenge is exemplified by scenarios where the source domain has a balanced label distribution, but the test domain becomes unbalanced. In such cases, our current monitoring tool might detect this label shift and trigger unnecessary adaptation in the absence of covariate shift. This underscores the need for a monitoring tool that remains invariant to label shifts. To address this challenge, one may consider two potential approaches. The first builds on ideas from [113], particularly their prediction-balanced reservoir sampling technique. This method can be used to approximately simulate an i.i.d. data stream from a non-i.i.d. stream in a class-balanced manner, potentially reducing our martingale process\u2019s sensitivity to label shifts. The second approach may involve the use of a weighted source CDF instead of the standard source CDF, with weights corresponding to the likelihood ratio $P^{t}(Y)/P^{s}(Y)$ . This concept, borrowed from conformal prediction literature [114], aims to make the test loss to \u201clook exchangeable\u201d with the source losses, thus adjusting for label shift. The main challenge here lies in reasonably approximating the likelihood ratio $P^{t}(\\bar{Y_{}})/P^{s}(Y)$ , especially when facing simultaneous covariate and label shifts at test time. The ideas presented in [115] may offer a promising starting point for exploring this avenue. ", "page_idx": 29}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We claimed to have contributed the following contributions: ", "page_idx": 30}, {"type": "text", "text": "\u2022 We develop a sequential test for classification entropy drift detection: see Section 3.3, Appendix B, Appendix C, and Appendix E.   \n\u2022 We show how to utilize the test martingale to analytically design a mapping function that transports the classifier entropies obtained at test time to resemble those of the source domain. The derivation of the algorithm is given in Sections 3.4, 3.5, and Appendix E.   \n\u2022 We also conducted a wide range of experiments to support our approach in Sections 3.2, 4, and Appendix F. ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We describe the problem setup and our assumptions in Section 2.1 and further discuss the limitations of our work in Section 5. ", "page_idx": 30}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The theoretical claims provided in Section 3.3, Appendix B, and Section 3.4 are proved in Appendix C. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: In Appendix F we provide all of the implementation details. The code used to conduct the experiments is attached to the submission as supplementary material. An open-source GitHub repository would be published upon publication. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: ImageNet and ImageNetC are both publicly available datasets. The data used in the synthetic experiment can be reproduced by running the code provided or implementing it based on Appendix F. All the results reported in the paper can be reproduced by running our software package. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The experiments settings are described in Section 3.2 and Section 4. All the implementation details are extensively discussed in Appendix F. ", "page_idx": 30}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We show the standard error in all graphs; we also report the standard errors in Tables 2 and 3. ", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: In Appendix F.2 we detail the computational resources we used to conduct the experiments in this work. ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The work is done in appropriation with https://neurips.cc/public/ EthicsGuidelines. ", "page_idx": 31}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We discussed the broader impacts of this work in Section 5. ", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: We do not release anything that warrants a safeguard. ", "page_idx": 31}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We credit prior contributions that we build upon, as well as provide links to the relevant code repositories. The open-source ImageNet and ImageNet-C datasets are also credited. ", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: While we do not provide new assets, we support the paper with a properly documented software package. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: No human subjects were used in this work. ", "page_idx": 32}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] Justification: No human subjects were used in this work. ", "page_idx": 32}]