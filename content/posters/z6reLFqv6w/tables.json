[{"figure_path": "z6reLFqv6w/tables/tables_8_1.jpg", "caption": "Table 1: Our method learns emergent features in multiscale datasets of brain activity. Final values of \u03a8 and \u03a8A as found during the training run of fe and post-hoc evaluation respectively. All values are greater than zero, indicating that in each case an emergent feature has been found.", "description": "This table summarizes the results of applying the proposed method to three different brain activity datasets: ECOG, MEG, and fMRI. For each dataset, it reports the values of two metrics calculated during the model training and post-hoc testing:  the training emergence metric (\u03a8) and the adjusted emergence metric (\u03a8A).  The post-hoc values are calculated after the model training is complete, providing further confirmation that emergent features were found. The table demonstrates the method's ability to detect emergent features across various neuroimaging modalities and scales.", "section": "3 Results"}, {"figure_path": "z6reLFqv6w/tables/tables_18_1.jpg", "caption": "Table 2: Hyperparameters for causal emergence representation learning on synthetic data", "description": "This table lists the hyperparameters used in the causal emergence representation learning experiments on synthetic data.  It includes parameters for the network architecture (number of layers, sizes of layers), training process (batch size, learning rates, weight decay), and the data generation process (autocorrelation parameters for the parity and extra bits).  These hyperparameters were chosen to balance the trade-off between model complexity and training efficiency, leading to the best results on the synthetic data.", "section": "2.3 Datasets"}, {"figure_path": "z6reLFqv6w/tables/tables_18_2.jpg", "caption": "Table 4: Hyperparameters used to train emergent feature network on MEG and fMRI dataset with \u03a8 criterion", "description": "This table lists the hyperparameters used for training the emergent feature network on MEG and fMRI datasets using the \u03a8 criterion.  It includes parameters such as batch size, the architecture of the representation network (f\u03b8) and critics, the learning rates for the different components of the model, and the number of training steps, highlighting the settings for optimizing the emergence objective function.", "section": "3.4 Learning emergent features in brain activity data"}, {"figure_path": "z6reLFqv6w/tables/tables_19_1.jpg", "caption": "Table 4: Hyperparameters used to train emergent feature network on MEG and fMRI dataset with \u03a8", "description": "This table lists the hyperparameters used for training the emergent feature network on MEG and fMRI datasets using the \u03a8 criterion.  It includes parameters for batch size, critic layer sizes, learning rates, number of training epochs,  fe layer sizes, fe learning rate, fe weight decay, number of steps to pretrain critics and number of steps between updates. These parameters were set to optimize the model's performance and stability in learning emergent features from the high-dimensional brain activity data.", "section": "3.4 Learning emergent features in brain activity data"}, {"figure_path": "z6reLFqv6w/tables/tables_19_2.jpg", "caption": "Table 5: Hyperparameters for Game of Life emergent feature learning with \u03a8 criterion", "description": "This table lists the hyperparameters used to train the model for learning emergent features in the Conway's Game of Life dataset.  It includes settings for the grid size, batch size, number of training epochs, feature size, the number of steps used for pretraining the critics, and the number of steps between updates for the representation learning network.  Layer sizes are specified for both the convolutional encoder and the critics, along with learning rates for both the encoder and critic networks. ", "section": "2.3 Datasets"}]