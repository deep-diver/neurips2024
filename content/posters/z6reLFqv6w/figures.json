[{"figure_path": "z6reLFqv6w/figures/figures_2_1.jpg", "caption": "Figure 1: Architecture for calculating loss terms for learning causally emergent representations. A representation network f\u03b8 applied to the data Xt learns a feature Vt. This feature is trained to optimise \u03a8 made up of predictive and marginal mutual information terms estimated by g\u03c6 and h\u03bei respectively (left). A further critic k\u03c3 may be added to calculate the mutual information with another emergent feature VA, to encourage the learning of a diverse set of emergent features (right).", "description": "This figure illustrates the architecture of the proposed model for learning causally emergent representations. The model consists of a representation network (f\u03b8) that learns a feature (Vt) from the input data (Xt).  The feature Vt is trained to maximize an objective function (\u03a8) that consists of predictive mutual information (I(Vt; Vt+1), estimated by g\u03c6) and marginal mutual information terms (I(Xi; Vt+1), estimated by h\u03bei). An optional critic (k\u03c3) is included to encourage diversity in the learned emergent features by estimating the mutual information between multiple emergent features (I(VA; Vt)).", "section": "2.2 Model architecture and information estimators"}, {"figure_path": "z6reLFqv6w/figures/figures_5_1.jpg", "caption": "Figure 2: The proposed architecture recovers ground truth emergent features. Using the emergence objective function (left column), the model finds the correct \u03a8 value and is able to recover the known emergent feature (parity bit). Using only predictive MI as the objective (right column), the model fails to discover any emergent features.", "description": "This figure shows the results of training a model to learn emergent features in a synthetic dataset. The left column shows the results when the model is trained using the full emergence objective function, which includes both predictive and marginal mutual information terms. In this case, the model successfully recovers the ground truth emergence value and is able to identify the known emergent feature (the parity bit). The right column shows the results when the model is trained using only the predictive mutual information term. In this case, the model fails to discover any emergent features. This demonstrates the importance of including marginal mutual information terms in the objective function for learning emergent representations.", "section": "3.1 Learning emergent features in synthetic datasets"}, {"figure_path": "z6reLFqv6w/figures/figures_6_1.jpg", "caption": "Figure 3: Our method learns a diverse set of multiple emergent features from the same system. Training two representation learners to learn independent emergent feature on the synthetic dataset. Both learned features were emergent (top row). The first learner (left column) yielded a feature that has high mutual information with the system's parity bit (bottom left), while for the second learner (right column) it had high mutual information with the bonus bit (bottom right).", "description": "This figure demonstrates the ability of the proposed method to learn multiple independent emergent features from the same system.  Two separate representation learners were trained on a synthetic bit-string dataset, each aiming to maximize emergence. The top row shows the emergence estimates over training steps for each learner, indicating successful identification of emergent features. The bottom row shows the mutual information between the learned features and the ground truth features (parity bit and bonus bit).  The results confirm that the two learners identified different, independent emergent features, one strongly correlated with the parity and the other with the bonus bit.", "section": "3.2 Learning diverse features in the bit-string dataset"}, {"figure_path": "z6reLFqv6w/figures/figures_7_1.jpg", "caption": "Figure 4: Standard methods do not learn emergent features, and their performance increases when combined with emergent features.. The hidden state of an RNN trained on the bit-string dataset has negligible \u03a8A, indicating no emergent feature learned (left). Accordingly, the mutual information between the hidden state and the extra, parity, and bonus bits shows that only the non-emergent extra bit is encoded (middle). Interestingly, representations learned by an RNN and by our method can be combined to yield better predictions of the future state of the system (right).", "description": "This figure shows a comparison between the performance of a standard RNN, the proposed emergence learning method, and a combination of both in learning emergent features from a synthetic dataset. The left panel shows that the RNN fails to capture emergent features. The middle panel shows that the RNN mainly encodes non-emergent information. The right panel shows that combining the RNN and the emergence learner improves prediction performance.", "section": "3.3 Comparison to baselines and ablation studies"}, {"figure_path": "z6reLFqv6w/figures/figures_14_1.jpg", "caption": "Figure 2: The proposed architecture recovers ground truth emergent features. Using the emergence objective function (left column), the model finds the correct \u03a8 value and is able to recover the known emergent feature (parity bit). Using only predictive MI as the objective (right column), the model fails to discover any emergent features.", "description": "This figure shows the results of training a model to learn emergent features from synthetic data.  The left column demonstrates that using the full emergence objective function successfully leads to the model recovering the ground truth emergence value (\u03a8) and identifying the known emergent feature (parity bit). The right column shows that when using only the predictive mutual information (MI) as the objective, the model fails to discover any emergent features, highlighting the importance of the full emergence objective for identifying emergent properties.", "section": "3.1 Learning emergent features in synthetic datasets"}, {"figure_path": "z6reLFqv6w/figures/figures_14_2.jpg", "caption": "Figure 2: The proposed architecture recovers ground truth emergent features. Using the emergence objective function (left column), the model finds the correct \u03a8 value and is able to recover the known emergent feature (parity bit). Using only predictive MI as the objective (right column), the model fails to discover any emergent features.", "description": "This figure shows the results of training a model to learn emergent features from a synthetic dataset.  The left column shows the results when the model is trained to maximize emergence using the proposed method.  The model successfully identifies the ground truth value of emergence (\u03a8) and recovers the known emergent feature (parity bit). In contrast, the right column displays the results obtained when the model is trained only to maximize predictive mutual information. In this case, the model fails to identify any emergent features.", "section": "3.1 Learning emergent features in synthetic datasets"}, {"figure_path": "z6reLFqv6w/figures/figures_15_1.jpg", "caption": "Figure 7: Glider states in the Game of Life simulation. Gliders cycle deterministically between these four states. To interpret the learned emergent feature in the experiments in Section 3.1, we trained a standard classification MLP to predict these four states from the value of Vt.", "description": "This figure shows the four states of a glider in Conway's Game of Life.  A glider is a specific pattern of cells that moves across the grid.  To understand the emergent features learned by the model, a Multilayer Perceptron (MLP) classifier was trained to predict these four states based on the learned representation Vt. This helps to interpret the meaning of the learned features in the context of the Game of Life.", "section": "2.3.1 Synthetic datasets"}, {"figure_path": "z6reLFqv6w/figures/figures_15_2.jpg", "caption": "Figure 8: Our method learns interpretable emergent features in Conway's Game of Life. a) Post-hoc checks reveal \u03a8A > 0, confirming the learned feature is emergent. b) Classification accuracy of the state of the glider (c.f. Supp. Fig. 7) on a held-out test set. Dashed black line represents chance level at 25%.", "description": "This figure shows the results of applying the proposed method to Conway's Game of Life.  Panel (a) demonstrates that the learned feature is indeed emergent by showing a positive value for the adjusted emergence metric (\u03a8A) after training.  Panel (b) shows the accuracy of a classifier trained to predict the state of the glider based on the learned feature. The high accuracy, exceeding the chance level, suggests that the learned feature captures relevant information about the glider's state.", "section": "3.1 Learning emergent features in synthetic datasets"}, {"figure_path": "z6reLFqv6w/figures/figures_15_3.jpg", "caption": "Figure 9: Learning emergent features from brain activity datasets. Post-hoc \u03a8A checks for our representation learner trained on a) primate ECoG data, b) human MEG data, and c) human fMRI data. Emergent features were successfully learned in all cases.", "description": "This figure shows the results of applying the proposed method to three different real-world brain activity datasets: primate electrocorticography (ECOG), human magnetoencephalography (MEG), and human functional magnetic resonance imaging (fMRI).  For each dataset, the emergence metric (\u03a8A) is plotted against training steps. The shaded area represents the standard deviation across multiple runs. The results indicate that the method successfully identifies emergent features across different brain recording modalities and spatial scales.", "section": "3 Results"}, {"figure_path": "z6reLFqv6w/figures/figures_16_1.jpg", "caption": "Figure 10: Learning diverse emergent features from ECoG brain activity data. a) After learning one emergent feature on the ECoG data (c.f. Supp. Fig. 9, adding the diversity loss term and training a new representation network results in another emergent feature, verified by a post-hoc \u03a8A check. b) We further verify that the new feature Vt is nearly independent from the previous one VA, as their mutual information (estimated with SMILE and the critic ko) vanishes.", "description": "This figure shows the results of training two representation learners to learn independent emergent features from the same ECOG dataset. The top panel (a) shows the emergence values (\u03a8A) for both learners, confirming that both features are indeed emergent.  The bottom panel (b) displays the mutual information (I(Vt; VA)) between the two features over time, showing that they are statistically independent, further supporting the idea that the model has successfully learned diverse emergent features.", "section": "3.4 Learning emergent features in brain activity data"}]