[{"figure_path": "xbuaSTqAEz/tables/tables_6_1.jpg", "caption": "Table 1: Dataset Statistics.", "description": "This table presents the statistics of eight datasets used in the paper's experiments. For each dataset, it shows the number of samples, the types of hand-crafted features used (if any), and the number of clusters used in the multiple clustering tasks.  The datasets cover diverse domains, including cars, playing cards, faces, fruits, flowers and general images, demonstrating the broad applicability of the proposed Multi-Sub method.", "section": "4 Experiments"}, {"figure_path": "xbuaSTqAEz/tables/tables_6_2.jpg", "caption": "Table 2: Quantitative comparison. The significantly best results with 95% confidence are in bold.", "description": "This table presents a quantitative comparison of the proposed Multi-Sub method with several other multiple clustering methods across a range of datasets.  The performance is measured using two metrics: Normalized Mutual Information (NMI) and Rand Index (RI).  Higher values for both metrics indicate better clustering performance.  The table highlights the datasets used, the type of clustering (e.g., by color, species), and the performance of each method on each dataset and clustering type.  The best performing method for each dataset and clustering type (with 95% confidence) is shown in bold.", "section": "4 Experiments"}, {"figure_path": "xbuaSTqAEz/tables/tables_7_1.jpg", "caption": "Table 3: Variants of CLIP. The significantly best results with 95% confidence are in bold.", "description": "This table compares the performance of three different CLIP variants (CLIP label, CLIPGPT, and Multi-Sub) across various datasets and clustering tasks.  The \"CLIP label\" variant uses ground truth labels, providing an upper bound on performance; \"CLIPGPT\" uses GPT-4 to generate labels, introducing noise into the process; and \"Multi-Sub\" represents the proposed method in the paper. The results show the Normalized Mutual Information (NMI) and Rand Index (RI) for each variant, highlighting Multi-Sub's superior performance in nearly all cases.", "section": "4 Experiments"}, {"figure_path": "xbuaSTqAEz/tables/tables_8_1.jpg", "caption": "Table 4: Comparison of different text encoders. The significantly best results with 95% confidence are in bold.", "description": "This table compares the performance of three different text encoders (CLIP, ALIGN, and BLIP) across various datasets and clustering tasks.  The results are presented in terms of Normalized Mutual Information (NMI) and Rand Index (RI).  The highest NMI and RI scores for each dataset and clustering type are shown in bold, indicating statistically significant improvements by ALIGN in most of the cases.  This table helps to assess the relative strengths and weaknesses of the different text encoders for use in multiple clustering tasks.", "section": "4 Experiments"}, {"figure_path": "xbuaSTqAEz/tables/tables_8_2.jpg", "caption": "Table 5: Ablation study of Multi-Sub. The results that achieved the highest and second highest performance for each clustering are indicated by boldface and underlined numerals, respectively.", "description": "This table presents the ablation study results for the Multi-Sub model, focusing on different ways of constructing the subspace and the impact of various text encoders.  It compares the performance (NMI and RI) across various clustering methods using different text and image representations. The highest and second-highest performing methods for each combination are highlighted.", "section": "4.2 Ablation study"}, {"figure_path": "xbuaSTqAEz/tables/tables_9_1.jpg", "caption": "Table 4: Comparison of different text encoders. The significantly best results with 95% confidence are in bold.", "description": "This table compares the performance of three different text encoders (CLIP, ALIGN, and BLIP) across various datasets and clustering tasks (color, species, order, suits, emotion, glass, identity, pose, type, and environment).  The best-performing encoder varies depending on the specific dataset and task, highlighting the importance of selecting an appropriate text encoder for optimal results in multi-modal clustering.", "section": "4 Experiments"}, {"figure_path": "xbuaSTqAEz/tables/tables_13_1.jpg", "caption": "Table 7: Clustering performance based on shape demand on the Fruit dataset.", "description": "This table presents a comparison of different multiple clustering methods' performance on the Fruit dataset, specifically focusing on a new clustering task based on the shape of the fruits (round vs. elongated).  The results demonstrate Multi-Sub's adaptability to new user-defined clustering criteria.", "section": "A.1 Further Analysis"}]