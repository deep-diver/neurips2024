{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduced NeRF, a foundational model for novel view synthesis that heavily influenced subsequent work on dynamic view synthesis and is directly referenced in the Exo2Ego-V paper's discussion of related work."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "As a state-of-the-art video diffusion model, it served as a strong baseline for comparison in the Exo2Ego-V experiments, highlighting the advancements made by the proposed method."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Video diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduced Video Diffusion Models (VDM), a key component within the Exo2Ego-V framework, which the authors extend and improve upon for their specific task."}, {"fullname_first_author": "Kristen Grauman", "paper_title": "Ego-exo4D: Understanding skilled human activity from first-and third-person perspectives", "publication_date": "2023-11-18", "reason": "The Ego-Exo4D dataset, introduced in this paper, is the primary dataset used to evaluate the Exo2Ego-V model's performance and is crucial for understanding the context and challenges addressed by the work."}, {"fullname_first_author": "Alex Yu", "paper_title": "PixelNeRF: Neural radiance fields from one or few images", "publication_date": "2021-00-00", "reason": "This paper introduced PixelNeRF, which inspired the design of the Exo2Ego view translation prior, a crucial component within the Exo2Ego-V framework for providing spatially aligned egocentric features."}]}