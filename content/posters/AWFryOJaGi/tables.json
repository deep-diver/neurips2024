[{"figure_path": "AWFryOJaGi/tables/tables_8_1.jpg", "caption": "Table 2: Performance comparison with dangling-entities-unaware baselines on GA16K.", "description": "This table presents the performance comparison results on the GA16K dataset between the proposed method and several state-of-the-art dangling-entities-unaware baselines.  The metrics used are Hits@1, Hits@10, and Hits@50, which measure the accuracy of the top-ranked predictions for entity alignment.  The results show that the proposed method outperforms or matches the performance of most baselines, indicating its effectiveness in entity alignment tasks even without explicitly considering dangling entities.", "section": "5 Experiments"}, {"figure_path": "AWFryOJaGi/tables/tables_8_2.jpg", "caption": "Table 3: Dangling detection results on DBP2.0 in the consolidated setting.", "description": "This table presents the performance of dangling entity detection methods on the DBP2.0 dataset, specifically focusing on the \"consolidated setting.\"  The consolidated setting means the evaluation includes both matchable and dangling entities.  The results are broken down by language pair (e.g., ZH-EN, EN-ZH), and for each pair, it shows the precision, recall, and F1-score for three different methods: Nearest Neighbor Classification (NNC), Marginal Ranking (MR), and Background Ranking (BR). The table also includes the results for the proposed \"Our Work\" method, demonstrating its performance compared to existing techniques in this more challenging scenario.", "section": "5 Experiments"}, {"figure_path": "AWFryOJaGi/tables/tables_18_1.jpg", "caption": "Table 1: Different EA models with dangling cases.", "description": "This table compares different entity alignment (EA) models in terms of their handling of dangling entities (entities without counterparts in the other knowledge graph).  It shows whether each method uses side information (like entity names or attributes), and whether it requires labeled dangling entities for training.  The table highlights that the proposed method in the paper is unique because it does not use side information nor labeled dangling entities.", "section": "1 Introduction"}, {"figure_path": "AWFryOJaGi/tables/tables_18_2.jpg", "caption": "Table 6: Statistics of DBP2.0-Plus and DBP2.0-Minus", "description": "This table presents the statistics of the DBP2.0-Plus and DBP2.0-Minus datasets.  These datasets are variations of the original DBP2.0 dataset, modified to have different proportions of positive (matchable) entities.  DBP2.0-Plus has a higher proportion of positive entities than the original DBP2.0, while DBP2.0-Minus has a lower proportion.  The table shows the number of entities, relations, triples, dangling entities, and aligned entities for each language pair (ZH-EN, JA-EN) in both datasets.", "section": "5 Experiments"}, {"figure_path": "AWFryOJaGi/tables/tables_19_1.jpg", "caption": "Table 7: Statistics of GA-DBP15K. c = [25%,20%,15%,10%].", "description": "This table presents the statistics of the GA-DBP15K dataset, which is a combination of the GA16K and DBP15K datasets.  It shows the number of entities, dangling entities, and aligned entities for each language pair (GA-EN, GA-ZH, GA-JA, GA-FR). The 'Align' column indicates the number of pre-aligned entity pairs from the DBP15K dataset, and the 'c%' represents the percentage of these pre-aligned pairs that are included in the final alignment, varying from 10% to 25%. This dataset is designed to evaluate the performance of entity alignment algorithms in the presence of a significant number of dangling entities.", "section": "5 Experiments"}, {"figure_path": "AWFryOJaGi/tables/tables_21_1.jpg", "caption": "Table 2: Performance comparison with dangling-entities-unaware baselines on GA16K.", "description": "This table compares the performance of the proposed method with several dangling-entities-unaware baselines on the GA16K dataset.  The metrics used are Hits@1, Hits@10, and Hits@50, which measure the accuracy of the entity alignment method at retrieving the correct alignment within the top 1, 10, and 50 results, respectively. The table highlights the superior performance of the proposed method compared to existing state-of-the-art methods.", "section": "5 Experiments"}, {"figure_path": "AWFryOJaGi/tables/tables_22_1.jpg", "caption": "Table 9: The entity alignment performance over different embedding dimensions on DBP2.0.", "description": "This table shows the impact of different embedding dimensions (64, 96, and 128) on the entity alignment performance across six different language pairs in the DBP2.0 dataset.  The results, presented as precision, recall, and F1-score, highlight the optimal embedding dimension for each language pair, demonstrating the sensitivity of model performance to this hyperparameter.", "section": "5.4 Ablation Studies and Varying Anchor Nodes"}, {"figure_path": "AWFryOJaGi/tables/tables_23_1.jpg", "caption": "Table 2: Performance comparison with dangling-entities-unaware baselines on GA16K.", "description": "This table presents a comparison of the proposed method's performance against several other methods on the GA16K dataset.  The methods compared are all \"Dangling-Entities-Unaware,\" meaning they do not explicitly handle or account for dangling entities in their models.  The table shows the Hits@K (K=1, 10, 50) metric for each method, which measures the accuracy of identifying correctly aligned entity pairs.  Higher Hits@K scores indicate better performance.  The results demonstrate that the proposed method outperforms the baselines, indicating its effectiveness even without specific handling of dangling entities.", "section": "5 Experiments"}, {"figure_path": "AWFryOJaGi/tables/tables_23_2.jpg", "caption": "Table 1: Different EA models with dangling cases.", "description": "This table compares different entity alignment (EA) models based on whether they utilize side information and labeled dangling entities.  It highlights that the proposed work, unlike others, does not require any labeled dangling entities or side information, making it suitable for scenarios with limited labeled data.", "section": "1 Introduction"}, {"figure_path": "AWFryOJaGi/tables/tables_23_3.jpg", "caption": "Table 12: Comparison of Lambda and LightEA under relaxed setting. '-' indicates the absence of data due to out of time.", "description": "This table compares the performance of the proposed method (Lambda) and a strong baseline method (LightEA) on the entity alignment task under a relaxed setting.  The relaxed setting refers to a scenario where dangling entities are not removed from the evaluation.  The results are shown for three different language pairs: ZH-EN, JA-EN, and FR-EN. Hits@1 and Hits@10 metrics are used to evaluate the performance.", "section": "G.6 LightEA as Strong Baseline for Comparison"}, {"figure_path": "AWFryOJaGi/tables/tables_24_1.jpg", "caption": "Table 13: Dangling entities detection by our classifier v.s. a trivial one on DBP2.0.", "description": "This table compares the performance of the proposed dangling entity detection method against a trivial classifier on the DBP2.0 dataset.  The proposed method significantly outperforms the trivial classifier in terms of precision, recall, and F1-score for all language pairs. The trivial classifier, which classifies all entities as dangling, serves as a baseline for comparison. This highlights the effectiveness of the proposed method in accurately identifying dangling entities.", "section": "5.3 Experiments Aware of Dangling Entities"}]