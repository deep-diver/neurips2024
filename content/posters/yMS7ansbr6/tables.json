[{"figure_path": "yMS7ansbr6/tables/tables_6_1.jpg", "caption": "Table 1: Cross-datasets validation. Results on AVLips, FF++, and DFDC are reported, including acc, ap, fpr, and fnr. The best result is highlighted in bold, while the second-ranking one is underscored. Throughout the entire experiment, the threshold for the AP metric was set to 0.5.", "description": "This table presents the performance comparison of LipFD and other state-of-the-art (SOTA) methods on three different datasets: AVLips, FaceForensics++, and DeepFake Detection Challenge dataset.  The metrics used are accuracy (ACC), average precision (AP), false positive rate (FPR), and false negative rate (FNR).  The best performing method for each dataset and metric is highlighted in bold, showing LipFD's superior performance.", "section": "5 Effectiveness Evaluation"}, {"figure_path": "yMS7ansbr6/tables/tables_6_2.jpg", "caption": "Table 2: Cross-manipulation generalization. Evaluation scores when videos are exposed to various unseen forgery algorithms.", "description": "This table presents the results of evaluating the model's performance on videos generated using unseen forgery algorithms.  It demonstrates the generalizability of the model by testing its ability to detect lip-sync deepfakes created with methods not included in its training data. The metrics used are accuracy (ACC), average precision (AP), false positive rate (FPR), and false negative rate (FNR).  The higher the accuracy and average precision scores, while keeping the false positive and negative rates low, the better the model's performance at generalizing to unseen methods. ", "section": "5 Experiment"}, {"figure_path": "yMS7ansbr6/tables/tables_6_3.jpg", "caption": "Table 3: Overall ablation results regarding core modules. We evaluated our model's performance after removing components listed in the left column.", "description": "This table presents the ablation study results of the LipFD model.  It shows the performance of the model when key components (Global Encoder, Global-Region Encoder, and Region Awareness) are removed one at a time. The results (ACC, AP, FPR, FNR, AUC) highlight the importance of each component in achieving high accuracy in lip-sync forgery detection.", "section": "5 Experiment"}, {"figure_path": "yMS7ansbr6/tables/tables_9_1.jpg", "caption": "Table 4: Performance under different ViT structures. We selected six popular vision transformers as Global Feature Encoder and tested the final performance of our model.", "description": "This table presents the performance comparison of different Vision Transformers (ViTs) used as the Global Feature Encoder in the LipFD model.  It shows the Accuracy (ACC), Average Precision (AP), False Positive Rate (FPR), and False Negative Rate (FNR) achieved by the model using six different ViT architectures.  These architectures are variations of CLIP and ImageNet pre-trained ViTs and Swin Transformers, with different sizes (L14, B16, L16, B16). The results highlight the impact of the choice of ViT on the model's overall performance in LipSync forgery detection.", "section": "6 Ablation Studies"}, {"figure_path": "yMS7ansbr6/tables/tables_16_1.jpg", "caption": "Table 5: Robustness experiment parameters. Each perturbation method employs five unique sets of hyperparameter values, modifying them solely during the video preprocessing phase.", "description": "This table details the hyperparameters used in the robustness experiments.  Each type of perturbation (Block-wise, Color Contrast, Color Saturation, Gaussian Blur, Gaussian Noise, Pixelation, Compression) has five different \"severity\" levels, each with a corresponding hyperparameter value. This allows for a systematic evaluation of the model's resilience to various degrees of image corruption.", "section": "5 Experiment"}, {"figure_path": "yMS7ansbr6/tables/tables_16_2.jpg", "caption": "Table 6: Evaluation of Real-world scenarios. Detection accuracy under various network delays and languages. CH stands for Chinese, and EN is in short for English.", "description": "This table shows the performance of the proposed LipFD model in real-world scenarios with different network delays (100ms, 200ms, and 500ms) and languages (Chinese and English).  The accuracy is measured for two types of scenarios: WeChat video calls and streaming media. The results demonstrate the robustness and real-world applicability of the proposed model, showing how the model performs in less-than-ideal network conditions.", "section": "5.5 Performance in Real Scenarios"}]