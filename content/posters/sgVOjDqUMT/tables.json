[{"figure_path": "sgVOjDqUMT/tables/tables_8_1.jpg", "caption": "Table 1: Evaluation of different KV cache compression methods on LongBench. MiniCache builds on top of 4-bit KIVI [11] and achieves the best performance with the strongest compression rate.", "description": "This table presents the results of evaluating different KV cache compression methods on the LongBench benchmark.  The methods compared include the baseline (no compression), Round-to-Nearest Quantization (RTN), SmoothQuant, KIVI-2, and MiniCache.  The table shows the performance of each method across several metrics (LCC, RepoBench-P, PR-en, TREC, 2wikimqa, GovReport, MQA-zh, and Average) for four different LLMs (Llama-2-7B-Chat, Llama-2-13B-Chat, Mistral-7B, and Mistral-7B-Instruct).  The \"Compression Ratio\" column indicates the memory savings achieved by each method compared to the baseline. MiniCache consistently demonstrates the highest compression ratio, indicating it is the most memory efficient.", "section": "5 Experiments"}, {"figure_path": "sgVOjDqUMT/tables/tables_8_2.jpg", "caption": "Table 2: Comparisons of various token retention thresholds \u03b3 by LLaMA-2-7B [5] on three benchmarks.", "description": "This table shows the performance of LLaMA-2-7B on three benchmark datasets (COQA, GSM8K, TruthfulQA) using different token retention thresholds (\u03b3).  The retention threshold controls how many tokens are kept during the merging process, balancing compression ratio and performance. The results show a tradeoff: Increasing \u03b3 improves performance but reduces compression. The optimal value seems to be around 0.05, offering a good balance between the two factors.", "section": "5 Experiments"}, {"figure_path": "sgVOjDqUMT/tables/tables_15_1.jpg", "caption": "Table A: Comparison between MiniCache with token sparsity based method H2O, using mistral-7B-instruct on LongBench dataset.", "description": "This table compares the performance of MiniCache against H2O (a token sparsity method) and Attention Sink on the LongBench dataset using the Mistral-7B-instruct model.  It shows the exact match scores or BLEU scores across multiple question answering and summarization tasks to demonstrate MiniCache's performance in comparison to other state-of-the-art approaches.", "section": "Additional Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_15_2.jpg", "caption": "Table B: Execution time comparison for different sequence lengths. We benchmarked the latency of LLaMA-2-7B on an NVIDIA A100 GPU using sequence lengths ranging from 1024 to 4096 with a batch size of 16.", "description": "This table compares the execution time of the H2O method and MiniCache method for different sequence lengths (1024, 2048, 3072, and 4096 tokens) with a batch size of 16 using an NVIDIA A100 GPU.  It demonstrates the latency reduction achieved by MiniCache compared to H2O, highlighting the efficiency improvements gained through the MiniCache's lightweight computations and matrix manipulations.", "section": "Additional Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_15_3.jpg", "caption": "Table C: Performance comparison of LLaMA-2-7B under different retention ratios of overall tokens.", "description": "This table presents the results of experiments evaluating the performance of the LLaMA-2-7B model under various retention ratios.  It shows the impact of keeping different percentages of tokens on the model's performance across three datasets: COQA, GSM8K, and TruthfulQA.  The exact match scores and BLEU scores (for TruthfulQA) are reported for different retention ratios (0%, 0.01%, 0.05%, 0.1%, 0.2%, and 1%) illustrating the trade-off between model accuracy and the number of tokens retained (memory efficiency).", "section": "Ablation for relations between performance and ratio of merged tokens"}, {"figure_path": "sgVOjDqUMT/tables/tables_15_4.jpg", "caption": "Table 2: Comparisons of various token retention thresholds \u03b3 by LLaMA-2-7B [5] on three benchmarks.", "description": "This table presents a comparison of the performance of LLaMA-2-7B across three benchmark datasets (COQA, GSM8K, TruthfulQA) while varying the token retention threshold (\u03b3).  The token retention threshold influences how many tokens are retained during merging which affects the final compression ratio.  The table shows that a token retention threshold (\u03b3) of 0.05 provides the best balance between performance and compression, achieving the highest compression ratio of 5.023x while maintaining relatively high scores on all three benchmarks.", "section": "5 Experiments"}, {"figure_path": "sgVOjDqUMT/tables/tables_16_1.jpg", "caption": "Table E: We benchmark the different components in the reparameterization and restoration stages using LLaMA-2-7B.", "description": "This table presents a benchmark of the computational overhead of different components within the reparameterization and restoration stages of the MiniCache algorithm using the LLaMA-2-7B model.  It breaks down the running times (in milliseconds) and standard variations for the magnitude, direction, distance calculation, token replacement, and overall attention computation. The results highlight that the computational overhead of the reparameterization and restoration processes is negligible compared to the overall attention computation.", "section": "Additional Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_16_2.jpg", "caption": "Table F: Performance comparison and compression ratios across different methods. MiniCache is orthogonal to existing quantization techniques.", "description": "This table compares the performance (Exact Match scores on COQA, GSM8K, and TruthfulQA datasets) and compression ratios of different KV cache compression methods: FP16 (full precision), KIVI-2 (2-bit quantization), KIVI-4 (4-bit quantization), Cross-layer Merging (MiniCache without quantization), and Cross-layer Merging + 4-bit quantization.  It highlights that MiniCache's cross-layer merging is orthogonal to existing quantization techniques and shows the combined effect of both techniques. The compression ratios are relative to the FP16 baseline.", "section": "Efficiency comparison without quantization"}, {"figure_path": "sgVOjDqUMT/tables/tables_17_1.jpg", "caption": "Table G: Comparison of performance using different cross-layer merging strategies. The experiment shows that SLERP has the best performance across three datasets.", "description": "This table compares the performance of three different cross-layer merging strategies: Average, Max Norm, and SLERP, across three datasets (COQA, GSM8K, and TruthfulQA).  The results show that SLERP consistently outperforms the other two strategies, indicating its superior effectiveness in merging KV cache states while preserving performance.", "section": "C Discussions and Limitations"}, {"figure_path": "sgVOjDqUMT/tables/tables_22_1.jpg", "caption": "Table H: Detailed performance comparison on GSM8K dataset with LLaMA-3-70B.", "description": "This table presents a detailed comparison of the performance of LLaMA-3-70B with and without MiniCache on the GSM8K dataset.  The results are broken down by layer, showing the Exact Match (EM) score for both the baseline LLaMA-3-70B model and the model enhanced with MiniCache.  This allows for a layer-by-layer analysis of the effectiveness of MiniCache in improving performance.", "section": "Detailed Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_23_1.jpg", "caption": "Table I: Detailed performance comparison on COQA dataset with LLaMA-3-70B.", "description": "This table presents a detailed comparison of the performance of the LLaMA-3-70B model with and without MiniCache on the COQA dataset.  It shows the exact match scores for both methods across different layers of the model, allowing for an assessment of the impact of MiniCache on performance at varying depths.", "section": "Detailed Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_23_2.jpg", "caption": "Table J: Detailed performance comparison on TruthfulQA dataset with LLaMA-3-70B.", "description": "This table presents a detailed performance comparison of the LLaMA-3-70B model on the TruthfulQA dataset, broken down by layer.  It shows the exact match scores achieved by both the standard LLaMA-3-70B model and the MiniCache-enhanced version, allowing for a layer-by-layer analysis of the impact of MiniCache on performance.  The \"Mean\" column likely represents the average performance across all layers.", "section": "5 Experiments"}, {"figure_path": "sgVOjDqUMT/tables/tables_24_1.jpg", "caption": "Table K: Detailed performance comparison on GSM8K dataset with LLaMA-3-8B.", "description": "This table presents a detailed comparison of the performance of the LLaMA-3-8B model on the GSM8K dataset, comparing the model's performance using the MiniCache technique against its performance using a simple averaging method.  It shows the exact match scores for both methods across various layers of the model, providing a layer-by-layer analysis of performance differences between the two methods.", "section": "5 Experiments"}, {"figure_path": "sgVOjDqUMT/tables/tables_24_2.jpg", "caption": "Table L: Detailed performance comparison on COQA dataset with LLaMA-3-8B.", "description": "This table presents a detailed comparison of the performance of the LLaMA-3-8B model with and without the MiniCache technique on the COQA dataset.  It shows the exact match scores for each layer of the model, allowing for a layer-by-layer analysis of the impact of MiniCache on performance.  The comparison includes scores for the baseline LLaMA-3-8B model, the LLaMA-3-8B model using MiniCache, and the mean score across all layers for the MiniCache model.", "section": "Detailed Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_25_1.jpg", "caption": "Table H: Detailed performance comparison on GSM8K dataset with LLaMA-3-70B.", "description": "This table presents a detailed comparison of the performance of the LLaMA-3-70B model with and without MiniCache on the GSM8K dataset. It shows the Exact Match (EM) scores for both methods across different layers of the model.  The \"MiniCache\" column represents the performance achieved by applying the MiniCache compression technique. The \"LLaMA-3-70B Mean\" column indicates the average EM score across all layers. The table allows for a layer-by-layer analysis of the impact of MiniCache on the model's performance.", "section": "F Detailed Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_25_2.jpg", "caption": "Table N: Detailed performance comparison on GSM8K dataset with Mixtral-8x7B.", "description": "This table presents a detailed comparison of the performance of the Mixtral-8x7B model on the GSM8K dataset, comparing the full cache baseline, the simple average method, and MiniCache.  For each method, the exact match score is shown for different layers (0-32) of the model.", "section": "5 Experiments"}, {"figure_path": "sgVOjDqUMT/tables/tables_26_1.jpg", "caption": "Table O: Detailed performance comparison on COQA dataset with Mixtral-8x7B.", "description": "This table presents a detailed comparison of the performance of the Mixtral-8x7B model on the COQA dataset, broken down by layer. It shows the performance of the full model (Mixtral-8x7B Mean), the model using MiniCache, and the difference between the two.  This allows for a layer-by-layer analysis of how MiniCache impacts performance.", "section": "Detailed Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_26_2.jpg", "caption": "Table N: Detailed performance comparison on GSM8K dataset with Mixtral-8x7B.", "description": "This table presents a detailed comparison of the performance of the Mixtral-8x7B model on the GSM8K dataset, showing the results for both the MiniCache method and a baseline approach (simple average).  It breaks down the results by layer, indicating the exact match scores obtained at each layer. This allows for a layer-by-layer analysis of the impact of MiniCache on model performance.", "section": "5 Experiments"}, {"figure_path": "sgVOjDqUMT/tables/tables_27_1.jpg", "caption": "Table Q: Detailed performance comparison on GSM8K dataset with Phi-3-Mini.", "description": "This table presents a detailed comparison of the performance of the Phi-3-Mini model with and without the MiniCache technique on the GSM8K dataset.  It shows the EM score for both methods across different transformer layers (0-32). The data illustrates the performance degradation when merging layers, particularly in deeper layers. This provides quantitative evidence to support the paper's claims regarding the effectiveness of the MiniCache method in preserving performance while achieving compression.", "section": "Detailed Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_27_2.jpg", "caption": "Table R: Detailed performance comparison on COQA dataset with Phi-3-Mini.", "description": "This table presents a detailed comparison of the performance of the Phi-3-Mini model and the MiniCache technique on the COQA dataset.  It shows the exact match scores achieved by each method at various layers of the model. This allows for a layer-by-layer analysis of the impact of MiniCache on the performance of Phi-3-Mini on this specific dataset.", "section": "Detailed Experiment Results"}, {"figure_path": "sgVOjDqUMT/tables/tables_28_1.jpg", "caption": "Table S: Detailed performance comparison on TruthfulQA dataset with Phi-3-Mini.", "description": "This table presents a detailed breakdown of the performance comparison between the Phi-3-Mini model and the MiniCache method on the TruthfulQA dataset. It shows the performance scores for each model at different layers of the model. The \"Phi-3-Mini Mean\" column shows the average performance score across the layers for the Phi-3-Mini model.", "section": "5 Experiments"}]