[{"figure_path": "Cw7Agrr8GJ/figures/figures_1_1.jpg", "caption": "Figure 1: A brief description of LLM-DA. Specifically, LLM-DA harnesses LLMs to formulate general rules on historical data. Subsequently, LLM-DA dynamically guides the LLMs to update these rules based on current data, ensuring they more accurately reflect the objective distribution.", "description": "The figure illustrates the LLM-DA framework.  It shows how LLM-DA uses LLMs to generate rules from historical data.  These rules are then dynamically updated using current data, aiming to better match the actual distribution of relations in the Temporal Knowledge Graph (TKG).  The diagram visually represents the shift in data distributions from historical to current data, demonstrating how the dynamically updated rules better model the current relations.", "section": "1 Introduction"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_3_1.jpg", "caption": "Figure 2: The Framework of LLM-DA. Specifically, LLM-DA first analyzes historical data to extract temporal rules and utilizes the powerful generative capabilities of LLMs to generate general rules. Subsequently, LLM-DA updates these rules using current data. Finally, the updated rules are applied to predict future events.", "description": "The figure illustrates the framework of the LLM-DA method. It shows four main stages: 1) Temporal Logical Rules Sampling, where constrained Markovian random walks are used to extract temporal logical rules from historical data; 2) Rule Generation, where LLMs generate general rules based on historical data and top-k relevant relations selected by a contextual selector; 3) Dynamic Adaptation, where LLMs update the generated rules using current data; and 4) Candidate Reasoning, where rule-based and graph-based reasoning are combined to generate candidates for the final answer. The entire process is illustrated with an example query and answer.", "section": "4 Methodology"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_4_1.jpg", "caption": "Figure 3: The constraints of the constrained Markovian random walks. \"X\" denotes this path does not exist, \"P\" indicates the transition probability.", "description": "This figure illustrates the constraints applied during the constrained Markovian random walks process used in the LLM-DA method for temporal knowledge graph reasoning.  It shows how the temporal order and temporal intervals between events influence the selection of the next node during the random walk.  The 'X' symbol indicates paths that are disallowed due to violating these constraints, while 'P' represents the transition probabilities, highlighting that paths with shorter temporal intervals receive higher weights.  This ensures the random walk prioritizes temporally closer nodes, reflecting the evolving nature of the data.", "section": "4.1 Temporal Logical Rules Sampling"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_8_1.jpg", "caption": "Figure 1: A brief description of LLM-DA. Specifically, LLM-DA harnesses LLMs to formulate general rules on historical data. Subsequently, LLM-DA dynamically guides the LLMs to update these rules based on current data, ensuring they more accurately reflect the objective distribution.", "description": "The figure illustrates the LLM-DA framework.  LLM-DA uses LLMs to generate rules from historical data, then dynamically updates those rules with current data to improve accuracy.  The diagram shows the process, including the distribution of LLM-generated rules from historical data, how these rules are updated based on current data, and the objective distribution of relations in the TKG (Temporal Knowledge Graph).", "section": "1 Introduction"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_9_1.jpg", "caption": "Figure 5: Comparison with different number of iterations on both datasets.", "description": "This figure shows the impact of varying the number of iterations in the dynamic adaptation module of the LLM-DA model on the Mean Reciprocal Rank (MRR) metric for two datasets, ICEWS14 and ICEWS05-15.  The x-axis represents the number of iterations, while the y-axis shows the MRR values.  The graph indicates that increasing the number of iterations generally leads to improved performance on both datasets, although the rate of improvement diminishes with additional iterations.", "section": "5 Experiments"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_13_1.jpg", "caption": "Figure 2: The Framework of LLM-DA. Specifically, LLM-DA first analyzes historical data to extract temporal rules and utilizes the powerful generative capabilities of LLMs to generate general rules. Subsequently, LLM-DA updates these rules using current data. Finally, the updated rules are applied to predict future events.", "description": "This figure presents the framework of the LLM-DA method proposed in the paper. It shows the four main stages involved in the process: 1. Temporal Logical Rules Sampling: extracting rules from historical data; 2. Rule Generation: using LLMs to generate general rules based on historical data; 3. Dynamic Adaptation: updating these rules with current data; and 4. Candidate Reasoning: using the updated rules to predict future events.  The diagram visually depicts the flow of data and the interactions between different components of the framework.", "section": "4 Methodology"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_17_1.jpg", "caption": "Figure 2: The Framework of LLM-DA. Specifically, LLM-DA first analyzes historical data to extract temporal rules and utilizes the powerful generative capabilities of LLMs to generate general rules. Subsequently, LLM-DA updates these rules using current data. Finally, the updated rules are applied to predict future events.", "description": "This figure illustrates the framework of the Large Language Models-guided Dynamic Adaptation (LLM-DA) method.  The process begins with extracting temporal logical rules from historical data using constrained Markovian random walks.  A contextual relation selector filters the relations, providing context for LLMs to generate high-quality general rules.  These rules are then dynamically adapted using current data, ensuring they incorporate the most recent knowledge.  Finally, the updated rules are applied for reasoning and prediction on future events.", "section": "4 Methodology"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_17_2.jpg", "caption": "Figure 2: The Framework of LLM-DA. Specifically, LLM-DA first analyzes historical data to extract temporal rules and utilizes the powerful generative capabilities of LLMs to generate general rules. Subsequently, LLM-DA updates these rules using current data. Finally, the updated rules are applied to predict future events.", "description": "This figure illustrates the LLM-DA framework, showing the four main stages: 1) Temporal Logical Rules Sampling extracts rules from historical data using constrained Markovian random walks.  2) Rule Generation uses LLMs to generate general rules from the sampled rules and top-k relevant relations selected by the contextual relation selector.  3) Dynamic Adaptation updates these general rules using current data and LLMs.  4) Candidate Reasoning combines rule-based and graph-based reasoning using the updated rules and a graph neural network to generate candidate answers.", "section": "4 Methodology"}, {"figure_path": "Cw7Agrr8GJ/figures/figures_18_1.jpg", "caption": "Figure 2: The Framework of LLM-DA. Specifically, LLM-DA first analyzes historical data to extract temporal rules and utilizes the powerful generative capabilities of LLMs to generate general rules. Subsequently, LLM-DA updates these rules using current data. Finally, the updated rules are applied to predict future events.", "description": "This figure illustrates the framework of the LLM-DA model. The model begins by extracting temporal rules from historical data using constrained Markovian random walks. Then it uses LLMs to generate general rules from these extracted rules, incorporating the top-k most important relations identified by a contextual relation selector.  These rules are then dynamically updated using current data via another LLM process. Finally, the updated rules are applied to predict future events through a combination of rule-based and graph-based reasoning.", "section": "4 Methodology"}]