{"references": [{"fullname_first_author": "Mark Rowland", "paper_title": "Distributional Reinforcement Learning", "publication_date": "2023", "reason": "This book provides a foundational overview of distributional reinforcement learning, which is the central topic of the current paper."}, {"fullname_first_author": "Mohammad Gheshlaghi Azar", "paper_title": "Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model", "publication_date": "2013", "reason": "This paper establishes a minimax lower bound for the sample complexity of reinforcement learning with a generative model, which is a key theoretical benchmark for the current paper."}, {"fullname_first_author": "Marc G. Bellemare", "paper_title": "A distributional perspective on reinforcement learning", "publication_date": "2017", "reason": "This paper introduced the distributional Bellman equation, which is a crucial theoretical foundation for the current paper\u2019s approach."}, {"fullname_first_author": "Li Zhang", "paper_title": "Near-optimal time and sample complexities for solving Markov decision processes with a generative model", "publication_date": "2023", "reason": "This paper raises the central open question of the paper, which is whether the lower bound for sample complexity of distributional reinforcement learning with a generative model can be achieved."}, {"fullname_first_author": "Will Dabney", "paper_title": "A distributional code for value in dopamine-based reinforcement learning", "publication_date": "2020", "reason": "This paper demonstrates the practical utility of distributional reinforcement learning in a real-world application, which helps to establish the importance of the research area."}]}