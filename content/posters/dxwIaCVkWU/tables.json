[{"figure_path": "dxwIaCVkWU/tables/tables_3_1.jpg", "caption": "Table 1: Comparison of divide-and-conquer predictive coding (DCPC) against other predictive coding algorithms. DCPC provides the greatest flexibility: arbitrary differentiable generative models, an empirical approximation to the posterior, and sampling according to the target's conditional structure.", "description": "The table compares four different predictive coding algorithms: PC, LPC, MCPC, and DCPC.  It highlights their differences in terms of the type of generative density they support (Gaussian vs. differentiable), the method used for approximating the posterior distribution (Laplace, Gaussian, or empirical), and whether they respect the conditional structure of the posterior. The table demonstrates that DCPC offers the most flexibility by supporting differentiable generative models, utilizing an empirical posterior approximation, and adhering to the posterior's conditional structure.", "section": "3 Divide-and-Conquer Predictive Coding"}, {"figure_path": "dxwIaCVkWU/tables/tables_6_1.jpg", "caption": "Table 2: Negative log-likelihood and mean squared error for MCPC against DCPC on held-out images from the MNISTS. Means and standard deviations are taken across five random seeds.", "description": "This table compares the performance of Monte Carlo Predictive Coding (MCPC) and Divide-and-Conquer Predictive Coding (DCPC) on three different MNIST-like datasets (MNIST, EMNIST, and Fashion MNIST).  The comparison uses two metrics: Negative Log-Likelihood (NLL) and Mean Squared Error (MSE). Lower values indicate better performance.  Results show that DCPC generally achieves lower NLL and MSE across all datasets, suggesting that it provides more accurate inference than MCPC.", "section": "5 Experiments"}, {"figure_path": "dxwIaCVkWU/tables/tables_7_1.jpg", "caption": "Table 3: FID score comparisons on the CelebA dataset [Liu et al., 2015]. The score for LPC comes from Figure 2 in Zahid et al. [2024], where they ablated warm-starts and initialized from the prior.", "description": "This table compares the Fr\u00e9chet Inception Distance (FID) scores achieved by different algorithms on the CelebA dataset.  The algorithms compared are PGD, DCPC (the authors' algorithm), LPC, and VAE.  The table shows the likelihood used, resolution, number of sweeps and epochs used for training, and the resulting FID score. Lower FID scores indicate better performance. Note that the LPC FID score is approximate, taken from another paper.", "section": "5 Experiments"}, {"figure_path": "dxwIaCVkWU/tables/tables_15_1.jpg", "caption": "Table 1: Comparison of divide-and-conquer predictive coding (DCPC) against other predictive coding algorithms. DCPC provides the greatest flexibility: arbitrary differentiable generative models, an empirical approximation to the posterior, and sampling according to the target's conditional structure.", "description": "The table compares four predictive coding algorithms: PC, LPC, MCPC, and the proposed DCPC.  It highlights key differences in the type of generative density they support (Gaussian vs. differentiable), the method of posterior approximation (Laplace, Gaussian, Empirical), and whether they respect the conditional structure of the generative model. DCPC stands out by supporting arbitrary differentiable models, using an empirical posterior approximation, and correctly modeling conditional dependencies, offering greater flexibility than the alternatives.", "section": "Experiments"}]