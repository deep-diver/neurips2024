[{"figure_path": "PaqJ71zf1M/tables/tables_3_1.jpg", "caption": "Table 1: A unified view of popular long-tail learning methods from our framework. \u201c-\u201d means that this method does not involve this issue and \"x\" indicates that the method has not resolved the issue.", "description": "This table categorizes several popular long-tail learning methods based on three key aspects: the approach used for density estimation (linear layer, Gaussian kernel, etc.), how they address label distribution shift (reweighting, logit adjustment, etc.), and their mini-batch computation strategy for a specific equation in the paper. The table shows how these methods relate to the proposed framework in the paper.", "section": "A Probabilistic Framework for Long-Tail Learning"}, {"figure_path": "PaqJ71zf1M/tables/tables_6_1.jpg", "caption": "Table 2: Test accuracy in consistent setting on CIFAR10-LT and CIFAR100-LT datasets. The best results are in bold.", "description": "This table presents the test accuracy results for different semi-supervised long-tailed recognition methods on CIFAR10-LT and CIFAR100-LT datasets.  The experiments were conducted under consistent settings, meaning that the imbalance ratio of labeled and unlabeled data is the same.  The table shows the performance of several baselines (FixMatch, FixMatch with various improvements) and the proposed CCL method under various hyperparameter settings. The best-performing method for each configuration is highlighted in bold.", "section": "4.1 Results on CIFAR10/100-LT and STL10-LT"}, {"figure_path": "PaqJ71zf1M/tables/tables_6_2.jpg", "caption": "Table 3: Test accuracy under inconsistent setting (\u03b3\u03b9 \u2260 \u03b3u) on CIFAR10-LT and STL10-LT datasets. \u03b3\u03b9 = 100 for CIFAR10-LT, and 10 and 20 for STL10-LT dataset. The best results are in bold.", "description": "This table presents the test accuracy results of several algorithms on CIFAR10-LT and STL10-LT datasets under inconsistent settings, where the imbalance ratio of labeled data (\u03b3\u03b9) is different from that of unlabeled data (\u03b3u).  The results show the performance under different \u03b3\u03b9 and \u03b3u values, with the best results highlighted in bold.", "section": "4.1 Results on CIFAR10/100-LT and STL10-LT"}, {"figure_path": "PaqJ71zf1M/tables/tables_7_1.jpg", "caption": "Table 3: Test accuracy under inconsistent setting (\u03b3\u03b9 \u2260 Yu) on CIFAR10-LT and STL10-LT datasets. \u03b3\u03b9 = 100 for CIFAR10-LT, and 10 and 20 for STL10-LT dataset. The best results are in bold.", "description": "This table shows the test accuracy results of different algorithms under various inconsistent settings (where the imbalance ratio of labeled data is not equal to that of unlabeled data).  It presents results for two datasets (CIFAR10-LT and STL10-LT) with different labeled data imbalance ratios (\u03b3\u03b9) and various unlabeled data imbalance ratios (Yu), highlighting the robustness of the algorithms in handling real-world scenarios with data distribution shifts. The best-performing algorithm for each setting is indicated in bold.", "section": "4.1 Results on CIFAR10/100-LT and STL10-LT"}, {"figure_path": "PaqJ71zf1M/tables/tables_7_2.jpg", "caption": "Table 5: Test accuracy on ImageNet-127. The best results are in bold.", "description": "This table presents the test accuracy results on the ImageNet-127 dataset for various long-tailed semi-supervised learning methods. The results are categorized by image size (32x32 and 64x64 pixels) and the method used.  The best-performing method for each category is highlighted in bold, showcasing the relative performance of different approaches in long-tailed recognition tasks.", "section": "4.2 Results on ImageNet-127"}, {"figure_path": "PaqJ71zf1M/tables/tables_16_1.jpg", "caption": "Table 1: A unified view of popular long-tail learning methods from our framework. \u201c-\u201d means that this method does not involve this issue and \"x\" indicates that the method has not resolved the issue.", "description": "This table provides a comparison of several popular long-tail learning methods.  It shows how these methods can be viewed through the lens of the proposed probabilistic framework, highlighting their approaches to density estimation (how they approximate the distribution of data), how they handle label distribution shift (differences between the training and test data distributions), and the mini-batch computation method used.  The framework helps to unify seemingly different approaches by showing their commonalities.", "section": "2 A Probabilistic Framework for Long-Tail Learning"}, {"figure_path": "PaqJ71zf1M/tables/tables_19_1.jpg", "caption": "Table 1: A unified view of popular long-tail learning methods from our framework. \u201c-\u201d means that this method does not involve this issue and \"x\" indicates that the method has not resolved the issue.", "description": "This table provides a comparison of various long-tail learning methods, categorized by their approach to density estimation, handling of label distribution shifts, and mini-batch computation.  It highlights how these methods relate to the proposed probabilistic framework introduced in the paper.", "section": "2 A Probabilistic Framework for Long-Tail Learning"}, {"figure_path": "PaqJ71zf1M/tables/tables_19_2.jpg", "caption": "Table 9: Average batch time of each algorithm.", "description": "This table shows the average time taken to process one batch of data for different algorithms (ACR and CCL) across three different datasets (CIFAR-10, CIFAR-100, and STL-10).  The results show the computational efficiency of each algorithm for a given batch size.", "section": "4.1 Results on CIFAR10/100-LT and STL10-LT"}]