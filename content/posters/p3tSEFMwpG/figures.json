[{"figure_path": "p3tSEFMwpG/figures/figures_1_1.jpg", "caption": "Figure 2: Illustrative transformation of an SCM to one exemplary functional representation. Shaded nodes indicate that their activations cannot be sampled. Feature nodes are blue, the target node is green, input/noise nodes are purple, and all others are gray. The figure also shows the mapping of shifted edges between a causal relationship and its functional form in red, ensuring that shifts specifically target the intended causal relationships without affecting others.", "description": "This figure illustrates the transformation from a structural causal model (SCM) graph representation to its equivalent functional representation.  It highlights how the SCM's nodes (mechanisms) and edges (relationships) translate into a functional graph where each node represents a scalar value and edges represent linear connections.  The figure also showcases how edge shifts, represented in red, are specifically applied to target causal relationships within the functional graph.", "section": "3.1 Structural Causal Model Prior"}, {"figure_path": "p3tSEFMwpG/figures/figures_1_2.jpg", "caption": "Figure 3: Diagram illustrating the integration of a 2nd-order SCM for adaptive edge shifting across evolving temporal domains. On the right, the primary network G generates data samples over multiple time domains, with red arrows indicating shifted edges. On the left, the 2nd-order SCM - an auxiliary network \u0124 - takes an input domain ck \u2208 C and outputs parameters to adaptively shift each edge weight wi in the base network.", "description": "This figure illustrates how the authors' method incorporates a second-order structural causal model (SCM) to dynamically adjust edge weights in a primary SCM, thereby simulating temporal distribution shifts in data. The 2nd-order SCM takes a temporal domain indicator as input and outputs weight adjustments for edges in the primary SCM.  This allows the model to adapt to changes in the underlying causal relationships over time.", "section": "3 Methodology"}, {"figure_path": "p3tSEFMwpG/figures/figures_1_3.jpg", "caption": "Figure 1: High-level overview of our method. We train a transformer that accepts entire datasets as input to learn the learning algorithm itself by training on millions of synthetic datasets once as part of algorithm development. The trained model can be applied to arbitrary real-world datasets. In (b), X, c, and y refer to features, time domain, and label respectively. In (c), we show predictions on test domains 4 (left) and 5 (right), where we see a distribution shift. Drift-Resilient TabPFN accurately updates decision boundaries in this example.", "description": "This figure provides a high-level overview of the proposed Drift-Resilient TabPFN method.  It shows how a transformer model is trained on synthetic datasets to learn a prediction algorithm that is robust to distribution shifts.  The model accepts the entire dataset as input and makes predictions in a single forward pass.  The figure illustrates the method's ability to adapt to temporal distribution shifts by accurately updating decision boundaries.", "section": "1 Introduction"}, {"figure_path": "p3tSEFMwpG/figures/figures_5_1.jpg", "caption": "Figure 2: Illustrative transformation of an SCM to one exemplary functional representation. Shaded nodes indicate that their activations cannot be sampled. Feature nodes are blue, the target node is green, input/noise nodes are purple, and all others are gray. The figure also shows the mapping of shifted edges between a causal relationship and its functional form in red, ensuring that shifts specifically target the intended causal relationships without affecting others.", "description": "This figure illustrates the transformation from a structural causal model (SCM) graph to its functional representation.  It shows how the SCM, representing causal relationships between variables, is converted into a directed acyclic graph where nodes represent functions and edges represent data flow. The shaded nodes highlight variables whose activations are not directly sampled, while the color-coding distinguishes between feature nodes (blue), the target node (green), input/noise nodes (purple), and other nodes (grey).  Importantly, it demonstrates how edge shifts (in red) in the SCM translate into corresponding adjustments in the functional representation, ensuring that only the intended relationships are modified.", "section": "3.1 Structural Causal Model Prior"}, {"figure_path": "p3tSEFMwpG/figures/figures_6_1.jpg", "caption": "Figure 3: Diagram illustrating the integration of a 2<sup>nd</sup>-order SCM for adaptive edge shifting across evolving temporal domains. On the right, the primary network G generates data samples over multiple time domains, with red arrows indicating shifted edges. On the left, the 2<sup>nd</sup>-order SCM - an auxiliary network \u0124 - takes an input domain ck \u2208 C and outputs parameters to adaptively shift each edge weight wi in the base network.", "description": "This figure shows how the model uses a second-order SCM to model temporal distribution shifts. The second-order SCM takes in the temporal domain index and outputs parameters that modify the weights of the edges in the primary SCM. This allows the model to adapt to changes in the data distribution over time. The figure visually illustrates this process by showing how a primary SCM (on the right) generates data samples for different time domains, with the edges of the SCM being shifted according to the outputs of the second-order SCM (on the left).", "section": "3 Methodology"}, {"figure_path": "p3tSEFMwpG/figures/figures_6_2.jpg", "caption": "Figure 4: Types of distribution shifts based on the definitions by Moreno-Torres et al. [51] represented as Bayesian networks as defined by Kull and Flach [52]. Here X, Y, and C denote the random variables of the features, label, and context, respectively. Note that all these types of shifts naturally arise in our prior, since we sample feature and target positions, as well as the locations of shifted edges, randomly at various positions in the synthetic datasets.", "description": "This figure illustrates five different types of distribution shifts (covariate shift, prior probability shift, concept shift (X->Y), concept shift (Y->X), and other types of shifts) using Bayesian networks.  Each network visually represents the relationships between features (X), labels (Y), and the context or domain (C). The figure highlights that these various shift types are inherently modeled within the prior used by the proposed Drift-Resilient TabPFN model due to the random sampling of feature and target positions, as well as edge locations within the structural causal model.", "section": "3.2 Inducing Temporal Robustness in SCMs"}, {"figure_path": "p3tSEFMwpG/figures/figures_9_1.jpg", "caption": "Figure 5: This figure displays the predictive behavior of TabPFNdist in the top row and TabPFNbase in the bottom row on the Intersecting Blobs dataset. It illustrates how each model adapts to unseen test domains when trained on domains Ctrain = {0,1,2,3}. The baseline is given the domain indices as a feature in train and test. The coloring indicates the probability of the most likely class at each point. Incorrectly classified samples are highlighted in red.", "description": "This figure compares the performance of Drift-Resilient TabPFN and the standard TabPFN on the Intersecting Blobs dataset.  It shows the decision boundaries learned by each model when trained on domains 0-3 and tested on domains 4-6.  The color intensity represents the prediction confidence, and misclassified points are highlighted in red.  The figure illustrates how Drift-Resilient TabPFN dynamically adjusts its decision boundaries to adapt to distribution shifts in unseen data, while TabPFN maintains a relatively static boundary.", "section": "Qualitative Analysis"}, {"figure_path": "p3tSEFMwpG/figures/figures_19_1.jpg", "caption": "Figure 6: This figure shows the temporal shifts of two synthetic datasets across selected domains.", "description": "This figure visualizes the temporal shifts in two synthetic datasets, Intersecting Blobs and Rotated Two Moons, across specific domains.  It provides a visual representation of how the data distributions change over time, illustrating the challenges of temporal distribution shifts in machine learning.  Each sub-plot shows the data points for one specific domain, illustrating how the location and shape of the data clusters vary across different time periods.", "section": "A.4.3 Qualitative Analysis"}, {"figure_path": "p3tSEFMwpG/figures/figures_19_2.jpg", "caption": "Figure 5: This figure displays the predictive behavior of TabPFNdist in the top row and TabPFNbase in the bottom row on the Intersecting Blobs dataset. It illustrates how each model adapts to unseen test domains when trained on domains Ctrain = {0,1,2,3}. The baseline is given the domain indices as a feature in train and test. The coloring indicates the probability of the most likely class at each point. Incorrectly classified samples are highlighted in red.", "description": "This figure compares the predictive behavior of Drift-Resilient TabPFN and the standard TabPFN model on the Intersecting Blobs dataset.  It shows how each model's decision boundary changes when presented with unseen test data (domains 4, 5, and 6), after being trained on domains 0, 1, 2, and 3. The color intensity represents the prediction confidence, with red indicating misclassified samples.", "section": "Qualitative Analysis"}, {"figure_path": "p3tSEFMwpG/figures/figures_20_1.jpg", "caption": "Figure 5: This figure displays the predictive behavior of TabPFNdist in the top row and TabPFNbase in the bottom row on the Intersecting Blobs dataset. It illustrates how each model adapts to unseen test domains when trained on domains Ctrain = {0,1,2,3}. The baseline is given the domain indices as a feature in train and test. The coloring indicates the probability of the most likely class at each point. Incorrectly classified samples are highlighted in red.", "description": "This figure compares the performance of Drift-Resilient TabPFN (TabPFNdist) and the standard TabPFN (TabPFNbase) on the Intersecting Blobs dataset.  It shows how well each model adapts to unseen test data (domains 4, 5, and 6) after being trained on domains 0, 1, 2, and 3. The color intensity represents the model's prediction confidence for each class at each point, and misclassified points are highlighted in red.  The comparison highlights how Drift-Resilient TabPFN adjusts its decision boundaries more effectively to handle unseen distributions shifts than the standard TabPFN.", "section": "Qualitative Analysis"}, {"figure_path": "p3tSEFMwpG/figures/figures_20_2.jpg", "caption": "Figure 5: This figure displays the predictive behavior of TabPFNdist in the top row and TabPFNbase in the bottom row on the Intersecting Blobs dataset. It illustrates how each model adapts to unseen test domains when trained on domains Ctrain = {0,1,2,3}. The baseline is given the domain indices as a feature in train and test. The coloring indicates the probability of the most likely class at each point. Incorrectly classified samples are highlighted in red.", "description": "This figure compares the performance of Drift-Resilient TabPFN (TabPFNdist) and the standard TabPFN (TabPFNbase) on the Intersecting Blobs dataset.  It shows how well each model extrapolates its predictions to unseen test data (domains 4, 5, and 6) after training only on domains 0, 1, 2, and 3. The color-coding represents the predicted probability of each class, highlighting misclassifications in red.  The visualization demonstrates Drift-Resilient TabPFN's superior ability to adapt its decision boundary to new, unseen data distributions.", "section": "Qualitative Analysis"}, {"figure_path": "p3tSEFMwpG/figures/figures_20_3.jpg", "caption": "Figure 9: Comparison of our method against DRAIN [12] and GI [13] on the Rotated Two Moons dataset. The models were trained on domains C = {0,1,..., 8} and tested on domain 9. While the authors of DRAIN present different, unknown levels of the decision boundary, we present the decision boundary with 50% probability. The plots for DRAIN and GI were taken from Bai et al. [12].", "description": "This figure compares the decision boundaries of the proposed method, DRAIN, and GI on the Rotated Two Moons dataset.  The models were trained on domains 0-8 and tested on domain 9. The 50% probability contour is shown for the proposed method, while the contours for DRAIN and GI were taken from the original paper. The visualization highlights the differences in how each method adapts its decision boundary to unseen data, showcasing the superior extrapolation capabilities of the proposed approach.", "section": "A.4.3 Qualitative Analysis"}, {"figure_path": "p3tSEFMwpG/figures/figures_22_1.jpg", "caption": "Figure 1: High-level overview of our method. We train a transformer that accepts entire datasets as input to learn the learning algorithm itself by training on millions of synthetic datasets once as part of algorithm development. The trained model can be applied to arbitrary real-world datasets. In (b), X, c, and y refer to features, time domain, and label respectively. In (c), we show predictions on test domains 4 (left) and 5 (right), where we see a distribution shift. Drift-Resilient TabPFN accurately updates decision boundaries in this example.", "description": "This figure provides a high-level overview of the proposed Drift-Resilient TabPFN method. It illustrates the three main steps: 1) Generating synthetic datasets with time-dependent structural causal models; 2) Training a transformer model on these synthetic datasets to learn the learning algorithm itself; 3) Applying the trained model to real-world datasets, automatically detecting and adapting to distribution shifts. The figure also shows an example of the model's ability to update decision boundaries in the presence of a distribution shift.", "section": "1 Introduction"}, {"figure_path": "p3tSEFMwpG/figures/figures_25_1.jpg", "caption": "Figure 11: This figure illustrates a comparative analysis of the resilience of the listed methods to out-of-distribution (OOD) difficulty across multiple datasets and splits. The x-axis captures the difficulty of each dataset split, while the y-axis measures the performance drop of a method compared to in-distribution (ID) performance. Individual methods are represented by scatter points and their corresponding linear regression lines, with shaded regions indicating the 95% confidence intervals for TabPFN methods. Directional arrows signify increasing or decreasing dataset difficulty. Flatter regression slopes indicate models that are more resilient to increases in dataset difficulty due to distribution shifts.", "description": "This figure shows a comparative analysis of how different models' performance changes in relation to the difficulty of the dataset regarding out-of-distribution (OOD) shifts. The x-axis shows dataset difficulty, measured as the difference in performance between in-distribution and out-of-distribution. The y-axis shows how much each model's performance drops from ID to OOD.  The plot shows that Drift-Resilient TabPFN is the most resilient to increasing dataset difficulty, maintaining performance better than baselines.", "section": "A.4.6 Analyzing the Relationship Between Out-of-Distribution Performance and Difficulty Across Datasets"}, {"figure_path": "p3tSEFMwpG/figures/figures_26_1.jpg", "caption": "Figure 12: This figure shows the performance of Drift-Resilient TabPFN and the baseline TabPFN on the Intersecting Blobs dataset. Thereby, we always test on domain Ctest = {9} and gradually increase on the x-axis the number of training domains starting with Ctrain = {0, 1} up to Ctrain = {0,1,...,8}. The results show that Drift-Resilient TabPFN achieves effective extrapolation with as few as four training domains, while TabPFN-base needs significantly more to reach similar performance.", "description": "This figure compares the performance of Drift-Resilient TabPFN and the standard TabPFN on the Intersecting Blobs dataset when varying the number of training domains (from 2 to 9). The evaluation metric (Accuracy, F1 Score, ROC AUC, and ECE) are shown on test domain 9 in separate subfigures. The results highlight Drift-Resilient TabPFN's ability to extrapolate effectively with a smaller number of training domains compared to TabPFN.", "section": "A.4.7 Number of Shift Observations Required for Effective Extrapolation"}, {"figure_path": "p3tSEFMwpG/figures/figures_27_1.jpg", "caption": "Figure 3: Diagram illustrating the integration of a 2nd-order SCM for adaptive edge shifting across evolving temporal domains. On the right, the primary network G generates data samples over multiple time domains, with red arrows indicating shifted edges. On the left, the 2nd-order SCM - an auxiliary network \u0124 - takes an input domain ck \u2208 C and outputs parameters to adaptively shift each edge weight wi in the base network.", "description": "This figure illustrates how the model incorporates temporal information into its handling of distribution shifts by using a secondary SCM (2nd-order SCM). This secondary SCM takes a temporal domain indicator as input and outputs parameters that dynamically adjust the weights of the edges within the main SCM. These adjusted weights then affect the data generation process, enabling the model to adapt to evolving temporal distribution shifts.", "section": "3 Methodology"}, {"figure_path": "p3tSEFMwpG/figures/figures_27_2.jpg", "caption": "Figure 14: Share of temporal domains in exemplary datasets prior seen up to any instance i. The figure illustrates the range and structure of the sampled temporal domains ck \u2208 C across four representative datasets. It highlights variations in domain size and demonstrates the presence of arbitrary gaps, simulating irregularities in data sampling.", "description": "This figure shows the distribution of temporal domains across four different datasets. Each line represents a different dataset, and the y-axis shows the cumulative proportion of instances from each domain up to a given instance index (x-axis). The figure highlights the variability in domain size and the presence of gaps, reflecting the irregularities in real-world data.", "section": "A.5 Supplementary Illustrations and Methodological Overviews"}, {"figure_path": "p3tSEFMwpG/figures/figures_27_3.jpg", "caption": "Figure 15: This figure presents three exemplary functions sampled from nodes within the network of a 2nd-order SCM \n\n\nH. In the plot, the x-axis represents the input temporal domain c\u1d62 \u2208 C, while the y-axis displays the corresponding node activation.", "description": "This figure shows three example functions generated by the second-order SCM (H) used in the Drift-Resilient TabPFN model.  The x-axis represents the temporal domain (c\u1d62), and the y-axis represents the sampled function values (h\u2c7c(c\u1d62)). Each function (h\u2080(c\u1d62), h\u2081(c\u1d62), h\u2082(c\u1d62)) shows a unique curve demonstrating the variation in edge weight changes over time that the 2nd-order SCM generates.  This helps to model complex distribution shifts.", "section": "3.2 Inducing Temporal Robustness in SCMs"}, {"figure_path": "p3tSEFMwpG/figures/figures_28_1.jpg", "caption": "Figure 1: High-level overview of our method. We train a transformer that accepts entire datasets as input to learn the learning algorithm itself by training on millions of synthetic datasets once as part of algorithm development. The trained model can be applied to arbitrary real-world datasets. In (b), X, c, and y refer to features, time domain, and label respectively. In (c), we show predictions on test domains 4 (left) and 5 (right), where we see a distribution shift. Drift-Resilient TabPFN accurately updates decision boundaries in this example.", "description": "This figure provides a high-level overview of the proposed Drift-Resilient TabPFN method. It illustrates the three main stages: (a) Generating synthetic datasets with temporal distribution shifts using structural causal models, (b) Training a transformer model on these datasets to learn the prediction algorithm itself, and (c) Applying the trained model to real-world datasets to make predictions in a single forward pass, automatically handling distribution shifts. The figure also includes detailed descriptions of the inputs and outputs of the model.", "section": "1 Introduction"}]