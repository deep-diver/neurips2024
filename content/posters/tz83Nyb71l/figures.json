[{"figure_path": "tz83Nyb71l/figures/figures_0_1.jpg", "caption": "Figure 1: Comparisons with others in terms of latency-accuracy (left) and size-accuracy (right) trade-offs. We measure the end-to-end latency using the official pre-trained models.", "description": "This figure compares YOLOv10 with other state-of-the-art real-time object detection models. The left graph shows the trade-off between latency (inference speed) and accuracy (mAP).  The right graph displays the trade-off between model size (number of parameters) and accuracy.  YOLOv10 demonstrates a favorable balance across various scales, achieving both high accuracy and efficiency.", "section": "Introduction"}, {"figure_path": "tz83Nyb71l/figures/figures_3_1.jpg", "caption": "Figure 2: (a) Consistent dual assignments for NMS-free training. (b) Frequency of one-to-one assignments in Top-1/5/10 of one-to-many results for YOLOv8-S which employs \u03b1o2m=0.5 and \u03b2o2m=6 by default [21]. For consistency, \u03b1o2o=0.5; \u03b2o2o=6. For inconsistency, \u03b1o2o=0.5; \u03b2o2o=2.", "description": "This figure illustrates the dual label assignment strategy used in the YOLOv10 model for NMS-free training.  (a) shows the architecture, with a one-to-many head and a one-to-one head processing feature maps from the backbone and neck.  The consistent matching metric, shown in (a) as well,  harmonizes supervision from both heads. (b) compares the frequency of one-to-one assignments among the top predictions (top 1, top 5, top 10) of the one-to-many head, showing improved alignment (consistency) with the proposed matching metric.", "section": "3.1 Consistent Dual Assignments for NMS-free Training"}, {"figure_path": "tz83Nyb71l/figures/figures_5_1.jpg", "caption": "Figure 3: (a) The intrinsic ranks across stages and models in YOLOv8. The stage in the backbone and neck is numbered in the order of model forward process. The numerical rank r is normalized to r/Co for y-axis and its threshold is set to Amax/2, by default, where Co denotes the number of output channels and Amax is the largest singular value. It can be observed that deep stages and large models exhibit lower intrinsic rank values. (b) The compact inverted block (CIB). (c) The partial self-attention module (PSA).", "description": "This figure shows the intrinsic ranks across different stages and models of YOLOv8, illustrating that deeper stages and larger models have lower intrinsic ranks, indicating redundancy.  It also presents the architecture of the proposed compact inverted block (CIB) and partial self-attention module (PSA) designed to improve efficiency and accuracy.", "section": "3.2 Holistic Efficiency-Accuracy Driven Model Design"}, {"figure_path": "tz83Nyb71l/figures/figures_8_1.jpg", "caption": "Figure 3: (a) The intrinsic ranks across stages and models in YOLOv8. The stage in the backbone and neck is numbered in the order of model forward process. The numerical rank r is normalized to r/Co for y-axis and its threshold is set to Amax/2, by default, where Co denotes the number of output channels and Amax is the largest singular value. It can be observed that deep stages and large models exhibit lower intrinsic rank values. (b) The compact inverted block (CIB). (c) The partial self-attention module (PSA).", "description": "Figure 3 visualizes the intrinsic ranks across different stages and model sizes in YOLOv8, demonstrating that deeper stages and larger models show lower ranks, suggesting redundancy.  It also illustrates the proposed compact inverted block (CIB) and partial self-attention module (PSA) as components of the optimized YOLOv10 architecture.", "section": "3.2 Holistic Efficiency-Accuracy Driven Model Design"}, {"figure_path": "tz83Nyb71l/figures/figures_19_1.jpg", "caption": "Figure 1: Comparisons with others in terms of latency-accuracy (left) and size-accuracy (right) trade-offs. We measure the end-to-end latency using the official pre-trained models.", "description": "This figure compares the performance of YOLOv10 with other state-of-the-art real-time object detection models.  The left-hand graph shows the trade-off between detection accuracy (AP) and inference latency (in milliseconds). The right-hand graph displays the trade-off between detection accuracy (AP) and the number of model parameters (in millions).  Both graphs demonstrate that YOLOv10 achieves a strong balance between accuracy and efficiency, outperforming many competing models in both speed and size.", "section": "Introduction"}, {"figure_path": "tz83Nyb71l/figures/figures_19_2.jpg", "caption": "Figure 1: Comparisons with others in terms of latency-accuracy (left) and size-accuracy (right) trade-offs. We measure the end-to-end latency using the official pre-trained models.", "description": "This figure compares YOLOv10 with other state-of-the-art real-time object detection models.  The left graph shows a latency-accuracy trade-off, demonstrating that YOLOv10 achieves higher accuracy with lower latency compared to other models.  The right graph illustrates a size-accuracy trade-off, indicating the model's efficiency in terms of parameter count and FLOPs while maintaining competitive accuracy.", "section": "Introduction"}]