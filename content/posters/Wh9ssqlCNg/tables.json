[{"figure_path": "Wh9ssqlCNg/tables/tables_7_1.jpg", "caption": "Table 5: Non-accelerated MoCo-v3 across training budgets and datasets, and comparison to the publicly released MoCo-V3 model (last row). The effective training epochs for the official MoCo implementation is doubled, as it uses a symmetric loss.", "description": "This table presents the results of non-accelerated MoCo-v3 experiments conducted on ImageNet-100 and ImageNet-1k datasets.  It shows the Nearest Neighbor (NN), Linear Probe (LP), and Fine-tuning (FT) accuracies achieved under varying training budgets (measured in millions of forward passes). The last row provides a comparison with the publicly available MoCo-v3 model, noting that the number of training epochs is effectively doubled due to the use of a symmetric loss in the official implementation.", "section": "6.1 Experimental Setup"}, {"figure_path": "Wh9ssqlCNg/tables/tables_9_1.jpg", "caption": "Table 3: Impact of training budgets on gradient acceleration strategies. Asymmetric token dropout (Lq = 50, Lk = 197) and symmetric patch scaling (p = 30).", "description": "This table shows the effect of different training budgets on two gradient acceleration strategies: asymmetric token dropout and symmetric patch scaling.  The results (Nearest Neighbor (NN) accuracy and Linear Probe (LP) accuracy) are presented for various budgets ranging from 25M to 200M units.  The table highlights how the effectiveness of constant acceleration strategies can vary depending on the training budget, particularly concerning overfitting at higher budgets.", "section": "6.2 Constant Gradient Acceleration Strategies"}, {"figure_path": "Wh9ssqlCNg/tables/tables_9_2.jpg", "caption": "Table 4: Acceleration of three augmentation invariance pretraining algorithms on ImageNet-1K. \u201cAccel\u201d indicated the use of the optimized acceleration schedule.", "description": "This table presents the results of applying the proposed optimized acceleration schedule to three different self-supervised learning algorithms (MoCo, SimCLR, and DINO) on the ImageNet-1K dataset.  For each algorithm, it shows the Nearest Neighbor (NN) accuracy, Linear Probe (LP) accuracy, and full Fine-tuning (FT) accuracy achieved with both the accelerated and non-accelerated training approaches.  The \"Budget (M)\" column indicates the training budget in millions of forward pass units. The results demonstrate the effectiveness of the acceleration techniques, showing improvements in training speed without significant performance degradation.", "section": "6.4 Accelerating Pretraining on ImageNet-1k"}]