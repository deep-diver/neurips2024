[{"figure_path": "LjnDqVcrE9/tables/tables_8_1.jpg", "caption": "Table 1: The results on Referring Object Classification Task (test set). The prompt of the task is featured as \u201cIs the object (location) a (class A) or a (class B)?\u201d. \u201c-\u201d denotes the method does not support this type of referring. Results in gray font are provided for reference only.", "description": "This table presents the results of the Referring Object Classification task on a test set.  The task involves determining whether an object in a specified location within an image is of class A or class B.  The table compares various methods, both training-based and training-free, assessing their performance across different types of referring inputs (box, mask, scribble, point).  The numbers represent the accuracy of each method, highlighting the superior performance of the proposed training-free method, especially when compared to existing training-based methods.", "section": "5.3 Comparisons"}, {"figure_path": "LjnDqVcrE9/tables/tables_8_2.jpg", "caption": "Table 2: The results on Referring Text Classification Task. The prompt of task is featured as \u201cIs the text (location) of the image \u2018(text A)' or '(text B)'?please select only one.\".", "description": "This table presents the results of the Referring Text Classification task.  The task evaluates the model's ability to correctly identify whether the text within a specified region of an image matches text A or text B. The results are broken down by the method used, distinguishing between training methods and training-free methods.  The table helps to illustrate the effectiveness of the proposed training-free method in handling this task compared to various training-based methods.", "section": "5.3 Comparisons"}, {"figure_path": "LjnDqVcrE9/tables/tables_9_1.jpg", "caption": "Table 3: The results on box Referring Description Task on RefCOCOg [29]. The prompt of task is featured as \"Can you provide a description of the region (location) in a sentence?\"", "description": "This table presents the results of the box Referring Description Task using the RefCOCOg dataset.  The task is to generate a sentence describing a specific region of an image.  The table compares the performance of the baseline LLaVA model, the LLaVA model with color added as visual prompt, and the LLaVA model with the proposed ControlMLLM method. The results are evaluated using four metrics: B@4, M, C, and S.  Higher scores indicate better performance.", "section": "5.3 Comparisons"}, {"figure_path": "LjnDqVcrE9/tables/tables_9_2.jpg", "caption": "Table 4: The results of combining with different MLLMs on ROC and RTC tasks (box, test set).", "description": "This table presents the results of applying the proposed training-free method to different Multimodal Large Language Models (MLLMs) for two distinct tasks: Referring Object Classification (ROC) and Referring Text Classification (RTC).  It showcases the performance improvements achieved by the method on both tasks across various MLLMs using box-type visual prompts during testing.  The table facilitates a comparison of the baseline MLLM performance with the performance enhancements obtained by incorporating the authors' training-free method.", "section": "5.3 Comparisons"}, {"figure_path": "LjnDqVcrE9/tables/tables_16_1.jpg", "caption": "Table 1: The results on Referring Object Classification Task (test set). The prompt of the task is featured as \"Is the object (location) a (class A) or a (class B)?\". \"-\" denotes the method does not support this type of referring. Results in gray font are provided for reference only.", "description": "This table presents the results of the Referring Object Classification task, comparing various methods' performance.  The task involves determining whether an object at a specified location is of class A or class B. The table includes both training-based and training-free methods, highlighting the performance of the proposed method ('LLaVA + Ours') against state-of-the-art baselines. Results are presented for different types of referring expressions (box, mask, scribble, point). Grayed-out results indicate that a particular method does not support that referring type.", "section": "5.3 Comparisons"}, {"figure_path": "LjnDqVcrE9/tables/tables_16_2.jpg", "caption": "Table 6: The ablation of ES (\u03b1 = 400, \u03b2 = 0.5, validation set).", "description": "This table presents the results of an ablation study on the impact of the early stopping (ES) technique on the model's performance. The study varied the number of iterations (T) during the optimization process (0, 4, and 5), while keeping the hyperparameters alpha (\u03b1) and beta (\u03b2) constant. The table shows the accuracy (Acc.) and relevancy (Rel.) scores achieved in the validation set for each value of T.  The relevancy score indicates the extent to which model output is influenced by visual content within the referring region.  The results demonstrate how early stopping influences model performance, illustrating a tradeoff between accuracy and potential overfitting.", "section": "5.4 Ablation Study"}, {"figure_path": "LjnDqVcrE9/tables/tables_16_3.jpg", "caption": "Table 4: The results of combining with different MLLMs on ROC and RTC tasks (box, test set).", "description": "This table presents the results of the proposed method when combined with different Multimodal Large Language Models (MLLMs) on two tasks: Referring Object Classification (ROC) and Referring Text Classification (RTC).  The results are for the \"box\" type of referring prompt, using test set data. It shows the performance improvement on ROC and RTC tasks achieved by the proposed training-free method compared to the baseline MLLMs (Vanilla).  The higher the score indicates better performance.", "section": "5.3 Comparisons"}, {"figure_path": "LjnDqVcrE9/tables/tables_17_1.jpg", "caption": "Table 8: The inference cost with different actual output token numbers on a single GTX3090 GPU. LLaVA + Ours with T = 5 without using Early Stop here.", "description": "This table presents the inference time and maximum GPU memory usage for different model configurations. It compares the baseline LLaVA model with the proposed ControlMLLM method. The comparison is made for both a small number of output tokens (6 and 7) and a larger number of output tokens (436 and 439).  The results show the increase in computation time and memory usage when using the proposed method, particularly with more tokens, demonstrating the trade-off between improved performance and computational cost. The absence of early stopping is noted, suggesting that the inference time could be further optimized with this strategy.", "section": "5.1 Experiment Details"}, {"figure_path": "LjnDqVcrE9/tables/tables_19_1.jpg", "caption": "Table 1: The results on Referring Object Classification Task (test set). The prompt of the task is featured as \u201cIs the object (location) a (class A) or a (class B)?\u201d. \u201c-\u201d denotes the method does not support this type of referring. Results in gray font are provided for reference only.", "description": "This table presents the results of the Referring Object Classification task on a test set.  The task is a binary classification problem: given an image and a region of interest (specified by a box, mask, scribble, or point), determine whether the object in that region belongs to class A or class B. The table compares various methods\u2014both training-based and training-free\u2014evaluating their performance across different referring types.  Training-free methods are particularly notable because they do not require additional training data for the referring task.  The results are shown for different types of visual prompts, including boxes, masks, scribbles, and points, indicating which methods support each type. The table helps to assess how well different models and visual prompts perform on this fine-grained referential reasoning task.", "section": "5.3 Comparisons"}, {"figure_path": "LjnDqVcrE9/tables/tables_19_2.jpg", "caption": "Table 1: The results on Referring Object Classification Task (test set). The prompt of the task is featured as \u201cIs the object (location) a (class A) or a (class B)?\u201d. \u201c-\u201d denotes the method does not support this type of referring. Results in gray font are provided for reference only.", "description": "This table presents the performance comparison of different methods on the Referring Object Classification task. The task is a binary classification problem where the model is asked to determine if an object at a specific location belongs to class A or class B.  The table compares training-based methods and training-free methods, using different referring methods (box, mask, scribble, and point). The results indicate the accuracy of each method and show which methods do not support specific referring types. Results from a baseline model are provided for reference.", "section": "5.3 Comparisons"}]