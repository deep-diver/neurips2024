[{"type": "text", "text": "Mitigating the Impact of Labeling Errors on Training via Rockafellian Relaxation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffliiation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Labeling errors in datasets are common, if not systematic, in practice. They nat  \n2 urally arise in a variety of contexts\u2014human labeling, noisy labeling, and weak   \n3 labeling (i.e., image classification), for example. This presents a persistent and   \n4 pervasive stress on machine learning practice. In particular, neural network (NN)   \n5 architectures can withstand minor amounts of dataset imperfection with traditional   \n6 countermeasures such as regularization, data augmentation, and batch normaliza  \n7 tion. However, major dataset imperfections often prove insurmountable. We pro  \n8 pose and study the implementation of Rockafellian Relaxation (RR), a new loss   \n9 reweighting, architecture-independent methodology, for neural network training.   \n10 Experiments indicate RR can enhance standard neural network methods to achieve   \n11 robust performance across classification tasks in computer vision and natural lan  \n12 guage processing (sentiment analysis). We find that RR can mitigate the effects   \n13 of dataset corruption due to both (heavy) labeling error and/or adversarial pertur  \n14 bation, demonstrating effectiveness across a variety of data domains and machine   \n15 learning tasks. ", "page_idx": 0}, {"type": "text", "text": "16 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "17 Labeling errors are systematic in practice, stemming from various sources. For example, the re  \n18 liability of human-generated labels can be negatively impacted by incomplete information, or the   \n19 subjectivity of the labeling task - as is commonly seen in medical contexts, in which experts can   \n20 often disagree on matters such as the location of electrocardiogram signal boundaries [8], prostate   \n21 tumor region delineation, and tumor grading [20]. As well, labeling systems, such as Mechanical   \n22 Turk1 often find expert labelers being replaced with unreliable non-experts [27]. For all these rea  \n23 sons, it would be advisable for any practitioner to operate under the assumption that their dataset is   \n24 corrupted with labeling errors, and possibly to a large degree.   \n25 In this paper, we propose a loss-reweighting methodology for the task of training a classifier on data   \n26 having higher levels of labeling errors. We show that our method relates to optimistic and robust dis  \n27 tributional optimization formulations aimed at addressing adversarial training (AT). These findings   \n28 underscore our numerical experiments on NNs that suggest this method of training can provide test   \n29 performance robust to high levels of labeling error, and to some extent, feature perturbation. Over  \n30 all, we tackle the prevalent challenges of label corruption and class imbalance in training datasets,   \n31 which are critical obstacles for deploying robust machine learning models. Our proposed approach   \n32 implements Rockafellian Relaxations [23] to address corrupted labels and automatically manage   \n33 class imbalances without the need for clean validation sets or sophisticated hyper-parameters - com  \n34 mon constraints of current methodologies. This distinct capability represents our key contribution,   \n35 making our approach more practical for handling large industrial datasets.   \n36 We proceed to discuss related works in section 2, and our specific contributions to the literature.   \n37 In section 3 we discuss our methodology in detail and provide some theoretical justifications that   \n38 motivate the effectiveness of our methodology. The datasets and NN model architectures upon which   \n39 our experimental results are based are discussed in sections 4 and 5, respectively. We then conclude   \n40 with numerical experiments and results in section 6. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "41 2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "42 Corrupted datasets are of concern, as they potentially pose severe threats to classification perfor  \n43 mance of numerous machine-learning approaches [36], including, most notably, NNs [15, 33]. Nat  \n44 urally, there have been numerous efforts to mitigate this effect [28, 8]. These efforts can be cate  \n45 gorized into robust architectures, robust regularization, robust loss function, loss adjustment, and   \n46 sample selection [28]. Robust architecture methods focus on developing custom NN layers and   \n47 dedicated NN architectures. This differs from our approach, which is architecture agnostic and   \n48 could potentially \"wrap around\" these methods. While robust regularization methods like data aug  \n49 mentation [26], weight decay [16], dropout [29], and batch normalization [14] can help to bolster   \n50 performance, they generally do so under lower levels of dataset corruption. Our approach, on the   \n51 other hand, is capable of handling high levels of corruption, and can seamlessly incorporate methods   \n52 such as these. In label corruption settings, it has been shown that loss functions, such as robust mean   \n53 absolute error (MAE) [10] and generalized cross entropy (GCE) [35] are more robust than categor  \n54 ical cross entropy (CCE). Again, our method is not dependent on a particular loss function, and it   \n55 is possible that arbitrary loss functions, including robust MAE and GCE, can be swapped into our   \n56 methodology with ease. Our approach resembles the loss adjustment methods most closely, where   \n57 the overall loss is adjusted based on a (re)weighting scheme applied to training examples.   \n58 In loss adjustment methods, individual training example losses are typically adjusted multiple times   \n59 throughout the training process prior to NN updates. These methods can be further grouped into   \n60 loss correction, loss reweighting, label refurbishment, and meta-learning [28]. Our approach most   \n61 closely resembles the loss reweighting methods. Under this scheme each training example is as  \n62 signed a unique weight, where smaller weights are assigned to examples that have likely been cor  \n63 rupted. This reduces the influence of corrupted examples. A training example can be completely   \n64 removed if its corresponding weight becomes zero. Indeed, a number of loss reweighting methods   \n65 are similar to our approach. For example, Ren et al., [22] learn sample weights through the use of   \n66 a noise-free validation set. Chang et al. [5] assign sample weights based on prediction variances,   \n67 and Zhang et al. [34] examine the structural relationship among labels to assign sample weights.   \n68 However, we view the need for a clean dataset, or at least one with sufficient class balance, by these   \n69 methods as a shortcoming, and our method, in contrast, makes no assumption on the availability of   \n70 such a dataset.   \n71 Satoshi et al. [12] propose a two-phased approach to noise cleaning. The first phase trains a standard   \n72 neural network to determine the top- $^{\\cdot m}$ most influential training instances that influence the decision   \n73 boundary; these are subsequently removed from the training set to create a cleaner dataset. In the   \n74 second phase, the neural network is retrained using the cleansed training set. Their method demon  \n75 strates superior validation accuracy for various values of $m$ on MNIST and CIFAR-10. Although   \n76 impressive, their method does not address the fact that most industrial datasets have a reasonably   \n77 large amount of label corruption [28] which, upon complete cleansing, could also remove informa  \n78 tive examples that lie close to the decision boundary. Additionally, the value of $m$ is an additional   \n79 hyper-parameter that could require significant tuning on different datasets and sources.   \n80 Mengye et al. [22] propose dealing with label noise and class imbalance by learning exemplar   \n81 weights automatically. They propose doing so in the following steps: a) Create a pristine noise-free   \n82 validation set. b) Initially train on a large, noisy training dataset, compute the training loss on the   \n83 training set, train on the clean validation set, and compute the training loss on the validation set.   \n84 c) Finally, compute the exemplar weights that temper the training loss computed in step two with   \n85 validation loss. This approach is algorithmically the most similar to ours, with some key differences.   \n86 The major difference is that it treats noise and class imbalance similarly. Our approach deals with   \n87 noisy labels explicitly and can cope with almost any amount of class imbalance automatically, as   \n88 tested in our experiments with the open-source Hate-Speech dataset, where we experimented with   \n89 different prevalence levels of Hate-Speech text. The biggest drawback of the method proposed   \n90 by Mengye et al. is that it requires a clean validation set, which in practice is almost impossible   \n91 to obtain; if it were possible, it would not be very prohibitive to clean the entire dataset. Noise,   \n92 typically, is an artifact of the generative distribution which cannot be cherry-picked as easily in   \n93 practice. Our approach does not require a clean dataset to be operational or effective. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "94 3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "95 3.1 Mislabeling ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "96 Let $\\mathcal{X}$ denote a feature space, with $\\boldsymbol{\\wp}$ a corresponding label space. Then $\\mathcal{Z}\\,:=\\,\\mathcal{X}\\times\\mathcal{Y}$ will be   \n97 a collection of feature-label pairs, with an unknown probability distribution $D$ . Throughout the   \n98 forthcoming discussions, $\\{(\\dot{x_{i}},y_{i})\\}_{i=1}^{N}$ will denote a sample of $N$ feature-label pairs, for which   \n99 some pairs will have a mislabeling. More precisely, we begin with a collection $(x_{i},\\tilde{y}_{i})$ drawn i.i.d.   \n100 from $D$ , but there is some unknown set $\\bar{C}\\,\\subsetneq\\,\\{1,\\ldots,N\\}$ denoting (corrupted) indices for which   \n101 $y_{i}\\;=\\;\\tilde{y}_{i}$ if and only if $i\\not\\in{\\cal C}$ . For those $i\\in~C$ , $y_{i}$ is some incorrect label, selected uniformly at   \n102 random, following the Noise Completely at Random (NCAR) model [8] also known as uniform   \n103 label noise. ", "page_idx": 2}, {"type": "text", "text": "104 3.2 Rockafellian Relaxation Method (RRM) ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "105 We adopt the empirical risk minimization (ERM) [31] problem formulation: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}\\frac{1}{N}\\sum_{i=1}^{N}J(\\theta;x_{i},y_{i})+r(\\theta)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "106 as a baseline against which our method is measured. Given an NN architecture with (learned) param  \n107 eter setting $\\theta$ that takes as input any feature $x$ and outputs a prediction $\\hat{y}$ ${\\hat{\\jmath}},\\,J(\\theta;x,y)$ is the loss with   \n108 which we evaluate the prediction $\\hat{y}$ with respect to $y$ . Finally, $r(\\theta)$ denotes a regularization term.   \n109 In ERM it is common practice to assign each training observation $i$ a probability $p_{i}=1/N$ . How  \n110 ever, when given a corrupted dataset, we may desire to remove those samples that are affected; in   \n111 other words, if $C\\subseteq\\{1,...,N\\}$ is the set of corrupted training observations, then we would desire to   \n112 set the probabilities in the following alternative way: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\np=(p_{1},...,p_{N})\\;\\mathrm{with}\\;p_{i}=\\left\\{0,\\qquad\\mathrm{if}\\;i\\in C\\right.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "113 where $|C|$ is the cardinality of the unknown set $C$ . In this work, we provide a procedure - the Rock  \n114 afellian Relaxation Method (RRM) - with the intention of aligning the $p_{i}$ values closer to the desired   \n115 (but unknown) $p$ of (2) in self-guided, automated fashion. It does so by adopting the Rockafellian   \n116 Relaxation approach of [23]. More precisely, we consider the problem ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}\\Big[v(\\theta):=\\operatorname*{min}_{u\\in U}\\sum_{i=1}^{N}(\\frac{1}{N}+u_{i})\\cdot J(\\theta;x_{i},y_{i})+\\gamma\\|u\\|_{1}\\Big],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "117 where $\\begin{array}{r}{U:=\\{u\\in\\mathbb{R}^{N}:\\sum_{i=1}^{N}u_{i}=0,\\frac{1}{N}+u_{i}\\ge0\\;\\;\\forall i=1,\\dots,N\\}.}\\end{array}$ , and some $\\gamma>0$ . ", "page_idx": 2}, {"type": "text", "text": "118 We proceed to comment  on this problem that is nonconvex in general, before providing an algorithm. ", "page_idx": 2}, {"type": "text", "text": "119 3.3 Analysis and Interpretation of Rockafellian Relaxation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "120 Although problem (3) is nonconvex in general, the computation of $v(\\theta)$ for any fixed $\\theta$ amounts   \n121 to a linear program. The following result characterizes the complete set of solutions to this linear   \n122 program, and in doing so, provides an interpretation of the role that $\\gamma$ plays in the loss-reweighting   \n123 action of RRM.   \n124 Theorem 3.1. Let $\\gamma>0$ and $c=(c_{1},\\ldots,c_{N})\\in\\mathbb{R}^{N}$ , with $c_{m i n}:=\\operatorname*{min}_{i}c_{i}$ , and $c_{m a x}:=\\operatorname*{max}_{i}c_{i}$ .   \n125 Write $I_{m i n}:=\\{i:c_{i}=c_{m i n}\\}$ , $I_{b i g}:=\\{i:c_{i}=c_{m i n}+2\\gamma\\}$ , and for any $S_{1}\\subseteq I_{m i n},S_{2}\\subseteq I_{b i g},$ , ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\scriptscriptstyle{126}\\quad d e f i n e\\ t h e\\ p o l y t o p e\\ U_{S_{1},S_{2}}^{*}:=\\left\\{u^{*}\\in U:\\begin{array}{r l}&{u_{i}^{*}\\geq0\\ \\ \\forall i:c_{i}=c_{m i n}}\\\\ &{u_{i}^{*}=0\\ \\forall i:c_{i}\\in\\left(c_{m i n},c_{m i n}+2\\gamma\\right)}\\\\ &{u_{i}^{*}=-\\frac{1}{N}\\ \\forall i\\in I_{b i g}\\ \\backslash S_{2}}\\\\ &{u_{i}^{*}=-\\frac{1}{N}\\ \\forall i:c_{i}>c_{m i n}+2\\gamma}\\\\ &{u_{i}^{*}=0\\ \\ \\forall i\\in S_{1}\\cup S_{2}}\\end{array}\\right\\}.T h e n\n$$", "text_format": "latex", "page_idx": 3}, {"type": "equation", "text": "$$\nc o n v\\left(\\cup_{S_{1},S_{2}}U_{S_{1},S_{2}}^{*}\\right)=\\underset{u\\in U}{\\arg\\operatorname*{min}}\\sum_{i=1}^{N}(\\frac{1}{N}+u_{i})\\cdot c_{i}+\\gamma\\|u\\|_{1}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "127 The theorem explains that the construction of any optimal solution $\\boldsymbol{u}^{*}$ essentially reduces to cate  \n128 gorizing each of the losses among $\\{c_{i}\\,=\\,J(\\theta;x_{i},y_{i})\\}_{i=1}^{N}$ as \u201csmall\" or \u201cbig\", according to their   \n129 position in the partitioning of $[c_{m i n},\\infty)\\,=\\,[c_{m i n},c_{m i n}+2\\gamma)\\cup[c_{m i n}+2\\gamma,\\infty)$ . For losses that   \n130 occur at the break points of $c_{m i n}$ and $c_{m i n}+2\\gamma$ , this classification can be arbitrary - hence, the use   \n131 of $S_{1}$ and $S_{2}$ set configurations to capture this degree of freedom.   \n132 In particular, those points with losses $c_{i}$ exceeding $c_{m i n}+2\\gamma$ are down-weighted to zero and ef  \n133 fectively removed from the dataset. And in the event that $c_{m a x}-c_{m i n}<2\\gamma.$ , no loss reweighting   \n134 occurs. In this manner, while lasso produces sparse solutions in the model parameter space, RRM   \n135 produces sparse weight vectors by assigning zero weight to data points with high losses.   \n136 Consequently, if $\\chi\\,:=\\,\\{i\\,:\\,c_{i}\\,\\in\\,(c_{m i n}+2\\gamma,\\infty)\\}$ converges over the course of any algorithmic   \n137 scheme, e.g., Algorithm 1, to some set $C$ , then we can conclude that these data points are effectively   \n138 removed from the dataset even if the training of $\\theta$ might proceed. This convergence was observed in   \n139 the experiments of Section 6. It is hence of possible consideration to tune $\\gamma$ for consistency with an   \n140 estimate $\\alpha\\in[0,1]$ of labeling error in the dataset $\\{(x_{i},y_{i})\\}_{i=1}^{N}$ . More precisely, we may tune $\\gamma$ so   \n141 that N $\\begin{array}{r}{\\frac{|\\chi|}{N}\\approx\\alpha}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "142 3.4 RRM and Optimistic Wasserstein Distributionally Robust Optimization ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "143 In this section, we discuss RRM\u2019s relation to distributionally robust and optimistic optimization   \n144 formulations. Indeed, (3)\u2019s formulation as a min-min problem bears resemblance to optimistic for  \n145 mulations of recent works, e.g., [19]. We will see as well that the minimization in $u$ , as considered   \n146 in Theorem 3.1, relates to an approximation of a data-driven Wasserstein Distributionally Robust   \n147 Optimization (DRO) formulation [30]. ", "page_idx": 3}, {"type": "text", "text": "148 3.4.1 Loss-reweighting via Data-Driven Wasserstein Formulation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "149 For this discussion, as it relates to reweighting, we will lift the feature-label space $\\mathcal{Z}\\,=\\,\\mathcal{X}\\times\\mathcal{Y}$ .   \n150 More precisely, we let $\\mathcal{W}:=\\mathbb{R}_{+}$ denote a space of weights. Next, we say $w\\times\\mathcal{Z}$ has an unknown   \n151 probability distribution $\\mathcal{D}$ such that $\\pi_{\\mathcal{Z}}\\mathcal{D}=D$ and $\\Pi_{\\mathcal{W}}\\mathcal{D}(\\{1\\})=1$ . In words, all possible (w.r.t.   \n152 $D$ ) feature-label pairs have a weight of 1. Finally, we define an auxiliary loss $\\ell:\\mathcal{W}\\times\\mathcal{Z}\\times\\Theta$ by   \n153 $\\ell(w,z;\\theta):=w\\cdot\\bar{J}(x,y;\\theta)$ , for any $z=(x,y)\\in{\\mathcal{Z}}$ .   \n154 Given a sample $\\{(1,x_{i},y_{i})\\}_{i=1}^{N}$ , just as in Section 3.2, we can opt not to take as granted the result  \n155 ing empirical distribution $\\mathcal{D}_{N}$ because of the possibility that $|C|$ -many have incorrect labels (i.e.,   \n156 $y_{i}\\neq\\tilde{y}_{i}$ ). Instead, we will admit alternative distributions obtained by shifting the $\\mathcal{D}_{N}$ \u2019s probability   \n157 mass off \u201ccorrupted\" tuples $(1,x_{i},y_{i})_{i\\in C}$ to possibly $(0,x_{i},y_{i})$ , $(1,x_{i},\\tilde{y}_{i})$ , or even some other tuple   \n158 $(1,x_{j},\\tilde{y}_{j})$ with $j\\not\\in C$ for example - equivalently, eliminating, correcting, or replacing the sample,   \n159 respectively. In order to admit such favorable corrections to $\\mathcal{D}_{N}$ , we can consider the optimistic   \n160 [19, 30] data-driven problem ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}\\left(v_{N}(\\theta):=\\operatorname*{min}_{\\substack{\\tilde{\\mathcal{D}}:W_{1}(\\mathcal{D}_{N},\\tilde{\\mathcal{D}})\\le\\epsilon}}\\mathbb{E}_{\\tilde{\\mathcal{D}}}\\left[\\ell(w,z;\\theta)\\right]\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "161 in which for each parameter tuning $\\theta$ , $v_{N}(\\theta)$ measures the expected auxiliary loss with respect to   \n162 the most favorable distribution within an $\\epsilon$ - prescribed $W_{1}$ (1- Wasserstein) distance of $\\mathcal{D}_{N}$ . It turns   \n163 out that a budgeted deviation of the weights alone (and not the feature-label pairs) can approximate   \n164 (up to an error diminishing in $N$ ) $v_{N}(\\theta)$ . More precisely, we derive the following approximation   \n165 along similar lines to [30].   \n166 Proposition 3.2. Let $\\epsilon>0$ , and suppose for any $\\theta$ , $\\mathrm{max}_{(x,y)\\in\\mathcal{Z}}\\left|J(\\theta;x,y)\\right|<\\infty$ . Then there exists   \n167 $\\kappa\\geq0$ such that for any $\\theta$ , the following problem ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nv_{N}^{M I X}(\\theta):=\\operatorname*{min}_{u_{1},\\dots,u_{N}}~\\sum_{i=1}^{N}(\\frac{1}{N}+u_{i})\\cdot J(\\theta;x_{i},y_{i})+\\gamma_{\\theta}\\sum_{i=1}^{N}|u_{i}|\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "168 satisfies $\\begin{array}{r}{v_{N}(\\theta)+\\frac{\\kappa}{N}\\geq v_{N}^{M I X}(\\theta)\\geq v_{N}(\\theta)}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "169 In particular, $\\begin{array}{r}{-\\gamma_{\\theta}\\,\\le\\,\\operatorname*{min}_{i}\\,J(\\theta;x_{i},y_{i}),}\\end{array}$ and $\\{i:J(\\theta;x_{i},y_{i})>\\gamma_{\\theta}\\}$ are all down-weighted to zero,   \n170 i.e., $u_{i}^{*}=-\\frac{1}{N}$ for any $\\boldsymbol{u}^{*}$ solving $v_{N}^{\\bar{M}I X}(\\theta)$ .   \n171 In summary, while the optimistic Wasserstein formulation would permit correction to $\\mathcal{D}_{N}$ with a   \n172 combination of reweighting and/or feature-label revision, the above indicates that a process focused   \n173 on reweighting alone could accomplish a reasonable approximation; further, upon comparison to   \n174 (3), we see that RRM is a constrained version of this approximating problem, that is, ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nv(\\theta)\\geq v_{N}^{M I X}(\\theta)\\geq v_{N}(\\theta).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "175 Hence, in some sense, we can confirm that RRM is an optimistic methodology but that it is less   \n176 optimistic than the data-driven Wasserstein approach. ", "page_idx": 4}, {"type": "text", "text": "177 3.5 RRM Algorithm ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "178 Towards solving problem (3) in the two decisions $\\theta$ and $u$ , we proceed iteratively with a block  \n179 coordinate descent heuristic outlined in Algorithm 1, whereby we update the two separately in cycli  \n180 cal fashion. In other words, we update $\\theta$ while holding $u$ fixed, and we update $u$ whilst holding $\\theta$   \n181 fixed. The update of $\\theta$ is an SGD step on a batch of $s-$ many samples. The update of $u$ reduces   \n182 to a linear program. In light of the discussion in 3.4, we also outline an Adversarial Rockafellian   \n183 Relaxation method (A-RRM), an execution of RRM that includes a perturbation (parameterized by   \n184 $\\epsilon\\geq0$ ) to the feature $x$ of a sample $(x,y)$ , for the purposes of adversarial training. ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 (Adversarial) Rockafellian Relaxation Algorithm (A-RRM/RRM) ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Require: Perturbation Multiplier $\\epsilon\\in[0,1]$ , Number of epochs $\\sigma$ , Batch size $s\\geq1$ , learning rate $\\eta>0$ , regularization parameter $\\gamma>0$ , reweighting step $\\mu\\in(0,1)$ . u \u21900 \u2208RN repeat for $e=1,\\ldots,\\sigma$ do for $b=1,\\ldots,\\lceil\\frac{N}{s}\\rceil$ do $\\{(x_{i}^{b},y_{i}^{b})\\}_{i=1}^{s}\\leftarrow$ Draw Batch of size $s$ from $\\{(x_{i},y_{i})\\}_{i=1}^{N}$ for $\\mathbf{i}=1,\\,.\\,.$ , s do $x_{i}^{b}\\leftarrow^{}x_{i}^{b}+\\epsilon\\cdot s i g n\\left(\\nabla_{x}J(\\theta;(x_{i}^{b},y_{i}^{b}))\\right)$ end for $\\begin{array}{r l}&{\\theta\\leftarrow\\theta-\\eta\\sum_{i=1}^{s}\\left(\\frac{1}{N}+u_{i}\\right)\\cdot\\nabla_{\\theta}J(\\theta;(x_{i}^{b},y_{i}^{b}))}\\end{array}$ end for end for $\\begin{array}{r l}&{u^{*}\\leftarrow\\operatorname*{min}_{u\\in U}\\sum_{i=1}^{N}\\left(\\frac{1}{N}+u_{i}\\right)\\cdot J(\\theta;x_{i},y_{i})+\\gamma\\|u\\|_{1}}\\\\ &{u\\leftarrow\\mu u^{*}+(1-\\mu)u}\\end{array}$ until Desired Validation Accuracy or Loss ", "page_idx": 4}, {"type": "text", "text": "185 The stepsize parameters $\\mu,\\eta$ and the regularization parameter $\\gamma$ are hyper-parameters that may be   \n186 tuned, or guided by the general discussions above in Section 3.3.   \n187 The RRM algorithm, in which $\\epsilon=0$ , is meant for contexts in which only label corruption and no   \n188 feature corruption occurs. The A-RRM algorithm, for which $\\epsilon>0$ , is intended for contexts in which   \n189 both label and feature corruption is anticipated.   \n191 We select several datasets to evaluate RRM. In some cases, the selected dataset is nearly pristine. In   \n192 these cases we perturb the dataset to achieve various types and levels of corruption. Other datasets   \n193 consist of weakly labeled examples, which we maintain unaltered. The varied data domains and   \n194 regimes of corruption enable a robust evaluation of RRM.   \n195 MNIST [17]: A multi-class classification dataset consisting of 70000 images of digits zero through   \n196 nine. 60000 digits are set aside for training and 10000 for testing. $0\\%$ , $5\\%$ , $10\\%$ , $20\\%$ , and $30\\%$   \n197 of the training labels are swapped for different, randomly selected digits. The test set labels are   \n198 unmodified.   \n199 Toxic Comments [6]: A multi-label classification problem from JIGSAW that consists of Wikipedia   \n200 comments labeled by humans for toxic behavior. Comments can be any number (including zero) of   \n201 six categories: toxic, severe toxic, obscene, threat, insult, and identity hate. We convert this into a   \n202 binary classification problem by treating the label as either none of the six categories or at least one   \n203 of the six categories. This dataset is a public dataset used as part of the Kaggle Toxic Comment   \n204 Classification Challenge.   \n205 IMDb [18]: A binary classification dataset consisting of 50000 movie reviews each assigned a posi  \n206 tive or negative sentiment label. 25000 reviews are selected randomly for training and the remaining   \n207 are used for testing. $25\\%$ , $30\\%$ , $40\\%$ , and $45\\%$ of the labels of the training reviews are randomly   \n208 selected and swapped from positive sentiment to negative sentiment, and vice versa, to achieve four   \n209 training datasets of desired levels of label corruption. The test set labels are unmodified.   \n210 Tissue Necrosis: A binary classification dataset consisting of $7874\\,256\\mathrm{x}256$ -pixel hematoxylin and   \n211 eosin (H&E) stained RGB images derived from [2]. The training dataset consists of 3156 images   \n212 labeled non-necrotic, as well as 3156 images labeled necrotic. The training images labeled non  \n213 necrotic contain no necrosis. However, only $25\\%$ of the images labeled necrotic contain necrotic   \n214 tissue. This type of label error can be expected in cases of weakly-labeled Whole Slide Imagery   \n215 (WSI). Here, an expert pathologist will provide a slide-level label for a potentially massive slide   \n216 consisting of gigapixels, but they lack time or resources to provide granular, segmentation-level   \n217 annotations of the location of the pathology in question. Also, the diseased tissue often occupies   \n218 a small portion of the WSI, with the remainder consisting of normal tissue. When the gigapixel  \n219 sized WSI is subsequently divided into sub-images of manageable size for typical machine-learning   \n220 workflows, many of the sub-images will contain no disease, but will be assigned the \"weak\" label   \n221 chosen by the expert for the WSI. The test dataset consists of 718 necrosis and 781 non-necrosis   \n222 256x256-pixel H&E images, which were also derived from [2]. For both the training and test images,   \n223 [2] provide segmentation-level necrosis annotations, so we are able to ensure a pristine test set, and,   \n224 in the case of the training set, we were able to identify the corrupted images for the purpose of   \n225 algorithm evaluation. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "226 5 Architectures ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "227 We do not strive to develop a novel NN architectures capable of defeating current state-of-the-art   \n228 (SOA) performance in each data domain. Nor do we focus on developing robust architectures as   \n229 described in [28]. Rather, we select a reasonable NN architecture and measure model performance   \n230 with and without the application of RRM. This approach enables us to demonstrate the general   \n231 superiority of RRM under varied data domains and NN architectures. We discuss the underlying   \n232 NN architectures that we employ in this section.   \n233 MNIST: The MNIST dataset has been studied extensively and harnessed to investigate novel   \n234 machine-learning methods, including CNNs [4]. We adopt a basic CNN architecture with a few   \n235 convolutional layers. The first layer has a depth of 32, and the next two layers have a depth of 64.   \n236 Each convolutional layer employs a kernel of size three and the ReLU activation function followed   \n237 by a max-pooling layer employing a kernal of size 2. The last convolutional layer is connected to a   \n238 classification head consisting of a 100-unit dense layer with ReLU activation, followed by a 10-unit   \n239 dense layer with softmax activation. In total, there are 159254 trainable parameters. Categorical   \n240 cross-entropy is employed for the loss function.   \n241 Toxic Comments: We use a simple model with only a single convolutional layer. A pretrained   \n242 embedding from FastText is first used to map the comments into a 300 dimension embedding space,   \n243 followed by a single convolutional layer with a kernel size of two with a ReLU activation layer   \n244 followed by a max-pooling layer. We then apply a 36-unit dense layer, followed by a 6 unit dense   \n245 layer with sigmoid activation. Binary cross-entropy is used for the loss function.   \n246 IMDb: Transformer architectures have achieved SOA performance on the IMDb dataset sentiment   \n247 analysis task [7, 32]. As such, we a adopt a reasonable transformer architecture to assess RRM. We   \n248 utilize the DistilBERT [25] architecture with low-rank adaptation (LoRA) [13] for large language   \n249 models, which reduces the number of trainable weights from 67584004 to 628994. In this manner,   \n250 we reduce the computational burden, while maintaining excellent sentiment analysis performance.   \n251 Binary cross-entropy is employed for the loss function.   \n252 Tissue Necrosis: Consistent with the computational histopathology literature [21], we employ a   \n253 convolutional neural network (CNN) architecture for this classification task. In particular, a ResNet  \n254 50 architecture with pre-trained ImageNet weights is harnessed. The classification head is removed   \n255 5 and replaced with a dense layer of 512 units and ReLU activation function, followed by an output   \n256 layer with a single unit using a sigmoid activation function. All weights, with the exception of   \n257 the new classification head are frozen, resulting in 1050114 trainable parameters out of 24637826.   \n258 Binary cross-entropy is employed for the loss function. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "259 6 Experiments and Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "260 In this work, we have discussed errors/perturbations/corruption to features and labels. We now   \n261 perform experiments to see how RRM performs under one or the other, or both. The MNIST ex  \n262 periments are performed under a setting of both adversarial perturbation, as well as label corruption.   \n263 The Toxic Comments experiments are performed under settings of label corruption only. All ex  \n264 periments are performed using a combination of GPU resources, both cloud-base, as well as access   \n265 to an on-premise high-performance computing (HPC) facility. We refer the reader to the Appendix   \n266 (Sections 6.3 and 6.4) for the experiments on IMDb and Tissue Necrosis. ", "page_idx": 6}, {"type": "text", "text": "267 6.1 MNIST ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "268 Twenty percent of the training data is set aside for validation purposes. Using Tensorflow 2.10 [1],   \n269 50 iterations of RRM are executed with $\\sigma=10$ epochs per iteration for a total of 500 epochs for   \n270 a given hyperparameter setting. For RRM, the hyperparameter settings of $\\mu$ and $\\gamma$ at 0.5 and 2.0,   \n271 respectively, are based on a search to optimize validation set accuracy. For contrast, we perform a   \n272 comparable 500 epochs using ERM. Both ERM and RRM employ stochastic gradient descent (SGD)   \n273 with a learning rate $(\\eta)$ of 0.1. Each time a batch is drawn, each training image is perturbed using   \n274 the Fast Gradient Sign Method (FGSM) [11] adversarial attack: $a d v_{x}=\\bar{x}+\\epsilon\\cdot s i g n(\\nabla_{x}J(\\theta,x,y))$ ,   \n275 where $a d v_{x}$ is the resulting perturbed image, $x$ is the original image, $y$ is the image label, $\\epsilon$ is a   \n276 multiplier controlling the magnitude of the image perturbation, $\\theta$ are the model parameters, and $J$ is   \n277 the loss. An $\\epsilon=1.0$ is used for all training image perturbations.   \n278 For each of the $0\\%$ , $5\\%$ , $10\\%$ , $20\\%$ , and $30\\%$ training label corruption levels, we compare ad  \n279 versarial training (AT) and adversarial RRM (A-RRM) performance under varios regimes of test set   \n280 perturbation $(\\epsilon_{t e s t}\\in0.0,0.1,0.25,0.5,1.0)$ . In Table 1 we show the test set accuracy achieved when   \nvalidation set accuracy peaks. We can see that training with an $\\epsilon_{t r a i n}=1.0$ and testing with lower   \n282 $\\epsilon_{t e s t}$ levels of $0.00,0.10$ , and 0.25, results in a drastic degradation in accuracy for AT for corruption   \n283 levels greater than $0\\%$ . This performance collapse is not observed when using A-RRM. Given that   \n284 it may be difficult to anticipate the adversarial regime in production environments, A-RRM seems   \n285 to confer a greater benefti than AT.   \n286 We examine the $u_{i}$ -value associated with each training observation, $i$ , from iteration-to-iteration of   \n287 the heuristic algorithm. Table 2 summarizes the progression of the $u_{i}$ -vector across its 49 updates   \n288 for the dataset corruption level of $20\\%$ . Column \u201c1. iteration\u201d shows the distribution of $u_{i}$ -values   \n289 following the first u-optimization for both the 9600 corrupted training observations and the 38400   \n290 clean training observations. Initially, all $u_{i}$ -values are approximately equal to 0.0. It is once again   \n291 observed that, over the course of iterations, the $u_{i}$ -values noticeably change. In column $\\sp{\\ast}10$ . itera  \n292 tion\u201d it can be seen that a significant number of the $u_{i}$ -values of the corrupted training observations ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Table 1: Test accuracy $(\\%)$ for AT and A-RRM on MNIST under different levels of corruption $C$ and test-set adversarial perturbation $\\epsilon_{t e s t}$ . ", "page_idx": 7}, {"type": "table", "img_path": "47CdPNiWUB/tmp/f90fa0a648a8975d0145172b3100360809ba711ddcd340679780ae4f06591018.jpg", "table_caption": ["Percentage Corrupted Training Data "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "293 achieve negative values, while a large majority of the $u_{i}$ -values for the clean training observations   \n294 remain close to 0.0. Finally, column \u201c49. iteration\u201d displays the final $u_{i}$ -values. 9286 out of 9600 of   \n295 the corrupted training observations have achieved a $u_{i}\\in(-2.08,-1.56]\\cdot10-5$ . This means these   \n296 training observations are removed, or nearly-so, from consideration because this value cancels the   \n297 nominal probability $1/N\\,{=}\\,2.08\\cdot10\u20135$ . It is observed that a large majority (35246/38400) clean train  \n298 ing observations remain with their nominal probability. This helps explain the performance benefti   \n299 of A-RRM over AT. A-RRM \"removes\" the corrupted data points in-situ, whereas AT does not. It   \n300 appears that under adversarial training regimes with corrupted training data, it is essential to identify   \n301 and \"remove\" the corrupted examples, especially if the level adversarial perturbation encountered in   \n302 the test set is unknown, or possibly lower than the level of adversarial perturbation applied to the   \n303 training set. ", "page_idx": 7}, {"type": "table", "img_path": "47CdPNiWUB/tmp/f2c7e8496f7650cb89e682b017a8e4801b2088c0688cdd752dc499b642393c20.jpg", "table_caption": ["Table 2: Evolution of u-vector across 9600 corrupted data points and 38400 clean data points. Note that $1/(9600+38400)=2.08\\cdot10\u20135$ . "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "304 6.2 Toxic Comment ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "305 We use the Toxic Comment dataset to test the efficacy of RRM on low prevalence text data. The   \n306 positive (toxic) comments consist of only $3\\%$ of the data and we corrupt anywhere from $1\\%$ to $20\\%$   \n307 of the labels. There are a total of 148,000 samples, and we set aside $80\\%$ for training and $20\\%$ for   \n308 test. $\\sigma\\,=\\,2$ with 3 iterations of the heuristic algorithm results in a total of 6 epochs, and ERM is   \n309 run for a total of 6 epochs to make the results comparable. Since the data is highly imbalanced,   \n310 we look at the area under the curve of the precision/recall curve to assess the performance of the   \n311 models. Unsurprisingly, as the noise increase, the model performance decreases. We note that RRM   \n312 outperforms ERM across all noise levels tested, though as the noise increase, the gap between RRM   \n313 and ERM decreases. ", "page_idx": 7}, {"type": "text", "text": "Table 3: Comparison of training and test area under the precision/recall curve for ERM and RRM at noise levels ranging from $1\\%$ to $20\\%$ . ", "page_idx": 7}, {"type": "table", "img_path": "47CdPNiWUB/tmp/c4e5468885d2e657058bc14ff74786b62ab4d329c54e35b10cb6218e80c762b3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "315 Twenty percent of the training data is set aside for validation purposes. Using Pytorch 2.1.0 [3],   \n316 30 iterations of RRM are executed, with $\\sigma=10$ epochs per iteration for a total of 300 epochs for   \n317 a given hyperparameter setting. For RRM, the hyperparameter settings of $\\mu$ and $\\gamma$ at 0.5 and 0.4,   \n318 respectively, are based on a search to optimize validation set accuracy. For contrast, we perform   \n319 a comparable 300 epochs using ERM. Both ERM and RRM employ stochastic gradient descent   \n320 (SGD) with a learning rate $(\\eta)$ of 0.001. In Table 4 we record both the test set accuracy achieved   \n321 when validation set accuracy peaks, as well as the maximum test set accuracy. At these high levels   \n322 of corruption RRM consistently achieves a better maximum test set accuracy. ", "page_idx": 8}, {"type": "table", "img_path": "47CdPNiWUB/tmp/e5c238645c044c76ce3d27f6f49e7da1e53170e9965a0180bbd4b8ff56571585.jpg", "table_caption": ["Table 4: Test accuracy $(\\%)$ for ERM and RRM on IMDb under different levels of corruption. Test set accuracy at peak validation accuracy and maximum test set accuracy are recorded. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "323 6.4 Tissue Necrosis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "324 Twenty percent of the training data is set aside for validation purposes, including hyperparameter   \n325 selection. 60 iterations of RRM are executed, with $\\sigma=10$ epochs per iteration, for a total of 600   \n326 epochs for a given hyperparameter setting. For RRM, the hyperparameter settings of $\\mu$ and $\\gamma$ at   \n327 0.5 and 0.016, respectively, are based on a search to optimize validation set accuracy. For contrast,   \n328 we perform a comparable 600 epochs using ERM. Both ERM and RRM employ stochastic gradient   \n329 descent (SGD) with a learning rate $(\\eta)$ of 5.0 and 1.0, respectively. RRM achieves a test set accuracy   \n330 at peak validation accuracy of 74.6, and a maximum test set accuracy 77.2, whereas ERM achieves   \n331 71.7 and 73.2, respectively. RRM appears to confer a performance benefti under this regime of   \n332 weakly labeled data. ", "page_idx": 8}, {"type": "text", "text": "333 7 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "334 In this study, we demonstrate the robustness of the A-RRM algorithm in a variety of data domains,   \n335 data corruption schemes, model architectures and machine learning applications. In the MNIST   \n336 example we show that conducting training in preparation for deployment environments with varied   \n337 levels of adversarial attacks, one can benefti from implementation of the A-RRM algorithm. This   \n338 can lead to a model more robust across levels of both feature perturbation and high levels of label   \n339 corruption. We also demonstrate the mechanism by which A-RRM operates and confers superior   \n340 results: by automatically identifying and removing the corrupted training observations at training   \n341 time execution.   \n342 The Toxic Comment example presents another challenging classification problem, characterized by   \n343 a low prevalence target class amidst label noise. Our experiments demonstrate that as the amount of   \n344 label noise increases, standard methods become increasingly ineffective. However, RRM remains   \n345 reasonably robust under varying degrees of label corruption. Therefore, RRM could be a valuable   \n346 addition to the set of tools being developed to enhance the robustness of AI-based decision engines.   \n347 In the IMDb example we demonstrate that RRM can confer beneftis to the sentiment analysis classi  \n348 fication task using pre-trained large models under conditions of high label corruption. The success   \n349 of fine-tuning in LLMs depends, in large part, on access to high quality training examples. We have   \n350 shown that RRM can mitigate this need by allowing effective training in scenarios of high training   \n351 data corruption. As such, resource allocation dedicated to dataset curation may be lessened by the   \n352 usage of RRM.   \n353 In the Tissue Necrosis example, we demonstrate that RRM also confers accuracy beneftis to the   \n354 necrosis identification task provided weakly labeled WSIs. Again, RRM can mitigate the need for   \n355 expert-curated, detailed pathology annotations, which are costly and time-consuming to generate. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "356 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "357 [1] Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro,   \n358 Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfel  \n359 low, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz   \n360 Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Man\u00e9, Rajat Monga, Sherry Moore,   \n361 Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever,   \n362 Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\u00e9gas, Oriol   \n363 Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Ten  \n364 sorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available   \n365 from tensorflow.org.   \n366 [2] Mohamed Amgad, Habiba Elfandy, Hagar Hussein, Lamees A Atteya, Mai A T Elsebaie,   \n367 Lamia S Abo Elnasr, Rokia A Sakr, Hazem S E Salem, Ahmed F Ismail, Anas M Saad,   \n368 Joumana Ahmed, Maha A T Elsebaie, Mustafjiur Rahman, Inas A Ruhban, Nada M Elgazar,   \n369 Yahya Alagha, Mohamed H Osman, Ahmed M Alhusseiny, Mariam M Khalaf, Abo-Alela F   \n370 Younes, Ali Abdulkarim, Duaa M Younes, Ahmed M Gadallah, Ahmad M Elkashash, Salma Y   \n371 Fala, Basma M Zaki, Jonathan Beezley, Deepak R Chittajallu, David Manthey, David A Gut  \n372 man, and Lee A D Cooper. Structured crowdsourcing enables convolutional segmentation of   \n373 histology images. Bioinformatics, 35(18):3461\u20133467, 02 2019.   \n374 [3] Jason Ansel, Edward Yang, Horace He, Natalia Gimelshein, Animesh Jain, Michael Voznesen  \n375 sky, Bin Bao, Peter Bell, David Berard, Evgeni Burovski, Geeta Chauhan, Anjali Chourdia,   \n376 Will Constable, Alban Desmaison, Zachary DeVito, Elias Ellison, Will Feng, Jiong Gong,   \n377 Michael Gschwind, Brian Hirsh, Sherlock Huang, Kshiteej Kalambarkar, Laurent Kirsch,   \n378 Michael Lazos, Mario Lezcano, Yanbo Liang, Jason Liang, Yinghai Lu, CK Luk, Bert Maher,   \n379 Yunjie Pan, Christian Puhrsch, Matthias Reso, Mark Saroufim, Marcos Yukio Siraichi, Helen   \n380 Suk, Michael Suo, Phil Tillet, Eikan Wang, Xiaodong Wang, William Wen, Shunting Zhang,   \n381 Xu Zhao, Keren Zhou, Richard Zou, Ajit Mathews, Gregory Chanan, Peng Wu, and Soumith   \n382 Chintala. PyTorch 2: Faster machine learning through dynamic python bytecode transforma  \n383 tion and graph compilation. In 29th ACM International Conference on Architectural Support   \n384 for Programming Languages and Operating Systems, Volume 2 (ASPLOS \u201924). ACM, 4 2024.   \n385 [4] Alejandro Baldominos, Yago Saez, and Pedro Isasi. A survey of handwritten character recog  \n386 nition with mnist and emnist. Applied Sciences, 9(15), 2019.   \n387 [5] Haw-Shiuan Chang, Erik Learned-Miller, and Andrew McCallum. Active bias: Training more   \n388 accurate neural networks by emphasizing high variance samples, 2018.   \n389 [6] cjadams, Jeffrey Sorensen, Julia Elliott, Lucas Dixon, Mark McDonald, nithum, and Will   \n390 Cukierski. Toxic comment classification challenge, 2017.   \n391 [7] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of   \n392 deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805,   \n393 2018.   \n394 [8] Benoit Frenay and Michel Verleysen. Classification in the presence of label noise: A survey.   \n395 IEEE Transactions on Neural Networks and Learning Systems, 25(5):845\u2013869, 2014.   \n396 [9] Rui Gao and Anton Kleywegt. Distributionally robust stochastic optimization with wasserstein   \n397 distance. Mathematics of Operations Research, 48(2):603\u2013655, 2023.   \n398 [10] Aritra Ghosh, Himanshu Kumar, and P. S. Sastry. Robust loss functions under label noise   \n399 for deep neural networks. In Proceedings of the Thirty-First AAAI Conference on Artificial   \n400 Intelligence, AAAI\u201917, page 1919\u20131925. AAAI Press, 2017.   \n401 [11] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adver  \n402 sarial examples. In 3rd International Conference on Learning Representations, 2015.   \n403 [12] Satoshi Hara, Atsushi Nitanda, and Takanori Maehara. Data cleansing for models trained with   \n404 SGD. Curran Associates Inc., Red Hook, NY, USA, 2019.   \n405 [13] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,   \n406 Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In In  \n407 ternational Conference on Learning Representations, 2022.   \n408 [14] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training   \n409 by reducing internal covariate shift. In International conference on machine learning, pages   \n410 448\u2013456. pmlr, 2015.   \n411 [15] Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom   \n412 Duerig, James Philbin, and Li Fei-Fei. The unreasonable effectiveness of noisy data for fine  \n413 grained recognition. In Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam,   \n414 The Netherlands, October 11-14, 2016, Proceedings, Part III 14, pages 301\u2013320. Springer,   \n415 2016.   \n416 [16] Anders Krogh and John Hertz. A simple weight decay can improve generalization. Advances   \n417 in neural information processing systems, 4, 1991.   \n418 [17] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010.   \n419 [18] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christo  \n420 pher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual   \n421 Meeting of the Association for Computational Linguistics: Human Language Technologies,   \n422 pages 142\u2013150, Portland, Oregon, USA, June 2011. Association for Computational Linguis  \n423 tics.   \n424 [19] Viet Anh Nguyen, Soroosh Shafieezadeh Abadeh, Man-Chung Yue, Daniel Kuhn, and Wol  \n425 fram Wiesemann. Optimistic distributionally robust optimization for nonparametric likelihood   \n426 approximation. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and   \n427 R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran   \n428 Associates, Inc., 2019.   \n429 [20] Guy Nir, Soheil Hor, Davood Karimi, Ladan Fazli, Brian F. Skinnider, Peyman Tavassoli,   \n430 Dmitry Turbin, Carlos F. Villamil, Gang Wang, R. Storey Wilson, Kenneth A. Iczkowski,   \n431 M. Scott Lucia, Peter C. Black, Purang Abolmaesumi, S. Larry Goldenberg, and Septimiu E.   \n432 Salcudean. Automatic grading of prostate cancer in digitized histopathology images: Learning   \n433 from multiple experts. Medical Image Analysis, 50:167\u2013180, 2018.   \n434 [21] Dominika Petr\u00edkov\u00e1 and Ivan Cimr\u00e1k. Survey of recent deep neural networks with strong   \n435 annotated supervision in histopathology. Computation, 11(4), 2023.   \n436 [22] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples   \n437 for robust deep learning. In International Conference on Machine Learning, 2018.   \n438 [23] Johannes O. Royset, Louis L. Chen, and Eric Eckstrand. Rockafellian relaxation and stochastic   \n439 optimization under perturbations. Mathematics of Operations Research (to appear), 2023.   \n440 [24] Johannes O. Royset and Roger J-B Wets. An Optimization Primer. Springer, 2021.   \n441 [25] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled   \n442 version of bert: smaller, faster, cheaper and lighter. ArXiv, abs/1910.01108, 2019.   \n443 [26] Connor Shorten and Taghi M Khoshgoftaar. A survey on image data augmentation for deep   \n444 learning. Journal of big data, 6(1):1\u201348, 2019.   \n445 [27] Rion Snow, Brendan O\u2019Connor, Daniel Jurafsky, and Andrew Ng. Cheap and fast \u2013 but is it   \n446 good? evaluating non-expert annotations for natural language tasks. In Mirella Lapata and   \n447 Hwee Tou Ng, editors, Proceedings of the 2008 Conference on Empirical Methods in Natu  \n448 ral Language Processing, pages 254\u2013263, Honolulu, Hawaii, October 2008. Association for   \n449 Computational Linguistics.   \n450 [28] Hwanjun Song, Minseok Kim, Dongmin Park, and Jae-Gil Lee. Learning from noisy labels   \n451 with deep neural networks: A survey. CoRR, abs/2007.08199, 2020.   \n452 [29] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi  \n453 nov. Dropout: a simple way to prevent neural networks from overftiting. The journal of   \n454 machine learning research, 15(1):1929\u20131958, 2014.   \n455 [30] Matthew Staib and Stefanie Jegelka. Distributionally robust deep learning as a generaliza  \n456 tion of adversarial training. In NIPS workshop on Machine Learning and Computer Security,   \n457 volume 3, page 4, 2017.   \n458 [31] V. Vapnik. Principles of risk minimization for learning theory. In Proceedings of the 4th   \n459 International Conference on Neural Information Processing Systems, NIPS\u201991, page 831\u2013838,   \n460 San Francisco, CA, USA, 1991. Morgan Kaufmann Publishers Inc.   \n461 [32] Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V Le. Unsupervised data   \n462 augmentation for consistency training. arXiv preprint arXiv:1904.12848, 2019.   \n463 [33] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understand  \n464 ing deep learning requires rethinking generalization. In International Conference on Learning   \n465 Representations, 2017.   \n466 [34] HaiYang Zhang, XiMing Xing, and Liang Liu. Dualgraph: A graph-based method for rea  \n467 soning about label noise. In 2021 IEEE/CVF Conference on Computer Vision and Pattern   \n468 Recognition (CVPR), pages 9649\u20139658, 2021.   \n469 [35] Zhilu Zhang and Mert R. Sabuncu. Generalized cross entropy loss for training deep neural   \n470 networks with noisy labels. In Proceedings of the 32nd International Conference on Neural In  \n471 formation Processing Systems, NIPS\u201918, page 8792\u20138802, Red Hook, NY, USA, 2018. Curran   \n472 Associates Inc.   \n473 [36] Xingquan Zhu and Xindong Wu. Class noise vs. attribute noise: A quantitative study. Artificial   \n474 intelligence review, 22:177\u2013210, 2004. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "475 A Appendix / supplemental material ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "476 A.1 Section 3 Proofs ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "477 Theorem 3.1. Let $\\gamma>0$ and $c=(c_{1},\\ldots,c_{N})\\in\\mathbb{R}^{N}$ , with $c_{m i n}:=\\operatorname*{min}_{i}c_{i}$ , and $c_{m a x}:=\\operatorname*{max}_{i}c_{i}$ .   \n478 Write $I_{m i n}:=\\{i:c_{i}=c_{m i n}\\}$ , $I_{b i g}:=\\{i:c_{i}=c_{m i n}+2\\gamma\\}$ , and for any $S_{1}\\subseteq I_{m i n},S_{2}\\subseteq I_{b i g}$ , ", "page_idx": 11}, {"type": "text", "text": "479 define the polytope $U_{S_{1},S_{2}}^{*}:=\\left\\{u_{i}^{*}=0\\ \\forall i:c_{i}=c_{m i n}\\atop u_{i}^{*}=0\\ \\forall i:c_{i}\\in\\left(c_{m i n},c_{m i n}+2\\gamma\\right)\\right\\}$ . Then $c o n v\\left(\\cup_{S_{1},S_{2}}U_{S_{1},S_{2}}^{*}\\right)=\\underset{u\\in U}{\\arg\\operatorname*{min}}\\sum_{i=1}^{N}(\\frac{1}{N}+u_{i})\\cdot c_{i}+\\gamma\\|u\\|_{1}.$ ", "page_idx": 11}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "480 Proof. For any set $C$ , let $\\iota_{C}(x)=0$ and $\\iota_{C}(x)=\\infty$ otherwise. We recognize that $\\boldsymbol{u}^{\\star}$ is a solution   \n481 of the minimization problem if and only if it is a minimizer of the function $h$ given by ", "page_idx": 11}, {"type": "equation", "text": "$$\nh(u)=\\sum_{i=1}^{N}\\Big(c_{i}/N+u_{i}c_{i}+\\gamma|u_{i}|+\\iota_{[0,\\infty)}(1/N+u_{i})\\Big)+\\iota_{\\{0\\}}\\Big(\\sum_{i=1}^{N}u_{i}\\Big)\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "482 Thus, because $h(u)\\,>\\,-\\infty$ for all $u\\,\\in\\,\\mathbb{R}^{N}$ and $h$ is convex, $u^{\\star}$ is a solution of the minimization   \n483 problem if and only if $0\\in\\partial h(u^{\\star})$ by Theorem 2.19 in [24]. We proceed by characterizing $\\partial h$ . ", "page_idx": 11}, {"type": "text", "text": "484 Consider the univariate function $h_{i}$ given by ", "page_idx": 11}, {"type": "equation", "text": "$$\nh_{i}(u_{i})=c_{i}/N+u_{i}c_{i}+\\gamma|u_{i}|+\\iota_{[0,\\infty)}(1/N+u_{i}).\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "485 For $u_{i}\\geq-1/N$ , the Moreau-Rockafellar sum rule (see, e.g, [24, Theorem 2.26]) gives that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\partial h_{i}(u_{i})=c_{i}+\\left\\{\\begin{array}{l l}{\\{\\gamma\\}}&{\\mathrm{if~}u_{i}>0}\\\\ {[-\\gamma,\\gamma]}&{\\mathrm{if~}u_{i}=0}\\\\ {\\{-\\gamma\\}}&{\\mathrm{if~}-1/N<u_{i}<0}\\\\ {(-\\infty,-\\gamma]}&{\\mathrm{if~}u_{i}=-1/N.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "486 For $u=(u_{1},\\dots,u_{N})\\in[-1/N,\\infty)^{N}$ , we obtain by Proposition 4.63 in [24] that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\partial\\Big(\\sum_{i=1}^{N}h_{i}\\Big)(u)=\\partial h_{1}(u_{1})\\times\\cdots\\times\\partial h_{N}(u_{N}).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "487 Let $h_{0}$ be the function given by $\\begin{array}{r}{h_{0}(u)=\\iota_{\\{0\\}}(\\sum_{i=1}^{N}u_{i})}\\end{array}$ . Again invoking the Moreau-Rockafellar   \n488 sum rule while recognizing that the interior of the domain of $\\sum_{i=1}^{N}h_{i}$ intersects with the domain of   \n489 $h_{0}$ , we obtain ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\partial h(u)=\\partial\\Big(\\sum_{i=1}^{N}h_{i}\\Big)(u)+\\partial h_{0}(u)=\\partial h_{1}(u_{1})\\times\\cdots\\times\\partial h_{N}(u_{N})+\\left[\\!\\!\\begin{array}{c}{{1}}\\\\ {{1}}\\\\ {{1}}\\end{array}\\!\\!\\right]\\mathbb{R}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "490 for any $\\boldsymbol{u}=(u_{1},\\dots,u_{N})$ with $u_{i}\\,\\geq-1/N,\\,i\\,=1,\\ldots,N$ , and $\\textstyle\\sum_{i=1}^{N}u_{i}=0$ . Hence, $u^{*}\\in U$ is   \n491 optimal if and only if for some $\\lambda\\in\\mathbb R$ , ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\lambda\\in\\left\\{\\begin{array}{l l}{\\{c_{i}+\\gamma\\}}&{\\mathrm{~if~}u_{i}^{\\star}>0}\\\\ {[c_{i}-\\gamma,c_{i}+\\gamma]}&{\\mathrm{~if~}u_{i}^{\\star}=0}\\\\ {\\{c_{i}-\\gamma\\}}&{\\mathrm{~if~}u_{i}^{\\star}\\in(-1/N,0)}\\\\ {(-\\infty,c_{i}-\\gamma]}&{\\mathrm{~if~}u_{i}^{\\star}=-1/N.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "492 It follows that $\\lambda\\,=\\,c_{m i n}+\\gamma$ can accompany any optimal $u^{*}$ in satisfying the above; hence, the   \n493 result follows. ", "page_idx": 12}, {"type": "text", "text": "494 ", "page_idx": 12}, {"type": "text", "text": "495 Proposition A.1. Let $\\epsilon>0$ , and suppose for any $\\theta$ , $\\mathrm{max}_{(x,y)\\in\\mathcal{Z}}\\left|J(\\theta;x,y)\\right|<\\infty$ . Then there exists   \n496 $\\kappa\\geq0$ such that for any $\\theta$ , the following problem ", "page_idx": 12}, {"type": "equation", "text": "$$\nv_{N}^{M I X}(\\theta):=\\operatorname*{min}_{u_{1},\\dots,u_{N}}~\\sum_{i=1}^{N}(\\frac{1}{N}+u_{i})\\cdot J(\\theta;x_{i},y_{i})+\\gamma_{\\theta}\\sum_{i=1}^{N}|u_{i}|\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "497 satisfies $\\begin{array}{r}{v_{N}(\\theta)+\\frac{\\kappa}{N}\\geq v_{N}^{M I X}(\\theta)\\geq v_{N}(\\theta).}\\end{array}$ . ", "page_idx": 12}, {"type": "text", "text": "498 In particular, $\\begin{array}{r}{-\\gamma_{\\theta}\\,\\le\\,\\operatorname*{min}_{i}\\,J(\\theta;x_{i},y_{i}),}\\end{array}$ , and $\\{i:J(\\theta;x_{i},y_{i})>\\gamma_{\\theta}\\}$ are all down-weighted to zero,   \n499 i.e., $u_{i}^{*}=-\\frac{1}{N}$ for any $\\boldsymbol{u}^{*}$ solving $v_{N}^{\\bar{M}I X}(\\theta)$ .   \n500 Proof. Fix $\\theta$ . Then for any $z=(x,y)\\in{\\mathcal{Z}}$ , the function $\\ell(\\cdot,z,\\theta)$ is linear, and hence Lipschitz with   \n501 constant $\\begin{array}{r}{\\ell(1,z,\\theta)=J(\\theta;x,y)\\leq\\operatorname*{max}_{(x,y)\\in\\mathcal{Z}}\\left|J(\\theta;x,y)\\right|<\\infty}\\end{array}$ . ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "502 By Lemma 3.1 of [30] and/or Corollary 2 of [9], ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{v_{N}^{M I X}(\\theta):=\\displaystyle\\operatorname*{min}_{\\tilde{w}^{1},...,\\tilde{w}^{N}\\geq0}\\,\\,\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}\\ell(\\tilde{w}^{i},z^{i};\\theta)}}\\\\ {{\\mathrm{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mathrm{s.t.}~}\\,\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}|\\tilde{w}^{i}-w^{i}|\\leq\\epsilon}}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "503 provides the stated approximation of $v(\\theta)$ . ", "page_idx": 12}, {"type": "text", "text": "504 Upon introducing the change of variable $\\begin{array}{r}{u_{i}\\,=\\,\\frac{\\tilde{w}^{i}}{N}-\\frac{1}{N}}\\end{array}$ , and applying a Lagrange multiplier $\\gamma_{\\theta}$ to   \n505 the budget constraint (any convex dual optimal multiplier), we recover ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\operatorname*{min}_{u_{1},\\ldots,u_{N}}~\\sum_{i=1}^{N}\\ell(u_{i}+\\frac{1}{N},z^{i};\\theta)+\\gamma_{\\theta}\\sum_{i=1}^{N}|u_{i}|}}\\\\ {{\\mathrm{s.t.}~~u_{i}+\\displaystyle\\frac{1}{N}\\geq0~~i=1,\\ldots,N}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "506 ", "page_idx": 13}, {"type": "text", "text": "507 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "509 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n510 paper\u2019s contributions and scope? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "14 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n15 made in the paper.   \n16 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n17 contributions made in the paper and important assumptions and limitations. A No or   \n18 NA answer to this question will not be perceived well by the reviewers.   \n19 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n520 much the results can be expected to generalize to other settings.   \n21 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these   \n22 goals are not attained by the paper. ", "page_idx": 14}, {"type": "text", "text": "523 2. Limitations ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "Justification: The paper has focused more on label corruption, rather than feature perturbation settings. ", "page_idx": 14}, {"type": "text", "text": "8 Guidelines:   \n9 \u2022 The answer NA means that the paper has no limitation while the answer No means   \n0 that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n2 \u2022 The paper should point out any strong assumptions and how robust the results are to   \nviolations of these assumptions (e.g., independence assumptions, noiseless settings,   \n4 model well-specification, asymptotic approximations only holding locally). The au  \n5 thors should reflect on how these assumptions might be violated in practice and what   \n6 the implications would be.   \n7 \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n8 only tested on a few datasets or with a few runs. In general, empirical results often   \ndepend on implicit assumptions, which should be articulated.   \n0 \u2022 The authors should reflect on the factors that influence the performance of the ap  \n1 proach. For example, a facial recognition algorithm may perform poorly when image   \n2 resolution is low or images are taken in low lighting. Or a speech-to-text system might   \n3 not be used reliably to provide closed captions for online lectures because it fails to   \n4 handle technical jargon.   \n5 \u2022 The authors should discuss the computational efficiency of the proposed algorithms   \n6 and how they scale with dataset size.   \n7 \u2022 If applicable, the authors should discuss possible limitations of their approach to ad  \ndress problems of privacy and fairness.   \n9 \u2022 While the authors might fear that complete honesty about limitations might be used by   \n0 reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n1 limitations that aren\u2019t acknowledged in the paper. The authors should use their best   \n2 judgment and recognize that individual actions in favor of transparency play an impor  \n3 tant role in developing norms that preserve the integrity of the community. Reviewers   \nwill be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 14}, {"type": "text", "text": "555 3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "556 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n557 a complete (and correct) proof? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "559 Justification: Section 3   \n560 Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 15}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes]   \nJustification: Sections 3.2, 4, 5, 6   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 15}, {"type": "text", "text": "614 Answer: [No]   \n615 Justification: The datasets are open-source, and the code will be made available pending   \n616 conference review of this work   \n617 Guidelines:   \n618 \u2022 The answer NA means that paper does not include experiments requiring code.   \n619 \u2022 Please see the NeurIPS code and data submission guidelines   \n620 (https://nips.cc/public/guides/CodeSubmissionPolicy) for more de  \n621 tails.   \n622 \u2022 While we encourage the release of code and data, we understand that this might not   \n623 be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n624 including code, unless this is central to the contribution (e.g., for a new open-source   \n625 benchmark).   \n626 \u2022 The instructions should contain the exact command and environment needed to run   \n627 to reproduce the results. See the NeurIPS code and data submission guidelines   \n628 (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n629 \u2022 The authors should provide instructions on data access and preparation, including how   \n630 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n631 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n632 proposed method and baselines. If only a subset of experiments are reproducible, they   \n633 should state which ones are omitted from the script and why.   \n634 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n635 versions (if applicable).   \n636 \u2022 Providing as much information as possible in supplemental material (appended to the   \n637 paper) is recommended, but including URLs to data and code is permitted.   \n638 6. Experimental Setting/Details   \n639 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n640 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n641 results?   \n642 Answer: [Yes]   \n643 Justification: Sections 4, 5, 6   \n644 Guidelines:   \n645 \u2022 The answer NA means that the paper does not include experiments.   \n646 \u2022 The experimental setting should be presented in the core of the paper to a level of   \n647 detail that is necessary to appreciate the results and make sense of them.   \n648 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n649 material.   \n650 7. Experiment Statistical Significance   \n651 Question: Does the paper report error bars suitably and correctly defined or other appropri  \n652 ate information about the statistical significance of the experiments?   \n653 Answer: [No]   \n654 Justification: Error bars are not reported because it would be too computationally expen  \n655 sive.   \n656 Guidelines:   \n657 \u2022 The answer NA means that the paper does not include experiments.   \n658 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n659 dence intervals, or statistical significance tests, at least for the experiments that support   \n660 the main claims of the paper.   \n661 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n662 example, train/test split, initialization, random drawing of some parameter, or overall   \n663 run with given experimental conditions).   \n664 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n665 call to a library function, bootstrap, etc.) ", "page_idx": 16}, {"type": "text", "text": "\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 17}, {"type": "text", "text": "677 8. Experiments Compute Resources ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "678 Question: For each experiment, does the paper provide sufficient information on the com  \n679 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n680 the experiments?   \n681 Answer: [Yes]   \n682 Justification: See section 6   \n683 Guidelines: ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 17}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: The paper conforms with the NeurIPS Code of Ethics Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 17}, {"type": "text", "text": "703 10. Broader Impacts ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "704 Question: Does the paper discuss both potential positive societal impacts and negative   \n705 societal impacts of the work performed? ", "page_idx": 17}, {"type": "text", "text": "6 Answer: [No] Justification: The work in the paper is foundational research and is not tied to a particular application or deployment. ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. \u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake proflies, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. ", "page_idx": 17}, {"type": "text", "text": "717 \u2022 The conference expects that many papers will be foundational research and not tied   \n718 to particular applications, let alone deployments. However, if there is a direct path to   \n719 any negative applications, the authors should point it out. For example, it is legitimate   \n720 to point out that an improvement in the quality of generative models could be used to   \n721 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n722 that a generic algorithm for optimizing neural networks could enable people to train   \n723 models that generate Deepfakes faster.   \n724 \u2022 The authors should consider possible harms that could arise when the technology is   \n725 being used as intended and functioning correctly, harms that could arise when the   \n726 technology is being used as intended but gives incorrect results, and harms following   \n727 from (intentional or unintentional) misuse of the technology.   \n728 \u2022 If there are negative societal impacts, the authors could also discuss possible mitiga  \n729 tion strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n730 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n731 feedback over time, improving the efficiency and accessibility of ML).   \n732 11. Safeguards   \n733 Question: Does the paper describe safeguards that have been put in place for responsible   \n734 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n735 image generators, or scraped datasets)?   \n736 Answer: [No]   \n737 Justification: No models are released as part of this work, and the datasets are publicly   \n738 available.   \n739 Guidelines:   \n740 \u2022 The answer NA means that the paper poses no such risks.   \n741 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n742 necessary safeguards to allow for controlled use of the model, for example by re  \n743 quiring that users adhere to usage guidelines or restrictions to access the model or   \n744 implementing safety fliters.   \n745 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n746 should describe how they avoided releasing unsafe images.   \n747 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n748 not require this, but we encourage authors to take this into account and make a best   \n749 faith effort.   \n750 12. Licenses for existing assets   \n751 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n752 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n753 properly respected?   \n754 Answer: [Yes]   \n755 Justification: Citations for publicly available datasets and code are provided.   \n756 Guidelines:   \n757 \u2022 The answer NA means that the paper does not use existing assets.   \n758 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n759 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n760 URL.   \n761 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n762 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n763 service of that source should be provided.   \n764 \u2022 If assets are released, the license, copyright information, and terms of use in the pack  \n765 age should be provided. For popular datasets, paperswithcode.com/datasets has   \n766 curated licenses for some datasets. Their licensing guide can help determine the li  \n767 cense of a dataset.   \n768 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n769 the derived asset (if it has changed) should be provided.   \n770 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n771 the asset\u2019s creators.   \n772 13. New Assets   \n773 Question: Are new assets introduced in the paper well documented and is the documenta  \n774 tion provided alongside the assets?   \n775 Answer: [No]   \n776 Justification: No new assets are introduced in the paper.   \n777 Guidelines:   \n778 \u2022 The answer NA means that the paper does not release new assets.   \n779 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n780 submissions via structured templates. This includes details about training, license,   \n781 limitations, etc.   \n782 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n783 asset is used.   \n784 \u2022 At submission time, remember to anonymize your assets (if applicable). You can   \n785 either create an anonymized URL or include an anonymized zip flie.   \n786 14. Crowdsourcing and Research with Human Subjects   \n787 Question: For crowdsourcing experiments and research with human subjects, does the pa  \n788 per include the full text of instructions given to participants and screenshots, if applicable,   \n789 as well as details about compensation (if any)?   \n790 Answer: [NA]   \n791 Justification: No crowdsourcing experiments or research with human subjects was con  \n792 ducted.   \n793 Guidelines:   \n794 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research   \n795 with human subjects.   \n796 \u2022 Including this information in the supplemental material is fine, but if the main contri  \n797 bution of the paper involves human subjects, then as much detail as possible should   \n798 be included in the main paper.   \n799 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, cura  \n800 tion, or other labor should be paid at least the minimum wage in the country of the   \n801 data collector.   \n802 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n803 Subjects   \n804 Question: Does the paper describe potential risks incurred by study participants, whether   \n805 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n806 approvals (or an equivalent approval/review based on the requirements of your country or   \n807 institution) were obtained?   \n808 Answer: [NA]   \n809 Justification: The paper does not involve research with human subjects.   \n810 Guidelines:   \n811 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research   \n812 with human subjects.   \n813 \u2022 Depending on the country in which research is conducted, IRB approval (or equiva  \n814 lent) may be required for any human subjects research. If you obtained IRB approval,   \n815 you should clearly state this in the paper.   \n816 \u2022 We recognize that the procedures for this may vary significantly between institutions   \n817 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n818 guidelines for their institution.   \n819 \u2022 For initial submissions, do not include any information that would break anonymity   \n820 (if applicable), such as the institution conducting the review. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}]