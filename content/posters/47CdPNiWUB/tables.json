[{"figure_path": "47CdPNiWUB/tables/tables_7_1.jpg", "caption": "Table 1: Test accuracy (%) for AT and A-RRM on MNIST under different levels of corruption C and test-set adversarial perturbation Etest.", "description": "This table presents the test accuracy results achieved by Adversarial Training (AT) and Adversarial Rockafellian Relaxation Method (A-RRM) on the MNIST dataset under varying levels of label corruption (C) and test-set adversarial perturbation (Etest).  It shows how the methods perform with different amounts of initially corrupted training data and different levels of adversarial noise added to the test data. This allows for a comparison of the robustness of each method to label noise and adversarial attacks.", "section": "6.1 MNIST"}, {"figure_path": "47CdPNiWUB/tables/tables_7_2.jpg", "caption": "Table 2: Evolution of u-vector across 9600 corrupted data points and 38400 clean data points. Note that 1/(9600 + 38400) = 2.08. 10-5.", "description": "This table shows the evolution of the weight vector (u) across iterations of the Rockafellian Relaxation algorithm. The table displays the distribution of u values among corrupted and clean data points at three different iteration stages: 1st iteration, 10th iteration, and 49th iteration.  It illustrates how the algorithm progressively assigns lower weights to corrupted data points, effectively down-weighting their influence on model training.  The final iteration's weights showcase the removal of corrupted points by setting their weights close to zero.", "section": "6.1 MNIST"}, {"figure_path": "47CdPNiWUB/tables/tables_7_3.jpg", "caption": "Table 3: Comparison of training and test area under the precision/recall curve for ERM and RRM at noise levels ranging from 1% to 20%.", "description": "This table presents the Area Under the Precision-Recall Curve (AUPRC) for both ERM and RRM models, evaluated on both training and testing sets.  The results are broken down by different percentages of label noise (corruption) in the training data (1%, 5%, 7%, 10%, 15%, 20%).  It shows how the performance of each model changes as the amount of noise increases.", "section": "6.2 Toxic Comment"}, {"figure_path": "47CdPNiWUB/tables/tables_8_1.jpg", "caption": "Table 4: Test accuracy (%) for ERM and RRM on IMDb under different levels of corruption. Test set accuracy at peak validation accuracy and maximum test set accuracy are recorded.", "description": "This table presents the test accuracy results for both ERM and RRM methods on the IMDb dataset under varying levels of label corruption (25%, 30%, 40%, and 45%).  For each corruption level, two test accuracy values are shown: the accuracy achieved at the point of peak validation accuracy and the maximum test accuracy obtained during the training process. This allows for a comparison of the methods' performance under different corruption scenarios and helps to assess the robustness of RRM in handling noisy labels.", "section": "6.3 IMDb"}]