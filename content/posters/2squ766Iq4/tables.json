[{"figure_path": "2squ766Iq4/tables/tables_7_1.jpg", "caption": "Table 1: Synthetic data test accuracy under both dense and sparse shifts across a range of distances.", "description": "This table presents the results of synthetic data experiments conducted to validate the theoretical findings of the paper.  The experiments focus on classification tasks under both dense and sparse shift conditions. The table displays test accuracy for three different methods:\n\n1.  **Only Source:** A baseline representing the model trained only on source data. \n2.  **iMSDA [18]:** A state-of-the-art domain adaptation method from prior work. \n3. **Ours:** The proposed method of the current paper.\n\nThe results are shown for different shift distances, allowing for an evaluation of how each method performs as the distance from the training data increases.  The \"dense\" and \"sparse\" columns refer to two different types of distribution shifts, affecting different numbers of data dimensions.", "section": "5 Synthetic Data Experiments"}, {"figure_path": "2squ766Iq4/tables/tables_8_1.jpg", "caption": "Table 2: Comparison of SOTA TTA Methods on CIFAR10-C, CIFAR100-C, and ImageNet-C. Average error rates over 15 test corruptions are reported. Baseline results are from Tomar et al. [21]. Values are (means + standard deviations) over three random seeds. * indicates our reproductions.", "description": "This table compares the performance of several state-of-the-art test-time adaptation (TTA) methods on three corrupted image datasets: CIFAR10-C, CIFAR100-C, and ImageNet-C.  The average error rates are presented across 15 different types of corruptions, demonstrating the effectiveness of different techniques in handling distribution shifts during the test phase. The table includes baseline results from a previous study by Tomar et al. [21] for comparison, and error bars (mean \u00b1 standard deviation) are provided to indicate variability across three independent runs of each experiment.  The authors' improved method is indicated with a '*'.", "section": "6.1 Generative Adaptation with Entropy Minimization"}, {"figure_path": "2squ766Iq4/tables/tables_8_2.jpg", "caption": "Table 3: Test accuracy (%) on ImageNet-C. The baseline results are from Gandelsman et al. [20].", "description": "This table presents the test accuracy results on the ImageNet-C dataset, comparing the proposed method with several baselines (Joint Train, Fine-Tune, ViT Probe, TTT-MAE).  The results are broken down by individual corruption types and show the average accuracy across all corruptions. The proposed method demonstrates a significant improvement in accuracy over all baselines.", "section": "6.1 Generative Adaptation with Entropy Minimization"}, {"figure_path": "2squ766Iq4/tables/tables_8_3.jpg", "caption": "Table 4: Understanding entropy-minimization steps on ImageNet100-C. Values are classification accuracy (mean and standard deviation) over three random seeds.", "description": "This table presents the results of adding entropy-minimization steps to the MAE-TTT framework.  It shows classification accuracy (mean and standard deviation across three random seeds) on the ImageNet100-C dataset for the baseline MAE-TTT and for the modified MAE-TTT with 1, 2, and 3 entropy-minimization steps. The results demonstrate that adding these steps significantly improves performance.", "section": "6.1 Generative Adaptation with Entropy Minimization"}, {"figure_path": "2squ766Iq4/tables/tables_21_1.jpg", "caption": "Table A1: Synthetic data results on regression (MSE) under both dense and sparse shifts across various distances.", "description": "This table presents the Mean Squared Error (MSE) results of a regression task performed on synthetic data under different shift conditions (dense and sparse).  The results are compared for three different out-of-support distances (18, 24, and 30), showing the performance of a model trained only on source data versus the proposed model.  It demonstrates the effectiveness of the model in handling extrapolation under both dense and sparse shift scenarios and different levels of out-of-distribution data.", "section": "A4.2 Regression Task Evaluation"}, {"figure_path": "2squ766Iq4/tables/tables_22_1.jpg", "caption": "Table 1: Synthetic data test accuracy under both dense and sparse shifts across a range of distances.", "description": "This table presents the results of synthetic data experiments on classification, comparing the test accuracy of three different methods: 'Only Source' (a model trained only on source data), iMSDA (an existing domain adaptation method), and the proposed method. The experiments were conducted under both 'dense shifts' (global transformations affecting all pixels) and 'sparse shifts' (local changes affecting only a subset of pixels). The accuracy is reported across different levels of 'distance' of the target sample from the source support, which represents the severity of distribution shift.  The results show that the proposed method outperforms the baselines across all conditions, validating its ability to handle extrapolation effectively.", "section": "5 Synthetic Data Experiments"}, {"figure_path": "2squ766Iq4/tables/tables_22_2.jpg", "caption": "Table 3: Test accuracy (%) on ImageNet-C. The baseline results are from Gandelsman et al. [20].", "description": "This table compares the test accuracy of different methods on the ImageNet-C dataset, which evaluates the robustness of models to various corruptions.  It shows the performance of the proposed method compared to a baseline MAE-TTT and other baselines (Joint Train, Fine-Tune, ViT Probe). The average accuracy across all corruption types, along with individual results for each corruption type, are provided.", "section": "6.1 Generative Adaptation with Entropy Minimization"}, {"figure_path": "2squ766Iq4/tables/tables_22_3.jpg", "caption": "Table 1: Synthetic data test accuracy under both dense and sparse shifts across a range of distances.", "description": "This table presents the results of synthetic data experiments conducted to validate the theoretical findings of the paper. The experiments involved binary classification tasks with varying levels of \"dense\" and \"sparse\" shifts in the data distribution. The accuracy of the model is evaluated across a range of distances between the target sample and the source distribution support. The results showcase how the model's performance is affected by the nature of the shift (dense vs. sparse) and the distance of the target sample from the source distribution support.", "section": "5 Synthetic Data Experiments"}]