[{"type": "text", "text": "An effective framework for estimating individualized treatment rules ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Joowon Lee1, Jared D. Huling2, Guanhua Chen1 1 University of Wisconsin-Madison, 2 University of Minnesota joowon.lee@wisc.edu, huling@umn.edu, gchen25@wisc.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Estimating individualized treatment rules (ITRs) is fundamental in causal inference, particularly for precision medicine applications. Traditional ITR estimation methods rely on inverse probability weighting (IPW) to address confounding factors and $L_{1}$ -penalization for simplicity and interpretability. However, IPW can introduce statistical bias without precise propensity score modeling, while $L_{1}$ -penalization makes the objective non-smooth, leading to computational bias and requiring subgradient methods. In this paper, we propose a unified ITR estimation framework formulated as a constrained, weighted, and smooth convex optimization problem. The optimal ITR can be robustly and effectively computed by projected gradient descent. Our comprehensive theoretical analysis reveals that weights that balance the spectrum of a \u2018weighted design matrix\u2019 improve both the optimization and likelihood landscapes, yielding improved computational and statistical estimation guarantees. In particular, this is achieved by distributional covariate balancing weights, which are model-free alternatives to IPW. Extensive simulations and applications demonstrate that our framework achieves significant gains in both robustness and effectiveness for ITR learning against existing methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Traditional medicine often uses a \"one-size-ftis-all\" approach where the same treatment is applied to all patients regardless of their unique attributes, aiming to find a single optimal treatment that may be most effective for a broad population. However, since not everyone ftis the mold, precision medicine has been popular in medical research, emphasizing personalized treatment based on a patient\u2019s unique characteristics [11]. ", "page_idx": 0}, {"type": "text", "text": "One key element of precision medicine is the estimation of individualized treatment regime (ITR), also known as treatment policy or policy. ITRs consider various factors like demographics and sociopsychological aspects to optimize treatment decisions, thereby maximizing individual outcomes. Many frameworks have been proposed for learning ITRs [41, 54, 57, 7, 58, 60, 56] and the related conditional average treatment effect (CATE) estimation problem [3, 53, 46, 13, 36]. For model interpretation and other practical concerns, researchers often focus on pre-specified rule classes. For example, the method proposed in [2] focuses on estimating ITRs using shallow-depth decision trees. ", "page_idx": 0}, {"type": "text", "text": "The central task in the ITR estimation is controlling confounding factors to isolate the causal effect of treatment from other factors that may influence the outcome. A standard approach is by weighting each sample using their inverse probability weights (IPWs), which requires specifying a propensity score model. However, propensity score methods have long been known to be highly sensitive to model misspecification, which yields biased estimates of causal effects [25, 30]. Distributional covariate balancing weights (DCBWs) [24, 27] are modern alternatives to IPWs, directly minimizing the distance between empirical covariate distributions induced by the weights. ", "page_idx": 0}, {"type": "text", "text": "ITR estimation can be framed as an optimization or maximum likelihood estimation (MLE) problem, where the choice of weights directly impacts both the optimization and likelihood landscapes. This, in turn, affects the computational and statistical errors in the ITR estimation, as well as the performance of the optimization algorithm. The key contribution of this work is to bridge the gap between causal inference and optimization perspectives in ITR estimation. Our main finding is both simple and surprising: Covariate balancing weights not only address confounding but also yield optimal optimization and likelihood landscapes for the ITR estimation. We show this claim by formulating the ITR estimation problem as a constrained, weighted, and smooth convex optimization problem. Our formulation is grounded in angle-based direct learning (AD-Learning) framework [39], which is a recent framework for multi-category treatments with a linear decision function class assumption. While we focus on multi-category treatments\u2014a relatively underexplored area\u2014we believe that the principles are equally applicable to binary treatments with a linear decision function. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Besides advancing our theoretical understanding of the impact of covariate balancing weights, we propose a unified computational and statistical framework for the ITR estimation. Notably, we introduce a hard $L_{1}$ -ball constraint to promote sparsity in regression coefficients, replacing the traditional soft $L_{1}$ -penalization. This approach keeps the optimization objective smooth, enabling fast and accurate ITR estimation using projected gradient descent (PGD). Furthermore, we integrate techniques such as (1) variable screening, (2) outcome augmentation, and (3) inverse variance weighting to account for heteroscedastic errors, which together show a synergistic effect. ", "page_idx": 1}, {"type": "text", "text": "Related Work. Most existing ITR approaches use IPW, which requires specifying a propensity score model for confounding control. Recent developments in causal inference have also introduced robust approaches that directly estimate weights based on balance-seeking objectives rather than relying solely on propensity scores. These approaches include entropy balancing weights [20], stable balancing weights [61] as well as DCBWs [24, 27]. However, despite the weights serving a critical role in the estimation process, these advancements have mainly focused on improving average treatment effect (ATE) and are largely under-explored in the ITR literature. To the best of our knowledge, this is the first work to apply DCBWs for ITR-Learning under a weighted optimization framework. While recent works have taken a similar approach by utilizing weighting schemes and directly optimizing the weights rather than relying on estimated IPW [28, 26], our method differs in key aspects. Unlike [26], which involves the evaluation of policy effects, our approach directly learns the optimal decision function, bypassing the need for intermediate policy effect evaluations. Although [28] introduced the concept of retargeting the population covariate distribution, which is conceptually related to our analysis, their approach relies on a reference policy, whereas our method does not. We also explore various statistical techniques to improve ITR-Learning. First, we perform variable screening using the distance covariance test [48] to retain key effect modifiers and precision variables that directly impact the outcome. Second, [50, 9] introduced outcome augmentation to minimize estimator variance in clinical trials and observational studies by IPW involving binary treatments. Building on these foundations, our work extends these approaches to a broader range of weighting schemes, such as DCBW particularly for multi-category treatments. Lastly, with inverse variance weighting, as introduced in stabilized angle-based direct learning (SABD-Learning) to address heteroscedasticity [44], this combined strategy enhances estimator precision and robustness. ", "page_idx": 1}, {"type": "text", "text": "Contributions. We summarize our contributions below. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Unified Framework of ITR-Learning: We introduce a novel framework that addresses the limitations of existing ITR estimation methods by formulating the problem as a constrained, weighted, and smooth convex optimization problem. Under the framework, we propose a PGD algorithm for ITR-Learning under a hard $L_{1}$ -constraint. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Improved Computational and Statistical Guarantees: We establish convergence guarantees (Theorem 3.3). Furthermore, under mild assumptions, we demonstrate that the parameter of ITR-Learning can be consistently estimated with high probability (Theorem 3.5) and provide computational and sample complexity. In both cases, we demonstrate that using covariate balancing weights controls confounding factors and leads to better optimization and likelihood landscapes, resulting in improved computational and statistical performance. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Statistical Framework of ITR-Learning: Our main contribution lies in providing a unified framework that combines DCBWs, variable screening, outcome augmentation, and inverse variance weighting in a synergistic and effective way. We demonstrated theoretical justifications for the combined approach, which, to our knowledge, have not been previously established. ", "page_idx": 1}, {"type": "text", "text": "2 Methods for ITR Estimation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Model Setup", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Individualized Treatment Rule and Optimal Decision Function. We observe a random vector $(\\mathbf{X},A,Y)$ where $\\mathbf{X}=(X_{1},X_{2},\\ldots,X_{p})\\in{\\mathcal{X}}$ denotes the $p$ -dimensional vector of pre-treatment covariates, a received treatment $A\\in{\\mathcal{A}}=\\{1,2,\\dots,K\\}$ , and the corresponding outcome $Y$ . Without loss of generality, we assume higher $Y$ values are more favorable. Let $Y(a)$ denote the random variable that describes the potential outcome that would have been observed were the individual assigned to treatment $a\\in{\\mathcal{A}}$ . We make the following standard assumptions using the potential outcome framework [43]: (i) Stable Unit Treatment Value Assumption (SUTVA): $Y=Y(A)$ , (ii) positivity: $0<\\pi(a,\\mathbf{X}):=\\mathbb{P}(A=a|\\mathbf{X})<1$ for all $a\\in A$ and all $\\mathbf{X}\\in\\mathcal{X}$ , (iii) no unmeasured confounding: $Y(a)\\perp A|\\mathbf{X}$ for any $a\\in{\\mathcal{A}}$ . ", "page_idx": 2}, {"type": "text", "text": "An ITR, $d(\\mathbf{x})$ , is a function mapping each covariate $\\mathbf{x}$ to one of the $K$ treatments. According to [41], the ITR $d$ can be measured by the value function $V(d)$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\nV(d):=\\mathbb{E}[Y(d(\\mathbf{X}))]=\\mathbb{E}[Y|A=d(\\mathbf{X})]=\\mathbb{E}\\left[{\\frac{Y\\ \\mathbf{1}(A=d(\\mathbf{X}))}{\\pi(A,\\mathbf{X})}}\\right]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Then the optimal ITR $d^{\\mathrm{opt}}$ is defined as a function that maximizes the expected potential outcome $d^{\\mathrm{opt}}(\\mathbf{x})\\in\\arg\\operatorname*{max}_{d\\in\\mathcal{D}}V(d)$ among all functions belonging to the treatment rule class $(\\mathcal{D})$ . Building on this, we adopt the following working model: ", "page_idx": 2}, {"type": "equation", "text": "$$\nY=\\mu(\\mathbf{X})+\\sum_{k=1}^{K}\\delta_{k}(\\mathbf{X})\\mathbf{I}(A=k)+\\epsilon,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mu({\\mathbf X})$ is treatment-free effect, $\\delta_{k}({\\mathbf X})$ is interaction effect between covariates and $k\\mathrm{th}$ treatment, and $\\epsilon$ is a random noise with mean zero and variance ${\\sigma}^{2}(A,\\mathbf{X})$ . For model identifiability, we assume $\\begin{array}{r}{\\sum_{k=1}^{K}\\delta_{k}(\\mathbf{x})=0}\\end{array}$ for all $\\mathbf{x}$ . Under this model, $\\delta_{k}({\\mathbf X})$ determines the optimal ITR, while $\\mu({\\bf x})$ has no impact on the ITR. One approach to identifying the optimal ITR is to use $K$ separate decision functions for each treatment with the sum-to-zero constraint, but this approach can be computationally inefficient [55]. ", "page_idx": 2}, {"type": "text", "text": "Instead, one can opt for simplex coding as an alternative, which inherently satisfies the sum-to-zero constraint. In AD-Learning [39], each of the $K$ treatments is represented as a vertex simplex on $\\mathbb{R}^{K-1}$ , denoted as $\\mathbf{u}_{k}$ , $k=1,\\ldots,K$ . In particular, $\\mathbf{u}_{k}$ is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{u}_{k}=\\left\\{\\begin{array}{l l}{\\frac{1}{\\sqrt{K-1}}\\mathbf{1}_{K-1}}&{\\mathrm{~if~}k=1,}\\\\ {-\\frac{1+\\sqrt{K}}{\\sqrt{(K-1)^{3}}}\\mathbf{1}_{K-1}+\\sqrt{\\frac{K}{K-1}}\\mathbf{e}_{k-1}}&{\\mathrm{~if~}k\\geq2,}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where ${\\bf1}_{K-1}$ is a $K-1$ dimensional vector with entries 1, and $\\mathbf{e}_{k-1}$ is a $K-1$ dimensional vector with entries 0 except its $k$ -th entry being 1. This vertex simplex has $K$ vertices with equal angles between them and an origin at the center of the simplex. All $\\mathbf{u}_{k}$ have the same Euclidean norm 1. Then the optimal ITR is reformulated as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\nd^{\\mathrm{out}}(\\mathbf{x})=\\operatorname*{arg\\,max}_{k\\in\\{1,\\ldots,K\\}}\\mathbb{E}[Y|\\mathbf{x},A=k]=\\operatorname*{arg\\,max}_{k\\in\\{1,\\ldots,K\\}}\\underbrace{\\mathbf{u}_{k}^{T}\\,\\mathbb{E}\\left[\\frac{Y\\mathbf{u}}{\\pi(A,\\mathbf{x})}\\Bigg|\\mathbf{x}\\right]}_{=:\\mathrm{f}_{\\mathrm{opt}}(\\mathbf{x})},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathbf{u}$ is a random treatment vector in $\\mathbb{R}^{K}$ , corresponding to the random treatment $A$ . Then estimating the optimal ITR can be converted into estimating the decision function ${\\textbf{f}}(\\mathbf{x})\\ =$ $(f_{1}(\\mathbf{x}),\\bar{\\dots},f_{K-1}\\bar{(\\mathbf{x})})^{T}$ , assigning a $K-1$ dimensional vector to each covariate $\\mathbf{x}$ . Here, while the optimal decision function $\\mathbf{f}_{\\mathrm{opt}}(\\cdot)$ can take a generic form, we assume the linear decision function within the linear treatment rule class $\\mathcal{D}$ , induced by the linear decision function class ${\\mathcal{F}}=\\{{\\mathbf{f}}({\\mathbf{X}})={\\mathbf{B}}^{T}{\\mathbf{X}}:{\\mathbf{B}}\\in\\mathbb{R}^{p\\times(K-1)}\\},$ . ", "page_idx": 2}, {"type": "text", "text": "Reduction to Weighted Convex Optimization. Suppose we have a sample $(\\mathbf{x}_{i},a_{i},y_{i})_{i=1}^{n}$ of size $n$ from the joint population distribution for $(\\mathbf{X},A,Y)$ . Estimating the optimal decision function $\\mathbf{f}_{\\mathrm{opt}}$ from the observed finite sample can be reduced to solving a weighted convex optimization problem: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{B\\in\\mathbb{R}^{p\\times(K-1)}}}\\;\\frac{1}{n}\\sum_{i=1}^{n}w\\bigl(a_{i},\\mathbf{x}_{i}\\bigr)\\,\\ell\\bigl(y_{i},\\mathbf{x}_{i},a_{i};\\mathbf{B}\\bigr)+R\\bigl(\\mathbf{B}\\bigr).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "There are three key components in the problem (3): the per-sample objective function $\\ell$ , the persample weights $w$ , and the regularization $R({\\bf B})$ . First, $\\ell$ denotes a model-dependent per-sample convex objective function given by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell(y_{i},\\mathbf{x}_{i},a_{i};\\mathbf{B})=\\left\\{\\begin{array}{l l}{\\frac{1}{2}\\left(\\frac{K}{K-1}y_{i}-\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)^{2}}&{\\mathrm{~for~continuous~outcome},}\\\\ {\\log\\left(1+\\exp(\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i})\\right)-y_{i}\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}}&{\\mathrm{~for~binary~outcome}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "An important characteristic of causal inference problems is that only one of the possible treatments can be observed for each subject. Thus, it is critical to control confounding variables to isolate the causal effect of the treatment from other factors that might influence the outcome. This effectively is done by choosing the appropriate weight $w_{i}=w(a_{i},{\\mathbf{x}}_{i})$ for the ith subject. A classic approach is to use IPW: $w(a,\\mathbf{x})=1/\\pi(a,\\mathbf{x})$ [39]. ", "page_idx": 3}, {"type": "text", "text": "2.2 Proposed ITR Estimation Framework ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Reducing Finite Sample Bias. The classic IPW approach requires specifying a propensity score model for confounding control. However, it is well-known that propensity score methods are highly sensitive to model misspecification, which yields biased estimates of causal effects [25, 30]. To address this issue, we investigate incorporating alternative, model-free weighting schemes such as energy balancing weights (EBWs) [23, 24], which are a type of DCBWs. Other options for DCBWs include maximum mean discrepancy (MMD) balancing weights [19, 27, 8] and Wasserstein distance-based balancing weights [52, 1]. Specifically, under the working model assumption (1), the optimal decision function $\\mathbf{f}_{\\mathrm{opt}}$ in (2) can be decomposed as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{f}_{\\mathrm{opt}}(\\mathbf{x})=\\underbrace{\\mu(\\mathbf{x})\\mathbb{E}\\left[\\frac{\\mathbf{u}}{\\pi(A,\\mathbf{x})}\\middle|\\mathbf{x}\\right]}_{\\mathrm{treatment:free}}+\\underbrace{\\sum_{k=1}^{K}\\delta_{k}(\\mathbf{x})\\mathbb{E}\\left[\\frac{\\mathbf{u}I(A=k)}{\\pi(A,\\mathbf{x})}\\middle|\\mathbf{x}\\right]}_{\\mathrm{interaction}}+\\mathbb{E}\\left[\\frac{\\mathbf{u}}{\\pi(A,\\mathbf{x})}\\middle|\\mathbf{x}\\right]\\mathbb{E}[\\epsilon|\\mathbf{x}].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Since $\\begin{array}{r}{\\mathbb{E}\\left[\\frac{{\\bf u}}{\\pi(A,{\\bf x})}|{\\bf x}\\right]=0}\\end{array}$ and $\\mathbb{E}[\\epsilon|{\\bf x}]=0$ , it follows that $\\begin{array}{r}{{\\bf f}_{\\mathrm{opt}}({\\bf x})=\\sum_{k=1}^{K}\\delta_{k}({\\bf x}){\\bf u}_{k}}\\end{array}$ , depending only on the interaction term. However, suppose the true propensity score is not correctly estimated. In that case, the estimated decision function may be biased and include additional factors including the treatment-free effect, leading to sub-optimal treatment decisions. There are two possible sources for this estimation error. First, an incorrectly specified propensity score model might lead to an estimated propensity score ${\\hat{\\mathbb{P}}}_{n}(A=a|\\mathbf{x})$ that deviates from the true propensity score $\\pi(A=a|\\mathbf{x})$ . Second, even with correct specification, insufficient sample size may lead to inaccurate finite-sample approximation ${\\hat{\\mathbb{P}}}_{n}(A=a|\\mathbf{x})$ of the true propensity score $\\pi(A=a|\\mathbf{x})$ [31]. It results in systematic bias for the estimated coefficient of the treatment-free term: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{\\mathbb{E}}_{n}\\left[\\frac{\\mathbf{u}}{\\pi(A,\\mathbf{x})}\\middle|\\mathbf{x}\\right]=\\sum_{k=1}^{K}\\frac{\\mathbf{u}_{k}}{\\pi(k,\\mathbf{x})}\\hat{\\mathbb{P}}_{n}(A=k|\\mathbf{x})\\neq0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Instead of using IPW, we use DCBWs such as EBWs. Such weights are data-driven and do not rely on specific model assumptions or large sample approximation. Furthermore, EBWs are known to promote independence between treatment and confounders [23], so $\\hat{\\mathbb{E}}_{n}[{\\bf u}w(A,{\\bf x})\\,|\\,{\\bf x}]\\approx$ $\\hat{\\mathbb{E}}_{n}[\\mathbf{u}]\\hat{\\mathbb{E}}_{n}[w(A,\\mathbf{x})\\,|\\,\\mathbf{x}]=0$ since $\\mathbb{\\hat{E}}_{n}[\\mathbf{u}]=0$ . Thus, EBWs may reduce the unfavorable impacts of bias on the finite-sample decision function. ", "page_idx": 3}, {"type": "text", "text": "Improving Optimization Guarantees. To our best knowledge, the impact of the choice of the regularization $R({\\bf B})$ on the model parameter $\\mathbf{B}$ on the detailed optimization landscape, especially in terms of the convergence rate and statistical estimation error bounds has been under-investigated in the literature. Contrary to the literature, we propose to use the combination of soft $L_{2}$ -regularization and a hard $L_{1}$ -ball constraint:. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)},\\,\\|\\mathbf{B}\\|\\leq\\lambda_{1}}\\left[\\mathcal{L}(\\mathbf{B}):=\\frac{1}{n}\\sum_{i=1}^{n}w(a_{i},\\mathbf{x}_{i})\\,\\ell(y_{i},x_{i},a_{i};\\mathbf{B})+\\frac{\\lambda_{2}}{2}\\|\\mathbf{B}\\|_{F}^{2}\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The above formulation has a smooth objective function that is unaffected by the hard $L_{1}$ -ball constraint. Also, $L_{2}$ -regularization ensures that the objective is at least $\\lambda_{2}$ -strongly convex. Thus, the ", "page_idx": 3}, {"type": "text", "text": "PGD algorithm (with suitable stepsize) enjoys a strong exponential convergence guarantee toward the global optimum. In contrast, standard approaches with $L_{1}$ -penalization loss need sub-gradient methods since it is non-smooth. It is known that the convergence rate of the sub-gradient methods is much slower than gradient methods [6, 18]. ", "page_idx": 4}, {"type": "text", "text": "We use the classical PGD to solve the convex-constrained optimization problem in (6). In each iteration, it involves conducting gradient descent with a suitable stepsize $\\alpha_{t}$ , followed by a projection $\\Pi_{B}$ onto the $L_{1}$ -ball $\\mathcal{B}:=\\{\\mathbf{B}\\,\\,\\in\\,\\mathbb{R}^{p\\times(K-1)}\\,:\\,\\|\\mathbf{B}\\|\\leq\\lambda_{1}\\}:$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{B}_{t}\\leftarrow\\Pi_{\\mathcal{B}}\\big(\\mathbf{B}_{t-1}-\\alpha_{t}\\nabla_{\\mathbf{B}}\\mathcal{L}\\big(\\mathbf{B}_{t-1}\\big)\\big).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "For the projection onto the $L_{1}$ -projection, we use the algorithm in [14]. Detailed implementation of this PGD algorithm is discussed in Algorithm 1 in the appendix. ", "page_idx": 4}, {"type": "text", "text": "Additional Improvements by Variance and Dimension Reduction. To ensure the stability of estimates for both balancing weights and outcome regression models, a variable screening step is recommended. We propose adapting distance covariance test [48] for its computational efficiency and its ability to detect complex dependencies between treatment and outcome. By focusing on screened variables that significantly impact the outcome, we can improve the estimation of outcome regression models. Additionally, estimating balancing weights based on effect modifiers rather than all variables provides more reliable weighting estimates. Hence, the screening approach serves to reduce bias and enhance the effectiveness of ITR-Learning. See Algorithm 2 in the appendix. ", "page_idx": 4}, {"type": "text", "text": "Lastly, we propose using both augmented outcomes and inverse variance weighting for variance reduction in learning ITRs. Under the working model assumption in (1), the interaction effect determines optimal treatment assignments, while the treatment-free effect acts as additional noise. Outcome augmentation helps reduce variance by mitigating residual variability due to the treatment-free effect. Nevertheless, misspecification of either the outcome or treatment-free effect models can induce heteroscedastic errors due to residual treatment-free effects [35]. In such scenarios, using inverse variance weighting, introduced in SABD-Learning, enhances robustness against misspecification [44]. Consequently, the combination of outcome augmentation and inverse variance weighting offers a robust and efficient approach to ITR-Learning, as they are complementary methods. Details are discussed in the appendix C.3 and C.4. ", "page_idx": 4}, {"type": "text", "text": "3 Statement of results ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our theoretical analysis shows that a \u201cweighted design matrix\u201d, specifically a $p(K-1)\\times p(K-1)$ positive semi-definite matrix, plays a central role in the local landscape analysis of the ITR estimation problem: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Psi:=\\frac{1}{n}\\sum_{i=1}^{n}\\omega\\big(a_{i},\\mathbf{x}_{i}\\big)\\big(\\mathbf{u}_{a_{i}}\\mathbf{u}_{a_{i}}^{T}\\big)\\otimes\\big(\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}\\big)\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\otimes$ denotes the Kronecker product. In order to control the strong convexity and the smoothness parameter of the ITR objective (6), we require that the eigenvalues of $\\Psi$ are uniformly bounded. ", "page_idx": 4}, {"type": "text", "text": "Note that the weights $w_{i}=w(a_{i},{\\bf x}_{i})$ , $i=1,\\dots,n$ affect the eigenvalues of the weighted design matrix $\\Psi$ . Our analysis reveals that, for the improved convergence rate of the PGD algorithm (Theorem 3.3) as well as a smaller statistical estimation error (Theorem 3.5), we need to choose the weights $w_{i}$ such that the minimum eigenvalue of $\\Psi$ is as large as possible. Roughly speaking, this is achieved when $w_{1},\\ldots,w_{n}$ are \u2018covariate balancing weights\u2019 where the weighted sample covariance matrices conditional for each treatment are approximately the same. In the special case when the covariates are discrete and one-hot encoded, the optimal weights are the ones that exactly balance the covariate distributions given treatments. Thus this provides an explicit spectral characterization of the DCBWs in causal inference literature. See the appendix D for more discussions. ", "page_idx": 4}, {"type": "text", "text": "3.1 Computational Guarantees ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Assumption 3.1 (Eigenvalue bounds on the weighted design matrix). There are constants $0\\leq\\lambda^{-}\\leq$ $\\lambda^{+}$ such that the eigenvalues of $\\Psi$ in (8) is between $\\lambda^{-}$ and $\\lambda^{+}$ , ", "page_idx": 4}, {"type": "text", "text": "For each subject $i=1,\\hdots,n$ , let $z_{i}$ and $p_{i}$ denote its \u2018activation\u2019 and \u2018predictive probability\u2019, where ", "page_idx": 5}, {"type": "equation", "text": "$$\nz_{i}:=\\mathbf{u}_{\\mathbf{a}_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i},\\qquad p_{i}:=\\exp(z_{i})/(1+\\exp(z_{i})).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We need the activation $z_{i}$ to be uniformly bounded for our theoretical analysis of the binary outcome.   \nSince the simplex vectors $\\mathbf{u}_{a_{i}}$ have unit length, it is enough to require the following assumption. ", "page_idx": 5}, {"type": "text", "text": "Assumption 3.2 (Bounded activation). There exists a constant $M\\,>\\,0$ such that for all model parameter $\\mathbf{B}\\in\\mathbb{R}^{\\dot{p}\\times(K-1)}$ in the constraint set $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ and observed sample $i=1,\\hdots,n$ , $\\|\\mathbf{B}^{T}\\mathbf{x}_{i}\\|\\leq M$ . Consequently, there exist constants $0<\\alpha^{-}\\leq\\alpha^{+}\\leq1/4$ such that $\\alpha^{-}\\leq p_{i}(1-p_{i})\\leq\\alpha^{+}$ for all $i$ . ", "page_idx": 5}, {"type": "text", "text": "With our hard $L_{1}$ -norm constraint on the model parameter $\\mathbf{B}$ , Assumption 3.2 can be easily verified whenever the covariate vectors $\\mathbf{x}_{i}$ are uniformly bounded, which is a standard in the literature. ", "page_idx": 5}, {"type": "text", "text": "We establish the convergence rate of Algorithm 1 for ITR-Learning with stepsizes that are fixed but sufficiently small and diminishing rate. An informal statement is given in Theorem 3.3 below, and a full statement is provided in Theorem E.1 in the appendix. Define ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mu:={\\binom{\\lambda^{-}+\\lambda_{2}}{\\alpha^{-}\\lambda^{-}+\\lambda_{2}}}\\quad L:={\\binom{\\lambda^{+}+\\lambda_{2}}{\\alpha^{+}\\lambda^{+}+\\lambda_{2}}}\\quad{\\mathrm{for~continuous~outcome}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We say a function $f:\\mathbb{R}^{p}\\rightarrow\\mathbb{R}$ is $\\mu$ -strongly convex if $\\textstyle f(x)-{\\frac{\\mu}{2}}\\|x\\|^{2}$ is convex and $L$ -smooth if $f$ is differentiable and $\\nabla f$ is $L$ -Lipschitz continuous. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.3 (Convergence rate of PGD for ITR-Learning). Let $(\\mathbf{B}_{t})_{t\\geq0}$ denote the sequence of parameters obtained by the PGD algorithm (7) for ITR-Learning problem (6) with arbitrary initialization $\\mathbf{B}_{0}$ . Suppose Assumptions 3.1 and 3.2 hold. Let $\\mathbf{B}^{\\star}$ denote the unique global optimum of (6). Then the following hold: ", "page_idx": 5}, {"type": "text", "text": "(i) (Optimization landscape) The ITR objective ${\\mathcal{L}}(\\mathbf{B})$ in (6), is $\\mu$ -strongly convex and $L$ -smooth, where $\\mu,L$ are as in (10). ", "page_idx": 5}, {"type": "text", "text": "(ii) (Linear convergence with fixed stepsize) Assume constant stepsize $\\alpha_{t}\\equiv\\alpha<2/L$ . Denote the contraction constant $\\rho(\\alpha):=\\operatorname*{max}\\{|1-\\alpha L|,|1-\\alpha\\mu|\\}\\in(0,1)$ . Then $\\|\\mathbf{B}_{t}-\\mathbf{B}^{\\star}\\|_{F}^{2}\\leq$ $\\rho(\\alpha)^{t}\\|\\mathbf{B}_{0}-\\mathbf{B}^{\\star}\\|_{F}^{2}$ for all $t\\geq1$ . ", "page_idx": 5}, {"type": "text", "text": "(iii) (Sublinear convergence with diminishing stepsize) Assume diminishing stepsize $\\begin{array}{r}{\\alpha_{t}=\\frac{\\beta}{\\gamma+t}}\\end{array}$ , where $\\beta=\\beta(\\mu,L)>0$ is a sufficiently large constant and $\\gamma>0$ is an arbitrary constant. Then $\\begin{array}{r}{\\|\\mathbf{B}_{t}-\\mathbf{B}^{\\star}\\|^{2}\\leq\\frac{\\nu}{\\gamma+t}}\\end{array}$ for all $t\\geq1$ for some constant $\\nu>0$ . ", "page_idx": 5}, {"type": "text", "text": "Our algorithm 1 with soft $L_{2}$ -penalization and hard constraint with $L_{1}$ -ball is guaranteed to converge to the true solution $\\mathbf{B}^{\\star}$ exponentially fast provided stepsizes $\\alpha_{t}$ are fixed and sufficiently small. ", "page_idx": 5}, {"type": "text", "text": "3.2 Statistical Guarantees ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Next, we introduce generative models for the ITR estimation problem, for which we will establish statistical estimation guarantees in Theorem 3.5. Fix a joint distribution $\\pi$ for the pair $(\\mathbf{X},A)$ of covariates $\\mathbf{X}\\in\\mathbb{R}^{p}$ and treatment $A\\in\\{1,\\ldots,K\\}$ . Fix a true parameter $\\mathbf{B}_{\\star}\\in\\mathbb{R}^{p\\times(K-1)}$ . Then we assume $n$ i.i.d. samples $\\left(\\mathbf{x}_{i},a_{i},y_{i}\\right)$ are drawn as $(\\mathbf{x}_{i},a_{i})\\sim\\pi$ and ", "page_idx": 5}, {"type": "equation", "text": "$$\ny_{i}|(\\mathbf{x}_{i},a_{i})\\sim\\left\\{\\begin{array}{l l}{N\\left(\\frac{K-1}{K}z_{i},\\sigma^{2}\\right)}&{\\mathrm{~for~continuous~outcome}}\\\\ {\\mathbf{Ber}\\left(\\frac{\\exp(z_{i})}{1+\\exp(z_{i})}\\right)}&{\\mathrm{~for~binary~outcome}}\\end{array}\\right.,\\quad\\mathrm{where}~z_{i}:=\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}_{\\star}^{T}\\mathbf{x}_{i},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $N(\\mu,\\sigma^{2})$ denotes a normal distribution with mean $\\mu$ and variance $\\sigma^{2}$ , whereas $\\mathbf{Ber}(p)$ denotes a Bernoulli distribution with mean $p$ . We assume that $\\pi$ does not depend on $\\mathbf{B}_{\\star}$ and the noise variance $\\sigma^{2}$ for the continuous case is known. We then seek to estimate the true parameter $\\mathbf{B}_{\\star}$ from the observed samples. It is easy to check that the negative log-likelihood function (up to additive constants) coincides with the per-sample loss function $\\ell$ in (4). Therefore, the weighted convex optimization problem (3) corresponds to weighted MLE under the generative models in (11) (see Section H in the appendix for details). ", "page_idx": 5}, {"type": "text", "text": "We assume that the weighted gradient of the per-sample loss $\\ell$ in (4) has uniformly bounded third moments for our statistical analysis of the generative ITR model above. ", "page_idx": 5}, {"type": "text", "text": "Assumption 3.4 (Bounded moments at $\\mathbf{B}_{\\star}$ and weights). Suppose $\\left(\\mathbf{x}_{i},a_{i},y_{i}\\right)$ follows the generative model above. Denote $U_{i}\\,:=\\,w_{i}\\nabla_{\\mathbf{B}}\\ell(y_{i},\\mathbf{x}_{i},a_{i};\\mathbf{B}_{\\star})\\,\\in\\,\\mathbb{R}^{p\\times(K-1)}$ for $w_{i}\\;:=\\;w(a_{i},{\\bf x}_{i})$ and $\\overline{{U}}_{i}:=U_{i}-\\mathbb{E}[U_{i}]$ . Suppose there are constants $D_{1},d_{1}\\,\\in\\,(0,\\infty)$ such that $\\mathbb{E}[\\|\\overline{{U}}_{i}\\|_{F}^{3}]\\,<\\,D_{1}$ and $\\operatorname*{min}_{k,l}\\operatorname{Var}(\\overline{{U}}_{i}(k,l))>d_{1}$ . Also, $\\begin{array}{r}{\\sum_{i=1}^{n}w_{i}^{3}/\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}=O(n^{-1/2})}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "Now we state our main result regarding the statistical estimation guarantee for the true generative model parameter $\\mathbf{B}_{\\star}$ . With high probability, Algorithm 1 can recover $\\mathbf{B}_{\\star}$ up to a statistical error $O(n^{-1/2})$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.5 (Statistical estimation guarantee). Let $(\\mathbf{x}_{i},a_{i},y_{i})_{i=1}^{n}$ be i.i.d. observations from the generative models in (11) with true parameter $\\mathbf{B}_{\\star}\\,\\in\\,\\mathbb{R}^{p\\times(K-1)}$ such that $\\|\\mathbf{B}_{\\star}\\|_{1}\\leq\\lambda_{1}$ for some $\\lambda_{1}\\geq0$ . Suppose Assumptions 3.1, 3.2, and 3.4 hold. Let $\\widehat{\\bf B}_{T}$ denote the weighted MLE obtained after $T$ iterations of PGD algorithm (7) for (3). Fix a const ant $\\varepsilon>0$ . ", "page_idx": 6}, {"type": "text", "text": "Then there exists a constant $C=C(\\varepsilon)>0$ such that with probability at least $1-\\varepsilon$ and for $\\mu$ as in (10) but with $\\lambda^{\\pm}=\\lambda^{\\pm}(\\mathbb{E}[\\Psi])$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\|\\mathbf{B}_{\\star}-\\widehat{\\mathbf{B}}_{T}\\|_{F}\\leq\\frac{C\\sqrt{(p/n)\\log\\epsilon^{-1}}}{\\mu}+\\frac{8\\lambda_{2}\\|\\mathbf{B}_{\\star}\\|_{F}}{\\mu},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "provided $n,T$ are large enough. More specifically, the above holds when (i) (Sample complexity) $n\\geq1$ large s.t. $\\frac{(\\sum_{i=1}^{n}w_{i}^{2})^{3}}{(\\sum_{i=1}^{n}w_{i}^{3})^{2}}\\geq C_{1}\\varepsilon^{-2}$ for some explicit constant $C_{1}>0$ ; ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "(ii) (Computational complexity) $T=O(\\log n)$ and $O(n^{-1})$ when constant or diminishing stepsize as in Theorem 3.3 is used, respectively. ", "page_idx": 6}, {"type": "text", "text": "Furthermore, we get $\\sqrt{n}$ -consistent estimation whenever $\\lambda_{2}=O(n^{-1/2}\\lVert\\mathbf{B}_{\\star}\\rVert_{F}^{-1})$ . ", "page_idx": 6}, {"type": "text", "text": "Notice that both terms in the error bound (12) are proportional to $1/\\mu$ , which depends both on the minimum eigenvalue $\\lambda^{-}$ of $\\mathbb{E}[\\Psi]$ as well as the $L_{2}$ -regularization parameter $\\lambda_{2}$ . Therefore, choosing the weighting function $\\omega(A,\\mathbf{\\bar{X}})$ to maximize $\\lambda^{-}$ helps minimize the overall statistical estimation error. (Detailed analysis and discussion on this point can be found in the appendix H.) Another easy way to increase $\\mu$ is to use large $L_{2}$ -regularization, but as in the second term in (12), using $L_{2}$ -regularization gives estimation bias of $O\\bar{(\\lambda_{2}||\\mathbf{B}_{\\star}||_{F}/\\mu)}$ . Hence, we nee\u221ad to choose $\\lambda_{2}$ is small enough so that this bias term is also of $O(n^{-1/2})$ . Then we obtain an overall $\\sqrt{n}$ -consistent estimator. ", "page_idx": 6}, {"type": "text", "text": "The key insight in our proof of Theorem 3.5 is that we can decompose the total estimation error $\\lVert\\mathbf{B}_{\\star}-\\widehat{\\mathbf{B}}_{T}\\rVert_{F}$ into computational and statistical parts: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\|\\mathbf{B}_{\\star}-\\widehat{\\mathbf{B}}_{T}\\|_{F}\\leq\\underbrace{\\|\\widehat{\\mathbf{B}}-\\widehat{\\mathbf{B}}_{T}\\|_{F}}_{\\mathrm{computational~error}}+\\underbrace{\\|\\mathbf{B}_{\\star}-\\widehat{\\mathbf{B}}\\|_{F}}_{\\mathrm{statistical~error}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\widehat{\\bf B}$ denotes the exact MLE. The computational error vanishes as the number $T$ of PGD iterations tends t o infinity according to Theorem 3.3. For the statistical error, we show ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\|\\mathbf{B}_{\\star}-\\widehat{\\mathbf{B}}\\|_{F}\\leq\\frac{2C}{\\sqrt{n}}+\\frac{8\\lambda_{2}\\|\\mathbf{B}_{\\star}\\|_{F}}{\\mu}\\right)\\geq1-O\\left(\\frac{\\sum_{i=1}^{n}w_{i}^{3}}{\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Thus, the \u2018skewness\u2019 of the weights $w_{i}$ measured by the ratio $\\begin{array}{r}{\\sqrt{n}\\sum_{i=1}^{n}w_{i}^{3}/\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\end{array}$ (which arises from Berry-Esseen bound) acts as a scalar multiple to the standard statistical error of $O(n^{-1/2})$ per the central limit theorem. Hence, more balanced weights lead to fewer statistical estimation errors. If this skewness ratio is uniformly bounded, we can ensure a small statistical error with probability at least $1-\\varepsilon$ , provided we have at least $O(\\varepsilon^{-2})$ samples. Then, we simp\u221aly need to ensure the PGD iteration $T$ is large enough so that the computational error is at most $C/\\bar{\\sqrt{n}}$ to achieve the high-probability total estimation error bound in Theorem 3.5. Another insight from the theorem is that maximizing $\\lambda_{\\operatorname*{min}}(\\mathbb{E}[\\Psi])$ promotes heterogeneous balancing weights $w_{i}$ , and we get increased sample complexity through the bound ((  iin==11  wwii3  ))2 \u2265C1\u03f5\u22122 (e.g., if wi \u22611, this is n \u2a86\u03f5\u22122, but if $w_{1}=n,w_{2}=\\cdot\\cdot\\cdot=w_{n}=0$ , this may not be satisfied for any $n$ ). ", "page_idx": 6}, {"type": "text", "text": "4 Simulation Studies ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We investigate four simulation settings, each designed to evaluate various factors influencing the performance of different ITR estimators. For each setting, we mimic a randomized trial (no-confounding) and an observational study (with confounding) as per [44]. We consider 4 treatments with sample sizes $n\\,=\\,200,600,1000$ , and covariate dimensions $p\\,=\\,20$ , 40, 60. The outcome $Y$ follows the model (1) with $\\epsilon|A,\\mathbf{X}\\sim N\\big(0,\\sigma^{2}(A,\\mathbf{X})\\big)$ . We evaluate method performance using accuracy (i.e., correct identification of the optimal treatment for each observation) and empirical value on a test dataset of $10,000$ observations. Each simulation setting is replicated independently 100 times. ", "page_idx": 7}, {"type": "text", "text": "In this section, we provide partial experiment results according to the proposed estimation framework in Section 2.2. Specifically, we focus on the results from two scenarios: one mimicking randomized trials with linear ITR as the optimal rule and the other mimicking observational studies with nonlinear ITR as the optimal rule for continuous outcome. Since our proposed method assumes linear treatment rule class, the latter involves a situation where our model\u2019s prespecified treatment rule class is misspecified. Specifically, we use following treatment-free effect function $\\mu({\\mathbf X})$ and interaction effect function $\\delta(\\mathbf{X})$ for each scenario: ", "page_idx": 7}, {"type": "text", "text": "1. Randomized Trial: Linear ITR as the true optimal ", "page_idx": 7}, {"type": "text", "text": "$\\mu(\\mathbf{X})=1+2X_{1}+2X_{2},$ \u03b4 $\\begin{array}{r}{\\langle\\mathbf{X}\\rangle=\\left\\{\\!\\!\\begin{array}{l}{0.75+1.5X_{1}+1.5X_{2}+1.5X_{3}+1.5X_{4},A=1;0.75+1.5X_{1}-1.5X_{2}-1.5X_{3}+1.5X_{4},\\!0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0..0.0.0.0.0.0..0.0.0.0..0.0.0.0..0.0.0..0.0.0..0.0.0..0.0.0..0.0.0..0.0.0..0.0.0..0.0.0..0.0.0..0.0.0.0..0.0.0.0..0.0.0.0..0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.00.0.0.0.0.00.0.0.0.00.0.0.00.0.0.00.0.00.0.00.0.00.0.00.0.00.00.0.00.00.0.00.00.00.0.00.00.00.00.00.0.00.$ 4, A = 2; 4, A = 4, ", "page_idx": 7}, {"type": "text", "text": "2. Observational Study: Nonlinear ITR as the true optimal ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mu({\\bf X})=1+2X_{1}+2X_{2}+2X_{4}-2X_{4}^{2}+2X_{1}X_{2}+2e^{-X_{1}X_{2}}+\\sin(X_{3}),}\\\\ &{\\delta({\\bf X})=\\left\\{\\begin{array}{l l}{0.5+1.0X_{1}-2.0X_{4}+0.5X_{4}^{2},A=1;~1.0+1.0X_{1}+1.0X_{4}-1.0X_{4}^{2},}\\\\ {1.5+2.0X_{1}-1.0X_{4}-1.0X_{4}^{2},A=3;~1.0-1.0X_{1}-1.0X_{4}-1.0X_{4}^{2},}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "in the working model (1). Further details about simulation settings, other scenarios, and corresponding results are available in the appendix I. ", "page_idx": 7}, {"type": "image", "img_path": "G7L65B2P0y/tmp/c2873e00ef6a5375ca4f6fce8a7e54f5b9a19c900ac6ee9ba46b71dba7970a25.jpg", "img_caption": ["Figure 1: Accuracy Comparison: proposed methods vs. benchmark methods. All subplots in the same row share the same simulation setting, focusing on randomized trials with linear ITR as the true optimal rule (top) and observational studies with nonlinear ITR as the true optimal rule (bottom). Each subplot presents (Left) accuracy comparisons based on weights, illustrating the difference between the standard IPW approach of AD-Learning with the proposed approach using EBW, (Middle) accuracy comparisons based on optimization algorithms, illustrating the difference between the standard $L_{1}$ -penalized approach against the proposed constrained optimization with PGD, (Right) evaluation of accuracies between existing standard approaches and the proposed method, which integrates EBWs, variance and dimension reduction techniques implemented through PGD. Error bars represent the standard errors of the mean (SEM) of accuracies across multiple simulations. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Using Distributional Covariate Balancing Weights. In the left subplots of Figure 1, the incorporation of DCBWs (e.g., EBWs) shows improvements in classification rates for ITR-Learning. While EBWs indeed provide more effective balancing weights in observational studies, as depicted in the lower left subplot in Figure 1, it also results in improvements even in randomized trial settings where the true propensity score is known. This is achieved by reducing finite sample imbalances, as shown in the upper left subplot in Figure 1. Moreover, when the underlying true treatment rule class is nonlinear, the performance of AD-Learning suffers due to a misalignment between the assumed linear treatment rule class and the actual class. In this scenario, using EBWs yields accuracy improvements compared to the conventional IPW approach. Further details can be found in the appendix I. ", "page_idx": 8}, {"type": "text", "text": "Using PGD for Constrained Optimization. The middle subplots of Figure 1 show accuracy comparisons between standard penalized approach and constrained optimization using PGD. Both optimization algorithms are based on the same proposed statistical approach, integrating EBWs with SABD-Learning, outcome augmentation, and additional variable screening. For solving the $L_{1}$ -penalized regression problems, the R package glmnet is a standard choice, which is based on cyclic coordinate descent with simulated-annealing-style hyperparameter tuning. However, glmnet does not handle hard $L_{1}$ -ball constraints required for our method. Therefore, to ensure a fair comparison, we directly implemented standard (projected) (sub)gradient descent to solve optimization problems for both penalized and constrained problems. In our experiment reported in Figure 1, we observe significant improvements using our PGD method, especially in the second scenario. One possible explanation for this improvement is that large penalization may yield a perturbed solution to the ITR problem. If the minimizer of the ITR problem lies on the boundary of the $L_{1}$ -ball, the solutions of constrained optimization and penalized optimization coincide. However, if the minimizer is the interior point of $L_{1}$ -ball, constrained optimization can find the exact solution, while the penalization may induce a perturbed solution. Furthermore, the trajectory of PGD for the constraint approach appears to be significantly more stable than that of the subgradient descent in the penalization approach (see Figure 2). ", "page_idx": 8}, {"type": "image", "img_path": "G7L65B2P0y/tmp/86f17e6909d103fa436401cade25d9edc32696a9c7f8d4c6387163750dfb3dc5.jpg", "img_caption": ["Figure 2: Comparison of Optimization Methods by $\\lambda_{1}$ . $\\lambda_{1}$ is $L_{1}$ -ball size of the constraint set in the constrained optimization and the regularization parameter with additional $L_{1}$ -regularization of the model parameter in the penalized regression, respectively. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Performance Evaluations between the Proposed Method and Benchmark Methods. In the right subplots of Figure 1, we evaluate accuracies by comparing benchmark methods to our proposed approach. The benchmarks include AD-Learning, SABD-Learning, a treatment-covariate interaction model with $L_{1}$ -regularization \u2018linear\u2019, and two popular tree-based methods:\u2018policytree\u2019 [47, 59] and double-machine learning-based \u2018causalDML\u2019 [10, 29]. Our proposed method integrates EBWs with SABD-Learning, outcome augmentation, and additional variable screening for variance and dimension reduction, implemented via PGD. However, causalDML requires a sufficiently large sample size, thereby making its evaluation unfeasible under a sample size of 200. Our numerical analysis provides evidence that our proposed approach outperforms existing methods in both scenarios. \u2018linear\u2019 performs well in the upper subplot, which simulates a randomized trial with a true optimal linear rule, as covariates are balanced and the model accurately captures the decision function. However, in the lower subplot, simulating an observational study with a nonlinear rule, the model performs poorly because it lacks balancing weights to address confounding and cannot fully capture nonlinear relationships. Further detailed analysis, including the effectiveness of additional techniques such as variable screening for performance improvement, is provided in the appendix I. ", "page_idx": 8}, {"type": "text", "text": "Additionally, our proposed method processes each dataset $\\mathrm{\\Deltap}=60$ , $\\mathtt{n}=1000)$ in an average of 4.40 seconds, compared to 2.01 seconds for the penalization method using glmnet in R. Other methods exhibit scalability challenges, with policytree averaging 12.02 seconds and causalDML taking 46.75 seconds. This demonstrates that computational efficiency is a notable advantage of our approach. ", "page_idx": 8}, {"type": "text", "text": "5 Applications ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We apply the proposed methods to two datasets from AIDS Clinical Trials Group (ACTG) 175 [21] and email marketing [22]. ACTG is a randomized trial for 2,139 patients with HIV infection who were randomly assigned to four different treatments. Twelve covariates including age and gender were used for the analysis. The outcome is the change in CD4 cell count from baseline to 20 weeks, where larger values are preferable. Email marketing dataset has 64,000 customers who were randomly chosen to receive an e-mail campaign among three different marketing methods. Eight covariates with historical customer attributes and their pairwise interactions were used. The outcome is whether customers visited the website in the following two weeks. The goal of the analysis using these two datasets is to find the best treatment/marketing methods based on individuals\u2019 attributes. Similar to [44], we randomly split the data into a training set of $\\{200,400,800,1000,1200\\}$ observations for the ACTG dataset and $\\{1000,3000,5000\\}$ observations for the email dataset. The remaining observations were used for test data with 10 iterations. We evaluate method performance using the empirical value function on a test dataset. The benchmarking methods include AD-Learning, SABD-Learning, and two tree-based methods (policytree [47] and causalDML [29]). However, causalDML requires a sufficiently large sample size, thereby making its evaluation unfeasible under a sample size of 200. For the binary outcome in Email dataset, SABD-Learning is not used, since the homoscedastic assumption is unnecessary for logistic regression. The results are shown in Table 1. ", "page_idx": 9}, {"type": "table", "img_path": "G7L65B2P0y/tmp/1ed36db3ca897ff447ea4a1b81a6e53d82a81755cc3612aa8aee783ceef0b101.jpg", "table_caption": ["Table 1: Average empirical value functions across different approaches for ACTG/Email datasets. Mean values with the corresponding standard errors of the mean (SEM) in parentheses are provided. The highest-performing methods are marked in bold. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Discussion and Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our method introduces a unified, robust framework for estimating ITR. By formulating the problem as a weighted, constrained optimization problem, we incorporate DCBWs to control confounding and propose the PGD algorithm for sparse ITRs with computational and statistical guarantees. Additionally, we propose variable screening and efficient augmentation, which together show synergistic effects. We demonstrate our method with continuous and binary outcomes, and it can be readily extended to other outcomes, such as censored outcomes. Although we focus on learning linear ITR to facilitate the demonstration of our idea, it can be extended to nonlinear ITR using the basis function [34]. For example, by taking the covariate powers up to M, the linear function class becomes the class of degree-M polynomial functions. The linear function class can also serve as a useful approximation to nonlinear decision functions. ", "page_idx": 9}, {"type": "text", "text": "We acknowledge that although most, if not all, types of ITR-Learning frameworks can benefit from using DCBWs, variable screening, and augmentation, our proposed framework for theoretical analysis relies on the specific assumption that the model can be formulated as a constrained, weighted, and convex optimization problem. Furthermore, we restricted the decision function to the linear function class. Generalizing our theoretical analysis to include nonlinear function classes with nonconvex problems, such as boosting or deep neural networks, is an interesting direction for future investigation. Another limitation of our method is its reliance on standard assumptions to identify optimal ITRs using observational data, including the assumption of no unmeasured confounding. An interesting future direction would be to extend our framework to cases where this assumption does not hold, utilizing instrumental variables [12, 38] and proximal causal learning [40, 45]. ", "page_idx": 9}, {"type": "text", "text": "Our work significantly impacts society by improving patient health outcomes through personalized care and advancing medical research in disease mechanisms and drug development. Beyond healthcare, these methods can be applied in marketing strategies based on customer characteristics. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Lee J and Chen G\u2019s efforts were partially supported by NSF Grant DMS-2054346. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta, Ricardo Henao, Fan Li, and Lawrence Carin. Counterfactual representation learning with balancing weights. In International Conference on Artificial Intelligence and Statistics, pages 1972\u20131980. PMLR, 2021. [2] Susan Athey and Stefan Wager. Policy learning with observational data. Econometrica, 89(1):133\u2013161, 2021. [3] Laura B Balzer, Maya L Petersen, Mark J van der Laan, and Search Collaboration. Targeted estimation and inference for the sample average treatment effect in trials with and without pair-matching. Statistics in medicine, 35(21):3717\u20133732, 2016.   \n[4] L\u00e9on Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT\u20192010, pages 177\u2013186. Springer, 2010. [5] Stephen Boyd, Stephen P Boyd, and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004. [6] Stephen Boyd, Lin Xiao, and Almir Mutapcic. Subgradient methods. lecture notes of EE392o, Stanford University, Autumn Quarter, 2004(01), 2003.   \n[7] Guanhua Chen, Donglin Zeng, and Michael R Kosorok. Personalized dose finding using outcome weighted learning. J. Amer. Statist. Assoc., 111(516):1509\u20131521, 2016. [8] Rui Chen, Jared D Huling, Guanhua Chen, and Menggang Yu. Robust sample weighting to facilitate individualized treatment rule learning for a target population. Biometrika, 111(1):309\u2013 329, 2024. [9] Shuai Chen, Lu Tian, Tianxi Cai, and Menggang Yu. A general statistical framework for subgroup identification and comparative treatment scoring. Biometrics, 73(4):1199\u20131209, 2017.   \n[10] Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, and Whitney Newey. Double/debiased/neyman machine learning of treatment effects. Am. Econ. Rev., 107(5):261\u201365, 2017.   \n[11] Francis S Collins and Harold Varmus. A new initiative on precision medicine. New England journal of medicine, 372(9):793\u2013795, 2015.   \n[12] Yifan Cui and Eric Tchetgen Tchetgen. A semiparametric instrumental variable approach to optimal treatment regimes under endogeneity. Journal of the American Statistical Association, 116(533):162\u2013173, 2021.   \n[13] Alicia Curth and Mihaela van der Schaar. Nonparametric estimation of heterogeneous treatment effects: From theory to learning algorithms. In International Conference on Artificial Intelligence and Statistics, pages 1810\u20131818. PMLR, 2021.   \n[14] John Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra. Efficient projections onto the l 1-ball for learning in high dimensions. In Proceedings of the 25th international conference on Machine learning, pages 272\u2013279, 2008.   \n[15] Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American statistical Association, 96(456):1348\u20131360, 2001.   \n[16] Jianqing Fan and Jinchi Lv. Sure independence screening for ultrahigh dimensional feature space. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70(5):849\u2013911, 2008.   \n[17] William Feller. An introduction to probability theory and its applications, Volume 2, volume 81. John Wiley & Sons, 1991.   \n[18] Jean-Louis Goffin. On convergence rates of subgradient optimization methods. Mathematical programming, 13:329\u2013347, 1977.   \n[19] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Sch\u00f6lkopf, and Alexander Smola. A kernel two-sample test. The Journal of Machine Learning Research, 13(1):723\u2013773, 2012.   \n[20] Jens Hainmueller. Entropy balancing for causal effects: A multivariate reweighting method to produce balanced samples in observational studies. Political analysis, 20(1):25\u201346, 2012.   \n[21] Scott M Hammer, David A Katzenstein, Michael D Hughes, Holly Gundacker, Robert T Schooley, Richard H Haubrich, W Keith Henry, Michael M Lederman, John P Phair, Manette Niu, et al. A trial comparing nucleoside monotherapy with combination therapy in hiv-infected adults with cd4 cell counts from 200 to 500 per cubic millimeter. New England Journal of Medicine, 335(15):1081\u20131090, 1996.   \n[22] Kevin Hillstrom. Minethatdata e-mail analytics and data mining challenge. https://www. uplift-modeling.com/en/v0.3.1/api/datasets/fetch_hillstrom.html, 2008. Accessed: 2024-04-28.   \n[23] Jared D Huling, Noah Greifer, and Guanhua Chen. Independence weights for causal inference with continuous treatments. Journal of the American Statistical Association, 119(546):1657\u2013 1670, 2024.   \n[24] Jared D Huling and Simon Mak. Energy balancing of covariate distributions. Journal of Causal Inference, 12(1):20220029, 2024.   \n[25] Kosuke Imai and Marc Ratkovic. Covariate balancing propensity score. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(1):243\u2013263, 2014.   \n[26] Nathan Kallus. Balanced policy evaluation and learning. Advances in neural information processing systems, 31, 2018.   \n[27] Nathan Kallus. Generalized optimal matching methods for causal inference. The Journal of Machine Learning Research, 21(1):2300\u20132353, 2020.   \n[28] Nathan Kallus. More efficient policy learning via optimal retargeting. Journal of the American Statistical Association, 116(534):646\u2013658, 2021.   \n[29] Michael C Knaus. Double machine learning-based programme evaluation under unconfoundedness. The Econometrics Journal, 25(3):602\u2013627, 2022.   \n[30] Brian K Lee, Justin Lessler, and Elizabeth A Stuart. Weight trimming and propensity score weighting. PloS one, 6(3):e18174, 2011.   \n[31] Fan Li, Kari Lock Morgan, and Alan M Zaslavsky. Balancing covariates via propensity score weighting. Journal of the American Statistical Association, 113(521):390\u2013400, 2018.   \n[32] Runze Li, Wei Zhong, and Liping Zhu. Feature screening via distance correlation learning. Journal of the American Statistical Association, 107(499):1129\u20131139, 2012.   \n[33] Haixu Ma, Donglin Zeng, and Yufeng Liu. Learning individualized treatment rules with many treatments: A supervised clustering approach using adaptive fusion. Advances in Neural Information Processing Systems, 35:15956\u201315969, 2022.   \n[34] Jacob M Maronge, Jared D Huling, and Guanhua Chen. A reluctant additive model framework for interpretable nonlinear individualized treatment rules. The Annals of Applied Statistics, 17(4):3384\u20133402, 2023.   \n[35] Weibin Mo and Yufeng Liu. Efficient learning of optimal individualized treatment rules for heteroscedastic or misspecified treatment-free effect models. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(2):440\u2013472, 2022.   \n[36] Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment effects. Biometrika, 108(2):299\u2013319, 2021.   \n[37] Wenliang Pan, Xueqin Wang, Heping Zhang, Hongtu Zhu, and Jin Zhu. Ball covariance: A generic measure of dependence in banach space. Journal of the American Statistical Association, 115(529):307\u2013317, 2019.   \n[38] Hongming Pu and Bo Zhang. Estimating optimal treatment rules with an instrumental variable: A partial identification learning approach. Journal of the Royal Statistical Society Series B: Statistical Methodology, 83(2):318\u2013345, 2021.   \n[39] Zhengling Qi, Dacheng Liu, Haoda Fu, and Yufeng Liu. Multi-armed angle-based direct learning for estimating optimal individualized treatment rules with various outcomes. Journal of the American Statistical Association, 115(530):678\u2013691, 2020.   \n[40] Zhengling Qi, Rui Miao, and Xiaoke Zhang. Proximal learning for individualized treatment regimes under unmeasured confounding. Journal of the American Statistical Association, pages 1\u201314, 2023.   \n[41] Min Qian and Susan A Murphy. Performance guarantees for individualized treatment rules. Annals of statistics, 39(2):1180, 2011.   \n[42] Brian C Ross. Mutual information between discrete and continuous data sets. PloS one, 9(2):e87357, 2014.   \n[43] Donald B Rubin. Randomization analysis of experimental data: The fisher randomization test comment. Journal of the American statistical association, 75(371):591\u2013593, 1980.   \n[44] Kushal S Shah, Haoda Fu, and Michael R Kosorok. Stabilized direct learning for efficient estimation of individualized treatment rules. Biometrics, 2022. doi: 10.1111/biom.13818.   \n[45] Tao Shen and Yifan Cui. Optimal treatment regimes for proximal causal learning. Advances in Neural Information Processing Systems, 36, 2024.   \n[46] Claudia Shi, David Blei, and Victor Veitch. Adapting neural networks for the estimation of treatment effects. Advances in neural information processing systems, 32, 2019.   \n[47] Erik Sverdrup, Ayush Kanodia, Zhengyuan Zhou, Susan Athey, and Stefan Wager. policytree: Policy learning via doubly robust empirical welfare maximization over trees. Journal of Open Source Software, 5(50):2232, 2020.   \n[48] G\u00e1bor J Sz\u00e9kely, Maria L Rizzo, and Nail K Bakirov. Measuring and testing dependence by correlation of distances. The Annals of Statistics, 35(6):2769\u20132794, 2007.   \n[49] Dingke Tang, Dehan Kong, Wenliang Pan, and Linbo Wang. Ultra-high dimensional variable selection for doubly robust causal inference. Biometrics, 79(2):903\u2013914, 2023.   \n[50] Lu Tian, Ash A Alizadeh, Andrew J Gentles, and Robert Tibshirani. A simple method for estimating interactions between a treatment and a large number of covariates. Journal of the American Statistical Association, 109(508):1517\u20131532, 2014.   \n[51] Roman Vershynin. High-dimensional probability: An introduction with applications in data science, volume 47. Cambridge university press, 2018.   \n[52] C\u00e9dric Villani et al. Optimal transport: old and new, volume 338. Springer, 2009.   \n[53] Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 113(523):1228\u20131242, 2018.   \n[54] Baqun Zhang, Anastasios A Tsiatis, Eric B Laber, and Marie Davidian. A robust method for estimating optimal treatment regimes. Biometrics, 68(4):1010\u20131018, 2012.   \n[55] Chong Zhang and Yufeng Liu. Multicategory angle-based large-margin classification. Biometrika, 101(3):625\u2013640, 2014.   \n[56] Qingyuan Zhao, Dylan S Small, and Ashkan Ertefaie. Selective inference for effect modification via the lasso. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(2):382\u2013413, 2022.   \n[57] Yingqi Zhao, Donglin Zeng, A John Rush, and Michael R Kosorok. Estimating individualized treatment rules using outcome weighted learning. Journal of the American Statistical Association, 107(499):1106\u20131118, 2012.   \n[58] Xin Zhou, Nicole Mayer-Hamblett, Umer Khan, and Michael R Kosorok. Residual weighted learning for estimating individualized treatment rules. Journal of the American Statistical Association, 112(517):169\u2013187, 2017.   \n[59] Zhengyuan Zhou, Susan Athey, and Stefan Wager. Offilne multi-action policy learning: Generalization and optimization. Operations Research, 71(1):148\u2013183, 2023.   \n[60] Ruoqing Zhu, Ying-Qi Zhao, Guanhua Chen, Shuangge Ma, and Hongyu Zhao. Greedy outcome weighted tree learning of optimal personalized treatment rules. Biometrics, 73(2):391\u2013400, 2017.   \n[61] Jos\u00e9 R Zubizarreta. Stable weights that balance covariates for estimation with incomplete outcome data. Journal of the American Statistical Association, 110(511):910\u2013922, 2015. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Preliminaries ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we review several notations and basic facts on linear algebra and matrix calculus. ", "page_idx": 14}, {"type": "text", "text": "The Kronecker product, denoted by $\\otimes$ , is a binary operation that combines two matrices to create a new matrix. Given two matrices $\\dot{\\mathbf{A}}=(a_{i j})\\in\\dot{\\mathbb{R}}^{m\\bar{\\times}n}$ and $\\mathbf{B}\\in\\mathbb{R}^{p\\times q}$ , then $\\mathbf{A}\\otimes\\mathbf{B}$ is an $m p\\times n q$ matrix defined as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbf{A}\\otimes\\mathbf{B}=\\left[\\begin{array}{c c c}{a_{11}\\mathbf{B}}&{\\cdots}&{a_{1n}\\mathbf{B}}\\\\ {\\vdots}&{\\ddots}&{\\vdots}\\\\ {a_{m1}\\mathbf{B}}&{\\cdots}&{a_{m n}\\mathbf{B}}\\end{array}\\right]\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "If $\\mathbf{A}^{\\prime}\\in\\mathbb{R}^{m\\times n^{\\prime}}$ , then for the horizontally stacked matrix $[\\mathbf{A},\\mathbf{A}^{\\prime}]\\in\\mathbb{R}^{m\\times(n+n^{\\prime})}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n[\\mathbf{A},\\mathbf{A}^{\\prime}]\\otimes\\mathbf{B}=[\\mathbf{A}\\otimes\\mathbf{B},\\mathbf{A}^{\\prime}\\otimes\\mathbf{B}].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For each $\\mathbf{A}=[\\mathbf{a}_{1},\\dots,\\mathbf{a}_{n}]\\in\\mathbb{R}^{m\\times n}$ , let $\\mathrm{vec}(\\mathbf{A}):=[\\mathbf{a}_{1}^{T},\\ldots,\\mathbf{a}_{n}^{T}]^{T}\\in\\mathbb{R}^{m n}$ denote its vectorization. The commutation matrix $\\mathbf{C}^{(a,b)}$ , which is a special instance of $a b\\times a b$ permutation matrix. Namely, for each integers $a,b\\;\\geq\\;1$ , there exists a unique matrix $\\mathbf{C}^{(a,b)}~\\in~\\{0,1\\}^{a b\\times a b}$ such that for all $\\textbf{A}\\in\\mathbb{R}^{a\\times b}$ , we have $\\mathbf{C}^{(a,b)}\\operatorname{vec}(\\mathbf{A})\\,=\\,\\operatorname{vec}(\\mathbf{A}^{T})$ . Note that $(\\mathbf{C}^{(a,b)})^{T}\\,=\\,\\mathbf{C}^{(b,a)}$ . Furthermore, $(\\mathbf{C}^{(a,b)})^{T}\\mathbf{C}^{(a,b)}=\\mathbf{I}_{a b}$ since $(\\mathbf{C}^{(a,b)})^{T}\\mathbf{C}^{(a,b)}\\operatorname{vec}(\\mathbf{A})=\\mathbf{C}^{(b,a)}\\operatorname{vec}(\\mathbf{A}^{T})=\\operatorname{vec}(\\mathbf{A})$ . Hence $\\mathbf{C}^{(a,b)}$ is positive semi-definite. Note that $\\mathbf{C}^{(a,1)}\\,=\\,\\mathbf{I}_{a}\\,=\\,\\mathbf{C}^{(1,a)}$ since if $\\mathbf{A}\\,\\in\\,\\mathbb{R}^{a\\times1}$ or $\\textbf{A}\\in\\mathbb{R}^{1\\times a}$ , $\\mathrm{vec}(\\mathbf{A})=\\mathrm{vec}(\\mathbf{A}^{T})$ . Also, for every matrices $\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$ and $\\mathbf{B}\\in\\mathbb{R}^{r\\times q}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbf{C}^{(r,m)}(\\mathbf{A}\\otimes\\mathbf{B})=(\\mathbf{B}\\otimes\\mathbf{A})\\mathbf{C}^{(q,n)}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Also recall the relations for vectorizing product of matrices: for $\\textbf{A}\\in\\,\\mathbb{R}^{a\\times b}$ , $\\textbf{B}\\in\\mathbb{R}^{b\\times c}$ , and $\\mathbf{C}\\in\\mathbb{R}^{c\\times d}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{vec}(\\mathbf{A}\\mathbf{B})=(\\mathbf{I}_{c}\\otimes\\mathbf{A})\\,\\mathrm{vec}(\\mathbf{B})=(\\mathbf{B}^{T}\\otimes\\mathbf{I}_{a})\\,\\mathrm{vec}(\\mathbf{A}),\\qquad\\qquad}\\\\ {\\mathrm{vec}(\\mathbf{A}\\mathbf{B}\\mathbf{C})=(\\mathbf{C}^{T}\\otimes\\mathbf{A})\\,\\mathrm{vec}(\\mathbf{B})=(\\mathbf{I}_{d}\\otimes\\mathbf{A}\\mathbf{B})\\,\\mathrm{vec}(\\mathbf{C})=(\\mathbf{C}^{T}\\mathbf{B}^{T}\\otimes\\mathbf{I}_{a})\\,\\mathrm{vec}(\\mathbf{A}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For $\\mathbf{A},\\mathbf{B},\\mathbf{C}$ , and $\\mathbf{D}$ are matrices of compatible sizes allowing the matrix products AC and BD, ", "page_idx": 14}, {"type": "equation", "text": "$$\n(\\mathbf{A}\\otimes\\mathbf{B})(\\mathbf{C}\\otimes\\mathbf{D})=(\\mathbf{AC}\\otimes\\mathbf{BD}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Next, recall that if $f:\\mathbb{R}^{a\\times1}\\rightarrow\\mathbb{R}^{b\\times1}$ and $g:\\mathbb{R}^{b\\times1}\\rightarrow\\mathbb{R}^{c\\times1}$ are differentiable functions, then the Jacobian $J_{f}$ can be written by using gradients as $J_{f}(x)\\,=\\,\\left(\\nabla_{x}f^{T}\\right)^{T}$ . By chain rule $J_{g\\circ f}(x)=$ $J_{g}(f(x))J_{f}(x)$ , we have the following chain rule for gradients ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\nabla_{\\boldsymbol{x}}\\left(\\boldsymbol{g}(\\boldsymbol{f}(\\boldsymbol{x}))^{T}\\right)=\\nabla_{\\boldsymbol{x}}\\left(\\boldsymbol{f}(\\boldsymbol{x})^{T}\\right)\\nabla_{\\boldsymbol{f}(\\boldsymbol{x})}\\left(\\boldsymbol{g}(\\boldsymbol{f}(\\boldsymbol{x}))^{T}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We will also frequently use the following fact: For $\\mathbf{A}\\in\\mathbb{R}^{a\\times b}$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\nabla_{\\mathrm{vec}(\\mathbf{A})}\\,\\mathrm{vec}(\\mathbf{A})^{T}=\\mathbf{I}_{a b},}\\\\ &{\\nabla_{\\mathrm{vec}(\\mathbf{A})}\\,\\mathrm{vec}(\\mathbf{A}^{T})^{T}=\\nabla_{\\mathrm{vec}(\\mathbf{A})}\\,\\mathrm{vec}(\\mathbf{A})^{T}\\mathbf{C}^{(b,a)}=\\mathbf{C}^{(b,a)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For two matrices $\\mathbf{A},\\mathbf{B}$ of the same size, we write $\\mathbf A\\preceq\\mathbf B$ if ${\\bf B}-{\\bf A}$ is positive semi-definite. The partial ordering $\\preceq$ is called the Loewner ordering. ", "page_idx": 14}, {"type": "text", "text": "B Details of model setup ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.1 Details of angle-based approach ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Consider the working model given by Equation (1) in the main text: ", "page_idx": 15}, {"type": "equation", "text": "$$\nY=\\mu(\\mathbf{X})+\\sum_{k=1}^{K}\\delta_{k}(\\mathbf{X})\\mathbf{I}(A=k)+\\epsilon.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": ".o  Umnadkee rt thhei so pmtiomdaell ,I ednetitefriamblien, esw te hiem oppotsiem tahl eI cToRn sftorra iannt $\\begin{array}{r}{\\sum_{k=1}^{K}\\delta_{k}(\\mathbf{x})=0}\\end{array}$ ofvora railalt ec ,a rwiahtieles $\\mathbf{x}$ $\\delta_{k}({\\bf x})$ $\\mathbf{x}$ $\\mu({\\bf x})$ has no impact on the ITR. However, using $K$ functions with the sum-to-zero constraint can be computationally inefficient [55]. Instead, one can opt for simplex coding as an alternative, which inherently satisfies the sum-to-zero constraint. ", "page_idx": 15}, {"type": "text", "text": "In AD-Learning, proposed by [39], each of the $K$ treatments is represented as a vertex simplex on $\\mathbb{R}^{K-1}$ , denoted as $\\mathbf{u}_{k}$ , $k=1,\\ldots,K$ . In particular, $\\mathbf{u}_{k}$ is defined as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbf{u}_{k}={\\left\\{\\begin{array}{l l}{{\\frac{1}{\\sqrt{K-1}}}\\mathbf{1}_{K-1}}&{{\\mathrm{~if~}}k=1,}\\\\ {-{\\frac{1+{\\sqrt{K}}}{\\sqrt{(K-1)^{3}}}}\\mathbf{1}_{K-1}+{\\sqrt{{\\frac{K}{K-1}}}}\\mathbf{e}_{k-1}}&{{\\mathrm{~if~}}k\\geq2,}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where ${\\bf1}_{K-1}$ is a $K-1$ dimensional vector with entries 1, and $\\mathbf{e}_{k-1}$ is a $K-1$ dimensional vector with entries 0 except its $k$ -th entry being 1. This vertex simplex has $K$ vertices with equal angles between them and an origin at the center of the simplex. All $\\mathbf{u}_{k}$ have the same Euclidean norm 1. To estimate the optimal ITR, a decision function $\\hat{\\mathsf{I}}(\\mathbf{x})=(f_{1}(\\mathbf{x}),\\hdots,f_{K-1}(\\mathbf{x}))^{T}$ is constructed, assigning a $K-1$ dimensional vector to each covariate $\\mathbf{x}$ . Here, $\\mathbf{f}\\left(\\cdot\\right)$ can take a generic form, while we assume the linear decision function in the main text. The optimal ITR is reformulated by the authors as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\nd^{\\mathrm{opt}}(\\mathbf{x})=\\underset{k\\in\\{1,\\dots,K\\}}{\\arg\\operatorname*{max}}\\ \\mathbf{u}_{k}^{T}\\mathbf{f}(\\mathbf{x})=\\underset{k\\in\\{1,\\dots,K\\}}{\\arg\\operatorname*{min}}\\ \\angle(\\mathbf{u}_{k},\\mathbf{f}(\\mathbf{x})),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\angle(\\cdot,\\cdot)$ represents the angle between two vectors. Note that due to $\\begin{array}{r}{\\sum_{k=1}^{K}\\mathbf{u}_{k}\\ =\\ \\mathbf{0},}\\end{array}$ $\\begin{array}{r}{\\sum_{k=1}^{K}\\mathbf{u}_{k}^{T}\\mathbf{f}\\left(\\mathbf{x}\\right)=0}\\end{array}$ for any given function f and covariate value $\\mathbf{x}$ . Then we can u se ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left(\\sum_{k=1}^{K}\\mathbf{u}_{k}\\mathbf{I}(A=k)\\right)^{T}\\mathbf{f}(\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "instead of $\\begin{array}{r}{\\sum_{k=1}^{K}\\delta_{k}(\\mathbf{X})\\mathbf{I}(A=k)}\\end{array}$ to encode the treatment and covariate interaction. Specifically, we use $\\mathbf{u}_{A}$ to denote $\\begin{array}{r}{\\left(\\sum_{k=1}^{K}\\mathbf{u}_{k}\\mathbf{I}(A=k)\\right)^{T}}\\end{array}$ and assume $\\mathbf{f}\\left(\\mathbf{x}\\right)$ to be linear in $\\mathbf{x}$ (with the coefficient matrix $\\mathbf{B}$ ). Therefore, terms pertaining to ITRs can be expressed as $\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}$ . ", "page_idx": 15}, {"type": "text", "text": "B.2 Details of binary outcome ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Again, under prespecified treatment rule class $\\mathcal{D}$ , the optimal ITR is given by ", "page_idx": 15}, {"type": "equation", "text": "$$\nd^{\\mathrm{opt}}(\\mathbf{x})=\\operatorname*{arg\\,max}_{k\\in\\{1,\\ldots,K\\}}\\mathbb{E}[Y|\\mathbf{x},A=k]=\\operatornamewithlimits{a r g\\,m a x}_{k\\in\\{1,\\ldots,K\\}}\\underbrace{\\mathbf{u}_{k}^{T}\\,\\mathbb{E}\\left[\\frac{Y\\mathbf{u}}{\\pi(A,\\mathbf{x})}\\,\\Bigg|\\,\\mathbf{x}\\right]}_{=:\\mathrm{fop}(\\mathbf{x})}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For the binary response setting, we assume the following logistic model ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}[Y=1|\\mathbf{x},A=k]=\\frac{\\exp(\\mathbf{u}_{k}^{T}\\mathbf{f}_{\\mathrm{opt}}(\\mathbf{x}))}{1+\\exp(\\mathbf{u}_{k}^{T}\\mathbf{f}_{\\mathrm{opt}}(\\mathbf{x}))}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Under this model, $\\mathbf{f}_{\\mathrm{opt}}$ is indeed the optimal decision function under the angle-based direct learning framework since ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d^{\\mathrm{opt}}(\\mathbf{x})=\\underset{k\\in\\{1,\\dots,K\\}}{\\arg\\operatorname*{max}}~\\mathbb{P}[Y=1|\\mathbf{x},A=k]}\\\\ &{\\qquad\\quad=~\\underset{k\\in\\{1,\\dots,K\\}}{\\arg\\operatorname*{max}}~\\frac{\\exp(\\mathbf{u}_{k}^{T}\\mathbf{f}_{\\mathrm{opt}}(\\mathbf{x}))}{1+\\exp(\\mathbf{u}_{k}^{T}\\mathbf{f}_{\\mathrm{opt}}(\\mathbf{x}))}}\\\\ &{\\qquad\\quad=~\\underset{k\\in\\{1,\\dots,K\\}}{\\arg\\operatorname*{max}}~\\mathbf{u}_{k}^{T}\\mathbf{f}_{\\mathrm{opt}}(\\mathbf{x}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Furthermore, it can be checked that the function $\\mathbf{f}_{\\mathrm{opt}}$ is an optimal solution to maximizing the IPW-weighted log-likelihood of the logistic regression model: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\arg\\operatorname*{min}_{\\mathbf{f}}\\mathbb{E}\\left[-\\frac{Y\\mathbf{u}^{T}\\mathbf{f}}{\\pi(A,\\mathbf{x})}+\\frac{\\log(\\exp(\\mathbf{u}^{T}\\mathbf{f})+1)}{\\pi(A,\\mathbf{x})}\\right],\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "under the assumption that the expectation and derivative w.r.t. f can be exchanged ([39]). ", "page_idx": 16}, {"type": "text", "text": "For the effective and robust ITR estimation, replacing IPW with DCBW leads to ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\underset{\\mathbf{f}}{\\arg\\operatorname*{min}}\\mathbb{E}\\left[w(\\mathbf{x},A)\\left\\{-Y\\mathbf{u}^{T}\\mathbf{f}+\\log(\\exp(\\mathbf{u}^{T}\\mathbf{f})+1)\\right\\}\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Now consider restricting it to the linear decision function class ${\\mathcal{F}}\\,=\\,\\left\\{\\mathbf{f}(\\mathbf{X})\\,=\\,\\mathbf{B}^{T}\\mathbf{X}\\,:\\,\\mathbf{B}\\,\\in$ $\\mathbb{R}^{p\\times(K-1)}\\}$ . Then the above (25) becomes ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\underset{\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)}}{\\arg\\operatorname*{max}}\\left\\mathbb{E}\\left[w(\\mathbf{x},A)\\{Y\\mathbf{u}^{T}\\mathbf{B}^{T}\\mathbf{x}-\\log(\\exp(\\mathbf{u}^{T}\\mathbf{B}^{T}\\mathbf{x})+1)\\}\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then, we can estimate the optimal parameter $\\mathbf{B}$ by solving the following empirical loss minimization ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{arg\\,min}_{\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)}}\\frac{1}{n}\\sum_{i=1}^{n}w(\\mathbf{x}_{i},a_{i})\\left(-y_{i}\\mathbf{u}_{i}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}+\\log(\\exp(\\mathbf{u}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i})+1)\\right)\\quad\\mathrm{~s.t~}\\quad\\|\\mathbf{B}\\|_{1}\\leq z,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where we imposed additionally the $L_{1}$ -penalization $\\|\\mathbf{B}\\|_{1}\\leq z$ , on $\\mathbf{B}$ to promote a sparse solution.   \nBy the proposed algorithm 1, we can efficiently solve the problem (26). ", "page_idx": 16}, {"type": "text", "text": "C Details of proposed approaches ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "To keep the appendix as self-contained as possible, we provide descriptions of the building blocks of the proposed methods. ", "page_idx": 17}, {"type": "text", "text": "C.1 Use of distributional covariate balancing weights ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we provide the background about the use of DCBWs for constructing effective and robust ITRs. For additional details, please refer to the original papers. ", "page_idx": 17}, {"type": "text", "text": "Many existing ITR-Learning approaches such as AD-Learning and SABD-Learning use inverse probability (of treatment) weighting (IPW), which requires specifying a propensity score model for confounding control. However, propensity score methods have long been known to be highly sensitive to model misspecification, which yields biased estimates of causal effects [25, 30]. For this reason, methods that directly estimate weights based on balance-seeking objectives instead of using IPW have been proposed. These approaches include entropy balancing weights [20], stable balancing weights [61] as well as DCBWs [24, 27]. However, despite the weights serving a critical role in the estimation process, these advancements have mainly focused on improving average treatment effect (ATE) and are largely under-explored in the ITR literature. Significant improvements in the performance of ITRs are often left on the table when the weights are not treated with the same level of emphasis and focus as the other aspects of ITR learning. ", "page_idx": 17}, {"type": "text", "text": "To tackle these challenges, we propose the use of DCBWs, such as energy balancing weights (EBWs) [24] and maximum mean discrepancy (MMD) balancing weights [19, 27, 8], as an alternative to IPW for ITR-Learning. Unlike traditional approaches, these methods do not rely on any pre-specified functional forms for constructing weights. Instead, they focus on minimizing the distance of the weighted empirical distributions of covariates across treatment groups to reduce potential confounding. Even for data from randomized trials, they can help reduce finite sample covariate imbalance. The emphasis on finite sample balance and the model-independent nature of distributional weighting methods effectively mitigate biases due to model misspecification, resulting in more precise and reliable ITR estimation. ", "page_idx": 17}, {"type": "text", "text": "In the remainder of this section, we provide additional details about EBWs. The EBWs are derived from the concept of \u201cweighted energy distance\" which modifies the energy distance measure to allow for measurement of the distance between a weighted empirical distribution and a target empirical distribution. This measure captures the distance between a weighted empirical cumulative distribution function (ECDF) of covariates for a specific treatment group $a$ , denoted as $\\{\\mathbf{X}_{i}\\}_{i:A_{i}=a}$ , and the combined ECDF of covariates, denoted as $\\{{\\bf X}_{i}\\}_{i=1}^{n}$ . Specifically, the weighted energy distance is defined as: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\Sigma\\left(F_{n,a,{\\bf w}},F_{n}\\right)\\equiv\\frac{2}{n_{a}n}\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{i}{\\bf I}\\left(A_{i}=a\\right)\\left\\Vert{\\bf X}_{i}-{\\bf X}_{j}\\right\\Vert_{2}-\\frac{1}{n_{a}^{2}}\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{i}w_{j}{\\bf I}\\left(A_{i}=A_{j}=a\\right)\\left\\Vert{\\bf X}_{i}-{\\bf X}_{j}\\right\\Vert_{2}}}\\\\ {{\\displaystyle~~~~~~~~~~~~~~~~~~-\\frac{1}{n^{2}}\\sum_{i=1}^{n}\\sum_{j=1}^{n}\\left\\Vert{\\bf X}_{i}-{\\bf X}_{j}\\right\\Vert_{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\begin{array}{r}{n_{a}=\\sum_{i=1}^{n}\\mathbf{I}(A_{i}=a)}\\end{array}$ . The weighted energy distance measures the distance between the weighted distribution of covariates among those with $A_{i}\\;=\\;a$ and the empirical distribution of covariates in the full sample; it takes value 0 if and only if these two distributions are identical. ", "page_idx": 17}, {"type": "text", "text": "The optimal weights are obtained by minimizing the sum of all the weighted energy distances of all treatment groups: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{w}_{n}\\in\\operatorname*{argmin}_{\\mathbf{w}=\\left(w_{1},\\ldots,w_{n}\\right)}\\sum_{a\\in A}\\mathcal{E}\\left(F_{n,a,\\mathbf{w}},F_{n}\\right)\\;\\mathrm{s.t.}\\;\\sum_{i=1}^{n}w_{i}I\\left(A_{i}=a\\right)=n_{a}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, the EBWs encourage the distributions of covariates for each treatment group to look like that of the target population, i.e. the full sample. Since (27) is a quadratic objective function along with linear constraints, it can be efficiently solved through interior point methods. Another advantage lies in the fact that it does not require parameter tuning. The estimated weights are effective in balancing all covariates of the covariate distributions, not just limited to the first or second moments. Lastly, the data-driven characteristic of EBWs that do not rely on specific model assumptions contributes to more robust ITR estimates. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "C.2 Implementation of the PGD algorithm ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We provide Algorithm 1 to solve the problem (6) using a projected gradient descent (PGD). The algorithm applies to either continuous or binary outcomes. For the projection onto the $L_{1}$ -ball, we use the algorithm in [14]. ", "page_idx": 18}, {"type": "text", "text": "Algorithm 1 Projected Gradient Descent Algorithm to Estimate Decision Function for ITR-Learning Input: Data set $(\\mathbf{x}_{i},a_{i},y_{i})_{i=1}^{n}\\in\\mathbb{R}^{n\\times p}\\times\\{1,2,\\cdots,K\\}^{n}\\times\\mathbb{R}^{n}$ $\\complement y_{i}$ can be continuous or binary); loss function $L$ Parameters: $\\mathbf{B}\\,\\in\\,\\mathbb{R}^{p\\times(K-1)}$ (model coefficient), $z\\,\\geq\\,0$ ( $\\mathcal{L}_{1}$ -ball size); $\\lambda_{1}~\\ge~0$ (additional $L_{2}$ -penalization for $R({\\bf B})$ ); $T\\in\\mathbb N$ (number of iterations), $\\alpha_{t}\\geq0$ (stepsize). Constraints: $L_{1}$ -ball ${\\mathcal{B}}:=\\{{\\mathbf{B}}\\in\\mathbb{R}^{p\\times(K-1)}\\,|\\,\\|{\\mathbf{B}}\\|_{1}\\leq z\\}$ Compute $\\mathbf{x}_{i}^{*}:=\\mathbf{x}_{i}\\mathbf{u}_{a_{i}}^{T}$ for all $i=1,\\cdots,n$ for faster computation. Choose any point from $\\mathbf{B}_{0}\\in\\mathcal{B}$ as initialization. For $t=1,2,\\ldots,T$ do: $\\mathbf{B}_{t}\\leftarrow\\Pi_{\\mathcal{B}}\\Bigg(\\mathbf{B}_{t-1}-\\alpha_{t}\\nabla_{\\mathbf{B}}\\mathcal{L}\\big(\\mathbf{B}_{t-1}\\big)\\Bigg).$ End for Output: ${\\bf B}_{T}$ ", "page_idx": 18}, {"type": "text", "text": "To help the convenient implementation of the above PGD algorithm, we provide the gradient of the ITR objective below. For the continuous outcome, we have (see Proposition F.1) ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{B}}\\,\\mathcal{L}(\\mathbf{B})=\\frac{1}{n}\\sum_{i=1}^{n}\\omega(a_{i},\\mathbf{x}_{i})\\,\\left(\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}\\mathbf{B}\\mathbf{u}_{a_{i}}\\mathbf{u}_{a_{i}}^{T}-\\frac{K}{K-1}y_{i}\\mathbf{x}_{i}\\mathbf{u}_{a_{i}}^{T}\\right)+\\lambda_{2}\\mathbf{B}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For the binary outcome, we have (see Proposition F.2) ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{B}}\\,\\mathcal{L}(\\mathbf{B})=\\frac{1}{n}\\left(\\sum_{i=1}^{n}\\omega(a_{i},\\mathbf{x}_{i})\\left(\\frac{\\exp(\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i})}{1+\\exp(\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i})}-y_{i}\\right)\\mathbf{x}_{i}\\mathbf{u}_{a_{i}}^{T}\\right)+\\lambda_{2}\\mathbf{B}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C.3 Additional improvements by dimension reduction: variable screening procedure ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "High dimensional covariates can significantly affect the performance of methods for estimating weights, outcome regression models, and the final ITR. Specifically, using screened variables is beneficial in estimating outcome regression models by focusing on fewer variables that significantly impact the outcome. Additionally, estimating balancing weights based on effect modifiers rather than all variables provides more reliable weighting estimates. Hence, the screening approach serves to reduce bias and enhance the efficiency of ITR-Learning. ", "page_idx": 18}, {"type": "text", "text": "Several techniques have been developed to choose appropriate variables in causal inference. One popular approach in the ITR setting is the group-lasso method introduced in [33] which filters out variables that only affect the treatment-free effect. For the ATE estimation, sure independence screening (SIS) method [16, 32] is widely used, which involves an initial screening step based on Pearson correlations between each covariate and the outcome. The covariates are then ranked based on these correlations, and only the top-ranked ones are used in the downstream analysis. While one could also use similar variable screening methods in the ITR setting, the use of Pearson correlation may limit their effectiveness in capturing nonlinear relationships, potentially leading to biased estimates of the ITR. ", "page_idx": 18}, {"type": "text", "text": "To address this issue, alternative approaches that employ non-linear dependence tests are explored, including the ball covariance, mutual information test, and distance covariance [37, 42, 48]. Ball covariance, previously applied to variable selection in ATE estimation, has been found to be effective [49]. Distance covariance is another way to capture the nonlinear dependence between two random vectors/variables [48]. The test compares the observed distances between pairs of observations to the expected distances under the assumption of independence. A zero value of distance covariance indicates independence between two random vectors. If the observed distances are significantly far from the expected distances, it indicates statistical dependence between the random vectors. The $p$ -value is calculated by comparing the observed empirical distance with the distribution of the same test statistic obtained from random permutations of the data under the assumption of independence. We propose adapting the distance covariance due to its computational efficiency and empirical performance for the settings we explored. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Now, we introduce our proposed variable screening procedure. In a setting with $K$ treatments, we aim to find which covariates have conditional dependence on the outcome given the treatment. Doing so allows the identification of covariates that either modify the treatment effect or otherwise affect the outcome (i.e. are precision variables). To do so, for each covariate $X_{j}$ where $j\\in\\{1,\\ldots,p\\}$ , conduct the distance covariance test between covariate and outcome $K$ times, conditioning on each treatment value. This conditioning on the treatment creates subgroups based on treatment assignments, allowing the assessment of the dependence between the covariate and the outcome within each subgroup. Then we set the $p$ -value of the covariate $X_{j}$ as the minimum ${\\bf p}$ -value from these $K$ tests. This approach ensures that we retain as many relevant variables as possible during this preliminary variable screening stage. For the same reason, we avoid the use of multiple comparison adjustments such as Bonferroni correction. Instead, we opt to select variables with a significance level of $5\\%$ . We perform the same steps for all covariates in the dataset. These procedures are summarized in Algorithm 2. ", "page_idx": 19}, {"type": "table", "img_path": "G7L65B2P0y/tmp/d233ee0a22f7db031e1a44dae82ac67d7fb9ff3da2799ae83124806463943421.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "This conditional independence test is crucial to retain effect modifiers and precision variables while filtering out instrumental variables associated with treatment but not the outcome [49]. While acknowledging that the procedure is ad-hoc, the simulation results show that it effectively reduces the number of covariates to estimate covariate balancing weights and outcome regression models, which improves efficiency and helps avoid overfitting. ", "page_idx": 19}, {"type": "text", "text": "C.4 Additional improvements by variance reduction: combining inverse variance weighting with augmented outcome ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Our additional recommendation includes dually using both augmented outcomes and inverse variance weighting for variance reduction. Under our working model (1), the outcome can be explained by the sum of the treatment-free effects of covariates, the interaction effect between covariates and each treatment, and random noise. As the interaction effect alone determines optimal treatment assignments, the treatment-free effect acts as extra noise. This noise can be mitigated using outcome model augmentation. One way to implement outcome augmentation is to use the augmented outcomes $\\check{Y}:=Y-\\widehat{\\mu}(\\mathbf{X})$ in place of the original outcomes for continuous outcomes when applying an ITR estimation method. Flexible techniques such as random forest and neural networks can be utilized to estimate the treatment-free effect. This is the first implementation for multi-category treatments with DCBWs, whereas previous work focused on binary treatments with IPW [44]. ", "page_idx": 19}, {"type": "text", "text": "Augmented outcomes can refine ITR estimates when correctly specified. Yet, misspecification of either outcome or treatment-free effect models can lead to heteroscedastic errors due to residual treatment-free effects. This is where SABD-Learning\u2019s inverse variance weighting helps, providing robustness against misspecification. SABD-Learning extends AD-Learning designed for homoscedasticity [39] to account for heteroscedasticity, i.e. when the conditional variance of the (potential) outcome given the covariates is not constant [44]. This method estimates the conditional variance of outcomes and reweights the final objective function by adjusting each sample\u2019s contribution based on the inverse of the estimated variance. Therefore, we propose to combine outcome augmentation and inverse variance weighting for robust and efficient ITR learning, as they are complementary methods. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "The key idea behind outcome augmentation is to add an asymptotically unbiased quantity to the objective function (negative log-likelihood function) so that the new optimizer for the \u2018augmented objective function\u2019 has a provably smaller variance than the original estimator. To do this, let $h$ be some unknown (to be determined) augmentation function depending on the covariate. The key property of asymptotic unbiasedness is ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}w(a_{i},\\mathbf{x}_{i})\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}h(\\mathbf{x}_{i})\\rightarrow0\\quad\\mathrm{as}\\;n\\rightarrow\\infty\\;\\mathrm{in}\\;\\mathrm{probability~for~all}\\;\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We will justify this property in Corollary C.3 toward the end of this section. Given (30), we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\ell(\\mathbf{B})\\approx\\ell(\\mathbf{B})+\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}h(\\mathbf{x}_{i}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\approx$ here means asymptotic equality in probability as $n\\to\\infty$ . Denote the \u2018augmented objective function\u2019 on the right-hand side as $\\ell_{a u g}({\\mathbf{B}})$ . ", "page_idx": 20}, {"type": "text", "text": "In the remainder of this section, we introduce the optimal augmented function $h_{\\mathrm{opt}}(\\mathbf{X})$ that minimizes the variance of the estimator, while maintaining asymptotic unbiasedness. We demonstrate that outcome augmentation remains valid when IPW is replaced with DCBWs, such as EBWs and MMD balancing weights. Our approach extends the work of [50, 9] to a more general setting, incorporating other types of covariate balancing weights that have asymptotic consistency (38) in a multi-category treatment setting. ", "page_idx": 20}, {"type": "text", "text": "Let $S(\\mathbf{B})$ be the derivative of the original objective function $\\ensuremath{\\ell}({\\mathbf{{B}}})$ with respect to B. Then setting the optimal $h(\\mathbf{X})$ is equivalent to minimizing the conditional variance of ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\widehat{\\mathbf{B}}_{a}-\\mathbf{B}^{\\star}\\approx\\underbrace{S(\\mathbf{B})-w(A,\\mathbf{X})h(\\mathbf{X})\\mathbf{u}_{A}^{T}|\\mathbf{X}=\\mathbf{x}}_{=:\\mathbf{Z}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\widehat{\\mathbf{B}}_{a}$ is the minimizer of $\\ell_{\\mathrm{aug}}(\\mathbf{B})$ , and $\\mathbf{B}^{\\star}$ is the minimizer of $\\mathbb{E}[\\ell(\\mathbf{B})]$ . Using the property of asymptotic unbiasedness Theorem C.2, which is $\\mathbb{E}[\\mathbf{Z}]\\,=\\,0$ , we need to minimize $\\mathbb{E}[\\|\\mathbf{Z}\\|_{F}^{2}]$ with respect to $h$ to minimize the conditional variance of $\\mathbf{Z}$ . Using the property of matrix trace, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\nabla_{h}\\mathbb{E}[\\|\\mathbf{Z}\\|_{F}^{2}]=\\nabla_{h}\\mathbb{E}[\\mathrm{tr}(\\mathbf{Z}^{T}\\mathbf{Z})]=-2\\mathbb{E}[w(A,\\mathbf{X})\\,\\mathbf{Z}\\,\\mathbf{u}_{A})|\\mathbf{X}=\\mathbf{x}],\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and setting $\\nabla_{h}\\mathbb{E}[\\|\\mathbf{Z}\\|_{F}^{2}]=0$ . Thus, $h_{\\mathrm{opt}}(\\mathbf{X})$ satisfies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[w(A,\\mathbf{X})(S(\\mathbf{B})-w(A,\\mathbf{X})h_{\\mathrm{opt}}(\\mathbf{X})\\mathbf{u}_{A}^{T})\\mathbf{u}_{A})|\\mathbf{X}=\\mathbf{x}]=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $\\mathbf{u}_{A}^{T}\\mathbf{u}_{A}=1$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nh_{\\mathrm{opt}}(\\mathbf{x})=\\frac{\\mathbb{E}[w(A,\\mathbf{X})S(\\mathbf{B}^{\\star})\\mathbf{u}_{A}|\\mathbf{X}=\\mathbf{x}]}{\\mathbb{E}[w(A,\\mathbf{X})^{2}|\\mathbf{X}=\\mathbf{x}]}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Now, we determine the functional form of $h_{\\mathrm{opt}}(\\mathbf{X})$ for both continuous and binary outcomes. For simplicity, let us define ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{w:=w(A,\\mathbf{X}),\\quad t_{i}:=\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}}\\\\ &{R_{1}(\\mathbf{x}):=\\mathbb{E}[w^{2}\\mathbf{u}_{A}|\\mathbf{X}=\\mathbf{x}],\\quad R_{2}(\\mathbf{x}):=\\mathbb{E}[w^{2}Y|\\mathbf{X}=\\mathbf{x}],\\quad c_{1}=E[w^{2}|\\mathbf{X}=\\mathbf{x}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then for continuous outcomes, using (28) without regularization term for $S(\\mathbf{B})$ and (32), we have \u2113aug(B) ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\left[w_{i}\\left(\\frac{K}{K-1}y_{i}-\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)^{2}-w_{i}\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}h_{\\mathrm{opt}}(\\mathbf{x}_{i})\\right]}\\\\ &{=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\left[w_{i}\\left(\\frac{K}{K-1}y_{i}-\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)^{2}-w_{i}\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\frac{1}{\\hat{c}_{1}}\\left(\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}\\mathbf{B}\\hat{R}_{1}(\\mathbf{x}_{i})-\\frac{2K}{K-1}\\mathbf{x}_{i}\\hat{R}_{2}(\\mathbf{x}_{i})\\right)\\right]}\\\\ &{=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\left[\\left(\\frac{K}{K-1}y_{i}-t_{i}\\right)^{2}-t_{i}\\left(\\mathbf{x}_{i}^{T}\\mathbf{B}\\frac{1}{\\hat{c}_{1}}\\hat{R}_{1}(\\mathbf{x}_{i})\\right)+t_{i}\\left(\\frac{2K}{K-1}\\frac{1}{\\hat{c}_{1}}\\hat{R}_{2}(\\mathbf{x}_{i})\\right)\\right]}\\\\ &{=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\left[\\left(t_{i}-\\frac{K}{K-1}\\left(y_{i}-\\frac{1}{\\hat{c}_{1}}\\hat{R}_{2}(\\mathbf{x}_{i})\\right)\\right)^{2}+\\mathrm{constant~w.r.t}\\ \\mathbf{B}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "assuming $\\widehat{R}_{1}(\\mathbf{x}_{i})/\\widehat{c}_{1}=0$ . Therefore, we obtain the optimal augmented function with the minimum estimation variance by properly defining $R_{2}(\\mathbf{X})$ . Our simulation studies demonstrate that setting $R_{2}(\\mathbf{X})=\\mathbb{E}[Y|\\mathbf{X}=\\dot{\\mathbf{x}}]$ leads to significant improvement. ", "page_idx": 21}, {"type": "text", "text": "Similarly, for binary outcomes, let us define ", "page_idx": 21}, {"type": "equation", "text": "$$\nQ_{1}(\\mathbf{x}):=\\mathbb{E}\\left[w^{2}{\\frac{\\exp(\\mathbf{u}_{A}^{T}\\mathbf{B}^{T}\\mathbf{X})}{1+\\exp(\\mathbf{u}_{A}^{T}\\mathbf{B}^{T}\\mathbf{X})}}\\bigg\\vert\\mathbf{X}=\\mathbf{x}\\right],\\qquad Q_{2}(\\mathbf{x}):=\\mathbb{E}[w^{2}Y\\vert\\mathbf{X}=\\mathbf{x}].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then using (29) without regularization term for $S(\\mathbf{B})$ and (32), we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ell_{\\mathrm{aug}}(\\mathbf{B})=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\left[-y_{i}\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}+\\log(1+\\exp(\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}))+\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}h_{\\mathrm{opt}}(\\mathbf{x}_{i})\\right]}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\left[-y_{i}t_{i}+\\log(1+\\exp(t_{i}))+\\frac{1}{\\widehat{c}_{1}}t_{i}(\\widehat{Q}_{1}(\\mathbf{x})-\\widehat{Q}_{2}(\\mathbf{x}))\\right]}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\left[-t_{i}\\left(y_{i}-\\frac{1}{\\widehat{c}_{1}}(\\widehat{Q}_{1}(\\mathbf{x})-\\widehat{Q}_{2}(\\mathbf{x}))\\right)+\\log(1+\\exp(t_{i}))\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, by selecting proper $Q_{1}(\\mathbf{X})$ and $Q_{2}(\\mathbf{X})$ , the minimizer of $\\ell_{\\mathrm{aug}}(\\mathbf{B})$ has smaller variance than that of the original estimator. ", "page_idx": 21}, {"type": "text", "text": "Now we prove asymptotic unbiasedness of in=1 w(ai, xi)uaTiBT h(xi). First, we consider IPWbased conditions for multi-category treatments. ", "page_idx": 21}, {"type": "text", "text": "Lemma C.1. Let $\\mathcal{A}=\\{1,\\ldots,K\\}$ be the possible treatment sets. Assume we have i.i.d. observations $\\left(\\mathbf{x}_{i},a_{i}\\right)$ from a population distribution of $(\\mathbf{X},A)$ such that $\\mathbb{P}(A=a\\,|\\,\\mathbf{x})$ is uniformly positive for all $a,\\mathbf{x}.$ . Define ", "page_idx": 21}, {"type": "equation", "text": "$$\nT:=\\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{\\mathbb{P}(A=a_{i}|\\mathbf{x}_{i})}h(\\mathbf{x}_{i})g(a_{i}).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If $g$ is any function with $\\textstyle\\sum_{j\\in{\\cal A}}g(j)=0$ , then for any function $h(\\mathbf{X}):\\mathbb{R}^{p}\\to\\mathbb{R}^{p}$ , then $T\\rightarrow0$ as $n\\to\\infty$ in probability. ", "page_idx": 21}, {"type": "text", "text": "Proof. First note that by iterated expectation, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[T]=\\mathbb{E}\\left[\\frac{h(\\mathbf{X})g(A)}{\\mathbb{P}(A|\\mathbf{X})}\\right]=\\mathbb{E}_{\\mathbf{X}}\\left[\\mathbb{E}_{A}\\left[\\frac{h(\\mathbf{X})g(A)}{\\mathbb{P}(A|\\mathbf{X})}\\middle|\\mathbf{X}\\right]\\right]}\\\\ &{\\phantom{=}=\\mathbb{E}_{\\mathbf{X}}\\left[\\sum_{j\\in A}\\frac{h(\\mathbf{X})g(j)}{\\mathbb{P}(A=j|\\mathbf{X})}\\mathbb{P}(A=j|\\mathbf{X})\\right]}\\\\ &{\\phantom{=}=\\mathbb{E}_{\\mathbf{X}}\\left[h(\\mathbf{X})\\sum_{j\\in A}g(j)\\right]}\\\\ &{\\phantom{=}=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then by the standard weak law of large numbers for i.i.d. samples, the empirical mean $T$ converges in probability to its population mean $\\begin{array}{r}{\\bar{\\mathbb{E}}[T]=0}\\end{array}$ as $n\\to\\infty$ . \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Note that in the statement of the Lemma C.1, the choice of such $g(j)$ can be each treatment vertex under the AD-Learning [39]. Now we replace IPW $\\mathbb{P}(A=a_{i}|\\mathbf{x}_{i})$ with covariate balancing weights $w(a_{i},\\mathbf{x}_{i})$ that has the following asymptotic consistency property: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{n\\to\\infty}\\frac{1}{n}\\sum_{i=1}^{n}\\left(w(a_{i},\\mathbf{x}_{i})-\\frac{1}{\\mathbb{P}(a_{i}|\\mathbf{x}_{i})}\\right)^{2}=0.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "For instance, maximum mean discrepancy (MMD) balancing weights, a type of distributional covariate energy balancing weight, satisfy the property (38) [8]. ", "page_idx": 22}, {"type": "text", "text": "Theorem C.2 (Asymptotic unbiasedness of augmented function). Assume we have i.i.d. observations $\\left(\\mathbf{x}_{i},a_{i}\\right)$ from population distribution of $(\\mathbf{X},A)$ . If $g\\;:\\;A\\;\\rightarrow\\;\\mathbb{R}$ is any bounded function with $\\textstyle\\sum_{j\\in{\\mathcal{A}}}g(j)=0$ , then for any bounded function $h(\\mathbf{x}):\\mathbb{R}^{p}\\rightarrow\\mathbb{R}^{p}$ , define ", "page_idx": 22}, {"type": "equation", "text": "$$\nT_{0}:=\\frac{1}{n}\\sum_{i=1}^{n}w(a_{i},\\mathbf{x}_{i})h(\\mathbf{x}_{i})g(a_{i}),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the weights $w(a_{i},\\mathbf{x}_{i})$ satisfy (38). Then $T_{0}\\rightarrow0$ as $n\\to\\infty$ in probability. That is, $T_{0}$ is an asymptotically mean zero, making it suitable to be used as the augmented function. ", "page_idx": 22}, {"type": "text", "text": "Proof. By the weak law of large numbers for i.i.d. samples, the empirical mean $T_{0}$ converges in probability to its population mean $\\mathbb{E}[T_{0}]=\\mathbb{E}[w(A,\\mathbf{X})h(\\bar{\\mathbf{X}})g(A)]$ . By continuous mapping theorem, $\\Vert T_{0}\\Vert^{2}$ converges to $\\Vert\\mathbb{E}[T_{0}]\\Vert^{2}$ as $n\\to\\infty$ in probability. Then we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Vert\\mathbb{E}[T_{0}]\\Vert^{2}=\\Vert\\mathbb{E}[w(A,\\mathbf{X})h(\\mathbf{X})g(A)]\\Vert^{2}\\overset{(a)}{=}\\left\\Vert\\mathbb{E}[w(A,\\mathbf{X})h(\\mathbf{X})g(A)]-\\mathbb{E}\\left[\\frac{h(\\mathbf{X})g(A)}{\\mathbb{P}(A|\\mathbf{X})}\\right]\\right\\Vert^{2}}&{}\\\\ {=\\bigg\\Vert\\mathbb{E}\\left[\\left(w(A,\\mathbf{X})-\\frac{1}{\\mathbb{P}(A|\\mathbf{X})}\\right)h(\\mathbf{X})g(A)\\right]\\bigg\\Vert^{2}}&{}\\\\ {\\overset{(b)}{\\leq}\\mathbb{E}\\left[\\left\\Vert\\left(w(A,\\mathbf{X})-\\frac{1}{\\mathbb{P}(A|\\mathbf{X})}\\right)h(\\mathbf{X})g(A)\\right\\Vert^{2}\\right]}&{}\\\\ {\\leq C\\mathbb{E}\\left[\\left(w(A,\\mathbf{X})-\\frac{1}{\\mathbb{P}(A|\\mathbf{X})}\\right)^{2}\\right]}&{}\\\\ {\\overset{(c)}{=}\\underset{n\\leq m}{\\operatorname*{lim}}C\\frac{1}{n}\\underset{i=1}{\\overset{n}{\\sum}}\\left(w(a_{i},\\mathbf{x}_{i})-\\frac{1}{\\mathbb{P}(a_{i}|\\mathbf{X})}\\right)^{2}\\rightarrow0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $C$ is any constant such that $\\|h(\\mathbf{X})g(A)\\|^{2}\\leq C$ . For (a), we use Lemma C.1; for (b) and (c), we use Jensen\u2019s inequality and the law of large numbers, respectively. The last term converges to 0 due to the property (38). Lastly, since $\\|T_{0}\\|^{2}$ converges to 0 in probability, we have $T_{0}$ converges to 0 in probability by continuous mapping theorem. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "The following corollary is useful in deriving outcome augmentation under the AD-Learning framework. ", "page_idx": 22}, {"type": "text", "text": "Corollary C.3. Assume the $A D$ -learning setting. For any function $h(\\mathbf{X})$ depending only on the covariate $\\mathbf{X}$ , and for each parameter matrix $\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)}$ , denoting, ", "page_idx": 22}, {"type": "equation", "text": "$$\nH_{0}(\\mathbf{B}):=w(A,\\mathbf{X})\\mathbf{u}_{A}^{T}\\mathbf{B}^{T}h(\\mathbf{X}),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "we have $\\mathbb{E}[H_{0}(\\mathbf{B})]=0$ . Furthermore, assuming the weights $w(A,\\mathbf{X})$ satisfying the consistency property (38), in probability as $n\\to\\infty$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}w(a_{i},\\mathbf{x}_{i})\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}h(\\mathbf{x}_{i})\\rightarrow0.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. Follows immediately from Theorem C.2 by noting that $\\textstyle\\sum_{a=1}^{K}\\mathbf{u}_{a}=0$ . ", "page_idx": 22}, {"type": "text", "text": "D Spectral characterization of optimal covariate balancing weight ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Recall the definition of the weighted design matrix: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\boldsymbol{\\Psi}:=\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\big(\\mathbf{u}_{a_{i}}\\mathbf{u}_{a_{i}}^{T}\\big)\\otimes\\big(\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}\\big)\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This is the $p(K-1)\\times p(K-1)$ design matrix encoding the sample of patients with covariate $\\mathbf{x}_{i}$ and observed treatment $a_{i}$ , for $i=1,\\hdots,n$ . We are free to choose the weight $w_{i}=\\omega(a_{i},{\\bf x}_{i})$ for the ith patient as a function as long as they sum to one. What is the best way to choose such weights? Our main results (Theorems 3.3, 3.5) suggest that it is best to choose them in a way that the minimum eigenvalue of $\\Psi$ is as large as possible. ", "page_idx": 23}, {"type": "text", "text": "To illustrate this point, suppose for simplicity that we have binary treatments $K=2$ and $u_{1}=1$ , $u_{2}=-1)$ ) and two discrete covariates (e.g., \u2018Male\u2019 and \u2018Female\u2019) encoded as one-hot vectors $(1,0)^{T}$ and $(0,1)^{T}$ . Then we can write $\\Psi$ as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{n\\Psi=w(1,M)n_{1,M}\\left[\\begin{array}{l l}{1}&{0}\\\\ {0}&{0}\\end{array}\\right]+w(2,M)n_{2,M}\\left[\\begin{array}{l l}{1}&{0}\\\\ {0}&{0}\\end{array}\\right]}\\\\ &{\\qquad\\quad+w(1,M)n_{1,M}\\left[\\begin{array}{l l}{0}&{0}\\\\ {0}&{1}\\end{array}\\right]+w(2,F)n_{2,F}\\left[\\begin{array}{l l}{0}&{0}\\\\ {0}&{1}\\end{array}\\right]}\\\\ &{\\qquad=\\left[w(1,M)n_{1,M}+w(2,M)n_{2,M}\\quad\\qquad\\qquad\\quad0\\right.}\\\\ &{\\qquad\\qquad\\quad0}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where for treatment $a=1,2$ and $g\\in\\{M,F\\},n(a,g)$ denotes the number of patients of gender $g$ with treatment $a$ , and $w(a,g)$ denotes the weight for patients of gender $g$ with treatment $a$ . Notice that the minimum eigenvalue of the last $2\\times2$ matrix is the minimum of its two diagonal entries. It is easy to see that the optimal choice of the weights is given by ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{w(1,M)=\\frac{n_{1,M}+n_{2,M}}{n_{1,M}},\\quad w(2,M)=\\frac{n_{1,M}+n_{2,M}}{n_{2,M}},}\\\\ {w(1,F)=\\frac{n_{1,F}+n_{2,F}}{n_{1,F}},\\quad w(2,F)=\\frac{n_{1,F}+n_{2,F}}{n_{2,F}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "These weights are exactly the ones that make the conditional distributions of the covariates given treatments the same. This observation holds for more general settings. ", "page_idx": 23}, {"type": "text", "text": "E Convergence analysis of PGD for ITR estimation ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we analyze the convergence properties of Algorithm 1 for ITR-Learning problem (6).   \nBelow we state the full version of Theorem 3.3 in the main text. ", "page_idx": 24}, {"type": "text", "text": "Theorem E.1 (Convergence rate of PGD for ITR-Learning). Let $(\\mathbf{B}_{t})_{t\\geq0}$ denote the sequence of parameters obtained by the PGD algorithm (7) for ITR-Learning problem (6) with arbitrary initialization $\\mathbf{B}_{0}$ . Suppose Assumptions 3.1 and 3.2 hold. Let $\\mathbf{B}^{\\star}$ denote the unique global optimum of (6). Then the following hold: ", "page_idx": 24}, {"type": "text", "text": "(i) (Optimization landscape) The ITR objective ${\\mathcal{L}}(\\mathbf{B})$ in (6), is $\\mu$ -strongly convex and $L$ -smooth, where $\\mu,L$ are as in (10). ", "page_idx": 24}, {"type": "text", "text": "(ii) (Linear convergence with fixed stepsize) Assume constant stepsize $\\alpha_{t}\\equiv\\alpha<2/L$ . Denote the contraction constant $\\rho(\\alpha):=\\operatorname*{max}\\{|1-\\alpha L|,|1-\\alpha\\mu|\\}\\in(0,1)$ . Then for all $t\\geq1$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathbf{B}_{t}-\\mathbf{B}^{\\star}\\|_{F}^{2}\\leq4\\rho(\\alpha)^{t}\\lambda_{1}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "In particular, if $\\begin{array}{r}{\\alpha=\\frac{2}{\\mu+L}}\\end{array}$ \u00b5+2L, then \u03c1(\u03b1) = $\\begin{array}{r}{\\rho(\\alpha)=\\frac{L-\\mu}{L+\\mu}\\in[0,1)}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "(iii) (Sublinear convergence with diminishing stepsize) Assume diminishing stepsize $\\begin{array}{r}{\\alpha_{t}=\\frac{\\beta}{\\gamma+t}}\\end{array}$ , where $\\begin{array}{r}{\\rho:=\\frac{2\\mu L}{\\mu+L}}\\end{array}$ and $\\beta>1/\\rho,\\,\\gamma>0$ are constants. Then for all $t\\geq1$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\|\\mathbf{B}_{t}-\\mathbf{B}^{\\star}\\|_{F}^{2}\\leq\\frac{\\nu}{\\gamma+t},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where 2\u03b22\u2225\u03b2\u2207\u03c1f(\u2212B1\u22c6)\u22252F, 4(\u03b3 + 1)\u03bb21 . In particular, the assertion holds for $\\begin{array}{r}{\\beta=2/\\rho=\\frac{\\mu+L}{\\mu L}}\\end{array}$ and $\\begin{array}{r}{\\nu=\\operatorname*{max}\\Big\\{\\frac{2(\\mu+L)^{2}\\|\\nabla f(\\mathbf{B}^{\\star})\\|_{F}^{2}}{\\mu^{2}L^{2}},\\,4(\\gamma+1)\\lambda_{1}^{2}\\Big\\}.}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "The proof of Theorem E.1 relies on two ingredients: a general result on the convergence of PGD (Lemma E.2) and a local landscape analysis of the ITR objective (Lemma E.3). ", "page_idx": 24}, {"type": "text", "text": "We first establish a general result on the convergence rate of PGD to find the minimizer of a strongly convex and smooth objective $f$ within a convex constraint $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ . Our argument is mostly based on the standard convergence analysis of PGD in the optimization literature [5, 4]. A new element we add is that for analyzing constrained optimization problems, the gradient of the objective $f$ at the minimizer $\\mathbf{B}^{\\star}$ does not need to be zero, which only needs to be in the negative normal cone at the constraint set $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . In our analysis, we treat the possibly nonzero gradient norm $\\|\\nabla f(\\mathbf{B}^{\\star})\\|_{F}$ as \u2018noise\u2019 (variance) of a stochastic gradient oracle in standard stochastic gradient descent analysis [4]. ", "page_idx": 24}, {"type": "text", "text": "Lemma E.2 (Convergence rate of PGD for strongly convex and smooth objectives). Let $f:$ $\\mathbb{R}^{p\\times(K-1)}\\ \\rightarrow\\ \\mathbb{R}$ be a $L$ -smooth and $\\mu$ -strongly convex function for some $\\mu,L\\,>\\,0$ . Suppose $f^{\\star}:=\\operatorname*{inf}_{\\mathbf{B}\\in\\mathcal{B}}f(\\mathbf{B})>-\\infty$ and denote $\\begin{array}{r}{\\mathbf{B}^{\\star}:=\\arg\\operatorname*{min}_{\\mathbf{B}\\in\\mathcal{B}}f(\\mathbf{B}),}\\end{array}$ , where $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is a convex constraint set of $\\mathbb{R}^{p\\times(K-1)}$ . Consider the following PGD iterates: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbf{B}_{t+1}\\leftarrow\\Pi_{\\mathcal{B}}\\left\\{\\mathbf{B}_{t}-\\alpha_{t}\\nabla_{\\mathbf{B}}f(\\mathbf{B}_{t})\\right\\}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then the following hold: ", "page_idx": 24}, {"type": "text", "text": "(i) (Linear convergence with fixed stepsize) Suppose $f$ is twice differentiable and $\\alpha_{t}\\equiv\\alpha<2/L$ . Let contraction constant $\\rho(\\alpha):=\\operatorname*{max}\\{|1-\\alpha L|,|1-\\alpha\\mu|\\}\\in(0,1)$ . Then for all $t\\geq1$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathbf{B}_{t}-\\mathbf{B}^{\\star}\\|_{F}^{2}\\leq\\rho(\\alpha)_{t}\\|\\mathbf{B}_{0}-\\mathbf{B}^{\\ast}\\|_{F}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The bound $\\rho(\\alpha)$ on the linear convergence rate is minimized at $\\begin{array}{r}{\\alpha=\\frac{2}{\\mu+L}}\\end{array}$ with minimum value $\\frac{L-\\mu}{L+\\mu}$ . ", "page_idx": 24}, {"type": "text", "text": "(ii) (Sublinear convergence with diminishing stepsize) Denote $\\begin{array}{r}{\\rho:=\\frac{2\\mu L}{\\mu+L}}\\end{array}$ . Suppose $\\begin{array}{r}{\\alpha_{t}=\\frac{\\beta}{\\gamma+t}}\\end{array}$ \u03b3\u03b2+t, where $\\beta>1/\\rho,\\,\\gamma>0$ are constants. Then for all $t\\geq1$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\|\\mathbf{B}_{t}-\\mathbf{B}^{\\star}\\|_{F}^{2}\\leq\\frac{\\nu}{\\gamma+t},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. Let $\\bar{\\mathbf{B}}_{t}:=\\mathbf{B}_{t}-\\alpha_{t}\\nabla_{\\mathbf{B}}f(\\mathbf{B}_{t})$ . Then ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\bar{\\mathbf{B}}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}=\\|\\bar{\\mathbf{B}}_{t}-\\mathbf{B}_{t}\\|_{F}^{2}+\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}+2\\langle\\bar{\\mathbf{B}}_{t}-\\mathbf{B}_{t},\\mathbf{B}_{t}-\\mathbf{B}^{*}\\rangle}\\\\ &{\\qquad\\qquad\\qquad=\\alpha_{t}^{2}\\|\\nabla_{\\mathbf{B}}f(\\mathbf{B}_{t})\\|_{F}^{2}+\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}-2\\alpha_{t}\\langle\\mathbf{B}_{t}-\\mathbf{B}^{*},\\nabla_{\\mathbf{B}}f(\\mathbf{B}_{t})\\rangle}\\\\ &{\\qquad\\qquad\\leq\\alpha_{t}^{2}\\|\\nabla_{\\mathbf{B}}f(\\mathbf{B}_{t})\\|_{F}^{2}+\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}-2\\alpha_{t}\\langle\\mathbf{B}_{t}-\\mathbf{B}^{*},\\nabla_{\\mathbf{B}}f(\\mathbf{B}_{t})-\\nabla_{\\mathbf{B}}f(\\mathbf{B}^{*})\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "using that $\\langle\\nabla f(\\mathbf{B}^{\\star}),\\mathbf{B}_{t}\\!-\\!\\mathbf{B}^{\\star}\\rangle\\geq0$ since $\\mathbf{B}^{\\star}$ is a stationary point of $f$ over $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . Using the co-coercivity of $\\mu$ -strongly convex and $L$ -smooth functions and, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\bar{\\mathbf{B}}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}\\leq\\alpha_{t}^{2}\\|\\nabla f(\\mathbf{B}_{t})\\|_{F}^{2}+\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}}\\\\ {\\displaystyle\\qquad\\qquad-\\,2\\alpha_{t}\\left(\\frac{\\mu L}{\\mu+L}\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|^{2}+\\frac{1}{\\mu+L}\\|\\nabla f(\\mathbf{B}_{t})-\\nabla f(\\mathbf{B}^{*})\\|_{F}^{2}\\right)}\\\\ {\\displaystyle\\leq\\left(1-\\frac{2\\alpha_{t}\\mu L}{\\mu+L}\\right)\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}+\\alpha_{t}^{2}\\|\\nabla f(\\mathbf{B}_{t})\\|_{F}^{2}-\\frac{2\\alpha_{t}}{\\mu+L}\\|\\nabla f(\\mathbf{B}_{t})-\\nabla f(\\mathbf{B}^{*})\\|_{F}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By Young\u2019s inequality, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\nabla f({\\mathbf B}_{t})\\|_{F}^{2}\\leq2\\|\\nabla f({\\mathbf B}_{t})-\\nabla f({\\mathbf B}^{\\star})\\|_{F}^{2}+2\\|\\nabla f({\\mathbf B}^{\\star})\\|_{F}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus the above yields, given that $\\alpha_{t}\\leq1/(\\mu+L)$ , ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\|\\bar{\\mathbf{B}}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}\\leq\\left(1-\\frac{2\\alpha_{t}\\mu L}{\\mu+L}\\right)\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}+2\\alpha_{t}\\left(\\alpha_{t}-\\frac{1}{\\mu+L}\\right)\\|\\nabla f(\\mathbf{B}_{t})-\\nabla f(\\mathbf{B}^{\\star})\\|_{F}^{2}}\\\\ {\\displaystyle\\qquad\\qquad+\\;2\\alpha_{t}^{2}\\|\\nabla f(\\mathbf{B}^{\\star})\\|_{F}^{2}}\\\\ {\\displaystyle\\leq\\left(1-\\frac{2\\alpha_{t}\\mu L}{\\mu+L}\\right)\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}+2\\alpha_{t}^{2}\\|\\nabla f(\\mathbf{B}^{*})\\|_{F}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since the projection onto the convex constraint set $B,\\Pi_{B}$ , is non-expansive, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\|\\mathbf{B}_{t+1}-\\mathbf{B}^{*}\\|_{F}^{2}\\leq\\|\\bar{\\mathbf{B}}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}\\leq(1-\\alpha_{t}\\rho)\\,\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}^{2}+\\alpha_{t}^{2}\\sigma^{2},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where we have denoted $\\begin{array}{r}{\\rho:=\\frac{2\\mu L}{\\mu+L}}\\end{array}$ and $\\sigma^{2}:=2\\|\\nabla f(\\mathbf{B}^{*})\\|_{F}^{2}$ . ", "page_idx": 25}, {"type": "text", "text": "Now, we show (i) (50). Suppose $\\alpha_{t}\\,\\equiv\\,\\alpha\\,>\\,0$ . Note that $\\mathbf{B}^{\\ast}$ is a unique minimizer of $f$ over $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ because of strong convexity. Since $-\\nabla f(\\mathbf{B}^{\\star})$ lies in the normal cone of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ at $\\mathbf{B}^{\\star}$ , we have $\\mathbf{B}^{\\star}=\\Pi_{\\mathcal{B}}(\\mathbf{B}^{\\star}-\\alpha\\bar{\\nabla}f(\\mathbf{B}^{\\star}))$ . Using non-expansiveness of convex projection $\\Pi_{B}$ , ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\|\\mathbf{B}_{t+1}-\\mathbf{B}^{*}\\|_{F}=\\|\\Pi_{B}(\\mathbf{B}_{t}-\\alpha\\nabla f(\\mathbf{B}_{t}))-\\Pi_{B}(\\mathbf{B}^{*}-\\alpha\\nabla f(\\mathbf{B}^{*}))\\|_{F}}&{}\\\\ {\\le\\|(\\mathbf{B}_{t}-\\alpha\\nabla f(\\mathbf{B}_{t}))-(\\mathbf{B}^{*}-\\alpha\\nabla f(\\mathbf{B}^{*}))\\|_{F}}&{}\\\\ {=\\left\\|\\int_{0}^{1}(I-\\alpha\\nabla^{2}f(\\mathbf{B}_{t}+s(\\mathbf{B}^{*}-\\mathbf{B}_{t})))(\\mathbf{B}_{t}-\\mathbf{B}^{*})\\,d s\\right\\|_{F}}&{}\\\\ {\\le\\operatorname*{sup}\\|I-\\alpha\\nabla^{2}f(\\tilde{\\mathbf{B}})\\|_{2}\\,\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}}&{}\\\\ {\\le\\underbrace{\\operatorname*{max}\\{|1-\\alpha L|,|1-\\alpha\\mu|\\}}_{=:\\rho(\\alpha)}\\,\\|\\mathbf{B}_{t}-\\mathbf{B}^{*}\\|_{F}.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For the last inequality, since the eigenvalues of $\\nabla^{2}f(\\tilde{\\mathbf{B}})$ are contained in the interval $[\\mu,L]$ , the eigenvalues of $\\bar{I^{\\mathrm{~-~}}}\\alpha\\bar{\\nabla}^{2}f(z)$ are between $\\operatorname*{min}(1-\\alpha L,\\,1-\\alpha\\mu)$ and $\\operatorname*{max}(1-\\alpha L,\\,1-\\alpha\\mu)$ . Note that $\\rho(\\alpha)$ is minimized at $\\begin{array}{r}{\\alpha=\\frac{2}{\\mu+L}}\\end{array}$ L with minimum value LL+\u2212\u00b5\u00b5. It follows that for any t \u22650, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\|\\mathbf{B}_{t+1}-\\mathbf{B}^{*}\\|_{F}\\leq\\rho(\\boldsymbol{\\alpha})^{t+1}\\,\\|\\mathbf{B}_{0}-\\mathbf{B}^{\\star}\\|_{F}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Next, we show (ii) (51) by induction. Indeed, it holds for $t\\,=\\,1$ by the choice of $\\nu$ . Denoting $\\hat{t}:=\\gamma+t$ , by the induction hypothesis and by the choices of $\\alpha_{t}=\\beta/\\hat{t}$ and $\\begin{array}{r}{\\nu\\ge\\frac{\\beta^{2}\\sigma^{2}}{\\beta\\rho-1}}\\end{array}$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\mathbf{B}_{t+1}-\\mathbf{B}^{\\star}\\|_{F}^{2}\\leq\\left(1-\\displaystyle\\frac{\\beta\\rho}{\\hat{t}}\\right)\\frac{\\nu}{\\hat{t}}+\\displaystyle\\frac{\\beta^{2}\\sigma^{2}}{\\hat{t}^{2}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(\\displaystyle\\frac{\\hat{t}-1}{\\hat{t}^{2}}\\right)\\nu\\underbrace{-\\left(\\frac{\\beta\\rho-1}{\\hat{t}^{2}}\\right)\\nu+\\frac{\\beta^{2}\\sigma^{2}}{\\hat{t}^{2}}}_{\\leq0}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{\\hat{t}-1}{(\\hat{t}-1)(\\hat{t}+1)}\\nu=\\frac{\\nu}{\\gamma+t+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Next, we establish the following global landscape result of the ITR learning problem (6) by computing the Hessian of the objective ${\\mathcal{L}}(\\mathbf{B})$ in (6). ", "page_idx": 26}, {"type": "text", "text": "Lemma E.3 (Local landscape of the ITR objective). Let ${\\mathcal{L}}(\\mathbf{B})$ denote the ITR objective in (6). ", "page_idx": 26}, {"type": "text", "text": "(i) Suppose Assumption 3.1 holds. For the continuous outcome, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\lambda^{-}+\\lambda_{2})\\mathbf{I}_{p(K-1)}\\preceq\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\nabla_{\\mathrm{vec}(\\mathbf{B})^{T}}\\mathcal{L}(\\mathbf{B})\\preceq(\\lambda^{+}+\\lambda_{2})\\mathbf{I}_{p(K-1)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the constants $\\lambda^{\\pm}$ are defined in Assumption 3.1. ", "page_idx": 26}, {"type": "text", "text": "(ii) Further Assumptions 3.1 and 3.2 hold. For the binary outcome, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\alpha^{-}\\lambda^{-}+\\lambda_{2})\\mathbf{I}_{p(K-1)}\\preceq\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\nabla_{\\mathrm{vec}(\\mathbf{B})^{T}}\\mathcal{L}(\\mathbf{B})\\preceq(\\alpha^{+}\\lambda^{+}+\\lambda_{2})\\mathbf{I}_{p(K-1)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the constants $\\lambda^{\\pm}$ and $\\alpha^{\\pm}$ are defined in Assumptions 3.1 and 3.2, respectively. ", "page_idx": 26}, {"type": "text", "text": "To maintain the flow, we write down the proof of Lemma E.3 to Section F. ", "page_idx": 26}, {"type": "text", "text": "Now we can easily deduce Theorem E.1. ", "page_idx": 26}, {"type": "text", "text": "Proof of Theorem E.1. Lemma E.3 shows that the eigenvalues of the Hessian $\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\nabla_{\\mathrm{vec}(\\mathbf{B})^{T}}\\mathcal{L}$ of the ITR objective in (6) are uniformly bounded between constants $\\mu$ and $L$ as defined in (10). Under Assumptions 3.1 and 3.2, we have $0<\\mu\\leq L<\\infty$ . This shows that $\\mathcal{L}$ is $\\mu$ -strongly convex and $L$ -smooth over $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , as claimed in Theorem E.1 (i). ", "page_idx": 26}, {"type": "text", "text": "Next, noting that $\\|\\cdot\\|_{F}\\leq\\|\\cdot\\|_{1}$ , triangle inequality and the fact that $\\hat{\\mathbf{B}}_{0},\\mathbf{B}^{\\star}\\in B$ yields that, for any $t\\geq0$ , ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\mathbf{B}_{t}-\\mathbf{B}^{\\star}\\|_{F}^{2}\\leq\\left(\\|\\mathbf{B}_{t}\\|_{F}+\\|\\mathbf{B}_{\\star}\\|_{F}\\right)^{2}}\\\\ &{\\qquad\\qquad\\leq\\left(\\|\\mathbf{B}_{t}\\|_{1}+\\|\\mathbf{B}_{\\star}\\|_{1}\\right)^{2}}\\\\ &{\\qquad\\qquad\\leq4\\lambda_{1}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Hence the assertions (i)-(ii) follow directly from combining Lemmas E.2 and E.3. ", "page_idx": 26}, {"type": "text", "text": "F Proof of Lemma E.3 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In this section, we prove Lemma E.3. We will first compute the gradient and the Hessian of the ITR objective in (6) separately for the continuous and binary outcome. We will then prove Lemma E.3 at the end of the section. ", "page_idx": 26}, {"type": "text", "text": "F.1 Continuous outcome ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Proposition F.1. Let ${\\mathcal{L}}(\\mathbf{B})$ denote the ITR objective in (6) with continuous outcome. Then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\nabla_{\\bf B}\\,{\\mathcal L}({\\bf B})=\\frac{1}{n}\\sum_{i=1}^{n}\\omega(a_{i},{\\bf x}_{i})\\,\\left({\\bf x}_{i}{\\bf x}_{i}^{T}{\\bf B}{\\bf u}_{a_{i}}{\\bf u}_{a_{i}}^{T}-\\frac{K}{K-1}y_{i}{\\bf x}_{i}{\\bf u}_{a_{i}}^{T}\\right)+\\lambda_{2}{\\bf B},}}\\\\ {{\\displaystyle\\nabla_{\\mathrm{vec}({\\bf B})}\\nabla_{\\mathrm{vec}({\\bf B})^{T}}{\\mathcal L}({\\bf B})=\\Psi+\\lambda_{2}\\,{\\bf I}_{p(K-1)}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\Psi$ is the weighted design matrix defined at (8). ", "page_idx": 26}, {"type": "text", "text": "Proof. Recall that the ITR objective for continuous outcome is given by ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\mathbf{B})=\\frac{1}{2n}\\sum_{i=1}^{n}\\omega(a_{i},\\mathbf{x}_{i})\\left(\\frac{K}{K-1}y_{i}-\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)^{2}+\\frac{\\lambda_{2}}{2}||\\mathbf{B}||_{F}^{2}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "It is trivial to show (57). For the Hessian, using (16), ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\allowdisplaybreaks}&{0\\leq\\mathrm{V}_{\\mathrm{we}(\\mathbf{B})}\\,\\mathrm{Ve}(\\mathrm{Br})\\,\\mathrm{Ce}(\\mathrm{Be}(\\mathbf{B}))}\\\\ &{=\\mathrm{V}_{\\mathrm{we}(\\mathbf{B})}\\,\\exp\\Bigg(\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i i,\\mathrm{x}}\\bigg(\\mathrm{Se}_{i}^{\\top}\\mathrm{Ba}_{i,\\mathrm{B}}\\mathrm{a}_{i,\\mathrm{B}}^{\\top}-\\frac{K}{K-1}\\mathrm{B}_{i}\\mathrm{Ba}_{i,\\mathrm{B}}^{\\top}\\bigg)\\Bigg)^{T}+\\lambda_{2}\\nabla_{\\mathbf{B}}^{2}(\\mathrm{B})}\\\\ &{=\\mathrm{V}_{\\mathrm{we}(\\mathbf{B})}\\,\\mathrm{Ve}\\Bigg(\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i i}\\mathrm{A}_{i}\\mathrm{\\Omega}_{i}\\bigg(\\mathrm{As}_{i}\\mathrm{X}_{i}^{\\top}\\mathrm{Ba}_{i,\\mathrm{B}}\\mathrm{a}_{i,\\mathrm{B}}^{\\top}\\bigg)^{T}+\\lambda_{2}\\mathrm{I}_{\\mathbf{R}}(\\mathrm{Br}-1)}\\\\ &{=\\mathrm{V}_{\\mathrm{we}(\\mathbf{B})}\\,\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i,\\mathrm{x}}\\bigg(\\bigg(\\mathrm{m}_{i,\\mathrm{B}}\\mathrm{a}_{i,\\mathrm{B}}^{\\top}\\mathrm{P}\\mathrm{\\Omega}_{\\mathrm{e}(\\mathbf{A})}\\bigg)\\mathrm{Ve}(\\mathrm{B})\\bigg)^{T}\\right]+\\lambda_{2}\\mathrm{I}_{\\mathbf{R}}(\\mathrm{Br}-1)}\\\\ &{=\\mathrm{V}_{\\mathrm{we}(\\mathbf{B})}\\,\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i,\\mathrm{x}}\\bigg(\\mathrm{Br}_{i}\\mathrm{B}_{i}^{\\top}\\mathrm{P}\\mathrm{\\Omega}_{\\mathrm{e}(\\mathbf{B})}\\mathrm{a}_{i,\\mathrm{B}}^{\\top}\\bigg)\\mathrm{Ce}(\\mathrm{Br}_{i}\\mathrm{B}_{i}^{\\top})^{T}\\right]+\\lambda_{2}\\mathrm{I}_{\\mathbf{R}}(\\mathrm{Br}-1)}\\\\ &{=\\mathrm{V}_{\\mathrm{we}(\\mathbf{B})}\\,\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "This shows the assertion. ", "page_idx": 27}, {"type": "text", "text": "F.2 Binary outcome ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Given the current model parameter $\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)}$ , define the scalars $z_{i},p_{i},w_{i}$ for the $i$ -th sample by ", "page_idx": 27}, {"type": "equation", "text": "$$\nz_{i}:=\\mathbf{u_{a_{i}}^{T}}\\mathbf{B}^{T}\\mathbf{x}_{i},\\qquad p_{i}:=\\frac{\\exp(z_{i})}{1+\\exp(z_{i})},\\qquad w_{i}:=w(a_{i},\\mathbf{x}_{i}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "For each binary label $y\\in\\{0,1\\}$ and activation $z\\in\\mathbb{R}$ , recall the negative log-likelihood of observing $y$ under the logistic model Ber $\\left(p_{i}\\right)$ is given by ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\ell(y,z)=\\log(1+\\exp(z))-y z.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "An easy computation shows ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l l}&{\\displaystyle\\dot{\\bf h}(y,z):=\\frac{\\partial}{\\partial z}\\ell(y,z)=\\frac{\\exp(z)}{1+\\exp(z)}-y,}\\\\ &{\\displaystyle\\ddot{\\bf h}(y,z):=\\frac{\\partial^{2}}{\\partial z^{2}}\\ell(y,z)=\\left(\\frac{\\exp(z)}{1+\\exp(z)}\\right)\\left(1-\\frac{\\exp(z)}{1+\\exp(z)}\\right)\\leq\\frac{1}{4}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "For the forthcoming computations, define matrices ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~\\mathbf{K}:=[\\dot{\\mathbf{h}}(y_{1},z_{1}),\\dots,\\dot{\\mathbf{h}}(y_{n},z_{n})]\\in\\mathbb{R}^{1\\times n},}\\\\ &{\\mathbf{M}:=\\mathrm{diag}\\left(\\ddot{\\mathbf{h}}(y_{1},z_{1}),\\dots,\\ddot{\\mathbf{h}}(y_{n},z_{n})\\right)\\in\\mathbb{R}^{n\\times n},}\\\\ &{~\\Phi:=[\\mathbf{u}_{a_{1}}\\otimes\\mathbf{x}_{1},\\dots,\\mathbf{u}_{a_{n}}\\otimes\\mathbf{x}_{n}]\\in\\mathbb{R}^{p(K-1)\\times n},}\\\\ &{\\mathbf{W}:=\\mathrm{diag}(w_{1},\\dots,w_{n})\\in\\mathbb{R}^{n\\times n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proposition F.2. Let ${\\mathcal{L}}(\\mathbf{B})$ denote the ITR objective in (6) with binary outcome. Suppose Assumption 3.1 holds. Let $z_{i}:=\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}$ for $i=1,\\hdots,n$ . Then ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\nabla_{\\mathbf{B}}\\,\\mathcal{L}({\\mathbf{B}})=\\frac{1}{n}\\left(\\sum_{i=1}^{n}w_{i}\\dot{\\mathbf{h}}(y_{i},z_{i})\\mathbf{x}_{i}\\mathbf{u}_{a_{i}}^{T}\\right)+\\lambda_{2}\\mathbf{B},}}\\\\ {{\\displaystyle\\nabla_{\\mathrm{vec}({\\mathbf{B}})}\\nabla_{\\mathrm{vec}({\\mathbf{B}})^{T}}\\mathcal{L}({\\mathbf{B}})=\\frac{1}{n}\\Phi(\\mathbf{M}{\\mathbf{W}})\\Phi^{T}+\\lambda_{2}\\mathbf{I}_{p(K-1)}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. We first claim that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad\\qquad\\nabla_{\\mathrm{vec}(\\mathbf{B})}z_{i}=\\mathbf{C}^{(K-1,p)}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a_{i}}),}\\\\ &{\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\,\\ell(y_{i},z_{i})=\\mathbf{C}^{(K-1,p)}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a_{i}})\\,\\dot{\\mathbf{h}}(y_{i},z_{i}),}\\\\ &{\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\,\\mathrm{vec}(\\mathbf{K})^{T}=\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\mathbf{K}=\\Phi\\mathbf{M}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Observe that by using (18), we can write ", "page_idx": 28}, {"type": "equation", "text": "$$\nz_{i}=\\mathrm{vec}(z_{i})=\\mathrm{vec}(\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i})=(\\mathbf{x}_{i}^{T}\\otimes\\mathbf{u}_{a_{i}}^{T})\\,\\mathrm{vec}(\\mathbf{B}^{T})=\\mathrm{vec}(\\mathbf{B}^{T})^{T}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a_{i}}).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Noting that $\\operatorname{vec}(\\mathbf{B}^{T})^{T}=(\\mathbf{C}^{(p,K-1)}\\operatorname{vec}(\\mathbf{B}))^{T}=\\operatorname{vec}(\\mathbf{B})^{T}\\mathbf{C}^{(K-1,p)}$ Hence we get ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\mathrm{vec}(\\mathbf{B})}z_{i}=\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\,\\mathrm{vec}(\\mathbf{B}^{T})^{T}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a_{i}})}\\\\ &{\\qquad\\qquad=\\mathbf{C}^{(K-1,p)}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a_{i}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "This verifies (68). Then by using the chain rule (20), we get ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\ell(y_{i},z_{i})=\\nabla_{\\mathrm{vec}(\\mathbf{B})}z_{i}\\ \\nabla_{z_{i}}\\ell(y_{i},z_{i})}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\mathbf{C}^{(K-1,p)}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a_{i}})\\,\\dot{\\mathbf{h}}(y_{i},z_{i}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "which verifies (69). ", "page_idx": 28}, {"type": "text", "text": "Next, we compute the gradients of $\\mathbf{K}$ in (66). First, using (68) and the chain rule (20), ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\,\\dot{\\mathbf{h}}(y_{i},z_{i})=\\nabla_{\\mathrm{vec}(\\mathbf{B})}z_{i}\\ \\nabla_{z_{i}}\\dot{\\mathbf{h}}(y_{i},z_{i})}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\mathbf{C}^{(K-1,p)}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a_{i}})\\dot{\\mathbf{h}}(y_{i},z_{i})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=(\\mathbf{u}_{a_{i}}\\otimes\\mathbf{x}_{i})\\ddot{\\mathbf{h}}(y_{i},z_{i}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the last equality uses commutation matrix relation (17). Then noting that $\\mathrm{vec}(\\mathbf{K})^{T}=\\mathbf{K}=$ $[{\\dot{\\mathbf{h}}}(y_{1},z_{1}),\\dots,{\\dot{\\mathbf{h}}}(y_{n},z_{n})]$ , it follows that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\operatorname{vec}(\\mathbf{K})^{T}\\overset{(a)}{=}\\Big[(\\mathbf{u}_{a_{1}}\\otimes\\mathbf{x}_{1})\\ddot{\\mathbf{h}}(y_{1},z_{1}),\\dots,(\\mathbf{u}_{a_{n}}\\otimes\\mathbf{x}_{n})\\ddot{\\mathbf{h}}(y_{n},z_{n})\\Big]}\\\\ &{\\overset{(b)}{=}[(\\mathbf{u}_{a_{1}}\\otimes\\mathbf{x}_{1}),\\dots,(\\mathbf{u}_{a_{n}}\\otimes\\mathbf{x}_{n})]\\operatorname{diag}\\Big(\\ddot{\\mathbf{h}}(y_{1},z_{1}),\\dots,\\ddot{\\mathbf{h}}(y_{n},z_{n})\\Big)}\\\\ &{\\overset{(c)}{=}\\Phi\\mathbf{M},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where (a) follows from (68) and the chain rule, (b) is an algebra, and (c) follows from the definition.   \nThis shows (70). ", "page_idx": 28}, {"type": "text", "text": "Now we compute the gradient: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\left[\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\,\\ell(y_{i},z_{i})\\right]\\stackrel{(a)}{=}\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\,\\left[\\mathbf{C}^{(K-1,p)}(\\mathbf{x}_{i}\\otimes\\mathbf{u}_{a})\\,\\dot{\\mathbf{h}}(y_{i},z_{i})\\right]}&{}\\\\ {\\stackrel{(b)}{=}\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}(\\mathbf{u}_{a_{i}}\\otimes\\mathbf{x}_{i})\\,\\dot{\\mathbf{h}}(y_{i},z_{i})}&{}\\\\ {=\\displaystyle\\frac{1}{n}\\left[w_{1}(\\mathbf{u}_{a_{1}}\\otimes\\mathbf{x}_{1}),\\dots,w_{n}(\\mathbf{u}_{a_{n}}\\otimes\\mathbf{x}_{n})\\right]\\left[\\dot{\\mathbf{h}}(y_{1},z_{1})\\right]}&{}\\\\ {\\vdots}&{}\\\\ {\\stackrel{(c)}{=}\\frac{1}{n}\\Phi\\mathbf{W}\\,\\mathrm{vec}(\\mathbf{K}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where (a) follows from (69), (b) uses the commutation matrix relation (17), and (c) follows from the definition. Then by using (72) and (18) with the fact that $\\dot{\\mathbf{h}}$ is a scalar, we deduce (66). ", "page_idx": 28}, {"type": "text", "text": "Next, we compute the Hessian. From (74), ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\nabla_{\\mathrm{vec}({\\bf B})}\\mathcal{L}({\\bf B})=\\frac{1}{n}\\Phi{\\mathbf{W}}\\,\\mathrm{vec}({\\mathbf{K}})+\\lambda_{2}\\,\\mathrm{vec}({\\bf B}).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Then using (69) with (75), we get ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\mathrm{vec}({\\bf B})}\\nabla_{\\mathrm{vec}({\\bf B})^{T}}\\mathcal{L}({\\bf B})=\\nabla_{\\mathrm{vec}({\\bf B})}\\left[\\frac{1}{n}\\,\\mathrm{vec}({\\bf K})^{T}{\\bf W}\\Phi^{T}+\\lambda_{2}{\\bf I}_{p(K-1)}\\right]}\\\\ &{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~=\\frac{1}{n}\\Phi({\\bf M}{\\bf W})\\Phi^{T}+\\lambda_{2}{\\bf I}_{p(K-1)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "This shows the assertion. ", "page_idx": 29}, {"type": "text", "text": "F.3 Proof of Lemma E.3 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "We are now ready to give proof of Lemma E.3. ", "page_idx": 29}, {"type": "text", "text": "Proof of Lemma E.3. Recall that $\\Phi:=[\\mathbf{u}_{a_{1}}\\otimes\\mathbf{x}_{1},\\dots,\\mathbf{u}_{a_{n}}\\otimes\\mathbf{x}_{n}]$ . Note that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{1}{n}\\Phi\\mathbf{W}\\Phi^{T}=\\frac{1}{n}\\sum_{i=1}^{n}w_{i}(\\mathbf{u}_{a_{i}}\\otimes\\mathbf{x}_{i})(\\mathbf{u}_{a_{i}}\\otimes\\mathbf{x}_{i})^{T}}}\\\\ &{}&{\\qquad=\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\big(\\mathbf{u}_{a_{i}}\\mathbf{u}_{a_{i}}^{T}\\otimes\\mathbf{x}_{i}\\mathbf{x}_{i}^{T}\\big)}\\\\ &{}&{\\qquad=\\Psi,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\Psi$ is the weighted design matrix defined at (8). (In particular, since $\\mathbf{W}$ is a diagonal matrix of nonnegative entries, this shows that $\\Psi$ is positive semi-definite.) ", "page_idx": 29}, {"type": "text", "text": "According to Propositions F.1 and F.2, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\nabla_{\\mathrm{vec}(\\mathbf{B})}\\nabla_{\\mathrm{vec}(\\mathbf{B})^{T}}{\\mathcal{L}}(\\mathbf{B})={\\left\\{\\begin{array}{l l}{n^{-1}\\Phi\\mathbf{W}\\Phi^{T}+\\lambda_{2}\\mathbf{I}_{p(K-1)}}&{{\\mathrm{for~continuous~outcome}}}\\\\ {n^{-1}\\Phi\\mathbf{M}\\mathbf{W}\\Phi^{T}+\\lambda_{2}\\mathbf{I}_{p(K-1)}}&{{\\mathrm{for~binary~outcome}}.}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Thus the assertion for the continuous outcome follows immediately. For the case of a binary outcome, by Assumption 3.2 we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\alpha^{-}\\mathbf{I}_{n}\\preceq\\mathbf{M}\\preceq\\alpha^{+}\\mathbf{I}_{n}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Then ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\alpha^{-}\\left(\\frac{1}{n}\\Phi\\mathbf{W}\\Phi^{T}\\right)\\preceq\\frac{1}{n}\\Phi(\\mathbf{M}\\mathbf{W})\\Phi^{T}\\preceq\\alpha^{+}\\left(\\frac{1}{n}\\Phi\\mathbf{W}\\Phi^{T}\\right).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "It follows that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\alpha^{-}\\lambda_{\\operatorname*{min}}\\left(\\frac1n\\Phi\\mathbf{W}\\Phi^{T}\\right)\\mathbf{I}_{p(K-1)}\\preceq\\frac1n\\Phi(\\mathbf{M}\\mathbf{W})\\Phi^{T}\\preceq\\alpha^{+}\\lambda_{\\operatorname*{max}}\\left(\\frac1n\\Phi\\mathbf{W}\\Phi^{T}\\right)\\mathbf{I}_{p(K-1)}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "This shows the assertion for the binary outcome holds. ", "page_idx": 29}, {"type": "text", "text": "G A non-asymptotic consistency of weighted, constrained, and regularized MLE ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In this section, we provide a general result on the non-asymptotic consistency of MLE in a general setting. Here, observations are assumed to be i.i.d. from a generative model, and the unknown true parameter of the generative model may lie on the boundary of the parameter space. ", "page_idx": 30}, {"type": "text", "text": "A generic sample $(X,Y)$ consists of a random covariate $X$ and outcome $Y$ . (In the ITR setting, we will specialize $X$ to be the pair of the patient\u2019s covariate and the corresponding treatment.) We assume the covariate $X$ follows a probability distribution $\\mu(\\cdot)$ and the conditional distribution of $Y$ given $X\\,=\\,x$ is parameterized as $\\pi_{\\pmb{\\theta}_{\\star}}(\\cdot\\mid x)$ for an unknown parameter $\\theta_{\\star}$ . Hence the generic random sample $(X,Y)$ follows the parameterized distribution $\\pi_{\\pmb{\\theta}_{\\star}}(y\\,|\\,x)\\mu(x)$ . Assume we know a smooth parametric family of conditional distributions $\\theta\\mapsto\\pi_{\\theta}(\\cdot\\,|\\,x)$ , where the true parameter $\\theta_{\\star}$ lies in a convex parameter space $\\Theta\\subseteq\\mathbb{R}^{d}$ . Our goal is to estimate $\\theta_{\\star}$ from i.i.d. samples $(x_{i},y_{i})$ , $i=1,\\hdots,n$ drawn from $\\pi_{\\pmb\\theta_{\\star}}(\\cdot\\mid\\cdot)\\mu(\\cdot)$ . ", "page_idx": 30}, {"type": "text", "text": "To estimate $\\theta_{\\star}$ , a natural approach is to maximize the empirical joint likelihood function. Since the marginal distribution of the covariate $x$ is independent of the parameter $\\pmb{\\theta}$ , we can apply the method of \u201creweighting\u201d the covariate distribution by introducing an additional random weight $\\omega(x)$ that we can control. Namely, fix a weighting function $\\omega(\\cdot):\\bar{\\mathscr{X}}\\rightarrow[0,\\infty)$ , where $\\mathcal{X}$ is covariate space, that assigns a nonnegative weight to each covariate value $x$ . Consider then the following weighted expected log-likelihood maximization problem: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{arg\\,min}_{\\pmb{\\theta}\\in\\Theta}\\,\\mathbb{E}_{(X,Y)}\\left[-\\omega(X)\\log\\pi_{\\pmb{\\theta}_{\\star}}(Y\\,|\\,X)\\right],\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where we omit the marginal distribution $\\mu(X)$ as it is independent of $\\pmb{\\theta}$ . ", "page_idx": 30}, {"type": "text", "text": "Recall that we get to design the weighting function $\\omega(\\cdot)$ . We first observe that the true parameter $\\theta_{\\star}$ is a stationary point of the weighted expected log-likelihood function $\\mathbb{E}\\left[-\\omega(X)\\log\\pi_{\\pmb{\\theta}_{\\star}}(Y\\,|\\,X)\\right]$ for arbitrary weighting function $\\omega$ . This can be justified under the mild assumption of exchangeability of the expectation and derivatives (which holds under twice continuous differentiability of the log-likelihood function by the dominated convergence theorem). Indeed, note that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{(X,Y)}\\left[\\omega(X)\\nabla_{\\theta}\\log\\pi_{\\theta}(Y\\mid X)\\right]=\\mathbb{E}_{(X,Y)}\\left[\\omega(X)\\frac{\\nabla_{\\theta}\\pi_{\\theta}(Y\\mid X)}{\\pi_{\\theta}(Y\\mid X)}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}_{X}\\left[\\mathbb{E}_{Y}\\left[\\omega(X)\\frac{\\nabla_{\\theta}\\pi(Y\\mid X)}{\\pi_{\\theta}(Y\\mid X)}\\,\\bigg\\vert\\,X\\right]\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}_{X}\\left[\\omega(X)\\,\\mathbb{E}_{Y\\sim\\pi_{\\theta_{\\star}}(\\cdot\\,\\mid X)}\\left[\\frac{\\nabla_{\\theta}\\pi_{\\theta}(Y\\mid X)}{\\pi_{\\theta}(Y\\mid X)}\\,\\bigg\\vert\\,X\\right]\\right]=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where the last equality follows from ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{E}_{Y\\sim\\pi_{\\theta_{\\star}}(\\cdot\\,|\\,X)}\\left[\\frac{\\nabla_{\\theta}\\pi_{\\theta_{\\star}}(Y|X)}{\\pi_{\\theta_{\\star}}(Y\\,|\\,X)}\\,\\bigg|\\,X\\right]=\\int\\nabla_{\\theta}\\pi_{\\theta_{\\star}}(y\\,|\\,X)\\,d y\\,}&{}&\\\\ {=\\nabla_{\\theta}\\int\\pi_{\\theta_{\\star}}(y\\,|\\,X)\\,d y\\,}&{}&\\\\ {=\\nabla_{\\theta}1=0.}&{}&\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Therefore, $\\theta_{\\star}$ is a critical point of $\\mathbb{E}\\left[\\omega(X)\\log\\pi_{\\theta}(Y\\,|\\,X)\\right]$ . In particular, if we assume that the log-likelihood function $\\log\\pi_{\\theta}(y\\mid x)\\mu(x)$ is convex in $\\pmb{\\theta}$ , then $\\theta_{\\star}$ is a global maximizer of $\\mathbb{E}\\left[\\omega(\\bar{X})\\log\\pi_{\\theta}(Y\\,|\\,X)\\right]$ . ", "page_idx": 30}, {"type": "text", "text": "Next, we introduce the finite-sample approximation of (85). Denote $w_{i}:=\\omega(x_{i})$ for the weight of the ith sample $\\left({x_{i},y_{i}}\\right)$ . Then the weighted negative log-likelihood of the observed samples under the model parameter $\\pmb{\\theta}$ is ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\pmb{\\theta}):=-\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\underbrace{\\log\\pi_{\\pmb{\\theta}}(y_{i}\\mid\\mathbf{x}_{i})}_{=:\\mathcal{L}_{0}(\\pmb{\\theta})}+R(\\pmb{\\theta}),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $R(\\theta)$ is a suitable choice of regularizer for parameter $\\pmb{\\theta}$ . The regularization term can be considered as prior knowledge about the model parameter $\\pmb{\\theta}$ . ", "page_idx": 30}, {"type": "text", "text": "Let $\\hat{\\pmb{\\theta}}_{n}$ denote a (possibly non-unique) minimizer of the above function over $\\Theta$ . This is a minimizer of the loss function $\\mathcal{L}$ over the constraint set $\\Theta$ , which we call the weighted, constrained, and regularized MLE of $\\theta_{\\star}$ . ", "page_idx": 31}, {"type": "text", "text": "As in the standard MLE analysis, we assume that the negative log-likelihood function $\\theta\\mapsto\\mathcal{L}_{0}(\\theta)$ is differentiable and strictly convex for all $x\\in\\mathbb{R}^{p}$ . Statistical literature typically assumes that the true parameter lies in the interior of the constrained parameter space, $\\Theta$ , a convex subset of $\\mathbb{R}^{d}$ . In contrast, we allow the true parameter $\\theta_{\\star}$ to lie on the boundary of $\\Theta$ . Regardless of that, we have seen above that the gradient of the weighted expected log-likelihood function vanishes at the true parameter $\\theta_{\\star}$ . ", "page_idx": 31}, {"type": "text", "text": "In this setting, we aim to provide a high-probability guarantee that there exists a global minimizer of (86) that is close to the true parameter $\\theta_{\\star}$ for an arbitrary weighting function $\\omega(\\cdot)$ , which we will optimize later for the best statistical guarantee. In Theorem G.1 below, we obtain such a result in the non-asymptotic, weighted, constrained, and regularized setting. For its proof, we combine a classical approach from [15] with concentration inequalities, namely, a classical Berry-Esseen bound for deviations from the standard normal distribution for independent but non-identically distributed random variables and a uniform McDirmid bound (Lemma G.2). The Berry-Esseen bound controls the linear term in the second-order Taylor expansion of the log-likelihood function $(T_{n}(\\pmb\\theta)$ in (99)), while the McDirmid bound controls the quadratic term $S_{n}(\\pmb\\theta)$ in (99)). By using an $\\varepsilon$ -net argument, the latter concentration inequality can be extended to a setting where the random variables are parameterized within a compact set. ", "page_idx": 31}, {"type": "text", "text": "Theorem G.1 (Non-asymptotic consistency of weighted, constrained, and regularized MLE). Consider the constrained, regularized, and weighted MLE problem (86) with unknown parameter $\\theta_{\\star}$ from a convex subset $\\Theta\\subseteq\\mathbb{R}^{\\breve{d}}$ . Fix an arbitrary weighting function $\\omega(\\cdot)$ . Assume the following holds: ", "page_idx": 31}, {"type": "text", "text": "(a1) (Smoothness) For each sample $(x,y)$ , the per-sample negative log-likelihood function $\\pmb\\theta\\mapsto$ $\\log\\pi_{\\theta}(y\\mid x)\\mu(x)$ is strictly convex, three-times continuously differentiable, and $R(\\theta)$ is differentiable. Furthermore, denote $U:=\\omega(X)\\nabla_{\\pmb\\theta}\\log\\pi_{\\pmb\\theta_{\\star}}(Y\\,|\\,X)\\in\\mathbb{R}^{d}$ and $\\overline{{U}}:=U-$ $\\mathbb{E}[U]$ . Suppose there are constants $D_{1},d_{1}\\in(0,\\infty)$ such that for all $i$ , ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\|\\overline{{U}}\\|^{3}]<D_{1},\\qquad\\operatorname*{min}_{1\\leq k\\leq d}{\\mathrm{Var}}(U(k))>d_{1}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "(a2) (First-order optimality) The true parameter $\\theta_{\\star}$ is a stationary point of the expected negative weighted log-likelihood function $\\overline{{\\mathcal{L}}}_{0}(\\pmb{\\theta}):=\\mathbb{E}_{\\pmb{\\theta}_{\\star}}\\left[-\\omega(X)\\log\\pi_{\\pmb{\\theta}}(Y\\mid X)\\right]$ over $\\Theta$ : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\langle\\nabla_{\\theta}\\,\\overline{{\\mathcal{L}}}_{0}(\\pmb{\\theta}_{\\star}),\\,\\theta-\\pmb{\\theta}_{\\star}\\rangle\\geq0\\quad\\forall\\pmb{\\theta}\\in\\pmb{\\Theta}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "(a3) (Approximate second-order optimality) Let $\\bar{\\mathcal{L}}(\\pmb{\\theta}):=\\overline{{\\mathcal{L}}}_{0}(\\pmb{\\theta})+R(\\pmb{\\theta})$ denote the expected regularized negative log- likelihood function. Then the regularized Fisher information $\\nabla^{2}\\bar{\\mathcal{L}}(\\pmb{\\theta})$ is positive definite at $\\theta=\\theta_{\\star}$ with minimum eigenvalue $\\rho>0$ . ", "page_idx": 31}, {"type": "text", "text": "Fix a constant $C>0$ . Let $\\begin{array}{r}{D=C n^{-1/2}+\\frac{8\\|\\nabla R(\\pmb{\\theta}_{\\star})\\|}{\\rho}}\\end{array}$ and $M=M(D)>0$ denote the supremum of the absolute values of all third-order partial derivatives of $\\mathcal{L}$ over all $\\pmb{\\theta}$ with $\\lVert\\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\rVert\\leq D$ . Suppose $\\lVert\\nabla R(\\pmb\\theta_{\\star})\\rVert$ is small enough so that ", "page_idx": 31}, {"type": "equation", "text": "$$\nD\\leq{\\frac{3\\rho}{4M(D)}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Then there are constants $c_{1},c_{2},c_{3}>0$ such that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left(\\left\\|\\theta_{\\star}-\\underset{\\theta\\in\\Theta}{\\mathrm{arg}\\operatorname*{min}}\\,\\mathcal{L}(\\theta)\\right\\|\\leq D\\right)\\geq1-c_{1}\\exp\\left(-\\frac{C^{2}\\rho^{2}}{2\\cdot32^{2}d}\\right)-\\frac{c_{2}\\sum_{i=1}^{n}w_{i}^{3}}{\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}}\\\\ {-\\,O(\\exp(-c_{3}n)).\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "That is, with high probability explicitly depending on $C,\\,\\rho,\\,d,$ , and $n,$ , there exists a global minimizer of $\\theta\\mapsto\\mathcal{L}(\\theta)$ in $\\Theta$ within distance $D$ from $\\theta_{\\star}$ . ", "page_idx": 31}, {"type": "text", "text": "It is important to notice that the minimum eigenvalue $\\rho$ of the weighted regularized Fisher information $\\nabla^{2}\\overline{{\\mathcal{L}}}(\\pmb{\\theta})$ depends on the choice of weighting function $\\omega(\\cdot)$ . Therefore, Theorem G.1 suggests that ", "page_idx": 31}, {"type": "text", "text": "it is best to choose the weighting function to maximize the minimum eigenvalue of the weighted regularized Fisher information in order to minimize the statistical estimation error. We elaborate more on this point in the proof of Theorem 3.5. ", "page_idx": 32}, {"type": "text", "text": "We devote the rest of this section to proving Theorem G.1 using Lemma G.2 and Theorem G.3. ", "page_idx": 32}, {"type": "text", "text": "Lemma G.2 (A uniform McDirmid\u2019s inequality). Let $\\mathbf{X}_{1},\\ldots,\\mathbf{X}_{n}$ be independent random vectors in $\\mathbb{R}^{p}$ from a joint distribution $\\pi$ . Fix a compact parameter space $\\Theta\\subseteq\\mathbb{R}^{d}$ and $f_{\\theta}:\\mathbb{R}^{d}\\rightarrow[-J,J]$ is a bounded functional for each $\\theta\\in\\Theta$ such that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\lVert f_{\\pmb{\\theta}}-f_{\\pmb{\\theta}^{\\prime}}\\rVert_{\\infty}\\leq L\\lVert\\pmb{\\theta}-\\pmb{\\theta}^{\\prime}\\rVert,\\qquad\\forall\\pmb{\\theta},\\pmb{\\theta}^{\\prime}\\in\\Theta\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "for some constant $L>0$ . Further assume that $\\mathbb{E}[f_{\\theta}(\\mathbf{X}_{k})]=0$ for all $\\theta\\,\\in\\,\\Theta$ and $k=1,\\hdots,n$ . Then there exist constant $J>0$ such that for each $n\\geq0$ , and $\\eta>0$ , ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{sup}_{\\theta\\in\\Theta}\\left\\vert\\frac{1}{n}\\sum_{k=1}^{n}f_{\\theta}(\\mathbf{X}_{k})\\right\\vert\\geq\\eta\\right)\\leq\\left(\\frac{2L\\operatorname{diam}(\\Theta)}{\\eta}\\right)^{d}\\exp\\left(-\\frac{\\eta^{2}n}{2J^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Proof. Since $\\Theta\\subseteq\\mathbb{R}^{d}$ is compact, it can be covered by a finite number of $L_{2}$ -balls of any given radius $\\varepsilon>0$ . Let $\\mathcal{U}_{\\varepsilon}$ be such an open cover using the least number of balls of radius $\\varepsilon>0$ . Let $N(\\varepsilon)=|\\mathcal{U}_{\\varepsilon}|$ denote the least number of such balls to cover $\\Theta$ . Moreover, let $\\dim(\\Theta)$ denote the diameter of $\\Theta$ , which is finite since $\\Theta$ is compact. Then $\\Theta$ is contained in a $d$ -dimensional box of side length $\\dim(\\Theta)$ . This box can be covered by $(\\mathrm{diam}(\\Theta)/\\varepsilon)^{d}$ cubes of side length $\\varepsilon$ . Covering each such cube of side length $\\varepsilon$ by a ball of radius $\\varepsilon$ , it follows that ", "page_idx": 32}, {"type": "equation", "text": "$$\nN(\\varepsilon)\\leq\\left(\\frac{\\mathrm{diam}(\\Theta)}{\\varepsilon}\\right)^{d}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Next, fix $\\eta>0,\\,\\pmb\\theta\\,\\in\\,\\Theta,$ , and $\\varepsilon>0$ . Let $\\theta_{1},\\dots,\\theta_{N(\\varepsilon)}$ be the centers of balls in the open cover $\\mathcal{U}_{\\varepsilon}$ . Then there exists $1\\leq j\\leq N(\\varepsilon)$ such that $\\|\\pmb{\\theta}-\\pmb{\\theta}_{j}\\|<\\varepsilon$ . By the hypothesis, $f_{\\theta}$ depends on $\\pmb{\\theta}$ uniformly continuously with respect to the supremum norm. Hence there exists $\\delta=\\delta(\\varepsilon)>0$ such that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\|f_{\\theta}-f_{\\theta_{j}}\\|_{\\infty}\\leq L\\varepsilon.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Denote $\\begin{array}{r}{H_{n}(\\pmb\\theta):=n^{-1}\\sum_{k=1}^{n}f_{\\pmb\\theta}(\\mathbf X_{k})}\\end{array}$ . Then this yields, almost surely, ", "page_idx": 32}, {"type": "equation", "text": "$$\n|H_{n}(\\pmb\\theta)-H_{n}(\\pmb\\theta_{j})|\\leq L\\varepsilon.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Furthermore, by the assumption, $\\|f_{\\theta}\\|_{\\infty}$ is uniformly bounded by $J>0$ . It follows that for each $\\theta\\:\\in\\:\\Theta$ , $H_{n}(\\pmb\\theta)$ changes its value at most by $M$ when one of $\\mathbf{X}_{1},\\ldots,\\mathbf{X}_{n}$ is replaced arbitrarily. Therefore, by the standard McDirmid\u2019s inequality (see Theorem 2.9.1. in [51]) and a union bound, with choosing $\\varepsilon=\\eta/(2L)$ , ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(|H_{n}(\\pmb\\theta)|\\geq\\eta\\right)\\leq\\sum_{j=1}^{N(\\eta/2L)}\\mathbb{P}\\left(|H_{n}(\\pmb\\theta_{j})|\\geq\\eta/2\\right)\\leq K\\left(\\frac{2L\\,\\mathrm{diam}(\\pmb\\Theta)}{\\eta}\\right)^{d}\\exp\\left(-\\frac{\\eta^{2}n}{2J^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "The above holds for all $n\\geq1$ and $\\eta>0$ . This shows the assertion. ", "page_idx": 32}, {"type": "text", "text": "Next, we recall the classical Berry-Esseen theorem for the rate of convergence of normal approximation for the sum of independent random variables due to Feller. ", "page_idx": 32}, {"type": "text", "text": "Theorem G.3 (Berry-Esseen, Theorem 2 in Ch. XVI.5 of Feller \u201991[17]). Let $X_{1},X_{2},\\ldots,X_{n}$ be independent and not necessarily identically distributed random variables with zero means and finite variances. Define $\\textstyle W=\\sum_{i=1}^{n}X_{i}$ let $F$ be the distribution function of $W$ and $\\Phi$ be the standard normal distribution funct ion. Then ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\|F-\\Phi\\|_{\\infty}\\leq\\frac{6\\sum_{i=1}^{n}\\mathbb{E}[|X_{i}|^{3}]}{\\left(\\sum_{i=1}^{n}\\mathbb{E}[X_{i}^{2}]\\right)^{3/2}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Now we prove Theorem G.1. ", "page_idx": 32}, {"type": "text", "text": "Proof of Theorem G.1. Suppose we have $n$ i.i.d. observed samples $\\left({x_{i},y_{i}}\\right)$ for $i=1,\\hdots,n$ from distribution $\\pi_{\\theta_{\\star}}(y\\,|\\,x)\\mu(x)$ . Also by the assumption, $\\scriptstyle{\\mathcal{L}}_{0}$ is twice continuously differentiable and $\\begin{array}{r}{n^{-1}\\sum_{i=1}^{n}w_{i}=\\overset{\\cdot}{1}}\\end{array}$ , so $\\dot{\\mathbb{E}}[\\overleftarrow{\\nabla}\\mathcal{L}_{0}]=\\nabla\\dot{\\mathbb{E}}[\\mathcal{L}_{0}]$ and $\\mathbb{E}[\\nabla^{2}\\mathcal{L}_{0}]=\\nabla^{2}\\mathbb{E}[\\mathcal{L}_{0}]$ by the dominated convergence theorem. ", "page_idx": 33}, {"type": "text", "text": "Note that, for any $r>0$ , ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\left\\{\\left\\|\\theta_{\\star}-\\underset{\\theta\\in\\Theta}{\\operatorname{arg\\,min}}\\,\\mathcal{L}(\\theta)\\right\\|\\leq r\\right\\}=\\left\\{\\underset{\\|\\theta-\\theta_{\\star}\\|=r}{\\operatorname*{inf}}\\,\\mathcal{L}(\\theta)-\\mathcal{L}(\\theta_{\\star})>0\\right\\}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The inclusion $\\subseteq$ is clear. Conversely, since $\\mathcal{L}$ is strictly convex, the event on the right implies that its unique global minimizer is within $r$ from $\\theta_{\\star}$ , as desired. Thus in order to show the main result in (90), it suffices to show that the probability of the event on the right with $\\begin{array}{r}{r=D=C n^{-1/2}+\\frac{8\\|\\nabla R(\\pmb{\\theta}_{\\star})\\|}{\\rho}}\\end{array}$ is at least the right-hand side of (90). ", "page_idx": 33}, {"type": "text", "text": "Fix $\\theta\\in\\Theta$ such that $\\lVert\\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\rVert=D$ . We introduce two random variables that we will bound to be small by using some concentration inequalities: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{l}{T_{n}(\\theta):=\\displaystyle\\frac{\\sqrt{n}}{\\|\\theta-\\theta_{\\star}\\|}\\left\\langle\\nabla_{\\theta}\\mathcal{L}_{0}(\\theta_{\\star})-\\mathbb{E}\\left[\\omega(X)\\nabla_{\\theta}\\mathcal{L}_{0}(\\theta_{\\star})\\right],\\,\\theta-\\theta_{\\star}\\right\\rangle,}\\\\ {S_{n}(\\theta):=\\displaystyle\\frac{1}{\\|\\theta-\\theta_{\\star}\\|^{2}}(\\theta-\\theta_{\\star})^{T}\\left(\\nabla_{\\theta}\\nabla_{\\theta^{T}}\\mathcal{L}(\\theta_{\\star})-\\nabla_{\\theta}\\nabla_{\\theta^{T}}\\left(\\mathbb{E}\\left[\\omega(X)\\mathcal{L}(\\theta_{\\star})\\right]\\right)\\right)(\\theta-\\theta_{\\star}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Roughly speaking, these quantities are of order 1 with high probability, $T_{n}$ by Central Limit Theorem and $S_{n}$ by the law of large numbers. Later in this proof, we will use non-asymptotic versions of these classical limit theorems to obtain high probability bounds for related quantities. ", "page_idx": 33}, {"type": "text", "text": "Since $\\theta\\mapsto\\mathcal{L}(\\theta)$ is assumed to be three-time continuously differentiable, the quantity $M\\geq0$ in the assertion is well-defined and is finite. Then, using the Taylor expansion, we may write ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}(\\pmb{\\theta})-\\mathcal{L}(\\pmb{\\theta}_{\\star})\\geq\\langle\\nabla_{\\pmb{\\theta}}\\mathcal{L}(\\pmb{\\theta}_{\\star}),\\ \\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\rangle+\\frac{1}{2}(\\pmb{\\theta}-\\pmb{\\theta}_{\\star})^{T}\\nabla_{\\pmb{\\theta}}\\nabla_{\\pmb{\\theta}^{T}}\\mathcal{L}(\\pmb{\\theta}_{\\star})(\\pmb{\\theta}-\\pmb{\\theta}_{\\star})}\\\\ &{\\phantom{\\mathcal{L}(\\pmb{\\theta})-\\mathcal{L}(\\pmb{\\theta}_{\\star})\\geq}-\\frac{M(\\|\\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\|)}{6}\\|\\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\|^{3}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We will lower bound the first two terms on the right-hand side above. Note that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\nabla_{\\theta}\\mathcal{L}(\\theta_{\\star}),\\,\\theta-\\theta_{\\star}\\rangle=\\langle\\nabla_{\\theta}\\mathcal{L}_{0}(\\theta_{\\star}),\\,\\theta-\\theta_{\\star}\\rangle-\\mathbb{E}\\left[\\omega(X)\\langle\\nabla_{\\theta}\\mathcal{L}_{0}(\\theta_{\\star}),\\,\\theta-\\theta_{\\star}\\rangle\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\quad+\\,\\langle\\nabla_{\\theta}\\mathbb{E}[\\omega(X)\\mathcal{L}_{0}(\\theta_{\\star})],\\,\\theta-\\theta_{\\star}\\rangle+\\langle\\nabla R(\\theta_{\\star}),\\,\\theta-\\theta_{\\star}\\rangle}\\\\ &{\\stackrel{(a)}{\\geq}\\langle\\nabla_{\\theta}\\mathcal{L}_{0}(\\theta_{\\star}),\\,\\theta-\\theta_{\\star}\\rangle-\\mathbb{E}\\left[\\omega(X)\\langle\\nabla_{\\theta}\\mathcal{L}_{0}(\\theta_{\\star}),\\,\\theta-\\theta_{\\star}\\rangle\\right]}\\\\ &{\\quad\\quad\\quad\\quad-\\|\\nabla R(\\theta_{\\star})\\|\\cdot\\|\\theta-\\theta_{\\star}\\|}\\\\ &{\\stackrel{(b)}{=}-\\frac{\\|\\theta-\\theta_{\\star}\\|}{\\sqrt{n}}\\,T_{n}(\\theta)-\\|\\nabla R(\\theta_{\\star})\\|\\cdot\\|\\theta-\\theta_{\\star}\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where for (a) we use the fact that $\\theta_{\\star}$ is a stationary point of $\\mathbb{E}[\\mathcal{L}_{0}(\\pmb{\\theta})]$ over $\\Theta$ and Cauchy-Schwarz inequality; for (b) we use the definition of $T_{n}(\\pmb\\theta)$ . ", "page_idx": 33}, {"type": "text", "text": "Next, we turn our attention to the second-order term in the Taylor expansion (101). Recall that from the assumption (a3) in Theorem G.1, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\omega(X)\\nabla_{\\theta}\\nabla_{\\theta^{T}}\\mathcal{L}(\\theta_{\\star})\\right]=\\nabla_{\\theta}\\nabla_{\\theta^{T}}\\left(\\mathbb{E}\\left[\\omega(X)\\mathcal{L}(\\theta_{\\star})\\right]\\right)\\succeq\\rho\\mathbf{I}_{p},}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $\\rho>0$ is a constant. It follows that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\theta-\\theta_{\\star})^{T}\\nabla_{\\theta}\\nabla_{\\theta^{T}}\\mathcal{L}(\\theta_{\\star})(\\theta-\\theta_{\\star})}\\\\ &{\\quad\\ge(\\theta-\\theta_{\\star})^{T}\\left[\\nabla_{\\theta}\\nabla_{\\theta^{T}}\\mathcal{L}(\\theta_{\\star})-\\nabla_{\\theta}\\nabla_{\\theta^{T}}\\left(\\mathbb{E}\\left[\\omega(X)\\mathcal{L}(\\theta_{\\star})\\right]\\right)\\right](\\theta-\\theta_{\\star})+{\\rho}{\\|\\theta-\\theta_{\\star}\\|}^{2}}\\\\ &{\\quad\\ge\\|\\theta-\\theta_{\\star}\\|^{2}\\left(S_{n}(\\theta)+{\\rho}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Combining the above inequalities with noting that $\\lVert\\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\rVert^{2}=D^{2}$ , we obtain ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\mathcal{L}(\\theta)-\\mathcal{L}(\\theta_{\\star})}{\\|\\theta-\\theta_{\\star}\\|^{2}}}\\\\ &{\\phantom{\\quad}\\ge\\frac{1}{\\|\\theta-\\theta_{\\star}\\|^{2}}\\left[\\langle\\nabla_{\\theta}\\mathcal{L}(\\theta_{\\star}),\\theta-\\theta_{\\star}\\rangle+\\frac{1}{2}(\\theta-\\theta_{\\star})^{T}\\nabla_{\\theta}\\nabla_{\\theta}r\\mathcal{L}(\\theta_{\\star})(\\theta-\\theta_{\\star})\\right.}\\\\ &{\\phantom{\\quad}\\quad\\quad\\quad\\quad\\quad\\left.-\\frac{M(\\|\\theta-\\theta_{\\star}\\|)}{6}\\|\\theta-\\theta_{\\star}\\|^{3}\\right]}\\\\ &{\\phantom{\\quad}\\ge-\\frac{1}{\\|\\theta-\\theta_{\\star}\\|}\\left[\\frac{T_{n}(\\theta)}{\\sqrt{n}}+\\|\\nabla R(\\theta_{\\star})\\|\\right]+\\frac{1}{2}(S_{n}(\\theta)+\\rho)-\\frac{M(\\|\\theta-\\theta_{\\star}\\|)}{6}\\|\\theta-\\theta_{\\star}\\|}\\\\ &{\\phantom{\\quad}=\\frac{1}{\\|\\theta-\\theta_{\\star}\\|}\\left(-\\|\\nabla R(\\theta_{\\star})\\|+\\frac{\\rho}{4}D-\\frac{M(D)}{6}D^{2}\\right)+\\left(\\frac{1}{2}\\left(S_{n}(\\theta)+\\frac{\\rho}{2}\\right)-\\frac{1}{\\sqrt{n}}T_{n}(\\theta)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Note that $I_{1}\\geq0$ if ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\frac{\\rho}{8}D\\geq\\|\\nabla R(\\pmb{\\theta}_{\\star})\\|\\quad\\mathrm{and}\\quad\\frac{\\rho}{8}D\\geq\\frac{M(D)}{6}D^{2}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The choice of $D$ holds the former condition, and the latter by the assumption (89). Thus, $I_{1}\\geq0$ . ", "page_idx": 34}, {"type": "text", "text": "We now take infimum over all $\\pmb\\theta\\in\\Theta$ such that $\\lVert\\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\rVert=D$ . It suffices to show that the random variable $I_{2}$ defined above is positive with high probability, since $I_{1}$ does not depend on $\\pmb{\\theta}$ . To this end, write ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\|\\theta-\\theta_{*}\\|=D}I_{2}\\geq\\underbrace{\\left(\\operatorname*{inf}_{\\|\\theta-\\theta_{*}\\|=D}-\\frac{1}{\\sqrt{n}D}T_{n}(\\theta)\\right)}_{=:A}+\\underbrace{\\left(\\operatorname*{inf}_{\\|\\theta-\\theta_{*}\\|=D}\\frac{1}{2}\\left(S_{n}(\\theta)+\\frac{\\rho}{2}\\right)\\right)}_{=:B}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Then the last expression in (106) is at least $\\rho/16$ if $A\\geq-\\rho/16$ and $B\\geq\\rho/8$ . By the hypothesis, $D=O(1)$ so it is uniformly bounded. Then by the uniform McDirmid\u2019s inequality in Lemma G.2, there exist constants $C^{\\prime},C^{\\prime\\prime}>0$ such that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(B<\\frac{\\rho}{8}\\right)=\\mathbb{P}\\left(\\operatorname*{inf}_{\\|\\theta-\\theta_{*}\\|=D}S_{n}(\\theta)<-\\frac{\\rho}{4}\\right)\\leq D^{d}C^{\\prime}\\exp(-C^{\\prime\\prime}n).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Next, we will show the following inequalities: For $K=6D_{1}/d_{1}^{3/2}$ , ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{P}\\left(A<-\\frac{\\rho}{16}\\right)=\\mathbb{P}\\left(\\underset{1\\not=0,-1}{\\operatorname*{inf}}T_{n}(\\theta)\\geq\\frac{\\sqrt{n}D\\rho}{16}\\right)}&{}\\\\ {\\overset{\\mathrm{(c)}}{\\leq}d\\left(\\mathbb{P}\\left(Z\\geq\\frac{\\sqrt{n}D\\rho}{32\\sqrt{d}}\\right)+\\frac{K\\sum_{i=1}^{n}w_{i}^{3}}{\\sqrt{n}\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\right)}&{}\\\\ {\\overset{(d)}{\\leq}d\\left(\\frac{32\\sqrt{d}}{C\\rho\\sqrt{2}\\pi}\\exp\\left(-\\frac{n D^{2}\\rho^{2}}{2\\cdot32^{2}d}\\right)+\\frac{K\\sum_{i=1}^{n}w_{i}^{3}}{\\sqrt{n}\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\right)}&{}\\\\ {\\overset{(e)}{\\leq}d\\left(\\frac{32\\sqrt{d}}{C\\rho\\sqrt{2}\\pi}\\exp\\left(-\\frac{C^{2}\\rho^{2}}{2\\cdot32^{2}d}\\right)+\\frac{K\\sum_{i=1}^{n}w_{i}^{3}}{\\sqrt{n}\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $Z\\,\\sim\\,N(0,1)$ is an independent standard normal random variable. (d) above is a simple consequence of the standard Gaussian tail bound P(N(0, 1) > x) \u2264ex\u2212\u221ax22/\u03c02 and (d), (e) are from the choice of $D$ which yields $n D^{2}\\geq C^{2}$ . We will show (c) at the end of this proof. Note that for any two events $E_{1},E_{2}$ defined on the same probability space, $\\mathbb{P}(E_{1}\\cap E_{2})\\geq\\mathbb{P}(\\bar{E}_{1})+\\mathbb{P}(E_{2})-1$ . Then ", "page_idx": 34}, {"type": "text", "text": "by combining (106), (107), and (108), we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\displaystyle\\left(\\operatorname*{inf}_{\\|{\\boldsymbol{\\theta}}-{\\boldsymbol{\\phi}}_{+}^{\\top}\\|={\\boldsymbol{D}}}\\frac{\\mathcal{L}({\\boldsymbol{\\theta}})-\\mathcal{L}({\\boldsymbol{\\theta}}_{\\star})}{\\|{\\boldsymbol{\\theta}}-{\\boldsymbol{\\theta}}_{\\star}\\|^{2}}\\geq\\frac{\\rho}{16}\\right)}\\\\ &{\\quad\\geq\\mathbb{P}\\left(A\\geq-\\frac{\\rho}{16}\\right)+\\mathbb{P}\\left(B\\geq\\frac{\\rho}{8}\\right)-1}\\\\ &{\\quad\\geq1-d\\left(\\frac{32\\sqrt{d}}{C\\rho\\sqrt{2\\pi}}\\exp\\left(-\\frac{C^{2}\\rho^{2}}{2\\cdot32^{2}d}\\right)+\\frac{K\\sum_{i=1}^{n}w_{i}^{3}}{(\\sum_{i=1}^{n}w_{i}^{2})^{3/2}}\\right)+\\left(1-D^{d}C^{\\prime}\\exp(-C^{\\prime\\prime}n)\\right)-1}\\\\ &{\\quad=1-c_{1}\\exp\\left(-\\frac{C^{2}\\rho^{2}}{2\\cdot32^{2}d}\\right)-\\frac{c_{2}\\sum_{i=1}^{n}w_{i}^{3}}{(\\sum_{i=1}^{n}w_{i}^{2})^{3/2}}-O(\\exp(-c_{3}n)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "with the corresponding constants $c_{1},c_{2},c_{3}>0$ . Then the assertion (90) will follow using (98). It remains to verify (c) in (108). To this end, write ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}\\mathcal{L}_{0}(\\pmb{\\theta}_{\\star})-\\mathbb{E}\\left[\\omega(X)\\nabla_{\\theta}\\mathcal{L}_{0}(\\pmb{\\theta}_{\\star})\\right]=-\\frac{1}{n}\\sum_{i=1}^{n}w_{i}\\overline{{U}}_{i},\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $U_{i}=\\omega(X_{i})\\nabla_{\\theta}\\log\\pi_{\\pmb\\theta_{\\star}}(Y_{i}\\,|\\,X_{i})\\in\\mathbb{R}^{d}$ and $\\overline{{U}}_{i}\\,=\\,U_{i}\\,-\\,\\mathbb{E}[U_{i}]$ as in the statement. Then by using Cauchy-Schwarz inequality and noting that $\\lVert\\pmb{\\theta}-\\pmb{\\theta}_{\\star}\\rVert=D$ , we get ", "page_idx": 35}, {"type": "equation", "text": "$$\nT_{n}(\\theta)=\\left\\langle-\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}w_{i}\\overline{{U_{i}}},\\frac{\\theta-\\theta_{\\star}}{D}\\right\\rangle\\leq\\left\\|\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}w_{i}\\overline{{U_{i}}}\\right\\|=\\sqrt{\\sum_{k=1}^{d}\\left|\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}w_{i}\\overline{{U}}_{i}(k)\\right|^{2}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "It is important to note that the distribution of the random variable on the last term above does not depend on $\\pmb{\\theta}$ . Note that $w_{i}\\overline{{U}}_{i}$ for $i=1,\\hdots,n$ are independent mean zero (but possibly non-identical distributions due to the weights $w_{i}$ ) random vectors in $\\mathbb{R}^{d}$ , and by the hypothesis, their respective coordinates have uniformly bounded variances. Hence by a union bound, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{inf}_{\\stackrel{\\theta\\in\\Theta}{\\|\\theta-\\theta_{\\star}\\|=D}}T_{n}(\\theta)\\geq t\\right)\\leq\\sum_{k=1}^{d}\\mathbb{P}\\left(\\left|\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}w_{i}\\overline{{U}}_{i}(k)\\right|\\geq\\frac{t}{\\sqrt{d}}\\right).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Let $\\begin{array}{r}{Q_{n}^{k}=\\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}w_{i}\\overline{{U}}_{i}(k)}\\end{array}$ . Then by the Berry-Esseen Theorem (Theorem G.3) and the hypothesis, for $Z\\sim N(0,1)$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{z\\in\\mathbb{R}}{\\operatorname*{sup}}\\left|\\mathbb{P}\\left(Q_{n}^{k}\\leq z\\right)-\\mathbb{P}\\left(Z\\leq z\\right)\\right|\\leq\\frac{6\\sum_{i=1}^{n}w_{i}^{3}\\mathbb{E}[\\|\\overline{{U}}_{i}\\|^{3}]}{\\left(\\sum_{i=1}^{n}w_{i}^{2}\\mathbb{V}\\alpha(\\overline{{U}}_{i}(k))\\right)^{3/2}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\frac{6\\mathbb{E}[\\|\\overline{{U}}_{1}\\|^{3}]\\sum_{i=1}^{n}w_{i}^{3}}{\\left(\\mathrm{Var}(\\overline{{U}}_{1}(k))\\right)^{3/2}\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{6D_{1}\\sum_{i=1}^{n}w_{i}^{3}}{d_{1}^{3/2}\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}}\\\\ &{\\qquad\\qquad\\qquad=\\frac{K\\sum_{i=1}^{n}w_{i}^{3}}{\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\;\\;\\mathrm{for}\\;k=1,\\ldots,d.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "with $K=6D_{1}/d_{1}^{3/2}$ . Combining with (109) and using a triangle inequality, we obtain ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{inf}_{\\stackrel{\\theta\\in\\Theta}{\\|\\theta-\\theta_{*}\\|=D}}T_{n}(\\theta)\\geq t\\right)\\leq d\\left(\\mathbb{P}\\left(Z\\geq\\frac{t}{2\\sqrt{d}}\\right)+\\frac{K\\sum_{i=1}^{n}w_{i}^{3}}{\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\right).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Thus (c) in (108) follows. ", "page_idx": 35}, {"type": "text", "text": "H Proof of Theorem 3.5 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "In this section, we provide proof of the computational and statistical estimation guarantee stated in Theorem (3.5) under the generative ITR model (11). Two key ingredients in our proof are the computational guarantee (Theorem. E.1) and non-asymptotic estimation guarantee of constrained and regularized MLE (Theorem. G.1). ", "page_idx": 36}, {"type": "text", "text": "As we have briefly explained in the main text, the connection between the weighted convex optimization (6) for ITR learning and the statistical estimation problem under the generative model (11) is established by writing down the corresponding maximum likelihood estimation problem. To see this, recall that covariate-treatment pair $(\\mathbf{x}_{i},a_{i})$ follows a joint distribution $\\pi$ that does not depend on the true parameter $\\mathbf{B}_{\\star}$ . Further, assume that $\\pi$ admits a density function $f_{\\pi}$ . Then, for the continuous setting, the joint log-likelihood of observing the triple $(\\mathbf{x}_{i},a_{i},y_{i})$ gives under the generative model with parameter $\\mathbf{B}$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n-\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{n}\\left(y_{i}-\\frac{K-1}{K}\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)^{2}+\\sum_{i=1}^{n}\\log f_{\\pi}(\\mathbf{x}_{i},a_{i})+\\mathrm{constant}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Thus, the standard (unweighted) maximum likelihood estimation of the true parameter $\\mathbf{B}_{\\star}$ can be written as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\substack{\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)},\\,\\|\\mathbf{B}\\|\\leq\\lambda_{1}}}\\sum_{i=1}^{n}\\left(\\frac{K}{K-1}y_{i}-\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where we imposed additional $L_{1}$ -ball constraint for the parameter $\\mathbf{B}$ . Now, if we use covariatebalancing weight $w(\\mathbf{x}_{i},a_{i})$ for each subject $i$ , the corresponding weighted MLE problem reads as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\substack{\\mathbf{B}\\in\\mathbb{R}^{p\\times(K-1)},\\,\\|\\mathbf{B}\\|\\leq\\lambda_{1}}}\\sum_{i=1}^{n}w(\\mathbf{x}_{i},a_{i})\\left(\\frac{K}{K-1}y_{i}-\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "which is exactly the weighted convex optimization problem (6) for continuous outcome. A similar discussion applies to the binary outcome simply by noting that the joint log-likelihood is given by ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}\\left(-\\log\\left(1+\\exp(\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i})\\right)+y_{i}\\mathbf{u}_{a_{i}}^{T}\\mathbf{B}^{T}\\mathbf{x}_{i}\\right)+\\sum_{i=1}^{n}\\log f_{\\pi}(\\mathbf{x}_{i},a_{i}).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Proof of Theorem 3.5. Consider the generative ITR model (11) with true parameter $\\mathbf{B}_{\\star}$ . Fix $\\varepsilon>0$ . Let $(\\widehat{\\bf B}_{t})_{t\\ge0}$ denote the estimated parameters by using the PGD algorithm (7) for the weighted empirical maximum likelihood estimation problem (6). Decompose the total estimation error into computational and statistical parts as ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\|\\mathbf{B}_{\\star}-\\widehat{\\mathbf{B}}_{T}\\|_{F}\\leq\\underbrace{\\|\\widehat{\\mathbf{B}}-\\widehat{\\mathbf{B}}_{T}\\|_{F}}_{=:I_{1}}+\\underbrace{\\|\\widehat{\\mathbf{B}}-\\widehat{\\mathbf{B}}_{\\star}\\|_{F}}_{=:I_{2}}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "By Theorem E.1, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\nI_{1}\\leq\\left\\{\\!\\!\\begin{array}{l l}{4\\rho(\\alpha)^{T}\\lambda_{1}^{2}}&{\\mathrm{with\\;constant\\;stepsize}}\\\\ {\\frac{\\nu}{\\gamma+T}}&{\\mathrm{with\\;diminishing\\;stepsize}.}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "We wish to apply our general result on weighted and constrained MLE in (Theorem G.1) with $L_{2}$ -regularization $\\begin{array}{r}{{\\cal R}({\\bf B})\\ {=\\ }\\frac{\\lambda_{2}}{2}\\,\\mathrm{||{\\bfB}||}_{F}^{2}}\\end{array}$ in order to get a high-probability bound on the term $I_{2}$ . For this, we first verify the hypothesis in Theorem G.1 for our generative ITR model (11). Assumption (a1) in Theorem G.1 follows from Assumption 3.4. For Assumption (a3) in Theorem G.1, denoting by $\\rho$ the minimum eigenvalue of the expected regularized Fisher information, by Lemma E.3 (also see (10)), ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\rho=\\mu=\\left\\{\\!\\!\\begin{array}{l l}{{\\lambda^{-}+\\lambda_{2}}}&{{\\mathrm{for\\;continuous\\;outcome}}}\\\\ {{\\alpha^{-}\\lambda^{-}+\\lambda_{2}}}&{{\\mathrm{for\\;binary\\;outcome}.}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $\\lambda_{-}$ is the minimum eigenvalue of the expected weighted design matrix $\\mathbb{E}[\\Psi]$ in (8) (see Assumption 3.1). The above quantity is positive under the hypothesis. ", "page_idx": 36}, {"type": "text", "text": "Lastly, for Assumption (a2) in Theorem G.1, we need to show that the true parameter $\\mathbf{B}_{\\star}$ is a global maximizer of the expected log-likelihood function of our generative ITR model (11). This can be shown by a standard argument under the mild assumption that expectations and derivatives are exchangeable. For simplicity, we prove this for the case when $\\mathbf{B}_{\\star}$ is in the interior of the constraint set $\\Theta$ . (The general case can be shown similarly by considering the first-order optimality condition for stationary points.) First note that, if we denote the likelihood of observing the triple $(X,A,Y)$ under the model parameter $\\mathbf{B}$ as $p_{\\mathbf{B}}(X,A,Y)=p_{\\mathbf{B}}(Y\\mid X,A)\\,p(X,A)$ , then $\\log p_{\\mathbf{B}}(X,A,Y)$ is a concave function in B. Thus we only need to show that the true parameter $\\mathbf{B}_{\\star}$ is a critical point of the expected weighted log-likelihood function $\\mathbb{E}\\left[\\omega(A,X)\\log p_{\\mathbf{B}}\\!\\left(X,A,Y\\right)\\right]$ . Indeed, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\mathbf{B}}\\mathbb{E}[\\omega(A,X)\\log p_{\\mathbf{B}}(X,A,Y)]}\\\\ &{\\quad=\\mathbb{E}\\left[\\omega(A,X)\\nabla_{\\mathbf{B}}\\left(\\log p_{\\mathbf{B}}(Y\\,|\\,X,A)+\\log p(X,A)\\right)\\right]}\\\\ &{\\quad=\\mathbb{E}\\left[\\omega(A,X)\\nabla_{\\mathbf{B}}\\log p_{\\mathbf{B}}(Y\\,|\\,X,A)\\right]}\\\\ &{\\quad=\\mathbb{E}\\left[\\omega(A,X)\\frac{\\nabla_{\\mathbf{B}}p_{\\mathbf{B}}(Y\\,|\\,X,A)}{p_{\\mathbf{B}}(Y\\,|\\,X,A)}\\right]}\\\\ &{\\quad=\\mathbb{E}_{X}\\left[\\mathbb{E}_{(Y,A)}\\left[\\omega(A,X)\\frac{\\nabla_{\\mathbf{B}}p_{\\mathbf{B}}(Y\\,|\\,X,A)}{p_{\\mathbf{B}}(Y\\,|\\,X,A)}\\,\\bigg|\\,X\\right]\\right]}\\\\ &{\\quad=\\mathbb{E}_{X}\\left[\\sum_{a=0}^{K}\\omega(a,X)\\pi(a,X)\\mathbb{E}_{Y\\sim p_{\\mathbf{B}_{\\mathbf{B}}}(\\cdot\\,|\\,X,a)}\\left[\\frac{\\nabla_{\\mathbf{B}}p_{\\mathbf{B}}(Y\\,|\\,X,A)}{p_{\\mathbf{B}}(Y\\,|\\,X,A)}\\,\\bigg|\\,X,A=a\\right]\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where we have used iterated expectation to condition first on the covariate $X$ and then integrate out the treatment-response pair $(A,Y)$ . Now note that ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{Y\\sim p_{\\mathbf{B}_{\\star}}(\\cdot\\,|\\,X,a)}\\left[\\frac{\\nabla_{\\mathbf{B}}p_{\\mathbf{B}_{\\star}}(Y|X,A)}{p_{\\mathbf{B}_{\\star}}(Y\\,|\\,X,A)}\\,\\bigg|\\,X,A=a\\right]=\\displaystyle\\int\\nabla_{\\mathbf{B}}p_{\\mathbf{B}_{\\star}}(Y|X,A)\\,d y}&{}\\\\ {=\\nabla_{\\mathbf{B}}\\int p_{\\mathbf{B}_{\\star}}(Y|X,A)\\,d y}&{}\\\\ {=\\nabla_{\\mathbf{B}}1=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Thus $\\mathbf{B}_{\\star}$ is a critical point of $\\mathbb{E}\\left[\\log p_{\\mathbf{B}}(X,A,Y)\\right]$ . By the concavity of the log-likelihood function, it follows that $\\mathbf{B}_{\\star}$ is a global maximizer of $\\mathbb{E}\\left[\\omega(A,\\overbar{X})\\log p_{\\mathbf{B}}(X,A,Y)\\right]$ . In particular, this verifies the assumption G.1 (a2). ", "page_idx": 37}, {"type": "text", "text": "Now we can apply Theorem G.1 with $L_{2}$ -regularization $\\begin{array}{r}{R({\\bf B})=\\frac{\\lambda_{2}}{2}\\|{\\bf B}\\|_{F}^{2}}\\end{array}$ for our generative ITR model. Denoting ", "page_idx": 37}, {"type": "equation", "text": "$$\nD:=\\frac{C}{\\sqrt{n}}+\\frac{8\\|\\nabla R({\\mathbf B}_{\\star})\\|_{F}}{\\mu}=\\frac{C}{\\sqrt{n}}+\\frac{8\\lambda_{2}\\|{\\mathbf B}_{\\star}\\|_{F}}{\\mu}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "for $C>0$ any constant, this gives ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{P}\\!\\left(I_{2}>D\\right)\\le c_{1}\\exp\\left(-\\frac{C^{2}\\mu^{2}}{2\\cdot32^{2}d}\\right)+\\frac{c_{2}\\sum_{i=1}^{n}w_{i}^{3}}{\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}+O(\\exp(-c_{3}n)),\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $c_{1},c_{2},c_{3}~>~0$ are constants and $d\\ =\\ p(K\\,-\\,1)$ . By Assumption 3.4, the quantities $\\begin{array}{r}{\\sqrt{n}\\sum_{i=1}^{n}w_{i}^{3}/\\left(\\sum_{i=1}^{n}w_{i}^{2}\\right)^{3/2}}\\end{array}$ are uniformly bounded in $n$ . Hence we can first choose $n$ large eno ugh so that the last two terms combined in the right-hand side in (116) are at most $\\varepsilon/2$ , for which $n\\gtrsim\\bar{\\varepsilon}^{-2}$ is sufficient. Then we can choose $C>0$ large enough so that the first term on the right-hand side of (116) is at most $\\varepsilon/2$ . For this, we choose ", "page_idx": 37}, {"type": "equation", "text": "$$\nC={\\frac{32{\\sqrt{2d}}}{\\mu}}{\\sqrt{\\log{\\frac{2c_{1}}{\\varepsilon}}}}=\\Omega\\left({\\frac{{\\sqrt{p\\log\\varepsilon^{-1}}}}{\\mu}}\\right)\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Accordingly, we can choose $T$ large enough so that $I_{1}\\leq C/\\sqrt{n}$ . Then the above gives ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\|\\mathbf{B}_{\\star}-\\widehat{\\mathbf{B}}_{T}\\|_{F}>\\frac{2C}{\\sqrt{n}}+\\frac{8\\lambda_{2}\\|\\mathbf{B}_{\\star}\\|_{F}}{\\mu}\\right)\\leq\\mathbb{P}\\left(I_{2}\\geq D\\right)\\leq\\varepsilon.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "This shows the assertion. ", "page_idx": 37}, {"type": "text", "text": "I Additional simulation details and results ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "The code supporting this study is available at https://github.com/ljw9510/effective-ITR, with plans for release as an R package soon. ", "page_idx": 38}, {"type": "text", "text": "I.1 Details of data-generating mechanism ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "In this section, we explain how data are generated and treatment assignments are allocated in our simulation studies. The outcome is generated under the working model assumption given by Equation 1 with heteroscedastic random noise $\\epsilon\\sim N(0,\\sigma^{2}(A,{\\bf X}))$ . We have four different settings/cases for the treatment-free effect and interaction effect functions, which are outlined below. ", "page_idx": 38}, {"type": "text", "text": "Case 1: Linear interaction functions with simple treatment-free effect functions ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "For Case 1, our randomized study aligns with Scenario 7 and our observational study mirrors Scenario 8 described in [44]. Specifically, we consider the following settings for the treatment-free effects and interaction effects: ", "page_idx": 38}, {"type": "text", "text": "Randomized trial:   \n$\\mu(\\mathbf{X})=1+2X_{1}+2X_{2},$   \n$\\delta(\\mathbf{X})=\\left\\{\\begin{array}{l l}{0.75+1.5X_{1}+1.5X_{2}+1.5X_{3}+1.5X_{4},A=1;}\\\\ {0.75+1.5X_{1}-1.5X_{2}-1.5X_{3}+1.5X_{4},A=2;}\\\\ {0.75+1.5X_{1}-1.5X_{2}+1.5X_{3}-1.5X_{4},A=3;}\\\\ {0.75-1.5X_{1}+1.5X_{2}-1.5X_{3}-1.5X_{4},A=4,}\\end{array}\\right.$   \nObservational study:   \n$\\begin{array}{r l}&{\\mu(\\mathbf{X})=1+X_{5}+3X_{6}+2X_{1}X_{2},}\\\\ &{\\delta(\\mathbf{X})=\\left\\{\\!\\!\\begin{array}{l l}{0.5+2X_{1}+X_{2}+X_{3},A=1;}&{1+X_{1}-X_{2}-X_{3},A=2;}\\\\ {1.5+3X_{1}-X_{2}+X_{3},A=3;}&{1-X_{1}-X_{2}+X_{3},A=4,}\\end{array}\\!\\!\\right.}\\end{array}$ ", "page_idx": 38}, {"type": "text", "text": "Case 2: Linear interaction functions with complicated treatment-free effect functions ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "For Case 2, we consider the following treatment-free effect function for model assumptions of $Y$ : ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\mu(\\mathbf{X})=1+X_{5}+X_{5}^{2}+2e^{-X_{1}X_{2}}+\\sin(X_{3}).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Case 3: Non-linear interaction functions with simple treatment-free effect functions ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "For Case 3, we consider the following non-linear interaction functions for model assumptions of $Y$ : ", "page_idx": 38}, {"type": "text", "text": "\u00b5(X) = 1 + 2X1 + 2X2 + 2X4 \u22122X42 + 2X1X2, $\\overset{*}{\\delta(\\mathbf{X})}=\\left\\{\\begin{array}{l l}{\\overset{*}{0.5+1.0X_{1}}-2.0X_{4}+0.5X_{4}^{2},A=1;\\ 1.0+1.0X_{1}+1.0X_{4}-1.0X_{4}^{2},A=2;}\\\\ {\\overset{}{1.5+2.0X_{1}}-1.0X_{4}-1.0X_{4}^{2},A=3;\\ 1.0-1.0X_{1}-1.0X_{4}-1.0X_{4}^{2},A=4.0+1.0X_{4}^{2}.}\\end{array}\\right.$ ", "page_idx": 38}, {"type": "text", "text": "Case 4: Non-linear interaction functions with a complicated treatment-free effect function ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "For Case 4, we consider the following complicated treatment-free effect function for model assumptions of $Y$ : ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\mu(\\mathbf{X})=1+2X_{1}+2X_{2}+2X_{4}-2X_{4}^{2}+2X_{1}X_{2}+2e^{-X_{1}X_{2}}+\\sin(X_{3}).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "In all four cases, we adopt the same treatment assignment principles and variance function ${\\sigma}^{2}(A,\\mathbf{X})$ that induces heteroscedastic error for observational studies as outlined in [44]: ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\pi(A,\\mathbf{X})=\\left\\{\\!0.25\\cdot\\mathbf{I}(X_{1}<0)+0.4\\cdot\\mathbf{I}(X_{1}>0),A=1\\!,\\right.}\\\\ &{\\left.\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\left.\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ &{\\sigma^{2}(A,\\mathbf{X})=0.25+2X_{2}\\cdot\\mathbf{I}(X_{2}>0)+X_{3}\\cdot\\mathbf{I}(X_{3}>0,A=1)+X_{4}\\cdot\\mathbf{I}(X_{4}>0,A=2)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "For randomized trials, each individual has an equal probability of assigning each treatment, therefore, no propensity score estimation was made for AD-learning and SABD-learning. For the heteroscedastic error for randomized trials, $\\sigma^{2}(A,{\\bf X})=0.25+0.2\\,{(1.5-X_{2})}^{2}$ was used. ", "page_idx": 39}, {"type": "text", "text": "I.2 Implementation details ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "All numerical experiments were performed on a 2022 Macbook Air with M1 chip and $16\\:\\mathrm{GB}$ of RAM. ", "page_idx": 39}, {"type": "text", "text": "In the computation of the final ITR estimates, we use two different approaches: one with weighted multivariate regression with $L_{1}$ -regularization for the penalized approach (named \u2018penalized\u2019 in the main text). The other uses the proposed PGD algorithm with $L_{1}$ -ball (named \u2018constrained\u2019 in the main text). To ensure a fair comparison, both the penalized method and the constrained optimization algorithm were implemented using code developed by the author. We do not consider additional $L_{2}$ -regularization in this setting. To determine the regularization constant or $L_{1}$ -ball size, we use mean squared error as the criterion. The iterate number $T$ of the PGD algorithm is 1000. ", "page_idx": 39}, {"type": "text", "text": "In our simulation study, we employ the default configuration of the random forest algorithm as implemented in the randomForest package in R to estimate the residual variance function in SABDLearning, the treatment-free effect, and the propensity score. This default configuration includes the construction of an ensemble of 500 decision trees, with each tree\u2019s splitting criterion determined using the Gini index. The number of variables considered for splitting at each node is set to the square root of the total number of covariates. For model performance evaluation, we utilize the out-of-bag (OOB) error estimate. ", "page_idx": 39}, {"type": "text", "text": "I.3 Additional simulation results ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "The goal of these additional simulations in the appendix is to demonstrate, under the pre-specified linear ITR, that DCBW, variable screening, and augmentation can synergistically benefit the final ITR. Methods using energy balancing weights are denoted as \u201c_e\u201d and those employing the distance covariance test for variable screening are indicated as $\\mathbf{\\ddot{\\mu}}\\leq\\mathbf{\\dot{s}}^{\\ast}$ in the table. Note that the augmented \u201cSABD_e_s\u201d corresponds to \u201c proposed+penalized\u201d in the main text. In this section, we include the performance of various methods implemented only by the penalized approach to compare the effectiveness of the proposed statistical methods. The simulation was implemented using package glmnet in R. ", "page_idx": 39}, {"type": "text", "text": "I.3.1 Treatment Decision Accuracy ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Here, we show the averages and standard deviations of treatment decision accuracy from the additional simulation studies. The first four tables present the results of experiments that mimic randomized trials, and the remaining four tables show the results of observational studies. ", "page_idx": 39}, {"type": "text", "text": "The simulation results indicate that individual components alone do not significantly improve performance. Instead, the synergistic effect of combining these components is essential for the ITR-Learning. For example, in high-dimensional settings, using DCBW alone balances the empirical distributions of all covariates (up to 60), including a significant portion of irrelevant ones. Additionally, estimated decision functions may include irrelevant variables, reducing the impact of DCBW. Similarly, using variable screening alone remains challenging due to model misspecification or highly nonlinear outcomes. Combining other methods, such as outcome augmentation, helps mitigate model misspecification effects. This combined application ensures efficient and robust optimal ITR estimation across diverse scenarios. ", "page_idx": 39}, {"type": "text", "text": "Below is a detailed investigation of each scenario. ", "page_idx": 39}, {"type": "text", "text": "First, we examine Case 1, where the treatment rule class is correctly specified (Tables 1, 5). With a relatively simple treatment-free effect, AD-Learning\u2019s performance is comparable to SABD-Learning, particularly following outcome augmentation. When combined with EBWs as AD_e, SABD_e, these methods exhibit improved performance over their original versions (AD, SABD). In randomized trials, EBWs effectively reduce finite sample imbalance compared to IPW with true propensity scores. In observational studies, energy balancing yields more effective balancing weights, resulting in higher accuracy. ", "page_idx": 39}, {"type": "text", "text": "Next, we delve into Case 2, involving a more complicated treatment-free effect function compared to Case 1 (Tables 2, 6). Notably, since the treatment-free effect does not affect ITR learning, a misspecified treatment-free effect function introduces heterogeneity and increases noise variance. Then we can see the synergistic effectiveness of outcome augmentation and inverse variance weighting in SABD-Learning, effectively handling additional heterogeneity in ITR estimation (See \u201caugmented\u201d panel in Tables 2, 6). However, it\u2019s important to note that all variants of AD-Learning show subpar performance, even with augmented outcomes. AD-Learning results in an intercept-only model frequently as its estimated decision function, which suggests that the mean squared error criterion in LASSO regularization may not be effective for selecting models. In such instances, different penalty types or performance metrics could prove beneficial. ", "page_idx": 40}, {"type": "text", "text": "Case 3 and Case 4 handle situations where the underlying treatment rule class is misspecified (Tables 3, 4, 7, and 8). Particularly, in Case 4, estimating ITR becomes even more challenging due to a highly non-linear covariate-outcome relationship, which leads to suboptimal results of the variants of ADLearning as in Case 2. Our results demonstrate that the more robust EBWs outperform standard IPW, particularly in observational studies. Additionally, variable screening enhances ITR learning in a highdimensional setting. Employing variable screening (SABD_s) enhances the performance of SABD, especially with limited sample sizes, as it aids in selecting effect modifiers and precision variables, thereby facilitating decision function estimation. However, even with perfect screening, estimating the decision function remains challenging due to model misspecification or highly nonlinear outcomes. Simultaneous use of EBWs and screening for SABD (SABD_e_s) further elevates performance, likely influenced by dimensionality in nonparametric balancing weight methods. ", "page_idx": 40}, {"type": "text", "text": "The significant enhancements from integrating DCBWs, variable screening, outcome augmentation, and inverse variance weighting underscore their collective importance. Their combined application ensures efficient and robust optimal ITR estimation across diverse scenarios. ", "page_idx": 40}, {"type": "table", "img_path": "G7L65B2P0y/tmp/68e856797b9406f4f3e06afec8c96d319ed5191f18a27be03669e2b818731bc4.jpg", "table_caption": ["Table 2: Average accuracy and their standard deviations (in parenthesis) in the randomized trial in Case 1: Linear interaction functions with simple treatment-free effect functions. "], "table_footnote": [], "page_idx": 41}, {"type": "table", "img_path": "G7L65B2P0y/tmp/10fd192f3a70f98be557e3b662340bc1f3e5befc9cb2032495568d60ccd6a8be.jpg", "table_caption": ["Table 3: Average accuracy and their standard deviations (in parenthesis) in the randomized trial in Case 2: Linear interaction functions with complicated treatment-free effect functions. "], "table_footnote": [], "page_idx": 42}, {"type": "table", "img_path": "G7L65B2P0y/tmp/22e5a4c7a3d4857977ad7d8253f60fc5effa0195ed3f50b5df37861f74df776c.jpg", "table_caption": ["Table 4: Average accuracy and their standard deviations (in parenthesis) in the randomized trial in Case 3: Non-linear interaction functions with simple treatment-free effect functions. "], "table_footnote": [], "page_idx": 43}, {"type": "table", "img_path": "G7L65B2P0y/tmp/5e0483c6e0581c11c5e258692fab50467d6ab12bed7e9ab0a8deb616c5c0de0d.jpg", "table_caption": ["Table 5: Average accuracy and their standard deviations (in parenthesis) in the randomized trial in Case 4: Non-linear interaction functions with a complicated treatment-free effect function. "], "table_footnote": [], "page_idx": 44}, {"type": "table", "img_path": "G7L65B2P0y/tmp/008e303fc9e4b54ea2dd50a6bdd57825f8966f928c11a4e9794ddf925287a67e.jpg", "table_caption": ["Table 6: Average accuracy and their standard deviations (in parenthesis) in the observational study in Case 1: Linear interaction functions with simple treatment-free effect functions. "], "table_footnote": [], "page_idx": 45}, {"type": "table", "img_path": "G7L65B2P0y/tmp/d5e575084849500c1a89b7151129f83f1eb15f95cd52237bc7ae0f34e60561ee.jpg", "table_caption": ["Table 7: Average accuracy and their standard deviations (in parenthesis) in the observational study in Case 2: Linear interaction functions with complicated treatment-free effect functions. "], "table_footnote": [], "page_idx": 46}, {"type": "table", "img_path": "G7L65B2P0y/tmp/85b151b2494464cb126c8afcf75fe4b8ac0afb1870e5d547055a2116e12dcc7b.jpg", "table_caption": ["Table 8: Average accuracy and their standard deviations (in parenthesis) in the observational study in Case 3: Non-linear interaction functions with simple treatment-free effect functions. "], "table_footnote": [], "page_idx": 47}, {"type": "table", "img_path": "G7L65B2P0y/tmp/5ac9e739ef4cc3d3fcccd6df78b0a8a83774bfb451aca3d34217121719434cee.jpg", "table_caption": ["Table 9: Average accuracy and their standard deviations (in parenthesis) in the observational study in Case 4: Non-linear interaction functions with a complicated treatment-free effect function. "], "table_footnote": [], "page_idx": 48}, {"type": "text", "text": "I.3.2 Empirical values ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "In this subsection, we show the averages and standard deviations of empirical values from the additional simulation studies. The empirical values of the estimated rule $\\mathbb{E}[Y(\\hat{d}(\\mathbf{X}))]$ are computed by utilizing the generated potential outcomes on the test dataset. ", "page_idx": 49}, {"type": "text", "text": "We include the empirical value of the optimal rule $\\mathbb{E}[Y(d^{\\mathrm{opt}}(\\mathbf{X}))]$ as well as the values obtained by assigning everyone to each of the four classes $\\mathbb{E}[Y(K)]$ for $K\\;=\\;1,\\ldots,4$ as benchmarks, assuming the higher value of empirical value is better. Again, the first four tables present the results of experiments that mimic randomized trials, and the remaining four tables show the results of observational studies. ", "page_idx": 49}, {"type": "text", "text": "Here, we can observe the beneftis of the three components that we found from the treatment decision accuracy results. In addition, the benchmarks of the empirical values reveal some intriguing insights. Firstly, the optimal empirical value provides information on how challenging the current scenario is. For instance, in the randomized trial of Case 1 (Table 9), the optimal empirical value is not significantly different from the mean empirical value evaluated by current methods. Especially with augmented outcomes using a sample size of 1000, it yields a value quite similar to the optimal. On the other hand, in the observational study of Case 4 (Table 16), the obtained empirical values show significant differences from the optimal value. Furthermore, the mean empirical value evaluated from AD-Learning with a sample size of 200 is not markedly different from the empirical value obtained by assigning all individuals to treatment 1. This implies that the estimated ITR provides results akin to a \u201cone-size-ftis-all\u201d outcome in small sample sizes, and this finding is not irrelevant to the fact that a majority of AD-Learning results in an intercept-only model as the final decision function under conditions of highly non-linear covariate-outcome relationships. In such instances, we can explore alternative methods to further advance our current results such as other penalty types or performance metrics. ", "page_idx": 49}, {"type": "text", "text": "Table 10: Average empirical values and their standard deviations (in parenthesis) in the randomized trial in Case 1: Linear interaction functions with simple treatment-free effect functions. The optimal empirical value is 5.160 and the average empirical values when assigning one treatment are 1.751, 1.752, 1.751, and 1.752, respectively. ", "page_idx": 50}, {"type": "table", "img_path": "G7L65B2P0y/tmp/7244c80c3794bbbf8353b280509160da5df8e9238703840e9ccc95b2d3a989e1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 50}, {"type": "text", "text": "Table 11: Average empirical values and their standard deviations (in parenthesis) in the randomized trial in Case 2: Linear interaction functions with complicated treatment-free effect functions. The optimal empirical value is 10.333 and the average empirical values when assigning one treatment are 6.923, 6.924, 6.923, and 6.924, respectively. ", "page_idx": 51}, {"type": "table", "img_path": "G7L65B2P0y/tmp/4c3791b56d9a3d3fb780ec6f796a416d27183a6fe1f16f960a2716bea5c240a0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 51}, {"type": "text", "text": "Table 12: Average empirical values and their standard deviations (in parenthesis) in the randomized trial in Case 3: Non-linear interaction functions with simple treatment-free effect functions. The optimal empirical value is 1.422 and the average empirical values when assigning one treatment are 0.041, -0.919, -0.419, and -0.920, respectively. ", "page_idx": 52}, {"type": "table", "img_path": "G7L65B2P0y/tmp/f5d1f7abe7539b334341710cb14deb1c157803db9bb6b73212fd53d234ccd3a0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 52}, {"type": "text", "text": "Table 13: Average empirical values and their standard deviations (in parenthesis) in the randomized trial in Case 4: Non-linear interaction functions with a complicated treatment-free effect function. The optimal empirical value is 5.623 and the average empirical values when assigning one treatment are 4.243, 3.282, 3.782, and 3.281 respectively. ", "page_idx": 53}, {"type": "table", "img_path": "G7L65B2P0y/tmp/3116d79800f1402caec840c4ddb3d5722119515b4c8104faad0b60ccae8226b6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 53}, {"type": "text", "text": "Table 14: Average empirical values and their standard deviations (in parenthesis) in the observational study in Case 1: Linear interaction functions with simple treatment-free effect functions. The optimal empirical value is 4.263 and the average empirical values when assigning one treatment are 1.503, 2.003, 2.502, and 2.001, respectively. ", "page_idx": 54}, {"type": "table", "img_path": "G7L65B2P0y/tmp/2066381774afb4735f53b4cb5e788ab3dfc5261d51923193dc04e6722c14ab27.jpg", "table_caption": [], "table_footnote": [], "page_idx": 54}, {"type": "text", "text": "Table 15: Average empirical values and their standard deviations (in parenthesis) in the observational study in Case 2: Linear interaction functions with complicated treatment-free effect functions. The optimal empirical value is 9.433 and the average empirical values when assigning one treatment are 6.672, 7.173, 7.672, and 7.171, respectively. ", "page_idx": 55}, {"type": "table", "img_path": "G7L65B2P0y/tmp/08d37539dd1df21578dba265bf5b9b0bad00ada9dc9a2cc5c08cca7290300635.jpg", "table_caption": [], "table_footnote": [], "page_idx": 55}, {"type": "text", "text": "Table 16: Average empirical values and their standard deviations (in parenthesis) in the observational study in Case 3: Non-linear interaction functions with simple treatment-free effect functions. The optimal empirical value is 1.422 and the average empirical values when assigning one treatment are 0.042, -0.920, -0.419, and -0.920, respectively. ", "page_idx": 56}, {"type": "table", "img_path": "G7L65B2P0y/tmp/2036b87fadfebdd6dacfaf61ce972a1adacd188d5bac0ba8f2e22f975be981ab.jpg", "table_caption": [], "table_footnote": [], "page_idx": 56}, {"type": "text", "text": "Table 17: Average empirical values and their standard deviations (in parenthesis) in the observational study in Case 4: Non-linear interaction functions with a complicated treatment-free effect function. The optimal empirical value is 5.623 and the average empirical values when assigning one treatment are 4.243, 3.282, 3.782, and 3.281, respectively. ", "page_idx": 57}, {"type": "table", "img_path": "G7L65B2P0y/tmp/5652c39c7b27a751314c7d71f6da6cea9e72ad2138384ca8abc826b4eeff8aca.jpg", "table_caption": [], "table_footnote": [], "page_idx": 57}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 58}, {"type": "text", "text": "Justification: Our main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 58}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Justification: Our paper discusses the limitations of the work in the section 6. ", "page_idx": 58}, {"type": "text", "text": "Guidelines: ", "page_idx": 58}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 58}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 58}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 59}, {"type": "text", "text": "Justification: We provide the full set of assumptions in the main text and complete proof in the appendix. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 59}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 59}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 59}, {"type": "text", "text": "Justification: Our paper fully discloses all the information needed to reproduce all simulation results and data applications of the paper. ", "page_idx": 59}, {"type": "text", "text": "Guidelines: ", "page_idx": 59}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 59}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 60}, {"type": "text", "text": "Justification: We provide open access to the code, with sufficient instructions to faithfully reproduce the main experimental results. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 60}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Justification: We specify all the training and test details including data splits, hyperparameters, how they were chosen, and type of optimizer for the benchmark. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 60}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 60}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Justification: We report the means and standard deviations with 100 (10) iterations in our simulation studies (applications), respectively. ", "page_idx": 60}, {"type": "text", "text": "Guidelines: ", "page_idx": 60}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 60}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 61}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 61}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 61}, {"type": "text", "text": "Justification: We provide sufficient information on the computer resources in the appendix. Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 61}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 61}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 61}, {"type": "text", "text": "Justification: We strictly follow the NeurIPS Code of Ethics. ", "page_idx": 61}, {"type": "text", "text": "Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 61}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 61}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 61}, {"type": "text", "text": "Justification: We discuss both potential positive societal impacts and negative societal impacts of our work in the section 6. ", "page_idx": 61}, {"type": "text", "text": "Guidelines: ", "page_idx": 61}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 61}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 62}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 62}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 62}, {"type": "text", "text": "Justification: Our paper poses no such risks. ", "page_idx": 62}, {"type": "text", "text": "Guidelines: ", "page_idx": 62}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 62}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 62}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 62}, {"type": "text", "text": "Justification: We cite the original papers and include the URL for the webpage. Guidelines: ", "page_idx": 62}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 62}, {"type": "text", "text": "", "page_idx": 63}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 63}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 63}, {"type": "text", "text": "Justification: We introduce our proposed with sufficient details in the paper. The documentation is provided alongside our code. ", "page_idx": 63}, {"type": "text", "text": "Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 63}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 63}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 63}, {"type": "text", "text": "Justification: We used open-source datasets and our paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 63}, {"type": "text", "text": "Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 63}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 63}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 63}, {"type": "text", "text": "Justification: our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 63}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 64}]