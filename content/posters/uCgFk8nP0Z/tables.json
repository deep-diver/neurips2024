[{"figure_path": "uCgFk8nP0Z/tables/tables_8_1.jpg", "caption": "Table 1: Worst-case comparison between DU-Shapley and competitors, for real-world datasets considered in Table 3. We report the averaged MSE across all players w.r.t. the exact Shapley value.", "description": "This table presents a comparison of the performance of DU-Shapley against other methods (MC-Shapley and MC-anti-Shapley) for approximating Shapley values in real-world datasets.  The comparison is done in a worst-case scenario, using real-world datasets (detailed in Table 3) and with a small number of players (10 and 20). The metric used for comparison is the Mean Squared Error (MSE) averaged across all players relative to the true (exactly computed) Shapley values.", "section": "4.1 Approximating the Shapley Value in Real-World Data"}, {"figure_path": "uCgFk8nP0Z/tables/tables_8_2.jpg", "caption": "Table 1: Worst-case comparison between DU-Shapley and competitors, for real-world datasets considered in Table 3. We report the averaged MSE across all players w.r.t. the exact Shapley value.", "description": "This table presents a comparison of the performance of DU-Shapley against other methods (MC-Shapley and MC-anti-Shapley) in approximating Shapley values for real-world datasets.  The \"worst-case\" scenario involves a smaller number of players (10 and 20) than is ideal for DU-Shapley's asymptotic guarantees to fully take effect. The table reports the Mean Squared Error (MSE) averaged across all players, relative to the true Shapley value, showcasing DU-Shapley's competitiveness even under less-than-ideal conditions.", "section": "4.1 Approximating the Shapley Value in Real-World Data"}, {"figure_path": "uCgFk8nP0Z/tables/tables_9_1.jpg", "caption": "Table 2: Comparison between DU-Shapley and competitors for real-world datasets considered in [17] in Noisy label detection, Dataset Removal and Dataset Addition.", "description": "This table compares the performance of DU-Shapley against other methods (Random, LOO, DataShapley, and KNN-Shapley) for three dataset valuation problems: noisy label detection (NLD), dataset removal (DR), and dataset addition (DA).  The results are shown for two datasets, CIFAR10 and BBC, and for different noise levels (5% and 15%). The metrics used are F1-score (for NLD), testing accuracy (for DR and DA), with lower values indicating better performance for DR and DA.", "section": "4.3 Applying DU-Shapley to dataset valuation problems"}, {"figure_path": "uCgFk8nP0Z/tables/tables_9_2.jpg", "caption": "Table 2: Comparison between DU-Shapley and competitors for real-world datasets considered in [17] in Noisy label detection, Dataset Removal and Dataset Addition.", "description": "This table compares the performance of DU-Shapley against other methods (Random, LOO, DataShapley, KNN-Shapley) for three dataset valuation problems: noisy label detection (NLD), dataset removal (DR), and dataset addition (DA) on two real-world datasets (BBC and IMDB).  The results show the performance metrics (F1-score for NLD, and testing accuracy for DR and DA) for different levels of noise (5% and 15%).  It demonstrates how DU-Shapley compares to existing approaches on real-world data, showing competitive results, even when assumptions made for theoretical guarantees in the main paper are not completely satisfied. ", "section": "4.3 Applying DU-Shapley to dataset valuation problems"}, {"figure_path": "uCgFk8nP0Z/tables/tables_14_1.jpg", "caption": "Table 3: Datasets considered in Section 4.1.", "description": "This table lists the six real-world datasets used in Section 4.1 of the paper for evaluating the performance of the proposed DU-Shapley method and comparing it with other methods. For each dataset, the table provides the dataset size, the number of features (d), and the type of machine learning task (classification or regression).  These datasets represent a variety of problem types and sizes, allowing for a comprehensive evaluation of the algorithms.", "section": "4.1 Approximating the Shapley Value in Real-World Data"}]