[{"figure_path": "HShs7q1Njh/tables/tables_5_1.jpg", "caption": "Table 1: Mean and standard error of MAE and NLL averaged over over the seven training set sizes and 3 seeds of each function for Mixtral-8\u00d77B A-LLMP and a GP with an RBF kernel.", "description": "This table presents a comparison of the Mean Absolute Error (MAE) and Negative Log-Likelihood (NLL) achieved by the Mixtral-8\u00d77B A-LLMP model and a Gaussian Process (GP) model with a radial basis function (RBF) kernel.  The comparison is made across seven different training set sizes (5, 10, 15, 20, 25, 50, and 75 data points) and three random seeds for each of twelve different synthetic functions.  The results show the average MAE and NLL for each model, along with the standard error, providing insights into the relative performance of each model under varying data conditions.", "section": "Evaluating LLMP Performance on Numerical Data"}, {"figure_path": "HShs7q1Njh/tables/tables_15_1.jpg", "caption": "Table 1: Mean and standard error of MAE and NLL averaged over over the seven training set sizes and 3 seeds of each function for Mixtral-8\u00d77B A-LLMP and a GP with an RBF kernel.", "description": "This table presents a comparison of the performance of the Mixtral-8x7B A-LLMP model and a Gaussian Process (GP) model on seven different training set sizes for twelve synthetic functions.  The metrics used for comparison are Mean Absolute Error (MAE) and Negative Log-Likelihood (NLL).  The table shows the mean and standard error for each metric across three random seeds for each function and training set size, allowing for a detailed analysis of the models' performance under varying data conditions.", "section": "4 Evaluating LLMP Performance on Numerical Data"}, {"figure_path": "HShs7q1Njh/tables/tables_19_1.jpg", "caption": "Table F.1: Times to load the LLM into GPU memory, for the LLM to generate all samples at all target points, and to compute the probability distribution over the true target points. All runs used the Llama-2-7B LLM and were executed on an NVIDIA 3090 GPU with 24GB of memory with a batch size of 10. All times are in seconds.", "description": "This table shows the time it takes to load the Llama-2-7B LLM into GPU memory, generate samples for all target points using the LLM, and compute likelihoods for the true target points.  The experiment used an NVIDIA 3090 GPU with 24GB memory and a batch size of 10.  Times are reported in seconds and vary based on the number of training points and whether independent or autoregressive sampling is used.", "section": "Additional Implementation Details"}, {"figure_path": "HShs7q1Njh/tables/tables_23_1.jpg", "caption": "Table G.2: NLL and MAE for various prompt formats and each LLM. The height of each bar is the mean of 10 random seeds that determine the locations of the observed points. The small black lines at the top of each bar indicates the standard error. From left to right, the prompts are ordered from the most to least token efficient. The number below each function indicates the number of observed points.", "description": "This table presents the negative log-likelihood (NLL) and Mean Absolute Error (MAE) for different prompt formats across three large language models (LLMs).  The results are averaged over multiple random seed initializations, each determining the positions of observed data points. The table shows how different formatting schemes for the prompt affect the LLMs' performance on various functions with varying numbers of observed points. It is organized to demonstrate the effect of prompt structure on model accuracy.", "section": "G Additional Configuration Results"}, {"figure_path": "HShs7q1Njh/tables/tables_24_1.jpg", "caption": "Table G.2: NLL and MAE for various prompt formats and each LLM. The height of each bar is the mean of 10 random seeds that determine the locations of the observed points. The small black lines at the top of each bar indicates the standard error. From left to right, the prompts are ordered from the most to least token efficient.", "description": "This table shows the negative log-likelihood (NLL) and mean absolute error (MAE) for different prompt formats used with three different large language models (LLMs).  Each bar represents the average performance over ten different random seed configurations, indicating the variation in results. The prompt formats are compared based on their token efficiency. The most efficient format is indicated on the left, while the least efficient is on the right. ", "section": "G Additional Configuration Results"}, {"figure_path": "HShs7q1Njh/tables/tables_25_1.jpg", "caption": "Table G.4: Mean Average Error (MAE) and NLL for various prompt orderings and each LLM. Each entry is the mean and standard error of 10 random seeds that determine the locations of the observed points. The small black lines at the top of each bar indicates the standard error.", "description": "This table shows the results of an experiment comparing three different training data orderings for LLMs: sequential, random, and distance-based.  The table presents the mean average error (MAE) and negative log-likelihood (NLL) for each ordering across three different LLMs (Llama-2-7B, Llama-2-70B, and Mixtral-8x7B) on three synthetic function datasets (Sigmoid with 10 points, Quadratic with 20 points, and Linear + Cosine with 75 points). The distance-based ordering consistently shows the best results, likely because it emphasizes the relevance of data points closer to the prediction target.", "section": "G.3 Additional Prompt Ordering Results"}, {"figure_path": "HShs7q1Njh/tables/tables_26_1.jpg", "caption": "Table 1: Mean and standard error of MAE and NLL averaged over over the seven training set sizes and 3 seeds of each function for Mixtral-8\u00d77B A-LLMP and a GP with an RBF kernel.", "description": "This table presents a comparison of the Mean Absolute Error (MAE) and Negative Log-Likelihood (NLL) achieved by the Mixtral-8x7B A-LLMP model and a Gaussian Process (GP) model using a Radial Basis Function (RBF) kernel.  The comparison is performed across seven different training set sizes (5, 10, 15, 20, 25, 50, and 75 data points) and three random seeds for each function. The results illustrate the predictive performance of both models on several synthetic functions and highlight how performance changes as the amount of training data varies.", "section": "Evaluating LLMP Performance on Numerical Data"}, {"figure_path": "HShs7q1Njh/tables/tables_28_1.jpg", "caption": "Table 1: Mean and standard error of MAE and NLL averaged over over the seven training set sizes and 3 seeds of each function for Mixtral-8\u00d77B A-LLMP and a GP with an RBF kernel.", "description": "This table presents a comparison of the Mean Absolute Error (MAE) and Negative Log-Likelihood (NLL) achieved by the Mixtral-8x7B A-LLMP model and a Gaussian Process (GP) model using a Radial Basis Function (RBF) kernel.  The comparison is made across seven different training set sizes (5, 10, 15, 20, 25, 50, and 75 training points) for twelve different synthetic functions.  The results are averaged across three random seeds for each function and training set size.  The table aims to demonstrate the competitive performance of the LLMP model compared to a well-established GP regression model.", "section": "Evaluating LLMP Performance on Numerical Data"}, {"figure_path": "HShs7q1Njh/tables/tables_29_1.jpg", "caption": "Table G.7: Mean Average Error (MAE) and Negative Log Likelihood (NLL) for autoregressive and marginal sampling with two different prompt orderings and three LLMs.", "description": "This table presents the results of an experiment comparing two methods for defining joint predictive distributions over multiple target locations (I-LLMP and A-LLMP) and using three different LLMs. The table shows the Mean Average Error (MAE) and Negative Log Likelihood (NLL) for each method, with the training data ordered randomly or by distance to the target point.  The results indicate that the autoregressive approach (A-LLMP) generally achieves better performance, particularly when using distance-ordered training data.", "section": "G Additional Configuration Results"}, {"figure_path": "HShs7q1Njh/tables/tables_47_1.jpg", "caption": "Table H.8: Black box optimization results. The number in the Function column indicates the number of x dimensions. The Trial column indicates the trial at which the Best estimate of the maximum for each method occurred.", "description": "This table compares the performance of Optuna and Llama-7B in a black-box optimization task across six different functions with varying numbers of dimensions. For each function, it shows the true maximum value, the trial number at which the best result was achieved by each method, and the best maximum value found by each method.  This allows for a comparison of the efficiency and effectiveness of each method in finding the optimum.", "section": "H.5 Black-box Optimization Results and Implementation Details"}]