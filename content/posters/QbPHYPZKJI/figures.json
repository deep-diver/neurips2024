[{"figure_path": "QbPHYPZKJI/figures/figures_1_1.jpg", "caption": "Figure 1: Manifold Free-Form Flows (M-FFF) learn generative models on a variety of manifolds. (Left) The learned distributions (colored surface) accurately match the test points (black dots). (Right) We parameterize M-FFF using a neural network in an embedding space, whose outputs are projected to the manifold. This enables simulation-free training and inference, and naturally respects the corresponding geometry, yielding fast sampling and continuous distributions regardless of the manifold.", "description": "This figure shows examples of manifold free-form flows (M-FFF) applied to various manifolds. The left side shows the learned distributions (colored surfaces) which accurately match the given test points (black dots) on spheres, tori, hyperbolic surfaces, and curved surfaces. The right side illustrates the process of M-FFF. It uses a neural network to generate outputs in an embedding space.  These outputs are then projected to the manifold, ensuring that the generated samples respect the underlying geometry. This approach allows for efficient and simulation-free training and inference, resulting in fast sampling and continuous distributions.", "section": "1 Introduction"}, {"figure_path": "QbPHYPZKJI/figures/figures_5_1.jpg", "caption": "Figure 2: Computation of the volume change in the tangent space of the manifold: The manifold change of variables formula in Eq. (10) requires to compute the change of a volume element in the tangent spaces under f, which in this example is given by the ratio of lengths of dt and dt'. Since f is a map in the embedding space, f'(x) defines a linear map between vectors from the embedding space. To correctly compute the change in volume, we use Q and R to change coordinates to the intrinsic tangent spaces, resulting in the linear map RT f'(x)Q : TxM \u2192 Tf(x)M, which maps dt to dt'.", "description": "The figure shows how the volume change is computed in the tangent space of a Riemannian manifold.  It illustrates that the Jacobian of a function acting on a manifold needs to be projected to the tangent space in order to correctly calculate the volume change. The projection is performed using orthonormal basis Q and R for the tangent spaces at x and f(x) respectively. This is because the function is defined on the embedding space, but volume change must be measured intrinsically on the manifold.", "section": "Manifold change of variables"}, {"figure_path": "QbPHYPZKJI/figures/figures_24_1.jpg", "caption": "Figure 1: Manifold Free-Form Flows (M-FFF) learn generative models on a variety of manifolds. (Left) The learned distributions (colored surface) accurately match the test points (black dots). (Right) We parameterize M-FFF using a neural network in an embedding space, whose outputs are projected to the manifold. This enables simulation-free training and inference, and naturally respects the corresponding geometry, yielding fast sampling and continuous distributions regardless of the manifold.", "description": "This figure shows examples of Manifold Free-Form Flows (M-FFF) applied to various manifolds.  The left side illustrates how the learned probability distribution (shown as a colored surface) accurately represents the data points (black dots) on different manifolds such as a sphere, torus, and hyperbolic surface. The right side illustrates the M-FFF model architecture. It shows that the model uses a neural network to parameterize the distribution in an embedding space and then projects these parameters to the target manifold. This allows M-FFF to learn distributions on arbitrary manifolds efficiently.", "section": "1 Introduction"}, {"figure_path": "QbPHYPZKJI/figures/figures_25_1.jpg", "caption": "Figure 5: Log density of M-FFF models in the (\u03a6, \u03a8)-plane of protein backbone dihedral angles (known as Ramachandran plot[Ramachandran et al., 1963]). The learned density matches the true density indicated by the test dataset (black dots) very well. Note also that the learned distribution obeys the periodic boundary conditions.", "description": "This figure shows the log density plots generated by the Manifold Free-Form Flows (M-FFF) models for four different protein datasets (General, Glycine, Proline, and Pre-Proline). Each plot displays the log density as a function of two dihedral angles, \u03a6 and \u03a8, which are commonly used to represent the backbone conformation of proteins. The black dots represent the actual data points from the test dataset. The color scheme represents the density, where darker colors indicate lower density and lighter colors indicate higher density. The plots demonstrate that the M-FFF model accurately captures the distribution of the data points and satisfies the periodic boundary conditions of the dihedral angles.", "section": "Torsion angles of molecules on tori"}, {"figure_path": "QbPHYPZKJI/figures/figures_26_1.jpg", "caption": "Figure 1: Manifold Free-Form Flows (M-FFF) learn generative models on a variety of manifolds. (Left) The learned distributions (colored surface) accurately match the test points (black dots). (Right) We parameterize M-FFF using a neural network in an embedding space, whose outputs are projected to the manifold. This enables simulation-free training and inference, and naturally respects the corresponding geometry, yielding fast sampling and continuous distributions regardless of the manifold.", "description": "This figure shows examples of Manifold Free-Form Flows (M-FFF) applied to various manifolds.  The left side shows the learned probability distributions (colored surfaces) overlayed on point clouds of the test data. The right side illustrates the architecture, showing how a neural network in an embedding space generates samples that are then projected onto the manifold, demonstrating the model's ability to generate data respecting the manifold's geometry, offering a simulation-free method that is both fast and accurate.", "section": "1 Introduction"}]