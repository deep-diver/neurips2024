{"references": [{"fullname_first_author": "R. Agarwal", "paper_title": "Deep reinforcement learning at the edge of the statistical precipice", "publication_date": "2021-12-01", "reason": "This paper provides a comprehensive analysis of deep reinforcement learning's challenges and limitations, which is crucial for understanding the context of the current work."}, {"fullname_first_author": "D. Bertsekas", "paper_title": "Multiagent reinforcement learning: Rollout and policy iteration", "publication_date": "2021-01-01", "reason": "This paper introduces the sequential updating scheme for MARL, which directly inspires the MADPO method and its theoretical foundation."}, {"fullname_first_author": "J. Kuba", "paper_title": "Trust region policy optimisation in multi-agent reinforcement learning", "publication_date": "2022-01-01", "reason": "This paper proposes HAPPO, a state-of-the-art sequential MARL algorithm, which is used as a key baseline for comparison in the current work."}, {"fullname_first_author": "C. Yu", "paper_title": "The surprising effectiveness of ppo in cooperative multi-agent games", "publication_date": "2022-12-01", "reason": "This paper explores the effectiveness of PPO in cooperative MARL, which provides valuable insights into the design and optimization of MADPO."}, {"fullname_first_author": "S. Yu", "paper_title": "The conditional cauchy-schwarz divergence with applications to time-series data and sequential decision making", "publication_date": "2023-01-01", "reason": "This paper introduces the conditional Cauchy-Schwarz divergence, a key component of MADPO that enhances exploration and stability."}]}