[{"figure_path": "PAWQvrForJ/tables/tables_7_1.jpg", "caption": "Table 1: AUC Score for detecting member texts from four LLMs across three datasets for SPV-MIA and five previously proposed methods. Bold and Underline respectively represent the best and the second-best results within each column (model-dataset pair).", "description": "This table presents the Area Under the Curve (AUC) scores for a membership inference attack (MIA) called SPV-MIA and five other MIA methods.  The AUC is a metric measuring the performance of the MIAs, with higher scores indicating better performance in distinguishing between data records used in the training dataset (member) and those not used (non-member). The results are broken down by four different Large Language Models (LLMs) and three distinct datasets, showing the AUC for each combination.  Bold and underlined values highlight the best and second-best performing MIAs, respectively, for each LLM/dataset pair.", "section": "5.2 Overall Performance"}, {"figure_path": "PAWQvrForJ/tables/tables_7_2.jpg", "caption": "Table 1: AUC Score for detecting member texts from four LLMs across three datasets for SPV-MIA and five previously proposed methods. Bold and Underline respectively represent the best and the second-best results within each column (model-dataset pair).", "description": "This table presents the Area Under the Curve (AUC) scores achieved by seven different membership inference attack (MIA) methods on four different large language models (LLMs) across three distinct datasets.  The AUC score reflects the performance of each MIA method in correctly identifying whether a data point was part of the training dataset for a given LLM.  The table highlights the superior performance of the proposed SPV-MIA method compared to existing techniques.", "section": "5.2 Overall Performance"}, {"figure_path": "PAWQvrForJ/tables/tables_9_1.jpg", "caption": "Table 3: The AUC performance of SPV-MIA against LLaMA fine-tuned with DP-SGD w.r.t different privacy budget e.", "description": "This table shows the AUC (Area Under the Curve) scores achieved by the SPV-MIA attack against the LLaMA language model. The LLaMA model was fine-tuned using DP-SGD (Differentially Private Stochastic Gradient Descent) with varying privacy budgets (epsilon).  The AUC represents the performance of the attack at different levels of privacy protection. Higher AUC values indicate a more successful attack, while lower values indicate a less successful attack, suggesting better privacy protection.", "section": "5.5 Defending against SPV-MIAS"}, {"figure_path": "PAWQvrForJ/tables/tables_9_2.jpg", "caption": "Table 4: The AUC Performance of SPV-MIA across LLaMAs fine-tuned with different PEFT techniques over three datasets. We choose LoRA [24], Prefix Tuning [35], P-Tuning [38] and (IA)\u00b3 [37] as four representative PEFT techniques.", "description": "This table shows the Area Under the Curve (AUC) scores achieved by the Self-calibrated Probabilistic Variation Membership Inference Attack (SPV-MIA) when using different Parameter-Efficient Fine-Tuning (PEFT) techniques on three different datasets (Wiki, AG News, and XSum).  It compares the performance across four PEFT methods: LoRA, Prefix Tuning, P-Tuning, and (IA)\u00b3, highlighting the impact of the number of trainable parameters on the attack's effectiveness.", "section": "5.5.1 Impact of Fine-tuning Methods"}, {"figure_path": "PAWQvrForJ/tables/tables_17_1.jpg", "caption": "Table 1: AUC Score for detecting member texts from four LLMs across three datasets for SPV-MIA and five previously proposed methods. Bold and Underline respectively represent the best and the second-best results within each column (model-dataset pair).", "description": "This table presents the Area Under the Curve (AUC) scores for several membership inference attack (MIA) methods, including the proposed SPV-MIA,  on four different Large Language Models (LLMs) and three datasets.  The AUC score measures the ability of each MIA to distinguish between data records that were and were not part of the LLM's training data.  Bold and underlined entries highlight the best and second-best performing methods for each LLM-dataset combination.", "section": "5.2 Overall Performance"}, {"figure_path": "PAWQvrForJ/tables/tables_19_1.jpg", "caption": "Table 6: The MIA performance of SPV-MIA while applied different paraphrasing methods.", "description": "This table presents the performance of the SPV-MIA attack using different paraphrasing methods (embedding, semantic, and neighbour comparing). The results are broken down by dataset (Wiki, AG News, Xsum) and show the average AUC score across all three datasets.  The table helps to evaluate the effectiveness of different paraphrasing techniques in improving the performance of the membership inference attack.", "section": "5 Experiments"}, {"figure_path": "PAWQvrForJ/tables/tables_19_2.jpg", "caption": "Table 7: Results of Ablation Study on GPT-J and LLaMA across three datasets.", "description": "This table presents the results of an ablation study conducted to evaluate the individual contributions of the two modules proposed in the SPV-MIA model: Practical Difficulty Calibration (PDC) and Probabilistic Variation Assessment (PVA).  The study compares the Area Under the Curve (AUC) scores achieved by the full SPV-MIA model against versions that exclude either PDC or PVA.  Results are shown for two different LLMs (GPT-J and LLaMA) and three datasets (Wiki, AG News, XSum).  This allows for assessment of the relative importance of each module in achieving the overall performance improvement.", "section": "5.2 Overall Performance"}, {"figure_path": "PAWQvrForJ/tables/tables_20_1.jpg", "caption": "Table 1: AUC Score for detecting member texts from four LLMs across three datasets for SPV-MIA and five previously proposed methods. Bold and Underline respectively represent the best and the second-best results within each column (model-dataset pair).", "description": "This table presents the Area Under the Curve (AUC) scores achieved by several membership inference attack (MIA) methods, including the proposed SPV-MIA, when applied to four different large language models (LLMs) across three different datasets.  The AUC score is a metric measuring the performance of the MIAs in distinguishing between data records that were part of the training dataset and those that weren't.  Higher AUC scores indicate better performance. The table highlights the superior performance of SPV-MIA compared to the existing MIAs.", "section": "5.2 Overall Performance"}, {"figure_path": "PAWQvrForJ/tables/tables_21_1.jpg", "caption": "Table 9: The perplexity (PPL) of each LLM-dataset pair on training set and test set.", "description": "This table shows the perplexity (PPL) scores for four different large language models (LLMs) fine-tuned on three different datasets.  Perplexity is a measure of how well a probability model predicts a sample. Lower perplexity indicates better performance.  The table is divided into training and test set perplexities for each LLM and dataset combination.", "section": "5.1 Experimental Setup"}, {"figure_path": "PAWQvrForJ/tables/tables_21_2.jpg", "caption": "Table 10: The perplexity (PPL) of each LLM-dataset pair trained w.r.t different privacy budget \u20ac.", "description": "This table shows the perplexity scores achieved by four different LLMs (GPT-2, GPT-J, Falcon, and LLaMA) when fine-tuned on three datasets (Wiki, AG News, and XSum) under varying privacy budget levels (15, 30, 60, and +inf).  Lower perplexity scores indicate better model performance.  The table allows for comparison of model performance across different LLMs and datasets while highlighting the effect of differential privacy on model perplexity.", "section": "5.5 Defending against SPV-MIAS"}, {"figure_path": "PAWQvrForJ/tables/tables_22_1.jpg", "caption": "Table 3: The AUC performance of SPV-MIA against LLaMA fine-tuned with DP-SGD w.r.t different privacy budget e.", "description": "This table shows the Area Under the Curve (AUC) scores for the SPV-MIA attack against the LLaMA language model.  The LLaMA model was fine-tuned using differentially private stochastic gradient descent (DP-SGD) with varying privacy budgets (epsilon). The AUC scores indicate the attack's performance at distinguishing between data points that were and were not part of the training set.  Higher AUC scores represent better attack performance, and the results show how the attack's effectiveness changes depending on the level of privacy protection applied during fine-tuning.", "section": "5.5 Defending against SPV-MIAS"}, {"figure_path": "PAWQvrForJ/tables/tables_22_2.jpg", "caption": "Table 1: AUC Score for detecting member texts from four LLMs across three datasets for SPV-MIA and five previously proposed methods. Bold and Underline respectively represent the best and the second-best results within each column (model-dataset pair).", "description": "This table presents the Area Under the Curve (AUC) scores achieved by seven different membership inference attack (MIA) methods on four different large language models (LLMs) across three distinct datasets.  SPV-MIA is compared to five existing MIA techniques.  The AUC score reflects the ability of each method to correctly identify whether a data record was used in the training of the LLM.  Bold and underlined values highlight the best and second-best performing methods in each column.", "section": "5.2 Overall Performance"}]