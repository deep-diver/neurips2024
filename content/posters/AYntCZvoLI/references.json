{"references": [{"fullname_first_author": "Ball\u00e9", "paper_title": "End-to-end optimized image compression", "publication_date": "2017-00-00", "reason": "This paper established the end-to-end rate-distortion minimization framework for learned image compression, a foundational work in the field."}, {"fullname_first_author": "Ball\u00e9", "paper_title": "Variational image compression with a scale hyperprior", "publication_date": "2018-00-00", "reason": "This paper introduced the use of a scale hyperprior in variational autoencoders for image compression, significantly improving performance."}, {"fullname_first_author": "Minnen", "paper_title": "Joint autoregressive and hierarchical priors for learned image compression", "publication_date": "2018-00-00", "reason": "This paper introduced the use of autoregressive models combined with hierarchical priors in the entropy model for learned image compression, which is a key technique."}, {"fullname_first_author": "He", "paper_title": "Elic: Efficient learned image compression with unevenly grouped space-channel contextual adaptive coding", "publication_date": "2022-00-00", "reason": "This paper introduced the unevenly grouped autoregressive coding strategy, improving efficiency and rate-distortion performance."}, {"fullname_first_author": "Zou", "paper_title": "The devil is in the details: Window-based attention for image compression", "publication_date": "2022-00-00", "reason": "This paper uses window-based attention in the autoencoder and improved the state-of-the-art results."}]}