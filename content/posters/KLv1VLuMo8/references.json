{"references": [{"fullname_first_author": "Volodymyr Mnih", "paper_title": "Human-level control through deep reinforcement learning", "publication_date": "2015-02-00", "reason": "This paper is foundational for deep reinforcement learning (DRL) and its success in addressing complex problems, which is the core topic of the subject paper."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal Policy Optimization Algorithms", "publication_date": "2017-08-00", "reason": "This paper introduces the Proximal Policy Optimization (PPO) algorithm, a crucial DRL algorithm used in the subject paper's experiments."}, {"fullname_first_author": "Niranjan Srinivas", "paper_title": "Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting", "publication_date": "2012-05-00", "reason": "This paper provides theoretical foundations for Bayesian optimization (BO), a key method used in the subject paper's Model-Based Transfer Learning (MBTL) framework."}, {"fullname_first_author": "Richard S. Sutton", "paper_title": "Reinforcement learning: an introduction", "publication_date": "2018-00-00", "reason": "This is a comprehensive textbook on reinforcement learning, providing essential background and context for the subject paper's research on contextual reinforcement learning."}, {"fullname_first_author": "Aditya Modi", "paper_title": "Markov Decision Processes with Continuous Side Information", "publication_date": "2018-04-00", "reason": "This paper formalizes the concept of contextual Markov Decision Processes (CMDPs), which is the theoretical foundation for the subject paper's focus on contextual reinforcement learning."}]}