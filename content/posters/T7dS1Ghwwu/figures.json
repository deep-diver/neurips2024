[{"figure_path": "T7dS1Ghwwu/figures/figures_8_1.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when a = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 - a class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure shows the class-conditional coverage and prediction set size for four different datasets (CIFAR-10, CIFAR-100, mini-ImageNet, and Food-101) using three different methods (CCP, Cluster-CP, and RC3P).  The top row shows the class-conditional coverage, demonstrating that RC3P achieves higher coverage above the target threshold (0.9) compared to the other methods. The bottom row displays the prediction set size, highlighting that RC3P generates significantly smaller prediction sets than CCP and Cluster-CP, especially for CIFAR-100, mini-ImageNet, and Food-101.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_9_1.jpg", "caption": "Figure 2: Visualization for the normalized frequency distribution of label ranks included in the prediction set of CCP, Cluster-CP, and RC3P with p = 0.1 for imbalance type EXP when a = 0.1 and models are trained with 200 epochs. It is clear that the distribution of normalized frequency generated by RC3P tends to be lower compared to those produced by CCP and Cluster-CP. Furthermore, the probability density function tail for label ranks in the RC3P prediction set is notably shorter than that of other methods.", "description": "This figure visualizes the normalized frequency distribution of label ranks in the prediction sets generated by three different methods (CCP, Cluster-CP, and RC3P) for imbalanced datasets with imbalance type EXP and a mis-coverage rate of 0.1. The models used were trained for 200 epochs.  The results show that RC3P produces a distribution with lower label ranks and a shorter tail compared to CCP and Cluster-CP, indicating a more effective use of lower-ranked labels in its predictions.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_9_2.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}y=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure empirically validates the theoretical condition (Equation 6 and Lemma 4.2) for RC3P to achieve better predictive efficiency than CCP.  It shows the distribution of the condition numbers (\u03c3y) across different classes for the CIFAR-10, CIFAR-100, mini-ImageNet, and Food-101 datasets. The vertical dashed line indicates a \u03c3y value of 1.  Since all observed \u03c3y values are below 1, the condition is satisfied, suggesting that RC3P should produce smaller prediction sets than CCP for the given settings.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_18_1.jpg", "caption": "Figure 4: Illustrative examples of the different imbalanced distributions of the number of training examples per class index on CIFAR-100.", "description": "This figure shows three different ways to create imbalanced datasets from a balanced dataset. The x-axis represents the class index, and the y-axis represents the number of training examples in each class.  (a) shows an exponential decay, (b) shows a polynomial decay, and (c) shows a majority-based decay.  These illustrate the different distributions of data that can occur with imbalanced datasets, where some classes have far fewer examples than others.", "section": "5.1 Experimental Setup"}, {"figure_path": "T7dS1Ghwwu/figures/figures_31_1.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when a = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 \u2212 a class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure shows the class-conditional coverage and prediction set size for four different datasets (CIFAR-10, CIFAR-100, mini-ImageNet, and Food-101) using three different conformal prediction methods (CCP, Cluster-CP, and RC3P).  The top row shows the distribution of class-wise coverage, demonstrating that RC3P achieves a higher coverage above the target threshold (0.9) than the other two methods. The bottom row illustrates the distribution of prediction set sizes, revealing that RC3P generates significantly smaller prediction sets, improving predictive efficiency while maintaining class-wise coverage.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_31_2.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when \u03b1 = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 \u2212 \u03b1 class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure compares the performance of three class-conditional conformal prediction methods (CCP, Cluster-CP, and RC3P) in terms of class-wise coverage and prediction set size on four imbalanced datasets.  The top row shows the class-wise coverage achieved by each method, while the bottom row shows the distribution of prediction set sizes.  The results demonstrate that RC3P achieves similar coverage to the other methods while generally producing significantly smaller prediction sets, particularly on CIFAR-100, mini-ImageNet, and Food-101.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_32_1.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when a = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 - a class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure compares the performance of three class-conditional conformal prediction methods (CCP, Cluster-CP, and RC3P) on four imbalanced datasets. The top row shows the class-conditional coverage, while the bottom row displays the prediction set sizes. The results demonstrate that RC3P achieves higher class-conditional coverage and smaller prediction set sizes than the other two methods, particularly on CIFAR-100, mini-ImageNet, and Food-101.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_32_2.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when a = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 \u2212 a class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure shows the class-conditional coverage and prediction set size for four different datasets (CIFAR-10, CIFAR-100, mini-ImageNet, Food-101) with an imbalance ratio of p=0.1 and using the exponential decay type.  The top row displays histograms of the class-wise coverage for each method (CCP, Cluster-CP, and RC3P), demonstrating that RC3P achieves higher class-conditional coverage above 0.9 (the target 1-\u03b1). The bottom row shows histograms of prediction set sizes, illustrating that RC3P produces significantly smaller prediction sets, especially for CIFAR-100, mini-ImageNet, and Food-101.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_33_1.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when a = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 - a class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure shows the class-conditional coverage and prediction set size for four different datasets (CIFAR-10, CIFAR-100, mini-ImageNet, and Food-101) using three different methods (CCP, Cluster-CP, and RC3P). The top row displays the class-conditional coverage for each method, while the bottom row shows the prediction set sizes. The results demonstrate that RC3P outperforms CCP and Cluster-CP in terms of both coverage and prediction set size, particularly for CIFAR-100, mini-ImageNet, and Food-101.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_33_2.jpg", "caption": "Figure 2: Visualization for the normalized frequency distribution of label ranks included in the prediction set of CCP, Cluster-CP, and RC3P with p = 0.1 for imbalance type EXP when a = 0.1 and models are trained with 200 epochs. It is clear that the distribution of normalized frequency generated by RC3P tends to be lower compared to those produced by CCP and Cluster-CP. Furthermore, the probability density function tail for label ranks in the RC3P prediction set is notably shorter than that of other methods.", "description": "This figure visualizes the normalized frequency distribution of label ranks in the prediction sets generated by three different methods: CCP, Cluster-CP, and RC3P.  It shows that RC3P uses lower-ranked labels more frequently than the other two methods, indicating improved predictive efficiency. The shorter tail of the distribution for RC3P further suggests that RC3P produces more concise prediction sets.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_33_3.jpg", "caption": "Figure 2: Visualization for the normalized frequency distribution of label ranks included in the prediction set of CCP, Cluster-CP, and RC3P with p = 0.1 for imbalance type EXP when a = 0.1 and models are trained with 200 epochs. It is clear that the distribution of normalized frequency generated by RC3P tends to be lower compared to those produced by CCP and Cluster-CP. Furthermore, the probability density function tail for label ranks in the RC3P prediction set is notably shorter than that of other methods.", "description": "This figure visualizes the distribution of label ranks used in prediction sets generated by CCP, Cluster-CP, and RC3P methods.  It shows that RC3P utilizes significantly fewer high-ranked labels compared to the other methods, implying better predictive efficiency. This is further highlighted by the shorter tail in the probability density function of label ranks for RC3P, indicating a preference for more certain predictions.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_34_1.jpg", "caption": "Figure 2: Visualization for the normalized frequency distribution of label ranks included in the prediction set of CCP, Cluster-CP, and RC3P with p = 0.1 for imbalance type EXP when a = 0.1 and models are trained with 200 epochs. It is clear that the distribution of normalized frequency generated by RC3P tends to be lower compared to those produced by CCP and Cluster-CP. Furthermore, the probability density function tail for label ranks in the RC3P prediction set is notably shorter than that of other methods.", "description": "This figure visualizes the normalized frequency distribution of label ranks in prediction sets generated by three different methods: CCP, Cluster-CP, and RC3P.  The experiment used the EXP imbalance type with p=0.1 and a miscoverage rate (alpha) of 0.1. Models were trained for 200 epochs.  The results show that RC3P uses lower-ranked labels more frequently than the other methods, indicated by a shorter tail in the probability distribution.  This suggests that RC3P incorporates less uncertain predictions (higher ranked labels) into its prediction sets.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_34_2.jpg", "caption": "Figure 2: Visualization for the normalized frequency distribution of label ranks included in the prediction set of CCP, Cluster-CP, and RC3P with p = 0.1 for imbalance type EXP when a = 0.1 and models are trained with 200 epochs. It is clear that the distribution of normalized frequency generated by RC3P tends to be lower compared to those produced by CCP and Cluster-CP. Furthermore, the probability density function tail for label ranks in the RC3P prediction set is notably shorter than that of other methods.", "description": "This figure visualizes the frequency distribution of label ranks within prediction sets generated by three different methods: CCP, Cluster-CP, and RC3P. The results show that RC3P tends to incorporate lower-ranked labels, indicating improved predictive efficiency. This efficiency is further emphasized by the shorter tail of the probability density function for label ranks in RC3P's predictions, suggesting a greater focus on more certain predictions.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_34_3.jpg", "caption": "Figure 2: Visualization for the normalized frequency distribution of label ranks included in the prediction set of CCP, Cluster-CP, and RC3P with p = 0.1 for imbalance type EXP when a = 0.1 and models are trained with 200 epochs. It is clear that the distribution of normalized frequency generated by RC3P tends to be lower compared to those produced by CCP and Cluster-CP. Furthermore, the probability density function tail for label ranks in the RC3P prediction set is notably shorter than that of other methods.", "description": "This figure visualizes the normalized frequency distribution of label ranks in the prediction sets generated by three different class-conditional conformal prediction methods: CCP, Cluster-CP, and RC3P.  The results are shown for an imbalanced dataset with an exponential decay in class distribution (EXP) with a miscoverage rate (alpha) of 0.1, and models trained for 200 epochs.  The key observation is that RC3P produces a significantly lower frequency of high-ranked labels in its prediction sets compared to CCP and Cluster-CP, indicating a greater emphasis on more certain predictions.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_34_4.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}K=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure verifies the condition in Lemma 4.2 of the paper. The condition number \u03c3y is computed for each class and plotted in a histogram.  The vertical dashed lines indicate the value 1. Since all the computed \u03c3y values are less than 1, it confirms that RC3P produces smaller prediction sets than CCP. This is because the combined calibration on non-conformity scores and label ranks of RC3P leads to better trade-off between coverage and efficiency compared to CCP.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_35_1.jpg", "caption": "Figure 15: Verification of condition numbers {\u03c3y}y=1 of Equation 6 when epoch = 200 and \u03b1 = 0.1 with p = 0.5 EXP. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP by the optimized trade-off between calibration on non-conformity scores and calibrated label ranks.", "description": "This figure shows the empirical verification of the condition numbers (\u03c3y) from Equation 6 in the paper.  Each histogram represents the distribution of \u03c3y values for one of four datasets (CIFAR-10, CIFAR-100, mini-ImageNet, Food-101). The vertical dashed line indicates a value of 1. Because all histograms show that the condition numbers are below 1, this provides empirical support for Lemma 4.2 in the paper, which states that the proposed algorithm (RC3P) produces smaller prediction sets than the baseline method (CCP).  The improved efficiency comes from the combined calibration of conformity scores and label ranks.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_35_2.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}y=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure shows the verification of condition numbers (\u03c3y) calculated using Equation 6.  The x-axis represents the calculated \u03c3y values, and the y-axis represents the frequency of those values.  The vertical dashed lines indicate the value of 1. The results show that all calculated \u03c3y values are less than 1, which confirms the conditions for Lemma 4.2 and that RC3P produces smaller prediction sets than CCP due to the optimized trade-off between calibration using non-conformity scores and label ranks.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_35_3.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}K y=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure empirically validates the theoretical finding in Lemma 4.2 and Equation 6 that supports the efficiency improvement of RC3P over CCP. The condition number \u03c3y is calculated for each class and is shown to be less than 1, satisfying the condition for improved efficiency. This confirms that the combined calibration strategy of RC3P on conformity scores and label ranks leads to smaller prediction sets, as theoretically proven.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_35_4.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}y=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure empirically validates the theoretical finding (Lemma 4.2) that RC3P produces smaller prediction sets than CCP.  It shows the distribution of the condition numbers (\u03c3y), which quantify the predictive efficiency gain of RC3P over CCP.  The fact that all \u03c3y values are below 1 supports the theoretical claim, indicating that RC3P's combined calibration strategy consistently leads to smaller prediction sets.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_36_1.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}K=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure shows the verification of the condition numbers (\u03c3y) for the proposed RC3P algorithm. The condition number is defined in Equation 6, and it is a measure of the predictive efficiency improvement of RC3P over CCP.  The condition numbers are computed for four datasets (CIFAR-10, CIFAR-100, mini-ImageNet, Food-101) with imbalance type EXP and ratio p = 0.1, and models trained for 200 epochs. The vertical dashed lines represent the value 1. Since all condition numbers are smaller than 1, this verifies the validity of Lemma 4.2, and therefore RC3P's predictive efficiency improvement over CCP.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_36_2.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}y=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure empirically validates the theoretical finding in Lemma 4.2 and Equation (6) of the paper. It demonstrates that the condition numbers (\u03c3y) for all classes (y) are less than 1. This inequality is a crucial condition for RC3P to guarantee that its predictive efficiency is better than the baseline CCP method, and this figure empirically verifies the condition. By selectively applying the conformal thresholding subroutine based on the label ranks of the classifier's prediction, RC3P effectively reduces the size of the prediction sets compared to the uniform thresholding used in CCP, while maintaining the class-wise coverage guarantee.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_36_3.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}y=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure empirically validates the theoretical finding (Equation 6 and Lemma 4.2) that the condition number \u03c3y is less than 1.  The condition number \u03c3y compares the probability of a test sample falling within the prediction set of RC3P to the probability of it falling within the prediction set of CCP.  The fact that \u03c3y < 1 means that RC3P produces smaller prediction sets than CCP, improving predictive efficiency.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_36_4.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when \u03b1 = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 \u2212 \u03b1 class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure shows the results of experiments comparing three class-conditional conformal prediction methods (CCP, Cluster-CP, and RC3P) on four imbalanced datasets.  The top row displays the class-conditional coverage, showing that RC3P achieves higher coverage above the target (1-\u03b1) than the other methods.  The bottom row illustrates the average prediction set sizes, demonstrating that RC3P produces significantly smaller prediction sets than CCP and Cluster-CP on three of the four datasets (CIFAR-100, mini-ImageNet, and Food-101).", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_37_1.jpg", "caption": "Figure 15: Verification of condition numbers {\u03c3y}y=1 of Equation 6 when epoch = 200 and \u03b1 = 0.1 with p = 0.1 EXP. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP by the optimized trade-off between calibration on non-conformity scores and calibrated label ranks.", "description": "This figure shows the empirical verification of the condition \u03c3y \u2264 1 (Equation 6 in the paper) for the proposed RC3P algorithm. The condition ensures that RC3P produces smaller prediction sets than the baseline CCP method.  The histograms represent the distribution of the condition number \u03c3y for each class across four different datasets (CIFAR-10, CIFAR-100, mini-ImageNet, Food-101) using the EXP imbalance type with ratio p = 0.1 and training for 200 epochs.  The vertical dashed lines indicate the threshold of 1.  The fact that most of the distributions are concentrated below 1 empirically supports the theoretical finding and the advantage of RC3P.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_37_2.jpg", "caption": "Figure 3: Verification of condition numbers {\u03c3y}y=1 in Equation 6 with imbalance type EXP, p = 0.1 when \u03b1 = 0.1 and models are trained with 200 epochs. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure empirically validates the theoretical finding in Lemma 4.2 and Equation 6, demonstrating that RC3P achieves improved predictive efficiency compared to CCP.  The histogram shows the distribution of condition numbers (\u03c3y) across different classes, all of which are less than 1.  This supports the claim that RC3P produces smaller prediction sets due to the combined calibration on non-conformity scores and label ranks.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}, {"figure_path": "T7dS1Ghwwu/figures/figures_38_1.jpg", "caption": "Figure 1: Class-conditional coverage (Top row) and prediction set size (Bottom row) achieved by CCP, Cluster-CP, and RC3P methods when a = 0.1 and models are trained with 200 epochs on four imbalanced datasets with imbalance type EXP p = 0.1. We clarify that RC3P overlaps with CCP on CIFAR-10. It is clear that RC3P has more densely distributed class-conditional coverage above 0.9 (the target 1 \u2212 a class-conditional coverage) than CCP and Cluster-CP with significantly smaller prediction sets on CIFAR-100, mini-ImageNet and Food-101.", "description": "This figure shows the class-conditional coverage and prediction set size distributions for CCP, Cluster-CP, and RC3P methods on four datasets (CIFAR-10, CIFAR-100, mini-ImageNet, and Food-101) with an imbalance ratio of 0.1.  The top row displays histograms of class-wise coverage, showing that RC3P achieves coverage above the target (0.9) more often than the other methods. The bottom row shows histograms of prediction set sizes, demonstrating that RC3P consistently produces smaller prediction sets, especially noticeable on CIFAR-100, mini-ImageNet, and Food-101.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_38_2.jpg", "caption": "Figure 2: Visualization for the normalized frequency distribution of label ranks included in the prediction set of CCP, Cluster-CP, and RC3P with p = 0.1 for imbalance type EXP when a = 0.1 and models are trained with 200 epochs. It is clear that the distribution of normalized frequency generated by RC3P tends to be lower compared to those produced by CCP and Cluster-CP. Furthermore, the probability density function tail for label ranks in the RC3P prediction set is notably shorter than that of other methods.", "description": "This figure visualizes the normalized frequency distribution of label ranks in the prediction sets generated by three different methods: CCP, Cluster-CP, and RC3P. The results indicate that RC3P uses fewer labels with higher ranks compared to other methods.  The shorter tail of RC3P's probability density function further supports this conclusion, implying a higher focus on more certain predictions.", "section": "5.2 Results and Discussion"}, {"figure_path": "T7dS1Ghwwu/figures/figures_39_1.jpg", "caption": "Figure 28: Verification of condition numbers {\u03c3y}K y=1 in Equation 6 on balanced datasets. Vertical dashed lines represent the value 1, and we observe that all the condition numbers are smaller than 1. This verifies the validity of the condition for Lemma 4.2, and thus confirms that RC3P produces smaller prediction sets than CCP using calibration on both non-conformity scores and label ranks.", "description": "This figure shows the verification of the condition numbers (\u03c3y) used in Lemma 4.2 to guarantee the improved efficiency of RC3P over CCP.  The condition number is calculated for four datasets (CIFAR-100, Places365, iNaturalist, ImageNet).  The histograms show the distribution of (\u03c3y) for each dataset, and the vertical dashed lines indicate the value 1. The results demonstrate that RC3P produces smaller prediction sets because all condition numbers are below 1, fulfilling the condition of Lemma 4.2.", "section": "4.2 Analysis of Predictive Efficiency for RC3P"}]