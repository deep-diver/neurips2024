[{"figure_path": "pVPyCgXv57/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of our method with conventional token merging. Contrary to prior works that merge tokens directly based on intermediate features in ViT, our method leverages a decoupled embedding to extract features tailored for token merging. The embedding module is trained via continuous relaxation of grouping and merging operators, i.e., soft grouping and merging, respectively, that allow differentiation.", "description": "The figure compares conventional token merging with the proposed DTEM method.  Conventional methods directly use intermediate features from the Vision Transformer (ViT) to determine which tokens to merge. DTEM, in contrast, uses a separate, learned \"decoupled embedding module\" to extract features specifically designed for the token merging process.  This decoupled approach allows for continuous relaxation of the merging operations during training, enabling more effective learning and facilitating integration with pre-trained ViT models. ", "section": "3 Method"}, {"figure_path": "pVPyCgXv57/figures/figures_6_1.jpg", "caption": "Figure 1: Comparison of our method with conventional token merging. Contrary to prior works that merge tokens directly based on intermediate features in ViT, our method leverages a decoupled embedding to extract features tailored for token merging. The embedding module is trained via continuous relaxation of grouping and merging operators, i.e., soft grouping and merging, respectively, that allow differentiation.", "description": "The figure compares the proposed DTEM method with conventional token merging methods.  Conventional methods directly use intermediate features from the Vision Transformer (ViT) to decide which tokens to merge.  In contrast, DTEM uses a separate, learned embedding module to extract features specifically designed for the token merging process. This decoupling allows for more effective merging and enables training using continuously relaxed (soft) grouping and merging operators, which are differentiable and thus more easily trained.", "section": "Method"}, {"figure_path": "pVPyCgXv57/figures/figures_8_1.jpg", "caption": "Figure 1: Comparison of our method with conventional token merging. Contrary to prior works that merge tokens directly based on intermediate features in ViT, our method leverages a decoupled embedding to extract features tailored for token merging. The embedding module is trained via continuous relaxation of grouping and merging operators, i.e., soft grouping and merging, respectively, that allow differentiation.", "description": "This figure compares the proposed method, Decoupled Token Embedding for Merging (DTEM), with conventional token merging methods.  Conventional methods directly use intermediate features from the Vision Transformer (ViT) to determine which tokens to merge.  In contrast, DTEM uses a separate, decoupled embedding module to learn features specifically for merging, independent of the ViT's main processing. This decoupling allows for more effective merging and training flexibility. DTEM uses 'soft' grouping and merging during training, enabling a differentiable process that improves learning of the decoupled embedding. During inference, these soft operators transition to hard operators, resulting in a similar outcome to other methods but with improved efficiency and generalization.", "section": "3 Method"}, {"figure_path": "pVPyCgXv57/figures/figures_9_1.jpg", "caption": "Figure 1: Comparison of our method with conventional token merging. Contrary to prior works that merge tokens directly based on intermediate features in ViT, our method leverages a decoupled embedding to extract features tailored for token merging. The embedding module is trained via continuous relaxation of grouping and merging operators, i.e., soft grouping and merging, respectively, that allow differentiation.", "description": "The figure compares the proposed method (DTEM) with conventional token merging methods.  Conventional methods directly use intermediate features from the Vision Transformer (ViT) to determine which tokens to merge. In contrast, DTEM uses a separate, decoupled embedding module to learn features specifically designed for the token merging process. This decoupled module is trained using a continuous relaxation of the grouping and merging steps, making the training process differentiable. This allows for more effective learning and easier integration into pre-trained ViT models.", "section": "3 Method"}, {"figure_path": "pVPyCgXv57/figures/figures_9_2.jpg", "caption": "Figure 1: Comparison of our method with conventional token merging. Contrary to prior works that merge tokens directly based on intermediate features in ViT, our method leverages a decoupled embedding to extract features tailored for token merging. The embedding module is trained via continuous relaxation of grouping and merging operators, i.e., soft grouping and merging, respectively, that allow differentiation.", "description": "This figure compares the proposed DTEM method with conventional token merging methods.  Conventional methods directly use intermediate features from the Vision Transformer (ViT) to determine which tokens to merge.  In contrast, DTEM uses a separate, decoupled embedding module to extract features specifically designed for the merging process. This decoupled module is trained using a continuous relaxation technique (soft grouping and merging), allowing for differentiable training and better optimization. The result is a more effective token merging strategy that avoids interfering with the ViT's core function of feature extraction.", "section": "3 Method"}, {"figure_path": "pVPyCgXv57/figures/figures_18_1.jpg", "caption": "Figure 6: More visualization of merged tokens. We apply a reduction profile with r = 16, leading to 11 tokens remaining in the final output.", "description": "This figure shows a visualization of merged tokens using two different methods: ToMe and DTEM.  It demonstrates the differences in how each method groups tokens together.  Each image is divided into patches, and patches of similar color represent groups merged by the algorithms.  Using a reduction rate of r=16 results in 11 remaining tokens after merging. The visualization highlights that DTEM focuses on merging background patches more effectively, resulting in a clearer separation of foreground objects compared to ToMe.", "section": "A.6 More Visualization Results"}]