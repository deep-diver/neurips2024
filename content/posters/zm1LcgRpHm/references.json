{"references": [{"fullname_first_author": "Haoyi Zhou", "paper_title": "Informer: Beyond efficient transformer for long sequence time-series forecasting", "publication_date": "2021-00-00", "reason": "This paper introduces Informer, a novel transformer-based model that significantly improves the efficiency of long-sequence time-series forecasting, directly influencing the development of S3."}, {"fullname_first_author": "Qiao Xiao", "paper_title": "Dynamic sparse network for time series classification: Learning what to \"see\"", "publication_date": "2022-00-00", "reason": "This paper introduces DSN, a dynamic sparse network architecture for time-series classification that serves as a key baseline and comparative model for S3."}, {"fullname_first_author": "Zhihan Yue", "paper_title": "TS2Vec: Towards universal representation of time series", "publication_date": "2022-00-00", "reason": "TS2Vec, a contrastive learning-based method for time-series representation, is frequently used as a baseline for evaluating the performance of S3."}, {"fullname_first_author": "Minhao Liu", "paper_title": "Scinet: Time series modeling and forecasting with sample convolution and interaction", "publication_date": "2022-00-00", "reason": "SCINet, another prominent convolutional neural network for time-series, provides a further comparison point and helps illustrate S3's advantages across different architectures."}, {"fullname_first_author": "Haixu Wu", "paper_title": "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting", "publication_date": "2021-00-00", "reason": "Autoformer, a transformer model focusing on long-term forecasting, is another relevant baseline, and its inclusion highlights the applicability of S3 to various types of time-series models."}]}