[{"figure_path": "444LAH3MhG/figures/figures_1_1.jpg", "caption": "Figure 1: Design philosophy of our BiLAF framework. In contrast to the previous method, our method ensures the selection of central samples to maintain diversity while also reserving capacity to choose boundary samples to enhance decision boundary learning.", "description": "This figure illustrates the key difference between the proposed BiLAF method and previous active finetuning methods in sample selection. Previous methods primarily focus on selecting samples based on global diversity, neglecting the importance of samples near decision boundaries.  In contrast, BiLAF incorporates a bi-level approach selecting both core samples (for diversity) and boundary samples (for uncertainty near decision boundaries) to improve model performance. The figure visually represents this using feature distribution diagrams, highlighting how BiLAF's selection strategy captures both global distribution and local decision boundary information.", "section": "1 Introduction"}, {"figure_path": "444LAH3MhG/figures/figures_2_1.jpg", "caption": "Figure 2: Our BiLAF framework in the Active Finetuning task. In the high-dimensional feature space, the Core Sample Selection focuses on pinpointing pseudo-class centers. Following this, we have devised a denoising method to eliminate noise samples. Subsequently, we compute the Boundary Score metric for each sample, which aids in the iterative selection of samples and the removal of candidates from the pool. Ultimately, the selected samples are labeled for supervised finetuning.", "description": "This figure illustrates the BiLAF framework's two-stage approach for active finetuning.  The first stage (Core Sample Selection) identifies pseudo-class centers in the high-dimensional feature space. A denoising method removes noisy samples. The second stage (Boundary Samples Selection) iteratively selects boundary samples based on a novel Boundary Score metric, balancing diversity and uncertainty.  Finally, selected samples are labeled and used for supervised finetuning.", "section": "3 BiLAF: Bi-Level Active Finetuning"}, {"figure_path": "444LAH3MhG/figures/figures_7_1.jpg", "caption": "Figure 3: tSNE Embeddings on CIFAR10 with 1% annotation budget of BiLAF. Pentagrams represent the chosen core samples, while circles denote the chosen boundary samples.", "description": "This figure uses t-distributed Stochastic Neighbor Embedding (t-SNE) to visualize the feature embeddings of CIFAR10 data points after applying the Bi-Level Active Finetuning Framework (BiLAF).  The core samples selected by BiLAF are marked as pentagrams, and the boundary samples are indicated by circles.  The visualization aims to show how BiLAF selects samples that are both representative of the data distribution (core samples) and informative for improving the model's decision boundaries (boundary samples). The different colors likely represent different classes in the CIFAR10 dataset. By focusing on these two types of samples, BiLAF aims to maximize the effectiveness of limited annotation budget in the active finetuning process. ", "section": "3 BiLAF: Bi-Level Active Finetuning"}, {"figure_path": "444LAH3MhG/figures/figures_8_1.jpg", "caption": "Figure 3: tSNE Embeddings on CIFAR10 with 1% annotation budget of BiLAF. Pentagrams represent the chosen core samples, while circles denote the chosen boundary samples.", "description": "This figure shows a t-SNE embedding of CIFAR10 features with 1% annotation budget using BiLAF.  The core samples selected by BiLAF are marked with pentagrams, and the boundary samples are marked with circles.  The visualization helps to illustrate how BiLAF selects core samples to represent the central areas of each class and boundary samples which lie near the decision boundaries. This approach improves the model's ability to learn the class boundaries effectively, which is one of the core ideas of BiLAF.", "section": "4.3 Analysis"}, {"figure_path": "444LAH3MhG/figures/figures_20_1.jpg", "caption": "Figure 5: Denoising Strength Visualization using tSNE Embeddings of CIFAR10.", "description": "This figure visualizes the impact of variations in the removal rate (Prm) during the denoising process on the retained samples.  The red bounding boxes highlight areas with significant changes, including outliers and regions of class confusion. As Prm increases, the number of samples in these areas decreases, reducing their influence on boundary selection, while relatively dense boundaries are often preserved. However, this is a trade-off, as some important samples might also be removed.", "section": "J Qualitative Visualization"}, {"figure_path": "444LAH3MhG/figures/figures_21_1.jpg", "caption": "Figure 6: tSNE Embeddings on CIFAR10 with 1% annotation budget of our BiLAF method and other methods.", "description": "This figure compares the sample selection results of four different methods (FDS, K-Means, ActiveFT, and BiLAF) on the CIFAR10 dataset using a 1% annotation budget.  t-SNE is used to visualize the high-dimensional feature embeddings in a 2D space.  Each color represents a different class. The plots show the spatial distribution of selected samples. BiLAF demonstrates a more focused selection on boundary samples, while the others show more central selections.", "section": "Qualitative Visualization"}]