[{"figure_path": "j6kJSS9O6I/tables/tables_5_1.jpg", "caption": "Table 1: Main Results. The best results are marked in bold and the second-best results are marked with underline. All the prompt-based baselines (\u221e) are evaluated under one-shot prompting and all the fine-tuning-based baselines (\u3147) are trained through LoRA. Red represents the changes of WKM relative to the optimal results in the baselines. WKM and agent model are different LoRAs sharing the same backbone.", "description": "This table presents the main results of the experiments conducted in the paper, comparing the performance of the proposed World Knowledge Model (WKM) against several strong baselines on three different datasets (ALFWorld, WebShop, and ScienceWorld).  The baselines include various prompt-based and fine-tuning-based methods.  The table shows the performance (seen and unseen tasks) for each method and dataset, with the best results highlighted. The \"Red\" values indicate the improvement achieved by WKM relative to the best-performing baseline for each dataset and task type.  The table also indicates whether the baseline is prompt-based or fine-tuned using LoRA.", "section": "4.2 Results"}, {"figure_path": "j6kJSS9O6I/tables/tables_6_1.jpg", "caption": "Table 3: Hallucinatory Action Rates on ALFWorld. We calculate the proportion of trajectories containing invalid actions regardless of their correctness.", "description": "This table presents the percentage of trajectories that contain invalid actions for different methods (NAT, ETO, KNOWAGENT, WKM) on the ALFWorld dataset, broken down into seen and unseen tasks.  An invalid action is an action that is not valid within the context of the task, regardless of whether the trajectory is ultimately successful or not. Lower percentages indicate better performance in avoiding hallucinatory actions.", "section": "4.2 Results"}, {"figure_path": "j6kJSS9O6I/tables/tables_6_2.jpg", "caption": "Table 1: Main Results. The best results are marked in bold and the second-best results are marked with underline. All the prompt-based baselines (\u221e) are evaluated under one-shot prompting and all the fine-tuning-based baselines (\u3147) are trained through LoRA. Red represents the changes of WKM relative to the optimal results in the baselines. WKM and agent model are different LoRAs sharing the same backbone.", "description": "This table presents the main results of the experiments conducted in the paper, comparing the performance of the proposed World Knowledge Model (WKM) with various baselines across three different datasets (ALFWorld, WebShop, and ScienceWorld).  The results are broken down by whether the model was prompt-based (one-shot) or fine-tuned using LoRA, and also by whether the task was seen or unseen. The table shows that the WKM consistently outperforms baselines in various scenarios, highlighting its effectiveness in improving agent planning performance.", "section": "4 Results"}, {"figure_path": "j6kJSS9O6I/tables/tables_7_1.jpg", "caption": "Table 4: Weak-guide-strong. The knowledge model here is based on Mistral-7B.", "description": "This table presents the results of using a weaker knowledge model (Mistral-7B) to guide stronger agent models (ChatGPT and GPT-4) on the ALFWorld task.  It demonstrates that even a weaker knowledge model can improve the performance of stronger models, supporting the 'weak-guide-strong' approach where a lightweight knowledge model guides a more powerful agent model.", "section": "4.3 Analysis"}, {"figure_path": "j6kJSS9O6I/tables/tables_15_1.jpg", "caption": "Table 1: Main Results. The best results are marked in bold and the second-best results are marked with underline. All the prompt-based baselines (\u221e) are evaluated under one-shot prompting and all the fine-tuning-based baselines (\u3147) are trained through LoRA. Red represents the changes of WKM relative to the optimal results in the baselines. WKM and agent model are different LoRAs sharing the same backbone.", "description": "This table presents the main results of the experiments comparing the proposed WKM method with several baselines across three different datasets (ALFWorld, WebShop, ScienceWorld).  For each dataset, results are shown separately for seen and unseen tasks, indicating the model's generalization ability.  The table shows performance metrics (average reward) for different models and highlights the best-performing method.", "section": "4 Results"}, {"figure_path": "j6kJSS9O6I/tables/tables_16_1.jpg", "caption": "Table 1: Main Results. The best results are marked in bold and the second-best results are marked with underline. All the prompt-based baselines (\u221e) are evaluated under one-shot prompting and all the fine-tuning-based baselines (\u3147) are trained through LoRA. Red represents the changes of WKM relative to the optimal results in the baselines. WKM and agent model are different LoRAs sharing the same backbone.", "description": "This table presents the main results of the proposed method (WKM) compared to various baselines across three datasets (ALFWorld, WebShop, and ScienceWorld).  It shows the performance of different models (using different backbones) under different evaluation setups (seen vs. unseen tasks), highlighting the superior performance of the proposed WKM.  The table also indicates whether methods are prompt-based (one-shot) or fine-tuned using LoRA.", "section": "4.2 Results"}, {"figure_path": "j6kJSS9O6I/tables/tables_19_1.jpg", "caption": "Table 1: Main Results. The best results are marked in bold and the second-best results are marked with underline. All the prompt-based baselines (\u221e) are evaluated under one-shot prompting and all the fine-tuning-based baselines (\u3147) are trained through LoRA. Red represents the changes of WKM relative to the optimal results in the baselines. WKM and agent model are different LoRAs sharing the same backbone.", "description": "This table presents the main results of the experiments conducted in the paper.  It compares the performance of the proposed World Knowledge Model (WKM) against several baseline methods across three different simulated environments (ALFWorld, WebShop, ScienceWorld) and under both seen and unseen conditions.  The table shows average reward, a measure of task completion success.  The baselines include both prompt-based methods (using large language models like GPT-4) and fine-tuning-based methods using LoRA.  The table highlights WKM's superior performance compared to other methods, especially on unseen tasks.", "section": "4.2 Results"}]