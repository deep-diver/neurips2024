[{"figure_path": "oe5ZEqTOaz/figures/figures_2_1.jpg", "caption": "Figure 1: The overall architecture of CGGM. During the training stage, classifiers are introduced to calculate the directions of unimodal gradients and evaluation metrics. During the inference stage, the classifiers are discarded.", "description": "This figure illustrates the architecture of the Classifier-Guided Gradient Modulation (CGGM) method.  It shows how multiple modalities are processed independently by encoders (\u03a61, \u03a62, ... \u03a6M), then fused by a fusion module (\u03a9).  Crucially, classifiers (f1, f2,... fM) are included during training to evaluate the individual contribution of each modality and adjust the gradient updates accordingly. The classifiers compute the utilization rate of each modality (direction) and the speed of improvement (magnitude) to guide the update of both modality-specific encoders and the fusion module, ensuring balanced multimodal learning. During inference, the classifiers are discarded for efficiency.", "section": "3 Proposed Method"}, {"figure_path": "oe5ZEqTOaz/figures/figures_3_1.jpg", "caption": "Figure 2: (a) Accuracy of each modality and the fusion. (b) Gradient magnitude of each modality. We use the Euclidean norm of the gradient vector to represent the gradient magnitude. (c) Gradient direction between each modality and their fusion. We use cosine similarity to represent the direction between two gradient vectors. We get all the results on the CMU-MOSI dataset.", "description": "This figure shows the analysis of gradient during the training process on the CMU-MOSI dataset.  (a) shows the accuracy of each modality (audio, video, text) and their fusion over epochs. (b) displays the gradient magnitude of each modality, using the Euclidean norm of the gradient vector. (c) illustrates the gradient direction similarity between each modality and the fusion using cosine similarity.", "section": "3.2 Gradient Analysis"}, {"figure_path": "oe5ZEqTOaz/figures/figures_7_1.jpg", "caption": "Figure 2: (a) Accuracy of each modality and the fusion. (b) Gradient magnitude of each modality. We use the Euclidean norm of the gradient vector to represent the gradient magnitude. (c) Gradient direction between each modality and their fusion. We use cosine similarity to represent the direction between two gradient vectors. We get all the results on the CMU-MOSI dataset.", "description": "This figure displays three graphs that illustrate the training process of a multimodal model using the CMU-MOSI dataset.  Graph (a) shows the accuracy of each modality (audio, video, text) and the fusion of all modalities over training epochs. Graph (b) illustrates the gradient magnitude for each modality and fusion. Graph (c) depicts the cosine similarity between each modality's gradient and the fused gradient, showing the alignment of gradients during training.", "section": "3.2 Gradient Analysis"}, {"figure_path": "oe5ZEqTOaz/figures/figures_8_1.jpg", "caption": "Figure 4: t-SNE visualization of the gradients of classifiers and the unimodal gradients. Each point represents a gradient vector or matrix of a batch of data.", "description": "This figure visualizes the gradients of classifiers and unimodal gradients using t-SNE for dimensionality reduction.  Each point in the plots represents a gradient vector or matrix from a batch of data. The plots compare the gradients obtained from the classifiers (which provide a prediction based on a single modality) to the gradients calculated for the fusion module, which integrates information from all modalities.  The proximity of points suggests the similarity of the gradients. This visualization helps to demonstrate the relationship between classifier gradients and the corresponding gradients used in the multimodal learning model, supporting the claim that classifier gradients can effectively represent unimodal gradients.", "section": "4.4 Classifier Performance and Gradient Direction"}, {"figure_path": "oe5ZEqTOaz/figures/figures_9_1.jpg", "caption": "Figure 5: The improved performance with different \\(p\\) and \\(\\lambda\\) compared to the joint training baseline.", "description": "This figure shows the ablation study results for hyperparameters \\(p\\) and \\(\\lambda\\) in the proposed CGGM method.  Subfigure (a) demonstrates the effect of varying the scaling hyperparameter \\(p\\) on accuracy and F1 score, showing an optimal range for \\(p\\) that maximizes performance. Subfigure (b) illustrates the effect of varying the loss trade-off hyperparameter \\(\\lambda\\) on accuracy and F1 score, revealing an optimal range for \\(\\lambda\\) that balances task performance and gradient modulation.  Both subfigures use bar graphs to present the improved performance compared to a joint training baseline, highlighting the importance of carefully tuning these parameters for optimal CGGM performance.", "section": "4.5 Ablation Study"}, {"figure_path": "oe5ZEqTOaz/figures/figures_13_1.jpg", "caption": "Figure 3: Changes in (a) performance, (b) gradient magnitude and (c) direction during training with CGGM. We get the results on CMU-MOSI dataset.", "description": "This figure visualizes the changes in model performance (accuracy), gradient magnitude, and gradient direction during the training process using the proposed Classifier-Guided Gradient Modulation (CGGM) method.  The results are specifically shown for the CMU-MOSI dataset.  It demonstrates how CGGM affects the learning dynamics across different modalities.  Panel (a) shows accuracy changes over epochs, while (b) and (c) illustrate the changes in the magnitude and direction of gradients, respectively.  The comparison highlights the balancing effect of CGGM on the learning process.", "section": "4.2 Implementation Details"}, {"figure_path": "oe5ZEqTOaz/figures/figures_13_2.jpg", "caption": "Figure 7: Changes in balancing term during the training process.", "description": "The figure shows the changes of balancing term during the training process with and without CGGM. The balancing term is used to modulate the gradient magnitude and direction to balance the training process. From the figure, we can observe that when CGGM is used, the balancing term of each modality fluctuates around 0, indicating that the training process is balanced. When CGGM is not used, the balancing term of the dominant modality is always greater than 0, indicating that the dominant modality is over-optimized.", "section": "4.5 Ablation Study"}]