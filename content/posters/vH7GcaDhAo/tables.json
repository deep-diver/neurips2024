[{"figure_path": "vH7GcaDhAo/tables/tables_4_1.jpg", "caption": "Table 1: Quantitative results on NYUv2. RSA (yellow), especially when trained with multiple datasets, generalizes better than using images to predict the transformation parameters. Global refers to optimizing a single scale and shift for the entire dataset (same scale and shift for every sample). Image denotes predicting scales and shifts using images. Red denotes scaling that uses ground truth. Median indicates scaling using the ratio between median of depth prediction and ground truth. Linear fit denotes optimizing scale and shift to fit to ground truth for each image. DA refers to domain adaptation. ZoeDepth performs per-pixel refinement.", "description": "This table presents a quantitative comparison of different methods for monocular depth estimation on the NYUv2 dataset.  It compares various scaling techniques (using images, a global scale and shift, median scaling, and linear fitting to ground truth) against the proposed RSA method. The results are evaluated using several metrics (\u03b4 < 1.25, \u03b4 < 1.25\u00b2, \u03b4 < 1.25\u00b3, Abs Rel, log10 RMSE).  The table highlights the improved generalization capabilities of RSA, particularly when trained on multiple datasets, compared to image-based scaling methods.", "section": "4 Experiments"}, {"figure_path": "vH7GcaDhAo/tables/tables_5_1.jpg", "caption": "Table 2: Quantitative results on KITTI Eigen Split. RSA (yellow), especially when trained with multiple datasets, generalizes better than using images to predict the transformation parameters. Please refer to Table 1 for more details about notations.", "description": "This table presents a quantitative comparison of different monocular depth estimation models on the KITTI Eigen Split dataset.  The models are evaluated using several metrics (\u03b4 < 1.25, \u03b4 < 1.25\u00b2, \u03b4 < 1.25\u00b3, Abs Rel, RMSElog, RMSE), comparing different scaling methods (Image, Median, Linear fit, Global, RSA).  The results show that the RSA method, especially when trained on multiple datasets (NYUv2, KITTI, VOID), achieves better generalization compared to using images alone to predict scale and shift parameters.  The table also provides a baseline comparison using median scaling and linear fitting.", "section": "4 Experiments"}, {"figure_path": "vH7GcaDhAo/tables/tables_6_1.jpg", "caption": "Table 3: Quantitative results on VOID. In zero-shot generalization and multi-dataset training (including the target dataset), RSA outperforms image scaling due to the robustness of text, which supports better generalization. Please refer to Table 1 for more details about notations.", "description": "This table presents a quantitative comparison of different methods for depth estimation on the VOID dataset, focusing on zero-shot generalization capabilities.  It compares RSA (the proposed method) against several baselines, including image-based scaling, median scaling, and a global scaling approach. The results are evaluated using several metrics (\u03b4<1.25, \u03b4<1.25\u00b2, \u03b4<1.25\u00b3, Abs Rel, log10 RMSE). The table demonstrates RSA's superior performance, particularly when trained on multiple datasets, highlighting the robustness of language descriptions in achieving better zero-shot generalization than image-based methods.", "section": "4 Experiments"}, {"figure_path": "vH7GcaDhAo/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative results on NYUv2. RSA (yellow), especially when trained with multiple datasets, generalizes better than using images to predict the transformation parameters. Global refers to optimizing a single scale and shift for the entire dataset (same scale and shift for every sample). Image denotes predicting scales and shifts using images. Red denotes scaling that uses ground truth. Median indicates scaling using the ratio between median of depth prediction and ground truth. Linear fit denotes optimizing scale and shift to fit to ground truth for each image. DA refers to domain adaptation. ZoeDepth performs per-pixel refinement.", "description": "This table presents a quantitative comparison of different monocular depth estimation methods on the NYUv2 dataset.  It evaluates the performance of various methods in terms of their ability to accurately predict metric depth from a single image. The methods compared include several baselines (Global, Image, Median, Linear Fit, and ZoeDepth) and the proposed RSA method. The table shows the results for three different metrics (\u03b4 < 1.25, \u03b4 < 1.25\u00b2, \u03b4 < 1.25\u00b3), along with Absolute Relative error (Abs Rel), log10 RMSE, and RMSE. The results demonstrate RSA's superior performance, particularly when trained on multiple datasets, highlighting its ability to generalize across different scenarios.", "section": "4 Experiments"}, {"figure_path": "vH7GcaDhAo/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative results on NYUv2. RSA (yellow), especially when trained with multiple datasets, generalizes better than using images to predict the transformation parameters. Global refers to optimizing a single scale and shift for the entire dataset (same scale and shift for every sample). Image denotes predicting scales and shifts using images. Red denotes scaling that uses ground truth. Median indicates scaling using the ratio between median of depth prediction and ground truth. Linear fit denotes optimizing scale and shift to fit to ground truth for each image. DA refers to domain adaptation. ZoeDepth performs per-pixel refinement.", "description": "This table presents a quantitative comparison of different methods for monocular depth estimation on the NYUv2 dataset.  The methods are evaluated using various metrics (\u03b4<1.25, \u03b4<1.25\u00b2, \u03b4<1.25\u00b3, Abs Rel, log10 RMSE), comparing the performance of RSA (the proposed method) against several baselines, including methods that use images or ground truth for scaling. The results show that RSA, especially when trained with multiple datasets, achieves better generalization and comparable performance to the upper bound of fitting relative depth to ground truth.", "section": "4 Experiments"}, {"figure_path": "vH7GcaDhAo/tables/tables_9_1.jpg", "caption": "Table 6: Different prompt design for RSA. Absolute relative errors (Abs Rel) reported. RSA models are trained using cross-datasets with the DPT model. For one given image, c(i) is the class of a detected or segmented instance, K(i) is the number of all instances belonging to c(i). By using segmentation results, the text includes background, which improves scale predication, especially for outdoors.", "description": "This table shows the impact of different prompt designs on the performance of the RSA model when trained across multiple datasets using the DPT model.  Four different prompt types are evaluated: using object detection results with and without instance counts, and using panoptic segmentation results with and without instance counts.  The results indicate that incorporating background information via panoptic segmentation generally leads to better performance, especially in outdoor scenes.", "section": "4 Experiments"}, {"figure_path": "vH7GcaDhAo/tables/tables_9_2.jpg", "caption": "Table 1: Quantitative results on NYUv2. RSA (yellow), especially when trained with multiple datasets, generalizes better than using images to predict the transformation parameters. Global refers to optimizing a single scale and shift for the entire dataset (same scale and shift for every sample). Image denotes predicting scales and shifts using images. Red denotes scaling that uses ground truth. Median indicates scaling using the ratio between median of depth prediction and ground truth. Linear fit denotes optimizing scale and shift to fit to ground truth for each image. DA refers to domain adaptation. ZoeDepth performs per-pixel refinement.", "description": "This table presents a quantitative comparison of different methods for monocular depth estimation on the NYUv2 dataset.  It evaluates various techniques, including RSA (the proposed method), using metrics such as \u03b4<1.25, Abs Rel, log10 RMSE.  The table highlights RSA's superior generalization capabilities when trained on multiple datasets compared to image-based methods and other baselines. Different scaling approaches (global, image, median, linear fit) are also compared, showing the effectiveness of RSA's approach.", "section": "4 Experiments"}]