[{"figure_path": "teVxVdy8R2/tables/tables_5_1.jpg", "caption": "Table 1: Comparisons on Metaworld benchmark. We utilize a single policy to solve all 50 tasks in Metaworld. Due to the space limit, we show a subset of tasks and the average success rate on all 50 tasks. Detailed data can be found in Appendix A.4.", "description": "This table presents a comparison of different methods on the Metaworld benchmark, focusing on multi-task performance.  It shows the success rate of each method on a selection of tasks and the average success rate across all 50 tasks.  The table also includes results for ablated versions of the PAD model (PAD w/o img and PAD w/o co-train) to demonstrate the impact of using image data and co-training on both robotic data and video data.", "section": "4 Experiments"}, {"figure_path": "teVxVdy8R2/tables/tables_6_1.jpg", "caption": "Table 2: Comparisons on real-world manipulation in-distribution tasks. PAD achieves the highest success rate. Incorporating depth modality can additionally lead to performance improvement. We evaluate each task with 50 roll-outs.", "description": "This table presents the success rates of different robotic manipulation methods on real-world in-distribution tasks.  It compares PAD's performance with several baselines (Diffusion Policy, SuSIE, RT-1, RT-2*), showing PAD's superior performance across multiple tasks.  It also demonstrates the beneficial effect of incorporating depth information into PAD (PAD-Depth). Each result is an average of 50 trials per task.", "section": "4.1 Environmental Setups and Baselines"}, {"figure_path": "teVxVdy8R2/tables/tables_9_1.jpg", "caption": "Table 3: We test PAD performance under various sizes and computational costs.", "description": "This table presents the performance of the PAD model with different sizes and computational costs.  It shows the effect of varying model parameters (layers, hidden size, heads, token length) and computational resources (parameters and GFlops) on the average success rate (SR) across various tasks.  The results indicate a strong correlation between computational resources and performance.", "section": "4.5 Scaling Analysis"}, {"figure_path": "teVxVdy8R2/tables/tables_14_1.jpg", "caption": "Table 3: We test PAD performance under various sizes and computational costs.", "description": "This table presents the results of experiments evaluating the performance of the PAD model with different model sizes and computational costs.  It shows that varying the model's size and architecture significantly impacts performance, as measured by success rate. The table details the specific configurations used, including the number of layers, hidden size, number of heads, number of parameters, Gflops, learning rate, batch size, input image shape, input noised latent, patchify size, image token size, input robot action shape, action token size, and total token size, for each model variation.", "section": "4.5 Scaling Analysis"}, {"figure_path": "teVxVdy8R2/tables/tables_16_1.jpg", "caption": "Table 1: Comparisons on Metaworld benchmark. We utilize a single policy to solve all 50 tasks in Metaworld. Due to the space limit, we show a subset of tasks and the average success rate on all 50 tasks. Detailed data can be found in Appendix A.4.", "description": "This table compares the performance of PAD against several baselines on the Metaworld benchmark.  It shows success rates for various tasks, highlighting PAD's superior performance and the impact of removing certain components (image prediction and co-training) on the model. The table focuses on multi-task learning with a single visual-language conditioned policy.", "section": "4 Experiments"}, {"figure_path": "teVxVdy8R2/tables/tables_17_1.jpg", "caption": "Table 5: Detailed success rate of baselines and ablations. We did not include the handle-pull-side-v2 and handle-pull-v2 tasks since the expert policy for these two tasks in the original benchmark had low success rates. Every task is tested with 25 rollouts.", "description": "This table presents a detailed breakdown of the success rates achieved by different methods (PAD, diffusion policy, SuSIE, RT-1, RT-2*, GR-1) across various tasks within the Metaworld benchmark.  It highlights PAD's superior performance and shows the impact of ablations (removing image prediction, removing video co-training) on PAD's results. Each task's success rate is based on 25 trials.", "section": "4.2 Main Results"}, {"figure_path": "teVxVdy8R2/tables/tables_18_1.jpg", "caption": "Table 1: Comparisons on Metaworld benchmark. We utilize a single policy to solve all 50 tasks in Metaworld. Due to the space limit, we show a subset of tasks and the average success rate on all 50 tasks. Detailed data can be found in Appendix A.4.", "description": "This table presents the multi-task performance comparison of PAD against several state-of-the-art baselines on the Metaworld benchmark.  It shows success rates for a subset of the 50 tasks in Metaworld, and the average success rate across all 50 tasks.  It highlights PAD's superior performance using a single, text-conditioned visual policy, compared to baselines that often employ separate policies for each task or a two-stage approach..  Additional results for all 50 tasks are available in the appendix.", "section": "4 Experiments"}]