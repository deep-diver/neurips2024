[{"type": "text", "text": "MR-Ben: A Meta-Reasoning Benchmark for Evaluating System-2 Thinking in LLMs ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhongshen Zeng1 Yinhong Liu2 Yingjia Wan2   \nJingyao Li1 Pengguang Chen1 Jianbo Dai3 Yuxuan Yao4   \nRongwu $\\mathbf{Xu^{5}}$ Zehan Qi5 Wanru Zhao2 Linling Shen6   \nJianqiao Lu7 Haochen Tan4 Yukang Chen1 Hao Zhang8   \nZhan Shi6 Bailin Wang9 Zhijiang Guo2\u2020 Jiaya Jia1\u2020 ", "page_idx": 0}, {"type": "text", "text": "1Chinese University of Hong Kong 2University of Cambridge 3University of Edinburgh   \n4City University of Hong Kong 5Tsinghua University 6University of Texas at Austin 7University of Hong Kong 8Nanyang Technological University 9Massachusetts Institute of Technology ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Large language models (LLMs) have shown increasing capability in problemsolving and decision-making, largely based on the step-by-step chain-of-thought reasoning processes. However, evaluating these reasoning abilities has become increasingly challenging. Existing outcome-based benchmarks are beginning to saturate, becoming less effective in tracking meaningful progress. To address this, we present a process-based benchmark MR-Ben that demands a meta-reasoning skill, where LMs are asked to locate and analyse potential errors in automatically generated reasoning steps. Our meta-reasoning paradigm is especially suited for system-2 slow thinking, mirroring the human cognitive process of carefully examining assumptions, conditions, calculations, and logic to identify mistakes. MR-Ben comprises 5,975 questions curated by human experts across a wide range of subjects, including physics, chemistry, logic, coding, and more. Through our designed metrics for assessing meta-reasoning on this benchmark, we identify interesting limitations and weaknesses of current LLMs (open-source and closed-source models). For example, with models like the o1 series from OpenAI demonstrating strong performance by effectively scrutinizing the solution space, many other state-of-the-art models fall significantly behind on MR-Ben, exposing potential shortcomings in their training strategies and inference methodologies1. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Reasoning, the cognitive process of using evidence, arguments, and logic to reach conclusions, is crucial for problem-solving, decision-making, and critical thinking [65, 19]. With the rapid advancement of Large Language Models (LLMs), there is an increasing interest in exploring their reasoning capabilities [30, 57]. Consequently, evaluating reasoning in LLMs reliably becomes paramount. Current evaluation methodologies primarily focus on the final result [16, 28, 22, 60], disregarding the intricacies of the reasoning process. While effective to some extent, such evaluation practices may conceal underlying issues like logical errors or unnecessary steps that compromise the accuracy and efficiency of reasoning [68, 41]. ", "page_idx": 0}, {"type": "text", "text": "Therefore, it is important to complement outcome-based evaluation with an intrinsic evaluation of the quality of the reasoning process. However, current benchmarks for evaluating LLMs\u2019 reasoning capabilities have certain limitations in terms of their scope and size. For instance, PRM800K [38] categorizes each reasoning step as positive, negative, or neutral. Similarly, BIG-Bench Mistake [64] focuses on identifying errors in step-level answers. We follow the same meta-reasoning paradigm as MR-GSM8K [77] and MR-Math [68], which go a step further by providing the error reason for the first negative step in the reasoning chain. However, these benchmarks are limited to a narrower task scope\u2014MR-GSM8K and MR-Math focus solely on mathematical reasoning, while BIG-Bench Mistake mainly assesses logical reasoning. To ensure a comprehensive evaluation of reasoning abilities, it is crucial to identify reasoning errors and assess the LLMs\u2019 capacity to elucidate them across wider domains. ", "page_idx": 1}, {"type": "text", "text": "To bridge this gap, we construct a comprehensive benchmark MR-Ben comprising 6k questions covering a wide range of subjects, including natural sciences like math, biology, and physics, as well as coding and logic. One unique aspect of MR-Ben is its meta-reasoning paradigm, which involves challenging LLMs to reason about different forms of reasoning. In this paradigm, LLMs take on the role of a teacher, evaluating the reasoning process by assessing correctness, analyzing potential errors, and providing corrections, as depicted in Figure 1. ", "page_idx": 1}, {"type": "text", "text": "Our analysis of various LLMs [50, 51, 5, 33, 47] uncovers distinct limitations and previously unidentified weaknesses in their reasoning abilities. While many LLMs are capable of generating correct answers, they often struggle to identify errors within their reasoning processes and explain the underlying rationale. To excel under our meta-reasoning paradigm, models must meticulously scrutinize assumptions, conditions, calculations, and logical steps, even inferring step outcomes counterfactually. These requirements align with the characteristics of \u201cSystem-2\u201d slow thinking [35, 9], which we believe remains underdeveloped in most of the state-of-the-art models we evaluated. ", "page_idx": 1}, {"type": "text", "text": "We suspect that a key reason for this gap lies in current fine-tuning paradigms, which prioritize correct solutions and limit effective exploration of the broader solution space. Echoing this hypothesis, we observed that models like o1-preview [52], which reportedly incorporate effective search and disambiguation techniques across trajectories in the solution space, outperform other models by a large margin. Moreover, we found that leveraging high-quality and diverse synthetic data [1] significantly mitigates this issue, offering a promising path to enhance performance regardless of model size. Additionally, our results indicate that different LLMs excel in distinct reasoning paradigms, challenging the notion that domain-specific enhancements necessarily yield broad cognitive improvements. We hope that MR-Ben will guide researchers in comprehensively evaluating their models\u2019 capabilities and foster the development of more robust AI reasoning frameworks. ", "page_idx": 1}, {"type": "text", "text": "Our key contributions are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We introduced MR-Ben, which includes around 6k questions across a wide range of subjects, from natural sciences to coding and logic, and employs a unique meta-reasoning paradigm. \u2022 We conduct an extensive analysis of various LLMs on MR-Ben, revealing various limitations and previously unidentified weaknesses in their reasoning abilities. \u2022 We offer potential pathways for enhancing the reasoning abilities of LLMs and challenge the assumption that domain-specific enhancements necessarily lead to broad improvements. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Reasoning Benchmarks Evaluating the reasoning capabilities of LLMs is crucial for understanding their potential and limitations. While existing benchmarks often assess reasoning by measuring performance on tasks that require reasoning, such as accuracy, they often focus on specific reasoning types like arithmetic, knowledge, logic, or algorithmic reasoning. Arithmetic reasoning, involving mathematical concepts and operations, has been explored in benchmarks ranging from elementary word problems [37, 4, 55, 16] to more complex and large-scale tasks [28, 48]. Knowledge reasoning, on the other hand, requires either internal (commonsense) or external knowledge, or a combination of both [14, 62, 22]. Logical reasoning benchmarks, encompassing deductive and inductive reasoning, use synthetic rule bases for the former [15, 61, 18] and specific observations for the latter to formulate general principles [78, 71]. Algorithmic reasoning often involves understanding the coding problem description and performing multi-step reasoning to solve it [17, 25]. Benchmarks like BBH [59] and ", "page_idx": 1}, {"type": "image", "img_path": "GN2qbxZlni/tmp/c4f79a3ed6602393229bae7d3aad3466ca14ba14bffe322bdbff3904dc30aa83.jpg", "img_caption": ["Figure 1: Overview of the evaluation paradigm and representative examples in MR-Ben. Each data point encompasses three key elements: a question, a Chain-of-Thought (CoT) answer, and an error analysis. The CoT answer is generated by various LLMs. Human experts annotate the error analyses, which include error steps, reasons behind the error, and subsequent corrections. The three examples shown are selected to represent arithmetic, logical, and algorithmic reasoning types. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "MMLU [27] indirectly assess reasoning by evaluating performance on tasks that require it. However, these benchmarks primarily focus on final results, neglecting the analysis of potential errors in the reasoning process. Unlike prior efforts, MR-Ben goes beyond accuracy by assessing the ability to locate potential errors in the reasoning process and provide explanations and corrections. Moreover, MR-Ben covers different types of reasoning, offering a more comprehensive assessment. ", "page_idx": 2}, {"type": "text", "text": "Evaluation Beyond Accuracy Many recent studies have shifted their focus from using only the final result to evaluating the reasoning quality beyond accuracy. This shift has led to the development of two approaches: reference-free and reference-based evaluation. Reference-free methods aim to assess reasoning quality without relying on human-provided solutions. For example, ROSCOE [23] evaluates reasoning chains by quantifying reasoning errors such as redundancy and hallucination. Other approaches convert reasoning steps into structured forms, like subject-verb-object frames [56] or symbolic proofs [58], allowing for automated analysis. Reference-based methods depend on human-generated step-by-step solutions. For instance, PRM800K [38] offers solutions to MATH problems [28], categorizing each reasoning step as positive, negative, or neutral. Building on this, MR-GSM8K [77] and MR-Math [68] further provide the error reason behind the first negative step. MR-GSM8K focuses on elementary math problems, sampling questions from GSM8K [16]. MR-Math samples a smaller set of 459 questions from MATH [28]. Using the same annotation scheme, BIG-Bench Mistake [64] focuses on symbolic reasoning. It encompasses 2,186 instances from 5 tasks in BBH [59]. Despite the progress made by these datasets, limitations in scope and size remain. To address this, we introduce MR-Ben, a benchmark consisting of 5,975 manually annotated instances covering a wide range of subjects, including natural sciences, coding, and logic. MR-Ben also features more challenging questions, spanning high school, graduate, and professional levels. ", "page_idx": 2}, {"type": "text", "text": "3 MR-Ben: Dataset Construction ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Dataset Structure ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To comprehensively evaluate the reasoning capabilities of LLMs, MR-Ben employs a meta-reasoning paradigm. This paradigm casts LLMs in the role of a teacher, where they assess the reasoning process by evaluating its correctness, analyzing errors, and providing corrections. As shown in Figure 1, each data point within MR-Ben consists of three key elements: a question, a CoT answer, and an error analysis. The construction pipeline is shown in Figure 6 in Appendix-D. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Question The questions in MR-Ben are designed to cover a diverse range of reasoning types and difficulty levels, spanning from high school to professional levels. To ensure this breadth, we curated questions from various subjects, including natural sciences (mathematics, biology, physics), coding, and logic. Specifically, we sampled questions from mathematics, physics, biology, chemistry, and medicine from MMLU [27], which comprehensively assesses LLMs across academic and professional domains. For logic questions, we draw from LogiQA [40], which encompasses a broad spectrum of logical reasoning types, including categorical, conditional, disjunctive, and conjunctive reasoning. Finally, we select coding problems from MHPP [17], which focuses on function-level code generation requiring advanced algorithmic reasoning. Questions in MMLU and LogiQA require a single-choice answer, while MHPP requires a snippet of code as the answer. ", "page_idx": 3}, {"type": "text", "text": "CoT Answer We queried GPT-3.5-Turbo-0125 [50], Claude2 [5], and Mistral-Medium [32] (as of February 2024) using a prompt template (provided in Figure-7 in Appendix-D) designed to elicit step-by-step solutions [66]. For clarity, all LLMs were instructed to format their solutions with numbered steps, except for coding problems. To encourage diverse solutions, we set the temperature parameter to 1 during sampling. This empirical setting yielded satisfactory instruction following and desirable fine-grained reasoning errors, which annotators and evaluated models are expected to identify. ", "page_idx": 3}, {"type": "text", "text": "3.2 Annotation Process ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "After acquiring the questions and their corresponding Chain-of-Thought (CoT) answers, we engage annotators to provide error analyses. The annotation process is divided into three stages. ", "page_idx": 3}, {"type": "text", "text": "Answer Correctness CoT answers that result in a final answer different from the ground truth are automatically flagged as incorrect. However, for cases where the final answer matches the ground truth, manual annotation is required. This is because there are instances where the reasoning process leading to the correct answer is flawed, as illustrated in the middle example of Figure 1. Therefore, annotators are tasked with meticulously examining the entire reasoning path to determine if the correct final answer is a direct result of the reasoning process. ", "page_idx": 3}, {"type": "text", "text": "Error Step This stage is applicable for solutions with either an unmatched final output or a matched final output underpinned by flawed reasoning. Following the prior effort [38], each step in the reasoning process is categorized as positive, neutral, or negative. Positive and neutral steps represent stages where the correct final output remains attainable. Conversely, negative steps indicate a divergence from the path leading to the correct solution. Annotators are required to identify the first step in the reasoning process where the conditions, assumptions, or calculations are incorrect, making the correct final result unreachable for the subsequent reasoning steps. ", "page_idx": 3}, {"type": "text", "text": "Error Reason and Correction Annotators are tasked with conducting an in-depth analysis of the reasoning that led to the identified error. As shown in Figure 1, annotators are required to provide the error reason and the corresponding correction to this reasoning step. This comprehensive approach ensures a thorough understanding and rectification of errors in the reasoning process. ", "page_idx": 3}, {"type": "text", "text": "3.3 Data Statistics ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Table 1 presents the statistics of MR-Ben. The benchmark exhibits a balanced distribution of correct and incorrect solutions, with an overall correct solution rate of $40.3\\%$ . Solutions, on average, involve 9.5 steps, and errors typically manifest around the fourth step (4.5). The questions and solutions are substantial, with average lengths of 85.6 and 308.8 words, respectively. The subject-wise analysis reveals that Math is the most challenging, with a correct solution rate of a mere $16.2\\%$ . This could be attributable to the intricacy of the arithmetic operations involved. Conversely, Biology emerges as the least daunting, with a high correct solution rate of $59.6\\%$ . Coding problems have the longest solutions, averaging 950.3 number of words. This underscores the complexity and the detailed procedural reasoning inherent in coding tasks. Similarly, Logic problems have the longest questions, averaging ", "page_idx": 3}, {"type": "table", "img_path": "GN2qbxZlni/tmp/6e0ebf456ad3aad36ed0f65037ee98afa26062a394efe33675424343ebfe1ebe.jpg", "table_caption": ["Table 1: Statistics of MR-Ben. The length of questions and solutions are measured inthe number of words. Notice that the steps for coding denote the number of lines of code. They are not directly comparable with other subjects. "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "154.8 words. This is in line with the need for elaborate descriptions in logical reasoning. The typical step at which the first error occurs is fairly consistent across most subjects, usually around the 3rd step out of a total of 5. However, Coding deviates from this trend. The first error tends to appear earlier, specifically around the 14th line out of a total of 32.5 lines. This suggests that the problem-solving process in Coding may have distinct dynamics compared to other subjects. ", "page_idx": 4}, {"type": "text", "text": "3.4 Quality Control ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Annotators Given the complexity of the questions, which span a range of subjects from high school to professional levels, we enlisted the services of an annotation company. This company meticulously recruited annotators, each holding a minimum of a bachelor\u2019s degree. Before their trial labeling, annotators are thoroughly trained and are required to review the annotation guidelines. We\u2019ve included the guidelines for all subjects in Appendix H for reference. The selection of annotators is based on their performance on a balanced, small hold-out set of problems for each subject. In addition to the annotators, a team of 14 quality controllers diligently monitors the quality of the annotation weekly. As a final layer of assurance, we have 4 meta controllers who scrutinize the quality of the work. ", "page_idx": 4}, {"type": "text", "text": "Quality Assurance Every problem in MR-Ben undergoes a rigorous three-round quality assurance process to ensure its accuracy and clarity. Initially, each question is labeled by two different annotators. Any inconsistencies in the solution correctness or the first error step are identified and reviewed by a quality controller for arbitration. Following this, every annotated problem is subjected to a secondary review by annotators who were not involved in the initial labeling. This is to ensure that the annotations for different solutions to the same problem are consistent and coherent. In the final phase of the review, $10\\%$ of the problems are randomly sampled and reviewed by the meta controllers. Throughout the entire evaluation process, all annotated fields are meticulously examined in multiple rounds for their accuracy and clarity. Any incorrect annotations or those with disagreements are progressively filtered out and rectified, ensuring a high-quality dataset. This rigorous process allows us to maintain a high level of annotation quality. ", "page_idx": 4}, {"type": "text", "text": "Dataset Artifacts & Biases Table 1 reveals a relatively balanced distribution of correct and incorrect solutions. However, an exception was observed in mathematical subjects, where the distribution tends to skew towards incorrect solutions. This skew could suggest an inherent complexity or ambiguity in mathematical problem statements. Our analysis of the first error step across all subjects indicated that errors predominantly occur in the initial stages $(n\\leq7)$ ) of problem-solving and are distributed relatively uniformly. This pattern was consistent across most subjects, with no significant skew towards later steps. More detailed discussions of biases are provided in the Appendix C. ", "page_idx": 4}, {"type": "text", "text": "4 Evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "For each question-solution pair annotated, the evaluated model are supposed to decide the correctness of the solution and report the first-error-step and error-reason if any. The solution-correctness and first-error-step is scored automatically based on the manual annotation result. Only when the evaluated model correctly identified the incorrect solution and first-error-step will its error-reason be further examined manually or automatically by models. Therefore in order to provide a unified and normalized score to reflect the overall competence of the evaluated model, we follow the work of [77] and apply a metric named MR-Score, which consist of three sub-metrics. ", "page_idx": 4}, {"type": "text", "text": "The first one is the Matthews Correlation Coefficient (a.k.a MCC, 46) for the binary classification of solution-correctness. ", "page_idx": 5}, {"type": "equation", "text": "$$\nM C C=\\frac{T P\\times T N-F P\\times F N}{\\sqrt{(T P+F P)\\times(T P+F N)\\times(T N+F P)\\times(T N+F N)}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where TP, TN, FP, FN stand for true positive, true negative, false positive and false negative. The MCC score ranges from $^-1$ to $+1$ with $^-1$ means total disagreement between prediction and observation, 0 indicates near random performance and $+1$ represents perfect prediction. In the context of this paper, we interpret negative values as no better than random guess and set 0 as cut-off threshold for normalization purpose. ", "page_idx": 5}, {"type": "text", "text": "The second metric is the ratio between numbers of solutions with correct first-error-step predicted and the total number of incorrect solutions. ", "page_idx": 5}, {"type": "equation", "text": "$$\nA C C_{\\mathrm{step}}={\\frac{N_{\\mathrm{correct\\_first\\_error\\_step}}}{N_{\\mathrm{incorrect\\_sols}}}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The third metrics is likewise the ratio between number of solutions with correct first-error-step plus correct error-reason predicted and the total number of incorrect solutions. ", "page_idx": 5}, {"type": "equation", "text": "$$\nA C C_{\\mathrm{reason}}={\\frac{N_{\\mathrm{correct\\_error\\_reason}}}{N_{\\mathrm{incorrect\\_sols}}}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "MR-Score is then a weighted combination of three metrics, given by ", "page_idx": 5}, {"type": "equation", "text": "$$\nM R-S c o r e=w_{1}*\\operatorname*{max}(0,M C C)+w_{2}*A C C_{\\mathrm{step}}+w_{3}*A C C_{\\mathrm{reason}}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For the weights $w_{1},w_{2}$ and $w_{3}$ , they are chosen based on our evaluation results to maximize the differentiation between different models. It is important to note that the Matthews Correlation Coefficient (MCC) and the accuracy of locating the first error step can be directly calculated by comparing the responses of the evaluated model with the ground truth annotations. However, assessing the accuracy of the error reason explained by the evaluated model presents more complexity. While consulting domain experts for annotations is a feasible approach, we instead utilized GPT-4-Turbo as a proxy to examine the error reasons, as detailed in Figure-11 in Appendix-D. ", "page_idx": 5}, {"type": "text", "text": "We operate under the assumption that while our benchmark presents a significant challenge for GPT-4 in evaluating complete solution correctness\u2014identifying the first error step and explaining the error reason\u2014it is comparatively easier for GPT-4 to assess whether the provided error reasons align with the ground truth. Specifically, in a hold-out set of sampled error reasons, there was a $92\\%$ agreement rate between the manual annotations by the authors and those generated by GPT-4. For more detailed evaluations on the robustness of MR-Score and its design thinking, please refer to our discussion in Appendix-B. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "5.1 Experiment Setup ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To evaluate the performance of different models on our new benchmark, we selected a diverse array of models based on size and source accessibility 2. This included smaller models like Gemma-2B[63], Phi-3[1], Qwen1.5-1.8B [7], as well as larger counterparts such as Llama3-70B [47], Deepseek67B[10], and Qwen1.5-72B[7]. We also compared open-source models (e.g. models from the Llama3 and Qwen1.5/Qwen2 series) against closed-source models from the GPT [51], Claude [6], Mistral [32], GLM [3], Yi [39], Moonshot [2], Doubao [12] families. Additionally, models from the Deepseek-Coder [10] series were included to assess the impact of coding-focused pretraining on reasoning performance. ", "page_idx": 5}, {"type": "text", "text": "Given the complexity of our benchmark, even larger open-source models like Llama3-70B-Instruct struggle to produce accurate evaluation results without the use of prompting methods, often achieving ", "page_idx": 5}, {"type": "table", "img_path": "GN2qbxZlni/tmp/edd091d49ad0807130b44357bfdc3d02b6bb1b8e22cf2b2e1716343a4a16207b.jpg", "table_caption": ["Table 2: Evaluation results on MR-Ben: This table presents a detailed breakdown of each model\u2019s performance evaluated under metric MR-Score across different subjects, where K stands for the number of demo examples here. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "MR-Scores near zero. Consequently, we employed a step-wise chain-of-thought prompting technique similar to those described in [77, 64]. This approach guides models in systematically reasoning through solution traces before making final decisions, as detailed in Appendix-D. ", "page_idx": 6}, {"type": "text", "text": "Considering the complexity of the task, which includes question comprehension, reasoning through the provided solutions, and adhering to format constraints, few-shot demonstration setups are also explored to investigate if models can benefit from In-Context Learning (ICL) examples. Due to the context token limits, we report zero and one-shot results in the main result table (Table 2). The performance of additional few-shot configurations on a selection of models with various capabilities is further discussed in Section 6.1. ", "page_idx": 6}, {"type": "text", "text": "5.2 Experiment Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The MR-Ben benchmark presents a significant shift in the challenge for state-of-the-art large language models, transitioning from question-answering to the nuanced role of question-solution scoring. This section details our findings, emphasizing variations in model performances and their implications. ", "page_idx": 6}, {"type": "text", "text": "Overall Performance Among the evaluated models, o1-preview consistently achieves the highest MR-Scores across all subjects, significantly outperforming most competitors from both open and closed-source communities. Notably, the open-sourced Qwen2-72B and Deepseek-V2-236B models are performing exceptionally well, surpassing every other open-sourced model including Llama3 by a large margin. Their scores are even comparable to or greater than some of the most capable models from commercial companies, such as Mistral, Yi, and Moonshot AI. In the small language model category, the performance of Phi3-3.8B exceeds many of the mid-size models, including Deepseek-Coder-33B, whose size is around tenfold larger. ", "page_idx": 6}, {"type": "image", "img_path": "GN2qbxZlni/tmp/76c7e00b96bf36f3ab9159ce7a762ef34151663a6a5331b3a8357c3a513c4073.jpg", "img_caption": ["Figure 2: Model performance across subjects "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "GN2qbxZlni/tmp/c4de5b7e42f9e3b40aafad2466a06dda0cce54c4e6d739f680e6fb8120d3ec4f.jpg", "img_caption": ["Figure 3: Model performance on different reasoning paradigms "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Performance across Model Size and Reasoning Paradigm Table 2 reveals a general trend where larger models tend to perform better, highlighting the correlation between model size and the efficacy in complex reasoning tasks. However, this relationship is not strictly linear, as demonstrated by models like Phi3-3.8B, which excel despite their smaller size. Since MR-Ben challenges the language models to reason about the reasoning in the solution space among a diverse range of domains, models like Phi-3 that are trained with effective data synthesis techniques and broader coverage of the solution space, intuitively achieve higher MR-Score. This suggests that while larger model sizes generally yield superior performances, techniques like knowledge distillation can also significantly boost reasoning performance. Similarly, although the size of the o1 model series remains undisclosed, these models reportedly employ mechanisms that scale computation efficiently through effective exploration, frequent retrospection, and meticulous reflection within the solution space. These characteristics align closely with the principles of \u201csystem-2\u201d thinking, which emphasizes deliberate, reflective problem-solving. As a result, the o1 models demonstrate a more effective reasoning process, achieving significantly higher MR-Scores than other models by a large margin. ", "page_idx": 7}, {"type": "text", "text": "Performance across Reasoning Types Our categorization into four reasoning types\u2014knowledge, arithmetic, algorithmic, and logic\u2014illustrates the unique challenges each model faces within these paradigms (Figure 3). Logic reasoning emerges as the most formidable due to the intricate logical operations required by questions from the LogiQA dataset. In stark contrast, o1-Preview and GPT-4- turbo demonstrate exceptional prowess in algorithmic reasoning, where their capabilities markedly surpass other models. Notably, models excel in different reasoning paradigms, reflecting their varied strengths and training backgrounds. For instance, despite Deepseek-Coder\u2019s specialized pre-training focused on coding tasks, it does not necessarily confer superior abilities in algorithmic reasoning, underscoring that targeted pretraining does not guarantee enhanced performance across all reasoning types. Comparing the performance of the Deepseek-Coder with that of the Phi-3 model, which excels despite its much smaller size, highlights the potential significance of high-quality synthetic data in achieving broad-based reasoning capabilities. ", "page_idx": 7}, {"type": "text", "text": "Sensitivity to Task Difficulty and Solution Length An examination across educational levels shows most models perform better at high school-level questions than college-level ones, indicating an intuitive level of sensitivity to the difficulty levels of the questions. Additionally, our analysis finds a minor negative correlation between the length of solution steps and MR-Scores, as detailed in Figure 4 and Figure 5. ", "page_idx": 7}, {"type": "image", "img_path": "GN2qbxZlni/tmp/cdc66d68fe63fe2d9b788f342c18adc6a8e27d6d4cf1e2fe53252ac5bb65db63.jpg", "img_caption": ["Figure 4: MR-Scores of different models on different levels of difficulty "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "GN2qbxZlni/tmp/c373470e0489ba3f8080f621eea53091e8fa4880aba3300634c10b47dcd723d4.jpg", "img_caption": ["Figure 5: The MR-Scores of models on solutions with different step numbers. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Summary: MR-Ben effectively differentiates model capabilities, often obscured in simpler settings. It not only identifies top performers but also underscores the influence of model size on outcomes, while demonstrating that techniques like knowledge distillation and test-time compute scaling, as seen with the Phi-3 and o1 models, can notably enhance smaller models\u2019 performance, challenging the dominance of larger models. The analysis further reveals that specialized training, such as in coding, does not guarantee superior algorithmic reasoning. This suggests the potential need for more balanced data approaches or improved data synthesis methods. ", "page_idx": 8}, {"type": "text", "text": "6 Further Analysis & Discussion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "6.1 Few Shot Prompting ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "As previously discussed and exemplified by our prompt template (Figure 10 in Appendix-D), our evaluation method is characterized by its high level of difficulty and complexity. In this experiment, we aimed to determine whether providing a few step-wise chain-of-thought (CoT) examples could improve model performance in terms of format adherence and reasoning quality. The results, as presented in Table 9 in Appendix, do not show a consistent pattern as the number of shots increases. While smaller language models like Gemma-2B exhibit performance improvements with additional shots, the performance of larger language models tends to fluctuate with an increasing number of shots. We hypothesize that for our complex tasks, the lengthy few-shot demonstrations may act more as a hindrance, providing distracting information rather than aiding in format adherence and reasoning. Our empirical findings suggest that a one-shot demonstration strikes the optimal balance between providing guidance and minimizing distraction. This supports our decision to focus on zero-shot versus one-shot comparisons in our primary experiments, as detailed in Table 2. ", "page_idx": 8}, {"type": "text", "text": "6.2 Self Refine Prompting ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "As suggested by [31], large language models typically cannot perform self-correction without external ground truth feedback. To explore whether this phenomenon occurs in our benchmark, we adopted a similar setting by prompting the language model to verify its own answer across a three-round interaction sequence: query, examine, and refine. Our prompting template, detailed in Figure 8 in Appendix D, is minimalistic and designed solely to encourage the model to self-examine. ", "page_idx": 8}, {"type": "text", "text": "The results of this self-refinement process are recorded in Table 4. Notably, models smaller than Llama3-70B exhibit performance degradation with self-refinement, while larger models, such as GPT-4, show marginal benefits from the process. Conversely, from Llama3-8B to Llama3-70B, despite a significant portion of correct predictions shifting to incorrect ones, as previously reported by [31], our benchmark shows an increasing trend of incorrect predictions shifting to correct ones as model size increases. This shift results in the significant performance improvements observed in models like Llama3-70B. ", "page_idx": 8}, {"type": "text", "text": "To understand the disproportionate improvement observed in the 70B model, we analyzed performance breakdown at the task level. These results are visualized and discussed in Figure 9 of ", "page_idx": 8}, {"type": "text", "text": "Table 3: Comparison of average accuracy in identifying the first error step and the corresponding error reason, with and without prior knowledge of the solutions\u2019 correctness. ", "page_idx": 9}, {"type": "table", "img_path": "GN2qbxZlni/tmp/1852cdbf8c02a360541a5a3d3e9a23ca9267aedb0fc8a6f7a92638f4121e26c6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "GN2qbxZlni/tmp/a54f4c6d5461152c8db3c248d61f0ce6f4c84f3f05a72dbdef689e9f2780c9b8.jpg", "table_caption": ["Table 4: Comparison of prompting methods: MR-Scores achieved by zero-shot step-wise CoT and Self-Refine technique. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Appendix E. In short, we believe the lack of consistency does not necessarily indicate a more robust or advanced reasoning ability, despite the increase of the evaluation results. ", "page_idx": 9}, {"type": "text", "text": "6.3 Solution Correctness Prior ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "To verify the influence of external ground truth signals, we sampled 100 incorrect solutions from each subject respectively as our test set. By observing the same set of language models under a zero-shot CoT setting, we aim to determine whether the knowledge of the solution\u2019s incorrectness enhances their ability to identify the first error step and the reason for the error. ", "page_idx": 9}, {"type": "text", "text": "The results in Table 3 illustrate that the benefits of knowing the solution correctness prior generally increase with the model\u2019s competence but begin to plateau at the level of sophisticated models like GPT-4. Specifically, the Gemma-2b model struggles significantly in our benchmark, showing nearly zero performance due to its limited ability to follow formats and comprehend complex tasks. Consequently, having the solution correctness prior does not improve its performance metrics. In contrast, models with moderate capabilities benefit substantially from this prior knowledge, which aids in accurately locating the first error step and elucidating the error reason. However, as model capabilities improve, the incremental benefits of this prior knowledge quickly diminish. For instance, GPT-4 shows only a marginal improvement in identifying the first error step and an almost negligible impact on error reason analysis when provided with the prior. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper highlights the importance of evaluating the reasoning capabilities of LLMs with processoriented design and presents a comprehensive benchmark called MR-Ben that addresses the limitations of existing evaluation methodologies. MR-Ben consists of questions from a diverse range of subjects and incorporates a meta-reasoning paradigm, where LLMs act as teachers to evaluate the reasoning process. Our evaluation of a diverse suite of LLMs on MR-Ben reveals several key limitations and weaknesses. Many models struggle with identifying and correcting errors within reasoning chains, demonstrating difficulty in performing system-2 style thinking\u2014such as scrutinizing assumptions, calculations, and intermediate steps. Furthermore, even state-of-the-art models often fail to maintain consistency across reasoning paradigms, exposing gaps in their generalization abilities. Additionally, our findings emphasize the importance of searching and reflecting on the solution space during inference. Models like the o1 series showcase the potential of scaling test-time computation, where frequent retrospection and iterative search through multiple solution paths significantly enhance reasoning performance. Nevertheless, improving LLMs\u2019 reasoning abilities on complex and nuanced tasks remains an open research question, and we encourage future work to develop upon MR-Ben. ", "page_idx": 9}, {"type": "text", "text": "8 Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported in part by the Research Grants Council under the Areas of Excellence scheme grant AoE/E-601/22-R. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et al. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219, 2024. ", "page_idx": 10}, {"type": "text", "text": "[2] Moonshot AI. Moonshot ai, 2024. URL https://www.moonshot.cn/. ", "page_idx": 10}, {"type": "text", "text": "[3] Zhipu AI. Welcome to glm-4, 2024. URL https://en.chatglm.cn/. ", "page_idx": 10}, {"type": "text", "text": "[4] Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. Mathqa: Towards interpretable math word problem solving with operation-based formalisms. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 2357\u20132367. Association for Computational Linguistics, 2019. doi: 10.18653/V1/N19-1245. URL https://doi.org/10.18653/v1/ n19-1245. ", "page_idx": 10}, {"type": "text", "text": "[5] Anthropic. Claude 2, 2024. URL https://www.anthropic.com/news/claude-2. ", "page_idx": 10}, {"type": "text", "text": "[6] Anthropic. Introducing the next generation of claude, 2024. URL https://www.anthropic. com/news/claude-3-family. ", "page_idx": 10}, {"type": "text", "text": "[7] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. Qwen technical report. arXiv preprint arXiv:2309.16609, 2023. ", "page_idx": 10}, {"type": "text", "text": "[8] Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosiute, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noem\u00ed Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. Constitutional AI: harmlessness from AI feedback. CoRR, abs/2212.08073, 2022. doi: 10. 48550/ARXIV.2212.08073. URL https://doi.org/10.48550/arXiv.2212.08073. ", "page_idx": 10}, {"type": "text", "text": "[9] Yoshua Bengio. Deep learning for system 2 processing. Presentation at the AAAI-20 Turing Award Winners 2018 Special Event, February 9 2020. ", "page_idx": 10}, {"type": "text", "text": "[10] Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, Huazuo Gao, Kaige Gao, Wenjun Gao, Ruiqi Ge, Kang Guan, Daya Guo, Jianzhong Guo, Guangbo Hao, Zhewen Hao, Ying He, Wenjie Hu, Panpan Huang, Erhang Li, Guowei Li, Jiashi Li, Yao Li, Y. K. Li, Wenfeng Liang, Fangyun Lin, Alex X. Liu, Bo Liu, Wen Liu, Xiaodong Liu, Xin Liu, Yiyuan Liu, Haoyu Lu, Shanghao Lu, Fuli Luo, Shirong Ma, Xiaotao Nie, Tian Pei, Yishi Piao, Junjie Qiu, Hui Qu, Tongzheng Ren, Zehui Ren, Chong Ruan, Zhangli Sha, Zhihong Shao, Junxiao Song, Xuecheng Su, Jingxiang Sun, Yaofeng Sun, Minghui Tang, Bingxuan Wang, Peiyi Wang, Shiyu Wang, Yaohui Wang, Yongji Wang, Tong Wu, Y. Wu, Xin Xie, Zhenda Xie, Ziwei Xie, Yiliang Xiong, Hanwei Xu, R. X. Xu, Yanhong Xu, Dejian Yang, Yuxiang You, Shuiping Yu, Xingkai Yu, B. Zhang, Haowei Zhang, Lecong Zhang, Liyue Zhang, Mingchuan Zhang, Minghua Zhang, Wentao Zhang, Yichao Zhang, Chenggang Zhao, Yao Zhao, Shangyan Zhou, Shunfeng Zhou, Qihao Zhu, and Yuheng Zou. Deepseek LLM: scaling open-source language models with longtermism. CoRR, abs/2401.02954, 2024. doi: 10.48550/ARXIV.2401.02954. URL https: //doi.org/10.48550/arXiv.2401.02954. ", "page_idx": 10}, {"type": "text", "text": "[11] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. ", "page_idx": 10}, {"type": "text", "text": "Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. CoRR, abs/2005.14165, 2020. URL https://arxiv.org/abs/2005.14165. ", "page_idx": 11}, {"type": "text", "text": "[12] Bytedance. Doubao team - crafting the industry\u2019s most advanced llms., 2024. URL https: //www.doubao.com/chat/. ", "page_idx": 11}, {"type": "text", "text": "[13] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instruction-finetuned language models. CoRR, abs/2210.11416, 2022. doi: 10.48550/ARXIV.2210.11416. URL https://doi.org/10.48550/arXiv.2210.11416.   \n[14] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? try arc, the AI2 reasoning challenge. CoRR, abs/1803.05457, 2018. URL http://arxiv.org/abs/1803.05457.   \n[15] Peter Clark, Oyvind Tafjord, and Kyle Richardson. Transformers as soft reasoners over language. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 3882\u20133890. ijcai.org, 2020. doi: 10.24963/IJCAI.2020/537. URL https://doi.org/10.24963/ijcai.2020/537.   \n[16] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. CoRR, abs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168.   \n[17] Jianbo Dai, Jianqiao Lu, Yunlong Feng, Rongju Ruan, Ming Cheng, Haochen Tan, and Zhijiang Guo. Mhpp: Exploring the capabilities and limitations of language models beyond basic code generation. arXiv preprint arXiv:2405.11430, 2024.   \n[18] Bhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan Xie, Hannah Smith, Leighanna Pipatanangkura, and Peter Clark. Explaining answers with entailment trees. In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih, editors, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pages 7358\u20137370. Association for Computational Linguistics, 2021. doi: 10.18653/V1/2021.EMNLP-MAIN.585. URL https://doi.org/10.18653/v1/2021.emnlp-main.585.   \n[19] Ronald Fagin and Joseph Y. Halpern. Reasoning about knowledge and probability. J. ACM, 41(2):340\u2013367, 1994. doi: 10.1145/174652.174658. URL https://doi.org/10.1145/ 174652.174658.   \n[20] Patrick Fernandes, Aman Madaan, Emmy Liu, Ant\u00f3nio Farinhas, Pedro Henrique Martins, Amanda Bertsch, Jos\u00e9 G. C. de Souza, Shuyan Zhou, Tongshuang Wu, Graham Neubig, and Andr\u00e9 F. T. Martins. Bridging the gap: A survey on integrating (human) feedback for natural language generation. CoRR, abs/2305.00955, 2023. doi: 10.48550/ARXIV.2305.00955. URL https://doi.org/10.48550/arXiv.2305.00955.   \n[21] Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Y. Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, and Kelvin Guu. RARR: researching and revising what language models say, using language models. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki, editors, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 16477\u201316508. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.ACL-LONG.910. URL https://doi.org/10.18653/v1/ 2023.acl-long.910.   \n[22] Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies. Trans. Assoc. Comput. Linguistics, 9:346\u2013361, 2021. doi: 10.1162/TACL\\_A\\_00370. URL https://doi.org/10.1162/tacl_a_00370.   \n[23] Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, and Asli Celikyilmaz. ROSCOE: A suite of metrics for scoring step-by-step reasoning. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/ pdf?id=xYlJRpzZtsY.   \n[24] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. CRITIC: large language models can self-correct with tool-interactive critiquing. CoRR, abs/2305.11738, 2023. doi: 10.48550/ARXIV.2305.11738. URL https://doi.org/10. 48550/arXiv.2305.11738.   \n[25] Alex Gu, Baptiste Rozi\u00e8re, Hugh James Leather, Armando Solar-Lezama, Gabriel Synnaeve, and Sida Wang. Cruxeval: A benchmark for code reasoning, understanding and execution. In Fortyfirst International Conference on Machine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024. URL https://openreview.net/forum?id $\\equiv$ Ffpg52swvg.   \n[26] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C\u00e9sar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, S\u00e9bastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. Textbooks are all you need. CoRR, abs/2306.11644, 2023. doi: 10.48550/ARXIV.2306.11644. URL https://doi.org/10.48550/arXiv.2306. 11644.   \n[27] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id $\\cdot$ d7KBjmI3GmQ.   \n[28] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset. In Joaquin Vanschoren and Sai-Kit Yeung, editors, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual, 2021. URL https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/ be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html.   \n[29] Dong Huang, Jianbo Dai, Han Weng, Puzhen Wu, Yuhao Qing, Jie M. Zhang, Heming Cui, and Zhijiang Guo. SOAP: enhancing efficiency of generated code via self-optimization. CoRR, abs/2405.15189, 2024. doi: 10.48550/ARXIV.2405.15189. URL https://doi.org/10. 48550/arXiv.2405.15189.   \n[30] Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A survey. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki, editors, Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023, pages 1049\u20131065. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023. FINDINGS-ACL.67. URL https://doi.org/10.18653/v1/2023.findings-acl.67.   \n[31] Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, and Denny Zhou. Large language models cannot self-correct reasoning yet. arXiv preprint arXiv:2310.01798, 2023.   \n[32] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L\u00e9lio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timoth\u00e9e Lacroix, and William El Sayed. Mistral 7b. CoRR, abs/2310.06825, 2023. doi: 10.48550/ARXIV.2310.06825. URL https://doi.org/10.48550/arXiv.2310. 06825.   \n[33] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, L\u00e9lio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Th\u00e9ophile Gervet, Thibaut Lavril, Thomas Wang, Timoth\u00e9e Lacroix, and William El Sayed. Mixtral of experts. CoRR, abs/2401.04088, 2024. doi: 10.48550/ARXIV. 2401.04088. URL https://doi.org/10.48550/arXiv.2401.04088.   \n[34] Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula, Ronan Le Bras, and Yejin Choi. Maieutic prompting: Logically consistent reasoning with recursive explanations. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 1266\u20131279. Association for Computational Linguistics, 2022. doi: 10.18653/V1/2022.EMNLP-MAIN.82. URL https: //doi.org/10.18653/v1/2022.emnlp-main.82.   \n[35] Daniel Kahneman. Thinking, fast and slow. Farrar, Straus and Giroux, 2011.   \n[36] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/ 8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html.   \n[37] Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. MAWPS: A math word problem repository. In Kevin Knight, Ani Nenkova, and Owen Rambow, editors, NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016, pages 1152\u20131157. The Association for Computational Linguistics, 2016. doi: 10.18653/V1/N16-1136. URL https://doi.org/10.18653/v1/n16-1136.   \n[38] Hunter Lightman, Vineet Kosaraju, Yura Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let\u2019s verify step by step. CoRR, abs/2305.20050, 2023. doi: 10.48550/ARXIV.2305.20050. URL https://doi.org/10. 48550/arXiv.2305.20050.   \n[39] LingYiWanWu. Yi ai, 2024. URL https://platform.lingyiwanwu.com/.   \n[40] Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 3622\u20133628. ijcai.org, 2020. doi: 10.24963/IJCAI.2020/501. URL https://doi.org/10.24963/ijcai.2020/501.   \n[41] Yinhong Liu, Zhijiang Guo, Tianya Liang, Ehsan Shareghi, Ivan Vuli\u00b4c, and Nigel Collier. Measuring, evaluating and improving logical consistency in large language models. arXiv preprint arXiv:2410.02205, 2024.   \n[42] Yinhong Liu, Han Zhou, Zhijiang Guo, Ehsan Shareghi, Ivan Vulic\u00b4, Anna Korhonen, and Nigel Collier. Aligning with human judgement: The role of pairwise preference in large language model evaluators, 2024.   \n[43] Yiqi Liu, Nafise Sadat Moosavi, and Chenghua Lin. Llms as narcissistic evaluators: When ego inflates evaluation scores, 2024.   \n[44] Jianqiao Lu, Zhiyang Dou, Hongru Wang, Zeyu Cao, Jianbo Dai, Yingjia Wan, Yinya Huang, and Zhijiang Guo. Autocv: Empowering reasoning with automated process labeling via confidence variation. CoRR, abs/2405.16802, 2024. doi: 10.48550/ARXIV.2405.16802. URL https://doi.org/10.48550/arXiv.2405.16802.   \n[45] Jianqiao Lu, Zhengying Liu, Yingjia Wan, Yinya Huang, Haiming Wang, Zhicheng Yang, Jing Tang, and Zhijiang Guo. Process-driven autoformalization in lean 4. CoRR, abs/2406.01940, 2024. doi: 10.48550/ARXIV.2406.01940. URL https://doi.org/10.48550/arXiv.2406. 01940.   \n[46] Brian W. Matthews. Comparison of the predicted and observed secondary structure of t4 phage lysozyme. Biochimica et biophysica acta, 405 2:442\u201351, 1975. URL https://api. semanticscholar.org/CorpusID:44596673.   \n[47] Meta. Introducing meta llama 3: The most capable openly available llm to date, 2024. URL https://ai.meta.com/blog/meta-llama-3/.   \n[48] Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, and Ashwin Kalyan. LILA: A unified benchmark for mathematical reasoning. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 5807\u20135832. Association for Computational Linguistics, 2022. doi: 10.18653/V1/2022. EMNLP-MAIN.392. URL https://doi.org/10.18653/v1/2022.emnlp-main.392.   \n[49] Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. Orca: Progressive learning from complex explanation traces of GPT-4. CoRR, abs/2306.02707, 2023. doi: 10.48550/ARXIV.2306.02707. URL https://doi.org/ 10.48550/arXiv.2306.02707.   \n[50] OpenAI. GPT-3.5 Turbo, 2023. URL https://platform.openai.com/docs/models/ gpt-3-5.   \n[51] OpenAI. GPT-4 Technical Report. CoRR, abs/2303.08774, 2023. doi: 10.48550/arXiv.2303. 08774. URL https://doi.org/10.48550/arXiv.2303.08774.   \n[52] OpenAI. Introducing openai o1-preview, 2024. URL https://openai.com/index/ introducing-openai-o1-preview/.   \n[53] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/ hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html.   \n[54] Arjun Panickssery, Samuel R. Bowman, and Shi Feng. Llm evaluators recognize and favor their own generations, 2024.   \n[55] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple math word problems? In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-T\u00fcr, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, pages 2080\u20132094. Association for Computational Linguistics, 2021. doi: 10.18653/V1/2021.NAACL-MAIN.168. URL https://doi.org/10.18653/v1/ 2021.naacl-main.168.   \n[56] Archiki Prasad, Swarnadeep Saha, Xiang Zhou, and Mohit Bansal. Receval: Evaluating reasoning chains via correctness and informativeness. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 10066\u201310086. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.EMNLP-MAIN.622. URL https://doi.org/10.18653/v1/2023.emnlp-main.622. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "[57] Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. Reasoning with language model prompting: A survey. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki, editors, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 5368\u20135393. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.ACL-LONG.294. URL https://doi.org/10. 18653/v1/2023.acl-long.294. ", "page_idx": 15}, {"type": "text", "text": "[58] Abulhair Saparov and He He. Language models are greedy reasoners: A systematic formal analysis of chain-of-thought. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/pdf?id $\\equiv$ qFVVBzXxR2V.   \n[59] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adri\u00e0 Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen, Andrea Santilli, Andreas Stuhlm\u00fcller, Andrew M. Dai, Andrew La, Andrew K. Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, and et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. CoRR, abs/2206.04615, 2022. doi: 10.48550/ARXIV.2206.04615. URL https://doi.org/10.48550/arXiv.2206.04615.   \n[60] Mirac Suzgun, Nathan Scales, Nathanael Sch\u00e4rli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. Challenging big-bench tasks and whether chain-of-thought can solve them. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki, editors, Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023, pages 13003\u201313051. Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.FINDINGS-ACL.824. URL https://doi.org/10.18653/v1/2023.findings-acl.824.   \n[61] Oyvind Tafjord, Bhavana Dalvi, and Peter Clark. Proofwriter: Generating implications, proofs, and abductive statements over natural language. In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021, volume ACL/IJCNLP 2021 of Findings of ACL, pages 3621\u20133634. Association for Computational Linguistics, 2021. doi: 10.18653/V1/2021.FINDINGS-ACL.317. URL https://doi.org/10.18653/v1/2021. findings-acl.317.   \n[62] Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: A question answering challenge targeting commonsense knowledge. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACLHLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4149\u20134158. Association for Computational Linguistics, 2019. doi: 10.18653/V1/N19-1421. URL https://doi.org/10.18653/v1/n19-1421.   \n[63] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi\u00e8re, Mihir Sanjay Kale, Juliette Love, et al. Gemma: Open models based on gemini research and technology. arXiv preprint arXiv:2403.08295, 2024.   \n[64] Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak, and Victor Carbune. Llms cannot find reasoning errors, but can correct them! CoRR, abs/2311.08516, 2023. doi: 10.48550/ARXIV. 2311.08516. URL https://doi.org/10.48550/arXiv.2311.08516.   \n[65] Peter Cathcart Wason and Philip Nicholas Johnson-Laird. Psychology of reasoning: Structure and content, volume 86. Harvard University Press, 1972.   \n[66] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/ hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html.   \n[67] Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel Khashabi, and Yejin Choi. Generating sequences by learning to self-correct. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/pdf?id $\\cdot$ hH36JeQZDaO.   \n[68] Shijie Xia, Xuefeng Li, Yixin Liu, Tongshuang Wu, and Pengfei Liu. Evaluating mathematical reasoning beyond accuracy. CoRR, abs/2404.05692, 2024. doi: 10.48550/ARXIV.2404.05692. URL https://doi.org/10.48550/arXiv.2404.05692.   \n[69] Jing Xiong, Zixuan Li, Chuanyang Zheng, Zhijiang Guo, Yichun Yin, Enze Xie, Zhicheng Yang, Qingxing Cao, Haiming Wang, Xiongwei Han, Jing Tang, Chengming Li, and Xiaodan Liang. Dq-lore: Dual queries with low rank approximation re-ranking for in-context learning. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/forum? id=qAoxvePSlq.   \n[70] Kevin Yang, Yuandong Tian, Nanyun Peng, and Dan Klein. Re3: Generating longer stories with recursive reprompting and revision. CoRR, abs/2210.06774, 2022. doi: 10.48550/ARXIV. 2210.06774. URL https://doi.org/10.48550/arXiv.2210.06774.   \n[71] Zonglin Yang, Li Dong, Xinya Du, Hao Cheng, Erik Cambria, Xiaodong Liu, Jianfeng Gao, and Furu Wei. Language models as inductive reasoners. In Yvette Graham and Matthew Purver, editors, Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2024 - Volume 1: Long Papers, St. Julian\u2019s, Malta, March 17-22, 2024, pages 209\u2013225. Association for Computational Linguistics, 2024. URL https://aclanthology.org/2024.eacl-long.13.   \n[72] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/ 271db9922b8d1f4dd7aaef84ed5ac703-Abstract-Conference.html.   \n[73] Yuxuan Yao, Han Wu, Zhijiang Guo, Biyan Zhou, Jiahui Gao, Sichun Luo, Hanxu Hou, Xiaojin Fu, and Linqi Song. Learning from correctness without prompting makes LLM efficient reasoner. CoRR, abs/2403.19094, 2024. doi: 10.48550/ARXIV.2403.19094. URL https://doi.org/10.48550/arXiv.2403.19094.   \n[74] Michihiro Yasunaga, Xinyun Chen, Yujia Li, Panupong Pasupat, Jure Leskovec, Percy Liang, Ed H. Chi, and Denny Zhou. Large language models as analogical reasoners. CoRR, abs/2310.01714, 2023. doi: 10.48550/ARXIV.2310.01714. URL https://doi.org/10. 48550/arXiv.2310.01714.   \n[75] Xi Ye and Greg Durrett. The unreliability of explanations in few-shot prompting for textual reasoning. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/ hash/c402501846f9fe03e2cac015b3f0e6b1-Abstract-Conference.html.   \n[76] Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal. Improving language models via plug-and-play retrieval feedback. CoRR, abs/2305.14002, 2023. doi: 10.48550/ARXIV.2305.14002. URL https://doi.org/10.48550/arXiv.2305.14002.   \n[77] Zhongshen Zeng, Pengguang Chen, Shu Liu, Haiyun Jiang, and Jiaya Jia. Mr-gsm8k: A metareasoning benchmark for large language model evaluation. CoRR, abs/2312.17080, 2023. doi: 10.48550/ARXIV.2312.17080. URL https://doi.org/10.48550/arXiv.2312.17080.   \n[78] Chi Zhang, Baoxiong Jia, Mark Edmonds, Song-Chun Zhu, and Yixin Zhu. ACRE: abstract causal reasoning beyond covariation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021, pages 10643\u2013 10653. Computer Vision Foundation / IEEE, 2021. doi: 10.1109/CVPR46437.2021. 01050. URL https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_ ACRE_Abstract_Causal_REasoning_Beyond_Covariation_CVPR_2021_paper.html.   \n[79] Han Zhou, Xingchen Wan, Lev Proleev, Diana Mincu, Jilin Chen, Katherine A Heller, and Subhrajit Roy. Batch calibration: Rethinking calibration for in-context learning and prompt engineering. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id $=$ L3FHMoKZcS.   \n[80] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/pdf?id $\\equiv$ 92gvk82DE-. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "A.1 Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The meta-reasoning evaluation framework in MR-Ben, while innovative, is not without its limitations. Firstly, its applicability may be restricted when it comes to subjects that are inherently holistic or creative in nature, such as humanities or sociology. These subjects often require a comprehensive understanding and modification (e.g. essay writing), which can be challenging to break down into specific, sequential reasoning steps and corrections. Secondly, MR-Ben is currently confined to questions in English. This could potentially limit the scope of reasoning challenges that can be explored, as different languages may present unique cognitive and linguistic hurdles. Lastly, the analysis and correction of errors in the reasoning steps are currently based on solutions generated by three LLMs, namely GPT-3.5, Mistral-Medium, and Claude 2. It\u2019s important to note that different LLMs and different individuals, may exhibit distinct reasoning and error patterns. Therefore, it would be beneficial to broaden the spectrum of solutions analyzed, incorporating a more diverse range of LLMs and even human responses. This would not only enhance the robustness of the evaluation framework but also provide a more nuanced understanding of the reasoning processes at play. ", "page_idx": 18}, {"type": "text", "text": "A.2 Broader Impact ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Positive Societal Impacts The proposed dataset MR-Ben has the potential to bring about significant positive societal impacts. It can contribute to the development and enhancement of LLMs by providing a comprehensive benchmark suite, which researchers and developers can use to identify and address the limitations and weaknesses of their models. This can lead to more accurate, efficient, and reliable LLMs. The meta-reasoning paradigm might open new avenues in AI research, leading to a deeper understanding of reasoning capabilities and the development of innovative methodologies for their evaluation and improvement. Moreover, with a wide range of subjects, MR-Ben can be a valuable resource for educational AI tools, providing personalized learning experiences and helping students understand and improve their reasoning skills. AI systems with improved reasoning capabilities can also be instrumental in various sectors, including healthcare, finance, and environmental management, aiding in complex decision-making and problem-solving tasks. ", "page_idx": 18}, {"type": "text", "text": "Negative Societal Impacts MR-Ben may also present potential negative societal impacts. As with any technology, there is a risk of LLMs being misused or used maliciously. For instance, LLMs with advanced reasoning capabilities could be used to manipulate information or deceive people. The use of LLMs in decision-making and problem-solving tasks could lead to an over-reliance on these systems, potentially undermining human judgment and critical thinking skills. Advanced LLMs, especially those used in sensitive sectors like healthcare and finance, need to handle vast amounts of data, which can raise privacy and security concerns if not managed properly. ", "page_idx": 18}, {"type": "text", "text": "A.3 Additional Related Work ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Improving Reasoning Abilities of LLMs To enhance the reasoning capabilities of LLMs, prior research primarily focuses on specific prompting techniques [11]. Existing efforts include few-shot prompting with intermediate steps augmented demonstrations [66, 72, 69] or zero-shot prompting with specific instructions [36, 74]. Although these methods have shown promising results, their effectiveness is often constrained by their task-specific nature and the labour-intensive process of designing prompts, leading to inconsistent outcomes across different tasks [75, 80]. Another strategy to facilitate reasoning involves instruction tuning or knowledge distillation, which elicits reasoning paths from LLMs without explicit prompting [13, 49, 26, 44]. These approaches typically involve resource-intensive fine-tuning over LLMs and require a large set of examples annotated with CoT. ", "page_idx": 18}, {"type": "text", "text": "Learning From Feedback Improving LLMs through learning from feedback has become a prevalent strategy, notably through reinforcement learning from human feedback, which seeks to align LLMs with human values by refining their outputs based on feedback [53, 8]. However, this method faces challenges such as high costs due to manual labor and a lack of real-time feedback capabilities [20]. An alternative strategy involves using self-correcting LLMs, which rely on automated feedback to iteratively adapt and understand the consequences of their actions without relying on hu", "page_idx": 18}, {"type": "table", "img_path": "GN2qbxZlni/tmp/c4061f0cb1ad2e414f5ad04b7e5b1b1f5d9f4b17d80e4aa406cfd49507900232.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Table 5: Scoring of error reasons from different models across subjects. ", "page_idx": 19}, {"type": "table", "img_path": "GN2qbxZlni/tmp/60569d72449b3ed4b1efd0a123470d0c2acbdd93b3aab6fcd1540963d91816bb.jpg", "table_caption": ["Table 6: Agreement ratio between the author and the proxy scoring model across different subjects. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "mans. This feedback can be derived from outside sources such as other models [70, 45], tools [24, 29], knowledge bases [21, 76], evaluation metrics [34, 67] or generation logits [73]. ", "page_idx": 19}, {"type": "text", "text": "B Robustness of MR-Score", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the ACC_reason metric\u2019s dependency on the judgments of different LLMs or human evaluators lead to variability in scoring ? ", "page_idx": 19}, {"type": "text", "text": "Answer: We would like to argue that due to the careful design of our evaluation mechanism, the automatic scoring of error reasons is both robust and economically feasible: ", "page_idx": 19}, {"type": "text", "text": "\u2022 Multiple annotators: During the annotation stage, we collected multiple annotations for the first error reasons and potential error rectification from different annotators who agreed on the solution correctness and the first error step. \u2022 Proxy Model Evaluation: Based on the ground truth annotations collected from various perspectives, the proxy language model (e.g., GPT-4-Turbo) then examines the error reasons provided by evaluating models. Given the question/solution pair and information regarding the first error step, error reasons, and rectification, the potential flaws of the error reasons provided by the evaluating models are easy to diagnose under contrast. \u2022 ACC_reason robustness: Table-5 shows the scores of error reasons sampled from our evaluation results. For the same set of error reasons collected in each subject, three different models made their predictions on correctness/incorrectness. We can clearly see the consistency of their predictions among the three models over questions in all subjects. Since the MR-Score is a weighted metric, the final score variability is less than 1 percent in total. ", "page_idx": 19}, {"type": "text", "text": "Human-Model Agreement Rate: As mentioned in 3, the agreement rate between manual annotations and the GPT-4 predictions over 100 samples randomly collected from all subjects is $92\\%$ . Below is the exact detail of our setup: ", "page_idx": 19}, {"type": "text", "text": "We randomly collected 100 data instances where the evaluating model correctly identified the solution correctness and the first error step across all subjects. We then manually examined whether the proxy scoring model (e.g., GPT-4-Turbo-2024-04-09) correctly scored the error reasons of the evaluating models. Table-6 is the detailed composition of the ratio in which the author agrees with the proxy scoring model. The annotation time varies significantly across subjects, as some problems\u2014such as coding and chemistry\u2014can take more than 10 minutes to evaluate, while subjects like biology are easier to assess. This high agreement rate further supports the reliability of our evaluation, thus avoiding the need for manual annotation of potentially 138,000 problems (6,000 benchmark size times 23 models evaluated). ", "page_idx": 19}, {"type": "text", "text": "Question: Is the MR-Score sensitive to different weightings? Is MR-Score a robust unified metric? Table-7 shows breakdown performance for models in all four metrics (MR-Score, MCC, ACC_step, and ACC_reason): ", "page_idx": 19}, {"type": "text", "text": "1. Metric Robustness: Due to the progressive nature of the definitions of our subtasks (e.g., the success of subsequent tasks depends on the previous ones), we can see the diminishing trend in the scores of MCC, ACC_step, and ACC_reason. However, thanks to the design ", "page_idx": 19}, {"type": "text", "text": "Table 7: Evaluation results breakdown on MR-Ben: This table presents a detailed breakdown of each model\u2019s performance evaluated under metric MCC/ACC-step/ACC-reason across different subjects. Here k stands for number of shot and every model we used in this experiment are instruction-tuned. ", "page_idx": 20}, {"type": "table", "img_path": "GN2qbxZlni/tmp/939333e4f80dc641528077993c5a33ef04e1859b984c6008a9671dbb3741360d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "of our evaluation mechanism and metrics, the score rankings of different models stay in relatively stable order across metrics. In other words, we have not observed any model that excels in determining the solution correctness (thus high in MCC) but is unable to explain the rationale behind it (e.g., low in ACC_reason). ", "page_idx": 20}, {"type": "text", "text": "2. Task Difficulties: As shown in the breakdown table, the ACC_reason metric is more discriminative than the MCC metric for competent models but vice versa for the less competent ones. This aligns with our intuition that generally more difficult questions are more discriminative for strong candidates, while weaker ones are simply incapable of solving them. This phenomenon could in part explain why in general the MR-Score is not very sensitive to minor changes in the weightings assigned to the subtasks, since the differentiability of the subtask metrics tends to reconcile with each other under different scenarios. ", "page_idx": 20}, {"type": "image", "img_path": "GN2qbxZlni/tmp/adebec09160dfabb6f12d54636653e6fdbe0c2025d84b93246d2fbb16f124e7e.jpg", "img_caption": ["Figure 6: This is the illustration of the dataset creation pipeline of MR-Ben . We first compile a set of questions from different subjects and then collect solutions from different LLMs. For each subject, a group of domain experts is recruited to annotate each question solution pair on its solution correctness, first error step, and error reasons. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "3. Differentiability and Interpretability: The weights of the MR-Score are ultimately decided by considering both the discriminative ability and the interpretability. To best differentiate models with different evaluation results, we conducted a thorough grid search to investigate the impact of the weightings. Since the weightings calculated returned a few optimal instances, we deliberately selected the one that assigns higher scores to more difficult tasks. We believe the current weighting ratio strikes a good balance between interpretability and differentiation: For example, GPT-4-Turbo, Deepseek-v2-236B, and Mistral-Large achieve $86.4\\%$ , $78.5\\%$ , and $81.2\\%$ respectively in MMLU but score $43.2\\%$ , $29.4\\%$ , and $21.3\\%$ in our benchmark. ", "page_idx": 21}, {"type": "text", "text": "C More Discussion on Biases ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "To quantitatively assess the relationship between the length of solutions and their correctness, PearsonCorrelation-Coefficients were calculated and reported in Table-8 in the Appendix. The result suggests varying dynamics across disciplines regarding how solution length impacts the likelihood of correctness. For subjects such as coding, chemistry and math, longer solutions are less likely to be correct, which could suggest that complexity or elaboration in responses may lead to mistakes or incorrect reasoning. For medicine, despite being weak, there\u2019s a tendency for longer solutions to be slightly more correct, possibly due to more detailed or thorough explanations being favorable. For the other subjects, length of solution does not appear to significantly affect correctness, indicating that other factors likely play a more dominant role in determining solution quality. The overall Pearson Coefficients analysis reflects the distinct nature of problem-solving in each field of our benchmark. ", "page_idx": 21}, {"type": "table", "img_path": "GN2qbxZlni/tmp/7d5c726aedb849ceea362c05fce0d182cfdc30c8f0d8c20bca6243980fa03d3c.jpg", "table_caption": ["Table 8: Pearson Correlation Between Solution Length and Correctness "], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "GN2qbxZlni/tmp/484e88fa8955f2b4b4a0319881811ec18861fe7759320891de05cfadd6b06e7c.jpg", "table_caption": ["Table 9: Evaluation Results of Models on MR-Bean in few-shot settings: This table presents a detailed breakdown of each model\u2019s performance evaluated under metric MR-Score across different subjects. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "D Evaluation Prompt ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Figure-10 is the prompt template we used to evaluate all the models in our paper. Note that with minor modifications on the following template, the evaluation results can be heavily affected. For example, by introducing a simple hint sentence \"Hint: This solution is incorrect. Please focus on looking for the First Error Step and Error Reason.\", the model performance can drastically improve as shown in 3. Also, by simply taking away the line of \u2019Solution Analysis\u2019 in the response format part of the prompt, the evaluated model will directly output the scoring result without step-wise COT analysis on the solution. This setup will lead to a near zero MR-Score performance as discussed in Section-5. ", "page_idx": 22}, {"type": "text", "text": "Figure-7 is the prompt we used to query language models for solution generation during the dataset compilation phase. Note that in the prompt, we specifically asked the model to analyse each option in the multiple-choice problem. This is crucial in examining if the model possesses a comprehensive understanding on the topics that the question is asking. ", "page_idx": 22}, {"type": "text", "text": "Figure-11 shows the prompt we used to query GPT-4 to score the error reasons returned from evaluated models. Despite the challenging nature of the original task to determine the solution correctness, it is a much easier job to determine if the error reason from the evaluated models aligns with the ground truth error reason. ", "page_idx": 22}, {"type": "text", "text": "Figure-8 demonstrates the prompt template we used for self-refine experiment. Note that we followed the setting of [31] without introducing any prior assumptions or knowledge. This minimum version of extra prompting would mostly rely on the capability of language models to perform self-refine procedure. ", "page_idx": 22}, {"type": "text", "text": "E Self Refine Analysis ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we present the results of self-refine in the task level. Specifically, we are looking at the change of labelling by the evaluated models in the determination of solution correctness as shown by Figure-9. We summarize our observation below: ", "page_idx": 22}, {"type": "text", "text": "\u2022 Small Models like Gemma-2B are too limited to perform effective self-reflection. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Competent Models like GPT4-Turbo are confident in their initial decisions, hardly switching their decisions during self-reflection. \u2022 Intermediate Models like Llama3-70B exhibit substantial changes during self-reflection, indicating a lack of consistency in their decisions. However, its change of decisions from incorrect to correct happens to be significantly higher in locating the first error step than in examining solution correctness and explaining the error reason, therefore boosting the overall MR-Score by a large margin. We believe the lack of consistency does not necessarily indicate a more robust or advanced reasoning ability, despite the increase in the evaluation results. ", "page_idx": 22}, {"type": "image", "img_path": "GN2qbxZlni/tmp/a81f01b921d294631220ebbad0cfdfdadfeb11457bed7ca68e1f09a37871fd98.jpg", "img_caption": ["Figure 7: This is the prompt we used for solution generation during the dataset compilation stage. Note that besides coding, every subject question in our dataset takes the form of multiple choice problem. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "\u2022 Conclusion: Our results support the observation that LLMs generally lack effective selfrefinement capabilities [31]. ", "page_idx": 23}, {"type": "text", "text": "F Error Analysis ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We provide qualitative analyses of how GPT-4 as an example model performed on our benchmark across all seven subjects. The purpose is to offer a deeper understanding of the types and causes of errors made by experimented models to inform future improvements. For each subject in the subsections below, a failure case and a success case are listed. Following the MR-Ben evaluation framework, each case demonstration consists of the following parts: (1) original questions, options, ground-truth final answers, and LLM-generated CoT solutions; (2) human annotations of step-wise error detection, explanation, and correction; (3) evaluation annotation from the experimented GPT-4 on the aforementioned LLM-generated CoT solutions; (4) scoring results of the error reason if the experimented model identifies the correct first error step. ", "page_idx": 23}, {"type": "text", "text": "From our analysis of sampled failure cases, several general observations are made. Firstly, the assessed model GPT-4 exhibits a widely resistant \u2018false positive bias\u2019 on our benchmark across all subjects: In cases where the LLM makes incorrect evaluations, the proportion of type I errors is much higher than type II errors. In other words, GPT-4 tends to overlook the mistakes that exist in incorrect model solutions and mislabel them as correct, while seldom actively mislabeling correct model solution steps as incorrect steps. In fact, among the 42 sampled cases we surveyed spanning the seven subjects, all failure cases (size $=21$ ) belong to the type I error category. We provide two possible explanations for such bias: (a) input bias: the implemented LLMs are instructed-tuned, and are inherently biased to follow the prompt input. Therefore, even when the models are asked to fairly judge these CoT solution steps in the prompt input in binary labels, it is likely their labeling threshold is affected and biased towards positive judgments. This is a common issue in using LLMs as generation evaluators and may be mitigated by adjusting the prompt design or other debiasing methods [42, 79]; (b) self-preference bias: it has drawn recent attention that state-of-the-art models display self-preference bias: the phenomenon in which an LLM inherently favors their own generated output over texts from other LLMs and humans [43, 54]. Therefore, the experiment results of LLMs that are under the same family of the three sampled models (GPT-3.5-Turbo-0125 [50], Claude2 [5], and Mistral-Medium [32]) may be affected. With the increasingly extensive use of self-evaluation and LLM-as-judge methods, we call for future researchers\u2019 attention to the potential issue. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "Secondly, the MR-Ben benchmark revealed many intricate cases where the assessed model GPT-4 reached a correct final answer through incorrect solution steps, challenging the models\u2019 multi-step reasoning capabilities to a greater scale. As shown in the failure cases in math, physics, biology, etc., our benchmark evaluation is able to identify step errors that the sample model made in the solution steps even when its final answer matches the final ground-truth choice. While such step errors can be trivial in terms of generating the correct final answer in the demonstrated failure cases, they can become significant in just slightly nuanced questions, as mentioned in the error analysis section of MMLU [27]. In contrast, our framework, by decomposing the question and model solutions, remains relatively immune to the nuances in question framing. This highlights an important significance of our MR-Ben benchmark in that it is not only elaborate but also robust compared to previous benchmarks. ", "page_idx": 24}, {"type": "text", "text": "Lastly, there are subtle nuances of model performance in different reasoning paradigms manifest in the case demonstrations of specific subjects. They are interpreted case by case by the captioned figures listed below. ", "page_idx": 24}, {"type": "text", "text": "E.1 Mathematics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Subject: High School Math ", "page_idx": 25}, {"type": "text", "text": "Question: What is the smallest whole number that has a remainder of 1 when divided by 4, a remainder of 1 when divided by 3, and a remainder of 2 when divided by 5? ", "page_idx": 25}, {"type": "text", "text": "Options: [A.] 67 [B.] 43 [C.] 57 [D.] 37 ", "page_idx": 25}, {"type": "text", "text": "Ground Truth Answer: D ", "page_idx": 25}, {"type": "text", "text": "- Sampled CoT ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Sampled Model: Claude2 ", "page_idx": 25}, {"type": "text", "text": "Model Solution Steps: ", "page_idx": 25}, {"type": "text", "text": "Step 1: Check Choice A (67) When 67 is divided by 4, the remainder is 3, not 1. So 67 is not the correct answer. ", "page_idx": 25}, {"type": "text", "text": "Step 2: Check Choice B (43) When 43 is divided by 4, the remainder is 1. When 43 is divided by 3, the remainder is 1. When 43 is divided by 5, the remainder is 3, not 2. So 43 is not the correct answer. Step 3: Check Choice C (57) When 57 is divided by 4, the remainder is 1. When 57 is divided by 3, the remainder is 0, not 1. So 57 is not the correct answer. ", "page_idx": 25}, {"type": "text", "text": "Step 4: Check Choice D (37) When 37 is divided by 4, the remainder is 1. When 37 is divided by 3, the remainder is 1. When 37 is divided by 5, the remainder is 2. ", "page_idx": 25}, {"type": "text", "text": "Step 5: Choice D (37) satisfies all the requirements and is the correct answer. Solution: Choice D ", "page_idx": 25}, {"type": "text", "text": "Solution: Choice D ", "page_idx": 25}, {"type": "text", "text": "- Human Annotation ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Model Solution Correctness: incorrect ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Model Solution First Error Step: Step 2 Model Solution Error Reason: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "The model\u2019s calculation is incorrect. In step 2, the model incorrectly calculated the remainder of 43 divided by 4 as 1 instead of 3. The model assumes that when 43 is divided by 4, the remainder is 1, but it should be 3. There is a miscalculation of the remainder here. ", "page_idx": 25}, {"type": "text", "text": "Model Solution Rectified First Error Step: Step 2: Check option B (43): When 43 is divided by 4, the remainder is 3, not 1. When 43 is divided by 3, the remainder is 1. When 43 is divided by 5, the remainder is 3, not 2. Therefore, 43 is not the correct answer. ", "page_idx": 25}, {"type": "text", "text": "-Model Evaluation Result\u2014 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo ", "page_idx": 25}, {"type": "text", "text": "Evaluation Raw Response: Solution Analysis: Step 1: The step checks the remainder when 67 is divided by 4 and finds that it yields a remainder of 3, not 1. This is a correct verification based on the criteria specified in the question. ", "page_idx": 25}, {"type": "text", "text": "Step 2: Checks the remainder of 43 when divided by 4, 3, and 5. The findings (1, 1, and 3 respectively) are verified correctly and match the expected remainders except for the one with 5, correctly identifying that the condition is not met for division by 5. ", "page_idx": 25}, {"type": "text", "text": "Step 3: The step calculates the remainders for 57 being divided by 4 and 3. The remainder when divided by 3 does not match the specified conditions (expected was 1, result was 0). Hence, the claim that 57 isn\u2019t correct is valid. ", "page_idx": 25}, {"type": "text", "text": "Step 4 and Step 5: Computes and verifies the remainders for 37 when divided by 4, 3, and 5, matching all the expected remainders accurately, and concludes that 37 meets all conditions specified in the problem. ", "page_idx": 25}, {"type": "text", "text": "The answer selection of Choice D for 37 is based on accurate verification that fulfills the problem\u2019s constraints. ", "page_idx": 25}, {"type": "text", "text": "Solution Correctness: correct ", "page_idx": 25}, {"type": "text", "text": "First Error Step: N/A Error Reason: N/A ", "page_idx": 25}, {"type": "text", "text": "\u2013Error Reason Scoring\u2014 ", "page_idx": 25}, {"type": "text", "text": "Need Error Reason Review: False ", "page_idx": 25}, {"type": "text", "text": "Figure E.1-1. A failure case in the math subject. This is a question where the sampled LLM (Claude2) reached a correct answer through incorrect multi-step reasoning. In \u2018Evaluation Results\u2019, the model fails to identify an error in step 2 of model solutions. As noted by the human-annotated \u2018Model Solution Error Reason\u2019, Step 2 checks the remainder when 43 is divided by 4 and incorrectly calculates the remainder as 1 while the correct calculation is 3. The failure case showcases one of the strengths of our benchmark in probing the intricacies of multi-step reasoning by examining process-level errors. ", "page_idx": 25}, {"type": "text", "text": "Subject: high school math ", "page_idx": 26}, {"type": "text", "text": "Question: Alex needs to borrow $810,000$ from the bank. The bank gives him two options. 1. A ten-year loan with an annual interest rate of $10\\%$ compounded quarterly, with the condition that at the end of 5 years, Alex must make a payment equal to half of what he owes. The other half continues to accrue interest, and at the end of the ten years, Alex will pay off the remaining balance. 2. A ten-year loan with a simple annual interest rate of $12\\%$ , with just one lump-sum payment at the end of the ten years. ", "page_idx": 26}, {"type": "text", "text": "Find the positive difference between the total amounts Alex has to pay back under the two schemes. Round your answer to the nearest dollar. ", "page_idx": 26}, {"type": "text", "text": "Options: [A.] 16401 [B.] 16400 [C.] 382 [D.] 383 ", "page_idx": 26}, {"type": "text", "text": "Ground Truth Answer: C ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Sampled Model: GPT3.5 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Step 1: Calculate the total amount Alex has to pay back under option 1.   \nStep 2: Calculate the total amount Alex has to pay back under option 2.   \nStep 3: Find the positive difference between the total amounts Alex has to pay back under the two schemes.   \nStep 4: Compare the positive difference calculated in step 3 with the given choices.   \nStep 5: Round the calculated positive difference to the nearest dollar if necessary.   \nStep 6: Determine which choice matches the calculated positive difference. Solution: Choice A ", "page_idx": 26}, {"type": "text", "text": "Solution Correctness: incorrect ", "page_idx": 26}, {"type": "text", "text": "Model Solution First Error Step: 6 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Model Solution Error Reason: According to the logic provided earlier, the model should give a correct match in the end, but the final answer given is wrong. In this step, the model selected the wrong answer, which could be due to errors in the deduction process that were not listed. ", "page_idx": 26}, {"type": "text", "text": "Model Solution Rectified First Error Step: Step 6: Determine which option matches the calculated positive difference. Answer: Option $D$ . ", "page_idx": 26}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Evaluation Raw Response: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Solution Analysis:   \n- Step 1: Neutral - This step claims to calculate the total amount Alex has to pay back under option 1 but does not provide any actual calculations or mathematical process.   \n- Step 2: Neutral - Similar to step 1, this step lacks any substantial content regarding how calculations are carried out for the repayment under option 2.   \n- Step 3: Neutral - This step mentions finding the positive difference between the total amounts, though no specific values or calculations are shown.   \n- Step 4: Neutral - Comparing the positive difference to given choices depends on values obtained in previous steps, which are not provided.   \n- Step 5: Neutral - The mention of rounding the difference falls in line with the problem\u2019s instructions but is non-specific due to lack of previous calculations.   \n- Step 6: Incorrect - Determining the choice without showing calculations leads to an unsupported conclusion. Solution Correctness: incorrect ", "page_idx": 26}, {"type": "text", "text": "First Error Step: Step 6 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Error Reason: The first error step is Step 6 where a decision is made on which choice matches the calculated positive difference without providing any calculations or reasons for the decision. The rectified reasoning should involve calculating the payback amounts for both options explicitly, finding their difference, rounding it if necessary, and then correctly selecting the matching option based on those calculated and verified figures. Need Error Reason Review: True ", "page_idx": 26}, {"type": "text", "text": "Error Reason Correctness Analysis: - The incorrect solution directly jumps to the final choice without showing any calculations or logical reasoning that leads to that decision. This skips essential steps that would normally validate the conclusion drawn. - The ground truth error reasons indicate that the error lies in the final selection of the answer without considering the calculation errors or logical missteps in previous steps that may have led to an incorrect conclusion. - Essentially, the error is not in the methodology but in the final step\u2019s execution, where an incorrect choice is selected without showing the work that would justify this selection. ", "page_idx": 26}, {"type": "text", "text": "Error Reason Analysis: - The student correctly identifies that the error occurs in the final step, where a decision is made without showing calculations or reasoning. This observation aligns with the ground truth that the final step incorrectly concludes without apparent justification. - The student emphasizes the need for explicit calculations and a clear demonstration of the reasoning process that leads to the selection of the correct option. This suggestion correctly identifies the lack of shown work and logical deduction in the provided incorrect solution. - The student\u2019s explanation focuses on the absence of explicit calculations and reasoned decision-making in the final step, which accurately reflects the actual error in the solution. ", "page_idx": 26}, {"type": "text", "text": "Error Reason Correctness: Correct ", "page_idx": 26}, {"type": "text", "text": "Figure E.1-2. success case in the math subject. The assessed model identifies the key mistake in Step 4 regarding the faulty equation $f(8)={\\textstyle{\\frac{1}{2}}}f(10)={\\textstyle{\\frac{1}{2}}}2f(8)$ and points out the incorrect and baseless cancellation leading to $f(8)=f(0)$ . Its error reason also correctly suggests that the proper method involves using the transformation properties iteratively in steps of 2 units backward from $f(10)$ to reach $f(0)$ . ", "page_idx": 26}, {"type": "text", "text": "E.2 Physics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Subject: college physics ", "page_idx": 27}, {"type": "text", "text": "Question: Protons used in cancer therapy are typically accelerated to about 0.6c. How much work must be done on a particle of mass m in order for it to reach this speed, assuming it starts at rest? ", "page_idx": 27}, {"type": "text", "text": "Ground Truth Answer: A ", "page_idx": 27}, {"type": "text", "text": "Sampled CoT ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Sampled Model: Claude2 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Step 1: The work-energy theorem states that the net work done on an object equals its change in kinetic energy.   \nStep 2: The kinetic energy of an object with mass $_{2n}$ moving at speed $\\bar{v}$ is ${\\scriptstyle{\\frac{1}{2}}}\\,m\\,v^{2}$ .   \nStep 3: Since the proton starts from rest, its initial kinetic energy is 0.   \nStep 4: The final speed $^{v}$ is given as 0.6c.   \nStep 5: Plugging this into the kinetic energy equation gives: ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{Final~KE}\\,=\\,\\frac{1}{2}\\,m\\left(0.6c\\right)^{2}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Step 6: Setting the change in kinetic energy equal to the net work done: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{Net~work}=\\mathrm{Final~KE-Initial~KE}=\\frac{1}{2}m(0.6c)^{2}\\,-\\,0=0.36m c^{2}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Step 7: Of the choices given, $_{0.36m c^{2}}$ is closest to $0.25m c^{2}$ . Solution: Choice A ", "page_idx": 27}, {"type": "text", "text": "Solution Correctness: incorrect ", "page_idx": 27}, {"type": "text", "text": "Model Solution First Error Step: 2 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Model Solution Error Reason: This step incorrectly uses the classical kinetic energy formula $\\begin{array}{r}{K E={\\frac{1}{2}}m v^{2}}\\end{array}$ to calculate the kinetic energy of a particle moving at speeds close to the speed of light. When the particle\u2019s speed approaches the speed of light, the relativistic kinetic energy formula $K E=(\\gamma-1)m c^{2}$ should be used, where $_{m}$ is the relativistic mass of the particle, $m_{0}$ is the rest mass of the particle, and $^c$ is the speed of light.   \nIn physics, when the velocity of an object approaches the speed of light, we need to use the principles of special relativity to calculate. In this case, the kinetic energy of the particle is no longer the classical kinetic energy formula but requires the use of the relativistic kinetic energy formula. ", "page_idx": 27}, {"type": "text", "text": "Model Solution Rectified First Error Step: Step 2: The relativistic kinetic energy of an object with mass $_{2n}$ and velocity v is $K$ . ", "page_idx": 27}, {"type": "text", "text": "Step 2: The kinetic energy of an object with mass m moving at velocity v is $m c^{2}\\:\\left(\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}\\:-\\:1\\right).$ ", "page_idx": 27}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Evaluation Raw Response: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "- Step 1: Correct. The work-energy theorem properly states that the net work done on an object is equal to its change in kinetic energy.   \n- Step 2: Incorrect. This is where the solution makes a fundamental error by using the classical formula for kinetic energy which isn\u2019t valid at significant fractions of the speed of light (like 0.6c).   \n- Step 3: Correct. The initial kinetic energy being zero since the particle starts from rest is a valid statement.   \n- Step 4: Correct. The final speed of the proton is appropriately given as 0.6c.   \n- Step 5: Incorrect as a consequence of Step 2, applying the incorrect equation.   \n- Step 6: Incorrect as it follows from the incorrect application of the kinetic energy formula and ends up with a wrong expression for net work done.   \nStep 7: Inc ri+b ", "page_idx": 27}, {"type": "text", "text": "Solution Correctness: incorrect First Error Step: Step 2 Error Reason: Step 2 uses the non-relativistic formula for kinetic energy, ${\\scriptstyle{\\frac{1}{2}}}\\,m\\,v^{2}$ , which is not accurate for speeds approaching the speed of light (such as 0.6c). The relativistic kinetic energy formula should be used instead, which is $K E\\,=\\,(\\gamma\\,-\\,1)m c^{2}$ where $\\gamma$ is the Lorentz factor, $\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ . Using this formula correctly accounts for the relativistic effects significant at high velocities. Solution Correctness: incorrect ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "First Error Step: Step 2 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Error Reason: Step 2 uses the non-relativistic formula for kinetic energy, ${\\scriptstyle{\\frac{1}{2}}}\\,m\\,v^{2}$ , which is not accurate for speeds approaching the speed of light (such as 0.6c). The relativistic kinetic energy formula should be used instead, which is $K E\\,=\\,(\\gamma\\,-\\,1)m c^{2}$ where $\\gamma$ is the Lorentz factor, $\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ . Using this formula correctly accounts for the relativistic effects significant at ", "page_idx": 27}, {"type": "text", "text": "Need Error Reason Review: True ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Error Reason Correctness Analysis: - At speeds approaching that of light, relativistic effects become significant. Thus, the classical mechanics approach is no longer accurate for describing the physics of the situation. - The correct formula to calculate kinetic energy at relativistic speeds includes the Lorentz factor, $\\gamma$ , which accounts for the effects of time dilation and length contraction at high velocities. - The relativistic kinetic energy (KE) formula is $K E\\,=\\,(\\gamma\\,-\\,1)m_{0}\\,c^{2}$ , where $^{m}0$ is the rest mass of the particle, $_c$ is the speed of light, and $\\gamma$ is the Lorentz factor, defined as $\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ . - This formula diverges from the classical $K E\\;=\\;{\\textstyle\\frac{1}{2}}\\,m\\upsilon^{2}$ when v becomes a significant fraction of c. - Therefore, the incorrect step in the solution is using the non-relativistic kinetic energy formula, which fails to account for the relativistic effects that are significant at a velocity of 0.6c.   \nError Reason Analysis: - The student correctly identifies that the non-relativistic kinetic energy formula is inaccurate for speeds approaching the speed of light. - The student accurately notes the requirement to use the relativistic kinetic energy formula, which includes the Lorentz factor $(\\gamma)$ . - The student provides the correct relativistic kinetic energy formula $K E=(\\gamma-1)m c^{2}$ and describes $\\gamma$ correctly as $\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ . - Overall, the student\u2019s explanation properly reflects the nature of the error in the solution and identifies the appropriate relativistic formula to use.   \nError Reason Correctness: Correct ", "page_idx": 27}, {"type": "text", "text": "Figure E.2-1. A failure case in the physics subject. It is another occurrence where the sampled LLM (Claude2) reached a correct answer even though its model solution contains an erroneous step. Physics formulas require strictly case-sensitive expressions to represent different concepts, as noted in \u2018Model Solution Error Reason\u2019, which models did not differentiate, thus making mistakes in explaining the relationship between the orbital period T and the satellite mass m. ", "page_idx": 27}, {"type": "text", "text": "Subject: college physics ", "page_idx": 28}, {"type": "text", "text": "Question: Protons used in cancer therapy are typically accelerated to about 0.6c. How much work must be done on a particle of mass m in order for it to reach this speed, assuming it starts at rest? ", "page_idx": 28}, {"type": "text", "text": "Ground Truth Answer: A ", "page_idx": 28}, {"type": "text", "text": "Sampled CoT ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Sampled Model: Claude2 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Model Solution Steps: ", "page_idx": 28}, {"type": "text", "text": "Step 1: The work-energy theorem states that the net work done on an object equals its change in kinetic energy.   \nStep 2: The kinetic energy of an object with mass $_{2n}$ moving at speed $\\bar{v}$ is ${\\scriptstyle{\\frac{1}{2}}}\\,m\\,v^{2}$ .   \nStep 3: Since the proton starts from rest, its initial kinetic energy is 0.   \nStep 4: The final speed v is given as $_{0.6c}$ .   \nStep 5: Plugging this into the kinetic energy equation gives: ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathrm{Final~KE}\\,=\\,\\frac{1}{2}\\,m\\left(0.6c\\right)^{2}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Step 6: Setting the change in kinetic energy equal to the net work done: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathrm{Net~work}=\\mathrm{Final~KE-Initial~KE}=\\frac{1}{2}m(0.6c)^{2}\\,-\\,0=0.36m c^{2}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Step 7: Of the choices given, $_{0.36m c^{2}}$ is closest to $0.25m c^{2}$ . Solution: Choice A ", "page_idx": 28}, {"type": "text", "text": "Solution Correctness: incorrect ", "page_idx": 28}, {"type": "text", "text": "Model Solution First Error Step: 2 ", "page_idx": 28}, {"type": "text", "text": "Model Solution Error Reason: This step incorrectly uses the classical kinetic energy formula $\\begin{array}{r}{K E={\\frac{1}{2}}\\,m\\,v^{2}}\\end{array}$ to calculate the kinetic energy of a particle moving at speeds close to the speed of light. When the particle\u2019s speed approaches the speed of light, the relativistic kinetic energy formula $K E=(\\gamma-1)m c^{2}$ should be used, where m is the relativistic mass of the particle, $m_{0}$ is the rest mass of the particle, and $^c$ is the speed of light. ", "page_idx": 28}, {"type": "text", "text": "Model Solution Rectified First Error Step: Step 2: The kinetic energy of an object with mass $_{2n}$ moving at velocity v i ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "image", "img_path": "GN2qbxZlni/tmp/97a3549a66ee7f3887099d2c5f0fffd459c3e97ce744fb25135cde173dea8578.jpg", "img_caption": [], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "Model Evaluation Result\u2014 ", "page_idx": 28}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Evaluation Raw Response: ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "- Step 1: Correct. The work-energy theorem properly states that the net work done on an object is equal to its change in kinetic energy.   \n- Step 2: Incorrect. This is where the solution makes a fundamental error by using the classical formula for kinetic energy which isn\u2019t valid at significant fractions of the speed of light (like 0.6c).   \n- Step 3: Correct. The initial kinetic energy being zero since the particle starts from rest is a valid statement.   \n- Step 4: Correct. The final speed of the proton is appropriately given as 0.6c.   \n- Step 5: Incorrect as a consequence of Step 2, applying the incorrect equation.   \n- Step 6: Incorrect as it follows from the incorrect application of the kinetic energy formula and ends up with a wrong expression for net work done.   \nStep $^{7}$ ", "page_idx": 28}, {"type": "text", "text": "Solution Correctness: incorrect First Error Step: Step 2 Error Reason: Step 2 uses the non-relativistic formula for kinetic energy, ${\\scriptstyle{\\frac{1}{2}}}\\,m\\,v^{2}$ , which is not accurate for speeds approaching the speed of light (such as 0.6c). The relativistic kinetic energy formula should be used instead, which is $K E\\,=\\,(\\gamma\\,-\\,1)m c^{2}$ where $\\gamma$ is the Lorentz factor, $\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ Using this formula correctly accounts for the relativistic effects significant at high velocities. Solution Correctness: incorrect ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "First Error Step: Step 2 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Error Reason: Step 2 uses the non-relativistic formula for kinetic energy, ${\\scriptstyle{\\frac{1}{2}}}\\,m\\,v^{2}$ , which is not accurate for speeds approaching the speed of light (such as 0.6c). The relativistic kinetic energy formula should be used instead, which is $K E\\,=\\,(\\gamma\\,-\\,1)m c^{2}$ where $\\gamma$ is the Lorentz factor, $\\displaystyle\\,\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ . Using this formula correctly accounts for the relativistic effects significant at ", "page_idx": 28}, {"type": "text", "text": "", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Need Error Reason Review: True   \nError Reason Correctness Analysis: - At speeds approaching that of light, relativistic effects become significant. Thus, the classical mechanics approach is no longer accurate for describing the physics of the situation. - The correct formula to calculate kinetic energy at relativistic speeds includes the Lorentz factor, $\\gamma$ , which accounts for the effects of time dilation and length contraction at high velocities. - The relativistic kinetic energy (KE) formula is $K E\\,=\\,(\\gamma\\,-\\,1)m_{0}\\,c^{2}$ , where $^{m}0$ is the rest mass of the particle, $_c$ is the speed of light, and $\\gamma$ is the Lorentz factor, defined as $\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ . - This formula diverges from the classical $K E\\;=\\;{\\textstyle\\frac{1}{2}}\\,m\\,v^{2}$ when $\\boldsymbol{w}$ becomes a significant fraction of c. - Therefore, the incorrect step in the solution is using the non-relativistic kinetic energy formula, which fails to account for the relativistic effects that are significant at a velocity of 0.6c.   \nError Reason Analysis: - The student correctly identifies that the non-relativistic kinetic energy formula is inaccurate for speeds approaching the speed of light. - The student accurately notes the requirement to use the relativistic kinetic energy formula, which includes the Lorentz factor $(\\gamma)$ . - The student provides the correct relativistic kinetic energy formula $K E=(\\gamma-1)m c^{2}$ and describes $\\gamma$ correctly as $\\gamma\\,=\\,\\frac{1}{\\sqrt{1-\\frac{v^{2}}{c^{2}}}}$ . - Overall, the student\u2019s explanation properly reflects the nature of the error in the solution and identifies the appropriate relativistic formula to use. ", "page_idx": 28}, {"type": "text", "text": "Error Reason Correctness: Correct ", "page_idx": 28}, {"type": "text", "text": "Figure E.2-2. A success case in the physics subject. The evaluator GPT-4 correctly identified the first error step and provided appropriate and rational reasons. ", "page_idx": 28}, {"type": "text", "text": "E.3 Biology ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Subject: college biology ", "page_idx": 29}, {"type": "text", "text": "Question: Which of the following statements most detracts from the claim that the human appendix is a completely vestigial organ? ", "page_idx": 29}, {"type": "text", "text": "Options: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "-[A.] The appendix can be surgically removed with no immediate ill effects.   \n-[B.] The appendix might have been larger in fossil hominids.   \n-[C.] The appendix has a substantial amount of defensive lymphatic tissue.   \n-[D.] Individuals with a larger-than-average appendix leave fewer offspring than those with a belowaverage-sized appendix. ", "page_idx": 29}, {"type": "text", "text": "Ground Truth Answer: C ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Sampled CoT \u2014 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Sampled Model: Claude2 ", "page_idx": 29}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Step 1: Choice A states that the appendix can be surgically removed without ill effects. This suggests the appendix may not serve an important function, supporting the claim that it is vestigial. ", "page_idx": 29}, {"type": "text", "text": "Step 2: Choice B states the appendix may have been larger in fossil hominids. This suggests the appendix may have served a more important function in our evolutionary ancestors, weakening the claim that it is vestigial. ", "page_idx": 29}, {"type": "text", "text": "Step 3: Choice C states the appendix has substantial lymphatic tissue. This suggests the appendix may play an immunological role, weakening the claim that it is completely vestigial. ", "page_idx": 29}, {"type": "text", "text": "Step 4: Choice D relates appendix size to reproductive fitness. This does not directly address whether the appendix is vestigial. ", "page_idx": 29}, {"type": "text", "text": "Step 5: Choice C provides the strongest evidence against the appendix being completely vestigial, by suggesting it has an immunological function. ", "page_idx": 29}, {"type": "text", "text": "Solution: Choice C ", "page_idx": 29}, {"type": "text", "text": "Solution Correctness: incorrect ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Model Solution First Error Step: 2 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Model Solution Error Reason: Step 2 incorrectly assumes that the fact that the appendix might have been larger in fossil hominids weakens the claim that the appendix is a vestigial organ. If the appendix was larger in fossil hominids, it might indicate that it had some function in the past, but now these functions have diminished or become unimportant, which supports the claim that the appendix is a vestigial organ. This option only indicates the function of the appendix in fossil hominids and cannot strongly prove the function of the appendix in modern humans. ", "page_idx": 29}, {"type": "text", "text": "Model Solution Rectified First Error Step: Step 2: Option B indicates that the appendix might have been larger in fossil hominids. This suggests that the appendix might have had more important functions in our evolutionary ancestors, further proving the claim that it is a vestigial organ. Step 2: Option B indicates that the appendix might have been larger in fossil hominids. However, this does not explain the function of the appendix in modern humans, so this option has limitations. ", "page_idx": 29}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo ", "page_idx": 29}, {"type": "text", "text": "Evaluation Raw Response: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Solution Analysis: - Step 1: This step is correct. It accurately identifies that the ability to remove the appendix without immediate ill effects supports the idea that the appendix might be vestigial. - Step 2: This step is also correct. It suggests that if the appendix was larger in the past, it may have had a more significant function in fossil hominids, which provides a basis for it not being entirely vestigial in humans today.   \n- Step 3: This step is correct. It presents the argument that the appendix\u2019s immunological function suggests it may serve a purpose and is not completely vestigial.   \n- Step 4: This step is neutral. It accurately states that Option D does not directly address whether the appendix is vestigial, which doesn\u2019t detract from nor support the idea of it being vestigial. - Step 5: This step is correct in concluding that considering the provided options, the immunological role indicated by C (substantial amount of lymphatic tissue) provides the strongest evidence against the appendix being completely vestigial. ", "page_idx": 29}, {"type": "text", "text": "Solution Correctness: correct ", "page_idx": 29}, {"type": "text", "text": "First Error Step: N/A Error Reason: N/A ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Need Error Reason Review: False ", "page_idx": 29}, {"type": "text", "text": "Figure E.3-1. A failure case of the biology subject. It is another occurrence where the sampled LLM (Claude2) reached a correct answer through incorrect multi-step reasoning. The evaluator GPT-4 did not spot the knowledge and logic reasoning error in step 2 about Choice B, but made a similar incorrect analysis. ", "page_idx": 29}, {"type": "text", "text": "Subject: college biology ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Natural selection is based on all of the following except Options: [A.] genetic variation exists within populations. [B.] the best-adapted individuals tend to leave the most offspring. [C.] individuals who survive longer tend to leave more offspring than those who die young. [D.] individuals adapt to their environments and, thereby, evolve. Ground Truth Answer: D ", "page_idx": 30}, {"type": "text", "text": "\u2014 Sampled CoT ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Sampled Model: GPT3.5 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Step 1: Genetic variation within populations is a fundamental concept of natural selection as it provides the raw material for evolution to occur. ", "page_idx": 30}, {"type": "text", "text": "Step 2: The best-adapted individuals leaving the most offspring is a key aspect of natural selection as it leads to the passing on of advantageous traits to subsequent generations. ", "page_idx": 30}, {"type": "text", "text": "Step 3: Individuals who survive longer tend to leave more offspring than those who die young is directly related to the concept of natural selection, as individuals with advantageous traits are more likely to survive and reproduce. ", "page_idx": 30}, {"type": "text", "text": "Step 4: Individuals adapting to their environments and evolving is the core principle of natural selection, as organisms that are better suited to their environment are more likely to survive and reproduce. Solution: Choice A: genetic variation exists within populations. ", "page_idx": 30}, {"type": "text", "text": "Solution Correctness: incorrect ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Model Solution First Error Step: 4 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Model Solution Error Reason: The model that describes individuals adapting to their environments and evolving is incorrect as a core principle of natural selection, because it is populations, not individuals, that are the basic units of evolution. The result of natural selection leads to species adapting to environments and evolving, but it is not based on the factor that individuals adapt to their environments and thereby evolve. ", "page_idx": 30}, {"type": "text", "text": "Model Solution Rectified First Error Step: Step 4: Individuals adapting to their environments and evolving is not a core principle of natural selection, because individuals adapting to environments to increase their chances of survival and reproduction cannot be termed as evolution. Solution: Option D: Individuals adapt to their environments and thereby evolve. Step 4: Individuals adapting to their environments and evolving is a result of natural selection, Solution: Option D. ", "page_idx": 30}, {"type": "text", "text": "\u2014Model Evaluation Result ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Evaluation Raw Response: ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Solution Analysis: - Step 1: This step is correct as it accurately identifies that genetic variation within populations is essential for natural selection because it provides the necessary diversity on which selection can act. - Step 2: This step is correct and highlights that the best-adapted individuals generally reproduce more, which is fundamental to natural selection because it ensures the spread of beneficial traits. - Step 3: This step is correct, establishing that individuals who live longer have more opportunities to reproduce, contributing to the mechanism of natural selection through differential survival. - Step 4: This step is incorrect. It misstates the process of natural selection by suggesting that individuals adapt to their environments and thereby evolve. Natural selection acts on existing variations within a population and doesn\u2019t involve organisms individually adapting or evolving in response to an environment. ", "page_idx": 30}, {"type": "text", "text": "Solution Correctness: incorrect First Error Step: Step 4 Error Reason: Step 4 incorrectly implies that individual organisms adapt to their environments and evolve as a result, which misunderstands natural selection. In reality, natural selection operates on a population level based on existing genetic variations, and individuals do not adapt or evolve during their lifetimes. Evolutionary changes can occur in the population over generations as those with beneficial traits have better survival and reproductive success. The corrected reasoning for this step would be: \u201dThe misconception that individuals adapt and thereby evolve is not a principle of natural selection, as natural selection acts on heritable traits that are beneficial prior to and independently from environmental pressures, not post-adaptation by individuals.\u201d ", "page_idx": 30}, {"type": "text", "text": "Solution Correctness: incorrect ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "First Error Step: Step 4 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Error Reason: Step 4 incorrectly implies that individual organisms adapt to their environments and evolve as a result, which misunderstands natural selection. In reality, natural selection operates on a population level based on existing genetic variations, and individuals do not adapt or evolve during their lifetimes. Evolutionary changes can occur in the population over generations as those with beneficial traits have better survival and reproductive success. The corrected reasoning for this step would be: \u201dThe misconception that individuals adapt and thereby evolve is not a principle of natural selection, as natural selection acts on heritable traits that are beneficial prior to and independently from environmental pressures, not postadaptation by individuals.\u201d ", "page_idx": 30}, {"type": "text", "text": "Need Error Reason Review: True ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Error Reason Correctness Analysis: 1. Step-by-Step Reasoning: - The original incorrect step implies that individual organisms are capable of adapting and evolving within their own lifetimes as a response to environmental pressures. This is a fundamental misunderstanding of how natural selection works. Natural selection operates at the level of populations over generations, not individuals. It is the differential survival and reproduction of individuals with certain heritable traits that leads to evolution. - The correct understanding is that while individuals with certain traits may have better survival and reproduction rates, these traits must already exist within the genetic makeup of the population. The population evolves over time as these traits become more common, not individuals adapting or evolving on their own. ", "page_idx": 30}, {"type": "text", "text": "2. Student Error Reason Analysis: - The student identifies the core issue with the incorrect step, noting that it incorrectly attributes the process of adaptation and evolution to individual organisms rather than populations. - The student correctly points out that natural selection is based on pre-existing genetic variation within a population and that individuals themselves do not adapt or evolve during their lifetimes. - The student\u2019s explanation correctly aligns with the principle that evolutionary changes are a consequence of differential reproductive success among individuals with different heritable traits, and these changes accumulate over generations within a population. - The student accurately clarifies the misconception by explaining that natural selection acts on heritable traits beneficial prior to any environmental changes and that the process does not involve post-adaptation evolution by individuals. ", "page_idx": 30}, {"type": "text", "text": "3. Final Decision: Correct ", "page_idx": 30}, {"type": "text", "text": "E.4 Medicine ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question UUID: 997088bb-200d-44b5-9833-a47b29e9a88b Subject: college medicine ", "page_idx": 31}, {"type": "text", "text": "Question: ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "A 63-year-old woman is in the hospital recovery room 4 hours after elective left hemicolectomy for colon carcinoma at the splenic flexure. She has a preoperative written directive for no blood products through transfusion for religious reasons. Medical history is significant for hypertension and coronary artery disease. The nurse tells you the patient\u2019s blood pressure has progressively declined since the operation. Vital signs now are temperature $35.8^{\\circ}\\mathrm{C}$ $(96.4^{\\circ}\\mathrm{F})$ , pulse $130/\\mathrm{min}$ , respirations $20/\\mathrm{min}$ , and blood pressure $80/50\\ \\mathrm{mm\\Hg}$ . Physical examination discloses a slightly distended abdomen with an intact incision. ECG shows sinus tachycardia. Urine output has been $10~\\mathrm{mL}$ during the past 2 hours. Hematocrit is $30\\%$ ; preoperative hematocrit was $41\\%$ . The patient has received $^\\mathrm{~4~L~}$ of intravenous crystalloid in the recovery room. Reported operative blood loss was $200~\\mathrm{mL}$ . Drainage from the nasogastric tube is clear. Damage to which of the following structures is most likely responsible for these findings? ", "page_idx": 31}, {"type": "text", "text": "Options: ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "A: Epigastric artery B: Liver   \nC: Middle colic artery D: Spleen ", "page_idx": 31}, {"type": "text", "text": "Ground Truth Answer: D ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Ground Truth Answer Modified: C ", "page_idx": 31}, {"type": "text", "text": "Sampled Model: mistral-medium Model Solution Steps: ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Step 1: Assess the vital signs and hematocrit ", "page_idx": 31}, {"type": "text", "text": "The patient\u2019s vital signs show hypotension (low blood pressure), tachycardia (rapid heart rate), and hypothermia (low body temperature). The urine output is also low, indicating possible renal hypoperfusion. The significant drop in hematocrit (from $41\\%$ to $30\\%$ ) suggests acute blood loss anemia. Step 2: Evaluate the intraoperative and postoperative fluid management ", "page_idx": 31}, {"type": "text", "text": "The reported operative blood loss is only $200~\\mathrm{mL}$ , which is not enough to cause such a significant drop in hematocrit and hemodynamic instability. The patient received $^\\mathrm{~4~L~}$ of intravenous crystalloids in the recovery room. However, this amount of fluid should have compensated for the blood loss and maintained blood pressure stability unless there is ongoing or occult blood loss. ", "page_idx": 31}, {"type": "text", "text": "Step 3: Assess the abdominal examination for signs of internal bleeding ", "page_idx": 31}, {"type": "text", "text": "The slightly distended abdomen and clear drainage from the nasogastric tube do not suggest an acute mechanical obstruction or ileus. The intact incision and absence of overt bleeding also do not indicate an external source of hemorrhage. ", "page_idx": 31}, {"type": "text", "text": "Step 4: Consider possible injury to abdominal structures during the operation ", "page_idx": 31}, {"type": "text", "text": "Since the patient had a left hemicolectomy, the potential structures that might have been injured include the epigastric artery, middle colic artery, spleen, or liver. ", "page_idx": 31}, {"type": "text", "text": "Step 5: Analyze each choice to determine the most likely cause of the patient\u2019s condition ", "page_idx": 31}, {"type": "text", "text": "Choice A: Epigastric artery - Injury to the epigastric artery is unlikely to cause significant bleeding during a left hemicolectomy, as these vessels are not in the immediate operative field. ", "page_idx": 31}, {"type": "text", "text": "Choice B: Liver - Although liver injury can lead to hemorrhage, it would typically present with an acute onset of hypotension and peritoneal signs. The patient\u2019s initial vital signs were stable, and there is no evidence of peritonitis. ", "page_idx": 31}, {"type": "text", "text": "Choice C: Middle colic artery - This artery is in the operative field and could be injured during a left hemicolectomy. Major bleeding from this artery could lead to the patient\u2019s hemodynamic instability and hematocrit drop. ", "page_idx": 31}, {"type": "text", "text": "Choice D: Spleen - Splenic injury could lead to significant hemorrhage, but this is an uncommon complication of a left hemicolectomy due to the spleen\u2019s anatomic location. ", "page_idx": 31}, {"type": "text", "text": "Step 6: Integrate all findings and determine the most likely cause ", "page_idx": 31}, {"type": "text", "text": "The patient\u2019s hemodynamic instability, low hematocrit, and minimal reported blood loss suggest ongoing or occult internal bleeding. The intact incision, clear nasogastric tube drainage, and slightly distended abdomen do not support external bleeding or mechanical obstruction. Among the possible injured structures, the middle colic artery is the most likely cause of the patient\u2019s condition. Solution: Choice C: Middle colic artery ", "page_idx": 31}, {"type": "text", "text": "Solution Correctness: incorrect ", "page_idx": 31}, {"type": "text", "text": "Model Solution First Error Step: 2 Model Solution Error Reason: ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "The analysis mentions that the patient has received 4 liters of intravenous crystalloid in the recovery room, yet the blood pressure continues to decline, indicating ongoing or occult blood loss. The decrease in hematocrit, which might be due to factors other than blood loss such as hemodilution, has not been fully considered. ", "page_idx": 31}, {"type": "text", "text": "When the patient woke up from the surgery and was transferred to the recovery room, the doctor had already administered 4 liters of crystalloid solution intravenously, which is equivalent to a significant hydration. However, despite this hydration, the patient\u2019s blood pressure has not returned to normal and continues to drop. This could mean that there is ongoing or stealthy blood loss inside the patient\u2019s body, causing the blood pressure to decrease. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "Model Solution Rectified First Error Step: ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Step 2: The patient has received 4 liters of intravenous crystalloid in the recovery room, but the blood pressure continues to decline. The reported operative blood loss was $200~\\mathrm{{mL}}$ , and the hematocrit dropped from $41\\%$ to $30\\%$ , which may be partly due to the hemodilution effect of the intravenous injection. Considering the patient\u2019s hemodynamic status, the possibility of ongoing or occult internal bleeding cannot be ruled out. ", "page_idx": 32}, {"type": "text", "text": "Step 2: After being transferred to the recovery room, the medical team administered 4 liters of crystalloid solution intravenously, which is equivalent to a significant amount of hydration. However, despite this, the patient\u2019s blood pressure continues to decline. The reported blood loss during the surgery was $200~\\mathrm{mL}$ , which usually would not cause a drop in blood pressure. Also, the patient\u2019s hematocrit dropped from $41\\%$ to $30\\%$ , which may be partly because the infused fluid diluted the blood. ", "page_idx": 32}, {"type": "text", "text": "Model Evaluation Result\u2014 Evaluated Model: gpt-4-turbo Evaluation Raw Response: ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Solution Analysis: ", "page_idx": 32}, {"type": "text", "text": "Step 1: Assess the vital signs and hematocrit - Correct. This step accurately summarizes vital signs and hematocrit values suggesting hypotension, tachycardia, hypothermia, and potential acute blood loss. ", "page_idx": 32}, {"type": "text", "text": "Step 2: Evaluate the intraoperative and postoperative fluid management - Correct. Observations are correct in stating the discrepancy between reported blood loss and observed symptoms, raising questions about additional or occult bleeding. ", "page_idx": 32}, {"type": "text", "text": "Step 3: Assess the abdominal examination for signs of internal bleeding - Correct. The abdominal examination findings are evaluated logically to rule out external bleeding sources and acute mechanical obstructions. ", "page_idx": 32}, {"type": "text", "text": "Step 4: Consider possible injury to abdominal structures during the operation - Correct. Considering potential injuries to relevant abdominal structures based on the type of surgery performed is a logical step. ", "page_idx": 32}, {"type": "text", "text": "Step 5: Analyze each choice to determine the most likely cause - Correct. Each option is analyzed based on anatomical relevance and likelihood of contributing to the observed clinical picture, leading to a rational elimination of less likely causes. ", "page_idx": 32}, {"type": "text", "text": "Step 6: Integrate all findings and determine the most likely cause - Correct. This step synthesizes the information from previous steps and identifies the middle colic artery as the most likely source of ongoing internal bleeding, which is consistent with the location of the surgery and the clinical symptoms. Solution Correctness: correct ", "page_idx": 32}, {"type": "text", "text": "First Error Step: N/A Error Reason: N/A ", "page_idx": 32}, {"type": "text", "text": "Solution Correctness: correct First Error Step: N/A Error Reason: N/A Need Error Reason Review: False ", "page_idx": 32}, {"type": "text", "text": "Figure E.4-1. A failure case in the medicine subject. The question is relatively lengthy, highlighting the potential importance of multi-step reasoning for decomposition and analysis. Before diving into the comparison of four options, the sample model solution first provided the initial four steps to assess important information in the question context (e.g., patient status and treatments). The model solution contains an error in step 2 analyzing the patient\u2019s fluid management which the evaluator GPT-4 fails to identify. ", "page_idx": 32}, {"type": "text", "text": "Subject: college medicine ", "page_idx": 33}, {"type": "text", "text": "Question: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Which of the following diagnostic techniques is of no value for the diagnosis of neural tube defects? ", "page_idx": 33}, {"type": "text", "text": "Options: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "A: Amniocentesis   \nB: Chorion villus sampling (CVS)   \nC: Maternal serum screening   \nD: Ultrasonography ", "page_idx": 33}, {"type": "text", "text": "Ground Truth Answer: B ", "page_idx": 33}, {"type": "text", "text": "Ground Truth Answer Modified: B Sampled CoT ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "Sampled Model: GPT3.5 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Step 1: Amniocentesis involves analyzing the amniotic fluid surrounding the developing fetus for genetic abnormalities. It can detect neural tube defects and is commonly used for prenatal diagnosis. ", "page_idx": 33}, {"type": "text", "text": "Step 2: Chorion villus sampling (CVS) is another prenatal diagnostic technique that involves taking a sample of the placental tissue to analyze the genetic composition of the fetus. It can also detect neural tube defects. Step 3: Maternal serum screening is a blood test that measures certain substances in the mother\u2019s blood to assess the risk of certain birth defects, including neural tube defects. It is a valuable tool for screening but may not definitively diagnose neural tube defects. ", "page_idx": 33}, {"type": "text", "text": "Step 4: Ultrasonography is a prenatal imaging technique that can visualize the developing fetus in the uterus.   \nIt can detect neural tube defects by visualizing the spine and brain of the fetus. ", "page_idx": 33}, {"type": "text", "text": "Solution: Choice C - Maternal serum screening is of no value for the diagnosis of neural tube defects. ", "page_idx": 33}, {"type": "text", "text": "Solution Correctness: incorrect ", "page_idx": 33}, {"type": "text", "text": "Model Solution First Error Step: 2 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Model Solution Error Reason: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "The model incorrectly assumes that Chorionic Villus Sampling (CVS) can detect neural tube defects. CVS is primarily used for the detection of chromosomal abnormalities, not for diagnosing structural birth defects like neural tube defects. ", "page_idx": 33}, {"type": "text", "text": "Chorionic Villus Sampling is a medical procedure that involves analyzing fetal cells in placental tissue to detect chromosomal abnormalities and genetic diseases. Although this technique can provide important information about the genetic condition of the fetus, its primary application does not include the direct diagnosis of neural tube defects. Therefore, describing the main purpose of CVS as directly used for diagnosing neural tube defects is inaccurate. ", "page_idx": 33}, {"type": "text", "text": "Model Solution Rectified First Error Step: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Step 2: Chorionic Villus Sampling (CVS) is a prenatal diagnostic technique primarily used for detecting chromosomal abnormalities, such as Down syndrome, by analyzing placental tissue. It is not typically used to detect neural tube defects. ", "page_idx": 33}, {"type": "text", "text": "Step 2: Chorionic Villus Sampling (CVS) involves collecting placental tissue and analyzing fetal cells, and is not directly used for diagnosing neural tube defects. ", "page_idx": 33}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo Evaluation Raw Response: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Solution Analysis: ", "page_idx": 33}, {"type": "text", "text": "Step 1: Correct - This explanation accurately describes the process and utility of amniocentesis in detecting genetic abnormalities, including neural tube defects. ", "page_idx": 33}, {"type": "text", "text": "Step 2: Incorrect - Chorion villus sampling (CVS) primarily looks at chromosomal information and is more effective in diagnosing chromosomal abnormalities rather than neural tube defects, which are best detected using other methods like amniocentesis, maternal serum screening, or ultrasonography. ", "page_idx": 33}, {"type": "text", "text": "Step 3: Correct - The description of maternal serum screening is accurate. While the test is valuable for screening, it is not definitive for diagnosis, hence its utility in assessing risk rather than confirming neural tube defects. ", "page_idx": 33}, {"type": "text", "text": "Step 4: Correct - Ultrasonography is correctly described as a visualization method capable of detecting neural tube defects through imaging. ", "page_idx": 33}, {"type": "text", "text": "Solution: Incorrect - The conclusion that maternal serum screening is of no value for the diagnosis of neural tube defects is incorrect. Though it is not definitive for diagnosis, it is still a valuable screening tool and does provide relevant information to suggest the presence of neural tube defects.   \nSolution Correctness: incorrect   \nFirst Error Step: Step 2 ", "page_idx": 33}, {"type": "text", "text": "Error Reason: The error in Step 2 pertains to the oversimplified or wrong explanation regarding the capability of CVS to detect neural tube defects. CVS is rather specific for detecting genetic and chromosomal abnormalities rather than structural defects like neural tube issues which are better detected by amniocentesis or ultrasonography. A rectified response could state that while CVS is valuable for chromosomal analysis, it does not typically detect neural tube defects, which are better assessed by other diagnostic methods outlined here. ", "page_idx": 33}, {"type": "text", "text": "Solution Correctness: incorrect ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "First Error Step: Step 2 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Error Reason: The error in Step 2 pertains to the oversimplified or wrong explanation regarding the capability of CVS to detect neural tube defects. CVS is rather specific for detecting genetic and chromosomal abnormalities rather than structural defects like neural tube issues which are better detected by amniocentesis or ultrasonography. A rectified response could state that while CVS is valuable for chromosomal analysis, it does not typically detect neural tube defects, which are better assessed by other diagnostic methods outlined here. ", "page_idx": 33}, {"type": "text", "text": "Need Error Reason Review: True ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Error Reason Correctness: Correct ", "page_idx": 33}, {"type": "text", "text": "Figure E.4-2. A success case of the medicine subject. The evaluator GPT-4 correctly identified the first error step and provided appropriate and rational reasons. ", "page_idx": 33}, {"type": "text", "text": "E.5 Chemistry ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Subject: college chemistry   \nQuestion:   \nCalculate the magnetic moment $\\left(\\mu_{I}\\right)$ of a $^{13}\\mathrm{C}$ nucleus.   \nOptions:   \nA: $6.1445\\times10^{-27}\\mathrm{~J~T^{-1}}$   \nB: $3.1445\\times10^{-27}\\mathrm{~J~T~}^{\\cdot}$ \u22121   \nC: $9.1445\\times10^{-27}\\mathrm{~J~}^{\\prime}$ T\u22121   \nD: $1.1445\\times10^{-28}$ J T\u22121   \nGround Truth Answer: C   \nGround Truth Answer Modified: A   \nSampled CoT   \nSampled Model: Claude2   \nModel Solution Steps:   \nStep 1: The magnetic moment $\\left(\\mu_{I}\\right)$ of a nucleus depends on its spin quantum number (I) according to the following formula:   \n$\\mu_{I}=\\gamma I\\hbar$   \nWhere $\\gamma$ is the gyromagnetic ratio and $\\hbar$ is the reduced Planck constant.   \nStep 2: For a $^{13}\\mathrm{C}$ nucleus, $\\begin{array}{r}{I=\\frac{1}{2}}\\end{array}$ .   \nStep 3: The gyromagnetic ratio for a $^{13}\\mathrm{C}$ nucleus is $6.728\\times10^{7}~\\mathrm{{T^{-1}s^{-1}}}$ .   \nStep 4: Substituting the values for $I$ and $\\gamma$ into the formula:   \n$\\mu_{I}=(6.728\\times10^{7}\\mathrm{~T}^{-1}\\mathrm{s}^{-1})(\\frac{1}{2})\\hbar$   \nStep 5: The value of the reduced Planck constant $\\hbar$ is $1.05457\\times10^{-34}$ J\u00b7s.   \nStep 6: Performing the calculation:   \n$\\mu_{I}=(6.728\\times10^{7}~{\\mathrm{T}}^{-1}{\\mathrm{s}}^{-1})(\\frac{1}{2})(1.05457\\times10^{-34}~{\\mathrm{J}}{\\cdot}{\\mathrm{s}})$   \n$=3.1445\\times10^{-27}\\mathrm{~J~T^{-1}}$   \nStep 7: Comparing to the answer choices, the magnetic moment calculated matches Choice B. Solution: Choice B   \nSolution Correctness: incorrect   \nModel Solution First Error Step: 1   \nModel Solution Error Reason:   \nThe formula given in the steps is incorrect, the correct formula should be $\\mu_{I}\\,=\\,\\gamma L\\hbar$ , where $L=$ $(I(I+1))^{1/2}$ .   \nThe formula provided in the steps is incorrect, the correct expression should be $\\mu_{I}\\,=\\,\\gamma L\\hbar$ , where $L=I(I+1)$ .   \nModel Solution Rectified First Error Step:   \nStep 1: The magnetic moment $\\left(\\mu_{I}\\right)$ of the nucleus is determined by the following formula based on its spin quantum number (I): $\\mu_{I}=\\gamma L\\hbar$ , where $L=(I(I+1))^{1/2}$ .   \nStep 1: The nuclear magnetic moment $\\left(\\mu_{I}\\right)$ can be calculated using the following formula based on its spin quantum number (I): $\\mu_{I}=\\gamma L\\hbar$ , where $L$ represents $L=I(I+1)$ .   \nModel Evaluation Result\u2014   \nEvaluated Model: gpt-4-turbo-2024-04-09   \nEvaluation Raw Response:   \nSolution Analysis:   \n- Step 1: This step is correct. It states the relationship between the nuclear magnetic moment $\\left(\\mu_{I}\\right)$ , the gyromagnetic ratio $(\\gamma)$ , and the reduced Planck constant $(\\hbar)$ .   \n- Step 2: This step is correct. The nuclear spin quantum number $(I)$ of carbon-13 $(^{13}\\mathrm{C})$ is indeed $\\textstyle{\\frac{1}{2}}$ . - Step 3: This step is correct. The stated gyromagnetic ratio for a $^{13}\\mathrm{C}$ nucleus $(6.728\\times10^{7}\\ \\mathrm{T^{-1}s^{-\\tilde{1}}})$ ) is the correct value for this isotope.   \n- Step 4: This step is correct. The given formula $\\mu_{I}=\\gamma I\\hbar$ is being correctly used to substitute in the values of the gyromagnetic ratio $(\\gamma)$ and the spin quantum number $(I)$ .   \n- Step 5: This step is correct. The provided value of the reduced Planck constant $\\mathit{\\dot{\\hbar}}{\\hbar}=1.05457\\times10^{-34}$ J\u00b7s) is accurate.   \n- Step 6: This step is correct. The calculation of the magnetic moment $\\left(\\mu_{I}\\right)$ is correctly performed using the provided values and the formula from step 4.   \n- Step 7: This step is correct. The calculated result from step 6 is accurately compared with the options given in the question and matches choice B.   \nSolution Correctness: correct   \nFirst Error Step: N/A   \nError Reason: N/A   \nSolution Correctness: correct   \nFirst Error Step: N/A   \nError Reason: N/A   \nNeed Error Reason Review: False ", "page_idx": 34}, {"type": "text", "text": "Subject: high school chemistry ", "page_idx": 35}, {"type": "text", "text": "Question: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Three $25.00~\\mathrm{mL}$ samples of approximately $0.10~\\mathrm{M}$ phenol, $\\mathrm{C_{6}H_{5}O H}$ , $K_{a}=1.0\\times10^{-10}$ were removed from a container and placed in separate $250~\\mathrm{mL}$ beakers. The samples were titrated with standard potassium hydroxide, KOH, solution. Cresol red was the acid-base indicator used in the titration. The samples required 31.75, 32.38, and $41.75~\\mathrm{mL}$ to reach the endpoint. Which of the following might explain why one of the samples required significantly more base to reach the endpoint? ", "page_idx": 35}, {"type": "text", "text": "Options: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "A: The indicator was added too late.   \nB: The wrong indicator was used.   \nC: There was a base contaminating the unclean beaker.   \nD: There was an acid contaminating the unclean beaker. ", "page_idx": 35}, {"type": "text", "text": "Ground Truth Answer: D ", "page_idx": 35}, {"type": "text", "text": "Ground Truth Answer Modified: D ", "page_idx": 35}, {"type": "text", "text": "Sampled Model: Claude2 ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Step 1: The phenol solutions were approximately $0.10\\,\\mathrm{~M~}$ concentration. At this concentration, the volumes of KOH required to reach the endpoint should be similar for all 3 samples. ", "page_idx": 35}, {"type": "text", "text": "Step 2: Two of the samples required similar volumes of KOH $31.75~\\mathrm{mL}$ and $\\mathrm{32.38~mL}$ ). However, the third sample required significantly more $\\mathrm{(41.75~mL)}$ ). ", "page_idx": 35}, {"type": "text", "text": "Step 3: Choice A suggests the indicator was added too late. This would not change the volume of KOH required, only the observed color change. ", "page_idx": 35}, {"type": "text", "text": "Step 4: Choice B suggests the wrong indicator was used. This may affect the observed color change, but not the volume of KOH required. ", "page_idx": 35}, {"type": "text", "text": "Step 5: Choice C suggests a contaminating base in one sample. A contaminating base would react with the phenol, requiring more KOH to reach the endpoint. ", "page_idx": 35}, {"type": "text", "text": "Step 6: Choice D suggests a contaminating acid. An acid contaminant would be neutralized by the KOH and not affect the volume required. ", "page_idx": 35}, {"type": "text", "text": "Step 7: Therefore, the explanation that a contaminating base required more KOH to reach the endpoint in one sample is choice C.   \nSolution: Choice C ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 35}, {"type": "text", "text": "Solution Correctness: incorrect ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Model Solution First Error Step: 5 Model Solution Error Reason: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "The statement in the erroneous step that more KOH is needed to reach the endpoint is inaccurate. The reaction of phenol with a basic contaminant would lead to a decrease in the amount of KOH used, not an increase. ", "page_idx": 35}, {"type": "text", "text": "In the description of the erroneous step, the statement that more KOH is needed to reach the endpoint is inaccurate. In fact, the reaction of phenol with a basic contaminant would result in a decrease in the consumption of KOH, not an increase. ", "page_idx": 35}, {"type": "text", "text": "Model Solution Rectified First Error Step: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Step 5: Option C indicates that there is a contaminated base in one of the samples. The contaminated base reacts with phenol, reducing the amount of KOH needed to reach the endpoint. ", "page_idx": 35}, {"type": "text", "text": "Step 5: Option C points out that the sample contains a contaminated base. This contaminated base reacts with phenol, leading to a reduction in the amount of KOH needed to reach the endpoint. ", "page_idx": 35}, {"type": "text", "text": "Model Evaluation Result ", "page_idx": 35}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo-2024-04-09 Evaluation Raw Response: ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Solution Analysis: ", "page_idx": 35}, {"type": "text", "text": "- Step 1 is correct. It establishes the expectation for the volumes of KOH required based on the concentration of phenol. ", "page_idx": 35}, {"type": "text", "text": "- Step 3 is correct. Adding the indicator too late would not alter the required volume of KOH, only the point at which the change is observed. ", "page_idx": 35}, {"type": "text", "text": "- Step 4 is correct. Using the wrong indicator may affect the endpoint\u2019s observation but not the actual chemically required volume of KOH. ", "page_idx": 35}, {"type": "text", "text": "- Step 5 is incorrect. The explanation here misunderstands the effect of a contaminating base. A contaminating base in a sample would actually reduce the amount of KOH required to reach the endpoint because it would partially neutralize the acid (phenol) present before the KOH is added, not require more KOH as stated. ", "page_idx": 35}, {"type": "text", "text": "- Step 6 is also incorrect but the identified first error is in Step 5. A contaminating acid would indeed require more KOH to reach the endpoint because it adds to the total amount of acid that must be neutralized. ", "page_idx": 35}, {"type": "text", "text": "- Step 7 reaches an incorrect conclusion based on incorrect reasoning presented in Step 5. Solution Correctness: incorrect First Error Step: Step 5 Error Reason: The error in reasoning is that a contaminating base would lead to an increased consumption of KOH. In reality, a contaminating base would have already neutralized some of the acid present, thus requiring less KOH to reach the endpoint of the titration. The corrected reasoning should suggest that a contaminating acid (not base) in the unclean beaker would explain why more KOH was required to reach the endpoint, pointing toward Choice D as the correct explanation rather than Choice C. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "Solution Correctness: incorrect ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "First Error Step: Step 5 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Error Reason: The error in reasoning is that a contaminating base would lead to an increased consumption of KOH. In reality, a contaminating base would have already neutralized some of the acid present, thus requiring less KOH to reach the endpoint of the titration. The corrected reasoning should suggest that a contaminating acid (not base) in the unclean beaker would explain why more KOH was required to reach the endpoint, pointing toward Choice D as the correct explanation rather than Choice C. ", "page_idx": 36}, {"type": "text", "text": "Need Error Reason Review: True Error Reason Correctness Analysis: Scoring Model: gpt-4-turbo-2024-04-09 ", "page_idx": 36}, {"type": "text", "text": "Scoring Raw Response: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "1. Step-by-Step Reasoning: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "- The error identifies the misconception about the effect of a contaminating base in one of the samples. - It is incorrectly stated that a contaminating base would lead to an increased consumption of KOH to reach the endpoint. ", "page_idx": 36}, {"type": "text", "text": "- In reality, if a base contaminant had reacted with the phenol, it would have neutralized some of the acid, thereby reducing the amount of KOH necessary to reach the endpoint.   \n- The correct understanding is that a contaminating acid, not a base, would require additional KOH to neutralize, thus explaining the increased volume of KOH needed for one of the samples.   \n2. Student Error Reason Analysis:   \n- The student correctly identifies the error in reasoning regarding the effect of a contaminating base on the consumption of KOH.   \n- They accurately point out that a contaminating base would result in less, not more, KOH needed to reach the titration endpoint because the base would have neutralized some of the acid present. - The student correctly redirects the reasoning towards a contaminating acid being the cause for the increased KOH volume required, aligning with the true reason for the observed discrepancy. - This explanation correctly shifts from Choice C (a contaminating base) to Choice D (a contaminating acid) as the valid reason for the anomaly in the titration results.   \n3. Final Decision: Correct ", "page_idx": 36}, {"type": "text", "text": "", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Annotation Analysis: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "- The error identifies the misconception about the effect of a contaminating base in one of the samples. - It is incorrectly stated that a contaminating base would lead to an increased consumption of KOH to reach the endpoint. - In reality, if a base contaminant had reacted with the phenol, it would have neutralized some of the acid, thereby reducing the amount of KOH necessary to reach the endpoint. - The correct understanding is that a contaminating acid, not a base, would require additional KOH to neutralize, thus explaining the increased volume of KOH needed for one of the samples. ", "page_idx": 36}, {"type": "text", "text": "Error Reason Analysis: ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "- The student correctly identifies the error in reasoning regarding the effect of a contaminating base on the consumption of KOH.   \n- They accurately point out that a contaminating base would result in less, not more, KOH needed to reach the titration endpoint because the base would have neutralized some of the acid present. - The student correctly redirects the reasoning towards a contaminating acid being the cause for the increased KOH volume required, aligning with the true reason for the observed discrepancy. - This explanation correctly shifts from Choice C (a contaminating base) to Choice D (a contaminating acid) as the valid reason for the anomaly in the titration results. ", "page_idx": 36}, {"type": "text", "text": "Error Reason Correctness: Correct ", "page_idx": 36}, {"type": "text", "text": "E.6 Logic ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question UUID: 57a04b12-b958-4a52-95a6-caf1e5261966 ", "page_idx": 37}, {"type": "text", "text": "Subject: logic ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "A highway management office decided to recruit 10 auxiliary road managers to solve the problem of shortage of formal managers, but this proposal aroused opposition from some people. The person believes that with the addition of these 10 road auxiliary managers, there will be more road violations and disciplinary violations will be found, and more formal managers will be needed to deal with these problems in the later stage. This will lead to a shortage of already tense formal managers. Which of the following, if true, will most weaken that person\u2019s point of view? ", "page_idx": 37}, {"type": "text", "text": "Options: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "A: The newly recruited auxiliary road managers may not be able to do their job with due diligence ", "page_idx": 37}, {"type": "text", "text": "B: There are many road violations, and the problem of disciplinary violations can be solved on the spot,   \nwithout delaying to post-processing   \nC: Auxiliary road managers can also deal with road violations and disciplinary violations later   \nD: The increase of road auxiliary managers will effectively reduce the occurrence of road violations and   \ndisciplinary violations on this section of the road ", "page_idx": 37}, {"type": "text", "text": "Ground Truth Answer: C ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Ground Truth Answer Modified: C ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Sampled Model: GPT3.5 ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Step 1: If the newly recruited auxiliary road managers may not be able to do their job with due diligence, it could potentially lead to more road violations and disciplinary issues, supporting the opposition\u2019s point of view. ", "page_idx": 37}, {"type": "text", "text": "Step 2: If there are many road violations, and the problem of disciplinary violations can be solved on the spot without delay, it weakens the argument that more formal managers will be needed to handle the issues later. ", "page_idx": 37}, {"type": "text", "text": "Step 3: If auxiliary road managers can also deal with road violations and disciplinary violations later, it weakens the argument that more formal managers will be required to handle these problems. ", "page_idx": 37}, {"type": "text", "text": "Step 4: If the increase of road auxiliary managers will effectively reduce the occurrence of road violations and disciplinary violations, it completely weakens the opposition\u2019s point of view that more formal managers will be needed to handle the expected increase in violations. ", "page_idx": 37}, {"type": "text", "text": "Solution: Choice D ", "page_idx": 37}, {"type": "text", "text": "Solution Correctness: incorrect ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Model Solution First Error Step: 4 ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Model Solution Error Reason: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Option D does not completely weaken the opponent\u2019s point of view. Because it only says that increasing personnel can effectively reduce violations, but the amount of reduction is uncertain, and the impact on later work is also uncertain. Therefore, the final solution reasoning result is incorrect. ", "page_idx": 37}, {"type": "text", "text": "This does not completely weaken the opponent\u2019s point of view. Because it lacks the specific number of how increasing personnel can effectively reduce violations, it does not provide the most reliable evidence. ", "page_idx": 37}, {"type": "text", "text": "Model Solution Rectified First Error Step: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Step 4: If the added auxiliary road managers can effectively reduce the occurrence of road violations and disciplinary violations, this to some extent weakens the opponent\u2019s point of view. But because it only says that increasing personnel can effectively reduce violations, but the amount of reduction is uncertain, and the impact on later work is also uncertain. Therefore, in comparison, option C is the most weakening option. Solution: Option C. ", "page_idx": 37}, {"type": "text", "text": "Step 4: If the added auxiliary road managers can effectively reduce the occurrence of road violations and disciplinary violations, this weakens the opponent\u2019s point of view, that is, more formal managers are needed to deal with the expected increase in violations. But it lacks the specific number of how increasing personnel can effectively reduce violations, it does not provide the most reliable evidence. Option C states that even if violations are discovered, auxiliary personnel can also solve the problem, so it will not increase the workload of formal personnel. Therefore, it most weakens the point of view. Solution: Option C. ", "page_idx": 37}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo-2024-04-09 ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Evaluation Raw Response: ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Solution Analysis: ", "page_idx": 37}, {"type": "text", "text": "- Step 1 explains Option A in which the auxiliary road managers may not perform well, potentially increasing issues rather than reducing them. This step is neutral as it provides background to Option A but does not directly weaken the opposition\u2019s viewpoint. ", "page_idx": 37}, {"type": "text", "text": "- Step 2 discusses Option B, suggesting that immediate resolution of violations reduces the need for formal managers later. This reasoning correctly identifies how this option weakens the argument. This step is correct. ", "page_idx": 37}, {"type": "text", "text": "- Step 3 examines Option C, indicating that auxiliary road managers being able to handle violations later could also weaken the need for formal managers. This is a valid point, and this step is correct. ", "page_idx": 37}, {"type": "text", "text": "- Step 4 analysis Option D and concludes that it directly weakens the opposition\u2019s point by reducing the occurrence of violations. This analysis is correct with sound reasoning. ", "page_idx": 37}, {"type": "text", "text": "- The selected solution (Choice D) directly addresses the concern about increasing violations requiring more formal managers by positing that violations would decrease. Solution Correctness: correct First Error Step: N/A Error Reason: N/A ", "page_idx": 37}, {"type": "text", "text": "Solution Correctness: correct ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "First Error Step: N/A ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Error Reason: N/ ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Need Error Reason Review: False ", "page_idx": 37}, {"type": "text", "text": "Question UUID: 17f4f79c-e8db-4514-b047-fbb2f905e7f6 ", "page_idx": 38}, {"type": "text", "text": "Subject: logic ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Living gifts refer to the donation of money to children, grandchildren and other relatives when the donor decides to live, or to use it for vacations and the establishment of trust funds. Among the following options, which is a living gift? ", "page_idx": 38}, {"type": "text", "text": "Options: ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "A: Mr. Wang made a will before his death, leaving $90\\%$ of his property to his only granddaughter. B: Chairman Li handed over $80\\%$ of his property and the entire group to his daughter, and then lived in the mountain village by himself.   \nC: Grandma Wang asked her grandson to get married in her own house and live in a nursing home by herself. D: Two years after Mr. Li disappeared, his son inherited his property. One day, he suddenly appeared at home. ", "page_idx": 38}, {"type": "text", "text": "Ground Truth Answer: B ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Ground Truth Answer Modified: B ", "page_idx": 38}, {"type": "text", "text": "Sampled Model: GPT3.5 ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Model Solution Steps: ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Step 1: Mr. Wang leaving $90\\%$ of his property to his only granddaughter in his will is not a living gift as it occurs after his death.   \nStep 2: Chairman Li handing over $80\\%$ of his property to his daughter and then living in a mountain village is not a living gift as it also occurs before his death.   \nStep 3: Grandma Wang asking her grandson to get married in her own house and living in a nursing home by herself is not a living gift, but more of a familial arrangement.   \nStep 4: Two years after Mr. Li disappeared, his son inherited his property, which suggests it was not a planned living gift.   \nConclusion: The only option that fits the definition of a living gift is Choice A: Mr. Wang made a will before his death, leaving $90\\%$ of his property to his only granddaughter. ", "page_idx": 38}, {"type": "text", "text": "Solution Correctness: incorrect ", "page_idx": 38}, {"type": "text", "text": "Model Solution First Error Step: 2 ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Model Solution Error Reason: ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "The model incorrectly assumes that Chairman Li handing over $80\\%$ of his property to his daughter is not a living gift. According to the definition of living gifts, these gifts are given when the donor is alive, and option B describes Chairman Li giving his property to his daughter during his lifetime, which fits the definition of a living gift. Therefore, the judgment in step 2 is wrong. ", "page_idx": 38}, {"type": "text", "text": "Model Solution Rectified First Error Step: ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Step 2: It should be pointed out that option B describes a living gift because Chairman Li transferred his property to his daughter during his lifetime, which is in line with the definition of living gifts. Step 2: Option B describes a case of living gifts because Chairman Li transferred his property to his daughter during his lifetime, which is consistent with the definition of living gifts, that is, the donation is made when the donor is alive. ", "page_idx": 38}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo Evaluation Raw Response: ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Solution Analysis: ", "page_idx": 38}, {"type": "text", "text": "Step 1: This step correctly identifies that Mr. Wang\u2019s will, which comes into effect after his death, does not qualify as a living gift. The reasoning is sound because living gifts are defined as donations made while the donor is still alive. ", "page_idx": 38}, {"type": "text", "text": "Step 2: This step misinterprets the definition of a living gift. Chairman Li handing over $80\\%$ of his property to his daughter and then living elsewhere matches the definition of a living gift since it is done while he is alive. Thus, the conclusion drawn in this step is incorrect. ", "page_idx": 38}, {"type": "text", "text": "Step 3: The analysis here is correct in determining that Grandma Wang\u2019s action doesn\u2019t directly involve a transfer of money or property as a gift to live; instead, it\u2019s about a living arrangement. However, it could still be considered a form of living gift indirectly, but the explanation does not explore this possibility. The step is more neutral due to lack of exploration. ", "page_idx": 38}, {"type": "text", "text": "Step 4: The identification that Mr. Li\u2019s post-disappeared inheritance does not constitute a living gift is correct, as it relies on the absence and presumed death of Mr. Li. ", "page_idx": 38}, {"type": "text", "text": "Conclusion: The conclusion drawn is incorrect, as it identifies Option A as the correct answer, which was established in the first step as not fitting the definition of a living gift due to it taking effect after death. Solution Correctness: incorrect ", "page_idx": 38}, {"type": "text", "text": "First Error Step: Step 2 ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Error Reason: The first error occurs in Step 2, where the solution incorrectly states that Chairman Li handing over property to his daughter is not a living gift because it \u201doccurs before his death.\u201d This contradicts the very definition of a living gift, which is specified to be the donation of money, property, etc., to relatives while the donor is still alive. Chairman Li\u2019s action of transferring his property to his daughter while he is alive perfectly aligns with the concept of a living gift. The corrected reasoning for Step 2 would affirm that Chairman Li\u2019s action is indeed a living gift, directly reflecting the definition provided in the question. Soluti ", "page_idx": 38}, {"type": "text", "text": "First Error Step: Step 2 ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Error Reason: The first error occurs in Step 2, where the solution incorrectly states that Chairman Li handing over property to his daughter is not a living gift because it \u201doccurs before his death.\u201d This contradicts the very definition of a living gift, which is specified to be the donation of money, property, etc., to relatives while the donor is still alive. Chairman Li\u2019s action of transferring his property to his daughter while he is alive perfectly aligns with the concept of a living gift. The corrected reasoning for Step 2 would affirm that Chairman Li\u2019s action is indeed a living gift, directly reflecting the definition provided in the question. ", "page_idx": 38}, {"type": "text", "text": "Error Reason Correctness: Correct ", "page_idx": 38}, {"type": "text", "text": "E.7 Coding ", "text_level": 1, "page_idx": 39}, {"type": "image", "img_path": "GN2qbxZlni/tmp/db15ef9e1b4910b6852c396372f9aadd63f7a738262b4df24c2399e76179fa4e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo Evaluation Raw Response: Solution Analysis: ", "page_idx": 39}, {"type": "text", "text": "1. The code starts by sorting the \u2018nums1\u2018 and \u2018nums2\u2018 lists. Sorting is neutral in this context since ensuring order is not necessary but doesn\u2019t inherently cause an error.   \n2. It then determines the length $^\\circ\\mathbf{n}^{\\circ}$ of \u2018nums1\u2018 (assumed to be equal to $\\mathrm{^\\circnums2^{\\circ}}$ since both are said to be of even length $^{\\ast}\\mathbf{n}^{\\ast}$ ). This is correct logic because the length is necessary to compute the number of elements to be removed.   \n3. The code calculates the number of elements to be deleted, \u2018remove count\u2018 as $\\sin\\ //\\ 2^{\\circ}$ . Given that $^\\circ}$ is always even (as stipulated by the question), this is a correct computation ensuring integers for indexing. 4. It then creates a set $\\mathbf{\\omega}^{\\ast}\\mathbf{s}^{\\ast}$ by concatenating $\\mathrm{\\dot{\\nums}1^{\\circ}}$ and \u2018nums2\u2018 from indices \u2018remove count\u2018 onwards. This directs removal of the first $\\mathrm{~\\dot{~}n~}//\\mathrm{~2^{\\circ}~}$ elements from each list and thus working on the latter half of both lists. 5. Finally, it returns the size of set \u2018s\u2018 which represents the number of unique elements in the resulting collected elements. This operation is correctly used by $^{\\bullet}\\mathrm{len}(\\mathrm{s})^{\\circ}$ . The provided implementation perfectly resonates with the objective of the algorithm as explained by the docstring.   \nSolution Correctness: correct   \nFirst Error Step: N/A   \nError Reason: N/A ", "page_idx": 39}, {"type": "text", "text": "Figure E.7-1. A failure case in coding. The sampled code fails to identify the key point that the set s is unindexed, hence duplicate elements will be removed. The assessed GPT-4 fails to annotate the error when evaluating the code solution, only blindly accepting the code as logically correct and computable. ", "page_idx": 39}, {"type": "text", "text": "from typing import List ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "def arrange_ark_pairs (ark\\_deck: List[int]) -> int: \"\"\" ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Legend tells of a great Ark built by Noah to survive an immense flood that would cover the Earth. To preserve the natural world , Noah invited animals to join him on the Ark , inviting them in pairs so that each species could continue in the new world. As the animals boarded the Ark , they were assigned places in a linear formation across the Ark \u2019s deck. However , in the rush to board before the rain began , the animal pairs became separated across the 2n available spaces . Each animal is known by a unique identifier , and the list of these identifiers as they are arranged on the Ark is given by an integer array \u2018arkDeck \u2018 where \u2018arkDeck [i]\u2018 represents the animal occupying the ith space. The pairs were meant to board in order , with the first pair being (0, 1), the second pair (2, 3), and so on , up to the last pair being (2n - 2, 2n - 1) ", "page_idx": 40}, {"type": "text", "text": "Your task is to help Noah figure out the minimum number of exchanges necessary to reposition the animals so that each pair is resting side by side. An exchange is the act of two animals , regardless of their species , standing up from their places and switching spots on the deck. >>> arrange_ark_pairs ([0,1,3,2]) ", "page_idx": 40}, {"type": "text", "text": ">>> arrange_ark_pairs ([0,3,2,1])   \n1   \n\"\"\" ", "page_idx": 40}, {"type": "text", "text": "Ground Truth Answer: Sampled Model: GPT3.5 Model Solution Steps: ", "page_idx": 40}, {"type": "text", "text": "from typing import List ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "ef arrange_ark_pairs (ark\\_deck: List[int]) -> int: swaps $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$ # Initialize a variable to count the number of swaps needed n = len(ark\\_deck) // 2 # Calculate the number of pairs based on the deck size # Iterate over the pairs and check if they are in order or not for i in range(n): if ark\\_deck $\\begin{array}{r l r}{\\left[2*\\dot{\\bf1}\\right]}&{{}==}&{2*\\dot{\\bf1}}\\end{array}$ and ark\\_deck $\\begin{array}{r l r}{\\left[2*\\dot{\\bf1}+1\\right]}&{{}==}&{2*\\dot{\\bf1}+\\bf1\\;;}\\end{array}$ : continue # If the pair is in order , move to the next pair else: # If the pair is not in order , find the position of the second member of the pair in the deck for j in range( $2*\\dot{1}+1$ , len(ark\\_deck)): if ark\\_deck $\\begin{array}{r l r}{\\left[\\mathbf{j}\\right]}&{{}==}&{2*\\mathbf{i}+\\mathbf{1}}\\end{array}$ : # Swap the positions of the two members of the pair ark\\_deck $\\left[2*\\dot{1}+1\\right]$ , ark\\_deck[j] $=$ ark\\_deck[j], ark\\ _deck $\\left[2*\\dot{1}+1\\right]$ swaps $+=~1$ # Increment the swap count by 1 break ", "page_idx": 40}, {"type": "text", "text": "return swaps ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "# Test cases ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Model Solution Rectified First Error Step: ", "page_idx": 41}, {"type": "table", "img_path": "GN2qbxZlni/tmp/700536a877ea441d73f3d43484d05078416fb5dc667469b3c9f2dc920ee7c267.jpg", "table_caption": [], "table_footnote": [], "page_idx": 41}, {"type": "text", "text": "Model Evaluation Result\u2014 ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Evaluation Result: ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Solution Analysis: ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "1. The function signature and the import statement are correct and set the right context for the problem.   \n2. Initializing \u2018swaps\u2018 to $^{\\ast}0\\,^{\\ast}$ is correct as it prepares to count the number of swaps necessary, thus contributing to solving the problem.   \n3. Calculating $\\mathbf{\\nabla}^{\\ast}\\mathbf{n}^{\\ast}$ as \u2018len(ark deck) $//\\ 2^{*}$ correctly determines the number of pairs, given the problem\u2019s constraints. 4. The \u2018for\u2018 loop starting with \u2018for i in range $(\\mathbf{n}):$ \u2018 sets up iteration over each pair correctly   \n. 5. The conditional \u2018if ark deck $[2^{*}\\mathrm{i}]\\ ==\\ 2^{*}\\mathrm{i}$ and ark dec $:[2^{*}\\mathrm{i}{+}1]\\;==\\;2^{*}\\mathrm{i}{+}1{:}$ \u2018 is incorrect. The logic assumes that the pairs being in the correct order is solely dependent on their indices being even and odd sequentially, which does not align with the problem statement regarding how pairs should be identified and arranged.   \n6. The \u2018else\u2018 block starting iteration from $^{\\ast}2^{\\ast}\\mathrm{i}+1^{\\ast}$ to look for the pair is a reasonable approach to find and swap the misplaced member of a pair.   \n7. The swapping logic inside the \u2018else\u2018 block and incrementing the \u2018swaps\u2018 counter by 1 if a swap is made is logically sound, 8. Returning \u2018swaps\u2018 correctly provides the solution to the problem based on the accumulated value. contributing to achieving the task.   \n9. The provided test cases confirm the solution\u2019s approach under specific conditions but might not sufficiently test all edge cases.   \nSolution Correctness: incorrect ", "page_idx": 41}, {"type": "text", "text": "First Error Step: $i f a r k\\_d e c k[2*i]\\;=\\;2*i a n d a r k\\_d e c k[2*i+1]\\;=\\;=\\;2*i+1\\;:$ ", "text_level": 1, "page_idx": 41}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "solution correctness: incorrect ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "error reason: This line incorrectly assumes that the correct order of pairs is determined by checking if the indices and values match such that both members of the pair have indices and values as even and odd sequentially (i.e., 2i and $^{2\\mathrm{i}+1}$ ). The problem statement describes that each pair is identified by their values being sequential (but not necessarily matching their positions sequentially as even or odd) because the identifiers themselves define the pairs (e.g., (0, 1), (2, 3), etc.), not their positions on the deck. A correct approach involves comparing each element to find its pair based on value, not position, considering the unique identifier nature of the animals. A possible correction involves removing or significantly modifying the condition to ensure it checks for pairs based on their values and not their positions in the deck: ", "page_idx": 41}, {"type": "text", "text": "- The solution should instead locate the partner of every animal by calculating the expected partner\u2019s identifier using an equation derived from its own identifier, considering the identifiers determine the pairs. This involves correcting the logic to find and swap the animals correctly, which might remove or alter this conditional check entirely in favor of an approach that considers the values of the identifiers rather than their positions in the array. ", "page_idx": 41}, {"type": "text", "text": "Evaluated Model: gpt-4-turbo Evaluation Raw Response: ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": ". Step-by-Step Reasoning: - The ground truth error is that the conditional check in the code incorrectly assumes that animals must be in sequential order by their identifiers on the deck (i.e., (0, 1) must be at positions 0 and 1, (2, 3) at positions 2 and 3, etc.). - The provided solution iterates over the elements of \u2018ark deck\u2018 in pairs and checks if the values at positions $^{\\ast}2^{\\ast}\\mathrm{i}^{\\ast}$ and $^{\\ast}2^{\\ast}\\mathrm{i}+1$ \u2018 are exactly $^{\\ast}2\\,^{\\ast}\\mathrm{i}\\,^{\\ast}$ and $^{\\;2^{*}\\mathrm{i}+1^{*}}$ . - However, the problem statement specifies that pairs only need to be side by side and does not mandate a specific order on the deck. This means that as long as each pair\u2019s identifiers are adjacent, the order is acceptable. - The error is in the condition $\\mathrm{\\nabla_{if}}$ ark deck $[2^{*}\\mathrm{i}]\\ ==\\ 2^{*}\\mathrm{i}$ and ark de $\\cdot\\mathbf{k}[2^{*}\\mathrm{i}{+}1]\\;==\\;2^{*}\\mathrm{i}{+}1{:}^{*}$ . This condition fails to check if the adjacent numbers are pairs regardless of their order on the deck. - The rectified step suggests an alternative approach that verifies if adjacent elements are part of the same pair by checking their values, not their positions. ", "page_idx": 41}, {"type": "text", "text": "2. Student Error Reason Analysis:   \n- The student correctly identifies the first error step in the solution as the condition that checks if the indices and values match in a specific sequential pattern.   \n- The student explains that the solution should check for pairs based on their values rather than their positions. This is aligned with the ground truth that the pairs only need to be adjacent, not in a specific sequential position on the deck. - The student\u2019s proposed correction to remove or modify the condition to ensure it checks for adjacent numbers being pairs based on their identifiers is also correct. This implies a logic change that focuses on the value of the animal identifiers rather than their positions in the array. ", "page_idx": 41}, {"type": "text", "text": "3. Final Decision: Correct ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "- The ground truth error is that the conditional check in the code incorrectly assumes that animals must be in sequential order by their identifiers on the deck (i.e., (0, 1) must be at positions 0 and $^{1}$ , (2, 3) at positions 2 and 3, etc.).   \n- The provided solution iterates over the elements of \u2018ark deck\u2018 in pairs and checks if the values at positions $^{\\ast}2^{\\ast}\\mathrm{i}^{\\ast}$ \u2018 and $^{\\ast}2^{\\ast}\\mathrm{i}+1$ \u2018 are exactly $^{\\ast}2\\,^{\\ast}\\mathrm{i}\\,^{\\ast}$ and $^{\\;2^{*}\\mathrm{i}+1^{*}}$ .   \n- However, the problem statement specifies that pairs only need to be side by side and does not mandate a specific order on the deck. This means that as long as each pair\u2019s identifiers are adjacent, the order is acceptable.   \n- The error is in the condition \u2018if ark deck $\\cdot[2^{*}\\mathrm{i}]\\ ==\\ 2^{*}\\mathrm{i}$ and ark d $\\mathrm{{\\bf~\\lambda}}^{\\mathrm{{\\bf~c}}\\mathrm{{\\bf~k}}\\left[2^{*}\\mathrm{i}+1\\right]}\\;==\\;2^{*}\\mathrm{i}\\!+\\!1\\!:^{\\ast}$ . This condition fails to check if the adjacent numbers are pairs regardless of their order on the deck.   \n- The rectified step suggests an alternative approach that verifies if adjacent elements are part of the same pair by checking their values, not their positions. ", "page_idx": 41}, {"type": "text", "text": "Error Reason Analysis: ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "- The student correctly identifies the first error step in the solution as the condition that checks if the indices and values match in a specific sequential pattern.   \n- The student explains that the solution should check for pairs based on their values rather than their positions. This is aligned with the ground truth that the pairs only need to be adjacent, not in a specific sequential position on the deck. - The student\u2019s proposed correction to remove or modify the condition to ensure it checks for adjacent numbers being pairs based on their identifiers is also correct. This implies a logic change that focuses on the value of the animal identifiers rather than their positions in the array. ", "page_idx": 41}, {"type": "text", "text": "Error Reason Correctness: Correct ", "page_idx": 41}, {"type": "text", "text": "Figure E.7-2. A success case in the coding subject. The model evaluates the error part correctly, and its error reason annotation aligns with human annotations. ", "page_idx": 41}, {"type": "text", "text": "G Computational Resources Used ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "In this paper, all experiments are either performed on open-source models with local inference or closed-source models with API calls. For local inference, we are using A800 machines with 8 GPUs to run the inferences. The total evaluation time on our 6k benchmark on the 70B language models typically takes around 2 hours using fast inference libraries such as vllm. For smaller language models such as Phi-3 or Gemma, the compute time is smaller. ", "page_idx": 42}, {"type": "text", "text": "H Annotation Guidelines ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Below we provide the original annotation guidelines distributed to annotators of distinctive subjects included in the MR-Ben benchmark: math, biology, physics, chemistry, logic, medicine, and coding. The guidelines serve as the primary training material and instructions for annotators to complete the labeling tasks, specified with detailed descriptions, requirements, and standards. ", "page_idx": 42}, {"type": "text", "text": "Annotation Guideline: Math Subject ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "1 Background ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "With the increasingly enhanced capabilities of large language models such as ChatGPT, existing models can break down complex problems and solve them step by step. However, while their solutions may often be seemingly correct, they can contain errors in understanding, calculation, and reasoning logic. In this annotation task, annotators will evaluate model-generated step-by-step solutions to questions in the mathematics subject (including university-level and high-school-level mathematics), and determine whether the model has obtained the correct answer based on the correct understanding and reasoning logic. ", "page_idx": 43}, {"type": "text", "text": "2 Annotation Task ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Given a question and a step-by-step solution generated by the model, the annotator needs to read the question and model-generated solutions carefully. There will be different solutions from multiple models for one question, and they need to be annotated independently. Each annotation task is divided into four sub-tasks. ", "page_idx": 43}, {"type": "text", "text": "2.1 Sub-task 1 ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "The first sub-task is to decide whether the model-generated step-by-step solution is correct. Even if the model\u2019s final answer matches the ground-truth answer, the model may arrive at the correct answer through incorrect understanding and reasoning. Therefore, regardless of whether the final answers match the ground-truth choice, annotators should read through each model solution carefully and complete all subtasks based on prudent judgments. ", "page_idx": 43}, {"type": "text", "text": "2.2 Sub-task 2 ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "The second sub-task is to identify the first incorrect step in the model-generated solution if the solution is incorrect. Specifically, each step can be interpreted as correct, neutral, or incorrect. ", "page_idx": 43}, {"type": "text", "text": "\u2022 Correct means both the calculation and understanding are correct, and the step is essential for reaching the correct result.   \n\u2022 Neutral refers to the current step possibly being a background statement about the question, a factual/formula description, or an exploratory step generated by the model. There are no obvious errors in this step, but whether this step leads to the final correct answer is not obvious.   \n\u2022 Incorrect step refers to obvious errors in calculation, understanding, or other possible errors in reasoning, regardless of whether this error affects the final calculation result. ", "page_idx": 43}, {"type": "text", "text": "The third sub-task is to describe the reason for the error in the first incorrect step. Annotators should carefully analyze the possible reasons for the error in the incorrect step and provide a rational analysis. Please try to incorporate the logic of the model\u2019s solution and analyze the reasons for this error from ", "page_idx": 43}, {"type": "text", "text": "2.4 Sub-task 4 ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "The fourth and final sub-task is to rewrite the first incorrect step. Based on the error reason you provided, correct the incorrect step that you identified. The rewritten step should naturally integrate into the original context of the model solution, with only the incorrect part modified when necessary. ", "page_idx": 44}, {"type": "text", "text": "3 Annotation Data Format ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "At the end of this guideline, Figure 1 shows an annotation example of one model-generated solution for a high-school mathematics question, which includes the following items: ", "page_idx": 44}, {"type": "text", "text": "Question, Options, Model_Solution_Steps and Ground_Truth_Answer: They are what annotators should carefully read and analyze. ", "page_idx": 44}, {"type": "text", "text": "Model_Solution_Correctness is the first sub-task item to be annotated. It is defined as whether the model solution is completely correct for all steps. Please only answer \"Yes\" or \"No\" in this column. Please do not fill in other variants such as correct, incorrect, positive, negative, etc. ", "page_idx": 44}, {"type": "text", "text": "Model_Solution_First_Error_Step_Num is the second sub-task item to be annotated. It is defined as the first incorrect step specified in the model solution. If the annotation of the previous item is \"No\", please enter the numerical step number with quotation marks here, such as \"1\", \"2\", etc.; If the result of the first item annotation is \"Yes\", fill in \"None\" here. Please note: ", "page_idx": 44}, {"type": "text", "text": "1. Do not fill in other variants such as \"one\", \"two\", or \"none\", \"no\", etc.   \n2. Step numbers should be written in double quotation marks; do not just write numbers. ", "page_idx": 44}, {"type": "text", "text": "Model_Solution_Error_Reason is the third sub-task item to be annotated. Please provide a detailed error analysis for the identified first incorrect step here. For example, whether the model refers to incorrect factual knowledge / correct facts but incorrect comprehension, calculation / incorrect contextual logic links / improper conditions or assumptions, etc. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. ", "page_idx": 44}, {"type": "text", "text": "Rectified_Model_Solution_First_Error_Step is the fourth and last sub-task item to be annotated. Please correct the incorrect step based on the error reason you provided. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. Note that we are not responsible for the consequential steps following the first incorrect step; we only need to correct the identified first error here. ", "page_idx": 44}, {"type": "text", "text": "4 Annotation Regulations & Quality Control ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "All questions are to be annotated according to the format requirements. If issues arise with the annotation format from sampling inspection, annotators should make modifications promptly. ", "page_idx": 44}, {"type": "text", "text": "If the annotations of error reasons and step corrections are too brief, perfunctory, or unclear, reannotation is required to ensure the annotation quality. For each batch of submitted files, if any of the following occurred, all questions of the same batch will be sent back for re-examination and re-annotation: ", "page_idx": 44}, {"type": "text", "text": "1. the annotation error rate is higher than $5\\%$ after random sampling, or   \n2. any of the requirements in this guideline are found violated. ", "page_idx": 44}, {"type": "text", "text": "5 Additional Notes for Math Subject ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "5.1 Look-Up Source ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "The mathematics subject of this task includes annotating questions in the difficulty level of American university and high school mathematics. When encountering unfamiliar or unclear mathematical ", "page_idx": 44}, {"type": "text", "text": "5.2 Math Expressions Format ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "The writing of mathematical formulas and special symbols is in the LaTeX language. ", "page_idx": 45}, {"type": "text", "text": "1. For convenience in question interpretation, annotators can use website tools such as https: //www.latexlive.com/ to convert and view the content enclosed in the symbols in the question. Since latexlive.com uses a single backslash instead of a double backslash, please change the two backslashes (\\\\) inside the mathematical formula in the question (e.g., $\\mathbb{S}\\backslash\\mathrm{Urac}\\{23\\}\\{3\\}\\mathbb{S})$ to a single backslash (\\\\) (e.g., $\\mathbb{S}\\mathrm{trac}\\{23\\}\\{3\\}\\mathbb{S})$ when previewing the formula.   \n2. Correspondingly, when filling in the annotations, annotators need to convert and write the mathematical formulas: please change the single backslash (\\) back to a double backslash (\\\\) and enclose the mathematical formula with. Examples of specific filling can be seen in the sample question annotation. ", "page_idx": 45}, {"type": "text", "text": "6 Common Questions ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Q1: When a step repeats the incorrect option should I mark it as the first incorrect step? ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "No, if a step only describes what an incorrect option is stating or repeats the exact words of the incorrect option without analysis, it does not constitute an incorrect step. But if the step includes wrong analysis/judgment about the incorrect option, then it is considered incorrect. ", "page_idx": 45}, {"type": "text", "text": "Q2: If previous steps so far have only stated relevant facts without specific analysis, how should I handle these steps? ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Similarly, if the steps focus solely on factual statements about the options or related background descriptions, these steps should be understood as neutral steps unless these steps contain incorrect understanding, incorrect facts, etc. The first incorrect step should be the one that involves incorrect analysis or reasoning. ", "page_idx": 45}, {"type": "text", "text": "Q3: What should I do if I encounter difficulty comprehending the question options or model solutions? ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "When encountering unfamiliar terms, look up textbook sources or use search engines to find reliable explanations first. Contact the annotation management team whenever in doubt. ", "page_idx": 45}, {"type": "text", "text": "Q4: The model\u2019s answer gives two answers, one of which is correct. How should I decide? ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Annotate it as \"No.\" Then follow the standard process to annotate the incorrect step, error reason, and the correction step. ", "page_idx": 45}, {"type": "text", "text": "Q5: It\u2019s inconvenient to read the JSON file without line breaks. ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "If you are using platforms like Visual Studio Code to annotate files in JSON format, you can install plugins like \u2019json editor\u2019 to assist in reading. However, take caution against modifying any content other than the required subtasks and do not manually change the data structure. ", "page_idx": 45}, {"type": "text", "text": "7 Annotation Example ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Figure 1 below is a model solution of a sample question to be annotated; Figure 2 shows an example annotation for the same model solution. ", "page_idx": 45}, {"type": "text", "text": "\"Question_UUID\": \"ef1e7d22-346e-4383-92b6-0cca25834f7d\", \"Subject\": \"hs_math\", \"Question\": \"Given that \\$a(a+2b) = \\\\frac{104}3\\$, \\$b(b+2c) = \\\\frac{7}{9}\\$, and \\$c(c+2a) = -7\\$, find \\$|a+b+c|\\$.\", \"Options\": \"A: \\\\frac{23}{3} \\nB: \\\\frac{5}{3} \\nC: \\\\frac{16}{3} \\nD: \\\\frac{10}{3} \", \"Ground_Truth_Analysis\": \"\", \"Ground_Truth_Answer\": \"C\", \"Model_Solution_Steps\": [ \"Step 1: Express a, b, and c in terms of the other variables using the given equations.\", \"From \\$a(a+2b) = \\\\frac{104}{3}\\$, we get \\$a = \\\\frac{104}{3(a+2b)}\\$.\", \"From \\$b(b+2c) $=$ \\\\frac{7}{9}\\$, we get \\$b = \\\\frac{7}{9(b+2c)}\\$.\", \"From \\$c(c+2a) = -7\\$, we get \\$c = -\\\\frac{7}{c+2a}\\$.\", \"Step 2: Substitute the expressions for a, b, and c found in Step 1 into the equation for c (since it has the fewest terms).\", \"Substituting a into the equation for c gives:\", \"\\$c = -\\\\frac{7}{c + 2(\\\\frac{104}{3(a+2b)})}\\$.\", \"Step 3: Simplify the equation for c from Step 2.\", \"First, clear the fraction by multiplying both sides of the equation by the denominator:\", \"\\$-7(c+2(\\\\frac{104}{3(a+2b)})) = c(c + 2(\\\\frac{104}{3(a+2b)}))\\$.\", \"Expanding and simplifying further, we obtain:\", \"\\$-\\\\frac{21c}{3} - \\\\frac{1428}{9(a+2b) ${\\begin{array}{r l r}{\\}}&{{}=}&{\\mathbf{c}^{\\land}2\\quad+}\\end{array}}$ \\\\frac{208c}{3(a+2b)}\\$.\", \"Step 4: Express c in terms of a and b by solving the quadratic equation found in Step 3.\", \"To do this, first rearrange the equation to the standard quadratic form:\", \"\\$c^2 + \\\\left(\\\\frac{208}{(3(a+2b)} + \\\\frac{21}{3}\\\\right)c + \\\\frac{1428}{9(a+2b)} = 0\\$.\", \"Then, solve for c using the quadratic formula.\", \"Step 5: Substitute the expression for a found in Step 1 into the equation for c from Step 4, then solve for $_\\subset$ in terms of b.\", \"Recall that \\$a = \\\\frac{104}{3(a+2b)}\\$. Thus, after some simplification, we obtain:\", \"\\$c^2 + \\\\left(\\\\frac{208}{(3(\\\\frac{104}{3a}+2b)} + \\\\frac{21}{3}\\\\right)c + \\\\frac{1428}{9(\\\\frac{104}{3a}+2b)} = 0\\$.\", \"Solving for c in terms of b yields two possible solutions. Choose one of them and continue the analysis.\", \"Step 6: Substitute the expressions for a and c found in Steps 1 and 5, respectively, into the equation for b from Step 1, then   \nsolve for b.\", \"Recall that \\$b = \\\\frac{7}{9(b+2c)}\\$. Substitute the expressions for a and c from Steps 1 and 5 into this equation, then solve   \nfor b.\",\"Step 7: Finally, substitute the solutions for a, b, and c found in Steps 1, 6, and 5 (respectively) into the expression   \n\\$|a+b+c|\\$.\", \"Evaluate the absolute value of the sum of a, b, and c using the found solutions from the previous steps.\", \"Step 8: Compare the result from Step 7 with the given Choice_A, Choice_B, Choice_C, and Choice_D to find the matching option.\", \"The correct choice should be equal to the value obtained from the previous step.\", \"Solution: Choice_A\" ], \"Sampled_Model\": \"mistral-medium\", \"Model_Solution_Correctness\": \"TBD\", \"Model_Solution_First_Error_Step_Num\": \"TBD\", \"Model_Solution_Error_Reason\": \"TBD\", \"Rectified_Model_Solution_First_Error_Step\": \"TBD\" ", "page_idx": 46}, {"type": "text", "text": "Figure 1: A task example of a model-generated solution for a high-school mathematics question (to be annotated). ", "page_idx": 46}, {"type": "text", "text": "", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "\"Model_Solution_Correctness\": \"No\", \"Model_Solution_First_Error_Step_Num\": \"3\", \"Model_Solution_Error_Reason\": \"Step 3 has an elimination arithmetic error when eliminating fractions by multiplying the denominator: eliminating fractions by multiplying the denominator \\$-7(c + 2(\\\\frac{104}{3(a+2b)}\uff09) $=$ c( $=+2$ (\\frac{104}{3(a+2b)}\uff09\uff09) $\\mathfrak{S}$ yields \\$ $-7=\\circ(\\circ+2$ (\\\\frac{104} {3(a+2b)}))s\uff0c not \\$-7(c $\\dots+\\dots$ \uff08\\\\frac{104}{3(a+2b)}\uff09) $=$ c(c $+2$ (\\frac{104}{3(a+2b)})))\\$.\", \"Rectified_Model_Solution_First_Error_Step\": \"Simplify the \\$c\\$ equation in step 2. First, eliminate simplifying further, we get: \\$- = c^2 + \\\\\\fr $\\mathsf{S}\\!-\\!\\top\\!\\!\\!\\!\\!=\\!\\!\\!\\!\\!\\!\\!\\!\\subset\\!\\!\\!\\!\\!\\!\\!\\!\\!(\\,\\!\\!\\!\\!\\!\\!\\!\\!\\mathrm{c}\\!\\!\\!\\!\\!\\!\\!\\!\\!_{\\!}\\!\\!\\!\\!\\!\\!\\!\\!-\\!\\!\\!\\!\\!\\!\\!\\!\\!\\gamma\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!)\\!\\!\\!\\!\\!\\!\\!\\!\\!=\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\subset\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! $ (\\\\frac(104}{3(a+2b)}))\\$. Expanding and simplifying further, we get: $\\mathbb{S}-\\mathbf{\\Omega}=\\mathbf{\\Omega}\\subset\\{\\hat{\\mathbf{\\Omega}}^{\\wedge}\\hat{\\mathbf{\\Omega}}^{\\bigstar}+\\mathbf{\\Omega}\\}$ \\\\\\frac{208c}{3(a+2b)}\\$.\" ", "page_idx": 46}, {"type": "text", "text": "Figure 2: An example of standard annotation (with the previous items omitted to save space). ", "page_idx": 46}, {"type": "text", "text": "Annotation Guideline: Physics Subject ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "1 Background ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "With the increasingly enhanced capabilities of large language models such as ChatGPT, existing models can break down complex problems and solve them step by step. However, while their solutions may often be seemingly correct, they can contain errors in understanding, calculation, and reasoning logic. In this annotation task, annotators will evaluate model-generated step-by-step solutions to questions in the physics subject (including university-level and high-school-level physics), and determine whether the model has obtained the correct answer based on the correct understanding and reasoning logic. ", "page_idx": 47}, {"type": "text", "text": "2 Annotation Task ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Given a question and a step-by-step solution generated by the model, the annotator needs to read the question and model-generated solutions carefully. There will be different solutions from multiple models for one question, and they need to be annotated independently. Each annotation task is divided into four sub-tasks. ", "page_idx": 47}, {"type": "text", "text": "2.1 Sub-task 1 ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "The first sub-task is to decide whether the model-generated step-by-step solution is correct. Even if the model\u2019s final answer matches the ground-truth answer, the model may arrive at the correct answer through incorrect understanding and reasoning. Therefore, regardless of whether the final answers match the ground-truth choice, annotators should read through each model solution carefully and complete all subtasks based on prudent judgments. ", "page_idx": 47}, {"type": "text", "text": "2.2 Sub-task 2 ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "The second sub-task is to identify the first incorrect step in the model-generated solution if the solution is incorrect. Specifically, each step can be interpreted as correct, neutral, or incorrect. ", "page_idx": 47}, {"type": "text", "text": "\u2022 Correct means both the calculation and understanding are correct, and the step is essential for reaching the correct result.   \n\u2022 Neutral refers to the current step possibly being a background statement about the question, a factual/formula description, or an exploratory step generated by the model. There are no obvious errors in this step, but whether this step leads to the final correct answer is not obvious.   \n\u2022 Incorrect step refers to obvious errors in calculation, understanding, or other possible errors in reasoning, regardless of whether this error affects the final calculation result. ", "page_idx": 47}, {"type": "text", "text": "The third sub-task is to describe the reason for the error in the first incorrect step. Annotators should carefully analyze the possible reasons for the error in the incorrect step and provide a rational analysis. Please try to incorporate the logic of the model\u2019s solution and analyze the reasons for this error from ", "page_idx": 47}, {"type": "text", "text": "2.4 Sub-task 4 ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "The fourth and final sub-task is to rewrite the first incorrect step. Based on the error reason you provided, correct the incorrect step that you identified. The rewritten step should naturally integrate into the original context of the model solution, with only the incorrect part modified when necessary. ", "page_idx": 48}, {"type": "text", "text": "3 Annotation Data Format ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "At the end of this guideline, Figure 1 shows an annotation example of one model-generated solution for a physics question, which includes the following items: ", "page_idx": 48}, {"type": "text", "text": "Question, Options, Model_Solution_Steps and Ground_Truth_Answer: They are what annotators should carefully read and analyze. ", "page_idx": 48}, {"type": "text", "text": "Model_Solution_Correctness is the first sub-task item to be annotated. It is defined as whether the model solution is completely correct for all steps. Please only answer \"Yes\" or \"No\" in this column. Please do not fill in other variants such as correct, incorrect, positive, negative, etc. ", "page_idx": 48}, {"type": "text", "text": "Model_Solution_First_Error_Step_Num is the second sub-task item to be annotated. It is defined as the first incorrect step specified in the model solution. If the annotation of the previous item is \"No\", please enter the numerical step number with quotation marks here, such as \"1\", \"2\", etc.; If the result of the first item annotation is \"Yes\", fill in \"None\" here. Please note: ", "page_idx": 48}, {"type": "text", "text": "1. Do not fill in other variants such as \"one\", \"two\", or \"none\", \"no\", etc.   \n2. Step numbers should be written in double quotation marks; do not just write numbers. ", "page_idx": 48}, {"type": "text", "text": "Model_Solution_Error_Reason is the third sub-task item to be annotated. Please provide a detailed error analysis for the identified first incorrect step here. For example, whether the model refers to incorrect factual knowledge / correct facts but incorrect comprehension, calculation / incorrect contextual logic links / improper conditions or assumptions, etc. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. ", "page_idx": 48}, {"type": "text", "text": "Rectified_Model_Solution_First_Error_Step is the fourth and last sub-task item to be annotated. Please correct the incorrect step based on the error reason you provided. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. Note that we are not responsible for the consequential steps following the first incorrect step; we only need to correct the identified first error here. ", "page_idx": 48}, {"type": "text", "text": "4 Annotation Regulations & Quality Control ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "All questions are to be annotated according to the format requirements. If issues arise with the annotation format from sampling inspection, annotators should make modifications promptly. ", "page_idx": 48}, {"type": "text", "text": "If the annotations of error reasons and step corrections are too brief, perfunctory, or unclear, reannotation is required to ensure the annotation quality. For each batch of submitted files, if any of the following occurred, all questions of the same batch will be sent back for re-examination and re-annotation: ", "page_idx": 48}, {"type": "text", "text": "1. the annotation error rate is higher than $5\\%$ after random sampling, or   \n2. any of the requirements in this guideline are found violated. ", "page_idx": 48}, {"type": "text", "text": "5 Additional Notes for Physics Subjects ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "5.1 Look-Up Source ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "The physics subject of this task includes annotating questions in the difficulty level of American university and high school physics. When encountering unfamiliar or unclear terms and concepts, ", "page_idx": 48}, {"type": "text", "text": "5.2 Physics Expressions Format ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "The writing of physics formulas and special symbols is in the LaTeX language. ", "page_idx": 49}, {"type": "text", "text": "1. For convenience in question interpretation, annotators can use website tools such as https://www.latexlive.com/ to convert and view the content enclosed in the symbols in the question. Since latexlive.com uses a single backslash instead of a double backslash, please change the two backslashes (\\\\) inside the physics formula in the question (e.g., ${\\mathfrak{H}}{\\mathfrak{W}}{\\mathfrak{r a c}}\\{23\\}\\{3\\}{\\mathfrak{F}})$ to a single backslash (\\\\) (e.g., ${\\mathfrak{S}}\\mathrm{trac}\\{23\\}\\{3\\}{\\mathfrak{S}})$ when previewing the formula.   \n2. Correspondingly, when filling in the annotations, annotators need to convert and write the physics formulas: please change the single backslash (\\) back to a double backslash (\\\\) and enclose the physics formula with. Examples of specific filling can be seen in the sample question annotation. ", "page_idx": 49}, {"type": "text", "text": "6 Common Questions ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Q1: When a step repeats the incorrect option should I mark it as the first incorrect step? ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "No, if a step only describes what an incorrect option is stating or repeats the exact words of the incorrect option without analysis, it does not constitute an incorrect step. But if the step includes wrong analysis/judgment about the incorrect option, then it is considered incorrect. ", "page_idx": 49}, {"type": "text", "text": "Q2: If previous steps so far have only stated relevant facts without specific analysis, how should I handle these steps? ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Similarly, if the steps focus solely on factual statements about the options or related background descriptions, these steps should be understood as neutral steps unless these steps contain incorrect understanding, incorrect facts, etc. The first incorrect step should be the one that involves incorrect analysis or reasoning. ", "page_idx": 49}, {"type": "text", "text": "Q3: What should I do if I encounter difficulty comprehending the question options or model solutions? ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "When encountering unfamiliar terms, look up textbook sources or use search engines to find reliable explanations first. Contact the annotation management team whenever in doubt. ", "page_idx": 49}, {"type": "text", "text": "Q4: The model\u2019s answer gives two answers, one of which is correct. How should I decide? ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Annotate it as \"No.\" Then follow the standard process to annotate the incorrect step, error reason, and the correction step. ", "page_idx": 49}, {"type": "text", "text": "Q5: It\u2019s inconvenient to read the JSON file without line breaks. ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "If you are using platforms like Visual Studio Code to annotate files in JSON format, you can install plugins like \u2018json editor\u2019 to assist in reading. However, take caution against modifying any content other than the required subtasks and do not manually change the data structure. ", "page_idx": 49}, {"type": "text", "text": "7 Annotation Example ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Figure 1 below is a model solution of a sample question to be annotated; Figure 2 shows an example annotation for the same model solution. ", "page_idx": 49}, {"type": "text", "text": "\"Subject\": \"high_school_physics\",   \n\"Question\": \"A body moving in th econd, the body has a constant speed of $^\\mathrm{x}$ meters per second. At t = 1 second, the body is $t=0$ a co $t=~1$   \nacceleration of 6 meters per second squared in the negative x direction $t=~1$ position x of the body at t = 11 seconds   \nacceleration of 6 meters per second squared in the negative $^\\mathrm{x}$ direction. The position $^\\mathrm{x}$ of the body at $\\mathrm{~t~}=~11$ seconds   \n\"Op   \n\"Ground_Truth_Analysis\": \"\",   \n\"Ground_Truth_Answer\": \"C\",   \n\"Ground_Truth_Answer_Modifi   \n\"Sampled_Model\": \"mistral-medium\",   \n\"Model_Solution_Steps\": [   \n\"Step 1: During the tim rection. The displacement during this time is (24 m/s)\\*(1 s) = 24 m.\",   \ndirection. The displacement during this time $\\begin{array}{r l r}{\\mathrm{~i~s~}}&{{}(24\\ \\mathrm{~m/s})\\star(1\\ \\mathrm{~s})}&{=}&{24\\ \\mathrm{~m}\\,.^{\\ast}}\\end{array}$ \uff0c p\u00a0l\"iSctaetpi o2n:  oAft $t=-1$ s tsaencto nadc,c etlheer avteiloonc iotfy  6b emc/osm\u00b2e si nz etrhoe  anse gtahtei vbeo dxy  dmiormeecnttiaorni.l\"y, comes to rest due to the instantaneous   \napplication of a constant acceleration of 6 m/s? in the negative $^\\mathrm{x}$ direction.\", \", stant acceleration in the negative x direction. $t=~1$ the ki $t_{0}\\pm\\Delta=11$ ation x = x\u2080 + v\u2080t + \u00bdat\u00b2 with x\u2080 = 0, v\u2080 =   \n0, a = -6 m/s\u00b2, and t = 10 seconds (s $\\times$ e 11 - 1 = 10), we find x = -300 m.\", $\\begin{array}{r l r}{{\\bf x}}&{{}\\equiv}&{{\\bf x}\\,\\boldsymbol\\Theta\\,\\,\\,\\,\\,+}\\end{array}$ vet + hat2 with x\u03b8 = 0\uff0c ve =   \n\"\", $\\t=\\ 10$ seconds (since $11\\ -\\ 1=\\ 10;$ \uff0cwe find $\\mathrm{~\\boldmath~x~}=\\mathrm{~\\boldmath~-~}300\\,\\mathrm{~\\boldmath~m~}.\\,^{\\ast}$ \uff0c !, th displacements are in the same direction. Thus, the final position x is (24 m) + (-300 m) = -276 m.\",   \nboth displacements are in the same direction. Thus, the final position x is (24 m) + (-300 m) = -276 m.\", !, vided choices, there seems to be a mistake or error in the question or the available choices. We cannot determine   \nthe correct solution based on the given information.\",   \nthe correct solution based on the given information.\", ,. \"Solution: Unable to determine a solution using the given choices.\" \"M \"Model_Solution_First_Error_Step\": \"   \n\"Model_Solution_First_Error_Step\": \"TBD\",   \n\"Model_Solution_Rectified_First_Error   \n\"Model_solution_Rectified_ First _Error_Step\": \"TBD\"   \n1 ", "page_idx": 50}, {"type": "text", "text": "Figure 1: A task example of a model-generated solution for a high-school-level physics question (to be annotated). ", "page_idx": 50}, {"type": "text", "text": "\"Model_Solution_Correctness\": \"incorrect\", \"Model_Solution_Error_Reason\": \"Accordi uantity that describes how quickly the velocity of an object changes. Combined with the problem statement that \\\"the object is given a constant acceleration of 6 meters per second squared in the negative x direction,\\\" it is known that this acceleration only causes the velocity to change gradually and does not make the velocity zero or bring the object to an instant stop.\\n\" \"Model_Solution_Rectified_First_Error_Step\": \"Step 2: At t = 1 -6 meters per second squared applied instantaneously in $t\\ =\\ 1$ gative x direction, the object's velocity first decreases gradually along the positive x direction until it red $_\\mathrm{x}$ es to zero, then increases in the negative x direction.\\n\" $_\\mathrm{x}$ direction until it reduces to zero, then increases in the negative $\\mathrm{_{x}}$ direction.\\n\" ", "page_idx": 50}, {"type": "text", "text": "Figure 2: An example of standard annotation (with the previous items omitted to save space). ", "page_idx": 50}, {"type": "text", "text": "Annotation Guideline: Biology Subject ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "1 Background ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "With the increasingly enhanced capabilities of large language models such as ChatGPT, existing models can break down complex problems and solve them step by step. However, while their solutions may often be seemingly correct, they can contain errors in understanding, calculation, and reasoning logic. In this annotation task, annotators will evaluate model-generated step-by-step solutions to questions in the biology subject (including university-level and high-school-level biology), and determine whether the model has obtained the correct answer based on the correct understanding and reasoning logic. ", "page_idx": 51}, {"type": "text", "text": "2 Annotation Task ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Given a question and a step-by-step solution generated by the model, the annotator needs to read the question and model-generated solutions carefully. There will be different solutions from multiple models for one question, and they need to be annotated independently. Each annotation task is divided into four sub-tasks. ", "page_idx": 51}, {"type": "text", "text": "2.1 Sub-task 1 ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "The first sub-task is to decide whether the model-generated step-by-step solution is correct. Even if the model\u2019s final answer matches the ground-truth answer, the model may arrive at the correct answer through incorrect understanding and reasoning. Therefore, regardless of whether the final answers match the ground-truth choice, annotators should read through each model solution carefully and complete all subtasks based on prudent judgments. ", "page_idx": 51}, {"type": "text", "text": "2.2 Sub-task 2 ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "The second sub-task is to identify the first incorrect step in the model-generated solution if the solution is incorrect. Specifically, each step can be interpreted as correct, neutral, or incorrect. ", "page_idx": 51}, {"type": "text", "text": "\u2022 Correct means both the calculation and understanding are correct, and the step is essential for reaching the correct result.   \n\u2022 Neutral refers to the current step possibly being a background statement about the question, a factual/formula description, or an exploratory step generated by the model. There are no obvious errors in this step, but whether this step leads to the final correct answer is not obvious.   \n\u2022 Incorrect step refers to obvious errors in calculation, understanding, or other possible errors in reasoning, regardless of whether this error affects the final calculation result. ", "page_idx": 51}, {"type": "text", "text": "The third sub-task is to describe the reason for the error in the first incorrect step. Annotators should carefully analyze the possible reasons for the error in the incorrect step and provide a rational analysis. Please try to incorporate the logic of the model\u2019s solution and analyze the reasons for this error from ", "page_idx": 51}, {"type": "text", "text": "2.4 Sub-task 4 ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "The fourth and final sub-task is to rewrite the first incorrect step. Based on the error reason you provided, correct the incorrect step that you identified. The rewritten step should naturally integrate into the original context of the model solution, with only the incorrect part modified when necessary. ", "page_idx": 52}, {"type": "text", "text": "3 Annotation Data Format ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "At the end of this guideline, Figure 1 shows an annotation example of one model-generated solution for a high-school biology question, which includes the following items: ", "page_idx": 52}, {"type": "text", "text": "Question, Options, Model_Solution_Steps and Ground_Truth_Answer: They are what annotators should carefully read and analyze. ", "page_idx": 52}, {"type": "text", "text": "Model_Solution_Correctness is the first sub-task item to be annotated. It is defined as whether the model solution is completely correct for all steps. Please only answer \"Yes\" or \"No\" in this column. Please do not fill in other variants such as correct, incorrect, positive, negative, etc. ", "page_idx": 52}, {"type": "text", "text": "Model_Solution_First_Error_Step_Num is the second sub-task item to be annotated. It is defined as the first incorrect step specified in the model solution. If the annotation of the previous item is \"No\", please enter the numerical step number with quotation marks here, such as \"1\", \"2\", etc.; If the result of the first item annotation is \"Yes\", fill in \"None\" here. Please note: ", "page_idx": 52}, {"type": "text", "text": "1. Do not fill in other variants such as \"one\", \"two\", or \"none\", \"no\", etc.   \n2. Step numbers should be written in double quotation marks; do not just write numbers. ", "page_idx": 52}, {"type": "text", "text": "Model_Solution_Error_Reason is the third sub-task item to be annotated. Please provide a detailed error analysis for the identified first incorrect step here. For example, whether the model refers to incorrect factual knowledge / correct facts but incorrect comprehension, calculation / incorrect contextual logic links / improper conditions or assumptions, etc. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. ", "page_idx": 52}, {"type": "text", "text": "Rectified_Model_Solution_First_Error_Step is the fourth and last sub-task item to be annotated. Please correct the incorrect step based on the error reason you provided. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. Note that we are not responsible for the consequential steps following the first incorrect step; we only need to correct the identified first error here. ", "page_idx": 52}, {"type": "text", "text": "4 Annotation Regulations & Quality Control ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "All questions are to be annotated according to the format requirements. If issues arise with the annotation format from sampling inspection, annotators should make modifications promptly. ", "page_idx": 52}, {"type": "text", "text": "If the annotations of error reasons and step corrections are too brief, perfunctory, or unclear, reannotation is required to ensure the annotation quality. For each batch of submitted files, if any of the following occurred, all questions of the same batch will be sent back for re-examination and re-annotation: ", "page_idx": 52}, {"type": "text", "text": "1. the annotation error rate is higher than $5\\%$ after random sampling, or   \n2. any of the requirements in this guideline are found violated. ", "page_idx": 52}, {"type": "text", "text": "5 Additional Notes for Biology Subject ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "5.1 Look-Up Source ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "The biology subject of this task includes annotating questions in the difficulty level of American university and high school biology. When encountering unfamiliar or unclear terms and concepts, ", "page_idx": 52}, {"type": "text", "text": "6 Common Questions ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Q1: When a step repeats the incorrect option should I mark it as the first incorrect step? ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "No, if a step only describes what an incorrect option is stating or repeats the exact words of the incorrect option without analysis, it does not constitute an incorrect step. But if the step includes wrong analysis/judgment about the incorrect option, then it is considered incorrect. ", "page_idx": 53}, {"type": "text", "text": "Q2: If previous steps so far have only stated relevant facts without specific analysis, how should I handle these steps? ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Similarly, if the steps focus solely on factual statements about the options or related background descriptions, these steps should be understood as neutral steps unless these steps contain incorrect understanding, incorrect facts, etc. The first incorrect step should be the one that involves incorrect analysis or reasoning. ", "page_idx": 53}, {"type": "text", "text": "Q3: What should I do if I encounter difficulty comprehending the question options or model solutions? ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "When encountering unfamiliar terms, look up textbook sources or use search engines to find reliable explanations first. Contact the annotation management team whenever in doubt. ", "page_idx": 53}, {"type": "text", "text": "Q4: The model\u2019s answer gives two answers, one of which is correct. How should I decide? ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Annotate it as \"No.\" Then follow the standard process to annotate the incorrect step, error reason, and the correction step. ", "page_idx": 53}, {"type": "text", "text": "Q5: It\u2019s inconvenient to read the JSON file without line breaks. ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "If you are using platforms like Visual Studio Code to annotate files in JSON format, you can install plugins like \u2019json editor\u2019 to assist in reading. However, take caution against modifying any content other than the required subtasks and do not manually change the data structure. ", "page_idx": 53}, {"type": "text", "text": "7 Annotation Example ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Figure 1 below is a model solution of a sample question to be annotated; Figure 2 shows an example annotation for the same model solution. ", "page_idx": 53}, {"type": "text", "text": "\"Question_UUID\": \"92f293be-132c-4b43-8937-dfb324d371be\", \"Question\": \"Both C4 and CAM pl ng is an accurate comparison of the two strategies?\",   \n\"Options\": \"A: C4 plants fix CO2 as the 4-carbon aci osphate. \\nB: C4 plants fix CO2 in the mesophyll but carry out the Calvin cycle in the bundle sheath, while CAM plants fix CO2   \nand carry out the Calvin cycle in the mesophyll. \\nC: C4 plants fix CO2 in the bundle sheath but carry out the Calvin cycle in the   \nmesophyll, while CAM plants fix CO2 and carry out the Calvin cycle in the bundle sheath. \\nD: C4 plants store CO2 as phosphoglycolate,   \nwhile CAM plants store CO2 as oxaloacetate. \",   \n\"Ground_Truth_Analysis\": \"\", \"Ground_Truth_Answer\": \"B\", \"Model_Solution_Steps\": [ \"Step 1: C4 plants fix \"Step 1: C4 plants fix CO2 as the 4-carbon acid oxaloacetate, while CAM plants fix CO2 as the 5-carbon acid ribulose 1, 5-   \n\"Step \"Step 3: C4 plants fix CO2 in the mesophyll but carry out the Calvin cycle in the bundle sheath, while CAM plants fix C t the Calvin cycle in the mesophyll.\", O2 and   \n\"Step 4: This statement accurately des tely describes this process in CAM plants.\",   \n\"Step 5: C4 plants fix CO2 in the bundle sh t the Calvin cycle in the bundle sheath.\",   \n\"Step 6: This statement inaccurately d \"Step 6: This statement inaccurately describes the spatial separation of initial CO2 fixation and the Calvin cycle in C4   \nplants.\", \"Step 8: This statement inaccurately describes how CO2 is stored in C4 and CAM plants.\", \"Solution: Choice_A\" \"Solution: Choice_A\" \"S \"Sampled_Model\": \"GPT3.5\", \"Model_Solution_First_Error_Step_Num\": \"Model_Solution_Error_Reason\": \"TBD\", \"Rectified_Model_Solution_First_Error \"Rectified_Model_Solution_First_Error_Step\": \"TBD\" ", "page_idx": 54}, {"type": "text", "text": "Figure 1: A task example of a model-generated solution for a high-school biology question (to be annotated). ", "page_idx": 54}, {"type": "text", "text": "\"Model_Solution_Correctness\": \"No\",   \n\"Model_Solution_Error_Reason\": \"The fixatio   \nis an incorrect statement; CO2 is fixed in oxalic acid by the enzyme PEP carboxylase in CAM plants (the sa   \nstep used by C4 plants), and then it is converted to malic acid or some other type of organic acid.\",   \n\"Rectified_Model_Solution_First_Error_Step\": \"The description of this statement is incorrect. Althoug   \nplants fix CO2 to oxaloacetate 4 carbonate, photorespiration is more limited in photosynthesis in CAM plan   \nplants fix co2 to oxaloacetate 4 carbonate, photorespiration is more limited in photosynthesis in CAM plants   \nin CAM plants (the same step as that used by C4 plants), and then is converted to malic acid or other kinds   \nin CAM plants (the same step as that used by C4 plants), and then is converted to malic acid or other kinds   \nof organic acids.\" ", "page_idx": 54}, {"type": "text", "text": "Figure 2: An example of standard annotation (with the previous items omitted to save space). ", "page_idx": 54}, {"type": "text", "text": "Annotation Guideline: Medicine Subject ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "1 Background ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "With the increasingly enhanced capabilities of large language models such as ChatGPT, existing models can break down complex problems and solve them step by step. However, while their solutions may often be seemingly correct, they can contain errors in understanding, calculation, and reasoning logic. In this annotation task, annotators will evaluate model-generated step-by-step solutions to questions in the medicine subject, and determine whether the model has obtained the correct answer based on the correct understanding and reasoning logic. ", "page_idx": 55}, {"type": "text", "text": "2 Annotation Task ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Given a question and a step-by-step solution generated by the model, the annotator needs to read the question and model-generated solutions carefully. There will be different solutions from multiple models for one question, and they need to be annotated independently. Each annotation task is divided into four sub-tasks. ", "page_idx": 55}, {"type": "text", "text": "2.1 Sub-task 1 ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "The first sub-task is to decide whether the model-generated step-by-step solution is correct. Even if the model\u2019s final answer matches the ground-truth answer, the model may arrive at the correct answer through incorrect understanding and reasoning. Therefore, regardless of whether the final answers match the ground-truth choice, annotators should read through each model solution carefully and complete all subtasks based on prudent judgments. ", "page_idx": 55}, {"type": "text", "text": "2.2 Sub-task 2 ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "The second sub-task is to identify the first incorrect step in the model-generated solution if the solution is incorrect. Specifically, each step can be interpreted as correct, neutral, or incorrect. ", "page_idx": 55}, {"type": "text", "text": "\u2022 Correct means both the calculation and understanding are correct, and the step is essential for reaching the correct result.   \n\u2022 Neutral refers to the current step possibly being a background statement about the question, a factual/formula description, or an exploratory step generated by the model. There are no obvious errors in this step, but whether this step leads to the final correct answer is not obvious.   \n\u2022 Incorrect step refers to obvious errors in calculation, understanding, or other possible errors in reasoning, regardless of whether this error affects the final calculation result. ", "page_idx": 55}, {"type": "text", "text": "The third sub-task is to describe the reason for the error in the first incorrect step. Annotators should carefully analyze the possible reasons for the error in the incorrect step and provide a rational analysis. Please try to incorporate the logic of the model\u2019s solution and analyze the reasons for this error from a holistic perspective. This error reason may serve as a reference for other annotators or models in the future, so please be as detailed, comprehensive, and clear as possible. ", "page_idx": 55}, {"type": "text", "text": "2.4 Sub-task 4 ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "The fourth and final sub-task is to rewrite the first incorrect step. Based on the error reason you provided, correct the incorrect step that you identified. The rewritten step should naturally integrate into the original context of the model solution, with only the incorrect part modified when necessary. ", "page_idx": 56}, {"type": "text", "text": "3 Annotation Data Format ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "At the end of this guideline, Figure 1 shows an annotation example of one model-generated solution for a medicine question, which includes the following items: ", "page_idx": 56}, {"type": "text", "text": "Question, Options, Model_Solution_Steps and Ground_Truth_Answer: They are what annotators should carefully read and analyze. ", "page_idx": 56}, {"type": "text", "text": "Model_Solution_Correctness is the first sub-task item to be annotated. It is defined as whether the model solution is completely correct for all steps. Please only answer \"Yes\" or \"No\" in this column. Please do not fill in other variants such as correct, incorrect, positive, negative, etc. ", "page_idx": 56}, {"type": "text", "text": "Model_Solution_First_Error_Step_Num is the second sub-task item to be annotated. It is defined as the first incorrect step specified in the model solution. If the annotation of the previous item is $\"\\mathrm{No}\".$ please enter the numerical step number with quotation marks here, such as \"1\", $\"2\"$ , etc.; If the result of the first item annotation is \"Yes\", fill in \"None\" here. Please note: ", "page_idx": 56}, {"type": "text", "text": "1. Do not fill in other variants such as \"one\", \"two\", or \"none\", \"no\", etc.   \n2. Step numbers should be written in double quotation marks; do not just write numbers. ", "page_idx": 56}, {"type": "text", "text": "Model_Solution_Error_Reason is the third sub-task item to be annotated. Please provide a detailed error analysis for the identified first incorrect step here. For example, whether the model refers to incorrect factual knowledge / correct facts but incorrect comprehension, calculation / incorrect contextual logic links / improper conditions or assumptions, etc. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. ", "page_idx": 56}, {"type": "text", "text": "Rectified_Model_Solution_First_Error_Step is the fourth and last sub-task item to be annotated. Please correct the incorrect step based on the error reason you provided. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. Note that we are not responsible for the consequential steps following the first incorrect step; we only need to correct the identified first error here. ", "page_idx": 56}, {"type": "text", "text": "4 Annotation Regulations & Quality Control ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "All questions are to be annotated according to the format requirements. If issues arise with the annotation format from sampling inspection, annotators should make modifications promptly. ", "page_idx": 56}, {"type": "text", "text": "If the annotations of error reasons and step corrections are too brief, perfunctory, or unclear, reannotation is required to ensure the annotation quality. For each batch of submitted files, if any of the following occurred, all questions of the same batch will be sent back for re-examination and re-annotation: ", "page_idx": 56}, {"type": "text", "text": "1. the annotation error rate is higher than $5\\%$ after random sampling, or   \n2. any of the requirements in this guideline are found violated. ", "page_idx": 56}, {"type": "text", "text": "5 Additional Notes for Medicine Subject ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "5.1 Look-Up Source ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Annotating the medicine subject questions requires professional expertise in the related field, as annotators have been notified and assessed accordingly in the recruitment round. When encountering unfamiliar or unclear terms and concepts, please use search engines and conduct factual inquiries from authoritative sources to assist with your annotation. Please do not use any language models as your annotation assistance tool. Contact the annotation management team whenever in doubt. ", "page_idx": 56}, {"type": "text", "text": "6 Common Questions ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Q1: When a step repeats the incorrect option should I mark it as the first incorrect step? ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "No, if a step only describes what an incorrect option is stating or repeats the exact words of the incorrect option without analysis, it does not constitute an incorrect step. But if the step includes wrong analysis/judgment about the incorrect option, then it is considered incorrect. ", "page_idx": 57}, {"type": "text", "text": "Q2: If previous steps so far have only stated relevant facts without specific analysis, how should I handle these steps? ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Similarly, if the steps focus solely on factual statements about the options or related background descriptions, these steps should be understood as neutral steps unless these steps contain incorrect understanding, incorrect facts, etc. The first incorrect step should be the one that involves incorrect analysis or reasoning. ", "page_idx": 57}, {"type": "text", "text": "Q3: What should I do if I encounter difficulty comprehending the question options or model solutions? ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "When encountering unfamiliar terms, look up textbook sources or use search engines to find reliable explanations first. Contact the annotation management team whenever in doubt. ", "page_idx": 57}, {"type": "text", "text": "Q4: The model\u2019s answer gives two answers, one of which is correct. How should I decide? ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Annotate it as \"No.\" Then follow the standard process to annotate the incorrect step, error reason, and the correction step. ", "page_idx": 57}, {"type": "text", "text": "Q5: It\u2019s inconvenient to read the JSON file without line breaks. ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "If you are using platforms like Visual Studio Code to annotate files in JSON format, you can install plugins like \u2018json editor\u2019 to assist in reading. However, take caution against modifying any content other than the required subtasks and do not manually change the data structure. ", "page_idx": 57}, {"type": "text", "text": "7 Annotation Example ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Figure 1 below is a model solution of a sample question to be annotated; Figure 2 shows an example annotation for the same model solution. ", "page_idx": 57}, {"type": "image", "img_path": "GN2qbxZlni/tmp/519d1c1b74cc2650e2b6ea1eb7fcc2a704948ee774afd96a22850dbf695e7f63.jpg", "img_caption": [], "img_footnote": [], "page_idx": 57}, {"type": "text", "text": "Figure 1: A task example of a model-generated solution for a medicine question (to be annotated). ", "page_idx": 57}, {"type": "text", "text": "\"Model_Solution_Correctness\": \"No\", \"Model_Solution_First_Error_Step_Num\": \"2\" \"Model_Solution_Error_Reason\": \"Excess creatine is not associated with inhibition of phosphocreatine resynthesis.\", \"Rectified_Model_Solution_First_Error_Step\": \"Step 2: Option A suggests that creatine excess inhibits and increases the amount of phosphocreatine, which improves the ability to resynthesize ATP during intensity and increases the amount of phosphocreatine, which improves the ability to resynthesize ATP during intensity exercise.\" ", "page_idx": 58}, {"type": "text", "text": "Figure 2: An example of standard annotation (with the previous items omitted to save space). ", "page_idx": 58}, {"type": "text", "text": "Annotation Guideline: Chemistry Subject ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "1 Background ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "With the increasingly enhanced capabilities of large language models such as ChatGPT, existing models can break down complex problems and solve them step by step. However, while their solutions may often be seemingly correct, they can contain errors in understanding, calculation, and reasoning logic. In this annotation task, annotators will evaluate model-generated step-by-step solutions to questions in the chemistry subject (including university-level and high-school-level chemistry), and determine whether the model has obtained the correct answer based on the correct understanding and reasoning logic. ", "page_idx": 59}, {"type": "text", "text": "2 Annotation Task ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "Given a question and a step-by-step solution generated by the model, the annotator needs to read the question and model-generated solutions carefully. There will be different solutions from multiple models for one question, and they need to be annotated independently. Each annotation task is divided into four sub-tasks. ", "page_idx": 59}, {"type": "text", "text": "2.1 Sub-task 1 ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "The first sub-task is to decide whether the model-generated step-by-step solution is correct. Even if the model\u2019s final answer matches the ground-truth answer, the model may arrive at the correct answer through incorrect understanding and reasoning. Therefore, regardless of whether the final answers match the ground-truth choice, annotators should read through each model solution carefully and complete all subtasks based on prudent judgments. ", "page_idx": 59}, {"type": "text", "text": "2.2 Sub-task 2 ", "text_level": 1, "page_idx": 59}, {"type": "text", "text": "The second sub-task is to identify the first incorrect step in the model-generated solution if the solution is incorrect. Specifically, each step can be interpreted as correct, neutral, or incorrect. ", "page_idx": 59}, {"type": "text", "text": "\u2022 Correct means both the calculation and understanding are correct, and the step is essential for reaching the correct result.   \n\u2022 Neutral refers to the current step possibly being a background statement about the question, a factual/formula description, or an exploratory step generated by the model. There are no obvious errors in this step, but whether this step leads to the final correct answer is not obvious.   \n\u2022 Incorrect step refers to obvious errors in calculation, understanding, or other possible errors in reasoning, regardless of whether this error affects the final calculation result. ", "page_idx": 59}, {"type": "text", "text": "The third sub-task is to describe the reason for the error in the first incorrect step. Annotators should carefully analyze the possible reasons for the error in the incorrect step and provide a rational analysis. Please try to incorporate the logic of the model\u2019s solution and analyze the reasons for this error from ", "page_idx": 59}, {"type": "text", "text": "2.4 Sub-task 4 ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "The fourth and final sub-task is to rewrite the first incorrect step. Based on the error reason you provided, correct the incorrect step that you identified. The rewritten step should naturally integrate into the original context of the model solution, with only the incorrect part modified when necessary. ", "page_idx": 60}, {"type": "text", "text": "3 Annotation Data Format ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "At the end of this guideline, Figure 1 shows an annotation example of one model-generated solution for a high-school chemistry question, which includes the following items: ", "page_idx": 60}, {"type": "text", "text": "Question, Options, Model_Solution_Steps and Ground_Truth_Answer: They are what annotators should carefully read and analyze. ", "page_idx": 60}, {"type": "text", "text": "Model_Solution_Correctness is the first sub-task item to be annotated. It is defined as whether the model solution is completely correct for all steps. Please only answer \"Yes\" or \"No\" in this column. Please do not fill in other variants such as correct, incorrect, positive, negative, etc. ", "page_idx": 60}, {"type": "text", "text": "Model_Solution_First_Error_Step_Num is the second sub-task item to be annotated. It is defined as the first incorrect step specified in the model solution. If the annotation of the previous item is \"No\", please enter the numerical step number with quotation marks here, such as \"1\", \"2\", etc.; If the result of the first item annotation is \"Yes\", fill in \"None\" here. Please note: ", "page_idx": 60}, {"type": "text", "text": "1. Do not fill in other variants such as \"one\", \"two\", or \"none\", \"no\", etc.   \n2. Step numbers should be written in double quotation marks; do not just write numbers. ", "page_idx": 60}, {"type": "text", "text": "Model_Solution_Error_Reason is the third sub-task item to be annotated. Please provide a detailed error analysis for the identified first incorrect step here. For example, whether the model refers to incorrect factual knowledge / correct facts but incorrect comprehension, calculation / incorrect contextual logic links / improper conditions or assumptions, etc. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. ", "page_idx": 60}, {"type": "text", "text": "Rectified_Model_Solution_First_Error_Step is the fourth and last sub-task item to be annotated. Please correct the incorrect step based on the error reason you provided. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. Note that we are not responsible for the consequential steps following the first incorrect step; we only need to correct the identified first error here. ", "page_idx": 60}, {"type": "text", "text": "4 Annotation Regulations & Quality Control ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "All questions are to be annotated according to the format requirements. If issues arise with the annotation format from sampling inspection, annotators should make modifications promptly. ", "page_idx": 60}, {"type": "text", "text": "If the annotations of error reasons and step corrections are too brief, perfunctory, or unclear, reannotation is required to ensure the annotation quality. For each batch of submitted files, if any of the following occurred, all questions of the same batch will be sent back for re-examination and re-annotation: ", "page_idx": 60}, {"type": "text", "text": "1. the annotation error rate is higher than $5\\%$ after random sampling, or   \n2. any of the requirements in this guideline are found violated. ", "page_idx": 60}, {"type": "text", "text": "5 Additional Notes for Chemistry Subject ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "5.1 Look-Up Source ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "The chemistry subject of this task includes annotating questions in the difficulty level of American university and high school chemistry. When encountering unfamiliar or unclear terms and concepts, ", "page_idx": 60}, {"type": "text", "text": "6 Common Questions ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Q1: When a step repeats the incorrect option should I mark it as the first incorrect step? ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "No, if a step only describes what an incorrect option is stating or repeats the exact words of the incorrect option without analysis, it does not constitute an incorrect step. But if the step includes wrong analysis/judgment about the incorrect option, then it is considered incorrect. ", "page_idx": 61}, {"type": "text", "text": "Q2: If previous steps so far have only stated relevant facts without specific analysis, how should I handle these steps? ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Similarly, if the steps focus solely on factual statements about the options or related background descriptions, these steps should be understood as neutral steps unless these steps contain incorrect understanding, incorrect facts, etc. The first incorrect step should be the one that involves incorrect analysis or reasoning. ", "page_idx": 61}, {"type": "text", "text": "Q3: What should I do if I encounter difficulty comprehending the question options or model solutions? ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "When encountering unfamiliar terms, look up textbook sources or use search engines to find reliable explanations first. Contact the annotation management team whenever in doubt. ", "page_idx": 61}, {"type": "text", "text": "Q4: The model\u2019s answer gives two answers, one of which is correct. How should I decide? ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Annotate it as \"No.\" Then follow the standard process to annotate the incorrect step, error reason, and the correction step. ", "page_idx": 61}, {"type": "text", "text": "Q5: It\u2019s inconvenient to read the JSON file without line breaks. ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "If you are using platforms like Visual Studio Code to annotate files in JSON format, you can install plugins like \u2019json editor\u2019 to assist in reading. However, take caution against modifying any content other than the required subtasks and do not manually change the data structure. ", "page_idx": 61}, {"type": "text", "text": "7 Annotation Example ", "text_level": 1, "page_idx": 61}, {"type": "text", "text": "Figure 1 below is a model solution of a sample question to be annotated; Figure 2 shows an example annotation for the same model solution. ", "page_idx": 61}, {"type": "text", "text": "\"Subject\": \"high_school_chemistry\", \"Question\": \"Which of the following \"Ground_Truth_Analysis\": \"\", \"Options\": \"A: Heat of fusio \"Ground_Truth_Answer\": \"A\", \"Model_Solution_Steps\": [ \"Step 1: Heat of fusion nge a substance from a solid to a liquid state.\",   \nto change a substance from a solid to a liquid state.\", er intermolecular forces require more energy to overcome these forces and boil.\",   \n\"Step 3: Vapor pressures are another good measure of relative intermolecular att eaker intermolecular forces have higher vapor pressures.\",   \n\"Step 4: Heat of vaporization is a good measure of the st nge a substance from a liquid to a gas state.\",   \n\"Step 5: Considering all the choices, it can b tive forces. Therefore, the correct choice is: None.\"   \nattractive forces. Therefore, the correct choice is: None.\" \"S \"Model_Solution_Correctnes \"Model_Solution_First_Error_Step_Num\" \"Model_Solution_Error_Reason\": \"TBD\", \"Rectified_Model_Solution_First_Error \"Rectified Model Solution First Error_Step\": \"TBD\" 1, ", "page_idx": 62}, {"type": "text", "text": "Figure 1: A task example of a model-generated solution for a high-school chemistry question (to be annotated). ", "page_idx": 62}, {"type": "text", "text": "\"Model_Solution_Correctness\": \"incorrect\" \"Model_Solution_Error_Reason\": \"The he , but it is not as good as them, leaning more towards the energy required to transition from solid to liquid, making it not a good method compared to the other three options.\\n\" \"Model_Solution_Rectified_First_Error_Step\": \"Step 1: The heat of fusi required to disrupt the orderly arrangement of molecules in a crystal structure, rather than just the strength of intermolecular attractive forces.\\n\", just the strength of intermolecular attractive forces.\\n\", ", "page_idx": 62}, {"type": "text", "text": "Figure 2: An example of standard annotation (with the previous items omitted to save space). ", "page_idx": 62}, {"type": "text", "text": "Annotation Guideline: Logic Subject ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "1 Background ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "With the increasingly enhanced capabilities of large language models such as ChatGPT, existing models can break down complex problems and solve them step by step. However, while their solutions may often be seemingly correct, they can contain errors in understanding, calculation, and reasoning logic. In this annotation task, annotators will evaluate model-generated step-by-step solutions to questions in the logic subject, and determine whether the model has obtained the correct answer based on the correct understanding and reasoning logic. ", "page_idx": 63}, {"type": "text", "text": "2 Annotation Task ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Given a question and a step-by-step solution generated by the model, the annotator needs to read the question and model-generated solutions carefully. There will be different solutions from multiple models for one question, and they need to be annotated independently. Each annotation task is divided into four sub-tasks. ", "page_idx": 63}, {"type": "text", "text": "2.1 Sub-task 1 ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "The first sub-task is to decide whether the model-generated step-by-step solution is correct. Even if the model\u2019s final answer matches the ground-truth answer, the model may arrive at the correct answer through incorrect understanding and reasoning. Therefore, regardless of whether the final answers match the ground-truth choice, annotators should read through each model solution carefully and complete all subtasks based on prudent judgments. ", "page_idx": 63}, {"type": "text", "text": "2.2 Sub-task 2 ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "The second sub-task is to identify the first incorrect step in the model-generated solution if the solution is incorrect. Specifically, each step can be interpreted as correct, neutral, or incorrect. ", "page_idx": 63}, {"type": "text", "text": "\u2022 Correct means both the calculation and understanding are correct, and the step is essential for reaching the correct result.   \n\u2022 Neutral refers to the current step possibly being a background statement about the question, a factual/formula description, or an exploratory step generated by the model. There are no obvious errors in this step, but whether this step leads to the final correct answer is not obvious.   \n\u2022 Incorrect step refers to obvious errors in calculation, understanding, or other possible errors in reasoning, regardless of whether this error affects the final calculation result. ", "page_idx": 63}, {"type": "text", "text": "The third sub-task is to describe the reason for the error in the first incorrect step. Annotators should carefully analyze the possible reasons for the error in the incorrect step and provide a rational analysis. Please try to incorporate the logic of the model\u2019s solution and analyze the reasons for this error from a holistic perspective. This error reason may serve as a reference for other annotators or models in the future, so please be as detailed, comprehensive, and clear as possible. ", "page_idx": 63}, {"type": "text", "text": "2.4 Sub-task 4 ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "The fourth and final sub-task is to rewrite the first incorrect step. Based on the error reason you provided, correct the incorrect step that you identified. The rewritten step should naturally integrate into the original context of the model solution, with only the incorrect part modified when necessary. ", "page_idx": 64}, {"type": "text", "text": "3 Annotation Data Format ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "At the end of this guideline, Figure 1 shows an annotation example of one model-generated solution for a logic question, which includes the following items: ", "page_idx": 64}, {"type": "text", "text": "Question, Options, Model_Solution_Steps and Ground_Truth_Answer: They are what annotators should carefully read and analyze. ", "page_idx": 64}, {"type": "text", "text": "Model_Solution_Correctness is the first sub-task item to be annotated. It is defined as whether the model solution is completely correct for all steps. Please only answer \"Yes\" or \"No\" in this column. Please do not fill in other variants such as correct, incorrect, positive, negative, etc. ", "page_idx": 64}, {"type": "text", "text": "Model_Solution_First_Error_Step_Num is the second sub-task item to be annotated. It is defined as the first incorrect step specified in the model solution. If the annotation of the previous item is $\"\\mathrm{No}\".$ please enter the numerical step number with quotation marks here, such as \"1\", $\"2\"$ , etc.; If the result of the first item annotation is \"Yes\", fill in \"None\" here. Please note: ", "page_idx": 64}, {"type": "text", "text": "1. Do not fill in other variants such as \"one\", \"two\", or \"none\", \"no\", etc.   \n2. Step numbers should be written in double quotation marks; do not just write numbers. ", "page_idx": 64}, {"type": "text", "text": "Model_Solution_Error_Reason is the third sub-task item to be annotated. Please provide a detailed error analysis for the identified first incorrect step here. For example, whether the model refers to incorrect factual knowledge / correct facts but incorrect comprehension, calculation / incorrect contextual logic links / improper conditions or assumptions, etc. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. ", "page_idx": 64}, {"type": "text", "text": "Rectified_Model_Solution_First_Error_Step is the fourth and last sub-task item to be annotated. Please correct the incorrect step based on the error reason you provided. If the annotation of the first item \u201cModel_Solution_Correctness\u201d is \"Yes\", fill in \"None\" here. Note that we are not responsible for the consequential steps following the first incorrect step; we only need to correct the identified first error here. ", "page_idx": 64}, {"type": "text", "text": "4 Annotation Regulations & Quality Control ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "All questions are to be annotated according to the format requirements. If issues arise with the annotation format from sampling inspection, annotators should make modifications promptly. ", "page_idx": 64}, {"type": "text", "text": "If the annotations of error reasons and step corrections are too brief, perfunctory, or unclear, reannotation is required to ensure the annotation quality. For each batch of submitted files, if any of the following occurred, all questions of the same batch will be sent back for re-examination and re-annotation: ", "page_idx": 64}, {"type": "text", "text": "1. the annotation error rate is higher than $5\\%$ after random sampling, or   \n2. any of the requirements in this guideline are found violated. ", "page_idx": 64}, {"type": "text", "text": "5 Additional Notes for Logic Subject ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "5.1 Look-Up Source ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "Annotating the logic subject questions requires prudent reasoning and inference abilities, as annotators have been notified and assessed accordingly in the recruitment round. When encountering unfamiliar or unclear terms and concepts, please use search engines and conduct factual inquiries from authoritative sources to assist with your annotation. Please do not use any language models as your annotation assistance tool. Contact the annotation management team whenever in doubt. ", "page_idx": 64}, {"type": "text", "text": "6 Common Questions ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Q1: When a step repeats the incorrect option should I mark it as the first incorrect step? ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "No, if a step only describes what an incorrect option is stating or repeats the exact words of the incorrect option without analysis, it does not constitute an incorrect step. But if the step includes wrong analysis/judgment about the incorrect option, then it is considered incorrect. ", "page_idx": 65}, {"type": "text", "text": "Q2: If previous steps so far have only stated relevant facts without specific analysis, how should I handle these steps? ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Similarly, if the steps focus solely on factual statements about the options or related background descriptions, these steps should be understood as neutral steps unless these steps contain incorrect understanding, incorrect facts, etc. The first incorrect step should be the one that involves incorrect analysis or reasoning. ", "page_idx": 65}, {"type": "text", "text": "Q3: What should I do if I encounter difficulty comprehending the question options or model solutions? ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "When encountering unfamiliar terms, look up textbook sources or use search engines to find reliable explanations first. Contact the annotation management team whenever in doubt. ", "page_idx": 65}, {"type": "text", "text": "Q4: The model\u2019s answer gives two answers, one of which is correct. How should I decide? ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Annotate it as \"No.\" Then follow the standard process to annotate the incorrect step, error reason, and the correction step. ", "page_idx": 65}, {"type": "text", "text": "Q5: It\u2019s inconvenient to read the JSON file without line breaks. ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "If you are using platforms like Visual Studio Code to annotate files in JSON format, you can install plugins like \u2018json editor\u2019 to assist in reading. However, take caution against modifying any content other than the required subtasks and do not manually change the data structure. ", "page_idx": 65}, {"type": "text", "text": "7 Annotation Example ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Figure 1 below is a model solution of a sample question to be annotated; Figure 2 shows an example annotation for the same model solution. ", "page_idx": 65}, {"type": "text", "text": "{ \"Question_UUID\": \"f337631a-5aeb-402e-9d5b-f69052da4938\", \"Question\": \"Nutrit ilk, meat, fruit and vegetables, and breads and cereals. This recommendation was, however, dangerous to health.Each of the   \nfollowing, if true, provides support for the critique above EXCEPT:\",   \n\"Options\": \"A: A healthy diet should include the consumption of s recommendation was often interpreted as satisfied by the consumption of a single serving of a fruit or vegetable. \\nB: The   \nrecommendation that some food from the fruit and vegetable group be consumed daily constituted a reminder not to neglect   \nthis group, which provides needed vitamins, minerals, and fiber. \\nC: The omission of fish, which contains beneficial oils,   \nfrom the names of groups in the list gave erroneous impression that it is less healthy as a food than is red meat. \\nD: The   \ndivision into four groups gave the impression that an equal amount of each should be consumed, but milk and meat tend to   \ncontain fats that promote heart disease and cancer and should be eaten in lesser amounts. \",   \n\"Ground_Truth_Analysis\": \"\", \"Ground_Truth_Answer\": \"B\", \"Ground_Truth_Answer_Modifie \"Sampled_Model\": \"Claude2\", \"Model_Solution_Steps\": [ \"Step 1: Choice A provi as allowing consumption of a single fruit or vegetable serving per day would be unhealthy. So Choice A should be   \neliminated as an answer.\",   \n\"\", \", vide health benefits. This supports the recommendation rather than critiquing it, so Choice B should also be   \nprovide health benefits. This supports the recommendation rather than critiquing it, so Choice B should also be   \n\"\", \"St is supports the claim that the recommendation was dangerous to health.\",   \nThis supports the claim that the recommendation was dangerous to health.\", , t\u00a0e\"nS tienp  l4e:s sCehro iacmeo uDn tcsr idtuieq uteos  htehael trhe cdoamnmgeenrdsa.t iTohni sb ys unpoptoirntgs  tthhaet  cilta iimm ptlhiaetd  tehqeu arle ccoomnmseunmdpattiioonn  owfa sf odoadn ggerroouupss.  t\"h,at should be   \neaten in lesser amounts due to health dangers. This supports the claim that the recommendation was dangerous. \", \"St \"Step 5: Choices A, B and D all provide support for the critique of the recommendation, while only Choice $\\mathbb{C}$ does not.\", \", \"Solution: Choice_C\"\" \"M \"Model_Solution_First_Error_Step\": \" \"Model_Solution_Error_Reason\": \"TBD\", \"Model Solution Error Reason\": \"TBD\", \"Model Solution_Rectified_First_Error_Step\": \"TBD\", ", "page_idx": 66}, {"type": "text", "text": "Figure 1: A task example of a model-generated solution for a logic question (to be annotated). ", "page_idx": 66}, {"type": "text", "text": "\"Model_Solution_Correctness\": \"incorrect\" \"Model_Solution_First_Error_Step\": \"2\", egetables in the diet. This contradicts the claim that this recommendation is dangerous vegetables in the diet. This contradicts the claim that this recommendation is dangerous to health.\" \"Model_Solution_Rectified_First_Error_Step\": \"Step 2: Option B supports the part of the recommendation about consuming fruits and vegetables, and does not provide criticism of the entire recommendation. So Option B should be the correct answer.\" ", "page_idx": 66}, {"type": "text", "text": "Annotation Guideline: Coding Subject ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "With the capabilities of large language models like ChatGPT gradually increasing, existing models often manage to decompose and partially solve complex problems. However, their explanations may sometimes be misleading or contain errors in understanding, calculation, and logical reasoning. In this annotation task, annotators should review and evaluate the step-by-step solutions provided by the model to determine whether the model has correctly understood and reasoned to obtain the correct answer. ", "page_idx": 67}, {"type": "text", "text": "2 Annotation Task Description ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "Given a question and a step-by-step solution generated by the model, annotators need to carefully read the question and solution, and review the solution. Each question will have multiple different solutions from the model, which need to be reviewed independently. ", "page_idx": 67}, {"type": "text", "text": "2.1 Data Format ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "Each data entry will include: ", "page_idx": 67}, {"type": "text", "text": "\u2022 A coding question and description (within a block comment in the function).   \n\u2022 A segment of the solution generated by the model.   \n\u2022 A series of assert statements to help us check the generated code. ", "page_idx": 67}, {"type": "text", "text": "The comments in the model-generated code solution should indicate the model\u2019s thought process. We should regard comments as steps in the thought process, and the code corresponding to each comment as the model\u2019s implementation of the comment. We can run the generated code and use assert statements to test and understand the code\u2019s logic to complete the following tasks. ", "page_idx": 67}, {"type": "text", "text": "2.2 Tasks ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "\u2022 Task 1: Determine the correctness of the step-by-step thought process. Even if the model\u2019s final answer does not produce an error, it might have arrived at the correct answer through incorrect understanding and reasoning. Therefore, regardless of whether the final answer matches, annotators should carefully read the question and understand the code, using assert statements to identify any errors. ", "page_idx": 67}, {"type": "text", "text": "\u2022 Task 2: Identify the first erroneous step. If the solution is incorrect, annotators need to identify the first erroneous step in the step-by-step solution. Specifically, if there is a logical error in the code, find the first incorrect thought step\u2019s comment. If the code logic is correct, but the implementation contains an error, identify the first line of erroneous code. If the model failed to correctly understand the intent of the question, find the first step explaining the thought process. Note that we need to find the first erroneous step. ", "page_idx": 67}, {"type": "text", "text": "\u2022 Task 3: Describe the reason for the first error. Annotators need to analyze the error in the erroneous step and provide a reasonable analysis. Please try to incorporate the model\u2019s thought process into the analysis. This error reason will serve as a reference for other annotators or models in the future, so please be detailed, thorough, and easy to understand. ", "page_idx": 67}, {"type": "text", "text": "\u2022 Task 4: Rewrite the erroneous step. Based on the provided error reason, correct the erroneous step. If the thought process is incorrect, modify the erroneous comment. If the code contains an error, modify the corresponding code. Note that we only need to correct the first line of erroneous code. If you have any questions about this step, please contact us. ", "page_idx": 68}, {"type": "text", "text": "3 Annotation File and Format Description ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Below is a sample annotation for a code answer (in response to a model reply). ", "page_idx": 68}, {"type": "text", "text": "\u2022 Model_Solution_Steps and assert_statements are the content that annotators should carefully read, analyze, and run tests on. ", "page_idx": 68}, {"type": "text", "text": "\u2022 Model_Solution_Correctness is the first item to be annotated: please only answer \"yes\" or \"no\" in this column. Do not fill in other variants such as correct, incorrect, right, wrong, etc. ", "page_idx": 68}, {"type": "text", "text": "\u2022 Model_Solution_First_Error_Step_Num is the second item to be annotated: if the first item annotation result is \"no\", then only answer the number of the erroneous code line in this column such as \"1\", \"2\". If the first item annotation result is \"yes\", leave this column blank. Note: ", "page_idx": 68}, {"type": "text", "text": "\u2013 Do not fill in other variants such as \"one\", \"two\" or \"none\", \"no\". \u2013 The step number should be written within quotation marks \"\", do not write just the number. (Line numbers can be enabled in the compiler, for example, in VSCode notebook, you can open the command palette and find Show Cell Line Numbers) The line number starts from the first line of the code block. If there is no code block symbol, start counting from the first line of import or def. ", "page_idx": 68}, {"type": "text", "text": "\u2022 Model_Solution_Error_Reason is the third item to be annotated: please fill in this column with a detailed error analysis. Explain in a three-step method: 1. What was the model\u2019s original solution trying to do, and where did the problem occur. 2. Give an example of why the model could not solve this step correctly. 3. Provide a potential correct solution thought, what should be done in this step. If the first item annotation result is \"yes\", leave this column blank. ", "page_idx": 68}, {"type": "text", "text": "\u2022 Rectified_Model_Solution_First_Error_Step is the fourth and last item to be annotated: in this column, rewrite the erroneous step correctly. Try to provide a correct step in the same style as the model so that it can directly replace the original erroneous step. If the first item annotation result is \"yes\", leave this column blank. Note: ", "page_idx": 68}, {"type": "text", "text": "We are not responsible for the steps after the first error. We only need to correct the error here. ", "page_idx": 68}, {"type": "text", "text": "\u2013 Each question may have multiple correct answers after the first error, we only need to choose one way to modify it.   \n\u2013 Please ensure the modified code has correct indentation. ", "page_idx": 68}, {"type": "text", "text": "4 FAQ ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "1. Q: If the code has multiple code blocks, how to locate the line number? ", "page_idx": 68}, {"type": "text", "text": "\u2022 A: We have regenerated the model answers and ensured a stricter format, now all code should be within one code block. If you still find such cases, please contact us. ", "page_idx": 68}, {"type": "text", "text": "2. Q: What if the model answer is abnormal (e.g., no code)? What if the question is incomprehensible, or the question itself seems problematic? ", "page_idx": 68}, {"type": "text", "text": "\u2022 A: Please write the issue in the feedback sheet below. We will follow up on the problem. ", "page_idx": 68}, {"type": "text", "text": "3. Q: If the generated code lacks library and function, what should be the error line number? ", "page_idx": 68}, {"type": "text", "text": "\u2022 A: All are considered errors. The error step should be located below the earliest existing import line, rather than where the inner function/library function is used. ", "page_idx": 68}, {"type": "text", "text": "5 Annotation Example ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "5.1 Items to Read / Run ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "5.1.1 Model_Solution_Steps: ", "page_idx": 69}, {"type": "table", "img_path": "GN2qbxZlni/tmp/e06a2ca013d754ed1b0b1506e012bae8a41e8139f97f670d755ca498a5c4d3ce.jpg", "table_caption": [], "table_footnote": [], "page_idx": 69}, {"type": "text", "text": "The key steps are: ", "page_idx": 69}, {"type": "text", "text": "1. Check if length of s is valid based on the constraints.   \n2. Iterate through s.   \n3. At each position, try to extract a substring of length 2 or 3.   \n4. Check if the substring is uniform.   \n5. Return False if any substring is not uniform.   \n6. If all substrings are valid, return True at the end. ", "page_idx": 69}, {"type": "text", "text": "The comments explain the reasoning and logic behind each step. ", "page_idx": 69}, {"type": "text", "text": "5.2 Items to Annotate ", "text_level": 1, "page_idx": 70}, {"type": "text", "text": "5.2.1 Model_Solution_Correctness: \u2018no\u2019 ", "page_idx": 70}, {"type": "text", "text": "5.2.2 Model_Solution_First_Error_Step_Num: \u201823\u2019 ", "page_idx": 70}, {"type": "text", "text": "5.2.3 Model_Solution_Error_Reason: ", "page_idx": 70}, {"type": "text", "text": "\u201cThe model tries to extract substring of length 2 and 3, but the ${\\mathfrak{c}}_{\\dot{\\exists}\\pounds},$ statement will skip the possibility of finding any uniform substring of length 3. For example, if the input s is $^{\\epsilon}00011\\,^{\\backprime}$ , the first uniform substring $^{\\epsilon}\\circ00\\rangle$ will be incorrectly split at $^{\\epsilon}\\circ0\\,^{\\bullet}$ . One possible solution is to record the length of all uniform substrings and check if their lengths satisfy the requirements. Therefore, at this step the model should find the length of the current uniform substring.\u201d ", "page_idx": 70}, {"type": "text", "text": "5.2.4 Rectified_Model_Solution_First_Error_Step: ", "page_idx": 70}, {"type": "text", "text": "Three-Round Interaction Prompt Template for Self-Refine ", "text_level": 1, "page_idx": 71}, {"type": "image", "img_path": "GN2qbxZlni/tmp/ca365ab32ce9e2186ea49e39f578fd73180d0c5f7cebee5045907db54cfd958b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 71}, {"type": "text", "text": "Figure 8: This is the prompt we used for self-refine experiment, note that three consecutive inference calls are made in order to perform the most basic self correction. ", "page_idx": 71}, {"type": "image", "img_path": "GN2qbxZlni/tmp/7ef2b1adb1ae235620c3fc38c8a2cc82ee1dfaeb8a1fcb5d601692ef42b5fc31.jpg", "img_caption": ["Figure 9: This is the performance breakdown for self-refine experiment in the task level, where task 1,2,3 refers to solution correctness, first error step and error reason determination. "], "img_footnote": [], "page_idx": 71}, {"type": "text", "text": "Prompt for Response Generation ", "text_level": 1, "page_idx": 72}, {"type": "image", "img_path": "GN2qbxZlni/tmp/da9d8374ac25a2359dbe98c57f4fc1cf718c461118b0cb79a1f8f4136b1cc18b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 72}, {"type": "text", "text": "Figure 10: This is the prompt template we used to evaluate all the models. The $\\mathbf{k}\\cdot$ -shot-demo and hint-sent are either the few shot examples and solution correctness prior or empty string, depending on the experiment setup. ", "page_idx": 72}, {"type": "text", "text": "Prompt for Scoring Error Reasons ", "text_level": 1, "page_idx": 73}, {"type": "text", "text": "As an experienced {data['Subject']} teacher, your assistance is required to evaluate a student's explanation regarding the error in a problem solution. The task involves a detailed understanding of the problem, the incorrect solution provided, and the ground truth behind the error. Your analysis should focus on whether the student's explanation aligns with the actual error in the solution. ", "page_idx": 73}, {"type": "text", "text": "Please find the details below: ", "page_idx": 73}, {"type": "text", "text": "Question: {data['Question']}   \nIncorrect Solution Provided: {data['Model_Solution_Steps']}   \nFirst Incorrect Step in the Solution: {data['Model_Solution_First_Error_Step']} Ground Truth Error Reasons: {data['Model_Solution_Error_Reason']}   \nGround Truth Rectified Steps: {data['Model_Solution_Rectified_First_Error_Step']} Student's Explanation of the Error: {data['Evaluation_Result']['error_reason']} ", "page_idx": 73}, {"type": "text", "text": "Based on this information, please provide the following: ", "page_idx": 73}, {"type": "text", "text": "1. Step-by-Step Reasoning: [Offer a succinct, step-by-step interpretation of the ground truth error reason.] 2. Student Error Reason Analysis: [Analyze the student's explanation step by step, determining its accuracy in reflecting the actual error briefly.] 3. Final Decision: [State only 'Correct' or 'Wrong' to conclude whether the student's explanation correctly identifies the error based on your analysis.] ", "page_idx": 73}, {"type": "text", "text": "Please follow this format without any additional introductory or concluding statements. ", "page_idx": 73}, {"type": "text", "text": "Figure 11: This is the prompt template we used to request GPT-4 to help us score the error reasons explained by evaluated models. Note that despite the difficulties of deciding the solution correctness, it is much easier to decide the error reason correctness given the ground truth annotations. ", "page_idx": 73}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 74}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 74}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 74}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 74}, {"type": "text", "text": "Justification: Yes, the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 74}, {"type": "text", "text": "Guidelines: ", "page_idx": 74}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 74}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 74}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 74}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 74}, {"type": "text", "text": "Justification: The limitations of this work are discussed in $\\S\\operatorname{A.l}$ . ", "page_idx": 74}, {"type": "text", "text": "Guidelines: ", "page_idx": 74}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 74}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 74}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 74}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 74}, {"type": "text", "text": "Justification: Our work does not involve theoretical assumptions and proofs. ", "page_idx": 75}, {"type": "text", "text": "Guidelines: ", "page_idx": 75}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 75}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 75}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 75}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 75}, {"type": "text", "text": "Justification: We disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and conclusions of the paper, detailed in $\\S\\ 5.1$ . ", "page_idx": 75}, {"type": "text", "text": "Guidelines: ", "page_idx": 75}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 75}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 75}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 76}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 76}, {"type": "text", "text": "Justification: We opensourced our evaluation benchmark and the script as described in Section-1. Additionally, we have detailed the experimental setup in the paper $\\left(\\S\\ 5\\right)$ , including model selection, hyperparameter settings, data selection, evaluation metrics, hardware resources, etc. ", "page_idx": 76}, {"type": "text", "text": "Guidelines: ", "page_idx": 76}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 76}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 76}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 76}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 76}, {"type": "text", "text": "Justification: We provide comprehensive dataset statistics, evaluation metric descriptions, hyperparameters, and tool usage in $\\S\\ S$ . ", "page_idx": 76}, {"type": "text", "text": "Guidelines: ", "page_idx": 76}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 76}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 76}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 76}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 76}, {"type": "text", "text": "Justification: Our proposed method is an inference-only approach for LLM and we adopt the greedy-decoding strategy for all of our experiments, making the experiment results of each session consistent. ", "page_idx": 76}, {"type": "text", "text": "Guidelines: ", "page_idx": 76}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 76}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 77}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 77}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 77}, {"type": "text", "text": "Answer:[Yes] ", "page_idx": 77}, {"type": "text", "text": "Justification: We provide comprehensive experimental setup and hardware computation resources used in $\\S\\,\\mathrm{G}$ . ", "page_idx": 77}, {"type": "text", "text": "Guidelines: ", "page_idx": 77}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 77}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 77}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 77}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 77}, {"type": "text", "text": "Justification: We confirm that the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics, and all the authors preserve anonymity. ", "page_idx": 77}, {"type": "text", "text": "Guidelines: ", "page_idx": 77}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 77}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 77}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 77}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 77}, {"type": "text", "text": "Justification: The broader impacts of our paper are presented in $\\S\\mathrm{~A.}2$ . Guidelines: ", "page_idx": 77}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 77}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 78}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 78}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 78}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 78}, {"type": "text", "text": "Justification: Our dataset focuses on evaluation rather than training models. We leverage existing datasets rather than scrape from the Internet. ", "page_idx": 78}, {"type": "text", "text": "Guidelines: ", "page_idx": 78}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 78}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 78}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 78}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 78}, {"type": "text", "text": "Justification: All the assets, i.e., codes, data and models used in our paper, are properly credited and we explicitly mention and properly respect the license and terms of use. ", "page_idx": 78}, {"type": "text", "text": "Guidelines: ", "page_idx": 78}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 78}, {"type": "text", "text": "", "page_idx": 79}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 79}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 79}, {"type": "text", "text": "Justification: We have submitted the anonymized dataset, codes, and corresponding documents together with the paper. ", "page_idx": 79}, {"type": "text", "text": "Guidelines: ", "page_idx": 79}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 79}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 79}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Justification: The full text of instructions given to human annotators is presented in $\\S\\mathrm{~H~}$ . Guidelines: ", "page_idx": 79}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 79}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 79}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 79}, {"type": "text", "text": "Justification: The justification is as follows: We solely engaged human annotators for the dataset, and they were not subjects of our study. Furthermore, we partnered with a legally recognized annotation company in the country, which has obtained all necessary governmental approvals to operate its annotation business. ", "page_idx": 79}, {"type": "text", "text": "Guidelines: ", "page_idx": 79}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 80}]