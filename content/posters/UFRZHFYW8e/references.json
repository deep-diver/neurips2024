{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a foundational vision-language model that the current research builds upon and contrasts with."}, {"fullname_first_author": "Saachi Jain", "paper_title": "Distilling model failures as directions in latent space", "publication_date": "2023-00-00", "reason": "This paper proposes a method for identifying model failures caused by spurious correlations that the current research improves upon."}, {"fullname_first_author": "Sabri Eyuboglu", "paper_title": "Domino: Discovering systematic errors with cross-modal embeddings", "publication_date": "2022-00-00", "reason": "This paper introduces a method for discovering spurious correlations in a manner similar to the current research, enabling a comparison of methodologies."}, {"fullname_first_author": "Shiori Sagawa", "paper_title": "Distributionally robust neural networks", "publication_date": "2020-00-00", "reason": "This paper introduces a technique for improving model robustness that the current research builds upon and adapts to the vision-language domain."}, {"fullname_first_author": "Yu Yang", "paper_title": "Mitigating spurious correlations in multi-modal models during fine-tuning", "publication_date": "2023-00-00", "reason": "This paper tackles the problem of spurious correlations in multi-modal models, providing a direct comparison to the current research's mitigation strategy."}]}