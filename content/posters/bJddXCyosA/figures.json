[{"figure_path": "bJddXCyosA/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure provides a visual overview of the VisMin benchmark.  VisMin tests a model's ability to identify minimal differences between image-caption pairs. Four types of minimal changes are shown: object, attribute, count, and spatial relation. Each example shows two images and captions which differ only in one of these aspects. The evaluation task involves predicting the correct image-caption match given either two images and one caption or two captions and one image.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_3_1.jpg", "caption": "Figure 2: Our dataset creation pipeline includes three stages: (i) Minimal-Change Pairs Synthesis: We develop methods for synthesizing minimal-change image-caption pairs involving Objects & Attributes and Counting & Spatial Relations. (ii) Automatic Filtering: An LLM generates questions and answers based on captions, and a VQA model predicts answers from images. Synthetically generated minimal-change data are excluded if answers don't match. (iii) Human Verification: Synthetically generated minimal-change data undergoes a rigorous 4-steps human verification, and only examples passing all stages are included in the benchmark.", "description": "This figure illustrates the three-stage pipeline used to create the VisMin dataset. Stage 1, Minimal-Change Pairs Synthesis, involves generating minimal changes to image-caption pairs using LLMs and diffusion models.  Stage 2, Automatic Filtering, uses an LLM and a VQA model to ensure the quality of the synthesized data by verifying the consistency between the image and the caption. Finally, Stage 3, Human Verification, involves a rigorous four-step human verification process to ensure the high quality of the minimal-change data. Only the data that passes all three stages is included in the final benchmark.", "section": "3 Minimal-Change Image-Text Dataset Creation"}, {"figure_path": "bJddXCyosA/figures/figures_5_1.jpg", "caption": "Figure 3: VisMin categories and subcategories.", "description": "This figure shows a sunburst chart visualizing the distribution of minimal changes in the VisMin benchmark dataset.  The main categories are object, attribute, count, and spatial relation. Each of these categories is further broken down into subcategories, representing more specific types of changes.  For example, \"object\" is divided into subcategories like \"person,\" \"vehicle,\" \"animal,\" etc., while \"attribute\" includes subcategories such as \"color,\" \"material,\" and \"pattern and appearance.\" The sizes of the segments in the chart reflect the proportion of each subcategory within the overall dataset.", "section": "4 Training and Benchmark sets"}, {"figure_path": "bJddXCyosA/figures/figures_8_1.jpg", "caption": "Figure 3: VisMin categories and subcategories.", "description": "This figure shows a breakdown of the four main categories of minimal changes in the VisMin benchmark: object, attribute, count, and spatial relation.  Each main category is further divided into subcategories representing more specific types of changes. For example, attribute changes are broken down into color, material, pattern, and other changes, providing a more detailed view of the types of minimal changes used in VisMin.", "section": "4 Training and Benchmark sets"}, {"figure_path": "bJddXCyosA/figures/figures_18_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure shows examples of the four types of minimal changes used in the VisMin benchmark: object change, attribute change, count change, and spatial relation change. Each example shows a pair of images and a pair of captions where only one aspect has changed between the two. The task is to correctly match the images and captions.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_20_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure shows four examples of minimal changes between image-caption pairs in the VisMin benchmark.  Each row demonstrates a different type of minimal change: object, attribute, count, and spatial relation.  The task is to correctly match the image and caption pairs, testing the model's ability to understand these fine-grained differences. The figure highlights the challenge of the benchmark; minimal changes make it difficult for models to distinguish between image-caption pairs.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_21_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure shows examples from the VisMin benchmark, illustrating the four types of minimal changes used: object change (different objects in the scene), attribute change (changes in object attributes like color or size), count change (different number of objects), and spatial relation change (changes in the relative positions of objects).  The benchmark evaluates a model's ability to correctly match image-caption pairs when only one of these aspects changes between the pairs.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_24_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure provides a visual overview of the VisMin benchmark. It shows four types of minimal changes between image-caption pairs: object, attribute, count, and spatial relation. Each minimal change is shown with two example images and captions.  The evaluation task requires a model to correctly match the image and caption given two pairs of slightly different images and captions.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_25_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure provides a visual overview of the VisMin benchmark, which focuses on evaluating the ability of visual language models to understand minimal changes between image-caption pairs.  Four types of minimal changes are highlighted: object, attribute, count, and spatial relation. The evaluation task involves predicting the correct match between two images and two captions, or between one image and two captions, where only one aspect differs between the pairs.  Each type of minimal change is illustrated with example image and caption pairs.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_26_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure shows examples of the four minimal change types in the VisMin benchmark: object change, attribute change, count change, and spatial relation change. Each row shows a pair of images and captions that differ only by one of these aspects.  The task is to evaluate a model's ability to correctly match the image and caption pair that share the same underlying meaning, despite the minimal differences.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_27_1.jpg", "caption": "Figure 1: Overview of our VisMin benchmark. VisMin consists of four types of minimal-changes \u2013 object, attribute, count and spatial relation \u2013 between two image-captions pairs. The evaluation task requires a model to predict the correct image-caption match given: 1) two images and one caption, 2) two captions and one image.", "description": "This figure provides a visual overview of the VisMin benchmark. VisMin tests the capability of Visual Language Models (VLMs) to understand minimal changes between images and captions.  It shows four types of minimal changes: object, attribute, count, and spatial relation. Each type is represented by an example image pair and a corresponding caption pair showing the change.  The evaluation requires a model to correctly match the image and captions, given either two images and one caption or two captions and one image.", "section": "1 Introduction"}, {"figure_path": "bJddXCyosA/figures/figures_28_1.jpg", "caption": "Figure 3: VisMin categories and subcategories.", "description": "This figure shows a donut chart illustrating the distribution of minimal changes across various categories and subcategories in the VisMin benchmark.  The main categories are object, attribute, count, and spatial relation. Each category is further broken down into more specific subcategories such as color, material, shape for attribute, etc. The chart visually represents the proportion of each subcategory within the overall benchmark, providing insight into the balance and complexity of the different minimal changes.", "section": "4 Training and Benchmark sets"}]