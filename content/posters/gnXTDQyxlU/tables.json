[{"figure_path": "gnXTDQyxlU/tables/tables_5_1.jpg", "caption": "Table 1: Success rate and speed comparison of different methods in four levels of tasks (%).", "description": "This table compares the performance of different models (Gato, BC-Z, Octo, SUSIE, RT-1, GR-1, Surfer, and PIVOT-R) across four levels of robotic manipulation tasks.  For each model, it shows the success rate (percentage of tasks successfully completed) for each task level and the average success rate across all levels.  It also provides the average time (in milliseconds) taken for each model to complete a single step in the manipulation tasks.  The numbers in parentheses indicate the relative improvement of PIVOT-R compared to the best-performing baseline model.", "section": "4.3 Results on Robotic Manipulation"}, {"figure_path": "gnXTDQyxlU/tables/tables_7_1.jpg", "caption": "Table 2: Performance of different methods on three real robot manipulation tasks (%). \u201cPick up\u201d: pick up the correct object from the table. \"Put on\": Pick up the object and place it on the correct color block. \u201cPush to\": Push the object to the correct color block.", "description": "This table presents the performance comparison of different robotic manipulation models on three real-world tasks: picking up an object, placing an object on a colored block, and pushing an object to a colored block.  The performance metric is the success rate (percentage) for each task, averaged across multiple trials.  The table shows that PIVOT-R outperforms other state-of-the-art methods, indicating the effectiveness of the proposed approach.", "section": "4.3 Results on Robotic Manipulation"}, {"figure_path": "gnXTDQyxlU/tables/tables_8_1.jpg", "caption": "Table 3: Performance comparison on seen scenarios, different backgrounds, changing lights, and more distractors (%).", "description": "This table presents the results of experiments evaluating the generalization ability of different models, including PIVOT-R, across various scenarios.  It compares the success rates of the models under four different conditions: seen scenarios (standard testing conditions), unseen backgrounds, changing lighting conditions, and increased distractions.  The results show how well the models generalize beyond the training data and their resilience to environmental variability.", "section": "4.4 Generalization Ability"}, {"figure_path": "gnXTDQyxlU/tables/tables_8_2.jpg", "caption": "Table 1: Success rate and speed comparison of different methods in four levels of tasks (%)", "description": "This table presents a comparison of the success rates and inference times of various models on four levels of robotic manipulation tasks from the SeaWave benchmark.  Each level represents increasing complexity in the language instructions provided to the robot.  The table shows the average success rate across all four levels, along with the average time taken (in milliseconds) for each model to perform a single manipulation step. This allows for a comparison of not only the performance of different models but also their efficiency.  The values in parentheses indicate the relative improvement or decrease in performance compared to the best baseline model.", "section": "4.3 Results on Robotic Manipulation"}, {"figure_path": "gnXTDQyxlU/tables/tables_14_1.jpg", "caption": "Table 1: Success rate and speed comparison of different methods in four levels of tasks (%)", "description": "This table presents a comparison of the success rates and inference speeds of various robotic manipulation models across four different difficulty levels.  It shows the performance of several state-of-the-art (SOTA) models and the proposed PIVOT-R model. The success rate indicates the percentage of times each model successfully completed a given manipulation task, while the inference speed (in milliseconds) reflects the time taken for the model to execute a single step in the task. The table highlights the relative improvement achieved by PIVOT-R compared to the other models.", "section": "4.3 Results on Robotic Manipulation"}, {"figure_path": "gnXTDQyxlU/tables/tables_14_2.jpg", "caption": "Table 1: Success rate and speed comparison of different methods in four levels of tasks (%)", "description": "This table presents a comparison of the success rates and inference speeds of various models on four different levels of robotic manipulation tasks from the SeaWave benchmark.  It shows the average success rate across all four levels for each model, allowing for a comparison of overall performance.  The time column indicates the average inference time in milliseconds per step for each model.", "section": "4.3 Results on Robotic Manipulation"}, {"figure_path": "gnXTDQyxlU/tables/tables_16_1.jpg", "caption": "Table 1: Success rate and speed comparison of different methods in four levels of tasks (%)", "description": "This table presents a comparison of the success rates and inference speeds of various models on four different levels of robotic manipulation tasks from the SeaWave benchmark.  Higher success rates indicate better performance in completing the tasks, and lower inference times represent greater efficiency.  The table shows that PIVOT-R outperforms other state-of-the-art models in terms of both success rate and efficiency.", "section": "4.3 Results on Robotic Manipulation"}, {"figure_path": "gnXTDQyxlU/tables/tables_16_2.jpg", "caption": "Table 1: Success rate and speed comparison of different methods in four levels of tasks (%)", "description": "This table compares the success rates and speeds of various models (Gato, BC-Z, Octo, SUSIE, RT-1, GR-1, Surfer, and PIVOT-R) across four different levels of manipulation tasks in the SeaWave benchmark.  Each level represents an increase in complexity in terms of the instructions given to the robot. The table shows PIVOT-R's significant performance improvement compared to other models, as well as its inference speed.", "section": "4.3 Results on Robotic Manipulation"}, {"figure_path": "gnXTDQyxlU/tables/tables_18_1.jpg", "caption": "Table 9: Experimental results for training with additional human data.", "description": "This table presents the results of experiments where additional human data was used to train the PIVOT-R model.  It compares the model's performance (success rate) on four different levels of tasks across various scenarios (seen, unseen backgrounds, changing lights, distractors). Three training methods are compared: original training (Origin), co-training (Co-Train), and pre-training (Pre-Train). The table shows that incorporating additional human data may improve model generalization in certain scenarios, although the co-training approach did not show significant improvements.", "section": "4.5 Ablation Study"}, {"figure_path": "gnXTDQyxlU/tables/tables_19_1.jpg", "caption": "Table 10: Performance comparison of different methods on SIMPLER benchmark (%). SIMPLER is a simulation benchmark which evaluation can be a scalable, reproducible, and reliable proxy for real-world evaluation. It selects four tasks from Bridgedata.", "description": "This table presents the success rate of four different models (RT-1-X, Octo-Base, Octo-Small, and PIVOT-R) on four subtasks within the SIMPLER benchmark.  The benchmark is designed to be scalable, reproducible, and a reliable stand-in for real-world testing, focusing on tasks involving the manipulation of various objects (spoon, carrot, green block, eggplant).  The results show the success rate for each model on each subtask, with the average success rate across all four tasks also provided. This data helps to evaluate the performance and generalization abilities of the models in a controlled environment.", "section": "4. Experiments"}]