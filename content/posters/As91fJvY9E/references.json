{"references": [{"fullname_first_author": "Abadi, M.", "paper_title": "TensorFlow: a system for Large-Scale machine learning", "publication_date": "2016-00-00", "reason": "This paper introduces TensorFlow, a widely used machine learning framework, crucial for implementing and running the ELCRec model."}, {"fullname_first_author": "Caron, M.", "paper_title": "Deep clustering for unsupervised learning of visual features", "publication_date": "2018-00-00", "reason": "This paper introduces a deep clustering method which is foundational to the ELCRec model's learnable clustering module."}, {"fullname_first_author": "He, K.", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduces Masked Autoencoders, a self-supervised learning technique that is relevant to the intent-assisted contrastive learning component in ELCRec."}, {"fullname_first_author": "Vaswani, A.", "paper_title": "Attention is all you need", "publication_date": "2017-00-00", "reason": "This paper introduces the Transformer architecture, a key component of the behavior encoding module in ELCRec."}, {"fullname_first_author": "Chen, Y.", "paper_title": "Intent contrastive learning for sequential recommendation", "publication_date": "2022-00-00", "reason": "This paper is highly relevant as it introduces intent contrastive learning, a concept directly related to and influential upon the methodology of ELCRec."}]}