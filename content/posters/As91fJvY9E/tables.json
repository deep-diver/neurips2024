[{"figure_path": "As91fJvY9E/tables/tables_6_1.jpg", "caption": "Table 1: Recommendation performance on benchmarks. Bold values and underlined values denote the best and runner-up results. * indicates that, in the t-test, the best method significantly outperforms the runner-up with p < 0.05. \"-\" indicates models do not converge.", "description": "This table presents the performance comparison of the proposed ELCRec model against nine state-of-the-art recommendation baselines across four benchmark datasets (Sports, Beauty, Toys, and Yelp).  Metrics used for comparison include HR@5, HR@20, NDCG@5, and NDCG@20.  Bold values highlight the best performing method for each metric on each dataset, while underlined values indicate the second-best. The p-value from a t-test is provided to show statistical significance of improvements.  A hyphen indicates that a particular model failed to converge during training.", "section": "4.1 Superiority"}, {"figure_path": "As91fJvY9E/tables/tables_8_1.jpg", "caption": "Table 2: Running time and memory costs. Bold values denote better results.", "description": "This table presents a comparison of the running time (in seconds) and GPU memory usage (in MB) for both ICLRec and ELCRec across four benchmark datasets (Sports, Beauty, Toys, Yelp).  The \"Improvement\" row indicates the percentage change in running time and memory consumption between ICLRec and ELCRec for each dataset, showing whether ELCRec is more efficient in terms of both time and memory.", "section": "4.3 Efficiency"}, {"figure_path": "As91fJvY9E/tables/tables_9_1.jpg", "caption": "Table 3: A/B testing on real-time large-scale industrial recommendation. Bold values denotes the significant improvements with p < 0.05. The symbol \"-\" denotes business secret.", "description": "This table presents the results of A/B testing on a real-time, large-scale industrial recommendation system.  It compares the performance of a baseline method against the proposed ELCRec method across four key metrics: Page View Click Through Rate (PVCTR) and Video View (VV) for livestreaming metrics, and PVCTR and User View Click Through Rate (UVCTR) for merchandise metrics.  Bold values indicate statistically significant improvements (p<0.05) achieved by ELCRec. Hyphens indicate that the data is confidential.", "section": "5 Application"}, {"figure_path": "As91fJvY9E/tables/tables_9_2.jpg", "caption": "Table 3: A/B testing on real-time large-scale industrial recommendation. Bold values denotes the significant improvements with p < 0.05. The symbol \"-\" denotes business secret.", "description": "This table presents the results of A/B testing on a real-time large-scale industrial recommendation system.  It compares the performance of a baseline method against the proposed ELCRec method, using two key metrics: PVCTR (Page View Click Through Rate) and VV (Video View) for livestreaming metrics, and PVCTR and UVCTR (User View Click Through Rate) for merchandise metrics. Bold values indicate statistically significant improvements (p<0.05) achieved by ELCRec.  The \"-\" symbol represents business-sensitive data that could not be disclosed.", "section": "5 Application"}, {"figure_path": "As91fJvY9E/tables/tables_18_1.jpg", "caption": "Table 1: Recommendation performance on benchmarks. Bold values and underlined values denote the best and runner-up results. * indicates that, in the t-test, the best method significantly outperforms the runner-up with p < 0.05. \"-\" indicates models do not converge.", "description": "This table presents a comparison of the proposed ELCRec model against nine state-of-the-art recommendation baselines across four benchmark datasets (Sports, Beauty, Toys, and Yelp).  For each dataset, multiple evaluation metrics are shown, including Hit Ratio@5 (HR@5), Hit Ratio@20 (HR@20), Normalized Discounted Cumulative Gain@5 (NDCG@5), and NDCG@20.  Bold values highlight the best performing method for each metric and dataset, while underlined values indicate the second-best performance. The \"*\" symbol signifies statistical significance (p<0.05) according to a t-test, meaning the best method significantly outperforms the runner-up.  \"-\" indicates that a model failed to converge during training.", "section": "4.1 Superiority"}, {"figure_path": "As91fJvY9E/tables/tables_19_1.jpg", "caption": "Table 1: Recommendation performance on benchmarks. Bold values and underlined values denote the best and runner-up results. * indicates that, in the t-test, the best method significantly outperforms the runner-up with p < 0.05. \"-\" indicates models do not converge.", "description": "This table presents the performance comparison of different recommendation models on four benchmark datasets (Sports, Beauty, Toys, and Yelp).  The metrics used to evaluate the models include HR@5, HR@20, NDCG@5, and NDCG@20. Bold values indicate the best performance for each metric on each dataset, while underlined values represent the second-best performance. The '*' symbol indicates that the best-performing model is statistically significantly better than the second-best model (p < 0.05).  '-' signifies that a model failed to converge during training.", "section": "4.1 Superiority"}, {"figure_path": "As91fJvY9E/tables/tables_19_2.jpg", "caption": "Table 1: Recommendation performance on benchmarks. Bold values and underlined values denote the best and runner-up results. * indicates that, in the t-test, the best method significantly outperforms the runner-up with p < 0.05. \"-\" indicates models do not converge.", "description": "This table presents the performance comparison of ELCRec with nine state-of-the-art recommendation methods across four benchmark datasets (Sports, Beauty, Toys, and Yelp).  The metrics used for evaluation are HR@5, HR@20, NDCG@5, and NDCG@20.  Bold values highlight the best performance for each metric on each dataset, and underlined values indicate the second-best performance.  The * symbol shows statistically significant improvements over the runner-up according to a t-test (p < 0.05).  A hyphen indicates that the method did not converge.", "section": "4.1 Superiority"}, {"figure_path": "As91fJvY9E/tables/tables_20_1.jpg", "caption": "Table 8: Recommendation performance on ML-1M dataset. Bold values denote the best results. * indicates the p-value<0.05.", "description": "This table presents the performance comparison between ICLRec and ELCRec on the MovieLens 1M dataset.  The metrics used are HR@5, HR@20, NDCG@5, and NDCG@20.  Bold values indicate the best performance for each metric, and the * symbol indicates statistical significance (p-value < 0.05).  The \"Impro.\" row shows the percentage improvement of ELCRec over ICLRec, and the final row gives the p-values from the statistical significance test.", "section": "4.1 Superiority"}, {"figure_path": "As91fJvY9E/tables/tables_20_2.jpg", "caption": "Table 9: Recommendation performance on MIND-small dataset. Bold values denote the best results. * indicates the p-value<0.05.", "description": "This table presents the performance comparison of the proposed ELCRec model against the ICLRec baseline on the MIND-small dataset.  The metrics used for comparison are HR@5, HR@20, NDCG@5, and NDCG@20, which are standard measures of ranking quality in recommender systems.  Bold values highlight the best results obtained by ELCRec, while the * symbol next to p-values indicates statistical significance (p<0.05), demonstrating that ELCRec's superior performance is not due to random chance. The \"Impro.\" row shows the percentage improvement of ELCRec over ICLRec for each metric.", "section": "4.1 Superiority"}, {"figure_path": "As91fJvY9E/tables/tables_21_1.jpg", "caption": "Table 1: Recommendation performance on benchmarks. Bold values and underlined values denote the best and runner-up results. * indicates that, in the t-test, the best method significantly outperforms the runner-up with p < 0.05. \"-\" indicates models do not converge.", "description": "This table presents the performance of various recommendation models on four benchmark datasets (Sports, Beauty, Toys, and Yelp).  It compares the proposed ELCRec model against nine state-of-the-art baselines across four metrics: HR@5, HR@20, NDCG@5, and NDCG@20.  Bold values highlight the best performance for each metric and dataset, while underlined values indicate the second-best performance. The '*' symbol denotes statistically significant outperformance (p<0.05) of the best model compared to the second-best model.  '-' indicates cases where a model failed to converge.", "section": "4.1 Superiority"}, {"figure_path": "As91fJvY9E/tables/tables_22_1.jpg", "caption": "Table 2: Running time and memory costs. Bold values denote better results.", "description": "This table presents a comparison of the running time (in seconds) and GPU memory usage (in MB) for three different methods: ICLRec, ELCRec, and S3-Rec.  The comparison is done across four different datasets: Sports, Beauty, Toys, and Yelp.  Bold values indicate better performance in terms of lower running time and memory usage. The table aims to demonstrate the efficiency gains of the proposed ELCRec method in terms of both time and memory consumption compared to existing approaches.", "section": "4.3 Efficiency"}, {"figure_path": "As91fJvY9E/tables/tables_28_1.jpg", "caption": "Table 1: Recommendation performance on benchmarks. Bold values and underlined values denote the best and runner-up results. * indicates that, in the t-test, the best method significantly outperforms the runner-up with p < 0.05. \"-\" indicates models do not converge.", "description": "This table presents the performance comparison of the proposed ELCRec model against nine state-of-the-art recommendation baselines across four benchmark datasets (Sports, Beauty, Toys, and Yelp).  The metrics used for comparison are HR@5, HR@20, NDCG@5, and NDCG@20.  Bold values highlight the best-performing model for each metric and dataset, while underlined values indicate the second-best performance.  The asterisk (*) indicates statistically significant improvements (p<0.05) of the best model over the second-best.  A hyphen (-) signifies that the model did not converge.", "section": "4.1 Superiority"}]