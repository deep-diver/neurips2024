[{"figure_path": "kN7GTUss0l/figures/figures_4_1.jpg", "caption": "Figure 1: Similar values of Wasserstein distance, different effect on posteriors. For visualization purposes, only the posterior means of two posterior GPs (blue for \u03bcD and orange for \u03bcD) are depicted, along a single dimension (e.g., time). The Wasserstein distance between the two posteriors is shown by the green shaded area. The GPs have a small lengthscale (left) or, conversely, a large lengthscale (right) for the chosen dimension.", "description": "This figure compares two pairs of posterior Gaussian processes (GPs).  Each pair has the same 2-Wasserstein distance (0.46), which quantifies the difference between the two distributions. However, the left pair shows GPs that are very similar while the right pair shows GPs that are very different. This illustrates how the length scale of the GP significantly influences the shape of the posterior distribution even when the overall Wasserstein distance remains constant.", "section": "3 A Wasserstein Distance-Based Criterion"}, {"figure_path": "kN7GTUss0l/figures/figures_4_2.jpg", "caption": "Figure 1: Similar values of Wasserstein distance, different effect on posteriors. For visualization purposes, only the posterior means of two posterior GPs (blue for \u03bcD and orange for \u03bcD) are depicted, along a single dimension (e.g., time). The Wasserstein distance between the two posteriors is shown by the green shaded area. The GPs have a small lengthscale (left) or, conversely, a large lengthscale (right) for the chosen dimension.", "description": "This figure shows the effect of the lengthscale parameter on the Wasserstein distance between two Gaussian Process (GP) posterior distributions.  Two pairs of GP posteriors are displayed, each with a similar Wasserstein distance. However, the left pair, generated with a small lengthscale, displays similar posterior means, while the right pair, with a large lengthscale, exhibits significantly different means. The shaded area visually represents the Wasserstein distance between the posteriors in each case.", "section": "3 A Wasserstein Distance-Based Criterion"}, {"figure_path": "kN7GTUss0l/figures/figures_7_1.jpg", "caption": "Figure 3: (Left) Sensitivity analysis on the Eggholder function. (Right) Aggregation of sensitivity analyses of W-DBO made on 10 synthetic functions and a real-world experiment. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of W-DBO over all the experiments is shown in black. Standard errors are depicted with colored bars (left) and shaded areas (right).", "description": "The left plot shows the sensitivity analysis of the hyperparameter \u03b1 in the W-DBO algorithm on the Eggholder function. The right plot shows the aggregation of sensitivity analyses across multiple synthetic functions and a real-world experiment. It demonstrates how the average regret of W-DBO is impacted by changes in \u03b1. Standard errors are included to show uncertainty in the results.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_8_1.jpg", "caption": "Figure 3: (Left) Sensitivity analysis on the Eggholder function. (Right) Aggregation of sensitivity analyses of W-DBO made on 10 synthetic functions and a real-world experiment. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of W-DBO over all the experiments is shown in black. Standard errors are depicted with colored bars (left) and shaded areas (right). parameters and the noise level are estimated on the fly.", "description": "The left plot shows the sensitivity analysis of the hyperparameter  \u03b1 on the Eggholder function. The right plot aggregates the sensitivity analysis results of  \u03b1 across 10 different synthetic functions and one real-world experiment. The average regrets are normalized for easy comparison. The results show that W-DBO achieves the best performance with \u03b1=1.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_9_1.jpg", "caption": "Figure 5: Visual summary of the results reported in Table 2. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of the DBO solutions is shown in black.", "description": "This figure provides a visual summary of the results presented in Table 2.  The average regrets for each experiment, across different DBO algorithms (GP-UCB, ABO, ET-GP-UCB, R-GP-UCB, TV-GP-UCB, and W-DBO), have been normalized to a range of 0 to 1 for easier comparison.  The average performance across all experiments is shown in black, offering a concise overview of W-DBO's performance relative to other algorithms.", "section": "Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_18_1.jpg", "caption": "Figure 6: (Top row) Absolute approximation error (55) with respect to the spatial lengthscale ls for a 1, 3 and 5-dimensional spatial domain. Both error terms in (55) are shown in orange and green dashed lines, respectively. Finally, the critical lengthscale (56) is shown as a red vertical line. In this example, ks is a SE correlation function. (Bottom row) Relative approximation error with respect to the spatial lengthscale ls. The color codes are the same.", "description": "This figure shows the absolute and relative approximation errors of equation (55) for different spatial dimensions (1, 3, and 5). The top row displays the absolute error, while the bottom row shows the relative error. Both plots show the individual errors from the first and second terms in equation (55) and the overall error. The critical length scale is marked by a red line. The figure illustrates how the approximation error varies with the spatial lengthscale and dimension.", "section": "C Approximation Error"}, {"figure_path": "kN7GTUss0l/figures/figures_18_2.jpg", "caption": "Figure 6: (Top row) Absolute approximation error (55) with respect to the spatial lengthscale ls for a 1, 3 and 5-dimensional spatial domain. Both error terms in (55) are shown in orange and green dashed lines, respectively. Finally, the critical lengthscale (56) is shown as a red vertical line. In this example, ks is a SE correlation function. (Bottom row) Relative approximation error with respect to the spatial lengthscale ls. The color codes are the same.", "description": "This figure shows the absolute and relative approximation errors for equation (55) in the paper.  The approximation error is plotted against the spatial lengthscale (ls) for 1, 3, and 5-dimensional spatial domains.  The figure helps to visualize how the approximation error varies with the lengthscale and dimensionality, highlighting a critical lengthscale where the error is maximal.", "section": "C Approximation Error"}, {"figure_path": "kN7GTUss0l/figures/figures_26_1.jpg", "caption": "Figure 8: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Rastrigin synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Rastrigin synthetic function.", "description": "This figure shows the performance comparison of different Dynamic Bayesian Optimization (DBO) algorithms on the Rastrigin function. The left panel displays the average response time against the average regret, while the right panel illustrates the dataset size over time.  This provides insights into the trade-off between computational cost (response time and dataset size) and optimization performance (regret).", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_27_1.jpg", "caption": "Figure 9: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Schwefel synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Schwefel synthetic function.", "description": "This figure shows the performance comparison of different Dynamic Bayesian Optimization (DBO) algorithms on the Schwefel function. The left panel displays the average response time against the average regret, indicating the trade-off between computational cost and optimization performance.  The right panel shows the dataset size of each algorithm over time, highlighting how the algorithms manage data over the optimization process. The results illustrate the performance differences between various DBO algorithms in terms of both accuracy and computational efficiency.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_27_2.jpg", "caption": "Figure 9: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Schwefel synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Schwefel synthetic function.", "description": "The left plot shows the average response time and average regret for different DBO algorithms on the Schwefel function. The right plot displays the dataset size of each algorithm over time.  The figure illustrates the tradeoff between response time (dataset size) and optimization performance for various DBO methods.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_28_1.jpg", "caption": "Figure 11: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Styblinski-Tang synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Styblinski-Tang synthetic function.", "description": "This figure shows the performance of different DBO algorithms on the Styblinski-Tang function. The left panel shows the average response time against the average regret, indicating the trade-off between computational cost and optimization performance.  The right panel displays the dataset size over time for each algorithm, highlighting how the size of the dataset used by each algorithm changes during the optimization process.  This illustrates the impact of different strategies on dataset management. The algorithms compared include GP-UCB, ABO, ET-GP-UCB, R-GP-UCB, TV-GP-UCB, and W-DBO.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_28_2.jpg", "caption": "Figure 3: (Left) Sensitivity analysis on the Eggholder function. (Right) Aggregation of sensitivity analyses of W-DBO made on 10 synthetic functions and a real-world experiment. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of W-DBO over all the experiments is shown in black. Standard errors are depicted with colored bars (left) and shaded areas (right).", "description": "The left plot shows the sensitivity analysis of the W-DBO algorithm on the Eggholder function by varying the hyperparameter \u03b1. The right plot aggregates the sensitivity analysis results over multiple synthetic functions and a real-world experiment, showing the average performance of W-DBO for different values of \u03b1.  Both plots illustrate the trade-off between dataset size and sampling frequency.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_29_1.jpg", "caption": "Figure 3: (Left) Sensitivity analysis on the Eggholder function. (Right) Aggregation of sensitivity analyses of W-DBO made on 10 synthetic functions and a real-world experiment. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of W-DBO over all the experiments is shown in black. Standard errors are depicted with colored bars (left) and shaded areas (right). parameters and the noise level are estimated on the fly.", "description": "The left plot shows the sensitivity analysis of the W-DBO algorithm's hyperparameter  \u03b1 on the Eggholder function. The right plot aggregates the sensitivity analyses across 10 synthetic functions and one real-world experiment, normalizing the average regrets. The black line represents the average performance of W-DBO across all experiments.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_29_2.jpg", "caption": "Figure 3: (Left) Sensitivity analysis on the Eggholder function. (Right) Aggregation of sensitivity analyses of W-DBO made on 10 synthetic functions and a real-world experiment. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of W-DBO over all the experiments is shown in black. Standard errors are depicted with colored bars (left) and shaded areas (right). parameters and the noise level are estimated on the fly.", "description": "The left plot shows the sensitivity analysis of the hyperparameter  \u03b1  on the Eggholder function. The right plot shows the aggregated sensitivity analysis results across 10 synthetic functions and one real-world experiment, where average regrets are normalized for better comparison. The plots illustrate the effect of the hyperparameter  \u03b1  on the performance of the W-DBO algorithm.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_30_1.jpg", "caption": "Figure 15: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Rosenbrock synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Rosenbrock synthetic function.", "description": "This figure presents a comparison of different dynamic Bayesian Optimization (DBO) algorithms on the Rosenbrock function.  The left panel shows a scatter plot of the average regret (y-axis) versus the average response time (x-axis) for each algorithm. The right panel displays the dataset size of each algorithm over the optimization duration (x-axis). The plots reveal trade-offs between algorithm performance and computational cost. ", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_30_2.jpg", "caption": "Figure 16: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Shekel synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Shekel synthetic function.", "description": "This figure shows a comparison of different Bayesian Optimization (BO) algorithms on the Shekel synthetic function.  The left panel displays average regret (a measure of optimization performance) plotted against average response time. The right panel shows the dataset size of each algorithm over the optimization time. This allows for a comparison of performance, runtime, and dataset management strategies.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_31_1.jpg", "caption": "Figure 17: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Hartmann-3 synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Hartmann-3 synthetic function.", "description": "This figure compares the performance of different DBO algorithms on the Hartmann-3 benchmark function.  The left panel shows average regret (lower is better) plotted against average response time. The right panel shows how the size of the dataset used by each algorithm changes over the duration of the optimization.  It provides insights into the trade-off between computational cost and optimization performance for each method, particularly highlighting the impact of observation removal strategies.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_31_2.jpg", "caption": "Figure 18: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Hartmann-6 synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Hartmann-6 synthetic function.", "description": "This figure shows the performance comparison of different dynamic Bayesian optimization (DBO) algorithms on the Hartmann-6 benchmark function. The left panel displays the average regret (a measure of performance) against the average response time of each algorithm. The right panel illustrates the dataset size of each algorithm over the optimization duration.  The comparison helps in understanding the trade-off between the accuracy of the model and computational efficiency of different DBO approaches in handling dynamic optimization problems. W-DBO is shown to achieve a good balance.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_32_1.jpg", "caption": "Figure 19: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Powell synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Powell synthetic function.", "description": "This figure shows the results of six different DBO algorithms on the Powell synthetic function. The left panel shows the average response time (x-axis) and average regret (y-axis). The right panel shows the dataset sizes used by each algorithm over the duration of the optimization. The results indicate that W-DBO outperforms the other algorithms in terms of both response time and average regret. In addition, W-DBO keeps the dataset size relatively small compared to the other algorithms.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_32_2.jpg", "caption": "Figure 20: (Left) Average response time and average regrets of the DBO solutions during the Temperature real-world experiment. (Right) Dataset sizes of the DBO solutions during the Temperature real-world experiment.", "description": "This figure shows the performance comparison of different DBO algorithms on a real-world temperature dataset.  The left panel displays average regret against average response time, illustrating the trade-off between accuracy and efficiency. The right panel shows the dataset size over time for each algorithm, highlighting how different methods manage data over time. The results demonstrate W-DBO's superior performance in balancing accuracy and dataset size.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_33_1.jpg", "caption": "Figure 21: (Left) Average response time and average regrets of the DBO solutions during the WLAN real-world experiment. (Right) Dataset sizes of the DBO solutions during the WLAN real-world experiment.", "description": "This figure shows the performance of different DBO algorithms on a real-world WLAN dataset.  The left panel displays the average regret (lower is better) plotted against the average response time of each algorithm. The right panel shows the dataset size used by each algorithm over the duration of the experiment.  This allows for a comparison of the trade-off between response time (which affects sampling frequency and the ability to track the optimum) and predictive accuracy (which relates to the regret).  The plot helps assess the efficiency and effectiveness of each DBO algorithm in balancing these competing factors.", "section": "5 Numerical Results"}, {"figure_path": "kN7GTUss0l/figures/figures_34_1.jpg", "caption": "Figure 22: Snapshot from one of the videos showing the optimization conducted by W-DBO. The normalized temporal dimension is shown on the x-axis and the normalized spatial dimension is shown on the y-axis. The observations that are in the dataset are depicted as red dots, while the deleted observations are depicted as black crosses. The maximal arguments \\{arg max_{x\u2208S} f(x,t), t \u2208 T\\} are depicted with a cyan curve. The predictions of W-DBO are shown with a contour plot. Finally, the present time is depicted as a black vertical line labelled t0.", "description": "This figure shows a snapshot of an animation from the paper that illustrates the W-DBO algorithm in action.  It displays the algorithm's performance on a 2D problem where the x-axis represents the normalized time and the y-axis represents the normalized space.  Red dots show observations currently used in the model, black crosses show observations that have been deemed irrelevant and discarded, and the cyan line traces the path of the algorithm's best guess of the optimal solution over time.  The contour plot displays the algorithm's predictions of the objective function.  The vertical line labeled 't0' indicates the current time.", "section": "H.4 Animated Visualizations"}]