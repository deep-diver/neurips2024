[{"type": "text", "text": "Instance-Specific Asymmetric Sensitivity in Differential Privacy ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "David Durfee Mozilla Anonym ddurfee@mozilla.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We provide a new algorithmic framework for differentially private estimation of general functions that adapts to the hardness of the underlying dataset. We build upon previous work that gives a paradigm for selecting an output through the exponential mechanism based upon closeness of the inverse to the underlying dataset, termed the inverse sensitivity mechanism. Our framework will slightly modify the closeness metric and instead give a simple and efifcient application of the sparse vector technique. While the inverse sensitivity mechanism was shown to be instance optimal, it was only with respect to a class of unbiased mechanisms such that the most likely outcome matches the underlying data. We break this assumption in order to more naturally navigate the bias-variance tradeof,f which will also critically allow for extending our method to unbounded data. In consideration of this tradeof,f we provide theoretical guarantees and empirical validation that our technique will be particularly effective when the distances to the underlying dataset are asymmetric. This asymmetry is inherent to a range of important problems including fundamental statistics such as variance, as well as commonly used machine learning performance metrics for both classification and regression tasks. We efifciently instantiate our method in $O(n)$ time for these problems and empirically show that our techniques will give substantially improved differentially private estimations. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the general problem of estimating aggregate functions or statistics of a dataset with differential privacy. The massive increase in data collection to improve analytics and modelling across industries has made such data computations invaluable, but can also leak sensitive individual information. Rigorously measuring such leakage can be achieved through differential privacy, which quantifies the extent that one individual\u2019s data can affect the output. Much of the focus within the field of differential privacy is upon constructing algorithms that give both accurate output and privacy guarantees by injecting specific types of randomness. One of the most canonical mechanisms for achieving this considers the maximum effect one individual\u2019s data could have upon the output of a given function, referred to as the sensitivity of the function, and adds proportional noise to the function output. In general, the notion of sensitivity plays a central role in many differentially private algorithms, directly affecting the accuracy of the output. ", "page_idx": 0}, {"type": "text", "text": "While using the worst-case sensitivity across all potential datasets will ensure privacy guarantees, the utility can be improved by using variants of sensitivity that are specific to the underlying dataset. This notion was initially considered in Nissim et al. (2007), introducing smooth sensitivity, an interpolation between worst-case sensitivity and local sensitivity of the underlying data, by which noise could be added proportionally. The smooth sensitivity adapts well to the underlying data and was further extended to other commonly used variants of the original privacy definition Bun & Steinke (2019). ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "More aggressive methods were also considered with a data-independent conjectured sensitivity parameter and more accurate results provided when the underlying data complies with the parameter. The propose-test-release methods check that all datasets close to the underlying data have sensitivity below a parameter and add noise proportional when the criteria is met and fail otherwise Dwork & Lei (2009); Thakurta & Smith (2013). Preprocessing methods provide an approximation of the function with sensitivity below a given parameter by which noise can be added proportionally and the approximation is accurate for underlying data with low sensitivity Chen & Zhou (2013); Blocki et al. (2013); Kasiviswanathan et al. (2013); Cummings & Durfee (2020). Clipping techniques, commonly seen in differentially private stochastic gradient descent Abadi et al. (2016), are also a more rudimentary and efifcient preprocessing method for ensuring sufifciently small sensitivity. The primary challenge with these approaches is the sensitivity parameter must be specified a priori and can add significant bias if the underlying data does not comply with the parameter. ", "page_idx": 1}, {"type": "text", "text": "In contrast, the inverse sensitivity mechanism directly improves upon the smooth sensitivity technique adapting even better to the underlying data. While several instantiations had been previously known in the literature, it was introduced in it\u2019s full generality in Asi & Duchi (2020b). Specifically, this framework considers all potential outputs based upon the closeness of their inverse to the underlying data and applies the exponential mechanism to select a point accordingly. This exact methodology can even improve upon adding noise proportional to the local sensitivity of the underlying data, which generally violates differential privacy. Follow-up work gave approximations of this method that allow for efifcient implementations of more complex instantiations Asi & Duchi (2020a). For both the exact and approximate versions, the inverse sensitivity mechanism is instance optimal and nearly instance optimal, respectively, under certain assumptions Asi & Duchi (2020a,b). ", "page_idx": 1}, {"type": "text", "text": "1.1 Our techniques ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We build upon the inverse sensitivity mechanism, particularly within the class of functions for which it was shown to be optimal. However, those guarantees only held for a class of unbiased mechanisms such that the most likely outcome matches the underlying data. The inverse sensitivity mechanism and smooth sensitivity techniques fit this characterization of unbiased. The methods that specify a data-independent sensitivity parameter break this assumption by essentially fixing the variance through this parameter but adding significant bias if the variance parameter is set too low. Our method will also break the unbiased assumption but still adapt well to the underlying data to more naturally navigate the bias-variance tradeof.f ", "page_idx": 1}, {"type": "text", "text": "In particular, we similarly consider the distance from the underlying data to the inverse of each possible output, which can be considered the inverse sensitivity. However, we instead invoke the well-known sparse vector technique, originally introduced in Dwork et al. (2009), to select an output close to the underlying data. The iterative nature of sparse vector technique will create a slight bias, while still adapting well to the underlying data. By utilizing this iterative technique, we can also better take advantage when the sensitivities are asymmetric that allows us to reduce the variance, and we thusly term our method the asymmetric sensitivity mechanism. In fact, the local sensitivity can be infinite with unbounded data and our technique can still naturally handle this setting for a wide variety of functions including our instantiations. We support this with theoretical utility guarantees that are asymptotically superior to previous work under these conditions. ", "page_idx": 1}, {"type": "text", "text": "Our notion of asymmetric sensitivities is inherent to a range of problems, and we first instantiate our method upon variance, a fundamental property of a dataset that is widely used in statistical analysis. Likewise, this property will also apply to commonly used machine learning performance metrics: cross-entropy loss, mean squared error (MSE), and mean absolute error (MAE). Model performance evaluation is an essential part of a machine learning pipeline, particularly for iterative improvement, so accurate and private evaluation is critical. We instantiate our method upon these functions as well, and give an extensive empirical study for each instantiation across a variety of datasets and privacy parameters. We show that our method significantly improves performance of private estimation for these important problems. We further complement our results with an approximate method that allows for more efifcient implementations of general functions while still preserving the asymmetry that we exploit for improved estimations. This will allow us to give $O(n)$ time implementations for each invocation of our method. ", "page_idx": 1}, {"type": "text", "text": "1.2 Additional related works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "While the most closely related literature was discussed in more detail previously, we provide additional related works here. Recent work considered instance-optimality but for estimators population quantities McMillan et al. (2022), which differ from the empirical quantities studied here and in the other previously mentioned work. Additional work formally considered the bias-varianceprivacy trade-of fparticularly for mean estimation Kamath et al. (2023), but considers bias in the more classical sense. Interestingly, it\u2019s also been seen in the work for obtaining (asymptotically) optimal mean estimation for subgaussian distributions Karwa & Vadhan (2018); Bun & Steinke (2019) and distributions satisfying bounded moment conditions Barber & Duchi (2014); Kamath et al. (2020), that adding bias was necessary. This fits with our results where bias, albeit a different type, was needed to improve instance-specific differential privacy. ", "page_idx": 2}, {"type": "text", "text": "1.3 Our contributions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We summarize our primary contributions as the following: ", "page_idx": 2}, {"type": "text", "text": "1. We introduce a new algorithmic framework for private estimation of general functions, which we refer to as the asymmetric sensitivity mechanism, along with a more computationally efifcient approximate variant (see Section 3).   \n2. We provide theoretical utility guarantees that asymptotically confirm our method\u2019s advantage when the sensitivities are asymmetric and further give intuition and empirical support of this asymmetric advantage (see Section 4)   \n3. We efifciently instantiate our method for private variance estimation, and provide an extensive empirical study showing significantly improved accuracy (see Section 5).   \n4. We further invoke our method upon model evaluation for both classification and regression tasks with corresponding efifcient implementations and empirical studies showing improved estimations (see Section 6). ", "page_idx": 2}, {"type": "text", "text": "Additional and supplemental analysis, results and empirical studies are pushed to the appendix. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "For simplicity and ease of comparison we borrow much of the notation from Asi & Duchi (2020a,b). Definition 2.1. Let $x,x^{\\prime}$ be datasets of our data universe $\\textstyle{\\mathcal{X}}^{n}$ . We define $d_{\\mathsf{h a m}}(\\boldsymbol{x},\\boldsymbol{x}^{\\prime})=|\\{i\\,:\\,\\boldsymbol{x}_{i}\\neq\\boldsymbol{x}_{i}^{\\prime}\\}|$ to be the Hamming distance between datasets. If $d_{\\mathsf{h a m}}(\\boldsymbol{x},\\boldsymbol{x}^{\\prime})\\leq1$ then $x,x^{\\prime}$ are neighboring datasets. ", "page_idx": 2}, {"type": "text", "text": "Note that we assume the swap definition of neighboring datasets but will also discuss how our results apply to the add-subtract definition in Appendix B.3. We further define the (global) sensitivity. ", "page_idx": 2}, {"type": "text", "text": "Definition 2.2. $f:\\mathcal{X}^{n}\\to\\mathbb{R}$ has sensitivity $\\Delta$ if for any neighboring datasets $|f(\\pmb{x})-f(\\pmb{x}^{\\prime})|\\leq\\Delta$ ", "page_idx": 2}, {"type": "text", "text": "We will be using the classical (pure) differential privacy definition, but will also discuss how our methods apply to other definitions with improved guarantees. ", "page_idx": 2}, {"type": "text", "text": "Definition 2.3. Dwork et al. (2006b,a) A mechanism $M:\\,\\mathcal{X}^{n}\\to\\mathcal{T}$ is $(\\varepsilon,\\delta)$ -differentially-private (DP) if for any neighboring datasets $\\pmb{x},\\pmb{x}^{\\prime}\\in\\mathcal{X}$ and measurable $S\\subseteq{\\mathcal{T}}$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{Pr}[M({\\pmb x})\\in S]\\leqslant e^{\\varepsilon}\\mathrm{Pr}[M({\\pmb x}^{\\prime})\\in S]+\\delta.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "If $\\delta=0$ then $M$ is $\\varepsilon$ -DP. ", "page_idx": 2}, {"type": "text", "text": "2.1 Sparse vector technique ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We define the fundamental sparse vector technique introduced in Dwork et al. (2009) and often considered to apply Laplacian noise Lyu et al. (2017). However, recent work showed the noise can instead be added from the exponential distribution at the same parameter for improved utility Durfee (2023). Let $\\mathsf{E x p o}(b)$ denote a draw from the exponential distribution with scale parameter $\\boldsymbol{b}$ . The sparse vector technique iteratively calls the following algorithm. ", "page_idx": 2}, {"type": "text", "text": "This technique can further see improvement when the queries are monotonic which will apply to most of our instantiations of our method. ", "page_idx": 2}, {"type": "text", "text": "Require: Input dataset $_x$ , a stream of queries $\\{f_{i}\\,:\\,\\mathcal{X}^{n}\\to\\mathbb{R}\\}$ with sensitivity $\\Delta$ , and a threshold \ud835\udc47   \n1: Set $\\hat{T}=T+\\mathsf{E x p o}(\\Delta/\\varepsilon_{1})$   \n2: for each query \ud835\udc56do 3: Set $\\nu_{i}=\\mathsf{E x p o}(\\Delta/\\varepsilon_{2})$ 4: if $f_{i}({\\boldsymbol{x}})+\\nu_{i}\\geq{\\hat{T}}$ then   \n5: Output $\\top$ and halt 6: else   \n7: Output \u22a5 8: end if   \n9: end for ", "page_idx": 3}, {"type": "text", "text": "Definition 2.4. We say that stream of queries $\\{f_{i}\\,:\\,\\mathcal{X}^{n}\\to\\mathbb{R}\\}$ with sensitivity $\\Delta$ is monotonic if for any neighboring $x,x^{\\prime}\\in\\mathcal{X}^{n}$ we have either $f_{i}(x)\\leq f_{i}(x^{\\prime})$ for all $i$ or $f_{i}({\\pmb x})\\geq f_{i}({\\pmb x}^{\\prime})$ for all $i.$ . ", "page_idx": 3}, {"type": "text", "text": "This allows for the following differential privacy guarantees from Durfee (2023). Proposition 2.5. Algorithm 1 is $\\left(\\varepsilon_{1}+2\\varepsilon_{2}\\right)$ -DP in general and $(\\varepsilon_{1}+\\varepsilon_{2})$ -DP for monotonic queries ", "page_idx": 3}, {"type": "text", "text": "2.2 Inverse sensitivity mechanism ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The inverse sensitivity mechanism had seen several previous instantiations but was introduced in it\u2019s full generality in Asi & Duchi (2020b). We first introduce the exponential mechanism. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.6. McSherry & Talwar (2007) The Exponential Mechanism is a randomized mapping $M:\\mathcal{X}^{n}\\rightarrow\\mathcal{T}$ such that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[M(\\pmb{x})=t\\right]\\propto\\exp\\left(\\frac{\\varepsilon\\cdot q(\\pmb{x},t)}{2\\Delta}\\right)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $q:\\mathcal{X}^{n}\\times\\mathcal{T}\\rightarrow\\mathbb{R}$ has sensitivity $\\Delta$ . ", "page_idx": 3}, {"type": "text", "text": "Proposition 2.7. McSherry & Talwar (2007) The exponential mechanism is $\\varepsilon$ -DP ", "page_idx": 3}, {"type": "text", "text": "We then define the distance of a potential output from the underlying dataset to be the Hamming distance required to change the data such that the new data matches the output. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.8. For a function $f:\\mathcal{X}^{n}\\to\\mathcal{T}$ and $x\\in\\mathcal{X}^{n}$ , let the inverse sensitivity of $t\\in\\mathcal T$ be ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathsf{l e n}_{f}({\\boldsymbol x};t)\\ {\\stackrel{\\mathrm{def}}{=}}\\ \\operatorname*{inf}_{{\\boldsymbol x}^{\\prime}}\\{d_{\\mathsf{h a m}}({\\boldsymbol x},{\\boldsymbol x}^{\\prime})|f({\\boldsymbol x}^{\\prime})=t\\}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "By construction this distance metric for any output cannot change by more than one between neighboring datasets due to the triangle inequality for Hamming distance. ", "page_idx": 3}, {"type": "text", "text": "Corollary 2.9. For any neighboring datasets $x,x^{\\prime}\\in\\mathcal{X}^{n}$ and $t\\in\\mathrm{im}(f)$ where $\\mathrm{i}\\mathfrak{m}(f)\\subseteq\\mathcal{T}$ is the image of the function, we have $|\\mathsf{l e n}_{f}({\\pmb x};t)-\\mathsf{l e n}_{f}({\\pmb x}^{\\prime};t)|\\leq1$ ", "page_idx": 3}, {"type": "text", "text": "The inverse sensitivity mechanism then draws from the exponential mechanism instantiated upon the distance metric giving the density function ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi_{M_{\\mathrm{inv}}(x)}(t)=\\frac{e^{-1\\mathsf{e n}_{f}(x;t)\\varepsilon/2}}{\\int_{T}e^{-1\\mathsf{e n}_{f}(x;s)\\varepsilon/2}d s}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "and mechanism M.1 is $\\varepsilon$ -DP by Proposition 2.7 and Corollary 2.9. ", "page_idx": 3}, {"type": "text", "text": "3 Asymmetric Sensitivity Mechanism ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section we introduce our general methodology for instance-specific differentially private estimation, which we term the asymmetric sensitivity mechanism. We first give the exact formulation which will fit an extensive class of functions focused upon in Asi & Duchi (2020b). Next we provide a simple framework by which our method can be implemented. The efifciency of this implementation is highly dependent upon the function of interest, but we supplement these results with an approximate method. This can allow for broader efifcient implementations and also extends our methodology to general functions. While this section will set up and provide the necessary rigor for our techniques, we also point the reader to Appendix C for a more intuitive explanation of our approach compared to the inverse sensitivity mechanism. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "3.1 Exact asymmetric sensitivity mechanism ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our method will similarly consider the distance for each output from the underlying data with the goal being to select an output with distance close to zero. The inverse sensitivity mechanism does this through the exponential mechanism, but we will instead apply the sparse vector technique. In order to better apply the sparse vector technique, we will first modify the inverse sensitivity such that it is negative for outputs that are less than output from the underlying data. ", "page_idx": 4}, {"type": "text", "text": "Definition 3.1. For $f:\\mathcal{X}^{n}\\to\\mathbb{R}$ and $x\\in\\mathcal{X}^{n}$ , let the reflective inverse sensitivity of $t\\in\\mathbb{R}$ be ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathsf{s}_{f}(\\pmb{x};t)\\ {\\stackrel{\\mathrm{def}}{=}}\\ \\mathsf{s g n}(t-f(\\pmb{x}))\\left(\\mathsf{l e n}_{f}(\\pmb{x};t)-{\\frac{1}{2}}\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Intuitively, the goal of applying the sparse vector technique will be to identify when the reflective inverse sensitivity crosses the threshold from negative to positive. While there are reasonable methods of extending our approach to higher dimensions, it will both become computationally inefifcient and the notion of asymmetry, which gives our method the most significant improvement, is less inherent in higher dimensions. Initially, we focus upon a general class of functions considered in Asi & Duchi (2020b) that was shown to include all continuous functions from a convex domain. ", "page_idx": 4}, {"type": "text", "text": "Definition 3.2 (Definition 4.1 in Asi & Duchi (2020b)). Let $f\\,:\\,\\,\\mathcal{X}^{n}\\,\\rightarrow\\,\\mathbb{R}$ . Then $f$ is samplemonotone if for every $x\\,\\in\\,\\mathcal{X}^{n}$ and $s,t\\,\\in\\,\\mathbb{R}$ satisfying $f(\\pmb{x})\\,\\leq\\,s\\,\\leq\\,t$ or $t\\,\\leq\\,s\\,\\leq\\,f(x)$ , we have $\\mathtt{l e n}_{f}(x;s)\\leq\\mathtt{l e n}_{f}(x;\\dot{t})$ ", "page_idx": 4}, {"type": "text", "text": "For this class of functions, we show that the reflective inverse sensitivity of an output maintains closeness between neighboring datasets. Accordingly, we can apply the sparse vector technique to a stream of potential outputs in order to (noisily) identify when the reflective inverse sensitivity crosses the threshold from negative to positive. This gives the asymmetric sensitivity mechanism for a stream of potential outputs $\\left\\{t_{i}\\right\\}$ that calls AboveThreshold and returns $t_{k}$ when ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathtt{A b o v e T h r e s h o l d}({\\boldsymbol{x}},\\{{\\boldsymbol{s}}_{f}({\\boldsymbol{x}};t_{i})\\},T=0)=\\{\\perp^{k-1},\\top\\}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To be effective, this stream of potential outputs should be increasing (or decreasing if we flip the sign of $\\mathsf{s}_{f}$ ) but will still achieve the desired privacy guarantees regardless which is shown in Appendix A.2. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.3. Given sample-monotone $f:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ and any stream of potential outputs $\\{t_{i}\\}$ , we have that mechanism M.2 is $(\\varepsilon_{1}+2\\varepsilon_{2})\u2013D P$ in general and $\\big(\\varepsilon_{1}+\\varepsilon_{2}\\big){-}D P\\,i f{\\bf s}_{f}$ is monotonic. ", "page_idx": 4}, {"type": "text", "text": "We further detail in Appendix B a simple, general, and robust strategy for selecting potential outputs that provides a reasonable limit on the number of queries. ", "page_idx": 4}, {"type": "text", "text": "3.2 Implementation framework ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The primary bottleneck in efifciently implementing both our asymmetric sensitivity mechanism and the inverse sensitivity mechanism is the computation of the inverse sensitivity. In particular, it will require computing upper and lower output bounds for different Hamming distances from our underlying data. ", "page_idx": 4}, {"type": "text", "text": "Definition 3.4. For a function $f\\,:\\,\\mathcal{X}^{n}\\,\\rightarrow\\,\\mathbb{R}$ , we define the upper and lower output bounds for Hamming distance $\\ell$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U_{f}^{\\ell}(x)\\stackrel{\\mathrm{def}}{=}\\underset{x^{\\prime}}{\\operatorname*{sup}}\\{f(x^{\\prime}):d_{\\mathsf{h a m}}(x,x^{\\prime})\\leq\\ell\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\\\ &{L_{f}^{\\ell}(x)\\stackrel{\\mathrm{def}}{=}\\underset{x^{\\prime}}{\\operatorname*{inf}}\\{f(x^{\\prime}):d_{\\mathsf{h a m}}(x,x^{\\prime})\\leq\\ell\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and ", "page_idx": 4}, {"type": "text", "text": "The complexity of computing these depends upon the function, but we can use the upper and lower output bounds to get the inverse sensitivity with the following lemma proven in Appendix A.2. ", "page_idx": 5}, {"type": "text", "text": "If we then assume access to the array $L_{f}^{n}({\\pmb x}),...,L_{f}^{1}({\\pmb x}),f({\\pmb x}),U_{f}^{1}({\\pmb x}),...,U_{f}^{n}({\\pmb x}),$ for any potential output $t_{i}$ we can compute $\\mathtt{l e n}_{f}(x;t_{i})$ in $O(\\log(n))$ time with a simple binary search. Alternatively, we could also take $O(\\bar{n})$ amortized time by maintaining a pointer and iteratively increasing the index for each new potential output if we assume the stream of potential outputs are non-decreasing. This gives the general implementation framework: ", "page_idx": 5}, {"type": "text", "text": "1. Compute upper and lower output bounds $U_{f}^{\\ell}(x)$ and $L_{f}^{\\ell}(x)$ for all $\\ell\\in[n]$   \n2. Use the output bounds to efifciently run AboveThreshol ${\\mathsf{d}}({\\pmb x},\\{{\\mathsf{s}}_{f}({\\pmb x};t_{i})\\},T=0)$ ", "page_idx": 5}, {"type": "text", "text": "3.3 Approximate asymmetric sensitivity mechanism ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In Section A, we show how we can extend our asymmetric sensitivity mechanism to general functions $f:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ and provide more efifcient implementations. It will follow closely with our exact version above. ", "page_idx": 5}, {"type": "text", "text": "4 Asymmetric Sensitivity Advantage ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we first connect our definitions with the corresponding definitions in the previous work, by which utility guarantees are provided. Then we discuss the notion of asymmetric sensitivities and provide our utility guarantees that exploit this asymmetry to asymptotically improve upon the previous work under those conditions. ", "page_idx": 5}, {"type": "text", "text": "4.1 Connection to previous work ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "An essential quantity for our method and both inverse and smooth sensitivity mechanisms is the amount a function output can change if $k$ individuals change their data. This is quantified in Equation 3 from Asi & Duchi (2020b) which can be translated to our definitions (in the case when $\\bar{\\boldsymbol{\\tau}_{\\mathrm{~=~}}}\\bar{\\mathbb{R}}$ ) as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\omega_{f}(\\pmb{x};\\pmb{k})\\stackrel{\\mathrm{def}}{=}\\operatorname*{max}\\{|f(\\pmb{x})-L_{f}^{k}(\\pmb{x})|,|f(\\pmb{x})-U_{f}^{k}(\\pmb{x})|\\}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that if $k=1$ then this is the local sensitivity of the function. It\u2019s then shown in Asi & Duchi (2020b) (Corollary 4.2 and Equation 13, respectively) that the general utility guarantees of both inverse sensitivity mechanism and smooth sensitivity mechanism are bounded with respect to this quantity. More simply, the accuracy guarantees degrade as the local sensitivity increases and there is no utility bound if local sensitivity is infinite. ", "page_idx": 5}, {"type": "text", "text": "4.2 Asymmetric accuracy guarantees ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To understand the advantages of our method, we will consider the sensitivities to be asymmetric if $|f(\\pmb{x})-U_{f}^{k}(\\pmb{x})|>>|f(\\pmb{x})-L_{f}^{k}(\\pmb{x})|$ for most $k$ (or vice versa), which is to say that changing an individual\u2019s data can generally increase the function more than decrease it. In general, we expect any lower bounded function to inherently limit the amount changing one individual\u2019s data can decrease the function compared to increasing the function. Each instantiation in our empirical study is a non-negative function which then fits this characterization. For simplicity, we will restrict our consideration to non-negative functions for our utility guarantees, but can easily apply these to other settings. ", "page_idx": 5}, {"type": "text", "text": "The goal for our method is to exploit the asymmetric sensitivities by instead applying the sparse vector technique. The iterative nature of this technique biases the output towards being less than $f(x)$ , but more importantly the $U_{f}^{k}({\\boldsymbol{x}})$ values will have little effect upon the accuracy. Specifically, once the threshold is crossed it becomes increasingly unlikely that the sparse vector technique will proceed. Explicitly connecting this with our mechanism, even if $U_{1}^{k}(\\dot{{\\boldsymbol{x}}})=\\infty$ and so the local sensitivity is infinite, we still have ${\\mathsf{s}}_{f}(x;t_{i})=1/2$ for all $t_{i}>f(x)$ and assuming $t_{i}$ is increasing it is increasingly unlikely that we output larger $t_{i}>f(x)$ . ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "We formalize this intuition by providing a theoretical utility guarantee that does not depend upon the upper bound values. Essentially, we are able to replace the $|f(\\pmb{x})-U_{f}^{k}(\\pmb{x})|$ in $\\omega_{f}(\\bar{x_{\\mathrm{;}}}k)$ with a relative error bound based upon a parameter that we fix across all our empirical instantiations. Accordingly, as $U_{f}^{1}(x)\\rightarrow\\infty$ and thereby asymmetry increases and also local sensitivity increases, our utility guarantees are asymptotically superior to both inverse and smooth sensitivity mechanisms. ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.1. Let \ud835\udc40denote the mechanism from M.2 with $t_{i}=\\beta^{i}\\!-\\!1$ where $\\beta>1$ and we let $\\varepsilon=\\varepsilon_{1}\\!+\\!2\\varepsilon_{2}$ with $\\varepsilon_{1}=\\varepsilon_{2}$ in the call to Algorithm 1. Given non-negative sample monotone $f:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ we have ", "page_idx": 6}, {"type": "equation", "text": "$$\nP r\\left[|M(x)-f(x)|<\\operatorname*{max}\\{|f(x)-L^{\\log k+1}(x)|,(\\beta^{k}-1)(f(x)+1)\\}\\right]>1-O\\left(\\frac{1}{k e^{\\epsilon/6}}\\right)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "for any $x\\in\\mathcal{X}^{n}$ such that $f(\\pmb{x})\\leq\\beta^{O(1)}$ . ", "page_idx": 6}, {"type": "text", "text": "We provide the proof in Appendix C along with further intuition and empirical evidence of our asymmetric advantage. We also extend these results to general non-negative functions in Corollary C.4 by applying our approximate variant to achieve the same guarantees. We set $\\beta=1.005$ in all our empirical studies and also note that our method is robust to reasonable choices of the $\\beta$ parameter (Appendix B.2). ", "page_idx": 6}, {"type": "text", "text": "5 Private Variance Estimation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we instantiate our asymmetric sensitivity mechanism upon variance, a fundamental property of a dataset that is widely used in statistical analysis. ", "page_idx": 6}, {"type": "text", "text": "Definition 5.1. Let $\\mathcal{X}=\\mathbb{R}$ and for $x\\in\\mathcal{X}^{n}$ we let $\\textstyle{\\bar{\\pmb{x}}}={\\frac{1}{n}}\\sum_{i=1}^{n}\\pmb{x}_{i}$ and define ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{Var}\\left[x\\right]\\stackrel{\\mathrm{def}}{=}\\frac1n\\sum_{i=1}^{n}(x_{i}-\\Bar{x})^{2}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "There has been extensive work in the privacy literature upon covariance estimation for univariate and multivariate Gaussians with a focus upon optimizing asymptotic performance1. Our focus here will be practical methods for general data, so a rigorous comparison to all these methods for Gaussians is untenable and outside the scope of this work. ", "page_idx": 6}, {"type": "text", "text": "We first show how the variance instantiation of asymmetric sensitivity can be implemented efifciently and give intuition upon why we expect asymmetric sensitivities for this function. Next we give a detailed empirical study that confirms this intuition, showing that our method will substantially outperform inverse sensitivity on the task of variance estimation. ", "page_idx": 6}, {"type": "text", "text": "5.1 Efifcient variance instantiation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "As seen in Section 3.2, we need to efifciently provide upper and lower output bounds in order to achieve an efifcient implementation. We first consider the lower output bounds and can provide the exact bounds from Definition 3.4 which we prove in Appendix D. ", "page_idx": 6}, {"type": "text", "text": "Lemma 5.2. Given $\\pmb{x}\\in\\mathbb{R}^{n}$ , i $f{\\pmb x}_{1}\\leq\\dots\\leq{\\pmb x}_{n}$ are ordered then we have lower output bounds ", "page_idx": 6}, {"type": "equation", "text": "$$\nL_{\\mathbf{Var}}^{\\ell}(x)=\\frac{n-\\ell}{n}\\operatorname*{min}_{0\\leq i\\leq\\ell}\\mathbf{Var}\\left[x_{[\\ell+1-i:n-i]}\\right]\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where we let $\\pmb{x}_{[\\ell+1-i:n-i]}\\overset{\\mathrm{def}}{=}(\\pmb{x}_{\\ell+1-i},...,\\pmb{x}_{n-i})$ ", "page_idx": 6}, {"type": "text", "text": "1See Karwa & Vadhan (2018); Du et al. (2020); Biswas et al. (2020); Kamath et al. (2019); Bun et al. (2019); Aden-Ali et al. (2021); Ashtiani $\\&$ Liaw (2022); Kothari et al. (2022); Tsfadia et al. (2022); Liu et al. (2022); Kamath et al. (2022) ", "page_idx": 6}, {"type": "text", "text": "While the formula above immediately suggests an $O(n^{2})$ time computation of all the lower output bounds, we will further prove in Appendix D that we can use our approximation to get a more efifcient implementation. In particular, we consider a data independent fixed distance and only compute the exact bounds outputs closer to the underlying data to still ensure accurate estimations. ", "page_idx": 7}, {"type": "text", "text": "Lemma 5.3. Given $x\\in\\mathbb{R}^{n}$ and $c\\ge0$ , we can compute all approximate output bounds $\\bar{L}_{\\mathbf{Var}}^{\\ell}(x)=$ $L_{\\mathbf{Var}}^{\\ell}(x)$ for $\\ell\\leq c$ and $\\bar{L}_{\\mathbf{Var}}^{\\ell}(x)=0$ for $\\ell>c$ in $O(n+c^{2})$ time. ", "page_idx": 7}, {"type": "text", "text": "Next we consider the upper output bounds, but if the data is unbounded then we must have $U_{\\mathbf{Var}}^{1}(x)=\\infty$ . It is precisely for this reason that asymmetric sensitivities are inherent for variance. Our method can naturally handle this setting and we show in Appendix B.1 that unbounded upper output bounds barely affects our accuracy. However, applying the inverse sensitivity mechanism requires reasonable bounds upon each data point that should be data-independent and also sufifciently loose to not add bias from clipping data points. ", "page_idx": 7}, {"type": "text", "text": "Lemma 5.4. If we restrict all values to the interval $[a,b]$ then given $x\\in[a,b]^{n}$ we can give approximate upper output bounds ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\overline{{U}}_{\\mathbf{Var}}^{\\ell}(x)=\\mathbf{Var}\\left[x\\right]+\\frac{\\ell(b-a)^{2}}{n}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "To our knowledge, there is no efifcient method for computing the exact upper output bounds for general data (contained in a range), so to maintain practicality we provide approximate bounds, proven in Appendix D. ", "page_idx": 7}, {"type": "table", "img_path": "4I2aEav51N/tmp/c853fd4c1375c750faa8799c7aa383d4c6a16b98063279d967935d90a6194d2b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Theorem 5.5. Algorithm 2 is $\\left(\\varepsilon_{1}+2\\varepsilon_{2}\\right)$ -DP and has a runtime of $O(n+q)$ where $q$ is the number of queries in AboveThreshold ", "page_idx": 7}, {"type": "text", "text": "Proof. If we assume the domain is restricted to $[a,b]^{n}$ then the privacy guarantees follow from Lemma 5.3 and Lemma 5.4 applied to Theorem A.4. If not then we apply Lemma 5.3 and $\\bar{U}_{{\\bf V a r}}^{1}(x)=$ $\\infty$ to Theorem A.4 to get our privacy guarantees. ", "page_idx": 7}, {"type": "text", "text": "For the runtime, computing all $\\bar{L}_{\\mathbf{Var}}^{\\ell}(x)$ is $O(n)$ time by Lemma 5.3 and fixing $c~=~100$ , and computing all $\\overline{{U}}_{\\mathbf{Var}}^{\\ell}(x)$ is $O(n)$ time. Finally, we can run AboveThreshold in $O(n+q)$ time as seen in Section 3.2 \u53e3 ", "page_idx": 7}, {"type": "text", "text": "In our implementations we\u2019ll more reasonably assume $\\beta\\geq1.001$ , so $\\beta^{50000}>10^{21}$ and we\u2019ll simply terminate AboveThreshold after at most 50,000 queries for all datasets without affecting the privacy guarantees. This then gives a runtime of $O(n)$ . ", "page_idx": 7}, {"type": "text", "text": "5.2 Empirical study of variance estimation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "For our instantiations of machine learning model evaluation we will be using the following datasets for regression tasks: Diamonds dataset containing diamond prices and related features Wickham (2016); Abalone dataset containing age of abalone and related features Nash et al. (1995); and Bike dataset containing number of bike rentals and related features Fanaee-T (2013). We will also use the labels from these datasets to test our variance invocation. We also use the Adult dataset, Becker & Kohavi (1996), for model evaluation of classification tasks so we will borrow two of the features, age and hours worked per week, to test our variance invocation. ", "page_idx": 7}, {"type": "text", "text": "While our method does not require any bounds on the data to still maintain high accuracy (see Appendix B.1), it is necessary for the other mechanisms. All of our data is inherently non-negative and some data has innate upper bounds. If not, we use reasonable upper bounds, which should be data independent, to avoid adding bias from clipping the data. We use the following bounds: [0,50000] for diamond prices; [0,50] for abalone ages; [0,5000] for city bike rentals; [0,168] for hours; and [0,125] for age. Our algorithm (Algorithm 2 in Appendix D) will have a parameter $\\beta$ which we fix $\\beta=1.005$ and will maintain this consistency across all experiments. We further show in Appendix B.2 that our method is robustly accurate across reasonable $\\beta$ choices. ", "page_idx": 7}, {"type": "image", "img_path": "4I2aEav51N/tmp/43d65ddabf3db7940ec83812d87032eb8264e39296414ac4c2cabaa607311e81.jpg", "img_caption": ["Figure 1: Plots comparing each method for estimating variance. For each privacy parameter we sample 1,000 datapoints from the dataset and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "For each privacy parameter, we repeat 100 times: sample 1,000 datapoints from the dataset and call each mechanism on the sampled data for estimates. We plot the average absolute error for each method along with confidence intervals of 0.9 in Figure 5.2. As expected, we see that our approach of variance estimation sees substantially less error across privacy parameters and datasets. ", "page_idx": 8}, {"type": "text", "text": "6 Private Machine Learning Model Evaluation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we invoke our asymmetric sensitivity mechanism upon commonly used metrics for machine learning model evaluation for both classification and regression tasks. In particular, we consider cross-entropy loss for classification tasks, and mean squared error (MSE) and mean absolute error (MAE) for regression tasks. Note that combining our improved estimation for variance in Section 5 with the improved estimation for MSE also implies an improved estimation of the coefifcient of determination, $R^{2}$ , also commonly used for evaluating regression performance. ", "page_idx": 8}, {"type": "text", "text": "We provide full definitions along with technical analysis in Section E. ", "page_idx": 8}, {"type": "text", "text": "6.1 Empirical study of model evaluation for classification ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "For our empirical study of model evaluation for classification tasks we will consider two tabular datasets with binary labels, the Adult dataset Becker & Kohavi (1996) and Diabetes dataset Efron et al. (2004), along with two computer vision tasks with 10 classes, the mnist dataset LeCun et al. (2010) and cifar10 dataset Krizhevsky et al. (2009). Our focus here is upon the accuracy of our evaluation, not optimizing the quality of the model itself. As such, we will be using reasonable choices for models for simplicity but certainly not state-of-the-art models . ", "page_idx": 8}, {"type": "text", "text": "For the tabular data, we partition into train and test with an 80/20 split and train with an xgboost classifier with the default parameters. For the mnist data, which is already partitioned, we use a simple MLP with one inner dense layer of 128 neurons and relu activation, and the final layer of 10 neurons has a softmax activation. We train this model for 5 epochs. For the cifar10 data, which is already partitioned, we use a relatively small CNN with several pooling and convolutional layers, and several dense layers at the end with relu activation and final layer with softmax activation. We train this model for 10 epochs. ", "page_idx": 8}, {"type": "image", "img_path": "4I2aEav51N/tmp/c193fd5e1d8efed4f235263dac0f6f25fe8a9ad978fe8278a9a059aa3bcada76.jpg", "img_caption": ["Figure 2: Plots comparing each method for estimating cross entropy loss. For each privacy parameter we both sample 1,000 datapoints from the test set and call each mechanism 100 times, plotting the average absolute error with 0.9 confidence intervals. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Again our method does not require any bounds on the data to maintain high accuracy, but it is necessary for the inverse sensitivity mechanism. Given the softmax activation for our models, the outputs are unbounded, but we will provide reasonable bounds. We will use the bounds [-10,10] of the model output for binary classification tabular data, and bounds $[-25,25]^{10}$ of the model output for the multi-classification vision data. Once again, we fix our parameter $\\beta=1.005$ . ", "page_idx": 9}, {"type": "text", "text": "6.2 Empirical study of model evaluation for regression ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "As discussed in Section 5, our machine learning model evaluations for regression will use the following datasets: Diamonds dataset containing diamond prices and related features Wickham (2016); Abalone dataset containing age of abalone and related feature Nash et al. (1995); and Bike dataset containing number of bike rentals and related feature Fanaee-T (2013). We also use the same parameters from Section 5 for these datasets. Once again, our goal here is to accurately assess the quality of the model and not optimize performance. As such we simply train with xgboost regressor under default parameters after partitioning each dataset into train and test with an 80/20 split. ", "page_idx": 9}, {"type": "image", "img_path": "4I2aEav51N/tmp/54cd05e22738ad3443a962ed9b95629323e59f16bc49baa68d0e7db73ce1b368.jpg", "img_caption": ["We first consider mean squared error estimation and repeat 100 times for each privacy parameter: draw 1,000 datapoints from the test set and call each mechanism 100 times for estimates. We then plot the average absolute error along with confidence intervals of 0.9. We repeat this process for mean absolute error. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "4I2aEav51N/tmp/7bb8e80101fe1f2c7d7fdbe48bf63a5e76bd3572826e0774ef8267891dfd261f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B., Mironov, I., Talwar, K., and Zhang, L. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pp. 308\u2013318, 2016.   \nAden-Ali, I., Ashtiani, H., and Kamath, G. On the sample complexity of privately learning unbounded high-dimensional gaussians. In Algorithmic Learning Theory, pp. 185\u2013216. PMLR, 2021.   \nAshtiani, H. and Liaw, C. Private and polynomial time algorithms for learning gaussians and beyond. In Conference on Learning Theory, pp. 1075\u20131076. PMLR, 2022.   \nAsi, H. and Duchi, J. C. Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms. Advances in neural information processing systems, 33:14106\u201314117, 2020a.   \nAsi, H. and Duchi, J. C. Near instance-optimality in differential privacy. arXiv preprint arXiv:2005.10630, 2020b.   \nBarber, R. F. and Duchi, J. C. Privacy and statistical risk: Formalisms and minimax bounds. arXiv preprint arXiv:1412.4451, 2014.   \nBecker, B. and Kohavi, R. Adult. UCI Machine Learning Repository, 1996. DOI: https://doi.org/10.24432/C5XW20.   \nBiswas, S., Dong, Y., Kamath, G., and Ullman, J. Coinpress: Practical private mean and covariance estimation. Advances in Neural Information Processing Systems, 33:14475\u201314485, 2020.   \nBlocki, J., Blum, A., Datta, A., and Sheffet, O. Differentially private data analysis of social networks via restricted sensitivity. In Proceedings of the 4th conference on Innovations in Theoretical Computer Science, pp. 87\u201396, 2013.   \nBun, M. and Steinke, T. Average-case averages: Private algorithms for smooth sensitivity and mean estimation. Advances in Neural Information Processing Systems, 32, 2019.   \nBun, M., Kamath, G., Steinke, T., and Wu, S. Z. Private hypothesis selection. Advances in Neural Information Processing Systems, 32, 2019.   \nChen, S. and Zhou, S. Recursive mechanism: towards node differential privacy and unrestricted joins. In Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data, pp. 653\u2013664, 2013.   \nCummings, R. and Durfee, D. Individual sensitivity preprocessing for data privacy. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 528\u2013547. SIAM, 2020.   \nDu, W., Foot, C., Moniot, M., Bray, A., and Groce, A. Differentially private confidence intervals. arXiv preprint arXiv:2001.02285, 2020.   \nDurfee, D. Unbounded differentially private quantile and maximum estimation. arXiv preprint arXiv:2305.01177, 2023.   \nDwork, C. and Lei, J. Differential privacy and robust statistics. In Proceedings of the forty-first annual ACM symposium on Theory of computing, pp. 371\u2013380, 2009.   \nDwork, C., Kenthapadi, K., McSherry, F., Mironov, I., and Naor, M. Our data, ourselves: Privacy via distributed noise generation. In Advances in Cryptology-EUROCRYPT 2006: 24th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St. Petersburg, Russia, May 28-June 1, 2006. Proceedings 25, pp. 486\u2013503. Springer, 2006a.   \nDwork, C., McSherry, F., Nissim, K., and Smith, A. Calibrating noise to sensitivity in private data analysis. In Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3, pp. 265\u2013284. Springer, 2006b.   \nDwork, C., Naor, M., Reingold, O., Rothblum, G. N., and Vadhan, S. On the complexity of differentially private data release: efifcient algorithms and hardness results. In Proceedings of the forty-first annual ACM symposium on Theory of computing, pp. 381\u2013390, 2009.   \nDwork, C., Roth, A., et al. The algorithmic foundations of differential privacy. Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407, 2014.   \nEfron, B., Hastie, T., Johnstone, I., and Tibshirani, R. Diabetes dataset. https://web.stanford. edu/\\~hastie/Papers/LARS/LeastAngle_2002.pdf, 2004.   \nFanaee-T, H. Bike Sharing Dataset. UCI Machine Learning Repository, 2013. DOI: https://doi.org/10.24432/C5W894.   \nKamath, G., Li, J., Singhal, V., and Ullman, J. Privately learning high-dimensional distributions. In Conference on Learning Theory, pp. 1853\u20131902. PMLR, 2019.   \nKamath, G., Singhal, V., and Ullman, J. Private mean estimation of heavy-tailed distributions. In Conference on Learning Theory, pp. 2204\u20132235. PMLR, 2020.   \nKamath, G., Mouzakis, A., Singhal, V., Steinke, T., and Ullman, J. A private and computationallyefifcient estimator for unbounded gaussians. In Conference on Learning Theory, pp. 544\u2013572. PMLR, 2022.   \nKamath, G., Mouzakis, A., Regehr, M., Singhal, V., Steinke, T., and Ullman, J. A bias-variance-privacy trilemma for statistical estimation. arXiv preprint arXiv:2301.13334, 2023.   \nKarwa, V. and Vadhan, S. Finite sample differentially private confidence intervals. In 9th Innovations in Theoretical Computer Science Conference (ITCS 2018). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2018.   \nKasiviswanathan, S. P., Nissim, K., Raskhodnikova, S., and Smith, A. Analyzing graphs with node differential privacy. In Theory of Cryptography: 10th Theory of Cryptography Conference, TCC 2013, Tokyo, Japan, March 3-6, 2013. Proceedings, pp. 457\u2013476. Springer, 2013.   \nKothari, P., Manurangsi, P., and Velingker, A. Private robust estimation by stabilizing convex relaxations. In Conference on Learning Theory, pp. 723\u2013777. PMLR, 2022.   \nKrizhevsky, A., Nair, V., and Hinton, G. Cifar-10 (canadian institute for advanced research, cifar-10 dataset). https://www.cs.toronto.edu/\\~kriz/cifar.html, 2009.   \nLeCun, Y., Cortes, C., and Burges, C. Mnist handwritten digit database. AT&T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist, 2010.   \nLiu, X., Kong, W., and Oh, S. Differential privacy and robust statistics in high dimensions. In Conference on Learning Theory, pp. 1167\u20131246. PMLR, 2022.   \nLyu, M., Su, D., and Li, N. Understanding the sparse vector technique for differential privacy. Proceedings of the VLDB Endowment, 10(6), 2017.   \nMcMillan, A., Smith, A., and Ullman, J. Instance-optimal differentially private estimation. arXiv preprint arXiv:2210.15819, 2022.   \nMcSherry, F. and Talwar, K. Mechanism design via differential privacy. In 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS\u201907), pp. 94\u2013103. IEEE, 2007.   \nNash, W., Sellers, T., Talbot, S., Cawthorn, A., and Ford, W. Abalone. UCI Machine Learning Repository, 1995. DOI: https://doi.org/10.24432/C55C7W.   \nNissim, K., Raskhodnikova, S., and Smith, A. Smooth sensitivity and sampling in private data analysis. In Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, pp. 75\u201384, 2007.   \nSmith, A. Privacy-preserving statistical estimation with optimal convergence rates. In Proceedings of the forty-third annual ACM symposium on Theory of computing, pp. 813\u2013822, 2011.   \nThakurta, A. G. and Smith, A. Differentially private feature selection via stability arguments, and the robustness of the lasso. In Conference on Learning Theory, pp. 819\u2013850. PMLR, 2013. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Tsfadia, E., Cohen, E., Kaplan, H., Mansour, Y., and Stemmer, U. Friendlycore: Practical differentially private aggregation. In International Conference on Machine Learning, pp. 21828\u201321863. PMLR, 2022. ", "page_idx": 12}, {"type": "text", "text": "Wickham, H. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016. ISBN 978-3-319-24277-4. URL https://ggplot2.tidyverse.org. ", "page_idx": 12}, {"type": "text", "text": "A Additional Analysis of Asymmetric Sensitivity Mechanism ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we give full details upon extending our asymmetric sensitivity mechanism to general functions $f:\\mathcal{X}^{n}\\overset{\\mathcal{\\tau}}{\\rightarrow}\\mathbb{R}$ and provide more efifcient implementations. We also provide all missing proofs from Section 3. ", "page_idx": 13}, {"type": "text", "text": "A.1 Approximate asymmetric sensitivity mechanism ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "As noted in Section 3, computing the upper and lower outputs bounds can be inefifcient or even infeasible, which is necessary for our method, inverse sensitivity method, and smooth sensitivity method. As such we provide an approximation of these bounds that is a slightly more granular version of the approximation method provided in Asi & Duchi (2020a) and also applies to the inverse sensitivity mechanism. ", "page_idx": 13}, {"type": "text", "text": "Definition A.1. For a function $f:\\mathcal{X}^{n}\\to\\mathbb{R},$ , we define approximate upper and lower sensitivity bounding functions of Hamming distance $\\ell$ to be $\\overline{{U}}_{f}^{\\ell}:\\,\\bar{\\mathcal{X}^{n}}\\!^{\\!-}\\!\\to\\!\\mathbb{R}$ and $\\bar{L}_{f}^{\\bar{\\ell}}\\,\\d:\\,\\mathcal{X}^{n}\\to\\mathbb{R},$ , if for all $\\ell\\geq0$ and any neighboring datasets $x,x^{\\prime}\\in\\mathcal{X}^{n}$ we have $\\overline{{{U}}}_{f}^{\\ell}(x)\\geq U_{f}^{\\ell}(x)$ and $\\ {\\overline{{U}}}_{f}^{\\ell}(x)\\leq{\\overline{{U}}}_{f}^{\\ell+1}(x^{\\prime})$ along with $\\bar{L}_{f}^{\\ell}(x)\\leq L_{f}^{\\ell}(x)$ and $\\bar{L}_{f}^{\\ell}(x)\\geq\\bar{L}_{f}^{\\ell+1}(x^{\\prime})$ ", "page_idx": 13}, {"type": "text", "text": "In particular, this definition separates the approximation for the upper vs lower bounds as opposed to treating them symmetrically. This maintains asymmetry which is precisely where our technique excels most. We then define a variant of closeness for each output to the underlying data which utilizes these approximate upper and lower bounds. ", "page_idx": 13}, {"type": "text", "text": "Definition A.2. For a function $f:\\mathcal{X}^{n}\\to\\mathbb{R}$ along with $\\overline{{U}}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ and $\\bar{L}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ , for any $t\\in\\mathbb{R}$ , we let ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\overline{{{\\mathsf{l e n}_{f}}}}(x;t)\\overset{\\mathrm{def}}{=}\\operatorname*{inf}\\{\\ell:\\bar{L}_{f}^{\\ell}(x)\\leq t\\leq\\overbar{U}_{f}^{\\ell}(x)\\}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Outputs can only be closer to the underlying data under this approximate definition which could hurt accuracy, but will still give the desired privacy for inverse sensitivity mechanism. We then extend this definition equivalently for our reflective inverse sensitivity. ", "page_idx": 13}, {"type": "text", "text": "Definition A.3. For a function $f:\\mathcal{X}^{n}\\to\\mathbb{R}$ along with $\\overline{{U}}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ and $\\bar{L}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ , for any $t\\in\\mathbb{R}$ , we let ", "page_idx": 13}, {"type": "equation", "text": "$$\n{\\overline{{s_{f}}}}({\\pmb x};t)\\ {\\stackrel{\\mathrm{def}}{=}}\\ \\mathrm{sgn}(t-f({\\pmb x}))\\left({\\overline{{1\\mathrm{e}\\mathsf{n}_{f}}}}({\\pmb x};t)-\\frac{1}{2}\\right)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We will then be able to show in general that the approximate reflective inverse sensitivity of an output maintains closeness between neighboring datasets. This gives the approximate asymmetric sensitivity mechanism for a stream of potential outputs $\\{t_{i}\\}$ that calls AboveThreshold and returns $t_{k}$ when ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathtt{A b o v e T h r e s h o l d}({\\boldsymbol{x}},\\{\\overline{{s_{f}}}({\\boldsymbol{x}};t_{i})\\},T=0)=\\{\\perp^{k-1},\\top\\}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "This will then achieve the same privacy guarantees which is shown in Appendix A.3. ", "page_idx": 13}, {"type": "text", "text": "Theorem A.4. Given $f:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ and any stream of potential outputs $\\{t_{i}\\}$ , we have that mechanism $M.3$ is $\\left(\\varepsilon_{1}+2\\varepsilon_{2}\\right)$ -DP in general and $(\\varepsilon_{1}+\\varepsilon_{2}){\\cdot}D P\\,i f{\\overline{{\\mathsf{s}_{f}}}}$ is monotonic. ", "page_idx": 13}, {"type": "text", "text": "A.2 Analysis for exact asymmetric sensitivity mechanism ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We first prove a helper lemma regarding the closeness of the reflective inverse sensitivities for neighboring datasets. ", "page_idx": 13}, {"type": "text", "text": "Lemma A.5. Given sample-monotone $f:\\mathcal{X}^{n}\\to\\mathbb{R}$ , we must have $\\mathrm{i}\\,\\mathfrak{m}(f)$ is a convex set, and for any neighboring datasets $x,x^{\\bar{\\prime}}\\in\\mathcal{X}^{n}$ and \ud835\udc61\u2208im $(f)$ we have $|s_{f}(\\pmb{x};t)-s_{f}(\\pmb{x}^{\\prime};t)|\\leq1$ ", "page_idx": 13}, {"type": "text", "text": "Proof. We first show the image is convex. For any $a,b\\in\\mathrm{im}(f)$ , there must be datasets $x_{a},x_{b}\\in\\mathcal{X}^{n}$ such that $f(\\pmb{x}_{a})=a$ and $f(\\pmb{x}_{b})=b$ . Furthermore, by Definition 2.1 we know $d_{\\mathsf{h a m}}(\\pmb{x}_{a},\\pmb{x}_{b})\\leq n$ , so $\\begin{array}{r}{\\mathsf{l e n}_{f}(x_{a};b)\\leq n}\\end{array}$ . Without loss of generality assume $a\\leq b$ , then by Definition 3.2 for any $c\\in[a,b]$ we must have $\\mathsf{l e n}_{f}(x_{a};c)\\leq n$ which implies $c\\in\\mathrm{i}\\mathsf{m}(f)$ . ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Next we show the closeness between neighboring datasets. First consider the case when $t~>$ $\\operatorname*{max}\\{f(x),f(x^{\\prime})\\}$ or $t\\,<\\,\\mathrm{min}\\{f(x),f(x^{\\prime})\\}$ . This implies $\\operatorname{sgn}(t-f(\\pmb{x}))\\,=\\,\\operatorname{sgn}(t-f(\\pmb{x}^{\\prime}))$ and the bound follows from Corollary 2.9. Without loss of generality, assume $f(\\pmb{x})\\geq f(\\pmb{x}^{\\prime})$ and consider the other case when $f({\\pmb x})\\geq t\\geq f({\\pmb x}^{\\prime})$ . Due to the fact that they\u2019re neighboring le $\\mathsf{n}_{f}(\\pmb{x};f(\\pmb{x}^{\\prime}))\\leq1$ and len ${\\bf\\Phi}_{f}({\\bf x}^{\\prime};f({\\bf x}))\\le1$ . Applying Definition 3.2, $\\mathsf{l e n}_{f}(\\boldsymbol{x};t)\\le1$ and $\\mathsf{l e n}_{f}(\\pmb{x}^{\\prime};t)\\leq1$ which implies $\\left|\\mathsf{s}_{f}(x;t)\\right|\\le1/2$ and $|\\mathsf{s}_{f}(\\underline{{\\boldsymbol{x}}}^{\\prime};t)|\\leq\\bar{1}/2$ giving the desired bound. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "With this lemma we can prove Theorem 3.3. ", "page_idx": 14}, {"type": "text", "text": "Proof of Theorem 3.3. For $t_{i}\\in\\dot{\\mathfrak{i}}\\mathfrak{m}(f)$ we know the sensitivity is at most 1 from Lemma A.5. Further if $t_{i}\\notin\\mathsf{i m}(f)$ then by the convexity of $\\mathrm{i}\\,{\\mathsf{m}}(f)$ from Lemma A.5 we know that either $t_{i}<f(x)$ and so ${\\sf s}_{f}(x,t)=-\\infty$ for all $x\\in\\mathcal{X}^{n}$ or $t_{i}>f(x)$ and so ${\\sf s}_{f}(x,t)=\\infty$ for all $x\\in\\mathcal{X}^{n}$ . The privacy guarantees then follow from Proposition 2.5. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "We also provide a proof of Lemma 3.5 connecting the inverse sensitivities to the upper and lower output bounds for sample-monotone functions. ", "page_idx": 14}, {"type": "text", "text": "Proof of Lemma 3.5. First consider the case when $t<L_{f}^{n}(x)$ or $t>U_{f}^{n}(x)$ , which implies $\\operatorname{inf}\\!\\{\\ell:$ $L_{f}^{\\ell}(x)\\leq t\\leq U_{f}^{\\ell}(x)\\}=\\infty$ because the infimum of the empty set is infinity. This also implies that $t\\not\\in$ ${\\mathrm{i}}\\,{\\mathsf{m}}(f)$ so ${\\sf l e n}_{f}({\\pmb x};t)=\\infty$ for the same reason. Next, consider the other case when $L_{f}^{n}(x)\\leq t\\leq U_{f}^{n}(x)$ and le $\\mathrm{t}\\,k=\\operatorname*{inf}\\{\\ell:L_{f}^{\\ell}(\\pmb{x})\\leq t\\leq U_{f}^{\\ell}(\\pmb{x})\\}$ . If there exists $x^{\\prime}$ such that $f(\\pmb{x}^{\\prime})=t$ and $d_{\\mathsf{h a m}}(x,x^{\\prime})=k^{\\prime}<k,$ then this would imply $L_{f}^{k^{\\prime}}({\\pmb x})\\leq t\\leq U_{f}^{k^{\\prime}}({\\pmb x})$ , so $\\operatorname*{inf}\\{\\ell:L_{f}^{\\ell}(x)\\leq t\\leq U_{f}^{\\ell}(x)\\}<k$ giving a contradiction. Thus we must have $\\mathsf{l e n}_{f}({\\boldsymbol{x}};t)\\geq k$ . Furthermore, the sample-monotone definition implies that ${\\mathsf{l e n}}_{f}({\\boldsymbol{x}};t)\\leq k$ because $L_{f}^{\\dot{k}}({\\pmb x})\\leq t\\leq U_{f}^{k}({\\pmb x})$ . Therefore, we also have ${\\sf l e n}_{f}({\\pmb x};t)=k$ . ", "page_idx": 14}, {"type": "text", "text": "A.3 Analysis for approximate asymmetric sensitivity mechanism ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We again prove a helper lemma regarding the closeness of the approximate inverse sensitivities for neighboring datasets. ", "page_idx": 14}, {"type": "text", "text": "Lemma A.6. Given $f\\,:\\,{\\mathcal{X}}^{n}\\,\\rightarrow\\,\\mathbb{R}$ , for any neighboring datasets $x,x^{\\prime}\\in\\mathcal{X}^{n}$ and $\\operatorname{nf}_{x}\\{f(x)\\}\\leq t\\leq$ $\\operatorname{sup}_{x}\\{f(x)\\}$ we have $\\left|\\overline{{\\mathsf{l e n}_{f}}}(\\pmb{x};t)-\\overline{{\\mathsf{l e n}_{f}}}(\\pmb{x}^{\\prime};t)\\right|\\leq1$ ", "page_idx": 14}, {"type": "text", "text": "Proof. By construction, $L_{f}^{n}(x)=\\operatorname*{inf}_{x}\\{f(x)\\}$ and $U_{f}^{n}(x)=\\operatorname*{sup}_{x}\\{f(x)\\}$ because the Hamming distance between any datasets is always at most $n$ . Thus we must have $\\overline{{\\mathrm{1en}_{f}}}(x;t)\\leq n$ and $\\overline{{1{\\sf e n}_{f}}}({\\sf x}^{\\prime};t)\\le n$ . Without loss of generality, assume $\\overline{{\\mathsf{l e n}_{f}}}({\\pmb x};t)\\leq\\overline{{\\mathsf{l e n}_{f}}}({\\pmb x}^{\\prime};t)$ and $\\overline{{\\mathrm{1en}_{f}}}(\\pmb{x};t)=\\ell$ . By Definition A.1 we then have $\\bar{L}_{f}^{\\ell+1}(x^{\\prime})\\leq t\\leq\\overline{{U}}_{f}^{\\ell+1}(x^{\\prime})$ so $\\overline{{1{\\sf e n}_{f}}}({\\pmb x}^{\\prime};t)\\leq\\ell+1,$ , which implies our desired inequality. ", "page_idx": 14}, {"type": "text", "text": "We then extend this closeness to the approximate reflective inverse sensitivities for neighboring datasets. ", "page_idx": 14}, {"type": "text", "text": "Lemma A.7. Given $f\\,:\\,{\\mathcal{X}}^{n}\\,\\rightarrow\\,\\mathbb{R}$ , for any neighboring datasets $x,x^{\\prime}\\in\\mathcal{X}^{n}$ and $\\operatorname*{inf}_{x}\\{f(x)\\}\\leq t\\leq$ $\\operatorname{sup}_{x}\\{f(x)\\}$ we have $|\\overline{{\\mathsf{S}_{f}}}(x;t)-\\overline{{\\mathsf{S}_{f}}}(x^{\\prime};t)|\\leq1$ ", "page_idx": 14}, {"type": "text", "text": "Proof. First consider the case when $t\\,>\\,\\operatorname*{max}\\{f(\\pmb{x}),f(\\pmb{x}^{\\prime})\\}$ or $t\\,<\\,\\operatorname*{min}\\{f(x),f(x^{\\prime})\\}.$ . This implies $\\operatorname{sgn}(t-f(\\pmb{x}))=\\operatorname{sgn}(t-f(\\pmb{x}^{\\prime}))$ and the bound follows from Lemma A.6. Without loss of generality, assume $f({\\boldsymbol{x}})\\,\\geq\\,f({\\boldsymbol{x}}^{\\prime})$ and consider the other case when $f(x)\\geq t\\geq f(x^{\\prime})$ . Due to the fact that they\u2019re neighboring and Definition A.2 we have $\\overline{{\\mathtt{l e n}_{f}}}({\\boldsymbol{x}};t)\\le1$ and $\\mathsf{l e n}_{f}(\\pmb{x}^{\\prime};t\\leq1$ . This implies $|\\overline{{\\sf s}_{f}}(x;t)|\\leq\\bar{1}/2$ and $|\\overline{{\\mathsf{s}_{f}}}(\\pmb{x}^{\\prime};t)|\\leq1/2$ giving the desired bound. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Proof of Theorem A.4. For $t$ such that $\\operatorname*{inf}_{x}\\{f(x)\\}\\leq t\\leq\\operatorname*{sup}_{x}\\{f(x)\\}$ we know the sensitivity is at most 1 from Lemma A.7. Otherwise either $t_{i}<f(x)$ and so $\\overline{{{\\sf s}_{f}}}(\\pmb{x},t)=-\\infty$ for all $x\\in\\mathcal{X}^{n}$ or $t_{i}>f(x)$ and so $\\overline{{\\mathsf{s}_{f}}}(x,t)=\\infty$ for all $x\\in\\mathcal{X}^{n}$ . The privacy guarantees then follow from Proposition 2.5. ", "page_idx": 15}, {"type": "text", "text": "B Supplemental Results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section we provide supplemental results and experiments to our main results. We first show that the asymmetric sensitivity mechanism naturally handles unbounded data for our instantiations with negligible accuracy loss. Next we provide a simple, general, and robust strategy for selecting potential outputs for our method and provide a corresponding empirical study. Finally, we discuss how our methods can also apply to the add-subtract definition of neighboring datasets. ", "page_idx": 15}, {"type": "text", "text": "B.1 Naturally handling unbounded data ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "As previously discussed in our instantiations from Sections 5 and 6, the functions considered will have infinite upper output bounds if the data is unbounded. Given the iterative nature of the sparse vector technique, we will be able to naturally handle this setting with negligible accuracy loss. In particular, Algorithm 1 outputs the first query above the threshold, and we see from our Definition A.3 that even if $U_{f}^{\\ell}(x)=\\mathsf{\\bar{\\infty}}$ then we will have that the reflective inverse sensitivity is 1/2 for all possible outputs greater than $f(x)$ . Thus each query of potential outputs greater than $f(x)$ is more likely than not to terminate the algorithm. The probability of termination increases even more if the reflective inverse sensitivity is greater than 1/2 but will have minimal effect. ", "page_idx": 15}, {"type": "text", "text": "We test this upon our variance instantion by using the bounds from Section 5 and also considering the unbounded case. We also use the same parameters and datasets from Section 5. From Figure 3, we see that the difference in performance for the unbounded setting is slim and thus our method can inherently consider unbounded data. ", "page_idx": 15}, {"type": "image", "img_path": "4I2aEav51N/tmp/b6178224b90b8a51fd407fdf4b5e8266f45ef1ed44ae6807a7d97f25d70d23c9.jpg", "img_caption": ["Figure 3: Plots of the absolute error for variance estimation with both reasonable bounds on the data and unbounded data. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "While this works for our instantiations, this is aided by each function being non-negative by construction, and applying our method generally to unbounded data will often require an innate lower or upper bound on the function output. In contrast, efifcient implementations of the inverse sensitivity mechanism require both upper and lower bounds on the function output, and often further require bounded data for reasonable accuracy such as in our instantiations. More specifically, the inverse sensitivity mechanism uses the upper and lower output bounds from Definition 3.4 to construct intervals and draws an interval from the exponential mechanism and uniformly selects a point from the chosen interval. But this requires setting a data independent upper and lower bound from the function for efifcient implementation. This efifcient approach was first seen in an instantiation of a close variant of the inverse sensitivity mechanism for privately computing quantiles Smith (2011). ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "B.2 Robust and efifcient potential output selection ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In order to handle both fully unbounded and partially unbounded functions, we provide an efifcient and robust potential output selection method that also borrows from the private quantile literature Durfee (2023), which instantiates a close variant of our asymmetric sensitivity mechanism. In Algorithm 2, we provided the explicit approach for selecting potential outputs when the outputs are non-negative. This same approach can be shifted to handle any other lower bounded functions and symmetrically applied to upper bounded functions. The exponential nature of the potential outputs implies that they will become incredibly large or small within a reasonable number of queries which limits the running time. Specifically, if we set reasonably assume $\\beta\\geq1.001$ , then $\\hat{\\beta}^{50000}>10^{21}$ and we can simply terminate AboveThreshold after at most 50,000 queries for all datasets without affecting the privacy guarantees. ", "page_idx": 16}, {"type": "text", "text": "If the function has no innate bounds then we can call sparse vector technique with two iterations, searching through the positive numbers first, and then searching through the negatives if the first iteration immediately terminated. If the function has both innate upper and lower bounds then we can uniformly select the potential outputs from these bounds. ", "page_idx": 16}, {"type": "image", "img_path": "4I2aEav51N/tmp/087d79e8702ca2cb8679e88a2eef9bd6b21206a0ae3805c8fa2c09eea78dba9d.jpg", "img_caption": ["Figure 4: Plot of variance estimation using our method for different $\\beta$ parameters "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "While this methodology introduces a new parameter $\\beta$ that must be selected independent of the underlying data, we were able to fix $\\beta=1.005$ as a default and still see high performance across different invocations and datasets. Furthermore, we show here that we could consider other reasonable settings of $\\beta$ and still see robustly accurate performance from our methodology. In fact, from our experiments we can see that our empirical results could have been further improved by setting $\\beta=\\Bar{1}.01$ ", "page_idx": 16}, {"type": "text", "text": "B.3 Add-subtract neighboring ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In Definition 2.1, we made the notion of neighboring datasets follow the swap definition. Another commonly used notion of neighboring datasets in the differential privacy literature is the addsubtract definition where a users data is added or removed between neighbors. Our asymmetric sensitivity mechanism can naturally extend to this notion of Hamming distance as well. ", "page_idx": 16}, {"type": "text", "text": "The primary difference would be that all datasets in the data universe would no longer be at most distance $n$ from one another as the size of the dataset could vary. As such, the list of upper and lower output bounds could be infinite, but we can circumvent this with minimal practical impact. Potential outputs far from the underlying data are already incredibly unlikely to be selected so relaxing the bounds will barely affect the output distribution. As such, we can set the approximate upper and lower bounds to be positive and negative infinity, respectively, which is essentially identical to what was done in Lemma 5.3. To account for this changed definition we would also need to update the upper and lower output bounds for our instantiations. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "C Intuition and Asymmetric Advantage ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we first give a more visual explanation of our methodology compared to the inverse sensitivity mechanism. We then provide strong intuition upon why our method will substantially improve the estimation accuracy when the sensitivities are asymmetric by more naturally balancing the bias-variance tradeof.f We further supplement this intuition with a formal metric that quantifies the asymmetry of the sensitivities, and we empirically validate that increased asymmetry directly corresponds to improved relative performance of our method. Finally, we give the missing analysis of Lemma 4.1, our theoretical utility guarantees. ", "page_idx": 17}, {"type": "text", "text": "C.1 Visualization of both methods ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Recall that the inverse sensitivity method considered the distance metric of any output from the underlying data in Definition 2.8. We then proposed a variant of that definition better suited to applying the sparse vector technique in Definition 3.1. ", "page_idx": 17}, {"type": "image", "img_path": "4I2aEav51N/tmp/db0fa5805fee07dcc2d2e97434e3ee55ad599fe5c084a27253ee20d9fc51e9d2.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Figure 5: We provide here an informal visualization of the inverse sensitivity and reflective inverse sensitivity. For most functions of interest we can just plot these as step functions using the upper and lower output bounds from Definition 3.4. In the plot, we denote $L_{f}^{\\kappa}(x)$ and $U_{f}^{\\kappa}(x)$ with $L\\kappa$ and $U\\kappa$ , respectively. We will go into further detail in the next section but note that the sensitivities are perfectly symmetric in this example. ", "page_idx": 17}, {"type": "text", "text": "Both of these functions essentially shift between neighboring datasets which allows for maintaining closeness between outputs for each metric. We further note that unlike the inverse sensitivity, a shift in the reflective inverse sensitivity will be monotonic because of it\u2019s increasing nature, allowing for improved privacy guarantees for many instantiations. Given the closeness between outputs for neighboring datasets, we can apply the exponential mechanism or sparse vector technique. Applying our method entails considering an increasing stream of potential output $\\{t_{i}\\}$ and (noisily) identifying when the reflective inverse sensitivity crosses from negative to positive by calling the sparse vector technique. ", "page_idx": 17}, {"type": "image", "img_path": "4I2aEav51N/tmp/96a78f59574cbc0ab3e1f3a01804fa8f34e69a1fd535264b1800b11860ed2559.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Figure 6: We provide here an informal visualization of the approximate PDFs for inverse sensitivity mechanism (ISM) and our asymmetric sensitivity mechanism (ASM) when the sensitivities are perfectly symmetric. We slightly alter our mechanism M.3 to uniformly draw an output in $[t_{k-1},t_{k}]$ for easier visualization, which implies our PDF will be a step function between the potential outputs. ", "page_idx": 17}, {"type": "text", "text": "The iterative nature of the sparse vector technique will most often lead to our method being slightly more likely to find an output less than the true output. This introduces bias into our mechanism but we still remain competitive with inverse sensitivity even in the perfectly symmetric setting. ", "page_idx": 17}, {"type": "text", "text": "C.2 Naturally navigating the bias-variance tradeof ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In Figure 6 we assumed that the sensitivities were perfectly symmetric. More specifically, for $\\ell>0$ we let $\\Delta_{L}^{\\ell}(f;{\\pmb x})\\ {\\stackrel{\\mathrm{def}}{=}}\\ {L}_{f}^{\\ell-1}({\\pmb x})-{L}_{f}^{\\ell}({\\pmb x})$ and $\\Delta_{U}^{\\ell}(f;{\\pmb x})\\ {\\stackrel{\\mathrm{def}}{=}}\\ U_{f}^{\\ell}({\\pmb x})-U_{f}^{\\ell-1}({\\pmb x}),$ , which are the amount the function can marginally decrease and increase, respectively, by changing the $\\ell^{\\mathrm{{th}}}$ individual\u2019s data. Note that for $\\ell=1$ these quantities correspond to the local sensitivity. We then say that the sensitivities are perfectly symmetric if $\\Delta_{L}^{\\ell}(f;{\\pmb x})\\stackrel{\\cdot}{=}\\Delta_{U}^{\\ell}(f;{\\pmb x})$ for all $\\ell>0$ , which held by construction for our examples in the previous section. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Informally, we will say that the sensitivities are asymmetric if $\\Delta_{L}^{\\ell}(f;x)<<\\Delta_{U}^{\\ell}(f;x)$ (or the reverse) for most $\\ell$ particularly those closer to 0. We now consider an example in which the upper and lower outputs bounds imply asymmetric sensitivities and compare the approximate PDFs for each method. ", "page_idx": 18}, {"type": "image", "img_path": "4I2aEav51N/tmp/f2c481c7590bc8512e6f54da476e8653ab48a5a8e8535cbf05714f311a48ec28.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 7: We provide here an informal visualization of the approximate PDFs but with asymmetric sensitivities. We remove the labels for $L_{f}^{1}(x),L_{f}^{2}(x)$ , and $L_{f}^{3}(x)$ as they become too condensed around $f(x)$ but we keep their tick marks on the $\\mathbf{X}$ -axis. We again slightly alter our mechanism M.3 to uniformly draw an output in $[t_{k-1},t_{k}]$ for easier visualization, which implies our PDF will be a step function between the potential outputs. ", "page_idx": 18}, {"type": "text", "text": "For a more encompassing discussion on the bias-variance trade-of,f we first consider applying the smooth sensitivity framework to this example. Smooth sensitivity is unbiased in the classical sense (the expected output matches the underlying data) but the noise is added proportional to at least the local sensitivity which would be $\\Delta_{U}^{1}(f;\\bar{x})$ here. The inverse sensitivity mechanism weakens the unbiased definition to better take advantage of the asymmetry from $\\Delta_{L}^{\\ell}(f;x)<<\\Delta_{U}^{\\ell}(f;x)$ and we see in Figure 7 that the probability mass of outputs less than $f(x)$ becomes much more closely concentrated around $f(x)$ . However, using their notion of unbiased still limits the extent that it can improve the private estimation. In contrast, a variant of the preprocessing method from Cummings & Durfee (2020) could be applied here and potentially be both unbiased and have low variance if the a priori sensitivity parameter closely matches the $\\Delta_{L}^{\\ell}(f;x)$ for $\\ell$ close to zero. However, applying this same reduced sensitivity parameter, which essentially fixes the variance and must be data independent, would lead to significant bias in Figure 6. ", "page_idx": 18}, {"type": "text", "text": "By adding the slight bias towards early stopping from the iterative nature of the sparse vector technique, we can take full advantage of the tighter grouping of the lower output bound to significantly reduce the variance. More specifically, if we map Figure 5 to these lower output bounds, then the reflective inverse sensitivity will be much steeper right below $f(x)$ , which has the biggest impact upon when sparse vector technique terminates. In fact, we could set the upper output bounds to be infinite and this would only slightly decay the accuracy of our method. This allows us to naturally consider unbounded data for a variety functions, and we specifically examine the effects upon variance estimation in Appendix B.1 with empirical results showing negligible impact upon accuracy. While our method does still have dependence upon the data-independent stream of potential outputs $\\{t_{i}\\}_{:}$ , we provide a simple and general strategy for this selection in Appendix B that robustly maintains accuracy across different invocations and datasets. As a result, the slight bias from our method can utilize the asymmetry for significant improvement while also remaining competitive under perfect symmetry, giving a more inherent optimization of the bias-variance trade-of.f ", "page_idx": 18}, {"type": "text", "text": "C.3 Formalizing asymmetry of sensitivities ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We previously defined asymmetric sensitivity to informally be a consistent mismatch between $\\Delta_{L}^{\\ell}(\\bar{f};x)$ and $\\bar{\\Delta}_{U}^{\\ell}(f;x)$ for most $\\ell,$ . Additionally, this mismatch has the highest impact when $\\ell$ is closest to 0, as the outputs farther away from the underlying data are far less likely to be selected. However, the level of privacy further affects this likelihood where smaller $\\varepsilon$ implies mismatched $\\Delta_{L}^{\\ell}(f;x)$ and $\\Delta_{U}^{\\ell}(f;x)$ have a higher impact upon symmetry for larger $\\ell.$ . Therefore, to obtain a formal measurement of asymmetry, we should consider an averaging of $\\Delta_{L}^{\\ell}(f;x)$ vs $\\Delta_{U}^{\\ell}(f;x)$ over all $\\ell$ but with higher weight given to smaller $\\ell$ and this weighting should be further scaled by the privacy parameter. We observe that the inverse sensitivity mechanism uniformly draws from $[\\dot{L_{f}^{\\ell}},L_{f}^{\\ell-1}\\dot{]}$ and $[U_{f}^{\\ell-1},U_{f}^{\\ell}]$ with probability proportional to $\\Delta_{L}^{\\ell}(f;x)\\cdot\\exp(-\\ell\\cdot\\varepsilon/2)$ and $\\Delta^{\\ell}(f;x)\\cdot\\exp(-\\bar{\\ell}\\cdot\\varepsilon/2),$ respectively, by construction of the exponential mechanism. This then precisely fits with our desired weighting and the probability that the inverse sensitivity mechanism selects an output greater than $f(x)$ is simply a normalization of $\\begin{array}{r}{\\sum_{\\ell}\\Delta_{U}^{\\ell}(f;\\pmb{x})\\cdot\\exp(-\\ell\\cdot\\varepsilon/2)}\\end{array}$ . With this connection of our informal notion to the inverse sensitivity mechanism, we then give a formal definition for measuring the asymmetry of the sensitivities. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Definition C.1. Given a function $f:\\mathcal{X}^{n}\\to\\mathbb{R}$ , we measure the asymmetry of the sensitivities by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{Pr}\\left[M_{\\mathrm{inv}}({\\pmb x})>f({\\pmb x})\\right]-\\frac{1}{2}{\\nonumber\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "based upon the probability distribution from M.1. ", "page_idx": 19}, {"type": "text", "text": "Accordingly, we have that the sensitivities are symmetric if $f(x)$ is the median of the inverse sensitivity mechanism. But this property does not imply accurate estimation as the variance could still be quite large. However, it is not surprising that it will perform relatively worse than our method for more asymmetric sensitivities. We empirically test this conjecture across different levels of sensitivity symmetry, which we also vary by toggling the level of privacy. ", "page_idx": 19}, {"type": "image", "img_path": "4I2aEav51N/tmp/a206c140718c21b327112fa4aa565ee98817a09edafb2da5e290f14f8183191d.jpg", "img_caption": ["Figure 8: We consider a range of randomly sampled output bounds and privacy parameters and compute the absolute error of our asymmetric sensitivity mechanism (ASM) and the inverse sensitivity mechanism (ISM) over a small number of random draws. We plot the (error ISM) / (error ASM) corresponding to the asymmetry of the sensitivities for the given output bounds and privacy parameter. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "For our simulations we uniformly distribute the lower and upper output bounds and we toggle the range of the upper output bounds to vary the level of asymmetry. We also consider upper output bounds that are more heavy tailed and toggle the level of privacy, thereby determining the impact of the tail, to vary the asymmetry of the sensitivities. For each simulated output bounds and privacy parameter, we compute the asymmetry of the sensitivities and we make several calls to both methods for private estimations and compute the average absolute error of each. While these simulations are not all-encompassing, they empirically validate our provided intuition, and we will further see in our instantiations of functions with inherent asymmetry that our methodology gives substantially improved estimates. ", "page_idx": 19}, {"type": "text", "text": "C.4 Analysis of theoretical utility guarantees ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section we provide the proof of Lemma 4.1. Our proof will first bound the probability that we output a value that\u2019s too small and then bound the probability that we output a value that\u2019s too large. As a result, we provide two helper lemmas for each direction that are close variants of Theorem 3.24 in Dwork et al. (2014). ", "page_idx": 19}, {"type": "text", "text": "Lemma C.2. For any sequence of m queries $f_{1},...,f_{m}$ with sensitivity 1 such that $|\\{i\\leq m:f_{i}(x)\\geq}$ $T-\\alpha\\}|\\,=\\,0$ , then Algorithm 1 (where we set $\\varepsilon_{1}\\,=\\,\\varepsilon_{2}$ and $\\varepsilon\\,=\\,\\varepsilon_{1}\\,+\\,2\\varepsilon_{2,}$ ) will terminate during these queries with probability at most \ud835\udc5a\u22c5\ud835\udc52\u2212\ud835\udefc\ud835\udf00/3 ", "page_idx": 19}, {"type": "text", "text": "Proof. We know that exponential noise is non-negative, so to terminate at query $i$ , the noisy result must exceed the threshold. By the CDF of the exponential distribution and our assumption, we have $\\operatorname*{Pr}_{\\nu_{i}\\sim\\mathsf{E x p o}(3/\\varepsilon)}\\left[f_{i}(\\pmb{x})+\\nu_{i}>T\\right]\\leq e^{-\\alpha\\varepsilon/3}$ . Applying a union bound over all $m$ queries gives our desired result. ", "page_idx": 19}, {"type": "text", "text": "Lemma C.3. For any sequence of m queries $f_{j},...,f_{j+m}$ with sensitivity 1 such that $\\left|\\left\\{i\\in\\left(j,j+m\\right)\\;:\\right.$ $f_{i}(x)<T+\\alpha\\}|=0$ , then Algorithm 1 (where we set $\\varepsilon_{1}=\\varepsilon_{2}$ and $\\varepsilon=\\varepsilon_{1}+2\\varepsilon_{2,}$ ) will terminate at query $j+m$ or later with probability at most $e^{-\\alpha\\varepsilon/3}/m$ ", "page_idx": 19}, {"type": "text", "text": "Proof. In order to terminate at query $j+m$ or later we need that the noisy threshold is above all previous noisy queries. Let $\\nu_{T}\\sim\\mathsf{E x p o}(3/\\varepsilon)$ and $\\nu_{i}\\sim\\mathsf E\\times\\mathsf{p o}(3/\\varepsilon)$ . There are $m-1$ indices in $(j,j+m)$ so by independence we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{1}{m}=\\mathrm{Pr}\\,\\left[\\nu_{T}>\\operatorname*{max}_{i\\in(j,j+m)}\\nu_{i}\\right]\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and furthermore by change of variable and the PDF of the exponential distribution ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[\\nu_{T}>\\operatorname*{max}_{i\\in(j,j+m)}\\nu_{i}\\right]=e^{\\alpha\\varepsilon/3}\\mathrm{Pr}\\left[\\nu_{T}-\\alpha>\\operatorname*{max}_{i\\in(j,j+m)}\\nu_{i}\\right]\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Due to our assumption that $f_{i}(x)\\geq T{+}\\alpha$ for all $i\\in(j,j\\!+\\!m)$ , we see that $\\operatorname*{Pr}\\left[\\nu_{T}-\\alpha>\\operatorname*{max}_{i\\in(j,j+m)}\\nu_{i}\\right]$ is an upper bound on the probability of still continuing at step $j+m$ . This implies our desired claim. ", "page_idx": 20}, {"type": "text", "text": "Proof of Lemma 4.1. We first show $\\mathrm{Pr}\\,\\left[M({\\pmb x})<L^{\\ln k}({\\pmb x})\\right]\\,<\\,C/k e^{\\varepsilon/6}$ for a constant $C$ . By Definition 3.1 and Lemma 3.5 we know that for any $t_{i}<L^{\\ln k+1}(x)$ we have ${\\mathsf{s}}_{f}(x;t_{i})<T\\!-\\!\\ln k$ . Furthermore, we assumed that $f({\\boldsymbol{x}})\\leq\\beta^{C}$ for a constant $C$ and $t_{i}=\\beta^{i}-1\\;\\!s o\\,t_{C}>f(\\pmb{x})\\geq L^{\\ln k+1}(\\pmb{x}).$ . We then apply Lemma C.2 with $\\alpha=\\ln k$ and $m=C$ , which implies $\\operatorname*{Pr}\\left[M(\\pmb{x})<L^{\\ln k}(\\pmb{x})\\right]<C/k e^{\\varepsilon/6}$ for a constant $C$ as desired. ", "page_idx": 20}, {"type": "text", "text": "Next, we want to show that $\\mathrm{~p~}\\bigl[M(x)>\\beta^{k}(f(x)+1)\\bigr]<C/k e^{\\varepsilon/6}$ for a constant $C$ . Using the fact that $f({\\boldsymbol{x}})+1\\geq1$ there are at least $k\\!-\\!1$ values of $t_{i}$ such that $t_{i}\\in[f({\\pmb x}),\\beta^{k}(f({\\pmb x}){+}1)]$ . By Definition 3.1 and Lemma 3.5 we know that for any $t_{i}\\,\\in\\,[f({\\pmb x}),\\beta^{k}(f({\\pmb x})+1)]$ we have ${\\mathsf{s}}_{f}({\\boldsymbol{x}};t_{i})\\geq T+1/2$ . We then apply Lemma C.3 with $\\alpha=1/2$ and $m=k$ to get that $\\mathrm{Pr}\\left[M(\\pmb{x})>\\beta^{k}(f(\\pmb{x})+1)\\right]\\leq1/k e^{\\varepsilon/6}$ as desired. ", "page_idx": 20}, {"type": "text", "text": "Combining these inequalities gives our desired ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[|M(x)-f(x)|<\\operatorname*{max}\\{|f(x)-L^{\\log k+1}(x)|,(\\beta^{k}-1)(f(x)+1)\\}\\right]>1-O\\left({\\frac{1}{k e^{\\varepsilon/6}}}\\right)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Corollary C.4. Let $M$ denote the mechanism from M.3 with $t_{i}\\,=\\,\\beta^{i}\\,-\\,1$ where $\\beta>1$ and we let $\\varepsilon=\\varepsilon_{1}+2\\varepsilon_{2}$ with $\\varepsilon_{1}=\\varepsilon_{2}$ in the call to Algorithm 1. Given non-negative $f:\\mathcal{X}\\to\\mathbb{R}$ we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nP r\\left[|M(x)-f(x)|<\\operatorname*{max}\\{|f(x)-L^{\\log k+1}(x)|,(\\beta^{k}-1)(f(x)+1)\\}\\right]>1-O\\left(\\frac{1}{k e^{\\epsilon/6}}\\right)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "when $f(\\pmb{x})\\leq\\beta^{O(1)}$ . ", "page_idx": 20}, {"type": "text", "text": "Proof. The proof follows identically but instead of applying Lemma 3.5 we can directly use Definition A.2 and note that setting $L_{f}^{\\ell}\\equiv\\bar{L}_{f}^{\\ell}$ satisfies Definition A.1 \u53e3 ", "page_idx": 20}, {"type": "text", "text": "D Additional Analysis of Variance Invocation ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section we provide the necessary proofs for the efifcient variance instantiation of our method. Most of the analysis could be considered folklore properties of variance as it is such a well-studied statistical property, but we duplicate some of these properties for completeness. We first provide a known alternative definition of variance. ", "page_idx": 20}, {"type": "text", "text": "Definition D.1. Let $\\mathcal{X}=\\mathbb{R}$ and for $x\\in\\mathcal{X}^{n}$ , we can equivalently define variance as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname{Var}\\,[x]\\ {\\stackrel{\\mathrm{def}}{=}}\\ {\\frac{1}{n^{2}}}\\sum_{i=1}^{n}\\sum_{j=1}^{n}{\\frac{1}{2}}(x_{i}-x_{j})^{2}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We will also add some helpful notation where for any $S\\subseteq[n]$ we let $\\pmb{x}_{S}=\\{\\pmb{x}_{i}\\,:\\,i\\in S\\}$ and similarly for any $1\\leq a\\leq b\\leq n$ we let $\\pmb{x}_{[a:b]}=(\\pmb{x}_{a},...,\\pmb{x}_{b})$ . ", "page_idx": 21}, {"type": "text", "text": "D.1 Analysis for Lemma 5.2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We first prove a helper lemma that if $\\ell$ individuals data is changed in order to minimize variance, then those values should be set to be the mean of the remaining values. ", "page_idx": 21}, {"type": "text", "text": "Lemma D.2. For any $x\\in\\mathcal{X}^{n}$ and any $S\\subset[n]$ , we have that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\mathbf{x}_{s}}\\mathbf{Var}\\left[\\boldsymbol{x}\\right]=\\frac{n-\\left|S\\right|}{n}\\mathbf{Var}\\left[\\boldsymbol{x}_{\\left[n\\right]\\setminus S}\\right]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. By least squares minimization we know that $\\begin{array}{r}{\\sum_{i\\in[n]\\setminus S}({\\pmb x}_{i}-{\\boldsymbol y})^{2}}\\end{array}$ is minimized by setting ", "page_idx": 21}, {"type": "equation", "text": "$$\ny=\\frac{1}{n-|S|}\\sum_{i\\in[n]\\setminus S}x_{i}\\ {\\stackrel{\\mathrm{def}}{=}}\\ {\\bar{x}}_{[n]\\setminus S}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If we set $x_{i}=\\bar{x}_{[n]\\setminus S}$ for all $i\\in S$ , then we have $\\bar{{\\pmb x}}=\\bar{{\\pmb x}}_{[n]\\setminus S}$ and we have $\\begin{array}{r}{\\sum_{i\\in S}(\\pmb{x}_{i}-\\bar{\\pmb{x}})^{2}=0}\\end{array}$ which must be minimal by the non-negativity of squared error. Combining these properties we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{x_{s}}\\mathbf{Var}\\left[x\\right]=\\frac{1}{n}\\sum_{i\\in[n]\\setminus S}(x_{i}-\\bar{x}_{[n]\\setminus S})^{2}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We can then apply our Definition 5.1 to get our desired result. ", "page_idx": 21}, {"type": "text", "text": "With this helper lemma we can then provide the proof of our lower output bounds through a proof by contradiction. ", "page_idx": 21}, {"type": "text", "text": "Proof of Lemma 5.2. By Lemma D.2 we have that ", "page_idx": 21}, {"type": "equation", "text": "$$\nL_{\\mathbf{Var}}^{\\ell}(x)=\\operatorname*{min}_{S\\subset[n]:|S|=\\ell}\\frac{n-\\ell}{n}\\mathbf{Var}\\left[x_{[n]\\setminus S}\\right]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We will then give our desired claim through a proof by contradiction. Suppose this is minimized by $S\\subset[n]$ with some $i\\in S$ such that there exists $j,k\\notin S$ where $\\pmb{x}_{j}<\\pmb{x}_{i}<\\pmb{x}_{k}$ . Let $S_{j}=(S\\setminus i)\\cup j$ and $S_{k}=(S\\setminus i)\\cup k$ . To obtain our contradiction it then sufifces to show that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{min}\\left\\{\\mathbf{Var}\\left[\\mathbf{\\boldsymbol{x}}_{[n]\\setminus S_{j}}\\right],\\mathbf{Var}\\left[\\mathbf{\\boldsymbol{x}}_{[n]\\setminus S_{k}}\\right]\\ \\right\\}<\\mathbf{Var}\\left[\\mathbf{\\boldsymbol{x}}_{[n]\\setminus S}\\right]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Applying our alternative formulation of variance from Definition D.1 we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname{Var}\\left[{\\pmb x}_{[n]\\setminus S}\\right]=\\frac{1}{n-\\ell}\\sum_{a\\in[n]\\setminus S}\\sum_{b\\in[n]\\setminus S}\\frac{1}{2}({\\pmb x}_{a}-{\\pmb x}_{b})^{2}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Through cancellation of like terms we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{Var}\\left[x_{\\lbrack n\\rbrack\\setminus S_{j}}\\right]<\\mathbf{Var}\\left[x_{\\lbrack n\\rbrack\\setminus S}\\right]\\iff\\sum_{a\\in[n]\\setminus(S_{j}\\cup i)}(x_{a}-x_{i})^{2}<\\sum_{a\\in[n]\\setminus(S\\cup j)}(x_{a}-x_{j})^{2}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "By construction we have $(S_{j}\\cup i)=(S\\cup j)$ , so by the convexity of least squares minimization and the fact that $x_{j}<x_{i}$ , we have that this inequality holds if ${\\pmb x}_{i}\\leq\\bar{\\pmb x}_{[n]\\setminus(S\\cup j)}$ . Equivalently, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\nx_{i}\\geq\\bar{x}_{[n]\\setminus(S\\cup k)}\\Rightarrow\\mathbf{Var}\\left[x_{[n]\\setminus S_{k}}\\right]<\\mathbf{Var}\\left[x_{[n]\\setminus S}\\right]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Further, we know that $\\bar{\\pmb{x}}_{[n]\\setminus(S\\cup j)}\\;>\\;\\bar{\\pmb{x}}_{[n]\\setminus(S\\cup k)}$ because $\\pmb{x}_{j}\\ <\\ x_{k}$ . Therefore we must have either $x_{i}\\leq\\bar{x}_{[n]\\setminus(S\\cup j)}$ or ${\\pmb x}_{i}\\geq\\bar{\\pmb x}_{[n]\\setminus(S\\cup k)}$ which implies ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}\\left\\{\\mathbf{Var}\\left[\\mathbf{\\boldsymbol{x}}_{[n]\\setminus S_{j}}\\right],\\mathbf{Var}\\left[\\mathbf{\\boldsymbol{x}}_{[n]\\setminus S_{k}}\\right]\\ \\right\\}<\\mathbf{Var}\\left[\\mathbf{\\boldsymbol{x}}_{[n]\\setminus S}\\right]\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and gives our desired contradiction. ", "page_idx": 22}, {"type": "text", "text": "D.2 Analysis for Lemma 5.3 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section we prove that the approximate lower output bounds fit Definition A.1 and can be efifciently computed. We note that these lower output bounds will still maintain high accuracy because the bounds further away from the underlying data have far less effect upon the mechanism and accordingly, loose bounds will have little effect. ", "page_idx": 22}, {"type": "text", "text": "Proof of Lemma 5.3. Recall that we assumed a fixed constant, $c$ and defined $\\bar{L}_{\\mathbf{Var}}^{\\ell}(x)=L_{\\mathbf{Var}}^{\\ell}(x)$ for $\\ell\\leq c$ and $\\bar{L}_{\\mathbf{Var}}^{\\ell}(x)=0$ for $\\ell>c$ . By construction, we know that variance is non-negative, so we must have $L_{\\mathbf{Var}}^{\\ell}(x)\\geq0$ for all \ud835\udcc1. This then implies $\\bar{L}_{f}^{\\ell}(x)\\leq L_{f}^{\\ell}(x)$ for all \ud835\udcc1. Furthermore, if $\\ell>c$ then we immediately have $\\bar{L}_{f}^{\\ell}(x)\\geq\\bar{L}_{f}^{\\ell+1}(x^{\\prime})$ . Otherwise $L_{f}^{\\ell}(x)=\\bar{L}_{f}^{\\ell}(x)$ and we know by definition that $L_{f}^{\\ell}(x)\\geq L_{f}^{\\ell+1}(x^{\\prime})$ which implies $\\breve{L}_{f}^{\\ell}(x)\\geq\\bar{L}_{f}^{\\ell+1}(x^{\\prime})$ ", "page_idx": 22}, {"type": "text", "text": "For the runtime, by Lemma 5.2 we see that it sufifces to compute Var $\\left[x_{[\\ell+1-i:n-i]}\\right]$ for all $0\\leq i\\leq$ $\\ell\\leq c$ , where we assume $x_{1}\\leq\\ldots\\leq x_{n}$ . However, this ordering only matters the largest and smallest $c$ values, so we compute these in $O(n+c\\log(c))$ time. Further, we compute $\\textstyle\\sum_{i=1}^{n}{\\bar{x}}_{i}$ and $\\textstyle\\sum_{i=1}^{n}x_{i}^{2}$ in $O(n)$ time and will utilize the well-known fact that variance can be computed in $O(1)$ time with these quantities. We can then just iterate through all $i$ , $\\ell$ such that $0\\leq i\\leq\\ell\\leq c$ updating the sum of variables and squares to compute each Var $\\left[x_{[\\ell+1-i:n-i]}\\right]$ in $O(1)$ time taking a total of $O(c^{2})$ time. ", "page_idx": 22}, {"type": "text", "text": "D.3 Analysis for Lemma 5.4 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proof of Lemma 5.4. We first show that for any neighboring datasets $x,x^{\\prime}$ we have $\\overline{{U}}_{\\mathbf{Var}}^{\\ell}(x)\\leq$ $\\overline{{U}}_{\\mathbf{Var}}^{\\ell+1}(x^{\\prime})$ . By construction, this reduces to showing that $\\mathbf{Var}\\left[x\\right]\\leq\\mathbf{Var}\\left[x^{\\prime}\\right]+(b-a)^{2}/n$ . Let $i$ be the index such that $x_{i}\\neq x_{i}^{\\prime}$ . Applying the alternative variance formulation in Definition D.1 and cancelling like terms reduces this to showing ", "page_idx": 22}, {"type": "equation", "text": "$$\n{\\frac{1}{n^{2}}}\\sum_{j\\neq i}(x_{i}-x_{j})^{2}\\leq{\\frac{1}{n^{2}}}\\sum_{j\\neq i}(x_{i}^{\\prime}-x_{j})^{2}+{\\frac{(b-a)^{2}}{n}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We assumed that all datasets were restricted to $[a,b]^{n}$ so we must then have $\\begin{array}{r}{\\sum_{j\\neq i}(x_{i}{-}x_{j})^{2}\\leq n(b{-}a)^{2}}\\end{array}$ , which then implies our desired inequality by the non-negativity of squared error. ", "page_idx": 22}, {"type": "text", "text": "Next we show that $U_{\\mathbf{Var}}^{\\ell}(x)\\,\\le\\,\\overline{{U}}_{\\mathbf{Var}}^{\\ell}(x)$ . It sufifces to show that for an arbitrary $x^{\\prime}$ such that $d_{\\mathsf{h a m}}(\\boldsymbol{x},\\boldsymbol{x}^{\\prime})=\\ell$ we have Var $[x^{\\prime}]\\leq\\mathbf{Var}\\,[x]\\!+\\!{\\frac{\\ell(b\\!-\\!a)^{2}}{n}}$ . We previously showed that $\\mathbf{Var}\\left[x\\right]\\geq\\mathbf{Var}\\left[x^{\\prime}\\right]+$ $(b-a)^{2}/n$ for any $x,x^{\\prime}$ such that $d_{\\mathsf{h a m}}(\\boldsymbol{x},\\boldsymbol{x}^{\\prime})=1$ , so our claim then follows inductively. ", "page_idx": 22}, {"type": "text", "text": "Therefore, our construction of $\\bar{U}_{\\mathbf{Var}}^{\\ell}$ satisfies Definition A.1 as desired. ", "page_idx": 22}, {"type": "text", "text": "E Additional Analysis of Model Evaluation Invocations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we provide the definitions and implementation details for applying our method to machine learning model evaluation functions. We further unify this analysis by considering applying our methodology to linearly separable functions. ", "page_idx": 22}, {"type": "text", "text": "We now define our datasets as $(x,y)\\in\\mathcal{X}^{n}\\!\\times\\!\\mathbb{R}^{n}$ and we set $d_{\\mathsf{h a m}}((\\boldsymbol{x},\\boldsymbol{y}),(\\boldsymbol{x}^{\\prime},\\boldsymbol{y}^{\\prime}))=|\\{i\\,:\\,\\boldsymbol{x}_{i}\\neq\\boldsymbol{x}_{i}^{\\prime}$ or $y_{i}\\neq$ $y_{i}^{\\prime}\\}$ to be the Hamming distance between datasets. We will be considering binary classification and multi-class classification, so we define cross-entropy loss for both. ", "page_idx": 23}, {"type": "text", "text": "Definition E.1. Given machine learning model for binary-classification $\\omega:\\mathcal{X}\\rightarrow\\mathbb{R}$ and assume all $y_{i}\\in\\{0,1\\},$ , let ", "page_idx": 23}, {"type": "equation", "text": "$$\n{\\mathsf{B C E}}_{\\omega}(x,y)=\\sum_{i=1}^{n}-y_{i}\\log\\left({\\frac{1}{1+e^{-\\omega(x_{i})}}}\\right)-(1-y_{i})\\log\\left({\\frac{e^{-\\omega(x_{i})}}{1+e^{-\\omega(x_{i})}}}\\right)\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Similarly, given machine learning model for multi-classification $\\omega:\\,\\mathcal{X}\\rightarrow\\mathbb{R}^{c}$ with $c$ classes and assume all $y_{i}\\in[c]$ , let ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathsf{C E}_{\\omega}({\\boldsymbol{x}},{\\boldsymbol{y}})=-\\sum_{i=1}^{n}\\log\\left(\\frac{e^{\\omega({\\pmb x}_{i})_{y_{i}}}}{\\sum_{j=1}^{c}e^{\\omega({\\pmb x}_{i})_{j}}}\\right)\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We also define the mean squared error and mean absolute error. ", "page_idx": 23}, {"type": "text", "text": "Definition E.2. Given a dataset $\\mathbf{\\Phi}(x,y)$ and machine learning model $\\omega:\\mathcal{X}\\rightarrow\\mathbb{R}$ , we define ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathsf{M S E}_{\\omega}({\\pmb x},y)=\\frac{\\sum_{i=1}^{n}(\\omega({\\pmb x}_{i})-y_{i})^{2}}{n}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathsf{M A E}_{\\omega}({\\pmb x},y)=\\frac{\\sum_{i=1}^{n}|\\omega({\\pmb x}_{i})-y_{i}|}{n}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "E.1 Application to linearly separable functions ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section we consider all linearly separable functions $f:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ such that ", "page_idx": 23}, {"type": "equation", "text": "$$\nf(\\pmb{x})=\\sum_{i=1}^{n}{\\mathcal{L}}(\\pmb{x}_{i})\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\mathcal{L}:\\mathcal{X}\\rightarrow\\mathbb{R}$ . We could also extend our results here to $\\mathcal{L}$ that are specific to the index, but for simplicity we will restrict our consideration. Without loss of generality assume the indices are ordered such that $\\mathcal L(x_{i})\\leq\\mathcal L(x_{i+1})$ . We first provide lower output bounds for these functions. ", "page_idx": 23}, {"type": "text", "text": "Lemma E.3. Given a linearly separable function $f:\\mathcal{X}\\to\\mathbb{R}$ , then ", "page_idx": 23}, {"type": "equation", "text": "$$\nL_{f}^{\\ell}(\\pmb{x})=\\sum_{i=1}^{n-\\ell}\\mathcal{L}(\\pmb{x}_{i})+\\ell\\cdot\\operatorname*{inf}_{\\pmb{x}_{k}\\in\\mathcal{X}}\\{\\mathcal{L}(\\pmb{x}_{k})\\}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. Changing any individual\u2019s data can only change their contribution to the sum by the linearly separable property. Therefore, decreasing the $\\ell$ individuals with the highest contribution to the sum must minimize the function for datasets with Hamming distance $\\ell$ from the underlying data. ", "page_idx": 23}, {"type": "text", "text": "Similarly, we provide upper output bounds for linearly separable functions. ", "page_idx": 23}, {"type": "text", "text": "Lemma E.4. Given a linearly separable function $f:\\mathcal{X}\\to\\mathbb{R}$ , then ", "page_idx": 23}, {"type": "equation", "text": "$$\nU_{f}^{\\ell}(\\pmb{x})=\\sum_{i=\\ell}^{n}{\\mathcal{L}}(\\pmb{x}_{i})+\\ell\\cdot\\operatorname*{sup}_{\\pmb{x}_{k}\\in\\mathcal{X}}\\{\\mathcal{L}(\\pmb{x}_{k})\\}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. Follows equivalently to the proof of Lemma E.3 ", "page_idx": 23}, {"type": "text", "text": "We then provide approximate relaxations of these bounds that will allow for easier application. ", "page_idx": 23}, {"type": "text", "text": "Lemma E.5. Given a linearly separable function $f\\,:\\,\\mathcal{X}\\rightarrow\\mathbb{R}$ , then approximate upper and lower sensitivity bounding functions $\\overline{{U}}_{f}^{\\ell}:\\mathcal{X}^{n}\\to\\overline{{\\mathbb{R}}}$ and $\\bar{L}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ satisfy Definition A.1 for ", "page_idx": 24}, {"type": "equation", "text": "$$\n{\\bar{L}}_{f}^{\\ell}(x)=\\sum_{i=1}^{n-\\ell}{\\mathcal{L}}(x_{i})+\\ell\\cdot a\\qquad\\quad a n d\\qquad\\quad{\\bar{U}}_{f}^{\\ell}(x)=\\sum_{i=\\ell}^{n}{\\mathcal{L}}(x_{i})+\\ell\\cdot b\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\ni f a\\leq\\operatorname*{inf}_{x_{k}\\in{\\mathcal{X}}}\\{{\\mathcal{L}}(x_{k})\\}\\ a n d\\,b\\geq\\operatorname*{sup}_{x_{k}\\in{\\mathcal{X}}}\\{{\\mathcal{L}}(x_{k})\\}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. We show this the approximate lower output bounds and the upper follow equivalently. We first have $\\bar{L}_{f}^{\\ell}(x)\\leq L_{f}^{\\ell}(x)$ by construction. Next, for neighboring $x,x^{\\prime}$ , let $j$ be the index at which $x_{j}\\neq x_{j}^{\\prime}$ . We assumed an ordering to the indices for simplicity, but we equivalently have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\bar{L}_{f}^{\\ell}({\\pmb x})=\\operatorname*{min}_{\\substack{S\\subseteq[n]:\\,|S|=n-\\ell}}\\Big\\{\\sum_{i\\in S}{\\mathcal L}({\\pmb x}_{i})\\Big\\}+\\ell\\cdot a\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "For some given $\\ell$ , let $S_{x}$ be the subset of indices that minimizes this for $\\bar{L}_{f}^{\\ell}(x)$ . If $j\\not\\in S_{x}$ then we have $\\bar{L}_{f}^{\\ell}(x)\\geq\\bar{L}_{f}^{\\ell}(x^{\\prime})$ , so $\\bar{L}_{f}^{\\ell}(x)\\geq\\bar{L}_{f}^{\\ell+1}(x^{\\prime})$ . Otherwise, we know that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\bar{L}_{f}^{\\ell+1}(\\pmb{x}^{\\prime})=\\operatorname*{min}_{\\substack{S\\subseteq[n]:\\,|S|=n-(\\ell+1}}\\Big\\{\\sum_{i\\in S}\\mathcal{L}(\\pmb{x}_{i}^{\\prime})\\Big\\}+(\\ell+1)\\cdot a\\leq\\sum_{i\\in S_{x}\\setminus j}\\mathcal{L}(\\pmb{x}_{i})+(\\ell+1)\\cdot a\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and because $a\\leq\\mathcal{L}(x_{j})$ then this implies $\\bar{L}_{f}^{\\ell}(x)\\geq\\bar{L}_{f}^{\\ell+1}(x^{\\prime})$ ", "page_idx": 24}, {"type": "text", "text": "We further show that our approximate bounds allow for monotonic reflective inverse sensitivities which implies improved privacy guarantees. ", "page_idx": 24}, {"type": "text", "text": "Lemma E.6. Given a linearly separable function $f\\,:\\,\\mathcal{X}\\rightarrow\\mathbb{R}$ , along with approximate upper and lower sensitivity bounding functions $\\overline{{U}}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ and $\\bar{L}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ such that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\bar{L}_{f}^{\\ell}(x)=\\sum_{i=1}^{n-\\ell}\\mathcal{L}(x_{i})+\\ell\\cdot a\\qquad\\quad a n d\\qquad\\quad\\bar{U}_{f}^{\\ell}(x)=\\sum_{i=\\ell}^{n}\\mathcal{L}(x_{i})+\\ell\\cdot b\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $a\\leq\\operatorname*{inf}_{x_{k}\\in{\\mathcal{X}}}\\{{\\mathcal{L}}(x_{k})\\}$ and $b\\geq\\operatorname*{sup}_{x_{k}\\in\\mathcal{X}}\\{\\mathcal{L}(x_{k})\\}$ . For any neighboring datasets $x,x^{\\prime}$ we have that either $\\overline{{\\mathsf{s}_{f}}}(x;t)\\leq\\overline{{\\mathsf{s}_{f}}}(x^{\\prime};t)$ for all $t\\in\\mathbb{R}$ or $\\overline{{\\mathsf{s}_{f}}}(x;t)\\geq\\overline{{\\mathsf{s}_{f}}}(x^{\\prime};t)$ for all $t\\in\\mathbb{R}$ ", "page_idx": 24}, {"type": "text", "text": "Proof. Without loss of generality, assume $f({\\boldsymbol{x}})\\leq f({\\boldsymbol{x}}^{\\prime})$ and we will show $\\overline{{\\mathsf{s}_{f}}}(x;t)\\geq\\overline{{\\mathsf{s}_{f}}}(x^{\\prime};t)$ for all $t\\in R$ . ", "page_idx": 24}, {"type": "text", "text": "We first consider $t\\in[f(\\pmb{x}),f(\\pmb{x}^{\\prime})]$ . Given that the datasets are neighboring, we must have $L_{f}^{1}(x)\\leq$ $t\\leq U_{f}^{1}(x)$ and $L_{f}^{1}({\\pmb x}^{\\prime})\\leq t\\leq U_{f}^{1}({\\pmb x}^{\\prime})$ . By Definition A.1 and Definition A.2, we have that $\\overline{{\\mathrm{1en}_{f}}}(\\pmb{x};t)\\leq1$ and $\\overline{{\\mathsf{l e n}_{f}}}(\\pmb{x}^{\\prime};t)\\leq1$ . Given that $t\\in[f(\\pmb{x}),f(\\pmb{x}^{\\prime})]$ this then implies $\\overline{{\\mathsf{s}_{f}}}(\\pmb{x};t)\\in\\{1/2,0\\}$ and $\\overline{{\\mathsf{S}_{f}}}(x^{\\prime};t)\\in$ $\\{-1/2,0\\}$ . Therefore $\\overline{{\\mathsf{s}_{f}}}(x;t)\\geq\\overline{{\\mathsf{s}_{f}}}(x^{\\prime};t)$ . ", "page_idx": 24}, {"type": "text", "text": "Next consider the case when $t<f(x)$ . This implies $\\operatorname{sgn}(t-f(\\pmb{x}))=\\operatorname{sgn}(t-f(\\pmb{x}^{\\prime}))=-1$ and also that $\\overline{{\\mathtt{l e n}_{f}}}(\\boldsymbol{x};t)\\ge1$ and $\\overline{{\\mathsf{l e n}_{f}}}(\\pmb{x}^{\\prime};t)\\ge1$ . By Lemma E.7 we have that $\\bar{L}_{f}^{\\ell}(x)\\leq\\bar{L}_{f}^{\\ell}(x^{\\prime})$ for all $\\ell\\geq0$ , which implies $\\overline{{\\mathtt{l e n}_{f}}}(\\pmb{x};t)\\leq\\overline{{\\mathtt{l e n}_{f}}}(\\pmb{x}^{\\prime};t)$ and therefore $\\overline{{\\mathsf{s}_{f}}}(x;t)\\geq\\overline{{\\mathsf{s}_{f}}}(x^{\\prime};t)$ . ", "page_idx": 24}, {"type": "text", "text": "Finally consider $t>f(x^{\\prime})$ . This implies $\\operatorname{sgn}(t-f(\\pmb{x}))=\\operatorname{sgn}(t-f(\\pmb{x}^{\\prime}))=1$ and also that $\\overline{{\\mathrm{1en}_{f}}}(x;t)\\geq$ 1 and $\\overline{{\\mathsf{l e n}_{f}}}(\\pmb{x}^{\\prime};t)\\ge1$ . By Lemma E.7 we have that $\\overline{{U}}_{f}^{\\ell}(x)\\leq\\overline{{U}}_{f}^{\\ell}(x^{\\prime})$ for all $\\ell\\geq0$ , which implies $\\overline{{\\mathsf{l e n}_{f}}}({\\pmb x};t)\\ge\\overline{{\\mathsf{l e n}_{f}}}({\\pmb x}^{\\prime};t)$ and therefore $\\overline{{\\mathsf{s}_{f}}}(x;t)\\geq\\overline{{\\mathsf{s}_{f}}}(x^{\\prime};t)$ . ", "page_idx": 24}, {"type": "text", "text": "We will also require the following helper lemma in order prove Lemma E.6. ", "page_idx": 24}, {"type": "text", "text": "Lemma E.7. Given a linearly separable function $f\\,:\\,\\mathcal{X}\\rightarrow\\mathbb{R}$ , along with approximate upper and lower sensitivity bounding functions $\\overline{{U}}_{f}^{\\ell}:\\mathcal{X}^{n}\\rightarrow\\mathbb{R}$ and $\\bar{L}_{f}^{\\ell}\\,:\\,\\mathcal{X}^{n}\\to\\mathbb{R}$ such that ", "page_idx": 25}, {"type": "equation", "text": "$$\n{\\bar{L}}_{f}^{\\ell}(x)=\\sum_{i=1}^{n-\\ell}{\\mathcal{L}}(x_{i})+\\ell\\cdot a\\qquad\\quad a n d\\qquad\\quad{\\bar{U}}_{f}^{\\ell}(x)=\\sum_{i=\\ell}^{n}{\\mathcal{L}}(x_{i})+\\ell\\cdot b\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $a\\leq\\operatorname*{inf}_{x_{k}\\in{\\mathcal{X}}}\\{{\\mathcal{L}}(x_{k})\\}\\,a n d b\\geq\\operatorname*{sup}_{x_{k}\\in{\\mathcal{X}}}\\{{\\mathcal{L}}(x_{k})\\}.$ For any neighboring datasets $x,x^{\\prime}$ , $i f f(x)\\leq f(x^{\\prime})$ then $\\bar{L}_{f}^{\\ell}(x)\\leq\\bar{L}_{f}^{\\ell}(x^{\\prime})$ and $\\overline{{U}}_{f}^{\\ell}(x)\\leq\\overline{{U}}_{f}^{\\ell}(x^{\\prime})$ for all $\\ell\\geq0$ ", "page_idx": 25}, {"type": "text", "text": "Proof. Let $j$ be the index at which $x_{j}\\neq x_{j}^{\\prime}$ , which implies $\\underline{{c}}(x_{j})\\leq\\underline{{c}}(x_{j}^{\\prime})$ because of our linearly separable property. We assumed an ordering to the indices for simplicity, but we equivalently have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\bar{L}_{f}^{\\ell}({\\pmb x})=\\operatorname*{min}_{\\substack{S\\subseteq[n]:\\,|S|=n-\\ell}}\\Big\\{\\sum_{i\\in S}{\\mathcal L}({\\pmb x}_{i})\\Big\\}+\\ell\\cdot a\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For a given $\\ell$ let $S_{x^{\\prime}}$ denote the set of indices that minimizes $\\bar{L}_{f}^{\\ell}(x^{\\prime})$ . If $j\\in S_{x^{\\prime}}$ then we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\bar{L}_{f}^{\\ell}(x^{\\prime})=\\mathcal{L}(x_{j}^{\\prime})+\\sum_{i\\in S_{x^{\\prime}}\\setminus j}\\mathcal{L}(x_{i})+\\ell\\cdot a\\geq\\mathcal{L}(x_{j})+\\sum_{i\\in S_{x^{\\prime}}\\setminus j}\\mathcal{L}(x_{i})+\\ell\\cdot a=\\sum_{i\\in S_{x^{\\prime}}}\\mathcal{L}(x_{i})+\\ell\\cdot a\\geq\\bar{L}_{f}^{\\ell}(x)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Similarly, if $j\\not\\in S_{x^{\\prime}}$ then ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\bar{L}_{f}^{\\ell}({\\pmb x}^{\\prime})=\\sum_{i\\in S_{x^{\\prime}}}\\mathcal L({\\pmb x}_{i})+\\ell\\cdot{\\boldsymbol a}\\geq\\bar{L}_{f}^{\\ell}({\\pmb x})\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The proof for $\\overline{{U}}_{f}^{\\ell}(x)\\leq\\overline{{U}}_{f}^{\\ell}(x^{\\prime})$ follows equivalently. ", "page_idx": 25}, {"type": "text", "text": "E.2 Efifcient cross-entropy loss instantiation ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We will provide the efifcient instantiation for multi-class cross entropy loss as this can easily be extended to binary cross entropy loss. Without loss of generality, assume the indices are ordered such that ", "page_idx": 25}, {"type": "equation", "text": "$$\n-\\log\\left(\\frac{e^{\\omega\\left(x_{i}\\right)_{y_{i}}}}{\\sum_{j=1}^{c}e^{\\omega\\left(x_{i}\\right)_{j}}}\\right)\\leq-\\log\\left(\\frac{e^{\\omega\\left(x_{i+1}\\right)_{y_{i+1}}}}{\\sum_{j=1}^{c}e^{\\omega\\left(x_{i+1}\\right)_{j}}}\\right)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We can then provide the lower output bounds for cross entropy loss ", "page_idx": 25}, {"type": "text", "text": "Lemma E.8. Given a dataset $\\mathbf{\\Phi}(x,y)$ and machine learning model $\\omega:\\,\\mathcal{X}\\rightarrow\\mathbb{R}^{c}$ , then ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\bar{L}_{\\mathtt{C E}_{\\omega}}^{\\ell}(x,y)=-\\sum_{i=1}^{n-\\ell}\\log\\left(\\frac{e^{\\omega(x_{i})_{y_{i}}}}{\\sum_{j=1}^{c}e^{\\omega(x_{i})_{j}}}\\right)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. We apply Lemma E.3 and Lemma E.5 and we observe that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{x_{i},y_{i}}\\left\\{\\begin{array}{l l}{\\displaystyle-\\log\\left(\\frac{e^{\\omega(x_{i})_{y_{i}}}}{\\sum_{j=1}^{c}e^{\\omega(x_{i})_{j}}}\\right)}\\end{array}\\right\\}\\geq0\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "As seen with variance in Section 5, we have that $U_{\\tt C E_{\\alpha}}^{1}(x,y)=\\infty$ which implies that cross-entropy loss has inherently asymmetric sensitivities. Similarly, we will need to restrict the range of these values in order to apply inverse sensitivity mechanism even though our method could easily handle the unbounded setting. We provide a proof for these upper output bounds in Appendix E. ", "page_idx": 25}, {"type": "text", "text": "Lemma E.9. Given a dataset $\\mathbf{\\Phi}(x,y)$ and machine learning model $\\omega\\,:\\,\\mathcal{X}\\rightarrow\\mathbb{R}^{c}$ where we restrict $\\omega(x_{i})\\in[a,b]^{c}$ for all $i$ , then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\overline{{U}}_{\\mathtt{C E}_{\\omega}}^{\\ell}(x,y)=-\\left(\\ell\\cdot\\log\\left(\\frac{e^{a-b}}{e^{a-b}+c-1}\\right)+\\sum_{i=\\ell+1}^{n}\\log\\left(\\frac{e^{\\omega(x_{i})_{y_{i}}}}{\\sum_{j=1}^{c}e^{\\omega(x_{i})_{j}}}\\right)\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. We apply Lemma E.4 and Lemma E.5, and we observe that with our restricted bounds we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{x_{i},y_{i}}\\left\\{\\begin{array}{l l}{\\displaystyle-\\log\\left(\\frac{e^{\\omega\\left(x_{i}\\right)_{y_{i}}}}{\\sum_{j=1}^{c}e^{\\omega\\left(x_{i}\\right)_{j}}}\\right)}\\end{array}\\right\\}\\leq-\\log\\left(\\frac{e^{a-b}}{e^{a-b}+c-1}\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The corresponding algorithm for instantiating cross-entropy loss with our method is similar to Algorithm 2. The privacy guarantees from Theorem 5.5 also follow equivalently, but we can additionally improve the privacy to be $\\left(\\boldsymbol{\\varepsilon}_{1}+\\boldsymbol{\\varepsilon}_{2}\\right)$ -DP by applying Lemma E.6 to achieve monotonicity. We can also achieve $O(n\\log(n)+q)$ runtime by computing all of our approximate upper and lower bounds, but we could also easily employ the same strategy of setting these bounds to be infinity and zero, respectively, for all $\\ell>c$ where we set $c=100$ . This then gives the linear runtime, where we also utilize the fact that we will never run AboveThreshold from more than 50,000 queries. ", "page_idx": 26}, {"type": "text", "text": "E.3 Efifcient implementation for regression evaluation ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We will only provide the efifcient implementation for MSE in this section as MAE will follow identically. Without loss of generality, assume the indices are ordered such that $(\\omega({x}_{i})-y_{i})^{2}\\leq$ $(\\omega(\\boldsymbol{x}_{i+1})-y_{i+1})^{2}$ . ", "page_idx": 26}, {"type": "text", "text": "Lemma E.10. Given a dataset $(x,y)$ and machine learning model $\\omega:\\mathcal{X}\\rightarrow\\mathbb{R}$ , then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\bar{L}_{\\sf M S E_{\\omega}}^{\\ell}(\\mathbf{x},y)=\\frac{\\sum_{i=1}^{n-\\ell}(\\omega(\\mathbf{x}_{i})-y_{i})^{2}}{n}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. We apply Lemma E.3 and Lemma E.5, and we observe that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{x_{i},y_{i}}\\{\\omega(x_{i})-y_{i})^{2}\\}\\geq0\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "As seen with variance in Section 5, we have that $U_{\\sf M S E}^{1}({\\pmb x},y)\\,=\\,\\infty$ which implies that MSE has inherently asymmetric sensitivities. Similarly, we will need to restrict the range of these values in order to apply inverse sensitivity mechanism even though our method could easily handle the unbounded setting. ", "page_idx": 26}, {"type": "text", "text": "Lemma E.11. Given a dataset $(x,y)$ and machine learning model $\\omega\\;:\\;\\mathcal{X}\\rightarrow\\mathbb{R}$ where we restrict $\\omega({\\boldsymbol x}_{i})\\in[a,b]$ and $y_{i}\\in[a,b]$ for all $i$ , then ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\overline{{U}}_{\\mathsf{M S E}_{\\omega}}^{\\ell}(x,y)=\\frac{\\ell(b-a)^{2}+\\sum_{i=\\ell+1}^{n}(\\omega({\\boldsymbol{x}}_{i})-y_{i})^{2}}{n}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof. We apply Lemma E.4 and Lemma E.5, and we observe that for our bounded setting ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{x_{i},y_{i}}\\{\\omega(x_{i})-y_{i})^{2}\\}\\leq(b-a)^{2}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The corresponding algorithm for instantiating MSE with our method is identical to Algorithm 2. The privacy guarantees from Theorem 5.5 also follow equivalently, but we can additionally improve the privacy to be $\\left(\\boldsymbol{\\varepsilon}_{1}+\\boldsymbol{\\varepsilon}_{2}\\right)$ -DP by applying Lemma E.6 to achieve monotonicity. We can also achieve $O(n\\log(n)+q)$ runtime by computing all of our approximate upper and lower bounds, but we could also easily employ the same strategy of setting these bounds to be infinity and zero, respectively, for all $\\ell>c$ where we set $c=100$ . This then gives the linear runtime, where we also utilize the fact that we will never run AboveThreshold from more than 50,000 queries. ", "page_idx": 27}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We enumerate the main claims made in the abstract and introduction at the end of the introduction with pointers to each section that contains their support. ", "page_idx": 28}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We provide an approximate variant of our method to overcome the limitations of the exact method which are discussed. We also give theoretical and empirical details upon when our method is advantageous. ", "page_idx": 28}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: All assumptions for each theoretical claim is contained in the claim and all proofs are in the appendix. ", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We provide full details on datasets, parameters, and experimental setup for all empirical results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufifcient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [No] ", "page_idx": 28}, {"type": "text", "text": "Justification: The data is open source and the code is straightforward to reproduce as all algorithms are simple, but we have not open sourced the code. We\u2019d be happy to provide all code used upon request. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: For each empirical study and dataset we specify all parameters, training/test splits and models used from open source packages. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: All figures from our empirical results contain confidence interval error bars. ", "page_idx": 28}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufifcient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [No] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our algorithms are lightweight so we just used basic colab notebooks to run the different empirical studies, but this was not specified in the paper. ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We believe this work conforms to the Code of Ethics ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This work only provides improved methods in differential privacy to give improved estimation for the same level of privacy. ", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: We don\u2019t propose any algorithms or models that could be considered high risk ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide citations for all datasets used. ", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: We don\u2019t introduce new assets. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper doesn\u2019t involve crowdsourding or research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper doesn\u2019t involve crowdsourding or research with human subjects. ", "page_idx": 29}]