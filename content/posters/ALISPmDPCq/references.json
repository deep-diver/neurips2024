{"references": [{"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational for the field of large language models (LLMs), introducing the concept of few-shot learning, which is highly relevant to the topic of the current paper."}, {"fullname_first_author": "Rohan Anil", "paper_title": "Gemini: A family of highly capable multimodal models", "publication_date": "2023-12-01", "reason": "This paper introduces Gemini, a family of advanced multimodal models, which are directly relevant to the performance-based model analysis discussed in the current paper."}, {"fullname_first_author": "Jasper Dekoninck", "paper_title": "Evading data contamination detection for language models is (too) easy", "publication_date": "2024-02-01", "reason": "This paper provides a detailed analysis of existing data contamination detection methods and their limitations, directly informing the proposed approach in the current work."}, {"fullname_first_author": "Shahriar Golchin", "paper_title": "Data contamination quiz: A tool to detect and estimate contamination in large language models", "publication_date": "2023-11-01", "reason": "This paper provides another relevant approach to detect and estimate contamination in large language models, and serves as a baseline method for comparison."}, {"fullname_first_author": "Yucheng Li", "paper_title": "An open source data contamination report for large language models", "publication_date": "2023-10-01", "reason": "This paper provides a large-scale empirical study of data contamination in publicly available large language models, and the results from this study are compared with the results of the current paper."}]}