[{"figure_path": "tVO3b68Oyp/figures/figures_1_1.jpg", "caption": "Figure 1: Left-Top: The loss prediction matrix C, where brighter is higher likelihood placed on the teacher label. A time-aligned transcript is on the bottom, and predicted cluster unit boundaries span vertically as dashed-lines. Left-Bottom: A Mel-Spectrogram of the input waveform with an example masked timespan in gray. The losses on tokens at timesteps covered by the solid blue and dotted red spans are mapped to their corresponding rows and columns in C as described in Section 3.1. Right: Visual of our agglomeration procedure. We train a student to match intermediate teacher features pooled over regions generated by pseudo-syllable-boundaries. We use a min-cut algorithm to extract boundaries, and then apply K-Means and Agglomerative clustering to obtain discrete units.", "description": "This figure illustrates the SyllableLM framework. The left-top panel shows the loss prediction matrix (C), which indicates the likelihood of teacher labels (obtained from a pre-trained HuBERT model) given masked input segments. Brighter colors represent higher likelihoods.  A corresponding time-aligned transcript is shown below with predicted syllabic units boundaries displayed as dashed lines. The left-bottom panel is a Mel-spectrogram, visualizing the input audio waveform with masked time spans (gray).  The loss for tokens within the blue and red masked spans are mapped to matrix C. The right panel depicts the iterative agglomeration process. The student HuBERT model aims to match the teacher features pooled over regions defined by pseudo-syllable boundaries. This process uses a min-cut algorithm for boundary extraction and then applies K-means and agglomerative clustering to create distinct units.", "section": "3 Learning Self-Supervised, Syllable-Like Representations from Raw Speech"}, {"figure_path": "tVO3b68Oyp/figures/figures_13_1.jpg", "caption": "Figure 1: Left-Top: The loss prediction matrix C, where brighter is higher likelihood placed on the teacher label. A time-aligned transcript is on the bottom, and predicted cluster unit boundaries span vertically as dashed-lines. Left-Bottom: A Mel-Spectrogram of the input waveform with an example masked timespan in gray. The losses on tokens at timesteps covered by the solid blue and dotted red spans are mapped to their corresponding rows and columns in C as described in Section 3.1. Right: Visual of our agglomeration procedure. We train a student to match intermediate teacher features pooled over regions generated by pseudo-syllable-boundaries. We use a min-cut algorithm to extract boundaries, and then apply K-Means and Agglomerative clustering to obtain discrete units.", "description": "This figure illustrates the process of extracting syllable-like units from raw speech.  The top-left panel shows the loss prediction matrix, where brighter colors indicate higher likelihood of the teacher label. The bottom-left shows a mel-spectrogram with masked regions, illustrating how losses are mapped to the matrix. The right panel shows the agglomeration process, where a student model learns to match teacher features, and K-Means and agglomerative clustering are used to obtain final units.", "section": "3 Learning Self-Supervised, Syllable-Like Representations from Raw Speech"}, {"figure_path": "tVO3b68Oyp/figures/figures_14_1.jpg", "caption": "Figure 1: Left-Top: The loss prediction matrix C, where brighter is higher likelihood placed on the teacher label. A time-aligned transcript is on the bottom, and predicted cluster unit boundaries span vertically as dashed-lines. Left-Bottom: A Mel-Spectrogram of the input waveform with an example masked timespan in gray. The losses on tokens at timesteps covered by the solid blue and dotted red spans are mapped to their corresponding rows and columns in C as described in Section 3.1. Right: Visual of our agglomeration procedure. We train a student to match intermediate teacher features pooled over regions generated by pseudo-syllable-boundaries. We use a min-cut algorithm to extract boundaries, and then apply K-Means and Agglomerative clustering to obtain discrete units.", "description": "This figure illustrates the process of extracting syllabic units from raw speech.  The top left shows a loss prediction matrix, visualizing the model's ability to predict masked segments. The bottom left shows a mel-spectrogram with masked regions highlighted. The right side illustrates the iterative agglomerative clustering process, showing how noisy boundaries are refined to create more precise syllabic units.", "section": "3 Learning Self-Supervised, Syllable-Like Representations from Raw Speech"}, {"figure_path": "tVO3b68Oyp/figures/figures_14_2.jpg", "caption": "Figure 1: Left-Top: The loss prediction matrix C, where brighter is higher likelihood placed on the teacher label. A time-aligned transcript is on the bottom, and predicted cluster unit boundaries span vertically as dashed-lines. Left-Bottom: A Mel-Spectrogram of the input waveform with an example masked timespan in gray. The losses on tokens at timesteps covered by the solid blue and dotted red spans are mapped to their corresponding rows and columns in C as described in Section 3.1. Right: Visual of our agglomeration procedure. We train a student to match intermediate teacher features pooled over regions generated by pseudo-syllable-boundaries. We use a min-cut algorithm to extract boundaries, and then apply K-Means and Agglomerative clustering to obtain discrete units.", "description": "This figure shows the process of extracting syllable-like units from raw speech. The top-left panel displays the loss prediction matrix, which is used to identify noisy syllable boundaries. The bottom-left panel shows a mel-spectrogram of the input waveform. The right panel illustrates the agglomerative clustering technique used to refine the syllable-like units.", "section": "3 Learning Self-Supervised, Syllable-Like Representations from Raw Speech"}, {"figure_path": "tVO3b68Oyp/figures/figures_14_3.jpg", "caption": "Figure 1: Left-Top: The loss prediction matrix C, where brighter is higher likelihood placed on the teacher label. A time-aligned transcript is on the bottom, and predicted cluster unit boundaries span vertically as dashed-lines. Left-Bottom: A Mel-Spectrogram of the input waveform with an example masked timespan in gray. The losses on tokens at timesteps covered by the solid blue and dotted red spans are mapped to their corresponding rows and columns in C as described in Section 3.1. Right: Visual of our agglomeration procedure. We train a student to match intermediate teacher features pooled over regions generated by pseudo-syllable-boundaries. We use a min-cut algorithm to extract boundaries, and then apply K-Means and Agglomerative clustering to obtain discrete units.", "description": "This figure illustrates the process of creating syllabic units from raw speech. The top-left panel shows the loss prediction matrix, which visualizes the correlation between masked spans in the input waveform and the model's prediction losses. The bottom-left panel displays a mel-spectrogram of the input audio. The right panel demonstrates the iterative agglomerative clustering process, where the model dynamically merges speech representations to produce syllabic-like units. The process includes using a min-cut algorithm to extract boundaries, followed by K-Means and agglomerative clustering.", "section": "3 Learning Self-Supervised, Syllable-Like Representations from Raw Speech"}]