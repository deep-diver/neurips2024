[{"figure_path": "JK728xy8G7/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative comparison of SEG with vanilla SDXL [35], SAG [17], and PAG [1] for unconditional generation.", "description": "This table presents a quantitative comparison of the proposed Smoothed Energy Guidance (SEG) method against three other methods: vanilla Stable Diffusion XL (SDXL), Self-Attention Guidance (SAG), and Perturbed Attention Guidance (PAG).  The comparison is based on unconditional image generation and uses three metrics: Fr\u00e9chet Inception Distance (FID), Learned Perceptual Image Patch Similarity (LPIPS) using VGG and AlexNet. Lower FID and LPIPS scores indicate better image quality.  The table shows that SEG achieves a Pareto improvement over existing methods, offering better image quality with fewer side effects.", "section": "5.1 Implementation details"}, {"figure_path": "JK728xy8G7/tables/tables_7_1.jpg", "caption": "Table 2: Text-conditional sampling with different \u03c3.", "description": "This table presents the quantitative results of text-conditional image generation experiments using the SEG method with varying standard deviation (\u03c3) of the Gaussian filter.  The metrics used to evaluate the quality are FID (Fr\u00e9chet Inception Distance), CLIP score (representing image-text alignment), LPIPSvgg (Learned Perceptual Image Patch Similarity using VGG network), and LPIPSalex (Learned Perceptual Image Patch Similarity using AlexNet). Lower FID and LPIPS scores indicate better quality, while a higher CLIP score indicates stronger image-text alignment. The results demonstrate the trade-off between image quality and deviation from the original sample as \u03c3 increases.", "section": "5.3 Controlling image generation with the standard deviation"}]