[{"figure_path": "PSPtj26Lbp/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative results for video-to-4D. Best is bolded. \u2020: results from Gao et al. [15].", "description": "This table presents a quantitative comparison of L4GM against other state-of-the-art video-to-4D generation approaches on a standard benchmark. The metrics used for comparison are LPIPS (lower is better), CLIP (higher is better), and FVD (lower is better), representing perceptual similarity, semantic similarity, and video quality, respectively. The table also shows the inference time taken by each method. The results demonstrate that L4GM significantly outperforms other methods in terms of all three quality metrics while achieving a speedup of 100 to 1000 times.", "section": "6.2 Comparisons to State-of-the-Art Methods"}, {"figure_path": "PSPtj26Lbp/tables/tables_8_1.jpg", "caption": "Table 2: Comparison to baselines by user study on synthesized 4D scenes with 24 examples. Numbers are percentages. Numbers do not add up to 100; difference is due to users voting \u201cno preference\u201d (details in Appendix).", "description": "This table presents the results of a user study comparing L4GM's performance to three other state-of-the-art methods (DG4D, OpenLRM, and STAG4D) across five different aspects: Overall Quality, 3D Appearance, 3D Alignment with Input Video, Motion Alignment with Input Video, and Motion Realism.  Each aspect is rated on a percentage scale based on user preferences from a total of 24 synthesized 4D scene examples.  The table highlights that L4GM receives a higher percentage of favorable user ratings than the other methods across all five criteria.", "section": "6.3 Ablation Studies"}, {"figure_path": "PSPtj26Lbp/tables/tables_19_1.jpg", "caption": "Table 4: Comparison between L4GM and state-of-the-arts approaches on full metrics in the Consistent4D benchmark. Baseline results are from Gao et al. [15].", "description": "This table presents a quantitative comparison of the proposed L4GM model against several state-of-the-art methods on the Consistent4D benchmark.  The metrics used for comparison include LPIPS (Learned Perceptual Image Patch Similarity), CLIP (Contrastive Language\u2013Image Pre-training) score, and FVD (Fr\u00e9chet Video Distance).  Lower LPIPS and FVD scores indicate better perceptual similarity and video quality, respectively, while higher CLIP scores represent better alignment with the ground truth. The table shows that L4GM outperforms existing methods across all metrics. Baseline results from Gao et al. [15] are also included for reference.", "section": "6.2 Comparisons to State-of-the-Art Methods"}, {"figure_path": "PSPtj26Lbp/tables/tables_22_1.jpg", "caption": "Table 5: Ablation results on the Consistent4D benchmark.", "description": "This table presents the ablation study results on the Consistent4D benchmark.  It shows the performance of the L4GM model with different modifications, such as removing temporal attention, adding a time embedding, freezing the LGM model, adding a HexPlane, and using the interpolation model.  Each row corresponds to a different variation of the model, with the baseline model in the first row.  The results are reported using LPIPS, CLIP, and FVD metrics to evaluate the quality of the 4D reconstruction. The table helps to understand the impact of each model component on the overall performance.", "section": "6.3 Ablation Studies"}, {"figure_path": "PSPtj26Lbp/tables/tables_22_2.jpg", "caption": "Table 6: Attention.", "description": "This table presents a comparison of memory usage (in GB) and processing time (in seconds) for different attention mechanisms used in the model.  The methods compared include using only cross-view attention, cross-view attention with temporal attention, cross-view attention with full attention, and full attention alone. The results show that using full attention significantly increases both memory and processing time compared to using only cross-view or cross-view with temporal attention.", "section": "6.3 Ablation Studies"}]