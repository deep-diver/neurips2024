[{"figure_path": "eFrdRuyHR9/figures/figures_2_1.jpg", "caption": "Figure 1: Representative task of finding pollution in a river while following the current. (a) Problem formulation: The star represents the maximizer and the arrows the Markov dynamics. (b) Objective formulation: Orange balls represent potential maximizers, with size corresponding to model uncertainty. (c) Optimization: Deploy a potentially stochastic policy that minimizes our objective.", "description": "This figure illustrates an application of the proposed method to environmental monitoring. Panel (a) shows the problem setup, where the goal is to find the source of pollution (star) while respecting constraints on movement (arrows). Panel (b) illustrates how the uncertainty in the pollution levels is modeled, with larger orange circles representing higher uncertainty. Panel (c) demonstrates how a policy can be created to optimize exploration and minimize the uncertainty.", "section": "1 Introduction"}, {"figure_path": "eFrdRuyHR9/figures/figures_7_1.jpg", "caption": "Figure 2: The Knorr pyrazole synthesis experiment. On the left, we show the quantitative results. The line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, we show ten paths in different colours chosen by the algorithm. The underlying black-box function is shown as the contours, and we can see the discretization as dots. We can see four remaining potential maximizers (in orange), which includes the true one (star). Notice all paths are non-decreasing in residence time, following the transition constraints.", "description": "This figure displays the results of the Knorr pyrazole synthesis experiment. The left side shows quantitative results using line plots for best prediction regret and bar charts for the percentage of runs correctly identifying the best arm per episode. The right side shows ten different paths generated by the algorithm, plotted over contours of the underlying black-box function.  The paths illustrate how the algorithm navigates the search space while adhering to the specified transition constraints (non-decreasing residence time).  The figure highlights the algorithm's ability to identify the true maximizer while respecting constraints.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_7_2.jpg", "caption": "Figure 6: High noise constrained Ypacarai experiment with immediate feedback.", "description": "The figure shows the results of the high noise constrained Ypacarai experiment with immediate feedback.  The lines represent the average regret, and the bars show the percentage of runs that correctly identified the best arm at the end of each episode.  Three different Bayesian Optimization methods are compared: Greedy-UCB, MDP-EI, and MDP-BO.  The graph illustrates the performance of each method over multiple episodes, demonstrating MDP-BO's superior performance in this challenging scenario.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_7_3.jpg", "caption": "Figure 3: Results for Ypacarai and free electron-laser tuning experiments. On the left, the line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, We plot the regret and compare against standard BO without accounting for movement-dependent noise.", "description": "This figure presents the results of two experiments: monitoring Lake Ypacarai and tuning a free-electron laser.  The left side shows the average regret (line plot) and the success rate of identifying the best arm (bar chart) over several episodes for both experiments. The right side compares the regret of the proposed method to a standard Bayesian optimization approach that doesn't consider movement-dependent noise, specifically for the free-electron laser tuning experiment.", "section": "Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_8_1.jpg", "caption": "Figure 4: Results of experiments on the asynchronous and synchronous benchmarks. We plot the median predictive regret and the 10% and 90% quantiles. For the asynchronous experiments, we can see that the paths taken by MDP-BO-TS are more consistent, and the final performance is comparable to TrSnAKe. While in the asynchronous setting, we found creating the maximization set using Thompson Sampling gave a stronger performance, in the synchronous setting, UCB is preferred. LSR gives a very strong performance, comparable to MDP-BO-UCB in almost all benchmarks.", "description": "The figure presents the median predictive regret and quantiles for both synchronous and asynchronous benchmarks across six test functions.  It compares the performance of MDP-BO-TS, MDP-BO-UCB, TrSnAKe, and LSR, highlighting the effects of different maximization set creation methods and synchronization on the overall performance.", "section": "Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_15_1.jpg", "caption": "Figure 5: Visual abstract of the work. In black we show the method presented in this paper, with literature connections shown in blue. In red we show solutions which we did not pursue due to intractability. The problem creates the (a) need to plan ahead. To do this, we take inspiration from hypothesis testing and focus on (b) the variance reduction in a set of maximizers, which leads to our (c) acquisition function. The objective is the same as Fiez et al. [30] introduced in the linear bandits literature from a frequentist perspective. To optimize it, we follow developments in Mutn\u00fd et al. [17], Hazan et al. [34] by (d) relaxing the acquisition function to the space of state-action distributions and (e) solving the planning problem using the Frank-Wolfe algorithm. This consists of iteratively solving tractable (f) reinforcement learning sub-problems which give us optimal Markov policies. We then apply adaptive resampling to obtain (g) Non-Markovian policies.", "description": "This figure provides a visual summary of the algorithm presented in the paper, highlighting the key steps and their relationships to existing research. It shows how the authors' approach addresses the challenges of transition-constrained Bayesian optimization by combining elements of hypothesis testing, acquisition function optimization, and reinforcement learning.", "section": "A Visual abstract of the algorithm"}, {"figure_path": "eFrdRuyHR9/figures/figures_16_1.jpg", "caption": "Figure 2: The Knorr pyrazole synthesis experiment. On the left, we show the quantitative results. The line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, we show ten paths in different colours chosen by the algorithm. The underlying black-box function is shown as the contours, and we can see the discretization as dots. We can see four remaining potential maximizers (in orange), which includes the true one (star). Notice all paths are non-decreasing in residence time, following the transition constraints.", "description": "This figure presents the results of applying the proposed algorithm to the Knorr pyrazole synthesis experiment.  The left side shows the average regret and the success rate of identifying the true maximum over episodes. The right side visualizes ten sample trajectories in the search space, highlighting how the algorithm respects the non-decreasing residence time constraint. The contours represent the true objective function, while the dots show discretized points, indicating the chosen search locations and the remaining potential maximizers.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_16_2.jpg", "caption": "Figure 2: The Knorr pyrazole synthesis experiment. On the left, we show the quantitative results. The line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, we show ten paths in different colours chosen by the algorithm. The underlying black-box function is shown as the contours, and we can see the discretization as dots. We can see four remaining potential maximizers (in orange), which includes the true one (star). Notice all paths are non-decreasing in residence time, following the transition constraints.", "description": "The figure shows the results of the Knorr pyrazole synthesis experiment using the proposed algorithm.  The left panel presents quantitative results showing regret and the percentage of successful maximizer identification. The right panel displays ten different trajectories generated by the algorithm within the constrained search space, with the optimal point and several potential maximizers highlighted.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_17_1.jpg", "caption": "Figure 2: The Knorr pyrazole synthesis experiment. On the left, we show the quantitative results. The line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, we show ten paths in different colours chosen by the algorithm. The underlying black-box function is shown as the contours, and we can see the discretization as dots. We can see four remaining potential maximizers (in orange), which includes the true one (star). Notice all paths are non-decreasing in residence time, following the transition constraints.", "description": "This figure presents the results of an experiment on the Knorr pyrazole synthesis.  The left side shows quantitative results using line plots for best prediction regret and bar charts indicating successful best arm identification. The right side visualizes ten different optimization paths, highlighting the impact of transition constraints by showing that all paths are non-decreasing in residence time. The contours represent the underlying black-box function, and the dots show the discretization.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_17_2.jpg", "caption": "Figure 2: The Knorr pyrazole synthesis experiment. On the left, we show the quantitative results. The line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, we show ten paths in different colours chosen by the algorithm. The underlying black-box function is shown as the contours, and we can see the discretization as dots. We can see four remaining potential maximizers (in orange), which includes the true one (star). Notice all paths are non-decreasing in residence time, following the transition constraints.", "description": "This figure presents the results of applying the proposed algorithm to the Knorr pyrazole synthesis experiment. The left side shows the average regret (the difference between the true optimal value and the algorithm's prediction) over multiple runs, comparing it against several baseline methods.  The bar charts show the percentage of successful runs in which the algorithm correctly identified the true maximizer. The right side illustrates ten different trajectories (paths) produced by the algorithm in the search space, highlighting their adherence to transition constraints (non-decreasing residence time). The contour plot displays the true underlying black-box function, with dots representing discretized points and the true maximizer marked by a star.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_18_1.jpg", "caption": "Figure 6: High noise constrained Ypacari experiment with immediate feedback.", "description": "This figure shows the results of a high-noise constrained Ypacarai experiment using immediate feedback.  It compares the performance of three different algorithms: Greedy-UCB, MDP-EI, and MDP-BO. The x-axis represents the iteration number, and the y-axis shows the average regret. The shaded areas represent the 10th and 90th percentile ranges. The results indicate that MDP-BO outperforms the other two algorithms in terms of both average regret and the consistency of its performance across multiple runs.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_27_1.jpg", "caption": "Figure 12: Lake Ypacarai with the added movement constraints. We show one local optimum and one global one. The constraints of the problem requiring beginning and ending the optimization in the dark square.", "description": "This figure illustrates the Lake Ypacarai environmental monitoring problem with added movement constraints.  The lake is represented as a graph, with nodes representing possible measurement locations and edges representing permissible movements between them.  Obstacles in the lake restrict movement, creating transition constraints in the optimization problem.  The goal is to find the location with the largest contamination (global optimum), indicated by a star, starting from a specified initial state (black square) and ending at a designated final state (dark square).  The red line shows the path chosen by the algorithm to navigate the constraints and reach the goal.", "section": "5.2 Monitoring Lake Ypacarai"}, {"figure_path": "eFrdRuyHR9/figures/figures_27_2.jpg", "caption": "Figure 2: The Knorr pyrazole synthesis experiment. On the left, we show the quantitative results. The line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, we show ten paths in different colours chosen by the algorithm. The underlying black-box function is shown as the contours, and we can see the discretization as dots. We can see four remaining potential maximizers (in orange), which includes the true one (star). Notice all paths are non-decreasing in residence time, following the transition constraints.", "description": "This figure presents results from the Knorr pyrazole synthesis experiment.  The left side shows quantitative results: best prediction regret over episodes (lines) and the percentage of runs correctly identifying the best arm (bars). The right side visualizes ten different trajectories (colored lines) generated by the algorithm, overlaid on a contour plot of the underlying black-box function and a dot representation of the discretized search space.  The paths are constrained to non-decreasing residence times. Four potential maximizers (orange) remain, with the actual maximizer marked with a star.", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_28_1.jpg", "caption": "Figure 2: The Knorr pyrazole synthesis experiment. On the left, we show the quantitative results. The line plots denote the best prediction regret, while the bar charts denote the percentage of runs that correctly identify the best arm at the end of each episode. On the right, we show ten paths in different colours chosen by the algorithm. The underlying black-box function is shown as the contours, and we can see the discretization as dots. We can see four remaining potential maximizers (in orange), which includes the true one (star). Notice all paths are non-decreasing in residence time, following the transition constraints.", "description": "The figure presents results of the Knorr pyrazole synthesis experiment. The left side shows quantitative results (regret and success rate in identifying the best arm) while the right side visualizes ten different paths followed by the algorithm in the search space.  The paths respect the transition constraint of non-decreasing residence time, as shown by the arrows. The contours represent the underlying black-box function, showing the algorithm's progress towards the true maximizer (star).", "section": "5 Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_28_2.jpg", "caption": "Figure 15: Ablation study into the size of the Thompson Sampling maximization set in the asynchronous Hartmann3D function. We can see that the performance of the algorithm is very similar for all values of K = 25, 50, 100.", "description": "This figure shows an ablation study on the size of the Thompson Sampling maximization set (K) used in the asynchronous Hartmann3D benchmark. The results show that the algorithm's performance remains consistent across different values of K (25, 50, and 100), suggesting that the choice of K is not a highly sensitive parameter affecting performance.", "section": "E.5.2 Size of batch for approximating the set of maximizers"}, {"figure_path": "eFrdRuyHR9/figures/figures_28_3.jpg", "caption": "Figure 4: Results of experiments on the asynchronous and synchronous benchmarks. We plot the median predictive regret and the 10% and 90% quantiles. For the asynchronous experiments, we can see that the paths taken by MDP-BO-TS are more consistent, and the final performance is comparable to TrSnAKe. While in the asynchronous setting, we found creating the maximization set using Thompson Sampling gave a stronger performance, in the synchronous setting, UCB is preferred. LSR gives a very strong performance, comparable to MDP-BO-UCB in almost all benchmarks.", "description": "This figure displays the median predictive regret, along with 10th and 90th percentiles, for asynchronous and synchronous benchmark experiments.  It compares the performance of different algorithms (MDP-BO-TS, MDP-BO-UCB, TrSnAKe, and LSR), highlighting the superior performance of Thompson Sampling in asynchronous settings and UCB in synchronous settings.  MDP-BO-UCB and LSR show similar strong results.", "section": "Experiments"}, {"figure_path": "eFrdRuyHR9/figures/figures_29_1.jpg", "caption": "Figure 17: Comparison of using XY-allocation against G-allocation as the basis for the objective. In both cases the maximization sets were created using Thompson Sampling. Overall the performances were often similar, however in a few examples, such as Branin2D which we showcase here, G-allocation performed very poorly. This is consistent with what we can expect from the bandits literature.", "description": "This figure compares the performance of two different allocation methods (XY-allocation and G-allocation) used in the Bayesian Optimization algorithm.  Both methods use Thompson Sampling to create maximization sets. While generally showing similar performance, the figure highlights a specific case (Branin2D) where G-allocation significantly underperforms XY-allocation, aligning with findings from the bandit literature.", "section": "F XY-allocation vs G-allocation"}, {"figure_path": "eFrdRuyHR9/figures/figures_32_1.jpg", "caption": "Figure 18: Comparing the numerical solution against the solutions found in equation (36).", "description": "This figure compares the numerical solution of an ODE (ordinary differential equation) model with an analytical (exact) solution derived from equation 36 in the paper. The purpose is to validate the accuracy of the analytical solution against a numerical approximation.  The plot shows the yield over time, with the numerical solution closely tracking the exact solution, demonstrating good agreement between the two approaches.", "section": "H Kernel for ODE Knorr pyrazole synthesis"}]