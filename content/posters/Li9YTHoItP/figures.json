[{"figure_path": "Li9YTHoItP/figures/figures_4_1.jpg", "caption": "Figure 1: The overview of our framework. For the question q in the constructed dataset, The open-sourced auxiliary model prevent the high-probability answers based on existing answer entities A from the black-box LLM (i.e., GPT-4) and generate 4 categories of ambiguous knowledge that are unfamiliar knowledge for the target model.", "description": "This figure presents a flowchart summarizing the framework for perceiving the knowledge boundary of LLMs using semi-open-ended questions. It begins with dataset construction, involving domain selection, question generation, and answer collection using an LLM.  To discover more ambiguous answers, an open-sourced auxiliary model is applied to reduce the generation probability of high-probability answers.  Finally, ambiguous knowledge verification compares LLM self-evaluation against RAG-based evaluation, categorizing answers into four types: unqualified answers, inaccurate evaluations, hidden correct answers, and unexpected wrong evaluations.  These categories represent different types of knowledge beyond the LLM's boundary.", "section": "3 Perception of Knowledge Boundary for LLM via Semi-open-ended QA"}]