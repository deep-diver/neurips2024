[{"figure_path": "JWF1dN4TOd/figures/figures_4_1.jpg", "caption": "Figure 1: Training process of MarketFCNet. On each iteration, the batch of M independent buyers are drawn, each buyer and each good are represented as k-dimension context. The (i, j)'th element in the allocation matrix represents the allocation computed from i'th buyer and j'th good. MarketFCNet training process alternates between the training of allocation network and prices. The training of allocation network need to achieve an unbiased estimator Lp(x\u03b8; \u03bb) of the loss function Lp(x\u03b8; \u03bb), followed by gradient descent. The training of prices need to get an unbiased estimator \u0394\u03bbj of \u0394\u03bbj, followed by ALMM updating rule \u03bbj \u2190 \u03bbj + \u03b2t\u0394\u03bbj.", "description": "This figure illustrates the training process of the MarketFCNet model.  It shows how batches of buyers and goods (represented by their contexts) are fed into an allocation network, which estimates the allocation of goods to buyers.  The model then updates its parameters using gradient descent to minimize a loss function, and the prices are updated using the ALMM method. The process iteratively refines the allocation and prices until convergence to market equilibrium.", "section": "4.1 Problem Reformulation"}, {"figure_path": "JWF1dN4TOd/figures/figures_8_1.jpg", "caption": "Figure 2: The Nash Gap and GPU running time for different algorithms: MarketFCNet, EG and EG-m. Different colors represent for different algorithm. Market size is chosen as n = 4,194,304 buyers and m = 10 goods.", "description": "This figure shows the Nash Gap and GPU running time for different algorithms (MarketFCNet, EG, and EG-m) with a market size of n = 4,194,304 buyers and m = 10 goods.  Different colors represent different algorithms. The subfigures (a) and (b) illustrate the results with different context distributions (Normal, Uniform, and Exponential), while subfigures (c) and (d) present the results with different CES utilities parameters (\u03b1 = 1, 0.5, 0, -1). The figure demonstrates the performance of MarketFCNet compared to the baselines in terms of accuracy (Nash Gap) and computational efficiency (GPU running time) across various market settings.", "section": "6 Experiments"}, {"figure_path": "JWF1dN4TOd/figures/figures_8_2.jpg", "caption": "Figure 3: The Nash Gap and GPU running time for different algorithms: MarketFCNet, EG and EG-m. Different colors represent for different algorithm. Market size is chosen as n = 218, 220, 222 buyers and m = 5, 10, 20 goods.", "description": "This figure shows the Nash Gap and GPU running time for three algorithms (MarketFCNet, EG, and EG-m) across different market sizes.  The market size is varied by changing the number of buyers (n = 2<sup>18</sup>, 2<sup>20</sup>, 2<sup>22</sup>) and the number of goods (m = 5, 10, 20).  Different colors represent each algorithm.  The figure helps to visualize how the performance of each algorithm changes as the market scale increases.", "section": "6 Experiments"}, {"figure_path": "JWF1dN4TOd/figures/figures_8_3.jpg", "caption": "Figure 3: The Nash Gap and GPU running time for different algorithms: MarketFCNet, EG and EG-m. Different colors represent for different algorithm. Market size is chosen as n = 218, 220, 222 buyers and m = 5, 10, 20 goods.", "description": "This figure compares the performance of MarketFCNet, EG, and EG-m across different market scales. The x-axis represents the number of buyers (n), and the y-axis represents the number of goods (m).  The bars show Nash Gap values for each algorithm and market size combination, illustrating the approximation quality. Additionally, GPU running times are displayed for each algorithm under various conditions.  The figure shows that MarketFCNet maintains relatively constant performance across varying market sizes, while the baselines show increased running times and Nash Gaps as the market expands.", "section": "6.2 Experiment Results"}]