[{"type": "text", "text": "Large-Scale Contextual Market Equilibrium Computation through Deep Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Market equilibrium is one of the most fundamental solution concepts in economics   \n2 and social optimization analysis. Existing works on market equilibrium computa  \n3 tion primarily focus on settings with a relatively small number of buyers. Motivated   \n4 by this, our paper investigates the computation of market equilibrium in scenarios   \n5 with a large-scale buyer population, where buyers and goods are represented by   \n6 their contexts. Building on this realistic and generalized contextual market model,   \n7 we introduce MarketFCNet, a deep learning-based method for approximating mar  \n8 ket equilibrium. We start by parameterizing the allocation of each good to each   \n9 buyer using a neural network, which depends solely on the context of the buyer   \n10 and the good. Next, we propose an efficient method to estimate the loss function of   \n11 the training algorithm unbiasedly, enabling us to optimize the network parameters   \n12 through gradient descent. To evaluate the approximated solution, we introduce   \n13 a metric called Nash Gap, which quantifies the deviation of the given allocation   \n14 and price pair from the market equilibrium. Experimental results indicate that   \n15 MarketFCNet delivers competitive performance and significantly lower running   \n16 times compared to existing methods as the market scale expands, demonstrating   \n17 the potential of deep learning-based methods to accelerate the approximation of   \n18 large-scale contextual market equilibrium. ", "page_idx": 0}, {"type": "text", "text": "19 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "20 Market equilibrium is a solution concept in microeconomics theory, which studies how individuals   \n21 amongst groups will exchange their goods to get each one better off [51]. The importance of   \n22 market equilibrium is evidenced by the 1972 Nobel Prize awarded to John R. Hicks and Kenneth   \n23 J. Arrow \u201cfor their pioneering contributions to general economic equilibrium theory and welfare   \n24 theory\u201d [58]. Market equilibrium has wide application in fair allocation [32], as a few examples,   \n25 fairly assigning course seats to students [11] or dividing estates, rent, fares, and others [35]. Besides,   \n26 market equilibrium are also considered for ad auctions with budget constraints where money has real   \n27 value [15, 16].   \n28 Existing works often use traditional optimization method or online learning technique to solve market   \n29 equilibrium, which can tackle one market with around 400 buyers and goods in experiments [30, 52].   \n30 However, in realistic scenarios, there might be millions of buyers in one market (e.g. job market,   \n31 online shopping market). In these scenarios, the description complexity for the market is $O(n m)$ and   \n32 it needs at least $O(n m)$ cost to do one optimization step for the market, if there are $n$ buyers and $m$   \n33 goods in the market, which is unacceptable when $n$ is extremely large and potentially infinite. In this   \n34 case, and traditional optimization methods do not work anymore.   \n35 However, contextual models come to the rescue. The success of contextual auctions[21, 5] demon  \n36 strate the power of contextual models, in which each bidder and item are represented as context and   \n37 the value (or the distribution) of item to bidder is determined by the contexts. In this way, auctions   \n38 as well as other economic problems can be described in a more memory-efficient way, making it   \n39 possible to accelerate the computation on these problems. Inspired by the models of contextual   \n40 auctions, we propose the concept of contextual markets in a similar way. We verify that contextual   \n41 markets can be useful to model large-scale markets aforementioned, since the real market can be   \n42 assumed to be within some low dimension space, and the values of goods to buyers are often not   \n43 hard to speculate given the knowledge of goods and buyers [46, 45]. Besides, contextual models   \n44 never lose expressive power compared with raw models[7], giving contextual markets capabilities to   \n45 generalize over traditional markets.   \n46 This paper initiates the study of deep learning for contextual market equilibrium computation   \n47 with a large number of buyers. The description complexity of contextual markets is $O({\\bar{n}}+m)$ ,   \n48 if there are $n$ buyers and $m$ items in the market, making them memory-efficient and helpful for   \n49 follow-up equilibrium computation while holding the market structure. Following the framework of   \n50 differentiable economics [18, 26, 62], we propose a deep-learning based approach, MarketFCNet,   \n51 in which one optimization step costs only $O(m)$ rather than $O(n m)$ in traditional methods, greatly   \n52 accelerating the computation of market equilibrium. MarketFCNet takes the representations of one   \n53 buyer and one good as input, and outputs the allocation of the good to the buyer. The training on   \n54 MarketFCNet targets at an unbiased estimator of the objective function of EG-convex program, which   \n55 can be formed by independent samples of buyers. By this way, we optimize the allocation function   \n56 on \u201cbuyer space\u201d implicitly, rather than optimizing the allocation to each buyer directly. Therefore,   \n57 MarketFCNet can reduce the algorithm complexity such that it becomes independent of $n$ , i.e., the   \n58 number of buyers.   \n59 The effectiveness of MarketFCNet is demonstrated by our experimental results. As the market   \n60 scale expands, MarketFCNet delivers competitive performance and significantly lower running times   \n61 compared to existing methods in different experimental settings, demonstrating the potential of deep   \n62 learning-based methods to accelerate the approximation of large-scale contextual market equilibrium. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "63 The contributions of this paper consist of three parts, ", "page_idx": 1}, {"type": "text", "text": "64 \u2022 We proposes a method, MarketFCNet, to approximate the contextual market equilibrium in   \n65 which the number of buyers is large.   \n66 \u2022 We proposes Nash Gap to quantify the deviation of the given allocation and price pair from   \n67 the market equilibrium.   \n68 \u2022 We conduct extensive experiments, demonstrating promising performance on the approxi  \n69 mation measure and running time compared with existing methods. ", "page_idx": 1}, {"type": "text", "text": "70 2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "71 The history of market equilibrium arises from microeconomics theory, where the concept of com  \n72 petitive equilibrium [51, $\\S10]$ was proposed, and the existence of market equilibrium is guaranteed   \n73 in a general setting [3, 61]. Eisenberg and Gale [28] first considered the linear market case, and   \n74 proved that the solution of EG-convex program constitutes a market equilibrium, which lays the   \n75 polynomial-time algorithmic foundations for market equilibrium computation. Eisenberg [27] later   \n76 showed that EG program also works for a class of CCNH utility functions. Shmyrev program later is   \n77 also proposed to solve market equilibrium with linear utility with a perspective shift from allocation   \n78 to price [57], while Cole et al. [14] later found that Shmyrev program is the dual problem of EG   \n79 program with a change of variables. There are also a branch of literature that consider computational   \n80 perspective in more general settings such as indivisible goods [54, 19, 20] and piece-wise linear   \n81 utility [60, 33, 34].   \n82 There are abundant of works that present algorithms to solve the market equilibrium and shows   \n83 the convergence results theoretically [13]. Gao and Kroer [30] discusses the convergence rates of   \n84 first-order algorithms for EG convex program under linear, quasi-linear and Leontief utilities. Nan   \n85 et al. [52] later designs stochastic optimization algorithms for EG convex program and Shmyrev   \n86 program with convergence guarantee and show some economic insight. Jalota et al. [42] proposes an   \n87 ADMM algorithm for CCNH utilities and shows linear convergence results. Besides, researchers   \n88 are more engaged in designing dynamics that possess more economic insight. For example, PACE   \n89 dynamic [32, 48, 65] and proportional response dynamic [63, 66, 12], though the original idea of   \n90 PACE arise from auction design [16, 15].   \n91 With the fast growth of machine learning and neural network, many existing works aim at resolving   \n92 economic problem by deep learning approach, which falls into the differentiate economy framework   \n93 [26]. A mainstream is to approximate the optimal auction with differentiable models by neural   \n94 networks [25, 29, 36, 55]. The problem of Nash equilibrium computation in normal form games   \n95 [22, 50, 23] and optimal contract design [62] through deep learning also attracts researchers\u2019 attentions.   \n96 Among these methodologies, transformer architecture [50, 21, 47] is widely used in solving economic   \n97 problems.   \n98 To the best of our knowledge, no existing works try to approximate market equilibrium through deep   \n99 learning. Besides, although some literature focuses on low-rank markets and representative markets   \n100 [46, 45], our works firstly propose the concept of contextual market. We believe that our approach   \n101 will pioneer a promising direction for large-scale contextual market equilibrium computation. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "102 3 Contextual Market Modelling ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "103 In this section, we focus on the model of contextual market equilibrium in which goods are assumed to   \n104 be divisible. Let the market consist of $n$ buyers, denoted as $1,...,n$ , and $m$ goods, denoted as $1,...,m$ .   \n105 We denote $[k]$ as the abbreviation of the set $\\{1,2,\\ldots,k\\}$ . Each buyer $i\\in\\bar{[n]}$ has a representation $b_{i}$ ,   \n106 and each good $j\\in[m]$ has a representation $g_{j}$ . We assume that $b_{i}$ belongs to the buyer representation   \n107 space $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , and $g_{j}$ belongs to the good representation space $\\mathcal{G}$ . For a buyer with representation $b\\in{\\mathfrak{B}}$ ,   \n108 she has budget $B(b)>0$ . Denote $Y(g)>0$ as the supply of good with representation $g$ . Although   \n109 many existing works [30] assume that each good $j$ has unit supply (i.e. $\\mathbf{\\bar{\\boldsymbol{Y}}}(g)\\equiv1$ for all $g\\in{\\mathcal{G}}$ )   \n110 without loss of generality, their results can be easily generalized to our settings.   \n111 An allocation is a matrix $\\pmb{x}=(x_{i j})_{i\\in[n],j\\in[m]}\\in\\mathbb{R}_{+}^{n\\times m}$ , where $x_{i j}$ is the amount of good $j$ allocated   \n112 to buyer $i$ . We denote $\\pmb{x}_{i}=(x_{i1},\\dots,x_{i m})$ as the vector of bundle of goods that is allocated to buyer   \n113 $i$ . The buyers\u2019 utility function is denoted as $u:B\\times\\mathbb{R}_{+}^{m}\\to\\mathbb{R}_{+}$ , here $u(b_{i};\\pmb{x}_{i})$ denotes the utility of   \n114 buyer $i$ with representation $b_{i}$ when she chooses to buy $\\pmb{x}_{i}$ . We denote $u_{i}(\\pmb{x}_{i})$ as an equivalent form   \n115 of $u(b_{i};\\pmb{x}_{i})$ and often refer them as the same thing. Similarly, $B(b_{i}),Y(g_{j})$ and $B_{i},Y_{j}$ are often   \n116 referred to as the same thing, respectively.   \n117 Let $\\pmb{p}=(p_{1},\\dots,p_{m})\\in\\mathbb{R}_{+}^{m}$ be the prices of the goods, the demand set of buyer with representation   \n118 $b_{i}$ is defined as the set of utility-maximizing allocations within budget constraint. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\nD(b_{i};p):=\\operatorname*{arg\\,max}_{\\pmb{x}_{i}}\\left\\{u(b_{i};\\pmb{x}_{i})\\mid\\pmb{x}_{i}\\in\\mathbb{R}_{+}^{m},\\,\\langle\\pmb{p},\\pmb{x}_{i}\\rangle\\leq B(b_{i})\\right\\}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "119 A contextual market is a 4-tuple: $\\mathcal{M}=\\langle n,m,(b_{i})_{i\\in[n]},(g_{j})_{j\\in[m]}\\rangle$ , where buyer utility $u(b_{i};\\pmb{x}_{i})$ is   \n120 known given the information of the market. We also assume budget function $B:B\\to\\mathbb{R}_{+}$ represents   \n121 the budget of buyers and capacity function $Y:{\\mathcal{G}}\\rightarrow\\mathbb{R}_{+}$ represents the supply of goods. All of   \n122 $u$ , $B$ and $Y$ are assumed to be public knowledge and excluded from a market representation. This   \n123 assumption mainly comes from two aspects: (1) these functions can be learned from historical data   \n124 and (2) budgets and supplies can be either encoded in $b$ and $g$ in some way.   \n125 The market equilibrium is represented as a pair $(x,p),\\,x\\in\\mathbb{R}_{+}^{n\\times m},\\;p\\in\\mathbb{R}_{+}^{m}$ , which satisfies the   \n126 following conditions. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "127 ", "page_idx": 2}, {"type": "text", "text": "128 ", "page_idx": 2}, {"type": "text", "text": "\u2022 Buyer optimality: $\\pmb{x}_{i}\\in D(b_{i},\\pmb{p})$ for all $i\\in[n]$ , \u2022 Market clearance: $\\textstyle\\sum_{i=1}^{n}x_{i j}\\leq Y(g_{j})$ for all $j\\in[m]$ , and equality must hold if $p_{j}>0$ . ", "page_idx": 2}, {"type": "text", "text": "129 We say that $u_{i}$ is homogeneous (with degree 1) if it satisfies $u_{i}(\\alpha{\\pmb x}_{i})=\\alpha u_{i}({\\pmb x}_{i})$ for any $x_{i}\\geq0$ and   \n130 $\\alpha>0$ [53, $\\S6.2]$ . Following existing works, we assume that $u_{i}\\mathbf{s}$ are CCNH utilities, where CCNH   \n131 represents for concave, continuous, non-negative, and homogeneous functions[30]. For CCNH   \n132 utilities, a market equilibrium can be computed using the following Eisenberg-Gale convex program   \n133 (EG): ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\sum_{i=1}^{n}B_{i}\\log u_{i}(\\pmb{x}_{i})\\quad{\\mathrm{s.t.}}\\ \\sum_{i=1}^{n}x_{i j}\\leq Y_{j},\\ \\pmb{x}\\geq0.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "134 Theorem 3.1 shows that the market equilibrium can be represented as the optimal solution of (EG). ", "page_idx": 2}, {"type": "text", "text": "135 Theorem 3.1 (Gao and Kroer [30]). Let $u_{i}$ be concave, continuous, non-negative and homogeneous   \n136 (CCNH). Assume $u_{i}(\\mathbf{1})>0$ for all i. Then, $(i)$ (EG) has an optimal solution and $(i i)$ any optimal   \n137 solution x to (EG) together with its optimal Lagrangian multipliers $\\pmb{p}^{*}\\in\\mathbb{R}_{+}^{m}$ constitute a market   \n138 equilibrium, up to arbitrary assignment of zero-price items. Furthermore, $\\langle\\pmb{p}^{*},\\pmb{x}_{i}^{*}\\rangle=B_{i}$ for all $i$ .   \n139 Based on Theorem 3.1, it\u2019s easy to find that we can always assume $\\textstyle\\sum_{i\\in[n]}x_{i j}=Y_{j}$ while preserving   \n140 the existence of market equilibrium, which states as follows.   \n141 Proposition 3.2. Following the assumptions in Theorem 3.1. For the following EG convex program   \n142 with equality constraints, ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\sum_{i=1}^{n}B_{i}\\log u_{i}(\\pmb{x}_{i})\\quad\\mathrm{s.t.}\\,\\sum_{i=1}^{n}x_{i j}=Y_{j},\\;\\pmb{x}\\geq0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "143 Then, an optimal solution $x^{*}$ together with its Lagrangian multipliers $\\pmb{p}^{*}\\in\\mathbb{R}_{+}^{m}$ constitute a market   \n144 equilibrium. Moreover, assume more that for each good j, there is some buyer i such that \u2202\u2202xuiij > $\\begin{array}{r}{\\frac{\\partial u_{i}}{\\partial x_{i j}}>0}\\end{array}$   \n145 always hold whenever $u_{i}(\\pmb{x}_{i})>0,$ , then all prices are strictly positive in market equilibrium. As $a$   \n146 consequence, Equation (EG) and Equation (2) derive the same solution.   \n147 We leave all proofs to Appendix B. Since the additional assumption in Proposition 3.2 is fairly weak,   \n148 without further clarification, we always assume the conditions in Proposition 3.2 hold and the market   \n149 clearance condition becomes $\\textstyle\\sum_{i\\in[n]}x_{i j}=Y(g_{j})$ , $\\forall j\\in[m]$ . ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "150 4 MarketFCNet ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "151 In this section, we introduce the MarketFCNet (denoted as Market Fully-Connected Network)   \n152 approach to solve the market equilibrium when the number of buyers is large and potentially infinite.   \n153 MarketFCNet is a sampling-based methodology, and the key point is to design an unbiased estimator   \n154 of an objective function whose solution coincides with the market equilibrium. The main advantage   \n155 is that it has the potential to fti the infinite-buyer case without scaling the computational complexity.   \n156 Therefore, MarketFCNet is scalable with the number of buyers varies. ", "page_idx": 3}, {"type": "text", "text": "157 4.1 Problem Reformulation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "158 Following the idea of differentiable economics [26], we consider parameterized models to represent   \n159 the allocation of good $j$ to buyer $i$ , denoted as $x_{\\theta}(b_{i},g_{j})$ , and call it allocation network, where $\\theta$ is the   \n160 network parameter. Given buyer $i$ and good $j$ , the network can automatically compute the allocation   \n161 $x_{i j}\\,=\\,x_{\\theta}^{\\bar{\\theta}}(b_{i},g_{j})$ . The allocation to buyer $i$ is represented as $\\pmb{x}_{i}\\,=\\,\\pmb{x}_{\\theta}(\\dot{b}_{i},\\pmb{g})$ and the allocation   \n162 matrix is represented as $\\pmb{x}=\\pmb{x}_{\\theta}(\\pmb{b},\\pmb{g})$ . Then the market clearance constraint can be reformulated as   \n163 $\\begin{array}{r}{\\sum_{i\\in[n]}x_{\\theta}(\\bar{b}_{i},g_{j})=Y(g_{j}),\\forall j\\in[m]}\\end{array}$ and the price constraint can be reformulated as ${\\pmb x}_{\\theta}({\\pmb b},{\\pmb g})\\geq0$   \n164 Let $b$ be uniformly distributed from $B=\\{b_{i}:i\\in[n]\\}$ , then the EG program (EG) becomes, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{x_{\\theta}}{\\operatorname*{max}}}&{\\mathrm{OBJ}(x_{\\theta})=\\mathbb{E}_{b}[B(b)\\log u(b;{\\mathbf x}_{\\theta}(b,\\pmb{g}))]}\\\\ {\\mathrm{s.t.}}&{\\mathbb{E}_{b}[x_{\\theta}(b,g_{j})]=Y(g_{j})/n,\\forall j\\in[m]}\\\\ &{{\\pmb x}_{\\theta}({\\pmb b},{\\pmb g})\\geq0}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "165 For simplicity, we take $Y(g_{j})/n\\equiv1$ for all $g_{j}$ . ", "page_idx": 3}, {"type": "text", "text": "166 4.2 Optimization ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "167 The second constraint in (EG-FC) can be easily handled by the network architecture (for example,   \n168 network with a softplus layer $\\sigma(x)=\\log(1+\\exp(x))$ . As for the first constraint, from Theorem 3.1,   \n169 we know the prices of goods are simply the Lagrangian multipliers for the first constraint in (EG-FC).   \n170 Therefore, we employ the Augmented Lagrange Multiplier Method (ALMM) to solve the problem   \n171 (EG-FC). We define $\\mathcal{L}_{\\rho}(x_{\\theta},\\lambda)$ as the Lagrangian, which has the form: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\rho}(x_{\\theta};\\lambda)=-\\;\\mathrm{OBJ}(x_{\\theta})+\\sum_{j=1}^{m}\\lambda_{j}\\left(\\mathbb{E}_{b}[x_{\\theta}(b,g_{j})]-1\\right)+\\frac{\\rho}{2}\\sum_{j=1}^{m}\\left(\\mathbb{E}_{b}[x_{\\theta}(b,g_{j})]-1\\right)^{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Figure 1: Training process of MarketFCNet. On each iteration, the batch of $M$ independent buyers are drawn. each buyer and each good are represented as $k$ -dimension context. The $(i,j)$ \u2019th element in the allocation matrix represents the allocation computed from $i$ \u2019th buyer and $j'$ th good. MarketFCNet training process alternates between the training of allocation network and prices. The training of allocation network need to achieve an unbiased estimator $\\widehat{\\mathcal{L}}_{\\rho}(x_{\\theta};\\lambda)$ of the loss function $\\mathcal{L}_{\\rho}(x_{\\theta};\\lambda)$ , followed by gradient descent. The training of prices need to get an unbiased estimator $\\widehat{\\Delta}\\lambda_{j}$ of $\\Delta\\lambda_{j}$ , followed by ALMM updating rule $\\lambda_{j}\\leftarrow\\lambda_{j}+\\beta_{t}\\widehat{\\Delta}\\lambda_{j}$ . ", "page_idx": 4}, {"type": "image", "img_path": "JWF1dN4TOd/tmp/330501e3105017941ec301e7eaa710d545a5e6e1db8de23dcfc392677c294f0a.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "172 Directly computing the objective function seems intractable due to the potentially infinite data size.   \n173 Therefore, we follow the framework in learning theory culture that we only guarantee to achieve an   \n174 unbiased gradient of the objective function [1, 8]. The training process of MarketFCNet is presented   \n175 in Figure 1. ", "page_idx": 4}, {"type": "text", "text": "176 To finish the ALMM algorithm, we need to obtain unbiased estimators of following two expressions. ", "page_idx": 4}, {"type": "text", "text": "177 ", "page_idx": 4}, {"type": "text", "text": "178 ", "page_idx": 4}, {"type": "text", "text": "\u2022 An unbiased estimator of $\\mathcal{L}_{\\rho}(x_{\\theta};\\lambda)$ .   \n\u2022 An unbiased estimator of $\\Delta\\lambda_{j}$ , where $\\Delta\\lambda_{j}$ is given by $\\Delta\\lambda_{j}=\\rho\\,(\\mathbb{E}_{b}[x_{\\theta}(b,g_{j})]-1)$ . ", "page_idx": 4}, {"type": "text", "text": "179 Unbiased estimator of $\\Delta\\lambda_{j}$ We aim to obtain an unbiased estimator of $\\mathbb{E}_{b}[x_{\\theta}(b,g_{j})]$ . By apply  \n180 ing Monte Carlo method, we can choose batch size $M$ and sample $b_{1},b_{2},...,b_{M}\\,\\sim\\,U(B)$ , then   \n181 $\\begin{array}{r}{\\frac{1}{M}\\sum_{i=1}^{M}x_{\\theta}(b_{i},g_{j})}\\end{array}$ forms an unbiased estimator.   \n182 Unbiased estimator of $\\mathcal{L}_{p}(x_{\\theta};\\lambda)$ For $\\mathrm{OBJ}(x_{\\theta})$ and the second term, the technique to achieve an   \n183 unbiased estimator is similar. $u(b;x_{\\theta}(b,\\pmb{g}))$ in ${\\mathrm{OBJ}}(x_{\\theta})$ can be calculated directly by summing over   \n184 all goods. For the last term, notice that ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left(\\mathbb{E}_{b}\\left[x_{\\theta}(b,g_{j})\\right]-1\\right)^{2}=\\left(\\mathbb{E}_{b}\\left[x_{\\theta}(b,g_{j})\\right]-1\\right)\\cdot\\left(\\mathbb{E}_{b^{\\prime}}\\left[x_{\\theta}(b^{\\prime},g_{j})\\right]-1\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "185 Therefore, we can sample $b_{1},...,b_{M},b_{1}^{\\prime},...,b_{M}^{\\prime}\\sim U(B)$ and compute ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{\\rho}{2}\\cdot\\frac{1}{M}\\sum_{i=1}^{M}\\sum_{j=1}^{m}\\big(x_{\\theta}(b_{i},g_{j})-1\\big)\\cdot\\big(x_{\\theta}(b_{i}^{\\prime},g_{j})-1\\big)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "186 which provides an unbiased estimator for the last term, capturing the squared deviation of output   \n187 allocations from the constraint. ", "page_idx": 4}, {"type": "text", "text": "188 5 Performance Measures of Market Equilibrium ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "189 In this section, we propose Nash Gap to measure the performance of an approximated market   \n190 equilibrium and show that Nash Gap preserves the economic interpretation for market equilibrium. To   \n191 introduce Nash Gap, we first introduce two types of welfare, Log Nash Welfare and Log Fixed-price   \n192 Welfare in Definition 5.1 and Definition 5.2, respectively. ", "page_idx": 4}, {"type": "text", "text": "193 Definition 5.1 (Log Nash Welfare). The Log Nash Welfare (abbreviated as LNW) is defined as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{LNW}(\\pmb{x})=\\frac{1}{B_{\\mathrm{total}}}\\sum_{i\\in[n]}B_{i}\\log u_{i}(\\pmb{x}_{i}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "194 where $\\begin{array}{r}{B_{\\mathrm{total}}=\\sum_{i\\in[n]}B_{i}}\\end{array}$ is the total budgets for buyers. ", "page_idx": 5}, {"type": "text", "text": "195 Notice that $\\operatorname{LNW}(x)$ is identical to the objective function in Equation (EG), differing only in the   \n196 constant term coefficient.   \n197 Definition 5.2 (Fixed-price and Log Fixed-price Welfare). We define the fixed-price utility for buyer   \n198 i as, ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{u}(b_{i};\\pmb{p})=\\operatorname*{max}_{\\pmb{x}_{i}}\\{u(b_{i};\\pmb{x}_{i})~|~\\pmb{x}_{i}\\in\\mathbb{R}_{+}^{m},\\langle\\pmb{p},\\pmb{x}_{i}\\rangle\\leq B(b_{i})\\}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "199 which represents the optimal utility that buyer $i$ can obtain at the price level $\\pmb{p}$ , regardless of the   \n200 market clearance constraints. The Log Fixed-price Welfare (abbreviated as LFW) is defined as the   \n201 logarithm of Fixed-price Welfare, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{LFW}(\\pmb{p})=\\frac{1}{B_{\\mathrm{total}}}\\sum_{i\\in[n]}B_{i}\\log\\tilde{u}_{i}(\\pmb{p})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "202 Based on these definitions, we present the definition of Nash Gap. ", "page_idx": 5}, {"type": "text", "text": "203 Definition 5.3 (Nash Gap). We define Nash Gap (abbreviated as NG) as the difference of Log Nash   \n204 Welfare and Log Fixed-price Welfare, i.e. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{{NG}}(x,p)=\\mathrm{{LFW}}(p)-\\mathrm{{LNW}}(x)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "205 5.1 Properties of Nash Gap ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "206 To show why NG is useful in the measure of market equilibrium, we first observe that, ", "page_idx": 5}, {"type": "text", "text": "207 Proposition 5.4 (Price constraints). If $(x,p)$ constitute a market equilibrium, the following identity   \n208 always hold, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sum_{j\\in[m]}p_{j}Y_{j}=\\sum_{i\\in[n]}B_{i}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "209 Below, we state the most important theorem in this paper. ", "page_idx": 5}, {"type": "text", "text": "210 Theorem 5.5. Let $\\left(x,p\\right)$ be a pair of allocation and price. Assuming the allocation satisfies market   \n211 clearance and the price meets price constraint, then we have $\\mathrm{NG}({\\pmb x},{\\pmb p})\\geq0$ . ", "page_idx": 5}, {"type": "text", "text": "212 Moreover, $\\mathrm{{NG}}({\\pmb x},{\\pmb p})=0$ if and only if $\\left(x,p\\right)$ is a market equilibrium. ", "page_idx": 5}, {"type": "text", "text": "213 Theorem 5.5 show that Nash Gap is an ideal measure of the solution concept of market equilibrium,   \n214 since it holds following properties, ", "page_idx": 5}, {"type": "text", "text": "\u2022 $\\mathrm{NG}({\\boldsymbol{x}},{\\boldsymbol{p}})$ is continuous on the inputs $\\left(x,p\\right)$ .   \n\u2022 $\\mathrm{NG}({\\boldsymbol{x}},{\\boldsymbol{p}})\\geq0$ always hold. (under conditions in Theorem 5.5)   \n\u2022 $\\mathrm{NG}({\\boldsymbol{x}},{\\boldsymbol{p}})=0$ if and only if $(x,p)$ meets the solution concept.   \n\u2022 The computation of NG does not require the knowledge of an equilibrium point $(\\pmb{x}^{\\ast},\\pmb{p}^{\\ast})$ ", "page_idx": 5}, {"type": "text", "text": "219 Since some may argue that $\\mathrm{NG}(\\boldsymbol{x},\\boldsymbol{p})$ is not intuitive to understand, we consider some more intuitive   \n220 measures, the Euclidean distance to the market equilibrium, i.e., $||\\mathbf x-\\mathbf x^{*}||$ and $||\\boldsymbol{p}-\\boldsymbol{p}^{*}||$ , as   \n221 well as the difference on Weighted Social Welfare, $|\\mathrm{WSW}({\\pmb x})-\\mathrm{WSW}({\\pmb x}^{*})|$ , where $\\mathrm{WSW}(\\pmb{x}):=$   \n222 $\\begin{array}{r}{\\sum_{i\\in[n]}\\frac{B_{i}}{B_{\\mathrm{total}}}u_{i}(\\pmb{x}_{i})}\\end{array}$ BtBoital ui(xi), and show the connection between NG and these intuitive measures.   \n223 Proposition 5.6. Under some technical assumptions (which is presented in Appendix B.4), if   \n224 $\\mathrm{{NG}}({\\pmb x},{\\pmb p})=\\varepsilon$ , we have: ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\bullet\\ ||p-p^{*}||=O({\\sqrt{\\varepsilon}}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "226 \u2022 $||\\pmb{x}_{i}-\\pmb{x}_{i}^{*}||=O(\\sqrt\\varepsilon)$ for all $i$ .   \n227 $\\mathbf{\\nabla}\\bullet\\mathbf{\\partial}\\vert\\mathrm{WSW}(\\pmb{x})-\\mathrm{WSW}(\\pmb{x}^{\\ast})\\vert=O(\\varepsilon).$ ", "page_idx": 6}, {"type": "text", "text": "228 Finally, we give a saddle-point explaination for Nash Gap. ", "page_idx": 6}, {"type": "text", "text": "229 Corollary 5.7. Within market clearance and price constraint, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{p}\\mathrm{LFW}(p)=\\operatorname*{max}_{x}\\mathrm{LNW}(x)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "230 Corollary 5.7 provides an economic interpretation for GAP. Market equilibrium can be seen as the   \n231 saddle point over social welfare, and the social welfare for $\\textbf{\\em x}$ can be actually implemented while   \n232 the social welfare for $\\pmb{p}$ is virtual and desired by buyers. Nash Gap measures the gap between the   \n233 \u201cdesired welfare\u201d and the \u201cimplemented welfare\u201d for buyers. ", "page_idx": 6}, {"type": "text", "text": "234 5.2 Measures in General Cases ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "235 Since NG only works for $(x,p)$ that satisfies market clearance and price constraints, we generalize   \n236 the measure of NG to a more general case, which need to give a measure for all positive $\\bar{(\\pmb{x},\\pmb{p})}$ .   \n237 We first notice that any equilibrium must satisfy the conditions of market clearance and price   \n238 constraint, we first make a projection on arbitrary positive $(x,p)$ to the space where these constraints   \n239 hold. Specifically, if we let ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\alpha_{j}=\\!\\!\\frac{V_{j}}{\\sum_{i}x_{i j}},\\quad\\tilde{x}_{i j}=x_{i j}\\cdot\\alpha_{j}\\qquad\\qquad\\qquad\\beta=\\frac{\\sum_{i}B_{i}}{\\sum_{j}V_{j}p_{j}},\\quad\\tilde{p}_{j}=\\beta\\cdot p_{j}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "240 then $(\\tilde{x},\\tilde{p})$ satisfies these constraints and we consider $\\mathrm{NG}(\\tilde{x},\\tilde{p})$ as the equilibrium measure. ", "page_idx": 6}, {"type": "text", "text": "241 Besides, we also need to measure how far is the point $\\left(x,p\\right)$ to the space within the conditions of   \n242 market clearance and price constraint. we propose following two measurement, called Violation of   \n243 Allocation (abbreviated as VoA) and Violation of Price (abbreviated as VoP), respectively. ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{VoA}(\\pmb{x}):=\\frac{1}{m}\\sum_{j}\\vert\\log\\alpha_{j}\\vert,\\qquad\\operatorname{VoP}(\\pmb{p}):=\\vert\\log\\beta\\vert\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "244 From the expressions of VoA and VoP, we know that these two constraints hold if and only if   \n245 $\\mathrm{VoA}({\\pmb x})=0$ and $\\mathrm{VoP}(p)=0$ .   \n246 We argue that this projection is of economic meaning. If $(x,p)$ constitute a market equilibrium   \n247 and we scale budget with a factor of $\\beta$ , then $(\\pmb{x},\\beta\\pmb{p})$ constitute a market equilibrium in the new   \n248 market. Similarly, if we scale the value for each buyer with factor $1/\\alpha$ (here $_{\\alpha}$ can be a vector in   \n249 $\\mathbb{R}_{+}^{m})$ ) and capacity with factor $\\alpha$ , then, $(\\alpha x,\\frac{1}{\\alpha}p)$ constitute a market equilibrium in the new market.   \n250 These instances are evidence that market equilibrium holds a linear structure over market parameters.   \n251 Therefore, a linear projection can eliminate the effect from linear scaling, while preserving the effect   \n252 from orthogonal errors.   \n253 Notice that $\\textbf{\\em x}=\\Tilde{\\textbf{x}}$ and $\\pmb{p}=\\tilde{\\pmb{p}}$ if and only if $\\mathrm{VoA}({\\pmb x})=0$ and $\\mathrm{VoP}(p)=0$ , respectively. From   \n254 Theorem 5.5 We can easy derive following statements:   \n255 Proposition 5.8. For arbitrary $\\textbf{\\em x}\\in\\texttt{R}_{+}^{n\\times m},\\pmb{p}\\in\\texttt{R}_{+}^{m}$ , we have $\\mathrm{VoA}({\\pmb x})~\\ge~0,\\mathrm{VoP}({\\pmb p})~~\\ge$   \n256 $0,\\bar{\\mathrm{NG}}(\\tilde{\\pmb{x}},\\tilde{\\pmb{p}})\\geq0$ always hold. Moreover, $(x,p)$ is a market equilibrium if and only $i f\\operatorname{VoA}({\\pmb x})=$   \n257 $\\mathrm{VoP}(p)=\\mathrm{NG}(\\tilde{\\pmb{x}},\\tilde{\\pmb{p}})=0$ .   \n258 Proposition 5.8 is a certificate that $\\mathrm{VoA}({\\pmb x}),\\mathrm{VoP}({\\pmb p}),\\mathrm{NG}({\\pmb x},{\\tilde{\\pmb p}})$ together form a good measure for   \n259 market equilibrium. Therefore, in our experiments we compute these measures of solutions and   \n260 prefer a lower measure without further clarification. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "261 6 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "262 In this section, we present empirical experiments that evaluate the effectiveness of MarketFCNet.   \n263 Though briefly mentioned in this section, we leave the details of baselines, implementations, hyper  \n264 parameters and experimental environments to Appendix C. ", "page_idx": 6}, {"type": "table", "img_path": "JWF1dN4TOd/tmp/ab973cb610dbc6c6ea78d08c637c2d5085886bb141e1b33820dd61f6b4d94d7c.jpg", "table_caption": ["Table 1: Comparison of MarketFCNet with baselines: $n=1,048$ , 576 buyers and $m=10$ goods. The GPU time for MarketFCNet represents the training time and testing time, respectively. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "265 6.1 Experimental Settings ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "266 In our experiments, all utilities are chosen as CES utilities, which captures a wide utility class   \n267 including linear utilities, Cobb-Douglas utilities and Leontief utilities and has been widely studied in   \n268 literature [59, 4]. CES utilities have the form, ", "page_idx": 7}, {"type": "equation", "text": "$$\nu_{i}(x_{i})=\\left(\\sum_{j\\in[m]}v_{i j}^{\\alpha}x_{i j}^{\\alpha}\\right)^{1/\\alpha}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "269 with $\\alpha\\leq1$ . The fixed-price utilities for CES utility is derived in Appendix A. ", "page_idx": 7}, {"type": "text", "text": "270 In order to evaluate the performance of MarketFCNet, we compare them mainly with a baseline that   \n271 directly maximizes the objective in EG convex program with gradient ascent algorithm (abbreviated   \n272 as $E G_{\\mathrm{,}}$ ), which is widely used in the field of market equilibrium computation. Besides, we also   \n273 consider a momentum version of $E G$ algorithm with momentum $\\beta=0.9$ (abbreviated as $E G{-m}$ ). We   \n274 move the details of all baselines, experimental environments and implementations of algorithms to   \n275 Appendix C.1 and Appendix C.2.   \n276 We also consider a na\u00efve allocation and pricing rule (abbreviated as Na\u00efve), which can be regarded as   \n277 the benchmark of the experiments: ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\nx_{i j}=\\;1,\\quad p_{j}=\\frac{\\sum_{i\\in[n]}B_{i}}{m V_{j}},\\quad\\mathrm{for}\\;\\mathrm{all}\\;i,j\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "278 In the following experiments, MarketFCNet is abbreviated as $F C$ . Notice that Na\u00efve always gives an   \n279 allocation that satisfies market clearance and price constraints, while $E G,E G{-}m$ and $F C$ do not. ", "page_idx": 7}, {"type": "text", "text": "280 6.2 Experiment Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "281 Comparing with Baselines We choose number of buyers $n=1,048$ , $576=2^{20}$ , number of items   \n282 $m=10$ , CES utilities parameter $\\alpha=0.5$ and representation with standard normal distribution as   \n283 the basic experimental environment of MarketFCNet; We consider $\\mathrm{NG}(\\tilde{\\mathbf{\\boldsymbol{x}}},\\tilde{\\mathbf{\\boldsymbol{p}}}),\\mathrm{VoA}(\\mathbf{\\boldsymbol{x}}),\\mathrm{VoP}(\\mathbf{\\boldsymbol{p}})$ and   \n284 the running time of algorithms as the measures. Without special specification, these parameters are   \n285 default settings among other experiments. Results are presented in Table 1. From these results we   \n286 can see that the approximations of MarketFCNet are competitive with $E G$ and $E G{-m}$ and far better   \n287 than Na\u00efve, which means that the solution of MarketFCNet are very close to market equilibrium.   \n288 MarketFCNet also achieve a much lower running time compared with $E G$ and $E G{-m}$ , which indicates   \n289 that these methods are more suitable to large-scale market equilibrium computation. In following   \n290 experiments, VoA and VoP measures are omitted and we only report NG and running time.   \n291 Experiments in different parameters settings In this experiments, the market scale is chosen as   \n292 $n=4$ , 194, 304 and $m=10$ . We consider experiments on different distribution of representation,   \n293 including normal distribution, uniform distribution and exponential distribution. See (a) and (b)   \n294 in Figure 2 for results. We also consider different $\\alpha$ in our experimental settings. Specifically,   \n295 our settings consist of: 1) $\\alpha\\,=\\,1$ , the utility functions are linear; 2) $\\alpha\\,=\\,0.5$ , where goods are   \n296 substitutes; 3) $\\alpha=0$ , where goods are neither substitutes or complements; 4) $\\alpha=-1$ , where goods   \n297 are complements. More detailed results are shown in (c) and (d) Figure 2. The performance of   \n298 MarketFCNet is robust in both settings. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Figure 2: The Nash Gap and GPU running time for different algorithms: MarketFCNet, EG and EG-m. Different colors represent for different algorithm. Market size is chosen as $n=4$ , 194, 304 buyers and $m=10$ goods. ", "page_idx": 8}, {"type": "image", "img_path": "JWF1dN4TOd/tmp/c353b4c04cb9f9e5f65e0dda630ceb0a4cd707fbcfd10cac5e8023f530ba34a7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 3: The Nash Gap and GPU running time for different algorithms: MarketFCNet, EG and EG-m. Different colors represent for different algorithm. Market size is chosen as $n=2^{18},2^{20},2^{22}$ buyers and $m=5$ , 10, 20 goods. ", "page_idx": 8}, {"type": "image", "img_path": "JWF1dN4TOd/tmp/018268bb3f1389ecb99c25bcc5cef738b4a341e724382a450303070c0ff2cac6.jpg", "img_caption": ["(a) Nash Gap on different market size, $\\stackrel{\\cdot}{n}=\\;2^{18},2^{\\mathbf{20}},2^{22}$ buyers and $m=$ 5, 10, 20 goods. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "JWF1dN4TOd/tmp/19c337096c3f1fdb789065f89e199588c5338d1e55a50f3501c507acdb8e29dd.jpg", "img_caption": ["(b) GPU running time on different market size, $n=2^{\\sqrt{18}},2^{20},2^{22}$ buyers and $m=5,10,20$ goods. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "299 Different market scale for MarketFCNet In this section we ask that how market size (here $n$   \n300 and $m$ ) will have impact on the efficiency of MarketFCNet. We set $m=5,10,20$ and $n=2^{18}=$   \n301 262, 114, $2^{20}=1$ , 048, 576, $2^{22}=4$ , 194, 304 as the experimental settings. For each combination   \n302 of $n$ and $m$ , we train MarketFCNet and compared with EG and EG-m, see results in Figure 3. As   \n303 the market size varies, MarketFCNet has almost the same Nash Gap and running time, which shows   \n304 the robustness of MarketFCNet method over different market sizes. However, as the market size   \n305 increases, both EG and EG-m have larger Nash Gaps and longer running times, demonstrating that   \n306 MarketFCNet is more suitable to large-scale contextual market equilibrium computation. ", "page_idx": 8}, {"type": "text", "text": "307 7 Conclusions and Future Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "308 This paper initiates the problem of large-scale contextual market equilibrium computation from a deep   \n309 learning perspective. We believe that our approach will pioneer a promising direction for large-scale   \n310 contextual market equilibrium computation.   \n311 For future works, it would be promising to extend these methods to the case when only the number of   \n312 goods is large, or both the numbers of goods and buyers are large, which stays a blank throughout our   \n313 works. Since many existing works proposed dynamics for online market equilibrium computation,   \n314 it\u2019s also promising to extend our approaches to tackle the online market setting with large buyers.   \n315 Besides, both existing works and ours consider sure budgets and values for buyers, and it would be   \n316 interesting to extend the fisher market and equilibrium concept when the budgets or values of buyers   \n317 are stochastic or uncertain. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "318 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "319 [1] Shun-ichi Amari. Backpropagation and stochastic gradient descent method. Neurocomputing, 5   \n320 (4-5):185\u2013196, 1993.   \n321 [2] Kenneth J Arrow. An extension of the basic theorems of classical welfare economics. In   \n322 Proceedings of the second Berkeley symposium on mathematical statistics and probability,   \n323 volume 2, pages 507\u2013533. University of California Press, 1951.   \n324 [3] Kenneth J Arrow and Gerard Debreu. Existence of an equilibrium for a competitive economy.   \n325 Econometrica: Journal of the Econometric Society, pages 265\u2013290, 1954.   \n326 [4] Kenneth J Arrow, Hollis B Chenery, Bagicha S Minhas, and Robert M Solow. Capital-labor   \n327 substitution and economic efficiency. The review of Economics and Statistics, pages 225\u2013250,   \n328 1961.   \n329 [5] Santiago Balseiro, Christian Kroer, and Rachitesh Kumar. Contextual standard auctions with   \n330 budgets: Revenue equivalence and efficiency guarantees. Management Science, 69(11):6837\u2013   \n331 6854, 2023.   \n332 [6] Siddhartha Banerjee, Vasilis Gkatzelis, Artur Gorokh, and Billy Jin. Online nash social welfare   \n333 maximization with predictions. In Proceedings of the 2022 Annual ACM-SIAM Symposium on   \n334 Discrete Algorithms (SODA), pages 1\u201319. SIAM, 2022.   \n335 [7] Yoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. Curriculum learning.   \n336 In Proceedings of the 26th annual international conference on machine learning, pages 41\u201348,   \n337 2009.   \n338 [8] L\u00e9on Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings   \n339 of COMPSTAT\u20192010: 19th International Conference on Computational StatisticsParis France,   \n340 August 22-27, 2010 Keynote, Invited and Contributed Papers, pages 177\u2013186. Springer, 2010.   \n341 [9] Simina Br\u00e2nzei, Yiling Chen, Xiaotie Deng, Aris Filos-Ratsikas, S\u00f8ren Frederiksen, and Jie   \n342 Zhang. The fisher market game: Equilibrium and welfare. In Proceedings of the AAAI   \n343 Conference on Artificial Intelligence, volume 28, 2014.   \n344 [10] Jonathan Brogaard, Terrence Hendershott, and Ryan Riordan. High-frequency trading and price   \n345 discovery. The Review of Financial Studies, 27(8):2267\u20132306, 2014.   \n346 [11] Eric Budish. The combinatorial assignment problem: Approximate competitive equilibrium   \n347 from equal incomes. Journal of Political Economy, 119(6):1061\u20131103, 2011.   \n348 [12] Yun Kuen Cheung, Richard Cole, and Yixin Tao. Dynamics of distributed updating in fisher   \n349 markets. In Proceedings of the 2018 ACM Conference on Economics and Computation, pages   \n350 351\u2013368, 2018.   \n351 [13] Richard Cole and Lisa Fleischer. Fast-converging tatonnement algorithms for one-time and   \n352 ongoing market problems. In Proceedings of the Fortieth Annual ACM Symposium on Theory   \n353 of Computing, pages 315\u2013324, 2008.   \n354 [14] Richard Cole, Nikhil Devanur, Vasilis Gkatzelis, Kamal Jain, Tung Mai, Vijay V Vazirani,   \n355 and Sadra Yazdanbod. Convex program duality, fisher markets, and nash social welfare. In   \n356 Proceedings of the 2017 ACM Conference on Economics and Computation, pages 459\u2013460,   \n357 2017.   \n358 [15] Vincent Conitzer, Christian Kroer, Debmalya Panigrahi, Okke Schrijvers, Nicolas E Stier-Moses,   \n359 Eric Sodomka, and Christopher A Wilkens. Pacing equilibrium in first price auction markets.   \n360 Management Science, 68(12):8515\u20138535, 2022.   \n361 [16] Vincent Conitzer, Christian Kroer, Eric Sodomka, and Nicolas E Stier-Moses. Multiplicative   \n362 pacing equilibria in auction markets. Operations Research, 70(2):963\u2013989, 2022.   \n363 [17] Michael Curry, Alexander R Trott, Soham Phade, Yu Bai, and Stephan Zheng. Finding general   \n364 equilibria in many-agent economic simulations using deep reinforcement learning. 2021.   \n365 [18] Michael Curry, Tuomas Sandholm, and John Dickerson. Differentiable economics for random  \n366 ized affine maximizer auctions. arXiv preprint arXiv:2202.02872, 2022.   \n367 [19] Xiaotie Deng, Christos Papadimitriou, and Shmuel Safra. On the complexity of equilibria. In   \n368 Proceedings of the Thiry-fourth Annual ACM Symposium on Theory of Computing, pages 67\u201371,   \n369 2002.   \n370 [20] Xiaotie Deng, Christos Papadimitriou, and Shmuel Safra. On the complexity of price equilibria.   \n371 Journal of Computer and System Sciences, 67(2):311\u2013324, 2003.   \n372 [21] Zhijian Duan, Jingwu Tang, Yutong Yin, Zhe Feng, Xiang Yan, Manzil Zaheer, and Xiaotie Deng.   \n373 A context-integrated transformer-based neural network for auction design. In International   \n374 Conference on Machine Learning, pages 5609\u20135626. PMLR, 2022.   \n375 [22] Zhijian Duan, Wenhan Huang, Dinghuai Zhang, Yali Du, Jun Wang, Yaodong Yang, and Xiaotie   \n376 Deng. Is nash equilibrium approximator learnable? In Proceedings of the 2023 International   \n377 Conference on Autonomous Agents and Multiagent Systems, pages 233\u2013241, 2023.   \n378 [23] Zhijian Duan, Yunxuan Ma, and Xiaotie Deng. Are equivariant equilibrium approximators   \n379 beneficial? In Proceedings of the 40th International Conference on Machine Learning, ICML\u201923.   \n380 JMLR.org, 2023.   \n381 [24] Zhijian Duan, Haoran Sun, Yurong Chen, and Xiaotie Deng. A scalable neural network for   \n382 DSIC affine maximizer auction design. 2023. URL https://openreview.net/forum?id=   \n383 cNb5hkTfGC.   \n384 [25] Paul D\u00fctting, Zhe Feng, Harikrishna Narasimhan, David Parkes, and Sai Srivatsa Ravindranath.   \n385 Optimal auctions through deep learning. In International Conference on Machine Learning,   \n386 pages 1706\u20131715. PMLR, 2019.   \n387 [26] Paul D\u00fctting, Zhe Feng, Harikrishna Narasimhan, David C Parkes, and Sai Srivatsa Ravin  \n388 dranath. Optimal auctions through deep learning: Advances in differentiable economics. Journal   \n389 of the ACM (JACM), 2023.   \n390 [27] Edmund Eisenberg. Aggregation of utility functions. Management Science, 7(4):337\u2013350,   \n391 1961.   \n392 [28] Edmund Eisenberg and David Gale. Consensus of subjective probabilities: The pari-mutuel   \n393 method. The Annals of Mathematical Statistics, 30(1):165\u2013168, 1959.   \n394 [29] Zhe Feng, Harikrishna Narasimhan, and David C Parkes. Deep learning for revenue-optimal   \n395 auctions with budgets. In Proceedings of the 17th International Conference on Autonomous   \n396 Agents and Multiagent Systems, pages 354\u2013362, 2018.   \n397 [30] Yuan Gao and Christian Kroer. First-order methods for large-scale market equilibrium computa  \n398 tion. Advances in Neural Information Processing Systems, 33:21738\u201321750, 2020.   \n399 [31] Yuan Gao and Christian Kroer. Infinite-dimensional fisher markets and tractable fair division.   \n400 Operations Research, 71(2):688\u2013707, 2023.   \n401 [32] Yuan Gao, Alex Peysakhovich, and Christian Kroer. Online market equilibrium with application   \n402 to fair division. Advances in Neural Information Processing Systems, 34:27305\u201327318, 2021.   \n403 [33] Jugal Garg, Ruta Mehta, Vijay V Vazirani, and Sadra Yazdanbod. Settling the complexity of   \n404 leontief and plc exchange markets under exact and approximate equilibria. In Proceedings of   \n405 the 49th Annual ACM SIGACT Symposium on Theory of Computing, pages 890\u2013901, 2017.   \n406 [34] Jugal Garg, Yixin Tao, and L\u00e1szl\u00f3 A V\u00e9gh. Approximating equilibrium under constrained   \n407 piecewise linear concave utilities with applications to matching markets. In Proceedings of   \n408 the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 2269\u20132284.   \n409 SIAM, 2022.   \n410 [35] Jonathan Goldman and Ariel D Procaccia. Spliddit: Unleashing fair division algorithms. ACM   \n411 SIGecom Exchanges, 13(2):41\u201346, 2015.   \n412 [36] Noah Golowich, Harikrishna Narasimhan, and David C Parkes. Deep learning for multi-facility   \n413 location mechanism design. In International Joint Conferences on Artificial Intelligence, pages   \n414 261\u2013267, 2018.   \n415 [37] Xue-Zhong He and Shen Lin. Reinforcement learning equilibrium in limit order markets.   \n416 Journal of Economic Dynamics and Control, 144:104497, 2022.   \n417 [38] Howard Heaton, Daniel McKenzie, Qiuwei Li, Samy Wu Fung, Stanley Osher, and Wotao Yin.   \n418 Learn to predict equilibria via fixed point networks. arXiv preprint arXiv:2106.00906, 2021.   \n419 [39] Edward Hill, Marco Bardoscia, and Arthur Turrell. Solving heterogeneous general equilibrium   \n420 economic models with deep reinforcement learning. arXiv preprint arXiv:2103.16977, 2021.   \n421 [40] Zhiyi Huang, Minming Li, Xinkai Shu, and Tianze Wei. Online nash welfare maximization   \n422 without predictions. In International Conference on Web and Internet Economics, pages   \n423 402\u2013419. Springer, 2023.   \n424 [41] Devansh Jalota and Yinyu Ye. Stochastic online fisher markets: Static pricing limits and adaptive   \n425 enhancements. arXiv preprinted arXiv:2205.00825, 2023.   \n426 [42] Devansh Jalota, Marco Pavone, Qi Qi, and Yinyu Ye. Fisher markets with linear constraints:   \n427 Equilibrium properties and efficient distributed algorithms. Games and Economic Behavior,   \n428 141:223\u2013260, 2023.   \n429 [43] Nils Kohring, Fabian Raoul Pieroth, and Martin Bichler. Enabling first-order gradient-based   \n430 learning for equilibrium computation in markets. In International Conference on Machine   \n431 Learning, pages 17327\u201317342. PMLR, 2023.   \n432 [44] Christian Kroer. Ai, games, and markets. 2023. https://www.columbia.edu/\\~ck2945/   \n433 files/main_ai_games_markets.pdf.   \n434 [45] Christian Kroer and Alexander Peysakhovich. Scalable fair division for\u2019at most one\u2019preferences.   \n435 arXiv preprint arXiv:1909.10925, 2019.   \n436 [46] Christian Kroer, Alexander Peysakhovich, Eric Sodomka, and Nicolas E Stier-Moses. Comput  \n437 ing large market equilibria using abstractions. In Proceedings of the 2019 ACM Conference on   \n438 Economics and Computation, pages 745\u2013746, 2019.   \n439 [47] Ningyuan Li, Yunxuan Ma, Yang Zhao, Zhijian Duan, Yurong Chen, Zhilin Zhang, Jian Xu,   \n440 Bo Zheng, and Xiaotie Deng. Learning-based ad auction design with externalities: The frame  \n441 work and a matching-based approach. In Proceedings of the 29th ACM SIGKDD Conference on   \n442 Knowledge Discovery and Data Mining, pages 1291\u20131302, 2023.   \n443 [48] Luofeng Liao, Yuan Gao, and Christian Kroer. Nonstationary dual averaging and online fair   \n444 allocation. Advances in Neural Information Processing Systems, 35:37159\u201337172, 2022.   \n445 [49] Yuxuan Lu, Qian Qi, and Xi Chen. A framework of transaction packaging in high-throughput   \n446 blockchains. arXiv preprint arXiv:2301.10944, 2023.   \n447 [50] Luke Marris, Ian Gemp, Thomas Anthony, Andrea Tacchetti, Siqi Liu, and Karl Tuyls. Tur  \n448 bocharging solution concepts: Solving nes, ces and cces with neural equilibrium solvers.   \n449 Advances in Neural Information Processing Systems, 35:5586\u20135600, 2022.   \n450 [51] Andreu Mas-Colell, Michael Dennis Whinston, Jerry R Green, et al. Microeconomic theory,   \n451 volume 1. Oxford University Press New York, 1995.   \n452 [52] Tianlong Nan, Yuan Gao, and Christian Kroer. Fast and interpretable dynamics for fisher   \n453 markets via block-coordinate updates. arXiv preprint arXiv:2303.00506, 2023.   \n454 [53] Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V Vazirani. Algorithmic game theory,   \n455 2007. Book available for free online, 2007.   \n456 [54] Christos Papadimitriou. Algorithms, games, and the internet. In Proceedings of the Thirty-third   \n457 Annual ACM Symposium on Theory of Computing, pages 749\u2013753, 2001.   \n458 [55] Jad Rahme, Samy Jelassi, Joan Bruna, and S Matthew Weinberg. A permutation-equivariant   \n459 neural network architecture for auction design. In Proceedings of the AAAI Conference on   \n460 Artificial Intelligence, volume 35, pages 5664\u20135672, 2021.   \n461 [56] Weiran Shen, S\u00e9bastien Lahaie, and Renato Paes Leme. Learning to clear the market. In   \n462 International Conference on Machine Learning, pages 5710\u20135718. PMLR, 2019.   \n463 [57] Vadim I Shmyrev. An algorithm for finding equilibrium in the linear exchange model with fixed   \n464 budgets. Journal of Applied and Industrial Mathematics, 3:505\u2013518, 2009.   \n465 [58] The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 1972. No  \n466 belprize.org. Nobel Prize Outreach AB 2024, Sun. 28 Jan 2024. https://www.nobelprize.   \n467 org/prizes/economic-sciences/1972/summary/.   \n468 [59] Hal R Varian and Hal R Varian. Microeconomic analysis, volume 3. Norton New York, 1992.   \n469 [60] Vijay V Vazirani and Mihalis Yannakakis. Market equilibrium under separable, piecewise-linear,   \n470 concave utilities. Journal of the ACM (JACM), 58(3):1\u201325, 2011.   \n471 [61] Leon Walras. Elements of pure economics. Routledge, 2013.   \n472 [62] Tonghan Wang, Paul D\u00fctting, Dmitry Ivanov, Inbal Talgam-Cohen, and David C Parkes.   \n473 Deep contract design via discontinuous piecewise affine neural networks. arXiv preprint   \n474 arXiv:2307.02318, 2023.   \n475 [63] Fang Wu and Li Zhang. Proportional response dynamics leads to market equilibrium. In   \n476 Proceedings of the Thirty-ninth Annual ACM Symposium on Theory of Computing, pages   \n477 354\u2013363, 2007.   \n478 [64] Ruitu Xu, Yifei Min, Tianhao Wang, Michael I Jordan, Zhaoran Wang, and Zhuoran Yang.   \n479 Finding regularized competitive equilibria of heterogeneous agent macroeconomic models via   \n480 reinforcement learning. In International Conference on Artificial Intelligence and Statistics,   \n481 pages 375\u2013407. PMLR, 2023.   \n482 [65] Zongjun Yang, Luofeng Liao, and Christian Kroer. Greedy-based online fair allocation with   \n483 adversarial input: Enabling best-of-many-worlds guarantees. arXiv preprint arXiv:2308.09277,   \n484 2023.   \n485 [66] Li Zhang. Proportional response dynamics in the fisher market. Theoretical Computer Science,   \n486 412(24):2691\u20132698, 2011. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "487 Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "488 A Derivation of Fixed-price Utility for CES Utility Functions ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "489 B Omitted Proofs ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "490 C Additional Experiments Details ", "page_idx": 13}, {"type": "text", "text": "491 A Derivation of Fixed-price Utility for CES Utility Functions ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "492 In this section we show the explicit expressions of Fixed-price Utility for CES utility functions.   \n493 We first consider the case $\\alpha\\neq0,1,-\\infty$ . The optimization problem for consumer $i$ is: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{x_{i j},j\\in[m]}}&{u_{i}(\\pmb{x}_{i})=\\left[\\displaystyle\\sum_{j\\in[m]}v_{i j}^{\\alpha}x_{i j}^{\\alpha}\\right]^{1}}\\\\ {s.t.~}&{\\displaystyle\\sum_{j\\in[m]}x_{i j}p_{j}=B_{i}}\\\\ &{x_{i j}\\geq0}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "(Budget Constraint) ", "page_idx": 13}, {"type": "text", "text": "494 Not hard to verify that in an optimal solution with Equation (Budget Constraint), Equation (16)   \n495 always holds, therefore we omit this constraint in our derivation. ", "page_idx": 13}, {"type": "text", "text": "496 We write the Lagrangian $L(\\pmb{x}_{i},\\lambda)$ ", "page_idx": 13}, {"type": "equation", "text": "$$\nL({\\pmb x}_{i},\\lambda)=u_{i}({\\pmb x}_{i})+\\lambda({\\pmb B}_{i}-\\sum_{j\\in[m]}x_{i j}p_{j})\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "497 By $\\begin{array}{r}{\\frac{\\partial L}{\\partial x_{i j}}=0}\\end{array}$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\partial u_{i}}{\\partial x_{i j}^{*}}({\\pmb x}_{i})=\\lambda p_{j}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "498 We derive that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\partial u_{i}}{\\partial x_{i j}}(\\pmb{x}_{i})=\\frac{1}{\\alpha}\\left[\\sum_{j\\in[m]}v_{i j}^{\\alpha}x_{i j}^{\\alpha}\\right]^{1/\\alpha-1}\\cdot\\alpha v_{i j}^{\\alpha}x_{i j}^{\\alpha-1}}\\\\ &{\\quad v_{i j}^{\\alpha}x_{i j}^{\\alpha-1}=c p_{j}\\qquad\\cdots\\cdot\\mathbf{let}\\,c=\\lambda\\cdot\\left[\\sum_{j\\in[m]}v_{i j}^{\\alpha}x_{i j}^{\\alpha}\\right]^{1/\\alpha-1}}\\\\ &{\\quad\\quad x_{i j}^{*}=\\frac{v_{i}^{\\frac{\\alpha}{2}}\\alpha}{c^{\\frac{1}{1-\\alpha}}\\cdot p_{j}^{\\frac{1}{1-\\alpha}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "499 Taking (21) into (Budget Constraint), we get ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{B_{i}=\\displaystyle\\sum_{j\\in[m]}\\frac{v_{i j}^{\\frac{\\alpha}{1-\\alpha}}}{c^{\\frac{1}{1-\\alpha}}}\\cdot p_{j}^{-\\frac{\\alpha}{1-\\alpha}}}\\\\ {c^{\\frac{1}{1-\\alpha}}=\\displaystyle\\frac{1}{B_{i}}\\sum_{j\\in[m]}\\left(\\frac{v_{i j}}{p_{j}}\\right)^{\\frac{\\alpha}{1-\\alpha}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "500 Taking Equation (23) into Equation (21), we get ", "page_idx": 14}, {"type": "equation", "text": "$$\nx_{i j}^{*}=\\frac{v_{i j}^{\\frac{\\alpha}{1-\\alpha}}}{p_{j}^{\\frac{1}{1-\\alpha}}}\\cdot\\frac{B_{i}}{c_{0}}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "501 where $\\begin{array}{r}{c_{0}=\\sum_{j\\in[m]}\\left(\\frac{v_{i j}}{p_{j}}\\right)^{\\frac{\\alpha}{1-\\alpha}}}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "502 Taking Equation (24) into Equation (15), we finally have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u_{i}(x_{i}^{*})=\\left[v_{i j}^{\\alpha}x_{i j}^{\\alpha}\\right]^{\\frac{1}{\\alpha}}}\\\\ &{\\phantom{\\frac{u_{i}(x_{i}^{*})}{\\alpha}}=\\left[\\displaystyle\\sum_{j\\in[m]}v_{i j}^{\\alpha}\\frac{v_{i j}^{\\frac{\\alpha}{1}-\\alpha}}{p_{j j}^{\\frac{1}{2}-\\alpha}}c_{0}^{\\alpha}\\right]}\\\\ &{\\phantom{\\frac{u_{i}(x_{i}^{*})}{\\alpha}}=\\left[\\displaystyle\\sum_{j\\in[m]}\\left(\\frac{v_{i j}}{p_{j j}}\\right)^{\\frac{\\alpha}{1-\\alpha}}c_{0}^{\\alpha}\\right]}\\\\ &{\\phantom{\\frac{u_{i}(x_{i}^{*})}{\\alpha}}=\\partial_{i}\\alpha_{i}^{1-\\frac{1}{\\alpha}}}\\\\ &{\\log\\tilde{u}_{i}(p)=\\log u_{i}(x_{i}^{*})=\\log B_{i}+\\frac{1-\\alpha}{\\alpha}\\log c_{0}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "503 For $\\alpha=1$ , by simple arguments we know that consumer will only buy the good that with largest   \n504 value-per-cost, i.e., $v_{i j}/p_{j}$ . Therefore, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\log\\tilde{u}_{i}(\\pmb{p})=\\log B_{i}+\\log\\operatorname*{max}_{j}\\frac{v_{i j}}{p_{j}}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "505 For $\\alpha=0$ , we have $\\begin{array}{r}{\\log u_{i}(\\mathbf{x}_{i})=\\frac{1}{v_{t}}\\sum_{j\\in[m]}v_{i j}\\log x_{i j}}\\end{array}$ where $\\begin{array}{r}{v_{t}=\\sum_{j\\in[m]}v_{i j}}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "506 Similarly, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{c p_{j}=}}\\\\ {{\\displaystyle{\\vphantom{\\Biggl(}}}}\\\\ {{\\displaystyle{x_{i j}^{*}=}\\frac{\\upsilon_{i j}}{c p_{j}}}}\\end{array}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "507 By solving budget constraints we have $\\begin{array}{r}{c=\\frac{v_{t}}{B_{i}}}\\end{array}$ , and therefore, $\\begin{array}{r}{x_{i j}^{*}=\\frac{v_{i j}B_{i}}{p_{j}v_{t}}}\\end{array}$ and ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\log u_{i}(\\pmb{x}_{i}^{*})=\\frac{1}{v_{t}}\\sum_{j\\in[m]}(v_{i j}\\log\\frac{v_{i j}B_{i}}{p_{j}v_{t}})}}\\\\ &{}&{=\\log B_{i}+\\displaystyle\\sum_{j\\in[m]}\\frac{v_{i j}}{v_{t}}\\log\\frac{v_{i j}}{p_{j}v_{t}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "508 For $\\alpha=-\\infty$ , we can easily know that $v_{i j}x_{i j}^{*}\\equiv c$ for some $c$ . By solving budget constraint we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{j\\in[m]}\\frac{c p_{j}}{v_{i j}}=B_{i}}\\\\ &{c=B_{i}\\left(\\displaystyle\\sum_{j\\in[m]}\\frac{p_{j}}{v_{i j}}\\right)^{-1}}\\\\ &{\\log\\tilde{u}_{i}(p)=\\log c=\\log B_{i}-\\log\\displaystyle\\sum_{j\\in[m]}\\frac{p_{j}}{v_{i j}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "509 Above all, the log Fixed-price Utility for CES functions is ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\log\\tilde{u}_{i}(\\pmb{p})=\\left\\{\\begin{array}{l l}{\\log B_{i}+\\operatorname*{max}_{j}\\log\\frac{v_{i j}}{p_{j}}\\quad\\mathrm{~for~}\\alpha=1}\\\\ {\\log B_{i}+\\sum_{j\\in[m]}\\frac{v_{i j}}{v_{t}}\\log\\frac{v_{i j}}{p_{j}v_{t}}\\quad\\mathrm{~for~}\\alpha=0}\\\\ {\\log B_{i}-\\log\\sum_{j\\in[m]}\\frac{p_{j}}{v_{i j}}\\quad\\mathrm{~for~}\\alpha=-\\infty}\\\\ {\\log B_{i}+\\frac{1-\\alpha}{\\alpha}\\log c_{0}\\quad\\mathrm{~others~}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "510 B Omitted Proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "511 B.1 Proof of Proposition 3.2 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "512 We consider Lagrangian multipliers $\\textbf{\\emph{p}}$ and use the KKT condition. The Lagrangian becomes ", "page_idx": 15}, {"type": "equation", "text": "$$\nL(\\pmb{p},\\pmb{x})=\\sum_{i}B_{i}\\log u_{i}(\\pmb{x}_{i})-\\sum_{j}p_{j}(\\sum_{i}x_{i j}-Y_{j})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "513 and the partial derivative of $x_{i j}$ is ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\frac{\\partial L(\\pmb{p},\\pmb{x}_{i})}{\\partial x_{i j}}}={\\frac{B_{i}}{u_{i}(\\pmb{x}_{i})}}{\\frac{\\partial u_{i}}{\\partial x_{i j}}}-p_{j}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "514 By complementary slackness of $x_{i j}\\geq0$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\frac{B_{i}}{u_{i}(\\mathbf{\\boldsymbol{x}}_{i})}}{\\frac{\\partial u_{i}}{\\partial x_{i j}}}\\leq p_{j}{\\mathrm{~for~all~}}i\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "515 By theorem 3.1, we know that if $(x,p)$ is a market equilibrium, we must have $u_{i}(\\pmb{x}_{i})>0$ for all $i$ ,   \n516 and by condition in Proposition 3.2, we can always select buyer $i$ such that \u2202\u2202xui > 0. Therefore, we   \n517 have $p_{j}>0$ . ", "page_idx": 15}, {"type": "text", "text": "518 As a consequence, $p_{j}>0$ indicates that $\\textstyle\\sum_{j}x_{i j}=V_{j}$ by market clearance condition. ", "page_idx": 15}, {"type": "text", "text": "519 B.2 Proof of Proposition 5.4 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "520 Consider the market equilibrium condition $\\langle\\pmb{p}^{*},\\pmb{x}_{i}^{*}\\rangle=B_{i}$ , we have $\\begin{array}{r}{\\sum_{j}p_{j}x_{i j}=B_{i}}\\end{array}$ . sum over this   \n521 expression, we have $\\begin{array}{r}{\\sum_{i}\\sum_{j}p_{j}x_{i j}=\\sum_{i}B_{i}}\\end{array}$ . Then, $\\begin{array}{r}{\\sum_{j}p_{j}\\sum_{i}x_{i j}=\\dot{\\sum}_{i}B_{i}}\\end{array}$ . Notice that we have   \n522 $\\textstyle\\sum_{i=1}^{n}x_{i j}=Y_{j}$ in market equilibrium, so $\\textstyle\\sum_{j}p_{j}Y_{j}=\\sum_{i}B_{i}$ , that completes the proof. ", "page_idx": 15}, {"type": "text", "text": "523 B.3 Proof of Theorem 5.5 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "524 Proof of Theorem 5.5. Denote $\\left(x,p\\right)$ as the market equilibrium, $\\textbf{\\emph{p}}$ as the price for goods and $\\pmb{x}_{i}^{*}(\\pmb{p})$   \n525 as the optimal consumption set of buyer $i$ when the price is $\\pmb{p}$ . ", "page_idx": 15}, {"type": "text", "text": "526 We have following equation: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{j}x_{i j}p_{j}=B_{i}}\\\\ &{\\quad\\quad\\quad x_{i}\\in\\pmb{x}_{i}^{*}(p)}\\\\ &{\\displaystyle\\sum_{i\\in[n]}x_{i j}=Y_{j}}\\\\ &{\\quad\\quad u_{i}(\\pmb{p})=u_{i}(\\pmb{x}_{i}),\\:\\forall\\pmb{p}\\in\\mathbb{R}_{+}^{m},\\:\\forall\\pmb{x}_{i}\\in\\pmb{x}_{i}^{*}(p)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "527 From Proposition 5.4 we know $\\begin{array}{r}{\\sum_{i\\in[n]}B_{i}=\\sum_{j\\in[m]}Y_{j}p_{j}}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "528 Let $\\pmb{p}^{\\prime}$ be some price for items such that $\\begin{array}{r}{\\sum_{j\\in[m]}Y_{j}\\boldsymbol{p}_{j}^{\\prime}=\\sum_{i\\in[n]}B_{i}}\\end{array}$ . Let $\\pmb{x}_{i}^{\\prime}\\in\\pmb{x}_{i}^{*}(\\pmb{p}^{\\prime})$ and $B_{i}^{\\prime}=$   \n529 $\\langle p^{\\prime},x_{i}\\rangle$ . We know that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{i\\in[n]}B_{i}^{\\prime}=\\langle\\pmb{p}^{\\prime},\\sum_{i\\in[n]}\\pmb{x}_{i}\\rangle=\\langle\\pmb{p}^{\\prime},\\pmb{Y}\\rangle=\\sum_{i\\in[n]}B_{i}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "530 For consumer $i$ , $\\pmb{x}_{i}$ costs $B_{i}^{\\prime}$ at price $\\pmb{p}^{\\prime}$ , thus $\\textstyle{\\frac{B_{i}}{B_{i}^{\\prime}}}\\mathbf{x}_{i}$ costs $B_{i}$ at price $\\pmb{p}^{\\prime}$ . Besides, $\\pmb{x}_{i}^{\\prime}$ also costs $B_{i}$ for   \n531 price $\\pmb{p}^{\\prime}$ , and $\\pmb{x}^{\\prime}$ is the optimal consumption for buyer $i$ . Then we have ", "page_idx": 16}, {"type": "equation", "text": "$$\nu_{i}(\\pmb{p}^{\\prime})=u_{i}(\\pmb{x}_{i}^{\\prime})\\geq u_{i}(\\frac{B_{i}}{B_{i}^{\\prime}}\\pmb{x}_{i})=\\frac{B_{i}}{B_{i}^{\\prime}}u_{i}(\\pmb{x}_{i})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "532 where the last equation is from the homogeneity(with degree 1) of utility function. ", "page_idx": 16}, {"type": "text", "text": "533 Taking logarithm and weighted sum with $B_{i}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{i\\in[n]}B_{i}\\log u_{i}(\\pmb{p}^{\\prime})\\geq\\sum_{i\\in[n]}B_{i}\\log\\frac{B_{i}}{B_{i}^{\\prime}}+\\sum_{i\\in[n]}B_{i}\\log u_{i}(\\pmb{x}_{i})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "534 Take $\\begin{array}{r}{B_{\\mathrm{total}}=\\sum_{i\\in[n]}B_{i}}\\end{array}$ , the first term in RHS becomes ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\sum_{i\\in[n]}B_{i}\\log\\frac{B_{i}}{B_{i}^{\\prime}}}\\\\ &{=\\!B_{\\mathrm{total}}\\displaystyle\\sum_{i\\in[n]}\\left(\\frac{B_{i}}{B_{\\mathrm{total}}}\\log\\frac{B_{i}/B_{\\mathrm{total}}}{B_{i}^{\\prime}/B_{\\mathrm{total}}}\\right)}\\\\ &{\\quad=\\!B_{\\mathrm{total}}\\cdot\\mathrm{KL}(\\frac{B}{B_{\\mathrm{total}}}||\\frac{B^{\\prime}}{B_{\\mathrm{total}}})}\\\\ &{>0}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "535 Therefore, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{i\\in[n]}B_{i}\\log u_{i}(\\pmb{p}^{\\prime})\\geq\\sum_{i\\in[n]}B_{i}\\log u_{i}(\\pmb{x}_{i})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "536 For $\\mathbf{\\nabla}x^{\\prime}$ that satisfies market clearance, by optimality of EG program(EG), we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{i\\in[n]}B_{i}\\log u_{i}(\\mathbf{x}_{i})\\geq\\sum_{i\\in[n]}B_{i}\\log u_{i}(\\mathbf{x}_{i}^{\\prime})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "537 Equation (49) and Equation (50) together complete the proof of the first part. ", "page_idx": 16}, {"type": "text", "text": "538 If $\\left(x,p\\right)$ constitutes a market equilibrium, it\u2019s obvious that $\\mathrm{LFW}(p)$ and $\\operatorname{LNW}(x)$ are identical,   \n539 therefore $\\mathrm{{NG}}({\\pmb x},{\\pmb p})=0$ .   \n540 On the other hand, if $(x,p)$ is not a market equilibrium, but $\\mathrm{NG}({\\boldsymbol{\\mathbf{x}}},{\\boldsymbol{\\mathbf{p}}})=0$ , it means that the KL   \n541 convergence term must equal to 0, and $B_{i}=B_{i}^{\\prime}$ for all $i$ , which means that $\\pmb{x}_{i}$ costs buyer $i$ with   \n542 money $B_{i}$ and $\\pmb{x}_{i}$ are in the consumption set of buyer $i$ . Since $(x,p)$ is not a market equilibrium,   \n543 there is at least one buyer that can choose a better allocation $\\mathbf{\\boldsymbol{x}}_{i}^{\\prime}$ to improve her utility, therefore   \n544 improve $\\mathrm{LFW}(p)$ , and it cannot be the case that $\\mathrm{LFW}(\\pmb{p})=\\mathrm{LNW}(\\pmb{x})$ , which makes a contradiction. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "545 ", "page_idx": 16}, {"type": "text", "text": "546 B.4 Proof of Proposition 5.6 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "547 We leave the formal presentation of Proposition 5.6 and proofs to three theorems below. ", "page_idx": 16}, {"type": "text", "text": "548 Lemma B.1. Assume that $u_{i}(\\pmb{x}_{i})$ is twice differentiable and denote $H(x_{i})$ as the Hessian matrix of   \n549 $u_{i}(\\pmb{x}_{i})$ . If following hold: ", "page_idx": 16}, {"type": "text", "text": "550 ", "page_idx": 16}, {"type": "text", "text": "551 ", "page_idx": 16}, {"type": "text", "text": "552 ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\bf\\bullet\\ }}\\end{array}||x_{i}-x_{i}^{*}||=\\varepsilon\\,f o r\\,s o m e\\ i\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "553 then we have $\\mathrm{OPT}-\\mathrm{LNW}(\\pmb{x})=\\Omega(\\varepsilon^{2})$ . ", "page_idx": 16}, {"type": "text", "text": "554 Lemma B.2. Denote $\\widetilde{u}_{i}(\\pmb{p},B_{i})$ and ${\\pmb x}_{i}^{*}({\\pmb p},B_{i})$ as the maximum utility buyer i can get and the   \n555 corresponding consumption for buyer $i$ when her budget is $B_{i}$ and prices are p. If following hold: ", "page_idx": 17}, {"type": "text", "text": "556 ", "page_idx": 17}, {"type": "text", "text": "$\\bullet\\ ||\\boldsymbol{p}-\\boldsymbol{p}^{*}||=\\varepsilon$ \u2022 $\\pmb{x}_{i}^{*}(\\pmb{p},B_{i})$ is differentiable with $\\textbf{\\emph{p}}$ . $\\begin{array}{r}{H_{X}:=(\\sum_{i\\in[n]}\\frac{\\partial x_{i j}^{*}}{\\partial p_{k}}(\\pmb{p}^{*},B_{i}))_{j,k\\in[m]}}\\end{array}$ ]\u2202\u2202xpi\u2217kj (p\u2217, Bi))j,k\u2208[m] has full rank. ", "page_idx": 17}, {"type": "text", "text": "559 then we have $L F W(\\pmb{p})-O P T=\\Omega(\\varepsilon^{2})$ . ", "page_idx": 17}, {"type": "text", "text": "560 Remark B.3. It\u2019s worth notice that $H(x_{i}^{*})$ can not has full rank $m$ , since $u_{i}({\\pmb x})$ is assumed to be   \n561 homogeneous and thus linear in the direction $\\textbf{\\em x}$ . Therefore, we have $H(x_{i})\\mathbf{x}_{i}=\\mathbf{0}$ for all $\\pmb{x}_{i}$ .   \n562 Let $C_{i}=\\{\\pmb{x}_{i}\\in\\mathbb{R}_{+}^{m}:\\langle\\pmb{p},\\pmb{x}_{i}\\rangle=B_{i}\\}$ be the consumption set of buyer $i$ , since $\\pmb{x}_{i}$ can not be parallel   \n563 with $C_{i}$ , the condition that $H(x_{i}^{*})$ has rank $m-1$ means that, $H(\\pmb{x}_{i})$ is strongly concave at point $\\pmb{x}_{i}^{*}$   \n564 on the consumption set $C_{i}$ .   \n565 Besides, we emphasize that the conditions in Lemma B.1 and Lemma B.2 are satisfied for CES utility   \n566 with $\\alpha<1$ . ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "567 Corollary B.4. Under the assumptions in Lemma B.1 and Lemma B.2, $i f\\mathrm{NG}({\\pmb x},{\\pmb p})=\\varepsilon,$ , we have: ", "page_idx": 17}, {"type": "text", "text": "568 ", "page_idx": 17}, {"type": "text", "text": "569 ", "page_idx": 17}, {"type": "text", "text": "$\\bullet\\ ||p-p^{*}||=O({\\sqrt{\\varepsilon}})$ \u2022 $||\\pmb{x}_{i}-\\pmb{x}_{i}^{*}||=O(\\sqrt\\varepsilon)\\,f o r\\,a l l\\,i$ ", "page_idx": 17}, {"type": "text", "text": "570 Proof of Corollary B.4. A direct inference from Lemma B.1 and Lemma B.2, notice that $\\mathrm{NG}=\\varepsilon$   \n571 indicates that $\\mathrm{OPT}-\\mathrm{LNW}(\\pmb{x})\\leq\\varepsilon$ and $\\mathrm{LFW}(\\pmb{p})-\\mathrm{OPT}\\leq\\varepsilon$ . \u53e3   \n572 Corollary B.4 states that, for a pair of $\\left(x,p\\right)$ that satisfy market clearance and price constraints, a   \n573 small Nash Gap indicates that the point $\\left(x,p\\right)$ is close to the equilibrium point $(\\pmb{x}^{\\ast},\\pmb{p}^{\\ast})$ , in the sense   \n574 of Euclidean distance. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "575 Lemma B.5. Assume following hold: ", "page_idx": 17}, {"type": "text", "text": "576 ", "page_idx": 17}, {"type": "text", "text": "577 ", "page_idx": 17}, {"type": "equation", "text": "$$\n||\\pmb{x}_{i}-\\pmb{x}_{i}^{*}||\\leq\\varepsilon\\,f o r\\,a l l\\,i\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "578 then, we have $|\\operatorname{WSW}(\\pmb{x})-\\operatorname{WSW}(\\pmb{x}^{*})|=O(\\varepsilon^{2}).$ ", "page_idx": 17}, {"type": "text", "text": "579 Remark B.6. These conditions can be held when buyers are homogeneous, i.e., $B_{i}\\ =\\ B_{j}$ and   \n580 $u_{i}({\\pmb x})=u_{j}({\\pmb x})$ for all $i,j,x\\in\\mathbb{R}_{+}^{m}$ . Besides, consider buyers with same budgets, these conditions   \n581 can also be held if the market has some \u201cequivariance property\u201d, e.g., there is a $n$ -cycle permutation of   \n582 buyers $\\rho$ and permutation of goods $\\tau$ , such that $u_{i}(\\pmb{x}_{i})=u_{\\rho(i)}(\\tau(\\pmb{x}_{\\rho(i)}))$ for all $i$ and $\\tau(Y_{1},...,Y_{m})=$   \n583 $(Y_{1},...,Y_{m})$ . ", "page_idx": 17}, {"type": "text", "text": "584 Corollary B.7. Under the assumptions in Lemma B.1 and Lemma B.5, $i f\\mathrm{NG}({\\pmb x},{\\pmb p})=\\varepsilon$ , we have ", "page_idx": 17}, {"type": "text", "text": "585 ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbf{\\nabla}\\bullet\\mathbf{\\partial}\\vert\\mathrm{WSW}(\\pmb{x})-\\mathrm{WSW}(\\pmb{x}^{\\ast})\\vert=O(\\varepsilon).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "586 Proof. A direct inference from Lemma B.1 and Lemma B.5. ", "page_idx": 17}, {"type": "text", "text": "587 B.4.1 Proof of Lemma B.1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "588 Proof of Lemma B.1. We observe that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{OPT-LNW}(\\pmb{x})=\\sum_{i\\in[n]}B_{i}\\left[\\log u_{i}(\\pmb{x}_{i}^{*})-\\log u_{i}(\\pmb{x}_{i})\\right]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "589 Consider the Taylor expansion of $\\log u_{i}(\\pmb{x}_{i})$ and $u_{i}(\\pmb{x}_{i})$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\log u_{i}(\\boldsymbol{x}_{i})=\\log u_{i}(\\boldsymbol{x}_{i}^{*})+\\frac{1}{u_{i}(\\boldsymbol{x}_{i}^{*})}(u_{i}(\\boldsymbol{x}_{i})-u_{i}(\\boldsymbol{x}_{i}^{*}))}\\\\ {-\\frac{1}{2u_{i}(\\boldsymbol{x}_{i}^{*})^{2}}(u_{i}(\\boldsymbol{x}_{i})-u_{i}(\\boldsymbol{x}_{i}^{*}))^{2}}\\\\ {+O((u_{i}(\\boldsymbol{x}_{i})-u_{i}(\\boldsymbol{x}_{i}^{*}))^{3})}\\\\ {u_{i}(\\boldsymbol{x}_{i})=\\!u_{i}(\\boldsymbol{x}_{i}^{*})+\\frac{\\partial u_{i}}{\\partial x_{i}}(\\boldsymbol{x}_{i}^{*})(\\boldsymbol{x}_{i}-\\boldsymbol{x}_{i}^{*})}\\\\ {+\\frac{1}{2}(\\boldsymbol{x}_{i}-\\boldsymbol{x}_{i}^{*})^{T}\\!H(\\boldsymbol{x}_{i}^{*})(\\boldsymbol{x}_{i}-\\boldsymbol{x}_{i}^{*})+O(||\\boldsymbol{x}_{i}-\\boldsymbol{x}_{i}^{*}||^{3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "590 Notice that $||\\pmb{x}_{i}-\\pmb{x}_{i}^{*}||=\\varepsilon$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log u_{i}(\\pmb{x}_{i})=\\log u_{i}(\\pmb{x}_{i}^{*})}\\\\ &{\\qquad\\qquad+\\frac{1}{u_{i}(\\pmb{x}_{i}^{*})}[\\frac{\\partial u_{i}}{\\partial\\mathscr{x}_{i}}(\\pmb{x}_{i}^{*})(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})\\cdot\\cdot\\cdot\\pmb{\\varepsilon}\\mathrm{~term}}\\\\ &{\\qquad\\qquad+\\frac{1}{2}(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})^{T}H(\\pmb{x}_{i}^{*})(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})]\\cdot\\cdot\\cdot\\pmb{\\varepsilon}^{2}\\mathrm{~term}}\\\\ &{\\qquad\\qquad-\\frac{1}{2u_{i}(\\pmb{x}_{i}^{*})^{2}}\\left(\\frac{\\partial u_{i}}{\\partial\\mathscr{x}_{i}}(\\pmb{x}_{i}^{*})(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})\\right)^{2}\\cdot\\cdot\\cdot\\cdot\\pmb{\\varepsilon}^{2}\\mathrm{~term}}\\\\ &{\\qquad\\qquad+O(\\varepsilon^{3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "591 We next deal with Equation (51) to Equation (53) separately. ", "page_idx": 18}, {"type": "text", "text": "592 Derivation of Equation (51) Since $\\pmb{x}_{i}^{*}$ solves the buyer $i$ \u2019s problem, we must have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{\\partial u_{i}}{\\partial x_{i}}(\\pmb{x}_{i}^{*})=\\lambda_{i}\\pmb{p}^{*}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "593 where $\\lambda_{i}$ is the Lagrangian Multipliers for buyer $i$ . ", "page_idx": 18}, {"type": "text", "text": "594 We also know that $u_{i}(\\pmb{x}_{i})$ is homogeneous with degree 1, by Euler formula, we derive ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\langle\\frac{\\partial u_{i}}{\\partial x_{i}}({\\pmb x}_{i}),{\\pmb x}_{i}\\rangle=u_{i}({\\pmb x}_{i})\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "595 Combine Equation (54) and Equation (55) and take $\\pmb{x}_{i}=\\pmb{x}_{i}^{*}$ , we derive ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\lambda_{i}\\langle p^{*},\\pmb{x}_{i}^{*}\\rangle=\\!u_{i}(\\pmb{x}_{i}^{*})}}\\\\ {{\\lambda_{i}=\\!\\frac{u_{i}(\\pmb{x}_{i}^{*})}{B_{i}}}}\\\\ {{\\displaystyle\\frac{\\partial u_{i}}{\\partial x_{i}}(\\pmb{x}_{i}^{*})=\\!\\frac{u_{i}(\\pmb{x}_{i}^{*})}{B_{i}}p^{*}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "596 Sum up over $i$ for Equation (51), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in[n]}B_{i}\\frac{1}{u_{i}(\\pmb{x}_{i}^{*})}\\frac{\\partial u_{i}}{\\partial x_{i}}(\\pmb{x}_{i}^{*})(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})}\\\\ &{\\displaystyle=p\\sum_{i\\in[n]}(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "597 Derivation of Equation (52) and Equation (53) Combining Equation (52) and Equation (53), we   \n598 have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\frac{B_{i}}{2u_{i}(\\pmb{x}_{i}^{*})}(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})^{T}H(\\pmb{x}_{i}^{*})(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})-\\frac{1}{2B_{i}}(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})^{T}(\\pmb{p}^{*}\\pmb{p}^{*T})(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})}\\\\ {\\displaystyle=\\frac{1}{2B_{i}}(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})^{T}(\\frac{B_{i}^{2}}{u_{i}(\\pmb{x}_{i}^{*})}H(\\pmb{x}_{i}^{*})-\\pmb{p}^{*}\\pmb{p}^{*T})(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "599 Denote $\\begin{array}{r}{H_{0}(\\pmb{x}_{i}^{*})=\\frac{B_{i}^{2}}{u_{i}(\\pmb{x}_{i}^{*})}H(\\pmb{x}_{i}^{*})-\\pmb{p}^{*}\\pmb{p}^{*T}}\\end{array}$ , next we assert that $H_{0}(x_{i}^{*})$ is negative definite. ", "page_idx": 19}, {"type": "text", "text": "600 Since $H(x_{i}^{*})$ and $-p^{*}p^{*T}$ are negative semi-definite, $H_{0}(x_{i}^{*})$ must be negative semi-definite with   \n601 $\\mathrm{rank}(H_{0}(\\pmb{x}_{i}^{*}))\\geq m-1$ .   \n602 Let $\\lambda_{1}\\,\\leq\\,\\lambda_{2}\\,\\leq\\,\\cdots\\,\\leq\\,\\lambda_{m-1}\\,<\\,\\lambda_{m}\\,=\\,0$ be eigenvalues and $v_{1},...,v_{n}\\,=\\,x_{i}^{*}$ be eigenvectors   \n603 of $H(x_{i}^{*})$ . If $\\mathrm{rank}(H_{0}(\\pmb{x}_{i}^{*}))\\,=\\,m-1$ , it means that $\\pmb{x}_{i}^{*}$ has to be eigenvectors of $-p^{*}p^{*T}$ with   \n604 eigenvalue 0. However, we have $-p^{*}p^{*T}\\pmb{x}_{i}^{*}=-B_{i}\\pmb{p}^{*}\\neq0$ , which leads to a contradiction.   \n605 Therefore, we have $\\mathrm{rank}(H_{0}(\\pmb{x}_{i}^{*}))\\,=\\,m$ and $H_{0}(x_{i}^{*})$ is negative definite, we denote $\\lambda_{1}^{i}\\,\\le\\,...,\\le$   \n606 $\\lambda_{n}^{i}<0$ as the eigenvalues of $H_{0}(x_{i}^{*})$ , and $k$ as the universal lower bound for $|\\lambda_{n}^{i}|$ , then we have that, ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{1}{2}({\\pmb x}_{i}-{\\pmb x}_{i}^{*})^{T}H_{0}({\\pmb x}_{i}^{*})({\\pmb x}_{i}-{\\pmb x}_{i}^{*})\\leq-\\frac{k}{2}\\varepsilon^{2}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "607 By combining Equation (56) and Equation (57), we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{OPT-LNW}(\\boldsymbol{x})=-\\displaystyle\\sum_{i\\in[n]}B_{i}\\left[\\frac{1}{2B_{i}}(\\boldsymbol{x}_{i}-\\boldsymbol{x}_{i}^{*})^{T}H_{0}(\\boldsymbol{x}_{i}^{*})(\\boldsymbol{x}_{i}-\\boldsymbol{x}_{i}^{*})\\right]+O(\\varepsilon^{3})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\geq\\displaystyle\\frac{k}{2}\\varepsilon^{2}+O(\\varepsilon^{3})}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\Omega(\\varepsilon^{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "608 ", "page_idx": 19}, {"type": "text", "text": "609 B.4.2 Proof of Lemma B.2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "610 Proof of Lemma B.2. The proof is similar with Appendix B.4.1 by using Taylor expansion technique.   \n611 Before that, we first derive some identities. ", "page_idx": 19}, {"type": "text", "text": "612 By Roy\u2019s identity, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\partial\\tilde{u_{i}}}{\\partial p_{j}}(\\pmb{p},B_{i})=-x_{i j}^{*}(\\pmb{p},B_{i})\\frac{\\partial\\tilde{u}_{i}}{\\partial B_{i}}(\\pmb{p},B_{i})\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "613 Since $u(\\pmb{x}_{i})$ is homogeneous with $\\pmb{x}_{i}$ , it\u2019s easy to derive that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\partial\\tilde{u}_{i}}{\\partial B_{i}}({\\pmb p},B_{i})=\\frac{\\tilde{u}_{i}({\\pmb p},B_{i})}{B_{i}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "614 Above all, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\partial{\\tilde{u}_{i}}}{\\partial p_{j}}(\\pmb{p},\\pmb{B_{i}})=-\\frac{1}{B_{i}}x_{i j}^{*}(\\pmb{p},B_{i}){\\tilde{u}_{i}}(\\pmb{p},B_{i})\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "615 Besides, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\frac{\\partial^{2}\\tilde{u}_{i}}{\\partial p_{j}\\partial p_{k}}({\\pmb p},B_{i})=\\!\\frac{1}{B_{i}^{2}}x_{i j}^{*}({\\pmb p},B_{i})x_{i k}^{*}({\\pmb p},B_{i})\\tilde{u}_{i}({\\pmb p},B_{i})}}\\\\ {{\\displaystyle-\\frac{1}{B_{i}}\\frac{x_{i j}^{*}({\\pmb p},B_{i})}{\\partial p_{k}}\\tilde{u}_{i}({\\pmb p},B_{i})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "616 Next we consider the Taylor expansion, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\log\\tilde{u}_{i}(p)=\\log\\tilde{u}_{i}(p^{*})}}\\\\ {{\\qquad\\qquad+\\displaystyle\\frac{1}{\\tilde{u}_{i}(p^{*})}[\\frac{\\partial\\tilde{u}_{i}}{\\partial p}(p^{*})(p-p^{*})\\cdot\\cdot\\cdot\\varepsilon\\mathrm{~term}}}\\\\ {{\\qquad\\qquad+\\displaystyle\\frac{1}{2}(p-p^{*})^{T}H_{p}(p-p^{*})]\\cdot\\cdot\\cdot\\varepsilon^{2}\\mathrm{~term}}}\\\\ {{\\qquad-\\displaystyle\\frac{1}{2\\tilde{u}_{i}(p^{*})^{2}}\\left[\\frac{\\partial\\tilde{u}_{i}}{\\partial p}(p^{*})(p-p^{*})\\right]^{2}\\cdot\\cdot\\cdot\\varepsilon^{2}\\mathrm{~term}}}\\\\ {{\\qquad+O(\\varepsilon^{3})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "617 where $H_{p}$ is the Hessian matrix for $\\tilde{u}_{i}(\\pmb{p})$ . ", "page_idx": 19}, {"type": "text", "text": "618 Derivation of Equation (59) We have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\displaystyle\\sum_{i\\in[n]}B_{i}\\frac{1}{\\tilde{u}_{i}(p^{*})}\\langle\\frac{\\partial\\tilde{u}_{i}}{\\partial p}(p^{*}),(p-p^{*})\\rangle}\\\\ &{=\\displaystyle\\sum_{i\\in[n]}\\langle x_{i}^{*},(p-p^{*})\\rangle}\\\\ &{=\\langle\\mathbf{1},(p-p^{*})\\rangle\\cdots\\mathrm{by~market~clearance}}\\\\ &{=0\\cdots\\mathrm{by~price~constraints}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "619 Derivation of Equation (60) and Equation (61) These expressions become ", "text_level": 1, "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\frac1{2{\\tilde{u}}_{i}({\\boldsymbol p}^{*})}[\\frac1{B_{i}^{2}}{\\tilde{u}}_{i}({\\boldsymbol p}^{*})\\langle x_{i}^{*},{\\boldsymbol p}-{\\boldsymbol p}^{*}\\rangle^{2}-\\frac1{B_{i}}{\\tilde{u}}_{i}({\\boldsymbol p}^{*})({\\boldsymbol p}-{\\boldsymbol p}^{*})^{T}(\\frac{\\partial x_{i j}^{*}}{\\partial p_{k}}({\\boldsymbol p}^{*},{\\boldsymbol B}_{i}))_{j,k\\in[m]}({\\boldsymbol p}-{\\boldsymbol p}^{*})]}}\\\\ {{\\displaystyle-\\frac1{2{\\tilde{u}}_{i}({\\boldsymbol p}^{*})^{2}}\\frac{{\\tilde{u}}_{i}({\\boldsymbol p}^{*})^{2}}{B_{i}^{2}}\\langle x_{i}^{*},{\\boldsymbol p}-{\\boldsymbol p}^{*}\\rangle^{2}}}\\\\ {{\\displaystyle=\\frac1{2B_{i}}({\\boldsymbol p}-{\\boldsymbol p}^{*})^{T}(\\frac{\\partial x_{i j}^{*}}{\\partial p_{k}}({\\boldsymbol p}^{*},{\\boldsymbol B}_{i}))_{j,k\\in[m]}({\\boldsymbol p}-{\\boldsymbol p}^{*})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "620 Summing up over $i$ , we derive that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\mathrm{LFW}(p)-\\mathrm{OPT}=\\displaystyle\\sum_{i\\in[n]}B_{i}\\frac{1}{2B_{i}}(p-p^{*})^{T}(\\frac{\\partial x_{i j}^{*}}{\\partial p_{k}}(p^{*},B_{i}))_{j,k\\in[m]}(p-p^{*})+{\\cal O}(\\varepsilon^{3})}}\\\\ {{=\\displaystyle\\frac{1}{2}(p-p^{*})^{T}H_{X}(p-p^{*})+{\\cal O}(\\varepsilon^{3})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "621 Since $\\pmb{p}^{*}$ gets the minimum of $\\mathrm{LFW}(p)$ , we must have that $H_{X}$ is positive semi-definite. Together   \n622 with $H_{X}$ has full rank, we know that $H_{X}$ is positive definite. Denote $\\lambda_{m}$ as the minimum eigenvalues   \n623 of $H_{X}$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\mathrm{LFW}(p)-\\mathrm{OPT}\\geq\\!\\displaystyle\\frac{\\varepsilon^{2}\\lambda_{m}}{2}+O(\\varepsilon^{3})}\\\\ {=\\Omega(\\varepsilon^{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "624 ", "page_idx": 20}, {"type": "text", "text": "625 B.4.3 Proof of Lemma B.5 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "626 Proof of Lemma B.5. Notice that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname{WSW}(\\pmb{x})=\\operatorname{WSW}(\\pmb{x}^{*})+\\sum_{i\\in[n]}\\langle\\frac{\\partial\\operatorname{WSW}}{\\partial\\pmb{x}_{i}}(\\pmb{x}_{i}^{*}),(\\pmb{x}_{i}-\\pmb{x}_{i}^{*})\\rangle+O(\\varepsilon^{2})\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "627 We have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\frac{\\partial\\mathrm{WSW}}{\\partial x_{i}}(x_{i}^{*})}\\\\ &{}&{\\quad=\\!B_{i}\\frac{\\partial u_{i}}{\\partial x_{i}}(x_{i}^{*})}\\\\ &{}&{\\quad=\\!B_{i}\\frac{u_{i}({\\pmb x}_{i}^{*})}{B_{i}}p^{*}}\\\\ &{}&{\\quad=\\!c p^{*}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "628 Therefore, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname{WSW}(\\pmb{x})=\\operatorname{WSW}(\\pmb{x}^{*})+\\sum_{i\\in[n]}c\\langle\\pmb{p}^{*},\\pmb{x}_{i}-\\pmb{x}_{i}^{*}\\rangle+O(\\varepsilon^{2})\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "629 which completes the proof. ", "page_idx": 20}, {"type": "text", "text": "630 ", "page_idx": 20}, {"type": "text", "text": "631 C Additional Experiments Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "632 C.1 More about baselines ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "633 EG program solver (abbreviated as EG) We propose the first baseline algorithm EG. Recall the   \n634 Eisenberg-Gale convex program(EG): ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\quad{\\frac{1}{n}}\\sum_{i=1}^{n}B_{i}\\log u_{i}(\\pmb{x}_{i})\\quad{\\mathrm{s.t.~}}{\\frac{1}{n}}\\sum_{i=1}^{n}x_{i j}=1,\\ x\\geq0.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "635 We use the network module in pytorch to represent the parameters $\\pmb{x}\\in\\mathbb{R}_{+}^{n\\times m}$ , and softplus activation   \n636 function to satisfy $x\\geq0$ automatedly. We use gradient ascent algorithm to optimize the parameters   \n637 $\\textbf{\\em x}$ . For constraint $\\textstyle{\\frac{1}{n}}\\sum_{i\\in[n]}x_{i j}\\,=\\,{\\dot{1}}$ , we introduce Lagrangian multipliers $\\lambda_{j}$ and minimize the   \n638 Lagrangian: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\mathcal{L}}_{\\rho}({\\pmb x};{\\pmb\\lambda})=-\\,\\frac{1}{n}\\sum_{i\\in[n]}B_{i}\\log u_{i}({\\pmb x}_{i})+\\sum_{j\\in[m]}\\lambda_{j}\\,\\left(\\frac{1}{n}\\sum_{i\\in[n]}x_{i j}-1\\right)}}\\\\ {{\\displaystyle+\\frac{\\rho}{2}\\sum_{j\\in[m]}\\left(\\frac{1}{n}\\sum_{i\\in[n]}x_{i j}-1\\right)^{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "639 The updates of $\\lambda$ is $\\begin{array}{r}{\\lambda_{j}\\gets\\lambda_{j}+\\beta_{t}\\rho\\left(\\frac{1}{n}\\sum_{i\\in[n]}x_{i j}-1\\right)}\\end{array}$ , here $\\beta_{t}$ is step size, which is identical with   \n640 that in MarketFCNet. The algorithm returns the final $(x,\\lambda)$ as the approximated market equilibrium.   \n641 EG program solver with momentum (abbreviated as EG- $\\mathbf{\\nabla}\\cdot\\mathbf{m}$ ) The program to solve is exactly   \n642 same with that in EG. The only difference is that we use gradient ascent with momentum to optimize   \n643 the parameters $\\textbf{\\em x}$ . ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "644 C.2 More Experimental Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "645 Without special specification, we use the experiment settings as follows. All experiments are con  \n646 ducted in one RTX 4090 graphics cards using 16 CPUs or 1 GPU. We set dimension of representations   \n647 of buyers and goods to be $d=5$ . Each elements in representation is i.i.d from ${\\mathcal{N}}(0,1)$ for normal   \n648 distribution (default) contexts, $U[0,1]$ for uniform distribution contexts and $E x p(1)$ for exponential   \n649 distribution contexts. Budget is generated with $B(b)=||b||_{2}$ , and valuation in utility function is   \n650 generated with $v(b,g)\\,=\\,\\mathrm{softplus}(\\langle b,g\\rangle)$ , where soft ${\\mathrm{lus}}(\\tilde{x})\\,=\\,\\log(1+\\exp(x))$ is a smoothing   \n651 function that maps each real number to be positive. $\\alpha$ in CES utility are chosen to be 0.5 by default.   \n652 MarketFCNet is designed as a fully connected network with depth 5 and width 256 per layer. $\\rho$ is   \n653 chosen to be 0.2 in Augmented Lagrange Multiplier Method and the step size \u03b2t is chosen to be\u221a1t.   \n654 We choose $K=100$ as inner iteration for each epoch, and training for 30 epochs in MarketFCNet.   \n655 For $E G$ and $E G{-m}$ baselines, we choose the inner iteration $K=1000$ when $n>1000$ and $K=100$   \n656 when $n\\leq1000$ for each epoch. Baselines are enssembled with early stopping as long as NG is lower   \n657 than $10^{-3}$ . Both baselines are optimized for 30 epochs in total.   \n658 We use Adam optimizer and learning rate $1e-4$ to optimize the allocation network in MarketFCNet.   \n659 When computing $\\Delta\\lambda_{j}$ in MarketFCNet, we directly compute $\\Delta\\lambda_{j}$ rather than generate an unbiased   \n660 estimator, since it does not cost too much to consider all buyers for one time. For those baselines,   \n661 we use gradient descent to optimize the parameters following existing works, and the step size is   \n662 fine-tuned to be $1e\\!+2$ for $\\alpha=1$ , $n>1000$ ; $1e+3$ for $\\alpha<1$ , $n>1000$ and 1 for $\\alpha<1$ , $n\\leq1000$   \n663 and 0.1 for $\\alpha\\,=\\,1$ , $n\\,\\leq\\,1000$ for better performances of the baselines. Since that Lagrangian   \n664 multipliers $\\lambda\\leq0$ will indicate an illegal Nash Gap measure, therefore, we hard code EG algorithm   \n665 such that it will only return a result when it satisfies that the price $\\lambda_{j}>0$ for all good j. All baselines   \n666 are run in GPU when $n>1000$ and CPU when $n\\leq1000$ .1 ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "667 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "668 1. Claims   \n669 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n670 paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "671 Answer: [TODO][Yes] ", "page_idx": 22}, {"type": "text", "text": "672 Justification: [TODO] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 22}, {"type": "text", "text": "Answer: [TODO][Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: [TODO]We discuss the limitations in Section 7. ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "714 3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "715 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n716 a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [TODO][No] ", "page_idx": 22}, {"type": "text", "text": "Justification: [TODO]The answer is [Yes] except for Theorem 3.1. Theorem 3.1 is a restated theorem of Gao and Kroer [30] and we do not cover that proof in this paper. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [TODO][Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: [TODO]We present the experimental details in Appendix C. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 23}, {"type": "text", "text": "773   \n774 Justification: [TODO]The code need to be more finely organized before it goes public.   \n775 Guidelines:   \n776 \u2022 The answer NA means that paper does not include experiments requiring code.   \n777 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n778 public/guides/CodeSubmissionPolicy) for more details.   \n779 \u2022 While we encourage the release of code and data, we understand that this might not be   \n780 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n781 including code, unless this is central to the contribution (e.g., for a new open-source   \n782 benchmark).   \n783 \u2022 The instructions should contain the exact command and environment needed to run to   \n784 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n785 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n786 \u2022 The authors should provide instructions on data access and preparation, including how   \n787 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n788 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n789 proposed method and baselines. If only a subset of experiments are reproducible, they   \n790 should state which ones are omitted from the script and why.   \n791 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n792 versions (if applicable).   \n793 \u2022 Providing as much information as possible in supplemental material (appended to the   \n794 paper) is recommended, but including URLs to data and code is permitted.   \n795 6. Experimental Setting/Details   \n796 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n797 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n798 results?   \n799 Answer: [TODO][Yes]   \n800 Justification: [TODO]These are presented in Appendix C   \n801 Guidelines:   \n802 \u2022 The answer NA means that the paper does not include experiments.   \n803 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n804 that is necessary to appreciate the results and make sense of them.   \n805 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n806 material.   \n807 7. Experiment Statistical Significance   \n808 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n809 information about the statistical significance of the experiments?   \n810 Answer: [TODO][No]   \n811 Justification: [TODO]Since the difference between baselines and our method is promi  \n812 nent, we believe that one experiment on each setting is an enough certificate to show the   \n813 effectiveness of our method.   \n814 Guidelines:   \n815 \u2022 The answer NA means that the paper does not include experiments.   \n816 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n817 dence intervals, or statistical significance tests, at least for the experiments that support   \n818 the main claims of the paper.   \n819 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n820 example, train/test split, initialization, random drawing of some parameter, or overall   \n821 run with given experimental conditions).   \n822 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n823 call to a library function, bootstrap, etc.)   \n824 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n825 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n826 of the mean.   \n827 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n828 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n829 of Normality of errors is not verified.   \n830 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n831 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n832 error rates).   \n833 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n834 they were calculated and reference the corresponding figures or tables in the text.   \n835 8. Experiments Compute Resources   \n836 Question: For each experiment, does the paper provide sufficient information on the com  \n837 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n838 the experiments?   \n839 Answer: [TODO][Yes]   \n840 Justification: [TODO]See Appendix C.   \n841 Guidelines:   \n842 \u2022 The answer NA means that the paper does not include experiments.   \n843 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n844 or cloud provider, including relevant memory and storage.   \n845 \u2022 The paper should provide the amount of compute required for each of the individual   \n846 experimental runs as well as estimate the total compute.   \n847 \u2022 The paper should disclose whether the full research project required more compute   \n848 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n849 didn\u2019t make it into the paper).   \n850 9. Code Of Ethics   \n851 Question: Does the research conducted in the paper conform, in every respect, with the   \n852 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n853 Answer: [TODO][Yes]   \n854 Justification: [TODO]   \n855 Guidelines:   \n856 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n857 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n858 deviation from the Code of Ethics.   \n859 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n860 eration due to laws or regulations in their jurisdiction).   \n861 10. Broader Impacts   \n862 Question: Does the paper discuss both potential positive societal impacts and negative   \n863 societal impacts of the work performed?   \n864 Answer: [TODO][Yes]   \n865 Justification: [TODO]The accelaration of market equilibrium computation is a positive   \n866 social impact.   \n867 Guidelines:   \n868 \u2022 The answer NA means that there is no societal impact of the work performed.   \n869 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n870 impact or why the paper does not address societal impact.   \n871 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n872 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n873 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n874 groups), privacy considerations, and security considerations. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [TODO][NA] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: [TODO] ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [TODO][NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: [TODO] ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 26}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to ", "page_idx": 27}, {"type": "text", "text": "the asset\u2019s creators.   \n13. New Assets Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [TODO][NA] Justification: [TODO] Guidelines: \u2022 The answer NA means that the paper does not release new assets. \u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. \u2022 The paper should discuss whether and how consent was obtained from people whose asset is used. \u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.   \n14. Crowdsourcing and Research with Human Subjects Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [TODO][NA] Justification: [TODO] Guidelines: \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.   \n15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 27}, {"type": "text", "text": "927   \n928   \n929   \n930   \n931   \n932   \n933   \n934   \n935   \n936   \n937   \n938   \n939   \n940   \n941   \n942   \n943   \n944   \n945   \n946   \n947   \n948   \n949   \n950   \n951   \n952   \n953   \n954   \n955   \n956   \n957   \n958   \n959   \n960   \n961   \n962   \n963   \n964   \n965   \n966   \n967   \n968   \n969   \n970   \n971   \n972   \n973   \n974   \n975   \n976 ", "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [TODO][NA] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: [TODO] ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]