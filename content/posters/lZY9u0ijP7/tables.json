[{"figure_path": "lZY9u0ijP7/tables/tables_6_1.jpg", "caption": "Table 1: Simulated EWIF under the assumption that the acceptance distribution is a Bernoulli distribution. BASE and SMALL refer to FLAN-T5-BASE and FLAN-T5-SMALL. In the simulation, speculative sampling with horizontal cascade exceeded the performance of the vanilla speculative decoding on both CNN Dailymail [16] and WMT EnDe [2] datasets.", "description": "This table shows the simulated Expected Walltime Improvement Factor (EWIF) under the assumption that the acceptance distribution follows a Bernoulli distribution.  It compares the EWIF of speculative decoding with and without a horizontal cascade using different FLAN-T5 models (BASE and SMALL). The results demonstrate that the horizontal cascade improves the EWIF in both CNN Dailymail and WMT EnDe datasets.", "section": "4 Analysis"}, {"figure_path": "lZY9u0ijP7/tables/tables_7_1.jpg", "caption": "Table 2: The experimental results on FLAN-T5. Speedup (MS) is the standardized walltime improvement with the assumption that the latency of each run of a model is its number of parameters (model size). Speedup (PW) is the SWI with the assumption that the latency of each run of a model is the time cost data reported from previous work [14].", "description": "This table shows the speedup achieved by different methods (autoregressive, speculative decoding, and Cascade Speculative Drafting) on two datasets (GSM8K and MMLU) using FLAN-T5 models of different sizes.  Speedup is calculated in two ways:  Speedup (MS) assumes model latency is proportional to the number of parameters, while Speedup (PW) uses latency data from prior work.  The table demonstrates that Cascade Speculative Drafting consistently outperforms other methods.", "section": "5.2 Experimental Results"}, {"figure_path": "lZY9u0ijP7/tables/tables_8_1.jpg", "caption": "Table 3: The experimental results on Vicuna-7B.", "description": "This table presents the experimental results on the Vicuna-7B model.  It compares the walltime (tokens per second) achieved by different algorithms on two datasets: GSM8K and MMLU. The algorithms include autoregressive decoding, speculative decoding (S Decoding), Cascade Speculative Drafting (CS Drafting), Medusa, and CS Drafting combined with tree attention. The results show that CS Drafting with tree attention achieves the best performance, indicating the effectiveness of the proposed approach in improving language model inference speed.", "section": "5.2 Experimental Results"}, {"figure_path": "lZY9u0ijP7/tables/tables_8_2.jpg", "caption": "Table 4: Results on GSM8K with Vicuna-7B under different generation length limits.", "description": "This table presents the results of experiments conducted on the GSM8K dataset using the Vicuna-7B model.  The experiments varied the generation length limits, and the table shows the resulting wall-time (tokens per second) for each limit.  This demonstrates the performance of the model under different conditions.", "section": "5 Experiments"}, {"figure_path": "lZY9u0ijP7/tables/tables_13_1.jpg", "caption": "Table 2: The experimental results on FLAN-T5. Speedup (MS) is the standardized walltime improvement with the assumption that the latency of each run of a model is its number of parameters (model size). Speedup (PW) is the SWI with the assumption that the latency of each run of a model is the time cost data reported from previous work [14].", "description": "This table presents the experimental results of the Cascade Speculative Drafting (CS Drafting) algorithm on the FLAN-T5 model for two datasets: GSM8K and MMLU.  It compares the speedup achieved by CS Drafting against autoregressive decoding and standard speculative decoding.  The speedup is calculated using two different assumptions for model latency:  one based on model size and another based on previously reported time cost data. The table also shows the hyperparameters used for each configuration of CS Drafting.", "section": "5.2 Experimental Results"}]