{"references": [{"fullname_first_author": "Kenneth Li", "paper_title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model", "publication_date": "2023", "reason": "This paper introduces a method for improving language model truthfulness by intervening on their internal representations, providing a significant contribution to the field of language model alignment and serving as a direct comparison for the LOFIT method."}, {"fullname_first_author": "Edward J. Hu", "paper_title": "LoRA: Low-Rank Adaptation of Large Language Models", "publication_date": "2022", "reason": "This paper presents LoRA, a parameter-efficient fine-tuning method for LLMs that is widely used and serves as a baseline for comparison against LOFIT in terms of efficiency."}, {"fullname_first_author": "Muling Wu", "paper_title": "Advancing Parameter Efficiency in Fine-tuning via Representation Editing", "publication_date": "2024", "reason": "This paper introduces RED, another parameter-efficient fine-tuning method that shares similarities with LOFIT, enabling a comparison of techniques for modifying LLM representations during adaptation."}, {"fullname_first_author": "Zhengxuan Wu", "paper_title": "ReFT: Representation Finetuning for Language Models", "publication_date": "2024", "reason": "This paper introduces ReFT, a parameter-efficient fine-tuning method that focuses on directly modifying LLM representations, providing another relevant baseline for comparison against LOFIT."}, {"fullname_first_author": "Callum McDougall", "paper_title": "Copy Suppression: Comprehensively Understanding an Attention Head", "publication_date": "2023", "reason": "This paper explores the interpretability of attention heads in LLMs, providing further context for understanding the LOFIT approach that focuses on modifying a subset of these heads"}]}