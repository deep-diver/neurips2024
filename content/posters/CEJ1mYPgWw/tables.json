[{"figure_path": "CEJ1mYPgWw/tables/tables_6_1.jpg", "caption": "Table 1: Performance of different GPT-4/4V settings in all tasks. Underline denotes statistical significance with p < 0.05 when comparing GPT-4 VoT against all baselines using two-sample z-test, while p < 0.16 is observed compared with GPT-4 CoT in natural language navigation task.", "description": "This table presents the performance of four different GPT model settings across three spatial reasoning tasks: visual navigation (route planning and next-step prediction), visual tiling, and natural language navigation.  The settings are: GPT-4 with Chain-of-Thought prompting (CoT), GPT-4 without visualization, GPT-4 Vision with CoT, and GPT-4 with Visualization-of-Thought prompting (VoT).  The underlined values indicate statistically significant improvements of VoT compared to other methods.", "section": "4.4 Results"}, {"figure_path": "CEJ1mYPgWw/tables/tables_7_1.jpg", "caption": "Table 2: Spatial visualization/understanding evaluation in visual navigation and visual tiling task.", "description": "This table presents the results of evaluating the spatial visualization and understanding capabilities of LLMs in visual navigation and visual tiling tasks.  It shows the compliance (how well the LLM's visualization followed spatial constraints) and accuracy of the spatial visualizations generated, as well as the accuracy of the spatial understanding demonstrated when the visualizations were accurate.  Higher numbers indicate better performance.", "section": "5 Analysis"}, {"figure_path": "CEJ1mYPgWw/tables/tables_8_1.jpg", "caption": "Table 3: Performance of VoT in GPT-3.5 and LLAMA3 models. Underline denotes statistical significance with p < 0.05 compared to corresponding CoT baseline using two-sample z-test.", "description": "This table presents the performance of Visualization-of-Thought (VoT) prompting compared to the conventional Chain-of-Thought (CoT) prompting method across three different language models: GPT-3.5, LLAMA3-8B, and LLAMA3-70B.  The results are shown for three spatial reasoning tasks: route planning, next-step prediction in visual navigation, visual tiling. The underlined values indicate statistically significant improvements achieved by VoT prompting compared to CoT prompting (p<0.05).  The table demonstrates that VoT prompting generally leads to better performance on the spatial reasoning tasks, especially with larger and more powerful language models.", "section": "4.4 Results"}, {"figure_path": "CEJ1mYPgWw/tables/tables_15_1.jpg", "caption": "Table 1: Performance of different GPT-4/4V settings in all tasks. Underline denotes statistical significance with p < 0.05 when comparing GPT-4 VoT against all baselines using two-sample z-test, while p < 0.16 is observed compared with GPT-4 CoT in natural language navigation task.", "description": "This table presents the performance comparison of different GPT model settings (GPT-4 CoT, GPT-4 w/o Viz, GPT-4V CoT, and GPT-4 VoT) across three spatial reasoning tasks: Route Planning, Next Step Prediction, and Visual Tiling.  The results show the completing rate and success rate for Route Planning, the prediction accuracy for Next Step Prediction, and the accuracy for Visual Tiling.  Statistical significance (p<0.05) is indicated by underlines, highlighting the superior performance of GPT-4 VoT compared to other methods, particularly significant when compared to GPT-4 CoT in the natural language navigation task.", "section": "4.4 Results"}, {"figure_path": "CEJ1mYPgWw/tables/tables_15_2.jpg", "caption": "Table 5: Details of visual tiling dataset. Some QA instances are discarded when multiple solutions exist and all answers are correct.", "description": "This table presents the details of the visual tiling dataset used in the paper's experiments. It shows the number of configurations and QA instances for different numbers of masked polyomino pieces (2 or 3).  The total number of QA instances is 796.  Note that some instances were discarded because there were multiple correct solutions or all solutions were correct, leading to a smaller number than a simple sum of configurations might suggest.", "section": "4.2 Dataset"}, {"figure_path": "CEJ1mYPgWw/tables/tables_19_1.jpg", "caption": "Table 1: Performance of different GPT-4/4V settings in all tasks. Underline denotes statistical significance with p < 0.05 when comparing GPT-4 VoT against all baselines using two-sample z-test, while p < 0.16 is observed compared with GPT-4 CoT in natural language navigation task.", "description": "This table presents the performance comparison of different GPT models (GPT-4, GPT-4V) across three spatial reasoning tasks: Route Planning, Next Step Prediction, and Visual Tiling.  It also includes results for a Natural Language Navigation task.  The models are evaluated under four different prompting approaches: GPT-4 CoT (Chain of Thought), GPT-4 w/o Viz (Chain of Thought without visualization), GPT-4V CoT (multimodal model with Chain of Thought), and GPT-4 VoT (Visualization-of-Thought). The table highlights the statistical significance of the VoT approach compared to other methods, showing superior performance in most tasks.  The metrics used are Completing Rate and Success Rate for Route Planning, and Accuracy for all other tasks. ", "section": "4.4 Results"}]