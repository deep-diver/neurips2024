[{"figure_path": "gCCMzedgbo/figures/figures_1_1.jpg", "caption": "Figure 1: TrAct learns the first layer of a vision model but with the training dynamics of an embedding layer. We illustrate this in an example with two 4-dimensional inputs x, a weight matrix W of size 4 \u00d7 3, and resulting pre-activations z of size 2 \u00d7 3. For language models (left), the input x is two tokens from a dictionary of size 4. For vision models (center + right), the input x is two patches of the image, each totaling 4 pixels. During backpropagation, we obtain the gradient wrt. our pre-activations \u2207z, from which the gradient and update to the weights W is computed (AW). The resulting update to the pre-activations Az equals x AW. For language models (left), Az = \u2207z, i.e., the training dynamics of the embeddings layer corresponds to updating the embeddings directly wrt. the gradient. Specifically, the update in a language model, for a token identifier i, is WiWi-n. VzL(z) where z = W\u2081 is the activation of the first layer and at the same time the ith row of the embedding (weight) matrix W. Equivalently, we can write z \u2190 z \u2212 \u03b7 \u00b7 \u2207zL(z). However, in vision models (center), the update Az strongly deviates from the respective gradients Vz. TrAct corrects for this by adjusting AW via a corrective term (x. x + \u00b7 I)\u00af\u00b9 (orange box), such that the update to z closely approximates Vz.", "description": "This figure illustrates the core idea of TrAct by comparing the training dynamics of the first layer in language models and vision models. In language models, the embedding vectors are updated directly based on the gradients of pre-activations.  However, in vision models, the weight updates are directly proportional to pixel values, leading to unequal impacts from images with varying contrasts. TrAct addresses this by modifying the gradient descent process to mimic the behavior of language model embedding layers, allowing the first-layer activations to be trained directly.", "section": "Method"}, {"figure_path": "gCCMzedgbo/figures/figures_5_1.jpg", "caption": "Figure 3: Training a ResNet-18 on CIFAR-10. We train for {100, 200, 400, 800} epochs using a cosine learning rate schedule and with SGD (left) and Adam (right). Learning rates have been selected as optimal for each baseline. Averaged over 5 seeds. TrAct (solid lines) consistently outperforms the baselines (dashed)-in many cases already with a quarter of the number of the epochs of the baseline.", "description": "The figure shows the training curves of ResNet-18 on CIFAR-10 dataset using SGD and Adam optimizers with and without TrAct.  Four different training epochs (100, 200, 400, 800) are tested.  The results are averaged over 5 different seeds.  The solid lines represent the performance with TrAct while the dashed lines are without TrAct.  The results demonstrate that TrAct consistently outperforms the baseline methods, often achieving comparable or better results in a significantly shorter number of training epochs.", "section": "4.1 CIFAR-10"}, {"figure_path": "gCCMzedgbo/figures/figures_5_2.jpg", "caption": "Figure 3: Training a ResNet-18 on CIFAR-10. We train for {100, 200, 400, 800} epochs using a cosine learning rate schedule and with SGD (left) and Adam (right). Learning rates have been selected as optimal for each baseline. Averaged over 5 seeds. TrAct (solid lines) consistently outperforms the baselines (dashed)-in many cases already with a quarter of the number of the epochs of the baseline.", "description": "This figure shows the training results for a ResNet-18 model trained on the CIFAR-10 dataset using both SGD and Adam optimizers.  The experiment compares the performance of the proposed TrAct method against standard training methods for different numbers of training epochs (100, 200, 400, 800). The results demonstrate that TrAct consistently outperforms standard training, often achieving comparable or better accuracy with significantly fewer epochs.", "section": "4.1 CIFAR-10"}, {"figure_path": "gCCMzedgbo/figures/figures_7_1.jpg", "caption": "Figure 5: Test accuracy of ResNet-50 trained on ImageNet for {30, 60, 90} epochs. When training for 60 epochs with TrAct, we achieve comparable accuracy to standard training for 90 epochs, showing a 1.5\u00d7 speedup. Plots for ResNet-18/34 are in the SM.", "description": "The figure shows the training curves for ResNet-50 on ImageNet for different numbers of training epochs (30, 60, 90).  The curves compare the standard training approach with the TrAct method for different values of the hyperparameter \u03bb.  It demonstrates that TrAct achieves comparable accuracy to standard training using fewer epochs which translates to a significant speedup (1.5x in this case) in training time.", "section": "4.3 ImageNet"}, {"figure_path": "gCCMzedgbo/figures/figures_8_1.jpg", "caption": "Figure 6: Effect of \u03bb for training a ViT on CIFAR-10. Training for 200 ep., setup as Fig. 4, avg. over 5 seeds.", "description": "This figure shows the impact of the hyperparameter \u03bb on the test accuracy of a Vision Transformer (ViT) model trained on the CIFAR-10 dataset.  The x-axis represents different values of \u03bb, while the y-axis shows the test accuracy.  The orange line shows results for the TrAct method, and the blue line shows results for vanilla training.  The shaded region around each line indicates the standard deviation over five different training runs. The plot demonstrates that TrAct is relatively robust to changes in \u03bb, offering consistent improvement over vanilla training across different \u03bb values.", "section": "4.4 Effect of \u03bb"}, {"figure_path": "gCCMzedgbo/figures/figures_8_2.jpg", "caption": "Figure 7: Ablation Study: training a ViT on CIFAR-10, including patch normalization (black, dashed) and DualPatchNorm (cyan, dashed). Setups as in Figure 4, averaged over 5 seeds.", "description": "This figure displays the results of an ablation study comparing TrAct's performance to patch-wise layer normalization and DualPatchNorm on a Vision Transformer (ViT) model trained on the CIFAR-10 dataset.  The plot shows test accuracy over 800 epochs.  The goal is to demonstrate that TrAct's performance advantage is not simply due to the effect of normalization techniques on the input data.  The various lines represent different training methods, including TrAct with different lambda values, standard training (vanilla), patch-wise normalization, and DualPatchNorm.  The plot shows TrAct consistently outperforms the other methods.", "section": "4.5 Ablation Study"}, {"figure_path": "gCCMzedgbo/figures/figures_9_1.jpg", "caption": "Figure 8: Ablation Study: training a ViT on CIFAR-10 without data standardization and with input value ranges of [0, 1] vs. [0, 255]. Setups as in Figure 4, 200 epochs, and avg. over 5 seeds. All other experiments in this work are trained with data standardization.", "description": "This figure displays the test accuracy results for training a Vision Transformer (ViT) on the CIFAR-10 dataset with and without data standardization. It compares the performance of vanilla training and TrAct (Training Activations) under two different input value ranges: [0, 1] (normalized) and [0, 255] (unnormalized). The experiment shows that TrAct is more robust to the lack of standardization, performing better with the wider [0, 255] range than with the normalized [0,1] range.", "section": "4.5 Ablation Study"}, {"figure_path": "gCCMzedgbo/figures/figures_9_2.jpg", "caption": "Figure 3: Training a ResNet-18 on CIFAR-10. We train for {100, 200, 400, 800} epochs using a cosine learning rate schedule and with SGD (left) and Adam (right). Learning rates have been selected as optimal for each baseline. Averaged over 5 seeds. TrAct (solid lines) consistently outperforms the baselines (dashed)-in many cases already with a quarter of the number of the epochs of the baseline.", "description": "This figure displays the results of training a ResNet-18 model on the CIFAR-10 dataset using both SGD and Adam optimizers.  The training was done for 100, 200, 400, and 800 epochs, each using a cosine learning rate schedule.  The figure compares the performance of the baseline training methods against the TrAct method, demonstrating a consistent improvement in test accuracy by TrAct. Notably, TrAct achieves comparable or superior results with far fewer training epochs, highlighting its efficiency.", "section": "4.1 CIFAR-10"}, {"figure_path": "gCCMzedgbo/figures/figures_14_1.jpg", "caption": "Figure 3: Training a ResNet-18 on CIFAR-10. We train for {100, 200, 400, 800} epochs using a cosine learning rate schedule and with SGD (left) and Adam (right). Learning rates have been selected as optimal for each baseline. Averaged over 5 seeds. TrAct (solid lines) consistently outperforms the baselines (dashed)-in many cases already with a quarter of the number of the epochs of the baseline.", "description": "This figure displays the training results for a ResNet-18 model on the CIFAR-10 dataset, using both SGD and Adam optimizers with a cosine learning rate schedule.  The experiment is run for 100, 200, 400, and 800 epochs.  The results show that TrAct consistently outperforms the baseline models, often achieving comparable or better accuracy with significantly fewer epochs.", "section": "4.1 CIFAR-10"}, {"figure_path": "gCCMzedgbo/figures/figures_14_2.jpg", "caption": "Figure 5: Test accuracy of ResNet-50 trained on ImageNet for {30, 60, 90} epochs. When training for 60 epochs with TrAct, we achieve comparable accuracy to standard training for 90 epochs, showing a 1.5\u00d7 speedup. Plots for ResNet-18/34 are in the SM.", "description": "The figure shows the test accuracy (top-1 and top-5) for ResNet-50 trained on the ImageNet dataset for 30, 60, and 90 epochs using both standard training and TrAct.  It demonstrates that TrAct achieves comparable accuracy with 60 epochs to that of standard training with 90 epochs, thus exhibiting a 1.5x speed-up in training.", "section": "4.3 ImageNet"}, {"figure_path": "gCCMzedgbo/figures/figures_14_3.jpg", "caption": "Figure 5: Test accuracy of ResNet-50 trained on ImageNet for {30, 60, 90} epochs. When training for 60 epochs with TrAct, we achieve comparable accuracy to standard training for 90 epochs, showing a 1.5\u00d7 speedup. Plots for ResNet-18/34 are in the SM.", "description": "The figure shows the training curves for ResNet-50 on ImageNet using different training epochs (30, 60, and 90).  It compares the standard training approach with the TrAct method (using different lambda values). The key observation is that training with TrAct for 60 epochs achieves similar accuracy to the standard training with 90 epochs, demonstrating a significant speedup (1.5x).", "section": "4.3 ImageNet"}]