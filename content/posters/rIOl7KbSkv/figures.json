[{"figure_path": "rIOl7KbSkv/figures/figures_4_1.jpg", "caption": "Figure 1: Piggyback spoofing of robust watermarks. (a) We can insert a large number of toxic tokens in robustly watermarked text without changing the watermark detection result, resulting in text that is likely to be identified as toxic. (b) We can use GPT4 to automatically modify watermarked text, making it appear inaccurate while retaining fluency.", "description": "This figure demonstrates the effectiveness of piggyback spoofing attacks against robust watermarks.  The left panel (a) shows that inserting toxic words into watermarked text doesn't prevent the watermark from being detected, making the output harmful.  The right panel (b) shows that even generating fluent, inaccurate content using GPT4 maintains watermark detection, illustrating the vulnerability of robustness to spoofing.", "section": "4 Attacking Robust Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_6_1.jpg", "caption": "Figure 2: Spoofing attack based on watermark stealing [14] and watermark-removal attacks on KGW watermark and LLAMA-2-7B model with different number of watermark keys n. Higher z-score reflects more confidence in watermarking and lower perplexity indicates better sentence quality. The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure shows the results of spoofing attacks based on watermark stealing and watermark removal attacks using different numbers of watermark keys.  The x-axis represents the number of keys used. The y-axis shows three metrics: Z-score (confidence of watermark detection), attack success rate (ASR, percentage of successful attacks), and perplexity (PPL, measuring text quality).  The figure demonstrates a trade-off: increasing the number of keys improves resistance to watermark stealing (lower ASR in the spoofing attack) but makes the watermark more vulnerable to removal attacks (higher ASR in the removal attacks and lower Z-score). The perplexity generally improves with more keys.", "section": "Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_7_1.jpg", "caption": "Figure 3: Attacks exploiting detection APIs on LLAMA-2-7B model.", "description": "This figure shows the results of watermark removal and spoofing attacks that exploit watermark detection APIs.  Three watermarking schemes (KGW, Unigram, Exp) are tested, with results presented as boxplots showing Z-scores and perplexity. (a) shows the Z-scores/P-values for watermark removal; successful attacks lower the score. (b) presents the perplexity of the modified text, indicating the quality of the text after watermark removal.  (c) depicts the Z-scores/P-values for spoofing attacks; successful attacks increase the score. The results demonstrate that the attacks are effective in manipulating the watermark detection scores while maintaining reasonable text quality.", "section": "6 Attacking Watermark Detection APIs"}, {"figure_path": "rIOl7KbSkv/figures/figures_8_1.jpg", "caption": "Figure 4: Evaluation of DP detection on KGW watermark and LLAMA-2-7B model. (a). Spoofing attack success rate (ASR) and detection accuracy (ACC) without and with DP watermark detection under different noise parameters. (b). Z-scores of original text without attack, spoofing attack without DP, and spoofing attacks with DP. We use the best \u03c3 = 4 from (a).", "description": "This figure shows the results of evaluating a differential privacy (DP) defense against spoofing attacks on a KGW watermarked LLAMA-2-7B model.  The left panel (a) displays a line graph comparing the spoofing attack success rate (ASR) and detection accuracy (ACC) with varying noise parameters (\u03c3).  The right panel (b) presents box plots illustrating the Z-scores for three scenarios: original text without attack, spoofing attack without DP, and spoofing attack with DP (using the optimal noise parameter \u03c3=4). The results demonstrate that the DP defense effectively mitigates spoofing attacks with minimal impact on detection accuracy.", "section": "Defending Detection with Differential Privacy"}, {"figure_path": "rIOl7KbSkv/figures/figures_16_1.jpg", "caption": "Figure 5: The relationship between s/l and z. The data points are evaluated on Unigram using LLAMA-2-7B and 500 samples from OpenGen dataset.", "description": "This figure validates Theorem 1 presented in the paper, which provides a bound on the maximum number of tokens that can be inserted or edited into a watermarked sentence to guarantee that the expected z-score of the edited text is above a threshold T. The x-axis represents the detection z-score (z) of the original watermarked text, and the y-axis represents the ratio of the number of inserted tokens (s) to the length of the original sentence (l). The green points show data points where the condition in Theorem 1 holds true, while red points indicate where it does not. The blue line represents the theoretical bound from Theorem 1.  The percentage of data points that satisfy the theorem (85.78%) and those that do not (14.22%) are shown.", "section": "E Validation of Theorem 1"}, {"figure_path": "rIOl7KbSkv/figures/figures_18_1.jpg", "caption": "Figure 1: Piggyback spoofing of robust watermarks. (a) We can insert a large number of toxic tokens in robustly watermarked text without changing the watermark detection result, resulting in text that is likely to be identified as toxic. (b) We can use GPT4 to automatically modify watermarked text, making it appear inaccurate while retaining fluency.", "description": "This figure shows the results of two different piggyback spoofing attacks on robust watermarks. The first attack involves inserting toxic tokens into the watermarked text, while the second involves using GPT-4 to modify the text in a way that makes it inaccurate but still fluent.  Both attacks demonstrate the vulnerability of robust watermarks to spoofing attacks, even when the watermark itself remains undetectable.  The figure highlights a key trade-off in watermarking design: Robustness to editing attacks can make the system more vulnerable to spoofing.", "section": "4 Attacking Robust Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_18_2.jpg", "caption": "Figure 1: Piggyback spoofing of robust watermarks. (a) We can insert a large number of toxic tokens in robustly watermarked text without changing the watermark detection result, resulting in text that is likely to be identified as toxic. (b) We can use GPT4 to automatically modify watermarked text, making it appear inaccurate while retaining fluency.", "description": "This figure shows the results of two piggyback spoofing attacks on robust watermarks.  The first attack involves inserting toxic tokens into watermarked text. The results show that a significant number of toxic tokens can be inserted without affecting the watermark detection, making the text toxic. The second attack uses GPT-4 to modify the watermarked text to make it inaccurate while maintaining fluency. The results show that this is also possible, with a high success rate. These findings highlight the inherent vulnerability of robust watermarks to spoofing attacks, a critical design trade-off.", "section": "4 Attacking Robust Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_18_3.jpg", "caption": "Figure 1: Piggyback spoofing of robust watermarks. (a) We can insert a large number of toxic tokens in robustly watermarked text without changing the watermark detection result, resulting in text that is likely to be identified as toxic. (b) We can use GPT4 to automatically modify watermarked text, making it appear inaccurate while retaining fluency.", "description": "This figure demonstrates the effectiveness of piggyback spoofing attacks against robust watermarks.  Subfigure (a) shows that a substantial number of toxic tokens can be inserted into watermarked text without affecting the watermark detection, leading to potentially harmful or inaccurate content.  Subfigure (b) illustrates how fluent but inaccurate text can be generated by editing a watermarked sentence, again without impacting the watermark detection. This highlights the vulnerability of robust watermarks to manipulation.", "section": "4 Attacking Robust Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_19_1.jpg", "caption": "Figure 1: Piggyback spoofing of robust watermarks. (a) We can insert a large number of toxic tokens in robustly watermarked text without changing the watermark detection result, resulting in text that is likely to be identified as toxic. (b) We can use GPT4 to automatically modify watermarked text, making it appear inaccurate while retaining fluency.", "description": "This figure shows the results of two different piggyback spoofing attacks against robust watermarks.  The first attack involves inserting toxic tokens into the watermarked text. The results show that a significant number of toxic tokens can be inserted without affecting the watermark detection. The second attack uses GPT-4 to modify the watermarked text to make it inaccurate while maintaining fluency. This also successfully bypasses watermark detection. The figure highlights the tradeoff between robustness and vulnerability to spoofing attacks inherent in robust watermarking schemes.", "section": "4 Attacking Robust Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_21_1.jpg", "caption": "Figure 10: Watermark stealing attack [14] on KGW watermark and LLAMA-2-7B model using three keys with different numbers of attacker obtained tokens Q (in million). The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure shows the results of a watermark stealing attack on the KGW watermark using the LLAMA-2-7B language model with three keys.  The x-axis represents the number of tokens (in millions) obtained by the attacker, and the y-axis shows both the Z-score (a measure of watermark confidence) and the attack success rate (ASR). The red dashed line indicates the detection threshold with a false positive rate (FPR) of 1e-3.  As the number of tokens obtained by the attacker increases, the attack success rate also increases, eventually exceeding the detection threshold. This demonstrates the vulnerability of the system to watermark stealing attacks even with multiple keys, if the attacker can obtain a sufficient number of watermarked tokens.", "section": "5 Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_21_2.jpg", "caption": "Figure 2: Spoofing attack based on watermark stealing [14] and watermark-removal attacks on KGW watermark and LLAMA-2-7B model with different number of watermark keys n. Higher z-score reflects more confidence in watermarking and lower perplexity indicates better sentence quality. The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure shows the results of spoofing attacks based on watermark stealing and watermark removal attacks using the KGW watermark on the LLAMA-2-7B language model.  The x-axis represents the number of watermark keys (n) used, ranging from 1 to 17.  The y-axis displays three key metrics: Z-score (reflecting watermark detection confidence), attack success rate (ASR), and perplexity (PPL, indicating text quality).  The plots demonstrate a trade-off: increasing the number of keys improves resistance to watermark stealing (lower ASR in the spoofing attack) but simultaneously increases vulnerability to watermark removal attacks (higher ASR in the watermark removal attack and slightly higher PPL).", "section": "Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_22_1.jpg", "caption": "Figure 2: Spoofing attack based on watermark stealing [14] and watermark-removal attacks on KGW watermark and LLAMA-2-7B model with different number of watermark keys n. Higher z-score reflects more confidence in watermarking and lower perplexity indicates better sentence quality. The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure shows the results of spoofing attacks based on watermark stealing and watermark removal attacks. The attacks target the KGW watermark on the LLAMA-2-7B language model and vary the number of watermark keys used (n).  Higher z-scores indicate a higher confidence in the watermark's presence, while lower perplexity scores suggest better sentence quality. The success rate of the attacks is determined using a false positive rate (FPR) threshold of 1e-3.  The figure demonstrates the trade-off between watermark robustness and vulnerability to attacks when employing multiple keys.", "section": "Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_22_2.jpg", "caption": "Figure 2: Spoofing attack based on watermark stealing [14] and watermark-removal attacks on KGW watermark and LLAMA-2-7B model with different number of watermark keys n. Higher z-score reflects more confidence in watermarking and lower perplexity indicates better sentence quality. The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure demonstrates the trade-off between watermark stealing resistance and watermark removal vulnerability when using multiple watermark keys.  The left panel shows that increasing the number of keys (n) significantly reduces the success rate of watermark stealing attacks. However, the middle panel reveals that increasing the number of keys makes the system increasingly vulnerable to watermark removal attacks, as the detection scores are drastically reduced. The right panel shows the perplexity of the generated text, indicating that using more keys generally leads to better sentence quality. This highlights a crucial design challenge:  enhancing security against one type of attack can unintentionally increase vulnerability to another.", "section": "5 Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_22_3.jpg", "caption": "Figure 2: Spoofing attack based on watermark stealing [14] and watermark-removal attacks on KGW watermark and LLAMA-2-7B model with different number of watermark keys n. Higher z-score reflects more confidence in watermarking and lower perplexity indicates better sentence quality. The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure shows the results of spoofing and watermark removal attacks using the KGW watermark on the LLAMA-2-7B language model with varying numbers of watermark keys (n).  The higher the z-score, the higher the confidence in the presence of a watermark, while lower perplexity values indicate better-quality text.  The attack success rate is determined by the threshold where the false positive rate is 1e-3. The figure demonstrates that increasing the number of keys improves the system's resistance to watermark stealing, but simultaneously increases its vulnerability to watermark removal.", "section": "Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_22_4.jpg", "caption": "Figure 2: Spoofing attack based on watermark stealing [14] and watermark-removal attacks on KGW watermark and LLAMA-2-7B model with different number of watermark keys n. Higher z-score reflects more confidence in watermarking and lower perplexity indicates better sentence quality. The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure shows the results of spoofing attacks based on watermark stealing and watermark removal attacks on the KGW watermark using the LLAMA-2-7B model with varying numbers of watermark keys.  Higher z-scores indicate higher confidence in the watermark's presence, and lower perplexity values suggest higher sentence quality. The attack success rates are calculated using a threshold with a false positive rate (FPR) of 1e-3.", "section": "5 Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_23_1.jpg", "caption": "Figure 3: Attacks exploiting detection APIs on LLAMA-2-7B model.", "description": "This figure shows the results of watermark removal and spoofing attacks that exploit publicly available watermark detection APIs.  The leftmost plot shows the Z-score (or P-value) of watermark removal attacks, demonstrating that the detection confidence is significantly reduced, while maintaining reasonable text quality. The center plot depicts the perplexity of the resulting text, indicating that the quality remains high despite the watermark removal. The rightmost plot showcases the results of the spoofing attacks, where the detection confidence is very high, confirming successful spoofing, despite the generated text not originating from the target watermarked LLM.", "section": "6 Attacking Watermark Detection APIs"}, {"figure_path": "rIOl7KbSkv/figures/figures_23_2.jpg", "caption": "Figure 4: Evaluation of DP detection on KGW watermark and LLAMA-2-7B model. (a). Spoofing attack success rate (ASR) and detection accuracy (ACC) without and with DP watermark detection under different noise parameters. (b). Z-scores of original text without attack, spoofing attack without DP, and spoofing attacks with DP. We use the best \u03c3 = 4 from (a).", "description": "This figure shows the results of evaluating the effectiveness of a differential privacy (DP) defense against spoofing attacks on a KGW watermark using the LLAMA-2-7B language model.  Part (a) presents a comparison of the spoofing attack success rate (ASR) and detection accuracy (ACC) with and without the DP defense, illustrating how different noise parameters (\u03c3) affect performance.  Part (b) visually represents the Z-scores (a measure of watermark detection confidence) for original text, spoofing attacks without DP, and spoofing attacks with the DP defense (using the optimal noise parameter, \u03c3=4, determined in part (a)).  The figure demonstrates the trade-off between the DP defense's ability to mitigate spoofing attacks and its impact on detection accuracy.", "section": "Defending Detection with Differential Privacy"}, {"figure_path": "rIOl7KbSkv/figures/figures_24_1.jpg", "caption": "Figure 4: Evaluation of DP detection on KGW watermark and LLAMA-2-7B model. (a). Spoofing attack success rate (ASR) and detection accuracy (ACC) without and with DP watermark detection under different noise parameters. (b). Z-scores of original text without attack, spoofing attack without DP, and spoofing attacks with DP. We use the best \u03c3 = 4 from (a).", "description": "This figure shows the results of an experiment evaluating the effectiveness of a differential privacy (DP) defense against spoofing attacks on a KGW watermark using the LLAMA-2-7B language model.  The left subplot (a) displays the spoofing attack success rate (ASR) and detection accuracy with different noise parameters (\u03c3), demonstrating how adding noise impacts the ability of attackers to successfully spoof the watermark. The right subplot (b) compares the watermark detection Z-scores (a measure of confidence) with and without the DP defense, illustrating the effectiveness of the defense in mitigating the spoofing attacks. The optimal noise parameter (\u03c3 = 4) was chosen based on the balance between minimizing the attack success rate and maintaining a reasonable detection accuracy.", "section": "Defending Detection with Differential Privacy"}, {"figure_path": "rIOl7KbSkv/figures/figures_24_2.jpg", "caption": "Figure 4: Evaluation of DP detection on KGW watermark and LLAMA-2-7B model. (a). Spoofing attack success rate (ASR) and detection accuracy (ACC) without and with DP watermark detection under different noise parameters. (b). Z-scores of original text without attack, spoofing attack without DP, and spoofing attacks with DP. We use the best \u03c3 = 4 from (a).", "description": "This figure shows the results of evaluating a defense mechanism using differential privacy (DP) against spoofing attacks on a KGW watermark using the LLAMA-2-7B language model.  Panel (a) presents a comparison of spoofing attack success rates (ASR) and detection accuracy (ACC) with and without the DP defense, across various noise levels (\u03c3).  Panel (b) illustrates the Z-scores (watermark confidence) for original text, spoofing attacks without DP, and spoofing attacks with DP (using the optimal noise level, \u03c3 = 4). The results demonstrate the trade-off between detection accuracy and the effectiveness of the DP defense in mitigating spoofing attacks.", "section": "6.3 Defending Detection with Differential Privacy"}, {"figure_path": "rIOl7KbSkv/figures/figures_24_3.jpg", "caption": "Figure 4: Evaluation of DP detection on KGW watermark and LLAMA-2-7B model. (a). Spoofing attack success rate (ASR) and detection accuracy (ACC) without and with DP watermark detection under different noise parameters. (b). Z-scores of original text without attack, spoofing attack without DP, and spoofing attacks with DP. We use the best \u03c3 = 4 from (a).", "description": "This figure shows the results of evaluating a differential privacy (DP) defense against spoofing attacks on a KGW watermark using the LLAMA-2-7B language model.  Panel (a) compares the spoofing attack success rate (ASR) and detection accuracy with and without the DP defense, showing varying levels of Gaussian noise (\u03c3). Panel (b) presents box plots visualizing the Z-scores (watermark confidence) for original text, attacks without DP, and attacks with the optimal DP noise level (\u03c3=4).  The DP defense significantly reduces the ASR while maintaining reasonable detection accuracy.", "section": "Defending Detection with Differential Privacy"}, {"figure_path": "rIOl7KbSkv/figures/figures_25_1.jpg", "caption": "Figure 4: Evaluation of DP detection on KGW watermark and LLAMA-2-7B model. (a). Spoofing attack success rate (ASR) and detection accuracy (ACC) without and with DP watermark detection under different noise parameters. (b). Z-scores of original text without attack, spoofing attack without DP, and spoofing attacks with DP. We use the best \u03c3 = 4 from (a).", "description": "This figure shows the results of evaluating a differential privacy (DP) defense against spoofing attacks on a KGW watermark using the LLAMA-2-7B language model.  Part (a) compares the spoofing attack success rate (ASR) and detection accuracy with different levels of added noise (\u03c3).  It demonstrates that DP effectively reduces the ASR while only slightly impacting detection accuracy. Part (b) visually represents the z-scores (a measure of watermark confidence) for the original text, the text after a spoofing attack without DP, and the text after a spoofing attack with DP. The optimal noise parameter (\u03c3 = 4) was selected based on the results from part (a).", "section": "Defending Detection with Differential Privacy"}, {"figure_path": "rIOl7KbSkv/figures/figures_25_2.jpg", "caption": "Figure 6: Piggyback spoofing of robust watermarks with toxic token insertion strategy on OPT-1.3B.", "description": "This figure presents the results of a piggyback spoofing attack using toxic token insertion on the OPT-1.3B language model.  It shows the maximum portion of toxic tokens that can be inserted into watermarked content without changing the watermark detection result.  The figure also shows the confidence scores from OpenAI's moderation model in identifying the content as violating its usage policy due to the inserted toxic tokens. The results demonstrate that a significant number of toxic tokens can be inserted into content generated by all the robust watermarking schemes, with a median portion higher than 20%.  The median confidence score for content flagged as violating OpenAI's policy is higher than 0.8 across all watermarking schemes, compared to an average confidence score of around 0.01 before the attack.", "section": "4.1 Evaluation"}, {"figure_path": "rIOl7KbSkv/figures/figures_25_3.jpg", "caption": "Figure 11: Spoofing attack based on watermark stealing [25] and watermark-removal attacks on Unigram watermark and LLAMA-2-7B model with different number of watermark keys n.", "description": "This figure shows the results of spoofing attacks based on watermark stealing and watermark removal attacks. The experiments are conducted on the Unigram watermark and LLAMA-2-7B model with different numbers of watermark keys. The x-axis represents the number of watermark keys, and the y-axis represents the attack success rate (ASR), z-score, and perplexity (PPL). The figure shows that using more keys can effectively defend against watermark stealing attacks, but it also makes the system more vulnerable to watermark removal attacks. There is a trade-off between the resistance against watermark stealing and the feasibility of removing watermarks.", "section": "5 Attacking Stealing-Resistant Watermarks"}, {"figure_path": "rIOl7KbSkv/figures/figures_25_4.jpg", "caption": "Figure 2: Spoofing attack based on watermark stealing [14] and watermark-removal attacks on KGW watermark and LLAMA-2-7B model with different number of watermark keys n. Higher z-score reflects more confidence in watermarking and lower perplexity indicates better sentence quality. The attack success rates are based on the threshold with FPR@1e-3.", "description": "This figure shows the results of spoofing and watermark removal attacks on the KGW watermark using the LLAMA-2-7B language model.  The attacks exploit the use of multiple watermark keys.  The figure demonstrates the trade-off between watermark security (resistance to stealing attacks) and vulnerability to removal attacks.  Higher z-scores indicate stronger watermark confidence, while lower perplexity suggests better text quality.  The attack success rates are calculated using a false positive rate (FPR) threshold of 1e-3.", "section": "Attacking Stealing-Resistant Watermarks"}]