[{"figure_path": "rIOl7KbSkv/tables/tables_1_1.jpg", "caption": "Table 1: Examples generated using LLAMA-2-7B with/without the KGW watermark [16] under various attacks. We mark tokens in the green and red lists (see Appendix C). Z-score reflects the detection confidence of the watermark, and perplexity (PPL) measures text quality. (a) In the piggyback spoofing attack, we exploit watermark robustness by generating incorrect content that appears as watermarked (matching the z-score of the watermarked baseline), potentially damaging the reputation of the LLM. Incorrect tokens modified by the attacker are marked in orange and watermarked tokens in blue. (b-c) In watermark-removal attacks, attackers can effectively lower the z-score below the detection threshold while preserving a high sentence quality (low PPL) by exploiting either the (b) use of multiple keys or (c) publicly available watermark detection API.", "description": "This table presents examples of text generated by the LLAMA-2-7B language model, both with and without a watermark. It showcases three different attack scenarios: a piggyback spoofing attack (where incorrect content is generated but still appears watermarked), and two watermark removal attacks (one exploiting multiple keys, and another exploiting a public detection API).  The table highlights the Z-score (detection confidence) and perplexity (text quality) for each example, demonstrating how attacks can compromise the effectiveness of watermarking.", "section": "4 Attacking Robust Watermarks"}, {"figure_path": "rIOl7KbSkv/tables/tables_7_1.jpg", "caption": "Table 1: Examples generated using LLAMA-2-7B with/without the KGW watermark [16] under various attacks. We mark tokens in the green and red lists (see Appendix C). Z-score reflects the detection confidence of the watermark, and perplexity (PPL) measures text quality. (a) In the piggyback spoofing attack, we exploit watermark robustness by generating incorrect content that appears as watermarked (matching the z-score of the watermarked baseline), potentially damaging the reputation of the LLM. Incorrect tokens modified by the attacker are marked in orange and watermarked tokens in blue. (b-c) In watermark-removal attacks, attackers can effectively lower the z-score below the detection threshold while preserving a high sentence quality (low PPL) by exploiting either the (b) use of multiple keys or (c) publicly available watermark detection API.", "description": "This table shows examples of text generated by LLAMA-2-7B with and without a watermark, subjected to different attacks.  It demonstrates the impact of piggyback spoofing and watermark removal attacks on the detection confidence (Z-score) and text quality (perplexity).  The different attack strategies (exploiting robustness, multiple keys, and public APIs) highlight the vulnerabilities of common watermarking design choices.", "section": "4 Attacking Robust Watermarks"}, {"figure_path": "rIOl7KbSkv/tables/tables_23_1.jpg", "caption": "Table 1: Examples generated using LLAMA-2-7B with/without the KGW watermark [16] under various attacks. We mark tokens in the green and red lists (see Appendix C). Z-score reflects the detection confidence of the watermark, and perplexity (PPL) measures text quality. (a) In the piggyback spoofing attack, we exploit watermark robustness by generating incorrect content that appears as watermarked (matching the z-score of the watermarked baseline), potentially damaging the reputation of the LLM. Incorrect tokens modified by the attacker are marked in orange and watermarked tokens in blue. (b-c) In watermark-removal attacks, attackers can effectively lower the z-score below the detection threshold while preserving a high sentence quality (low PPL) by exploiting either the (b) use of multiple keys or (c) publicly available watermark detection API.", "description": "This table presents examples of text generated by LLAMA-2-7B with and without a watermark, subjected to different attacks. It shows the Z-score (watermark detection confidence) and perplexity (text quality) for each example.  Three types of attacks are demonstrated: piggyback spoofing (generating incorrect but seemingly watermarked text), and two types of watermark removal attacks (exploiting multiple keys or a public detection API). The table highlights the trade-offs between watermark robustness, utility, and usability.", "section": "4 Attacking Robust Watermarks"}]