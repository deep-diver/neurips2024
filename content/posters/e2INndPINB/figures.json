[{"figure_path": "e2INndPINB/figures/figures_1_1.jpg", "caption": "Figure 1: The training graphs in (a) and the unseen graph in (b) exhibit different structural characteristics, but a Graph-AE model reconstructs the graph in (b) more accurately than those in (a).", "description": "The figure shows a counter-intuitive result from graph autoencoders.  Three training graphs (a) with similar structures have higher reconstruction errors than an unseen graph (b) with a different structure. This phenomenon, termed \"reconstruction flip,\" challenges the assumption that graph autoencoders reconstruct similar graphs better than dissimilar ones, a core assumption in graph-level anomaly detection methods.", "section": "Analysis of Graph Autoencoders"}, {"figure_path": "e2INndPINB/figures/figures_3_1.jpg", "caption": "Figure 2: Reconstruction flip occurs. When Graph-AEs are trained on graphs sharing a primary pattern of weak strength, the trained Graph-AEs exhibit lower reconstruction errors for graphs with the same pattern but with higher strength (red lines) than those with weaker strength (blue lines).", "description": "This figure shows the results of training graph autoencoders (GAEs) on graphs with similar structures (same primary pattern) but varying strength.  The experiment demonstrates the 'reconstruction flip' phenomenon.  GAEs trained on weak-strength graphs reconstruct strong-strength graphs more accurately (lower reconstruction error) than weak-strength graphs. This contradicts the common assumption in Graph-AE-based anomaly detection that similar graphs should have lower reconstruction errors.", "section": "3 Analysis of Graph Autoencoders"}, {"figure_path": "e2INndPINB/figures/figures_3_2.jpg", "caption": "Figure 3: Reconstruction flip does NOT occur. When Graph-AEs are trained on graphs sharing a primary pattern, the trained Graph-AEs exhibit higher reconstruction errors for graphs with a different pattern (red lines) than those with the same pattern (blue lines).", "description": "This figure shows that when the Graph-AE is trained on graphs with the same primary pattern, it does not exhibit lower reconstruction error for graphs with different patterns.  The reconstruction error for graphs with different patterns is higher than that for graphs with the same pattern. This is opposite to the reconstruction flip phenomenon. ", "section": "3 Analysis of Graph Autoencoders"}, {"figure_path": "e2INndPINB/figures/figures_3_3.jpg", "caption": "Figure 4: A clean-cycle graph and a noisy-cycle graph.", "description": "This figure shows two types of synthetic graphs used in the paper to illustrate the concepts of primary pattern P and pattern strength S.  The \"Clean cycle\" graph is a simple cycle with 10 nodes, representing a strong pattern.  The \"Noisy cycle\" graph is almost a cycle, but has one extra edge, making the cycle pattern weaker. These graphs are used to demonstrate reconstruction flip and its implications for graph anomaly detection.", "section": "3.1 Synthetic graphs"}, {"figure_path": "e2INndPINB/figures/figures_5_1.jpg", "caption": "Figure 5: A case of Graph-AEs (specifically, GAE [22]) having similar mean reconstruction errors for two dissimilar graphs (specifically, G\u2081 has 0.6622 and G\u2082 has 0.6627), while their error distributions differ significantly.", "description": "This figure demonstrates a limitation of using only the mean reconstruction error for anomaly detection.  Two graphs (G1 and G2) are shown, visually distinct. Despite having very similar mean reconstruction errors (0.6622 and 0.6627, respectively), their error distributions, as shown by the Kernel Density Estimate (KDE) plots, are quite different. This highlights that relying solely on the mean can mask important differences in the underlying data and lead to inaccurate anomaly detection.", "section": "4.1 Limitations of existing Graph-AEs in GLAD"}, {"figure_path": "e2INndPINB/figures/figures_9_1.jpg", "caption": "Figure 6: Comparison of the three strongest GLAD methods\u2019 robustness against training set contamination. MUSE undergoes the least performance drop among the three methods.", "description": "This figure displays the robustness of three GLAD methods (MUSE, OCGTL, and GLAM) against training set contamination.  The x-axis represents the percentage of anomalies injected into the training data (0%, 10%, 20%, 30%). The y-axis shows the test AUROC score, a measure of the model's performance. The figure shows that as the percentage of anomalies in the training data increases, the performance of all three methods decreases. However, MUSE shows the smallest decrease, indicating its superior robustness to noisy training data containing anomalies.", "section": "6.3 RQ2. Robustness against the training set contamination"}, {"figure_path": "e2INndPINB/figures/figures_9_2.jpg", "caption": "Figure 7: PCA visualization of MUSE's error representations of graphs. Graphs belonging to different classes are well-separated in the representation space.", "description": "This figure shows the results of applying Principal Component Analysis (PCA) to the error representations generated by MUSE.  The plot visualizes how well MUSE can separate graphs from different classes in a lower-dimensional space.  The clear separation suggests that MUSE's error representations effectively capture the distinguishing characteristics of graphs from different classes, aiding in accurate anomaly detection.", "section": "RQ3. Error representation visualization"}, {"figure_path": "e2INndPINB/figures/figures_25_1.jpg", "caption": "Figure 2: Reconstruction flip occurs. When Graph-AEs are trained on graphs sharing a primary pattern of weak strength, the trained Graph-AEs exhibit lower reconstruction errors for graphs with the same pattern but with higher strength (red lines) than those with weaker strength (blue lines).", "description": "The figure shows the reconstruction error (both BCE and Frobenius loss) of Graph-AEs trained on graphs with weak community structures (blue lines) and then tested on graphs with weak (blue) and strong (red) community structures.  It demonstrates that the reconstruction error is lower for the unseen graphs with stronger community structure even though they share the same primary structural pattern with the training graphs. This phenomenon is defined in the paper as reconstruction flip.", "section": "3 Analysis of Graph Autoencoders"}, {"figure_path": "e2INndPINB/figures/figures_25_2.jpg", "caption": "Figure 2: Reconstruction flip occurs. When Graph-AEs are trained on graphs sharing a primary pattern of weak strength, the trained Graph-AEs exhibit lower reconstruction errors for graphs with the same pattern but with higher strength (red lines) than those with weaker strength (blue lines).", "description": "The figure shows that when a graph autoencoder is trained on graphs with a certain pattern (e.g., community structure) of weak strength, the model makes smaller reconstruction errors for graphs with the same pattern but stronger strength than for graphs with the same pattern but weaker strength. This phenomenon is called \"reconstruction flip\".", "section": "3 Analysis of Graph Autoencoders"}]