[{"type": "text", "text": "Rethinking Reconstruction-based Graph-Level Anomaly Detection: Limitations and a Simple Remedy ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Sunwoo ${\\bf K}{\\bf i m}^{1}$ , Soo Yong Lee1, Fanchen $\\mathbf{B}\\mathbf{u}^{2}$ , Shinhwan Kang1, Kyungho ${\\bf K i m}^{1}$ , Jaemin $\\mathbf{Y00}^{2}$ , Kijung Shin1,2 1Kim Jaechul Graduate School of AI, 2School of Electrical Engineering Korea Advanced Institute of Science and Technology (KAIST) {kswoo97, syleetolow, boqvezen97, shinhwan.kang, kkyungho, jaemin, kijungs}@kaist.ac.kr ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graph autoencoders (Graph-AEs) learn representations of given graphs by aiming to accurately reconstruct them. A notable application of Graph-AEs is graph-level anomaly detection (GLAD), whose objective is to identify graphs with anomalous topological structures and/or node features compared to the majority of the graph population. Graph-AEs for GLAD regard a graph with a high mean reconstruction error (i.e. mean of errors from all node pairs and/or nodes) as anomalies. Namely, the methods rest on the assumption that they would better reconstruct graphs with similar characteristics to the majority. We, however, report non-trivial counterexamples, a phenomenon we call reconstruction filp, and highlight the limitations of the existing Graph-AE-based GLAD methods. Specifically, we empirically and theoretically investigate when this assumption holds and when it fails. Through our analyses, we further argue that, while the reconstruction errors for a given graph are effective features for GLAD, leveraging the multifaceted summaries of the reconstruction errors, beyond just mean, can further strengthen the features. Thus, we propose a novel and simple GLAD method, named MUSE. The key innovation of MUSE involves taking multifaceted summaries of reconstruction errors as graph features for GLAD. This surprisingly simple method obtains SOTA performance in GLAD, performing best overall among 14 methods across 10 datasets. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graph autoencoders (Graph-AEs) are a family of graph neural networks (GNNs) that learn latent representations of given graphs by aiming to accurately reconstruct them. Representative examples of Graph-AEs include GAE [22] and GraphMAE [15], which respectively aim to accurately reconstruct graph structure and node features. Graph-AEs have a broad spectrum of applications, such as anomaly detection [38, 33, 6] and link prediction [13, 22, 24]. ", "page_idx": 0}, {"type": "text", "text": "Graph-AEs are trained to capture the structural information of graphs used for training (i.e., training graphs). Thus, intuitively, Graph-AEs are expected to better reconstruct graphs that are similar to the training graphs. However, to our surprise, this expectation is not always true. Given Graph-AEs trained to reconstruct the graphs in Figure 1(a), which share common structural characteristics, one would expect that the Graph-AEs would reconstruct the training graphs with smaller reconstruction errors than a dissimilar counterpart (e.g., in Figure 1 (b)). We, however, report the opposite. The reconstruction error is lower for the graph in Figure 1(b) than the training graphs. While similar observations were reported in computer vision application [31], which we elaborate on in Section 2.1, the existing literature does not clearly explain the aforementioned phenomenon. ", "page_idx": 0}, {"type": "text", "text": "This counterintuitive phenomenon guides our analysis, implication, and the proposed method. First, we aim to understand this counterintuitive phenomenon, which we refer to as the reconstruction filp. ", "page_idx": 0}, {"type": "image", "img_path": "e2INndPINB/tmp/520c6658d5bbc70a1c1d9a6660121cd2f9d2ea755902527041221dd971609758.jpg", "img_caption": ["Figure 1: The training graphs in (a) and the unseen graph in (b) exhibit different structural characteristics, but a Graph-AE model reconstructs the graph in (b) more accurately than those in (a). "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "We argue that the phenomenon can occur when (1) the training graphs and unseen graphs share a primary structural pattern and (2) the pattern is more pronounced in unseen graphs than in training graphs. We corroborate our claim with our theoretical and empirical analysis. ", "page_idx": 1}, {"type": "text", "text": "Second, our finding has strong implications for graph-level anomaly detection (GLAD). GLAD aims to identify graphs of different characteristics (e.g., structures and/or features) from the majority [38, 33, 39, 32]. Many existing GLAD methods leverage Graph-AEs [33, 38]. They regard a graph with a high mean reconstruction error (i.e. mean of errors from all node pairs and/or nodes) as anomalies, assuming trained Graph-AEs would struggle to reconstruct the graphs with structural patterns (and/or node attributes) that deviate from most training graphs. However, our finding suggests that this assumption does not always hold. Specifically, anomalous graphs with structural characteristics distinct from the training graphs may exhibit similar or even lower mean reconstruction errors. In such cases, the existing methods would struggle to detect anomalous graphs. We argue that this issue arises from how the existing methods leverage reconstruction errors, yet these errors remain valuable graph features for GLAD. We propose using multifaceted summaries of the reconstruction errors, rather than relying solely on their mean, to further enhance the features. ", "page_idx": 1}, {"type": "text", "text": "Third, based on the analysis and implication, we propose a simple and novel GLAD method, MUSE (Multifacted Summarization of Reconstruction Errors). MUSE, like other Graph-AE-based GLAD methods, reconstructs given graphs. However, MUSE employs a new way of using reconstruction errors: representing a graph with multifaceted summaries (e.g., mean, standard deviation, etc.) of the graph\u2019s reconstruction errors for GLAD. This simple innovation allows MUSE to obtain SOTA performance in the GLAD tasks. Through our extensive experiments including 13 baseline methods and 10 benchmark datasets, MUSE performs overall best, achieving up to $28.1\\%$ performance gain (in terms of AUROC) compared to the best competitor. We summarize our contribution as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Analysis (Section 3) with implications (Section 4): We investigate the reconstruction flip phenomenon both theoretically and empirically, yielding practical implications for GLAD. \u2022 Effective method (Section 5): Motivated by our analysis, we propose MUSE, a simple yet effective GLAD method that represents a graph as multifaceted summaries of its reconstruction errors. \u2022 Extensive experiments (Section 6): Our experiments on 10 datasets demonstrate the superiority of MUSE over prior GLAD methods. Our code and datasets are available at https://github. com/kswoo97/GLAD_MUSE. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work and Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this section, we provide a brief literature review on graph-level anomaly detection (GLAD) and peculiar observations in GLAD. We then present the preliminaries of our work. ", "page_idx": 1}, {"type": "text", "text": "2.1 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Graph-level anomaly detection. Graph-level anomaly detection (GLAD) aims to identify graphs whose characteristics deviate from those of the majority of the graph population [38, 33, 39, 32]. GLAD has various applications, including brain diagnosis [25] and drug discovery [46]. While several GLAD methods require anomaly label supervision to train a detector [54, 35], we focus on the methods that do not require anomaly labels [38, 33, 39, 32], since anomaly labels are often not available in real-world scenarios. A GLAD method typically trains a model to perform certain pretext tasks on given graphs, and the graphs are regarded as anomalies if the trained model shows poor pretext task performance on them. Notable pretext tasks include graph reconstruction [38, 33], graph embedding hypersphere minimization [39, 57], and cross-view mutual information maximization [34, 32]. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Peculiar observations in graph-level anomaly detection. The most relevant literature with our work is a study of Zhao and Akoglu [56]. In graph classification datasets, they regarded graphs belonging to a particular class as normal graphs and otherwise as anomalies to benchmark several GLAD methods. In this setting, they observed that several GLAD methods, especially kernel-based ones, occasionally perform worse than random guessing. However, their analysis focused on graph kernels [37, 41], without covering graph autoencoders, which are our focus. In computer vision, Liu et al. [31] suggested that certain anomalous images can be easier to reconstruct than normal ones, presenting a method that can overcome these undesirable circumstances. However, neither their analysis nor the method can be trivially extended to the graph domain, as elaborated in Appendix F.1. ", "page_idx": 2}, {"type": "text", "text": "2.2 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Graphs. A graph $\\mathcal{G}\\,=\\,(\\mathcal{V},\\mathcal{E})$ is defined by a node set $\\mathcal{V}=\\left\\{v_{1},\\ldots,v_{|\\mathcal{V}|}\\right\\}$ and an edge set $\\mathcal{E}=$ $\\{e_{1},\\ldots,e_{|\\mathcal{E}|}\\}$ , where each edge $e_{i}\\in\\mathcal{E}$ is defined by a node pair. We assume that each node $v_{i}\\in\\mathcal{V}$ is equipped with a feature vector $\\mathbf{x}_{i}\\in\\mathbb{R}^{d}$ , which forms a node feature matrix $\\mathbf{X}\\in\\mathbb{R}^{|\\mathcal{V}|\\times d}$ where each $i$ -th row $\\mathbf{X}_{i,:}=\\mathbf{x}_{i}$ . Moreover, $\\mathcal{E}$ can be represented by an adjacency matrix $\\mathbf{A}\\in\\{0,1\\}^{|\\mathcal{V}|\\times|\\mathcal{V}|}$ , where $\\mathbf{A}_{i,j}=1$ if and only if $\\{v_{i},v_{j}\\}\\in\\mathcal{E}$ . Therefore, the graph can also be defined as $\\mathcal{G}=(\\mathbf{X},\\mathbf{A})$ . ", "page_idx": 2}, {"type": "text", "text": "Graph neural networks. Graph neural networks (GNNs) are a category of neural networks designed for processing graph data. GNNs primarily leverage message passing schemes [49, 14, 45, 11, 28, 30]. In this work, we consider GNNs as parameterized functions $f_{\\theta}$ that generate node embeddings $\\mathbf{Z}=f_{\\theta}(\\mathbf{X},\\mathbf{A})\\in\\mathbb{R}^{|\\mathcal{V}|\\times d^{\\prime}}$ for each graph $\\mathcal{G}=(\\mathbf{X},\\mathbf{A})$ . 1 ", "page_idx": 2}, {"type": "text", "text": "Graph autoencoders. Graph autoencoders (Graph-AEs) are a family of GNNs that learn graph latent representations by graph reconstruction. Specifically, Graph-AEs reconstruct a given graph\u2019s structure [22, 43] and/or node features [15, 16]. For example, GAE [22] reconstructs the adjacency matrix of a given graph. Specifically, GAE first uses an encoder GNN $f_{\\theta}$ to generate node embeddings $\\mathbf{Z}=f_{\\theta}(\\mathbf{X},\\mathbf{A})$ of a given graph $\\mathcal{G}=(\\mathbf{X},\\mathbf{A})$ . Then, GAE obtains a reconstructed adjacency matrix $\\hat{\\mathbf{A}}\\in\\mathbb{R}^{|\\mathcal{V}|\\times|\\mathcal{V}|}$ through the inner-product of node embeddings and entry-wise sigmoid activation $\\sigma$ (i.e., $\\hat{\\mathbf{A}}=\\sigma(\\mathbf{Z}\\mathbf{Z}^{T}))$ . Lastly, it minimizes the difference between A and $\\hat{\\bf A}$ , for which one can use the binary cross-entropy (BCE) loss $\\begin{array}{r}{\\mathcal{L}_{\\mathrm{BCE}}(\\mathcal{G}\\mid f_{\\theta}):=-\\sum_{i,j=1}^{|\\mathcal{V}|}\\left(\\mathbf{A}_{i,j}\\log\\hat{\\mathbf{A}}_{i,j}+\\left(1-\\mathbf{A}_{i,j}\\right)\\log\\left(1-\\hat{\\mathbf{A}}_{i,j}\\right)\\right)}\\end{array}$ or the squared Frobenius-norm loss $\\begin{array}{r}{\\mathcal{L}_{\\mathrm{SFN}}(\\boldsymbol{\\mathcal{G}}\\mid f_{\\theta}):=\\|\\mathbf{A}-\\hat{\\mathbf{A}}\\|_{F}^{2}=\\sum_{i,j=1}^{|\\mathcal{V}|}\\left(\\mathbf{A}_{i,j}-\\hat{\\mathbf{A}}_{i,j}\\right)^{2}}\\end{array}$ . Given a set of training graphs $\\mathbb{G}=\\{\\mathcal{G}_{1},\\mathcal{G}_{2},\\cdot\\cdot\\cdot,\\mathcal{G}_{|\\mathbb{G}|}\\}$ , GAE is trained (i.e., the encoder parameter $\\theta$ is updated) to minimize $\\sum_{\\mathcal{G}\\in\\mathbb{G}}\\mathcal{L}(\\mathcal{G}\\mid f_{\\theta})$ (or equivalently, $\\mathbb{E}_{\\mathcal{G}\\in\\mathbb{G}}\\mathcal{L}(\\mathcal{G}\\mid f_{\\theta}))$ , where $\\mathcal{L}$ is $\\mathcal{L}_{\\mathrm{BCE}}$ or $\\mathcal{L}_{\\mathrm{SFN}}$ . In our analysis below, we focus on methods that reconstruct graph structures, while we describe and investigate node-feature-reconstruction methods in Appendix E.1. ", "page_idx": 2}, {"type": "text", "text": "3 Analysis of Graph Autoencoders ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we explore reconstruction filp phenomena (e.g., the phenomenon described in Figure 1), where graph autoencoders (Graph-AEs) reconstruct some unseen graphs that are dissimilar to training graphs better than training graphs. ", "page_idx": 2}, {"type": "text", "text": "Our analysis focuses on evidencing the claims below. We assume GAE [22] trained on graphs sharing a primary pattern $\\mathcal{P}$ of strength $\\boldsymbol{S}$ . ", "page_idx": 2}, {"type": "text", "text": "Claims ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "\u2022 Reconstruction filp tends to occur when unseen (test) graphs have the same primary pattern $\\mathcal{P}$ but with a greater strength $S^{\\prime}>S$ .   \n\u2022 Reconstruction filp tends not to occur when unseen (test) graphs have a different primary pattern $\\mathcal{P}^{\\prime}\\neq\\mathcal{P}$ . ", "page_idx": 2}, {"type": "image", "img_path": "e2INndPINB/tmp/376b63ab42958cd521bbf921ada3c9ef0ad5fbcbe012d75da5a5f3a9b8101f9a.jpg", "img_caption": ["Figure 2: Reconstruction flip occurs. When Graph-AEs are trained on graphs sharing a primary pattern of weak strength, the trained Graph-AEs exhibit lower reconstruction errors for graphs with the same pattern but with higher strength (red lines) than those with weaker strength (blue lines). "], "img_footnote": [], "page_idx": 3}, {"type": "image", "img_path": "e2INndPINB/tmp/a9025514b1f6c1f560ccb441fdff08d96851ebcac24ac946d5a15213f7895de0.jpg", "img_caption": ["Figure 3: Reconstruction flip does NOT occur. When Graph-AEs are trained on graphs sharing a primary pattern, the trained Graph-AEs exhibit higher reconstruction errors for graphs with a different pattern (red lines) than those with the same pattern (blue lines). "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "That is, when Graph-AEs are trained on graphs with a primary pattern $\\mathcal{P}$ of strength $\\boldsymbol{S}$ , the trained Graph-AEs tend to exhibit lower errors in reconstructing graphs with $\\mathcal{P}$ of a greater strength $S^{\\prime}>S$ . However, the trained Graph-AEs tend to exhibit higher errors in reconstructing graphs with a different pattern $\\mathcal{P}^{\\prime}\\neq\\mathcal{P}$ . For demonstration, we elaborate on $\\mathcal{P}$ and $\\boldsymbol{S}$ via synthetic datasets (Section 3.1) and present both empirical (Section 3.2) and theoretical (Section 3.3) investigations. ", "page_idx": 3}, {"type": "text", "text": "3.1 Synthetic graphs ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To elaborate on the concepts of a primary pattern $\\mathcal{P}$ and a pattern strength $\\boldsymbol{S}$ , we employ two types of synthetic graphs: (1) graphs with community structures and (2) graphs with cycles. ", "page_idx": 3}, {"type": "text", "text": "Community type. Syn-Com graphs have community structures, a pervasive pattern in real-world graphs [12], as the primary pattern $\\mathcal{P}$ . Graphs in Figure 1 are instances of such graphs. We control the strength $S$ of community structures through a parameter $\\tau\\in[0,1]$ . The 10 nodes in each graph are evenly divided into two communities. Each intra- and inter-community edge is formed with probability $(1+\\tau)/2$ and $(1-\\tau)/2$ , respectively. In our empirical analysis, we consider two graph classes with different $\\tau$ \u2019s. Graphs in one class $\\mathbb{G}_{\\tau=0.4}^{c o m}$ are generated with $\\tau=0.4$ (weaker community structure; the graphs in Figure 1(a)) and those in the other class c\u03c4o=m0.8 are generated with \u03c4 = 0.8 (stronger community structure; the graph in Figure 1(b)). ", "page_idx": 3}, {"type": "text", "text": "Cycle type. Syn-Cycle graphs contain a cycle of nodes (i.e., a closed chain of nodes), which is commonly observed in realworld graphs [8]. In Syn-Cycle, the primary pattern $\\mathcal{P}$ corresponds to the node cycle. Graphs in Figure 4 are instances of Syn-Cycle. In Syn-Cycle graphs, the pattern strength $\\boldsymbol{S}$ is stronger in the clean-cycle graph consisting only of a cycle with $n$ nodes (the left graph in Figure 4), and it is weaker in noisy-cycle graphs, where a node within the cycle of $(n-1)$ ", "page_idx": 3}, {"type": "image", "img_path": "e2INndPINB/tmp/4dc689e07b2cef6ea2020cf3ab762c40198a5c5e936981290212726d5508d623.jpg", "img_caption": ["Figure 4: A clean-cycle graph and a noisy-cycle graph. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "nodes is linked to an extra node (the right graph in Figure 4). The number of nodes $n$ is fixed to 10. ", "page_idx": 3}, {"type": "text", "text": "We provide detailed descriptions of both graph types in Appendix C. ", "page_idx": 3}, {"type": "text", "text": "3.2 Empirical analysis ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Sweet tlienvge.r agWee  (c1o) ntshied eCr otmw-oC socemn daraitoass.e tI, n wShceerne atrhieo  t1r,a iwnien agi gmr taop hvsa lairdea tsea mouprl efdir sftr oclma $\\mathbb{G}_{\\tau=0.4}^{c o m}$ t hainsd e tnhde, unseen graphs are sampled from , and (2) the Cycle-Cycle dataset, where the training graphs are sampled from the noisy-cycle graphs and the unseen graph is the clean-cycle graph. ", "page_idx": 3}, {"type": "text", "text": "In Scenario 2, we aim to validate our second claim. To this end, we leverage (3) the Com-Cycle dataset, where the training graphs are sampled from Gc\u03c4o=m0.4 and the unseen graphs are sampled from the noisy-cycle graphs, and (4) the Cycle-Com dataset, where the training graphs are sampled from the noisy-cycle graphs and the unseen graphs are sampled from $\\mathbb{G}_{\\tau=0.4}^{c o m}$ . ", "page_idx": 4}, {"type": "text", "text": "For each dataset, we train GAE [22] equipped with GIN [49] as the graph encoder. We use either the (1) binary cross-entropy (BCE) loss or the (2) squared Frobenius-norm (Frobenius) loss, which are formalized in Section 2.2, for the reconstruction loss. We compare the reconstruction losses for the training graphs and unseen graphs. Further details are provided in Appendix D.2. ", "page_idx": 4}, {"type": "text", "text": "Note. While we focus on adjacency reconstruction in this section, we provide an analysis of featurereconstruction methods in Appendix E.1, where the results are consistent with those below. ", "page_idx": 4}, {"type": "text", "text": "Empirical results. In Scenario 1, for both Com-Com and Cycle-Cycle datasets, reconstruction losses are lower for the graphs with stronger pattern strengths, which are unseen graphs (see Figure 2). That is, all graphs share a primary pattern $\\mathcal{P}$ (either node community or cycle) with two different strengths $s<\\bar{S^{\\prime}}$ , and GAE trained on graphs of pattern strength $\\boldsymbol{S}$ reconstructs those of pattern strength $S^{\\prime}$ with lower losses, demonstrating our first claim. In Scenario 2, for both Com-Cycle and Cycle-Com datasets, reconstruction losses become lower for the training graphs after some training epochs (see Figure 3). That is, given training graphs with a primary pattern $\\mathcal{P}$ (either node communities or a cycle), the trained GAE reconstructs graphs with the same pattern $\\mathcal{P}$ with lower losses than those with a different pattern $\\mathcal{P}^{\\prime}$ , demonstrating our second claim. ", "page_idx": 4}, {"type": "text", "text": "3.3 Theoretical analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this subsection, we theoretically analyze the empirical observations in Section 3.2, focusing on the occurrence of reconstruction flip. Informally speaking, we shall show that when GAE is trained on graphs with a primary pattern $\\mathcal{P}$ of strength $\\boldsymbol{S}$ , the following holds: ", "page_idx": 4}, {"type": "text", "text": "(A1) Reconstruction losses decrease for graphs with the same $\\mathcal{P}$ of various strengths. ", "page_idx": 4}, {"type": "text", "text": "(A2) Reconstruction losses decrease more rapidly for graphs with the same $\\mathcal{P}$ of greater strengths. ", "page_idx": 4}, {"type": "text", "text": "Setting. For theoretical analysis, we use a single-layer linear GAE. Formally, for a given graph $\\mathcal{G}\\,=\\,({\\bf X},{\\bf A})$ , the linear GAE reconstructs the given graph\u2019s adjacency matrix as follows: $\\mathbf{\\bar{A}}=$ $\\mathbf{AXW}(\\mathbf{AXW})^{T}$ , where $\\mathbf{W}\\in\\mathbb{R}^{n\\times n}$ is a learnable weight matrix and $n$ is the number of nodes. We use the squared Frobenius norm as the reconstruction loss $\\mathcal{L}(\\mathcal{G},\\mathbf{W})=\\|\\mathbf{A}-\\hat{\\mathbf{A}}\\|_{F}^{2}$ . We consider Syn-Com graphs $\\mathbb{G}_{\\tau}^{c o m}$ (Section 3.1). To formalize the training of linear GAE, we define the expected gradient descent update of $\\mathbf{W}$ as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{W}(\\tau,\\mathbf{W},\\gamma)=\\mathbf{W}-\\gamma\\mathbb{E}_{\\mathcal{G}}\\left[\\frac{\\partial\\mathcal{L}(\\mathcal{G},\\mathbf{W})}{\\partial\\mathbf{W}}\\mid\\tau\\right]\\in\\mathbb{R}^{n\\times n},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\gamma>0$ is a learning rate and $\\mathbb{E}_{\\mathcal{G}}[\\cdot|\\tau]$ takes the expectation over all the graphs $\\mathcal{G}\\in\\mathbb{G}_{\\tau}^{c o m}$ . We assume graphs of strength $\\tau_{1}$ are used as the training graphs and graphs of strength $\\tau_{2}$ are used as the unseen (test) graphs. ", "page_idx": 4}, {"type": "text", "text": "Theoretical results. We now present our theoretical results, with proof of each theorem in Appendix A. We first demonstrate that (A1) holds by expectation. ", "page_idx": 4}, {"type": "text", "text": "Theorem 1 (Generalization across $\\tau$ ). For any $n\\geq12$ and $0<\\tau_{1}\\le1$ , there exists $\\epsilon>0$ such that for any $0<\\gamma\\leq\\epsilon$ and any $0<\\tau_{2}\\le1$ (recall that 0 and 1 are the lower and upper bounds of $\\tau$ , respectively) with the initial weight matrix $\\mathbf{W}^{(0)}=\\mathbb{I}_{n}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathcal{G}}[\\mathcal{L}(\\mathcal{G},\\mathbb{W}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))|\\tau_{2}]_{,}\\;<\\;\\qquad\\;\\mathbb{E}_{\\mathcal{G}}[\\mathcal{L}(\\mathcal{G},\\mathbf{W}^{(0)})|\\tau_{2}]_{,}\\qquad\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Roughly, Theorem 1 states that regardless of the values of $\\tau_{1}$ and $\\tau_{2}$ , updating W with graphs of strength $\\tau_{1}$ reduces the reconstruction losses for graphs of strength $\\tau_{2}$ . Intuitively, this suggests that GAE learns the primary pattern $\\mathcal{P}$ , regardless of the strength $\\boldsymbol{S}$ (here, $\\tau_{1}$ ) of the training graphs. ", "page_idx": 4}, {"type": "text", "text": "Now, we demonstrate that (A2) holds by expectation. ", "page_idx": 4}, {"type": "image", "img_path": "e2INndPINB/tmp/a014763ce35c5a0b372eac74888343801cdaef6d2b6be7a238f8dc9944530ba5.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 5: A case of Graph-AEs (specifically, GAE [22]) having similar mean reconstruction errors for two dissimilar graphs (specifically, $\\mathcal{G}_{1}$ has 0.6622 and $\\mathscr{G}_{2}$ has 0.6627), while their error distributions differ significantly. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2 (Correlation with $\\tau$ ). For any $n\\geq34$ and $0<\\tau_{1}\\le0.98$ , there exists $\\epsilon>0$ such that for any $0<\\gamma\\leq\\epsilon$ and any $\\tau_{1}+0.02\\leq\\tau_{2}\\leq1$ with the initial weight $\\mathbf{W}^{(0)}=\\mathbb{I}_{n}$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{\\mathfrak{c}}_{\\mathcal{G}}\\left[\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\mathbf{W}^{(0)})-\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\mathbb{W}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))\\mid\\tau_{1}\\right]<\\mathbb{E}_{\\boldsymbol{\\mathcal{G}}}\\left[\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\mathbf{W}^{(0)})-\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\mathbb{W}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))\\mid\\tau_{2}\\right].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Roughly, Theorem 2 states that updating W using graphs of pattern strength $\\tau_{1}$ results in a greater reduction of reconstruction losses for graphs of higher strength $\\tau_{2}>\\tau_{1}$ than for the graphs used in W update (i.e., graphs of strength $\\tau_{1}$ ). Intuitively, this result suggests that even if GAE is trained on graphs with a primary pattern $\\mathcal{P}$ of strength $\\boldsymbol{S}$ (here, $\\tau_{1}$ ), the trained GAE tends to reconstruct graphs of a greater strength $S^{\\prime}$ (here, $\\tau_{2}$ ) with smaller losses. ", "page_idx": 5}, {"type": "text", "text": "4 Implications in Graph-Level Anomaly Detection ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we investigate the practical implications of our analysis in Section 3 for graph-level anomaly detection (GLAD). Specifically, we discuss the limitations of existing graph-autoencoderbased GLAD methods and propose an improved approach to using graph reconstruction errors. ", "page_idx": 5}, {"type": "text", "text": "4.1 Limitations of existing Graph-AEs in GLAD ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Anomalous graphs may have low mean reconstruction errors. As outlined in Section 2.1, many methods for graph-level anomaly detection (GLAD) use graph autoencoders (Graph-AEs), aiming to identify graphs whose characteristics deviate from the majority. Typically, such GLAD methods [33, 38] consider graphs with higher reconstruction losses (i.e. mean (or sum) of reconstruction errors from all node pairs and/or nodes) as anomalies. This is based on the intuition that Graph-AEs would struggle to reconstruct anomalous graphs that are dissimilar to the majority of training graphs. However, our empirical (Section 3.2) and theoretical (Section 3.3) analyses reveal that Graph-AEs can exhibit lower mean reconstruction errors for graphs that are less similar to training graphs. In the context of GLAD, when anomalous graphs have the same primary pattern as training graphs but have stronger strengths, Graph-AEs tend to exhibit lower mean reconstruction errors, compared to the training graphs. Thus, such anomalies tend not to be detected by existing Graph-AE-based GLAD methods, revealing their severe limitations. ", "page_idx": 5}, {"type": "text", "text": "Mean is not all you need. In addition in practice, we find that in some cases, dissimilar graphs can have similar mean reconstruction errors. As shown in Figure 5, although the graph $\\mathcal{G}_{1}$ in (a) and the graph $\\mathcal{G}_{2}$ in (b) have significantly different numbers of edges, their mean reconstruction errors are similar, making it difficult to distinguish between the two graphs (refer to the caption of Figure 5). On the other hand, Figure 5(c) shows that the reconstruction error distributions over individual node pairs 2 of $\\mathcal{G}_{1}$ (blue distribution) and $\\mathcal{G}_{2}$ (red distribution) differ significantly in shape. Other descriptive statistics, such as standard deviation, can effectively distinguish the two graphs in such cases. Thus, incorporating additional statistical measures beyond the mean is beneficial for Graph-AEs in GLAD. ", "page_idx": 5}, {"type": "text", "text": "4.2 Enhancing the use of reconstruction errors ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Based on the implications discussed in Section 4.1, we argue that a graph\u2019s reconstruction errors aggregated in various ways can provide features that effectively distinguish anomalous graphs from normal graphs. We provide detailed descriptions of this claim below. ", "page_idx": 6}, {"type": "text", "text": "Reconstruction errors serve as good features for GLAD. Consider the following scenarios where Graph-AEs are trained on graphs sharing a pattern $\\mathcal{P}$ of strength $\\boldsymbol{S}$ . First, for an unseen graph of a pattern $\\mathcal{P}$ with higher strength $S^{\\prime}>S$ , Graph-AEs tend to return lower mean reconstruction errors compared to those of the training graphs (Figure 2). Second, for an unseen graph of a different pattern $\\mathcal{P}^{\\prime}\\neq\\mathcal{P}$ , Graph-AEs tend to give higher mean reconstruction error than those of the training graphs (Figure 3). In both cases, the error distributions of anomalous graphs differ from those of normal graphs, serving as effective features for distinguishing them. ", "page_idx": 6}, {"type": "text", "text": "Using multifaceted summaries of errors is important for GLAD. In practice, we need a fixed-size representation of the error distribution to be used with anomaly classifiers, which generally require a fixed-size input vector. To achieve this, we propose using various summary statistics (e.g., mean and standard deviation) to represent the given error distribution. Specifically, rather than relying on a single statistic, we use multifaceted summaries that capture various aspects of the error distributions. This is because distinct error distributions may share certain similar summary statistics, as shown in Figure 5. Therefore, multifaceted summaries of the error distribution can act as an effective feature vector for distinguishing anomalous graphs from normal graphs. ", "page_idx": 6}, {"type": "text", "text": "5 Proposed Method: MUSE ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Based on the discussions provided in Section 4.2, we present MUSE (Multifacted Summarization of Reconstruction Errors), a simple yet effective graph-level anomaly detection (GLAD) method. MUSE aggregates a graph\u2019s reconstruction errors into multiple summary statistics and uses a vector of these aggregated errors as the graph\u2019s representation for GLAD. We describe how we train the reconstruction model in Section 5.1 and how we obtain the error representation (i.e., a multifaceted summary of reconstruction errors) in Section 5.2. ", "page_idx": 6}, {"type": "text", "text": "5.1 Step 1: Training a reconstruction model ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We first train MUSE to reconstruct graphs in training data. Step 1 is composed of three parts: (1) augmentation, (2) encoding/decoding, and (3) reconstruction loss minimization. For an input graph $\\mathcal{G}=(\\mathbf{X},\\mathbf{A})$ , MUSE first augments the input graph by randomly dropping some edges, mitigating potential overftiting problems. Specifically, MUSE randomly samples $\\lceil p\\vert\\mathcal{E}\\vert\\rceil$ edges from $\\mathcal{E}$ for some $0\\le p<1$ . Let ${\\mathcal{E}}^{\\prime}$ denote the set of sampled edges. We mask the corresponding entries in A by setting them to zero to generate the augmented adjacency matrix $\\mathbf{A}^{\\prime}\\in\\{0,\\mathbf{\\dot{1}}\\}^{|\\mathcal{V}|\\times|\\mathbf{\\bar{\\nu}}|}$ (i.e., $\\mathbf{A}_{i,j}^{\\prime}=0$ if $\\{v_{i},v_{j}\\}\\in\\mathcal{E}^{\\prime}$ , otherwise ${\\bf A}_{i,j}^{\\prime}={\\bf A}_{i,j,},\\forall i,j\\in[|\\mathcal{V}|])$ . ", "page_idx": 6}, {"type": "text", "text": "MUSE then encodes the augmented graph $\\mathcal{G}^{\\prime}=(\\mathbf{X},\\mathbf{A}^{\\prime})$ to obtain node embeddings $\\mathbf{Z}\\in\\mathbb{R}^{|\\mathcal{V}|\\times d^{\\prime}}$ by using a graph neural network (GNN) encoder $f_{\\theta}$ (i.e., $\\mathbf{Z}=f_{\\theta}(\\mathbf{X},\\mathbf{A}^{\\prime}))$ . Subsequently, MUSE decodes the node embeddings $\\mathbf{Z}$ to obtain reconstructed node features $\\hat{\\mathbf{X}}\\in\\mathbb{R}^{|\\mathcal{V}|\\times d}$ and reconstructed adjacency matrix $\\hat{\\mathbf{A}}\\in(0,\\bar{1})^{|\\mathcal{V}|\\times|\\mathcal{V}|}$ . For node feature reconstruction, MUSE uses a node feature decoder $g_{\\psi}:\\mathbb{R}^{d^{\\prime}}\\mapsto\\mathbb{R}^{d}$ (i.e., $\\hat{\\mathbf{X}}=g_{\\psi}(\\mathbf{Z}))$ . Similarly, for adjacency matrix reconstruction, MUSE uses an adjacency matrix decoder $h_{\\phi}:\\mathbb{R}^{d^{\\prime}}\\mapsto\\mathbb{R}^{d^{\\prime\\prime}}$ and the inner product of its output (i.e., $\\hat{\\bf A}=$ $\\sigma(\\mathbf{Z}^{\\prime}\\mathbf{Z}^{'T})$ , where $\\sigma$ is a sigmoid function and ${\\bf Z}^{\\prime}=h_{\\phi}({\\bf Z}))$ . ", "page_idx": 6}, {"type": "text", "text": "Lastly, for training, we leverage reconstruction losses regarding the node features and the adjacency matrix. For node feature reconstruction, we use the cosine-similarity loss as in GraphMAE [15]. Formally, the loss is defined as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathbf{X}}(\\boldsymbol{\\mathcal{G}})=\\frac{1}{|\\mathcal{V}|}\\sum_{i=1}^{|\\mathcal{V}|}\\left(1-\\frac{\\mathbf{X}_{i,:}^{T}\\hat{\\mathbf{X}}_{i,:}}{\\lVert\\mathbf{X}_{i,:}\\rVert_{2}\\cdot\\lVert\\hat{\\mathbf{X}}_{i,:}\\rVert_{2}}\\right),\\mathrm{~where~}\\lVert\\cdot\\rVert_{2}\\mathrm{~is~the~}\\ell_{2}\\mathrm{-norm}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "For adjacency-matrix reconstruction, we use the binary cross-entropy (BCE) loss as in GAE [22]. Since real-world graphs are often sparse (i.e., the adjacency matrix contains significantly more zero ", "page_idx": 6}, {"type": "text", "text": "entries than ones), we weight the loss terms associated with non-zero entries to stabilize model training in the presence of this imbalance. Formally, the loss is defined as follows: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathbf{A}}(\\mathcal{G})=-\\left(\\frac{1}{|\\mathcal{V}|}\\right)^{2}\\sum_{i=1}^{|\\mathcal{V}|}\\sum_{j=1}^{|\\mathcal{V}|}\\left(\\omega\\mathbf{A}_{i,j}\\log\\hat{\\mathbf{A}}_{i,j}+\\left(1-\\mathbf{A}_{i,j}\\right)\\log\\left(1-\\hat{\\mathbf{A}}_{i,j}\\right)\\right),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "$\\begin{array}{r}{\\omega=(\\frac{|\\mathcal{V}|^{2}}{\\sum_{i=1}^{|\\mathcal{V}|}\\sum_{j=1}^{|\\mathcal{V}|}\\mathbf{A}_{i,j}}-1)^{\\tau}}\\end{array}$ and $\\tau$ is a scale hyperparameter. Then, the total reconstruction loss $\\mathcal{L}(\\mathcal{G})$ is defined as the mean of ${\\mathcal{L}}_{\\mathbf{X}}({\\mathcal{G}})$ (Eq. (2)) and $\\mathcal{L}_{\\mathbf{A}}(\\mathcal{G})$ (Eq. (3)) (i.e., $\\begin{array}{r}{\\mathcal{L}(\\mathcal{G})=(\\mathcal{L}_{\\mathbf{X}}(\\mathcal{G})+}\\end{array}$ $\\mathcal{L}_{\\mathbf{A}}(\\mathcal{G}))/2)$ . For a set of training graphs $\\mathbb{G}=\\{\\mathcal{G}_{1},\\cdot\\cdot\\cdot,\\mathcal{G}_{K}\\}$ , we update the parameters (i.e., $\\theta,\\psi$ , and $\\phi$ ) by using gradient descent aiming to minimize $\\textstyle{\\frac{1}{K}}\\sum_{t\\in[K]}{\\mathcal{L}}({\\mathcal{G}}_{t})$ . ", "page_idx": 7}, {"type": "text", "text": "5.2 Step 2: Generating error representation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "After training the reconstruction model, we represent each graph using its reconstruction errors, specifically those from all node pairs and/or nodes. Consider obtaining the reconstruction errors for a graph $\\mathcal{G}=(\\mathbf{X},\\mathbf{A})$ with the trained reconstruction model (i.e., $f_{\\theta},g_{\\psi}$ , and $h_{\\phi}$ ). To this end, we first obtain reconstructed features X\u02c6 and a reconstructed adjacency matrix A\u02c6 by using the encoding and decoding scheme described in Section 5.1. Note that we do not perform augmentation for Step 2 (i.e., the original graph $(\\mathbf{X},\\mathbf{A})$ is the input of the encoder $f_{\\theta}$ ). ", "page_idx": 7}, {"type": "text", "text": "After that, we obtain node-feature reconstruction errors $\\mathbb{L}_{\\mathbf{X}}(\\mathcal{G}\\mid f_{\\theta},g_{\\psi},h_{\\phi})$ on each node and adjacency-matrix reconstruction errors $\\mathbb{L}_{\\mathbf{A}}(\\mathcal{G}\\mid f_{\\theta},g_{\\psi},h_{\\phi})$ on each node pair. Formally, ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{L}_{\\mathbf{X}}(\\boldsymbol{\\mathcal{G}})=\\mathbb{L}_{\\mathbf{X}}(\\boldsymbol{\\mathcal{G}}\\mid f_{\\theta},g_{\\psi},h_{\\phi}):=\\left[1-\\frac{\\mathbf{X}_{i,:}^{T}\\hat{\\mathbf{X}}_{i,:}}{\\lVert\\mathbf{X}_{i,:}\\rVert_{2}\\cdot\\lVert\\mathbf{X}_{i,:}\\rVert_{2}}\\right]_{i\\in[|\\mathcal{V}|]}\\in\\mathbb{R}^{|\\mathcal{V}|},\\;\\mathrm{and}}\\\\ &{\\mathbb{L}_{\\mathbf{A}}(\\boldsymbol{\\mathcal{G}})=\\mathbb{L}_{\\mathbf{A}}(\\boldsymbol{\\mathcal{G}}\\mid f_{\\theta},g_{\\psi},h_{\\phi}):=\\left[\\mathbf{A}_{i,j}\\log\\hat{\\mathbf{A}}_{i,j}+\\left(1-\\mathbf{A}_{i,j}\\right)\\log\\left(1-\\hat{\\mathbf{A}}_{i,j}\\right)\\right]_{i,j\\in[|\\mathcal{V}|]}\\in\\mathbb{R}^{|\\mathcal{V}|^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Lastly, based on the motivation described in Section 4, we aggregate reconstruction errors (i.e., \u201csummarize\u201d vectors into scalars) using $T$ different aggregation functions $\\mathtt{A g g}_{t}$ \u2019s as follows: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname{Err}(\\mathcal{G}):=[\\mathtt{A g g}_{1}(\\mathbb{L}_{\\mathbf{X}}(\\mathcal{G})),\\cdots,\\mathtt{A g g}_{T}(\\mathbb{L}_{\\mathbf{X}}(\\mathcal{G})),\\ \\mathtt{A g g}_{1}(\\mathbb{L}_{\\mathbf{A}}(\\mathcal{G})),\\cdots,\\mathtt{A g g}_{T}(\\mathbb{L}_{\\mathbf{A}}(\\mathcal{G}))]\\in\\mathbb{R}^{2T}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Any aggregation functions that provides a representative summary of $\\mathbb{L}_{\\mathbf{X}}(\\mathcal{G})$ and $\\mathbb{L}_{\\mathbf{A}}(\\mathcal{G})$ are applicable, such as mean and standard deviation. As a result, we represent a graph $\\mathcal{G}$ as a $2T$ -dimensional vector $\\operatorname{Err}({\\mathcal{G}})$ (Eq. (6)), which we refer to as the final error representation of $\\mathcal{G}$ . We present a time complexity analysis of MUSE in Appendix F.3. ", "page_idx": 7}, {"type": "text", "text": "After obtaining error representations of graphs, we leverage one-class classifiers on these representations to finally perform anomaly detection. Note that Steps 1 and 2 are decoupled from the application of one-class classifiers (i.e., one-class classifier is trained after completing Steps 1 and 2). ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we evaluate the effectiveness of MUSE in graph-level anomaly detection (GLAD) by addressing four key research questions. ", "page_idx": 7}, {"type": "text", "text": "\u2022 RQ1. How accurately does MUSE detect anomalous graphs?   \n\u2022 RQ2. How robust is MUSE against contamination of the training set?   \n\u2022 RQ3. Can the error representations of MUSE distinguish anomalies from normal graphs in the representation space?   \n\u2022 RQ4. Are the key components of MUSE essential for its performance? ", "page_idx": 7}, {"type": "text", "text": "6.1 Experimental settings ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Datasets. Given the absence of benchmark datasets with ground-truth graph-level anomalies, following existing GLAD studies [39, 32, 33, 55, 34, 38], we use graph classification benchmark datasets for evaluation. Specifically, we use 10 datasets from diverse domains, such as chemical molecules, bioinformatics, and social networks. Detailed descriptions of the datasets are in Appendix B. ", "page_idx": 7}, {"type": "table", "img_path": "e2INndPINB/tmp/18f4963c79921ea414e21ed8d30a1ac9851d6bebd4fc749fd4474404ae8c4a00.jpg", "table_caption": ["Table 1: GLAD performance: Mean and standard deviation of test AUROC values $(\\times100)$ in the GLAD task are reported. The best and second-best performances are highlighted in green and yellow. A.R. denotes average ranking. MUSE obtains the best average ranking among 18 methods. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Training and evaluation. Following Qiu et al. [39], for a dataset with $C$ graph classes, we use $C$ experimental configurations. In each configuration, graphs with one class are treated as normal, while graphs with the other classes are considered anomalies. For each configuration, the normal graphs are split into training, validation, and test sets in an $80\\%/10\\%/10\\%$ ratio. Additionally, $5\\%$ of anomalies are sampled for the validation set (only for hyperparameter tuning) and $5\\%$ for the test set. We conduct five trials for each configuration, with each trial using different data splits and model initializations. Each model\u2019s performance on each dataset is evaluated by averaging the test mean AUROC across all configurations. ", "page_idx": 8}, {"type": "text", "text": "Baseline methods and MUSE. We compare MUSE against 13 baseline methods, including 7 GLAD methods [39, 32, 33, 55, 34, 38, 6] and 6 graph self-supervised learning (SSL) methods [15, 22, 53]. Among SSL methods, those with \u2018-1\u2019 in their names are one-stage SSL methods that use SSL losses as anomaly scores. Those with $\\rrangle_{-2},$ are two-stage SSL methods that (1) obtain graph embeddings the models learn via SSL and (2) employ a one-class classifier. For aggregation functions of MUSE (Eq. (6)), we use two aggregation functions: mean and standard deviation. Therefore, we represent each graph with a 4-dimensional vector, which is formalized in Appendix D.4. All methods use GIN [49] as a graph encoder. All two-stage approaches use an MLP autoencoder as a one-class classifier. Details of two-stage methods and the MLP autoencoder are in Appendix D.3. In addition, we provide further experimental details, including hyperparameter configurations, in Appendix D. ", "page_idx": 8}, {"type": "text", "text": "6.2 RQ1. Performance in graph-level anomaly detection ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "As shown in Table 1, MUSE outperforms all baseline methods in terms of average ranking. Two points stand out. First, in 8 out of 10 datasets, MUSE outperforms all other GLAD methods. Compared to the second-best GLAD method (OCGTL), MUSE achieves up to $16.2\\%$ performance gain (in the NCI1 dataset). Second, in 8 out of 10 datasets, MUSE outperforms all the SSL-based two-stage baselines (GraphCL-2, GAE-2, and GraphMAE-2). Given that they use the same one-class classifier with MUSE, this result demonstrates the effectiveness of the proposed error representation (Eq. (6)). ", "page_idx": 8}, {"type": "text", "text": "6.3 RQ2. Robustness against the training set contamination ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In real-world scenarios, training data may also contain anomalous graphs, making the robustness of GLAD methods against training set contamination crucial for their practical effectiveness. To assess this robustness, we inject anomalous graphs into the training set at rates of $10\\%$ , $20\\%$ , and $30\\%$ . 3 As shown in Figure 6, MUSE exhibits the least performance drop, among the three strongest GLAD methods, demonstrating its robustness. ", "page_idx": 8}, {"type": "image", "img_path": "e2INndPINB/tmp/7dbd006cd65793f87b6c4a3bed179ef1aa4bb17d265c50f776b854e2aa39e8d4.jpg", "img_caption": ["Figure 6: Comparison of the three strongest GLAD methods\u2019 robustness against training set contamination. MUSE undergoes the least performance drop among the three methods. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "6.4 RQ3. Error representation visualization ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We evaluate whether the error representation offered by MUSE can effectively distinguish graphs of different classes. We sample half of the graphs belonging to the same class to train MUSE. Then, we visualize the error representations generated by the trained MUSE for the rest half and graphs sampled from another class. As shown in Figure 7, the error representations produced by MUSE are distinguishable across different classes. ", "page_idx": 9}, {"type": "text", "text": "6.5 RQ4. Ablation study ", "text_level": 1, "page_idx": 9}, {"type": "image", "img_path": "e2INndPINB/tmp/acab45f2c20a7e7d65e6e5a5794d4a7d17636335a5c0687d3070eff2e4fcd7ec.jpg", "img_caption": ["Figure 7: PCA visualization of MUSE\u2019s error representations of graphs. Graphs belonging to different classes are wellseparated in the representation space. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Lastly, we provide an ablation study of MUSE. We aim to justify the two key components of MUSE: (1) the reconstruction errors $\\mathbb{L}_{\\mathbf{X}}$ and $\\mathbb{L}_{\\mathbf{A}}$ , and (2) multiple aggregation functions (specifically, mean and standard deviation). To this end, we leverage the following four variants of MUSE: ", "page_idx": 9}, {"type": "text", "text": "(V1) MUSE w/o LX: A variant that only leverages adjacency matrix reconstruction, (V2) MUSE w/o LA: A variant that only leverages node feature reconstruction, (V3) MUSE w/o STD: A variant that only leverages mean aggregation, (V4) MUSE w/o AVG: A variant that only leverages standard-deviation aggregation. ", "page_idx": 9}, {"type": "text", "text": "As shown in Table 1, MUSE with all components outperforms all of its variants in 8 out of 10 datasets, justifying the design choice of MUSE. ", "page_idx": 9}, {"type": "text", "text": "7 Discussions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we report and analyze an intriguing phenomenon, reconstruction flip of graph autoencoders (Graph-AEs). We investigate the phenomenon theoretically and empirically (Section 3) and further claim their implication in graph-level anomaly detection (GLAD; Section 4). Based on our analysis, we propose a novel GLAD method, MUSE (Section 5), and report its superior performance in GLAD via extensive experiments (Section 6). Below, we conclude the paper by discussing some potential limitations of our research, which could be addressed in future work. ", "page_idx": 9}, {"type": "text", "text": "More diverse and general primary patterns. In our analysis, we focus on the two patterns: community structures and a node cycle (Section 3). Although our claims hold for these patterns, a wide range of graph patterns remains unexplored in this work. Furthermore, a unified framework that can incorporate various graph patterns into a single pattern may exist. Further investigation into these patterns may improve our analysis, leading to new potential applications. ", "page_idx": 9}, {"type": "text", "text": "Scalability improvement. Since MUSE reconstructs the entire adjacency matrix of a graph (Eq. (3)), its time complexity for reconstruction is $O(n^{2})$ , where $n$ is the number of nodes in the graph. While this complexity is manageable for many real-world graph-level datasets (refer to Table 2), leveraging MUSE for large-scale graphs can be challenging. A simple technique that reconstructs only a sampled subset of an adjacency matrix results in a performance drop (refer to Appendix E.5). Therefore, improving the scalability of MUSE while preserving its detection performance is a non-trivial task, making it a promising direction for future research. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. RS-2024-00406985) $(90\\%)$ . This work was supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. RS-2019-II190075, Artificial Intelligence Graduate School Program (KAIST)) $(10\\%)$ . ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] K. M. Borgwardt, C. S. Ong, S. Sch\u00f6nauer, S. Vishwanathan, A. J. Smola, and H.-P. Kriegel. Protein function prediction via graph kernels. Bioinformatics, 21(1):i47\u2013i56, 2005.   \n[2] Z. Chen, Y. Fu, Y.-X. Wang, L. Ma, W. Liu, and M. Hebert. Image deformation meta-networks for one-shot learning. In CVPR, 2019.   \n[3] W.-L. Chiang, X. Liu, S. Si, Y. Li, S. Bengio, and C.-J. Hsieh. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. In KDD, 2019.   \n[4] M. Choe, S. Kim, J. Yoo, and K. Shin. Classification of edge-dependent labels of nodes in hypergraphs. In KDD, 2023.   \n[5] J. Dai, H. Qi, Y. Xiong, Y. Li, G. Zhang, H. Hu, and Y. Wei. Deformable convolutional networks. In ICCV, 2017.   \n[6] K. Ding, J. Li, R. Bhanushali, and H. Liu. Deep anomaly detection on attributed networks. In SDM, 2019.   \n[7] P. D. Dobson and A. J. Doig. Distinguishing enzyme structures from non-enzymes without alignments. Journal of molecular biology, 330(4):771\u2013783, 2003.   \n[8] I. J. Farkas, I. Der\u00e9nyi, A.-L. Barab\u00e1si, and T. Vicsek. Spectra of \u201creal-world\u201d graphs: Beyond the semicircle law. Physical Review E, 64(2):026704, 2001.   \n[9] S. Freitas, Y. Dong, J. Neil, and D. H. Chau. A large-scale database for graph representation learning. In NeurIPS, 2021.   \n[10] H. Gao and S. Ji. Graph u-nets. In ICML, 2019.   \n[11] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl. Neural message passing for quantum chemistry. In ICML, 2017.   \n[12] M. Girvan and M. E. Newman. Community structure in social and biological networks. Proceedings of the national academy of sciences, 99(12):7821\u20137826, 2002.   \n[13] Z. Guo, F. Wang, K. Yao, J. Liang, and Z. Wang. Multi-scale variational graph autoencoder for link prediction. In WSDM, 2022.   \n[14] W. Hamilton, Z. Ying, and J. Leskovec. Inductive representation learning on large graphs. In NeurIPS, 2017.   \n[15] Z. Hou, X. Liu, Y. Cen, Y. Dong, H. Yang, C. Wang, and J. Tang. Graphmae: Self-supervised masked graph autoencoders. In KDD, 2022.   \n[16] Z. Hou, Y. He, Y. Cen, X. Liu, Y. Dong, E. Kharlamov, and J. Tang. Graphmae2: A decodingenhanced masked self-supervised graph learner. In WWW, 2023.   \n[17] J. Kazius, R. McGuire, and R. Bursi. Derivation and validation of toxicophores for mutagenicity prediction. Journal of medicinal chemistry, 48(1):312\u2013320, 2005.   \n[18] S. Kim, D. Lee, Y. Kim, J. Park, T. Hwang, and K. Shin. Datasets, tasks, and training methods for large-scale hypergraph learning. Data Mining and Knowledge Discovery, 37(6):2216\u20132254, 2023.   \n[19] S. Kim, S. Kang, F. Bu, S. Y. Lee, J. Yoo, and K. Shin. Hypeboy: Generative self-supervised representation learning on hypergraphs. In ICLR, 2024.   \n[20] S. Kim, S. Y. Lee, Y. Gao, A. Antelmi, M. Polato, and K. Shin. A survey on hypergraph neural networks: an in-depth and step-by-step guide. In KDD, 2024.   \n[21] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR, 2015.   \n[22] T. N. Kipf and M. Welling. Variational graph auto-encoders. In NeurIPS Worksop of Bayesian Deep Learning, 2016.   \n[23] T. N. Kipf and M. Welling. Semi-supervised classification with graph convolutional networks. In ICLR, 2017.   \n[24] G. Kollias, V. Kalantzis, T. Id\u00e9, A. Lozano, and N. Abe. Directed graph auto-encoders. In AAAI, 2022.   \n[25] T. Lanciano, F. Bonchi, and A. Gionis. Explainable classification of brain networks via contrast subgraphs. In KDD, 2020.   \n[26] S. Laue, M. Mitterreiter, and J. Giesen. Computing higher order derivatives of matrix and tensor expressions. In NeurIPS, 2018.   \n[27] J. Lee, S. Kim, and K. Shin. Slade: Detecting dynamic anomalies in edge streams without labels via self-supervised learning. In KDD, 2024.   \n[28] S. Y. Lee, F. Bu, J. Yoo, and K. Shin. Towards deep attention in graph neural networks: Problems and remedies. In ICML, 2023.   \n[29] S. Y. Lee, S. Kim, F. Bu, J. Yoo, J. Tang, and K. Shin. Feature distribution on graph topology mediates the effect of graph convolution: Homophily perspective. In ICML, 2024.   \n[30] L. Liang, S. Kim, K. Shin, Z. Xu, S. Pan, and Y. Qi. Sign is not a remedy: Multiset-to-multiset message passing for learning on heterophilic graphs. In ICML, 2024.   \n[31] W. Liu, H. Chang, B. Ma, S. Shan, and X. Chen. Diversity-measurable anomaly detection. In CVPR, 2023.   \n[32] Y. Liu, K. Ding, Q. Lu, F. Li, L. Y. Zhang, and S. Pan. Towards self-interpretable graph-level anomaly detection. In NeurIPS, 2023.   \n[33] X. Luo, J. Wu, J. Yang, S. Xue, H. Peng, C. Zhou, H. Chen, Z. Li, and Q. Z. Sheng. Deep graph level anomaly detection with contrastive learning. Scientific Reports, 12(1):19867, 2022.   \n[34] R. Ma, G. Pang, L. Chen, and A. van den Hengel. Deep graph-level anomaly detection by glocal knowledge distillation. In WSDM, 2022.   \n[35] X. Ma, J. Wu, J. Yang, and Q. Z. Sheng. Towards graph-level anomaly detection via deep evolutionary mapping. In KDD, 2023.   \n[36] C. Morris, N. M. Kriege, F. Bause, K. Kersting, P. Mutzel, and M. Neumann. Tudataset: A collection of benchmark datasets for learning with graphs. In Workshop on Graph Representation Learning and Beyond $\\left(G R L+\\right.$ ), 2020.   \n[37] M. Neumann, R. Garnett, C. Bauckhage, and K. Kersting. Propagation kernels: efficient graph kernels from propagated information. Machine learning, 102:209\u2013245, 2016.   \n[38] C. Niu, G. Pang, and L. Chen. Graph-level anomaly detection via hierarchical memory networks. In ECML-PKDD, 2023.   \n[39] C. Qiu, M. Kloft, S. Mandt, and M. Rudolph. Raising the bar in graph-level anomaly detection. In IJCAI, 2022.   \n[40] K. Riesen and H. Bunke. Iam graph database repository for graph based pattern recognition and machine learning. In Structural, Syntactic, and Statistical Pattern Recognition: Joint IAPR International Workshop, pages 287\u2013297. Springer, 2008.   \n[41] N. Shervashidze, P. Schweitzer, E. J. Van Leeuwen, K. Mehlhorn, and K. M. Borgwardt. Weisfeiler-lehman graph kernels. Journal of Machine Learning Research, 12(9), 2011.   \n[42] J. J. Sutherland, L. A. O\u2019brien, and D. F. Weaver. Spline-fitting with a genetic algorithm: A method for developing classification structure- activity relationships. Journal of chemical information and computer sciences, 43(6):1906\u20131915, 2003.   \n[43] Q. Tan, N. Liu, X. Huang, S.-H. Choi, L. Li, R. Chen, and X. Hu. S2gae: self-supervised graph autoencoders are generalizable learners with graph masking. In WSDM, 2023.   \n[44] W. Tu, Q. Liao, S. Zhou, X. Peng, C. Ma, Z. Liu, X. Liu, Z. Cai, and K. He. Rare: Robust masked graph autoencoder. IEEE Transactions on Knowledge and Data Engineering, 36(10): 5340\u20135353, 2024.   \n[45] P. Veli\u02c7ckovi\u00b4c, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio. Graph attention networks. In ICLR, 2017.   \n[46] H. G. Vogel. Drug discovery and evaluation: pharmacological assays. Springer Science & Business Media, 2002.   \n[47] N. Wale, I. A. Watson, and G. Karypis. Comparison of descriptor spaces for chemical compound retrieval and classification. Knowledge and Information Systems, 14:347\u2013375, 2008.   \n[48] J. Xia, L. Wu, J. Chen, B. Hu, and S. Z. Li. Simgrace: A simple framework for graph contrastive learning without data augmentation. In WWW, 2022.   \n[49] K. Xu, W. Hu, J. Leskovec, and S. Jegelka. How powerful are graph neural networks? In ICLR, 2019.   \n[50] X. Yan, H. Cheng, J. Han, and P. S. Yu. Mining significant graph patterns by leap search. In SIGMOD, 2008.   \n[51] P. Yanardag and S. Vishwanathan. Deep graph kernels. In KDD, 2015.   \n[52] Z. Ying, J. You, C. Morris, X. Ren, W. Hamilton, and J. Leskovec. Hierarchical graph representation learning with differentiable pooling. In NeurIPS, 2018.   \n[53] Y. You, T. Chen, Y. Sui, T. Chen, Z. Wang, and Y. Shen. Graph contrastive learning with augmentations. In NeurIPS, 2020.   \n[54] G. Zhang, Z. Yang, J. Wu, J. Yang, S. Xue, H. Peng, J. Su, C. Zhou, Q. Z. Sheng, L. Akoglu, et al. Dual-discriminative graph neural network for imbalanced graph-level anomaly detection. In NeurIPS, 2022.   \n[55] Z. Zhang and L. Zhao. Unsupervised deep subgraph anomaly detection. In ICDM, 2022.   \n[56] L. Zhao and L. Akoglu. On using classification datasets to evaluate graph outlier detection: Peculiar observations and new insights. Big Data, 11(3):151\u2013180, 2023.   \n[57] L. Zhao, S. Sawlani, A. Srinivasan, and L. Akoglu. Graph anomaly detection with unsupervised gnns. In ICDM, 2022.   \n[58] Y. Zhou, H. Huo, Z. Hou, L. Bu, J. Mao, Y. Wang, X. Lv, and F. Bu. Co-embedding of edges and nodes with deep graph convolutional neural networks. Scientific Reports, 13(1):16966, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Proof ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we provide proof of each theorem presented in the paper. ", "page_idx": 13}, {"type": "text", "text": "A.1 Proof of Theorem 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Theorem 1 (Suspicious generalization across $\\tau$ ). For any $n\\geq12$ and $0<\\tau_{1}\\le1$ , there exists $\\epsilon>0$ such that for any $0<\\gamma\\leq\\epsilon$ and any $0<\\tau_{2}\\le1$ with the initial weight matrix $\\mathbf{W}^{(0)}=\\mathbb{I}_{n}$ , ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathcal{G}}[\\mathcal{L}(\\mathcal{G},\\mathbb{W}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))|\\tau_{2}]\\!\\!.\\ <\\qquad\\phantom{\\frac{1}{\\Delta x}}\\!\\!\\!\\!\\mathbb{E}_{\\mathcal{G}}[\\mathcal{L}(\\mathcal{G},\\mathbf{W}^{(0)})|\\tau_{2}]}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. Note that the reconstruction loss is defined as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}:=\\|\\mathbf{A}-\\mathbf{AXW}(\\mathbf{AXW})^{T}\\|_{F}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Here, since $\\mathbf{X}$ is identity, Eq. (7) is equal to $\\mathcal{L}:=||\\mathbf{A}-\\mathbf{A}\\mathbf{W}\\mathbf{W}\\mathbf{A}||_{F}^{2}$ . The derivative of Eq. (7) and its expectation are as follows [26]: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left.\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}}\\right|_{\\mathbf{W}=\\mathbb{I}_{n}}=2(\\mathbf{A}^{4}-\\mathbf{A}^{3}),\\;\\;\\;\\mathbf{\\Omega}}\\\\ {\\left.\\mathbb{E}_{\\mathbf{A}}\\left[\\left.\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}}\\right|_{\\mathbf{W}=\\mathbb{I}_{n}}\\right]=2(\\mathbb{E}[\\mathbf{A}^{4}]-\\mathbb{E}[\\mathbf{A}^{3}]).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Given $n$ (the total number of nodes) and $\\tau$ (the community strength), let $\\begin{array}{r}{N\\,=\\,\\frac{n}{2}}\\end{array}$ (the number of nodes in each community) and $\\begin{array}{r}{p=\\frac{1+\\tau}{2}}\\end{array}$ (the inner-community edge probability), we have ", "page_idx": 13}, {"type": "text", "text": "(1) If $i=j$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathbf{A}_{i j}^{3}]=(N-1)(N-2)p^{3}+2N(N-1)p(1-p)^{2}+N(N-1)p(1-p)^{2},}\\\\ &{\\qquad\\quad=(N-1)(N-2)p^{3}+3N(N-1)p(1-p)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "and ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathfrak{L}[\\mathbf{A}_{i j}^{4}]=(N-1)(N-2)(N-3)p^{4}+(N-1)(N-2)p^{2}+(N-1)(N-2)p^{2}+(N-1)p}&{}\\\\ {+\\,2(N-1)(N-2)N p^{2}(1-p)^{2}+2N(N-1)p(1-p)^{2}}&{}\\\\ {+\\,(N-1)(N-2)N p^{2}(1-p)^{2}+(N-1)N p(1-p)}&{}\\\\ {+\\,2N^{2}(N-1)p^{2}(1-p)^{2}+N(N-1)^{2}(1-p)^{4}+N(N-1)(1-p)^{2}+N(N-1)(1-p)^{2}}&{}\\\\ {+\\,N(N-1)(N-2)p^{2}(1-p)^{2}+N(N-1)p(1-p),}&{}\\\\ {=(-6+11N-6N^{2}+N^{3})p^{4}+2(-1+N)p^{2}(-2+N-4N(1-p)^{2}+3N^{2}(1-p)^{2})}&{}\\\\ {+\\,N(1-p)(1+2(-1+N)(1-p)+(-1+N)^{2}(1-p)^{3})}&{}\\\\ {+\\,p(-1+2N^{2}(1-p)(1+(1-p))+N(1-2(1-p)-2(1-p)^{2})),}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "(2) If $i$ and $j$ are in the same group: ", "text_level": 1, "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{I}[\\mathbf{A}_{i j}^{3}]=(N-2)(N-3)p^{3}+p+2N(N-2)p(1-p)^{2}+2N p(1-p)+N(N-1)p(1-p)^{2},}\\\\ &{\\qquad=(N-2)(N-3)p^{3}+N(3N-5)p(1-p)^{2}+p+2N p(1-p),}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\xi[\\mathbf{A}_{i j}^{4}]=(N-2)(N-3)(N-4)p^{4}+(N-2)(N-3)p^{3}+2(N-2)(N-3)p^{3}+2(N-2)p^{3}}\\\\ &{\\hphantom{=}+(N-2)p^{3}+2(N-2)(N-3)p^{4}+2(N-2)p^{2}}\\\\ &{\\hphantom{=}+2(N-2)(N-3)N p^{2}(1-p)^{2}+2(N-2)N p(1-p)^{2}+2N p(1-p)^{2}+2(N-2)N p}\\\\ &{\\hphantom{=}+(N-2)(N-3)N p^{2}(1-p)^{2}+2(N-2)N p^{2}(1-p)^{2}+N p(1-p)^{2}+2N(N-1)(N-2)p^{2}}\\\\ &{\\hphantom{=}+2N(N-1)p^{2}(1-p)^{2}+N(N-1)(N-2)(1-p)^{4}+N(N-2)(1-p)^{3}+2N(N-1)(N-2)p^{2}}\\\\ &{\\hphantom{=}+2N(1-p)^{2}+N(N-1)(N-2)p^{2}(1-p)^{2}+N(N-1)p(1-p)^{2},}\\\\ &{\\hphantom{=}3(-2+N)^{2}p^{3}+(-3+N)(-2+N)^{2}p^{4}+N(-2+3N)p(1-p)^{2}}\\\\ &{\\hphantom{=}+N(1-p)^{2}(2+(-2+N)(1-p)+(-1+N)N(1-p)^{2})}\\\\ &{\\hphantom{=}+2p^{2}(-2+N+7N(1-p)^{2}-9N^{2}(1-p)^{2}+3N^{3}(1-p)^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "(3) If $i$ and $j$ are in different groups ", "text_level": 1, "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathbf{A}_{i j}^{3}]=2(N-1)(N-2)p^{2}(1-p)+2(N-1)p(1-p)}\\\\ &{\\qquad\\qquad+\\,(N-1)^{2}p^{2}(1-p)+(N-1)^{2}(1-p)^{3}+(1-p),}\\\\ &{\\qquad\\qquad=(N-1)(3N-5)p^{2}(1-p)+(N-1)^{2}(1-p)^{3}+2(N-1)p(1-p)+(1-p),}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\dot{z}[\\mathbf{A}_{\\ell}^{4}]=(N-1)(N-2)(N-3)p^{8}(1-p)+(N-1)(N-2)p^{8}(1-p)+(N-1)(N-2)p^{2}(1-p)}\\\\ &{+(N-1)(N-2)p^{2}(1-p)+(N-1)p(1-p)+(N-1)^{2}(N-2)p^{8}(1-p)}\\\\ &{+(N-1)(N-2)p^{2}(1-p)+(N-1)^{2}(N-2)p(1-p)^{3}+(N-1)^{2}p(1-p)^{3}}\\\\ &{+(N-1)(N-2)p(1-p)^{2}+(N-1)p(1-p)^{2}+(N-1)^{2}p(1-p)^{2}+(N-1)p(1-p)}\\\\ &{+(N-1)^{2}(N-2)p^{8}(1-p)+(N-1)^{2}p^{2}(1-p)+(N-1)^{2}(N-2)p(1-p)^{3}}\\\\ &{+(N-1)^{2}p(1-p)^{2}+(N-1)(N-2)p(1-p)^{3}+(N-1)^{2}p(1-p)^{3}+(N-1)p(1-p)}\\\\ &{+(N-1)p(1-p)^{2}+(N-1)^{2}(N-2)p(1-p)^{3}+(N-1)(N-2)p(1-p)^{2}}\\\\ &{+(N-1)^{2}p(1-p)^{3}+(N-1)^{2}p(1-p)^{2}+(N-1)p(1-p)^{2}+(N-1)p(1-p)}\\\\ &{+(N-1)^{2}(N-2)p(1-p)^{3}+(N-1)^{2}p(1-p)^{3}+(N-1)^{2}p(1-p)^{3}+(N-1)(N-1)}\\\\ &{+(N-1)p(1-p)^{2}+(N-1)p(1-p)^{2}+(N-1)(N-2)(N-3)p^{3}(1-p)}\\\\ &{+(N-1)(N-2)p^{2}(1-p)+(N-1)(N-2)p^{2}(1-p)+(N-1)p(1-p)}\\\\ &{=(-1+N)p(1-p)\\Delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\hat{\\Sigma}=4+(-11+6N)p+(14-15N+4N^{2})p^{2}+(-1+5N)(1-p)+(-1-5N+4N^{2})(1-p)^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, the entries in ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}_{A}[\\mathbf{A}^{4}-\\mathbf{A}^{3}]=\\frac{1}{2}\\mathbb{E}\\mathbf{A}\\left[\\left.\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{W}}\\right|_{\\mathbf{W}=\\mathbb{I}_{n}}\\right]\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "have three different values: (1) $i$ and $j$ are equal, (2) $i\\neq j$ and $v_{i}$ and $v_{j}$ belong to the same group, and (3) $i\\neq j$ and $v_{i}$ and $v_{j}$ belong to the different groups. Thus, we can express $\\mathbb{E}_{A}[\\mathbf{A}^{4}-\\mathbf{A}^{3}]$ as $a\\mathbf{I}+b\\mathbf{P}+c\\mathbf{U}$ , where $a,b,c\\in\\mathbb{R}$ and $\\mathbf{P}$ and $\\mathbf{U}$ are defined as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\bf P}=\\left(\\begin{array}{l l}{{{\\bf1}}}&{{{\\bf0}}}\\\\ {{{\\bf0}}}&{{{\\bf1}}}\\end{array}\\right),\\mathrm{~and~}{\\bf U}=\\left(\\begin{array}{l l}{{{\\bf0}}}&{{{\\bf1}}}\\\\ {{{\\bf1}}}&{{{\\bf0}}}\\end{array}\\right),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\mathbf{1}\\in\\{1\\}^{N\\times N}$ and $\\mathbf{0}\\in\\{0\\}^{N\\times N}$ . ", "page_idx": 14}, {"type": "text", "text": "Specifically, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{a=3(N-2)(N-3)p^{4}+2N(4N-6)p(1-p)^{2}+N(N-1)(1-p)^{4}}\\\\ &{b=(N-2)(N-3)p^{3}((N-4)p-1)+N(3N-5)p(1-p)^{2}(2(N-2)p-1)}\\\\ &{\\;\\;\\;\\;\\;\\;+\\;N(N-1)(N-2)(1-p)^{4},}\\\\ &{\\;\\;\\;\\;\\;=N^{3}(1-4p+12p^{2}-16p^{3}+8p^{4})+N^{2}(-3+9p-34p^{2}+52p^{3}-34p^{4})}\\\\ &{\\;\\;\\;\\;\\;\\;\\;+\\;N(2-3p+22p^{2}-38p^{3}+48p^{4})-6p^{3}(1+4p)}\\\\ &{c=(N-1)p^{2}(1-p)(4(N-2)^{2}p-3N+5)+(N-1)(1-p)^{3}(4(N-2)^{2}p-N+1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For any training graphs with $0<\\tau_{1}\\le1$ , i.e., $0.5<p\\leq1$ , we have ", "page_idx": 15}, {"type": "text", "text": "Thus, $a,b,c>0$ for any $N\\geq6$ (i.e., $n\\geq12$ ) hold. ", "page_idx": 15}, {"type": "text", "text": "Let $W^{\\prime}=\\mathbb{W}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma)$ be the updated $W$ after one step of gradient descent with learning rate $\\gamma$ trained on graphs with $\\tau_{1}$ (and $n$ ). Now, we derive the reconstruction loss on test graphs computed with $W^{\\prime}$ . Formally, reconstruction loss by using $W^{\\prime}$ is defined as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{L}=\\|\\mathbf{A}-\\mathbf{A}W^{\\prime}(\\mathbf{A}W^{\\prime})^{T}\\|_{2}^{2}=\\|\\mathbf{A}-\\mathbf{A}(W^{\\prime})^{2}\\mathbf{A}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We further simplify $(W^{\\prime})^{2}$ as follows: ", "page_idx": 15}, {"type": "equation", "text": "$$\n(W^{\\prime})^{2}=\\mathbf{I}+2(\\epsilon_{1}\\mathbf{I}+\\epsilon_{2}\\mathbf{P}+\\epsilon_{3}\\mathbf{U})+(\\epsilon_{1}\\mathbf{I}+\\epsilon_{2}\\mathbf{P}+\\epsilon_{3}\\mathbf{U})^{2},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\begin{array}{r}{\\epsilon_{1}=-\\frac{1}{2}\\gamma a,\\epsilon_{2}=-\\frac{1}{2}\\gamma b.}\\end{array}$ , and $\\epsilon_{3}=-\\textstyle{\\frac{1}{2}}\\gamma c$ . ", "page_idx": 15}, {"type": "text", "text": "To simplify Eq. (10), we use the property that $\\mathbf{P}^{2}\\,=\\,N\\mathbf{P}$ , ${\\mathbf{U}}^{2}\\,=\\,N{\\mathbf{U}}$ , and $\\mathbf{PU}=\\mathbf{U}\\mathbf{P}=N\\mathbf{U}$ . Using these facts, we rewrite Eq. (10) as below: ", "page_idx": 15}, {"type": "text", "text": "$(W^{\\prime})^{2}=\\mathbf{I}+2(\\epsilon_{1}\\mathbf{I}+\\epsilon_{2}\\mathbf{P}+\\epsilon_{3}\\mathbf{U})+(\\epsilon_{1}^{2}\\mathbf{I}+\\epsilon_{2}^{2}N\\mathbf{P}+\\epsilon_{3}^{2}N\\mathbf{U})+2\\epsilon_{1}\\epsilon_{2}\\mathbf{P}+2\\epsilon_{1}\\epsilon_{3}\\mathbf{U}+2\\epsilon_{2}\\epsilon_{3}N\\mathbf{U},$ (11) where ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\alpha_{1}=2\\epsilon_{1}+\\epsilon_{1}^{2}}}\\\\ {{\\alpha_{2}=2\\epsilon_{2}+N\\epsilon_{2}^{2}+2\\epsilon_{1}\\epsilon_{2}}}\\\\ {{\\alpha_{3}=2\\epsilon_{3}+N\\epsilon_{3}^{2}+2\\epsilon_{1}\\epsilon_{3}+2N\\epsilon_{2}\\epsilon_{3}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Now, by using the derived results, we rewrite the reconstruction loss term Eq. (9) as below: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{L}=\\|\\mathbf{A}-\\mathbf{A}(\\mathbf{I}+\\alpha_{1}\\mathbf{I}+\\alpha_{2}\\mathbf{P}+\\alpha_{3}\\mathbf{P})\\mathbf{A}\\|_{F}^{2}=\\|(\\mathbf{A}-\\mathbf{A}^{2})-(\\alpha_{1}\\mathbf{A}^{2}+\\alpha_{2}\\mathbf{A}\\mathbf{P}\\mathbf{A}+\\alpha_{3}\\mathbf{A}\\mathbf{U}\\mathbf{A})\\|_{F}^{2},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{(APA)}_{i j}=\\displaystyle\\sum_{k,\\,\\ell\\,\\mathrm{in\\,the\\;same\\;group}}\\mathbf{A}_{i k}\\mathbf{A}_{j l}}\\\\ {\\mathbf{(AUA)}_{i j}=\\displaystyle\\sum_{k,\\,\\ell\\,\\mathrm{in\\,different\\;groups}}\\mathbf{A}_{i k}\\mathbf{A}_{j l}}\\\\ {\\mathbf{(A}^{2})_{i j}=\\displaystyle\\sum_{k}\\mathbf{A}_{i k}\\mathbf{A}_{j k}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We can decompose the loss by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{L}=\\sum_{i,j}\\big(\\mathbf{A}_{i j}-(1+\\alpha_{1})(\\mathbf{A}^{2})_{i j}-\\alpha_{2}(\\mathbf{A}\\mathbf{P}\\mathbf{A})_{i j}-\\alpha_{3}(\\mathbf{A}\\mathbf{U}\\mathbf{A})_{i j}\\big))^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Given $i$ and $j$ , let $x=A_{i j}$ , $y=(\\mathbf{A}^{2})_{i j}$ , $z=(\\mathbf{A}\\mathbf{P}\\mathbf{A})_{i j}$ , and $w=(\\mathbf{AUA})_{i j}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal L_{i j}=(x-(1+\\alpha_{1})y-\\alpha_{2}z-\\alpha_{3}w)^{2}}\\\\ &{\\qquad=x^{2}+-2(1+\\alpha_{1})x y-2\\alpha_{2}x z-2\\alpha_{3}x w+(1+\\alpha_{1})^{2}y^{2}}\\\\ &{\\qquad\\quad+\\,2(1+\\alpha_{1})\\alpha_{2}y z+2(1+\\alpha_{1})\\alpha_{3}y w+\\alpha_{2}^{2}z^{2}+2\\alpha_{2}\\alpha_{3}z w+\\alpha_{3}^{2}w^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $\\bar{\\mathcal{L}}_{i j}=(\\mathbf{A}_{i j}-(\\mathbf{A}^{2})_{i j})^{2}=(x-y)^{2}$ . By using this notation, we derive the following result: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{i j}-\\bar{\\mathcal{L}}_{i j}=-2\\alpha_{1}x y-2\\alpha_{2}x z-2\\alpha_{3}x w+\\alpha_{1}(\\alpha_{1}+2)y^{2}\\qquad\\qquad\\qquad\\qquad\\quad}\\\\ {+\\;2(1+\\alpha_{1})\\alpha_{2}y z+2(1+\\alpha_{1})\\alpha_{3}y w+\\alpha_{2}^{2}z^{2}+2\\alpha_{2}\\alpha_{3}z w+\\alpha_{3}^{2}w^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We shall show that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\sum_{i,j}(\\mathcal{L}_{i j}-\\bar{\\mathcal{L}}_{i j})]<0.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "As $\\gamma\\to0^{+}$ , ignoring higher-order terms and keeping the term linear w.r.t. $\\gamma$ , it suffices to show that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{i,j}a(\\mathbb{E}[x y]-\\mathbb{E}[y^{2}])+b(\\mathbb{E}[x z]-\\mathbb{E}[y z])+c(\\mathbb{E}[x w]-\\mathbb{E}[y w])<0.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Note: In the following derivation, $p$ is from test graphs (i.e., $\\begin{array}{r}{p=\\frac{\\tau_{2}+1}{2}.}\\end{array}$ ). ", "page_idx": 16}, {"type": "text", "text": "(1) If $i=j$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\alpha(x+\\ell)}{2(x)}=0}\\\\ &{\\hat{x}[\\mathcal{Z}]=0}\\\\ &{\\hat{y}[\\mathcal{Z}]=0}\\\\ &{\\hat{z}[\\mathcal{Y}]=(N-1)p+(N-1)(N-2)p^{2}+N(1-p)+N(N-1)(1-p)^{2}+2N(N-1)p(1-p)}\\\\ &{\\quad\\quad=N^{2}+N(-2)p^{2}+(2p^{2}-p)}\\\\ &{\\hat{y}[\\mathcal{Z}]=(N-1)(N-2)(N-3)p^{3}+3(N-1)(N-2)p^{2}+(N-1)p}\\\\ &{\\quad\\quad\\quad+N(N-1)^{2}p(1-p)^{2}+N(N-1)p(1-p)}\\\\ &{\\quad\\quad\\quad+N(N-1)(N-2)p^{2}(1-p)+N(N-1)p(1-p)}\\\\ &{\\quad\\quad\\quad+N(N-1)(N-2)(1-p)^{3}+3N(N-1)(1-p)+N(1-p)}\\\\ &{\\quad\\quad\\quad+N^{3}(1-p+2p^{2}+N^{2}(3p-4p^{2}-2p^{3})}\\\\ &{\\quad\\quad\\quad+N(-p-4p^{2}+N p)^{3}+(-p+6p^{2}-6p^{3})}\\\\ &{\\quad\\quad\\quad=N(N-1)(N-2)p^{2}(1-p)+(N-1)(N-1)p}\\\\ &{\\quad\\quad\\quad+N(N-1)(N-2)p^{2}(1-p)+2N(N-1)p}\\\\ &{\\quad\\quad\\quad+N^{3}(N-1)(N-1)p^{2}+N(N-1)p-2p^{3}}\\\\ &{\\quad\\quad\\quad\\quad+N^{2}(N-2)p^{2}+N p^{2})-2N(N-1)(p-2p-2p^{3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Hence, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{11}:=\\mathbb{E}[x y]-\\mathbb{E}[y^{2}]=-N^{2}+N(2p^{2})+(p-2p^{2})}\\\\ &{d_{12}:=\\mathbb{E}[x z]-\\mathbb{E}[y z]=N^{3}(-1+2p-2p^{2})+N^{2}(-3p+4p^{2}+2p^{3})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\,N(p+4p^{2}-8p^{3})+(p-6p^{2}+6p^{3})}\\\\ &{d_{13}:=\\mathbb{E}[x w]-\\mathbb{E}[y w]=N^{3}(-2p+2p^{2})+N^{2}(-2p^{3}+2p^{2})+N(-4p^{2}+2p+2p^{3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "(2) Else if $i$ and $j$ are in the same group ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\{x\\}=\\mathbb{E}\\{y|y|=N\\}(1-y+2p+2p^{*})-2p^{*}}\\\\ &{\\mathbb{E}\\{x\\}=\\mathbb{E}\\{z\\}=\\mathbb{E}^{2}\\{\\hat{x}\\}=\\mathcal{N}^{2}\\{1-x^{2}y}(1-2p+2p^{*})-2N^{2}y+p^{*}}\\\\ &{\\hat{\\mathcal{L}}\\{x\\}=\\hat{y}\\{x\\}=\\hat{z}\\}\\\\ &{\\hat{\\mathcal{L}}\\{y\\}=\\hat{x}\\ |\\hat{x}-2\\hat{y}|^{2}-2p^{*})+\\hat{\\mathcal{N}}\\{y\\}+\\mathcal{N}\\{y\\}-p^{*}}\\\\ &{\\hat{\\mathcal{L}}\\{y\\}=\\hat{x}-2\\hat{y}-12\\hat{y}-12\\hat{y}-11+\\hat{\\mathcal{N}}\\{y\\}+\\mathcal{N}\\{X\\}(1-y)^{2}+\\hat{N}(X-1)(1-p)^{4}+2N(N-2)p^{*}(1-p)}\\\\ &{\\hat{\\mathcal{L}}\\{y\\}=(N-1)2\\hat{y}+\\hat{\\mathcal{L}}\\{x\\}-2p^{*})-2N^{2}y+1+\\hat{\\mathcal{N}}\\{y\\}-5p^{*}}\\\\ &{\\hat{\\mathcal{L}}\\{y\\}=(N-2)(N-3)(N-4p^{*}+2N(N-2)(N-3)p^{*}+(N-2)p^{*})}\\\\ &{+(N-2)(N-3)p^{*}+2(N-2)(N-3)p^{*}+(N-2)p^{*}}\\\\ &{+N(N-1)(N-2)(N-1)^{2}+N(N-2)p^{*}(1-p)}\\\\ &{+N(N-1)(N-3)(N-1)p^{*}(1-p)^{2}+N(N-2)p^{*}(1-p)}\\\\ &{+N(N-1)(N-2)(N-2)p^{*}(1-p)+N(N-2)p^{*}}\\\\ &{+N(N-1)(N-2)(N-3)p^{*}(1-p)}\\\\ &{=N^{3}(1-p+2p^{*})-2p^{*}(1-p+3p^{*})}\\\\ &{+N^{2}(N^{3}-15p+2q^{*})-16p^{*}-112p^{*}+21p^{*})(2p^{*})}\\\\ &{\\hat{\\mathcal{L} \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence, ", "text_level": 1, "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{21}:=\\mathbb{E}[x y]-\\mathbb{E}[y^{2}]=-N^{2}(1-2p+2p^{2})^{2}+N p(-1+6p-10p^{2}+10p^{3})+2p^{2}(1-p-3p^{2})}\\\\ &{d_{22}:=\\mathbb{E}[x z]-\\mathbb{E}[y z]=-N^{3}(1-2p+2p^{2})^{2}+p^{2}(2-9p+6p^{2})}\\\\ &{\\phantom{d_{21}:=\\mathbb{E}[x y]-\\mathbb{E}[y z]=-N^{3}(1-1p+2p^{2}-20p^{3})+N^{2}p(-2+13p-22p^{2}+16p^{3})}\\\\ &{\\phantom{d_{21}:=\\mathbb{E}[x w]-\\mathbb{E}[y w]=2N(-1+p)p(N(-1+3p-6p^{2})+N^{2}(1-2p+2p^{2})+2(-1+p+2p^{2}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "(3) Else if $i$ and $j$ are in different groups ", "text_level": 1, "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad=(1-p)\\xi\\xi\\xi\\eta-2(N-1)\\psi^{(1)}-p\\xi^{\\prime}}\\\\ &{\\quad=(-1-p)\\xi\\xi\\xi-2(N-1)\\psi^{(1)}-2p^{\\prime}(1-p)^{3}}\\\\ &{\\quad=(1-p)\\xi\\xi\\xi-(1-p)\\xi\\eta-(1-p)\\xi\\eta^{(2)}(1-p)^{3}}\\\\ &{\\quad=(1-p)(1-p)\\xi+2(N-1)(N-2)p^{\\prime}(1-p)^{3}+2(N-1)\\psi^{(2)}}\\\\ &{\\quad=2(N-1)\\psi(1-p)+2(N-1)(2N-3)\\psi^{(1)}-2(N-2)\\psi^{(2)}(1-p)^{2}}\\\\ &{\\quad=2(N-1)(N-2)(N-1)\\psi^{(2)}-2p^{\\prime}(1-p)^{3}}\\\\ &{\\quad=2(N-1)(N-2)(N-1)\\psi^{(2)}-2p^{\\prime}(1-p)\\chi-(1)(N-2)\\psi^{(2)}}\\\\ &{\\quad=2(N-1)(N-2)\\psi^{(2)}(1-p)+2(N-1)\\psi^{(1)}}\\\\ &{\\quad=2(N-1)(N-2)\\psi^{(2)}(1-p)^{2}+2(N-1)\\psi^{(2)}}\\\\ &{\\quad=2(N-1)(N-2)(N-1)\\psi^{(2)}+2(N-1)\\psi^{(2)}(1-p)^{2}}\\\\ &{\\quad=(1-p)\\xi\\left(N-2)\\psi^{(1)}-2(N-1)\\psi^{(2)}-2p^{\\prime}(1-p)^{2}\\right.}\\\\ &{\\quad\\left.+N(N-1)\\psi^{(2)}(1-p)^{2}+2(N-1)\\psi^{(1)}-2\\psi^{(2)}(1-p)^{3}\\right.}\\\\ &{\\quad=2(N-1)^{2}(N-2)\\psi^{(1)}(1-p)^{3}+2(N-1)\\psi^{(1)}}\\\\ &{\\quad\\quad+(N-1)(N-2)(N-1)\\psi^{(1)}+2(N-1)\\psi^{(2)}(1-p)^{3}}\\\\ &{\\quad\\quad+(N-1)(N-2)(N-1)\\psi^{(1)}+(N-1)\\psi^{(2)}(1-p)^{2}}\\\\\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{31}:=\\mathbb{E}[x y]-\\mathbb{E}[y^{2}]=-2(-1+N)(2+2N(-1+p)-3p)(-1+p)p^{2}}\\\\ &{d_{32}:=\\mathbb{E}[x z]-\\mathbb{E}[y z]=-2(-1+N)^{2}(2+2N(-1+p)-3p)(-1+p)p^{2}}\\\\ &{d_{33}:=\\mathbb{E}[x w]-\\mathbb{E}[y w]=(-1+p)(p(-1+2p-4p^{2})+2N^{3}p(1-2p+2p^{2})}\\\\ &{\\phantom{d_{33}}:=\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\,N p(3-8p+13p^{2})-N^{2}(1+2p-9p^{2}+13p^{3}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Conclusion. ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Recall that $a,b,c>0$ for any $n\\geq12$ and $0<\\tau_{1}\\le1$ and we aim to show that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{i,j}a(\\mathbb{E}[x y]-\\mathbb{E}[y^{2}])+b(\\mathbb{E}[x z]-\\mathbb{E}[y z])+c(\\mathbb{E}[x w]-\\mathbb{E}[y w])<0.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "It suffices to show that, for any $0.5<p\\leq1$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{i,j}(\\mathbb{E}[x y]-\\mathbb{E}[y^{2}])\\leq0\\sum_{i,j}(\\mathbb{E}[x z]-\\mathbb{E}[y z])\\leq0\\sum_{i,j}(\\mathbb{E}[x w]-\\mathbb{E}[y w])\\leq0\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "with at least one inequality being strict. Since there are ", "page_idx": 18}, {"type": "text", "text": "\u2022 $2N$ pairs of $(i,j)$ such that $i=j$ , \u2022 $2N(N-1)$ pairs of $(i,j)$ such that $i\\neq j$ and $i$ and $j$ are in the same group, and \u2022 $2N^{2}$ pairs of $(i,j)$ such that $i\\neq j$ and $i$ and $j$ are in different groups, ", "page_idx": 18}, {"type": "text", "text": "it is equivalent to showing that ", "page_idx": 18}, {"type": "equation", "text": "$$\nd_{1i}+(N-1)d_{2i}+N d_{3i}\\leq0,\\forall i\\in\\{1,2,3\\},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and at least for one $i$ value, the inequality is strict. ", "page_idx": 18}, {"type": "text", "text": "Indeed, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{+\\left(N-1\\right)\\!d_{21}+N d_{31}=-N^{4}(1-2p+2p^{2})^{2}+2N p(-1+6p-12p^{2}+10p^{3})}}\\\\ {{+\\left.N^{2}(-1+4p-17p^{2}+29p^{3}-26p^{4})+N^{3}(1-6p+17p^{2}-22p^{3}+10p^{2}+0.0002p^{4})\\right.}}\\\\ {{+\\left.(p-4p^{2}+9p^{3}-6p^{4})<0}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for any $N\\ge4$ ; ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\iota_{12}+(N-1)d_{22}+N d_{32}=N^{4}(-1+4p-12p^{2}+16p^{3}-8p^{4})+N^{3}p(-4+31p-56p^{2}+34p^{3}}\\\\ &{\\hphantom{\\frac{12p^{2}+(N-1)d_{32}+\\frac{12p^{2}}{2\\rho}}}+N^{2}(p-33p^{2}+77p^{3}-52p^{4})+N p(-1+22p-52p^{2}+32p^{3})}\\\\ &{\\hphantom{\\frac{12p^{2}+(N-1)d_{32}+\\frac{12p^{2}}{2\\rho}}}+p-8p^{2}+15p^{3}-6p^{4}<0}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for any $N\\geq3$ ; ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{13}+(N-1)d_{23}+N d_{33}=N(-1+p)(p-12p^{3}+4N^{3}p(1-2p+2p^{2})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\;N p(1-12p+33p^{2})-N^{2}(1+4p-19p^{2}+29p^{3}))<0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for any $N\\geq2$ . ", "page_idx": 18}, {"type": "text", "text": "In conclusion, when trained with any $0.5\\,<\\,p_{t r a i n}\\,\\leq\\,1$ (i.e., $0\\,<\\,\\tau_{1}\\,\\leq\\,1\\,\\$ ) and $N_{t r a i n}\\,\\geq\\,6$ (i.e., $n\\geq12\\$ ), as $\\gamma$ approaches $0^{+}$ , for any $0.5<p_{t e s t}\\le1$ (i.e., $0<\\tau_{2}\\leq1$ ), ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{1}:=d_{11}+(N-1)d_{21}+N d_{31}<0}\\\\ &{d_{2}:=d_{12}+(N-1)d_{22}+N d_{32}<0}\\\\ &{d_{3}:=d_{13}+(N-1)d_{23}+N d_{33}\\leq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "completing the proof. ", "page_idx": 18}, {"type": "text", "text": "A.2 Proof of Theorem 2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Theorem 2 (Correlation with $\\tau$ ). For any $n\\geq34$ and $0<\\tau_{1}\\le0.98$ , there exists $\\epsilon>0$ such that for any $0<\\gamma\\leq\\epsilon$ and any $\\tau_{1}+0.02\\leq\\tau_{2}\\leq1$ with the initial weight $\\mathbf{W}^{(0)}=\\mathbb{I}_{n}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathcal{G}}\\left[\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\mathbf{W}^{(0)})-\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\boldsymbol{\\mathbb{W}}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))\\mid\\tau_{1}\\right]<\\mathbb{E}_{\\mathcal{G}}\\left[\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\mathbf{W}^{(0)})-\\mathcal{L}(\\boldsymbol{\\mathcal{G}},\\boldsymbol{\\mathbb{W}}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))\\mid\\tau_{2}\\right],\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Following the notations in the proof of Theorem 1 above, regarding the \u201cspeed\u201d of gradient, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\partial d_{1}}{\\partial p}=4N^{4}(1-4p+6p^{2}-4p^{3})+N^{3}(-6+34p-66p^{2}+64p^{3})}\\\\ &{\\qquad+N^{2}(4-34p+87p^{2}-104p^{3})+N(-2+24p-72p^{2}+80p^{3})}\\\\ &{\\qquad+(1-8p+27p^{2}-24p^{3})}\\\\ &{\\frac{\\partial d_{2}}{\\partial p}=4N^{4}(1-2p)^{3}+2N^{3}(-2+31p-84p^{2}+68p^{3})}\\\\ &{\\qquad+N^{2}(1-66p+231p^{2}-208p^{3})+N(-1+44p-156p^{2}+128p^{3})}\\\\ &{\\qquad+(1-16p+45p^{2}-24p^{3})}\\\\ &{\\frac{\\partial d_{3}}{\\partial p}=4N^{4}(-1+2p)^{3}+N^{3}(3-46p+144p^{2}-116p^{3})}\\\\ &{\\qquad+N^{2}(-1+26p-135p^{2}+132p^{3})+N(-1+2p+36p^{2}-48p^{3}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Trained with $\\begin{array}{r}{p^{\\prime}=\\frac{\\tau_{1}+1}{2}}\\end{array}$ and testing with $\\begin{array}{r}{p=\\frac{\\tau_{2}+1}{2}}\\end{array}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\alpha(N,p)\\frac{\\partial d_{1}(N,p)}{\\partial p}+b(N,p^{\\prime})\\frac{\\partial d_{2}(N,p)}{\\partial p}+c(N,p^{\\prime})\\frac{\\partial d_{3}(N,p)}{\\partial p}}\\\\ &{=-((-1+N)N(-1+2p+3q^{2}p^{2}-48p^{3}+4N^{3}(-1+2p)^{3}+N^{2}(3-46p+144p^{2}-116p^{3})}\\\\ &{\\quad+N(-1+26p-135p^{2}+132p^{3}))(-1+p^{\\prime})(1+14p^{\\prime}-26p^{2}+32p^{3}+4N^{2}p^{2}(1-2p^{\\prime}+2p^{\\prime}}\\\\ &{\\quad-N(1+1\\mu^{\\prime}-28p^{2}+32p^{3}))-(-1+8p-27p^{2}+24p^{3}+N(2-24p+72p^{2}-80p^{3})}\\\\ &{\\quad+N^{3}(6-34p+66p^{2}-64p^{3})+4N^{4}(-1+4p-6p^{2}+4p^{3})}\\\\ &{\\quad+N^{2}(-4+34p-87p^{2}+104p^{3}))(18p^{4}+N^{2}(1+4p^{\\prime}-10p^{2}+4p^{3}+4p^{4})}\\\\ &{\\quad-N(1+8p^{\\prime}-18p^{2}+8p^{3}+16p^{4}))-(-1+16p-45p^{2}+24p^{3}+4N^{4}(-1+2p)^{3}}\\\\ &{\\quad+N(1-4p+156p^{2}-128p^{3})}\\\\ &{\\quad-2N^{3}(-2+31p-84p^{2}+68p^{3})+N^{2}(-1+66p-231p^{2}+208p^{3})(-6p^{3}(1+4p^{\\prime})}\\\\ &{\\quad+N^{2}(-3+9p^{2}-34p^{2}+52p^{3}-34p^{4})+N^{3}(1-4p^{\\prime}+12p^{2}-16p^{3}+8p^{4})}\\\\ &{\\quad+N(2-3p^{2}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Given p1 = $\\begin{array}{r}{p_{1}=\\frac{\\tau_{1}+2}{2}}\\end{array}$ and $\\begin{array}{r}{p_{2}=\\frac{\\tau_{2}+2}{2}}\\end{array}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha=(-1+\\eta_{1}-2\\xi_{2})^{2}+2\\xi_{1}^{2}+3\\xi_{2}^{2}+(2-2\\xi_{1}+72\\xi_{2}-3\\xi_{1})^{2}+3\\xi_{2}^{2}+3\\xi_{3}+3\\xi_{2}^{2}-4\\xi_{3}\\right)}\\\\ &{+3\\xi_{1}^{2}-1+\\eta_{3}-6\\xi_{2}^{2}+4\\eta_{3}}\\\\ &{=(3-1)^{2}+4\\eta_{3}-3\\xi_{2}^{2}+1+3\\xi_{1}^{2}(10\\xi_{1}+72\\xi_{2}+16\\xi_{3}-4\\xi_{3})^{2}+4\\eta_{3}^{2}+1+6\\xi_{1}^{2}}\\\\ &{+3\\eta_{3}-1+3\\xi_{1}^{2}+9\\eta_{3}+9\\eta_{3}^{2}}\\\\ &{+3\\xi_{2}^{2}-1+3\\xi_{2}^{2}+3\\eta_{3}}\\\\ &{+3\\eta_{3}-1+9\\xi_{1}-2\\xi_{2}\\eta_{3}-2\\xi_{3}^{2}-3(3-9\\xi_{1}+3\\xi_{2}+3\\xi_{1}+2\\eta_{3})}\\\\ &{+3\\xi_{1}^{2}-1+9\\eta_{3}+12\\xi_{2}^{2}-3\\xi_{2}^{2}+3\\xi_{3}+3\\xi_{1}^{2}+3\\xi_{2}^{2}}\\\\ &{+3\\eta_{3}-1+3\\xi_{1}^{2}+3\\xi_{2}^{2}+3\\xi_{3}+3\\xi_{1}^{2}+3\\xi_{2}^{2}}\\\\ &{+3\\xi_{1}^{2}-4\\eta_{3}+12\\xi_{2}^{2}-1+3\\xi_{1}^{2}(1-3\\xi_{2}+3\\xi_{2}+3\\xi_{1}+3\\xi_{1}^{2})}\\\\ &{-3(3-1)^{2}+3\\xi_{1}^{2}+3\\xi_{2}^{2}+9\\eta_{3}^{2}}\\\\ &{-3(6-3\\xi_{1}+7\\xi_{2}-3\\xi_{1}+3\\xi_{1}^{2}+1+\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "By analyzing the above equation, we can find that when $N\\geq17$ (i.e., $n\\geq34\\$ ), $0.5<p_{1}\\leq0.99$ (i.e., $0<\\tau_{1}\\leq0.98)$ , and $p_{1}+0.01\\,\\leq\\,p_{2}\\,\\leq\\,1$ (i.e., $\\tau_{1}+0.02\\,\\leq\\,\\tau_{2}\\,\\leq\\,1)$ , the above equation is negative, i.e., $f(p_{2},p_{1},N)-f(p_{1},p_{1},N)<0$ or equivalently ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{lim}_{\\gamma\\to0^{+}}\\frac{1}{\\gamma}(\\mathbb{E}_{\\mathcal{G}}\\left[\\mathcal{L}(\\mathcal{G},\\mathbf{W}^{(0)})-\\mathcal{L}(\\mathcal{G},\\mathbb{W}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))\\mid\\tau_{1}\\right]}\\\\ &{\\quad\\quad\\quad-\\mathbb{E}_{\\mathcal{G}}\\left[\\mathcal{L}(\\mathcal{G},\\mathbf{W}^{(0)})-\\mathcal{L}(\\mathcal{G},\\mathbb{W}(\\tau_{1},\\mathbf{W}^{(0)},\\gamma))\\mid\\tau_{2}\\right])<0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "completing the proof. ", "page_idx": 20}, {"type": "text", "text": "B Datasets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we describe the details of the benchmark graph classification datasets utilized in our experiments. For experiments, we use datasets that are preprocessed by Morris et al. [36]. We provide descriptive statistics of each dataset in Table 2. ", "page_idx": 20}, {"type": "text", "text": "The DD dataset [7] is a bioinformatics dataset that contains protein graphs. Each graph represents a particular protein. Each node represents an individual amino acid. Each edge represents two nodes that satisfy certain spatial proximity. Each node feature represents a type of the corresponding node\u2019s amino acid type. Each graph binary label represents whether the corresponding compound is an enzyme or not. ", "page_idx": 20}, {"type": "text", "text": "The Protein dataset [1] is a bioinformatics dataset that contains protein graphs. Each graph represents a particular protein. Each node represents a secondary structure element of a protein. Each edge ", "page_idx": 20}, {"type": "table", "img_path": "e2INndPINB/tmp/f624c96c2e5cf3876148381307f223da70d424b7f24febe2266bb906b73ffc48.jpg", "table_caption": ["Table 2: Descriptive statistics of the utilized graph classification benchmark datasets. "], "table_footnote": ["represents two nodes that are neighbors along the amino acid sequence or are top-K neighbors $(\\mathsf{K}{=}3)$ at the protein space. Each node feature represents a type of the corresponding node\u2019s secondary structure element type. Each graph binary label represents whether the corresponding protein is an enzyme or not. "], "page_idx": 21}, {"type": "text", "text": "The NCI1 dataset [47] is a chemical dataset that contains chemical molecular compound graphs. Each graph represents a particular chemical molecular compound. Each node represents an atom. Each edge represents a chemical bond between two atoms. Each node feature represents a type of atom (e.g., carbon, and hydrogen). Each graph binary label represents whether the corresponding compound is an anti-cancer chemical or not. ", "page_idx": 21}, {"type": "text", "text": "The AIDS dataset [40] is a chemical dataset that contains chemical molecular compound graphs. Each graph represents a particular chemical molecular compound. Each node represents an atom. Each edge represents a chemical bond between two atoms. Each node feature represents a type of atom (e.g., carbon, and hydrogen). Each graph binary label represents whether the corresponding compound shows an anti-HIV activity or not. ", "page_idx": 21}, {"type": "text", "text": "The Reddit dataset [51] is a social-network dataset that contains social network graphs. Among Reddit-Binary, Reddit-Multi-5K, and Reddit-Multi-12K, we utilized Reddit-Binary. Each graph represents a thread on Reddit. Each node represents a user. Each edge represents a comment between two users. There are no available node features, thus, we utilize the one-hot encoded degree of the node as its feature, following existing literature in GLAD [39]. Each graph binary label represents whether the corresponding thread is a discussion-based thread or question-answer-based thread. ", "page_idx": 21}, {"type": "text", "text": "The IMDB dataset [51] is an actor-ego-network dataset that contains social network graphs. Each graph represents the ego network of a particular actor. Each node represents an actor. Each edge represents a co-appearance of two actors in (a) movies. There are no available node features, thus, we utilize the one-hot encoded degree of the node as its feature, following existing literature in GLAD [39]. Each graph binary label represents whether the corresponding ego-user particularly acts in the romance genre or action genre. ", "page_idx": 21}, {"type": "text", "text": "The MUTAG (formally, mutagenicity) dataset [17] is a chemical dataset that contains chemical molecular compound graphs. Each graph represents a particular chemical molecular compound. Each node represents an atom. Each edge represents a chemical bond between two atoms. Each node feature represents a type of atom (e.g., carbon, and hydrogen). Each graph binary label represents whether the corresponding compound is mutagenic or not. ", "page_idx": 21}, {"type": "text", "text": "The DHFR dataset [42] is a chemical dataset that contains chemical molecular compound graphs. Each graph represents a particular chemical molecular compound. Each node represents an atom. Each edge represents a chemical bond between two atoms. Each node feature represents a type of atom (e.g., carbon, and hydrogen). Each graph binary label represents whether the corresponding compound works as a dihydrofolate reductase inhibitor or not. ", "page_idx": 21}, {"type": "text", "text": "The BZR [42] dataset is a chemical dataset that contains chemical molecular compound graphs. Each graph represents a particular chemical molecular compound. Each node represents an atom. Each edge represents a chemical bond between two atoms. Each node feature represents a type of atom (e.g., carbon, and hydrogen). Each graph binary label represents whether the corresponding compound is active against the benzodiazepine receptor. ", "page_idx": 21}, {"type": "text", "text": "The ER dataset is a chemical dataset that contains chemical molecular compound graphs. Specifically, it contains compounds that are NR-estrogen receptor (ER)-LBD. Each graph represents a particular chemical molecular compound. Each node represents an atom. Each edge represents a chemical bond between two atoms. Each node feature represents a type of atom (e.g., carbon, and hydrogen). Each graph binary label represents whether the corresponding compound has toxicity or not. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "The source of the ER dataset is https://tripod.nih.gov/tox21/challenge/data.jsp. ", "page_idx": 22}, {"type": "text", "text": "C Formal Expression of Synthetic Datasets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we formally describe the leveraged synthetic graphs: Syn-Com and Syn-Cycle. We elaborate on how each graph is generated. ", "page_idx": 22}, {"type": "text", "text": "C.1 Syn-Com ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We formalize the data generation process of Syn-Com. For a given even number of nodes $n>2$ , assume two disjoint node communities $\\mathcal{V}_{a}$ and $\\nu_{b}$ (WLOG, $\\mathcal{V}_{a}\\;=\\;\\{v_{i}\\;:\\;1\\;\\leq\\;i\\;\\leq\\;n/2\\}$ and $\\mathcal{V}_{b}=\\{v_{j}:n/2\\,\\dot{+}\\,1\\le j\\le n\\}\\}$ ). For a given community parameter $\\tau\\in[0,1]$ , a graph of Syn-Com $\\mathcal{G}\\,=\\,({\\bf X},{\\bf A})$ satisfies the following: $\\mathbf{A}_{i,j}\\,=\\,\\mathbf{A}_{j,i}\\,\\sim\\,b(1,(\\tau+1)/2)$ for $\\{v_{i},v_{j}\\}\\,\\in\\,\\binom{\\nu_{a}}{2}\\cup\\binom{\\nu_{b}}{2}$ , $\\mathbf{A}_{i,j}=\\mathbf{A}_{j,i}\\sim b(1,(1-\\tau)/2)$ for $v_{i}\\,\\in\\,\\mathcal{V}_{a},v_{j}\\,\\in\\,\\mathcal{V}_{b}$ , and $\\mathbf{A}_{i,i}\\,=\\,0,\\forall i\\,\\in\\,[n]$ , where $b(1,p)$ is a Bernoulli sampling with a parameter $p$ . We let $\\mathbf{X}=\\mathbb{I}_{n}$ , where $\\mathbb{I}_{n}$ is a $n$ -by- ${\\cdot n}$ identity matrix. ", "page_idx": 22}, {"type": "text", "text": "C.2 Syn-Cycle ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We formalize the data generation process of Syn-Cycle. For a given number of nodes $n\\,>\\,2$ , we consider a clean-cycle graph $\\mathcal{G}_{*}^{c y c}\\bar{=}\\left(\\mathcal{V},\\mathcal{E}^{*}\\right)\\equiv\\bar{(\\mathbf{X},\\dot{\\mathbf{A}}^{*})}$ where $\\mathcal{E}^{*}=\\{v_{i},v_{i+1}:i\\in[n]\\}\\cup\\{v_{1},v_{n}\\}$ and $\\mathbf{A}^{*}$ is the adjacency matrix that represents $\\mathcal{E}^{*}$ . ", "page_idx": 22}, {"type": "text", "text": "We also consider a set of noisy-cycle graphs (i.e., pan graphs) $\\mathbb{G}_{\\prime}^{c y c}$ , constructed by randomly relocating an edge from $\\mathcal{G}_{*}^{c y c}$ to form a $(n-1)$ -size cycle, (i.e., $(\\mathbf{X},\\{v_{i},v_{j|i}\\}\\cup\\mathcal{E}^{*}\\setminus\\{e_{k}\\})$ , $(\\mathbf{X},\\{v_{j},v_{i|j}\\}\\cup$ $\\mathcal{E}^{*}\\setminus\\left\\{e_{k}\\right\\})\\in\\mathbb{G}_{\\sigma}^{c y c},\\forall e_{k}=\\{v_{i},v_{j}\\}\\in\\mathcal{E}^{*}$ , where $v_{j|i}$ is a $v_{j}$ \u2019s neighbor except for $v_{i}$ ). We let $\\mathbf{X}=\\mathbb{I}_{n}$ . Note that for $n$ nodes, there exist $2n$ noisy-cycle graphs in $\\mathbb{G}_{\\prime}^{c y c}$ and a single clean-cycle graph. ", "page_idx": 22}, {"type": "text", "text": "D Experimental Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we provide experimental details of the conducted experiments in our work. ", "page_idx": 22}, {"type": "text", "text": "D.1 Machines ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "All experiments of this work are performed on a machine with NVIDIA RTX 8000 D6 GPUs (48GB VRAM) and two Intel Xeon Silver 4214R processors. ", "page_idx": 22}, {"type": "text", "text": "D.2 Details of empirical analysis ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "gFroarp thhs ef rCoom dfaotr ausents,e ewne  gsraampphlse. 500 graphs from $\\mathbb{G}_{\\tau=0.4}^{c o m}$ for training graphs and sample 500 $\\mathbb{G}_{\\tau=0.8}^{c o m}$ ", "page_idx": 22}, {"type": "text", "text": "For the Cycle-Cycle dataset, we sample half of $\\mathbb{G}_{\\prime}^{c y c}$ for training graphs and employ the clean-cycle graph as the unseen graph. ", "page_idx": 22}, {"type": "text", "text": "oFfo fCoor mu-nsCeyecnl eg rdaapthass.et, we sample 500 graphs from $\\mathbb{G}_{\\tau=0.4}^{c o m}$ for training graphs and sample half $\\mathbb{G}_{\\prime}^{c y c}$ ", "page_idx": 22}, {"type": "text", "text": "For the Cycle-Com dataset, we sample half of $\\mathbb{G}_{\\prime}^{c y c}$ for training graphs and sample 500 graphs from $\\mathbb{G}_{\\tau=0.4}^{c o m}$ for unseen graphs. ", "page_idx": 22}, {"type": "text", "text": "Training and evaluation We train GAEs for 200 epochs. The results are similar for 500 epochs, but we present the 200-epoch results for better visualization since the error lines flatten after 200 epochs. For every 10 epochs of training, we measure the mean reconstruction errors for each graph and report the mean of these values for graphs within the same class. ", "page_idx": 22}, {"type": "text", "text": "D.3 Details of two-stage GLAD methods ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We provide an overview of two-stage anomaly detection methods. First, by performing certain pretext tasks, they learn representations of data. Then, upon the obtained representations, they utilize a oneclass classifier to detect anomalies. Below, (1) we describe graph representations of utilized GLAD methods, including MUSE, and (2) describe the utilized one-class classifier, an MLP autoencoder. ", "page_idx": 23}, {"type": "text", "text": "Note. MUSE is a two-stage method. ", "page_idx": 23}, {"type": "text", "text": "Graph representation. As described in Section 5, MUSE obtains a representation of each graph with the proposed error representation Eq (6). On the other hand, utilized baseline two-stage approaches, which are GraphCL [53], GAE [23], and GraphMAE [15], obtain graph representations from the graph or node embeddings. Specifically, they first train graph neural network encoders with their pretext tasks. Specifically, GraphCL performs graph contrastive learning, GAE performs adjacency matrix reconstruction, and GraphMAE performs node feature reconstruction. After finalizing selfsupervised learning, we utilize the trained encoder to obtain embeddings of graphs or nodes. Details of each method are as follows: ", "page_idx": 23}, {"type": "text", "text": "\u2022 GraphCL: It learns graph embeddings to perform its contrastive learning task. Thus, we directly utilize the graph embeddings as representations of graphs.   \n\u2022 GAE: It only learns node embeddings. Thus, we pool node embeddings by using the elementwisemean readout function.   \n\u2022 GraphMAE: It only learns node embeddings. Thus, we pool node embeddings by using the elementwise-mean readout function. ", "page_idx": 23}, {"type": "text", "text": "One-class classifier. In our experiments, every two-stage method leverages an MLP autoencoder as its one-class classifier. In a nutshell, the MLP autoencoder detects anomalies by using the reconstruction loss of a graph. We first elaborate on how we train the MLP autoencoder and then describe how the trained MLP autoencoder is leveraged to detect anomalies. ", "page_idx": 23}, {"type": "text", "text": "We start with the training of the MLP autoencoder. Formally, for a given data representation vector $\\mathbf{z}\\in\\mathbb{R}^{d}$ , the MLP autoencoder $\\mathtt{M L P}_{\\xi}:\\mathbb{R}^{d}\\mapsto\\mathbb{R}^{d}$ generates a reconstructed representation $\\hat{\\mathbf{z}}\\in\\mathbb{R}^{d}$ (i.e., $\\hat{\\mathbf{z}}=\\mathtt{M L P}_{\\xi}(\\mathbf{z}))$ ). Then, we compute a L2-norm reconstruction loss $\\mathcal{L}$ as follows: $\\mathcal{L}:=\\|\\mathbf{z}-\\hat{\\mathbf{z}}\\|_{2}$ . We update the parameters of the MLP autoencoder $\\xi$ by using gradient descent to minimize $\\mathcal{L}$ . ", "page_idx": 23}, {"type": "text", "text": "After training the MLP autoencoder $\\mathtt{M L P}_{\\xi}$ , we detect anomalies by using a reconstruction loss as an anomaly score. However, since the scale of each representation dimension significantly varies, the reconstruction loss is often dominated by dimensions with larger scales, overshadowing those with smaller values. To mitigate this undesirable phenomenon, in the anomaly inference step, we leverage dimensionwise-weighted L2 scores. Importantly, we apply different weights to different dimensions $w_{l}\\in\\mathbb{R},\\forall l\\in[d]$ (note that $d$ is the dimension of an input vector). Specifically, we utilize the dimensionwise standard deviation of train data\u2019s representations, which is defined as follows: ", "page_idx": 23}, {"type": "equation", "text": "$$\nw_{\\ell}=\\sqrt{\\frac{1}{|\\mathscr{D}_{t r a i n}|}\\sum_{\\substack{\\mathcal{G}_{k}\\in\\mathcal{D}_{t r a i n}}}\\left(\\mathbf{z}_{k,\\ell}-\\left(\\frac{1}{|\\mathscr{D}_{t r a i n}|}\\sum_{\\substack{\\mathcal{G}_{t}\\in\\mathcal{D}_{t r a i n}}}\\mathbf{z}_{t,\\ell}\\right)\\right)^{2}},\\forall\\ell\\in[d].\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where ${\\bf z}_{i,l}$ is a $l$ -th element of $i$ -th graph\u2019s representation vector and $\\mathcal{D}_{t r a i n}$ is a set of training graphs. By using the normalization weight of Eq (13), we compute the anomaly score. Formally, the anomaly detection score of $\\mathcal{G}_{t}$ , denoted by $s_{T}$ , is defined as follows: ", "page_idx": 23}, {"type": "equation", "text": "$$\ns_{t}:=\\exp\\left(-\\sqrt{\\sum_{\\ell=1}^{d}\\left(\\frac{\\mathbf{z}_{t,\\ell}^{\\prime}-\\mathtt{M L P}_{\\xi}(\\mathbf{z}_{t}^{\\prime})_{\\ell}}{w_{\\ell}}\\right)^{2}}\\right)\\in[0,1].\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Note that the higher $s_{t}$ indicates the $t$ -th data point is normal. ", "page_idx": 23}, {"type": "text", "text": "D.4 Details of MUSE ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this subsection, we provide details of MUSE. ", "page_idx": 23}, {"type": "text", "text": "Reconstruction models. As described in Section 6, we use GIN [49] as our backbone encoder, which is the same as other leveraged GLAD baseline methods. For the node feature decoder and adjacency matrix decoder, we use a 2-layer MLP with a ReLU activation function. ", "page_idx": 23}, {"type": "text", "text": "Error representation. For aggregation functions of error representation, we leverage a mean function and a standard deviation function. Formally, for a set $\\boldsymbol{\\mathcal{A}}$ where $A\\subset\\mathbb{R}$ , a mean aggregation function $\\mathtt{A g g}_{\\mathtt{m e a n}}:2^{\\mathbb{R}}\\mapsto\\mathbb{R}$ and a standard deviation aggregation function $\\operatorname{Agg}_{\\mathrm{std}}:2^{\\mathbb{R}}\\mapsto{\\overline{{\\mathbb{R}}}}_{\\geq0}$ are defined as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathsf{A g g}_{\\mathtt{m e a n}}(\\mathcal{A}):=\\frac{1}{|\\mathcal{A}|}\\sum_{a\\in\\mathcal{A}}a,\\quad\\mathsf{A g g}_{\\mathtt{s t d}}(\\mathcal{A}):=\\sqrt{\\frac{1}{|\\mathcal{A}|}\\sum_{a\\in\\mathcal{A}}(a-\\mathsf{A g g}_{\\mathtt{m e a n}}(\\mathcal{A}))^{2}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, we represent each graph $\\mathcal{G}$ by using a $\\mathbb{R}^{4}$ vector as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname{Err}(\\mathcal{G})=[\\mathtt{A}\\mathrm{g}\\mathrm{g}_{\\mathtt{m e a n}}(\\mathbb{L}_{\\mathtt{X}}(\\mathcal{G})),\\ \\mathtt{A}\\mathrm{g}\\mathrm{g}_{\\mathtt{s t d}}(\\mathbb{L}_{\\mathtt{X}}(\\mathcal{G})),\\ \\mathtt{A}\\mathrm{g}\\mathrm{g}_{\\mathtt{m e a n}}(\\mathbb{L}_{\\mathtt{A}}(\\mathcal{G})),\\ \\mathtt{A}\\mathrm{g}\\mathrm{g}_{\\mathtt{s t d}}(\\mathbb{L}_{\\mathtt{A}}(\\mathcal{G}))]\\in\\mathbb{R}^{4}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "D.5 Hyperparameters and Details of Baselines ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "For every method, we tune the hyperparameters and choose the hyperparameter configuration that gives the best validation AUROC. We provide details of the search space of each model category and its hyperparameters. ", "page_idx": 24}, {"type": "text", "text": "Fixed settings. For all the methods, we fix the dropout probability and weight decay as 0.3 and $1e-6$ , respectively. In addition, all the methods are trained with Adam optimizer [21]. ", "page_idx": 24}, {"type": "text", "text": "One-stage learning-based GLAD methods. We tune the following hyperparameters for one-stage learning-based GLAD methods, which are DOMINANT, OCGTL, GLADC, GLocalKD, GLAM, HIMNET, and SIGNET: ", "page_idx": 24}, {"type": "text", "text": "\u2022 Training learning rate $\\gamma\\in\\{10^{-3},10^{-4}\\}$ \u2022 Models hidden dimension $d^{\\prime}\\in\\{16,32,64,128,256\\}$ \u2022 Number of GNN layers $K\\in\\{3,4,5\\}$ \u2022 Number of model training epochs $L\\in\\{30,60,\\cdots300\\}$ ", "page_idx": 24}, {"type": "text", "text": "For other hyperparameters, we follow the default configuration provided in their official Github. ", "page_idx": 24}, {"type": "text", "text": "Two-stage learning-based GLAD methods. We tune the following hyperparameters for two-stage learning-based GLAD methods, which are GraphCL, GAE, GraphMAE, and MUSE. ", "page_idx": 24}, {"type": "text", "text": "Note. Our proposed method MUSE is also included in this category and tuned hyperparameters according to the below ", "page_idx": 24}, {"type": "text", "text": "\u2022 Pretext task learning rate $\\gamma\\in\\{10^{-3},10^{-4}\\}$ \u2022 Models hidden dimension $d^{\\prime}\\in\\{16,32,64,128,256\\}$ \u2022 Number of GNN layers $K\\in\\{3,4,5\\}$ \u2022 Number of pretext task training epochs $L\\in\\{20,40,\\cdot\\cdot\\cdot\\,,200\\}$ ", "page_idx": 24}, {"type": "text", "text": "In addition to these hyperparameters, we also tune the positive weight coefficient for our adjacency matrix reconstruction, which is denoted as $\\tau$ in Section 5, within $\\{\\bar{0}.0,1.0,2.0\\}$ . ", "page_idx": 24}, {"type": "text", "text": "Here, models indicate both the encoder model and decoder model that are utilized to perform pretext tasks. Note that as described in Appendix D.3, all two-stage methods utilize MLP autoencoder for their one-class classifier. We tune the hyperparameter of the MLP autoencoder as follows: ", "page_idx": 24}, {"type": "text", "text": "\u2022 MLP hidden dimension $d^{\\prime}\\in\\{32,64,128\\}$ \u2022 MLP learning rate $\\gamma\\in\\{10^{-2}.10^{-3},10^{-4}\\}$ ", "page_idx": 24}, {"type": "text", "text": "We fix the MLP auteoncoder training epochs and the number of MLP layers as 500 and 3, respectively. ", "page_idx": 24}, {"type": "text", "text": "Two-stage baselines details. For GraphCL, we obtain graph views by randomly dropping $50\\%$ of edges and adding Gaussian noise to node features sampled from $\\mathcal{N}(0,0.1)$ and use a two-layer MLP projection head. For GraphMAE, we mask $50\\%$ of node features with the zero mask, which is empirically demonstrated to be more effective than a learnable mask in our preliminary study. For GAE, we utilize a binary cross-entropy loss and a two-layer MLP decoder. 4 ", "page_idx": 24}, {"type": "image", "img_path": "e2INndPINB/tmp/aedfcc1b373b3d2ff2572aea26ad41be33182c640cf041b22e139f07cadcd153.jpg", "img_caption": ["Figure 8: Reconstruction flip occurs on feature reconstruction method. When Graph-AEs are trained on graphs sharing a primary pattern of weaker strength, the trained Graph-AEs give smaller reconstruction losses for graphs having the same pattern of a stronger strength (red lines) than those of a weaker strength (blue lines). "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "e2INndPINB/tmp/bb305eda30879449a7f88f6dafdff86298f3c4b166c08686c040a00b6d044fc5.jpg", "img_caption": ["Figure 9: Reconstruction filp does NOT occur on feature reconstruction method. When GraphAEs are trained on graphs sharing a primary pattern, the trained Graph-AEs give larger reconstruction for graphs having a different pattern (red lines) than those of the same pattern (blue lines). "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "E Additional Experimental Results ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "E.1 Node feature reconstruction methods ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Note that in Section 3, we investigate Graph-AEs that reconstruct the adjacency matrix of a given graph. In this subsection, we analyze another large branch of Graph-AEs: node feature reconstruction methods [15, 16, 44]. ", "page_idx": 25}, {"type": "text", "text": "Feature reconstruction model. We first formalize the node feature reconstruction method. Consider a graph $\\mathcal{G}=(\\mathbf{X},\\mathbf{A})$ , where $\\mathbf{X}\\in\\mathbb{R}^{|\\mathcal{V}|\\times d}$ . First, a GNN encoder $f_{\\theta}$ is utilized to generates node embeddings $\\bar{\\mathbf{Z}}\\in\\mathbb{R}^{|\\mathcal{V}|\\times d^{\\prime}}$ (i.e., $f_{\\theta}(\\mathbf{X},\\mathbf{A})=\\mathbf{Z})$ ). Then, by using the feature decoder $g_{\\phi}:\\mathbb{R}^{d^{\\prime}}\\mapsto$ $\\mathbb{R}^{d}$ , the reconstructed node features $\\hat{\\mathbf{X}}\\,\\in\\,\\mathbb{R}^{|\\mathcal{V}|\\times d}$ are obtained. Lastly, we compute the feature reconstruction loss, which is either (1) squared Frobenius norm loss [38] (i.e., $\\bar{\\mathcal{L}}:=\\|\\mathbf{X}-\\hat{\\mathbf{X}}\\|_{F}^{2})$ or (2) cosine similarity loss [15] (i.e., $\\begin{array}{r}{\\mathcal{L}:=\\frac{1}{|\\mathcal{V}|}\\sum_{i=1}^{|\\mathcal{V}|}(1-\\frac{\\mathbf{X}_{i}^{T}\\hat{\\mathbf{X}}_{i}}{\\Vert\\mathbf{X}_{i}\\Vert_{2}\\cdot\\Vert\\hat{\\mathbf{X}}_{i}\\Vert_{2}}))}\\end{array}$ \u2212\u2225XiX\u22252i\u00b7 \u2225X\u02c6X\u02c6ii\u22252 )). Parameters of the GNN encoder $f_{\\theta}$ and the node feature decoder $g_{\\phi}$ are updated by gradient descent to minimize $\\mathcal{L}$ . ", "page_idx": 25}, {"type": "text", "text": "Setting. The dataset setting is equal to that of empirical analysis provided in Section 3.2. Regarding the model setting, we utilize 3-layer GIN as the GNN encoder $f_{\\theta}$ and 2\u2212layer MLP as the feature decoder $g_{\\phi}$ . We utilize either squared Frobenius norm or cosine similarity loss for the reconstruction loss. We train each reconstruction model for 200 epochs. ", "page_idx": 25}, {"type": "text", "text": "Results. In a nutshell, we can observe the same results as those of GAE. In Scenario 1, as shown in Figure 8, one can observe that the reconstruction flip occurs, which is also observed in GAE. In Scenario 2, as shown in Figure 9, one can observe that the reconstruction flip does not occur. Thus, we verify that our findings in Section 3.2 are not only restricted to the adjacency matrix reconstruction methods but also hold for the node feature reconstruction methods. ", "page_idx": 25}, {"type": "text", "text": "E.2 Experimental results on each setting. ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We present experimental results in each setting of our main experiment. Specifically, experimental results for the case where class 0 graphs are anomalies and class 1 graphs are normal are provided in Table 3. In addition, experimental results for the case where class 1 graphs are anomalies and class 0 graphs are normal are provided in Table 4. Notably, in both cases, MUSE obtains the best average ranking among 18 methods (refer to Table 3 and Table 4). ", "page_idx": 25}, {"type": "table", "img_path": "e2INndPINB/tmp/fd9ed770f0337beb7b8a3291affdee3bff0f9e5c68888a4e3603141d41964d9f.jpg", "table_caption": ["Table 3: Average and standard deviation of the test AUROC when graphs belonging to class 0 are anomalies and graphs belonging to class 1 are normal. A.R. denotes the average ranking. MUSE outperforms other GLAD methods in terms of average ranking. "], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "e2INndPINB/tmp/c7d1883fac3028ca4c67ed21a71394aa89d1a42c1cad5b1ec97fcefc5050ed2f.jpg", "table_caption": ["Table 4: Average and standard deviation of the test AUROC when graphs belonging to class 1 are anomalies and graphs belonging to class 0 are normal. A.R. denotes average ranking. MUSE outperforms other GLAD methods in terms of average ranking. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "E.3 Experimental results on additional evaluation metrics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In this section, we compare the GLAD performance of MUSE against those of two strongest competitors, OCGTL and GLAM. To this end, we leverage two metrics: average precision score (AP score) and precision $@\\,\\mathrm{K}$ . As shown in Table 5 and Table 6, MUSE outperforms the competitors in 7/10 and 8/10 in terms of AP score and precision $@\\,\\mathrm{K}$ , respectively. These results demonstrate the effectiveness of MUSE is not limited to a particular evaluation metric. ", "page_idx": 26}, {"type": "text", "text": "E.4 Experimental results on additional ablation study ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In this section, we demonstrate the effectiveness of the following two components of MUSE: graph augmentation and cosine-similarity feature reconstruction loss. To this end, we use two variants of MUSE. MUSE w/o Aug. is a variant where the input graph augmentation is removed. MUSE w/o Cos. is a variant that uses the Frobenious norm loss for the feature reconstruction loss, instead of the ", "page_idx": 26}, {"type": "table", "img_path": "e2INndPINB/tmp/475ccea6483c3b0bf2681c773be3873a46ff0ebad09ebedc9e2ced43955a1989.jpg", "table_caption": ["Table 5: GLAD performance: Average and standard deviation of test AP score values $(\\times100)$ in the GLAD task are reported. The best performances are highlighted in green. "], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "e2INndPINB/tmp/4bc03f9e3c6a38e616a24bc847f1d1b3cd6863b61b81348458990745c077650c.jpg", "table_caption": ["Table 6: GLAD performance: Average and standard deviation of test Precision $@10$ score values $(\\times10)$ in the GLAD task are reported. The best performances are highlighted in green. "], "table_footnote": ["cosine similarity loss. Note that MUSE uses both input graph augmentation and cosine similarity loss. As shown in Table 7, MUSE outperforms its variants in 8 out of 10 datasets, demonstrating the effectiveness of our graph augmentation and cosine-similarity loss. "], "page_idx": 27}, {"type": "text", "text": "E.5 Experimental results from the scalability analysis ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we study the scalability and effectiveness of GLAD methods in large-scale graphs. ", "page_idx": 27}, {"type": "text", "text": "Datasets. We use two large-scale real-world graphs, which are MalNetTiny [9] and OVCAR-8 [50]. Specifically, the MalNetTiny dataset consists of graphs, each containing a large number of nodes and edges. In contrast, the OVCAR-8 dataset consists of a large number of graphs. ", "page_idx": 27}, {"type": "text", "text": "Scalable MUSE. Note that MUSE may not be scalable for graphs with a large number of nodes, since MUSE reconstructs all the entries of an adjacency matrix, which results in the complexity of ${\\cal O}(|\\nu|^{2})$ . Thus, we present a scalable version of MUSE, which we call MUSE-Sample. Specifically, MUSE-Sample samples $K$ number of entries from the adjacency matrix, and reconstructs only the sampled entries. Therefore, the time complexity of computing reconstruction loss becomes ", "page_idx": 27}, {"type": "text", "text": "Experimental results. We compare the (1) GLAD performance and (2) inference runtime of our proposed methods (i.e., MUSE and MUSE-Sample) against the two strongest baseline methods: OCGTL and GLAM. Regarding the performance comparison, as shown in Table 8, MUSE and MUSE-Sample outperform the baseline methods in both datasets. Regarding the runtime analysis, as shown in Table 9, MUSE is the second-fastest method among the four methods. ", "page_idx": 27}, {"type": "text", "text": "F Further Analysis and Discussion ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we provide our further analyses and discussions. ", "page_idx": 27}, {"type": "text", "text": "F.1 Reconstruction flip in computer vision ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Analogous to our observations of the reconstruction flips in graphs, certain images are more easily reconstructed. For instance, Liu et al. [31] noted that \"anomalies with colors close to the background may yield unreliable reconstruction errors\". Moreover, in the MNIST dataset, a reconstruction model trained on class-7 images sometimes reconstructs class-4 images better than class-7 images [31]. ", "page_idx": 27}, {"type": "text", "text": "To mitigate this undesirable phenomenon, Liu et al. [31] proposed a deformation-based anomaly detection method. In this method, an input image is first deformed in a way that makes a reconstruction model easy to reconstruct. Here, a deformation method that maintains the semantics of the input image is employed [5]. To identify whether an image is an anomaly, they first deform the image and then let a reconstruction model reconstruct it. Their underlying intuition is that the deformation model would drastically change the image dissimilar to the majority of the training images, and this would make the deformed anomalous image different from its original image. Finally, when the deformed image is reconstructed by the reconstruction model, the reconstructed anomalous image would be significantly different from the original anomalous image, resulting in a large reconstruction error. ", "page_idx": 27}, {"type": "table", "img_path": "e2INndPINB/tmp/066a85ef160e2f8c5287e2c0a12e1b0dfc8a01547a97740cf1e6ea9564d40426.jpg", "table_caption": ["Table 7: Additional ablation study: Average and standard deviation of test AUROC values $(\\times10)$ in the GLAD task are reported. The best performances are highlighted in green. "], "table_footnote": [], "page_idx": 28}, {"type": "table", "img_path": "e2INndPINB/tmp/0dfcf22f7c5517d356a7d3b40530db19813315c01d89ebc45b6031eb0fb03c85.jpg", "table_caption": ["Table 8: Large-scale graphs GLAD performance: The average and standard deviation of test AUROC values $(\\times10)$ in the GLAD task on large-scale graphs are reported. The best performances are highlighted in green. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "While the method is intuitive in computer vision, the extension of the suggested method to the graph domain is non-trivial. First, the graph deformation that maintains semantics is non-trivial. It is hard to know the semantics of a graph without sufficient domain knowledge, especially without any external graph labels. Furthermore, naive graph augmentations, such as node dropping and edge perturbation, may harm the semantics of a graph [48]. Second, while the deformation techniques are widely studied in computer vision [5, 2], those of a graph is an underexplored region. Therefore, employing an adequate technique for graph deformation is also practically infeasible. ", "page_idx": 28}, {"type": "text", "text": "Considering these challenges, we consider that the method proposed in Liu et al. [31] is hard to be trivially extended to the graph domain. ", "page_idx": 28}, {"type": "text", "text": "F.2 Reconstruction flip in real-world graph datasets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We provide our in-depth analysis result of reconstruction flip in Section 3 by using the synthetic datasets. In this section, we analyze whether the reconstruction filp phenomena occur in real-world graph datasets. ", "page_idx": 28}, {"type": "text", "text": "Setting. We focus on the anomaly detection task performance of GAE [22], which reconstructs the adjacency matrix of a given graph. GAE uses reconstruction loss as an anomaly score, where an anomalous graph is likely to have high reconstruction errors. We measure the AUROC score on test graphs, based on the setting described in Section 6.1. Here, the AUROC score lower than 0.5 indicates the corresponding model performs worse than random guessing, implying the reconstruction flip has occurred. ", "page_idx": 28}, {"type": "text", "text": "Results. As shown in Table 3, in the protein dataset, GAE [22] tends to perform worse than random guessing (spec., average AUROC is 0.458), which indicates that the reconstruction filp occurs. Thus, we demonstrate that the reconstruction flip is not limited to synthetic scenarios but also occurs in real-world graph datasets. ", "page_idx": 28}, {"type": "text", "text": "F.3 Complexity analysis of MUSE ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In this section, we provide a time complexity analysis for the forward pass of MUSE, concerning the size of a graph (i.e., number of nodes $\\vert\\nu\\vert$ and edges $|\\mathcal{E}|)$ . ", "page_idx": 28}, {"type": "text", "text": "Encoding. We first encode a graph $\\mathcal{G}=(\\mathbf{X}\\in\\mathbb{R}^{|\\mathcal{V}|\\times d},\\mathbf{A}\\in\\{0,1\\}^{|\\mathcal{V}|\\times|\\mathcal{V}|})$ with a GNN encoder. The time complexity of encoding $\\mathcal{G}$ with $L-$ layer GCN [23] is $O(L|\\mathcal{V}|d^{2}+L|\\mathcal{E}|d)$ [3]. Given that $d$ and $L$ are constants, the complexity is equivalent to $O(|\\mathcal{V}|+|\\mathcal{E}|)$ . ", "page_idx": 28}, {"type": "table", "img_path": "e2INndPINB/tmp/e1c98cc6cbddd074d8bb41c3d7194b60e27256d5d0de71eb6aefda8b9f0ae733.jpg", "table_caption": ["Table 9: Runtime analysis: Average runtime (secs) per each graph of each method on each dataset. Overall, MUSE is the second-fasted method among the four methods. "], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "Decoding. We decode node embeddings by using a node decoder and edge decoder, which are MLPs. Since the hidden dimensions and the number of layers of MLPs are all constants, the complexity of decoding is equivalent to $O(|\\mathcal{V}|)$ . ", "page_idx": 29}, {"type": "text", "text": "Reconstruction loss. We compute adjacency matrix reconstruction loss and node feature reconstruction loss. Each loss computation has the time complexity of $O(|\\nu|^{2})$ and $O(|\\mathcal{V}|)$ , respectively. Thus, the overall time complexity of the reconstruction loss computation becomes $O^{\\stackrel{.}{(}|\\gamma|^{2})}$ . ", "page_idx": 29}, {"type": "text", "text": "Error representation. We utilize average pooling and standard deviation pooling, which both have linear time complexity. Thus, the time complexity is equivalent to $O(|\\mathcal{V}|^{2})$ . ", "page_idx": 29}, {"type": "text", "text": "Overall. Thus, the time complexity of the forward pass of MUSE is as follows: ", "page_idx": 29}, {"type": "equation", "text": "$$\nO(|\\mathcal{V}|+|\\mathcal{E}|)+O(|\\mathcal{V}|)+O(|\\mathcal{V}|^{2})+O(|\\mathcal{V}|^{2})=O(|\\mathcal{V}|^{2}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "While MUSE has a quadratic complexity to the number of nodes, our task is a graph-level task where real-world graphs typically have an affordable number of nodes (as shown in Table 2, the dataset that has the largest average number of nodes has smaller than 430 average number of nodes). ", "page_idx": 29}, {"type": "text", "text": "F.4 Broader impacts of our work ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In this section, we discuss the broader impacts of our research. While our focus lies in the graph-level task, similar observations can be found in node-level tasks within various types of graphs, such as dynamic graphs [27], heterophilic graphs [29, 30], and hypergraphs [19, 20, 4, 18]. We anticipate that our findings and the proposed MUSE will be widely utilized in applications requiring graphlevel anomaly detection, such as drug discovery and brain diagnosis. In addition, as described in Section 2.1, the phenomenon of the reconstruction flip is not limited to the graph domain, and it is also observed in other domains such as computer vision. To our knowledge, we are the first to utilize summarized reconstruction errors as a representation feature of data. This approach can be directly applied to other fields, such as computer vision. ", "page_idx": 29}, {"type": "text", "text": "F.5 Generalized categorization of primary patterns ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Expectation. In this work, as a primary pattern, we use community structure and node cycles. As a future direction, more general and formal categorization of graph patterns can be considered. This categorization would enable our analysis (Section 3) to be more systematic and generalized. ", "page_idx": 29}, {"type": "text", "text": "Challenge. However, real-world datasets may exhibit a wider variety of patterns, including those related to node attributes. For example, in the protein dataset, both normal and anomalous graphs exhibit homophilic patterns (i.e., edges tend to join nodes with the same attribute), with anomalies displaying a stronger pattern than normal graphs. This diversity makes the categorization not straightforward. Thus, adequately considering real-world graph patterns would play a crucial role in this categorization. ", "page_idx": 29}, {"type": "text", "text": "G Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We clarify our goal, analyzing reconstruction filp, and provide analysis results in Section 3. We present a method (Section 5) and demonstrate its superiority (Section 6). ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide limitations of the proposed method MUSE in Section 7. ", "page_idx": 30}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide the full statements for all theorems in Section 3.3 and provide full proofs in Appendix A. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide architectures of MUSE in Section 5, details regarding hyperparameters in Appendix D, and model code in https://github.com/kswoo97/GLAD_MUSE. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide all the utilized datasets, full code for models, and instructions to run the code in https://github.com/kswoo97/GLAD_MUSE. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We provide the key setting in Section 6, and further details in Appendix D. ", "page_idx": 30}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We describe the number of experimental runs and standard deviation of the performance in Section 6. ", "page_idx": 30}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We describe machines utilized for the experiments in Appendix D.1. ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We strictly follow the NeurIPS Code of Ethics, particularly in terms of anonymity that we do not reveal our nationality and institutes, etc. ", "page_idx": 31}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We discuss the broader impact of our work in Appendix F.4 ", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] Justification: We believe we do not have risks of misusing. ", "page_idx": 31}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We properly add citations for all the mentioned existing literature or methods. ", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: We do not release any new assets. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: We do not utilize any crowdsourcing or human-related tasks. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 31}, {"type": "text", "text": "Justification: We do not utilize any crowdsourcing or human-related tasks. ", "page_idx": 31}]