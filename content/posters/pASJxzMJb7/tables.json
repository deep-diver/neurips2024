[{"figure_path": "pASJxzMJb7/tables/tables_2_1.jpg", "caption": "Table 1: The difference between type-based sampling and token-based sampling.", "description": "This table compares word sampling methods based on types and tokens. Type-based sampling selects words uniformly from the vocabulary, while token-based sampling selects words based on their frequency in a corpus.  The table shows that type-based sampling tends to select rare words, while token-based sampling more accurately reflects the distribution of words in typical text.", "section": "3 Embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_2_2.jpg", "caption": "Table 2: The empirical performance of Zipfian whitening, which exploits the empirical frequency of words during expectation calculations. Each cell shows the STS-B [15] score \u00d7100. By carefully performing the simple operation of whitening, it consistently outperforms powerful baseline methods.", "description": "This table presents the results of the STS-B task using different word embedding models (GloVe, Word2Vec) and preprocessing techniques.  It shows that applying Zipfian whitening, a method that incorporates word frequency into the whitening process, consistently achieves better results than standard methods (centering and whitening) and other baselines (ABTT, SIF + CCR).", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_3_1.jpg", "caption": "Table 2: The empirical performance of Zipfian whitening, which exploits the empirical frequency of words during expectation calculations. Each cell shows the STS-B [15] score \u00d7100. By carefully performing the simple operation of whitening, it consistently outperforms powerful baseline methods.", "description": "This table presents the results of an empirical evaluation comparing the performance of Zipfian whitening against several baselines on the STS-B benchmark.  The STS-B score (semantic textual similarity) is presented, showing the improvement achieved by using Zipfian whitening. The table highlights the consistent superior performance of Zipfian whitening across various baseline methods.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_4_1.jpg", "caption": "Table 2: The empirical performance of Zipfian whitening, which exploits the empirical frequency of words during expectation calculations. Each cell shows the STS-B [15] score \u00d7100. By carefully performing the simple operation of whitening, it consistently outperforms powerful baseline methods.", "description": "This table shows the results of the STS-B benchmark for different word embedding models (GloVe, Word2Vec) using various methods for embedding symmetry enhancement.  It compares the performance of standard centering and whitening against ABTT [39] and SIF + CCR [7] baselines, with and without the use of Zipfian weighting based on empirical word frequencies.  The results demonstrate that Zipfian whitening consistently outperforms the other methods.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_4_2.jpg", "caption": "Table 2: The empirical performance of Zipfian whitening, which exploits the empirical frequency of words during expectation calculations. Each cell shows the STS-B [15] score \u00d7100. By carefully performing the simple operation of whitening, it consistently outperforms powerful baseline methods.", "description": "This table shows the results of an empirical evaluation of Zipfian whitening on the STS-B benchmark dataset.  It compares the performance of Zipfian whitening against several baselines (GloVe + various methods, Word2Vec + various methods). Each entry represents the STS-B score (\u00d7100), a measure of semantic textual similarity. The table demonstrates that Zipfian whitening consistently outperforms the baselines.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_5_1.jpg", "caption": "Table 3: Spearman's \u03c1 \u00d7 100 (each cell) between the symmetry scores (each column) and downstream STS-B performance (each row), on pre-trained and post-processed embeddings (GloVe, word2Vec, and fastText). The scores based on the Zipfian prior show a significantly higher correlation with task performance compared to those based on the uniform prior including Ave. Cos. and IsoScore.", "description": "This table presents the Spearman's rank correlation coefficients (multiplied by 100) between different symmetry scores and the downstream STS-B task performance.  The symmetry scores are calculated using both uniform and Zipfian priors for pre-trained and post-processed word embeddings from GloVe, word2Vec, and fastText.  The results show a much stronger correlation between the Zipfian-based symmetry scores and task performance compared to the uniform-based scores, including those from established methods like Average Cosine Similarity and IsoScore.", "section": "3.3 Evaluation of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_9_1.jpg", "caption": "Table 5: The empirical performance difference between \u201cuniform\u201d-enforced centering and whitening with a uniform prior for dynamic embeddings, and \u201cZipfian\u201d\u2014conventional uniform centering and whitening over tokens with an implicit Zipfian prior over types. Each cell shows the STS-B [15] score \u00d7100. This comparison reveals that token-level uniform centering/whitening, corresponding to type-level Zipfian centering/whitening, leads to empirically better performance.", "description": "This table compares the performance of two different methods for enhancing the symmetry of word embeddings: uniform whitening and Zipfian whitening.  It shows that applying uniform whitening to token embeddings (which implicitly incorporates a Zipfian distribution at the type level) outperforms applying uniform whitening directly to type embeddings. The results are presented using the STS-B (Semantic Textual Similarity Benchmark) score.", "section": "5.1 Uniform whitening of token embeddings \u2248 Zipfian whitening of type embeddings"}, {"figure_path": "pASJxzMJb7/tables/tables_16_1.jpg", "caption": "Table 2: The empirical performance of Zipfian whitening, which exploits the empirical frequency of words during expectation calculations. Each cell shows the STS-B [15] score \u00d7100. By carefully performing the simple operation of whitening, it consistently outperforms powerful baseline methods.", "description": "This table presents the results of the STS-B benchmark task, comparing the performance of various word embedding methods, with a focus on Zipfian whitening and its impact on performance.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_22_1.jpg", "caption": "Table 8: Full results of the empirical performance of Zipfian whitening. Each cell shows the STS score \u00d7100. As empirical word frequency p(w), we used enwiki. Across all models and tasks, Zipfian whitening outperforms powerful baseline methods.", "description": "This table presents the results of the empirical performance evaluation of Zipfian whitening on various sentence similarity tasks (STS).  The results are broken down by word embedding model (GloVe, Word2Vec, fastText, and fastText-subword), and by different methods for processing the word embeddings (Averaging, Centering, Whitening, ABTT, and SIF+CCR).  For each model and method, the STS scores are reported, showing the effectiveness of Zipfian whitening compared to standard techniques.  The empirical word frequency used was derived from the enwiki dataset.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_23_1.jpg", "caption": "Table 8: Full results of the empirical performance of Zipfian whitening. Each cell shows the STS score \u00d7100. As empirical word frequency p(w), we used enwiki. Across all models and tasks, Zipfian whitening outperforms powerful baseline methods.", "description": "This table presents the results of applying Zipfian whitening to word embeddings on various sentence similarity tasks (STS).  It compares the performance of Zipfian whitening against several baselines, including averaging, uniform centering and whitening, and ABTT (all-but-the-top).  The empirical word frequency used is derived from the enwiki dataset.  The table shows that across all models and tasks tested, Zipfian whitening consistently outperforms the other methods.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_23_2.jpg", "caption": "Table 10: Evaluation results using Japanese fastText. Each cell shows the JSTS [29] score \u00d7100. Even in the multilingual setting, Zipfian whitening outperforms powerful baseline methods.", "description": "This table presents the results of experiments using Japanese fastText embeddings.  It compares the performance of various methods (averaging, centering, whitening, ABTT, SIF+CCR) using both uniform and Zipfian whitening approaches on the Japanese Sentence Textual Similarity (JSTS) benchmark. The results demonstrate that Zipfian whitening consistently outperforms baseline methods in a multilingual setting.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_23_3.jpg", "caption": "Table 10: Evaluation results using Japanese fastText. Each cell shows the JSTS [29] score \u00d7100. Even in the multilingual setting, Zipfian whitening outperforms powerful baseline methods.", "description": "This table presents the results of the JSTS (Japanese Semantic Textual Similarity) benchmark using Japanese fastText word embeddings.  The results are broken down by different preprocessing methods (averaging, centering, whitening, ABTT, and SIF+CCR) using both uniform and Zipfian whitening approaches. The table highlights that Zipfian whitening consistently achieves superior performance across all methods tested, demonstrating the effectiveness of this approach even in multilingual settings.", "section": "3.2 Enhancement of embedding symmetry"}, {"figure_path": "pASJxzMJb7/tables/tables_23_4.jpg", "caption": "Table 11: Each cell shows the STS-B [15] score \u00d7100.", "description": "This table presents the results of an experiment comparing different methods for improving word embeddings.  The core comparison is between uniform and Zipfian whitening, with an additional condition of applying uniform whitening first, followed by rescaling norms using Zipfian whitening. This experiment aimed to see the effect of solely applying Zipfian whitening versus applying uniform whitening followed by Zipfian norm rescaling.", "section": "Experiments with a mix of uniform and Zipfian settings"}, {"figure_path": "pASJxzMJb7/tables/tables_24_1.jpg", "caption": "Table 12: Full results of the whitening on dynamic embeddings. Each cell shows the STS score \u00d7100. Token-level uniform centering/whitening (\"Zipfian\" settings), which corresponds to centering/whitening at the word type level under a Zipfian prior, consistently outperforms the \"Uniform\" setting across all STS tasks.", "description": "This table presents the results of applying uniform and Zipfian whitening methods to dynamic word embeddings on several sentence similarity tasks (STS).  The results show that applying Zipfian whitening, which accounts for the non-uniform distribution of word frequencies (Zipf's law), consistently leads to better performance than uniform whitening.", "section": "Experimental results on all benchmark datasets to evaluate the effects of uniform whitening on token embeddings"}]