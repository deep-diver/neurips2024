[{"figure_path": "N4quRxE19p/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of AVATAR. AVATAR consists of a actor LLM and a comparator LLM. (a) During optimization, the actor generates actions to answer queries by leveraging the provided tools. Then, the comparator contrasts a set of well-performing (positive) and poorly-performing (negative) queries, automatically generating holistic prompts to teach the actor more effective retrieval strategies and tool usage (cf. Section 4). (b) At deployment, the actor with optimized prompts or actions can be effectively used to answer new queries.", "description": "This figure illustrates the AVATAR framework, highlighting its two main components: the actor and the comparator.  The actor LLM uses tools to answer queries, while the comparator LLM analyzes the actor's performance on positive and negative examples to iteratively refine prompts and improve tool usage. The optimization phase focuses on improving the actor's strategies through contrastive reasoning, while the deployment phase leverages the optimized actor for efficient query answering.", "section": "4 Our Method: Optimizing Agents for Tool-Assisted Multi-Step Tasks"}, {"figure_path": "N4quRxE19p/figures/figures_3_1.jpg", "caption": "Figure 2: Comparison between AVATAR and ReAct. (a) The ReAct agent exhibits incomplete task decomposition and employs suboptimal tool combinations, such as lengthy string matching, leading to poor task performance. (b) AVATAR decomposes the task into multiple steps, such as type filtering and flexible token matching. Moreover, it implements robust tool usage and precise synthesis with learned parameters from the optimization phase to achieve excellent performance on new queries.", "description": "This figure compares the performance of AVATAR and ReAct on a sample query. ReAct uses lengthy string matching and suboptimal tool combinations, resulting in poor performance.  AVATAR, in contrast, effectively decomposes the query into multiple steps (decomposing into sub-queries, using embedding tool to filter, using token matching, LLM reasoning for validation), which improves the overall accuracy of the system.  It uses a more sophisticated approach, utilizing multiple tools strategically and combining scores with learned parameters, thus achieving significantly better results.", "section": "1 Introduction"}, {"figure_path": "N4quRxE19p/figures/figures_5_1.jpg", "caption": "Figure 3: Demonstration example during optimization. Best viewed in color. The task of the comparator is to automatically generate instructions based on sampled positive and negative queries. Then comparator provides holistic instructions that guide the actor to improve query decomposition, utilize better tools, and incorporate more comprehensive information.", "description": "This figure shows a demonstration of AVATAR's optimization process.  The comparator analyzes positive (successful) and negative (unsuccessful) query examples from the actor's previous attempts. By contrastively reasoning between these examples, the comparator generates holistic instructions (not just single-query corrections) to improve the actor's query decomposition strategy, tool selection, and use of information.  The updated instructions are shown to guide the actor toward improved performance in subsequent iterations.", "section": "4.2 Automate Holistic Instruction Generation with Comparator"}, {"figure_path": "N4quRxE19p/figures/figures_8_1.jpg", "caption": "Figure 4: Optimization dynamics of AVATAR agents on STARK. The figures show validation performance (solid line) and its moving average (dashed line) during the optimization of AVATAR.", "description": "This figure displays the performance of AVATAR agents during the optimization process on the STARK benchmark.  Three subplots show the optimization dynamics for each of the three datasets within the STARK benchmark (Amazon, MAG, Prime). The solid lines represent the validation performance at each iteration, while the dashed lines represent the moving average of the validation performance. This visualization helps to understand how AVATAR agents improve over iterations and to assess the stability and convergence of the optimization process.", "section": "5 Experiments"}, {"figure_path": "N4quRxE19p/figures/figures_8_2.jpg", "caption": "Figure 4: Optimization dynamics of AVATAR agents on STARK. The figures show validation performance (solid line) and its moving average (dashed line) during the optimization of AVATAR.", "description": "This figure displays graphs illustrating the performance of AVATAR agents on the STARK benchmark during the optimization process.  The graphs plot the validation performance (solid line) and its moving average (dashed line) over a series of iterations. This visualization helps to show the improvement of AVATAR during optimization process. There are three subfigures which correspond to three different metrics (Hit@1, Hit@5, MRR).", "section": "5 Experiments"}, {"figure_path": "N4quRxE19p/figures/figures_9_1.jpg", "caption": "Figure 3: Demonstration example during optimization. Best viewed in color. The task of the comparator is to automatically generate instructions based on sampled positive and negative queries. Then comparator provides holistic instructions that guide the actor to improve query decomposition, utilize better tools, and incorporate more comprehensive information.", "description": "This figure shows a demonstration of AVATAR's optimization process.  The comparator module analyzes positive (successful) and negative (unsuccessful) query examples.  Based on this analysis, the comparator generates improved instructions for the actor module. These instructions guide the actor to enhance its query decomposition strategy, select more appropriate tools, and utilize more comprehensive information when responding to new queries, ultimately leading to improved performance. The visual representation illustrates the iterative process of contrastive reasoning and instruction refinement.", "section": "4.2 Automate Holistic Instruction Generation with Comparator"}, {"figure_path": "N4quRxE19p/figures/figures_15_1.jpg", "caption": "Figure 7: Example data on FLICKR30K-ENTITIES. Each entity is an image along with its image patches and associated phrases with the image patches.", "description": "This figure shows three example images from the FLICKR30K-ENTITIES dataset. Each image has multiple bounding boxes highlighting different objects within the image. Each bounding box is also associated with a textual description, which is displayed in the figure. The images represent diverse scenes, including a portrait of a person wearing an orange hat and glasses, a group of people at a pride parade, and a wedding scene. This visual representation demonstrates how images and associated textual descriptions are organized in the dataset, emphasizing its multimodal and complex nature.", "section": "A Retrieval Tasks"}, {"figure_path": "N4quRxE19p/figures/figures_17_1.jpg", "caption": "Figure 3: Demonstration example during optimization. Best viewed in color. The task of the comparator is to automatically generate instructions based on sampled positive and negative queries. Then comparator provides holistic instructions that guide the actor to improve query decomposition, utilize better tools, and incorporate more comprehensive information.", "description": "This figure demonstrates an example of how the AVATAR framework works during optimization. The comparator module analyzes positive and negative query examples to identify systematic flaws in the actor's actions and tool usage. Then, it generates holistic instructions to guide the actor towards improved query decomposition, more effective tool selection, and the use of more comprehensive information. The illustration shows iterative updates to the instructions and the actor's actions, highlighting the contrastive reasoning mechanism of AVATAR.", "section": "4.2 Automate Holistic Instruction Generation with Comparator"}]