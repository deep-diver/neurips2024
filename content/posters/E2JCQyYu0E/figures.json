[{"figure_path": "E2JCQyYu0E/figures/figures_0_1.jpg", "caption": "Figure 1: Image to 3D shape. From the segmented images, containing occlusion due to interaction, MHCDIFF reconstructs 3D human shapes as point clouds.", "description": "This figure shows the overall pipeline of the proposed method, MHCDIFF.  It starts with a single input image depicting two people interacting, resulting in occlusions. The image is then segmented to isolate the individual people. Finally, MHCDIFF processes these segmented images to generate a 3D point cloud representation of each person. The generated point clouds accurately reflect the 3D shapes of the individuals, even in areas where occlusions were present in the input image.", "section": "Introduction"}, {"figure_path": "E2JCQyYu0E/figures/figures_4_1.jpg", "caption": "Figure 2: (Left) Overview of MHCDIFF. Given an occluded image I, MHCDIFF reconstructs 3D human shape as a point cloud. First, we extract the 2D feature map \u03b5(I) and hypothesize pose and shape parameters of multiple plausible SMPL meshes {Si}i\u2208{1,...,s}. Our method consists of the conditioned point cloud diffusion model (Sec. 4.4). We project the 2D image features to capture details of the image (Sec. 3) and extract local features from multiple hypothesized SMPL meshes to leverage human body priors (Sec. 4.3) (Upper Right) The details of local features (Sec. 4.2). The signed distance field is visualized in positive and negative regions. The arrows indicate normal vectors n. (Lower Right) The details of multi-hypotheses (Sec. 4.3). We can consider the whole distribution during denoising process with the argmax i, and the denoising can be approximated by red arrows. However, it is sensitive to extreme samples of the distribution, so we condition the mean of occupancy values, which is visualized by transparency, and the denoising can be approximated by blue arrows.", "description": "This figure shows the overall framework of MHCDIFF, a multi-hypotheses conditioned point cloud diffusion model for 3D human reconstruction from occluded images.  It illustrates the process from input image to final 3D point cloud reconstruction, highlighting key components like 2D feature extraction, multiple SMPL mesh hypothesis generation, local feature extraction, and the conditioned diffusion process.  The figure also details the local features (signed distance field and normals) and the multi-hypotheses conditioning strategy used.", "section": "4 MHCDIFF: Multi-hypotheses Conditioned Point Cloud Diffusion"}, {"figure_path": "E2JCQyYu0E/figures/figures_8_1.jpg", "caption": "Figure 3: A cumulative occlusion-to-reconstruction test. This figure shows the performance of different models from the images of various occlusion ratios. From the whole-body images, which is 0% occlusion, we randomly mask the images from 10% to 40%. MHCDIFF is robust to the occlusion ratio, showing the best performance.", "description": "This figure presents a comparison of the performance of several methods for 3D human reconstruction in the presence of varying degrees of occlusion.  The x-axis represents the percentage of occlusion in the input images (0% to 40%), while the y-axis shows the reconstruction error, measured using Chamfer Distance and Point-to-Surface Distance. The plot demonstrates that the proposed MHCDIFF method consistently outperforms other state-of-the-art techniques across all occlusion levels, highlighting its robustness to occlusions.", "section": "5 Experiments"}, {"figure_path": "E2JCQyYu0E/figures/figures_8_2.jpg", "caption": "Figure 4: Qualitative results on CAPE dataset. We evaluate our method with SMPL estimation method and implicit-function-based methods. Given the upper image, PaMIR, ICON, and HiLo cannot generate the occluded regions. They cannot also handle the misaligned SMPL mesh on the arms, creating incomplete bodies. ProPose predicts the full-body shape, but cannot capture the details like the blazer of the lower image. However, MHCDIFF is robust to the occlusion and misalignment, and can capture pixel-aligned details.", "description": "This figure shows a qualitative comparison of different methods for 3D human reconstruction from occluded images on the CAPE dataset.  The results demonstrate the superiority of MHCDIFF in handling occlusions and misaligned SMPL meshes, resulting in more complete and detailed reconstructions.", "section": "5 Experiments"}, {"figure_path": "E2JCQyYu0E/figures/figures_9_1.jpg", "caption": "Figure 5: Qualitative results on in-the-wild images. Two images on the left show occlusions due to interactions, and the rightmost image shows loose clothes. From internet photos, we use [32] to segment images.", "description": "This figure shows the qualitative results of the MHCDIFF model on real-world images obtained from the internet. The images contain various occlusions due to human interactions or loose clothing. The figure compares the 3D reconstruction results of MHCDIFF against other state-of-the-art methods (ProPose, PaMIR, ICON, SIFU, and HiLo). The results demonstrate that MHCDIFF is capable of accurately reconstructing pixel-aligned 3D human shapes despite the occlusions and complex clothing styles. It is also robust to various levels of occlusion and interactions.  Each column represents a different method, showing the input image, segmented images, and the corresponding 3D reconstruction.", "section": "Experiments"}, {"figure_path": "E2JCQyYu0E/figures/figures_16_1.jpg", "caption": "Figure 4: Qualitative results on CAPE dataset. We evaluate our method with SMPL estimation method and implicit-function-based methods. Given the upper image, PaMIR, ICON, and HiLo cannot generate the occluded regions. They cannot also handle the misaligned SMPL mesh on the arms, creating incomplete bodies. ProPose predicts the full-body shape, but cannot capture the details like the blazer of the lower image. However, MHCDIFF is robust to the occlusion and misalignment, and can capture pixel-aligned details.", "description": "This figure compares the 3D human reconstruction results of MHCDIFF against several state-of-the-art methods on the CAPE dataset.  The results demonstrate MHCDIFF's superior ability to handle occlusions and misaligned SMPL meshes, producing more complete and detailed 3D human models, especially in areas with occlusions.", "section": "5 Experiments"}, {"figure_path": "E2JCQyYu0E/figures/figures_16_2.jpg", "caption": "Figure 7: Qualitative results on Hi4D dataset.", "description": "This figure shows qualitative results of 3D human reconstruction on the Hi4D dataset, which contains close human-human interactions with high-fidelity meshes. The input images are shown on the left side, along with their segmented versions.  The reconstruction results from MHCDIFF and other baseline methods (ProPose, PaMIR, ICON, SIFU, HiLo) are displayed for comparison. This showcases MHCDIFF's ability to handle complex interactions and occlusions,  producing more complete and detailed 3D human shapes compared to the baselines.", "section": "5 Experiments"}]