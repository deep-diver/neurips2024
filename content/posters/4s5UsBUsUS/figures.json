[{"figure_path": "4s5UsBUsUS/figures/figures_1_1.jpg", "caption": "Figure 1: Equipped with the S6 model, our VFIMamba achieves the state-of-the-art performance on benchmarks across different input resolutions.", "description": "This radar chart visualizes the performance of VFIMamba and other state-of-the-art video frame interpolation methods across various benchmark datasets with different resolutions (2K and 4K).  Each axis represents a different dataset, and the values on the axes show the performance scores. VFIMamba consistently outperforms other methods, especially in the high-resolution X-TEST datasets.", "section": "1 Introduction"}, {"figure_path": "4s5UsBUsUS/figures/figures_3_1.jpg", "caption": "Figure 2: Overall pipeline of VFIMamba. Firstly, a lightweight feature extractor is employed to encode the input frames into shallow features. Subsequently, we utilize the Mixed-SSM Block (MSB) to conduct inter-frame modeling using S6, iterating N times at each scale. Finally, these inter-frame features are leveraged to generate the intermediate frame.", "description": "This figure illustrates the overall architecture of VFIMamba, a video frame interpolation model. It consists of three main stages: feature extraction, inter-frame modeling, and frame generation.  The feature extraction stage uses a lightweight network to extract shallow features from input frames. The inter-frame modeling stage uses Mixed-SSM Blocks (MSBs), which leverage the S6 model for efficient and dynamic inter-frame modeling. This stage is repeated N times at each scale. Finally, the frame generation stage takes the inter-frame features and generates the intermediate frame.", "section": "3 Method"}, {"figure_path": "4s5UsBUsUS/figures/figures_5_1.jpg", "caption": "Figure 3: Visualizations of different rearrangement methods and scan directions. The choice of rearrangement strategy impacts the information flow during inter-frame modeling with S6. For example, consider the 6-th token from Io and the 11-th token from I\u2081. In sequential rearrangement, the intermediate tokens introduce too many irrelevant tokens, whereas interleaved rearrangement more effectively preserves the spatiotemporal locality.", "description": "This figure compares two methods for rearranging tokens from consecutive frames before processing with the S6 model: sequential and interleaved rearrangement.  It shows how each method affects the flow of information between tokens when using horizontal and vertical scans. Interleaved rearrangement is shown to better preserve the spatiotemporal relationships between tokens, which is advantageous for video frame interpolation.", "section": "3.3 State space models for inter-frame modeling"}, {"figure_path": "4s5UsBUsUS/figures/figures_7_1.jpg", "caption": "Figure 4: Visualizations from SNU-FILM (Reda et al., 2022) and X-TEST (Sim et al., 2021).", "description": "This figure shows a visual comparison of video frame interpolation results from different methods on two datasets: SNU-FILM and X-TEST.  Each row represents a different video sequence, showing the input frames (Overlay), and the intermediate frames generated by various methods (RIFE, XVFI, BiFormer, AMT-G, EMA-VFI, SGM-VFI, VFIMamba) along with the ground truth.  Arrows indicate areas where VFIMamba performs better than other methods, showcasing its superior motion estimation and detail preservation, especially in high-motion scenarios.", "section": "4.1 Comparison with the State-of-the-Art Methods"}, {"figure_path": "4s5UsBUsUS/figures/figures_7_2.jpg", "caption": "Figure 5: Comparisons of FLOPs and GPU memory usage with increasing resolution input.", "description": "The figure shows a comparison of the computational cost (FLOPs) and GPU memory usage of VFIMamba against VFIFormer and AMT for different input resolutions (256, 512, 768, 1024).  It demonstrates that VFIMamba is significantly more efficient than the other two methods, particularly at higher resolutions.", "section": "4. Experiments"}, {"figure_path": "4s5UsBUsUS/figures/figures_9_1.jpg", "caption": "Figure 6: Performance of different learning methods, recorded every 30 epochs. Curriculum learning has the best performance in both the low-resolution and high-resolution benchmarks eventually.", "description": "This figure shows a comparison of four different learning strategies for video frame interpolation: Vimeo90K Only, Sequential Learning, Mixed Learning, and Curriculum Learning.  The performance is measured using PSNR on the Vimeo90K and X-TEST datasets, recorded every 30 epochs.  The graph demonstrates that the Curriculum Learning strategy outperforms the other three methods, achieving the highest PSNR on both datasets at the end of training.  This highlights the effectiveness of the proposed curriculum learning approach in improving model performance for video frame interpolation tasks.", "section": "4 Experiments"}, {"figure_path": "4s5UsBUsUS/figures/figures_13_1.jpg", "caption": "Figure 7: Visualizations of Effective Receptive Field (ERF) (Luo et al., 2016) of different models before and after training. We utilize the red area in Io to inspect its corresponding ERF in I\u2081. S6 model has a significantly larger receptive field and becomes more accurate after training.", "description": "This figure visualizes the effective receptive fields (ERFs) of different models for video frame interpolation, before and after training.  The red box on the left image (I0) indicates the area of interest.  The subsequent images display the corresponding ERFs in the next frame (I1) for three different models: Convolution, Local Attention, and the authors' proposed S6 model. The visualization shows that the S6 model has a significantly larger ERF than the other two models, and that the ERF becomes more focused and accurate after training, suggesting better performance. ", "section": "A.3 Visualizations on effective receptive field"}, {"figure_path": "4s5UsBUsUS/figures/figures_14_1.jpg", "caption": "Figure 4: Visualizations from SNU-FILM (Reda et al., 2022) and X-TEST (Sim et al., 2021).", "description": "This figure displays visual comparisons of video frame interpolation results from several state-of-the-art methods (RIFE, XVFI, BiFormer, AMT-G, EMA-VFI, SGM-VFI) and VFIMamba on two datasets: SNU-FILM and X-TEST.  The results show that VFIMamba produces sharper and more accurate intermediate frames, especially in challenging scenarios with large motion. The red arrows highlight areas where VFIMamba excels.", "section": "4.1 Comparison with the State-of-the-Art Methods"}, {"figure_path": "4s5UsBUsUS/figures/figures_14_2.jpg", "caption": "Figure 9: Details of frame feature extraction. The same color represents the same block structure.", "description": "This figure shows the detailed architecture of the frame feature extraction module used in VFIMamba.  It consists of three stages, each containing a convolutional block, a patch embedding layer, and another convolutional block.  The resolution of the feature maps is progressively reduced (H\u00d7W, H/2\u00d7W/2, H/4\u00d7W/4) through the use of strided convolutions.  Each convolutional block utilizes 3x3 convolutions with stride 1, followed by a prelu activation. The same color blocks represent identical structures across different scales. This design is intended to efficiently extract relevant features for subsequent inter-frame modeling.", "section": "A.5 Frame feature extraction"}, {"figure_path": "4s5UsBUsUS/figures/figures_15_1.jpg", "caption": "Figure 10: Details of frame generation. IFBlock is adopted from Huang et al. (2022), which is used optionally to enhance the local detail generation performance.", "description": "This figure details the frame generation process of VFIMamba. It shows how the intermediate flow is estimated using features from the inter-frame modeling block (MSB), and then refined using a residual estimation module. The IFBlock is then used to enhance the local details before a backward warp operation is performed to generate the intermediate frame. The final frame is then produced using a RefineNet to refine the appearance.", "section": "3.3 State space models for inter-frame modeling"}]