[{"figure_path": "4D7hnJ9oM6/figures/figures_1_1.jpg", "caption": "Figure 1: (a) The different templates used during our experiments. (b) Matrix of cosine similarity between each template, averaged over all classes of the CIFAR-10 dataset. (c) Comparison of accuracy (%) using cross-entropy (CE) on CIFAR-10 and some corruptions of CIFAR-10-C datasets using different templates and our weight average strategy.", "description": "This figure shows the different text prompt templates used in the experiments (a), the cosine similarity matrix between these templates averaged across all CIFAR-10 classes (b), and a comparison of the classification accuracy achieved using different templates and the proposed weight average strategy on CIFAR-10 and various corrupted versions of CIFAR-10 (c).  The results highlight the variability in information encoded by different templates and the effectiveness of the proposed weight averaging technique in improving robustness across domain shifts.", "section": "3 Method"}, {"figure_path": "4D7hnJ9oM6/figures/figures_2_1.jpg", "caption": "Figure 2: Loss and Error surfaces on model parameters for the Gaussian noise corruption of the CIFAR-10C dataset. Points T\u00ba, T\u00b9, and T2 represent models adapted with different text templates (please see Fig. 1a). The central point (cross) shows the model obtained by averaging these weights, demonstrating improved performance.", "description": "This figure shows the loss and error surfaces for three models adapted using three different text templates (T0, T1, T2) under Gaussian noise corruption of the CIFAR-10-C dataset.  Each point on the surface represents a model's performance based on its parameter values. The central point (marked by a cross) represents the model obtained by averaging the weights of the three individually adapted models. This visualization demonstrates that the weight averaging strategy leads to a model with improved performance (lower loss and error) compared to models adapted with individual templates.", "section": "3 Method"}, {"figure_path": "4D7hnJ9oM6/figures/figures_3_1.jpg", "caption": "Figure 3: Overview of the proposed WATT method. In the Adaptation Phase, the model is adapted using different text templates (T0, T1, ..., TH), with weight averaging performed periodically. In the Evaluation Phase, the adapted CLIP model uses averaged text embeddings from all templates and the weight averaged model to predict the class of the test image.", "description": "This figure illustrates the WATT method's two phases: Adaptation and Evaluation.  In the Adaptation Phase, multiple versions of the CLIP model are created, each using a different text template to adapt to a test image.  Weight averaging is performed periodically to combine the knowledge gained from each template.  The Evaluation Phase leverages the averaged text embeddings and the weight-averaged vision encoder from the Adaptation Phase to generate a final class prediction for the test image.", "section": "3 Method"}, {"figure_path": "4D7hnJ9oM6/figures/figures_5_1.jpg", "caption": "Figure 4: Visual comparison of the Parallel (left) and Sequential (right) approaches for multi-template weight averaging during adaptation.", "description": "This figure visually compares two multi-template weight averaging strategies: Parallel (WATT-P) and Sequential (WATT-S).  In the Parallel approach, multiple models are trained in parallel, each using a different template.  After L iterations, their weights are averaged to obtain a final set of weights. This process is repeated M times.  The Sequential approach trains a single model iteratively, updating the weights after each template is used for L iterations, this is also repeated M times. The diagram shows how the weights are updated and averaged for each method, highlighting the differences in their adaptation strategies.", "section": "3 Method"}, {"figure_path": "4D7hnJ9oM6/figures/figures_6_1.jpg", "caption": "Figure 5: Evolution of the accuracy for different numbers of random template on 5 test-time runs.", "description": "This figure shows the performance of the WATT model on CIFAR-10, CIFAR-10.1, and CIFAR-10-C datasets as the number of templates used for adaptation is varied.  The x-axis represents the number of templates randomly selected for adaptation in each of the 5 test-time runs. The y-axis shows the test-time accuracy.  The shaded regions represent the standard deviation across those 5 runs.  The plot demonstrates that the model's accuracy increases with the number of templates, particularly on the more challenging CIFAR-10-C dataset, which involves various types of image corruptions. For CIFAR-10 and CIFAR-10.1, the accuracy plateaus after using about 6 templates.", "section": "5.1 Ablation Studies"}, {"figure_path": "4D7hnJ9oM6/figures/figures_6_2.jpg", "caption": "Figure 6: Evolution of accuracy on CIFAR-100 corruptions with the Parallel MTWA method.", "description": "This figure shows how the accuracy of the Parallel Multi-Template Weight Averaging (MTWA) method changes over different numbers of iterations on various CIFAR-100 corruptions (e.g., Defocus Blur, Frost, Contrast).  It illustrates the convergence of the model's performance as the number of adaptation iterations increases.  The plot helps to determine an optimal number of iterations where additional adaptations yield minimal improvement, suggesting a point of diminishing returns in the model's refinement process.", "section": "5 Results"}]