{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a foundational vision-language model that is directly extended and improved upon in this work."}, {"fullname_first_author": "Chao Jia", "paper_title": "Scaling up visual and vision-language representation learning with noisy text supervision", "publication_date": "2021-00-00", "reason": "This paper is highly relevant due to its focus on scaling up visual and vision-language representation learning, a key aspect of the research presented in this work."}, {"fullname_first_author": "Manli Shu", "paper_title": "Test-time prompt tuning for zero-shot generalization in vision-language models", "publication_date": "2022-00-00", "reason": "This work directly addresses test-time adaptation of CLIP, a core theme of this work, and proposes an approach that is contrasted with the method presented here."}, {"fullname_first_author": "Zhengfeng Lai", "paper_title": "Padclip: Pseudo-labeling with adaptive debiasing in clip for unsupervised domain adaptation", "publication_date": "2023-10-00", "reason": "This paper focuses on unsupervised domain adaptation using CLIP, a relevant topic closely related to the test-time adaptation research presented in this work."}, {"fullname_first_author": "David Osowiechi", "paper_title": "Clust3: Information invariant test-time training", "publication_date": "2023-00-00", "reason": "This work is highly relevant because it also explores test-time training and adaptation of vision-language models, contributing to the body of knowledge that underpins this work."}]}