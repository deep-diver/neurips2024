[{"figure_path": "0VeSCjRDBy/tables/tables_7_1.jpg", "caption": "Table 1: Comparison with state-of-the-art KD methods on the instruction-following dataset using fine-tuned OpenLLaMA-7B as the teacher and fine-tuned OpenLLaMA-3B as the student. We format the best, the second best and worse than SFT results. The results based on GPT-2 are available in Appendix C.1.", "description": "This table compares the performance of different knowledge distillation (KD) methods on an instruction-following task.  It uses a fine-tuned OpenLLaMA-7B model as the teacher and a fine-tuned OpenLLaMA-3B model as the student.  The results are evaluated using two metrics: GPT-4 and R-L, with the best, second-best, and worse-than-SFT results highlighted for clarity.  Additional results using GPT-2 are included in Appendix C.1.", "section": "4.1 Task-Agnostic Distillation"}, {"figure_path": "0VeSCjRDBy/tables/tables_8_1.jpg", "caption": "Table 2: Comparison with the state-of-the-art KD methods on text summarization, machine translation and commonsense reasoning datasets. We report the ROUGE-L, BLEU and accuracy for SAMSum, IWSLT'17 (en-de) and StrategyQA, respectively. We format the best, the second best and worse than SFT results.", "description": "This table compares the performance of the proposed adversarial moment-matching distillation method against other state-of-the-art knowledge distillation methods on three different downstream tasks: text summarization (SAMSum dataset), machine translation (IWSLT'17 en-de dataset), and commonsense reasoning (StrategyQA dataset).  The results are broken down by the size of the student model (T5-Small, T5-Base, T5-Large) and show ROUGE-L scores for summarization, BLEU scores for machine translation, and accuracy scores for commonsense reasoning.  The table highlights the best, second best, and results that are worse than simply fine-tuning the student model (SFT).", "section": "4.2 Task-Specific Distillation"}, {"figure_path": "0VeSCjRDBy/tables/tables_21_1.jpg", "caption": "Table 1: Comparison with state-of-the-art KD methods on the instruction-following dataset using fine-tuned OpenLLaMA-7B as the teacher and fine-tuned OpenLLaMA-3B as the student. We format the best, the second best and worse than SFT results. The results based on GPT-2 are available in Appendix C.1.", "description": "This table compares the performance of the proposed adversarial moment-matching distillation method against several state-of-the-art knowledge distillation techniques on an instruction-following dataset.  The teacher model is a fine-tuned OpenLLaMA-7B, and the student model is a fine-tuned OpenLLaMA-3B.  The table highlights the best, second-best, and worse-than-SFT (supervised fine-tuning) results for each method across various evaluation metrics.  Additional results using GPT-2 are provided in the appendix.", "section": "4.1 Task-Agnostic Distillation"}, {"figure_path": "0VeSCjRDBy/tables/tables_21_2.jpg", "caption": "Table 1: Comparison with state-of-the-art KD methods on the instruction-following dataset using fine-tuned OpenLLaMA-7B as the teacher and fine-tuned OpenLLaMA-3B as the student. We format the best, the second best and worse than SFT results. The results based on GPT-2 are available in Appendix C.1.", "description": "This table compares the performance of the proposed adversarial moment-matching distillation method against several state-of-the-art knowledge distillation methods on an instruction-following task.  The teacher model is a fine-tuned OpenLLaMA-7B, and the student model is a fine-tuned OpenLLaMA-3B.  The table highlights the best performing method for each metric across different evaluation criteria and notes which methods perform better or worse than standard supervised fine-tuning (SFT).  Additional results using GPT-2 are available in the appendix.", "section": "4.1 Task-Agnostic Distillation"}, {"figure_path": "0VeSCjRDBy/tables/tables_22_1.jpg", "caption": "Table 1: Comparison with state-of-the-art KD methods on the instruction-following dataset using fine-tuned OpenLLaMA-7B as the teacher and fine-tuned OpenLLaMA-3B as the student. We format the best, the second best and worse than SFT results. The results based on GPT-2 are available in Appendix C.1.", "description": "This table compares the performance of the proposed adversarial moment-matching knowledge distillation method against several state-of-the-art methods on an instruction-following task.  The teacher model is OpenLLaMA-7B, and the student model is OpenLLaMA-3B.  Results are shown for multiple evaluation metrics (DollyEval, SelfInst, VicunaEval, S-NI, UnNI) and using different evaluation methods (GPT-4, R-L).  The table highlights the best performing method for each metric.", "section": "4.1 Task-Agnostic Distillation"}, {"figure_path": "0VeSCjRDBy/tables/tables_25_1.jpg", "caption": "Table 6: Effects of the off-/on-policy combination factor \u03b2 on four datasets.", "description": "This table shows the performance of the model on four different datasets (DollyEval, SAMSum, IWSLT'17 (en-de), StrategyQA) using different values for the off-/on-policy combination factor \u03b2.  The results demonstrate how varying the balance between on-policy and off-policy learning affects performance on different downstream tasks. The best results for each dataset are highlighted in bold.", "section": "4.3 Analysis on Step-Wise Distance Optimization"}]