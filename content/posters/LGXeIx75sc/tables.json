[{"figure_path": "LGXeIx75sc/tables/tables_7_1.jpg", "caption": "Table 1: Benchmark (a) Personalized Segmentation (b) Video Label Propagation. Our method shows the best performance on all benchmarks and achieves a notable balance between J and F, indicating its effectiveness in capturing both region and contour details.", "description": "This table presents the quantitative results of the proposed method (PDM) and other baseline methods on two tasks: personalized image segmentation and video label propagation.  The personalized image segmentation results are shown for two datasets, PerSeg and PerMIS (image).  Video label propagation results are shown for DAVIS and PerMIS (video).  Metrics used vary depending on the task and include mIoU, bIoU, J, F, and J&F.  The table demonstrates PDM's superior performance compared to other methods in both tasks.", "section": "5.1 Personalized Image Segmentation"}, {"figure_path": "LGXeIx75sc/tables/tables_8_1.jpg", "caption": "Table 2: Personalized Retrieval: Mean Average Precision (mAP) on various benchmarks comparing PDM with state-of-the-art self-supervised, weakly supervised, and supervised methods. While our method yields superior performance, other methods leveraging our PDM features also yield a performance boost.", "description": "This table presents a comparison of the mean average precision (mAP) for personalized retrieval across several benchmarks.  It compares the performance of the proposed Personalized Diffusion Features Matching (PDM) method against various state-of-the-art methods categorized into self-supervised, weakly supervised, and supervised approaches. The table highlights PDM's superior performance and demonstrates that incorporating PDM features into other methods can also lead to performance improvements.", "section": "5.3 Personalized Retrieval"}, {"figure_path": "LGXeIx75sc/tables/tables_13_1.jpg", "caption": "Table S 1: Performance comparison across diffusion models. We report segmentation performance (mIoU, bIoU), feature extraction run time per image, and mean PSNR for the inversion-reconstruction quality.", "description": "This table compares the performance of three different diffusion models (SDXL-turbo, SDXL, and SDv2.1) on two personalized image segmentation datasets (PerSeg and PerMIS).  For each model, it reports the mean Intersection over Union (mIoU) and boundary IoU (bIoU) scores, the time taken for feature extraction per image, and the mean Peak Signal-to-Noise Ratio (PSNR) which measures the quality of the image reconstruction after the inversion process.", "section": "5.1 Personalized Image Segmentation"}, {"figure_path": "LGXeIx75sc/tables/tables_14_1.jpg", "caption": "Table S 2: Comparison of performance between feature averaging and weighted averaging for combining appearance and semantic features on the ROxford-Hard and PerMIR datasets.", "description": "This table presents a comparison of the performance achieved using two different methods for combining appearance and semantic features: simple feature averaging (as used in the main paper) and weighted averaging (optimized using a training set). The results are shown for two datasets: ROxford-Hard (a standard benchmark dataset for image retrieval) and PerMIR (a new benchmark dataset introduced in this paper which includes multiple instances of the same object class). The weighted averaging approach significantly outperforms the simple averaging approach on both datasets, demonstrating the potential benefits of using more sophisticated methods for feature fusion, particularly when a training set is available.", "section": "5.3 Personalized Retrieval"}]