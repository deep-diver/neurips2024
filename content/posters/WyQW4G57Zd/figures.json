[{"figure_path": "WyQW4G57Zd/figures/figures_7_1.jpg", "caption": "Figure 1: (Top) Diffusion Bridge P* evaluated on 322. (Bottom) Learned process P evaluated on 2562", "description": "This figure shows the results of a diffusion bridge matching algorithm applied to bridging probability density functions. The top row shows the results when evaluating the learned process on a coarser grid (32x32), while the bottom row shows the results when evaluating on a finer grid (256x256).  The figure demonstrates the algorithm's ability to learn a smooth transition between two probability distributions, even when evaluated at different resolutions. This highlights the algorithm's resolution-invariance property and its capability of learning continuous functional representations rather than simply memorizing discrete evaluations.", "section": "5.1 Bridge Matching"}, {"figure_path": "WyQW4G57Zd/figures/figures_7_2.jpg", "caption": "Figure 2: Results on 1D function generation. (Left) Real data and (Right) generated samples from our model.", "description": "This figure displays the results of 1D function generation experiments using three different datasets: Quadratic, Melbourne, and Gridwatch.  The left column shows the real data for each dataset, while the right column shows the samples generated by the proposed model. The plots visually compare the generated samples against the ground truth data, showcasing the model's ability to generate realistic data that closely resembles the original datasets' distributions.  This demonstrates the effectiveness of the proposed approach in modeling and generating one-dimensional functions.", "section": "5.1 Bridge Matching"}, {"figure_path": "WyQW4G57Zd/figures/figures_8_1.jpg", "caption": "Figure 3: Results on Unpaired image transfer task. (Up) EMNIST \u2192 MNIST (Down) AFHQ-64 Wild \u2192 Cat. (Left) Real data and (Right) generated samples from our model. For generation at unseen resolutions, the images within the red and blue boxed initial conditions were upsampled (using bi-linear transformation) from the observed resolution (322) for EMNIST and (642) for AFHQ-64 Wild, respectively.", "description": "This figure shows the results of an unpaired image transfer experiment using the proposed method.  Two datasets are used: EMNIST to MNIST (top) and AFHQ-64 Wild to Cat (bottom).  The left side displays real images from the target datasets, and the right shows the images generated by the model.  The experiment demonstrates the model's ability to transfer images even at higher resolutions than those it was trained on (unseen resolutions).  Images in the red and blue boxes were upsampled before being passed through the model. This highlights the model's capacity to learn continuous functional representations rather than simply memorizing discrete evaluations.", "section": "5.1 Bridge Matching"}, {"figure_path": "WyQW4G57Zd/figures/figures_9_1.jpg", "caption": "Figure 4: Sampled functions from a learned stochastic process X evaluated on [0, I] for t \u2208 [0, \u03c4, T]. The grey line represents the mean function E[X] and the blue-shaded region represents the confidence interval. (Left) GP with RBF kernel. (Right) Physionet.", "description": "This figure shows the results of applying the Bayesian learning algorithm to generate functions from a learned stochastic process.  The left panel displays results using a Gaussian Process with a radial basis function kernel, while the right panel shows results using the Physionet dataset.  Each panel shows several sampled functions with the mean and confidence interval. The goal is to illustrate the algorithm's ability to accurately reconstruct functions from partial observations.", "section": "5.2 Bayesian Learning"}, {"figure_path": "WyQW4G57Zd/figures/figures_21_1.jpg", "caption": "Figure A.1: Transformer-based network architecture.", "description": "This figure illustrates the architecture of the transformer-based network used in the paper's experiments.  The input is a latent array representing the data (e.g., an image). This is then processed by an encoder, which consists of cross-attention and self-attention blocks.  The output from the encoder is further transformed, (e.g., using a projection or GFFT), and fed into a decoder consisting of additional cross-attention and self-attention blocks. Finally, the output of the decoder is transformed into the desired output, such as a generated image.", "section": "A.8 Experimental Details"}, {"figure_path": "WyQW4G57Zd/figures/figures_23_1.jpg", "caption": "Figure 3: Results on Unpaired image transfer task. (Up) EMNIST \u2192 MNIST (Down) AFHQ-64 Wild \u2192 Cat. (Left) Real data and (Right) generated samples from our model. For generation at unseen resolutions, the images within the red and blue boxed initial conditions were upsampled (using bi-linear transformation) from the observed resolution (322) for EMNIST and (642) for AFHQ-64 Wild, respectively.", "description": "This figure shows the results of an unpaired image transfer task using the proposed method.  The top row demonstrates the transfer from the EMNIST dataset to the MNIST dataset, while the bottom row shows the transfer from the AFHQ-64 Wild dataset to the AFHQ-64 Cat dataset. The left column displays the real data, while the right column displays samples generated using the proposed method.  The experiment also tests the model's ability to generate images at higher resolutions than it was trained on (unseen resolutions), showing the results at 32x32, 64x64, and 128x128 pixel resolutions.", "section": "5.1 Bridge Matching"}, {"figure_path": "WyQW4G57Zd/figures/figures_23_2.jpg", "caption": "Figure 3: Results on Unpaired image transfer task. (Up) EMNIST \u2192 MNIST (Down) AFHQ-64 Wild \u2192 Cat. (Left) Real data and (Right) generated samples from our model. For generation at unseen resolutions, the images within the red and blue boxed initial conditions were upsampled (using bi-linear transformation) from the observed resolution (322) for EMNIST and (642) for AFHQ-64 Wild, respectively.", "description": "This figure shows the results of an unpaired image translation experiment using the proposed method.  The top row demonstrates translation from EMNIST to MNIST, and the bottom row shows translation from wild cat images (AFHQ) to domestic cat images (AFHQ). The left columns show real images, and the right columns show images generated by the model. Notably, the model also generates images at higher resolutions (128x128) than the training resolution (32x32 and 64x64), demonstrating resolution invariance.", "section": "5.1 Bridge Matching"}]