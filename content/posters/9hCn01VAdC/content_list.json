[{"type": "text", "text": "Knowledge-Empowered Dynamic Graph Network for Irregularly Sampled Medical Time Series ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yicheng Luo, Zhen Liu\\*, Linghao Wang, Junhao Zheng, Binquan Wu, Qianli Ma\u2217 ", "page_idx": 0}, {"type": "text", "text": "School of Computer Science and Engineering, South China University of Technology, Guangzhou, China {csluoyicheng2001, cszhenliu, cskyun_ng} $@$ mail.scut.edu.cn, {linghaowang6, junhaozheng47} $@$ outlook.com, qianlima@scut.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Irregularly Sampled Medical Time Series (ISMTS) are commonly found in the healthcare domain, where different variables exhibit unique temporal patterns while interrelated. However, many existing methods fail to efficiently consider the differences and correlations among medical variables together, leading to inadequate capture of fine-grained features at the variable level in ISMTS. We propose Knowledge-Empowered Dynamic Graph Network (KEDGN), a graph neural network empowered by variables\u2019 textual medical knowledge, aiming to model variable-specific temporal dependencies and inter-variable dependencies in ISMTS. Specifically, we leverage a pre-trained language model to extract semantic representations for each variable from their textual descriptions of medical properties, forming an overall semantic view among variables from a medical perspective. Based on this, we allocate variable-specific parameter spaces to capture variable-specific temporal patterns and generate a complete variable graph to measure medical correlations among variables. Additionally, we employ a density-aware mechanism to dynamically adjust the variable graph at different timestamps, adapting to the time-varying correlations among variables in ISMTS. The variable-specific parameter spaces and dynamic graphs are injected into the graph convolutional recurrent network to capture intra-variable and inter-variable dependencies in ISMTS together. Experiment results on four healthcare datasets demonstrate that KEDGN significantly outperforms existing methods. Our code is available at https://github.com/qianlima-lab/KEDGN. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In the medical environment, the widely used Electronic Health Records (EHRs) have abundant typical Irregularly Sampled Medical Time Series (ISMTS) data [1]. Each ISMTS typically comprises multiple medical variables for a patient, each with distinct medical properties, resulting in significant differences in the sampling patterns of each variable series. Additionally, due to the dynamic changes in a patient\u2019s condition, the sampling rate of variables varies over different periods, resulting in uneven sampling intervals [2]. ", "page_idx": 0}, {"type": "text", "text": "Many existing methods for ISMTS primarily focus on addressing uneven sampling intervals and have proposed approaches such as Ordinary Differential Equations (ODEs) [3, 4] and continuous-time embeddings [5, 6], etc, which have already achieved significant success. Recent advancements in regularly sampled multivariate time series analysis [7, 8] underscore the importance of capturing variable-specific temporal patterns. However, many existing methods for ISMTS have not adequately considered this aspect, having limited ability to explicitly distinguish multiple variable series with different time patterns and thus lacking finer-grained capturing of variable-level features. Particularly in ISMTS, different variables have distinct medical properties, further intensifying the degree of differences among variables. In such cases, capturing differentiated variable patterns requires a deeper exploration of inherent differences among variables. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Despite the differentiated temporal patterns occurring among variables within ISMTS, they are not entirely independent but exhibit medical correlations. Due to the dynamic changes in the patient\u2019s condition, this correlation varies along with the sampling density of variables at different periods, as illustrated in Figure 1. Some existing work has introduced graph neural networks [9, 10] to model the time-varying correlations among variables in ISMTS. However, due to the lack of prior medical knowledge, these methods learn variable correlation graphs from misaligned and imbalanced observations in variables of ISMTS and rely solely on downstream tasks for graph optimization. Consequently, the variable graphs learned by these methods may face challenges in accurately reflecting the general medical correlations among variables, resulting in suboptimal performance. ", "page_idx": 1}, {"type": "text", "text": "To this end, we aim to explicitly consider the differences and correlations among variables in ISMTS, empowering the model to capture fine-grained features at the variable level. However, the sampling rates, sampling times, observation spans, and observation lengths of different variables vary in ISMTS, as shown in three subgraphs in Figure 2. This makes it tough and complex to infer these two aspects only from the time series modality of variables. We rethink the issue based on an intuitive observation as shown in Figure 2: Variables that exhibit (dis)similar temporal patterns frequently have (dis)similar medical properties in reality, which motivates us to consider the differences and correlations of variables from the perspective of domain knowledge directly. Recent work [11, 12] has successfully represented domain knowledge through textual modal information, enhancing model performance in medical imaging, which provides us with insights. Specifically, the medical properties of each variable can be described in natural language. Leveraging the powerful semantic understanding capabilities of the Pre-trained Language model (PLM), we can obtain semantic representations from the textual knowledge of each variable. This set of textual representations forms an overall view of variables from the perspective of medical knowledge, clearly showing inherent differences and correlations among variables\u2014exactly what we need. ", "page_idx": 1}, {"type": "image", "img_path": "9hCn01VAdC/tmp/9af021007af69a5ded08f46dbb41a1290bd7eae18ac6576d0545b7fab80c495c.jpg", "img_caption": ["Figure 1: Illustration of three variables in an ISMTS sample. In the first 7 seconds (Box 1), a strong correlation between HR and NIDiasABP is observed. As NIDiasABP becomes more sparse, the correlation between HR and NIDiasABP weakens between 7 and 50 seconds (Box 2), while the correlation between HR and DiasABP increases. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Based on the above analysis, we propose the Knowledge-Empowered Dynamic Graph Network (KEDGN), which utilizes textual semantic representations of variables obtained through PLM as guidance. On this basis, we 1) allocate unique parameter space for each variable to capture their specific temporal pattern, 2) generate a complete variable graph and introduce a density-aware mechanism to explicitly model time-varying correlations among variables in ISMTS. Finally, these ", "page_idx": 1}, {"type": "image", "img_path": "9hCn01VAdC/tmp/38954d35f25aff031a30a6e1a52ab104d89b684e00bbd14bcdad0ea2eb649685.jpg", "img_caption": ["(a) Invasive arterial blood pressure (b) Renal function indicators (c) Ion concentration indicators "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 2: The time patterns (sampling rates, sampling times, observation spans, observation lengths, trends, etc.) of variables among different subgraphs exhibit significant differences, as they have distinct medical properties. Meanwhile, variables within the same subgraph share similar time patterns, and their medical properties are closely related. (More variable groups can be found in Figure 7). ", "page_idx": 1}, {"type": "text", "text": "two modules are integrated with a graph convolutional recurrent network to capture both temporal and inter-variable dependencies in ISMTS. Our contributions can be summarized in three aspects: ", "page_idx": 2}, {"type": "text", "text": "\u2022 We leverage variable-specific textual medical knowledge to empower the model to capture variable-specific temporal patterns in ISMTS distinctively.   \n\u2022 We introduce a density-aware mechanism based on the knowledge-empowered variable graph to model the time-varying inter-variable dependencies in ISMTS.   \n\u2022 Empirical results on four real-world medical datasets demonstrate that KEDGN outperforms state-of-the-art methods. Visualization analysis further illustrates the strong interpretability of our approach. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Irregularly Sampled Multivariate Time Series Modeling Existing methods can be roughly categorized into interpolation-based and raw data-based approaches. The former, employing methods such as kernel-based approaches [13, 14], Gaussian process [15] or hourly aggregation [16], aims to obtain a set of regularly spaced observations. However, interpolation may result in the loss of useful information about the original sequences, such as missing patterns. The latter, raw databased methods, directly learn from irregular time series. To adapt to uneven sampling intervals, [17] improves recurrent neural networks, [3, 4] introduce neural ordinary differential equations and [6, 5, 18, 19] adopt time embeddings. [20] converts ISMTS into line graph images and utilizes pretrained vision transformers for extracting features. These methods primarily focus on overall temporal dependencies, needing more consideration for fine-grained variable-level patterns and correlations. Despite recent research introducing attention [21, 22] or graph neural networks [9, 23] to account for variable correlations, these methods have limited performance due to the lack of prior knowledge and the use of shared parameter spaces among all variables. ", "page_idx": 2}, {"type": "text", "text": "Graph Neural Networks for Multivariate Time Series In recent years, a series of studies have integrated GNN with various time series modeling frameworks to effectively capture both intervariable and inter-temporal dependencies in MTS [24]. These approaches have been widely applied in diverse domains, including transportation [25], healthcare [26], economics [27], demonstrating promising results in mainstream tasks such as prediction [28], classification [29], and imputation [30]. Although recent work [31, 32, 33, 34] has proposed the idea of modeling variable relationships through learning dynamic graphs, most of these methods are primarily designed for regularly sampled MTS with synchronous observations, and further improvements are needed to adapt them for irregularly sampled time series. ", "page_idx": 2}, {"type": "text", "text": "Medical Knowledge Enhanced Models Several studies have utilized the rich domain knowledge in the medical field to enhance models. [12, 35] apply knowledge for computing additional features, while [36, 37] utilize knowledge to guide the final training loss, demonstrating the effectiveness of medical prior knowledge. However, existing methods commonly focus on visual language pretraining in medical scenes or medical report generation [11]. How to effectively integrate domain knowledge to guide medical time series modeling remains a challenge. ", "page_idx": 2}, {"type": "text", "text": "3 Problem Definition ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given a dataset $\\mathcal{D}\\,=\\,\\{(s_{i},\\;\\;y_{i})\\;|\\;\\;i\\,=\\,1,..\\,,\\;N\\}$ containing $N$ patient samples, the $i$ -th sample consists of an irregular multivariate time series $s_{i}$ and a label $y_{i}$ . For the dataset with a total variable count of $V$ and a maximum sample observation length of $T$ , $s_{i}$ can be denoted as a tuple: $s_{i}=(t_{i},x_{i},m_{i})$ , where $t_{i}\\in\\mathbb{R}^{T}$ represents the observation timestamps, $\\boldsymbol{x}_{i}\\in\\mathbb{R}^{V\\times T}$ represents the multivariate time series observations, and any unobserved values or the missing parts of the time series shorter than the maximum sample observation length are filled with 0. The binary indicator $m_{i}$ has the same size as $x_{i}$ , indicating which elements in the $x_{i}$ are actually observed. We use 1 to represent observed values and 0 to represent missing values. In this paper, we focus on patient mortality and morbidity prediction, i.e., classification task, aiming to correctly predict class label $\\hat{y}_{i}$ given a sample $s_{i}$ . ", "page_idx": 2}, {"type": "image", "img_path": "9hCn01VAdC/tmp/d71461893b4fdedced78b8f9337ddb6b2d6d1c21f8f0bd7347d5621dbc80143d.jpg", "img_caption": ["Figure 3: The model framework of KEDGN. We (1) utilize a PLM to extract semantic representations for each variable from textual medical properties (Section 4.1). Based on this, we (2) allocate variable-specific parameter space to capture variable-specific temporal patterns (Section 4.2), (3) generate dynamic variable graphs by combining knowledge-empowered graph with a density-aware mechanism to model time-varying correlations among variables (Section 4.3). (4) The above two modules are injected into graph convolutional recurrent network to model intra-variable and intervariable dependencies in ISMTS simultaneously (Section 4.4). "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "4 The Proposed Model ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "4.1 Variable Semantic Representations Extraction ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "First, we introduce how to extract semantic representation for each variable from medical knowledge. Let $\\mathcal{V}=\\{v_{1},v_{2},\\ldots,v_{V}\\}$ be the set of variables, and a descriptive sentence of medical properties associated with the $j^{t h}$ variable can be denoted as: ", "page_idx": 3}, {"type": "equation", "text": "$$\nP_{j}=\\big\\{w_{j,1},w_{j,2},...,w_{j,l_{j}}\\;\\big|\\;\\;j=1,2,...\\,,\\;V\\big\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $l_{j}$ is the length of the $j^{t h}$ variable\u2019s sentence and $w_{j,i}$ denotes the $i^{t h}$ word of the $j^{t h}$ sentence. We leverage a PLM to represent each text description $P_{j}$ as a $d$ -dimensional embedding. Considering the diverse types of PLMs with varying methods of utilization, we use the widely adopted encoderbased model BERT [38] as an illustration: ", "page_idx": 3}, {"type": "equation", "text": "$$\ne_{j}=\\mathbf{B}\\mathbf{E}\\mathbf{R}\\mathbf{T}([\\mathrm{CLS}],w_{j,1},w_{j,2},...,w_{j,l_{j}},[\\mathrm{SEP}])\\in\\mathbb{R}^{(l_{j}+2)\\times d},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where [CLS] and [SEP] are special tokens indicating a sequence\u2019s beginning and end, respectively. BERT generates an embedding for each token of the input sequence. Since the embedding at the [CLS] position captures the semantic information of the entire input sequence, we take the hidden state at the [CLS] position as the overall semantic representation of each variable: $E_{j}=e_{j}(\\mathrm{[CLS]})$ . This yields a semantic representation matrix $\\pmb{{\\cal E}}=[{\\cal E}_{1},{\\cal E}_{2},...,{\\cal E}_{V}]\\in\\mathbb{R}^{V\\times d}$ and forms an overall view of variables from the perspective of medical knowledge. ", "page_idx": 3}, {"type": "text", "text": "4.2 Variable-specific Parameter Learning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Since temporal patterns of ISMTS vary from variable to variable, simply using shared parameter space for all variables is insufficient to capture differentiated temporal dependencies. In this section, we adjust parameter space for different variables to adapt to differentiated temporal patterns based on the extracted variables\u2019 semantic representations. For any parameter matrix $\\boldsymbol{w}\\overset{\\cdot}{\\in}\\mathbb{R}^{I\\times O}$ with input dimension $I$ and output dimension $O$ , the total parameter space needed for $V$ variables is $\\Theta^{^{\\!}}\\in\\mathbb{R}^{V\\times I\\times O}$ . Inspired by [39], we decompose $\\Theta$ into two matrices: a variable representation matrix $Q\\in\\mathbb{R}^{V\\times q}$ and a weight pool matrix $\\mathbf{\\mathcal{W}}\\in\\mathbb{R}^{q\\times I\\times O}$ , where $q$ is a hyperparameter for the intermediate dimension. Here, $Q$ consists of $q$ -dimensional query vectors for $V$ variables used to distinguish differences among variables and obtain variable-specific parameters from the weight pool. ", "page_idx": 3}, {"type": "text", "text": "We use a projection $f(\\cdot):\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{q}$ to variable semantic representations $\\boldsymbol{E}$ for obtaining query vectors rather than directly using $\\boldsymbol{E}$ . On the one hand, the dimension of the query vector $q$ directly determines the size of the weight pool, but the output dimension of PLM is often large (e.g., 768 in BERT), leading to a sharp increase in model complexity. On the other hand, there is a modality gap between textual embeddings and the temporal parameter space. The projection $f(\\cdot)$ can achieve both feature reduction and modality transformation. In our implementation, we use a nonlinear projection with one additional hidden layer (and ReLU activation). Thus, the parameter space specific to variable $i$ can be obtained using the following formula: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta_{i}=f(E_{i})W\\in\\mathbb{R}^{I\\times O},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The approach we employ to generate variable-specific parameter space is general and not restricted to a specific model backbone because any model architecture is composed of multiple parameter matrices $W$ . ", "page_idx": 4}, {"type": "text", "text": "4.3 Dynamic Variable Graph Generation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we introduce how to generate dynamic correlation graphs of variables for explicitly modeling the time-varying correlations among variables in ISMTS. ", "page_idx": 4}, {"type": "text", "text": "4.3.1 Complete Variable Correlation Graph Learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The misaligned and imbalanced observations of the variables in ISMTS make it difficult to learn the variable correlations from the time series. Therefore, we extract a static complete variable correlation graph based on the textual semantic representations of the variables directly from the perspective of the actual medical properties of variables. We apply another non-linear projection $g(\\cdot):\\mathbb{R}^{d^{\\star}}\\!\\to\\mathbb{R}^{n}$ to the textual representations of variables $\\boldsymbol{E}$ to obtain $n$ -dimensional node embeddings for each variable. Subsequently, we calculate the pairwise cosine similarity among the node embeddings of variables, resulting in a $V\\times V$ matrix of variable similarity. Finally, we use the softmax function to normalize the edge weights corresponding to each node, producing a normalized graph of variable correlations. The correlation weight between the $i^{t h}$ and $j^{t\\bar{h}}$ variables can be calculated as: ", "page_idx": 4}, {"type": "equation", "text": "$$\nA_{i j}=\\mathrm{\\Softmax}(\\frac{g(E_{i})\\cdot g(E_{j})}{\\|g(E_{i})\\|\\cdot\\|g(E_{j})\\|}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\cdot$ represents vector dot product and $\\Vert\\cdot\\Vert$ represents the vector magnitude. The introduction of $g(\\cdot)$ in this context not only performs feature reduction but also avoids using a completely fixed prior graph. It preserves the model\u2019s ability to adaptively optimize the graph structure based on different data distributions and downstream tasks. Thus, we obtain a knowledge-empowered complete graph with $V$ nodes to measure the static correlation among variables in general medical cases, and its adjacency matrix is denoted as $\\pmb{A}$ . ", "page_idx": 4}, {"type": "text", "text": "4.3.2 Dynamic Density-aware Adjustment Mechanism ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Due to the varying subsets of variables observed at each timestamp in ISMTS, we use different subgraphs of $\\pmb{A}$ to describe the variable correlations at different timestamps. Specifically, we use a mask matrix $M^{(t)}\\in\\mathbb{R}^{V\\times V}$ to indicate the subgraph topology at timestamp $t$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\nM_{i j}^{(t)}=\\binom{1,}{0,}\\;\\;\\;\\mathrm{if\\;both\\;variables\\;}i\\;\\mathrm{and}\\;j\\;\\mathrm{are\\;observed\\;at}\\;t\\;,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Therefore, we can calculate the variable correlation subgraph $A^{(t)}$ at timestamp $t$ through $A^{(t)}=$ $A\\odot M^{(t)}$ , where $\\odot$ represents Hadamard product. Additionally, we introduce a density-aware mechanism to dynamically adjust edge weights of subgraphs in different timestamps to fit in the time-varying correlations among variables mentioned in Figure 1. Specifically, we estimate the sampling density of any observation point by considering the average time interval between each observation point and its preceding and succeeding observations. If there is no preceding/succeeding observation, we take the time interval of the succeeding/preceding observation as the density. If neither a preceding nor a succeeding observation exists, it indicates that this observation is the only one for the variable, and we take half of the maximum observation time span as the density. The formula for calculating the sampling density of the $i$ -th observation of variable $v$ at timestamp $t$ is: ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\nZ^{(t)}=Z_{i,v}=\\left\\{\\begin{array}{l l}{((t_{i,v}-t_{i-1,v})+(t_{i+1,v}-t_{i,v}))/2,\\mathrm{if~both}\\;t_{i+1,v}\\mathrm{~and~}t_{i-1,v}\\mathrm{~exist}}\\\\ {t_{i,v}-t_{i-1,v},}&{\\mathrm{if~}t_{i+1,v}\\mathrm{~does~not~exist}}\\\\ {t_{i+1,v}-t_{i,v},}&{\\mathrm{if~}t_{i-1,v}\\mathrm{~does~not~exist}}\\\\ {t_{m a x}/2,}&{\\mathrm{if~neither~}t_{i+1,v}\\mathrm{~nor~}t_{i-1,v}\\mathrm{~exists}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Then we calculate the density scores for various variables at timestamp $t$ through: ", "page_idx": 5}, {"type": "equation", "text": "$$\nD^{(t)}=\\alpha\\sigma(Z^{(t)})\\in\\mathbb{R}^{V},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\sigma$ is an activation function and $\\alpha$ is a hyperparameter that controls the proportion. At timestamp $t$ , the edge weight between the $i^{t h}$ and $j^{t h}$ variables is adjusted as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{G}_{i j}^{(t)}=\\pmb{A}_{i j}^{(t)}\\times(1-W_{i j}|D_{i}^{(t)}-D_{j}^{(t)}|),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $W\\in\\mathbb{R}^{V\\times V}$ is a learnable parameter matrix. Thereby, we achieve the dynamic adjustment of the variable graph weights in response to changes in variable sampling density. ", "page_idx": 5}, {"type": "text", "text": "4.4 Variable-specfic Dynamic Graph Convolutional Recurrent Network ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Under the empowerment of variable textual representation, we have obtained variable-specific parameters $\\stackrel{\\cdot}{\\Theta}\\,\\stackrel{\\cdot}{\\in}\\mathbb{R}^{V\\times I\\times O}$ and dynamic variable graph $G\\in\\mathbb{R}^{T\\times V\\times V}$ . In this section, we integrate these two modules into the graph convolutional neural network to handle ISMTS. GCRNN [40] is a backbone network that introduces graph convolutional operations on top of an RNN variant, Gated Recurrent Unit [41]. This structure is simple, effective, and easy-to-adapt for ISMTS, as it enables variable-level parallel computation of asynchronous observations without explicit interpolation. Specifically, we allocate a unique hidden state for each variable, updating the state only at the observed timestamps to avoid imputation and preserve the individual sampling patterns of each variable. The graph convolution operation over a graph signal $S\\in\\mathbb{R}^{V\\times I}$ containing $V$ nodes at timestamp $t$ is defined as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Theta\\star_{G^{(t)}}S\\approx(I_{V}+G^{(t)})^{T}S\\times\\Theta,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $I_{V}\\,\\in\\,\\mathbb{R}^{V\\times V}$ is identity matrix, $\\times$ represents batch matrix multiplication. Here, we adopt $1^{s t}$ -order Chebyshev polynomial expansion approximation [42] for graph convolution. The updated formulas for variable states at timestamp $t$ are: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r^{(t)}=\\sigma(\\Theta_{r}\\star_{G^{(t)}}[X^{(t)}||H^{(t-1)}]+b_{r}),}\\\\ &{u^{(t)}=\\sigma(\\Theta_{u}\\star_{G^{(t)}}[X^{(t)}||H^{(t-1)}]+b_{u}),}\\\\ &{C^{(t)}=t a n h(\\Theta_{C}\\star_{G^{(t)}}[X^{(t)}||(r^{(t)}\\odot H^{(t-1)})]+b_{C}),}\\\\ &{H_{i}^{(t)}=\\left\\{H_{i}^{(t-1)},\\quad\\mathrm{if~variable~}i\\mathrm{~is~unobserved~at~time~}t\\quad\\right.,}\\\\ &{\\left.u_{i}^{(t)}\\odot H_{i}^{(t-1)}+(1-u_{i}^{(t)})\\odot C_{i}^{(t)},\\mathrm{otherwise~}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $||$ denotes the concatenate operation, $H^{(t-1)}\\in\\mathbb{R}^{V\\times h}$ is the variable states at the previous timestamp and $X^{(t)}\\in\\mathbb{R}^{V\\times k}$ denotes the input representation at current timestamp. We follow the structured input encoding method of [22], using multiple fully-connected mappings to encapsulate each observed value and its corresponding timestamp into a $k$ -dimensional input representation $\\left[A\\right]\\rvert\\left.0\\right$ vectors for unobserved values) to indicate flexible observation time and adapt to the uneven intervals within variables. $\\boldsymbol{r}^{(t)},\\boldsymbol{u}^{(t)}\\,\\in\\,\\mathbb{R}^{V\\times h}$ are reset gate and updated gate, respectively. $\\Theta_{r},\\Theta_{u},\\Theta_{C}\\in$ RV \u00d7(k+h)\u00d7h are variable-specific parameters obtained by respectively multiplying the query vectors matrix $Q\\in\\mathbb{R}^{V\\times q}$ with three weight matrices $W_{r},W_{u},\\bar{W}_{C}\\in\\mathbb{R}^{q\\times(\\bar{k}+h)\\times h}$ . ", "page_idx": 5}, {"type": "text", "text": "We calculate the sum of $h$ channels for each variable\u2019s hidden state $H_{i}$ at the last observed timestamp to get a $V$ -dimensional vector $C$ . Additionally, we follow the approach used in [9] to incorporate the static features. Specifically, static features of each sample are mapped into a static vector $S$ through a linear layer. Finally, $C$ and $S$ are concatenated to predict the final classification probabilities: $\\hat{y}=\\mathrm{Softmax}(W^{y}[C||S]+b^{y})$ . The training objective is minimizing the cross-entropy loss between $\\hat{y}$ and $y$ . The pseudo-code for KEDGN is presented in Appendix A (Algorithm 1). ", "page_idx": 5}, {"type": "text", "text": "5 Experiment ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1 Experimental Setting ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets and Baselines We conduct experiments on four widely used irregular medical time series datasets, namely P19 [43], Physionet [44], MIMIC-III [45] and P12 [46] where Physionet is a reduced version of P12 considered by prior work [6]. We compare our method with the state-of-the-art methods for modeling irregular time series, including GRU-D [17], ODE-RNN [4], IP-Net [14], SeFT [5], mTAND [6], Raindrop [9], StraTS [18], DuETT [19], ViTST [20] and Warpformer [22]. In addition, we also compare our method with two approaches initially designed for forecasting tasks, namely $\\mathrm{\\DeltaDGM^{2}}$ -O [13] and MTGNN [47]. The implementation and hyperparameter settings of these baselines are kept consistent with those used in [9]. More details of datasets and baselines can be found in Appendix B and C. ", "page_idx": 6}, {"type": "text", "text": "Evaluation Setup For the data pre-processing of MIMIC-III, we follow the method described in [48] and divide the dataset into three parts for training, validation, and testing with the ratio of $70\\%,15\\%,15\\%$ . For the remaining three datasets, we adhered to [9] \u2019s approaches, and the ratio of training, validation, and testing set is 8:1:1. We measure the classification performance with the Area Under the Receiver Operating Characteristic Curve (AUROC) and Area Under the Precision-Recall Curve (AUPRC) since all the four datasets are binary classification datasets with highly imbalanced class distribution. AUPRC has better sensitivity to sample imbalance [49]; thus, the optimal model parameters that achieve the best AUPRC on the validation set are used for the test set. More details of metrics can be found in Appendix D. ", "page_idx": 6}, {"type": "text", "text": "Implementation Details We adopt the Adam [50] optimizer, and the number of training epochs is set as 10. Due to differences in dataset sizes, the learning rate is set as 0.001 for Physionet and P12 and 0.005 for MIMIC-III and P19. The textual sources for variable descriptions are flexible; we chose three sources, including the variable\u2019s full name, Wikipedia source, and ChatGPT source (Default), corresponding to model names KEDGN-Name, KEDGN-Wiki, and KEDGN-ChatGPT, respectively. All experiments are conducted with five random seeds, and the average and standard deviation are reported. More implementation details and hyperparameter settings can be found in Appendix E. ", "page_idx": 6}, {"type": "text", "text": "5.2 Main Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Table 1: Method benchmarking on irregularly sampled medical time series classification. The best results are highlighted in bold, and the second-best results are in underlined. The results in the table are presented in the form of $(\\mathrm{Mean}\\pm\\mathrm{Std}\\;\\%)$ ). ", "page_idx": 6}, {"type": "table", "img_path": "9hCn01VAdC/tmp/1ad5c727ef784ab58debc839634f6f1170e3c730306a2046fe90909c4d8b5cec.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Classic time series classification The evaluation results are summarized in Table 1, in which we use BERT to extract variables\u2019 semantic representations. More experimental results and analyses using other PLMs can be found in Appendix F.1. Overall, our KEDGN achieves the best performance on all four datasets and outperforms the strongest baseline by an average of $0.9\\%$ on AUROC and ", "page_idx": 6}, {"type": "text", "text": "$1.6\\%$ on AUPRC. In addition, the results of models using different text sources are similar, which demonstrates that our method is not limited to a specific text source and exhibits generalizability. We also provide an analysis of computational costs in Appendix F.2. ", "page_idx": 7}, {"type": "text", "text": "Leave-variables-out To demonstrate the robustness of our method, we test whether KEDGN can achieve good performance when a subset of variables is completely missing. We uniformly discard $10\\%$ , $20\\%$ , $30\\%$ , $40\\%$ , and $50\\%$ of the variables, hiding all their observations in both validation and test sets. Table 2 reports the results on the MIMIC-III dataset, while the results for the remaining datasets are presented in Appendix F.3 (Table 8). Our method achieves the highest performance on 35 out of 40 metrics across 4 datasets as the missing rate increases from $10\\%$ to $50\\%$ . This may be attributed to KEDGN only handling actually observed points, avoiding the accumulation of imputation errors, particularly in cases of higher missing ratios, thus exhibiting a degree of robustness. ", "page_idx": 7}, {"type": "table", "img_path": "9hCn01VAdC/tmp/083919daa8bcdfb3c14eb2d2f1cbeb115b6e07072d56d25a43c550f95ce14733.jpg", "table_caption": ["Table 2: Classification performance on samples with a fixed set of left-out variables on the MIMIC-III dataset. The best results are highlighted in bold and the second best results are in underlined. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "5.3 Ablation Study ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we investigate the performance benefits generated by each key component of the proposed method on all four datasets. We compare the full versioned method with its six variants: (1) w/o VSW: We apply shared RNN parameter weights for all variables; (2) w/o Text: We replace the variable-specific textual semantic representations $E_{i}$ with randomly initialized learnable embeddings; (3) w/o Graph: We set the graph $\\boldsymbol{G}$ to be a fully zero matrix, disregarding dependencies among variables; (4) w/o KEE: We replace knowledge-empowered node embeddings of variables $\\bar{g}(E_{i})$ with randomly initialized learnable embeddings, (5) w/o DAG: We remove the density-aware adjustment for edge weights of the graph, using static adjacency matrix $A^{(t)}$ during different periods. (6) w/o TE: We remove the timestamp embedding part of the structured input encoding $X^{(t)}$ . The results on the P19 dataset are presented in Table 3, while the results for the remaining datasets are presented in Appendix F.4 (Table 9). The results show that all model components are necessary and variable-specific parameter space makes the most significant contribution to the performance of KEDGN. ", "page_idx": 7}, {"type": "table", "img_path": "9hCn01VAdC/tmp/210490b533459af7d1d611434c0147d732fc2481c45017635ad80e095f1d38e7.jpg", "table_caption": ["Table 3: The ablation study of our proposed method KEDGN on P19. The results in the table are presented in the form of $(\\mathrm{Mean}\\pm\\mathrm{Std}\\;\\%)$ ). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5.4 Visualization Analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "5.4.1 Visualization of Variables Textual Representations ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we explore why textual information is effective for time series modeling through visualization analysis. We first group variables with similar time patterns on the P12 dataset, as illustrated in Figure 2 (More variables groups can be found in Appendix F.7 (Figure 7)). Subsequently, we use T-SNE [51] to visualize the distribution of variable semantic representations. Figures 4a and 4b respectively display the distributions of ChatGPT and Wikipedia sources, while Figure 4c shows the final distribution learned by replacing the text representation with randomly initialized learnable embeddings. Variables with similar time patterns are labeled with the same color. It can be observed that the textual representation space of variables exhibits distinct clustering. Although there may be occasional outliers when using different text sources, such as BUN in Figure 4a and HCO3 in Figure 4b, the overall clusters are generally consistent with the variable groups we divide based on time series patterns. However, the learnable variable embeddings in Figure 4c, optimized by classification loss, tend to be distributed uniformly, which is difficult to effectively reflect the intrinsic differences among variables. More visualizations of other datasets and other PLMs can be found in Appendix F.8 and F.9, respectively. Based on this phenomenon, we infer that text descriptions and time series are both external manifestations of the inherent sense of variables; they just belong to different data modalities. These two forms of data for the same variable should exhibit relative consistency. Therefore, the relative distribution among variables extracted from text and time series should ideally be similar. Leveraging PLM allows for the straightforward and efficient extraction of this universal view from textual descriptions, which is equally applicable to describing the relative distribution of temporal patterns among variables. Thus, the effectiveness of PLM and the cross-modal relative consistency are the keys to guiding time series modeling based on textual information. ", "page_idx": 7}, {"type": "image", "img_path": "9hCn01VAdC/tmp/b90436b5725404ea874b79b6c89ba765f17c7064ef0fa8c127b4ad980b18f763.jpg", "img_caption": ["Figure 4: T-SNE visualization of partial variable representations on the P12 dataset. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5.4.2 Visualization of Variable Correlation Graph ", "text_level": 1, "page_idx": 8}, {"type": "image", "img_path": "9hCn01VAdC/tmp/e7836c78745c7e5fda537a2218cf3932900e177d9b0cdc17bf71245139115373.jpg", "img_caption": ["Figure 5: Visualization of the learned correlation graph of variables on the MIMIC-III dataset. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "We visualize the learned partial inter-variable correlation graphs on the MIMIC-III dataset in the form of heatmaps. In Figure 5a, we depict the graph learned based on node embeddings mapped from textual representations, while in Figure 5b, the graph is learned based on randomly initialized learnable node embeddings. We observe that the top-left and bottom-right corners of the heatmap in Figure 5a exhibit darker colors, indicating strong correlations consistent with medical domain knowledge. Specifically, the variables in the top-left corner, Heart Rate (HR) and Respiration Rate (RR), are commonly monitored together in clinical settings for assessing vital signs and respiratory system ", "page_idx": 8}, {"type": "text", "text": "function [52]. The variables in the bottom-right corner, GCS-MR, GCS-T, and GCS-VR, collectively constitute the Glasgow Coma Scale (GCS), which is used to assess a patient\u2019s neurological status and level of consciousness [53]. These correlations are not evident in the graph without textual representations. This once again validates our perspective that relying solely on downstream task optimization for adaptive learning in graphs in ISMTS is insufficient to reflect the actual medical correlations among variables and lacks interpretability. In contrast, textual representations can guide the model to accurately extract variable correlations aligned with domain knowledge to provide high interpretability. ", "page_idx": 8}, {"type": "text", "text": "5.4.3 Visualization of Dynamic Density-aware Graph ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In Figure 6, we visualize the dynamic density-aware graph for the sample in Figure 1. We present the time series of three variables and the corresponding correlation heatmaps learned by our model at ", "page_idx": 8}, {"type": "text", "text": "timestamps 4, 15 and 56. From the time series, we observe that around $t=4$ , HR shows a strong correlation with NIDiasABP, while the correlation with DiasABP is masked as 0 since DiasABP has not been observed yet. Around $t=15$ , the correlation between HR and NIDiasABP decreases, while a relatively strong correlation with DiasABP emerges. By $t=56$ , HR exhibits a strong correlation with both variables. This process is clearly reflected in the heatmaps: the color between HR and NIDiasABP transitions from dark to light from $t=4$ to $t=15$ and darkens again from $t=15$ to $t=56$ . The color between HR and DiasABP remains dark at $t=15$ and $t=56$ . This demonstrates that our dynamic density-aware mechanism exactly reflects the time-varying correlations among variables in ISMTS. ", "page_idx": 9}, {"type": "image", "img_path": "9hCn01VAdC/tmp/4a1387197fc706cb606f3d414aa3265cdc82402829734edb319342c9ab36524f.jpg", "img_caption": ["Figure 6: Visualization of the dynamic graph of three variables over time for the sample in Figure 1. To enhance the contrast ratio, we set the diagonal elements to 0. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6 Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Although our proposed method effectively guides ISMTS modeling through the domain knowledge from text modality, it has some limitations. The backbone of our model is a recurrent-based architecture, which inherently has a sequential computation characteristic that can be a bottleneck in terms of runtime. Additionally, our method is specifically tailored for medical applications, and its performance may be limited in other irregular multivariate time series applications, such as human activity recognition, where variables lack domain knowledge and thus cannot generate high-quality text descriptions. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we propose KEDGN for modeling ISMTS. The proposed method leverages a PLM to flexibly extract semantic representation for each variable from the textual medical knowledge. Based on these representations, we allocate the variable-specific parameter space to capture variable-specific temporal patterns and extract a complete variable graph as a measure of the variables\u2019 static medical correlations. Considering the time-varying variables correlations in ISMTS, we introduce a densityaware mechanism to dynamically adjust the subgraph across different periods. Our experimental results demonstrate that KEDGN outperforms existing methods in ISMTS classification tasks and provides high interpretability. Our future work will focus on investigating the applicability of KEDGN in a range of related tasks, such as interpolation, extrapolation, and regression. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The work described in this paper was partially funded by the National Natural Science Foundation of China (Grant No. 62272173), the Natural Science Foundation of Guangdong Province (Grant Nos. 2024A1515010089, 2022A1515010179), the Science and Technology Planning Project of Guangdong Province (Grant No. 2023A0505050106), and the National Key R&D Program of China (Grant No. 2023YFA1011601). Yicheng Luo and Zhen Liu equally contributed to this work. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Chenxi Sun, Shenda Hong, Moxian Song, and Hongyan Li. A review of deep learning methods for irregularly sampled medical time series data. arXiv preprint arXiv:2010.12493, 2020.   \n[2] Satya Narayan Shukla and Benjamin M Marlin. A survey on principles, models and methods for learning from irregularly sampled time series. arXiv preprint arXiv:2012.00168, 2020.   \n[3] Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differential equations. Advances in neural information processing systems, 31, 2018.   \n[4] Yulia Rubanova, Ricky T. Q. Chen, and David K Duvenaud. Latent ordinary differential equations for irregularly-sampled time series. In Advances in Neural Information Processing Systems, volume 32, 2019. [5] Max Horn, Michael Moor, Christian Bock, Bastian Rieck, and Karsten Borgwardt. Set functions for time series. In International Conference on Machine Learning, pages 4353\u20134363. PMLR, 2020.   \n[6] Satya Narayan Shukla and Benjamin Marlin. Multi-time attention networks for irregularly sampled time series. In International Conference on Learning Representations, 2021.   \n[7] Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and Mingsheng Long. itransformer: Inverted transformers are effective for time series forecasting. arXiv preprint arXiv:2310.06625, 2023.   \n[8] Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth 64 words: Long-term forecasting with transformers. In International Conference on Learning Representations, 2023.   \n[9] Xiang Zhang, Marko Zeman, Theodoros Tsiligkaridis, and Marinka Zitnik. Graph-guided network for irregularly sampled multivariate time series. In International Conference on Learning Representations, ICLR, 2022.   \n[10] Zhen Wang, Ting Jiang, Zenghui Xu, Jianliang Gao, and Ji Zhang. Irregularly sampled multivariate time series classification: A graph learning approach. IEEE Intelligent Systems, 2023.   \n[11] Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi Xie. Medklip: Medical knowledge enhanced language-image pre-training for x-ray diagnosis. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 21372\u201321383, 2023.   \n[12] Xiaoman Zhang, Chaoyi Wu, Ya Zhang, Weidi Xie, and Yanfeng Wang. Knowledge-enhanced visual-language pre-training on chest radiology images. Nature Communications, 14(1):4542, 2023.   \n[13] Yinjun Wu, Jingchao Ni, Wei Cheng, Bo Zong, Dongjin Song, Zhengzhang Chen, Yanchi Liu, Xuchao Zhang, Haifeng Chen, and Susan B Davidson. Dynamic gaussian mixture based deep generative model for robust forecasting on sparse multivariate time series. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 651\u2013659, 2021.   \n[14] Satya Narayan Shukla and Benjamin Marlin. Interpolation-prediction networks for irregularly sampled time series. In International Conference on Learning Representations, 2019.   \n[15] Qingxiong Tan, Mang Ye, Grace Lai-Hung Wong, and Pong Chi Yuen. Cooperative joint attentive network for patient outcome prediction on irregular multi-rate multivariate health data. In IJCAI, pages 1586\u20131592, 2021.   \n[16] Liantao Ma, Junyi Gao, Yasha Wang, Chaohe Zhang, Jiangtao Wang, Wenjie Ruan, Wen Tang, Xin Gao, and Xinyu Ma. Adacare: Explainable clinical health status representation learning via scale-adaptive feature extraction and recalibration. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 825\u2013832, 2020.   \n[17] Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. Recurrent neural networks for multivariate time series with missing values. Scientific reports, 8(1):6085, 2018.   \n[18] Sindhu Tipirneni and Chandan K Reddy. Self-supervised transformer for sparse and irregularly sampled multivariate clinical time-series. ACM Transactions on Knowledge Discovery from Data (TKDD), 16(6):1\u201317, 2022.   \n[19] Alex Labach, Aslesha Pokhrel, Xiao Shi Huang, Saba Zuberi, Seung Eun Yi, Maksims Volkovs, Tomi Poutanen, and Rahul G. Krishnan. Duett: Dual event time transformer for electronic health records, 2023.   \n[20] Zekun Li, Shiyang Li, and Xifeng Yan. Time series as images: Vision transformer for irregularly sampled time series. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \n[21] Sheo Yon Jhin, Minju Jo, Taeyong Kong, Jinsung Jeon, and Noseong Park. Ace-node: Attentive co-evolving neural ordinary differential equations. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 736\u2013745, 2021.   \n[22] Jiawen Zhang, Shun Zheng, Wei Cao, Jiang Bian, and Jia Li. Warpformer: A multi-scale modeling approach for irregular clinical time series. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD \u201923, page 3273\u20133285, New York, NY, USA, 2023. Association for Computing Machinery.   \n[23] Zheng Fang, Qingqing Long, Guojie Song, and Kunqing Xie. Spatial-temporal graph ode networks for traffic flow forecasting. In Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining, pages 364\u2013373, 2021.   \n[24] Ming Jin, Huan Yee Koh, Qingsong Wen, Daniele Zambon, Cesare Alippi, Geoffrey I Webb, Irwin King, and Shirui Pan. A survey on graph neural networks for time series: Forecasting, classification, imputation, and anomaly detection. arXiv preprint arXiv:2307.03759, 2023.   \n[25] Saeed Rahmani, Asiye Baghbani, Nizar Bouguila, and Zachary Patterson. Graph neural networks for intelligent transportation systems: A survey. IEEE Transactions on Intelligent Transportation Systems, 2023.   \n[26] Lijing Wang, Aniruddha Adiga, Jiangzhuo Chen, Adam Sadilek, Srinivasan Venkatramanan, and Madhav Marathe. Causalgnn: Causal-based graph neural networks for spatio-temporal epidemic forecasting. In Proceedings of the AAAI conference on artificial intelligence, volume 36, pages 12191\u201312199, 2022.   \n[27] Jianian Wang, Sheng Zhang, Yanghua Xiao, and Rui Song. A review on graph neural network methods in financial applications. arXiv preprint arXiv:2111.15367, 2021.   \n[28] Guangyin Jin, Yuxuan Liang, Yuchen Fang, Zezhi Shao, Jincai Huang, Junbo Zhang, and Yu Zheng. Spatio-temporal graph neural networks for predictive learning in urban computing: A survey. IEEE Transactions on Knowledge and Data Engineering, 2023.   \n[29] Huaiyuan Liu, Xianzhang Liu, Donghua Yang, Zhiyu Liang, Hongzhi Wang, Yong Cui, and Jun Gu. Todynet: Temporal dynamic graph neural network for multivariate time series classification. arXiv preprint arXiv:2304.05078, 2023.   \n[30] Andrea Cini, Ivan Marisca, and Cesare Alippi. Filling the g_ap_s: Multivariate time series imputation by graph neural networks. In International Conference on Learning Representations, 2022.   \n[31] Renhe Jiang, Zhaonan Wang, Jiawei Yong, Puneet Jeph, Quanjun Chen, Yasumasa Kobayashi, Xuan Song, Shintaro Fukushima, and Toyotaro Suzumura. Spatio-temporal meta-graph learning for traffic forecasting. In Proceedings of the AAAI conference on artificial intelligence, volume 37, pages 8078\u20138086, 2023.   \n[32] Qihe Huang, Lei Shen, Ruixin Zhang, Shouhong Ding, Binwu Wang, Zhengyang Zhou, and Yang Wang. Crossgnn: Confronting noisy multivariate time series via cross interaction refinement. Advances in Neural Information Processing Systems, 36:46885\u201346902, 2023.   \n[33] Dingsu Wang, Yuchen Yan, Ruizhong Qiu, Yada Zhu, Kaiyu Guan, Andrew Margenot, and Hanghang Tong. Networked time series imputation via position-aware graph enhanced variational autoencoders. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 2256\u20132268, 2023.   \n[34] Binwu Wang, Pengkun Wang, Yudong Zhang, Xu Wang, Zhengyang Zhou, Lei Bai, and Yang Wang. Towards dynamic spatial-temporal graph learning: A decoupled perspective. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 9089\u20139097, 2024.   \n[35] Zhihong Chen, Yan Song, Tsung-Hui Chang, and Xiang Wan. Generating radiology reports via memory-driven transformer. In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1439\u20131449, Online, November 2020. Association for Computational Linguistics.   \n[36] Xiaomeng Li, Xiaowei Hu, Lequan Yu, Lei Zhu, Chi-Wing Fu, and Pheng-Ann Heng. Canet: cross-disease attention network for joint diabetic retinopathy and diabetic macular edema grading. IEEE transactions on medical imaging, 39(5):1483\u20131493, 2019.   \n[37] Qing Liao, Ye Ding, Zoe L Jiang, Xuan Wang, Chunkai Zhang, and Qian Zhang. Multi-task deep convolutional neural network for cancer diagnosis. Neurocomputing, 348:66\u201373, 2019.   \n[38] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.   \n[39] Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. Adaptive graph convolutional recurrent network for traffic forecasting. Advances in neural information processing systems, 33:17804\u201317815, 2020.   \n[40] Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. In International Conference on Learning Representations (ICLR \u201918), 2018.   \n[41] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.   \n[42] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations, 2017.   \n[43] Matthew A Reyna, Chris Josef, Salman Seyedi, Russell Jeter, Supreeth P Shashikumar, M Brandon Westover, Ashish Sharma, Shamim Nemati, and Gari D Clifford. Early prediction of sepsis from clinical data: the physionet/computing in cardiology challenge 2019. In 2019 Computing in Cardiology (CinC), pages Page\u20131. IEEE, 2019.   \n[44] Ikaro Silva, George Moody, Daniel J Scott, Leo A Celi, and Roger G Mark. Predicting inhospital mortality of icu patients: The physionet/computing in cardiology challenge 2012. In 2012 Computing in Cardiology, pages 245\u2013248. IEEE, 2012.   \n[45] Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a freely accessible critical care database. Scientific data, 3(1):1\u20139, 2016.   \n[46] Ary L Goldberger, Luis AN Amaral, Leon Glass, Jeffrey M Hausdorff, Plamen Ch Ivanov, Roger G Mark, Joseph E Mietus, George B Moody, Chung-Kang Peng, and H Eugene Stanley. Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physiologic signals. circulation, 101(23):e215\u2013e220, 2000.   \n[47] Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and Chengqi Zhang. Connecting the dots: Multivariate time series forecasting with graph neural networks. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, pages 753\u2013763, 2020.   \n[48] Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. Multitask learning and benchmarking with clinical time series data. Scientific data, 6(1):96, 2019.   \n[49] Jesse Davis and Mark Goadrich. The relationship between precision-recall and roc curves. In Proceedings of the 23rd international conference on Machine learning, pages 233\u2013240, 2006.   \n[50] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[51] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008.   \n[52] Craig Lockwood, Tiffany Conroy-Hiller, and Tamara Page. Vital signs. JBI Evidence Synthesis, 2(6):1\u201338, 2004.   \n[53] George L Sternbach. The glasgow coma scale. The Journal of emergency medicine, 19(1):67\u201371, 2000.   \n[54] Jesse Davis and Mark Goadrich. The relationship between precision-recall and roc curves. volume 06, 06 2006.   \n[55] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1\u201367, 2020.   \n[56] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension. CoRR, abs/1910.13461, 2019.   \n[57] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.   \n[58] Iz Beltagy, Matthew E. Peters, and Arman Cohan. Longformer: The long-document transformer. arXiv:2004.05150, 2020.   \n[59] Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization, 2019. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "table", "img_path": "9hCn01VAdC/tmp/51a2d50c67eb0533cec3dac8d305d4b7acd1c70a6b53debf6198350cb2aa237f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "B Datasets ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We use four irregularly sampled medical time series datasets to evaluate the classification performance of our model and baseline models. The dataset statistics are summarized in Table 4. ", "page_idx": 14}, {"type": "table", "img_path": "9hCn01VAdC/tmp/8a1fd55bc2a242980d9b234dc4354c04d7e8d81c05665dd7c19cac1f5152844e.jpg", "table_caption": ["Table 4: Dataset statistics. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "P19 The PhysioNet Sepsis Early Prediction Challenge 2019 [43] dataset consists of medical records from 38,803 patients. Each patient\u2019s record includes 34 variables of up to 60 hours and a static vector indicating attributes such as age, gender, the time interval between hospital admission and ICU admission, type of ICU, and length of stay in the ICU measured in days. Additionally, each patient is assigned a binary label indicating whether sepsis occurs within the subsequent 6 hours. We follow the procedures of [9] to ensure certain samples with excessively short or long time series are excluded. It is available at https://physionet.org/content/challenge-2019/1.0.0/. ", "page_idx": 14}, {"type": "text", "text": "P12 The P12 [46] dataset comprises data from 11,988 patients after 12 inappropriate samples identified by [5] were removed from the dataset. Each patient\u2019s record in the P12 dataset includes multivariate time series data collected during their initial 48-hour stay in the ICU. The time series data consists of measurements from 36 sensors (excluding weight). Additionally, each sample is associated with a static vector containing 9 elements, including age, gender, and other relevant attributes. Furthermore, each patient in the P12 dataset is assigned a binary label indicating the length of their stay in the ICU. A negative label signifies a hospitalization period of three days or shorter, while a positive label indicates a hospitalization period exceeding three days. It is available at https://physionet.org/content/challenge-2012/1.0.0/. ", "page_idx": 14}, {"type": "text", "text": "MIMIC-III The MIMIC-III [45] dataset is a widely used database that comprises de-identified Electronic Health Records of patients who were admitted to the ICU at Beth Israel Deaconess ", "page_idx": 14}, {"type": "text", "text": "Medical Center from 2001 to 2012. It Originally encompassed around 57,000 records of ICU patients, containing diverse variables such as medications, in-hospital mortality, and vital signs. [48] established a variety of benchmark tasks using a subset of this database. In this paper, we focus on the binary in-hospital mortality prediction task to assess classification performance. Following preprocessing, our dataset consists of 16 features from the preceding 48 hours and 21,107 samples. It is available at https://physionet.org/content/mimiciii/1.4/. ", "page_idx": 15}, {"type": "text", "text": "Physionet Physionet[44] contains the data from the first 48 hours of ICU patients, which is a reduced version of P12 considered by prior work. Therefore, we follow the same preprocessing methods used for the P12 dataset. The processed data set includes 3997 labeled instances. We focus on predicting in-hospital mortality. It is available at https://physionet.org/content/challenge-2012/. ", "page_idx": 15}, {"type": "text", "text": "C Baselines ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The implementation of baselines follows the corresponding papers or default implementation of their code repositories. Considering that different baselines have varying convergence speeds, we search for the number of epochs in the range of $\\{10,20,50\\}$ to ensure all baselines can reach convergence. We search for the learning in the range of $\\{0.001,0.005\\}$ due to the differences in model complexity and dataset size. Since all four datasets are highly imbalanced, we upsample the minority class in each batch to make the batch balance. Here are the detailed hyperparameter settings of these baselines: ", "page_idx": 15}, {"type": "text", "text": "ODE-RNN [4]: ODE-RNN uses neural ODEs to model hidden state dynamics and an RNN to update the hidden state in the presence of a new observation. The latent dimension is set as 40, and the ODE function has 3 layers with 50 units. The source code can be found at https://github.com/YuliaRubanova/latent_ode ", "page_idx": 15}, {"type": "text", "text": "GRU-D [17]: GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture. The number of hidden states of GRU-D is set as 49. We use the open source code from https://github.com/Han-JD/GRU-D ", "page_idx": 15}, {"type": "text", "text": "SEFT [5]: A set function approach where all the observations are modeled individually before pooling them together using an attention-based approach. We use a constant architecture for the attention network $f^{\\prime}$ with 2 layers, 4 heads and dimensionality of the dot product space $d$ of 128. In addition, the attention network $f^{\\prime}$ was always set to use mean aggregation. We use the open source code from https://github.com/BorgwardtLab/SeFT. ", "page_idx": 15}, {"type": "text", "text": "mTAND [6]: A deep learning framework for ISMTS data that learns an embedding of continuous time values and uses an attention mechanism to produce a fixed-length representation. We use the encoder of the overall framework for classification tasks. We set the latent dimension and the hidden size of GRU to 32. The number of reference points and the dimension of time embedding is 128. The source code can be found at https://github.com/reml-lab/mTAN. ", "page_idx": 15}, {"type": "text", "text": "IP-Net [14]: A model architecture for ISMTS data based on several semi-parametric interpolation layers organized into an interpolation network followed by a prediction network GRU. The number of reference points is set as 192. The hidden size of GRU is 100. We take the source code at https://github.com/mlds-lab/interp-net. ", "page_idx": 15}, {"type": "text", "text": "$\\mathbf{DGM^{2}{-}O}$ [13]: A generative model, which tracks the transition of latent clusters instead of isolated feature representations, achieves robust sparse time series modeling. We use the $\\mathrm{DGM}^{2}$ -O and set both the hidden dimension and the cluster_num as 10. We use the source code at https://github.com/thuwuyinjun/DGM2. ", "page_idx": 15}, {"type": "text", "text": "MTGNN [47]: A general graph neural network framework designed for MTS data. We use 5 graph convolution and 5 temporal convolution modules with the dilation exponential factor 2. The graph convolution and temporal convolution modules have 16 output channels. The skip connection layers all have 32 output channels. The first layer of the output module has 64 output channels, and the second layer has 1 output channel. We use the open source code from: https://github.com/nnzhan/MTGNN. ", "page_idx": 15}, {"type": "text", "text": "Raindrop [9]: A graph neural network that embeds ISMTS while learning the dynamics of sensors purely from observation data. The dimension of observation embedding is 4. The dimensions of time representation $p^{t}$ and $r_{v}$ are 16. We set the number of Raindrop layers $L$ as 2. The $d_{k}$ is set to 20. The $d_{a}$ is set equal to the number of sensors. The source code can be found at https://github.com/mimsharvard/Raindrop ", "page_idx": 16}, {"type": "text", "text": "StraTS [18] is a self-supervised transformer for sparse IMTS. We use the implementation at https://github.com/sindhura97/STraTS and the following setting in our experiment: hidden_ $\\dim=64$ , num_layers $=2$ , num_heads $=16$ , dropout $=0.2$ . ", "page_idx": 16}, {"type": "text", "text": "DuETT [19] is a dual event time transformer for Electronic Health Records (EHRs). We use the implementation at https://github.com/layer6ai-labs/DuETT and the default settings of the model declaration in this repository. ", "page_idx": 16}, {"type": "text", "text": "ViTST [20] transforms IMTS into line graph images and adapts powerful vision transformers to perform time series classification in the same way as image classification. We use the implementation at https://github.com/Leezekun/ViTST. ", "page_idx": 16}, {"type": "text", "text": "Warpformer [22]: A transformer-based network that captures features at different scales in IMTS using warping modules and dual attention mechanisms. We use three scales with normalized length $\\overset{\\sim}{L}{^{(0)}}=0$ , $\\widetilde{L}^{(1)}=0.2$ and $\\widetilde{L}^{(2)}=1$ . The dimension of representations $D$ is set as 32. The attention heads and the layers of the warpformer are set as 1 and 2, respectively. We use the implementation at https://github.com/imJiawen/Warpformer. ", "page_idx": 16}, {"type": "text", "text": "D Performance Metrics ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "AUROC AUROC is commonly employed in binary classification tasks, where one class is designated as positive and the other as negative. It represents the area under the Receiver Operating Characteristic (ROC) curve, constructed by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR). AUROC ranges from 0 to 1, with a higher value indicating better model performance in accurately discriminating between positive and negative instances. An AUROC equal to 0.5 indicates a model\u2019s performance equivalent to random guessing, while an AUROC greater than 0.5 signifies superiority over random guessing. ", "page_idx": 16}, {"type": "text", "text": "AUPRC The Area Under the Precision-Recall Curve is widely used as a performance metric for imbalanced binary classification tasks. It provides a comprehensive assessment of a model\u2019s precision-recall trade-off. The Precision-Recall curve is constructed by plotting recall on the $\\mathbf{X}$ -axis and precision on the y-axis. AUPRC ranges from 0 to 1, and a higher value indicates better model performance in achieving high precision and recall simultaneously. It has been suggested as a good criterion for unevenly distributed classification problems [54]. ", "page_idx": 16}, {"type": "text", "text": "E More Implementation Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Generation of Variables\u2019 Textual Descriptions We have chosen three textual sources: the full name of the variable, Wikipedia, and ChatGPT, for variable descriptions. The full name of the variable and Wikipedia sources can be directly extracted from dataset descriptions and web pages without requiring special processing, so we don\u2019t delve into them further here. Regarding the ChatGPT source, the medical properties description for each variable is generated by providing consistent question templates to ChatGPT, aiming to maintain a relatively uniform format across variables. We initiate queries to ChatGPT using the following template: What medical prior knowledge do you know about the medical variable $\\textcircled{1}$ in $\\textcircled{2}?$ to obtain a textual description for each variable in a specific dataset. The position marked as $\\overline{{\\u{\\upsilon}}}$ \u2019 corresponds to the variable name to be queried, and the position marked as $\\mathbf{\\Phi}^{,}$ corresponds to the dataset-specific task description. For instance, the task for the MIMIC-III dataset is $I C U$ patients\u2019 in-hospital mortality prediction, so the query for obtaining textual information associated with the variable Heart Rate could be: What medical prior knowledge do you know about the medical variable Heart Rate in diagnosing whether ICU patients will die during hospitalization? The following is a part of ChatGPT\u2019s answer for this example: ", "page_idx": 16}, {"type": "text", "text": "Heart rate is a fundamental physiological variable that plays a significant role in diagnosing and assessing the condition of ICU patients and their potential risk of mortality during hospitalization. Here\u2019s what you need to know about the medical variable \"heart rate\" in this context: Normal Heart Rate: A normal resting heart rate for adults typically ranges between 60 to 100 beats per minute (bpm). Deviations from this range can indicate potential health issues. Tachycardia: An elevated heart rate (tachycardia), often above 100 bpm, can be a sign of various medical conditions ... . ", "page_idx": 17}, {"type": "text", "text": "The complete text description can be obtained through the code link. ", "page_idx": 17}, {"type": "text", "text": "Hyperparameters We search all hyperparameters in the grid to find the best hyperparameters for our proposed model KEDGN. Specifically, our model has a total of 5 hyperparameters: dimension of query vectors $q$ , dimension of variables\u2019 node embeddings $n$ , proportion of density score $\\alpha$ , dimension of variables\u2019 hidden state $h$ , and dimension of structured encoding representations $k$ . For all datasets, $h$ and $k$ are set to be equal, and we search them over the range $\\{8,12,16\\}$ . Additionally, we search the dimension of query vectors $q$ in $\\{5,7,9\\}$ , the dimension of variables\u2019 node embedding $n$ in $\\{7,9,11\\}$ and the proportion of density score $\\alpha$ in $\\{1.0,2.0,3.0\\}$ . The best hyperparameters for each dataset are reported in the code. ", "page_idx": 17}, {"type": "text", "text": "F Additional Experiment ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "F.1 Classification Results Using Different PLMs ", "text_level": 1, "page_idx": 17}, {"type": "table", "img_path": "9hCn01VAdC/tmp/5129d3c1fe3abdccbc9ba6804027f904ed81ecaf811f0629f808fdeab2a79de5.jpg", "table_caption": ["Table 5: Details of Pre-trained Language Models. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "In KEDGN, we utilize a PLM to extract sentence embeddings of variables\u2019 textual medical information as variable semantic representations. The choice of PLM is diverse, and in our default implementation, we use BERT. Additionally, we have experimented with other PLMs, including T5 [55], Bart [56], GPT2 [57], LED [58], and Pegasus [59]. The detailed information of these PLMs is listed in Table 5. We extract the hidden state at ", "page_idx": 17}, {"type": "text", "text": "the [CLS] position for BERT. For other models, we uniformly take the last hidden state (average pooling) of the models as the representations of the variables. The classification results of using different PLMs on four datasets are listed in Table 6. ", "page_idx": 17}, {"type": "text", "text": "The results show that BERT (Encoder-Only model) achieved high performance on most datasets. Several Encoder-Decoder-based models also demonstrated competitive results, with Bart outperforming BERT on the P12 dataset, LED slightly surpassing BERT on the Physionet dataset and T5 showing slightly lower performance than BERT on the MIMIC-III dataset. However, the Decoder-Only GPT exhibited notably lower results on the P19 dataset and MIMIC-III compared to other models. This situation may be attributed to the fact that, in our task, PLMs are used to extract sentence-level semantic representations, which are utilized to differentiate variables and measure correlations among them, resembling a text classification process among variables. On the one hand, Encoder-Only models may excel at understanding tasks such as text classification, with BERT specifically adding a special [CLS] token dedicated to extracting sentence-level overall semantic information. On the other hand, models incorporating a decoder involve tasks related to predicting the next word and may be more focused on text generation tasks. They may exhibit a slight deficiency in extracting distinctive sentence-level representations, especially for Decoder-Only models. These models sometimes require carefully designed prompts to guide them in generating high-quality outputs. ", "page_idx": 17}, {"type": "text", "text": "In summary, variable semantic representations extracted by different PLMs can impact downstream task performance. Choosing a PLM that is more suitable for the task and dataset can further enhance the performance of KEDGN. In the context of the application in this paper, a simple pure encoder model may be more suitable for achieving optimal results. ", "page_idx": 17}, {"type": "text", "text": "F.2 Computational Cost Analysis ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Table 6: Classification results using different PLMs. The best results are highlighted in bold, and the second-best results are in underlined. The results in the table are presented in the form of (Mean $\\pm$ Std $\\%$ ). ", "page_idx": 18}, {"type": "table", "img_path": "9hCn01VAdC/tmp/5f87b6c0cf127fd0b626108fd85e17ee03bbd6a0812d9009953ca58b6449e6ca.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "We conduct a analysis of the time and space overhead on the Physionet dataset, with a batch size of 128, and utilizing Nvidia 1080Ti GPU infrastructure. The results are shown in Table 7. Our method achieves a balanced time and space overhead. The introduction of textual information involves generating semantic embeddings using PLMs, and the adjustment of the variable graph based on observed local density, both of which can be predetermined and integrated into the preprocessing step without increasing model training overhead. Attention-based methods (SeFT, mTAND) achieve parallel computing in the time dimension, resulting in low time overhead, but this sacrifices fine-grained feature extraction at the variable level. Furthermore, compared to the same RNN-based method GRU-D, our method only deals with actual observation points at each timestamp, thus significantly reducing time overhead. While our method\u2019s runtime is 1.3 times that of the latest SOTA model, Warpformer, our space overhead is only $16\\%$ of its size. In situations where computational resources permit, our method can further reduce runtime by employing the space-for-time trade-off strategy (such as increasing batch size). ", "page_idx": 18}, {"type": "table", "img_path": "9hCn01VAdC/tmp/1022027ecf1373c5e128274fc77edee0157dc13f04d9291c5a8f029a3b957e4b.jpg", "table_caption": ["Table 7: Comparison of computational costs on Physionet dataset. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "F.3 More Results for Leave-variables-out ", "text_level": 1, "page_idx": 18}, {"type": "table", "img_path": "9hCn01VAdC/tmp/72ce4d520112ed294dfa71909b84832d7e8956138a792854261345c9be01ea44.jpg", "table_caption": ["Table 8: Classification performance on samples with a fixed set of left-out variables. The best results are highlighted in bold and the second best results are in underlined. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "F.4 More Results for Ablation Study ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Table 9: The ablation study of our proposed method KEDGN. The results in the table are presented in the form of $(\\mathrm{Mean}\\pm\\mathrm{Std}\\;\\%)$ ). ", "page_idx": 19}, {"type": "table", "img_path": "9hCn01VAdC/tmp/a7e6bd5b4fb578fd39e9a84b0cb537fc00a0e493362ec00b2d5cf6c313cfd7d0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "We find that the model performance declines after introducing text information on P12 dataset. As indicated in Table 6, when we replace PLM from BERT to Bart, there is a slight improvement of $0.5\\%$ in AUPRC on the P12 dataset, slightly outperforming the model without text. Therefore, the reason for the decline in model performance is likely attributed to the choice of default PLM (BERT), which may not be optimal for extracting textual embeddings on this dataset, rather than the text itself causing the decline. In other words, introducing text offers the potential for enhancing model performance, with the extent of improvement depending on the degree of effective utilization of text. ", "page_idx": 19}, {"type": "text", "text": "F.5 Effects of different activation functions in Eq.(7) ", "text_level": 1, "page_idx": 19}, {"type": "table", "img_path": "9hCn01VAdC/tmp/05f507297b6d4c41399dd425ef878bd900b6f4acbd6723b9970d822858498178.jpg", "table_caption": ["Table 10: Comparison of the results of different activation functions in Eq.(7). "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "On one hand, the activation function in Eq.(7) reflects the dynamics of variables, such as time decay or exponential increase. On the other hand, this activation function serves a normalization purpose because the edge weights in the knowledge-empowered complete graph $\\pmb{A}$ are normalized values. If directly using the absolute value of the density to adjust the edge weights, the values might become excessively large or small, which would severely disrupt the basic graph structure learned from textual knowledge. Typical activation functions with normalization capabilities include Sigmoid and Tanh. As shown in Table 10, Tanh is chosen since it performs better. ", "page_idx": 19}, {"type": "text", "text": "F.6 Parameter Complexity Analysis ", "text_level": 1, "page_idx": 19}, {"type": "table", "img_path": "9hCn01VAdC/tmp/444137e161d2f3ccf74f88399f1ba84b27157d9b98ba74090d04b82caee6366e.jpg", "table_caption": ["Table 11: Comparison of the number of model parameters for three models. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "As shown in Table 11, the parameter count of our model is not particularly high. It is on the same order of magnitude as Warpformer and significantly lower than Raindrop by three orders of magnitude. Although we calculate an independent parameter space for each variable, the total $W_{t}\\in\\mathbb{R}^{\\boldsymbol{\\mathsf{V}}\\times\\boldsymbol{I}\\times\\boldsymbol{O}}$ does not equate to the parameter count. $W_{t}$ is derived from the multiplication of two matrices: the variable embedding matrix $Q\\in\\mathbb{R}^{V\\times q}$ and the weight matrix $W\\in\\dot{\\mathbb{R}^{q\\times I\\times O}}$ . The first matrix is computed from textual embeddings, and only the second matrix belongs to the model parameters. The sizes $q,\\,I$ , and $O$ are hyperparameters, independent of the number of variables, and typically set to be less than 16. This ensures that the parameter complexity of our model remains within an acceptable range. ", "page_idx": 19}, {"type": "text", "text": "F.7 More variables groups on the P12 dataset ", "page_idx": 20}, {"type": "image", "img_path": "9hCn01VAdC/tmp/f4ca4762cdcb45f6572d22ea5226f7885e4c7a988cf8f6514a53ead46cac6564.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 7: Variable groups (Partial) divided by temporal patterns on the P12 dataset. ", "page_idx": 20}, {"type": "text", "text": "F.8 More Visualizations of Variables Textual Representations ", "text_level": 1, "page_idx": 20}, {"type": "image", "img_path": "9hCn01VAdC/tmp/1f7472b3ccef4335910d2ec7e67a5ec4689a0b62e0975e57d689cf1354a4b604.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 8: Variable groups (Partial) divided by temporal patterns on the P19 dataset. ", "page_idx": 20}, {"type": "image", "img_path": "9hCn01VAdC/tmp/bb61d9e9024e70db5358b2c21be3f77deafbcf20ad95156c37a5ecd8df664b59.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 9: T-SNE visualization of partial variable semantic representations on the P19 dataset. ", "page_idx": 20}, {"type": "image", "img_path": "9hCn01VAdC/tmp/348ebc0d8f8d1ab864cdfeea7afe04fbc3f0968211580ddc4e95bf5c94594f90.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 10: Variable groups (Partial) divided by temporal patterns on the MIMIC-III dataset. ", "page_idx": 20}, {"type": "image", "img_path": "9hCn01VAdC/tmp/7da5e57866085a56958f926a76864ad9935a6abbd5a4a1b37af974a4581ff088.jpg", "img_caption": ["Figure 11: T-SNE visualization of partial variable semantic representations on the MIMIC-III dataset. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "9hCn01VAdC/tmp/9f97aed231fbbc2e127b444ed437e593f2925467ba8c15f7d77e8510ab7f07b3.jpg", "img_caption": ["Figure 12: T-SNE visualization of variable semantic representations generated by different PLMs on the P19 dataset. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "9hCn01VAdC/tmp/cd157bac360a498f5a187543839535457382258823b3904a6b26fba6beb94a45.jpg", "img_caption": ["Figure 13: T-SNE visualization of variable semantic representations generated by different PLMs on the MIMIC-III dataset. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "We conduct T-SNE visualization analysis on variable representations obtained from different PLMs. Figures 12 and 13 correspond to the results of the P19 and MIMIC-III datasets, respectively. We observe that when the clusters of variable representations extracted by PLMs are consistent with the grouping of variable time series patterns and exhibit distinctiveness, the corresponding downstream classification task performance tends to be better. For example, on the P19 dataset, BERT and LED achieve higher classification performance, with their corresponding variable representations having good distinctiveness: the three groups of variables represented by blue, yellow, and green colors show high cohesion and low coupling, while the T5 model, which exhibits suboptimal classification performance, has a distribution where Resp, WBC, and Platelets are notably confused with the green variables. Additionally, in the MIMIC-III dataset, the variable representations obtained from BERT and T5, which achieve higher performance, with blue and green clusters having longer distances, indicating better distinctiveness. On the other hand, variable representations obtained from GPT2 show poor distinctiveness, with the variable RR being close to GCS-EO and GCS-MR. ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: The abstract and introduction have clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We discuss the limiations of the work in Section 6. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: The paper does not include theoretical results. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The code and data are provided by a Github repository link Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The code and data are provided by a Github repository link. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We specify all the training and test details in Section 5.1 and Appendix E. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: We provide the standard deviation of the mean in the experiments. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We provide information on the computer resources in Appendix F.2 Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The research conducted in the paper conform with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 25}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 26}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We cite the original paper that produced the code package or dataset. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 26}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: We release our model by a Github URL. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]