[{"figure_path": "qwgfh2fTtN/tables/tables_5_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of experiments evaluating the easy-to-hard generalization performance of different language models (generators) using various decoding methods.  It compares the performance of models trained with different methods (supervised fine-tuning (SFT) and in-context learning (ICL)) and on different datasets (PRM800K and METAMATH). The results are evaluated using accuracy metrics on the MATH500 test set, categorized by decoding settings (Greedy, Majority Voting @16, and Majority Voting @256). The table helps to analyze how effectively different training strategies enable models to generalize from easy to hard tasks.", "section": "4 Main Results"}, {"figure_path": "qwgfh2fTtN/tables/tables_8_1.jpg", "caption": "Table 2: Comparing reinforcement learning (RL) approaches for easy-to-hard generalization. All methods are of 7b size and evaluated with greedy decoding.", "description": "This table compares the performance of different reinforcement learning (RL) methods for easy-to-hard generalization.  All models used have 7 billion parameters (7b) and utilize greedy decoding. The table shows the accuracy achieved on easy tasks (level 1-3), hard tasks (level 4-5), and overall accuracy across all task levels. Different RL approaches (REST-EM, Iterative DPO, PPO) are compared, trained with different data and reward model configurations (process-supervised reward models).  The results highlight the impact of the evaluator (reward model) on the generalization capability of the generator (policy model) in hard tasks.", "section": "4.2.2 Reinforcement Learning (RL)"}, {"figure_path": "qwgfh2fTtN/tables/tables_9_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of an experiment evaluating different methods for generating solutions to math problems. The methods are categorized as different types of generators trained on either easy or hard problems or a mixture. The performance of these models is compared across various decoding settings (greedy, majority voting, best-of-N). The table shows that supervised fine-tuning (SFT) generally outperforms in-context learning (ICL), and that models trained on both easy and hard data (Full SFT) perform best. ", "section": "4.1 Easy-to-Hard Generalization of Generators"}, {"figure_path": "qwgfh2fTtN/tables/tables_18_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of different generator models trained on easy and hard tasks, comparing their performance using various decoding settings. PRM800K and METAMATH datasets are used for supervised fine-tuning (SFT) and in-context learning (ICL).  The performance is evaluated on the MATH500 test set. The table highlights the performance differences between various training methods and decoding settings. It's used to assess the easy-to-hard generalization ability of the generators.", "section": "4.1 Easy-to-Hard Generalization of Generators"}, {"figure_path": "qwgfh2fTtN/tables/tables_19_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of experiments evaluating different methods for generating solutions to mathematical problems, focusing on \"easy-to-hard\" generalization.  It compares various generator models trained under different settings (supervised fine-tuning (SFT) and in-context learning (ICL)) using different datasets (PRM800K and METAMATH). The performance is measured by accuracy on the MATH500 test set using greedy decoding and majority voting with different numbers of samples (MAJ@16 and MAJ@256). The table helps to understand how different training data and methods affect the ability of the models to generalize from easy to hard problems.", "section": "4.1 Easy-to-Hard Generalization of Generators"}, {"figure_path": "qwgfh2fTtN/tables/tables_20_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of experiments evaluating the easy-to-hard generalization capabilities of different generator models.  It compares the performance of several methods for generating solutions to mathematical problems, varying both the decoding strategies used and the training data provided. The models were evaluated on the MATH500 dataset.  PRM800K and METAMATH refer to different datasets used for supervised fine-tuning (SFT) and in-context learning (ICL), respectively.", "section": "4 Main Results"}, {"figure_path": "qwgfh2fTtN/tables/tables_21_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "The table presents a comparison of different methods for generating solutions to mathematical problems, focusing on the ability of models trained on easier problems to generalize to harder ones.  It compares the performance of various generator models (In-context Learning and Supervised Fine-Tuning) under different decoding settings (greedy, majority voting, and best-of-N) on the MATH500 test set.  The data used for training the models is indicated (PRM800K and METAMATH).", "section": "4 Main Results"}, {"figure_path": "qwgfh2fTtN/tables/tables_22_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of an experiment comparing the performance of different methods for generating solutions to mathematical problems.  The experiment tested several generator models under various decoding settings, including greedy decoding and majority voting. The training data used included PRM800K and METAMATH datasets.  The performance is evaluated on the MATH500 test set.", "section": "4.1 Easy-to-Hard Generalization of Generators"}, {"figure_path": "qwgfh2fTtN/tables/tables_28_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of experiments evaluating the easy-to-hard generalization performance of different language models used as generators.  The models are evaluated under various decoding settings (greedy, majority voting, etc.). Two datasets, PRM800K and METAMATH, are used as training data, representing Supervised Fine-Tuning (SFT) and In-Context Learning (ICL) approaches.  The performance is measured on the MATH500 test set, allowing comparison across different model architectures, training data, and decoding methods.", "section": "4.1 Easy-to-Hard Generalization of Generators"}, {"figure_path": "qwgfh2fTtN/tables/tables_37_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of an experiment evaluating the easy-to-hard generalization performance of different generator models.  It compares various decoding settings (greedy, majority voting, etc.) applied to models trained using different datasets (PRM800K, Metamath) and methods (in-context learning, supervised fine-tuning). The results are shown in terms of accuracy on the MATH500 test set.", "section": "4.1 Easy-to-Hard Generalization of Generators"}, {"figure_path": "qwgfh2fTtN/tables/tables_38_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table compares the performance of different language models (generators) on a mathematical reasoning task (MATH500). It shows how well models trained with different methods (supervised fine-tuning (SFT) and in-context learning (ICL)) on easier problems generalize to harder problems. The table also shows performance under various decoding settings (greedy, majority voting, etc.) and with different training datasets (PRM800K and METAMATH).", "section": "4 Main Results"}, {"figure_path": "qwgfh2fTtN/tables/tables_41_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of experiments evaluating different methods for generating solutions to mathematical problems, specifically focusing on the ability of models to generalize from easier to harder problems. It compares the performance of several generator models under various decoding settings (greedy, majority voting at different numbers of samples), trained on either the full dataset (Full ICL/SFT) or only the easier portion (Easy-to-Hard ICL/SFT).  The results are evaluated on the MATH500 test set, and the training data used (PRM800K or MetaMath) is specified. This table helps to demonstrate whether training on easier tasks leads to successful generalization to more complex ones and provides a benchmark for the different methods explored.", "section": "4 Main Results"}, {"figure_path": "qwgfh2fTtN/tables/tables_44_1.jpg", "caption": "Table 1: Easy-to-hard generalization of generators. We compare generator performance under various decoding settings. PRM800K and METAMATH indicate the SFT training data and ICL exemplars. Evaluations are performed on the same MATH500 test set.", "description": "This table presents the results of different generator models on the MATH500 dataset. The models are evaluated under various decoding settings (greedy, majority voting, etc.).  The training data used includes PRM800K and MetaMATH, representing supervised fine-tuning (SFT) and in-context learning (ICL), respectively. The table shows the performance of each generator model on different levels of the MATH500 test set. This helps to analyze how well different methods generalize from easier to harder tasks.", "section": "4.1 Easy-to-Hard Generalization of Generators"}]