[{"figure_path": "nmUkwoOHFO/tables/tables_15_1.jpg", "caption": "Table A1: Zero and 5-shot accuracies. We report micro and macro averages on the MMLU test set.", "description": "This table presents the zero-shot and five-shot accuracies for different large language models on the Massive Multitask Language Understanding (MMLU) test set.  The accuracies are given as both macro and micro averages. Macro average is the arithmetic mean of the accuracies per subject, while the micro average is the total number of correct answers divided by the total number of questions. The difference between these reflects the class imbalance in the dataset.", "section": "Appendix"}, {"figure_path": "nmUkwoOHFO/tables/tables_15_2.jpg", "caption": "Table A2: Fine-tuning accuracies. We report the micro and macro averages on the MMLU test set. We only report the micro average on the train sets.", "description": "This table shows the fine-tuned model's performance on the MMLU test set, providing both micro and macro accuracy scores.  It also indicates the training set micro accuracy for each model. The micro average is the percentage of correctly classified instances over the whole test set; the macro average calculates the average accuracy across individual subjects, accounting for class imbalance.", "section": "Appendix"}]