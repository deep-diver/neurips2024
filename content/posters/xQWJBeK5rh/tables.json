[{"figure_path": "xQWJBeK5rh/tables/tables_9_1.jpg", "caption": "Table 4: Average counts of multi-hop negative edges and true positive edges reconstructed upon VN_SP_15 dataset with 12 nodes are sampled with different residual blocks. The average is performed based on 10 runs. For reference, L = 7. Each residual block is numbered as their closeness to the input side. For example, Residual Block [1] is the first one, [1 \u2013 3] refers to the integrating outputs from 1 to 3 Residual Blocks.", "description": "This table presents the results of an ablation study evaluating the impact of using different numbers of residual blocks in the SICSM model on the counts of multi-hop negative edges (incorrectly predicted edges spanning more than one hop) and true positive edges (correctly predicted edges).  The experiment used the VN_SP_15 dataset with only 12 out of 15 nodes sampled, and the results are averaged over 10 independent runs.  The table shows how combining outputs from multiple residual blocks (e.g., using 1-7 blocks) gradually improves the accuracy of edge prediction, reducing the number of false negative predictions (missing edges) and increasing the number of true positives. The results highlight the importance of aggregating dynamic information from multiple layers in SICSM for better structural inference in partially observed systems.", "section": "E.4 Why Do We Need All Residual Outputs?"}, {"figure_path": "xQWJBeK5rh/tables/tables_21_1.jpg", "caption": "Table 1: Statistics of PEMS datasets.", "description": "This table presents the statistics of three PEMS datasets, including the number of nodes, edges, time steps, and the missing ratio.  The PEMS datasets are derived from the California Caltrans Performance Measurement System and consist of traffic flow data aggregated into 5-minute intervals. The adjacency matrix is constructed using a thresholded Gaussian kernel based on road network distances.  The missing ratio indicates the percentage of missing data points in each dataset.", "section": "5.1 General Settings"}, {"figure_path": "xQWJBeK5rh/tables/tables_23_1.jpg", "caption": "Table 2: Number of Residual Blocks in the encoder of SICSM.", "description": "This table shows how the number of residual blocks in the encoder of the SICSM model scales with the number of nodes (n) in the graph.  As the number of nodes increases, more residual blocks are used to capture the increasing complexity of the system's dynamics.  This reflects an adaptive design where the model's architecture adjusts to handle the varying difficulty of the inference task, depending on the size of the system being modeled.", "section": "E More Experimental Results"}, {"figure_path": "xQWJBeK5rh/tables/tables_25_1.jpg", "caption": "Table 3: Average AUROC results (%) on PEMS datasets.", "description": "This table presents the performance evaluation of three methods (JSP-GFN, SIDEC, and SICSM) on three real-world datasets (PEMS03, PEMS04, and PEMS07).  The AUROC (Area Under the Receiver Operating Characteristic curve) is a common metric for evaluating the accuracy of a model's predictions. Higher AUROC values indicate better performance. The table shows that SICSM consistently outperforms the other two methods across all three datasets.", "section": "E.3 Experimental Results on PEMS"}, {"figure_path": "xQWJBeK5rh/tables/tables_27_1.jpg", "caption": "Table 4: Average counts of multi-hop negative edges and true positive edges reconstructed upon VN_SP_15 dataset with 12 nodes are sampled with different residual blocks. The average is performed based on 10 runs. For reference, L = 7. Each residual block is numbered as their closeness to the input side. For example, Residual Block [1] is the first one, [1 \u2013 3] refers to the integrating outputs from 1 to 3 Residual Blocks.", "description": "This table presents the results of an experiment evaluating the impact of using different numbers of residual blocks in the SICSM model on the accuracy of reconstructing the graph structure for a dataset with 12 nodes. The model's performance is measured by the average counts of multi-hop negative edges (incorrectly identified connections) and true positive edges (correctly identified connections). Results are averaged over 10 runs for each configuration.", "section": "E.4 Why Do We Need All Residual Outputs?"}, {"figure_path": "xQWJBeK5rh/tables/tables_28_1.jpg", "caption": "Table 5: Average AUROC results of SICSM with different neural networks in each block. The networks under consideration are Transformer, LSTM and GRU. The experiments are irregularly sampled time steps and partially observed nodes on VN_SP_15 dataset.", "description": "This table presents the AUROC (Area Under the Receiver Operating Characteristic curve) scores achieved by the proposed SICSM model using different neural networks (Transformer, LSTM, GRU) within its residual blocks.  The experiment was performed under conditions of irregularly sampled time steps and partially observed nodes in the VN_SP_15 dataset. The AUROC is a common metric for evaluating the performance of binary classifiers in which a higher score (closer to 1.0) implies better performance.", "section": "E.5 Ablation Study on the Choice of Neural Networks in the Blocks"}, {"figure_path": "xQWJBeK5rh/tables/tables_28_2.jpg", "caption": "Table 6: Training time (hours) of SICSM and baseline methods on VN_NS datasets.", "description": "This table presents the training times, in hours, for various structural inference methods (NRI, MPM, ACD, iSIDG, RCSI, JSP-GFN, SIDEC, and SICSM) across four different datasets (VN_NS_15, VN_NS_30, VN_NS_50, VN_NS_100) with varying node counts.  The results highlight the computational cost of each method and its scaling behavior with dataset size.  SICSM demonstrates superior inference accuracy but at the cost of increased training time.", "section": "5.1 General Settings"}, {"figure_path": "xQWJBeK5rh/tables/tables_29_1.jpg", "caption": "Table 7: Comparison with the exact posterior distribution, on small graphs with n = 5 nodes. Quantitative evaluation of different methods for joint posterior approximation, both in terms of edge features and cross-entropy of sampling distribution and true posterior P(\u03bb|Adj, Uall). All values correspond to the mean and 95% confidence interval across the 10 experiments.", "description": "This table compares the performance of JSP-GFN and SICSM against the exact posterior distribution for small graphs (5 nodes).  It evaluates both the accuracy of edge feature approximation and the cross-entropy between the sampling distribution of parameters \u03bb and the true posterior distribution.  The results show that both methods provide good approximations, with SICSM showing slightly better performance.", "section": "E.7 How Good is the Approximation?"}]