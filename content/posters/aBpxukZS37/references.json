{"references": [{"fullname_first_author": "Alex Nichol", "paper_title": "Glide: Towards photorealistic image generation and editing with text-guided diffusion models", "publication_date": "2021-12-01", "reason": "This paper introduces Glide, a foundational text-guided diffusion model that significantly advanced the field of image generation and directly influenced the current work's approach."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with CLIP latents", "publication_date": "2022-04-01", "reason": "This paper details a hierarchical text-conditional image generation model using CLIP latents, a crucial advancement directly impacting the methodology of the current research."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper presents a significant improvement in image resolution for diffusion models, directly relevant to the high-quality image generation focus of this work."}, {"fullname_first_author": "Marco Tulio Ribeiro", "paper_title": "why should i trust you?: Explaining the predictions of any classifier", "publication_date": "2016-01-01", "reason": "This paper introduces LIME, a crucial technique for interpreting individual predictions of machine learning models, foundational to the interpretability goals of this research."}, {"fullname_first_author": "Scott M. Lundberg", "paper_title": "A unified approach to interpreting model predictions", "publication_date": "2017-01-01", "reason": "This paper introduces SHAP, another important technique for explaining machine learning model predictions, providing a complementary approach to LIME in furthering the interpretability goals of this work."}]}