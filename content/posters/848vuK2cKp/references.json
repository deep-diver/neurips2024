{"references": [{"fullname_first_author": "Dylan J Foster", "paper_title": "Beyond UCB: Optimal and efficient contextual bandits with regression oracles", "publication_date": "2020-00-00", "reason": "This paper provides a foundational algorithm for contextual bandits which is generalized by the current paper to solve the contextual MDP problem."}, {"fullname_first_author": "Dylan J Foster", "paper_title": "The statistical complexity of interactive decision making", "publication_date": "2021-00-00", "reason": "This paper provides a general reduction from interactive decision making to online density estimation, which is used in the current paper to reduce the CMDP problem to offline density estimation."}, {"fullname_first_author": "David Simchi-Levi", "paper_title": "Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability", "publication_date": "2021-00-00", "reason": "This paper presents the FALCON algorithm, which is generalized in the current paper to solve the CMDP problem."}, {"fullname_first_author": "Orin Levy", "paper_title": "Optimism in face of a context: Regret guarantees for stochastic contextual MDP", "publication_date": "2023-00-00", "reason": "This paper establishes the minimax lower bound for the CMDP problem, against which the current paper compares its results."}, {"fullname_first_author": "Chi Jin", "paper_title": "Reward-free exploration for reinforcement learning", "publication_date": "2020-00-00", "reason": "This paper introduces the concept and problem setting for reward-free reinforcement learning, which is extended to contextual MDPs in the current paper."}]}