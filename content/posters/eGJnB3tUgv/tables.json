[{"figure_path": "eGJnB3tUgv/tables/tables_2_1.jpg", "caption": "Table 1: Comparison on standard fairness datasets (averaged from 5 runs). Each of {LtR, FORML, Meta-gDRO} is paired with {Overall AUC, Max-gAUCD, Worst-gAUC} rsp. for aligning intended fairness goals. Top results of each row in bold.", "description": "This table compares the performance of three conventional one-stage meta-learning methods (LtR, FORML, and Meta-gDRO) and the proposed two-stage Nash-Meta-Learning method on six standard fairness datasets.  The performance is measured using three fairness metrics: Overall AUC (higher is better), Max-gAUCD (lower is better), and Worst-gAUC (higher is better).  The table highlights the best performance for each metric across the different methods.  The results show that the two-stage method generally outperforms the one-stage methods.", "section": "4.2 Standard fairness benchmarks"}, {"figure_path": "eGJnB3tUgv/tables/tables_8_1.jpg", "caption": "Table 1: Comparison on standard fairness datasets (averaged from 5 runs). Each of { LtR, FORML, Meta-gDRO } is paired with { Overall AUC, Max-gAUCD, Worst-gAUC } rsp. for aligning intended fairness goals. Top results of each row in bold.", "description": "This table presents the performance comparison of the proposed two-stage Nash-Meta-Learning method against three conventional one-stage meta-learning methods (LtR, FORML, and Meta-gDRO) and a baseline method (DRO) across six standard fairness datasets.  The results are averaged over five runs. Each method is evaluated using three fairness metrics: Overall AUC (higher is better), Max-gAUCD (lower is better), and Worst-gAUC (higher is better).  The table highlights the best performing method for each dataset and metric.", "section": "4.2 Standard fairness benchmarks"}, {"figure_path": "eGJnB3tUgv/tables/tables_20_1.jpg", "caption": "Table 2: We detail the number of samples per group, categorized by protected attributes and labels. The student performance dataset allocates 10% for testing due to its smaller size, while others reserve 3%. Notably, in the adult income training dataset with race as a protected attribute, only one Amer-Indian sample with the positive (favorable) label. Additionally, after balancing test and validation sets, the community and crime dataset has no samples in the \u201cFalse", "description": "This table details the data distribution across different groups based on protected attributes and labels for six fairness datasets. It highlights imbalances in some datasets, such as the adult income dataset having only one Amer-Indian sample with a positive label, and the communities and crime dataset having no samples in the 'False' group after balancing the test and validation sets. This information is relevant for understanding the experimental setup and potential challenges in achieving fairness.", "section": "4.2 Standard fairness benchmarks"}, {"figure_path": "eGJnB3tUgv/tables/tables_21_1.jpg", "caption": "Table 1: Comparison on standard fairness datasets (averaged from 5 runs). Each of {LtR, FORML, Meta-gDRO} is paired with {Overall AUC, Max-gAUCD, Worst-gAUC} rsp. for aligning intended fairness goals. Top results of each row in bold.", "description": "This table compares the performance of the proposed two-stage Nash-Meta-Learning method against three conventional one-stage meta-learning methods (LtR, FORML, Meta-gDRO) and a baseline method (DRO) across six standard fairness datasets.  The performance is evaluated using three metrics: Overall AUC (higher is better, measuring overall prediction accuracy), Max-gAUCD (lower is better, measuring the maximum difference in AUC across groups), and Worst-gAUC (higher is better, measuring the AUC of the worst-performing group). The best result for each metric in each dataset is shown in bold.", "section": "4.2 Standard fairness benchmarks"}, {"figure_path": "eGJnB3tUgv/tables/tables_22_1.jpg", "caption": "Table 1: Comparison on standard fairness datasets (averaged from 5 runs). Each of { LtR, FORML, Meta-gDRO } is paired with { Overall AUC, Max-gAUCD, Worst-gAUC } rsp. for aligning intended fairness goals. Top results of each row in bold.", "description": "This table compares the performance of the proposed two-stage Nash-Meta-Learning method with three conventional one-stage meta-learning methods (LtR, FORML, Meta-gDRO) and a baseline method (DRO) across six standard fairness datasets.  For each dataset and method, the overall AUC (Area Under the Curve), maximum group AUCD (AUC Disparity), and worst-group AUC are reported. The table highlights the improvements achieved by the proposed method in terms of overall performance and fairness.", "section": "4.2 Standard fairness benchmarks"}, {"figure_path": "eGJnB3tUgv/tables/tables_23_1.jpg", "caption": "Table 6: One-stage methods in the first 15 epochs on US Crime dataset. \"Hypergradients aligned\" means the proposed update of the batch lies in A (\u2207L<sup>i</sup>g<sub>i</sub> > 0 for all i). Percentage in parenthesis is the portion out of total number of batches (1275 batches). We observed that approximately 80% of time the A is nonempty, which gives room for improvement with bargaining.", "description": "This table shows the performance of three different one-stage fairness-aware meta-learning methods (LtR, FORML, and Meta-gDRO) in terms of hypergradient alignment. It demonstrates that the proportion of batches where the hypergradients are aligned with the fairness objectives varies significantly between the different methods.  The table also shows how frequently the set of feasible update directions (A) was non-empty during the first 15 training epochs.", "section": "4.1 Simulation"}]