[{"figure_path": "eGJnB3tUgv/figures/figures_1_1.jpg", "caption": "Figure 1: Overview: We illustrate the problem of hypergradient conflicts in conventional one-stage fairness-aware meta-learning, which we find can lead to erratic performance and/or convergence at suboptimal, unfair local minima. Left: Graphical depiction of group-wise hypergradient conflicts (I, II) showing different scenarios where conflicts arise in one-stage meta-learning, affecting performance stability; (III) provides a depiction of the contrast case where the aggregated direction is not conflicting with any of the groups, which leads to a more stable, fair, and performant model. Right: (a, b) Comparison of conventional one-stage meta-learning (Vanilla showcased by FORML, highlighted in gray) with our proposed two-stage meta-learning approach (Ours, highlighted in green) which resolves hypergradient conflicts through a bargaining process. In our evaluation, we show the efficacy of our method in enhancing fairness-aware meta-learning, with improvements in performance by up to 10% and fairness by up to 67%, by initially focusing on conflict resolution in Stage 1 to steer the model towards the Pareto front followed by focusing on fairness goals in Stage 2.", "description": "The figure illustrates the problem of hypergradient conflicts in one-stage fairness-aware meta-learning and proposes a two-stage solution. The left panel shows different conflict scenarios, while the right panel compares the performance of the proposed two-stage method with a conventional one-stage method, demonstrating significant improvements in both performance and fairness.", "section": "1 Introduction"}, {"figure_path": "eGJnB3tUgv/figures/figures_1_2.jpg", "caption": "Figure 1: Overview: We illustrate the problem of hypergradient conflicts in conventional one-stage fairness-aware meta-learning, which we find can lead to erratic performance and/or convergence at suboptimal, unfair local minima. Left: Graphical depiction of group-wise hypergradient conflicts (I, II) showing different scenarios where conflicts arise in one-stage meta-learning, affecting performance stability; (III) provides a depiction of the contrast case where the aggregated direction is not conflicting with any of the groups, which leads to a more stable, fair, and performant model. Right: (a, b) Comparison of conventional one-stage meta-learning (Vanilla showcased by FORML, highlighted in gray) with our proposed two-stage meta-learning approach (Ours, highlighted in green) which resolves hypergradient conflicts through a bargaining process. In our evaluation, we show the efficacy of our method in enhancing fairness-aware meta-learning, with improvements in performance by up to 10% and fairness by up to 67%, by initially focusing on conflict resolution in Stage 1 to steer the model towards the Pareto front followed by focusing on fairness goals in Stage 2.", "description": "This figure illustrates the problem of hypergradient conflicts in one-stage fairness-aware meta-learning and introduces a two-stage solution. The left panel shows scenarios of conflicting and non-conflicting hypergradients, while the right panel compares a conventional one-stage approach with the proposed two-stage approach, highlighting performance and fairness improvements (up to 10% and 67%, respectively).", "section": "1 Introduction"}, {"figure_path": "eGJnB3tUgv/figures/figures_5_1.jpg", "caption": "Figure 1: Overview: We illustrate the problem of hypergradient conflicts in conventional one-stage fairness-aware meta-learning, which we find can lead to erratic performance and/or convergence at suboptimal, unfair local minima. Left: Graphical depiction of group-wise hypergradient conflicts (I, II) showing different scenarios where conflicts arise in one-stage meta-learning, affecting performance stability; (III) provides a depiction of the contrast case where the aggregated direction is not conflicting with any of the groups, which leads to a more stable, fair, and performant model. Right: (a, b) Comparison of conventional one-stage meta-learning (Vanilla showcased by FORML, highlighted in gray) with our proposed two-stage meta-learning approach (Ours, highlighted in green) which resolves hypergradient conflicts through a bargaining process. In our evaluation, we show the efficacy of our method in enhancing fairness-aware meta-learning, with improvements in performance by up to 10% and fairness by up to 67%, by initially focusing on conflict resolution in Stage 1 to steer the model towards the Pareto front followed by focusing on fairness goals in Stage 2.", "description": "This figure illustrates the problem of hypergradient conflicts in one-stage fairness-aware meta-learning and introduces a two-stage solution. The left panel shows scenarios where hypergradient conflicts lead to instability and suboptimal performance. The right panel compares a conventional one-stage approach with the proposed two-stage approach which resolves the conflicts using Nash Bargaining Solution (NBS), resulting in improved performance and fairness.", "section": "1 Introduction"}, {"figure_path": "eGJnB3tUgv/figures/figures_7_1.jpg", "caption": "Figure 3: Synthetic illustration of the bargaining effects. \"\": final point not close to the fairness goal (x=y). \"\u2192\": final point not at the Pareto front. (a) Bargaining across all 1000 steps; (b) Bargaining only included in the first 100 steps (two-stage method).", "description": "This figure shows the results of synthetic experiments comparing the performance of continuous bargaining and two-stage bargaining (with bargaining only in the first 100 steps) in resolving hypergradient conflicts and converging to the Pareto front.  It illustrates how the proposed two-stage approach using Nash Bargaining Solution (NBS) effectively guides the model to the Pareto front by initially resolving conflicts, thereby achieving improved fairness and performance compared to the continuous bargaining approach.", "section": "4.1 Simulation"}, {"figure_path": "eGJnB3tUgv/figures/figures_8_1.jpg", "caption": "Figure 1: Overview: We illustrate the problem of hypergradient conflicts in conventional one-stage fairness-aware meta-learning, which we find can lead to erratic performance and/or convergence at suboptimal, unfair local minima. Left: Graphical depiction of group-wise hypergradient conflicts (I, II) showing different scenarios where conflicts arise in one-stage meta-learning, affecting performance stability; (III) provides a depiction of the contrast case where the aggregated direction is not conflicting with any of the groups, which leads to a more stable, fair, and performant model. Right: (a, b) Comparison of conventional one-stage meta-learning (Vanilla showcased by FORML, highlighted in gray) with our proposed two-stage meta-learning approach (Ours, highlighted in green) which resolves hypergradient conflicts through a bargaining process. In our evaluation, we show the efficacy of our method in enhancing fairness-aware meta-learning, with improvements in performance by up to 10% and fairness by up to 67%, by initially focusing on conflict resolution in Stage 1 to steer the model towards the Pareto front followed by focusing on fairness goals in Stage 2.", "description": "This figure illustrates the problem of hypergradient conflicts in one-stage fairness-aware meta-learning and introduces a two-stage approach to resolve them. The left panel shows different scenarios of hypergradient conflicts, while the right panel compares the performance of a conventional one-stage method and the proposed two-stage method, highlighting the improvement in both performance and fairness achieved by the latter.", "section": "1 Introduction"}, {"figure_path": "eGJnB3tUgv/figures/figures_14_1.jpg", "caption": "Figure 5: Synthetic illustration of each gradient aggregation method in resolving gradient conflicts and their implication in converging to Pareto front. Red circles imply the nodes that cannot converge to the Pareto front after 1000 steps of updates.", "description": "This figure compares different gradient aggregation methods' performance in resolving hypergradient conflicts and converging to the Pareto front in a synthetic experiment.  The methods compared are the Nash Bargaining Solution (NBS), Generalized Mean (GM) with p=1 and p=-1, PCGrad, and CAGrad.  The plot shows the trajectory of the optimization process for multiple initial points. Red circles highlight the points that fail to reach the Pareto front after 1000 optimization steps. The figure demonstrates that the NBS effectively steers the optimization toward the Pareto front, while other methods struggle with conflicts and may get stuck in suboptimal regions.", "section": "3.2 Solving the problem"}, {"figure_path": "eGJnB3tUgv/figures/figures_22_1.jpg", "caption": "Figure 2: The unreliable performance of conventional one-stage fairness-aware meta-learning.", "description": "This figure illustrates the challenges of using conventional one-stage fairness-aware meta-learning methods.  It shows that these methods can lead to erratic performance and/or convergence at suboptimal, unfair local minima. Panel (a) compares the performance of three different one-stage methods across multiple fairness notions, showing inconsistent results. Panel (b) visualizes the trajectory of the optimization process for these methods, demonstrating that they often fail to reach a point that is both fair and performant. This highlights the need for a more robust approach to fairness-aware meta-learning, such as the two-stage Nash bargaining approach proposed in the paper.", "section": "Unreliability of one-stage meta-learning for fairness"}, {"figure_path": "eGJnB3tUgv/figures/figures_23_1.jpg", "caption": "Figure 6: Visualizations of how Nash bargaining improves gradient conflicts across different methods (adult income with sex as the sensitive attribute). With (i), (ii), (iii) in (a), (b), (c) depicting the least value of group-wise hypergradient alignment (min{g; \u2207Ls : i \u2208 [K]), the averaged group-wise hypergradient alignment value (\u2211i\u2208[K] 9\u0142\u2207L\u03b2), and the maximum value of group-wise hypergradient alignment (max{g\u2207L\u00df : i \u2208 [K]}) respectively.", "description": "This figure shows how Nash bargaining resolves hypergradient conflicts in different one-stage fairness-aware meta-learning methods.  It uses histograms to illustrate the distribution of the minimum, average, and maximum group-wise hypergradient alignment values (before and after Nash bargaining). The results show that Nash bargaining effectively resolves conflicts and improves hypergradient alignment, leading to better fairness and performance.", "section": "3.6 Dynamics of Two-stage Nash-Meta-Learning"}, {"figure_path": "eGJnB3tUgv/figures/figures_23_2.jpg", "caption": "Figure 3: Synthetic illustration of the bargaining effects. \"\": final point not close to the fairness goal (x=y). \"\u2192\": final point not at the Pareto front. (a) Bargaining across all 1000 steps; (b) Bargaining only included in the first 100 steps (two-stage method).", "description": "This figure illustrates the effectiveness of Nash bargaining in resolving hypergradient conflicts and guiding the model towards the Pareto front in synthetic experiments.  Panel (a) shows continuous bargaining throughout the entire training process, demonstrating that the bargaining process enhances convergence to the Pareto front. Panel (b) contrasts this with the two-stage approach, where bargaining is used only in the initial stage to resolve conflicts before focusing on fairness goals, showing a similar positive impact on the model's convergence to the Pareto front. In both cases, points far from the fairness goal (x=y) or not on the Pareto front are highlighted to show contrast and improved results from Nash bargaining.", "section": "4.1 Simulation"}, {"figure_path": "eGJnB3tUgv/figures/figures_23_3.jpg", "caption": "Figure 3: Synthetic illustration of the bargaining effects. \"\": final point not close to the fairness goal (x=y). \"\u2192\": final point not at the Pareto front. (a) Bargaining across all 1000 steps; (b) Bargaining only included in the first 100 steps (two-stage method).", "description": "This figure illustrates the effectiveness of Nash bargaining in resolving hypergradient conflicts and steering the model towards the Pareto front in a synthetic setting.  Panel (a) shows continuous bargaining throughout the entire training process, while panel (b) demonstrates the two-stage approach where bargaining is only used in the initial steps before the model focuses on fairness goals. The results highlight that the two-stage method using Nash bargaining achieves a better convergence to the Pareto front compared to conventional one-stage methods and improves fairness and performance.", "section": "4.1 Simulation"}, {"figure_path": "eGJnB3tUgv/figures/figures_23_4.jpg", "caption": "Figure 3: Synthetic illustration of the bargaining effects. \"\": final point not close to the fairness goal (x=y). \"\": final point not at the Pareto front. (a) Bargaining across all 1000 steps; (b) Bargaining only included in the first 100 steps (two-stage method).", "description": "This figure shows the results of synthetic experiments comparing the performance of a conventional one-stage fairness-aware meta-learning method with a proposed two-stage method that incorporates Nash bargaining.  The figure highlights how the two-stage method effectively resolves hypergradient conflicts and guides the model toward the Pareto front, leading to better fairness and performance outcomes compared to the one-stage method. Subfigure (a) shows continuous bargaining throughout the entire training process, while subfigure (b) shows bargaining only in the initial 100 steps.  The results demonstrate the efficacy of resolving conflicts before focusing on specific fairness goals.", "section": "4.1 Simulation"}, {"figure_path": "eGJnB3tUgv/figures/figures_23_5.jpg", "caption": "Figure 2: The unreliable performance of conventional one-stage fairness-aware meta-learning.", "description": "The figure shows the unreliable performance of conventional one-stage fairness-aware meta-learning methods across various fairness notions. Subfigure (a) compares the model performance of three conventional one-stage meta-learning methods (LtR, FORML, and Meta-gDRO) across various fairness notions. Subfigure (b) shows the trajectory of 1000-step optimizations for the three methods, illustrating hypergradient conflicts leading to unstable performance and convergence at suboptimal, unfair local minima.", "section": "2 Problem Statement"}, {"figure_path": "eGJnB3tUgv/figures/figures_23_6.jpg", "caption": "Figure 2: The unreliable performance of conventional one-stage fairness-aware meta-learning.", "description": "This figure shows the unreliable performance of conventional one-stage fairness-aware meta-learning methods across various fairness notions.  The left panel (a) compares the average model performance of three methods (LtR, FORML, and Meta-gDRO) across various fairness notions.  The results highlight instability and suboptimal performance in terms of both overall performance and fairness. The right panel (b) visualizes the optimization trajectory of these one-stage methods, showing erratic convergence and a tendency to converge to unfair local minima, rather than the desired point of equal validation loss for both groups and optimal performance, illustrated by the Pareto front.", "section": "Unreliability of one-stage meta-learning for fairness"}]