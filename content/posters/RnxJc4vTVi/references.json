{"references": [{"fullname_first_author": "Sergey Levine", "paper_title": "End-to-end training of deep visuomotor policies", "publication_date": "2016-01-01", "reason": "This paper is foundational for deep reinforcement learning in robotics, providing a key starting point for the current research on long-horizon tasks."}, {"fullname_first_author": "Youngwoon Lee", "paper_title": "Learning to coordinate manipulation skills via skill behavior diversification", "publication_date": "2019-01-01", "reason": "This paper directly addresses the problem of skill chaining for long-horizon manipulation, making it a core reference for the current work."}, {"fullname_first_author": "Youngwoon Lee", "paper_title": "Adversarial skill chaining for long-horizon robot manipulation via terminal state regularization", "publication_date": "2022-01-01", "reason": "This paper proposes a skill-chaining method using adversarial learning which is closely related to the current work and is directly compared against."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning", "publication_date": "1999-01-01", "reason": "This paper introduces the concept of temporal abstraction in reinforcement learning, which is a fundamental concept underlying hierarchical reinforcement learning approaches used in long-horizon tasks."}, {"fullname_first_author": "George Konidaris", "paper_title": "Skill discovery in continuous reinforcement learning domains using skill chaining", "publication_date": "2009-01-01", "reason": "This early work on skill chaining offers a foundational perspective on how to manage long-horizon robotic tasks by breaking them into smaller subtasks, which is a key concept in the current work."}]}