[{"type": "text", "text": "Fair GLASSO: Estimating Fair Graphical Models with Unbiased Statistical Behavior ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Madeline Navarro Samuel Rey Andrei Buciulea Rice University King Juan Carlos University King Juan Carlos University nav@rice.edu samuel.rey.escudero@urjc.es andrei.buciulea@urjc.es ", "page_idx": 0}, {"type": "text", "text": "Antonio G. Marques King Juan Carlos University antonio.garcia.marques@urjc.es ", "page_idx": 0}, {"type": "text", "text": "Santiago Segarra Rice University segarra@rice.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We propose estimating Gaussian graphical models (GGMs) that are fair with respect to sensitive nodal attributes. Many real-world models exhibit unfair discriminatory behavior due to biases in data. Such discrimination is known to be exacerbated when data is equipped with pairwise relationships encoded in a graph. Additionally, the effect of biased data on graphical models is largely underexplored. We thus introduce fairness for graphical models in the form of two bias metrics to promote balance in statistical similarities across nodal groups with different sensitive attributes. Leveraging these metrics, we present Fair GLASSO, a regularized graphical lasso approach to obtain sparse Gaussian precision matrices with unbiased statistical dependencies across groups. We also propose an efficient proximal gradient algorithm to obtain the estimates. Theoretically, we express the tradeoff between fair and accurate estimated precision matrices. Critically, this includes demonstrating when accuracy can be preserved in the presence of a fairness regularizer. On top of this, we study the complexity of Fair GLASSO and demonstrate that our algorithm enjoys a fast convergence rate. Our empirical validation includes synthetic and real-world simulations that illustrate the value and effectiveness of our proposed optimization problem and iterative algorithm. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Data analysis frequently requires estimating complex dyadic relationships, which can be conveniently encoded in graphical representations such as Gaussian graphical models (GGMs) [1\u20133]. Myriad real-world applications model structure in data by obtaining graphs from observations, in fields including neuroscience, genomics, finance, and more [4\u20136]. However, it is known that real-world data can encode historical biases which models ought not to consider, such as discriminatory biases against sensitive populations [7, 8]. For example, social networks often exhibit preferential relationships that may unfairly discriminate against sensitive communities [9\u201311]. Moreover, the use of unfair graphs for downstream tasks is known to exacerbate existing biases [12\u201314]. While accurate graphical representations are critical for applications and analyses, the propagation of undesirable bias in graph data necessitates learning models that balance both fairness and accuracy. ", "page_idx": 0}, {"type": "text", "text": "The long-standing popularity of GGMs for several applications, many of them high-stakes, warrants care in how we estimate them from potentially biased data. However, there is no formal definition of fairness for graphical models, and existing definitions for graph-based machine learning may not be applicable for obtaining fair statistical relationships. Indeed, while fairness for graph data has recently received copious attention, the study of biased graphs in statistics and graph signal processing (GSP) ", "page_idx": 0}, {"type": "text", "text": "is only beginning [15\u201317]. Furthermore, previous works primarily consider fairness for downstream tasks, while few attempt to learn unbiased graphs from data [16\u201318]. We thus arrive at two vital questions. First, what does it mean for a graphical model to be fair? We aim to compare such a notion to existing definitions of fairness on graphs. Second, how can we obtain GGMs that are fair in the presence of biased data? To address these questions, we consider estimation of fair GGMs from biased observations, where nodes belong to groups corresponding to different sensitive attributes. ", "page_idx": 1}, {"type": "text", "text": "We propose an optimization framework to obtain fair GGMs from potentially biased data, where statistical dependencies between nodes show no preferences for particular groups. We first define fairness for graphical models by introducing two bias metrics that measure similarities in statistical behavior between pairs of groups. Our metrics are simple and convex, yet they intuitively capture biases in terms of conditional dependence. We then propose Fair GLASSO, a penalized maximum likelihood estimator using our bias metrics as regularizers, which aims to obtain sparse Gaussian precision matrices that optimally extract structural information from observed data while promoting fairer statistical behavior across node groups. We summarize our contributions as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We formally define fairness for graphical models via two bias metrics, one balancing statistical dependencies evenly across all groups and a stronger alternative requiring each node to be balanced across all groups. We relate our definition to other notions of fairness on graphs, where ours is specific to graphs encoding conditional dependence structures, which in turn allows greater interpretability and more detailed statistical analysis.   \n\u2022 We present Fair GLASSO, a penalized maximum likelihood estimator for sparse Gaussian precision matrices that are unbiased according to any measure of graphical fairness, which we demonstrate with our proposed bias metrics. We theoretically demonstrate that our approach yields a tradeoff between fairness and accuracy, which depends on the bias in the underlying graph.   \n\u2022 The convexity of Fair GLASSO under our proposed metrics allows us to propose an efficient iterative method based on proximal gradient descent. We show that our algorithm enjoys iterations of moderate complexity and provable convergence.   \n\u2022 We evaluate Fair GLASSO on both synthetic and real-world datasets. The former provides empirical validation of the efficiency of our algorithm and the existence of the fairness-accuracy tradeoff. The latter shows the myriad real-world applications for which we can reliably obtain graphical representations from data while also balancing statistical behavior across sensitive groups. ", "page_idx": 1}, {"type": "text", "text": "1.1 Notation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "For any positive integer $p\\in\\mathbb N$ , we let $[p]:=\\{1,2,\\dots,p\\}$ . For a matrix $\\mathbf{X}\\in\\mathbb{R}^{p\\times p}$ and a set of indices $\\dot{\\mathcal{C}}\\in[p]^{2}$ , we let $\\mathbf{X}_{\\mathcal{C}}$ denote a masking operation on $\\mathbf{X}$ permitting non-zero entries only at indices in $\\mathcal{C}$ . If we define $\\bar{D}:=\\{p(i-1)+i\\}_{i=1}^{\\bar{p}}$ , then $\\mathbf{X}_{\\mathcal{D}}$ is a diagonal matrix containing the diagonal entries of $\\mathbf{X}$ . For $\\bar{\\mathcal{D}}:=[p]^{2}\\backslash\\mathcal{D}$ denoting the complement of the set $\\mathcal{D}$ , $\\mathbf{X}_{\\mathcal{\\Bar{D}}}=\\mathbf{X}-\\mathbf{X}_{\\mathcal{D}}$ contains non-zero values of $\\mathbf{X}$ only in its off-diagonal entries. We also let $\\mathrm{vec}(\\mathbf{X})\\in\\mathbb{R}^{p^{2}}$ denote the vertical concatenation of the columns of $\\mathbf{X}$ . The smallest and largest eigenvalues of a matrix $\\mathbf{X}$ are represented respectively by $\\lambda_{\\operatorname*{min}}(\\mathbf{X})$ and $\\lambda_{\\operatorname*{max}}(\\mathbf{X})$ . ", "page_idx": 1}, {"type": "text", "text": "2 Fair Gaussian Graphical Models ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "GGMs succinctly model pairwise relationships in multivariate Gaussian distributions through intuitive graphical representations. We denote undirected graphs by $\\mathcal{G}=(\\mathcal{V},\\mathcal{E},\\mathbf{W})$ , where $\\boldsymbol{\\mathcal{V}}=\\boldsymbol{\\bar{[p]}}$ is the set of $p$ nodes and $\\mathcal{E}\\subseteq\\mathcal{V}\\times\\mathcal{V}$ the set of edges connecting pairs of nodes. For graphs with weighted edges, $\\mathbf{W}\\in\\mathbb{R}^{p\\times p}$ encodes the topological structure of $\\mathcal{G}$ such that $W_{i j}\\neq0$ if and only if $(i,j)\\in\\mathcal{E}$ , that is, there is an edge in $\\mathcal{E}$ connecting nodes $i$ and $j$ with weight $W_{i j}$ . Let $\\pmb{x}\\in\\mathbb{R}^{p}$ be a random vector following a zero-mean Gaussian distribution with positive definite covariance matrix $\\Sigma_{0}\\succ0$ , that is, $\\mathbf{\\boldsymbol{x}}\\sim\\mathcal{N}(\\mathbf{0},\\pmb{\\Sigma}_{0})$ . The precision matrix $\\Theta_{0}=\\Sigma_{0}^{-1}$ completely describes the conditional dependence structure among the variables in $\\textbf{\\em x}$ . In particular, for any distinct pair $i,j\\in[p]$ , variables $x_{i}$ and $x_{j}$ are conditionally independent if and only if $[\\Theta_{0}]_{i j}=\\mathrm{\\dot{0}}$ [1, 2]. This Markovian property yields a graphical representation, where off-diagonal entries of $\\Theta$ encode the weighted edges of a graph $\\mathcal{G}$ connecting conditionally dependent variables. In this work, we aim to obtain the structure encoded in $\\Theta_{\\mathrm{0}}$ using observations sampled from $\\mathcal{N}(\\mathbf{0},\\Sigma_{0})$ . ", "page_idx": 1}, {"type": "text", "text": "When considering group fairness, we associate each variable in $\\textbf{\\em x}$ with one of $g$ groups that partition the variables according to a sensitive attribute [20, 21]. We represent group membership by the indicator matrix ${\\bf Z}=[{\\bf z}_{1},\\ldots,{\\bf z}_{g}]\\in\\{0,1\\}^{p\\times g}$ , where $Z_{i a}=1$ if and only if variable $i$ belongs to group $a\\in[g]$ , otherwise $Z_{i a}=0$ . Group sizes are denoted by $\\begin{array}{r}{p_{a}=\\sum_{i=1}^{\\bar{p}}Z_{i a}}\\end{array}$ for every $a\\in[g]$ We also assume that groups are non-overlapping, thus $\\begin{array}{r}{p=\\sum_{a=1}^{g}p_{a}}\\end{array}$ ga=1 pa. GGMs may possess biases when a group of variables behaves significantly more or less  similarly to particular groups. Indeed, individuals within the same political party tend to vote similarly [18]. In this case, entries of $\\mathbf{{\\Theta}}_{0}$ corresponding to pairs of voters of the same party will likely be positive and larger in magnitude. ", "page_idx": 1}, {"type": "image", "img_path": "a3cauWMXNV/tmp/8d4bfc7de04671e46d780afdde581d93fc9a95723f5212dc8d2b94d571996527.jpg", "img_caption": ["Figure 1: Three real-world networks with node groups denoted by color. Within-group edges are in blue and across-group edges in red, while edge widths correspond to edge weight magnitudes. For each network, we present (\u201cM\u201d) the modularity of the graphs with respect to group membership [19], (\u201cW\u201d) the ratio of positive to negative estimated partial correlations for within-group edges, and (\u201cA\u201d) an analogous ratio for across-group edges. Networks in (a) and (c) show high group-wise modularity, while (b) and (c) show significant preferences for positive correlations in the same group. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "We empirically demonstrate this phenomenon in Figure 1 for multiple real-world networks. Figures 1a and b show two social network examples, Zachary\u2019s karate club network [22, 23] and the Dutch school network [24], where nodes represent individuals and edges connect them by their relationships. Figure 1c is a political network that connects U.S. senators if their voting patterns exhibit correlated behavior [18]. For each network, we present both their modularity with respect to group membership [19] and a comparison of their approximate partial correlations within and across nodal groups [25, 26], with both metrics defined in Appendix G. Figures 1a and c show higher group-wise modularity, in line with the ubiquitous preference for within-group connections in realworld networks [9, 10]. However, observe that Figures 1b and c exhibit a clear preference for positive correlations between nodes in the same group. Despite its presence in real-world interconnected data, this type of discriminatory behavior is typically not addressed in existing works [27]. These examples inspire us to develop a definition of fairness for graphical models that accounts for both correlation bias, when behavior is highly correlated between certain groups, and connectivity bias, when connections are denser or sparser across certain group pairs. ", "page_idx": 2}, {"type": "text", "text": "2.1 Bias Metric for Fair Graphical Models ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To address biases in both connectivity and correlations, we propose a definition of group fairness for graphical models. We consider the popular notion of demographic parity (DP), the primary choice for fairness on graphs [20]; however, other definitions of group fairness can be similarly adapted [21]. DP requires that outcomes be agnostic to sensitive attributes [20, 28]. In our case, we require estimation of graphical models with unbiased edge selection with respect to nodal groups. Thus, we present the following definition of dyadic DP for graphical models. ", "page_idx": 2}, {"type": "text", "text": "Definition 1 For a graphical model with the matrix $\\Theta_{0}\\in\\mathbb{R}^{p\\times p}$ encoding the underlying conditional dependence structure, we consider $D P$ to be satisfied $i f$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}[[\\Theta_{0}]_{i j}|Z_{i a}=1,Z_{j a}=1]=\\mathbb{P}[[\\Theta_{0}]_{i j}|Z_{i a}=1,Z_{j b}=1]\\quad\\forall\\,a,b\\in[g].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Note that the distribution need not be Gaussian for this definition. Intuitively, our graphical model DP requires that groups have evenly balanced connections across groups and do not behave significantly more or less similarly to certain groups. Crucially, Definition 1 accounts for both forms of bias showcased in Figure 1, connectivity bias in the support of $\\Theta_{\\mathrm{0}}$ and correlation bias in the signs of entries in $\\mathbf{{\\Theta}}_{0}$ . Not only is this definition appropriately tailored to fairness for graphical models, but it also provides flexibility in how we address biases. We may adjust similarities in behavior without changing the topology of the graph [14, 29], but conversely, we may alter connections if correlations cannot be changed [30]. Finally, note that works for fairness on graphs with weighted or signed edges are rare [27], and to the best of our knowledge no previous work has specified fairness for graphical models that encode conditional dependencies. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "We consider a graphical model unfair when there is a gap in DP, that is, when (1) does not hold. In practice, we measure biases in GGMs by approximating the DP gap. For this purpose, we propose the following bias metric inspired by [18], ", "page_idx": 3}, {"type": "equation", "text": "$$\nH(\\Theta)\\;:=\\;\\frac{1}{g^{2}-g}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\left(\\frac{{\\bf z}_{a}^{\\top}\\Theta_{\\bar{D}}{\\bf z}_{a}}{p_{a}^{2}-p_{a}}-\\frac{{\\bf z}_{a}^{\\top}\\Theta_{\\bar{D}}{\\bf z}_{b}}{p_{a}p_{b}}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Each term in (2) compares the average within-group edge weight and the average across-group edge weight for every distinct group pair. Thus, $H(\\Theta)$ will increase if variables belonging to two groups exhibit either significantly denser or sparser connections or significantly stronger or weaker correlations. As we aim to balance statistical behavior across groups, we consider obtaining precision matrices $\\Theta$ that balance data fidelity with small values of $H(\\Theta)$ . The main difference between $H(\\Theta)$ and the related metric in [18] lies in the use of squared summands. While subtle, this modification tends to yield fairer outcomes, as group pairs are balanced overall as opposed to the metric in [18], which may favor balancing some pairs of groups over others. ", "page_idx": 3}, {"type": "text", "text": "In addition to (2), we also propose a stronger alternative metric for node-wise fairness across groups, ", "page_idx": 3}, {"type": "equation", "text": "$$\nH_{\\mathrm{node}}(\\Theta)\\;:=\\;\\frac{1}{p g}\\sum_{i=1}^{p}\\sum_{a=1}^{g}\\left(\\frac{1}{g-1}\\sum_{b\\neq a}\\frac{[\\Theta_{\\bar{D}}\\mathbf{z}_{a}]_{i}}{p_{a}}-\\frac{[\\Theta_{\\bar{D}}\\mathbf{z}_{b}]_{i}}{p_{b}}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is zero if and only if every variable is completely balanced across groups in terms of connections or correlation. This stronger metric is inspired by [15, 18], also modified by squaring summands as for $H(\\Theta)$ . As an alternative interpretation, observe that $H_{\\mathrm{node}}(\\Theta)$ increases when the correlation between the group of a variable $i$ and the $i$ -th column of $\\Theta$ increases. This node-wise penalty is stronger than $H(\\Theta)$ , as we require that not only pairs of groups exhibit no preference in statistical similarities but also each node must show no preference for connecting to certain groups. ", "page_idx": 3}, {"type": "text", "text": "For graph-based works, the predominant choice of bias metric is DP (see related works in Appendix A). Thus, we approach the nascent task of graphical model estimation with a familiar bias metric to verify our approach with established measurements. However, our formulation is suited to others such as equalized odds (EO), defined in Appendix I. While both DP and EO are popular fairness definitions, we cannot compute EO for the true precision matrix since it is conditioned on the ground truth connections. For this reason, we emphasize DP for group fairness since a measure of bias in the true precision matrix is critical to our theoretical interpretation of the fairness-accuracy tradeoff. ", "page_idx": 3}, {"type": "text", "text": "3 Fair GLASSO ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "3.1 Graphical Lasso for Fair GGMs ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We apply our proposed metrics in (2) and (3) to estimate GGMs from observations while mitigating both connectivity and correlation biases (see Section 2). Assume that we observe $n$ samples from the distribution $\\mathcal{N}(\\mathbf{0},\\Sigma_{0})$ collected in the data matrix $\\mathbf{X}\\,\\in\\,\\mathbb{R}^{n\\times p}$ . To estimate fair and sparse precision matrices from data, we adapt the celebrated graphical lasso method [26, 31, 32], a penalized maximum likelihood approach for recovering GGMs. ", "page_idx": 3}, {"type": "text", "text": "Given the sample covariance matrix $\\begin{array}{r}{\\hat{\\Sigma}=\\frac{1}{n}\\mathbf{X}^{\\top}\\mathbf{X}}\\end{array}$ , we present Fair GLASSO, a version of graphical lasso for fair GGMs, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Theta^{*}\\;=\\;\\underset{\\boldsymbol{\\Theta}}{\\mathrm{argmin~}}\\operatorname{tr}(\\hat{\\boldsymbol{\\Sigma}}\\boldsymbol{\\Theta})-\\log\\operatorname*{det}(\\boldsymbol{\\Theta}+\\epsilon\\mathbf{I})+\\mu_{1}\\left\\|\\mathbf{\\Theta}_{\\Bar{\\mathcal{D}}}\\right\\|_{1}+\\mu_{2}R_{H}(\\boldsymbol{\\Theta})}\\\\ &{\\quad\\quad\\quad\\mathrm{s.t.~}\\;\\;\\boldsymbol{\\Theta}\\in\\mathcal{M}:=\\{\\boldsymbol{\\Theta}\\in\\mathbb{R}^{p\\times p}:\\boldsymbol{\\Theta}\\succeq0,\\ \\|\\boldsymbol{\\Theta}\\|_{2}^{2}\\leq\\alpha\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $R_{H}$ denotes a bias penalty measuring the fairness of $\\Theta$ and $\\mu_{1},\\mu_{2}\\geq0$ tune the encouragement of sparse and fair precision matrices, respectively. For the penalty $R_{H}$ , we can choose not only our proposed metrics $H$ and $H_{\\mathrm{node}}$ but also any metric for measuring bias on graphs. Similar to existing works on graph Laplacian GGMs [33], the addition of $\\epsilon\\mathbf{I}$ for $\\epsilon>0$ adds practicality to our approach, permitting us to obtain positive semi-definite precision matrices. The ability to estimate rank-deficient matrices allows for disconnected graph solutions. We assume that the true precision matrix $\\mathbf{{\\Theta}}_{0}$ has bounded eigenvalues (see AS2 and AS3 in Section 3.2), hence the constraint $\\|\\Theta\\|_{2}^{2}\\leq\\alpha$ on the spectral norm of $\\Theta$ for large enough $\\alpha\\,>\\,0$ . In practice, an effective $\\alpha$ can be obtained by overshooting its value based on the minimum eigenvalue of the sample covariance $\\hat{\\Sigma}$ . For further context of how both our proposed bias metrics $H$ and $H_{\\mathrm{node}}$ and our Fair GLASSO method relate to existing works, we provide a detailed review of related works in Appendix A. We present our approach for estimating GGMs, but indeed we may consider other distributions for the problem formulation in (4), such as the Ising negative log-likelihood. As our theoretical analysis requires Gaussianity, we proceed under this assumption, but future work will see the application of fair regularization to other distributions. Moreover, our empirical results in Section 4 show satisfactory performance optimizing (4) even for real-world datasets with non-Gaussian data. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "3.2 Fair GLASSO Theoretical Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We theoretically characterize the performance of Fair GLASSO. In particular, we focus on the effect of our fairness penalty in (4). Our result demonstrates the error rate of $\\Theta^{*}$ not only from a traditional statistical perspective but also in terms of the bias in the true precision matrix $\\Theta_{0}$ . Indeed, as $\\mathbf{{\\Theta}}_{0}$ becomes more unfair, we expect that imposing unbiased estimates hinders estimation performance. Let the set $S:=\\{(i,j)\\in[p]^{\\bar{2}}:\\,[\\Theta_{0}]_{i j}\\not=0,\\,i\\not=j\\}$ contain the indices of the non-zero, off-diagonal entries of $\\mathbf{{\\Theta}}_{0}$ . We first share the following assumptions on $\\mathbf{{\\Theta}}_{0}$ and $\\mathbf{Z}$ . ", "page_idx": 4}, {"type": "text", "text": "AS1 (Bounded sparsity) There exists a constant $s>0$ such that the cardinality of $\\boldsymbol{S}$ satisfies $\\vert{\\cal S}\\vert\\le s$ ", "page_idx": 4}, {"type": "text", "text": "AS2 (Bounded spectrum) There exists a constant $\\underline{{k}}>0$ such that $\\lambda_{\\operatorname*{min}}(\\Sigma_{0})\\geq\\underline{{k}}>0$ . ", "page_idx": 4}, {"type": "text", "text": "AS3 (Bounded spectrum) There exists a constant $\\bar{k}>0$ such that $\\lambda_{\\operatorname*{max}}(\\Sigma_{0})\\leq\\bar{k}<\\infty$ . ", "page_idx": 4}, {"type": "text", "text": "AS4 (Persistent groups) All groups have the same size, that is, $p_{a}=\\bar{p}\\geq2$ for every $a\\in[g]$ . ", "page_idx": 4}, {"type": "text", "text": "Assumptions AS1, AS2, and AS3 follow those from the distinguished work [32]. Note that AS4 is imposed for simplicity, but similar results hold if we merely require asymptotically similar groups sizes, where no groups vanish as $p\\rightarrow\\infty$ . With our assumptions in place, we present our main result on the error rate of Fair GLASSO, the proof of which can be found in Appendix B. ", "page_idx": 4}, {"type": "text", "text": "Theorem 1 Assume that AS1 to AS4 hold and that $\\mu_{1}\\asymp\\sqrt{(\\log p)/n}$ and $\\mu_{2}=o(1)$ . Moreover, let $R_{H}=H$ from (2) and $\\epsilon=0$ in (4). With probability tending to $^{\\,I}$ as $n,p\\to\\infty$ , there exist constants $m_{1},m_{2}>0$ such that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\|\\Theta^{*}-\\Theta_{0}\\|_{F}\\leq m_{1}\\sqrt{\\frac{(p+s)\\log p}{n}}+m_{2}\\frac{\\sqrt{g}\\sqrt[4]{H(\\Theta_{0})}}{\\sqrt{p}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Moreover, there exists a constant $q>0$ such that if $\\mu_{2}$ satisfies ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mu_{2}^{2}\\leq\\frac{q p^{2}\\log p}{g^{2}n\\sqrt{H(\\Theta_{0})}},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "then with probability tending to $^{\\,I}$ as $p\\rightarrow\\infty$ we can further guarantee that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\|\\Theta^{*}-\\Theta_{0}\\|_{F}\\leq m_{1}\\sqrt{\\frac{(p+s)\\log p}{n}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Our error bound consists of the Frobenius norm convergence rate for graphical lasso in [32] and a term accounting for the bias penalty in (4). In particular, the second term in (5) portrays the influence of bias in the true precision matrix $\\mathbf{{\\Theta}}_{0}$ . Theorem 1 not only provides an intuitive error bound for fair estimation of GGMs but also exemplifies when a tradeoff between fairness and accuracy may occur. When the true model $\\Theta_{\\mathrm{0}}$ is biased, that is, $H(\\Theta_{0})$ is large, then performance may suffer according to (5). However, if bias mitigation is mild enough, that is, if $\\mu_{2}$ is small enough to satisfy (6), then we instead enjoy the error rate of [32] with no adverse effect from the bias penalty. Indeed, as the true $\\Theta_{\\mathrm{0}}$ becomes fairer, so too grows the range of values of $\\mu_{2}$ that guarantee (7). Thus, if $\\Theta_{\\mathrm{0}}$ is unbiased, then imposing a strong bias penalty can obtain fair estimates $\\Theta^{*}$ while maintaining accuracy. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "In addition to the explicit Frobenius error rate of $\\Theta^{*}$ , we are also interested in when we can sufficiently describe the true model behavior. Our next result shows how well Fair GLASSO solutions approximate the true distribution, which enjoys the same rate as in Theorem 1, proven in Appendix $\\mathbf{C}$ . ", "page_idx": 5}, {"type": "text", "text": "Corollary 1 Let the assumptions of Theorem 1 hold. Then, with probability tending to $^{\\,l}$ as $n,p\\to\\infty$ , there exist constants $m_{1}^{\\prime},m_{2}^{\\prime}>0$ such that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|\\Theta^{*}\\Sigma_{0}-\\mathbf{I}\\|_{F}\\leq m_{1}^{\\prime}\\sqrt{\\frac{(p+s)\\log p}{n}}+m_{2}^{\\prime}\\frac{\\sqrt{g}\\sqrt{H(\\Theta_{0})}}{\\sqrt{p}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Moreover, there exists a constant $q>0$ such that when $\\mu_{2}$ satisfies (6), then with probability tending to $^{\\,l}$ as $p\\rightarrow\\infty$ we can further guarantee that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\big\\|\\Theta^{*}\\Sigma_{0}-\\mathbf{I}\\big\\|_{F}\\leq m_{1}^{\\prime}\\sqrt{\\frac{\\left(p+s\\right)\\log p}{n}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that a similar rate to (9) holds up to a constant if we replace $\\pmb{\\Sigma}_{0}$ with $\\hat{\\Sigma}$ . Thus, we may apply $\\|\\Theta^{*}\\hat{\\Sigma}-\\mathbf{I}\\|_{F}$ as an error metric when the true covariance matrix $\\Sigma_{0}$ is unavailable. ", "page_idx": 5}, {"type": "text", "text": "3.3 Algorithmic Implementation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "If we choose $R_{H}$ in (4) as $H$ or $H_{\\mathrm{node}}$ , the convexity of the resultant problem allows us to introduce a simple yet effective algorithm for Fair GLASSO estimates. We base our approach on an accelerated proximal gradient method known as fast iterative shrinkage algorithm (FISTA) [34], which is well suited to solving nonsmooth, constrained optimization problems. More", "page_idx": 5}, {"type": "table", "img_path": "a3cauWMXNV/tmp/1ed309399aac3e68920422ed39d3c039a009510970698cacf1b2be3ec69b951a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "over, our ensuing FISTA approach is still applicable under other distributions as long as the associated loss in (4) is convex and differentiable, such as the negative log-likelihood of the Ising model. ", "page_idx": 5}, {"type": "text", "text": "We separate the Fair GLASSO objective function $F(\\Theta)\\;=\\;f(\\Theta)\\:+\\:h(\\Theta)$ into its smooth and non-smooth terms via $f(\\Theta)$ and $h(\\Theta)$ , respectively, which are given by ", "page_idx": 5}, {"type": "equation", "text": "$$\nf(\\Theta):=\\mathrm{tr}(\\hat{\\Sigma}\\Theta)-\\log\\operatorname*{det}(\\Theta+\\epsilon\\mathbf{I})+\\mu_{2}R_{H}(\\Theta),\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;h(\\Theta):=\\mu_{1}\\|\\Theta_{\\mathcal{D}}\\|_{1}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The proposed algorithm to estimate $\\Theta^{*}$ is presented in Algorithm 1. We discuss the steps of our algorithm in Appendix D, and we provide further details in Appendix $\\boldsymbol{\\mathrm E}$ , including specifying the gradient $\\nabla_{\\Theta}f$ and the Lipschitz constant of $f$ when $R_{H}=H$ or $R_{H}=H_{\\mathrm{node}}$ . ", "page_idx": 5}, {"type": "text", "text": "Computationally, the complexity of Algorithm 1 is limited by an eigendecomposition in the projection step and a matrix inverse in the proximal gradient descent step (see (50) and (51) in Appendix $\\mathrm{D}$ for details). Over-the-shelf implementations of these operations render a computational complexity of ${\\mathcal{O}}(p^{3})$ . However, implementations based on fast matrix multiplication may result in an improved complexity of $\\mathcal{O}(p^{2.4})$ , a remarkable improvement since the optimization problem involves learning $p^{2}$ variables. Finally, in addition to a mild computational complexity, the proposed algorithm enjoys a convergence rate of $\\mathcal{O}\\big(\\frac{1}{k^{2}}\\big)$ , which we formally state next and prove in Appendix F. ", "page_idx": 5}, {"type": "image", "img_path": "a3cauWMXNV/tmp/8570feed77d21ca0e555cf0c9f5cfb06b7c975d8fb0e36b6bf28914343caeb30.jpg", "img_caption": ["Figure 2: Estimation performance in terms of error and bias. (a) Bias and error for estimating a fair graph as data becomes more biased. (b) Bias and error as graph size $p$ grows for ER graphs. (c) Bias and error for a biased real-world network [23] as the number of observations $n$ grows. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Theorem 2 Let $\\{\\hat{\\Theta}^{(k)}\\}_{k\\geq1}$ be the sequence generated by Algorithm 1 for solving the optimization problem (4), where we denote the global minimum by $\\Theta^{*}$ . Then, for any $k\\geq1$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\|\\hat{\\boldsymbol{\\Theta}}^{(k)}-\\boldsymbol{\\Theta}^{*}\\|_{F}^{2}\\leq\\frac{4L\\|\\boldsymbol{\\Theta}^{(0)}-\\boldsymbol{\\Theta}^{*}\\|_{F}^{2}}{\\alpha(k+1)^{2}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $L$ is the Lipschitz constant of $f(\\Theta)$ and $\\alpha$ corresponds to the spectral constraint in (4). ", "page_idx": 6}, {"type": "text", "text": "Thus, Theorem 2 guarantees convergence of Algorithm 1 to the optimal solution $\\Theta^{*}$ under our constraints in (4) with either of our bias metrics in (2) or (3). Not only are the convex fairness penalties amenable to efficient algorithms with well-understood performance guarantees, we also are able to guarantee that our algorithm converges with respect to the estimation variable, which is stronger than previous works\u2019 results on convergence of the objective function [35]. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We illustrate the ability of Fair GLASSO to reliably estimate both synthetic and real-world graphs from data while promoting unbiased connections. Extensive experimental details including our performance metrics, the baselines with which we compare, and the real-world datasets are provided in Appendix G; these details are summarized here. We include additional experiments on the effect of varying the hyperparameters $\\mu_{1}$ and $\\mu_{2}$ and violating assumptions (AS1)-(AS4) of Theorem 1 on Appendix H. ", "page_idx": 6}, {"type": "text", "text": "We compare our method with existing approaches for both scalability and performance. In particular, we consider (i) GL: Traditional graphical lasso [26], (ii) FGL: Fair GLASSO with $R_{H}=H$ , (iii) NFGL: Fair GLASSO with $R_{H}=H_{\\mathrm{node}}$ , (iv) FST: Network inference from spectral templates with a group-wise bias penalty [18, 36], (v) NFST: Network inference from spectral templates with a node-wise bias penalty [15, 18], and (vi) RWGL: Graphical lasso with randomly rewired edges. ", "page_idx": 6}, {"type": "text", "text": "We then perform GGM estimation on multiple real-world networks: (i) Karate club: the social network of Zachary\u2019s karate club members [23], (ii) School: A contact network of high school students [37], (iii) Friendship: The friendship network of the same high school students as in School [37], (iv) Co-authorship: An author collaboration network [38], and (v) MovieLens: A movie recommender network [39]. Figure 1 demonstrated that interconnected data may have fair or unfair relationships; thus, our experiment not only exemplifies the viability of our approach for real-world settings but also the fairness-accuracy tradeoff depending on biases in data. ", "page_idx": 6}, {"type": "text", "text": "4.1 Estimating Fair Graphs with Biased Data ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Consider the realistic setting where our model is to be implemented in a fair setting, but our observations contain unfair biases [8]. We aim to obtain accurate graphical models by reducing the biases encoded in data. We consider synthetic networks whose nodes show no preferential connections, but our observations become increasingly unfair, growing in preference for within-group correlations. ", "page_idx": 6}, {"type": "text", "text": "Figure 2a presents the error and bias from networks estimated using graphical lasso with and without bias penalties $H$ and $H_{\\mathrm{node}}$ . As expected, all methods show an increase in both error and bias as the data becomes more unfair, as our observations are not only straying from the true distribution but also tending toward unfair behavior. However, FGL and NFGL not only preserve a lower bias than GL, but we also improve estimation performance. This significant result exemplifies the situation described in Section 3.2; our proposed penalties not only yield unbiased estimates but also serve as informative priors when the underlying graph is fair. Thus, we enjoy improvement in both fairness and accuracy for this realistic setting. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4.2 Performance as Graph Size Increases ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Fair GLASSO adapts traditional GGM learning through the bias penalty, which includes (2) and (3). To observe the regularization effect of our penalties, we compare graphical lasso both with and without bias penalties for estimating synthetic networks as the graph size $p$ grows, which also demonstrates the scalability of our method. We thus implement GL via a state-of-the-art approach for comparison [26]. ", "page_idx": 7}, {"type": "table", "img_path": "a3cauWMXNV/tmp/9144e2fca2033fbf4e0089210d5bf85566cde04948160d2785b44e7eafa7146e.jpg", "table_caption": ["Table 1: Running time in seconds of Algorithm 1 and graphical lasso via [26]. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 2b shows the relationship between error and bias in the estimated graphs. Each line corresponds to a graph estimation method, and points on the lines denote the varying dimension, ranging from $p=50$ (highlighted via darker, filled markers) to $p=1000$ . ", "page_idx": 7}, {"type": "text", "text": "First, observe that GL achieves superior accuracy at the expense of a larger bias, while NFGL improves bias, albeit with greater error. In contrast, FGL for $\\bar{\\mu_{2}}\\in\\{1,10\\}$ can improve bias without sacrificing accuracy, where $\\mu_{2}\\,=\\,10$ yields the most Pareto-optimal solution. This result aligns with Theorem 1, showcasing the ability of Fair GLASSO to maintain estimation performance while significantly improving the fairness of the obtained graph. Critically, even as $p$ increases, our method enjoys relatively short running times, ranging from 0.5 seconds for 50 nodes to 30 minutes for 1000, which we show in Table 1. Our implementation of the classical algorithm in [26] requires 2 seconds and 170 minutes for $p=50$ and $p=1000$ , respectively. We can then conclude that our efficient algorithm for Fair GLASSO can sufficiently handle larger graphs. ", "page_idx": 7}, {"type": "text", "text": "4.3 Social Network with Synthetic Signals ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We next apply Fair GLASSO for the Karate club network, a real-world graph with known biased connections [23]. As this network famously exhibits group-wise modularity [22], we can compare different methods for estimating a real biased network. We show bias and error as the number of data samples increases from $n=1\\bar{0}^{2}$ (denoted by darker, filled markers) to $n=10^{5}$ in Figure 2c. Since this graph does not have data, we generate synthetic Gaussian observations on the social network. Note that we only consider synthetic samples for this real-world dataset; the remainder are equipped with a set of real graph signals. In addition to the previously considered baselines, we also compare to FGL-L1 and NFGL-L1, which correspond to Fair GLASSO using the group-wise and node-wise bias metrics in [18] as the penalty $R_{H}$ . These metrics may prioritize balancing some group pairs over others, as described in Section 2.1. ", "page_idx": 7}, {"type": "text", "text": "For all methods, increasing the number of samples improves estimation error, but bias also grows since the underlying graph is unfair. Observe that all alternatives to GL are able to reduce estimation bias. As expected, randomly rewiring edges from graphical lasso estimates in RWGL does mildly improve bias when compared to GL, but error also rises significantly. The methods designed for fair graph estimation achieve the greatest improvement in bias, with our proposed methods FGL and NFGL outperforming FST and NFST in both bias and error. We also observe that FGL and NFGL using our bias metrics $H$ and $H_{\\mathrm{node}}$ with squared terms improve both fairness and accuracy over FGL-L1 and NFGL-L1 using the analogous metrics in [15, 18], which consider sums of absolute values of each term. Moreover, not only does FGL outperform other methods in both fairness and accuracy for all $n$ , but FGL is the only approach that simultaneously decreases bias and error. Fair GLASSO is therefore viable for estimating real-world networks with known biased connections. ", "page_idx": 7}, {"type": "text", "text": "We also investigate the effect of $H$ versus $H_{\\mathrm{node}}$ for estimating group-wise modular networks. Figure 3 visualizes three graphs learned using GL, FGL, and NFGL. Both FGL and NFGL attempt to mitigate biased connections by reducing larger weights for existing within-group edges. However, since FGL aims to improve bias in expectation, Figure 3b shows an increase in negative within-group edges, that is, negative partial correlations between nodes in the same group. Conversely, Figure 3c shows a network with more balanced connections per node, where more nodes are connected to new edges that are both positive and negative. This result suggests that the bias metric $H$ for group-wise balance in expectation aligns more with existing definitions of DP, while the node-wise DP gap $H_{\\mathrm{node}}$ behaves closer to an individual fairness metric [40, 41]. ", "page_idx": 7}, {"type": "image", "img_path": "a3cauWMXNV/tmp/304839998eb5dcd200e2ac975dca510eebb02c3c985624038574ceeef3cb4509.jpg", "img_caption": ["Figure 3: Estimated Karate club network via graphical lasso with and without penalties $H$ and $H_{\\mathrm{node}}$ . Node colors denote group membership, while edge thickness denotes edge weight magnitude and edge color its sign, with blue (red) as positive (negative) correlation. (a) Estimation via GL. (b) Estimation via FGL. (c) Estimation via NFGL. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.4 Fair GGMs for Real-World Data ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Finally, in Table 2 we evaluate Fair GLASSO to estimate graphs from four real-world datasets consisting of two social networks, School and Friendship with gender as the sensitive attribute; a collaboration network Co-authorship with groups representing the type of conference in which each author publishes most; and a recommendation network MovieLens, where we consider binary sensitive attributes for each movie (node) denoting whether or not the movie was released after 1991. Evaluating Fair GLASSO on these datasets not only demonstrates its effectiveness on relevant real-world scenarios with biases, which are described in greater detail in Appendix G, but we can also showcase performance on non-Gaussian data, such as the discrete graph signals of the School and Friendship social networks. As each network varies in level of biases in their connections and observations, we show results for both weak and strong bias mitigation, that is, $\\mu_{2}\\in\\{1,10^{6}\\}$ , for all fair graph learning methods. ", "page_idx": 8}, {"type": "text", "text": "For the relatively unbiased School and Friendship networks, our methods FGL and NFGL obtain superior estimation accuracy while sufficiently accounting for biases, particularly in comparison with FST and NFST. Unsurprisingly, we observe the lowest estimation error when $\\mu_{2}=1$ is small enough such that FGL and NFGL achieve similar bias to Ground truth. However, observe that FGL and NFGL have low estimation error even for large $\\mu_{2}=10^{6}$ , which enjoys significant bias reduction. This verifies the results from Theorem 1 and in Figure 2a for real-world data; when the underlying graph is fair, our bias penalties serve as informative structural priors that improve performance. ", "page_idx": 8}, {"type": "text", "text": "For the Co-authorship network, we also observe the best accuracy using FGL and NFGL when $\\mu_{2}$ is small enough that bias is similar to that of the true network. Critically, even when $\\mu_{2}$ is large, we observe errors for FGL and NFGL competitive with GL while also achieving low bias. Moreover, for the MovieLens dataset, Fair GLASSO is the only method that rivals GL in accuracy while acquiring significantly fairer estimates. Indeed, FGL with $\\mu_{2}=10^{6}$ is the only method to achieve both low error and bias simultaneously. This implies that the observations in both the Co-authorship and MovieLens datasets are biased, since high bias mitigation yielding fair estimates improves estimation performance. Thus, we demonstrate that relationships in real data can be explained by graphical models rivaling the accuracy of state-of-the-art approaches while also exhibiting fairer behavior. ", "page_idx": 8}, {"type": "table", "img_path": "a3cauWMXNV/tmp/50e40bb869c18fe6d7e1d0e38b8d6df7eaa56b618aad9d9a5f3cf14da84f39de.jpg", "table_caption": [], "table_footnote": ["Table 2: Bias and error for estimating four real-world networks. The top row shows the bias present in the true underlying network. The best performances are in bold. "], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work proposes two metrics to evaluate bias in graphical models, which we apply as regularizers for fair GGM estimation. In particular, we adapt DP to measure biases in the conditional dependence structure encoded in graphical models, where nodes may show preferences for certain groups in terms of either connections or correlations. Unlike existing works that typically only consider fairness based on the unweighted topology of a known graph, we extend the concept of graph DP for the weighted connectivity patterns represented by the precision matrix of a Gaussian distribution. Moreover, we apply our group fairness for graphical models to modify graphical lasso for estimating fair GGMs. Future work will see more general graphical models, along with other extensions both in terms of the graph setting and fairness, which we discuss further in Appendix I. ", "page_idx": 9}, {"type": "text", "text": "Broader Impact ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we proposed a fair adaptation of graphical lasso, an extremely prominent method for complex data analysis. The development of methods that encourage fairness is necessary to ensure ethical and trustworthy tools, particularly those applied as extensively as GGMs to several critical and sensitive applications. Biases present in real-world graphs are well known, such as biased connections due to gender in social network analysis or segregated communities of co-authors in different disciplines. We revealed that these graphical biases extend beyond preferences in connections to include within-group correlations in behavior. Indeed, while intuitive, the tendency for group members to behave similarly has not been investigated for graphical models, as bias in signed edges has not been considered. Our paper contributes to expanding available unbiased graph-based methods, leading to extensions of other graphical models and statistical tools. ", "page_idx": 9}, {"type": "text", "text": "Moreover, as fairness on graphs is still nascent, several graph-based tasks have yet to be considered under the lens of fairness. Indeed, models are typically encouraged to be unbiased with respect to independent entities, but recent years have seen greater attention paid to the treatment of data equipped with graphical relationships. We not only participate in this movement, but we also extend fairness on graphs by considering weighted and signed edges for graphical models encoding conditional dependencies. This paper serves as a critical step in developing fair graph-based tools, particularly as GGMs are used in several high-stakes fields, including finance and medicine. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was partially supported by the Spanish AEI PID2022-136887NB-I00 and TED2021- 130347B-I00, the Community of Madrid via the ELLIS Madrid Unit, and the U.S. NSF under award CCF-2340481. Research was sponsored by the Army Research Office and was accomplished under Grant Number W911NF-17-S-0002. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Army or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Daphne Koller and Nir Friedman. Probabilistic Graphical Models: Principles and Techniques. MIT press, 2009.   \n[2] Steffen L Lauritzen. Graphical Models, volume 17. Clarendon Press, 1996.   \n[3] Gonzalo Mateos, Santiago Segarra, Antonio G Marques, and Alejandro Ribeiro. Connecting the dots: Identifying network structure via graph signal processing. IEEE Signal Processing Magazine, 36(3):16\u201343, 2019.   \n[4] Eugene Belilovsky, Ga\u00ebl Varoquaux, and Matthew B Blaschko. Testing for differences in Gaussian graphical models: Applications to brain connectivity. In Advances in Neural Information Processing Systems, volume 29, 2016.   \n[5] Stephen M Smith, Karla L Miller, Gholamreza Salimi-Khorshidi, Matthew Webster, Christian F Beckmann, Thomas E Nichols, Joseph D Ramsey, and Mark W Woolrich. Network modelling methods for FMRI. NeuroImage, 54(2):875\u2013891, 2011.   \n[6] Oliver Stegle, Sarah A Teichmann, and John C Marioni. Computational and analytical challenges in single-cell transcriptomics. Nature Reviews Genetics, 16(3):133\u2013145, 2015.   \n[7] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through awareness. In Innovations in Theoretical Computer Science, page 214\u2013226, 2012.   \n[8] Anja Lambrecht and Catherine Tucker. Algorithmic bias? An empirical study of apparent gender-based discrimination in the display of STEM career ads. Management Science, 65(7):2966\u20132981, 2019.   \n[9] Fariba Karimi, Mathieu G\u00e9nois, Claudia Wagner, Philipp Singer, and Markus Strohmaier. Homophily influences ranking of minorities in social networks. Scientific Reports, 8(1):11077, 2018.   \n[10] Yosh Halberstam and Brian Knight. Homophily, group size, and the diffusion of political information in social networks: Evidence from Twitter. Journal of Public Economics, 143:73\u201388, 2016.   \n[11] Eli Pariser. The Filter Bubble: How the New Personalized Web Is Changing What We Read and How We Think. Penguin, 2011.   \n[12] Avishek Bose and William Hamilton. Compositional fairness constraints for graph embeddings. In International Conference on Machine Learning, volume 97, pages 715\u2013724, 2019.   \n[13] Enyan Dai and Suhang Wang. Say no to the discrimination: Learning fair graph neural networks with limited sensitive attribute information. In International Conference on Web Search and Data Mining, page 680\u2013688, 2021.   \n[14] Peizhao Li, Yifei Wang, Han Zhao, Pengyu Hong, and Hongfu Liu. On dyadic fairness: Exploring and mitigating bias in graph connections. In International Conference on Learning Representations, 2021.   \n[15] Oyku Deniz Kose, Yanning Shen, and Gonzalo Mateos. Fairness-aware optimal graph fliter design. arXiv preprint arXiv:2310.14432, 2023.   \n[16] Davoud Ataee Tarzanagh, Laura Balzano, and Alfred O Hero. Fair community detection and structure learning in heterogeneous graphical models. arXiv preprint arXiv:2112.05128, 2023.   \n[17] Xiang Zhang and Qiao Wang. A unified framework for fair spectral clustering with effective graph learning. arXiv preprint arXiv:2311.13766, 2023.   \n[18] Madeline Navarro, Samuel Rey, Andrei Buciulea, Antonio G Marques, and Santiago Segarra. Mitigating subpopulation bias for fair network topology inference. arXiv preprint arXiv:2403.15591, 2024.   \n[19] Farzan Masrour, Tyler Wilson, Heng Yan, Pang-Ning Tan, and Abdol Esfahanian. Bursting the fliter bubble: Fairness-aware network link prediction. AAAI Conference on Artificial Intelligence, 34(01):841\u2013848, 2020.   \n[20] Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. Certifying and removing disparate impact. In ACM International Conference on Knowledge Discovery and Data Mining, page 259\u2013268, 2015.   \n[21] Moritz Hardt, Eric Price, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. In Advances in Neural Information Processing Systems, volume 29, 2016.   \n[22] Michelle Girvan and Mark E J Newman. Community structure in social and biological networks. Proceedings of the National Academy of Sciences of the United States of America, 99(12):7821\u20137826, 2002.   \n[23] Wayne W Zachary. An information flow model for conflict and fission in small groups. Journal of Anthropological Research, 33(4):452\u2013473, 1977.   \n[24] Andrea Beate Knecht. Friendship selection and friends\u2019 influence: dynamics of networks and actor attributes in early adolescence. PhD thesis, University Utrecht, 2008.   \n[25] Arthur P Dempster. Covariance selection. Biometrics, 28(1):157\u2013175, 1972.   \n[26] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. Sparse inverse covariance estimation with the graphical lasso. Biostatistics, 9(3):432\u2013441, 2008.   \n[27] Akrati Saxena, George Fletcher, and Mykola Pechenizkiy. FairSNA: Algorithmic fairness in social network analysis. ACM Computing Surveys, 56(8):1\u201345, 2024.   \n[28] Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. Preventing fairness gerrymandering: Auditing and learning for subgroup fairness. In International Conference on Machine Learning, volume 80, pages 2564\u20132572, 2018.   \n[29] Indro Spinelli, Simone Scardapane, Amir Hussain, and Aurelio Uncini. FairDrop: Biased edge dropout for enhancing fairness in graph representation learning. IEEE Transactions on Artificial Intelligence, 3(3): 344\u2013354, 2022.   \n[30] Oyku Deniz Kose and Yanning Shen. Fair contrastive learning on graphs. IEEE Transactions on Signal and Information Processing over Networks, 8:475\u2013488, 2022.   \n[31] Alexandre d\u2019Aspremont, Onureena Banerjee, and Laurent El Ghaoui. First-order methods for sparse covariance selection. SIAM Journal on Matrix Analysis and Applications, 30(1):56\u201366, 2008.   \n[32] Adam J Rothman, Peter J Bickel, Elizaveta Levina, and Ji Zhu. Sparse permutation invariant covariance estimation. Electronic Journal of Statistics, 2, 2008.   \n[33] Jiaxi Ying, Jos\u00e9 Vin\u00edcius de Miranda Cardoso, and Daniel Palomar. Nonconvex sparse graph learning under Laplacian constrained graphical model. In Advances in Neural Information Processing Systems, volume 33, pages 7101\u20137113, 2020.   \n[34] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183\u2013202, 2009.   \n[35] Sang Oh, Onkar Dalal, Kshitij Khare, and Bala Rajaratnam. Optimization methods for sparse pseudolikelihood graphical model selection. In Advances in Neural Information Processing Systems, volume 27, 2014.   \n[36] Santiago Segarra, Antonio G Marques, Gonzalo Mateos, and Alejandro Ribeiro. Network topology inference from spectral templates. IEEE Transactions on Signal and Information Processing over Networks, 3(3):467\u2013483, 2017.   \n[37] Julie Fournet and Alain Barrat. Contact patterns among high school students. PLoS ONE, 9(9):e107878, 2014.   \n[38] Andrei Buciulea, Elvin Isuf,i Geert Leus, and Antonio G Marques. Learning graphs and simplicial complexes from data. In IEEE International Conference on Acoustics, Speech, and Signal Processing, pages 9861\u20139865, 2024.   \n[39] F Maxwell Harper and Joseph A Konstan. The MovieLens datasets: History and context. ACM Transactions on Interactive Intelligent Systems, 5(4), 2015.   \n[40] Yushun Dong, Jian Kang, Hanghang Tong, and Jundong Li. Individual fairness for graph neural networks: A ranking based approach. In ACM International Conference on Knowledge Discovery and Data Mining, pages 300\u2013310, 2021.   \n[41] Jian Kang, Jingrui He, Ross Maciejewski, and Hanghang Tong. InFoRM: Individual fairness on graph mining. In ACM International Conference on Knowledge Discovery and Data Mining, pages 379\u2013389, 2020.   \n[42] Eric D Kolaczyk. Statistical Analysis of Network Data: Methods and Models. Springer, 2009.   \n[43] Brian Baingana, Gonzalo Mateos, and Georgios B Giannakis. Proximal-gradient algorithms for tracking cascades over social networks. IEEE Journal of Selected Topics in Signal Processing, 8(4):563\u2013575, 2014.   \n[44] Onureena Banerjee, Laurent El Ghaoui, and Alexandre d\u2019Aspremont. Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data. Journal of Machine Learning Research, 9(15):485\u2013516, 2008.   \n[45] Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American Statistical Association, 96(456):1348\u20131360, 2001.   \n[46] Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. The Annals of Statistics, 38(2):894\u2013942, 2010.   \n[47] Samuel Rey, Madeline Navarro, Andrei Buciulea, Santiago Segarra, and Antonio G Marques. Joint graph learning from Gaussian observations in the presence of hidden nodes. In Asilomar Conference on Signals, Systems, and Computers, pages 53\u201357. IEEE, 2022.   \n[48] Patrick Danaher, Pei Wang, and Daniela M Witten. The joint graphical lasso for inverse covariance estimation across multiple classes. Journal of the Royal Statistical Society, Series B (Statistical Methodology), 76 (2):373\u2013397, 2013.   \n[49] Andrei Buciulea, Jiaxi Ying, Antonio G Marques, and Daniel P Palomar. Polynomial graphical lasso: Learning edges from Gaussian graph-stationary signals. arXiv preprint arXiv:2404.02621, 2024.   \n[50] Nicolai Meinshausen and Peter B\u00fchlmann. High-dimensional graphs and variable selection with the Lasso. The Annals of Statistics, 34(3), 2006. ISSN 0090-5364.   \n[51] Pradeep Ravikumar, Martin J Wainwright, Garvesh Raskutti, and Bin Yu. High-dimensional covariance estimation by minimizing $\\ell_{1}$ -penalized log-determinant divergence. Electronic Journal of Statistics, 5, 2011. ISSN 1935-7524.   \n[52] Clifford Lam and Jianqing Fan. Sparsistency and rates of convergence in large covariance matrix estimation. The Annals of Statistics, 37(6B), 2009.   \n[53] Pradeep Ravikumar, Martin J Wainwright, and John D Lafferty. High-dimensional Ising model selection using $\\ell_{1}$ -regularized logistic regression. The Annals of Statistics, 38(3), 2010. ISSN 0090-5364.   \n[54] Eunho Yang, Genevera Allen, Zhandong Liu, and Pradeep Ravikumar. Graphical models via generalized linear models. In Advances in Neural Information Processing Systems, volume 25, 2012.   \n[55] Rebecca Morrison, Ricardo Baptista, and Youssef Marzouk. Beyond normality: Learning sparse probabilistic graphical models in the non-Gaussian setting. In Advances in Neural Information Processing Systems, volume 30, 2017.   \n[56] Sandeep Kumar, Jiaxi Ying, Jose Vinicius de Miranda Cardoso, and Daniel Palomar. Structured graph learning via Laplacian spectral constraints. In Advances in Neural Information Processing Systems, volume 32, 2019.   \n[57] Madeline Navarro, Samuel Rey, Andrei Buciulea, Antonio G Marques, and Santiago Segarra. Joint network topology inference in the presence of hidden nodes. IEEE Transactions on Signal Processing, 2024.   \n[58] Samuel Rey, T Mitchell Roddenberry, Santiago Segarra, and Antonio G Marques. Enhanced graph-learning schemes driven by similar distributions of motifs. IEEE Transactions on Signal Processing, 71:3014\u20133027, 2023.   \n[59] Mart\u00edn Sevilla, Antonio G Marques, and Santiago Segarra. Estimation of partially known Gaussian graphical models with score-based structural priors. In International Conference on Artificial Intelligence and Statistics, pages 1558\u20131566, 2024.   \n[60] Ruijia Wang, Xiao Wang, Chuan Shi, and Le Song. Uncovering the structural fairness in graph contrastive learning. In Advances in Neural Information Processing Systems, volume 35, pages 32465\u201332473, 2022.   \n[61] Maarten Buyl and Tijl De Bie. DeBayes: A Bayesian method for debiasing network embeddings. In International Conference on Machine Learning, volume 119, pages 1220\u20131229, 2020.   \n[62] Le Wu, Lei Chen, Pengyang Shao, Richang Hong, Xiting Wang, and Meng Wang. Learning fair representations for recommendation: A graph-based perspective. In ACM Web Conference, pages 2198\u20132208, 2021.   \n[63] Chirag Agarwal, Himabindu Lakkaraju, and Marinka Zitnik. Towards a unified framework for fair and stable graph representation learning. In The Conference on Uncertainty in Artificial Intelligence, volume 161, pages 2114\u20132124, 2021.   \n[64] Oyku Deniz Kose and Yanning Shen. Fair node representation learning via adaptive data augmentation. arXiv:2201.08549, 2022.   \n[65] Yushun Dong, Ninghao Liu, Brian Jalaian, and Jundong Li. EDITS: Modeling and mitigating data bias for graph neural networks. In ACM Web Conference, pages 1259\u20131269, 2022.   \n[66] Oyku Deniz Kose and Yanning Shen. FairWire: Fair graph generation. arXiv:2402.04383, 2024.   \n[67] Peter J Bickel and Elizaveta Levina. Regularized estimation of large covariance matrices. The Annals of Statistics, 36(1):199\u2013227, 2008.   \n[68] Amir Beck. First-Order Methods in Optimization. SIAM, 2017.   \n[69] Ana-Andreea Stoica, Christopher Riederer, and Augustin Chaintreau. Algorithmic glass ceiling in social networks: The effects of social recommendations on network diversity. In International World Wide Web Conference, page 923\u2013932, 2018.   \n[70] Chen Avin, Zvi Lotker, Yinon Nahum, and David Peleg. Modeling and analysis of glass ceiling and power inequality in bi-populated societies. In International Winter School and Conference on Network Science, pages 61\u201373. Springer International Publishing, 2017.   \n[71] Cho-Jui Hsieh, Matyas A Sustik, Inderjit S Dhillon, Pradeep K Ravikumar, and Russell Poldrack. BIG & QUIC: Sparse inverse covariance estimation for a million variables. In Advances in Neural Information Processing Systems, volume 26, 2013.   \n[72] Tianyi Yao, Minjie Wang, and Genevera I Allen. Fast and accurate graph learning for huge data via minipatch ensembles. arXiv preprint arXiv:2110.12067, 2021.   \n[73] Xiwen Wang, Jiaxi Ying, and Daniel Palomar. Learning large-scale $M T P_{2}$ Gaussian graphical models via bridge-block decomposition. In Advances in Neural Information Processing Systems, volume 36, pages 73211\u201373231, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Related Work ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Graph Estimation ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Obtaining graphical representations from data has long stood as one of the most prominent tasks in several fields, including statistics, GSP, and more [3, 42, 43]. Maximum likelihood estimation of GGMs was first introduced by Dempster [25], and subsequent additions of the $\\ell_{1}$ -norm penalty produced the famous graphical lasso approach [31, 32, 44]. Several modifications and extensions followed, typically proposing alternative penalties [4, 45\u201349], and its popularity has brought about copious theoretical investigation into its performance, its limitations, and more [26, 32, 50\u201352]. While Gaussianity is typical for estimating graphs, extensions to non-Gaussian distributions are also well studied [53\u201355]. Similar approaches have found use in GSP, both under additional constraints and in more general settings [33, 36, 56, 57]. ", "page_idx": 14}, {"type": "text", "text": "Most works learn graphs from data solely to preserve some notion of fidelity that may potentially be aided by prior structural assumptions [58, 59]. However, estimating graphs while improving performance in both accuracy and fairness in connections remains novel [18]. Moreover, to the best of our knowledge, we are the first to estimate graphical models from data while explicitly encouraging fairness in its connections, particularly in terms of both connectivity and correlation bias [16]. ", "page_idx": 14}, {"type": "text", "text": "A.2 Fairness on Graphs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Fairness in graph-based tasks has received much attention recently, particularly in the field of machine learning. In addition to group fairness [13, 14], some works consider other definitions such as individual or structural fairness [40, 41, 60]. The most prevalent tasks for fairness on graphs are link prediction [12, 14, 19, 61, 62] and node representation [12, 13, 62\u201364], where nodes must experience equal treatment regardless of their sensitive attributes. Some works directly alter graph structure to promote unbiased connections, but, unlike our work, this requires a known graph [14, 19, 29, 30, 61, 65]. ", "page_idx": 14}, {"type": "text", "text": "A number of works consider creating fair graphs, which share our goal of obtaining graph representations that possess unbiased connectivity patterns [16\u201318, 66]. This includes fair graph generative models [66], which aims to learn distributions of graph data, whereas we learn graph structure from nodal observations. We note [16\u201318] as the only other works of which we are aware that estimate graphs from data while considering fair outcomes. However, for [16, 17], the task is fundamentally different as they aim to cluster nodes fairly without explicitly imposing fairness on graph structure. While the task in [18] is the same as ours, we differ not only in how our samples are modeled but also in our definition of fairness, which is specific to graphical models encoding conditional dependence. Moreover, we provide further theoretical results, including guarantees of both error rates and algorithmic convergence. ", "page_idx": 14}, {"type": "text", "text": "B Proof of Theorem 1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Our proof of Theorem 1 is inspired by that of [32]. While some steps in this work are analogous to those of our result in Theorem 1, the presence of the bias penalty yields subtle differences. Thus, we elaborate on all steps of the proof to demonstrate deviations from the original result along with providing a self-contained result for clarity. We first require the following lemma [67, Lemma A.3], which allows us to bound differences between entries of estimated and true Gaussian covariance matrix entries with high probability. ", "page_idx": 14}, {"type": "text", "text": "Lemma 1 (Bickel and Levina [67]) For iid Gaussian random vectors $\\mathbf{Z}_{i}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{S})$ for $i\\,\\in\\,[n]$ such that $\\lambda_{\\operatorname*{max}}(\\mathbf{S})\\leq\\bar{k}<\\infty$ , we have that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\left|\\sum_{\\ell=1}^{n}Z_{i\\ell}Z_{j\\ell}-S_{i j}\\right|\\geq n\\epsilon\\right]\\leq c_{1}\\exp\\{-c_{2}n\\epsilon^{2}\\},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\epsilon>0$ is bounded, and $c_{1},\\:c_{2}$ , and $\\epsilon$ are dependent only on $\\bar{k}$ . ", "page_idx": 14}, {"type": "text", "text": "We proceed with the proof of (5) in the statement of Theorem 1. Consider a function $Q$ that measures the difference in the objective of (4) given $\\Theta\\in\\mathcal{M}$ and the true precision matrix $\\Theta_{\\mathrm{0}}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q(\\Theta)\\;:=\\;\\mathrm{tr}(\\hat{\\Sigma}\\Theta)-\\log\\operatorname*{det}\\Theta+\\mu_{1}\\left\\lVert\\Theta_{\\bar{\\mathcal{D}}}\\right\\rVert_{1}+\\mu_{2}H(\\Theta)}\\\\ &{\\qquad\\qquad-\\mathrm{tr}(\\hat{\\Sigma}\\Theta_{0})+\\log\\operatorname*{det}\\Theta_{0}-\\mu_{1}\\left\\lVert[\\Theta_{0}]_{\\bar{\\mathcal{D}}}\\right\\rVert_{1}-\\mu_{2}H(\\Theta_{0})}\\\\ &{\\qquad=\\;\\mathrm{tr}((\\hat{\\Sigma}-\\Sigma_{0})(\\Theta-\\Theta_{0}))+\\mathrm{tr}(\\Sigma_{0}(\\Theta-\\Theta_{0}))-(\\log\\operatorname*{det}\\Theta-\\log\\operatorname*{det}\\Theta_{0})}\\\\ &{\\qquad\\qquad+\\;\\mu_{1}\\big(\\left\\lVert\\Theta_{\\bar{\\mathcal{D}}}\\right\\rVert_{1}-\\left\\lVert[\\Theta_{0}]_{\\bar{\\mathcal{D}}}\\right\\rVert_{1}\\big)+\\mu_{2}\\big(H(\\Theta)-H(\\Theta_{0})\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We may also represent the objective difference in terms of the disparity between $\\Theta$ and $\\Theta_{\\mathrm{0}}$ , that is, $G(\\pmb{\\Delta})=Q(\\pmb{\\Theta}_{0}+\\pmb{\\Delta})$ for $\\pmb{\\Delta}=\\pmb{\\Theta}-\\pmb{\\Theta}_{0}$ , where we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{G(\\Delta)\\,=\\,\\mathrm{tr}((\\hat{\\Sigma}-\\Sigma_{0})\\Delta)+\\mathrm{tr}(\\Sigma_{0}\\Delta)-\\big(\\log\\operatorname*{det}(\\Theta_{0}+\\Delta)-\\log\\operatorname*{det}\\Theta_{0}\\big)}&{}\\\\ {+\\,\\mu_{1}\\big(\\,\\|(\\Theta_{0}+\\Delta)_{\\bar{\\mathcal{D}}}\\|_{1}-\\|[\\Theta_{0}]_{\\bar{\\mathcal{D}}}\\|_{1}\\,\\big)+\\mu_{2}\\big(H(\\Theta_{0}+\\Delta)-H(\\Theta_{0})\\big).}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We may then use $Q$ and $G$ to compare $\\Theta^{*}$ and $\\Theta_{\\mathrm{0}}$ via their difference under the objective function of our proposed graphical lasso problem (4). ", "page_idx": 15}, {"type": "text", "text": "By the definition of $\\Theta^{*}\\in\\mathcal{M}$ as the minimizer of (4), we have that $Q(\\Theta^{*})\\leq0$ and thus $G(\\Delta^{*})\\leq0$ for $\\Delta^{*}=\\Theta^{*}-\\Theta_{0}$ . If we can show that $G(\\Delta)>0$ for every $\\Delta\\in\\mathcal{M}$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\Delta\\|_{F}>m_{1}r_{n}+m_{2}\\frac{g\\sqrt{H(\\Theta_{0})}}{\\sqrt{p}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where ", "page_idx": 15}, {"type": "equation", "text": "$$\nr_{n}:={\\sqrt{\\frac{\\left(p+s\\right)\\log p}{n}}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for some constants $m_{1},m_{2}>0$ , then we know that $\\|\\Delta^{*}\\|_{F}$ satisfies (5) in Theorem 1, as desired. To this end, we obtain a lower bound of $G(\\Delta)$ and determine the conditions under which we can guarantee that $G(\\Delta)>0$ for any $\\Delta\\in\\mathcal{M}$ such that (15) holds. ", "page_idx": 15}, {"type": "text", "text": "Trace difference. We begin by addressing the first term of (14). These steps are analogous to those of [32]. By the triangle inequality, we define nonnegative values $t_{1}$ and $t_{2}$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left|\\mathbf{t}((\\hat{\\Sigma}-\\Sigma_{0})\\Delta)\\right|\\,\\leq\\,\\left|\\sum_{i\\neq j}(\\hat{\\Sigma}_{i j}-[\\Sigma_{0}]_{i j})\\Delta_{i j}\\right|+\\left|\\sum_{i=1}^{p}(\\hat{\\Sigma}_{i i}-[\\Sigma_{0}]_{i i})\\Delta_{i i}\\right|=:t_{1}+t_{2},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for which we provide an upper bound. To bound $t_{1}$ , note that by Lemma 1, we may choose any constant $c_{1}>0$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n|\\hat{\\Sigma}_{i j}-[\\Sigma_{0}]_{i j}|\\;=\\;\\left|\\frac{1}{n}\\sum_{k=1}^{n}X_{k i}X_{k j}-[\\Sigma_{0}]_{i j}\\right|\\ge c_{1}\\sqrt{\\frac{\\log p}{n}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with probability at most $d_{1}p^{-d_{2}c_{1}^{2}}$ for constants $d_{1},d_{2}>0$ . Then, by the union sum inequality, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{P}\\left[\\underset{i\\neq j}{\\operatorname*{max}}\\,|\\hat{\\Sigma}_{i j}-[\\Sigma_{0}]_{i j}|\\geq c_{1}\\sqrt{\\frac{\\log p}{n}}\\right]\\ =\\ \\mathbb{P}\\left[\\bigcup_{i\\neq j}|\\hat{\\Sigma}_{i j}-[\\Sigma_{0}]_{i j}|\\geq c_{1}\\sqrt{\\frac{\\log p}{n}}\\right]}}\\\\ &{}&{\\leq\\ \\underset{i\\neq j}{\\sum}\\mathbb{P}\\left[|\\hat{\\Sigma}_{i j}-[\\Sigma_{0}]_{i j}|\\geq c_{1}\\sqrt{\\frac{\\log p}{n}}\\right]}\\\\ &{}&{\\leq\\ d_{1}(p^{2}-p)p^{-d_{2}c_{1}^{2}}\\leq d_{1}p^{-d_{3}},~~~~~}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $c_{1}\\,>\\,\\sqrt{2/d_{2}}$ and $d_{3}\\,>\\,d_{2}c_{1}^{2}\\,-\\,2$ . We then apply the Cauchy-Schwarz inequality for the following bound on $t_{1}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\nt_{1}\\leq\\operatorname*{max}_{i\\neq j}\\left|\\hat{\\Sigma}_{i j}-[\\Sigma_{0}]_{i j}\\right|\\cdot\\left\\|\\Delta_{\\bar{\\mathcal{D}}}\\right\\|_{1}\\leq c_{1}\\sqrt{\\frac{\\log p}{n}}\\left\\|\\Delta_{\\bar{\\mathcal{D}}}\\right\\|_{1},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "whose probability tends to 1 as $p\\rightarrow\\infty$ as in the right-hand side of (19). ", "page_idx": 16}, {"type": "text", "text": "For $t_{2}$ , we again apply the Cauchy-Schwarz inequality and Lemma 1 to obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{t_{2}\\le\\ \\left(\\sum_{i=1}^{p}(\\hat{\\Sigma}_{i i}-[\\Sigma_{0}]_{i i})^{2}\\right)^{1/2}\\cdot\\|\\Delta_{\\mathcal{D}}\\|_{F}}}\\\\ &{\\le\\ \\sqrt{p}\\operatorname*{max}_{i\\in[p]}\\ensuremath{\\vert\\hat{\\Sigma}_{i i}-[\\Sigma_{0}]_{i i}\\vert}\\cdot\\|\\Delta_{\\mathcal{D}}\\|_{F}}\\\\ &{\\le\\ c_{2}\\sqrt{\\frac{p\\log p}{n}}\\cdot\\|\\Delta_{\\mathcal{D}}\\|_{F}}\\\\ &{\\le\\ c_{2}r_{n}\\,\\|\\Delta_{\\mathcal{D}}\\|_{F}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "with probability again approaching 1 as $p\\rightarrow\\infty$ . ", "page_idx": 16}, {"type": "text", "text": "We combine (20) and (21) to obtain a lower bound of the first term of (14), ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname{tr}((\\hat{\\Sigma}-\\Sigma_{0})\\Delta)\\ \\geq\\ -\\left|\\operatorname{tr}((\\hat{\\Sigma}-\\Sigma_{0})\\Delta)\\right|\\ \\geq\\ -\\ c_{1}\\sqrt{\\frac{\\log p}{n}}\\left\\|\\Delta_{\\vec{D}}\\right\\|_{1}-c_{2}r_{n}\\left\\|\\Delta_{\\mathcal{D}}\\right\\|_{F}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Log-determinant difference. We next consider the difference of log determinants in $G(\\Delta)$ which differs from the proof of [32] as we consider an inequality in (15) rather than an equality. Consider the function $f(t)=\\log\\operatorname*{det}(\\Theta_{0}+t\\Delta)$ . The derivative and second derivative of $f(t)$ are ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f^{\\prime}(t)=\\mathrm{tr}((\\Theta_{0}+t\\Delta)^{-1}\\Delta),}\\\\ &{f^{\\prime\\prime}(t)=-\\mathrm{tr}(\\Delta(\\Theta_{0}+t\\Delta)^{-1}\\Delta(\\Theta_{0}+t\\Delta)^{-1}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "respectively. Then, the Maclaurin series expansion of $f(1)$ with the integral form of the remainder is ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(1)-f(0)=f^{\\prime}(0)+\\int_{0}^{1}f^{\\prime\\prime}(v)(1-v)d v,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "so by the symmetry of $\\mathbf{{\\Theta}}_{0}$ and $\\Delta$ we apply the Kronecker product for ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\operatorname*{det}(\\Theta_{0}+\\Delta)-\\log\\operatorname*{det}\\Theta_{0}}\\\\ &{\\qquad\\qquad=\\mathrm{~tr}(\\Sigma_{0}\\Delta)-\\displaystyle\\int_{0}^{1}(1-v)\\mathrm{tr}\\big(\\Delta(\\Theta_{0}+v\\Delta)^{-1}\\Delta(\\Theta_{0}+v\\Delta)^{-1}\\big)d v}\\\\ &{\\qquad\\qquad=\\mathrm{~tr}(\\Sigma_{0}\\Delta)-\\mathrm{vec}(\\Delta)^{\\top}\\left[\\displaystyle\\int_{0}^{1}(1-v)\\big(\\Theta_{0}+v\\Delta\\big)^{-1}\\otimes\\big(\\Theta_{0}+v\\Delta\\big)^{-1}d v\\right]\\mathrm{vec}(\\Delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Recall that the definition of the smallest eigenvalue of a matrix $\\mathbf{A}$ is $\\begin{array}{r}{\\lambda_{\\mathrm{min}}({\\bf A})=\\operatorname*{min}_{{\\bf x}:\\|{\\bf x}\\|_{2}=1}{\\bf x}^{\\top}{\\bf A}{\\bf x}}\\end{array}$ . We thus have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\operatorname*{det}(\\Theta_{0}+\\Delta)-\\log\\operatorname*{det}\\Theta_{0}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathrm{~tr}(\\Sigma_{0}\\Delta)-\\left\\lVert\\Delta\\right\\rVert_{F}^{2}\\lambda_{\\operatorname*{min}}\\left(\\displaystyle\\int_{0}^{1}(1-v)(\\Theta_{0}+v\\Delta)^{-1}\\otimes(\\Theta_{0}+v\\Delta)^{-1}d v\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathrm{~tr}(\\Sigma_{0}\\Delta)-\\left\\lVert\\Delta\\right\\rVert_{F}^{2}\\displaystyle\\int_{0}^{1}(1-v)\\lambda_{\\operatorname*{min}}^{2}(\\Theta_{0}+v\\Delta)^{-1}d v}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "since the eigenvalues of the Kronecker product of two matrices are the products of their eigenvalues. Then, we have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\log\\operatorname*{det}(\\Theta_{0}+\\Delta)-\\log\\operatorname*{det}\\Theta_{0}\\,\\le\\,\\operatorname{tr}(\\Sigma_{0}\\Delta)-\\frac{1}{2}\\left\\lVert\\Delta\\right\\rVert_{{F}\\mathit{v}\\in[0,1]}^{2}\\lambda_{\\operatorname*{min}}^{2}(\\Theta_{0}+v\\Delta)^{-1}}&{}\\\\ {\\,\\le\\,\\operatorname{tr}(\\Sigma_{0}\\Delta)-\\frac{1}{2}\\left\\lVert\\Delta\\right\\rVert_{{F}}^{2}\\lambda_{\\operatorname*{min}}^{2}(\\Theta_{0}+\\Delta)^{-1}}&{}\\\\ {\\,=\\,\\operatorname{tr}(\\Sigma_{0}\\Delta)-\\frac{1}{2}\\left\\lVert\\Delta\\right\\rVert_{{F}}^{2}\\lambda_{\\operatorname*{max}}^{-2}(\\Theta_{0}+\\Delta)}&{}\\\\ {\\,\\le\\,\\operatorname{tr}(\\Sigma_{0}\\Delta)-\\frac{1}{2}\\left\\lVert\\Delta\\right\\rVert_{{F}}^{2}(\\left\\lVert\\Theta_{0}\\right\\rVert_{2}+\\left\\lVert\\Delta\\right\\rVert_{2})^{-2}}&{}\\\\ {\\,\\le\\,\\operatorname{tr}(\\Sigma_{0}\\Delta)-\\frac{1}{2}\\left\\lVert\\Delta\\right\\rVert_{{F}}^{2}(\\underline{{k}}^{-1}+\\left\\lVert\\Delta\\right\\rVert_{{F}})^{-2}.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We define $\\tau:=\\operatorname*{max}\\{4,(1+\\underline{{k}}\\,\\|\\Delta\\|_{F})^{2}\\}$ , which gives us ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\log\\operatorname*{det}(\\Theta_{0}+\\Delta)-\\log\\operatorname*{det}\\Theta_{0}\\,\\leq\\,\\mathrm{tr}\\bigl(\\Sigma_{0}\\Delta\\bigr)-\\frac12\\,\\|\\Delta\\|_{F}^{2}\\,\\bigl(\\underline{{k}}^{-1}\\operatorname*{max}\\{2,\\underline{{k}}\\,\\|\\Delta\\|_{F}+1\\bigr\\}\\bigr)^{-2}}\\\\ {\\displaystyle\\,\\leq\\,\\mathrm{tr}\\bigl(\\Sigma_{0}\\Delta\\bigr)-\\frac{1}{2\\tau}\\underline{{k}}^{2}\\,\\|\\Delta\\|_{F}^{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Sparsity penalties. For the sparsity penalties, note that by the definition of $\\boldsymbol{S}$ , we may follow the steps in [32] and exploit the fact that $\\|[\\pmb{\\Theta}_{0}+\\pmb{\\Delta}]_{\\bar{\\mathcal{D}}}\\|_{1}\\,=\\,\\|[\\pmb{\\Theta}_{0}+\\pmb{\\Delta}]_{\\bar{\\mathcal{D}}\\cap\\mathcal{S}}\\|_{1}+\\|\\pmb{\\Delta}_{\\bar{\\mathcal{D}}\\cap\\bar{\\mathcal{S}}}\\|_{1}$ and $\\|[\\Theta_{0}]_{\\bar{\\mathcal{D}}}\\|_{1}=\\|[\\Theta_{0}]_{\\bar{\\mathcal{D}}\\cap\\mathcal{S}}\\|_{1}$ . Then, by the triangle inequality, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mu_{1}(\\|[\\Theta_{0}+\\Delta]_{\\bar{\\mathcal{D}}}\\|_{1}-\\|[\\Theta_{0}]_{\\bar{\\mathcal{D}}}\\|_{1})\\geq\\mu_{1}(\\|\\Delta_{\\bar{\\mathcal{D}}\\cap\\bar{\\mathcal{S}}}\\|_{1}-\\|\\Delta_{\\bar{\\mathcal{D}}\\cap\\mathcal{S}}\\|_{1}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "DP gaps. Finally, we consider the difference in DP gaps. Observe that $H(\\Theta)$ is both differentiable and convex in $\\Theta$ . Thus, we have that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{H(\\Theta_{0}+\\Delta)-H(\\Theta_{0})\\;\\geq\\;\\mathrm{tr}(\\nabla_{\\Theta}H(\\Theta_{0})\\Delta)}&{}\\\\ {\\;\\geq\\;-\\;|\\mathrm{tr}(\\nabla_{\\Theta}H(\\Theta_{0})\\Delta)|}&{}\\\\ {\\;\\geq\\;-\\;|\\mathrm{tr}(\\nabla_{\\Theta}H(\\Theta_{0})\\Theta_{0})|-|\\mathrm{tr}(\\nabla_{\\Theta}H(\\Theta_{0})\\Theta)|}&{}\\\\ {\\;\\geq\\;-\\;\\|\\nabla_{\\Theta}H(\\Theta_{0})\\|_{*}\\,(\\|\\Theta_{0}\\|_{2}+\\|\\Theta\\|_{2})}&{}\\\\ {\\;\\geq\\;-\\left(\\alpha^{1/2}+\\underline{{k}}^{-1}\\right)\\|\\nabla_{\\Theta}H(\\Theta_{0})\\|_{*}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Moreover, recall that by definition ${\\bf C}_{a b}$ is block-wise constant for every $a,b\\in[g]$ . Thus, the gradient $\\nabla_{\\Theta}H(\\Theta_{0})$ as in the right-hand side of (51) is block-wise constant with $g$ blocks, hence it is at most rank $g$ . We then have that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Vert\\nabla_{\\Theta}H(\\Theta_{0})\\Vert_{*}\\,\\le\\,\\sqrt{g}\\,\\Vert\\nabla_{\\Theta}H(\\Theta_{0})\\Vert_{F}}&{}\\\\ &{\\le\\,\\frac{2\\sqrt{g}}{g^{2}-g}\\displaystyle\\sum_{a=1}^{g}\\sum_{b\\ne a}^{g}\\mathrm{tr}(\\mathbf{C}_{a b}\\Theta_{0})\\,\\Vert\\mathbf{C}_{a b}\\Vert_{F}}\\\\ &{=\\,\\frac{2\\sqrt{g}}{g^{2}-g}\\displaystyle\\sum_{a=1}^{g}\\sum_{b\\ne a}^{\\infty}\\vert\\mathrm{tr}(\\mathbf{C}_{a b}\\Theta_{0})\\vert\\left(\\frac{1}{\\bar{p}^{2}-\\bar{p}}+\\frac{1}{\\bar{p}^{2}}\\right)^{1/2}}\\\\ &{\\le\\,\\frac{4\\sqrt{g}}{\\bar{p}(g^{2}-g)}\\displaystyle\\sum_{a=1}^{g}\\sum_{b\\ne a}^{\\infty}\\vert\\mathrm{tr}(\\mathbf{C}_{a b}\\Theta_{0})\\vert}\\\\ &{\\le\\,\\frac{4\\sqrt{g}}{\\bar{p}\\sqrt{g^{2}-g}}\\left(\\displaystyle\\sum_{a=1}^{g}\\sum_{b\\ne a}^{\\infty}\\vert\\mathrm{tr}(\\mathbf{C}_{a b}\\Theta_{0})\\vert^{2}\\right)^{1/2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last inequality holds by $\\left\\|\\mathbf{x}\\right\\|_{1}\\leq{\\sqrt{m}}\\left\\|\\mathbf{x}\\right\\|_{2}$ for any vector $\\mathbf{x}\\in\\mathbb{R}^{m}$ . By the definition of $H$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|\\nabla\\!\\Theta^{}H(\\Theta_{0})\\|_{*}\\;\\leq\\;\\frac{4\\sqrt{g}}{\\bar{p}}\\sqrt{H(\\Theta_{0})}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We then have the following lower bound for the difference in DP gaps, ", "page_idx": 17}, {"type": "equation", "text": "$$\nH(\\Theta_{0}+\\Delta)-H(\\Theta_{0})\\;\\ge\\;-\\;\\frac{4\\sqrt{g}(\\sqrt{\\alpha}+\\underline{{k}}^{-1})}{\\bar{p}}\\sqrt{H(\\Theta_{0})}\\;\\ge\\;-\\;\\frac{c_{3}g}{\\bar{p}}\\sqrt{H(\\Theta_{0})}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We now combine the lower bounds for each term in (14), that is, (22), (29), (30), and (34). For $\\epsilon_{1}<1$ , we let ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mu_{1}=\\frac{c_{1}}{\\epsilon_{1}}\\sqrt{\\frac{\\log p}{n}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{G(\\Delta)\\ \\geq\\ \\frac{1}{2\\tau}\\dot{L}^{2}\\ \\|\\Delta\\|_{F}^{2}-c_{1}\\sqrt{\\frac{\\log p}{n}}\\,\\|\\Delta_{\\mathcal{D}}\\|_{1}-c_{2}r_{n}\\,\\|\\Delta_{\\mathcal{D}}\\|_{F}}&{}\\\\ &{\\qquad\\qquad+\\ \\mu_{1}(\\|\\Delta_{\\mathcal{D}\\cap\\mathcal{S}}\\|_{1}-\\|\\Delta_{\\mathcal{D}\\cap\\mathcal{S}}\\|_{1})-\\frac{\\mu_{2}c_{3}g}{\\bar{p}}\\sqrt{H(\\Theta_{0})}}\\\\ &{\\geq\\ \\frac{1}{2\\tau}\\dot{L}^{2}\\,\\|\\Delta\\|_{F}^{2}-c_{1}\\bigg(1+\\frac{1}{\\epsilon_{1}}\\bigg)r_{n}\\,\\|\\Delta_{\\mathcal{D}}\\|_{F}-c_{2}r_{n}\\,\\|\\Delta_{\\mathcal{D}}\\|_{F}-\\frac{\\mu_{2}c_{3}g}{\\bar{p}}\\sqrt{H(\\Theta_{0})}}\\\\ {\\ =\\ \\|\\Delta_{\\mathcal{D}}\\|_{F}\\,\\bigg[\\frac{1}{4\\tau}\\dot{L}^{2}\\,\\|\\Delta_{\\mathcal{D}}\\|_{F}-c_{1}\\bigg(1+\\frac{1}{\\epsilon_{1}}\\bigg)r_{n}\\bigg]}\\\\ &{\\qquad\\qquad+\\,\\|\\Delta_{\\mathcal{D}}\\|_{F}\\,\\bigg[\\frac{1}{4\\tau}\\dot{L}^{2}\\,\\|\\Delta_{\\mathcal{D}}\\|_{F}-c_{2}r_{n}\\bigg]}\\\\ &{\\qquad\\qquad+\\,\\bigg[\\frac{1}{4\\tau}\\dot{L}^{2}\\,\\|\\Delta\\|_{F}^{2}-\\frac{\\mu_{2}c_{3}g}{\\bar{p}}\\sqrt{H(\\Theta_{0})}\\bigg]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where we aim to find conditions on $\\|\\Delta\\|_{F}$ ensuring that each term (36), (37), and (38) are positive so that $G(\\Delta)>0$ . For the first two terms (36) and (37), we obtain the following lower bounds ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\lVert\\Delta_{\\bar{\\mathcal{D}}}\\rVert_{F}>4\\tau\\underline{{k}}^{-2}c_{1}\\left(1+\\frac{1}{\\epsilon_{1}}\\right)r_{n}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|\\pmb{\\Delta}_{\\mathcal{D}}\\|_{F}>4\\tau\\underline{{k}}^{-2}c_{2}r_{n},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "respectively. For the third term (38), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|\\Delta\\|_{F}^{2}>4\\tau c_{3}\\mu_{2}\\cdot\\frac{g}{\\bar{p}}\\sqrt{H(\\Theta_{0})}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "All three conditions (40), (39), and (41) guarantee that $G(\\Delta)$ is positive. Combining the conditions, we obtain a sufficient condition to ensure that $G(\\Delta)>0$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|\\pmb{\\Delta}\\|_{F}~>~\\operatorname*{max}\\left\\{4\\tau\\underline{{k}}^{-2}\\left(c_{1}\\left(1+\\frac{1}{\\epsilon_{1}}\\right)+c_{2}\\right)r_{n},\\sqrt{4\\tau c_{3}\\mu_{2}}\\cdot\\sqrt{\\frac{g}{p}}\\sqrt{H(\\Theta_{0})}\\right\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Thus, there exist constants $m_{1},m_{2}>0$ such that with high probability as $n,p\\to\\infty$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|\\Delta\\|_{F}>m_{1}r_{n}+m_{2}\\frac{\\sqrt{g}\\,\\sqrt[4]{H(\\Theta_{0})}}{\\sqrt{\\bar{p}}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "When this holds for any $\\Delta\\in\\mathcal{M}$ , then we have shown that $G(\\Delta)>0$ . Thus, since $G(\\Delta^{*})\\leq0$ and $\\Delta^{*}\\in\\mathcal{M}$ , we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|\\Delta^{*}\\|_{F}\\leq m_{1}r_{n}+m_{2}\\frac{\\sqrt{g}\\sqrt{H(\\Theta_{0})}}{\\sqrt{\\bar{p}}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "with high probability. Recalling that $g\\bar{p}=p$ by AS4, we obtain the inequality in (5), as desired. Moreover, note that if we select $\\mu_{2}$ such that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mu_{2}\\,\\leq\\,\\frac{4\\tau\\underline{{k}}^{-4}}{c_{3}}\\left(c_{1}\\left(1+\\frac1{\\epsilon_{1}}\\right)+c_{2}\\right)^{2}\\left(\\frac{\\bar{p}^{2}\\log p}{n\\sqrt{H(\\Theta_{0})}}\\right)}\\\\ {\\,\\leq\\,\\frac{4\\tau\\underline{{k}}^{-4}}{c_{3}}\\left(c_{1}\\left(1+\\frac1{\\epsilon_{1}}\\right)+c_{2}\\right)^{2}\\left(\\frac{\\bar{p}(p+s)\\log p}{n g\\sqrt{H(\\Theta_{0})}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "then (42) becomes equivalent to ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\Delta\\right\\|_{F}\\;>\\;4\\tau\\underline{{{k}}}^{-2}\\left(c_{1}\\left(1+\\frac{1}{\\epsilon_{1}}\\right)+c_{2}\\right)r_{n},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and we need only satisfy $\\|\\pmb{\\Delta}\\|_{F}>m_{1}r_{n}$ with probability tending to 1 as $n,p\\to\\infty$ for any $\\Delta\\in\\mathcal{M}$ , which guarantees that $G(\\Delta)>0$ . Again, since $G(\\Delta^{*})\\stackrel{<}{\\leq}0$ , we then have with high probability as $p\\rightarrow\\infty$ that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\lVert\\mathbf{A}^{*}\\rVert_{F}\\leq m_{1}r_{n}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for small enough $\\mu_{2}$ dependent on the dimension $p$ , the number of samples $n$ , the number of groups $g$ , and the fairness of the true precision matrix $H(\\Theta_{0})$ , satisfying (7) as desired. ", "page_idx": 18}, {"type": "text", "text": "C Proof of Corollary 1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Recall that by definition, $\\mathbf{\\Theta}\\Theta_{0}\\Sigma_{0}=\\mathbf{I}$ . Then, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\Theta^{*}\\Sigma_{0}-\\mathbf{I}\\|_{F}\\;=\\;\\left\\|(\\Theta^{*}-\\Theta_{0})\\Sigma_{0}\\right\\|_{F}\\;\\leq\\;\\bar{k}\\left\\|\\Theta^{*}-\\Theta_{0}\\right\\|_{F}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The result then follows from Theorem 1 for $m_{1}^{\\prime}=\\bar{k}m_{1}$ and $m_{2}^{\\prime}=\\bar{k}m_{2}$ . ", "page_idx": 19}, {"type": "text", "text": "D Optimization Algorithm Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We provide an overview on computing the update steps for Algorithm 1. For each iteration, we first take a gradient step for $f(\\Theta)$ , where the Lipschitz constant of $f$ plays the role of the step size, then we perform a proximal step over the non-smooth terms in $h(\\Theta)$ . The proximal step for $h(\\Theta)$ is the soft-thresholding operation for the $\\ell_{1}$ norm, ", "page_idx": 19}, {"type": "equation", "text": "$$\nT_{\\lambda}(\\Theta_{i j})=\\operatorname*{max}\\{|\\Theta_{i j}|-\\lambda,0\\}\\mathrm{sign}(\\Theta_{i j}),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\mathrm{sign}(x)$ returns the sign of $x$ . After the proximal gradient step, we perform an orthogonal projection $\\Pi_{\\mathcal{M}}$ onto the feasible set, which in our case is given by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Pi_{\\mathcal{M}}(\\boldsymbol{\\Theta})=\\mathbf{V}\\operatorname*{min}\\left\\{\\operatorname*{max}\\left\\{\\mathbf{A},0\\right\\},\\alpha^{1/2}\\right\\}\\mathbf{V}^{\\top},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "with $\\mathbf{V}$ and $\\Lambda$ respectively denoting the eigenvectors and eigenvalues of $\\Theta$ , and with some abuse of notation we let $\\operatorname*{min}\\lbrace\\operatorname*{max}\\lbrace\\mathbf{A},0\\rbrace,\\alpha^{{1}/{2}}\\rbrace$ denote an element-wise minimum and maximum operation on the entries of $\\Lambda$ , which projects all the eigenvalues in the diagonal of $\\pmb{\\Lambda}$ onto the interval $[0,\\alpha^{1/2}]$ . ", "page_idx": 19}, {"type": "text", "text": "Both the gradient $\\nabla\\Theta f$ and the Lipschitz constant $L$ of $f$ are contingent on the choice of bias penalty. The following two lemmas provide their computation for the cases where we apply $R_{H}=H$ , our DP gap measurement (2), or $R_{H}=H_{\\mathrm{node}}$ , its node-wise alternative (3). The proofs of both lemmas are deferred to Appendix E. ", "page_idx": 19}, {"type": "text", "text": "Lemma 2 Let the bias penalty $R_{H}$ in (4) be given by $H(\\Theta)$ in (2). Then, the gradient of $f(\\Theta)$ is given by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\nabla\\Theta^{}f(\\Theta)\\;=\\;\\hat{\\Sigma}-(\\Theta+\\epsilon\\mathbf{I})^{-1}+\\frac{2\\mu_{2}}{g^{2}-g}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\operatorname{tr}(\\mathbf{C}_{a b}\\Theta)\\mathbf{C}_{a b}^{\\top}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\mathbf{C}_{a b}:=[\\mathbf{z}_{a}\\mathbf{z}_{a}^{\\top}/(p_{a}^{2}-p_{a})-\\mathbf{z}_{a}\\mathbf{z}_{b}^{\\top}/(p_{a}p_{b})]\\bar{\\boldsymbol{\\mathcal{D}}}$ for every $a,b\\in[g]$ such that $a\\neq b$ . Moreover, for $\\begin{array}{r}{\\bar{\\mathbf{C}}:=\\sum_{a\\neq b}\\mathbf{C}_{a b}\\otimes\\mathbf{C}_{a b}^{\\top}}\\end{array}$ we have that $\\nabla_{\\Theta}f(\\Theta)$ is Lipschitz with constant ", "page_idx": 19}, {"type": "equation", "text": "$$\nL_{1}\\;=\\;{\\frac{1}{\\epsilon^{2}}}+{\\frac{2\\mu_{2}}{g^{2}-g}}\\lambda_{\\mathrm{max}}({\\bar{\\mathbf{C}}})\\;\\leq\\;{\\bar{L}}_{1}\\;=\\;{\\frac{1}{\\epsilon^{2}}}+{\\frac{2\\mu_{2}}{g^{2}-g}}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\lambda_{\\mathrm{max}}^{2}(\\mathbf{C}_{a b}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Intuitively, while $L_{1}$ is a smaller Lipschitz constant, it involves computing the eigendecomposition of a $p^{2}\\times\\dot{p}^{2}$ matrix, which may be prohibitive in higher-dimensional settings. Consequently, ${\\bar{L}}_{1}$ provides an approximation involving only $p\\times p$ matrices. The following lemma provides similar results when the node-wise DP gap $H_{\\mathrm{node}}$ is employed. ", "page_idx": 19}, {"type": "text", "text": "Lemma 3 Let the bias penalty $R_{H}$ in (4) be given by $H_{\\mathrm{node}}(\\Theta)$ in (3). Then, the gradient of $f(\\Theta)$ is given by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\nabla_{\\Theta}f(\\Theta)=\\hat{\\Sigma}-(\\Theta+\\epsilon\\mathbf{I})^{-1}+2\\mu_{2}[\\mathbf{A}\\Theta_{\\bar{\\mathcal{D}}}]_{\\bar{\\mathcal{D}}},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbf{A}:=\\frac{1}{p g(g-1)^{2}}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\left(\\sum_{b\\neq a}\\frac{\\mathbf{z}_{a}}{p_{a}}-\\frac{\\mathbf{z}_{b}}{p_{b}}\\right)\\left(\\sum_{b\\neq a}\\frac{\\mathbf{z}_{a}}{p_{a}}-\\frac{\\mathbf{z}_{b}}{p_{b}}\\right)^{\\intercal}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Moreover, $\\nabla_{\\Theta}f(\\Theta)$ is Lipschitz with constant ", "page_idx": 19}, {"type": "equation", "text": "$$\nL_{2}=\\frac{1}{\\epsilon^{2}}+2\\mu_{2}\\lambda_{\\mathrm{max}}(\\mathbf{A}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For more concrete intuition, we present a brief analysis for bias metric $R_{H}(\\Theta)=H_{\\mathrm{node}}(\\Theta)$ , but a similar analysis holds for other penalties such as $\\dot{R}_{H}(\\Theta)=H(\\Theta)$ . The first step of Algorithm 1 is a proximal gradient step. Computing the gradient requires an inverse $(\\Theta+\\epsilon\\dot{\\mathbf{I}})^{-1}$ and product $\\mathbf{A}\\mathbf{\\Theta}_{\\mathcal{\\Bar{D}}}$ , both incurring $\\bar{\\mathcal{O}}(\\bar{p^{3}})$ operations. The gradient step and soft-thresholding enjoy entry-wise computations with complexities ${\\mathcal{O}}(p^{2})$ . The projection step onto the set of positive semidefinite matrices involves an eigendecomposition of \u0398\u02d9(k) w ith complexity ${\\mathcal{O}}(p^{3})$ . Finally, the step size update only requires scalar operations, and the accelerated update of $\\check{\\Theta}^{(k+1)}$ involves $O(p^{2})$ operations, so they can be neglected. ", "page_idx": 20}, {"type": "text", "text": "E Gradients and Lipschitz Constants ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Here, we provide the computation of relevant gradients and Lipschitz constants for $f$ in (10) used in the proposed Algorithm 1. Both the gradient and the Lipschitz constant of $f$ depend on the choice of bias penalty $H(\\Theta)$ . ", "page_idx": 20}, {"type": "text", "text": "E.1 Proof of Lemma 2 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "First, we rewrite the demographic parity $\\Delta\\mathrm{DP}$ in (2) as ", "page_idx": 20}, {"type": "equation", "text": "$$\nH(\\Theta)=\\frac{1}{g^{2}-g}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\operatorname{tr}(\\mathbf{C}_{a b}\\Theta)^{2},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\mathbf{C}_{a b}$ is defined in the statement of Lemma 2. The gradient of $H$ can be obtained as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\nabla\\Theta^{\\boldsymbol{\\cal H}}(\\Theta)=\\frac{2}{g^{2}-g}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\operatorname{tr}(\\mathbf{C}_{a b}\\Theta)\\mathbf{C}_{a b}^{\\top},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and adding it to the gradient of the remaining terms of $f(\\Theta)$ , the result follows ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\nabla\\mathsf{e}f(\\Theta)=\\hat{\\Sigma}-\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}+\\frac{2\\mu_{2}}{g^{2}-g}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\operatorname{tr}(\\Theta\\mathbf{C}_{a b})[\\mathbf{C}_{a b}]^{\\top}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Next, to show that the gradient of $f(\\Theta)$ is Lipschitz, it suffices to show that its Hessian is bounded. The Hessian $\\nabla_{\\Theta}^{2}f(\\Theta)$ can be computed as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\nabla_{\\Theta}^{2}f(\\Theta)=\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\otimes\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}+\\frac{2\\mu_{2}}{g^{2}-g}\\sum_{a=1}^{g}\\sum_{b\\neq a}\\left(\\mathbf{C}_{a b}\\otimes\\mathbf{C}_{a b}^{\\top}\\right),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and it is bounded by ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla_{\\Theta}^{2}f(\\Theta)\\|_{2}\\leq\\left\\|\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\otimes\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\right\\|_{2}+\\frac{2\\mu_{2}}{g^{2}-g}\\left\\|\\displaystyle\\sum_{a=1}^{g}\\sum_{b\\neq a}\\left(\\mathbf{C}_{a b}\\otimes\\mathbf{C}_{a b}^{\\top}\\right)\\right\\|_{2}}\\\\ &{\\quad\\quad\\quad\\quad\\leq\\displaystyle\\frac{1}{\\epsilon^{2}}+\\frac{2\\mu_{2}}{g^{2}-g}\\displaystyle\\sum_{a=1}^{g}\\sum_{b\\neq a}\\lambda_{\\operatorname*{max}}(\\mathbf{C}_{a b})=L_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Moreover, it also follows that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla_{\\Theta}^{2}f(\\Theta)\\|_{2}\\ \\leq\\ \\left\\|\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\otimes\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\right\\|_{2}+\\frac{2\\mu_{2}}{g^{2}-g}\\left\\|\\bar{\\mathbf{C}}\\right\\|_{2}}\\\\ &{\\leq\\ \\frac{1}{\\epsilon^{2}}+\\frac{2\\mu_{2}}{g^{2}-g}\\lambda_{\\operatorname*{max}}(\\bar{\\mathbf{C}})=\\tilde{L}_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Consequently, the gradient $\\nabla_{\\Theta}f(\\Theta)$ is Lipschitz with constants $L_{1}\\leq\\tilde{L}_{1}$ . ", "page_idx": 20}, {"type": "text", "text": "E.2 Proof of Lemma 3 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "For the node-based DP gap $H_{\\mathrm{node}}(\\Theta)$ as in (3), applying standard gradient calculus to compute the gradient and the Hessian of $f(\\Theta)$ gives ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\Theta}f(\\Theta)=\\hat{\\Sigma}-\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}+2\\mu_{2}[\\mathbf{A}\\Theta_{\\bar{\\mathcal{D}}}]_{\\bar{\\mathcal{D}}},}\\\\ &{\\nabla_{\\Theta}^{2}f(\\Theta)=\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\otimes\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}+2\\mu_{2}\\left(\\mathbf{I}\\otimes\\mathbf{A}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then, the Lipschitz constant is obtained from the following upper bound of the Hessian ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\|\\nabla_{\\Theta}^{2}f(\\Theta)\\|_{2}\\le\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\otimes\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\|_{2}+2\\mu_{2}\\|\\mathbf{I}\\otimes\\mathbf{A}\\|_{2}\\le\\frac{1}{\\epsilon^{2}}+2\\mu_{2}\\lambda_{\\mathrm{max}}(A)=L_{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "F Proof of Theorem 2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Our proof builds over the convergence result for FISTA [34, Thm. 4.4], which establishes that the sequence $\\{\\Theta^{(k)}\\}_{k\\geq1}$ generated by FISTA satisfies the following bound ", "page_idx": 21}, {"type": "equation", "text": "$$\nF(\\Theta^{(k)})-F(\\Theta^{*})\\leq\\frac{2L\\|\\Theta^{(0)}-\\Theta^{*}\\|_{F}^{2}}{(k+1)^{2}},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\Theta^{*}$ is the global minimum of the objective function of (4). This result requires $f(\\Theta)$ , the smooth components of $F(\\Theta)$ , to be a convex function with Lipschitz continuous gradient, while $h(\\Theta)$ , the non-smooth components of $F(\\Theta)$ , are only required to be convex. ", "page_idx": 21}, {"type": "text", "text": "From the expression of $f(\\Theta)$ and $h(\\Theta)$ in (10) it is clear that both terms of our objective function are convex. Furthermore, from Lemma 2 and Lemma 3 it follows that the gradient of $f(\\Theta)$ is Lipschitz continuous when we consider $R_{H}=H$ or $R_{H}=H_{\\mathrm{node}}$ , so the conditions from [34, Thm. 4.4] are met and (65) holds. ", "page_idx": 21}, {"type": "text", "text": "Next, we demonstrate that the objective function $F(\\Theta)$ is strongly convex. A function $F(\\Theta)$ is $\\sigma$ -strongly convex if $F(\\Theta)-\\sigma\\|\\bar{\\Theta_{\\mathrm{\\scriptsize~()F}}}\\|_{F}^{2}$ is also convex, which implies that $\\nabla_{\\Theta}^{2}F(\\Theta)-\\sigma\\mathbf{I}\\succeq\\mathbf{0}$ . Put in words, the eigenvalues of the Hessian need to be larger than $\\sigma$ for $F(\\Theta)$ to be $\\sigma$ -strongly convex. Let $f_{1}(\\Theta)=\\mathrm{tr}(\\hat{\\Sigma}\\Theta)-\\mathrm{log}\\,\\mathrm{det}(\\Theta+\\epsilon{\\bf I})$ , whose Hessian is given by ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\nabla_{\\Theta}^{2}f_{1}(\\Theta)=\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}\\otimes\\left(\\Theta+\\epsilon\\mathbf{I}\\right)^{-1}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since $\\Theta$ is constrained by $\\|\\Theta\\|_{2}^{2}\\leq\\alpha$ , applying the properties of the inverse and the Kronecker product renders the following bound on the eigenvalues of $\\nabla_{\\Theta}f_{1}(\\Theta)$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\lambda_{\\operatorname*{min}}\\left(\\nabla_{\\Theta}^{2}f_{1}(\\Theta)\\right)=\\frac{1}{\\lambda_{\\operatorname*{max}}^{2}(\\Theta+\\epsilon\\mathbf{I})}\\approx\\frac{1}{\\lambda_{\\operatorname*{max}}^{2}(\\Theta)}=\\frac{1}{\\alpha}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Recall that $\\epsilon$ is assumed to be a small parameter such that $\\epsilon^{2}\\;\\ll\\;\\lambda_{\\mathrm{max}}^{2}(\\Theta)$ . Consequently, $\\nabla_{\\Theta}^{2}f_{1}(\\Theta)\\succeq\\frac{1}{\\alpha}\\mathbf{I}$ , so $f_{1}(\\Theta)$ is strongly convex with constant $\\frac{1}{\\alpha}$ , hence rendering $F(\\Theta)$ also strongly convex with the same constant. ", "page_idx": 21}, {"type": "text", "text": "The last ingredient is given by [68, Thm. 5.25], which establishes that if $F(\\Theta)$ is strongly convex with constant $\\sigma$ , then ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\|\\Theta-\\Theta^{*}\\|_{F}^{2}\\leq\\frac{2}{\\sigma}\\left(F(\\Theta)-F(\\Theta^{*})\\right),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for every $\\Theta$ in the domain of $F$ ", "page_idx": 21}, {"type": "text", "text": "Finally, our result follows from combining (65) and (68). ", "page_idx": 21}, {"type": "text", "text": "G Experimental Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The following details include descriptions of our datasets, baselines, and performance metrics. For synthetic experiments, we run simulations over 50 independent realizations of generated data. Moreover, excepting experiments for which we test different specific parameter values, we choose optimal values of hyperparameters via grid search. ", "page_idx": 21}, {"type": "text", "text": "Datasets. The numerical evaluation of the proposed algorithm is carried out over synthetic and real-world data. The main features of the different datasets are summarized in Table 3. Additional details are given next. ", "page_idx": 21}, {"type": "table", "img_path": "a3cauWMXNV/tmp/4adf806a7008a13db435507214553d1bcecef3a270203e2023fc2a73b59c2f78.jpg", "table_caption": ["Table 3: Properties of the real datasets used in Section 4. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "\u2022 Synthetic data. Unless specified otherwise, graphs with $p=100$ nodes are sampled from an Erd\u02ddos-R\u00e9nyi (ER) random graph model with an average of 10 links per node. The precision matrix is set to either the combinatorial graph Laplacian [33] or an adjacency matrix with a loaded diagonal to ensure positive definiteness, and is employed to sample graph signals from a zero-mean multivariate Gaussian distribution. The number of sampled signals satisfies the conditions of Theorem 1. For experiments based on synthetic data, 50 independent realizations of graphs and signals are generated and we report the mean performance. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Karate club. A social network where the 34 nodes represent members from a karate club and edges capture interactions between pairs of members outside the club [22, 23]. This dataset is famously modular with respect to groups, serving as a well-known biased network of real-world individuals. Since this graph does not have associated nodal observations, we generate signals as multivariate Gaussian samples as described in the previous point for synthetic data using the adjacency matrix of the social network with a loaded diagonal as the precision matrix. Similarly, we evaluate experiments with this synthetic data over 50 independent realizations of generated signals with the mean performance reported. ", "page_idx": 22}, {"type": "text", "text": "\u2022 MovieLens1. This movie-recommendation dataset contains ratings for 1,682 movies by 943 users, resulting in sparse data as many movies have few ratings. Biases in recommendation systems can reproduce and even exacerbate existing harmful stereotypes [69]. The MovieLens dataset, a common benchmark for fair graph machine learning, exemplifies our ability to form unbiased models from networks used for recommendation systems. To address this sparsity, we followed the setup in [17] and selected the 200 most-rated movies as nodes, using the ratings from the 943 users as graph signals. Since the dataset lacks a ground truth graph, we report the model fti as defined in Corollary 1 rather than the error in Table 2. The sensitive attribute for each node is determined by whether the movie was released before or after 1991. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Co-authorship2.The dataset includes papers from the ACM conference, featuring 17,431 authors, 122,499 papers, and 1,903 keywords. The nodes represent a subset of these authors. The sensitive attribute associated with each author is determined by the conference type in which that author publishes the most. We demonstrate an example of data with more than two groups through the Co-authorship network with publication type as the sensitive attribute. To create the ground truth graph, we analyzed author-paper relationships and established an edge between two authors if they collaborated on a paper. For graph data generation, we utilized the total number of different keywords, with each input graph signal reflecting the frequency with which a specific author uses a particular keyword across their papers. We constructed the graph by selecting a connected subset of the authors. The associated graph signals were then used to estimate the graph through the considered methods. ", "page_idx": 22}, {"type": "text", "text": "\u2022 School3. The dataset contains the temporal network of contacts between students in a high school in Marseilles, France. In real-world social network analysis, common network characteristics such as homophily can lead to negative outcomes across gender in both social and academic settings [70]. Hence, both the School network and the Friendship network described below require scrutiny with respect to fairness, where gender is a critical consideration. The data includes the interactions of students from three classes over four days in December 2011. We used the available contact data to construct a ground truth graph, where nodes represent students and edges represent all interactions between them. We ", "page_idx": 22}, {"type": "image", "img_path": "a3cauWMXNV/tmp/c4589e0f0144a3e71bfa66a524bbf64966d800aeba41f410a7f42f7532d6e558.jpg", "img_caption": ["Figure 4: Performance in terms of error and bias for estimating a fair precision matrix. (a) Error as parameters $\\mu_{1}$ and $\\mu_{2}$ vary. (b) Bias as parameters $\\mu_{1}$ and $\\mu_{2}$ vary. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "generated the signals by grouping the interactions into sets of four. Gender was considered as sensitive attribute for each node. \u2022 Friendship4. This dataset corresponds to the contacts and friendship relations between students in nine classes at a high school in Marseilles, France, over five days in December 2013. Following the same procedure as with the School dataset, we used the available contact data to generate the ground truth graph, where nodes represent students and edges represent all interactions between them. The graph signals were generated by grouping the interactions into sets of four, and gender was considered the sensitive attribute. ", "page_idx": 23}, {"type": "text", "text": "Baselines. We compare the performance of our proposed Fair GLASSO approach with the following baselines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 GL: The celebrated graphical lasso algorithm from [26] constitutes a workhorse alternative to estimate the topology of the graph encoded in precision matrices. However, it ignores the sensitive attributes of the nodes, so it is prone to include biases existing in the true graph.   \n\u2022 RWGL: a naive fair alternative to graphical lasso where several edges are randomly rewired after estimating the precision matrix with GL. Since the rewiring process is independent of the sensitive attributes of nodes, it will render a fairer estimate, but the random perturbation may yield highly inaccurate estimates. Methods denoted \u201cRWGL-N\u201d for some positive integer $N$ represents RWGL with $N$ edges rewired.   \n\u2022 FST: a fair alternative for learning the graph from stationary observations while mitigating biases in the topology via a group-wise bias penalty [18, 36]. Different from graphical lasso, stationary methods assume that the covariance of the observed data is a polynomial of a matrix encoding the graph topology. This more lenient assumption typically comes at the expense of requiring a larger number of observations.   \n\u2022 NFST: a variant of FST that estimates the graph topology from stationary observations including a node-wise regularization to promote fairness [15, 18]. ", "page_idx": 23}, {"type": "text", "text": "Moreover, note that the notation \u201cFGL- $\\mathbf{.X}^{\\bullet}$ for some number $\\mathbf{X}$ denotes FGL with $\\mu_{2}=\\mathbf{X}$ , and this similarly holds for \u201cNFGL-X\u201d. ", "page_idx": 23}, {"type": "text", "text": "Performance metrics. To measure the error of our estimated precision matrices $\\Theta^{*}$ , we apply the following normalized squared Frobenius error ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\left\\|\\frac{[\\Theta^{*}]_{\\bar{\\mathcal{D}}}}{\\|[\\Theta^{*}]_{\\bar{\\mathcal{D}}}\\|_{F}}-\\frac{[\\Theta_{0}]_{\\bar{\\mathcal{D}}}}{\\|[\\Theta_{0}]_{\\bar{\\mathcal{D}}}\\|_{F}}\\right\\|_{F}^{2}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "for true precision matrix $\\mathbf{{\\Theta}}_{0}$ . When such a true matrix $\\Theta_{0}$ is unavailable, we instead apply the lefthand side of (8) from Corollary 1 using the sample covariance matrix $\\hat{\\Sigma}$ estimated from observations. To measure the bias in a given precision matrix $\\Theta^{*}$ for nodal group memberships $\\mathbf{Z}$ , observe that $H$ and $H_{\\mathrm{node}}$ compute average differences in edge weights within and across groups, whether group-wise or node-wise. Thus, for our practical bias metric we normalize by edge weight to obtain ", "page_idx": 23}, {"type": "image", "img_path": "a3cauWMXNV/tmp/1885bc84bfbaf355dd9953dbcbe0114be9f3dabc1617f842688fd8a8205411b9.jpg", "img_caption": ["Figure 5: Performance in terms of error and bias for estimating an unfair precision matrix. (a) Error as parameters $\\mu_{1}$ and $\\mu_{2}$ vary. (b) Bias as parameters $\\mu_{1}$ and $\\mu_{2}$ vary. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{2\\sqrt{H(\\pmb\\Theta^{*})}}{\\|[\\pmb\\Theta^{*}]_{\\mathcal{\\Bar{D}}}\\|_{1}},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "that is, we take the square root of $H(\\Theta)$ , which acts as a squared $\\ell_{2}$ norm across distinct group pairs, and we divide by the average edge weight for unordered variable pairs. ", "page_idx": 24}, {"type": "text", "text": "The group-wise modularity presented in Figure 1 is defined in [19], that is, ", "page_idx": 24}, {"type": "equation", "text": "$$\nQ(\\Theta)=\\sum_{a=1}^{g}\\frac{\\mathbf{z}_{a}^{\\top}\\Theta_{\\bar{\\mathcal{D}}}\\mathbf{z}_{a}}{2s}-\\sum_{a=1}^{g}\\left(\\frac{\\mathbf{z}_{a}^{\\top}\\Theta_{\\bar{\\mathcal{D}}}\\mathbf{z}_{a}}{2s}\\right)^{2},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $s$ denotes the number of nonzero entries in $\\Theta$ . To estimate partial correlation in Figure 1, we apply graphical lasso without a bias penalty, and entries of the resultant precision matrix denote estimates of partial correlation for every pair of variables. ", "page_idx": 24}, {"type": "text", "text": "Hardware details. The experiments are run on a computer with AMD Ryzen Threadripper 3970X 32-Core Processor, two Nvidia Titan RTX GPU, and 188GB of RAM. ", "page_idx": 24}, {"type": "text", "text": "H Additional Experiments ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we provide additional simulations to demonstrate Fair GLASSO behavior under hyperparameter tuning and violation of assumptions. Figures 4 and 5 of the attached document present Fair GLASSO performance as hyperparameters $\\mu_{1}$ and $\\mu_{2}$ vary when estimating a fair or unfair precision matrix, respectively. Observe that when the true precision matrix is unfair, increasing $\\mu_{2}$ encourages a fairer estimate and thus increases the error. Moreover, smaller values of $\\mu_{2}$ yield greater bias for the unfair setting in Figure 2 than the fair setting in Figure 4. While a larger $\\mu_{2}$ decreases the bias in both settings, the effect is greater in Figure 5 for a true precision matrix that is unfair. ", "page_idx": 24}, {"type": "text", "text": "Moreover, we provide additional simulations in Figure 6 where the precision matrix varies in sparsity (AS1), the true precision matrix is rank-deficient (AS2), and the group sizes vary (AS4). Figure 6a shows the classical graphical lasso result, where as the precision matrix grows denser, estimation error suffers, particularly when the sparsity penalty weight $\\mu_{1}$ is larger. In Figure 6b, we demonstrate the effects of rankness on estimation performance. Indeed, the use of $\\epsilon>0$ permits low-rank estimates, and we observe relatively robust estimation error for different values of $\\epsilon$ . Finally, Figure 6c shows that as the ratio between two groups becomes small, that is, the precision matrix becomes unfair due to imbalanced groups, error increases, particularly for larger $\\mu_{2}$ . ", "page_idx": 24}, {"type": "text", "text": "I Limitations and Future Work ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "This work focuses on group fairness via minimizing DP gap for Gaussian graphical models. While our proposed definition of DP for graphical models does not require Gaussianity, the theoretical results and optimization algorithm require assuming both Gaussian random variables and use of our proposed metrics. Interesting and critical extensions of this work include more general graphical models and other ideas of fairness. Consider for instance the following adaptation of equalized odds (EO) [21], ", "page_idx": 24}, {"type": "image", "img_path": "a3cauWMXNV/tmp/949ee32bba1dce79091d8886a8c486bb4ed96299763635df790996b8b7825cd9.jpg", "img_caption": ["Figure 6: Performance in terms of the Frobenius error as different assumptions are violated. (a) Error as true precision matrix becomes denser. (b) Error as eigenvalues of true precision matrix grow close to 0. (c) Error as group sizes become increasingly imbalanced. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\Theta_{i j}^{*}\\mid[\\Theta_{0}]_{i j},Z_{i a}=1,Z_{j a}=1\\right]=\\mathbb{P}\\left[\\Theta_{i j}^{*}\\mid[\\Theta_{0}]_{i j},Z_{i a}=1,Z_{j b}=1\\right]\\,\\forall a,b\\in[g],\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\Theta^{*}$ denotes an estimate of the true precision $\\mathbf{{\\Theta}}_{0}$ , and $\\mathbf{Z}$ is the group membership indicator matrix. The comparison of fairness metrics for graphs warrants separate investigation since many fairness metrics in machine learning have not yet been adapted to the graph setting. Such an analysis of fairness metrics ought to be applied to tasks beyond graph learning and is thus out of scope of this paper. Moreover, while we considered discrete sensitive attributes, we also aim to promote equitable treatment for continuous sensitive traits. ", "page_idx": 25}, {"type": "text", "text": "Regarding the implementation of Fair GLASSO, Algoritm 1 can handle any function where the smooth and non-smooth components are separable. In principle, this includes non-convex functions, but the convergence result in Theorem 2 requires the smooth components to be strongly convex. Weaker results exist for convex functions [34], but no convergence guarantees are available for non-convex functions. In addition, Section 4.2 demonstrates the estimation of graphs with up to 1000 nodes. However, the computational complexity scales more than linearly with the number of optimization variables, rendering our approach potentially unsuitable for graphs with millions of nodes. Nonetheless, existing works can efficiently estimate very large graphical models, potentially under additional assumptions [71\u201373]. We can combine these approaches with our proposed fairness metrics, although we may lose our guarantee of convergence in Theorem 2. ", "page_idx": 25}, {"type": "text", "text": "Additional future directions include consideration of more general families of graphs. While we consider the underexplored case of signed, weighted graphs for fairness, our work is specific to graphical models encoding conditional dependence. We aim to consider more general interpretations of graphs with real-valued edges, including the novel extension to directed graphs. ", "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The abstract and introduction claim that we make two contributions: we define fairness for graphical models, and we propose fair GGM estimation using proposed bias metrics. The former is provided in Section 2 and the latter in Section 3. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: In Appendix I, we detail limitations of our approach based on the explicit assumptions made in the paper. Additionally, for future work we refer to the broader context of fairness and graphs to point out areas outside the scope of this work. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Each theorem and derivation both in the body of the paper and in the appendix include the required assumptions and a reference to its associated proof in the appendix. In particular, Theorem 1 and Corollary 1 in Section 3.2 have proofs in Appendices B and C, respectively, while Theorem 2 in Section 3.3 is proven in Appendix F. The reference for Lemma 1 is provided for its associated details and proof [67], while Lemmas 2 and 3 and their associated proofs are provided in Appendices D and E, respectively. The formal assumptions AS1 to AS4 that are needed for Theorem 1 and Corollary 1 are stated immediately preceding the theoretical results, while the remaining theoretical results have simpler assumptions provided in the statement of the result. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: The body of the paper includes a brief description of our experimental settings in Section 4, and an in-detail description is included in Appendix G. Moreover, the code, which is included in the submission for completeness, will be made available on GitHub if the draft is accepted. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 27}, {"type": "text", "text": "5. Open access to data and code ", "page_idx": 27}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: In the supplementary material we provide the code for the experiments shown in this paper. We also share links to all publicly availably datasets in Appendix G. The remaining datasets are synthetic, and detailed descriptions of how they are generated are provided in Appendix G. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: Hyperparameters for optimization methods are either chosen to showcase specific scenarios as in Sections 4.2 and 4.4 or chosen via classical hyperparameter tuning methods as stated in Appendix G. Remaining experimental details are in Appendix G. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: Our experiments in Section 4 consist of synthetic observations in Sections 4.1, 4.2, and 4.3. The results of the synthetic simulations are averaged over 50 trials; however, we observed low variance in the measured performances across 50 independent realizations, thus we do not provide error bars. The experiments in Section 4.4 apply real networks, and we use all available signals, so variance cannot be measured, thus we again need not provide statistical significance test for these results. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: We provide at the end of Appendix G a summary of the compute resources used for the experiments.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: While simulations in Section 4 involve information of individuals via social network analysis, these datasets are anonymized. The datasets, listed in detail in Appendix G, are publicly available, and we do not provide any new data in this work that might be at risk of harmful consequences. Moreover, rather than being at risk of unsafe usage, our method is designed to promote improvement in societal outcomes.   \nGuidelines: ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative   \nsocietal impacts of the work performed?   \nAnswer: [Yes] Justification: Following Section 5, we provide a discussion on the broader impacts of this work, which aims for improved societal outcomes.   \nGuidelines: ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. \u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations ", "page_idx": 29}, {"type": "text", "text": "(e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Justification: We do not provide data or models with high risk of misuse. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: All methods in Section 4 with which we compare include the reference to the original paper. Moreover, all real-world datasets used are publicly available and referenced appropriately, and links to these are provided in Appendix G. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The code for both our method and our experiment from Section 4 are provided in the supplementary material. If this manuscript is accepted, we will release the code on GitHub for public use. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "ustification: We do not perform research using human subjects or involving crowdsourcing. Guidelines: \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: We do not perform research using human subjects or involving crowdsourcing. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 31}]