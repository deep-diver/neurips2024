[{"figure_path": "KHcB1drMRX/figures/figures_1_1.jpg", "caption": "Figure 1: Chain-of-Sight concept overview. Recent current MLLMs maintain a constant set of visual tokens in both pre-training and fine-tuning. These tokens typically represent visual contents at a single visual scale. In contrast, our Chain-of-Sight approach leverages the idea of visual hierarchy, producing multi-scale visual tokens. Moreover, the token scaling strategy enabled by our multi-scale visual resamplers allow us to start with a small pool of visual tokens for pre-training, before increasing the number of tokens during fine-tuning. This considerably accelerates the pre-training phase.", "description": "This figure illustrates the core concept of Chain-of-Sight.  Existing Multimodal Large Language Models (MLLMs) use a fixed number of visual tokens during both pre-training and fine-tuning. Chain-of-Sight, in contrast, employs a multi-scale approach. It starts with fewer visual tokens in the pre-training phase, capturing visual information at multiple scales. Then, a token scaling strategy increases the number of tokens for the fine-tuning stage. This approach significantly reduces pre-training time (by ~73% as indicated in the figure) without compromising performance.", "section": "1 Introduction"}, {"figure_path": "KHcB1drMRX/figures/figures_2_1.jpg", "caption": "Figure 2: The Chain-of-Sight framework. Through partitioning visual features into windows and restricting cross-attention to the windowed features associated with the learnable tokens, our Chain-of-Sight approach produces visual tokens that encompass multiple scales. Thanks to the post-pretrain token scaling strategy, Chain-of-Sight reduces the required number of visual tokens in pre-training, thus accelerating the process. In contrast, the number of visual tokens remains constant in resampler-based methods [44, 2, 4, 99] for pre-training and fine-tuning, and the linear-layer [56, 63, 97, 15] produce a large number of visual tokens, incurring a high cost for pre-training.", "description": "This figure illustrates the Chain-of-Sight framework, comparing it to existing methods.  Existing methods use either resamplers or linear layers to generate visual tokens, maintaining a constant number throughout training. In contrast, Chain-of-Sight partitions visual features into windows of various sizes, creating multi-scale visual tokens.  The post-pretrain token scaling allows for a reduction in visual tokens during pre-training, accelerating the process without sacrificing performance in fine-tuning. The figure shows the process for both pre-training and fine-tuning phases.", "section": "2.2 Multi-scale visual resamplers"}, {"figure_path": "KHcB1drMRX/figures/figures_3_1.jpg", "caption": "Figure 3: Detailed illustration of our post-pretrain token scaling strategy.", "description": "This figure illustrates the Chain-of-Sight's post-pretrain token scaling strategy. It shows how the number of visual tokens can be increased after the pre-training phase using a combination of resolution scaling and window scaling.  The leftmost panel shows the initial visual tokens used during pre-training. The next panel shows how increasing the number of windows within a given resolution increases token numbers (window scaling). The third panel shows how using higher resolution images increases token numbers (resolution scaling). Finally, the rightmost panel combines resolution and window scaling to achieve a significant increase in the number of visual tokens used during fine-tuning, which allows Chain-of-Sight to achieve high performance while significantly reducing the number of tokens needed during the computationally expensive pre-training phase.", "section": "2.3 Post-pretrain token scaling strategy"}, {"figure_path": "KHcB1drMRX/figures/figures_4_1.jpg", "caption": "Figure 4: Pre-train acceleration by Chain-of-Sight, in comparison with standard resamplers. The average performance is computed over the reported benchmarks in Table 2. Our method achieves a pre-train acceleration of 73% without compromising performance.", "description": "This figure shows the pre-training time and average performance comparison between Chain-of-Sight and standard resamplers.  The x-axis represents the different model configurations with varying numbers of visual tokens used during pre-training (PT) and fine-tuning (SFT). The y-axis shows the average performance across multiple benchmarks. Chain-of-Sight achieves a 73% reduction in pre-training time while maintaining comparable or even slightly better performance compared to standard resamplers.", "section": "3.2 Ablations"}, {"figure_path": "KHcB1drMRX/figures/figures_15_1.jpg", "caption": "Figure 2: The Chain-of-Sight framework. Through partitioning visual features into windows and restricting cross-attention to the windowed features associated with the learnable tokens, our Chain-of-Sight approach produces visual tokens that encompass multiple scales. Thanks to the post-pretrain token scaling strategy, Chain-of-Sight reduces the required number of visual tokens in pre-training, thus accelerating the process. In contrast, the number of visual tokens remains constant in resampler-based methods [44, 2, 4, 99] for pre-training and fine-tuning, and the linear-layer [56, 63, 97, 15] produce a large number of visual tokens, incurring a high cost for pre-training.", "description": "This figure illustrates the Chain-of-Sight framework, comparing it to existing methods.  It shows how Chain-of-Sight partitions visual features into windows, uses windowed cross-attention with learnable tokens to generate multi-scale visual tokens, and leverages a post-pretrain token scaling strategy to reduce the number of visual tokens needed during pre-training, thereby accelerating the process.  The figure highlights the differences in visual token handling between Chain-of-Sight and existing methods (resampler-based and linear-layer approaches), emphasizing the efficiency gains achieved by Chain-of-Sight.", "section": "2.2 Multi-scale visual resamplers"}]