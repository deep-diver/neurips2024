[{"type": "text", "text": "On the Necessity of Collaboration for Online Model Selection with Decentralized Data ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Junfan Lil ZheshunWul Zenglin $\\mathbf{Xu}^{2,3,4*}$ Irwin King5 ", "page_idx": 0}, {"type": "text", "text": "1School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen 2Pengcheng Lab 3 Artificial Intelligence Inovation and Incubation $(\\mathrm{AI^{3}})$ Institute, Fudan University 4Shanghai Academy of AI for Science   \n5Department of Computer Science and Engineering, The Chinese University of Hong Kong lijunfan@hit.edu.cn wuzhsh23@gmail.com zenglin@gmail.com king@cse.cuhk.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider online model selection with decentralized data over $M$ clients,and study the necessity of collaboration among clients. Previous work proposed various federated algorithms without demonstrating their necessity, while we answer the question from a novel perspective of computational constraints. We prove lower bounds on the regret, and propose a federated algorithm and analyze the upper bound. Our results show (i) collaboration is unnecessary in the absence of computational constraints on clients; (i) collaboration is necessary if the computational cost on each client is limited to $o(K)$ ,where $K$ is the number of candidate hypothesis spaces. We clarify the unnecessary nature of collaboration in previous federated algorithms for distributed online multi-kernel learning, and improve the regret bounds at a smaller computational and communication cost. Our algorithm relies on three new techniques including an improved Bernstein's inequality for martingale, a federated online mirror descent framework, and decoupling model selection and prediction, which might be of independent interest. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Model selection which is a fundamental problem for offline machine learning focuses on how to select a suitable hypothesis space for a machine learning algorithm [Mitchell, 1997, Bartlett et al., 2002, Mohri et al., 2018]. Model selection for online machine learning is called online model selection (OMS), such as model selection for online supervised learning [Foster et al., 2017, Zhang and Liao, 2018, Zhang et al., 2021, Li and Liao, 2022], model selection for online active learning [Karimi et al., 2021], and model selection for contextual bandits [Foster et al., 2019, Pacchiano et al., 2020, Ghosh and Chowdhury, 2022]. We consider model selection for online supervised learning. Let $\\mathcal{F}=\\{\\mathcal{F}_{1},\\ldots,\\mathcal{F}_{K}\\}$ contain $K$ hypothesis spaces and $\\ell(\\cdot,\\cdot)$ be a loss function. For a sequence of examples $\\{(\\mathbf{x}_{t},y_{t})\\}_{t=1,\\dots,T}$ , we aim to adapt to the case that the optimal hypothesis space $\\mathcal{F}_{i^{*}}\\in\\mathcal{F}$ is given by an oracle and we run an online learning algorithm in $\\mathcal{F}_{i^{*}}$ . OMS can be defined by minimizing the regret, i.e., ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{f_{1},\\ldots,f_{T}}\\left(\\sum_{t=1}^{T}\\ell(f_{t}(\\mathbf{x}_{t}),y_{t})-\\operatorname*{min}_{f\\in\\mathcal{F}_{i^{\\ast}}}\\sum_{t=1}^{T}\\ell(f(\\mathbf{x}_{t}),y_{t})\\right),\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $f_{t}\\in\\cup_{i=1}^{K}\\mathcal{F}_{i}$ is the hypothesis used by an OMS algorithm at the $t$ -th round. The optimal value of the regret depends on the complexity of $\\mathcal{F}_{i^{*}}$ [Foster et al., 2017, 2019]. ", "page_idx": 1}, {"type": "text", "text": "In this work, we consider online model selection with decentralized data (OMS-DecD) over $M$ clients, in which each client observes a sequence of examples $\\left\\{\\left(\\mathbf{x}_{t}^{(j)},y_{t}^{(j)}\\right)\\right\\}_{t=1,\\ldots,T},j=1,\\ldots,M,$ and but does not share personalized data with others. There is a central server that coordinates the clients by sharing personalized models or gradients [Konecny et al., 2016, Kairouz et al., 2021, Zeng et al., 2023a,b]. OMS-DecD captures some real-world applications where the data may be collected bysensors on $M$ different remote devices or mobile phones [Li et al., 2020, Patel et al., 2023, Kwon et al., 2023], or a local device can not store all of data due to low storage and thus it is necessary to store the data on more local devices [Slavakis et al., 2014, Bouboulis et al., 2018]. OMS-DecD can be defined by minimizing the following regret, ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{f_{t}^{(j)},t=1,\\dots,T,j=1,\\dots,M}\\left(\\sum_{j=1}^{M}\\sum_{t=1}^{T}\\ell\\left(f_{t}^{(j)}\\left(\\mathbf{x}_{t}^{(j)}\\right),y_{t}^{(j)}\\right)-\\operatorname*{min}_{f\\in\\mathcal{F}_{i^{*}}}\\sum_{j=1}^{M}\\sum_{t=1}^{T}\\ell\\left(f\\left(\\mathbf{x}_{t}^{(j)}\\right),y_{t}^{(j)}\\right)\\right),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Where $f_{t}^{(j)}\\in\\cup_{i=1}^{K}\\mathcal{F}_{i}$ is the hypothesis adopted by the $j$ th clientathe $t^{\\th}$ thround. Solving OMSDecD must achieve two goals: G1 minimizing the regret, and G2 providing privacy protection. ", "page_idx": 1}, {"type": "text", "text": "A trivial approach is to use a noncooperative algorithm that independently runs a copy of an OMS algorithm on the $M$ clients. It naturally provides strong privacy protection, that is, it achieves G2, but suffers a regret bound that increases linearly with $M$ . It is unknown whether it achieves G1. Another approach is federated learning which is a framework of cooperative learning with privacy protection and is provably effective in stochastic convex optimization [McMahan et al., 2017, Woodworth et al., 2020b, Wang et al., 2021, Reddi et al., 2021]. It is natural to ask: ", "page_idx": 1}, {"type": "text", "text": "Question 1. Whether collaboration is effective for OMS-DecD ", "page_idx": 1}, {"type": "text", "text": "The question reveals the hardness of OMS-DecD and is helpful to understand the limitations of federated learning. Previous work studied a special instance of OMS-DecD called distributed online multi-kernel learning (OMKL) where ${\\mathcal{F}}_{i}$ is a reproducing kernel Hilbert space (RKHS), and proposed three federated OMKL algorithms including vM-KOFL, eM-KOFL [Hong and Chae, 2022] and POF-MKL [Ghari and Shen, 2022]. The three algorithms also suffer regret bounds that increase linearly with $M$ , and thus can not answer the question. If $K=1$ , then OMS-DecD is equivalent to distributed online learning [Mitra et al., 2021, Kwon et al., 2023, Patel et al., 2023]. A noncooperative algorithm that independently runs online gradient descent (OGD) on each client achieves the two goals simultaneously [Patel et al., 2023]. Collaboration is unnecessary in the case of $K=1$ ", "page_idx": 1}, {"type": "text", "text": "In summary, previous work can not answer the question well. On one hand, previous work can not answer the question in the case of $K>1$ . On the other hand, in the case of $K=1$ ,previouswork has answered the question only using the statistical property of algorithms, i.e., the worst-case regret, but omitted the computational property which is very important for real-world applications. ", "page_idx": 1}, {"type": "text", "text": "1.1 Main Results ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this paper, we will answer the question from a new perspective of computational constraints on the problem (Section 5.5). Our main results are as follows. ", "page_idx": 1}, {"type": "text", "text": "(1) An upper bound on the regret. We propose a federated algorithm, FOMD-OMS, and prove an upper bound on the regret (Theorem 2). Besides, if $\\mathcal{F}_{1},...,\\mathcal{F}_{K}$ are RKHSs, then our algorithm improves the regret bounds of FOP-MKL [Ghari and Shen, 2022] and eM-KOFL [Hong and Chae, 2022] at a smaller computational and communication cost. Table 1 summarizes the results.   \n(2) Lower bounds on the regret. We separately prove a lower bound on the regret of any (possibly cooperative) algorithm and any noncooperative algorithm (Theorem 3).   \n(3) A new perspective of computational constraints for Question 1. By the upper bound and lower bounds, we conclude that (i) collaboration is unnecessary when there are no computational constraints on clients, thereby generalizing the result for distributed online learning, i.e., $K=1$ (ii) collaboration is necessary if the computational cost on each client is limited to $o(K)$ where irrelevant parameters are omitted. Our results clarify the unnecessary nature of collaboration in previous federated algorithms for distributed OMKL. ", "page_idx": 1}, {"type": "text", "text": "1.2  Technical Challenges ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "There are two main technical challenges on designing a federated online model selection algorithm. ", "page_idx": 2}, {"type": "text", "text": "The first challenge lies in obtaining high-probability regret bounds that adapt to the complexity of individual hypothesis space, a fundamental problem in online model selection [Foster et al., 2017]. While acquiring expected regret bounds that adapt to the complexity of individual hypothesis spaces is straightforward, the crux is to derive high-probability bounds from expected bounds. To this end, we introduce a new Bernstein's inequality for martingale (Lemma 1), which might be of independent interest. ", "page_idx": 2}, {"type": "text", "text": "The second challenge involves achieving a per-round communication cost of $o(K)$ .To tackle this challenge, we propose two techniques: (i) decoupling model selection and prediction; (i) an algorithmic framework, named FOMD-No-LU, which might be of independent interest. Specifically, when clients execute model selection, server must broadcast an aggregated probability distribution, denoted by $\\mathbf{p}\\in\\mathbb{R}^{K}$ , to clients, naturally incurring a $O(K)$ download cost. Our algorithm conducts model selection on server and makes predictions on clients, thereby eliminating the need to broadcast the aggregated probability distribution to clients. Additionally, if we use the local updating approach [Mitra et al., 2021, Patel et al., 2023], then server must broadcast $K$ aggregated models to clients, also resulting in a $O(K)$ download cost [Ghari and Shen, 2022]. By utilizing FOMD-No-LU, our algorithm only broadcasts the selected models to clients and can achieve a $o(K)$ download cost. ", "page_idx": 2}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Previous work has studied the necessity of collaboration for distributed bandit convex optimization [Patel et al., 2023], where a federated algorithmic framework named FEDPOSGD was proposed. Although the regret bounds of FEDPOSGD are smaller than some noncooperative algorithms, there is not a lower bound on the regret of any noncooperative algorithm [Patel et al., 2023]. Moreover, the regret analysis of FEDPOSGD is based on the analysis for federated online gradient descent that is not applicable to our algorithm, FOMD-OMS. The regret analysis of FOMD-OMS requires the analysis for federated online mirror descent with negative entropy regularizer. ", "page_idx": 2}, {"type": "text", "text": "Our work is also different from federated bandits, such as federated $K$ -armed bandits [Wang et al., 2020] and federated linear contextual bandits [Huang et al., 2021]. For OMS-DecD, we do not assume that the examples $(\\mathbf{x}_{t}^{(j)},y_{t}^{(j)})$ \uff0c $t=1,\\dots,T$ on each client are independent and identically distributed (i.i.d.). In contrast, in both federated $K$ -armed bandits or federated linear contextual bandits, the rewards must be i.i.d., thereby making collaboration effective. This is similar to the approach used in federated stochastic optimization. However, this may not hold true for OMS-DedD. Therefore, it is a distinctive problem for OMS-DecD to study whether collaboration is effective. ", "page_idx": 2}, {"type": "text", "text": "3 Problem Setting ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Notations Let $\\mathcal{X}=\\left\\{\\mathbf{x}\\in\\mathbb{R}^{d}|\\|\\mathbf{x}\\|_{2}<\\infty\\right\\}$ be an instance space, $\\mathcal{V}=\\{y\\in\\mathbb{R}:|y|<\\infty\\}$ be an output space, and $\\{(\\mathbf{x}_{t},y_{t})\\}_{t\\in[T]}$ be a sequence of examples, where $[T]\\,=\\,\\{1,\\dots,T\\}$ \uff0c $\\mathbf{x}_{t}\\,\\in\\,\\mathcal{X}$ and $y_{t}\\,\\in\\,\\mathcal{V}$ Let $S\\,=\\,\\{s_{1},s_{2},..\\,.\\}$ be a finite set, ${\\mathrm{Uni}}(S)$ be the uniform distribution over the elements in $S$ and $s_{[T]}$ be the abbreviation of the sequence $s_{1},s_{2},\\ldots,s_{T}$ . Denote by $\\mathbb{P}[A]$ the probability that an event $A$ occurs, $a\\wedge b=\\operatorname*{min}\\{a,b\\}$ \uff0c $a\\vee b=\\operatorname*{max}\\{a,b\\}$ and $\\log(a)=\\log_{2}(a)$ Let $\\psi_{t}(\\cdot):\\Omega\\rightarrow\\mathbb{R},t\\in[T]$ be a sequence of time-variant strongly convex regularizers defined on a domain $\\Omega$ . The Bregman divergence denoted by $\\mathcal{D}_{\\psi_{t}}(\\cdot,\\cdot)$ , associated with $\\psi_{t}(\\cdot)$ is defined by ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\forall\\mathbf{u},\\mathbf{v}\\in\\Omega,\\quad\\mathcal{D}_{\\psi_{t}}(\\mathbf{u},\\mathbf{v})=\\psi_{t}(\\mathbf{u})-\\psi_{t}(\\mathbf{v})-\\langle\\nabla\\psi_{t}(\\mathbf{v}),\\mathbf{u}-\\mathbf{v}\\rangle.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "3.1  Online Model Selection (OMS) ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Let $\\mathcal{F}=\\{\\mathcal{F}_{1},...,\\mathcal{F}_{K}\\}$ contain $K$ hypothesis spaces where ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{F}_{i}=\\left\\{f(\\mathbf{x})=\\mathbf{w}^{\\top}\\phi_{i}(\\mathbf{x}):\\phi_{i}(\\mathbf{x})\\in\\mathbb{R}^{d_{i}},\\|\\mathbf{w}\\|_{2}\\leq U_{i}\\right\\}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Let $\\mathcal{F}_{i^{*}}\\in\\mathcal{F}$ be the optimal but unknown hypothesis space for a given $\\{(\\mathbf{x}_{t},y_{t})\\}_{t\\in[T]}$ . OMS can be defined as follows: generating a sequence of hypotheses $f_{[T]}$ that minimizes the following regret, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall i\\in[K],\\quad\\mathrm{Reg}(\\mathcal{F}_{i})=\\sum_{t=1}^{T}\\ell(f_{t}(\\mathbf{x}_{t}),y_{t})-\\operatorname*{min}_{f\\in\\mathcal{F}_{i}}\\sum_{t=1}^{T}\\ell(f(\\mathbf{x}_{t}),y_{t}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $f_{t}\\in\\cup_{i=1}^{K}\\mathcal{F}_{i}$ . The optimal hypothesis space $\\mathcal{F}_{i^{*}}$ must contain a good hypothesis and has a low complexity [Foster et al., 2017, 2019], and is defined by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{F}_{i^{*}}=\\underset{\\mathcal{F}_{i}\\in\\mathcal{F}}{\\arg\\operatorname*{min}}\\left[\\operatorname*{min}_{f\\in\\mathcal{F}_{i}}\\sum_{t=1}^{T}\\ell(f(\\mathbf{x}_{t}),y_{t})+\\Theta\\left(\\sqrt{T\\cdot\\mathfrak{C}_{i}}\\right)\\right],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathfrak{C}_{i}$ measures the complexity of ${\\mathcal{F}}_{i}$ , such as $U_{i}$ and $d_{i}$ ", "page_idx": 3}, {"type": "text", "text": "OMS is more challenge than online learning, since we not only learn the optimal hypothesis space, but also learn the optimal hypothesis in the space. Next we give some examples of OMS. ", "page_idx": 3}, {"type": "text", "text": "Example 1 (Online Hyper-parameters Tuning). Let ${\\mathcal{F}}_{i}$ consist of linear functions of the form ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}_{i}=\\{f(\\mathbf{x})=\\langle\\mathbf{w},\\mathbf{x}\\rangle,\\|\\mathbf{w}\\|_{2}\\leq U_{i}\\}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $U_{i}>0$ is a regularization parameter Let $\\mathcal{U}=\\{U_{i},i\\in[K]:U_{1}<U_{2}<...<U_{K}\\}$ The hypothesis spaces are nested, i.e., ${\\mathcal{F}}_{1}\\subseteq{\\mathcal{F}}_{2}\\subseteq\\ldots\\subseteq{\\mathcal{F}}_{K}$ .The optimal regularization parameter $U_{i^{*}}\\in\\mathcal{U}$ corresponds to the optimal hypothesis space $\\mathcal{F}_{i^{*}}\\in\\mathcal{F}$ ", "page_idx": 3}, {"type": "text", "text": "Example 2 (Online Kernel Selection [Shen et al., 2019, Li and Liao, 2022]). Let $\\kappa_{i}(\\cdot,\\cdot):\\mathbb{R}^{d}\\times\\mathbb{R}^{d}\\rightarrow$ $\\mathbb{R}$ beapositivesemidefnitekenelfunction,and $\\phi_{i}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{d_{i}}$ be the associated feature mapping. ${\\mathcal{F}}_{i}$ is the RKHS associated with $\\kappa_{i}$ ,i.e., ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{F}_{i}=\\left\\{f(\\mathbf{x})=\\left\\langle\\mathbf{w},\\phi_{i}(\\mathbf{x})\\right\\rangle:\\|\\mathbf{w}\\|_{2}\\leq U_{i}\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The optimal kernel function $\\kappa_{i^{*}}\\in\\{\\kappa_{1},\\ldots,\\kappa_{K}\\}$ corresponds to the optimal RKHS $\\mathcal{F}_{i^{*}}\\in\\mathcal{F}$ ", "page_idx": 3}, {"type": "text", "text": "Example 3 (Online Pre-trained Classifier Selection [Karimi et al., 2021]). Generally, ${\\mathcal{F}}_{i}$ canbe $a$ well-trainedmachinelearningmodel.Let $\\mathcal{F}$ contain $K$ pre-trained classifiers.Fora new instance $\\mathbf{x}_{t}$ .we select a (combinational) pre-trained classifier and make a prediction. The selection of $a$ pre-trained classifier has an important implication in practical scenarios. ", "page_idx": 3}, {"type": "text", "text": "3.2  Online Model Selection with Decentralized Data (OMS-DecD) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We formally define OMS-DecD as follows. Assuming that there are $M$ clients and a server. At any round $t$ each client observes an instance $\\mathbf{x}_{t}^{(j)}$ , and selects a hypothesis $f_{t}^{(j)}\\,\\in\\,\\cup_{i=1}^{K}\\mathcal{F}_{i},\\,j\\,\\in\\,[M]$ Then clients output pedictions $\\{f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)})\\}_{j=1}^{M}$ The goal is to minimize the fllowing regret ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall i\\in[K],\\ \\ \\ \\mathrm{Reg}_{D}(\\mathcal{F}_{i})=\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\ell\\left(f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\operatorname*{min}_{f\\in\\mathcal{F}_{i}}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\ell\\left(f(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "whereyt $y_{t}^{(j)}$ is the label or true output. Each client can not share personalized data with others, but can share personalized models or gradients via the central server. ", "page_idx": 3}, {"type": "text", "text": "4 FOMD-No-LU ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we propose a federated algorithmic framework, FOMD-No-LU (Federated Online Mirror Descent without Local Updating) for online collaboration. ", "page_idx": 3}, {"type": "text", "text": "Let $\\Omega$ be a convex and bounded decision set. At any round $t$ , each client $j\\in[M]$ selects a decision $\\mathbf{u}_{t}^{(j)}\\in\\Omega$ and then observes aloss function $l_{t}^{(j)}(\\cdot):\\Omega\\rightarrow\\mathbb{R}$ The client computes the loss $l_{t}^{(j)}(\\mathbf{u}_{t}^{(j)})$ and an estimator of the gradient denoted by $\\tilde{g}_{t}^{(j)}$ (or the gradient denoted by $g_{t}^{(j)}$ ). To reduce the communication cost, we adopt the intermittent communication (IC) protocol [Woodworth et al., 2021] where clients communicate with server every $N$ rounds. Assuming that $T=N\\times R$ where $N,R\\in\\mathbb{Z}$ , the IC protocol limits the rounds of communication to $R$ ", "page_idx": 3}, {"type": "text", "text": "We divide $[T]$ into $R$ disjoint sub-intervals denoted by $\\{T_{r}\\}_{r=1}^{R}$ , in which ", "page_idx": 4}, {"type": "equation", "text": "$$\nT_{r}=\\{(r-1)N+1,(r-1)N+2,\\ldots,r N\\}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "For any $t\\in T_{r}$ , all clients always select the initial decision, i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\forall j\\in[M],\\,\\forall t\\in T_{r},\\quad\\mathbf{u}_{t}^{(j)}=\\mathbf{u}_{(r-1)N+1}^{(j)}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Arthe end ofthe $r N$ roundaloelensendl $\\textstyle\\frac{1}{N}\\sum_{\\underline{{t}}\\in\\underline{{T}}_{\\mathcal{T}}}\\tilde{g}_{\\underline{{t}}}^{(j)},j\\in[M]$ to server.Then serverupdates the decision within online mirror descent framework [Bubeck and Cesa-Bianchi, 2012], ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\bar{g}}_{t}=\\displaystyle\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\frac{1}{N}\\sum_{t\\in T_{r}}{\\tilde{g}}_{t}^{(j)}\\right),}\\\\ {\\nabla_{\\bar{\\mathbf{u}}_{t+1}}\\psi_{t}(\\bar{\\mathbf{u}}_{t+1})=\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-\\bar{g}_{t},\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ {\\mathbf{u}_{t+1}=\\arg\\operatorname*{min}\\mathcal{D}_{\\psi_{t}}(\\mathbf{u},\\bar{\\mathbf{u}}_{t+1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "(4)-(5) is called model averaging [McMahan et al., 2017] and shows the collaboration among clients. Finally, server may broadcast $\\mathbf{u}_{t+1}$ to all lients. Let the initial decision ${\\bf u}_{1}^{(j)}={\\bf u}_{1}$ for all $j\\in[M]$ then it must be $\\mathbf{u}_{t}^{(j)}=\\mathbf{u}_{t}$ for all $t\\in[T]$ . Thus clients do not transmit $\\mathbf{u}_{t}^{(j)}$ to server. The pseudo-code of FOMD-No-LU is shown in Algorithm 1. ", "page_idx": 4}, {"type": "text", "text": "4.1  Regret Bound ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Theorem 1. Let $\\mathcal{E}\\;=\\;\\{N,2N,....,R N\\}$ where $\\begin{array}{r}{N\\ =\\ \\frac{T}{R}}\\end{array}$ and $R\\,\\in\\,[T]$ .Assuming that $l_{t}^{(j)}(\\cdot)$ $t\\in[T],j\\in[M],$ are convex lssfnctions Lt $g_{t}^{(j)}=\\nabla_{\\mathbf{u}_{t}^{(j)}}l_{t}^{(j)}(\\mathbf{u}_{t}^{(j)})$ and $\\tilde{g}_{t}^{(j)}$ be an estimator of $g_{t}^{(j)}$ .Aa any round $t\\in\\mathcal{E}$ let $\\mathbf q_{t+1}$ and $\\mathbf{r}_{t+1}$ betwo auxiliary decisions defnedasfllows, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\daleth_{\\mathbf{q}_{t+1}\\psi_{t}}(\\mathbf{q}_{t+1})=\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-2\\sum_{j=1}^{M}\\frac{\\tilde{g}_{t}^{(j)}-g_{t}^{(j)}}{M},~~~\\nabla_{\\mathbf{r}_{t+1}}\\psi_{t}(\\mathbf{r}_{t+1})=\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-\\frac{2}{M}\\sum_{j=1}^{M}g_{t}^{(j)}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "ThenFOMD-No-LU guarantees that, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\forall\\mathbf{v}\\in\\Omega,\\quad\\displaystyle\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\frac{l_{t}^{(j)}(\\mathbf{u}_{t}^{(j)})-l_{t}^{(j)}(\\mathbf{v})}{N M}\\leq\\displaystyle\\sum_{\\underbrace{l\\in\\mathcal{E}}_{\\mathbf{\\Omega}}}\\left[\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t+1})+\\frac{\\mathcal{D}_{\\psi_{t}}(\\mathbf{u}_{t},\\mathbf{r}_{t+1})}{2}\\right]+}\\\\ {\\underset{t\\in\\mathcal{E}}{\\underbrace{\\sum_{t\\in\\mathcal{E}}\\frac{\\mathcal{D}_{\\psi_{t}}(\\mathbf{u}_{t},\\mathbf{q}_{t+1})}{2}+\\frac{1}{M}\\displaystyle\\sum_{t\\in\\mathcal{E}}\\displaystyle\\sum_{j=1}^{M}\\left\\langle\\tilde{g}_{t}^{(j)}-g_{t}^{(j)},\\mathbf{u}_{t}-\\mathbf{v}\\right\\rangle}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "It is intriguing that the regret bound comprises two components: the first part, $\\Xi_{1}$ , cannot be reduced by collaboration, while the second part, $\\Xi_{2}$ , highlights the benefits of collaboration. $\\Xi_{1}$ is the regret induced by exact gradients, while $\\Xi_{2}$ is the regret induced by estimated gradients and shows how collaboration controls the regret. It is worth mentioning that Theorem 1 gives a general regret bound, from which various types of regret bounds can be readily derived by instantiating the decision set $\\Omega$ and the regularizer $\\psi_{t}(\\cdot)$ . For instance, if $\\Omega=\\mathcal{F}_{i}$ where ${\\mathcal{F}}_{i}$ follows Example 1, $\\begin{array}{r}{\\psi_{t}(\\mathbf{v})=\\frac{1}{2\\lambda}\\|\\mathbf{v}\\|_{2}^{2}}\\end{array}$ and $\\mathbb{E}[\\|\\tilde{g}_{t}^{(j)}\\|_{2}^{2}]\\le C\\|g_{t}^{(j)}\\|_{2}^{2}$ , then FOMD-No-LU becomes a ederated online descent descent It is easy to give a $O(M U_{i}\\sqrt{(1+\\frac{C}{M})T})$ expected regret from Theorem 1. Besides, $N>1$ increases the regret and shows the trade-off between communication cost and regret bound. ", "page_idx": 4}, {"type": "text", "text": "Theorem rquiresa novlalys n ho the bia ofestmators ieo $\\sum_{j=1}^{M}\\|\\tilde{g}_{t}^{(j)}-g_{t}^{(j)}\\|_{2}^{2}$ is controlled by cooperation. To this end, we introduce two virtual decisions $\\mathbf q_{t+1}$ and $\\mathbf{r}_{t+1}$ that are updated by 2=1 $\\begin{array}{r}{2\\sum_{j=1}^{M}\\frac{\\tilde{g}_{t}^{(j)}-g_{t}^{(j)}}{M}}\\end{array}$ and $2\\sum_{j=1}^{M}\\frac{g_{t}^{(j)}}{M}$ respetively Previous federated online miror descent uses exact gradients $g_{t}^{(j)},j\\in[M]$ [Mitra et al., 2021]. Thus its analysis is different from ours. ", "page_idx": 4}, {"type": "table", "img_path": "uqWfLgZpV1/tmp/a7dbb3082d6c7edf1d69b9bf9bda07626b78f49ec3c5b3a86782d0bc6416842c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "4.2  Comparison with Previous Work ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In fact, FOMD-No-LU adopts the batching technique [Dekel et al., 2011], that is, it divides $[T]$ into $R$ sub-intervals and executes (3) during each sub-intervals. The batching technique (also known as mini-batch) has been used in the multi-armed bandit problem [Arora et al., 2012] and distributed stochastic convex optimization [Karimireddy et al., 2020, Woodworth et al., 2020a]. We use the batching technique for the first time to distributed online learning. ", "page_idx": 5}, {"type": "text", "text": "FOMD-No-LU is different from FedOMD (federated online mirror descent) [Mitra et al., 2021]. (i) FedOMD only transmits exact gradients, while FOMD-No-LU can transmit estimated gradients. Thus the regret bound of FedOMD did not contain $\\Xi_{2}$ in Theorem 1. (i) FedOMD uses local updating, such as local OGD [Patel et al., 2023] and local SGD [McMahan et al., 2017, Reddi et al., 2021]. Thus FedOMD induces client dift, i.e., $\\mathbf{u}_{t}^{(j)}\\neq\\mathbf{u}_{t}$ . Besides, if we use FedOMD to design a federated online model selection algorithm, then the download cost is in $O(M K)$ bits. ", "page_idx": 5}, {"type": "text", "text": "5  A Federated Algorithm for OMS-DecD ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we just consider the case $R=T$ , that is, there is no communication constraints. Due to space constraints, we have deferred the algorithm and result of $R<T$ to the appendix. ", "page_idx": 5}, {"type": "text", "text": "At a high level, our algorithm comprises two components both of which are critical for achieving a communicationcost in $o(K)$ : (i) decoupling model selection and online prediction; (i) collaboratively updating decisions within the framework of FOMD-No-LU. ", "page_idx": 5}, {"type": "text", "text": "5.1 Decoupling Model Selection and Prediction ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Model Selection on Server At any round $t$ server maintains $K$ hypotheses $\\{f_{t,i}^{(j)}\\in\\mathcal{F}_{i}\\}_{i=1}^{K}$ and a probability distribution $\\mathbf{p}_{t}^{(j)}$ over the $K$ hypotheses for all $j\\in[M]$ . The model selection process aimsto select ahypothesis from $\\{f_{t,i}^{(j)}\\}_{i=1}^{K}$ and then predicts the utput f $\\mathbf{x}_{t}^{(j)}$ . An intuitive idea is that, for each $j\\in[M]$ , the client samples a hypothesis following $\\mathbf{p}_{t}^{(j)}$ . However, such an approach requires that server broadcasts $\\mathbf{p}_{t}^{(j)}$ to clients, and will cause a download cost in $O(K)$ ", "page_idx": 5}, {"type": "text", "text": "The sampling operation (or model selection process) can be executed on server. Specifically, server just broadcasts the selected hypotheses, and thus saves the communication cost. For each $j\\in[M]$ server selects $J\\in[2,K]$ hypotheses denoted by $f_{t,A_{t,a}}^{(j)},a\\in[J]$ where $A_{t,a}\\in[K]$ . For simplicity, let $O_{t}^{(j)}=\\{A_{t,1},\\ldots,A_{t,J}\\}$ We instantiate $\\mathbf{u}_{t}=\\mathbf{p}_{t}$ in FOMD-No-LU. Then FOMD-No-LU ensures $\\mathbf{p}_{t}^{(j)}=\\mathbf{p}_{t}$ for all $j\\in[M]$ .We sample $A_{t,1},\\dotsc,A_{t,J}$ in order and follow T). ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{A_{t,1}\\sim\\mathbf{p}_{t},}\\\\ {A_{t,a}\\sim\\operatorname{Uni}([K]\\setminus\\{A_{t,1},\\ldots,A_{t,a-1}\\}),\\;a\\in[2,J].}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Server samples $O_{t}^{(j)}$ for all $j\\in[M]$ and thus must independently execute (7) $M$ times which only pays an additional computational cost in $O(M\\log K)$ . The factor $\\log K$ arises from the process of sampling a number from $\\{1,...,K\\}$ . Server only sends $f_{A_{t,a}}^{(j)},a\\in[J]$ to the $j$ -th client. It is worth $\\mathbf{p}_{t}$ $\\begin{array}{r}{O(\\sum_{j=1}^{M}\\sum_{a=1}^{J}(d_{A_{t,a}}+\\log K))}\\end{array}$ If $J$ is independent of $K$ , then the download cost is only $O(M\\log K)$ ", "page_idx": 6}, {"type": "text", "text": "Prediction on Clients For each $j\\in[M]$ the $j$ th lent receives $f_{A_{t,a}}^{(j)}$ \uff0c $a\\in[J]$ and uses $f_{t,A_{t,1}}^{(j)}$ to output a prediction, i.e., ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\hat{y}_{t}^{(j)}=f_{t,A_{t,1}}^{(j)}\\left(\\mathbf{x}_{t}^{(j)}\\right)=\\left<\\mathbf{w}_{t,A_{t,1}}^{(j)},\\phi_{A_{t,1}}(\\mathbf{x}_{t}^{(j)})\\right>,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Wwhere we asmethat $f_{t,i}^{(j)}$ $\\mathbf{w}_{t,i}^{(j)}\\in\\mathbb{R}^{d_{i}}$ (s I)ing $y_{t}^{(j)}$ $\\ell(f_{t,A_{t,1}}^{(j)}(\\mathbf x_{t}^{(j)}),y_{t}^{(j)})$ ", "page_idx": 6}, {"type": "text", "text": "It is worth mentioning that the other $J-1$ hypotheses $f_{t,A_{t,a}}^{(j)}$ \uff0c $a\\geq2$ are just usedto obtain more information on the loss function. We will explain more in the following subsection. Thus we do not cumulate the loss $\\ell(f_{t,A_{t,a}}^{(j)}(\\mathbf x_{t}^{(j)}),y_{t}^{(j)}),a\\geq2$ ", "page_idx": 6}, {"type": "text", "text": "5.2  Online Collaboration Updating ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "$j~\\in~[M]$ $\\mathbf{c}_{t}^{(j)}\\,=\\,(c_{t,1}^{(j)},\\hdots,c_{t,K}^{(j)})$ whe $c_{t,i}^{(j)}\\,=$ $\\ell(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)})$ $f_{t,i}^{(j)},\\,i\\,\\in\\,[K]$ The $j$ $c_{t,i}^{(j)}$ $i\\in O_{t}^{(j)}$ .to server. Since $c_{t,i}^{(j)}$ \uff0c $i\\notin O_{t}^{(j)}$ can nt eoserved,itis necesar to construct an etimated los vector $\\tilde{\\mathbf{c}}_{t}^{(j)}=$ $(\\tilde{c}_{t,1}^{(j)},\\ldots,\\tilde{c}_{t,K}^{(j)})$ $\\begin{array}{r}{\\tilde{c}_{t,i}^{(j)}=\\frac{c_{t,i}^{(j)}}{\\mathbb{P}[i\\in O_{t}^{(j)}]}\\cdot\\mathbb{I}_{i\\in O_{t}^{(j)}}}\\end{array}$ \uff0c $i\\in[K]$ $\\mathbb{E}_{t}\\left[\\tilde{c}_{t,i}^{(j)}\\right]=c_{t,i}^{(j)}$ and $\\begin{array}{r}{\\mathbb{E}_{t}\\left[(\\tilde{c}_{t,i}^{(j)})^{2}\\right]\\leq\\frac{K-1}{J-1}(c_{t,i}^{(j)})^{2}}\\end{array}$ where $\\mathbb{E}_{t}[\\cdot]:=\\mathbb{E}\\left[\\cdot|O_{[t-1]}^{(j)}\\right]$ . Thus sampling $A_{t,a}$ \uff0c $a\\geq2$ reduces the variance of the estimators which is equivalent to obtain more information on the true loss. ", "page_idx": 6}, {"type": "text", "text": "Server agregates $\\tilde{\\mathbf{c}}_{t}^{(j)},j\\in[M]$ andupdates $\\mathbf{p}_{t}$ $\\Delta_{K}$ bethe $(K\\!-\\!1)$ dimensional simplex, $\\Omega=\\Delta_{K}$ and $\\tilde{g}_{t}^{(j)}=\\tilde{\\mathbf{c}}_{t}^{(j)}$ . Then the server executes (8). ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle\\nabla_{\\bar{\\mathbf{p}}_{t+1}}\\psi_{t}(\\bar{\\mathbf{p}}_{t+1})=\\nabla_{\\mathbf{p}_{t}}\\psi_{t}(\\mathbf{p}_{t})-\\displaystyle\\frac{1}{M}\\sum_{j=1}^{M}\\tilde{\\mathbf{c}}_{t}^{(j)},}\\\\ {\\displaystyle\\qquad\\qquad\\mathbf{p}_{t+1}=\\mathop{\\mathrm{arg}\\,\\mathrm{min}}_{\\mathbf{p}\\in\\Delta_{K}}\\mathcal{D}_{\\psi_{t}}(\\mathbf{p},\\bar{\\mathbf{p}}_{t+1}),}\\\\ {\\displaystyle\\qquad\\qquad\\psi_{t}(\\mathbf{p})=\\sum_{i=1}^{K}\\frac{C_{i}}{\\eta_{t}}p_{i}\\ln p_{i},}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\psi_{t}(\\mathbf{p})$ is the weighted negative entropy regularizer [Bubeck et al., 2017], $\\eta_{t}>0$ is a timevariant learning rate and $C_{i}>0$ satisfies that $\\operatorname*{max}_{t,j}c_{t,i}^{(j)}\\leq C_{i}$ . It is obvious that server does not broadcast pt+1. ", "page_idx": 6}, {"type": "text", "text": "Updating hpothes For each $j\\in[M]$ and $i\\in[K]$ $\\nabla_{t,i}^{(j)}=\\nabla_{\\mathbf{w}_{t,i}^{(j)}}\\ell\\left(\\left\\langle\\mathbf{w}_{t,i}^{(j)},\\phi_{i}(\\mathbf{x}_{t}^{(j)})\\right\\rangle,y_{t}^{(j)}\\right)$ Since $\\nabla_{t,i}^{(j)},i\\notin O_{t}^{(j)}$ a $\\begin{array}{r}{\\tilde{\\nabla}_{t,i}^{(j)}=\\frac{\\nabla_{t,i}^{(j)}}{\\mathbb{P}[i\\in O_{t}^{(j)}]}\\cdot\\mathbb{I}_{i\\in O_{t}^{(j)}}}\\end{array}$ for all $j\\,\\in\\,[M],i\\,\\in\\,[K]$ . Clients send $\\{\\nabla_{t,i}^{(j)},i\\in O_{t}^{(j)}\\},j\\in[M]$ to server. Then server aggregates $\\{\\tilde{\\nabla}_{t,i}^{(j)},i\\in\\,[K]\\},\\,j\\,\\in\\,[M]$ and updates the hypotheses following (4)-(6). For each $i\\in[K]$ let $\\Omega=\\mathcal{F}_{i}$ and $\\tilde{g}_{t}^{(j)}=\\tilde{\\nabla}_{t,i}^{(j)}$ . Server executes (9). ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle\\nabla_{\\overline{{\\mathbf{w}}}_{t+1,i}}\\psi_{t,i}(\\bar{\\mathbf{w}}_{t+1,i})=\\nabla_{\\mathbf{w}_{t,i}}\\psi_{t,i}(\\mathbf{w}_{t,i})-\\displaystyle\\frac{1}{M}\\displaystyle\\sum_{j=1}^{M}\\tilde{\\nabla}_{t,i}^{(j)},\\quad i=1,...,K,}\\\\ {\\displaystyle\\mathbf{w}_{t+1,i}=\\arg\\operatorname*{min}\\mathcal{D}_{\\psi_{t,i}}\\big(\\mathbf{w},\\bar{\\mathbf{w}}_{t+1,i}\\big),}\\\\ {\\displaystyle\\psi_{t,i}(\\mathbf{w})=\\displaystyle\\frac{1}{2\\lambda_{t,i}}\\|\\mathbf{w}\\|_{2}^{2},}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\psi_{t,i}(\\mathbf{w})$ is the Euclidean regularizer and $\\lambda_{t,i}$ is a time-variant learning rate. ", "page_idx": 7}, {"type": "text", "text": "We name this algorithm FOMD-OMS (FOMD-No-LU for OMS-DecD) and show it in Algorithm 2. ", "page_idx": 7}, {"type": "text", "text": "5.3  Regret bounds ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "To obtain high-probability regret bounds that adapt to the complexity of individual hypothesis space, we establish a new Bernstein's inequality for martingale. ", "page_idx": 7}, {"type": "text", "text": "Lemma 1. Let $X_{1},\\ldots,X_{n}$ be a bounded martingale difference sequence w.r.t. the filtration $\\mathcal{H}=$ $(\\mathcal{H}_{k})_{1\\leq k\\leq n}$ and with $|X_{k}|\\leq a$ Let $\\begin{array}{r}{Z_{t}=\\sum_{k=1}^{t}\\bar{X_{k}}}\\end{array}$ be the associated martingale. Denote the sum of the conditional variances by $\\begin{array}{r}{\\Sigma_{n}^{2}=\\sum_{k=1}^{n}\\mathbb{E}\\left[X_{k}^{2}|\\mathcal{H}_{k-1}\\right]\\leq v\\,}\\end{array}$ , where $v\\in[0,B]$ is a random variable and $B\\geq2$ is a constant. Then for any constant $a>0$ with probability at least $1-2\\lceil\\log B\\rceil\\delta$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{t=1,\\ldots,n}Z_{t}<\\frac{2a}{3}\\ln\\frac{1}{\\delta}+\\sqrt{\\frac{2}{B}\\ln\\frac{1}{\\delta}}+2\\sqrt{v\\ln\\frac{1}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Note that $v$ is a random variable in Lemma 1, while it is a constant in standard Bernstein's inequality for martingale (see Lemma A.8 [Cesa-Bianchi and Lugosi, 2006]). Lemma 1 is derived from the standard Bernstein's inequality along with the well-known peeling technique [Bartlett et al., 2005]. ", "page_idx": 7}, {"type": "text", "text": "Assumption 1. For each $i\\in[K]$ there is a constant $b_{i}$ such that $\\|\\phi_{i}(\\mathbf{x})\\|_{2}\\,\\leq\\,b_{i}$ where $\\phi_{i}(\\cdot)$ is defined in (1). ", "page_idx": 7}, {"type": "text", "text": "Lemma 2. Under Assumption $^{\\,l}$ for each $i\\in[K]$ , there are two constants $C_{i}>0,G_{i}>0$ that dependon $U_{i}$ 0 $b_{i}$ suchthat $\\operatorname*{max}_{t,j}\\boldsymbol{c}_{t,i}^{(j)}\\le C_{i}$ and $\\operatorname*{max}_{t,j}\\|\\nabla_{t,i}^{(j)}\\|_{2}\\leq G_{i}$ ", "page_idx": 7}, {"type": "text", "text": "Theorem 2. Let $R\\,=\\,T$ UnderAssumption $^{\\,l}$ .denote by $A_{m}\\ =\\ \\mathrm{argmin}_{i\\in[K]}C_{i}$ and ${\\cal C}\\,=$ $\\operatorname*{max}_{i\\in[K]}C_{i}$ .Assuming that $\\ell(\\cdot,\\cdot)$ is convex and $K\\geq J\\geq2.$ Let $\\begin{array}{r}{g_{K,J}=\\frac{K-J}{J-1}}\\end{array}$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\forall i\\in A_{m},\\ p_{1,i}=\\displaystyle\\frac{1}{\\left|A_{m}\\right|}\\left(1-\\frac{\\sqrt{K}}{\\sqrt{T}}\\right)+\\frac{1}{\\sqrt{K T}}\\quad\\mathrm{and}\\quad\\forall i\\notin A_{m},\\ p_{1,i}=\\displaystyle\\frac{1}{\\sqrt{K T}},}\\\\ &{\\ \\forall t\\in[T],\\ \\eta_{t}=\\displaystyle\\frac{\\sqrt{\\ln\\left(K T\\right)}}{2\\sqrt{\\left(1+\\frac{g_{K J}}{M}\\right)T}}\\land\\frac{1}{2g_{K,J}},\\quad\\lambda_{t,i}=\\displaystyle\\frac{U_{i}}{2G_{i}\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)\\cdot\\left(g_{K,J}^{2}\\vee t\\right)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "With probability at least $1-\\Theta\\left(M\\log(T)+\\log(K T/M)\\right)\\cdot\\delta,$ . the regret of FOMD-OMS satisfies: $\\langle i\\in[K],\\mathrm{Reg}_{D}(\\mathcal{F}_{i})=O\\left(M B_{i,1}\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)T}+B_{i,2}\\cdot g_{K,J}\\ln\\frac{1}{\\delta}+B_{i,3}\\sqrt{g_{K,J}M T\\ln\\frac{1}{\\delta}}\\right),$ where $B_{i,1}=U_{i}G_{i}+C_{i}\\sqrt{\\ln(K T)},B_{i,2}=M C+U_{i}G_{i}$ and $B_{i,3}=U_{i}G_{i}+\\sqrt{C C_{i}}$ ", "page_idx": 7}, {"type": "text", "text": "Both $C_{i}$ and $G_{i}$ depend on $U_{i}$ or $b_{i}$ (see Lemma 2). Let $\\mathfrak{C}_{i}=\\Theta(U_{i}G_{i}+C_{i})$ . Thus $\\mathfrak{C}_{i}$ measures the complexity of ${\\mathcal{F}}_{i}$ .Then ourregret bound adapts to $\\sqrt{\\mathfrak{C}\\mathfrak{C}_{i}}$ Where ${\\mathfrak{C}}=\\operatorname*{max}_{i\\in[K]}{\\mathfrak{C}}_{i}$ , while previous regret bounds depend on ${\\mathfrak C}$ [Ghari and Shen, 2022, Hong and Chae, 2022], that is, they can not adapt to the complexity of individual hypothesis space. If ${\\mathfrak{C}}_{i^{\\ast}}\\ll{\\mathfrak{C}}$ , then our regret bound is much better. ", "page_idx": 7}, {"type": "text", "text": "The regret bound in Theorem 2 is also called multi-scale regret bound [Bubeck et al., 2017]. However, previous regret analysis can not yield a high-probability multi-scale bound. The reason is the lack of the new Bernstein's inequality for martingale (Lemma 1). If we use the new Freedman's inequality for martingale [Lee et al., 2020], then a high-probability bound can still be obtained, but is worse than the bound in Theorem 2 by a factor of order $O(\\mathrm{poly}(\\ln T))$ ", "page_idx": 7}, {"type": "text", "text": "5.4  Time Complexity and Communication Complexity Analysis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "For each $j\\in[M]$ , the $j$ th client makes prediction and computes gradients in time $O(\\sum_{i\\in O_{t}^{(j)}}d_{i})$ Server samples $O_{t}^{(j)},j\\in[M]$ aggregate gradints adudatglbalmdeThrro complexity on server is $\\begin{array}{r}{\\dot{O(\\sum_{j=1}^{M}\\sum_{i\\in O_{t}^{(j)}}d_{i}+\\sum_{i=1}^{K}d_{i}+J M\\log K)}}\\end{array}$ \uff0c ", "page_idx": 8}, {"type": "text", "text": "Upload At any round $t\\in[T]$ the $j$ th clien transmits $c_{t,i}^{(j)},\\nabla_{t,i}^{(j)},\\,i\\in O_{t}^{(j)}$ and the corresponding indexes to server. It requires $J(\\sum_{i\\in O_{t}^{(j)}}d_{i}+1)$ floating-point numbers and $J$ integers. If we use 32 bits to represent a float, and use $\\log K$ bits to represent an integer in $[K]$ . Each client transmits $(32J(\\sum_{i\\in O_{t}^{(j)}}d_{i}+1)+J\\log K)$ bits to server. ", "page_idx": 8}, {"type": "text", "text": "Download Server broadcasts $\\mathbf{w}_{t,i}\\in\\mathbb{R}^{d_{i}},i\\in O_{t}^{(j)}$ and the corresponding indexes to clients. The total download cost is $(32M J(\\sum_{i\\in O_{t}^{(j)}}d_{i}+1)+M J\\log K)$ bits. ", "page_idx": 8}, {"type": "text", "text": "5.5 Answers to Question 1 ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Before discussing Question 1, we give two lower bounds on the regret. ", "page_idx": 8}, {"type": "text", "text": "Theorem 3 (Lower Bounds). Assuming that $5\\,\\leq\\,K\\,\\leq\\,\\operatorname*{min}\\{d,T\\}$ . For each $i\\,\\in\\,[K]$ let ${\\mathcal{F}}_{i}\\,=$ $\\{f_{i}(\\mathbf{x})=\\mathbf{e}_{i}^{\\top}\\mathbf{x}\\}$ and $\\begin{array}{r}{\\mathcal{D}_{i}=[\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}f_{i}(\\mathbf{x}),\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{X}}f_{i}(\\mathbf{x})],}\\end{array}$ where $\\mathbf{e}_{i}$ is the standard basis vector in $\\mathbb{R}^{d}$ . Denote by sup the supremum over all examples. ", "page_idx": 8}, {"type": "text", "text": "(i) There are no computational constraints on clients. Let $\\ell(v,y)\\,=\\,|v\\,-\\,y|$ .The regret of any algorithm for OMS-DecD satisfies: $\\begin{array}{r}{\\operatorname*{lim}_{T\\rightarrow\\infty}\\operatorname*{sup}\\operatorname*{max}_{i\\in[K]}\\mathrm{{Reg}}_{D}(\\mathcal{F}_{i})\\geq0.25M\\sqrt{T\\ln K},}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "(ii) The per-round time complexity on each client is limited to $O(J)$ .Let $\\ell(v,y)=1\\!-\\!v\\!\\cdot\\!y$ The regret of any, possibly randomized, noncooperative algorithm with outputs in $\\cup_{i\\in[K]}{\\mathcal{D}}_{i}$ for OMS-DecD satisfies: sup $\\begin{array}{r}{\\mathbb{E}[\\operatorname*{max}_{i\\in[K]}\\operatorname{Reg}_{D}(\\mathcal{F}_{i})]\\geq0.1M\\sqrt{K T J^{-1}}}\\end{array}$ where the expectation is taken over the randomization of algorithm. ", "page_idx": 8}, {"type": "text", "text": "The assumption that the outputs of any noncooperative algorithm belong to $\\cup_{i=\\in[K]}{\\mathcal{D}}_{i}$ is natural, and can be removed in the case of $J=1$ . Next we define a noncooperative algorithm, NCO-OMS. ", "page_idx": 8}, {"type": "text", "text": "Definition 1 (NCO-OMS). NCO-OMS independently samples $O_{t}^{(j)}$ following (7) and executes ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\forall j\\in[M],\\quad\\nabla_{\\overline{{\\mathbf{p}}}_{t+1}}\\psi_{t}(\\overline{{\\mathbf{p}}}_{t+1})=\\nabla_{\\mathbf{p}_{t}^{(j)}}\\psi_{t}\\left(\\mathbf{p}_{t}^{(j)}\\right)-\\tilde{\\mathbf{c}}_{t}^{(j)},\\qquad\\quad\\mathbf{p}_{t+1}^{(j)}=\\underset{\\mathbf{p}\\in\\Delta\\kappa}{\\mathrm{arg}\\,\\mathrm{min}}\\,\\mathcal{D}_{\\psi_{t}}(\\mathbf{p},\\overline{{\\mathbf{p}}}_{t+1}).}\\\\ &{}&{\\nabla_{\\overline{{\\mathbf{w}}}_{t+1,i}}\\psi_{t,i}(\\overline{{\\mathbf{w}}}_{t+1,i})=\\!\\nabla_{\\mathbf{w}_{t,i}^{(j)}}\\psi_{t,i}\\left(\\mathbf{w}_{t,i}^{(j)}\\right)-\\tilde{\\nabla}_{t,i}^{(j)},\\quad\\mathbf{w}_{t+1,i}^{(j)}=\\underset{\\mathbf{w}\\in\\mathcal{F}_{i}}{\\mathrm{arg}\\,\\mathrm{min}}\\,\\mathcal{D}_{\\psi_{t,i}}(\\mathbf{w},\\overline{{\\mathbf{w}}}_{t+1,i})}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where hedefnions of $\\tilde{\\mathbf{c}}_{t}^{(j)}$ and $\\tilde{\\nabla}_{t,i}^{(j)}$ follow FOMD-OMS. ", "page_idx": 8}, {"type": "text", "text": "It is easy to prove the regret of NCO-OMS satisfies: with probability at least $1-\\Theta\\left(M\\log(K T)\\right)\\cdot\\delta,$ $\\forall i\\in[K],\\ {\\mathrm{Reg}}_{D}(\\mathcal{F}_{i})=O\\left(M\\left(B_{i,1}\\sqrt{\\left(1+g_{K,J}\\right)T}+B_{i,2}g_{K,J}\\ln\\frac{1}{\\delta}+B_{i,3}\\sqrt{g_{K,J}T\\ln\\frac{1}{\\delta}}\\right)\\right),$ where $B_{i,1}=U_{i}G_{i}+C_{i}\\sqrt{\\ln(K T)}$ $B_{i,2}=C+U_{i}G_{i}$ and $B_{i,3}=U_{i}G_{i}+\\sqrt{C C_{i}}$ .Weleavethe pseudo-code of NCO-OMS and the corresponding regret analysis in appendix. ", "page_idx": 8}, {"type": "text", "text": "Next we discuss Question 1 by considering two cases. ", "page_idx": 8}, {"type": "text", "text": "Case 1: There are no computational constraints on clients. Collaboration is unnecessary. ", "page_idx": 8}, {"type": "text", "text": "Let $J=\\Theta(K)$ in FOMD-OMS and NCO-OMS. By Theorem 2, both FOMD-OMS and NCO-OMS enjoya $O(M U_{i}G_{i}{\\sqrt{T}}+M C_{i}{\\sqrt{T\\ln(K T)}})$ regret. By Theorem 3, FOMD-OMS and NCO-OMS are nearly optimal in terms of the dependence on $M$ and $T$ . Thus collaboration is unnecessary. ", "page_idx": 8}, {"type": "text", "text": "Case 2: The per-round time complexity on each client is limited to $o(K)$ . Collaboration is necessary. ", "page_idx": 8}, {"type": "text", "text": "Let $\\begin{array}{r l r}{J}&{{}=}&{o(K)}\\end{array}$ in FOMD-OMS and Theorem 3. By Theorem 2, FOMD-OMS enjoys a $O(M B_{i,1}\\sqrt{T}+B_{i,3}\\sqrt{M K T J^{-1}\\ln\\delta^{-1}})$ regret, which is smaller than the lower bound on the regret of any noncooperative algorithm (see Theorem 3). Thus collaboration is necessary. ", "page_idx": 8}, {"type": "table", "img_path": "uqWfLgZpV1/tmp/24cd3f888bc52d1adf9fe91f6f769358527fc12fb8fc103e15dad305a5dd4800.jpg", "table_caption": ["Table 1: Comparison with previous algorithms. $D$ is the number of random features [Rahimi and Recht, 2007]. Time (s) is the per-round time complexity on client. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "6  Application to Distributed OMKL ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We will apply the proposed FOMD-OMS to a special instance of OMS-DecD, known as distributed OMKL, in which ${\\mathcal{F}}_{i}$ is a RKHS. Then we contrast our results with those from earlier studies, highlighting the unnecessary nature of collaboration in prior federated algorithms. ", "page_idx": 9}, {"type": "text", "text": "Theorem 4. Let ${\\mathcal{F}}_{i}$ be a RHKS for all $\\textit{i}\\in\\textit{[K]}$ and $R\\ \\le\\ T$ \uff1aWith probability at least $1-\\Theta\\left(T M\\log(R)+T\\log(K R/M)\\right)\\cdot\\delta,$ . the regret of FOMD-OMS satisfies, $\\forall i\\in[K]$ ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{D}(\\mathcal{F}_{i})=\\tilde{O}\\left(M B_{i,1}\\sqrt{1+\\frac{g_{K,J}}{M}}\\cdot\\frac{T}{\\sqrt{R}}+\\frac{B_{i,2}M g_{K,J}T}{R}+\\frac{B_{i,3}T}{\\sqrt{R}}\\sqrt{M g_{K,J}}+\\frac{U_{i}G_{i}M T}{\\sqrt{D}}\\right),\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where the notation $\\tilde{O}(\\cdot)$ hides polylogarithmic factor in $\\delta^{-1}$ and $D=d_{i}$ follows (1). ", "page_idx": 9}, {"type": "text", "text": "We defer the algorithm in appendix. Let $R\\,=\\,T$ and $J\\,=\\,2$ . We compare FOMD-OMS with eM-KOFL [Hong and Chae, 2022] and POF-MKL [Ghari and Shen, 2022]. Table 1 gives the results. We observe that FOMD-OMS significantly improves the computational complexity of eM-KOFL and POF-MKL (by a factor of $O(K),$ on each client. The per-round time complexity of the two algorithms is $O(D K)$ . Recalling the answer to Question 1 (see Section 5.5), collaboration in eM-KOFL and POF-MKL is unnecessary. ", "page_idx": 9}, {"type": "text", "text": "Next we compare the regret bound of the three algorithms. Recalling that ${\\mathfrak{C}}_{i}\\leq{\\mathfrak{C}}$ . The regret bounds of eM-KOFL and POF-MKL can not adapt to the complexity of individual hypothesis space. (i) The regret bound of FOMD-OMS is better than that of POF-MKL in relation to its dependence on $M$ and $\\mathfrak{C}_{i}$ i In the case of $K=O\\left({\\frac{\\mathfrak{C}}{\\mathfrak{C}_{i}}}M\\cdot\\ln K\\right)$ theregret bound of FOMD-OMS is beterthanthat of eM-KOFL. (i)Inthe case of $\\begin{array}{r}{K=\\Omega\\left(\\frac{\\mathfrak{C}}{\\mathfrak{C}_{i}}M\\cdot\\ln K\\right)}\\end{array}$ , the regret bound of FOMD-OMS is worse than that of eM-KOFL. If $K$ is sufficiently large, the regret bound of eM-KOFL is better than that of FOMD-OMS by a factor of $O(\\sqrt{K})$ ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we have studied the necessity of collaboration for OMS-DecD from the perspective of computational constraints. We demonstrate that collaboration is unnecessary when there are no computational constrains on clients, while it becomes necessary if the time complexity on each client is limited to $o(K)$ . Our work clarifies the unnecessary nature of collaboration in previous algorithms for the first time, gives conditions under which collaboration is necessary, and provides inspirations for studying the problem from constraints beyond computational constrains. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We thank all anonymous reviewers for their valuable comments and suggestions. This work was supported by the Major Key Project of PCL (No. 2022ZD0115301). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Raman Arora, Ofer Dekel, and Ambuj Tewari. Online bandit learning against an adaptive adversary: from regret to policy regret. In Proceedings of the 29th International Conference on Machine Learning, pages 1503-1510, 2012.   \nPeter L. Bartlett, Stephane Boucheron, and Gebor Lugosi. Model selection and error estimation. Machine Learning, 48(1):85-113, 2002.   \nPeter L. Bartlett, Olivier Bousquet, and Shahar Mendelson. Local rademacher complexities. Annals of Statistics, 33(4):1497-1537, 2005.   \nPantelis Bouboulis, Symeon Chouvardas, and Sergios Theodoridis. Online distributed learning over networks in RKH spaces using random fourier features. IEEE Transactions on Signal Processing, 66(7):1920-1932, 2018.   \nStephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, New York, NY, 2004.   \nSebastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multiarmed bandit problems. Foundations and Trends? in Machine Learning, 5(1):1-122, 2012.   \nSebastien Bubeck, Nikhil R. Devanur, Zhiyi Huang, and Rad Niazadeh. Online auctions and multiscale online learning. In Proceedings of the 2017ACM Conference on Economics and Computation, pages 497-514, 2017.   \nNicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge University Press, New York, NY, 2006.   \nOfer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao. Optimal distributed online prediction. In Proceedings of the 28th International Conference on Machine Learning, pages 713-720, 2011.   \nDylan J Foster, Satyen Kale, Mehryar Mohri, and Karthik Sridharan. Parameter-free online learning via model selection. Advances in Neural Information Processing Systems, 30:6022-6032, 2017.   \nDylan J Foster, Akshay Krishnamurthy, and Haipeng Luo. Model selection for contextual bandits. Advances in Neural Information Processing Systems, 32:14741-14752, 2019.   \nPouya M. Ghari and Yanning Shen. Personalized online federated learning with multiple kernels. Advances in Neural Information Processing Systems, 35:33316-33329, 2022.   \nAvishek Ghosh and Sayak Ray Chowdhury. Model selection in reinforcement learning with general function approximations. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases, pages 148-164, 2022.   \nMark A. Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. The WEKA data mining software: an update. SIGKDD Explorations, 11(1):10-18, 2009.   \nSongnam Hong and Jeongmin Chae. Communication-efficient randomized algorithm for multi-kernel online federated learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44 (12):9872-9886, 2022.   \nRuiquan Huang, Weiqiang Wu, Jing Yang, and Cong Shen. Federated linear contextual bandits. Advances in Neural Information Processing Systems, 34:27057-27068, 2021.   \nPeter Kairouz, H. Brendan McMahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista A. Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G. L. D'Oliveira, Hubert Eichner, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adria Gascon,Badih GhaziPhillipB.Gibbons,MarcoGruteer, Zaid HarchaouiChayan He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Konecny, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancrede Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer Ozgur, Rasmus Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar, Mariana Raykova, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tramer, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances and open problems in federated learning. Foundations and Trends in Machine Learning, 14(1-2): 1-210, 2021.   \nMohammad Reza Karimi, Nezihe Merve Gurel, Bojan Karlas, Johannes Rausch, Ce Zhang, and Andreas Krause. Online active model selection for pre-trained classifiers. In Proceedings of the 24th International Conference on Artificial Intelligence and Statistics, pages 307-315, 2021.   \nSai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J. Reddi, Sebastian U. Stich, and Ananda Theertha Suresh. SCAFFOLD: stochastic controlled averaging for federated learning. In Proceedings of the 37th International Conference on Machine Learning, pages 5132-5143, 2020.   \nJakub Konecny, H. Brendan McMahan, Felix X. Yu, Peter Richtarik, Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for improving communication efficiency. CoRR, arXiv:1610.05492v2, 2016.   \nDohyeok Kwon, Jonghwan Park, and Songnam Hong. Tighter regret analysis and optimization of online federatedlearning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45 (12):15772-15789, 2023.   \nChung-Wei Lee, Haipeng Luo, Chen-Yu Wei, and Mengxiao Zhang. Bias no more: high-probability data-dependent regret bounds for adversarial bandits and mdps. Advances in Neural Information Processing Systems, 33:15522-15533, 2020.   \nJunfan Li and Shizhong Liao. Improved regret bounds for online kernel selection under bandit feedback. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases, pages 333-348, 2022.   \nJunfan Li and Shizhong Liao. Improved regret bounds for online kernel selection under bandit feedback. CoRR, arXiv:2303.05018v2, 2023.   \nTian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods, and future directions. IEEE Signal Processing Magazine, 37(3):50-60, 2020.   \nZhu Li, Jean-Francois Ton, Dino Oglic, and Dino Sejdinovic. Towards a unified analysis of random Fourierfeatures. In Proceedings of the 36th International Conference on Machine Larning pages 3905-3914, 2019.   \nBrendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-effcient learning of deep networks from decentralized data. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, pages 1273-1282, 2017.   \nTom M. Mitchell. Machine Learning. McGraw-Hill Science, New York, NY, 1997.   \nAritra Mitra, Hamed Hassani, and George J. Pappas. Online federated learning. In Proceedings of the 60th IEEE Conference on Decision and Control, pages 4083-4090, 2021.   \nMehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning (second edition). MIT Press, Cambridge, MA, 2018.   \nAldo Pacchiano, My Phan, Yasin Abbasi-Yadkori, Anup Rao, Julian Zimmert, Tor Lattimore, and Csaba Szepesvari. Model selection in contextual stochastic bandit problems. Advances in Neural Information Processing Systems, 33:10328-10337, 2020.   \nKumar Kshitij Patel, Lingxiao Wang, Aadirupa Saha, and Nathan Srebro. Federated online and bandit convex optimization. In Proceedings of the 4oth International Conference on Machine Learning, pages 27439-27460, 2023.   \nAli Rahimi and Benjamin Recht. Random features for large-scale kernel machines. Advances in Neural Information Processing Systems, 20:1177-1184, 2007.   \nAli Rahimi and Benjamin Recht. Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. Advances in Neural Information Processing Systems, 21:1313- 1320, 2008.   \nSashank J. Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konecny, Sanjiv Kumar, and Hugh Brendan McMahan. Adaptive federated optimization. In Proceedings of the 9th International Conference on Learning Representations, 2021.   \nYevgeny Seldin, Peter L. Bartlett, Koby Crammer, and Yasin Abbasi- Yadkori. Prediction with limited advice and multiarmed bandits with paid observations. In Proceedings of the 31st International Conference on Machine Learning, pages 280-287, 2014.   \nYanning Shen, Tianyi Chen, and Georgios B. Giannakis. Random feature-based online multi-kernel learning in environments with unknown dynamics. Journal of Machine Learning Research, 20 (22):1-36, 2019.   \nKonstantinos Slavakis, Georgios B. Giannakis, and Gonzalo Mateos. Modeling and optimization for big data analytics: (statistical) learning tools for our era of data deluge. IEEE Signal Processing Magazine, 31(5):18-31, 2014.   \nRoman Vershynin. High-dimensional probability: An introduction with applications in data science. Cambridge University Press, New York, NY, 2018.   \nJianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H. Brendan McMahan, Blaise Agiera y Arcas, Maruan Al-Shedivat, Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data, Suhas N. Diggavi, Hubert Eichner, Advait Gadhikar, Zachary Garrett, Antonious M. Girgis, Filip Hanzely, Andrew Hard, Chaoyang He, Samuel Horvath, Zhouyuan Huo, Alex Ingerman, Martin Jaggi, Tara Javidi, Peter Kairouz, Satyen Kale, Sai Praneeth Karimireddy, Jakub Konecny, Sanmi Koyejo, Tian Li, Luyang Liu, Mehryar Mohri, Hang Qi, Sashank J. Reddi, Peter Richtarik, Karan Singhal, Virginia Smith, Mahdi Soltanolkotabi, Weikang Song, Ananda Theertha Suresh, Sebastian U. Stich, Ameet Talwalkar, Hongyi Wang, Blake E. Woodworth, Shanshan Wu, Felix X. Yu, Honglin Yuan, Manzil Zaheer, Mi Zhang, Tong Zhang, Chunxiang Zheng, Chen Zhu, and Wennan Zhu. A field guide to federated optimization. CoRR, abs/2107.06917, 2021.   \nYuanhao Wang, Jiachen Hu, Xiaoyu Chen, and Liwei Wang. Distributed bandit learning: Nearoptimal regret with efficient communication. In Proceedings of the 8th International Conference on Learning Representations, 2020.   \nBlake E. Woodworth, Kumar Kshitij Patel, and Nati Srebro. Minibatch vs local SGD for heterogeneous distributed learning. Advances in Neural Information Processing Systems, 33:6281-6292, 2020a.   \nBlake E. Woodworth, Kumar Kshitij Patel, Sebastian U. Stich, Zhen Dai, Brian Bullins, H. Brendan McMahan, Ohad Shamir, and Nathan Srebro. Is local SGD better than minibatch sgd? In Proceedings of the 37th International Conference on Machine Learning, pages 10334-10343, 2020b.   \nBlake E. Wodworth, Brian Bullins, Ohad Shamir, and Nathan Srebro. The min-max complexity of distributed stochastic convex optimization with intermittent communication. In Proceedings of the 34th Annual Conference on Learning Theory, pages 4386-4437, 2021.   \nDun Zeng, Siqi Liang, Xiangjing Hu, Hui Wang, and Zenglin Xu. Fedlab: A fexible federated learning framework. Journal of Machine Learning Research, 24(100):1-7, 2023a.   \nDun Zeng, Zenglin Xu, Yu Pan, Xu Luo, Qifan Wang, and Xiaoying Tang. Enhanced federated optimization: Adaptive unbiased client sampling with reduced variance. CoRR, arXiv:2310.02698v3, 2023b. URL https : //arxiv.org/abs/2310.02698.   \nXiao Zhang and Shizhong Liao. Online kernel selection via incremental sketched kernel alignment. In Proceedingsof the Twenty-Seventh International Joint Conference on Artifcial Intelligence, pages 3118-3124, 2018.   \nXiao Zhang, Shizhong Liao, Jun Xu, and Ji-Rong Wen. Regret bounds for online kernel selection in continuous kernel space. In Proceedings of the Thirty-Fifth AAAl Conference on Artificial Intelligence, pages 10931-10938, 2021.   \nMartin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the Twentieth International Conference on Machine Learning, pages 928-936, 2003. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Limitations ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The main limitation of this work lies in the first lower bound in Theorem 3 that holds in the case of $T\\to\\infty$ . Although this lower bound nearly matches our upper bound asymptotically and is enough to answer Question 1, it is desired to establish a non-asymptotical lower bound, that is, the lower bound holdsfor anyvalue of $T$ ", "page_idx": 13}, {"type": "text", "text": "B Broader Impact ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "This work can be potentially applied to distributed online prediction tasks. We aim to address a fundamental problem whether collaboration among clients is necessary and under what conditions collaboration is necessary. A predictable economic benefit of our work is to give a guidance on the usage of federated learning and save unnecessary communication overhead. ", "page_idx": 13}, {"type": "text", "text": "Our work can also instruct the machine learning engineers to tune the hyper-parameter of online learning algorithms. Thus our work can alleviate the burden of machine learning engineers and improve the utility of online leaning algorithms in industrial applications. ", "page_idx": 13}, {"type": "text", "text": "C Experiments ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we aim to verify the following three goals which are our main results. ", "page_idx": 13}, {"type": "text", "text": "G1 Collaboration is unnecessary if we allow the computational cost on each client to be $O(K)$ Weset $R=T$ and $J=K$ in FOMD-OMS. In this case, the per-round running time on each client is $O(K)$ . We aim to verify that FOMD-OMS enjoys similar prediction performance with the noncooperative algorithm, NCO-OMS with $J=K$ (see Definition 1). ", "page_idx": 13}, {"type": "text", "text": "G2 Collaboration is necessary if we limit the computational cost on each client to $o(K)$ ", "page_idx": 13}, {"type": "text", "text": "Weset $R=T$ and $J\\,=\\,2$ in FOMD-OMS. In this case, the per-round running time on each client is $O(1)$ . We aim to verify that FOMD-OMS enjoys better prediction performance than NCO-OMS with $J=2$ ", "page_idx": 13}, {"type": "text", "text": "G3 FOMD-OMS improves the regret bounds of algorithms for distributed OMKL. ", "page_idx": 13}, {"type": "text", "text": "FOMD-OMSwith $R=T$ and $J=2$ enjoys similar prediction performance with eM-KOFL [Hong and Chae, 2022], and enjoys better prediction performance than POF-MKL [Ghari and Shen, 2022] at a smaller computational cost on each client. Although there are more baseline algorithms, such as vM-KOFL [Hong and Chae, 2022], pMKOFL [Hong and Chae, 2022] and OFSKL [Ghari and Shen, 2022], we do not compare with the three algorithms since they do not perform as well as eM-KOFL and POF-MKL. ", "page_idx": 13}, {"type": "text", "text": "C.1  Experimental setting ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We will execute three experiments and each one verifies a goal. For simplicity, we do not measure the actual communication cost and use serial implementation to simulate the distributed implementation. To verify G1 and $\\mathbf{G}2$ , we use the instance of online model selection given in Example 1. The first experiment verifies G1. We construct 10 nested hypothesis spaces (i.e., $K=10$ )asfollows ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\forall i\\in[10],\\quad\\mathcal{F}_{i}=\\left\\{f(\\mathbf{x})=\\langle\\mathbf{w},\\mathbf{x}\\rangle,\\|\\mathbf{w}\\|_{2}\\leq U_{i}\\right\\},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\begin{array}{r}{U_{i}=\\frac{i}{10}}\\end{array}$ . We set $R=T$ and $J\\,=\\,K$ in FOMD-OMS. Since $J\\,=\\,K$ , we have $O_{t}^{(j)}=[K]$ and $\\mathbb{P}\\left[i\\in O_{t}^{(j)}\\right]=1$ The larning rates $\\eta_{t},\\lambda_{t,i},i\\in[K]$ of FOMD-OMS follow Theorem 2. For NCO-OMS, we set $J=K$ and set the learning rate $\\eta_{t},\\lambda_{t,i},i\\in[K]$ following Theorem 2 in which $M=1$ i.e., ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\forall t\\in[T],\\;\\eta_{t}=\\frac{\\sqrt{\\ln{(K T)}}}{2\\sqrt{T}},\\quad\\lambda_{t,i}=\\frac{U_{i}}{2G_{i}\\sqrt{t}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We use the square loss function $\\ell(f(\\mathbf{x}),y)=(f(\\mathbf{x})-y)^{2}$ . For both FOMD-OMS and NCO-OMS, wetune $G_{i}=(U_{i}+1)\\times\\{1,2,4,6,8,10\\}$ and set $C_{i}=(U_{i}+1)^{2}$ ", "page_idx": 13}, {"type": "table", "img_path": "uqWfLgZpV1/tmp/6f33a5d7c2040a0ba426626d497e028615caa731619ce38242b61b76f7aecd6a.jpg", "table_caption": ["Table 2: Basic information of datasets. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "The second experiment verifies G2. We set $R=T$ and $J=2$ in FOMD-OMS. The learning rates of FOMD-OMS also follow Theorem 2. For NCO-OMS, we also set $J=2$ and set the learning rate $\\eta_{t},\\lambda_{t,i},i\\in[K]$ following Theorem 2 in which $M=1$ ,i.e., ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\forall t\\in[T],\\quad\\eta_{t}=\\frac{\\sqrt{\\ln\\left(K T\\right)}}{2\\sqrt{(K-1)\\,T}}\\land\\frac{1}{2(K-2)},\\quad\\lambda_{t,i}=\\frac{U_{i}}{2G_{i}\\sqrt{(K-1)\\cdot((K-2)^{2}\\setminus\\ell\\,t)}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Similar to the first experiment, we tune $G_{i}=(U_{i}+1)\\times\\{1,2,4,6,8,10\\}$ and set $C_{i}=(U_{i}+1)^{2}$ ", "page_idx": 14}, {"type": "text", "text": "The third experiment verifies G3. We consider online kernel selection (as known as online multikernel learning) which is an instance of online model selection given in Example 2. We select the Gaussian kernel with 8 different kernel widths (i.e., $K=8$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\forall i\\in[8],\\quad\\kappa_{i}(\\mathbf{x},\\mathbf{v})=\\exp\\left(-\\frac{\\|\\mathbf{x}-\\mathbf{v}\\|_{2}^{2}}{2\\sigma_{i}^{2}}\\right),\\sigma_{i}=2^{i-2},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and construct the corresponding hypothesis space ${\\mathcal{F}}_{i}$ and $\\mathbb{H}_{i}$ following (21) in which we set $U_{i}=U$ and $D_{i}=D$ for all $i\\in[K]$ and tune $U\\in\\{1,2,4\\}$ . Note that $U_{i}$ is same for all $i\\in[K]$ . We replace the initial distribution $\\mathbf{p}_{1}$ in Theorem 2 with auniform distribution $\\textstyle\\left({\\frac{1}{K}},\\cdot\\cdot\\cdot,{\\frac{1}{K}}\\right)$ We set $D=100$ for FOMD-OMS, eM-KOFL and POF-MKL. is the number of random features. We set $R=T$ $J=2$ and $C=U+1$ in FOMD-OMS. Thus the per-round time complexity on each client is $O(D)$ and the per-round communication cost is $O(M D+M\\log K)$ . There are three hyper-parameters in eM-KOFL, i.e., $\\eta_{g},\\,\\eta_{l}$ and $\\lambda$ $\\eta_{g}$ is the global learning rate, $\\eta_{l}$ is the local learning rate and $\\lambda$ is a regularization parameter. There are $2M+3$ hyper-parameters in POF-MKL, i.e., $\\eta_{g},\\eta_{j},\\xi_{j},j\\in[M],$ $m,\\lambda$ in which $M/m$ plays the same role with $J$ in FOMD-OMS. $\\eta_{g}$ is the global learning rate, $\\eta_{j}$ is the local learning rate, $\\xi_{j}$ is called exploration rate and $\\lambda$ is a regularization parameter. Since $J=2$ in FOMD-OMS, we can set $m=M/2$ for FOMD-OMS. Following the original paper [Ghari and Shen, 2022], we set $\\xi_{j}=1$ . For a fair comparison, we change the learning rates of FOMD-OMS, eM-KOFL and POF-MKL. Following the parameter setting of eM-KOFL [Hong and Chae, 2022], we tune $\\eta_{g},\\eta_{l},\\eta_{j}\\in\\{0.1,0.5,1,4,8,16\\}$ and $\\lambda\\in\\{0.1,0.001,0.0001\\}$ for eM-KOFL and POF-MKL. For FOMD-OMS, we also tune $\\eta_{t},\\lambda_{t,i}\\in\\{0.1,0.5,1,4,8,16\\}$ ", "page_idx": 14}, {"type": "text", "text": "For all of the three experiments, we set 10 clients, i.e., $M=10$ We use8regression datasets shown in Table 2 from WEKA \u00b2 [Hall et al., 2009] and UCI machine learning repository 3, and rescale the target variables and features of all datasets to fit in [O,1] and [-1,1] respectively. For each dataset, we randomly divide it into 10 subsets and each subset simulates the data on a client. We randomly permutate the instances in the datasets 10 times and report the average results. All algorithms are implementedwith $\\mathbf{R}$ on a Windows machine with 2.8 GHz Core(TM) i7-1165G7 CPU 4. ", "page_idx": 14}, {"type": "text", "text": "We use the square loss function and define the mean squared error (MSE) of all algorithms, i.. ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathrm{MSE}=\\frac{1}{M T}\\sum_{j=1}^{M}\\sum_{t=1}^{T}\\left(f_{t}^{(j)}\\left(\\mathbf{x}_{t}^{(j)}\\right)-y_{t}^{(j)}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We record the mean of MSE over 10 random experiments, and the standard deviation of the mean of MSE. We also record the mean of of the total running time on each client, and the standard deviation of the mean of running time. ", "page_idx": 14}, {"type": "table", "img_path": "uqWfLgZpV1/tmp/42fbcb08614629d07eb66cb6c9a6eea04195333f62aef8f73bbb7a0270fc33e3.jpg", "table_caption": ["Table 3: Comparison with the noncooperative algorithm. $\\Delta$ is the difference of MSE between NCO-OMS and FOMD-OMS. aE- $\\cdot b=\\dot{a}\\times10^{-b}$ $\\bar{a}>0,b>0$ "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "C.2 Results of the First and the Second Experiment ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We summary the experimental results of the first and the second experiments in Table 3. ", "page_idx": 15}, {"type": "text", "text": "In Table 3, $\\Delta$ is defined as the difference of MSE between NCO-OM and FOMD-OMS. Thus $\\Delta$ shows whether collaboration improves the prediction performance of the noncooperative algorithm. Times (s) records the total running time on all clients. ", "page_idx": 15}, {"type": "text", "text": "We first consider the case $J=K$ in which the per-round time complexity on each client is $O(K)$ It is obvious that the MSE of NCO-OMS is similar with that of FOMD-OMS. Although there are four datasets on which FOMD-OMS performs better than NCO-OMS, such as the elevator, bank, Year and Slice datsets, the improvement is very limited. Beside, the value of $\\Delta$ is very small. Thus collaboration does not significantly improve the prediction performance of the noncooperative algorithm. The results verify the first goal G1. ", "page_idx": 15}, {"type": "text", "text": "Next we consider the case $J=2$ in which the per-round time complexity on each client is $O(1)$ . It is obvious that FOMD-OMS performs better than NCO-OMS on all datasets. Besides, the value of $\\Delta$ in the case of $J=2$ is much larger than that in the case of $J=K$ , such as the elevators, ailerons, ailerons and Year datasets. Thus collaboration indeed improves the prediction performance of the noncooperative algorithm. The results verify the second goal G2. ", "page_idx": 15}, {"type": "text", "text": "Finally we compare the running time of all algorithms. It is obvious that FOMD-OMS with $J=2$ runs faster than the other algorithms. The results coincide with our theoretical analysis. NCO-OMS runs slower than FOMD-OMS. The reason is that NCO-OMS must solve the sampling probability $\\mathbf{p}_{t}$ using an additional binary search on each client (see Section G.1). In other words, NCO-OMS must execute binary search $M$ times at each round. FOMD-OMS only executes one binary search on server at each round. The improvement on the computational cost is benefit from decoupling model selection and prediction. ", "page_idx": 15}, {"type": "text", "text": "C.3  Results of the Third Experiment ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We summary the experimental results of the third experiment in Table 4. ", "page_idx": 15}, {"type": "table", "img_path": "uqWfLgZpV1/tmp/38f9c4f45b24eafa0332258cd2f998868d69db0c367327316866b0a1faec537a.jpg", "table_caption": ["Table 4: Comparison with the state-of-the-art algorithms. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "We first compare FOMD-OMS with eM-KOFL. As a whole, the MSE of the two algorithms is similar. On the TomsHardware, Twitter and ailerons datasets, eM-KOFL enjoys slightly better prediction performance than FOMD-OMS. However, the running time of eM-KOFL is much larger than that of FOMD-OMS. The results coincide with the theoretical observations that FOMD-OMS enjoys a similar regret bound with eM-KOFL at a much smaller computational cost on the clients. ", "page_idx": 16}, {"type": "text", "text": "Next we compare FOMD-OMS with POF-MKL. Both the MSE and running time of FOMD-OMS are much smaller than that of POF-MKL. The results coincide with the theoretical observations that FOMD-OMS enjoys a smaller regret bound than POF-MKL at a much smaller computational cost on theclients. ", "page_idx": 16}, {"type": "text", "text": "Thus the results in Table 4 verifies the third goal G3. ", "page_idx": 16}, {"type": "text", "text": "Finally, we explain that why POF-MKL performs worse than FOMD-OMS. There are three reasons. ", "page_idx": 16}, {"type": "text", "text": "(1) POF-MKL does not use federated learning to learn a global probability distribution denoted by $\\mathbf{p}_{t}$ , but learns a personalized probability distribution denoted by $\\mathbf{p}_{t,j}$ on each client. Thus POF-MKL converges to the best kernel function at a lower rate. ", "page_idx": 16}, {"type": "text", "text": "(2) POF-MKL uniformly samples two kernel functions and then learns two global hypotheses, while FOMD-OMSuses $\\mathbf{p}_{t}$ to sample a kernel function and learns a global hypothesis. Thus POF-MKL can learn a better global hypothesis. ", "page_idx": 16}, {"type": "text", "text": "(3) On each client, POF-MKL executes model selection and combines the predictions of $K$ hypotheses using $\\mathbf{p}_{t,j}$ . Thus the time complexity is in $O(D K)$ . FOMD-OMS executes model selection on server, and only uses the sampled hypothesis to make prediction. Thus the time complexity on each client is in $O(D)$ ", "page_idx": 16}, {"type": "text", "text": "D A Federated Algorithm for OMS-DecD with Communication Constraints ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Let $R<T$ . Clients communicate with server every $N$ rounds. At the $r$ -th communication, clients transmit {\u2265teT. t t server at the last roud iT hn serverts sampling probabilities and hypotheses. We give the pseudo-code in Algorithm 3. ", "page_idx": 16}, {"type": "text", "text": "Require: $U,T,R,J$   \nEnsure: $f_{1,i}^{(j)}=0$ $p_{1,i}$ \uff0c\u3002 $i\\in[K],j\\in[M]$ 1: for $r=1,2,\\ldots,R$ do 2: for $t\\in T_{r}$ do 3: if $t==(r-1)N+1$ then 4: for $j=1,\\dots,M$ do 5: Server samples $O_{t}^{(j)}$ following (7) 6: Server ransmits $\\bar{f}_{t,i}^{(j)},i\\in O_{t}^{(j)}$ to the $j$ th lient 7: end for 8: end if 9: for $j=1,\\dots,M$ in parallel do   \n10: Output ft,At,1 $f_{t,A_{t,1}}^{(j)}(\\mathbf{x}_{t}^{(j)})$   \n11: for $i\\in O_{t}^{(j)}$ do   \n12: $\\nabla_{t,i}^{(j)}$ $c_{t,i}^{(j)}$   \n13: end for   \n14: end for   \n15: if $t==r N$ then   \n16: $\\begin{array}{r}{\\{\\frac{1}{N}\\sum_{t\\in T_{r}}\\nabla_{t,i}^{(j)},\\frac{1}{N}\\sum_{t\\in T_{r}}c_{t,i}^{(j)}\\}_{i\\in O_{t}^{(j)}}}\\end{array}$   \n17: Server computes $\\mathbf{p}_{t+1}$ following (8)   \n18: Server computes $\\mathbf{w}_{t+1,i},i\\in[K]$ following (9)   \n19: end if   \n20: end for   \n21: end for ", "page_idx": 17}, {"type": "text", "text": "Theorem 5. Let $R<T$ For any $t\\in[R]$ ,let ", "text_level": 1, "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\forall i\\in A_{m},\\ p_{1,i}=\\!\\frac{1}{\\left|A_{m}\\right|}\\left(1-\\frac{\\sqrt{K}}{\\sqrt{R}}\\right)+\\frac{1}{\\sqrt{K R}}\\quad\\mathrm{and}\\quad\\forall i\\notin A_{m},\\ p_{1,i}=\\frac{1}{\\sqrt{K R}},}\\\\ &{\\ \\forall t\\in[R],\\ \\eta_{t}=\\!\\frac{\\sqrt{\\ln\\left(K R\\right)}}{2\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)R}}\\land\\frac{1}{2g_{K,J}},\\quad\\lambda_{t,i}=\\frac{U_{i}}{2G_{i}\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)\\cdot\\left(g_{K,J}^{2}\\lor t\\right)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "UnderthonditfThr,withrobabilyatlat $\\begin{array}{r}{1\\!-\\!\\Theta\\left(\\frac{T}{R}M\\log(R)+\\frac{T}{R}\\log(K R/M)\\right)\\!\\cdot\\!\\delta,}\\end{array}$ the regret of FOMD-OMS satisfies: $\\forall i\\in[K]$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{D}(\\mathcal{F}_{i})=O\\left(M B_{i,1}\\sqrt{1+\\frac{g_{K,J}}{M}}\\cdot\\frac{T}{\\sqrt{R}}+\\frac{T}{R}\\cdot B_{i,2}M g_{K,J}\\ln\\frac{1}{\\delta}+\\frac{B_{i,3}T}{\\sqrt{R}}\\sqrt{M g_{K,J}\\ln\\frac{1}{\\delta}}\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The regret bound depends on $\\textstyle O({\\frac{1}{\\sqrt{R}}})$ . Thus FOMD-OMS explicitly balances the prediction performance and the communication cost. ", "page_idx": 17}, {"type": "text", "text": "Proof. If FOMD-OMS runs on a sequence of examples with length $T=R$ , then Theorem 2 gives, with probability at least $1-\\Theta\\left(M\\,\\mathrm{log}(C R)+\\mathrm{log}(\\bar{C}K R/M)\\right)\\cdot\\bar{\\delta}.$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{D}(\\mathcal{F}_{i})=O\\left(M B_{i,1}\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)R}+B_{i,2}g_{K,J}\\ln\\frac{1}{\\delta}+B_{i,3}\\sqrt{g_{K,J}M R\\ln\\frac{1}{\\delta}}\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "According to Theorem 1, the regret bound of FOMD-OMS with $R<T$ satisfies, with probability at least $\\begin{array}{r}{1-\\breve{\\Theta}\\left(\\frac{T}{R}M\\log(C R)+\\frac{\\breve{T}}{R}\\log(C K R/M)\\right)\\cdot\\delta,}\\end{array}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathrm{Reg}_{D}(\\mathcal{F}_{i})=\\!O\\left(N M B_{i,1}\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)R}+N B_{i,2}g_{K,J}\\ln\\frac{1}{\\delta}+N B_{i,3}\\sqrt{g_{K,J}M R\\ln\\frac{1}{\\delta}}\\right)}\\\\ &{}&{\\mathrm{=}\\!O\\left(\\frac{T}{\\sqrt{R}}M B_{i,1}\\sqrt{1+\\frac{g_{K,J}}{M}}+\\frac{T}{R}\\cdot B_{i,2}g_{K,J}\\ln\\frac{1}{\\delta}+\\frac{T}{\\sqrt{R}}B_{i,3}\\sqrt{g_{K,J}M\\ln\\frac{1}{\\delta}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 17}, {"type": "text", "text": "E Proof of Theorem 1 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We first state a technical lemma. ", "page_idx": 18}, {"type": "text", "text": "Lemma 3 (Boyd and Vandenberghe [2004]). Assuming that $\\psi(\\cdot):\\mathcal{X}\\rightarrow\\mathbb{R}$ is aconvex anddifferential function,and $\\mathcal{X}$ is a convex domain. Let $f^{*}=\\operatorname{argmin}_{f\\in\\mathcal{X}}\\psi(f)$ .Then it must be ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\forall g\\in\\mathcal{X},\\quad\\langle\\nabla\\psi(f^{*}),g-f^{*}\\rangle\\geq0.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Lemma 3 gives the first-order optimality condition. ", "page_idx": 18}, {"type": "text", "text": "Proof of Theorem 1. We first consider the case $R=T$ ", "page_idx": 18}, {"type": "text", "text": "The main idea is to give an lower bound and upper bound on $\\langle\\bar{g}_{t},{\\mathbf{u}}_{t+1}-{\\mathbf{v}}\\rangle$ , respectively. Next we give an upper bound. ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\bar{g}_{t},\\mathbf{u}_{t+1}-\\mathbf{v}\\rangle}\\\\ &{=\\langle\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-\\nabla_{\\bar{\\mathbf{u}}_{t+1}}\\psi_{t}(\\bar{\\mathbf{u}}_{t+1}),\\mathbf{u}_{t+1}-\\mathbf{v}\\rangle}\\\\ &{=\\langle\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-\\nabla_{\\mathbf{u}_{t+1}}\\psi_{t}(\\mathbf{u}_{t+1}),\\mathbf{u}_{t+1}-\\mathbf{v}\\rangle+\\langle\\nabla_{\\mathbf{u}_{t+1}}\\psi_{t}(\\mathbf{u}_{t+1})-\\nabla_{\\bar{\\mathbf{u}}_{t+1}}\\psi_{t}(\\bar{\\mathbf{u}}_{t+1}),\\mathbf{u}_{t+1}-\\mathbf{v}\\rangle}\\\\ &{=\\!\\!\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t+1})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{u}_{t+1},\\mathbf{u}_{t})-\\langle\\nabla_{\\mathbf{u}_{t+1}}\\mathcal{D}_{\\psi_{t}}(\\mathbf{u}_{t+1},\\bar{\\mathbf{u}}_{t+1}),\\mathbf{v}-\\mathbf{u}_{t+1}\\rangle}\\\\ &{\\le\\!\\!\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t+1})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{u}_{t+1},\\mathbf{u}_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The last inequality comes from Lemma 3. ", "page_idx": 18}, {"type": "text", "text": "Then we give a lower bound. ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\langle\\bar{g}_{t},\\mathbf{u}_{t+1}-\\mathbf{v}\\rangle}\\\\ &{=\\displaystyle\\frac{1}{M}\\sum_{j=1}^{M}\\left[\\left\\langle g_{t}^{(j)},\\mathbf{u}_{t+1}-\\mathbf{v}\\right\\rangle+\\left\\langle\\tilde{g}_{t}^{(j)}-g_{t}^{(j)},\\mathbf{u}_{t+1}-\\mathbf{v}\\right\\rangle\\right]}\\\\ &{=\\displaystyle\\frac{1}{M}\\sum_{j=1}^{M}\\left\\langle g_{t}^{(j)},\\mathbf{u}_{t}^{(j)}-\\mathbf{v}\\right\\rangle+\\underbrace{\\frac{1}{M}\\displaystyle\\sum_{j=1}^{M}\\left\\langle g_{t}^{(j)},\\mathbf{u}_{t+1}-\\mathbf{u}_{t}\\right\\rangle}_{\\Xi_{1}}+\\underbrace{\\frac{1}{M}\\displaystyle\\sum_{j=1}^{M}\\left\\langle\\tilde{g}_{t}^{(j)}-g_{t}^{(j)},\\mathbf{u}_{t+1}-\\mathbf{v}\\right\\rangle}_{\\Xi_{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where ut $\\mathbf{u}_{t}^{(j)}=\\mathbf{u}_{t}$ ", "page_idx": 18}, {"type": "text", "text": "Next we analyze $\\Xi_{1}$ and $\\Xi_{2}$ ", "page_idx": 18}, {"type": "text", "text": "To analyze $\\Xi_{1}$ , we introduce an auxiliary variable $\\mathbf{r}_{t+1}$ defined as follows ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{r}_{t+1}}\\psi_{t}(\\mathbf{r}_{t+1})=\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-2\\sum_{M}^{M}\\sum_{j=1}^{g}g_{t}^{(j)}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi_{1}=\\!\\frac{1}{2}\\left\\langle\\displaystyle\\frac{2}{M}\\displaystyle\\sum_{j=1}^{M}g_{t}^{(j)},\\mathbf{u}_{t+1}-\\mathbf{u}_{t}\\right\\rangle}\\\\ &{\\quad=\\!\\frac{1}{2}\\left\\langle\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-\\nabla_{\\mathbf{r}_{t+1}}\\psi_{t}(\\mathbf{r}_{t+1}),\\mathbf{u}_{t+1}-\\mathbf{u}_{t}\\right\\rangle}\\\\ &{\\quad=\\!\\frac{1}{2}\\left(\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t+1},\\mathbf{r}_{t+1}\\big)-\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t+1},\\mathbf{u}_{t}\\big)-\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t},\\mathbf{r}_{t+1}\\big)\\right)}\\\\ &{\\quad\\geq-\\,\\displaystyle\\frac{1}{2}\\left(\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t+1},\\mathbf{u}_{t}\\big)+\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t},\\mathbf{r}_{t+1}\\big)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Before analyzing $\\Xi_{2}$ , we also introduce an auxiliary variable $\\mathbf q_{t+1}$ defined as follows ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{q}_{t+1}}\\psi_{t}(\\mathbf{q}_{t+1})=\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-\\frac{2}{M}\\sum_{j=1}^{M}\\left(\\tilde{g}_{t}^{(j)}-g_{t}^{(j)}\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now we can analyze $\\Xi_{2}$ . We have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Xi_{2}=\\frac{1}{2}\\left\\langle\\frac{2}{M}\\sum_{j=1}^{M}\\left(\\tilde{g}_{t}^{(j)}-g_{t}^{(j)}\\right),\\mathbf{u}_{t+1}-\\mathbf{u}_{t}\\right\\rangle+\\left\\langle\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{g}_{t}^{(j)}-g_{t}^{(j)}\\right),\\mathbf{u}_{t}-\\mathbf{v}\\right\\rangle\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle=\\frac{1}{2}\\left\\langle\\nabla_{\\mathbf{u}_{t}}\\psi_{t}(\\mathbf{u}_{t})-\\nabla_{\\mathbf{q}_{t+1}}\\psi_{t}(\\mathbf{u}_{t+1}),\\mathbf{u}_{t+1}-\\mathbf{u}_{t}\\right\\rangle+\\Xi_{3}}\\\\ &{\\displaystyle=\\frac{1}{2}\\left(\\mathcal{D}_{\\psi}(\\mathbf{u}_{t+1},\\mathbf{q}_{t+1})-\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t+1},\\mathbf{u}_{t}\\big)-\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t},\\mathbf{q}_{t+1}\\big)\\right)+\\Xi_{3}}\\\\ &{\\displaystyle\\geq-\\,\\frac{1}{2}\\left(\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t+1},\\mathbf{u}_{t}\\big)+\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t},\\mathbf{q}_{t+1}\\big)\\right)+\\Xi_{3}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Combining the lower bound and upper bound gives ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{M}\\sum_{j=1}^{M}\\left[\\left<g_{t}^{(j)},\\mathbf{u}_{t}^{(j)}-\\mathbf{v}\\right>\\right]}\\\\ &{\\displaystyle\\leq\\!\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t+1})+\\Xi_{3}+\\frac{1}{2}\\mathcal{D}_{\\psi}(\\mathbf{u}_{t},\\mathbf{q}_{t+1})+\\frac{1}{2}\\mathcal{D}_{\\psi}(\\mathbf{u}_{t},\\mathbf{r}_{t+1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Using the convexity of $l_{t}^{(j)}$ , that is, $l_{t}^{(j)}(\\mathbf{u}_{t}^{(j)})-l_{t}^{(j)}(\\mathbf{v})\\leq\\left\\langle g_{t}^{(j)},\\mathbf{p}_{t}^{(j)}-\\mathbf{v}\\right\\rangle$ we further obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{1}{M}\\sum_{j=1}^{M}\\left(l_{t}^{(j)}(\\mathbf{u}_{t}^{(j)})-l_{t}^{(j)}(\\mathbf{v})\\right)}\\\\ {\\displaystyle\\leq\\!\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t+1})+\\frac{1}{2}\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t},\\mathbf{q}_{t+1}\\big)+\\frac{1}{2}\\mathcal{D}_{\\psi}\\big(\\mathbf{u}_{t},\\mathbf{r}_{t+1}\\big)+\\Xi_{3},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 19}, {"type": "text", "text": "Now we consider the case $R<T$ Recalling that $\\mathcal{E}=\\{N,2N,3N\\dots,R N\\}$ and ", "page_idx": 19}, {"type": "equation", "text": "$$\nT_{r}=\\{(r-1)N+1,(r-1)N+2,\\ldots,r N\\},\\quad r=1,\\ldots,R.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For any batch $T_{r}$ $\\mathit{\\Pi}_{r}^{\\ '},\\mathit{r}=1,\\ldots,R$ we define a new loss function $\\bar{l}_{r N}^{(j)}(\\cdot)$ at the end of this batch, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\forall j\\in[M],\\,\\forall\\mathbf{u}\\in\\Omega,\\quad\\bar{l}_{r N}^{(j)}(\\mathbf{u})=\\frac{1}{N}\\sum_{\\tau\\in T_{r}}l_{\\tau}^{(j)}(\\mathbf{u}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "During each batch, our algorithmic framework does not change the decision, i.e., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\forall j\\in[M],\\,t\\in T_{r},\\quad\\mathbf{u}_{t}^{(j)}=\\mathbf{u}_{(r-1)N+1}^{(j)}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Thus the regret can be decomposed as follows, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left(l_{t}^{(j)}(\\mathbf{u}_{t}^{(j)})-l_{t}^{(j)}(\\mathbf{v})\\right)=\\displaystyle\\frac{1}{M}\\sum_{r=1}^{R}\\left[\\sum_{t\\in T_{r}}\\sum_{j=1}^{M}\\left(l_{t}^{(j)}(\\mathbf{u}_{(r-1)N+1}^{(j)})-l_{t}^{(j)}(\\mathbf{v})\\right)\\right]}\\\\ &{\\displaystyle=\\frac{N}{M}\\sum_{r=1}^{R}\\left[\\sum_{j=1}^{M}\\sum_{t\\in T_{r}}\\frac{1}{N}\\left(l_{t}^{(j)}(\\mathbf{u}_{(r-1)N+1}^{(j)})-l_{t}^{(j)}(\\mathbf{v})\\right)\\right]}\\\\ &{\\displaystyle=\\frac{N}{M}\\sum_{r=1}^{R}\\sum_{j=1}^{M}\\left(\\bar{l}_{r N}^{(j)}(\\mathbf{u}_{(r-1)N+1}^{(j)})-\\bar{l}_{r N}^{(j)}(\\mathbf{v})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "$R=T$ $\\{\\bar{l}_{r N}^{(1)},\\ldots,\\bar{l}_{r N}^{(M)}\\}_{r=1,\\ldots,R}$ use Theorem 1 to obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle\\frac{1}{N M}\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{j=1}^{M}\\left(l_{t}^{(j)}(\\mathbf{u}_{t}^{(j)})-l_{t}^{(j)}(\\mathbf{v})\\right)\\leq\\displaystyle\\sum_{t\\in\\mathcal{E}}\\left[\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{u}_{t+1})+\\frac{1}{2}\\mathcal{D}_{\\psi_{t}}(\\mathbf{u}_{t},\\mathbf{q}_{t+1})\\right]+}\\\\ {\\displaystyle\\frac{1}{2}\\sum_{t\\in\\mathcal{E}}\\mathcal{D}_{\\psi_{t}}(\\mathbf{u}_{t},\\mathbf{r}_{t+1})+\\displaystyle\\frac{1}{M}\\displaystyle\\sum_{t\\in\\mathcal{E}}\\displaystyle\\sum_{j=1}^{M}\\left\\langle\\tilde{g}_{t}^{(j)}-g_{t}^{(j)},\\mathbf{u}_{t}-\\mathbf{v}\\right\\rangle,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "FProof of Lemma 1 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Lemma 4 (Bernstein's inequality for martingale). Let $X_{1},\\ldots,X_{n}$ be a bounded martingale difference sequence w.r.t. the filtration $\\mathcal{H}=(\\mathcal{H}_{k})_{1\\leq k\\leq n}$ andwith $|X_{k}|\\leq a$ Let $\\begin{array}{r}{Z_{t}=\\sum_{k=1}^{t}X_{k}}\\end{array}$ bethe associated martingale. Denote the sum of the conditional variances by ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Sigma_{n}^{2}=\\sum_{k=1}^{n}\\mathbb{E}\\left[X_{k}^{2}|\\mathcal{H}_{k-1}\\right]\\leq v.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then for all constants $a,v>0,$ with probability at least $1-\\delta$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{t=1,\\ldots,n}Z_{t}<{\\frac{2}{3}}a\\ln{\\frac{1}{\\delta}}+{\\sqrt{2v\\ln{\\frac{1}{\\delta}}}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Note that $v$ must be a constant. Lemma 4 is derived from Lemma A.8 in [Cesa-Bianchi and Lugosi, 2006]. ", "page_idx": 20}, {"type": "text", "text": "Proof.Let $v\\in[0,B]$ is a random variable and $B\\geq2$ is a constant. We use the well-known peeling technique [Bartlett et al., 2005]. We divide the interval $[0,B]$ as follows ", "page_idx": 20}, {"type": "equation", "text": "$$\n[0,B]\\subseteq\\left[0,2^{-\\lceil\\log B\\rceil}\\right]\\bigcup_{j=-\\lceil\\log B\\rceil+1}^{\\lceil\\log B\\rceil}\\left(2^{j-1},2^{j}\\right].\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "First, we consider the case $v>2^{-\\lceil\\log B\\rceil}$ . Let ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\epsilon=\\frac{2}{3}a\\ln\\frac{1}{\\delta}+2\\sqrt{v\\ln\\frac{1}{\\delta}}>\\frac{2}{3}a\\ln\\frac{1}{\\delta}+2\\sqrt{2^{-1-\\log B}\\ln\\frac{1}{\\delta}}=\\frac{2}{3}a\\ln\\frac{1}{\\delta}+\\sqrt{\\frac{2}{B}\\ln\\frac{1}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We decompose the random event as follows, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{P}\\left[\\underset{t=1,\\ldots,n}{\\operatorname*{max}}Z_{t}>\\epsilon,\\Sigma_{n}^{2}\\leq v,v>2^{-\\lceil\\log B\\rceil}\\right]}\\\\ &{=\\!\\!\\mathbb{P}\\left[\\underset{t\\leq n}{\\operatorname*{max}}Z_{t}>\\epsilon,\\Sigma_{n}^{2}\\leq v,\\bigcup_{i=-\\lceil\\log B\\rceil+1}^{\\log B}\\!\\!2^{i-1}<v\\leq2^{i}\\right]}\\\\ &{\\leq\\!\\!\\mathbb{P}\\left[\\underset{t\\leq n}{\\operatorname*{max}}Z_{t}>\\epsilon_{i},\\Sigma_{n}^{2}\\leq v,\\bigcup_{i=-\\lceil\\log B\\rceil+1}^{\\log B}\\!\\!2^{i-1}<v\\leq2^{i}\\right]}\\\\ &{\\leq\\!\\!\\!\\!\\!\\sum_{i=-\\lceil\\log B\\rceil+1}^{\\lceil\\log B\\rceil}\\mathbb{P}\\left[\\underset{t\\leq n}{\\operatorname*{max}}Z_{t}>\\epsilon_{i},\\Sigma_{n}^{2}\\leq v,2^{i-1}<v\\leq2^{i}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\begin{array}{r}{\\epsilon_{i}=\\frac{2}{3}a\\ln\\frac{1}{\\delta}+2\\sqrt{2^{i-1}\\ln\\frac{1}{\\delta}}}\\end{array}$ . For each sub-event, Lemma 4 yields ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\operatorname*{max}_{t\\leq n}Z_{t}>\\epsilon_{i},\\Sigma_{n}^{2}\\leq v,2^{i-1}<v\\leq2^{i}\\right]\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\operatorname*{max}_{t\\in[n]}Z_{t}>\\epsilon,\\Sigma_{n}^{2}\\leq v,v>2^{-\\lceil\\log B\\rceil}\\right]\\leq\\sum_{i=-\\lceil\\log B\\rceil+1}^{\\lceil\\log B\\rceil}\\delta\\leq2\\lceil\\log B\\rceil\\delta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then we consider the case $\\begin{array}{r}{v\\leq2^{-\\lceil\\log B\\rceil}\\leq\\frac{1}{B}}\\end{array}$ . Lemma 4 yields, with probability at least $1-\\delta$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{t=1,\\ldots,n}Z_{t}\\leq\\!\\frac{2}{3}a\\ln\\frac{1}{\\delta}+\\sqrt{2^{1-\\lceil\\log B\\rceil}\\ln\\frac{1}{\\delta}}\\leq\\frac{2}{3}a\\ln\\frac{1}{\\delta}+\\sqrt{\\frac{2}{B}\\ln\\frac{1}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Combining the two cases, with probability at least $1-2\\lceil\\log B\\rceil\\delta$ \uff0c ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{t=1,\\ldots,n}Z_{t}\\leq\\frac{2a}{3}\\ln\\frac{1}{\\delta}+\\sqrt{\\frac{2}{B}\\ln\\frac{1}{\\delta}}+2\\sqrt{v\\ln\\frac{1}{\\delta}},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 20}, {"type": "text", "text": "G  Properties of Online Mirror Descent (OMD) ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "G.1  OMD with the weighted negative entropy regularizer ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Let $\\Omega=\\Delta_{K}$ and $\\begin{array}{r}{\\psi_{t}(\\mathbf{p})=\\sum_{i=1}^{K}\\frac{C_{i}}{\\eta_{t}}p_{i}\\ln p_{i}}\\end{array}$ . Then we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\forall\\mathbf{p}\\in\\mathbb{R}^{K},\\quad\\nabla_{p_{i}}\\psi_{t}(\\mathbf{p})=\\frac{C_{i}}{\\eta_{t}}\\left(\\ln p_{i}+1\\right),\\quad\\nabla_{i,i}^{2}\\psi_{t}(\\mathbf{p})=\\frac{C_{i}}{\\eta_{t}p_{i}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The Bregman divergence associated with the negative entropy regularizer is ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{D}_{\\psi_{t}}({\\bf p},{\\bf q})=\\frac{1}{\\eta_{t}}\\sum_{i=1}^{K}C_{i}\\left(p_{i}\\ln\\frac{p_{i}}{q_{i}}+q_{i}-p_{i}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Denote by $\\begin{array}{r}{\\bar{\\mathbf{c}}_{t}=\\frac{1}{M}\\sum_{j=1}^{M}\\tilde{\\mathbf{c}}_{t}^{(j)}}\\end{array}$ . Recalling that the OMD is defined as follows, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\nabla_{\\bar{\\mathbf{p}}_{t+1}}\\psi_{t}(\\bar{\\mathbf{p}}_{t+1})=\\nabla_{\\mathbf{p}_{t}}\\psi_{t}(\\mathbf{p}_{t})-\\bar{\\mathbf{c}}_{t},\\quad\\mathbf{p}_{t+1}=\\arg\\operatorname*{min}_{\\mathbf{p}\\in\\Delta_{K}}\\mathcal{D}_{\\psi_{t}}\\big(\\mathbf{p},\\bar{\\mathbf{p}}_{t+1}\\big).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Substituting into the gradient of $\\psi_{t}$ , the mirror updating can be simplified. ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\forall i\\in[K],\\quad\\bar{p}_{t+1,i}=p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}\\bar{c}_{t,i}}{C_{i}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now we use the Lagrangian multiplier method to solve the projection associated with Bregman divergence. ", "page_idx": 21}, {"type": "equation", "text": "$$\nL(\\mathbf{p},\\lambda)=\\frac{1}{\\eta_{t}}\\sum_{i=1}^{K}C_{i}\\left(p_{i}\\ln\\frac{p_{i}}{\\bar{p}_{t+1,i}}+\\bar{p}_{t+1,i}-p_{i}\\right)+\\lambda\\left(\\sum_{i=1}^{K}p_{i}-1\\right)-\\sum_{i=1}^{K}\\beta_{i}p_{i}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The KKT conditions are ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\frac{\\partial{\\cal L}}{\\partial p_{i}}=C_{i}\\frac{\\ln p_{i}+1-\\ln\\bar{p}_{t+1,i}-1}{\\eta_{t}}+\\lambda-\\beta_{i}=0,}\\\\ {\\displaystyle\\frac{\\partial{\\cal L}}{\\partial\\lambda}=\\left(\\sum_{i=1}^{K}p_{i}-1\\right)=0,}\\\\ {\\displaystyle\\beta_{i}p_{i}=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Let $\\mathbf{p}_{t+1}$ $\\lambda^{*}$ and $\\{\\beta_{i}^{*}\\}_{i=1}^{K}$ be the optimal solution. By the KKT conditions, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle p_{t+1,i}=\\bar{p}_{t+1,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda^{*}-\\beta_{i}^{*})}{C_{i}}\\right),}\\\\ {\\displaystyle\\sum_{i=1}^{K}\\bar{p}_{t+1,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda^{*}-\\beta_{i}^{*})}{C_{i}}\\right)=\\displaystyle\\sum_{i=1}^{K}p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda^{*}-\\beta_{i}^{*}+\\bar{c}_{t,i})}{C_{i}}\\right)=1,}\\\\ {\\displaystyle\\beta_{i}^{*}=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "in which the last equality comes from $p_{t+1,i}>0$ . The reason is that by the fact $p_{1,i}\\,>\\,0$ for all $i\\in[K]$ , we can iteratively prove that $p_{t,i}>0$ and $p_{t+1,i}>0$ , satisfying the condition under which $\\beta_{i}^{*}=0$ . Then we can obtain the solution $\\mathbf{p}_{t+1}$ ,i.e., ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\forall i\\in[K],\\quad p_{t+1,i}=p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda^{*}+\\bar{c}_{t,i})}{C_{i}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Next we prove that $\\lambda^{*}$ can be found by the binary search. ", "page_idx": 21}, {"type": "text", "text": "$\\lambda^{*}\\geq0$ then $\\begin{array}{r}{\\sum_{i=1}^{K}p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda^{*}+\\bar{c}_{t,i})}{C_{i}}\\right)\\leq\\sum_{i=1}^{K}p_{t,i}\\leq1.}\\end{array}$ f $\\lambda^{*}\\leq-\\operatorname*{max}_{i}\\bar{c}_{t,i}$ thn $\\begin{array}{r}{\\sum_{i=1}^{K}p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda^{*}+\\bar{c}_{t,i})}{C_{i}}\\right)\\geq\\sum_{i=1}^{K}p_{t,i}\\geq1.}\\end{array}$ Thus it must be $-\\operatorname*{max}_{i}\\bar{c}_{t,i}\\leq\\lambda^{*}\\leq0$ . For any $0\\geq\\lambda_{1}\\geq\\lambda_{2}\\geq-\\operatorname*{max}_{i}\\bar{c}_{t,i}$ we can obtain ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{K}p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda_{1}+\\bar{c}_{t,i})}{C_{i}}\\right)\\leq\\sum_{i=1}^{K}p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}(\\lambda_{2}+\\bar{c}_{t,i})}{C_{i}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus $\\begin{array}{r}{\\sum_{i=1}^{K}p_{t,i}\\cdot\\exp{\\left(-\\frac{\\eta_{t}\\left(\\lambda^{*}+\\bar{c}_{t,i}\\right)}{C_{i}}\\right)}}\\end{array}$ is non-increasing w.t. $\\lambda^{*}$ ", "page_idx": 21}, {"type": "text", "text": "We can use the binary search to find $\\lambda^{*}$ ", "page_idx": 21}, {"type": "text", "text": "G.2  OMD with the Euclidean regularizer ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Let $\\Omega=\\mathcal{F}_{i}$ and $\\begin{array}{r}{\\psi_{t,i}(\\mathbf{w})=\\frac{1}{2\\lambda_{t,i}}\\|\\mathbf{w}\\|_{2}^{2}}\\end{array}$ Then we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\forall\\mathbf{w}\\in\\mathbb{R}^{d_{i}},\\quad\\nabla_{\\mathbf{w}}\\psi_{t,i}(\\mathbf{w})=\\frac{1}{\\lambda_{t,i}}\\mathbf{w},\\quad\\nabla_{\\mathbf{w}}^{2}\\psi_{t,i}(\\mathbf{w})=\\frac{1}{\\lambda_{t,i}},\\quad\\mathcal{D}_{\\psi_{t,i}}(\\mathbf{w},\\mathbf{v})=\\frac{1}{2\\lambda_{t,i}}\\|\\mathbf{w}-\\mathbf{v}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Recalling that the OMD is defined as follows, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla_{\\overline{{\\mathbf{w}}}_{t+1,i}}\\psi_{t,i}(\\overline{{\\mathbf{w}}}_{t+1,i})=\\nabla_{\\mathbf{w}_{t,i}}\\psi_{t}(\\mathbf{w}_{t,i})-\\bar{\\nabla}_{t,i},\\quad\\mathbf{w}_{t+1,i}=\\underset{\\mathbf{w}\\in\\mathcal{F}_{i}}{\\arg\\operatorname*{min}}\\mathcal{D}_{\\psi_{t,i}}\\big(\\mathbf{w},\\bar{\\mathbf{w}}_{t+1,i}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The mirror updating is as follows, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\forall i\\in[K],\\quad\\bar{\\mathbf{w}}_{t+1,i}=\\mathbf{w}_{t,i}-\\lambda_{t,i}\\cdot\\bar{\\nabla}_{t,i},}\\\\ &{\\mathbf{w}_{t+1,i}=\\operatorname*{min}\\left\\{1,\\frac{U_{i}}{\\|\\bar{\\mathbf{w}}_{t+1,i}\\|_{2}}\\right\\}\\cdot\\bar{\\mathbf{w}}_{t+1,i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus OMD with the Euclidean regularizer is online gradient descent [Zinkevich, 2003]. ", "page_idx": 22}, {"type": "text", "text": "H Proof of Lemma 2 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Recalling that c. $c_{t,i}^{(j)}=\\ell(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)})$ , in which ", "page_idx": 22}, {"type": "equation", "text": "$$\nf_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)})=\\langle\\mathbf{w}_{t,i}^{(j)},\\phi_{i}(\\mathbf{x}_{t}^{(j)})\\rangle\\leq U_{i}b_{i}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since $|y_{t}^{(j)}|$ is uniformly bounded for ll $j\\in[M]$ and $t\\in[T]$ , there is a constant $C_{i}$ that depends on $U_{i}$ and $b_{i}$ such that $c_{t,i}^{(j)}\\leq C_{i}$ ", "page_idx": 22}, {"type": "text", "text": "Recalling that $\\nabla_{t,i}^{(j)}=\\ell^{\\prime}(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)})\\cdot\\phi_{i}(\\mathbf{x}_{t}^{(j)})$ Since $\\ell(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)})$ can be upper bounded by $C_{i}$ and $\\|\\phi_{i}(\\mathbf{x}_{t}^{(j)})\\|_{2}\\le b_{i}$ , there is a constant $G_{i}$ that depends on $U_{i}$ and $b_{i}$ such that $\\|\\nabla_{t,i}^{(j)}\\|_{2}\\leq G_{i}$ ", "page_idx": 22}, {"type": "text", "text": "1 Proof of Theorem 2 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The regret w.r.t. any $f\\in\\mathcal{F}_{i}$ can be decomposed as follows. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{j=1}^{M}\\ell\\left(f_{t,A_{t,1}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\displaystyle\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\ell\\left(f(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)}\\\\ &{=\\displaystyle\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left[\\ell\\left(f_{t,A_{t,1}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\ell\\left(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)+\\ell\\left(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\ell\\left(f(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]}\\\\ &{=\\displaystyle\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left[c_{t,i_{t,1}}^{(j)}-c_{t,i}^{(j)}\\right]+\\displaystyle\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left[\\ell\\left(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\ell\\left(f(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Next we separately give an upper bound on $\\Xi_{4}$ and $\\Xi_{5}$ ", "page_idx": 22}, {"type": "text", "text": "1.1  Analyzing $\\Xi_{4}$ ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We start with Lemma 1 and instantiate some notations. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Omega=\\Delta_{K},\\quad{\\bf v}={\\bf v}\\in\\Delta_{K},}\\\\ &{\\forall t\\in[T],\\ \\ {\\bf\\boldsymbol{g}}_{t}^{(j)}={\\bf{c}}_{t}^{(j)},\\quad{\\tilde{\\boldsymbol{g}}}_{t}^{(j)}={\\tilde{\\bf\\boldsymbol{c}}}_{t}^{(j)},\\quad{\\bar{\\boldsymbol{g}}}_{t}={\\bar{\\bf\\boldsymbol{c}}}_{t},\\quad{\\bf u}_{t}^{(j)}={\\bf p}_{t}^{(j)},\\quad{\\bf u}_{t}={\\bf p}_{t},}\\\\ &{l_{t}^{j}({\\bf u}_{t}^{j})=\\left\\langle{\\bf c}_{t}^{(j)},{\\bf p}_{t}^{(j)}\\right\\rangle,\\quad l_{t}^{j}({\\bf v})=\\left\\langle{\\bf c}_{t}^{(j)},{\\bf v}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma 1 gives, $\\forall\\mathbf{v}\\in\\Delta_{K}$ \uff0c", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left<\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}-\\mathbf{v}\\right>}\\\\ {\\displaystyle\\leq\\sum_{t=1}^{T}\\left(\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{p}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{p}_{t+1})\\right)+\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{\\psi_{t}}(\\mathbf{p}_{t},\\mathbf{q}_{t+1})+\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{\\psi_{t}}(\\mathbf{p}_{t},\\mathbf{r}_{t+1})+}\\\\ {\\displaystyle\\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left<\\tilde{\\mathbf{c}}_{t}^{(j)}-\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}-\\mathbf{v}\\right>.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Recalling that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\nabla_{{\\bf q}_{t+1}}\\psi_{t}({\\bf q}_{t+1})=\\nabla_{{\\bf u}_{t}}\\psi_{t}({\\bf u}_{t})-2\\sum_{j=1}^{M}\\frac{\\tilde{g}_{t}^{(j)}-g_{t}^{(j)}}{M},}}\\\\ {{\\displaystyle\\nabla_{{\\bf r}_{t+1}}\\psi_{t}({\\bf r}_{t+1})=\\nabla_{{\\bf u}_{t}}\\psi_{t}({\\bf u}_{t})-\\frac{2}{M}\\sum_{j=1}^{M}g_{t}^{(j)}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In (13), we redefine $\\Omega=\\Delta_{K}$ and $\\begin{array}{r}{\\psi_{t}(\\mathbf{p})=\\sum_{i=1}^{K}\\frac{C_{i}}{\\eta_{t}}p_{i}\\ln p_{i}}\\end{array}$ ad i (14) we redefine $\\Omega=\\Delta_{K}$ and $\\begin{array}{r}{\\psi_{t}(\\mathbf{p})=\\sum_{i=1}^{K}\\frac{2C_{i}}{\\eta_{t}}p_{i}\\ln p_{i}}\\end{array}$ Uinghr ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\forall i\\in[K],\\quad q_{t+1,i}=p_{t,i}\\exp\\left(-\\frac{\\eta_{t}\\delta_{t,i}}{C_{i}}\\right),\\quad\\delta_{t,i}=\\displaystyle\\frac{2}{M}\\sum_{j=1}^{M}\\left(\\tilde{c}_{t,i}^{(j)}-c_{t,i}^{(j)}\\right),}\\\\ &{r_{t+1,i}=p_{t,i}\\exp\\left(-\\frac{\\eta_{t}\\hat{c}_{t,i}}{2C_{i}}\\right),\\quad\\hat{c}_{t,i}=\\displaystyle\\frac{2}{M}\\sum_{j=1}^{M}c_{t,i}^{(j)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "It can be verified that $\\begin{array}{r}{\\delta_{t,i}\\in[-2C_{i},2\\frac{K-J}{J-1}C_{i}]}\\end{array}$ and $\\hat{c}_{t,i}\\in[0,2C_{i}]$ ", "page_idx": 23}, {"type": "text", "text": "Recalling the defnition of learning rate $\\eta_{t}$ in Theorem 2. We can obtain $\\begin{array}{r}{\\frac{\\eta_{t}\\delta_{t,i}}{C_{i}}\\geq-1}\\end{array}$ and $\\begin{array}{r}{\\frac{\\eta_{t}\\hat{c}_{t,i}}{2C_{i}}\\geq-1}\\end{array}$ Next we use (10) and (15) to analyze the following two Bregman divergences. ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{\\psi_{i}}(\\mathbf{p}_{t},\\mathbf{r}_{t+1})=\\displaystyle\\sum_{t=1}^{T}\\frac{1}{\\eta_{t}}\\displaystyle\\sum_{i=1}^{K}2C_{i}\\,\\cdot\\left(p_{t,i}\\ln\\frac{p_{t,i}}{r_{t+1,i}}+r_{t+1,i}-p_{t,i}\\right)}\\\\ &{\\!=\\!\\displaystyle\\sum_{t=1}^{T}\\frac{1}{\\eta_{t}}\\displaystyle\\sum_{i=1}^{K}2C_{i}\\,\\cdot\\left(\\frac{p_{t,i}\\eta_{t}\\tilde{e}_{t,i}}{2C_{i}}+p_{t,i}\\cdot\\exp{\\left(-\\frac{\\eta_{t}\\tilde{e}_{t,i}}{2C_{i}}\\right)}-p_{t,i}\\right)}\\\\ &{\\!\\leq\\!\\displaystyle\\sum_{t=1}^{T}\\frac{1}{\\eta_{t}}\\displaystyle\\sum_{i=1}^{K}2C_{i}\\,\\cdot\\left(\\frac{p_{t,i}\\eta_{t}\\tilde{e}_{t,i}}{2C_{i}}+p_{t,i}\\cdot\\left(1-\\frac{\\eta_{t}\\tilde{e}_{t,i}}{2C_{i}}+\\left(\\frac{\\eta_{t}\\tilde{e}_{t,i}}{2C_{i}}\\right)^{2}\\right)-p_{t,i}\\right)}\\\\ &{\\!\\leq\\!\\displaystyle\\sum_{t=1}^{T}\\eta_{t}\\displaystyle\\sum_{i=1}^{K}\\frac{p_{t,i}}{2C_{i}}\\left(\\frac{2}{M}\\sum_{j=1}^{M}c_{t,i}^{(j)}\\right)^{2}}\\\\ &{\\!\\leq\\!\\displaystyle2\\sum_{t=1}^{T}\\eta_{t}\\cdot\\frac{1}{M}\\displaystyle\\sum_{j=1}^{M}p_{t,i}c_{t,i}^{(j)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{\\psi_{t}}(\\mathbf{p}_{t},\\mathbf{q}_{t+1})=\\sum_{t=1}^{T}\\frac{1}{\\eta_{t}}\\sum_{i=1}^{K}C_{i}\\left(p_{t,i}\\ln\\frac{p_{t,i}}{q_{t+1,i}}+q_{t+1,i}-p_{t,i}\\right)}\\\\ &{\\displaystyle=\\sum_{t=1}^{T}\\frac{1}{\\eta_{t}}\\sum_{i=1}^{K}C_{i}\\left(\\frac{p_{t,i}\\eta_{t}\\delta_{t,i}}{C_{i}}+p_{t,i}\\cdot\\exp\\left(-\\frac{\\eta_{t}\\delta_{t,i}}{C_{i}}\\right)-p_{t,i}\\right)}\\\\ &{\\displaystyle\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\leq4\\sum_{t=1}^{T}\\eta_{t}\\sum_{i=1}^{K}\\frac{p_{t,i}}{C_{i}}\\left(\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{c}_{t,i}^{(j)}-c_{t,i}^{(j)}\\right)\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "in where we use the fact $\\exp(-x)\\leq1-x+x^{2}$ for all $x\\geq-1$ ", "page_idx": 24}, {"type": "text", "text": "Substituting the two upper bounds into (12) gives ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\in\\Delta_{K},\\quad\\displaystyle\\frac{1}{M}\\sum_{\\underset{j=1}{\\overset{r\\_{M}}{\\sum}}}^{T}\\left<\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}-\\mathbf{v}\\right>}\\\\ &{\\leq\\displaystyle\\sum_{\\underset{j=1}{\\overset{r\\_{M}}{\\sum}}}^{T}(\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{p}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{v},\\mathbf{p}_{t+1}))+2\\sum_{t=1}^{T}\\eta\\sum_{i=1}^{K}\\frac{p_{t,i}}{C_{i}}\\left(\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{c}_{t,i}^{(j)}-c_{t,i}^{(j)}\\right)\\right)^{2}+}\\\\ &{\\ \\ \\ \\displaystyle\\sum_{t=1}^{T}\\frac{\\eta}{M}\\sum_{j=1}^{M}p_{t,i}c_{t,i}^{(j)}+\\underbrace{\\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left<\\bar{c}_{t}^{(j)}-c_{t}^{(j)},\\mathbf{p}_{t}-\\mathbf{v}\\right>}_{\\underset{j=1}{\\overset{r\\_{M}}{\\sum}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Bounding $\\Xi_{4,1}$ ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We define a random variable $X_{t}$ as follows, ", "page_idx": 24}, {"type": "equation", "text": "$$\nX_{t}=c_{t,A_{t,1}}^{(j)}-\\left<\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}\\right>.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Let $H_{t}=\\{O_{t}^{(1)},\\dots,O_{t}^{(M)}\\}$ Then we have $\\mathbb{E}[X_{t}|H_{[t-1]}]=0$ and $\\left|X_{t}\\right|\\leq C$ where $C=\\operatorname*{max}_{i}C_{i}$ Thus $X_{[T]}$ is a bounded martingale difference sequence w.r.t. the filtration $H_{[T]}$ . The sum of condition variance satisfies ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{E}\\left[\\left|X_{t}\\right|^{2}\\left|H_{[t-1]}\\right]\\leq\\sum_{t=1}^{T}\\mathbb{E}\\left[\\left|c_{t,A_{t,1}}^{(j)}\\right|^{2}\\left|H_{[t-1]}\\right.\\right]\\leq C\\cdot\\sum_{t=1}^{T}\\left\\langle\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}\\right\\rangle\\leq C^{2}T.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The upper bound is a random variable. Lemma 1 yields, with probability at least $1-M\\log(C^{2}T)\\delta,$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\Xi_{4,1}\\geq\\sum_{t=1}^{T}\\sum_{j=1}^{M}c_{t,A_{t,1}}^{(j)}-\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left<\\mathbf{c}_{t}^{(j)},\\mathbf{v}\\right>-\\frac{2C M}{3}\\ln\\frac{1}{\\delta}-2\\sqrt{C M\\cdot\\sum_{j=1}^{M}\\sum_{t=1}^{T}\\left<\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}\\right>\\cdot\\ln\\frac{1}{\\delta}},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the fail probability comes from the union-of-events, and the lower order term $M{\\sqrt{{\\frac{2}{C^{2}T}}\\ln{\\frac{1}{\\delta}}}}$ is omitted. ", "page_idx": 24}, {"type": "text", "text": "Bounding $\\Xi_{4,2}$ ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "According to (10), we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\Xi_{4,2}\\leq\\mathcal{D}_{\\psi_{1}}(\\mathbf{v},\\mathbf{p}_{1})=\\frac{1}{\\eta}\\sum_{i=1}^{K}C_{i}\\left(v_{i}\\ln\\frac{v_{i}}{p_{1,i}}+p_{1,i}-v_{i}\\right)\\leq\\frac{C_{i}}{\\eta}\\ln\\frac{1}{p_{1,i}}+\\frac{1}{\\eta}\\sum_{k=1}^{K}C_{k}p_{1,k}-\\frac{C_{i}}{\\eta}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Bounding $\\Xi_{4,3}$ ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We define a random variable $X_{t}$ as follows, ", "page_idx": 25}, {"type": "equation", "text": "$$\nX_{t}=\\sum_{i=1}^{K}\\frac{p_{t,i}}{C_{i}}\\left(\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{c}_{t,i}^{(j)}-c_{t,i}^{(j)}\\right)\\right)^{2}-\\mathbb{E}_{t}\\left[\\sum_{i=1}^{K}\\frac{p_{t,i}}{C_{i}}\\left(\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{c}_{t,i}^{(j)}-c_{t,i}^{(j)}\\right)\\right)^{2}\\right].\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "It can be verified that $\\mathbb{E}[X_{t}|H_{[t-1]}]\\,=\\,0$ and $\\begin{array}{r}{|X_{t}|\\,\\le\\,\\frac{K-J}{J-1}C}\\end{array}$ . Next we upper bound the sum of condition variance. ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{T}{\\underset{t=1}{\\overset{n}{\\sum}}}\\mathbb{E}_{\\xi}[X_{t}^{2}]\\leq\\frac{T}{\\underset{t=1}{\\overset{n}{\\sum}}}\\mathbb{E}_{\\xi}\\left[\\left(\\underset{t=1}{\\overset{N}{\\sum}}\\frac{p_{t,t}}{C_{t}^{\\frac{1}{\\ell}}}\\left(\\frac{1}{M_{p-1}^{\\frac{1}{\\ell}}}\\left(\\frac{u_{t}^{2}}{t_{\\xi}^{\\frac{1}{n}}-c_{\\xi}^{\\frac{1}{\\ell}}}\\right)\\right)\\right)^{2}\\right]}\\\\ &{\\leq\\frac{T}{\\underset{t=1}{\\overset{n}{\\sum}}}\\mathbb{E}_{\\xi}\\left[\\underset{t=1}{\\overset{N}{\\sum}}\\frac{p_{t,t}}{\\left(\\frac{\\sum}{\\xi_{t}^{\\frac{1}{n}}}+\\frac{1}{M_{p-1}^{\\frac{1}{\\ell}}}\\left(\\frac{1}{M_{p-1}^{\\frac{1}{\\ell}}}\\left(\\frac{u_{t}^{2}}{t_{\\xi}^{\\frac{1}{n}}-c_{\\xi}^{\\frac{1}{\\ell}}}\\right)\\right)\\right)^{2}\\right]}\\\\ &{\\leq\\frac{(K-\\beta^{2})^{2}}{(2-1)^{3}}\\frac{T}{\\underset{t=1}{\\overset{n}{\\sum}}}\\underset{t=1}{\\overset{n}{\\sum}}\\Bigg[\\underset{t=1}{\\overset{N}{\\sum}}p_{t,t}\\left(\\frac{1}{M_{p-1}^{\\frac{1}{\\ell}}}\\left(\\frac{u_{t}^{2}}{t_{\\xi}^{\\frac{1}{n}}-c_{\\xi}^{\\frac{1}{\\ell}}}\\right)\\right)^{2}\\Bigg]}\\\\ &{=\\frac{(K-\\beta^{2})^{2}}{(2-1)^{3}}\\frac{T}{\\underset{t=1}{\\overset{n}{\\sum}}}\\sum_{i=1}^{K}\\underset{t=1}{\\overset{n}{\\sum}}\\Bigg[\\underset{t=1}{\\overset{N}{\\sum}}\\left(\\frac{u_{t}^{2}}{t_{\\xi}^{\\frac{1}{n}}-c_{\\xi}^{\\frac{1}{\\ell}}}\\right)^{2}\\Bigg]}\\\\ &{\\leq\\frac{(K-\\beta^{2})^{3}}{(2-1)^{\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "$\\begin{array}{r}{\\tilde{c}_{t,i}^{(j)}\\,=\\,\\frac{c_{t,i}^{(j)}}{\\mathbb{P}\\left[i\\in O_{t}^{(j)}\\right]}\\,\\ge\\,\\frac{K-1}{J-1}c_{t,i}^{(j)}\\,}\\end{array}$ K2 . Lemma 1 yields, with probability at least $1-\\log(C^{2}K^{3}T/M)\\delta,$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\bar{\\mathfrak{z}}_{4,3}\\leq\\eta\\left(\\frac{g_{K,J}}{M^{2}}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}\\right\\rangle+\\frac{2C g_{K,J}}{3}\\ln\\frac{1}{\\delta}+2\\sqrt{\\frac{g_{K,J}^{3}}{M^{2}}C}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}\\right\\rangle\\cdot\\ln\\frac{1}{\\delta}\\right),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\begin{array}{r}{g_{K,J}=\\frac{K-J}{J-1}}\\end{array}$ and the lower order term $\\sqrt{\\frac{2M}{g_{K,J}^{3}C^{2}T}\\ln\\frac{1}{\\delta}}$ is omitted. ", "page_idx": 25}, {"type": "text", "text": "Bounding $\\Xi_{4,4}$ ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We define a random variable $X_{t}$ as follows, ", "page_idx": 25}, {"type": "equation", "text": "$$\nX_{t}=\\left\\langle\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\mathbf{c}}_{t}^{(j)}-\\mathbf{c}_{t}^{(j)}\\right),\\mathbf{p}_{t}-\\mathbf{v}\\right\\rangle=\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\sum_{i=1}^{K}(p_{t,i}-v_{i})\\left(\\tilde{c}_{t,i}^{(j)}-c_{t,i}^{(j)}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "$\\{X_{t}\\}_{t=1}^{T}$ is a bounded martingale difference sequence and $|X_{t}|\\le g_{K,J}C$ . We further have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\frac{1}{2M}\\sum_{i=1}^{M/1}\\mathscr{E}_{i}\\left[\\displaystyle\\sum_{j=1}^{M}\\left(\\sum_{l=1}^{K}\\left(\\gamma_{l}-\\nu_{l}\\right)\\left(\\hat{e}_{l,l}^{(j)}-\\epsilon_{l,j}^{(j)}\\right)\\right)^{2}\\right]+}\\\\ &{\\quad\\frac{1}{M^{2}}\\sum_{i=1}^{M}\\sum_{j=1}^{M}\\left[\\sum_{l=1}^{M}\\left(\\sum_{l=1}^{K}\\left(\\gamma_{l}-\\nu_{l}\\right)\\left(\\hat{e}_{l,l}^{(j)}-\\epsilon_{l,j}^{(j)}\\right)\\right)^{2}\\right]+}\\\\ &{\\quad\\frac{1}{M^{2}}\\sum_{i=1}^{M}\\sum_{j=1}^{M}\\left[\\sum_{l=1}^{M}\\left(\\sum_{l=1}^{K}\\left(\\beta_{l-i}-\\nu_{l}\\right)\\left(\\hat{e}_{l,l}^{(j)}-\\epsilon_{l,j}^{(j)}\\right)\\right)\\left(\\sum_{l=1}^{K}\\left(\\beta_{l-i}-\\nu_{l}\\right)\\left(\\hat{e}_{l,l}^{(j)}-\\epsilon_{l,j}^{(j)}\\right)\\right)\\right]}\\\\ &{=\\frac{1}{M^{2}}\\sum_{i=1}^{M}\\sum_{j=1}^{M}\\mathscr{E}_{i}\\left[\\left(\\sum_{l=1}^{K}\\left(\\beta_{l-i}-\\nu_{l}\\right)\\left(\\hat{e}_{l,l}^{(j)}-\\epsilon_{l,j}^{(j)}\\right)\\right)^{2}\\right]}\\\\ &{\\quad2\\frac{2}{M^{2}}\\sum_{i=1}^{M}\\mathscr{E}_{i}\\left[\\left(\\sum_{l=1}^{K}\\beta_{l-i}\\left(\\hat{e}_{l,l}^{(j)}-\\hat{e}_{l,j}^{(j)}\\right)\\right)^{2}\\right]+\\frac{2}{M^{2}}\\sum_{l=1}^{M}\\sum_{l=1}^{M}\\mathbb{E}_{i}\\left[\\left(\\sum_{l=1}^{K}\\nu_{l}\\left(\\hat{e}_{l,l}^{(j)}-\\epsilon_{l,j}^{(j)}\\right)\\right)^{2}\\right]}\\\\ &{\\quad\\leq2\\frac{2}{M^{2}}\\sum_{j=1}^{M}\\mathscr{E}_{i}\\left[\\\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\begin{array}{r}{\\left\\langle\\mathbf{c}_{t}^{(j)}\\otimes\\mathbf{c}_{t}^{(j)},\\mathbf{v}\\right\\rangle=\\sum_{i=1}^{K}v_{i}(c_{t,i}^{(j)})^{2}}\\end{array}$ ", "page_idx": 26}, {"type": "text", "text": "With probability at least $1-\\log(4C^{2}K T/M)\\delta$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\Xi_{4,4}\\leq\\frac{2C g_{K,J}}{3}\\ln\\frac{1}{\\delta}+2\\sqrt{2\\frac{g_{K,J}}{M^{2}}\\ln\\frac{1}{\\delta}}\\cdot\\sqrt{C\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\Big\\langle\\mathbf{c}_{t}^{(j)},\\mathbf{p}_{t}^{(j)}\\Big\\rangle+\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\Big\\langle\\mathbf{c}_{t}^{(j)}\\otimes\\mathbf{c}_{t}^{(j)},\\mathbf{v}\\Big\\rangle}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "For simplicity, we introduce some new notations ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\bar{L}_{T}=\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\mathbf c_{t}^{(j)},\\mathbf p_{t}^{(j)}\\right\\rangle,\\quad\\bar{L}_{T}(\\mathbf v)=\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\mathbf c_{t}^{(j)},\\mathbf v\\right\\rangle,\\quad\\tilde{L}_{T}(\\mathbf v)=\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\mathbf c_{t}^{(j)}\\otimes\\mathbf c_{t}^{(j)},\\mathbf v\\right\\rangle.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining all ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Combining all gives, with probability at least $1-\\Theta(\\log(C K T/M))\\cdot\\delta$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\bar{L}_{T}-\\bar{L}_{T}(\\mathbf v)\\leq\\displaystyle\\frac{M}{\\eta}\\left(C_{i}\\ln\\frac{1}{p_{1,i}}+\\sum_{k=1}^{K}C_{k}p_{1,k}-C_{i}\\right)+}}\\\\ {{\\eta\\left(\\left(1+\\frac{g_{K,J}}{M}\\right)\\bar{L}_{T}+\\frac{2M C}{3}g_{K,J}\\ln\\frac{1}{\\delta}+2\\sqrt{g_{K,J}^{3}C\\cdot\\bar{L}_{T}\\cdot\\ln\\frac{1}{\\delta}}\\right)+}}\\\\ {{\\frac{2M C g_{K,J}}{3}\\ln\\frac{1}{\\delta}+2\\sqrt{2g_{K,J}\\ln\\frac{1}{\\delta}}\\cdot\\sqrt{C\\bar{L}_{T}+\\tilde{L}_{T}(\\mathbf v)}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Rearranging terms gives ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\left(1-\\eta\\left(1+\\frac{{\\displaystyle g}_{K,J}}{M}\\right)\\right)\\bar{L}_{T}-\\left(2\\eta\\sqrt{g_{K,J}^{3}C\\ln\\frac{1}{\\delta}}+2\\sqrt{2g_{K,J}C\\ln\\frac{1}{\\delta}}\\right)\\sqrt{\\bar{L}_{T}}}\\\\ {\\mathrm{\\le}\\bar{L}_{T}({\\bf v})+\\frac{M}{\\eta}\\left(C_{i}\\ln\\frac{1}{p_{1,i}}+\\displaystyle\\sum_{k=1}^{K}C_{k}p_{1,k}-C_{i}\\right)+\\frac{4M C g_{K,J}}{3}\\ln\\frac{1}{\\delta}+2\\sqrt{2g_{K,J}\\ln\\frac{1}{\\delta}}\\cdot\\sqrt{\\tilde{L}_{T}({\\bf v})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Recalling that, the solution of the following inequality ", "page_idx": 27}, {"type": "equation", "text": "$$\nx-a{\\sqrt{x}}-b\\leq0,x>0,a>0,b>0,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": ".is $x\\leq a^{2}+b+a{\\sqrt{b}}$ Solving for $\\bar{L}_{T}$ gives ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\bar{L}_{T}-\\bar{L}_{T}(\\mathbf{v})\\leq\\frac{\\left(2\\eta\\sqrt{g_{K,J}^{3}C\\ln\\frac{1}{\\delta}}+2\\sqrt{2g_{K,J}C\\ln\\frac{1}{\\delta}}\\right)^{2}}{\\left(1-\\eta\\left(1+\\frac{g_{K,J}}{M}\\right)\\right)^{2}}+\\frac{2\\eta\\sqrt{g_{K,J}^{3}C\\ln\\frac{1}{\\delta}}+2\\sqrt{2g_{K,J}C\\ln\\frac{1}{\\delta}}}{\\left(1-\\eta\\left(1+\\frac{g_{K,J}}{M}\\right)\\right)^{\\frac{3}{2}}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\sqrt{\\bar{L}_{T}({\\bf v})+\\frac{M}{\\eta}\\left(C_{i}\\ln\\frac{1}{p_{1,i}}+\\sum_{k=1}^{K}C_{k}p_{1,k}-C_{i}\\right)+\\frac{4M C g_{K,J}}{3}\\ln\\frac{1}{\\delta}+2\\sqrt{2g_{K,J}\\ln\\frac{1}{\\delta}}\\cdot\\sqrt{\\tilde{L}_{T}({\\bf v})}+\\frac{1}{\\eta}\\displaystyle\\sqrt{\\frac{\\eta}{b}}\\left(\\frac{1}{p_{1,i}}\\right)}}\\\\ {{\\displaystyle\\frac{\\eta\\left(1+\\frac{g_{K,J}}{M}\\right)}{1-\\eta\\left(1+\\frac{g_{K,J}}{M}\\right)}\\bar{L}_{T}({\\bf v})+}}\\\\ {{\\displaystyle\\frac{M}{\\eta}\\left(C_{i}\\ln\\frac{1}{p_{1,i}}+\\sum_{k=1}^{K}C_{k}p_{1,k}-C_{i}\\right)+\\frac{4M C g_{K,J}}{3}\\ln\\frac{1}{\\delta}+2\\sqrt{2g_{K,J}\\ln\\frac{1}{\\delta}}\\cdot\\sqrt{\\tilde{L}_{T}({\\bf v})}}}\\\\ {{\\displaystyle1-\\eta\\left(1+\\frac{g_{K,J}}{M}\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Denote by $A_{m}=\\mathrm{argmin}_{i\\in[K]}C_{i}$ . Let the learning rate and initial distribution $\\mathbf{p}_{1}$ satisfy ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\eta=\\frac{\\sqrt{\\ln\\left(K T\\right)}}{2\\sqrt{\\left(1+\\frac{K-J}{(J-1)M}\\right)T}}\\wedge\\frac{J-1}{2(K-J)},}\\\\ {\\displaystyle p_{1,k}=\\left(1-\\frac{\\sqrt{K}}{\\sqrt{T}}\\right)\\frac{1}{|A_{m}|}+\\frac{1}{\\sqrt{K T}},k\\in A_{m},\\quad p_{1,j}=\\frac{1}{\\sqrt{K T}},j\\neq A_{m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle C_{i}\\ln\\frac{1}{p_{1,i}}+\\sum_{k=1}^{K}C_{k}p_{1,k}-C_{i}}\\\\ &{\\le\\!C_{i}\\ln(\\sqrt{K T})+\\frac{C\\cdot(K-|A_{m}|)}{\\sqrt{K T}}+\\operatorname*{min}_{i}C_{i}\\cdot|A_{m}|\\cdot\\left(\\left(1-\\frac{\\sqrt{K}}{\\sqrt{T}}\\right)\\frac{1}{|A_{m}|}+\\frac{1}{\\sqrt{K T}}\\right)-C_{i}}\\\\ &{\\le\\!C_{i}\\ln(\\sqrt{K T})+\\frac{C\\sqrt{K}}{\\sqrt{T}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We further simplify $\\bar{L}_{T}-\\bar{L}_{T}(\\mathbf{v})$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\bar{L}_{T}-\\bar{L}_{T}(\\mathbf{v})\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad-\\cdots\\cdots}\\\\ &{\\le64g_{K,J}C\\ln\\frac1\\delta+11\\sqrt{g_{K,J}C\\ln\\frac1\\delta}\\cdot}\\\\ &{\\quad\\sqrt{C_{i}T M+\\frac M\\eta\\left(C_{i}\\ln(\\sqrt{K T})+\\frac{C\\sqrt{K}}{\\sqrt{T}}\\right)+\\frac{4M C g_{K,J}}3}\\ln\\frac1\\delta+2\\sqrt{2g_{K,J}\\ln\\frac1\\delta}\\cdot\\sqrt{\\bar{L}_{T}(\\mathbf v)}+}\\\\ &{\\quad\\quad2\\eta\\left(1+\\frac{g_{K,J}}{M}\\right)C_{i}T+\\frac{\\frac M\\eta\\left(C_{i}\\ln(\\sqrt{K T})+\\frac{C\\sqrt{K}}{\\sqrt{T}}\\right)+\\frac{4M C g_{K,J}}3}{\\frac13}\\ln\\frac1\\delta+2C_{i}\\sqrt{2g_{K,J}\\ln\\frac1\\delta}\\cdot\\sqrt{T\\Lambda}}\\\\ &{\\le(64+3M)g_{K,J}C\\ln\\frac1\\delta+17\\sqrt{M g_{K,J}C C_{i}T\\ln\\frac1\\delta}+\\frac4{\\sqrt2}C_{i}M\\sqrt{\\left(1+\\frac{K-J}{(J-1)M}\\right)T\\ln(K T)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "in which we omit the lower order terms such as $O(T^{\\frac{1}{4}})$ and $O(\\sqrt{g_{K,J}C\\ln\\frac{1}{\\delta}})$ ", "page_idx": 28}, {"type": "text", "text": "Finally, using the upper bound on $\\Xi_{4,1}$ gives, with probability at least $1\\,-\\,\\Theta(M\\log(C T)\\,+$ $\\log(\\dot{C}K T/\\bar{M}))\\cdot\\delta$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\bar{L}_{T}-\\bar{L}_{T}(\\mathbf v)+\\displaystyle\\frac{2C M}{3}\\ln\\frac1{\\delta}+2\\sqrt{C M\\cdot\\displaystyle\\sum_{j=1}^{M}\\sum_{t=1}^{T}\\left\\langle\\mathbf c_{t}^{(j)},\\mathbf p_{t}^{(j)}\\right\\rangle\\cdot\\ln\\frac1\\delta}}\\\\ &{\\leq\\bar{L}_{T}-\\bar{L}_{T}(\\mathbf v)+\\displaystyle\\frac{2C M}{3}\\ln\\frac1{\\delta}+2\\sqrt{C M\\cdot\\left(\\bar{L}_{T}(\\mathbf v)+\\Xi_{4,5}\\right)\\cdot\\ln\\frac1\\delta}}\\\\ &{\\leq(64+3M)g_{K,J}C\\ln\\frac1\\delta+17\\sqrt{M g_{K,J}C C_{i}T\\ln\\frac1\\delta}+\\displaystyle\\frac4{\\sqrt2}C_{i}M\\sqrt{\\left(1+\\frac{K-J}{(J-1)M}\\right)T\\ln\\left(K T\\right)}+}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where we omit $O(\\sqrt{C M{\\Xi}_{4,5}\\cdot\\ln{\\frac{1}{\\delta}}})$ which is a lower order term. ", "page_idx": 28}, {"type": "text", "text": "1.2 Analyzing $\\Xi_{5}$ ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We also start with Lemma 1. ", "page_idx": 28}, {"type": "text", "text": "We just a fixed $i\\in\\mathcal{F}_{i}$ . We instantiate some notations. ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Omega={\\mathscr F}_{i},\\quad{\\mathbf v}={\\mathbf w}\\in{\\mathscr F}_{i},}\\\\ {\\forall t\\in[T],\\quad g_{t}^{(j)}={\\nabla_{t,i}^{(j)}},\\quad\\tilde{g}_{t}^{(j)}=\\tilde{\\nabla}_{t,i}^{(j)},\\quad\\bar{g}_{t}=\\bar{\\nabla}_{t,i},\\quad{\\mathbf u}_{t}^{(j)}={\\mathbf w}_{t,i}^{(j)},\\quad{\\mathbf u}_{t}={\\mathbf w}_{t},}\\\\ &{l_{t}^{j}(\\mathbf u_{t}^{j})=\\ell\\left(f_{t,i}^{(j)}(\\mathbf x_{t}^{(j)}),y_{t}^{(j)}\\right),\\quad l_{t}^{j}({\\mathbf v})=\\ell\\left(f(\\mathbf x_{t}^{(j)}),y_{t}^{(j)}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Lemma 1 gives ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\forall\\mathbf{w}\\in\\mathcal{F}_{i},\\ \\ \\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left[\\ell\\left(f_{t,i}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\ell\\left(f(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]}\\\\ {\\displaystyle\\leq\\sum_{t=1}^{T}\\left(\\mathcal{D}_{\\psi_{t,i}}(\\mathbf{w},\\mathbf{w}_{t})-\\mathcal{D}_{\\psi_{t}}(\\mathbf{w},\\mathbf{w}_{t+1})\\right)+\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{\\psi_{t,i}}(\\mathbf{w}_{t},\\mathbf{q}_{t+1})+}\\\\ {\\displaystyle\\ \\ \\ \\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{\\psi_{t,i}}(\\mathbf{w}_{t},\\mathbf{r}_{t+1})+\\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)},\\mathbf{w}_{t}-\\mathbf{w}\\right\\rangle,}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the Bregman divergence is ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathcal{D}_{\\psi_{t,i}}(\\mathbf{w},\\mathbf{v})=\\frac{1}{2\\lambda_{t,i}}\\|\\mathbf{w}-\\mathbf{v}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Besides, (13) and (14) can be instantiated as follows ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{q}_{t+1}=\\mathbf{w}_{t}-\\lambda_{t,i}\\cdot\\cfrac{2}{M}\\displaystyle\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right),}\\\\ &{\\mathbf{r}_{t+1}=\\mathbf{w}_{t}-\\lambda_{t,i}\\cdot\\cfrac{2}{M}\\displaystyle\\sum_{j=1}^{M}\\nabla_{t,i}^{(j)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Thus we have: $\\forall\\mathbf{w}\\in\\mathcal{F}_{i}$ \uff0c", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\displaystyle\\sum_{t=1}^{T}\\frac{\\|\\mathbf{w}-\\mathbf{w}_{t}\\|_{2}^{2}-\\|\\mathbf{w}-\\mathbf{w}_{t+1}\\|_{2}^{2}}{2\\lambda_{t,i}}+2\\sum_{t=1}^{T}\\lambda_{t,i}\\left\\|\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right\\|_{2}^{2}+}\\\\ &{\\quad2\\displaystyle\\sum_{t=1}^{T}\\lambda_{t,i}\\left\\|\\frac{1}{M}\\sum_{j=1}^{M}\\nabla_{t,i}^{(j)}\\right\\|_{2}^{2}+\\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)},\\mathbf{w}_{t}-\\mathbf{w}\\right\\rangle}\\\\ &{\\leq\\displaystyle\\frac{2U_{i}^{2}}{\\lambda_{T,i}}+2G_{i}^{2}\\sum_{t=1}^{T}\\lambda_{t,i}+2\\sum_{t=1}^{T}\\lambda_{t,i}\\left\\|\\sum_{j=1}^{M}\\frac{\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}}{M}\\right\\|_{2}^{2}+\\underbrace{\\frac{1}{M}\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\left\\langle\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)},\\mathbf{w}_{t}-\\mathbf{w}\\right\\rangle}_{\\triangleq_{S,2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Next we separately give a high-probability upper bound on $\\Xi_{4,1}$ and $\\Xi_{4,2}$ ", "page_idx": 29}, {"type": "text", "text": "Bounding $\\Xi_{5,2}$ ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "We define a random variable $X_{t}$ as follows, ", "page_idx": 29}, {"type": "equation", "text": "$$\nX_{t}=\\left\\langle\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right),\\mathbf{w}_{t}-\\mathbf{w}\\right\\rangle.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "$X_{[T]}$ is a bounded martingale difference sequence w.r.t. $H_{[T]}$ and $|X_{t}|\\leq2g_{K,J}G_{i}U_{i}$ . We further have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\mathbb{E}_{t}[\\left|X_{t}\\right|^{2}]\\leq\\sum_{t=1}^{T}4U_{i}^{2}\\mathbb{E}_{t}\\left[\\left\\|\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right\\|_{2}^{2}\\right]\\leq4U_{i}^{2}G_{i}^{2}\\frac{g_{K,J}}{M}T.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The upper bound on the sum of conditional variance is a constant. Lemma 4 gives, with probability atleast $1-\\delta$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\Xi_{5,2}\\leq{\\frac{4G_{i}U_{i}g_{K,J}}{3}}\\ln{\\frac{1}{\\delta}}+2G_{i}U_{i}\\sqrt{2{\\frac{g_{K,J}}{M}}T\\ln{\\frac{1}{\\delta}}}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Bounding $\\Xi_{5,1}$ ", "page_idx": 29}, {"type": "text", "text": "Recalling that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\lambda_{t,i}=\\left\\{\\begin{array}{l l}{\\frac{U_{i}}{2G_{i}\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)\\cdot g_{K,J}^{2}}}}&{\\mathrm{if~}t\\leq g_{K,J}^{2},}\\\\ {\\frac{U_{i}}{2G_{i}\\sqrt{\\left(1+\\frac{g_{K,J}}{M}\\right)\\cdot t}}}&{\\mathrm{otherwise.}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "It can be found that $\\begin{array}{r}{\\lambda_{t,i}\\leq\\frac{U_{i}}{2g_{K,J}G_{i}}}\\end{array}$ ", "page_idx": 30}, {"type": "text", "text": "Case 1: T > gkJ. We decompose $\\Xi_{5,1}$ as follows, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\Xi_{5,1}=\\underbrace{\\sum_{t=1}^{g_{K,J}^{2}}\\lambda_{t,i}\\left\\|\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right\\|_{2}^{2}}_{\\Xi_{5,1,1}}+\\underbrace{\\sum_{t=g_{K,J}^{2}+1}^{T}\\lambda_{t,i}}_{\\Xi_{5,1,2}}\\left\\|\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We separately analyze $\\Xi_{5,1,1}$ and $\\Xi_{5,1,2}$ . Let ", "page_idx": 30}, {"type": "equation", "text": "$$\nX_{t}=\\lambda_{t,i}\\left\\lVert\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right\\rVert_{2}^{2}-\\lambda_{t,i}\\mathbb{E}_{t}\\left[\\left\\lVert\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right\\rVert_{2}^{2}\\right].\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Xm isamartingalediffrence equence and satisfes X\u2264\u5165, 9<KG. We further have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{g_{K,J}^{2}}\\mathbb{E}_{t}[|X_{t}|^{2}]\\leq\\displaystyle\\sum_{t=1}^{g_{K,J}^{2}}\\mathbb{E}_{t}\\left[\\lambda_{t,i}^{2}\\left|\\left|\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right|\\right|_{2}^{4}\\right]\\leq U_{i}^{2}G_{i}^{2}\\frac{g_{K,J}^{3}}{4M},}\\\\ &{\\displaystyle\\sum_{t=g_{K,J}^{2}+1}^{T}\\mathbb{E}_{t}[|X_{t}|^{2}]\\leq\\!U_{i}^{2}G_{i}^{2}\\frac{g_{K,J}}{4M}\\left(T-g_{K,J}^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "With probability at least $1-2\\delta$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi_{5,1}\\leq\\displaystyle\\sum_{t=1}^{T}\\lambda_{t,i}\\mathbb{E}_{t}\\left[\\left\\|\\frac{1}{M}\\sum_{j=1}^{M}\\left(\\tilde{\\nabla}_{t,i}^{(j)}-\\nabla_{t,i}^{(j)}\\right)\\right\\|_{2}^{2}\\right]+\\frac{2g_{K,J}G_{i}U_{i}}{3}\\ln\\frac{1}{\\delta}+G_{i}U_{i}\\sqrt{2\\frac{g_{K,J}}{M}}T\\ln\\frac{1}{\\delta}}\\\\ &{\\qquad\\le\\displaystyle\\frac{g_{K,J}}{M}G_{i}^{2}\\sum_{t=1}^{T}\\lambda_{t,i}+\\frac{2g_{K,J}G_{i}U_{i}}{3}\\ln\\frac{1}{\\delta}+G_{i}U_{i}\\sqrt{2\\frac{g_{K,J}}{M}}T\\ln\\frac{1}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Combining with all results gives, with probability at leat $1-3\\delta$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{M}\\Xi_{5}\\leq\\frac{2U_{i}^{2}}{\\lambda_{T,i}}+2G_{i}^{2}\\left(1+\\frac{g_{K,J}}{M}\\right)\\left(\\underset{t=1}{\\overset{\\rho_{K,J}^{2}}{\\sum}}\\lambda_{t,i}+\\underset{t=\\sigma_{K,J}^{2}+1}{\\overset{T}{\\sum}}\\lambda_{t,i}\\right)+2g_{K,J}G_{i}U_{i}\\ln\\frac{1}{\\delta}+}\\\\ &{\\ \\ \\ \\ \\ 3G_{i}U_{i}\\sqrt{\\frac{2g_{K,J}T}{M}\\ln\\frac{1}{\\delta}}}\\\\ &{\\ \\ \\ \\ \\ \\leq\\frac{2U_{i}^{2}}{\\lambda_{T,i}}+G_{i}U_{i}\\sqrt{1+\\frac{g_{K,J}}{M}}\\left(g_{K,J}+\\int_{t=\\sigma_{K,J}^{2}+1}^{T}\\frac{1}{\\sqrt{t}}\\mathrm{d}\\,t\\right)+2g_{K,J}G_{i}U_{i}\\ln\\frac{1}{\\delta}+}\\\\ &{\\ \\ \\ \\ 3G_{i}U_{i}\\sqrt{\\frac{2g_{K,J}T}{M}\\ln\\frac{1}{\\delta}}}\\\\ &{\\ \\ \\ \\ \\ \\leq6U_{i}G_{i}\\sqrt{\\left(1+\\frac{g_{K,J}T}{M}\\right)T}+2g_{K,J}G_{i}U_{i}\\ln\\frac{1}{\\delta}+3G_{i}U_{i}\\sqrt{\\frac{2g_{K,J}T}{M}\\ln\\frac{1}{\\delta}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Case 2: $T\\le g_{K,J}^{2}$ ", "page_idx": 30}, {"type": "text", "text": "In this case, we do not decompose $\\Xi_{5,1}$ and $\\begin{array}{r}{\\lambda_{t,i}\\,=\\,\\frac{U_{i}}{2G_{i}\\sqrt{\\left(1+\\frac{g K,J}{M}\\right)g_{K,J}^{2}}}}\\end{array}$ .With probability at least $1-\\delta$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\Xi_{5,1}\\leq\\frac{g_{K,J}}{M}G_{i}^{2}\\sum_{t=1}^{T}\\lambda_{t,i}+\\frac{g_{K,J}G_{i}U_{i}}{3}\\ln\\frac{1}{\\delta}+G_{i}U_{i}\\sqrt{\\frac{g_{K,J}}{2M}T\\ln\\frac{1}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Furthermore, with probability at least $1-2\\delta$ \uff0c ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{M}\\Xi_{5}\\leq\\frac{2U_{i}^{2}}{\\lambda_{T,i}}+2G_{i}^{2}\\left(1+\\frac{g_{K,J}}{M}\\right)\\sum_{t=1}^{T}\\lambda_{t,i}+\\frac{5g_{K,J}G_{i}U_{i}}{3}\\ln\\frac{1}{\\delta}+4G_{i}U_{i}\\sqrt{\\frac{g_{K,J}}{M}}T\\ln\\frac{1}{\\delta}}\\\\ &{\\qquad\\leq5U_{i}G_{i}\\sqrt{1+\\frac{g_{K,J}}{M}}\\cdot g_{K,J}+\\frac{5g_{K,J}G_{i}U_{i}}{3}\\ln\\frac{1}{\\delta}+4G_{i}U_{i}\\sqrt{\\frac{g_{K,J}}{M}}T\\ln\\frac{1}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Combining the two cases gives, with probability at least $1-(M+5)\\delta$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\frac{1}{M}\\Xi_{5}\\leq6U_{i}G_{i}\\sqrt{1+\\frac{g_{K,J}}{M}}\\left(\\sqrt{T}+g_{K,J}\\right)+2g_{K,J}G_{i}U_{i}\\ln\\frac{1}{\\delta}+3G_{i}U_{i}\\sqrt{\\frac{2g_{K,J}}{M}}T\\ln\\frac{1}{\\delta}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "1.3 Combining all ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Combining the upper bounds on $\\Xi_{4}$ and $\\Xi_{5}$ gives an upper bound on the regret. With probability at least $1-\\Theta\\left(M\\log(C T)+\\log(C K T/M)\\right)\\cdot\\delta$ $\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\ell\\left(f_{t,A_{t,1}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\displaystyle\\sum_{t=1}^{T}\\sum_{j=1}^{M}\\ell\\left(f(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)}\\\\ &{\\leq\\!M\\sqrt{1+\\frac{g K_{,J}}{M}}\\left(6U_{i}G_{i}\\left(\\sqrt{T}+g_{K,J}\\right)+\\frac{4}{\\sqrt{2}}C_{i}\\sqrt{T\\ln\\left(K T\\right)}\\right)+}\\\\ &{\\left(64C+3M C+2U_{i}G_{i}\\right)g_{K,J}\\ln\\frac{1}{\\delta}+\\left(3\\sqrt{2}G_{i}U_{i}+17\\sqrt{C C_{i}}\\right)\\!\\sqrt{2M g_{K,J}T\\ln\\frac{1}{\\delta}}+2M C_{i}\\sqrt{T\\ln\\frac{1}{\\delta}}.}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "Omitting the constant terms and lower order terms concludes the proof. ", "page_idx": 31}, {"type": "text", "text": "JProof of Theorem 3 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We first establish a technical lemma. ", "page_idx": 31}, {"type": "text", "text": "Lemma 5. Let $X_{1},...,X_{K}$ be a sequence of independent standard normal random variables. Let $Z_{K}=\\operatorname*{max}\\{X_{1},...,X_{K}\\}$ $K\\geq5$ then $\\begin{array}{r}{\\mathbb{E}[Z_{K}]\\stackrel{{}}{\\geq}\\left(1-\\frac{1}{\\sqrt{\\mathrm{e}}}\\right)\\sqrt{2\\ln K}}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "Proof of Lemma 5. Proposition 2.1.2 in Vershynin [2018] gives a lower bound on the tail probability of standard normal distribution. ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\forall x>0,\\mathbb{P}[X_{1}\\geq x]=\\int_{x}^{+\\infty}{\\frac{1}{\\sqrt{2\\pi}}}\\exp\\left(-{\\frac{\\mu^{2}}{2}}\\right){\\mathrm{d}}\\,\\mu\\geq{\\frac{1}{\\sqrt{2\\pi}}}\\left({\\frac{1}{x}}-{\\frac{1}{x^{3}}}\\right)\\exp\\left(-{\\frac{x^{2}}{2}}\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Then we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[Z_{K}]=\\mathbb{E}\\left[Z_{K}\\left|\\mathcal{D}_{i}\\in[K],X_{i}\\geq\\varepsilon\\right|\\cdot\\mathbb{P}\\left[\\exists i\\in[K],X_{i}\\geq\\varepsilon\\right]+\\mathbb{E}[Z_{K}|\\forall X_{i}<\\varepsilon]\\cdot\\mathbb{P}\\big[\\forall X_{i}<\\varepsilon\\big]}\\\\ &{\\qquad\\qquad\\geq\\mathbb{P}\\left[\\exists i\\in[K],X_{i}\\geq\\varepsilon\\right]\\cdot\\varepsilon}\\\\ &{\\qquad=(1-\\mathbb{P}\\big|\\mathcal{N}_{i}<\\varepsilon\\big|)\\cdot\\varepsilon}\\\\ &{\\qquad=\\left(1-\\displaystyle\\prod_{i=1}^{K}\\mathbb{P}\\left[X_{i}<\\varepsilon\\right]\\right)\\cdot\\varepsilon}\\\\ &{\\qquad=\\left(1-\\displaystyle\\prod_{i=1}^{K}\\left(1-\\mathbb{P}\\left[X_{i}\\geq\\varepsilon\\right]\\right)\\right)\\cdot\\varepsilon}\\\\ &{\\qquad\\geq\\left(1-\\left(1-\\displaystyle\\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{1}{\\varepsilon}-\\frac{1}{\\varepsilon^{3}}\\right)\\exp\\left(-\\frac{\\varepsilon^{2}}{2}\\right)\\right)^{K}\\right)\\cdot\\varepsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Let $\\varepsilon={\\sqrt{2\\ln K}}$ .If $K>5$ , then we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(1-\\displaystyle\\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{1}{\\varepsilon}-\\displaystyle\\frac{1}{\\varepsilon^{3}}\\right)\\exp\\left(-\\frac{\\varepsilon^{2}}{2}\\right)\\right)^{K}=\\left(1-\\displaystyle\\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{1}{\\sqrt{2\\ln K}}-\\displaystyle\\frac{1}{\\ln^{1.5}K^{2}}\\right)\\frac{1}{K}\\right)^{K}}\\\\ &{\\phantom{\\left(1-\\displaystyle\\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{1}{\\varepsilon}\\right)\\right)^{K}}\\ \\ \\ \\ }\\\\ &{\\phantom{\\left(1-\\displaystyle\\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{1}{\\varepsilon}\\right)\\right)^{K}}\\ \\ \\ \\ \\ }\\\\ &{\\phantom{\\left(1-\\displaystyle\\frac{1}{\\sqrt{2\\pi}}\\right)^{K}}\\ \\ \\ \\ \\ \\ }\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Substituting into the lower bound of $\\mathbb{E}[Z_{K}]$ concludes the proof. ", "page_idx": 32}, {"type": "text", "text": "J.1 Proof of the First Lower Bound ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Proof. Let $d\\,\\geq\\,K$ \uff0c\uff0c $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ and $y\\in\\{0,1\\}$ .We use the absolute loss function $\\ell(f(\\mathbf x_{t}),y_{t})=$ $\\lvert f(\\mathbf{x}_{t})-y_{t}\\rvert$ . Recalling that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathcal{F}_{i}=\\left\\{f_{i}(\\mathbf{x})=\\langle\\mathbf{e}_{i},\\mathbf{x}\\rangle\\right\\},\\quad i=1,2,...,K,\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where $\\mathbf{e}_{i}$ is the standard basis vector in $\\mathbb{R}^{d}$ . It is obvious that the time complexity of computing $f_{i}(\\mathbf{x})\\,=\\,x_{i}$ .s $O(1)$ . At each client $j$ let the selcted hypothesis be $f_{t}^{(j)}$ and the prediction be $f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)})$ . Since there are no computational constraints on each client, $f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)})$ can be a weighted combination of $K$ preditions i.e. $\\begin{array}{r}{f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)})~=~\\sum_{i=1}^{K}w_{t,i}^{(j)}f_{i}(\\mathbf{x}_{t}^{(j)})}\\end{array}$ Th time complexity of computing $f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)})$ $O(K)$ We wil folow the techniqgues used in the proof of Theorem 3. in Patel et al. [2023] and Theorem 3.7 in Cesa-Bianchi and Lugosi [2006]. ", "page_idx": 32}, {"type": "text", "text": "Following the proof of Theorem 3.1 in Patel et al. [2023], the adversary gives a sequence of same examples for each client. To be specific, we define ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\left(\\mathbf{x}_{t}^{(j)},y_{t}^{(j)}\\right)=(\\mathbf{x}_{t},y_{t}),\\quad t=1,...,T,\\quad j=1,...,M,\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where $\\mathbf{x}_{t}=(b_{t,1},b_{t,2},...,b_{t,K},0,\\ldots,0)\\in\\mathbb{R}^{d}$ and $b_{t,1},b_{t,2},...,b_{t,K},y_{t}$ is a sequence of symmetric ii.d. Bernoullirandom variables,. $\\begin{array}{r}{\\mathbb{P}[y_{t}=1]=\\mathbb{P}[y_{t}=0]=\\frac{1}{2}}\\end{array}$ ", "page_idx": 32}, {"type": "text", "text": "At any round $t$ , the minimax regret against the best hypothesis can be simplified as follows ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad_{f_{1}^{(1)}}\\operatorname*{inf}_{x\\in I_{N}^{(\\pm)}(x,y),\\eta\\in[M],\\epsilon\\in[N]}\\mathrm{max~Reg}_{D}(\\mathcal{F}_{i})}\\\\ &{\\geq_{f_{1}^{(1)}}\\operatorname*{inf}_{x\\in I_{N}^{(\\pm)}(x,y),\\eta\\in[M]}\\mathrm{meax~Reg}_{D}(\\mathcal{F}_{i})}\\\\ &{\\geq_{f_{1}^{(1)}}\\operatorname*{inf}_{x\\in I_{N}^{(\\pm)}(x,y),\\eta\\in[F]}\\left[\\sum_{i=1}^{T}\\sum_{j=1}^{M}\\ell\\left(f_{i}^{(j)}(x_{i}),y_{j}\\right)-\\frac{\\operatorname*{inf}_{x\\in I_{N}^{(\\pm)}(\\sum_{i=1}^{M}\\ell(f_{i}(x_{i}),y_{j})}}{i\\in[N]_{i}\\sum_{i=1}^{M}j_{i}-1}\\right]}\\\\ &{=_{f_{1}^{(1)}}\\operatorname*{inf}_{x\\in I_{N}^{(\\pm)}(\\mathbf{x},y),\\eta\\in[F]}\\left[\\sum_{i=1}^{T}\\sum_{j=1}^{M}|f_{i}^{(j)}(\\mathbf{x}_{i})-y_{i}|-M\\operatorname*{inf}_{i\\in[N]_{i}^{(\\pm)}}\\sum_{i=1}^{T}|f_{i}(\\mathbf{x}_{i})-y_{i}|\\right]}\\\\ &{=\\frac{M T}{2}-M\\sum_{\\ i=1}^{M}\\frac{\\mathbb{E}_{i}}{(\\mathbf{x}_{i},y),\\epsilon}\\left[\\frac{\\operatorname*{inf}_{i}}{\\left\\langle\\epsilon\\left|\\mathbf{x}_{i}\\right|}\\frac{T}{\\prod_{i=1}^{M}}|f_{i}(\\mathbf{x}_{i})-y_{i}|\\right]}\\\\ &{=\\!M\\left(\\underbrace{\\sum_{i=1}^{M}\\sum_{j=1}^{N}\\left[\\frac{\\sum_{i=1}^{N}\\ell_{i}(\\mathbf{x}_{i})}{\\epsilon\\left|\\mathbf{x}_{i}\\right|}\\right]\\cdot(1\\!\\!-\\!2y)}_{(\\mathbf{x}_{i},y),\\epsilon}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "in which $f_{i}(\\mathbf{x}_{t})=b_{t,i}$ is a Bernoulli random variable and ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\underset{(\\mathbf{x},y_{t}),t\\in[T]}{\\mathbb{E}}\\left[\\sum_{t=1}^{T}\\sum_{j=1}^{M}|f_{t}^{(j)}(\\mathbf{x}_{t})-y_{t}|\\right]=\\underset{y_{t},t\\in[T]}{\\mathbb{E}}\\left[\\sum_{t=1}^{T}\\sum_{j=1}^{M}y_{t}\\right]=\\frac{M T}{2}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "We further obtain ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{inf}_{f_{1}^{(1)},\\ldots,f_{T}^{(M)}(\\mathbf{x}_{t}^{(j)},\\boldsymbol{y}_{t}^{(j)}),j\\in[M],t\\in[T]}\\operatorname*{max}_{i\\in[K]}\\mathrm{Reg}_{D}(\\mathcal{F}_{i})\\geq\\frac{M}{2}\\operatorname*{max}_{\\sigma_{t},Z_{t,i},t\\in[T],i\\in[K]}\\left[\\operatorname*{max}_{i\\in[K]}\\sum_{t=1}^{T}Z_{t,i}\\cdot\\sigma_{t}\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where both $\\{Z_{t,i}\\}_{t\\in[T],i\\in[K]}$ and $\\{\\sigma_{t}\\}_{t\\in[T]}$ are i.i.d. Rademacher random variables. ", "page_idx": 33}, {"type": "text", "text": "By Lemma A.11 in Cesa-Bianchi and Lugosi [2006], we obtain ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{T\\to\\infty}\\mathbb{E}\\left[\\operatorname*{max}_{i\\in[K]}\\frac{1}{\\sqrt{T}}\\sum_{t=1}^{T}Z_{t,i}\\right]=\\mathbb{E}\\left[\\operatorname*{max}_{i\\in[K]}G_{i}\\right],\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $G_{1},...,G_{N}$ are independent standard normal random variables. ", "page_idx": 33}, {"type": "text", "text": "By Lemma 5, we obtain ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{T\\rightarrow\\infty}\\operatorname*{inf}_{f_{1}^{(1)},\\dots,f_{T}^{(M)}}\\operatorname*{sup}_{(\\mathbf{x}_{t}^{(j)},\\mathbf{y}_{t}^{(j)}),j\\in[M],t\\in[T]}\\operatorname*{max}_{i\\in[K]}\\mathrm{Reg}_{D}(\\mathcal{F}_{i})\\geq\\frac{1}{2}\\left(1-\\frac{1}{\\sqrt{\\mathrm{e}}}\\right)M\\sqrt{2T\\ln K},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 33}, {"type": "text", "text": "J.2Proof of the Second Lower Bound ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We mainly use the techniques in the proof of Theorem 2 in Seldin et al. [2014], but also require a new technique. The idea of our proof is to reduce the online model selection on each client to multi-armed bandit problem with additional observations. ", "page_idx": 33}, {"type": "text", "text": "Proof. Now we prove the second lower bound in Theorem 3. ", "page_idx": 33}, {"type": "text", "text": "Let $d\\geq K$ $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ and $y\\in\\{0,1\\}$ . We use a linear loss function $\\ell(f(\\mathbf{x}_{t}),y_{t})=1-y_{t}f(\\mathbf{x}_{t})$ Recalling that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathcal{F}_{i}=\\left\\{f_{i}(\\mathbf{x})=\\langle\\mathbf{e}_{i},\\mathbf{x}\\rangle\\right\\},\\quad i=1,2,...,K.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "It is obvious that the time complexity of computing $f_{i}(\\mathbf{x})=x_{i}$ is $O(1)$ . Under the constraint that the time complexity on each client is limited to $O(J)$ , on each client, any algorithm can only select $J$ hypotheses and then output a prediction. ", "page_idx": 33}, {"type": "text", "text": "One of challenges is that the prediction may be a combination of $J$ predictions. To be specific, for each client $\\begin{array}{r}{\\dot{j}\\;\\in\\;[M],\\;f_{t}^{(j)}({\\bf x}_{t}^{(j)})\\;=\\;\\sum_{i\\in{\\cal O}_{t}^{(j)}}w_{t,i}f_{i}({\\bf x}_{t}^{(j)})}\\end{array}$ where $\\bar{O}_{t}^{(j)}$ contains th index of selected $J$ hypotheses by some algorithm. To address this challenge, we introduce a virtual strategy that randomly selects a hypothesis $f_{I_{t}^{(j)}}^{(j)}\\,\\in\\,\\{f_{A_{t,1}},f_{A_{t,2}},...,f_{A_{t,J}}\\}$ following the distribution $(w_{t,A_{t,1}},w_{t,A_{t,2}},...,w_{t,A_{t,J}})$ where $A_{t,a}\\,\\in\\,O_{t}^{(j)}$ \uff0c $a\\,=\\,1,...,J$ . Since the loss function is a linear function, it is easy to prove that, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\ell(f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)})\\right]=\\ell\\left(\\mathbb{E}\\left[f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)})\\right],y_{t}^{(j)}\\right)=\\ell\\left(f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the xectaonistaer $I_{t}^{(j)}$ Assmigthat $\\ell(f_{i}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)})\\le C$ for all $i=1,...,K$ Lemma A.7 in Cesa-Bianchi and Lugosi [2006] gives, with probability at least \uff0c ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left[\\ell(f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)})-\\ell\\left(f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]\\leq-C\\sqrt{\\frac{T}{2}\\ln\\frac{1}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Note that we assume $w_{t,i}\\geq0$ and $\\textstyle\\sum_{i\\in O_{t}^{(j)}}w_{t,i}=1$ for all $t=1,...,T$ Recalling that Theorem 3 assumes the outputs of algorithm belong to $\\begin{array}{r}{[\\operatorname*{min}_{i\\in[K],\\mathbf{x}\\in\\mathcal{X}}f_{i}(\\mathbf{x}),\\operatorname*{max}_{i\\in[K],\\mathbf{x}\\in\\mathcal{X}}f_{i}(\\mathbf{x})]}\\end{array}$ If $w_{t,i}<0$ 0 $\\textstyle\\sum_{i\\in O_{t}^{(j)}}w_{t,i}>1$ we can still find a weight vector $w_{t,i}^{\\prime}\\geq0$ and $\\textstyle\\sum_{i\\in O_{t}^{(j)}}w_{t,i}^{\\prime}=1$ , such that ", "page_idx": 33}, {"type": "equation", "text": "$$\nf_{t}^{(j)}(\\mathbf{x}_{t}^{(j)})=\\sum_{i\\in O_{t}^{(j)}}w_{t,i}f_{i}(\\mathbf{x}_{t}^{(j)})=\\sum_{i\\in O_{t}^{(j)}}w_{t,i}^{\\prime}f_{i}(\\mathbf{x}_{t}^{(j)}).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Then  we sample $I_{t}^{(j)}$ following $(w_{t,A_{t,1}}^{\\prime},w_{t,A_{t,2}}^{\\prime},...,w_{t,A_{t,J}}^{\\prime})$ We can replace $(w_{t,A_{t,1}},w_{t,A_{t,2}},...,w_{t,A_{t,J}})$ with $(w_{t,A_{t,1}}^{\\prime},w_{t,A_{t,2}}^{\\prime},...,w_{t,A_{t,J}}^{\\prime})$ ", "page_idx": 34}, {"type": "text", "text": "Since the algorithm is non-cooperative, the total regret can be decomposed into the summation of the regret on each client. With probability at least $1-M\\delta$ ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\forall i\\in[K],\\quad\\mathrm{Reg}_{D}(\\mathscr{F}_{i})=\\displaystyle\\sum_{j=1}^{M}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\displaystyle\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]}\\\\ &{\\phantom{l i d}=\\displaystyle\\sum_{j=1}^{M}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{t_{i}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]+}\\\\ &{\\phantom{l i d}\\displaystyle\\sum_{j=1}^{M}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{t}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\sum_{t=1}^{T}\\ell\\left(f_{t_{i}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]}\\\\ &{\\geq\\displaystyle\\sum_{j=1}^{M}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{t_{i}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]+C\\sqrt{\\frac{T}{2}\\ln\\frac{1}{\\delta}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Note that if we take expectation w.r.t. the randomness of algorithm, then the additional term $C{\\sqrt{{\\frac{T}{2}}\\ln{\\frac{1}{\\delta}}}}$ in (17) can be omitted following (16). ", "page_idx": 34}, {"type": "text", "text": "Ithepedict $J$ predictios, bu gust $f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)})$ the we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\forall i\\in[K],\\ \\ \\ \\mathrm{Reg}_{D}(\\mathcal{F}_{i})=\\underbrace{\\sum_{j=1}^{M}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)-\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]}_{\\overline{{\\mathrm{Reg}}}_{D}(\\mathcal{F}_{i})}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Combining with the two cases, we just need to analyze $\\overline{{\\mathrm{Reg}}}_{D}(\\mathcal{F}_{i})$ ", "page_idx": 34}, {"type": "text", "text": "The adversary first uniformly samples a same $\\textit{h}\\in\\:[K]$ for all clients, and then constructs $\\{(\\mathbf{x}_{t}^{(j)},y_{t})\\}_{t=1}^{T}$ as follows ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t}^{(j)}=\\mathbf{x}_{t}:=\\left(b_{t,1},b_{t,2},...,b_{t,K},0,\\ldots,0\\right),\\quad y_{t}^{(j)}=1,\\quad j=1,...,M,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "in which $b_{t,i}$ satisfies ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\mathbb{P}_{h}\\left[b_{t,i}=1\\right]{=}\\displaystyle\\frac{1-\\rho}{2},\\quad\\mathbb{P}_{h}\\left[b_{t,i}=0\\right]{=}\\displaystyle\\frac{1+\\rho}{2},\\quad i\\neq h,}\\\\ {\\mathbb{P}_{h}\\left[b_{t,h}=1\\right]{=}\\displaystyle\\frac{1+\\rho}{2},\\quad\\mathbb{P}_{h}\\left[b_{t,h}=0\\right]{=}\\displaystyle\\frac{1-\\rho}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Let $\\mathbb{E}_{h}[\\cdot]$ and $\\mathbb{P}_{h}[\\cdot]$ separately be the expectation and probability operator conditioned on $h$ is selected. Then we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\mathbb{P}_{h}\\left[\\ell(f_{i}(\\mathbf{x}_{t}),1)=1\\right]\\!=\\!\\frac{1+\\rho}{2},\\quad\\mathbb{P}_{h}\\left[\\ell(f_{i}(\\mathbf{x}_{t}),1)=0\\right]\\!=\\!\\frac{1-\\rho}{2},\\quad{i\\neq h},}\\\\ {\\displaystyle\\mathbb{P}_{h}\\left[\\ell(f_{h}(\\mathbf{x}_{t}),1)=1\\right]\\!=\\!\\frac{1-\\rho}{2},\\quad\\mathbb{P}_{h}\\left[\\ell(f_{h}(\\mathbf{x}_{t}),1)=0\\right]\\!=\\!\\frac{1+\\rho}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "It is obvious that online model selection can be reduced to a $K$ -armed bandit problem, in which $f_{i}$ is the $i$ -th arm. At each round $t$ let $I_{t}^{(j)}$ be the selected arm. Besides, any algorithm can select another $J-1$ arms. Thus any algorithm can observe $J$ losses. Let $O_{t}^{(j)}$ be the set of the selected $J$ arms. Note that $f_{I_{t}^{(j)}}^{(j)}=f_{I_{t}^{(j)}}$ for any $I_{t}^{(j)}\\in[K]$ ", "page_idx": 34}, {"type": "text", "text": "Assuming that the algorithm is deterministic, that is, $O_{t}^{(j)}$ is determined by $\\{O_{\\tau}^{(j)}\\}_{\\tau=1}^{t-1}$ and the observed losses. Let $\\begin{array}{r}{N_{T,i}=\\sum_{t=1}^{T}\\mathbb{I}_{I_{t}^{(j)}=i}}\\end{array}$ . Taking expectation w.r.t. $(b_{t,1},...,b_{t,K})_{t=1}^{T}$ yields ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{h}\\left[\\displaystyle\\sum_{t=1}^{T}\\ell\\left(f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}),1\\right)-\\operatorname*{min}_{i\\in[K]}\\displaystyle\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}),1\\right)\\right]}\\\\ &{\\ge\\mathbb{E}_{h}\\left[\\displaystyle\\sum_{t=1}^{T}\\ell\\left(f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}),1\\right)\\right]-\\operatorname*{min}_{i\\in[K]}\\mathbb{E}_{h}\\left[\\displaystyle\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}),1\\right)\\right]}\\\\ &{=\\rho\\cdot\\mathbb{E}_{h}\\left[\\displaystyle\\sum_{t=1}^{T}\\mathbb{I}_{I_{t}^{(j)}\\neq h}\\right]}\\\\ &{=\\rho T\\cdot\\left(1-\\displaystyle\\frac{1}{T}\\mathbb{E}_{h}\\left[N_{T,h}\\right]\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Following the techniques in the proof of Theorem 2 in Seldin et al. [2014], we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\frac{1}{K T}\\sum_{h=1}^{K}\\mathbb{E}_{h}\\left[N_{T,h}\\right]\\leq\\frac{1}{K}+\\sqrt{-\\frac{J T}{K}\\frac{2\\rho^{2}}{1-\\rho^{2}}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Recalling that $T\\geq K\\geq5.$ Let $\\begin{array}{r}{\\rho=\\frac{\\sqrt{K}}{3\\sqrt{J T}}}\\end{array}$ . We further have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{K}\\displaystyle\\sum_{h=1}^{K}\\left[\\mathbb{E}_{h}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}),1\\right)\\right]-\\displaystyle\\operatorname*{min}_{i\\in[K]}\\mathbb{E}_{h}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}),1\\right)\\right]\\right]}\\\\ &{\\displaystyle\\geq\\rho T\\cdot\\left(1-\\frac{1}{K}-\\frac{3}{2}\\rho\\sqrt{\\frac{J T}{K}}\\right)}\\\\ &{\\displaystyle\\geq0.1\\frac{\\sqrt{K T}}{\\sqrt{J}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For any deterministic algorithm, we can prove ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phantom{=}\\rho_{\\left(a,b\\right),\\left(T\\right),\\left(a,b\\right)}^{\\nu,\\mu,\\nu,\\mu}\\mathrm{E}_{\\left(a,b\\right),\\left(b\\right)}^{\\nu,\\mu}\\mathrm{E}_{\\left(b\\right),\\left(a,b\\right)}^{\\nu,\\mu}}\\\\ &{\\overset{\\mathrm{(a)}}{\\underset{\\mathrm{(a,b)},\\mathrm{~u=1}}{\\leq}}\\mathrm{E}_{\\left(b,a\\right),\\left(b\\right)}^{\\nu,\\mu}\\left[\\frac{\\displaystyle\\sum_{t=1}^{T}}{\\displaystyle\\sum_{t=1}^{T}}\\sigma_{\\left(t^{\\prime}\\left(t^{\\prime}\\left(u_{t}\\right),1\\right)\\right)}^{\\nu,\\mu}-\\frac{\\displaystyle\\mu_{\\left(b\\right)}^{\\nu}}{\\displaystyle\\sum_{t=1}^{T}\\sum_{=1}^{T}\\sigma_{\\left(t^{\\prime}\\left(t^{\\prime}\\left(u_{t}\\right),1\\right)\\right)}^{\\nu}}\\right]}\\\\ &{\\overset{\\mathrm{(a)}}{\\underset{\\mathrm{(a,b)},\\mathrm{~u=1}}{=}}\\mathrm{E}_{\\left(b,a\\right),\\left(b\\right)}^{\\nu,\\mu}\\left[\\frac{\\displaystyle\\sum_{t=1}^{T}}{\\displaystyle\\sum_{t=1}^{T}\\sigma_{\\left(t^{\\prime}\\left(t^{\\prime}\\left(u_{t}\\right),1\\right)\\right)}^{\\nu}}+\\beta\\alpha\\frac{\\displaystyle\\sum_{t=1}^{T}}{\\displaystyle\\sum_{t=1}^{T}\\sigma_{\\left(t^{\\prime}\\left(t^{\\prime}\\left(u_{t}\\right),1\\right)\\right)}^{\\nu}}\\frac{\\displaystyle\\sum_{t=1}^{T}}{\\displaystyle\\sum_{t=1}^{T}\\sigma_{\\left(t^{\\prime}\\left(t^{\\prime}\\left(u_{t}\\right),1\\right)\\right)}^{\\nu}}\\right]}\\\\ &{\\overset{\\mathrm{(a)}}{\\underset{\\mathrm{(a,b)},\\mathrm{~u=1}}{\\leq}}\\mathrm{E}_{\\left(b,a\\right),\\left(b\\right)}^{\\nu,\\mu}\\left[\\frac{\\displaystyle\\sum_{t=1}^{T}}{\\displaystyle\\sum_{t=1}^{T}\\sigma_{\\left(t^{\\prime}\\left(t^{\\prime}\\left(u_{t}\\right),1\\right)\\right)}^{\\nu}}+\\left(\\rho_{\\left(t^{\\prime}\\left(t^{\\prime}\\left(u_{t}\\right),1\\right)\\right)}^{\\nu}-\\frac{\\displaystyle\\mu_{\\\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Algorithm 4 NCO-OMS   \nRequire: $T,J,\\eta_{1},\\{U_{i},\\lambda_{1,i},i\\in[K]\\}$ $f_{1,i}^{(j)}=0,p_{1,i},i\\in[K],j\\in[M]$ $t=1,2,\\ldots,T$   \n2: for $j=1,\\dots,M$ do   \n3: The lient samples $O_{t}^{(j)}$ following (7)   \n4: The client outputs fAt1 $f_{t,A_{t,1}}^{(j)}(\\mathbf{x}_{t}^{(j)})$   \n5: The client computes $f_{t,A_{t,a}}^{(j)}(\\mathbf{x}_{t}^{(j)})$ (j) for alla = 2, .., J   \n6: Th lent computes $\\tilde{\\nabla}_{t,i}^{(j)}$ and $\\tilde{c}_{t,i}^{(j)}$ for ll $i\\in O_{t}^{(j)}$   \n7: Th lint computes $\\mathbf{p}_{t+1}^{(j)}$ and $\\mathbf{w}_{t+1,i}^{(j)},i\\in[K]$ following Defnion 1   \n8: end for   \n9: end for ", "page_idx": 36}, {"type": "text", "text": "where the last inequality comes from (19). As claimed in the proof of Theorem 6.11 in CesaBianchi and Lugosi [2006], the lower bound of any randomized algorithm is same with that of any deterministic algorithm, i.e., ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{sup}_{(\\mathbf{x}_{t}^{(j)},\\mathbf{y}_{t}^{(j)}),t\\in[T],j\\in[M]}\\mathbb{E}\\left[\\operatorname*{max}\\overline{{\\mathrm{Reg}}}_{D}(\\mathcal{F}_{i})\\right]}\\\\ &{=\\displaystyle\\operatorname*{sup}_{(\\mathbf{x}_{t}^{(j)},\\mathbf{y}_{t}^{(j)}),t\\in[T],j\\in[M]}\\left[\\mathbb{E}\\left[\\sum_{t=1}^{T}\\ell\\left(f_{I_{t}^{(j)}}^{(j)}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]-\\operatorname*{min}_{i\\in[K]}\\sum_{t=1}^{T}\\ell\\left(f_{i}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)\\right]}\\\\ &{\\geq0.1M\\frac{\\sqrt{K T}}{\\sqrt{J}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "in which the expectation is taken over the internal randomness of algorithm. Substituting into (17), or (18) concludes the proof. \u53e3 ", "page_idx": 36}, {"type": "text", "text": "K  Regret Analysis of NCO-OMS ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Algorithm 4 gives the pseudo-code of NCO-OMS. ", "page_idx": 36}, {"type": "text", "text": "Following the definition of NCO-OMS and Algorithm 4, it is obvious that the regret bound of NCO-OMS on each client is same with Theorem 2 in which we set $M=1$ .The regretbound on $M$ clients is $M$ times of that of a client. Thus we have Theorem 6. ", "page_idx": 36}, {"type": "text", "text": "Theorem 6 (Regret Bound of NCO-OMS). Let the learning rate n, $\\lambda_{t,i}$ and the initial distribution ${\\bf p}_{1}$ be same for each client $j\\in[M]$ . The values of , $\\lambda_{t,i}$ and $\\mathbf{p}_{1}$ follow Theorem 2 in which $M=1$ With probability at least $1-\\Theta\\left(M\\log(K T)\\right)\\cdot\\delta,$ . the regret of NCO-OMS satisfies: $\\forall i\\in[K],\\ {\\mathrm{Reg}}_{D}(\\mathcal{F}_{i})=O\\left(M\\left(B_{i,1}\\sqrt{\\left(1+g_{K,J}\\right)T}+B_{i,2}g_{K,J}\\ln\\frac{1}{\\delta}+B_{i,3}\\sqrt{g_{K,J}T\\ln\\frac{1}{\\delta}}\\right)\\right),$ where $B_{i,1}=U_{i}G_{i}+C_{i}\\sqrt{\\ln(K T)},B_{i,2}=C+U_{i}G_{i}$ and $B_{i,3}=U_{i}G_{i}+\\sqrt{C C_{i}}$ and $C=\\operatorname*{max}_{i}C_{i}$ ", "page_idx": 36}, {"type": "text", "text": "L Proof of Theorem 4 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "L.1 Algorithm ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "We give the pseudo-code in Algorithm 5. ", "page_idx": 36}, {"type": "text", "text": "To implement Algorithm 5, we require one more technique, i.e., the random features [Rahimi and Recht, 2007]. We will use the random features to construct an approximation of the implicity kernel mapping. The are two reasons. The first one is that we can avoid transferring the data itself and thus the privacy is protected. The second one is that we can avoid the ${\\cal O}(T)$ computational cost on the clients. ", "page_idx": 36}, {"type": "text", "text": "For any $i\\in[K]$ , we consider the kernel function $\\kappa_{i}(\\mathbf{x},\\mathbf{v})$ that has an integral representation, i.. ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\kappa_{i}(\\mathbf{x},\\mathbf{v})=\\int_{\\Gamma}\\varphi_{i}(\\mathbf{x},\\omega)\\varphi_{i}(\\mathbf{v},\\omega)\\mathrm{d}\\,\\mu_{i}(\\omega),\\;\\forall\\mathbf{x},\\mathbf{v}\\in\\mathcal{X},\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $\\varphi_{i}:\\mathcal{X}\\times\\Gamma\\to\\mathbb{R}$ is the eigenfunctions and $\\mu_{i}(\\cdot)$ is a distribution function on $\\Gamma$ . Let $p_{i}(\\cdot)$ be the density function of $\\mu_{i}(\\cdot)$ . We sample $\\{\\omega_{j}\\}_{j=1}^{D}\\sim\\dot{p_{i}}(\\omega)$ independently and compute ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\widetilde{\\kappa}_{i}(\\mathbf{x},\\mathbf{v})=\\frac{1}{D}\\sum_{j=1}^{D}\\varphi_{i}(\\mathbf{x},\\omega_{j})\\varphi_{i}(\\mathbf{v},\\omega_{j}).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "For  any $\\begin{array}{r l r}{f({\\bf x})}&{{}=}&{\\int_{\\Gamma}\\alpha(\\omega)\\varphi_{i}({\\bf x},\\omega)p_{i}(\\omega)\\mathrm{d}\\,\\omega}\\end{array}$ We  can approximate $f(\\mathbf{x})$ by $\\begin{array}{r l}{{\\hat{f}}(\\mathbf{x})}&{{}=}\\end{array}$ $\\begin{array}{r}{\\frac{1}{D}\\sum_{j=1}^{D}\\alpha(\\omega_{j})\\varphi_{i}(\\mathbf{x},\\omega_{j})}\\end{array}$ . It can be verified that $\\mathbb{E}[\\hat{f}(\\mathbf{x})]=f(\\mathbf{x})$ . Such an approximation scheme also defines an explicit feature mapping denoted by ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\phi_{i}(\\mathbf{x})=\\frac{1}{\\sqrt{D}}\\left(\\varphi_{i}(\\mathbf{x},\\omega_{1}),\\dots,\\varphi_{i}(\\mathbf{x},\\omega_{D})\\right).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "For each $\\kappa_{i},i\\in[K]$ , we define two hypothesis spaces [Rahimi and Recht, 2008, Li and Liao, 2022] asfollows ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathcal{F}_{i}=\\left\\{f({\\bf x})=\\int_{\\Gamma}\\alpha(\\omega)\\varphi_{i}({\\bf x},\\omega)p_{i}(\\omega)\\mathrm{d}\\,\\omega\\left\\vert|\\alpha(\\omega)|\\leq U_{i}\\right.\\right\\},}\\\\ {\\displaystyle\\mathbb{H}_{i}=\\left\\{\\hat{f}({\\bf x})=\\sum_{j=1}^{D}\\alpha_{j}\\varphi_{i}({\\bf x},\\omega_{j})\\left.\\left\\vert|\\alpha_{j}|\\leq\\frac{U_{i}}{D}\\right.\\right\\}\\,}\\\\ {\\displaystyle~~~=\\left\\{\\hat{f}({\\bf x})={\\bf w}^{\\top}\\phi_{i}({\\bf x})\\left.\\right\\vert{\\bf w}=\\sqrt{D}(\\alpha_{1},\\ldots,\\alpha_{D})\\in\\mathbb{R}^{D},\\vert\\alpha_{j}\\vert\\leq\\frac{U_{i}}{D}\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "in which ${\\mathcal{F}}_{i}$ is exact the hypothesis space defined in (1). ", "page_idx": 37}, {"type": "text", "text": "It can be verified that $\\lVert\\mathbf{w}\\rVert_{2}^{2}\\leq U_{i}^{2}$ .Let $\\begin{array}{r}{\\mathcal{W}_{i}=\\{\\mathbf{w}\\in\\mathbb{R}^{D}:\\|\\mathbf{w}\\|_{\\infty}\\leq\\frac{U_{i}}{\\sqrt{D}}\\}}\\end{array}$ We replace (9) with (22), ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle\\nabla_{\\overline{{\\mathbf{w}}}_{t+1,i}}\\psi_{t,i}(\\bar{\\mathbf{w}}_{t+1,i})=\\nabla_{\\mathbf{w}_{t,i}}\\psi_{t,i}(\\mathbf{w}_{t,i})-\\displaystyle\\frac{1}{M}\\displaystyle\\sum_{j=1}^{M}\\tilde{\\nabla}_{t,i}^{(j)},\\quad i=1,...,K,}\\\\ {\\displaystyle\\mathbf{w}_{t+1,i}=\\arg\\operatorname*{min}\\mathcal{D}_{\\psi_{t,i}}\\big(\\mathbf{w},\\bar{\\mathbf{w}}_{t+1,i}\\big),}\\\\ {\\displaystyle\\psi_{t,i}\\big(\\mathbf{w}\\big)=\\displaystyle\\frac{1}{2\\lambda_{t,i}}\\cdot\\|\\mathbf{w}\\|_{2}^{2}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "L.2 Regret Analysis ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "We first give an assumption and a technique lemma. ", "page_idx": 37}, {"type": "text", "text": "Assumption 2 (Li et al. [2019]). For any $i\\in[K]$ $\\cdot_{\\kappa_{i}}$ satisfies (20), then there is a bounded constant $b_{i}$ such that, $\\forall\\mathbf{x}\\in\\mathcal{X}$ $|\\varphi_{i}(\\mathbf{x},\\omega)|\\leq b_{i}$ ", "page_idx": 37}, {"type": "text", "text": "Under Assumption 2, we have $|f(\\mathbf{x})|\\leq U_{i}b_{i}$ for any $f\\in\\mathbb{H}_{i}$ and $f\\in\\mathcal{F}_{i}$ . It is worth mentioning that if Assumption 2 holds, then Assumption 1 holds with the same $b_{i}$ ", "page_idx": 37}, {"type": "text", "text": "Lemma 6. For any $i\\in[K]$ let ${\\mathcal{F}}_{i}$ and $\\mathbb{H}_{i}$ follow (21). With probability at least $1-\\delta,\\,\\forall f\\in\\mathcal{F}_{i}$ there is a $\\hat{f}\\in\\mathbb{H}_{i}$ such that $\\begin{array}{r}{|f(\\mathbf{x})-\\hat{f}(\\mathbf{x})|\\le\\frac{U b_{i}}{\\sqrt{D}}\\sqrt{2\\ln\\frac{1}{\\delta}}}\\end{array}$ ", "page_idx": 37}, {"type": "text", "text": "The lemma is adopted from Lemma 5 in [Li and Liao, 2023]. Thus we omit the proof.   \nNow we begin to prove Theorem 4. ", "page_idx": 37}, {"type": "text", "text": "Require: $U,T,R,J$   \nEnsure: $f_{1,i}^{(j)}=0,p_{1,i},i\\in[K],j\\in[M]$   \n1: for $r=1,2,\\ldots,R$ do   \n2: for $t\\in T_{r}$ do   \n3: $t==(r-1)N+1$ then   \n4: for $j=1,\\dots,M$ do   \n5: Server samples $O_{t}^{(j)}$ following (7)   \n6: Server transmits $\\mathbf{\\bar{w}}_{t,i},i\\in O_{t}^{(j)}$ to the $j$ -th client   \n7: end for   \n8: end if   \n9: for $j=1,\\dots,M$ in parallel do   \n10: for $i\\in O_{t}^{(j)}$ do   \n11: Computing $\\phi_{i}(\\mathbf{x}_{t}^{(j)})$   \n12: end for   \n13: Outputting $\\mathbf{w}_{t,A_{t,1}}^{\\top}\\phi_{A_{t,1}}\\!\\left(\\mathbf{x}_{t}^{(j)}\\right)$ and receiving $y_{t}^{(j)}$   \n14: for $i\\in O_{t}^{(j)}$ do   \n15: nCompuing $\\nabla_{t,i}^{(j)}$ $c_{t,i}^{(j)}$   \n16: end for   \n17: end for   \n181 $t==r N$ $\\begin{array}{r}{\\{\\frac{1}{N}\\sum_{t\\in T_{r}}\\nabla_{t,i}^{(j)},\\frac{1}{N}\\sum_{t\\in T_{r}}c_{t,i}^{(j)}\\}_{i\\in O_{t}^{(j)}}}\\end{array}$ tosever   \n20: Server computes $\\mathbf{p}_{t+1}$ following (8)   \n21: Servercomputes $\\mathbf{w}_{t+1,i},i\\in[K]$ following (22)   \n22: end if   \n23: end for   \n24: end for ", "page_idx": 38}, {"type": "text", "text": "Proof of Theorem 4. The regret w.r.t. any $f\\in\\mathcal{F}_{i}$ can be decomposed as follows. ", "page_idx": 38}, {"type": "image", "img_path": "uqWfLgZpV1/tmp/2e296cd6eb2e5a0bf9d901ae6c55ebf5f74044fcbf93defaadf82da2fd47278b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "${\\mathrm{Reg}}_{D}(\\mathbb{H}_{i})$ is the regret that we run FOMD-OKS with hypothesis spaces $\\{\\mathbb{H}_{i}\\}_{i=1}^{K}$ $\\hat{f}\\in\\mathbb{H}_{i}$ satisfies Lemma 6. In other words, $\\Xi_{6}$ is induced by the approximation error that we use $\\hat{f}$ to approximate $f$ ${\\mathrm{Reg}}_{D}(\\mathbb{H}_{i})$ has been given by Theorem 5. Next we analyze $\\Xi_{6}$ ", "page_idx": 38}, {"type": "text", "text": "Using the convexity of $\\ell(\\cdot,\\cdot)$ , with probability at least $1-T M\\delta$ ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi_{6}\\leq\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{j=1}^{M}\\frac{\\mathrm{d}\\ell\\left(\\hat{f}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)}{\\mathrm{d}\\hat{f}(\\mathbf{x}_{t}^{(j)})}\\cdot\\left(\\hat{f}(\\mathbf{x}_{t}^{(j)})-f(\\mathbf{x}_{t}^{(j)})\\right)}\\\\ &{\\ \\ \\ \\leq\\displaystyle\\sum_{t=1}^{T}\\displaystyle\\sum_{j=1}^{M}\\left|\\frac{\\mathrm{d}\\ell\\left(\\hat{f}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)}{\\mathrm{d}\\hat{f}(\\mathbf{x}_{t}^{(j)})}\\right|\\cdot\\left|\\hat{f}(\\mathbf{x}_{t}^{(j)})-f(\\mathbf{x}_{t}^{(j)})\\right|}\\\\ &{\\ \\ \\ \\leq_{g h}b_{t}\\overline{{\\sum_{j}}}\\sqrt{2\\ln\\frac{1}{\\delta}}}\\\\ &{\\leq G_{i}U_{i}\\displaystyle\\frac{M T}{\\sqrt{D}}\\sqrt{2\\ln\\frac{1}{\\delta}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Under Assumption 2, there is a constant $g_{i}$ such that $\\left|\\frac{\\mathrm{~d~}\\ell\\left(\\hat{f}(\\mathbf{x}_{t}^{(j)}),y_{t}^{(j)}\\right)}{\\mathrm{~d~}\\hat{f}(\\mathbf{x}_{t}^{(j)})}\\right|\\,\\leq\\,g_{i}$ . The last inequality comes from the definition of Lipschitz constant (see Lemma 2). ", "page_idx": 39}, {"type": "text", "text": "Combining the upper bounds on ${\\mathrm{Reg}}_{D}(\\mathbb{H}_{i})$ and $\\Xi_{6}$ concludes the proof. ", "page_idx": 39}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: We have clearly stated our main results, technical contributions and scope in the abstract and introduction. The main results are also supported by our theoretical and experimental results. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and refect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 40}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Justification: We have discussed the limitations of this work in appendix (Section A). Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u25cf The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u25cf The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should refect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u25cf If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 40}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: We have give all assumptions in the main paper. Due to the limited space, we do not include proof sketches in the main paper, but give a complete and correct proof for each theoretical result (including lemma and theorem) in appendix. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u25cf The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u25cf Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 41}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: We have clearly state the experimental setting and datasets, and give the datasets and code in supplemental material. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 41}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: All of the datasets used in this paper are public. The datasets and code of all algorithms are available at https : //github. com/ JunfLi-TJU/OMS-DecD . git. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u25cf At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 42}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: We have clearly specified the experimental setting in appendix (Section C) including basic information of datasets, the type of hyperparameters, the value of hyperparameters and so on. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u25cf The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 42}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: We have reported the error bar which is the standard deviation of the mean. We run each experiment 10 times, record the mean of 10 random results (including MSE and running time) and the standard deviation of the mean. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u25cf It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 43}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We have stated the compute resources in the experimental setting (Section C). All algorithms are implemented with R on a Windows machine with 2.8 GHz Core(TM) i7-1165G7 CPU. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u25cf The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 43}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We have reviewed the NeurIPs Code of Ethics and our research conforms with the NeurIPS Code of Ethics. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u25cf The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 43}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We have included the broader impacts in appendix (Section B) Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 44}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: Our paper poses no such risks. Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u25cf The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 44}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We use public datasets and give the URL from which the datasets are downloaded. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets. \u00b7 The authors should cite the original paper that produced the code package or dataset. \u00b7 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 45}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We have provided the code of our algorithms with a simplified documentation available at https: //github. com/ JunfLi-TJU/OMS-DecD.git. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u25cf At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 45}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u25cf The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 45}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 45}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 45}, {"type": "text", "text": "\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 46}]