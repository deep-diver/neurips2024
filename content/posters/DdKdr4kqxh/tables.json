[{"figure_path": "DdKdr4kqxh/tables/tables_6_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on a synthetic dataset based on CERRA reanalysis data.  It compares the proposed method's performance against several baseline approaches, including those based on integrated gradients, one-class unsupervised learning, reconstruction-based methods, and multiple instance learning. The table shows the F1-score, Intersection over Union (IoU), and Overall Accuracy (OA) metrics for both the validation and testing sets, highlighting the best-performing method for each metric.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_8_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents a comparison of different algorithms for driver detection on a synthetic CERRA reanalysis dataset.  It shows the F1-score, Intersection over Union (IoU), and Overall Accuracy (OA) for both validation and testing sets. The algorithms compared include several anomaly detection methods (one-class, reconstruction-based, multiple instance learning), interpretable forecasting methods, and the authors' proposed method.  The best-performing algorithm in each metric is highlighted.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_21_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on a synthetic dataset based on CERRA reanalysis.  It compares the proposed method's performance against several baselines, including methods from interpretable forecasting, one-class unsupervised, reconstruction-based, and multiple instance learning approaches. The results are evaluated using three metrics: F1-score, Intersection over Union (IoU), and Overall Accuracy (OA). For each metric, the best performing algorithm is highlighted in bold.  The standard deviation is reported to reflect the variability of the results across three runs.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_21_2.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of driver detection experiments performed on a synthetic dataset generated using CERRA reanalysis data.  It compares the proposed method with several baseline methods across different metrics: F1-score (higher is better, indicates the balance between precision and recall), IoU (Intersection over Union, higher is better, indicates the overlap between predicted and ground truth driver locations), and OA (Overall Accuracy, higher is better, indicates the percentage of correctly classified pixels).  The best performance for each metric is highlighted in bold, and standard deviations over 3 independent runs are provided.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_22_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on a synthetic dataset based on the CERRA reanalysis.  It compares the proposed method's performance against several baseline approaches, including those based on interpretable forecasting, one-class, reconstruction-based, and multiple instance learning methods. The table shows the F1-score, Intersection over Union (IoU), and Overall Accuracy (OA) metrics for both validation and test sets. The best performance for each metric is highlighted in bold, and standard deviations across three runs are also included.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_28_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on the synthetic CERRA dataset. It compares the performance of the proposed model against several baselines, including those based on interpretable forecasting, one-class unsupervised methods, reconstruction-based methods, and multiple instance learning.  The table displays F1-score, Intersection over Union (IoU), and Overall Accuracy (OA) metrics for both validation and test sets, highlighting the best performance for each metric.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_29_1.jpg", "caption": "Table 8: Ablation studies on the quantization layer. The metric is F1-score on the driver/extreme detection.", "description": "This table presents the results of ablation studies conducted on the quantization layer of the proposed model.  Different quantization methods were tested: Threshold (Tanh), Random Quantization (RQ), Vector Quantization (VQ) with and without orthogonality, Finite Scalar Quantization (FSQ), and Lookup-free Quantization (LFQ). The F1-score, a metric evaluating the balance between precision and recall, is reported for both driver and extreme event detection for each method.  The table shows how the choice of quantization method significantly impacts the model's performance.", "section": "C.1 Quantization layer"}, {"figure_path": "DdKdr4kqxh/tables/tables_29_2.jpg", "caption": "Table 8: Ablation studies on the quantization layer. The metric is F1-score on the driver/extreme detection.", "description": "This table presents the ablation study on different quantization methods used in the proposed model for identifying spatio-temporal drivers of extreme events.  The F1-score metric evaluates the performance of each quantization method on both driver and extreme event detection tasks. The results show that the Lockup-free quantization (LFQ) method outperforms other methods.", "section": "C.1 Quantization layer"}, {"figure_path": "DdKdr4kqxh/tables/tables_30_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on a synthetic dataset based on CERRA reanalysis data.  It compares the proposed method's performance against several baseline methods across three evaluation metrics: F1-score, Intersection over Union (IoU), and Overall Accuracy (OA).  The results are shown for both the validation and test sets, with the best performance for each metric highlighted. The standard deviation for three independent runs is also included, providing insights into the reliability of the results.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_30_2.jpg", "caption": "Table 11: Ablation study on the backbone  used for feature extraction. The metric is F1-score on the driver/extreme detection.", "description": "This table presents the ablation study on the backbone used for feature extraction in the proposed model. Three different backbones are compared: 3D CNN, Video Swin Transformer, and Mamba.  For each backbone, three different hidden dimensions (K) are tested: 8, 16, and 32. The table shows the number of parameters for each configuration and the resulting F1-score on both driver and extreme detection tasks. This helps to understand the impact of backbone architecture and its complexity on the performance of the model.", "section": "C Ablation studies"}, {"figure_path": "DdKdr4kqxh/tables/tables_30_3.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on a synthetic dataset based on CERRA reanalysis data.  It compares the proposed approach against several baseline methods, including those based on interpretable forecasting, one-class unsupervised learning, reconstruction-based methods, and multiple instance learning.  The table provides the F1-score, Intersection over Union (IoU), and Overall Accuracy (OA) metrics for both validation and test sets, highlighting the best-performing model for each metric.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_31_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on a synthetic dataset based on CERRA reanalysis data.  It compares the proposed model's performance to several baseline methods across three evaluation metrics: F1-score, Intersection over Union (IoU), and Overall Accuracy (OA). The results are shown for both the validation and test sets.  The best performing model for each metric on each set is highlighted in bold. The \u00b1 symbol indicates the standard deviation calculated across three separate runs for each model, providing an estimate of the variability in performance.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_32_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents a quantitative comparison of the proposed driver detection model against several baseline methods on a synthetic dataset mimicking CERRA reanalysis data.  The performance is evaluated across three metrics: F1-score, Intersection over Union (IoU), and Overall Accuracy (OA).  The results are shown for both validation and testing sets, and the best performance for each metric is highlighted.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_32_2.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on the synthetic CERRA dataset.  It compares the proposed model's performance against several baseline methods across three evaluation metrics: F1-score, Intersection over Union (IoU), and Overall Accuracy (OA).  The results are shown for both the validation and test sets, allowing for an assessment of the model's generalization capabilities.  The best performance for each metric is highlighted in bold.  Standard deviation values are included to indicate the variability of the results across three independent experimental runs. The naive baseline provides a simple comparison, showing results when all variables are assumed to be drivers for all extreme event pixels.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_33_1.jpg", "caption": "Table 16: The relation between the definition of extremes from VHI and the model prediction. The metric is F1-score (\u2191) on the extreme droughts detection for the validation sets.", "description": "This table shows the impact of different thresholds for defining extreme drought events (using the Vegetation Health Index, VHI) on the model's ability to detect them.  It compares the F1-score of the model for three different VHI thresholds (VHI<26, VHI<40, VHI<50) when using either only soil temperature (stl1) or a set of multiple input variables ({t2m, fal, e, tp, stl1, swvll}) for prediction.  The results illustrate the sensitivity of extreme event detection to how extreme events are defined.", "section": "D.3 Scientific validity"}, {"figure_path": "DdKdr4kqxh/tables/tables_33_2.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on the synthetic CERRA dataset.  It compares the proposed method's performance against several baseline methods across three evaluation metrics: F1-score, Intersection over Union (IoU), and Overall Accuracy (OA). The best result for each metric is highlighted in bold.  Standard deviations across three separate runs are also provided, giving a measure of the model's consistency. The table shows the performance on both the validation and test splits of the dataset, giving a comprehensive evaluation of the different models' performance.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_35_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on a synthetic dataset based on CERRA reanalysis. It compares the proposed model's performance against several baseline methods across different metrics: F1-score, IoU, and overall accuracy (OA).  The best performing model for each metric is highlighted in bold.  The standard deviation across three runs is included to show the consistency of the results.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_35_2.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of the driver detection task on the synthetic CERRA dataset.  It compares the proposed model's performance against several baseline methods across various metrics: F1-score, Intersection over Union (IoU), and Overall Accuracy (OA).  The results are shown for both validation and test sets, and standard deviations are provided to indicate the stability of the results. The best performance for each metric is clearly highlighted.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_36_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of driver detection experiments conducted on a synthetic CERRA reanalysis dataset.  It compares the proposed method's performance (F1-score, IoU, and overall accuracy) against several baseline methods representing various anomaly detection approaches (one-class, reconstruction-based, and multiple instance learning), as well as a naive baseline. The table highlights the best performing model for each evaluation metric, showing the superiority of the proposed approach.  The standard deviation for three experimental runs is included to demonstrate reliability.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_37_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents a quantitative comparison of the proposed driver detection method against several baseline methods on a synthetic CERRA reanalysis dataset.  The metrics used for comparison include F1-score, Intersection over Union (IoU), and Overall Accuracy (OA). The best-performing method for each metric is highlighted in bold. The standard deviation across three runs is also provided to show the variability of the results.", "section": "5.1 Experiments on the synthetic datasets"}, {"figure_path": "DdKdr4kqxh/tables/tables_38_1.jpg", "caption": "Table 1: Driver detection results on the synthetic CERRA reanalysis. The best performance on each metric is highlighted in a bold text. (\u00b1) denotes the standard deviation for 3 runs.", "description": "This table presents the quantitative results of driver detection experiments conducted on a synthetic dataset based on the CERRA reanalysis.  It compares the performance of the proposed model against several baseline methods across different evaluation metrics: F1-score (higher is better, indicating accuracy in identifying drivers), IoU (Intersection over Union, higher is better, measuring the overlap between predicted and actual driver regions), and OA (Overall Accuracy, higher is better, showing the overall correctness of the prediction). The best performance in each metric for each baseline is highlighted.  The standard deviations across three separate runs are provided, illustrating the stability and reliability of the results.  The 'Naive' baseline represents a simple strategy for comparison.", "section": "5.1 Experiments on the synthetic datasets"}]