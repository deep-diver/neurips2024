[{"figure_path": "yAa5l92TtQ/tables/tables_3_1.jpg", "caption": "Table 1: Comparing with baseline. The table displays the pass@1 success rates of the baselines and POETRY. The highest success rates for each set are highlighted in bold.", "description": "This table compares the performance of POETRY against several baseline methods (Thor w/o sledgehammer, GPT-f Baseline with sampling decoding, and GPT-f Baseline with beam search decoding) and shows the pass@1 success rate for each method on three different datasets: miniF2F-valid, miniF2F-test, and PISA (split into single-level and multi-level subsets).  The highest success rate for each dataset is highlighted in bold, indicating POETRY's superior performance.", "section": "4 Experiments"}, {"figure_path": "yAa5l92TtQ/tables/tables_6_1.jpg", "caption": "Table 1: Comparing with baseline. The table displays the pass@1 success rates of the baselines and POETRY, The highest success rates for each set are highlighted in bold.", "description": "This table compares the performance of POETRY against several baseline methods on three datasets: miniF2F-valid, miniF2F-test, and PISA.  For the PISA dataset, results are further broken down into single-level and multi-level subsets based on proof complexity.  The table shows the pass@1 success rate (percentage of problems solved in one attempt) for each method on each dataset/subset.  The highest success rates for each dataset/subset are highlighted in bold. The baselines include Thor without sledgehammer and two versions of a GPT-f baseline (one with and one without sampling decoding).", "section": "4.1 Experimental Setup"}, {"figure_path": "yAa5l92TtQ/tables/tables_6_2.jpg", "caption": "Table 2: Comparing with state-of-the-art search-based methods on the miniF2F dataset. The table displays the pass@1 success rates of previous works and POETRY, The highest success rates for each set are highlighted in bold.", "description": "This table compares the performance of POETRY against other state-of-the-art search-based neural theorem proving methods on the miniF2F dataset.  It shows the pass@1 success rate (percentage of theorems correctly proven in a single attempt) for each method, broken down by the miniF2F-valid and miniF2F-test sets.  The table highlights POETRY's superior performance compared to existing methods across both datasets.", "section": "4.2 Main Results"}, {"figure_path": "yAa5l92TtQ/tables/tables_14_1.jpg", "caption": "Table 3: Dataset statistics. The table displays the dataset statistics for our newly extracted PISA dataset based on Isabelle 2022.", "description": "This table presents a statistical overview of the newly curated PISA dataset, which is based on Isabelle 2022. It provides the number of theorems, proof steps, average and maximum proof lengths, average and maximum proof levels for the training, validation, and test sets. Additionally, it breaks down these statistics for single-level and multi-level problems within the test set.", "section": "4.1 Experimental Setup"}, {"figure_path": "yAa5l92TtQ/tables/tables_15_1.jpg", "caption": "Table 2: Comparing with state-of-the-art search-based methods on the miniF2F dataset. The table displays the pass@1 success rates of previous works and POETRY, The highest success rates for each set are highlighted in bold.", "description": "This table compares the performance of POETRY against other state-of-the-art search-based neural theorem provers on the miniF2F dataset.  It shows the pass@1 success rate (the percentage of problems solved in a single attempt) for each method. The methods are categorized by the formal environment they use (Lean or Isabelle) and the results highlight POETRY's superior performance.", "section": "4.2 Main Results"}, {"figure_path": "yAa5l92TtQ/tables/tables_16_1.jpg", "caption": "Table 1: Comparing with baseline. The table displays the pass@1 success rates of the baselines and POETRY, The highest success rates for each set are highlighted in bold.", "description": "This table compares the performance of POETRY against several baseline methods on three datasets: miniF2F (valid and test sets) and PISA (single-level and multi-level sets).  The pass@1 metric represents the success rate of proving a theorem in a single attempt.  The table highlights POETRY's superior performance, particularly on the miniF2F datasets, showing a significant improvement over the baseline methods. The results also indicate that POETRY performs better with more complex, multi-level proofs within the PISA dataset.", "section": "4.1 Experimental Setup"}]