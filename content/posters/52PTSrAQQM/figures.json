[{"figure_path": "52PTSrAQQM/figures/figures_1_1.jpg", "caption": "Figure 1: The overall pipeline of our framework. A top-down pathway is introduced into slot attention to utilize top-down information. The pathway consists of two parts: bootstrapping top-down knowledge and exploiting them. Firstly, semantic information is bootstrapped from slot attention outputs by mapping slots to discrete codes from a learned codebook through vector quantization. Secondly, slot attention is modulated using these codes and its attention maps, transforming it into a self-modulating module. Inner activations are modulated across channels with codes and across space with centered attention maps. Slot attention is then repeated with these modulated activations, yielding more representative slots.", "description": "This figure illustrates the architecture of the proposed self-modulating slot attention framework.  It shows how a top-down pathway is integrated into the standard slot attention mechanism.  The top-down pathway first bootstraps semantic information from the slot attention outputs using a codebook and vector quantization. This semantic information is then used to modulate the slot attention, improving the representation quality of the extracted object slots. The modulation happens both across channels and space, using attention maps. Finally, the modulated slot attention is repeated to refine the slots further.", "section": "1 Introduction"}, {"figure_path": "52PTSrAQQM/figures/figures_8_1.jpg", "caption": "Figure A6: Visualization of the input image, predicted object mask, and attention maps of slot attention before and after self-modulation on COCO [29]. Lighter the color, higher the attention score.", "description": "This figure visualizes the impact of self-modulation on slot attention.  It shows four examples of images from the COCO dataset. For each example, there are three columns. The first column shows the original image. The second column shows the predicted object mask after applying the self-modulating slot attention. The third column shows the slot attention maps before and after self-modulation. This illustrates how the self-modulation process refines the attention maps and highlights objects more precisely. Lighter colors in the attention maps indicate higher attention scores.", "section": "Appendices"}, {"figure_path": "52PTSrAQQM/figures/figures_9_1.jpg", "caption": "Figure 2: Visualization of the codebook C on COCO [29]. The results show that the codebook learns to capture recurring semantic concepts in the dataset, such as \u2018pizza\u2019 (code 124), \u2018sign\u2019 (code 496), \u2018clock\u2019 (code 235), \u2018zebra\u2019 (code 207), \u2018motorcycle\u2019 (code 341), \u2018surfer\u2019 (code 352), \u2018dog\u2019 (code 359), and \u2018skier\u2019 (code 343).", "description": "This figure visualizes examples from a learned codebook used in the proposed model. Each code in the codebook represents a distinct semantic concept, and the figure shows example images associated with each code, demonstrating that the codebook successfully learns high-level semantic information about different object categories.", "section": "4.3 Qualitative Results"}, {"figure_path": "52PTSrAQQM/figures/figures_13_1.jpg", "caption": "Figure A5: Visualization of CLEVR6 [20].", "description": "This figure shows a qualitative comparison of object segmentation results using slot attention with and without the proposed top-down pathway. The top row displays results obtained using standard slot attention, while the bottom row presents results after incorporating the top-down pathway. The improved segmentation in the bottom row demonstrates the effectiveness of the top-down pathway in refining the attention process.", "section": "Additional Experiments"}, {"figure_path": "52PTSrAQQM/figures/figures_15_1.jpg", "caption": "Figure A6: Visualization of the input image, predicted object mask, and attention maps of slot attention before and after self-modulation on COCO [29]. Lighter the color, higher the attention score.", "description": "This figure visualizes the results of the proposed self-modulating slot attention model on the MS COCO dataset.  It shows comparisons between the original images, the model's prediction of object masks, and the slot attention maps before and after the application of self-modulation.  The color intensity in the attention maps corresponds to the attention score; lighter colors indicate higher attention scores. This visualization demonstrates the impact of self-modulation on refining the attention maps to more precisely delineate individual objects in complex scenes.", "section": "Appendices"}]