{"references": [{"fullname_first_author": "Sanjeev Arora", "paper_title": "A theory for emergence of complex skills in language models", "publication_date": "2023-07-15", "reason": "Provides a theoretical framework for understanding the emergence of complex skills in large language models, which is directly relevant to the paper's investigation of inductive biases."}, {"fullname_first_author": "Nikunj Saunshi", "paper_title": "Understanding contrastive learning requires incorporating inductive biases", "publication_date": "2022-00-00", "reason": "Formalizes the concept of inductive bias in the context of contrastive learning, which is relevant to the paper's focus on the inductive bias of stacking in language models."}, {"fullname_first_author": "Hong Liu", "paper_title": "Same pre-training loss, better downstream: Implicit bias matters for language models", "publication_date": "2023-00-00", "reason": "Highlights the importance of implicit bias in language models, showing that different pre-training methods can lead to different downstream performance despite having similar pre-training loss, which aligns with the paper's findings."}, {"fullname_first_author": "Linyuan Gong", "paper_title": "Efficient training of bert by progressively stacking", "publication_date": "2019-00-00", "reason": "Introduces the concept of progressive stacking, a training strategy that the current paper builds upon and improves with the MIDAS method."}, {"fullname_first_author": "Sashank Reddi", "paper_title": "Efficient training of language models using few-shot learning", "publication_date": "2023-00-00", "reason": "Presents gradual stacking, a key method compared against in the current work; understanding gradual stacking's limitations is central to the current work's improvements."}]}