[{"figure_path": "EFkw0OgZOr/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between point cloud-based and image-based open-vocabulary 3D object detection methods. During training, point cloud-based approaches require corresponding point cloud and image data to derive pseudo labels, while image-based methods can leverage large-scale image data and the most advanced depth estimation models for pseudo-label generation. During inference, point cloud-based methods necessitate expensive LiDAR or other 3D sensors for deployment, whereas image-based approaches only require a camera.", "description": "This figure compares point cloud-based and image-based open-vocabulary 3D object detection methods.  The main difference lies in the data used for training and inference. Point cloud-based methods require both point cloud and image data, making them expensive to deploy due to the need for LiDAR. In contrast, the proposed image-based method uses only RGB images, making it more cost-effective and scalable.  The figure clearly illustrates the differences in training and inference stages for both approaches.", "section": "1 Introduction"}, {"figure_path": "EFkw0OgZOr/figures/figures_2_1.jpg", "caption": "Figure 2: Comparison between LiDAR data and pseudo-LiDAR. Although pseudo-LiDAR is much denser than LiDAR, it is highly noisy (as highlighted in the red boxes), making it inadequate for directly generating accurate 3D bounding boxes.", "description": "This figure compares LiDAR data with pseudo-LiDAR data generated from a single RGB image and a depth estimation model.  It highlights the density advantage of pseudo-LiDAR but emphasizes its significant noise compared to the ground truth LiDAR data. The red boxes show regions with the most prominent noise artifacts in the pseudo-LiDAR data, demonstrating its unsuitability for direct 3D bounding box generation. This illustrates a key challenge addressed by the paper\u2019s proposed method.", "section": "2 Related Works"}, {"figure_path": "EFkw0OgZOr/figures/figures_3_1.jpg", "caption": "Figure 3: The overall framework of OVM3D-Det. Step 1: Generate per-instance pseudo-LiDAR. Step2: Apply an adaptive erosion process to remove artifacts and noises. Step 3: Estimate the orientation. Step 4: Tightly fit a box and utilize object priors to assess the estimated box; if deemed unreasonable, search for the optimal box. Step 5: Train the model with pseudo labels.", "description": "This figure shows the overall framework of the OVM3D-Det model, which is a novel open-vocabulary monocular 3D object detection framework. The framework consists of five main steps: 1. Pseudo-LiDAR Generation: generating pseudo-LiDAR point clouds from RGB images using a depth estimation model and an open-vocabulary 2D detector. 2. Adaptive Pseudo-LiDAR Erosion: removing artifacts and noises from the pseudo-LiDAR using an adaptive erosion process based on object size. 3. Box Orientation Estimation: estimating the ground plane and using principal component analysis to determine the orientation of 3D bounding boxes. 4. Bounding Box Search: tightly fitting a bounding box around the pseudo-LiDAR points and using object priors from large language models to refine the bounding box if necessary. 5. Training: training the monocular 3D object detector using the refined pseudo labels.", "section": "3 Method"}, {"figure_path": "EFkw0OgZOr/figures/figures_5_1.jpg", "caption": "Figure 4: Ray tracing loss and point ratio loss.", "description": "This figure illustrates the two loss functions used in the bounding box search process.  (a) shows the ray tracing loss, which calculates the distance between each LiDAR point and the nearest intersection point between the proposal box and the camera ray.  (b) shows the point ratio loss, which calculates the ratio of points inside the box to the total number of points. These two loss functions are combined to select the best-fitting proposal box.", "section": "3.2 Generate Pseudo 3D Bounding Boxes"}, {"figure_path": "EFkw0OgZOr/figures/figures_9_1.jpg", "caption": "Figure 5: Qualitative results on SUN RGB-D and KITTI.", "description": "This figure shows some qualitative results of the proposed OVM3D-Det model on SUN RGB-D and KITTI datasets.  The images display 3D bounding boxes around detected objects with their class labels. This visually demonstrates the model's ability to perform open-vocabulary 3D object detection in both indoor (SUN RGB-D) and outdoor (KITTI) scenes.", "section": "4.4 Qualitative Results"}, {"figure_path": "EFkw0OgZOr/figures/figures_9_2.jpg", "caption": "Figure 6: Effect of training data. As the volume of training data grows, we consistently see performance improvements.", "description": "This figure shows the impact of the amount of training data used on the model's performance.  The x-axis represents the percentage of training data used, and the y-axis represents the average precision (AP) achieved by the model.  The plot shows a clear upward trend, indicating that as more training data is used, the model's performance improves consistently.", "section": "4 Experiments"}, {"figure_path": "EFkw0OgZOr/figures/figures_16_1.jpg", "caption": "Figure 7: Diagram of the erosion process of M<sub>i</sub>. To perform the erosion operation M<sub>i</sub> \u2192 B, first place the structuring element B over each pixel of M<sub>i</sub>. If every foreground pixel of B aligns with a foreground pixel of M<sub>i</sub>, then the central pixel of B in M<sub>i</sub> will retain the value of 1. If not, that central pixel will be set to 0.", "description": "This figure shows an example of image erosion using a 3x3 kernel. Image erosion is a morphological operation that shrinks or wears away the boundaries of foreground objects in a binary image. The figure illustrates how the erosion process works by showing how a 3x3 kernel is applied to the original binary image (left) to produce an eroded image (right). The result is a smaller, smoother image with less noise at the edges of objects.", "section": "C Image Erosion Process"}, {"figure_path": "EFkw0OgZOr/figures/figures_17_1.jpg", "caption": "Figure 5: Qualitative results on SUN RGB-D and KITTI.", "description": "This figure shows qualitative results of the proposed OVM3D-Det model on SUN RGB-D and KITTI datasets. The images display the model's ability to detect and localize objects of various types and sizes in both indoor and outdoor scenes.  The model successfully identifies and draws bounding boxes around objects such as cars, trucks, and pedestrians. This demonstrates the model's capability in open-vocabulary 3D object detection.", "section": "4.4 Qualitative Results"}]