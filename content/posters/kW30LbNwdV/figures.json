[{"figure_path": "kW30LbNwdV/figures/figures_1_1.jpg", "caption": "Figure 1: The comparison between the sample-based fair adversarial training and our label-based fair adversarial training. For the former ideology in (a), the trained model's bias is avoided by re-weighting the sample's importance according to the different contribution to fairness. For the latter ideology in (b), the trained model's bias is avoided by re-temperating the smoothness degree of soft labels for different classes.", "description": "This figure compares two approaches to achieving fairness in adversarial training.  The left side (a) shows sample-based fair adversarial training, where the model's bias is addressed by re-weighting training samples based on their contribution to fairness. Samples from hard classes (those the model struggles to classify correctly) are weighted more heavily. The right side (b) illustrates the proposed label-based approach. It focuses on modifying the soft labels (probability distributions over classes) rather than sample weights.  The smoothness of the soft labels is adjusted; harder classes receive sharper (less smooth) labels and easier classes receive smoother labels, influencing the model\u2019s learning process and mitigating bias.", "section": "1 Introduction"}, {"figure_path": "kW30LbNwdV/figures/figures_3_1.jpg", "caption": "Figure 2: The class-wise and average robustness of DNNs guided by soft labels with the same smoothness degree (SSD) and different smoothness degree (DSD) for different classes, respectively. For the soft labels with different smoothness degrees, we use sharper soft labels for hard classes and use smoother soft labels for easy classes. We select two DNNs (ResNet-18 and MobileNet-v2) trained by SAT [20] on CIFAR-10. The robust accuracy is evaluated based on PGD. The checkpoint is selected based on the best checkpoint of the highest mean value of all-class average robustness and the worst class robustness following [36]. We see that blue lines and red lines have similar average robustness, but the worst robustness of blue lines are remarkably improved compared with red lines.", "description": "This figure compares the class-wise robustness of two different models (ResNet-18 and MobileNetV2) trained with soft labels having either the same or different smoothness degrees across classes.  Using sharper soft labels for harder classes and smoother ones for easier classes improves the worst-case robustness without significantly affecting the average robustness, indicating that adjusting the smoothness of soft labels can help mitigate the robust fairness problem.", "section": "3 Robust Fairness via Smoothness Degree of Soft Labels"}, {"figure_path": "kW30LbNwdV/figures/figures_8_1.jpg", "caption": "Figure 3: The class-wise robustness (PGD) of models guided by RSLAD and ABSLD on CIFAR-10. We can see that the harder classes' robustness (class 3, 4, 5, 6) of ABSLD (blue lines) have different levels of improvement compared with RSLAD (red lines).", "description": "This figure shows the class-wise robustness of ResNet-18 and MobileNet-v2 models trained using RSLAD and ABSLD methods against PGD attacks on CIFAR-10 dataset. It compares the robustness of each class individually, highlighting that ABSLD significantly improves the robustness of harder classes (classes 3-6) compared to RSLAD.", "section": "5.2 Robust Fairness Performance"}, {"figure_path": "kW30LbNwdV/figures/figures_8_2.jpg", "caption": "Figure 3: The class-wise robustness (PGD) of models guided by RSLAD and ABSLD on CIFAR-10. We can see that the harder classes' robustness (class 3, 4, 5, 6) of ABSLD (blue lines) have different levels of improvement compared with RSLAD (red lines).", "description": "This figure compares the class-wise robustness of ResNet-18 and MobileNet-v2 models trained using RSLAD and ABSLD against PGD attacks.  It shows that ABSLD improves the robustness of harder classes more than RSLAD, indicating its effectiveness in addressing the robust fairness problem. The x-axis represents the class index and the y-axis represents the robust accuracy.", "section": "5.2 Robust Fairness Performance"}]