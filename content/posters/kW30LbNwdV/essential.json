{"importance": "This paper is crucial for AI researchers working on **adversarial robustness** and **fairness**.  It addresses a critical issue of imbalanced robustness across different classes, offering a novel approach that improves both robustness and fairness. The proposed method, ABSLD, provides a new avenue for enhancing model security and reliability, impacting various applications of deep learning. This research paves the way for more secure and equitable AI systems.", "summary": "Boosting adversarial robustness fairness in deep neural networks, Anti-Bias Soft Label Distillation (ABSLD) adaptively adjusts soft label smoothness to reduce error gap between classes.", "takeaways": ["ABSLD addresses adversarial robustness fairness by adjusting the smoothness of soft labels for different classes.", "The method improves both robustness and fairness metrics compared to existing techniques.", "The approach is theoretically sound and empirically verified across different datasets and models."], "tldr": "Deep neural networks (DNNs) are susceptible to adversarial attacks, and adversarial training (AT) is used to mitigate this issue. However, the resulting models often exhibit strong robustness for some classes ('easy' classes) and weak robustness for others ('hard' classes), a phenomenon known as robust fairness. Existing works attempted to solve this issue by re-weighting the training samples, ignoring the information embedded in the labels that guide the model training process. This paper introduces an in-depth analysis of this phenomenon.\nThe paper proposes Anti-Bias Soft Label Distillation (ABSLD), a new method that addresses this issue.  ABSLD operates within the knowledge distillation (KD) framework, modifying how the 'teacher' model's soft labels are used to train the 'student' model. ABSLD selectively sharpens soft labels for hard classes and smoothes them for easy classes. This is achieved by assigning different temperatures to the KD process for different classes, effectively controlling the class-wise smoothness of soft labels. The results of extensive experiments demonstrate that ABSLD outperforms other state-of-the-art methods in terms of both robustness and fairness.", "affiliation": "Institute of Artificial Intelligence, Beihang University", "categories": {"main_category": "AI Theory", "sub_category": "Robustness"}, "podcast_path": "kW30LbNwdV/podcast.wav"}