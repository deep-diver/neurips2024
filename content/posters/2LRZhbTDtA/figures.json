[{"figure_path": "2LRZhbTDtA/figures/figures_1_1.jpg", "caption": "Figure 1: Differences between Class Incremental Learning (class-IL), Blurry Incremental Learning (blur-IL), and Compositional Incremental Learning (composition-IL). The object classes are not allowed to recur in the class-IL scenario, whereas they may recur randomly in the blur-IL scenario. Different from them, the classes in composition-IL involve state-object compositions apart from the object classes. Besides, the compositions do not reoccur, but the primitives (states or objects) may randomly reappear across incremental sessions.", "description": "This figure illustrates the differences between three incremental learning paradigms: Class Incremental Learning (class-IL), Blurry Incremental Learning (blur-IL), and Compositional Incremental Learning (composition-IL).  Class-IL strictly prohibits the recurrence of previously seen object classes in new tasks. Blur-IL relaxes this constraint, allowing for the random reappearance of previously seen classes. Composition-IL focuses on learning state-object compositions (e.g., 'brown pants', 'yellow dress'). While object and state primitives can reappear across tasks, the specific state-object combinations are unique to each task, preventing redundancy. This visual comparison helps to understand the novel compositional incremental learning problem introduced in the paper.", "section": "1 Introduction"}, {"figure_path": "2LRZhbTDtA/figures/figures_2_1.jpg", "caption": "Figure 2: Data Statistics of Split-Clothing and Split-UT-Zappos for tasking composition-IL. Split-Clothing is divided into a 5-task scenario, while Split-UT-Zappos includes both 5-task and 10-task scenarios. In all settings, the number of images per task has been balanced properly.", "description": "This figure shows the data distribution for the three experimental settings used in the paper: Split-Clothing (5 tasks), Split-UT-Zappos (5 tasks), and Split-UT-Zappos (10 tasks). Each setting is represented by a semicircular chart, divided into sections corresponding to the different tasks. The size of each section is proportional to the number of images in that task.  The figure demonstrates that the number of images per task is relatively balanced across all three experimental settings. This ensures a fair comparison between different tasks and experimental setups.", "section": "3 Preliminaries"}, {"figure_path": "2LRZhbTDtA/figures/figures_3_1.jpg", "caption": "Figure 3: t-SNE feature distributions of seven compositions from the Split-Clothing benchmark. For the compositions with the same object but with different states, our CompILer achieves more distinguishable boundaries than the L2P baseline.", "description": "This figure uses t-SNE to visualize the feature distributions of seven compositions from the Split-Clothing dataset learned by both the L2P and CompILer models.  The visualization shows that CompILer is better able to distinguish between compositions that share the same object but differ in state (e.g., different colors of dresses).  This highlights CompILer's improved ability to model fine-grained compositionality compared to L2P.", "section": "3.3 Revealing the Ambiguous Composition Boundary"}, {"figure_path": "2LRZhbTDtA/figures/figures_4_1.jpg", "caption": "Figure 4: Overall architecture of our composition incremental learner (CompILer), which comprises multi-pool prompt learning, object-injected state prompting, and generalized-mean prompt fusion. The multi-pool prompt learning mechanism captures information related to states, objects, and their compositions, each through a dedicated pool. The object-injected state prompting utilizes the object prompt to promote the state representation learning. Moreover, the generalized-mean prompt fusion is used to prioritize the useful prompts and diminish the irrelevant ones.", "description": "This figure illustrates the architecture of the CompILer model, which is designed for Compositional Incremental Learning.  The model consists of three main components: 1) Multi-pool prompt learning that uses separate prompt pools for states, objects, and compositions; 2) Object-injected state prompting, which uses object prompts to guide the selection of state prompts; and 3) Generalized-mean prompt fusion, which combines the selected prompts to reduce irrelevant information. The figure shows how the different components interact, starting with feature extraction from an image and ending with classification based on the fused prompts. ", "section": "4 Methodology"}, {"figure_path": "2LRZhbTDtA/figures/figures_5_1.jpg", "caption": "Figure 5: Architecture of object-injected state prompting. Query feature serves as Q, while fused object prompt serves as both K and V.", "description": "This figure illustrates the object-injected state prompting mechanism.  A query feature vector, q(x), representing the input image, acts as the query (Q) in a cross-attention layer.  The fused object prompt (Po), a composite of learned prompts representing object features, simultaneously serves as both the key (K) and value (V) vectors in this cross-attention operation.  The output of the cross-attention is a refined query feature, qs(x), which is object-informed and used for selecting state prompts. This injection of object information helps to guide the selection of relevant state prompts, improving the state representation learning process.", "section": "4.2 Object-injected State Prompting"}, {"figure_path": "2LRZhbTDtA/figures/figures_9_1.jpg", "caption": "Figure 6: Results and analysis. (a) to (c) show accuracy of CompILer on composition, state, and object for each task in Split-Clothing. The x-axis represents the test stream, and the y-axis denotes the status after training the Tk task. Darker background color indicates higher accuracy. (d) displays some images and their predictions: top row is GT, middle row is CompILer prediction, and bottom row is L2P [43] prediction. Green indicates correct predictions, while red indicates incorrect predictions.", "description": "This figure presents a comprehensive analysis of the CompILer model's performance on the Split-Clothing dataset across different incremental learning tasks.  Subfigures (a), (b), and (c) visualize the accuracy trends for composition, state, and object recognition, respectively, as new tasks are added. Darker colors represent higher accuracy.  Subfigure (d) provides a qualitative comparison of CompILer and the L2P baseline predictions on example images.  Green indicates correctly classified instances, red indicates errors.", "section": "5.6 Additional Results and Analysis"}, {"figure_path": "2LRZhbTDtA/figures/figures_13_1.jpg", "caption": "Figure 2: Data Statistics of Split-Clothing and Split-UT-Zappos for tasking composition-IL. Split-Clothing is divided into a 5-task scenario, while Split-UT-Zappos includes both 5-task and 10-task scenarios. In all settings, the number of images per task has been balanced properly.", "description": "This figure shows the data distribution for the two datasets used in the paper for evaluating compositional incremental learning (composition-IL).  Split-Clothing is divided into 5 incremental tasks, while Split-UT-Zappos is divided into both 5 and 10 incremental tasks. The number of images per task is shown in bar graphs for each dataset and task split scenario.  The key observation is that the number of images per task is balanced across tasks for all scenarios.", "section": "3.2 Dataset Construction"}, {"figure_path": "2LRZhbTDtA/figures/figures_15_1.jpg", "caption": "Figure 8: The t-SNE visualization of learned prompts on Split-Clothing (5 tasks), Split-UT-Zappos(5 tasks), and Split-UT-Zappos (10 tasks). The composition prompts are colored in yellow, the state prompts in green, and the object prompts in blue.", "description": "This figure shows the t-SNE visualization of the learned prompts for three different datasets: Split-Clothing (5 tasks), Split-UT-Zappos (5 tasks), and Split-UT-Zappos (10 tasks).  The visualization helps illustrate the separation of prompts learned for compositions, states, and objects.  Different colors represent different types of prompts: yellow for composition, green for state, and blue for object. The separation demonstrates the effectiveness of the multi-pool prompt learning in distinguishing between these concepts.", "section": "A.3 Empirical Analysis on Learned Prompts"}, {"figure_path": "2LRZhbTDtA/figures/figures_15_2.jpg", "caption": "Figure 9: Impact of hyper-parameters on average accuracy in Split-UT-Zappos (5 tasks).", "description": "This figure shows the effect of hyperparameters (\u03bb\u2081, \u03bb\u2082, and \u03bb\u2083) on the average accuracy of the model in the Split-UT-Zappos dataset with 5 tasks.  Each sub-figure displays the average accuracy achieved for different values of a single hyperparameter, while keeping the others constant. It helps understand the sensitivity of the model's performance to the tuning of these parameters.", "section": "5.5 Ablation Study and Analysis"}, {"figure_path": "2LRZhbTDtA/figures/figures_17_1.jpg", "caption": "Figure 1: Differences between Class Incremental Learning (class-IL), Blurry Incremental Learning (blur-IL), and Compositional Incremental Learning (composition-IL). The object classes are not allowed to recur in the class-IL scenario, whereas they may recur randomly in the blur-IL scenario. Different from them, the classes in composition-IL involve state-object compositions apart from the object classes. Besides, the compositions do not reoccur, but the primitives (states or objects) may randomly reappear across incremental sessions.", "description": "This figure compares three incremental learning paradigms: class-IL, blurry-IL, and compositional-IL.  Class-IL strictly prohibits the recurrence of old classes in new tasks. Blurry-IL allows old classes to reappear randomly. Compositional-IL focuses on learning state-object compositions (e.g., \"brown pants\"). While compositions themselves don't reappear, the individual object and state primitives can.", "section": "1 Introduction"}]