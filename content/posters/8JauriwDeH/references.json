{"references": [{"fullname_first_author": "O. Catoni", "paper_title": "Statistical learning theory and stochastic optimization: Ecole d'Et\u00e9 de Probabilit\u00e9s de Saint-Flour, XXXI-2001", "publication_date": "2004-01-01", "reason": "This paper provides foundational theoretical results on PAC-Bayes bounds, which are crucial for the analysis of the clipped SGD algorithm."}, {"fullname_first_author": "Y. Cherapanamjeri", "paper_title": "Algorithms for heavy-tailed statistics: Regression, covariance estimation, and beyond", "publication_date": "2020-01-01", "reason": "This paper provides state-of-the-art algorithms for heavy-tailed mean estimation, which are used as a comparison point in the paper."}, {"fullname_first_author": "S. Bubeck", "paper_title": "Convex optimization: Algorithms and complexity", "publication_date": "2014-01-01", "reason": "This paper provides a comprehensive overview of convex optimization algorithms, which are fundamental to the paper's approach."}, {"fullname_first_author": "J. Tropp", "paper_title": "Freedman's inequality for matrix martingales", "publication_date": "2011-01-01", "reason": "This paper presents a crucial concentration inequality for matrix martingales that is used in the paper's analysis."}, {"fullname_first_author": "G. Lugosi", "paper_title": "Mean estimation and regression under heavy-tailed distributions: A survey", "publication_date": "2019-01-01", "reason": "This paper provides a comprehensive survey of mean estimation and regression under heavy-tailed distributions, providing context and background for the problem studied in the paper."}]}