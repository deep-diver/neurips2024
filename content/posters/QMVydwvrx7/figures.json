[{"figure_path": "QMVydwvrx7/figures/figures_1_1.jpg", "caption": "Figure 1: Schematic of (a) DL-based pansharpening approach in a supervised fashion, in which the \"network\" can be any deep module, e.g., denoising diffusion probabilistic models (DDPM). The comparison of (b) the LoRA based on DDPM and (c) the proposed APFM in our SSDiff. G and U represent the spectral and spatial domains, respectively. The LoRA can expand learnable weights Wo with AW (but without applications to pansharpening), and the given APFM can obtain pansharpened HrMSI from PAN image and LrMSI through alternating projections.", "description": "This figure illustrates three different approaches to pansharpening using deep learning. (a) shows a general supervised DL-based approach where a network combines PAN and LrMSI to produce HrMSI. (b) demonstrates LoRA (Low-rank Adaptation) applied to a DDPM (Denoising Diffusion Probabilistic Model) for pansharpening, showing how it modifies weights in the network. (c) introduces the paper's proposed APFM (Alternating Projection Fusion Module) within the SSDiff model, highlighting the alternating projection between spatial (U) and spectral (G) domains to achieve the fusion of PAN and LrMSI to generate the HrMSI.", "section": "1 Introduction"}, {"figure_path": "QMVydwvrx7/figures/figures_2_1.jpg", "caption": "Figure 2: Schematic diagram of the relationship between subspace decomposition and self-attention mechanism. f(Q, K) is the classic self-similarity equation in self-attention mechanism.", "description": "This figure illustrates the connection between subspace decomposition and the self-attention mechanism.  Subspace decomposition is represented as matrix multiplication of a subspace matrix (D) and coefficients (C) to reconstruct the original matrix (X).  The self-attention mechanism is shown similarly, with query (Q) and key (K) matrices multiplied by a value (V) matrix, using a self-similarity function f(Q, K) to generate the result matrix X. This shows that the self-attention mechanism can be seen as a specific instance of subspace decomposition via vector projection.", "section": "2 Related Works"}, {"figure_path": "QMVydwvrx7/figures/figures_3_1.jpg", "caption": "Figure 3: Overall framework of the proposed SSDiff.  \u03b5t = \u221a1 \u2013 \u0101t\u03b5t is a Gaussian noise, where t is the time step. Fspa is the output of the spatial branch, and Fspe is the output of the spectral branch. The process of APFM follows Theorem 1.", "description": "This figure illustrates the overall architecture of the SSDiff model.  It shows two branches: a spatial branch and a spectral branch. Each branch processes either PAN or LrMSI images and extracts spatial or spectral features, respectively.  The spatial branch uses ResNet blocks for feature extraction, while the spectral branch employs convolutional layers.  A Frequency Modulation Inter-branch Module (FMIM) interacts between the branches. The features from each branch are then fused using an Alternating Projection Fusion Module (APFM), which uses alternating projections to create pansharpened images. Finally, a Multi-Layer Perceptron (MLP) produces the final output.", "section": "3.1 SSDiff Architecture"}, {"figure_path": "QMVydwvrx7/figures/figures_5_1.jpg", "caption": "Figure 4: The denoising process. The top row consists of a series of iteratively generated images from the gradual denoising process. The subsequent two rows represent the associated low-frequency and high-frequency spatial domain information obtained through inverse Fourier transform from the denoised image in the first row of each corresponding step.", "description": "This figure shows the denoising process of the SSDiff model. The top row displays a series of images generated during the denoising process, showing a gradual increase in clarity and detail.  The middle and bottom rows show the corresponding low and high-frequency components, respectively, extracted from the generated images using an inverse Fourier transform. This visual representation helps to illustrate how SSDiff separates and refines spatial information during image generation, ultimately producing a high-resolution pansharpened image.", "section": "3.3 Frequency Modulation Inter-branch Module"}, {"figure_path": "QMVydwvrx7/figures/figures_6_1.jpg", "caption": "Figure 5: Visual comparisons on a reduced-resolution WorldView-3 and GaoFen-2 case. The first two rows are the results of WV3, and the last two rows are the results of GF2. The first and third rows are the predicted HrMSI for each method, and the second and fourth rows are the error maps of the predicted HRMS versus ground truth (GT) for each one.", "description": "This figure presents a visual comparison of pansharpening results on WorldView-3 and GaoFen-2 datasets at reduced resolution.  The top two rows showcase the pansharpened high-resolution multispectral images (HrMSI) generated by different methods for WorldView-3, while the bottom two rows show the results for GaoFen-2.  The first and third rows display the HrMSI produced by various techniques, including the proposed SSDiff method. The second and fourth rows present error maps, which visually represent the differences between the generated HrMSI and the ground truth (GT).  The green boxes highlight specific regions of interest for detailed comparison. This visual comparison demonstrates the relative performance of different pansharpening methods in terms of accuracy and detail preservation.", "section": "4.1 Experimental Results"}, {"figure_path": "QMVydwvrx7/figures/figures_14_1.jpg", "caption": "Figure 6: The sketch of the proposed LoRA-like branch-wise alternative fine-tuning process.", "description": "This figure illustrates the LoRA-like branch-wise alternative fine-tuning process used in SSDiff.  The top half shows the process of fine-tuning the spectral branch, while the bottom half shows fine-tuning the spatial branch. In both cases, one branch's parameters are frozen (locked) while the other branch's parameters are updated (trainable). This alternating approach allows for more focused and discriminative feature learning in each branch without increasing the overall number of parameters.", "section": "3.4 LoRA-like Branch-wise Alternative Fine-tuning"}, {"figure_path": "QMVydwvrx7/figures/figures_15_1.jpg", "caption": "Figure 5: Visual comparisons on a reduced-resolution WorldView-3 and GaoFen-2 case. The first two rows are the results of WV3, and the last two rows are the results of GF2. The first and third rows are the predicted HrMSI for each method, and the second and fourth rows are the error maps of the predicted HRMS versus ground truth (GT) for each one.", "description": "This figure showcases visual comparisons of pansharpening results on reduced-resolution WorldView-3 and GaoFen-2 datasets.  It presents the high-resolution multispectral images (HrMSI) generated by various methods (SSDiff, PanDiff, DCFNet, MMNet, LAGConv, CTINN, PNN, FusionNet, MSDCNN, DICNN, BT-H, MTF-GLP-FS, BDSD-PC) along with error maps comparing these results against the ground truth (GT). The error maps illustrate the differences between the predicted HrMSI and the actual GT, providing a visual assessment of the accuracy of each method.", "section": "4.1 Experimental Results"}, {"figure_path": "QMVydwvrx7/figures/figures_16_1.jpg", "caption": "Figure 5: Visual comparisons on a reduced-resolution WorldView-3 and GaoFen-2 case. The first two rows are the results of WV3, and the last two rows are the results of GF2. The first and third rows are the predicted HrMSI for each method, and the second and fourth rows are the error maps of the predicted HRMS versus ground truth (GT) for each one.", "description": "This figure shows a visual comparison of pansharpening results on reduced-resolution WorldView-3 and GaoFen-2 datasets.  It presents the pansharpened high-resolution multispectral images (HrMSI) produced by various methods (SSDiff, PanDiff, DCFNet, MMNet, LAGConv, CTINN, PNN, FusionNet, MSDCNN, DiCNN, BT-H, and MTF-GLP-FS) alongside error maps that quantify the difference between the generated HrMSI and the ground truth (GT). The visual comparison aids in assessing the accuracy and quality of each method's pansharpening performance.", "section": "4.1 Experimental Results"}]