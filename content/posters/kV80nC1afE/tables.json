[{"figure_path": "kV80nC1afE/tables/tables_4_1.jpg", "caption": "Table 1: Average CPU time (in seconds) for different side information functions over 100 randomized trials of Algorithm 2.", "description": "This table shows the average CPU time in seconds taken by Algorithm 2 for different side information functions across 100 randomized trials.  The different functions compared are log return, switching cost, weighted l1 norm, and group lasso. The table shows results for different problem dimensions (N = 500, 1000, 2000, 5000). The results demonstrate the computational efficiency of Algorithm 2, which leverages the successive convex approximation technique to accelerate computation.", "section": "3.3 Efficient Algorithm"}, {"figure_path": "kV80nC1afE/tables/tables_5_1.jpg", "caption": "Table 1: Average CPU time (in seconds) for different side information functions over 100 randomized trials of Algorithm 2.", "description": "This table presents the average CPU time in seconds taken by Algorithm 2 for different side information functions over 100 randomized trials.  The functions compared include 'log return', 'switching cost', 'weighted l1 norm', and 'group Lasso'.  The results are shown for different problem dimensions (N = 500, 1000, 2000, 5000), demonstrating the effect of problem size on computation time for each function.  The values are reported as mean \u00b1 standard deviation.", "section": "3.3 Efficient Algorithm"}, {"figure_path": "kV80nC1afE/tables/tables_9_1.jpg", "caption": "Table 1: Average CPU time (in seconds) for different side information functions over 100 randomized trials of Algorithm 2.", "description": "This table shows the average CPU time in seconds for Algorithm 2, which is an efficient algorithm for solving the weight selection problem in the APAS framework.  The algorithm's efficiency is evaluated using four different types of side information functions: log return, switching cost, weighted l1 norm, and group lasso.  The experiment is run 100 times for four different problem dimensions (N = 500, 1000, 2000, and 5000), and the average CPU time and standard deviation are reported for each condition. This table demonstrates that the computational efficiency of the APAS algorithm is only slightly affected by the choice of side information function.  Although group lasso shows increased computation time with increasing dimensionality N,  the overall efficiency of the proposed method is demonstrated.", "section": "3.3 Efficient Algorithm"}, {"figure_path": "kV80nC1afE/tables/tables_18_1.jpg", "caption": "Table 2: Tracking error of APAS under different combinations of noise and data distributions.", "description": "This table presents the tracking error results obtained from the Adaptive Passive-Aggressive online regression framework with Side information (APAS) model under various noise and data distribution conditions.  The experiment compared four scenarios: both noise and data following a normal distribution, noise following a normal distribution and data following a Student's t-distribution, noise following a Student's t-distribution and data following a normal distribution, and both noise and data following a Student's t-distribution. The results are shown for different values of lambda (\u03bb), a trade-off parameter in the APAS model.", "section": "4.2 Real Market Data Experiments"}, {"figure_path": "kV80nC1afE/tables/tables_18_2.jpg", "caption": "Table 2: Tracking error of APAS under different combinations of noise and data distributions.", "description": "This table presents the tracking error results obtained from the APAS model under various combinations of noise and data distributions.  Specifically, it shows how the tracking error changes when either the noise or the data (or both) are drawn from a heavy-tailed Student's t-distribution, as compared to using only Gaussian distributions.  Different values of the trade-off parameter (\u03bb) are also included, showing its impact on the tracking error under different distribution scenarios.", "section": "4.1 Synthetic Data Experiments"}]