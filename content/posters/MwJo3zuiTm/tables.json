[{"figure_path": "MwJo3zuiTm/tables/tables_6_1.jpg", "caption": "Table 1: Accuracy comparisons (MTA) under different \u03b1 on CIFAR10.", "description": "This table presents the mean test accuracy (MTA) achieved by different federated learning algorithms on the CIFAR-10 dataset under varying levels of competition (\u03b1).  It compares the performance of FedEgoists against nine baseline methods across different data heterogeneity settings (pathological and Dirichlet distributions).  The results are presented as mean \u00b1 standard deviation, allowing for the assessment of algorithm performance under different competitive scenarios.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_6_2.jpg", "caption": "Table 1: Accuracy comparisons (MTA) under different \u03b1 on CIFAR10.", "description": "This table presents the mean test accuracy (MTA) achieved by FedEgoists and nine other baseline methods on the CIFAR-10 dataset under various levels of competition (\u03b1).  Different data heterogeneity methods (pathological and Dirichlet distributions) are used. The results show the average performance across five independent trials.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_8_1.jpg", "caption": "Table 1: Accuracy comparisons (MTA) under different \u03b1 on CIFAR10.", "description": "This table presents the mean test accuracy (MTA) achieved by different federated learning algorithms on the CIFAR-10 dataset under varying levels of competition (\u03b1).  Two different data heterogeneity settings are used: Pathological (PAT) and Dirichlet (Dir).  The algorithms compared include FedAvg, FedProx, SCAFFOLD, pFedMe, pFedHN, FedDisco, pFedGraph, FedOra, and the proposed FedEgoists algorithm. The results show the performance of each algorithm under different levels of competition and data heterogeneity.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_8_2.jpg", "caption": "Table 1: Accuracy comparisons (MTA) under different \u03b1 on CIFAR10.", "description": "This table presents the mean test accuracy (MTA) achieved by different federated learning (FL) approaches on the CIFAR-10 dataset under varying levels of competition (\u03b1).  The results are shown for two different data heterogeneity methods: Pathological (PAT) and Dirichlet (Dir).  Each row represents a different \u03b1 value, and each column shows the performance of a different FL algorithm, including FedEgoists, the proposed method. The table allows for a comparison of FedEgoists against state-of-the-art baselines in terms of accuracy across different competitive scenarios.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_9_1.jpg", "caption": "Table 3: The worst-case performance of the proposed approach compared with the baseline approaches.", "description": "This table presents the worst-case performance comparison between the proposed FedEgoists algorithm and nine baseline methods across different competition intensities (\u03b1) and data heterogeneity settings (Pathological and Dirichlet distributions) on CIFAR-10 and CIFAR-100 datasets. For each setting, five trials were conducted, and the worst-case performance for the baseline methods (the best performance across the five trials) is compared to the performance of FedEgoists. The values show the performance difference between the best-performing baseline method and FedEgoists in the worst-case scenario.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_9_2.jpg", "caption": "Table 1: Accuracy comparisons (MTA) under different \u03b1 on CIFAR10.", "description": "This table presents the mean test accuracy (MTA) achieved by different federated learning algorithms on the CIFAR-10 dataset under varying levels of competition (\u03b1).  It compares the performance of FedEgoists against nine other state-of-the-art methods, showing accuracy results across two data heterogeneity scenarios (pathological and Dirichlet distributions) and four different competition levels (\u03b1 = 0.05, 0.1, 0.2, 0.3, 0.4). The results highlight FedEgoists' effectiveness in achieving higher accuracy compared to baseline approaches across various settings.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_21_1.jpg", "caption": "Table 5: Accuracy comparisons under different \u03b2 of Dirichlet distribution", "description": "This table presents the mean test accuracy (MTA) achieved by various federated learning algorithms across different data heterogeneity levels (\u03b2 values) using the Dirichlet distribution. The algorithms compared include Local, FedAvg, FedProx, SCAFFOLD, pFedMe, pFedHN, FedDisco, pFedGraph, FedOra, and FedEgoists.  Different \u03b2 values represent varying degrees of data heterogeneity, with smaller \u03b2 values indicating higher heterogeneity. The results show the average accuracy and standard deviation across multiple trials for each algorithm and heterogeneity level. This allows for a comparison of algorithm performance under different conditions and data distributions.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_23_1.jpg", "caption": "Table 6: Experimental results (MSE) with synthetic data under fixed competing graphs: The weakly non-IID setting", "description": "This table presents the Mean Squared Error (MSE) results for different federated learning algorithms on synthetic data with a weakly non-IID setting and fixed competing graphs.  The weakly non-IID setting introduces a skew in the amount of data available to each participating FL-PT (some have 2000 samples, others have only 100), and the competing graph defines competition relationships between FL-PTs. The table shows the MSE for each algorithm across eight FL-PTs (v1 to v8). Lower MSE values indicate better performance.", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}, {"figure_path": "MwJo3zuiTm/tables/tables_23_2.jpg", "caption": "Table 6: Experimental results (MSE) with synthetic data under fixed competing graphs: The weakly non-IID setting", "description": "This table presents the Mean Squared Error (MSE) results of different federated learning algorithms on synthetic data with a weakly non-IID setting and fixed competing graphs.  The results are shown for various algorithms including LOCAL, FEDAVE, FEDPROX, SCAFFOLD, PFEDME, PFEDHN, PFEDGRAPH and FEDEGOISTS.  The 'weakly non-IID' designation indicates that there's a significant difference in the sample quantities across different federated learning participants (FL-PTs), creating a data imbalance. Each algorithm's performance is evaluated across eight different FL-PTs (v1 through v8).", "section": "5.2 Benchmark Experiments: CIFAR-10 & CIFAR-100"}]