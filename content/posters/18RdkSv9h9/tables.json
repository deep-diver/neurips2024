[{"figure_path": "18RdkSv9h9/tables/tables_4_1.jpg", "caption": "Table 1: Comparison of different features using Clustering rule, SNR rule, and MOS on neural vocoding.", "description": "This table presents the results of evaluating different feature extractors for use in perceptual loss for speech enhancement.  Three criteria were used: Clustering Rule (how well features of the same sound cluster together), SNR Rule (how well features separate by SNR level), and MOS (Mean Opinion Score from a neural vocoding task, measuring the perceptual quality of the generated audio). The results show WavLM-conv features perform best across all criteria.", "section": "3 Perceptual Loss for Speech Generation"}, {"figure_path": "18RdkSv9h9/tables/tables_8_1.jpg", "caption": "Table 2: Comparison with prior work on Voxceleb and UNIVERSE validation data.", "description": "This table compares the performance of the proposed FINALLY model against several baselines on two datasets: VoxCeleb and UNIVERSE.  The VoxCeleb dataset contains real-world data, while the UNIVERSE dataset contains artificially generated data with various types of simulated distortions. The table shows the Mean Opinion Score (MOS), UT MOS, WV-MOS, DNSMOS, Phoneme Error Rate (PhER), and Real-Time Factor (RTF) for each model and dataset.  The results highlight that FINALLY achieves state-of-the-art performance in terms of both perceptual quality and computational efficiency.", "section": "6 Results"}, {"figure_path": "18RdkSv9h9/tables/tables_8_2.jpg", "caption": "Table 3: Comparison with the baselines on VCTK-DEMAND.", "description": "This table compares the performance of the proposed model, FINALLY, against several baseline models on the VCTK-DEMAND dataset.  The metrics used include MOS (Mean Opinion Score), UTMOS (Utokyo-based MOS), WV-MOS (weighted MOS), DNSMOS (DNN-based MOS), PESQ (Perceptual Evaluation of Speech Quality), STOI (Short-Time Objective Intelligibility), SI-SDR (Scale-Invariant Signal-to-Distortion Ratio), and WER (Word Error Rate). The table shows that FINALLY outperforms the baselines on most of the metrics, indicating its superior performance in speech enhancement.", "section": "6 Results"}, {"figure_path": "18RdkSv9h9/tables/tables_9_1.jpg", "caption": "Table 4: Ablation study (VoxCeleb real data).", "description": "This table presents the results of an ablation study conducted on the VoxCeleb real dataset to evaluate the effectiveness of different design choices made in the proposed speech enhancement model.  The study compares the performance of the LMOS loss against two other regression losses (Mel-Spectrogram loss and Reconstruction loss), and then assesses the impact of adding WavLM encoder features, scaling the architecture, adding a third training stage, and incorporating a human feedback loss.  The MOS, UTMOS, WV-MOS, and DNSMOS scores are reported for each configuration.", "section": "6 Results"}, {"figure_path": "18RdkSv9h9/tables/tables_9_2.jpg", "caption": "Table 5: Ablation of WavLM encoder on UNIVERSE validation data.", "description": "This table presents the ablation study results focusing on the impact of using WavLM encoder in the FINALLY model. It compares the model's performance with and without the WavLM encoder, evaluating metrics such as MOS, UTMOS, WV-MOS, DNSMOS, and PhER on the UNIVERSE validation dataset. The results demonstrate the significant contribution of WavLM encoder to achieving better speech enhancement quality.", "section": "6 Results"}, {"figure_path": "18RdkSv9h9/tables/tables_18_1.jpg", "caption": "Table 6: MOS on neural vocoding for different loss functions.", "description": "This table compares the Mean Opinion Score (MOS) achieved by different perceptual loss functions used in neural vocoding.  The MOS score is a measure of perceived audio quality. The comparison includes  PFPL, SSSR loss with HuBERT features, MS-STFT + L1 waveform, LMOS (the proposed method), and adv. MPD-MSD. Ground truth MOS is also provided for reference.", "section": "B Additional results for perceptual losses"}, {"figure_path": "18RdkSv9h9/tables/tables_19_1.jpg", "caption": "Table 7: MOS Scores for comparison with Miipher (LibriTTS, test_other).", "description": "This table compares the objective and subjective speech quality scores of the proposed FINALLY model against the Miipher model on the LibriTTS test_other dataset.  The metrics used include MOS (Mean Opinion Score), UTMOS, DNSMOS, WV-MOS, and WER (Word Error Rate).  The comparison helps to evaluate the relative performance of the two models in terms of perceived audio quality and linguistic accuracy.", "section": "6 Results"}, {"figure_path": "18RdkSv9h9/tables/tables_20_1.jpg", "caption": "Table 1: Comparison of different features using Clustering rule, SNR rule, and MOS on neural vocoding.", "description": "This table presents a comparison of different feature extractors used for perceptual loss in speech generation. It evaluates the features based on two criteria: Clustering rule (whether representations of the same sound form a cluster) and SNR rule (whether representations of speech sounds contaminated by noise move away from clean sounds with increasing noise level).  The table also includes the Mean Opinion Score (MOS) obtained for neural vocoding using each feature extractor, which indicates the quality of the generated speech. The results show that features extracted by the convolutional encoder of the WavLM model present the best performance.", "section": "3 Perceptual Loss for Speech Generation"}, {"figure_path": "18RdkSv9h9/tables/tables_21_1.jpg", "caption": "Table 1: Comparison of different features using Clustering rule, SNR rule, and MOS on neural vocoding.", "description": "This table compares various feature extractors used as backbones for perceptual loss in a neural vocoding task.  It evaluates the feature spaces based on two criteria: the Clustering rule (whether representations of identical speech sounds form separable clusters) and the SNR rule (whether representations of speech sounds contaminated by different noise levels move away from the clean sound cluster monotonically with increasing noise).  The Mean Opinion Score (MOS) for neural vocoding using each feature type is also reported to assess the suitability of the feature space for perceptual loss in speech generation.", "section": "3 Perceptual Loss for Speech Generation"}, {"figure_path": "18RdkSv9h9/tables/tables_22_1.jpg", "caption": "Table 10: Comparison of resources and data used for training.", "description": "This table compares the training data scale and model sizes of the proposed model, FINALLY, against various baseline models. It highlights that while FINALLY has more parameters than many baselines, the majority are used for handling low-resolution features, resulting in a significantly lower Real-Time Factor (RTF) on a V100 GPU.", "section": "6 Results"}, {"figure_path": "18RdkSv9h9/tables/tables_23_1.jpg", "caption": "Table 4: Ablation study (VoxCeleb real data).", "description": "This table presents the results of an ablation study conducted on the VoxCeleb real data to evaluate the effectiveness of different design choices made in the paper. The study compares the LMOS loss against two other regression losses (Mel-Spectrogram loss and Reconstruction loss) in the context of training a smaller speech enhancement model.  It also investigates the impact of adding WavLM encoder features, scaling the architecture, adding a third training stage, and incorporating a human feedback loss.  The results show the MOS, UTMOS, WV-MOS, and DNSMOS scores for each configuration.", "section": "6.3 Ablation study"}, {"figure_path": "18RdkSv9h9/tables/tables_23_2.jpg", "caption": "Table 12: Comparison with HiFi++ on VoxCeleb data.", "description": "This table compares the performance of the proposed FINALLY model against the HiFi++ baseline on the VoxCeleb dataset.  It shows the improvements achieved in terms of three objective metrics: UTMOS, WV-MOS, and DNSMOS, which assess different aspects of speech quality.  Higher scores indicate better quality, demonstrating the effectiveness of the proposed model in enhancing speech quality.", "section": "6.3 Ablation study"}]