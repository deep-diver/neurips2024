[{"figure_path": "0HRRNEAQFp/figures/figures_1_1.jpg", "caption": "Figure 1: Motivation: What do large vision models know about the 3D scene? We take Stable Diffusion as an example because Stable Diffusion is generative, so its output is an image that can be judged directly for verisimilitude. The Stable Diffusion inpainting model is here tasked with inpainting the masked region of the real images. It correctly predicts a shadow consistent with the lighting direction (top), and a supporting structure consistent with the scene geometry (bottom). This indicates that the Stable Diffusion model generation is consistent with the geometry (of the light source direction) and physical (support) properties. These examples are only for illustration and we probe a general Stable Diffusion network to determine whether there are explicit features for such 3D scene properties. The appendix provides more examples of Stable Diffusion's capability to predict different physical properties of the scene.", "description": "This figure demonstrates the ability of Stable Diffusion to understand 3D scenes by inpainting masked regions in real images. The model correctly predicts shadows and supporting structures, suggesting an implicit understanding of 3D physics.", "section": "1 Introduction"}, {"figure_path": "0HRRNEAQFp/figures/figures_4_1.jpg", "caption": "Figure 2: Example images for probing scene geometry. The first row shows a sample annotation for the same plane, and the second row is a sample annotation for perpendicular plane. Here, and in the following figures, (A, B) are a positive pair, while (A, C) are negative. The images are from the ScanNetv2 dataset [8] with annotations for planes from [24]. In the first row, the first piece of floor (A) is on the same plane as the second piece of floor (B), but is not on the same plane as the surface of the drawers (C). In the second row, the table top (A) is perpendicular to the wall (B), but is not perpendicular to the stool top (C).", "description": "This figure shows example images used to test the model's ability to understand scene geometry, specifically whether two regions are on the same plane or perpendicular planes.  Each row presents an original image with annotated regions (A, B, C). Region pairs (A, B) represent positive examples of the geometric relationship (same plane or perpendicular), while (A, C) show negative examples.", "section": "3.2 Datasets"}, {"figure_path": "0HRRNEAQFp/figures/figures_5_1.jpg", "caption": "Figure 3: Example images for probing material, support relation and shadow. The first row is for material, the second row for support relation, and the third row for shadow. First row: the material images are from the DMS dataset [39]. The paintings are both covered with glass (A and B) whereas the curtain (C) is made of fabric. Second row: the support relation images are from the NYUv2 dataset [36]. The paper (A) is supported by the table (B), but it is not supported by the chair (C). Third row: the shadow images are from the SOBA dataset [41]. The person (A) has the shadow (B), not the shadow (C).", "description": "This figure shows example images used for evaluating three different properties: material, support relation, and shadow. Each row represents a different property with a positive and negative example pair. The image datasets used are DMS for material, NYUv2 for support relation and SOBA for shadow.", "section": "3.2 Datasets"}, {"figure_path": "0HRRNEAQFp/figures/figures_6_1.jpg", "caption": "Figure 2: Example images for probing scene geometry. The first row shows a sample annotation for the same plane, and the second row is a sample annotation for perpendicular plane. Here, and in the following figures, (A, B) are a positive pair, while (A, C) are negative. The images are from the ScanNetv2 dataset [8] with annotations for planes from [24]. In the first row, the first piece of floor (A) is on the same plane as the second piece of floor (B), but is not on the same plane as the surface of the drawers (C). In the second row, the table top (A) is perpendicular to the wall (B), but is not perpendicular to the stool top (C).", "description": "This figure shows example images used to test the model's ability to understand scene geometry, specifically whether two regions are on the same plane or perpendicular planes. Each row shows an example of a positive pair (A,B) and a negative pair (A,C), where the positive pair shares the property of interest (same plane or perpendicular plane) and the negative pair does not.", "section": "3.2 Datasets"}, {"figure_path": "0HRRNEAQFp/figures/figures_7_1.jpg", "caption": "Figure 5: (a) Nomenclature for the U-Net Layers. We probe 4 downsampling encoder layers E1-E4 and 4 upsampling decoder layers D1-D4 of the Stable Diffusion U-Net. (b) A prediction failure for Material. In this example the model does not predict that the two regions are made of the same material (fabric). (c) A prediction failure for Occlusion. In this example the model does not predict that the two regions belong to the same object (the sofa).", "description": "This figure shows the architecture of the U-Net used in Stable Diffusion and illustrates two prediction failures.  (a) labels the encoder (E1-E4) and decoder (D1-D4) layers of the U-Net. (b) shows an example where the model incorrectly predicts the material of two regions. (c) shows an example where the model fails to identify that two regions belong to the same occluded object.", "section": "4.2 Results for Stable Diffusion"}, {"figure_path": "0HRRNEAQFp/figures/figures_16_1.jpg", "caption": "Figure 6: Stable Diffusion generated images testing scene geometry prediction. Here and for the following figures, the model is tasked with inpainting the masked region of the real images. Stable Diffusion 'knows' about same plane and perpendicular plane relations in the generation. When the intersection of two sofa planes (first row), two walls (second and sixth row), two cabinet planes (third row), two pillar planes (fourth row) or two fridge planes (fifth row) is masked out, Stable Diffusion is able to generate the two perpendicular planes at the corner based on the unmasked parts of the planes.", "description": "This figure showcases Stable Diffusion's ability to predict scene geometry, specifically focusing on same-plane and perpendicular-plane relationships.  The model successfully inpaints masked regions in real images, demonstrating an understanding of how planes intersect to form corners, even when only part of the planes are visible.", "section": "B More Stable Diffusion Generated Images"}, {"figure_path": "0HRRNEAQFp/figures/figures_17_1.jpg", "caption": "Figure 7: Stable Diffusion generated images testing material, support relation and shadow prediction. Stable Diffusion \u2018knows\u2019 about support relations and shadows in the generation, but may fail sometimes for material. Rows 1\u20132: Material; Rows 3\u20134: Support Relation; Rows 5\u20136: Shadow. In the first row, the model distinguishes the two different materials clearly and there is clear boundary between the generated pancake and plate; while in the second row, the model fails to distinguish the two different materials clearly, generating a mixed boundary. In the third row and fourth rows, the model does inpaint the supporting object for the stuff on the table and the machine. In the fifth and sixth rows, the model manages to inpaint the shadow correctly. Better to zoom in for more details.", "description": "This figure shows examples of Stable Diffusion inpainting images for material, support relation, and shadow. The model performs well on support relation and shadow prediction, but struggles with material prediction when the boundary between materials is unclear.", "section": "B More Stable Diffusion Generated Images"}, {"figure_path": "0HRRNEAQFp/figures/figures_18_1.jpg", "caption": "Figure 8: Stable Diffusion generated images testing occlusion and depth prediction. Stable Diffusion \u2018knows\u2019 about depth in the generation, but may fail sometimes for occlusion. Rows 1\u20133: Occlusion; Rows 4\u20136: Depth. In Row 1, the model fails to connect the tail with the cat body and generates a new tail for the cat, while in Row 2, the model successfully connects the separated people and generates their whole body, and in Row 3, the separated parts of oven are connected to generate the entire oven. In Rows 4\u20136, the model correctly generates a car of the proper size based on depth. The generated car is larger if it is closer, and smaller if it is farther away.", "description": "This figure shows examples of Stable Diffusion's image inpainting results, demonstrating its ability to predict depth accurately but sometimes failing to correctly handle occlusions. The figure includes six examples, with the first three focusing on occlusions and the latter three on depth perception.", "section": "4.2 Results for Stable Diffusion"}, {"figure_path": "0HRRNEAQFp/figures/figures_20_1.jpg", "caption": "Figure 9: Curves for AUC at different layers and time steps of probing Stable Diffusion for the same plane task.", "description": "This figure shows the Area Under the Curve (AUC) values for different layers (D1-D4, E1-E4) and timesteps of the Stable Diffusion model when performing the \"same plane\" task.  The x-axis represents the timestep, and the y-axis represents the AUC score. Each line corresponds to a different layer within the Stable Diffusion model.  The plot illustrates how the performance (AUC) of the model changes for the same-plane prediction task across different layers and different timesteps of the diffusion process.", "section": "D AUC Curves for Stable Diffusion Features Grid Search"}, {"figure_path": "0HRRNEAQFp/figures/figures_21_1.jpg", "caption": "Figure 10: Curves for AUC at different layers and time steps of probing Stable Diffusion for the perpendicular plane task.", "description": "This figure shows the Area Under the Curve (AUC) values obtained for the \"perpendicular plane\" task using Stable Diffusion.  Different curves represent different layers (D1-D4, E1-E4) of the U-Net within the Stable Diffusion model.  The x-axis represents the different time steps used during the diffusion process, illustrating how the AUC varies across layers and time steps.  The overall trend helps to determine the optimal layers and time steps for maximizing performance on this specific task of identifying perpendicular planes.", "section": "4.2 Results for Stable Diffusion"}, {"figure_path": "0HRRNEAQFp/figures/figures_21_2.jpg", "caption": "Figure 11: Curves for AUC at different layers and time steps of probing Stable Diffusion for the material task.", "description": "This figure shows the Area Under the Curve (AUC) values for different layers (D1-D4, E1-E4) and timesteps of the Stable Diffusion model when applied to the material property prediction task.  Each line represents a specific layer, and the x-axis represents different timesteps in the diffusion process. The y-axis shows the AUC, measuring the model's performance in distinguishing between different materials. The graph helps analyze which layers and timesteps of the Stable Diffusion model are most effective for material property prediction.", "section": "4.2 Results for Stable Diffusion"}, {"figure_path": "0HRRNEAQFp/figures/figures_22_1.jpg", "caption": "Figure 9: Curves for AUC at different layers and time steps of probing Stable Diffusion for the same plane task.", "description": "This figure shows the Area Under the Curve (AUC) for different layers (D1-D4, E1-E4) and timesteps of the Stable Diffusion model when performing the \"same plane\" task.  The x-axis represents the timestep, ranging from 0 to 500, and the y-axis represents the AUC score, indicating the model's performance at classifying whether two regions are on the same plane. Each line corresponds to a different layer of the model, showing how the model's performance varies across different layers and timesteps.", "section": "4.2 Results for Stable Diffusion"}, {"figure_path": "0HRRNEAQFp/figures/figures_22_2.jpg", "caption": "Figure 13: Curves for AUC at different layers and time steps of probing Stable Diffusion for the shadow task.", "description": "This figure shows the Area Under the Curve (AUC) values obtained for different layers and timesteps when probing the Stable Diffusion model's ability to predict shadows. The x-axis represents the timestep, and the y-axis represents the AUC score. Different lines represent different layers in the model (D1-D4, E1-E4). The graph helps to understand which layer and timestep combination performs best for shadow prediction in the Stable Diffusion model.", "section": "D AUC Curves for Stable Diffusion Features Grid Search"}, {"figure_path": "0HRRNEAQFp/figures/figures_23_1.jpg", "caption": "Figure 9: Curves for AUC at different layers and time steps of probing Stable Diffusion for the same plane task.", "description": "This figure shows the Area Under the Curve (AUC) values obtained when probing different layers and timesteps of the Stable Diffusion model for the \"same plane\" task.  The x-axis represents the timestep in the diffusion process, and the y-axis shows the AUC score which indicates how well the model can distinguish between pairs of regions that are on the same plane versus those that are not. Each line represents a different layer within the U-Net architecture of Stable Diffusion (D1-D4 representing decoder layers and E1-E4 representing encoder layers). The curves illustrate the performance of different layers at different timesteps, allowing researchers to identify which layer and timestep combination is most effective for this specific task in 3D scene understanding.", "section": "4.2 Results for Stable Diffusion"}, {"figure_path": "0HRRNEAQFp/figures/figures_23_2.jpg", "caption": "Figure 15: Curves for AUC at different layers and time steps of probing Stable Diffusion for the depth task.", "description": "This figure shows the Area Under the Curve (AUC) values obtained from using features extracted from different layers (D1-D4, E1-E4) and timesteps (0-500) of the Stable Diffusion model for a depth prediction task. The plot helps to visualize how the performance of the model varies across different layers and timesteps. It indicates the optimal layers and timesteps to extract features for the depth prediction task.", "section": "4.2 Results for Stable Diffusion"}]