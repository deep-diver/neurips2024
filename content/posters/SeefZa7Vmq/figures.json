[{"figure_path": "SeefZa7Vmq/figures/figures_2_1.jpg", "caption": "Figure 2: (a) Training on the transformed ModelNet10 dataset (employing sample-wise, dataset-wise, and class-wise patterns) using PointNet classifier; (b) The high-level overview of the class-wise setting", "description": "Figure 2(a) shows the result of training a PointNet classifier on the ModelNet10 dataset after applying three different transformation patterns: sample-wise, dataset-wise, and class-wise. The class-wise pattern shows significantly lower test accuracy, satisfying the condition for an unlearnable scheme. Figure 2(b) illustrates the high-level concept of the class-wise setting, where a new mapping is established between class-wise transformations and their corresponding ground truth labels. This mapping makes it difficult for unauthorized users to learn the true relationship between the input data and labels.", "section": "3 Our Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/figures/figures_4_1.jpg", "caption": "Figure 3: An overview of our proposed integral unlearnable pipeline", "description": "This figure illustrates the complete pipeline of the proposed unlearnable framework.  It starts with the raw 3D point cloud data and shows the steps involved in protecting the data from unauthorized use (the unlearnable transformation process) and then restoring the data for authorized training (the data restoration scheme). The figure highlights the use of class-wise transformations, the category-adaptive allocation strategy, matrix multiplication, and inverse transformations. It also shows the roles of the data protector and the authorized user in the process, along with a visual representation of the transformation effect and its impact on the accuracy results for authorized and unauthorized users.", "section": "3 Our Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/figures/figures_6_1.jpg", "caption": "Figure 4: The test accuracy (%) results obtained after training on the clean, UMT, and restoration datasets", "description": "This figure shows the test accuracy results for four different point cloud models (PointNet, PointNet++, DGCNN, and PointCNN) trained on three different datasets: clean dataset, UMT dataset (unlearnable data created by applying class-wise multi-transformations), and restoration dataset (UMT data restored using the proposed data restoration scheme).  The results demonstrate that the UMT dataset leads to significantly lower test accuracy compared to the clean dataset, indicating that the proposed unlearnable mechanism is effective.  Moreover, the restoration dataset is able to restore the accuracy to a level comparable to that of the clean dataset, confirming the effectiveness of the data restoration scheme.", "section": "Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/figures/figures_7_1.jpg", "caption": "Figure 5: Hyper-parameter sensitivity analysis: The impact of hyperparameters rs, rp, b\u2081, and b\u1d64 on the test accuracy results (%) on the UMT (using RS) ModelNet10 dataset", "description": "This figure shows the impact of four hyperparameters (rs, rp, b\u2081, and b\u1d64) on the test accuracy of the UMT model using the RS transformation on the ModelNet10 dataset.  Each subfigure shows the accuracy for different values of one hyperparameter while keeping the others constant. The results indicate the sensitivity of the UMT model's performance to these hyperparameters, helping to guide the selection of optimal values for these parameters in the model.", "section": "4.3 Ablation Study and Hyper-Parameter Sensitivity Analysis"}, {"figure_path": "SeefZa7Vmq/figures/figures_8_1.jpg", "caption": "Figure 6: UMT in weight space. The blue arrow represents the clean training trajectory of the weights \u03b8i at step i, while the red arrows denote the UMT training trajectory. The values for plotting this figure are provided in Appendix C.6. (a) Testing on clean test set (blue and red ellipses); (b) Testing on UMT test set (green ellipse)", "description": "This figure shows the training trajectory of model weights in the weight space when using clean data and UMT data.  The blue arrows represent the trajectory with clean data, showing a smooth path to low loss on the clean test set (Figure 6a). The red arrows represent the trajectory with UMT data, showing a different path that leads to low training loss but high loss on the clean test set (Figure 6a). When testing on the UMT test set (Figure 6b), both trajectories converge to low loss, which is expected given the consistent application of UMT to both training and test data.", "section": "4.4 Insightful Analysis Into UMT"}, {"figure_path": "SeefZa7Vmq/figures/figures_20_1.jpg", "caption": "Figure 3: An overview of our proposed integral unlearnable pipeline", "description": "This figure illustrates the complete process of the proposed unlearnable framework for 3D point clouds. It starts with raw 3D point cloud data without any protection, and then applies a category-adaptive allocation strategy to assign class-wise transformation parameters for different categories of data. The data protector then performs class-wise multi-transformations to the data, creating unlearnable transformed point cloud data. The authorized user receives a lightweight message containing class-wise parameters from the data protector, uses these parameters to construct the inverse transformation matrix, and applies it to the unlearnable data for restoration. This process ensures only authorized users can access and use the data for training.", "section": "3 Our Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/figures/figures_21_1.jpg", "caption": "Figure 3: An overview of our proposed integral unlearnable pipeline", "description": "This figure illustrates the proposed integral unlearnable framework for 3D point clouds. It shows two main processes: (1) unlearnable data protection and (2) authorized data restoration.  The unlearnable data protection involves a class-wise setting using category-adaptive allocation strategy. The data is transformed using class-wise multi-transformations, which makes it difficult for unauthorized users to train a model effectively. The authorized data restoration uses a lightweight message from the data protector to perform a class-wise inverse transformation, making the data learnable again for authorized users. The figure highlights the key components involved in each process, illustrating the flow of data from clean data to unlearnable data and then back to learnable data for authorized training. ", "section": "3 Our Proposed Unlearnable Schemes"}]