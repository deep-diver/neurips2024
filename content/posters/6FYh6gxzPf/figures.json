[{"figure_path": "6FYh6gxzPf/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of the active grasp detection system. The RGB, depth and predicted graspness from a new view are mapped to the Neural Graspness Field (NGF) by rendering loss. After each mapping step, the scene geometry is exported from the neural representation using the marching-cubes algorithm [19] and the candidate positions for grasp synthesis are sampled by neural graspness sampling. If the maximum perception step is reached or a specific result condition is satisfied, e.g., a sufficient number of high-quality grasps are detected, the robot arm is employed to execute the detected grasps. Otherwise, the Next-Best-View (NBV) planner is employed to sample candidate views and select the view with the largest information gain for robot movement.", "description": "This figure illustrates the overall workflow of the active grasp detection system.  It starts with input RGB and depth data, which are processed through the Neural Graspness Field (NGF) to incrementally build a 3D representation of grasp possibilities.  A Next-Best-View (NBV) planner then determines the optimal camera position to reduce uncertainty and improve grasp detection.  The system iteratively refines the NGF, samples grasps using neural graspness sampling, and eventually executes a grasp if sufficient high-quality grasps are found or the maximum number of iterations is reached.", "section": "3 Method"}, {"figure_path": "6FYh6gxzPf/figures/figures_3_1.jpg", "caption": "Figure 2: The pipeline of the proposed mapping and NBV planning methods.", "description": "This figure shows the pipeline of the proposed neural graspness field mapping and next-best-view (NBV) planning methods.  (a) Neural Graspness Field Mapping illustrates how the RGB image, depth image and graspness prediction from a graspness network are combined using SDF-based volume rendering to create a Neural Graspness Field (NGF). (b) Graspness Inconsistency-guided NBV Planning shows how the NGF is used to determine the next view by minimizing the inconsistency between the predicted graspness (from the NGF) and the pseudo-graspness (predicted from a depth image via the graspness network) in the candidate views. This inconsistency guides the selection of the next-best-view, aiming to efficiently and incrementally refine the grasp distribution in the NGF.", "section": "3.2 Neural Graspness Field Mapping"}, {"figure_path": "6FYh6gxzPf/figures/figures_5_1.jpg", "caption": "Figure 3: (a) The pseudo-graspness error Eg(\u011d) and rendered graspness error E\u011d of initial steps. (b) Visualization of the pseudo-graspness, rendered graspness and the corresponding information gain of different views.", "description": "This figure visualizes the performance of the proposed graspness inconsistency-guided next-best-view (NBV) planning strategy.  Subfigure (a) shows the pseudo-graspness error and rendered graspness error over multiple steps, indicating how the errors decrease as more views are incorporated. Subfigure (b) displays the pseudo-graspness, rendered graspness, and information gain for different views during the NBV planning process.  The yellow boxes highlight areas with higher grasp probability, demonstrating how the NGF improves grasp prediction accuracy with additional views.", "section": "3.3 Graspness Inconsistency-guided Next-Best-View Planning"}, {"figure_path": "6FYh6gxzPf/figures/figures_6_1.jpg", "caption": "Figure 4: Comparison on different NBV policies based on the proposed NGF.", "description": "This figure compares the performance of different Next-Best-View (NBV) policies on the proposed Neural Graspness Field (NGF) for robotic grasp detection. The policies tested are: Ours (the proposed method), ActiveNeRF, Close-loop NBV, ACE-NBV, and Uncertainty-policy.  The comparison is made across three object categories (Seen, Similar, Novel) using a variety of performance metrics. The x-axis represents the plan step (number of camera movements), and the y-axis represents the Average Precision (AP). The shaded areas represent confidence intervals. The results show that the proposed method outperforms other methods on all three object categories and across multiple performance measures, particularly in later planning steps.", "section": "4.2 Simulation Experiments"}, {"figure_path": "6FYh6gxzPf/figures/figures_6_2.jpg", "caption": "Figure 5: The comparison of grasp detection result generated with the graspness predicted from 3D geometry and sampled from NGF.", "description": "This figure compares the grasp detection results obtained using two different methods: one using graspness predicted from a 3D geometric representation, and the other using graspness sampled from a Neural Graspness Field (NGF). The results are shown separately for seen, similar, and novel objects across different planning steps (number of views used for active perception).  The shaded area represents the standard deviation across multiple trials.  The figure demonstrates the superior performance of the NGF-based sampling method, especially for novel objects.", "section": "4.2 Simulation Experiments"}, {"figure_path": "6FYh6gxzPf/figures/figures_7_1.jpg", "caption": "Figure 7: The robot setup of real-world experiments and the objects used for grasping.", "description": "This figure shows the experimental setup used for real-world grasping experiments.  The left image displays a UR-10 robotic arm equipped with a RealSense D435i depth camera, positioned above a table with various objects. The right image shows a collection of the different objects used in the experiments, laid out on a flat surface. These items represent a variety of shapes, sizes, and textures to challenge the grasping system.", "section": "4.3 Real-world Experiments"}, {"figure_path": "6FYh6gxzPf/figures/figures_8_1.jpg", "caption": "Figure 8: Visualization of the geometry and graspness extracted from NGF in different planning steps.", "description": "This figure visualizes the Neural Graspness Field (NGF) with different numbers of perception views (2, 5, and 10 views).  The yellow color in the 3D reconstruction represents a high grasp probability. The figure demonstrates that the NGF can reconstruct the scene geometry and model the graspness distribution. With more views added, the details of the geometry and grasp distribution are incrementally refined, showcasing the effectiveness of the proposed active perception method.", "section": "4.4 Visualization of the Neural Graspness Field"}, {"figure_path": "6FYh6gxzPf/figures/figures_8_2.jpg", "caption": "Figure 9: Visualization of the camera trajectories generated from different active grasp detection methods.", "description": "This figure visualizes the camera trajectories generated by three different active grasp detection methods: Close-loop NBV, ACE-NBV, and the proposed method.  Each method's trajectory is shown on a 3D reconstruction of the scene, illustrating how each strategy plans camera movements to gather information for grasp detection.  Close-loop NBV focuses on maximizing scene coverage, while ACE-NBV prioritizes regions with high grasp affordance. The proposed method aims for a balance between comprehensive scene coverage and focusing on grasp-relevant areas, as seen in the more efficient trajectories.", "section": "4.5 Visualization of the Planned Camera Trajectories"}, {"figure_path": "6FYh6gxzPf/figures/figures_12_1.jpg", "caption": "Figure 10: Object setting of the real-world experiment.", "description": "This figure shows the setup of real-world experiments. There are five scenes in total, each with five objects placed in different poses. The figure visualizes the arrangement of objects in each scene to demonstrate the complexity of the real-world grasping tasks.", "section": "4.3 Real-world Experiments"}]