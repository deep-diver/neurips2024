{"references": [{"fullname_first_author": "Yury Gorishniy", "paper_title": "Revisiting deep learning models for tabular data", "publication_date": "2021", "reason": "This paper challenges the dominance of gradient-boosted decision trees in tabular data by introducing an improved multilayer perceptron (MLP) architecture and demonstrating its competitiveness with GBDTs."}, {"fullname_first_author": "L\u00e9o Grinsztajn", "paper_title": "Why do tree-based models still outperform deep learning on typical tabular data?", "publication_date": "2022", "reason": "This paper provides a comprehensive analysis of why and when gradient boosted decision trees outperform deep learning models on tabular data, shaping the context for the current study's exploration of MLP improvements and default parameter tuning."}, {"fullname_first_author": "Vadim Borisov", "paper_title": "Deep neural networks and tabular data: A survey", "publication_date": "2022", "reason": "This survey paper provides a broad overview of deep learning methods for tabular data, including various architectures and regularization techniques, which helps contextualize the current study's focus on MLPs."}, {"fullname_first_author": "Pieter Gijsbers", "paper_title": "AMLB: an AutoML benchmark", "publication_date": "2024", "reason": "This paper introduces a new AutoML benchmark dataset used in evaluating the proposed RealMLP model against other models, providing a robust evaluation framework for the current study's results."}, {"fullname_first_author": "Philipp Probst", "paper_title": "Tunability: Importance of hyperparameters of machine learning algorithms", "publication_date": "2019", "reason": "This paper examines the tunability of machine learning methods and introduces a metric to quantify the importance of hyperparameter tuning, relevant to the current study's investigation of default hyperparameter settings and their impact on performance."}]}