[{"figure_path": "jCPufQaHvb/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Reasonable model predictions exhibit coherence across consecutive segments rather than repeated interruptions. (b) In the healthcare domain, different physicians have varying annotations regarding the start and end times of seizure waves. (c) Based on the proximity to the boundary, we divide each class sequence into 5 levels, from which an equal number of segments are sampled. A one-layer MLP is trained on the segments from each level respectively for the same number of epochs. (d) We visualize the predicted probability of the trained MLP for each level. We observe that as the segments approach the boundaries, the model finds it increasingly challenging to make correct classifications, resulting in more extreme wrong predictions. This strongly underscores the significance of handling boundary segments.", "description": "This figure shows four subfigures that illustrate the challenges of handling boundary segments in segmented time series classification tasks.  Subfigure (a) shows that reasonable model predictions are coherent across consecutive segments, while subfigure (b) demonstrates the inconsistency in annotations among different physicians. Subfigure (c) describes a method for dividing class sequences into levels based on their proximity to the boundary to better understand the effect of inconsistent labels on classification performance. Finally, subfigure (d) visualizes the predicted probabilities of an MLP trained on segments from each level to show how the model's accuracy decreases as the segments get closer to the boundaries. ", "section": "1 Introduction"}, {"figure_path": "jCPufQaHvb/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of Con4m. (a) Overview of continuous contextual representation encoder in Con4m. The leftmost part shows the details of Con-Attention. The right part of the figure shows the architecture of Con-Transformer and the whole encoder of Con4m. (b) Overview of context-aware coherent class prediction and consistent label training framework in Con4m. The right part describes the neighbor class consistency discrimination task and the prediction behavior constraint. The leftmost part presents the training and inference details for label harmonization.", "description": "This figure provides a detailed overview of the Con4m architecture. Panel (a) illustrates the continuous contextual representation encoder, highlighting the Con-Attention mechanism and the Con-Transformer structure, which leverage contextual information to improve the discriminative power of the model. Panel (b) shows the context-aware coherent class prediction and consistent label training framework, focusing on neighbor class consistency discrimination, prediction behavior constraints, and label harmonization techniques. This framework harmonizes inconsistent labels, ensuring robustness and reliability in handling segmented time series classification tasks with varying durations.", "section": "3 The Con4m Method"}, {"figure_path": "jCPufQaHvb/figures/figures_8_1.jpg", "caption": "Figure 1: (a) Reasonable model predictions exhibit coherence across consecutive segments rather than repeated interruptions. (b) In the healthcare domain, different physicians have varying annotations regarding the start and end times of seizure waves. (c) Based on the proximity to the boundary, we divide each class sequence into 5 levels, from which an equal number of segments are sampled. A one-layer MLP is trained on the segments from each level respectively for the same number of epochs. (d) We visualize the predicted probability of the trained MLP for each level. We observe that as the segments approach the boundaries, the model finds it increasingly challenging to make correct classifications, resulting in more extreme wrong predictions. This strongly underscores the significance of handling boundary segments.", "description": "This figure illustrates the challenges of segmented time series classification (TSC) with multiple classes and varying durations (MVD). Subfigure (a) shows ideal coherent predictions across segments. Subfigure (b) shows annotation inconsistencies among physicians in the healthcare domain (seizure detection). Subfigures (c) and (d) demonstrate that model performance deteriorates as segments approach class boundaries, highlighting the importance of handling boundary segments.", "section": "1 Introduction"}, {"figure_path": "jCPufQaHvb/figures/figures_9_1.jpg", "caption": "Figure 1: (a) Reasonable model predictions exhibit coherence across consecutive segments rather than repeated interruptions. (b) In the healthcare domain, different physicians have varying annotations regarding the start and end times of seizure waves. (c) Based on the proximity to the boundary, we divide each class sequence into 5 levels, from which an equal number of segments are sampled. A one-layer MLP is trained on the segments from each level respectively for the same number of epochs. (d) We visualize the predicted probability of the trained MLP for each level. We observe that as the segments approach the boundaries, the model finds it increasingly challenging to make correct classifications, resulting in more extreme wrong predictions. This strongly underscores the significance of handling boundary segments.", "description": "This figure shows the impact of inconsistent boundary labels on model performance in a segmented time series classification task. Subfigure (a) shows that reasonable model predictions exhibit coherence across consecutive segments, (b) illustrates inconsistencies in boundary annotations from different physicians, (c) shows how class sequences are divided into 5 levels based on their proximity to boundaries, and (d) shows the predicted probabilities from an MLP trained on segments from each level. The results highlight the challenges posed by inconsistent boundaries.", "section": "1 Introduction"}, {"figure_path": "jCPufQaHvb/figures/figures_16_1.jpg", "caption": "Figure 1: (a) Reasonable model predictions exhibit coherence across consecutive segments rather than repeated interruptions. (b) In the healthcare domain, different physicians have varying annotations regarding the start and end times of seizure waves. (c) Based on the proximity to the boundary, we divide each class sequence into 5 levels, from which an equal number of segments are sampled. A one-layer MLP is trained on the segments from each level respectively for the same number of epochs. (d) We visualize the predicted probability of the trained MLP for each level. We observe that as the segments approach the boundaries, the model finds it increasingly challenging to make correct classifications, resulting in more extreme wrong predictions. This strongly underscores the significance of handling boundary segments.", "description": "This figure demonstrates the challenges of segmented time series classification with inconsistent boundary labels.  Subfigure (a) shows ideal coherent predictions across segments, contrasting with the inconsistent annotations of different physicians in (b). Subfigure (c) illustrates the methodology of dividing class sequences into levels based on proximity to boundaries, training an MLP on each level's segments, and visualizing the resulting prediction probabilities in (d). The results in (d) highlight the decreased accuracy and increased errors near the boundaries, emphasizing the importance of handling these boundary segments.", "section": "1 Introduction"}, {"figure_path": "jCPufQaHvb/figures/figures_17_1.jpg", "caption": "Figure 1: (a) Reasonable model predictions exhibit coherence across consecutive segments rather than repeated interruptions. (b) In the healthcare domain, different physicians have varying annotations regarding the start and end times of seizure waves. (c) Based on the proximity to the boundary, we divide each class sequence into 5 levels, from which an equal number of segments are sampled. A one-layer MLP is trained on the segments from each level respectively for the same number of epochs. (d) We visualize the predicted probability of the trained MLP for each level. We observe that as the segments approach the boundaries, the model finds it increasingly challenging to make correct classifications, resulting in more extreme wrong predictions. This strongly underscores the significance of handling boundary segments.", "description": "This figure demonstrates the impact of inconsistent boundary labeling on model performance in segmented time series classification (TSC).  Panel (a) shows ideal coherent predictions across segments. Panel (b) illustrates inconsistencies in annotations from different physicians on seizure data. Panel (c) shows how the class sequences were divided into five levels based on proximity to the boundary, with segments sampled from each level used to train a simple MLP. Panel (d) shows that as the level (proximity to the boundary) increases, model accuracy decreases, highlighting the challenge of handling inconsistent boundary labels and the importance of contextual information.", "section": "1 Introduction"}, {"figure_path": "jCPufQaHvb/figures/figures_22_1.jpg", "caption": "Figure 1: (a) Reasonable model predictions exhibit coherence across consecutive segments rather than repeated interruptions. (b) In the healthcare domain, different physicians have varying annotations regarding the start and end times of seizure waves. (c) Based on the proximity to the boundary, we divide each class sequence into 5 levels, from which an equal number of segments are sampled. A one-layer MLP is trained on the segments from each level respectively for the same number of epochs. (d) We visualize the predicted probability of the trained MLP for each level. We observe that as the segments approach the boundaries, the model finds it increasingly challenging to make correct classifications, resulting in more extreme wrong predictions. This strongly underscores the significance of handling boundary segments.", "description": "This figure demonstrates the challenges in handling boundary segments in segmented time series classification with multiple classes and varying durations (MVD). It shows that (a) coherent model predictions are expected across consecutive segments, (b) annotation inconsistencies exist among physicians in the healthcare domain, (c) dividing each class sequence into levels based on proximity to the boundary helps analyze model performance, and (d) model accuracy decreases near boundaries, highlighting the importance of handling boundary segments.", "section": "1 Introduction"}]