[{"figure_path": "cUGf2HaNcs/figures/figures_2_1.jpg", "caption": "Figure 1: TURTLE's Architecture. The overall architecture diagram of the proposed method. TURTLE is a U-Net [52] style architecture, wherein the encoder blocks are historyless feedforward blocks, while the decoder couples the causal history model (CHM) to condition the restoration procedure on truncated history of the input. We also present assorted restoration examples on the right-frame taken from video raindrops and rain streak removal [71], night deraining [47], and video deblurring [41] tasks, respectively.", "description": "This figure shows the architecture of the proposed video restoration method, TURTLE.  It's a U-Net style architecture with historyless feedforward encoder blocks and a decoder that incorporates a Causal History Model (CHM) to utilize information from previous frames. The figure also includes example results of video restoration for various tasks, such as raindrop removal, night deraining, and deblurring, highlighting the model's capabilities.", "section": "3.1 Architecture Design"}, {"figure_path": "cUGf2HaNcs/figures/figures_3_1.jpg", "caption": "Figure 2: Causal History Model. The diagrammatic illustration of the proposed Causal History Model (CHM) detailing the internal function. In the initial phase, for each patch in the current frame (denoted by the stars), we identify and implicitly align the top-k similar patches in the history. In the subsequent phase, we score and aggregate features from this aligned history to create a refined output that blends the input frame features with pertinent history data. We visualize frames in this diagram for exposition, but in practice the procedure operates on the feature maps.", "description": "The figure illustrates the Causal History Module (CHM), a key component of the TURTLE architecture.  CHM aligns patches from the current frame with similar patches from a truncated history of previous frames.  This alignment is implicit, learned by the model rather than relying on explicit motion estimation.  After alignment, a scoring mechanism determines the relevance of each historical patch to the current frame's restoration.  The relevant patches are aggregated to create a refined output that combines current frame information with relevant historical information, improving restoration quality.", "section": "3.2 Causal History Model"}, {"figure_path": "cUGf2HaNcs/figures/figures_5_1.jpg", "caption": "Figure 3: Visual Results on Video Desnowing and Nighttime Video Deraining. We compare video desnowing results with the best published method in literature, SVDNet [10]. The video frame has both snow, and haze. While SVDNet [10] removes snow flakes, TURTLE can remove haze, and snow flakes, and hence is more faithful to the ground truth. In nighttime deraining, we compare TURTLE to MetaRain [47]. TURTLE maintains color consistency in the restored result.", "description": "This figure shows visual comparisons of video desnowing and nighttime deraining results between TURTLE and other state-of-the-art methods.  The desnowing example demonstrates that while SVDNet removes snow, TURTLE additionally removes haze, resulting in a more accurate restoration.  In the nighttime deraining example, TURTLE produces a result that is more color-consistent than MetaRain.", "section": "4 Experiments"}, {"figure_path": "cUGf2HaNcs/figures/figures_7_1.jpg", "caption": "Figure 1: TURTLE's Architecture. The overall architecture diagram of the proposed method. TURTLE is a U-Net [52] style architecture, wherein the encoder blocks are historyless feedforward blocks, while the decoder couples the causal history model (CHM) to condition the restoration procedure on truncated history of the input. We also present assorted restoration examples on the right-frame taken from video raindrops and rain streak removal [71], night deraining [47], and video deblurring [41] tasks, respectively.", "description": "This figure shows the architecture of the proposed video restoration method, TURTLE.  It is a U-Net architecture with historyless feedforward encoder blocks and a decoder that incorporates a causal history model (CHM). The CHM uses a truncated history of the input to improve restoration. The figure also includes examples of video restoration results for various tasks such as raindrop removal, night deraining, and video deblurring, demonstrating the effectiveness of the proposed method.", "section": "3.1 Architecture Design"}, {"figure_path": "cUGf2HaNcs/figures/figures_8_1.jpg", "caption": "Figure 5: Blind Video Denoising and Video Super-Resolution Visual Results. Qualitative compar-ison of previous methods with TURTLE on a test frame from Set8 dataset for blind video denoising (\u03c3 = 50), and MVSR4\u00d7 dataset [71] for video super resolution. In video denoising, TURTLE restoresdetails, while BSVD-64 [49] smudges textures (text and the dinosaur on the biker's jacket). In VSR, previous methods such as TTVSR [37], BasicVSR++ [7], or EAVSR [71] tend to introduce blur inresults, while TURTLE's restored results are sharper, and crisper.", "description": "This figure shows visual comparisons of video denoising and super-resolution results using different methods, including TURTLE and several state-of-the-art techniques.  The top row presents a blind video denoising example, highlighting TURTLE's ability to preserve fine details compared to BSVD-64's smudged output. The bottom row showcases video super-resolution, demonstrating TURTLE's superior sharpness and detail retention compared to methods such as TTVSR, BasicVSR++, and EAVSR, which produce blurrier results.", "section": "4.5 Video Super-Resolution"}, {"figure_path": "cUGf2HaNcs/figures/figures_16_1.jpg", "caption": "Figure 1: TURTLE's Architecture. The overall architecture diagram of the proposed method. TURTLE is a U-Net [52] style architecture, wherein the encoder blocks are historyless feedforward blocks, while the decoder couples the causal history model (CHM) to condition the restoration procedure on truncated history of the input. We also present assorted restoration examples on the right-frame taken from video raindrops and rain streak removal [71], night deraining [47], and video deblurring [41] tasks, respectively.", "description": "The figure shows the architecture of the proposed TURTLE model for video restoration.  It's a U-Net-like architecture with a historyless feedforward encoder and a decoder that uses a Causal History Model (CHM) to incorporate information from previous frames. The right side of the image shows examples of video restoration results from different tasks.", "section": "3.1 Architecture Design"}, {"figure_path": "cUGf2HaNcs/figures/figures_16_2.jpg", "caption": "Figure 7: CHM Tracking. Visual illustration of CHM tracking query points in the frame history (frames previous to the input frame). In the top row, we plot the correctly tracked points, while the bottom row visualizes the limitations in the case of redundant patterns. We plot the query and most similar points on input frames for ease of exposition, but in practice, they function on feature maps.", "description": "This figure shows how the causal history model (CHM) tracks similar patches across the frames in the history. The top row shows successful tracking, while the bottom row demonstrates limitations when redundant patterns exist.  Note that this visualization uses input frames for clarity; the CHM actually operates on feature maps.", "section": "Further Visual Comparisons"}, {"figure_path": "cUGf2HaNcs/figures/figures_17_1.jpg", "caption": "Figure 8: Illustration of Historyless FFN. Transformer block is similar in spirit to the block introduced in [79], while the Historyless FFN's design takes inspiration from the blocks in [15, 11].", "description": "This figure shows the architecture of the Historyless Feed Forward Network (FFN) and the Transformer block used in the Causal History Module (CHM). The Historyless FFN consists of several convolutional layers, followed by a GELU activation function, and then a 1x1 convolutional layer. The Transformer block is similar to the one used in the Restormer paper [79], which uses a combination of pointwise convolutions, depthwise convolutions, channel attention, and channel MLP.  The figure highlights the differences in architecture between the Historyless FFN and the Transformer block, illustrating their roles within the overall TURTLE model.", "section": "B TURTLE's Specifications & Details"}, {"figure_path": "cUGf2HaNcs/figures/figures_18_1.jpg", "caption": "Figure 4: Visual Results on Video Deblurring and Raindrops and Rain Streaks Removal. Qualitative results on video deblurring on the GoPro dataset [41] are in the top row. Our method, TURTLE, restores the frames without any artifacts (see the number plate) unlike DSTNet [45]. On video raindrops and rain streaks removal task, we compare our method with the best method in literature ViMPNet [71]. Notice how the frame restored by ViMPNet [71] has artifacts (see tree region, and the railing gate), while TURTLE's output is free of unwanted artifacts.", "description": "This figure shows a comparison of video deblurring and rain removal results between TURTLE and other state-of-the-art methods. The top row demonstrates that TURTLE effectively removes blur from a video frame without introducing artifacts, unlike DSTNet, which leaves artifacts. The bottom row showcases the superiority of TURTLE over ViMPNet in removing rain streaks and raindrops, preserving details that ViMPNet fails to retain.", "section": "4 Experiments"}, {"figure_path": "cUGf2HaNcs/figures/figures_20_1.jpg", "caption": "Figure 4: Visual Results on Video Deblurring and Raindrops and Rain Streaks Removal. Qualitative results on video deblurring on the GoPro dataset [41] are in the top row. Our method, TURTLE, restores the frames without any artifacts (see the number plate) unlike DSTNet [45]. On video raindrops and rain streaks removal task, we compare our method with the best method in literature ViMPNet [71]. Notice how the frame restored by ViMPNet [71] has artifacts (see tree region, and the railing gate), while TURTLE's output is free of unwanted artifacts.", "description": "This figure shows visual comparisons of video deblurring and rain removal results.  The top row demonstrates that TURTLE effectively removes blur from a video sequence better than a competing method (DSTNet), preserving fine details like license plates. The bottom rows compare TURTLE to ViMPNet on a rain/streak removal task.  While ViMPNet leaves artifacts (blurriness, missing details), TURTLE produces cleaner results.", "section": "4 Experiments"}, {"figure_path": "cUGf2HaNcs/figures/figures_20_2.jpg", "caption": "Figure 3: Visual Results on Video Desnowing and Nighttime Video Deraining. We compare video desnowing results with the best published method in literature, SVDNet [10]. The video frame has both snow, and haze. While SVDNet [10] removes snow flakes, TURTLE can remove haze, and snow flakes, and hence is more faithful to the ground truth. In nighttime deraining, we compare TURTLE to MetaRain [47]. TURTLE maintains color consistency in the restored result.", "description": "This figure shows visual comparisons of video desnowing and nighttime video deraining results between the proposed TURTLE method and existing state-of-the-art methods (SVDNet for desnowing and MetaRain for deraining).  The results demonstrate TURTLE's improved ability to remove both snow and haze in desnowing, and to maintain color consistency while removing rain streaks in nighttime deraining, showcasing superior performance compared to existing methods.", "section": "3 Methodology"}, {"figure_path": "cUGf2HaNcs/figures/figures_21_1.jpg", "caption": "Figure 1: TURTLE's Architecture. The overall architecture diagram of the proposed method. TURTLE is a U-Net [52] style architecture, wherein the encoder blocks are historyless feedforward blocks, while the decoder couples the causal history model (CHM) to condition the restoration procedure on truncated history of the input. We also present assorted restoration examples on the right-frame taken from video raindrops and rain streak removal [71], night deraining [47], and video deblurring [41] tasks, respectively.", "description": "This figure shows the architecture of the proposed TURTLE model for video restoration. It's a U-Net architecture with historyless feedforward encoder blocks and a decoder that uses a causal history model (CHM) to incorporate previous frames' information. The figure also displays example restoration results for various video degradation types, demonstrating the model's capability.", "section": "3.1 Architecture Design"}, {"figure_path": "cUGf2HaNcs/figures/figures_22_1.jpg", "caption": "Figure 1: TURTLE's Architecture. The overall architecture diagram of the proposed method. TURTLE is a U-Net [52] style architecture, wherein the encoder blocks are historyless feedforward blocks, while the decoder couples the causal history model (CHM) to condition the restoration procedure on truncated history of the input. We also present assorted restoration examples on the right-frame taken from video raindrops and rain streak removal [71], night deraining [47], and video deblurring [41] tasks, respectively.", "description": "This figure shows the architecture of the proposed TURTLE model for video restoration.  It's a U-Net-like structure with a historyless feedforward encoder and a decoder that incorporates a Causal History Model (CHM). The CHM leverages a truncated history of the input frames to improve restoration quality.  The figure also includes examples of restoration results from several video restoration tasks.", "section": "3.1 Architecture Design"}, {"figure_path": "cUGf2HaNcs/figures/figures_23_1.jpg", "caption": "Figure 1: TURTLE's Architecture. The overall architecture diagram of the proposed method. TURTLE is a U-Net [52] style architecture, wherein the encoder blocks are historyless feedforward blocks, while the decoder couples the causal history model (CHM) to condition the restoration procedure on truncated history of the input. We also present assorted restoration examples on the right-frame taken from video raindrops and rain streak removal [71], night deraining [47], and video deblurring [41] tasks, respectively.", "description": "This figure shows the overall architecture of the proposed TURTLE model for video restoration.  The model uses a U-Net architecture with historyless feedforward encoder blocks and a decoder that incorporates a causal history model (CHM) to leverage information from previously processed frames. The right side of the figure displays examples of video restoration results from various tasks, illustrating the model's capabilities in handling different types of degradation, such as raindrops, rain streaks, night deraining, and deblurring.", "section": "3.1 Architecture Design"}]