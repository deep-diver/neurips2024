[{"figure_path": "vpEq2bzsS0/tables/tables_6_1.jpg", "caption": "Table 1: Ablation study on various components of MoTE with ViT-L/14 network.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of different components of the MoTE model on its performance.  The study uses the ViT-L/14 network.  It shows the performance of the baseline model (Text4Vis) and then progressively adds components of MoTE (temporal experts, weight merging regularization, MSE loss, and temporal feature modulation) to assess the effect of each component on the final performance, measured using Top-1 accuracy on Kinetics-400 and zero-shot accuracy on UCF101, HMDB, and Kinetics-600.", "section": "4.2 Ablation Studies"}, {"figure_path": "vpEq2bzsS0/tables/tables_6_2.jpg", "caption": "Table 2: Ablation studies on key details. We report close-set accuracy on K400 and zero-shot accuracy on UCF-101 and K600 split1, using the ViT-L/14 network. Default settings are colored in gray.", "description": "This table presents ablation study results focusing on the impact of different hyperparameters and design choices on the performance of the MoTE model. It shows the effect of various factors, such as initialization and training data distribution across experts, the number of temporal experts, knowledge aggregation methods, routing policies during fine-tuning, different types of Weight Merging Regularization, and different scale parameters for temporal feature modulation, on the model's performance. The results are evaluated in terms of top-1 accuracy on the Kinetics-400 (K400) dataset for close-set evaluation, and on UCF-101 and K600 (split1) datasets for zero-shot evaluation. The table provides quantitative evidence to support the claims about MoTE's design choices and their effects on performance.", "section": "4.2 Ablation Studies"}, {"figure_path": "vpEq2bzsS0/tables/tables_7_1.jpg", "caption": "Table 3: Zero-shot video recognition performance compared with the state-of-the-art methods on UCF-101, HMDB-51, and Kinetics-600. \u2020 denotes reproduced results with our implementation.", "description": "This table presents a comparison of the proposed MoTE model's zero-shot video recognition performance against several state-of-the-art methods.  The comparison is done across three benchmark datasets: UCF-101, HMDB-51, and Kinetics-600.  The table shows the top-1 accuracy achieved by each method on each dataset, along with details like the encoder used (ViT-B/16 or ViT-L/14), the number of frames used as input, and whether the results were reproduced by the authors of the current paper.", "section": "4.3 Main Results"}, {"figure_path": "vpEq2bzsS0/tables/tables_8_1.jpg", "caption": "Table 4: Close-set and zero-shot performance trade-off compared with the state-of-the-art methods. We report close-set results on K400. \"HMzs\" indicates the harmonic mean of zero-shot results on UCF, HMDB, and K600. \"Trade-off\" is defined as the harmonic mean of Top-1K400 and HMzs. \"Unified model\" indicates whether the method is evaluated using the same model in both settings.", "description": "This table compares the performance of MoTE against other state-of-the-art methods in video recognition.  It shows both close-set (Kinetics-400) and zero-shot (UCF-101, HMDB-51, Kinetics-600) results.  The \"HMzs\" column represents the harmonic mean of the zero-shot results across the three datasets.  The \"Trade-off\" score balances both close-set and zero-shot performance, highlighting MoTE's ability to perform well on both aspects simultaneously. The \"Unified model\" column indicates whether the same model was used for both close-set and zero-shot evaluations, emphasizing MoTE's unified approach.", "section": "4.3 Main Results"}, {"figure_path": "vpEq2bzsS0/tables/tables_8_2.jpg", "caption": "Table 5: Few-shot results compared with the state-of-the-art methods on HMDB, UCF, and SSv2. All methods directly fine-tune on CLIP, except MAXI (Tuning after pre-training on K400.)", "description": "This table presents a comparison of few-shot video recognition performance between the proposed MoTE method and other state-of-the-art methods.  The results are shown for different numbers of shots (K=2, 4, 8, 16) on three benchmark datasets: HMDB-51, UCF-101, and Something-Something V2 (SSv2).  The table highlights the improvements achieved by MoTE compared to existing methods, particularly in terms of few-shot learning capability across various datasets.", "section": "4.3 Main Results"}, {"figure_path": "vpEq2bzsS0/tables/tables_14_1.jpg", "caption": "Table 1: Ablation study on various components of MoTE with ViT-L/14 network.", "description": "This ablation study analyzes the impact of different components of the MoTE model on its performance.  It uses the ViT-L/14 network and shows results for various metrics on the Kinetics-400, UCF-101, HMDB-51, and Kinetics-600 datasets, comparing a baseline (Text4Vis) against versions of MoTE with added components such as temporal experts, weight merging regularization (LWMR), mean squared error loss (LMSE), and temporal feature modulation.  The table highlights the incremental performance improvements achieved by each component.", "section": "4.2 Ablation Studies"}, {"figure_path": "vpEq2bzsS0/tables/tables_15_1.jpg", "caption": "Table 7: Additional ablation studies. Default settings are colored in gray. (a) Optional designs for the temporal expert. (b) Varying neighbor numbers K for the temporal feature modulation. (c) Different types of Weight Merging Regularization. (d) Ablation study on the training costs of MoTE. (e) Results of fine-tuning on UCF and zero-shot evaluating on K400. (f) Effect of temperature selection schemes.", "description": "This table presents the results of ablation studies conducted to analyze different components of the MoTE model. It explores various architectural designs for the temporal expert, investigates the impact of changing the number of neighbors for temporal feature modulation, compares different types of weight merging regularization, examines the training costs, evaluates the model's performance under different training scenarios, and assesses different temperature selection schemes.", "section": "Additional Ablations"}, {"figure_path": "vpEq2bzsS0/tables/tables_17_1.jpg", "caption": "Table 1: Ablation study on various components of MoTE with ViT-L/14 network.", "description": "This table presents an ablation study on the MoTE model using the ViT-L/14 network architecture. It systematically evaluates the contribution of different components of the MoTE framework to the overall performance, including temporal experts, weight merging regularization (LWMR), mean squared error (LMSE) loss, and temporal feature modulation.  The results are shown in terms of Top-1 accuracy for zero-shot video recognition on the UCF-101, HMDB-51, and Kinetics-600 datasets, as well as close-set performance on the Kinetics-400 dataset. By comparing the performance with and without each component, the table quantifies the effectiveness of each component in improving both zero-shot generalization and close-set performance.", "section": "4.2 Ablation Studies"}]