{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that is the basis for the adaptation in this paper."}, {"fullname_first_author": "Bolin Ni", "paper_title": "Expanding language-image pretrained models for general video recognition", "publication_date": "2022-10-26", "reason": "This paper is directly compared against in the experimental section and serves as a benchmark for video recognition using large language models."}, {"fullname_first_author": "Noam Shazeer", "paper_title": "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer", "publication_date": "2017-01-24", "reason": "The Mixture-of-Experts architecture used in this paper is directly inspired by this paper, which outlines the fundamental principles and advantages of such architectures."}, {"fullname_first_author": "Hanoona Rasheed", "paper_title": "Fine-tuned clip models are efficient video learners", "publication_date": "2023-06-01", "reason": "This paper provides a direct comparison to the methods used in this paper, highlighting the efficiency of using fine-tuned CLIP models for video recognition."}, {"fullname_first_author": "Junting Pan", "paper_title": "ST-Adapter: Parameter-efficient image-to-video transfer learning", "publication_date": "2022-12-01", "reason": "This paper proposes ST-Adapter, a method directly compared and ablated against in this paper, highlighting the potential for parameter-efficient transfer learning in video recognition."}]}