[{"figure_path": "eNeqGc9AgR/figures/figures_0_1.jpg", "caption": "Figure 1: Flatten Anything Model (FAM) for neural surface parameterization: (a) input 3D models; (b) learned UV coordinates; (c) texture mappings; (d) learned cutting seams.", "description": "This figure shows examples of the Flatten Anything Model (FAM) applied to various 3D models. It demonstrates the model's ability to generate UV coordinates, texture mappings, and cutting seams for different types of 3D models, including disk-type, genus-0, genus-1, and complex topologies. It also shows the results for real-scanned objects, real-scanned scenes, and 3D AIGC models, demonstrating the model's versatility in handling diverse input data.", "section": "Abstract"}, {"figure_path": "eNeqGc9AgR/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of bi-directional cycle mapping, composed of (a) 2D\u21923D\u21922D cycle mapping branch, and (b) 3D\u21922D\u21923D cycle mapping branch. Modules with the same color share network parameters. (c) shows the learned cutting seams. (d) shows the checker-image texture mapping.", "description": "This figure illustrates the bi-directional cycle mapping framework of the Flatten Anything Model (FAM).  It shows the two branches of the model: one starting with a 2D lattice, transforming it to a 3D surface, and then back to a 2D parameterization; and another starting with a 3D point cloud, flattening it to a 2D parameterization and then reconstructing it in 3D. The figure highlights the shared parameters between modules, the learned cutting seams, and the resulting texture mapping. ", "section": "3.1 Bi-directional Cycle Mapping"}, {"figure_path": "eNeqGc9AgR/figures/figures_7_1.jpg", "caption": "Figure 3: Comparison of UV unwrapping and texture mapping results on different (a) open surface models produced by (b) our FAM and (c) SLIM, where the 2D UV coordinates are color-coded by ground-truth point-wise normals to facilitate visualization.", "description": "This figure compares the UV unwrapping and texture mapping results of the proposed FAM model and SLIM model on several open surface models.  The FAM model's results are shown alongside the results from the SLIM model for comparison. The 2D UV coordinates are color-coded according to the ground truth point-wise normals to aid in visualization and analysis of the results. This visualization helps to assess the quality and accuracy of the parameterization methods.", "section": "4 Experiments"}, {"figure_path": "eNeqGc9AgR/figures/figures_8_1.jpg", "caption": "Figure 4: Display of surface parameterization results produced by our FAM: (a) input 3D models; (b) learned UV coordinates; (c) texture mappings; (d) learned cutting seams.", "description": "This figure shows the results of applying the Flatten Anything Model (FAM) to various 3D models.  It demonstrates the model's ability to produce high-quality, global free-boundary surface parameterizations. The four columns display: (a) the input 3D model, (b) the learned UV coordinates (a 2D representation of the 3D surface), (c) the texture mapping applied to the 2D UV coordinates, and (d) the cutting seams automatically discovered by FAM that are required for flattening the surface.", "section": "4 Experiments"}, {"figure_path": "eNeqGc9AgR/figures/figures_8_2.jpg", "caption": "Figure 5: Point cloud parameterization achieved by our FAM (left) and FBCP-PC (right).", "description": "This figure compares the results of point cloud parameterization using the proposed Flatten Anything Model (FAM) and the FBCP-PC method.  The left side shows FAM's results, which directly takes unstructured points without normals as input. The right side shows FBCP-PC's results, requiring additional inputs of oriented boundary indices.  Three example point clouds are visualized: cloth-pts, julius-pts, and spiral-pts.  The comparison highlights the difference in input requirements and the resulting parameterizations.", "section": "4 Experiments"}, {"figure_path": "eNeqGc9AgR/figures/figures_9_1.jpg", "caption": "Figure 2: Illustration of bi-directional cycle mapping, composed of (a) 2D\u21923D\u21922D cycle mapping branch, and (b) 3D\u21922D\u21923D cycle mapping branch. Modules with the same color share network parameters. (c) shows the learned cutting seams. (d) shows the checker-image texture mapping.", "description": "This figure illustrates the bi-directional cycle mapping framework of the Flatten Anything Model (FAM). It shows how the model learns to map between 2D and 3D spaces using two parallel branches: one going from 2D to 3D to 2D and the other from 3D to 2D to 3D.  The modules in the same color share the same network parameters. The learned cutting seams and checker-image texture mapping are also shown.", "section": "3.1 Bi-directional Cycle Mapping"}, {"figure_path": "eNeqGc9AgR/figures/figures_9_2.jpg", "caption": "Figure 4: Display of surface parameterization results produced by our FAM: (a) input 3D models; (b) learned UV coordinates; (c) texture mappings; (d) learned cutting seams.", "description": "This figure shows examples of surface parameterization results obtained using the Flatten Anything Model (FAM).  It presents four columns: (a) the original 3D models, (b) the learned UV coordinates (a flattened representation of the 3D surface), (c) the texture mapping applied to the 2D UV coordinates and then mapped back onto the 3D model, and (d) the automatically learned cutting seams used to prepare the 3D model for flattening. The visualization of UV coordinates uses a rainbow color scheme to demonstrate the mapping from 3D to 2D. This figure highlights the model's ability to parameterize various shapes, including those with complex geometries and topologies.", "section": "4 Experiments"}, {"figure_path": "eNeqGc9AgR/figures/figures_9_3.jpg", "caption": "Figure 9: (a) input meshes; (b) UV maps; (c): texture mappings and learned cutting seams.", "description": "This figure shows the results of applying FAM to a Hilbert-space-filling cylinder model (a complex shape) and a ShapeNet car model (a CAD model with rich interior structures and multiple layers).  Subfigure (a) displays the input 3D models.  (b) Shows the learned UV coordinates (parameterization). (c) Presents the texture mappings and learned cutting seams generated by FAM on the input models. The results for the Hilbert-space-filling cylinder highlight the model's ability to handle complex shapes. In contrast, the ShapeNet car model shows some limitations when dealing with intricate interior structures, indicating areas for future improvement.", "section": "Experiments"}, {"figure_path": "eNeqGc9AgR/figures/figures_9_4.jpg", "caption": "Figure 9: (a) input meshes; (b) UV maps; (c) texture mappings and learned cutting seams.", "description": "This figure shows the results of applying FAM to three different models. The first model is a simple shape, the second is a more complex shape with internal structures, and the third is a very complex CAD model. The results show that FAM is able to generate accurate UV maps for simple shapes, but the accuracy decreases as the complexity of the shape increases. For the very complex CAD model, FAM is unable to generate a seamless UV map.", "section": "Experiments"}, {"figure_path": "eNeqGc9AgR/figures/figures_13_1.jpg", "caption": "Figure 10: Experiments on the nefertiti testing model whose topology is not homeomorphic to a disk. (a) The parameterization results of SLIM are obtained by manually-specifying a high-quality cutting seam, with the conformality metric of 0.089. (b) The parameterization results of our FAM, in which the cutting seam is automatically learned, with the conformality metric of 0.117.", "description": "This figure compares the results of surface parameterization on the Nefertiti model using SLIM (manual cutting) and FAM (automatic cutting).  Both methods show the UV unwrapping and texture mapping, along with the cutting seam that was used.  FAM demonstrates its ability to automatically learn a reasonable cutting seam, while SLIM's results rely on manual specification. The conformality metrics (lower is better) are shown, indicating slightly lower quality with FAM's learned cutting seam.", "section": "A.2 Discussions about Global and Multi-Chart Surface Parameterization"}, {"figure_path": "eNeqGc9AgR/figures/figures_14_1.jpg", "caption": "Figure 2: Illustration of bi-directional cycle mapping, composed of (a) 2D\u21923D\u21922D cycle mapping branch, and (b) 3D\u21922D\u21923D cycle mapping branch. Modules with the same color share network parameters. (c) shows the learned cutting seams. (d) shows the checker-image texture mapping.", "description": "This figure illustrates the Flatten Anything Model (FAM)'s bi-directional cycle mapping framework.  It shows the two branches of the model: 2D to 3D to 2D and 3D to 2D to 3D.  Modules with the same color share parameters.  The figure also highlights the learned cutting seams and a checker-image texture mapping as a result of the process. The FAM uses these mappings to perform global free-boundary surface parameterization.", "section": "3.1 Bi-directional Cycle Mapping"}, {"figure_path": "eNeqGc9AgR/figures/figures_14_2.jpg", "caption": "Figure 2: Illustration of bi-directional cycle mapping, composed of (a) 2D\u21923D\u21922D cycle mapping branch, and (b) 3D\u21922D\u21923D cycle mapping branch. Modules with the same color share network parameters. (c) shows the learned cutting seams. (d) shows the checker-image texture mapping.", "description": "This figure illustrates the proposed bi-directional cycle mapping framework. It shows the two branches of the framework: 2D to 3D to 2D and 3D to 2D to 3D.  Modules with the same color share parameters indicating a parameter sharing strategy.  The learned cutting seams and checker image texture mapping are also visualized. This framework mimics the actual physical surface parameterization process.", "section": "3.1 Bi-directional Cycle Mapping"}]