[{"figure_path": "JRSyMBBJi6/tables/tables_2_1.jpg", "caption": "Table 1: Comparison with existing CLQA approaches. Ind. denotes inductive generalization to new entities (e) and relations (r). ULTRAQUERY is the first inductive method the generalizes to queries over new entities and relations at inference time.", "description": "The table compares ULTRAQUERY with existing Complex Logical Query Answering (CLQA) approaches.  It highlights whether each method supports inductive generalization to new entities (Ind. e) and new relations (Ind. r) during inference, and the type of logical operators used (parametric or fuzzy). ULTRAQUERY is presented as the first method to achieve inductive generalization for both entities and relations, utilizing fuzzy logical operators.", "section": "Related Work"}, {"figure_path": "JRSyMBBJi6/tables/tables_7_1.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot inference performance of ULTRAQUERY and its ablated version (ULTRAQUERY LP) against the best-performing baselines across 23 datasets.  It breaks down the results by dataset type (transductive, inductive (e), and inductive (e,r)), showing mean reciprocal rank (MRR) and Hits@10 for EPFO (average of 9 query types) and negation (average of 5 query types).  ULTRAQUERY was fully trained on one dataset, while ULTRAQUERY LP only underwent pre-training for KG completion. The \"no thrs.\" variant of ULTRAQUERY LP omits score thresholding during inference.  The table highlights the zero-shot capability of ULTRAQUERY, which is trained on only one dataset but tested on many more.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_9_1.jpg", "caption": "Table 3: Zero-shot inference results on 20 inductive datasets of ULTRAQUERY trained on 1, 2, and 3 datasets, respectively. The biggest gains of the 2G model are in bold.", "description": "This table presents the results of a zero-shot inference experiment using the ULTRAQUERY model trained on different numbers of datasets (1, 2, and 3).  It shows the mean reciprocal rank (MRR) and Hits@10 metrics for both EPFO (average of 9 query types) and negation queries (average of 5 query types) across 20 inductive datasets (11 inductive (e, r) and 9 inductive (e)). The bold values highlight the best performance achieved with training on 2 datasets, indicating that training the model on two datasets gives better performance in this specific experiment.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_13_1.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents the zero-shot inference results of the ULTRAQUERY model and its ablated version (ULTRAQUERY LP) on 23 different datasets.  It compares their performance to the best reported baselines for each dataset.  The table breaks down the results by dataset type (transductive, inductive (e), inductive (e,r)) and shows the Mean Reciprocal Rank (MRR) and Hits@10 metrics for both EPFO (average of 9 query types) and negation queries (average of 5 query types).  It highlights that ULTRAQUERY, trained on a single transductive dataset, achieves competitive or better performance than the best baselines, which are specifically trained on each dataset. ULTRAQUERY LP, a pre-trained model with a scoring thresholding technique, also shows results but with a different performance profile.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_13_2.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot inference performance of ULTRAQUERY and its ablated version (ULTRAQUERY LP) against the best-performing baselines on 23 datasets.  It breaks down the results by dataset type (transductive, inductive (e), and inductive (e,r)) and shows Mean Reciprocal Rank (MRR) and Hits@10 for both EPFO (average of 9 query types) and negation queries (average of 5 query types).  ULTRAQUERY was trained on a single transductive dataset (FB15k237), while ULTRAQUERY LP used a pre-trained model without further training.  The table highlights the zero-shot capability of ULTRAQUERY by comparing its performance to baselines that were specifically trained on each dataset.  The \"no thrs.\" column refers to a variation of ULTRAQUERY LP that does not employ score thresholding.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_13_3.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot inference performance of ULTRAQUERY and its ablated version (ULTRAQUERY LP) against the best-performing baselines on 23 different datasets.  It breaks down the results by dataset type (transductive, inductive (e), and inductive (e,r)), showing Mean Reciprocal Rank (MRR) and Hits@10 for both EPFO (average of 9 query types) and negation queries (average of 5 query types).  The table highlights ULTRAQUERY's zero-shot capability by training it on only one dataset (FB15k237) and then testing it on the others.  ULTRAQUERY LP uses a pre-trained model without further training, and a \"no thrs.\" version is also included for comparison.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_14_1.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot inference performance of ULTRAQUERY and its ablated version, ULTRAQUERY LP, against the best-reported baselines across 23 datasets.  The datasets are categorized into transductive, inductive (e), and inductive (e,r) groups.  ULTRAQUERY was trained on a single transductive dataset, while ULTRAQUERY LP only underwent pre-training for KG completion.  The table shows MRR and Hits@10 metrics for EPFO (average of 9 query types) and negation queries (average of 5 query types).  It highlights the differences in performance based on training methodology and thresholding techniques.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_14_2.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot inference performance of ULTRAQUERY and its ablated version (ULTRAQUERY LP) against the best-performing baselines on 23 different datasets.  It highlights the performance across various types of datasets (transductive, inductive (e), and inductive (e,r)), showcasing the effectiveness of ULTRAQUERY even without training on the target datasets. The table also shows the impact of score thresholding in ULTRAQUERY LP.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_14_3.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot performance of the ULTRAQUERY model and its ablated version (ULTRAQUERY LP) against state-of-the-art baselines across 23 datasets.  It breaks down the results by dataset type (transductive, inductive (e), and inductive (e,r)) and query type (EPFO average and negation average), showing mean reciprocal rank (MRR) and hits@10.  The training methodology for each model (ULTRAQUERY trained on FB15k237, ULTRAQUERY LP pre-trained only) and the baseline training methods are also specified to highlight the zero-shot nature of the ULTRAQUERY evaluation.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_16_1.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot inference performance of ULTRAQUERY and its ablated version (ULTRAQUERY LP) against the best-performing baselines on 23 datasets.  It highlights the performance across three dataset categories: transductive, inductive (e), and inductive (e,r).  The table shows that ULTRAQUERY, trained only on one dataset, achieves competitive or better performance than the baselines which are specifically trained on each dataset. It also illustrates the impact of score thresholding on ULTRAQUERY LP's performance.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}, {"figure_path": "JRSyMBBJi6/tables/tables_16_2.jpg", "caption": "Table 2: Zero-shot inference results of ULTRAQUERY and ablated ULTRAQUERY LP on 23 datasets compared to the best reported baselines. ULTRAQUERY was trained on one transductive FB15k237 dataset, ULTRAQUERY LP was only pre-trained on KG completion and uses scores thresholding. The no thrs. version does not use any thresholding of intermediate scores (Section 4.1). The best baselines are trainable on each transductive and inductive (e) dataset, and the non-parametric heuristic baseline on inductive (e, r) datasets.", "description": "This table presents a comparison of the zero-shot inference performance of ULTRAQUERY and its ablated version (ULTRAQUERY LP) against the best-performing baselines on 23 different datasets.  It highlights the performance on three dataset categories: transductive, inductive (e), and inductive (e,r).  The table shows MRR and Hits@10 scores for EPFO (average of 9 query types) and Negation (average of 5 query types) queries.  ULTRAQUERY was trained on a single transductive dataset (FB15k237), while ULTRAQUERY LP utilized a pre-trained model without further training. The table demonstrates the effectiveness of ULTRAQUERY's zero-shot generalization capabilities across diverse KG datasets.", "section": "5.2 Main Experiment: Zero-shot Query Answering"}]