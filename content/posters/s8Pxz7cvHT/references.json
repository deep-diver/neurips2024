{"references": [{"fullname_first_author": "C. Szegedy", "paper_title": "Intriguing properties of neural networks", "publication_date": "2014-XX-XX", "reason": "This paper is foundational for the field of adversarial attacks, introducing the concept and demonstrating their surprising effectiveness against neural networks."}, {"fullname_first_author": "I. Goodfellow", "paper_title": "Explaining and harnessing adversarial examples", "publication_date": "2015-XX-XX", "reason": "This paper significantly advanced the understanding of adversarial examples, providing both an explanation of their underlying mechanisms and techniques for generating them."}, {"fullname_first_author": "A. Madry", "paper_title": "Towards deep learning models resistant to adversarial attacks", "publication_date": "2018-XX-XX", "reason": "This work is highly influential due to its introduction of the now-standard Madry-style adversarial training and its comprehensive analysis of adversarial robustness."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-XX-XX", "reason": "This paper introduced a powerful framework for generative modeling based on diffusion processes, which has had a significant impact on various areas of AI, and is relevant to this work due to its use of diffusion models in adversarial attacks."}, {"fullname_first_author": "J. Song", "paper_title": "Denoising diffusion implicit models", "publication_date": "2020-XX-XX", "reason": "This paper offers an improvement over previous diffusion models, providing a more efficient and flexible framework which is used by this paper to design new attack methods."}]}