[{"figure_path": "zNIhPZnqhh/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of EM-based Clustering and the proposed Spike-based Bayesian Computation Methods for Event Decoupling.", "description": "This figure compares two methods for event decoupling: EM-based clustering and the proposed spike-based Bayesian computation. The EM-based clustering method uses an iterative algorithm to group events based on their likelihood of belonging to different motion models, while the spike-based Bayesian computation method uses a network of spiking neurons to perform Bayesian inference and decouple the event streams. The figure shows the steps involved in each method, including the assignment of events to clusters, the estimation of motion parameters, and the update of model parameters based on the data. The spike-based Bayesian computation method is shown to be more efficient and accurate than the EM-based clustering method.", "section": "1 Introduction"}, {"figure_path": "zNIhPZnqhh/figures/figures_4_1.jpg", "caption": "Figure 2: Architecture of the spike-based motion-segmentation network.", "description": "This figure shows the architecture of a spike-based motion segmentation network.  Event streams are input into the network, where each event is processed by a set of motion neurons (yj) that represent different motion models. The output of each motion neuron is then passed through a winner-take-all (WTA) circuit, which selects the most active neuron representing the dominant motion. This selection is further refined by a global inhibition neuron (H) that suppresses less-active neurons. Finally, the spike output from the WTA circuit represents the segmented motions.  The motion parameters (\u03b8j) for each motion model are updated through spike-timing-dependent plasticity (STDP).", "section": "4.1 Model Construction and Learning"}, {"figure_path": "zNIhPZnqhh/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of learning through STDP. (a). Learning curves of STDP for motion parameters \u03b8. (b). Optimization trajectory of parameters during STDP learning. The heat map shows the gradient of f (\u03b8) in Eq. 6 as motion parameters change.", "description": "This figure illustrates the learning process of STDP in the context of motion parameter optimization.  Panel (a) shows learning curves depicting how STDP adjusts motion parameters (\u03b8) over time. Panel (b) shows an optimization trajectory on a heatmap visualizing the gradient of the objective function (f(\u03b8)) across different parameter values, illustrating how STDP dynamically updates parameters to maximize contrast.", "section": "4 Spike-based Bayesian Computation for Motion Segmentation"}, {"figure_path": "zNIhPZnqhh/figures/figures_6_1.jpg", "caption": "Figure 4: Initialization of parameters \u03b8 through sampling parameters with the contrast of IWE as the objective function. (a). SVD components of parameters of different patches. (b). Sampling process of parameters of different patches. (c). Warping events with the best sampling parameters \u03b8*. ", "description": "This figure shows the initialization process of motion parameters \u03b8.  The contrast of the Image of Warped Events (IWE) is used as the objective function. The process involves dividing events into patches, sampling parameters for each patch using the Tree-structured Parzen Estimator (TPE), then using Singular Value Decomposition (SVD) to select the most significant parameters. Finally, events are warped using the best parameters.", "section": "5.1 Implementation Details"}, {"figure_path": "zNIhPZnqhh/figures/figures_8_1.jpg", "caption": "Figure 5: Examples of motion segmentation through the proposed spike-based EM models.", "description": "This figure shows the results of motion segmentation using the proposed spike-based Bayesian computation model.  The leftmost panel shows the raw event stream data in a three-dimensional representation (time, width, height). The top-middle panels display the warped event images (IWE) before any learning has occurred (i.e., initial state), representing the contrast of warped events in different motion models. The bottom-middle panels present the IWE after the network has learned, exhibiting a marked increase in contrast. This improved contrast facilitates better separation between events corresponding to different motion patterns. The rightmost panels visually illustrate the result of event segmentation, using different colors to represent events belonging to different motion models, both before and after the learning phase. The contrast enhancement resulting from the learning process is clearly observable, making the distinct motion components much more easily identified.", "section": "5.2 Evaluation on Event Motion Segmentation Datasets"}, {"figure_path": "zNIhPZnqhh/figures/figures_9_1.jpg", "caption": "Figure 6: Motion segmentation results for continuous event streams. Different colors represent the firing of different output neurons z of the proposed spike-based network.", "description": "This figure shows the results of motion segmentation for three different scenarios from the Extreme Event Dataset (EED).  Each row represents a different scene: 'What is background?', 'Occlusions', and 'Fast drone'. The leftmost column shows the accumulated events with polarity, illustrating the raw sensor input. The remaining columns display the motion segmentation results obtained by the proposed spike-based Bayesian computation framework. In each scene, the events are segmented into different motion components, each represented by a different color, illustrating the effectiveness of the proposed model in separating different motion patterns, even in challenging scenarios with complex backgrounds and occlusions.", "section": "5.2 Evaluation on Event Motion Segmentation Datasets"}, {"figure_path": "zNIhPZnqhh/figures/figures_12_1.jpg", "caption": "Figure S7: Explanation of Var(Ij). From left to right: events, IWEs of different motion patterns.", "description": "This figure shows the variance of the warped events (IWEs) for different motion patterns. The leftmost panel displays a 3D representation of an event stream in space-time, illustrating the distribution of events over time and space. The middle and right panels show heatmaps of the IWEs for two different motion models. The IWE with higher variance (582.87) corresponds to the correct motion model, which concentrates the event distribution along object edges, producing sharper object boundaries. In contrast, the IWE with lower variance (55.18) corresponds to an incorrect motion model, where the event distribution is dispersed, resulting in blurred boundaries. The variances of the IWEs serve as a measure of the model's accuracy in separating the event streams according to the underlying motion patterns.", "section": "Appendix"}, {"figure_path": "zNIhPZnqhh/figures/figures_13_1.jpg", "caption": "Figure 4: Initialization of parameters \u03b8 through sampling parameters with the contrast of IWE as the objective function. (a). SVD components of parameters of different patches. (b). Sampling process of parameters of different patches. (c). Warping events with the best sampling parameters \u03b8*. ", "description": "This figure shows the initialization process of motion parameters \u03b8 in the proposed spike-based Bayesian computation framework for event segmentation.  It uses a combination of random sampling and Bayesian optimization (Tree-structured Parzen Estimator or TPE) to search for parameters that maximize the contrast of the Image of Warped Events (IWE).  Subsequently, Singular Value Decomposition (SVD) is applied to the obtained parameter set to select the most significant ones for initialization, thereby ensuring efficient and effective parameter initialization for the network. The subfigures (a), (b), and (c) illustrate the SVD components, sampling process, and warping results, respectively.", "section": "5.1 Implementation Details"}]