[{"figure_path": "hdUCZiMkFO/figures/figures_1_1.jpg", "caption": "Figure 1: The diagram of Continual Generalized Category Discovery (C-GCD). In this paper, we focus on a more pragmatic setting with (1) more continual stages and more novel categories, (2) rehearsal-free learning, and (3) no prior knowledge of the ratio of new class samples.", "description": "This figure illustrates the process of Continual Generalized Category Discovery (C-GCD). It starts with an initial training phase using labeled data (Stage-0).  Subsequent stages involve incremental learning from unlabeled data containing both previously seen ('old') and unseen ('new') classes (Stages 1-T). The key aspect highlighted is that the model does not retain past data samples and has to learn continuously.  The figure emphasizes that the number of new classes increases over stages and that there's no prior knowledge about the proportion of old and new class samples in each stage.", "section": "1 Introduction"}, {"figure_path": "hdUCZiMkFO/figures/figures_3_1.jpg", "caption": "Figure 2: Preliminary results. We identify two issues and underlying causes, including (a) Issue 1: performance gap between old and new classes, caused by (b) Reason 1: model's overconfidence in old classes, i.e., prediction bias. (c) Issue 2: accuracy fluctuations in new class across various stages, caused by (d) Reason 2: different categories have varying levels of difficulty, i.e., hardness bias.", "description": "This figure presents preliminary experimental results that reveal two key issues in continual generalized category discovery (C-GCD): prediction bias and hardness bias.  (a) shows a significant performance gap between accuracy on old and new classes. (b) illustrates that this is due to the model being overconfident in its predictions for old classes (prediction bias). (c) highlights accuracy fluctuations for new classes across multiple stages. (d) explains this is caused by varying difficulty levels across different classes (hardness bias). These findings motivate the proposed debiased learning framework in the paper.", "section": "3.2 Preliminary Experiments: Two Bias Problems"}, {"figure_path": "hdUCZiMkFO/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of the proposed Happy framework. Top: Overall learning pipeline for continual stages. Bottom Left: Clustering-guided Initialization, together with Soft Entropy Regularization (Section 4.2) ensures effective novel class category. Bottom Right: Hardness-aware Prototype Sampling (Section 4.3) remarkably mitigates catastrophic forgetting of old classes.", "description": "This figure illustrates the Happy framework, a debiased learning framework for continual generalized category discovery. The top part shows the overall learning pipeline, while the bottom left focuses on clustering-guided initialization and soft entropy regularization for effective novel class discovery. The bottom right details hardness-aware prototype sampling to mitigate catastrophic forgetting of old classes.", "section": "4 The Proposed Framework: Happy"}, {"figure_path": "hdUCZiMkFO/figures/figures_8_1.jpg", "caption": "Figure 3: Illustration of the proposed Happy framework. Top: Overall learning pipeline for continual stages. Bottom Left: Clustering-guided Initialization, together with Soft Entropy Regularization (Section 4.2) ensures effective novel class category. Bottom Right: Hardness-aware Prototype Sampling (Section 4.3) remarkably mitigates catastrophic forgetting of old classes.", "description": "This figure illustrates the Happy framework, which is a debiased learning framework for continual generalized category discovery.  It shows the overall pipeline, which consists of initial supervised training and continual unsupervised discovery.  The figure highlights two key components of the framework: clustering-guided initialization with soft entropy regularization to discover new classes, and hardness-aware prototype sampling to mitigate forgetting of old classes.  The diagram visually explains how these components work together to address prediction bias and hardness bias in the continual learning setting.", "section": "4 The Proposed Framework: Happy"}, {"figure_path": "hdUCZiMkFO/figures/figures_16_1.jpg", "caption": "Figure 7: Confidence gap of various metrics between old and new classes of baseline models.", "description": "This figure displays the distribution of confidence scores for old and new classes, using four different metrics: Max Softmax Probability, Max Logit, Margin, and Negative Entropy.  The distributions highlight a significant difference in confidence scores between old (previously seen) and new classes, indicating a prediction bias towards old classes.  This bias is visualized in each of the four subplots and underscores the challenges addressed by the Happy framework in the paper.", "section": "D Metrics of C-GCD"}, {"figure_path": "hdUCZiMkFO/figures/figures_17_1.jpg", "caption": "Figure 8: All accuracy on 15 unseen shifted distributions of CIFAR100-C with severity=2. 10-stage C-GCD on CIFAR100 and TinyImageNet, as shown in Table 9 and Table 10. Our method still consistently outperforms others over the whole course of continual stages.", "description": "This figure shows the accuracy of three different continual learning methods (VanillaGCD, MetaGCD, and Happy) across 15 different unseen shifted distributions of the CIFAR100-C dataset.  The severity level is set to 2.  The results demonstrate that the Happy method consistently outperforms the other two methods across all 15 distributions, even over a longer duration (10 stages) of continual learning. This highlights Happy's robustness and generalization capabilities in handling unseen data distributions.", "section": "5 Experiments"}]