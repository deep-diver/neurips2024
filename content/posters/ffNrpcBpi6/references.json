{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-01", "reason": "This paper introduces the Transformer architecture, the foundation of the models studied in the current paper."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019-06-01", "reason": "BERT is one of the main transformer models used for the experiments in the current paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "publication_date": "2019-09-01", "reason": "This paper introduces GPT-2, another key transformer model used for experiments in this paper."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Training data-efficient image transformers & distillation through attention", "publication_date": "2021-07-01", "reason": "DeiT, a vision transformer model based on this paper, is used for experiments in the current paper."}, {"fullname_first_author": "Ze Liu", "paper_title": "Swin Transformer: Hierarchical vision transformer using shifted windows", "publication_date": "2021-10-01", "reason": "Swin Transformer, a vision transformer model based on this paper, is used for experiments in the current paper."}]}