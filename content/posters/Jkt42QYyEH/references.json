{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "This paper introduces NeRF, a foundational work in neural radiance fields that has heavily influenced the field and is directly relevant to LiveScene's approach."}, {"fullname_first_author": "Kacper Kania", "paper_title": "Conerf: Controllable neural radiance fields", "publication_date": "2022-01-01", "reason": "Conerf directly addresses the challenge of controllable scene reconstruction, a key aspect of LiveScene, providing a crucial foundation for the work presented."}, {"fullname_first_author": "Sara Fridovich-Keil", "paper_title": "K-Planes: Explicit radiance fields in space, time, and appearance", "publication_date": "2023-01-01", "reason": "K-Planes introduces an efficient representation for dynamic scenes by using explicit planes, influencing the design of LiveScene's multi-scale interaction space factorization."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-07-01", "reason": "This paper introduces a novel rendering technique using 3D Gaussians, a method adopted and improved in LiveScene for efficient rendering and scene reconstruction."}, {"fullname_first_author": "Justin Kerr", "paper_title": "Lerf: Language embedded radiance fields", "publication_date": "2023-01-01", "reason": "LERF integrates language into neural radiance fields, a critical component that LiveScene expands upon for scene-level language grounding and control."}]}