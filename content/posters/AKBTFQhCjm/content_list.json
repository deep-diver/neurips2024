[{"type": "text", "text": "DEFT: Efficient Fine-Tuning of Diffusion Models by Learning the Generalised $h$ -transform ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Alexander Denker\u2217 University College London a.denker@ucl.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Francisco Vargas\\* University of Cambridge fav25@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Shreyas Padhy\\* University of Cambridge sp2058@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Kieran Didi\\* University of Cambridge ked48@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Simon Mathis\\* University of Cambridge svm34@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Vincent Dutordoir University of Cambridge vd309@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Riccardo Barbano Atinary Technologies rbarbano@atinary.com ", "page_idx": 0}, {"type": "text", "text": "Emile Mathieu University of Cambridge ebm32@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Urszula Julia Komorowska University of Cambridge ujk21@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Pietro Lio University of Cambridge pl219@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Generative modelling paradigms based on denoising diffusion processes have emerged as a leading candidate for conditional sampling in inverse problems. In many real-world applications, we often have access to large, expensively trained unconditional diffusion models, which we aim to exploit for improving conditional sampling. Most recent approaches are motivated heuristically and lack a unifying framework, obscuring connections between them. Further, they often suffer from issues such as being very sensitive to hyperparameters, being expensive to train or needing access to weights hidden behind a closed API. In this work, we unify conditional training and sampling using the mathematically well-understood Doob\u2019s $h$ -transform. This new perspective allows us to unify many existing methods under a common umbrella. Under this framework, we propose DEFT (Doob\u2019s $h$ -transform Efficient FineTuning), a new approach for conditional generation that simply fine-tunes a very small network to quickly learn the conditional $h$ -transform, while keeping the larger unconditional network unchanged. DEFT is much faster than existing baselines while achieving state-of-the-art performance across a variety of linear and non-linear benchmarks. On image reconstruction tasks, we achieve speedups of up to $1.6\\times$ , while having the best perceptual quality on natural images and reconstruction performance on medical images. Further, we also provide initial experiments on protein motif scaffolding and outperform reconstruction guidance methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Denoising diffusion models are a powerful class of generative models where noise is gradually added to data samples until they converge to pure noise. The time reversal of this noising process then allows noise to be transformed into samples. This process has been widely successful in generating high-quality images [28] and has more recently shown promise in designing protein backbones that have been validated in experimental protein design workflows [77]. Recently, there has been much interest in conditioning the time reversal process, in order to generate samples that are subject to an observed condition. Conditional sampling requires the posterior score $\\nabla_{x}\\ln p_{t}(x|Y=y)$ , given some observation $\\textit{\\textbf{y}}$ . As diffusion models typically approximate the score of the underlying distribution, i.e., $s_{t}^{\\theta^{*}}({\\pmb x})\\approx\\nabla_{\\pmb{x}}\\ln p_{t}({\\pmb x})$ , a pre-trained diffusion model can be leveraged using Bayes\u2019 theorem ", "page_idx": 0}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/05552e7e032bcaeb170c7f2ef3cc3b2cf372f8ed563105e2d41253c5af32f02f.jpg", "img_caption": ["Figure 1: DEFT reverse diffusion setup. The pre-trained unconditional diffusion model $s_{t}^{\\theta}$ and the fine-tuned $h_{-}$ -transform $h_{t}^{\\phi}$ are combined at every sampling step. We propose a special network to parametrise the $h$ -transform including the guidance term $\\nabla_{\\hat{\\pmb{x}}_{0}}\\ln p(\\pmb{y}|\\hat{\\pmb{x}}_{0})$ as part of the architecture. Here $\\hat{\\pmb{x}}_{0}$ denotes the unconditional denoised estimate given $s_{t}^{\\theta}(\\mathbf{x}_{t})$ . During training, we only need to fine-tune $h_{t}^{\\phi}$ (usually $4{-}9\\%$ the size of $s_{t}^{\\theta}$ ) using a small dataset of paired measurements, keeping $s_{\\theta}^{t}$ fixed. During sampling, we do not need to backpropagate through either model, resulting in speed-ups during evaluation. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\n\\nabla_{x}\\ln{p_{t}(x|Y=y)}\\approx s_{t}^{\\theta^{*}}(x)+\\nabla_{x}\\ln{p_{t}(Y=y|x)},\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "to approximate the posterior score. The time-dependent likelihood $\\nabla_{x}\\ln{p_{t}(\\pmb{Y}=\\pmb{y}|x)}$ is often termed guidance due to its interpretation to guide the reverse process to the conditioned inputs, and is unfortunately analytically intractable. To tackle this problem, several approximations for the guidance have been proposed; see, for example, [12, 22, 29, 56, 65, 69] and further discussion in Appendix B. Instead of relying on the decomposition (1), another line of work aims to learn the posterior score directly [5, 27], which requires expensive training for new conditional sampling tasks, and access to large amounts of paired data points. ", "page_idx": 1}, {"type": "text", "text": "In the setting of conditional generation with diffusion models, our primary goal is to leverage large pre-trained foundation models which are prevalent in applications, but which typical front-end users are not able to backpropagate through, making approaches like [12, 22] infeasible. This might be due to their prohibitive computation times or because they lie behind an API preventing the usage of autodiff frameworks. ", "page_idx": 1}, {"type": "text", "text": "In this work, we propose a unified framework for conditional generation using Doob\u2019s $h$ -transform, a well-known result in the stochastic differential equations (SDE) literature [14, 55, 61, 78]. Under this framework, we propose DEFT (Doob\u2019s h-transform Efficient FineTuning), an algorithm that estimates the time-dependent likelihood directly from data, i.e., $h^{*}=\\nabla_{\\pmb{x}}\\ln p_{t}(\\pmb{Y}=\\pmb{y}|\\pmb{x})$ , while being able to leverage an existing pre-trained unconditional model. We learn the guidance term $h$ -transform) efficiently using 1) smaller networks, and 2) a small training dataset of paired data points and corresponding observations. Furthermore, through connections to stochastic control, we propose a novel network architecture for general-purpose fine-tuning, which, in conjunction with our proposed loss, achieves competitive results across a series of inverse problems in imaging and protein design, while having a much lower computational cost. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2 Conditioning diffusions via the $h$ -transform ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we explore the formal mechanism to condition the boundary points of an SDE mathematically, and connect it to existing methodologies for conditioning diffusions in generative modelling. For a more rigorous background to denoising diffusion models, see Appendix A. Let us first recap the score-based generative modelling framework of [68]; we start with a forward SDE, which progressively transforms the target distribution ${\\mathcal P}_{0}$ (e.g. $\\mathcal{P}_{0}=p_{\\mathrm{data}})$ ) ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{d}X_{t}=f_{t}(\\mathbf{{X}}_{t})\\,\\mathrm{d}t+\\sigma_{t}\\overline{{\\mathrm{d}\\mathbf{W}_{t}}},\\quad X_{0}\\sim\\mathcal{P}_{0},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with drift $f_{t}$ and diffusion $\\sigma_{t}$ . Under some regular assumptions, there exists a corresponding reverse SDE with corresponding drift $\\bar{b}_{t}$ [2], that allows us to take samples from $\\mathcal{P}_{T}$ (typically $\\mathcal{N}(0,\\mathbf{I}))$ and denoise them to generate samples from $\\mathcal{P}_{0}$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}X_{t}=\\left(f_{t}(X_{t})-\\sigma_{t}^{2}\\nabla_{X_{t}}\\ln p_{t}(X_{t})\\right)\\,\\mathrm{d}t+\\sigma_{t}\\mathrm{d}\\mathbf{W}_{t},\\quad X_{T}\\sim\\mathcal{P}_{T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the time flows backwards, and $\\bar{b}_{t}\\,=\\,f_{t}(\\mathbf{X}_{t})-\\sigma_{t}^{2}\\nabla_{\\mathbf{X}_{t}}\\ln{p_{t}(\\mathbf{X}_{t})}$ . The goal of conditional sampling is to condition the reverse SDE on a particular observation, i.e., to produce samples that satisfy constraints. For example, we might want to use (3) to generate samples where we already know some dimensions of the sample (e.g. knowing some pixels of the image a-priori in image inpainting). Doob\u2019s $h$ -transform [55, 14] provides a formal mechanism for conditioning an SDE to hit an event at a given time. We will show that existing methods for conditional generative modelling arise as approximate instances of this proposed framework. Formally, we have: ", "page_idx": 2}, {"type": "text", "text": "Proposition 2.1. (Doob\u2019s $h$ -transform [55]) Consider the reverse SDE in Eqn. (3). The conditioned process $X_{t}|X_{0}\\in B$ is a solution of ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}H_{t}=\\left(\\Bar{b}_{t}(H_{t})-\\sigma_{t}^{2}\\;\\nabla_{H_{t}}\\ln\\Bar{p}_{0|t}(X_{0}\\in B|H_{t})\\;\\right)\\,\\mathrm{d}t+\\sigma_{t}\\mathrm{d}\\overline{{\\mathbf{W}}}_{t},\\quad H_{T}\\sim\\mathcal{P}_{T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with a backward drift $\\bar{b}_{t}({\\pmb H}_{t})\\ =\\ \\ f_{t}({\\pmb H}_{t})\\ -\\ \\sigma_{t}^{2}\\nabla_{{\\pmb H}_{t}}\\ln p_{t}({\\pmb H}_{t}),$ , such that Law $\\begin{array}{r l}{(\\boldsymbol{H_{s}}|\\boldsymbol{H_{t}})}&{=}\\end{array}$ $\\vec{p}_{s|t,0}(\\mathbf{\\boldsymbol{x}}_{s}|\\mathbf{\\boldsymbol{x}}_{t},\\mathbf{\\boldsymbol{x}}_{0}\\in B)$ and $\\mathbb{P}(X_{0}\\in B)=1$ . ", "page_idx": 2}, {"type": "text", "text": "Note, that we will refer to the conditional process with $H_{t}$ and to the unconditional process with $X_{t}$ . Doob\u2019s $h$ -transform shows that by conditioning a diffusion process to hit a particular event $X_{0}\\in B$ at a boundary time, the resulting conditional process is itself an SDE with an additional drift term (shown in the blue box above). Furthermore, the resulting SDE will hit the specified event within a finite time $T$ . The function $h(t,H_{t})\\triangleq\\overleftarrow{P}_{0\\mid t}(X_{0}\\in B\\mid\\overbar{H_{t}})$ is referred to as the $h$ -transform [55, 14]. See also Appendix C.3 for a discussion about the connection to reconstruction guidance methods. ", "page_idx": 2}, {"type": "text", "text": "Rather than conditioning an SDE on a deterministic event, one is often interested in a posterior arising from noisy observations (e.g. noisy inverse problems) ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Y=\\mathrm{noisy}(\\mathcal{A}(X_{0})),\\ X_{0}\\sim p_{\\mathrm{data}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\boldsymbol{\\mathcal{A}}$ is a forward operator, \u201cnoisy\u201d describes a noise process and unlike the classical $h$ -transform, we are not enforcing a deterministic condition such as $A(X_{0})=Y$ . We typically assume we can evaluate and sample from the likelihood $p(\\pmb{y}|\\pmb{X}=\\pmb{x}_{0})$ ). Our goal is to sample from the posterior $p({\\pmb x}_{0}|{\\pmb Y}\\,=\\,{\\pmb y})\\,=\\,p({\\pmb y}|{\\pmb x}_{0})p_{\\mathrm{data}}({\\pmb x}_{0})/p({\\pmb y})$ . Sampling from the posterior $\\bar{p}(x_{0}|\\pmb{Y}\\;=\\;\\bar{y})$ can be achieved by a generalisation of the $h$ -transform that build on results in [75], given as follows: ", "page_idx": 2}, {"type": "text", "text": "Proposition 2.2. (Generalised $h$ -transform) Given the following backwards SDE with marginals $p_{t}$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{X}_{t}=\\bar{b}_{t}(\\mathbf{X}_{t})\\,\\mathrm{d}t+\\sigma_{t}\\,\\mathrm{\\overbar{\\mathrm{d}}}\\mathbf{W}_{t},\\quad\\mathbf{X}_{T}\\sim\\mathbb{P}_{T},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "then it follows that the backward $S D E$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\pmb{H}_{T}\\sim Q_{T}^{f_{t}}[p(\\pmb{x}_{0}|\\pmb{y})]=\\int\\vec{p}_{T|0}(\\pmb{x}|\\pmb{x}_{0})p(\\pmb{x}_{0}|\\pmb{y})\\mathrm{d}\\pmb{x}_{0}}\\\\ &{\\mathrm{d}\\pmb{H}_{t}=\\left(\\breve{b}_{t}(\\pmb{H}_{t})-\\sigma_{t}^{2}\\,\\nabla_{\\pmb{H}_{t}}\\ln p_{y|t}(\\pmb{Y}=\\pmb{y}|\\pmb{H}_{t})\\,\\right)\\,\\mathrm{d}t+\\sigma_{t}\\,\\overleftarrow{\\mathrm{d}\\pmb{W}}_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "satisfies Law $(H_{0})\\,=\\,p({\\pmb x}_{0}|{\\pmb Y}\\,=\\,{\\pmb y})$ with $\\begin{array}{r}{p_{y|t}(Y\\,=\\,y|\\cdot)\\,=\\,\\int p(Y\\,=\\,y|x_{0})\\bar{p}_{0|t}(x_{0}|\\cdot)\\mathrm{d}x_{0}}\\end{array}$ . We recover guidance based diffusions via $\\tilde{b}_{t}(\\pmb{H}_{t})=f_{t}(\\pmb{H}_{t})-\\sigma_{t}^{2}\\nabla_{\\pmb{H}_{t}}\\ln p_{t}(\\pmb{H}_{t})$ . ", "page_idx": 3}, {"type": "text", "text": "Here $\\begin{array}{r}{Q_{T}^{f_{t}}[\\pi(\\mathbf{x}_{0})]=\\int\\vec{p}_{T|0}(\\pmb{x}|\\pmb{x}_{0})\\pi(\\pmb{x}_{0})\\mathrm{d}\\pmb{x}_{0}}\\end{array}$ is the transition operator of the forward process. Note, that the initial distribution $Q_{T}^{f_{t}}[p(x_{0}|\\pmb{y})]$ of the controlled SDE differs from the unconditional SDE. However, in Proposition G.2 we show that for the VP-SDE the difference between them gets exponentially small for increasing $T$ . To summarise, the above result gives a generalisation of the $h$ -transform that allows sampling from posteriors; notice that it recovers the traditional $h$ -transform in the no-noise setting. Whilst this more general formulation of the $h$ -transform has been explored in unconditional generative modelling [78], this is the first work to cast conditional generative modelling in this light. We refer to the term in blue as the generalised $h$ -transform henceforth. ", "page_idx": 3}, {"type": "text", "text": "Proposition 2.2 provides theoretical backing to methodologies such as DPS [12] or \u03a0GDM [65], in which the reverse SDE (7) is used to solve noisy inverse problems. For a careful derivation of Proposition 2.2 see Appendix D. While prior works have explored using Bayes\u2019 rule to decompose the conditional score, we provide rigorous arguments for intermediate steps, and carefully formalise the connection between conditional generative modelling and the $h$ -transform, providing a concise result. This framework is flexible enough to also encompass prior work on conditional score matching, see e.g., [5, 27], and the discussion Appendix H. ", "page_idx": 3}, {"type": "text", "text": "3 Learning the generalised $h$ -transform ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Prior works either learn the posterior score from scratch, see e.g. [5, 27], or use approximations to the generalised $h$ -transform, see e.g. [12, 32]. Instead, we propose a method to learn the generalised $h$ -transform. We refer to this process as fine-tuning, as the pre-trained unconditional network remains unchanged and only the approximation to the generalised $h$ -transform is learned. Our main result is given in the following theorem, where we give several representations of the generalised $h$ -transform. ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.1. (Representations of conditional SDE sampling) For a given ${\\pmb y}\\sim n o i s y({\\cal A}({\\pmb x}_{0})),$ , let $\\mathbb{Q}$ be the path measure of the conditional SDE ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{d}H_{t}=\\left(f_{t}(H_{t})-\\sigma_{t}^{2}\\left(\\nabla_{H_{t}}\\ln p_{t}(H_{t})+h_{t}(H_{t})\\right)\\right)\\mathrm{d}t+\\sigma_{t}\\mathrm{~d}\\mathbf{W}_{t},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $H_{T}\\sim Q_{T}^{f_{t}}[p(x_{0}|\\pmb{y})]$ . The generalised $h$ -transforms admits the following representations: ", "page_idx": 3}, {"type": "text", "text": "1) The path measure induced by the $h$ -transformed SDE satisfies $\\begin{array}{r}{\\mathrm{d}\\mathbb{Q}^{*}=\\mathrm{d}\\mathbb{P}\\frac{\\mathrm{d}p(\\pmb{x}_{0}|\\pmb{y})}{\\mathrm{d}\\mathbb{P}_{0}}}\\end{array}$ , where $\\mathbb{P}$ is the path measure of the unconditioned $S D E$ and $\\mathbb{P}_{0}$ is it\u2019s time 0 marginal. ", "page_idx": 3}, {"type": "text", "text": "2) The $h$ -transform admits a denoising score matching representation ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h^{*}=\\underset{h\\in\\mathcal{H}}{\\arg\\operatorname*{min}}\\,\\mathcal{L}_{S M}^{y}(h)}\\\\ &{\\quad\\mathcal{L}_{S M}^{y}(h):=\\underset{X_{0}\\sim p(x_{0}\\mid y)}{\\mathbb{E}}\\quad\\bigg[\\bigg\\|\\big(h_{t}(H_{t})\\!+\\!\\nabla_{H_{t}}\\ln p_{t}(H_{t})\\big)\\!-\\!\\nabla_{H_{t}}\\ln\\vec{p}_{t\\mid0}(H_{t}|X_{0})\\bigg\\|^{2}\\bigg]}\\\\ &{\\quad\\quad\\quad\\quad t\\sim\\!\\mathrm{U}(0,T),H_{t}\\!\\sim\\!p_{t\\mid0}(x_{t}|x_{0})}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "3) The $h$ -transform admits the following stochastic control formulation ", "page_idx": 3}, {"type": "equation", "text": "$$\nh^{*}=\\mathop{\\mathrm{arg\\,min}}_{h\\in\\mathcal{H}}\\left\\{\\mathcal{L}_{S C}^{y}(h):=\\mathbb{E}_{\\mathbb{Q}}\\left[\\frac{1}{2}\\int_{0}^{T}\\sigma_{t}^{2}||h(H_{t})||^{2}\\mathop{\\mathrm{d}t}\\right]-\\mathbb{E}_{H_{0}\\sim\\mathbb{Q}_{0}}[\\ln p(y|H_{0})]\\right\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbb{Q}$ is the path measure for the conditional SDE being controlled. ", "page_idx": 3}, {"type": "text", "text": "4) The path measure induced by the $h$ -tranformed SDE solves the a Schr\u00f6dinger bridge problem with boundary conditions $\\mathbb{Q}_{0}=Q_{T}^{f_{t}}[p(\\pmb{x}_{0}|\\pmb{y})]\\approx\\mathcal{N}(0,I),$ , $\\mathbb{Q}_{T}=p(\\pmb{x}_{0}|\\pmb{y})$ and with the unconditional process $\\mathbb{P}$ as its reference. ", "page_idx": 3}, {"type": "text", "text": "Here, 4) and 1) follow directly from [7, 73]. For the proof 2) see Appendix D.2 and for 3) see Appendix G. Under appropriate conditions on the likelihood, the space of admissible controls $\\mathcal{H}$ ", "page_idx": 3}, {"type": "text", "text": "can be taken to be the set of $C_{1}$ -vector fields with linear growth in space; see [48]. In the following sections, we will discuss the representations in 2) and 3) in more detail. ", "page_idx": 4}, {"type": "text", "text": "3.1 DEFT: Fine-tuning by score matching ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The score matching objective in Theorem 3.1 2) offers a simulation-free loss function to estimate the generalised $h$ -transform. While the theorem\u2019s formulation focuses on learning the $h$ -transform for a specific measurement $\\textit{\\textbf{y}}$ , this loss function can naturally be extended and amortized over the full range of measurements, i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{h\\in\\mathcal{H}}\\mathbb{E}_{\\boldsymbol{y}\\sim\\boldsymbol{Y}}[\\mathcal{L}_{\\mathrm{SM}}^{\\boldsymbol{y}}(h)],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "to obtain $h_{t}^{*}(\\pmb{x},\\pmb{y})\\,=\\,\\nabla_{\\pmb{x}}\\ln p_{t}(\\pmb{y}|\\pmb{x})$ . Further, for settings where the operator may vary, we can additionally amortise over the forward operator $A\\sim p$ and learn $h_{t}^{\\ast}(\\pmb{x},\\pmb{\\bar{y}},\\pmb{\\mathcal{A}})=\\nabla_{\\pmb{x}}\\ln p_{t}^{\\prime}(\\pmb{y}|\\pmb{x},\\pmb{\\mathcal{A}})$ . We exploit this to amortise over inpainting masks, see Section 4.1, and motif scaffolding, see Section 4.3. For the DDPM [28] discretisation of the SDE and a pre-trained epsilon matching model $\\epsilon_{t}^{\\theta^{*}}$ , the fine-tuning objective (9) reduces to ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\phi}\\mathbb{E}_{(X_{0},Y),\\epsilon,t}\\left[\\|\\big(h_{t}^{\\phi}(H_{t},Y)+\\epsilon_{t}^{\\theta^{*}}(H_{t})\\big)-\\epsilon\\|^{2}\\right],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "with ${H_{t}}=\\sqrt{{{\\bar{\\alpha}}_{t}}}{X_{0}}+\\sqrt{1-{{\\bar{\\alpha}}_{t}}}\\epsilon$ , $(X_{0},Y)\\sim p(\\pmb{x}_{0},\\pmb{y}),\\epsilon\\sim\\mathcal{N}(0,\\mathbf{I})$ , where $h_{t}^{\\phi}$ represents the neural network used to approximate the generalised $h$ -transform. Note that the loss function (10) only requires evaluation of the pre-trained model, without needing to backpropagate through the weights $\\theta^{*}$ , which is often quite expensive and sometimes impossible in closed APIs. Training under the DDPM discretisation can be performed according to Algorithm 5. Sampling with DEFT is further explained in Algorithm 6, and pictorially represented in Figure 1. As an additional insight into the behaviour of the $h$ -transform that makes it more flexible and capable of modelling non-linear tasks than standard reconstruction guidance methods, we show that the $h$ -transform can be interpreted as a correction term for the Tweedie estimate [20]. We can express the conditional Tweedie\u2019s estimate as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[x_{0}|x_{t},y]\\approx\\hat{x}_{0}(x_{t},y)}\\\\ &{\\qquad\\qquad=\\frac{x_{t}-\\sqrt{1-\\bar{\\alpha}_{t}}\\,\\Big(h_{t}^{\\phi^{*}}(x_{t},y)+\\epsilon_{t}^{\\theta^{*}}(x_{t})\\Big)}{\\sqrt{\\bar{\\alpha}_{t}}}=\\hat{x}_{0}(x_{t})-\\frac{\\sqrt{1-\\bar{\\alpha}_{t}}}{\\sqrt{\\bar{\\alpha}_{t}}}h_{t}^{\\phi^{*}}(x_{t},y),}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\hat{\\pmb{x}}_{0}(\\pmb{x}_{t})$ is the unconditional Tweedie estimate. Equation (11) highlights that the $h$ -transform can also be interpreted as a correction factor to the unconditional denoised estimate, similar to [52, 80]. ", "page_idx": 4}, {"type": "text", "text": "3.2 Connections to variational inference and stochastic control ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "A limitation to the fine-tuning objective with DEFT is that it requires a small dataset of paired datapoints and measurements. In this section, we propose an alternative approach by expressing the solution to the conditional sampling problem as a stochastic optimal control objective, which is highlighted in Theorem 3.1 3). This allows us to learn the $h$ -transform by optimising a variational inference-type problem. Importantly, this stochastic control objective only requires the availability of a single noisy observation $\\textit{\\textbf{y}}$ instead of a paired fine-tuning dataset. Further, the stochastic control objective can even be used in other conditional sampling tasks, for example in reward tilted distributions, i.e. where the goal is to sample from $\\pi(\\pmb{x})\\propto e^{r(\\pmb{x})}p_{\\mathrm{data}}(\\pmb{x})$ . Here $e^{r(\\pmb{x})}$ serves the same purpose as the likelihood, but there is no explicit measurement $\\textit{\\textbf{y}}$ [18]. ", "page_idx": 4}, {"type": "text", "text": "However, the stochastic control objective is not directly applicable for high-dimensional training, as the complete chain $\\{H_{t}\\}_{t}$ must be kept in memory and backpropagated through or adjoint methods have to be used [36]. In Appendix G.3, we discuss several alternatives and present experiments for scaling up the above objective, e.g., methods like VarGrad [53]. VarGrad allows to detach the trajectory from the gradient computation, drastically reducing the memory footprint. Further, we discuss concurrent work in G.1 and G.2. The stochastic control objective serves as a conceptual bridge between sampling from unnormalised densities using diffusion models [74, 75, 81] and conditional score-based generative modelling. ", "page_idx": 4}, {"type": "text", "text": "3.3 Likelihood-informed inductive bias ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "If the likelihood is differentiable, we can impose an inductive bias on the $h$ -transform approximation. Specifically, the generalized $h$ -transform can be expressed as an expectation, and we can apply the DPS approximation [12] as follows ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\nabla_{x_{t}}\\ln p_{y|t}(y|x_{t})=\\nabla_{x_{t}}\\ln\\mathbb{E}_{x_{0}\\sim p(x_{0}|x_{t})}[p(y|x_{0})]\\approx\\nabla_{x_{t}}\\ln p(y|\\mathbb{E}[\\hat{x}_{0}|x_{t}])}\\\\ &{}&{\\approx\\nabla_{x_{t}}\\ln p(y|\\hat{x}_{0}(x_{t})),\\ \\ \\ }\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where we use Tweedie\u2019s estimate based on the pre-trained unconditional diffusion model in the last step. The DPS approximation has been validated in many different conditional sampling tasks, so it would make for a good initialisation of the learned $h$ -transform. However, the DPS approximation requires the Jacobian of the unconditional model, which is expensive to compute and known to be poorly conditioned. Further, in applications where we only have access to the forward pass of the unconditional model, the Jacobian is infeasible to compute. Similar to [50], we found that omitting this term still leads to an expressive architecture, while greatly reducing the computational cost. Thus, we propose the following network architecture ", "page_idx": 5}, {"type": "equation", "text": "$$\nh_{t}^{\\phi}(x_{t},y)=\\mathrm{NN}_{1}^{\\phi}(x_{t},\\hat{x}_{0}(x_{t}),\\nabla_{\\hat{x}_{0}}\\ln p(y|\\hat{x}_{0}(x_{t})),t)+\\mathrm{NN}_{2}^{\\phi}(t)\\nabla_{\\hat{x}_{0}}\\ln p(y|\\hat{x}_{0}(x_{t})),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "to parametrise the $h$ -transform, where the last layer of $\\mathbf{NN}_{1}^{\\phi}$ is initialised with 0 and $\\mathbf{NN}_{2}^{\\phi}$ is initialised to output 1. This initialisation provides a computationally efficient approximation to the $h$ -transform, which still guides the sampling. ", "page_idx": 5}, {"type": "text", "text": "This type of network architecture has been proposed within the sampling community to apply diffusion models to normalising constant estimation [49, 74, 81]. The theoretical connection to stochastic control in Section 3.2, motivates us further to adapt the architectures from the sampling field to the conditional generative modelling setting. We ablate the different components of our proposed architecture in Appendix F.1 and find that the additional components greatly improve performance empirically. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We evaluate the DEFT framework from Section 3.1 on both linear and non-linear natural and medical image reconstruction tasks, as well as the motif scaffolding problem in protein design. Further, in Appendix H.2 we provide a comparison of the conditional training framework with DEFT on the FLOWERS [47] image dataset. We provide our code https://github.com/alexdenker/DEFT. ", "page_idx": 5}, {"type": "text", "text": "4.1 Image reconstruction ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We test a wide variety of both linear and non-linear image reconstruction tasks on the $256\\times256\\mathrm{px}$ ImageNet dataset [58]. We make use of a pre-trained unconditional diffusion model with $\\sim500\\mathrm{M}$ parameters $[16]^{2}$ . We perform all our evaluations on a $1k$ subset of the validation $\\mathrm{set}^{3}$ . For all inverse problems under consideration, the $h$ -transform was trained on a separate 1k subset of the validation set. For linear inverse problems, we compare against \u03a0GDM [65], DDRM [32], DPS [12] and RED-diff [44]. Additionally, we evaluate $\\mathrm{\\Delta}\\hat{\\mathrm{I}}^{2}\\mathrm{SB}$ [39]. The performance of $\\mathrm{I}^{2}\\mathrm{SB}$ can be seen as an upper-bound to DEFT, as it is a conditional diffusion trained on the complete ImageNet dataset. For non-linear tasks, we only compare against DPS and RED-diff as both \u03a0GDM and DDRM are not directly applicable to non-linear forward operators. For DEFT we make use of the DDIM sampling scheme with 100 time steps [64]. For the comparison methods we used the same hyperparameters as in [44] without further tuning, including the number of sampling steps (1000 for DPS and RED-Diff, 20 for DDRM and 100 for \u03a0GDM). ", "page_idx": 5}, {"type": "text", "text": "We compute PSNR and SSIM, which are commonly used distortion measures, along with perceptual metrics such as Learned Perceptual Image Patch Similarity (LPIPS) [83], Kernel Inception Distance (KID) [8], and top-1 classifier accuracy of a pre-trained ResNet50 model [26]. There is a well-known tradeoff between optimising distortion metrics versus perceptual quality, and depending on the task, one may wish for better performance along one axis at the cost of the other. For natural image tasks involving in-painting and super-resolution, it is common to prefer \"natural\"-looking images, which score better on perceptual similarity, whereas for tasks involving (medical) image reconstruction it is standard to prefer a lower distortion metric [9]. Further, we calculate the total time (including training for DEFT) for evaluation 1k validation images in the \"Time (hrs)\" row. Furthermore, we report the effective time taken to sample a single image in the \"Time per sample (s)\" row. This time is calculated by fitting the largest batch size of validation images that fit on a single A100 GPU and dividing the time taken for the batch by the batch size. ", "page_idx": 5}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/75e44125b5753c23246b83965de7a481b08f74660f9c26623085365a4d7b37ec.jpg", "img_caption": ["Figure 2: Results for inpainting. We show the ground truth with the inpainting mask superimposed. Table 1: Results on inpainting and $4\\mathbf{x}$ super-resolution. Best values are shown in bold, second best values are underlined. We report both the total time to sample 1k images, and the time per sample in seconds. The time to sample includes the training time for DEFT. These tasks aim to generate \"natural\"-looking images and therefore perceptual similarity metrics (KID, LPIPS and top-1) are more relevant. I2SB (grey column) can be considered an upper bound on performance. "], "img_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "AKBTFQhCjm/tmp/123ee0ec22d7fc882108a63914f63d1ea3697866c4c448200c33405b4dfe7cd9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Inpainting First, we evaluate DEFT on the linear inverse problem of image inpainting. We make use of the inpainting masks for the 1k subset used by $[59\\bar{]}^{2}$ , which includes masks that obscure $20\\%-30\\%$ of the image. Results are shown in Table 1, including the computational time for sampling all 1000 validation images. For DEFT, this computational time additionally includes the 3.9 hrs of training time of the $h$ -transform additionally with the 1.2 hrs of evaluation. Even with the added training time, we reduce the overall computational time for DEFT, compared to DPS and RED-diff. A visual comparison is provided in Figure 2. Further, in Figure 8 in the Appendix, we show the diversity of samples using different initial seeds. Even though \u03a0GDM and DDRM are faster methods, they perform significantly worse, and are only applicable for linear inverse problems. Inpainting is a task that prefers \"natural\"-looking image samples, and DEFT outperforms all other methods on perceptual metrics such as LPIPS and KID, being a close second on top-1 accuracy. ", "page_idx": 6}, {"type": "text", "text": "Super-resolution For another linear inverse problem, we evaluate ${\\mathrm{4}}\\mathbf{x}$ noiseless super-resolution. Here, the forward operator is given by a bicubic downsampling. The results are presented in Table 1. While DEFT has a lower PSNR compared to the baseline methods, we see significant improvement on perceptual quality metrics (KID, LPIPS, and top-1 accuracy). We show visual results in Figure 9. ", "page_idx": 6}, {"type": "text", "text": "High dynamic range For the first non-linear tasks, we make use of the high dynamic range (HDR) task described in [44]. Here, the forward operator is given by $\\pmb{\\mathscr{A}}(\\pmb{x})=\\mathrm{clip}(2\\pmb{x};-1,1)$ , where $\\textbf{\\em x}$ denotes the RGB image scaled to the range $[-1,1]$ . The results are presented in Table 2. We observe that DPS struggles with this specific non-linear tasks, while DEFT achieves good results. We show a visual comparison in the Appendix, see Figure 10. ", "page_idx": 6}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/37b5e0cb08ea4d1753fd61e1e46b3417d8bf93e8aaede2149c09bddc7dd41d49.jpg", "img_caption": ["Figure 3: Results for non-linear deblurring. We show both the ground truth, the measurements and samples for DPS, RED-diff and DEFT. DEFT is able to reconstruct high-quality images. "], "img_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "AKBTFQhCjm/tmp/17feff77f1c04eed7a3f72c153ba75b9879501fa40fc0cf86e20a2b20fb89132.jpg", "table_caption": ["Table 2: Results on different non-linear image reconstruction tasks. Best values are shown in bold, second best values are underlined. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Phase retrieval The goal in phase retrieval is to recover the image from intensity measurements only, i.e., the forward operator is given by $\\boldsymbol{A}(\\boldsymbol{x})\\,=\\,|\\mathcal{F}\\boldsymbol{x}|$ , with $\\mathcal{F}$ as the Fourier transform. We study the same $2\\mathbf{x}$ oversampling setting as in [12, 44]. Phase retrieval is a challenging non-linear inverse problem, as the forward operator is invariant to translations, global phase shifts and complex conjugation. In Figure 7 in the appendix, we show samples for different initial seeds and observe a wide variety of image quality. We also observe this behaviour for the baseline methods. However, DEFT is able to achieve better performance compared to RED-diff and DPS, see also Table 2. However, there is room for further improvement to achieve good reconstructions on a consistent basis. ", "page_idx": 7}, {"type": "text", "text": "Non-linear deblurring The non-linear deblurring task was originally proposed by [12]. Here, the forward operator is defined by a trained neural network [70], resulting in a highly non-linear blur. Quantitative results are presented in Table 2. This non-linear reconstruction task was also evaluated for RED-diff in [44]. However, we found that the forward operator of the original implementation4 leads to a nearly trivial reconstruction task. In Appendix F.2, we show results with the code from [44], while Table 2 shows the results with our implementation of the forward operator. Further, in Figure 3 we provide a visual comparison, where DEFT is able to recover the ground truth quite faithfully. ", "page_idx": 7}, {"type": "text", "text": "Ablation: Size of fine-tuning dataset As DEFT requires a dataset for fine-tuning, we ablate the number of training samples. We trained DEFT on a subset of 10, 100 and 200 ImageNet images for Inpainting. We see improvements of all metrics, when training on a larger dataset. The results are presented in Table 3. For the KID, we outperform RED-diff (KID: 0.86) even when trained on only 200 images. However, even with 10 images, we perform quite competitively, showcasing that our method is very sample-efficient when it comes to learning a conditional transform. ", "page_idx": 7}, {"type": "text", "text": "Table 3: Varying the size of the fine-tuning dataset for DEFT for Inpainting on ImageNet. ", "page_idx": 8}, {"type": "table", "img_path": "AKBTFQhCjm/tmp/45e6a4853a2a0d3712e123af673cbb7fbb2486d0d5e46d2a167a2f720c38d492.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/c1bc5bd9899d1c9ed5fc6816cf8668648fd5e134bdf797dd788bf965ea3417d5.jpg", "img_caption": ["Figure 4: Reconstructions for computed tomography on LoDoPab-CT "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.2 Computed tomography ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We are evaluating DEFT both on the 2016 American Association of Physicists in Medicine (AAPM) grand challenge dataset [45], and the LoDoPab-CT dataset [35], for details see Appendix E.1. For the unconditional models we make use of the attention U-Net architecture [16]. For the model trained on AAPM, we use exactly the same architecture $\\approx374$ params.) as in [11], while for LoDoPab-CT we use a smaller model $\\langle\\approx133\\mathrm{{M}}$ params.). For the forward operator, we use a parallel-beam ", "page_idx": 8}, {"type": "text", "text": "Table 4: Results for CT on AAPM and LODOPABCT and sampling time per image on a single GeForce RTX 3090. Best values are shown in bold, second best values are underlined. For DEFT we use 100 DDIM steps, while RED-diff and DPS use 1000 time steps. ", "page_idx": 8}, {"type": "table", "img_path": "AKBTFQhCjm/tmp/6258fb5d4194a626edc996adb2dedf146bbaf987e012ab4da8de096faaddec86.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "radon transform with 60 angles and add Gaussian noise with $\\sigma_{y}=1.0$ , which corresponds to approx. $3.5\\%$ relative noise. We compare against DPS [12] and RED-diff [44], where the parameters were obtained using a grid search on a subset of the validation set to maximise the PSNR. In Table 4 we present PSNR and SSIM, in addition to the sampling time, and provide a visual comparison Figure 4. For both datasets, we choose the same DEFT architecture with about 23M parameters.In the Appendix F, we perform an ablation regarding the parametrisation of DEFT, see Table 6. In particular, these results show the necessity of providing the unconditional Tweedie estimate $\\hat{\\pmb{x}}_{0}$ as input to the $h$ -transform in (12). We observe almost a 8dB difference in PSNR for models without the Tweedie estimate and the log-likelihood term. ", "page_idx": 8}, {"type": "text", "text": "4.3 Conditional protein design: motif scaffolding ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We evaluate DEFT on the contiguous motifs of the RFDiffusion benchmark [77]. In this motif scaffolding task, we sample protein $C_{\\alpha}$ atom coordinates $\\pmb{x}\\in\\mathbb{R}^{d}$ such that the generated backbone contains a targeted motif, i.e. a subset of $C_{\\alpha}$ coordinates $\\pmb{y}\\in\\mathbb{R}^{n}$ , similar to an image outpainting task. The forward operator is therefore given by ${\\pmb y}={\\pmb A}({\\pmb x})=\\mathrm{A}{\\pmb x}$ , where $\\mathrm{A}\\in\\{0,1\\}^{\\overline{{n}}\\times d}$ denotes a masking matrix which only selects the $n$ observed $C_{\\alpha}$ coordinates. ", "page_idx": 8}, {"type": "text", "text": "We leverage the pretrained Genie diffusion model which is an unconditional model for protein backbone generation [37]. To apply DEFT to it, we use a downsized version of the unconditional base model as our $h$ -transform model which only uses $200\\mathrm{k}$ instead of the original 4.1M parameters. To adopt this model to the DEFT algorithm, we modify the SE(3)-invariant encoder by adding additional conditional pair feature networks for the motif coordinates as well as the unconditional Tweedie estimate $\\hat{\\pmb{x}}_{0}$ , similar to the setting in the previous experiments. As per Section 3.3, we add a time-dependent likelihood approximation term to the $h$ -transform network. We train the $h$ -transform network on the same SCOPe dataset as in [17]. More details on the training details can be found in App. E.2. We compare DEFT against DPS [12] and a previously published version of Genie that was trained in an amortised fashion [17]. The guidance parameter of DPS was tuned over 5 different experiment runs. The amortised model serves here as an upper limit of how well DEFT can perform with Genie as a base model. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "The overall in-silico success, defined by $\\mathrm{scRMSD<2\\mathring{A}}$ and motifRMSD $<1\\mathring{\\mathsf{A}}$ , is provided in Figure 5. In the Appendix, we provide a detailed breakdown of these results, see Figure 13. Further, in Figure 14 and Figure 15 we provide a comparison of the task 1YCR for the different methods. We observe that DEFT outperforms DPS, solving 10 out of the 12 tasks compared to only 5 tasks for DPS. While it has lower success rates than the amortised model, it still solves all but two tasks in that benchmark with only $9\\%$ of the parameter count and significantly shorter training time compared to the amortised model (800 epochs for DEFT vs 2100 epochs for amortised). The low performance of DPS indicates that the base Genie model is limiting the performance here and may partly explain the performance difference between DEFT and amortised training. Exploring DEFT with a more capable base model is therefore another promising avenue for research. Excitingly, the lower training time and data requirements of DEFT enable fine-tuning a model on specific protein families for particular applications, a task that is left for future work. ", "page_idx": 9}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/985659f2a77b689c135bd90d8351da405dc7cec59e00514cb237b3835067b979.jpg", "img_caption": ["Figure 5: Comparison of DPS, DEFT and amortised training for motif scaffolding for 12 contiguous targets. $4\\%$ and $9\\%$ are the relative sizes of the h-transform compared to the unconditional model. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/9d30c65c791233ac14ee4cc65b541f12c3e2410757b1ff4001c909474d63f50e.jpg", "img_caption": ["Table 5: RFDIFF benchmark metrics (averaged over the 11 targets, 100 samples each). Success: $\\mathrm{\\bar{scRMSD}}<2\\mathrm{\\bar{A}}$ , mo $\\mathrm{ifRMSD}<1\\mathring{\\mathrm{A}}$ . Details in Sec. 4.3. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We presented a unified mathematical framework, based on Doob\u2019s $h$ -transform, to better understand and classify different conditional diffusion methods. Under this framework, we proposed DEFT, a novel parameter-efficient conditional fine-tuning method that does not require backpropagation through large pre-trained score networks, resulting in efficient sampling. We evaluated DEFT on several image reconstruction tasks and showed that it reliably outperformed standard methods, both in time, reconstruction quality and perceptual similarity metrics. While DEFT requires additional training on a small dataset of paired measurements, we find that it is still faster than many existing baselines due to being able to use fewer sampling steps during evaluation, and not needing to backpropagate during evaluation. ", "page_idx": 9}, {"type": "text", "text": "Limitations and future work The DEFT framework uses a (small) fine-tuning dataset, in contrast to zero-shot conditional sampling approaches, e.g., DPS [12] or \u03a0GDM [65]. Fine-tuning on small datasets may have the risk of overfitting to biases inherent in the data. In contrast to zeroshot conditional sampling, DEFT assumes no knowledge of the forward operator. However, the forward operator can be incorporated as an inductive bias within the network architecture to improve performance. We also proposed a zero-shot approach through the optimal control loss in Section 3.2, which only needs a single observation $\\textit{\\textbf{y}}$ to learn the $h$ -transform. Though we show promising results scaling this approach to the MNIST dataset in Appendix H, the computational burden of simulating the full SDE at each iteration is still high, which might make this optimal control loss infeasible for high-dimensional data. However, there is promising recent work on partial trajectory optimisation [79], which may reduce the computational burden of the stochastic control objective, making it competitive with existing methods. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Alexander Denker acknowledges support by the EPSRC programme grant EP/V026259/1. Shreyas Padhy is funded by the University of Cambridge Harding Distinguished Postgraduate Scholars Programme. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Michael S Albergo, Nicholas M Boff,i and Eric Vanden-Eijnden. Stochastic interpolants: A unifying framework for flows and diffusions. arXiv preprint arXiv:2303.08797, 2023.   \n[2] Brian D.O. Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Applications, 12(3):313\u2013326, 1982.   \n[3] Simon Arridge, Peter Maass, Ozan \u00d6ktem, and Carola-Bibiane Sch\u00f6nlieb. Solving inverse problems using data-driven models. Acta Numerica, 28:1\u2013174, 2019.   \n[4] Dominique Bakry, Ivan Gentil, Michel Ledoux, et al. Analysis and geometry of Markov diffusion operators, volume 103. Springer, 2014.   \n[5] Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Sch\u00f6nlieb, and Christian Etmann. Conditional image generation with score-based diffusion models. arXiv preprint arXiv:2111.13606, 2021.   \n[6] Julius Berner, Lorenz Richter, and Karen Ullrich. An optimal control perspective on diffusionbased generative modeling. In NeurIPS 2022 Workshop on Score-Based Methods, 2022.   \n[7] Espen Bernton, Jeremy Heng, Arnaud Doucet, and Pierre E Jacob. Schr\u00f6dinger bridge samplers. arXiv preprint, 2019.   \n[8] Mikolaj Bi\u00b4nkowski, Danica J Sutherland, Michael Arbel, and Arthur Gretton. Demystifying mmd gans. arXiv preprint arXiv:1801.01401, 2018.   \n[9] Yochai Blau and Tomer Michaeli. The perception-distortion tradeoff. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 6228\u20136237, 2018.   \n[10] Valentin De Bortoli. Convergence of denoising diffusion models under the manifold hypothesis. Transactions on Machine Learning Research, 2022. ISSN 2835-8856.   \n[11] Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving diffusion models for inverse problems using manifold constraints. In NeurIPS, 2022.   \n[12] Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong Chul Ye. Diffusion posterior sampling for general noisy inverse problems. In ICLR, 2023.   \n[13] Kevin Clark, Paul Vicol, Kevin Swersky, and David J. Fleet. Directly fine-tuning diffusion models on differentiable rewards. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id $=1$ 1vmSEVL19f.   \n[14] Valentin De Bortoli, Arnaud Doucet, Jeremy Heng, and James Thornton. Simulating diffusion bridges with score matching. arXiv preprint arXiv:2111.07243, 2021.   \n[15] Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion Schr\u00f6dinger bridge with applications to score-based generative modeling. NeurIPS, 2021.   \n[16] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. NeurIPS, 2021.   \n[17] Kieran Didi, Francisco Vargas, Simon V Mathis, Vincent Dutordoir, Emile Mathieu, Urszula J Komorowska, and Pietro Lio. A framework for conditional diffusion modelling with applications in motif scaffolding for protein design. arXiv preprint arXiv:2312.09236, 2023.   \n[18] Carles Domingo-Enrich, Michal Drozdzal, Brian Karrer, and Ricky TQ Chen. Adjoint matching: Fine-tuning flow and diffusion generative models with memoryless stochastic optimal control. arXiv preprint arXiv:2409.08861, 2024.   \n[19] Vincent Dutordoir, Alan Saul, Zoubin Ghahramani, and Fergus Simpson. Neural diffusion processes. In ICML, pages 8990\u20139012. PMLR, 2023.   \n[20] Bradley Efron. Tweedie\u2019s formula and selection bias. Journal of the American Statistical Association, 106(496):1602\u20131614, 2011.   \n[21] James R Fienup. Phase retrieval algorithms: a comparison. Applied optics, 21(15):2758\u20132769, 1982.   \n[22] Marc Anton Finzi, Anudhyan Boral, Andrew Gordon Wilson, Fei Sha, and Leonardo ZepedaN\u00fa\u00f1ez. User-defined event sampling and uncertainty quantification in diffusion models for physical dynamical systems. In ICML, pages 10136\u201310152. PMLR, 2023.   \n[23] Wendell H Fleming and Raymond W Rishel. Deterministic and stochastic optimal control, volume 1. Springer Science & Business Media, 2012.   \n[24] Xizewen Han, Huangjie Zheng, and Mingyuan Zhou. Card: Classification and regression diffusion models. NeurIPS, 35:18100\u201318115, 2022.   \n[25] Andreas Hauptmann, Jonas Adler, Simon Arridge, and Ozan \u00d6ktem. Multi-scale learned iterative reconstruction. IEEE transactions on computational imaging, 6:843\u2013856, 2020.   \n[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \n[27] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. In NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications, 2021.   \n[28] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. NeurIPS, 33:6840\u20136851, 2020.   \n[29] Ajil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G Dimakis, and Jon Tamir. Robust compressed sensing mri with deep generative priors. NeurIPS, 34:14938\u201314954, 2021.   \n[30] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin \u017d\u00eddek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583\u2013589, 2021.   \n[31] Hilbert J Kappen. Linear theory for control of nonlinear stochastic systems. Physical review letters, 95(20):200201, 2005.   \n[32] Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. Denoising diffusion restoration models. In ICLR Workshop on Deep Generative Models for Highly Structured Data, 2022.   \n[33] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. ICLR 2015, 2015.   \n[34] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http: //yann.lecun.com/exdb/mnist/.   \n[35] Johannes Leuschner, Maximilian Schmidt, Daniel Otero Baguer, and Peter Maass. Lodopab-ct, a benchmark dataset for low-dose computed tomography reconstruction. Scientific Data, 8(1): 109, 2021.   \n[36] Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, and David K. Duvenaud. Scalable gradients and variational inference for stochastic differential equations. In Symposium on Advances in Approximate Bayesian Inference, pages 1\u201328. PMLR, 2020.   \n[37] Yeqing Lin and Mohammed Alquraishi. Generating novel, designable, and diverse protein structures by equivariantly diffusing oriented residue clouds. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 20978\u201321002. PMLR, 23\u201329 Jul 2023.   \n[38] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative modeling. arXiv preprint arXiv:2210.02747, 2022.   \n[39] Guan-Horng Liu, Arash Vahdat, De-An Huang, Evangelos A. Theodorou, Weili Nie, and Anima Anandkumar. I2sb: image-to-image schr\u00f6dinger bridge. In Proceedings of the 40th International Conference on Machine Learning, ICML\u201923. JMLR.org, 2023.   \n[40] Xingchao Liu and Lemeng Wu. Learning diffusion bridges on constrained domains. In ICLR, 2023.   \n[41] Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. arXiv preprint arXiv:2209.03003, 2022.   \n[42] Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, and Yoshua Bengio. Trajectory balance: Improved credit assignment in gflownets. NeurIPS, 35:5955\u20135967, 2022.   \n[43] Nikolay Malkin, Salem Lahlou, Tristan Deleu, Xu Ji, Edward Hu, Katie Everett, Dinghuai Zhang, and Yoshua Bengio. Gflownets and variational inference. arXiv preprint arXiv:2210.00580, 2022.   \n[44] Morteza Mardani, Jiaming Song, Jan Kautz, and Arash Vahdat. A variational perspective on solving inverse problems with diffusion models. In ICLR, 2024.   \n[45] Cynthia H McCollough, Adam C Bartley, Rickey E Carter, Baiyu Chen, Tammy A Drees, Phillip Edwards, David R Holmes III, Alice E Huang, Farhana Khan, Shuai Leng, et al. Low-dose ct for the detection and classification of metastatic liver lesions: results of the 2016 low dose ct grand challenge. Medical physics, 44(10):e339\u2013e352, 2017.   \n[46] Xiangming Meng and Yoshiyuki Kabashima. Diffusion model based posterior sampling for noisy linear inverse problems. arXiv preprint arXiv:2211.12343, 2022.   \n[47] Maria-Elena Nilsback and Andrew Zisserman. Automated flower classification over a large number of classes. In Indian Conference on Computer Vision, Graphics and Image Processing, Dec 2008.   \n[48] Nikolas N\u00fcsken and Lorenz Richter. Solving high-dimensional Hamilton\u2013Jacobi\u2013Bellman PDEs using neural networks: perspectives from the theory of controlled diffusions and measures on path space. Partial Differential Equations and Applications, 2(4):1\u201348, 2021.   \n[49] Angus Phillips, Hai-Dang Dau, Michael John Hutchinson, Valentin De Bortoli, George Deligiannidis, and Arnaud Doucet. Particle denoising diffusion sampler. arXiv preprint arXiv:2402.06320, 2024.   \n[50] Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Mildenhall. Dreamfusion: Text-to-3d using 2d diffusion. In ICLR, 2023.   \n[51] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 8821\u20138831. PMLR, 18\u201324 Jul 2021.   \n[52] Sriram Ravula, Brett Levac, Ajil Jalal, Jon Tamir, and Alex Dimakis. Optimizing sampling patterns for compressed sensing MRI with diffusion generative models. In NeurIPS 2023 Workshop on Deep Learning and Inverse Problems, 2023.   \n[53] Lorenz Richter, Ayman Boustati, Nikolas N\u00fcsken, Francisco Ruiz, and Omer Deniz Akyildiz. Vargrad: a low-variance gradient estimator for variational inference. NeurIPS, 33:13481\u201313492, 2020.   \n[54] Lorenz Richter, Julius Berner, and Guan-Horng Liu. Improved sampling via learned diffusions. arXiv preprint arXiv:2307.01198, 2023.   \n[55] L Chris G Rogers and David Williams. Diffusions, Markov processes and martingales: Volume 2, It\u00f4 calculus, volume 2. Cambridge university press, 2000.   \n[56] Litu Rout, Negin Raoof, Giannis Daras, Constantine Caramanis, Alex Dimakis, and Sanjay Shakkottai. Solving linear inverse problems provably via posterior sampling with latent diffusion models. NeurIPS, 36, 2024.   \n[57] Francois Rozet and Gilles Louppe. Score-based data assimilation. arXiv preprint arXiv:2306.10574, 2023.   \n[58] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. IJCV, 115:211\u2013252, 2015.   \n[59] Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, and Mohammad Norouzi. Palette: Image-to-image diffusion models. In ACM SIGGRAPH 2022 conference proceedings, pages 1\u201310, 2022.   \n[60] Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J Fleet, and Mohammad Norouzi. Image super-resolution via iterative refinement. TPAMI, 45(4):4713\u20134726, 2022.   \n[61] Simo S\u00e4rkk\u00e4 and Arno Solin. Applied stochastic differential equations, volume 10. Cambridge University Press, 2019.   \n[62] Mathis Simon V, Julia Komorowska Urszula, Jamnik Mateja, and Lio Pietro. Normal mode diffusion: Towards dynamics-informed protein design. The 2023 ICML Workshop on Computational Biology. Baltimore, Maryland, USA, 2023. C, 2023.   \n[63] Vignesh Ram Somnath, Matteo Pariset, Ya-Ping Hsieh, Maria Rodriguez Martinez, Andreas Krause, and Charlotte Bunne. Aligned diffusion schr\u00f6dinger bridges. arXiv preprint arXiv:2302.11419, 2023.   \n[64] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In ICLR, 2021.   \n[65] Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan Kautz. Pseudoinverse-guided diffusion models for inverse problems. In ICLR, 2022.   \n[66] Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advances in neural information processing systems, 33:12438\u201312448, 2020.   \n[67] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In ICLR, 2021.   \n[68] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In ICLR, 2021.   \n[69] Yang Song, Liyue Shen, Lei Xing, and Stefano Ermon. Solving inverse problems in medical imaging with score-based generative models. In ICLR, 2022.   \n[70] Phong Tran, Anh Tuan Tran, Quynh Phung, and Minh Hoai. Explore image deblurring via encoded blur kernel space. In Proceedings of the IEEE/CVF CVPR, pages 11956\u201311965, 2021.   \n[71] Belinda Tzen and Maxim Raginsky. Theoretical guarantees for sampling and inference in generative models with latent diffusions. In Conference on Learning Theory, pages 3084\u20133114. PMLR, 2019.   \n[72] Masatoshi Uehara, Yulai Zhao, Kevin Black, Ehsan Hajiramezanali, Gabriele Scalia, Nathaniel Lee Diamant, Alex M Tseng, Tommaso Biancalani, and Sergey Levine. Finetuning of continuous-time diffusion models as entropy-regularized control. arXiv preprint arXiv:2402.15194, 2024.   \n[73] Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving Schr\u00f6dinger bridges via maximum likelihood. Entropy, 23(9):1134, 2021.   \n[74] Francisco Vargas, Will Sussman Grathwohl, and Arnaud Doucet. Denoising diffusion samplers. In ICLR, 2023.   \n[75] Francisco Vargas, Andrius Ovsianas, David Fernandes, Mark Girolami, Neil D Lawrence, and Nikolas N\u00fcsken. Bayesian learning via neural Schr\u00f6dinger\u2013F\u00f6llmer flows. Statistics and Computing, 33(1):3, 2023.   \n[76] Francisco Vargas, Shreyas Padhy, Denis Blessing, and Nikolas N\u00fcsken. Transport meets variational inference: Controlled monte carlo diffusions. In ICLR, 2024.   \n[77] Joseph L Watson, David Juergens, Nathaniel R Bennett, Brian L Trippe, Jason Yim, Helen E Eisenach, Woody Ahern, Andrew J Borst, Robert J Ragotte, Lukas F Milles, et al. De novo design of protein structure and function with rfdiffusion. Nature, pages 1\u20133, 2023.   \n[78] Mao Ye, Lemeng Wu, and Qiang Liu. First hitting diffusion models for generating manifold, graph and categorical data. In NeurIPS, 2022.   \n[79] Dinghuai Zhang, Ricky Tian Qi Chen, Cheng-Hao Liu, Aaron Courville, and Yoshua Bengio. Diffusion generative flow samplers: Improving learning signals through partial trajectory optimization. arXiv preprint arXiv:2310.02679, 2023.   \n[80] Lvmin Zhang, Anyi Rao, and Maneesh Agrawala. Adding conditional control to text-to-image diffusion models. In Proceedings of the IEEE/CVF ICCV, pages 3836\u20133847, 2023.   \n[81] Qinsheng Zhang and Yongxin Chen. Path integral sampler: A stochastic control approach for sampling. In ICLR, 2022. URL https://openreview.net/forum?id $\\equiv$ _uCb2ynRu7Y.   \n[82] Qinsheng Zhang and Yongxin Chen. Fast sampling of diffusion models with exponential integrator. arXiv preprint arXiv:2204.13902, 2022.   \n[83] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 586\u2013595, 2018.   \n[84] Linqi Zhou, Aaron Lou, Samar Khanna, and Stefano Ermon. Denoising diffusion bridge models. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id $=$ FKksTayvGo. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Background on diffusion formulations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 Recap - continuous and discrete diffusion formulations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The discretised DDPM versions with various discrete time schedules amount to the time-dependent OU process ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{X}_{t}=-\\frac{\\beta(t)}{2}\\mathbf{\\calX}_{t}\\mathrm{d}t+\\sqrt{\\beta(t)}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where choosing different time schedules amounts to choosing different functions $\\beta(t)$ . This process gives rise to the following transition probabilities ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{p(\\pmb{x},t|\\pmb{x}_{0},0)=\\vec{p}_{t|0}(\\pmb{x}|\\pmb{x}_{0})}\\\\ &{\\qquad\\qquad=\\mathcal{N}\\left(\\pmb{x}_{0}e^{-\\int_{0}^{T}\\frac{\\beta(s)}{2}\\mathrm{d}s},\\pmb{I}\\int_{0}^{T}\\beta(t)e^{-\\int_{0}^{T-t}\\beta(s)\\mathrm{d}s}\\mathrm{d}t\\right)}\\\\ &{\\qquad\\qquad=\\mathcal{N}\\left(\\pmb{x}_{0}e^{-\\int_{0}^{T}\\frac{\\beta(s)}{2}\\mathrm{d}s},\\left(1-e^{-\\int_{0}^{T}\\beta(s)\\mathrm{d}s}\\right)\\pmb{I}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "see also Appendix $\\mathbf{B}$ in [67]. With $\\bar{\\alpha}(t)=e^{-\\int_{0}^{T}\\beta(s)\\mathrm{d}s}$ , this is the familiar form ([28]): ", "page_idx": 15}, {"type": "equation", "text": "$$\np(\\pmb{x},t|\\pmb{x}_{0},0)=\\vec{p}_{t|0}(\\pmb{x}|\\pmb{x}_{0})=\\mathcal{N}\\left(\\pmb{x}_{0}\\sqrt{\\bar{\\alpha}(t)},(1-\\bar{\\alpha}(t))\\pmb{I}\\right),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with $\\bar{\\alpha}(t)$ time-dependent and we can therefore choose different functional forms for the noise schedule by either choosing the transition parameters $\\beta(t)$ or the cumulative parameters $\\alpha(t)$ . ", "page_idx": 15}, {"type": "text", "text": "If we define the noise schedule in terms of $\\beta(t)$ , the time-dependent OU process is immediately apparent (see (13)). If we define the noise schedule in terms of ${\\bar{\\alpha}}(t)$ , the mean and variance of the corresponding OU process can simply be obtained from ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\beta(t)=-{\\frac{\\mathrm{d}}{\\mathrm{d}t}}\\left[\\ln\\bar{\\alpha}(t)\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A.2 Score, noise and mean diffusion formulations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The score-based model used for generation at inference time can be parametrised to model different quantities. The three most common one are the score, the noise and the mean. Using the score based SDE formulation we parametrise the network as the score that is the network approximates the quantity: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla_{\\pmb{x}}\\ln p_{t}(\\pmb{x}_{t})\\approx s_{t}^{\\theta}(\\pmb{x}_{t})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Moving on to the DDPM formulation one typically trains a noise prediction network instead which is proportional to the score ", "page_idx": 15}, {"type": "equation", "text": "$$\ns_{t}^{\\theta}(\\mathbf{x}_{t})=-\\frac{1}{\\sqrt{1-\\bar{\\alpha}(t)}}\\epsilon_{t}^{\\theta}(\\mathbf{x}_{t}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "This formulation is typically preferable for training as it is known to learn a less stiff vector field [82]. Finally in its most naive form DDPM also admits a mean matching formulation ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mu_{0}^{\\theta}({x}_{t},t)=\\frac{1}{\\sqrt{\\alpha_{t}}}\\left({x}_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-\\bar{\\alpha}(t)}}\\epsilon_{t}^{\\theta}({x}_{t})\\right),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "whilst not the ideal parametrisation for direct training, it is a useful expression/macro, for expressing the sampling updates more succinctly. ", "page_idx": 15}, {"type": "text", "text": "In this work we parametrise $\\epsilon_{t}^{\\theta}$ directly with our novel architecture for finetuning, using a noise matching objective as in DDPM, however we allude to and use the above parametrisations across our propositions and novel architectures. See Algorithm 1 for training and Algorithm 2 for sampling. ", "page_idx": 15}, {"type": "text", "text": "B Related Work Discussion ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A common distinction to all the works we will discuss in this section is that they all either train the conditional network from scratch or they initialise the conditional network with a pretrained score and fully train a conditional network. This is in stark contrast to DEFT which completely freezes the unconditional score and trains a highly efficient network to learn the $h$ -transform which ranges from $4-17\\%$ in total parameter size of the pretrained unconditional score network. ", "page_idx": 16}, {"type": "text", "text": "Classifier free guidance Methodologies such as classifier free guidance [27] do not model the forward operator explicitly. As a result, if these methods are applied to settings such as motifscaffolding or image out-painting (where the conditioning is on a subset of the random variable), these methodologies would only denoise the scaffolding and the missing image patches. This is different to our approach which adds noise to both motif and scaffolding and then proceeds to denoise both jointly as part of the same space. In a way, one can view RFDiffusion\u2019s conditional training as an application of classifier-free guidance to this subset conditioning setting. ", "page_idx": 16}, {"type": "text", "text": "Image 2 Image Schr\u00f6dinger Bridges (I2SB [39]) I2SB and more generally aligned Schr\u00f6dinger Bridges [63] are a recently proposed class of conditional generative models based on ideas from Schr\u00f6dinger bridges. The premise of these methods is that they aim to learn an interpolating diffusion between a clean data sample and a altered or corrupted data sample. This is in contrast to our framework: we consider an unconditioned SDE and condition it to hit an event at a particular time, thus learning an interpolating distribution between noise and an un-corrupted target distribution. This results in several algorithmic differences: ", "page_idx": 16}, {"type": "text", "text": "\u2022 At its core, I2SB treat $\\pmb{Y}\\,=\\,\\mathcal{A}(\\pmb{X}_{0})\\,+\\,\\eta$ and $\\textstyle X_{0}$ as source and target distributions respectively; thus, at sampling time, $\\mathbf{Y}$ is provided to the learned SDE which generates approximate samples from Law $\\left(X_{0}\\right)$ . However, in our approach, the source distribution is $\\mathcal{N}(0,\\mathbf{I})$ and we pass $\\mathbf{\\deltaY}$ to the score network to then obtain approximate samples from Law $\\left(X_{0}\\right)$ .   \n\u2022 The score network in I2SB is a function only of $X_{t}$ and not $\\pmb{Y}=\\pmb{\\mathcal{A}}(\\pmb{X}_{0})+\\eta$ . This means that in I2SB, the network is parametrised as $\\epsilon_{t}^{\\theta}(X_{t})$ , whilst in our setting we parametrise as $\\epsilon_{t}^{\\theta}(X_{t},\\mathcal{A}(X_{0})+\\eta,\\mathcal{A})$ . In the case of completion tasks like motif-scaffolding or image out-painting, our paramerisation looks something like $\\epsilon_{t}^{\\theta}(X_{t},X_{0}^{\\mathrm{mask}}$ , mask). This makes the task much easier for the network as we effectively provide it with a binary variable indicating which parts of the image are conditioned and which are not. In I2SB, the network must learn this on its own. Furthermore, as we show in Prop. H.1, adding this to the network parametrisation is essential to allow recovering the true conditional score.   \n\u2022 The training procedure in I2SB uses the diffusion bridge $p(\\pmb{x}_{t}|\\pmb{x}_{0},\\pmb{y})$ to add noise to both the source and target distributions, whilst our forward process is given by the transition density of an OU process $p(\\mathbf{\\boldsymbol{x}}_{t}|\\mathbf{\\boldsymbol{x}}_{0})$ and is identical to standard DDPM/VP-SDE [28, 68] noise adding procedures.   \n\u2022 Finally and most importantly I2SB does full fine-tuning firstly initialising with a pretrained score and training all parameters of this large pretrained network to learn an unconditional network, this requires longer training times and significantly larger networks as they must be at least the same size as the unconditional score network. ", "page_idx": 16}, {"type": "text", "text": "To summarise: whilst both methodologies employ similar mathematical methodologies (e.g. Diffusion Bridges [14]), their ideations and resulting methods are fundamentally different: on one side, [39] learns an interpolating distribution between the unconditioned $p(\\bar{\\pmb{x_{0}}})$ and conditioned $p(\\pmb{y}|\\pmb{x}_{0})$ samples. On the other, we learn a denoising procedure that directly samples from the posterior $\\lceil p(\\pmb{x}_{0}|\\pmb{y})$ ; via this, we derive and explain most popular approaches for conditioning denoising diffusion models as part of our framework. ", "page_idx": 16}, {"type": "text", "text": "It\u2019s important to highlight that another akin approach to I2SB, also based on the h-transform but leveraging VP-SDes, was recently proposed in [84]. ", "page_idx": 16}, {"type": "text", "text": "CDE [5] Similar to classifier free guidance. CDE [5] trains a conditional network from scratch without leveraging a pretrained unconditional score. For more details on CDE please see our detailed discussion in Appendix H. ", "page_idx": 16}, {"type": "text", "text": "First Hitting Diffusions A line of generative modelling methods proposed in [40, 78] utilise the $h$ -transform for unconditional generative modelling in the following settings: ", "page_idx": 17}, {"type": "text", "text": "\u2022 Hitting the target distribution $p_{\\mathrm{data}}$ in a finite amount of time $[0,T]$ via time reversing an h-transformed VP-SDE conditioned to hit 0 at time $T$ . \u2022 Constraining a diffusion process at time $T$ to lie in a subset of the reals $\\Omega\\subseteq\\mathbb{R}^{d}$ . ", "page_idx": 17}, {"type": "text", "text": "Whilst the aforementioned work uses a similar methodology and theory the focus is more in line with unconditional generative modelling rather than our setting which seeks to sample from the posterior arising in an inverse problem / conditional generative modelling. ", "page_idx": 17}, {"type": "text", "text": "RFDiffusion As highlighted in Alg. 3 and in contrast to AMORTISED TRAINING, RFDiffusion [77]   \ndoes not noise the motif coordinates $X_{0}^{[M]}$ with the forward OU-Process, instead it directly aims to   \ntshaims palpep frrooamch $p(\\pmb{X}_{t}^{[\\backslash M]}|\\pmb{X}_{0}^{[M]})$ d  alneda rensitnigm oatf e Dthoios bs\u2019cs -et rwanhislfeo rkmee, pbiyn gn tohtien gm tohtiaft  fRixFe dd.i ffWues icoann c raenl abtee $h$ understood as learning the marginal conditional score ", "page_idx": 17}, {"type": "equation", "text": "$$\np({\\pmb x}_{t}^{[\\backslash M]}|{\\pmb x}_{0}^{[M]})=\\int\\,\\overbrace{p({\\pmb x}_{t}|{\\pmb x}_{0}^{[M]})}^{\\propto h(t,{\\pmb x}_{t})p_{t}({\\pmb x}_{t})}\\,d{\\pmb x}_{t}^{[M]}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This can be viewed as RFDiffusion estimating a marginal counterpart of our amortised $h$ -transform approach. See Algs. 3 and 4 for more details on how these approaches differ in a pseudo-code implementation. ", "page_idx": 17}, {"type": "text", "text": "C Doob\u2019s $h$ -transform ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "C.1 Doob\u2019s $h$ -transform intuition ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Doob\u2019s transform provides a formal mechanism for conditioning a stochastic differential equation (SDE) to hit an event at a given time. The $h$ -transform drift decomposes into two terms via Bayes rule, a conditional and a prior score ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla_{H_{t}}\\ln\\overline{{P}}_{0|t}(X_{0}\\in B\\mid H_{t})=\\nabla_{H_{t}}\\ln\\overline{{P}}_{t|0}(H_{t}\\mid X_{0}\\in B)-\\nabla_{H_{t}}\\ln P_{t}(H_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "whereby the conditional score ensures that the event is hit at the specified boundary time, while the prior score ensures it is time-reversal of the correct forward process [14]. Doob\u2019s $h$ -transform adds a new drift to the SDE which amounts to two terms (via Bayes Theorem), a conditional and an unconditional score ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla\\ln\\overline{{P}}_{0\\mid t}(X_{0}\\in B|\\cdot)=\\nabla\\ln\\overline{{P}}_{t\\mid0}(\\cdot|X_{0}\\in B)-\\nabla\\ln P_{t}(\\cdot).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Interestingly, these two terms provide for a unique intuition: the Doob\u2019s transform SDE is the time reversal of the forward SDE corresponding to (3), that is the time reversal of the forward SDE ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{d}X_{t}=\\vec{b}_{t}(X_{t})\\,\\mathrm{d}t+\\sigma_{t}\\overline{{\\mathrm{d}\\mathbf{W}_{t}}},\\quad X_{0}\\sim\\vec{P}_{0}(\\cdot|X_{0}\\in B),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "coincides with the Doob transformed SDE (4) [14]. Thus we can view Doob\u2019s transform as the following series of steps: ", "page_idx": 17}, {"type": "text", "text": "1. Time reverse the SDE we want to condition ((4) to (25)).   \n2. Impose the condition via ancestral sampling from the conditioned distribution/posterior.   \n3. Time reverse once more to be in the same time direction as we started. ", "page_idx": 17}, {"type": "text", "text": "C.2 Example: Truncated normal ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Here for illustrative purposes we frame the problem of sampling from a truncated normal distribution as simulating an SDE that is given by Doob\u2019s h-transform. ", "page_idx": 17}, {"type": "text", "text": "Let\u2019s remind that a 1d truncated normal distribution had a density $p(x|a,b)\\propto\\mathbb{1}_{x\\in(a,b)}(x)\\mathcal{N}(x|\\mu,\\sigma^{2})$ . Now, let\u2019s assume a data distribution $p_{0}(x)~=~\\mathcal{N}(\\mu,\\sigma^{2})$ which is noised with an OU process (13). Thus we have that $p(x_{0}|x_{t})\\;=\\;\\mathcal{N}(x_{0}|\\hat{\\mu}_{0|t}(x_{t}),\\hat{\\sigma}_{0|t}(x_{t})^{2})$ is Gaussian, and so is ", "page_idx": 17}, {"type": "text", "text": "$p(x_{t})\\;=\\;\\mathcal{N}(x_{t}|\\hat{\\mu}_{t},\\hat{\\sigma}_{t}^{2})$ . Let\u2019s add the constraint that the process hit at time $t~=~0$ the event $X_{0}\\in(a,b)$ . ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\,\\mathrm{d}{H_{t}}=\\beta(t)\\left(\\frac{H_{t}}{2}+\\nabla_{H_{t}}\\ln\\overline{{P}}_{t}(H_{t})-\\nabla_{H_{t}}\\ln\\overline{{P}}_{0\\mid t}(X_{0}\\in(a,b)\\mid H_{t})\\right)\\,\\mathrm{d}t+\\sqrt{\\beta(t)}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We have that the h-transform is given by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h(t,H_{t})=\\overline{{P}}_{0\\mid t}(X_{0}\\in(a,b)|H_{t})=\\int\\mathbb{1}_{x\\in(a,b)}(x_{0})\\overline{{p}}_{0\\mid t}(x_{0}|H_{t})\\mathrm{d}x_{0}}\\\\ &{\\qquad\\qquad=\\int\\mathbb{1}_{x\\in(a,b)}(x_{0})\\mathcal{N}(x|\\hat{\\mu}_{0\\mid t}(H_{t}),\\hat{\\sigma}_{0\\mid t}(H_{t})^{2})\\mathrm{d}x_{0}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\phi\\left(\\frac{H_{t}-\\hat{\\mu}_{0\\mid t}(H_{t})}{\\hat{\\sigma}_{0\\mid t}(H_{t})}\\right)}\\\\ &{\\qquad\\qquad=\\frac{1}{\\hat{\\sigma}_{0\\mid t}(H_{t})}\\frac{\\phi}{\\Phi\\left(\\frac{b-\\hat{\\mu}_{0\\mid t}(H_{t})}{\\hat{\\sigma}_{0\\mid t}(H_{t})}\\right)-\\Phi\\left(\\frac{a-\\hat{\\mu}_{0\\mid t}(H_{t})}{\\hat{\\sigma}_{0\\mid t}(H_{t})}\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\begin{array}{r l r}{\\phi(\\xi)}&{{}=}&{\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}\\xi^{2}\\right)}\\end{array}$ is the pdf of a standard normal distribution, $\\begin{array}{r l r}{\\Phi(\\xi)}&{{}=}&{}\\end{array}$ ${\\frac{1}{2}}\\left(1+\\operatorname{erf}(\\xi/{\\sqrt{2}})\\right)$ its cumulative function. The corrective drift term due to the $_\\mathrm{h}$ -transform can then be computed via autograd. The unconditional score term can be computed in closed form. ", "page_idx": 18}, {"type": "text", "text": "C.3 Doob\u2019s $h$ -transform classical noiseless setting ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We now consider events of the form $X_{0}\\in B$ which are described by an equality constraint $\\mathcal{A}(\\mathbf{{X}}_{0})=$ $\\textit{\\textbf{y}}$ with $\\boldsymbol{\\mathcal{A}}$ a known measurement (or forward) operator and $\\textit{\\textbf{y}}$ an observation, which is a common setup in inverse problems such as inpainting or super-resolution. ", "page_idx": 18}, {"type": "text", "text": "Corollary C.1. Consider the reverse $S D E$ (3), then it follows that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathrm{d}\\boldsymbol{H}_{t}=\\left(\\tilde{b}_{t}(\\boldsymbol{H}_{t})-\\sigma_{t}^{2}\\nabla_{\\boldsymbol{H}_{t}}\\ln\\overline{{P}}_{0\\mid t}(\\boldsymbol{A}(\\boldsymbol{X}_{0})=y\\mid\\boldsymbol{H}_{t})\\right)\\mathrm{d}t+\\sigma_{t}\\mathrm{d}\\mathbf{W}_{t},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "with $\\tilde{b}_{t}(\\pmb{H}_{t})=f_{t}(\\pmb{H}_{t})-\\sigma_{t}^{2}\\nabla_{\\pmb{H}_{t}}\\ln p_{t}(\\pmb{H}_{t})$ satisfies Law $(H_{s}|H_{t})=\\operatorname{Law}\\left(X_{s}|X_{t},{\\mathcal{A}}(X_{0})=y\\right)$ thus Law $(H_{0})=\\operatorname{Law}\\left(X_{0}|\\mathcal{A}(X_{0})=y\\right)$ . ", "page_idx": 18}, {"type": "text", "text": "Sampling from (28) directly provides samples $x\\sim p_{\\mathrm{data}}$ which also satisfy $\\boldsymbol{A}(\\boldsymbol{x})=\\boldsymbol{y}$ . Crucially, this SDE is guaranteed to hit the conditioning in finite time, unlike prior equilibrium-motivated approaches [12, 19, 22, 24, 46, 65]. ", "page_idx": 18}, {"type": "text", "text": "Reconstruction guidance To get better insight into the challenge of sampling via Doob\u2019s $h$ - transform in (28) let us re-express the $h$ -transform as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\overline{{P}}_{0\\mid t}(A(X_{0})=y\\mid H_{t})=\\int\\mathbb{1}_{A(x_{0})=y}(x_{0})\\overline{{p}}_{0\\mid t}(x_{0}\\vert H_{t})\\mathrm{d}x_{0},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where in the case of denoising diffusion models $\\overleftarrow{p}_{0|t}(\\mathbf{\\boldsymbol{x}}_{0}|\\cdot)$ is the transition density of the reverse SDE (3). In practice, one does not have access to this transition density \u2013 i.e. we can sample from this distribution, but we cannot easily get its value at a certain point. This makes it difficult to approximate the integral. To alleviate this, a strand of recent works [12, 22, 57, 65] have proposed to apply a Gaussian approximation of $\\overline{{p}}_{0\\mid t}(\\mathbf{x}_{0}|\\cdot)\\approx\\mathcal{N}(\\mathbf{x}_{0}\\mid\\mathbb{E}[X_{0}|X_{t}=\\cdot],\\Gamma_{t})$ leveraging Tweedie\u2019s formula and the pre-trained score network. This line of work is referred as reconstruction guidance. We note that whilst proposing to approximate the quantity $\\overleftarrow{P}_{0|t}(\\mathcal{A}(\\mathbf{X}_{0})=\\pmb{y}|\\cdot)$ ), they do not make the connection to Doob\u2019s transform and thus are unable to provide guarantees on the conditional sampling that Cor. C.1 provides. Overall, the Gaussian-based approximations of Doob\u2019s $h$ -transform lead to reconstruction guidance-based approaches ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}{\\cal H}_{t}=\\left(\\bar{b}_{t}({\\cal H}_{t})+\\sigma_{t}^{2}\\nabla_{{\\cal H}_{t}}||y-\\mathrm{A}\\mathbb{E}[X_{0}|X_{t}={\\cal H}_{t}]||_{\\Gamma_{t}}^{2}\\right)\\mathrm{d}t+\\sigma_{t}\\mathrm{d}\\overline{{\\mathbf{W}}}_{t},X_{T}\\sim\\mathcal{P}_{T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\Gamma_{t}$ acts as a guidance scale [57, 62], and A is a matrix if $\\boldsymbol{\\mathcal{A}}$ is linear otherwise $\\mathrm{~A~}=$ $\\mathrm{d}\\mathcal{A}(\\mathbb{E}[X_{0}|X_{t}=H_{t}])$ . ", "page_idx": 18}, {"type": "text", "text": "D Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "D.1 Proof of Proposition 2.2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. Starting from the unconditioned reverse SDE ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}X_{t}=\\bar{b}_{t}(X_{t})\\,\\mathrm{d}t+\\sigma_{t}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},\\quad X_{T}\\sim\\mathbb{P}_{T}=Q_{T}^{f_{t}}[p(\\mathbf{x}_{0})],}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "we consider its reversal, the forward SDE, but we change its initial from distribution $p(\\pmb{x}_{0})$ to the target posterior $p(x_{0}|y)$ , i.e., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{d}H_{t}=f_{t}(H_{t})\\,\\mathrm{d}t+\\sigma_{t}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},\\quad H_{0}\\sim\\frac{p(\\pmb{y}|\\pmb{x}_{0})p_{\\mathrm{data}}(\\pmb{x}_{0})}{p(\\pmb{y})},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\begin{array}{r}{\\dot{b}_{t}(H_{t})=f_{t}(H_{t})-\\sigma_{t}^{2}\\nabla_{H_{t}}\\ln p_{t}(H_{t}).}\\end{array}$ ", "page_idx": 19}, {"type": "text", "text": "Now let us use $\\begin{array}{r}{p_{t|y}(\\pmb{x}|\\pmb{y})=\\int p(\\pmb{x}_{t}|\\pmb{x}_{0})\\mathrm{d}p(\\pmb{x}_{0}|\\pmb{y})}\\end{array}$ to denote the marginal of the above SDE and as before $p_{t}$ to denote the marginal of the reference starting at the data distribution. Then it follows that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{p_{t|y}(\\pmb{x}|\\pmb{y})=p_{t}(\\pmb{x})p(\\pmb{y})^{-1}\\int\\frac{\\vec{p}_{t|0}(\\pmb{x}|\\pmb{x}_{0})}{p_{t}(\\pmb{x})}p(\\pmb{y}|\\pmb{x}_{0})p_{\\mathrm{data}}(\\pmb{x}_{0})d\\pmb{x}_{0}}}\\\\ {{\\qquad\\qquad=p_{t}(\\pmb{x})p(\\pmb{y})^{-1}\\int\\bar{p}_{0|t}(\\pmb{x}_{0}|\\pmb{x})p(\\pmb{y}|\\pmb{x}_{0})d\\pmb{x}_{0}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and thus the score of the reference starting at the posterior is given by: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\nabla_{x}\\ln p_{t|y}({\\pmb x}|{\\pmb y})=\\nabla_{x}\\ln p_{t}({\\pmb x})+\\nabla_{x}\\ln\\int\\bar{p}_{0|t}({\\pmb x}_{0}|{\\pmb x})p({\\pmb y}|{\\pmb x}_{0})d x_{0}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Now that we have the score of the SDE in Equation 32 we can reverse it yet another time to obtain the conditional backwards SDE: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H_{T}\\sim Q_{T}^{f_{t}}[p(x_{0}|y)]=\\int\\vec{p}_{T|0}(x|x_{0})p(x_{0}|y)\\mathrm{d}x_{0}}\\\\ &{\\mathrm{d}H_{t}=\\left(f_{t}(H_{t})-\\sigma_{t}^{2}\\left(\\nabla_{H_{t}}\\ln p_{t}(H_{t})+\\nabla_{H_{t}}\\ln p_{y|t}(Y=y|H_{t})\\right)\\right)\\,\\mathrm{d}t+\\sigma_{t}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},}\\\\ &{\\mathrm{d}H_{t}=\\left(\\overline{{b}}_{t}(H_{t})-\\sigma_{t}^{2}\\nabla_{H_{t}}\\ln p_{y|t}(Y=y|H_{t})\\right)\\,\\mathrm{d}t+\\sigma_{t}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Where it is very important to notice that the backward SDE starts a the terminal distribution of the conditional forward SDE $Q_{T}^{f_{t}}[p(x_{0}|\\pmb{y})]$ and not $\\mathbb{P}_{T}=Q_{T}^{f_{t}}[p(\\pmb{x}_{0})]$ , for a VP-SDE this happens to approximately be ${\\mathcal{N}}(0,I)$ in both cases (i.e. $Q_{T}^{f_{t}}[p(\\mathbf{x}_{0}|y)]\\approx Q_{T}^{f_{t}}[p(\\mathbf{x}_{0})]\\approx\\mathcal{N}(0,I))$ however more generally it is not and one needs to be careful. ", "page_idx": 19}, {"type": "text", "text": "Note that this remark highlights that the score used in DPS [12] (i.e. $\\nabla_{x}\\ln p_{t|y}(x|y))$ is in fact the score of an OU process starting at $p(x_{0}|y)$ notice the cancellation going from Equations (33) to (34) was only possible since the prior in our target posterior is the initial distribution for the forward SDE (in their case an OU-process) with marginal $p_{t}$ , these considerations are subtle yet important and omitted in prior works. Whilst this is akin the relationship motivated in DPS as $\\nabla_{\\bar{\\mathbf{x}}}\\ln p_{t|y}(\\mathbf{x}|y)=\\nabla_{x}\\ln\\bar{p_{t}}(\\mathbf{x})+\\nabla_{x}\\ln p_{t}(\\mathbf{y}|x)$ , DPS fails to convey that this is in fact the score of a VP-SDE with the posterior $p(x_{0}|y)$ as its initial distribution. ", "page_idx": 19}, {"type": "text", "text": "D.2 Proof of Theorem 3.1 2) ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. The idea of the proof is similar to Proposition H.1. Here, we directly proof the amortised variation from Equation (9). First, we state the well known score matching identity for the posterior score: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\nabla_{x_{t}}\\ln p_{t}(\\pmb{x}|\\pmb{y})=\\int\\nabla_{\\pmb{x}_{t}}\\ln\\vec{p}_{t|0}(\\pmb{x}_{t}|\\pmb{x}_{0})\\bar{p}_{0|t}(\\pmb{x}_{0}|\\pmb{x}_{t},\\pmb{y})\\mathrm{d}\\pmb{x}_{0}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Via the mean squared error property of the conditional expectation we get the minimiser as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\nabla_{H_{t}}\\ln\\vec{p}_{t|0}(H_{t}|X_{0})-\\nabla_{H_{t}}\\ln p_{t}(H_{t})\\Big|Y=y,H_{t}=x\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h_{t}^{*}(\\pmb{x},\\pmb{y})=\\int(\\nabla_{x}\\ln\\vec{p}_{t\\mid0}(\\pmb{x}|\\pmb{x}_{0})-\\nabla_{x}\\ln p_{t}(\\pmb{x}))\\overline{{p}}_{0\\mid t}(x_{0}|\\pmb{H}_{t}=\\pmb{x},\\pmb{Y}=\\pmb{y})\\mathrm{d}x_{0}}\\\\ &{\\qquad\\quad=\\int\\nabla_{x}\\ln\\vec{p}_{t\\mid0}(\\pmb{x}|x_{0})\\overline{{p}}_{0\\mid t}(x_{0}|\\pmb{H}_{t}=\\pmb{x},\\pmb{Y}=\\pmb{y})\\mathrm{d}x_{0}-\\nabla_{x}\\ln p_{t}(\\pmb{x})}\\\\ &{\\qquad\\quad=\\nabla_{x}\\ln p_{t}(\\pmb{x}|\\pmb{y})-\\nabla_{x}\\ln p_{t}(\\pmb{x})=\\nabla_{x}\\ln p_{t}(\\pmb{y}|\\pmb{x}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "E Experimental details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "E.1 Image Experiments ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In the image experiment, we use the DDPM [28] formulation for the diffusion model with $N=1000$ steps, a linear $\\beta.$ -schedule with $\\beta_{0}=10^{-4}$ and $\\beta_{N}=2\\cdot10^{-2}$ . In all our imaging experiments the $h$ -transform was implemented according to the parametrisation in Section 3.3 using an attention U-Net [16] for $\\mathbf{NN}_{1}^{\\phi}$ . The network $\\mathbf{N}\\mathbf{N}_{2}^{\\phi}$ in the residual pathway was implemented as a small three layer fully connected network with SiLU activation functions, predicting a single scalar value. The final layer in $\\mathbf{NN}_{1}^{\\phi}$ was initialised with zeros. All weights in $\\mathbf{NN}_{2}^{\\phi}$ where initialised with zeros, expect for the bias in the last layer, which was initialised to 0.01. We found that this initialisation was stable over all imaging tasks, i.e., close to the unconditional model. All tasks on ImageNet were noiseless, i.e., the log-likelihood $p(\\pmb{x}|\\pmb{y})$ would be a Delta function. However, for the guidance term $\\nabla_{\\hat{\\pmb{x}}_{0}}\\ln p(\\pmb{y}|\\hat{\\pmb{x}}_{0})$ we always approximated the log-likelihood using a Gaussian with $\\sigma_{y}=1.0$ . ", "page_idx": 20}, {"type": "text", "text": "Computed Tomography The 2016 American Association of Physicists in Medicine (AAPM) grand challenge dataset [45] contains CT scans of 10 patients. We only make use of the abdomen scans. We use the scans of 9 patients to train both the unconditional model and the $h$ -transform. The remaining patient, i.e., id L035 with 87 slices, is used for testing only. We used a bilinear interpolation to resize the images to $256\\times256\\mathrm{px}$ . The unconditional model follows the same architecture as in [11] with about 374M parameters. The model was trained for 300 epochs using the Adam optimiser [33]. We used exponential moving average on the weights as in [66] with a parameter of 0.999. ", "page_idx": 20}, {"type": "text", "text": "The LoDoPab-CT dataset [35] is a collection of human chest CT scans. We resize the images to $256\\times256\\mathrm{px}$ using a bilinear interpolation. The training set contains 35820 images and was used to train the unconditional diffusion model. The validation set contains 3522 images and was used to train the $h$ -transform model and for a hyperparameter search for DPS and RED-diff. Finally, we take 178 images (every 20th) from the test set to compute the final results. The unconditional model is an attention U-Net [16] with about 133M parameters. The unconditional model was trained for 75 epochs, corresponding to about 671625 gradient steps using the Adam optimiser [33]. We used exponential moving average on the weights as in [66] with a parameter of 0.999. ", "page_idx": 20}, {"type": "text", "text": "For both datasets we used the same parametrisation for the $h$ -transform, with an attention U-Net [16] and a residual path as in Section 3.3. The $h$ -transform has about 23M parameters. Thus, the $h$ -transform is about $6\\%$ and $17\\%$ the size of the unconditional model for AAPM and LoDoPab-CT, respectively. For LoDoPab-CT, the $h$ -transform was trained on a set of 3522 images, while for AAPM we trained the $h$ -transform on the same dataset as the unconditional model. The forward operator $A$ is linear and we added Gaussian noise with standard deviation $\\sigma_{y}=1.0$ . Thus, the gradient of the log likelihood reduces to ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\nabla_{\\hat{\\pmb{x}}_{0}}\\ln p({\\pmb y}|\\hat{\\pmb x}_{0})=-\\frac{1}{2\\sigma_{y}^{2}}A^{*}(A\\hat{\\pmb x}_{0}-{\\pmb y}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $A^{*}$ denotes the backprojection. Here, instead of the backprojection, we made use of the flitered backprojection, which is a common technique for computed tomography [25]. ", "page_idx": 20}, {"type": "text", "text": "Inpainting We made use of the pre-trained ImageNet dataset. For this task, we also amortised over the different sampling masks. We implemented the $h$ -transform using an attention U-Net [16] as the base network $\\mathrm{NN_{1}}$ with an initial convolution with 13 channels, i.e., the noisy image $\\pmb{x}_{t}$ , the denoised estimate $\\hat{\\pmb{x}}_{0}$ , the observation $\\textit{\\textbf{y}}$ (where the missing pixels fliled with zeros), the mask $M$ and the cheap guidance term $\\nabla_{\\hat{\\pmb{x}}_{0}}\\ln p(\\pmb{y}|\\hat{\\pmb{x}}_{0})$ . The pre-trained unconditional score model has 550M parameters, and we use a fine-tuning network with 23M parameters $(4.2\\%$ of the size). The fine-tuning network was trained for 200 epochs using a batch size of 16, and the Adam optimiser with a learning rate of $5e^{-4}$ and annealing. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Super-resolution We made use of the pre-trained ImageNet dataset. We implemented the $h$ - transform using an attention U-Net [16] as the base network $\\mathrm{{NN}_{1}}$ with an initial convolution with 9 channels, i.e., the noisy image $\\pmb{x}_{t}$ , the denoised estimate $\\hat{\\pmb{x}}_{0}$ , the observation $\\textit{\\textbf{y}}$ bilinear upsampled to the original size and the cheap guidance term $\\nabla_{\\hat{\\pmb{x}}_{0}}\\ln p(\\pmb{y}|\\hat{\\pmb{x}}_{0})$ . The pre-trained unconditional score model has 550M parameters, and we use a fine-tuning network with $23\\mathbf{M}$ parameters $4.2\\%$ of the size). The fine-tuning network was trained for 200 epochs using a batch size of 16, and the Adam optimiser with a learning rate of $5e^{-4}$ and annealing. ", "page_idx": 21}, {"type": "text", "text": "HDR For HDR the forward operator is given by $\\pmb{\\mathscr{A}}(\\pmb{x})=\\mathrm{clip}(2x;-1,1)$ for the RGB image scaled to $[-1,1]$ . This leads to a reduction of high intensity values. We approximated the cheap guidance term ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\nabla_{\\hat{\\pmb{x}}_{0}}\\ln p(\\pmb{y}|\\hat{\\pmb{x}}_{0})\\approx0.5(A(\\hat{\\pmb{x}}_{0})-\\pmb{y}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and found this to achieve good results. The pre-trained unconditional score model has 550M parameters, and we use a fine-tuning network with 23M parameters $(4.2\\%$ of the size). The finetuning network was trained for 200 epochs using a batch size of 16, and the Adam optimiser with a learning rate of $5e^{-4}$ and annealing. ", "page_idx": 21}, {"type": "text", "text": "Phase retrieval The $h$ -transform was again implemented as an attention U-Net [16] as the base network $\\mathrm{{NN}_{1}}$ . The observations in phase retrieval corresponds to the magnitude values of the Fourier transform. In our initial experiments, we feed these observation directly into the model. However, this model failed to create convincing reconstruction. Instead we used two rough reconstruction. For the first initial reconstruction, we used the phase of the unconditional Tweedie estimate $\\hat{\\pmb{x}}_{0}$ and the magnitude of the observation to construct an image. For the second initial reconstruction, we ran 350 steps of an ER algorithm [21] with a random initialisation. Further, we used the cheap guidance term $\\nabla_{\\hat{\\pmb{x}}_{0}}\\|\\pmb{y}-\\mathcal{A}(\\hat{\\pmb{x}}_{0})\\|_{2}^{2}$ , calculated using torch autograd. The $h$ -transform had about 23M parameter, i.e., $4\\%$ of the size of the unconditional model. ", "page_idx": 21}, {"type": "text", "text": "Non-linear Deblurring For non-linear deblurring we found that there was little improvement when using the cheap guidance term $\\nabla_{\\hat{\\pmb{x}}_{0}}\\|\\pmb{y}-\\mathcal{A}(\\hat{\\pmb{x}}_{0})\\|_{2}^{\\mathcal{T}}$ , calculated using torch autograd. As the forward operator is defined by a trained neural network this additional autograd term adds to the computational expense. We found that the DEFT provided results of a similar quality, with a reduced computational burden, by using $\\boldsymbol{A}(\\boldsymbol{\\mathcal{A}}(\\hat{\\mathbf{x}}_{0})-\\mathbf{\\boldsymbol{y}})$ as a rough approximation. The pre-trained unconditional score model has 550M parameters, and we use a fine-tuning network with 23M parameters $4.2\\%$ of the size). The fine-tuning network was trained for 200 epochs using a batch size of 16, and the Adam optimiser with a learning rate of $5e^{-4}$ and annealing. ", "page_idx": 21}, {"type": "text", "text": "E.2 Protein Motif Scaffolding ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Diffusion process We use a discrete-time DDPM [28] formulation for the diffusion model with $N=1000$ steps and cosine $\\beta$ -schedule [16]. ", "page_idx": 21}, {"type": "text", "text": "Noise model The denoising model $\\varepsilon_{\\theta}$ is adapted from the Genie diffusion model [37]. In Genie, the denoiser architecture consists of an SE(3)-invariant encoder and an SE(3)-equivariant decoder. While the network uses Frenet-Serret frames as intermediate representations, the diffusion process itself is defined in Euclidean space over the $C_{\\alpha}$ coordinates. Similar to AlphaFold2, the denoiser network consists of a single representation track that is initialised via a single feature network and a pair representation track that is initialised via a pair feature network. These two representations are further transformed via a pair transform network and are used in the decoder for noise prediction via IPA [30]. ", "page_idx": 21}, {"type": "text", "text": "To evaluate unconditional sampling-based methods, we used a pre-trained version of the unconditional Genie model. ", "page_idx": 21}, {"type": "text", "text": "To evaluate the AMORTISED approach (Alg. 4), we perform a minor modification to the unconditional Genie model as described in [17]: we add an additional conditional pair feature network that takes the motif frames as input with the ground truth coordinates for the motif and 0 as values for all other coordinates that are not part of the motif. The output of this motif-conditional pair feature network is concatenated with the output of the unconditional pair feature network to form an intermediate dimension of twice the channel size compared to the unconditional model before being linearly projected down to the channel size of the unconditional model. From then onward the output is processed by the remaining Genie components as in the unconditional model. The implementation is therefore similar to the image case, where the motif features are presented as additional input and the model learns to use these for reconstructing the motif. This minor alteration of the Genie architecture means that the amortised network has 4.162M parameters while the unconditional Genie networks have 4.087M parameters $\\sim1.8\\%$ fewer). In $80\\%$ of the training steps for the amortised model, we pass a condition to the network. The other $20\\%$ contains an empty mask consisting of only 0\u2019s. ", "page_idx": 22}, {"type": "text", "text": "For the DEFT implementation, we follow a similar way of feeding in the additional inputs via conditional pair feature networks, but as part of the downsized h-transform model as described in the main text. ", "page_idx": 22}, {"type": "text", "text": "Metrics We measure the performance of the methods across two axes: designability and success rate. To assess whether a particular protein scaffold is designable, we run the same pipeline as [37], consisting of an inverse folding generated $C_{\\alpha}$ backbones with ProteinMPNN and then re-folding the designed sequences via ESMFold. The considered metrics and their corresponding thresholds are the following: ", "page_idx": 22}, {"type": "text", "text": "\u2022 $\\mathrm{scTM}>0.5$ : This refers to the TM-score between the structure that\u2019s been designed and the predicted structure based on self-consistency as previously described. The scTM-score ranges from 0 to 1. Higher scores indicate a higher likelihood that the input structure can be designed.   \n\u2022 $\\mathrm{scRMSD}<2\\ ,$ \u00c5 : The scRMSD metric is akin to the scTM metric. However, it uses the RMSD (Root Mean Square Deviation) to measure the difference between the designed and predicted structures, instead of the TM-score. This metric is more stringent than scTM as RMSD, being a local metric, is more sensitive to minor structural variances.   \n\u2022 $\\mathtt{p L D D T}\\!>\\!70$ and pAE $<5$ : Both scTM and scRMSD metrics depend on a structure prediction method like AlphaFold2 or ESMFold to be reliable. Hence, additional confidence metrics such as pLDDT and pAE are employed to ascertain the reliability of the self-consistency metrics. ", "page_idx": 22}, {"type": "text", "text": "In addition, we want to judge whether the motif scaffolding was successful or not. Therefore, similar to previous work by [77], we calculate the motifRMSD between the predicted design structure and the original input motif and judge samples with $<1\\,\\mathring{\\mathsf{A}}$ motifRMSD as a successful motif scaffold. ", "page_idx": 22}, {"type": "text", "text": "We follow previous work and call a sample a \"success\" if $\\mathrm{scRMSD}<2\\mathrm{~\\AA~}$ and motifRMSD $<1\\,\\mathring{\\mathsf{A}}$ . Similar to previous work we call a task \"solved\" if among 100 samples for this task at least 1 sample is a success. ", "page_idx": 22}, {"type": "text", "text": "F Additional Results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "F.1 Ablation of the DEFT parametrisation ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The parametrisation of the $h$ -transform is motivated by the sampling theory in Section 3.3. We evaluate different parametrisations of this choice for the CT experiment on LoDoPab-CT. For all architecture choices, we used the same training setup. For quantitative results, see Table 6. In particular, we see that the naive choice $\\mathbf{NN}_{1}^{\\phi}(\\pmb{x},A^{*}\\pmb{y},t)$ only achieves a PSNR of 26.62dB. Note, that we do not input the observations directly into the network, but first transform them using the backprojection, which is a standard technique for computed tomography reconstruction [3]. In CT the observations correspond to sinograms and have a different geometry to the images. In difference, if we add the unconditional Tweedie estimate $\\hat{\\pmb{x}}_{0}$ to the model architecture, we get an improvement to $\\mathrm{34.04dB}$ . This shows that it is beneficial to supply the $h$ -transform with the information of the unconditional diffusion model. Further, given our architecture, i.e., adding the additional information ", "page_idx": 22}, {"type": "text", "text": "Trained residual scaling $\\mathsf{N N}_{2}^{\\phi}(t)$ ", "page_idx": 23}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/8cbb5fd01fce45177bdd1d209cdc7dbb0ca2d6c158371d94a7f82c37f5dec46c.jpg", "img_caption": ["Figure 6: The trained residual scaling network $\\mathbf{NN}_{2}^{\\phi}$ in the DEFT architecture (see Section 3.3) for computed tomography reconstruction on LoDoPab-CT and AAPM. "], "img_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "AKBTFQhCjm/tmp/ca14e53d2b0f7f086150d78a761911bc9b61d015f5efd477200dc17768c92878.jpg", "table_caption": ["Table 6: PSNR and SSIM for computed tomography on LoDoPab-CT with different parametrisation of the $h$ -transform. "], "table_footnote": ["Table 7: Results on the non-linear blurring operator from [44], where both methods achieve very high reconstruction and perceptual clarity due to the operator resulting in a trivial forward operation, rather than a non-linear blur. On this task, we still find DEFT to outperform RED-diff, with less time taken overall. "], "page_idx": 23}, {"type": "text", "text": "of the log-likelihood term, achieves a PSNR of 35.81dB. Further, we show the learning residual scaling network $\\mathbf{NN}_{2}^{\\phi}$ in Figure 6. We observe a similar behaviour for all tasks,i.e., at the start of sampling $t\\approx1000$ the scaling network assigned a small weighting to the guidance part, which increases during sampling $(t\\rightarrow0)$ ). ", "page_idx": 23}, {"type": "text", "text": "F.2 Non-linear Deblurring: Implementation from [44] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We find that the original implementation of the non-linear forward operator from the codebase provided in [44] results in an almost trivial reconstruction task, due to incorrect loading of weights for the neural network used for the non-linear deblurring. As a result, both RED-diff and DEFT can achieve highly performant results on this trivial task, as shown in Table 7. For the non-linear deblurring tasks in the main text in Table 2, we load the weights for the neural network correctly, and see much lower performance, corresponding to the difficulty of the non-linear task. ", "page_idx": 23}, {"type": "text", "text": "G Generalised $h$ -transform and Stochastic Control ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Thanks to our formal framework in this section we develop a new VI objective for learning the conditional score in the noisy inverse problems setting. That is by minimising the following ELBO ", "page_idx": 23}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/33689ff8306ee6306c934f69f7881c4d1906a6885154a2152b49778dc6ecdcff.jpg", "img_caption": ["Figure 7: Example reconstructions for phase retrieval. Phase retrieval has many local minima, which fully satisfy the data consistency constraints (e.g., complex conjugate, global phase sign). We often see flipped (and perturbed) images as our reconstruction. In some instances, even only one colour channel is flipped. This leads to a strong diversity of samples. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/a1fc9d0d06dcf90b4d10e7540abdd1fdf0097d162382a9b8163973216161bb3f.jpg", "img_caption": ["Figure 8: Diversity of samples for inpainting. On the left, we show the inpainting mask as a overlay over the ground truth. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "with respect to an additional fine-tuning network, one can learn the conditional score ", "page_idx": 24}, {"type": "equation", "text": "$$\nh^{*}=\\arg\\operatorname*{min}_{f}\\mathbb{E}_{\\mathbb{Q}}\\left[\\frac{1}{2}\\int_{0}^{T}\\sigma_{t}^{2}||h(H_{t})||^{2}\\mathrm{d}t\\right]-\\mathbb{E}_{H_{0}\\sim\\mathbb{Q}_{0}}[\\ln p(y|H_{0})],\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $H_{t}$ follows the unconditioned score SDE with an added control $h$ . This objective provides a way to learn the conditioned SDE from the unconditioned one, without making Gaussian approximations. We formalise this connection in the following proposition. ", "page_idx": 24}, {"type": "text", "text": "Proposition G.1. The following stochastic control problem ", "page_idx": 24}, {"type": "equation", "text": "$$\nh^{*}=\\arg\\operatorname*{min}_{f}\\mathbb{E}_{\\mathbb{Q}}\\left[\\frac{1}{2}\\int_{0}^{T}\\sigma_{t}^{2}||h(H_{t})||^{2}\\mathrm{d}t\\right]-\\mathbb{E}_{H_{0}\\sim\\mathbb{Q}_{0}}[\\ln p(y|H_{0})]\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "with ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad H_{T}\\sim Q_{T}^{f_{t}}[p(\\mathbf{x}_{0}|y)]}\\\\ &{\\qquad\\mathrm{d}H_{t}=\\left(f_{t}(H_{t})-\\sigma_{t}^{2}(\\nabla_{H_{t}}\\ln p_{t}(H_{t})+h_{t}(H_{t}))\\right)\\,\\mathrm{d}t+\\sigma_{t}\\,\\overleftarrow{\\mathrm{d}\\mathbf{W}}_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/52c95abebf96d2ef62509f2b098b5a72623d8eb3c8558669f48a3dd8178c8e8d.jpg", "img_caption": ["Figure 9: Results for 4x super-resolution. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/6044b8d4f46b0e7d4f8c7cde47b2213e02b99ca8337a4cefa26cf84472eeddf4.jpg", "img_caption": ["Figure 10: Results for non-linear HDR. Similar to [44], we found that DPS does not converge to a good solution, returning often black or images not consistent with the ground truth. Given that the forward operator $\\mathcal{A}(\\pmb{x})\\bar{\\phantom{*}}=\\mathrm{clip}(2\\pmb{x}|-1,1)$ has a zero gradient for $|\\pmb{x}|\\geq0.5$ the guidance term is often not informative. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "is minimised by the conditional score SDE in Equation (28), that is ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{h_{t}^{*}(\\pmb{x})=\\nabla_{\\pmb{x}}\\ln\\mathbb{E}_{\\pmb{X}_{0}\\sim p_{0\\mid t}(\\cdot|\\pmb{x})}[p(\\pmb{y}|\\pmb{X}_{0})]=\\nabla_{\\pmb{x}}\\ln p_{y\\mid t}(\\pmb{y}|\\pmb{x}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Furthermore, $h^{*}$ solves an associated half-bridge problem $I7J$ with the SDE in Eqn. (3) as its reference process and $p(x_{0}|y)$ as its source distribution. ", "page_idx": 25}, {"type": "text", "text": "Proof. The derivation for this objective is inspired by the sequential Bayesian learning scheme proposed in Lemma 1, Appendix $\\mathbf{B}$ of [75]. ", "page_idx": 25}, {"type": "text", "text": "Let $\\mathbb{P}$ denote the distribution for the forward SDE in Eqn. (25). Now consider the following variational problem termed a half-bridge [7, 15, 73]. ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{Q}^{*}=\\operatorname*{arg\\,min}_{\\mathbb{Q}:\\mathbb{Q}_{0}=p(x_{0}|y)}D_{\\mathrm{KL}}(\\mathbb{Q}||\\mathbb{P})\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the constraint enforces that at time 0 we hit the target posterior $p(\\pmb{x}|\\pmb{y})$ then via standard results in half bridges we know that the above optimisation problem has an unconstrained formulation (e.g. ", "page_idx": 25}, {"type": "text", "text": "see [74]) that is $\\begin{array}{r}{\\mathrm{d}\\mathbb{Q}^{*}=\\mathrm{d}\\mathbb{P}\\frac{\\mathrm{d}p\\left(\\pmb{x}|\\pmb{y}\\right)}{\\mathrm{d}\\mathbb{P}_{0}}}\\end{array}$ Now following [75] we notice that we can cancel the $p_{\\mathrm{data}}$ prior in the posterior term: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbb{P}\\frac{\\mathrm{d}p(\\pmb{x}|\\pmb{y})}{\\mathrm{d}\\mathbb{P}_{0}}=\\mathrm{d}\\mathbb{P}\\frac{\\mathrm{d}p(\\pmb{x}|\\pmb{y})}{\\mathrm{d}p_{\\mathrm{data}}}=\\mathrm{d}\\mathbb{P}\\frac{\\mathrm{d}p(\\pmb{y}|\\pmb{x})}{\\mathrm{d}p(\\pmb{y})}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and thus: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{Q}^{*}=\\operatorname*{arg\\,min}_{\\mathbb{Q}}D_{\\mathrm{KL}}(\\mathbb{Q}||\\mathbb{P})-\\mathbb{E}_{H_{0}\\sim\\mathbb{Q}_{0}}[\\ln p(\\pmb{y}|H_{0})]\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "with $\\mathbb{Q}_{T}=\\operatorname{Law}\\left(X_{T}\\right)\\approx\\mathcal{N}(0,\\mathbf{I})$ when $X_{0}\\sim p(x|y)$ . Furthermore, we can parametrise $\\mathbb{P}$ as : ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathrm{d}X_{t}=\\left(f_{t}(X_{t})-\\sigma_{t}^{2}\\nabla_{X_{t}}\\ln p_{t}(X_{t})\\right)\\mathrm{d}t+\\sigma_{t}\\overline{{\\mathrm{d}\\mathbf{W}_{t}}},\\quad X_{0}\\sim Q_{T}^{f_{t}}[p_{\\mathrm{data}}(x_{0})]\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and thus $\\mathbb{Q}$ as ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H_{T}\\sim Q_{T}^{f_{t}}[p(x_{0}|y)]}\\\\ &{\\mathrm{d}H_{t}=\\big(f_{t}(H_{t})-\\sigma_{t}^{2}(\\nabla_{H_{t}}\\ln p_{t}(H_{t})+h_{t}(H_{t}))\\big)\\ \\mathrm{d}t+\\sigma_{t}\\ \\overline{{\\mathrm{d}{\\mathbf{W}}}}_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "then via Girsanov Theorem we can re-express the KL term in Eqn. (43) as ", "page_idx": 26}, {"type": "equation", "text": "$$\nh^{*}=\\arg\\operatorname*{min}_{h}\\mathbb{E}_{\\mathbb{Q}}\\left[\\frac{1}{2}\\int_{0}^{T}\\sigma_{t}^{2}||h(H_{t})||^{2}\\mathrm{d}t\\right]-\\mathbb{E}_{H_{0}\\sim\\mathbb{Q}_{0}}[\\ln p(y|H_{0})].\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Now noticing that Eqn. (46) is a standard stochastic control problem [48, 31] we can characterise its minimiser as (using Theorem 2.2 in [48] and the Hopf-Cole transform [23]) ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{h_{t}^{*}(\\pmb{x})=\\nabla_{\\pmb{x}}\\ln\\mathbb{E}_{\\pmb{X}_{0}\\sim p_{0\\mid t}(\\cdot|\\pmb{x})}[p(\\pmb{y}|\\pmb{X}_{0})],}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and thus the SDE in Eqn. 45 with $h_{t}^{*}$ hits the target posterior $p(\\pmb{y}|\\pmb{x}_{0})$ at time 0 as it is the minimiser of half-bridge posed in Eqn. (41). \u53e3 ", "page_idx": 26}, {"type": "text", "text": "Notice that in the case of a VP-SDE, the stochastic control objective reduces to: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\arg\\operatorname*{min}_{h}\\mathbb{E}_{\\mathbb{Q}}\\left[\\int_{0}^{T}\\frac{\\beta_{t}}{2}||h(\\pmb{H}_{t})||^{2}\\mathrm{d}t\\right]-\\mathbb{E}_{\\pmb{H}_{0}\\sim\\mathbb{Q}_{0}}[\\ln p(\\pmb{y}|\\pmb{H}_{0})]\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Discretisation of inverse problem objective Following [74] we will discretise the objective presented in Eqn. (48). Let us consider the pre-trained score SDE with an added tuning network: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad H_{T}\\sim\\mathcal{N}(0,I)}\\\\ &{\\qquad\\mathrm{d}H_{t}=-\\beta_{t}(H_{t}+2s_{\\theta}(H_{t})+2h_{\\phi}(H_{t}))\\,\\mathrm{d}t+\\sqrt{2\\beta_{t}}\\,\\frac{1}{\\mathrm{d}\\mathbf{W}_{t}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "now using an exponential-like discretisation [10] (Ideally we want to discretise in the same way we trained the model): ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{c}{H_{t_{K}}\\sim\\mathcal{N}(0,I)}\\\\ {H_{t-1}=\\left(\\sqrt{1-\\alpha_{k}}H_{t_{k}}+2(1-\\sqrt{1-\\alpha_{k}})\\left(s_{\\theta^{*}}(H_{t_{k}})+h_{\\phi}(H_{t_{k}})\\right)\\right)+\\sqrt{\\alpha_{k}}\\varepsilon_{k},}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\begin{array}{r}{\\alpha_{k}=1-\\exp\\left(\\int_{t_{k-1}}^{t_{k}}\\beta_{s}\\mathrm{d}s\\right)}\\end{array}$ , note we will denote the distribution of the above discrete time chain as $q_{\\phi}$ . Now if we follow the sketch in Proposition 3 of [74] the discretised objective then becomes: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\underset{\\phi}{\\arg\\operatorname*{min}}\\mathbb{E}_{H\\sim q_{\\phi}}\\left[2\\sum_{k=1}^{K}\\frac{\\lambda_{k}^{2}}{\\alpha_{k}}||h_{\\phi}(k,H_{t_{k}})||^{2}-\\ln p(\\pmb{y}|\\pmb{H}_{0})\\right]\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\lambda_{k}\\,=\\,1\\mathrm{~-~}\\sqrt{1-\\alpha_{k}}$ . For a more stable/simple objective following [74] we can make the approximation $\\lambda_{k}=1-\\sqrt{1-\\alpha_{k}}\\approx\\alpha_{k}/2$ for small time steps. This leads to the following iteration (which is possibly more akin to the training update being used): ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{c}{H_{t_{K}}\\sim\\mathcal{N}(0,I)}\\\\ {H_{t_{k-1}}=\\left(\\sqrt{1-\\alpha_{k}}H_{t_{k}}+\\alpha_{k}\\left(s_{\\theta^{*}}(H_{t_{k}})+h_{\\phi}(H_{t_{k}})\\right)\\right)+\\sqrt{\\alpha_{k}}\\varepsilon_{k},}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and objective: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\underset{\\phi}{\\arg\\operatorname*{min}}\\mathbb{E}_{H\\sim q_{\\phi}}\\left[\\sum_{k=1}^{K}\\frac{\\alpha_{k}}{2}||h_{\\phi}(k,H_{t_{k}})||^{2}-\\ln p(y|H_{0})\\right].\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Discrete Time Intuition For further intuition, we will provide a discrete-time derivation as to how this objective arises. Consider the following discrete-time VP-SDE (i.e let. $p_{k+1|k}(\\pmb{h}_{t_{k+1}}|\\pmb{h}_{t_{k}})=$ $\\mathcal{N}(h_{t_{k+1}}|\\sqrt{1-\\alpha_{k}}h_{t_{k}},\\alpha_{k}))$ starting from the posterior: ", "page_idx": 27}, {"type": "equation", "text": "$$\np({\\pmb h}_{t_{1}:t_{k}})=\\frac{p({\\pmb y}|{\\pmb h}_{0})p_{\\mathrm{data}}({\\pmb h}_{0})}{p({\\pmb y})}\\prod_{k=1}^{K}p_{k+1|k}({\\pmb h}_{t_{k+1}}|{\\pmb h}_{t_{k}})\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Now applying Bayes rule and [2, Section 5] $\\begin{array}{r}{p_{k+1|k}(h_{t_{k+1}}|h_{t_{k}})=\\frac{p_{k|k+1}^{\\mathrm{uncnd}}(h_{t_{k}}|h_{t_{k+1}})p_{k+1}^{\\mathrm{uncnd}}(h_{t_{k+1}})}{p_{k}^{\\mathrm{uncnd}}(h_{t_{k}})}}\\end{array}$ and telescoping to cancel the marginals we have: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{p({h_{t_{1}:t_{k}}})=\\frac{p_{K}^{\\mathrm{uncnd}}(h_{T})p(\\pmb{y}|h_{0})\\,\\hat{p}_{\\mathrm{data}}(h_{0})}{p(\\pmb{y})\\,\\,\\hat{\\beta}_{\\mathrm{data}}(h_{0})}\\prod_{k=1}^{K}p_{k+1|k}^{\\mathrm{uncnd}}(h_{t_{k+1}}|{h_{t_{k}}})}\\\\ &{\\quad\\quad\\quad=\\frac{p_{K}^{\\mathrm{uncnd}}(h_{T})p(\\pmb{y}|h_{0})}{p(\\pmb{y})}\\prod_{k=1}^{K}p_{k+1|k}^{\\mathrm{uncnd}}(h_{t_{k+1}}|{h_{t_{k}}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $p_{k|k+1}^{\\mathrm{uncnd}}(h_{t_{k}}|{\\pmb g}_{t_{k+1}})$ is the transition density of the unconditional score SDE and $p_{k}^{\\mathrm{uncnd}}(h_{t_{k}})$ correspond to its marginals. Now we would like to learn a backwards process that matches the above process (reverses the VP-SDE starting from the posterior). We can do so by minimising the KL: ", "page_idx": 27}, {"type": "equation", "text": "$$\nD_{\\mathrm{KL}}(q^{\\phi}||p)\\propto\\mathbb{E}_{q}\\left[\\ln\\frac{\\prod_{k}q_{k|k+1}^{\\phi}(h_{t_{k}}|h_{t_{k+1}})}{\\prod_{k}p_{k|k+1}^{\\mathrm{uncnd}}(h_{t_{k}}|h_{t_{k+1}})}-\\ln p(\\pmb{y}|\\pmb{h}_{0})\\right]\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where we can approximate the score transition via: ", "page_idx": 27}, {"type": "equation", "text": "$$\np_{k-1|k}^{\\mathrm{uncnd}}(h_{t_{k}}|h_{t_{k+1}})\\approx\\mathcal{N}(h_{t_{k-1}}|\\sqrt{1-\\alpha_{k}}h_{t_{k}}+2(1-\\sqrt{1-\\alpha_{k}})s_{\\theta^{*}}(h_{t_{k}}),\\alpha_{k})\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and parametrise the new conditional denoiser as ", "page_idx": 27}, {"type": "equation", "text": "$$\nq_{k-1|k}^{\\phi}(h_{t_{k}}|h_{t_{k+1}})=\\mathcal{N}(h_{t_{k-1}}|\\sqrt{1-\\alpha_{k}}h_{t_{k}}+2(1-\\sqrt{1-\\alpha_{k}})\\left(s_{\\theta^{*}}(h_{t_{k}})+h_{\\phi}(h_{t_{k}})\\right),\\alpha_{k})\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "making these two substitutions will lead to the objective in Eqn. (53). ", "page_idx": 27}, {"type": "text", "text": "G.1 Related Work ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Fine-tuning diffusion models via a optimal control perspective, e.g., devolved in [6], has received a lot of attention in recent years. In particular, in the context of fine-tuning with respect to a differentiable reward function, i.e., considering a tilted posterior [18], ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\pi(x_{0})=\\frac{e^{r({\\pmb x}_{0})}p_{\\mathrm{data}}({\\pmb x}_{0})}{\\mathcal{Z}},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $e^{r(\\pmb{x}_{0})}$ serves an equivalent role to the likelihood $p(\\pmb{y}|\\pmb{x}_{0})$ in our setting. ", "page_idx": 27}, {"type": "text", "text": "The DRaFT framework [13] proposes a heuristic method to estimate the $h$ -transform by only optimising the reward function. We want to highly that concurrently [72] develop the same stochastic control formulation as we do, and arrive at the same insight that the optimal starting distribution is given by $p_{T}=Q_{T}^{f_{t}}[\\pi]$ , however, they chose to learn this distribution which we argue is not necessary for diffusion models due to the mixing property of the OU process leading to a negligible error by approximating $Q_{T}^{f_{t}}[\\pi]\\approx\\mathcal{N}(0,I)$ with a Gaussian. ", "page_idx": 27}, {"type": "text", "text": "G.2 Connection to [18] - Value Function Bias ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In [18], it is argued that minimising the stochastic control objective does not lead to hitting the posterior $p(x_{0}|\\bar{\\boldsymbol{y}})$ at time $t\\;=\\;0$ due to bias introduced by the value function. We can apply Proposition G.1 to the tilted posterior $\\pi(\\pmb{x}_{0})$ from (58) which yields the following objective: ", "page_idx": 27}, {"type": "equation", "text": "$$\nh^{*}=\\arg\\operatorname*{min}_{h}\\mathbb{E}_{\\mathbb{Q}}\\left[\\frac{1}{2}\\int_{0}^{T}\\sigma_{t}^{2}||h(\\pmb{H}_{t})||^{2}\\mathrm{d}t\\right]-\\mathbb{E}_{\\pmb{H}_{0}\\sim\\mathbb{Q}_{0}}[r(\\pmb{H}_{0})]\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "with ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H_{T}\\sim Q_{T}^{f_{t}}[p(x_{0}|y)]}\\\\ &{\\mathrm{d}H_{t}=\\left(f_{t}(H_{t})-\\sigma_{t}^{2}(\\nabla_{H_{t}}\\ln p_{t}(H_{t})+h_{t}(H_{t}))\\right)\\,\\mathrm{d}t+\\sigma_{t}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "then by Theorem 2.1 in [71] the optimal transition density of the controlled process is given by $(s\\leq t)$ : ", "page_idx": 28}, {"type": "equation", "text": "$$\np_{s|t}^{*}(\\pmb{x}|\\pmb{y})=e^{h(\\pmb{x},s)-h(\\pmb{y},t)}p_{s|t}^{\\mathrm{ref}}(\\pmb{x}|\\pmb{y})\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the $h$ -transform $h$ coincides with the negative of the value function in [18, 71]. Then for $s=0$ and $t=T$ this induces the following joint distribution: ", "page_idx": 28}, {"type": "equation", "text": "$$\np_{0,T}^{*}(\\pmb{x}|\\pmb{y})=e^{r(\\pmb{x})-\\ln\\mathcal{Z}-h(\\pmb{y},T)}p_{s|t}^{\\mathrm{ref}}(\\pmb{x}|\\pmb{y})p_{T}(\\pmb{y})\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where [18] argue that in general the term $e^{-h(\\pmb{y},T)}$ induces a bias such that when we marginalise out ${\\boldsymbol y}\\,,p_{0}^{*}({\\boldsymbol x})$ is not the tilted distribution, more precisely: ", "page_idx": 28}, {"type": "equation", "text": "$$\np_{0}^{*}(\\pmb{x})=e^{r(\\pmb{x})-\\ln\\mathcal{Z}}\\int e^{-h(\\pmb{y},T)}p_{0|T}^{\\mathrm{ref}}(\\pmb{x}|\\pmb{y})p_{T}(\\pmb{y})\\mathrm{d}\\pmb{y}\\neq\\frac{e^{r(\\pmb{x})}p_{\\mathrm{data}}(\\pmb{x})}{\\mathcal{Z}}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "However, let\u2019s look more closely as to why this is the case; first let us re-express the $_\\mathrm{h}$ -transform at time $T$ as a ratio of densities: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{e^{h({\\boldsymbol y},T)}=\\displaystyle\\int\\frac{\\mathrm{d}\\pi}{\\mathrm{d}p_{\\mathrm{data}}}(y_{0})p_{0|T}^{\\mathrm{ref}}(y_{0}|{\\boldsymbol y}_{T})\\mathrm{d}{\\boldsymbol y}_{0}}\\\\ &{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "substituting back into (62) and marginalizing we have: ", "page_idx": 28}, {"type": "equation", "text": "$$\np_{0}^{*}(\\pmb{x})=e^{r(\\pmb{x})-\\ln\\mathcal{Z}}\\int p_{0|T}^{\\mathrm{ref}}(\\pmb{x}|\\pmb{y})p_{T}(\\pmb{y})\\frac{p_{T}^{\\mathrm{ref}}(\\pmb{y})}{Q_{T}^{f_{t}}[\\pi](\\pmb{y})}\\mathrm{d}\\pmb{y}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "now notice $p_{T}(\\pmb{y})$ is the distribution we simulate our stochastic control from which in our case we have chosen to be $p_{T}=Q_{T}^{f_{t}}[\\pi]$ making the cancellation ", "page_idx": 28}, {"type": "equation", "text": "$$\np_{0}^{*}(\\pmb{x})=e^{r(\\pmb{x})-\\ln\\mathcal{Z}}\\int p_{0|T}^{\\mathrm{ref}}(\\pmb{x}|\\pmb{y})p_{T}^{\\mathrm{ref}}(\\pmb{y})\\mathrm{d}\\pmb{y}=\\frac{e^{r(\\pmb{x})}p_{\\mathrm{data}}(\\pmb{x})}{\\mathcal{Z}}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Leading us to the following remark ", "page_idx": 28}, {"type": "text", "text": "Remark 1. The choice of setting $p_{T}=Q_{T}^{f_{t}}[\\pi]$ leads to removing the value function bias [18] in Equation $^{63}$ . Note the authors of [18] pursue a different avenue for removing this bias by altering the noise of the controlled SDE. ", "page_idx": 28}, {"type": "text", "text": "Proposition G.2. (Value function bias when approximating $Q_{T}^{f_{t}}[\\pi]\\approx\\mathcal{N}(0,I))$ In practice, we often do not have access to $Q_{T}^{f_{t}}[\\pi]$ and thus we may make an approximation with some tractable distribution $p_{T}$ , then we can bound the value function bias as follows ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left\\Vert p_{0}^{*}(\\pmb{x})-\\frac{e^{r(\\pmb{x})}p_{\\mathrm{data}}(\\pmb{x})}{\\mathcal{Z}}\\right\\Vert_{\\mathrm{TV}}\\leq\\left\\Vert p_{T}-Q_{T}^{f}[\\pi]\\right\\Vert_{\\mathrm{TV}},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "then in the VP-SDE with a time homogenous $\\beta_{t}=\\beta$ based diffusion model (for simplicity), where chose $p_{T}=\\mathcal{N}(0,I)$ we can obtain a tight bound, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left\\Vert p_{0}^{*}(\\pmb{x})-\\frac{e^{r(\\pmb{x})}p_{\\mathrm{data}}(\\pmb{x})}{\\mathcal{Z}}\\right\\Vert_{\\mathrm{TV}}\\leq C e^{-\\beta T}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for some constant $C>0,$ , thus the value function bias $I I8J$ is exponentially small for score based diffusion models. ", "page_idx": 28}, {"type": "text", "text": "Proof. Applying Theorem 17 from [15] we have: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|p_{0}^{*}(\\pmb{x})-\\frac{e^{r(\\pmb{x})}p_{\\mathrm{data}}(\\pmb{x})}{\\mathcal{Z}}\\right\\|_{\\mathrm{TV}}=\\left\\|P_{0}^{f_{t}+h_{t}^{*}}[N(0,I)]-P_{0}^{f_{t}+h_{t}^{*}}[Q^{f}[\\pi]]\\right\\|_{\\mathrm{TV}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\left\\|\\mathcal{N}(0,I)-Q_{T}^{f}[\\pi]\\right\\|_{\\mathrm{TV}}=C e^{-\\beta T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "the final equality follows from the mixing properties of the OU process [4], where ", "page_idx": 29}, {"type": "equation", "text": "$$\nP_{0}^{f_{t}+h_{t}^{*}}[\\mu](\\pmb{x})=\\int p_{0|T}^{*}(\\pmb{x}|\\pmb{y})\\mu(\\pmb{x})\\mathrm{d}\\pmb{y}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Finally we want to highlight that the benefits of Proposition G.2 can only be leveraged in score matching settings where we have a clear characterisation of the forward process and we are able to tractably characterise $p_{0}^{\\ast}$ however in settings such as flow matching [38, 41] and stochastic interpolants [1] where the forward process is not explicitly characterised we wither have to learn $p_{0}^{*}$ like in [72] or use a memoryless noise schedule as proposed in [18]. ", "page_idx": 29}, {"type": "text", "text": "G.3 Scaling up the Control Objective ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Naively trying to minimise Eqn. (37) is demanding, as the full chain has to be kept in memory, which is infeasible for high dimensional problems. To alleviate this problem, one could make use of the stochastic adjoint sensitivity method [36], in which an adjoint SDE is solved to estimate the gradients of the stochastic control loss in Theorem 3.1 3). This method has the advantage of a constant memory cost. However, the computational cost increases as both the reverse SDE and the adjoint SDE must be simulated. Instead, we discuss two alternative approaches to reduce the memory requirements. ", "page_idx": 29}, {"type": "text", "text": "VarGrad We can make use of a VarGrad [53, 54] type loss to reduce the memory requirements. In contrast to the KL loss of Eqn. (37), then the VarGrad loss is given by: ", "page_idx": 29}, {"type": "equation", "text": "$$\nD_{\\mathrm{logvar}}(\\mathbb{Q},\\mathbb{P};\\mathbb{W})=\\mathbb{E}_{H_{0:T}^{g_{t}}\\sim\\mathbb{W}}\\left[\\left(\\ln\\frac{\\mathrm{d}\\mathbb{Q}}{\\mathrm{d}\\mathbb{P}}(H_{0:T}^{g_{t}})-\\mathbb{E}\\left[\\ln\\frac{\\mathrm{d}\\mathbb{Q}}{\\mathrm{d}\\mathbb{P}}(H_{0:T}^{g_{t}})\\right]\\right)^{2}\\right],\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\mathbb{Q}$ and $\\mathbb{P}$ are defined as in the proof of Proposition G.1, i.e., $\\mathbb{Q}$ is given by the conditional SDE and $\\mathbb{P}$ is given by the unconditional SDE. The RND in Eqn. (77) is evaluated at the trajectory of a reference process $\\mathbb{W}=\\operatorname{Law}(H_{0:T}^{g_{t}})$ , given by ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H_{T}\\sim Q_{T}^{f_{t}}[p(x_{0}|y)]}\\\\ &{\\mathrm{d}H_{t}=\\left(f_{t}(H_{t})-\\sigma_{t}^{2}(\\nabla_{H_{t}}\\ln p_{t}(H_{t})+g_{t}(H_{t}))\\right)\\,\\mathrm{d}t+\\sigma_{t}\\,\\overbrace{\\mathrm{d}\\mathbf{W}}_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The Radon\u2013Nikodym derivative (RND) in Eqn (75) can be evaluated as (Using the RND for time reverse SDEs see Equation 64 in [76]): ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ln\\frac{\\mathrm{d}\\mathbb{Q}}{\\mathrm{d}\\mathbb{P}}(H_{0:T}^{g_{t}})=-\\frac{1}{2}\\int_{0}^{T}\\sigma_{t}^{2}\\|h_{t}(H_{t}^{g_{t}})\\|^{2}\\mathrm{d}t+\\int_{0}^{T}\\sigma_{t}^{2}(g_{t}^{\\top}h_{t})(H_{t}^{g_{t}})\\mathrm{d}t-\\ln p(y|x_{0}^{g_{t}})}\\\\ &{\\qquad\\qquad\\qquad+\\int_{0}^{T}\\sigma_{t}h_{t}^{\\top}(H_{t}^{g_{t}})\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "for the reference process $\\mathbb{W}$ . The core advantage of VarGrad is that we can choose this reference process. In particular, the choice $g_{t}=\\mathrm{stop}_{-}\\mathrm{grad}(h_{t})$ gives us a way to detach the trajectories, saving us from having to score all gradients in memory. ", "page_idx": 29}, {"type": "text", "text": "Trajectory Balance An alternative to the VarGrad loss in Eqn. (75) is the following trajectory balance [42, 43] loss ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{TB}}^{\\mathrm{w}}(\\mathbb{Q},\\mathbb{P};k)=\\mathbb{E}_{H_{0:T}^{g_{t}}\\sim\\mathbb{W}}\\left[\\left(\\ln\\frac{\\mathrm{d}\\mathbb{Q}}{\\mathrm{d}\\mathbb{P}}\\left(H_{0:T}^{g_{t}}\\right)-k\\right)^{2}\\right],\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $k\\in\\mathbb{R}$ is a learnable parameter and $\\mathbb{W}$ is the same reference process as above. We again choose $g_{t}=\\mathrm{stop\\_grad}(h_{t})$ This loss is also motivated by a valid divergence, see [48]. In difference to the VarGrad loss (75), the inner expectation is exchanged with $k$ , which approximates a running mean. In practice, we optimise $k$ and and $h_{t}$ at the same time. ", "page_idx": 29}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/2f7a371ab15de292773a60a6a1d7a2de5ea1e1931029601268779d748c864af3.jpg", "img_caption": ["Figure 11: Left: Tracking the stochastic optimal control loss (37) for the three methods. Right: Mean PSNR of samples. "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "G.4 Stochastic Optimal Control - Experiments ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "We provide some initial proof of concept experiments on the MNIST dataset [34] of handwritten digits. In particular, we make use of a parallel beam Radon transform with 5 angles as the forward operator and perturb the observations with $10\\%$ additive Gaussian noise. All SDEs are discretised using an Euler-Maruyma scheme and the integrals are estimated using simple quadrature rules. We use a non-equidistant time grid according to a square root function, i.e., let $0=t_{0}\\leq\\dots\\leq t_{K-1}=1$ be an equidistant grid of $[0,1]$ for $K$ time points. We then use $t_{0}^{2},t_{1}^{2},\\ldots,t_{K-1}^{2}$ as the time points for evaluating the SDEs. This gives us a finer discretisation closer to $t=0$ . The unconditional MNIST model is based on the attention U-Net architecture [16] with about 3M parameters. The $h$ -transform is implemented using the same DEFT parametrisation as in Section 3.3 with about 70 000 parameters. We compare EM-backprop, i.e., directly backpropagting through the discrete SDE solver (see e.g. [36]), with VarGrad and TrajectoryBalance from Section G.3. For EM-backprop we use a batch size of 16 and use 60-80 time steps. Instead, for VarGrad and TrajectoryBalance we were able to use a batch size of 26 and 80-140 time steps. For training we used a single GeForce RTX 3090 and the training time took about 1h. The results are presented in Figure 11, where the loss trajectory of Eqn. (37) and the mean PSNR of samples is shown. Both VarGrad and TrajectoryBalance are able to minimise the stochastic optimal control objective to the same extend as EM-backprop. Further, in Figure 12 we provide an overview of the TrajectoryBalance training. Here, we observe that $k$ is working as a estimator of the mean RND with a lower variance. ", "page_idx": 30}, {"type": "text", "text": "H Amortised Conditional Training ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In this section, we discuss an objective for learning the full conditional score at training time in an amortised fashion instead of enforcing the constraint during inference time as before in reconstruction guidance approaches. This objective is akin to CDE [5] with the difference that we propose amortising over the the forward operator, for example in image inpainting or motif-scaffolding. ", "page_idx": 30}, {"type": "text", "text": "Note that since $\\overline{{P}}_{0\\mid t}(Y\\,=\\,y|X_{t}\\,=\\,x)\\,=\\,\\overline{{P}}_{t\\mid0}(x|Y\\,=\\,y)p_{0}(Y\\,=\\,y)/p_{t}(X_{t}\\,=\\,x),$ , we can re-express the Doob\u2019s transformed SDE of a reversed OU process as: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}H_{t}=-\\beta_{t}\\left(H_{t}+2\\nabla_{H_{t}}\\ln\\overline{{P}}_{t|0}(H_{t}|Y=y)\\right)\\,\\mathrm{d}t+\\sqrt{2\\beta_{t}}\\,\\overline{{\\mathrm{d}\\mathbf{W}}}_{t},\\,\\,\\,H_{T}\\sim\\mathrm{Law}\\left(X_{T}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proposition H.1. The minimiser of ", "text_level": 1, "page_idx": 30}, {"type": "equation", "text": "$$\nf^{*}\\!=\\!\\arg\\operatorname*{min}_{h}\\mathbb{E}_{\\mathbf{t}\\sim\\mathrm{U}(0,T)\\sim p(x_{0},Y)}\\left[||h(t,H_{t},y)-\\nabla_{H_{t}}\\mathrm{ln}\\,\\vec{p}_{t\\mid0}(H_{t}|X_{0})||^{2}\\right],\n$$", "text_format": "latex", "page_idx": 30}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/01e969631cfd8d030ce6c7b3deb7bb163ecd0ecc061d5e45b8008889dd81612f.jpg", "img_caption": ["Figure 12: Training using TrajectoryBalance. Left: The trajectory balance objective loss (78) over training steps. Right: The mean RND and the trained $k$ . We see that $k$ follows the mean RND. However, it has a smaller variance. "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "is given by the conditional score $f_{t}^{*}(\\pmb{x},\\pmb{y})=\\nabla_{\\pmb{x}}\\ln\\vec{p}_{t|0}(\\pmb{x}|\\pmb{Y}=\\pmb{y}).$ ", "page_idx": 31}, {"type": "text", "text": "Proof. Via the mean squared error property of the conditional expectation the minimiser is given by: ", "page_idx": 31}, {"type": "equation", "text": "$$\nh_{t}^{*}(\\pmb{x},\\pmb{y})=\\mathbb{E}\\left[\\nabla_{H_{t}}\\ln\\vec{p}_{t|0}(\\pmb{X}_{t}|\\pmb{X}_{0})|\\pmb{Y}=\\pmb{y},\\pmb{H}_{t}=\\pmb{x}\\right]\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Then: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h_{t}^{*}(x,y)=\\int\\nabla_{x}\\ln\\overline{{p}}_{t|0}(x|x_{0})\\overline{{p}}_{0|t}(x_{0}|H_{t}=x,Y=y)\\mathrm{d}x_{0}}\\\\ &{\\quad=\\int\\overline{{p}}\\overline{{s}}\\overline{{p}}_{t|0}(x|x_{0})\\frac{\\overline{{p}}_{t|0}(H_{t}=x|x_{0},Y=y)p(x_{0}|Y=y,\\mathrm{\\ensuremath{\\partial}})}{p(H_{t}=x|Y=y)}\\mathrm{d}x_{0}}\\\\ &{\\quad=\\frac{1}{p(H_{t}=x|Y=y)}\\int\\overline{{\\frac{\\nabla_{x}\\overline{{p}}_{t|0}(x|x_{0})}{\\overline{{p}}_{t|0}(x|x_{0})}\\overline{{p}}_{t|0}(H_{t}=x|x_{0})p(x_{0}|Y=y)\\mathrm{d}x_{0}}}}\\\\ &{\\quad=\\frac{1}{p(H_{t}=x|Y=y)}\\nabla_{x}\\int\\overline{{p}}_{t|0}(x|x_{0})p(x_{0}|Y=y)\\mathrm{d}X_{0}}\\\\ &{\\quad=\\frac{1}{p(H_{t}=x|Y=y)}\\nabla_{x}\\overline{{p}}(x_{t}|x_{0})p(x_{0}|Y=y)\\mathrm{d}X_{0}}\\\\ &{\\quad=\\frac{1}{\\overline{{p}}(X_{t}=x|Y=y)}\\nabla_{x}\\overline{{p}}(X_{t}=x|Y=y)}\\\\ &{\\quad=\\nabla_{x}\\ln\\overline{{p}}(X_{t}=x|Y=y),}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where we use that $\\vec{p}_{t\\vert0}({\\cal H}_{t}=x|x_{0},Y=y)=\\vec{p}_{t\\vert0}({\\cal H}_{t}=x|x_{0})$ as $H_{t}$ is independent from $\\mathbf{Y}$ given $X_{0}$ . \u53e3 ", "page_idx": 31}, {"type": "text", "text": "As with DEFT, for settings where $\\boldsymbol{\\mathcal{A}}$ varies like in image completion we sample $\\boldsymbol{\\mathcal{A}}$ randomly and amortise it over our learned $h$ -transform, i.e. estimating $h_{t}^{*}(x,y,A)$ . ", "page_idx": 31}, {"type": "text", "text": "We refer to this approach as amortised learning for conditional sampling, since practically the neural network approximating the (conditional) score is amortised over $\\boldsymbol{\\mathcal{A}}$ and $\\textit{\\textbf{y}}$ , instead of learning a separate network for each condition. This approach is also reminiscent of \u2018classifier free guidance\u2019 [27] where the score network is amortised over some auxiliary variable (e.g. as in text-to-image models [51]), or of RFDiffusion [77] where proteins are designed given a specific subset motif, or similar to [5]. See also Appendix B for a discussion of related conditional training methodologies. ", "page_idx": 31}, {"type": "text", "text": "Note that conditional amortised learning is different to \u2018classifier free guidance\u2019 as $\\boldsymbol{\\mathcal{A}}$ is assumed to be known (e.g. an inpainting mask). Also note that due to its formulation, classifier guidance would be unable to noise a subset of $\\mathbf{\\deltaX}$ (the motif) as we do and would instead be more akin to RFDiffusion. ", "page_idx": 31}, {"type": "text", "text": "H.1 Relationship to Conditional denoising estimator (CDE) ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Conditional denoising estimator (CDE) [5] is the adaptation of [27, 60] to inverse problem-like settings, deriving a variation of classifier-free guidance to a measurement model styled scenario. Whilst they do not focus on the measurement model, they estimate a very similar quantity as our Proposition 2.5 ", "page_idx": 32}, {"type": "equation", "text": "$$\nf^{\\mathrm{CDE}}({\\pmb x},{\\pmb y})=\\nabla_{\\pmb x}\\ln\\vec{p}_{t|0}({\\pmb x}|{\\pmb Y}={\\pmb y})\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "In contrast to to the amortised conditional training: ", "page_idx": 32}, {"type": "equation", "text": "$$\nf^{\\mathrm{amortised}}(\\pmb{x},\\pmb{y},\\pmb{A})=\\nabla_{\\pmb{x}}\\ln\\vec{p}_{t\\mid0}(\\pmb{x}|\\pmb{Y}=\\pmb{y},\\pmb{A}=\\pmb{A})\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "when explicitly considering the distribution over the measurement model, one can see that the quantities are related to one another via marginalizing the measurement model $p_{\\cal A}$ . This introduces several practical and conceptual differences: ", "page_idx": 32}, {"type": "text", "text": "\u2022 If we consider in/out painting as an example, the score network estimating $f^{\\mathrm{CDE}}$ is not explicitly aware of where in the image the missing pixels are. As a result, it must perform inference over $\\boldsymbol{\\mathcal{A}}$ (effectively marginalizing it) in order to know where to complete the image. This is clearly a much harder task for a single network to learn than conditioning on $\\boldsymbol{\\mathcal{A}}$ where we provide this information.   \n\u2022 Viewed under the lens of the $_\\mathrm{h}$ -transform, $f^{\\mathrm{CDE}}$ can be viewed as amortising the event $\\pmb{\\mathcal{A}}(\\pmb{\\{X}}_{0})\\;=\\;\\pmb{y}$ for random $\\boldsymbol{\\mathcal{A}}$ . It therefore falls under the soft constraint settings since $\\mathcal{A}(X_{0})|X_{0}$ is not a delta. Our quantity $f^{\\mathrm{amortised}}$ is amortising over $\\pmb{A}(\\pmb{X}_{0})\\,=\\,\\pmb{y}$ for deterministic $\\pmb{A}$ and is therefore part of the more classical hard constraint domain of Doobs transform. We believe amortising over these simpler deterministic events can offer an advantage in making the problem easier to learn. ", "page_idx": 32}, {"type": "text", "text": "H.2 Comparison to $h$ -transform fine-tuning ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We compare the amortised training framework against our $h$ -transform fine-tuning on the FLOWERS dataset. The preprocessing procedure consisted of centrally cropping the image to size $64\\times64$ , and rescaling to pixel values $[-1,1]$ . The dataset is split into three parts containing 6149, 1020 and 1020 images each. We use the first part to train the unconditional and amortised model. The second part is used for the $h$ -transform fine-tuning. The third part is used for evaluation. ", "page_idx": 32}, {"type": "text", "text": "For this experiment, we choose both an inpainting and an outpainting task. For the inpainting task a random $18\\times18\\mathrm{px}$ patch from the image is removed. In difference, for outpainting only a random $18\\times18\\mathrm{px}$ patch remains and the rest of the image is removed. Thus, the outpainting tasks tests better the generational capabilities of our framework. For the unconditional and amortised model, we use a standard attention U-Net [16] in the discrete DDPM framework. Both the unconditional and the amortised model have about 24M parameters. There is a minor difference due the fact that the unconditional network has 3 input channels and the amortised model has 7 input channels, i.e., the noisy image, the observations and the mask. The $h$ -transform is implemented according to the parametrisation in Section 3.3 with an attention U-Net [16] for $\\mathbf{NN}_{1}^{\\phi}$ . In total, the $h$ -transform has about 4M parameters, i.e., about $18\\%$ of the size of the amortised model. We evaluate three different settings for the amortised model: ", "page_idx": 32}, {"type": "text", "text": "\u2022 AMORTISED ( $20\\mathrm{X}$ , FULL DATA): trained on the full training dataset for 1200 epochs, \u2022 AMORTISED (2X): trained on the fine-tuning dataset for 700 epochs, \u2022 AMORTISED (1X): trained on the fine-tuning dataset with the same computational budget as DEFT (300 epochs). ", "page_idx": 32}, {"type": "text", "text": "We trained all models on a single GeForce RTX 3090. Training time for AMORTISED (20X, FULL DATA) and the unconditional model was about 50h. The training time for AMORTISED (2X) was 4.5h, while the fine-tuning and AMORTISED (1X) took about 2.5h. ", "page_idx": 32}, {"type": "text", "text": "Results are presented in Table 8. With a same computational budget, DEFT outperforms the amortised model on all tasks. Training the amortised model with a larger computational budget, recovers a similar performance to DEFT. Finally, in the scenario of full access to the complete dataset and large computational budget the amortised model is able to outperform both DEFT and DPS. ", "page_idx": 32}, {"type": "text", "text": "Table 8: Comparing the full amortised training with our conditional fine-tuning objective on the Flowers dataset for inpainting, outpainting and blur. ", "page_idx": 33}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/6741ac74870c9901119d31aca110cbf09433f0db2b3ac21d401d763170c94e43.jpg", "img_caption": [], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "Figure 13: Full results for DEFT ${}^{9\\%}$ model). For each task, we show the full scatter plot of scRMSD and motifRMSD for all 100 samples. The colour indicates the pLDDT confidence score of the re-folded structure with ESMFold. Samples with pLDDT $\\geq0.7$ are outlined. ", "page_idx": 33}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/bee7917cc83acef8c4eb7ec318f11bb81decd24418c1867685090068ad6f7e76.jpg", "img_caption": ["Figure 14: Comparison of the amortised model, DPS and DEFT $(9\\%)$ on the task 1YCR. We see the general trend for DPS that for low guidance scales the samples have high designability but do not adhere to the motif constraint, while for higher guidance scales they adhere to the motif constraint but have low designability. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "AKBTFQhCjm/tmp/e1c6f5951be9871ed1506ed7287d437736fa65e4dd54960c6ff2596504b944ef.jpg", "img_caption": ["Amortised ", "DPS ", "DEFT 9% "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "Figure 15: Comparison of samples from the amortised model, DPS and DEFT $(9\\%)$ on the tasks 6EXZ med. One can see that while the amortised and DEFT samples incorporate the motif into a realistic backbone, this is not the case for DPS. We generally observed that at small guidance scales DPS produced realistic backbones without the desired motif and at high guidance scales it placed the motif into an unrealistic backbone. ", "page_idx": 34}, {"type": "text", "text": "I Algorithms ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "In this section, we reformulate multiple algorithms from the literature under our common framework as a reference for practitioners. In these algorithms, we use the following conventions: our dataset is drawn from the law $\\mathcal{P}_{\\mathrm{data}}$ , but we can only sample from the simpler law $\\mathcal{P}_{\\mathrm{sampling}}$ at inference time, which is often chosen as multivariate standard normal $\\mathcal{P}_{\\mathrm{sampling}}\\,=\\mathcal{N}(0,\\mathbf{I})$ . Therefore, we construct a forward noising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$ that is parametrised via the noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ and try to learn the reverse denoising process $\\mathcal{P}_{\\mathrm{sampling}}\\to\\mathcal{P}_{\\mathrm{data}}$ . Due to this notion of \"forward\", and to keep consistency with the literature on denoising diffusion models, we explicate the nomenclature $\\mathcal{P}_{\\mathrm{data}}=\\mathcal{P}_{0}$ and $\\mathcal{P}_{\\mathrm{sampling}}=\\mathcal{P}_{T}$ . ", "page_idx": 35}, {"type": "text", "text": "There is an additional law $\\mathcal{P}_{\\mathrm{noise}}$ that is sometimes confused with $\\mathcal{P}_{\\mathrm{sampling}}$ since in practice both are often chosen as $\\mathcal{N}(0,\\mathbf{I})$ , but they are two distinct laws that could in principle be different. $\\mathcal{P}_{\\mathrm{noise}}$ is the law from which the noise added during the forward noising process as well as the during the reverse diffusion process is drawn from. ", "page_idx": 35}, {"type": "text", "text": "Require: Dataset drawn from law $\\mathcal{P}_{\\mathrm{data}}=\\mathcal{P}_{0}$ $\\triangleright$ Dataset law $\\mathcal{P}_{\\mathrm{data}}$   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t).$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \nRequire: Untrained noise predictor function $\\epsilon_{t}^{\\theta}(x)$ with parameters $\\theta$   \n1: repeat   \n2: $\\begin{array}{r l}&{\\pmb{x}_{0}\\sim\\mathcal{P}_{0}=\\mathcal{P}_{\\mathrm{data}}}\\\\ &{t\\sim\\mathrm{Uniform}(\\{1,...,T\\})}\\end{array}$   \n3:   \n4: $\\triangleright$ Forward noise sample, $x_{t}\\sim\\vec{p}_{t\\vert0}(x_{0})$ \u25c1   \n5: $\\begin{array}{l}{\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}}\\\\ {x_{t}\\leftarrow\\sqrt{\\bar{\\alpha}_{t}}x_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\varepsilon_{t}}\\end{array}$ \u25b7Often Brownian motion, $\\mathcal{P}_{\\mathrm{noise}}=\\mathcal{N}(0,\\mathbb{I})$   \n6:   \n7: $\\triangleright$ Estimate noise of noised sample \u25c1   \n8: $\\hat{\\varepsilon}_{\\theta}\\gets\\epsilon_{t}^{\\theta}({\\pmb x}_{t})$   \n9: Take gradient descent step on $\\nabla_{\\theta}\\bar{L}(\\varepsilon_{t},\\hat{\\varepsilon}_{\\theta})$ $\\triangleright$ Typically, loss $L(x_{\\mathrm{{true}}},x_{\\mathrm{{pred}}})=||x_{\\mathrm{{true}}}-x_{\\mathrm{{pred}}}||^{2}$   \n10: until converged or max epoch reached ", "page_idx": 35}, {"type": "text", "text": "Require: Unconditionally trained noise predictor $\\epsilon_{t}^{\\theta}(\\mathbf{x}_{t})$   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \n1: $\\triangleright$ Sample a starting point $x_{T}$ \u25c1   \n2: $x_{T}\\sim\\mathcal{P}_{T}=\\mathcal{P}_{\\mathrm{sampling}}$ g \u25b7Often $\\mathcal{P}_{T}=\\mathcal{N}(0,\\mathbf{I})$   \n3: $\\triangleright$ Iteratively denoise for $T$ steps \u25c1   \n4: for $t$ in $(T,T-1,\\ldots,1)$ do   \n5: $\\triangleright$ Predict noise with learned network \u25c1   \n6: $\\hat{\\varepsilon}_{\\theta}\\gets\\epsilon_{t}^{\\theta}({\\pmb x}_{t})$   \n7: $\\triangleright$ Denoise sample with learned reverse process $x_{t-1}\\sim\\breve{p}_{t-1|t}(x_{t})$ \u25c1   \n8: $\\triangleright$ Perform reverse drift \u25c1   \n9: $\\pmb{x}_{t-1}\\leftarrow\\frac{1}{\\sqrt{1-\\beta_{t}}}\\left(\\pmb{x}_{t}-\\frac{\\beta_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\hat{\\pmb{\\varepsilon}}_{\\theta}\\right)$   \n10: $\\triangleright$ Perform reverse diffusion, which is often Brownian motion in $\\mathbb{R}^{n}$ , i.e. $\\mathcal{P}_{\\mathrm{noise}}=\\mathcal{N}(0,\\mathbb{I})\\subset$   \n11: $\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}$ if $t>1$ else $\\varepsilon_{t}\\gets0$   \n12: $\\pmb{x}_{t-1}\\leftarrow\\pmb{x}_{t-1}+\\sigma_{t}\\pmb{\\varepsilon}_{t}$ \u25b7A common choice is $\\sigma_{t}=\\beta(t)$   \n13: return $\\scriptstyle x_{0}$ ", "page_idx": 35}, {"type": "text", "text": "Require: Dataset drawn from $\\mathcal{P}_{\\mathrm{data}}$ $\\triangleright$ Dataset law $\\mathcal{P}_{\\mathrm{data}}$   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \nRequire: Untrained conditional noise predictor function ${\\bf f}_{\\boldsymbol{\\theta}}({\\boldsymbol{x}},\\mathrm{t},M)$ with parameters $\\theta$   \n1: repeat   \n3: 2: $\\begin{array}{r l}&{\\pmb{x}_{0}\\sim\\mathcal{P}_{0}=\\mathcal{P}_{\\mathrm{data}}}\\\\ &{t\\sim\\mathrm{Uniform}(\\{1,...,T\\})}\\end{array}$   \n4: $\\pmb{x}_{0}^{[M]}\\cup\\pmb{x}_{0}^{[\\setminus M]}\\leftarrow\\pmb{x}_{0}$ \u25b7Randomly partition data point into motif and rest   \n5: $\\triangleright$ Forward noise the non-motif rest via sampling from $\\vec{p}_{0\\mid t}(x_{0})$ \u25c1   \n6: $\\begin{array}{r l}&{\\pmb{\\varepsilon}_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}}\\\\ &{\\pmb{x}_{t}^{[\\backslash M]}\\leftarrow\\sqrt{\\bar{\\alpha}_{t}}\\pmb{x}_{0}^{[\\backslash M]}+\\sqrt{1-\\bar{\\alpha}_{t}}\\pmb{\\varepsilon}_{t}^{[\\backslash M]}}\\end{array}$   \n7:   \n8: $\\triangleright$ Combine unnoised motif with noised rest and set timestep of motif part to 0 \u25c1   \n9: $\\begin{array}{r l}&{\\pmb{x}_{t}\\gets\\pmb{x}_{0}^{[M]}\\cup\\pmb{x}_{t}^{[\\backslash M]}}\\\\ &{t^{[M]}\\gets0}\\\\ &{\\hat{\\pmb{\\varepsilon}}_{\\theta}\\gets\\mathbf{f}_{\\theta}(\\pmb{x}_{t},t,M)}\\end{array}$   \n10:   \n11: $\\triangleright$ Estimate noise of sample with noised rest   \n12: Take gradient descent step on $\\nabla_{\\boldsymbol{\\theta}}\\bar{L}(\\varepsilon,\\hat{\\varepsilon}_{\\boldsymbol{\\theta}})$ $\\mathrm{\\nabla>Typically,}\\,L(x_{\\mathrm{true}},x_{\\mathrm{pred}})=||x_{\\mathrm{true}}-x_{\\mathrm{pred}}||^{2}$   \n13: until converged or max epoch reached   \nRequire: Dataset drawn from $\\mathcal{P}_{\\mathrm{data}}$ $\\triangleright$ Dataset law $\\mathcal{P}_{\\mathrm{data}}$   \nRequire: Noise schedule $\\beta_{t}=\\beta(t)$ , $\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \nRequire: Untrained amortised noise predictor function $\\mathbf{f}_{\\theta}(\\mathbf{x},t,\\mathbf{x}^{[M]},M)$ with parameters $\\theta$   \n1: repeat   \n2: $\\mathbf{x}_{0}\\sim\\mathcal{P}_{0}=\\mathcal{P}_{\\mathrm{data}}$   \n3: $\\begin{array}{l}{{{\\bf x}_{0}\\sim{\\cal F}_{0}={\\cal F}_{\\mathrm{data}}\\nonumber}}\\\\ {{t\\sim\\mathrm{Uniform}(\\{1,...,T\\})}}\\end{array}$   \n4: $\\mathbf{x}_{0}^{[M]}\\cup\\mathbf{x}_{0}^{[\\setminus M]}\\leftarrow\\mathbf{x}_{0}$ \u25b7Randomly partition data point into motif and rest   \n5: $\\triangleright$ Forward noise full sample via sampling from $\\vec{p}_{0\\,|\\,t}(\\mathbf{x}_{0})$ \u25c1   \n6: $\\begin{array}{l}{\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}}\\\\ {\\mathbf{x}_{t}\\leftarrow\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x}_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\varepsilon_{t}}\\end{array}$   \n7:   \n8: $\\triangleright$ Estimate noise of sample with original motif as additional input \u25c1   \n9: \u03b5\u02c6\u03b8 \u2190f\u03b8(xt, t, x[0M], M)   \n10: Take gradient descent step on $\\nabla_{\\boldsymbol{\\theta}}\\bar{L}(\\varepsilon,\\hat{\\varepsilon}_{\\boldsymbol{\\theta}})$ $\\mathrm{\\nabla>Typically,}\\,L(x_{\\mathrm{true}},x_{\\mathrm{pred}})=||x_{\\mathrm{true}}-x_{\\mathrm{pred}}||^{2}$   \n11: until converged or max epoch reached ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "Algorithm 5 | $h$ -transform fine-tuning (new) ", "page_idx": 37}, {"type": "text", "text": "Require: Dataset drawn from $\\mathcal{P}_{\\mathrm{data}}$ $\\triangleright$ Dataset law Pdata   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \nRequire: Trained noise predictor function $\\epsilon_{t}^{\\theta}(x)$ with parameters $\\theta$   \nRequire: Untrained $h$ -transform $h_{t}^{\\phi}(\\mathbf{x},\\hat{\\pmb{x}}_{0},\\pmb{y})$ with parameters $\\phi$   \n1: repeat   \n2: $\\pmb{x}_{0}\\sim\\mathcal{P}_{0}=\\mathcal{P}_{\\mathrm{data}}$   \n3: $t\\sim\\mathrm{Uniform}(\\{1,...,T\\})$   \n4: y \u223cp(y|x0) $\\triangleright$ Simulate observations   \n5: $\\triangleright$ Forward noise full sample via sampling from $\\vec{p}_{0\\mid t}(x_{0})$ \u25c1   \n6: $\\begin{array}{r l}&{\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}}\\\\ &{x_{t}\\leftarrow\\sqrt{\\bar{\\alpha}_{t}}x_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\varepsilon_{t}}\\\\ &{\\hat{\\varepsilon}_{\\theta}\\leftarrow\\epsilon_{t}^{\\theta}(x_{t})}\\\\ &{\\hat{x}_{0}\\leftarrow(x_{t}-\\sqrt{1-\\bar{\\alpha}_{t}}\\hat{\\varepsilon}_{\\theta})/\\sqrt{\\bar{\\alpha}_{t}}}\\\\ &{\\hat{\\epsilon}_{\\phi}\\leftarrow h_{t}^{\\phi}(x_{t},\\hat{x}_{0},y)}\\end{array}$   \n7:   \n8: \u25b7Estimate noise of sample with pretrained model   \n9:   \n10: \u25b7Estimate noise of sample with $h$ -transform   \n11: Take gradient descent step w.r.t. $\\phi$ on $\\nabla_{\\theta}\\bar{L}(\\varepsilon,\\hat{\\varepsilon}_{\\theta}+\\hat{\\varepsilon}_{\\phi})$ $\\mathrm{\\nabla>Typically,}\\,L(x_{\\mathrm{true}},x_{\\mathrm{pred}})=||x_{\\mathrm{true}}-x_{\\mathrm{pred}}||^{2}$   \n12: until converged or max epoch reached ", "page_idx": 37}, {"type": "text", "text": "Algorithm 6 | $h$ -transform DDIM sampling (new) ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Require: Trained $h$ -transform $h_{t}^{\\phi}(\\mathbf{x},\\hat{\\pmb{x}}_{0},\\pmb{y})$ with parameters $\\phi$   \nRequire: Unconditionally trained noise predictor $\\epsilon_{t}^{\\theta}(\\mathbf{x}_{t})$   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \nRequire: Schedule $\\sigma_{t}=\\sigma(t)$   \nRequire: Observation $\\textit{\\textbf{y}}$   \n1: \u25b7Sample a starting point $x_{T}$ \u25c1   \n2: xT \u223cPT = Psampling \u25b7Often $\\mathcal{P}_{T}=\\mathcal{N}(0,\\mathbf{I})$   \n3: $\\triangleright$ Iteratively denoise for $T$ steps \u25c1   \n4: for $t$ in $(T,T-1,\\ldots,1)$ do   \n5: $\\triangleright$ Predict unconditional noise with learned network \u25c1   \n6: $\\begin{array}{l}{\\hat{\\varepsilon}_{\\theta}\\leftarrow\\epsilon_{t}^{\\theta}(x_{t})}\\\\ {\\hat{x}_{0}\\leftarrow\\frac{x_{t}-\\sqrt{1-\\bar{\\alpha}_{t}}\\hat{\\varepsilon}_{\\theta}}{\\sqrt{\\bar{\\alpha}_{t}}}}\\\\ {\\hat{\\epsilon}_{\\phi}\\leftarrow h_{t}^{\\phi}({\\bf x}_{t},\\hat{x}_{0},y)}\\end{array}$   \n7:   \n8:   \n9: $\\triangleright$ Estimate posterior noise \u25c1   \n10: \u03f5\u02c6 \u2190\u03b5\u02c6\u03b8 + \u03f5\u02c6\u03d5   \n11: \u03b5t \u223cPnoise if t > 1 else $\\varepsilon_{t}\\gets0$   \n12: xt\u22121 \u2190 \u03b1\u00aft\u22121 xt \u2212 1 \u2212\u03b1\u00aft\u03f5\u02c6 + 1 \u2212\u03b1\u00aft\u22121 \u2212\u03c3t2 \u03f5\u02c6 + \u03c3t\u03b5t \u03b1\u00aft   \n13: return $\\scriptstyle x_{0}$ ", "page_idx": 37}, {"type": "text", "text": "Algorithm 7 | RFDiffusion conditional sampling [77] ", "page_idx": 38}, {"type": "text", "text": "Require: Conditionally trained noise predictor ${\\bf f}_{\\theta}({\\bf x},t,M)$   \nRequire: Target motif/context $\\mathbf{x}_{0}^{[M]}$   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \n1: $\\triangleright$ Sample a starting point $\\mathbf{x}_{T}$ \u25c1   \n2: xT \u223cPT = Psampling ", "page_idx": 38}, {"type": "text", "text": "3: $\\triangleright$ Iteratively denoise for $T$ steps \u25b7Often $\\mathscr{P}_{T}=\\mathcal{N}(0,\\ensuremath{\\mathbb{I}})\\leq$   \n4: for $t$ in $(T,T-1,\\ldots,1)$ do   \n5: $\\triangleright$ Overwrite motif variables with target motif and reset their time parameter \u25c1   \n6: \u25b7Note: Original RFDiffusion zero-centers $\\mathbf{x}_{t}$ and $\\mathbf{x}_{0}^{[M]}$ individually for equivariance. \u25c1   \n7: $\\mathbf{x}_{t}^{[M]}\\leftarrow\\mathbf{x}_{0}^{[M]}$ $\\triangleright$ Set noisy motif to unnoised motif   \n8: $t^{[M]}\\gets0$ \u25b7Set timesteps for motif to 0   \n9: $\\hat{\\boldsymbol{\\varepsilon}}_{\\theta}=\\mathbf{f}_{\\theta}(\\mathbf{x}_{t},t,M)$ $\\triangleright$ Predict noise with learned network   \n10: $\\triangleright$ Denoise sample with learned reverse process $\\mathbf x_{t-1}\\sim\\breve{p}_{t-1|t}(\\mathbf x_{t})$ \u25c1   \n11: $\\triangleright$ Perform reverse drift \u25c1   \n12: $\\mathbf{x}_{t-1}\\leftarrow\\frac{1}{\\sqrt{1-\\beta_{t}}}\\left(\\mathbf{x}_{t}-\\frac{\\beta_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\hat{\\pmb{\\varepsilon}}_{\\theta}\\right)$   \n13: $\\triangleright$ Perform reverse diffusion, which is often Brownian motion in $\\mathbb{R}^{n}$ , i.e. $\\mathcal{P}_{\\mathrm{noise}}=\\mathcal{N}(0,\\mathbb{I})\\subset$   \n14: $\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}$ if $t>1$ else $\\varepsilon_{t}\\gets0$   \n15: $\\mathbf{x}_{t-1}\\leftarrow\\mathbf{x}_{t-1}+\\sigma_{t}\\boldsymbol{\\varepsilon}_{t}$ \u25b7A common choice is $\\sigma_{t}=\\beta(t)$   \n16: return x0 ", "page_idx": 38}, {"type": "text", "text": "Algorithm 8 | Replacement conditional sampling for motif-scaffolding ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Require: Unconditionally trained noise predictor $\\epsilon_{t}^{\\theta}(\\mathbf{x}_{t})$   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parametrising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \nRequire: Target motif $\\pmb{x}_{0}^{[M]}$   \n1: Sample a starting point $x_{T}$   \n2: $x_{T}\\sim\\mathcal{P}_{T}=\\mathcal{P}_{\\mathrm{sampling}}$ g ", "page_idx": 38}, {"type": "text", "text": "3: \u25b7Iteratively denoise for $T$ steps \u25b7Often $\\mathscr{P}_{T}=\\mathcal{N}(0,\\ensuremath{\\mathbb{I}})<$   \n4: for $t$ in $(T,T-1,\\ldots,1)$ do   \n5: $\\triangleright$ Predict noise with learned network \u25c1   \n6: $\\hat{\\varepsilon}_{\\theta}\\gets\\epsilon_{t}^{\\theta}({\\pmb x}_{t})$   \n7: $\\triangleright$ Denoise sample with learned reverse process $\\boldsymbol{x}_{t-1}\\sim\\breve{\\boldsymbol{p}}_{t-1|t}(\\boldsymbol{x}_{t})$ \u25c1   \n8: $\\triangleright$ Perform reverse drift \u25c1   \n9: $\\pmb{x}_{t-1}\\leftarrow\\frac{1}{\\sqrt{1-\\beta_{t}}}\\left(\\pmb{x}_{t}-\\frac{\\beta_{t}}{\\sqrt{1-\\bar{\\alpha}_{t}}}\\hat{\\pmb{\\varepsilon}}_{\\theta}\\right)$   \n10: $\\triangleright$ Perform reverse diffusion, which is often Brownian motion in $\\mathbb{R}^{n}$ , i.e. $\\mathcal{P}_{\\mathrm{noise}}=\\mathcal{N}(0,\\mathbb{I})\\subset$   \n11: $\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}$ if $t>1$ else $\\varepsilon_{t}\\gets0$   \n12: $\\pmb{x}_{t-1}\\leftarrow\\pmb{x}_{t-1}+\\sigma_{t}\\pmb{\\varepsilon}_{t}$ \u25b7A common choice is $\\sigma_{t}=\\beta(t)$   \n13: \u25b7Forward noise the target motif x[tM\u22121] $x_{t-1}^{[M]}\\sim\\vec{p}_{0\\mid t-1}(x_{0}^{[M]})$ \u25c1   \n14: $\\eta_{t-1}\\sim\\mathcal{P}_{\\mathrm{noise}}$ if $t>1$ else $\\eta_{t-1}\\leftarrow0$   \n15: $\\pmb{x}_{t-1}^{[M]}\\leftarrow\\sqrt{\\bar{\\alpha}_{t-1}}\\pmb{x}_{0}^{[M]}+\\sqrt{1-\\bar{\\alpha}_{t-1}}\\pmb{\\eta}_{t-1}$   \n16: $\\pmb{x}_{t-1}\\leftarrow\\pmb{x}_{t-1}^{[\\backslash M]}\\cup\\pmb{x}_{t-1}^{[M]}$ $\\triangleright$ Insert noised motif into current sample   \n17: return ", "page_idx": 38}, {"type": "text", "text": "Algorithm 9 | Reconstruction Guidance (i.e. Moment Matching (MM) Approximation to $h$ -transform, DPS [12]) for general inverse problems ${\\pmb y}\\sim\\mathrm{noise}({\\mathcal{A}}({\\pmb x}))$ ", "page_idx": 39}, {"type": "text", "text": "Require: Unconditionally trained noise predictor $\\epsilon_{t}^{\\theta}(\\mathbf{x}_{t})$ , observation $\\textit{\\textbf{y}}$ .   \nRequire: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parameterising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$   \nRequire: Guidance scale (schedule) $\\gamma_{t}=\\gamma(t)$   \nRequire: Conditioning loss $l(y_{\\mathrm{pred}},y)$ . e.g, Gaussian MM $l({\\pmb y}_{\\mathrm{pred}},{\\pmb y})=||{\\pmb y}_{\\mathrm{pred}}-{\\pmb y}||^{2}$   \n1: \u25b7Sample a starting point $x_{T}$ \u25c1 2: $x_{T}\\sim\\mathcal{P}_{T}=\\mathcal{P}_{\\mathrm{samplin}}$ g \u25b7Often $\\mathcal{P}_{T}=\\mathcal{N}(0,\\mathbf{I})$ 3: $\\triangleright$ Iteratively denoise and condition for $T$ steps \u25c1 4: for $t$ in $(T,T-1,\\ldots,1)$ do   \n5: $\\hat{\\varepsilon}_{\\theta}\\gets\\epsilon_{t}^{\\theta}({\\pmb x}_{t})$ $\\triangleright$ Predict noise with learned network 6: $\\triangleright$ Estimate current denoise\u221ad estimate via Tweedie\u2019s formula \u25c1 7: $\\begin{array}{r}{\\hat{\\pmb{x}}_{0}(\\pmb{x}_{t},\\hat{\\pmb{\\varepsilon}}_{\\theta})\\leftarrow\\frac{1}{\\sqrt{\\bar{\\alpha}_{t}}}(\\pmb{x}_{t}-\\sqrt{1-\\bar{\\alpha}_{t}}\\hat{\\pmb{\\varepsilon}}_{\\theta})}\\end{array}$ \u25b7c.f. also eq. 15 in [28] 8: $\\triangleright$ Perform gradient descent step towards data consistency \u25c1 9: $\\pmb{x}_{t}\\gets\\pmb{x}_{t}-\\gamma_{t}\\nabla_{x}l(\\pmb{\\mathscr{A}}(\\pmb{\\hat{x}}_{0}),\\pmb{y})$ \u25b7Requires backprop through $\\epsilon_{t}^{\\theta}$ via e.g. $L_{2}$ loss 10: $\\triangleright$ Denoise sample with learned reverse process $\\boldsymbol{x}_{t-1}\\sim\\overleftarrow{\\boldsymbol{p}}_{t-1|t}(\\boldsymbol{x}_{t})$ \u25c1 11: $\\pmb{x}_{t-1}\\leftarrow(1-\\beta_{t})^{-1/2}\\left(\\pmb{x}_{t}-\\beta_{t}(1-\\bar{\\alpha}_{t})^{-1/2}\\hat{\\pmb{\\varepsilon}}_{\\theta}\\right)$ \u25b7Perform reverse drift 12: $\\triangleright$ Perform reverse diffusion, which is often Brownian motion in $\\mathbb{R}^{n}$ , i.e. $\\mathcal{P}_{\\mathrm{noise}}=\\mathcal{N}(0,\\mathbb{I})\\subset$ 13: $\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}$ if $t>1$ else $\\varepsilon_{t}\\gets0$   \n14: $\\pmb{x}_{t-1}\\leftarrow\\pmb{x}_{t-1}+\\sigma_{t}\\pmb{\\varepsilon}_{t}$ \u25b7A common choice is $\\sigma_{t}=\\beta(t)$ 15: return x0 ", "page_idx": 39}, {"type": "text", "text": "Algorithm 10 | Reconstruction Guidance (i.e. Moment Matching (MM) Approximation to $h$ - transform, DPS [12]) for motif scaffolding ", "page_idx": 39}, {"type": "text", "text": "Require: Unconditionally trained noise predictor $\\epsilon_{t}^{\\theta}(\\mathbf{x}_{t})$ , target motif/context $\\pmb{x}_{0}^{[M]}$ . Require: Noise schedule $\\beta_{t}=\\beta(t),\\bar{\\alpha}_{t}=\\bar{\\alpha}(t)$ , parameterising process $\\mathcal{P}_{\\mathrm{data}}\\to\\mathcal{P}_{\\mathrm{sampling}}$ g Require: Guidance scale (schedule) $\\gamma_{t}=\\gamma(t)$ Require: Conditioning loss $l(\\mathbf{{x}_{\\mathrm{{true}}}},\\mathbf{{x}_{\\mathrm{{pred}}}})$ . e.g, Gaussian MM $l(\\mathbf{\\alpha}_{\\mathrm{true}},\\mathbf{\\alpha}_{\\mathbf{x}_{\\mathrm{pred}}})=||x_{\\mathrm{true}}-x_{\\mathrm{pred}}||^{2}$ 1: \u25b7Sample a starting point $x_{T}$ \u25c1 2: xT \u223cPT = Psamplin g $\\triangleright$ Often $\\mathcal{P}_{T}=\\mathcal{N}(0,\\mathbf{I})$ ", "page_idx": 39}, {"type": "text", "text": "3: \u25b7Iteratively denoise and condition for $T$ steps \u25c1   \n4: for $t$ in $(T,T-1,\\ldots,1)$ do   \n5: $\\hat{\\varepsilon}_{\\theta}\\gets\\epsilon_{t}^{\\theta}({\\pmb x}_{t})$ $\\triangleright$ Predict noise with learned network   \n6: $\\triangleright$ Estimate current denoise\u221ad estimate via Tweedie\u2019s formula \u25c1   \n7: $\\begin{array}{r}{\\hat{\\pmb{x}}_{0}(\\pmb{x}_{t},\\hat{\\pmb{\\varepsilon}}_{\\theta})\\leftarrow\\frac{1}{\\sqrt{\\bar{\\alpha}_{t}}}(\\pmb{x}_{t}-\\sqrt{1-\\bar{\\alpha}_{t}}\\hat{\\pmb{\\varepsilon}}_{\\theta})}\\end{array}$ \u25b7c.f. also eq. 15 in [28]   \n8: $\\triangleright$ Perform gradient descent step towards condition on motif dimensions $M$ \u25c1   \n9: $\\pmb{x}_{t}\\gets\\pmb{x}_{t}-\\gamma_{t}\\nabla_{x}l(\\pmb{x}_{0}^{[M]},\\hat{\\pmb{x}}_{0}^{[M]}(\\pmb{x}_{t},\\hat{\\varepsilon}_{\\theta}))$ \u25b7Requires backprop through $\\epsilon_{t}^{\\theta}$ via e.g. $L_{2}$ loss   \n10: $\\triangleright$ Denoise sample with learned reverse process $\\boldsymbol{x}_{t-1}\\sim\\overleftarrow{\\boldsymbol{p}}_{t-1|t}(\\boldsymbol{x}_{t})$ \u25c1   \n11: $\\pmb{x}_{t-1}\\leftarrow(1-\\beta_{t})^{-1/2}\\left(\\pmb{x}_{t}-\\beta_{t}(1-\\bar{\\alpha}_{t})^{-1/2}\\hat{\\pmb{\\varepsilon}}_{\\theta}\\right)$ $\\triangleright$ Perform reverse drift   \n12: $\\triangleright$ Perform reverse diffusion, which is often Brownian motion in $\\mathbb{R}^{n}$ , i.e. $\\mathcal{P}_{\\mathrm{noise}}=\\mathcal{N}(0,\\mathbb{I})\\subset$   \n13: $\\varepsilon_{t}\\sim\\mathcal{P}_{\\mathrm{noise}}$ if $t>1$ else $\\varepsilon_{t}\\gets0$   \n14: $\\pmb{x}_{t-1}\\leftarrow\\pmb{x}_{t-1}+\\sigma_{t}\\pmb{\\varepsilon}_{t}$ \u25b7A common choice is $\\sigma_{t}=\\beta(t)$   \n15: return $\\scriptstyle x_{0}$ ", "page_idx": 39}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: We propose a new framework for conditional sampling from diffusion models, referred to as DEFT in the paper. This is stated both in the abstract and introduction, see 1. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 40}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Justification: Limitation of DEFT are discussed in a special paragraph in Section 5 ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 40}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: The assumptions for the proposition are always stated in the corresponding block. Proofs for statements are provided in Appendix D, with an exception for the optimal control loss. The derivation for this loss function is given in Appendix G. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 41}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: We clearly explain the settings and choices of our experiments either directly in the main paper, see Section 4, or in Appendix E. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 41}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: We provide anonymised code for our experiments here, as well as details on how to use the datasets we refer to. All datasets we use are publicly available and open-source. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 42}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: Full training details are provided in the released code base. Further, the setup is explained in both the experimental section, see Section 4, or in Appendix E. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 42}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 42}, {"type": "text", "text": "Answer: [No] ", "page_idx": 42}, {"type": "text", "text": "Justification: Due to the computational expense needed for sampling, providing error bars for conditional sampling results is not standard. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 42}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 43}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We provide training times and experimental setup in the relevant sections. Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 43}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: The authors have reviewed the NeurIPS ethics guidelines and conducted the research according to these guidelines. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 43}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: As DEFT is a generative model, it suffers from the sample issues as other generative approaches. The model can easily reproduce biases inherent in the training data. Further, due to the ability for conditional sampling, i.e., drawing samples according to specific constraints, the method can be used for \u201cdeep fakes\u201d or misinformation. However, these impacts do not only apply to DEFT, but to other conditional sampling method as well. We added a sentence to the conclusion. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 44}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: We only use pre-trained diffusion models, which are already publicly available in open-source code bases or publicly available datasets. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 44}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: Where applicable, we provide references to the code bases, datasets and implementation used. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 44}, {"type": "text", "text": "\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 45}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We provide a framework for conditional sampling from diffusion models. The codebase is provided as an anonymized Github repository. We re-use datasets and models with open licenses. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 45}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 45}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 45}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 46}]