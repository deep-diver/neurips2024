[{"figure_path": "axnjX20Ssl/figures/figures_0_1.jpg", "caption": "Figure 1: View-Consistent D-Normal Regularizer. Pseudo normals predicted from pretrained monocular normal estimators tend to be inconsistent across different views (left). Our method calculates a confidence map indicating the confidence of the pseudo normals (middle). The confidence is used to weigh the loss imposed on our proposed D-Normals. Our method achieves new state-of-the-art surface reconstruction results and rendering quality comparable with prior work.", "description": "This figure illustrates the core idea of the View-Consistent Depth-Normal Regularizer (VCR-GauS) method.  The left panel shows inconsistencies in pseudo-normals (estimated surface normals) predicted from a pre-trained monocular normal estimator across different views of a house. The middle panel displays a confidence map generated by the VCR-GauS method, highlighting areas where the pseudo-normals are more reliable. This confidence map is then used to weight the loss function, improving the accuracy of the final D-Normals. The right panel shows the high-quality 3D reconstruction and rendering achieved by VCR-GauS, demonstrating its superiority over existing methods.", "section": "Introduction"}, {"figure_path": "axnjX20Ssl/figures/figures_1_1.jpg", "caption": "Figure 2: Illustration of rendered normal supervision and the D-Normal regularizer. (a) As a result of the back-propagation through alpha-blending via Eq. 1, rendered normal supervision Ln moves Gaussians closer to (P1) or away from (P2) the intersecting ray. When the normal of a Gaussian is closer to the GT surface normal, the supervision pushes this Gaussian (P1) towards the ray to increase its weight in the rendering equation, and vice-versa (P2). (b) Such movement of Gaussians stops when the rendered normal loss Ln is equal to zero. In either case ((a) or (b)), the rendered normal loss cannot move Gaussian towards the surface. In contrast, (c) the D-Normal regularizer Lan can move Gaussians towards or away from GT surface. P1 and P2 are the 3D positions corresponding to the mean depth of two neighboring pixels (rays) via Eq. 10. The D-Normal Na is derived from P1 and P2 in Eq. 11. Lan encourages Na to align with the ground truth normal N, resulting in Gaussians moving towards or away from the surface.", "description": "This figure illustrates the difference between rendered normal supervision and the proposed D-Normal regularizer in Gaussian splatting.  It shows how rendered normal supervision (Ln) only moves Gaussians closer or further from a ray, failing to effectively pull them towards the surface. In contrast, the D-Normal regularizer (Ldn) uses depth information to directly move Gaussians towards or away from the ground truth surface, improving surface reconstruction accuracy.", "section": "1 Introduction"}, {"figure_path": "axnjX20Ssl/figures/figures_3_1.jpg", "caption": "Figure 3: Overview of our VCR-GauS. During densification and splitting, our method only keeps the Gaussians at the first intersections and splits large Gaussians into smaller ones along the major principle axis. The rendered normals are supervised with pseudo normals predicted from a pretrained monocular normal estimator in Ln. We further calculate an uncertainty map based on the discrepancies between the rendered and pseudo normals (cf. Eq. 13) to weigh the loss Lan between pseudo normals and D-Normals derived from the rendered depth maps. We compare different approaches for normal calculation (Top Right) and show our intersection depth (Bottom Right).", "description": "This figure provides a visual overview of the VCR-GauS method, highlighting the key steps involved in surface reconstruction.  It shows how the method uses 3D Gaussians, regularizes them using a depth-normal approach incorporating confidence from a pretrained model, and refines the surface using densification and splitting strategies. The image is divided into four key parts to detail each part of the pipeline, from 3D Gaussian generation, to regularization, comparing normal and D-Normal methods and details of depth intersection.", "section": "3 Our Method"}, {"figure_path": "axnjX20Ssl/figures/figures_6_1.jpg", "caption": "Figure 4: Illustration of the rationals behind the densification and splitting strategies. (a) Comparison between large and small Gaussians of depth errors caused by a small normal error (in side view). (b) Comparison of the original and the proposed splitting strategies (in bird-eye view).", "description": "This figure illustrates the reasoning behind the densification and splitting strategies used in the proposed method.  Panel (a) shows that depth errors caused by small normal errors are significantly larger for large Gaussians than for small ones. This motivates densifying large Gaussians into smaller ones to reduce depth errors. Panel (b) compares the original Gaussian splitting method with the proposed method, showing that the proposed method avoids clustering of split Gaussians, which can lead to surface protrusions and inaccuracies.", "section": "3.4 Densification and Splitting"}, {"figure_path": "axnjX20Ssl/figures/figures_6_2.jpg", "caption": "Figure 4: Illustration of the rationals behind the densification and splitting strategies. (a) Comparison between large and small Gaussians of depth errors caused by a small normal error (in side view). (b) Comparison of the original and the proposed splitting strategies (in bird-eye view).", "description": "This figure illustrates the reasoning behind the densification and splitting strategies used in the proposed method.  Part (a) shows how a small error in normal estimation leads to larger depth errors for large Gaussians, motivating the splitting of large Gaussians into smaller ones. Part (b) compares the original splitting strategy with the proposed one, highlighting how the new method aims to mitigate Gaussian clustering and surface protrusions.", "section": "3.4 Densification and Splitting"}, {"figure_path": "axnjX20Ssl/figures/figures_7_1.jpg", "caption": "Figure 5: Qualitative comparison on TNT dataset. From top to bottom, we show the reconstructed meshes from our method, SuGar, 2DGS, and NeuS, as well as the ground truth colored point cloud. Our method reconstructs more complete surfaces featuring smoother planar regions and finer details.", "description": "This figure compares the 3D surface reconstruction results of four different methods (VCR-GauS, SuGar, 2DGS, NeuS) on three scenes from the Tanks and Temples dataset.  The top row shows the reconstructions generated by the proposed VCR-GauS method. The subsequent rows display the results from SuGar, 2DGS, and NeuS respectively. The bottom row presents the ground truth point clouds for comparison. The visual comparison highlights that VCR-GauS produces more complete and detailed reconstructions with smoother surfaces, particularly in planar regions, compared to other methods.", "section": "4 Experiments"}, {"figure_path": "axnjX20Ssl/figures/figures_8_1.jpg", "caption": "Figure 7: Qualitative ablation for the confidence. Without the confidence weight, the reconstructed surface shows protrusions caused by the inconsistent pseudo normal maps across different views.", "description": "This figure shows an ablation study comparing surface reconstruction results with and without a confidence term in the D-Normal regularizer.  The left image displays the result without the confidence term, illustrating surface protrusions caused by inconsistent pseudo normal maps across multiple views. The right image shows the reconstruction with the confidence term, demonstrating improved smoothness and accuracy by mitigating the effects of inconsistent normals.", "section": "4.2 Ablation Studies"}, {"figure_path": "axnjX20Ssl/figures/figures_9_1.jpg", "caption": "Figure 1: View-Consistent D-Normal Regularizer. Pseudo normals predicted from pretrained monocular normal estimators tend to be inconsistent across different views (left). Our method calculates a confidence map indicating the confidence of the pseudo normals (middle). The confidence is used to weigh the loss imposed on our proposed D-Normals. Our method achieves new state-of-the-art surface reconstruction results and rendering quality comparable with prior work.", "description": "This figure illustrates the view-consistent D-Normal regularizer proposed in the paper.  It shows how inconsistent pseudo-normals (predicted from a pre-trained model) are across different views. The authors' method addresses this by calculating a confidence map that weights the loss during the optimization process of their D-Normals. This leads to improved surface reconstruction and rendering quality compared to previous methods.", "section": "Introduction"}, {"figure_path": "axnjX20Ssl/figures/figures_14_1.jpg", "caption": "Figure 8: Qualitative ablation for the semantic trimming. The left is disabling the semantic trimming and the right is enabling the strategy. We can see that the proposed semantic trimming can prune the unwanted regions, e.g. the sky in the left figure.", "description": "This figure shows a comparison of 3D reconstruction results with and without semantic surface trimming.  The left image shows the reconstruction without trimming, resulting in the inclusion of unwanted background elements such as the sky. The right image demonstrates the result with semantic trimming, effectively removing the sky and other background elements to focus solely on the target object.", "section": "A.1 Semantic Surface Trimming"}, {"figure_path": "axnjX20Ssl/figures/figures_17_1.jpg", "caption": "Figure 3: Overview of our VCR-GauS. During densification and splitting, our method only keeps the Gaussians at the first intersections and splits large Gaussians into smaller ones along the major principle axis. The rendered normals are supervised with pseudo normals predicted from a pretrained monocular normal estimator in Ln. We further calculate an uncertainty map based on the discrepancies between the rendered and pseudo normals (cf. Eq. 13) to weigh the loss Lan between pseudo normals and D-Normals derived from the rendered depth maps. We compare different approaches for normal calculation (Top Right) and show our intersection depth (Bottom Right).", "description": "This figure provides a visual overview of the VCR-GauS method, highlighting the key steps involved in densification, splitting, normal supervision, and depth calculation.  It shows how the algorithm refines the 3D Gaussian representation of a scene by selectively splitting large Gaussians, incorporating pseudo-normals from a pretrained model weighted by a confidence term, and using intersection depth instead of Gaussian centers for more accurate depth estimation.  The top right shows different normal calculation methods, comparing traditional and D-Normal methods, while the bottom right details the proposed intersection depth calculation.", "section": "3 Our Method"}, {"figure_path": "axnjX20Ssl/figures/figures_18_1.jpg", "caption": "Figure 10: Qualitative results on the Replica dataset.", "description": "This figure presents a qualitative comparison of 3D surface reconstruction results on the Replica dataset.  It shows results from the proposed method (Ours), SuGar, 2DGS, and the ground truth (GT). Each row compares a specific scene from different viewpoints, allowing for a visual assessment of the accuracy and completeness of the 3D models generated by each method. The comparison highlights the strengths and weaknesses of each approach in terms of detail preservation, surface smoothness, and overall accuracy in reconstructing the scene from multiple viewpoints.", "section": "4.1 Comparison"}, {"figure_path": "axnjX20Ssl/figures/figures_18_2.jpg", "caption": "Figure 1: View-Consistent D-Normal Regularizer. Pseudo normals predicted from pretrained monocular normal estimators tend to be inconsistent across different views (left). Our method calculates a confidence map indicating the confidence of the pseudo normals (middle). The confidence is used to weigh the loss imposed on our proposed D-Normals. Our method achieves new state-of-the-art surface reconstruction results and rendering quality comparable with prior work.", "description": "This figure shows the effectiveness of the proposed view-consistent D-Normal regularizer.  The left side illustrates the inconsistency of pseudo-normals predicted by a pre-trained monocular normal estimator across different views. The middle shows a confidence map generated by the method, indicating the reliability of these pseudo-normals. This confidence map is then used to weight the loss function for the D-Normals, leading to improved consistency. The right displays the high-quality reconstructed scene geometry and texture achieved by the method, showcasing its state-of-the-art performance.", "section": "Introduction"}, {"figure_path": "axnjX20Ssl/figures/figures_19_1.jpg", "caption": "Figure 1: View-Consistent D-Normal Regularizer. Pseudo normals predicted from pretrained monocular normal estimators tend to be inconsistent across different views (left). Our method calculates a confidence map indicating the confidence of the pseudo normals (middle). The confidence is used to weigh the loss imposed on our proposed D-Normals. Our method achieves new state-of-the-art surface reconstruction results and rendering quality comparable with prior work.", "description": "This figure showcases the effectiveness of the proposed View-Consistent Depth-Normal Regularizer in addressing inconsistencies in pseudo-normal predictions from different viewpoints.  The left side shows inconsistencies in pseudo-normals from a pre-trained model. The middle shows a confidence map generated by the method, which indicates the confidence levels of the pseudo normals. This confidence map is then used to weigh the loss function applied to the D-Normals in the proposed method. The right demonstrates the improved quality of reconstructed scene geometry and texture using the proposed approach, highlighting its state-of-the-art performance.", "section": "1 Introduction"}, {"figure_path": "axnjX20Ssl/figures/figures_19_2.jpg", "caption": "Figure 1: View-Consistent D-Normal Regularizer. Pseudo normals predicted from pretrained monocular normal estimators tend to be inconsistent across different views (left). Our method calculates a confidence map indicating the confidence of the pseudo normals (middle). The confidence is used to weigh the loss imposed on our proposed D-Normals. Our method achieves new state-of-the-art surface reconstruction results and rendering quality comparable with prior work.", "description": "This figure illustrates the core concept of the proposed View Consistent Depth-Normal Regularizer (VCR-GauS). The left panel shows inconsistencies in pseudo-normals predicted by a pre-trained monocular normal estimator across different viewpoints. The middle panel demonstrates a confidence map generated by the method, which assesses the reliability of these pseudo-normals. Finally, the right panel presents the improved 3D scene geometry and texture achieved by using the confidence map to weigh the loss applied to the D-Normals (Depth-Normals), resulting in state-of-the-art surface reconstruction and rendering quality.", "section": "Introduction"}]