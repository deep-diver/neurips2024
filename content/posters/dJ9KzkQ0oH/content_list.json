[{"type": "text", "text": "Neural Model Checking ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mirco Giacobbe\u2217 University of Birmingham, UK ", "page_idx": 0}, {"type": "text", "text": "Daniel Kroening\u2217 Amazon Web Services, USA ", "page_idx": 0}, {"type": "text", "text": "Abhinandan Pal\u2217 ", "page_idx": 0}, {"type": "text", "text": "University of Birmingham, UK ", "page_idx": 0}, {"type": "text", "text": "Michael Tautschnig Amazon Web Services, USA and Queen Mary University of London, UK ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We introduce a machine learning approach to model checking temporal logic, with application to formal hardware verification. Model checking answers the question of whether every execution of a given system satisfies a desired temporal logic specification. Unlike testing, model checking provides formal guarantees. Its application is expected standard in silicon design and the EDA industry has invested decades into the development of performant symbolic model checking algorithms. Our new approach combines machine learning and symbolic reasoning by using neural networks as formal proof certificates for linear temporal logic. We train our neural certificates from randomly generated executions of the system and we then symbolically check their validity using satisfiability solving which, upon the affirmative answer, establishes that the system provably satisfies the specification. We leverage the expressive power of neural networks to represent proof certificates as well as the fact that checking a certificate is much simpler than finding one. As a result, our machine learning procedure for model checking is entirely unsupervised, formally sound, and practically effective. We experimentally demonstrate that our method outperforms the state-of-the-art academic and commercial model checkers on a set of standard hardware designs written in SystemVerilog. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Electronic design is complex and prone to error. Hardware bugs are permanent after production and as such can irremediably affect the correctness of software\u2014which runs on hardware\u2014and can compromise the safety of cyber-physical systems\u2014which embed hardware. Correctness assurance is core to the engineering of digital circuitry, with the median FPGA and IC/ASIC projects spending respectively ${\\bar{40}}\\,\\%$ and $60\\,\\%$ of time in verification [48]. Verification approaches based on directed or constrained random testing are easy to set up but are inherently non-exhaustive [89, 91]. Testing cannot show the absence of bugs which, for systems the safety of which is critical, can have serious consequences; notably, over $40\\,\\%$ of hardware development projects must satisfy at least one functional safety standard [48]. In contrast to testing, model checking a design against a formal specification of correctness answers the question of whether the design satisfies the specification with mathematical certainty, for every possible execution of the system [9, 13, 35]. ", "page_idx": 0}, {"type": "text", "text": "The EDA industry has heavily invested in software tools for symbolic model checking. Early symbolic model checking algorithms utilise fixed-point computations with binary decision diagrams (BDDs) [7], where each node specifies the Boolean assignment for a circuit\u2019s filp-flop or input bit [26, 45]. BDDs struggle to scale when applied to complex arithmetic data paths, prompting a shift towards iterative approximation of fixed points using propositional satisfiability (SAT) solving [16, 17, 33], which is now the state-of-the-art technique. Both BDD and SAT-based model checking, despite extensive research, remain computationally demanding; even small circuit modules can require days to verify or may not complete at all. Consequently, verification engineers often limit state space exploration to a bounded time horizon through bounded model checking, sacrificing global correctness over the unbounded time domain. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "We present a machine learning approach to hardware model checking that leverages neural networks to represent proof certificates for the compliance of a given hardware design with a given linear temporal logic (LTL) specification [82]. Our approach avoids fixed-point algorithms entirely, capitalises on the efficient word-level reasoning of satisfiability solvers, and delivers a formal guarantee over an unbounded time horizon. Given a hardware design and an LTL specification $\\Phi$ , we train a wordlevel neural certificate for the compliance of the design with the specification from test executions, which we then check using a satisfiability solver. We leverage the observation that checking a proof certificate is much simpler than solving the model checking problem directly, and that neural networks are an effective representation of proof certificates for the correctness of systems [28, 50]. We ultimately obtain a machine learning procedure for hardware model checking that is entirely unsupervised, formally sound and, as our experiments show, very effective in practice. ", "page_idx": 1}, {"type": "text", "text": "Our learn-and-check procedure begins by generating a synthetic dataset through random executions of the system alongside a B\u00fcchi automaton that identifies counterexamples to $\\Phi$ . We then train a neural ranking function designed to strictly decrease whenever the automaton encounters an accepting state and remain stable on non-accepting states. After training, we formally check that the ranking function generalises to all possible executions. We frame the check as a cost-effective one-step bounded model checking problem involving the system, the automaton, and the quantised neural ranking function, which we delegate to a satisfiability solver. As the ranking function cannot decrease indefinitely, this confirms that the automaton cannot accept any system execution, effectively proving that such executions are impossible. Hence, if the solver concludes that no counterexample exists, it demonstrates that no execution satisfies $\\neg\\Phi$ , thereby affirming that the system satisfies $\\Phi$ [37, 95]. ", "page_idx": 1}, {"type": "text", "text": "We have built a prototype that integrates PyTorch, the bounded model checker EBMC, the LTLto-automata translator Spot, the SystemVerilog simulator Verilator, and the satisfiability solver Bitwuzla [44, 76, 80, 88]. We have assessed the effectiveness of our method across 194 standard hardware model checking problems written in SystemVerilog and compared our results with the state-of-the-art academic hardware model checkers ABC and nuXmv [24, 27], and two commercial counterparts. For any given time budget of less than 5 hours, our method completes on average $60\\,\\%$ more tasks than ABC, $34\\,\\%$ more tasks than nuXmv, and $11\\,\\%$ more tasks than the leading commercial model checker. Our method is faster than the academic tools on $67\\,\\%$ of the tasks, 10X faster on $34\\,\\%$ , and 100X faster on $4\\,\\%$ ; when considering the leading commercial tool, our method is faster on $75\\,\\%$ , 10X faster on $29\\,\\%$ , and 100X faster on $\\bar{2}\\,\\%$ of them. Overall, with a straightforward implementation, our method outperforms mature academic and commercial model checkers. ", "page_idx": 1}, {"type": "text", "text": "Our contribution is threefold. We present for the first time a hardware model checking approach based on neural certificates. We extend neural ranking functions, previously introduced for the termination analysis of software, to LTL model checking and the verification of reactive systems. We have built a prototype and experimentally demonstrated that our approach compares favourably with the leading academic and commercial hardware model checkers. Our technology delivers formal guarantees of correctness and positively contributes to the safety assurance of systems. ", "page_idx": 1}, {"type": "text", "text": "2 Automata-theoretic Linear Temporal Logic Model Checking ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "An LTL model checking problem consists of a model $\\mathcal{M}$ that describes a system design and an LTL formula $\\Phi$ that describes the desired temporal behaviour of the system [52, 82]. The problem is to decide whether all traces of $\\mathcal{M}$ satisfy $\\Phi$ . ", "page_idx": 1}, {"type": "text", "text": "Our formal model $\\mathcal{M}$ of a hardware design consists of a finite set of bit-vector-typed variables $X_{\\mathcal{M}}$ with fixed bit-width and domain of assignments $S$ , partitioned into input variables inp $X_{\\mathcal{M}}\\subseteq X_{\\mathcal{M}}$ and state-holding register variables reg $X_{\\mathcal{M}}\\subseteq X_{\\mathcal{M}}$ ; we interpret primed variables $X_{\\mathcal{M}}^{\\prime}$ as the value of $X_{\\mathcal{M}}$ after one clock cycle. Then, a sequential update relation $\\mathrm{Update}_{\\mathcal{M}}$ relates $X_{\\mathcal{M}}$ and reg $X_{\\mathcal{M}}^{\\prime}$ and computes the next-state valuation of the registers from the current-state valuation of all variables; we interpret $\\mathrm{Update}_{\\mathcal{M}}$ as a first-order logic formula encoding this relation. A state $s\\,\\in\\,S$ is a valuation for the variables $X_{\\mathcal{M}}$ . We denote as reg $\\pmb{s}$ , inp $s,\\dots$ the restriction of $\\pmb{s}$ to the respective class of variables. For two states $\\pmb{s}$ and $s^{\\prime}$ , the state $s^{\\prime}$ is a successor of $\\pmb{s}$ , which we write as $\\pmb{\\mathscr{s}}\\rightarrow_{\\mathcal{M}}\\pmb{\\mathscr{s}}^{\\prime}$ , if Update $_M^{\\left(s,\\,\\mathrm{reg}\\,s^{\\prime}\\right)}$ evaluates to true. We call $\\rightarrow_{M}$ the transition relation of $\\mathcal{M}$ and say that an infinite sequence of states $\\bar{s}_{0},\\bar{s}_{1},\\bar{s}_{2},\\ldots$ is an execution of $\\mathcal{M}$ if $\\bar{\\pmb{s}}_{i}\\rightarrow_{\\mathcal{M}}\\bar{\\pmb{s}}_{i+1}$ for all $i\\geq0$ ; we say that an execution is initialised in $s_{0}\\in S$ when $\\bar{s}_{0}=s_{0}$ . ", "page_idx": 1}, {"type": "image", "img_path": "dJ9KzkQ0oH/tmp/aac5caf3a8aec74dce4db33344f31ef61e7470c91deb20bc7ceb78732b69daa5.jpg", "img_caption": ["Figure 1: Automata-theoretic neural model checking via fair termination "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "We specify the intended behaviour of systems in LTL, which is the foundation of SystemVerilog Assertions. LTL extends propositional logic with temporal modalities X, G, F, and U. The modality $\\textsf{X}\\Phi_{1}$ indicates that $\\Phi_{1}$ holds immediately after one step in the future, G $\\Phi_{1}$ indicates that $\\Phi_{1}$ holds at all times in the future, F $\\Phi_{1}$ indicates that $\\Phi_{1}$ holds at some time in the future, and $\\Phi_{1}\\cup\\Phi_{2}$ indicates that $\\Phi_{1}$ holds at all times until $\\Phi_{2}$ holds at some time in the future. We refer the reader to the literature for the formal syntax and semantics of LTL [82]. The atomic propositions of the LTL formulae we consider are Boolean variables of $\\mathcal{M}$ , which we call the observables obs $X_{\\mathcal{M}}\\subseteq X_{\\mathcal{M}}$ of $\\mathcal{M}$ . We note that any first-order predicate over $X_{\\mathcal{M}}$ can be bound to a Boolean observable using combinational logic (cf. Figure 4, where observable ful corresponds to predicate $\\mathsf{c n t\\ ==\\ 7}$ ). ", "page_idx": 2}, {"type": "text", "text": "We call a trace of $\\mathcal{M}$ a sequence obs $\\bar{s}_{0}$ , obs $\\bar{s}_{1}$ , obs $\\bar{s}_{2},\\ldots$ where $\\bar{\\pmb{s}}_{0},\\bar{\\pmb{s}}_{1},\\bar{\\pmb{s}}_{2},\\dots$ is an execution of $\\mathcal{M}$ . We define the language $L_{\\mathcal{M}}$ of $\\mathcal{M}$ as the maximal set of traces of $\\mathcal{M}$ . Every LTL formula $\\Phi$ is interpreted over traces and as such defines the language $L_{\\Phi}$ of traces that satisfy $\\Phi$ . The model checking problem corresponds to deciding the language inclusion question $L_{\\mathcal{M}}\\subseteq L_{\\Phi}$ . ", "page_idx": 2}, {"type": "text", "text": "As is standard in automata-theoretic model checking, we rely on the result that every LTL formula admits a non-deterministic B\u00fcchi automaton that recognises the same language [95, 96]. A nondeterministic B\u00fcchi automaton $\\boldsymbol{\\mathcal{A}}$ consists of a finite set of states $Q$ , an initial start state $q_{0}\\,\\in\\,Q$ , an input domain $\\Sigma$ (also called alphabet), a transition relation $\\delta\\subseteq Q\\times\\Sigma\\times Q$ , and a set of fair states $F\\subseteq Q$ . One can interpret an automaton $\\boldsymbol{\\mathcal{A}}$ as a hardware design with one register variable reg $X_{A}=\\{\\mathfrak{q}\\}$ having domain $Q$ , input and observable variables inp $X_{\\mathcal{A}}=\\operatorname{obs}X_{\\mathcal{A}}$ having domain $\\Sigma$ , and sequential update relation Update $\\mathbf{\\Sigma}_{A}(\\pmb{\\sigma},\\pmb{q},\\pmb{q}^{\\prime})\\equiv(\\pmb{q},\\pmb{\\sigma},\\pmb{q}^{\\prime})\\in\\bar{\\delta}$ governing the automaton state transitions. We say that an execution of $\\boldsymbol{\\mathcal{A}}$ is fair (also said to be an accepting execution) if it visits fair states infinitely often. We define the fair language $L_{\\mathcal{A}}^{\\mathrm{f}}$ of $\\boldsymbol{\\mathcal{A}}$ as the maximal set of traces corresponding to fair executions initialised in $q_{0}$ . Given any LTL formula $\\Phi$ , there are translation algorithms and tools to construct non-deterministic B\u00fcchi automata $A_{\\Phi}$ such that $L_{\\mathcal{A}_{\\Phi}}^{\\mathrm{f}}=L_{\\Phi}$ [44, 58]. ", "page_idx": 2}, {"type": "text", "text": "The standard approach to answer the language inclusion question $L_{\\mathcal{M}}\\subseteq\\ L_{\\Phi}$ is to answer the dual language emptiness question $L_{\\mathcal{M}}\\cap L_{\\neg\\Phi}\\ =\\ \\emptyset$ [13, 35]. For this purpose, we first construct a non-deterministic B\u00fcchi automaton $A_{\\neg\\Phi}$ for the complement specification $\\neg\\Phi$ where inp $X_{A_{\\neg\\Phi}}\\,=\\,\\mathrm{obs}\\,X_{\\mathcal{M}}$ , then we reason over the synchronous composition (over a shared clock) of $\\mathcal{M}$ and $A_{\\neg\\Phi}$ as illustrated in Figure 1a. We direct the reader to the relevant literature for general definitions of system composition [10]. In this context, the synchronous composition results in the system $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ with input variables i $\\operatorname*{np}X_{\\mathcal{M}\\parallel A_{\\neg\\Phi}}\\,=\\,\\operatorname*{inp}X_{\\mathcal{M}}$ , register variables $\\operatorname{reg}X_{\\mathcal{M}\\parallel,4_{\\neg\\Phi}}=\\operatorname{reg}X_{\\mathcal{M}}\\cup\\{{\\mathbf{q}}\\}$ , observable variables obs $X_{\\mathcal{M}\\parallel\\mathcal{A}_{\\to\\Phi}}=\\cos X_{\\mathcal{M}}$ , and sequential update relation $\\mathrm{Update}_{\\mathcal{M}||_{\\mathcal{A}\\to\\Phi}}(s,q,r^{\\prime},q^{\\prime})=\\mathrm{Update}_{\\mathcal{M}}(s,r^{\\prime})\\wedge\\mathrm{Update}_{\\mathcal{A}\\to\\Phi}(\\mathrm{obs}\\,s,q,q^{\\prime}).$ We extend the fair states of $A_{\\neg\\Phi}$ to $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ , i.e., we define them as $\\{(s,q)\\mid s\\in S,q\\in F\\}$ , and as a result we have that $L_{\\mathcal{M}\\parallel\\mathcal{A}_{\\to\\Phi}}^{\\mathrm{f}}=L_{\\mathcal{M}}\\cap L_{\\mathcal{A}_{\\to\\Phi}}^{\\mathrm{f}}=L_{\\mathcal{M}}\\cap L_{\\to\\Phi}$ . This reduces our language emptiness question to the equivalent fair emptiness problem $L_{\\mathcal{M}\\parallel\\mathcal{A}_{\\neg\\Phi}}^{\\mathrm{f}}=\\emptyset$ . ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\underbrace{\\overbrace{\\mathrm{Learn}\\;}^{\\;\\;\\;\\zeta\\;\\;\\;D}}_{\\;\\;\\;\\bigcup\\;\\;}-\\overbrace{V}^{\\;\\;\\;\\theta\\;}\\frac{\\overbrace{\\mathrm{Learn}\\;}^{\\;\\;\\;\\zeta}}{\\overbrace{\\mathrm{Learn}\\;}^{\\;\\;\\;\\zeta\\;\\;\\mathrm{heck}\\;}}-\\overbrace{V}^{\\;\\;\\;\\tilde{\\theta}\\;\\rightarrow\\;\\mathrm{valid}};\n$$", "text_format": "latex", "page_idx": 3}, {"type": "image", "img_path": "", "img_caption": ["Figure 2: Learn-and-check workflow for provably sound neural ranking function learning "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "The fair emptiness problem amounts to showing that all executions of $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ are unfair, and we do so by presenting a ranking function that witnesses fair termination [51, 67]. A ranking function for fair termination is a map $V$ : r $\\operatorname{\\mathrm{?}}\\!\\operatorname{\\mathrm{~}}\\!S\\times Q\\to R$ where $(R,\\prec)$ defines a well-founded relation and, for all system and automaton states $s,s^{\\prime}\\in S,q,q^{\\prime}\\in Q$ , the following two conditions hold true: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(s,q)\\rightarrow_{\\mathcal{M}||A_{\\rightarrow\\Phi}}(s^{\\prime},q^{\\prime})\\implies V(\\mathrm{reg}\\,s,q)\\succeq V(\\mathrm{reg}\\,s^{\\prime},q^{\\prime})}\\\\ &{(s,q)\\rightarrow_{\\mathcal{M}||A_{\\rightarrow\\Phi}}(s^{\\prime},q^{\\prime})\\land q\\in F\\implies V(\\mathrm{reg}\\,s,q)\\succ V(\\mathrm{reg}\\,s^{\\prime},q^{\\prime})}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "A ranking function $V$ strictly decreases every time a transition from a fair state is taken, and never increases in any other case. Since every strictly decreasing sequence must be bounded from below (well-foundedness), every fair state can be visited at most finitely many times; the intuition is presented in Figure 1b, where ${\\bf1}_{F}(q)$ denotes the indicator function of $F$ , returning 1 if $q\\in F$ and 0 otherwise. The existence of a valid ranking function represented in some form establishes that every execution of $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ is necessarily unfair [95]. In this work, we represent ranking functions as neural networks, the parameters of which we train from generated sample executions. ", "page_idx": 3}, {"type": "text", "text": "3 Neural Ranking Functions for Fair Termination ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We approach the problem of computing a ranking function for fair termination by training a neural network $\\bar{V}\\colon\\mathbb{R}^{n}\\stackrel{\\cdot}{\\times}\\Theta\\rightarrow\\mathbb{R}$ , with $n$ input neurons where $n=|\\arg X_{\\mathcal{M}}|$ is the number of register variables of the system, one output neuron, and with a space of learnable parameters $\\Theta$ for its weights and biases. We associate a distinct trainable parameter $\\theta_{q}\\,\\in\\,\\Theta$ to each state $q\\in Q$ of the B\u00fcchi automaton. We train these parameters on sampled executions of $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ to ultimately represent a ranking function as a neural network $V(r,q)^{\\prime}\\!\\equiv\\bar{V}(r;\\theta_{q})$ , which we call a neural ranking function. This scheme is illustrated in Figure 1, where we denote the set of all parameters by the unindexed $\\theta$ . ", "page_idx": 3}, {"type": "text", "text": "We define our training objective as fulfilling conditions (1) and (2) on our synthetic dataset of sampled executions which, by analogy with reinforcement learning, can be viewed as a special case of episodes [53, 55]. Subsequently, we verify the conditions symbolically over the full state space $S\\times Q$ using satisfiability solving modulo theories (SMT) [14, 60], to confirm the validity of our neural ranking function or obtain a counterexample for re-training. Overall, our approach combines learning and SMT-based checking for both efficacy and formal soundness, as illustrated in Figure 2. ", "page_idx": 3}, {"type": "text", "text": "For a system $\\mathcal{M}$ and a specification $\\Phi$ , we train the parameters $\\theta$ of a neural network $\\bar{V}$ from a sample dataset $D\\subset\\mathrm{reg}\\,S\\times Q\\times\\mathrm{reg}\\,S\\times Q$ of subsequent transition pairs, which we construct from random executions of the synchronous composition $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ . Each execution $\\left(\\bar{\\pmb{s}}_{0},\\bar{\\pmb{q}}_{0}\\right),\\left(\\bar{\\pmb{s}}_{1},\\bar{\\pmb{q}}_{1}\\right),\\dots,\\left(\\bar{\\pmb{s}}_{k},\\bar{\\pmb{q}}_{k}\\right)$ initiates from a random system and automaton state pair and is then simulated over a finite number of steps; the inputs to $\\mathcal{M}$ and the non-deterministic choices in $A_{\\neg\\Phi}$ are resolved randomly. Our dataset $D$ is constructed as the set of all quadruples $(\\mathrm{reg}\\,\\bar{s}_{i},\\bar{q}_{i},\\mathrm{reg}\\,\\bar{s}_{i+1},\\bar{q}_{i+1})$ for $i=0,\\ldots,k-1$ from all sampled executions, capturing consecutive state pairs along each execution; notably, the order in which quadruples are stored in $D$ is immaterial for our purpose, as our method reasons and trains locally on each transition pair regardless of their order of appearance along any execution. ", "page_idx": 3}, {"type": "text", "text": "We train the parameters of our neural network $\\bar{V}$ to satisfy the ranking function conditions (1) and (2) over $D$ . For each quadruple $(r,q,r^{\\prime},q^{\\prime})\\in D$ , this amounts to minimising the following loss function: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{Rank}}(r,q,r^{\\prime},q^{\\prime};\\theta)=\\mathrm{ReLU}(\\bar{V}(r^{\\prime};\\theta_{q^{\\prime}})-\\bar{V}(r;\\theta_{q})+\\epsilon\\cdot{\\bf1}_{F}(q)).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\epsilon>0$ is a hyper-parameter that denotes the margin for the decrease condition. When $\\mathcal{L}_{\\mathrm{Rank}}$ takes its minimum value\u2014which is zero\u2014then the following two cases are satisfied: if ${\\textbf{\\em q}}\\not\\in F$ , then $\\bar{V}$ does not increase along the given transition, i.e., $\\bar{V}(\\pmb{r};\\pmb{\\theta_{q}})\\geq\\bar{V}(\\pmb{r}^{\\prime};\\pmb{\\theta_{q^{\\prime}}})$ , which corresponds to satisfy condition (1); if otherwise $\\pmb q\\in F$ , then $\\bar{V}$ decreases by at least the margin $\\epsilon>0$ along the given transition, i.e., $\\bar{V}(r;\\theta_{\\pmb q})\\geq\\bar{V}(r^{\\prime};\\theta_{\\pmb q^{\\prime}})+\\epsilon$ , which corresponds to satisfy condition (2). ", "page_idx": 3}, {"type": "image", "img_path": "dJ9KzkQ0oH/tmp/2268a7ee084047b2f414c170ca7192a810f2730be533c7cd88712a6c03034062.jpg", "img_caption": ["Figure 3: Neural ranking function architecture "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Overall, our learning phase ensures that the total loss function $\\mathcal{L}(D;\\theta)$ below takes value zero: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}(D;\\theta)=\\mathbb{E}_{(r,q,r^{\\prime},q^{\\prime})\\in D}[\\mathcal{L}_{\\mathrm{Rank}}(r,q,r^{\\prime},q^{\\prime};\\theta)]}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Unlike many other machine learning applications, for our purpose it is essential to attain the global minimum; if this fails, there are counterexamples to $\\bar{V}$ being a ranking function in the dataset $D$ itself. To facilitate the optimisation process, we train the parameters associated to each automaton state independently, one after the other, as opposed to training all parameters at once. Iteratively, we select one automaton state $q\\in Q$ and optimise only $\\theta_{q}\\in\\Theta$ for a number of steps, while keeping all other parameters $\\theta_{q^{\\prime}}\\in\\Theta$ fixed to their current value, for all $q^{\\prime}\\neq q$ . We repeat the process over each automaton state, possibly iterating over the entire set of automaton states $Q$ multiple times, until the total loss $\\mathcal{L}(D;\\theta)$ takes value zero. ", "page_idx": 4}, {"type": "text", "text": "Our neural network $\\bar{V}$ follows a feed-forward architecture as depicted in Figure 3: for a given automaton state $q\\in Q$ and associated parameter $\\theta_{q}$ , it takes an $n$ -dimensional input $r\\in\\mathbb{R}^{n}$ where each input neuron corresponds to the value of a register variable in reg $X_{\\mathcal{M}}$ , and produces one output for the corresponding ranking value $\\bar{V}(r;\\theta_{q})$ . Our architecture consists of a normalisation layer, followed by an element-wise multiplication layer, in turn followed by a multi-layer perceptron with clamped ReLU activation functions. The first layer applies a scaling factor to each input neuron independently to ensure consistent value ranges across inputs, implemented via element-wise multiplication with a constant vector of scaling coefficients derived from the dataset $D$ before training; this integrates data normalisation into the network, enables $\\bar{V}$ to use raw data from $\\mathcal{M}$ and simplifies the symbolic encoding of the normalisation operation during the verification phase. The second layer applies a trainable scaling factor to each individual neuron and is implemented via element-wise multiplication with a $n$ -dimensional vector with trainable coefficients. Finally, this is followed by a fully connected multi-layer perceptron with trainable weights and biases, with the activation function defined as the element-wise application of $\\mathrm{Clamp}(x;\\bar{u})=\\operatorname*{max}(0,\\operatorname*{min}(x,u))$ ; the upper bound $u$ and the depth and width of the hidden layers of the multi-layer perceptron component are hyper-parameters chosen to optimise training and verification performance. ", "page_idx": 4}, {"type": "text", "text": "Attaining zero total loss $\\mathcal{L}(D;\\theta)$ guarantees that our neural ranking function candidate $\\bar{V}$ satisfies the ranking criteria for fair termination over the dataset $D$ but not necessarily over the entire transition relation $\\rightarrow\\mathcal{M}\\Vert\\mathcal{A}_{\\neg\\Phi}$ , as required to fulfli conditions (1) and (2) and consequently to answer our model checking question (cf. Section 2). To formally check whether the ranking criteria are satisfied over the entire transition relation, we couple our learning procedure with a sound decision procedure that verifies their validity, as illustrated in Figure 2. ", "page_idx": 4}, {"type": "text", "text": "We check the validity of our candidate ranking neural network using satisfiability modulo the theory of bit-vectors. While the sequential update relation $\\mathrm{Update}_{\\mathcal{M}\\parallel A_{\\neg}\\Phi}$ is natively expressed over the theory of bit-vectors, the formal semantics of the neural network $\\bar{V}$ is defined on the reals. Hence, encoding $\\bar{V}$ and Update $\\mathcal{M}\\Vert\\mathcal{A}_{\\neg\\Phi}$ within the same query would result in a combination of real and bit-vector theories, which is supported in modern SMT solvers but often leads to sub-optimal performance [60]. Therefore, to leverage the efficacy of specialised solvers for the theory of bitvectors [80], we quantise our neural network using a standard approach for this purpose [57]; this converts all arithmetic operations within the neural networks into fixed-point arithmetic, which are implemented using integer arithmetic only. We quantise our parameters to their respective integer representation $\\tilde{\\theta}\\stackrel{.}{\\approx}2^{f}\\stackrel{.}{\\cdot}\\theta$ , where $f$ is a hyper-parameter for the number of fractional digits in fixed-point representation, and we replace linear layers and activation functions by their quantised counterpart; readers may consult the relevant literature for more detailed information on neural network quantisation [49, 57]. This results in a quantised neural network ${\\tilde{V}}\\colon\\mathbb{Z}^{n}\\times{\\tilde{\\Theta}}\\to\\mathbb{Z}$ that approximates our trained network $\\tilde{V}\\approx2^{f}\\cdot\\bar{V}$ , where $\\Tilde{\\Theta}$ denotes the space of integer parameters. fractional digits introduced by the linear layers [49, 57]. We consider the quantised network $\\tilde{V}$ as our candidate proof certificate for fair termination. ", "page_idx": 4}, {"type": "image", "img_path": "dJ9KzkQ0oH/tmp/8f27312e7e6f9ce70458b2f9607a63c536d920ae517779d7e92f7c4d9c272d4f.jpg", "img_caption": ["Figure 4: Illustrative hardware design, B\u00fcchi automaton, and respective ranking function "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "We reduce the validity query\u2014whether our quantised neural network $\\tilde{V}$ satisfies the ranking criteria for fair termination (1) and (2) over the entire transition relation of $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ \u2014to the dual satisfiability query for the existence of a counterexample to the criteria. Specifically, we delegate to an off-the-shelf SMT solver the task of computing a satisfying assignment $s\\in S,r^{\\prime}\\in\\arg S$ for which the following quantifier-free first-order logic formula is satisfied: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\bigvee_{q,q^{\\prime}\\in Q}\\mathrm{Update}_{\\mathcal{M}\\|A_{\\neg\\Phi}}(s,q,r^{\\prime},q^{\\prime})\\wedge\\tilde{V}(\\mathrm{reg}\\,s;\\tilde{\\theta}_{q})-{\\bf1}_{F}(q)<\\tilde{V}(r^{\\prime};\\tilde{\\theta}_{q^{\\prime}})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\tilde{\\pmb{\\theta}}$ is the (constant) parameter resulting from training and quantisation. We encode the quantised neural network $\\tilde{V}$ using a standard translation into first-order logic over the theory of bit-vectors [49], supplementing it with specialised rewriting rules to enhance the solver\u2019s performance, as detailed in Appendix A. We additionally note that V\u02dc is guaranteed to be bounded from below as $S$ is finite, albeit potentially very large, i.e., exponential in the combined bit-width of $X_{\\mathcal{M}}$ . ", "page_idx": 5}, {"type": "text", "text": "If the solver finds a satisfying assignment, then the assignment represents a transition of $\\mathcal{M}$ that refutes the validity of $\\tilde{V}$ ; in this case, we extend it to a respective transition in $\\mathcal{M}\\parallel\\mathcal{A}_{\\lnot\\Phi}$ , we add it to our dataset $D$ and repeat training and verification in a loop. Conversely, if the solver determines that formula (5) is unsatisfiable, then our procedure concludes that $\\tilde{V}$ is formally a valid neural ranking function and, consequently, system $\\mathcal{M}$ satisfies specification $\\Phi$ . ", "page_idx": 5}, {"type": "text", "text": "We note that LTL model checking of hardware designs is decidable and PSPACE-complete [9, 13, 35]. While it is theoretically possible for our approach to achieve completeness when a ranking function exists by enumerating all transitions and employing a sufficiently large neural network as a lookup table over the entire state space, this is impractical for all but toy cases. In this work, we employ tiny neural networks and incomplete but practically effective gradient descent algorithms to train neural ranking functions. We experimentally demonstrate on a large set of formal hardware verification benchmarks that this solution is very effective in practice. ", "page_idx": 5}, {"type": "text", "text": "4 Illustrative Example ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Modern hardware designs frequently incorporate word-level arithmetic operations, the simplest of which being counter increments/decrements, which are a staple in hardware engineering [71, 98]. One such example is illustrated as part of the SystemVerilog module in Figure 4. This represents a simplified buffer controller that counts the number of packets stored in the buffer and indicates when the buffer is full or empty with the ful and emp signals, respectively. This specific controller internally coordinates read-and-write operations through the rw signal: iteratively, the system signals $\\mathtt{r w}=1$ until the buffer is full and then $\\mathtt{r w}=0$ until the buffer is empty. ", "page_idx": 5}, {"type": "text", "text": "The design satisfies the property that both our observables ful and emp are true infinitely often, captured by the LTL formula $\\Phi=\\mathsf{G F}$ ful $\\wedge$ GF emp. Dually, this specification says that the system does not eventually go into a state from where $\\neg\\mathtt{f u1}$ holds indefinitely nor \u00acemp holds indefinitely, that is, $\\neg\\Phi=\\mathsf{F G\\neg\\bar{f}u1}\\lor\\mathsf{F G\\neg\\mathsf{e m p}}$ . Equivalently, this amounts to proving that no system trace is in the fair language of the automaton $A_{\\neg\\Phi}$ given in Figure 4. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "A neural ranking function $\\bar{V}$ for the fair termination of this system and automaton has 5 input neurons for the register variables cnt, m, ful, emp, and rw, and one hidden layer with three neurons in the multi-layer perceptron component. As illustrated in Figure 4, each automaton state is associated with a ranking function defined in terms of this architecture and their respective parameters. The sequence below gives an execution of model states alongside the respective ranking function values: ", "page_idx": 6}, {"type": "table", "img_path": "dJ9KzkQ0oH/tmp/58383d4ace276be9ddae114c397069bc236703965f5c93ba1906ef8bd299f26a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "One can observe that all transitions throughout this execution satisfy conditions (1) and (2). This assessment is based on the (not explicitly presented) synchronous composition with the automaton. First, we note that every transition originating from $q_{0}$ has a non-increasing ranking value, as $\\bar{V}(\\cdot;\\theta_{q_{0}})=14$ is an upper bound to all other values. Furthermore, every transition leaving $q_{1}$ \u2014that is, every transition whose source state satisfies \u00acful\u2014exhibits a strictly decreasing value $\\bar{V}(\\cdot;\\theta_{q_{1}})$ . Similarly, the same observation applies to $q_{2}$ and the condition \u00acemp. We note that the transitions that exhibit increasing values from 1 to 14 in this execution are impossible over the synchronous composition; this is because they are originating from states that satisfy both ful and $q_{1}$ , and similarly states that satisfy both emp and $q_{2}$ , and which do not have corresponding transitions in the automaton. ", "page_idx": 6}, {"type": "text", "text": "This neural ranking function admits no increasing transition originating from $q_{0}$ and no non-decreasing transitions originating from $q_{1}$ or $q_{2}$ on the synchronous composition of the system and the automaton. Therefore, it is a valid proof certificate for every system trace to satisfy specification $\\Phi$ . ", "page_idx": 6}, {"type": "text", "text": "5 Experimental Evaluation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We examine 194 verification tasks derived from ten parameterised hardware designs, detailed in Appendix B. By adjusting parameter values, we create tasks of varying complexity, resulting in different logic gate counts and state space sizes, thus offering a broad spectrum of verification complexity for tool comparison. The parameter ranges for each design are given as \u201call tasks\u201d in Figure 5. These tasks serve as benchmarks to evaluate the scalability of our method relative to conventional model checking. ", "page_idx": 6}, {"type": "text", "text": "Implementation We have developed a prototype tool for neural model checking2, utilising Spot 2.11.6 [44] to generate the automaton $A_{\\neg\\Phi}$ from an LTL specification $\\Phi$ . As depicted in Figure 1, the circuit model $\\mathcal{M}$ and the automaton $A_{\\neg\\Phi}$ synchronise over a shared clock to form a product machine. Using Verilator version 5.022 [88], we generate a dataset $D$ from finite trajectories of this machine. This dataset trains a neural network using PyTorch 2.2.2, as outlined in Section 3. To ensure formal guarantees, the network is quantised and subsequently translated to SMT, following the process outlined in Appendix A. The SystemVerilog model is converted to SMT using EBMC 5.2 [76]. We check the satisfiability problem using the Bitwuzla 0.6.0 SMT solver [80]. ", "page_idx": 6}, {"type": "text", "text": "State of the Art We benchmarked our neural model checking approach against two leading model checkers, nuXmv [27] and ABC [24, 25]. ABC and nuXmv were the top performers in the liveness category of the hardware model checking competition (HWMCC) [15, 19]. Our comparison employed the latest versions: nuXmv 2.0.0 and ABC\u2019s Super Prove tool suite [25], which were also used in the most recent HWMCC\u201920 [15]. We further consider two widely used industrial formal verification tools for SystemVerilog, anonymised as industry tool X and industry tool Y. Tool Y fails to complete any of the 194 tasks and is therefore not referenced further in this section. ", "page_idx": 6}, {"type": "table", "img_path": "dJ9KzkQ0oH/tmp/5202093c2235fc003e67a4957ef2d7a8ea58376c9955ef10c8bfc3a1b42c0d2f.jpg", "table_caption": ["Table 1: Number of verification task completed by academic and industrial tool, per design "], "table_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "dJ9KzkQ0oH/tmp/af8012190593a24106a8b01e42b7c76afca4303f8f97514bdca9d532a18cb765.jpg", "img_caption": ["Figure 5: Solved tasks in terms of state space size and logic gate count (log scale) "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Experimental Setup Evaluations were conducted on an Intel Xeon $2.5\\,\\mathrm{GHz}$ processor with eight threads and 32 GB of RAM running Ubuntu 20.04. Bitwuzla and nuXmv utilise one core each, ABC used three cores, and PyTorch leveraged all available cores. Each tool was allotted a maximum of five hours for each verification task, as detailed in Appendix C. ", "page_idx": 7}, {"type": "text", "text": "Hyper-parameters We instantiate the architecture described in Section 3 and illustrated in Figure 3, employing two hidden layers containing 8 and 5 neurons. The normalisation layer scales the input values to the range [0, 100]. We train with the AdamW optimiser [70], typically setting the learning rate to 0.1 or selecting from 0.2, 0.05, 0.03, 0.01 if adjusted, with a fixed weight decay of 0.01, demonstrating minimal hyperparameter tuning for training. ", "page_idx": 7}, {"type": "text", "text": "Dataset Generation In hardware design, engineers utilise test benches to verify safety properties through directed testing or Constraint Random Verification (CRV), aiming for high coverage and capturing edge cases [48, 89]. We apply CRV to the SystemVerilog flie, generating random trajectories. As outlined in Section 3, we start these trajectories by selecting the internal states of model $\\mathcal{M}$ (e.g., module BufferCtr and automaton $A_{\\lnot\\Phi}$ ; in Figure 4) using a uniform distribution. At each step, we assign random inputs to model $\\mathcal{M}$ and handle the non-determinism in automaton $A_{\\lnot\\Phi}$ by making choices from uniform or skewed distributions. We skew the distribution when a particular event is too predominant or too rare. In our experiments, such skewing is rare and limited to the reset and enable signals in $\\mathcal{M}$ , as well as the non-determinism in the automaton $A_{\\lnot\\Phi}$ . ", "page_idx": 7}, {"type": "text", "text": "Solved Tasks Table 1 presents the number of completed tasks for each tool across the ten hardware designs, while Figure 5 shows the range of state-space sizes and logic gate counts each tool successfully handled. Overall, our tool performs favourably in comparison to others, with the notable exception of the VGA design, where training a ranking function failed due to local minima, preventing convergence to zero loss\u2014a known limitation of gradient descent-based methods. ", "page_idx": 7}, {"type": "text", "text": "Aggregate Runtime Comparison Figure 6a displays a cactus plot with a $^\\mathrm{5\\,h}$ limit, we consider our configuration with 8 and 5 hidden neurons as detailed in the section, along with the aggregate of the best time on individual tasks obtained from our ablation study, as detailed in Appendix D. While the default architecture performs the best across all tasks, on some tasks a smaller network is sufficient, and leads to lower verification time. At the same time, larger networks often succeed on tasks that otherwise fail, making the \u201cour best\u201d line strictly better than \u201cour $(5,8)^{\\circ}$ . This shows that improvement can be obtained by tuning the width of the hidden layers; note that this analysis considers three additional configurations (i.e, (3, 2), (5, 3), (15, 8)) that adhere to the architecture introduced in Section 3. For the rest of our experiments, we continue using the default architecture. ", "page_idx": 7}, {"type": "image", "img_path": "dJ9KzkQ0oH/tmp/7b93280e876f98c2851dd13dd44d40f5ca8733f726706c1adad854e34c252d60.jpg", "img_caption": ["Figure 6: Runtime comparison with the state of the art (all times are in log scale) "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "The plot further shows that our tool completes $93\\,\\%$ of tasks, outperforming ABC, nuXmv, and industry tool X, which completes $29\\,\\%$ , $60\\,\\%$ , and $80\\,\\%$ , respectively. At any point in the time axis, we compute the difference between the percentage of tasks completed by our tool with each of the others in the figure. Then, taking the average of these differences across the time axis, showing that our method is successful in $60\\,\\bar{\\%}$ more tasks than ABC, $34\\,\\%$ more than nuXmv, and $11\\,\\%$ more than the leading commercial model checker at any given time. Furthermore, the number of tasks completed by nuXmv in $^\\mathrm{5\\,h}$ are finished by our tool in less than $8\\,\\mathrm{{min}}$ , and those completed by ABC in $5\\,\\mathrm{h}$ take just under $3\\,\\mathrm{{min}}$ with our method. ", "page_idx": 8}, {"type": "text", "text": "Individual Runtime Comparison Figure 6b presents a scatter plot where each point represents a verification task, with size and brightness indicating the state-space size. Points are plotted horizontally by the lesser of time taken by nuXmv or ABC and vertically by our method\u2019s time. The plot reveals that academic tools time out on $39\\,\\%$ of tasks, while our method times out on $7\\,\\%$ . Moreover, we are faster than the academic tools on $67\\,\\%$ of tasks, 10 times faster on $34\\,\\%$ , and 100 times faster on $4\\,\\%$ . These results demonstrate that we generally outperform the state of the art on this benchmark set (see Appendix 3 for individual runtimes). However, we perform relatively worse on the UARTt design. This design involves an $N$ -bit register for data storage and a counter for transmitted bits, enabling sequential outputs. Since there is no word-level arithmetic over the $N$ -bit register, increasing its size minimally affects the complexity of symbolic model checking. Consequently, ABC, nuXmv, and industry tool X complete all UARTt tasks in under a second, while our tool takes a few minutes due to overhead from the sampling, learning, and SMT-check steps, making us slower on trivial model-checking problems. ", "page_idx": 8}, {"type": "text", "text": "Learning vs. Checking Time Figure 6c illustrates the time split between learning the neural network\u2014which involves dataset generation and training\u2014and verifying it as a valid ranking function. The lower line indicates learning time; the upper line represents total time, with the gap showing the time spent on SMT checking. Extensive sampling across a broad range of trajectories covering most edge cases led our method to learn the network directly without needing retraining due to counterexamples in the SMT-check phase, except in four tasks. The plot shows that $93\\,\\%$ of tasks were trained successfully, generally within five minutes, and remarkably, the $70\\,\\%$ were completed in under a minute. For tasks that did not train to zero loss, the $5\\,\\mathrm{h}$ time limit was not fully utilised; the loss function stabilised at local minima in just a few minutes. Moreover, training was faster than verification on $97\\,\\%$ tasks\u201410 times faster on $46\\,\\%$ and 100 times faster on $6\\,\\%$ . ", "page_idx": 8}, {"type": "text", "text": "Limitations The primary limitation of our approach arises from the extended SMT-check times and the risk of getting trapped in local minima. Despite these challenges, our method consistently outperforms traditional symbolic model checkers while relying on off-the-shelf SMT solvers and machine learning optimisers. Additionally, our neural architecture requires numerical inputs at the word level, which limits its application to bit-level netlists. This limitation is not high-impact, as modern formal verification tools predominantly utilise Verilog RTL rather than netlist representations. ", "page_idx": 8}, {"type": "text", "text": "Threats to Validity The experimental results may not generalise to other workloads. As any work that relies on benchmarks, our benchmarks may not be representative for other workloads. We mitigate this threat by selecting extremely common hardware design patterns from the standard literature. We remark that our data sets we use to train the neural nets do not suffer from the common threat of training data bias, and the common out-of-distribution problem: we train our neural net from scratch for each benchmark using randomly generated trajectories, and do not use any pretraining. ", "page_idx": 8}, {"type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Formal verification, temporal logic and model checking have been developed for more than fifty years; key contributors have been recognised with the 1996, 2007 and 2013 ACM Turing Awards. Here, we restrict our discussion to algorithms that are the basis of the model checkers for SystemVerilog that available to hardware engineers today as well as on the techniques that underpin this work. ", "page_idx": 9}, {"type": "text", "text": "Temporal logic describes the intended behaviour of systems and SystemVerilog Assertions\u2014which is based on LTL\u2014is a widely adopted language for this purpose [48, 82]. Any temporal specifications are compositions of safety and liveness properties, where the former indicate the dangerous conditions to be avoided and the latter indicate the desirable conditions to be attained [8, 65]. Safety properties are a fragment of LTL, and can be checked using BDDs by forward fixed-point iterations [12, 34, 62]. Bounded model checking uses SAT and scales much better than BDDs [16], but it is only complete when the bound reaches an often unrealistically large completeness threshold [59]. SAT-based unbounded safety checking uses sophisticated Craig Interpolation and IC3 algorithms [20, 73, 87]. ", "page_idx": 9}, {"type": "text", "text": "Our work uses a one-step bounded model checking query to check the ranking function (see Eq. (5)), and goes beyond safety. Liveness checking for branching-time CTL is straightforward to implement using BDD-based fixed points [35, 45]. Our method does not support CTL; this is considered acceptable given the prevailing use of LTL-based property languages in industry. LTL model checking is commonly reduced to the fair emptiness problem and, for this purpose, bounded model checking has been generalised to $k$ -liveness [31, 56], IC3 has been augmented with strongly connected components [23], and BDD-based algorithms with the Emerson-Lei fixed-point computation [23, 46]. Iterative symbolic computation is the bottleneck on systems with word-level arithmetic. This is usually addressed by either computing succinct explicit-state abstractions of the system [6, 32], or by computing proof certificates based on inductive invariants and ranking functions. ", "page_idx": 9}, {"type": "text", "text": "Ranking functions were introduced for termination analysis of software [47], and subsequently generalised to liveness verification [5, 37, 39, 43, 51, 67, 95]. Software and hardware model checking share common questions [42, 76, 77]. Early symbolic approaches for software analysis based on constraint solving are limited to linear ranking functions [21, 84]. As we illustrate in Figure 4, even simple examples often require non-linear ranking functions. These include piecewise-defined functions [63, 93, 94], word-level arithmetic functions [29, 40], lexicographic ranking functions [22, 68], and disjoint well-founded relations [36, 38, 61, 83], and similar proof certificates based on liveness-to-safety translation to reason about the transitive closure of the system [18, 78, 85]. ", "page_idx": 9}, {"type": "text", "text": "Our method follows a much more lightweight approach than the symbolic approaches above, by training ranking functions from synthetic executions [81]. Deep learning has been successfully applied to generate software and hardware designs, but without delivering any formal guarantees [30, 69, 74]. In our work, we use neural networks to represent formal proof certificates, rather than to generate proofs or designs. This goes along the lines of recent work on neural certificates, previously applied to control [1, 2, 28, 41, 66, 79, 86, 99\u2013102], formal verification of software and probabilistic programs [3, 4, 50], and this work applies them for the first time to hardware model checking. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We have introduced a method that leverages (quantised) neural networks as representations of ranking functions for fair termination, which we train from synthetic executions of the system without using any external information other than the design at hand and its specification. We have applied our new method to model checking SystemVerilog Assertions and compared its performance with the state of the art on a range of SystemVerilog designs. We employed off-the-shelf SMT solving (Bitwuzla) and bounded model checking (EBMC) to formally verify our neural ranking functions [76, 80]; although this phase takes the majority of our compute time, with a straightforward implementation and using tiny feed-forward neural networks, we obtained scalability superior to traditional symbolic model checking. Whether alternative neural architectures as well as specialised solvers for quantised neural networks can further improve our approach is topic of future work [11, 64, 72, 75]. ", "page_idx": 9}, {"type": "text", "text": "This is the first successful application of neural certificates to model checking temporal logic, and introduces hardware model checking as a new application domain for this technology. Neural networks could be used in many other ways to improve model checking. Our work creates a baseline for further development in this field and positively contributes to the safety assurance of systems. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We thank Matthew Leeke, Sonia Marin, and Mark Ryan for their feedback and the anonymous reviewers for their comments and suggestions on this manuscript. This work was supported in part by the Advanced Research $^+$ Invention Agency (ARIA) under the Safeguarded AI programme. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] A. Abate, D. Ahmed, A. Edwards, M. Giacobbe, and A. Peruffo. FOSSIL: a software tool for the formal synthesis of Lyapunov functions and barrier certificates using neural networks. In HSCC, pages 24:1\u201324:11. ACM, 2021.   \n[2] A. Abate, D. Ahmed, M. Giacobbe, and A. Peruffo. Formal synthesis of Lyapunov neural networks. IEEE Control. Syst. Lett., 5(3):773\u2013778, 2021.   \n[3] A. Abate, M. Giacobbe, and D. Roy. Learning probabilistic termination proofs. In CAV (2), volume 12760 of Lecture Notes in Computer Science, pages 3\u201326. Springer, 2021.   \n[4] A. Abate, A. Edwards, M. Giacobbe, H. Punchihewa, and D. Roy. Quantitative verification with neural networks. In CONCUR, volume 279 of LIPIcs, pages 22:1\u201322:18. Schloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, 2023.   \n[5] A. Abate, M. Giacobbe, and D. Roy. Stochastic omega-regular verification and control with supermartingales. In CAV (3), volume 14683 of Lecture Notes in Computer Science, pages 395\u2013419. Springer, 2024.   \n[6] A. Abate, M. Giacobbe, and Y. Schnitzer. Bisimulation learning. In CAV (3), volume 14683 of Lecture Notes in Computer Science, pages 161\u2013183. Springer, 2024.   \n[7] S. B. Akers. Binary decision diagrams. IEEE Trans. Computers, 27(6):509\u2013516, 1978. [8] B. Alpern and F. B. Schneider. Recognizing safety and liveness. Distributed Comput., 2(3): 117\u2013126, 1987.   \n[9] R. Alur. Principles of Cyber-Physical Systems. MIT Press, 2015.   \n[10] R. Alur and T. A. Henzinger. Reactive modules. In LICS, pages 207\u2013218. IEEE, 1996.   \n[11] G. Amir, H. Wu, C. W. Barrett, and G. Katz. An SMT-based approach for verifying binarized neural networks. In TACAS (2), volume 12652 of Lecture Notes in Computer Science, pages 203\u2013222. Springer, 2021.   \n[12] Z. S. Andraus, M. H. Liffiton, and K. A. Sakallah. Reveal: A formal verification tool for Verilog designs. In LPAR, volume 5330 of Lecture Notes in Computer Science, pages 343\u2013352. Springer, 2008.   \n[13] C. Baier and J. Katoen. Principles of Model Checking. MIT Press, 2008.   \n[14] C. W. Barrett, R. Sebastiani, S. A. Seshia, and C. Tinelli. Satisfiability modulo theories. In Handbook of Satisfiability, volume 185 of Frontiers in Artificial Intelligence and Applications, pages 825\u2013885. IOS Press, 2009.   \n[15] A. Biere, N. Froleyks, and M. Preiner. Hardware model checking competition (HWMCC) 2020. URL https://hwmcc.github.io/2020/.   \n[16] A. Biere, A. Cimatti, E. M. Clarke, and Y. Zhu. Symbolic model checking without BDDs. In TACAS, volume 1579 of LNCS, pages 193\u2013207. Springer, 1999.   \n[17] A. Biere, E. M. Clarke, R. Raimi, and Y. Zhu. Verifiying safety properties of a Power PC microprocessor using symbolic model checking without BDDs. In CAV, volume 1633 of LNCS, pages 60\u201371. Springer, 1999.   \n[18] A. Biere, C. Artho, and V. Schuppan. Liveness checking as safety checking. In FMICS, volume 66 of Electronic Notes in Theoretical Computer Science, pages 160\u2013177. Elsevier, 2002.   \n[19] A. Biere, T. Van Dijk, and K. Heljanko. Hardware model checking competition 2017. In Formal Methods in Computer Aided Design (FMCAD), pages 9\u20139. IEEE, 2017.   \n[20] A. R. Bradley. SAT-based model checking without unrolling. In VMCAI, volume 6538 of Lecture Notes in Computer Science, pages 70\u201387. Springer, 2011.   \n[21] A. R. Bradley, Z. Manna, and H. B. Sipma. Linear ranking with reachability. In CAV, volume 3576 of Lecture Notes in Computer Science, pages 491\u2013504. Springer, 2005.   \n[22] A. R. Bradley, Z. Manna, and H. B. Sipma. The polyranking principle. In ICALP, volume 3580 of Lecture Notes in Computer Science, pages 1349\u20131361. Springer, 2005.   \n[23] A. R. Bradley, F. Somenzi, Z. Hassan, and Y. Zhang. An incremental approach to model checking progress properties. In FMCAD, pages 144\u2013153. FMCAD Inc., 2011.   \n[24] R. K. Brayton and A. Mishchenko. ABC: an academic industrial-strength verification tool. In CAV, volume 6174 of LNCS, pages 24\u201340. Springer, 2010.   \n[25] R. K. Brayton, B. Sterin, N. Een, S. Ray, J. Long, and A. Mishchenko. Model checking system \"super_prove\", 2008-2017. URL https://github.com/sterin/super-prove-build.   \n[26] J. R. Burch, E. M. Clarke, K. L. McMillan, D. L. Dill, and L. J. Hwang. Symbolic model checking: $10^{20}$ states and beyond. Inf. Comput., 98(2):142\u2013170, 1992.   \n[27] R. Cavada, A. Cimatti, M. Dorigatti, A. Griggio, A. Mariotti, A. Micheli, S. Mover, M. Roveri, and S. Tonetta. The nuXmv symbolic model checker. In CAV, volume 8559 of LNCS, pages 334\u2013342. Springer, 2014.   \n[28] Y. Chang, N. Roohi, and S. Gao. Neural Lyapunov Control. In NeurIPS, pages 3240\u20133249, 2019.   \n[29] H. Chen, C. David, D. Kroening, P. Schrammel, and B. Wachter. Bit-precise procedure-modular termination analysis. ACM Trans. Program. Lang. Syst., 40(1):1:1\u20131:38, 2018.   \n[30] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and W. Zaremba. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021.   \n[31] K. Claessen and N. S\u00f6rensson. A liveness checking algorithm that counts. In FMCAD, pages 52\u201359. IEEE, 2012.   \n[32] E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided abstraction refinement. In CAV, volume 1855 of Lecture Notes in Computer Science, pages 154\u2013169. Springer, 2000.   \n[33] E. M. Clarke, D. Kroening, and F. Lerda. A tool for checking ANSI-C programs. In TACAS, volume 2988 of LNCS, pages 168\u2013176. Springer, 2004.   \n[34] E. M. Clarke, R. P. Kurshan, and H. Veith. The localization reduction and counterexampleguided abstraction refinement. In Essays in Memory of Amir Pnueli, volume 6200 of Lecture Notes in Computer Science, pages 61\u201371. Springer, 2010.   \n[35] E. M. Clarke, O. Grumberg, D. Kroening, D. A. Peled, and H. Veith. Model checking, 2nd Edition. MIT Press, 2018.   \n[36] B. Cook, A. Podelski, and A. Rybalchenko. Termination proofs for systems code. In PLDI, pages 415\u2013426. ACM, 2006.   \n[37] B. Cook, A. Gotsman, A. Podelski, A. Rybalchenko, and M. Y. Vardi. Proving that programs eventually do something good. In POPL, pages 265\u2013276. ACM, 2007.   \n[38] B. Cook, A. See, and F. Zuleger. Ramsey vs. lexicographic termination proving. In TACAS, volume 7795 of Lecture Notes in Computer Science, pages 47\u201361. Springer, 2013.   \n[39] B. Cook, H. Khlaaf, and N. Piterman. Fairness for infinite-state systems. In TACAS, volume 9035 of Lecture Notes in Computer Science, pages 384\u2013398. Springer, 2015.   \n[40] C. David, D. Kroening, and M. Lewis. Unrestricted termination and non-termination arguments for bit-vector programs. In ESOP, volume 9032 of Lecture Notes in Computer Science, pages 183\u2013204. Springer, 2015.   \n[41] C. Dawson, Z. Qin, S. Gao, and C. Fan. Safe nonlinear control using robust neural Lyapunovbarrier functions. In CoRL, volume 164 of Proceedings of Machine Learning Research, pages 1724\u20131735. PMLR, 2021.   \n[42] D. Dietsch, M. Heizmann, V. Langenfeld, and A. Podelski. Fairness modulo theory: A new approach to LTL software model checking. In CAV (1), volume 9206 of Lecture Notes in Computer Science, pages 49\u201366. Springer, 2015.   \n[43] R. Dimitrova, L. M. F. Fioriti, H. Hermanns, and R. Majumdar. Probabilistic CTL\\*: The deductive way. In TACAS, volume 9636 of Lecture Notes in Computer Science, pages 280\u2013296. Springer, 2016.   \n[44] A. Duret-Lutz, E. Renault, M. Colange, F. Renkin, A. G. Aisse, P. Schlehuber-Caissier, T. Medioni, A. Martin, J. Dubois, C. Gillard, and H. Lauko. From Spot 2.0 to Spot 2.10: What\u2019s new? In CAV (2), volume 13372 of LNCS, pages 174\u2013187. Springer, 2022.   \n[45] E. A. Emerson and E. M. Clarke. Characterizing correctness properties of parallel programs using fixpoints. In ICALP, volume 85 of LNCS, pages 169\u2013181. Springer, 1980.   \n[46] E. A. Emerson and C. Lei. Modalities for model checking: Branching time strikes back. In POPL, pages 84\u201396. ACM Press, 1985.   \n[47] R. W. Floyd. Assigning meanings to programs. In Proceedings of Symposium in Applied llathematics, volume 19, pages 19\u201332, 1967.   \n[48] H. Foster. The 2022 Wilson research group functional verification study, 2022. URL https://blogs.sw.siemens.com/verificationhorizons/2022/10/10/ prologue-the-2022-wilson-research-group-functional-verification-study/.   \n[49] M. Giacobbe, T. A. Henzinger, and M. Lechner. How many bits does it take to quantize your neural network? In TACAS (2), volume 12079 of LNCS, pages 79\u201397. Springer, 2020.   \n[50] M. Giacobbe, D. Kroening, and J. Parsert. Neural termination analysis. In ESEC/SIGSOFT FSE, pages 633\u2013645. ACM, 2022.   \n[51] O. Grumberg, N. Francez, J. A. Makowsky, and W. P. de Roever. A proof rule for fair termination of guarded commands. Inf. Control., 66(1/2):83\u2013102, 1985.   \n[52] D. Harel and A. Pnueli. On the development of reactive systems. In Logics and Models of Concurrent Systems, volume 13 of NATO ASI Series, pages 477\u2013498. Springer, 1984.   \n[53] H. Hasanbeig, D. Kroening, and A. Abate. Certified reinforcement learning with logic guidance. Artif. Intell., 322:103949, 2023.   \n[54] D. G. Holmes and T. A. Lipo. Pulse width modulation for power converters: principles and practice, volume 18. John Wiley & Sons, 2003.   \n[55] R. T. Icarte, T. Q. Klassen, R. A. Valenzano, and S. A. McIlraith. Reward machines: Exploiting reward function structure in reinforcement learning. J. Artif. Intell. Res., 73:173\u2013208, 2022.   \n[56] A. Ivrii, Z. Nevo, and J. Baumgartner. k-FAIR $=$ k-LIVENESS $^+$ FAIR\u2014revisiting SAT-based liveness algorithms. In FMCAD, pages 1\u20135. IEEE, 2018.   \n[57] B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. G. Howard, H. Adam, and D. Kalenichenko. Quantization and training of neural networks for efficient integer-arithmetic-only inference. In CVPR, pages 2704\u20132713. Computer Vision Foundation / IEEE Computer Society, 2018.   \n[58] J. Kret\u00ednsk\u00fd, T. Meggendorfer, and S. Sickert. Owl: A library for $\\omega$ -words, automata, and LTL. In ATVA, volume 11138 of Lecture Notes in Computer Science, pages 543\u2013550. Springer, 2018.   \n[59] D. Kroening and O. Strichman. Efficient computation of recurrence diameters. In VMCAI, volume 2575 of Lecture Notes in Computer Science, pages 298\u2013309. Springer, 2003.   \n[60] D. Kroening and O. Strichman. Decision Procedures\u2014An Algorithmic Point of View, Second Edition. Texts in Theoretical Computer Science. Springer, 2016.   \n[61] D. Kroening, N. Sharygina, A. Tsitovich, and C. M. Wintersteiger. Termination analysis with compositional transition invariants. In CAV, volume 6174 of Lecture Notes in Computer Science, pages 89\u2013103. Springer, 2010.   \n[62] O. Kupferman and M. Y. Vardi. Model checking of safety properties. In CAV, volume 1633 of Lecture Notes in Computer Science, pages 172\u2013183. Springer, 1999.   \n[63] S. Kura, H. Unno, and I. Hasuo. Decision tree learning in CEGIS-based termination analysis. In CAV (2), volume 12760 of Lecture Notes in Computer Science, pages 75\u201398. Springer, 2021.   \n[64] L. C. Lamb, A. S. d\u2019Avila Garcez, M. Gori, M. O. R. Prates, P. H. C. Avelar, and M. Y. Vardi. Graph neural networks meet neural-symbolic computing: A survey and perspective. In IJCAI, pages 4877\u20134884. ijcai.org, 2020.   \n[65] L. Lamport. Proving the correctness of multiprocess programs. IEEE Trans. Software Eng., 3 (2):125\u2013143, 1977.   \n[66] M. Lechner, D. \u017dikelic\u00b4, K. Chatterjee, and T. A. Henzinger. Stability verification in stochastic control systems via neural network supermartingales. In AAAI, pages 7326\u20137336. AAAI Press, 2022.   \n[67] D. Lehmann, A. Pnueli, and J. Stavi. Impartiality, justice and fairness: The ethics of concurrent termination. In ICALP, volume 115 of LNCS, pages 264\u2013277. Springer, 1981.   \n[68] J. Leike and M. Heizmann. Ranking templates for linear loops. Log. Methods Comput. Sci., 11(1), 2015.   \n[69] M. Liu, N. R. Pinckney, B. Khailany, and H. Ren. VerilogEval: Evaluating large language models for Verilog code generation. In ICCAD, pages 1\u20138. IEEE, 2023.   \n[70] I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In ICLR (Poster). OpenReview.net, 2019.   \n[71] A. K. Maini. Digital electronics: principles, devices and applications, Chapter 11: Counters and Registers. John Wiley & Sons, 2007.   \n[72] J. B. P. Matos, Jr., E. B. de Lima Filho, I. Bessa, E. Manino, X. Song, and L. C. Cordeiro. Counterexample guided neural network quantization refinement. IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 43(4):1121\u20131134, 2024.   \n[73] K. L. McMillan. Applying SAT methods in unbounded symbolic model checking. In CAV, volume 2404 of Lecture Notes in Computer Science, pages 250\u2013264. Springer, 2002.   \n[74] A. Mirhoseini, A. Goldie, M. Yazgan, et al. A graph placement methodology for fast chip design. Nature, (594):207\u2013212, 2021.   \n[75] S. Mistry, I. Saha, and S. Biswas. An MILP encoding for efficient verification of quantized deep neural networks. IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 41(11):4445\u20134456, 2022.   \n[76] R. Mukherjee, D. Kroening, and T. Melham. Hardware verification using software analyzers. In ISVLSI, pages 7\u201312. IEEE Computer Society, 2015.   \n[77] R. Mukherjee, P. Schrammel, D. Kroening, and T. Melham. Unbounded safety verification for hardware using software analyzers. In DATE, pages 1152\u20131155. IEEE, 2016.   \n[78] V. Murali, A. Trivedi, and M. Zamani. Closure certificates. In HSCC, pages 10:1\u201310:11. ACM, 2024.   \n[79] A. Nadali, V. Murali, A. Trivedi, and M. Zamani. Neural closure certificates. In AAAI, pages 21446\u201321453. AAAI Press, 2024.   \n[80] A. Niemetz and M. Preiner. Bitwuzla. In CAV (2), volume 13965 of LNCS, pages 3\u201317. Springer, 2023.   \n[81] A. V. Nori and R. Sharma. Termination proofs from tests. In ESEC/SIGSOFT FSE, pages 246\u2013256. ACM, 2013.   \n[82] A. Pnueli. The temporal logic of programs. In FOCS, pages 46\u201357. IEEE, 1977.   \n[83] A. Podelski and A. Rybalchenko. Transition invariants. In LICS, pages 32\u201341. IEEE Computer Society, 2004.   \n[84] A. Podelski and A. Rybalchenko. A complete method for the synthesis of linear ranking functions. In VMCAI, volume 2937 of Lecture Notes in Computer Science, pages 239\u2013251. Springer, 2004.   \n[85] A. Podelski and A. Rybalchenko. Transition predicate abstraction and fair termination. ACM Trans. Program. Lang. Syst., 29(3):15, 2007.   \n[86] Z. Qin, K. Zhang, Y. Chen, J. Chen, and C. Fan. Learning safe multi-agent control with decentralized neural barrier certificates. In ICLR. OpenReview.net, 2021.   \n[87] T. Seufert, F. Winterer, C. Scholl, K. Scheibler, T. Paxian, and B. Becker. Everything you always wanted to know about generalization of proof obligations in PDR. IEEE Trans. Comput. Aided Des. Integr. Circuits Syst., 42(4):1351\u20131364, 2023.   \n[88] W. Snyder. Verilator and SystemPerl. In North American SystemC Users\u2019 Group, Design Automation Conference, 2004.   \n[89] C. Spear and G. Tumbush. SystemVerilog for verification\u2014a guide to learning the testbench language features. 2012.   \n[90] A. Subero and A. Subero. USART, SPI, and I2C: serial communication protocols. Programming PIC Microcontrollers with XC8, pages 209\u2013276, 2018.   \n[91] T. Trippel, K. G. Shin, A. Chernyakhovsky, G. Kelly, D. Rizzo, and M. Hicks. Fuzzing hardware like software. In USENIX Security Symposium, pages 3237\u20133254. USENIX Association, 2022.   \n[92] UM10204. I2C-bus specification and user manual, 2021. URL https://www.nxp.com/ docs/en/user-guide/UM10204.pdf.   \n[93] C. Urban. The abstract domain of segmented ranking functions. In SAS, volume 7935 of Lecture Notes in Computer Science, pages 43\u201362. Springer, 2013.   \n[94] C. Urban. FuncTion: An abstract domain functor for termination (competition contribution). In TACAS, volume 9035 of Lecture Notes in Computer Science, pages 464\u2013466. Springer, 2015.   \n[95] M. Y. Vardi. Verification of concurrent programs: The automata-theoretic framework. Ann. Pure Appl. Log., 51(1-2):79\u201398, 1991.   \n[96] M. Y. Vardi and P. Wolper. An automata-theoretic approach to automatic program verification (preliminary report). In LICS, pages 332\u2013344. IEEE, 1986. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "[97] E. W. Weisstein. Gray code. https://mathworld.wolfram.com/, 2003. ", "page_idx": 15}, {"type": "text", "text": "[98] X. Zhang, S. Dwarkadas, G. Folkmanis, and K. Shen. Processor hardware counter statistics as a first-class system resource. In HotOS. USENIX Association, 2007.   \n[99] H. Zhao, X. Zeng, T. Chen, and Z. Liu. Synthesizing barrier certificates using neural networks. In HSCC, pages 25:1\u201325:11. ACM, 2020.   \n[100] D. Zhi, P. Wang, S. Liu, L. Ong, and M. Zhang. Unifying qualitative and quantitative safety verification of DNN-controlled systems. In CAV, Lecture Notes in Computer Science. Springer, 2024.   \n[101] D. Zikelic, M. Lechner, T. A. Henzinger, and K. Chatterjee. Learning control policies for stochastic systems with reach-avoid guarantees. In AAAI, pages 11926\u201311935. AAAI Press, 2023.   \n[102] D. Zikelic, M. Lechner, A. Verma, K. Chatterjee, and T. A. Henzinger. Compositional policy learning in stochastic control systems with formal guarantees. In NeurIPS, 2023. ", "page_idx": 15}, {"type": "text", "text": "A Details of the SMT Encoding of Quantised Neural Networks ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The $k^{\\mathrm{th}}$ hidden layer in our network comprises a fully connected layer followed by a clamp operation that restricts outputs to the range $[0,u]$ . This layer has $h_{k}$ neurons, and the previous layer contains $h_{k-1}$ neurons. Each neuron $i$ in the $k^{\\mathrm{th}}$ layer is defined by: ", "page_idx": 16}, {"type": "equation", "text": "$$\nx_{i}^{(k)}=\\mathrm{Clamp}(y_{i}^{(k)};u),\\quad y_{i}^{(k)}=b_{i}^{(k)}+z_{i}^{(k)},\\quad z_{i}^{(k)}=\\sum_{j=1}^{h_{k-1}}w_{i j}^{(k-1)}x_{j}^{(k-1)}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "To facilitate SMT-checking modulo Bit-Vector theory, we quantise the floating-point weights $w_{i j}$ and biases $b_{i}$ by multiplying them by $2^{f}$ and truncating decimals, where $f$ determines the precision. We define: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\tilde{w}_{i j}^{(k)}=\\mathrm{trunc}(w_{i j}^{(k)}\\cdot2^{f}),\\quad\\tilde{b}_{i}^{(k)}=\\mathrm{trunc}(b_{i}^{(k)}\\cdot2^{f})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This transformation converts weights from floating-point values in $[0,u]$ to integers in $[0,2^{f}u]$ . To ensure consistency between bit-vector and floating-point arithmetic, the output of each bit-vector encoded component should be equivalent to multiplying the floating-point output by $2^{f}$ and truncating the decimals. To achieve this, the SMT constraints on the bit-vectors are formulated as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\bigwedge_{i=1}^{h_{k}}\\left(\\tilde{x}_{i}^{(k)}=\\mathrm{Clamp}(\\tilde{y}_{i}^{(k)};2^{f}u)\\wedge\\tilde{y}_{i}^{(k)}=\\tilde{b}_{i}^{(k)}+\\mathrm{ashr}(\\tilde{z}_{i}^{(k)};f)\\wedge\\tilde{z}_{i}^{(k)}=\\sum_{j=1}^{h_{k-1}}\\tilde{w}_{i j}^{(k-1)}\\tilde{x}_{j}^{(k-1)}\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here, w\u02dci(jk $\\tilde{w}_{i j}^{(k-1)}$ and $\\tilde{x}_{j}^{(k-1)}$ are integers in $[0,2^{f}u]$ , thus their product remains within $[0,2^{2f}u^{2}]$ . The sum $\\tilde{z}_{i}^{(k)}$ aggregates $h_{k}$ such products, resulting in $[0,2^{2f}u^{2}h_{k}]$ . An arithmetic right shift by $f$ bits scales $\\tilde{z}_{i}^{(k)}$ to $[0,2^{f}u^{2}h_{k}]$ to align with $\\tilde{b}_{i}$ in $[0,2^{f}u]$ (in floating-point arithmetic, the addition would involve values in $[0,u^{2}h_{k}]$ and $[0,u])$ . The clamp operation then restricts $\\tilde{y}_{i}^{(k)}$ to $[0,2^{f}u]$ , ensuring consistency with the floating-point arithmetic, where the value would lie within $[0,u]$ . ", "page_idx": 16}, {"type": "text", "text": "To prevent overflow in the SMT query, we set bit-vector sizes appropriately. Let $B$ be such that $2^{B}\\,\\geq\\,2^{f}u$ . Each product $\\tilde{w}_{i j}^{(k)}\\tilde{x}_{j}^{(k)}$ requires up to $2B$ bits, and summing $h_{k}$ terms necessitates additional $\\log{h_{k}}$ bits. ", "page_idx": 16}, {"type": "text", "text": "This encoding is standard in post-training quantisation of fully connected layers [49]. For elementwise multiplication layers, where each input is multiplied by a corresponding weight, we quantise $w_{i}\\cdot x_{i}$ as $\\mathrm{ashr}(\\tilde{w}_{i}\\cdot\\tilde{x}_{i};f)$ : Again, $\\tilde{w}_{i}\\tilde{x}_{i}$ lies within $[\\bar{0},2^{2f}u^{\\bar{2}}]$ , and the right shift scales it back to $[0,2^{f}u^{2}]$ , ensuring consistency with the floating point encoding. ", "page_idx": 16}, {"type": "text", "text": "To address the significant slowdown caused by negative numbers in the Bitwuzla SMT-solver during our experiments, we restructured the dot product computation in equation 7. By decomposing the weight vector $\\tilde{w}_{i j}$ into two non-negative components\u2014 $\\tilde{w}_{i j}^{+}$ containing positive weights and $\\tilde{w}_{i j}^{-}$ containing the absolute values of negative weights\u2014we expressed the linear layers as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{j=1}^{h}\\tilde{w}_{i j}\\tilde{x}_{j}=\\sum_{j=1}^{h}\\tilde{x}_{j}\\tilde{w}_{i j}^{+}-\\sum_{j=1}\\tilde{x}_{j}\\tilde{w}_{i j}^{-}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This transformation simplified multiplications to involve only non-negative numbers and consolidated negative operations into a single subtraction, speeding up the SMT-check in our experiments. ", "page_idx": 16}, {"type": "text", "text": "We further rewrite the SMT encoding\u2014originally involving several ${\\tilde{a}}\\cdot{\\tilde{x}}$ multiplications, where $\\tilde{x}$ is a neuron value and $\\tilde{a}$ is a quantised integer weight\u2014by replacing these multiplications with additions and left shifts. By factorising $\\tilde{a}$ as a sum of powers of two, $\\begin{array}{r}{\\tilde{{a}}=\\sum_{i=0}^{d}c_{i}\\cdot2^{i}}\\end{array}$ , where $c_{i}\\in\\{0,1\\}$ , the multiplication can be rewritten as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\tilde{a}\\cdot\\tilde{x}=\\sum_{i=0}^{d}c_{i}\\cdot\\mathrm{shl}(\\tilde{x};i),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathrm{shl}(\\tilde{x};i)$ represents left-shifting $x$ by $i$ bits, effectively multiplying $x$ by $2^{i}$ . ", "page_idx": 16}, {"type": "text", "text": "B Details of the Case Studies ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We consider ten hardware designs in our study. These serve as benchmarks to demonstrate the scalability of our method compared to conventional symbolic model checkers. They are designed to be parameterizable. ", "page_idx": 17}, {"type": "text", "text": "The DELAY models generates a positive signal ${\\tt s i g}$ after a fixed delay determined by the counter cnt, includes a reset input event that sets $\\mathsf{c n t}$ to 0, and aims to ensure that sig occurs infinitely often under the assumption that the reset event rst is received finitely many times, resulting in the specification FG !rst $\\rightarrow\\tt G F$ sig. We further verify FG !rst $\\rightarrow\\mathsf{G F}$ $(\\tt s i g\\wedge X:s i g)$ , to ensure sig doesn\u2019t remain triggered forever. ", "page_idx": 17}, {"type": "text", "text": "The LCD Controller (LCD) performs a display initialisation setup, then awaits the lcd_enable signal to transition from ready to send for data transmission, and returns to ready after a fixed interval, ensuring FG lcd_enable $\\rightarrow\\mathsf{G F}$ ready. ", "page_idx": 17}, {"type": "text", "text": "Similarly, Thermocouple (Tmcp.) transitions through stages, start, get_data and pause with suitable delay in between, processing SPI transactions and managing transitions based on bus activity, adhering to the specification FG !rst \u2192GF get_data. ", "page_idx": 17}, {"type": "text", "text": "The 7-Segment $(7-\\mathtt{S e g})$ model alternates between two displays, ensuring each is activated regularly unless reset, as specified by FG $:\\mathtt{l r s t}\\to(\\mathsf{G F}\\,\\mathtt{d i s p}\\;=\\;0\\,\\land\\,\\mathsf{\\bar{G F}}\\,\\mathtt{d i s p}\\;=\\;\\bar{1})$ , we also verify a simpler specification $\\mathsf{F G}:\\mathtt{r s t}\\to\\mathsf{G F}\\;\\mathsf{d i s p}\\;=\\;1$ . ", "page_idx": 17}, {"type": "text", "text": "The i2c Stretch (i2cS) generates timing signals scl_clk and data_clk based on the ratio of input and bus clock frequencies [90, 92]. It monitors rst and detects the ena signal to manage clock stretching, ensuring $\\mathsf{F G}\\left(\\mathsf{\\Omega}_{:\\,\\mathtt{r s t}\\,\\&\\,\\mathtt{e n a}}\\right)\\to\\mathsf{G F}$ stretch. ", "page_idx": 17}, {"type": "text", "text": "The Pulse Width Modulation (PWM) system utilises an $N$ -bit counter to adjust pulse widths dynamically based on input, verifying the low setting of pulse infinitely often as GF !pulse [54]. ", "page_idx": 17}, {"type": "text", "text": "The VGA Controller (VGA) manages a display interface using horizontal and vertical counters for pixel coordinates, ensuring smooth rendering by adjusting sync pulses and the display enable signal disp_ena, here we confirm FG ! $\\colon\\mathtt{r s t}\\to\\mathtt{G F}$ disp_ena. ", "page_idx": 17}, {"type": "text", "text": "The UART Transmitter (UARTt) toggles between wait for preparing data and transmit for sending data, based on tx_ena requests and clk signals, validated by FG !rst $\\rightarrow\\tt G F$ wait [90]. ", "page_idx": 17}, {"type": "text", "text": "The Load-Store (LS) toggles between load and store with a delay implemented by counter which counts from 0 up to $_\\mathrm{N}$ when load then switch to store counting back down to 0, before switching back to load, sig signals a switch from load to store, and we verify FG !rst $\\rightarrow$ GF sig. ", "page_idx": 17}, {"type": "text", "text": "Lastly, the Gray Counter (Gray) counts in Gray codes to minimise transition errors by ensuring single bit changes between consecutive counts, with $\\mathsf{F G}:\\mathtt{r s t}\\to\\mathsf{G F}$ sig, indicating regular signalling of complete cycles [97]. Similar to the Delay module, we aim to ensure that the signal sig does not remain triggered indefinitely. We establish this with two distinct specifications $\\mathsf{F G!r s t\\to}$ $\\mathsf{G F}(\\mathbf{sig}\\wedge\\mathsf{X}:\\mathbf{sig})$ and $\\mathsf{F G}\\colon\\mathbf{rst}\\to(\\mathsf{G F s i g}\\land\\mathsf{G F}\\because\\mathtt{s i g})$ . ", "page_idx": 17}, {"type": "text", "text": "C Details of the Experimental Results ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Table 3 provides the runtimes for each tool on the 194 verification tasks considered in Section 5. These tasks involve verifying each hardware design across an increasing state space, labelled numerically. The \u201cTrain Time\u201d column indicates the training duration for the neural network in seconds, while the other columns represent the total runtime for each tool, with the fastest tool time in bold and the rest in grey. In this table, our method uses the configuration described in Section 5, with two hidden layers containing 8 and 5 neurons, respectively. Some of our runtimes are marked with an asterisk $(^{*})$ , indicating that in those cases we obtained counterexamples using the SMT solver; these were used for retraining and then validating the trained network. The reported time includes all SMT checks and training. Table 1 summaries these results by showing the number of tasks successfully completed by each tool for each design. Tasks not marked as out of time (oot.) or did not train (dnt.) are considered successful. Table 3 serves as the basis for computing all statistical observations discussed in Section 1 and Section 5, except those related to the \"our best\" line in Figure 6a. All other components of Figure 6 are derived from this table. By aggregating the duration of each experiment in the table, including OOT instances counted as 5 hours per experiment, the total time amounts to 104 days and 11 hours. ", "page_idx": 17}, {"type": "table", "img_path": "dJ9KzkQ0oH/tmp/fb0729c9e95e4010c3c0fb458dc5112d66fa3ada14481ac86fc2a93356b02f56.jpg", "table_caption": ["Table 2: Model Name and LTL Specification in our Benchmark "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "D Ablation Study ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The network architecture described in Section 3 includes an element-wise multiplication layer and separate trainable parameters associated with each state of the automaton $A_{\\neg\\Phi}$ . For most of our experiments in Section 5 and all experiments in Appendix C, we employ a fully connected multilayer perceptron component with two hidden layers containing 8 and 5 neurons, respectively. To experimentally justify our architecture, we perform an ablation study and report the runtimes for different configurations in Table 4. We consider three configurations for the two hidden layers: containing (3, 2) neurons, (5, 3) neurons, and (15, 8) neurons, respectively. We further replace the element-wise multiplication layer with a fully connected layer of the same size, denoted as \u2018ExtL\u2019 for the extra layer. Additionally, we explore providing the global trainable parameters $\\theta$ to all automaton states of the automaton $\\mathcal{A}_{\\neg\\Phi}$ , leading to a monolithic neural ranking function $V(r,q)\\equiv\\bar{V}(r,q;\\theta)$ , where the automaton state $q$ is given as an additional input, which we denote as \u2018Mono\u2019. ", "page_idx": 18}, {"type": "text", "text": "Given the large number of possible combinations of these modifications, we restrict our ablation study to switching only a single configuration at a time. In Table 4, the column labelled \u2018Default\u2019 contains the results for our original configuration\u2014the runtimes in this column are the same as those under \u2018Our (8, 5)\u2019 in Table 3. Following that, we have one column for each of the three hidden layer configurations, followed by columns for the extra layer (\u2018ExtL\u2019), and the monolithic neural ranking function (\u2018Mono\u2019). The \u2018our best\u2019 line in Figure 6a is obtained by selecting the minimum runtime from the \u2018Default\u2019 and the three hidden layer configuration columns for each of the 194 tasks. ", "page_idx": 18}, {"type": "text", "text": "From Table 4, we observe that our default configuration succeeds in more cases than the alternative configurations, justifying our choices experimentally. Specifically, the default configuration completes $93\\,\\%$ of the tasks, while the three configurations with hidden layers containing (3, 2), (5, 3), and (15, 8) neurons complete $25\\,\\%$ , $63\\,\\%$ , and $\\bar{7}4\\,\\%$ of the tasks, respectively. The extra-layer configuration and the monolithic neural ranking function complete $24\\,\\%$ , and $39\\,\\%$ , of the tasks, respectively. ", "page_idx": 18}, {"type": "text", "text": "Generally\u2014but not always\u2014when a smaller network succeeds, its runtime is lower than that of the default network. Specifically, among the tasks completed by the (3, 2) neuron configuration, it was faster than the default configuration in $57\\,\\%$ of cases; for the (5, 3) neuron configuration, this statistic rises to $94\\%$ . Interestingly, this trend does not hold when comparing the (3, 2) and (5, 3) configurations: despite having more neurons, the (5, 3) configuration was faster than the (3, 2) configuration in $56\\,\\%$ of tasks. The default configuration not only completes more tasks than the (15, 8) configuration but is also faster on $97\\,\\%$ of the tasks successfully completed by the (15, 8) configuration. Notably, among the hidden layer configurations only the (15, 8) configuration succeeds on any of the tasks for the VGA design, labelled as $\\mathbf{\\nabla}\\mathbf{V}^{\\bullet}$ in the table. In $67\\,\\%$ of the tasks that the \u2018Ext. L\u2019 configuration completes, it is faster than the default configuration; this figure rises to $86\\,\\%$ for the \u2018Mono\u2019 configuration. While the monolithic neural ranking function (\u2018Mono\u2019) fails on $61\\%$ of tasks, it surprisingly succeeds on nine out of the ten tasks for the VGA design. Overall, only 5 of the 194 tasks fail under all configurations in the ablation study. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The primary claims of our paper are outlined in the abstract and further detailed in Section 1. Here, we briefly discuss the theoretical aspects of our claims and provide a brief summary of experiments that quantify the scalability of our method. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: Our paper includes a subsection on \u2018Limitations\u2019 in Section 5, where we clearly outline our assumptions and justify their reasonableness alongside our theoretical limitations. In the same section, the \u2018Threats to Validity\u2019 subsection validates the scope of our claims by justifying the benchmarks used to compare our method against tools developed with alternative verification methods. Section 5 also presents two case studies, VGA and UART, to discuss the performance limitations of our approach, in comparison to others. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: We provide references for all theoretical results we rely on, i.e., automatatheoretical LTL model checking and fair termination, in Sec. 2 ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: Subsections \u2018Implementation\u2019, \u2018Dataset Generation\u2019, and \u2018Network Hyperparameters\u2019 in Section 5 detail the workflow and specify the versions of our dependencies. These subsections clearly outline the hyperparameters and neural network architecture used. Specifically, Section 3 addresses theoretical aspects of the loss function, dataset generation, training procedures, neural network architecture, and the SMT-check problem. In contrast, the aforementioned subsections of Section 5 focus on practical implementation details, together providing sufficient information for implementing neural model checking. Additionally, \u2018Standard Model Checkers\u2019 and \u2018Industrial Verification Tools\u2019 discuss the tool versions we compare against. For additional specific implementation details, our code and benchmarks will be made available. ", "page_idx": 19}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: Alongside the paper, we include a zip file in accordance with NeurIPS guidelines. This file contains benchmarks, scripts for running our experiments, and a README.md file that offers detailed instructions on how to reproduce our experiments. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: Section 5, particularly the \u2018Network Hyper-parameter\u2019 subsection, outlines training details and along with other subsections in the section provides essential information for interpreting the results. Appendix C includes a table with the data used to generate the figures and tables in the main body of the paper. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer:[Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: While error bars and confidence intervals are typically not applicable to our experiments that compare formal verification tools\u2014which must be formally correct\u2014we still present statistical data about our benchmarks. This data includes the range of logic gate counts and state space sizes considered for each design. Such metrics are definable for each SystemVerilog file and inherently free from errors. These details are presented in Figure 5. We further discuss potential biases of the benchmark set in the subsection \u2018Threats to Validity\u2019 in Section 5. ", "page_idx": 20}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: The computational resources allocated for our experiments are outlined in Section 5. The Appendix C details the computational time required for each experiment and the cumulative time to run all experiments sequentially. We included all our experiments in the experimental evaluation Section 5, and we discuss the experiments where our tool performs worse than the alternatives in the discussion of its limitations. ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: We hereby affirm that all information presented in our research is disclosed with utmost academic integrity. Original works are duly cited and we ensure the reproducibility of our methodology through a detailed description of it throughout the paper, we also provide our implementation of the methodology with all our experiments in the supplementary materials accompanying this paper. Notably, our experiments utilize solely synthetic data, with no human subjects involved, thereby aligning with ethical research standards. Our method aims to enhance the reliability and safety of computer systems. The benchmarks employed are derived from standard algorithms extensively documented in academic textbooks, which are referenced appropriately. Furthermore, we have thoroughly reviewed the NeurIPS Code of Ethics and confirm our strict adherence to it. ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: As discussed in the introduction, it is conceivable that improving the correctness of hardware designs prior to production delivers safer and more reliable devices; not manufacturing buggy silicon reduces waste. We are not aware of a direct path to a negative application. ", "page_idx": 21}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: Our work contributes to the safety of hardware systems. The designs used in our benchmarks are standard designs, from well-known literature, which are public domain and pose no risks for misuse. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We include the licences of the academic tools ABC and nuXmv. Appropriate references are used. ", "page_idx": 21}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: We include the source of code of our prototype and our benchmarks as supplementary material of this paper with MIT licence. ", "page_idx": 21}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 21}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: Neither crowdsourcing nor human subjects are involved. ", "page_idx": 21}, {"type": "table", "img_path": "dJ9KzkQ0oH/tmp/d2f18cd9e82e5dd3575a6fc9add384bfad3c024894b24cfddea3bf600e3f18d8.jpg", "table_caption": ["Table 3: Runtime comparison with the state of the art on individual tasks. "], "table_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "dJ9KzkQ0oH/tmp/f5d33db010daf44f1eb130b4785b061f121cdcaa40594162667ed0fc3ca0b178.jpg", "table_caption": ["Table 4: Ablation Study Runtime. "], "table_footnote": [], "page_idx": 23}]