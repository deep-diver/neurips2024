[{"figure_path": "dJ9KzkQ0oH/tables/tables_6_1.jpg", "caption": "Table 3: Runtime comparison with the state of the art on individual tasks.", "description": "This table presents a detailed comparison of the runtime performance of the proposed neural model checking method against three state-of-the-art model checkers (ABC, nuXmv, and Industry Tool X) across 194 verification tasks.  The tasks are categorized by hardware design and include the training time for the neural network, as well as the total time taken by each tool to complete each verification task.  The table highlights the effectiveness of the proposed method, showing that it outperforms other tools, especially in terms of the time it takes to successfully complete verification tasks.", "section": "Experimental Evaluation"}, {"figure_path": "dJ9KzkQ0oH/tables/tables_7_1.jpg", "caption": "Table 1: Number of verification task completed by academic and industrial tool, per design", "description": "This table presents the number of verification tasks successfully completed by four different model checkers (ABC, nuXmv, the authors' method, and an unnamed industrial tool) across ten different hardware designs.  Each design is further broken down into multiple tasks of varying complexity.  The table allows a comparison of the performance of different model checking approaches on a wide range of verification problems.", "section": "Experimental Evaluation"}, {"figure_path": "dJ9KzkQ0oH/tables/tables_18_1.jpg", "caption": "Table 3: Runtime comparison with the state of the art on individual tasks.", "description": "This table details the runtime comparison of the proposed neural model checking method against existing state-of-the-art academic and commercial model checkers on 194 individual verification tasks.  For each task, it lists the training time for the neural network and the total runtime for each tool, highlighting the fastest time.  The table also indicates instances where tools timed out or failed to train.  This comprehensive comparison demonstrates the proposed method's performance relative to the existing tools across various benchmarks and complexities.", "section": "5 Experimental Evaluation"}, {"figure_path": "dJ9KzkQ0oH/tables/tables_22_1.jpg", "caption": "Table 3: Runtime comparison with the state of the art on individual tasks.", "description": "This table presents a detailed breakdown of the runtime performance of the proposed neural model checking method against existing state-of-the-art methods (nuXmv, ABC, and Industry Tool X) across 194 verification tasks.  For each task, the table shows the training time for the neural network, and the total runtime for each tool. The results are presented in seconds, with 'oot.' indicating that a tool timed out, and 'dnt.' indicating that the tool did not complete the task. This provides granular information to understand the performance differences across tasks of varying complexity.", "section": "5 Experimental Evaluation"}, {"figure_path": "dJ9KzkQ0oH/tables/tables_23_1.jpg", "caption": "Table 3: Runtime comparison with the state of the art on individual tasks.", "description": "This table presents a detailed comparison of the runtime performance of the proposed neural model checking method against state-of-the-art academic and commercial model checkers on 194 verification tasks. For each task, the table shows the training time for the neural network, along with the total runtime for each tool. The fastest runtime is highlighted in bold, and the table includes additional information about tasks that did not complete within the time limit or encountered issues during training. This comprehensive comparison allows for a thorough evaluation of the proposed method's efficiency and scalability.", "section": "5 Experimental Evaluation"}]