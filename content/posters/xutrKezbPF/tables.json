[{"figure_path": "xutrKezbPF/tables/tables_7_1.jpg", "caption": "Table 1: Acc. (%) on CIFAR-100 over simple CNNs. All numbers from our implementation.", "description": "This table presents the classification accuracy (%) on CIFAR-100 dataset using simple Convolutional Neural Networks (CNNs). It compares the performance of different knowledge distillation methods, including the baseline (KD), Teacher Assistant KD (TAKD), Densely Guided KD (DGKD), and the proposed Controlled Information Flow for Knowledge Distillation (CIFD) with varying numbers of Rate-Distortion Modules (RDMs). The results show the improvement achieved by CIFD over existing methods.", "section": "4.1 Supervised Training"}, {"figure_path": "xutrKezbPF/tables/tables_7_2.jpg", "caption": "Table 2: Acc. (%) on CIFAR-100. Comparison with more baselines in Table 10.", "description": "This table presents the classification accuracy results on CIFAR-100 dataset. It compares the performance of the proposed CIFD method with several other knowledge distillation techniques, including KD, TAKD, DGKD, AT, FT, CRD, WSLD, and IPWD.  The table shows accuracy for two different student model architectures (WRN-40-1 and resnet8x4) when trained to distill knowledge from two different teacher models (WRN-40-2 and resnet32x4).", "section": "4.1 Supervised Training"}, {"figure_path": "xutrKezbPF/tables/tables_7_3.jpg", "caption": "Table 3: Acc. (%) on ImageNet. Comparison with more baselines in Table 11.", "description": "This table presents the Top-1 and Top-5 accuracy results on the ImageNet dataset for different knowledge distillation methods.  It compares the performance of CIFD (with 3 RDMs) against several other state-of-the-art methods, including KD, FT, TAKD, DGKD, IFD, NormKD, IPWD, and DistKD.  Two scenarios are shown: one where the teacher and student models have the same architecture style (ResNet-34 to ResNet-18), and another where they use different architectures (ResNet-50 to MobileNet-v1). CIFD achieves state-of-the-art results in both scenarios.", "section": "4.1 Supervised Training"}, {"figure_path": "xutrKezbPF/tables/tables_8_1.jpg", "caption": "Table 4: Zero-shot image-text classification performance on ImageNet and Object Net, and retrieval performance on FlickR30k [53] test sets. Zero-shot classification over more datasets in Table 14, zero-shot retrieval results over more datasets in Table 15. All results reproduced by us.", "description": "This table presents the zero-shot performance results of different CLIP-like models on ImageNet, ObjectNet, and Flickr30k datasets.  The results include top-1 and top-5 accuracy for classification tasks, and recall at ranks 1, 5, and 10 for retrieval tasks.  The table compares the proposed CIFD method against several other state-of-the-art CLIP distillation methods (OpenCLIP, TinyCLIP, CLIPKD) across various teacher-student model combinations. It highlights the improved performance of CIFD, especially when there is a large capacity gap between the teacher and student models.", "section": "4.2 Image Language Pretraining"}, {"figure_path": "xutrKezbPF/tables/tables_8_2.jpg", "caption": "Table 5: Effect of number of RDMs on zero-shot image-text classification over ImageNet and Object Net, and retrieval over Flickr30k [53] test sets. Best in bold and second best underlined.", "description": "This table shows the impact of using different numbers of Rate-Distortion Modules (RDMs) on the performance of the CIFD method.  The results are presented for zero-shot image-text classification on ImageNet and ObjectNet datasets, as well as zero-shot image-text retrieval on the Flickr30k dataset. The table highlights how increasing the number of RDMs can improve performance, with the best results obtained using 3 RDMs.", "section": "4.3 Ablation studies"}, {"figure_path": "xutrKezbPF/tables/tables_9_1.jpg", "caption": "Table 6: Ablation study of number of RDMs and IBM. IBM is crucial when number of RDMs increases.", "description": "This table presents the ablation study results to analyze the impact of the number of Rate-Distortion Modules (RDMs) and the Information Bottleneck Module (IBM) on the model's performance.  It shows the accuracy achieved on the CIFAR-100 dataset and the ImageNet dataset (distilling ResNet34 to ResNet18) with varying numbers of RDMs, both with and without the IBM.  The results demonstrate the effectiveness of IBM in regularizing the model when multiple RDMs are used, preventing overfitting and improving generalization.", "section": "4.3 Ablation studies"}, {"figure_path": "xutrKezbPF/tables/tables_9_2.jpg", "caption": "Table 3: Acc. (%) on ImageNet. Comparison with more baselines in Table 11.", "description": "This table presents the top-1 and top-5 accuracy results on the ImageNet dataset for different knowledge distillation methods.  It compares the performance of the proposed CIFD method against several existing state-of-the-art knowledge distillation techniques, specifically focusing on distilling from ResNet-34 to ResNet-18 and ResNet-50 to MobileNet-v1. The table highlights the improvement achieved by CIFD compared to other methods.", "section": "4.1 Supervised Training"}, {"figure_path": "xutrKezbPF/tables/tables_15_1.jpg", "caption": "Table 1: Acc. (%) on CIFAR-100 over simple CNNs. All numbers from our implementation.", "description": "This table compares the accuracy of different knowledge distillation methods on the CIFAR-100 dataset using simple Convolutional Neural Networks (CNNs).  It shows the accuracy of a student model trained using various methods (KD, TAKD, DGKD, and CIFD with varying numbers of RDMs) in comparison to the teacher model accuracy. The results highlight the performance gains achieved by using the proposed CIFD approach.", "section": "4.1 Supervised Training"}, {"figure_path": "xutrKezbPF/tables/tables_16_1.jpg", "caption": "Table 9: CLIP model architectures. The architecture corresponds to the implementation in [58].", "description": "This table details the architectures of various CLIP models used in the experiments.  It shows the embedding dimensions, vision encoder details (model architecture, image size, layers, width, patch size), and text encoder details (model architecture, context length, vocabulary size, width, heads, layers) along with the total number of parameters for each model.  These details are crucial for understanding the computational cost and performance characteristics of the different CLIP models used in the knowledge distillation experiments described in the paper. The models include ResNet50, ViT-S-16, ViT-B-16 and ViT-L-14, all of which are variations of Vision Transformer models used to process image data and Transformer-based models used to process text data.", "section": "A.3 CLIP"}, {"figure_path": "xutrKezbPF/tables/tables_17_1.jpg", "caption": "Table 10: Top-1 accuracies (%) on CIFAR-100", "description": "This table compares the performance of the proposed CIFD method against several other state-of-the-art knowledge distillation methods on the CIFAR-100 dataset.  The results are shown for two different teacher-student model architectures (WRN-40-2 to WRN-40-1 and resnet32x4 to resnet8x4).  It demonstrates that CIFD achieves competitive performance compared to existing methods.", "section": "4.1 Supervised Training"}, {"figure_path": "xutrKezbPF/tables/tables_18_1.jpg", "caption": "Table 3: Acc. (%) on ImageNet. Comparison with more baselines in Table 11.", "description": "This table shows the top-1 and top-5 accuracy results on the ImageNet dataset for different knowledge distillation methods.  It compares the performance of CIFD (the proposed method) against several other state-of-the-art methods for two different teacher-student model architectures: ResNet-34 to ResNet-18 and ResNet-50 to MobileNet-v1.  The results highlight CIFD's superior performance compared to existing techniques.", "section": "4.1 Supervised Training"}, {"figure_path": "xutrKezbPF/tables/tables_19_1.jpg", "caption": "Table 12: Zero-shot image classification performance with same teacher different students. Larger the parameter ratio between teacher to student, CIFD shows larger benefit over CLIPKD for 3 out 5 datasets.", "description": "This table presents the results of zero-shot image classification experiments using different teacher-student model combinations.  It compares the performance of the proposed CIFD method against CLIPKD, highlighting the performance gains achieved with CIFD, especially when the model size difference (parameter ratio) between the teacher and student models is significant. The results are presented across five datasets (IN, IN-V2, IN-R, IN-A, ObjNet), showing Top-1 and Top-5 accuracies. The table emphasizes that CIFD's advantage over CLIPKD is particularly pronounced when there is a considerable disparity in model size between the teacher and student.", "section": "4.2 Image Language Pretraining"}, {"figure_path": "xutrKezbPF/tables/tables_19_2.jpg", "caption": "Table 15: Zero-shot image-text retrieval performance on COCO [52] and FlickR30k [53] test sets. All methods use the first Teacher, MobileCLIP additionally uses Teacher-2\u2020.", "description": "This table compares the zero-shot image-text retrieval performance of different methods on the COCO and Flickr30k datasets.  It shows the recall at different ranks (R@1, R@5, R@10) for both image-to-text and text-to-image retrieval tasks.  The results are broken down by model (ViT-L-14, ViT-S-16, ViT-B-16, RN50) and method (OpenCLIP, MobileCLIP, TinyCLIP, CLIPKD, CIFD).  The table highlights the improvements achieved by CIFD over existing methods, especially for larger teacher-student model size differences.", "section": "4.2 Image Language Pretraining"}, {"figure_path": "xutrKezbPF/tables/tables_19_3.jpg", "caption": "Table 4: Zero-shot image-text classification performance on ImageNet and Object Net, and retrieval performance on FlickR30k [53] test sets. Zero-shot classification over more datasets in Table 14, zero-shot retrieval results over more datasets in Table 15. All results reproduced by us.", "description": "This table presents the zero-shot performance comparison of different methods on various image and text classification and retrieval tasks.  It shows the Top-1 and Top-5 accuracies for zero-shot image classification on ImageNet and ObjectNet datasets and the Recall@1, Recall@5, and Recall@10 for zero-shot image-text retrieval on the Flickr30k dataset. The results highlight the superior performance of the proposed CIFD method compared to existing state-of-the-art techniques.", "section": "4.2 Image Language Pretraining"}, {"figure_path": "xutrKezbPF/tables/tables_20_1.jpg", "caption": "Table 4: Zero-shot image-text classification performance on ImageNet and Object Net, and retrieval performance on FlickR30k [53] test sets. Zero-shot classification over more datasets in Table 14, zero-shot retrieval results over more datasets in Table 15. All results reproduced by us.", "description": "This table presents the zero-shot performance of different models on ImageNet, ObjectNet, and Flickr30k datasets.  The performance is measured using Top-1 and Top-5 accuracy for classification and Recall@1, Recall@5, and Recall@10 for retrieval tasks.  The results compare the proposed CIFD method against several existing CLIP distillation methods (TinyCLIP, CLIPKD) and a baseline (OpenCLIP). The table shows that CIFD consistently outperforms the other methods across all datasets and metrics, highlighting its effectiveness in improving zero-shot capabilities of CLIP-like models.", "section": "4.2 Image Language Pretraining"}]