[{"figure_path": "r5nev2SHtJ/tables/tables_8_1.jpg", "caption": "Table 1: Linear identifiability when number of concepts n is less than latent dimension dz with observed dimension dx, averaged over 5 seeds.", "description": "This table presents the results of experiments on linear identifiability when the number of concepts (n) is less than the latent dimension (dz) with different observed dimensions (dx). The results are averaged over five seeds, providing a measure of the robustness of the findings.  The table shows the R\u00b2 (R-squared) and MCC (Matthews correlation coefficient) metrics, which quantify the accuracy of the linear identifiability of the concepts.  Higher values indicate better performance.", "section": "6 Experiments"}, {"figure_path": "r5nev2SHtJ/tables/tables_30_1.jpg", "caption": "Table 2: Mean valuations and standard deviation on the test set for the floor hue and wall hue attributes.", "description": "This table presents the mean and standard deviation of the concept valuations for the floor hue and wall hue attributes on a test set, using two different CLIP models (ViT-B/32 and RN101).  Each row represents a specific hue value (0.0 to 0.9), and the columns show the mean and standard deviation of the valuations for each model.  The data illustrates the distributions of the valuations for each hue and how consistent the valuations are between the models.", "section": "Probing the theory on multimodal CLIP models"}, {"figure_path": "r5nev2SHtJ/tables/tables_31_1.jpg", "caption": "Table 3: Mean valuations and standard deviation on the test set for the object hue and scene orientation attributes.", "description": "This table presents the mean and standard deviation of the concept valuations for object hue and scene orientation attributes obtained from two different CLIP models (ViT-B/32 and RN101).  The results show the average value and variability of the learned concepts for different values of the attributes on a held-out test set.  The variations of object hue are 0.0 to 0.9, with corresponding mean valuations reported for each CLIP model.", "section": "D.2 Further results"}, {"figure_path": "r5nev2SHtJ/tables/tables_31_2.jpg", "caption": "Table 3: Mean valuations and standard deviation on the test set for the object hue and scene orientation attributes.", "description": "This table presents the mean and standard deviation of the concept valuations for the object hue and scene orientation attributes on a test set.  The valuations were obtained using two different pretrained CLIP models (ViT-B/32 and RN101). The data shows the concept valuations for different values of the hue and orientation, allowing for an analysis of how well these concepts are captured by the models.  The results are relevant to the paper's investigation into the linear representation hypothesis for human-interpretable concepts in multimodal models.", "section": "D.2 Further results"}, {"figure_path": "r5nev2SHtJ/tables/tables_31_3.jpg", "caption": "Table 4: Mean valuations and standard deviation on the test set for the scale and shape attributes.", "description": "This table presents the mean and standard deviation of concept valuations for the scale and shape attributes obtained from two different CLIP models (ViT-B/32 and RN101) on a test set.  The results are broken down by the specific values of the scale and shape attributes.  The table helps evaluate the linearity of representation hypothesis by examining the concept valuations across different models and values.", "section": "Experiments"}, {"figure_path": "r5nev2SHtJ/tables/tables_31_4.jpg", "caption": "Table 4: Mean valuations and standard deviation on the test set for the scale and shape attributes.", "description": "This table shows the mean and standard deviation of the concept valuations for the scale and shape attributes on the test set, using two different CLIP models (ViT-B/32 and RN101).  The results are separated for different shapes (cube, cylinder, ball, ellipsoid) and for different scales (0.8, 0.9, 1.0, 1.1, 1.2).  The concept valuation is the value of the linear projection of the image embedding into the concept vector.", "section": "6 Experiments"}, {"figure_path": "r5nev2SHtJ/tables/tables_32_1.jpg", "caption": "Table 5: Correlation coefficients of the evaluations learned for two different CLIP models evaluated on the full dataset.", "description": "This table shows the correlation coefficients between the concept valuations obtained from two different CLIP models (ViT-B/32 and RN101) for six different factors of variation in the 3D-Shapes dataset.  High correlation suggests that the concept valuations learned from different models are consistent, up to a linear transformation. The factors of variation included are floor hue, wall hue, object hue, scale, shape and orientation. ", "section": "Probing the theory on multimodal CLIP models"}, {"figure_path": "r5nev2SHtJ/tables/tables_36_1.jpg", "caption": "Table 6: Comparison of steering vectors for LLM alignment", "description": "This table compares the performance of different steering vector techniques for improving the truthfulness of LLMs using the TruthfulQA benchmark.  The techniques compared include a baseline, a random direction, a CCS direction, two variants of ITI (Probe weight and Mass mean shift), and a novel approach using steering matrices.  The table shows the accuracy, cross-entropy loss, and KL divergence for each technique, providing a quantitative comparison of their effectiveness in aligning LLMs toward truthfulness.", "section": "Alignment of LLMs"}, {"figure_path": "r5nev2SHtJ/tables/tables_38_1.jpg", "caption": "Table 1: Linear identifiability when number of concepts n is less than latent dimension dz with observed dimension dx, averaged over 5 seeds.", "description": "This table presents the results of linear identifiability experiments conducted on synthetic data. The experiments varied the number of concepts (n), the latent dimension (dz), and the observed dimension (dx).  The table shows the R-squared (R2) and Matthews Correlation Coefficient (MCC) values obtained, averaged over five different random seeds, for both linear and non-linear mixing functions.  Higher R2 and MCC values indicate better identifiability.", "section": "6 Experiments"}]