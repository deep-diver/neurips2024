[{"figure_path": "B9FPPdNmyk/figures/figures_1_1.jpg", "caption": "Figure 1: (a): Models trained on in-distribution (ID) data inevitably encounter distributional shifts during their deployment. OOD generalization expects the model to correctly classify covariate-shifted data that undergoes noise or corruption due to environmental issues. OOD detection aims to identify samples that do not belong to any known classes for trustworthiness consideration. (b): Limitations of current SOTA methods.", "description": "This figure demonstrates the challenges of out-of-distribution (OOD) detection and generalization in real-world scenarios.  (a) shows three types of data an autonomous driving model might encounter: in-distribution (ID) data, covariate-shifted OOD data (e.g., a car in rainy conditions), and semantic OOD data (e.g., a deer on the road).  (b) illustrates the dilemma faced by state-of-the-art (SOTA) OOD detection methods, which achieve superior OOD detection performance by sacrificing OOD generalization ability, creating a trade-off.", "section": "1 Introduction"}, {"figure_path": "B9FPPdNmyk/figures/figures_1_2.jpg", "caption": "Figure 1: (a): Models trained on in-distribution (ID) data inevitably encounter distributional shifts during their deployment. OOD generalization expects the model to correctly classify covariate-shifted data that undergoes noise or corruption due to environmental issues. OOD detection aims to identify samples that do not belong to any known classes for trustworthiness consideration. (b): Limitations of current SOTA methods.", "description": "This figure demonstrates the dilemma faced by current state-of-the-art (SOTA) out-of-distribution (OOD) detection methods.  Subfigure (a) illustrates the three types of data encountered in real-world deployments of machine learning models: in-distribution (ID) data, covariate-shifted OOD data (with noise or corruption), and semantic OOD data (samples not belonging to any known class). Subfigure (b) shows that most SOTA OOD detection methods achieve high performance by sacrificing OOD generalization ability. They operate in a trade-off area,  while the proposed method (DUL) achieves both high OOD detection and generalization performance.", "section": "4 Sensitive-robust Dilemma of Out-of-distribution Detection"}, {"figure_path": "B9FPPdNmyk/figures/figures_9_1.jpg", "caption": "Figure 1: (a): Models trained on in-distribution (ID) data inevitably encounter distributional shifts during their deployment. OOD generalization expects the model to correctly classify covariate-shifted data that undergoes noise or corruption due to environmental issues. OOD detection aims to identify samples that do not belong to any known classes for trustworthiness consideration. (b): Limitations of current SOTA methods.", "description": "Figure 1(a) shows three types of data that machine learning models encounter in the real world: in-distribution (ID) data, covariate-shifted OOD data (with noise or corruption), and semantic OOD data (from unknown classes).  Figure 1(b) illustrates the dilemma of current state-of-the-art (SOTA) OOD detection methods.  These methods achieve high OOD detection performance but sacrifice OOD generalization ability.  The figure uses a trade-off area graph to depict this balance.", "section": "4 Sensitive-robust Dilemma of Out-of-distribution Detection"}, {"figure_path": "B9FPPdNmyk/figures/figures_9_2.jpg", "caption": "Figure 2: Visualization of different types of uncertainty estimated by DUL.", "description": "This figure visualizes the different types of uncertainty estimated by the Decoupled Uncertainty Learning (DUL) method.  It shows the distributions of data uncertainty, distributional uncertainty, and total uncertainty for three different model training scenarios: a pretrained model, a model finetuned without DUL, and a model finetuned with DUL. The distributions are shown for both in-distribution (ID) and out-of-distribution (OOD) data, allowing for a comparison of how DUL affects the various uncertainty measures, particularly in relation to OOD detection and generalization.", "section": "6.2 Experimental Results"}, {"figure_path": "B9FPPdNmyk/figures/figures_24_1.jpg", "caption": "Figure 1: (a): Models trained on in-distribution (ID) data inevitably encounter distributional shifts during their deployment. OOD generalization expects the model to correctly classify covariate-shifted data that undergoes noise or corruption due to environmental issues. OOD detection aims to identify samples that do not belong to any known classes for trustworthiness consideration. (b): Limitations of current SOTA methods.", "description": "This figure demonstrates the challenges in out-of-distribution (OOD) detection and generalization.  (a) shows the different types of data encountered during model deployment, including in-distribution (ID) data, covariate-shifted OOD data (noisy or corrupted), and semantic OOD data (from completely different classes).  (b) illustrates the trade-off dilemma that state-of-the-art (SOTA) OOD detection methods face.  These methods achieve high OOD detection performance but at the cost of sacrificing OOD generalization ability.", "section": "1 Introduction"}]