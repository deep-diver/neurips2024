[{"figure_path": "cV2LKBdlz4/figures/figures_4_1.jpg", "caption": "Figure 1: Overview of DiT Score Network Architecture sw (., t). WE denotes the linear layer from the input data space to the linear latent space. f(\u00b7) = R\u00af\u00b9 ofT0R(\u00b7) denotes the transformer network f\u315c(\u00b7) with reshaping layer R(\u00b7), where f\u315c(\u00b7) \u2208 \u0422\u0440,\u0442,1. WB denotes the linear layer from the linear latent space to the input data space. o(t) denote the variance of the conditional distribution P(xt | xo).", "description": "This figure illustrates the architecture of the DiT score network, which is a crucial component in latent diffusion transformers. It shows how the input data (x \u2208 R^D) is processed through several layers to produce the score function estimate (sw(x,t)).  The process involves a linear transformation to a lower-dimensional latent space (x \u2208 R^d0), reshaping the latent representation for use in a transformer network (fT \u2208 Tr,m,l), and a subsequent linear transformation back to the original data space before finally generating the score function.", "section": "DiT Score Network Class"}]