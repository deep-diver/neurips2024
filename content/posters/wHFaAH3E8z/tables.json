[{"figure_path": "wHFaAH3E8z/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of estimation error (in terms of MCC and F-norm= ||new - new ||F) and running time (seconds) on synthetic dataset. \u03a9* is generated from a Random graph. * means that the time exceeds 30 minutes.", "description": "This table presents a comparison of the estimation error and running time of different methods on a synthetic dataset. The estimation error is measured using two metrics: Matthews Correlation Coefficient (MCC) and Frobenius norm (F-norm).  The running time is given in seconds. The dataset used for this comparison is a synthetic dataset generated from a random graph. An asterisk (*) indicates that the running time exceeded 30 minutes.", "section": "6.1 Synthetic Experiment"}, {"figure_path": "wHFaAH3E8z/tables/tables_8_2.jpg", "caption": "Table 1: Comparison of estimation error (in terms of MCC and F-norm= ||new - new ||F) and running time (seconds) on synthetic dataset. \u03a9* is generated from a Random graph. * means that the time exceeds 30 minutes.", "description": "This table presents a comparison of the estimation error (measured by Matthews Correlation Coefficient (MCC) and Frobenius norm) and running time of different methods for estimating precision matrices on synthetic datasets where the true precision matrix is generated from a random graph model.  The results are shown for different sample sizes (n) and numbers of features (p).  The asterisk (*) indicates that the running time exceeded 30 minutes.", "section": "6.1 Synthetic Experiment"}, {"figure_path": "wHFaAH3E8z/tables/tables_23_1.jpg", "caption": "Table 3: Negative log-determinant Bregman divergence of the estimated precision matrices of the new task in the real-world dataset using FasMe and other baselines. A larger value of negative log-determinant Bregman divergence indicates better performance.", "description": "This table compares the performance of FasMe against other baseline methods on two real-world datasets: fMRI and ChIP-Seq.  The metric used is the negative log-determinant Bregman divergence, where a larger value indicates better performance.  The table shows that FasMe significantly outperforms the other methods on both datasets.", "section": "6.2 Real-world Experiment: Application to Gene and fMRI Data"}, {"figure_path": "wHFaAH3E8z/tables/tables_24_1.jpg", "caption": "Table 4: Comparison of standard MDMC and our improved MDMC", "description": "This table compares the standard Maximum Determinant Matrix Completion (MDMC) method with the improved MDMC method proposed in the paper.  It highlights the differences in terms of the type of matrices they handle (partially observed matrices with chordality vs. partially observed matrices) and their time complexity (O(p\u00b2OINV) vs. O(plog\u03b5\u207b\u00b9)). The improved MDMC method offers significantly lower time complexity.", "section": "B.4.3 Meta-student"}, {"figure_path": "wHFaAH3E8z/tables/tables_24_2.jpg", "caption": "Table 5: Random graph, n = 100, p = 1000", "description": "This table presents the MCC scores (%) achieved by the proposed FasMe model on a random graph with varying sparsity levels (1/p, 10/p, 20/p, 30/p, 40/p, 50/p), where n (sample size) = 100 and p (feature dimension) = 1000.  The MCC (Matthews Correlation Coefficient) is a measure of the quality of a binary classification. Higher MCC scores indicate better performance of the model.", "section": "B.5 Accuracy with Different Sparsity"}, {"figure_path": "wHFaAH3E8z/tables/tables_25_1.jpg", "caption": "Table 6: Tree graph, n = 100, p = 1000\nSparsity\nMCC score (%)", "description": "This table presents the MCC scores achieved by the FasMe model on a simulated dataset using a Tree graph structure with 100 samples and 1000 features.  The MCC (Matthews Correlation Coefficient) is a measure of the quality of binary classification; higher values indicate better performance. The different rows represent different levels of sparsity in the generated graph (1/p, 10/p, 20/p, 30/p, 40/p, 50/p), where p is the number of features.", "section": "B.6 Hyperarameter Selection"}, {"figure_path": "wHFaAH3E8z/tables/tables_26_1.jpg", "caption": "Table 7: The time comparisons of FasMe and the baselines on the simulated datasets varying p and sample size n = p/20.", "description": "This table compares the computational time (in seconds) required by FasMe and four baseline methods (QUIC, Neighborhood Selection, Meta-IE, and gRankLasso) to estimate precision matrices on simulated datasets with varying feature dimensions (p) and a fixed sample size (n = p/20).  The results show that FasMe is significantly faster than all the baseline methods, particularly as the dimension p increases. ", "section": "6.1 Synthetic Experiment"}, {"figure_path": "wHFaAH3E8z/tables/tables_26_2.jpg", "caption": "Table 8: The time comparisons of FasMe and the baselines on the simulated datasets varying p and sample size n = p/10.", "description": "This table presents a comparison of the computational time (in seconds) required by FasMe and four baseline methods (QUIC, Neighborhood Selection, Meta-IE, and gRankLasso) for estimating precision matrices on simulated datasets.  The comparison is made across different feature dimensions (p), keeping the sample size (n) constant at one-tenth of the feature dimension (n = p/10). The results highlight the significant speed advantage of FasMe over the other methods, especially as the dimensionality (p) increases.", "section": "6.1 Synthetic Experiment"}, {"figure_path": "wHFaAH3E8z/tables/tables_26_3.jpg", "caption": "Table 9: The time comparisons of FasMe and the baselines on the simulated datasets varying p and sample size n = p/5.", "description": "This table compares the computation time (in seconds) required by FasMe and four baseline methods (QUIC, Neighborhood Selection, Meta-IE, and gRankLasso) for estimating precision matrices on simulated datasets. The feature dimension (p) varies from 500 to 2500, and the sample size (n) is set to p/5.  FasMe demonstrates significantly faster computation times compared to the baselines.", "section": "6.1 Synthetic Experiment"}, {"figure_path": "wHFaAH3E8z/tables/tables_26_4.jpg", "caption": "Table 10: The time comparisons of FasMe and the baselines on the simulated datasets varying p and sample size n = p.", "description": "This table compares the computation time (in seconds) of FasMe against four baseline methods (QUIC, Neighborhood Selection, Meta-IE, and gRankLasso) across five different feature dimensions (p = 500, 1000, 1500, 2000, 2500).  The sample size (n) is set to be equal to the feature dimension (n=p) for each experiment.  The table shows that FasMe is significantly faster than all baseline methods, especially as the dimensionality increases.", "section": "6.1 Synthetic Experiment"}]