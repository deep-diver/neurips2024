{"references": [{"fullname_first_author": "Richard S. Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "1998-01-01", "reason": "This is a foundational textbook in reinforcement learning, providing the basic framework and terminology used throughout the field."}, {"fullname_first_author": "Justin Fu", "paper_title": "D4RL: Datasets for deep data-driven reinforcement learning", "publication_date": "2020-04-07", "reason": "This paper introduced D4RL, a benchmark dataset crucial for evaluating offline reinforcement learning algorithms, which is heavily used in the current paper's experiments."}, {"fullname_first_author": "Tuomas Haarnoja", "paper_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor", "publication_date": "2018-07-01", "reason": "Soft Actor-Critic (SAC) is a widely used off-policy reinforcement learning algorithm, and this paper details its core methodology, which is a key component of the proposed method."}, {"fullname_first_author": "Peter Sunehag", "paper_title": "Value-decomposition networks for cooperative multi-agent learning based on team reward", "publication_date": "2018-07-01", "reason": "This paper presents Value Decomposition Networks (VDN), a crucial multi-agent reinforcement learning algorithm used for efficient cooperation among agents, a core component of the proposed method."}, {"fullname_first_author": "Yihan Wang", "paper_title": "DOP: Off-policy multi-agent decomposed policy gradients", "publication_date": "2020-01-01", "reason": "This paper details DOP, a multi-agent policy gradient algorithm used in the proposed method for efficient optimization within a multi-agent framework."}]}