[{"figure_path": "C4zmR2kyP8/tables/tables_7_1.jpg", "caption": "Table 1: Overall performance (%) of CL methods across three benchmarks under various VL models.", "description": "This table presents a comparison of the performance of different continual learning (CL) methods on three vision-language (VL) benchmarks.  The benchmarks are: 7 Task VG+VAW, 7 Task VG, and 5 Task VAW.  The performance is measured using three metrics: Final Average Accuracy (FAA), Cumulative Average Accuracy (CAA), and Final Forgetting Measure (FFM).  The table shows the performance of various methods including Continual-FT, LORA, Layered-LORA, LwF, ZSCL, MoE-Adapters, ConStruct-VL, and the proposed ZAF method.  The results are presented for different pre-trained VL models: BLIP, BLIP w/ CapFilt-L, and BLIP w/ NLVR. The table allows for a comparison of the effectiveness of different CL methods in terms of accuracy and their ability to prevent forgetting previously learned tasks.", "section": "Experiment"}, {"figure_path": "C4zmR2kyP8/tables/tables_8_1.jpg", "caption": "Table 2: Comparison of training complexity among various CL methods across three benchmarks.", "description": "This table compares different continual learning (CL) methods across three vision-language benchmarks in terms of model size, number of trainable parameters, and training time. It highlights the computational efficiency of the proposed ZAF method compared to other state-of-the-art CL approaches.", "section": "5 Experiment"}, {"figure_path": "C4zmR2kyP8/tables/tables_8_2.jpg", "caption": "Table 1: Overall performance (%) of CL methods across three benchmarks under various VL models.", "description": "This table presents a comparison of the performance of different continual learning (CL) methods on three vision-language (VL) benchmarks using various pre-trained VL models.  The performance is measured using three metrics: Final Average Accuracy (FAA), Cumulative Average Accuracy (CAA), and Final Forgetting Measure (FFM).  The table shows the FAA, CAA, and FFM for each CL method across the three benchmarks and for each of the three pre-trained models. This allows for a comprehensive comparison of the effectiveness of various methods in terms of both learning new tasks and retaining previously acquired knowledge.", "section": "Experiment"}, {"figure_path": "C4zmR2kyP8/tables/tables_17_1.jpg", "caption": "Table 1: Overall performance (%) of CL methods across three benchmarks under various VL models.", "description": "This table presents a comparison of the performance of different continual learning (CL) methods across three vision-language (VL) benchmarks.  The benchmarks evaluate the ability of models to learn new VL concepts while retaining previously learned ones.  The table shows the final average accuracy (FAA), cumulative average accuracy (CAA), and final forgetting measure (FFM) for each method on each benchmark, using various pre-trained VL models as a base.  Higher FAA and CAA scores indicate better overall performance, while a lower FFM indicates less forgetting of previously learned knowledge.", "section": "Experiment"}, {"figure_path": "C4zmR2kyP8/tables/tables_17_2.jpg", "caption": "Table 1: Overall performance (%) of CL methods across three benchmarks under various VL models.", "description": "This table presents a comprehensive comparison of different continual learning (CL) methods on three vision-language (VL) benchmarks.  It shows the final average accuracy (FAA), cumulative average accuracy (CAA), and final forgetting measure (FFM) for each method across the benchmarks, using various pre-trained VL models (BLIP, BLIP w/ CapFilt-L, BLIP w/ NLVR).  The results highlight the relative performance of each method in terms of learning new tasks while retaining previously acquired knowledge.", "section": "Experiment"}, {"figure_path": "C4zmR2kyP8/tables/tables_20_1.jpg", "caption": "Table 1: Overall performance (%) of CL methods across three benchmarks under various VL models.", "description": "This table presents a comparison of the performance of different continual learning (CL) methods across three vision-language (VL) benchmarks.  The benchmarks evaluate the models' ability to learn new concepts while retaining previously learned ones. The table shows the final average accuracy (FAA), cumulative average accuracy (CAA), and final forgetting measure (FFM) for each method.  The results are presented for three different pre-trained VL models (BLIP, BLIP w/ CapFilt-L, and BLIP w/ NLVR). FAA indicates the final accuracy on all tasks, CAA represents the average accuracy across all tasks, and FFM measures the degree of forgetting on previously learned tasks.  Lower FFM values are better, indicating less forgetting.  The table allows for a comparison of the performance of various methods in terms of accuracy and forgetting across different pre-trained models and benchmarks.", "section": "Experiment"}]