[{"figure_path": "MSsQDWUWpd/figures/figures_8_1.jpg", "caption": "Figure 1: Accuracy plot (average over 50 trials) against the signal-to-noise ratio of the features (ratio of the distance between the means to the standard deviation) for increasing number of convolutions. Here, v = D1/21 and the \u201cGCN with v\u03c5\u2122 removed\u201d refers to convolution with the corrected, normalized adjacency matrix. \u201cGCN with 11T removed\u201d is the corrected, unnormalized matrix.", "description": "This figure shows the accuracy of node classification for different numbers of graph convolutions (1, 2, 4, 8, 12, 16) against varying signal-to-noise ratios.  Three methods are compared: the original graph convolutional network (GCN), GCN with the principal eigenvector removed from the convolution matrix (using the normalized adjacency matrix), and GCN with the principal eigenvector removed (using the unnormalized adjacency matrix). The results demonstrate the improved performance and robustness of the corrected convolution methods, especially in scenarios with low signal-to-noise ratios, showcasing their ability to mitigate the negative effects of over-smoothing.", "section": "Experiments"}, {"figure_path": "MSsQDWUWpd/figures/figures_9_1.jpg", "caption": "Figure 1: Accuracy plot (average over 50 trials) against the signal-to-noise ratio of the features (ratio of the distance between the means to the standard deviation) for increasing number of convolutions. Here, v = D1/21 and the \u201cGCN with v\u03c5\u2122 removed\u201d refers to convolution with the corrected, normalized adjacency matrix. \u201cGCN with 11T removed\u201d is the corrected, unnormalized matrix.", "description": "The figure shows the accuracy of different graph convolutional networks (GCNs) against the signal-to-noise ratio of node features for various numbers of convolutions. Three types of GCNs are compared: the original GCN, a GCN with the principal eigenvector removed (GCN with vvT removed), and a GCN with the all-ones vector removed (GCN with 11T removed). The results demonstrate that removing the principal or all-ones eigenvector improves the performance of GCNs, especially in low signal-to-noise settings.", "section": "9.1 Synthetic Data"}, {"figure_path": "MSsQDWUWpd/figures/figures_9_2.jpg", "caption": "Figure 3: Accuracy plots (average over 50 trials) against the number of layers for real datasets.", "description": "This figure compares the performance of the original GCN and corrected graph convolution on three real-world citation network datasets: Cora, Citeseer, and PubMed.  The x-axis represents the number of layers in the graph convolutional network, and the y-axis represents the accuracy of node classification.  The figure shows that the accuracy of the standard GCN decreases significantly as the number of layers increases (oversmoothing). In contrast, the accuracy of the corrected graph convolution remains relatively stable or even improves slightly. This demonstrates the effectiveness of the proposed method in mitigating the oversmoothing problem in real-world graph data.", "section": "9.2 Real Data"}, {"figure_path": "MSsQDWUWpd/figures/figures_27_1.jpg", "caption": "Figure 1: Accuracy plot (average over 50 trials) against the signal-to-noise ratio of the features (ratio of the distance between the means to the standard deviation) for increasing number of convolutions. Here, v = D1/21 and the \u201cGCN with v\u03c5\u2122 removed\u201d refers to convolution with the corrected, normalized adjacency matrix. \u201cGCN with 11T removed\u201d is the corrected, unnormalized matrix.", "description": "The figure shows accuracy plots for different numbers of graph convolutions, comparing the original GCN model against two corrected versions. The x-axis represents the signal-to-noise ratio, and the y-axis shows the accuracy. The plots demonstrate that the corrected graph convolution methods maintain accuracy even with noisy data, unlike the original GCN which shows a performance drop with more convolutions.", "section": "Experiments"}, {"figure_path": "MSsQDWUWpd/figures/figures_30_1.jpg", "caption": "Figure 1: Accuracy plot (average over 50 trials) against the signal-to-noise ratio of the features (ratio of the distance between the means to the standard deviation) for increasing number of convolutions. Here, v = D1/21 and the \u201cGCN with v\u03c5\u2122 removed\u201d refers to convolution with the corrected, normalized adjacency matrix. \u201cGCN with 11T removed\u201d is the corrected, unnormalized matrix.", "description": "The figure shows the accuracy of node classification for different numbers of graph convolutions with and without the principal eigenvector removed from the adjacency matrix.  The x-axis represents the signal-to-noise ratio (SNR) of node features, and the y-axis shows the accuracy of a linear classifier trained on the graph convolution output. Three variations are compared: a standard Graph Convolutional Network (GCN), a GCN with the top eigenvector (vvT) removed, and a GCN with the all-ones vector (11T) removed.  The plots demonstrate how removing the top eigenvector improves accuracy, particularly at lower SNRs and for higher numbers of graph convolutions. The plots visualize the effectiveness of corrected graph convolutions in mitigating oversmoothing.", "section": "Experiments"}, {"figure_path": "MSsQDWUWpd/figures/figures_30_2.jpg", "caption": "Figure 3: Accuracy plots (average over 50 trials) against the number of layers for real datasets.", "description": "The figure compares the performance of three graph convolutional network models (GCN, GCN with the principal eigenvector removed, and GCN with the all-ones vector removed) on three real-world citation networks (Cora, CiteSeer, and Pubmed).  The x-axis represents the number of layers in the GCN, and the y-axis represents the classification accuracy.  The plot shows that the accuracy of the standard GCN decreases as the number of layers increases, exhibiting oversmoothing. In contrast, the accuracy of the corrected GCNs remains stable or even slightly improves as the number of layers increases, demonstrating the effectiveness of removing the principal eigenvector in mitigating oversmoothing.", "section": "Experiments"}]