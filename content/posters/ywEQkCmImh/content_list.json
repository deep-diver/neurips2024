[{"type": "text", "text": "Towards Multi-Domain Learning for Generalizable Video Anomaly Detection ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "MyeongAh Cho\u2217 Taeoh Kim Minho Shim Kyung Hee University NAVER Cloud NAVER Cloud maycho@khu.ac.kr taeoh.kim@navercorp.com minho.shim@navercorp.com ", "page_idx": 0}, {"type": "text", "text": "Dongyoon Wee NAVER Cloud dongyoon.wee@navercorp.com ", "page_idx": 0}, {"type": "text", "text": "Sangyoun Lee\u2020 Yonsei University syleee@yonsei.ac.kr ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Most of the existing Video Anomaly Detection (VAD) studies have been conducted within single-domain learning, where training and evaluation are performed on a single dataset. However, the criteria for abnormal events differ across VAD datasets, making it problematic to apply a single-domain model to other domains. In this paper, we propose a new task called Multi-Domain learning for VAD (MDVAD) to explore various real-world abnormal events using multiple datasets for a general model. MDVAD involves training on datasets from multiple domains simultaneously, and we experimentally observe that Abnormal Conflicts between domains hinder learning and generalization. The task aims to address two key objectives: (i) better distinguishing between general normal and abnormal events across multiple domains, and (ii) being aware of ambiguous abnormal conflicts. This paper is the first to tackle abnormal conflict issue and introduces a new benchmark, baselines, and evaluation protocols for MDVAD. As baselines, we propose a framework with Null(Angular)-Multiple Instance Learning and an Abnormal Conflict classifier. Through experiments on a MDVAD benchmark composed of six VAD datasets and using four different evaluation protocols, we reveal abnormal conflicts and demonstrate that the proposed baseline effectively handles these confilcts, showing robustness and adaptability across multiple domains. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Video Anomaly Detection (VAD) is identifying abnormal events in diverse scenarios depicted in a video and determining their temporal intervals at a frame-level. Nowadays, CCTVs are ubiquitous, recording every moment of life, which aids in preventing accidents and responding to crimes promptly. However, human monitoring of every situation is highly inefficient, requiring significant labor and resources. Consequently, extensive research has been conducted to automate VAD through deep learning by leveraging large amounts of surveillance data [33, 5, 24, 15, 55, 44, 43, 50, 21, 7]. ", "page_idx": 0}, {"type": "text", "text": "In VAD research, Weakly-supervised VAD (WVAD) [55, 44, 43, 50, 21, 7], which involves learning normal and abnormal events with minimal supervision of the video-level annotation and detecting abnormal events at the frame-level during testing, has been studied a lot recently. This paper focuses on the WVAD setting (denoted as VAD), and a summary of VAD research is explained in the supplementary material $(\\S\\,\\mathrm{E})$ . Unlike the conventional VAD research, we first address the following three key questions: ", "page_idx": 0}, {"type": "image", "img_path": "ywEQkCmImh/tmp/dc32a39e6653ee274f1531cb2b8df3cd327fedfa60ba8b2198af1cea266f281c.jpg", "img_caption": ["", "Figure 1: (a) An example of abnormal conflict: Pedestrian on the road is normal in UCFC dataset but is abnormal in TAD. (b) Each circle represents each domain. MDVAD aims to design a general model that effectively considers abnormal conflicts to separate general normal and abnormal events. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Q1: What is the problem with the existing VAD model? Most VAD models are trained in a singledomain where the training and evaluation dataset are the same. In the case of single-domain learning, application across different datasets (cross-domain evaluation) results in performance degradation as reported in [14, 6, 7] because VAD models are heavily influenced by the criteria for abnormality defined by each dataset. ", "page_idx": 1}, {"type": "text", "text": "$Q2$ : Why do we need a general VAD model? First, a single generalized model removes the need for multiple specific models for different domains, analogous to multi-task learning. Second, proper pre-training on multiple domains embodies generalized representation, and it can discriminate abnormal events according to their domain, leading to better performance in unseen target domains. Consequently, a general VAD model will be highly beneficial for applying VAD in practical scenarios. ", "page_idx": 1}, {"type": "text", "text": "Q3: Is it possible to create a general VAD model? The general VAD model aims to handle multiple domains, but this is challenging because the definition of abnormal differs for each dataset, leading to conflicts between these abnormal events. For example, as shown in Fig. 1(a), in one dataset, a pedestrian on the road is considered normal, while in another dataset, it is deemed abnormal. A general VAD cannot be solved with a naive muti-task learning because of this confusion across multiple domains, which this paper defines as \u2018Abnormal Confilct.\u2019 Therefore, for general VAD, it is necessary to be aware of these abnormal conflicts (yellow region in Fig. 1(b)) and learn general normal (green region in Fig. 1(b)) or abnormal (red region in Fig. 1(b)) representations that are common across all domains. ", "page_idx": 1}, {"type": "text", "text": "Our goal is to construct a general VAD model by conducting multi-domain learning while recognizing abnormal conflicts and exploring representations of general normality and abnormality. To achieve this goal, we introduce a new task called 1) Multiple Domain VAD (MDVAD), along with a benchmark and new evaluation protocols. MDVAD involves concurrent training on multiple VAD datasets, each with its own definition of abnormality. Specifically, the MDVAD benchmark comprises six representative VAD datasets with balanced sampling $(\\S\\,4.1)$ . We also propose four evaluation protocols: held-in, leave-one-out, low-shot domain adaptation, and full fine-tuning. The held-in protocol is designed to evaluate the model\u2019s ability as a unified model like multi-task model, while the leave-one-out, low-shot domain adaptation, and full fine-tuning protocols are intended to access the model\u2019s capability as a general pre-training for an unseen target domain. ", "page_idx": 1}, {"type": "text", "text": "As multi-domain learning is a novel concept in the field of VAD, we also introduce baselines and new learning methods. We design domain-specific multiple heads to mitigate abnormal confilcts and learn generality across domains. To facilitate multi-head learning without conflicts, we propose the 2) Null-Multiple Instance Learning (Null-MIL) and NullAngular-MIL (NullAng-MIL) losses, which activate only the output of the head corresponding to the input domain, assigning inactive heads with Null values to prevent confusion. Additionally, we suggest the 3) Abnormal Conflict (AC) Classifier to explore general features while being aware of abnormal conflicts, leveraging the variance in abnormal scores across the multiple heads (Fig. 2 green and yellow region in the Venn diagram). Through experiments with four protocols on the MDVAD benchmark, we reveal the limitations of multi-domain learning with abnormal confilct and demonstrate the effectiveness of our baselines in offering a generalized and adaptive model. ", "page_idx": 1}, {"type": "text", "text": "1.1 Scope of research ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Focusing on Multiple Domains. In this paper, we focus on solving the problems in multiple domains introduced above rather than solving problems in a single domain. Therefore, complex design of the backbone and head or achieving state-of-the-art performance in a single domain can proceed orthogonally with our research. Instead, this paper raises the issue of abnormal conflict and focuses on the necessity of MDVAD. ", "page_idx": 2}, {"type": "text", "text": "Distinction from Open-set VAD Approaches. Unlike Open-set VAD [59, 25, 1], which separates seen and unseen anomalies within a single-domain cannot achieve robust representation learning among multiple domains, this paper excels at handling abnormal conflicts and shows adaptability across domains with versatile evaluation protocols (held-in/out and low-shot). ", "page_idx": 2}, {"type": "text", "text": "2 Observations ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Datasets ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this paper, we use six representative VAD datasets: UCF-Crimes (UCFC) [43], XD-Violences (XD) [51], Large-scale Anomaly Detection (LAD) [47], UBI-Fights (UBIF) [9], Traffic Anomaly Dataset (TAD) [19], and Shanghai-Tech Campus (ST) [24]. As shown in Table 1, each dataset has different environments (e.g. CCTV, Traffic, Campus), quantities, and abnormal categories. Unlike other datasets, ST is an unsupervised VAD benchmark whose training set comprises only normal videos, so the training set has been reorganized following [21, 45, 57]. More details are provided in the supplementary material (Sec. A). ", "page_idx": 2}, {"type": "text", "text": "2.2 Analysis ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Based on observations of each dataset\u2019s properties, we aim to quantify how the different properties negatively affect domain shifts. Table 2 presents cross-domain evaluation results, i.e., single-domain models validated on different target datasets. The results reveal that while these models excel indomain settings (diagonal elements of the table), they exhibit significant performance degradation in cross-domain scenarios. This implies that a single-domain VAD model may be ineffective in most other environments unless the environment and user\u2019s intention are precisely identical. Therefore, leveraging diverse datasets for generalized feature learning is crucial, enabling the model to handle unknown domain and well adapted to unseen anomalies. This paper addresses two primary issues: 1) Abnormal conflict arising during the multi-domain learning process, and 2) Scene discrepancy occurring during the evaluation process on an unseen target domain. ", "page_idx": 2}, {"type": "text", "text": "Abnormal conflict. As illustrated in Fig. 1, abnormal conflicts indicate abnormal events that are considered abnormal in one (or some) domain(s) but are denoted as normal in other domains. As shown in Table 1, there is relatively little overlap of abnormal classes in ST with other datasets. In other words, this means that the abnormal conflict with other datasets is relatively large. This conflict leads to low cross-dataset performances of models trained or evaluated on ST in Table 2. Taking UCFC as an example (target domain: UCFC column in Table 2), performance increases in the order of TAD, ST, LAD, XD, and UBIF, which is proportional to the number of abnormal conflict categories that exist in the source domain. Abnormal confilct makes the MDVAD unique as the label spaces between domains literally conflict because of each other\u2019s differing definitions. ", "page_idx": 2}, {"type": "table", "img_path": "ywEQkCmImh/tmp/8b0f532b77dd65458d244c3c0729391554eb58f2bbf508d252f36bde08342542.jpg", "table_caption": ["able 1: Datasets and abnormal categories. Colored categories are shared Table 2: Anomaly detection performances (Area under curve, normal categories with other datasets. Uncolored categories are considered AUC) of single-domain models. Diagonal elements are innormal events in other datasets. Gray categories are defined by ourselves domain results and off-diagonal elements are cross-domain while all other categories are provided by datasets. results. "], "table_footnote": [], "page_idx": 2}, {"type": "image", "img_path": "ywEQkCmImh/tmp/451248bacc7534e042ae6432d310914e88c8ad7c78ab37fa8c77e7c70cc3da37.jpg", "img_caption": ["Figure 2: The overall framework of our MDVAD baselines that consists of domain-agnostic layers, single abnormal head (Sec. 3.1), multiple abnormal heads (Sec. 3.2), and AC classifier (Sec. 3.3). "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Scene discrepancy. Scene discrepancy refers to differences in the visual settings of scenes, distinct from abnormal conflict arising from variations in the definition of abnormal classes. To quantify scene discrepancy, we utilize the Earth Mover\u2019s Distance (EMD) [38] introduced in [8] to calculate the distance between VAD datasets in the Table 3. In Table 3, the top-right section illustrates the comparison of normal features, while the bottom-left provides a numerical comparison of class-wise abnormal features. Lighter colors indicate a higher discrepancy between datasets. Unlike other datasets, TAD, which comprises traffic videos, exhibits a large distance from normal sample distances in the dataset, while LAD, with diverse and complex scenes for abnormal classes, shows the furthest distance from other datasets. This explains the results of domain adaptation experiments. (Table 7). ", "page_idx": 3}, {"type": "text", "text": "3 Baselines ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Fig. 2 depicts the overall framework of our MDVAD baselines divided into domain-agnostic layers, consisting of the video backbone and aggregation modules, Single $(\\S\\,3.1)$ or Multiple heads (\u00a7 3.2), and AC classifier $(\\S\\ 3.3)$ . ", "page_idx": 3}, {"type": "text", "text": "Domain-agnostic layers. The input abnormal or normal video ${\\bf V}^{a}$ or ${\\mathbf V}^{n}$ is divided into uniformly sampled $T$ snippets $(\\mathbf{V}^{a}\\;\\in\\;\\{\\mathbf{v}_{1}^{a},\\cdots,\\mathbf{v}_{T}^{a}\\})$ . These $T$ snippets pass through a pre-trained video backbone, resulting in a $C$ -dimensional feature $\\mathbf{B}\\in\\mathbb{R}^{T\\times C}$ that undergoes an aggregation module, fusing them from the feature level to the temporal level. The feature aggregation layer doubles the channel size $\\hat{\\mathbf{B}}\\in\\mathbb{R}^{T\\times2C}$ , followed by a split and max operation $\\mathbf{F}_{a g g,i}=\\operatorname*{max}\\left[\\hat{\\mathbf{B}}_{i}^{c},\\hat{\\mathbf{B}}_{i}^{C+c}\\right]_{c=1,\\cdots,C}$ to squeeze the channel size back to $C$ for the $i$ -th snippet. Activating only the maximum element during gradient propagation enables the implicit differentiation of class-specific channels, allowing the model to establish discrepancies between classes [7, 52]. The temporal aggregation layer, with a temporal kernel size of 3, produces the domain-agnostic aggregated feature $\\bar{\\mathbf{F}_{D A}}\\in\\mathbb{R}^{T\\times\\bar{C}/2}$ . ", "page_idx": 3}, {"type": "text", "text": "3.1 Single-domain learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The final feature $\\mathbf{F}_{D A}$ undergoes fully connected layers denoted as FC and the single abnormal head $(\\mathbf{w}_{D_{1}}^{a}\\in\\mathbb{R}^{C/16\\times1})$ followed by a sigmoid function to derive the final abnormal score $\\mathbf{s}_{D_{1}}^{a}\\in\\mathbb{R}^{T\\times1}$ . ", "page_idx": 4}, {"type": "text", "text": "MIL. Due to the absence of temporal interval training labels for abnormal events, WVAD models rely on video-level labels for training, employing the Multiple Instance Learning (MIL) method. When the top- $K$ score set is represented as $\\Omega_{k}(\\mathbf{s}_{D_{1}}^{a})$ , the Binary Cross Entropy-based (BCE) classification loss function is formulated as presented in Eq. 1, where $y=\\{0,1\\}$ . ", "page_idx": 4}, {"type": "equation", "text": "$$\nL_{M I L}=\\sum_{i\\in\\Omega_{k}(\\mathbf{s}_{D_{1}}^{a})}-(y l o g s_{D_{1},i}^{a}+(1-y)l o g(1-s_{D_{1},i}^{a})),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This loss function ensures that only snippets with high (Top- $K$ ) abnormal scores can contribute to the loss. This single-head model serves as the single-domain baseline (MIL in Fig. 2). ", "page_idx": 4}, {"type": "text", "text": "3.2 Multi-domain learning: Multi-head learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Null-MIL. To address the abnormal conflict issue mentioned in Sec. 2, in the MDVAD framework, the abnormal head is divided into multiple heads, each responsible for its own domain, allowing for the domain-wise prediction of the output score. Inspired by [18], the prediction score for the input snippet from the $D_{d}$ dataset is derived exclusively from the output of the $D_{d}$ -head, and the results from heads of other datasets are fliled with Null values (Null-MIL in Fig. 2). Compared to Eq. 1, the Null-MIL loss is changed as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nL_{N u l l-M I L}=\\sum_{d=1}^{M}\\ \\sum_{i\\in\\Omega_{k}(\\mathbf{s}_{D_{d}}^{a})}-(y l o g s_{D_{1},i}^{a}+(1-y)l o g(1-s_{D_{1},i}^{a}))\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $M$ is the number of heads (domains). To avoid the abnormal conflicts, the heads between datasets are separated where $D_{d}$ -head\u2019s weight $\\mathbf{w}_{D_{d}}^{a}$ is independently trained for the corresponding dataset. In Eq. 2, only $\\mathbf{s}_{D_{d}}^{a}$ among all output scores is added to the loss, thus the gradient becomes $\\frac{\\partial\\mathbf{s}_{D_{d}}^{a}}{\\partial\\mathbf{w}_{D_{d}}^{a}}$ , while other heads are not affected. ", "page_idx": 4}, {"type": "text", "text": "For the test, the abnormal score of $i$ -th snippet is $s_{D_{d},i}^{a}$ when the target dataset is $D_{d}$ and $\\operatorname*{max}_{d}s_{D_{d},i}^{a}$ by selecting the maximum value for unseen target data. ", "page_idx": 4}, {"type": "text", "text": "NullAng-MIL. We additionally propose a NullAngular-based MIL method that employs the angular margin to effectively diminish large variations among intra-class instances. In this case, multiple normal heads are added (NullAng-MIL in Fig. 2). When head classifier weight of each dataset $D_{d}$ is denoted as $\\mathbf{w}_{D_{d}}^{a}$ and $\\mathbf{w}_{D_{d}}^{n}$ and final embedding feature is $\\mathbf{F}$ , the final abnormal and normal scores are representedd by $\\mathbf{s}_{D_{d}}^{a}\\doteq\\mathbf{F}\\cdot\\mathbf{w}_{D_{d}}^{a}$ and $\\mathbf{s}_{D_{d}}^{n}=\\mathbf{F}\\cdot\\mathbf{w}_{D_{d}}^{n}$ , respectively. Normalizing the head weight and feature vector to 1 results in $\\mathbf{s}_{D_{d}}^{a}=\\lVert\\mathbf{F}\\rVert\\,\\lVert\\mathbf{w}_{D_{\\underline{{d}}}}^{a}\\rVert\\cos\\pmb{\\theta}_{D_{\\underline{{d}}}}^{a}=\\cos\\pmb{\\theta}_{D_{d}}^{a}$ and $\\mathbf{s}_{D_{d}}^{n}=\\cos\\pmb{\\theta}_{D_{d}}^{n}$ representing cosine similarity. Thus, in the cosine space, Eq. 2 can be defined as Eq. 3, requiring the maximum cosine similarity between the feature from dataset $D_{d}$ and the abnormal head $\\mathbf{w}_{D_{d}}^{a}$ to be at least an angular margin of $m$ greater than the normal head $\\mathbf{w}_{D_{d}}^{n}$ that enlarging the gap between normal and abnormal. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{i}\\cos{(\\theta_{D_{d},i}^{a}+m)}>\\operatorname*{max}_{i}\\cos{\\theta_{D_{d},i}^{n}}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Denoting the top- $K$ abnormal scores from the head of dataset $D_{d}$ as $\\begin{array}{r l}{\\Omega_{k}(\\mathbf{s}_{D_{d}})}&{{}=}\\end{array}$ $\\left\\{\\mathbf{s}_{D_{d},i}^{a},\\mathbf{s}_{D_{d},i}^{n}\\right\\}_{\\mathrm{i=topk\\,indices}}$ , rewriting Eq. 2 as an angular margin-based regression problem results in Eq. 4. Similar to Null-MIL, the loss is computed by the head associated with the input dataset, while scores from other heads have no impact on updating the model\u2019s weights. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{N u l l A n g-M I L}=}\\\\ &{\\displaystyle\\sum_{d=1}^{M}\\sum_{i\\in\\Omega_{k}(\\mathbf{s}_{D_{d}})}-(y l o g\\frac{e^{\\cos{(\\theta_{D_{d},i}^{a}+m)}}}{e^{\\cos{(\\theta_{D_{d},i}^{a}+m)}}+e^{\\cos{\\theta_{D_{d},i}^{n}}}}}\\\\ &{\\phantom{m m m m m m m m}+(1-y)l o g\\frac{e^{\\cos{(\\theta_{D_{d},i}^{n}+m)}}}{e^{\\cos{\\theta_{D_{d},i}^{a}}}+e^{\\cos{(\\theta_{D_{d},i}^{n}+m)}}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "For the test, since the normal and abnormal heads are trained through angular margin learning, the abnormal score is shown in Eq. 5. ", "page_idx": 5}, {"type": "equation", "text": "$$\n=\\left\\{\\!\\!\\begin{array}{c c}{s_{D_{d},i}^{a}+(1-s_{D_{d},i}^{n})}&{\\mathrm{source}\\:D_{d}\\mathrm{=target}}\\\\ {\\operatorname*{max}_{d}s_{D_{d},i}^{a}+(1-\\operatorname*{max}_{d}s_{D_{d},i}^{n})}&{\\mathrm{source}\\forall\\mathrm{trget}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "When the source domain of the pre-trained general model is different from the target domain, we determine the final score to reflect confilcts by taking the maximum normal and abnormal score from multiple heads. ", "page_idx": 5}, {"type": "text", "text": "Unseen domain adaptation. After multi-domain learning, when a new target dataset or unseen condition appears, the final score is computed based on the similarity between the embedding feature of the input video and each source domain\u2019s head classifier. Therefore, it operates by considering domain similarity, which can address the performance degradation issue that occurs due to the scene discrepancy discussed in Sec. 2. ", "page_idx": 5}, {"type": "text", "text": "Complexity. Only the final layer is added based on the number of datasets, with the head\u2019s weight denoted as $\\mathbf{w}_{D_{d}}\\in\\mathbb{R}^{T\\times1}$ , which is a very small proportion of the entire model. Comparing a single and multiple heads (6 datasets), the training times are 2.68 and 2.81 hours, and the inference times are 0.158 and 0.164 milliseconds per snippet, respectively, indicating a negligible increase in complexity. ", "page_idx": 5}, {"type": "text", "text": "3.3 Abnormal Conflict (AC) classifier ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In the domain-agnostic feature extraction phase, it is crucial to capture general features that can handle every domain. While we have divided the heads to avoid abnormal confilcts in multiple source datasets, the agnostic part extracts features from all datasets using a single branch, and inconsistent labels cause confusion. Therefore, we propose an Abnormal Confilct (AC) classifier for learning the final embedding feature $\\mathbf{F}_{D A}$ that passes through the detector heads. ", "page_idx": 5}, {"type": "text", "text": "In Fig. 2, each classifier head distinguishes between $D_{d}$ and $D_{d}^{\\mathrm{~c~}}$ , while the AC classifier is intended to distinguish between elements that are abnormal or normal across all source datasets (green area) and elements that represent confilcts (yellow area) within the Venn diagram. The AC classifier takes the embedding feature $\\mathbf{F}_{D A}$ as input, followed by two FC layers, to predict the final conflict score $\\mathbf{s}^{A C}$ . In Eq. 6, the AC label is generated based on the scores of all abnormal heads, where $y_{i}^{A C}=1$ if the deviation between the scores is above a threshold $\\tau$ . ", "page_idx": 5}, {"type": "equation", "text": "$$\ny_{i}^{A C}=\\binom{1}{0}\\begin{array}{r}{[\\operatorname*{max}_{d}s_{D_{d},i}^{a}-\\operatorname*{min}_{d}s_{D_{d},i}^{a}-\\tau]_{+}>0}\\\\ {\\mathrm{otherwise}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The loss of the AC classifier, denoted as $L_{A C}$ and calculated using cross-entropy as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\nL_{A C}=\\sum_{i=1}^{T}\\ -(y_{i}^{A C}l o g s_{i}^{A C}+(1-y_{i}^{A C})l o g(1-s_{i}^{A C}))\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The total objective function is $L=L_{N u l l A n g-M I L}+\\lambda L_{A C}$ . ", "page_idx": 5}, {"type": "text", "text": "During the testing phase, the auxiliary branch AC classifier is eliminated, and the output is calculated for each input snippet $\\mathbf{v}_{i}$ as the final Abnormal ${\\mathrm{Score}}_{i}$ . ", "page_idx": 5}, {"type": "text", "text": "4 Experimental Results ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1 MDVAD benchmark ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As shown in Table 1, VAD comprises six representative datasets with diverse settings and volumes. The MDVAD is a task aimed at addressing domain shifts between datasets, and each dataset included in the MDVAD benchmark should be structured so that it is not biased toward any particular dataset or anomalies. Consequently, datasets should have an equal volume in the training set and encompass various abnormal categories and criteria. To achieve this, we sampled each dataset to align with the dataset with the smallest volume, ensuring that each abnormal category has a similar proportion and conducted 3-fold experiments. Additionally, to handle small datasets like TAD and ST, which have minimal volumes, we combined them with the traffic dataset CADP [41] and campus dataset NWPU [3], respectively, by reorganizing their training sets. The volume of MDVAD benchmark is unified at 386 videos per dataset. More details provided in the supplementary material (Sec. B). ", "page_idx": 5}, {"type": "table", "img_path": "ywEQkCmImh/tmp/d1a97e7bb4aaef6e8840690e1a681c2a60c9d65359c4fd837d93bc6374ebfbfd.jpg", "table_caption": ["Table 4: Single-domain results (AUC): In-domain (diagonal elements) and cross-domain (off-diagonal elements) results. "], "table_footnote": ["Training: Single-source dataset / Testing: Target dataset Out Avg.: Average of cross-domain results. "], "page_idx": 6}, {"type": "table", "img_path": "ywEQkCmImh/tmp/8ce30a6ae1ef54f0bb9888708e817ffbb335530076a9d0f47b7a0b890ca620e4.jpg", "table_caption": ["Table 5: E1: Multi-domain training: held-in results (AUC). "], "table_footnote": ["Training: All six datasets / Testing: Target dataset Column-wise coloring with increased intensity for higher values "], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "4.2 Empirical studies ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This section presents empirical studies as follows: first, single-domain results for comparison, followed by the results of four evaluation protocols for the MDVAD benchmark. The models are trained on the training set of the source domain and evaluated on the test set of the target domain under the following settings: Held-in (E1), Leave-one-out (E2), Low-shot adaptation (E3), and Full finetuning (E4). The Area Under Curve (AUC) is used as the evaluation metric. The hyper-parameters are $T=32$ , $\\lambda=10$ , $\\tau=0.3$ , and $m=0.3$ . Since the single-head baseline cannot assign AC labels using Eq. 6, pseudo-labels for the AC classifier are assigned based on the range of predicted abnormal scores. All detailed implementations, more results, and discussions are provided in the supplementary material. ", "page_idx": 6}, {"type": "text", "text": "Single-domain results. In the preliminary experiment, we examine the performance of the MDVAD benchmark under single-source and single-target conditions using a single-head MIL baseline. Comparing the in-domain (diagonal elements) results in Table 2 (using the original training set) and Table 4 (using the sampled training set), we observe that the performance diminishes when datasets, other than TAD and ST, are reduced during sampling. Conversely, TAD and ST show improved performance, beneftiing from increased diversity and data volume due to reorganization with CADP and NWPU for TAD and ST, respectively. The cross-domain (off-diagonal elements) results in Table 4 demonstrate consistent trends with both the MDVAD and VAD benchmarks. These trends primarily arise from challenges related to abnormal confilct and scene discrepancies, indicating that the issues are confined to in-domain settings. Consequently, to uphold in-domain performance across diverse datasets and effectively address issues related to abnormal conflict and scene discrepancies, we emphasize the essential role of multi-domain learning in developing a general model for VAD. ", "page_idx": 6}, {"type": "text", "text": "4.2.1 Held-in results (E1) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we discuss the held-in evaluation results, where models are trained on all datasets of MDVAD, and the test set of each source dataset is used as the target. Table 5 presents the results obtained by training with the MIL baseline with a single-head, which is commonly used in traditional WVAD, and the proposed Null(Ang)-MIL baseline composed of multiple heads. Because UCFC, XD, and LAD exhibit low abnormal confilcts, numerous similarities in abnormal categories, and minimal scene discrepancy, there are great performances with the single-head MIL baseline. However, when TAD and ST are targets, the results demonstrate that the Null(Ang)-MIL baselines, which extract general domain features in the domain-agnostic part and avoid confilct by assigning Null values with multiple heads, outperform the MIL baseline. ", "page_idx": 6}, {"type": "text", "text": "Handling multi-domain with a single $\\mathbf{Null(Ang)-MIL}$ baseline. The average performance of single Null-MIL and NullAng-MIL is comparable to or even better than the average performance of individual in-domain models trained for each domain $(86.52\\%)$ . Moreover, the NullAng-MIL baseline, which effectively performs inter/intra-class learning through cosine angular margin while avoiding conflict between each head, achieves superior results, with $91.82\\%$ (TAD) and $91.26\\%$ (ST) compared to the performances of single in-domain results of $90.75\\%$ (TAD) and $90.79\\%$ (ST), highlighting the effectiveness of learning with diverse and abundant data to enhance model generality. Furthermore, additional performance boosts are observed across all baselines with the auxiliary AC classifier to make the model conflict-aware. ", "page_idx": 6}, {"type": "table", "img_path": "ywEQkCmImh/tmp/2eacf691f20f65bd5bdc3c44be60fd3d1a509282daa747d09f025ffadf275053.jpg", "table_caption": ["Table 6: E2: Leave-one-out results "], "table_footnote": ["Training: Five datasets except the target dataset Testing: Target dataset "], "page_idx": 7}, {"type": "table", "img_path": "ywEQkCmImh/tmp/a8521b43e1b7833e09eb184221a17da1c03a641c3809238cb1d3131f3da6a8f4.jpg", "table_caption": ["Table 7: E3: Low-shot adaptation results "], "table_footnote": ["Training: $\\overline{{{\\bf E}2+\\bf\\delta}}$ a few target samples Testing: Target dataset "], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4.2.2 Leave-one-out results (E2) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The E2 experiments, in Table 6, are conducted on the leave-one-out setting among multiple source datasets and evaluated on the unseen target dataset unlike E1. Each column represents the outcomes of models trained with the target dataset excluded. Compared with the held-in results, the evaluation results conducted without prior knowledge of abnormal boundaries for unseen target data lead performance gap between E1 and E2. ", "page_idx": 7}, {"type": "text", "text": "Effectiveness of multi-domain learning for unseen target domain. When comparing single-domain learning and multi-domain learning in the results of unseen target evaluation (Out Avg. in Table 6), it is evident that the performance with multiple datasets is significantly superior. Effectively addressing conflict and discrepancy issues, and learning from diverse and complex situations across multiple domains, leads to the development of a general model with better performance on unseen domains. ", "page_idx": 7}, {"type": "text", "text": "4.2.3 Low-shot adaptation results (E3) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In E3, we delve into low-shot learning, examining how well the model trained with multiple sources in the leave-one-out experiments (E2) adapts to unseen targets. In this experiment, we utilized $10\\%$ of the target training set for low-shot learning (in a 3-fold setting). For datasets with abnormal categories, an equal number of data per category are randomly sampled, while for uncategorized datasets like UBIF and ST, random sampling is employed. ", "page_idx": 7}, {"type": "text", "text": "Importance of general pre-trained baselines for adaptation. In Table 7, comparing with Table 6, notable performance improvements are observed across all baselines for target samples with severe domain conflicts and gaps, such as UBIF, TAD, and ST, even with a limited volume of training samples. This emphasizes the importance of building a general model to adapt on unforeseen targets. While the MIL baseline with a single head holds an advantage in adapting specific single head when target samples are appropriately selected, it may become dependent on specific samples and is susceptible to overftiting. On the other hand, NullAng-MIL, with confilct-aware learning and training on diverse domains, outperforms other methods in adaptation performance. ", "page_idx": 7}, {"type": "text", "text": "4.2.4 Full fine-tuning results (E4) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Multi-domain models superior to specific singledomain models. Table 8 shows the full fine-tuning results of single-domain and multi-domain trained baselines. The single-domain models reflect results from training and testing within a specific dataset. When evaluating multi-domain baselines trained on all datasets in the held-in (E1) setting, it demonstrates performance comparable to single-domain models that perform well by fitting to a single dataset. However, after full fine-tuning on the target dataset, the E1 model achieves superior performance in most cases. The E1 and E2 models, which are well-explored across multiple domains, outperform the models specifically trained on a single domain after full fine-tuning. ", "page_idx": 7}, {"type": "table", "img_path": "ywEQkCmImh/tmp/6c4ee071a9bc5354de7c6048978042af08888ef37133e7a18802360150c6bfc2.jpg", "table_caption": ["Table 8: E4: Comparison between the single-domain model and full fine-tuned models from the E1 and E2. "], "table_footnote": ["Finetuning: Target dataset / Testing: Target dataset "], "page_idx": 7}, {"type": "image", "img_path": "ywEQkCmImh/tmp/5b9bf221f1e49eeb53966df301865781fb128dc75e6d9091bba8b8180ed7f282.jpg", "img_caption": ["Figure 3: (a) The plot of AC scores. Both scenes are from UCFC and are normal in UCFC. (Top) Yellow box indicates abnormal confilct, which is abnormal in ST. (Bottom) Normal scene. (b) Qualitative results. Red box indicates abnormal event in the scene. (Top) Bicyclist on walkway abnormal event in ST. (Bottom) Accident abnormal event in UCFC and Pedestrian on Road abnormal conflict in TAD. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.2.5 Summary ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Null-MIL and NullAng-MIL. The Null-MIL baseline achieves the best performance $(86.86\\%)$ in the Held-in setting (E1), even surpassing the in-domain average results $(86.52\\%)$ . However, in the Leaveone-out setting (E2), which involves unknown target domains, it shows suboptimal performance. This is because it is impossible to determine which head\u2019s output score among the source dataset heads is more reliable, so multiple head baselines employ the maximum score for unknown domains. Conversely, NullAng-MIL exhibits superior results in E2 due to its similarity-based score calculation. NullAng-MIL considers the cosine distance between the final feature and the weights of each source head. As a result, when calculating the final score, the head with high similarity to the target data is activated, yielding promising results. When pre-training the general VAD model without knowledge of the target, we observed that utilizing the NullAng-MIL baseline is beneficial. However, when conducting multi-domain learning with knowledge of the target, employing Null-MIL yields better results. We observed that when pre-training the general VAD model without prior knowledge of the target, utilizing the NullAng-MIL baseline proves beneficial and employing Null-MIL yields better results when knowledge of the target is available during multi-domain learning. ", "page_idx": 8}, {"type": "text", "text": "Role of the AC Classifier. In multi-domain learning, the proposed AC classifier serves as an auxiliary branch designed to predict whether there is an abnormal confilct between domains, thus making the model aware of confilcts. Since it is not used during testing, it does not impact the final model\u2019s cost but provides performance gains in most experiments. Notably, in E2 and E3, training with the AC classifier shows a significant boost effect, aiding in adaptation to unseen domains. ", "page_idx": 8}, {"type": "text", "text": "4.3 Discussions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Open-set VAD. We conducted experiments in an open-set scenario using UBNormal (UBN) dataset [1]. The UBN is a VAD benchmark proposed for openset scenarios to handle unexpected abnormal events. Both normal and abnormal events are available during training, but the anomalies that occur during inference belong to a distinct set of anomaly types (categories). Unlike other VAD datasets, UBN consists of synthetic videos to alleviate the difficulty of collecting abnormal event data in the real world. There are substantial abnormal conflicts and differences in the visual settings of scenes compared to other domains. For multi-domain learning, we reorganized the training/ testing set of UBN to maintain the same number of normal and abnormal videos in the training set with MDVAD, which is uniformly sampled and balanced the same amount of videos from all domains. As shown in Table 9, despite domain discrepancies and abnormal confilct, the model effectively handles multiple domain learning, demonstrating that general feature learning can adequately address unseen abnormal categories. Please refer to $\\S$ . A5 for more details. ", "page_idx": 8}, {"type": "table", "img_path": "ywEQkCmImh/tmp/3399be420b697fba02c51491795247ffc9a3ff009a97111d9a9c44d3c4da32bc.jpg", "table_caption": ["Table 9: Ablation studies on Open-set VAD scenario "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Comparison with WVAD models. Although this paper focuses on the analysis of multiple domain learning within the context of abnormal conflict issues, instead of exploring complex architecture designs for single-domain VAD models, we compare with various VAD models. Table 10 presents the results of other MILbased WVAD models, MMIL [43], ARNet [46], WSAL [30], and COMO [7] on the MDVAD task. Compared to the proposed baseline trained with the AC classifier, our method achieves the highest average AUC, particularly in datasets with severe abnormal conflicts and scene discrepancies, such as TAD and ST, in both the E2 and even more in the E3 settings. Various single-domain VAD models or backbones can be incorporated into the MDVAD task, showing a direction for future generalization work. Please refer to $\\S\\mathrm{\\A}6$ . ", "page_idx": 9}, {"type": "text", "text": "AC classifier. The AC classifier helps the model learn conflict-aware features, providing a clearer understanding of abnormalities. The proposed framework is composed of Domain", "page_idx": 9}, {"type": "table", "img_path": "ywEQkCmImh/tmp/b5fbdd349a73d4f788ea229374553923ec177ed465584609f312e66527eda928.jpg", "table_caption": ["Table 10: WVAD models on MDVAD Benchmark "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Agnostic Layers that learn general features across multiple domains, followed by Multiple Heads that predict abnormalities specific to each domain. When the Domain-Agnostic layers learn to perform AC classification, they capture whether the input snippets relate to abnormal confilct or not. From the Heads\u2019 perspective, these features are separated into abnormal conflict and non-AC in the feature space, allowing the Heads to apply different criteria (decision boundaries) when distinguishing between normal and abnormal instances. For example, in classifying abnormalities, non-AC scenarios can be addressed more straightforwardly, while abnormal conflict scenarios require a more careful exploration. Fig. 3(a) presents the results of the AC classifier of NullAng-MIL baseline from E1. It shows abnormal confilct scores for two scenarios: (Top) A car on the Sidewalk abnormal event in ST, which is normal in the UCFC. (Bottom) A normal situation of people shopping in a grocery store. Through the multi-domain learning, the AC classifier outputs a high abnormal confilct score for the top sample, demonstrating that the model has learned to be conflict-aware. ", "page_idx": 9}, {"type": "text", "text": "Qualitative results. Fig. 3(b) illustrates abnormal conflict scene: (Top) Bicyclist on Walkway, abnormal in ST but normal in other domains, and (Bottom) Pedestrian on Road, abnormal in TAD but normal in UCFC. In these scenarios, the MIL baseline trained with multiple domains predicts (Top) false negative and (Bottom) false positive, while ours adaptively handles conflicts across different domains. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion, Limitation, and Future Works ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we propose a new task called MDVAD, whose ultimate goal is to effectively learn from multiple domains with different data distributions and definitions of abnormality without confusion, resulting in a general VAD model. As a baseline, we propose a new multi-head framework with Null(Ang)-MIL loss and AC classifier. These modules effectively handle abnormal confilcts between domains and show meaningful results in the MDVAD benchmark with diverse evaluation protocols. ", "page_idx": 9}, {"type": "text", "text": "Instead of exploring complex architecture design of single-domain VAD models, this paper focuses on resolving abnormal conflicts from multiple domains. Various single-domain VAD models or backbones can be applied into our novel framework to address the MDVAD task, representing a valuable direction for future generalization research. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was partly supported by the NAVER Cloud Corporation and the National Research Foundation of Korea (NRF) grant funded by the Korea government(MSIT)(RS-2024-00456589). ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Andra Acsintoae, Andrei Florescu, Mariana-Iuliana Georgescu, Tudor Mare, Paul Sumedrea, Radu Tudor Ionescu, Fahad Shahbaz Khan, and Mubarak Shah. Ubnormal: New benchmark for supervised open-set video anomaly detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 20143\u201320153, 2022.   \n[2] Abhishek Aich, Kuan-Chuan Peng, and Amit K Roy-Chowdhury. Cross-domain video anomaly detection without target domain adaptation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 2579\u20132591, 2023.   \n[3] Congqi Cao, Yue Lu, Peng Wang, and Yanning Zhang. A new comprehensive benchmark for semisupervised video anomaly detection and anticipation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 20392\u201320401, June 2023.   \n[4] Joao Carreira and Andrew Zisserman. Quo vadis, action recognition? a new model and the kinetics dataset. In proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6299\u20136308, 2017.   \n[5] Yunpeng Chang, Zhigang Tu, Wei Xie, and Junsong Yuan. Clustering driven deep autoencoder for video anomaly detection. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XV 16, pages 329\u2013345. Springer, 2020.   \n[6] MyeongAh Cho, Taeoh Kim, Woo Jin Kim, Suhwan Cho, and Sangyoun Lee. Unsupervised video anomaly detection via normalizing flows with implicit latent features. Pattern Recognition, 129:108703, 2022.   \n[7] MyeongAh Cho, Minjung Kim, Sangwon Hwang, Chaewon Park, Kyungjae Lee, and Sangyoun Lee. Look around for anomalies: Weakly-supervised anomaly detection via context-motion relational learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12137\u2013 12146, 2023.   \n[8] Yin Cui, Yang Song, Chen Sun, Andrew Howard, and Serge Belongie. Large scale fine-grained categorization and domain-specific transfer learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4109\u20134118, 2018.   \n[9] Bruno Degardin and Hugo Proen\u00e7a. Iterative weak/self-supervised classification framework for abnormal events detection. Pattern Recognition Letters, 145:50\u201357, 2021.   \n[10] Qi Dou, Daniel Coelho de Castro, Konstantinos Kamnitsas, and Ben Glocker. Domain generalization via model-agnostic learning of semantic features. Advances in neural information processing systems, 32, 2019.   \n[11] Mark Dredze, Alex Kulesza, and Koby Crammer. Multi-domain learning by confidence-weighted parameter combination. Machine Learning, 79:123\u2013149, 2010.   \n[12] Masoud Faraki, Xiang Yu, Yi-Hsuan Tsai, Yumin Suh, and Manmohan Chandraker. Cross-domain similarity learning for face recognition in unseen domains. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15292\u201315301, 2021.   \n[13] Jia-Chang Feng, Fa-Ting Hong, and Wei-Shi Zheng. Mist: Multiple instance self-training framework for video anomaly detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 14009\u201314018, 2021.   \n[14] Mariana Iuliana Georgescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Marius Popescu, and Mubarak Shah. A background-agnostic framework with adversarial training for abnormal event detection in video. IEEE transactions on pattern analysis and machine intelligence, 44(9):4505\u20134523, 2021.   \n[15] Dong Gong, Lingqiao Liu, Vuong Le, Budhaditya Saha, Moussa Reda Mansour, Svetha Venkatesh, and Anton van den Hengel. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1705\u20131714, 2019.   \n[16] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pages 448\u2013456. pmlr, 2015.   \n[17] Mahesh Joshi, Mark Dredze, William Cohen, and Carolyn Rose. Multi-domain learning: when do domains matter? In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1302\u20131312, 2012.   \n[18] Dongwan Kim, Yi-Hsuan Tsai, Yumin Suh, Masoud Faraki, Sparsh Garg, Manmohan Chandraker, and Bohyung Han. Learning semantic segmentation from multiple datasets with label shifts. In European Conference on Computer Vision, pages 20\u201336. Springer, 2022.   \n[19] Siwon Kim, Kukjin Choi, Hyun-Soo Choi, Byunghan Lee, and Sungroh Yoon. Towards a rigorous evaluation of time-series anomaly detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 7194\u20137201, 2022.   \n[20] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[21] Shuo Li, Fang Liu, and Licheng Jiao. Self-training multi-sequence learning with transformer for weakly supervised video anomaly detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 1395\u20131403, 2022.   \n[22] Yunsheng Li and Nuno Vasconcelos. Efficient multi-domain learning by covariance normalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5424\u20135433, 2019.   \n[23] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision, pages 2980\u20132988, 2017.   \n[24] Wen Liu, Weixin Luo, Dongze Lian, and Shenghua Gao. Future frame prediction for anomaly detection\u2013a new baseline. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 6536\u20136545, 2018.   \n[25] Wen Liu, Weixin Luo, Zhengxin Li, Peilin Zhao, Shenghua Gao, et al. Margin learning embedded prediction for video anomaly detection with a few anomalies. In IJCAI, volume 3, pages 023\u20133, 2019.   \n[26] Zuhao Liu, Xiao-Ming Wu, Dian Zheng, Kun-Yu Lin, and Wei-Shi Zheng. Generating anomalies for video anomaly detection with prompt-based feature mapping. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 24500\u201324510, 2023.   \n[27] Yiwei Lu, Frank Yu, Mahesh Kumar Krishna Reddy, and Yang Wang. Few-shot scene-adaptive anomaly detection. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part V 16, pages 125\u2013141. Springer, 2020.   \n[28] Haohan Luo and Feng Wang. A simulation-based framework for urban traffic accident detection. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 1\u20135. IEEE, 2023.   \n[29] Hui Lv, Chen Chen, Zhen Cui, Chunyan Xu, Yong Li, and Jian Yang. Learning normal dynamics in videos with meta prototype network. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 15425\u201315434, 2021.   \n[30] Hui Lv, Chuanwei Zhou, Zhen Cui, Chunyan Xu, Yong Li, and Jian Yang. Localizing anomalies from weakly-labeled videos. IEEE transactions on image processing, 30:4505\u20134515, 2021.   \n[31] Zhen Ma, Jos\u00e9 JM Machado, and Jo\u00e3o Manuel RS Tavares. Weakly supervised video anomaly detection based on 3d convolution and lstm. Sensors, 21(22):7508, 2021.   \n[32] Hyeonseob Nam and Bohyung Han. Learning multi-domain convolutional neural networks for visual tracking. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4293\u20134302, 2016.   \n[33] Trong-Nguyen Nguyen and Jean Meunier. Anomaly detection in video sequence with appearance-motion correspondence. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1273\u20131283, 2019.   \n[34] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.   \n[35] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1406\u20131415, 2019.   \n[36] Sylvestre-Alvise Rebuff,i Hakan Bilen, and Andrea Vedaldi. Learning multiple visual domains with residual adapters. Advances in neural information processing systems, 30, 2017.   \n[37] Sylvestre-Alvise Rebuff,i Hakan Bilen, and Andrea Vedaldi. Efficient parametrization of multi-domain deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8119\u20138127, 2018.   \n[38] Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. A metric for distributions with applications to image databases. In Sixth international conference on computer vision (IEEE Cat. No. 98CH36271), pages 59\u201366. IEEE, 1998.   \n[39] Alice Schoenauer-Sebag, Louise Heinrich, Marc Schoenauer, Michele Sebag, Lani F Wu, and Steve J Altschuler. Multi-domain adversarial learning. In International Conference on Learning Representations, 2018.   \n[40] Seonguk Seo, Yumin Suh, Dongwan Kim, Geeho Kim, Jongwoo Han, and Bohyung Han. Learning to optimize domain specific normalization for domain generalization. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXII 16, pages 68\u201383. Springer, 2020.   \n[41] Ankit Parag Shah, Jean-Bapstite Lamare, Tuan Nguyen-Anh, and Alexander Hauptmann. Cadp: A novel dataset for cctv traffic camera based accident analysis. In 2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), pages 1\u20139. IEEE, 2018.   \n[42] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overftiting. The journal of machine learning research, 15(1): 1929\u20131958, 2014.   \n[43] Waqas Sultani, Chen Chen, and Mubarak Shah. Real-world anomaly detection in surveillance videos. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 6479\u20136488, 2018.   \n[44] Shengyang Sun and Xiaojin Gong. Hierarchical semantic contrast for scene-aware video anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22846\u2013 22856, 2023.   \n[45] Yu Tian, Guansong Pang, Yuanhong Chen, Rajvinder Singh, Johan W Verjans, and Gustavo Carneiro. Weakly-supervised video anomaly detection with robust temporal feature magnitude learning. In Proceedings of the IEEE/CVF international conference on computer vision, pages 4975\u20134986, 2021.   \n[46] Boyang Wan, Yuming Fang, Xue Xia, and Jiajie Mei. Weakly supervised video anomaly detection via center-guided discriminative learning. In 2020 IEEE international conference on multimedia and expo (ICME), pages 1\u20136. IEEE, 2020.   \n[47] Boyang Wan, Wenhui Jiang, Yuming Fang, Zhiyuan Luo, and Guanqun Ding. Anomaly detection in video sequences: A benchmark and computational model. IET Image Processing, 15(14):3454\u20133465, 2021.   \n[48] Li Wang, Dong Li, Han Liu, Jinzhang Peng, Lu Tian, and Yi Shan. Cross-dataset collaborative learning for semantic segmentation in autonomous driving. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 2487\u20132494, 2022.   \n[49] Xudong Wang, Zhaowei Cai, Dashan Gao, and Nuno Vasconcelos. Towards universal object detection by domain attention. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 7289\u20137298, 2019.   \n[50] Peng Wu and Jing Liu. Learning causal temporal relation and feature discrimination for anomaly detection. IEEE Transactions on Image Processing, 30:3513\u20133527, 2021.   \n[51] Peng Wu, Jing Liu, Yujia Shi, Yujia Sun, Fangtao Shao, Zhaoyang Wu, and Zhiwei Yang. Not only look, but also listen: Learning multimodal violence detection under weak supervision. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXX 16, pages 322\u2013339. Springer, 2020.   \n[52] Xiang Wu, Ran He, Zhenan Sun, and Tieniu Tan. A light cnn for deep face representation with noisy labels. IEEE Transactions on Information Forensics and Security, 13(11):2884\u20132896, 2018.   \n[53] Shuhan Yi, Zheyi Fan, and Di Wu. Batch feature standardization network with triplet loss for weaklysupervised video anomaly detection. Image and Vision Computing, 120:104397, 2022.   \n[54] Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. Gradient surgery for multi-task learning. Advances in Neural Information Processing Systems, 33:5824\u20135836, 2020.   \n[55] Chen Zhang, Guorong Li, Yuankai Qi, Shuhui Wang, Laiyun Qing, Qingming Huang, and Ming-Hsuan Yang. Exploiting completeness and uncertainty of pseudo labels for weakly supervised video anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16271\u201316280, 2023.   \n[56] Xiangyun Zhao, Samuel Schulter, Gaurav Sharma, Yi-Hsuan Tsai, Manmohan Chandraker, and Ying Wu. Object detection with a unified label space from multiple datasets. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XIV 16, pages 178\u2013193. Springer, 2020.   \n[57] Jia-Xing Zhong, Nannan Li, Weijie Kong, Shan Liu, Thomas H Li, and Ge Li. Graph convolutional label noise cleaner: Train a plug-and-play action classifier for anomaly detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1237\u20131246, 2019.   \n[58] Yi Zhu and Shawn Newsam. Motion-aware feature for improved video anomaly detection. arXiv preprint arXiv:1907.10211, 2019.   \n[59] Yuansheng Zhu, Wentao Bao, and Qi Yu. Towards open set video anomaly detection. In European Conference on Computer Vision, pages 395\u2013412. Springer, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Supplementary Material ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Table A1: Detailed descriptions of VAD datasets used in the paper. N: The number of normal videos.   \nA: The number of abnormal videos. ", "page_idx": 14}, {"type": "table", "img_path": "ywEQkCmImh/tmp/d08c6dc5f2a0ef87e8964da68d08d8059a4bded994247e7a1f75258156bef901.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "Summary The supplementary material is organized in the following order. First, it provides an explanation of the characteristics of the Video Anomaly Detection (VAD) dataset and introduces the detailed configuration and experimental settings of the MDVAD benchmark. Following this, we present implementation details of the experiments and examples and explanations related to abnormal conflict. Lastly, we discuss the pseudo labeling equation, score comparison plots, and failure cases. Note that back-references in the supplementary material sections and tables are from the main manuscript. ", "page_idx": 14}, {"type": "text", "text": "Terminology ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "\u2022 Domain/ Dataset: In this paper, \u2019domain\u2019 refers to the broader context or environment, while \u2019dataset\u2019 refers to the specific collection of data used within that domain.   \n\u2022 Single-domain: Training and evaluation data are the same, as in traditional VAD research.   \n\u2022 Multi-domain Learning/ General VAD: General VAD is the objective of detecting anomalies across various domains, while Multi-domain Learning is the method used to achieve this by training on multiple domains.   \n\u2022 Multi-head Learning: The baseline method proposed in this paper for Multi-domain Learning.   \n\u2022 Multi-task Learning: Performing multiple tasks with a single model, related to E1 by integrating various domain\u2019s anomalies into one framework.   \n\u2022 General Pre-training: A methodology of pre-training on large data without target knowledge, related to E2 by training in a held-out setting and applying to an unseen target. Furthermore, general pre-trained models adapt well to low-shot learning in E3 and finetuning in E4. ", "page_idx": 14}, {"type": "text", "text": "A VAD Datasets ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "As mentioned in $\\S2$ , the VAD task encompasses diverse datasets, as delineated in Table A1. ", "page_idx": 14}, {"type": "text", "text": "UCFC [43], the prominent large-scale dataset for the Weakly-Supervised approach, consists of untrimmed surveillance videos. It categorizes anomalies into 13 classes related to public safety, ranging from crimes such as abuse and arson to more complicated scenarios like stealing and shoplifting. The dataset consists of a total of 950 normal and abnormal videos each, with the training set maintaining a balanced distribution of 800 and 810 samples for normal and abnormal videos, respectively. ", "page_idx": 14}, {"type": "image", "img_path": "ywEQkCmImh/tmp/83558506604b4f5306656e506a9ab3076a18d8d95119f35e64a353d94d839f1c.jpg", "img_caption": ["Figure A4: (a) Distribution of the training videos by abnormal category in the MDVAD benchmark. (b)(c) Examples of abnormal conflict between VAD datasets. The scenes colored by red and blue borders represent abnormal and normal situations, respectively, based on the labels from the corresponding dataset. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "The XD dataset [51] stands out as the most extensive dataset with a variety of environments, including CCTV, movies, hand-held cameras, and car camera settings. It incorporates six categories of violence, such as abuse, riot, and explosion, defining anomalies. Within the dataset of 4,754 videos, there are 2,049 normal and 1,905 abnormal training videos. ", "page_idx": 15}, {"type": "text", "text": "The LAD dataset [47] is defined by a detailed categorization of 14 anomaly classes, including crash, fire, and violence, consisting of 2,000 videos, with 958 normal and 482 abnormal videos. ", "page_idx": 15}, {"type": "text", "text": "The UBIF dataset [9] is composed of various fighting-related anomalies extracted from our daily life videos. This dataset consists of 1,000 videos without a specific categorization for the fighting class, and the training set consists of 757 normal and 176 abnormal videos, leading class imbalance issue. ", "page_idx": 15}, {"type": "text", "text": "The TAD dataset [19] is structured with traffic surveillance and 1st-person videos, encompassing anomalies related to traffic, such as accidents, illegal turns, and road spills. This dataset, totaling 500 videos, has a small volume with 210 and 190 numbers of normal and abnormal training videos. ", "page_idx": 15}, {"type": "text", "text": "The ST [24] serves as a campus surveillance dataset, capturing anomalies occurring on pedestrian walkways. It exhibits a heightened sensitivity to abnormal events, ranging from fighting and throwing to running and jumping. With only 175 normal and 63 abnormal videos in the training set out of a total of 437 videos, there is a notable imbalance between classes, and the quantity of data is insufficient for learning. Abnormal categories in the training set cover all anomalies in the testing set on each dataset except for ST (ST remains indeterminate because of the absence of category information), which means evaluations are exclusively conducted for seen abnormal events. ", "page_idx": 15}, {"type": "text", "text": "Examining the dataset samples in Table A1 reveals that TAD and ST exhibit a visual gap compared to the other datasets, UCFC, XD, and LAD. Such gap is attributed to visual elements such as scene settings and conditions that impact the visual characteristics of scenes, which is the scene discrepancy discussed in $\\S2$ . While LAD (some videos) and ST are recorded in square or campus settings to establish real-world scenario datasets, the remaining datasets are constructed online, such as YouTube and LiveLeak using text search queries. These datasets also exhibit a significant domain distance, as indicated in Table 3. As such, the criteria for defining abnormalities and the visual characteristics of scenes vary across different datasets. ", "page_idx": 15}, {"type": "text", "text": "B MDVAD Benchmarks ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.1 Configuration ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The five datasets introduced in Table A1 have different training set volumes, leading to challenges in handling multiple dataset learning, where larger datasets may overwhelm the learning process. ", "page_idx": 15}, {"type": "text", "text": "For instance, there is a significant disparity in training set volumes, with TAD (400 videos), ST (238 videos), and XD (3954 videos) differing by almost 10 times. Additionally, the number of abnormal videos in XD differs roughly 10 and 30 times compared to TAD and ST, respectively. ", "page_idx": 16}, {"type": "text", "text": "The objective of the MDVAD task is to avoid abnormal conflict and build a general model through balanced learning across diverse situations and anomalies. To control for other variables, we uniformly sampled and balanced the same amount of videos from all domains, equal to the number of videos in the smallest domain. Since TAD and ST have an insufficient number of videos for training, we recombine them with two new datasets, CADP [41] and NWPU [3], respectively, to balance the numbers. CADP is a dataset for traffic accident analysis, and it shares similarities with TAD in terms of setting and abnormal definition. Hence, following the approach in [28], we compose TAD\u2019s training set by adding abnormal videos from CADP. Additionally, incorporating the recently released NWPU dataset, which collects various anomalies of pedestrians on campus, we augment ST\u2019s dataset with NWPU data. For both datasets, we conducted random sampling for normal and abnormal videos, considering the smallest sample size, resulting in a number of 210 normal and 176 abnormal videos. In this process, for datasets with information on abnormal classes, we compose to achieve a uniform number of instances per abnormal category on each dataset. For datasets with a sufficient amount, we organize 3-fold sets to minimize overlap. All reported performance metrics are the average results of evaluations conducted on the target dataset after training on each fold. For example, in the E2 leave-one-out setting, the average results are derived from models trained on each fold and evaluated on an E3 low-shot adaptation set for the corresponding fold. ", "page_idx": 16}, {"type": "text", "text": "The MDVAD benchmark incorporates the datasets introduced in Table A1, including abnormal categories: Abuse, Arrest, Arson, Assault, Accident, Burglary, Explosion, Fighting, Robbery, Shooting, Stealing, Shoplifting, Vandalism, Drop, Hurt, Fall Into Water, Falling, Destroy, Fire, Violence, Crowd, Thiefing, Panic, Loitering, Trampled, Illegal Turns, Illegal Occupations, Retrograde Motion, Traffic Else, Pedestrian on Road, Road Spills, and Campus Else. The circular chart in Fig. A4(a) illustrates the distribution of categories. For datasets without abnormal categories like ST (named as Campus Else), TAD (where additional categories are labeled as Traffic Else), and UBIF (where categorization is not specified and all fall under Fighting), we provide appropriate category names. The averages across the 3-folds are calculated, and in the case of XD with multiple labels per video, we count the number of categories per video. The Fighting predominates in the majority of datasets, occupying the largest portion, followed by categories like Accident, Explosion, and others. ", "page_idx": 16}, {"type": "text", "text": "B.2 Experimental settings ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "VAD is predominantly evaluated using the Area Under the Curve (AUC) score based on abnormal scores, focusing on the trade-off between sensitivity and specificity, emphasizing the false positive rate (FPR). While XD employs the Average Precision (AP) metric to balance precision and recall and concentrate on positive samples for direct comparison in cross-dataset and held-in/out evaluations, and emphasizing False Positive Rate (FPR) (detailed explanation is in Section D), we utilize the AUC score across all evaluations. ", "page_idx": 16}, {"type": "text", "text": "The MDVAD benchmark comprises four protocols: Held-in (E1) involves multiple-source learning with all datasets, Leave-one-out (E2) employs a leave-one-out approach where a dataset left out during training is used for evaluation, low-shot adapation learning (E3) is training on the remaining datasets, and Full fine-tuning (E4) that fine-tunes a multi-domain models on single-domain datasets. In the E3 setting, around $10\\%$ of the training set, 20 videos, is randomly sampled for low-shot examples. For datasets with anomaly category information, low-shot examples are selected uniformly to ensure an even distribution within each category. To mitigate the impact of randomness, the low-shot setting is also conducted with 3-fold cross-validation, obtaining low-shot examples from each fold. In all cases, including MIL, Null-MIL, and NullAng-MIL models, all weights except for the pretrained backbone are updated. Additionally, for abnormal videos, the score from the AC classifier is multiplied to the loss value. ", "page_idx": 16}, {"type": "text", "text": "C Implementation Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "All experiments are conducted on the MDVAD benchmark. We use I3D backbone feature which is pretrained on Kinetics dataset [4] with $C=2048$ dimension of RGB features. During the training phase, we conduct consistent experiments with a batch size of 32, utilizing the Adam optimizer [20] with a learning rate of $5e-5$ and weight decay of $5e-4$ . The input image size is set to $224\\times224$ and following [21, 31, 45, 7], we perform 10-crop augmentation when extracting backbone features. The backbone is used the same as RTFM [45] and CoMo [7]. For input data, 16 frames are stacked for a snippet, and $T$ snippets are uniformly sampled in the video during training. For testing, all snippets pass through the model, and the output score is assigned to all frames within the snippet. For MIL learning, the Top- $.K$ snippets, where $K$ equals $10\\%$ of the total, i.e., $K=3$ , are utilized. In the case of a single-headed MIL model in Table 5 (E1) setting, since pseudo-labels cannot be generated through multiple heads, the AC classifier is trained with a label that $y^{A C}=1$ for a score $s_{D_{1}}^{a}$ within the [0.4, 0.7] range. When computing EMD metric in $\\S2$ , we use a pretrained I3D backbone model for extract embedding features of each dataset and measure the distance between feature vectors. We use a test set with frame-level annotations for abnormalities. All models and experiments are implemented and evaluated end-to-end using PyTorch [34] with a single NVIDIA V100 GPU. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "In weakly-supervised VAD, maintaining class balance is pivotal, so the number of normal and abnormal input videos within a batch is kept equal for the MIL-based learning. Similarly, during multiple source learning, an equal number of input videos from each source domain within a batch is crucial. Despite each head is trained independently, the final feature $\\mathbf{F}_{D A}$ is extracted from a shared domain-agnostic part, necessitating the balance in the number of source domains. Moreover, when training the AC classifier, in order to address the imbalance between the number of abnormal confilct snippets and all normal/abnormal snippets, we apply focal loss [23] to $L_{A C}$ . During the testing phase, the AC classifier is eliminated, and the output is calculated for each input snippet $\\mathbf{v}_{i}$ as the final Abnormal ${\\mathrm{Score}}_{i}$ . ", "page_idx": 17}, {"type": "text", "text": "Table A4 provides information about the layers of the baseline model. Conv1d, fc, Max, BN, and DO represent 1D convolutional layer, fully connected layer, element-wise max activation, 1D batch normalization [16], and dropout [42], respectively, with a dropout probability set to $p=0.7$ . In $\\mathsf{c o n v1d}(c,k,s)$ and $\\mathbf{f}\\,\\mathsf{c}(c),c,k.$ , and $s$ denote the channel size, kernel size, and stride size, respectively. $T$ input snippets pass through the backbone, resulting in a backbone feature $B$ with a shape of $(N,T,C)$ , where $N$ represents the batch size. The feature aggregation layer undergoes channel doubling followed by channel squeezing with element-wise max operation, resulting in an output feature ${\\bf F}_{a g g}$ with a shape of $(N,T,C)$ . Subsequently, the temporal aggregation layer outputs $\\mathbf{F}_{D A}$ with a shape of $(N,T,C/2)$ . These embeddings are then input into the AC classifier and fc layer.The AC classifier, composed of consecutive fc layers, outputs AC scores $\\mathbf{s}^{A C}$ for each snippet with a shape of $(N,T,1)$ . Additionally, the final feature $\\mathbf{F}$ , processed through an fc layer, is input into multiple domain heads $\\mathbf{w}_{D_{d}}$ for NullAng-MIL learning. During this process, both the feature and weights are normalized with respect to $\\|\\mathbf F\\|$ and $\\|\\mathbf{w}_{D_{d}}\\|$ for each domain. ", "page_idx": 17}, {"type": "text", "text": "D Abnormal Conflict ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In Fig. A4, (a) represents a video labeled as normal in UCFC, while (c) is labeled as abnormal in TAD, both depicting a situation where people are present on the road. Similarly, (b) is labeled as a normal video in XD, whereas (d) is considered abnormal in ST; both scenes show bicycling on a ", "page_idx": 17}, {"type": "table", "img_path": "ywEQkCmImh/tmp/8219b89df4aa1fb68434342e45b5ba306c5f6465bd637b1e4d4080e4f00e8841.jpg", "table_caption": ["Table A2: Abnormal Conflict: Average of Relative FPR and Relative FNR. "], "table_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "ywEQkCmImh/tmp/9f2419861ad743900539e47a8042bc9e379e7b28f22c395f0a1ed4c7ad072b8e.jpg", "table_caption": ["Table A4: Illustration of each layer of proposed model. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "walkway. We define such instances, where the criteria for abnormalities differ across datasets, as abnormal conflicts. ", "page_idx": 18}, {"type": "text", "text": "While cross-domain evaluation in Table 2 reveals a domain gap, it is difficult to attribute as abnormal confilcts directly. In Table A2, we calculate the average of the relative False Positive Rate (FPR) and relative False Negative Rate (FNR) to quantify the abnormal conflict between domains. ", "page_idx": 18}, {"type": "equation", "text": "$$\nA C_{i,j}=\\frac{(F P R_{i,j}-F P R_{j,j})+(F N R_{i,j}-F N R_{j,j})}{2},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $i$ and $j$ indicate source and target domain, repectively. First, FPR and FNR refer to the rate of misclassifying abnormal as normal and normal as abnormal in the scenario of learning from a source and testing on a target, respectively. However, since these include the FPR and FNR caused by the incompleteness of the model itself, this cannot accurately reflect the abnormal conflict between the source and target dataset. Therefore, we subtract the FPR and FNR when the source domain is the same as the target domain $(F P R_{j,j}$ and $F N R_{j,j}.$ ) from the cross-domain FPR and FNR to calculate the relative FPR and FNR caused by the domain shift. Table A2 shows similar trends compared to Table 2, where values are not normalized. This shows that abnormal conflicts between domains are relevant to the reduction in generalization ability that can occur when transferring between domains. ", "page_idx": 18}, {"type": "text", "text": "E Related Works ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As mentioned, proposing a new VAD model is beyond the scope of this paper, this part is organized to aid understanding. ", "page_idx": 18}, {"type": "text", "text": "Unsupervised VAD Defining anomalies precisely is challenging as they can vary based on criteria and sensitivity, and it is impossible to categorize and collect datasets for every scenario. For this reason, Unsupervised VAD methods [33, 5, 24, 15] have been developed to learn normal patterns using only normal training data and then detect anomalies as scenes with low normality during the test phase. However, this approach leads to a significant bias towards the normal samples, causing the detector to misclassify normal patterns that differ from the learned data as abnormal events, resulting in a high false alarm rate. To address this issue, Weakly-supervised VAD (WVAD) approaches [55, 44, 43, 50, 21, 7] have been introduced to differentiate between normal and abnormal events with minimal supervision using video-level annotations, achieving significant performance improvements while incurring lower labeling costs compared to frame-level annotations. ", "page_idx": 18}, {"type": "text", "text": "Weakly-supervised VAD MMIL [43] is the first WVAD method to pose the MIL ranking approach as a regression problem that achieves significant performance gains. Various learning methods, including magnitude feature learning [45], self-training approaches through pseudo labels [13, 21], and distance learning [53], have been explored alongside traditional MIL methods. Furthermore, subsequent approaches have focused on capturing features by focusing temporal or motion information [58], leveraging additional audio signals [51], learning relations between temporal [50] or motion and context information [7]. These methods differentiate complex anomalies through contextual information; for example, the same motion may be classified as normal or abnormal depending on the surrounding environment. PFMP [26] proposed a method to utilize virtual data anomalies to reduce scene discrepancy with real-world data, addressing the issue of data scarcity in VAD. However, these approaches still cannot address abnormal confilcts, where the same situation is labeled differently as abnormal or normal based on the criteria of different datasets. ", "page_idx": 18}, {"type": "text", "text": "Generalization for VAD A few studies have been conducted to generalize VAD. Domain adaptation refers to evaluating a new domain that was not seen during training, and some works have proposed using some data from the target domain [27, 29] or not using it at all [2]. We also experiment with domain adaptation, but the difference is that we use multiple domains compared to existing studies that only use a single domain during training. Open-set recognition aims to work well even in untrained classes (abnormal categories in VAD). Compared to our research involving multiple domains, Open-set VAD [59, 1] focuses on learning and evaluation within a single domain. ", "page_idx": 18}, {"type": "text", "text": "Multi-domain learning Multi-Domain Learning (MDL) refers to a method for learning datasets from multiple domains with various distributions together. MDL originated from natural language processing [11, 17] and has been applied to various tasks in computer vision [36, 37, 22, 32, 49, ", "page_idx": 18}, {"type": "image", "img_path": "ywEQkCmImh/tmp/6acb69639382f62389253b56b9ea68df38f159209fb018ab4ff57e89da9c5410.jpg", "img_caption": ["Figure A5: The plot illustrates the abnormal confilct scores from the AC Classifier on normal videos on UCFC. For clarity, all scores have been normalized using the minimum and maximum values of the entire score distribution produced by the AC Classifier. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "48, 56, 18]. The difficulty of MDL arises when the difference in distribution between domains is significant, and learning domain-invariant features is the basic approach [39]. In the fields of image classification [36, 37, 22], object tracking [32], detection [49], and segmentation [48], methods for learning multiple domains with multiple heads have been proposed. After that, methods have been proposed to have a unified label space [56, 18], but in this process, the problem that the labels are different for each domain arises. [18] solved the label conflict problem by proposing classindependent loss using the Null class strategy. On the other hand, VAD has only two classes, normal and abnormal, so there is no explicit label confilct problem, but there is an implicit abnormal confilct problem where the definition of a label is different for each domain. ", "page_idx": 19}, {"type": "text", "text": "A similar method is multi-task learning [54], which considers differences between tasks rather than domains. In addition, multi-source domain adaptation [35] utilizes data from the target domain, and domain generalization [10, 40, 12] requires adaptation to an unseen target domain. The difference with these tasks is that they basically share the label space between the source and target domains, while MDL for VAD has different label definitions. ", "page_idx": 19}, {"type": "text", "text": "F Discussions ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "F.1 Pseudo label of AC Classifier ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The purposes of the AC Classifier is the facilitation of feature learning with consideration of the discrepancies across multiple domains. In cases where snippet is entirely normal or abnormal across all datasets, the AC score is low, making it difficult to directly use it for the abnormal score. Noisy samples can indeed have a negative impact on training in Eq. 6. However, in cases where even one of the multiple datasets has a different definition of normal and abnormal, it is crucial to sensitively detect ccoonndfiluccttse id na sbulacthi osna smtupldeise,s  lewaitdhi nSgt du. s $\\tau=0.1$ )e  atnhda t au fsiixnegd  av adliuffee $(y_{i}^{A C}=\\mathbf{\\dot{1}}$ r ewfheerraeb $0.3<s_{D_{d},i}^{a}<0.7)$ which revealed no significant differences between the methods. ", "page_idx": 19}, {"type": "text", "text": "F.2 Abnormal conflict score ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Fig. A5 depicts the output abnormal conflict scores from the AC classifier of the E1 held-in model. While all events are considered normal in UCFC, (a) and (b) correspond to the Pedestrian on Road abnormal category in TAD (as shown in Fig. 1(c)). Therefore, unlike (c) and (d), the normal situations of people shopping in a grocery store, (a) and (b) exhibit elevated abnormal conflict scores. ", "page_idx": 19}, {"type": "text", "text": "F.3 Abnormal score ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Fig. A6 compares the abnormal scores of our model, trained with NullAng-MIL $+\\,\\mathrm{AC}$ classifier, and the MIL model trained with MIL loss on a single head in the E2 multiple dataset setting. In scenario (a), before the explosion, an oil truck passes, causing the MIL model to generate a high abnormal ", "page_idx": 19}, {"type": "image", "img_path": "ywEQkCmImh/tmp/afa579f86d1d7587c6af313f589bd3f93a1856ca1b3de3be2ccc6ab2129c0c8b.jpg", "img_caption": ["(d) \u2018Car on walkway\u2019 abnormal test video on ST "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure A6: The plot of abnormal scores with blue and magenta lines representing our model and the MIL baseline model (E1), respectively. The red region indicates the time when abnormal events occurred. The scenes are from input videos whose borders are colored red and blue for normal and abnormal scenes, respectively. For clarity, the scores from each model have been normalized. ", "page_idx": 20}, {"type": "text", "text": "score as a false alarm, while our model accurately predicts only the explosion abnormal situation. In scenario (b), where a person loitering the office, the MIL model outputs a high abnormal score, in contrast, our model that trained with multiple heads to avoid domain conflicts categorizes only the arrest defined in UCFC as an abnormal event. ", "page_idx": 20}, {"type": "text", "text": "Scenarios (c) and (d) involve abnormal videos in the ST dataset where a running person or car appears on the walkway. Because these scenarios are classified as normal scenes in other datasets during training, the MIL model considers them as normal. However, our model, recognizing them as abnormal scenes corresponding to ST, outputs high abnormal scores. Thus, when learning from multiple datasets, it is crucial to avoid confilcts by simultaneously learning domain-agnostic features with the AC classifier and predicting domain-specific scores using multiple heads according to each dataset\u2019s criteria. ", "page_idx": 20}, {"type": "text", "text": "F.4 Multi-domain learning on Virtual dataset ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The UBNormal (UBN) dataset [1] is a VAD benchmark proposed for open-set scenarios to handle unexpected abnormal events, where the abnormal categories in the train set and test set do not overlap. Unlike other VAD datasets which were collected from the real world, UBN consists of synthetic videos which leads ", "page_idx": 20}, {"type": "table", "img_path": "ywEQkCmImh/tmp/90d0b4ecf9f93760d6d9b812547527885ca4c94b443b0b7c864255b14897a909.jpg", "table_caption": ["Table A5: Multi-source learning on MDVAD with UBN in E1 "], "table_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "ywEQkCmImh/tmp/9b6134a6563109c7dc7884f6b1ada6da0e6faa72bffe3c808a369c80c1c79c68.jpg", "img_caption": ["(c) \u2018Skateboarder on walkway\u2019 abnormal test video on ST "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Figure A7: The abnormal scores of our model and the MIL model, where (a) corresponds to False Positive results, and (b)(c) represent False Negative results. ", "page_idx": 21}, {"type": "text", "text": "abnormal confilcts and differences in the visual settings of scenes. It comprises ", "page_idx": 21}, {"type": "text", "text": "543 videos across 29 scenes with 22 types of anomaly categories. Same as MDVAD benchmark, we reorganize Training set with 210 number of normal videos and 176 number of abnormal videos where training anomaly categories are falling, dancing, walking injured, running injured, crawling and stumbling walk and testing anomalies are running, having a seizure, laying down, shuffilng, walking drunk, people and car accident, car crash, jumping, fire, smoke, jaywalking and driving outside lane. ", "page_idx": 21}, {"type": "text", "text": "The Table A5 shows the performance in each target domain when trained with MDVAD and UBNormal under the E1: held-in setting. In the single-head MIL baseline, there is a performance drop when trained with MDVAD $^{1+}$ UBN, indicating difficulty in handling AC. However, the model trained with multiple heads and the AC classifier shows improved results. By leveraging the virtual dataset, we can overcome data limitations and create a general model capable of handling diverse and complex scenes. ", "page_idx": 21}, {"type": "text", "text": "F.5 Baseline models ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We conducted additional experiments using the WSAL [30] model as a baseline to validate our proposed method on the MDVAD benchmark\u2019s four protocols. The Table A6 presents the results, where all settings are consistent with the other experiments in the paper. The results show the addition of multi-head learning with NullAng-MIL and the AC Classifier to the WSAL model brings performance gains which effectively operate across ", "page_idx": 21}, {"type": "table", "img_path": "ywEQkCmImh/tmp/76f5138df493b799b7791309479e7877e815b0a4e3061749fb94ed6a2f92fa42.jpg", "table_caption": ["Table A6: Results of MDVAD with different baseline "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "different baselines. Notably, in the E3 and E4, which shows the target adaptation of the pre-trained general model, the method yielded competitive results. Future studies can be delve deeper into studying more sophisticated baselines for resolving AC within the MDVAD setting. ", "page_idx": 21}, {"type": "text", "text": "F.6 Failure cases ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Fig. A7(a) presents an abnormal test video from UCFC corresponding to Arrest anomalies. However, this video includes scenes of Stealing, leading to the subsequent arrest and physical fighting. Both the MIL and our models output high abnormal scores for scenes other than the Arrest, as they correspond to Stealing and Fighting abnormal categories in UCFC. Models predict accurately in categories other than Arrest, but this failure is observed because of a single abnormal label for each video. ", "page_idx": 22}, {"type": "text", "text": "In Fig. A7(b), an abnormal event from ST is considered normal by both models, as other datasets are generally classified as normal. Similarly, in Fig. A7(c), the skateboarder is deemed normal, resulting in a false negative failure case. However, these situations are challenging to identify as severe abnormalities from a general perspective. This failure case is able to be addressed through low-shot learning or fine-tuning based on ST\u2019s criteria. ", "page_idx": 22}, {"type": "text", "text": "F.7 Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The development of Multi-Domain Learning for Generalizable VAD enhances the reliability and accuracy of security and surveillance systems across diverse environments, thereby improving public safety. This research advances AI and machine learning by addressing domain adaptation challenges, promoting robust and generalizable systems. Additionally, it underscores the importance of ethical considerations and privacy, ensuring that advanced surveillance technologies are deployed responsibly and transparently. ", "page_idx": 22}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: In Abstract, $\\S\\ 1$ , and $\\S\\ 1.1$ . ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: In $\\S\\ S$ and F.6 ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: In $\\S\\ 4$ and $\\S\\,C$ Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "page_idx": 24}, {"type": "text", "text": "Justification: We will release the data and code when the paper is accepted. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: In $\\S\\ 4,\\S\\ C$ , and Table A4 Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: We do not reprot the error bars but all reported experimental results are average of 3-fold setting. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: In $\\S\\,C$ Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We have complied with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: In $\\S\\,\\mathrm{F}.7$ ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 26}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 27}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: In $\\S$ A ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}]