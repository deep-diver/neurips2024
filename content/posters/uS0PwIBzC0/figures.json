[{"figure_path": "uS0PwIBzC0/figures/figures_1_1.jpg", "caption": "Figure 1: Performance vs total trainable parameters for GSM-8K (left) and Commonsense Reasoning (right) on Gemma-2B. SVFT/R outperforms DoRA,=8/16 with 75% less trainable parameters.", "description": "This figure compares the performance (accuracy) of various parameter-efficient fine-tuning (PEFT) methods against the number of trainable parameters required.  The left panel shows results on the GSM-8K benchmark, while the right panel shows results on a commonsense reasoning benchmark.  Both use the Gemma-2B language model.  The figure demonstrates that SVFT achieves higher accuracy than competing methods (like LoRA and DORA) while using significantly fewer trainable parameters.  Specifically, SVFT and its random variant (SVFT/R) outperform DoRA with 8 and 16 ranks using 75% fewer parameters.", "section": "1 Introduction"}, {"figure_path": "uS0PwIBzC0/figures/figures_2_1.jpg", "caption": "Figure 2: Schematic comparison of LoRA, VeRA, DORA, and SVFT (left to right).", "description": "This figure schematically compares four parameter-efficient fine-tuning (PEFT) methods: LoRA, VeRA, DORA, and SVFT.  Each method is illustrated with a diagram showing how it updates the pretrained weight matrix (W).  LoRA uses low-rank matrices (B and A) to update W. VeRA employs trainable diagonal matrices (Ab and Ad) with shared random matrices. DORA decomposes W into magnitude and direction components, updating only the direction with low-rank matrices. SVFT updates W using a sparse combination of its singular vectors (U and V), training only the coefficients (M) of these combinations.  The diagrams highlight the differences in the structure of the update matrices and the number of trainable parameters in each method.", "section": "3 Method"}, {"figure_path": "uS0PwIBzC0/figures/figures_3_1.jpg", "caption": "Figure 3: An Overview of SVFT. The original weights W are decomposed into U, \u03a3, V. Here, M contains all the trainable parameters, which can be configured into patterns such as Plain, Random, Banded, and Top-k, represented by patterns of trainable (orange) and zero (gray) elements.", "description": "This figure illustrates the core idea of the SVFT method.  The original weight matrix W is decomposed using Singular Value Decomposition (SVD) into three components: U (left singular vectors), \u03a3 (singular values), and V (right singular vectors).  SVFT introduces a sparse, learnable matrix M to modify the singular values. The figure shows four different configurations for the sparsity pattern of M: Plain (diagonal), Banded, Random, and Top-k. The orange cells represent the trainable parameters within M, while gray cells are fixed to zero.  The Top-k configuration highlights a matrix where only the top k strongest interactions are trainable.", "section": "3 Method"}, {"figure_path": "uS0PwIBzC0/figures/figures_7_1.jpg", "caption": "Figure 4: Performance variation with SVFT based on the adapted weight matrices \u2013 GSM-8K with Gemma-2B. Adapting more target weight types results in greater gains in performance. Interestingly, for a fixed parameter budget, adapting U and D weight types gives greater lifts than adapting Q and V.", "description": "This figure shows the impact of adapting different weight matrices (Q, K, V, U, D, O, G) on the performance of SVFT.  It demonstrates that including more weight types in the fine-tuning process generally leads to better accuracy.  Different levels of off-diagonal elements (d = 2, 4, 8) are tested.  Interestingly, it also highlights that updating the U and D weight matrices provides better performance gains compared to Q and V matrices, especially considering the same parameter budget.", "section": "5.5 Impact of M's Structure on Performance"}, {"figure_path": "uS0PwIBzC0/figures/figures_16_1.jpg", "caption": "Figure 1: Performance vs total trainable parameters for GSM-8K (left) and Commonsense Reasoning (right) on Gemma-2B. SVFT/R outperforms DoRA,=8/16 with 75% less trainable parameters.", "description": "This figure compares the performance (accuracy) of various parameter-efficient fine-tuning (PEFT) methods against the number of trainable parameters used.  The left panel shows results for the GSM-8K benchmark, while the right panel shows results for Commonsense Reasoning, both using the Gemma-2B language model.  The figure demonstrates that SVFT consistently achieves higher accuracy than competing methods (LoRA, DORA, BOFT, VeRA) while using significantly fewer trainable parameters.  Specifically, SVFT outperforms DoRA with 8 and 16 ranks while using 75% fewer parameters.", "section": "1 Introduction"}]