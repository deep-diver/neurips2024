{"references": [{"fullname_first_author": "Jacob Devlin", "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019-06-01", "reason": "This paper introduced BERT, a foundational model for many subsequent language models, demonstrating the power of transformer-based architectures in natural language processing."}, {"fullname_first_author": "Lili Chen", "paper_title": "Decision Transformer: Reinforcement learning via sequence modeling", "publication_date": "2021-12-01", "reason": "This is a highly influential paper that introduced the Decision Transformer, which is central to the Meta-DT algorithm proposed in this paper."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper demonstrated the surprising few-shot learning capabilities of large language models, inspiring similar approaches to few-shot learning in reinforcement learning."}, {"fullname_first_author": "Scott Fujimoto", "paper_title": "Off-policy deep reinforcement learning without exploration", "publication_date": "2019-06-01", "reason": "This paper presented a significant advance in off-policy reinforcement learning, addressing a key challenge in offline meta-RL."}, {"fullname_first_author": "Sergey Levine", "paper_title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems", "publication_date": "2020-05-01", "reason": "This paper provides a comprehensive overview of offline reinforcement learning, which is the context for the Meta-DT algorithm proposed in the paper."}]}