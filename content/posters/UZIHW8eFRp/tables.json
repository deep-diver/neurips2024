[{"figure_path": "UZIHW8eFRp/tables/tables_5_1.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents a comparison of the normalized scores achieved by different offline reinforcement learning algorithms across various Gym-MuJoCo benchmark tasks.  The \"Trifle\" algorithm is the focus, and its performance is compared against several baseline methods. The results for Trifle are averages across 12 different random seeds to show statistical significance.  The table includes various dataset types (Med-Expert, Medium, and Med-Replay) and environments (HalfCheetah, Hopper, and Walker2d).  Normalized scores allow comparison across different environments.", "section": "6 Experiments"}, {"figure_path": "UZIHW8eFRp/tables/tables_8_1.jpg", "caption": "Table 2: Normalized Scores on the Action-Space-Constrained Gym-MuJoCo Variants. The results of Trifle and TT are both averaged over 12 random seeds, with mean and standard deviations reported.", "description": "This table presents the performance comparison between Trifle and TT on action-space-constrained versions of three Gym-MuJoCo environments (Halfcheetah, Hopper, and Walker2d).  The results are averages over 12 random seeds, reporting the mean and standard deviation of the normalized scores. The \"Med-Expert\" dataset is used for all environments.", "section": "6.3 Action-Space-Constrained Gym-MuJoCo Variants"}, {"figure_path": "UZIHW8eFRp/tables/tables_18_1.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents the normalized scores achieved by Trifle and various baseline algorithms across nine standard Gym-MuJoCo benchmark tasks.  The datasets used vary in trajectory quality (Medium-Expert, Medium, and Med-Replay), while the environments encompass three different locomotion tasks (HalfCheetah, Hopper, and Walker2d).  Trifle's results are averaged across 12 independent runs to demonstrate statistical robustness. Baseline results are taken directly from their respective publications.", "section": "6 Experiments"}, {"figure_path": "UZIHW8eFRp/tables/tables_18_2.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents the normalized scores achieved by Trifle and other baseline algorithms on nine standard Gym-MuJoCo benchmark tasks.  The results show Trifle's performance in comparison to existing offline RL methods, broken down by dataset type (Medium-Expert, Medium, and Medium-Replay) and environment (HalfCheetah, Hopper, and Walker2d). The scores are normalized, with 100 representing a well-trained SAC agent and 0 representing a random policy. Trifle's performance is averaged across 12 random seeds.", "section": "6 Experiments"}, {"figure_path": "UZIHW8eFRp/tables/tables_19_1.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents the normalized scores achieved by Trifle and various baseline methods across nine standard Gym-MuJoCo benchmark tasks.  The scores are normalized to range from 0 (random policy) to 100 (a well-trained SAC agent).  Trifle's results are averaged over 12 random seeds for a robust evaluation, while baseline results are taken from their original papers.", "section": "6 Experiments"}, {"figure_path": "UZIHW8eFRp/tables/tables_20_1.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents the normalized scores achieved by Trifle and other baseline algorithms across various Gym-MuJoCo benchmark tasks.  The scores are normalized relative to a well-trained SAC agent (100) and a random policy (0). Trifle's results are averaged over 12 random seeds for robustness, using the same number of seeds as a comparable algorithm from a previous study where applicable.  The results for other baselines are taken directly from their original papers.", "section": "6 Experiments"}, {"figure_path": "UZIHW8eFRp/tables/tables_20_2.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents the normalized scores achieved by Trifle and other offline RL baselines on nine standard Gym-MuJoCo benchmark environments.  These environments are categorized by dataset difficulty (Medium-Expert, Medium, and Medium-Replay), representing varying qualities of offline data. The table highlights Trifle's state-of-the-art performance, achieving top scores on 7 out of 9 tasks and the highest average score overall.", "section": "Experiments"}, {"figure_path": "UZIHW8eFRp/tables/tables_21_1.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents the normalized scores achieved by Trifle and various baseline methods across nine standard Gym-MuJoCo benchmark environments.  The environments are categorized by dataset difficulty (Med-Expert, Medium, Med-Replay) and locomotion task (HalfCheetah, Hopper, Walker2d).  Trifle's results are averaged over 12 random seeds for a robust evaluation.  The scores for baseline methods are taken directly from the cited papers, allowing for a fair comparison against state-of-the-art performance.", "section": "Experiments"}, {"figure_path": "UZIHW8eFRp/tables/tables_21_2.jpg", "caption": "Table 1: Normalized Scores on the standard Gym-MuJoCo benchmarks. The results of Trifle are averaged over 12 random seeds (For DT-base and DT-Trifle, we adopt the same number of seeds as [6]). Results of the baselines are acquired from their original papers.", "description": "This table presents the normalized scores achieved by Trifle and various baseline algorithms across nine standard Gym-MuJoCo benchmark tasks.  The normalized scores are relative to a well-trained SAC agent (100) and a random policy (0). Trifle's results are averaged over 12 random seeds for a fair comparison. Baseline results are taken from their respective original papers.", "section": "6 Experiments"}]