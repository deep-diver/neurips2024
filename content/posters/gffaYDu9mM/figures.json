[{"figure_path": "gffaYDu9mM/figures/figures_1_1.jpg", "caption": "Figure 1: Inpainting outcomes of multi-view images from original Stable Diffusion [71] (middle) with those achieved by our approach (right). The inpainted areas are highlighted in red and green boxes.", "description": "This figure shows a comparison of image inpainting results using Stable Diffusion and the proposed method.  The top row displays View #1, and the bottom row displays View #2. For each view, there are three images: (a) the original image with the object to be removed; (b) the image inpainted using Stable Diffusion, demonstrating inconsistencies between the two views; and (c) the image inpainted using the proposed method, showing improved consistency between the views. The inpainted areas are highlighted with red and green boxes to clearly show the differences.", "section": "1 Introduction"}, {"figure_path": "gffaYDu9mM/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of our method. Our approach begins with (a) pre-training the NeRF \u03d5 with a sampled inpainting prior Zp from Stable Diffusion \u03b8, detailed in Sec. 4.1. It then progresses to (b) latent-aligned inpainting {Z}i for multi-view images through Explicit Latents Alignment (ELA) and Implicit Latents Alignment (ILA), as described in Sec. 4.2. Finally, the NeRF is optimized using a patch-based hybrid loss strategy outlined in Sec. 4.3. Throughout the training process, we fix Stable Diffusion \u03b8 and update the scene-specific NeRF parameters \u03d5 only.", "description": "This figure shows a schematic overview of the proposed In-N-Out method for 3D object removal.  It consists of two main stages: (a) Pre-training a Neural Radiance Field (NeRF) using a single-view inpainting prior generated by a diffusion model; and (b) inpainting multiple views by aligning latent representations (explicitly for initial latents and implicitly for intermediate latents) and optimizing the NeRF with a patch-based hybrid loss.  The figure highlights the key components:  Stable Diffusion, the NeRF, Explicit Latent Alignment (ELA), Implicit Latent Alignment (ILA), and the patch-based loss. The process begins with a pre-trained NeRF, then proceeds to inpaint the multiple views using latent alignments and the patch-based hybrid loss to optimize the NeRF.", "section": "4 Method"}, {"figure_path": "gffaYDu9mM/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of two types of Latent Alignment. This figure depicts the Explicit Latents Alignment (ELA) and Implicit Intermediate Latents Alignment (ILA) processes, as detailed in Sec. 4.2.", "description": "This figure illustrates the two key components of the proposed latent alignment approach: Explicit Initial Latent Alignment (ELA) and Implicit Intermediate Latents Alignment (ILA).  ELA aligns the initial latent across views using geometric information derived from a pre-trained NeRF, ensuring structural consistency. ILA leverages cross-view attention in the diffusion model's denoising process to align intermediate latents implicitly, improving appearance consistency. The diagram shows how both methods ensure consistent latent features across different views when inpainting.", "section": "4.2 Stage 2: Latents Alignment"}, {"figure_path": "gffaYDu9mM/figures/figures_5_2.jpg", "caption": "Figure 3: Illustration of two types of Latent Alignment. This figure depicts the Explicit Latents Alignment (ELA) and Implicit Intermediate Latents Alignment (ILA) processes, as detailed in Sec. 4.2.", "description": "This figure illustrates the two key components of the proposed latent alignment approach. (a) shows the explicit initial latent alignment (ELA), which leverages the pre-trained NeRF to align the initial latent across different views. (b) shows the implicit intermediate latent alignment (ILA), which utilizes cross-view attention to align the intermediate latents during the denoising process. The goal is to achieve consistent inpainting across multiple views by aligning both initial and intermediate latents.", "section": "4.2 Stage 2: Latents Alignment"}, {"figure_path": "gffaYDu9mM/figures/figures_7_1.jpg", "caption": "Figure 4: Qualitative results on the SPIn-NeRF dataset. High-frequency loss is observed in multi-view-based methods (SPIn-NeRF and NeRFiller). Conversely, the single-view-based method, InFusion, sometimes results in geometry artifacts in the test views, as in the second and fourth rows.", "description": "This figure shows a qualitative comparison of object removal results on the SPIn-NeRF dataset using four different methods: SPIn-NeRF, NeRFiller, InFusion, and the proposed 'In-N-Out' method. Each row represents a different scene. The red boxes highlight the areas where the object was removed and inpainted.  The figure demonstrates that SPIn-NeRF and NeRFiller, while achieving multi-view consistency, suffer from high-frequency detail loss, resulting in blurry inpainted areas. In contrast, the single-view-based InFusion method, while preserving detail, sometimes introduces geometric inconsistencies in the inpainted region. The proposed 'In-N-Out' method is shown to effectively mitigate the shortcomings of the other methods by maintaining both high-frequency detail and multi-view consistency.", "section": "5.2 Main Results"}, {"figure_path": "gffaYDu9mM/figures/figures_8_1.jpg", "caption": "Figure 4: Qualitative results on the SPIn-NeRF dataset. High-frequency loss is observed in multi-view-based methods (SPIn-NeRF and NeRFiller). Conversely, the single-view-based method, InFusion, sometimes results in geometry artifacts in the test views, as in the second and fourth rows.", "description": "This figure compares the qualitative results of four different methods for 3D object removal on the SPIn-NeRF dataset. The methods are SPIn-NeRF, NeRFiller, InFusion, and the proposed 'Ours' method.  The figure shows that multi-view methods (SPIn-NeRF and NeRFiller) tend to lose high-frequency details while the single-view method (InFusion) can produce geometry artifacts.  The 'Ours' method aims to mitigate both of these issues.", "section": "5.2 Main Results"}, {"figure_path": "gffaYDu9mM/figures/figures_8_2.jpg", "caption": "Figure 6: Ablation study on latent aligned onpainting. 2D Inpainting results when key components of our proposed method are omitted. Naive inpainting using Stable Diffusion can refer to Fig. 1.", "description": "This figure shows an ablation study comparing the results of the proposed method with and without its key components: Explicit Latent Alignment (ELA) and Implicit Latent Alignment (ILA).  The leftmost image shows the inpainting prior, a sample from a randomly selected view.  The next three images demonstrate the effects of removing ELA, removing ILA, and the complete method respectively.  It highlights the importance of both ELA and ILA for achieving high-quality and consistent inpainting results, and compares them with a naive inpainting approach using Stable Diffusion (as seen in Figure 1).", "section": "5.3 Ablation Studies"}, {"figure_path": "gffaYDu9mM/figures/figures_9_1.jpg", "caption": "Figure 7: Ablation study on design choices based on rendering quality. This figure displays rendering results from NeRF when key components are individually removed from our full model.", "description": "This figure shows the ablation study results on the rendering quality of the NeRF model by removing key components individually: ELA (Explicit Latent Alignment), ILA (Implicit Latent Alignment), the patch-based loss, the LPIPS loss, and the adversarial loss.  The results show that each component plays an important role in generating high-quality, coherent inpainted 3D scenes.  Removing ELA causes geometric mismatches, removing ILA leads to blurry colors, removing the patch loss results in overall poor quality, and removing the perceptual and adversarial losses impact the detail and sharpness, respectively.", "section": "5.3 Ablation Studies"}, {"figure_path": "gffaYDu9mM/figures/figures_20_1.jpg", "caption": "Figure 4: Qualitative results on the SPIn-NeRF dataset. High-frequency loss is observed in multi-view-based methods (SPIn-NeRF and NeRFiller). Conversely, the single-view-based method, InFusion, sometimes results in geometry artifacts in the test views, as in the second and fourth rows.", "description": "This figure shows a qualitative comparison of object removal results using four different methods: SPIn-NeRF, NeRFiller, InFusion, and the proposed 'In-N-Out' method.  The results are presented for several scenes, showcasing the impact of each approach on the preservation of high-frequency details and overall 3D scene consistency. The figure highlights the shortcomings of multi-view methods (SPIn-NeRF and NeRFiller) in preserving high-frequency details and the limitations of single-view methods (InFusion) that can sometimes lead to geometric inconsistencies. The 'In-N-Out' method aims to address these limitations.", "section": "5.2 Main Results"}, {"figure_path": "gffaYDu9mM/figures/figures_21_1.jpg", "caption": "Figure 4: Qualitative results on the SPIn-NeRF dataset. High-frequency loss is observed in multi-view-based methods (SPIn-NeRF and NeRFiller). Conversely, the single-view-based method, InFusion, sometimes results in geometry artifacts in the test views, as in the second and fourth rows.", "description": "This figure shows a qualitative comparison of object removal results on the SPIn-NeRF dataset using four different methods: SPIn-NeRF, NeRFiller, InFusion, and the proposed 'In-N-Out' method.  Each row represents a different scene. The images show that multi-view methods (SPIn-NeRF and NeRFiller) tend to lose high-frequency details, while the single-view method (InFusion) can produce geometric artifacts. The proposed method aims to address these limitations by aligning latent representations across multiple views, resulting in a better balance between detail preservation and consistency.", "section": "5.2 Main Results"}, {"figure_path": "gffaYDu9mM/figures/figures_22_1.jpg", "caption": "Figure 1: Inpainting outcomes of multi-view images from original Stable Diffusion [71] (middle) with those achieved by our approach (right). The inpainted areas are highlighted in red and green boxes.", "description": "This figure compares the inpainting results of a multi-view image using Stable Diffusion and the proposed method. The original image shows an occluded area (in red and green boxes). The middle column shows the inpainting results obtained from Stable Diffusion, which exhibits inconsistencies across views.  In contrast, the right column shows the inpainting results of the proposed method, demonstrating improved multi-view consistency and fidelity.", "section": "1 Introduction"}]