{"references": [{"fullname_first_author": "Moritz Hardt", "paper_title": "Strategic classification", "publication_date": "2016-00-00", "reason": "This paper is foundational to the field of strategic classification, introducing the core concepts and challenges addressed in the current work."}, {"fullname_first_author": "Sagi Levanon", "paper_title": "Generalized strategic classification and the case of aligned incentives", "publication_date": "2022-07-17", "reason": "This paper extends the theory of strategic classification, offering a more general framework and addressing the scenario where agents' incentives align with the decision-maker's goals."}, {"fullname_first_author": "Rohan Taori", "paper_title": "Data feedback loops: Model-driven amplification of dataset biases", "publication_date": "2023-00-00", "reason": "This paper highlights the issue of model-driven bias amplification when using models for data annotation, directly relevant to the risks of model retraining with strategic feedback explored in the current work."}, {"fullname_first_author": "George Alexandru Adam", "paper_title": "Error amplification when updating deployed machine learning models", "publication_date": "2022-00-00", "reason": "This paper investigates the risks of retraining machine learning models in deployed systems, offering insights directly applicable to the current work's focus on retraining models with strategic feedback."}, {"fullname_first_author": "Jinshuo Dong", "paper_title": "Strategic classification from revealed preferences", "publication_date": "2018-00-00", "reason": "This paper addresses strategic classification in a setting where agent preferences are revealed through their actions, which is relevant to the current paper's modeling of strategic agent behavior."}]}