[{"figure_path": "TNQ0hxh3O1/figures/figures_1_1.jpg", "caption": "Figure 1: Image-level labels in large-scale datasets such as ImageNet-21k [16] often do not convey precise object information [17, 15] which affects while learning generalizable detectors. Recent methods tackle this issue by various label-to-box assignment strategies [12, 13, 14, 15] as in (a) but are heavily restricted by raw image-level labels and still suffer from image-to-box label mismatch [17]. Self-training [18] with the detectors pre-trained with [13, 14, 15] could circumvent the label mismatch issue but the generated pseudo box labels are error-prone due to the lack of proper supervision as in (b). Our proposed LHST introduces language hierarchy to expand the image-level labels and enables co-regularization between the expanded labels and self-training which allows producing more accurate pseudo box labels in (c).", "description": "This figure illustrates the limitations of existing weakly supervised object detection methods and introduces the proposed Language Hierarchical Self-Training (LHST) method.  (a) shows how current label-to-box assignment strategies struggle with the imprecision of image-level labels. (b) demonstrates the issue with self-training, where generated pseudo-labels can be inaccurate due to a lack of supervision. (c) presents the LHST approach, which uses a language hierarchy (WordNet) to expand image-level labels and co-regularizes them with self-training for more accurate pseudo-labels, mitigating the image-to-box mismatch problem.", "section": "1 Introduction"}, {"figure_path": "TNQ0hxh3O1/figures/figures_3_1.jpg", "caption": "Figure 2: The proposed language hierarchical self-training consists of two flows including Pseudo Label Generation (top box) and Training with Generated Labels (bottom box). The Pseudo Label Generation flow leverages WordNet to expand the image-level labels, and then merges the expanded image-level labels with the predicted pseudo box labels, such that the expanded image-level labels could provide richer and more flexible supervision (than the limited and rigid raw labels) to regularize the self-training which is prone to errors in pseudo labeling. In addition, as the labels expanded by WordNet (i.e., the expanded logits \u20181\u2019 in yhieage and ybier) are not all reliable, Pseudo Label Generation predicts reliability scores for the expanded labels to adaptively re-weight them when applying them on different images or pseudo boxes. In Training with Generated Labels, we optimize the detector with the generated image-level and box-level labels, where the image-level training could regularize the training with pseudo box-level labels as pseudo box labels vary along training iterations and are not very stable.", "description": "This figure illustrates the Language Hierarchical Self-training (LHST) process. LHST uses WordNet to expand image-level labels, merges them with predicted pseudo-box labels, and uses predicted confidence scores to weight the expanded labels. This improves self-training by providing richer supervision and mitigating the image-to-box label mismatch problem.", "section": "3.2 Language Hierarchical Self-training"}, {"figure_path": "TNQ0hxh3O1/figures/figures_20_1.jpg", "caption": "Figure 1: Image-level labels in large-scale datasets such as ImageNet-21k [16] often do not convey precise object information [17, 15] which affects while learning generalizable detectors. Recent methods tackle this issue by various label-to-box assignment strategies [12, 13, 14, 15] as in (a) but are heavily restricted by raw image-level labels and still suffer from image-to-box label mismatch [17]. Self-training [18] with the detectors pre-trained with [13, 14, 15] could circumvent the label mismatch issue but the generated pseudo box labels are error-prone due to the lack of proper supervision as in (b). Our proposed LHST introduces language hierarchy to expand the image-level labels and enables co-regularization between the expanded labels and self-training which allows producing more accurate pseudo box labels in (c).", "description": "This figure illustrates the limitations of using image-level labels for object detection.  It compares three approaches: (a) standard label-to-box assignment, which suffers from mismatch; (b) self-training, which generates inaccurate pseudo labels; and (c) the proposed LHST method, which uses language hierarchy to improve pseudo label accuracy.", "section": "1 Introduction"}, {"figure_path": "TNQ0hxh3O1/figures/figures_20_2.jpg", "caption": "Figure 4: Qualitative results of DetLH over zero-shot cross-dataset object detection for autonomous driving. Zoom in for details. Top: Detic [15]. Bottom: DetLH (Ours).", "description": "This figure shows a qualitative comparison of the object detection results obtained by Detic [15] and the proposed DetLH method on the autonomous driving dataset.  The top row displays results from Detic [15], while the bottom row showcases results from DetLH (Ours). Each column represents a different image from the dataset.  The images illustrate that DetLH improves upon Detic's performance, particularly in terms of object localization and accuracy. The details shown in the zoomed-in view highlight these improvements.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/figures/figures_20_3.jpg", "caption": "Figure 3: Qualitative results of DetLH over zero-shot cross-dataset object detection for common objects. Zoom in for details. Top: Detic [15]. Bottom: DetLH (Ours).", "description": "This figure shows qualitative results of DetLH and Detic [15] on common object detection datasets.  Each column represents a different image from a different dataset and shows the detection results using Detic [15] (top row) and DetLH (bottom row). The results demonstrate the performance of both methods on various common objects and challenging conditions, allowing for a visual comparison of their detection accuracy and localization ability.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/figures/figures_20_4.jpg", "caption": "Figure 4: Qualitative results of DetLH over zero-shot cross-dataset object detection for autonomous driving. Zoom in for details. Top: Detic [15]. Bottom: DetLH (Ours).", "description": "This figure shows a qualitative comparison of the object detection results of the proposed DetLH method and the Detic method on the autonomous driving dataset. The top row displays the results from the Detic method, while the bottom row displays the results from the DetLH method. Each column represents a different image from the dataset, and the results show the detected objects with bounding boxes and class labels. The comparison highlights the improved accuracy and robustness of the DetLH method in detecting objects in challenging autonomous driving scenarios.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/figures/figures_21_1.jpg", "caption": "Figure 7: Qualitative results of DetLH over zero-shot cross-dataset object detection for Wildlife Detection. Zoom in for details. Top: Detic [15]. Bottom: DetLH (Ours).", "description": "This figure shows qualitative comparisons of object detection results between Detic and the proposed DetLH method on the African Wildlife dataset.  Both methods are tested in a zero-shot cross-dataset setting. The top row displays Detic's detections, while the bottom row displays DetLH's detections.  The figure highlights the improved accuracy and robustness of DetLH, especially in accurately identifying and localizing wildlife objects within their respective bounding boxes.", "section": "4 Experiments"}]