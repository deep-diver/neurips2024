[{"figure_path": "TNQ0hxh3O1/tables/tables_5_1.jpg", "caption": "Table 1: Zero-shot cross-dataset object detection for common objects. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over target datasets (i.e., Object365 and Pascal VOC with objects from common classes and scenarios) without finetuning. \u201cDataset-specific oracles\u201d denote the detectors that are fully supervised which are trained by using the training data of respective datasets.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment.  Four different object detection methods (WSDDN, YOLO9000, DLWL, Detic) and the proposed method (DetLH) were evaluated on two target datasets (Object365 and Pascal VOC). The models were trained on the LVIS and ImageNet-21K datasets, and then tested on the target datasets without further fine-tuning.  A \u2018dataset-specific oracle\u2019 is included as a baseline representing the performance achievable if the model is trained specifically on the target dataset's data.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_6_1.jpg", "caption": "Table 2: Zero-shot cross-dataset object detection for autonomous driving. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over autonomous driving datasets (i.e., Cityscapes, Vistas and SODA10M) without finetuning.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment focusing on autonomous driving.  Four different object detection methods (WSDDN, YOLO9000, DLWL, Detic) and the proposed DetLH method were evaluated on three autonomous driving datasets: Cityscapes, Vistas, and SODA10M. The models were trained on the LVIS and ImageNet-21K datasets but not fine-tuned on the autonomous driving datasets.  The table shows the average precision (AP) and average precision at different Intersection over Union (IoU) thresholds (AP50 and AP75) for each method on each dataset, along with the average performance across all three datasets. Dataset-specific oracles (fully supervised detectors trained on each dataset) are included as a performance baseline.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_6_2.jpg", "caption": "Table 3: Zero-shot cross-dataset object detection under different weather and time-of-day conditions (using metric AP50). All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over BDD100K and DAWN datasets without finetuning.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment.  The experiment evaluates the performance of several object detectors under varying weather and time-of-day conditions.  The detectors were trained on the LVIS and ImageNet-21K datasets and tested on the BDD100K and DAWN datasets without any fine-tuning.  The AP50 metric is used to evaluate the performance.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_6_3.jpg", "caption": "Table 4: Zero-shot cross-dataset object detection for intelligent surveillance. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over surveillance datasets MIO-TCD, BAAI-VANJEE, DETRAC and UAVDT without finetuning.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment focusing on intelligent surveillance.  Four different surveillance datasets (MIO-TCD, BAAI-VANJEE, DETRAC, and UAVDT) were used to evaluate the performance of several object detection models (WSDDN, YOLO9000, DLWL, Detic, and the proposed DetLH).  The models were all trained on the same training datasets (LVIS and ImageNet-21K) without any fine-tuning on the test datasets, demonstrating their generalization abilities. The table shows the average precision (AP), AP at 50% IoU (AP50), and AP at 75% IoU (AP75) for each model across the four datasets.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_7_1.jpg", "caption": "Table 5: Zero-shot cross-dataset object detection for Wildlife Detection. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over wildlife datasets (i.e., Arthropod Detection, AfricanWildlife and Animals Detection) without finetuning.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment on three wildlife detection datasets: Arthropod Detection, African Wildlife, and Animals Detection.  The detectors were trained on a combination of LVIS and ImageNet-21K datasets but were not fine-tuned on the target wildlife datasets.  The table shows the average precision (AP), AP at 50% IoU (AP50), and AP at 75% IoU (AP75) for each method (WSDDN, YOLO9000, DLWL, Detic, and the proposed DetLH) and a dataset-specific oracle.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_7_2.jpg", "caption": "Table 6: Ablation studies of our DetLH with Language Hierarchical Self-training (LHST) and Language Hierarchical Prompt Generation (LHPG). The experiments are conducted with Swin-B based Center-Net2 [15] and the detectors are evaluated on Object365 in zero-shot cross-dataset object detection setup.", "description": "This table presents the ablation study results of the proposed DetLH model. It shows the impact of the two main components, LHST and LHPG, on the model's performance (AP50) using the Swin-B based Center-Net2 architecture.  The baseline uses only box-level supervision.  The results demonstrate that both LHST and LHPG contribute to improved performance, with the combination achieving the best AP50 score.", "section": "4.2 Ablation Studies"}, {"figure_path": "TNQ0hxh3O1/tables/tables_7_3.jpg", "caption": "Table 7: Zero-shot cross-dataset object detection on various datasets. Results are averaged on 14 widely studied datasets.", "description": "This table presents a comparison of the proposed DetLH method against existing state-of-the-art methods (WSDDN, YOLO9000, DLWL, and Detic) on 14 different object detection datasets. The results, averaged across these datasets, are reported in terms of Average Precision (AP) and its variants (AP50, AP75, APS, APm, and API).  The table showcases the superior generalization performance of DetLH across diverse datasets.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_8_1.jpg", "caption": "Table 8: Zero-shot cross-dataset object detection with different network architectures. All networks architectures are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over Object365 without finetuning.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment on the Object365 dataset.  The experiment evaluates the generalization performance of the DetLH model across four different network architectures: Swin-B, ConvNeXt-T, ResNet-50, and ResNet-18.  Each architecture was trained on the LVIS and ImageNet-21K datasets and then evaluated on Object365 without any fine-tuning. The table shows the average precision (AP) and its variations (AP50, AP75, APs, APm, APl) for each architecture and method.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_8_2.jpg", "caption": "Table 12: Parameter Studies for Language Hierarchical Self- training (LHST) on zero-shot transfer object detection over object365 dataset. We study the thresholding parameter t used in generating pseudo box labels in LHST.", "description": "This table shows the result of ablation study on the threshold parameter t used in generating pseudo box labels in LHST. The result shows that the detection performance is not sensitive to the threshold t.", "section": "4.2 Ablation Studies"}, {"figure_path": "TNQ0hxh3O1/tables/tables_16_1.jpg", "caption": "Table 10: Strategy studies for Language Hierarchical Self-training on zero-shot cross-dataset object detection over object365 dataset.", "description": "This table presents a comparison of different training strategies for Language Hierarchical Self-training (LHST).  It shows the AP50 (average precision at 50% IoU) achieved by different methods on the Object365 dataset using a zero-shot cross-dataset object detection setup. The methods compared include Detic [15] as a baseline, Self-training [21], Direct WordNet Hierarchy Labeling [21], a combination of Self-training and Direct WordNet Hierarchy Labeling, and the proposed Language Hierarchical Self-training (LHST). The results demonstrate the superior performance of LHST in this setting.", "section": "4.2 Ablation Studies"}, {"figure_path": "TNQ0hxh3O1/tables/tables_17_1.jpg", "caption": "Table 11: Ablation studies of Language Hierarchical Self-training. The experiment setup is zero-shot cross-dataset object detection over Object365 dataset.", "description": "This table presents the ablation study of the Language Hierarchical Self-training (LHST) method proposed in the paper. It shows the impact of using box-level LHST and image-level LHST on the performance of zero-shot cross-dataset object detection on the Object365 dataset. The results demonstrate that both box-level and image-level LHST contribute to improved performance, with the combined use of both yielding the best results.", "section": "4.2 Ablation Studies"}, {"figure_path": "TNQ0hxh3O1/tables/tables_17_2.jpg", "caption": "Table 12: Parameter Studies for Language Hierarchical Self- training (LHST) on zero-shot transfer object detection over object365 dataset. We study the thresholding parameter t used in generating pseudo box labels in LHST.", "description": "This table presents the ablation study on the threshold parameter *t* used in the Language Hierarchical Self-training (LHST) method.  The threshold *t* determines whether a prediction is filtered out based on its confidence score. The table shows the AP50 (average precision at 50% intersection over union) values for different threshold values, ranging from 0.65 to 0.85.  The results indicate that the model's performance is not highly sensitive to variations in this threshold parameter.", "section": "4.2 Ablation Studies"}, {"figure_path": "TNQ0hxh3O1/tables/tables_17_3.jpg", "caption": "Table 13: Analysis of discrepancies of the taxonomies of image vs. box categories.", "description": "This table shows the mismatch ratio between ImageNet-21K and other datasets for different object detection tasks. The mismatch ratio indicates the proportion of image-level labels that do not have corresponding box-level labels.  The table also provides the AP50 scores of the baseline method and the proposed DetLH method, demonstrating how the DetLH method improves performance as the mismatch ratio increases. The \u0394 column shows the improvement gained by DetLH over the baseline.", "section": "4.3 Discussion"}, {"figure_path": "TNQ0hxh3O1/tables/tables_17_4.jpg", "caption": "Table 14: How effective DetLH deals with noisy labels.", "description": "This table presents ablation study results comparing the performance of DetLH with and without reliability scores when dealing with noisy labels in the Object365 dataset.  The results demonstrate that incorporating reliability scores improves performance, suggesting that DetLH effectively handles noisy pseudo-labels generated during self-training.", "section": "4.2 Ablation Studies"}, {"figure_path": "TNQ0hxh3O1/tables/tables_18_1.jpg", "caption": "Table 15: The impact of using proxy vocabulary.", "description": "This table presents the ablation study results on using proxy vocabulary in LHPG. The results show that using proxy vocabulary significantly improves the performance compared to using only CLIP embeddings.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_18_2.jpg", "caption": "Table 16: Comparisons with other semi-supervised WSOD methods. ", "description": "This table compares the performance of the proposed DetLH method with other state-of-the-art semi-supervised weakly supervised object detection (WSOD) methods on the Object365 dataset using the AP50 metric.  The results show that DetLH outperforms the other methods, highlighting its effectiveness.", "section": "4.1 Comparison with the state-of-the-art"}, {"figure_path": "TNQ0hxh3O1/tables/tables_18_3.jpg", "caption": "Table 1: Zero-shot cross-dataset object detection for common objects. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over target datasets (i.e., Object365 and Pascal VOC with objects from common classes and scenarios) without finetuning. \u201cDataset-specific oracles\u201d denote the detectors that are fully supervised which are trained by using the training data of respective datasets.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment.  The experiment evaluated various object detection methods on two datasets, Object365 and Pascal VOC, using only data from LVIS and ImageNet-21K for training. The performance of each method is measured using Average Precision (AP) and its variants (AP50, AP75, APs, APm, APl).  A \"Dataset-specific oracle\" row provides a baseline representing the best possible performance achievable when training and testing on the same dataset.  This allows for a comparison of the generalizability of the tested models.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_19_1.jpg", "caption": "Table 1: Zero-shot cross-dataset object detection for common objects. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over target datasets (i.e., Object365 and Pascal VOC with objects from common classes and scenarios) without finetuning. \u201cDataset-specific oracles\u201d denote the detectors that are fully supervised which are trained by using the training data of respective datasets.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment.  Four different object detection methods (WSDDN, YOLO9000, DLWL, Detic) and the proposed method (DetLH) were evaluated on the Object365 and Pascal VOC datasets. The detectors were trained on the LVIS and ImageNet-21K datasets, but not fine-tuned on the target datasets.  A \"dataset-specific oracle\" result is also provided as a benchmark to compare performance against a fully supervised model trained on each target dataset.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_19_2.jpg", "caption": "Table 1: Zero-shot cross-dataset object detection for common objects. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over target datasets (i.e., Object365 and Pascal VOC with objects from common classes and scenarios) without finetuning. \u201cDataset-specific oracles\u201d denote the detectors that are fully supervised which are trained by using the training data of respective datasets.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment.  The experiment evaluated several different object detection models on the Object365 and Pascal VOC datasets.  All models were trained on the LVIS and ImageNet-21K datasets, but not fine-tuned on the target datasets (Object365 and Pascal VOC). The table shows the average precision (AP) scores for each model, along with a comparison to fully supervised models trained specifically for each target dataset (Dataset-specific oracles). This provides a measure of how well the models generalize to unseen datasets.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_19_3.jpg", "caption": "Table 1: Zero-shot cross-dataset object detection for common objects. All detectors are trained over the training datasets (LVIS and ImageNet-21K) and evaluated over target datasets (i.e., Object365 and Pascal VOC with objects from common classes and scenarios) without finetuning. \u201cDataset-specific oracles\u201d denote the detectors that are fully supervised which are trained by using the training data of respective datasets.", "description": "This table presents the results of a zero-shot cross-dataset object detection experiment.  Four different object detection methods (WSDDN, YOLO9000, DLWL, Detic) and the proposed method (DetLH) were evaluated on two target datasets (Object365 and Pascal VOC). The evaluation focused on common object classes found in both training and test sets. For comparison, results from fully supervised detectors trained only on the target dataset are also included.", "section": "4 Experiments"}, {"figure_path": "TNQ0hxh3O1/tables/tables_19_4.jpg", "caption": "Table 7: Zero-shot cross-dataset object detection on various datasets. Results are averaged on 14 widely studied datasets.", "description": "This table presents a comparison of the proposed DetLH method against several other state-of-the-art object detection methods on 14 benchmark datasets.  The results are averaged across the datasets for a comprehensive comparison of performance in terms of Average Precision (AP), AP50, AP75, APs (small object AP), APm (medium object AP), and APl (large object AP).", "section": "4.3 Discussion"}]