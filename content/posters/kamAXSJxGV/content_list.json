[{"type": "text", "text": "Prior-itizing Privacy: A Bayesian Approach to Setting the Privacy Budget in Differential Privacy ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zeki Kazan   \nDepartment of Statistical Science   \nDuke University   \nDurham, NC 27708   \nzekican.kazan@duke.edu   \nJerome P. Reiter   \nDepartment of Statistical Science   \nDuke University   \nDurham, NC 27708   \njreiter@duke.edu ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "When releasing outputs from confidential data, agencies need to balance the analytical usefulness of the released data with the obligation to protect data subjects\u2019 confidentiality. For releases satisfying differential privacy, this balance is reflected by the privacy budget, $\\varepsilon$ . We provide a framework for setting $\\varepsilon$ based on its relationship with Bayesian posterior probabilities of disclosure. The agency responsible for the data release decides how much posterior risk it is willing to accept at various levels of prior risk, which implies a unique $\\varepsilon$ . Agencies can evaluate different risk profiles to determine one that leads to an acceptable trade-off in risk and utility. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Differential privacy (DP) [11] is a gold standard definition of what it means for data curators, henceforth referred to as agencies, to protect individuals\u2019 confidentiality when releasing sensitive data. The confidentiality guarantee of DP is determined principally by a parameter typically referred to as the privacy budget $\\varepsilon$ . Smaller values of $\\varepsilon$ generally imply greater confidentiality protection at the cost of injecting more noise into the released data. Thus, agencies must choose $\\varepsilon$ to balance confidentiality protection with analytical usefulness. This balancing act has resulted in a wide range of values of $\\varepsilon$ in practice. For example, early advice in the field recommends $\\varepsilon$ of $^{\\bullet\\bullet}0.01$ , 0.1, or in some cases, $\\log(2)$ or $\\log(3)^{,}$ [10], whereas recent large-scale implementations use $\\varepsilon=8.6$ in OnTheMap [31], $\\varepsilon=14$ in Apple\u2019s use of local DP for iOS 10.1.1 [44], and an equivalent of $\\varepsilon=17.14$ in the 2020 decennial census redistricting data release [1]. ", "page_idx": 0}, {"type": "text", "text": "Some decision makers may find interpreting and selecting $\\varepsilon$ difficult [20, 24, 29, 36, 43]. For example, a recent study of practitioners using DP Creator [43] found that users wished for more explanation about how to select privacy parameters and better understanding of the effects of this choice. One potential path for providing guidance is to convert the task of selecting $\\varepsilon$ to setting bounds on the allowable probabilities of adversaries learning sensitive information from the released data, as in the classical disclosure limitation literature [8, 14, 41]. There is precedent for this approach: prior work in the literature suggests that \u201cprivacy semantics in terms of Bayesian inference can shed more light on a privacy definition than privacy semantics in terms of indistinguishable pairs of neighboring databases\u201d [28] and prevailing advice for setting $\\delta$ in $(\\varepsilon,\\delta)$ -DP originates from such Bayesian semantics [25]. ", "page_idx": 0}, {"type": "text", "text": "We propose that agencies utilize relationships between DP and Bayesian semantics [2, 11, 25, 26, 27, 28, 29, 33] to select values of $\\varepsilon$ that accord with their desired confidentiality guarantees. The basic idea is as follows. First, the agency constructs a function that summarizes the maximum posterior probability of disclosure permitted for any prior probability of disclosure. For example, for a prior risk of 0.001, the agency may be comfortable with a ten-fold (or more) increase in the ratio of posterior risk to prior risk, whereas for a prior risk of 0.4, the agency may require the increase not exceed, say, 1.2. Second, for each prior risk value, the agency converts the posterior-to-prior ratio into the largest $\\varepsilon$ that still ensures the ratio is satisfied. Third, the agency selects the smallest $\\varepsilon$ among these values, using that value for the data release. Importantly, the agency does not use the confidential data in these computations\u2014they are theoretical and data free\u2014so that they do not use up part of the overall privacy budget. Our main contributions include: ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "\u2022 We propose a framework for selecting $\\varepsilon$ under certain conditions (see Section 3) that applies to any DP mechanism, does not use additional privacy budget, and can account for disclosure risk from both an individual\u2019s inclusion and the sensitivity of values in the data.   \n\u2022 We enable agencies to tune the choice of $\\varepsilon$ to achieve their desired posterior-to-prior risk profile. This can avoid setting $\\varepsilon$ unnecessarily small if, for example, the agency tolerates larger posterior-to-prior ratios for certain prior risks. In turn, this can help agencies better manage trade-offs in disclosure risk and data utility.   \n\u2022 We give theoretic justification for the framework and derive closed-form solutions for the $\\varepsilon$ implied by several risk profiles. For more complex risk profiles, we also provide a general form for $\\varepsilon$ as a minimization problem. ", "page_idx": 1}, {"type": "text", "text": "To streamline the discussion, we focus on the release of discrete-valued statistics computed on discrete-valued data. Extension to continuous-valued statistics and data can be accomplished by replacing sums with integrals and PMFs with PDFs throughout the theorem statements and proofs. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Motivation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We first describe some aspects of DP and Bayesian probabilities of disclosure relevant for our approach. We summarize all notation and definitions in Tables 2 and 3 in Appendix A.1. ", "page_idx": 1}, {"type": "text", "text": "2.1 Differential Privacy ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Let $\\mathbf{P}$ represent a population of individuals. The agency has a subset of $\\mathbf{P}$ , which we call $\\mathbf{Y}$ , comprising $n$ individuals measured on $d$ variables. For any individual $i$ , let $Y_{i}$ be the length- $d$ vector of values corresponding to individual $i$ , and let $I_{i}=1$ when individual $i$ is in $\\mathbf{Y}$ and $I_{i}=0$ otherwise. For all $i$ such that $I_{i}=1$ , let $\\mathbf{Y}_{-i}$ be the $(n-1)\\times d$ matrix of values for the $n-1$ individuals in $\\mathbf{Y}$ excluding individual $i$ .1 The agency wishes to release some function of the data, $T(\\mathbf{Y})$ . We assume $\\mathbf{Y}$ and $T(\\mathbf{Y})$ each have discrete support but may be many-dimensional. The agency turns to DP and will release $T^{*}(\\mathbf{Y})$ , a noisy version of $T(\\mathbf{Y})$ under $\\varepsilon$ -DP. ", "page_idx": 1}, {"type": "text", "text": "Our work focuses on unbounded DP as defined in [9], which involves the removal or addition of one individual\u2019s information.2 If a function $T^{*}(\\mathbf{Y})$ with discrete support satisfies unbounded $\\varepsilon$ -DP, then for all $i$ , all $y$ in the support of $Y_{i}$ , all $\\mathbf{y}_{-i}$ in the support of $\\mathbf{Y}_{-i}$ , and all $t^{*}$ in the support of $T^{*}(\\mathbf{Y})$ , ", "page_idx": 1}, {"type": "equation", "text": "$$\ne^{-\\varepsilon}\\leq{\\frac{P[T^{*}(\\mathbf{Y})=t^{*}\\mid Y_{i}=y,I_{i}=1,\\mathbf{Y}_{-i}=\\mathbf{y}_{-i}]}{P[T^{*}(\\mathbf{Y}_{-i})=t^{*}\\mid I_{i}=0,\\mathbf{Y}_{-i}=\\mathbf{y}_{-i}]}}\\leq e^{\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "In settings where the statistic of interest is a count, a commonly used algorithm to satisfy DP is the geometric mechanism [18]. ", "page_idx": 1}, {"type": "text", "text": "Definition 1 (Geometric Mechanism). Let $T(\\mathbf{Y})\\,\\in\\,\\mathbb{Z}$ be a count statistic and suppose we wish to release a noisy count $T^{*}(\\mathbf{Y})\\in\\mathbb{Z}$ satisfying $\\varepsilon$ -DP. The geometric mechanism produces a count centered at $T(\\mathbf{Y})$ with noise from a two-sided geometric distribution with parameter $e^{-\\varepsilon}$ . That is, ", "page_idx": 1}, {"type": "equation", "text": "$$\nP[T^{*}(\\mathbf{Y})=t^{*}\\mid T(\\mathbf{Y})=t]={\\frac{1-e^{-\\varepsilon}}{1+e^{-\\varepsilon}}}e^{-\\varepsilon|t^{*}-t|},\\qquad t^{*}\\in\\mathbb{Z}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Under the geometric mechanism, the variance of $T^{*}(\\mathbf{Y})$ is $2e^{-\\varepsilon}/(1-e^{-\\varepsilon})^{2}$ . The variance increases as $\\varepsilon$ decreases, reflecting the potential loss in data usefulness when setting $\\varepsilon$ to a small value. ", "page_idx": 1}, {"type": "text", "text": "Of course, data usefulness is only one side of the coin. Agencies also need to assess the implications of the choice of $\\varepsilon$ for disclosure risks [7, 42, 43]. Prior works on setting $\\varepsilon$ focus on settings where (i) ", "page_idx": 1}, {"type": "text", "text": "the data have yet to be collected, and the goal is to simultaneously select $\\varepsilon$ and determine how much to compensate individuals for their loss in privacy [6, 15, 23, 30], (ii) the population is already public information, and the goal is to protect which subset of individuals is included in a release [29, 35], or (iii) data holders can utilize representative test data or the confidential data set itself [4, 17, 20, 35]. We focus on the common setting where data already have been collected, the population they are drawn from is not public information, and no data are available for tuning $\\varepsilon$ . ", "page_idx": 2}, {"type": "text", "text": "2.2 Bayesian Measures of Disclosure Risk ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Consider an adversary who desires to learn about some particular individual $i$ in $\\mathbf{Y}$ using the release of $T^{*}(\\mathbf{Y})$ . We suppose that the adversary has a model, $\\mathcal{M}$ , for making predictions about the components of $Y_{i}$ that they do not already know.3 For example, the adversary could know some demographic information about individual $i$ but not some other sensitive variable. The adversary might predict this sensitive variable from the demographic information using a model estimated with proprietary information or data from sources like administrative records. We assume that the release mechanism for $T^{*}(\\mathbf{Y})$ is known to the adversary, that the DP release mechanism does not depend on $\\mathcal{M}$ , and that, under $\\mathcal{M}$ , the observations are independent but not necessarily identically distributed. These conditions are formalized in Section 3. For our ultimate purpose, i.e., helping agencies set $\\varepsilon$ , the exact form of the adversary\u2019s $\\mathcal{M}$ is immaterial. In fact, as we shall discuss, we are not concerned whether the adversary\u2019s predictions from $\\mathcal{M}$ are highly accurate or completely awful. ", "page_idx": 2}, {"type": "text", "text": "On a technical note, we make the distinction that the agency views $\\mathbf{Y}$ and $I_{i}$ as fixed quantities, since it knows which rows are in the collected data and what values are associated to each row. The adversary, however, views $\\mathbf{Y}$ and $I_{i}$ as random variables, and thus probabilistic statements about these quantities are well defined from the adversary\u2019s perspective. Notationally, we signify that a probabilistic statement is from the adversary\u2019s perspective via the subscript $\\mathcal{M}$ . ", "page_idx": 2}, {"type": "text", "text": "Let $\\boldsymbol{S}$ be the subset of the support of $Y_{i}$ that the agency considers a privacy violation. For example, if $d=1$ and $\\mathbf{Y}$ is income data, then $\\boldsymbol{S}$ may be the set of possible incomes within 5,000 or within $5\\%$ of the true income for individual $i$ . Alternatively, if $d=1$ and $\\mathbf{Y}$ is binary, then $\\boldsymbol{S}$ is a subset of $\\{0,1\\}$ . The selection of $\\boldsymbol{S}$ must not depend on $\\mathbf{P}$ , as this might constitute a privacy violation. ", "page_idx": 2}, {"type": "text", "text": "The agency may be concerned about the risk that the adversary determines individual $i$ is in $\\mathbf{Y}$ or the risk that the adversary makes a disclosure for individual $i$ ; that is, $I_{i}=1$ and $Y_{i}\\in S$ , respectively. Assuming that the adversary\u2019s model puts nonzero probability mass on these events, we can express their relevant prior probabilities as follows. ", "page_idx": 2}, {"type": "equation", "text": "$$\nP_{\\mathcal{M}}[I_{i}=1]=p_{i},\\qquad P_{\\mathcal{M}}[Y_{i}\\in\\mathcal{S}\\ |\\ I_{i}=1]=q_{i}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "For fixed $p_{i}$ and $q_{i}$ , we can measure the risk of disclosure for individual $i$ in a number of ways. Drawing from [33], one measure is the relative disclosure risk, $r_{i}(p_{i},q_{i},t^{*})$ . Writing the noisy statistic as $T^{*}$ and suppressing the dependence on $\\mathbf{Y}$ or $\\mathbf{Y}_{-i}$ , this is defined as follows. ", "page_idx": 2}, {"type": "text", "text": "Definition 2 (Relative Disclosure Risk). For fixed data $\\mathbf{Y}$ , individual $i$ , adversary\u2019s model $\\mathcal{M}$ , and released $T^{*}=t^{*}$ , the relative disclosure risk is the posterior-to-prior risk ratio, ", "page_idx": 2}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})=\\frac{P_{M}[Y_{i}\\in\\mathcal{S},I_{i}=1\\mid T^{*}=t^{*}]}{P_{M}[Y_{i}\\in\\mathcal{S},I_{i}=1]}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The relative risk can be decomposed into the posterior-to-prior ratio from inclusion $(I_{i})$ and the posterior-to-prior ratio from the values $(Y_{i})$ . We have ", "page_idx": 2}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})=\\frac{P_{M}[Y_{i}\\in\\mathcal{S}\\mid I_{i}=1,T^{*}=t^{*}]}{P_{M}[Y_{i}\\in\\mathcal{S}\\mid I_{i}=1]}\\cdot\\frac{P_{M}[I_{i}=1\\mid T^{*}=t^{*}]}{P_{M}[I_{i}=1]}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The relative risk, however, does not tell the full story. As discussed in [22], the data holder also may care about absolute disclosure risks, $a_{i}(p_{i},q_{i},t^{*})$ . ", "page_idx": 2}, {"type": "text", "text": "Definition 3 (Absolute Disclosure Risk). For fixed data $\\mathbf{Y}$ , individual $i$ , adversary\u2019s model $\\mathcal{M}$ , and released $T^{*}=t^{*}$ , the absolute disclosure risk is the posterior probability, ", "page_idx": 2}, {"type": "equation", "text": "$$\na_{i}(p_{i},q_{i},t^{*})=P_{\\cal M}[Y_{i}\\in{\\cal S},I_{i}=1\\mid T^{*}=t^{*}].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Since $r_{i}(p_{i},q_{i},t^{*})=a_{i}(p_{i},q_{i},t^{*})/(p_{i}q_{i})$ , we can convert between these risk measures. ", "page_idx": 2}, {"type": "text", "text": "2.3 Risk Profiles ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The quantities from Section 2.2 can inform the choice of $\\varepsilon$ . For example, DP implies that ", "page_idx": 3}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\leq e^{2\\varepsilon}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "for all $(p_{i},q_{i},t^{*})$ . 4 The inequality in (7) implies a naive strategy for setting $\\varepsilon$ : select a desired bound on the relative risk, $r^{*}$ , and set $\\varepsilon=\\log(r^{*})/2$ . Practically, however, this strategy suffers from two drawbacks that could result in a smaller recommended $\\varepsilon$ than necessary. First, for any particular $p_{i}$ and $q_{i}$ , the bound in (7) need not be tight. In fact, this bound is actually quite loose across a wide range of values. Second, this strategy does not account for agencies willing to tolerate different relative risks for different prior probabilities. For example, if $p_{i}q_{i}=0.25$ , an agency may wish to limit the adversary\u2019s posterior to $a_{i}(p_{i},q_{i},t^{*})\\,\\leq\\,2\\times\\bar{0.25}=\\bar{0.5}$ , but for $p_{i}q_{i}\\,\\,{\\overline{{=}}}\\,\\,10^{-6}$ , the same agency may find a limit of $a_{i}(p_{i},q_{i},t^{*})\\leq2\\times10^{-6}$ unnecessarily restrictive. ", "page_idx": 3}, {"type": "text", "text": "Rather than restricting to a constant bound, the agency can consider tolerable relative risks as a function of a hypothetical adversary\u2019s prior probabilities. We refer to this function as the agency\u2019s risk proflie, denoted $r^{*}(p_{i},q_{i})$ . Thus, the agency establishes a $r^{*}(p_{i},q_{i})$ so that, for all $p_{i},q_{i}$ , and $t^{*}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\leq r^{*}(p_{i},q_{i}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As the following results show, the requirement in (8) translates to a maximum value of $\\varepsilon$ . ", "page_idx": 3}, {"type": "text", "text": "3 Theoretical Results ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we describe our main theoretical results. To devote more space to examples and applications, we describe supporting results in Appendix B.1 and provide all proofs in Appendix E. ", "page_idx": 3}, {"type": "text", "text": "We begin by formalizing the assumptions on the release mechanism for $T^{*}$ and the adversary\u2019s model, $\\mathcal{M}$ . We emphasize that $P[T^{*}(\\mathbf{Y})=t^{*}\\ |\\ Y_{i}=y,\\mathbf{Y}_{-i}=\\mathbf{y}_{-i},I_{i}=1]$ and $P[T^{*}(\\mathbf{Y}_{-i})\\,=\\,t^{*}\\ |$ ${\\bf Y}_{-i}={\\bf y}_{-i},I_{i}=0]$ are probabilities under the actual DP mechanism used for the release of $T^{*}(\\mathbf{Y})$ when $i$ is and is not included, respectively. We use these probabilities in two assumptions as follows. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1. For all y in the support of $Y_{i}$ , $\\mathbf{y}_{-i}$ in the support of $\\mathbf{Y}_{-i}$ , and $t^{*}$ in the support of $T^{*}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{M}[T^{*}(\\mathbf{Y})=t^{*}\\mid Y_{i}=y,\\mathbf{Y}_{-i}=\\mathbf{y}_{-i},I_{i}=1]=P[T^{*}(\\mathbf{Y})=t^{*}\\mid Y_{i}=y,\\mathbf{Y}_{-i}=\\mathbf{y}_{-i},I_{i}=1]}\\\\ &{\\qquad P_{M}[T^{*}(\\mathbf{Y}_{-i})=t^{*}\\mid\\mathbf{Y}_{-i}=\\mathbf{y}_{-i},I_{i}=0]=P[T^{*}(\\mathbf{Y}_{-i})=t^{*}\\mid\\mathbf{Y}_{-i}=\\mathbf{y}_{-i},I_{i}=0].}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Assumption 1 implies that the mechanism for releasing $T^{*}$ given $\\mathbf{Y}$ is known to the adversary and that the adversary uses the actual release mechanism. An adversary who uses something other than the actual release mechanism to compute probabilities is unlikely in general to find more success than the adversary who does. Hence, Assumption 1 assures that the agency\u2019s computations are principled and cover a type of \u201cworst-case\u201d analysis. ", "page_idx": 3}, {"type": "text", "text": "Assumption 2. For all $y$ in the support of $Y_{i}$ and $\\mathbf{y}_{-i}$ in the support of $\\mathbf{Y}_{-i}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\nP_{\\mathcal M}[{\\bf Y}_{-i}={\\bf y}_{-i}\\mid I_{i}=1,Y_{i}=y]=P_{\\mathcal M}[{\\bf Y}_{-i}={\\bf y}_{-i}\\mid I_{i}=0].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Assumption 2 implies that the adversary\u2019s beliefs about the distribution of $\\mathbf{Y}_{-i}$ do not change whether individual $i$ is included in the data or not, nor do they depend on individual $i$ \u2019s confidential values. This assumption is similar to one explored in [28], who consider the case where \u201cthe presence/absence/record-value of each individual is independent of the presence/absence/recordvalues of other individuals,\u201d although we do not require that (9) holds for all $i$ . Since DP is designed to capture the effect that a single atomic unit of data has on the output distribution, assuming this type of independence structure ensures one atomic unit is a single data point.5 We believe these two assumptions are weaker than those in related work on choosing $\\varepsilon$ , which we discuss in Section 6. ", "page_idx": 3}, {"type": "text", "text": "Under Assumption 1 and Assumption 2, we can relate $\\varepsilon$ to the distribution of $T^{*}$ unconditional on $\\mathbf{Y}_{-i}$ via the following lemma. This result is similar, but not identical to, Theorem 6.1 in [28]. ", "page_idx": 3}, {"type": "text", "text": "Lemma 1. Under Assumption $^{\\,I}$ and Assumption 2, if the release of $T^{*}=t^{*}$ satisfies $\\varepsilon$ -DP, then for any subset $\\boldsymbol{S}$ of the domain of $Y_{i}$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\ne^{-\\varepsilon}\\leq{\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in S,I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}}\\leq e^{\\varepsilon},\\qquad e^{-2\\varepsilon}\\leq{\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in S,I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\notin S,I_{i}=1]}}\\leq e^{2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We emphasize that Lemma 1 and all subsequent results require Assumption 2. Without it, generalizable knowledge from the release can lead to arbitrarily large relative risk, as demonstrated by examples in [25, 27]. ", "page_idx": 4}, {"type": "text", "text": "For a given function $r^{*}$ selected by the data holder, we can determine the $\\varepsilon$ that should be used for the release. This is due to the following result relating the relative risk to $\\varepsilon$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 1. Under Assumption $^{\\,l}$ and Assumption 2, if the release of $T^{*}=t^{*}$ satisfies $\\varepsilon$ -DP, then ", "page_idx": 4}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\leq\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i})p_{i}+e^{-\\varepsilon}(1-p_{i})}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "One can solve for $e^{-\\varepsilon}$ in (11) to determine the recommended $\\varepsilon$ , which is given by Theorem 2. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2. For any individual $i$ , fix the prior probabilities, $p_{i}$ and $q_{i}$ , and a desired bound on the relative disclosure risk, $r^{*}(p_{i},q_{i})$ . Define $\\varepsilon_{i}(p_{i},q_{i})$ to be the function ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon_{i}(p_{i},q_{i})=\\left\\{\\!\\!\\begin{array}{l l}{\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{*}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right),}&{i f0<q_{i}<1;}\\\\ {\\log\\left(\\frac{1-p_{i}}{\\frac{1}{r^{*}(p_{i},1)}-p_{i}}\\right),}&{i f q_{i}=1.}\\end{array}\\ \\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Under the conditions of Theorem $^{\\,l}$ , any statistic $T^{*}=t^{*}$ released under $\\varepsilon$ -DP with $\\varepsilon\\leq\\varepsilon_{i}(p_{i},q_{i})$ will satisfy $r_{i}(p_{i},q_{i},t^{*})\\leq r^{*}(p_{i},q_{i})$ . ", "page_idx": 4}, {"type": "text", "text": "By Theorem 2, to achieve $r_{i}(p_{i},q_{i},t^{*})\\leq r^{*}(p_{i},q_{i})$ for all $(p_{i},q_{i})$ , the agency should set $\\varepsilon$ via the following minimization problem: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\varepsilon=\\operatorname*{min}_{p_{i},q_{i}\\in(0,1]}\\varepsilon_{i}(p_{i},q_{i}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Closed forms for the $\\varepsilon$ resulting from a few specific risk profiles are included in the appendix. ", "page_idx": 4}, {"type": "text", "text": "4 Using Posterior-to-prior Risks for Setting $\\varepsilon$ ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we illustrate how an agency can use the results of Section 3 to select $\\varepsilon$ . Notationally, for a given quantity $x$ , we use $\\tilde{x}$ to indicate the agency has fixed $x$ to a particular constant. ", "page_idx": 4}, {"type": "text", "text": "Given $\\boldsymbol{S}$ , the agency must select a form for $r^{*}(p_{i},q_{i})$ . A default choice, equivalent to the naive strategy using (7) discussed above, is to set the bound to a constant $\\tilde{r}>1$ , i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\tilde{r}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As we prove in Theorem 3 in the appendix, the bound in (14) implies the agency should set $\\varepsilon=$ $\\log(\\tilde{r})/2$ . While a constant bound on relative risk is simple, agencies that tolerate different risk profiles may be able to set $\\varepsilon$ to larger values, as we now illustrate. ", "page_idx": 4}, {"type": "text", "text": "Consider an agency that seeks to bound the relative risks for high prior probabilities and bound the absolute disclosure risk for low prior probabilities. For example, the agency may not want adversaries whose prior probabilities are low to use $t^{*}$ to increase those probabilities beyond 0.10. Simultaneously, the agency may want to ensure adversaries with prior probabilities around, for example, 0.20 cannot use $t^{*}$ to triple their posterior probability. Such an agency can specify a risk profile that requires either the relative risk be less than some $\\tilde{r}>1$ or the absolute risk be less than some $\\tilde{a}<1$ , as we now illustrate via the following two examples. ", "page_idx": 4}, {"type": "text", "text": "The first example is a setting inspired by a case study in [13]. ", "page_idx": 4}, {"type": "image", "img_path": "kamAXSJxGV/tmp/5981f505234a47eff5fae20cfe6c6b9af3ded2ff491fe174403afda1d53f0c11.jpg", "img_caption": ["Figure 1: Each column corresponds to a particular hypothetical agency. The first row presents the agency\u2019s risk profile and the second row presents the profile\u2019s implied maximal allowable $\\varepsilon$ at each point on the curve. Agency 1\u2019s risk profile is given by (15) with $\\tilde{a}=0.1$ , $\\tilde{q}=1$ , and $\\tilde{r}=3$ , while Agency 2\u2019s risk proflie is given by (16) with $\\tilde{a}=0.1$ , $\\tilde{p}=0.05$ , and $\\tilde{r}=3$ . For Agency 2, $r^{*}$ and $\\varepsilon_{i}$ are very large for small $q_{i}$ ; large values are truncated for readability. "], "img_footnote": [], "page_idx": 5}, {"type": "table", "img_path": "kamAXSJxGV/tmp/1bf7a63f89df8f97f9248291dc739a78dbc4fc3f141876228a55d483ceae892b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Table 1: The $\\varepsilon$ recommended by our framework for three risk profiles of the form in (15). Also included are the standard deviations of the noise distribution and the probabilities that the exact value is released, i.e., the mass at zero, for geometric mechanisms that satisfy the corresponding $\\varepsilon$ -DP. ", "page_idx": 5}, {"type": "text", "text": "Example 1. A healthcare provider possesses a data set comprising demographic information about individuals diagnosed with a particular form of cancer in a region of interest. They plan to release the count of individuals diagnosed with this form of cancer in various demographic groups via the geometric mechanism, but are concerned this release, if insufficient noise is added, could reveal which individuals in the community have cancer. They wish to choose \u03b5 appropriately. ", "page_idx": 5}, {"type": "text", "text": "In this example, the primary concern is with respect to inclusion in the data set. That is, for a given individual $i$ , the adversary\u2019s prior probability $p_{i}$ is the key quantity, whereas the $q_{i}$ is not as important for any given $\\boldsymbol{S}$ . The agency can fix some $\\tilde{q}\\in(0,1]$ , for example $\\tilde{q}=1$ to focus on adversaries who already know individual $i$ \u2019s demographic information. To simplify the analysis, we set the risk proflie to $\\infty$ for adversaries with $\\tilde{q}\\neq1$ , which indicates these adversaries are not considered. A reasonable risk profile for this agency then might be of the form, for some $\\tilde{r}>1$ and $\\tilde{a}<1$ ,6 ", "page_idx": 5}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\left\\{\\!\\!\\operatorname*{max}\\left\\{\\!\\frac{\\tilde{a}}{p_{i}\\tilde{q}},\\tilde{r}\\right\\}\\!\\right\\},\\quad\\mathrm{if~}q_{i}=\\tilde{q};}\\\\ {\\infty,\\quad\\mathrm{if~}q_{i}\\neq\\tilde{q}.}\\end{array}\\right.\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!r^{*}(p_{i},q_{i})=\\left\\{\\begin{array}{l l}{\\frac{\\tilde{a}}{p_{i}\\tilde{q}},}&{\\mathrm{~if~}q_{i}=\\tilde{q}\\mathrm{~and~}0<p_{i}<\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}};}\\\\ {\\tilde{r},}&{\\mathrm{~if~}q_{i}=\\tilde{q}\\mathrm{~and~}\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}}\\leq p_{i}\\leq1;}\\\\ {\\infty,}&{\\mathrm{~if~}q_{i}\\neq\\tilde{q}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "An example visualization of this risk function is presented in the first column of Figure 1. The upper plot displays the risk proflie as a function of $p_{i}$ when $q_{i}=\\tilde{q}$ , and the lower plot displays the maximal $\\varepsilon$ for which the relative risk bound holds for each $p_{i}$ . We can derive a closed form for $\\varepsilon$ under this risk proflie; see Table 4 in Appendix A.2 for a summary and Theorem 5 in Appendix B.1 for details. ", "page_idx": 5}, {"type": "text", "text": "Suppose the agency is generally willing to accept a maximum absolute disclosure risk of $\\tilde{a}=0.25$ for adversaries with small prior probabilities. Table 1 presents the maximal $\\varepsilon$ which satisfies the desired risk proflie for three such agencies. Agency A is risk averse, agency C is utility seeking, and agency ", "page_idx": 5}, {"type": "text", "text": "B sits in between in terms of risk and utility. For adversaries with high prior probabilities, agencies A, B, and C bound the relative disclosure risk at $\\tilde{r}=1.5$ , $\\tilde{r}=3$ , and $\\tilde{r}=6$ , respectively. Figure 3 in Appendix C.1 plots the forms of each agency\u2019s risk profile. To provide intuition on the amount of noise implied by these $\\varepsilon$ , in Table 1 we display the standard deviation of the noise distribution for each statistic under the geometric mechanism and the probability that the geometric mechanism will output the exact value of each statistic. The risk averse agency is recommended an $\\varepsilon$ that results in a release with a high standard deviation and fairly low probability of releasing the exact value of the statistic. The utility seeking agency is recommended an $\\varepsilon$ that results in a release with a fairly low standard deviation and high probability of releasing the exact value of the statistic. ", "page_idx": 6}, {"type": "text", "text": "The recommendations from these risk proflies, which are tailored to the setting and agency preferences, are higher than the recommendations from a corresponding simple risk profile of $\\bar{r}^{*}(\\bar{p_{i}},\\bar{q_{i}})=\\tilde{r}$ for all prior probabilities. This simple profile yields $\\varepsilon\\approx0.20$ , $\\varepsilon\\approx0.55$ , and $\\varepsilon\\approx0.90$ for $\\tilde{r}=1.5$ , $\\tilde{r}=3$ , and $\\tilde{r}=6$ , respectively, less than half the corresponding $\\varepsilon$ values in Table 1. ", "page_idx": 6}, {"type": "text", "text": "We now consider a second example, inspired by Example 16 in [45], that alters Example 1. ", "page_idx": 6}, {"type": "text", "text": "Example 2. A survey is performed on a sample of individuals in the region of interest. $5\\%$ of the region is surveyed, and respondents are asked whether they have this particular form of cancer along with a series of demographic questions. The agency plans to release the counts of surveyed individuals who have and do not have the cancer in various demographic groups via the geometric mechanism, but is concerned this release, if insufficient noise is added, could reveal which individuals in the community have cancer. The agency wishes to choose \u03b5 appropriately. ", "page_idx": 6}, {"type": "text", "text": "In this example, the primary concern is with respect to the values in the data set. For ease of notation, let $Y_{i}$ be a $d$ -vector of binary values, and let the first element, $Y_{1i}$ , be an indicator for whether individual $i$ has this form of cancer. Set $\\boldsymbol{S}$ to be the subset of the support of $Y_{i}$ for which individual $i$ has the cancer, i.e., ${\\cal S}=\\{y\\in\\{0,1\\}^{d}:y_{1}=1\\}$ . For individual $i$ , the adversary\u2019s $q_{i}$ is the key quantity, and their $p_{i}$ is not of interest. The agency can fix some $\\tilde{p}\\,\\in\\,(0,1]$ ; for example, if the agency is most concerned about adversaries whose only prior knowledge is that individual $i$ is in the population, but not whether they were surveyed, they might set $\\tilde{p}=0.05$ . Alternatively, they might set $\\tilde{p}=1$ to imply an adversary that knows a priori that individual $i$ is included in $\\mathbf{Y}$ . A reasonable risk profile for this agency might be of the form, for some $\\tilde{a}<1$ and $\\tilde{r}>1$ , 7 ", "page_idx": 6}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\left\\{\\!\\!\\!\\begin{array}{l l}{\\operatorname*{max}\\left\\{\\!\\frac{\\tilde{a}}{\\tilde{p}q_{i}},\\tilde{r}\\right\\},}&{\\mathrm{if~}p_{i}=\\tilde{p};}\\\\ {\\infty,}&{\\mathrm{if~}p_{i}\\neq\\tilde{p}.}\\end{array}\\!\\!\\right.\\mathrm{~if~}p_{i}=\\tilde{p};\\mathrm{and~}\\frac{\\tilde{a}}{\\tilde{p}\\tilde{r}}\\leq q_{i}\\leq\\frac{\\tilde{a}}{1};\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "An example visualization of this risk function is presented in the second column of Figure 1. The upper plot displays the risk profile as a function of $q_{i}$ when $p_{i}=\\tilde{p}$ , and the lower plot displays the maximal $\\varepsilon$ for which the relative risk bound holds for each $p_{i}$ . The agency can select the smallest $\\varepsilon$ on this curve for their release. We can derive a closed form the minimum; see Table 4 in Appendix A.2 for a summary and Theorem 4 in Appendix B.1 for details. Notably, it can be shown that the $\\varepsilon$ selected under these two proflies is bounded below by $\\log(\\tilde{r})/2$ and may be much larger. We provide further exploration and visualizations for this example in Appendix C.2. ", "page_idx": 6}, {"type": "text", "text": "As demonstrated by these examples, the gap between the baseline strategy of (14) and our recommendation can be large. To further illustrate, suppose an agency has a simple, \u201cpoint\u201d risk proflie, where $r^{*}(0.5,1)=r^{\\prime}$ for $r^{\\prime}<2$ (and $\\infty$ elsewhere). The baseline recommends $\\varepsilon=\\log\\left(\\bar{r^{\\prime}}\\right)/2<0.35$ , while the recommendation from Theorem 2 can be shown to have the form $\\varepsilon=\\log\\left(r^{\\prime}/\\left(2-r^{\\prime}\\right)\\right)$ , which diverges as $r^{\\prime}\\rightarrow2$ . Thus, the gap between the recommendations can be arbitrarily large. While this likely does not represent a realistic disclosure risk proflie of a real-world agency, it is instructive. In general, the baseline\u2019s recommendation is smaller because it is enforcing a relative risk of $r^{\\prime}$ for adversaries with small priors. If $r^{\\prime}<2\\$ , then an adversary with prior probability $p_{i}q_{i}=0.001$ is restricted to a posterior probability at most 0.002, leading to a small $\\varepsilon$ recommendation. If adversaries with small priors are ignored or allowed to have large relative risks, the recommendation from our method will outperform the baseline, and possibly by a substantial amount. ", "page_idx": 6}, {"type": "text", "text": "A particular agency\u2019s risk proflie may not be characterized by one of the forms described above. For example, an agency may be equally concerned about $p_{i}$ and $q_{i}$ , rather than focusing on one; see ", "page_idx": 6}, {"type": "text", "text": "Appendix C.3 for an example of this setting. Or, as argued in [32], in some settings, agencies might be most concerned about the difference between the posterior and prior probabilities (rather than their ratio).8 In such settings, it is straightforward to write down the corresponding risk function, $r^{*}(p_{i},q_{i})$ , and the optimal $\\varepsilon$ can be determined by numerically solving the minimization problem in (13).9 ", "page_idx": 7}, {"type": "text", "text": "Regardless of the agency\u2019s desiderata for a risk profile, we recommend that they keep the following in mind when setting its functional form. First, for any region where $r^{*}(p_{i},\\dot{q}_{i})\\,\\stackrel{!}{>}\\,1/(p_{i}q_{i})$ , the risk profile generates a bound on the posterior probability that exceeds 1. Of course, the posterior probabilities themselves cannot exceed 1; thus, in these regions, the risk profile effectively does not bound the posterior risk. For example, an agency that sets $r^{*}(p_{i},1)=3$ in the region where $p_{i}\\geq1/3$ (as in the left column of Figure 1) implicitly is willing to accept an unbounded $\\varepsilon$ for prior probabilities $p_{i}\\,\\geq\\,1/3$ . Second, when bounding the absolute disclosure risk below some $\\tilde{a}$ in some region of $(p_{i},q_{i})$ , the agency should require $p_{i}q_{i}<\\tilde{a}$ in that region. When $p_{i}q_{i}=\\tilde{a}$ , the recommended $\\varepsilon=0$ since the data holder requires $T^{*}$ to offer no information about $Y_{i}$ . This also suggests that an agency bounding absolute disclosure risk in a region of $(p_{i},q_{i})$ that sets $\\tilde{a}$ close to some value of $p_{i}q_{i}$ in the region is willing to accept only small $\\varepsilon$ values. ", "page_idx": 7}, {"type": "text", "text": "5 Managing the Trade-off in Privacy and Utility ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Agencies can use the framework to manage trade-offs in disclosure risk and data utility. In particular, the agency can evaluate potential impacts of the DP algorithm using data quality metrics under different risk proflies, choosing an $\\varepsilon$ that leads to a satisfactory trade-off. We demonstrate this in the below example, using data on infant mortality in Durham county, N.C. We note that these data may not require the use of DP in reality, but they do allow us to illustrate the process with public data. ", "page_idx": 7}, {"type": "text", "text": "Example 3. Suppose that an agency in Durham county, N.C., wishes to release a differentially private version of the number of infant deaths the county experienced in the year 2020. The agency plans to use the geometric mechanism to release this value. Of particular interest is whether the county infant death rate meets the U. S. Department of Health and Human Services\u2019 Healthy People 2020 target of 6.0 or fewer deaths per 1,000 live births [21]. The agency wishes to minimize the probability that they release a noisy count that changes whether or not the 6.0 target is met; their goal is to ensure this probability is below $I O\\%$ . It is public information that there were 4,012 live births in Durham county in 2020 [38]. ", "page_idx": 7}, {"type": "text", "text": "The primary concern in Example 3 is with respect to inclusion in the data. Thus, the agency focuses on adversaries with $q_{i}=1$ and varying $p_{i}$ . The agency is generally willing to incur large relative risks if $p_{i}$ is small and small relative risks if $p_{i}$ is large. Furthermore, due to possible policy ramifications of appearing not to meet the target rate, the agency is open to accepting greater privacy risks for greater accuracy in the released count, within reason as determined by agency decision makers. ", "page_idx": 7}, {"type": "text", "text": "The agency\u2019s privacy experts determine that they can characterize the agency\u2019s risk proflies reasonably well using the following general class of risk profiles. ", "page_idx": 7}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\left\\{\\!\\!\\!\\begin{array}{l l}{\\operatorname*{max}\\left\\{\\frac{\\tilde{a}}{p_{i}},\\tilde{r}\\right\\},}&{\\mathrm{if~}q_{i}=1;}\\\\ {\\infty,}&{\\mathrm{if~}q_{i}\\neq1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "To allow for consideration of the effects on accuracy of different specifications of (17), the agency considers combinations of $\\tilde{r}\\in\\{1.2,2,5\\}$ and $\\tilde{a}\\in\\{0.1,0.25,0.5\\}$ . They also examine $\\tilde{a}=0$ , which corresponds to a constant risk proflie $r^{*}(p_{i},q_{i})=\\dot{\\tilde{r}}$ . The agency could consider other combinations of parameters or risk proflies classes should these not lead to a satisfactory trade-off in risk and utility. ", "page_idx": 7}, {"type": "text", "text": "Figure 2 summarizes an analysis of the risk/utility trade-offs. For all $\\tilde{r}$ , the recommended $\\varepsilon$ is larger when $\\tilde{a}~>~0$ than under the corresponding constant risk profile. Similar increases in $\\varepsilon$ also are evident for the risk proflies of Section 4; see Appendix C. Naturally, increases in $\\tilde{r}$ and $\\tilde{a}$ decrease the $\\mathrm{RMSEs^{10}}$ of the noisy counts due to larger $\\varepsilon$ . The switching probabilities in the top panel do not use ", "page_idx": 7}, {"type": "image", "img_path": "kamAXSJxGV/tmp/381e0c4f16560636c6534e82f5694cccea2f8c0be24c3bcd64defabc6106fc2d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 2: The top panel presents the probability that the differentially private algorithm switches whether Durham county\u2019s released rate is above or below the 6.0 target\u2014e.g., the added noise makes the released rate 6.5 but the actual rate is 5.5. Each color represents a different hypothetical absolute difference between the true and target rate. The middle panel presents RMSEs of the noisy count of infant deaths. The bottom panel presents the implied $\\varepsilon$ . Each bar corresponds to a different risk profile of the form in (17). ", "page_idx": 8}, {"type": "text", "text": "the true count of infant deaths; rather, they consider hypothetical deviations of 0.25, 0.5, 1, and 2 in the true rate from the target rate of 6.0. In this way, the agency avoids additional privacy leakage. The probability differs substantially for each of the four deviations, with the deviation of 0.25 leading to the largest probability of a switch. To ensure the probability is below $10\\%$ for the deviation of 0.25, the agency would need to use the most aggressive of the risk profiles, which allows absolute disclosure risk of $\\tilde{a}=0.5$ or relative disclosure risk of $\\tilde{r}=5$ . This leads to $\\varepsilon\\approx2.20$ with RMSE $\\approx0.53$ . If they are willing to allow the probability to exceed $10\\%$ or to place priority on deviations exceeding 0.25, the agency could select a less aggressive risk profile that yields a smaller $\\varepsilon$ . ", "page_idx": 8}, {"type": "text", "text": "In actuality, there were 6.2 infant deaths per 1,000 live births in Durham County in 2020 [37]. As the truth is close to the 6.0 target, the agency would need to use a large $\\varepsilon$ to achieve their goal. ", "page_idx": 8}, {"type": "text", "text": "6 Relationship to Prior Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The most similar work we are aware of is Lee and Clifton [29]\u2019s \u201cHow Much is Enough? Choosing $\\varepsilon$ for Differential Privacy,\u201d which also uses a Bayesian approach to set $\\varepsilon$ . The authors focus on settings where the population is public information and the adversary\u2019s goal is to determine which subset of individuals in the population was used for a differentially private release of a statistic. Their method for selecting $\\varepsilon$ is tailored to the setting where only disclosure of an individual\u2019s inclusion in the data is of concern and the values of the entire population can be used to inform the choice of $\\varepsilon$ . [29] focuses on the setting where the Laplace mechanism is used and the population size is known; their proposal was extended to any DP mechanism by [24, 39] and settings where the population size is unknown by [34]. In Appendix D.1, we compare the recommended $\\varepsilon$ from the proposal in [29] and our framework in several examples. We find that the approach of [29], for particular statistics and populations, can recommend a larger $\\varepsilon$ than the one resulting from our approach. However, our framework may be used in settings where the values of the entire population are not public and settings where the privacy of the values in the release is of primary concern. ", "page_idx": 8}, {"type": "text", "text": "Another series of related work involves using Bayesian semantics to communicate the meaning of $\\varepsilon$ to potential study participants. For an overview of recent work in this area, see [16], [36], and citations therein. We highlight an example in [45] (corrected in [46]), which considers an individual deciding whether or not to participate in a survey for which results will be released via DP with a particular $\\varepsilon$ . The authors suggest that the individual consider a bound on a posterior-to-posterior ratio similar to the bound in (11) to make an informed decision about whether to participate in the survey. We describe the advice of [45] using our notation in Appendix D.2. While their and our bounds have similar expressions, the goal in [45] differs from ours. They use the bound to characterize the individual\u2019s disclosure risks for a fixed $\\varepsilon$ , whereas we establish the agency\u2019s disclosure risk proflie in order to set $\\varepsilon$ . ", "page_idx": 9}, {"type": "text", "text": "There are a number of other works that examine Bayesian semantics of $\\varepsilon$ -DP, which we now briefly summarize. In their seminal work proposing DP, [11] showed that, under some conditions, bounded DP is equivalent to a bound on the relative risk when all but one data point is fixed. [25] showed that bounded DP implies a bound on the total variation distance between the posterior distribution with all data points included and the posterior distribution with one data point removed. [28] showed that both bounded and unbounded DP are equivalent to a bound on the posterior-to-prior odds ratio exactly when the presence/absence/record-value of each individual is independent of that of other individuals. Finally, [27] showed that both bounded and unbounded DP imply bounds on the ratio of the posterior distribution with all data points included to the posterior with one observation replaced with a draw from the posterior with their observation removed. These works do not discuss how these semantic characterizations of DP can be used to select $\\varepsilon$ . ", "page_idx": 9}, {"type": "text", "text": "7 Commentary ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this article, we propose a framework for selecting $\\varepsilon$ for DP by establishing disclosure risk proflies. Essentially, we provide a method for agencies to trade the problem of selecting $\\varepsilon$ for a release for the problem of specifying their desired disclosure risk profile. This process involves focusing on particular classes of adversaries the agency is most concerned about\u2014represented by the set $S.$ \u2014and tuning $\\varepsilon$ to ensure the risk from these adversaries is sufficiently low. We emphasize that, once applied, DP will protect against all attacks with the guarantee of DP, not just the attack used to tune $\\varepsilon$ . ", "page_idx": 9}, {"type": "text", "text": "We primarily focus on the risk from one class of adversary attacks on one individual, assuming all individuals are exchangeable. If agencies assign different risk profiles for different classes of adversaries, they could repeat the analysis for each class For example, the agency might assign different risk proflies to adversaries targeting different characteristics, e.g., they may consider whether an individual has a disease more sensitive than their age. Similarly, if an agency does not treat individuals in the data as exchangeable\u2014for example, if an agency seeks to ensure lesser disclosure risks for groups with some characteristics than for not-necessarily-disjoint groups without those characteristics \u2014the agency could repeat this analysis for each group. In both of these settings, the agency has a decision problem on its hands. As with designing DP solutions in general, the agency must prioritize some risks over others, e.g., using decision-theoretic criteria. This is an important topic for future work and raises ethical questions regarding how assigning different risk profiles for individuals with different characteristics could affect data equity. ", "page_idx": 9}, {"type": "text", "text": "One avenue for future work involves incorporating a version of this framework into differentially private data analysis tools. Recently developed interfaces for DP data releases such as [24] and [35] use the framework of [29] to guide users in setting $\\varepsilon$ . Our framework could be similarly incorporated to provide guidance in settings that do not satisfy the assumption of [29] that the values of the population are public. Another avenue for future work involves examining how an agency can set the risk profile appropriate for a particular release. We envision agencies could do so analogously to the elicitation of utility functions in decision theory, e.g., by considering a series of bets [40]. Other future extensions involve examining whether similar results follow under weaker assumptions. This includes settings with multiple differentially private releases via existing results that relate the relative risk to DP composition theorems (e.g., S5 of [26]). This also includes extension to variants of DP\u2014such as zero-concentrated DP [5] or approximate DP [12]\u2014by deriving Bayesian semantics analogous to Theorem 1 or leveraging existing results [25, 27]. Additionally, it may be possible to extend the results in this article from posterior-to-prior risks to the sorts of posterior-to-posterior risks discussed in Section 6. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This research was supported by NSF grant SES-2217456. We would like to thank the anonymous reviewers for their helpful feedback as well as Salil Vadhan and J\u00f6rg Drechsler for insightful discussion about a preliminary version of this work. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] John M Abowd, Robert Ashmead, Ryan Cumings-Menon, Simson Garfinkel, Micah Heineck, Christine Heiss, Robert Johns, Daniel Kifer, Philip Leclerc, Ashwin Machanavajjhala, et al. The 2020 census disclosure avoidance system topdown algorithm. arXiv preprint arXiv:2204.08986, 2022.   \n[2] John M Abowd and Lars Vilhuber. How protective are synthetic data? In International Conference on Privacy in Statistical Databases, pages 239\u2013246. Springer, 2008.   \n[3] Borja Balle, Gilles Barthe, and Marco Gaboardi. Privacy amplification by subsampling: Tight analyses via couplings and divergences. Advances in Neural Information Processing Systems, 31, 2018.   \n[4] Mihai Budiu, Pratiksha Thaker, Parikshit Gopalan, Udi Wieder, and Matei Zaharia. Overlook: Differentially private exploratory visualization for big data. Journal of Privacy and Confidentiality, 12(1), 2022.   \n[5] Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. In Theory of Cryptography Conference, pages 635\u2013658. Springer, 2016.   \n[6] Pranav Dandekar, Nadia Fawaz, and Stratis Ioannidis. Privacy auctions for recommender systems. ACM Transactions on Economics and Computation (TEAC), 2(3):1\u201322, 2014.   \n[7] J\u00f6rg Drechsler. Differential privacy for government agencies\u2014are we there yet? Journal of the American Statistical Association, 118(541):761\u2013773, 2023.   \n[8] George T Duncan and Diane Lambert. Disclosure-limited data dissemination. Journal of the American Statistical Association, 81(393):10\u201318, 1986.   \n[9] Cynthia Dwork. Differential privacy. In International colloquium on automata, languages, and programming, pages 1\u201312. Springer, 2006.   \n[10] Cynthia Dwork. A firm foundation for private data analysis. Communications of the ACM, 54(1):86\u201395, 2011.   \n[11] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In Theory of Cryptography Conference, pages 265\u2013284. Springer, 2006.   \n[12] Cynthia Dwork, Guy N Rothblum, and Salil Vadhan. Boosting and differential privacy. In 2010 IEEE 51st annual symposium on foundations of computer science, pages 51\u201360. IEEE, 2010.   \n[13] Amalie Dyda, Michael Purcell, Stephanie Curtis, Emma Field, Priyanka Pillai, Kieran Ricardo, Haotian Weng, Jessica C Moore, Michael Hewett, Graham Williams, et al. Differential privacy for public health data: An innovative tool to optimize information sharing while protecting data confidentiality. Patterns, 2(12):100366, 2021.   \n[14] Stephen E Fienberg and Ashish P Sanil. A Bayesian approach to data disclosure: Optimal intruder behavior for continuous data. Journal of Official Statistics, 13(1):75, 1997.   \n[15] Lisa K Fleischer and Yu-Han Lyu. Approximately optimal auctions for selling privacy when costs are correlated with data. In Proceedings of the 13th ACM Conference on Electronic Commerce, pages 568\u2013585, 2012.   \n[16] Daniel Franzen, Saskia Nu\u00f1ez von Voigt, Peter S\u00f6rries, Florian Tschorsch, and Claudia M\u00fcllerBirn. Am i private and if so, how many? communicating privacy guarantees of differential privacy with risk communication formats. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, pages 1125\u20131139, 2022.   \n[17] Marco Gaboardi, James Honaker, Gary King, Jack Murtagh, Kobbi Nissim, Jonathan Ullman, and Salil Vadhan. Psi ({\\Psi}): a private data sharing interface. arXiv preprint arXiv:1609.04340, 2016.   \n[18] Arpita Ghosh, Tim Roughgarden, and Mukund Sundararajan. Universally utility-maximizing privacy mechanisms. SIAM Journal on Computing, 41(6):1673\u20131693, 2012.   \n[19] Ruobin Gong and Xiao-Li Meng. Congenial differential privacy under mandated disclosure. In Proceedings of the 2020 ACM-IMS on Foundations of Data Science Conference, pages 59\u201370, 2020.   \n[20] Michael Hay, Ashwin Machanavajjhala, Gerome Miklau, Yan Chen, Dan Zhang, and George Bissias. Exploring privacy-accuracy tradeoffs using dpcomp. In Proceedings of the 2016 International Conference on Management of Data, pages 2101\u20132104, 2016.   \n[21] HHS. Healthy people 2020. Office of Disease Prevention and Health Promotion, U.S. Department of Health and Human Services, 2020. Accessed on 22 April 2024.   \n[22] V Joseph Hotz, Christopher R Bollinger, Tatiana Komarova, Charles F Manski, Robert A Moffitt, Denis Nekipelov, Aaron Sojourner, and Bruce D Spencer. Balancing data privacy and usability in the federal statistical system. Proceedings of the National Academy of Sciences, 119(31), 2022.   \n[23] Justin Hsu, Marco Gaboardi, Andreas Haeberlen, Sanjeev Khanna, Arjun Narayan, Benjamin C Pierce, and Aaron Roth. Differential privacy: An economic method for choosing epsilon. In 2014 IEEE 27th Computer Security Foundations Symposium, pages 398\u2013410. IEEE, 2014.   \n[24] Mark F St John, Grit Denker, Peeter Laud, Karsten Martiny, Alisa Pankova, and Dusko Pavlovic. Decision support for sharing data using differential privacy. In 2021 IEEE Symposium on Visualization for Cyber Security (VizSec), pages 26\u201335. IEEE, 2021.   \n[25] Shiva P Kasiviswanathan and Adam Smith. On the\u2019semantics\u2019 of differential privacy: A Bayesian formulation. Journal of Privacy and Confidentiality, 6(1), 2014.   \n[26] Zeki Kazan and Jerome Reiter. Assessing statistical disclosure risk for differentially private, hierarchical count data, with application to the 2020 us decennial census. Statistica Sinica, 34:to appear, 2024.   \n[27] Daniel Kifer, John M Abowd, Robert Ashmead, Ryan Cumings-Menon, Philip Leclerc, Ashwin Machanavajjhala, William Sexton, and Pavel Zhuravlev. Bayesian and frequentist semantics for common variations of differential privacy: Applications to the 2020 census. arXiv preprint arXiv:2209.03310, 2022.   \n[28] Daniel Kifer and Ashwin Machanavajjhala. Pufferfish: A framework for mathematical privacy definitions. ACM Transactions on Database Systems (TODS), 39(1):1\u201336, 2014.   \n[29] Jaewoo Lee and Chris Clifton. How much is enough? choosing $\\varepsilon$ for differential privacy. In International Conference on Information Security, pages 325\u2013340. Springer, 2011.   \n[30] Chao Li, Daniel Yang Li, Gerome Miklau, and Dan Suciu. A theory of pricing private data. ACM Transactions on Database Systems (TODS), 39(4):1\u201328, 2014.   \n[31] Ashwin Machanavajjhala, Daniel Kifer, John Abowd, Johannes Gehrke, and Lars Vilhuber. Privacy: Theory meets practice on the map. In 2008 IEEE 24th International Conference on Data Engineering, pages 277\u2013286. IEEE, 2008.   \n[32] Charles F Manski. The lure of incredible certitude. Economics & Philosophy, 36(2):216\u2013245, 2020.   \n[33] David McClure and Jerome P Reiter. Differential privacy and statistical disclosure risk measures: An investigation with binary synthetic data. Transactions on Data Privacy, 5(3):535\u2013552, 2012.   \n[34] Luise Mehner, Saskia Nu\u00f1ez von Voigt, and Florian Tschorsch. Towards explaining epsilon: A worst-case study of differential privacy risks. In 2021 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW), pages 328\u2013331. IEEE, 2021.   \n[35] Priyanka Nanayakkara, Johes Bater, Xi He, Jessica Hullman, and Jennie Rogers. Visualizing privacy-utility trade-offs in differentially private data releases. Proceedings on Privacy Enhancing Technologies, 2022.   \n[36] Priyanka Nanayakkara, Mary Anne Smart, Rachel Cummings, Gabriel Kaptchuk, and Elissa M Redmiles. What are the chances? explaining the epsilon parameter in differential privacy. In 32nd USENIX Security Symposium (USENIX Security 23), pages 1613\u20131630, 2023.   \n[37] NCDHHS. 2020 north carolina infant mortality report, table 1. NC State Center for Health Statistics, 2020. Accessed on 22 April 2024.   \n[38] NCDHHS. Cy2020 north carolina resident births by county of residence and month. NC State Center for Health Statistics, 2020. Accessed on 22 April 2024.   \n[39] Alisa Pankova and Peeter Laud. Interpreting epsilon of differential privacy in terms of advantage in guessing or approximating sensitive attributes. In 2022 IEEE 35th Computer Security Foundations Symposium (CSF), pages 96\u2013111. IEEE, 2022.   \n[40] Giovanni Parmigiani and Lurdes Inoue. Decision theory: Principles and approaches. John Wiley & Sons, 2009.   \n[41] Jerome P Reiter. Estimating risks of identification disclosure in microdata. Journal of the American Statistical Association, 100(472):1103\u20131112, 2005.   \n[42] Jerome P Reiter. Differential privacy and federal data releases. Annual Review of Statistics and Its Application, 6:85\u2013101, 2019.   \n[43] Jayshree Sarathy, Sophia Song, Audrey Haque, Tania Schlatter, and Salil Vadhan. Don\u2019t look at the data! how differential privacy reconfigures the practices of data science. arXiv preprint arXiv:2302.11775, 2023.   \n[44] Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and Xiaofeng Wang. Privacy loss in Apple\u2019s implementation of differential privacy on macos 10.12. arXiv preprint arXiv:1709.02753, 2017.   \n[45] Alexandra Wood, Micah Altman, Aaron Bembenek, Mark Bun, Marco Gaboardi, James Honaker, Kobbi Nissim, David R O\u2019Brien, Thomas Steinke, and Salil Vadhan. Differential privacy: A primer for a non-technical audience. Vanderbilt Journal of Entertainment & Technology Law, 21:209, 2018.   \n[46] Alexandra Wood, Micah Altman, Kobbi Nissim, and Salil Vadhan. Designing access with differential privacy. In Handbook on Using Administrative Data for Research and Evidencebased Policy. Abdul Latif Jameel Poverty Action Lab, Cambridge, MA, 2020. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Supplemental Tables ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Notation Summary ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Table 2 summarizes the notation of Section 2. Table 3 summarizes the definitions of key probabilistic quantities. ", "page_idx": 13}, {"type": "table", "img_path": "kamAXSJxGV/tmp/49f5bfbfe50558e556e4caad15756747a801ed5d629f1dc30dc4bfd48e52b81d.jpg", "table_caption": [], "table_footnote": ["Table 2: Summary of notation. "], "page_idx": 13}, {"type": "table", "img_path": "kamAXSJxGV/tmp/525e8088eacd8689af932f8e45d8fc07c1f5189257984d3ab8ada8a17bba571c.jpg", "table_caption": [], "table_footnote": ["Table 3: Summary of definitions. "], "page_idx": 13}, {"type": "text", "text": "A.2 Closed Forms for $\\varepsilon$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we provide a reference for all derived closed forms for $\\varepsilon$ . Corresponding formal theorem statements are provided in Appendix B.1 and discussion of closed forms not referenced in the main text is provided in Appendix B.2. Table 4 provides the closed forms. ", "page_idx": 14}, {"type": "table", "img_path": "kamAXSJxGV/tmp/2fe0cc8699d3c759d84dc351aee4765d117b01f076930e7a4863b7f5e452fdc5.jpg", "table_caption": [], "table_footnote": ["Table 4: Closed forms for $\\varepsilon$ for various $r^{*}(p_{i},q_{i})$ . "], "page_idx": 14}, {"type": "text", "text": "B Additional Results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "B.1 Omitted Results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we present all results omitted from the paper. Proofs of these results are included in Appendix E. ", "page_idx": 15}, {"type": "text", "text": "First, we state a corollary to Theorem 1, which generalizes Theorem 1.3 in [19] to sets where $\\vert{\\cal S}\\vert>1$ and to unbounded DP. ", "page_idx": 15}, {"type": "text", "text": "Corollary 1. Under the conditions of Theorem $^{\\,l}$ , for all $p_{i},q_{i}\\in(0,1]$ and all $t^{*}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\le e^{2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Next, we state a corollary to Theorem 2 which considers the special case where $p_{i}~=~1$ . This corresponds to a setting where individual $i$ \u2019s inclusion in the data is known a priori by the adversary, for example data from a census or public social media platform. ", "page_idx": 15}, {"type": "text", "text": "Corollary 2. Under the conditions of Theorem 2, if $p_{i}=1$ and $0<q_{i}<1$ , any statistic $T^{*}=t^{*}$ released under $\\varepsilon$ -DP with ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\varepsilon\\leq\\frac{1}{2}\\log\\left(\\frac{1-q_{i}}{\\frac{1}{r^{*}(1,q_{i})}-q_{i}}\\right),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "will satisfy $r_{i}(1,q_{i},t^{*})\\leq r^{*}(1,q_{i})$ . ", "page_idx": 15}, {"type": "text", "text": "For particular forms of $r^{*}$ , the optimization in (13) has a closed form solution. This is detailed by the following theorems, which are preceded by two lemmas used in the proofs. ", "page_idx": 15}, {"type": "text", "text": "Lemma 2. Fix $p_{i},q_{i}\\in(0,1)$ and let $\\begin{array}{r}{r^{*}(p_{i},q_{i})=\\frac{\\tilde{a}}{p_{i}q_{i}}}\\end{array}$ . Then the function ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\varepsilon(p_{i},q_{i})=\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{*}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "has partial derivatives such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n0<p_{i}<1\\,a n d\\,0<q_{i}<1\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma 3. Fix $p_{i},q_{i}\\in(0,1)$ and let $r^{*}(p_{i},q_{i})=\\tilde{r}$ . Then the function ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\varepsilon(p_{i},q_{i})=\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{\\ast}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "has partial derivatives such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\partial\\varepsilon(p_{i},q_{i})}{\\partial p_{i}}<0\\;i f0<q_{i}<\\frac{1}{\\tilde{r}+1}\\;a n d\\,0<p_{i}<1}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\partial\\varepsilon(p_{i},q_{i})}{\\partial p_{i}}>0\\;i f\\frac{1}{\\tilde{r}+1}<q_{i}<1\\;a n d\\,0<p_{i}<1}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Theorem 3. Under the conditions of Theorem 2, $f r^{*}(p_{i},q_{i})=\\tilde{r}>1$ , the solution to the minimization problem in $(I3)$ is ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\varepsilon=\\frac12\\log\\left(\\tilde{r}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Theorem 4. Under the conditions of Theorem 2, let $\\tilde{a}<1$ , $\\tilde{p}\\leq1$ , and $\\tilde{r}>1$ , and $0<q_{i}<1$ . If the function $r^{*}$ is such that $r^{*}(\\tilde{p},q_{i})=\\operatorname*{max}\\{\\tilde{a}/(\\tilde{p}q_{i}),\\tilde{r}\\}$ and $r^{*}(p_{i},q_{i})=\\infty\\,i f\\,p_{i}\\neq\\tilde{p}_{*}$ , then the solution to the minimization problem in (13) is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon=\\left\\{\\log\\left(\\frac{\\tilde{a}(1-\\tilde{p})}{\\tilde{p}(1-\\tilde{a})}\\right),\\quad}&{i f0<\\tilde{p}\\leq\\frac{\\tilde{a}}{\\tilde{r}};}\\\\ {\\log\\left(\\frac{2(\\tilde{p}\\tilde{r}-\\tilde{a})}{\\sqrt{\\tilde{r}^{2}(1-\\tilde{p})^{2}+4(\\tilde{p}\\tilde{r}-\\tilde{a})(1-\\tilde{a})}-\\tilde{r}(1-\\tilde{p})}\\right),\\quad i f\\frac{\\tilde{a}}{\\tilde{r}}<\\tilde{p}\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Theorem 5. Under the conditions of Theorem 2, let $\\tilde{a}<1$ , $\\tilde{q}\\leq1$ , and $\\tilde{r}>1$ , and $0<p_{i}<1$ . If the function $r^{*}$ is such that $r^{*}(p_{i},\\tilde{q})=\\operatorname*{max}\\{\\tilde{a}/(p_{i}\\tilde{q}),\\tilde{r}\\}$ and $r^{\\ast}(p_{i},q_{i})=\\infty$ for $q_{i}\\neq\\tilde{q},$ , then the solution to the minimization problem in (13) is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\varepsilon=\\left\\{\\begin{array}{l l}{\\frac{1}{2}\\log\\left(\\frac{\\tilde{a}(1-\\tilde{q})}{\\tilde{q}(1-\\tilde{a})}\\right),}&{i f0<\\tilde{q}\\leq\\frac{\\tilde{a}}{\\tilde{r}};}\\\\ {\\frac{1}{2}\\log\\left(\\frac{1-\\tilde{q}}{\\frac{1}{\\tilde{r}}-\\tilde{q}}\\right),}&{i f0<\\tilde{q}\\leq\\frac{1}{\\tilde{r}+1}\\,a n d\\,\\frac{\\tilde{a}}{\\tilde{r}}<\\tilde{q}<1;}\\\\ {\\log\\left(\\frac{2\\tilde{a}(1-\\tilde{q})}{\\sqrt{(\\tilde{r}\\tilde{q}-\\tilde{a})^{2}+4\\tilde{a}\\tilde{q}(1-\\tilde{q})(1-\\tilde{a})}-(\\tilde{r}\\tilde{q}-\\tilde{a})}\\right),}&{i f\\frac{1}{\\tilde{r}+1}<\\tilde{q}<1\\,a n d\\,\\frac{\\tilde{a}}{\\tilde{r}}<\\tilde{q}<1;}\\\\ {\\log\\left(\\frac{\\tilde{r}-\\tilde{a}}{1-\\tilde{a}}\\right),}&{i f\\tilde{q}=1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "B.2 Additional Closed Forms ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we present closed form results for the $\\varepsilon$ implied by additional disclosure risk proflies not discussed in the main text. Proofs of these results are not provided, although we note that proofs would have a structure similar to the proofs of Theorems 3\u20135. It is straightforward to verify these results empirically. ", "page_idx": 16}, {"type": "text", "text": "First, consider an agency that requires a constant relative risk bound to hold on a subset of the $(p_{i},q_{i})$ space and does not have any bounds outside that space. That is, rather than enforcing $r^{*}(p_{i},q_{i})=\\tilde{r}$ for all $0\\leq p_{i},q_{i}\\leq1$ , the agency only enforces this condition for $\\tilde{p}_{0}\\leq p_{i}\\leq\\tilde{p}_{1}$ and $\\tilde{q}_{0}\\leq q_{i}\\leq\\tilde{q}_{1}$ , where $0\\leq\\tilde{p}_{0}\\leq\\tilde{p}_{1}\\leq1$ and $0\\leq\\tilde{q}_{0}\\leq\\tilde{q}_{1}\\leq1$ (for $\\tilde{p}_{1},\\tilde{q}_{1}>0_{,}$ ). Formally, ", "page_idx": 16}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\left\\{\\!\\!\\begin{array}{l l}{\\tilde{r},}&{\\mathrm{if}~\\tilde{p}_{0}\\leq p_{i}\\leq\\tilde{p}_{1}~\\mathrm{and}~\\tilde{q}_{0}\\leq q_{i}\\leq\\tilde{q}_{1};}\\\\ {\\infty,}&{\\mathrm{otherwise}.}\\end{array}\\ \\right.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The recommended $\\varepsilon$ for an agency with the risk profile in (25) is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\varepsilon=\\left\\{\\begin{array}{l l}{\\log\\left(\\frac{2\\tilde{p}_{1}\\left(1-\\tilde{q}_{0}\\right)}{\\sqrt{(1-\\tilde{p}_{1})^{2}+4\\tilde{p}_{1}(1-\\tilde{q}_{0})\\left(\\frac{1}{\\tilde{r}}-\\tilde{p}_{1}\\tilde{q}_{0}\\right)}-(1-\\tilde{p}_{1})}\\right),}&{\\mathrm{if~}0\\leq\\tilde{q}_{0}\\leq\\frac{1}{\\tilde{r}+1};}\\\\ {\\log\\left(\\frac{2\\tilde{p}_{0}\\left(1-\\tilde{q}_{0}\\right)}{\\sqrt{(1-\\tilde{p}_{0})^{2}+4\\tilde{p}_{0}(1-\\tilde{q}_{0})\\left(\\frac{1}{\\tilde{r}}-\\tilde{p}_{0}\\tilde{q}_{0}\\right)}-(1-\\tilde{p}_{0})}\\right),}&{\\mathrm{if~}\\frac{1}{\\tilde{r}+1}<\\tilde{q}_{0}<1\\mathrm{~and~}\\tilde{p}_{0}>0;}\\\\ {\\log\\left(\\tilde{r}\\right),}&{\\mathrm{if~}\\frac{1}{\\tilde{r}+1}<\\tilde{q}_{0}<1\\mathrm{~and~}\\tilde{p}_{0}=0;}\\\\ {\\log\\left(\\frac{1-\\tilde{p}_{0}}{\\frac{1}{\\tilde{r}}-\\tilde{p}_{0}}\\right),}&{\\mathrm{if~}\\tilde{q}_{0}=1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Next, consider an agency that desires a constant bound on the difference between the posterior and the prior. That is, for some $\\tilde{b}\\in(0,1)$ , they would like to enforce ", "page_idx": 16}, {"type": "equation", "text": "$$\nP_{\\mathcal{M}}[Y_{i}\\in S,I_{i}=1\\mid T^{*}=t^{*}]-P_{\\mathcal{M}}[Y_{i}\\in S,I_{i}=1]\\le\\tilde{b}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This constraint corresponds to the following risk profile. ", "page_idx": 16}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\frac{p_{i}q_{i}+\\tilde{b}}{p_{i}q_{i}}=1+\\frac{\\tilde{b}}{p_{i}q_{i}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The recommended $\\varepsilon$ for an agency with this risk profile is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\varepsilon=\\log\\left(\\frac{1+\\tilde{b}}{1-\\tilde{b}}\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Notably, by a Taylor series approximation, $-\\log(1-\\tilde{b})\\approx\\tilde{b}+\\tilde{b}^{2}/2$ . Thus, for small $\\tilde{b}$ , it follows that the recommended $\\varepsilon$ can be approximated by ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\varepsilon=\\log(1+\\tilde{b})-\\log(1-\\tilde{b})\\approx\\left(\\tilde{b}-\\frac{\\tilde{b}^{2}}{2}\\right)+\\left(\\tilde{b}+\\frac{\\tilde{b}^{2}}{2}\\right)=2\\tilde{b}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "image", "img_path": "kamAXSJxGV/tmp/691c02d8a3df2d834a0092a76f124df43aa12ba6a187906996be8b283065879f.jpg", "img_caption": [], "img_footnote": ["Figure 3: The risk profiles for three agencies with risk profile given by (31). The lines in the lower panels represent the risk profiles for $q_{i}=1$ as a function of $p_{i}$ , and the colors represent the implied $\\varepsilon$ at each point on the curve. The lines in the upper panels represent the corresponding baseline $r^{*}(p_{i},1)=\\tilde{r}$ . The left plots set $\\tilde{r}=1.5$ , the center plots set $\\tilde{r}=3$ , and the right plots set $\\tilde{r}=6$ . "], "page_idx": 17}, {"type": "text", "text": "C Additional Examples ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "This section provides additional examples of risk profiles. ", "page_idx": 17}, {"type": "text", "text": "C.1 Additional Figure for Example 1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Here we provide an additional figure for Example 1. The setting is restated below. ", "page_idx": 17}, {"type": "text", "text": "Example 1. A healthcare provider possesses a data set comprising demographic information about individuals diagnosed with a particular form of cancer in a region of interest. They plan to release the count of individuals diagnosed with this form of cancer in various demographic groups via the geometric mechanism, but are concerned this release, if insufficient noise is added, could reveal which individuals in the community have cancer. They wish to choose \u03b5 appropriately. ", "page_idx": 17}, {"type": "text", "text": "As discussed in Section 4, a reasonable risk profile for this setting might focus on $p_{i}$ and set $q_{i}=1$ . If we additionally suppose the agency is generally willing to accept a maximum absolute disclosure risk of 0.25 for adversaries with small prior probabilities. A risk profile for this agency might be of the form, for some $\\tilde{r}>1$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\left\\{\\!\\!\\begin{array}{l l}{\\operatorname*{max}\\left\\{\\frac{0.25}{p_{i}},\\tilde{r}\\right\\},}&{\\mathrm{if~}q_{i}=1;}\\\\ {\\infty,}&{\\mathrm{if~}q_{i}\\neq1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The three example risk functions considered in Section 4 are presented in Figure 3. Agency A is risk averse, agency $\\mathbf{C}$ is utility seeking, and agency $\\mathbf{B}$ sits in between in terms of risk and utility. For adversaries with high prior probabilities, agencies A, B, and $\\mathbf{C}$ bound the relative disclosure risk at $\\tilde{r}=1.5$ , $\\tilde{r}=3$ , and $\\tilde{r}=6$ , respectively. ", "page_idx": 17}, {"type": "text", "text": "C.2 Extended Example 2 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Here we provide an extended analysis of Example 2. The setting is restated below. ", "page_idx": 17}, {"type": "image", "img_path": "kamAXSJxGV/tmp/4cebf8bfd467fbe8e117cdf46ddfce7127cab2692624534c4a8870b9f8951b97.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 4: The risk profiles for three agencies with risk profile given by (32). The lines represent the risk proflies for $p_{i}=0.05$ as a function of $q_{i}$ , and the colors represent the implied $\\varepsilon$ at each point on the curve. The left plot sets $\\tilde{a}=0.025$ , the center sets $\\tilde{a}=0.15$ , and the right sets $\\tilde{a}=0.3$ . ", "page_idx": 18}, {"type": "table", "img_path": "kamAXSJxGV/tmp/60ddd47c020441e0dd76619c01d00278fdbbd858bdde187b6d183263173db05c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Table 5: For each of the three risk proflies in Figure 4, we present the $\\varepsilon$ recommended by our framework. For a release satisfying $\\varepsilon$ -DP using the geometric mechanism, we present the corresponding standard deviation of the noise distribution and the probability that the exact value is released (i.e., the noise distribution\u2019s probability mass at zero). ", "page_idx": 18}, {"type": "text", "text": "Example 2. A survey is performed on a sample of individuals in the region of interest. $5\\%$ of the region is surveyed, and respondents are asked whether they have this particular form of cancer along with a series of demographic questions. The agency plans to release the counts of surveyed individuals who have and do not have the cancer in various demographic groups via the geometric mechanism, but is concerned this release, if insufficient noise is added, could reveal which individuals in the community have cancer. The agency wishes to choose \u03b5 appropriately. ", "page_idx": 18}, {"type": "text", "text": "As discussed in Section 4, a reasonable risk proflie for this setting might set ${\\cal S}=\\{y\\in\\{0,1\\}^{d}:y_{1}=$ $1\\}$ and focus on $q_{i}$ , while fixing $p_{i}=0.05$ . Additionally, suppose the agency is generally willing to accept a maximum relative disclosure risk of 3 for adversaries with large prior probabilities. A reasonable risk profile for this agency might be of the form, for some $\\tilde{a}<1$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\left\\{\\!\\!\\begin{array}{l l}{\\operatorname*{max}\\left\\{\\frac{\\tilde{a}}{0.05q_{i}},3\\right\\},}&{\\mathrm{if}\\;p_{i}=0.05;}\\\\ {\\infty,}&{\\mathrm{if}\\;p_{i}\\neq0.05.}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Three example risk functions of this form are presented in Figure 4. Once again, agency A is risk averse, agency $\\mathbf{C}$ is utility seeking, and agency $\\mathbf{B}$ sits in between on risk and utility. Agencies A, B, and C are willing to allow adversaries to achieve an absolute disclosure risk of $\\tilde{a}=0.025$ , $\\tilde{a}=0.15$ , and $\\tilde{a}=0.3$ , respectively. Table 5 presents the $\\varepsilon$ recommendations for each agency along with the standard deviation of the noise and probability of releasing the exact value of each statistic under the geometric mechanism. ", "page_idx": 18}, {"type": "text", "text": "As in Table 1, the $\\varepsilon$ recommendations reflect trade offs between privacy and accuracy. They also are much higher than the recommendations from a corresponding simple risk proflie of $r^{\\dot{*}}(p_{i},q_{i})=3$ for all prior probabilities, which implies $\\varepsilon\\approx0.55$ . Even the most risk averse agency is recommended an $\\varepsilon$ that is much larger than this baseline risk proflie. This gain is primarily due to the assumptions that the survey is a simple random sample from the population, and the adversary has no prior knowledge about which individuals are surveyed. Essentially, the additional uncertainty from the sampling mechanism allows for an $\\varepsilon$ recommendation with less noise injected. This is consistent with prior work showing that DP mechanisms applied to random subsamples provide better privacy guarantees [3]. The recommended $\\varepsilon$ will increase as the proportion of individuals from the population surveyed $\\left(\\tilde{p}\\right)$ decreases. For example, for the risk function in (32) with $\\tilde{a}=0.025$ and $\\tilde{r}=3$ , if $\\tilde{p}=0.005$ , we recommend $\\varepsilon\\approx1.63$ ; if $\\tilde{p}=0.0005$ , we recommend $\\varepsilon\\approx3.94$ . ", "page_idx": 18}, {"type": "image", "img_path": "kamAXSJxGV/tmp/d9cf2dc462498b05b6be011ada1b5f1264d92bdb244db7bf4bbae1d64866767e.jpg", "img_caption": ["Figure 5: The top panel presents the $r^{*}(p_{i},q_{i})$ from (33) as a function of $p_{i}$ and $q_{i}$ . The bottom panel presents the implied $\\varepsilon_{i}(p_{i},q_{i})$ as a function of $p_{i}$ and $q_{i}$ . The red point represents $\\mathrm{argmin}_{(p_{i},q_{i})}\\,\\varepsilon_{i}(p_{i},q_{i})$ . For clarity of presentation, all $r^{*}(p_{i},q_{i})>100$ are truncated to 100 and all $\\varepsilon_{i}(p_{i},q_{i})>4$ are truncated to 4. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "C.3 Two-dimensional Example ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The examples in Appendices C.1 and C.2 focus on settings where only one of $p_{i}$ and $q_{i}$ is important and the other can be reasonably fixed to a constant. Now we consider the setting where both may be simultaneously important. For example, in Example 2, the agency may wish to consider adversaries with various $p_{i}$ , rather than only $\\tilde{p}=0.05$ . Perhaps the agency wishes to limit the absolute disclosure to be below $\\tilde{a}\\:=\\:0.25$ when total prior probability of disclosure, $p_{i}q_{i}$ , is low and limit relative disclosure to be below $\\tilde{r}=3$ when $p_{i}q_{i}$ is high. This corresponds to the following risk profile. ", "page_idx": 19}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\operatorname*{max}\\left\\{\\frac{\\tilde{a}}{p_{i}q_{i}},\\tilde{r}\\right\\}=\\operatorname*{max}\\left\\{\\frac{0.25}{p_{i}q_{i}},3\\right\\}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "A plot of this desired bound on pairs $(p_{i},q_{i})$ on the space $(0,1]\\times(0,1]$ is presented in the top panel of Figure 5. Notably, if $p_{i}$ is fixed at $\\tilde{p}\\in(0,1]$ , a plot of $r^{*}(\\tilde{p},q_{i})$ as a function of $q_{i}$ has a form similar to the plots of Figure 4. Similarly, if $q_{i}$ is fixed at $\\tilde{q}\\in(0,1]$ , a plot of $r^{*}(p_{i},\\tilde{q})$ as a function of $p_{i}$ has a form similar to the plots of Figure 3. ", "page_idx": 19}, {"type": "text", "text": "To determine the $\\varepsilon$ recommended by this proflie, we numerically solve the minimization problem in (13). A plot of $\\varepsilon_{i}(p_{i},q_{i})$ as a function of pairs $(p_{i},q_{i})$ on the space $(0,1]\\times(0,1]$ is presented in the bottom panel of Figure 5. Our framework recommends $\\varepsilon\\approx0.65$ , which corresponds to $p_{i}=1$ and $q_{i}=0.083=\\tilde{a}/\\tilde{r}$ . ", "page_idx": 20}, {"type": "text", "text": "D Additional Discussion of Prior Work ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we describe two previous works with similar aims to our framework using the notation in Section 2.2, expanding on the discussion in Section 6. ", "page_idx": 20}, {"type": "text", "text": "D.1 \u201cHow Much is Enough? Choosing $\\varepsilon$ for Differential Privacy\" ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "[29] focus on settings where the population, $\\mathbf{P}$ , of size $n$ is public information and the adversary\u2019s goal is to determine which subset of individuals in $\\mathbf{P}$ was used for a differentially private release of a statistic. We can characterize their setting with the notation of Section 2.2 as follows. We define $\\mathbf{Y}$ to be the subset of individuals\u2019 values in $\\mathbf{P}$ used to compute the statistic of interest, $T(\\mathbf{Y})$ , and its released DP counterpart, $T^{*}(\\mathbf{Y})$ . In their examples, the authors focus on the setting where only one individual is removed from $\\mathbf{P}$ to create $\\mathbf{Y}$ , and the adversary\u2019s goal is to determine which $i$ was removed. ", "page_idx": 20}, {"type": "text", "text": "We can apply our framework to this setting with a minor modification. For this comparison, we assume the adversary\u2019s $q_{i}=P_{\\mathcal{M}}[Y_{i}\\in\\mathcal{S}\\ |\\ \\bar{I_{i}}=0]=1$ for any set $\\boldsymbol{S}$ (although we note that this is a weaker assumption than that of Lee and Clifton, since we do not assume $\\mathbf{P}$ is public). We redefine $p_{i}$ and the risk measures to be in terms of $I_{i}=0$ , rather than $I_{i}=1$ . ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{c}{p_{i}=P_{\\mathcal{M}}[I_{i}=0]}\\\\ {r_{i}(p_{i},1,t^{*})=\\frac{P_{\\mathcal{M}}[I_{i}=0\\mid T^{*}=t^{*}]}{P_{\\mathcal{M}}[I_{i}=0]}}\\\\ {a_{i}(p_{i},1,t^{*})=P_{\\mathcal{M}}[I_{i}=0\\mid T^{*}=t^{*}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "[29] focus on the case of $p_{i}\\,=\\,1/n$ , and seek to enforce the bound $a_{i}(1/n,1,t^{*})\\,\\leq\\,\\tilde{a}$ for some constant $\\tilde{a}$ and all $t^{*}$ , which implies the relative risk bound ", "page_idx": 20}, {"type": "equation", "text": "$$\nr^{*}(p_{i},q_{i})=\\left\\{\\!\\!\\begin{array}{l l}{{n\\tilde{a},}}&{{\\mathrm{if}\\ p_{i}=\\frac{1}{n},q_{i}=1;}}\\\\ {{\\infty,}}&{{\\mathrm{otherwise.}}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "From an analogy to Theorem 2 with the redefined $p_{i}$ , it follows that under these conditions, our method sets ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\varepsilon=\\log\\left(\\frac{1-\\frac{1}{n}}{\\frac{1}{n\\tilde{a}}-\\frac{1}{n}}\\right)=\\log\\left(\\frac{(n-1)\\tilde{a}}{1-\\tilde{a}}\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In the motivating example from their paper, the authors set $n=4$ and $\\tilde{a}=1/3$ , giving $r^{*}(1/n,1)=$ $4/3$ . This results in $\\varepsilon\\stackrel{\\cdot}{=}\\log(3/2)\\approx0.41$ from our method. When the release mechanism is the addition of Laplace noise, [29]\u2019s method arrives at a similar form, but with the recommendation scaled by a factor of $\\Delta T/\\Delta v$ . ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\varepsilon=\\displaystyle\\frac{\\Delta T}{\\Delta v}\\log\\left(\\frac{(n-1)\\widetilde{a}}{1-\\widetilde{a}}\\right),}\\\\ &{\\Delta T=\\operatorname*{max}\\left\\{\\left|T(\\mathbf{Y}_{1})-T(\\mathbf{Y}_{2})\\right|:\\mathbf{Y}_{2}\\subset\\mathbf{Y}_{1}\\subset\\mathbf{P},\\left|\\mathbf{Y}_{1}\\right|=n-1,\\left|\\mathbf{Y}_{2}\\right|=n-2\\right\\}}\\\\ &{\\Delta v=\\operatorname*{max}\\left\\{\\left|T(\\mathbf{Y}_{1})-T(\\mathbf{Y}_{2})\\right|:\\mathbf{Y}_{1}\\subset\\mathbf{P},\\mathbf{Y}_{2}\\subset\\mathbf{P},\\left|\\mathbf{Y}_{1}\\right|=\\left|\\mathbf{Y}_{2}\\right|=n-1\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The recommendation of [29]\u2019s method thus depends on both the population and the particular release function. This results in different $\\varepsilon$ values for the same $n$ and $\\tilde{a}$ , as low as 0.34 and as high as 1.62 in the authors\u2019 examples, depending on the statistic of interest and the values in the data. ", "page_idx": 20}, {"type": "text", "text": "D.2 \u201cDifferential Privacy: A Primer for a Non-Technical Audience\" ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The example in [45] considers an individual deciding whether or not to participate in a survey for which results will be released via DP with a particular $\\varepsilon$ . Using our notation, let $Z_{i}=f(Y_{i},\\bar{I}_{i})\\in$ $\\{0,1\\}$ be a quantity of interest to the adversary, who wishes to learn whether $Z_{i}=1$ . They have some prior $\\bar{q_{i}}=\\dot{P_{\\mathcal M}}[Z_{i}=1]$ . Rather than considering the relative or absolute disclosure risk, the individual is interested in comparing the adversary\u2019s posterior probability if they participate in the survey, $a_{1i}(q_{i},t^{*})=P_{M}[Z_{i}=1\\mid I_{i}=1,T^{*}=t^{*}]$ , to the adversary\u2019s posterior probability if they do not participate, $a_{0i}(q_{i},t^{*})=P_{M}[Z_{i}=1\\mid I_{i}=0,T^{*}=t^{*}]$ . The authors of [45] state that for all $q_{i}$ and all $t^{*}$ , ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "equation", "text": "$$\na_{1i}(q_{i},t^{*})\\leq\\frac{a_{0i}(q_{i},t^{*})}{a_{0i}(q_{i},t^{*})+e^{-2\\varepsilon}(1-a_{0i}(q_{i},t^{*}))}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This expression is in the same spirit as the results from our framework with $p_{i}=1$ . By Theorem 1, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\nr_{i}(1,q_{i},t^{*})\\leq\\frac{1}{q_{i}+e^{-2\\varepsilon}(1-q_{i})}\\ \\ \\ \\implies\\ \\ \\ a_{i}(1,q_{i},t^{*})\\leq\\frac{q_{i}}{q_{i}+e^{-2\\varepsilon}(1-q_{i})}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The authors of [45] suggest that the individual considering survey participation use (42) to bound $a_{1i}$ for various values of $a_{0i}$ . The individual can examine these bounds to make an informed decision about whether to participate in the survey. ", "page_idx": 21}, {"type": "text", "text": "E Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "This section provides proofs of results from Section 3 and Appendix B.1. ", "page_idx": 22}, {"type": "text", "text": "Lemma 1. Under Assumption 1 and Assumption 2, if the release of $T^{*}=t^{*}$ satisfies DP, then for any subset $\\boldsymbol{S}$ of the domain of $Y_{i}$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\ne^{-\\varepsilon}\\leq{\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in S,I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}}\\leq e^{\\varepsilon},\\qquad e^{-2\\varepsilon}\\leq{\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in S,I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\notin S,I_{i}=1]}}\\leq e^{2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. To begin, we demonstrate that for all $y$ in the support of $Y_{i}$ and $t^{*}$ in the support of $T^{*}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\ne^{-\\varepsilon}\\leq\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}=y,I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}\\leq e^{\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let $\\mathcal{V}_{-i}$ be the support of $\\mathbf{Y}_{-i}$ under $\\mathcal{M}$ . Then, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{M}[T^{*}=t^{*}\\mid Y_{i}=y,I_{i}=1]}\\\\ &{\\qquad=\\displaystyle\\sum_{\\mathbf y_{-i}\\in\\mathcal{Y}_{-i}}P[T^{*}=t^{*}\\mid Y_{i}=y,\\mathbf Y_{-i}=\\mathbf y_{-i},I_{i}=1]\\,P_{M}[\\mathbf Y_{-i}=\\mathbf y_{-i}\\mid Y_{i}=y,I_{i}=1]}\\\\ &{\\qquad\\le\\displaystyle\\sum_{\\mathbf y_{-i}\\in\\mathcal{Y}_{-i}}e^{\\varepsilon}P[T^{*}=t^{*}\\mid\\mathbf Y_{-i}=\\mathbf y_{-i},I_{i}=0]\\,P_{M}[\\mathbf Y_{-i}=\\mathbf y_{-i}\\mid Y_{i}=y,I_{i}=1]}\\\\ &{\\qquad=e^{\\varepsilon}\\displaystyle\\sum_{\\mathbf y_{-i}\\in\\mathcal{Y}_{-i}}P_{M}[T^{*}=t^{*}\\mid\\mathbf Y_{-i}=\\mathbf y_{-i},I_{i}=0]\\,P[\\mathbf Y_{-i}=\\mathbf y_{-i}\\mid I_{i}=0]}\\\\ &{\\qquad=e^{\\varepsilon}P_{M}[T^{*}=t^{*}\\mid I_{i}=0].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The equality in (45) follows from the law of total probability and Assumption 1. The inequality in (46) follows from DP via (1). The equality in (47) follows from Assumption 2. The equality in (48) follows from the law of total probability and Assumption 1. This completes the proof of the right inequality. The proof of the left inequality is identical with the other inequality in (1) applied in (46). ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in\\mathcal{S},I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}=\\frac{\\frac{P_{M}[Y_{i}\\in\\mathcal{S}|T^{*}=t^{*},I_{i}=1]\\,P_{M}[T^{*}=t^{*}|I_{i}=1]}{P_{M}[Y_{i}\\in\\mathcal{S}|I_{i}=1]}}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\frac{P_{M}[T^{*}=t^{*}\\mid I_{i}=1]\\,P_{M}[Y_{i}\\in\\mathcal{S}\\mid T^{*}=t^{*},I_{i}=1]}{P_{M}[Y_{i}\\in\\mathcal{S}\\mid I_{i}=1]\\,P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We can then break the second term in the numerator into a summation and apply Bayes\u2019 Theorem to each term in the sum. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in\\mathcal{S},I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}}\\quad}&{}\\\\ &{\\qquad=\\frac{P_{M}[T^{*}=t^{*}\\mid I_{i}=1]\\,\\sum_{y\\in\\mathcal{S}}P_{M}[Y_{i}=y\\mid T^{*}=t^{*},I_{i}=1]}{P_{M}[Y_{i}\\in\\mathcal{S}\\mid I_{i}=1]\\,P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}}\\\\ &{\\qquad=\\frac{P_{M}[T^{*}=t^{*}\\mid I_{i}=1]\\,\\sum_{y\\in\\mathcal{S}}\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}=y,I_{i}=1]P_{M}[Y_{i}=y\\mid I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=1]}}{P_{M}[Y_{i}\\in\\mathcal{S}\\mid I_{i}=1]\\,P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}}\\\\ &{\\qquad=\\frac{\\sum_{y\\in\\mathcal{S}}\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}=y,I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}\\,P_{M}[Y_{i}=y\\mid I_{i}=1]}{P_{M}[Y_{i}\\in\\mathcal{S}\\mid I_{i}=1]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We apply (44) to achieve the left bound in the first expression of (10). ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in{\\cal S},I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}\\ge\\frac{\\sum_{y\\in{\\cal S}}e^{-\\varepsilon}P_{M}[Y_{i}=y\\mid I_{i}=1]}{P_{M}[Y_{i}\\in{\\cal S}\\mid I_{i}=1]}=e^{-\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We achieve the right bound in the first expression of (10) in a similar fashion. ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{P_{\\mathcal M}[T^{*}=t^{*}\\mid Y_{i}\\in\\mathcal S,I_{i}=1]}{P_{\\mathcal M}[T^{*}=t^{*}\\mid I_{i}=0]}\\le\\frac{\\sum_{y\\in\\mathcal S}e^{\\varepsilon}P_{\\mathcal M}[Y_{i}=y\\mid I_{i}=1]}{P_{\\mathcal M}[Y_{i}\\in\\mathcal S\\mid I_{i}=1]}=e^{\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We now turn to the second expression in (10). First note that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in\\mathcal{S},I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\not\\in\\mathcal{S},I_{i}=1]}}\\\\ &{\\qquad\\qquad=\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in\\mathcal{S},I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}\\cdot\\frac{P_{M}[T^{*}=t^{*}\\mid I_{i}=0]}{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\not\\in\\mathcal{S},I_{i}=1]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By applying the bounds in the first expression in (10) to $\\boldsymbol{S}$ and $S^{C}$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{e^{-\\varepsilon}\\leq\\frac{P_{M}\\left[T^{*}=t^{*}\\mid Y_{i}\\in\\mathcal{S},I_{i}=1\\right]}{P_{M}\\left[T^{*}=t^{*}\\mid I_{i}=0\\right]}\\leq e^{\\varepsilon},}\\\\ {e^{-\\varepsilon}\\leq\\frac{P_{M}\\left[T^{*}=t^{*}\\mid Y_{i}\\not\\in\\mathcal{S},I_{i}=1\\right]}{P_{M}\\left[T^{*}=t^{*}\\mid I_{i}=0\\right]}\\leq e^{\\varepsilon}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Thus, to achieve the left inequality in the second expression in (10), ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in S,I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\not\\in S,I_{i}=1]}\\geq e^{-\\varepsilon}\\cdot(e^{\\varepsilon})^{-1}=e^{-2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "To achieve the right inequality in the second expression in (10), ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\in{\\mathcal{S}},I_{i}=1]}{P_{M}[T^{*}=t^{*}\\mid Y_{i}\\not\\in{\\mathcal{S}},I_{i}=1]}\\le e^{\\varepsilon}\\cdot\\left(e^{-\\varepsilon}\\right)^{-1}=e^{2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Theorem 1. Under Assumption $^{\\,l}$ and Assumption 2, if the release of $T^{*}=t^{*}$ satisfies $D P,$ then ", "page_idx": 24}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\leq\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i})p_{i}+e^{-\\varepsilon}(1-p_{i})}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. We begin by applying Bayes\u2019 Theorem to reverse the conditional in the relative risk. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r_{i}(p_{i},q_{i},t^{*})=\\frac{P_{M}\\left[Y_{i}\\in\\mathcal{S},I_{i}=1\\;\\middle|\\;T^{*}=t^{*}\\right]}{P_{M}\\left[Y_{i}\\in\\mathcal{S},I_{i}=1\\right]}}\\\\ &{\\qquad\\qquad=\\frac{\\frac{P_{M}\\left[T^{*}=t^{*}|Y_{i}\\in\\mathcal{S},I_{i}=1\\right]P_{M}\\left[Y_{i}\\in\\mathcal{S},I_{i}=1\\right]}{P_{M}\\left[T^{*}=t^{*}\\right]}}{P_{M}\\left[Y_{i}\\in\\mathcal{S},I_{i}=1\\right]}}\\\\ &{\\qquad\\qquad=\\frac{P_{M}\\left[T^{*}=t^{*}\\;\\middle|\\;Y_{i}\\in\\mathcal{S},I_{i}=1\\right]}{P_{M}\\left[T^{*}=t^{*}\\right]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We may decompose the denominator via the law of total probability. ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{\\mathcal M}[T^{*}=t^{*}]=P_{\\mathcal M}[T^{*}=t^{*}\\ |\\ Y_{i}\\in\\mathcal S,I_{i}=1]\\ P_{\\mathcal M}[Y_{i}\\in\\mathcal S\\ |\\ I_{i}=1]\\ P_{\\mathcal M}[I_{i}=1]}\\\\ &{\\qquad\\qquad\\quad+\\ P_{\\mathcal M}[T^{*}=t^{*}\\ |\\ Y_{i}\\not\\in\\mathcal S,I_{i}=1]\\ P_{\\mathcal M}[Y_{i}\\not\\in\\mathcal S\\ |\\ I_{i}=1]\\ P_{\\mathcal M}[I_{i}=1]}\\\\ &{\\qquad\\qquad\\quad+\\ P_{\\mathcal M}[T^{*}=t^{*}\\ |\\ I_{i}=0]\\ P_{\\mathcal M}[I_{i}=0]}\\\\ &{\\qquad\\quad=P_{\\mathcal M}[T^{*}=t^{*}\\ |\\ Y_{i}\\in\\mathcal S,I_{i}=1]\\ q_{i}p_{i}}\\\\ &{\\qquad\\qquad\\quad+\\ P_{\\mathcal M}[T^{*}=t^{*}\\ |\\ Y_{i}\\not\\in\\mathcal S,I_{i}=1]\\left(1-q_{i}\\right)p_{i}}\\\\ &{\\qquad\\qquad\\quad+\\ P_{\\mathcal M}[T^{*}=t^{*}\\ |\\ I_{i}=0]\\left(1-p_{i}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Using this expansion in the expression for $r_{i}$ and dividing through by the numerator yields ", "page_idx": 24}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})=\\frac{1}{q_{i}p_{i}+\\frac{P_{M}[T^{*}=t^{*}|Y_{i}\\notin S,I_{i}=1]}{P_{M}[T^{*}=t^{*}|Y_{i}\\in S,I_{i}=1]}\\left(1-q_{i}\\right)p_{i}+\\frac{P_{M}[T^{*}=t^{*}|I_{i}=0]}{P_{M}[T^{*}=t^{*}|Y_{i}\\in S,I_{i}=1]}\\left(1-p_{i}\\right)}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Using Lemma 1, we then have ", "page_idx": 24}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\leq\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i})p_{i}+e^{-\\varepsilon}(1-p_{i})}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Theorem 2. For any individual $i$ , fix the prior probabilities, $p_{i}$ and $q_{i}$ , and a desired bound on the relative disclosure risk, $r^{*}(p_{i},q_{i})$ . Define $\\varepsilon_{i}(p_{i},q_{i})$ to be the function. ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon_{i}(p_{i},q_{i})=\\left\\{\\!\\!\\begin{array}{l l}{\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{*}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right),}&{i f0<q_{i}<1;}\\\\ {\\log\\left(\\frac{1-p_{i}}{\\frac{1}{r^{*}(p_{i},1)}-p_{i}}\\right),}&{i f q_{i}=1.}\\end{array}\\ \\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Under the conditions of Theorem $^{\\,l}$ , any statistic $T^{*}=t^{*}$ released under $\\varepsilon$ -DP with $\\varepsilon\\leq\\varepsilon_{i}(p_{i},q_{i})$ will satisfy $r_{i}(p_{i},q_{i},t^{*})\\leq r^{*}(p_{i},q_{i})$ . ", "page_idx": 25}, {"type": "text", "text": "Proof. We begin with the simpler case where $q_{i}=1$ . By Theorem 1, ", "page_idx": 25}, {"type": "equation", "text": "$$\nr_{i}(p_{i},1,t^{*})\\leq\\frac{1}{p_{i}+e^{-\\varepsilon}(1-p_{i})}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since $\\varepsilon\\le\\log\\big((1-p_{i})/(1/r^{*}(p_{i},1)-p_{i})\\big)$ , it follows that $e^{-\\varepsilon}\\geq(1/r^{*}(p_{i},1)\\!-\\!p_{i})/(1\\!-\\!p_{i})$ . Thus, as desired, ", "page_idx": 25}, {"type": "equation", "text": "$$\nr_{i}(p_{i},1,t^{*})\\leq\\frac{1}{p_{i}+\\frac{\\frac{1}{r^{*}(p_{i},1)}-p_{i}}{1-p_{i}}\\left(1-p_{i}\\right)}=\\frac{1}{p_{i}+\\left(\\frac{1}{r^{*}(p_{i},1)}-p_{i}\\right)}=r^{*}(p_{i},1).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Now consider the case where $0<q_{i}<1$ . By Theorem 1, ", "page_idx": 25}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\leq\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i})p_{i}+e^{-\\varepsilon}(1-p_{i})}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\varepsilon\\leq\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{*}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "it follows that ", "page_idx": 25}, {"type": "equation", "text": "$$\ne^{-\\varepsilon}\\geq\\frac{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{\\ast}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}{2p_{i}(1-q_{i})}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Taking the square gives ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{e^{-2\\varepsilon}\\geq\\frac{4p_{i}(1-q_{i})\\left(\\frac{1}{r^{\\ast}(p_{i},q_{i})}-p_{i}q_{i}\\right)+2(1-p_{i})^{2}}{4p_{i}^{2}(1-q_{i})^{2}}\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\\\ {-\\cfrac{2(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{\\ast}(p_{i},q_{i})}-p_{i}q_{i}\\right)}}{4p_{i}^{2}(1-q_{i})^{2}}\\qquad\\qquad\\qquad\\qquad\\qquad\\quad(7}\\\\ {=\\frac{\\frac{1}{r^{\\ast}(p_{i},q_{i})}-p_{i}q_{i}}{p_{i}(1-q_{i})}+\\cfrac{(1-p_{i})^{2}-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{\\ast}(p_{i},q_{i})}-p_{i}q_{i}\\right)}}{2p_{i}^{2}(1-q_{i})^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{c^{-2\\nu}(1-q_{0})\\eta_{1}+c^{-\\nu}(1-p_{1})}\\\\ &{\\geq q_{0}\\hbar+\\frac{q_{0}^{-\\nu}(\\frac{1}{p_{0}(1-q_{0})}-p_{0})}{p_{0}(1-q_{0})}\\cdots\\beta\\eta_{1}}\\\\ &{\\quad+\\frac{(1-p_{0})^{2}-(1-p_{0})\\sqrt{\\left(1-p_{0}\\right)^{2}+4p_{0}(1-q_{0})\\left(\\frac{1}{p_{0}(1-q_{0})}-p_{0}\\right)}}{2p_{0}^{2}(1-q_{0})^{2}}\\cdots(1-q_{0})p}\\\\ &{\\quad+\\frac{\\sqrt{\\left(1-p_{0}\\right)^{2}+4p_{0}(1-q_{0})\\left(\\frac{1}{p_{0}(1-q_{0})}-p_{0}\\right)}-(1-p_{0})}{2p_{0}(1-q_{0})}\\cdots(1-p_{0})}\\\\ &{=q_{0}\\hbar+\\left(\\frac{1}{p_{0}(\\nu_{0},q_{0})}-p_{0}\\alpha\\right)}\\\\ &{\\quad+\\left((1-p_{0})-\\sqrt{(1-p_{0})^{2}+4p_{0}(1-q_{0})\\left(\\frac{1}{p_{0}(1-q_{0})}-p_{0}\\right)}\\right)\\frac{1-p_{0}}{2p_{0}(1-q_{0})}}\\\\ &{\\quad-\\left((1-p_{0})-\\sqrt{(1-p_{0})^{2}+4p_{0}(1-q_{0})\\left(\\frac{1}{p_{0}(1-q_{0})}-p_{0}\\right)}\\right)\\frac{1-p_{0}}{2p_{0}(1-q_{0})}}\\\\ &{=\\frac{p_{0}}{p_{0}(1-p_{0})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "It is then immediate that ", "page_idx": 26}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\le\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i})p_{i}+e^{-\\varepsilon}(1-p_{i})}\\le\\frac{1}{\\frac{1}{r^{*}(p_{i},q_{i})}}=r^{*}(p_{i},q_{i}).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Corollary 1. Under the conditions of Theorem $^{\\,l}$ , for all $p_{i},q_{i}\\in(0,1]$ and all $t^{*}$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\le e^{2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. First note that since, $0\\leq e^{-\\varepsilon}\\leq1$ , it follows that $e^{-2\\varepsilon}\\leq e^{-\\varepsilon}$ . Then, applying the result of Theorem 1, ", "page_idx": 27}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\le\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i})p_{i}+e^{-\\varepsilon}(1-p_{i})}\\le\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i})p_{i}+e^{-2\\varepsilon}(1-p_{i})}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Combining terms and using the fact that $q_{i}p_{i}\\geq0$ gives ", "page_idx": 27}, {"type": "equation", "text": "$$\nr_{i}(p_{i},q_{i},t^{*})\\le\\frac{1}{q_{i}p_{i}+e^{-2\\varepsilon}(1-q_{i}p_{i})}\\le\\frac{1}{e^{-2\\varepsilon}+q_{i}p_{i}(1-e^{-2\\varepsilon})}\\le\\frac{1}{e^{-2\\varepsilon}+0}=e^{2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Corollary 2. Under the conditions of Theorem 2, if $p_{i}\\,=\\,1\\,$ and $0\\,<\\,q_{i}\\,<\\,1$ , then any statistic $T^{*}=t^{*}$ released under $\\varepsilon{-}D P$ with ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\varepsilon\\leq\\frac{1}{2}\\log\\left(\\frac{1-q_{i}}{\\frac{1}{r^{*}(1,q_{i})}-q_{i}}\\right),\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "will satisfy $r_{i}(1,q_{i},t^{*})\\leq r^{*}(1,q_{i})$ . ", "page_idx": 27}, {"type": "text", "text": "Proof. Plugging $p_{i}=1$ into the expression from Theorem 2 yields ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon\\leq\\log\\left(\\frac{2\\left(1-q_{i}\\right)}{\\sqrt{0+4(1-q_{i})\\left(\\frac{1}{r^{\\ast}(1,q_{i})}-q_{i}\\right)}-0}\\right)}\\\\ &{\\ =\\log\\left(\\sqrt{\\frac{1-q_{i}}{\\frac{1}{r^{\\ast}(1,q_{i})}-q_{i}}}\\right)}\\\\ &{\\ =\\frac{1}{2}\\log\\left(\\frac{1-q_{i}}{\\frac{1}{r^{\\ast}(1,q_{i})}-q_{i}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Lemma 2. Fix $p_{i},q_{i}\\in(0,1)$ and let $r^{*}(p_{i},q_{i})=\\tilde{a}/(p_{i}q_{i})$ . Then the function ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\varepsilon(p_{i},q_{i})=\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{*}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "has partial derivatives such that ", "page_idx": 28}, {"type": "text", "text": "Proof. To begin, we re-express the function of interest in the form ", "text_level": 1, "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\varepsilon(p_{i},q_{i})=\\log\\left(2p_{i}(1-q_{i})\\right)-\\log\\left(\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{p_{i}q_{i}}{\\tilde{a}}-p_{i}q_{i}\\right)}-(1-p_{i})\\right)}\\\\ &{}&{=\\log\\left(2p_{i}(1-q_{i})\\right)-\\log\\left(\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}q_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)}-(1-p_{i})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We first examine $\\partial\\varepsilon(p_{i},q_{i})/\\partial p_{i}$ . Taking the partial derivative with respect to $q_{i}$ gives ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{\\partial\\left(P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}\\otimes P_{j-1}}&{}\\\\ {-\\frac{1}{P_{j}}+\\frac{((-P_{j})^{2}+4)((P_{j})^{2}+4)(((-P_{j})^{2}+4)((-P_{j})^{2}+4)(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_{j})^{2}+4(P_ \n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Certainly, the denominator of (94) is positive. Thus, $\\partial\\varepsilon(p_{i},q_{i})/\\partial p_{i}<0$ , as desired. ", "page_idx": 28}, {"type": "text", "text": "We now examine $\\partial\\varepsilon(p_{i},q_{i})/\\partial q_{i}$ . Taking the partial derivative with respect to $q_{i}$ gives ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\left(\\overline{{p}}_{i},\\,q_{i}\\right)}{\\partial q_{i}}=-\\frac{1}{1-\\,q_{i}}-\\frac{\\frac{4p_{i}^{2}\\left(\\frac{1}{4}-1\\right)\\overline{{\\rho}}_{i}^{2}\\left(q_{i}\\left(1-q_{i}\\right)\\right)}{2\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)}}}{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)}-\\left(1-p_{i}\\right)}\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\\\ &{\\quad=-\\frac{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)}-\\left(1-p_{i}\\right)+\\frac{2p_{i}^{2}\\left(\\frac{1}{4}-1\\right)\\left(1-q_{i}\\right)}{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)}}}{\\left(1-\\,q_{i}\\right)\\left[\\sqrt{\\left(1-p_{i}\\right)^{2}+4^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)}-\\left(1-p_{i}\\right)\\right]}\\qquad\\qquad\\qquad\\quad}\\\\ &{\\quad=-\\frac{\\frac{\\left(1-p_{i}\\right)^{2}+4p_{i}^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)-\\left(1-p_{i}\\right)^{2}+4p_{i}^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)}{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}^{2}q_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{4}-1\\right)}+2p_{i}^{2}\\left(\\frac{1}{4}-1\\right)\\left(1-q_{i}\\right)\\frac{\\rho}{\\rho_{i}}\\left[q_{i}\\left(1-q_{i}\\right)\\right]}}{\\left(1-\\,q_{i}\\right)\\left[\\sqrt{\\left(\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Consider the three parts of (97). Since $\\tilde{a}<1$ , we have that in the denominator of the numerator, $\\begin{array}{r}{\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}q_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)}>0}\\end{array}$ . The denominator is also positive, since $(1-q_{i})>0$ and ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\left[\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}q_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)}-(1-p_{i})\\right]>\\left[\\sqrt{(1-p_{i})^{2}}-(1-p_{i})\\right]=0.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "This leaves the numerator of the numerator of (97). Let us denote this expression as $g(q_{i})$ . If $g(q_{i})\\,>\\,0$ , then it follows that $\\partial\\varepsilon(p_{i},q_{i})/\\partial q_{i}\\;<\\;0$ . To show this, we begin by simplifying the expression for $g(q_{i})$ : ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{g(q_{i})=(1-p_{i})^{2}+4p_{i}^{2}q_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}q_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)}\\quad}\\\\ &{}&{+\\,2p_{i}^{2}\\left(\\frac{1}{\\tilde{a}}-1\\right)(1-q_{i})\\frac{\\partial}{\\partial q_{i}}\\left[q_{i}(1-q_{i})\\right]\\quad}\\\\ &{}&{=(1-p_{i})^{2}+2p_{i}^{2}(1-q_{i})(2q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}(1-q_{i})q_{i}\\left(\\frac{1}{\\tilde{a}}-1\\right)}\\quad}\\\\ &{}&{+\\,2p_{i}^{2}(1-q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)(1-2q_{i})\\quad}\\\\ &{}&{(104)}\\\\ &{}&{=(1-p_{i})^{2}-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}(1-q_{i})q_{i}\\left(\\frac{1}{\\tilde{a}}-1\\right)}\\quad}\\\\ &{}&{\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Taking the derivative of $g$ , we find that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\frac{\\partial g(q_{i})}{\\partial q_{i}}=-(1-p_{i})\\,\\frac{4p_{i}^{2}(1-2q_{i})\\left(\\frac{1}{\\tilde{a}}-1\\right)}{2\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}(1-q_{i})q_{i}\\left(\\frac{1}{\\tilde{a}}-1\\right)}}-2p_{i}^{2}\\left(\\frac{1}{\\tilde{a}}-1\\right)}\\\\ &{}&{=-2p_{i}^{2}\\left(\\frac{1}{\\tilde{a}}-1\\right)\\left[(1-p_{i})\\,\\frac{1-2q_{i}}{\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}(1-q_{i})q_{i}\\left(\\frac{1}{\\tilde{a}}-1\\right)}}+1\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "For $0<q_{i}\\leq1/2,1-2q_{i}\\geq0$ and so $\\partial g(q_{i})/\\partial q_{i}<0$ . For $1/2<q_{i}<1$ , since $2q_{i}-1<1$ and $\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}(1-q_{i})q_{i}\\left(1/\\tilde{a}-1\\right)}>1-p_{i}$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\partial g(q_{i})}{\\partial q_{i}}=-2p_{i}^{2}\\left(\\frac{1}{\\tilde{a}}-1\\right)\\left[1-\\left(1-p_{i}\\right)\\frac{2q_{i}-1}{\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}(1-q_{i})q_{i}\\left(\\frac{1}{\\tilde{a}}-1\\right)}}\\right]}\\\\ {\\displaystyle<-2p_{i}^{2}\\left(\\frac{1}{\\tilde{a}}-1\\right)\\left[1-\\left(1-p_{i}\\right)\\frac{1}{1-p_{i}}\\right]}\\\\ {\\displaystyle<0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Thus, $g(q_{i})$ strictly decreasing as a function of $q_{i}$ on $0<q_{i}<1$ . Since ", "page_idx": 30}, {"type": "equation", "text": "$$\ng\\left(1\\right)=(1-p_{i})^{2}-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}^{2}(1-1)1\\left(\\frac{1}{\\tilde{a}}-1\\right)}+2p_{i}^{2}(1-1)\\left(\\frac{1}{\\tilde{a}}-1\\right)=0,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "it follows that $g(q_{i})>0$ for $0<q_{i}<1$ and so $\\partial\\varepsilon(p_{i},q_{i})/\\partial q_{i}<0$ in this range. ", "page_idx": 30}, {"type": "text", "text": "Lemma 3. Fix $p_{i},q_{i}\\in(0,1)$ and let $r^{*}(p_{i},q_{i})=\\tilde{r}<1/(p_{i}q_{i})$ . Then the function ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\varepsilon(p_{i},q_{i})=\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{r^{\\ast}(p_{i},q_{i})}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right)\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "has partial derivatives such that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\partial\\varepsilon(p_{i},q_{i})}{\\partial p_{i}}<0\\;i f0<q_{i}<\\frac{1}{\\tilde{r}+1}\\;a n d\\,0<p_{i}<1}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\partial\\varepsilon(p_{i},q_{i})}{\\partial p_{i}}=0\\;i f q_{i}=\\frac{1}{\\tilde{r}+1}\\;a n d\\,0<p_{i}<1}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\partial\\varepsilon(p_{i},q_{i})}{\\partial p_{i}}>0\\;i f\\frac{1}{\\tilde{r}+1}<q_{i}<1\\;a n d\\,0<p_{i}<\\frac{1}{q_{i}\\tilde{r}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\partial\\varepsilon(p_{i},q_{i})}{\\partial q_{i}}>0\\;i f0<p_{i}<1\\,a n d\\,0<q_{i}<\\frac{1}{p_{i}\\tilde{r}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. To begin, we re-express the function of interest in the form ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\varepsilon(p_{i},q_{i})=\\log\\left(2p_{i}(1-q_{i})\\right)-\\log\\left(\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}-(1-p_{i})\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We now examine $\\partial\\varepsilon(p_{i},q_{i})/\\partial p_{i}$ . Taking the partial derivative of with respect to $p_{i}$ and simplifying gives ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{C(P_{k},q)}{\\partial q_{k}}=}&{\\frac{1}{{\\displaystyle\\frac{q}{\\sqrt{1+\\beta}}\\left(1-p\\right)^{2}+4p_{k}(1-p)\\left(1-p\\right)}+1}+1}\\\\ &{=\\frac{1}{{\\displaystyle\\frac{q}{\\sqrt{1+\\beta}}\\left(1-p\\right)^{2}+4p_{k}(1-p)\\left(1-p\\right)-(1-p)}}-1}\\\\ &{=\\frac{1}{{\\displaystyle\\frac{q}{\\sqrt{1+\\beta}}\\frac{\\frac{1}{2}\\left(1-p\\right)+4p_{k}(1-p)-4p_{k}(1-p)\\left(1-p\\right)+(4p_{k}(1-p)+4p_{k}(1-p\\right)}{2p_{k}(1-p)+4p_{k}(1-p)+4p_{k}(1-p\\right)}}}}\\\\ &{=\\frac{1}{{\\displaystyle\\frac{q-p^{2}+4p_{k}(1-p\\right)+4p_{k}(1-p\\right)+4p_{k}(1-p\\left(1-p\\right)\\left(1-p\\right))}{p_{k}(1-p)+4p_{k}(1-p\\right)+4p_{k}(1-p\\right)+4p_{k}(1-p\\right)}}}}\\\\ &{=\\frac{1}{{\\displaystyle\\frac{q-p^{2}+4p_{k}(1-p\\right)+4p_{k}(1-p\\left(1-p\\right)+4p_{k}(1-p\\right)+4p_{k}(1-p\\right)}{p_{k}(1-p)+4p_{k}(1-p\\right)}}}}\\\\ &{\\quad+\\frac{{\\displaystyle\\frac{q(1-p)-3p_{k}(1-p\\mid(1-p\\right)+4p_{k}(1-p\\mid(1-p\\mid)+4p_{k}(1-p\\mid))}{p_{k}(1-p)+4p_{k}(1-p\\mid(1-p\\mid))-(1-p\\mid)}}}{{\\displaystyle\\frac{p+4p_{k}(1-p\\mid(1-p\\mid)+4p_{k}(1-p\\mid)-4p_{k}(1-p\\mid))}{p_{k}(1-p\\mid(1-p\\mid)-(1-p\\mid))-(1-p\\mid)}}}}\\\\ &{=\\frac{1}{{\\displaystyle\\frac{q(1-p\\mid+4p_{k}(1-p\\mid)+4p_{k}(1-p\\mid(1-p\\mid)+4p_{k}(1-p\\mid))-(1-p\\mid(1-p\\mid))}{p_{k}(1-p\\mid(1-\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n=\\frac{2p_{i}(1-q_{i})\\frac{1}{\\bar{r}}+(1-p_{i})-\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}}{p_{i}\\left[\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}-(1-p_{i})\\right]\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We can rearrange the expression in (114) to the following form. ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\frac{\\partial\\varepsilon(p_{i},q_{i})}{\\partial p_{i}}=\\frac{\\frac{2p_{i}(1-q_{i})\\frac{1}{\\bar{r}}}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\big(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\big)}-(1-p_{i})}-1}{p_{i}\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The denominator of (115) is certainly always positive, so the sign of $\\partial\\varepsilon(p_{i},q_{i})/\\partial p_{i}$ is determined by the sign of the numerator. To determine the sign, we will use the following equality. ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2p_{i}(1-q_{i})\\frac{1}{\\tilde{r}}}\\\\ &{\\quad=\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)+4p_{i}^{2}(1-q_{i})\\frac{\\tilde{r}^{2}-1}{\\tilde{r}^{2}}\\left(q_{i}-\\frac{1}{\\tilde{r}+1}\\right)}-(1-p_{i}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "To demonstrate that (116) holds, note the following. ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\bigg(2p_{t}(1-q)\\frac{1}{r}+(1-p_{t})\\bigg)^{2}=4p_{t}^{2}(1-q)^{\\frac{1}{\\rho}}\\frac{1}{r^{2}}+4p_{t}(1-p_{t})(1-q)\\frac{1}{r}+(1-p_{t})^{2}}&{\\quad{\\mathrm{(II)}}}\\\\ {=4p_{t}^{2}(1-q)\\frac{1}{r^{2}}+4p_{t}(1-p_{t})(1-q)\\frac{1}{r}-4p_{t}^{2}(1-q)\\frac{1}{r^{2}}-2\\left(q-\\frac{1}{r}+\\right)}\\\\ {\\quad}&{+4p_{t}^{2}(1-q)\\frac{1}{r^{2}}-1\\left(q-\\frac{1}{r}\\right)+(1-p_{t})^{2}}\\\\ {=4p_{t}(1-q)\\left[p_{t}(1-q)\\frac{1}{r^{2}}+(1-p_{t})\\frac{1}{r}-2\\nu_{t}\\frac{1}{r^{2}}\\right]\\bigg(q-\\frac{1}{r}+\\bigg)\\right]}\\\\ &{\\quad\\quad+4p_{t}^{2}(1-q)\\frac{1}{r^{2}}-1\\left(q-\\frac{1}{r}+\\right)+(1-p_{t})^{2}}\\\\ {=4p_{t}(1-q)\\left[\\frac{1}{r}+p_{t}\\left(\\frac{1}{r^{2}}-\\frac{1}{r}+\\frac{1}{r^{2}-1}\\right)-p_{t}\\big(\\frac{1}{r^{2}}+\\frac{p^{2}-1}{r^{2}}\\big)\\right]}&{\\quad{\\mathrm{(II)}}}\\\\ &{\\quad\\quad+4p_{t}(1-q)\\frac{1}{r}-\\beta\\left(q-\\frac{1}{r}+\\frac{1}{r}-\\frac{1}{r}\\right)+\\mathcal{O}(\\Big(\\frac{1}{r^{2}}+\\frac{p^{2}-1}{r^{2}}\\Big)\\right]}\\\\ &{\\quad\\quad\\quad+4q_{t}^{2}(1-q)\\frac{1}{r^{2}}-1\\left(q-\\frac{1}{r}+\\frac{1}{r}\\right)+(1-p_{t})^{2}}\\\\ {=4p_{t}(1-q)\\left(\\frac{1}{r}-p_{t}\\right)+4q_{t}^{2}(1-q)\\frac{1}{\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Rearranging (121) gives (116). ", "page_idx": 32}, {"type": "text", "text": "Now note that, from (116), if $q_{i}=1/(\\tilde{r}+1)$ , then ", "page_idx": 32}, {"type": "equation", "text": "$$\n2p_{i}(1-q_{i})\\frac{1}{\\tilde{r}}=\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}-(1-p_{i}).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "It follows that the ratio in the numerator of (115) equals 1 and thus $\\partial\\varepsilon(p_{i},q_{i})/\\partial p_{i}=0$ . If $0<q_{i}<$ $\\textstyle{\\frac{1}{{\\tilde{r}}+1}}$ , then the term $4p_{i}^{2}(1-q_{i})(\\tilde{r}^{2}-1)/\\tilde{r}^{2}(q_{i}-1/(\\tilde{r}+1))<0$ and so ", "page_idx": 32}, {"type": "equation", "text": "$$\n2p_{i}(1-q_{i})\\frac{1}{\\tilde{r}}<\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}-(1-p_{i}).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "It follows that the ratio in the numerator of (115) is less than 1 and thus $\\partial\\varepsilon(p_{i},q_{i})/\\partial p_{i}\\,<\\,0$ . If $\\begin{array}{r}{\\frac{1}{\\tilde{r}+1}<q_{i}<1}\\end{array}$ , then the term $4p_{i}^{2}(1-q_{i})(\\tilde{r}^{2}-1)/\\tilde{r}^{2}(q_{i}-1/(\\tilde{r}+1))>0$ and so ", "page_idx": 32}, {"type": "equation", "text": "$$\n2p_{i}(1-q_{i})\\frac{1}{\\tilde{r}}>\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}-(1-p_{i}).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "It follows that the ratio in the numerator of (115) is greater than 1 and thus $\\partial\\varepsilon(p_{i},q_{i})/\\partial p_{i}>0$ . ", "page_idx": 32}, {"type": "text", "text": "We now examine $\\partial\\varepsilon(p_{i},q_{i})/\\partial q_{i}$ . Taking the partial derivative of with respect to $q_{i}$ gives ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\partial\\underline{{c}}(p_{i},q_{i})}{\\partial q_{i}}=-\\frac{1}{1-q_{i}}-\\frac{\\frac{4p_{i}\\frac{p_{i}}{p_{i}}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)}{2\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)}}}{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)}}\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad(125)}\\\\ &{\\qquad=-\\frac{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)}-\\left(1-p_{i}\\right)+\\frac{2p_{i}\\left(1-q_{i}\\right)\\frac{\\partial}{p_{i}}\\left[\\left(1-q_{i}\\right)\\left(\\frac{1}{q}-p_{i}q_{i}\\right)\\right]}{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)}}}{\\left(1-q_{i}\\right)\\left[\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)}-\\left(1-p_{i}q_{i}\\right)\\right]}\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad(126)}\\\\ &{\\qquad=-\\frac{\\frac{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)-\\left(1-p_{i}\\right)\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)}+2p_{i}\\left(1-q_{i}\\right)\\frac{\\partial}{p_{i}}\\left[\\left(1-q_{i}\\right)\\left(\\frac{1}{p}-p_{i}q_{i}\\right)\\right]}{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac \n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Consider the three parts of (127). Since $\\tilde{r}<1/(p_{i}q_{i})$ , it follows that $\\left(1/\\tilde{r}-p_{i}q_{i}\\right)>0$ . Thus, in the denominator of the numerator, $\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(1/\\tilde{r}-p_{i}q_{i}\\right)}>0$ . The denominator is also positive, since $\\left(1-q_{i}\\right)>0$ and ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\left[\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}-(1-p_{i})\\right]>\\left[\\sqrt{(1-p_{i})^{2}}-(1-p_{i})\\right]=0.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "This leaves the numerator of the numerator of (127). Let us denote this expression as $g(q_{i})$ . If $g(q_{i})\\,<\\,0$ , then it follows that $\\partial\\varepsilon(p_{i},q_{i})/\\partial q_{i}\\;>\\;0$ . To show this, we begin by simplifying the expression for $g(q_{i})$ : ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{g(q_{i})=(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}}&\\\\ &{}&{+2p_{i}(1-q_{i})\\frac{\\partial}{\\partial q_{i}}\\left[(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)\\right]}\\\\ &{}&{=(1-p_{i})^{2}+2p_{i}(1-q_{i})\\left(\\frac{2}{\\tilde{r}}-2p_{i}q_{i}\\right)-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}}\\\\ &{}&{+\\;2p_{i}(1-q_{i})\\left(2p_{i}q_{i}-p_{i}-\\frac{1}{\\tilde{r}}\\right)}&{(13(}\\\\ &{}&{\\qquad=(1-p_{i})^{2}-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}+2p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Taking the derivative of $g$ , we find that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\frac{\\partial g(q_{i})}{\\partial q_{i}}=-(1-p_{i})\\,\\frac{4p_{i}\\,\\left(2p_{i}q_{i}-p_{i}-\\frac{1}{\\tilde{r}}\\right)}{2\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}}-2p_{i}\\left(\\frac{1}{\\tilde{r}}-p_{i}\\right)}\\\\ &{}&{=2p_{i}\\,\\left[(1-p_{i})\\,\\frac{2p_{i}(1-q_{i})+\\left(\\frac{1}{\\tilde{r}}-p_{i}\\right)}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)}}-\\left(\\frac{1}{\\tilde{r}}-p_{i}\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Note that since $\\begin{array}{r}{\\tilde{r}<\\frac{1}{p_{i}q_{i}}}\\end{array}$ , it follows that $\\begin{array}{r}{\\left(\\frac{1}{\\tilde{r}}-p_{i}q_{i}\\right)>0}\\end{array}$ and $\\begin{array}{r}{p_{i}(1-q_{i})>p_{i}-\\frac{1}{r}}\\end{array}$ . Thus, ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\partial g(q_{i})}{\\partial q_{i}}=2p_{i}\\left[\\left(1-p_{i}\\right)\\frac{2p_{i}(1-q_{i})-\\left(p_{i}-\\frac{1}{\\bar{r}}\\right)}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}}+\\left(p_{i}-\\frac{1}{\\bar{r}}\\right)\\right]}\\\\ {\\displaystyle~~>2p_{i}\\left[\\left(1-p_{i}\\right)\\frac{\\left(p_{i}-\\frac{1}{\\bar{r}}\\right)}{\\sqrt{(1-p_{i})^{2}}}+\\left(p_{i}-\\frac{1}{\\bar{r}}\\right)\\right]}\\\\ {\\displaystyle~~=4p_{i}\\left(p_{i}-\\frac{1}{\\bar{r}}\\right)}\\\\ {\\displaystyle~~>0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Thus, $g(q_{i})$ is strictly increasing for $\\tilde{r}<1/(p_{i}q_{i})$ . Note that in terms of $q_{i}$ , this is equivalent to the range $0<q_{i}<1/(p_{i}\\tilde{r})$ . Since ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{g\\left(\\frac{1}{p_{i}\\tilde{r}}\\right)}&{=2p_{i}\\left(1-p_{i}\\right)}\\\\ &{}&{=(1-p_{i})^{2}-(1-p_{i})\\sqrt{(1-p_{i})^{2}+4p_{i}(1-\\frac{1}{p_{i}\\tilde{r}})\\left(\\frac{1}{\\tilde{r}}-p_{i}\\frac{1}{p_{i}\\tilde{r}}\\right)}+2p_{i}\\left(1-\\frac{1}{p_{i}\\tilde{r}}\\right)\\left(\\frac{1}{\\tilde{r}}-p_{i}\\right)}\\\\ &{}&{=2p_{i}\\left(1-\\frac{1}{p_{i}\\tilde{r}}\\right)\\left(\\frac{1}{\\tilde{r}}-p_{i}\\right)}\\\\ &{}&{=2p_{i}\\left(1-\\frac{1}{p_{i}\\tilde{r}}\\right)\\left(\\frac{1}{\\tilde{r}}-p_{i}\\right)}\\\\ &{}&{\\cdots}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "it follows that $g(q_{i})\\,<\\,0$ for $0\\;<\\;q_{i}\\;<\\;1/(p_{i}\\tilde{r})$ . Thus, as desired, $\\partial\\varepsilon(p_{i},q_{i})/\\partial q_{i}\\;>\\;0$ in this range. \u53e3 ", "page_idx": 34}, {"type": "text", "text": "Theorem 3. Under the conditions of Theorem 2, $\\colon f\\,r^{*}(p_{i},q_{i})=\\tilde{r}>1,$ , the solution to the minimization problem in $(I3)$ is ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\varepsilon=\\frac12\\log\\left(\\tilde{r}\\right).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof. We define $\\varepsilon(p_{i},q_{i})$ as follows. ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon(p_{i},q_{i})=\\left\\{\\!\\!\\!\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right),\\quad\\mathrm{if~}0<q_{i}<1;}\\\\ {\\log\\left(\\frac{1-p_{i}}{\\frac{1}{\\bar{r}}-p_{i}}\\right),\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\mathrm{if~}q_{i}=1.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The solution to the minimization problem in (13) corresponds to the minimum of $\\varepsilon(p_{i},q_{i})$ over $(0,1]\\times(0,1]$ . Lemma 3 implies that $\\partial\\varepsilon(p_{i},q_{i})/\\partial q_{i}\\neq0$ for any $0<q_{i}<1$ . This means that this function must take its minimum value around its boundary, i.e., when $p_{i}=1,\\,q_{i}=1,\\,p_{i}\\to0$ , or $q_{i}\\to0$ . We examine each of these in turn. ", "page_idx": 35}, {"type": "text", "text": "We begin with the boundary where $p_{i}=1$ . By Corollary 2, for $0<q_{i}<1$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\varepsilon(1,q_{i})=\\frac{1}{2}\\log\\left(\\frac{1-q_{i}}{\\frac{1}{\\tilde{r}}-q_{i}}\\right).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We take the partial derivative of this function with respect to $q_{i}$ . ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\frac{\\partial\\varepsilon(1,q_{i})}{\\partial q_{i}}=\\frac{1}{2}\\left[-\\frac{1}{1-q_{i}}+\\frac{1}{\\frac{1}{\\tilde{r}}-q_{i}}\\right].\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Since $1/\\tilde{r}<1$ , it follows that $\\partial\\varepsilon(1,q_{i})/\\partial q_{i}>0$ for all $0<q_{i}<1$ . Thus, the minimum occurs as $q_{i}\\to0$ and is ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{q_{i}\\to0}\\varepsilon(1,q_{i})=\\frac{1}{2}\\log(\\tilde{r}).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We next examine with the boundary where $q_{i}=1$ . When $0<p_{i}<1$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\varepsilon(p_{i},1)=\\log\\left(\\frac{1-p_{i}}{\\frac{1}{\\tilde{r}}-p_{i}}\\right).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We take the partial derivative of this function with respect to $p_{i}$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\frac{\\partial\\varepsilon(p_{i},1)}{\\partial p_{i}}=-\\frac{1}{1-p_{i}}+\\frac{1}{\\frac{1}{\\tilde{r}}-p_{i}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Since $1/\\tilde{r}<1$ , it follows that $\\partial\\varepsilon(p_{i},1)/\\partial p_{i}>0$ for all $0<p_{i}<1$ . Thus, the minimum occurs as $p_{i}\\to0$ and is ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{p_{i}\\to0}\\varepsilon(p_{i},1)=\\log(\\tilde{r}).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We next examine the boundary where $p_{i}\\to0$ . Since the logarithm is a continuous function, for all $0<q_{i}<1$ , ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\underset{p_{i}\\rightarrow0}{\\operatorname*{lim}}\\varepsilon(p_{i},q_{i})=\\underset{p_{i}\\rightarrow0}{\\operatorname*{lim}}\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right)}\\\\ &{}&{=\\log\\left(\\underset{p_{i}\\rightarrow0}{\\operatorname*{lim}}\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Using L\u2019H\u00f4pital\u2019s Rule, ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{p_{i}\\rightarrow0}{\\operatorname*{lim}}\\varepsilon(p_{i},q_{i})=\\log\\left(\\underset{p_{i}\\rightarrow0}{\\operatorname*{lim}}\\frac{2\\left(1-q_{i}\\right)}{\\frac{-2\\left(1-p_{i}\\right)+4\\left(1-q_{i}\\right)\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)-4p_{i}q_{i}\\left(1-q_{i}\\right)}{2\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}\\left(1-q_{i}\\right)\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}}+1}\\right)}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\log\\left(\\frac{2\\left(1-q_{i}\\right)}{\\frac{-1+2\\left(1-q_{i}\\right)\\left(\\frac{1}{\\bar{r}}\\right)}{\\sqrt{1}}+1}\\right)=\\log(\\tilde{r}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Finally, we examine the boundary where $q_{i}\\to0$ . For all $0<p_{i}\\le1$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{q_{i}\\rightarrow0}\\varepsilon(p_{i},q_{i})=\\operatorname*{lim}_{q_{i}\\rightarrow0}\\log\\left(\\frac{2p_{i}(1-q_{i})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-q_{i})\\left(\\frac{1}{\\bar{r}}-p_{i}q_{i}\\right)}-(1-p_{i})}\\right)\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "We take the partial derivative with respect to $p_{i}$ . From (115) in the proof of Lemma 3, we have that ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\partial}{\\partial p_{i}}\\left(\\underset{q_{i}\\rightarrow0}{\\operatorname*{lim}}\\varepsilon(p_{i},q_{i})\\right)=\\frac{\\partial}{\\partial p_{i}}\\left(\\log\\left(\\frac{2p_{i}}{\\sqrt{(1-p_{i})^{2}+4p_{i}\\left(\\frac{1}{\\bar{r}}-p_{i}\\right)}-(1-p_{i})}\\right)\\right)}\\\\ &{\\qquad\\qquad=\\frac{\\frac{2p_{i}\\frac{1}{\\bar{r}}}{\\sqrt{(1-p_{i})^{2}+4p_{i}\\left(\\frac{1}{\\bar{r}}\\right)-(1-p_{i})}}-1}{p_{i}\\sqrt{(1-p_{i})^{2}+4p_{i}\\left(\\frac{1}{\\bar{r}}\\right)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "By (116) with $\\begin{array}{r l r}{q_{i}}&{{}=}&{0}\\end{array}$ , the ratio in the numerator of (156) is less than 1 and so $\\partial/\\partial p_{i}\\left(\\operatorname*{lim}_{q_{i}\\to0}\\varepsilon(p_{i},q_{i})\\right)$ is negative for all $0\\,<\\,p_{i}\\,\\leq\\,1$ . Thus, the minimum occurs at $p_{i}\\,=\\,1\\,$ and is as in (145). The global minimum of $\\varepsilon(p_{i},q_{i})$ is thus $1/2\\log(\\tilde{r})$ . \u53e3 ", "page_idx": 36}, {"type": "text", "text": "Theorem 4. Under the conditions of Theorem 2, let $\\tilde{a}<1$ , $\\tilde{p}\\leq1$ , and $\\tilde{r}>1$ , and $0<q_{i}\\le1$ . If the function $r^{*}$ is such that $r^{*}(\\tilde{p},q_{i})=\\operatorname*{max}\\{\\tilde{a}/(\\tilde{p}q_{i}),\\tilde{r}\\}$ and $r^{*}(p_{i},q_{i})=\\infty\\,i f\\,p_{i}\\neq\\tilde{p}_{*}$ , then the solution to the minimization problem in (13) is ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon=\\left\\{\\log\\left(\\frac{\\tilde{a}(1-\\tilde{p})}{\\tilde{p}(1-\\tilde{a})}\\right),\\quad}&{i f0<\\tilde{p}\\leq\\frac{\\tilde{a}}{\\tilde{r}};}\\\\ {\\log\\left(\\frac{2(\\tilde{p}\\tilde{r}-\\tilde{a})}{\\sqrt{\\tilde{r}^{2}(1-\\tilde{p})^{2}+4(\\tilde{p}\\tilde{r}-\\tilde{a})(1-\\tilde{a})}-\\tilde{r}(1-\\tilde{p})}\\right),\\quad i f\\frac{\\tilde{a}}{\\tilde{r}}<\\tilde{p}\\leq1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Proof. We define $\\varepsilon(q_{i})$ as follows. ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon(q_{i})=\\left\\{\\begin{array}{l l}{\\log\\left(\\frac{2\\widetilde{p}(1-q_{i})}{\\sqrt{(1-\\widetilde{p})^{2}+4\\widetilde{p}(1-q_{i})\\left(\\frac{1}{r^{*}(\\widetilde{p},q_{i})}-\\widetilde{p}q_{i}\\right)}-(1-\\widetilde{p})}\\right),}&{\\mathrm{~if~}0<q_{i}<1;}\\\\ {\\log\\left(\\frac{1-\\widetilde{p}}{\\frac{1}{r^{*}(\\widetilde{p},q_{i})}-\\widetilde{p}}\\right),}&{\\mathrm{~if~}q_{i}=1.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "The solution to the minimization problem in (13) corresponds to the minimum of $\\varepsilon(q_{i})$ over $(0,1]$ . ", "page_idx": 37}, {"type": "text", "text": "We begin with the case where $0<\\tilde{p}\\leq\\tilde{a}/\\tilde{r}$ . In this setting, we have that $\\tilde{r}\\,\\leq\\,\\tilde{a}/\\tilde{p}\\,\\leq\\,\\tilde{a}/(\\tilde{p}q_{i})$ , so $r^{*}(\\tilde{p},\\tilde{q_{i}})=\\tilde{a}/(\\tilde{p}q_{i})$ for all $q_{i}$ . By Lemma 2, $\\varepsilon(q_{i})$ is a decreasing function of $q_{i}$ , so the minimum occurs at $q_{i}=1$ and is ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\varepsilon(1)=\\log\\left(\\frac{1-\\tilde{p}}{\\frac{1}{r^{*}(\\tilde{p},1)}-\\tilde{p}}\\right)=\\log\\left(\\frac{1-\\tilde{p}}{\\frac{\\tilde{p}}{\\tilde{a}}-\\tilde{p}}\\right)=\\log\\left(\\frac{\\tilde{a}(1-\\tilde{p})}{\\tilde{p}(1-\\tilde{a})}\\right).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "We now consider the case where $\\tilde{a}/\\tilde{r}<\\tilde{p}\\leq1$ . Note that $\\tilde{r}\\geq\\tilde{a}/(\\tilde{p}q_{i})$ whenever $q_{i}\\geq\\tilde{a}/(\\tilde{p}\\tilde{r})$ . Since in this setting $\\tilde{a}/(\\tilde{p}\\tilde{r})<1$ , the risk bound can be written in piece-wise form ", "page_idx": 37}, {"type": "equation", "text": "$$\nr^{*}(\\tilde{p},q_{i})=\\left\\{\\!\\!\\begin{array}{l l}{\\frac{\\tilde{a}}{\\tilde{p}q_{i}},}&{\\mathrm{~if~}0<q_{i}<\\frac{\\tilde{a}}{\\tilde{p}\\tilde{r}};}\\\\ {\\tilde{r},}&{\\mathrm{~if~}\\frac{\\tilde{a}}{\\tilde{p}\\tilde{r}}\\leq q_{i}<1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Note that if $q_{i}\\geq1/(\\tilde{r}\\tilde{p})$ , then $\\tilde{r}\\geq1/(\\tilde{p}q_{i})$ . Thus, $r^{*}(\\tilde{p},q_{i})\\geq\\tilde{r}\\geq1/(\\tilde{p}q_{i})$ and so ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sqrt{(1-\\tilde{p})^{2}+4\\tilde{p}(1-q_{i})\\left(\\cfrac{1}{r^{*}(\\tilde{p},q_{i})}-\\tilde{p}q_{i}\\right)}-(1-\\tilde{p})}\\\\ &{\\qquad\\qquad\\leq\\sqrt{(1-\\tilde{p})^{2}+4\\tilde{p}(1-q_{i})\\left(\\tilde{p}q_{i}-\\tilde{p}q_{i}\\right)}-(1-\\tilde{p})}\\\\ &{\\qquad\\qquad=\\sqrt{(1-\\tilde{p})^{2}}-(1-\\tilde{p})}\\\\ &{\\qquad\\qquad=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Thus, $\\varepsilon(q_{i})=\\infty$ for any $q_{i}\\geq1/(\\tilde{r}\\tilde{p})$ . We may thus restrict our attention to $q_{i}<\\mathrm{min}\\{1,1/(\\tilde{r}\\tilde{p})\\}$ ", "page_idx": 37}, {"type": "text", "text": "Since $r^{*}(\\tilde{p},q_{i})$ is a continuous function of $q_{i}$ and $\\varepsilon(q_{i})$ is a continuous function of $r^{*}(\\tilde{p},q_{i})$ , it follows that $\\varepsilon(q_{i})$ is a continuous function of $q_{i}$ . By Lemma 2, $\\varepsilon(q_{i})$ is a decreasing function of $q_{i}$ for $0\\,<\\,q_{i}\\,<\\,\\dot{\\tilde{a}}/(\\tilde{p}\\tilde{r})$ and by Lemma 3, $\\varepsilon(q_{i})$ is an increasing function of $q_{i}$ for $\\tilde{a}\\bar{/}(\\tilde{p}\\tilde{r})<q_{i}<$ $\\operatorname*{min}\\{1,1/(\\tilde{r}\\tilde{p})\\}$ . Thus, the minimum must occur at $q_{i}=\\tilde{a}/(\\tilde{p}\\tilde{r})$ and is ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\varepsilon\\left(\\frac{\\tilde{a}}{\\tilde{p}\\tilde{r}}\\right)=\\log\\left(\\frac{2\\tilde{p}\\left(1-\\frac{\\tilde{a}}{\\tilde{p}\\tilde{r}}\\right)}{\\sqrt{(1-\\tilde{p})^{2}+4\\tilde{p}\\left(1-\\frac{\\tilde{a}}{\\tilde{p}\\tilde{r}}\\right)\\left(\\frac{1}{\\tilde{r}}-\\tilde{p}\\frac{\\tilde{a}}{\\tilde{p}\\tilde{r}}\\right)}-(1-\\tilde{p})}\\right)}}\\\\ &{}&{=\\log\\left(\\frac{2\\left(\\tilde{p}\\tilde{r}-\\tilde{a}\\right)}{\\sqrt{\\tilde{r}^{2}(1-\\tilde{p})^{2}+4\\left(\\tilde{p}\\tilde{r}-\\tilde{a}\\right)\\left(1-\\tilde{a}\\right)}-\\tilde{r}(1-\\tilde{p})}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Theorem 5. Under the conditions of Theorem 2, let $\\tilde{a}<1$ , $\\tilde{q}\\leq1$ , and $\\tilde{r}>1$ , and $0<p_{i}<1$ . If the function $r^{*}$ is such that $r^{*}(p_{i},\\tilde{q})=\\operatorname*{max}\\{\\tilde{a}/(p_{i}\\tilde{q}),\\tilde{r}\\}$ and $r^{\\ast}(p_{i},q_{i})=\\infty$ for $q_{i}\\neq\\tilde{q},$ , then the solution to the minimization problem in (13) is ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\varepsilon=\\left\\{\\begin{array}{l l}{\\frac{1}{2}\\log\\left(\\frac{\\tilde{a}(1-\\tilde{q})}{\\tilde{q}(1-\\tilde{a})}\\right),}&{i f0<\\tilde{q}\\leq\\frac{\\tilde{a}}{\\tilde{r}};}\\\\ {\\frac{1}{2}\\log\\left(\\frac{1-\\tilde{q}}{\\frac{1}{\\tilde{r}}-\\tilde{q}}\\right),}&{i f0<\\tilde{q}\\leq\\frac{1}{\\tilde{r}+1}\\,a n d\\,\\frac{\\tilde{a}}{\\tilde{r}}<\\tilde{q}<1;}\\\\ {\\log\\left(\\frac{2\\tilde{a}(1-\\tilde{q})}{\\sqrt{(\\tilde{r}\\tilde{q}-\\tilde{a})^{2}+4\\tilde{a}\\tilde{q}(1-\\tilde{q})(1-\\tilde{a})}-(\\tilde{r}\\tilde{q}-\\tilde{a})}\\right),}&{i f\\frac{1}{\\tilde{r}+1}<\\tilde{q}<1\\,a n d\\,\\frac{\\tilde{a}}{\\tilde{r}}<\\tilde{q}<1;}\\\\ {\\log\\left(\\frac{\\tilde{r}-\\tilde{a}}{1-\\tilde{a}}\\right),}&{i f\\tilde{q}=1.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Proof. We define $\\varepsilon(p_{i})$ as follows. ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon(p_{i})=\\left\\{\\begin{array}{l l}{\\log\\left(\\frac{2p_{i}(1-\\tilde{q})}{\\sqrt{(1-p_{i})^{2}+4p_{i}(1-\\tilde{q})\\left(\\frac{1}{r^{\\ast}(p_{i},\\tilde{q})}-p_{i}\\tilde{q}\\right)}-(1-p_{i})}\\right),}&{\\mathrm{~if~}0<\\tilde{q}<1;}\\\\ {\\log\\left(\\frac{1-p_{i}}{\\frac{1}{r^{\\ast}(p_{i},\\tilde{q})}-p_{i}}\\right),}&{\\mathrm{~if~}\\tilde{q}=1.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "The solution to the minimization problem in (13) corresponds to the minimum of $\\varepsilon(p_{i})$ over $(0,1]$ . ", "page_idx": 38}, {"type": "text", "text": "We begin with the case where $0\\,<\\,\\tilde{q}\\,\\leq\\,\\tilde{a}/\\tilde{r}$ . In this setting, we have that $\\tilde{r}\\,\\leq\\,\\tilde{a}/\\tilde{q}\\,\\leq\\,\\tilde{a}/\\bigl(p_{i}\\tilde{q}\\bigr)$ so $r^{*}(p_{i},\\bar{\\tilde{q}})=\\tilde{a}/(p_{i}\\tilde{q})$ for all $p_{i}$ . By Lemma 2, $\\varepsilon(p_{i})$ is a decreasing function of $p_{i}$ , so the minimum occurs at $p_{i}=1$ and is, by Corollary 2, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\varepsilon(1)=\\frac{1}{2}\\log\\left(\\frac{1-\\tilde{q}}{\\frac{\\tilde{q}}{\\tilde{a}}-\\tilde{q}}\\right)=\\frac{1}{2}\\log\\left(\\frac{\\tilde{a}(1-\\tilde{q})}{\\tilde{q}(1-\\tilde{a})}\\right).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "We now consider the case where $\\tilde{a}/\\tilde{r}<\\tilde{q}\\leq1$ . Note that $\\tilde{r}\\geq\\tilde{a}/(p_{i}\\tilde{q})$ whenever $p_{i}\\geq\\tilde{a}/(\\tilde{q}\\tilde{r})$ . Since in this setting $\\tilde{a}/(\\tilde{q}\\tilde{r})<1$ , the risk bound can be written in piece-wise form ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r^{*}(\\tilde{p},q_{i})=\\left\\{\\frac{\\tilde{a}}{p_{i}\\tilde{q}},\\quad\\mathrm{if~}0<p_{i}<\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}};\\right.}\\\\ {\\quad\\left.\\tilde{r},\\quad\\quad\\mathrm{if~}\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}}\\leq p_{i}<1..\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Note that if $p_{i}\\geq1/(\\tilde{r}\\tilde{q})$ , then $\\tilde{r}\\geq1/(p_{i}\\tilde{q})$ . Thus, $r^{*}(p_{i},\\tilde{q})\\geq\\tilde{r}\\geq1/(p_{i}\\tilde{q})$ and so ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sqrt{\\left(1-p_{i}\\right)^{2}+4p_{i}(1-\\tilde{q})\\left(\\frac{1}{r^{\\ast}\\left(p_{i},\\tilde{q}\\right)}-p_{i}\\tilde{q}\\right)}-(1-p_{i})}\\\\ &{\\qquad\\qquad\\leq\\sqrt{(1-p_{i})^{2}+4p_{i}(1-\\tilde{q})\\left(p_{i}\\tilde{q}-p_{i}\\tilde{q}\\right)}-(1-p_{i})}\\\\ &{\\qquad\\qquad=\\sqrt{(1-p_{i})^{2}}-(1-p_{i})=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Thus, $\\varepsilon(p_{i})=\\infty$ for any $p_{i}\\geq1/(\\tilde{r}\\tilde{q})$ . We may thus restrict our attention to $p_{i}<\\mathrm{min}\\{1,1/(\\tilde{r}\\tilde{q})\\}$ . ", "page_idx": 38}, {"type": "text", "text": "Since $r^{*}(p_{i},\\tilde{q})$ is a continuous function of $p_{i}$ and $\\varepsilon(p_{i})$ is a continuous function of $r^{*}(p_{i},\\tilde{q})$ , it follows that $\\varepsilon(p_{i})$ is a continuous function of $p_{i}$ . By Lemma 2, $\\varepsilon(p_{i})$ is a decreasing function of $p_{i}$ for $0<p_{i}<\\tilde{a}/(\\tilde{q}\\tilde{r})$ . ", "page_idx": 38}, {"type": "text", "text": "When $0<\\tilde{q}<1/(\\tilde{r}\\!+\\!1)$ , note that $1/(\\tilde{q}\\tilde{r})>(\\tilde{r}+1)/\\tilde{r}>1$ and $\\mathrm{so}\\,\\mathrm{min}\\{1,1/(\\tilde{r}\\tilde{q})\\}=1$ . By Lemma 3, $\\varepsilon(p_{i})$ is a decreasing function of $p_{i}$ for $\\tilde{a}/(\\tilde{q}\\tilde{r})<p_{i}<1$ . Thus, the minimum must occur at $p_{i}=1$ and is, by Corollary 2, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\varepsilon(1)=\\frac{1}{2}\\log\\left(\\frac{1-\\tilde{q}}{\\frac{1}{\\tilde{r}}-\\tilde{q}}\\right).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "When $\\tilde{q}=1/(\\tilde{r}+1)$ , again $1/(\\tilde{q}\\tilde{r})=(\\tilde{r}+1)/\\tilde{r}>1$ . By Lemma 3, $\\varepsilon(p_{i})$ is flat for $\\tilde{a}/(\\tilde{q}\\tilde{r})<p_{i}<$ $\\operatorname*{min}\\{1,1/(\\tilde{r}\\tilde{q})\\}=1$ . Thus, the minimum is shared by all points in this range and is equal to (172). ", "page_idx": 38}, {"type": "text", "text": "When $1/(\\tilde{r}+1)<\\tilde{q}<1$ , by Lemma 3, $\\varepsilon(p_{i})$ is an increasing function of $p_{i}$ for $\\tilde{a}/(\\tilde{q}\\tilde{r})\\,<\\,p_{i}\\,<$ $\\operatorname*{min}\\{1,1/(\\tilde{r}\\tilde{q})\\}$ . Thus, the minimum must occur at $p_{i}=\\tilde{a}/(\\tilde{q}\\tilde{r})$ and is ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon\\left(\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}}\\right)=\\log\\left(\\frac{2\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}}(1-\\tilde{q})}{\\sqrt{(1-\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}})^{2}+4\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}}(1-\\tilde{q})\\left(\\frac{1}{\\tilde{r}}-\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}}\\tilde{q}\\right)}-(1-\\frac{\\tilde{a}}{\\tilde{q}\\tilde{r}})}\\right)}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\log\\left(\\frac{2\\tilde{a}(1-\\tilde{q})}{\\sqrt{(\\tilde{q}\\tilde{r}-\\tilde{a})^{2}+4\\tilde{a}\\tilde{q}(1-\\tilde{q})\\left(1-\\tilde{a}\\right)}-(\\tilde{q}\\tilde{r}-\\tilde{a})}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Finally, when $\\tilde{q}=1$ for $\\tilde{a}/(\\tilde{q}\\tilde{r})<p_{i}<\\mathrm{min}\\{1,1/(\\tilde{r}\\tilde{q})\\}$ , ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\varepsilon(p_{i})=\\log\\left(\\frac{1-p_{i}}{\\frac{1}{\\tilde{r}}-p_{i}}\\right).\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "It was shown in (147) that $\\varepsilon(p_{i})$ is an increasing function of $p_{i}$ for $\\tilde{a}/\\tilde{r}<p_{i}<\\operatorname*{min}\\{1,1/\\tilde{r}\\}$ . The minimum then must occur at $p_{i}=\\tilde{a}/\\tilde{r}$ and is ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\varepsilon\\left(\\frac{\\tilde{a}}{\\tilde{r}}\\right)=\\log\\left(\\frac{1-\\frac{\\tilde{a}}{\\tilde{r}}}{\\frac{1}{\\tilde{r}}-\\frac{\\tilde{a}}{\\tilde{r}}}\\right)=\\log\\left(\\frac{\\tilde{r}-\\tilde{a}}{1-\\tilde{a}}\\right).\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: Our contribution is a novel, general framework for selecting $\\varepsilon$ in DP, which is stated in the abstract and introduction. We emphasize throughout that the framework requires some assumptions, which are provided at the beginning of Section 3. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 40}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Justification: The main limitation of our framework is the required assumptions, especially Assumption 2. We make an effort to call out that these assumptions are required for our framework to be used, while also noting that they are milder than assumptions in the existing literature on selecting $\\varepsilon$ . ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 40}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Justification: All theorems and lemmas are proved in Appendix $\\boldsymbol{\\mathrm E}$ and all assumptions are clearly stated in Section 3. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 41}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: All equations required to reproduce the tables and figures are provided in the text. To find the $\\varepsilon$ implied by each profile, the minimization problem is stated in (13), closed forms are provided in Appendix A.2 where applicable, and code to solve the problem numerically is provided. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 41}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 42}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: Code to produce all figures and tables in the text is provided. Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 42}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: We present illustrations of the approach with results derived from mathematical properties of the framework rather than data-based experiments. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 42}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: Our numerical results derive from calculations based on probabilistic properties of the framework, so error bars or other measures of statistical significance are unnecessary. Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 43}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: While we do not have any experiments, the code to produce all figures and tables can be run on a personal computer in a few seconds. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 43}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We have reviewed and ensured that our paper meets the NeurIPS Code of Ethics. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 43}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 43}, {"type": "text", "text": "Answer: [No] ", "page_idx": 43}, {"type": "text", "text": "Justification: We demonstrate how our framework can help agencies better manage risk and utility trade-offs in private data releases, which can help agencies release information that better informs policy decisions. However, we do not discuss societal impacts beyond that notion. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 44}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: The paper poses no such risks as it uses no confidential data. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 44}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 44}, {"type": "text", "text": "", "page_idx": 45}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 45}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 45}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 45}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 46}]