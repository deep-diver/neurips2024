{"references": [{"fullname_first_author": "Mikhail Belkin", "paper_title": "Reconciling modern machine-learning practice and the classical bias-variance trade-off", "publication_date": "2019-00-00", "reason": "This paper is foundational in establishing the double descent phenomenon, a key concept explored and extended in the current work."}, {"fullname_first_author": "Trevor Hastie", "paper_title": "Surprises in high-dimensional ridgeless least squares interpolation", "publication_date": "2022-00-00", "reason": "This paper provides a comprehensive theoretical analysis of double descent in the over-parameterized regime, offering a benchmark for comparison and extension."}, {"fullname_first_author": "Preetum Nakkiran", "paper_title": "Optimal Regularization can Mitigate Double Descent", "publication_date": "2020-00-00", "reason": "This paper investigates the impact of regularization on double descent, a topic directly relevant to the current paper's exploration of under-parameterized regimes."}, {"fullname_first_author": "Edgar Dobriban", "paper_title": "High-dimensional asymptotics of prediction: ridge regression and classification", "publication_date": "2018-00-00", "reason": "This paper provides a theoretical framework for understanding high-dimensional regression, which is crucial for analyzing the behavior of linear models in the under-parameterized regime."}, {"fullname_first_author": "Peter Bartlett", "paper_title": "Benign overfitting in linear regression", "publication_date": "2020-00-00", "reason": "This paper offers a theoretical explanation for benign overfitting in linear regression, which helps contextualize the occurrence of double descent in under-parameterized settings."}]}