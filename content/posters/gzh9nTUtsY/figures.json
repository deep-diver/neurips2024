[{"figure_path": "gzh9nTUtsY/figures/figures_0_1.jpg", "caption": "Figure 1: Bias-variance trade-off and double descent.", "description": "This figure shows two plots illustrating the concepts of bias-variance trade-off and double descent in machine learning. (a) Classical Bias Variance Trade-off: This plot displays the classical relationship between model complexity and total error, which is composed of bias and variance. It shows that as model complexity increases, bias decreases while variance increases, leading to a U-shaped curve representing total error. (b) Modern Double Descent:  This plot demonstrates the phenomenon of double descent. It shows that when model complexity increases beyond the number of data points (i.e., the interpolation threshold), generalization error first increases before decreasing again. This behavior suggests a more nuanced relationship between model capacity and generalization performance.", "section": "1 Introduction"}, {"figure_path": "gzh9nTUtsY/figures/figures_5_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares theoretical and empirical values of generalization error in the under-parameterized regime.  The theoretical values come from Theorem 1 in the paper, while the empirical values are obtained through experiments. The figure demonstrates the under-parameterized double descent phenomenon, showing that the generalization error is non-monotonic and exhibits a peak in the under-parameterized region for the data scaling regime. This peak's location is a function of the regularization parameter, \u00b5. The experiments used 1000 data points and dimensions and ran at least 100 trials for each empirical data point.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_6_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares theoretical and empirical results for the generalization error (risk) in the data scaling regime for three different values of the ridge regularization parameter \u03bc (0.1, 1, and 2).  The theoretical curve is derived from Theorem 1 in the paper. The empirical values are obtained from simulations, averaging at least 100 trials for each data point.  The plot demonstrates the occurrence of under-parameterized double descent in the risk curve, meaning the risk initially increases then decreases as the ratio of the dimension (d) to the number of training points (n) changes. The Appendix G provides further details on the experimental setup.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_7_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through experiments. The data scaling regime is used, meaning the number of data points (n) is varied while keeping the dimensionality (d) constant.  Three subfigures show the results for different values of the regularization parameter \u03bc (0.1, 1, and 2). Each point represents the average of at least 100 experimental trials.  The figure visually demonstrates the under-parameterized double descent phenomenon discussed in the paper, showing that for particular settings, the generalization error exhibits a U-shape behavior in the under-parameterized regime (d/n < 1). Appendix G provides more detail on the experimental setup.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_7_2.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through simulations. Three different values of the regularization parameter \u03bc (0.1, 1, and 2) are considered, showcasing how the peak in the risk curve changes its position in the under-parameterized regime. The data scaling regime is used (fixing d and varying n), and at least 100 trials are performed for each data point.  Appendix G provides further details on the experimental setup.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_8_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve predicted by Theorem 1 with empirical results obtained through simulations.  The data scaling regime is used, meaning the dimension (d) is fixed at 1000, while the number of training data points (n) is varied, resulting in different aspect ratios (c = d/n). Three different values of the regularization parameter \u03bc (0.1, 1, and 2) are shown.  For each value of c, at least 100 trials were run to obtain the empirical data points, and error bars are included to give a sense of the variability.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_8_2.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through simulations.  The plots show the generalization error (risk) as a function of the aspect ratio (c = d/Ntrn), which represents the ratio of data dimension to the number of training data points.  Three different values of the regularization parameter (\u03bc) are presented, demonstrating how the shape of the curve changes with the strength of regularization. The data scaling regime, where the dimension (d) is fixed while the number of training samples (n) is varied, is used. Empirical data points are averages of at least 100 simulation runs, providing confidence in the observed patterns.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_13_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through simulations. The data scaling regime is used, where the number of data points n is varied while keeping the dimension d fixed. Three different values of the regularization parameter \u03bc (0.1, 1, and 2) are considered to illustrate the effect of \u03bc on the risk curve. For each \u03bc value, multiple trials (at least 100) were conducted to generate empirical risk values. The consistency between the theoretical curve and the empirical data points suggests the validity of the proposed theoretical analysis. Appendix G provides further details about the experimental setup.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_14_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "The figure compares theoretical and empirical risk curves for different values of the regularization parameter \u03bc in a linear regression model. The data scaling regime is used, with the dimension of the problem fixed at 1000 and the number of training points varied.  The plots show that the theoretical risk curve accurately predicts the behavior of the empirical risk curves, demonstrating the existence of double descent in the underparameterized regime at c = 1/(1+\u03bc\u00b2).", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_15_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through simulations.  Three subfigures show the results for different values of the regularization parameter \u03bc (0.1, 1, and 2). The data scaling regime is used, where the number of data points (n) is varied while keeping the dimensionality (d) fixed. The consistency between theoretical and empirical results verifies the presence of double descent in the under-parameterized regime.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_16_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "The figure shows the theoretical and empirical risk curves for three different values of the regularization parameter \u03bc (0.1, 1, and 2). The theoretical curves are generated using Theorem 1 from the paper, and the empirical curves are obtained through simulations.  The x-axis represents the aspect ratio c (dimensionality/number of data points), and the y-axis shows the generalization error. The plot demonstrates that the theoretical and empirical results align closely and show a peak in the under-parameterized regime (c<1).  Appendix G contains further details on the experimental setup.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_16_2.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through simulations.  The three subplots represent different values of the regularization parameter \u03bc (0.1, 1, and 2).  Each subplot shows the generalization error (risk) as a function of the aspect ratio (c = d/Ntrn), where d is the dimension and Ntrn is the number of training data points.  The data scaling regime is used where d is fixed, and Ntrn is varied. The empirical data points are averages from at least 100 trials each, and more details are available in Appendix G of the paper.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_17_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through simulations. The data scaling regime is used, where the dimension d is fixed at 1000, and the number of training data points n varies.  Three different values of the regularization parameter \u03bc (0.1, 1, and 2) are shown, illustrating the impact of regularization strength on the double descent phenomenon.  The empirical results are averages over at least 100 trials for each point, demonstrating agreement with the theoretical predictions.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_17_2.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares theoretical and empirical risk curves for the first example (alignment mismatch) in the under-parameterized regime.  Three subplots show results for different values of the regularization parameter \u03bc (0.1, 1, and 2). The data scaling regime is used (d is fixed, n varies), \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000.  Each empirical data point is the average of at least 100 trials. The figure visually confirms Theorem 1's prediction of a local maximum in the under-parameterized regime.", "section": "4 Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_17_3.jpg", "caption": "Figure 11: The first two figures show the  \u03c3trn versus risk curve for c = 0.5, \u03bc = 1 and c = 2, \u03bc = 0.1 with d = 1000. The second two figures show the risk when training using the optimal \u03c3trn for the data scaling and parameter scaling regimes.", "description": "This figure displays the generalization error versus the training noise standard deviation (\u03c3trn) for two different aspect ratios (c = 0.5 and c = 2) and regularization strengths (\u03bc = 1 and \u03bc = 0.1). The left two subfigures show that there exists an optimal value of \u03c3trn that minimizes the generalization error. The right two subfigures then show the risk when this optimal value of \u03c3trn is used for the data scaling and parameter scaling regimes. These plots show that the optimal value of \u03c3trn is not sufficient to remove double descent.", "section": "D Regularization Trade-off"}, {"figure_path": "gzh9nTUtsY/figures/figures_18_1.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results obtained through simulations. Three subfigures are presented, each corresponding to a different value of the regularization parameter \u03bc (0.1, 1, and 2). The data scaling regime is used, where the number of data points (n) is varied while keeping the dimensionality (d) constant at 1000.  Each empirical data point in the plots is an average of at least 100 simulation trials. Appendix G provides further details about the experimental setup.", "section": "Alignment Mismatch"}, {"figure_path": "gzh9nTUtsY/figures/figures_18_2.jpg", "caption": "Figure 2: Figure showing the theoretical risk curve from Theorem 1 and empirical values in the data scaling regime for different values of \u03bc [(L) \u03bc = 0.1, (C) \u03bc = 1, (R) \u03bc = 2]. Here \u03c3trn = \u221an, \u03c3tst = \u221antst, d = 1000, Ntst = 1000. For each empirical point, we ran at least 100 trials. More details can be found in Appendix G.", "description": "This figure compares the theoretical risk curve derived from Theorem 1 with empirical results from simulations for three different values of the regularization parameter \u03bc (0.1, 1, and 2).  The data scaling regime is used (n varies, d is fixed), and for each empirical point at least 100 trials were run.  The plots show that the theoretical curve accurately captures the double descent phenomenon in the under-parameterized regime.", "section": "4 Alignment Mismatch"}]