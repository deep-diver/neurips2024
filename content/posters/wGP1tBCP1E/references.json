{"references": [{"fullname_first_author": "Anish Athalye", "paper_title": "Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples", "publication_date": "2018-07-01", "reason": "This paper highlights the limitations of existing adversarial defense mechanisms, motivating the need for stronger, more robust defense methods like those explored in the current paper."}, {"fullname_first_author": "Jeremy Cohen", "paper_title": "Certified adversarial robustness via randomized smoothing", "publication_date": "2019-07-01", "reason": "This paper introduces the randomized smoothing technique, a key component of the proposed method for achieving certified robustness, providing a foundational theoretical framework."}, {"fullname_first_author": "Hadi Salman", "paper_title": "Provably robust deep learning via adversarially trained smoothed classifiers", "publication_date": "2019-07-01", "reason": "This paper establishes the theoretical basis for the connection between randomized smoothing and certified robustness, which is central to the proposed method."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion models, the core generative models used in this paper as classifiers, providing the essential foundation for the approach."}, {"fullname_first_author": "Yang Song", "paper_title": "Score-based generative modeling through stochastic differential equations", "publication_date": "2021-05-01", "reason": "This paper provides an alternative theoretical framework for understanding diffusion models which informed the approach used in this work."}]}