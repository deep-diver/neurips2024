[{"figure_path": "uyqjpycMbU/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of our active learning pipeline", "description": "This figure illustrates the active learning pipeline used in the paper.  It shows how unlabeled samples are processed using a contrastive learning-based encoder to create embeddings in a metric space. These embeddings are then used with Coreset to select the most informative samples for labeling, which are then added to the labeled dataset.  This iterative process continues until a desired level of annotation is reached.", "section": "3 Methodology"}, {"figure_path": "uyqjpycMbU/figures/figures_7_1.jpg", "caption": "Figure 2: Describes the relationship between model performance and annotation time for our method utilizing weakly and fully-supervised 2D slices and random sampling of fully-supervised 3D volumes on the ACDC dataset. Annotation % is measured as the percentage of the fully-labeled ACDC training data. For weak supervision, we extrapolate the percentage of fully-labeled data based on equivalent annotation time (we follow prior work which assumes that annotators annotate scribbles 15x as fast as the full masks (72)). The dashed green line represents the performance of our method using weakly-supervised 2D slices with 40% of the ACDC training data.", "description": "This figure shows a comparison of the model performance (Dice score) against the annotation time (percentage of fully labeled data) for different active learning methods. It compares weakly supervised 2D slices, fully supervised 2D slices using the proposed method, and random sampling of fully supervised 3D volumes on the ACDC dataset. The result shows that the proposed method achieves higher Dice score using weakly supervised 2D slices with significantly less annotation time than random sampling using 3D volumes.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/figures/figures_7_2.jpg", "caption": "Figure 3: Qualitative comparison of our method, CoreGCN, and Coreset. Blue indicates agreement between model predictions and groundtruth masks and red indicates disagreement.", "description": "This figure shows a qualitative comparison of the segmentation results obtained by three different active learning methods: the proposed method, CoreGCN, and Coreset.  For each method, segmentation results at annotation percentages of 2%, 3%, 4%, and 5% are shown.  Blue coloration indicates areas where the model's prediction and the ground truth mask agree, while red shows disagreement. The visual comparison allows for assessment of the qualitative differences in performance between methods at various annotation budgets.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/figures/figures_8_1.jpg", "caption": "Figure 4: t-SNE visualization of dataset clusters generated by different g\u00f8", "description": "This figure visualizes the effect of different loss functions on the learned feature representations.  The left panel shows the clusters generated using the NT-Xent loss, while the right panel shows the clusters generated using the proposed Group-based Contrastive Learning (GCL) loss.  The t-SNE visualization helps to understand the quality of cluster separation and cohesion achieved by each loss function. The GCL loss shows better separation and cohesion, indicating that it learns more informative and relevant features for the Coreset.", "section": "3.2.1 Group-based Contrastive Learning for feature representation in metric learning"}, {"figure_path": "uyqjpycMbU/figures/figures_16_1.jpg", "caption": "Figure 1: Overview of our active learning pipeline", "description": "This figure shows the pipeline of the proposed active learning method. It starts with unlabeled samples and uses Coreset to select a subset of samples. These samples are then used for contrastive learning to obtain embeddings. The embeddings are used to calculate distances between samples in the metric space, which helps select the most informative samples. Finally, these newly labeled samples are added to the training set to improve the segmentation model.", "section": "3 Methodology"}, {"figure_path": "uyqjpycMbU/figures/figures_17_1.jpg", "caption": "Figure 1: Overview of our active learning pipeline", "description": "This figure illustrates the active learning pipeline used in the paper.  It shows how unlabeled samples are processed using contrastive learning to generate embeddings in a metric space.  These embeddings are used with the Coreset algorithm to select the most informative samples for labeling.  Newly labeled samples are then added to the training set, improving the model's performance. The pipeline iteratively selects and labels samples until a desired budget or performance threshold is reached.", "section": "3 Methodology"}]