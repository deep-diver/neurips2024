[{"figure_path": "4vp0edVY4o/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of our methods. Task i's data representations are denoted as h\u1d62 with pre-trained token representations as grey dots in the \u2018Representation\u2019 block. Correlations between aligned data representations from different tasks depends on correlations between pre-trained token representations. In the 'Class Vectors' block, class vectors for different classes have different focuses on representations after probing, which can reduce interference caused by overlapped representations.", "description": "This figure illustrates the proposed continual learning method using global alignment.  It shows how task-specific data representations (h\u1d62) are created as compositions of pre-trained token representations (grey dots). The alignment of these representations across tasks is grounded by the correlations between the pre-trained tokens.  The 'Class Vectors' block highlights how a probing strategy helps to reduce interference from overlapping representations by allowing different classes to focus on different aspects of the data representation.", "section": "4 Methodology"}, {"figure_path": "4vp0edVY4o/figures/figures_3_1.jpg", "caption": "Figure 2: T-SNE plots of all tasks' data representations after learning the first (with classes Village, Athlete) and last task. Under the vanilla sequential learning in (a), after the first task, representations of data from unseen tasks are overlapped. This may cause interference when switching tasks, which makes representations indistinguishable after the first and last tasks. With our global alignment model (Wire-Neigh) in (b), representations remain distinguishable after the first and last tasks.", "description": "This figure shows t-SNE plots visualizing the data representations learned by a model without global alignment (a) and a model with global alignment (b).  The plots compare the representations after learning the first task and after learning the last task in a continual learning scenario. The model without global alignment shows significant overlap in representations from different tasks after the first task, leading to interference and indistinguishable representations after the last task. In contrast, the model with global alignment maintains distinct representations for different tasks even after learning all tasks, showcasing the effectiveness of the proposed global alignment method.", "section": "3.2 Cross-Task Interference"}, {"figure_path": "4vp0edVY4o/figures/figures_5_1.jpg", "caption": "Figure 3: Comparison between alignment models. Modules in blue are pre-trained and in orange are learnable. Representations in grey are mainly adapted and in blue are close to the pre-trained ones. We specify hidden representations for [CLS] and any other token as h[CLS] and hothers.", "description": "This figure compares three different alignment models: Fixed Wiring, Wiring with Neighbor Attention, and Controlled LoRA.  It illustrates how each model uses pre-trained (blue) and learnable (orange) components to generate task-specific data representations (grey). Fixed wiring directly adapts pre-trained representations for the [CLS] token, while Wiring with Neighbor Attention incorporates contextual information from neighboring tokens. Controlled LoRA adjusts pre-trained representations through low-rank updates applied to all tokens. The models aim to balance learning task-specific features with maintaining alignment to pre-trained representations to prevent catastrophic forgetting.", "section": "4.2 Global Alignment Models"}, {"figure_path": "4vp0edVY4o/figures/figures_8_1.jpg", "caption": "Figure 4: (a). Class-IL accuracy after the last task. Dashed lines show accuracies of ERACE, which replays previous tasks\u2019 data with Class-IL loss. (b). Average Class-IL accuracies after each task.", "description": "This figure shows the results of class-incremental learning experiments.  Subfigure (a) presents a bar chart comparing the classification accuracy after the final task for different continual learning methods, with and without the probing-then-fine-tuning (PF) strategy. Subfigure (b) displays line graphs illustrating the average class-incremental learning accuracy across multiple tasks. The results highlight the performance of the proposed alignment models in both scenarios, particularly in comparison to methods using experience replay like ERACE.", "section": "5.3 Results"}]