{"references": [{"fullname_first_author": "Kaiming He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-00-00", "reason": "This paper introduced the ResNet architecture, a fundamental model used extensively in computer vision tasks, which is relevant to the current paper's methodology involving vision foundation models."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This work introduced Vision Transformers (ViTs), a crucial architectural component of vision foundation models (VFMs), that the current paper builds upon for medical image classification."}, {"fullname_first_author": "Bo Han", "paper_title": "Co-teaching: Robust training of deep neural networks with extremely noisy labels", "publication_date": "2018-00-00", "reason": "This paper is foundational in addressing noisy label issues in deep learning, a core challenge the current paper directly tackles with its curriculum fine-tuning strategy."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper significantly advanced self-supervised learning for vision transformers, which are crucial components of the VFMs used in the current research."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper presents the Masked Autoencoder (MAE) approach, a key technique employed in self-supervised learning for VFMs, directly influencing the current work's methodology."}]}