[{"figure_path": "bIRcf8i1kp/figures/figures_1_1.jpg", "caption": "Figure 4: Diverse Tasks of GarmentLab Benchmark. We introduced 20 garment and deformable manipulation tasks including complicated long-horizon tasks. The last row shows the execution of these tasks in the real world.", "description": "This figure shows various tasks included in the GarmentLab benchmark.  The tasks are categorized into five groups based on physical interactions: Garment-Garment, Garment-Fluid, Garment-FEMObjects, Garment-Rigid, and Garment-Avatar.  Examples of tasks include folding, hanging, flinging, clothes piles, blowing, dress up, grasping, storing cloth, tidying up, and cleaning tables.  The figure also shows three long-horizon tasks: organizing clothes, washing clothes, and setting a table.  The bottom row of the image shows the real-world application of these tasks.", "section": "4 GarmentLab Benchmark"}, {"figure_path": "bIRcf8i1kp/figures/figures_2_1.jpg", "caption": "Figure 1: GarmentLab provides realistic simulation for diverse garments with different physical propoerties, benchmarking various novel garment manipulation tasks in both simulation and the real world.", "description": "GarmentLab is a unified simulation and benchmark environment for garment manipulation.  It provides realistic simulations of various garment types with different physical properties (multi-physics), using methods such as FEM and PBD.  The benchmark includes a wide range of tasks performed by different robotic systems and manipulators in both simulated and real-world settings, allowing for evaluation of state-of-the-art vision methods, reinforcement learning, and imitation learning approaches. The figure visually depicts the three key aspects of GarmentLab: MultiPhysics simulation, Teleoperation capabilities for data collection, and a Real-World Benchmark for sim-to-real transfer.", "section": "1 Introduction"}, {"figure_path": "bIRcf8i1kp/figures/figures_3_1.jpg", "caption": "Figure 2: The Architecture of GarmentLab. (Left) Built on PhysX5, our environment supports various simulation methods. (Middle) Our environment can deliver realistic simulations of diverse robots, garments, and interactions between multiple physics media. (Right) Subsequently, we can utilize these assets to construct tasks across various categories. (Bottom) The framework supports real-world deployment.", "description": "The figure shows the overall architecture of GarmentLab, a unified simulation and benchmark for garment manipulation. It highlights the three main components: the GarmentLab Engine (left), which uses various simulation methods (PhysX5, FEM, PBD) and integrates with ROS for real-world robot control; the GarmentLab Asset (middle), which includes a large-scale dataset of garments, robots, and other objects; and the GarmentLab Benchmark (right), which defines a set of tasks for evaluating garment manipulation algorithms in both simulation and real-world settings. The bottom part shows the sim-to-real pipeline.", "section": "3 GarmentLab Environment"}, {"figure_path": "bIRcf8i1kp/figures/figures_4_1.jpg", "caption": "Figure 4: Diverse Tasks of GarmentLab Benchmark. We introduced 20 garment and deformable manipulation tasks including complicated long-horizon tasks. The last row shows the execution of these tasks in the real world.", "description": "This figure shows various tasks included in the GarmentLab benchmark.  These tasks are categorized into five groups based on physical interactions: Garment-Garment, Garment-Fluid, Garment-FEMObjects, Garment-Rigid, and Garment-Avatar.  The tasks range in complexity from simple manipulation actions (e.g., folding, hanging) to complex, long-horizon tasks requiring planning and integration of multiple skills (e.g., organizing clothes, washing clothes, setting a table, dressing up). The bottom row displays the real-world execution of these complex tasks, highlighting the sim-to-real transfer capabilities of GarmentLab.", "section": "4 GarmentLab Benchmark"}, {"figure_path": "bIRcf8i1kp/figures/figures_5_1.jpg", "caption": "Figure 4: Diverse Tasks of GarmentLab Benchmark. We introduced 20 garment and deformable manipulation tasks including complicated long-horizon tasks. The last row shows the execution of these tasks in the real world.", "description": "This figure shows various tasks included in the GarmentLab benchmark.  The top two rows illustrate different simulation tasks categorized by the type of interaction (Garment-Garment, Garment-Fluid, Garment-FEMObjects, Garment-Rigid, and Garment-Avatar).  The bottom row displays real-world experiments showcasing the transfer of simulated learning to real-world scenarios.", "section": "4 GarmentLab Benchmark"}, {"figure_path": "bIRcf8i1kp/figures/figures_6_1.jpg", "caption": "Figure 5: Real-World Benchmark. Part a demonstrates the whole pipeline of converting real-world objects into simulation assets. Part b demonstrates the performance of different categories of objects in both simulation and the real world (the first row), and the results of these objects being manipulated by the robot (the second row).", "description": "This figure shows the process of creating a real-world benchmark for deformable objects. Part (a) illustrates the steps involved in converting real-world objects into simulation assets, including 3D scanning and post-processing. Part (b) showcases examples of various objects (garments, toys, household items) in both the simulation environment and real-world scenarios, along with the results of robot manipulation on those objects.", "section": "Real-World Benchmark"}, {"figure_path": "bIRcf8i1kp/figures/figures_7_1.jpg", "caption": "Figure 6: Sim2Real Framework. On the left, we highlight our MoveIt and teleoperation pipeline, a lightweight and easy-to-deploy system built using ROS. On the right, we present our three proposed visual sim-to-real algorithms, demonstrating a significant improvement in model performance after deploying these algorithms.", "description": "This figure illustrates the GarmentLab's Sim2Real framework. The left side shows the teleoperation and MoveIt pipelines, utilizing ROS for a lightweight and easily deployable system.  The right side showcases three visual Sim2Real algorithms: Keypoint Embedding Alignment, Noisy Observation, and Point Cloud Alignment.  Each algorithm's effect on learned representations (visualized through point-level correspondence) is shown, highlighting improved performance after deploying these algorithms in a real-world setting.", "section": "Sim2Real Framework"}, {"figure_path": "bIRcf8i1kp/figures/figures_8_1.jpg", "caption": "Figure 7: Qualitative Results. We visualize the qualitative results of the three vision-based algorithms: the left, middle, and right sections of this image correspond to the Affordance, Correspondence, and DIFT algorithms, respectively. Note that the DIFT exhibits query errors. For detailed analysis, please refer to Experiment Section.", "description": "This figure shows a qualitative comparison of three vision-based algorithms (Affordance, Correspondence, and DIFT) on garment manipulation tasks.  The left column displays results from the Affordance algorithm, the middle column shows results from the Correspondence algorithm, and the right column shows results from the DIFT algorithm.  The images show the predicted manipulation results overlaid on the source images of the garments. The caption notes that the DIFT algorithm shows some errors in its predictions.", "section": "7.2 Simulation Result and Analysis"}, {"figure_path": "bIRcf8i1kp/figures/figures_23_1.jpg", "caption": "Figure 8: Different Types of Particle-Particle Interaction", "description": "This figure illustrates the different types of particle interactions considered in the GarmentLab simulation.  It shows how the simulation handles interactions between solid particles (e.g., parts of a garment), fluid particles (e.g., water), and combinations of solid and fluid particles.  The diagrams depict the various scenarios, including the \"rest offset\" parameter which influences the way particles interact, particularly at boundaries between different material types.", "section": "D Physics Simulation"}, {"figure_path": "bIRcf8i1kp/figures/figures_27_1.jpg", "caption": "Figure 9: Objects Scanning Process.", "description": "The figure illustrates the four-stage process of scanning real-world objects for the GarmentLab benchmark.  First, a model wears the clothes to create natural-looking wrinkles. Next, a 3D scanner captures the model's shape. The data is then post-processed to reduce the number of points (down-sampling), add texture details, and fill in any gaps in the point cloud. Finally, key points on the garment are manually annotated.", "section": "F Real-World Benchmark"}, {"figure_path": "bIRcf8i1kp/figures/figures_27_2.jpg", "caption": "Figure 4: Diverse Tasks of GarmentLab Benchmark. We introduced 20 garment and deformable manipulation tasks including complicated long-horizon tasks. The last row shows the execution of these tasks in the real world.", "description": "This figure shows a variety of tasks included in the GarmentLab benchmark.  The tasks are categorized into five groups based on the physical interactions involved.  There are short-horizon tasks such as folding, hanging, flinging, and placing, but also long-horizon, complex tasks which are more challenging and require planning, such as organizing clothes, washing clothes, setting a table, and dressing up. The bottom row of images shows the same tasks performed in the real world, demonstrating the ability of the benchmark to transfer knowledge from simulation to real-world scenarios.", "section": "4 GarmentLab Benchmark"}, {"figure_path": "bIRcf8i1kp/figures/figures_30_1.jpg", "caption": "Figure 6: Sim2Real Framework. On the left, we highlight our MoveIt and teleoperation pipeline, a lightweight and easy-to-deploy system built using ROS. On the right, we present our three proposed visual sim-to-real algorithms, demonstrating a significant improvement in model performance after deploying these algorithms.", "description": "This figure illustrates the Sim2Real framework used in the GarmentLab. The left side showcases the teleoperation and MoveIt pipelines which are lightweight and easy to deploy using ROS.  The right side displays the three proposed visual sim-to-real algorithms. Each algorithm's effect on visual representations before and after implementation is visually demonstrated, illustrating significant performance improvements after algorithm deployment.", "section": "Sim2Real Framework"}, {"figure_path": "bIRcf8i1kp/figures/figures_30_2.jpg", "caption": "Figure 12: The Hand Model Used in Leap Motion, each knuckle joints' spatial position is computed by retargeting algorithm and broadcasted though ROS Message.", "description": "This figure shows a diagram of a hand model used in the Leap Motion system for teleoperation.  It illustrates the various parts of the hand, including the distal, intermediate, and proximal phalanges, as well as the metacarpals and the 0-length thumb metacarpal.  Each knuckle joint's spatial position is calculated using a retargeting algorithm and transmitted via ROS (Robot Operating System) messages. This is a crucial component of the system's ability to accurately track human hand movements and translate those movements into control signals for the robot arm in both simulation and the real world.", "section": "I Teleoperation"}]