{"references": [{"fullname_first_author": "A. Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-01", "reason": "This paper introduced the Transformer architecture, a fundamental building block for many modern speech recognition models, including the one used in this research."}, {"fullname_first_author": "A. Baevski", "paper_title": "wav2vec 2.0: A framework for self-supervised learning of speech representations", "publication_date": "2020-12-01", "reason": "This work details wav2vec 2.0, a significant advancement in self-supervised speech representation learning that influenced the self-supervised pre-training approach in this paper."}, {"fullname_first_author": "B. Shi", "paper_title": "Learning audio-visual speech representation by masked multimodal cluster prediction", "publication_date": "2022-01-01", "reason": "This highly-related work introduced AV-HuBERT, a key self-supervised model for audio-visual speech recognition that provides a comparison point for the approach in this research."}, {"fullname_first_author": "A. Haliassos", "paper_title": "Jointly learning visual and auditory speech representations from raw data", "publication_date": "2022-12-01", "reason": "This paper, also by the authors of the current paper, presents groundwork for the unified model approach in the current research."}, {"fullname_first_author": "P. Ma", "paper_title": "Visual speech recognition for multiple languages in the wild", "publication_date": "2022-11-01", "reason": "This paper addressed challenges in visual speech recognition, providing insights into the training strategies and optimization methods used in this work."}]}