{"references": [{"fullname_first_author": "Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper is foundational for diffusion models, introducing the core concept of denoising diffusion processes for image generation."}, {"fullname_first_author": "Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduced latent diffusion models (LDMs), a significant advancement that enables efficient high-resolution image generation."}, {"fullname_first_author": "Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-07-01", "reason": "This is a seminal work in text-to-image synthesis, demonstrating the potential of using large language models and image encoders for image generation from textual descriptions."}, {"fullname_first_author": "Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This paper established the superiority of diffusion models over generative adversarial networks (GANs) in image synthesis, paving the way for widespread adoption of diffusion models."}, {"fullname_first_author": "Chefer", "paper_title": "Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models", "publication_date": "2023-07-01", "reason": "This paper introduced a method for improving prompt compliance in diffusion models by using attention maps to guide the generation process, directly addressing a key challenge tackled in the current paper."}]}