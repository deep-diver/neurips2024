[{"figure_path": "esVleaqkRc/tables/tables_6_1.jpg", "caption": "Table 1: Problem class characteristics. All problems have a single budget constraint in the leader; for the follower, the DNDP has network flow constraints whereas other problems have a knapsack constraint. The arrows refer to minimization (\u2193) or maximization (\u2191) in leader and follower, respectively. B = Binary, C = Continuous, MI = Mixed-Integer, Lin = Linear, BLin = Bilinear, NLin = Non-Linear.", "description": "This table summarizes the characteristics of four benchmark bilevel optimization problems used in the paper: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), Donor-Recipient Problem (DRP), and Discrete Network Design Problem (DNDP). For each problem, it specifies the type of variables for the leader (x) and follower (y) (Binary, Continuous, or Mixed-Integer), the type of objective function (Linear, Bilinear, or Non-Linear), and the type of constraints (Linear, Bilinear, or Non-Linear). It also indicates whether the leader's objective is to minimize or maximize, and the same for the follower's objective.", "section": "Experimental Setup"}, {"figure_path": "esVleaqkRc/tables/tables_8_1.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  For KIP, results are shown for different problem sizes and budget constraints, comparing the neural network-based approach (NEUR2BILO) with a greedy value function approximation and a branch-and-cut method. For CNP and DNDP, the table presents average results for various problem instances and compares NEUR2BILO against other baselines.  The table highlights the computational efficiency and solution quality of NEUR2BILO in comparison to established techniques.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_8_2.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower\u2019s greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving time for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  For KIP, results are shown for different problem sizes (number of items).  The no-learning baseline G-VFA is included for comparison.  For CNP and DNDP, problem instances are generated randomly according to procedures in the referenced literature. The table shows that the proposed method (NEUR2BILO) is competitive with or significantly outperforms state-of-the-art methods in terms of both solution quality and computation time.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_8_3.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower\u2019s greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "The table presents the mean relative error (MRE) and average solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of NEUR2BILO's upper-level and lower-level approximations against existing baselines (B&C, G-VFA, MKKT) for various problem sizes and parameters. The results show that NEUR2BILO is significantly faster than the baselines while maintaining competitive solution quality.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_19_1.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower\u2019s greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed Neural Bilevel Optimization (NEUR2BILO) framework (using both upper and lower-level approximations) against existing baselines (e.g., branch-and-cut algorithms). The table shows that NEUR2BILO achieves high-quality solutions much faster than traditional methods for all three problems, even with complex constraints.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_20_1.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed NEUR2BILO method (using both upper-level and lower-level neural network approximations, NN\u00b9 and NN\u2122) against existing baseline methods (B&C, G-VFA, and MKKT).  The table shows that NEUR2BILO achieves high accuracy and significantly faster solving times, especially for larger problem instances.  Different problem sizes and budget constraints are considered for each problem. The no-learning baseline, G-VFA, uses a simplified approach based on the greedy solution of the follower problem.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_20_2.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed NEUR2BILO method (using both upper-level and lower-level approximations) against existing baselines (B&C, G-VFA, MKKT).  The table shows that NEUR2BILO achieves high accuracy within significantly less time compared to the baseline methods for the problems examined, even for large instances and non-linear problems.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_20_3.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower\u2019s greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed Neural Bilevel Optimization (NEUR2BILO) approach (using both upper-level and lower-level approximations) against existing baseline methods (Branch and Cut, G-VFA, MKKT).  The table shows that NEUR2BILO generally achieves comparable or better solution quality with significantly faster solving times, especially for larger problem instances.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_21_1.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed NEUR2BILO method (using both upper and lower-level approximations) against existing baseline methods.  The table shows that NEUR2BILO achieves high accuracy and speed, particularly compared to exact methods.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_21_2.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed NEUR2BILO method (using both upper and lower-level approximations) against existing baselines (B&C, G-VFA, MKKT) across different problem sizes and parameter settings. The table highlights the speed and accuracy of NEUR2BILO, particularly for larger and more complex instances.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_21_3.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  For KIP, results are shown for different problem sizes (number of items, n). For CNP, the results represent averages over 300 randomly sampled instances, and for DNDP, averages over 10 instances are shown. The table also includes a comparison with baseline methods (G-VFA for KIP and B&C for CNP). The budget constraints for each problem are also specified.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_24_1.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table summarizes the performance of NEUR2BILO and baseline methods on three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It shows the mean relative error (MRE) and solution times for each method and problem instance size, illustrating NEUR2BILO's efficiency and solution quality compared to state-of-the-art techniques.", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_25_1.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower's greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed Neural Bilevel Optimization (NEUR2BILO) method (using both upper and lower-level approximations) against existing baseline methods for each problem. The table shows that NEUR2BILO achieves high accuracy within significantly shorter computation times, especially as the problem size increases.  The baseline methods used vary depending on the problem; for KIP, it's branch and cut (B&C), for CNP it's B&C again, for DNDP it's modified KKT conditions (MKKT).", "section": "Experimental Results"}, {"figure_path": "esVleaqkRc/tables/tables_25_2.jpg", "caption": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with n \u2264 30, we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For n = 100, our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower\u2019s greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details.", "description": "This table presents the mean relative error (MRE) and solving times for three different bilevel optimization problems: Knapsack Interdiction Problem (KIP), Critical Node Problem (CNP), and Discrete Network Design Problem (DNDP).  It compares the performance of the proposed NEUR2BILO method (using both upper and lower-level approximations) against existing baseline methods. The table highlights the computational efficiency and solution quality of NEUR2BILO, especially when compared to exact methods which struggle to scale to larger problem sizes.  Note that different numbers of instances are used for each problem, along with varying solution methods and data generation procedures.", "section": "Experimental Results"}]