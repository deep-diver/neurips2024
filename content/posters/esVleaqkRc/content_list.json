[{"type": "text", "text": "NEUR2BILO: Neural Bilevel Optimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Justin Dumouchelle\u2217 Esther Julien Jannis Kurtz Elias B. Khalil University of Toronto TU Delft University of Amsterdam University of Toronto ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Bilevel optimization deals with nested problems in which a leader takes the first decision to minimize their objective function while accounting for a follower\u2019s best-response reaction. Constrained bilevel problems with integer variables are particularly notorious for their hardness. While exact solvers have been proposed for mixed-integer linear bilevel optimization, they tend to scale poorly with problem size and are hard to generalize to the non-linear case. On the other hand, problemspecific algorithms (exact and heuristic) are limited in scope. Under a data-driven setting in which similar instances of a bilevel problem are solved routinely, our proposed framework, NEUR2BILO, embeds a neural network approximation of the leader\u2019s or follower\u2019s value function, trained via supervised regression, into an easy-to-solve mixed-integer program. NEUR2BILO serves as a heuristic that produces high-quality solutions extremely fast for four applications with linear and non-linear objectives and pure and mixed-integer variables. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "A motivating application. Consider the following discrete network design problem (DNDP) [47, 48]. A transportation planning authority seeks to minimize the average travel time on a road network represented by a directed graph of nodes $N$ and links $A_{1}$ by investing in constructing a set of roads (i.e., links) from a set of options $A_{2}$ , subject to a budget $B$ . The planner knows the number of vehicles that travel between any origin-destination (O-D) pair of nodes. A good selection of links should take into account the drivers\u2019 reactions to this decision. One common assumption is that drivers will optimize their O-D paths such that a user equilibrium is reached. This is known as Wardrop\u2019s second principle in the traffic assignment literature, an equilibrium in which \u201cno driver can unilaterally reduce their travel costs by shifting to another route\u201d [41]. This is in contrast to the system optimum, an equilibrium in which a central planner dictates each driver\u2019s route, an unrealistic assumption that would not require bilevel modeling. A link cost function is used to model the travel time on an edge as a function of traffic. Let $c_{i j}\\in\\mathbb{R}_{+}$ be the capacity (vehicles per hour (vph)) of a link and $T_{i j}\\in\\mathbb{R}_{+}$ the free-flow travel time (i.e., travel time on the link without congestion). The US Bureau of Public Roads uses the following widely accepted formula to model the travel time $t(y_{i j})$ on a link used by $y_{i j}$ vehicles per hour: $t(y_{i j})=T_{i j}(1+0.15(y_{i j}/c_{i j})^{4})$ . As the traffic $y_{i j}$ grows to exceed the capacity $c_{i j}$ , a large quartic increase in travel time is incurred [41]. ", "page_idx": 0}, {"type": "text", "text": "Bilevel optimization (BiLO) [4] models the DNDP and many problems in which an agent (the leader) makes decisions that minimize their cost function subject to another agent\u2019s (the follower\u2019s) best response. In the DNDP, the leader is the transportation planner and the follower is the population of drivers, giving rise to the following optimization problem ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\min_{\\times\\in\\{0,1\\}^{|A_{2}|},\\mathbf{y}}\\quad}&{\\displaystyle\\sum_{(i,j)\\in A}y_{i j}t(y_{i j})}\\\\ {\\mathrm{s.t.}\\quad}&{\\displaystyle\\sum_{(i,j)\\in A_{2}}g_{i j}x_{i j}\\leq B,}\\\\ &{\\displaystyle\\mathbf{y}\\in\\underset{\\mathbf{y}^{\\prime}\\in\\mathbb{R}_{+}^{|A|}}{\\mathrm{arg}\\,\\mathrm{min}}\\quad\\sum_{(i,j)\\in A}\\int_{0}^{y_{i j}^{\\prime}}t_{i j}(v)d v}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "equation", "text": "$$\nx_{i j}=0\\implies y_{i j}^{\\prime}=0,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $A_{2}\\cap A_{1}\\,=\\,\\varnothing,A\\,=\\,A_{1}\\cup A_{2}$ . The leader minimizes the total travel time across all links subject to a budget constraint and the followers\u2019 equilibrium which is expressed as a network flow on the graph augmented by the leader\u2019s selected edges that satisfies O-D demands; the integral in the follower\u2019s objective models the desired equilibrium and evaluates to $\\begin{array}{r}{T_{i j}y_{i j}^{\\prime}+\\frac{0.15T_{i j}}{5c_{i j}^{4}}\\left(y_{i j}^{\\prime}\\right)^{5}}\\end{array}$ . ", "page_idx": 1}, {"type": "text", "text": "Going beyond the DNDP, Dempe [16] lists more than 70 applications of BiLO ranging from pricing in electricity markets (leader is an electricity-supplying retailer that sets the price to maximize profti, followers are consumers who react accordingly to satisfy their demands [60]) to interdiction problems in security settings (leader inspects a budgeted subset of nodes on a road network, follower selects a path such that they evade inspection [56]). ", "page_idx": 1}, {"type": "text", "text": "Scope of this work. We are interested in mixed-integer non-linear bilevel optimization problems, simply referred to hereafter as bilevel optimization or BiLO, a very general class of bilevel problems where all constraints and objectives may involve non-linear terms and integer variables. At a high level, we have identified three limitations of existing computational methods for BiLO: ", "page_idx": 1}, {"type": "text", "text": "1. The state-of-the-art exact solvers of Fischetti et al. [24] and Tahernejad et al. [53] are limited to mixed-integer bilevel linear problems and do not scale well. When high-quality solutions to large-scale problems are sought after, such exact solvers may be prohibitively slow.   \n2. Specialized algorithms, heuristic or exact, do not generalize beyond the single problem they were designed for. For instance, the state-of-the-art exact Knapsack Interdiction solver [57] only works for a single knapsack constraint and fails with two or more, a significant limitation even if one is strictly interested in knapsack-type problems.   \n3. Existing methods, exact or heuristic, generic or specialized, are not designed for the \u201cdata-driven algorithm design\u201d setting [3] in which similar instances are routinely solved and the goal is to construct generalizable high-efficiency algorithms that leverage historical data. ", "page_idx": 1}, {"type": "text", "text": "NEUR2BILO (for Neural Bilevel Optimization) is a learning-based framework for bilevel optimization that deals with these issues simultaneously. The following observations make NEUR2BILO possible: ", "page_idx": 1}, {"type": "text", "text": "1. Data collection is \u201ceasy\u201d: For a fixed decision of the leader\u2019s, the optimal value of the follower can be computed by an appropriate (single-level) solver (e.g., for mixed-integer programming (MIP) or convex programming), enabling the collection of samples of the form: (leader\u2019s decision, follower\u2019s value, leader\u2019s value).   \n2. Offline learning in the data-driven setting: While obtaining data online may be prohibitive, access to historical training instances affords us the ability to construct, offline, a large dataset of samples that can then serve as the basis for learning an approximate value function using supervised regression. The output of this training is a regressor mapping a pair consisting of an instance and a leader\u2019s decision to an estimated follower or leader value.   \n3. MIP embeddings of neural networks: If the regressor is MIP-representable, e.g., a feedforward ReLU neural network or a decision tree, it is possible to use a MIP solver to find the leader\u2019s decision that minimizes the regressor\u2019s output. This MIP, which includes any leader constraints, thus serves as an approximate single-level surrogate of the original bilevel problem instance.   \n4. Follower constraints via the value function reformulation: The final ingredient of the NEUR2BILO recipe is to include any of the follower\u2019s constraints, some of which may ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "involve leader variables. This makes the surrogate problem a heuristic version of the well-known value function reformulation (VFR) in BiLO. The VFR transforms a bilevel problem into a single-level one, assuming that one can represent the follower\u2019s value (as a function of the leader\u2019s decision) compactly. This is typically impossible as the value function may require an exponential number of constraints, a bottleneck that is circumvented by our small (approximate) regression models. ", "page_idx": 2}, {"type": "text", "text": "5. Theoretical guarantees: For interdiction problems, a class of BiLO problems that attract much attention, NEUR2BILO solutions have a constant, additive absolute optimality gap which mainly depends on the prediction accuracy of the regression model. ", "page_idx": 2}, {"type": "text", "text": "Through a series of experiments on (i) the bilevel knapsack interdiction problem, (ii) the \u201ccritical node problem\u201d from network security, (iii) a donor-recipient healthcare problem, and (iv) the DNDP, we will show that NEUR2BILO is easy to train and produces, very quickly, heuristic solutions that are competitive with state-of-the-art methods. ", "page_idx": 2}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Bilevel optimization (BiLO) deals with hierarchical problems where the leader (or upper-level) problem decides on $\\mathbf{x}\\in\\mathcal{X}$ and parameterizes the follower (or lower-level) problem that decides on $\\mathbf{y}\\in\\mathcal{V}$ ; the sets $\\mathcal{X}$ and $\\boldsymbol{\\wp}$ represent the domains of the variables (continuous, mixed-integer, or pure integer). Both problems have their own objectives and constraints, resulting in the following model: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathbf{x}\\in\\mathcal{X},\\mathbf{y}}{\\mathrm{min}}}&{F(\\mathbf{x},\\mathbf{y})}\\\\ {\\mathrm{s.t.}}&{G(\\mathbf{x},\\mathbf{y})\\geq\\mathbf{0},}\\\\ &{\\mathbf{y}\\in\\underset{\\mathbf{y}^{\\prime}\\in\\mathcal{Y}}{\\arg\\operatorname*{max}}\\{f(\\mathbf{x},\\mathbf{y}^{\\prime}):g(\\mathbf{x},\\mathbf{y}^{\\prime})\\geq\\mathbf{0}\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where we consider the general mixed-integer non-linear case with $F,f:\\mathcal{X}\\times\\mathcal{Y}\\to\\mathbb{R}$ , $G:\\mathcal{X}\\times\\mathcal{Y}\\rightarrow$ $\\mathbb{R}^{m_{1}}$ , and $g:\\mathcal{X}\\times\\mathcal{Y}\\rightarrow\\mathbb{R}^{m_{2}}$ non-linear functions of the upper-level $\\mathbf{x}$ and lower-level variables $\\mathbf{y}$ . ", "page_idx": 2}, {"type": "text", "text": "The applicability of exact (i.e., global) approaches critically depends on the nature of the lower-level problem. A continuous lower-level problem admits a single-level reformulation that leverages the Karush-Kuhn-Tucker (KKT) conditions as constraints on y. For linear programs in the lower level, strong duality conditions can be used in the same way. Solving a BiLO problem with integers in the lower level necessitates more sophisticated methods such as branch and cut [17, 24] along with some assumptions: DeNegre and Ralphs [17] do not allow for coupling constraints (i.e., $G(\\mathbf{x},\\mathbf{y})=G(\\mathbf{x}))$ and both methods do not allow continuous upper-level variables to appear in the linking constraints $(g(\\mathbf x,\\mathbf y))$ ). Other approaches, such as Benders decomposition, are also applicable [25]. G\u00fcm\u00fc\u00b8s and Floudas [29] propose single-level reformulations of mixed-integer non-linear BiLO problems using polyhedral theory, an approach that only works for small problems. Later, \u201cbranch-and-sandwich\u201d methods were proposed [33, 45] where bounds on both levels\u2019 value functions are used to compute an optimal solution. Algorithms for non-linear BiLO generally do not scale well. Kleinert et al. [32] survey more exact methods. ", "page_idx": 2}, {"type": "text", "text": "Assumptions. In what follows, we make the following standard assumptions: ", "page_idx": 2}, {"type": "text", "text": "1. Either (i) the follower\u2019s problem has a feasible solution for each $\\mathbf{x}\\in\\mathcal{X}$ , or (ii) there are no coupling constraints in the leader\u2019s problem, i.e., $G(\\mathbf{x},\\mathbf{y})=G(\\mathbf{x})$ ; 2. The optimal follower value is always attained by a feasible solution [see 5, Section 7.2]. ", "page_idx": 2}, {"type": "text", "text": "Value function reformulation. We consider the so-called optimistic setting: if the follower has multiple optima for a given decision of the leader\u2019s, the one that optimizes the leader\u2019s objective is implemented. We can then rewrite problem (1) using the value function reformulation (VFR): ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathbf{x}\\in\\mathcal{X},\\mathbf{y}\\in\\mathcal{Y}}{\\mathrm{min}}}&{F(\\mathbf{x},\\mathbf{y})}\\\\ {\\mathrm{s.t.}}&{G(\\mathbf{x},\\mathbf{y})\\geq\\mathbf{0},}\\\\ &{g(\\mathbf{x},\\mathbf{y})\\geq\\mathbf{0},}\\\\ &{f(\\mathbf{x},\\mathbf{y})\\geq\\Phi(\\mathbf{x}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with the optimal lower-level value function defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Phi(\\mathbf x)=\\operatorname*{max}_{\\mathbf y\\in\\mathcal{Y}}\\{f(\\mathbf x,\\mathbf y):g(\\mathbf x,\\mathbf y)\\geq\\mathbf{0}\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Lozano and Smith [39] used this formulation to construct an exact algorithm (without any public code) for solving mixed-integer non-linear BiLO problems with purely integer upper-level variables. Sinha et al. [50, 51, 52] propose a family of evolutionary heuristics for continuous non-linear BiLO problems that approximate the optimal value function by using quadratic and Kriging (i.e., a function interpolation method) approximations. Taking it one step further, Beykal et al. [9] extend the framework of the previous authors to handle mixed-integer variables in the lower level. ", "page_idx": 3}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "NEUR2BILO refers to two learning-based single-level reformulations for general BiLO problems. The reformulations rely on representing the thorny nested structure of a BiLO problem with a trained regression model that predicts either the upper-level or lower-level value functions. Appendix B includes pseudocode for data collection, training, and model deployment. ", "page_idx": 3}, {"type": "text", "text": "3.1 NEUR2BILO ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Upper-level approximation. The obvious bottleneck in solving BiLO problems is their nested structure. One rather straightforward way of circumventing this difficulty is to get rid of the lower level altogether in the formulation, but predict its optimal value. Namely, we predict the optimal upper-level objective value function as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{NN}^{u}(\\mathbf{x};\\Theta)\\approx F(\\mathbf{x},\\mathbf{y}^{\\star}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\Theta$ are the weights of a neural network, $F$ the objective function of the leader (2b), and $\\mathbf{y}^{\\star}$ an optimal solution to the lower level problem (3). To train such a model, one can sample $\\mathbf{x}$ from $\\mathcal{X}$ , solve (3) to obtain an optimal lower-level solution $\\mathbf{y}^{\\star}$ , and subsequently compute a label $F(\\mathbf{x},\\mathbf{y}^{\\star})$ . We can then model the single-level problem as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}\\quad\\mathrm{NN}^{u}(\\mathbf{x};\\Theta)\\quad\\mathrm{~s.t.~}G(\\mathbf{x})\\geq\\mathbf{0},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where we only optimize for $\\mathbf{x}$ and thus dismiss the lower-level constraints and objective function. A trained feedforward neural network $\\mathrm{NN}^{u}(\\cdot;\\Theta)$ with ReLU activations can be represented as a mixed-integer linear program (MILP) [22], where now the input (and output) of the network are decision variables. With this representation, Problem (5) becomes a single-level problem and can be solved using an off-the-shelf MIP solver. Note that linear and decision tree-based models also admit MILP representations [38]. ", "page_idx": 3}, {"type": "text", "text": "This reformulation is similar to the approach by Bagloee et al. [2], wherein the upper-level value function is predicted using linear regression. Our method differs in that it is not iterative and does not require the use of \u201cno-good cuts\u201d (which avoid reappearing solutions $\\mathbf{x}$ ). As such, our method is extremely efficient as will be shown experimentally. ", "page_idx": 3}, {"type": "text", "text": "The formulation of (5) only allows for problem classes that do not have coupling constraints, i.e., $G(\\mathbf{x},\\mathbf{y})\\,=\\,G(\\mathbf{x})$ . Moreover, the feasibility of a solution $\\mathbf{x}$ in the original BiLO problem is not guaranteed, an issue that will be addressed later in this section (see Bilevel feasibility.). ", "page_idx": 3}, {"type": "text", "text": "Lower-level approximation. This method makes use of the VFR (2). The VFR moves the nested complexity of a BiLO to constraint (2d), where the right-hand side is the optimal value of the lower-level problem, parameterized by $\\mathbf{x}$ . We introduce a learning-based VFR in which $\\Phi(\\mathbf{x})$ is approximated by a regression model with parameters $\\Theta$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)\\approx\\Phi(\\mathbf{x}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Both $\\mathbf{NN}^{l}$ and ${\\tt N N}^{u}$ take in a leader\u2019s decision as input and require solving the follower (3) for data generation. By replacing $\\Phi(\\mathbf{x})$ with $\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)$ in (2d) and introducing a slack variable $s\\in\\mathbb{R}_{+}$ , the ", "page_idx": 3}, {"type": "text", "text": "surrogate VFR reads as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathbf{x}\\in\\mathcal{X},\\mathbf{y}\\in\\mathcal{Y}}{\\mathrm{min}}}&{F(\\mathbf{x},\\mathbf{y})+\\lambda s}\\\\ {\\mathrm{s}\\geq0}\\\\ {\\mathrm{s}.\\mathrm{t}.}&{G(\\mathbf{x},\\mathbf{y})\\geq\\mathbf{0},}\\\\ &{g(\\mathbf{x},\\mathbf{y})\\geq\\mathbf{0},}\\\\ &{f(\\mathbf{x},\\mathbf{y})\\geq\\mathbf{N}^{l}(\\mathbf{x};\\boldsymbol{\\Theta})-s.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "All follower and leader constraints of the original BiLO problem are part of Problem (7). However, without the slack variable $s$ , the problem could become infeasible due to inaccurate predictions by the neural network. This happens when $\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)$ strictly overestimates the follower\u2019s optimal value for each $\\mathbf{x}$ . In this case, there does not exist a follower decision for which Constraint (7d) is satisfied. A value of $s\\,>\\,0$ can be used to make Constraint (7d) satisfiable at a cost of $\\lambda s$ in the objective, guaranteeing feasibility. ", "page_idx": 4}, {"type": "text", "text": "Bilevel feasibility. Given a solution $\\mathbf{x}^{\\star}$ or a solution pair $(\\mathbf{x}^{\\star},\\tilde{\\mathbf{y}})$ returned by our upper- or lowerlevel approximations, respectively, we would like to produce a lower-level solution $\\mathbf{y}^{\\star}$ such that $(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})$ is bilevel-feasible, i.e., it satisfies the original BiLO in (1). The following procedure achieves this goal: ", "page_idx": 4}, {"type": "text", "text": "1. Compute the follower\u2019s optimal value under $\\mathbf{x}^{\\star}$ , $\\Phi(\\mathbf{x}^{\\star})$ , by solving (3). 2. Compute a bilevel-feasible follower solution $\\mathbf{y}^{\\star}$ by solving problem (2) with fixed $\\mathbf{x}^{\\star}$ and the right-hand side of (2d) set to $\\Phi(\\mathbf{x}^{\\star})$ , a constant. Return $(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})$ . ", "page_idx": 4}, {"type": "text", "text": "If only Assumption 1(i) is satisfied, then only the lower-level approximation is applicable and this procedure guarantees an optimistic bilevel-feasible solution for it. If only Assumption 1(ii) is satisfied, then this procedure can detect in Step 1 that an upper-level approximation\u2019s solution $\\mathbf{x}^{\\star}$ does not admit a follower solution, i.e., that it is infeasible, or calculates a feasible $\\mathbf{y}^{\\star}$ if one exists in Step 2. If both Assumptions 1(i) and 1(ii) are satisfied simultaneously, then this procedure guarantees an optimistic bilevel-feasible solution for either approximation. ", "page_idx": 4}, {"type": "text", "text": "Upper- v.s. lower-level level approximation. Here, we note two important trade-offs between the upper- and lower-level approximations. ", "page_idx": 4}, {"type": "text", "text": "\u2013 Generality: Example C.1 in Appendix C shows that under Assumption 1(ii), it may happen that solving the upper-level approximation problem variant (5) returns an infeasible solution while the lower-level variant (7) does not. ", "page_idx": 4}, {"type": "text", "text": "\u2013 Scalability: The upper-level approximation has fewer variables and constraints than its lowerlevel counterpart as it does not represent the follower\u2019s problem directly. For problems in which the lower-level problem is large, e.g., necessitating constraints for each node and link to enforce a network flow in the follower solution as in the DNDP from the introduction, this property makes the upper-level approximation easier to solve, possibly at a sacrifice in final solution quality. This tradeoff will be assessed experimentally. ", "page_idx": 4}, {"type": "text", "text": "Limitations. Since NEUR2BILO is in essence a learning-based heuristic, it does not guarantee an optimal solution to the bilevel problem. However, it guarantees a feasible solution with the lower-level approximation and can only give an infeasible solution while using the upper-level approximation when only Assumption 1(ii) is satisfied. Moreover, as will be shown in Section 3.3, the performance of NEUR2BILO depends on the regression error, which is generally the case when integrating machine learning in optimization algorithms. Empirically, we note that the prediction error achieved on every problem is very low (see Appendix K.3). ", "page_idx": 4}, {"type": "text", "text": "3.2 Model architecture ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "For ease of notation in previous sections, all regression models take as input the upper-level decision variables. However, in our experiments, we leverage instance information as well to train a single model that can be deployed on a family of instances. This is done by leveraging information such as coefficients in the objective and constraints for each problem. ", "page_idx": 4}, {"type": "text", "text": "For the model\u2019s architecture, the general principle deployed is to first explicitly represent or learn instance-based features. The second is to combine instance-based features with (leader) decision variable information to make predictions. ", "page_idx": 5}, {"type": "text", "text": "The overall architecture can be summarized as the following set of operations. Fix a particular instance of a BiLO problem and let $n$ be the number of leader variables, $\\mathbf{f}_{i}$ a vector of features for each leader variable $\\mathbf{x}_{i}$ (independently of the variable\u2019s value), and $h(\\mathbf{x}_{i})$ a feature map that describes the ith leader variable for a specific value of that variable. The functions $\\Psi^{s},\\Psi^{d}$ , and $\\Psi^{v}$ are neural networks with appropriate input-output dimensions. The vector $\\Theta$ includes all learnable parameters of networks $\\Psi^{s},\\Psi^{d}$ , and $\\Psi^{v}$ . The functions SUM, CONCAT, and AGGREGATE sum up a set of vectors, concatenate two vectors into a single column vector, and aggregate a set of scalar values (e.g., by another neural network or simply summing them up), respectively. Our final objective value predictions are then given by the following sequence of steps: ", "page_idx": 5}, {"type": "text", "text": "1. Embedding the set of variable features $\\{\\mathbf{f}_{i}\\}$ using a set-based architecture, e.g., the same network $\\Psi^{d}$ , summing up the resulting $n$ variable embeddings, then passing the resulting vector to network $\\Psi^{s}$ , yielding a vector we refer to as the INSTANCEEMBEDDING: ", "page_idx": 5}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\begin{array}{r}{\\mathrm{INSTANCEEMBEDDING}=\\Psi^{s}\\big(\\mathrm{SUM}\\big(\\{\\Psi^{d}(\\mathbf{f}_{i})\\}_{i=1}^{n}\\big)\\big).}\\end{array}$ . This is akin to the DeepSets approach of Zaheer et al. [58]. However, note that this step can alternatively be done via a feedforward or graph neural network depending on the problem structure.   \n2. Conditional on a specific assignment of values to the leader\u2019s decision vector $\\mathbf{x}$ , a per-variable embedding is computed by network $\\Psi^{v}$ to allow for interactions between the INSTANCEEMBEDDING and the specific assignment of variable $i$ as represented by $h(\\mathbf{x}_{i})$ : VARIABLEEMBEDDING $\\mathbf{\\Phi}_{\\mathrm{I}}(i)=\\Psi^{v}(\\mathbf{CovCAT}(h(\\mathbf{x}_{i})$ , INSTANCEEMBEDDING)).   \n3. The final value prediction for either of our approximations aggregates the variable embeddings possibly after passing them through a function $g_{i}$ : $\\begin{array}{r}{\\mathbf{NN}(\\mathbf{x};\\boldsymbol{\\Theta})=\\mathrm{AGGREGATE}\\big(\\{g_{i}\\big(\\mathrm{VARIABLEEMBEDDING}(i)\\big)\\}_{i=1}^{n}\\big).}\\end{array}$ For example, if the follower\u2019s objective is a linear function and VARIABLEEMBEDDING $(i)$ is a scalar, then it is useful to use the variable\u2019s known objective function coefficient $d_{i}$ here, i.e.: $g_{i}\\big(\\mathrm{VARIABLEMBEDDING}(i)\\big)=d_{i}\\,.$ VARIABLEEMBEDDING $(i)$ . The final step is to aggregate the per-variable $g_{i}(\\cdot)$ outputs, e.g., by a summation for linear or separable objective functions. ", "page_idx": 5}, {"type": "text", "text": "NEUR2BILO is largely agnostic to the learning model utilized as long as it is MILP-representable. In our experiments, we primarily focus on neural networks, but for some problems also explore the use of gradient-boosted trees. More details on the specific architectures for each problem can be found in Appendix K.1. ", "page_idx": 5}, {"type": "text", "text": "3.3 Approximation guarantees ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Lower-level approximation. Next, we present an approximation guarantee for the lower-level approximation with $\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)$ . Appendix D includes the complete proofs. ", "page_idx": 5}, {"type": "text", "text": "Since the prediction of the neural network is only an approximation of the true optimal value of the follower\u2019s problem $\\Phi(\\mathbf{x})$ , NEUR2BILO may return sub-optimal solutions for the original problem (1). We derive approximation guarantees for a specific setup that appears in interdiction problems: the leader and the follower have the same objective function (i.e., $\\bar{f}(\\mathbf{x},\\mathbf{y})=F(\\mathbf{x},\\mathbf{y})$ for all $\\mathbf{x}\\in\\mathcal{X},\\mathbf{y}\\in\\mathcal{Y})$ , and Assumption 1(i) holds. Consider a neural network that approximates the optimal value of the follower\u2019s problem up to an absolute error of $\\alpha>0$ , i.e., ", "page_idx": 5}, {"type": "equation", "text": "$$\n|\\mathbf{NN}^{l}(\\mathbf{x};\\Theta)-\\Phi(\\mathbf{x})|\\leq\\alpha\\quad\\mathrm{~for~all~}\\mathbf{x}\\in\\mathcal{X}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Furthermore, we define the parameter $\\Delta$ as the maximum difference $f(\\mathbf{x},\\mathbf{y})-f(\\mathbf{x},\\mathbf{y}^{\\prime})\\geq0$ over all $\\mathbf{x}\\in{\\mathcal{X}},\\mathbf{y},\\mathbf{y}^{\\prime}\\in{\\mathcal{Y}}$ such that no $\\tilde{\\mathbf{y}}\\in\\mathcal{V}$ exists which has function value $f(\\mathbf{x},\\mathbf{y})>f(\\mathbf{x},\\tilde{\\mathbf{y}})>f(\\mathbf{x},\\mathbf{y}^{\\prime})$ We can bound the approximation guarantee of the lower-level NEUR2BILO as follows: ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.1. If the leader and the follower have the same objective function and $\\lambda\\ >\\ 1$ , NEUR2BILO returns a feasible solution $(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})$ for Problem (1) with objective value ", "page_idx": 5}, {"type": "equation", "text": "$$\nf(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})\\leq\\mathrm{opt}+3\\alpha+\\frac2\\lambda\\Delta,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where opt is the optimal value of (1) and $\\lambda$ the penalty term in (7a) . ", "page_idx": 5}, {"type": "text", "text": "Upper-level approximation. As Example C.1 shows, it may happen that the upper-level surrogate problem (5) returns an infeasible solution and hence no approximation guarantee can be derived in this case. However, in the case where all leader solutions are feasible and the neural network predicts for every $\\mathbf{x}\\in\\mathcal{X}$ an upper-level objective value that deviates at most $\\alpha>0$ from the true one, then the returned solution trivially approximates the true optimal value with an absolute error of at most $2\\alpha$ . This follows since the worst that can happen is that the objective value of the optimal solution is overestimated by $\\alpha$ while a solution with objective value $\\mathrm{opt}+2\\alpha$ is underestimated by $\\alpha$ and hence has the same predicted value as the optimal solution. Problem (5) then may return the latter sub-optimal solution. ", "page_idx": 6}, {"type": "text", "text": "4 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Benchmark problems and their characteristics are summarized in Table 1; their MIP formulations are deferred to Appendix E and brief descriptions follow: ", "page_idx": 6}, {"type": "text", "text": "\u2013 Knapsack interdiction (KIP) [10]: The leader interdicts a subset of at most $k$ items and the follower solves a knapsack problem over the remaining (non-interdicted) items. The leader aims to minimize the follower\u2019s (maximization) objective. ", "page_idx": 6}, {"type": "text", "text": "\u2013 Critical node problem (CNP) [18, 11]: This problem regards the protection (by the leader) of resources in a network against malicious follower attacks. It has applications in the protection of computer networks against cyberattacks as demonstrated by Dragotto et al. [18]. ", "page_idx": 6}, {"type": "text", "text": "\u2013 Donor-recipient problem (DRP) [27]: This problem relates to the donations given by certain agencies to countries in need of, e.g., healthcare projects. The leader (the donor agency) decides on which proportion of the cost, per project, to subsidize, whereas the follower (a country) decides which projects it implements. ", "page_idx": 6}, {"type": "text", "text": "\u2013 Discrete network design problem (DNDP) [47]: This is the problem described in Section 1. We build on the work of Rey [47] who provided benchmark instances for the transportation network of Sioux Falls, South Dakota, and an implementation of the state-of-the-art method of Fontaine and Minner [25]. This network and corresponding instances are representative of the state of the DNDP in the literature. ", "page_idx": 6}, {"type": "table", "img_path": "esVleaqkRc/tmp/1bcdd71a9746e229a3e520208f520f5194c398da7c147d78cc53c8c8bc937e06.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Table 1: Problem class characteristics. All problems have a single budget constraint in the leader; for the follower, the DNDP has network flow constraints whereas other problems have a knapsack constraint. The arrows refer to minimization $\\left(\\downarrow\\right)$ or maximization (\u2191) in leader and follower, respectively. $\\mathbf{B}=$ Binary, ${\\bf C}={\\bf\\Psi}$ Continuous, $\\mathbf{M}\\mathbf{I}=1$ Mixed-Integer, Lin $=$ Linear, BLin $=$ Bilinear, NLin $=$ Non-Linear. ", "page_idx": 6}, {"type": "text", "text": "Baselines. As mentioned previously, the branch-and-cut (B&C) algorithm by Fischetti et al. [24] is considered to be state-of-the-art for solving mixed-integer linear BiLO. The method is applicable if the continuous variables of the leader do not appear in the follower\u2019s constraints. Both KIP and CNP meet these assumptions. This algorithm will act as the baseline for these problems. For DRP, we compare against the results produced by an algorithm in the branch-and-cut paradigm $(\\mathbf{B}\\&C+)$ from Ghatkar et al. [27]. For DNDP, the follower\u2019s problem only has continuous variables, so the baseline is a method based on KKT conditions (MKKT) [25]. Of the learning-based approaches for BiLO, we compare against Zhou et al. [59], given the generality of their approach and the availability of source code. NEUR2BILO decisively outperforms this method on KIP, finding solutions with $10\u2013100\\times$ smaller mean relative error roughly $1000\\times$ faster; full results are deferred to Appendix F. ", "page_idx": 6}, {"type": "text", "text": "Data collection & Training. For each problem class, data is collected by sampling feasible leader decisions $\\mathbf{x}$ and then solving $\\Phi(\\mathbf{x})$ to compute either the upper- or lower-level objectives as labels. We then train regression models to minimize the least-squares error on the training samples. Typically, data collection and training take less than one hour, a negligible cost given that for larger instances baseline methods require more time per instance. Additionally, the same trained model can be used on multiple unseen test instances. We report times for data collection and training in Appendix K.2. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Evaluation & Setup. For evaluation in KIP, CNP, and DRP, all solving was limited to 1 hour. For DNDP, we consider a more limited-time regime, wherein we compare NEUR2BILO at 5 seconds against the baseline at 5, 10, and 30 seconds. For all problems, we evaluate both the lower- and upper-level approximations with neural networks, namely $\\mathbf{NN}^{l}$ and ${\\bf N N}^{u}$ . For $\\mathbf{NN}^{l}$ we set $\\lambda=1$ for all results presented in the main paper. Details of the computing setup are provided in Appendix J. Our code and data are available at https://github.com/khalil-research/Neur2BiLO. ", "page_idx": 7}, {"type": "text", "text": "5 Experimental Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We summarize the results as measured by average solution times and mean relative errors (MREs). The relative error on a given instance is computed as 100 \u00b7 |obj|oAb\u2212jboebsjtb|est|, where $o b j_{A}$ is the value of the solution found by method $\\boldsymbol{\\mathcal{A}}$ and $o b j_{b e s t}$ is the best-known objective value for that instance. These results are reported in Table 2. More detailed results and box-plots of the distributions of relative errors are in Appendices G and H. Our experimental design answers the following questions: ", "page_idx": 7}, {"type": "text", "text": "Q1: Can NEUR2BILO find high-quality solutions quickly on classical interdiction problems? Table 2 compares NEUR2BILO to the B&C algorithm of Fischetti et al. [24]. NEUR2BILO terminates in $1\\!-\\!2\\%$ of the time required by B&C on the smaller $(n\\leq30)$ ) well-studied KIP instances of Tang et al. [54]. However, when the instance size increases to $n=100$ , both $\\mathbf{NN}^{l}$ and ${\\bf N N}^{u}$ find much better solutions than NEUR2BILO in roughly 30 seconds, even when B&C runs for the full hour. Furthermore, Table 4 in Appendix G shows that B&C requires 10 to 1, $000\\times$ more time than $\\mathbf{NN}^{l}$ or ${\\bf N N}^{u}$ to find equally good solutions. In addition, the best solutions found by B&C at the termination times of $\\mathrm{NN}^{l}$ or ${\\bf N N}^{u}$ are generally worse, even for small instances. ", "page_idx": 7}, {"type": "text", "text": "Q2: Do these computational results extend to non-linear and more challenging BiLO problems? Interdiction problems such as the KIP are well-studied but are only a small subset of BiLO. We will shift attention to the more practical problems, starting with the CNP (Table 2). CNP includes terms that are bilinear (i.e., $z\\,=\\,x y.$ ) in the upper- and lower-level variables, resulting in a much more challenging problem for general-purpose B&C. In this case, both $\\mathbf{NN}^{l}$ and ${\\bf N N}^{u}$ tend to outperform B&C as the problem size increases. In addition, the results on incumbents reported in Table 5 in Appendix $\\mathrm{G}$ are as good, if not even stronger than those of KIP. ", "page_idx": 7}, {"type": "text", "text": "Secondly, we discuss DRP (Table 6 in Appendix G). For DRP, we evaluate on the most challenging instances from Ghahtarani et al. [26], all of which have gaps of $\\sim50\\%$ at a 1-hour time limit with $\\mathbf{B}\\&C+$ , a specialized B&C-based algorithm. Here ${\\bf N N}^{u}$ performs remarkably well: it finds the best-known solutions on every single instance in roughly $\\sim0.1$ seconds at an average improvement in solution quality of $26\\%$ over $\\mathbf{B}\\&C+$ . ", "page_idx": 7}, {"type": "text", "text": "Q3: How does NEUR2BILO perform on BiLO problems with complex constraints? Given that NEUR2BILO has strong performance on benchmarks with budget constraints, the next obvious question is whether it can be applied to BiLO problems that have complex constraints. To answer this, we will refer to the results in Table 2 for the DNDP. In this setting, we focus on a limited-time regime wherein we compare NEUR2BILO with a 5-second time limit to MKKT at time limits 5, 10, and 30 seconds. ${\\bf N N}^{u}$ can achieve high-quality solutions much faster than any other method with only a minor sacrifice in solution quality, making it a great candidate for domains where interactive decision-making is needed (e.g., what-if analysis of various candidate roads, budgets, etc.). ", "page_idx": 7}, {"type": "text", "text": "$\\mathbf{NN}^{l}$ , on the other hand, takes longer than ${\\bf N N}^{u}$ but computes solutions that are competitive with the baseline, the latter requiring $5\\times$ more time. We suspect that the better solution quality from $\\mathbf{NN}^{l}$ is due to its explicit modeling of feasible lower-level decisions that \u201calign\u201d with the predictions, whereas ${\\bf N N}^{u}$ may simply extrapolate poorly. In terms of computing time, one computational burden for $\\mathbf{NN}^{l}$ is the requirement to model the non-linear upper- and lower-level objectives, which requires a piece-wise linear approximation based on Fontaine and Minner [25], a step that introduces additional variables and constraints. Appendix $\\mathrm{G}$ includes results for DNDP with gradient-boosted trees (GBT), demonstrating that other learning models are directly applicable and, in some cases, may even lead to better solution quality, faster optimization, and simpler implementation. ", "page_idx": 7}, {"type": "table", "img_path": "esVleaqkRc/tmp/d1f707eb490c200070f52e76122d5423ba5232eab3cbf8972aa5bab3c05d4c0f.jpg", "table_caption": ["Knapsack Interdiction Problem "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "esVleaqkRc/tmp/dbd99d7f997fea6bab86b72d2bbee38415949f52e47e4f8032b51b5b84fa4f5d.jpg", "table_caption": ["Critical Node Problem "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "esVleaqkRc/tmp/c669208e62321dbdb3c4c9b051d4a2cabcd577188fa6f68d811dda8c45e9afc1.jpg", "table_caption": ["Discrete Network Design Problem "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 2: Mean relative error (MRE) and solving times for KIP, CNP, and DNDP. For KIP with $n\\leq30$ , we directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. For $n=100$ , our evaluation instances (100 per size) are generated using the same procedure of Tang et al. [54]. The no-learning baseline G-VFA is a VFR using the follower\u2019s greedy solution as lower-level value function approximation. For CNP, each row is averaged over 300 instances that are randomly sampled using the procedure described in Dragotto et al. [18]. For DNDP, each row is averaged over 10 instances from Rey [47]. The budget is a fraction of the total cost of all 30 possible candidate links; see Appendix K.2 for more details. ", "page_idx": 8}, {"type": "text", "text": "Q4: Can approximations derived from heuristics be useful? We now refer back to KIP and focus on the greedy value function approximation (G-VFA), a KIP-specific approximation that relies on the fact that greedy algorithms are typically good for 1-dimensional knapsack problems. Namely, the heuristic is based on ordering the items with their value-to-weight ratio [15] and is used as the knapsack solution in the follower problem, while still being parameterized by x. This heuristic is embedded in a single-level problem as this heuristic is MILP-representable [see 1]; we note that we are not aware of uses in the literature of this approximation and it may be of independent interest. Generally, G-VFA performs quite well, and in some cases outperforms $\\mathbf{NN}^{l}$ and ${\\bf N N}^{u}$ , but there are clear cases where $\\mathbf{NN}^{l}$ and ${\\bf N N}^{u}$ outperform G-VFA demonstrating that learning is beneficial. In addition, heuristics like G-VFA can be utilized to compute features for $\\mathbf{NN}^{l}$ and ${\\bf N N}^{u}$ . For KIP, the inclusion of these features derived from G-VFA strongly improves the results (see ", "page_idx": 8}, {"type": "text", "text": "Table 10 in Appendix I.3). This demonstrates that there is value in leveraging any problem-specific MILP-representable heuristics as features for learning. ", "page_idx": 9}, {"type": "text", "text": "Q5: How does $\\lambda$ affect $\\mathbf{NN}^{l}?$ Table 9 in Appendix I.2 shows that a slack penalty of $\\lambda\\,=\\,0.1$ notably improves the performance of both $\\mathbf{NN}^{l}$ and $\\mathrm{GBT}^{l}$ for DNDP, compared to the $\\lambda=1$ reported in Table 2. As an alternative to adding slack, one can even dampen predictions of the value function to allow more flexibility using the empirical error observed during training; see Table 8 in Appendix I.1. ", "page_idx": 9}, {"type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Learning for bilevel optimization. Besides the approaches of Sinha et al. [50, 51, 52] and Beykal et al. [9] discussed in Section 2, other learning-based methods have been introduced to solve BiLO problems. Bagloee et al. [2] present a heuristic for DNDP which uses a linear prediction of the leader\u2019s objective function. An iterative algorithm refines the prediction with new solutions, terminating after a pre-determined number of iterations. Chan et al. [13] propose to simultaneously optimize the parameters of a learning model for a subset of followers in a large-scale cycling network design problem. Here, only non-parametric or linear models are utilized as optimizing more sophisticated learning models is generally challenging with MILP-based optimization. Molan and Schmidt [42] make use of a neural network to predict the follower variables. The authors assume a setting with a black-box follower\u2019s problem, no coupling constraints, and continuous leader variables. Another learning-based heuristic is proposed by Kwon et al. [35] for a bilevel knapsack problem. This approach is knapsack-specific and requires a sophisticated, GPU-based, problem-specific graph neural network for which no code is publicly available. Zhou et al. [59] propose a learning-based algorithm for binary bilevel problems which, similar to our approach, predicts the optimal value function and develops a single-level reformulation based on the trained model. They propose using a graph neural network and an input-supermodular neural network, both of which can only be trained on a single instance rather than learning across classes of instances as NEUR2BILO does. NEUR2BILO significantly outperforms this method as shown in Appendix F. For continuous unconstrained bilevel optimization, a substantially different setting, many methods have been proposed recently due to interest in solving nested problems in machine learning (e.g., hyperparameter tuning and meta-learning) [37]. ", "page_idx": 9}, {"type": "text", "text": "Data-driven optimization. The integration of a trained machine learning model into a MIP is a vital element of NEUR2BILO. This is possible due to MILP formulations of neural networks [14, 22, 49], and of other predictors like decision trees [38, 8]. These methods have become easily applicable due to open software implementations [7, 12, 40, 55] and the gurobi-machinelearning library. One such application is constraint learning [21]. More similar to our setting are the approaches in [19, 20, 34] for predicting value functions of other nested problems such as two-stage stochastic and robust optimization. Our method caters to the specificities of BiLO, particularly in the lower-level approximation which performs well in highly-constrained BiLO settings such as the DNDP, has approximation guarantees based on the error of the predictive model, and computational results on problems with non-linear interactions between the variables in each stage of the optimization problem; these aspects distinguish NEUR2BILO from prior work. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In both its upper- and lower-level instantiations, NEUR2BILO finds high-quality solutions in a few milliseconds or seconds across four benchmarks that span applications in interdiction, network security, healthcare, and transportation planning. In fact, we are not aware of any bilevel optimization method which has been evaluated across such a diverse range of problems as existing methods make stricter assumptions that limit their applicability. NEUR2BILO models are generic, easy to train, and accommodating of problem-specific heuristics as features. One limitation of our experiments is that they lack a problem that involves coupling constraints in (1b). We could not identify benchmark problems with this property in the literature, but exploring this setting would be valuable. Of future interest are potential extensions to bilevel stochastic optimization [6], robust optimization with decision-dependent uncertainty [28] (a special case of BiLO), and multi-level problems beyond two levels, e.g. [36]. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Dumouchelle, Julien, and Khalil acknowledge funding support from the Natural Sciences and Engineering Research Council Discovery Grant Program and the SCALE AI Research Chair Program. Julien received funding from the Dutch Research Council (Nederlandse Organisatie voor Wetenschappelijk Onderzoek, NWO) under project OCENW.GROOT.2019.015. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] David Avis, David Bremner, Hans Raj Tiwary, and Osamu Watanabe. Polynomial size linear programs for problems in p. Discrete Applied Mathematics, 265:22\u201339, 2019. [2] Saeed Asadi Bagloee, Mohsen Asadi, Majid Sarvi, and Michael Patriksson. A hybrid machinelearning and optimization method to solve bi-level problems. Expert Systems with Applications, 95:142\u2013152, 2018.   \n[3] Maria-Florina Balcan. Data-driven algorithm design. arXiv preprint arXiv:2011.07177, 2020. [4] Jonathan F Bard. Practical bilevel optimization: algorithms and applications, volume 30. Springer Science & Business Media, 2013.   \n[5] Yasmine Beck and Martin Schmidt. A gentle and incomplete introduction to bilevel optimization. Lecture notes, 2021.   \n[6] Yasmine Beck, Ivana Ljubi\u00b4c, and Martin Schmidt. A survey on bilevel optimization under uncertainty. European Journal of Operational Research, 2023.   \n[7] David Bergman, Teng Huang, Philip Brooks, Andrea Lodi, and Arvind U Raghunathan. JANOS: an integrated predictive and prescriptive modeling framework. INFORMS Journal on Computing, 34(2):807\u2013816, 2022. [8] Dimitris Bertsimas, Jack Dunn, and Yuchen Wang. Near-optimal nonlinear regression trees. Operations Research Letters, 49(2):201\u2013206, 2021.   \n[9] Burcu Beykal, Styliani Avraamidou, Ioannis PE Pistikopoulos, Melis Onel, and Efstratios N Pistikopoulos. Domino: Data-driven optimization of bi-level mixed-integer nonlinear problems. Journal of Global Optimization, 78:1\u201336, 2020.   \n[10] Alberto Caprara, Margarida Carvalho, Andrea Lodi, and Gerhard J Woeginger. Bilevel knapsack with interdiction constraints. INFORMS Journal on Computing, 28(2):319\u2013333, 2016.   \n[11] Margarida Carvalho, Gabriele Dragotto, Andrea Lodi, and Sriram Sankaranarayanan. Integer programming games: a gentle computational overview. In Tutorials in Operations Research: Advancing the Frontiers of OR/MS: From Methodologies to Applications, pages 31\u201351. INFORMS, 2023.   \n[12] Francesco Ceccon, Jordan Jalving, Joshua Haddad, Alexander Thebelt, Calvin Tsay, Carl D Laird, and Ruth Misener. OMLT: Optimization & machine learning toolkit. arXiv preprint arXiv:2202.02414, 2022.   \n[13] Timothy CY Chan, Bo Lin, and Shoshanna Saxe. A machine learning approach to solving large bilevel and stochastic programs: Application to cycling network design. arXiv preprint arXiv:2209.09404, 2022.   \n[14] Chih-Hong Cheng, Georg N\u00fchrenberg, and Harald Ruess. Maximum resilience of artificial neural networks. In International Symposium on Automated Technology for Verification and Analysis, pages 251\u2013268. Springer, 2017.   \n[15] George B Dantzig. Discrete-variable extremum problems. Operations research, 5(2):266\u2013288, 1957.   \n[16] Stephan Dempe. Bilevel optimization: theory, algorithms, applications and a bibliography. Bilevel Optimization: Advances and Next Challenges, pages 581\u2013672, 2020.   \n[17] Scott T DeNegre and Ted K Ralphs. A branch-and-cut algorithm for integer bilevel linear programs. In Operations research and cyber-infrastructure, pages 65\u201378. Springer, 2009.   \n[18] Gabriele Dragotto, Amine Boukhtouta, Andrea Lodi, and Mehdi Taobane. The critical node game, 2023.   \n[19] Justin Dumouchelle, Rahul Patel, Elias B Khalil, and Merve Bodur. Neur2SP: Neural two-stage stochastic programming. Advances in Neural Information Processing Systems, 35, 2022.   \n[20] Justin Dumouchelle, Esther Julien, Jannis Kurtz, and Elias Boutros Khalil. Neur2RO: Neural two-stage robust optimization. In The Twelfth International Conference on Learning Representations, 2024.   \n[21] Adejuyigbe O Fajemisin, Donato Maragno, and Dick den Hertog. Optimization with constraint learning: a framework and survey. European Journal of Operational Research, 2023.   \n[22] Matteo Fischetti and Jason Jo. Deep neural networks and mixed integer linear optimization. Constraints, 23(3):296\u2013309, 2018.   \n[23] Matteo Fischetti, Ivana Ljubic\u00b4, Michele Monaci, and Markus Sinnl. Intersection cuts for bilevel optimization. In Integer Programming and Combinatorial Optimization: 18th International Conference, IPCO 2016, Li\u00e8ge, Belgium, June 1-3, 2016, Proceedings 18, pages 77\u201388. Springer, 2016.   \n[24] Matteo Fischetti, Ivana Ljubi\u00b4c, Michele Monaci, and Markus Sinnl. A new general-purpose algorithm for mixed-integer bilevel linear programs. Operations Research, 65(6):1615\u20131637, 2017.   \n[25] Pirmin Fontaine and Stefan Minner. Benders decomposition for discrete\u2013continuous linear bilevel problems with application to traffic network design. Transportation Research Part B: Methodological, 70:163\u2013172, 2014.   \n[26] Alireza Ghahtarani, Ahmed Saif, Alireza Ghasemi, and Erick Delage. A double-oracle, logicbased benders decomposition approach to solve the $\\mathbf{k}$ -adaptability problem. Computers & Operations Research, 155:106243, 2023.   \n[27] Shraddha Ghatkar, Ashwin Arulselvan, and Alec Morton. Solution techniques for bi-level knapsack problems. Computers & Operations Research, 159:106343, 2023.   \n[28] Marc Goerigk, Jannis Kurtz, Martin Schmidt, and Johannes Th\u00fcrauf. Connections and reformulations between robust and bilevel optimization. optimization-online pre-print, 2023.   \n[29] Zeynep H G\u00fcm\u00fcs\u00b8 and Christodoulos A Floudas. Global optimization of mixed-integer bilevel programming problems. Computational Management Science, 2:181\u2013212, 2005.   \n[30] Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual, 2023. URL https://www. gurobi.com.   \n[31] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[32] Thomas Kleinert, Martine Labb\u00e9, Ivana Ljubi\u00b4c, and Martin Schmidt. A survey on mixedinteger programming techniques in bilevel optimization. EURO Journal on Computational Optimization, 9:100007, 2021.   \n[33] Polyxeni-M Kleniati and Claire S Adjiman. A generalization of the branch-and-sandwich algorithm: from continuous to mixed-integer nonlinear bilevel problems. Computers & Chemical Engineering, 72:373\u2013386, 2015.   \n[34] Jan Kronqvist, Boda Li, Jan Rolfes, and Shudian Zhao. Alternating mixed-integer programming and neural network training for approximating stochastic two-stage problems. arXiv preprint arXiv:2305.06785, 2023.   \n[35] Sunhyeon Kwon, Hwayong Choi, and Sungsoo Park. Solving bilevel knapsack problem using graph neural networks. arXiv preprint arXiv:2211.13436, 2022.   \n[36] Markus Leitner, Ivana Ljubic\u00b4, Michele Monaci, Markus Sinnl, and K\u00fcbra Tan\u0131nm\u0131\u00b8s. An exact method for binary fortification games. European Journal of Operational Research, 307(3): 1026\u20131039, 2023.   \n[37] Risheng Liu, Jiaxin Gao, Jin Zhang, Deyu Meng, and Zhouchen Lin. Investigating bi-level optimization for learning and vision from a unified perspective: A survey and beyond. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(12):10045\u201310067, 2021.   \n[38] Michele Lombardi, Michela Milano, and Andrea Bartolini. Empirical decision model learning. Artificial Intelligence, 244:343\u2013367, 2017.   \n[39] Leonardo Lozano and J Cole Smith. A value-function-based exact approach for the bilevel mixed-integer programming problem. Operations Research, 65(3):768\u2013786, 2017.   \n[40] Donato Maragno, Holly Wiberg, Dimitris Bertsimas, $\\mathrm{S}$ \u02d9Ilker Birbil, Dick den Hertog, and Adejuyigbe O Fajemisin. Mixed-integer optimization with constraint learning. Operations Research, 2023.   \n[41] Tom V Mathew and KV Krishna Rao. Introduction to transportation engineering, traffic assignment. Lecture notes, 2006.   \n[42] Ioana Molan and Martin Schmidt. Using neural networks to solve linear bilevel problems with unknown lower level. Optimization Letters, pages 1\u201321, 2023.   \n[43] Alec Morton, Ashwin Arulselvan, and Ranjeeta Thomas. Allocation rules for global donors. Journal of health economics, 58:67\u201375, 2018.   \n[44] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, highperformance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9- Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8024\u20138035. Curran Associates, Inc., 2019. http://papers.neurips.cc/paper/9015-pytorchan-imperative-style-high-performance-deep-learning-library.pdf.   \n[45] Remigijus Paulavic\u02c7ius and Claire S Adjiman. New bounding schemes and algorithmic options for the branch-and-sandwich algorithm. Journal of Global Optimization, 77(2):197\u2013225, 2020.   \n[46] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825\u20132830, 2011.   \n[47] David Rey. Computational benchmarking of exact methods for the bilevel discrete network design problem. Transportation Research Procedia, 47:11\u201318, 2020.   \n[48] David Rey. Optimization and game-theoretical methods for transportation systems. PhD thesis, Toulouse 3 Paul Sabatier, 2023.   \n[49] Thiago Serra, Christian Tjandraatmadja, and Srikumar Ramalingam. Bounding and counting linear regions of deep neural networks. In International Conference on Machine Learning, pages 4558\u20134566. PMLR, 2018.   \n[50] Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. Solving optimistic bilevel programs by iteratively approximating lower level optimal value function. In 2016 IEEE Congress on Evolutionary Computation (CEC), pages 1877\u20131884. IEEE, 2016.   \n[51] Ankur Sinha, Zhichao Lu, Kalyanmoy Deb, and Pekka Malo. Bilevel optimization based on iterative approximation of multiple mappings, 2017.   \n[52] Ankur Sinha, Samish Bedi, and Kalyanmoy Deb. Bilevel optimization based on kriging approximations of lower level optimal value function. In 2018 IEEE congress on evolutionary computation (CEC), pages 1\u20138. IEEE, 2018.   \n[53] Sahar Tahernejad, Ted K Ralphs, and Scott T DeNegre. A branch-and-cut algorithm for mixed integer bilevel linear optimization problems and its implementation. Mathematical Programming Computation, 12:529\u2013568, 2020.   \n[54] Yen Tang, Jean-Philippe P Richard, and J Cole Smith. A class of algorithms for mixed-integer bilevel min\u2013max optimization. Journal of Global Optimization, 66:225\u2013262, 2016.   \n[55] Mark Turner, Antonia Chmiela, Thorsten Koch, and Michael Winkler. Pyscipopt-ml: Embedding trained machine learning models into mixed-integer programs. arXiv preprint arXiv:2312.08074, 2023.   \n[56] Alan Washburn and Kevin Wood. Two-person zero-sum games for network interdiction. Operations research, 43(2):243\u2013251, 1995.   \n[57] Noah Weninger and Ricardo Fukasawa. A fast combinatorial algorithm for the bilevel knapsack problem with interdiction constraints. In International Conference on Integer Programming and Combinatorial Optimization, pages 438\u2013452. Springer, 2023.   \n[58] Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and Alexander J Smola. Deep sets. Advances in neural information processing systems, 30, 2017.   \n[59] Bo Zhou, Ruiwei Jiang, and Siqian Shen. Learning to solve bilevel programs with binary tender. In The Twelfth International Conference on Learning Representations, 2024.   \n[60] Marco Zugno, Juan Miguel Morales, Pierre Pinson, and Henrik Madsen. A bilevel model for electricity retailers\u2019 participation in a demand response market environment. Energy Economics, 36:182\u2013197, 2013. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Impact Statement ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Bilevel optimization has been used to model attacker-defender situations, which could be used in defense or similar political contexts. We have attempted to cover more socially beneficial healthcare and transportation planning applications but duly acknowledge that our methods could be applied in rather nefarious domains. That being said, there remain many domains that could benefit from our work and that are widely beneficial, such as in the management of energy systems. ", "page_idx": 14}, {"type": "text", "text": "B NEUR2BILO Pseudocode ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Here, we outline pseudocode for NEUR2BILO. Algorithm 1 presents the pseudocode for data collection and training. Algorithm 2 presents the pseudocode for optimization. Following Algorithm 2, the objective is computed via the bilevel feasibility procedure detailed in Section 3.1. Note that data collection can be done once to collect labels for both the upper- and lower-level approximations. Additionally, a single trained model may be (and is in our experiments) evaluated across multiple test instances. ", "page_idx": 14}, {"type": "text", "text": "Algorithm 1 NEUR2BILO Data Collection and Training ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Data Collection $\\mathcal{D}\\gets\\{\\}$ for $i=1$ to number of instances to sample do $\\mathcal{P}\\leftarrow$ sampled instance. Note that $\\mathcal{P}$ is defined by $F(\\cdot),G(\\cdot),f(\\cdot),g(\\cdot),\\mathcal{Y}_{\\cdot}$ , and $\\mathcal{X}$ . For most BiLO problems, these functions are defined by the constraint and objective coefficients for $j=1$ to number of decisions per-instance do $\\mathbf{x}\\gets$ sampled upper-level decision $\\mathbf{y}^{\\star}\\leftarrow\\arg\\operatorname*{max}_{\\mathbf{y}\\in{\\boldsymbol{y}}}\\{f(\\mathbf{x},\\mathbf{y}):g(\\mathbf{x},\\mathbf{y})\\geq\\mathbf{0}\\}$ Add $(\\mathcal{P},\\mathbf{x},F(\\mathbf{\\dot{x}},\\mathbf{y}^{\\star}),f(\\mathbf{x},\\mathbf{y}^{\\star}))$ to $\\mathcal{D}$ end for end for return $\\mathcal{D}$   \nTraining if approximating upper-level then Train regressor $(\\mathsf{N N}^{u})$ with features $({\\mathcal{P}},\\mathbf{x})$ and label $(F(\\cdot))$ from dataset $\\mathcal{D}$ else if approximating lower-level then Train regressor $(\\mathsf{N N}^{l})$ with the features $({\\mathcal{P}},\\mathbf{x})$ and label $(f(\\cdot))$ from dataset $\\mathcal{D}$ end if return NNu or NNl ", "page_idx": 14}, {"type": "text", "text": "Algorithm 2 NEUR2BILO Optimization ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Input: Evaluation instance $\\mathcal{P}^{\\prime}$ , trained model $\\mathrm{NN}^{u}/\\mathrm{NN}^{u}$ . Note that the trained model $(\\mathbf{N}\\mathbf{N}^{u}/\\mathbf{N}\\mathbf{N}^{u})$   \nis used on multiple evaluation instances.   \nif approximating upper-level then $\\mathbf{x}^{\\star}\\gets$ upper-level solution from the upper-level approximation (Equation (5))   \nelse if approximating lower-level then $\\mathbf{x}^{\\star}\\gets$ upper-level solution from the lower-level approximation (Equation (7))   \nend if   \nreturn $\\mathbf{x}^{\\star}$ ", "page_idx": 14}, {"type": "text", "text": "C Example Comparing the Upper- and Lower-level Approximations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Example C.1. Consider the problem ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{x\\in\\{0,1\\}}{\\operatorname*{min}}\\ y}\\\\ &{\\quad s.t.\\quad y\\in\\underset{y\\in\\{0,1\\}}{\\arg\\operatorname*{max}}\\left\\lbrace y:2x+y\\leq1\\right\\rbrace.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Solution $x=1$ makes the follower\u2019s problem infeasible. For solution $x=0$ , the optimal follower solution is $y=1$ leading to the optimal value 1. Assume that the same trained neural network is used in both approaches; this is possible since leader and follower have the same objective functions. If it predicts $\\mathbf{NN}(0)=2$ and $\\mathbf{NN}(1)=0$ , then the upper-level approximation problem (5) will return $x=1$ which is infeasible whereas the lower-level approximation (7) correctly returns $x=0$ . ", "page_idx": 15}, {"type": "text", "text": "D Proofs for Approximation Guarantees ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "This section includes the full analysis of the derived approximation guarantee in Section 3.3 for the lower-level approximation with $\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)$ . ", "page_idx": 15}, {"type": "text", "text": "Recall that we look at a specific setup for which we derive approximation guarantees: the leader and the follower have the same objective function (i.e., $f(\\mathbf{x},\\mathbf{y})=F(\\mathbf{x},\\mathbf{y})$ for all $\\mathbf{x}\\in\\mathcal{X},\\mathbf{y}\\in\\mathcal{Y})$ , we assume that Assumption 1(i) holds and that the neural network approximates the optimal value of the follower\u2019s problem up to an absolute error of $\\alpha>0$ , i.e., ", "page_idx": 15}, {"type": "equation", "text": "$$\n|\\mathbf{NN}^{l}(\\mathbf{x};\\Theta)-\\Phi(\\mathbf{x})|\\leq\\alpha\\quad\\mathrm{~for~all~}\\mathbf{x}\\in\\mathcal{X}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We furthermore define the parameter $\\Delta$ as the maximum difference of functions values $f(\\mathbf{x},\\mathbf{y})-$ $f(\\mathbf{x},\\mathbf{y}^{\\prime})\\;\\geq\\;0$ over all $\\mathbf{x}\\,\\in\\,{\\mathcal{X}},\\mathbf{y},\\mathbf{y}^{\\prime}\\,\\in\\,{\\mathcal{Y}}$ such that no $\\tilde{\\textbf{y}}\\in\\mathcal{V}$ exists which has function value $f(\\mathbf{x},\\mathbf{y})>f(\\mathbf{x},\\tilde{\\mathbf{y}})>f(\\mathbf{x},\\mathbf{y}^{\\prime})$ . Note that $\\Delta$ can be strictly larger than zero if the follower decisions are integer. ", "page_idx": 15}, {"type": "text", "text": "For a fixed $\\mathbf{x}\\in\\mathcal{X}$ , ${\\bf y}_{\\mathrm{NN}}^{\\star}({\\bf x})$ denotes an optimal solution of (7). Furthermore, for any given $\\mathbf y\\in\\mathcal D$ we denote by $\\mathbf{s}^{\\star}(\\mathbf{x},\\mathbf{y})$ an optimal slack-value in Problem (7) if the upper- and lower-level variables are fixed to $\\mathbf{x}$ and $\\mathbf{y}$ , respectively. ", "page_idx": 15}, {"type": "text", "text": "Observation D.1. For any $\\mathbf{x}\\in\\mathcal{X}$ and $\\mathbf y\\in\\mathcal D$ we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbf{s}^{\\star}(\\mathbf{x},\\mathbf{y})=\\operatorname*{max}\\{0,\\mathbf{NN}^{l}(\\mathbf{x};\\Theta)-f(\\mathbf{x},\\mathbf{y})\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma D.2. Assume the leader and the follower have the same objective function and $\\lambda>1$ . Then, for any given $\\textbf{x}\\in\\:\\mathcal{X}$ the following conditions hold for the optimal follower solution ${\\bf y}_{\\mathrm{NN}}^{\\star}({\\bf x})$ of Problem (7): ", "page_idx": 15}, {"type": "text", "text": "$-\\,\\,I f\\,\\mathbf{NN}^{l}(\\mathbf{x;}\\Theta)\\,\\geq\\,\\Phi(\\mathbf{x}),$ , then $f({\\bf x},{\\bf y}_{\\mathrm{NN}}^{\\star}({\\bf x}))\\;=\\;\\Phi({\\bf x}),$ , i.e., $(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ is feasible for the original bilevel problem. $\\begin{array}{r}{-\\ H\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)<\\Phi(\\mathbf{x}),\\,t h e n\\,\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)-\\frac{1}{\\lambda}\\Delta\\leq f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))\\leq\\Phi(\\mathbf{x}).}\\end{array}$ ", "page_idx": 15}, {"type": "text", "text": "Proof. Case 1: Let $\\mathbf{x}\\in\\mathcal{X}$ for which it holds $\\begin{array}{r}{\\mathrm{NN}^{l}(\\mathbf{x};\\Theta)\\ge\\Phi(\\mathbf{x})}\\end{array}$ and assume the opposite of the statement is true, i.e., for the optimal reaction $y_{\\mathrm{NN}}^{\\star}(\\mathbf{x})$ in (7) it holds that $\\Phi(\\mathbf{x})\\,>\\,{\\bar{f}}(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ . Since $\\lambda\\,>\\,0$ and due to Constraint (7d) the optimal slack value for solution $\\mathbf{x}$ in Problem (7) is $\\mathbf{s}^{\\star}(\\mathbf{x},\\mathbf{y})=\\mathbf{NN}^{l}(\\mathbf{x};\\Theta)-f(\\mathbf{x},\\mathbf{y})$ . Assume $\\mathbf{y}^{\\star}(\\mathbf{x})$ is the optimal follower reaction in (2) for $\\mathbf{x}$ , then it holds that: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(\\mathbf{x},\\mathbf{y}_{\\mathbf{NN}}^{\\star}(\\mathbf{x}))+\\lambda\\mathbf{s}^{\\star}(\\mathbf{x},\\mathbf{y}_{\\mathbf{NN}}^{\\star}(\\mathbf{x}))}\\\\ &{=f(\\mathbf{x},\\mathbf{y}_{\\mathbf{NN}}^{\\star}(\\mathbf{x}))+\\lambda\\left(\\mathbf{NN}^{l}(\\mathbf{x};\\boldsymbol{\\Theta})-f(\\mathbf{x},\\mathbf{y}_{\\mathbf{NN}}^{\\star}(\\mathbf{x}))\\right)}\\\\ &{>f(\\mathbf{x},\\mathbf{y}_{\\mathbf{NN}}^{\\star}(\\mathbf{x}))+\\lambda\\left(\\mathbf{NN}^{l}(\\mathbf{x};\\boldsymbol{\\Theta})-f(\\mathbf{x},\\mathbf{y}_{\\mathbf{NN}}^{\\star}(\\mathbf{x}))\\right)+(\\lambda-1)\\left(f(\\mathbf{x},\\mathbf{y}_{\\mathbf{NN}}^{\\star}(\\mathbf{x}))-f(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))\\right)}\\\\ &{=f(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))+\\lambda\\left(\\mathbf{NN}^{l}(\\mathbf{x};\\boldsymbol{\\Theta})-f(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))\\right)}\\\\ &{=f(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))+\\lambda\\mathbf{s}^{\\star}(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the first inequality follows since $\\lambda>1$ and $f(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))\\,=\\,\\Phi(\\mathbf{x})\\,>\\,f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ and the latter equality follows from $\\mathbf{NN}^{l}(\\mathbf{x};\\Theta)\\,\\geq\\,\\Phi(\\mathbf{x})\\,=\\,f(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))$ . The latter result shows that the solution $(\\mathbf{x},\\mathbf{y}^{\\star}(\\mathbf{x}))$ has a strictly better objective value in the surrogate problem (7) than $(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ which contradicts the optimality of $(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ . ", "page_idx": 16}, {"type": "text", "text": "Case 2: Let $\\mathbf{x}\\in\\mathcal{X}$ be a leader\u2019s decision for which $\\mathrm{NN}^{l}(\\mathbf{x};\\boldsymbol{\\Theta})<\\boldsymbol{\\Phi}(\\mathbf{x})$ and assume the opposite of the statement, i.e., for the optimal reaction ${\\bf y}_{\\mathrm{NN}}^{\\star}({\\bf x})$ in (7) it holds that $\\begin{array}{r}{\\mathbf{NN}^{l}(\\mathbf{x};\\Theta)-\\frac{1}{\\lambda}\\Delta>f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))}\\end{array}$ . Hence the optimal slack value in (7) is ", "page_idx": 16}, {"type": "equation", "text": "$$\ns^{\\star}\\big({\\bf x},{\\bf y}_{\\mathrm{NN}}^{\\star}({\\bf x})\\big)=\\mathrm{NN}^{l}({\\bf x};\\Theta)-f({\\bf x},{\\bf y}_{\\mathrm{NN}}^{\\star}({\\bf x}))>\\frac{1}{\\lambda}\\Delta.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "First, assume there exists another feasible solution $\\bar{\\bf y}({\\bf x})$ for Problem (7) with ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))<f(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))<\\mathbf{NN}^{l}(\\mathbf{x};\\Theta)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "then solution $(\\mathbf{x},\\bar{\\mathbf{y}}(x))$ has a strictly better objective value than $(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ in (7) since increasing the value of $f$ by $\\delta$ decreases the value of the slack variable by $\\delta$ which results in a better objective value since $\\lambda>1$ , which contradicts the optimality of $(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ . ", "page_idx": 16}, {"type": "text", "text": "Second, assume there exists no other feasible solution $\\bar{\\bf y}({\\bf x})$ for Problem (7) with ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))<f(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))<\\mathbf{NN}^{l}(\\mathbf{x};\\Theta).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then there must exists a feasible solution $\\bar{\\bf y}({\\bf x})$ with $f(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))\\ge\\mathbf{NN}^{l}(\\mathbf{x};\\boldsymbol{\\Theta})$ and ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))-f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))\\leq\\Delta,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "by definition of $\\Delta$ . In this case, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))+\\lambda\\mathbf{s}^{\\star}(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))-f(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))-\\lambda\\mathbf{s}^{\\star}(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))}\\\\ &{=f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))+\\lambda\\mathbf{s}^{\\star}(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))-f(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))}\\\\ &{>f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))+\\Delta-f(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))\\geq-\\Delta+\\Delta=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the first equality follows since $\\mathbf{s}^{\\star}(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))=0$ , the first inequality follows from (10) and the last inequality follows from (11). In summary, the latter results show that there exists a solution $(\\mathbf{x},\\bar{\\mathbf{y}}(\\mathbf{x}))$ for (7) which has strictly better objective value than $(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))$ which is a contradiction. Note that the inequality $f(\\mathbf{x},\\mathbf{y}_{\\mathrm{NN}}^{\\star}(\\mathbf{x}))\\leq\\Phi(\\mathbf{x})$ follows directly from the definiton of $\\Phi(\\mathbf{x})$ . \u518f\u53e3 ", "page_idx": 16}, {"type": "text", "text": "The latter lemma states, that if the neural network is overestimating the follower value for a solution $\\mathbf{x}\\in\\mathcal{X}$ , then the surrogate problem (7) still selects an optimal follower response. However, if the neural network underestimates the value, it may happen that the surrogate problem chooses a follower response for which the objective value either is larger than the true value or differs by at most $\\scriptstyle{\\frac{1}{\\lambda}}\\Delta$ Note that the latter term can be controlled by increasing the penalty $\\lambda$ . ", "page_idx": 16}, {"type": "text", "text": "By applying Lemma D.2 we can bound the approximation guarantee of the lower-level NEUR2BILO. ", "page_idx": 16}, {"type": "text", "text": "Theorem 3.1. If the leader and the follower have the same objective function and $\\lambda\\ >\\ 1$ , NEUR2BILO returns a feasible solution $(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})$ for Problem (1) with objective value ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})\\leq\\mathrm{opt}+3\\alpha+\\frac2\\lambda\\Delta,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where opt is the optimal value of (1) and $\\lambda$ the penalty term in (7a) . ", "page_idx": 16}, {"type": "text", "text": "Proof. Let $(\\mathbf{x}_{\\mathrm{NN}}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})$ be an optimal solution of the surrogate problem (7). By Lemma D.2 and by definition (8) it follows that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Phi(\\mathbf{x}_{\\mathrm{NN}}^{\\star})\\geq f(\\mathbf{x}_{\\mathrm{NN}}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})\\geq\\mathbf{NN}^{l}(\\mathbf{x}_{\\mathrm{NN}}^{\\star};\\Theta)-\\frac{1}{\\lambda}\\Delta}\\\\ &{\\quad\\quad\\quad\\geq\\Phi(\\mathbf{x}_{\\mathrm{NN}}^{\\star})-\\alpha-\\frac{1}{\\lambda}\\Delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Following the three steps presented in Section 3.1, NEUR2BILO returns a feasible solution $(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})$ for Problem (2) where $\\mathbf{x}^{\\star}=\\mathbf{x}_{\\mathrm{NN}}^{\\star}$ and $f(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})=\\Phi(\\mathbf{x}^{\\star})$ . Hence the following holds: ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(\\mathbf{x}^{\\star},\\mathbf{y}^{\\star})=\\Phi(\\mathbf{x}^{\\star})\\leq f(\\mathbf{x}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})+\\alpha+\\frac{1}{\\lambda}\\Delta.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Assume $(\\mathbf{x}^{\\star\\star},\\mathbf{y}^{\\star\\star})$ is an optimal bilevel solution of Problem (1) and $\\mathbf{y}_{\\mathrm{NN}}^{\\star\\star}$ the optimal follower response in the surrogate problem (7). Then we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nf(\\mathbf{x}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})+\\mathbf{s}^{*}(\\mathbf{x}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})\\le f(\\mathbf{x}^{\\star\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star\\star})+\\mathbf{s}^{*}(\\mathbf{x}^{\\star\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star\\star})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "since $(\\mathbf{x}_{\\mathrm{NN}}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})$ is an optimal solution of (7) with objective value given by (7a). From the latter inequality we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(\\mathbf{x}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})\\leq f(\\mathbf{x}^{\\star\\star},y_{\\mathrm{NN}}^{\\star\\star})+\\mathbf{s}^{*}(\\mathbf{x}^{\\star\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star\\star})-\\mathbf{s}^{*}(\\mathbf{x}^{\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star})}\\\\ &{\\qquad\\qquad\\leq f(\\mathbf{x}^{\\star\\star},\\mathbf{y}^{\\star\\star})+\\mathbf{s}^{*}(\\mathbf{x}^{\\star\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star\\star})}\\\\ &{\\qquad\\qquad\\leq f(\\mathbf{x}^{\\star\\star},\\mathbf{y}^{\\star\\star})+\\mathrm{NN}^{l}(\\mathbf{x}^{\\star\\star};\\boldsymbol{\\Theta})-f(\\mathbf{x}^{\\star\\star},\\mathbf{y}_{\\mathrm{NN}}^{\\star\\star})}\\\\ &{\\qquad\\qquad\\leq f(\\mathbf{x}^{\\star\\star},\\mathbf{y}^{\\star\\star})+\\Phi(\\mathbf{x}^{\\star\\star})+\\alpha-(\\Phi(\\mathbf{x}^{\\star\\star})-\\alpha-\\frac{1}{\\lambda}\\Delta)}\\\\ &{\\qquad\\qquad=\\mathsf{o p t}+2\\alpha+\\frac{1}{\\lambda}\\Delta}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the second inequality follows from ${\\bf s}^{*}({\\bf x}^{\\star},{\\bf y}_{\\mathrm{NN}}^{\\star})\\,\\ge\\,0$ and $\\mathbf{y}^{\\star\\star}$ being an optimal follower solution for $\\mathbf{x}^{\\star\\star}$ . The third inequality follows from Observation D.1 and the fourth inequality follows from (8) and from (12) applied to $\\mathbf{x}^{\\star\\star}$ . ", "page_idx": 17}, {"type": "text", "text": "Together with (13), this completes the proof. ", "page_idx": 17}, {"type": "text", "text": "E Problem Formulations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "E.1 Knapsack interdiction ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The bilevel knapsack problem with interdiction constraints as described in Tang et al. [54] is given by ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\min_{\\mathbf{x}\\in\\{0,1\\}^{n},\\mathbf{y},\\mathbf{y}}}&{\\displaystyle\\sum_{i=1}^{n}p_{i}y_{i}}\\\\ {\\mathrm{s.t.}\\quad}&{\\displaystyle\\sum_{i=1}^{n}x_{i}\\leq k,}\\\\ &{\\mathbf{y}\\in\\underset{\\mathbf{y}^{\\prime}\\in\\{0,1\\}^{n}}{\\mathrm{arg~max}}\\quad\\displaystyle\\sum_{i=1}^{n}p_{i}y_{i}^{\\prime}}\\\\ &{\\qquad\\qquad\\mathrm{s.t.}\\quad\\displaystyle\\sum_{i=1}^{n}a_{i}y_{i}^{\\prime}\\leq b,}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mu_{i}^{\\prime}+x_{i}\\leq1,i\\in[n],}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathbf{x}$ are the leader\u2019s variables and $\\mathbf{y}$ are that of the follower. The leader decides to interdict (a maximum of $k$ ) items of the knapsack solved in the follower\u2019s problem with $n$ the number of items, $p_{i}$ the profits, $a_{i}$ the weight of item $i$ , respectively, and the budget of the knapsack is denoted by $b$ . ", "page_idx": 17}, {"type": "text", "text": "E.2 Critical node problem ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The critical node problem is described in Carvalho et al. [11] as follows ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{\\mathbf{x}\\in\\{0,1\\}^{n},\\mathbf{y}}}&{\\displaystyle\\sum_{i=1}^{n}\\Big(p_{i}^{d}\\big((1-x_{i})(1-y_{i})+\\eta x_{i}y_{i}+\\epsilon x_{i}(1-y_{i})+\\delta(1-x_{i})y_{i}\\big)\\Big)}\\\\ {\\mathrm{s.t.}~}&{\\displaystyle\\sum_{i=1}^{n}d_{i}x_{i}\\leq D,}\\\\ &{\\mathbf{y}\\in\\mathrm{~arg\\,max}~}&{\\displaystyle\\sum_{i=1}^{n}\\Big(p_{i}^{a}\\big(-\\gamma(1-x_{i})(1-y_{i}^{\\prime})+(1-x_{i})y_{i}^{\\prime}+(1-\\eta)x_{i}y_{i}^{\\prime}\\big)\\Big)}\\\\ {\\mathrm{s.t.}~}&{\\displaystyle\\sum_{i=1}^{n}a_{i}y_{i}^{\\prime}\\leq A,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathbf{x}$ and y are the leader\u2019s and follower\u2019s variables, respectively. Here, x denotes the decisions of the leader (defender) who selects which nodes to deploy resources to defend a set of nodes, while y are the decisions for the follower (attacker) for which nodes to attack. $d_{i}$ and $a_{i}$ are the costs for the $x_{i}$ and $y_{i}$ , respectively. $D$ and $A$ are the budgets for the defender and attacker, respectively. In this problem, the bilinearity arises in the objectives of both the leader and follower, which results in four outcomes for each possible combination of defending and attacking a node $i$ . The first outcome arises when both the leader and follower do not select the node. In this case, the leader receives the full profit, $p_{i}^{d}$ , and the follower pays an opportunity cost of $-\\gamma p_{i}^{a}$ for not attacking an undefended node. Second is a successful attack, wherein the leader receives a reduced profit of $\\delta p_{i}^{d}$ and the follower receives the full profti $p_{i}^{a}$ . Third is a mitigated attack, wherein the leader receives a profti of $\\eta p_{i}^{d}$ for a degradation in operations, while the follower receives a profit of $(1-\\eta)p_{i}^{a}$ for a mitigated attack. Fourth is a mitigation without an attack, wherein the leader receives a profti $\\epsilon{p}_{i}^{d}$ for a degradation in operations, while the follower receives a profit of 0 for a mitigated attack. ", "page_idx": 18}, {"type": "text", "text": "E.3 Donor-recipient problem ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The donor-recipient problem as described in Ghatkar et al. [27], and introduced in Morton et al. [43], is formulated as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\operatorname*{max}_{\\mathbf{x}\\in[0,1]^{n},\\mathbf{y},\\mathbf{y}_{0}}}&{\\displaystyle\\sum_{i=1}^{n}w_{i}y_{i}}\\\\ {\\mathrm{s.t.}\\quad}&{\\displaystyle\\sum_{i=1}^{n}c_{i}x_{i}\\leq B_{d},}\\\\ &{(\\mathbf{y},y_{0})\\in\\displaystyle\\operatorname*{arg\\,max}_{\\mathbf{y}^{\\prime}\\in\\{0,1\\}^{n},\\mathbf{y}_{0}^{\\prime}\\in[0,1]}\\quad\\displaystyle\\sum_{i=1}^{n}v_{i}y_{i}^{\\prime}+v_{0}y_{0}^{\\prime}}\\\\ &{\\mathrm{s.t.}\\quad\\quad\\displaystyle\\sum_{i=1}^{n}(c_{i}-c_{i}x_{i})y_{i}^{\\prime}+c_{0}y_{0}^{\\prime}\\leq B_{r},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the leader\u2019s decisions $\\mathbf{x}$ represent those of the donor and the follower\u2019s decisions $(\\mathbf{y},y_{0})$ the ones of the recipient. The profit of project $i$ is given as $w_{i}$ for the leader and $v_{i}$ for the follower, the cost as $c_{i}$ , and the budget of the leader, resp. follower, as $B_{d}$ and $B_{r}$ . Next to the projects, the recipient can allocate its budget to external projects, for which the profti is given as $v_{0}$ and the cost $c_{\\mathrm{0}}$ . ", "page_idx": 18}, {"type": "text", "text": "E.4 Discrete network design problem ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We use the standard formulation from Section 1 following the computational benchmarking study of Rey [47] and the code provided by the author 2. ", "page_idx": 18}, {"type": "text", "text": "F Comparison to the Learning-Based Approach of Zhou et al. [59] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "This section compares our approach to a recent learning-based approach from Zhou et al. [59] based on code provided by the author 3. We specifically compare the input-supermodular neural network (ISNN), i.e., the best-performing model from Zhou et al. [59]. Their approach requires sampling and training for each instance, which is reflected in the time, whereas the model for $\\mathrm{NN}^{l}$ and ${\\bf N N}^{u}$ can be trained once and evaluated across multiple instances, so the data collection and training time are excluded. We also restrict ISNN to run for one iteration given Zhou et al. [59] report very minimal improvements when increasing the number of iterations. Moreover, one iteration requires the least amount of time. Table 3 reports the MRE and time for each method for the knapsack instances from Tang et al. [54]. Generally, we can see a significant improvement over ISNN in both computing time and MRE. ", "page_idx": 18}, {"type": "table", "img_path": "esVleaqkRc/tmp/49e3b0370d059ceca2b8858bbeb379b2cff68c2624dd1a4664225bacba987008.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Table 3: Comparison to ISNN from Zhou et al. [59] on the knapsack interdiction problem. $n$ and $k$ denote the number of items and the interdiction budget, respectively. We directly evaluate on the 180 instances (10 per size) of Tang et al. [54]; each value is the average over 10 instances. We compare the upper- and lower-level approximations, as well as the no-learning baseline (G-VFA) and the exact algorithm (B&C). ", "page_idx": 19}, {"type": "text", "text": "G Objective & Incumbent Results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "This section reports the more detailed information related to the objective values for each problem. Objective results for each problem are given in Tables 4-7. In addition, for KIP and CNP, as the solver from Fischetti et al. [23] provides easily accessible incumbent solutions, we include two additional metrics. ", "page_idx": 19}, {"type": "text", "text": "\u2013 The first metric \u201cSolver Time Ratio\" measures the time it takes the solver to obtain an equally good (or better) incumbent solution, divided by the solving time of the respective approximation. The number in brackets to the right indicates the number of instances for which the solver finds an equivalent solution.   \n\u2013 The second metric \u201cSolver Relative Error at Time\" measures the relative error of the best solution found by the solver compared to the respective approximation. The value in brackets to the right indicates the number of instances for which the solver finds an incumbent before the approximation is done solving. ", "page_idx": 19}, {"type": "image", "img_path": "esVleaqkRc/tmp/8a94a7f8971926d1a97b4611ea5934a0a93d59da9b6fb4c897f0edb9fe793008.jpg", "img_caption": ["Table 4: KIP objective and incumbent results. Each row averaged over 10 instances, except for $n=100$ , which is average over 100 instances. $\\mathbf{NN}^{l}$ and ${\\bf N N}^{u}$ specify the lower- and upper-level approximations respectively. All times in seconds. "], "img_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "esVleaqkRc/tmp/af9e79530ab8310c16366aacf0f1e368802969c91ed3333a9513898261567c65.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "esVleaqkRc/tmp/eb4ecf0b5ce6b1e453a4eff73623e56bf769dbd86ed94cc1fcde312abd7e1da4.jpg", "table_caption": ["Table 5: CNP objective and incumbent results. Each row averaged over 300 instances. All times in seconds. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Table 6: DRP objective results. Each row corresponds to a single instance from dataset 15, i.e., the most challenging instances from Ghatkar et al. [27]. All times in seconds. ", "page_idx": 20}, {"type": "table", "img_path": "esVleaqkRc/tmp/7cb0927d177451b105f313f4a81c78cfe58a0ecff229f533f189e5e4f44cbac1.jpg", "table_caption": ["Table 7: DNDP objective results. Each is averaged across 10 instances. All times in seconds. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "H Distributional Results for Relative Error ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "I Ablation ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "I.1 Lower-level value function constraints ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we present an ablation study comparing alternative types of value function approximation (VFA) for the lower-level approximation on the KIP. Namely, we compare the approach used the the main paper, $\\mathbf{NN}^{l}$ , which utilizes a slack variable to ensure feasibility. In addition, we include ${\\mathsf{N N}}^{n}$ which does not use a slack at all, and $\\mathbf{NN}^{d}$ , which uses the largest error in the validation set to scale the prediction down. Table 8 reports objectives, relative errors, and solving times of each method. In general, the solution quality of $\\mathbf{NN}^{l}$ slightly exceeds that of $\\mathbf{NN}^{d}$ , while ${\\bf N N}^{n}$ does significantly worse. The latter results is unsurprising given that any underestimation will cause a loss of feasibility for potentially high quality upper-level decisions. $\\mathbf{NN}^{l}$ is additionally generally the fastest to optimize as well. ", "page_idx": 20}, {"type": "text", "text": "I.2 The effect of $\\lambda$ ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we present results with $\\lambda=0.1$ for DNDP. Table 9 presents relative error and solving times for this setting. Notably, this choice of $\\lambda$ tends to provide higher quality solutions than $\\lambda=1$ , as reported in the main paper in Table 2. Tuning this hyperparameter further can thus improve the already strong numerical results reported for DNDP, and possibly other problems. ", "page_idx": 20}, {"type": "text", "text": "I.3 Greedy features for Knapsack ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "This section explores the impact of the use of greedy features on the KIP problem. We specifically compare a model trained purely on the coefficients to a model trained on the coefficients with additional features derived from KIP-specific greedy heuristics. From Table 10, there is a clear advantage with the greedy features in terms of solution quality at the cost of increased solving time. ", "page_idx": 20}, {"type": "table", "img_path": "esVleaqkRc/tmp/5ec2539abdee3e00b9cc0f2458f47eca2b69481569f96f3cd89dd1d73890551a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "esVleaqkRc/tmp/ac0bec9466e824ff1fd088cc72fdee2c9ea4a791233398f66ab502119a1aec64.jpg", "table_caption": ["Table 8: KIP results comparing $\\mathbf{NN}^{l},\\,\\mathbf{NN}^{d}$ , and ${\\bf N N}^{n}$ . Each row is an average over 10 instances, except for $n=100$ , which is an average over 100 instances. All times in seconds. "], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "esVleaqkRc/tmp/6ea2e188756069ecd52bffa2f9fac779bea6f0e99d64cf442713dffbfd5d83ca.jpg", "table_caption": ["Table 9: DNDP results for $\\lambda=0.1$ . Each is averaged across 10 instances. $\\mathbf{NN}^{l}$ and $\\mathrm{GBT}^{l}$ are the learning-based formulations with slack for the lower-level approximation. ${\\bf N N}^{u}$ and $\\mathrm{GBT^{\\mathit{u}}}$ are the learning-based formulations for the upper-level approximation. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "Table 10: KIP results comparing $\\mathbf{NN}^{l}$ with and without greedy-based features $\\mathbf{NN}^{d}$ . Each row averaged over 10 instances, except for $n=100$ , which is an average over 100 instances. All times in seconds. ", "page_idx": 21}, {"type": "image", "img_path": "esVleaqkRc/tmp/5c6aecf9d2dbf24540f6568c189c523fd54623482c16ba684a09df264198d336.jpg", "img_caption": ["Figure 1: Box plot of relative errors for KIP with interdiction budget of $k=n/4$ . "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "esVleaqkRc/tmp/d811284fcc381fdc419417e0491378e8192578aaa7e0a5e805eb03c80929ec07.jpg", "img_caption": ["Figure 2: Box plot of relative errors for KIP with interdiction budget of $k=n/2$ . "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "J Computing Setup ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The experiments for three out of four benchmarks were run on a computing cluster with an Intel Xeon CPU E5-2683 and Nvidia Tesla P100 GPU with 64GB of RAM (for training). The experiments for one benchmark were run on a virtual machine with two Intel Xeon(R) CPUs at 2.20GHz and 12GB of RAM. Pytorch 2.0.1 [44] was used for all neural network models and scikit-learn 1.4.0 was used for gradient-boosted trees in the DNDP [46]. Gurobi 11.0.1 [30] was used as the MILP solver and gurobi-machinelearning 1.4.0 was used to embed the learning models into MILPs. ", "page_idx": 22}, {"type": "text", "text": "K Machine Learning Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "K.1 Models, features, & hyperparameters ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "For all problems, we derive features that correspond to each upper-level decision variable, as well as general instance features. ", "page_idx": 22}, {"type": "text", "text": "K.1.1 KIP, CNP, DRP ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "For KIP, CNP, DRP, we have $n$ decisions in both the upper- and lower-level of the problems. For the learning model, we utilize a set-based architecture [58], wherein we first represent the objective and constraint coefficients for each upper-level and lower-level decision, independent of the decision $(\\mathbf{f}_{i})$ . Each of these are passed through a feed-forward network with shared parameters $(\\Psi_{d})$ to compute an $m$ -dimension embedding. The embeddings are then summed and passed through another feed-forward network $(\\Psi_{s})$ to compute the instance\u2019s $k$ -dimensional embedding. This instance embedding is then concatenated with features related to the upper- and lower-level that are dependent on the decision $(h(\\mathbf{x}_{i}))$ . The concatenated vector is passed through a feed-forward network with shared parameters $(\\Psi_{v})$ to predict $n$ scalar values (i.e., one for each decision). The final prediction is equal to the dot product of the $n$ predictions with the objective function coefficients of the upper- or lower-level problem, depending on the type of value function approximation. This final step exploits the separable nature of the objective functions in question as they can all be expressed as in=1 cizi, where $c_{i}$ is a known coefficient and $z_{i}$ is a decision variable or a function of a set of decision variables with index $i$ . The objectives for KIP, CNP, and DRP all satisfy this property. We leverage this knowledge of the coefficients of separable objective functions as an inductive bias in the design of the learning architecture to facilitate convergence to accurate models. The decision-dependent and decision-independent features are summarized in Table 11. ", "page_idx": 22}, {"type": "image", "img_path": "esVleaqkRc/tmp/99dacfdd82da669828fb7bc62e5f276d52adbba63c0d87ff169e372d4c1314ef.jpg", "img_caption": ["Figure 3: Box plot of relative errors for KIP with interdiction budget of $k=3n/4$ . "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "esVleaqkRc/tmp/a884f980d235044ec0c788b7e14b5198d794ff553c44603b939bda8b13c12f24.jpg", "img_caption": ["Figure 4: Box plot of relative errors for CNP. B&C does not find any upper-level solutions for 2 of the 300 instances of size $|V|=500$ , so these are excluded from the plot. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "One minor remark for KIP is that since it is an interdiction problem, we multiply the concatenated vector, i.e., the input to $\\Psi_{v}$ , by $\\left(1-x_{i}\\right)$ as a mask given that the follower cannot select the same items as the leader. ", "page_idx": 23}, {"type": "text", "text": "For all instances, we do not perform systematic hyperparameter tuning. The sub-networks $\\Psi_{d},\\,\\Psi_{s}$ , $\\Psi_{v}$ are feed-forward networks with one hidden layer of dimension 128. The decision-independent feature embedding dimension $(m)$ is 64, and the instance embedding dimension $(k)$ is 32. We use a batch size of 32, a learning rate of 0.01, and Adam [31] as an optimizer. ", "page_idx": 23}, {"type": "text", "text": "K.1.2 DNDP ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We train neural network models (one hidden layer, 16 neurons, a learning rate of 0.01 with the Adam optimizer) and gradient-boosted trees (default scikit-learn hyperparameters, except for n_estimators $=50$ ). The inputs to these models are 30-dimensional binary vectors representing the subset of links selected by the leader. ", "page_idx": 23}, {"type": "image", "img_path": "esVleaqkRc/tmp/eae88bbab2365211e96939627ff344f74660bf1ba8703d32e9e10867ed196ee8.jpg", "img_caption": ["Figure 5: Box plot of relative errors for DNDP with 10 edges. MKKT-{5,10,30} corresponds to MKKT run with each respective time limit. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "esVleaqkRc/tmp/5f0bcde5cc25a51ab521e0fadfe1f075b223d77df503cccb0613451325128e0e.jpg", "img_caption": ["Figure 6: Box plot of relative errors for DNDP with 20 edges. MKKT-{5,10,30} corresponds to MKKT run with each respective time limit. "], "img_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "esVleaqkRc/tmp/ef8981c7743f2cf4848a740895fac9fdc19b7f5154ee7837c5bd588cb2f29faa.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Table 11: Features for KIP, CNP, and DRP. Most features are derived directly from the objective aarned  ccoomnspturtaeidn t ucsoinefg fsiciimenptlse,  gsroe reedfye rh teou rAisptipcesn. dFiox r Et hfeo rK tIhPe  DdIeFf,i niwtieo cnos.m Fpourt $x_{i}^{d g},y_{i}^{d g},o b j^{d g}$ ,e awthuircehs $k$ profit to cost ratio $(p_{i}/a_{i})$ and the lower-level decisions are the largest remaining highest profit to cost ratio items. For $h(\\mathbf{x}_{i})$ in KIP, we also include lower-level decisions based on G-VFA $(y_{i}^{g})$ . ", "page_idx": 24}, {"type": "text", "text": "K.2 Data collection & training times ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "For KIP, CNP, DRP, we sample 1,000 instances according to the procedures specified in Tang et al. [54], Dragotto et al. [18], and Ghatkar et al. [27], respectively. For each instance, we sample 100 upper-level decisions, i.e., 100,000 samples in total. Additionally, for KIP, CNP, DRP, the lower-level problems are solved with 30 CPUs in parallel. For training, we train for 1,000 epochs. However, if the validation mean absolute error does not improve in 200 iterations, we terminate early. Data collection and training times are reported in Table 12. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "For DNDP, we use the Sioux Falls transportation network provided by [47] along with the author\u2019s 60 test instances. All instances use the same base network with different sets of candidate links to add and different budgets. There are 30 candidate links in total, and each test instance involves a subset of 10 or 20 of these links. To construct a training set, we sample 1000 leader decisions by first uniformly sampling an integer between 1 and 20, then uniformly sampling that many candidate links out of the set of 30 options; samples with total cost exceeding $50\\%$ of the total cost of all 30 edges are rejected as they are likely to exceed realistic budgets. ", "page_idx": 25}, {"type": "table", "img_path": "esVleaqkRc/tmp/b290f4d6abe25641b3f51dcf93c3cd50fa9cb21c16dc3278a458a07642ebad99.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "K.3 Prediction error ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "For KIP, CNP, and DRP, we provide the Mean Absolute Error (MAE), as well as the Mean Absolute Label (MAL) as a reference to access the prediction quality for the validation data in Table 13. The table shows that models achieve a MAE of at most $\\sim\\!1e^{-\\bar{6}}$ with a MAL ranging from 0.006 to 200 depending on the problem. For the DNDP, both neural network and gradient-boosted tree models achieve Mean Absolute Percentage Error (MAPE) values of less than $5\\%$ . ", "page_idx": 25}, {"type": "table", "img_path": "esVleaqkRc/tmp/c4bf0bf57fb491e5394435dd141c0945f3e5b701dc4c2233e79216af29ba430a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "Table 13: Prediction errors for all problems. Note that as KIP is an interdiction problem, the same trained model can be used for the upper- and lower-level approximation, so we simply leave the lower-level as - for this problem. ", "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The methodology and numerical results accurately validate the key methodological contributions and computational performance discussed in the abstract and introduction. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Key limitations of NEUR2BILO are briefly discussed in Section 3. Any assumptions are explicitly stated throughout the paper and appendices. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Full theorems, assumptions, and complete proofs are provided in the appendix.   \nImportant assumptions are mentioned in the main paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Yes, the paper provides sufficient detail for the methodology and the learning models in the appendix. The code provided also include can be run to reproduce the results in the paper, the trained models and test instances are also included. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 27}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: Yes, all of the code and data are available here at https://github.com/ khalil-research/Neur2BiLO. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification:Yes, these details are included in detail in Appendix K Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: Yes. While the main paper reports averages, full distributional information for the main computational results is included in Appendix H. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: All computing information is discussed in Appendix J. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Justification: The research does not involve human subjects. Given the nature of the paper, there are no data-related concerns. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: Yes, an impact statement is provided in the appendix. For the camera-ready version of the paper, we will include this in the main paper, given the additional space provided. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The released models do not have a high risk of misuse. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The creators either own or properly credit all code/data/models. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: All assets (dataset/code/model) are available and anonymized. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 31}]